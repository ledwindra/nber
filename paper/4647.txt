NBER WORKING PAPER SERIES

DID COMPUTER TECHNOLOGY DIFFUSE
QUICKLY?: BEST AND AVERAGE
PRACI1CE IN MAINFRAME COMPUTERS,
1968-1983

Shane M. Greenstein

Working Paper No. 4647

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
February 1994

This paper is a condensed version of Greenstein [1993a]. I would like to thank Ernst Berndt,
Paul David, Zvi Griliches, Larry Neal, Ed Steinmueller, and Manuel Trajtenberg for useful
conversations connected with this work. Seminar participants at the NBER productivity
workshop, the University of Illinois, and University of Oregon provided many comments on
earlier drafts. Julie Lee and Jennifer Howitt entered data, and Sandra Ospina and Ken Brown
provided outstanding research assistance. Patrick McGovern and the Charles Babbage
Institute deserve thanks for helping out in the assembly of the data used in this paper. The
Center for Economic Policy Research at Stanford University and the Arnold 0. Beckman
Endowment at the University of Illinois provided funding. Only I am responsible for the
errors contained in this paper. This paper is part of NBER's program in Productivity. Any
opinions expressed are those of the author and not those of the National Bureau of Economic
Research.

NBER Working Paper #4647
February 1994

DID COMPUTER TECHNOLOGY DIFFUSE
QUICKLY?: BEST AND AVERAGE
PRACTICE IN MAINFRAME COMPUTERS,
1968-1983

ABSTRACT

An economy benefits from advances in technical frontiers only when new technology

comes into general use. This paper measures the diffusion of computing equipment at a time
when computing technology underwent dramatic technical improvement. These data shed light

on the long lag between advances in computing technology and advances in economic
performance of users. There is little evidence that long lags were produced by the 'slow
diffusion' of new technology embodied in new hardware. "Average practice" in computing
advanced as rapidly as "best practice," lagging it by a maximum of 6 to 7 years.

Shane M. Greenstein
Department of Economics
David Kinley Hall, Box 70
University of Illinois
Urbana, IL 61801
and NBER

1. Inliixhction

Best-practice computing technology has advanced rapidly in the last 30 years) Yet, it is hasty

to infer that economic ve1fare improved at the same rate. What matters for economic lfare is the

advance of echnologies in general use, not necessarily the advance of the best practice, ich very
few may put into use quickly. Despite all the attention paid to the advances in best practice, little
economic research examines the diffusion of computing technology or the economic value of systems

in 2
This paper provides rneasuces of diffusion for 1968 to 1983, a time when the best practice

technology wxiernt rapid improvemenL

analysis sho that average practice advanced rapidly

in the United States. In most years, average practice advanced at a rate comparable to best practice,
irrespective of the measuce used for either. Average practice never lagged best practice by more than 6

to 7 years and usually by less. Compared vith many other studies of the diffusion of important
historical innovation of the last 200 years (e.g., Mansfield [1968]), this represents an extraordinary fast
diffusion of new technology.

These results support tw conclusions. First, the papet's results relate to several difftision

mechanisms, analyzed in David [1989], that could account for the long lag beten advance of best
practice computing technology and productivity growth. The analysis shos that there is no evidence
to support the simplist possible mechanism, that hardware embodying new technology diffused slowly.

This result is consistent with David's [1989] emphasis on other mechanisms, e.g., the time it takes to
learn about new capabilities and the re-organize business enterprises.

See Gordon [1989], EXilberger [1989], Cole et al [1986], Triplett [1989], Berndt, Sho1ter, and Woolridge
[1990], Bemdt and Griliches [1991], and (Miner [1993a]. Despite some disagreement, most indexes of
mainframes yield advances in qua1it'price on the order of 20% to 25% a year over the last thirty years.
2Exceptions include: Berndt and Mxrison [1991], Berndt, N'krrison and Rosenblum [1992], and Bresnahan
[1987].

In the same spirit, the paper highlights others ways in which best practice frontiers for
computing. usually estimated with hedonic methods (Tiipplett [1989]), may provide a deceptive
indicator of the economic benefits accmeing to computer users. The besic economics of the problem is

straightforward and wil-known Each old user reacts to new technology with a different adoption
response. Advances in best practice do not necessarily translate into uniform economic benefits across
all computer users because new practice does not uniformly replace old practice everywhere very
quickly. The open issues addressed in this paper are empirical, i.e., how varied is the response across
users and how does this variation influence measurement of the benefits from technical change?

2. Data on the Installed Base of CompterSysteim
This study uses data from DC, & best historical data available on the size of installed bese
of computers and their rental prices. No other comparable data source exists for the l960s and 1970s.
Only a few studies of the computing market (e.g., Mlcheals [1979], Phister [1979], Flamm [l987a,b],
Ehilberger [1989], Oliner [1993a]) have used data from a similar source and none ever exploited all

facets of it. Before beginning U analysis, the paper must discuss the limitations these data impose on
the measure of best and average practice. lvkre detailed descriptions of these data are included in the

appendix
The anaiysis begins with the December 31, l%8 report and end with the January 1, 1983
report. It begins with 1968 because this is the first year in which DC distinguished between the
nunther of installations within the US and outside the United States. It ends with the 1983 report,

because all of IDCs census undeznt a massive reclassification after 1983, the last year that DC
maintains its mainframe file separately from other types of computer systems.

This paper accepts IDCs definitions of what is a mainframe computer (as opposed to a minicomputer, a small business system or a desktop system). This makes my estimates comparable with

2

Phister's [1979] and Flarnm's [1987] description of the diffusion of computing equipment, vhith used

more aggregate IDC data It also makes my results comparable to Olinefs [1993a] analysis of the

retirement patterns anxng IBM mainframes, wiith uses similar DC data for IBM systems. As a
secondary benefit, employing IDCs definitions renves any suspicion that tho defmition vas chosen
arbitrarily or chosen to manipulate the results (though I have found that most of this paper's analysis is
robust to small changes in definitions). Over the entire 16 year period, these data concern the installed

base of over 350 different computer systems. 11 appendix provides a list of the important frluded
systems.

Three biases arise from maintaining exclusive use of IDCs definition of a mainframe. First, in
1968 and 1969 IDCs early definition of a mainframe is too broad, including some systems that they
reclassifS' as "Digital Dedicated Application" in i97O. This will influence some of the results below.

Second, more redefinition problems arise on a smaller scale when DC began several data bases for
systems other than mainframes (i.e., minicomputers, small business systems, desktop). Its researchers

occasionally move a system into the mainframe category that was not there previously or move a
system out of the mainframe category that was there previously. Most of these redefinitions do not

matter, but a few influence the results below. The most important case is IDCs decision to include the
IBM System 36 in the sample in 1976 (estimated installed base at 5000 units) and exclude it from
mainframes thereafter (but include it in "small business systems"). Third, by the end of the sample, the
difference between mainframes and some large mini-computers (a.k.& "super-minis") becomes bkuTed,

main issue is whether IDC includes in the

raising questions about the survey's completeness.

mainframe category all the super-minicomputer systems that ware close substitutes for mainframes. A

3Phister identifies several years in ich IDC revised the reported number of installations in previous years,
particular for IBM models in 1967-1972. In those cases, Phist&s reported updates were used.
4This occulTed as part of a general reclassification of all IDC censuses.

3

reasonable case could be made that DC incloded most relevant systems.5 A reasonable case could also

be made that they did not, especially by 1983.' Overall, the omissions do not bias important results
below except in one place, which svill be noteci

3. A first look at different vintages.

IDCs surveys do not record when a user installs each new acquisition. However, IDC does
record the date (year-month) at which each model of a system was first installed anywhere in the
United States. For example, the IBM 360i20 was first installed in November 1965, the IBM 37&125

in May 1973, and the IBM 3031 inFebmasy 1978. Asummasy of product introductions is presented
in the appendix. Call this munber VINFAGE. VThffAGE provides one measure of the technology

embedded in each systen because systems developed later arid introduced later tend to be better in
several respects than those developed and introduced earlier.

As a measure of technological capability, VINFAGE has two significant dmwhecks. First, it
does not measure differences in the performance of different systems introduced at the same time.
Thus, VINFAGE is likely to be a poor measure of success in inter-system competition. This deficiency
is difficult to correct because there is no standard method for using installed base to weight results
(e.g., See Greenstein [1 993b] for one such attempt). A second important drawback is that VINTAGE

It is not clear whether the money spent on super-minis ever amounted to more than a small fraction of the
amount of money spent on mainframes. According to the 1983 IDC census for mini-computers and mainframes,
the value of installed base associated with super-minicomputers came to roughly half the value of all minicomputers, or roughly 15 percent of the value of the installed base of mainframes. IDCs census differs from the
other censuses, particularly CBEMA's, because IDC includes several systems as mainframes (i.e., those from
IBM) which others classify as super-minicomputers. This matters a great deal by the end of the sample. For
example, according to the CBEMA [1992], in 1976 mainframe shipments reached over 5 billion dollars, while
the total spent on all minicomputers was 1.8 billion. By 1982, howaver, mainframe shipments reached 10.6
billion and minicomputer shipments reached 7.7 billion. CBEMA does not state what fraction went to superminicomputers.
'The most questionable omissions in IDCs mainframe tables are those regarding the VAX models from
DEC, and similar competitive models from other firms such as Prime and Data General.

4

overlooks differences betveen cohort and age effects. It assumes that the same measured difference

between an earlier and later technical vintage means the same thing in tvv different periods. That is, it

presumes that a 1968 technology is better than a 1965 technology by exactly tha same aniunt that a
1981 technology is better than a 1978 technology, and so on. Some corrections are possible (see
below).

The advantage of using VINFAGE for rneasuiing technical capability is that it available for all

systems in all 16 years of the data and it is easy to use. Second, over the long run, VINFAGE

provides a quick and reasonable measure of imvements in new tec11ogy embedded in successive
generations of computing equipment, which is finc for the diffusion issues addressed in this paper.

Third, this measure does not rely on an arbitraiy estimate of best practice technology, nor does it rely

on a company's announcement regarding tl product Rather, it uses a historical event, when the
product first came to market. Thus, it is an appealing definition for an economic study.
?vkst important; VINTAGE provides a bound on the degree of technical knowledge embodied

in a system. This occurs for three reasons. First, the installed base of systems in use must be yoimger
than VIWFAGE indicates because the date of first installation is older than the date at which most
users install their rented or purchased model. Second, VINFAGE overstates a system's true technical
age in situations where new installations of an old vintage technology are using technology retrofitted

th improvements. Lastly, VIWFAGE does not correct for typical utilization rates of especially older
systems. In other wxds, it overstates how important old systems may be by assuming a "one-boss-

shay" model for old systems - if a system is installed, then it is still in use. In sian, VINFAGE will
give the most pessimistic picture possible. If the results are positive in spite of this bias then
VI1'H'AGE does a good job.

Rather than analyze t& vintages of systems in each year, it is easier to examine their
"technical age," which makes various years comparable.

5

"technical age" of a system is defined as

the difference betwen the date of observation and a system's vintage.That is

TECHAGE = YROBS - VINFAGE

where YROBS is the date of observation.1 AU systems introduced on the same date have the same

technical age. The same strengths and wakness that apply to VINTAGE also apply to TECHAGE

4. The Disthhilion of Technical Age.
Figure 1 presents a summary of the changing technical age of US mainframe computer

installations over the entire 16 years (fl wlerlying data are presented in Table Al in the appendix).
A few technical generations dominate the distribution of the technical age over the first years of the
sample. The first major technical cohort in the data is associated primarily with the introduction of the

IBM system 360. In the end of 1968, there e 17580 systems installed whose technical generation is
1965. In each of the next t successive years this technical generation grows to a peak of 27040
systems, which 'vas over 40% of the systems in use in 1970. This technical cohort continues to be

quite large for many more years, making up more than 20% of the systems in use up to 1974. The
second major cohort is associated with the IBM system 3 and system 370 (spread primarily through
vintages 70-73). By year-end 1974 more than one quarter of the installed systems in use are associated
with this new technical generation. The importance of the system 370 and system 3 continues for a
few more years. As will be clear below, no other singje system introduction influences the
rneasureincnt results as much as the technical cohorts associated with the system 360 and 370.
Figure 2 presents three different estimates of the average technical age of mainframe

7Srnce each survey samples the market at the start of the year, YROBS for the first year of the sample will
equal 1968.0. YROBS ll equal 1983.0 in the final sample year.

6

computing systems in the United States able A2 in the appendix present the raw calculation). Three
measures are used because the inferences are sensitive to the measure usei The average technical age

of all installations emphasizes popular systems Th average technical age, vvighting by the rental

vaiue of the installations, emphasizes tbe r systems, the bigger systems, aixi popular systems.'

11 median technical age of t1 systems installed de-emphasizes any skesss in the distribution.
Figure 2 illustrates tha trends. The median has tbe most unusual pattern. Because of the

diffusion patterns associated vith the system 360 and 370 tha median technical age jumps discretely

year to year. It grows from 1968 until 1973 at a rate of one per year, ich reflects tha influence of
the 360 cohort As many users bought the system 3 and upgraded their 360 systems to 370s the

influence of the 370 cohort rose. The aqt decline in tbe median age of systems between 1973 and
1974 reflects the accumulation of users shifting ay from tbe 360 and to the 370 and system 3. Both

the shifts avy from the 360 and to the 370 se recessaiy to produre this abnipt change. It is
difficult to make any strong inferences from these movements in the median after 1974. After 1974 the
median technical age increases for a few years, stays virtually unchanged for a few years, and then

fails markedly in the last couple of years.
The measures of the average technical age of systems stay remarkably close to one another,
despite the different weighting used in each case. Not surprisingly, these measures are smoother than

the median. They too show a rising average technical age over the early part of the sample. The
technical age weighted by value rises 2.3 years from 1968 to 1979 and stays just above six years from
1975 until 1983. The unweighted technical age rises by 3.3 years from 1968 to 1980 and also stays
above six years from 1975 onwsrcL

The rise in the technical age over the first half of the sample years is not surprising. The

'It may also slightly exaggerate the importance of older systenis, as Phister [1979] werns. See appendix for
further discussion of these and other potential biases.

7

computing market had just experienced dramatic growth in the late 1960s and only moderate growth in

the early 1970s. The average age of systems grew as users held on to their systems and did not retire
them. By the mid 1 970s, however, users phased out enough of the oldest systems and replaced them

with ner systems, resulting in no increasing trend for these averages. The stabilization of the
average technical age in the later years of the sample is surprising because the continuing existence of
somo very old systems should bias the maasure upward as the market grows older. It seems that the

only way to get a stabilization of the average technical age is for buyers to acquire new systems at a
fast pace.

Figure 3 verifies the above conjecture. It shows the different quartiles of the vintages of
computing capital stock (it also shows the maximum and minimum). The percentage of yoimg systems

is growing in the early 1980s and the age of the oldest quartile is falling. Thus, despite the possibility
that users could and did hold on to old computing stock, the average age does not change much over

the late 1970s and early 1980s. Note that the abmpt change in the maximum technical age betveen
1976 and 1977 reflects one system's retirement and does not reflect any important economic factor.

Is an average technical age of 6 to 7 years a high level or a low level? The obvious

benchmark to compare TECHAGE ainst are several classic diffusion studies. Mansfield's [1968]
sumnmazy of the diffusion of 12 important innovations in bituminous coal, iron, steel, brewing and

railroads, shows enormous variance, as does Griliches' [1957] analysis of the adoption of hybrid seed

corn, and David's [1975] analysis of the MCormick Reaper. Most innovations take longer than 10
years to be filly adopted and several take 20 or more years. The comparison is not perfect because
these and similar studies analyze the adoption of the first generation of a product innovation (e.g.,
automobile, radio, television) or process innovation (e.g. continnous mining machine, diesel

locomotive), not the turnover in technical vintages of a stock of systems in use. Despite this
precaution, a technical age of 6 to 7 years seems small in comparison. This measure is biased towards

8

a pessimistic answer. New generations of computers must be turning over every few years to prodixe

this result Very few of the classic stndies just mentioned show adoption taking a few years.

A few tentative conclusions enge. Fust, the market displays a pattern consistent with the
heavy growth of new users in the late 1960s. By the early 1970s this growth slowed and much new

technology adoption is beg made by experience users. Consistent with this story, estimates of the
levels of best practice frontiers are certain to be closer to average practice in the early years of this

sample wn first adoptions are made. Similarly, best practice frontiers may provide a deceptive
picture of the economic benefits from technical progress in the later years because the gap between
best and average practice is likely to be greater for many experienced users. Second, users added new

systems at a fast pace in

late 1970s and early 1980s. This last result is surprising, given the rising

importance of small substitutes for mainframe computers. Third, there is some indication that new
technology comes into use quickly, particular in comparison to previous major innovations. However,
this conclusion needs more careful analysis of turnover of computers from different technical
generations.

5. Technical fronlieis and the fvance of average practice
The ultimate goal of this section is to measure the speed with which "best practice" diffuses
into general economic use. This section corrects for the main deficiency of TECHAGE, that one unit
of TECHAGE means the same thing in every year, though each vintage's capabilities differ.

What is meant by "best practice" and "average practice" in a heterogenous product market?
Economists typically represent best practice by a "frontier" of models that can provide combinations of

product traits at the lowest cost It follows that "average" practice is a measure of the typical type (and

typical cost) of systems in use.
This paper employs traditional hedonic estimates of the best practice frontier in computing.

9

Researchers have usually foi.nxi that the rate of improvement in the performance per dollar of new

systems lies somewhere betven 15% and 25% per year over the ss1le sample. Hover, these rates
vary year toy and over periods. Unfortunately, meet researchers do not estimate changes in the
hedonic frontiers over the entire period of interest, from the early 1950s until 1983 - exceptions are
Gordon's [1989] estimates and Tripletts [1989] synthesis of estimates from different researchers.
For estimates of technical frontier, I employ Triplett's [1989] best practice index for computing

equipment (Tables 4. 13A and 4.14.). This iriex was Triplett's evaluation and synthesis of the best
hedonic research on computer technology. Triplett's indexes start in the imd 1950s and go all the way
until 1984. They cover all vintages and all manufacti.wers in the computing stock. Triplett's index
completely covers the industry, which makes it the best choice for this paper.9

Even with an appropriate index, how should it be used to estimate best and average practice?
This is particularly important in light of the recent discussion about the existence of multiple hedonic

frontiers operating in the market at the same time)° Is it better to assume that all systems for sale are

priced on the same frontier or not? In a putty-putty 'vrld, all systems are on the same frontier. Then a
system's price and hedonic index are sufficient for comparing different systems' value. If systems are
not on the same frontier, what is the appropriate scheme for differentiating between different
applications and intensity of use?
The strategy of this paper is to compute a bound on average practice even if system are on

9Since Gordon's index and Triplett's index do not sharply differ in the long run, the results are not sensitive
to this choice.
'°

Fisher, et al. [1983] argue that the computer market is subject to "disequilibrium." That is, the introduction
of new products frequently disrupts expectations, market pricing, and investment patterns. Buyers may lock
themselves into investments, but regret the decision as conditions change unexpectedly. In the short run, buyers
may be uncertain about the true capabilities of the latest systems and may defer new purchases until better
information is available. M a result, the market may never settle into uniform prices for systems with similar
charteristics. Hedonic researchers, such as Dulberger [1989] and Oliner [1993a], interpret this to mean that new
Froducts and older commercial systems may not lie on the same hedonic frontier. Departures from the frontier
may differ with age. Dulberger find evidence in favor of disequilibrium, while Oliner finds a more mixed bag.

10

different frontiers. Thus, I assign the vorse possible frontier to each system. The frontier associated

th a system's VIN1AGE provides such a lo bound, i.e., the loswst technical frontier for a system
is usually realized wien a system is first introduced. This is a 1over bound because this index will not
change with market conditions even though new systems may improve with the introduction of more
software or other peripherals. Prices of old systems may also decline in response to new entry driving

the technical frontier outrcLU
Table 1 and Figure 4 show this measure of the computing capital stock. More precisely, Table

1 computes the quality adjusted vah for each system by dividing the introductory price of the system
by a hedonic index for new systems that year. In other vords,

EU1 =

wiere P, is the pt-ice of system i introduced in year v, wiich is its first year, and H. is the hedonic
value of systems of vintage v. EU1 represents "efficiency units" or the quality embedded in a system

at its introduction, so the number does not change over time. This computation is exactly right if
sellers price all new systems on their vintage hedonic surface and the productivity of each model does

not dramatically change over time. Othervise, EU should be interpreted as a lor bound. Table I and
Figure 4 present the average EU for each year. This equals

AVE(EU) = [E Q EU,]!

[Q],

11Particularly lithe price for a system declines over time or lithe technical capabilities for systems improve
over the production lifetime of a system. See Oliner [1993a] for evidence that discounting from list prices
foIlo a general predictable pattern over the commercial life of a system. See Flartman and Teece [1990] for a
similar discussion about strategic pricing in the mini-computer industy.
11

where Q, is the installed base of model i in year t. Median EU is done in an analogous manner. The
table ends in 1981 because this is the last year IDC publishes rental price data A mean and median
were used (instead of a total) because these measures minimize biases from arbitrary changes to the

definition of a mainframe. The abeolute value of the mean is higher than the median because in any

year U distribution of prices of systems is skewL That is, the larger systems are more expensive
than the smaller systems are cheap.

Consistent with the previous figtues there is r evidence in this table that diffusion is slow.
The median and mean start at different levels, but grow at roughly the same rate. The mean growa at

22.6 percent a year, while the median grows at 23.6 percent a year. The mean shows steady growth
after 1970. The decrease from 1969 to 1970 was likely caused by IDCs redefinition of a mainframe,
which resulted in the exclusion of many systems from the 1970 census that had been in the 1969
census. The median shows steady growth through out the whole sample, with a few exceptions in the

early to mid 1970s. The decline from 1969 to 1970 is an artifact of abrupt changes in the sample of
systems. IDC removed several newer systems, mostly minicomputers, from the survey.'2

The rate of growth shown in Table 1 compres closely with the hedonic index presented in
Table 2. The index declines at 19.8 percent a year from 1958 to 1984, with the biggest declines
coming from 1958 to 1970. Thus, the decrease in the cost per i.ntit of quality translates into roughly

the same rate of growth in the quality of U installed computing capital. Sometimes the rate of growth
was even faster.

6 Diffusion lags
This section defines and analyzes diffusion lags, which measure how manyyears average

t2Overall, these results do not seem to be a consequence of a change in the typical size of systems in this
sample over time. All experiments with changes to the sample of systems yielded similar results.

12

practice is behind best practice. A diffusion lag is the difference beteen average practice in one
period and its equivalent best practice in a previous time. Diffusion laga are easy to compute vith
logistic curves in single-product, single-vintage nrkets. A similar index in a multiple vintage,
multiple product market involves a bit more effort.

The paper's measure of the diffusion lag computes the average practice in one year. 11n, it

fixes that value and searches for the previous year in which best practice fronti sere at this level.
The difference in time provides a measure of the "vii tage-eçiivelant" of a given yea? s average

practice. Mre precisely, let FJ be the best practice value for all systezn of vintage v, and let
AVEPRAC be the average practice for year t. This paper uses the AVEPRAC in time t and compares
it against previous H, interpolating where necessazy. In othervvrds, the diffusion lag. DIFLAG, is

defined by the fol1ong procedure:

If AVEPRAC(t) = FL then

DIFLAGt-v.

This procedure takes advantage of the most data available.
Different definitions of "best practice" and "average practice" provide different insights. As

argued above, hedonic measures can represent the technical frontier in time t for all systems

introduced in that year. It follo that average practice is the average (or median) of these values over
all systems in use.

Table 2 and Figure 5 present the results for 1968 through 1983. The results of this procedure

are striking. For the average, diffusion la grow over the early and middle part of the sampi;
reaching a peak of over 10 years in 1979, 1980, and 1982. The la essentially level off in the last
five years of the sample. The results show that average practice changes at over 14.4 percent a year

13

from 1%8 to 1983, which is just under the 16.4 percent change in best practice during the same years.

The diffusion 1a lengthen because a number of very old systems are still in the installed base in the
late 1970s. Users may or may not use these old systems as intensively as they use new. }wvver, an
average does not correct for intensity of use.
One possible correction is sbown in Figure 5 and presented in Table 2 under the heading
"median practice." It computes the hedonic frontier value of the median system in use. This definition
is not as sensitive to the existence of older systems. Of course, this measure will also abruptly change

any tin the median TECHAGE abruptly changes. The diffusion lag associated with the median
practice is markedly different than average practice, as expectei It grows over the early years of the
sample, but levels off by 1972 It drops abruptly in 1974, reflecting the abrupt change in the median
system, as described in the discussion about the median techage. This drop is in contrast to the average
diffusion lag. In addition, the median diffusion lag never exceeds 7 years, which is markedly less than

the average diffusion lag This maximum is reached in 1972, 1973, 1977, 1979, 1980, and 1981. The
turnover in the number of young systems is sufficiently fast to prevent the installed base of old

systems from mattering as mueh I conclude that the median is a less reasonable measure when there
are abrupt changes in the median system, as in the mid 1970s. Howvver, it is a more reasonable
measure of long run trends under the assumption that users do not intensively use very old systems. D
So it is probably more appropriate for the late 1970s and early l980s.

Several conclusions emerge from Table 2 and Figure 5. First the overall rate of diffusion of

new technology to users embedded in new technology is quite fast, especially considering that all the
above measures represent a pessimistic estimate. The average computer user possessed new technology

that was improving at roughly the same rate as the best practice frontier, though the level of average

This result is also consistent with the industiy perception that the "typical" user turns over their system
eveiy 4 to 6 years. If the "typical" user makes this purchase I to 3 years after the iroduction of a product, then
a median of roughly 6 to 7 years will result

14

practice obviously lagged behind. Second, tlp between the levels of best and average practice
grew in the first five years, as or

uld expect in a relatively new market Thereafter, the retirement

patterns of the older vintages largely detenriines the nasured diffusion p. Third, despite the
generally positive overall picture, there is considerable variation in the experience of users. A
substantial minority continued to possess old equipment much of it representing generations that were

easily 10 years old or older. This observation focuses attention on the need to better wderstand the
relationship between the installed base of old computing equipment, the intensity with which it is used,
and users' tendency to make another purchase.

7. Ciosing reimrks
This paper's analysis aimed to prevent any hasty inference about economic welfare based

solely on estimates of growth in the computing technical frontier. \Mat matters for economic welfare
is what technologies users employ, not only what is available or what wes recently bought. In terms of
this motivation, the results were quite positive. Average practice generally lagged best practice by a

maximum of 6 to 7 years and wss often shorter. While this answer is somewhat sensitive to
assumptions about the intensity of use of old systems, it is biased towards a pessimistic answer. A
maximum of 6 to 7 years is hardly slow, especially in comparison to the diffusion of other important
innovations.

The analysis highlighted several important features of the diffusion of computing. A few
vintages and computer system models greatly influence the results in some years. It follows that any
measurement of diffusion will be sensitive to the valuation placed on popular systems, particularly the
IBM system 360 and the IBM system 370. This is a disturbing conclusion, given the different hedonic
estimates for these systems (Gordon [1989], Dulberger [1989], Oliner [l993aD.
Second, the analysis found a general correlation between advances in technical frontiers and

15

advances in average practice, but also fotaxi mh variation arotuxi the trerii A large number of users
continued to hold onto old equipment and did not turnover technical generations quickly. By

impliction, a complete description of the advance of average practice requires a complete survey of
the experience of new and popular systems, and also a survey of the use of old vintages. Thus, at

best hedonic frontiers alone are a eak approximation of the general economic benefits from technical
advance in the short rtni These observations highlight the need to better axierstand the relationship
between the elasticity of demand for computing, U intensity of use of old technical vintages, and the
adoption of new technology (e.g., See Bresnahan and Greenstein [1993]). Further research on the
intensity of use of old equipment and its retirement patterns (e.g., Oliner [1993a}, [1993bJ) can
partially address this gap in knowledge.
The paper's results have another important implication. Economists have been puzzied by the
abeence of any of the expected produetivity improvements that should follow technical advances in
computers. One set of possible hypotheses emphasize that average practice lagged far behind best

practice. This paper provides a quantitative test of the simplist slow-diffusion mechanism, that new
technology embedded in hardware diffused slowly. The analysis rejects this mechanism because

average practice advanced at a rate comparable to best practice and the diffusion lag associated with
new technology embodied in mainframe hardware was typically short Thus, to remain viable, the
slow-diffusion hypothesis must focus on the slow development of software, human learning. and

appropriate organization forms, as suggested in David [1989], if it is to survive as a viable explanation

for the productivity pule.t4
This paper's experiment ends at an interesting turning point in the mainframe computer

'4mese is not likely any supporting evidence in the diffusion of products complementaiy to hardware, such
as software or peripheral components. Recent hedonic research shos a rapid rise in the technical frontier for
many different peripherals (Cole et al [1986], Oliner [1993b]). Since the sale of these peripherals positively
correlates sith sale of processors, there is likely to be little difference in the diffusion lag for peripheral
technologies in the United States.

16

industry. Ser minicomputers had already begun cutting into the mainfran market share by 1983

and personal computers became much nire ubiquitous thin businesses after 1983 Besnahan and
Greenstein [1993]). One might expect tha retirement patterns and acquisition patterns to change as a

result. Furtber research may be able to identify thei tha diffusion 1a increased or decreased after
1983.

Fwther rk could constnt estimates of the demand for computing capabilities. Demand
estimates will say something about the degree of change in the surplus of users due to technical
improvement This is the spirit of Flamm's [1987a1 estimate of the benefits from improvements in
computer systems, Bresnahan's [1987] research on the use of computers in the fmancial services sector,

and Trajtenbergs [1989,1990] estimates of tbe sv1fare gain from the adoption of CT scanners. Since

the data in this paper incindes data on quantity and prices, it is possible to rk in this direction.
Greenstein [1993bJ contains such research.

17

Table 1

Median and Average

Efficiency Units

1968-1981

Year
1968
1969
1970
1971
1972
1973
1974
1975
1976
1977
1978
1979
1980
1981

Mean

22.28
22.33
19.33
25.41
35.90
45.10
54.99
65.19
71.02
92.65
135.16
209.45
323.40
529.00

18

Median
5.00
7.04
10.55
10.55
10.55
11.41
11.41
11.41
13.70
28.92
48.40
63.52
70.04
136.61

Table 2
Average versus Beat Practice
1968-1983

Year
1957
1958
1959
1960
1961
1962
1963
1964
1965
1966
1967
1968
1969
1970
1971
1972
1973
1974
1975
1976
1977
1978
1979
1980
1981
1982
1983

Hedonic
Beat

Practice
3640.9
2895.5
2422.7
1863.6
1377.3
927.3
700.0
568.2
454.6
286.4
231.8
190.9
172.7
159.1
122.7
100.0
98.6
80.3

73.2
65.7
51.4
34.5
29.6
23.9
21.8
20.4
16.3

Median

Average

Diffusion Median
Diffusion
Practice Lag
Lag

Average

Practice

.

5.4

794.2
671.7
556.3
503.6
422.8
380.9
313.0
274.5
229.4
224.2
199.1
186.4
168.7
136.6
116.0
91.4

5.8
5.8

6.4

6.8
7.6
8.2
8.8
8.9
9.8

10.2
10.7

10.7
10.3
10.7

9.6

19

568.2
454.6
454.6
454.6
454.6
286.4
159.1
159.1
159.1
159.1
100.0
100.0
98.6
80.3

65.7
34.6

4
4

5
6
7
7
4
5
6

7
6
7
7
7
6
5

C,)
aD

It

c'J

IT

VV.4.

<<<II
I—I--H V

3D

V V V<

a,

0
cc
C.')

E

C)

>

cc

N

G)
Ci)

N

(I)

-o
0)

.4—'

(0

0)

U)

N.

C,)

N

I

c.'J

N.

k/rAr%r4r4rAr%

0
C)

(0
cc

(0

00009

0000t

00O0

0

lt)-

co-

68

369

I

3

70

I

71

I

/

72

I

2

3
/'

//

%

I

'
I

73

,/

I

I,

74

I

3

I

I

75

I

3

I

76

I

3

2,

2
2,

77

I

78

I

79

I

80

81

I

82

I

Mean when weighted by value
Mean when weighted by installations
Median when weighted by installations

2'

./

Technical Age of Installed Systems

gm2

83

3

o

If)

o

c'J

-

-

—

4

5__•

.1

2

'

2

2

__3--_

Maximum
______________________
_____________________

Third quantile

Minimum
First quantile
Median

____________________

\

5_——,J

2

2

2

2

2

3- 3___ 3-.__ 3--- 3-..

5__•

2•

3

4

2

I

71

I

70

I

69

I

68

72

I

73

I

74

I

I

76

I

75

77

I

78

I

I

80

I

79

81

I

82

83

i_1—11_11—1—1—1—1—11—1—1—1—1

2

5—

5___

——I

5—\

F1gm3
Technical Age of Installed Systems

('4

0
0-

0

0-

CD

0
0-

C

0-

0
0

0

('4

0
C

1968
1969

I

1970

1971

I

I

1973

I

1972

Average

1975
year

1974

I

1976

Efficiency Units

Rgure4

1977

1978

1979

1980

1981

0•
(0

0

0
0
c'J

0

0

cD

62

5

Price Index
Practice
- - - - Average
Median Practice

—

63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83

Diffusion Laos

Mgt

Pefernces
Bemdt, Ernst [1991], The Practice of Econometrics: Classic and Conteniporary Reading, MA.
Addison-Wesley.
Berndt, Ernst, and Zvi Griliches [1990], "Price Indexes for Microcomputers: An Exploratory
Study," NBER working paper #8878, Cambridge, MA.

Berndt, E. R, M. H. Showalter, and J. M Woolridge [19911, "On the sensitivity of hedonic
price indexes for computers to the choice of fuentional form," Mlmeo.
Berndt, Ernst, R and Catherine J. Morrison [1991], "Assessing the Productivity of
Information Technology Equipment in U.S. Manufacturing Industries" NBER Working Paper
3582, Cambridge, MA., Januaiy 1991.
Bemdt, Ernst, R, Catherine J. Morrison, and Larry Rosenbium [1992], "High-Tech Capital
formation and labor Composition in U.S. Manufacturing Industries: An Exploratory Analysis,"
NBER Working Paper 4010, Cambridge MA., March 1992.
Bresnahan, Tunothy, F. [1987], "Measuring the Spillover from Technical Advance:
Mainframe Computer in Financial SeMces" American Economic Review, Marth

Bresnahari, Timothy, F. and Shane M. (3reenstein [1993], "The Competitive Crash in Large
Scale Computing," mimeo, University of Illinois.

Brock, Gerald W. [1975], U.S. Computer Industi : A Study in Market Powet, Cambridge
Mass: Ballinger Publishing Co. 1975
CBEMA [1992], Information Technology Industri Databook, 1992, Washington, D.C.
Cole Rosanne, Chen, Y.C., Barquin-Stolleman, Joan A., Dulberger, Ellen, Helvacian, Hurhan,
and Hodge, James FL [1986], "Quality-Adjusted Price Indexes for Computer Processors and
Selected Peripheral Equipment," Survey of Current Business, 66(Januazy), pp. 41-50.

David, Paul A. [1975], "The Mechanization of Reaping in the Ante-Bellum Midwest," in
Technical Choice. Innovation.. and Economic (T3ro'vth: Essays on American and British
Experience in the Nineteenth Centiy. Cambridge University Press, New York, NY.
avid, Paul A. [1989], "The Computer and the Dynamo: the Modern Productivity Paradox in
a Not-Too-Distant Mirror," CEPR Working Paper no. 172, Stanford University, July.

lAilberger, Ellen R [1989], "The application of a Hedonic Model to Quality-Adjusted Price
Index for Computer Processors," in Technology and Capital Formation, Edited by Dale W.
Jorgenson and Ralph Landau, MIT Press.
20

Fisher, Franklin M. and McGowan, John 3., and Greenwood, Joen E. [1983], Folded,
Spindled, and Mutilated: Economic Analysis and U.S. vs. IBM, MIT Press, Cambridge Mass..
Flarnm, Kenneth [1987a}, Targeting the Computen Government Support and International
Competition. Washington D.C.: The Brookings Institute.

Flamm, Kenneth [1987b}, Creating the Computen Government Industiy, and High
Technology, Washington D.C.: The Brookings Institute.
Gordon. Robert J. [1989], "The Postwar Evolution of Computer Prices," in Technology and
Capital Formation, Edited by Dale W. Jorgenson and Ralph Landau, MIT Press.
Greenstein, Shane [1993a], "The Diffusion of Multiple Vintages in a Differentiated Product
Market: Best and Average Practice in Mainframe Computers: 1968-1983," mimeo, University
of Illinois.
Greenstein, Shane [1993b], "From Superminis to Super-computers: Estimating the Benefits
from Improvements in Computing," Mlmeo, University of Illinois, November.

Griliches, Zvi [1957], "Hybrid Corn: An Exploration in the Economics of Technological
Change," Econometrics, 25, pp. 501-22.
Hartman, Raymond S. and Teece, David 3. [1990], "Product Emulation Strategies in the
Presence of Reputation Effects and Network Externalities: Some evidence form the
Minicomputer Industiy," Economics of Innovation and New Technology.
Michels, Robert [1979], "Hedonic Prices and the Structure of the Digital Computer Industry,"
Journal of Industrial Economics.
Mansfield, Edwin [1968], Industrial Research and Technological Innovation, New York:
Norton.

Oliner, Steve [1993a], "Constant Quality Price Changes, Depreciation, and Retirement of
Mainframe Computers," in Price Measurement and Their Uses, edited by Murray F. Foss,
Marilyn E. Manser, and Allan FL Young, University of Chicago Press, Chicago, IL.
Oliner, Steve [1993b], "Estimates of Depreciation and Retirement for Computer Peripheral
Equipment," Mlrneo, Board of Govemers of the Federal Reserve System, Division of
Research and Statistics.
Phister, Montgomery, Jr. [1979], Data Processing Technology and Economics, Digital Press,
Santa Monica

Trajtenberg. Manuel [1990], Economic Analysis of Product Innovation, The Case of CT
21

Scanners, Harvard University Press, Cambridge MA.

Trajtenberg, Manuel [1989], "The Welfare Analysis of Product Innovations, th an
Application to Computed Tomography Scanners," Journal of Political Economy, 97, 2, April.
Triplett, Jack R [1989], "Price and Technological Change in A Capital Good: A Survey of
Research on Computers," in Technology and Capital Formation, Edited by Dale W. Jorgenson
and Ralph Landau, MIT Press.

22

Appetilix

Al. Dati docunntation
These data on computer prices, quantities, and vintages come from the archives of the Charles Babbage
Institute at the University of Minnesota, which contains a collection of industry "censuses" from International

Data Corporation's ([DC) EDP Industry Reports (EDP/IR). This paper also makes use of a set of EDP Industry
Reports contained at the Library for the Graduate School of Business at Stanford University. Patrick McGovern
began compiling this census in 1962 in Computers and Automation magazine. It continued in modified form
under IDC auspices from the mid 1960s onward. IDC annually surveyed most mainframe users and suppliers in
the country and estimated the number of installations of each type of computer system. In addition, until 1981
[DC estimated the monthly rental at which an average type of the system leased. AiIer 1981 they estimated an

average purchase price for the system.
The [DC data on the installed base of each model is the right magnitude, though not precise, especially

in capturing yearly changes. IDCs own literature warns against the hazards of inferring net sales from changes

in the data on installed base. The problem is that they update their figures for tw reasons: (1) Real changes in
the holdings of users; (2) changes in IDCs information about (proprietary) sales activity, both in the present and
in the past Patrick McGovern recalls (in a private communication) that most suppliers except IBM cooperated

with [DC, which is why IDC had to undertake a major revision of the data pertaining to IBMs systems (Phister
[1979] contains a complete set of these revisions).
Phister [1979] clearly believes that IDC's estimates are the best among the available alternatives. He

states on pg. 250 "It is my opinion that IDCs staff; files, and data sources make that organization's published
statistics the best available." Nevertheless, he warns about several potential problems that could influence

calculations using these data. For example, due to occasional revisions of previous EDP/IR reports, Phister is not

convinced that IDCs estimates of the size of installed base are precise. However, many of his uses of these data
indicate that he believes [DC got the general order of magnitude correct
Dulberger also questions the accuracy of IDCs estimates of installed base, while conceding that they are
the best publicly available. One especially difficult problem is that [DC may underestimate the number of users

who upgrade their systems (Dulberger, private communication). However, she relies less directly on IDCs

numbers. She used them only to determine the size of her data sample of systems for sale in a given year. For

each year's sample she included processors associated with systems wfiose installed base s still growing, since
these systems are likely to still be experiencing positive sales.

Given these concerns, I also subjected these data to some internal consistency checks, wiuich they

readily met. The history of each new system was examined. Did the development of its installed base follow a
reasonable pattern of growth, i.e., several years of growth followed by several years of decline? The absence of

such a pattern vuld bring into question the plausibility of the data.
Similar issues influence the use of IDCs rental price data. IDC estimated the price of a typical system
configuration. Phister believes that the prices for obsolete systems are too high, since IDC uld use the last
offered price for a system in the absence of any rent transaction. Nonetheless, Phister uses these prices for

estimates of the value of installed base. He believes that the bias in old prices influences only a few of the
systems in the United Stales. Flamm reaches a similar conclusion before using Phister's estimates for a few

caiculations. In addition, using these prices is not without precedent in the hedonic literature. The prices for new
systems used by Gordon (as well as many others) are very similar to those used here. Gordon's prices for his
sample after 1977 were taken from Computerworld. which is published by IDC.

These research&s experiences show that IDCs estimates are probably the right order of magnitude but
also subject to measurement error. These observations warrant a cautious research strategy. No strong
conclusions should rely exclusively on one data point. Strong inferences will arise only from procedures in which
cumulative measurement errors wash out.

A2. The Technical VINTAGE of Inoilant irifxame Qnuter Systetm
VINTAGE=50
UNI 1103/5

VINTAGE=51

ll/ll

VINTAGE=54
BUR2O5
1BM650

VINTAGE=55
1BM704
1BM705

VINFAGE=57
1BM305

UN

VINTAGE=58
BUR22O
1BM709
P1-11210(211

UN1SS0
VINTAGE=59
1BM7090

UNI5OI

VINTAGE6O
CDC16O4/AIB, GEL2IO, HONHSOO, IBMI4OI, 1BM1620, 1BM7070174, IBM709cV94, NCR3O4, UNI3OI,
UNTLARC

VWrAGE=61
BUR200, CDCG-20, GEN225r255, HONI-1400, IBMI4IO, 1BM7030, 1BM7080, NCR3IO, NCR39O, RCA3O1,
1JN14911492,

VINTAGE62
1BM7094, NCR315, RCA6O5, UNIifi UNII 107,
VINTAGE=63
BURB55/5700, CDO600, GEL2I5, 1BM1440, 1BM1460, IBM7OIO, 1BM7040/44, PHI1000, P1-11212,
UNI4 I 8V11, UN! 1004, UNI 1050,

VINFAGE=64
BURBIOOS, CDC3I/3 150, CDO200, CDC3400, CDC6600, DECPDP6, GEL2O5, GEL2351265, GEL415/420,
GEL425/430, HON200, HONI400, HONI800, 1-KGAMMA10, IBMI4OIG, 1BM7094-ll, UN13301, XER9300,

VINTAG5
BURB300S, CDC3300, CDC3 800, GEL235/265, GEL4351440, GEL625, GEL635, IBM3&V20, IBM3&V30,
LBM3&V40, 1BM360/50, 1BM360/65, NCR3I5RMC, NCR500, Rc1\S7'15, RCAS7Q'25, UNJ11O8,

VINTAGE6

CDC6400, GEL55, GELI 15, GEL645, HONI-1120, HONH1200, HONH2200, IBM3&V44, 1BM360167,
1BM360175, IBMI 130, RCAS7cV55, UN1494, UNIIOO5, XERSIGMA7, XER94O

VWFA67
BUBB2500, BURB3500, CDC6500, DEC1O4O/50, GEL225r255, GEL415/420,

HONHI25, IBM36x,

IBM1401H RCAS7O/35, SCCIC6000, UN19200, UN19300, XERSIGMA5,
VINFAGD=68
BURB500, GEL4O5/410, HON1 10, H0N1250, H0N4200, 1BM364Y25, NCRCaITIoo, RCAS7O/46, SSCIC400

VINTAGE=69
BURB6500, BURB8500, CDc3soO, CDC7600, GEL58, GELIO5, GELI3O, GEL2451275, GEL15, H0NH8200,
NCRCENT200, SCCIC7000, UN1418111, UNI1IO6, UN19400

V1NTAGE70
CDC317O, CDC6200, CDC6700, FRISYSTEM1O, GELS3, GELI2O, GEL4OS/410, GEL425/430, GEL435/440,
H4H1 05/115, HONH3200, IBMSYS3/6, IBMSYS3/10, SENSYS1 0, RCAS7cV6O, XERSIGMA6,

VINTAGE=71
BURB4500, CDCCYBER72, GEL6O3O/40, GEL6O5O/60, GEL607W80,
HONIH1OI5/2015, 1BM37W145, 1BM370/155, 1BM370/165, 1BM370/195,
V]NTAGE=71
1BM360122, NCRCENT5O, RCAS7O/61, RCAS7Oi2, RCAS7O/3
RCAS7cV6, RCAS7Y7, XERSIGMA8, XERSIGMA9,

VINTAGE=72
BIIRB2700, BURB3700, CDCCYBER73, CDCCYBER74, CDCCYBER76, DEC 1060170, HONI-12040,
HONI-12050/2060, HONH2O7O, 1BM37U'135, NCRCr101, NCRCEfl00, UNTI 110, UNI9O/70/9700

ViNI'AGE=73
BURB172O, BURB7700, GEN6023125, H0NH2020130, 1BM370/125, 1BM370/158, 1BM370/168,
NCRCENfl25 1, XER53O

VINTAGE=74
CDcSTARI00, GEN6 180, FIONH6I/58, HONH61/60, HONHLEVEL62, HONHLEVEL64, HONH6&'20,27,
HcH66/40/60, HONH66/80, 1-10NH68/80, LBMSYS3/15, 1BM370/115, UNI9O/60, XERS5O/560,

V1NTAGE75
AMD47OW6II, BURB17IO, CDCCYBERI72, CDCCYBER173, CDCCYBERI74
CDCCYBERI75, DEC1O8CV9O, l-10NH66/ICWI7, IBMSYS3/8, NCRCfl51, UNI90/30, UNII 100/20,
liNT 1100/40,

V1NrA76
BURB2800, BURB4800, CDCCYBER71, CRAY1A/1B, DEC2041'50, HONH6I/40, HONH6605/07,
IBMSYS3/4, IBMSYS3/12, 1BM37CV138, NCRS55O, NCR8570, NCRCENT7S, UNI9O/80, UN11 100/10,

VNrAGE=77
AMD47OV/511, BURB18I5,25/3, BURB1855-85, BURB3SOO, BURB6SOO, CDCOMEGA48O-1,
CDCCYBERI71, 1BM37W148, NASAS/4, NASAS/5, NCRS35O, NCR8450, NCR8560, UN90125,
UNII 100/80-82

V1NFA78
AMD47OV/7AB, BURB7800, CDCOMEGA48O-2, CDcCYBER176, DEC2020, HONH66/DPS/BC,

HONH6S/DPS, 1BM303 1, IBM3 032, mM3033U,A,M MAGMSO/4, NASAS/3, NASAS/703 1, NASAS/6,
NCRS37O, NCRS43O, NCR8S8O, UNI9O/40, UNI 1100/83, UNI 1100/84,

VINTAGE79
AMD47OV/8, CAX1638/40, CDCCYB17O-720, CDCCYB17O.-730, CDCCYBI7O-750, CDCCYBI7O-760,
DEC2060, HONH64/300, H0NH66144U1520, HONCOM/XER, 1BM4331-1, 1BM4341-1, MAGM8W3,
NASiW7O2O,30 , NCRS27O, NCRS4IO, NCR8455, NCR8555, NCR3565, NCR8575, NCR8585,,,

VWrAGE8O
BURB 1905, BURB1955/85 , BURB2900, BURB6900, CAXI64I, CDCOMEGA4SO-3, CDCCYBER2O3,
CDCCYB17O-740 , CRAY1S HONDPS&20, HONDPS&/44, HONDPS8/52, HONDPSSI7O, HONDPS4,
IBMSYS38/3, IBMSYS38/5, 1BM433 1-Z 1BM3033N, 1PL4436, 1PL4443, MAGMSOI3 1, MAGM8(2,
NASAS/3000, NASAS/5000, NASASI7000, NASAS/9000, UNISYS8O-3-4 UNII 100/60,

VLNTAG81
AMD47OVI7C, BURB3955, BURB593O, CAX1636, CDCCYBER2O5 , HONDPSS/62, HONDPS7,
IIBMSYS38/4, 1BM4341-2, 1BM3033S, IBM3O8ID, 1PL4446, MAGM8V3O, GM8W30E, MAGM8O/42,
MAGM80/43, NCR8650,
VThiFAG1>=82

AMDS8cV586O, BURB592O, BURB692S, CAXI 651, CDCCYBER855, CDCCYB17O-825 , CDCCYB 170-835,
CDCCYBI7O-855 , CDCCYB17O-875 , DENHEPIBMSYS38/7, 1BM4321, 1BM4331-11, 1BM4341-10,
1BM4341-1 1, IBM3O8IG, IBM3O8IK, 1PL4445, MAGM80, MAGM8cW4I, NASAS/6600, NASASI9O4O,
NASASJ9O5O, NASAS/9060, ,NASA&'9070, NASAS/9080, NCR853511, NCR854511, NCRS5S5H, NCR856511,
NCRS67O, NCR857511, NCR858511, NCR859511, UNISYS8O-5-6

VINTA3
AMDS8O/5850, AMD68W5870 , AMD5SV5S8O, BURB2925, BURB49S5, BURB7900FI-IK, CAX1636-10,
CAX164I-1 1, CAXI651-I 1, CDCCYBI7O-865 , CDCCYBI7O-875D, CRAYXMP22, CRAYXMP24, CRAYM
1-IONDPS88/81 , FKDPS8&82 , HONDPS837, HOND?S849, IBMSYS38J8, 1BM4341-9, 1BM4341-12,
1BM3083E, 11BM3083B, 1BM3083J, 1PL4460, 1PL4480, NCR3635, NCR8645, NCR8655, NCR8665, NCR8675,
NCR8685, NCR8695, UNISYS8O-8,

The Technical Age

Age
<1

1-2
2-3
3-4
4-5
5-6
6-7
7-8

8-9
9-10
10-11
11-12
>12

Total

68

<1

4-5
5-6

6-7
7-8
8-9
9-10
10-11
11-12
>12

Total

1968-1983

70

71

338
493
476
1182 2920 3138
17580 2653 2698 3839
3491 25824
719 2935
4168 3031 27040
730
549

1651

72

1500
4073
7119
4965
3605

of

CputerB

73

74

75

1353 1509
5211 3539
3315 6392
9702 5137
3816 16596

2121
3900
5433
5964
5204

3223 3157 4152 28240
759 3773 2691 17987
1882 2946 1477
910 27791 5942 3953 1974
6642 2424 3195 1329 856 17923 4501 3381

220 4784 1087 2475 1251 1295 12244 4021
184
203 3259
908 2277 1889 1063 10229
76
142
360 2730
712
480 1611
912
124
58
131
309 2401
859
375 1387
503
532
90
141
303 2232 2636 2523
40293 47274 47621 48160 57612 57790 62247 65036

76
1-2
2-3
3-4

69

Table Al

the Inatalled Baae

of

6888
5152
5186
5927
4845
5824
17632
1338
3169

3360
8671

813
3089

77

78

79

80

81

82

2507 1028
700
947 3483
873
4512 6870 2802 2157 6937 6556
4949 6355 7923 3994 3499 10851
5882 5480 6312 7129 4380 3285
6291 4424 5765 4779 5839 4406
4093 5712 4079 6202 3486 4147
4276 3547 5218 3801 5832 2378
13123 3078 3035 4056 3349 4711
742 8810 2713 2419 3082 2800
2136
547 7624 2280 2038 2105
2703 1680
502 6065 1984 1511
6469 2186 1569 401 4925 1601
3417 8306 9718 9013 7681 10418

83

5940

5409
6190
9563
3137
3392
3094
2331
3902
2250
1340
1054
9358

71894 61100 58023 57960 53243 56515 55642 56960

Table A2

Technical age of a typical ystn
1968-1983

Year
1968
1969
1970
197].
1972
1973
1974

1975
1976
1977
1978
1979
1980
1981
1982
1983

Average

weighted
by value
4.29
4.62
5.13
5.85
5.79
5.60
5.53
5.69
6.05
6.37
6.48
6.52
6.38
6.20
6.61
6.16

Median
Average
wei?hted
tall
by 3.flS
4.18
4.60
4.99
5.46
5.53
5.67
5.63
5.93
5.85
6.45
6.51
7.02
7.38
6.87
6.77
6.25

3.50
3.75
4.66
5.33
6.33
6.91
4.00
5.00
6.00
6.25
5.66
6.25
6.58
6.25
5.50
4.83

