NBER WORKING PAPER SERIES

OPTIMAL POLICY WITH LOW-PROBABILITY EXTREME EVENTS
Lars E.O. Svensson
Working Paper 10196
http://www.nber.org/papers/w10196
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2003

A preliminary version of this paper was presented at “Macroeconomics, Monetary Policy, and Financial
Stability,” a Festschrift for Charles (Chuck) Freedman hosted by the Bank of Canada, June 20, 2003. It was
provoked by issues raised by Chuck [3] in the general discussion of Svensson [6] at the Jackson Hole
Symposium in 2002. I thank Chuck, Charles Bean, Guy Debelle, Pierre Duguay and Charles Goodhart for
helpful discussions and comments. I thank Annika Andreasson and Kathleen Hurley for editorial and
secretarial assistance and Jose Mauricio Prado, Jr. for research assistance. Financial support from Princeton
University’s Center for Economic Policy Studies is gratefully acknowledged. Remaining errors and expressed
views are my own. The views expressed herein are those of the authors and not necessarily those of the
National Bureau of Economic Research.
©2003 by Lars E.O. Svensson. All rights reserved. Short sections of text, not to exceed two paragraphs, may
be quoted without explicit permission provided that full credit, including © notice, is given to the source.

Optimal Policy with Low-Probability Extreme Events
Lars E.O. Svensson
NBER Working Paper No. 10196
December 2003
JEL No. E52, E58, E61
ABSTRACT
The optimal policy response to a low-probability extreme event is examined. A simple policy
problem is solved for a sequence of different loss functions: quadratic, combined quadratic/absolutedeviation, absolute-deviation, combined quadratic/constant, and perfectionist. The paper shows that,
under some simplifying assumptions, each of these loss functions puts less weight on a lowprobability extreme event than the previous one, down to the quadratic/constant and perfectionist
loss functions, which completely ignores the low-probability extreme event. The case when the size
of the extreme shock is endogenous and depends on the policy is also examined. This introduces an
additional effect on the optimal policy except for the combined quadratic/constant and the
perfectionist loss functions.
Lars E.O. Svensson
Department of Economics
Fisher Hall
Princeton University
Princeton, NJ 08544-1021
and NBER
svensson@princeton.edu

1. Introduction
A standard result in optimal-control theory is certainty equivalence, which results under the
assumption of a linear model with additive uncertainty and a quadratic loss function. Certainty equivalence implies that only the mean values (that is, the probability-weighted average
outcomes) of target variables matter for the optimal policy setting. Consider monetary policy
under flexible inflation targeting, where inflation and the output gap are the target variables.
Because of the sizable lags in the full eﬀects of monetary policy actions on output and inflation,
say about a year for output and about two years for inflation, such monetary policy is most
eﬀective if it is forward-looking and relies on inflation and output-gap projections. Certainty
equivalence then implies that optimal monetary policy need only consider mean inflation and
output-gap projections. That is, the central bank need only to do flexible “mean” inflation
targeting, regardless of the degree of uncertainty of the projections. Only the first (statistical)
moment matters for policy, not the higher moments.
Furthermore, certainty equivalence implies that a low-probability extreme event (that is, a
large shock with a small probability) should be taken into account by the mean size of the
event, that is, the probability-weighted size of the shock. Such events could, for instance, be
a large and sudden depreciation of the currency (say, the pound or the dollar), a bursting of
an asset-price bubble (say, a property-price bubble), or a war in the Middle East with, among
other disturbances, an associated oil-price hike. For the Bank of England, the possibility of a
sudden substantial depreciation of the pound and resulting higher inflation has been a relevant
example. If the Bank of England normally aims at achieving the inflation target at a two-year
horizon, this would imply setting interest rates such that mean inflation about two years ahead,
including the possibility of a sudden depreciation, approximately equals the inflation target. If
a depreciation of the pound would not occur during the next two years, actual inflation would
most likely end up lower than the inflation target. Since a depreciation would occur only by a
small (subjective) probability, actual inflation would with a large probability fall short of the
inflation target.
In informal discussions, several central bankers have questioned whether, in such situations,
it may make sense to put less weight on the low-probability event than suggested by certainty
equivalence and the mean size of the event, perhaps even to ignore the low-probability event
altogether. For instance, another policy option is to wait and see, and to deal with the event
only if it occurs. Freedman [3, p. 319—330], at the Jackson Hole Symposium in 2002, sponsored
1

by the Federal Reserve Bank of Kansas City, stated, in commenting on Svensson [6]:
There are two points about this paper I’d like to make. The first relates to the
mean versus mode debate, and I’d like to tie that to the asset price issue. One of
the real challenges to central banks is how to deal with small probability cases. If
we have a situation where there is, say, a 10 percent probability of an asset price
collapse and a 90 percent probability that it is not going to happen, do you then go
ahead and focus on what one would call the mode, which is the appropriate path
for policy in the 90 percent case and say, “If the 10 percent case happens, we’ll try
and deal with it later.”? Or do we try to deal with the mean? In that case if the
small probability outcome doesn’t happen, you are going to have an interest rate
path that is not appropriate. But even if it does happen, you will not have moved
interest rates enough to deal with the collapse of asset prices in any case. So, it is
very much an open question of how to deal with such a situation.
The Monetary Policy Committee (MPC) of the Bank of England has raised issues like these,
for instance, on February 6—7, 2002, in discussing the issue of a potential depreciation of the
pound, [1, p. 10]:
[S]ome members placed weight on upside risks to the inflation outlook. Two main
risks to inflation were emphasised: from the possibility of a depreciation of sterling’s
exchange rate and from the possibility that consumption would not slow as much as
projected. ... There was evidence that the exchange rate was overvalued. ... Other
members placed less weight on the exchange rate risk in the published fan charts
— either because they thought the probability of a depreciation was low or because
the pass through to prices would be small or because policy could react if and when
sterling fell.
Furthermore, MPC member Nickell [4, p. 19] discusses the issue of exchange rate movements for
the Bank of England’s monetary policy in somewhat greater detail:
The important question here is should we move interest rates up today in order to
forestall the potential inflationary consequences of a significant exchange rate fall
which might come about as UK domestic demand growth slows and international
demand growth speeds up?
He prefers a wait-and-see approach, though:
In my view, the answer is simply no. If, and when, such a fall in the exchange rate
comes about, then is the time to make appropriate adjustments, if any, in interest
rates. To act pre-emptively on this front is diﬃcult because of the huge uncertainties
involved in forecasting exchange rate movements and not really necessary because
the lags to demand from interest rates and exchange rates are of the same order of
magnitude.
He clarifies the last point by stating [4, footnote 16]:
2

The argument here is that the first round, price level eﬀects from sudden exchange
rate moves should be accommodated, with monetary policy only acting on the potential second-round eﬀects.
The quotes from the Bank of England’s minutes and Nickell’s speech could be interpreted as
indicating a desire to assume the problem away and to argue that there is no tradeoﬀ, because
(i) it is appropriate to accommodate the first-round eﬀect on inflation of a currency depreciation,
and (ii) the second-round eﬀects on inflation have such long lags that they can be handled by
interest-rate adjustments once the depreciation has occurred. But what if it would be undesirable
to accommodate also the first-round eﬀect on the price level?
Clearly, if the extreme event in question is such that there is time to react to it in case it
materializes, there is no point in trying to preempt the event. Instead, there is an option value of
waiting to see if the event materializes and only then take the appropriate action. But assume
that the event will, with some probability, occur within the lag between a policy action and
its impact on the target variables and, furthermore, have a sizable direct impact on the target
variable within that lag, so that any policy action after the event cannot undo this. Then, there
is a genuine tradeoﬀ between acting to preempt the event by taking it into account by its mean
size, and not preempting.
This paper tries to come to grips with problems of this type, when there is a genuine tradeoﬀ
between preempting and not, by examining what kind of optimal policy for a low-probability
shock is implied by other loss functions than the standard quadratic one.1 The paper considers a simple policy problem with a sequence of diﬀerent loss functions: quadratic, combined
quadratic/absolute-deviation, absolute-deviation, combined quadratic/constant, and perfectionist.2 Obviously, this is a short and far from exhaustive list of possible loss functions. The paper
shows that, under some simplifying assumptions, each of these loss functions puts less weight
on a low-probability extreme event than the previous one, down to the quadratic/constant and
perfectionist loss functions, which completely ignore the low-probability extreme event. The
paper also examines the case when the size of the extreme shock is endogenous and depends
on the policy instrument. This introduces an additional eﬀect on optimal policy of the extreme
shock for all loss functions except the combined quadratic/constant and the perfectionist.
1

Vickers [9] and Wallis [10] have previously examined whether some of these loss functions motivate mean,
median or mode inflation targeting under normal circumstances.
2
The combined quadratic/constant loss function can be seen as a simplification of the bell loss function
examined by Bray and Goodhart [2].

3

2. A simple policy problem
Let π denote (the rate of) future inflation, and assume that future inflation is determined by
the current state of the economy, x, a current (policy) instrument, i, and an exogenous future
stochastic shock, z, according to
π = x − αi + z,
where α is a positive constant. Assume that the instrument has to be set before the future shock
is known but after the current state of the economy is observed. Assume that the future shock
is the sum of two independently distributed random variables, ε and η,
z = ε + η.
Assume that ε has a zero mean and a continuous distribution. It will be interpreted as a future
normal-size shock with relatively modest variance. Let f (ε) denote the density function of the
normal-size shock.
Let η have a discrete distribution such that it can take two values, 0 and a, with probability
1 − γ > 0 and γ > 0, respectively. Let a > 0 be a given large number, and let γ be a small
probability. (The case when the size of the shock is endogenous will be examined in section 8.)
The high-probability outcome, η = 0, and the resulting shock, z = ε, will be identified with a
future normal outcome. The low-probability outcome, η = a, and the resulting shock, z = a + ε,
will be identified with a future extreme outcome. Thus, the extreme outcome is here a large
inflationary shock.3
Let h(z) be the density function of the future shock z. Under the assumptions above, it will
be given by
h(z) ≡ (1 − γ)f (z) + γf (z − a).

(2.1)

An example of such a density function is shown in figure 2.1. The unconditional mean of z, E z,
fulfills
Ez ≡

Z

zh(z)dz = γa.

For future reference, let med(z) denote the median of z. It is (for a continuous distribution)
defined by
1
Pr[z ≤ med(z)] = ,
2
3

(2.2)

The extreme outcome could be a large deflationary shock. This brings in issues of the zero lower bound on
interest rates and the risk for the economy of falling into a liquidity trap with a prolonged recession and deflation.
These topical issues have to do with nonlinearities in the transmission mechanism of monetary policy and raise
separate issues that are not discussed here. See Svensson [7], for instance, for a recent discussion of deflation and
liquidity traps and references to the literature on those issues.

4

Figure 2.1: The density function of the shock
h(z)

(1−γ) f (z)

γ f (z− a)

a

0

where Pr[z ≤ y] ≡

Ry

−∞ h(z)dz

z

denotes the probability that the realization of the future shock z

is less than or equal to a given value y. Furthermore, let mode(z) denote the mode of z, that is,
the set of z (which can have several elements) for which the probability density is the highest,
mode(z) ≡ arg max h(z).
Let π̄ denote expected future inflation conditional on the future normal outcome, the normal
mean (future) inflation,
π̄ ≡ E [π; η = 0] .
We note that normal mean inflation is related to the current state of the economy and the
current instrument by
π̄ = x − αi,

(2.3)

and that the relation between realized future inflation and normal mean inflation is
π = π̄ + z.

(2.4)

For given normal mean inflation, the density function of future inflation is then given by h(π−π̄).
It is shown in figure 2.2. Unconditional mean (future) inflation, E π, will fulfill
Z
E π ≡ πh(π − π̄)dπ = π̄ + γa.

(2.5)

It follows that we can conveniently discuss the policy action in terms of the resulting normal
mean inflation, and for given normal mean inflation (and current state of the economy) then
infer the corresponding instrument setting from (2.3).
5

Figure 2.2: The density function of future inflation
h(π − π-)

(1−γ) f (π − π-)

γ f (π − π- − a)

π- + a

π-

π

Let L(π) be a loss function over inflation with a fixed inflation target, π ∗ , which we take to be
a low positive number. The loss function has a minimum for the inflation target: L(π) ≥ L(π ∗ )
for all π. The minimum will be unique for the loss functions considered here (L(π) > L(π ∗ )
for all π 6= π ∗ ), but this is not necessary and the treatment here can easily be extended to
loss functions that have non-unique minima, for instance those corresponding to a “zone of
indiﬀerence.”4
The policy problem then consists of selecting the normal mean inflation, π̄, so as to minimize
the expected loss,
E L(π) ≡

Z

L(π)h(π − π̄)dπ =

Z

L(π̄ + z)h(z)dz.

Since inflation is the only target variable (the only variable entering the loss function), this is a
case of so-called “strict” inflation targeting–an unrealistic but simple case to deal with.
The first-order condition for an optimum can then be written
Z
Z
∂L(π̄ + z)
∂L(π)
∂
E L(π) =
h(z)dz =
h(π − π̄)dπ = 0,
∂ π̄
∂π
∂π
where

∂L(π)
∂π

is the marginal loss (function), the derivative of the loss function with respect to

inflation. Hence, we can write this simply as
E

∂L(π)
= 0.
∂π

(2.6)

That is, the normal mean inflation should be chosen so that the expected marginal loss equals
4
A loss function fulfilling L(π) = 0 for |π − π∗ | ≤ c > 0 and L(π) = c for |π − π∗ | > c is an example of a
zone-of-indiﬀerence loss function.

6

zero. This is the optimal targeting rule for this problem (see, for instance, Svensson [8] on
targeting rules).

3. A quadratic loss function: Mean inflation targeting
Consider a quadratic loss function,
1
L(π) ≡ (π − π ∗ )2 .
2

(3.1)

This loss function is shown as the solid curve in figure 3.1. The marginal loss is continuous,
linear and increasing in inflation,
∂L(π)
= π − π∗ .
∂π

(3.2)

It is shown as the solid line AA’ in figure 3.2.
From the optimal targeting rule, (2.6), and the marginal loss, (3.2), it follows that the optimal
targeting rule in the quadratic case is simply
E π = π∗ .
That is, normal mean inflation should be set so as to make unconditional mean inflation equal
to the inflation target, what we can call (unconditional) mean inflation targeting. This is an
example of the certainty equivalence that holds under the assumption of a linear model with
additive uncertainty and a quadratic loss function.
It follows from (2.5) that the optimal normal mean inflation with a quadratic loss function,
denoted π̄ q , is given by
π̄ q = π ∗ − γa.
It hence undershoots the inflation target by the mean future extreme event, γa, the probabilityweighted size of the future extreme shock.

4. An absolute-deviation loss function: median inflation targeting
Consider an absolute-deviation loss function, that is, a loss function that is linear in the absolute
deviation of inflation from the inflation target,
L(π) ≡ |π − π ∗ | .

7

(4.1)

Figure 3.1: Alternative loss functions
L(π )

c2/2

π*− c

0

π*

π

π*+c

Figure 3.2: Alternative marginal loss functions
A’

∂ L(π ) /∂π
F’

c-

π*− c
D

−c-

π*

E

B

C

C’

B’

E’

π*+c

D’

π

F

A

This loss function is shown as the V-shaped dashed-dotted line in figure 3.1. For this loss
function, the marginal loss is discontinuous at the inflation target and otherwise constant,
½
∂L(π)
− 1 for π < π ∗ ,
=
1 for π > π ∗ .
∂π
It is shown as the step function CBFF’B’C’ in figure 3.2.
The expected marginal loss is hence
Z π∗
Z ∞
∂L(π)
= −
h(π − π̄)dπ +
h(π − π̄)dπ
E
∂π
−∞
π∗
= − Pr[π ≤ π ∗ ] + Pr[π > π ∗ ]
= 1 − 2 Pr[π ≤ π ∗ ],
8

where I have used that Pr[π > π ∗ ] = 1 − Pr[π ≤ π ∗ ]. The optimal targeting rule, (2.6), requires
setting this equal to zero, which results in
1
Pr[π ≤ π ∗ ] = .
2

(4.2)

It follows from (2.2) that normal mean inflation should be set so that median future inflation
equals the inflation target, what we can call median inflation targeting,
med(π) = π ∗ .

(4.3)

It then follows from (2.4) and (4.3) that the optimal normal mean inflation with an absolutedeviation loss function, denoted π̄ a , is given by
π̄ a = π ∗ − med(z).

(4.4)

4.1. A special case
Assume that the normal future shock, ε, has a bounded symmetric support, ε ∈ [− b, b] (where
b > 0 is a constant).5 Furthermore, assume that
a > 2b.

(4.5)

This implies that the support of the extreme shock, z = a + ε ∈ [a − b, a + b], falls outside the
support of the normal shock (this is the case for the density function shown in figure 2.1). This
is consistent with the previous assumption that the variance of the normal shock ε is modest
relative to the size of the extreme event.
Furthermore, in order to conveniently compute the median of the total future shock, z,
assume that ε is uniformly distributed,
f (ε) =

½

1
2b

for |ε| ≤ b,
for |ε| > b.

0

Then the density function of the future shock, h(z), is given by

0
for z < − b,



1

 (1 − γ) 2b for − b ≤ z ≤ b,
0
for b < z < a − b,
h(z) =

1

for a − b ≤ z ≤ a + b,
γ


2b

0
for a + b < z.

(4.6)

(4.7)

This density function is illustrated in figure 4.1.
5

The support of a probability distribution is the set of outcomes for which the density or probability is positive.

9

Figure 4.1: The special-case density function of the shock
h(z)

Height = (1−γ )/2b

Height = γ /2b

−b 0 b

a−b a+b

To compute the median of z, med(z), we assume that γ <

1
2

z

(recall that we assume that γ

is a small positive number) and use that the median then falls within the support of the normal
shock,
0 < med(z) < b.

(4.8)

It follows from (4.7) that
Pr[z ≤ med(z)] = (1 − γ)

1
[med(z) + b],
2b

which together with (2.2) results in a convenient expression for the median of z,
med(z) =

γ
b,
1−γ

(4.9)

confirming (4.8). It follows from (4.4) and (4.9) that normal inflation with an absolute-deviation
loss function will fulfill
π̄ a = π ∗ −

γ
b < π∗ .
1−γ

Unconditional mean inflation will then fulfill
E π = π ∗ + γ(a −
where the inequality holds for γ <

1
2

and (4.5).

10

1
b) > π ∗ ,
1−γ

(4.10)

5. A combined quadratic/absolute-deviation loss function: Less weight on the
extreme event
Consider a loss function that is quadratic for moderate deviations of inflation from the inflation
target but linear in the absolute deviation from the target for large deviations,
½
1
∗ 2
for |π − π ∗ | ≤ c,
2 (π − π )
L(π) ≡
1 2
∗
c |π − π | − 2 c for |π − π ∗ | > c,

(5.1)

where c > 0 denotes the deviation from the target at which the loss function shifts from quadratic
to linear. I shall refer to |π − π ∗ | ≤ c as the quadratic range of the loss function and to
|π − π ∗ | > c as the linear range. This loss function is shown as the combined solid curve for the
quadratic range and short-dashed lines for the linear range in figure 3.1.
Such a loss function represents a situation when a quadratic loss function with a rising
marginal loss is considered appropriate for moderate deviations from the target. For large
deviations from the target, the marginal loss is considered constant rather than increasing,
corresponding to a linear range of the loss function.
The loss function is continuous and has a continuous marginal loss,

−c
for π − π ∗ < − c,
∂L(π) 
∗
=
π − π for |π − π ∗ | ≤ c,

∂π
c
for π − π ∗ > c.

This marginal loss is shown in figure 3.2 and consists of the constant segment CB, the increasing
linear segment BB’, and the constant segment B’C’.
The expected marginal loss is then
Z π∗ −c
Z π∗ +c
Z ∞
∂L(π)
∗
= −
ch(π − π̄)dπ +
(π − π )h(π − π̄)dπ +
ch(π − π̄)dπ
E
∂π
−∞
π ∗ −c
π ∗ +c
Z π∗ +c
∗
(π − π ∗ )h(π − π̄)dπ + c Pr[π > π ∗ + c]
= − c Pr[π ≤ π − c] +
π ∗ −c

∗

= − c Pr [π − π ≤ − c] + E [π − π ∗ ; |π − π ∗ | ≤ c] Pr[|π − π ∗ | ≤ c]
+ c Pr [π − π ∗ > c] .

Setting the expected marginal loss equal to zero in accordance with the optimal targeting rule,
(2.6), results in
∗

∗

E [π; |π − π | ≤ c] = π − c

½

Pr [π − π ∗ > c] − Pr [π − π ∗ ≤ − c]
Pr[|π − π ∗ | ≤ c]

¾

.

(5.2)

This condition says that mean inflation conditional on inflation falling within the quadratic
range of the loss function should undershoot the inflation target by the product of the marginal
11

loss in the linear range times the ratio between (i) the diﬀerence between the probability of
inflation falling in the upper linear range and the probability of inflation falling in the lower
linear range and (ii) the probability of inflation falling in the quadratic range.
Regarding the special case discussed above, assume that a, b and c fulfill
a−b>

1 − 2γ
1
c>
c > b.
1−γ
1−γ

That is, a − b exceeds b in (4.5) with a suﬃcient margin, so

1
1−γ c

(5.3)
and

1−2γ
1−γ c

fit in between (recall

that γ is a small number, so these two expressions are close to c). This will imply that the
normal support of inflation, [π̄ − b, π̄ + b], will fall within the quadratic range, and the extreme
support of inflation, [π̄ + a − b, π̄ + a + b], will fall within the linear range of the loss function.
Given (5.3), we then have
E [π; |π − π ∗ | ≤ c] = π̄,

Pr [π − π ∗ ≤ − c] = 0 and

Pr [π − π ∗ > c] = γ.

It follows from the first-order condition (5.2), that the optimal normal mean inflation under the
quadratic/absolute-deviation loss function, denoted π̄ qa , undershoots the inflation target by the
γ
1−γ

times the marginal cost of inflation in the linear range,6
π̄ qa = π ∗ −

γ
c < π∗ .
1−γ

(5.4)

Unconditional mean inflation then fulfills
E π = π ∗ + γ(a −

1
c) > π ∗ ,
1−γ

where the inequality follows from (5.3).

6. A combined quadratic/constant loss function: Normal mean inflation targeting
Consider a combined quadratic/constant loss function, that is quadratic for moderate deviations
of inflation from the inflation target and constant for large deviations,
½ 1
∗ 2 for |π − π ∗ | ≤ c,
2 (π − π )
L(π) ≡
1 2
for |π − π ∗ | > c,
2c

(6.1)

6
With this optimal normal mean inflation, the normal support of inflation is [π∗ − γc/(1 − γ) − b, π∗ − γc/(1 −
γ) + b], which by (5.3) falls within the quadratic range, [π∗ − c, π∗ + c]. The extreme support of inflation is
[π∗ − γc/(1 − γ) + a − b, π ∗ − γc/(1 − γ) + a + b], which by (5.3) falls within the linear range above the inflation
target, [π∗ + c, ∞).

12

where c > 0 denotes the deviation from the target at which the loss function shifts from quadratic
to constant. The loss function is shown as the combined curve for the quadratic range and
horizontal long-dashed line for the linear range in figure 3.1. The loss function is continuous,
whereas the marginal loss is discontinuous at π = π ∗ ± c,
½
∂L(π)
π − π ∗ for |π − π ∗ | < c,
=
0
for |π − π ∗ | > c.
∂π
The marginal loss function, shown in figure 3.2, consists of the segment DE, BB’ and E’D’.
This loss function can be seen as a simplification of the “bell loss function,”
L(π) = c(1 − e− (π−π

∗ )2 /2

),

which is discussed and examined by Bray and Goodhart [2]. The bell loss function is close to a
quadratic loss function for small deviations from the target and asymptotically approaches an
upper bound c for large deviations. The marginal loss of the bell loss function is continuous,
∂L(π)
∗ 2
= c(π − π ∗ )e− (π−π ) /2 ,
∂π
approximately linear and increasing for small deviations from the inflation target and approaching zero for large deviations. It can be motivated by a finite upper bound for the loss, for
instance, if the worst thing that can happen to a central banker is to be fired from the job after
bad performance and this is associated with a finite loss.
The expected marginal loss of the combined quadratic/constant loss function is then
Z π∗ +c
∂L(π)
=
(π − π ∗ )h(π − π̄)dπ = E [π − π ∗ ; |π − π ∗ | ≤ c] Pr [|π − π ∗ | ≤ c] .
E
∂π
∗
π −c
Setting this equal to zero, according to the optimal targeting rule, results in
E [π; |π − π ∗ | ≤ c] = π ∗ .

(6.2)

Expected inflation conditional on inflation falling within the quadratic range of the loss function
should equal the inflation target.
In the special case of (5.3), we have E [π; |π − π ∗ | ≤ c] = π̄. It follows that optimal normal
mean inflation under a combined quadratic/constant loss function, denoted, π̄ qc , fulfills
π̄ qc = π ∗ .
The unconditional mean inflation then fulfills
E π = π ∗ + γa > π ∗ .
13

7. A perfectionist loss function: Mode inflation targeting
Finally, let us consider a perfectionist, all-or-nothing, loss function, a rather special case where
only an outcome right on the inflation target is acceptable and everything else is a failure. This
can be represented with the help of Dirac’s Delta function, δ(x), which has the properties
½
∞ for x = 0,
δ(x) =
0 for x 6= 0,
and

Z

δ(x)f (x)dx = f (0)

for any function f (x). The perfectionist loss function can then be written
L(π) ≡ − δ(π − π ∗ ),
giving an unbounded gain (negative loss) when inflation equals the inflation target and zero
otherwise. The Delta function can be seen as the limit of a sequence of δ n (x)-functions, the
tent-shaped function illustrated in figure 7.1, when n approaches infinity,
δ(π − π ∗ ) = lim δ n (π − π ∗ ).
n→∞

I avoid illustrating the Delta function in figure 3.1. It would be an infinitesimally thin negative
spike extending to minus infinity located at π = π ∗ and equal to zero elsewhere.
The Delta function is not diﬀerentiable at π = π ∗ , so we cannot specify the marginal loss in
this case. Therefore, the optimal targeting rule stating that the expected marginal loss should
equal zero does not apply here. Instead, we have to look directly at the expected loss. It is
Z
E L(π) ≡ L(π)h(π − π̄)dπ = − h(π ∗ − π̄),
the negative of the density function for inflation at the inflation target. Minimizing the loss then
corresponds to adjusting normal mean inflation, π̄, so as to maximize the probability density of
an inflation outcome equal to the inflation target. This means adjusting normal mean inflation
such that the mode of inflation coincides with the inflation target, mode inflation targeting,
mode(π) = π ∗ .
It follows from (2.4) that the optimal normal mean inflation under the perfectionist loss function,
π̄ p , is given by
π̄ p = π ∗ − mode(z).
14

Figure 7.1: The δ n (π − π ∗ ) function
δn(π − π*)
n

0

π*−1/n π* π*+1/n

π

For the density function h(z) in (2.1), since the probability of the extreme event, γ, is a
small number, the mode of h(z) coincides with the mode of f (z), the distribution for the normal
shock,
mode(z) = mode(z; η = 0).
That is, since the extreme event has low probability, the mode occurs for the normal outcome
and is independent of the probability and the size of the extreme event. Thus, mode inflation
targeting completely disregards the extreme event (as long as it has low probability).
For a symmetric unimodal distribution for the normal outcome, the mode, the mean and the
median are all equal. This is the case for the probability distribution f (z) shown in figure 2.1,
for which mode(z) is zero. Hence, in this case, optimal normal inflation under the perfectionist
loss function, π̄ p , equals the inflation target,
π̄ p = π ∗ .
For distributions that are not symmetric or unimodal, the mode, the mean and the median
will generally diﬀer from each other. Furthermore, the mode is not necessarily unique. The
uniform probability distribution, assumed in the special case and shown in figure 4.1, has the
mode equal to the whole support of the distribution for the normal outcome,
−b ≤ mode(z) ≤ b.
Thus, in this case, the optimal normal mean inflation under the perfectionist loss function,
denoted π̄ p , is not unique but given by the interval
π ∗ − b ≤ π̄ p ≤ π ∗ + b,
15

which we can write as π̄ p = π ∗ + [− b, b].
Thus, a rather bizarre loss function is required to give prominence to mode projections.
Furthermore, mode projections have some undesirable properties. Of possible measures of the
“central tendency” of a projection, it seems less relevant than the mean or the median. Some
central banks nevertheless present their main projections as mode projections. This practice
seems diﬃcult to defend, as noted by Svensson [5], for instance.

8. An endogenous extreme shock
Above, the size and probability of the extreme shock have been taken as exogenous. A possible
relevant case, however, is when the size and/or the probability of the extreme shock depend on
the policy instrument. For instance, the bursting of an asset-price bubble may depend on the
policy.7
A simple case is when the size of the extreme shock, a, is a linear function of the instrument,
a = a1 + a2 i,
where a1 is a given large positive number and a2 is a given number. Let us assume that the
coeﬃcient a2 is positive, that is, the size of the extreme inflationary shock is increasing in the
instrument. This would seem to fit the U.K. exchange-rate example, since a higher interest
rate might increase the potential overvaluation of the pound and thereby the later depreciation.
Generally, the sign of the coeﬃcient a2 could depend on the nature of the shock. The case above
with exogenous a obviously corresponds to a2 = 0. We assume that a remains a large positive
number for the relevant range of the instrument.
The probability density function of the shock z can then be written as
h(z, i) ≡ (1 − γ)f (z) + γf (z − a1 − a2 i),
where the instrument i now has a special direct eﬀect on the density function, since a2 is diﬀerent
from zero. It follows that the density function of inflation can be written
h(π − π̄, i) = (1 − γ)f (π − π̄) + γf (π − π̄ − a1 − a2 i),
again with a direct eﬀect of the instrument on the density, in addition to the standard eﬀect on
normal mean inflation in (2.3).
7
Pierre Duguay and Charles Goodhart made this point at the conference, which led me to add this section to
the paper. The section has benefited from additional comments from Charles Goodhart.

16

The optimal policy now has to take the special direct eﬀect of the instrument into account.
The expected loss is
E L(π) ≡

Z

L(π)h(π − π̄, i)dπ =

Z

L(π̄ + z)h(z, i)dz.

The derivative of the expected loss with respect to the instrument is
Z
Z
∂
∂L(π̄ + z) ∂ π̄
∂h(z, i)
EL(π) =
h(z, i)dz + L(π̄ + z)
dz.
∂i
∂π
∂i
∂i
Since

∂ π̄
∂i

= − α by (2.3), the first term on the right side can be written
Z
∂L(π̄ + z) ∂ π̄
∂L(π)
h(z, i)dz = E
(− α),
∂π
∂i
∂π

the expected marginal loss times − α. The second term can be written
Z
Z
∂h(z, i)
∂
L(π̄ + z)
dz = Pr[η = a]
L(π̄ + a1 + a2 i + z)f (z)dz
∂i
∂i
Z
∂L(π̄ + a1 + a2 i + z)
f (z)dz a2
= γ
∂π
¸
·
∂L(π)
; η = a a2 ,
= γE
∂π
the probability of the extreme event times the expected loss conditional on the extreme event
times a2 .
The first-order condition with respect to the instrument sets the derivative
This, together with the above expressions, results in the optimal targeting rule,
·
¸
∂L(π)
∂L(π)
(−α) + γE
; η = a a2 = 0.
E
∂π
∂π

∂
∂i E L(π)

= 0.

(8.1)

It can be interpreted as follows: A marginal increase di > 0 of the instrument shifts the whole
probability distribution of inflation in figure 2.2 to the left by αdi. The corresponding marginal
change of the expected loss is E ∂L(π)
∂π (− α)di. Furthermore, this increases the size of the extreme
shock by da = α2 di and shifts the extreme part of the probability distribution of inflation in figure
2.2, the density function around π̄ + a, to the right by the same amount. The corresponding
marginal change of the expected loss is γE[ ∂L(π)
∂π ; η = a] a2 di, the probability of the extreme
shock times the expected marginal loss conditional on the extreme event times the increase in
the size of the extreme shock. The sum of these marginal changes in the expected loss must be
zero in an optimum, which gives (8.1).
Policy is aﬀected by the endogeneity of the size of the shock only when the marginal loss
∂L(π)
conditional on the extreme shock is nonzero. Then, we will have E ∂L(π)
∂π > 0 instead of E ∂π =

17

0, and optimal normal mean inflation will be higher than when the size of the extreme shock is
exogenous. It will be optimal to lower the size of the extreme shock somewhat, but this require
a lower instrument level and results in a higher normal mean inflation.
For the quadratic loss function, we have
E
γE

·

∂L(π)
= E [π − π ∗ ] = π̄ q + γaq − π ∗ ,
∂π ¸

∂L(π)
;η = a
∂π

= γE [π − π ∗ ; η = a] = γ(aq − π ∗ ),

(8.2)
(8.3)

where π̄ q and aq denote the optimal normal mean inflation and size of the extreme shock,
respectively. They are related by
π̄ q = x − αiq ,

(8.4)

aq = a1 + a2 iq ,

(8.5)

where iq denotes the optimal instrument setting. Substitution of (8.2) and (8.3) into (8.1) leads
to the optimal targeting rule
π̄ q = π ∗ − γaq + γ(aq − π ∗ )

a2
.
α

(8.6)

Substitution of (8.4) and (8.5) into (8.6) allows us to solve for the optimal iq and thereby π̄ q
and aq . Since we have aq > π ∗ (recall that a is assumed to remain a large positive number and
π ∗ is a low positive number), we see from (8.6) that normal mean inflation will undershoot the
inflation target by less than the mean size of the extreme shock. If a2 /α > aq /(aq − π ∗ ), normal
mean inflation will even overshoot rather than undershoot the inflation target.
For the combined quadratic/absolute-deviation loss function, we have
E
γE

·

∂L(π)
= (1 − γ)E [π − π ∗ ; η = 0] + γc = (1 − γ)(π̄ qa − π ∗ ) + γc,
∂π ¸

∂L(π)
;η = a
∂π

= γc,

the latter under the assumption that the support of inflation for the extreme shock falls within
the linear range. Substituting this into (8.1) gives
π̄ qa = π ∗ −

a2
γ
c(1 − ).
1−γ
α

The optimal normal mean inflation undershoots the inflation target by less than when the size
of the extreme shock is exogenous, cf. (5.4). If a2 > α, the optimal normal mean inflation even
overshoots the inflation target.
18

For the absolute-deviation loss function, we have
E
γE

·

∂L(π)
= 1 − 2 Pr[π ≤ π ∗ ],
∂π ¸

∂L(π)
;η = a
∂π

= γ.

Substituting this into (8.1) gives
a2
1
Pr[π ≤ π ∗ ] = (1 − γ ),
2
α

(8.7)

which implies that the median inflation will overshoot the inflation target. Let z̃ be defined by
a2
1
Pr[z ≤ z̃] ≡ (1 − γ ).
2
α
We have z̃ < med(z). Then,
π̄ a = π ∗ − z̃ > π ∗ − med(z).
The optimal normal mean inflation undershoots the inflation target by less than when the size
of the extreme shock is exogenous.
Under the special case of a uniform distribution, f (z), we have
Pr[z ≤ z̃] = (1 − γ)

1
(z̃ + b)
2b

for − b ≤ z ≤ b.

Combining this with (8.7) gives
z̃ =

a2
γ
γ
b(1 − ) < med(z) =
b.
1−γ
α
1−γ

For a2 > α, z̃ < 0, and optimal mean inflation will overshoot the inflation target.
For the combined quadratic/constant loss function and the perfectionist loss function, the
endogeneity of the size of the extreme shock does not aﬀect the optimal policy, since then
E[∂L(π)/∂π; η = a] = 0.

9. Comparing optimal policy for the diﬀerent loss functions
Comparing the resulting optimal normal mean inflation for the diﬀerent loss functions when the
size of the extreme shock is exogenous, we have
π̄ q = π ∗ − mean(z) < π̄ qa = π ∗ −

γ
c < π̄ a = π ∗ − med(z) < π̄ qc = π ∗ Q π̄ p = π ∗ − mode(z),
1−γ

19

where mean(z) = γa, and where the median and the mode of z depend on the distribution f (z).
In the special case of (4.5), (4.6) and (5.3), we have
π̄ q = π ∗ − γa < π̄ qa = π ∗ −

γ
γ
c < π̄ a = π ∗ −
b < π̄ qc = π ∗ Q π̄ p = π ∗ + [− b, b].
1−γ
1−γ

The quadratic loss function implies setting unconditional mean inflation equal to the inflation target and hence letting mean inflation conditional on the normal outcome, normal mean
inflation, π̄ q , undershoot the target by the mean size of the extreme event, γa, the probabilityweighted size of the extreme event. Thus, the amount of undershooting depends both on
the probability, γ, and the size, a, of the extreme event. The quadratic/absolute-deviation
loss function implies letting normal mean inflation, π̄ qa , undershoot the inflation target by the
probability-weighted constant marginal loss for the extreme event, γc, which is less than the
probability-weighted size of the extreme event. Once the extreme shock is so large that inflation
then falls in the linear range, the weight on the extreme event is independent of the size of the
extreme event.
The absolute-deviation loss function implies setting median inflation equal to the target;
hence letting the normal mean inflation, π̄ a , undershoot the target by the median of the total
shock to inflation, med(z) =

γ
1−γ b.

This puts even less weight on the extreme event (by (5.3), b

is less than c). Again, the monetary-policy response is independent of the size of the extreme
event. Finally, the quadratic/constant loss function completely ignores the extreme event, letting
the normal mean inflation, π̄ qc , equal the inflation target. It ignores the extreme event when
the shock is large enough to fall in the constant range of the loss function, regardless of its
probability.
The perfectionist loss function leads to a focus on mode projections and thereby ignores the
extreme event because it is low-probability, regardless of its size. Whether this implies that
normal mean inflation under- or overshoots the target depends on whether or not the mode of
the normal shock under- or overshoots the mean.
We have also considered the case when the size of the extreme shock is endogenous and,
more precisely, a linear function of the policy instrument. We noted that whether the size of
the extreme shock is increasing and decreasing depends on the nature of the shock and took
as the main case the one where the size is increasing in the instrument, which fits the U.K.
exchange-rate example. Then the size of the extreme shock and normal mean inflation move in
opposite directions when the instrument is adjusted. Then, optimal normal mean inflation will
undershoot the inflation target less for the quadratic, combined quadratic/absolute-deviation
20

and absolute-deviation loss functions than when the size of the extreme shock is exogenous. If
the eﬀect on the size of the extreme shock of the instrument is suﬃciently large relative to the
eﬀect on inflation, the optimal normal mean inflation will even overshoot the inflation target in
those cases. The reason is that lowering the instrument and increasing the normal mean inflation
will reduce the size and thereby the expected loss from the extreme shock. For the combined
quadratic/constant and perfectionist loss functions, endogeneity of the size of the extreme shock
has no eﬀect on policy, since the expected loss from the extreme shock is then independent of
its size.
Which of these diﬀerent loss functions makes most sense for monetary policy? This is, of
course, a rather deep question. The answer depends on, for instance, whether the loss function is
an approximation to social welfare, assigned to the central bank by society or political authorities
as in a principal-agent situation, an interpretation by the central bank of less precise instructions
or legislation, or the private loss function of a decisionmaker. In the latter case, Bray and
Goodhart [2] argue that there is nothing worse than being fired, for which situation they find their
bell loss function with an upper bound appropriate. However, even in this case, a decisionmaker
can be fired with more or less personal disgrace, making the fixed upper bound somewhat
doubtful.
One way to evaluate the sensibility of the loss functions is to consider the marginal loss. Does
it make sense that the marginal loss is increasing, constant or decreasing in the deviation from
the target? Is the marginal loss increasing for small deviations and constant or decreasing for
large ones? I hope I am excused for not having any definite answers to these questions, except
that the perfectionist loss function seems rather extreme.

References
[1] Bank of England (2002), Minutes of Monetary Policy Committee Meeting, 6 and 7 February
2002, Bank of England.
[2] Bray, Margaret, and Charles Goodhart (2002), “ ‘You Might as Well Be Hung for a Sheep
as a Lamb’: The Loss Function of an Agent,” LSE Financial Markets Group Discussion
Paper No. 418.
[3] Freedman, Charles (2002), “General Discussion: Monetary Policy and Real Stabilization,”
in Rethinking Stabilization Policy, A Symposium Sponsored by the Federal Reserve Bank of
21

Kansas City, Federal Reserve Bank of Kansas City, 319—331.
[4] Nickell, Stephen (2002), “Monetary Policy Issues: Past, Present, Future,” speech on June
19, 2002, Bank of England, www.bankofengland.co.uk.
[5] Svensson, Lars. E.O. (2001), “Price Stability as a Target for Monetary Policy: Defining and
Maintaining Price Stability,” in Deutsche Bundesbank, ed. (2001), The Monetary Transmission Process: Recent Developments and Lessons for Europe, Palgrave, New York, 60—102.
(Also available as NBER Working Paper No. 7276.)
[6] Svensson, Lars E.O. (2002), “Monetary Policy and Real Stabilization”, in Rethinking Stabilization Policy, A Symposium Sponsored by the Federal Reserve Bank of Kansas City,
Federal Reserve Bank of Kansas City, 261—312, www.princeton.edu/∼svensson.
[7] Svensson, Lars E.O. (2003a), “Escaping from a Liquidity Trap and Deflation: The Foolproof
Way and Others,” working paper, www.princeton.edu/∼svensson.
[8] Svensson, Lars E.O. (2003b), “What Is Wrong with Taylor Rules? Using Judgment in
Monetary Policy through Targeting Rules,” Journal of Economic Literature 41, 426-477.
[9] Vickers, John (1998), “Inflation Targeting in Practice: The UK Experience,” Bank of England Quarterly Bulletin 38, 368—375.
[10] Wallis, Kenneth F. (1999), “Asymmetric Density Forecasts of Inflation and Bank of England’s Fan Chart,” National Institute Economic Review 167, 106—112.

22

