NBER WORKING PAPER SERIES

THE FUTURE OF DRUG DEVELOPMENT:
THE ECONOMICS OF PHARMACOGENOMICS
John A. Vernon
W. Keener Hughen
Working Paper 11875
http://www.nber.org/papers/w11875
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2005

We are very grateful to a number of individuals for helpful comments and suggestions on this research: Ernie
Berndt, Bob Goldberg, Larry Gorkin, Mike Grossman, Scott Johnson, Jack McMillan, Patrice Milos, Henry
Olsen, Michelle Penny, Charlie Petrie, Aidan Power, and Antonio Trujillo. We also benefited from
comments provided to us during a presentation of this research at the FDA. Randy Lutter, Theresa Mullin,
and Janet Woodcock, in particular, offered very valuable comments and suggestions. We also thank Pfizer
Inc.’s Global Steering Committee on Pharmacogenomics for helpful comments provided to us at a recent
presentation in New London, Connecticut. The views expressed herein are those of the author(s) and do not
necessarily reflect the views of the National Bureau of Economic Research.
©2005 by John A. Vernon and W. Keener Hughen. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is
given to the source.

The Future of Drug Development: The Economics of Pharmacogenomics
John A. Vernon and W. Keener Hughen
NBER Working Paper No. 11875
December 2005
JEL No. I10, I11, I12
ABSTRACT
This paper models how the evolving field of pharmacogenomics (PG), which is the science of using
genomic markers to predict drug response, may impact drug development times, attrition rates, costs,
and the future returns to research and development (R&D). While there still remains an abundance
of uncertainty around how PG will impact the future landscape of pharmaceutical and biological
R&D, we identify several likely outcomes. We conclude PG has the potential to significantly reduce
both expected drug development costs (via higher probabilities of technical success, shorter clinical
development times, and smaller clinical trials) and returns. The impact PG has on expected returns
is partially mitigated by higher equilibrium prices, expedited product launches, and longer effective
patent lives. Our conclusions are, of course, accompanied by numerous caveats.
John A. Vernon
University of Connecticut
Department of Finance
2100 Hillside Road
Storrs, CT 06269
and NBER
jvernon@business.uconn.edu
W. Keener Hughen
University of Connecticut
Department of Finance
2100 Hillside Road
Storrs, CT 06269
keener.hughen@business.uconn.edu

The Future of Drug Development: The Economics of Pharmacogenomics
I.

Introduction
The pace at which science is learning about human genetics and DNA and their

influence on the evolution and treatment of human diseases is astounding. One of the
most promising avenues of this research is pharmacogenomics (PG), which is the science
of using genomic markers to predict drug response and safety. PG has the potential to
identify patients at high risk for adverse drug events (ADEs) or to predict, prior to
treatment, the efficacy of a drug for a particular patient or group of patients (based on the
expression various genotypes). To date, the most well-known and successful application
of pharmacogenomics is the Her-2/neu diagnostic test for use with the biologic Herceptin
(trastuzumab), which is a treatment for breast cancer. Her-2/neu is an oncogene that is
amplified and results in an over expression of the her-2/neu protein in a certain subset
(25-30 percent) of advanced breast cancer patients. The pharmacogenomic test for this
oncogene identifies those women who over express her-2/neu and appear to respond to
Herceptin, and for whom treatment is highly efficacious. In contrast, patients without
this genetic marker respond poorly to Herceptin.

While other examples of

pharmacogenomic applications also exist (e.g., Gleevec), this science is still relatively
new and its potential applications are evolving rapidly. To facilitate, and indeed keep up
with, the advances in this new science, the U.S. Food and Drug Administration (FDA)
recently (in late 2003) issued draft guidelines for the industry to simultaneously
encourage the use of pharmacogenomics and clarify how the FDA will evaluate these
new types of data.

2

Former FDA Commissioner, Mark McClellan, remarked at the release of these
guidelines,
“Pharmacogenomics holds great promise to shed scientific light on the often risky and
costly process of drug development…we intend to do all we can to use it to promote the
development of medicines. By providing practical guidance on how to turn the explosion
of pharmacogenomic information into real evidence on new drugs, we are taking an
important step toward that goal." (FDA News PO3-89, 2003)

While the science behind this field has captured the imagination and attention of both the
public and scientific community, the economic implications of pharmacogenomics are
equally interesting; they will likely change the drug research and development (R&D)
landscape dramatically. The costs, risks, and returns to pharmaceutical and biological
R&D may be greatly influenced by pharmacogenomics and this will have a direct impact
on public health in the United States. This paper will carefully explore these issues and
discuss their implications for the future of drug development.
Our paper is structured around three inter-related economic perspectives of
pharmacogenomics: its impact on costs, returns (net revenues), and social welfare.
Specifically, we will first consider how pharmacogenomics is likely to impact drug
development costs, times, and attrition rates (all of which are related). Second, we will
consider the financial risks and returns associated with the use of pharmacogenomics in
drug development. Third, we will discuss the potential welfare implications of
pharmacogenomics in terms of its likely impact on patient access to new and existing
drugs, firm incentives for R&D, and public health. We will proceed as follows.

3

Section II will describe the primary ways in which pharmacogenomics is likely to
influence the cost of drug development.

For example, relative to traditional drug

development, pharmacogenomics has the potential to reduce clinical trial costs (through
smaller and possibly fewer clinical trials), drug attrition rates, and clinical developmental
times. We consider and discuss these and several other related issues in this section.
Section III will analyze the market environment for products developed using this
technology. Specifically, we will consider how product revenues may be affected when
markets are segmented using pharmacogenomics.

For products developed using

pharmacogenomics there is likely to be a substantially different post-launch cash flow
profile. This section will build upon our previous work, which examined the marketdemand side issues of PG segmentation and product pricing, and consider the impact PG
may have on present value net revenues.

More specifically, we will describe how

expedited product launches and longer effective patent lives, via shorter clinical
development times, may, in certain circumstances, increase present value product cash
flows despite a smaller, segmented patient population. This section will also consider the
net present value (NPV) profile of a pharmacogenomically-developed product versus a
traditionally developed one. This will be based, as will all our qualitative remarks in this
paper, on a formal mathematical model we present in the appendix. While generalized
conclusions will not be drawn, the principle factors affecting a product’s NPV within
both environments (a traditional development paradigm versus a pharmacogenomics one)
will be discussed and some predictions will be offered with caution. Section IV will
conclude the paper with a brief discussion on the potential welfare implications of
pharmacogenomics.

4

Section II: Pharmacogenomics and the Cost of Drug Development
There are several ways in which pharmacogenomics may have a significant
impact on the cost of developing new drugs, the most important of which are likely to be
out-of-pocket clinical trials costs, clinical development times, and the attrition rate for
developmental products. The latter two categories impact the cost of drug development
because of the opportunity cost of R&D capital and the cost of product failures,
respectively. As DiMasi, Hansen, and Grabowski (2003) have shown, these two cost
categories account for the vast majority of the average cost of developing a new drug. To
be

certain,

there

are

other

important

ways

the

widespread

utilization

of

pharmacogenomics might affect drug development costs. These include the additional
costs associated with developing and using the pharmacogenomic diagnostic tests, issues
relating to scale and scope economies in development and manufacturing, and the impact
this technology may have on the growth and evolution of the industry, which could
impact financial risk and thus a firm’s cost of capital (Golec and Vernon, 2005).
However, our focus will be upon the aforementioned three areas of clinical trials
costs, development times, and attrition rates, where we think costs will be most affected.
Much of the discussion in this section is based upon a formal economic model, which is
presented in the appendix to this paper.

Clinical Trial Sizes and the Out-of-Pocket Costs of Drug Development
To frame our discussion around how the cost structure of a pharmacogenomic clinical
program will differ from a traditional one, we must consider several key factors. First,
5

for simplicity, we assume that a diseased population has two types of patients: patients
with a genetic marker for higher therapeutic efficacy and patients without this genetic
marker. This binary assumption could easily be relaxed, but this would not affect our
qualitative conclusions. We let λ represent the fraction of this population that carries the
polymorphisms.

Furthermore, we assume that patients without the marker have an

efficacy rate of ε and patients with the marker have the efficacy rate of ε+δ. It is
straightforward to show that the efficacy rate in the pooled population (i.e., the entire
population that includes individuals with and without the genetic marker) is simply
ε+λδ, or the weighted average efficacy in the entire diseased population. For a clinical
trial to demonstrate efficacy from a statistical perspective, a sufficient number of patients
must be enrolled in the trial; a trial must be powered to detect the differential efficacy
between the experimental treatment (new drug or biologic) and control (i.e., placebo). In
the appendix we derive the formula for N, which is the number of patients needed in the
trial for a given level of statistical power. We show that N is a decreasing function of
efficacy; fewer patients need to be enrolled to statistically detect a greater efficacy level.
This is of course intuitive. The number N is also a function of α and β, the well-known
statistical parameters used in powering clinical trials; these are, respectively, the
probabilities of incorrectly rejecting the Null Hypothesis of no treatment effect (Type I
error) and of failing to reject the Null Hypothesis when it is indeed false (Type II error).
For a developmental compound with a known (or hypothesized) treatment effect (the
Alternate Hypothesis), the quantity 1-β is the power of the trial, and it represents the
probability that the Null Hypothesis will be correctly rejected. Figure 1 below illustrates

6

this relationship with the treatment effect being the horizontal distance between the
population means of the Null and Alternate Hypothesis sample distributions.

Figure 1: Powering Clinical Trials: A Simple Illustration

Treatment effect

Power = 1-β

H0

HA

β−level HA

α−level H0

All things held constant, as the sample size used in the clinical trial is increased, the two
distributions in Figure 1 converge to spikes centered above their population means, and
the power of the clinical trial (1-β) approaches 100 percent. Of course, it is economically
inefficient (infeasible) to power clinical trials at such high levels (near 100 percent)
because of the extremely large sample sizes required.
The obvious benefit of a clinical development program that enrolls only highresponse-rate individuals is that fewer patients will need to be enrolled in the clinical
trials to demonstrate a statistically significant treatment effect. Because the variable cost
of a clinical trial is driven largely by the number of patients enrolled in that trial (personal
correspondence, Pfizer Clinical Development), we approximate the percentage reduction

7

in variable, out-of-pocket clinical trial costs1 (when following a pharmacogenomic
development program instead of a traditional one) by the ratio ∆N / N T , where ∆N is the

difference between N T , the of patients needed to detect the effect ε+λδ, and N G , the
number of patients needed to detect the effect ε+δ:
N T − N G = ∆N = f (ε , λ , δ , α , β )

(1)

Because clinical trials, and especially Phase III clinical trials, represent the vast majority
of variable out-of-pocket clinical development costs (DiMasi et al. 2003), the ratio
∆N / N T serves as a rough first approximation of the reduction in these costs associated
with following a pharmacogenomic development approach (relative to the same product
developed following the traditional drug development approach)2.

In the following

section and in the appendix we consider how the length of the clinical development
program will impact the out-of-pocket costs by assuming costs can be modeled on a perpatient, per-unit-of-time basis. Finally, it should be noted that there are also fixed costs
associated with clinical trials and clinical development, but data on the distribution across
these two cost categories are not publicly available. The larger the proportion of clinical
development costs that are variable costs, the greater the impact a pharmacogenomic
development program will have on the out-of-pocket cost of drug development. We
focus our analyses on variable costs exclusively.

1

This analysis applies primarily to Phase III clinical trials because the smaller Phase I and II trials are
focused largely on issues of drug metabolism and dosing. However, because Phase III is by far the largest
and most costly phase (DiMasi et al., 2003 estimate that Phase III clinical costs are approximately 70
percent of out-of-pocket clinical development costs) it seems reasonable to focus on these trials.
2
We are not presently modeling the possibility that in addition to smaller clinical trials fewer clinical trials
may be required. This would result in pharmacogenomic development programs having even lower costs
relative to traditional development programs.

8

To illustrate this through a simple example, and to demonstrate the
interrelationship among some of the key model parameters, consider the clinical
development program for a drug under both a pharmacogenomic development paradigm
and a traditional one. We assume that the clinical trials are powered such that α = 0.05
and β = 0.10. We further assume that the efficacy rate for patients without the genetic
marker for a high response rate is 10 percent (i.e. ε =0.10) and the incremental efficacy
for patients with the genetic marker, δ, are 0.05, 0.10, and 0.15.
Table 1 reports the percentage reductions in variable, out-of-pocket clinical
development costs for different values of λ (the proportion of patients with the genetic
marker) and δ (the incremental efficacy associated with having the genetic marker). The
values in Table 1 are conservative approximations for out-of-pocket development costs
because we are not modeling the temporal aspect of drug development and how PG will
impact the length of clinical development programs. The forthcoming sections of this
paper and the appendix consider these factors in detail. The appendix also discusses the
issue of running separate trials for high rate responders (patients with the genetic marker)
and low rate responders (patients without the genetic marker).
Table 1: Clinical Development Cost Reductions Associated with
PG for Different Values of λ and δ (ε = 10 percent)

δ = 0.05 δ = 0.10 δ = 0.15
λ = 0.1
λ = 0.3
λ = 0.5
λ = 0.7
λ = 0.9

33.5%
26.4%
19.0%
11.6%
3.9%

50.6%
40.2%
29.4%
18.1%
6.2%

9

61.0%
49.1%
36.4%
22.6%
7.8%

The results in Table 1 are striking, and suggest that for clinical trials, and clinical
development programs to the extent there costs are proportional to clinical trial costs, PG
has the potential to significantly reduce out-of-pocket costs. In support of this prediction,
it is worth noting that a major pharmaceutical firm recently reported redesigning a $10
million clinical trial in order to utilize genomic markers to predict drug response; the PG
trial cost the firm only $500,000 to complete (Mattingly, 2004).
While this simple exercise provides some insight into the impact that
pharmacogenomics may have on the average out-of-pocket clinical development costs for
new drugs, there are a number of factors that were not considered. For example, we do
not model the possibility that following a pharmacogenomics development approach may
require fewer numbers of clinical trials. Nor do we model how out-of-pocket pre-clinical
costs may be affected. There are also certain to be costs associated with the development
and study of pharmacogenomic diagnostic tools. However, as stated in the beginning of
this section, the most significant ways pharmacogenomics is likely to impact average
drug development costs is through its effect on drug development times and attrition
rates. This seems plausible because the costs associated with product failures and the
opportunity cost of investment capital account for over four-fifths of the total average
cost of developing a new drug (DiMasi et al., 2003). Nevertheless, some intuition around
how out-of-pocket clinical developments costs might be affected is necessary to consider;
hence our preceding analyses.

10

Clinical Development Times and Expedited Product Launches
The Herceptin and Her-2/neu diagnostic example discussed in the introduction may shed
light on the likely impact pharmacogenomics will have on average drug development
times. Because of the compelling evidence in support of Herceptin’s effectiveness in
patients with an over expressed Her-2/neu oncogene, the FDA gave Herceptin a fast-track
designation with expedited review for the treatment of metastatic breast cancer; within
4.5 months of submission (September 1998), Herceptin and HercepTest (the diagnostic
test used to identify over expressed Her-2/neu oncogenes) were approved for marketing.
Of course, the fact that Herceptin and HercepTest were being developed for a very
serious form of cancer also contributed to the fast-track designation, but it seems
plausible that the expediency with which approval was granted was also influenced by
the compelling clinical evidence that the her-2/neu diagnostic was able to quickly identify
patients likely to benefit from treatment. Most importantly, the high level of therapeutic
efficacy within patients with over expressed Her-2/neu oncogenes made it possible to
rapidly demonstrate a clinically and statistically significant survival benefit from
Herceptin therapy.
Theoretically, therefore, it seems reasonable to postulate that smaller (and
possibly fewer) clinical trials may be undertaken and completed more rapidly than larger
(and possibly more) clinical trials. Enrolling a smaller number of patients should, ceteris
paribus, take less time—especially when smaller numbers of patients per trial are coupled
with a smaller number of clinical trials. This may be the case because in a more
efficacious subpopulation of patients clinically significant treatment effects can be
demonstrated more rapidly than would be the case in a population comprised of

11

responders and non-responders (or responders and less-efficacious responders). It is not
uncommon for clinical trials to be terminated earlier than planned because of
unexpectedly favorable treatment effects. This, however, occurs because the treatment
effect was underestimated in clinical trial design, and as a result the trial was “over
powered.” Thus, while this consideration is useful in explaining why higher efficacy
levels (in subpopulations with genetic markers for high-rate responders) may lead to
shorter clinical development times, our model assumes perfect information on the
treatment effect a priori, such that the benefit of higher efficacy comes via smaller
clinical trials (i.e., ∆N from the previous section).

This should be kept in mind

throughout the forthcoming discussion because it is one possible link between smaller
clinical trails and shorter development times.
Other factors that should be considered include whether a clinical program is
developing a product for high-efficacy responders and low-efficacy responder separately
(the appendix discusses why this will be uneconomical relative to a program that simply
pools the two groups and develops a product for the pooled population); the cost and time
associated with developing a pharmacogenomic test; and the extent to which clinical trial
enrollment may take longer because of the smaller proportion of the diseased population
carrying the genetic marker (i.e., λ), all else held constant. We model the reduced
clinical development time associated with a pharmacogenomic development program as
∆Τ, where ∆T = TT – TG (where TT and TG denote average clinical development times
under a traditional drug development approach and pharmacogenomic approach,
respectively); ∆T should, in theory, be a function of the reduced clinical trial sizes, ∆N,
(and number of clinical trials), the proportion of the disease population carrying the

12

genetic marker for high-response, λ, and the time associated with developing a reliable
pharmacogenomic test or diagnostic, τ. Mathematically, we represent this as follows,
where the new variable, θ , is a proportionality scaling factor designed to capture the fact
that, in addition to reduced clinical trial sample sizes, there may also be fewer trials
required:

∆T = g θ ⋅

∆N
(ε , λ , δ , α , β ), λ ,τ
NT

(2)

Unlike equation (1), which (per the appendix) precisely mapped the relationship
between ∆N/NT and the other model variables, the function g in (2) is only a general
specification. The appendix employs several proportionality and economies of scale
assumptions, but these are somewhat speculative in nature. It is probable that ∆T is
increasing in θ and ∆N/NT, but decreasing in λ and τ. While most of these relationships
are quite intuitive, the link between ∆T and λ deserves some explanation and
clarification.

Enrolling patients in clinical trails can be a time consuming process

because patients must be screened for inclusion (exclusion) criteria. As λ approaches 0
(i.e., the proportion of patients with the relevant genetic marker gets very small), it may
be quite time consuming to screen and enroll only those patients with the relevant genetic
marker because they represent an increasingly small fraction of the diseased population
the clinical trial seeks to study. A simple example will illustrate this point. If 25 percent
of breast cancer patients carry a particular genetic marker for (i.e., λ=0.25) for high
efficacy, then on average 4 patients must be screed for every one patient that is eligible
for the clinical trial. This number increases to 10 patients per enrollee if only 10 percent

13

of breast cancer patients carry the genetic marker (i.e., λ=0.10), and 100 if only 1 percent
carry the marker (i.e., λ=0.01)3. Simply put, the number of potential enrollees that must
be screened, on average, to obtain an additional clinical trial patient is 1/λ, which grows
very rapidly for small values of λ.

Thus, the influence λ will have on clinical

development times via this effect will be strongest when λ is very small. When λ is not
very small, say for example 25 percent, as in the Herceptin example, then it seems
probable that this effect will be dominated by factors that tend to reduce clinical
development times (i.e., θ and ∆N/NT).

The additional time required to study and

develop pharmacogenomic diagnostic tests, τ, will also influence development times, but
we suspect the net effect will be a significant reduction in clinical development times.
Indeed, some recent estimates suggest that pharmacogenomic-based clinical development
programs will average 3-5 years in length compared to 10-12 years for traditional
programs (Quintiles Transnational, 2004).
Before proceeding to our discussion on how pharmacogenomics, both through
improved efficacy (via genetic targeting) and reduced adverse events (via screening), will
likely impact the technical success of drug development (and thus the expected cost of
drug development), it is worthwhile to illustrate graphically how drug development using
pharmacogenomics may be different from traditional drug development within the
context of the analysis presented in this section and the last. Figure 2 captures these
fundamental differences.

3

We do not consider this to be a major factor in our model of out-of-pocket development costs because
screening patients for genetic markers typically involves only taking a blood sample to test the individuals
DNA. Of course, as will be discussed later in the paper, there are very significant costs associated with
clinical development program length (due to the opportunity cost of investment capital), but in the previous
section we only consider out-of-pocket costs.

14

Out of Pocket Development Costs - Millions

Figure 2: The Principle Ways Pharmacogenomics May Influence
The Economics of Clinical Development

$50
PG Launch

Traditional Launch

∆T

$0
∝ ∆N/NT

PG Program
Clinical Trials
Traditional Program

0

5

10

15

Years

It is worth emphasizing that Figure 2 depicts only out-of-pocket cash flows and
not expected cash flows (which incorporate the probabilities of advancing through the
different stages of clinical development). If pharmacogenomic development programs
increase the probability of technical success (over those associated with traditional
development programs) at each development stage, then expected clinical development
costs per drug developed will be proportionately even smaller than is illustrated in Figure
2. Of course, the total expected cost of developing a new drug must also consider the
firm’s opportunity cost of investment capital; shorter development times will thus lower
expected development costs even more. This is particularly true given the fact that recent

15

estimates of the expected cost of bring a new drug to market find that these opportunity
costs of investment capital account for approximately half of the total cost (DiMasi et al.,
2003). We turn to these issues next and develop a more formal model of the impact
pharmacogenomics will have on drug development costs.
Probabilities of Technical Success in Drug Development and the Cost of Bringing a Drug
to Market
There are important ways pharmacogenomics may affect the probability of a new drug
advancing through the developmental pipeline and gaining FDA approval. The two most
fundamental are related to what are often referred to as the first and second hurdles of
drug development: safety and efficacy. The focus of our paper thus far has centered on
the higher therapeutic efficacy in a genetically identified subpopulation of patients;
however, an equally promising (if not more so) opportunity for pharmacogenomics lies in
the safety arena. Identifying patients at high risk for adverse drug events (ADEs) could
salvage a developmental product from program termination. Consider Figure 3 below,
which depicts a hypothetical population of diseased patients.
Figure 3: The Use of Pharmacogenomics to Salvage Clinical Development Programs

Safe to Enroll
In Trials
No ADE Patients
ADE Patient
Subgroup

Not Safe to Enroll

16

If the ADE is a particularly dangerous one, or even fatal one, then without a priori
information on which patients are at risk for this ADE (i.e., the ADE patient subgroup)
the product has no hope of ever reaching the market and benefiting those patients who
could safely take the drug. However, with the technology of pharmacogenomics, there is
now a much greater chance that such a product could be brought to market. Thalidomide,
the notorious 1950’s drug that was indicated for morning sickness in pregnant women
and that resulted in birth defects (and which was the impetus to the 1962 Kefauver-Harris
Amendments) received FDA approval in 1998 for the treatment of a particular skin
condition and is currently being investigated for several other indications, including use
in treating certain types of cancer (MayoClinic.com, 2005). While this example (at least
currently) does not entail the application of pharmacogenomics, it does clearly illustrate
the benefits (and high stakes) associated with successfully identifying patients at risk for
severe ADEs. For years it was unthinkable that Thalidomide might one day be back on
the market. Regarding the application of pharmacogenomics in this capacity, current
research shows there are already a number of actual and potential applications (Phillips et
al., 2001).
To more formally demonstrate how pharmacogenomics is likely to reduce the
expected cost of drug development through higher probabilities of technical success,
consider the following expression for the average capitalized cost of bringing a new drug
to market:

E[Cost] per Success =

n −1

n

t =0

t =0

C 0 p 0 + C1 p 0 p1 + C 2 p 0 p1 p 2 ... + C n −1 ∏ pt +C n ∏ p t
n

∏p
t =0

17

t

(3)

Equation (3) is based on a discrete, n-period fixed model of drug development where the
capitalized out-of-pocket drug development cost per period is denoted by Ct, and the
probability the product will advance from one period to the next is denoted by pt (with p0
assumed to be equal to unity). The Ct terms may be thought of as the capitalized discretetime counterparts to the continuous-time costs shown in Figure 2.
Equation (3) depicts the structure of the DiMasi et al. (2003) method of
calculating the average cost of developing a new drug (with a cost of capital equal to
zero). It is straightforward to see from (3) how expected development costs decrease in
pt. That is, as the probabilities of technical success increase at each development stage,
average expected development costs per successful new drug decrease.

A simple

example will illustrate this important point. Consider the simple 3-stage development
model shown below in Figure 4.

Figure 4: Expected Cost of Drug Development

Succeed

Drug Launched
(p=0.20 X 0.50 X 0.80 =0.08)

p=0.80
Succeed
p=0.20

p=0.50
Fail

Succeed
p=0.20

p=0.50
Fail

p=0.80
Fail

Pre-Clinical Program

Clinical Program

18

FDA Review

If failure or success is determined only after all out-of-pocket costs associated with that
development stage have been incurred, and if we assume the cost of investment capital is
zero, then it is easy to show how improved technical success lowers expected drug
development costs per drug. To show this assume pre-clinical development costs are $0
(for simplicity), clinical development programs cost $50 million dollars, and all FDA
submissions and New Drug Applications (NDAs) cost $10 million.

Under these

assumptions, and based on the technical success probabilities shown in Figure 4, the
expected cost of development for a given developmental drug is:
E[Cost] = 0.2 × $50,000,000 + 0.2 × 0.5 × $10,000,000 = $11,000,000

(4)

To calculate the expected cost per drug successfully developed (because the cost of
bringing a new drug to market must include the costs associated with failed drug
development programs), we simply divide this expected cost by the probability that a
drug will actually make it to market:

E[Cost] per Successful Drug =

$11,000,000
= $137,500,000
0.08

(5)

Let us now consider the expected cost per drug if the probabilities of technical success
improve, holding everything else constant. Specifically, we assume that the probability
of technical success in pre-clinical development increases from 0.20 to 0.30 and that the
probability of clinical development success increases from 0.50 to 0.80. We further
assume the probability of FDA approval remains the same. The expected cost per drug
developed is now the following:

19

E[Cost] per Successful Drug =

$17,400,000
= $90,625,000
0.192

(6)

Thus, as the probabilities of technical success increase, the expected development cost
per drug necessarily declines4.
In the preceding example we held constant out-of-pocket development costs and
clinical development times.

However, as we have already shown, it is likely that

pharmacogenomics development programs will involve both smaller out-of-pocket costs
and shorter clinical development times, as shown previously in Figure 2. These two
factors, when combined with higher probabilities of technical success, reduce the
expected cost per new drug even further, relative to a traditional drug development.
In sum, the preponderance of evidence from our analyses suggests that
pharmacogenomics will likely reduce the average cost of drug development in a very
significant manner in the future. But what will pharmacogenomics mean for drugs once
they reach the market? The general sentiment expressed among industry experts and
insiders is that this technology will segment markets, and all but do away with the
blockbuster model of drug development that has been the driving force behind the
incentives for R&D investment in the pharmaceutical industry (Grabowski and Vernon,
2000, Vernon, 2003; 2005, Giaccotto, Santerre, and Vernon, 2005). We will turn to this
and other related issues next.

4

It is worth noting that the expected development costs associated with any given program, all else held
constant, will increase because it increases the likelihood that later-stage development costs will be
incurred. For example, if the probabilities of technical success in our current example were all raised to
unity, such that there was a 100 percent chance of advancing all the way through development and gaining
FDA approval, then the expected cost (which is not really an expectation given this perfect certainty) would
be $60,000,000. This would also be the cost per drug because of the aforementioned perfect certainty of
success. The key point is that the expected cost per successful drug will always decrease in these technical
probabilities.

20

Section III: Pharmacogenomics, Market Segmentation, and Drug Revenues

In this section of the paper we undertake a fundamental review of the post-launch
economics behind pharmacogenomics.

We will base some of our analyses on our

previously work in this area (Vernon, Hughen, Johnson, and Trujillo, 2005). Danzon and
Towse (2002) also provide an excellent overview of these and other related issues.
Because the pharmaceutical industry’s core business is the innovation, development, and
marketing of new drugs, pharmacogenomic diagnostic testing will be attractive to drug
makers if it can support this business. We will explore this issue within the context of a
simple economic analysis of increased pharmaceutical market segmentation through
pharmacogenomic test development (following our approach in the last section, we will
continue to model pharmacogenomics markers in a binary manner). Specifically, we
address the sub-segmenting issue by reviewing how pharmaceutical drug revenues may
be affected in both responder and non-responder segments. We illustrate this first in a
simple, single-period model, and then consider several dynamic extensions.
The impact of pharmacogenomic-driven market segmentation on price, market
size, and present value net revenues will be shown to depend on such factors as
consumers’ (e.g., individuals, managed care plans, or national governments) willingnessto-pay for new products, the proportions of responders and non-responders, and the costs
of treating the underlying disease for which the new drug is indicated. Underpinning our
analysis is the cost-effectiveness framework widely used by payers for determining
whether a product will be covered and reimbursed for use by its enrollees or citizens for
national health insurance systems. Cost-effectiveness analysis (CEA) has come to

21

predominate in determining the value of new technology as it entails an acceptable
combination of economic theory, medical information, and empirical flexibility
(Eisenberg, 1989; Sloan, 1995; Drummond et al., 1997). Most of Western Europe,
Canada, Australia, and New Zealand use explicit or implicit forms of CEA (Jommi, 2001;
Gosling, 2000). The United Kingdom has the most stringent and formal CEA review
embodied in their National Institute for Clinical Excellence (NICE), which was
introduced in 1999 to ensure that healthcare funding is used efficiently and that policies
on treatment choice are consistent across the country, and to evaluate the costeffectiveness of pharmaceutical products deemed to significantly increase health system
expenditures (Atkinson, 2002). NICE issues criteria by which it will use CEA to conduct
these evaluations for public review, and uses a £30,000 per quality-adjusted-life-year
(QALY) threshold, or the maximum the payer is willing-to-pay per QALY.
While CEA allows payers to have a formal method for determining value for new
technology, it also allows firms to determine their customer’s maximum willingness-topay. By decomposing a new drug’s price from the total costs of the intervention, firms
may gauge the potential future price of their developmental products. In this section of
the paper we will consider how pharmacogenomic tests will divide a market into two
segments, responders and non-responders, based on the efficacies in each, and how this
segmentation will impact future drug price and market size. We then consider how
pharmacogenomics will impact present value net revenues by extending this model into a
dynamic setting.

22

While our approach will be primarily based on this simple framework, we
acknowledge that pharmacogenomics may increase a drug’s value in numerous other
important ways. We will discuss these at the end of this section.
Cost-Effectiveness, Pharmacogenomics, and Drug Prices
If one assumes that payers use cost-effectiveness standards (explicitly or
implicitly) when evaluating new therapeutic technologies, insofar as pricing is concerned,
then it is quite easy to develop a simple model capable of illuminating the key
deterministic relationships that influence both price and total revenues under traditional
and pharmacogenomic development programs.

In recent years there has been

considerable growth in the use of cost-effectiveness analyses to make decisions about
covering and reimbursing new pharmaceutical and biotechnology products. The future
appears to hold an even larger role for these analyses, even in the U.S. market, which has
traditionally not relied on these methods.

The passage of the 2003 Medicare

Modernization Act (MMA), and the Medicare Drug Benefit contained therein (which
goes into effect in January 2006), will likely exert significant pressure to expand the use
of these methods to ensure good value for money and to contain costs.
To begin, we consider a static population of q patients with disease x , for which
there is currently no treatment. As in the last section, we assume that the fraction,
λ, represents the proportion of patients with a genetic marker for high therapeutic
efficacy, i.e., ε + δ compared to ε for patients without the marker (and ε+λδ for the entire,
or pooled, population). We assume there are two cost components to disease x: c f , which
is the cost of the disease independent of treatment success (fixed costs), and cv , which is

23

a cost that is not incurred if treatment is successful (variable costs). Both costs are
strictly positive. Finally, we assume pharmaceuticals are priced such that they satisfy the
following cost-effectiveness criterion with equality: ∆(Costs)/∆(Efficacy) ≤ Ω , where Ω
is the payers’ (consumers’) maximum willingness to pay per unit efficacy (e.g., £30,000
per QALY). The costs considered in most cost-effectiveness analyses include direct
costs such as drug acquisition costs, doctor visits, hospitalizations costs, among others;
indirect costs such as time lost from work and family caregiver help are also typically
incorporated.

After differencing the costs associated with treatment using the new

technology (drug) from the costs associated with the current (standard of care) treatment,
this marginal cost is compared (divided by) the incremental efficacy of the new
technology over the current technology; this generates a measure of the cost per unit of
effectiveness, which is the cost effectiveness ratio.
Given these assumptions it is straightforward, if somewhat algebraically
cumbersome, to evaluate the total revenues under a traditional development program and
a segmented, pharmacogenomic development program (the appendix does this in a stepby-step fashion). Under a traditional development program there is no segmentation, and
thus a larger market to serve; however, under a pharmacogenomic development paradigm
there is a higher level of therapeutic efficacy, and thus from a cost-effectiveness (or value
for money) perspective, a higher equilibrium price.5 It can be shown that the latter effect
5

We do not explicitly consider the possibility that a firm will develop the product separately for responders
(the fraction λ of the population) and non-responders (or more precisely low-rate responders). The
appendix considers this possibility and shows how if firms could price discriminate based of the costeffectiveness of the drug in each market segment, then revenues under a segmenting/pharmacogenomics
development approach would yield equivalent revenues to that of a non-segmenting/traditional
development approach. However, the challenges to preventing inter-market arbitrage would be
considerable (Vernon et. al., 2005); thus, we focus our analyses on a pharmacogenomic development
program that develops a product exclusively for the proportion of the population carrying the genetic
marker for a high response rate.

24

(higher prices) will never offset the former effect (a smaller market), and specifically that
the ratio, Φ, of the revenues under the two development programs, RG and RT, for the
traditional and pharmacogenomic programs, respectively, collapses to a function of only
the clinical parameters, λ, ε, and δ:

Φ=

RG λ (e + δ )
=
≤1
RT
e + λδ

(7)

This relationship is shown in Figure 5 where Φ is on the vertical (or z-) axis with
range on the interval Φ ∈ [0,1] , λ is on the x-axis and has the domain λ ∈ [0,1] , and δ is
on the y-axis with domain δ ∈ [0,1 − ε ] = [0,0.9] . We arbitrarily set ε equal to a value of
0.10 to generate this three-dimensional space.

Figure 5: The Impact of Pharmacogenomics on Drug Revenues in a
Static, One-Period Model

Φ

1
0.75
0.5
0.25
0
0

0.8
0.6
0.4

0.25
0.5

λ

0.2
0.75
10

25

δ

Obviously, Figure 5 could be reproduced for any non-marker efficacy level, ε. As
intuition suggests and as Figure 5 clearly shows, small values of δ and λ result in less
favorable revenue outcomes for a pharmacogenomic development approach relative to
larger values of δ and λ , all else considered. We will use our measure of Φ in the next
section when we consider several dynamic extensions of the current model.

Expedited Product Launches, Effective Patent Lives, and Present Value Net Revenues
While our simple example shows that in a static, one-period model drug revenues are
likely to be less following a pharmacogenomics approach to drug development, a more
relevant issue is the impact this technology will have on present value net revenues. Two
factors are likely to work together to mitigate the static, one period reduction in revenues
of 1- Φ percent: the time value of money associated with an expedited product launch of
∆T years (from the previous section) and a longer effective patent life, which is a direct
consequence of an expedited product launch (effective patent life is equal to the
remaining patent period on a new drug or biologic at the time it is launched). Because
generic entry post-patent expiration results in a significant cannibalization of brand sales
(see, for example, Grabowski and Vernon, 2000), the value of an expedited product
launch does more than simply shift cash flow profile of a product to the left (see Figure 6
below), it also extends the pre-generic entry revenue segment of this profile.

26

Figure 6: An Economic Model of the Impact of Pharmacogenomics on
Life-Cycle Product Cash Flows

Generic Entry

Approval Approval

PG Profile

∝ 1-Φ

Net Revenue - Millions

$100

$0
Launch, Promotion, Peak Sales, Competition

∝

Clinical Trials

0

5

10

∆N/NT

15

20

30

Figure 6 is intended only to illustrate these aforementioned points in a very
general manner. There is, however, a direct link between the static, single period,
revenue model developed earlier. This link is depicted by the horizontal distance between
the two net revenue curves, which should be (after controlling for temporal shifts in the
two life-cycle net revenue curves) proportional to 1-Φ. This is similar in many respects
to our analyses and argument for why out-of-pocket development costs for a
pharmacogenomic development program will be less than those of a traditional
development program in proportion to the quantity ∆N/NT.
The relevant question is the following: is the scaling (down) effect associated with
a segmented market (1-Φ) more than offset by the favorable economic effects of an

27

expedited market launch?

That is, are present value net revenues greater under a

pharmacogenomic development model or the traditional one? It seems obvious that the
answer to this question will depend on the parameters values for ε, δ, λ, and ∆Τ. A
definitive answer is not readily available, but it seems likely that the larger the values of
Φ and ∆Τ, the more probable it is that a pharmacogenomic development program will
generate higher present value net revenues relative to a traditional program of drug
development. The appendix considers this question in greater detail.
Of course, the ultimate question one would like to answer deals not with present
value net revenues, but with the project’s net present value (NPV) under both
development paradigms. To consider this we must also incorporate the probabilities of
technical success under both drug development approaches. Because it seems likely from
our earlier analyses and discussion that pharmacogenomics will reduce the expected costs
of drug development through smaller and possibly fewer clinical trials, expedited market
launches, and higher probabilities of technical success, it seems probable that, at least for
a proportion of products, the NPV associated with a pharmacogenomic development
program will be higher than that associated with a traditional development program. This
will be particularly true, as stated above, for drugs or biologics that are associated with
large values of Φ and ∆Τ. Expressed more formally, we may write:
NPVG-NPVT = ∆(NPV) = h[∆Ν, ∆Τ, Φ]

(8)

In our model, ∆(NPV) is increasing in ∆N and ∆T and decreasing in Φ. For values of
Φ close to and approaching unity, it seems very likely that ∆(NPV) > 0, and

28

pharmacogenomics will thus lead to more financially attractive R&D investment
opportunities.
While our economic models of pharmacogenomics, and their expected impact on
both clinical development and drug revenues, are quite general, the considerations they
have identified seem to suggest that, on net, the financial benefits could easily exceed the
costs. While this may not be true for all cases, it is certain to be the case in many
circumstances.

This being said, however, there remain several other commercial

opportunities not captured in our model that warrant attention prior to concluding this
paper with a brief discussion on the future welfare implication of pharmacogenomics.
Other Commercial Considerations and Opportunities for Pharmacogenomics
There are a number of ways pharmacogenomics may enhance the commercial
opportunities for a new or existing pharmaceutical or biologic. In terms of improving the
value of marketed drugs, products could be offensively or defensively positioned through
the

strategic

inclusion

of

additional

efficacy

information

on

their

labels.

Pharmacogenomic tests associated with a product may also be used or act as a signal of
quality to physician prescriber-users or regulators by indicating an additional level of
scientific rigor behind the stated efficacy of a drug, therein reducing related uncertainty
as to its utility in the provider’s mind.
Other potential means of improving drug value through pharmacogenomics
include reducing product liability through developing a more specific, validated label or
resuscitating a withdrawn drug by developing the ability to identify prospectively adverse
reactants (as discussed in detail in the previous section of this paper). Similarly, there is

29

the possibility that pharmacogenomics could prospectively create new or expand existing
markets at a more rapid rate. The latter case may hold where a population could be
screened as being at risk for a disease and thus a candidate for early, preventive therapy.
Prospective patients with hereditary diseases such as Alzheimer’s or prostate cancer
could be screened and potentially initiate therapy years earlier than they otherwise would
have with current screening and diagnostic technology. It is also possible that additional
revenues may be earned through off-label prescribing to patients not carrying a genetic
marker for high efficacy.

While our model does not include these commercial

opportunities, it seems likely that they will significantly enhance the economic benefits
(to firms and consumers) associated with pharmacogenomics.

Section IV: Incentives for R&D, Welfare Considerations, and Conclusions
To more fully gauge the likely impact of pharmacogenomics on the future of drug
development, it is necessary to understand how this technology will shape the financial
incentives of firms in the pharmaceutical industry. In particular, if this technology has a
positive impact on the expected financial returns to investment in R&D, as we suspect it
one day will, then R&D investment in the future with will increase as a result, and so too
will innovation. The direct link between R&D investment and innovation is difficult to
predict, but recent research on the historical mapping between R&D investment and
innovation suggests that this is a highly productive investment for society, one that
generates considerable social value in terms of improved life expectancy, quality of life,
and the eradication of many diseases. For example, econometric research by Lichtenberg
(2002) has recently estimated that for every $1,345 invested in pharmaceutical R&D, the

30

U.S. gains approximately one human life year. Given the fact that recent estimates for
the value of a U.S. life year range between $100,000 and $160,000 (Cutler and
McClellan, 2001; Murphy and Topel, 2003), the social returns to increased future levels
of industry R&D will almost certainly generate benefits greatly in excess of costs. This is
consistent with research that suggests the United States is currently under investing in
medical and pharmaceutical R&D (Murphy and Topel, 2003)6.

As a result, any

significant change in the pharmaceutical R&D landscape that affects the incentives to
invest in R&D will have important implications for social welfare in the U.S.
Pharmacogenomics, it seems, has the potential to increase the future incentives for
investment in R&D, and this will mean improved access to new pharmaceutical and
biologic innovations for many Americans. Moreover, pharmacogenomics offers the very
real potential for more rapid access to drugs via expedited market launches and higher
probabilities of technical success (especially in the sense that this technology could result
in products being brought to market that otherwise would have been terminated in
development because of severe adverse reactions among a small number of patients).
While there still remain numerous challenges associated with this technology, our review
of the basic economics behind pharmacogenomics suggest that once these challenges
have been surmounted, the future for drug development, both in terms of the financial
awards associated with it, and in terms of the social benefits it will impart, is very
promising.

6

The reasons why there may be a socially suboptimal level (too little) of current pharmaceutical and
medical R&D are beyond the scope of this paper; the interested reader is referred to the edited volume by
Murphy and Topel, “Measuring the Gains from Medical Research”

31

References
Atkinson, T. (2002) The Global Parallel Trade Outlook 2001-2006: A country-by-country
analysis, REUTERS Business Insight, Healthcare, Spring 2002.
Cutler DM and McClellan M (2001) Is technological change in medicine worth it?
Health Affairs. Sept/Oct; pp. 11-29
Giaccotto, C., Santerre, RE, and Vernon, JA (2005) “Drug Prices and R&D Investment
Behavior in the Pharmaceutical Industry” Vol. 48, Issue 1, 195-214 2005. Journal of Law
and Economics.
Danzon, PM and Towse, A. (2002) "The Economics of Gene Therapy and
Pharmacogenetics.. Value in Health 5(1): 5-13, 2002.
DiMasi JA, Hansen RW, Grabowski HG (2003) The price of innovation: new estimates
of drug development costs. Journal of Health Economics. 22:151-185.
Drummond et al. (1997) Methods for the Economic Evaluation of Health Care
Programmes. New York, Oxford University Press.
Eisenberg, J. M. (1989) Clinical Economics: a Guide to the Economic Analysis of
Clinical Practices. Journal of the American Medical Association 262(20): 2879-86
FDA News PO3-89 (2003) http://www.fda.gov/bbs/topics/NEWS/2003/NEW00969.html
(accessed on October 26, 2005).
Golec, JH. and Vernon, JA (2005) “What’s at Stake in Pharmaceutical Reimportation:
The Costs in Terms of Life Years, Lives, and Dollars.” Journal of Law and Public Policy
16:1: 135-149.
Gosling, H. 2000. European Pharmacoeconomics: The Fourth Hurdle, Global
Pharmaceutical Reports, SMi Publishing, 2000
Grabowski HG and Vernon JM (2000) The distribution of sales revenues from
pharmaceutical innovation. Pharmacoeconomics. 18 Suppl. 1: 21-32.
Jommi, C. (2001) Pharmaceutical policy and organisation of the regulatory authorities in
the main EU countries (Collana Cergas, Centro di ricerche sulla gestione dell'
assistenza
sanitaria dell'
Università Bocconi) CERGAS, Egea Publishing.
Lichtenberg FR (2002) Sources of U.S. longevity increase, 1960-1997. National Bureau
of Economic Research, working paper 8755, Cambridge, MA.

32

Mattingly, S (2004) “Really Personal Medicine,” The National Journal of Technology
Commercialization, October-November, p. 26-28.
MayoClinic.com (2005) http://www.mayoclinic.com/health/thalidomide (accessed on
November 2, 2005).
Murphy KM and Topel RH (2003) The economic value of medical research; in
Measuring the gains from medical research; edited by Kevin M. Murphy and Robert H.
Topel, The University of Chicago Press.
Phillips KA, Veenstra DL, Sadee W, Oren E, Lee JK. (2001) "The potential role of
pharmacogenomics in reducing adverse drug reactions: A systematic review". JAMA,
2001: 286 (18): 2270-2279.
Sloan, F. ed. 1995, 2nd edition 1998. Valuing Health Care. Cambridge: Cambridge
University Press.
Vernon JA (2003) “Simulating the impact of price regulation on pharmaceutical
innovation.” Pharmaceutical Development and Regulation. 1(1): 55-65.
Vernon, JA (2005) Examining the Link Between Price Regulation and Pharmaceutical
R&D Investment. 14:1 2005: 1-17. Health Economics.
Vernon, JA, Hughen, WK, Johnson, S, and Trujillo (2005) “Economic and
Developmental Considerations for of Pharmacogenomic Technology” Forthcoming in
PharmacoEconomics
Quintiles Transnational (2004) Cited in “Personalized Medicine: The Emerging
Pharmacogenomics Revolution,” PriceWaterHouseCoopers, Global Technology Center,
Health Research Institute, February 2005.

33

Appendix: A Mathematical Model of Pharmacogenomic (PG) Technology
and its Potential Impact on Drug Development
This appendix describes the mathematical model from which much of our inferences and
conclusions in the paper are derived. We consider, for simplicity, the binary case where a
fraction of a potential patient population carries a genetic marker that signals a higher
therapeutic response to drug therapy. The appendix contains four sub-sections: the prelaunch model, the post-launch model, the NPV model, and a brief analysis of
pharmacogenomic market segmentation.

A.I:

Impact of PG on the Cost and Expediency of Drug Development

The following notation will be used throughout the appendix:

λ = proportion of patients with genetic marker, where λ ∈ [0,1] .

ε = efficacy rate for patients without the genetic marker, where ε ∈ [0,1]
ε + δ = efficacy rate for patients with genetic marker, where δ ∈ [0,1 − ε ] .
E P = pooled efficacy rate: E p = λ (ε + δ ) + (1 − λ )ε = ε + λδ .
∆ t = drug development costs in year t, which have the following fixed and variable cost
components: ∆ t = ∆Ft + ∆Vt .
The pooled efficacy rate is the average efficacy rate over the entire patient
population; it is the efficacy rate that a traditional developmental program would have7.
The fixed cost component, ∆Ft , consists of all costs that are the same for traditional and

7

It is important to recognize that we are now using the subscript ‘p’ (for pooled) to denote the traditional
approach of drug development. We do this in order to reserve the subscript ‘t’ for ‘time’ (which we used in
the paper to denote ‘traditional’) because of its expanded use in our analysis in this appendix.

34

PG development, while the variable cost component, ∆Vt , consists of those costs that are
different for the two developmental programs. The most likely ways the variable drug
development costs may be affected are through clinical trials size requirements and the
time required to conduct the trials, the pharmacogenomic diagnostic test/tool
development costs, and the attrition rate for developmental products.
The size of the clinical trials will be different for the two developmental
programs; the number N P of patients that must be enrolled in the traditional drug
developmental program will be greater than the number N G of patients that must be
enrolled in the PG developmental program. This is because the number of patients
enrolled in a clinical trial must be sufficient for the trial to demonstrate efficacy from a
statistical perspective. This number depends on the true efficacy rate and the well-known
statistical parameters α and β that determine Type I and Type II errors, as discussed in
the paper; as we show below, a higher efficacy rate requires fewer patients to
demonstrate statistical significance.
Assume that a trial is designed to measure the proportion of responders to a new
drug treatment (relative to placebo). Under the Null Hypothesis the difference in the
proportion of responders in the treatment arm and the placebo arm is zero:
H 0 : P2 − P1 = 0
P1 and P2 are the proportions of responders in the placebo and treatment arms,
respectively. For a sufficiently large number N of patients in each arm (N>30), the
clinical trial results will generate a sample statistic, ∆π = π 2 − π 1 , that is normally
distributed with mean zero and standard deviation:

35

σ=

P1 (1 − P1 ) + P2 (1 − P2 )
N

(1)

Under the Alternate Hypothesis the difference in the proportion of responders is:
H A : P2 − P1 = E
To simplify the analysis, we assume that the placebo response rate is 0, i.e., P1 = 0 , so
that the Alternate Hypothesis is that the treatment arm has efficacy rate E. If the Null
Hypothesis were true, then the sample statistic distribution of ∆π would be centered at 0;
if the Alternate Hypothesis were true, then the sample statistic distribution ∆π would be
centered at E. In either case, the standard deviation from Equation (1) is:

σ=

E (1 − E )
N

(2)

For a given probability α of committing a Type I error, and a given probability β of
committing a Type II error, there is a unique value of N determined by the equation:
0 + zα σ = E − z β σ

(3)

Here, zα is the z-value (for the standard normal distribution) corresponding to area α ,
i.e.:
1
2π

zα

e

−x

2

2

dx = 1 − α

−∞

Substituting for σ in Equation (3), and then solving for N gives the formula for the
number of patients required in a clinical trial to show statistical significance at the given

α and β levels:
N=

1
2
− 1 (zα + z β )
E

(4)

36

Note that N is decreasing in the efficacy E , and in each of the probabilities, α and β, as
we might expect. In particular,
NP =

1
1
2
2
− 1 (z α + z β ) >
− 1 (z α + z β ) = N G
ε + λδ
ε +δ

The total clinical trial time, T, under either traditional or PG development, should
be an increasing function of the trial size N; patients must be screened for inclusion
criteria, and the clinical trial itself will most likely take longer to run for more patients.
We assume both the screening time and the trial time are proportional to the square root
of the number of patients. On average, 1 / λ patients must be screened for every patient
with the genetic marker that is included in the trial, and so the number of patients that
must be screened to get N patients enrolled in the trial is N / λ . Under PG development,
there is also the additional time, τ , associated with developing a reliable
pharmacogenomic test or diagnostic. With these assumptions, the total time required to
complete the clinical trials under each developmental programs is:

TP = a N P + b N P = ( a + b ) N P

(5)

TG = a N G λ + b N G + τ

(6)

The use of the square root function captures the idea that there should be economies of
scale at work, so that doubling the size will not double the time, i.e., the clinical trial time
required is a concave down function of the size. We also make the assumption that the
time to screen each patient for inclusion in a trial is much smaller than the time for a
patient to undergo the actual trial: a << b , so that T p ≈ b N p .
For each developmental program, the total cost of conducting the clinical trials
includes the cost of developing the PG diagnostic test (for the PG program), the screening
37

costs, and the costs of running the actual trials. We assume that the unit cost per patient is
constant over time for both the screening and trial phases; therefore, the cost of screening
the patients is proportional to ( N λ )

3/ 2

, while the cost of running the actual trials is

proportional to N 3 / 2 , and furthermore, we assume the unit screening cost, s, is much
smaller than the unit cost, c, of running the actual trial. Finally, we assume the cost of
developing the diagnostic test is also constant over time. With these assumptions, the
total costs of the clinical trials for the two developmental programs are:
∆VP = cN P3 / 2

(7)

∆VG = s ( N G λ )

3/ 2

+ cN G3 / 2 + kτ

(8)

For small values of λ , the search cost becomes very significant, and ∆VP < ∆VG . On the
other hand, for values of λ near 1, N P and N G converge, but if there are positive costs
associated with screening/searching and diagnostic test development, then once again

∆VP < ∆VG . However, if the screening and diagnostic test development costs are not too
large, there will be values of λ for which ∆VP > ∆VG ; the reduction in clinical trial size
under PG development will be large enough to offset the search and test development
costs.
For example, suppose α = 0.05,

β = 0.10, ε = 0.1, δ = 0.15, and c = 1,

s = 0.01, and k = 0 , so that the screening and test development costs are negligible. The
percentage

change

(

)

for

the

variable

costs

under

the

two

development

strategies, ∆VP − ∆VG ∆VP , from Equations (7) and (8), is plotted below in Figure 1 as a
function of the fraction λ , the percentage of patients with the marker. With these

38

parameter values, ∆VP > ∆VG for λ > 0.02 or so; in fact, for λ ≈ 0.15 the variable cost
under PG development is about 70% less than the variable cost under traditional
development. Figure A.1 also shows the percentage change in clinical trial sizes,

(N P − N G )

N P , which were presented in Table 1 of the paper, and which represented

our conservative approximation of the percentage reduction in variable, out-of-pocket
clinical development costs associated with PG.

Figure A.1

Percentage Out-of-pocket Clinical Development Cost Savings from
PG ( ε =.10 and δ =0.15)

80%
70%

Full Model w ith per-unit-time costs,
time, screening and enrollment costs.

60%
50%
40%
30%
20%

Conservative cost model based on
clinical trial size.

10%
0%
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

% of Patients with Genetic Marker

As s and k get larger relative to c, the PG variable cost will increase and the
percentage change in the variable costs will decrease. Indeed, if the screening and
diagnostic test development costs are large enough, then the PG variable cost will always
be greater than the traditional variable cost, for all values of λ . However, in this case, it
may still be possible that the length of time required to bring the drug to market is smaller

39

under PG development. In addition to Figure A.1, we also illustrate the percentage cost
savings from PG (under the current model) for a range of values of δ; we do this using
the three-dimensional surface shown below in Figure A.2.

Figure A.2
Percentage Clinical Development Cost Reduction from PG
(As a Function of λ and δ when ε = 0.10)

0.5
% Cost
Reduction

0
0.1

-0.5
0

δ
0.25

0.05
0.5

λ

0.75
1 0

Per the discussion in the paper, because of the considerable influence that the
opportunity cost of capital has on drug development costs, this could significantly reduce
the costs associated with PG development8. It may also be the case that under PG
development fewer clinical trials are required; we captured this by scaling the unit

8

Of course, it bears reemphasizing, too, that we are not, at present, considering the impact PG will have via
the probability of advancing through clinical development, and thus making it to market.

40

screening and trial costs for PG development by a factor θ < 1 . This will offset these costs
and drive down the variable costs under PG development even further.
The analysis thus far has assumed that all products successfully advance through
the developmental pipeline. However, the vast majority of developmental products don’t
successfully make it to launch because of safety issues or lack of efficacy. If pt is the
probability that a developmental product advances in period t, the fraction of products
n

that successfully make it to launch (which occurs at the end of period n) is ∏ pt . The
t =0

total cost of successfully bringing a drug to launch includes the cost of the failures and
the opportunity cost of a firm’s investment capital; the later, while exerting a significant
influence on costs because of the long development times associated with drug
development, is, from an analysis perspective, trivial, and we assume the firms cost of
capital to be equal to zero for now; thus, the average or expected developmental cost for
each successful product is the following:

E[Cost] per Success =

n −1

n

t =0

t =0

∆ 0 p 0 + ∆1 p 0 p1 + ∆ 2 p 0 p1 p 2 ... + ∆ n −1 ∏ pt +∆ n ∏ p t
n

∏p
t =0

(9)

t

This expected cost decreases as the probability of advancing each period, pt , increases.
This is perhaps most easily seen by rewriting Equation (9) as follows:
E[Cost] per Success =

∆0

+

n

∆1

∏p ∏p
t =1

t

+

n

t =2

t

∆ n −1
+ ∆n ,
pn

and noting that each term in the sum on the right hand side is decreasing in pt .

41

On average, developmental products with higher efficacy or, especially, lower
adverse event rates, are more likely to advance each period. An important benefit of PG
technology is that it may allow for the identification of not only patients who respond
more efficaciously to drug therapy, but also patients who react adversely to the drug
treatment. Thus, PG has the potential to greatly reduce adverse drug event risks, and
thereby increase the number of drugs that make it to market. This would not only reduce
the cost of failures and decrease expected development costs per drug, it would also
benefit patients who react positively to the drug treatment and who without PG would
have been denied access (an important benefit of PG our analysis does not capture!).

A.II:

The Impact of PG on the Drug Revenues
Once the drug has reached the market, revenues will be determined by the number

of patients with the disease, q, and the unit drug price, π , that can be supported in
equilibrium. We assume this equilibrium price is determined by cost-effectiveness
analyses; specifically, payers or consumers are willing to pay a higher price for a drug
treatment that has higher benefits, according to the following relation that was discussed
at length in the paper:

∆C
=Ω
∆E

(10)

In (10), ∆C represents the incremental disease treatment costs with a new technology
(e.g., drug) relative to the standard of care, and ∆E is the incremental efficacy of the new
technology from some baseline treatment (e.g., the current standard of care if one exists;

42

if not, the baseline could be no treatment at all), and Ω is a given threshold that
represents payers’ maximum willingness to pay per unit efficacy.
We assume that baseline is no treatment at all, and that the cost of care for each
patient with the disease has two components: a fixed cost, C F , and a variable cost, C V ;
this variable cost is not incurred if treatment with the drug is successful. Using our
previous notation for efficacy, the increase in treatment cost with a PG development
program and a traditional program (as compared to baseline) are, respectively,

∆CG = π P − C V (ε + δ )
∆C P = π G − C V (ε + λδ )
The increase in efficacy for each program is simply:

∆EG = ε + δ
∆E P = ε + λδ
It follows from Equation (10) that the price that can be supported in equilibrium for each
of the two programs is:

π G = (Ω + C V )(ε + δ )
π P = (Ω + C V )(ε + λδ )
The number of patients receiving treatment is different under the two
developmental programs. Under a traditional developmental program, the number of
patients receiving treatment is q; under a PG program, the number is λq . Thus, the total
revenues are

RG = λq(Ω + C V )(ε + δ )
RP = q(Ω + C V )(ε + λδ )

43

Note that the ratio of PG revenues to traditional revenues is no greater than 1, and it
equals unity if and only if the fraction of patients with the genetic marker is itself equal to
unity:

Φ≡

RG λ (ε + δ )
=
≤1
ε + λδ
RP
Thus, at least within the context of this simple static model, the revenues

generated under a PG development program will never be greater than those generated
under a traditional program. However, we have not taken into account the possibility that
the revenues generated under a PG program may be realized sooner, and would thus have
a higher present value, than those under a traditional program. We address this issue in
the next section.

A.III:

NPV Considerations: PG vs. Traditional Drug Development
To keep the analysis relatively simple, we assume that the fixed development

costs ∆F are incurred at the same time for the two development programs, and that the
variable developmental costs ∆V are incurred, and the revenues R are generated, at the
time of product launch. This particular timing assumption is made for convenience and
amounts to the assumption that the variable costs and the revenues are given in terms of
dollars (capitalized or discounted) as of the time of product launch. This time of product
launch will generally be different for the two programs because of the different screening
and clinical trial times, and the time required to develop the PG diagnostic test, τ . Let

∆T be the difference in launch times for the two programs:

44

∆T = TP − TG = b N P − a N G λ − b N G − τ

(11)

In (11), N P and N G are the numbers of patients required in the clinical trials under the
two programs.
The revenues under the two developmental programs are generated at different
points in time; to compare the two revenues RP and RG we compute the present value of
RP relative to the point in time when RG is generated, i.e., relative to the time of launch
under PG development. For a continuously compounded discount rate r, the discount
factor is simply the exponential of the product of negative r with the difference in launch
times.
Thus, by our timing assumptions, the difference in the net present value at the
time of launch under PG development is:

NPVG − NPVP = RG − ∆VG − e − r∆T ( RP − ∆VP ) = (Φ − e − r∆T ) RP + e − r∆T ∆VP − ∆VG

(12)

This difference is a function of the model parameters ε , δ , λ ,τ , c, s, k , α , β , Ω, C V , q, a, b,
and the appropriate discount rate r.

A.IV: PG Segmentation and Drug Development: What’s Rational?
Suppose the firm could somehow ensure no inter-market arbitrages and sell the
drug to both segments of the market, those with the genetic marker and those without the
marker, separately; and that the price at which the drug is sold in each market segment is
determined by the cost-effectiveness in that segment. The computations in Section A.II of
this Appendix imply that the price π in each segment is:

π = (Ω + C V ) E
45

E is the efficacy rate in that segment ( EG = ε + δ for the segment with the genetic
marker, E nG = ε for the segment without the marker, and E P = ε + λδ for the pooled
population). Because the pooled efficacy rate is the average of the efficacy rates for the
two segments, it follows that the price under traditional development is the average of the
prices for the two segments:

π P = (Ω + C V )(λEG + (1 − λ ) E nG ) = λ (Ω + C V ) EG + (1 − λ )(Ω + C V ) E nG = λπ G + (1 − λ )π nG
Multiplying both sides by the patient population size q, we see that the revenue generated
under traditional development is the sum of the revenues generated in each segment:
RP = qπ P = λqπ G + (1 − λ )qπ nG = RG + RnG
In other words, the revenues generated under the program in which the firm develops the
product separately for each market segment and price discriminates based on the costeffectiveness in each segment are the same as the revenues under a traditional (nonsegmenting) developmental approach.
The developmental costs, however, are likely to be very different. In fact, the
number of patients required to show a statistically significant efficacy among the patients
without the marker is larger than the number required among the pooled population:
because E nG = ε < ε + λδ = E P ,
N nG =

1
1
2
2
− 1 (zα + z β ) >
− 1 (zα + z β ) = N P
E nG
EP

That is, the clinical trials for the non-marker segment will be larger than for the pooled
population, and thus the clinical trial costs for the non-marker segment alone will be
larger than the clinical trial costs for the pooled (traditional) developmental program.
This is even more so the case if there are positive search or screening costs in finding
46

those patients without the marker. Thus, firms won’t rationally choose to follow this
program, and will either follow the traditional approach or one in which it develops the
product only for those patients carrying the genetic marker.

47

