NBER WORKING PAPER SERIES

TESTS OF MUTLIFACTOR PRICING MODELS,
VOLATILITY BOUNDS AND
PORTFOLIO PERFORMANCE
Wayne E. Ferson
Working Paper 9441
http://www.nber.org/papers/w9441
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2003

The author acknowledges financial support from the Collins Chair in Finance at Boston College and the PigottPACCAR professorship at the University of Washington. He is also grateful to George Constantinides and Ludan
Liu for helpful comments and suggestions. The views expressed herein are those of the authors and not
necessarily those of the National Bureau of Economic Research.
©2003 by Wayne E. Ferson. All rights reserved. Short sections of text not to exceed two paragraphs, may be
quoted without explicit permission provided that full credit including . notice, is given to the source.

Tests of Multifactor Pricing Models, Volatility Bounds and Portfolio Performance
Wayne E. Ferson
NBER Working Paper No. 9441
January 2003
JEL No. G000, G110, G120, G140
ABSTRACT
Three concepts: stochastic discount factors, multi-beta pricing and mean variance efficiency, are at the
core of modern empirical asset pricing. This paper reviews these paradigms and the relations among
them, concentrating on conditional asset pricing models where lagged variables serve as instruments
for publicly available information. The different paradigms are associated with different empirical
methods. We review the variance bounds of Hansen and Jagannathan (1991), concentrating on
extensions for conditioning information. Hansen's (1982) Generalized Method of Moments (GMM)
is briefly reviewed as an organizing principle. Then, cross-sectional regression approaches as developed
by Fama and MacBeth (1973) are reviewed and used to interpret empirical factors, such as those
advocated by Fama and French (1993, 1996). Finally, we review the multivariate regression approach,
popularized in the finance literature by Gibbons (1982) and others. A regression approach, with a beta
pricing formulation, and a GMM approach with a stochastic discount factor formulation, may be
considered competing paradigms for empirical work in asset pricing. This discussion clarifies the
relations between the various approaches. Finally, we bring the models and methods together, with a
review of the recent conditional performance evaluation literature, concentrating on mutual funds and
pension funds.

Wayne E. Ferson
Boston College
Carroll School of Management
140 Commonwealth Avenue, 330B
Chestnut Hill, MA 02467
and NBER
wayne.ferson@bc.edu

CONTENTS
I. Introduction
2. Multi-factor Asset Pricing Models: Review and Integration
2.1

The Stochastic Discount Factor Representation
Expected Risk Premiums
Return Predictability

2.2

Consumption-based Asset Pricing Models

2.3

Multi-beta pricing Models
Relation to the Stochastic Discount Factor
Relation to Mean variance efficiency
A "Large Markets" Interpretation

2.4

Mean variance efficiency with conditioning information
Conditional versus Unconditional Efficiency
Implications for Tests

2.5

Choosing the factors

3. Modern Variance Bounds
3.1

The Hansen Jagannathan Bounds

3.2

Variance bounds with conditioning information
Efficient-portfolio bounds
Optimal bounds
Discussion

3.3

The Hansen Jagannathan Distance

4. Methodology and Tests of Multifactor Asset Pricing Models
4.1

The Generalized Method of Moments Approach

4.2

Cross-sectional Regression Methods
The Fama-MacBeth approach
Interpreting the estimates
A Caveat
Errors in Betas

4.3

Multivariate Regression and beta pricing models
Comparing the Beta Pricing and stochastic discount factor approaches

3
5. Conditional Performance Evaluation
5.1

Stochastic Discount Factor formulation
Invariance to the number of funds

5.2

Beta pricing formulation

5.3

Using portfolio weights
Conditional Performance Attribution
Interim Trading Bias

5.4

Conditional market timing models

5.5

Empirical Evidence on Conditional Performance

6. Conclusions

I. Introduction
The asset pricing models of modern finance describe the prices or expected rates of return of financial
assets, which are claims traded in financial markets. Examples of financial assets are common stocks,
bonds, options, futures and other "derivatives," so named because they derive their values from other,
underlying assets. Asset pricing models are based on two central concepts. The first is the no
arbitrage principle, which states that market forces tend to align prices so as to eliminate arbitrage
opportunities. An arbitrage opportunity arises when assets can be combined in a portfolio with zero
cost, no chance of a loss and positive probability of a gain. The second central concept in asset pricing
is financial market equilibrium.

Investors' desired holdings of financial assets derive from an

optimization problem. In equilibrium the first order conditions of the optimization problem must be
satisfied, and asset pricing models follow from these conditions. When the agent considers the
consequences of the investment decision for more than a single period in the future, intertemporal asset
pricing models result.
The present paper reviews multi-factor asset pricing models from an empiricists' perspective.
Multi-factor models can be motivated by either the no arbitrage principle or by an equilibrium model.
Their distinguishing feature is that expected asset returns are determined by a linear combination of
their covariances with variables representing the risk factors. This paper has two main objectives. The
first is to integrate the various empirical models and their tests in a self contained discussion. The
second is to review the application to the problem of measuring investment performance.
This paper concentrates heavily on the role of conditioning information, in the form of lagged
variables that serve as instruments for publicly available information. I think that developments in this
area, conditional asset pricing, represent some of the most significant advances in empirical asset
pricing research in recent years.
The models described in this paper are set in the classical world of perfectly efficient financial

2
markets, and perfectly rational economic agents. Of course, a great deal of research is devoted to
understanding asset prices under market imperfections like information and transactions costs. The
perfect markets models reviewed here represent a baseline, and a starting point for understanding these
more complex issues.
Work in empirical asset pricing over the last few years has provided a markedly improved
understanding of the relations among the various asset-pricing models. Bits and pieces of this are
scattered across a number of published papers, and some is "common" knowledge, shared by
aficionados. This paper provides an integrative discussion, refining the earlier review in Ferson (1995)
to reflect what I hope is an improved understanding.
Much of our understanding of how asset pricing models' empirical predictions are related
flows from representing the models as stochastic discount factors. Section 2 presents the stochastic
discount factor approach, briefly illustrates a few examples of stochastic discount factors, and then
relates the representation to beta pricing and to mean variance efficiency. These three concepts:
stochastic discount factors, beta pricing and mean variance efficiency, are at the core of modern
empirical asset pricing. We show the relation among these three concepts, and a "large-markets"
interpretation of these relations. The discussion then proceeds to refinements of these issues in the
presence of conditioning information. Section 2 ends with a brief discussion of how the risk factors
have been identified in the empirical literature, and what the empirical evidence has to say about the
selection of factors.
Section 3 begins with a fundamental empirical application of the stochastic discount factor
approach - the variance bounds originally developed by Hansen and Jagannathan (1991). Unlike the
case where a model identifies a particular stochastic discount factor, the question in the HansenJagannathan bounds is: Given a set of asset returns, and some conditioning information, what can be

3
said about the set of stochastic discount factors that could properly "price" the assets? By now, a
number of reviews of the original Hansen-Jagannathan bounds are available in the literature. The
discussion here is brief, quickly moving on to focus on less well-known refinements of the bounds to
incorporate conditioning information.
Section 4 discusses empirical methods, starting with Hansen's (1982) Generalized Method of
Moments (GMM). This important approach has also been the subject of several review articles and
textbook chapters. We briefly review the use of the GMM to estimate stochastic discount factor
models. This section is included only to make the latter parts of the paper accessible to a reader who is
not already familiar with the GMM. Section 4 then discusses two special cases that remain important
in empirical asset pricing. The first is the cross-sectional regression approach, as developed by Fama
and MacBeth (1973), and the second is the multivariate regression approach, popularized in the finance
literature following Gibbons (1982).
Once the mainstay of empirical work on asset pricing, cross-sectional regression continues to
be used and useful. Our main focus is on the economic interpretation of the estimates. The discussion
attempts to shed light on recent studies that employ the empirical factors advocated by Fama and
French (1993, 1996), or generalizations of that approach. The multivariate regression approach to
testing portfolio efficiency can be motivated by its immunity to the errors-in-variables problem that
plagues the two step, cross-sectional regression approach. The multivariate approach is also elegant,
and provides a nice intuition for the statistical tests.
A regression approach, with a beta pricing formulation, and a GMM approach with a
stochastic discount factor formulation, may be considered as competing paradigms for empirical work
in asset pricing. However, under the same distributional assumptions, and when the same moments are
estimated, the two approaches are essentially equivalent. The present discussion attempts to clarify

4
these points, and suggests how to think about the choice of empirical method.
Section 5 brings the models and methods together, in a review of the relatively recent
literature on conditional performance evaluation. The problem of measuring the performance of
managed portfolios has been the subject of research for more than 30 years. Traditional measures use
unconditional expected returns, estimated by sample averages, as the baseline. However, if expected
returns and risks vary over time, this may confuse common time-variation in fund risk and market risk
premiums with average performance.

In this way, traditional methods can ascribe abnormal

performance to an investment strategy that trades mechanically, based only on public information.
Conditional performance evaluation attempts to control these biases, while delivering potentially more
powerful performance measures, by using lagged instruments to control for time-varying expectations.
Section 5 reviews the main models for conditional performance evaluation, and includes a summary of
the empirical evidence. Finally, Section 6 of this paper offers concluding remarks.

2. Multifactor Asset Pricing Models: Review and Integration
2.1 The Stochastic Discount Factor Representation
Virtually all asset pricing models are special cases of the fundamental equation:

Pt = Et {mt+1 (Pt+1 + Dt+1)},

(1)

where Pt is the price of the asset at time t and Dt+1 is the amount of any dividends, interest or other
payments received at time t+1. The market-wide random variable mt+1 is the stochastic discount factor
(SDF).1 The prices are obtained by "discounting" the payoffs using the SDF, or multiplying by mt+1, so
1

The random variable mt+1 is also known as the pricing kernel, benchmark pricing variable, or

5
that the expected "present value" of the payoff is equal to the price.
The notation Et{.} denotes the conditional expectation, given a market-wide information set,
Ωt. Since empiricists don't get to see Ωt, it will be convenient to consider expectations conditioned on
an observable subset of instruments, Zt. These expectations are denoted as E(.|Zt). When Zt is the null
information set, we have the unconditional expectation, denoted as E(.). Empirical work on asset
pricing models like (1) typically relies on rational expectations, interpreted as the assumption that the
expectation terms in the model are mathematical conditional expectations. Taking the expected values
of equation (1), rational expectations implies that versions of (1) must hold for the expectations E(.|Zt)
and E(.).
Assuming nonzero prices, equation (1) is equivalent to:

E(mt+1 Rt+1 - 1 |Ωt)=0,

(2)

where Rt+1 is the N-vector of primitive asset gross returns and 1 is an N-vector of ones. The gross
return Ri,t+1 is defined as (Pi,t+1 + Di,t+1)/Pi,t. We say that a SDF "prices" the assets if equations (1) and
(2) are satisfied. Empirical tests of asset pricing models often work directly with equation (2) and the
relevant definition of mt+1.
Without more structure the equations (1-2) have no content because it is almost always
possible to find a random variable mt+1 for which the equations hold. There will be some mt+1 that
"works," in this sense, as long as there are no redundant asset returns.2 With the restriction that mt+1 is

intertemporal marginal rate of substitution, depending on the context. The representation (1) goes at
least back to Beja (1971), while the term "stochastic discount factor" is usually ascribed to Hansen and
Richard (1987).
2

For example, take a sample of assets with a nonsingular second moment matrix and let mt+1 be

6
a strictly positive random variable, equation (1) becomes equivalent to the no arbitrage principle, which
says that all portfolios of assets with payoffs that can never be negative, but which are positive with
positive probability, must have positive prices [Beja (1971), Rubinstein (1976), Ross (1977), Harrison
and Kreps (1979), Hansen and Richard (1987)].
The no arbitrage condition does not uniquely identify mt+1 unless markets are complete. In that
case, mt+1 is equal to primitive state prices divided by state probabilities. To see this write equation (1)
as Pi,t = Et{mt+1Xi,t+1}, where Xi,t+1 = Pi,t+1 + Di,t+1. In a discrete-state setting, Pit = ΣsπsXi,s =
Σsqs(πs/qs)Xi,s, where qs is the probability that state s will occur and πs is the state price, equal to the
value at time t of one unit of the numeraire to be paid at time t+1 if state s occurs at time t+1. Xi,s is the
total payoff of the security i at time t+1 if state s occurs. Comparing this expression with equation (1)
shows that ms = πs/qs > 0 is the value of the SDF in state s.
While the no arbitrage principle places some restrictions on mt+1, empirical work typically
explores the implications of equilibrium models for the SDF, based on investor optimization. Consider
the Bellman equation for a representative consumer-investor's optimization:

J(Wt,st) ≡ Max Et{ U(Ct,.) + J(Wt+1,st+1)},

(3)

where U(Ct,.) is the direct utility of consumption expenditures at time t, and J(.) is the indirect utility of
wealth. The notation allows the direct utility of current consumption expenditures to depend on
variables such as past consumption expenditures or other state variables, st. The state variables are
sufficient statistics, given wealth, for the utility of future wealth in an optimal consumption-investment
plan. Thus, changes in the state variables represent future consumption-investment opportunity risk.
[1' (Et{Rt+1Rt+1'})-1]Rt+1.

7
The budget constraint is: Wt+1 = (Wt - Ct) x'Rt+1, where x is the portfolio weight vector, subject to x'1 =
1.
If the allocation of resources to consumption and investment assets is optimal, it is not
possible to obtain higher utility by changing the allocation. Suppose an investor considers reducing
consumption at time t to purchase more of (any) asset. The expected utility cost at time t of the
foregone consumption is the expected marginal utility of consumption expenditures, Uc(Ct,.) > 0
(where a subscript denotes partial derivative), multiplied by the price Pi,t of the asset, measured in the
numeraire unit. The expected utility gain of selling the investment asset and consuming the proceeds at
time t+1 is Et{(Pi,t+1+Di,t+1) Jw(Wt+1,st+1)}. If the allocation maximizes expected utility, the following
must hold: Pi,t Et{Uc(Ct,.)} = Et{(Pi,t+1+Di,t+1) Jw(Wt+1,st+1)}, which is equivalent to equation (1), with

mt+1 = Jw(Wt+1,st+1)/Et{Uc(Ct,.)}.

(4)

The mt+1 in equation (4) is the intertemporal marginal rate of substitution (IMRS) of the consumerinvestor, and equations (2) and (4) combined are the intertemporal Euler equation.
Asset pricing models typically focus on the relation of security returns to aggregate quantities.
To get there, it is necessary to aggregate the Euler equations of individuals to obtain equilibrium
expressions in terms of aggregate quantities. Theoretical conditions which justify the use of aggregate
quantities are discussed by Wilson (1968), Rubinstein (1974) and Constantinides (1982), among others.
Some recent empirical work does not assume aggregation, but relies on panels of disaggregated data.
Examples include Zeldes (1989), Brav, Constantinides and Geczy (2002) and Balduzzi and Yao
(2001).
Multiple factor models for asset pricing follow when mt+1 can be written as a function of

8
several factors. Equation (4) suggests that likely candidates for the factors are variables that proxy for
consumer wealth, consumption expenditures or the state variables -- the sufficient statistics for the
marginal utility of future wealth in an optimal consumption-investment plan.

Expected Risk Premiums
Typically, empirical work focuses on expressions for expected returns and excess rates of
return. Expected excess returns are related to the risk factors that create variation in mt+1. Consider any
asset return Ri,t+1 and a reference asset return, R0,t+1. Define the excess return of asset i, relative to the
reference asset as ri,t+1 = Ri,t+1 - R0,t+1. If equation (2) holds for both assets it implies:

Et{mt+1 ri,t+1} = 0 for all i.

(5)

Use the definition of covariance to expand equation (5) into the product of expectations plus the
covariance, obtaining:

Et{ri,t+1} = Covt(ri,t+1; -mt+1) / Et{mt+1}, for all i,

(6)

where Covt(.;.) is the conditional covariance. Equation (6) is a general expression for the expected
excess return, from which most of the expressions in the literature can be derived. The conditional
covariance of return with the SDF, mt+1, is a very general measure of systematic risk. Asset pricing
models say that assets earn expected return premiums for their systematic risk, not their total risk (i.e.,
variance of return). The covariance with -mt+1 is systematic risk because it measures the component of
the return that contributes to fluctuations in the marginal utility of wealth. If we regressed the asset

9
return on the SDF, the residual in the regression would capture the "unsystematic" risk and would not
be "priced," or command a risk premium.
If the conditional covariance with the SDF is zero for a particular asset, the expected excess
return of that asset should be zero.3 The more negative is the covariance with mt+1 the less desireable is
the distribution of the random return, as the larger payoffs tend to occur when the marginal utility is
low. The expected compensation for holding assets with this feature must be higher than for those with
a more desireable distribution. Expected risk premiums should therefore differ across assets in
proportion to their conditional covariances with -mt+1.

Return Predictability
Rational expectations implies that the difference between return realizations and the
expectations in the model should be unrelated to the information that the expectations in the model are
conditioned on. For example, equation (2) says that the conditional expectation of the product of mt+1
and Ri,t+1 is the constant, 1.0. Therefore, 1-mt+1Ri,t+1 should not be predictably different from zero using
any information available at time t. If we run a regression of 1-mt+1Ri,t+1 on any lagged variable, Zt, the
regression coefficients should be zero. If there is predictability in a return Ri,t+1 using instruments Zt, the
model implies that the predictability is removed when Ri,t+1 is multiplied by the correct mt+1. This is the
sense in which conditional asset pricing models are asked to "explain" predictable variation in asset
returns. This view generalizes the older "random walk" model of stock values, which states that stock
returns should be completely unpredictable. That model is a special case which can be motivated by
3

Equation (6) is weaker than equation (2), since equation (6) is equivalent to Et{mt+1Ri,t+1} = ∆t, all i,
where ∆t is a constant across assets, while equation (2) restricts ∆t=1. Therefore, empirical tests based
on equation (6) do not exploit all of the restrictions implied by a model that may be stated in the form
of equation (2).

10
risk neutrality. Under risk neutrality the IMRS, mt+1, is a constant. Therefore, in this case the model
implies that the return Ri,t+1 should not differ predictably from a constant.
Conditional asset pricing presumes the existence of some return predictability. There should
be instruments Zt for which E(Rt+1|Zt) or E(mt+1|Zt) vary over time, in order for the equation E(mt+1Rt+11|Zt)=0 to have empirical bite.4 Interest in predicting security market returns is about as old as the
security markets themselves. Fama (1970) reviews the early evidence.
One body of literature uses lagged returns to predict future stock returns, attempting to exploit
serial dependence. High frequency serial dependence, such as daily or intra-day patterns, are often
considered to represent the effects of market microstructure, such as bid-ask spreads (e.g. Roll, 1984)
and nonsynchronous trading of the stocks in an index (e.g. Scholes and Williams, 1977). Serial
dependence at longer horizons may represent predictable changes in the expected returns.
Conrad and Kaul (1989) report serial dependence in weekly returns. Jegadeesh and Titman
(1993) find that relatively high return, "winner" stocks tend to repeat their performance over three to
nine-month horizons. DeBondt and Thaler (1985) find that past high-return stocks perform poorly over
the next five years, and Fama and French (1988) find negative serial dependence over two to five-year
horizons. These serial dependence patterns motivate a large number of studies which attempt to assess
the economic magnitude and statistical robustness of the implied predictability, or to explain the
predictability as an economic phenomenon. For more comprehensive reviews, see Campbell, Lo and
MacKinlay (1997) or Kaul (1996). Research in this area continues, and its fair to say that the jury is
still out on the issue of predictability using lagged returns.
4

At one level this is easy. Since E(mt+1|Zt) should be the inverse of a risk-free return, all we need is
observable risk free rates that vary over time. Ferson (1989) shows that the behavior of stock returns
and short term interest rates imply that conditional covariances of returns with mt+1 must also vary over
time.

11
A second body of literature studies predictability using other lagged variables as instruments.
Fama and French (1989) assemble a list of variables from studies in the early 1980's, that as of this
writing remain the workhorse instruments for conditional asset pricing models. These variables include
the lagged dividend yield of a stock market index, a yield spread of long-term government bonds
relative to short term bonds, and a yield spread of low-grade (high default risk) corporate bonds over
high-grade bonds. In addition, studies often include the level of a short term interest rate (Fama and
Schwert (1977), Ferson, 1989) and the lagged excess return of a medium-term over a short-term
Treasury bill (Campbell (1987), Ferson and Harvey, 1991). Recently proposed instruments include an
aggregate book-to-market ratio (Pontiff and Schall, 1998) and lagged consumption-to-wealth ratios
(Lettau and Ludvigson, 2000). Of course, many other predictor variables have been proposed and more
will doubtless be proposed in the future.
Predictability using lagged instruments remains controversial, and there are some good
reasons the question the predictability. Studies have identified various statistical biases in predictive
regressions (e.g. Hansen and Hodrick (1980), Stambaugh (1999), Ferson, Sarkissian and Simin, 2002),
questioned the stability of the predictive relations across economic regimes (e.g. Kim, Nelson and
Startz, 1991) and raised the possibility that the lagged instruments arise solely through data mining (e.g.
Campbell, Lo and MacKinlay (1990), Foster, Smith and Whaley, 1997).
A reasonable response to these concerns is to see if the predictive relations hold out-ofsample. This kind of evidence is also mixed. Some studies find support for predictability in step-ahead
or out-of-sample exercises (e.g. Fama and French (1989), Pesaran and Timmerman, 1995). Similar
instruments show some ability to predict returns outside the U.S. context, where they arose (e.g. Harvey
(1991), Solnik (1993), Ferson and Harvey, 1993, 1999).

However, other studies conclude that

predictability using the standard lagged instruments does not hold (e.g. Goyal and Welch (1999),

12
Simin, 2002). It seems that research on the predictability of security returns will always be interesting,
and conditional asset pricing models should be useful in framing many future investigations of these
issues.

2.2 Consumption-based Asset Pricing Models
In these models the economic agent maximizes a lifetime utility function of consumption
(including possibly a bequest to heirs). Consumption models may be derived from equation (4) by
exploiting the envelope condition, Uc(.) = Jw(.), which states that the marginal utility of consumption
must be equal to the marginal utility of wealth if the consumer has optimized the tradeoff between the
amount consumed and the amount invested.
Breeden (1979) derived a consumption-based asset pricing model in continuous time,
assuming that the preferences are time-additive.

The utility function for the lifetime stream of

consumption is Σt βtU(Ct), where β is a time preference parameter and U(.) is increasing and concave
in current consumption, Ct. Breeden's model is a linearization of equation (2) which follows from the
assumption that asset values and consumption follow diffusion processes [Bhattacharya (1981),
Grossman and Shiller (1982)]. A discrete-time version follows Rubinstein (1976) and Lucas (1978),
assuming a power utility function:
C 1−α − 1
U (C ) =
,
1−α

(7)

where α > 0 is the concavity parameter. This function displays constant relative risk aversion5 equal to
α. Using (7) and the envelope condition, the IMRS in equation (4) becomes:
5

Relative risk aversion in consumption is defined as -Cu''(C)/u'(C). Absolute risk aversion is u''(C)/u'(C). Ferson (1983) studies a consumption-based asset pricing model with constant absolute risk
aversion.

13

mt+1 = β(Ct+1/Ct)-α.

(8)

A large literature has tested the pricing equation (1), with the SDF given by the consumption model (8),
and generalizations of that model.6

2.3 Multi-beta Pricing Models
The vast majority of the empirical work on asset pricing models involves expressions for
expected returns, stated in terms of beta coefficients relative to one or more portfolios or factors. The
beta is the regression coefficient of the asset return on the factor. Multi-beta models have more than
one risk factor and more than one beta for each asset. The Arbitrage Pricing Theory (APT) leads to
approximate expressions for expected returns with multiple beta coefficients.

Models based on

investor optimization and equilibrium lead to exact expressions.7 Both of these approaches lead to
models with the following form:
K

Et ( Ri ,t +1 ) = λ0t + ∑ bijt λ jt , for all i.

(9)

j =1

The bi1t,..., biKt are the time t betas of asset i relative to the K risk factors Fj,t+1, j=1,..,K. These betas

6

An important generalization allows for nonseparabilities in the Uc(Ct,.) function in (4), as may be
implied by the durability of consumer goods, habit persistence in the preferences for consumption over
time, or nonseparability of preferences across states of nature. Singleton (1990), Ferson (1995) and
Campbell, in Chapter 19 of this volume, review this literature.
7

The multiple-beta equilibrium model was developed in continuous time by Merton (1973), Breeden
(1979) and Cox, Ingersoll and Ross (1985). Long (1974), Sharpe (1977), Cragg and Malkiel (1982),
Connor (1984), Dybvig (1983), Grinblatt and Titman (1983) and Shanken (1987) provide multibeta
interpretations of equilibrium models in discrete time.

14
are the conditional multiple regression coefficients of the assets on the factors. The λ j,t , j=1,...,K are
the factor risk premiums, which represent increments to the expected return per unit of type-j beta.
These premiums do not depend on the specific security i. λ0,t is the expected zero-beta rate. This is
the expected return of any security that is uncorrelated with each of the K factors in the model (i.e., b0jt
= 0, j=1,...,K). If there is a risk-free asset, then λ0,t is the return of this asset.

Relation to the Stochastic Discount Factor
We first show how a multi-beta model can be derived as a special case of the SDF
representation, when the factors capture the relevant systematic risks. We take this to mean that the
error terms, ui,t+1, in a regression of returns on the factors are not "priced;" that is, they are uncorrelated
with mt+1: Covt(ui,t+1,mt+1)=0. We then state the general equivalence between the two representations.
This equivalence was first discussed, for the case of a single-factor model, by Dybvig and Ingersoll
(1982). The general, multi-factor case follows from Ferson and Jagannathan (1996).
Let R0,t+1 be a zero beta portfolio, and λ0,t the expected return on the zero beta portfolio.
Equation (6) implies:

Et(Ri,t+1) = λ0,t + Covt(Ri,t+1; -mt+1)/Et(mt+1).

(10)

Substituting the regression model Ri,t+1 = ai + Σj bijt Fj,t + ui,t+1 into the right hand side of (10) and
assuming that Covt(ui,t+1,mt+1)=0 implies:

Et(Ri,t+1) = λ0,t + Σj=1,...K bijt [ Covt{Fj,t+1, -mt+1 }/Et(mt+1) ],

(11)

15
-wide risk premium per unit of type-j beta is λ j,t = [Covt{Fj,t+1, -mt+1}/Et(mt+1)]. In the special case
where the factor Fj,t+1 is a traded asset return, equation (11) implies that λ j,t =Et(Fj,t+1)- λ0,t ; the
expected risk premium equals the factor portfolio's expected excess return.
Equation (11) is useful because it provides intuition about the signs and magnitudes of
expected risk premiums for particular factors. The intuition is the same as in equation (6) above. If a
risk factor Fj,t+1 is negatively-correlated with mt+1, the model implies that a positive risk premium is
associated with that factor beta. A factor that is positively-related to marginal utility should carry a
negative premium, because the big payoffs come when the value of payoffs is high. This implies a high
present value and a low expected return. Expected risk premiums for a factor should also change over
time if the conditional covariances of the factor with the scaled marginal utility [mt+1/Et(mt+1)] vary
over time.
The steps that take us from (6) to (11) can be reversed, so the SDF and multi-beta
representations are, in fact, equivalent. The formal statement is:

Lemma 1 (Ferson and Jagannathan, 1996): The stochastic discount factor representation
(2) and the multi-beta model (9) are equivalent,
where, mt+1 = c0t + c1t F1t+1 +...+ cKt FKt+1,
with

c0t = [ 1 + Σ k { λ k Et(Fk,t+1)/Vart(Fk,t+1)} ]/ λ0,t ,

and

cjt = - { λ j ,t / λ0,t Vart(Fj,t+1)}, j=1,...,K.

(12)

For a proof, see Ferson and Jagannathan (1996).
If the factors are not traded asset returns, then it is typically necessary to estimate the expected
risk premiums for the factors, λ k ,t . These may be identified as the conditional expected excess returns
on factor-mimicking portfolios. A factor-mimicking portfolio is defined as a portfolio whose return can

16
be used in place of a factor in the model. There are several ways to obtain mimicking portfolios, as
described in more detail below.8

Relation to Mean variance Efficiency
The concept of a minimum variance portfolio is central in the asset pricing literature. A
portfolio Rp,t+1 is a minimum variance portfolio if no portfolio with the same expected return has a
smaller variance. Roll (1977) and others have shown that the portfolio Rp,t+1 is a minimum variance
portfolio if and only if a beta pricing model holds:9

Et{Ri,t+1-Rpz,t+1} = βipt Et{Rp,t+1-Rpz,t+1}, all i;

(13)

βipt = [Covt(Ri,t+1; Rp,t+1) /Vart(Rp,t+1)].

In equation (13), βipt is the conditional beta of Ri,t+1 relative to Rp,t+1. Rpz,t+1 is a zero beta asset relative
to Rp,t+1. A zero beta asset satisfies Covt(Rpz,t+1; Rp,t+1)=0. Equation (13) is essentially a restatement of
the first order condition for the optimization problem that defines a minimum variance portfolio.
Equation (13) first appeared as an asset pricing model in the famous Capital Asset Pricing
Model (CAPM) of Sharpe (1964) and Lintner (1965). The CAPM is equivalent to the statement that
the market portfolio Rm,t+1 is mean variance efficient. The market portfolio is the portfolio of all
8

Breeden (1979, footnote 7) derives maximum correlation mimicking portfolios. Grinblatt and Titman
(1987), Shanken (1987), Lehmann and Modest (1988), and Huberman, Kandel and Stambaugh (1987)
provide further characterizations of mimicking portfolios when there is no conditioning information.
Ferson and Siegel (2002b) and Ferson, Siegel and Xu (2002) consider cases where there is conditioning
information.
9

It is assumed that the portfolio Rp,t+1 is not the global minimum variance portfolio; that is, the
minimum variance over all levels of expected return. This is because the betas of all assets on the
global minimum variance portfolio are the identical.

17
marketed assets, weighted according to their relative total values. The portfolio is mean variance
efficient if it satisfies equation (13), and also Et(Rm,t+1-Rmz,t+1)>0.
When the factors are traded assets like a market portfolio, or when mimicking portfolios are
used, the multi-beta model in equation (9) is equivalent to the statement that a combination of the factor
portfolios is minimum variance efficient.10 Therefore, multiple beta asset pricing models like (9)
always imply that combinations of particular portfolios are minimum variance efficient.

This

correspondence is exploited by Gibbons, Ross and Shanken (1989) and Kandel and Stambaugh (1989),
among others, to develop tests of multi-beta models based on mean variance efficiency. Such tests are
discussed in Section 4 below.
Since the SDF representation in (2) is equivalent to a multi-beta expression for expected
returns, and a multi-beta model is equivalent to a statement about minimum variance efficiency, it
follows that the SDF representation is equivalent to a statement about minimum variance efficiency.
Let’s now complete the loop.

Lemma 2: A portfolio which maximizes squared (conditional) correlation with mt+1 in
equation (2) is a minimum (conditional) variance portfolio.

Proof: Consider the conditional projection of mt+1 on the vector of returns Rt+1. The coefficient vector
is wt ≡ (Et(Rt+1R't+1))-1 Et(Rt+1mt+1) = (Et(Rt+1R't+1))-1 1. Define the portfolio return Rp,t+1 = (wt/wt'1)'Rt+1.
The portfolio maximizes the squared conditional correlation with mt+1. The regression of mt+1 on the
vector of returns can be written as mt+1 = (wt'1)Rp,t+1 + εt+1. The error term εt+1 is conditionally
10

This result is proved by Grinblatt and Titman (1987), Shanken (1987), and Huberman, Kandel and
Stambaugh (1987), and reviewed by Ferson (1995).

18
uncorrelated with Ri,t+1 for all i, and therefore with Rp,t+1.11 Substituting for mt+1 in equation (6) from
this regression produces:

Et{ri,t+1} = [Covt(ri,t+1; Rp,t+1) /Covt(rp,t+1; Rp,t+1)] Et{rp,t+1}, all i,

(14)

where ri,t+1 and rp,t+1 are excess returns. If the reference asset for the excess returns is taken to be Rpz,t+1,
a zero beta asset for Rp,t+1, then equation (13) follows directly from (14). Equation (13) implies that
Rp,t+1 is a conditional minimum variance portfolio. QED.
We have seen that exact multibeta pricing is equivalent to the statement that E(mRi)=1 for all
i, under the assumption that m is a linear function of the factors, and also equivalent to the statement
that a portfolios of the factors is a minimum variance efficient portfolio. Thus, we have equivalence
among the three paradigms: Exact multibeta pricing, stochastic discount factors, and mean variance
efficiency.

A Large-Markets Interpretation
This section describes how the three paradigms of empirical asset pricing work in the large
markets of the Arbitrage Pricing Theory (APT) of Ross (1976), as refined by Chamberlain (1983) and
Chamberlain and Rothschild (1983). For this purpose, we ignore the existence of any "conditioning
information," and suppress the time subscripts and related notation. (For arbitrage pricing relations
with conditioning information, see Stambaugh, 1983).
11

The fitted values of the regression will have the same pricing implications as mt+1. That is,
m*t+1=(wt'1)Rp,t+1 can replace mt+1 in equation (1). Note that when the covariance matrix of asset returns
is nonsingular, m*t+1 is the unique SDF (i.e. satisfies (1)) which is also an asset return. An SDF which
satisfies (1) is not in general an asset return, nor is it unique, unless markets are complete. If markets
are complete, m*t+1 is perfectly correlated with mt+1 [Hansen and Richard (1987)].

19
Assume that the following data generating model describes equity returns in excess of a riskfree asset:

ri = E(ri) + βi'f + ei,

(15)

where E(f) = 0 = E(eif), all i, and ft = Ft - E(Ft) are the unexpected factor returns. We can normalize the
factors to have the identity as their covariance matrix; the βi absorb the normalization. The N x N
covariance matrix of the asset return residuals can then be expressed as:

Cov(R) ≡ Σ = BB’+V,

(16)

where V is the covariance matrix of the residual vector, e, B is the N x K matrix of the βi, and Σ is
assumed to be nonsingular for all N. The factor model assumes that the eigenvalues of V are bounded
as N -> ∞, while the K nonzero eigenvalues of BB' become infinite as N -> ∞. Thus, the covariance
matrix Σ has K unbounded and N-K bounded eigenvalues as N becomes large. This is called an
"approximate factor structure," to distinguish it from an "exact" factor structure, where V is assumed to
be diagonal.
The factor model in (16) decomposes the variances of returns into "pervasive" and
"nonsystematic" risks. If x is an N-vector of portfolio weights, the portfolio variance is x'Σx, where
λmax(Σ) x’x ≥ x’Σ x ≥ λmin(Σ) x’x, λmin(Σ) being the smallest eigenvalue of Σ and λmax(Σ) being the

largest. Following Chamberlain (1983), a portfolio is "well diversified" iff x'x -> 0 as N grows without
bound. For example, an equally weighted portfolio is well diversified; in this case x'x = (1/N) -> 0.
The bounded eigenvalues of V imply that V captures the component of portfolio risk that is not

20
pervasive or systematic, in the sense that this part of the variance vanishes in a well diversified
portfolio. The exploding eigenvalues of BB' imply that the common factor risks are pervasive, in the
sense that they remain in a large, well-diversified portfolio.
The arbitrage pricing theory of Ross (1976) asserts that α’α < ∞ as N grows without bound,
where α is the N vector of "alphas," or expected abnormal returns, measured as the differences between
the left and right hand sides of equation (9), using the APT factors in the multi-beta model. The alphas
are the differences between the assets' expected returns and the returns predicted by the multi-beta
model, sometimes called the "pricing errors." The Ross's APT implies that the multi-beta model's
pricing errors are "small," on average, in a large market. If α’α < ∞ as N grows, then the cross-asset
average of the squared pricing errors, (α'α)/N, must go to zero as N grows.
To see how the approximate beta pricing of the APT relates to the other paradigms of
empirical asset pricing, we first describe how the pricing errors in the beta pricing model are related to
those of a stochastic discount factor representation. If we define αm = E(mR - 1), where m is linear in
the APT factors, then it follows from equations (10) and (11) that αm = E(m) α; the beta pricing and
stochastic discount factor alphas are proportional, where the risk free rate determines the constant of
proportionality. Provided that the risk-free rate is bounded above -100%, then E(m) is bounded, and
α'α is bounded above if and only if αm'αm is bounded above. Thus, the Ross APT has the same
implications for the pricing errors in the stochastic discount factor and beta pricing paradigms.
The third paradigm is mean variance efficiency. We know that a combination of the APT
factors is minimum variance efficient, if and only if α=0. Thus, under the Ross APT a combination of
the factors is not minimum variance efficient. However, an upper bound on α’α implies a lower bound
on the correlation between a minimum variance combination of the factors and a minimum variance
efficient portfolio.

21
To see how the Ross APT restricts the correlation between the factors and a minimum
variance efficient portfolio, we need two facts. The first is the "law of conservation of squared Sharpe
ratios," developed as equation (54) below. Here we state the law as S2(r) = α'Σ-1α + S2(f), where S2(f) is
the maximum squared Sharpe ratio that can be obtained by a portfolio of the factors12, S2(r) is the
squared Sharpe ratio of a minimum variance efficient portfolio using all of the assets, and Σ is the
covariance matrix of the assets's excess returns. The second fact, which follows from equation (49),
relates the correlation, ρ, between the minimum variance efficient portfolio of the factors with the
minimum variance efficient portfolios that uses all of the assets: ρ = S(f)/S(r). Combining these
results, S2(r) - S2(f) = α'Σ-1α ≤ α'α λmax(Σ-1) = α'α / λmin(Σ). Substituting for S(r) in terms of ρ and S(f),
we arrive at: [1/ρ2 -1] ≤ α’α /[λmin(Σ) S2(f)]. Thus, an upper bound on α'α places a lower bound on the
squared correlation between the minimum variance factor portfolio and a minimum variance efficient
portfolio of the assets.
The "exact" version of the APT asserts that α'α -> 0 as N grows without bound, thus, the
pricing errors of all assets go to zero as the market gets large. This version of the model requires
stronger economic assumptions, as described by Connor (1982). Chamberlain (1983) shows that the
exact APT is equivalent to the statement that all minimum variance portfolios are well-diversified, and
are thus combinations of the APT factors. In this case, we are essentially back to the original
equivalence between the three paradigms holding as N gets large. That is, we have E(mR - 1) = 0 if
and only if α=0 when m is linear in the APT factors, and equivalently, a combination of the factors is a
minimum variance efficient portfolio in the large market.

2.4 Mean variance Efficiency with Conditioning Information
12

The Sharpe ratio is the expected excess return divided by the standard deviation.

22
Most asset pricing models are stated in terms of expected asset returns, covariances and betas,
conditional on the available public information at time t. However, empirical tests traditionally
examine unconditional expected returns and betas, or use instruments that are a subset of the available
public information. Given the equivalence between mean variance efficiency and the other asset
pricing representations, it follows that all tests of asset pricing models using portfolios, have examined
whether particular portfolios are either unconditionally minimum variance, or minimum variance
conditional on a subset of the information. To understand how such tests are related to the theories we
need to examine different concepts of efficiency when there is conditioning information.
When there is conditioning information, minimum variance efficiency may be defined in
terms of the conditional means and variances (conditionally efficient), or in terms of unconditional
moments. When the objective is to minimize the unconditional variance for a given unconditional
mean, but where portfolio strategies may be functions of the information, we have (unconditional)
minimum variance efficiency with respect to the conditioning information.
Unconditional efficiency with respect to conditioning information may seem confusing
because conditioning information may be employed by the portfolio, but unconditional expectations
about that portfolio's returns are used to define efficiency. However, this information structure is
actually quite common. Often the agent conducting a portfolio optimization uses more information
than is available to the observer of the outcomes. If the observer does not have the conditioning
information, he or she can only form unconditional, or less informed, expectations.
Dybvig and Ross (1985) provide an example. Consider a portfolio manager who is evaluated
based on the unconditional mean and variance of the portfolio return.

The manager may use

conditioning information about future returns in forming the portfolio. They show that the manager's
conditionally efficient portfolio will typically not appear efficient to the uninformed investor. The

23
portfolio that maximizes the manager's measured performance in this setting is the unconditionally
efficient portfolio with respect to the information.
Ferson and Siegel (2001) derive efficient portfolio strategies with respect to conditioning
information and illustrate their properties. Consider an example with two assets: a riskless asset (with
gross rate of return Rf) and a risky asset with gross return, R. The risky asset's return is written as:

R = Rf + µ(Z) + ε,

(17)

where µ(Z) = E(R-Rf|Z). The conditional variance of the return given Z, is Σ(Z). The problem to be
solved is:
Minx(Z) Var{x(Z)'R} subject to: µp = Rf + E{x(Z)'[R-Rf]}.

(18)

The weight function x(Z) specifies the fraction invested in the risky asset, as a function of the
conditioning information, Z. Here we provide a constructive derivation.13 Let Λ(Z)-1= E{(R - Rf)2|Z}
= Σ(Z) + µ(Z)2 and write the Lagrangian:

L(x|Z) = E{ x(Z)'Λ(Z)-1x(Z) - 2λ[x(Z)'µ(Z) - (µp - Rf)] }.

(19)

Let ŵ (Z) = x(Z) + a y(Z), where y(Z) is any function and x(Z) is the optimal solution. If we consider

13

Thanks to Ludan Liu.

24
L( ŵ (Z)|Z) = L(x(Z) + a y(Z)|Z), then optimality of x(Z) requires ∂L/∂a|a=0 = 0 = E[ {x(Z)'Λ(Z)-1-1

λµ(Z)} y(Z)]=0. Since this must hold for all functions y(Z), it implies x(Z)'Λ(Z) - λµ(Z) = 0. Solving

for x(Z) and evaluating λ by substituting the solution back into the constraint that E{x(Z)'µ(Z)} = (µp Rf) gives the solution for the unconditionally mean-variance efficient strategy with respect to the
information, Z:
x( Z ) =

where

ζ −1 ( µ P − R f ) µ ( Z )
[ µ ( Z )]2 + Σ( Z ),

ζ = E {µ(Z)2 /[µ(Z)2 +Σ(Z)]}.

(20)

(21)

The minimized variance implied by this solution is:
σp2 = (µp - Rf)2 (1 - ζ)/ζ

(22)

Figure 1 gives an empirical example of the optimal weight as a function of the conditional
expected excess return µ(Z), for a given unconditional mean µp, equal to 11.1% per year. This figure
matches the Standard and Poors 500 stock index return for the 1963-1994 sample period. The example
assumes homoskedasticity, where Σ(Z) is a constant. The weight is shown for several values of R2,
defined as the ratio of the variance of the conditional mean to the variance of the stock index return. As
R2 approaches zero the weight becomes a constant function.
When the conditional expected excess return of the risky asset is zero, the weight in the risky
asset is zero. For conditional expected excess returns near zero, the efficient weight appears monotone
and nearly linear in µ(Z). This is similar to other utility-maximizing strategies. For example, assuming

25
a normal distribution the strategy that maximizes an exponential utility is linear in the conditional
expected return. Kim and Omberg (1996) and Campbell and Viceira (1999) solve intertemporal
portfolio problems and find that the portfolio weights are approximately linear in the state variables.
Thus, traditional solutions to the portfolio optimization problem imply portfolio weights that are highly
sensitive to extreme values of the signal. For example, if the signal is normally distributed a linear
portfolio weight is unbounded.
The weight in (20) satisfies x(Z)→0 as µ(Z)→±∞. After a certain point, even an optimistic
extreme signal leads to purchasing less of the risky asset, when the objective is to attain a given
unconditional mean return with the smallest unconditional variance. Intuitively, an extremely high
expected return presents an opportunity to reduce risk by taking a small position in the risky asset this
period, without compromising the average portfolio performance.14
______________________________________________________________________________
insert figure 1 here
_____________________________________________________________________________

14

The precise shape of the curve depends on the homoskedasticity assumption used in Figure 1.
However, according to Equation (20), if there is heteroskedasticity, where an extreme value of the
signal is associated with a large conditional variance, the conservative behavior of the strategy is
reinforced. Ferson and Siegel (2001) show that the solution for an n-asset example also implies the
portfolio weight is a bounded function of the signal. They also note that the graph of the
unconditionally efficient portfolio weight is similar to the redescending influence curves used in robust
statistics (e.g. Hampel (1974), Goodall (1983), Carroll, 1989). This suggests that the unconditionally
efficient portfolios may be empirically robust.

26

Optimal Weight versus Signal
Rquares are .0045, .105 and .355
4
3

Risky Asset Weight

2
1
0
-1
-2
-3
-4
-0.6

-0.4

-0.2

0
Signal

0.2

0.4

0.6

27
The "conservative" nature of the solution implies an interesting "agency" problem in a
portfolio management context. The portfolio manager who is evaluated, as is common in practice, on
the basis of unconditional mean return relative to unconditional return volatility may be induced to
adopt a conservative response to extreme signals in order to maximize the measured performance.

Conditional versus Unconditional Efficiency
Hansen and Richard (1987) show that in the set of returns that can be generated using
conditioning information, an unconditionally efficient strategy with respect to the information must be
conditionally efficient, but the reverse is not true. The relation between conditional and unconditional
efficiency with respect to conditioning information may be understood in terms of the utility functions
for which the solutions are optimal.
Ferson and Siegel (2001) show that an unconditionally efficient portfolio with respect to the
conditioning information maximizes the conditional expectation of a quadratic utility function in a
single-period problem. Since quadratic-utility agents choose mean-variance efficient portfolios, this
implies that an unconditionally-efficient portfolio must be a conditionally mean-variance efficient
portfolio. However, other utility functions also lead to conditional mean-variance efficient portfolios.
One example is the exponential utility function previously mentioned, when returns are normally
distributed conditional on the information.

Ferson and Siegel show that the solution for the

unconditionally efficient portfolio with respect to the information is unique, so the exponential utility
agent chooses a conditionally mean-variance efficient portfolio that is not unconditionally efficient with
respect to the information. Thus, conditional efficiency does not imply unconditional efficiency with
respect to the information. The unconditional efficient portfolios with respect to given conditioning

28
information are a subset of the conditionally efficient portfolios with respect to the same information.
The relation between conditional and unconditional efficient portfolios with respect to given
conditioning information can be represented as in Figure 2, with the unconditional mean return on the y
axis and unconditional standard deviation on the x axis. The usual "fixed weight" mean-standard
deviation boundary, which ignores the conditioning information, is the curve farthest to the right in the
lower portion of the figure. There are an infinite number of conditionally efficient portfolio strategies,
some examples of which are depicted by the other curves.15 Some of the conditionally efficient
strategies can plot inside the fixed weight strategy that ignores the conditioning information, as shown
by Dybvig and Ross (1985) and illustrated by one of the examples in the figure. The unconditional
efficient strategy with respect to the information Z is the outer envelope of all the conditionally efficient
strategies. This is shown as the left-most curve in Figure 2. Hansen and Richard (1987) provide a
formal characterization and prove that the outer envelope in Figure 2 has the familiar properties
associated with mean-standard deviation boundaries when there is no conditioning information (e.g.,
two-fund separation. See Ingersoll, 1987).
______________________________________________________________________________
insert figure 2 here
_____________________________________________________________________________

15

To see that there are an infinite number, note that a conditionally minimum variance efficient
strategy solves:
Minx(Z) Var[x(Z)'R|Z] s.t. E[x(Z)'R|Z] = T(Z),
where T(Z) is the target conditional mean return. Each of the infinite possible specifications for the

29
MINIMUM VARIANCE BOUNDARIES

1.02

Expected Gross Return

1.015
1.01
1.005
1
0.995
0.99
0.985
0.98
0

0.5

1

1.5
Standard Deviation

function T(Z) implies a conditionally efficient strategy.

2

2.5

3

30
Implications for Tests
These concepts of minimum variance efficiency have important implications for tests of asset
pricing models.

In principle, we can devise tests to reject the hypothesis that a portfolio is

unconditional efficient or efficient conditional on some observed instruments, but we can not tell if a
portfolio is efficient given all the public information, Ω. If we interpret asset pricing models as
identifying which portfolios are conditionally efficient given Ω, we have a problem. The collection of
minimum variance portfolios, conditional on the market information set, Ω, is larger than the set of
minimum variance portfolios conditional on an observable subset of instruments, Z. Thus, even if we
reject that a portfolio is efficient given Z, we can not infer that it is inefficient given Ω. This is similar
to the Roll (1977) critique of tests of the CAPM. Roll pointed out that since the market portfolio of the
CAPM can not be measured, the CAPM can not be tested without making assumptions about the
unobserved market return. The problem here is that we can not test the conditional CAPM because the
full information set Ω is not observed, unless we make assumptions about the unobserved information
set. This problem is present even if the true market portfolio return could be measured.16
There is an important exception to this conundrum. When tests are based on equation (2) it is
possible to test the model without observing the complete information set, when mt+1 depends only on
observable data and model parameters. Equation (2) implies that E(mt+1Rt+1|Zt)=1, so tests may
proceed using the observed instruments Zt.

This is the case, for example, in versions of the

consumption-based asset pricing model, when the relevant consumption can be measured. Given a
model in which mt+1 is a function of observed data and parameters, it is also possible to use the concept
of unconditional efficiency with respect to given information, Z, to conduct tests of the model. This
16

See Wheatley (1989) for a critique of the earliest conditional asset pricing studies based on similar
logic.

31
approach is developed in Ferson and Siegel (2002b).

2.5 Choosing the Factors
A beta pricing model has no empirical content until the factors are specified, since there will
always be a minimum variance portfolio which satisfies (13). The minimum variance portfolio can
serve as a single factor in (12). Therefore, the empirical content of the model is the discipline imposed
in selecting the factors.
There have been three main approaches to specifying empirical factors for multiple-beta asset
pricing models. One approach is to use statistical factor analytic or principal components methods.
This approach is motivated by the APT, where the "right" factors are the ones that capture all the
pervasive (unbounded eigenvalue) risk, leaving only diversifyable (bounded eigenvalue) risk in the
residuals. That approach is pursued by Roll and Ross (1980) and Connor and Korajczyk (1986),
among others. The advantage of the Connor-Korajczyk approach is that the factor extraction is
conducted under essentially the same large-markets assumptions that lead to the APT. This lends some
rigor to the tests. The disadvantage is that purely statistical factors provide little economic intuition.
Burmeister and MecElroy (1988) augment statistical factors with a market portfolio and illustrate how
to "rotate" the factors, to interpret them relative to more intuitive economic variables.
In a second approach the risk factors are explicitly chosen economic variables or portfolios,
chosen based on economic intuition (e.g., Chen, Roll and Ross (1986), Ferson and Harvey (1991),
Campbell (1993), and Cochrane, 1996). Here is where equation (4) should come in. According to that
equation, the factors should be related to consumer wealth, consumption expenditures, and the
sufficient statistics for the marginal utility of future wealth in an optimal consumption-investment plan.

32

A third approach for choosing factors uses the cross-sectional empirical relation of stock
returns to firm attributes. For example, portfolios are formed by ranking stocks on firm characteristics
that are observed to be correlated with the cross-section of average returns. Perhaps the most famous
current example is the three-factor model of Fama and French (1993, 1996). Fama and French group
common stocks according to their “size” (market value of equity) and their ratios of book value to
market value of equity per share. Previous studies such as Keim (1983) and Reinganum (1981) found
that stock returns are related to these attributes. Fama and French use the returns of small stocks in
excess of large stocks, and the returns of high book-to-market in excess of low book-to-market stocks,
as two “factors.” This approach is critiqued on methodological grounds in section 4.2.
The empirical literature which examines multiple-beta pricing models is vast. Fama (1991),
Connor and Korajczyk (1995) and Harvey and Kirby (1996) provide selective reviews. Studies
typically focus on particular factors, and may mix the three approaches to factor selection. There is
scant empirical evidence that focuses directly on the general question: Which of the three methods of
factor selection is superior? The answer to this question depends on the application to which the
multiple-beta model is part.
In their role as empirical models for security returns, multiple-beta models are used for
essentially three things. First, they are used to explain the cross-section of average returns on different
securities.

This relates to Equation (6), where expected returns differ according to the return

covariances with mt+1. Second, the models are used to explain predictable patterns in security returns
over time. This is the main goal of conditional asset pricing, as discussed in Section 2.1. Finally,
multiple-beta models are used to explain the contemporaneous variance of security returns, through the

33
variation of the risk factors. This relates more to multiple regression regression models, that are often
associated with multiple-beta expected return models like Equation (9).
The cross section of expected returns is central for a number of applications. The models’
fitted expected returns serve as estimates of “required” returns, in relation to risk. They are used, among
other things, for the cost of equity capital, an important input in corporate project selection problems
(see the surveys of Bruner, et al. (1998) and Graham and Harvey, (2001), and for portfolio construction
and performance evaluation (see Section 5). There are problems in evaluating the three approaches to
factor selection for this purpose. First, the results depend crucially on the “test assets,” or portfolios for
which the models are evaluated. If portfolios are formed to emphasize cross sectional variation in a
particular dimension, thus de-emphasizing others17, then a model that “explains” that particular
dimension will look good. For example, the Fama-French (1993) three-factor model emphasizes size
and book-to-market. Fama and French (1996) find that it captures the cross section of average returns
pretty well in size and book-to-market sorted portfolios. However, when confronted with industry
returns (Fama and French, 1997) or with cross-sectional variation in average returns, related to the
momentum effect of Jegadesh and Titman (1993), the model performs poorly. This issue of portfolio
formation has muddled some attempts in the literature to distinguish between the explanation of power
of security characteristics versus betas on related factors, for the cross-section of average returns (e.g.
Daniel and Titman, 1997). See Berk (2001) for an analysis and critique.
The second problem in evaluating the methods of factor selection relates to the discussion of
conditional and unconditional efficiency in Section 2.4. A model may identify a conditionally efficient
portfolio, but the portfolio is unconditionally inefficient. In other words, conditional covariances with a
17

The total sum of squares in any sample must equal the across-group sum of squares plus the
within-group sum of squares.

34
portfolio return could provide an exact description of the cross section of conditional expected returns,
while at the same time average returns are not explained by their unconditional covariances with the
same portfolio return. To see this algebraically, take the unconditional expectation of Equation (10),
and recall that the expectation of the conditional covariance differs from the unconditional covariance
by the covariance of the conditional means. If the cross section of assets i differ in their values of
Cov{Et (Ri,t+1),Et(mt+1)}, we have a problem. Recall that Et(mt+1) is the inverse of the risk-free return.
Evidence from Fama and Schwert (1977) and Ferson (1989) shows that different assets’ expected
returns have different sensitivities to measures of risk-free interest rates, so this problem may be a
serious one.
Although these caveats make it difficult to interpret the evidence in relation to theory, it is still
interesting to know which models provide a good empirical description for the cross section of average
returns. A few studies compare the alternative approaches to factor selection. Lehmann and Modest
(1987) take no stand on which approach is superior, but observe that predicted expected returns for a
sample of mutual funds can be very sensitive to using the CAPM versus the APT, as well as to different
approaches for implementing the APT. Farnsworth et al (2002) compare a collection of SDF models,
including (1) three-factor models based on the asymptotic principal components of Connor and
Kovajczyk (1986); (2) three traded economic factors relating to the stock market, government bonds
and low-grade corporate bonds, and (3); the three-factor model of Fama and French (1993, 1996).
They estimate the models in a common sample of nine primitive “assets,” portfolios emphasizing
variation in equity size, book-to-market and momentum, as well as bond market returns. They find that
the principal components-based model is the worst-performing model in this group for explaining the
cross section of average returns, as summarized by the Hansen-Jagganathan distance measure described
in the next section.

35
Explaining predictability in security returns is another important and controversial application
for multibeta asset pricing models. Much of the controversy relates to the interpretation. Fama (1970,
1991) emphasizes that evidence relating to market efficiency involves a “joint hypothesis.” A model of
equilibrium (essentially, a specification for the SDF) is jointly tested with the hypothesis that markets
are informationally efficient with respect to particular information. If the tests reject, then logically the
market could be inefficient or the SDF model could be wrong. From this perspective, predictability that
cannot be explained using any of the standard asset pricing models suggests market inefficiency; or
alternatively, the need to move beyond the standard models.
A few studies have compared the alternative approaches to factor selection, for the purpose of
explaining return predictability. Ferson and Korajczyk (1995) compare economic factors similar to
those chosen by Chen, Roll and Ross (1986) with the asymptotic principal components of Connor and
Korajczyk (1986). They study predictability in one-month to two-year returns based on a list of
“standard” lagged instruments discussed above, estimating the fraction of the predictable variance of
return that is captured by the models. They find that single-factor models can capture about 60% of the
predictable variance in a sample of industry returns, while five-factor models capture about 80%.
These results are not highly sensitive to the return horizon. The performance of a five-principal
components model and a five prespecified-factor model are broadly similar for capturing predictability
in returns for all of the horizons. Farnsworth et al (2002) find that, among the three-factor models, the
Fama-French model performs the worst for explaining predictability in their study.

Additional

evidence that this model performs poorly for capturing return predictability is presented by Kirby
(1998) and Ferson and Harvey (1999).
Factors with good contemporaneous explanatory power for security returns are useful for risk
modeling and for controlling systematic variance in some research contexts. A regression of security

36
returns on a selection of factors does not impose an asset pricing model unless the regression
coefficients are restricted: examples are given in Section 4. But it is easier to draw general conclusions
about the empirical performance of the methods of factor selection in this setting. In a given sample, a
factor analytic approach constructs factors to be highly correlated with the asset returns. If in-sample,
contemporaneous correlation is the goal, this approach almost has to be the most effective. Choosing
economic variables is likely to be the worst approach, because security returns, and stock returns in
particular, are only weakly correlated with most economic data (e.g. Roll 1988). Indeed, this low
contemporaneous correlation is one motivation for the use of mimicking portfolios, described in
Section 4, to replace factors based on economic data in empirical models.

3. Modern Variance Bounds
3.1 The Hansen Jagannathan Bounds
Hansen and Jagannathan (HJ, 1991) showed how the fundamental asset pricing equation (1)
places restrictions on the mean and variance of mt+1. These restrictions depend only on the sample of
assets, and thus provide a diagnostic tool for comparing different models of mt+1. If a candidate for
mt+1, corresponding to a particular theory, fails to satisfy the HJ bounds, then it can not satisfy the
Equation (1). Recent papers refine and extend the HJ bounds in several directions, and a number of
papers and textbooks provide basic reviews [see Ferson (1995)].18 We briefly review the case where

18

Snow (1991) considers selected higher moments of the returns distribution. Bansal and Lehmann
(1997) derive restrictions on E[ln(m)] that involve all higher moments of m and reduce to the HJ
bounds if returns are lognormally distributed. Balduzzi and Kallal (1997) incorporate the implications
for the risk premium on an economic variable. Cochrane and Hansen (1992) state restrictions in terms
of the correlation between the stochastic discount factor and returns, while Cochrane and Saa'-Requejo
(2000) consider bounds on the Sharpe ratios of assets' pricing errors. Hansen, Heaton and Luttmer
(1995) develop asymptotic distribution theory for specification errors on stochastic discount factors,

37
there is no conditioning information, then move on to extensions with conditioning information.
Assume that the random column n-vector R of the assets’ gross returns has mean E(R)=µ and
covariance matrix Σ. When there is no conditioning information a stochastic discount factor is defined
as any random variable m such that E(mR)=1. Hansen and Jagannathan (1991) show that the stochastic
discount factor with minimum variance for its expectation E(m) is given by:

m* = E(m) + [1' - E(m)E(R')] Σ-1 [R - µ],

(23)

and the minimum variance for a SDF is the variance of m*:

Var(m) ≥ [1' - E(m)E(R')] Σ-1 [1'- E(m)E(R)].

(24)

The proof is instructive. Consider a regression of any m satisfying E(mR)=1 on the asset returns, R.
The fitted value is m* = E(m) + Cov(m,R)Σ-1[R-µ], and m = m* + ε, where ε is the regression error
satisfying E(ε)=0=E(εR). Since m* is a linear function of R, it follows that E(εm*)=0. Thus, Var(m) =
Var(m*) + Var(ε) ≥ Var(m*). Finally, expanding E(mR) = 1 = E(m)µ + Cov(m,R) and substituting for
Cov(m,R), we arrive at equation (23). The right hand side of equation (24) is just the variance of the
m* in Equation (3).
The HJ bound is related to the maximum Sharpe ratio that can be obtained by a portfolio of
where the HJ bounds are a special case, and Ferson and Siegel (2002a) evaluate these standard errors
by simulation.

38
the assets. The Sharpe ratio is defined as the ratio of the expected excess return to the standard
deviation of the portfolio return. If the vector of assets' expected excess returns is µ - E(m)-1 and Σ is
the covariance matrix, the square of the maximum Sharpe ratio is [µ-E(m)-1]'Σ-1[µ-E(m)-1]. Thus, from
Equation (24) the lower bound on the variance of stochastic discount factors is the maximum squared
Sharpe ratio multiplied by E(m)2. The larger is the maximum squared Sharpe ratio for a given E(m),
the tighter is the bound on Var(m) and the more potential SDFs can be ruled out.
The Hansen and Jagannathan (1991) region for {E(m),σ(m)} is given by the square root of
Equation (24). The boundary of this region is the minimum value of the standard deviation, σ(m), for
each value of E(m). Some empirical examples are illustrated in Figure 3, corresponding to the different
versions of the bounds described below. The bounds are drawn for quarterly data similar to Hansen
and Jagannathan, consisting of 3, 6, 9 and 12-month Treasury bill returns for the 1964-1986 sample
period. For a given hyperbola in Figure 3, as we vary E(m) we move around the {E(m), σ(m)}
boundary. In order for an SDF to satisfy E(mR)=1, its mean and standard deviation must plot above
the boundary, "inside the cup." The points shown by the "×" symbols are the sample means and
standard deviations of the mt+1 of equation (8), using quarterly total US consumption data per capita
over the same sample period, and various values of the relative risk aversion, α. Note that the SDF
does not plot inside even the lowest cup for many values of α. In fact, the SDF just touches the
boundary of Figure 3 when α=71. The SDF does not enter the highest cups for any value of risk
oversion. The simple consumption model does not produce SDF's that are volatile enough. This is a
version of the equity premium puzzle of Mehra and Prescott (1985).
______________________________________________________________________________
insert figure 3 here

39
_____________________________________________________________________________

HANSEN JAGANNATHAN BOUNDS
2
1.8
1.6
1.4

Std(m)

1.2
1
0.8
0.6
0.4
0.2
0
0.97

0.98

0.99

1
E(m)

1.01

1.02

1.03

40
The bound in (24) is not the sharpest lower bound on σ(m) that can be derived. Hansen and
Jagannathan (1991) show how imposing that mt+1 is a strictly positive random variable can sharpen the
bound. Computing the bounds imposing positivity requires a numerical search procedure. Another way
to sharpen the bounds is through the use of conditioning information.

3.2 Variance Bounds with Conditioning Information
The preceding analysis is based on the unconditional moments.

With conditioning

information Z, we may consider a stochastic discount factor for (R,Z) to be any random variable m
such that E(mR|Z)=1 for all realizations of Z. In principle, everything above could be stated for
conditional means and variances, an approach pursued by Gallant, Hansen and Tauchen (1990). This
would complicate figure 3, because we would have to show a new one for each realization of Zt.
Alternatively, Hansen and Jagannathan (1991) describe a clever way to extend the analysis to partially
exploit the information in a set of lagged instruments, while using unconditional moments to describe
the bound. Equation (5) implies that for any set of instruments E{mt+1ri,t+1⊗Zt |Zt}=0, and therefore
E{ mt+1ri,t+1⊗Zt }=0, where ⊗ is the kronecker product. If we view {ri,t+1⊗Zt} as the excess returns to a
set of "dynamic" trading strategies, the preceding analysis goes through essentially unchanged. (The
trading rule holds at time t, Zt units of the asset i long and Zt units of the zero-th asset short.)
The approach of Hansen and Jagannathan (1991) is just one way to implement HJ bounds that
use conditioning information. To understand how alternative approaches to conditioning information
can refine the bounds let rt+1 be the vector of excess returns. In this case, Equation (5) is equivalent to
the following:

41
E{mt+1rt+1 f(Zt)} = 0 for all functions f(.),

(25)

where the unconditional expectation is assumed to exist. In other words, if we consider rt+1f(Zt) to
represent a possible dynamic trading strategy, then the presence of conditioning information Zt says
that mt+1 should price all the dynamic trading strategies, not just rt+1⊗ Zt. The larger is the set of
strategies for which the Equation (25) is required to hold, the smaller is the set of mt+1’s that can satisfy
the condition, and the tighter are the bounds. This is the motivation for extending HJs original
approach, in order to use the information efficiently.
Three versions of HJ bounds with conditioning information have appeared in the literature.
These may be understood through Equation (25). First are the multiplicative bounds of Hansen and
Jagannathan (1991), who choose f(.) to be the linear function, I⊗Zt. Second are the efficient portfolio
bounds of Ferson and Siegel (2002a), where f(.) is the set of portfolio weights that may depend on Zt
and sum to 1. Finally, the optimal bounds of Gallant, Hansen and Tauchen (1990) require Equation
(25) to hold for all functions f(.).

Efficient Portfolio Bounds
Efficient portfolio bounds are based on the unconditionally efficient portfolios with respect to
the information Z, derived by Ferson and Siegel (2001) and discussed in section 2.4. Since these
portfolios maximize the Sharpe ratio, over all dynamic strategies x(Z) whose weights sum to 1.0, they
efficiently use the information in Z to tighten the bounds. For given (R,Z), the solutions describe an
unconditional mean-standard deviation boundary, as depicted in Figure 2. Fixed-weight combinations
of any two portfolios on an unconditional mean-standard-deviation boundary can describe the entire

42
boundary [Hansen and Richard (1987)]. Thus, efficient portfolio bounds can be formed from two
"arbitrary" portfolios from the boundary.

Optimal Bounds
Gallant, Hansen and Tauchen (1990) derive optimal bounds that do not restrict to portfolio
functions, with weights that sum to 1.0. The solution for the optimal bounds is presented in Ferson and
Siegel (2002a) as follows. First, define the following conditional portfolio constants, which are
analogous to the efficient-set constants used in the traditional mean-variance analysis [see, e.g.,
Ingersoll (1987)]:
α(Z) = 1'Σ(Z)-1 1 ,

(26)

β(Z) = 1'Σ(Z)-1 µ(Z), and
-1

γ(Z) = µ(Z)'Σ(Z) µ(Z),

where µ(Z) and Σ(Z) are the conditional mean and variance functions. The stochastic discount factor m
for (R,Z) with minimum variance for its expectation E(m) is given by

m*(Z) = ζ(Z) + [1 - κ(Z)µ(Z)]' Σ(Z)-1 [R - µ(Z)],

where ζ(Z) is the conditional mean of m given Z, defined as:

(27)

43

ζ(Z) = E(m|Z) = {1+γ(Z)}-1 {β(Z) + E[{1+γ(Z)}-1][E(m) - E(β(Z)/{1+γ(Z)})]}.

(28)

The unconditional variance of m*(Z) is:

Var(m*(Z))

= E[{1+γ(Z)}-1][E(m)-E(β(Z)/{1+γ(Z)})]2 + E[α(Z)] - [E(m)]2 - E(β(Z)2 /{1+γ(Z)}).

(29)

Equation (29) may be used directly to compute the optimal HJ bounds. To implement the
bound, it is necessary to specify the conditional mean function µ(Z) and the conditional variance
function. Then, the four unconditional expectations that appear in Equation (29) may be estimated from
the corresponding sample means, independent of the value of E(m).

Discussion:
For given conditioning information, Z, the optimal bounds provide the greatest lower bound
on stochastic discount factors and thus the highest, most restrictive cup. The efficient portfolio bounds
incorporate an additional restriction to functions that are portfolio weights, which sum to 1.0 at each
date.

This reduces the flexibility of the efficient portfolio bounds to exploit the conditioning

information, and thus they do not attain the greatest lower bound. Intuitively, suppose there was only
one asset. Then the restricted weight could not respond at all to the conditioning information. The
multiplicative bound of Hansen and Jagannathan (1991) does not restrict portfolio weights, but neither
does it attempt to use the conditioning information efficiently.
Ferson and Siegel (2002a) conduct a simulation study of the various HJ bounds with

44
conditioning information. They find that sample values of the bounds are upwardly biased, the bias
becoming substantial when the number of assets is large relative to the number of time-series
observations. This means that studies using the biased bounds run a risk of rejecting too many models
for the stochastic discount factor. They derive a finite-sample adjustment for the bounds and show that
it helps control the bias.

Their simulation analysis leads to several conclusions.

First, the

Multiplicative bounds of HJ can be terribly biased in realistic samples. It is important to use the finitesample adjustment to their location. Second, the Optimal bounds of Gallant, Hansen and Titman
(1990) are more difficult to implement than the multiplicative bounds, requiring the specification of
conditional means and variances, but they are the tightest bounds. While not as biased as the
multiplicative bounds, they are significantly biased in some finite samples.

The finite-sample

adjustment should be used and improves their accuracy. Third, the efficient-portfolio bounds are
similar in complexity to the optimal bounds, also requiring the specification of the conditional
moments. However, unlike the optimal bounds, they remain valid but inefficient, when these moments
are not specified correctly. They have the smallest sampling error variances of all the bounds with
conditioning information. They are not as biased as either the optimal or multiplicative bounds, but
finite-sample adjustment is still useful.

3.3 The Hansen-Jagannathan Distance
Hansen and Jagannathan (1997) develop measures of misspecification for models of the
stochastic discount factor. They consider m(φ), a "candidate" stochastic discount factor, as may be
proposed by an asset pricing model. Since the candidate SDF is misspecified, then E(m(φ)R-1|Z)≠0.
They propose a measure for how "close" is m(φ) to a stochastic discount factor that "works." We first

45
consider the case where there is no conditioning information.
It is easy to show that a particular SDF, formed from the asset returns, m* = [1'E(RR')-1]R, is
one that "works" for pricing R. Hansen and Jagannathan measure how close m(φ) is to m*. They do
this by first projecting m(φ) on the returns R to get the fitted value m̂ = [E(m(φ)R') E(RR')-1] R. They
then measure the mean square distance between the fitted values and m*. This is the HJ Distance
Measure:
HJD = E{ ( m̂ -m*)2 },

(30)

where the sample averages are used in practice to estimate the expectations.
Note that m̂ -m* = [E(m(φ)R) - 1]' E(RR')-1 R, so we may write HJD as:
[E(m(φ)R) - 1]' E(RR')-1 [E(m(φ)R) - 1]. This leads to a couple of nice interpretations. First, if we let
g=E(m(φ)R)-1, W = E(RR')-1, then HJD = g'Wg is Hansen's J-test with a particular W, described in
the next section. Second, by analogy with the T2 test, HJD measures the "most mispriced" return. To
see this interpretation, recall that g = αm = E{m(φ)R) - 1} is a measure of expected pricing error using
m(φ). The alpha of a portfolio with weight vector x is the scalar αp = x'αm. Consider the problem of
finding the absolutely most mispriced portfolio, relative to its second moment:
Maxx 2x'α + λ{x'E(RR')x - E(rp2)}, where λ is a Lagrange multiplier. The maximized value of αp2/E(rp2)
is α'E(RR')-1α, equivalent to the HJD measure.
When there is conditioning information in the form of lagged instruments, Z, then a correctly
specified SDF has E(m(φ)R-1|Z)=0, which implies E[m(φ)(R⊗Z) - (1⊗Z)] = E(0⊗Z) = 0. Let ź ≡
Z./E(Z), where ./ denotes element-by-element division.
E[m(φ)(R⊗ ź) - (1⊗ ź)] = 0, or E[m(φ)(R⊗ ź)] = 1.

The previous equation holds only if

46
If we define Ŕ ≡ R⊗ ź, we have E[m(φ)Ŕ] = 1, and we can proceed as before using Ŕ instead of R.

4. Methodology and Tests of Multifactor Asset Pricing Models
The method of moments is briefly reviewed as a general way to test models based on equation (2).
This general framework is then specialized to discuss various tests of asset pricing models. The special
cases include cross-sectional regressions and multivariate regressions.

4.1 The Generalized Method of Moments Approach
Let xt+1 be a vector of observable variables. Given a model which specifies
mt+1 = m(θ,xt+1), estimation of the parameters θ and tests of the model can proceed under weak
assumptions, using the Generalized Method of Moments (GMM), as developed by Hansen (1982).
Define the model error term:

ui,t+1 = m(θ,xt+1)Ri,t+1 – 1.

(31)

Suppose that we have a sample of N assets and T time periods. Combine the error terms from (31) into
a TxN matrix u, with typical row u't+1. Equation (2) and the model for mt+1 imply that E(ui,t+1|Zt)=0 for
all i and t, and therefore E(ut+1⊗Zt)=0 for all t. The condition E(ut+1⊗Zt)=0 says that ut+1 is orthogonal to
Zt, and is therefore called an orthogonality condition.

Define an NxL matrix of sample mean

orthogonality conditions: vec(Z'u/T), where Z is a TxL matrix of observed instruments with typical

47
row Zt', a subset of the available information at time t.19
Hansen's (1982) GMM estimates of θ are obtained as follows. Search for parameter values
that make g close to zero by minimizing a quadratic form g'Wg, where W is a fixed NLxNL weighting
matrix.

Hansen (1982) shows that the estimators of θ that minimize g'Wg are consistent and

asymptotically normal, for any fixed W. If W is chosen to be the inverse of a consistent estimate of the
covariance matrix of the orthogonality conditions, g, the estimators are asymptotically efficient in the
class of estimators that minimize g'Wg for fixed W's. The asymptotic variance matrix of the GMM
estimator of the parameter vector is then:

Ĉov (θ) ≈ [T(∂g/∂θ)'W(∂g/∂θ)]-1.

(32)

where ∂g/∂θ is an NL x dim(θ) matrix of derivatives. Hansen (1982) also shows that J=Tg'Wg is
asymptotically chi-square distributed, with degrees of freedom equal to the difference between the
number of orthogonality conditions NL and the number of parameters, dim(θ). This is Hansen's Jstatistic, mentioned in the last section, which serves as a goodness-of-fit statistic for the model. Several
choices for the weighting matrix W are available. A simple version of the optimal choice, where W =
Ĉov (g)-1, is:

Ĉov (g) = (1/T)Σt (gt gt') = [(1/T)Σt (ut+1ut+1')⊗(ZtZt')],

19

(33)

The vec(.) operator stacks the columns of a matrix. We assume that the same instruments are used
for each of the asset equations. In general, each asset equation could use a different set of instruments,

48

and ⊗ denotes the Kronecker product. This case applies when the error terms ut, and therefore the
moment conditions gt are serially uncorrelated. More general cases, and more detailed reviews are
available in Hamilton (1994), Ferson (1995), Harvey and Kirby (1996), and Cochrane (2001), among
others.

4.2 Cross-sectional Regression Methods
Much of the early empirical work on asset pricing used cross-sectional regressions of returns
on estimates of market betas (e.g. Lintner, reported in Douglas, 1969). The approach remains popular.
Multiple-beta models, in particular, are often studied using this technique (e.g. Chen, Roll and Ross
(1986), Ferson and Harvey (1991), Fama and French (1993), Lettau and Ludvigson, 2001). Crosssectional regression is appealing because it is an intuitive approach. Taking the simple CAPM as an
example, we hypothesize: E(Ri) = Rf + βi E(Rm - Rf), i=1,...,N. The model implies that the crosssectional relation between mean returns and betas has a slope equal to the expected excess return of the
market. The intercept should be a riskfree return, or a zero beta portfolio expected return. Let's start
our discussion of cross-sectional regressions with a classical two-step approach, similar to that of
Black, Jensen and Scholes (1972) or Fama and MacBeth (1973).
For the first step, suppose that market betas are constant over time. The betas come from:

rit = ai + rmt'βi + εit, t=1, ..., T for each i,

which complicates the notation.

(34)

49

For now we ignore the estimation error in the time series estimates of beta. This will be discussed later.
The second step is a cross-sectional regression for each month:

rit = λ0t + λ1t'βi + uit, i=1,...,N

(35)

There could be K > 1 betas if we are testing a multi-factor asset pricing model, then rmt is a vector of K
excess returns, and λ1t is a K-vector of slope coefficients.
It is instructive to consider the GMM solution to the cross-sectional regression estimator.
Define gt' = (1/N)Σi(rit-λ0t-λ1t'βi)⊗(1,βi'). Choose the parameters to minimize gt'Wgt for some
weighting matrix, W. Here the model is exactly identified, with the same number of parameters as
moment conditions, so the GMM solution may be obtained by setting gt = 0. This results in:

λ0t = (1/N) Σirit - λ1t' (1/N) Σi βi

(36)

λ1t = Σi (βiβi')-1 Σi βi(rit - λ0t)'

Iteratively solving (36) yields estimates of the premium for market beta, λ1t, and the zero-beta return,

λ0t, similar to Black, Jensen and Scholes (1972). If the risk-free rate is known, we have a crosssectional regression of excess returns on betas.
Of course, we want to use the cross-sectional regression to test hypotheses on the coefficients.

50
For example, the hypothesis that E(λ1t) = 0 says that the expected market risk premium is zero, or that
beta has no cross-sectional explanatory power for returns. Alternatively, we may hypothesize that
E(λ1t-rmt) = 0, which says that the premium is the market excess return. Standard errors for the
coefficients may be obtained from (36), which implies that

λ̂1t - λ1t = Σi (βiβi')-1 Σi (βi' uit),
so that
Var( λ̂1t - λ1t)

= Σi (βiβi')-1 Var(Σi βi uit) Σi (βiβi')-1

(37)

= (B'B)-1 [B'Cov(ut) B] (B'B)-1,
where B is the N x K matrix of betas. Note that the variance of the estimators given by (37) are not the
same as the OLS solution, σut (B'B)-1, where σut is a scalar, that one would obtain using a standard
regression package to run a cross-sectional regression. Only in the special case where Cov(ut) = σut In,
are the OLS standard errors correct. This would occur if the cross-sectional regression errors were
uncorrelated across assets and homoskedastic across assets -- a very unlikely scenario for stock market
return data.

The Fama-MacBeth Approach
Fama and MacBeth (1973) devise a simple and clever way to get estimates of the standard
errors, while accounting for cross-sectional dependence. They suggest using the time-series of the
estimators from a sequence of cross-sectional regressions, one for each month in the sample, to
compute the standard error of the mean coefficient. In testing the hypothesis that E(λ1t)=0, they
propose a simple t-ratio: (1/T)Σt λ̂1t /se((1/T)Σt λ̂1t ), where the standard error is estimated by:

51

se((1/T)Σt λ̂1t ) ≈ (1/√T)[(1/T) Σt [ λ̂1t - (1/T)Σt λ̂1t ]2]1/2

(38)

We can evaluate this using the previous equations. First, the sample variance of λ̂1t is examined under
the null hypothesis that λ1t is zero.

(1/T) Σt [ λ̂1t - (1/T)Σt λ̂1t ]2
= (1/T) Σt [ {λ1t + (B'B)-1 B'ut} - (1/T)Σt{λ1t + (B'B)-1 B'ut} ]2
= (1/T) Σt [(B'B)-1 B'(ut - (1/T)Σtut)]2, if the true λ1t =0,
= (B'B)-1 B' [(1/T) Σt (ut-(1/T)Σtut)(ut-(1/T)Σtut)'] B (B'B)-1
-> (B'B)-1 B'[Cov(u)] B (B'B)-1,

which is the same as equation (37). If we assume the λ̂1t are uncorrelated over time, with a constant
variance, we have Var{(1/T)Σt λ̂1t } = (1/T)2 Σt Var{ λ̂1t }. Estimating Var{ λ̂1 } with the sample

variance of the time series of the λ̂1t , as in Equation (38), produces the correct result. Thus, if we
ignore estimation error in the betas, and assume that stock returns are serially uncorrelated, then under
the null hypothesis that the expected λ1t =0, the Fama-MacBeth approach delivers the correct standard
errors.

52
Interpreting the Estimates

Fama (1976) provides an intuitive interpretation of the cross-sectional regression estimators as
portfolio returns. To fix things, start with the cross-sectional regression Rit = λ0t + λ1t βi + uit, i=1,...,N.
And let there be a single beta (K=1). The CAPM implies that E(λ1t) = E(Rmt - Rft) and E(λ0t-Rft) = 0.
Under the standard assumptions that make OLS best linear unbiased, the cross sectional estimator
solves:

λ̂1t solves

Min{wi} Σi ûit2, subject to:

(39)

Unbiased: E( λ̂1t ) = λ1t
Linear: λ̂1t = Σi wi Rit

We can use these conditions to characterize λ̂1t as a portfolio.20 In particular:
E( λ̂1t )=E(Σi wiRit)=E(Σiwi[λ0t+ λ1tβi+ uit]) = λ1t implies (Σiwi)=0, and (Σiwiβi)=1. This shows that the
portfolio has weights, {wi} on the assets which sum to zero, and has a beta equal to one.21 The first
condition, (Σiwi)=0, says that the return is an excess return. The second conditions, (Σiwiβi)=1, says
20

Since uit is likely to be correlated across assets, GLS is better in theory. This amounts to a
transformation of the asset returns and their betas into a different set of portfolios, then running OLS on
the new portfolios. Therefore, the intuition here will translate.
21

This condition would also apply in a multi-beta context, in which case the coefficient for a particular
beta is a portfolio return with unit beta on the particular factor. Unbiasedness would also imply that the
beta on the other factors equal zero, so the portfolio targets only the risk as represented by the factor in
question.

53

that the portfolio beta must equal 1.0. In order for the weights to sum to zero while the beta is positive,
the portfolio must be "long" (positive weights) in high beta securities, and also "short" (negative
weights) in low beta securities.
A Similar analysis restricts the intercept estimator, implying that (Σiwi)=1 and (Σiwiβi)=0.
Thus, the intercept is a fully invested portfolio with no "systematic," or factor-related risk. Its expected
return should therefore be the zero-beta rate. If there is a risk-free security, this should be the risk-free
rate.
The Fama-MacBeth cross-sectional regression coefficients represent one way to obtain the
excess returns on mimicking portfolios for the risk factors. This is especially useful if the factors are
not traded excess returns. Regression betas on nontraded variables, such as consumption, GNP growth
or inflation, can be used. In this case, the Fama-MacBeth coefficients deliver excess returns, whose
expected values are risk estimated premiums for the factors. Indeed, the preceding analysis goes
through if the cross-sectional regressors are not betas. For example, studies have used attributes such
as firm size, dividend yield, or book-to-market ratio in place of beta coefficients.

A Caveat

The Fama-MacBeth procedure constructs a "factor-mimicking" portfolio, for anything that we
put on the right-hand side of the regression. This raises a potentially serious caveat. If a firm attribute
is used that represents an anomaly, even if completely unrelated to risk, the procedure can deliver a
mimicking portfolio return that may appear to work as a risk factor. This caveat is explored by Ferson,
Sarkissian and Simin (1999). For a simple illustration, consider the following hypothetical regression:
Rit = λ0t + λ1t αi + uit, i=1,...,N

(40)

54

where αi is an anomaly in the average return of asset i. Let Ai ≡ αi - (1/N) Σi αi, then the OLS FamaMacbeth slope estimator constructs the portfolio:

Rpt = λ̂1t = Σi wi Rit , wi = Ai / Σi Ai2

(41)

Suppose we used Rpt as a "factor" in an asset pricing model. Would it appear to "price," i.e. would
returns be linear in covariances with Rpt?

Cov(Rt, Rpt) = Cov(R)w = Cov(R)A / Σi Ai2,

(42)

where A is the N-vector of the Ai's. If Cov(R)A ∝ A, then the vector of covariances with Rpt = λ1t
will appear to "explain" the cross-section of expected asset returns. For example: suppose Cov(R)=I.
Then, returns are independent and there is no systematic risk. But, Cov(R)A ∝ A, so the "factor"
Rpt, formed by the Fama-MacBeth approach, will appear to work perfectly, in the sense that
covariances with the factor return will exactly explain the cross-section of expected returns!
Similar results should be obtained when "spread" portfolios replace the FM coefficients, as in
Fama and French (1993, 1996). Spread portfolios are formed as the difference between a high-attribute
portfolio and a low-attribute portfolio return. Thus, they are long the high-attribute stocks, short the
low-attribute stocks, and their weights sum to zero. A cross-sectional regression coefficient for stock
returns on the attribute is also a linear combination of the returns, with weights that sum to zero. The

55

portfolio is long in high-attribute stocks and short in low-attribute stocks. If a multiple regression is
used, it has zero exposure to the other regressors. Subject to these conditions, it has minimum variance.
A spread portfolio has a similar property if multiple independent sorts are used, as in Fama and French
(1996), to control for the other attributes. While a spread portfolio does not explicitly minimize
variance subject to these conditions, it avoids estimation error. Ferson, Sarkissian and Simin (1999)
provide an example where Fama-MacBeth coefficients and spread portfolios, similar to Fama and
French (1996), produce similar results in the face of an anomaly in asset returns. Their example shows
that an arbitrary attribute, bearing an anomalous relation to returns, can be repackaged as a spurious
risk factor.
Recent studies employing the approach of Fama and French (1996) do not use arbitrary
anomalous attributes. Some of the most empirically powerful characteristics for the cross-sectional
prediction of returns are ratios, with market price per share in the denominator.

Berk (1995)

emphasizes that the price of any stock is the value of its future cash flows discounted by future returns,
so an anomalous pattern in the cross-section of returns would produce a corresponding pattern in bookto-market ratios or other proxies of cash-flow-to-price. A cross-sectional regression of returns on these
ratios will pick out the anomalous patterns. Thus, the use of valuation ratios such as book-to-market as
a sorting criterion increases the risk of creating a spurious risk factor.
In the real world, empirically measured attributes may be correlated with systematic risk and
also with anomalous patterns in return. The net result of the two effects, risk versus anomaly, is
complicated and model specific. However, equity market databases are inherently unbalanced panels,
with more stocks than quarters or months. As new data on equity attributes becomes widely accessible,
more studies will sort securities according to their attributes. The important caveat is that sorting
procedures are subtle and easily abused. More work is needed to improve our understanding of the

56

properties of such approaches.

Errors-in-Betas

When the cross-sectional regression uses betas that are measured with error, two main issues
arise. First, the cross-sectional regression coefficients suffer from a classical "attenuation bias."
Second, the standard errors are biased. Early studies that used cross-sectional regression also used
portfolio grouping procedures, attempting to minimize errors in the betas, and to ensure that the
remaining errors were uncorrelated with the other error terms in the model. More recently, empirical
studies have taken to sorting stocks in order to accentuate some anomaly in the data, such as firm size,
book-to-market, etc., in order to "challenge" the asset pricing model more forcefully. Thus, concerns
about errors in the betas remain relevant.
Consider first the cross-sectional regression model with no errors in the betas:

Rt = λ0t + B λt + ut,

(43)

where Cov(ut, B)=0 and Rt is an N-vector of returns. Assume that we don't get to see the true B,
instead we have B*, where:
B* = B + v = true + "noise," Cov(v,B)=0.

(44)

Using the first stage time-series or GMM estimation, we can get an estimate of Cov(v), the crosssectional covariance matrix of the errors-in-betas. If the run the cross-sectional regression on the noisy

57

betas:
Rt = λ0t + B* λ t + et,

(45)

then λ̂1 ->p Cov(B*)-1 Cov(B*,Rt) = [Cov(B)+ Cov(v)]-1 Cov(B+v, Bλt + ut) =
[Cov(B)+ Cov(v)]-1 { Cov(B)λt }. Theil (1971) proposes an adjusted estimator to control the bias:

λt* ≡ [Cov(B*) - Cov(v)]-1 [Cov(B*)] λ̂1 ->p λ t

(46)

This estimator is used by Black and Scholes (1974), and Litzenberger and Ramaswamy (1979, 1982).
Most of the preceding analysis assumes that the same betas are used in each cross-sectional
month. Under this simplifying assumption, errors in betas imply that the cross-sectional regression
coefficients are not independent over time, because the same beta (with error) is used in each month.
Shanken (1992) shows how to correct Fama-MacBeth standard errors for this fact.
In principle, the cleanest way to deal with errors-in-betas is to estimate the time-series model
of betas and the cross-sectional regression simultaneously, thus accounting for the estimation error.
This is the subject of the next section.

4.3 Multivariate Regression and Beta Pricing Models

Tests of portfolio efficiency using multivariate regression analysis and maximum likelihood
became popular in empirical finance following the work of Gibbons (1982) and Stambaugh (1982).
The traditional focus of this literature is tests of the CAPM, which implies that the market portfolio is

58

mean variance efficient. However, given the discussion in Section 2.3, multibeta models and stochastic
discount factor models also imply that some portfolio is minimum variance efficient, and the
techniques reviewed here can be applied. Following the traditional literature, we ignore the presence of
conditioning information in this section. (For tests of efficiency with conditioning information, see
Ferson and Siegel, 2002b.) For simplicity, consider the case where a risk-free asset exists.
Let rt = {Rit - RFt}i be an N-vector of excess returns, and let rpt = Rpt - RFt, be the excess return
of the particular portfolio to be tested. The null hypothesis to be tested is that Rpt is a minimum
variance portfolio, which from equation (13) is equivalent to:

E(rt) = β E(rpt); β ≡ Cov(rt; rpt) Var(rpt)-1

(47)

when there is a given riskfree rate. The tests are based on a regression model:

rt = α + β rpt + εt, εt ~ iid(0,Ω)

(48)

where the null hypothesis implies that the vector of alphas or intercepts, α = 0.
MacKinlay and Richardson (1991) illustrate that it is easy to use the GMM to implement the
tests of portfolio efficiency. To do so, one can form the moment conditions:

εt = rt - α - β rpt

(49)

59

Zt' = (1, rpt)
g = Σt (εt ⊗ Zt)/T

The parameters are φ = (α', β')'. Choosing the parameters to Minφ g'Wg, we have the GMM estimators,
which are the same as seemingly-unrelated OLS. These are consistent and asymptotically normal, even
without the assumptions that the error terms are independent and identically distributed over time. It is
assumed that the data are stationary, that E(ut)=0=E(utrpt), and other technical conditions given by
Hansen (1982). If the assumptions that justify OLS as best linear unbiased are imposed, GMM delivers
the OLS standard errors as well.
If the GMM uses the "optimal" weighting matrix, W = (1/T)[Cov(g)]-1, then the asymptotic
variance of the parameters is given by equation (34). Imposing that
εt ~ iid(0,Ω), the GLS standard errors fall out as a special case. Several tests for the hypothesis that α=0

are available using the GMM. (See, e.g., Newey and West, 1987). One example is the Wald test, which
may be formed as Tα'ACov(α)-1α, where ACov(.) denotes the asymptotic covariance.22 The Wald
statistic is asymptotically distributed as a Chi-squared variable, with degrees of freedom equal to the
dimension of α.
Much of the literature works in a normal, maximum likelihood setting. In this case, the log of
the likelihood function to be maximized is:

22

The notation is as follows. √T( Ĉ -C) converges in distribution to a vector with mean zero and
variance, ACov( Ĉ ). Thus, the asymptotic approximation to the finite sample variance of Ĉ is

60

lnL = (NT/2)ln(2Π) - (T/2)ln|Ω| - (1/2)Σt(rt-α-βrpt)'Ω-1(rt-α-βrpt)

(50)

Standard tests for the hypothesis that α=0 are compared by Buse (1982) and Gibbons, Ross and
Shanken (1989), and most of the standard tests have been used to the test the efficiency of stock market
indexes, as in the CAPM. Examples include the likelihood ratio test (Gibbons, 1982), the Lagrange
multiplier test (Stambaugh, 1982) and the Wald test (Gibbons, Ross and Shanken, 1989). The Wald
test is of particular interest. This is not because of its sampling performance, which is typically the
worst of the three, but because it leads to a graphical interpretation that provides some economic
intuition for the tests.

Since the likelihood ratio and Lagrange multiplier tests are simple

transformations of the Wald statistic, as shown by Buse (1982), a similar intuition would apply.
We first need some facts about squared Sharpe ratios. The Sharpe ratio of rp is E(rp)/σ(rp),
the ratio of the expected excess return to the standard deviation. Let S2(r) be the maximum squared
Sharpe ratio that can be obtained using fixed-weight portfolios of the N assets:

S2(r) ≡ Max x { (x'E(r))2 / x'Σx } = E(r)'Σ-1 E(r)

(51)

where the second equality follows from solving the calculus problem. The maximum squared Sharpe
ratio in a sample of assets is related to the squared Sharpe ratio of a tested portfolio, rp, included among
the test assets, through a quadratic form in the alphas. I call this result the:

(1/T)ACov( Ĉ ).

61
Law of Conservation of Squared Sharpe Ratios:

S2(r) = α' Σ-1 α + S2(rp)

(52)

A proof uses the fact that, in the stacked regression model, α'Σ-1 β = 0.23
Proof:

S2(r)

= E(r)' Σ-1 E(r)
= [α + β E(rp)]' Σ-1 [α + β E(rp)]
= α' Σ-1 α + 2E(rp) α' Σ-1 β + E(rp)'β'Σ-1 β E(rp)
= α' Σ-1 α + E(rp)'β'Σ-1β E(rp)
= α' Σ-1 α + E(rp)'Var(rp)-1E(rp)
= α' Σ-1 α + S2(rp). QED

The law states that the highest squared Sharpe ratio obtainable in the sample is equal to the squared
Sharpe ratio of the tested portfolio, plus a sort of squared Sharpe ratio, based on the alphas. If the
alphas are zero, the two Sharpe ratios are the same and the tested portfolio is efficient. When the tested
portfolio is not efficient, the quadratic form in the alphas tells how far it is from efficient. This is
23

This occurs when the right hand side variable(s) are simple combinations of the test assets. In a
stacked regression model: r = α + rpβ + u, where rp=rW is a combination of the test assets with weight
given by the nxk matrix, W. Using the definition β' = (W'ΣW)-1W'Σ, where Σ is the covariance matrix
of r, then
α'Σ-1β = E(r - rpβ')Σ-1[(W'ΣW)-1W'Σ]'
= E(r - rpβ')Σ-1Σ W (W'ΣW)-1
= E(r - r W(W'ΣW)-1W'Σ) W (W'ΣW)-1
= E{ r W (W'ΣW)-1 - r W (W'ΣW)-1}
= 0.
Note also that Var(rp) = (W'ΣW), and β'Σ-1β = (W'ΣW)-1.

62

similar to our previous discussion of how a quadratic form in the APT pricing errors bounds the
correlation between a combination of the APT factor portfolios and a minimum variance efficient
portfolio. MacKinlay (1995) develops the interpretation of portfolios whose weights are proportional
to Σ-1α, which have many interesting properties.
The law of conservation of squared Sharpe ratios provides a graphical interpretation of the
Wald test statistic. Using the law, and the fact that in a multivariate regression model the covariance
matrix of the intercept estimator is proportional to the covariance matrix of the left hand side asset
returns, or Cov(α) = (1+ S2(rp))Σ, we may write the Wald test as:

Wald = T α'Cov(α)-1 α
= T (1+ S2(rp))-1 α'Σ-1 α
= T (1+ S2(rp))-1 [ S2(r) - S2(rp)]

(53)

Thus, the test may be interpreted as a normalized difference between S2(r), the maximum squared
Sharpe ratio in the sample of tested assets, and S2(rp), the squared ratio for the tested portfolio. If the
tested portfolio presents a Sharpe ratio that is "close" to the sample efficient portfolio, the value of the
test statistic is small and we should not reject efficiency. If the tested portfolio lies far inside the sample
mean variance frontier, we are likely to reject its efficiency.

Comparing the SDF and Beta Pricing Approaches

Before the mid 1980s, most of the empirical asset pricing literature used the beta pricing

63

representation (9) and regression based approaches or MLE. Then, the SDF representation combined
with the GMM began to take hold. The latter combination is appealing, since Et{mR-1}=0 leads
naturally to moment conditions for the GMM, and it is easy to multiply by lagged instruments, in order
to use conditioning information. Recent studies have started to explore the tradeoffs between these
approaches; see Kan and Zhou (1999), Jagannathan and Wang (2001) and Cochrane (2001).
We have seen that both cross-sectional and time-series regressions are special cases of the
GMM. So is maximum likelihood. If we use the GMM on the first order conditions, or "scores" of the
likelihood function (52), we get quasi-maximum likelihood estimators. If we further impose normality,
then the information matrix identity leads to the MLE standard errors for the parameters, and therefore
to the Cramer-Rao lower bound (See Hamilton, 1994). The implication is that the tradeoff between the
approaches has little to do with GMM versus MLE or regression, but has everything to do with the set
of moments that are examined. The SDF representation and the beta pricing formulation can lead us to
examine different moments. When they do, their empirical results can differ.
This can be illustrated in the context of a recent debate. Kan and Zhou (1999) consider
returns in excess of a risk-free rate, r, comparing beta pricing with the SDF approach. Ignoring
conditioning information, beta pricing says rt = β(ft + λ) + ut, where ft ≡ Ft - E(Ft) is the mean-centered
factor, and the moments are E(ut)=E(utft)=0. The stochastic discount factor is mt = 1 - b'ft, and the SDF
moment conditions for the excess returns are E{rr(1 - b'ft)}=0. Kan and Zhou find that the SDF
approach is much less efficient than beta pricing. However, the moments being used are not the same.
Jagannathan and Wang (2001) and Cochrane (2001) show that when the two methods exploit the same
moments, they deliver consistent results.

64
5. Conditional Performance Evaluation

Classical measures of investment performance compare the return of a managed portfolio to that of a
benchmark. For example, an alpha for a fund may be calculated as the average return in excess of a
risk-free rate, minus a fixed beta times the average excess return of a benchmark portfolio. Using the
market portfolio of the CAPM as the benchmark, Jensen (1968) advocated such a risk-adjusted
measure of performance. These classical measures are "unconditional," in the sense that the expected
returns and betas in the model are unconditional moments, estimated by past averages.
If expected returns and risks vary over time, the classical approach is likely to be unreliable.
For example, if the risk exposure of a managed portfolio varies predictably with the business cycle, but
the manager has no superior forecasting ability, a traditional approach to performance measurement
will confuse the common variation in fund risk and expected market returns with abnormal
performance. Conditional performance models the conditional expected returns and risk measures,
attempting to account for their changes with the state of the economy, and thus controlling for common
variation.
The problem of confounding variation in mutual fund risks and market returns has long been
recognized (e.g. Jensen (1972), Grant, 1977), but previous studies interpreted it as reflecting superior
information or market timing ability. Conditional performance evaluation takes the view that a
managed portfolio strategy which can be replicated using readily available public information should
not be judged as having superior performance. For example: in a conditional approach, a mechanical
market timing rule using lagged interest rate data is not a value-adding strategy. Only managers who
correctly use more information than is generally publicly available, are considered to have potentially
superior ability. Conditional performance evaluation is therefore consistent with a version of market

65

efficiency, in the semi-strong form sense of Fama (1970).
The beauty of a conditional approach to performance evaluation is that it can accommodate
whatever standard of superior information is held to be appropriate, by the choice of the lagged
instruments that are used to represent the public information. Incorporating a given set of lagged
instruments, managers who trade mechanically in response to these variables get no credit. In practice,
the trading behavior of managers may overlay complex portfolio dynamics on the dynamics of the
underlying assets they trade.

The desire to handle such dynamic strategies further motivates a

conditional approach.

A numerical example

The appeal of a conditional model for performance evaluation can be illustrated with the
following highly stylized numerical example. Assume that there are two equally-likely states of the
market as reflected in investors' expectations; say, a "Bull" state and a "Bear" state. In a Bull market,
assume that the expected return of the S&P500 is 20%, and in a Bear market, it is 0%. The risk-free
return to cash is 5%. Assume that all investors share these views -- the current state of expected market
returns is common knowledge. In this case, an investment strategy using as its only information the
current state of the market, will not yield abnormal returns.
Now, imagine a mutual fund which holds the S&P500 in a Bull market and holds cash in a
Bear market. Conditional on a Bull market, the beta of the fund is 1.0, the fund's expected return is
20%, equal to the S&P500, and the fund's alpha is zero. Conditional on a Bear market, the fund's beta
is 0.0, the expected return of the fund is the risk-free return, 5%, and the alpha is, again, zero. A
conditional approach to performance evaluation correctly reports an alpha of zero in each state.

66

By contrast, an unconditional approach to performance evaluation incorrectly reports an alpha
greater than zero for our hypothetical mutual fund. The unconditional beta of the fund24 is 0.75. The
unconditional expected return of the fund is .5(.20) + .5(.05) = 0.125. The unconditional expected
return of the S&P500 is .5(.20) + .5(.0) = .10, and the unconditional alpha of the fund is therefore:
(.125 -.05) - 0.75(.10-.05) = 0.0375. The unconditional approach leads to the mistaken conclusion that
the manager has positive abnormal performance. But the manager's performance does not reflect
superior skill or ability, it just reflects the fund's decision to take on more market risk in times when the
risk is more highly rewarded in the market. Investors who have access to the same information about
the economic state, would not be willing to pay the fund management fees to use this common
knowledge.

5.1 Stochastic Discount Factor Formulation

For a given SDF we may define a fund's conditional SDF alpha following Chen and Knez

24

The calculation is as follows. The unconditional beta is Cov(F,M)/Var(M), where F is the fund
return and M is the market return. The numerator is:
Cov(F,M) =
=
=

E{ (F-E(F))(M-E(M)) |Bull} x Prob(Bull) +
E{ (F-E(F))(M-E(M)) |Bear} x Prob(Bear)
{ (.20-.125)(.20-.10) } x .5 + { (.05-.125)(0-.10) } x .5
0.0075.

The denominator is:
Var(M) =
=
=

E{ (M-E(M))2 |Bull} x Prob(Bull) +
E{ (M-E(M))2 |Bear} x Prob(Bear)
{ (.20-.10)2 } x .5 + { ( .0-.10)2 } x .5
0.01.

The beta is therefore .0075/.01 = 0.75.

67

(1996) and Farnsworth, et al (2002) as:

αpt ≡ E(mt+1 Rp,t+1|Zt) - 1,

(54)

where one dollar invested with the fund at time t returns Rp,t+1 dollars at time t+1. If the SDF prices a
set of "primitive" assets, Rt+1, then αpt will be zero when the fund (costlessly) forms a portfolio of the
primitive assets, if the portfolio strategy uses only the public information at time t. In that case Rp,t+1 =
x(Zt)'Rt+1, where x(Zt) is the portfolio weight vector. Then equation (2) implies that αpt =
[E(mt+1 x(Zt)'Rt+1|Zt)]-1 = x(Zt)'[E(mt+1 Rt+1|Zt)]-1 = x(Zt)'1 -1 = 0.
Consider an example where mt+1 is the intertemporal marginal rate of substitution for a
representative investor, and equation (2) is the Euler equation which must be satisfied in equilibrium.
If the consumer has access to a fund for which the conditional alpha is not zero he or she will wish to
adjust the portfolio, purchasing more of the fund if alpha is positive and less if alpha is negative.
The SDF alpha depends on the model for the SDF, and the SDF is not unique unless markets
are complete. Thus, different SDFs can produce different measured performance. This mirrors the
classical approaches to performance evaluation, where performance is sensitive to the benchmark.25
While αpt is in general a function of Zt, it is simpler to discuss the estimation of αp = E(αpt).
The parameter αp is the expectation of the conditional alpha, defined by equation (54). Thus, we

25

Roll (1978), Dybvig and Ross (1985), Brown and Brown (1987), Chen, Copeland and Mayers (1987), Lehman
and Modest (1988) and Grinblatt and Titman (1989) address this issue in the beta pricing context. Farnsworth et
al (2002) provide empirical evidence for the SDF setting.

68

examine the average abnormal performance of a fund.26 A useful approach for estimating SDF alphas
in this case is to form a system of equations as follows:

u1t = [mt+1 Rt+1 - 1] ⊗ Zt
u2t = αp - mt+1 Rp,t+1 + 1

(55)

The sample moment condition is g = T-1 Σt (u1t', u2t').' We can use the GMM to simultaneously
estimate the parameters of the SDF model and the fund's SDF alpha.

Invariance to the number of funds

The system (55) may be estimated using a two-step approach, where the parameters of the
model for mt+1 are estimated in the first step and the fitted SDF is used to estimate alphas in the second
step. Farnsworth, et al. (2002) find that simultaneous estimation is dramatically more efficient.
However, a potential problem with the simultaneous approach is that the number of moment conditions
grows substantially if many funds are to be evaluated, and there are more funds than months in most of
the available data sets.
Fortunately, Farnsworth et al. (2002) show that we can estimate the joint system separately for
each fund without loss of generality. Estimating a version of system (55) for one fund at a time is
equivalent to estimating a system with many funds simultaneously. The estimates of αp and the
standard errors for any subset of funds is invariant to the presence of another subset of funds in the
26

For a discussion of time-varying conditional alphas, see Christopherson, Ferson and Glassman (1998).

69

system.

Additional issues

Farnsworth et al (2002) consider two sets of linear factor models for mt+1. One is based on
nontraded factors (e.g. industrial production) and another is based on traded factors (e.g. the S&P 500
index). For the traded factor models, they find that it is important to impose the restriction that the
model price the traded factors. For example, in the unconditional CAPM, mt+1 = a + bRm,t+1, where
Rm,t+1 is the gross market return. Requiring the model to price the market return and also a zero beta
return we have:

E{[a+bRm,t+1]Rm,t+1}=1 and E{[a+bRm,t+1]R0t+1}=1.

(56)

These two conditions identify the parameters a(.) and b(.) as functions of the first and second moments
of the market index and the zero beta return, as shown previously in Lemma 1.
Farnsworth et al. also find that it is important to impose the restriction that the model price the
risk-free asset. This identifies the conditional mean of the SDF: E(mt+1|Zt) = Rft-1, when RFt is
included in Zt. Non-traded factor models, in particular, are much less accurate when they aren't forced
to price the risk-free asset.

5.2 Beta pricing formulation

70

Ferson and Schadt (1996) modify Jensen's alpha and two simple market timing models to
incorporate conditioning information.

They start with a conditional CAPM, which implies that

equation (57) is satisfied for the assets available to portfolio managers. They show it is easy to extend
the analysis beyond the CAPM, for a conditional multiple-beta model.

rit+1 = βim(Zt) rmt+1 + ui,t+1, i=0,...,N, t=0,...T-1,

(57)

E(ui,t+1|Zt) = 0,
E(ui,t+1 rmt+1|Zt) = 0,

The βim(Zt) are the time t conditional market betas of the excess return of asset i. The second equation
of (57) follows from the conditional CAPM assumption and the third equation says that the βim(Zt) are
conditional regression coefficients. Equation (57) implies that a portfolio strategy which depends only
on the public information Zt will satisfy a similar regression. The intercept, or "alpha" of the regression
should be zero, and the error term should not be related to the public information variables.27
Under the hypothesis that the manager uses no more information than Zt, then the portfolio
beta, βpm(Zt), is a function only of Zt. Using a Taylor series we can approximate this function linearly:

βpm(Zt) = b0p + Bp' zt,

27

(58)

That is, if Rp,t+1 = x(Zt)'Rt+1, where x(.) is an N-vector of weights and Rt+1 is the N-vector of the available risky
security returns, then the portfolio excess return will satisfy the conditional CAPM, with βpm(Zt) = x(Zt)'βm(Zt), where

71

where zt=Zt-E(Z) is a vector of the deviations of Zt from the unconditional means, and Bp is a vector
with dimension equal to the dimension of Zt. The coefficient b0p may be interpreted as an "average
beta," i.e., the unconditional mean of the conditional beta: E(βpm(Zt)). The elements of Bp are the
response coefficients of the conditional beta with respect to the information variables Zt.
Equations (57) and (58) imply a regression of a managed portfolio excess return on the market
factor excess return and its product with the lagged information:

rpt+1 = αp + δ1p rmt+1 + δ2p'(zt rmt+1) + εpt+1,

(59)

where the model implies αp=0, δ1p=b0p, and δ2p=Bp.
The regression (59) may be interpreted as a multi-factor model, where the excess market
return is the first factor and the product of the market and the lagged information variables are
additional factors. The additional factors may be interpreted as the returns to dynamic strategies, which
hold zt units of the market index, financed by borrowing or selling zt in Treasury bills. The coefficient
αp is the average difference between the managed portfolio excess return and the excess return to the
dynamic strategies, which replicate its time-varying risk exposure. A manager with a positive alpha in
this setting is one whose average return is higher than the average return of the conditional-betareplicating strategies.

5.3 Using portfolio weights

βm(Zt) is the vector of the securities' conditional betas. The error term in the regression for the portfolio strategy is

72

The previously discussed performance measurement techniques are all returns-based. The
strength of returns-based methodologies is their minimal information requirements. One needs only
returns on the managed portfolio and data for the model of mt+1. However, this ignores potentially
useful information that is often available in practice: the composition of the managed portfolio.
Grinblatt and Titman (1993) propose a weight-based measure of mutual fund performance. Their
measure combines portfolio weights with unconditional moments to measure performance. Ferson and
Khang (2002) argue that the use of portfolio weights may be especially important in a conditional
setting. When expected returns are time-varying and managers trade between return observation dates,
returns-based approaches are likely to be biased. This "interim trading bias" can be avoided by using
portfolio weights in a conditional setting.
The intuition behind weight-based performance measures can be motivated with a singleperiod model where an investor maximizes the expected utility of terminal wealth.

Maxx E{ U(W0 [Rf + x'r]) |Z,S},

(60)

where Rf is the riskfree rate, r is the vector of risky asset returns in excess of the riskfree rate, W0 is the
initial wealth, x is the vector of portfolio weights on the risky assets, Z is public information available
at time 0, and S is private information available at time 0. Private information, by definition, is
correlated with r, conditional on Z. If returns are conditionally normal, the first and second order
conditions for the maximization when the investor has nonincreasing absolute risk aversion imply (see
Khang, 1997) that

up,t+1 = x(Zt)'ut+1, where ut+1 is the vector of the ui,t+1's, and therefore E(up,t+1|Zt)=E(x(Zt)'ut+1|Zt)=x(Zt)'E(ut+1|Zt)=0.

73

E{ x(Z,S)'[r - E(r|Z)] |Z} > 0,

(61)

where x(Z,S) is the optimal weight vector and r - E(r|Z) are the unexpected, or abnormal returns, from
the perspective of an observer with the public information. Conditional on the public information, the
sum of the conditional covariances between the weights of a manager with private information, S, and
the abnormal returns for the securities in a portfolio is positive. If the manager has no private
information, S, then the covariance is zero.
Ferson and Khang (2002) study a Conditional Weight Measure (CWM) that follows from
equation (63). They introduce a "benchmark" weight, xb, that is in the public information set Z, so
equation (63) implies

E{ [x(Z,S)-xb]'[r - E(r|Z)] |Z} > 0,

(62)

if the manager has superior information, S. Because xb is a constant given Z, it will not affect the
conditional covariance. Weight changes are advantageous on statistical grounds, as the levels of the
weights may be nonstationary. Other benchmark weights could be used, when a particular benchmark
may be suggested by the application.

Conditional Performance Attribution

Traditional regression-based analysis sometimes interprets the regression as providing a

74

decomposition of the sources of a fund's returns. For example, fund beta times the market excess return
is the component of the fund's return due to the overall market exposure. Conditional performance
measures allow refinements of such decompositions. For example, in the Ferson and Schadt regression
(59), we have a component due to average market exposure and one due to the mechanical use of the
instruments, Zt, to track the time-varying exposure. The average conditional alpha is the difference
between the fund return and the dynamic beta-matched strategy. Weight-based measures allow a
similar decomposition.
Consider the following identity for the unconditional covariance:

Σj Cov(∆xj, rj) = Σj E{Cov(∆xj, rj|Z)} + Σj Cov{E(∆xj|Z), E(rj|Z)},

(63)

where ∆xj ≡ xjt - xbjt. The left-hand side is the unconditional weight measure (UWM) as in Grinblatt
and Titman (1993). The second term is the "average" conditional weight measure, equal to the
unconditional mean of equation (62). The third term captures the variation in the weight changes
associated with changes in the expected returns, conditioned on public information. By comparing the
conditional and unconditional measures, the third term may be calculated as a residual.
Equation (63) decomposes the manager's total return from active trading into a component
attributable to private information (the first term on the right) and a component attributable to the
public information. For example, the second component may be compared with the investor's cost of
monitoring the public information. The first component is the performance the investor could not
obtain without the manager, even if he chose to monitor the public information. Isolating this
component enables an investor to compensate a manager for his use of private information.

75

Interim Trading Bias

The conditional weight-based approach can control an interim trading bias, which arises when
we depart from the assumption that returns are independently and identically distributed over time (iid),
and is therefore especially relevant to a conditional setting. Consider an example where returns are
measured over two “periods,” but a manager trades each period. The manager has neutral performance,
but the portfolio weights for the second period can be a function of public information at the
intervening date. If returns are iid, this creates no bias, as there is no information at the intervening date
that is correlated with the second period return. However, if expected returns vary with public
information, then a manager who observes and trades on public information at the intervening date
generates a return for the second period from the conditional distribution. His two-period portfolio
strategy will contain more than the public information at the beginning of the first period, and a returnsbased measure over the two periods will detect this as "superior" information.
Goetzmann and Ivkovic (2000) address interim trading bias by simulating the multiperiod
returns generated by the option to trade between return observation dates. A conditional weight-based
measure avoids the problem by examining the conditional covariance between the manager's weights at
the beginning of the first period and the subsequent two-period returns. The ability of the manager to
trade at the intervening period thus creates no interim trading bias.
Of course, managers may engage in interim trading based on superior information to enhance
performance, and a weight-based measure will not record these interim trading effects. Interim trading
thus presents a bias under the null hypothesis that managers possess only pubic information. Under the
alternative hypothesis of superior ability, a weight-based measure may have limited power to detect the

76

ability. Thus, the cost of using a weight-based measure to avoid bias is a potential loss of power.
Ferson and Khang (2002) evaluate these tradeoffs, and conclude that the conditional weight-based
measure is attractive.

5.4 Conditional Market Timing Models

In a market-timing context, the goal of conditional performance evaluation is to distinguish
timing ability that merely reflects publicly available information, as captured by the set of lagged
instrumental variables, from timing based on better information. We may call such informed timing
ability conditional market timing.
A classic market timing regression, when there is no conditioning information, is the quadratic
regression of Treynor and Mazuy (1966):

rpt+1 = ap + bp rmt+1 + γtmu [rm,t+1]2 + vpt+1 ,

(64)

where the coefficient γtmu measures market timing ability. Admati, et.al. (1986) describe a model in
which a manager with constant absolute risk aversion in a normally distributed world, observes at time
t a private signal equal to the future market return plus noise, rmt+1 + η. The manager's response is
change the portfolio beta as a linear function of the signal. They show that the γtmu coefficient in
regression (64) is positive if the manager increases market exposure when the signal about the future
market return is positive.
In a conditional model, the part of the correlation of fund betas with the future market return

77

that can be attributed to the public information, is not considered to reflect market timing ability.
Ferson and Schadt (1996) develop a conditional version of the Treynor-Mazuy regression:

rpt+1 = ap + bp rmt+1 + Cp'(zt rmt+1) + γtmc [rm,t+1]2 + vpt+1 ,

(65)

where the coefficient vector Cp captures the linear response of the manager's beta to the public
information, Zt. The term Cp'(zt rmt+1) controls for the public information effect, which would bias the
coefficients in the original Treynor-Mazuy model. The coefficient γtmc measures the sensitivity of the
manager's beta to the private market timing signal.
Merton and Henriksson (1981) and Henriksson (1984) describe an alternative model of
market timing in which the quadratic term in (64) is replaced by an option payoff, Max(0,rm,t+1). This
reflects the idea that market timers may be thought of as delivering (hopefully, attractively priced) put
options on the market index. Ferson and Schadt (1996) develop a conditional version of this model as
well.
Becker, et al (1999) develop conditional market-timing models with explicit performance
benchmarks. In this case, managers maximize the utility of their portfolio returns in excess of a
benchmark portfolio return.

In practice, performance benchmarks often represent an important

component of managers' incentive systems. Such benchmarks have been controversial in the academic
literature. Starks (1987), Grinblatt and Titman (1989) and Admati and Pfleiderer (1997) argue that
benchmarks don't properly align managers' incentives. Carpenter, Dybvig and Farnsworth (2000)
provide a theoretical justification of benchmarks, used in combination with investment restrictions.
Becker, et al simultaneously estimate the fund managers' risk aversion for tracking error and the

78

precision of the market-timing signal, in a sample of more than 400 U.S. mutual funds for 1976-94,
including a subsample with explicit asset allocation objectives. The estimates suggest that U.S equity
mutual funds behave as risk averse, benchmark investors, but little evidence of timing ability is found.

5.5 Empirical Evidence On Conditional Performance

Traditional measures of the average abnormal performance of mutual funds, like Jensen's
alpha, are observed to be negative more often than positive across the many studies. For example,
Jensen (1968) used the CAPM to conclude that a typical fund has neutral performance, only after
adding back expenses. Traditional measures of market timing often find that any significant market
timing ability is perversely "negative," suggesting that investors could time the market by doing the
opposite of a typical fund. Such results make little economic sense, which suggests that they may be
spurious.
Conditional performance evaluation takes the view that a mechanically managed portfolio

strategy using only public information does not have abnormal performance. A manager's return is
therefore compared with such a benchmark, mechanically constructed using public information to
match the time-varying risk of the fund. The empirical evidence suggests that conditional performance
measures can produce results different from the classical methods.
Ferson and Schadt (1996) find evidence that funds' risk exposures change in response to
public information on the economy, such as level of interest rates and dividend yields.

Using

conditional models Ferson and Schadt (1996), Kryzanowski, Lalancette and To (1997) and Zheng
(1999) find that the distribution of mutual fund alphas shifts to the right and is centered near zero.
Ferson and Warther (1996) attribute differences between unconditional and conditional alphas to

79

predictable flows of public money into funds. Inflows are correlated with reduced market exposure, at
times when the public expects high returns, due to larger cash holdings at such times. In pension funds,
which are not subject to high frequency flows of public money, no overall shift in the distribution of
fund alphas is found when moving to conditional models (Christopherson, et. al., 1998b).
Once we control for public information variables, there seems to be little evidence that mutual
funds have conditional timing ability for the level of the market return. Busse (1999) asks whether
fund returns contain information about market volatility. He finds evidence using daily data that funds
may shift their market exposures in response to changes in second moments. Further research in this
direction is clearly warranted.
Farnsworth et al. (2002) use a variety of SDF models to evaluate performance in a monthly
sample of US equity mutual funds. They find that many of the SDF models are biased. The average
bias is about -0.19% per month for unconditional models, -0.12% for conditional models. This is less
than two standard errors, as a typical standard error is 0.1% per month. They find that the average
mutual fund alpha is no worse than a hypothetical stock-picking fund with neutral performance.
Adding back average expenses of about 0.17% per month to the mutual fund alphas (since the actual
funds pay expenses, while the hypothetical funds do not), the average fund's performance is slightly
higher than hypothetical funds with no ability.
Ferson and Khang (2002) develop the conditional, weight-based approach to measuring
performance.

Using a sample of equity pension fund managers, 1985-1994, they find that the

traditional, returns-based alphas of the funds are positive, consistent with previous studies of pension
fund performance. However, these alphas are smaller than the potential effects of interim trading bias.
By using instruments for public information combined with portfolio weights, their conditional weight-

80

based measures find that the pension funds also have neutral performance. Thus, the empirical
evidence based on conditional performance measures suggests that abnormal fund performance,
controlling for public information, is rare.

6. Conclusions

This paper has reviewed tests of multifactor asset pricing models, volatility bounds and portfolio
performance. We developed three essentially equivalent paradigms: Beta pricing, stochastic discount
factors and minimum variance efficiency, and we discussed each approach in the context of conditional
asset pricing models. These models are stated in terms of expected returns and risk measures,

conditioned on available information about the state of the economy. Conditional models are most
interesting when there are observable instruments that can track time-varying expected returns and
security risks. The evidence for such predictability in returns is both extensive and controversial.
Conditional asset pricing models should provide a useful framework for many continuing
investigations.
The three paradigms of empirical asset pricing have traditionally been linked with particular
empirical methods. The stochastic discount factor paradigm seems to fit naturally with the generalized
method of moments. Mean variance efficiency tests have (since the early 1980s) most commonly
employed multivariate regression, and multibeta models seem to cry out for cross-sectional regressions.
But this pairing of the models and methods is not sacrosanct. In fact, any of these empirical methods
can be paired with any of the paradigms, and recent studies are beginning to explore the possibilities
and tradeoffs. I am coming to the view that the set of moments the investigator chooses to examine is
the key issue. Different approaches can lead one to examine different moments, and when they do, the

81

results will differ.
Conditional performance evaluation provides an example, where the models and methods

meet the data. Empirical work in this area essentially applies conditional asset pricing models to the
returns of managed portfolios. The evidence to date shows that conditional models make a difference.
I expect these approaches to yield more interesting insights in the future, about the behavior and
performance of mutual funds, pension funds, hedge funds and other professionally managed portfolios.
Conditional asset pricing and conditional performance evaluation are still relatively young.
They are roughly "teenagers" at the time of this writing. I expect them to contribute a lot more to our
state of knowledge as they mature with future research. I hope that this paper helps to facilitate some of
that research.

References

Admati, Anat and P. Pfleiderer, 1997, Performance benchmarks: Does it all add up? Journal of
Business
Balduzzi, Pierluigi, and Heidi Kallal, 1997, Risk Premia and Variance Bounds, The Journal of Finance
52(5), 1913-49.
Balduzzi, Pierluigi, and T. Yao, 2001, Does heterogeneity matter for asset pricing? working paper,
Boston College.
Bansal, Ravi and Bruce N. Lehmann, 1997, Growth-Optimal Restrictions on Asset Pricing Models,
Macroeconomic Dynamics 1, 1-22.
Becker, Connie, W. Ferson, D. Myers and M. Schill, 1999, Conditional Market Timing with
Benchmark Investors, Journal of Financial Economics 52, 119-148. et al, 1999,
Beja, A., 1971, The structure of the cost of capital under uncertainty, Review of Economic Studies 4,
359-369.

82

Berk, Jonathan, 1995, A critique of size-related anomalies, Review of Financial Studies 8, 275-286.
Berk, Jonathan, 2000, Sorting out sorts, Journal of Finance 55, 407-427.
Bhattacharya, Sudipto, 1981, Notes on multiperiod valuation and the pricing of options, Journal of
Finance 36, 163-180.
Black, F., 1972, Capital Market Equilibrium with Restricted Borrowing," Journal of Business 45,
444-454.
Black, F. and M. Scholes, 1974, The effects of dividend yield and dividend policy on common stock
prices and returns, Journal of Financial Economics, 1, 1-22.
Black, F., M. Jensen and M. Scholes, 1972, The Capital Asset Pricing Model: Some empirical tests, in
Jensen, M. (ed.) Studies in the Theory of Capital Markets, Praeger, New York.
Breeden, D., 1979, An intertemporal asset pricing model with stochastic consumption and investment
opportunities, Journal of Financial Economics 7, 265-296.
Breeden, Douglas T., Michael R. Gibbons and Robert H. Litzenberger, 1989, Empirical tests of the
consumption-oriented CAPM, Journal of Finance 44, 231-62.
Brav, Alon, G. Constantinides and C. Geczy, 2002, Asset pricing with heterogeneous consumers and
limited participation: Empirical evidence, Journal of Political Economy (forthcoming).
Brown, K. and G. Brown, 1987, Does the market portfolio's composition matter? Journal of Portfolio
Management 13, 26-32.
Bruner, Robert F., Kenneth Eades, Robert Harris and Robert Higgins, 1998, Best practices in
estimating the cost of capital: Survey and synthesis, Journal of Financial Practice and Education
(Spring).
Burmeister, E. and M. B. McElroy, 1988, Joint estimation of factor sensitivities and risk premia for the
arbitrage pricing theory, Journal of Finance 43, 721-733.
Buse, Adolf, 1982, The likelihood ratio, Woud and Largrange multiplier tests: An expository note,
American Statistician 36, 153-157.
Carroll, Raymond J., 1989, Redescending M-Estimators, p. 134-137 of Encyclopedia of Statistical
Sciences, Supplement Volume, New York: John Wiley & Sons.

83

Campbell, John Y., 1987, Stock returns and the term structure, Journal of Financial Economics 18, 373399.
Campbell, John Y., 1993, Intertemporal Asset Pricing without consumption data, American Economic
Review 83, 487-512.
Campbell, John Y. and J. H. Cochrane, 1999, By force of habit: A consumption-based explanation of
aggregate stock market behavior, Journal of Political Economy 107, 205-251.
Campbell, John Y., A. Lo and A.C. MacKinlay, 1997, The econometrics of financial markets,
Princeton University Press, Princeton NJ.
Campbell, John Y. and L. Viceira, 1999, Consumption and portfolio decisions when expected returns
are time-varying, Quarterly Journal of Economics 114, 433-495.
Carpenter, J., P.H. Dybvig and H. Farnsworth, 2000, Portfolio performance and agency, working paper,
Washington University, St. Louis.
Chamberlain, Gary, 1983, Funds, factors and diversification in arbitrage pricing models, Econometrica
51, 1305-1324.
Chamberlain, Gary, and M. Rothschild, 1983, Arbitrage, Factor Structure and Mean Variance Analysis
on Large Asset Markets, Econometrica 51, 1281-1304.
Chen, Zhiwu, and Peter J. Knez. 1996. Portfolio Performance Measurement: Theory and Applications.
Review of Financial Studies 9: 511-556..
Chen, N., R. Roll, and S. Ross, 1986, Economic Forces and the Stock Market, Journal of Business 59,
383-403.
Chen, Nai-fu, T. Copeland and D. Mayers. 1987. A comparison of single and multifactor perforamance
methodologies. Journal of Financial and Quantitative Analysis 22: 401-17.
Christopherson, Jon A., W. Ferson and Debra A. Glassman, 1998a, Conditioning Manager Alphas on
Economic Information: Another Look at the Persistence of Performance, Review of Financial Studies
11, 111-142 (Spring).
Christopherson, Jon A., W. Ferson and Debra A. Glassman, 1998b, Conditional Measures of
Performance and Persistence for Pension Funds, in Research in Finance, vol. 16, JAI Press. Stamford,

84

Ct. ISBN: 0-7623-0328-X; pp. 1-46.
Cochrane, John H., 1996, A cross-sectional test of a production based asset pricing model, working
paper, Journal of Political Economy.
Cochrane, John H., 2001, Asset Pricing, Princeton University Press, New Jersey.
Cochrane, John and Lars Hansen, 1992, Asset pricing lessons for macroeconomics, in The
Macroeconomics Annual, O. Blanchard and S. Fisher (eds), MIT Press: Cambridge.
Cochrane, John H., and Jesus Saa'-Requejo, 2000, Beyond Arbitrage: Good-Deal Pricing of Derivatives
in Incomplete Markets, Journal of Political Economy 108, 79-119.
Connor, Gregory, 1984, A Unified beta pricing Theory, Journal of Economic Theory 34, 13-31.
Connor, Gregory and Robert A. Korajczyk, 1986, Performance Measurement with the Arbitrage
Pricing Theory: A New Framework for Analysis, Journal of Financial Economics 15, 373-394.
Connor, G. and R. Korajczyck, 1988, Risk and Return in An Equilibrium APT: Application of a new
test methodology, Journal of Financial Economics 21, 255-290.
Connor, G. and R. Korajczyk, 1995, Arbitrage Pricing Theory, in R. Jarrow, V., Maksimovic and W.T.
Ziemba (eds) Finance, North Holland.
Conrad, Jennifer and Gautam Kaul, 1989, Mean reversion in short-horizon expected returns, Review of
Financial Studies 2, 225-240.
Constantinides, George M. 1982, Intertemporal Asset Pricing with heterogeneous consumers and
without demand Aggregation, Journal of Business 55, 253-267.
Constantinides, George M., 1990, Habit formation: a resolution of the equity premium puzzle, Journal
of Political Economy 98, 519-543.
Cox, John C., Jonathan E. Ingersoll, and Stephen A. Ross, 1985, A Theory of the Term Structure of
Interest Rates, Econometrica 53, 385-408.
Cragg, J. G. and Malkiel, B. G., 1982, Expectations and the Structure of Share Prices. Chicago:
University of Chicago Press.
Daniel, Kent, and Sheridan Titman, 1997, Evidence on the characteristics of cross sectional variation in

85

stock returns, Journal of Finance 52, 1-33.
DeBondt, Werner, and R. Thaler, 1985, Does the stock market overreact? Journal of Finance 40, 793805.
Douglas, G. 1969, Risk in equity markets: An empirical appraisal of market efficiency, Yale
Economics Essays 9, 3-45.
Dybvig, P.H., 1983, An explicit bound on individual assets' deviations from APT pricing in a finite
economy, Journal of Financial Economics 12, 483-496.
Dybvig, P. and J. Ingersoll, 1982, Mean variance theory in complete markets, Journal of Business 55,
233-252.
Dybvig, Philip H., and Ross, Stephen A. 1985. Performance Measurement Using Differential
Information and a Security Market Line. Journal of Finance 40: 383-99.
Fama, Eugene F., 1970, Efficient capital markets: A review of theory and empirical work, Journal of
Finance 25, 383-417.
Fama, Eugene F., 1976, Foundations of Finance, Basic Books, New York.
Fama, Eugene F., 1991, Efficient capital markets II, Journal of Finance 46, 1575-1617.
Fama, E. and K. French, 1988, Permanent and temporary components of stock prices, Journal of
Political Economy 96, 246-273.
Fama, E. and K. French, 1989, Business conditions and expected returns on stocks and bonds, Journal
of Financial Economics 25, 23-49.
Fama, E. and K. French, 1993, Common risk factors in the returns of stocks and bonds, Journal of
Financial Economics 33, 3-56.
Fama, Eugene F. and Kenneth R. French, 1996, Multifactor explanations of asset pricing anomalies,
Journal of Finance 51, 55-87.
Fama, Eugene F. and Kenneth R. French, 1997, Industry costs of equity, Journal of Financial
Economics 43, 153-194.
Fama, Eugene F. and James D. MacBeth, 1973, Risk, Return and Equilibrium: Empirical Tests,

86

Journal of Political Economy 81, 607-36.
Fama, Eugene F. and G. W. Schwert, 1997, Asset returns and inflation, Journal of Financial Economics
5, 115-146.
Farnsworth, Heber, W. Ferson, David Jackson and Steven Todd, 2002, Performance Evaluation with
Stochastic Discount Factors, Journal of Business 75, 473-504 (July).
Ferson, Wayne E., 1983, Expectations of real interest rates and aggregate consumption: empirical tests,
Journal of Financial and Quantitative Analysis 18, 477-497.
Ferson, Wayne E., 1989, Changes in Expected Security Returns, Risk and the Level of Interest Rates,
Journal of Finance 44, 1191-1217 (December).
Ferson, Wayne E., 1995, Theory and Empirical Testing of Asset Pricing Models, Chapter 5 in Finance,
Handbooks in Operations Research and Management Science, by Jarrow, Maksimovic and Ziemba
(editors), Elsevier, 145-200.
Ferson, Wayne E. and George M. Constantinides, 1991, Habit persistence and durability in aggregate
consumption: empirical tests, Journal of Financial Economics 29, 199-240.
Ferson Wayne E. and Campbell R. Harvey, 1991, The Variation of Economic Risk Premiums, Journal
of Political Economy 99, 385-415 (April).
Ferson Wayne E. and Campbell R. Harvey, 1993, The Risk and Predictability of International Equity
Returns, Review of Financial Studies 6, 527-566.
Ferson Wayne E. and Campbell R. Harvey, 1999, Economic, Financial and Fundamental Global Risk
In and Out of EMU, Swedish Economic Policy Review 6, 123-184.
Ferson, Wayne E. and Ravi Jagannathan, 1996, Econometric Evaluation of Asset Pricing Models,
Chapter 1 (pp.1-30) in the Handbook of Statistics: vol. 14: Statistical Methods in Finance, G.S.
Maddala and C.R. Rao (editors), North Holland ISBBN: 0-444-81964-9.
Ferson, Wayne E. and Kenneth Khang, 2002, Conditional Performance Measurement Using Portfolio
Weights: Evidence for Pension Funds, Journal of Financial Economics 65, 249-282.
Ferson, W. E., and Rudi W. Schadt, 1996, Measuring fund strategy and performance in changing
economic conditions, Journal of Finance 51, 425-462 (June).

87

Ferson, Wayne E., Sergei Sarkissian and Timothy Simin, 1999, The Alpha Factor Asset Pricing Model:
A Parable, Journal of Financial Markets 2, 49-68 (February).
Ferson, Wayne E., Sergei Sarkissian and Timothy Simin, 2002, Spurious regressions in Financial
Economics? Journal of Finance, (forthcoming).
Ferson, W. E. and A. F. Siegel, 2001, The efficient use of Conditioning Information in Portfolios,
Journal of Finance 56:3, 967-982 (June).
Ferson, W. E. and A. F. Siegel, 2002a, Stochastic Discount Factor Bounds with Conditioning
Information, Review of Financial Studies, (forthcoming).
Ferson, W. E. and A. F. Siegel, 2002b, Testing Portfolio Efficiency with Conditioning Information,
working paper, Boston College.
Ferson, W. E., A. Siegel and P. Xu, 2002, Mimicking portfolios with conditioning information,
working paper, Boston College.
Ferson, W. E., and Vincent A. Warther, 1996, Evaluating Fund Performance in a Dynamic Market,
Financial Analysts Journal 52, no. 6, pp.20-28.
Foster, Douglas, T. Smith and R. Whaley, 1997, Assessing goodness-of-fit of asset pricing models: The
distributio of the maximal R-squared, Journal of Finance 52, 591-607.
Gallant, Ronald, 1987, Nonlinear statistical Models, Wiley and Sons, New York, NY.
Gallant, R.A, Lars P. Hansen and George Tauchen, 1990, Using the conditional moments of asset
payoffs to infer the volatility of intertemporal marginal rates of substitution, Journal of Econometrics
45, 141-179.
Ghysels, Eric, 1998, On stable factors in the pricing of risk: Do time-varying betas help or hurt? Journal
of Finance 53, 549-574.
Gibbons, Michael R., 1982, Multivariate tests of Financial models, Journal of Financial Economics
10, 3-27.
Gibbons, Michael R., Stephen A. Ross and Jay Shanken, 1989, A test of the efficiency of a given
portfolio, Econometrica 57, 1121-1152.
Goyal, Amit and Ivo Welch, 1999, Predicting the equity premium, working paper, UCLA.

88

Grinblatt, Mark and Sheridan Titman, 1983, Factor pricing in a finite economy, Journal of Financial
Economics 12, 497-508.
Grinblatt, Mark and Sheridan Titman, 1987, The Relation Between Mean-Variance Efficiency and
Arbitrage Pricing, Journal of Business 60, 97-112.
Goetzmann, William N., Jonathan Ingersoll and Zoran Ivkovic, 2000, Monthly measurement of daily
timers, Journal of Financial and Quantitative Analysis 35, 257-290.
Goodall, Colin, 1983, M-estimators of location: An outline of the theory, p. 339-403 of Understanding
Robust and Exploratory Data Analysis, edited by Hoaglin, David C., Frederick Mosteller, and John W.
Tukey, New York: John Wiley & Sons.
Graham, John R. and Campbell R. Harvey, 2001, The theory and practice of corporate finance:
Evidence from the field, Journal of financial economics 60, 187-243.
Grant, D., 1977, Portfolio performance and the "cost" of timing decisions. Journal of Finance 32, 837846.
Grinblatt, Mark and Sheridan Titman, 1993, Performance measurement without benchmarks: an
examination of mutual fund returns, Journal of Business 60, 97-112.
Grinblatt, Mark and Sheridan Titman, 1989a, Mutual fund performance: An analysis of quarterly
portfolio holdings, Journal of Business 62, 393-416.
Grinblatt, Mark and Sheridan Titman, 1989b, Portfolio performance evaluation: old issues and new
insights, Review of Financial Studies 2, 393-421.
Grossman, Sanford and Robert J. Shiller, 1982, Consumption correlatedness and risk measurement in
economies with nontraded assets and heterogeneous information, Journal of Financial Economics 10,
195-210.
Hamilton, James D., 1994, Time-series Analysis, Princeton University Press, Princeton, New Jersey.
Hampel, Frank R., 1974, The influence curve and its role in robust estimation, Journal of the American
Statistical Association 69, 383-393.
Hansen, Lars P., 1982, Large sample properties of the generalized method of moments estimators,
Econometrica 50, 1029-1054.

89

Hansen, Lars P., J. Heaton and E. Luttmer, 1995, Econometric Evaluation of Asset Pricing Models,
Review of Financial Studies 8, 237-274.
Hansen, Lars P., and R. Hodrick, 1980, Forward exchange rates as optimal predictors of future spot
rates: An econometric analysis, Journal of Political Economy 88, 829-853.
Hansen, Lars P. and Ravi Jagannathan, 1991, Implications of security market data for models of
dynamic economies, Journal of Political Economy 99, 225-262.
Hansen, Lars P. and Ravi Jagannathan, 1997, Assessing specification errors in stochastic discount
factor models, Journal of Finance 52, 557-590.
Hansen, Lars P. and Scott F. Richard, 1987, The role of conditioning information in deducing testable
restrictions implied by dynamic asset pricing models, Econometrica 55, 587-613.
Harrison M. and D. Kreps, 1979, Martingales and arbitrage in multi-period securities markets, Journal
of Economic Theory 20, 381-408.
Harvey, C.R., 1991, The world price of covariance risk, Journal of Finance 46, 111-157.
Harvey, C.R. and C.M. Kirby, 1996, Instrumental variables estimation of conditional beta pricing
models, Chapter 2 in the Handbook of Statistics, Vol 14, edited by G.S. Maddala and C.R. Rao,
Elsevier, New York.
Henriksson, Roy D., 1984, Market timing and mutual fund performance: An empirical investigation,
Journal of Business 57, 73-96.
Huberman, Gur, S. A. Kandel and R. F. Stambaugh, 1987, Mimicking Portfolios and Exact Arbitrage
Pricing, Journal of Finance 42, 1-10.
Jegadeesh, N. and S. Titman, 1993, Returns to buying winners and selling losers: Implicataions for
stock market efficiency, Journal of Finance 48, 65-91.
Ingersoll, Jonathan E., 1987, Theory of financial decision making, Rowman and Littlefield (Savage,
Maryland).
Jensen, M. 1968. The performance of mutual funds in the period 1945-1964. Journal of Finance 23:
389-46.

90

Jobson, J.D. and Robert Korkie, 1982, Potential performance and tests of portfolio efficiency, Journal
of Financial Economics 10, 433-466.
Jobson, J. D. Robert Korkie, 1985, Some tests of asset pricing with multivariate normality, Canadian
Journal of Administrative Sciences 2, 114-138.
Jagannathan and Wang, 2002, Empirical evaluation of asset pricing models: A comparison of SDF and
beta methods, Journal of Finance (forthcoming).
Kan, Raymond, and Guofu Zhou. 1999. A critique of the stochastic discount factor methodology.
Journal of Finance 54: 1221-1248.
Kandel, Shmuel A., 1984, The likelihood ratio test statistic of mean variance efficiency without a
riskless asset, Journal of Financial Economics 13, 575-592.
Kandel, Shmuel A., 1986, The geometry of the maximum likelihood estimator of the zero beta return,
Journal of Finance 31, 339-346.
Kandel, Shmuel and Robert F. Stambaugh, 1989, A mean variance framework for tests of asset pricing
models, Review of financial studies 2, 125-156.
Kaul, Gautam, 1996, Predictable components in stock returns, Chapter 9 (pp. 269-296) in Handbook of
Statistics 14, G.S. Maddala and C.R. Rao, eds., Elsevier Science, Amsterdam.
Keim, Donald B., 1983, Size-related anomalies and stock return seasonality: Further empirical
evidence, Journal of Financial Economics 12, 13-32.
Khang, Kenneth, 1997, Performance measurement using portfolio weights and conditioning
information: An examination of pension fund equity manager performance, Unpublished Ph.D
dissertation, University of Washington.
Kim, T.S. and Edward Omberg, 1996, Dynamic nonmyopic portfolio behavior, Review of Financial
Studies 9, 141-161.
Kim, Myung, C.R. Nelson and R. Startz, 1991, Mean reversion in stock returns? A reappraisal of the
statistical evidence, Review of Economic Studies 58, 515-528.
Kirby, Chris, 1998, The restrictions on predictability implied by asset pricing models, Review of
Financial Studies 11, 343-382.

91

Kryzanowski, L., S. Lalancette and M.C. To, 1997, Performance attribution using at APT with
prespecified macrofactors and time-varying risk premia and betas, Journal of Financial and
Quantitative Analysis 32, 205-224.
Lehmann, B.N. and David M. Modest, 1988, The empirical foundations of the arbitrage pricing theory,
Journal of Financial Economics 21, 213-254.
Lehmann, B.N. and David M. Modest, 1987, Mutual fund performance evaluation: A comparison of
benchmarks and benchmark comparisons, Journal of Finance 42, 233-265.
Lettau, Martin, and S. Ludvigson, 2001, Consumption, aggregate wealth and expected stock returns,
Journal of Finance 56, 815-849.
Litzenberger, R. and K., Ramaswamy, 1979, The effect of personal taxes and dividends on capital asset
prices: Theory and evidence, Journal of Financial Economics 7, 163-196.
Litzenberger, R. and K., Ramaswamy, 1982, The effects of dividends on common stock prices: Tax
effects or information effects? Journal of Finance 37, 429-433.
Long, J., 1974, Stock Prices, Inflation, and the Term Structure of Interest Rates, Journal of Financial
Economics 1, 131-170.
Lintner, John, 1965, The valuation of risk assets and the selection of risky investments in stock
portfolios and Capital budgets, Review of Economics and Statistics 47, 13-37.
Lucas, Robert E., Jr., 1978, Asset prices in an exchange economy, Econometrica 46, 1429-1445.
MacKinlay, A. Craig, 1987, On multivariate Tests of the CAPM, Journal of Financial Economics 18,
341-371.
MacKinlay, A. Craig, 1995, Multifactor models do not explain deviations from the CAPM, Journal of
Financial Economics 38, 3-28.
MacKinlay, A. Craig and Matthew P. Richardson, 1991, Using the generalized method of moments to
test mean-variance efficiency, Journal of Finance 46, 511-528.
Mehra, R. and E. Prescott, 1985, The equity premium: a Puzzle, Journal of Monetary Economics 15,
145-162.
Merton, Robert C., 1973, An Intertemporal Capital Asset Pricing Model, Econometrica 41, 867-87.

92

Merton, Robert C., and R. Henriksson, 1981, On market timing and investment performance II:
Statistical procedures for evaluating forecasting skills, Journal of Business 54, 513-533.
Newey, Whitney and Kenneth D. West 1987, A simple, positive definite, heteroskedasticity and
autocorrelation consistent covariance matrix, Econometrica 55, 703-708.
Pesaran, M.H. and Alan Timmermann, 1995, Predictability of stock returns: Robustness and economic
significance, Journal of Finance 50, 1201-1228.
Pontiff, Jeffrey and L. Schall, 1998, Book-to-market as a predictor of market returns, Journal of
Financial Economics 49, 141-160.
Reinganum, Marc R., 1981, Misspecification of capital asset pricing: Empirical anomalies based on
earnings yields and market values, Journal of Financial Economics 9, 19-46.
Roll, Richard R., 1988, R2, Journal of Finance 43, 541-566.
Roll, Richard R., 1984, A simple implicit measure of the effective bid-ask spread in an efficient market,
Journal of Finance 39, 1127-1140.
Roll, Richard R., 1985, A note on the geometry of Shanken's CSR T2 test for mean/variance efficiency,
Journal of Financial Economics 14, 349-357.
Roll, Richard, 1977, A critique of the asset pricing theory's tests - part 1: On past and potential
testability of the theory, Journal of Financial Economics 4, 129-176.
Roll, Richard, 1978, Ambiguity when performance is measured by the security market line, Journal of
Finance 33, 1051-1069.
Roll, Richard and S. A. Ross, 1980, An empirical investigation of the Arbitrage Pricing Theory, Journal
of Finance 35, 1073-1103.
Ross, S. A., 1976, The Arbitrage Pricing Theory of Capital Asset Pricing, Journal of Economic Theory
13, 341-60.
Ross, S., 1977, Risk, return and arbitrage, in Friend, I. and J. Bicksler, eds.: Risk and Return in Finance
(Ballinger, Cambridge, Massachusetts).
Rubinstein, Mark, 1974, An aggregation theorem for securities markets, Journal of Financial

93

Economics 1, 225-244.
Rubinstein, Mark, 1976, The valuation of uncertain income streams and the pricing of options, Bell
Journal of Economics and Management Science 7, 407-425.
Sarkissian, Sergei, 2002, Incomplete consumption risk sharing and currency risk premiums, Review of
Financial Studies (forthcoming)
Scholes, M. and J. Williams, 1977, Estimating beta from nonsynchronous data, Journal of Financial
Economics 5, 309-327.
Shanken, Jay, 1985, Multivariate Tests of portfolio efficiency when the zero beta rate is unknown,
Journal of Financial Economics 14, 327-348.
Shanken, Jay, 1986, Testing portfolio efficiency when the zero beta rate is unknown: a note, Journal of
Finance 41, 269-276.
Shanken, Jay, 1987, Multivariate Proxies and Asset Pricing Relations: Living with the Roll Critique,
Journal of Financial Economics 18, 91-110.
Shanken, Jay, 1992, On the estimation of beta pricing models, Review of Financial Studies 5, 1-34.
Sharpe, W. F., 1964, Capital Asset Prices: A Theory of Market Equilibrium under Conditions of Risk,
Journal of Finance 19, 425-442.
Sharpe, William F., 1977, The capital asset pricing model: A muti-beta interpretation, in H. Levy and
M. Sarnat, eds, Financial Decision making under uncertainty, Academic Press: New York.
Simin, Timothy, 2002, The (poor) predictive performance of asset pricing models, working paper, the
Pennsylvania State University.
Singleton, K., 1990, Specification and estimation of intertemporal asset pricing models, Handbook of
Monetary Economics, B. Freidman and F. Hahn, eds., North Holland (the Netherlands).
Solnik, Bruno, 1993, The unconditional performance of international asset allocation strategies using
conditioning information, Journal of Empirical Finance 1, 33-55.
Stambaugh, Robert F., 1982, On the exlusio of assets from tests of the two-parameter model, Journal of
Finanical Economics 10, 235-268.

94

Stambaugh, 1983, Testing the CAPM with broader market indexes: A problem of mean deficiency,
Journal of Banking and Finance 7, 5-16.
Stambaugh, Robert S., 1999, Predictive regressions, Journal of Financial Economics 54, 315-421.
Starks, L., 1987, Performance incentive fees: an agency theoretic approach. Journal of Financial and
Quantitative Analysis 22, 17-32.
Snow, Karl N., 1991, Diagnosing asset pricing models using the distribution of asset returns, Journal of
Finance 46, 955-983.
Theil, Henri, 1971, Principles of econometrics, John Wiley and Sons, New York.
Treynor, J., Mazuy, K., 1966. Can mutual funds outguess the market?. Harvard Business Review 44,
131-136.
Wheatley, Simon, 1989, A critique of latent variable tests of asset pricing models, Journal of Financial
Economics 23, 325-338.
Wilson, Robert B., 1968, The Theory of Syndicates, Econometrica 36, 119-131.
Zeldes, Stephen, 1989, Consumption and liquidity constraints: An empirical investigation, Journal of
Political Economy 97, 305-346.
Zheng, L., 1999, Is money smart? A study of mutual fund investors' fund selection ability, Journal of
Finance 54, 901-933.

