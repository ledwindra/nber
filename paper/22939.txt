NBER WORKING PAPER SERIES

ASYMMETRIC EFFECTS OF NON-PECUNIARY SIGNALS ON SEARCH AND
PURCHASE BEHAVIOR FOR ENERGY-EFFICIENT DURABLE GOODS
J. Scott Holladay
Jacob LaRiviere
David M. Novgorodsky
Michael Price
Working Paper 22939
http://www.nber.org/papers/w22939

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2016

We thank the Baker Center at University of Tennessee and Becker Center at University of
Chicago for funding support and help in executing the experiment. Wooju Lee provided excellent
research assistance. We thank our private and public sector partners for their support. Ben
Gilbert, Michael Greenstone, Grant Jacobsen, Steven Levitt, John List, Preston McAfee, Justin
Rao, and Dmitry Taubinksy and seminar participants at the 2014 EEE NBER Summer Institute,
2014 ERE World Congress, 2014 Camp Resources, 2015 AEA meetings, 2015 Fall APPAM
Conference, University of Wyoming and UC Davis all provided important feedback that greatly
improved this paper. Any mistakes are ours. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
¬© 2016 by J. Scott Holladay, Jacob LaRiviere, David M. Novgorodsky, and Michael Price. All
rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without
explicit permission provided that full credit, including ¬© notice, is given to the source.

Asymmetric Effects of Non-Pecuniary Signals on Search and Purchase Behavior for Energy-Efficient
Durable Goods
J. Scott Holladay, Jacob LaRiviere, David M. Novgorodsky, and Michael Price
NBER Working Paper No. 22939
December 2016
JEL No. C93,D01,D83,Q41
ABSTRACT
We report the results of a field experiment where we exogenously vary the use of social
comparisons "nudges" and subsidies for participation in an in-home energy audit program, and
follow subjects through to the subsequent purchase of durable goods. We therefore can compare
the causal effect of financial incentives and nudges along two margins, audits, which we liken to
search, and purchase of durables. Using data on nearly 100,000 households, we document an
asymmetry; nudges increase audits, but lead to lower rates of purchase. We find no evidence of a
differential response for those offered a financial incentive. These differences suggest
heterogeneity in the motives of the marginal consumer induced by nudges versus prices.

J. Scott Holladay
The University of Tennessee
515 Stokely Management Center
Knoxville, TN 37996
jhollad3@utk.edu
Jacob LaRiviere
Microsoft
Department of Economics
University of Tennessee
525 Stokely Management Center
Knoxville, TN 37996-0550
jlariv@microsoft.com

David M. Novgorodsky
University of Chicago
Saieh Hall for Economics
1126 E. 59th St.
Chicago IL, 60637
davidnov@uchicago.edu
Michael Price
Experimental Economics Center
Andrew Young School of Policy Studies
Georgia State University
P.O. Box 3992
Atlanta, GA 30302-3992
and NBER
mprice25@gsu.edu

1

Introduction

There is a growing body of literature documenting that individuals respond to social comparisons
that provide informative signals about the actions or beliefs of reference groups. Specifically, such
messages have been shown to influence a wide array of activities from residential electricity and
water use (Allcott, 2011; Brent et al., 2015; Costa and Kahn, 2013; Ferraro and Price, 2013; Gromet
et al., 2013; Ito et al., 2013; Schutlz et al., 2007) to charitable giving (Chen et al., 2010; Frey and
Meier, 2004; Shang and Croson, 2009) and retirement savings (Beshears et al., 2015; Esther Duflo,
2003). To date, this literature has focused predominantly on decisions along an intensive margin
(e.g., changes in electricity use, changes in water use, or average contribution levels). A less studied
question is the impact of such signals on patterns of information acquisition and subsequent decisions
along an extensive margin (e.g., the purchase of energy-saving technologies).
In this paper, we report the results of a natural field experiment designed to link the content of a
targeted advertisement to search intensity and search to subsequent purchase decisions. Our context
is participation in a utility-sponsored in-home energy audit program (IHEA) and the resulting
purchase of energy-efficient durable goods.1 We compare the relative impact of pecuniary incentives,
in the form of randomly-varied subsidies2 , with the effects of informative nudges in the form of social
comparisons that vary the unit of comparison (e.g., monthly kWh of use, monthly expenditures
for energy, or CO2 emissions due to energy use) on the likelihood a household signs up for an
IHEA (e.g., search for information about energy savings) and subsequently purchases a range of
energy-efficient durable goods.

1

We view participation in an IHEA as an act akin to costly search behavior: a household must pay a cost (in both
money and time) to reduce uncertainty in the expected monetary benefit of a durable good investment. In doing so,
we build upon prior work showing that many individuals systematically underestimate the relative energy intensity of
many durables in the home (Attari et al., 2010) and a related body of work showing that individuals have difficulty
calculating the long-run cost savings from purchasing energy efficient durable goods (Allcott and Greenstone, 2012).
2
We use the terms ‚Äúsubsidy‚Äù and ‚Äúrebate‚Äù interchangeably throughout.

2

In the field experiment, we partnered with a utility and electricity wholesaler to send letters
encouraging the household to sign-up for an in-home energy audit. Our experiment was conducted in
a medium-sized metropolitan statistical area (MSA) in the southeastern United States and includes
information on IHEA participation for a large control group that did not receive any letter or
encouragement to schedule such. During the experiment, we mailed letters to approximately 51,000
residential consumers over five waves. All letters stated that any durable good purchases by the
household that satisfied a broad range of criteria would be eligible for a rebate that provided a
dollar-for-dollar subsidy on the first $1000 spent on eligible durables (i.e., households that completed
an IHEA would be eligible for a $500 rebate on durable good purchases).3
Our experiment includes 12 different treatments arranged in a four-by-three design. Each
household in the treatment group received a letter with one of four possible signals of historical
electricity use and one of three possible rebate levels offered for scheduling an IHEA. The signals
can broadly be delineated by: a) whether or not a household‚Äôs own use was presented together with
average historical use in their nine-digit zip code (No Comparison vs. Comparison), and b) the
unit used to convey historical use (monthly kWHs, monthly expenditures on electricity, or CO2
emissions).4 Households receiving the No Comparison letter were provided information on their
average monthly consumption in kWhs over the prior twelve month period. Households receiving
one of the Comparison letters were provided this same information along with information on the
average monthly use of counterparts in their local area. Information in the Comparison treatments
was conveyed in one of three forms; (i) monthly kWhs consumed, (ii) monthly expenditures in
dollars, or (iii) pounds of CO2 attributable to their monthly electricity consumption. We cross the
comparison types with treatments that offer the recipient a $20 or $50 gift card that can be used to

3

Eligible durable goods include new energy-saving windows, insulation, duct sealing, etc.
We use nine-digit zip code averages for the local areas with 10 or more households. For smaller nine-digit zip
areas we use five-digit zip averages. Throughout, wherever we refer to nine-digit zip codes, this caveat applies.
4

3

offset the cost of the IHEA which was $50 over the entirety of the study period. In this regard, our
subsidy treatment introduced random variation in the price of the audit.
Our design and context allow us to overcome several challenges faced in prior work exploring
the role of targeted messages (advertisements) on the economic behaviors we study. First, our
design permits us to separately estimate the effect of the informational content of a message (i.e.,
a description of the program or information about a household‚Äôs average electricity use) and the
marginal effect of augmenting such messages to include a social comparison (i.e., information that
compares one‚Äôs own actions to the actions of like others) on search behavior. Second, we are able to
place a monetary value on social comparisons by comparing the effects of these treatments to the
effect of changing the price of the IHEA in our No Comparison treatment. Third, households in our
subsidy treatment were required to schedule the IHEA within thirty days of receiving our letter to
qualify for the gift card. By design, our program places a time limit on potential treatment effects
which allows us to circumvent the challenge of open-ended search (Lewis and Rao, 2015). Finally,
while the regional wholesaler schedules initial audits and provides a list of approved contractors, they
do not follow up with households to encourage them to complete the recommended installations; it is
the household‚Äôs responsibility to qualify for the $500 rebate. Our context is thus an ideal setting to
observe the impact of our treatments on both search intensity and subsequent purchase decisions.5
We find three main results for treatment‚Äôs impact on IHEA uptake. First, receiving a letter
that provided information on the IHEA program and a household‚Äôs average consumption, but no
nudge or subsidy, had no significant impact on IHEA uptake. Second, ‚Äúnudges‚Äù in the form of
social comparisons are an effective strategy for promoting IHEAs. Households that receive either
a kWh or expenditure comparison were more than twice as likely to schedule an IHEA than are

5

In this regard, our approach differs from the IHEA program studied in Allcott and Greenstone (2015) which
provides more support for households following the initial audit as a way to increase both participation in the IHEA
and subsequent purchases.

4

counterparts in the control group. Finally, consistent with the literature we find demand for IHEAs
is somewhat inelastic: subsidizing audits led to statistically significant increases in IHEA rates,
but even when audits were costless in monetary terms ($50 subsidy) rates were still low. We can,
though, price out a kWh and expenditure comparison to be $35-$50 in subsidies based upon our
point estimates in terms of IHEA uptake.
With respect to durable good purchases, we find that households in the both the kWh and
expenditure treatments were less likely to make an installation than were counterparts in the control.
Importantly, these differences hold whether we examine installations conditioned on completing
an IHEA or examine the unconditional effect of treatment on the purchase decision. Conversely,
purchase rates for households in our subsidy treatments are statistically indistinguishable from those
observed amongst the control group. Taken jointly, these differences suggest heterogeneity in the
motives of the marginal consumer that is induced to take the audit across treatments. We find
evidence that nudges were less effective at inducing installations than subsidies but more effective
at leading to additional audits.
The findings highlight that what motivates the marginal auditor (e.g., search behavior) versus
the marginal durable goods installer (e.g., purchase behavior) can vary as a function of pecuniary
and non-pecuniary signals. For example, in our experiment a $50 subsidy and kWh comparison had
similar impacts on IHEAs but different impacts on durable good purchase. Our finding is consistent
with there not being a one-to-one mapping between social comparisons and price signals across
all microeconomic behavior. We don‚Äôt view this finding as particularly surprising however as the
literature remains unsettled as to all the precise mechanisms through which social comparisons
operate despite recent advances (Allcott and Kessler, 2015).
The next section motivates IHEAs as a form of search and describes the field experiment. Section
3 presents data. Section 4 presents results and offers discussion. Section 5 briefly concludes.

5

2

Audits as Search

We follow Gilbert et al. (2015) and argue that IHEAs are a form of search. The canonical search
literature motivates search in the context of a consumer acquiring product information via brick and
mortar shopping before making a purchase (Rothschild, 1974). However, brick and mortar shopping
is not the only way an individual can engage in search. Seeking expert advice can also be modeled
as a form of search (e.g., Pitchik and Schotter (1987) and Edo and Szentes (2007)). In such models,
the agent seeking advice is uncertain about the state of the world but can learn about it by paying
for an informative signal from an expert. As a result, the agent undertakes a costly action ‚Äì paying
an expert ‚Äì as a way to acquire information before making a purchase decision.
When a consumer signs up for an IHEA, they are seeking expert advice about the benefits of
making an investment in an energy-efficient durable good. During an IHEA, a paid professional
enters a home and uses specialized equipment to identify a range of durable good investments that,
if made, would allow the household to save electricity and get the greatest possible return on their
investment.6 However, many individuals may incorrectly perceive the relative energy intensity
of many actions within the home (Attari et al., 2010) or have difficulty calculating the long-run
cost savings from purchasing energy efficient durables (Allcott and Greenstone, 2012; Palmer and
Walls, 2015). An important function of an IHEA is that the auditor helps resolve such uncertainty
and, in doing so, better anchors a household‚Äôs expectations about the net present value (NPV) of
investments in various durable goods.7
Our experimental treatments are designed to introduce variation in the expected net benefits of
scheduling an audit and/or introduce new motives for search (social norms). In the Appendix, we

6

Auditors may also provide advice on ways to reduce electricity consumption without changing the stock of durable
goods in the home - e.g., by setting thermostats at a higher temperature during summer months.
7
While McKinsey (2009) documents large variability in the implied rate of return across the spectrum of durable
good investments that may be suggested to a household during an IHEA, auditors in our study area limit suggested
installs and recommend 3 to 5 items that are ordered based on the implicit rate of return.

6

walk through a simple theoretical model of audits as a form of search in line with Gilbert et al. (2015).
We also discuss our ability to parse between the various channels through which our treatments
shift expected audit benefits in greater detail below. For example, variation in the framing of the
social comparison allow us to measure whether households weigh information differently when it
highlights expected private benefits (expenditures) as opposed to public benefits (carbon emissions)
on search and associated changes in consumption.
There are direct links between our study and measuring the returns from advertising. In general,
there are two key challenges to measuring returns to advertising. The first is the data challenge of
linking exogenous variation in advertising to revealed preference data on search and subsequently
revealed preference sales data. The second is the nature of search and purchase: especially for high
cost items like durable goods there is a significant amount of search so that even after an advertising
campaign, a household may delay their purchase of a good while gathering information. Our field
experiment, described in the next section, allows us to overcome both of these problems for three
reasons. First, we randomly vary both the price of search and non-price signals (e.g., nudges) and
are able to use administrative records to link treatment to a particular customer. This allows us to
identify and directly compare the effect of the various messages on search intensity and subsequent
purchase decisions. Second, we exploit a key feature of the IHEA program to track both search (e.g.,
audit uptake) and purchase (e.g., home durable good upgrades) for the same user over time. In
our study region, households were required to have a third party auditor verify installations if they
wished to claim the available rebates on purchase. We are thus able to identify treatment‚Äôs impact
on search and purchase behavior using administrative records. Third, our pecuniary treatment,
audit cost subsidies, sets a bound on the maximum length of time available to subjects to redeem
the subsidy. From a design perspective, then, we are well-suited to address time lag challenges
noted in the literature and identify the effects of our treatments on both search intensity and the

7

resulting purchase decisions (Lewis and Rao, 2015).
It is also important to place our paper in the context of the larger literature on nudges and
economic behavior. There is a growing body of literature showing that social norms and specifically
‚Äúnudges‚Äù in the form of social comparisons can be used to change patterns of electricity and water
consumption (Allcott, 2011; Costa and Kahn, 2013; Brent et al., 2015; Ferraro and Price, 2013; Ito
et al., 2013; Wichman et al., 2016). Moreover, given results from Ferraro et al. (2011), Bernedo et al.
(2014), Allcott and Rodgers (2014) and Dolan and Metcalfe (2015) showing that social comparisons
can have persistent effects on patterns of electricity and water use, it is reasonable to posit that
such signals may influence patterns of search and subsequent purchase of more efficient durable
goods rather than exclusively working through long-run changes in behavior. We investigate this
directly in our paper by focusing on energy-efficient durable good upgrades.
We investigate nudges‚Äô ability to cause households to invest in the energy efficiency of their
home, and in doing so add to the nudge and social norm literature in several novel ways. First,
we investigate IHEAs and durable good investment decisions available to all households- not just
low income households as in Fowlie et al. (2015). Second, our treatments exogenously vary the use
of nudges, the form of nudges (private versus social frames) and the price of IHEAs providing an
apples-to-apples comparison of nudges in terms of dollars. Third, because we follow subjects through
the audit process to purchase, we can determine if subjects ‚Äúnudged‚Äù into audits behave similarly
in purchase space as subjects ‚Äúpriced‚Äù in through subsidies. Fourth, because we use comparisons
highlighting both private aspects ($ and kWh) and public aspects (CO2 ) of electricity consumption
we are able to identify how framing of nudges impacts their effectiveness in the context of IHEAs.

8

3

The IHEA Program and Experimental Design

IHEAs are widely-available programs in which a trained expert with specialized equipment examines
a home and recommends the most cost-effective investments a household could make to save money
on electricity bills. Local utilities and policymakers across the U.S. have implemented a range of
programs designed to increase the rate of IHEAs as a means to stimulate the purchase of energyefficient durables (e.g., NYSERDA, TVA Energy Right, New Jersey Clean Energy Program, and
Mass Save, among others) to reduce demand for electricity and mitigate externalities associated
with its consumption. Our study area is reflective of this national trend. Like other areas, our area
exhibits annual rates of IHEAs that are low (less than 1 percent), which has prompted the regional
wholesaler to pursue a variety of ways to increase participation including the ideas tested in our
experiment (Palmer and Walls, 2015).
Our field experiment was conducted with the support of an electric utility and their primary
wholesaler which funds and administers the IHEA program. The program is branded and passively
advertised on the utility‚Äôs website.8 At the time of our experiment, the only way to schedule an
audit was for a customer to call a hotline managed by the regional wholesaler and arrange for an
auditor to come to their home at a predetermined time. At the end of the experiment, we were
provided the universe of call logs for our sample area. This allows us to observe and record all
audits scheduled in our sample area during the course of our experiment.
During an audit, a professionally trained auditor comes to the customer‚Äôs home and performs a
visual inspection.9 The auditor typically inspects the home‚Äôs attic, basement and HVAC system.
At the time of our experiment, the audit took approximately half an hour to complete and the

8

Over the course of our experiment, there was no change in the marketing of the program by either our partner
utility or the wholesaler.
9
Some IHEA programs use trained engineers and infrared cameras or blower door tests to find sources of energy
leakage. The program we investigate is intended to be a low cost, less time-intensive audit and provides more general
information.

9

homeowner was required to be present during this time. The audit cost $50 but the amount was
refunded if the customer made a recommended investment.
At the end of the audit, the auditor presented the customer with a list of suggested investments
that could include improved insulation in the attic, replacing windows or sealing HVAC system
ducts. Each customer was presented with the same list of potential investments and provided
informal suggestions about which investments were likely to provide the greatest return for them
specifically. In addition, customers were provided a list of approved contractors who could perform
the work and informed that they would receive a dollar-for-dollar subsidy of up to $500 for any
investment on the list.
To receive the durable good subsidy, households were required to schedule a follow-up audit and
provide confirmation from the auditor that the installation was done properly. The follow-up audits
were scheduled by phone and noted in the log book as a verification appointment. As a result, we
have administrative records on both audits and subsequent purchases in the audit program.

3.1

Experimental Design

As noted above, our field experiment was conducted with the support of an electric utility and their
primary wholesaler. Our sample area was a medium-sized MSA in the U.S. served almost entirely
by the same utility.10 The goal of the field experiment is to identify how subsidies and different
forms of comparative information affect the 1) probability of signing up for an IHEA and 2) the
probability of subsequently making an installation. Importantly, we worked with the utility and the
wholesaler in designing the experiment so as to maintain consistency with their project goals.
Figure 1 provides a graphical depiction of the timing of subjects‚Äô decisions in our field experiment.

10

In this area, the utility provides electricity to all residential customers via average cost pricing; there is no block
structure for residential consumers. During the study period, the retail price of electricity for households was constant.

10

As noted in the figure, households were first randomized into either a control group or one of twelve
treatment groups that received a letter inviting them to sign up for an in-home audit. Households
then determined whether or not they wished to sign up for the IHEA and call the auditing agency
to schedule the audit.11 Conditional on completing an audit, households had the opportunity to
purchase and install a range of energy-efficient technologies that were eligible for a rebate from the
auditing agency. To receive the rebate, the household had to schedule a follow-up audit to verify
the installation.
Our research design compares the relative impact of pecuniary incentives (subsidies that lower
the cost of the IHEA) with the effects of social comparisons that convey relative consumption
from three different frames; (i) average monthly kWh, (ii) average monthly expenditures, and (iii)
CO2 emissions related to average monthly use. The various treatment letters were designed in
collaboration with the regional wholesaler. Because we cannot observe whether letters are opened
or not we estimate intent-to-treat effects (ITTs) in all but one case (probability of installation
conditional on audit).
Table 1 depicts the four-by-three treatment design utilized in our natural field experiment.
Cell entries reflect a unique treatment letter (described below) and the corresponding number of
households that received the given letter type. For example, the upper left corner of the table
corresponds to our baseline - ‚ÄúNo Comparison, No Subsidy‚Äù - treatment letter which was mailed to
3,923 distinct households. This treatment compared to the large control group allows us to estimate
the informative effects of the letter on audits and installs. In total, we sent out over 50,000 letters
and observe decisions for a large control group who did not receive a letter during the course of
the experiment. Table 1 also shows statistically insignificant differences in average pre-treatment

11

Households in the control group did not receive a letter encouraging them to sign up for an IHEA but had the
same opportunity to participate in the program. Moreover, the procedure for scheduling an audit and the nature of
the audits themselves were identical for households in the treatment and control groups.

11

electricity usage by subject.
Treatment letters were printed on the electricity wholesaler‚Äôs official letterhead (e.g., the entity
overseeing IHEAs in the area) and sent via first-class mail in envelopes from the wholesaler to
maximize the likelihood that they would be opened by the household and associated with the IHEA
program. Letters were mailed across five waves starting in December 2012 through August 2013.
Our utility partners required the waves to be spread over time to avoid exceeding the capacity of
the existing staff of auditors. Figure 2 shows the wave-by-wave timing in a Gantt chart. While
the figure describes the period of study for subjects getting audits attributable to treatment, for
experimental design reasons discussed below, we observe all installations through mid-December
2013. We provide evidence below that this is sufficient coverage for our experiment.
Table 2 describes the samples sizes and date of mailing for each treatment wave. It also reports
the number of households in each treatment type in each wave. Each pilot wave has around four
thousand households and the three main waves varied between fifteen and twenty thousand treated
households. In all, approximately 51,000 households are in one of twelve treatment groups in
addition to a large control group of roughly 50,000 households (roughly 10,000 of which are held as
explicitly within-wave control units).
The sample sizes are nonlinear across subsidy levels to improve power to detect nonlinear
response to subsidy levels; in particular, we employed a weighted design over the various subsidy
levels (25%-50%-25%) which allows us to identify non-linear effects of price on likelihood of signing
up for an IHEA and is the optimal sample arrangement if we believe that the underlying demand
function is quadratic. Waves 1 and 2 did not include CO2 treatment types of any subsidy amount
because of low uptake during the pilots.

12

3.1.1

No Comparison Letter

Our baseline letter provided households an ‚Äúinformation-only‚Äù message designed to encourage the
recipient to sign-up for an IHEA (see Appendix). The letter included a brief description of the
IHEA program along with a phone number and web address that the household could use to get
more information about the program. Specifically, the letter describes the IHEA program as follows:
There‚Äôs no place like home, and there‚Äôs no time like now to make your home
more energy efficient. You can conserve energy, save on utility bills, and get
cash rebates by participating in....
If you sign up for an IHEA, a ... Certified Energy Advisor will visit your
home at a time convenient for you. The advisor will recommend cost-effective
ways to increase your home‚Äôs energy efficiency and will install free CFLs and
low-flow water saving measures if you choose.
...evaluation fee is $150 (currently with an instant rebate of $100). And
you will receive the remaining $50 fee back if you spend $150 or more on
qualifying improvements. You will also receive matching rebates of up to $500
for installing eligible improvements....
In addition to information on the IHEA program, our baseline letter included information on
the household‚Äôs average monthly consumption during the preceding year. Such information was
conveyed using a bar chart12 which was a statement reading ‚Äú...Your average energy consumption
over the past year: XXX kWh...‚Äù We calculated average monthly consumption using billing records
shared with us by our partner utility. Specifically, we used monthly billing data for the period July

12
This bar chart and those corresponding to our three other content-related treatments are depicted in Figure 3
side-by-side.

13

2011 through July 2012 to calculate a household-specific measure of average monthly consumption.13

3.1.2

The Social Comparison Letters

We build upon the social comparison and ‚Äúnudge‚Äù literature by augmenting our baseline letter to
include a comparison of the household‚Äôs average electricity use to the average use of other households
in their nine-digit zip code.14
Information in the social comparison treatments were conveyed in one of three forms; (i) monthly
kWhs consumed, (ii) monthly expenditures in dollars, or (iii) pounds of CO2 attributable to
their monthly electricity consumption.15 We chose these three frames to identify if households
respond to nudges which make different aspects of electrity consumption more or less salient: use
(kWh), expenditures ($) or a public bad associated with electricity consumption (CO2 emissions).
Differential responses for search and purchase due to different frames would provide information
about what aspects of a nudge induce subjects into changing their behavior. We included a bar
chart to illustrate the comparison graphically. Below the bar chart, we included a statement reading:
Your Average Energy Consumption

XXXkWh

Local Area Homes‚Äô Average Energy Consumption

XXXkWh

You used XX percent more (less) energy than other area homes
Our choice of nine-digit zip rather than a higher level of aggregation as the comparison group
was informed by a large body of work in social psychology showing that comparative signals are

13

Households in our sample area receive bills from our partner utility on a monthly basis. While monthly bills
display consumption for each of the previous 12 months, they do not provide information on average consumption
over the period.
14
Recall that for subjects with fewer than 10 households in a nine-digit zip, we used five-digit zip code averages.
15
To our knowledge, ours is the first paper to explore how varying the way in which comparative information is
framed impacts subsequent behavior. While Allcott and Greenstone (2015) present results from a field experiment
that uses a variety of ‚Äúnudges‚Äù to induce participation in an IHEA program, the aim of their paper is to quantify
the welfare implications of such programs rather than explore whether and how such strategies influence patterns of
search and subsequent purchase decisions.

14

most effective when the reference group is more proximate to the individual receiving the signal (e.g.,
Trope and Liberman (2010).) We framed the percentile text depending on whether a household
used more or less electricity than their local area. We interpret such framing as a way to emphasize
how many people do or do not engage in the targeted behavior (e.g., Cialdini et al. (2006) and
Schultz et al. (2007))

3.1.3

The Subsidy Letters

Our final treatment dimension is designed to introduce experimental variation in the expected net
benefit of an in-home audit. To do so, we augment the baseline and social comparison letters to
include a rebate for households that sign-up for an IHEA. Specifically, our subsidy treatments offered
the recipient a $20 or $50 gift card that could be used to offset the cost of the IHEA. Information
about the subsidy was included in the final sentence of the third paragraph which in part reads:
As an additional thank you for participating, if you have an In-Home Energy
Evaluation within 30 days from the date of this letter you will receive a $XX
gift card.
Before proceeding to the results section, a few key features of our experimental design should
be highlighted. First, within each wave of the experiment, treatment letters were mailed on the
same day.16 Second, there were around 3,000 letters that were returned to sender and thus not
delivered. We dropped these households from our empirical analysis. Third, households that moved
or had their electricity service cut off due to delinquent bills during the course of our experiment
were dropped from the analysis. Finally, all treatment letters included a unique code located at the
bottom left corner. The call center recorded this code when scheduling an IHEA which allowed us

16

One minor exeption occurred during the first pilot during which letters were sent across two days - December
18,2012 and December 21, 2012.

15

to match households that scheduled an IHEA to their respective treatment group.

4

Data and Experimental Results

Each treatment letter had a unique identifier that matched the specific letter (and therefore treatment
group) to an address. We entered into a data sharing agreement with the auditing agency and
wholesaler in order to measure how treatment affected audits and installations. To do so, we first
matched the universe of scheduled IHEAs to the randomized treatment and control assignments
based on the address of the household.17 We next linked audit scheduling with subsequent purchase
decisions, using data from the follow-up audits and the installations verified during this audit.
Letters in the subsidy treatment contained a clause noting that to guarantee the subsidy the
household had to call and schedule an IHEA within 30 days of receiving the letter.18 Due to a
small number of scheduling conflicts and at the suggestion of the auditor, we honored the subsidies
for up to sixty days of sending the letter. For each household, we thus limit the post-intervention
period to a fixed period of sixty days following the mailing of any treatment letter to estimate upper
bounds for audit uptake treatment effects. All households in the area to whom this utility provides
electricity (approximately 100,000 total) were subject to randomized treatment assignment.
There are two sets of results from the IHEA field experiment. The first identifies the effect of
treatment on IHEA participation. The second set of results identifies the effect of treatment on
installations. There are two parts to the installation results: how treatment impacts the likelihood
of a purchase and how treatment impacts the timing of installs relative to control households.

17
Our randomization was a block randomization on a household‚Äôs mean electricity use in the preceding year with
approximate blocking on which decile a household‚Äôs mean use in the preceding year falls into among households in its
local area. We summarize the results of this block randomization with the mean pre-treatment use in Table 1 as well
as the distribution of treatment assignment in Figure A5 in the Appendix.
18
Importantly, this allows us to verify the effect of advertisements (treatment) on search. Other studies note that
not being able to place time limits on search complicates the problem of estimating the effects of advertisements on
purchase (Lewis and Rao, 2015).

16

We performed power tests before implementing our experiment to gauge the likelihood of finding
significant results. The results of those power tests are presented in the Appendix. Due to the stated
experience of the audit providers with advertising campaigns, we designed the experiment to detect
treatment effects which double baseline audit and installation rates. Those results suggest that our
sample size is sufficient to detect effects of treatment when all treatment groups are aggregated
into one group (least granular), as well as when social comparison treatment effects are additively
separable in price treatment effects and vice versa (more granular). We therefore use an empirical
specification which allows a unique estimate for each comparison treatment and each subsidy level
by using indicators for each type of comparison and each level of subsidy (but not the interaction).19

4.1

Search: Treatment on IHEA Uptake

The primary goal of the field experiment is to provide an apples-to-apples comparison of pecuniary
incentives and informative ‚Äúnudges‚Äù on search (e.g., IHEA uptake) and purchase behavior (e.g.,
durable good installation). Given the explicit time limitation built into our pecuniary treatments,
we focus on IHEA uptake rates in the two months following treatment.20 As a result the two month
audit uptake rate is the primary statistic of interest. As a benchmark, the two month audit uptake
rate for households in the meta-control group, the right counterfactual for our analysis, is .0011.
In Table 3 we report raw 60 day IHEA uptake rates across treatments over the experimental
window.21 Columns show different subsidy treatments and rows show different comparison treatments.
There are several important points regarding Table 3. First, overall effects across all treatments were

19
We lack power to estimate 12 unique comparison-subsidy treatment effects to gauge the impacts of the interaction
of comparison and price effects but report those results in the Appendix for completeness; they are consistent with
the main results presented here and statistically significant in several cases.
20
Recall that, by design, households in our subsidy treatments had to schedule an IHEA within 30 days of receiving
the letter to be eligible for the gift card.
21
Note that Table 3 (as well as 4) drops eight IHEAs unmatched because they either occurred during a break in the
billing time series or occurred precisely on the last day of a household‚Äôs final bill in the time series.

17

modest, not quite doubling two month uptake rates (.0019 relative to .0011). This is consistent with
the larger literature on audit uptake which finds inducing additional audits is challenging (Fowlie et
al., 2015; Palmer and Walls, 2015). Second, the ‚ÄúNo Comparison-No Subsidy‚Äù treatment, which
only included information on the audit itself, did nothing to increase uptake and potentially even
decreased audit uptake (.0008 versus .0011). We don‚Äôt view this as strong evidence on a significant
decrease, though, given the relatively small size of the ‚ÄúNo Comparison-No Subsidy‚Äù treatment
cell. Third, expenditure and kWh comparisons both have a positive impact on IHEA uptake and
those impacts are identical. CO2 comparisons look to have a no impact on IHEA uptake. This
is consistent with findings from the larger literature that social comparisons can induce economic
action (Allcott, 2011; Ferraro and Price, 2013) but that different frames can asymmetrically impact
behavior (Chen and Li, 2009; Chen et al., 2010). Fourth, subsidies increased IHEA uptake but not
by as much as comparisons, and there is no consistent evidence for an impact of moving from the
$20 to $50 subsidy. This third and fourth point taken together imply that some social norms can be
more valuable than either a $20 or $50 subsidy.
To examine the statistical significance of these findings and control for seasonality/differences
in IHEA participation across waves of the experiment, we proceed from the suggestive results in
Table 3 to regression-adjusted results. In such models, we separately estimate the average ITT
effect of receiving any letter (which we typically associate with a variable called Any Letter) and
the marginal ITT effect of different content framings (which we typically associate with a set of
variables called kWh Comparison, $ Comparison, and CO2 Comparison).22
In the estimation we collapse the panel data series to a cross sectional data series with wave-level

22

While our interest is in analyzing search, we are evaluating a relevant policy instrument at the same time. In
this vein, note that with any mailing, no amount of targeting on the part of policymaker solves the unobservable
opening of mail, so the ITT effect is also a policy relevant treatment effect. Nonetheless, our coefficients inevitably
underestimate the average treatment effect on the treated.

18

treatment and control audit uptake indicators defined to give an apples-to-apples comparison
between treatment and control groups given both multiple treatment waves and limited treatment
windows to schedule an audit (e.g., 60 days). We‚Äôve estimated the same specification at the month
level and all results are similar but we view this as conceptually easier to interpret. We also use
the entire set of super-control households randomly assigned to different waves. This gives roughly
99,000 subject households in the full estimating sample. In sum, we perform our main estimating
specification via a cross-sectional OLS regression:

1{IHEAi } = Œ± + œâw + ŒΩtz + 1{Any Letteri }Œ≥ +

X

1{f Comparisoni }Œ≤f

f ‚àà{kWh, $, CO2 }

+ 1{$20 subsidyi }Œ¥1 + 1{$50 subsidyi }Œ¥2 + i .

(1)

1{IHEAi } is an indicator which denotes whether household i conducted an IHEA with two months of
being treated. 1{Any Letteri } is an indicator variable that takes the value of one if a household was
randomized to receive any letter. A similar definition applies for each framing f in 1{f Comparisoni }
which allows for estimation of the marginal effect of each comparison on IHEA uptake. To explain
wave-specific variation in IHEA rates, we include wave fixed effects œâw . To explain some time-series
and spatial variation in IHEA rates and improve the precision of the estimated treatment effects, we
also include fixed effects ŒΩtz capturing features of the particular month in which the audit occurred
(t) and the particular five-digit zip code (z) where the household is located. This technique assures
proper weighting of control households and that treated households are never grouped as control
households (e.g., in the 61st day after a letter).
Given our baseline specification, the coefficient Œ≥ is the ‚Äúpure information‚Äù effect of receiving any
letter (e.g., without a social comparison) on bi-monthly IHEA rate. Œ≤f describes the marginal effect

19

for each framing f ‚àà {kWh, $, CO2 } - i.e., it captures the effect of the given framing in addition to
the pure information effect associated with receipt of a letter. Looking beyond non-pecuniary effects,
our baseline specification also allows us to estimate the causal effect of subsidies on IHEA uptake by
an indicator variable for each subsidy level (e.g., 1{$20 subsidyi }). Importantly, this specification
will allow us to identify the dollar-equivalent of a comparison (i.e., a ‚Äúnudge‚Äù) by comparing the
marginal effect of a subsidy to each Œ≤f .
Table 4 shows the coefficient estimates from estimating equation (1). We estimate the ITT effect
for the full sample in columns 1 and 2. Column 1 does not include controls for waves (œâw ) or for
audit month-of-year by 5-digit-zip (ŒΩtz ) fixed effects whereas column 2 does. Differences in sample
sizes are driven by singleton households within the fixed effects. We report results for specifications
that parse the sample above and below median electricity use within a local area (columns 3 and 4)
and above and below median electricity use for the sample area as a whole (columns 5 and 6). Such
specifications allow us to explore whether the effects of our treatments differ across high and low
user groups. We note, though, that parsing the sample in this way greatly reduces statistical power
so we consider those results to be suggestive only. In each specification we use heteroskedasticity
robust standard errors.
For the full sample without controls (column 1) and with controls (column 2) we find that the
pure information treatment effect Œ≥ is an imprecisely estimated zero. Moving to marginal effects,
we find positive and significant effects of both the kWh and expenditure comparisons. The point
estimate of both kWh or expenditure comparisons are more than double that of the control group
in Column 1. Moreover, as in the raw data, we find no effect of a CO2 comparison on uptake. We
emphasize that these impacts are the marginal impact of a comparison relative to the exact same
information, including a subject‚Äôs own average energy usage, in the treatment letter. Parsing the
sample by above and below local (nine-digit zip) and MSA medians the effect of dollar comparisons

20

remains significant but only for energy users below the median. Subsidies had an impact for above
MSA-median households, though. While suggestive, due to lack of statistical power we don‚Äôt claim
strong inference from this result.
The impact of subsidies is positive but somewhat less consistent than the impact of social
comparisons. A $20 subsidy has a positive and statistically significant impact on IHEA uptake in
the regression without controls but becomes insignificant in the specification with controls. The
opposite is true for the $50 subsidy: it has an insignificant impact on IHEAs without controls and
significant with controls. We favor the regression with controls (column 2) since fixed effects increase
the signal to noise ratio in treatment.
The subsidy results in column 2 are consistent with economic intuition on subsidies and the
effectiveness of nudges. First, the point estimate for a $20 subsidy is less than a $50 subsidy.
However the two coefficients are not statistically different from each other. Second, we find that
point estimates for the statistically significant results in columns 1 and 2 put to dollar value of
either a kWh or expenditure ($) comparison at between $35 (column 1) and $50 (column 2). This
dollar value of a nudge is consistent with what we observe when we estimate this regression as a
panel (results available upon request and presented in earlier versions of this paper).
In sum, we find that non-pecuniary signals (expenditure and use comparisons) significantly
increase search intensity (audit uptake) in our experiment. Further, our results suggest that the
framing of the non-pecuniary signals mattered; only privately framed comparisons increased audit
uptake. CO2 comparisons have no statistically significant impact on IHEA uptake. We note that
we are somewhat less confident in this CO2 comparison result given there were only half as many
households in the CO2 treatment. We view this as important, though, because there is evidence
that the type of framing matters and our result is consistent with that (Chen and Li, 2009; Chen et
al., 2010; Costa and Kahn, 2013).

21

We acknowledge that monthly IHEA uptake is small in both our study area and the nation
(Palmer and Walls, 2015). Hence, even though our field experiment increased IHEA rates by over
100%, we still have few households conducting IHEAs. To place these effect sizes in context, our
IHEA uptake rates are actually similar to click-through rates for online banner advertisements
(Lewis and Rao, 2015). Even with over 50,000 households in the treatment, treatment induced 80
additional IHEAs. This is no surprise: even when fully subsidized, IHEAs impose a time cost on
households. For example, DellaVigna et al. (2016) find that households‚Äô time costs to be surveyed in
their homes are on the order of $35/hour. IHEAs must be scheduled in advance and, as mentioned
earlier, take roughly half an hour to complete. Thus, even when there is no expenditure for an
IHEA, there is still a non-trivial price for this kind of search. Taken at face value, our estimates
suggest that subsidies would need to be on the order of $67.50 in the location of our field experiment
in order to make IHEAs ‚Äúfree‚Äù for households (e.g., $67.50 = $50 IHEA price + $17.50 time cost).
These results allow us to perform a back-of-the-envelope calculation (assuming out point estimates
are externally valid) to determine the implied cost of this policy if it were widely implemented.23
We sent out out roughly 50,000 letters at 45 cents per letter (in 2012) for a total cost of $22,500.
Each audit therefore had an implicit cost of roughly $281. There are two ways to reduce this cost.
First, sending the letters by bulk would halve costs. Assuming bulk mail is opened at the same rate
and by the same types of households as first class mail, the costs drop to roughly $140/audit. Now
assume that instead of sending each treatment, only the most effective treatments were sent: either
kWh or expenditure comparisons and a $50 subsidy. Recalling that roughly 60% of households got
either a kWh or expenditure comparison, and only a small fraction both the $50 subsidy and a kWh
or expenditure comparison (e.g., .60*.25 = .15), the implied cost of using an optimized version of

23

Note that this back-of-the-envelope is not necessarily of scientific interest given that we care about installations
and not audits per se.

22

this policy is roughly $85 per audit. Paying the $50 subsidy increases the price of an audit using
this policy back to $135 per audit.

4.2

Purchase: Treatment on Installs

Next we test for treatment‚Äôs impact on installing a new durable good. Juxtaposing treatment‚Äôs effect
on durable good purchases with treatment‚Äôs effect on search in a unified field experiment is the main
contribution of the paper. Our context is also important for policy - if households in the treatment
group are more likely to sign up for an IHEA but less unlikely to actually make an installation, it
would suggest that both non-pecuniary signals (‚Äúnudges‚Äù in our case) and pecuniary incentives for
IHEA participation are cost-ineffective ways to induce households to make large energy-efficient
durable good upgrades. As a result, we focus on the behavior of ‚Äúnudged in‚Äù subjects versus ‚Äúpriced
in‚Äù subjects versus control subjects in terms of installation behavior.
As a first step we investigate the timing decision of treated versus control households who make
installations relative to when they schedule an audit. This provides a view of not just total effects
on installations but also to possible differences in those mechanisms. This is also important to
verify the internal validity of the experiment: our installation data are through Dec 15, 2013 and
the final wave of letters was sent on August 12, 2013. If there is a significant time gap between
audits and installations we may not have complete coverage and thus underestimate the likelihood
of installations. We investigate the impact of treatment on installations in great detail below, but
note that the likelihood of an installation conditional on an audit in control households is roughly
66%.
Figure 4 is a histogram illustrating the number of days between an initial IHEA and an
installation for all households in the experimental sample making an installation. The figure shows
two important characteristics of installation behavior: first, almost 50% of installations occur on

23

the same day as the audit. Second, almost all installations occur within three months of the initial
audit. This is reassuring given our data only runs for 120 days after the final wave of letters was
sent and the letters stated audits must be scheduled within 30 days of treatment.
Table 5 parses average installation timing by treatment and control group. Control households
have an average delay between initial audit and install of 41.5 days and treated households 27.6
days. This difference is preserved when only including the pilots and waves one and two. This
shows weak evidence that treatment decreases time to make an install. We exclude regression
results but note similar findings with statistically significant negative differences at the 10% level
for kWh comparisons only. This is consistent with the idea that treated households view the audit
and installation procedure as more salient: treated households act more quickly than untreated.
While we acknowledge truncation of the data in December 2013 would lead to downward bias in the
likelihood of installations conditional on an audit, we view these results as strong evidence we have
very good coverage of treated installations.
Turning to treated households‚Äô propensity to make durable good purchases, we estimate treatment‚Äôs effect on durable good purchases in two ways. First, we estimate the unconditional effect
of treatment on making an installation for all households in the sample. Second, we estimate the
effect of treatment on installations conditional on households who scheduled audits. While the first
specification captures the policy relevant effects, we believe that the second is more interesting
from an economic perspective. Specifically, the second specification allows us to derive an apples to
apples comparison of the likelihood of making a durable good purchase for control subjects who
self-select into an IHEA and subjects who are ‚Äúnudged‚Äù or ‚Äúpriced‚Äù into an IHEA by treatment.
To identify the unconditional effect of treatment on installations, we estimate the following

24

model:

X

1{Any Installi } = Œ± + œâw + œÄm + Œ∑tz + 1{Any Letteri }Œ≥ +

1{f Comparisoni }Œ≤f

f ‚àà{kWh, $, CO2 }

+ 1{$20 subsidyi }Œ¥1 + 1{$50 subsidyi }Œ¥2 + i .

(2)

As before, we study the cross section of roughly 99,000 households who we identified as non-movers.
Collapsing to a cross section handles heterogeneity in the time lag between when a household
schedules their initial IHEA and the final inspection IHEA to verify a installation occurred.24
The left-hand side variable in equation (2) takes the value of one if a household made an install
at any time during the field experiment. Most of the right-hand side variables are defined as in the
IHEA regression in equation (1): the variable 1{Any Letteri } takes on a value of one if a household
received any treatment letter during the experiment. 1{f Comparisoni } takes on the value of one
if a household received any letter with framing f during the experiment. The subsidy indicators
denote households receiving each of the subsidy levels. Finally, œâw are wave fixed effects, as before.
We make one alteration and one addition to the right-hand side variables in equation (1). First,
we introduce fixed effects Œ∑tz capturing features of the particular month in which the install occurred
(t) and the particular five-digit zip code (z) where the household is located.25 In addition, we
introduce œÄm as fixed effects for the number of post-treatment months m ‚àà {1, 2, . . . , 12} that
household i had in which to get an install. Together with the wave fixed effects, these œÄm control
for the variation induced by differential timing of treatment letters.
While the coefficient Œ± describes the average probability, for a particular subgroup, of making
a durable good purchase over the course of the field experiment, the coefficients Œ≥, Œ≤f , Œ¥1 , and Œ¥2

24
We‚Äôve estimated alternative specifications in which we don‚Äôt collapse to a cross section and also define installs by
treated households in more and less restricted ways. All specifications give very similar results and are available from
the authors upon request.
25
This is in contrast to the set of fixed effects ŒΩtz for each audit month and five-digit zip pair in equation (1).

25

capture the marginal impact of any letter, different frames and different subsidy treatments on the
unconditional probability of making an install. We are confident in the quality of our data since any
install must occur after an IHEA in order to be eligible for the $500 rebate in our study area.
Table 6 reports the estimation results of equation (2). Recall that this specification measures
the propensity for a household to get an install over the entire treatment period, which is roughly
12 months. The audit regressions measured the propensity of households to get an audit over only
two months. As a result, the point estimates measure IHEAs and installs at different time scales
(two versus twelve months). Further, before we include various controls for post-treatment months,
month-of-year-zip, etc. the results aren‚Äôt directly comparable. In the raw data we observe roughly
67% of households scheduling an audit eventually getting an install.
As with the IHEA regressions, we focus on our preferred specifications in columns 1 and 2.
In the first column without controls, there is a highly significant and negative treatment effect of
receiving a letter on getting an install. However, no marginal effects are statistically significant.
The point estimate for the treatment effect for receiving any letter is just over 50% of the point
estimate for install averages over the entire sample (.0016 versus .0028). This is consistent with the
raw data for install probabilities conditional on audits: for control households about 66% of IHEA
households made an install. The install rate for treatment households who scheduled an audit was
roughly 33%. We investigate these conditional installation results further below.
The significance of the Any Letter coefficient but insignificance of the marginal impacts of
comparisons and subsidies can be explained straightforwardly as a power issue in column 1. Recall
that IHEAs significantly increased in the expenditure and kWh comparisons above. However, given
low installation rates of treated households it is feasible that marginal impacts are not pronounced
enough to be significant without adding additional controls.
The underpowered explanation for column 1 is supported by results from column 2 which add

26

the full set of fixed effects. In that column, the first important result is that there is no negative
impact of Any Letter on installations but there is for kWh and expenditure Comparisons. This
implies households who are ‚Äúnudged‚Äù are less likely to make an install than un-nudged households
despite them being more likely to have an IHEA. This asymmetry in search and purchase behavior
is not present in the impacts of subsidies: we find no statistically significant impact of receiving
subsidies on install probabilities. The subsidy estimates are imprecisely estimated zeroes with point
estimates an order of magnitude lower than the comparison estimates. This is informative since the
coefficient on the $50 subsidy indicator was positive and statistically significant at the 5% level in
the IHEA regression. As before, we are cautious to interpret columns 3-6 due to power concerns but
note the broad patterns are shared in those columns.
The unconditional results show that while both nudges and subsidies are effective at increasing
IHEA, the subsequent behavior of treated households is different. Social comparison treatments
are not effective for increasing installs in our experiment but subsidized households do not install
in a significantly different way than households in the control group. This is consistent with
nudged households having a lower marginal value of installs than households that select to make an
installation on their own. Yet we note that there are a variety of other channels that could be at
play.
We investigate treatment‚Äôs effect on installs further by restricting the sample to only households
who made scheduled audits in our sample and re-estimating equation (2). Trimming the sample
in this way changes the interpretation of the coefficients Œ≥, Œ≤f , Œ¥1 , and Œ¥2 . In this specification
they are the average differences across treatment conditions in propensity to purchase a durable
good conditional on a household having scheduled an IHEA. Significant coefficients indicate that
households induced into search behavior by treatment are significantly different in their subsequent
purchase behavior than households who self-select into search.

27

Table 7 shows the results of the conditional install regressions. Due to the very small sample
size, we view column 1 as the preferred specification. The estimated constant term in the first
column represents the probability (67.7%) a control household makes any installation after an IHEA.
Households induced into having an IHEA by kWh and expenditure comparisons were less likely to
make any installation than the control group of untreated households who self-selected into making
an installation. There is no statistically significant impact on either subsidy level although point
estimates are negative. Adding fixed effects in column two confirms much of the findings of column
1 despite the small sample size. Thus, the general asymmetry across nudges and dollars is preserved
vis-a-vis installations.
These purchase results, both unconditional (Table 6) and conditional (Table 7) are somewhat
surprising: the same kWh and expenditure comparisons which led to a significant increase in search
led to a significant decrease in purchase behavior. There are a few possible candidate explanations,
some more plausible than others. First, consider who comprises the set of people eligible to be in
the treatment group: all households who had not scheduled an IHEA or made an install prior to the
our randomization of treatment status. As a result, they are the set of households least likely, in
some sense, to benefit from getting IHEA/install given that the IHEA/install program predated our
field experiment. However, the fact that these comparison effects are net of the pure information
treatment effect suggests that our result is not merely a function of the marginal household being
entirely inelastic. Further, subsidies induce households to audit and install behavior at a rate
statistically indistinguishable from the control group.
An alternative take on this result is that there is a fundamental discrepancy in what causes
search behavior and what causes purchase behavior. The marginal person induced to search by
an expenditure comparison could be very different from the marginal person who is induced to
purchase conditional on the outcome of that search behavior (e.g., the information revealed in the

28

IHEA itself). For example, if the mechanism behind increased search is normative guilt, that guilt
could be alleviated by the IHEA. To the extent that such guilt is concentrated among households
that are least elastic on the purchase margin, such a ‚Äúnudged‚Äù household could be less likely to
even consider making a purchase after an IHEA since they are simply focusing on the social norm
during an IHEA.26
There are myriad other explanations. Our design does not allow us to identify the precise
mechanism at play. More research in the spirit of Allcott and Kessler (2015) would be useful in
understanding ‚Äúnudges‚Äù more precisely along different margins. Our findings highlight, though,
that marginal consumers responding to non-pecuniary signals in search can be different than the
marginal consumer responding to pecuniary signals in search when we investigate the purchase
dimension. This is broadly consistent with other findings that even within the same behavioral
margin the impact of non-pecuniary signals can vary (Costa and Kahn, 2013; Gromet et al., 2013).
In this way it is in some ways unsurprising, but important for policy, that we find evidence that
nudges can be very effective at inducing some economic behaviors but not others.

5

Discussion

We find that non-pecuniary signals in our experiment significantly increased search: households
that received kWh and expenditure comparisons were significantly more likely to schedule IHEAs.
Comparing that to the point estimate for the treatment effect due to subsidies, it amounts to
a subsidy of the IHEA price of $35-$50, although the price effect is not statistically significant.
However, for purchase behavior we find largely the opposite result: conditional on getting an IHEA
and unconditionally, subjects in the expenditure and kWh comparison treatments were significantly

26

Similarly, someone clicking on an ad for a product that they were referred to by a friend may simply prefer to see
what their friend suggested rather than even consider purchasing the good.

29

less likely to make an installation than control households. There is no such divergence in direction
of effect for IHEA subsidies.
We urge caution in generalizing our results as we study a very specific type of non-pecuniary
information (e.g., comparisons) in only a single scenario. While our results are novel, it is unclear
exactly how portable the results of our non-pecuniary signal are to other types of advertising.
Even other types of audit programs, for example one that provide a higher level of support to
households considering making energy-efficiency installations, could experience different returns
to non-pecuniary information. As a result, further research is needed since ours is a single field
experiment in a single area. To that end, we found that the content of the non-pecuniary signal
matters and simple messages about the existence of the program had little to no effect on search
nor purchase.27
There are other important implications as well. Consistent with the priming literature, signal
framing matters for microeconomic decision-making like search behavior (Chen and Li, 2009; Chen
et al., 2010). We find that the ‚Äúnudges‚Äù which have been shown to induce changes in electricity
use (e.g., the intensive margin) are not the same nudges that induce longer-lived changes through
expensive durable goods purchases (Allcott, 2011; Costa and Kahn, 2013; Ferraro and Price, 2013;
Ito et al., 2013; Schultz et al., 2007). This is not to say that the effect of nudges on the intensive
margin can‚Äôt be long-lived through habit formation or some other mechanism (Brent et al., 2015).
As a result, understanding who is the marginal consumer for ‚Äúnudges‚Äù and in what way they are
marginal will require additional theoretical understanding of the mechanisms at play with different

27
While we‚Äôve focused on the private good market implications of our research, there are also public good implications.
Different federal, state and local policies attempt to correct market failure by establishing or completing markets.
Take the example of healthcare.gov as an online marketplace for U.S. consumers to shop for health insurance: much
of the literature focuses on the effect of increased medical care on consumer welfare. We inform a complementary
question: if healthcare.gov is the solution to a market failure, are there effective non-pecuniary strategies to increase
search in addition to enrollment? Further, our results serve as caution against the assumption that strategies effective
at increasing search necessarily increase subsequent purchase.

30

forms of non-pecuniary signals.
Our findings, while only a single study, suggest that additional research on the mechanisms
behind non-pecuniary signals‚Äô effects on different but related dimensions of human behavior would
be valuable. The asymmetric effect of different frames offers suggestive evidence about the channel
determining increases in search behavior: privately-framed comparisons (kWh and expenditures),
rather than comparisons highlighting a public good aspect (CO2 ) or ‚Äúpure information,‚Äù affected
search in our context. This result has implications for the channel through which comparisons may
operate. Our results are consistent with both 1) a social norm channel and 2) an information-based
channel in which households infer information about what their use could be based upon averages
in their local area. Finally, given that we provided the same information framed differently, it also
provides evidence of bounded rationality. Nonetheless, it is not clear what caused households to be
‚Äúnudged‚Äù into IHEAs by kWh and expenditure comparisons. Further work is needed to identify the
precise mechanism. In particular, our findings motivate future work to understand exactly who is
marginal for different kinds of non-pecuniary signals that affect various economic decisions (e.g.,
search, purchase, etc.).

31

References
Allcott, H. and T. Rodgers, ‚ÄúThe Short-Run and Long-Run Effects of Behavioral Interventions:
Experimental Evidence from Energy Conservation,‚Äù American Economic Review, 2014, 104 (10),
3003‚Äì3037.
Allcott, Hunt, ‚ÄúSocial Norms and Energy Conservation,‚Äù Journal of Public Economics, 2011, 95
(9), 1082‚Äì1095.
and Judd B. Kessler, ‚ÄúThe Welfare Effect of Nudges,‚Äù NBER Working Paper 21671, 2015.
and Michael Greenstone, ‚ÄúIs There an Energy Efficiency Gap?,‚Äù Journal of Economic
Perspectives, 2012, 26 (1), 3‚Äì28.
and

, ‚ÄúMeasuring the Welfare Effects of Energy Efficiency Programs,‚Äù Working paper, 2015.

Attari, Shahzeen Z., Michael L. DeKay, Cliff I. Davidson, and WaÃàndi Bruine de Bruin,
‚ÄúPublic perceptions of energy consumption and savings,‚Äù Proceedings of the National Academy of
Sciences, 2010, 107 (37), 16054‚Äì16059.
Bernedo, Marƒ±ÃÅa, Paul Ferraro, and Michael Price, ‚ÄúThe Persistent Impacts of Norm-Based
Messaging and Their Implications for Water Conservation,‚Äù Journal of Consumer Policy, September 2014, 37 (3), 437‚Äì452.
Beshears, John, James J. Choi, David Laibson, Brigitte C. Madrian, and Katherine L.
Milkman, ‚ÄúThe Effect of Providing Peer Information on Retirement Savings Decisions,‚Äù Journal
of Finance, 2015, 70 (3), 1161‚Äì1201.
Brent, Daniel A, Joseph H Cook, and Skylar Olsen, ‚ÄúSocial Comparisons, Household Water
Use, and Participation in Utility Conservation Programs: Evidence from Three Randomized

32

Trials,‚Äù Journal of the Association of Environmental and Resource Economists, 2015, 2 (4),
597‚Äì627.
Chen, Y. and S. Li, ‚ÄúGroup Identity and Social Preferences,‚Äù American Economic Review, 2009,
99 (1), 431‚Äì457.
, F.M. Harper, and J. Konstan S. Li, ‚ÄúSocial Comparisons and Contributions to Online
Communities: A Field Experiment on MovieLens,‚Äù American Economic Review, 2010, 100 (4),
1358‚Äì1398.
Cialdini, Robert B, Linda J Demaine, Brad J Sagarin, Daniel W Barrett, Kelton
Rhoads, and Patricia L Winter, ‚ÄúManaging social norms for persuasive impact,‚Äù Social
influence, 2006, 1 (1), 3‚Äì15.
Costa, Dora L and Matthew E Kahn, ‚ÄúEnergy conservation nudges and environmentalist
ideology: Evidence from a randomized residential electricity field experiment,‚Äù Journal of the
European Economic Association, 2013, 11 (3), 680‚Äì702.
DellaVigna, Stefano, John A. List List, and Ulrike Malmendier, ‚ÄúTesting for Altruism
and Social Pressure in Charitable Giving,‚Äù Quarterly Journal of Economics, 2012, 127 (1), 1‚Äì56.
, John A. List, Ulrike Malmendier, and Gautam Rao, ‚ÄúVoting to Tell Others,‚Äù Review
of Economics Studies, 2016, forthcoming.
Dolan, Paul and Robert Metcalfe, ‚ÄúNeighbors, knowledge, and nuggets: Two natural field
experiments on the role of incentives on energy conservation,‚Äù University of Chicago Working
paper, 2015.

33

Duflo, Emmanuel Saez Esther, ‚ÄúThe Role of Information and Social Interactions in Retirement
Plan Decisions: Evidence from a Randomized Experiment,‚Äù The Quarterly Journal of Economics,
2003, 118 (3), 815‚Äì842.
Edo, P. and B. Szentes, ‚ÄúThe Price of Advice,‚Äù The RAND Journal of Economics, 2007, 38 (4),
865‚Äì880.
Ferraro, Paul and Michael Price, ‚ÄúUsing Non-Pecuniary Strategies to Influence Behavior:
Evidence from a Large Scale Field Expirement,‚Äù Review of Economics and Statistics, 2013, 95
(1), 64‚Äì73.
Ferraro, Paul J., Juan Jose Miranda, and Michael K. Price, ‚ÄúThe Persistence of Treatment
Effects with Norm-Based Policy Instruments: Evidence from a Randomized Environmental Policy
Experiment,‚Äù American Economic Review, May 2011, 101 (3), 318‚Äì22.
Fowlie, Meredith, Michael Greenstone, and Catherine Wolfram, ‚ÄúAre the non-monetary
costs of energy efficiency investments large? Understanding low take-up of a free energy efficiency
program,‚Äù The American Economic Review, 2015, 105 (5), 201‚Äì204.
Frey, Bruno S. and Stephan Meier, ‚ÄúSocial Comparisons and Pro-social Behavior: Testing
&quot;Conditional Cooperation&quot; in a Field Experiment,‚Äù American Economic Review,
December 2004, 94 (5), 1717‚Äì1722.
Gilbert, B., J. LaRiviere, and K. Novan, ‚ÄúIncentives and Additionality in Energy Efficiency
Subsidies,‚Äù Association of Environmental and Resource Economists 4th Annual Summer Conerence,
2015, June.

34

Gromet, Dena M, Howard Kunreuther, and Richard P Larrick, ‚ÄúPolitical ideology affects
energy-efficiency attitudes and choices,‚Äù Proceedings of the National Academy of Sciences, 2013,
110 (23), 9314‚Äì9319.
Ito, Koichiro, Takanori Ida, and Makoto Tanaka, ‚ÄúUsing Dynamic Electricity Pricing to
Address Energy Crises Evidence from Randomized Field Experiments,‚Äù Boston University Working
Paper, 2013.
Lewis, R. and J. Rao, ‚ÄúThe Unfavorable Economics of Measuring the Returns to Adverising,‚Äù
Quarterly Journal of Economics, 2015, forthcoming.
McKinsey, ‚ÄúUnlocking energy efficiency in the US economy,‚Äù McKinsey and Company, 2009.
Palmer, Karen and Margaret Walls, ‚ÄúLimited Attention and the Residential Energy Efficiency
Gap,‚Äù The American Economic Review, 2015, 105 (5), 192‚Äì195.
Pitchik, C. and A. Schotter, ‚ÄúHonesty in a Model of Strategic Information Transmission,‚Äù The
American Economic Review, 1987, 77 (5), 1032‚Äì1036.
Rothschild, M., ‚ÄúA One-Armed Bandit Model of Search Behavior,‚Äù Journal of Economic Theory,
1974, 9, 185‚Äì202.
Schultz, P Wesley, Jessica M Nolan, Robert B Cialdini, Noah J Goldstein, and Vladas
Griskevicius, ‚ÄúThe constructive, destructive, and reconstructive power of social norms,‚Äù Psychological science, 2007, 18 (5), 429‚Äì434.
Schutlz, PW, JM Nolan, RB Cialdini, NJ Goldstein, and V Griskevicius, ‚ÄúThe Constructive, Destructive, and Reconstructive Power of Social Norms,‚Äù Psychological Science, 2007,
18 (5), 429‚Äì434.

35

Shang, Jen and Rachel Croson, ‚ÄúA Field Experiment in Charitable Contribution: The Impact
of Social Information on the Voluntary Provision of Public Goods,‚Äù The Economic Journal, 2009,
119 (540), 1422‚Äì1439.
Trope, Yaacov and Nira Liberman, ‚ÄúConstrual-Level Theory of Psychological Distance,‚Äù Psychological Review, 2010, 117 (2), 440‚Äì463.
Wichman, Casey, Laura Taylor, and Roger von Haefen, ‚ÄúConservation policies: Who
responds to price and who responds to prescription?,‚Äù Journal of Environmental Economics and
Management, 2016, 79, 114‚Äì134.

36

Figure 1: Decision Tree for Field Experiment

Treatment

Control

USE

No Audit

Audit

Install

No Install

Install Composition
Note: Control households have same access to same decisions over every node.

37

Figure 2: Timing of Waves Gantt Chart
12/1/2012

10/1/2013

12/18/2012

2/16/2013

5/3/2013

7/1/2013

8/12/2013
Wave 3 - Eligible Audit Period

Wave 2 - Eligible Audit Period
Wave 1 - Eligible Audit Period
Pilot 2 - Eligible Audit Period
Pilot 1 - Eligible Audit Period

Pilot 1
First Letter Sent

Pilot 2
Send Date

Wave 1
Send Date

Wave 2
Send Date

Wave 3
Send Date

Note: Timing of the experimental waves as well as the post-treatment windows during which we count eligible experimental audits. In general, each eligible
audit period is 60 days from the wave-specific letter send date. In the case of Pilot 1, the letters were sent in two batches one on 12/18/2012 and one on
12/21/2012. For households that were a part of Pilot 1, the eligible audit period is the 60 day period after either 12/18/2012 or 12/21/2012, respectively. We
omit the 12/21/2012 batch from the Figure to simplify the presentation.

Figure 3: Variation in Letter Content

Note: The top left panel corresponds to the No Comparison treatment letters. The top right panel
corresponds to the kWh Comparison letters. The bottom left panel corresponds to the CO2 Comparison
letters. Finally, the bottom right panel corresponds to the $ Comparison (i.e., expenditure) letters.

39

0

.1

Density
.2

.3

.4

Figure 4: Timing of Installs Relative to Audits

0

1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91+
Days between Audit and Install

Note: Data include all installations in the data set. All installations are preceeded by an audit.

40

Table 1: Treatments Used in Field Experiment and Covariate Balance

No Comparison

Sample Size
Mean Pre-Treatment Use (kWh)

kWh Comparison

Sample Size
Mean Pre-Treatment Use (kWh)

$ Comparison

Sample Size

41

Mean Pre-Treatment Use (kWh)
CO2 Comparison

Sample Size
Mean Pre-Treatment Use (kWh)

All Letter Types

Sample Size
Mean Pre-Treatment Use (kWh)

No Subsidy

$20 Subsidy

$50 Subsidy

All Subsidy Levels

3,923

7,617

3,694

15,234

1,326.90

1,322.06

1,312.30

1,320.94

(9.33)

(6.76)

(9.71)

(4.77)

3,476

6,893

3,374

13,743

1,316.45

1,319.69

1,327.60

1,320.81

(10.25)

(7.09)

(10.23)

(5.07)

3,737

7,736

3,756

15,229

1,323.17

1,318.91

1,325.74

1,321.64

(9.88)

(6.75)

(10.28)

(4.91)

1,632

3,347

1,612

6,591

1,317.90

1,317.50

1,330.52

1,320.79

(14.48)

(10.59)

(15.07)

(7.44)

12,768

25,593

12,436

50,797

1,321.81

1,319.87

1,322.87

1,321.09

(5.27)

(3.71)

(5.43)

(2.65)

Note: In the No Comparison treatment row, households are told only their own use measured in kWhs. Elements of each cell indicate
individual treatments, whereas numbers in parenthesis record the number of households in that treatment cell. There was also a large
control group consisting of a within-wave control group and a super-control group never assigned to a wave. The size of the super
control group was 49,751 households, with a mean pre-treatment use of 1,319.56 kWh and standard error of 2.69.

Table 2: Sample Size by Wave and Treatment Type

42

Pilot 1

Pilot 2

Wave 1

Wave 2

Wave 3

Dec 18-21, 2012

Feb 16, 2013

May 3, 2013

Jul 1, 2013

Aug 12, 2013

Within-Wave Control

632

522

2,598

2,726

3,089

9,567

No Comparison - No Subsidy

280

304

1,075

1,097

1,167

3,923

kWh Comparison - No Subsidy

224

0

1,121

1,019

1,112

3,476

$ Comparison - No Subsidy

253

298

1,046

1,074

1,066

3,737

CO2 Comparison - No Subsidy

209

333

0

0

1,090

1,632

No Comparison - $20 Subsidy

452

652

2,188

2,189

2,136

7,617

kWh Comparison - $20 Subsidy

423

0

2,239

2,097

2,134

6,893

$ Comparison - $20 Subsidy

564

646

2,157

2,095

2,274

7,736

CO2 Comparison - $20 Subsidy

493

621

0

0

2,233

3,347

No Comparison - $50 Subsidy

192

332

1,051

1,033

1,086

3,694

kWh Comparison - $50 Subsidy

196

0

1,055

997

1,126

3,374

$ Comparison - $50 Subsidy

205

288

1,039

1,139

1,085

3,756

CO2 Comparison - $50 Subsidy

204

308

0

0

1,100

1,612

4,327

4,304

15,569

15,466

20,698

60,364

Total

Total

Note: Each column reports the sample size for a particular wave of the experiment and each row reports the sample size for a treatment
type. The experiment also included a super-control of 40,184 households which were not assigned to any wave. Date represents the drop
date for the mailing of the treatment letters in that wave. Any cells with 0 households indicate a letter type (either kWh Comparison or
CO2 Comparison) that was not included in that particular wave.

Table 3: Unadjusted IHEA Uptake Rates During Experiment by Treatment Type
No Subsidy

$20 Subsidy

$50 Subsidy

Total

No Comparison

0.0008

0.0012

0.0014

0.0011

kWh Comparison

0.0021

0.0022

0.0036

0.0025

$ Comparison

0.0016

0.0032

0.0022

0.0025

CO2 Comparison

0.0006

0.0018

0.0006

0.0012

Total

0.0014

0.0021

0.0021

0.0019

Note: Each cell in the table reports the average 60-day (from the date the
treatment letters were sent out) uptake rate of IHEAs by households in that
particular treatment cell. Omitted from the table is the average 60-day IHEA
uptake rate for the control group (which was not sent any letter) which is .0011.
Throughout, we exclude households with IHEAs prior to treatment or after the
end of the observation period (1,548 households excluded, in total).

43

Table 4: Impact of Treatment Letter and Subsidy on IHEA Uptake Rates
1

2

3

4

5

6

-0.0005
(0.0004)
0.0014***
(0.0005)
0.0014***
(0.0005)
0.0001
(0.0005)
0.0008*
(0.0004)
0.0008
(0.0005)
0.0011***
(0.0001)

-0.0003
(0.0002)
0.0004**
(0.0002)
0.0005**
(0.0002)
0.0003
(0.0002)
0.0002
(0.0002)
0.0005**
(0.0002)

-0.0001
(0.0003)
-0.0001
(0.0003)
0.0001
(0.0003)
0.0001
(0.0003)
0.0002
(0.0002)
0.0001
(0.0003)

-0.0000
(0.0002)
-0.0000
(0.0001)
0.0005**
(0.0002)
0.0001
(0.0002)
-0.0002
(0.0002)
0.0002
(0.0002)

-0.0002
(0.0003)
-0.0000
(0.0003)
0.0001
(0.0003)
0.0001
(0.0003)
0.0004**
(0.0002)
0.0002
(0.0002)

-0.0001
(0.0002)
0.0000
(0.0001)
0.0008***
(0.0003)
0.0001
(0.0002)
-0.0002
(0.0002)
0.0002
(0.0002)

Audit Month-Year by ZIP5

No

Yes

Yes

Yes

Yes

Yes

Wave

No

Yes

Yes

Yes

Yes

Yes

Sample

Full
Sample

Full
Sample

Above
Local Median

Below
Local Median

Above
MSA Median

Below
MSA Median

R2
N

0.0003
99,000

0.6950
98,952

0.7558
50,426

0.7283
38,978

0.7478
50,859

0.7251
38,253

Any Letter
kWh Comparison
$ Comparison
CO2 Comparison
$20 Subsidy
$50 Subsidy
Constant
44

Note: Dependent variable is an indicator for households that completed an IHEA within 60 days of receiving a treatment letter (or be
part of the control group). Any Letter is an indicator for receiving any of the social comparison letters or an information-only letter
during the study. kWh Comparison is an indicator for receiving a social comparison letter with units all in kWh during the study. $
Comparison is an indicator for receiving a social comparison letter with units all in dollars during the study. CO2 Comparison is an
indicator for receiving a social comparison letter with units all in pounds of CO2 during the study. Columns 1 and 2 are estimated
on the full sample of households. Column 3 is estimated on the restricted sample of households with average pre-experiment use
above the median in their local area. Column 4 is estimated on the restricted sample of households with average pre-experiment use
below the median in their local area. Columns 5 and 6 reproduce Columns 3 and 4 (respectively), but use MSA instead of local area.
Column 1 includes no controls. Columns 2-6 include controls for the wave of the experiment as well as month-year-ZIP5 level using
the IHEA date. All standard errors are robust to heteroskedasticity. We exclude households with IHEAs prior to treatment or after
the end of the observation period (a total of 1,548 households). Neither above- nor below-median models include households within
the median (fifth) decile.
‚àó ‚àó ‚àó significant at the 1% level, ‚àó‚àó significant at the 5% level, ‚àó significant at the 10% level.

Table 5: Unadjusted Time-to-Install (from Audit Date) by Treatment
No Subsidy

$20 Subsidy

$50 Subsidy

Total

No Comparison

44.33

40.75

13.40

37.68

kWh Comparison

52.62

14.47

6.42

19.82

$ Comparison

25.57

26.00

17.00

23.55

CO2 Comparison

39.50

20.56

224.00

40.67

Total

41.46

26.35

19.00

27.58

Note: Each cell reports the average time-to-install (among installs within that
cell) from the date of the audit. Control group mean post-audit time-to-install
is roughly 41.46 days. Certain cells in the table only have 1 or 2 observations.

45

Table 6: Impact of Treatment Letter and Subsidy on Installs Ever
1

2

3

4

5

6

-0.0016***
(0.0004)
-0.0005
(0.0004)
-0.0002
(0.0004)
-0.0003
(0.0005)
0.0002
(0.0004)
-0.0004
(0.0004)
0.0028***
(0.0002)

-0.0002
(0.0002)
-0.0003*
(0.0002)
-0.0005**
(0.0002)
-0.0000
(0.0002)
-0.0000
(0.0002)
-0.0000
(0.0002)

0.0001
(0.0003)
-0.0004
(0.0003)
-0.0008***
(0.0003)
-0.0001
(0.0003)
-0.0002
(0.0002)
0.0001
(0.0002)

-0.0003
(0.0002)
-0.0003
(0.0002)
0.0002
(0.0002)
-0.0001
(0.0001)
0.0001
(0.0002)
-0.0000
(0.0002)

0.0000
(0.0003)
-0.0003
(0.0003)
-0.0007**
(0.0003)
-0.0001
(0.0003)
-0.0001
(0.0002)
0.0001
(0.0002)

-0.0002
(0.0002)
-0.0004
(0.0002)
-0.0000
(0.0002)
-0.0001
(0.0001)
0.0000
(0.0002)
0.0000
(0.0002)

Install Month-Year by ZIP5

No

Yes

Yes

Yes

Yes

Yes

Wave

No

Yes

Yes

Yes

Yes

Yes

# Post-Treatment Months

No

Yes

Yes

Yes

Yes

Yes

Sample

Full
Sample

Full
Sample

Above
Local Median

Below
Local Median

Above
MSA Median

Below
MSA Median

R2
N

0.0005
99,000

0.7326
98,962

0.7443
50,435

0.8833
38,969

0.7321
50,865

0.8826
38,248

Any Letter
kWh Comparison
$ Comparison
CO2 Comparison
$20 Subsidy
$50 Subsidy
Constant

46

Note: Dependent variable is an indicator for households that made 1 or more energy-efficient installations at some point during the
experiment and post-treatment. Any Letter is an indicator for receiving any of the social comparison letters or an information-only
letter during the study. kWh Comparison is an indicator for receiving a social comparison letter with units all in kWh during
the study. $ Comparison is an indicator for receiving a social comparison letter with units all in dollars during the study. CO2
Comparison is an indicator for receiving a social comparison letter with units all in pounds of CO2 during the study. Columns 1
and 2 are estimated on the full sample of households. Column 3 is estimated on the restricted sample of households with average
pre-experiment use above the median in their local area. Column 4 is estimated on the restricted sample of households with average
pre-experiment use below the median in their local area. Columns 5 and 6 reproduce Columns 3 and 4 (respectively), but use MSA
instead of local area. Column 1 includes no controls. To account for differential timing of the treatment letter send dates, Columns
2-6 include controls for the wave of the experiment as well as the number of post-treatment months that each household had to
(potentially) respond to treatment. In addition, Columns 2 - 6 include fixed effects at the month-year-ZIP5 level using the install
date. All standard errors are robust to heteroskedasticity. We exclude households with IHEAs prior to treatment or after the end of
the observation period (a total of 1,548 households). Neither above- nor below-median models include households within the median
(fifth) decile.
‚àó ‚àó ‚àó significant at the 1% level, ‚àó‚àó significant at the 5% level, ‚àó significant at the 10% level.

Table 7: Impact of Treatment Letter and Subsidy on Installs Ever (Conditional on IHEA)
1

2

3

4

5

6

-0.0819
(0.1221)
-0.2494**
(0.1111)
-0.2009*
(0.1089)
-0.0309
(0.1726)
-0.0643
(0.1128)
-0.1871
(0.1266)
0.6766***
(0.0333)

-0.3235**
(0.1569)
-0.0739
(0.1218)
-0.1179
(0.0996)
0.0122
(0.1473)
0.0625
(0.1048)
0.2448*
(0.1242)

-0.3506
(0.2193)
-0.0871
(0.1493)
-0.2324**
(0.1169)
-0.1391
(0.2682)
0.0637
(0.1644)
0.2400
(0.1636)

-0.3327
(0.2106)
-0.8092***
(0.1734)
0.3230
(0.1949)
0.1489
(0.1451)
-0.2515
(0.1507)
0.0656
(0.1607)

-0.3524
(0.2524)
-0.0760
(0.1554)
-0.1976
(0.1288)
-0.1382
(0.2693)
0.0618
(0.1791)
0.2475
(0.1918)

-0.5790
(0.3754)
-0.5279*
(0.2980)
0.1341
(0.1803)
0.1503
(0.1603)
-0.1158
(0.2186)
0.2213
(0.3409)

Install Month-Year by ZIP5

No

Yes

Yes

Yes

Yes

Yes

Wave

No

Yes

Yes

Yes

Yes

Yes

# Post-Treatment Months

No

Yes

Yes

Yes

Yes

Yes

Sample

Full
Sample

Full
Sample

Above
Local Median

Below
Local Median

Above
MSA Median

Below
MSA Median

R2
N

0.1215
335

0.5778
297

0.6687
167

0.8625
62

0.6399
162

0.8278
68

Any Letter
kWh Comparison
$ Comparison
CO2 Comparison
$20 Subsidy
$50 Subsidy
Constant

47

Note: All results are conditional on scheduling an IHEA. Dependent variable is an indicator for households that made 1 or more
energy-efficient installations at some point during the experiment and post-treatment. Any Letter is an indicator for receiving any of
the social comparison letters or an information-only letter during the study. kWh Comparison is an indicator for receiving a social
comparison letter with units all in kWh during the study. $ Comparison is an indicator for receiving a social comparison letter with
units all in dollars during the study. CO2 Comparison is an indicator for receiving a social comparison letter with units all in pounds
of CO2 during the study. Columns 1 and 2 are estimated on the full sample of households. Column 3 is estimated on the restricted
sample of households with average pre-experiment use above the median in their local area. Column 4 is estimated on the restricted
sample of households with average pre-experiment use below the median in their local area. Columns 5 and 6 reproduce Columns 3
and 4 (respectively), but use MSA instead of local area. Column 1 includes no controls. To account for differential timing of the
treatment letter send dates, Columns 2-6 include controls for the wave of the experiment as well as the number of post-treatment
months that each household had to (potentially) respond to treatment. In addition, Columns 2 - 6 include fixed effects at the
month-year-ZIP5 level using the install date. All standard errors are robust to heteroskedasticity. We exclude households with
IHEAs prior to treatment or after the end of the observation period (a total of 1,548 households). Neither above- nor below-median
models include households within the median (fifth) decile.
‚àó ‚àó ‚àó significant at the 1% level, ‚àó‚àó significant at the 5% level, ‚àó significant at the 10% level.

Appendix
Power Tests
In choosing the size of our treatment and control groups we performed power tests for each
variable in order to determine the likelihood of discriminating effect sizes of economic significance.
We briefly summarize those power tests here.
The auditor reported that the average monthly rate at which households in our sample sign up
for IHEAs was around 0.1%.28 In conversations with the auditing agency in our study region, they
said an optimistic expectation would be for treatment to cause IHEA rates to double. As a result,
we assume in our IHEA calculations that signup rates will average .19% (e.g., a marginal effect of
.09%) meaning that IHEA probabilities increase by roughly 90% with treatment.
Our control group is roughly 50,000 households and the average treatment group is roughly
4600 households (total of 55,200 households). For our power tests, we assign binary IHEA uptake
decisions to simulated treatment and control households according to a binomial distribution with
the uptake probabilities for treatment and control households as described above. We then estimate
the marginal effect of being in any treatment group on IHEA uptake (i.e., pooled treatment versus
control). We reject the null hypothesis of zero effect in 98% of cases. As a result, we will very clearly
be able to tell if the field experiment had any effect when we aggregate all treatment cells.
When we perform the same exercise, disaggregating by treatments so that there are only 4600
treated households per treatment, we reject the null hypothesis in only 41% of cases. The main
difference is the precision of the estimates: while the mean coefficient estimate is the same across
both power tests, the estimated t-stat of the marginal effect of treatment in the single treatment is
roughly one third of the t-stat when all treated groups are aggregated into a single large treated

28
In our data covering the duration of the experiment the rate of audit uptake in the control was in fact around half
that rate.

i

group (e.g., roughly 1.76, sitting just significant at the 10% level). Aggregating across signal types
or subsidy levels, improves the power greatly: the average t-stat is 2.67 and we are able to reject
the null hypothesis of zero effect 71.5% of the time.
In sum, then, we are reasonably confident that we will be able to detect an effect of treatment
on IHEAs given the size of our field experiment when treatments are aggregated across signals and
less so for individual treatments of each of the twelve treatments. As a result, we are willing to
cautiously consider treatment effects that are significant at the 10% level as significant rather than
noise. That said, we take great care in trying to eliminate noise in both the treatment and control
group in robustness checks. For example, we remove around 3,000 returned letters by hand and
remove all households who had an IHEA within the previous 18 months of the start of the field
experiment. Doing this effectively increases the size of each treatment group by 10% and the size of
the control by 5%. The effect of doing so increases the average estimated t-stat to 1.83 (up from
1.76) and the percent of successfully rejected null hypotheses to 43% (up from 41%). There was a
similar increase when aggregating across prices for a given comparison so that we reject the null
hypothesis of no effect roughly 75% of the time for each individual comparison.
Given the results of these power tests, distinguishing different treatment effects across individual
treatments (e.g., different signal types) requires that treatment vary by at least a factor of two
(e.g., the ATE for one of the twelve treatments is twice the ATE for another) to expect that we
find any significant effect across individual treatments. These results also motivate our empirical
specification to allow the price of the subsidy enter parametrically rather than use indicators for all
twelve treatments.
Model of Audits as Search
To fix ideas, we present a simplified version of the search model in Gilbert et al. (2015). Our
aim is not to provide a rigorous theoretical model to derive testable predictions. Rather, we aim to

ii

motivate how IHEAs are a form of search and develop a framework that links our treatments to
search intensity and the subsequent purchase of durable goods.
Assume that conditional on household i‚Äôs (observable and unobservable) characteristics Œ∏i ,
monthly electricity bills are a random draw from the time-invariant distribution: ‚àÄ t, et |Œ∏i ‚àº
N (¬µi (Œ∏i ), r) where r is the precision (i.e., the inverse of the variance) of the conditional distribution
of electricity bills.29 The mean of the distribution ¬µi (¬∑) is modelled as a function of Œ∏i , e.g., consumers
living in older houses are likely to have higher bills on average, ceteris paribus. While household i
knows its own characteristics Œ∏i with certainty, it has uncertainty over ¬µi (¬∑). In particular, household
i has priors over ¬µi (¬∑) described by F (¬µi (¬∑)) which the household forms by observing household
characteristics (e.g., Œ∏i ) and updates these beliefs by using monthly electricity bills et to form
posteriors using Bayes‚Äô rule. As a result, home owners who have lived in their homes for a longer
period of time will have a better idea of their average electricity use than do counterparts who have
lived in their home for a shorter period.
Purchasing an energy-efficient durable good serves to reduce mean electricity use by a factor
of Œ± ‚àà (0, 1) with probability œÅ. After a purchase, a household with characteristics Œ∏i will see
mean electricity bills drop to (1 ‚àí Œ±)¬µi (Œ∏i ) with probability œÅ and remain at ¬µi (Œ∏i ) with probability
1 ‚àí œÅ. Therefore, households are uncertain about the benefits of making an investment in a durable
good that is expected to improve energy efficiency. To resolve this uncertainty, a household can
conduct an IHEA for a cost c and learn whether or not an energy efficient upgrade lowers their
mean electricity use. IHEAs thus serve to eliminate uncertainty about the benefits associated with
the purchase of any given durable good. In this regard, IHEAs are akin to expert advice in models
such as Pitchik and Schotter (1987) and Edo and Szentes (2007) - the households pays a fixed cost

29

For simplicity, we follow Gilbert et al. (2015) and do not model the choice problem underlying monthly energy use.

iii

to the auditor as a way to resolve uncertainty before making a purchase decision.30
Our experimental design, which we discuss in detail in Section IV, provides exogenous variation
over key parameters of this model. Our subsidy treatments provide exogenous variation in the cost
of an audit, c. In doing so, we generate exogenous variation in the expected net benefits of getting
an audit. Hence, we would expect to see increased participation in the IHEA for households in
our Subsidy treatments. Our Social Comparison treatments introduce random variation in what
households know about their consumption relative to the average consumption of their neighbors.
In our framework, this information could impact the household‚Äôs expected gains from an audit in
two ways. First, households may use information on relative usage to update their beliefs about the
probability that an install would result in savings (œÅ) and/or the expected reductions in energy use
from a successful install (Œ±). We are agnostic about the precise channel since our data do not allow
us to observe and model belief updating. Yet it is important to note that if a household were to
observe they are below mean local area use, it is plausible that the household would update their
beliefs such that it reduces the expected benefits of an audit. Second, it is possible that Social
Comparisons introduce a form of moral suasion that is akin to the social pressure term in DellaVigna
et al. (2012). If so, households may schedule an audit as a way to alleviate feelings of guilt that are
triggered upon learning that their consumption exceeds that of similar neighbors. However, as the
underlying decision to search is driven by the expected costs of not searching as opposed to the
expected benefits of search, such motives may lead to lower rates of purchase as such individuals
are searching for the ‚Äúwrong‚Äù reasons.

30

This simple model has two notable shortcomings. First, there are well-known discounting issues in durable good
purchases known as the energy paradox. In the context of our field experiment, though, this is second order since any
discounting issues are shared by both the treatment and control groups. Second, the binomial distribution of Œ± is very
much a simplifying abstraction. A richer model would offer a continuous distribution which is itself a function of Œ∏i .
However, the important characteristic of the model- uncertainty over benefits of an audit- is verified in data we show
below, e.g., incomplete install rates.

iv

Month Day, Year
Dear Valued Customer,
There‚Äôs no place like home, and there‚Äôs no time like now to make your home more energy efficient. You can
conserve energy, save on utility bills, and get cash rebates by participating in EnergyRight¬Æ Solutions In-Home
Energy Evaluation (IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.
If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home‚Äôs energy efficiency and
will install free CFLs and low-flow water saving measures if you choose.
The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back
if you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. As an additional thank you for participating, if you have an In-Home Energy Evaluation within 30
days from the date of this letter you will receive a $50 Visa gift card.
We thought that you might be interested in the following information about your energy usage last year:

Relative Energy Usage over Past Year

Your Average

0

50

100

150

200

250

300

350

400

450

Kilowatt-hours (kWh)
Kilowatt hours is a unit of energy equal to one kilowatt of power used for one hour. A 100 Watt
bulb burning for 10 hours/week uses 1 kWh (100/1000x10)

Your average energy consumption over the past year: 400 kWh

For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation
link on the www.energyright.com home page.

Sincerely,

EnergyRight¬Æ Solutions Team

NC123

Figure A1: No Comparison Letter Example with $50 Subsidy Offer
v

Month Day, Year
Dear Valued Customer,
There‚Äôs no place like home, and there‚Äôs no time like now to make your home more energy efficient. You can
conserve energy, save on utility bills, and get cash rebates by participating in EnergyRight¬Æ Solutions In-Home
Energy Evaluation (IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.
If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home‚Äôs energy efficiency and
will install free CFLs and low-flow water saving measures if you choose.
The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back
if you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. As an additional thank you for participating, if you have an In-Home Energy Evaluation within 30
days from the date of this letter you will receive a $50 Visa gift card.
We thought that you might be interested in the following information about your energy usage last year:

Your Average Energy Usage
Local Area Homes‚Äô Average Energy Usage

400 kWh
333 kWh

You consumed 20% more energy than other area homes.

For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation
link on the www.energyright.com home page.
Sincerely,
EnergyRight¬Æ Solutions Team

kWh123

Figure A2: kWh Comparison Letter Example with $50 Subsidy Offer
vi

Month Day, Year
Dear Valued Customer,
There‚Äôs no place like home, and there‚Äôs no time like now to make your home more energy efficient. You can
conserve energy, save on utility bills, and get cash rebates by participating in EnergyRight¬Æ Solutions In-Home
Energy Evaluation (IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.
If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home‚Äôs energy efficiency and
will install free CFLs and low-flow water saving measures if you choose.
The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back
if you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. As an additional thank you for participating, if you have an In-Home Energy Evaluation within 30
days from the date of this letter you will receive a $20 Visa gift card.
We thought that you might be interested in the following information about your energy bills last year:

Relative Energy Bills over Past Year
Your Average
Neighborhood Average
0

20

40

60

80

100

120

*Dollars per Month
*Dollars per month calculated at $.XX per kWh

Your Average Energy Bill
Local Area Homes‚Äô Average Energy Bill

$42.50
$33.28

You spent 28% more dollars than other area homes.

For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation
link on the www.energyright.com home page.

Sincerely,
EnergyRight¬Æ Solutions Team

Ex2123

Figure A3: $ Comparison Letter Example with $20 Subsidy Offer
vii

Month Day, Year
Dear Valued Customer,
There‚Äôs no place like home, and there‚Äôs no time like now to make your home more energy efficient. You can conserve
energy, save on utility bills, and get cash rebates by participating in EnergyRight¬Æ Solutions In-Home Energy Evaluation
(IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.
If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home‚Äôs energy efficiency and will
install free CFLs and low-flow water saving measures if you choose.
The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back if
you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. [NO GIFT CARD REBATE]
We thought that you might be interested in the following information about the CO2 created through your energy
consumption last year. Carbon emissions can best be defined as carbon substances which end up in the atmosphere.
Such gases are produced by many things including cars, industrial plants and electricity production.

Relative CO2 Created over Past Year
Neighborhood Average
Your Average
0

100

200

300

400

500

600

700

CO2 lbs (1 kWh=2.17 CO2 lbs)

Your Energy Use
Local Area Homes‚Äô Energy Use

500 kWh created 1,085 lbs of CO2 emissions
600 kWh created 1,302 lbs of CO2 emissions

You produced 20% more CO2 emissions than other area homes.
For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation link
on the www.energyright.com home page.

Sincerely,
EnergyRight¬Æ Solutions Team

CO2123

Figure A4: CO2 Comparison Letter Example with No Subsidy Offer
viii

Frequency Across Treatments
.05
.1
.15

.2

Figure A5: Treatment Assignment (Proportion) by Local Decile of Pre-Treatment Use

8
6
2
7
11
4
0
12
9
1
10
5
3

12
3
11
2
6
9
0
5
7
10
1
8
4

10
1
5
11
8
4
7
6
0
9
3
2
12

9
7
1
12
10
4
3
0
5
8
6
11
2

9
4
1
7
2
11
8
0
5
10
3
6
12

12
10
2
3
6
0
5
8
7
9
11
1
4

12
3
4
11
1
10
6
2
0
8
5
7
9

8
12
6
5
9
1
0
7
11
4
3
2
10

7
4
9
3
11
5
1
2
6
0
10
8
12

0

4
2
0
5
3
8
6
11
12
7
10
9
1

1

2

3
4
5
6
7
8
Pre-Treatment Decile of Use Within Local Area

9

10

Note: The figure summarizes one measure of balance of treatment assignment along the decile of
pre-treatment use within a local area (either nine or five digit ZIP). Exact balance across all 13
treatments cells (control and 12 treatment letters) would require each decile represent 1/10 (the solid
red line) of the assigned households for each treatment. Actual treatment assignment proportions
can be identified by the treatment number. The control group is denoted as 0. Along the subsidy
dimension: a) households receiving no subsidy are in treatments 1 through 4, b) households receiving a
$20 subsidy are in treatments 5 through 8, and c) households receiving a $50 subsidy are in treatments
9 through 12. Along the content dimension: a) households receiving a ‚ÄúNo Comparison‚Äù letter are in
treatments 1, 5, and 9, b) households receiving a kWh Comparison letter are in treatments 2, 6, and
10, c) households a receiving $ Comparison letter are in treatments 3, 7, and 11, and d) households
receiving a CO2 Comparison letter are in treatments 4, 8, and 12.

ix

Table A1: Impact of Treatment Letter and Subsidy on IHEA Uptake Rates (Saturated Model)
1

2

3

4

5

6

-0.0003
(0.0005)
0.0010
(0.0008)
0.0005
(0.0007)
-0.0005
(0.0006)
0.0001
(0.0004)
0.0011*
(0.0006)
0.0021***
(0.0007)
0.0007
(0.0008)
0.0003
(0.0006)
0.0025**
(0.0011)
0.0011
(0.0008)
-0.0005
(0.0006)
0.0011***
(0.0001)

-0.0004*
(0.0002)
0.0002
(0.0003)
0.0002
(0.0003)
-0.0000
(0.0002)
-0.0001
(0.0003)
0.0000
(0.0002)
0.0006*
(0.0003)
0.0004
(0.0003)
0.0002
(0.0003)
0.0012**
(0.0005)
0.0003
(0.0003)
-0.0000
(0.0002)

-0.0004
(0.0004)
-0.0002
(0.0003)
0.0003
(0.0005)
-0.0003
(0.0002)
0.0001
(0.0004)
-0.0003
(0.0003)
0.0003
(0.0004)
0.0005
(0.0004)
0.0002
(0.0005)
0.0005
(0.0005)
-0.0005
(0.0003)
-0.0003
(0.0002)

-0.0001
(0.0001)
0.0003
(0.0003)
0.0001
(0.0002)
0.0001
(0.0001)
-0.0000
(0.0003)
-0.0003*
(0.0002)
0.0002
(0.0002)
-0.0001
(0.0003)
-0.0001
(0.0001)
-0.0001
(0.0001)
0.0013**
(0.0006)
0.0001
(0.0001)

-0.0004
(0.0004)
-0.0001
(0.0003)
0.0001
(0.0005)
-0.0002
(0.0002)
0.0002
(0.0003)
-0.0001
(0.0003)
0.0005
(0.0004)
0.0005
(0.0004)
0.0002
(0.0005)
0.0005
(0.0005)
-0.0004
(0.0003)
-0.0002
(0.0002)

-0.0002
(0.0001)
0.0003
(0.0003)
0.0005
(0.0004)
0.0001
(0.0002)
-0.0001
(0.0003)
-0.0003*
(0.0002)
0.0004
(0.0003)
-0.0001
(0.0003)
-0.0001
(0.0001)
-0.0001
(0.0001)
0.0013**
(0.0006)
0.0001
(0.0002)

Audit Month-Year by ZIP5

No

Yes

Yes

Yes

Yes

Yes

Wave

No

Yes

Yes

Yes

Yes

Yes

Sample

Full
Sample

Full
Sample

Above
Local Median

Below
Local Median

Above
MSA Median

Below
MSA Median

R2
N

0.0004
99,000

0.6950
98,952

0.7559
50,426

0.7284
38,978

0.7478
50,859

0.7251
38,253

No Comparison - No Subsidy
kWh Comparison - No Subsidy
$ Comparison - No Subsidy
CO2 Comparison - No Subsidy
No Comparison - $20 Subsidy
kWh Comparison - $20 Subsidy
$ Comparison - $20 Subsidy
CO2 Comparison - $20 Subsidy
No Comparison - $50 Subsidy
kWh Comparison - $50 Subsidy
$ Comparison - $50 Subsidy
CO2 Comparison - $50 Subsidy
Constant

Note: Dependent variable is an indicator for households that completed an IHEA within 60 days of being randomized to receive a
treatment letter (or be part of the control group). Rows are indicator variables on each of the 12 unique treatments. Columns 1
and 2 are estimated on the full sample of households. Column 3 is estimated on the restricted sample of households with average
pre-experiment use above the median in their local area. Column 4 is estimated on the restricted sample of households with average
pre-experiment use below the median in their local area. Columns 5 and 6 reproduce Columns 3 and 4 (respectively), but use
MSA instead of local area. Column 1 includes no controls. Columns 2-6 include controls for the wave of the experiment as well as
month-year-ZIP5 level using the IHEA date. All standard errors are robust to heteroskedasticity. We exclude households with IHEAs
prior to treatment or after the end of the observation period (a total of 1,548 households). Neither above- nor below-median models
include households within the median (fifth) decile.
‚àó ‚àó ‚àó significant at the 1% level, ‚àó‚àó significant at the 5% level, ‚àó significant at the 10% level. ‚àó ‚àó ‚àó significant at the 1% level, ‚àó‚àó
significant at the 5% level, ‚àó significant at the 10% level.

x

