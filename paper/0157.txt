NBER WORKLNG PAPER SERIES

EFFICIENT ESTflIATION OF A DYNAMIC ERROR-SHOCK MODEL

C. Hsiao
P.M. Robinson

Working Paper No. 157

National Bureau of Economic Research, Inc.
675 Technology Square
Cambridge, Massachusetts

02139

November 1976

Preliminary:

NBER

rking papers

are

Not for Quotation

distributed informally and in

limited number

for

corrments only. They should not be quoted without written permission.

report has not undergone the review accorded official NBER publications
in particular, it has not yet been submitted for approval by the Board of
Directors.

This

*Universjty of California and National Bureau of Economic Research. Research
supported in part by National Science Foundation Crant SOC7S-18919.

Harvard University. Research supported in part by National Science Foundation
Grant SOC7S—13'436.

.

Abstract

This paper is concerned with the estirrtion of the parameters in a dynamic
simultaneous equation model with stationary disturbances under the assimption
that the variables are subj ect to random measurement errors. The conditions
under which the parameters are identified are stated. An asymptotically

efficient
suggested.

frequency-domain class of instrumental variables estimators is

The procedure

consists

of two basic

steps.

The first step

the model in such a way that the observed exogenous variables
are asymptotically orthogonal to the residual terms. The second step involves
an iterative procedure like that of Robinson [13].
transforms

Contents

1. Introduction
2.

Identification arid

2

a Consistent Initial

Estimator

3. Efficient Estimation
..

Coirrnents

References

8

19
22

2

Introduction

1.

We assume the existence of an underlying economic system of the form

B(t.-) +

(1.1)

Here '

x

and

=

t

,

=

1,2

are discrete vector-valued covariance-stationary

processes of dimension G, K and G, respectively; they have mean vectors
=

and zero, respectively, and satisfy E

0, all t, S, the

prime denoting transposition. The B. and Ti are matrices (of dinien-

sions GxG and GxK respectively) B0 being nonsingular and all zeros

of det{

B.z3} being outside the unit circle.
j=0
In this paper we assume in general that all the quantities in (1.1)

are unknown or unobserved (except for certain elements of the B and
knowledge of which will identify the model -- see below). The estimation

and x exactly for

of (1.1) in the case where one observes
t =

1,2,... ,T,

in the absence of stringent restrictions on the autocovariarice

structure of

case G = K =

has been considered by Hannan and Nicholls [8] (for the

1),

Hannan and Terrell [9] (for the case p = q =

0),

Espasa

and Sargan [1]. We relax this requirement by assuming that we observe

=

=

0, EtC =
=

0,

=

+i

,

t = l,...,T

are Gxl and Kxl vector processes which satisfy

and

The

,x

ts2'

Ent =

0,

Entr = 652ir0,

being Kronecker's delta. Clearly,

sistently and efficiently estimated by ,

=T
t=l

respectively.

EtX = 0, Etr = 0,
and

X

= T

are con-

x

However, it will be apparent from knowledge of the classical

errors-in-variables problem that standard estimators of the B3, Ti, that

3
would be asymptotically efficient if 0 were a null matrix, will not in

general be consistent or efficient when 0 is non-null. We shall not be
concerned with estimating c because under our assumptions it will not

be identifiable. We do wish to estimate 0, however, along with the B.

r. by consistent and efficient methods. Since the t' like the
play the role of white noise measurement errors, an a priori

assumption

that will often not be unreasonable, and will prevent too large an expansion of the parameter space over that in [8], [9], is that the elements of

are contemporaneously uncorrelated. Therefore, we assume throughout

•that 0 is a diagonal matrix. Moreover, we shall allow for the possibility
that we know that one or more of the elements of

x is, almost surely,

observed without error for all t, in which case we fix the corresponding

diagonal element of 0 as zero. (We nowhere require 0, or 2, to be
nonsingular). Therefore, we have achieved a generalization of the usual

dynamic simultaneous equations model: prior information that an exogenous
variable is error-free is equivalent to an exclusion constraint on a para-

meter. This will fit in well with our other constraints on the

r,
for we assume, for simplicity, that all these are also of the exclusion
type (apart from a normalization and sign constraint on each equation).
Measurement errors with similar properties were considered by Goldberger

[4,5], Geraci [3], Hsiao [10], etc. However, in their work, only the

static case of (1.1) (the case p = q

=

0) was considered, and the

were assumed to be white noise. The most significant difference is that
we are principally concerned here with the case where

Xt is not white

noise, when the identification problem may be solved by the use of lagged

observable exogenous variables as instruments. We pay some attention also
to the case where

Xt is white noise, when the lagged exogenous variables

4

are useless as instruments and a basically different approach is required.

Identification and a Consistent InitialEstimator

2.

When (1.1) is transformed in terms of the observables y, x, we have

=

(2.2)

We

=

+

(2.1)

+ r.ntj

Et +

define the discrete Fourier transforms
T

w(X) = (2iiT1'2 )
t=l

w(A) = (2T)_h/2yte1tX
= (2irT)

w (x)
U

u e1

t=lt

and replace (2.1) by an asymptotic approximation to its Fourier transform,

(2.3)

B(X)w(X) +

r(x)w(x)

=

w(X)

,

A

/ 0

where

B(X) =

B.e

3=0
omitting the terms in p,

,

r(x)

=

r.e
j=03

which are 0(ThhI'2) when A

0. The

transformed system can be treated as a contemporaneous model. Thus,
because

and {c}

are incoherent of {x} but

is not,

w(X) can be decomposed into a sum of two orthogonal components, one of

5

which (depending upon {r}) is correlated with w(A), and the other
(depending upon {Et} {}) is not. Therefore, the measurement errors in
can be amalgamated with (c} to produce a composite, stationary,
residual term. It would be possible to identify 2 if, for example,
=

0,

almost surely, all t, whence (1.1) is a homogeneous structural

relation between Xt) ,

and

u is a moving average sequence of order

max(p,q), but we shall not do this; we prefer to allow for the presence
of a stationary

in (1.1), to possibly represent exogenous variables

that should have been included in (1.1). We could, indeed, have omitted

explicit reference to a measurement error pertaining to ,

and indeed

the assumption that this measurement error is white noise essentially plays

no role in our results. In any case, if 0 =

0,

there is no problem in

consistently estimating the B., F., but merely an efficient estimation

in (2.2): if

problem caused by the moving average in

is a moving

average sequence of order r then the residual term is a moving average
of order rnax(p,r), and a vector extension of the methods of Haqnan and
Nicholls [8] may be appropriate. We are concerned only with the case

8 t 0, however.

For simplicity, we assume that B(A) and F(X) are relatively left
prime, so that the redundancy in the specification can be eliminated
(Hannan [7]) and the a priori information on the

B. r is entirely in the

form of exclusion restrictions. We also assume that

Cx(i) =

E(xt_1.Ix)(xt+_ux)'

,

j = 0,1,... ,r

are nonsingular and unrestricted for some r > 0. Furthermore, because of
the requirement that the instrumental variable estimates discussed in §3 do
not involve a singular matrix, we follow Fisher [2, Condition 6.2.1] in

6

. X_q are

assuming that the pG+ (q+1)K elements of t-l
not connected by any linear identities, where

=

with L the lag operator. A sufficient condition for this to hold is:
F.z} are outside the unit circle;
B.z3} and det{
j=03

(a) all zeros det{
p
(b) {

.

) B.z},

j=03

qj=0.3
{

F.z3} are relatively left prime; i.e., they have

I,,,

as

j=03

greatest common left divisor; and (c) rank(Bp1'q) = G.

Then, by the same

reasoning as in Hsiao [11], one can show that the number of excluded predetermined variables be at least as great as the number of included joint dependent
variables less one is what is necessary for the identification of the 1th

equation. If we let one element in each row of Bo be prescribed as unity
the necessary and sufficient condition to locally identify (2.1) is that at

least (G-l) zeros be prescribed in each row of

A =

[B

B1

B r0

•••

]

and the rank of each submatrix of A obtained by taking the columns of A
with prescribed zeros in a certain row is (G-l).
If

is a white noise, i.e., C(j) = 0

for j > 0,

we need a

much stronger condition to identify the unknown parameters of the th equation of (2.1). In particular, in addition to the conditiQn that the number
of excluded predetermined variables has to be at least as great as the
number of included joint dependent variables plus the number of unknown
measurement error variances (associated with the included current and lagged
exogenous variables) less one, we need additional conditions on the way the
included current or lagged exogenous appear in the 1th behavioral equation.

Let h denote the number of th lagged included exogenous variables which
are not measured exactly. We arrange them in increasing order so that

h > h71,

for i =

1,2,... ,q.

That is, the th lagged included exogenous

variables contain more inaccurately measured variables than 1th lagged
variables. Then this additional necessary condition is that the number of

7

th lagged excluded exogenous variables be at least as great as the number
of additional unknown measurement error variances which were not introduced

by h ,...,h'1. It seems unlikely that x+ will be white noise, in
3,

the

I-

context of a time series model such as (1.1). Given the assumption

that

is white noise, Xt will be white noise if and only if

x is

white noise, and the latter question can easily be resolved by looking t
the

data.
Another way of stating the identification conditions is that there

exists a sufficient number of instrumental variables. Thus, provided the
model is identified we can apply an instrumental variables method equation
by equation to obtain consistent estimates of the Ba's and ri's and 0 (see below).
The standard instruments will be the current or lagged exogenous variables

which do not appear in the equation under consideration. Since the measurement errors among the exogenous variables are assumed to be uncorrelated,
the excluded exogenous variables can be used as instruments irrespective
of whether they are observed exactly.
Theoretically, all the lagged exogenous variables can be used as
instruments and the addition of new instrumental variables will increase
the efficiency unless the partial correlation between each variable in the
relationship and the new instrumental variables is zero after the effects

on the other instrumental variables have been allowed for. In practice,
if the first few instruments are well chosen, there may be no great advan-

tage in increasing the number of instruments. Sargan [15] has shown that
the estimates have large biases if the number of instrumental variables

becomes too large. Actually, he suggested that the number of instruments
should not be greater than 1/20.

8

Efficient Estimation

3.

We assume that the normalization conditions on the equations (1.1) are

that the diagonal elements of B0 are all units. We write

B(X) 'G =

(3.1)

B =

e(X)' =

All

[BO_IG3Bl...BP]

[l,e,..

.

r(x) =

B(eP(X)ØIG)

,e]

prior constraints on B and r

r =

[r0r1...rq]

eq(A)' =

are

r(eq(x)eIK)

[l,e1X,... ix)

zero ones, and we incorporate theip

in a way like that in Robinson [12]. Suppose there are

zero constraints

on B. Then the unconstrained ones may be written as the G2(p+1)X 1 vector
=

L1vec(B),

where L1 is obtained from

Iby

eliminating rows

corresponding to zero elements. Likewise, if there are G2 zero constraints

on F we write the unconstrained parameters as y = L2vec(F),

where L2

is obtained from 1Gk eliminating rows corresponding to zero elements.
Also, we write 0 =

L3vec(O),

where L3 is obtained from the (K-F) xK2

2 by eliminating rows corresponding to the off-

matrix obtained from
K

diagonal elements and the F, 0 < F < K,

a priori zero diagonal elements

of 0.
Since all processes are covariance stationary, we define the vtocovaraince and cross-autocovariance matrices

C(i) =

E{(xtExt)(xt÷-Ext)'}

Cyx(i) =

E{(YEYt)(xt÷Ext)'}

and we assume the existence of the spectral and cross-spectral density

matrices

9

=

C(j)e•'JA

=

-r <

Cyx(j)e•••JX

x

r

<

Similar notation will be used to denote second order properties pertaining
-r < A < it.

to other sequences. We note that f(x) = ®,

Now it is known that, under fairly wide conditions (see Hannan [6,

Chapter IV]) the limiting covariance between the discrete Fourier transforms
of two stationary sequences is the cross-spectral density of the sequences.
Thus

*

(3.1)

fUX (x) =

lini Ew (A)w (A) =
U
X

T-,OD

r(x)o

x

,

0

We therefore rewrite (2.3) as

w(A) = (IG-B(A))w(x)

(3.2)

w,.(A)
when

=

-

w(A)

r(x)(IKof
—

(xy1)w(x) +

w(X)

,

r(x)of(x1w(x)

fX(X) is nonsingular, and where

is the GxG identity matrix.

Now because of (3.1) and because

fx

urn Ew(A)w (X)* =
X

T-o

(x) ,

A

0 ,

we have

Urn Ew(x)wx(x)* =

f(x)

-

r(A)of(AY'f(x)

=

0

Thus, (3.2) possesses (asymptotically) the classical property of orthogonality

between the "exogenous variable" w(A) and the "residual" w1(X).

10

We now rewrite (3.2) as

w(A) =

(3.3)

-B(e(X)®w(X))
+

(C'øA)vec(B)

w(A) =

X(X)L'
=

X(A)

=

r(eq(A)®wx(x))

r(eq(x)ØIK)ofx(xY1wx(x)

We use the relation vec(ABC) =

(3.4)

-

+

w(A)

to rewrite (3.3) as

+ w.(A)

(, ,y' ,e

)

[-(e(x)øw(x)øIG),(e'(x)øw'(A)®IK),w'(x)f(xY1ør(A)]
L1

0

0

L= 0 L2 0
0 0 L3
We shall consider (3.4) for I equally-spaced values of A pver
(-Tr,Tr],

denoted

=

2jiL/T,

-1/2 <

2. < [T/2].

Now it is known that under

fairly general conditions (see Hannan [6, Chapter IV])

the w(wL) are

asymptotically independent (complex) normally distributed, with zero means

and covariance matrix f_(w2.). Now, f(X) and r(A), in
X(x), are unknown but consistent estimation of both is possible. Thus,
an asymptotically efficient instrumental variables method will be possible

after we find an appropriate instrument for w(A). and a consistent
estimate of

f.(X) =
U

lim Ew(X)w(X)
U
U

The method we propose follows that of Robinson [12]. One major difference
is that in Robinson [12] no measurement error was allowed for. A second
major difference is that in [13] a system of differential equations was tQ

.

11

be estimated. The discrete approximation used there led, in the frequency

domain, to matrix polynomials in iX rather than, as here, in e1). As
noted in [13], the method applies to difference equation models if one

replaces iX by e1X. A third departure from [13] lies in the identification conditions. In both cases, a fundamental feature of the identification problem is an aliasing problem connected to the exogenous variables.
However, in [13] the problem is concerned with identifying a continuous-time
signal from knowledge of a discrete one, whereas here it is concerned with

extracting a signal in the presence of noise. A fourth difference from [13]

is that here an, initial consistent estimate of y, as well as of ,

is

essential.

As in [13], iteration may well be desirable, and so we describe our
procedure as if it were iterative, although iteration produces no improve-

ment in efficiency. Our procedure is efficient in the sense that the limit-

ing

covariance matrix of our estimates is the same as that of maximum-

likelihood estimates based on Gaussian w(X). Efficient estimates could
also be obtained by a minimum-distance procedure, using a suitable metric
(like that in Robinson [14]). They could also be obtained by replacing

w(X) in (3.2) by its instrument, and then using a type of generalized
least squares (like that in Hannan and Terrell [9]). With all these procedures,
again, iteration is probably desirable, but providing they are initiated

with consistent estimates, and providing the type of iterative step taken
is appropriate, asymptotically efficient estimates will result after a

single step. The reason we concentrate on our procedure is that it seems
among the simplest to compute and to describe.
Before describing the method, some interim computations must be detailed.

For an integer M, much less than T (see below) we introduce the 2M sets

)

12

B = {xI
m

= {Xj
with A = 0

-Ir<A<-1T(l -k), ir(1

-) <A<M}

Then for all m, -M-I <

omitted from

=

Imi <M-l

2M<m2M' AmM} '

m

f (A ) =

4 wy(w)w(w)*

x m

I

m

(35)

2M
yxm -- T
wy(w)wx(w)*
m

where the sums are over w e B .
.Q
m

M,

we define

x (w)w(w)*

yx(xm)*

assume that 2M/T is sufficiently

in each B to be at least max(G,K). In

small for the number of

that case, ? (A )
x m

We

=

xy(xm)

,

w
B

m <

will

in general be nonsingular.

Now denote by x), (i) the

estimates of r(x), 0 obtained on

the th iterative step, with ?°(x) (o) the consistent ones referredtoing2

so that ?(A) =

and below. Then define

?3(eq(X)øIK).

Returning

to (3.2), we consider the first-order Taylor approximation

(3.6)

r(A)(rK_ofX(x))
+
=

We

r(A)(IK-3fX(xY1)

r(A)(IK-

f(xy1)

xL

replace A by w, and then replace f (c )

B.

Then we approximate (3.2), with A =

xm x

w (w) ?i(A m )3 (A )w (w) =

-

rK-0fX

+

by

?

x (Am),

wa,, by
+

w(w) ,

r _e(w) ®w(u)

xc,x)' =
(xY1wx (u)er(x)'
[eq()ø(IKIx(AY1)wx(A)øIG]
x

where

e

13
An estimate of f is needed. We first put

(x) =
The Sisolutionhi of

(3.7)

_(x)(IK_ofx(xY1)

(3.2)

w(X) =

(A)w(X) +w(X)

=

,

w(A)

=

- xy fyx*
f(x) -

(3.10)

B(A1w_(X)

= (x)f(x)

f(x)

=

B(x)r(x)

=

We have, therefore,

V

(3.8)

(3.9)

p(x)

is thus

where urn Ew (X)w (A)* = 0.

T-' X

,

+

fu(x)

We thus define, using (3.9), (3.10),
=

0)(Xm)
where

Bi(X) =

-

=

(eq(X)eIK).

(i)

being the estimate of B from

the th step. On 'ater iterative steps an estimate of (x)
porates the prior constraints may be used. If

from the th step, define
(3.11)

'() = _(i)(A)(I_ê(i)?(x)—1)
=

that incor-

is the estimate of o

1)

13a

As already noted, the (O) (O) may be one of many consistent instrumental variables estimates. A consistent

may be found by applying

minimum distance methods to (3.2), after replacing B(X), r(x), f(X) by

°(x), P(X), ?X(A). Then

from (3.8), (3.10), put

.

.

14

mxym - yxm3)m)*

=

+
=

for j>1.
We

now discuss the instrument for w(X). From (3.7) we would like to

MA)w(A). The instrument for w(w) on the th step will therefore

(3.12)

where

(3.13)

.3)) is (3.11) for j >1, and

0(A) =

(Cf. (3.8)). As noted earlier, we could replace w() by (3.12) in (3.6),
and then use GLS like in [9]. Our procedure might be preferred in that it
seems to involve one less approximation. On the other hand, the GLS approach
has the advantage in that, unlike ours, it involves the inversion of a

synietric matrix. (Of course, our matrix converges to a symmetric matrix.)
Both types of procedure reduce, essentially, to three stage least squares

(3SLS) in the classical simultaneous equations case p = q = K' =

0,

f..(A)

constant, a priori. As noted in Robinson [13], (3.13) is a narrow-band
version of the reduced form estimate used in 3SLS.
We are now able to define our efficient estimates,

(3.14)

where

(j+l) =

(LD')Ll)_1Ld)

.

i

-°

=

=

z(J),x m)*X(J)(A m)
mwe8m

=

Z(W m
X)*wy(w)
L
mweB

eq(w)ø(IK_3x(x)_1)wx(u)øs1)(A)_1
r'(x) 11C1)(x)—l

To prove asymptotic properties, conditions additional to those in

c} be mutuafly

are needed. We describe these as follows. Let

independent sequences of independent, identically distributed (i.i.d.)

random vectors. Let {x} {c} be mutually independent sequences, inde-

pendent also of {},

.

= _jt_ '

(3.15)

where

{}, with representations
=

{-rt}, {v} are i.i.d. sequences with finite second moments. Also,

let the spectra f(A), f(X)

Lip a, a >

- (i.e.

satisfy Lipschitz

conditions of order greater than one half, see Zygmund [16]). (This is

slightly stronger than assuming flaJ <

, flbff

<

, where

the Euclidean norm.) Therefore, f (A) e Lip a, a > -.

Thus,

det{f(A)} is bounded away from zero, f(X1 e Lip a, a >

fl' is
assuming

also,

since

it is a rational function of the elements of f(A). Therefore, (X)

a > .-.

Also,

Lip

a,

from (3.1), (3.2) it may be inferred that

=

f(X)

-

r(X)of(AY1®F(X)

We note, parenthetically, that this is nonnegative definite, as is apparent

.

16

on rewriting it as

f.(x) =

f(x)

Because

+ B(x)cB(x)* + r(x)(f(x)+f(x)f(xylf(x))r(x)*

is involved in our estimates, we must assume also that f

is positive definite. Now from the above, we may infer that f(X)
a > -,

and thus f(A) e Lip a, a >

-. It

Lip a,

follows from Zygmund [16] that

f(A) may be written as

(ce13X)

(cjei3X)*

Thus, in a mean square sense, we may take the time domain structural resito be

dual process, orthogonal to

with spectrum f and

representation
=

_ocjpt_j
with i.i.d.

the last fact being inferred from the fact that

{v} are i.i.d. sequences. Further, in the solution of the system,

=

(3.16)

!jxt_j + Vt

(i.e. the time domain version of (3.7)), v must have a representation

Vt =

gjtj

where {} is an i.i.d. sequence. Thus, because xt}, f'} are strictly
stationary and ergodic sequences with continuous spectra, because also

17

EX5V;

0, all s, t, and because t(X)

e Lip a, a >

te13>

-, we

can, essentially, analyze the estimates in terms of the model (3.16), for

which theorems in [6], [13] are available. A small additional condition
is needed in order for the error of approximation of the Fourier transform
of (3.16) by (3.12) to be asymptotically negligible in the central limit
have finite fourth moments and cross moments and let

theorem. Let

the fourth cumulant functions of all elements of x x x÷ x be
1

2

'3

4

finite and expressible as the (trivariate) Fourier transform of a cçntinuous

function for all t1, t2, t3, t4. Then x also possesses the latter
property.

It should be noted that the theorem below would hold under weaker conditions than those above; in particular our i.i.d. assumption could be

relaxed. We have used these conditions for simplicity of exposition, and
because the weaker conditions would be unfamiliar to many readers.

We define a matrix

D11 U12 13

0= D2 022 023
Dj3 D3 D33
where the partitions are (p+1)G2:(q+1)GK:K2, and

011 =

Jep(_X)e,(X)®L(A)fx(_X)(A)*®f(A)_IdX

012 =
J

013 =

J

e(X)®(X)®f(XY1r(X)dX

•

18

D22 -

J

D33 = fx r(x)*f_(x)*(x)dx
Theorem. Under the above conditions, there exists some sequence
M = M(T)

increasing as T -

, such

that

tS

almost

surely (a.s.)

and T1"2(-.6) has a limiting niultivariate normal distribution with

zero means and covariance matrix (LDL'), where 0 is strongly consis-

j

tently estimated by

>

o.

The proof will not be given in detail, as it resembles theorems in

[8], [9], [13], [14]. In any case, the theorem need be proved only for
j =

1.

We first deal with consistency. ?(x), uiO)(Am) ?(O)(Xm)
were replaced by f(u), fu(w9).

r(w)

A(üt),

w 8m'

strong consistency certainly follows. However, we note that under our
conditions, including those described in §2, the initial estimates will be

strongly consistent. Also, for some M(T) increasing with 1,

yx yx f(x)

fu(X)

a.s. and uniformly in X, where the band is roughly centered on, and

degenerates to, X (see [14]). Because of these results, it follows that
there is an M(T) such that the above replacement is possible and so

(l)

5.

Next we consider asymptotic normality. In this case, we can

show that we may replace ?x(Xm) m' r10)(xm), °(Am) by the
a.s. limits as I -

but

M stays fixed. Then in this situation

1

19

Tlf2(l)_5) can be shown to be asymptotically multivariate normal, from

On increasing M, then,the

[14].

We note that LDL'

covariance matrix converges to (LDL').

is essentially the limit of the information matrix

based on Gaussian w...(w). Therefore, its nonsingularity requires local
identifiability of the model. Note that, if iJ(X)
is

identifiable by the relation

f(x) + )f(x)

(3.17)

4.

is identifiable, 0

=

Comments

1)

An alternative frequency domain approach to the problem of dealing

with measurement error

is that of simply eliminating from one's estimate

those frequencies that seem likely to have a small signal-to--noise ratio,

usually high ones (see [9], for example). This approach has the advantage
over ours of making no explicit assumptions about the autocovariance structure of the measurement error, and of being somewhat easier computationally.

However, the portion of the frequency band with a small signal-to-noise
ratio may be rather large, and so if all these frequencies are omitted

the resulting estimate may have rather large variance. Moreover, there may
be no frequencies for which the signal-to-noise ratio is really large; this
may be the case when, as we assume, the measurement error has uniform

spectrum. On the other hand, our approach would often seem to be more

efficient, for F will tend to be small relative to the number of other
parameters. Its disadvantage, however, lies in the very strong assumptions

about f, which, if invalid, might lead to serious bias. The choice would
often seem to depend on whether the danger of bias in our method seems

greater or less than the danger of large variances, and possibly bias

.

20

also resulting from the other one. Some clues may be available by inspect-

ing fX(X). If the diagonal elements tend, say, to be very large for

small Am but very small for large A. the frequency-elimination method
may be the more suitable. On the other hand, if ?x(Xm) is more stable
over (-7r,rr], our approach might be preferred. The assumption that f
be diagonal, as well as flat, may also be examined. If it is reasonable,

the fx(Xm) will tend to be very well conditioned with the product of the
1th and th diagonal elements substantially greater than the squared modulus

of the (1)th element, for all i, j. On the other hand, this phenomenon
would occur also if the elements of

x. have low coherence. A more direct

way of verifying the flatness and diagonality assumptions would be to use

(3.17), investigating which matrices 0 approximately satisfy

yxm +
for

P°(Am)fx(Am)

=

each A

m

2)

It seems that a frequency-domain approach is particularly natural

in the present case. With many time series models, an alternative efficient
time domain approach is based on an autoregression specification for the

residuals. A low order autoregressive specification may produce better
results in moderate samples than a frequency domain one, which seems to

require both M and T/M to be fairly large. Thus, Hannan and Terrell
[9] consider both types of approach for estimating simultaneous equations

with stationary errors. However, in our case, the effects of the measurement errors are such that in general no autoregressive transformation could

possibly produce a model with white noise residuals incoherent of {x}.
3)

Our procedure has been developed with computational considerations

in mind, and in this respect it seems simpler than some other procedures

21

that might be used. However, the computation of the estimates still

seems

a formidable task, particularly if there is iteration. Nevertheless, time
domain procedures, as well as seemingly rather inappropriate and inflexib'e
(see comment 2) seem unlikely to be much easier coniputationally. It is

true that it is a tedious task to express the components of the 6Li),
in terms of the real and imaginary parts of the summands, particularly

as inverses of complex matrices are involved. However, complex arithmetic
can often be carried out directly on the computer.

22

References

[1] Espasa, A. and J.D. Sargan, "The Spectral Estimation of Simultaneous
Equation Systems with Lagged Endogenous Variables." Paper presented
at the Third World Congress of the Econometric Society, Toronto,
Canada, August 1975.
[2] Fisher, F.M., The Identification Problem in Econometrics. New York:
McGraw-Hill, 1966.
[3] Geraci, J., "Simultaneous Equation Models with Measurement Error."
Ph.D. Thesis, University of Wisconsin, 1974.
[4] Goldberger, A.S., "Structural Equation Methods in the Social Sciences."
Econometrica 40 (1972), 979-1001.

[5] _______________, "Unobservable Variables in Econometrics." In Frontiers
of Econometrics, P. Zarembka (ed.), New York: Academic Press, 1973.

[6] Hannan, E.J., Multiple Time Series. New York: Wiley, 1970.
[7] _____________, "The Identification Problem for Multiple Equation
Systems with Moving Average Errors." Econometrica 39 (1971), 751-765.
[8]

____________ and D.F. Nicholls, "The Estimation of Mixed Regression,

)

Autoregression, Moving Average and Distributed Lag Models."
Econometrica 40 (1972), 529-547.
[9]

___________ and R.D. Terrell, "Multiple Equation Systems with
Stationary Errors." Econometrica 41 (1973), 299-320.

[10] Hsiao, C., "Identification and Estimation of Simultaneous Equation
Models with Measurement Error." International Economic Review 17
(1976), 319—339.

—

[11]

_________, "Measurement Error in a Dynamic Simultaneous Equations
Model with Stationary Disturbances." Paper presented at the Econometric
Society annual meeting, Atlantic City, N.J., September 1976.

[12] Robinson, P.M., "Identification, Estimation and Large-Sample Theory
for Regressions Containing Unobservable Variables." International
Economic Review 15 (1974), 680-692.
[13] ______________, "Instrumental Variables Estimation of Differential
Equations." Econometrica 44 (1976), 765-776.
[14]

, "Fourier Estimation of Continuous Time Models." In
Statistical Inference in Continuous Time Economic Models,
A.R. Bergstrom (ed.). Amsterdam: North-Holland, 1976.

—

[15] Sargan, J.D., "The Estimation of Economic Relationships Using Instrumental Variables." Econometrica 26 (1958), 393-415.

23
[16] Zygmund, A., Tripnornetric
University Press, 1959.

Series,

0..

Cambridge: Cambridge

.

