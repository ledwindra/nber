{
    "id": 29549,
    "citation_title": "Selection in Surveys: Using Randomized Incentives to Detect and Account for Nonresponse Bias",
    "citation_author": [
        "Deniz Dutz",
        "Ingrid Huitfeldt",
        "Santiago Lacouture",
        "Magne Mogstad",
        "Alexander Torgovitsky",
        "Winnie van Dijk"
    ],
    "citation_publication_date": "2021-12-06",
    "issue_date": "2021-12-02",
    "revision_date": "2022-10-24",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Estimation Methods",
        "\n",
        "Data Collection",
        "\n",
        "Public Economics",
        "\n",
        "Labor Economics",
        "\n",
        "COVID-19",
        "\n"
    ],
    "program": [
        "\n",
        "Labor Studies",
        "\n",
        "Public Economics",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nWe show how to use randomized participation incentives to test and account for nonresponse bias in surveys. We first use data from a survey about labor market conditions, linked to full-population administrative data, to provide evidence of large differences in labor market outcomes between participants and nonparticipants, differences which would not be observable to an analyst who only has access to the survey data. These differences persist even after correcting for observable characteristics, raising concerns about nonresponse bias in survey responses. We then use the randomized incentives in our survey to directly test for nonresponse bias, and find strong evidence that the bias is substantial. Next, we apply a range of existing methods that account for nonresponse bias and find they produce bounds (or point estimates) that are either wide or far from the ground truth. We investigate the failure of these methods by taking a closer look at the determinants of participation, finding that the composition of participants changes in opposite directions in response to incentives and reminder emails. We develop a model of participation that allows for two dimensions of unobserved heterogeneity in the participation decision. Applying the model to our data produces bounds (or point estimates) that are narrower and closer to the ground truth than the other methods. Our results highlight the benefits of including randomized participation incentives in surveys. Both the testing procedure and the methods for bias adjustment may be attractive tools for researchers who are able to embed randomized incentives into their survey.\n\n",
    "acknowledgement": "\nWe would like to thank Bengt Oscar Lagerstr\u00f8m and his team at Statistics Norway for implementing the survey. We would like to thank Joe Altonji, Alex Bick, Raj Chetty, Michael Greenstone, Nathan Hendren, Ali Horta\u00e7su John Eric Humphries, Larry Katz, Costas Meghir, Azeem Shaikh, and seminar participants at the 2021 Cowles Foundation Conference on Labor Economics & Public Finance, the Harvard Seminar in Labor Economics, and the Arizona State University Applied Microeconomics Seminar for helpful discussion. Isabel Almazan, Marcus Lim, and Yifan Xu provided excellent research assistance. Any errors are our own. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}