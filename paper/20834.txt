NBER WORKING PAPER SERIES

COGNITIVE ECONOMICS
Miles S. Kimball
Working Paper 20834
http://www.nber.org/papers/w20834

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2015

Conversations with Robert Willis inspired this paper. I would also like to thank participants at the
Japanese Economic Review conference at Keio University. In addition to an honorarium associated
with that conference, this work was supported by National Institute on Aging grants P01-AG026571
and R01-AG040787 to the University of Michigan. The views expressed herein are those of the author
and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2015 by Miles S. Kimball. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

Cognitive Economics
Miles S. Kimball
NBER Working Paper No. 20834
January 2015
JEL No. B4,D03,D6,G02,J24
ABSTRACT
Cognitive Economics is the economics of what is in people’s minds. It is a vibrant area of research
(much of it within Behavioral Economics, Labor Economics and the Economics of Education) that
brings into play novel types of data—especially novel types of survey data. Such data highlight the
importance of heterogeneity across individuals and highlight thorny issues for Welfare Economics.
A key theme of Cognitive Economics is finite cognition (often misleadingly called “bounded rationality”),
which poses theoretical challenges that call for versatile approaches. Cognitive Economics brings a
rich toolbox to the task of understanding a complex world.

Miles S. Kimball
Department of Economics
University of Michigan
Ann Arbor, MI 48109-1220
and NBER
mkimball@umich.edu

I. Introduction
Names matter. In particular, naming subfields of economics can help economists to see
connections they otherwise might not have seen between their own research agenda and
the research agenda of other economists. A well-chosen name can foster esprit de corps
within a subfield and help in explaining the unifying ideas in that subfield to students.
This paper is an argument for the appropriateness of the name “Cognitive Economics” for
a growing subfield of economics, and for the importance of the research that has been
done and can be done in Cognitive Economics. It also discusses key themes in Cognitive
Economics and the issues they raise.
It is important to stress that (if the name I propose is deemed acceptable), research in
Cognitive Economics has already been underway for a long time. But as a participant in
this subfield, it seems to me that research in this area has been growing in recent years. I
argue here that there are great opportunities for further research in Cognitive Economics.
Even the name “Cognitive Economics” is not altogether new, as googling “Cognitive
Economics” quickly shows. Notable in using this label are two 2004 edited volumes: Paul
Bourgine and Jean-Pierre Nadal’s Cognitive Economics: An Interdisciplinary Approach,
and Massimo Egidi and Salvatore Rizzello’s two-volume Cognitive Economics, both of
which predate the earliest April 7, 2007 version of this paper by several years. Although
their views are not exactly the same as the one I give below, I consider the way they use
the term “Cognitive Economics” as broadly consistent with mine. But the label
“Cognitive Economics” is still not in broad use. My hope is that this paper help in
popularizing what I think is a very useful label, as well as to foster the research that it
refers to.
Below, much of the discussion is about how Cognitive Economics relates to Behavioral
Economics (primarily as a subset of Behavioral Economics, though not entirely). But I
also see a logical relationship between Cognitive Economics and Human Capital Theory.
The development of economics in many topical areas often follows a progression from
treating a model element as a black box viewed from the outside to peering into the
mechanism inside the black box. In black box treatments, the cognitive and
informational nature of human capital and technology is pushed into the background. For
human capital and technology, looking deeply into the black box involves looking at
what is going on inside human minds. Thus, I see Cognitive Economics as a logical
extension and broadening of human capital theory—including both those types of human
capital that are acquired and those types that one is born with.
II. Defining Cognitive Economics
Cognitive Economics is defined as the economics of what is in people’s minds. In
practical terms, this means that cognitive economics is characterized by its use of a
distinctive kind of data. This includes data on expectations, hypothetical choices,
cognitive ability, and expressed attitudes. Categorizing a field of economics by the type

2

of data used and theorized about makes some sense from a practical point of view
because working with a particular type of data often requires some specific human
capital. A simple typology of areas of economic research by type of data addressed
would be something like the following. (Note that each of these areas of economics is
concerned with data on naturally occurring market choices and time allocations as well as
its distinctive type of data.)
 Traditional Economics: data on naturally occurring market choices and time
allocations only.
 Experimental Economics: data on choices in artificial situations with real stakes.
 field experiments
 lab experiments
 Neuroeconomics: data from brain imaging and other ways of measuring brain
activity, data on eyeball orientation, and data on other physiological measures
such as skin conductance, muscle activation, or hormone levels.
 Genoeconomics: data on genes.
 Cognitive Economics: data on hypothetical choices, psychometric data, and selfreport data on mental contents.
 survey measures of expectations
 survey measures of preference parameters
 direct measures of intelligence
 direct measures of decision-making skill
 self-reported emotions, including self-reported happiness
 survey measures of beliefs about how the world works
There is some tension between the definition of Cognitive Economics as the economics
of what is in people’s minds and the practical delineation of Cognitive Economics as the
use of survey data to access what is in people’s minds in relation to economics. In
particular, experimental economics data and neuroeconomic data are also key ways of
getting at what is in people’s minds. To the extent only or mainly experimental
economics data and neuroeconomic data are used, those labels will serve just fine. But I
would class mixed approaches using a heavy dose of survey data combined with some
experimental economics data or some neuroeconomics data as Cognitive Economics. As
ways are found to reduce the cost of experimental data and neuroeconomics data, such
mixed approaches to Cognitive Economics will become more and more important.
The name “Cognitive Economics” is coined by analogy to “Cognitive Psychology,” the
area of psychology that examines internal mental processes such as problem solving,
memory and language. Historically, Cognitive Psychology was a departure from the
Behaviorism of Ivan Pavlov, Leonard Bloomfield and B.F Skinner—which insisted that
only outward behavior was a legitimate subject of study. Similarly, Cognitive Economics
is a departure from the tradition in economics that only outward behavior is a fit subject
of study for Economics—a tradition that was fostered by Vilfredo Pareto, Paul
Samuelson, and Milton Friedman (1912-2006) among others, and was still strong when I
attended graduate school in the mid-1980’s. 1
1

For this history, see the discussion in Franz Dietrich and Christian List (2012).
3

The name “Cognitive Economics” might initially sound as if it might be yet another
synonym for Behavioral Economics (which might have been better named Psychological
Economics). But although there will be overlap, I mean something different. The most
obvious difference is that Cognitive Economics is narrower. Behavioral Economics
addresses a huge range of issues and cuts across all of the data types listed above, while
Cognitive Economics focuses primarily on innovative kinds of survey data, along with
lab data of the same basic type. To say the same thing in a more pointed way, Behavioral
Economics is so big, it is very difficult to keep up with all of the developments within
Behavioral Economics. Cognitive Economics has a more manageable size.
Second, important pieces of Cognitive Economics are inspired by the internal dynamic of
economics rather than by psychology. As examples, in addition to the interest in
intelligence measures that arose out of human capital theory, the importance of
expectations and preference parameters in macroeconomics has spurred a desire for direct
measurement of expectations and preference parameters.
Third, I think it is fair to say that Behavioral Economics has been to an important degree
a school of thought as well as an area of study. In coming up with a definition of
Cognitive Economics, I want to indicate an area of study, not a particular viewpoint. To
make this point clear, a research agenda arguing that, in fact, data on mental contents and
hypothetical choices was unreliable would be part of Cognitive Economics. Indeed, at the
more constructive end of doubting data on mental contents and psychological data, in my
view it is hard to take empirical work on data on mental contents or hypothetical choices
seriously unless the statistical modeling includes a response error term. Kimball, Claudia
Sahm and Matthew Shapiro (2008) gives a basic example of such modeling. Moreover,
when studying more than one type of question within a survey wave, it is typically
important to allow also for correlations across different response errors within a survey
wave.
Finally, there is a slice of Behavioral Economics that explicitly excludes the mind:
notably the “mindless economics” that Faruk Gul and Wolfgang Pesendorfer advocate, in
which empirical data suggesting nonstandard outward behavior is studied from a purely
axiomatic point of view. (There is a fair amount of microeconomic theory done in a way
consistent with this view, although often by economists who themselves are also
comfortable with a more mindful approach.)
In addition to the overlap between Cognitive Economics and Behavioral Economics,
there is an obvious complementarity between Cognitive Economics and Behavioral
Economics. Although it is possible to consider nonstandard theories of human behavior
on the basis of standard data on market decisions alone, freeing up economic theory from
traditional assumptions tends to increase the number of free parameters. There is a great
value to additional data that can help pin down these additional free parameters.
Standard data on market decisions do not always provide power for decisive tests of new
theories. Looking at the complementarity from the other direction, even an approach to
new kinds of data that begins by attempting to measure standard economic concepts such

4

as expectations and preferences with the hope that these concepts obey the standard
assumptions is likely to find at least some areas where the standard assumptions seem to
be violated. Here, Behavioral (Psychological) Economics can help provide alternative
theories to be tested.
Before moving on, let me make the practical delineation of Cognitive Economics by its
heavy use of novel types of survey data more vivid by giving a few specific examples.
1. Intelligence tests are used in one way when intelligence tests are seen as one input
into earning ability. But quiz questions can also be used to see if people
understand what they would need to understand to make economic decisions in
the way specified in standard economic models. The University of Michigan’s
Cognitive Economics Survey and RAND’s American Life Panel both have
extensive batteries of questions measuring financial sophistication, and many
other surveys have basic financial literacy questions. Analyzing such data can be
very sobering for economists used to assuming very high levels of competence on
the part of the agents in their models.
2. Survey measurement of expectations at the individual level has a long and
distinguished history. For example, many macroeconomists, including many
macroeconomists in central banks, take survey measures of inflation expectations
seriously. The University of Michigan’s Survey of Consumers, the University of
Michigan’s Health and Retirement Study and RAND’s American Life Panel have
many other types of expectations data—for example personal mortality
expectations and stock market return expectations. Techniques for dealing with
expectations data have become quite sophisticated. See for example Jeffrey
Dominitz and Charles Manski (2011) and Peter Hudomiet, Gabor Kezdi and
Robert Willis (2011).
3. If one is willing to give some credence to hypothetical choices, it is possible to
design survey measures of a wide range of preference parameters. The University
of Michigan’s Health and Retirement Study has hypothetical choice measures of
risk aversion, time preference and intertemporal substitution, the income elasticity
of labor supply, and altruism. But in principle, almost any type of preference
parameter can be assessed by hypothetical choice questions. Internal consistency
checks (including estimation of the size of response error variance) can often be
devised to help identify the practical boundary of what can be measured at this
point in the development of technique. (For example, it turns out that measuring
the marginal propensity to consume is very difficult. The approach pioneered by
Matthew Shapiro and Joel Slemrod and continued with Claudia Sahm had to
make many compromises. See Shapiro and Slemrod, 2003 and Sahm, Shapiro and
Slemrod, 2012.)
4. There is now a vast literature in economics using self-reported happiness or other
subjective well-being measures such as life satisfaction, or one’s rank on a ladder
of life. The recent push to develop national well-being measures, and doubts
about the comprehensiveness of any one survey question on well-being, have led
to a more and more multidimensional approach to measuring subjective wellbeing. That in turn has led to efforts to combine the measurement of a vector of

5

levels of subjective well-being with hypothetical choice data on how individuals
would trade off different dimensions of well-being. (See Daniel Benjamin, Ori
Heffetz, Miles Kimball and Nichole Szembrot, 2014.)
5. Data on the personality psychologists’ big five personality traits—openness to
experience, conscientiousness, extraversion, agreeableness and neuroticism—are
available on many surveys. (For example, the University of Michigan’s Health
and Retirement Study has questions to assess the big five on its psychosocial
leave-behind—a pencil and paper survey left behind after in-person interviews.)
But other traits may be just as important. Mathilde Almlund, Angela Lee
Duckworth, James J. Heckman and Tim D. Kautz (2011) give a useful survey of
some of the results that have been found.
Having defined the field of Cognitive Economics in what is hopefully a fairly neutral
way, let me give my opinion on existing research and future directions in Cognitive
Economics, organized around three themes: using data on hypothetical choices and
mental contents (1) to identify individual heterogeneity, (2) to revisit welfare economics
and (3) to study finite cognition. Data on hypothetical choices and what is in people’s
minds has obvious relevance to these three themes. Finite cognition also raises some
important theoretical issues that I will discuss.
III. Identifying Individual Heterogeneity
Heterogeneity across individuals in preferences and cognitive ability is not at all
controversial. But data limitations have often forced economists to assume uniformity.
Here the kind of data discussed above can do a lot to allow economists to capture some of
the heterogeneity that exists. In addition to mattering in obvious ways for empirical work,
direct data on preference heterogeneity across individuals can inspire theory with a
greater emphasis on heterogeneity. For example Kimball, Shapiro, Tyler Shumway and
Jing Zhang (2015) use estimates of the distribution of risk tolerance from hypothetical
choice data in the Health and Retirement Study to calibrate a model of “Portfolio
Rebalancing in General Equilibrium.”
IV. Revisiting Welfare Economics
Concern with policy and overall welfare motivates some of the concern with measuring
preference parameters that I discussed above in the context of identifying individual
heterogeneity. In particular, the population distributions of the elasticity of intertemporal
substitution, labor supply elasticities, and interpersonal dependencies in preferences have
important implications for the welfare effects of capital and labor taxation. In addition to
data on preferences based on hypothetical choices, there has been considerable interest in
using data on self-reported happiness to study welfare issues.
The use of self-reported happiness to study welfare issues illustrates a key
methodological issue in Cognitive Economics. Whenever a new measure is used, its
relationship to standard concepts of economic theory is at issue. For example, welfare
economics is based on preferences, with the objective of getting people as much as

6

possible of what they want. Thus, in order to use self-reported happiness to address
welfare issues, it is crucial to establish the relationship between self-reported happiness
and preferences. The most common assumption in the economic literature using selfreported happiness has been that self-reported happiness is equal to some version of
utility. If self-reported happiness were, in fact, tightly linked to preferences in this way,
its importance for welfare economics would be of enormous importance.2 Kimball and
Willis (2006) argue at length that self-reported happiness does not behave like utility, but
has a more complex relationship to utility. Benjamin, Heffetz, Kimball and Alex ReesJones (2012, 2014) back up this view.
It is possible, however, that happiness data could have a tight relationship to preferences
even if the level of happiness does not. In particular, to explain the data, Kimball and
Willis (2006) suggest that a large component of self-reported happiness depends on
recent innovations in lifetime utility. Whenever people receive good news about lifetime
utility, self-reported happiness temporarily spikes up; whenever people receive bad news
about lifetime utility, self-reported happiness temporarily dips down. If true, this means
that while it is questionable to use the level of happiness to infer preferences, the
dynamics of happiness are informative about preferences and so can be used to inform
welfare economics. Like the empirically doubtful assumption that the level of happiness
has a tight relationship to utility, a tight relationship between the impulse response of
happiness to news and the size of innovations to lifetime utility would have great
practical value for economists in areas where market choices are not fully informative
about preferences. Even if such an assumption is only approximately true, it would mean
that the dynamics of happiness could be used to study interpersonal dependencies in the
utility function, preferences over events largely outside of one’s control such as the death
of one’s spouse, and preferences over nonfinancial aspects of public policy. Work on this
hypothesis is still in its infancy. Kimball, Helen Levy, Fumio Ohtake and Yoshiro Tsutsui
(2006) and Kimball, Ryan Nunn and Daniel Silverman (2015) are examples of work in
this area. (Here it is important to distinguish between focusing on the short-run dynamics
of happiness as informative and studying the long-run changes once the dynamics have
settled down, as in, say, Takuya Ishino, Akiko Kamesaka, Toshiya Murai and Masao
Ogaki.)
V. Studying Finite Cognition
Taking a simplified view of information as recorded data and data summaries, for the
purposes of this paper I will call all of the other operations of the human mind besides the
bare recording and accessing of information “cognition,” without the finer distinctions
that psychologists often focus on. Moreover, to avoid the judgment Herbert Simon’s
phrase “bounded rationality” can inadvertently suggest, I will refer instead to “finite
2

Layard (2005) explicitly makes some of the policy recommendations that would flow from assuming that
self-reported happiness directly indicates true preferences. It is sometimes hard to distinguish the view that
self-reported happiness is equal to a version of utility in the economist’s sense of utility from a view
common among psychologists studying happiness (following Kahneman, 1999) that self-reported
happiness is distinct from preferences, but that as a matter of public policy we should maximize the present
discounted value of self-reported happiness rather than give people what they prefer.
7

cognition.”3 Finite cognition means something more than just imperfect information—it
means finite intelligence, imperfect information processing, and decision-making that is
costly. Finite cognition is the second key theme I see for Cognitive Economics.
If true, explanations based on finite cognition have enormous practical consequences and
policy implications. In particular, finite cognition implies that even in the absence of
externalities, welfare can often be improved by economic education, setting up
appropriate default choices for people, or providing disinterested, credible advice. By
contrast, explanations of puzzling behavior on the basis of individuals maximizing exotic
preferences imply (if true) that welfare improvements must come in the standard way
from addressing externalities, or in the case of inconsistent preferences, by taking sides in
an internal conflict. Once puzzling behavior that is difficult to explain on the basis of
standard economic theory is identified, it is hard to think of a more important question
than whether people behave that way because they want to, or simply because they are
confused.
My perspective on finite cognition is close to that of the excellent discussion by Conlisk
(1996). So I will limit myself to highlighting a few of what I consider the most salient
points, with my own spin.
A. The Reality of Finite and Scarce Cognition. The first key point is the reality of
finite cognition. Although the inadequacies of our current tools can make it hard to study
finite cognition theoretically, the claim that human intelligence is finite--and that finite
intelligence matters for economic life—scarce cognition—is not really controversial.4
Even those economists whose opinion of their own intelligence is unreasonably exalted
are regularly reminded by what they see in students and coworkers that not everyone has
unlimited intelligence. Many people pay substantial sums for financial advice even aside
from commissions on transactions. Even those who have low wage rates, so that their
time is less expensive, often pay others to do their tax returns. As for lawyers, even if one
considers talking in a courtroom a special skill that is not just a matter of intelligence,
people pay a lot of money to lawyers who only read law books and extract the relevant
information. If everyone had infinite intelligence, it would be easy to understand the law
books on one’s own, and paying someone else to do it would only make sense if one’s
3

Often, the inadvertent judgment suggested by “bounded rationality” is quite inappropriate. For example,
if decision-making is actually costly, which is more “rational,” to choose in a way that takes into account
the costliness of decision-making or to pretend that decision-making has zero cost? If one’s intelligence is
actually finite, which is more rational, taking into account the limits on one’s intelligence, or pretending
that one’s thinking power is unlimited? There is certainly a sense in which knowing and adjusting to one’s
own limitations can often be the height of “rationality.”

4

There are many problems that are too hard for even very high levels of intelligence. For example, one of
the problems with Bayesian updating is that, strictly speaking, it involves putting a positive probability on a
much greater than astronomically huge set of possibilities. Various strategies of economizing on
information processing are always essential in practice. Even the existence of a utility function itself is, in
a sense, a technique of economizing on information transfer and processing. If evolution could process an
infinite amount of information, and the genetic code could transmit an infinite amount of information, we
could be endowed with decision rules embracing essentially all contingencies instead of mere objective
functions and calculation capabilities.
8

wage rate was higher than the lawyer’s wage rate, or if one was a slow reader for
physiological reasons. If everyone had infinite intelligence, even finite reading speeds
would not give trained lawyers enough of an edge for them to charge the fees they do.
One of the most important economic manifestations of finite intelligence is the expensive
and time-consuming acquisition of human capital. Most obviously, the large amount of
resources devoted to mathematical education and research would make little economic
sense in a world in which everyone had infinite cognition. Mathematicians spend their
entire careers discovering and teaching things with very little informational content about
the external world—things that would be easily deducible by anyone with infinite
intelligence. In other subject areas, education may involve a significant amount of
straightforward information transfer. But in most areas, the acquisition of useful habits
of thought is at least as important.5 Teaching students to “think like an economist” is
itself somewhere between information transfer and the inculcation of some of those
useful habits of thought. Below I present a model of the effects of being taught a
standard model of portfolio choice. This is an area where I think many individuals are
confused and where making the right choices is important. This model of
misunderstanding is relatively simple, but breaks some of the normal theoretical taboos.
The remainder of this section makes the case for why it is sometimes necessary to break
those taboos.
B. Difficulties in Studying Finite Cognition with Standard Theoretical Tools. One
key reason it is not easy using our standard theoretical tools to model finite cognition is
the “infinite regress” problem emphasized by John Conlisk (1996). The infinite regress
problem afflicts models that assume a cost of computation or other decision-making cost.
The problem is that figuring out how much time to spend in making a decision is almost
always a strictly harder decision than the original decision. In particular, one would
typically need to know the right choice to the original decision in order to calculate the
value of making additional computations in order to make the right choice instead of
another choice. Given costly decision-making, the agent faces a serious issue of figuring
out whether it is worth thinking carefully about the original problem, which leads to the
issue of figuring out whether it is worth thinking carefully about thinking carefully about
the original problem, and so on.
Costs to decision-making are a natural enough assumption for economists that a
substantial percentage of all applied economic theory papers might include them, if it
were not for the infinite regress problem. Finessing the infinite regress problem
somehow is essential if economists are to develop effective theoretical tools for studying
finite cognition. There are several feasible strategies for getting around the infinite
regress problem—every one of which requires breaking at least one inhibition shared by
5

This becomes clear when one thinks of what education that was straightforward Bayesian updating of
information would look like. After diligent information acquisition in elementary and secondary school,
students would arrive at college with a mental checklist of blanks to be filled in as “True” or “False” and
parameter values (including probabilities) to be adjusted according to each new piece of data encountered.
Education as straightforward Bayesian updating would not involve any true insights—only partial
confirmations and disconfirmations of things students saw as at least dim possibilities from the very
beginning.
9

many economists. Least transgressive are models in which an agent sits down once in a
long while to think very carefully about how carefully to think about decisions of a
frequently encountered type. For example, it is not impossible that someone might spend
one afternoon considering how much time to spend on each of many grocery-shopping
trips in comparison shopping. In this type of modeling, the infrequent computations of
how carefully to think about repeated types of decisions could be approximated as if there
were no computational cost, even though the context of the problem implies that those
computational costs are strictly positive.
A second strategy is to give up on modeling finite cognition directly and use models of
limited information transmission capacity as a way of getting agents to make more
imperfect decisions. In other words, one can accept the fact that our standard tools
require constrained optimization with its implication of infinite intelligence somewhere in
the model, but handicap agents in the model by giving them a “thick skull” that is very
inefficient at transmitting information to the infinitely intelligent decision-maker within
(that is, the perfect constrained optimizer within). This is a way to interpret the program
of Christopher Sims (2002) that disconnects the implied transmission bit-rates from
anything in the external world, since low bit-rates would only be a metaphor for finite
cognition.6
A third feasible strategy is in the spirit of what the complexity theorists call “agent-based
modeling.”7 This typically involves modeling agents with very limited intelligence, such
as finite-state automata. One of the findings is that such very limited agents can still
handle some kinds of decisions surprisingly well. Many other modeling techniques such
as adaptive expectations or simple rules of thumb similarly endow the agents in models
with unrealistically subhuman intelligence. This type of modeling substitutes the problem
of agents that have unrealistically subhuman intelligence for the problem we have been
focusing on of agents that have unrealistically superhuman intelligence. Despite this lack
of realism, the results can be very instructive because the failure of realism is in the
opposite direction from what economists are used to.
In this paper, I would like to focus on a fourth strategy for getting around the infinite
regress problem--one that seems to me less commonly used: modeling economic actors
as doing constrained optimization in relation to a simpler economic model than the
model treated as true in the analysis. This simpler economic modeled treated as true by
the agent can be called a “folk theory.”8
6

Sticky information of various sorts has become an important topic area in macroeconomics. Michael
Woodford (2002) follows the Sims approach directly. A substantial literature stimulated by Greg Mankiw
and Ricardo Reis (2002) models sticky information as agents who only periodically incorporate new
external information into their inner information sets.
7
Agent-based modeling is a big emphasis of Bourgine and Nadal (2004). See also the review by N.
Wilcox (2005a).
8
Although the relevant chapters do not treat subjective views as formal folk theories, the theme of
subjectivity is important in the Austrian and Hayekian economics emphasized in Massimo Egidi and
Salvatore Rizzello (2004), a pair of edited volumes with the title Cognitive Economics. The work of Karl
Polanyi, with its emphasis on tacit knowledge, is also highlighted. A folk theory can be tacit, rather than
fully expressed by agents in words. See also the review by N. Wilcox (2005b).
10

A folk theory should not be confused with the Folk Theorem of repeated game theory.
We are talking about folk economics in the same sense as the well established ideas of
“folk psychology,” “folk physics” and “folk biology” (all of which are worth looking up
on Wikipedia).
My example of a folk theory model will be a partially uninformed household that solves a
portfolio choice problem as if the objective function were additively separable in the
outcomes for the various securities making up the portfolio. The justification for such a
modeling approach is the idea that it is possible for economic actors to be aware of a
simple economic theory, but unaware of more sophisticated economics. This lack of
awareness makes them act in their own eyes as if the simpler theory were true.
C. Modeling Unawareness Requires a Subjective State Space for the Economic
Actor Distinct from the True State Space.9 The idea of someone being unaware of an
idea, while intuitive, has more radical theoretical implications than one might at first
suspect. These implications are encapsulated in the title of an important paper by Eddie
Dekel, Bart Lipman and Aldo Rustichini (1998): “Standard State-Space Models Preclude
Unawareness.”10 Dekel, Lipman and Rustichini (1998) say the following about two
“properties of knowledge [that] are usually assumed, but will prove problematic for an
agent who is unaware of something”:
“Necessitation is the assumption that the agent ‘knows all tautologies.’ This name comes from the
philosophy literature. Monotonicity says that if E implies F, then knowledge of E implies knowledge
of F.
The reader should suspect that there will be problems with making these assumptions hold in a
model where the agent is unaware of some possibilities. Both seem to require the agent to have a

9

The proof of this statement in Dekel, Lipman and Rustichini (1998) involves assuming event sufficiency
(the very useful assumption that if two propositions are true on the same subset of a state space, the agent is
aware of one if and only if she is aware of the other), plausibility (unawareness implies not knowing and
not knowing that one doesn’t know), KU introspection (one never knows one is unaware of a particular
event), AU introspection (being aware of the possibility of being unaware of a specific event implies being
aware of the possibility of that event) and weak necessitation (being aware of a proposition implies being
aware of “obvious” tautologies involving that proposition, such as the statement that the proposition
implies itself).
10
My attempt to translate the formal mathematical argument for why “standard state space models preclude
unawareness” into words (though admittedly not into normal English) goes as follows. Because of the
fundamental meaning of “unawareness,” for any event, it is a contradiction to know that you are unaware of
that event, since that knowledge of unawareness would make you aware of the possibility of the event. If
you know the state space (as several different tempting assumptions imply you would), you know the
things that are always true in the state space, including this basic logic. That is, you know that you will
never know that you are unaware of a particular event. But knowing that you don’t know something
implies that you are aware of the possibility of that thing. In particular, knowing that you will never know
that you are unaware of a particular event means you must be aware of the possibility of being unaware of
that particular event. But being aware of the possibility of being unaware of something implies that you are
aware of that thing. In particular, being aware of the possibility of being unaware of a particular event
implies that you must be aware of the possibility of that particular event. Since this argument works for
any event, if you know the state space, you must be aware of the possibility of every event in that state
space.
11

certain understanding of the state space which seems questionable when the agent is unaware of
something.” (p. 164)

Later on, Dekel, Lipman and Rustichini (1998) argue for relaxing what they call the “real
states” assumption as follows:
“In standard state-space models, states play two distinct roles: they are the analyst’s descriptions of
ways the world might be and they are also the agent’s descriptions of ways the world might be. If the
agent is unaware of some possibility, though, ‘his’ states should be less complete than the analyst’s. In
particular, the propositions the agent is unaware of should not ‘appear in’ the states he perceives.”

This description of the real states assumption is very close to what the stricture of
“rational expectations” has meant in practice within macroeconomics: whatever model
the analyst is using, the agent also has that model in her mind.11 Departures from the
real states assumption would allow agents to have a different model of the economic
situation in their minds than the maintained assumptions the analyst is using to model the
situation of those very agents.12 For example, the agents might have in mind an outdated
model of the economic situation that appeared in a highly respected economics article
from years gone by, while the analyst takes a more sophisticated model as the maintained
assumption. In this case, to say that it is ridiculous for the agents to have in mind that
outdated economic model would be to claim that it was unreasonable for anyone-esteemed predecessor or no--to ever have entertained the outdated model.
For example, think of a high school senior deciding whether or not to go to college.13
Suppose going to college will reduce computation costs that aid in future economic
decision-making. Full-scale calculation of the value of this reduction in economic
decision-making costs would involve knowing what the optimal decisions are for many
choices in the future, as well as the likely faulty decisions given higher decision-making
costs. But the high school senior need not be modeled as approaching this problem as a
full-scale Bayesian optimizer. Instead, the high-school senior might be modeled as
having in mind a simple black-box model of human capital similar to Becker’s original
human capital model, with some very rough expectations about what the value of the
benefits of education are.14

11

For perspective on expectations, it is useful to read early discussions of expectations in economics such
as G. Shackle (1949).
12
Since the economic theorist would then know more about the fundamental situation than the agent the
theorist is modeling, a departure from the real states assumption could be in the opposite direction from the
common econometric assumption that the agents know more than the econometrician. Of course, both gaps
can happen: the analyst could know more of the basic structure of the situation, while the agent knows
certain parameters better.
13
Finite cognition is an unavoidable issue when making decisions about one’s own education. See Kimball
(2013) and Kimball and Smith (2013).
14
One practical implication for economists of such a failure of full-scale rational expectations is that
expectations must be measured rather than deduced. Given the fact that the high school senior cannot
really calculate the true value of the benefits of education, there is no reason to assume that these
expectations will be tightly anchored to the true value, so empirical implementation of such a model should
ideally include an attempt to directly measure the expectations of high school seniors.

12

Note that if someone is successfully taught a more sophisticated model, this would
involve an expansion in the individual’s subjective state space. If positive probabilities
were accorded to the newly added states, this must necessarily involve a departure from
Bayesian updating.
Presumably it is also possible for people to “see the light” even without being explicitly
taught. For example, the agent might be driven to entertain an expanded model if the
probability of observed events conditional on the initial folk model ever appeared
sufficiently low.15 We all recognize the practical importance of expansions in one’s
subjective state space when in scientific contexts we say “Asking the right question is
half the battle.”
D. Using Folk Theories to Model Finite Cognition: A Portfolio Choice Example.
Ultimately, the choice among folk theories in a folk theory model must be based on direct
evidence about how people view the world. But to design questions to determine how
people view the relevant aspects of the world, it is important to develop formal candidate
folk theories, just as it is important to develop the theories that we as analysts treat as our
best approximation to the truth.
The definition of a folk theory in this context is simply any theory that one or more
agents in the model hold--other than the theory the analyst is taking as the maintained
hypothesis. Clearly, the desirable properties for a modeled folk theory are quite different
from the desirable properties for a theory proposed as a good approximation of reality. A
folk theory need not be logically consistent at a deep level. Indeed, in representing
reality, it may be a positive virtue for a folk theory to have logical inconsistencies of a
form similar to the logical inconsistencies real people might have in their views of the
world. Other than (a) descriptive accuracy as a reasonable representation of how people
actually view the world, for theoretical purposes the key desirable properties for a
modeled folk theory are (b) providing a clear prediction for how the people holding that
folk theory will behave in various circumstances and (c) representing clearly what the
people holding the folk theory are confused about and what they do understand. In terms
discussed in Richard Herrnstein (1997)--particular in the chapters with Drazen Prelec--a
folk theory should at least implicitly model the accounting framework that an agent uses,
in addition to the objective function.
Because it need not be logically consistent at a deep level, the argument for a folk theory
can involve (correct reasoning about) logical leaps and plausible, though fallacious
reasoning. In our model of a folk theory of portfolio choice, I propose that people have
heard that (1) mean return is good, (2) risk is bad and (3) diversification is good.
Diversification being good might be represented by a maxim such as “Don’t put all of
15

That is, if one is willing to depart from Bayesian updating, the reliance of an agent on a simple model S
need not imply that the agent will react with denial to overwhelming evidence against S. But if the only
way one is willing to describe an agent’s reliance on the simple model S is to say that the agent puts a zero
prior probability on anything outside of S, then one is forced to predict that the agent will react with denial
even to overwhelming evidence against S. More commonly, to avoid the implication of heedless denial, the
agent is implicitly assumed to have a strictly positive prior probability on a huge range of possibilities, so
that whatever the analyst thinks is the truth is sure to be included as something the agent thinks is possible.
13

your eggs in one basket.” In order to provide a clear prediction for what people will do, I
will model portfolio choice as a maximization problem, but a maximization problem
using an ill-founded indirect utility function. Indeed, I intend the maximization problem
to be the kind of thing a bad economist who did not know the literature might come up
with to represent the three ideas (1) mean return is good, (2) risk is bad and (3)
diversification is good.
The agent is assumed to face (or believe she faces) a no short-sales constraint and solves

max
si  0

 si 1

 (

i

i

  i2 / 2)( si   si2 / 2),

i

where si is the share of each asset i in the agent’s financial portfolio, μi is the mean real
return, γ is risk aversion, σi2 is the variance of the real return of asset i, and θ is the
diversification parameter. (A plausible variant of this folk theory would use the nominal
mean and variance of the return.)
There are several things worth pointing out about this folk theory. First, for this agent,
the concept of diversification is not well connected to the risk considerations that better
theories link it to. Indeed, tendency toward diversification has its own separate
parameter, θ. Some agents could have high risk aversion but no motivation towards
diversification, while others have a strong motivation to diversify (but still without much
understanding) corresponding to a high θ. Second, other than the overall constraint that
shares must add up to 1, each asset is treated separately. The agent has no understanding
of hedging. What is worse from a welfare point of view, the agent has no understanding
that diversification reduces risk enough that it is relatively safe to hold a large amount of
risky assets overall. The agent will be helped if some of the assets indexed by i are
actually mutual funds. But in this case, the agent may “diversify” by choosing several
mutual funds of the same type. Much more could be said, but this gives some idea of the
kinds of “puzzles” this folk theory could help to explain. (However, I don’t intend this
folk theory model to be taken that seriously, but only to illustrate what I mean by a “folk
theory model.”)
Consider now what an agent would gain and lose by being taught a still grossly
inadequate, but to economists somewhat more familiar type of indirect utility function,
leading to

max

si  0
si 1



 s
i

i i

   si2 i2 .
i

i

14

Although this second folk theory ignores all covariances between assets, it does convey
the idea that diversification allows one to safely hold a relatively large amount of risky
assets, since it multiplies the variances of returns by the squared shares. Indeed, this folk
theory would tend to overstate this benefit of diversification, since positive covariances
apply between most pairs of assets.
A third folk theory would get much closer to how economists usually think:

max s '    s ' s ,
s 0

 s 1
i

where s is the vector of asset shares, μ is the vector of mean returns and Ω is the variancecovariance matrix of returns. Note that even this folk theory omits many important
things. For example, it omits integration of human capital into the portfolio, and the
implication of this integration that many people who have small amounts of financial
wealth but large amounts of human capital uncorrelated with the market should have all
of their wealth in a leveraged, diversified market fund. It also omits subtle implications of
an intertemporal model, such as the understanding that many of the apparent financial
risks of fluctuations in the long-term real interest rate are canceled out by the
corresponding shifts in the price of purchasing a given stream of future consumption.
The understanding this third folk theory brings of covariances comes at the considerable
cost of either needing to understand vector and matrix notation, or being able to deal with
the messy algebra that would be revealed using scalar notation.
In reality, I am confident that people’s thinking about portfolio choice varies from person
to person with a wild profusion of different kinds of misunderstanding. In most other
contexts as well—at least where there is some complexity--any model that assumes
everyone’s folk theory is of the same type is likely to be false. Realizing that people don’t
always have the same mental model of a situation as the economist studying that situation
is the first step toward facing the motley truth about people’s folk theories.
VI. Conclusion
Economic research using more and more direct data about what is in people’s minds is
flourishing. But much more can be done. Fostering continued progress in this area of
Cognitive Economics calls for three inputs. First, new theoretical tools for dealing with
finite cognition need to be developed, and existing theoretical tools sharpened. Second,
welfare economics needs to be toughened up for the rugged landscape revealed by
peering into people’s minds. Third, the statement “The data are endogenous” needs to
become not only an econometrician’s warning but also a motto reminding economists that
new surveys can be designed and new data of many kinds can be collected to answer
pressing questions.
Acknowledgements

15

Conversations with Robert Willis inspired this paper. I would also like to thank
participants at the Japanese Economic Review conference at Keio University. This work
was supported by National Institute on Aging grants P01-AG026571 and R01-AG040787
to the University of Michigan.
References
Almlund, Mathilde, Angela Lee Duckworth, James J. Heckman and Tim D. Kautz, 2011.
“Personality Psychology and Economics,” in E. Hanushek, S. Machin, and L. Woessman,
eds., Handbook of the Economics of Education, Amsterdam: Elsevier. pp. 1-181. (2011).
Benjamin, Daniel J., Ori Heffetz, Miles S. Kimball, and Alex Rees-Jones (2012). “What
Do You Think Would Make You Happier? What Do You Think You Would
Choose?” American Economic Review, 102(5), 2083–2110.
Benjamin, Daniel J., Ori Heffetz, Miles S. Kimball, and Alex Rees-Jones (2014). “Can
Marginal Rates of Substitution Be Inferred From Happiness Data? Evidence from
Residency Choices.” American Economic Review, 104(11), 3498-3528.
Benjamin, Daniel J., Ori Heffetz, Miles S. Kimball, and Nichole Szembrot. 2014.
"Beyond Happiness and Satisfaction: Toward Well-Being Indices Based on Stated
Preference." American Economic Review, 104(9): 2698-2735.
Bourgine, Paul, and Jean-Pierre Nadal (eds.), 2004.
Interdisciplinary Approach, Berlin, Springer-Verlag.

Cognitive Economics: An

Conlisk, John, 1996. “Why Bounded Rationality?” Journal of Economic Literature,
34(2) (June), 669-700.
Dekel, Eddie, Barton Lipman and Aldo Rustichini, 1998. “Standard State-Space Models
Preclude Unawareness,” Econometrica 66 (January), 159-173.
Dietrich, Franz and List, Christian, Mentalism Versus Behaviourism in Economics: A
Philosophy-of-Science Perspective (April 1, 2012). Available at SSRN:
http://ssrn.com/abstract=2033165 or http://dx.doi.org/10.2139/ssrn.2033165
Dietrich, Franz, and Christian List, 2012. “Mentalism versus behaviourism in economics:
a philosophy-of-science perspective.”
Dominitz, Jeffrey, and Charles Manski, 2011. “Measuring and Interpreting Expectations
of Equity Returns,” Journal of Applied Econometrics, 26(3), pp. 352-370.
Egidi, Massimo, and Salvatore Rizzello (eds.), 2004. Cognitive Economics (Volumes I
and II), Cheltenham, UK and Northampton, MA, USA, Elgar.

16

Faruk Gul and Wolfgang Pesendorfer, “The Case for Mindless Economics,” in: The
Foundations of Positive and Normative Economics, by Andrew Caplin and
AndrewShotter (eds.). Oxford University Press. 2008.
Herrnstein, Richard, 1997. The Matching Law: Papers in Psychology and Economics,
Harvard University Press, Cambridge, MA.
Hudomiet, Peter, Gabor Kezdi, and Robert Willis, 2011. "Stock market crash and
expectations of American households." Journal of Applied Econometrics, 26(3): 393-415.
Ishino, Takuya, Akiko Kamesaka, Toshiya Murai and Masao Ogaki, 2012. “Effects of the
Great East Japan Earthquake on Subjective Well-Being,” Journal of Behavioral
Economics and Finance, 5 (Proceedings of the 6th Annual Meeting), 269‒272
Kahneman, Daniel, 1999. “Objective Happiness,” chapter 1 in Daniel Kahneman, Ed
Diener and Norbert Schwarz eds., Well-Being: The Foundations of Hedonic Psychology,
Russell Sage Foundation, New York.
Kimball, Miles, 2013. “The Unavoidability of Faith,” blog post, Confessions of a SupplySide Liberal
http://blog.supplysideliberal.com/post/64545705877/the-unavoidability-of-faith
Kimball, Miles, Helen Levy, Fumio Ohtake and Yoshiro, Tsutsui, 2006. “Unhappiness
after Hurricane Katrina,” National Bureau of Economic Research Working Paper #12062
Kimball, Miles, Ryan Nunn and Daniel Silverman, 2015. “Accounting for Adaptation in
the Economics of Happiness,” unpublished.
Kimball, Miles, Claudia Sahm, and Matthew D. Shapiro, 2008. "Imputing Risk
Tolerance from Survey Responses,” Journal of the American Statistical Association 103
(September) 1028-1038.
Kimball, Miles, Matthew D. Shapiro, Tyler Shumway and Jing Zhang, 2015. "Portfolio
Rebalancing in General Equilibrium," working paper, University of Michigan.
Kimball, Miles, and Noah Smith, 2013. “There’s one key difference between kids who
excel at math and those who don’t,” Quartz (online magazine)
http://qz.com/139453/theres-one-key-difference-between-kids-who-excel-at-math-andthose-who-dont/
Kimball, Miles, and Robert Willis, 2006. “Utility and Happiness,” unpublished,
University of Michigan.
Layard, Richard, 2005. Happiness. London, UK: Penguin Press. This book is based to a
large extent on Layard’s 2003 Lionell Robbins Memorial Lectures, London School of
Economics.

17

Mankiw, N. Gregory and Ricardo Reis, 2002. “Sticky Information Versus Sticky Prices:
A Proposal to Replace the New Keynesian Phillips Curve,” Quarterly Journal of
Economics, 117 (4), 1295-1328.
Sahm, Claudia R. Matthew D. Shapiro, and Joel Slemrod, 2012. “Check in the Mail or More in
the Paycheck: Does the Effectiveness of Fiscal Stimulus Depend on How It Is Delivered?” by
American Economic Journal: Economic Policy 4 216–250.
Shackle, George S., 1949. Expectations in Economics, Cambridge University Press.
Shapiro, Matthew, and Joel Slemrod, 2003. "Consumer Response to Tax Rebates" (Revised
version, October 2002) American Economic Review 93 (March) 381-396.
Sims, Christopher, 2002. “Implications of Rational Inattention,” unpublished paper,
Princeton University.
Wilcox, N. 2005a. “Review of Bourgine, P. and Nadal, J-P., eds., Cognitive Economics: An
Interdisciplinary Approach. Berlin: Springer-Verlag, 2004.” Journal of Economic Psychology
26(4):599-601.
Wilcox, N. 2005b. “Review of Egidi, M. and Rizello, S., eds., Cognitive Economics (Volumes I
and II). Cheltenham, UK: Elgar, 2004.” Journal of Economic Psychology 26(5):788-792.
Woodford, Michael, 2002. “Imperfect Common Knowledge and the Effects of Monetary
Policy," in P. Aghion, R. Frydman, J. Stiglitz, and M. Woodford, eds., Knowledge, Information,
and Expectations in Modern Macroeconomics: In Honor of Edmund S. Phelps, Princeton Univ.
Press.

18

