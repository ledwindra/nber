NBER WORKING PAPER SERIES

IDENTIFICATION WITH IMPERFECT INSTRUMENTS
Aviv Nevo
Adam M. Rosen
Working Paper 14434
http://www.nber.org/papers/w14434

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
October 2008

We thank Joel Horowitz, Chuck Manski, Rob Porter, and Elie Tamer as well as seminar participants
at Northwestern University, University College London, SITE, University of Paris I, and the University
of Toronto for comments. Adam Rosen gratefully acknowledges financial support form the Center
for the Study of Industrial Organization, the Eisner Memorial Fellowship at Northwestern University,
and the Economic and Social Research Council through the ESRC Centre for Microdata Methods
and Practice grant RES-589-28-0001. The authors are solely responsible for any and all errors. The
views expressed herein are those of the author(s) and do not necessarily reflect the views of the National
Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2008 by Aviv Nevo and Adam M. Rosen. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

Identification with Imperfect Instruments
Aviv Nevo and Adam M. Rosen
NBER Working Paper No. 14434
October 2008
JEL No. C30,C31,C33
ABSTRACT
Dealing with endogenous regressors is a central challenge of applied research. The standard solution
is to use instrumental variables that are assumed to be uncorrelated with unobservables. We instead
assume (i) the correlation between the instrument and the error term has the same sign as the correlation
between the endogenous regressor and the error term, and (ii) that the instrument is less correlated
with the error term than is the endogenous regressor. Using these assumptions, we derive analytic
bounds for the parameters. We demonstrate the method in two applications.

Aviv Nevo
Department of Economics
Northwestern University
2001 Sheridan Road
Evanston, IL 60208-2600
and NBER
nevo@northwestern.edu
Adam M. Rosen
Department of Economics
Gower Street
London WC1E 6BT
adam.rosen@ucl.ac.uk

Identi…cation with Imperfect Instruments
Aviv Nevoy

Adam M. Rosenz

Northwestern University and NBER

UCL, IFS, and CEMMAP

July 16, 2008

Abstract
Dealing with endogenous regressors is a central challenge of applied research. The standard solution
is to use instrumental variables that are assumed to be uncorrelated with unobservables. We instead
assume (i) the correlation between the instrument and the error term has the same sign as the correlation
between the endogenous regressor and the error term, and (ii) that the instrument is less correlated with
the error term than is the endogenous regressor. Using these assumptions, we derive analytic bounds for
the parameters. We demonstrate the method in two applications.

1

Introduction

Dealing with endogeneity is one of the central issues in non-experimental studies. A common method for
dealing with potential endogeneity issues in econometric models is to use an instrumental variable (IV). In
linear models an IV has to be correlated with the endogenous covariate and uncorrelated with the econometric
unobservable. The former condition is known as relevance, or strength of the IV, and the latter as exogeneity,
or validity.
The exogeneity assumption cannot be tested in many cases and therefore the validity of the identifying
restrictions is based on the subjective judgement of the researcher. Unfortunately, even when great care is
We thank Joel Horowitz, Chuck Manski, Rob Porter, and Elie Tamer as well as seminar participants at Northwestern
University, University College London, SITE, University of Paris I, and the University of Toronto for comments. Adam Rosen
gratefully acknowledges …nancial support form the Center for the Study of Industrial Organization, the Eisner Memorial
Fellowship at Northwestern University, and the Economic and Social Research Council through the ESRC Centre for Microdata
Methods and Practice grant RES-589-28-0001. The authors are solely responsible for any and all errors.
y Address: Aviv Nevo, Department of Economics, Northwestern University, 2001 Sheridan Road, Evanston, IL 60208-2600,
nevo@northwestern.edu.
z Address: Adam Rosen, Department of Economics, University College London, Gower Street, London WC1E 6BT,
adam.rosen@ucl.ac.uk.

1

taken, the validity of the instruments chosen is often a matter of faith. Empirical …ndings are often called into
question as a result of debate over the IV assumptions. Furthermore, the search for exogenous IVs sometimes
leads the researcher towards IVs that are weak, i.e., are only weakly correlated with the endogenous variable.
In this paper we examine identi…cation when we replace the standard exogeneity assumption with a
weaker inequality. We set up the model in general, but in order to obtain analytic results we focus on a
linear equation with one endogenous regressor, when the researcher has at least one imperfect instrumental
variable (IIV). The IIV is allowed to be correlated with the error term. We show that without further
assumptions this variable does not identify even the direction of the bias of the least squares estimator.
We assume that the sign of the correlation between the IIV and the error term is the same as the
correlation between the endogenous variable and the error term. We show how this assumption can be used
to partially identify the parameter of interest. In particular, we show that if the IIV and the endogenous
variable are negatively correlated, the parameter of interest can be bounded both from above and below.
We add the assumption that the correlation coe¢ cient between the IIV and the error term is less than the
correlation coe¢ cient between the endogenous variable and the error term. That is, the IIV is thought to
be correlated with the unobservable in the equation of interest, but less so than the endogenous regressor.
Using this assumption we improve the bounds. Finally, we discuss the case where several IIVs are available.
Of particular interest is the case where none of these variables provide useful bounds on their own. We show
how di¤erencing the variables to create an IIV can generate meaningful bounds.
A strength of our approach is its simplicity. By focusing on the linear model we are able to analytically
characterize the identi…ed set. Furthermore, the bounds we compute are well known estimators that are
computed by standard econometric packages. Thus, the estimation and inference are simple to do, and
require little additional programming. Indeed, many of the numbers we need to compute our bounds are
available in many published papers.
We apply our estimator to two common examples in the Industrial Organization literature: production
function estimation and demand estimation. While our motivation lies in applications such as these, the
method is more generally applicable in practically all …elds of economics. The applications demonstrate that,
at least in the cases we examine, our approach can generate useful bounds on the parameters of interest.

1.1

Related Literature

Three related papers that also consider inference when instrument exogeneity fails are Conley, Hansen, and
Rossi (2006), Hahn and Hausman (2003a), and Manski and Pepper (2000).
2

Like our own work Conley,

Hansen, and Rossi (2006) consider a linear model with endogenous regressors and invalid instruments.
However, they take an alternative approach to ours by parameterizing the degree of instrument endogeneity
by its associated coe¢ cient, denoted
instruments jointly.

, in a linear regression of the outcome variable on regressors and

They …rst investigate the degree to which knowledge of only the support of

be used to infer the parameter of interest

.

can

They then consider the added bene…t of specifying a prior

distribution for , and the implications of imposing a prior distribution over all model parameters jointly.
This provides useful (set) identi…cation results, inferential procedures, and methods of sensitivity analysis,
though for a di¤erent set of modeling assumptions than those considered here.

Rather than derive the

identi…ed set for model parameters in the presence of imperfect instruments, Hahn and Hausman (2003a)
compare the mean-squared-error and bias of the OLS and 2SLS estimators when the instrument exogeneity
assumption fails.

Manski and Pepper (2000) characterize the identi…cation region for model parameters

when, instead of the usual exogeneity condition, the expectation of the outcome variable conditional on the
instrument is assumed to be monotone for any given value of the endogenous covariate. Unlike our analysis,
their analysis applies to nonparametric models, but focuses on a bounded dependent variable. When a linear
parametric model is imposed, as done in Manski and Pepper (1998), the Manski and Pepper assumptions
neither nest nor are nested by ours. The Manski and Pepper monotone IV assumption implies monotonicity
of the mean of the unobservable conditional on the instrument, whereas we employ weaker restrictions on
correlations. However, in addition to this we also impose restrictions on the relative correlations of exogenous
regressors with errors and instruments with errors, and there are no such restrictions imposed by Manski
and Pepper. A bene…t of the assumptions imposed in this paper, at least in the context of linear models,
are analytic results on the bounds of the parameter of interest, which are easy to compute with standard
regression software.
Related papers that bound parameters of a linear regression include those of Frisch (1934), Leamer (1981),
Klepper and Leamer (1984), and Bontemps, Magnac, and Maurin (2006). Frisch (1934) develops bounds
for the slope parameter in a simple linear regression model with measurement error. Klepper and Leamer
(1984) generalize this result to multivariate regression with errors in all variables, deriving bounds on the true
regression coe¢ cient vector. Leamer (1981) considers an under-identi…ed simultaneous equations model of
supply and demand without instruments to overcome the simultaneity problem. He shows that knowledge
of the signs of regression parameters, e.g. downward sloping demand, upward sloping supply, can be used
to bound the slope of either demand or supply via directed and reverse regression.

Bontemps, Magnac,

and Maurin (2006) study set identi…cation in linear models, providing an estimation procedure that relies
3

on an estimator for the identi…ed set’s support function. In addition, they generalize the Sargan test for
overidenti…cation to their setup, establishing a test of supernumerary restrictions whose intersection may in
fact be a proper set, a point, or empty. While each of these papers provides bounds on the coe¢ cients of a
linear regression model, the models considered are quite di¤erent from the one we study in this paper.
Whereas this paper addresses the potential failing of the exogeneity condition for an instrument, the
recent literature on weak instruments and weak identi…cation confronts the possibility of the instruments
having little relevance.

This literature focusses on complications that arise when the relevance condition

is not strongly satis…ed, i.e. when the correlation between the endogenous regressor and the instruments is
small. Standard methods for inference with instrumental variables are known to perform poorly when the
instruments are weak (e.g. Rothenberg (1984), Nelson and Startz (1990), Bound, Jaeger, and Baker (1995),
and Dufour (1997)) or when the necessary rank condition fails altogether, see Phillips (1989). The literature
has thus sought to develop methods to test for weak IVs (e.g. Hahn and Hausman (2002) and Stock and
Yogo (2005)), as well devise inferential methods that are robust to weak instruments, such as Anderson and
Rubin (1949), Anderson and Rubin (1950), Staiger and Stock (1997), Wang and Zivot (1998), Zivot, Startz,
and Nelson (1998), Stock and Wright (2000), Dufour and Jasiak (2001), Chioda and Jansson (2005), Dufour
and Taamouti (2005), Guggenberger and Smith (2005), Kleibergen (2005), Andrews, Moreira, and Stock
(2006), and Andrews and Marmer (2008). An extensive review of this literature is well beyond the scope
of this paper, but surveys are given by Stock, Wright, and Yogo (2002), Dufour (2003), Hahn and Hausman
(2003b), and Andrews and Stock (2007).
We focus on the possibility that the variables employed as instruments fail to satisfy the exogeneity
condition rather than the relevance condition.

Interestingly, we show that the correlation between the

instrumental variable and the endogenous regressor plays a key role, much like it does in the case of weak
IV. In our case, however, the key condition is that this correlation be negative. The larger its magnitude,
the tighter are the bounds.
In section 2 we lay out the more general setup and develop conditions that de…ne the identi…ed set.
In section 3 we …rst focus attention on the special case of a simple linear regression with one imperfect
instrument, and characterize analytically the identi…cation region for the slope parameter

.

We then

extend the results to the multiple regression model and discuss the case of several imperfect IVs. Section
4 then discusses estimation and inference.

Section 5 provides two empirical illustrations and section 6

concludes.

4

2

The Model

2.1

The Setup

The econometrician is interested in identifying the parameters of a regression with one endogenous variable
and an arbitrary number of exogenous variables. For each observation, the outcome variable Y is a function
of an endogenous covariate X, a 1

kw vector of additional covariates W , and U , an additively separable

mean zero error unobserved by the econometrician. We assume a parametric functional form.
Assumption AP (parametric functional form):

Y = m (X; W; ) + U ,

where

is a vector of parameters and m (X; W; ) is twice continuously di¤erentiable in .

For some results, we focus on the case where the function m ( ; ; ) is linear in parameters.
Assumption AL (linear model):

=

;

0 0

and

Y = X + W + U:

We further assume that there exists an observable vector of random variables Z which has dimension kz .
These will be imperfect instruments in the sense de…ned in our assumptions A3 and A4 below. In addition,
we assume the existence of a 1

kw vector of valid instruments Z w , which may include elements of W if

some of the regressors are themselves exogenous. If the number of valid instruments exceeded the dimension
of W , then model parameters would be point-identi…ed under the usual rank condition for Z w0 (X; W ), and
model parameters could be consistently estimated by standard instrumental variable methods such as GMM.
For this reason, we restrict the number of valid instruments to be equal to the number of elements of W .
We assume the econometrician observes a random sample of (Y; X; W; Z; Z w ) drawn from population
( ; F; P).

We use the subscript i to denote observations drawn from this population, and subscript j to

denote individual elements of these vectors.
0

Assumption A1 (random sampling): (yi ; xi ; wi ; zi ; ziw ; i ) , i = 1; :::; n are iid realizations from P.
We assume that the distribution P is such that the valid instruments Z w are exogenous, in the sense
that each component of Z w is uncorrelated with the unobservable U , but X is endogenous.
Assumption A2 (Z w exogenous, X endogenous): E (Z w0 U ) = 0, E (XU ) 6= 0.

5

The variable X may be correlated with U . This can happen, for example, when the value of X is chosen
by an economic agent who observes U prior to choosing X. In this case, in the linear model identi…cation
and estimation of the model parameters

typically relies on the use a vector of instrumental variables that

are correlated with X but not with U .

Such IV assumptions are often called into question in empirical

work, and in some cases may be untestable. We assume instead that the econometrician has observations
of some imperfect instruments, Z that are also correlated with the unobservable U , but less so than the
endogenous regressor X, which we formalize below in assumptions A3 and A4.

We assume that kz , the

number of imperfect instruments, is …xed.
Formally, the assumptions we impose on our imperfect instruments (IIV) are as follows.
notation

ab

and

ab

We use the

throughout to denote the covariance and correlation, respectively, between any two

random variables a; b.
Assumption A3 (same direction of correlation):

xu zj u

0 , j = 1; :::kz .

Assumption A4 (instruments “less endogenous” than x):

j

xu j

, j = 1; :::kz .

zj u

Assumption A3 asserts that the endogenous regressor X and the IIV have the same direction of correlation
with the error term. Assumption A4 then adds the condition that the IIV be less correlated with the error
term than the endogenous regressor.
zj u

Were we to replace A3 and A4 with the stronger assumption that

= 0, then Zj would be a valid instrument in the classical sense.

We also make use of the standard rank conditions which are needed for the probability limits of the
standard OLS and 2SLS estimators to be well-de…ned in the linear model.
0

Assumption A5 (rank and order): rank E (Z; Z w ) (Z; Z w )
0

kw + 1, and rank E (Z; Z w ) (X; W )

2.2

= kw + 1, kz

0

= kz + kw , rank E (X; Z w ) (X; Z w )

=

1.

Identi…cation

We now show how the modeling assumptions can be used to identify the parameters. The assumptions yield
a system of moment equalities and inequalities that restrict the feasible values of model parameters . In

6

general, these restrictions will not be su¢ cient for point identi…cation, but may still embody information
regarding the value of .
A useful starting point is to assume we know the relative correlations of the instrument Zj and regressor
X with the econometric error term. De…ne this correlation as

zj u = xu ,

j

(2.1)

Assumptions A3 and A4 are equivalent to the restriction that

j

2 [0; 1]. If

j

were known, then it could

be used to construct a weighted average of Zj and X that is uncorrelated with the error term. To see this,
de…ne the function Vj ( ) as
Vj ( )
By de…nition, Vj
0. Although
x

j

j

x Zj

zj X.

(2.2)

is uncorrelated with U , and satis…es the moment condition E (Y

m (X; W; )) Vj

is unknown, it o¤ers a convenient parameterization of the relative correlations of

, which will prove useful for characterization of the identi…ed set. The hope is that by varying

j

zj

j

and

between

0 and 1 we will be able to bound the parameters of interest.
The implied restrictions of assumption A1 - A4 are:

E Zjw0 (Y
E (Y

m (X; W; )) Vj
j

where

j

m (X; W; )) = 0,
j

(2.3a)

= 0, j = 1; :::; kz ,

(2.3b)

2 [0; 1] , j = 1; :::; kz ,

(2.3c)

and Vj ( ) are as de…ned in (2.1) and (2.2), respectively. Thus, the model parameters must satisfy

the kw + kz moment conditions (2.3a), (2.3b). If

=

1;

conditions were satis…ed, these moment conditions would identify

;

kz

were known and the standard rank

locally under the parametric model (AP)

and globally in the linear model (AL). These conditions could then be used for consistent estimation via
GMM. However, since

is only known to belong to the unit cube in Rkz ,

identi…ed. The identi…ed set for

is the set of parameter values that satisfy these restrictions.

Proposition 1 Let (AP), A1 - A4 hold. Then
Corollary 1 Suppose that AL holds. Then
The characterization of

will generally not be point

= f : conditions (2.3a)-(2.3c) holdg
is convex.

above can be used to perform estimation and inference on the identi…ed set
7

=

using a variety of methods recently considered for models comprised of moment equalities and inequalities,
see for example Chernozhukov, Hong, and Tamer (2007) and the references therein.
researcher is willing to sign

xu ,

one way this can be done is by rewriting (2.3b) and (2.3c) as 2kz moment

inequalities obtained by setting
E (Y

m (X; W; )) Vj

j

For example, if the

j

= 0 and

j

= 1 into (2.3b) to obtain lower and upper bounds on

. This allows for estimation and inference on the entire parameter vector ,

though in some cases one may be interested in inference on the marginal e¤ect of X.

3

The Linear Model

The characterization of the identi…ed set, provided in Proposition 1, is not very informative. For example, it
does not tell us if the identi…ed set is bounded in all directions. In other words, Assumptions 3 and 4 might
not be very informative. In this section, in order to obtain an analytic characterization of the identi…ed set,
we restrict attention to the linear model. We show that in the linear model, our modeling restrictions lead
to a straightforward characterization of the identi…ed set that can be exploited to perform (set) estimation
with standard linear regression methods.

We start with the simple linear model and then generalize the

results to multiple IIVs as well as additional regressors.

3.1

The Simple Linear Model with One Imperfect Instrument

Consider the simple linear model

Y =

+ X + U,

(3.4)

where E [U ] = 0.
For notational ease, we de…ne

OLS

and

IV
z

to be the probability limits of the standard OLS and IV,

with Z as the instrument, estimators for , respectively. That is

OLS

xy
2
x

=

xu
,
2
x

+

(3.5)

and
IV
z

zy

=

xz

+

zu
xz

b OLS and ^ IV are taken to be their corresponding estimators.
z
8

.

(3.6)

The true value of the parameter can be bounded when assumptions (A1)-(A3) are imposed.
Lemma 1 Let (A1), (A2), and (A3) hold.
upper bound if xu > 0, while
n
o
min OLS ; IV
, while if
z

If

xz

< 0 then

OLS

xu

is the lower bound if
n
< 0,
max OLS ;

lies between
< 0.
o
.

xu
IV
z

Lemma 1 gives a simple characterization of bounds for

OLS

If instead

and

IV
z

.

OLS

0, then if

xz

: Given assumptions A1-A3,

OLS

is the

xu

and

> 0,

IV
z

provide either two-sided or one-sided bounds for , depending on the correlation between X and Z, which
is identi…ed and can be consistently estimated.
If

< 0 assumption A3 can provide …nite, hopefully economically helpful, bounds on the parameter

xz

of interest. Before exploring the gains from imposing assumption A4, we ask under what conditions can the
direction of bias of the OLS estimator to be ascertained based on the IV estimator.
Lemma 2 Let A1-A3 hold. If

xz

< 0 or

OLS

sgn

When
Since

xz

xz

>

then

IV
z

< 0 it follows that the bias of

= sgn

OLS

OLS

.

has the same sign as

OLS

IV
z

, which is identi…ed.

is unknown however, the second condition generally will not be veri…able. A common intuition –

that, even if the IV is not valid, the IV estimate corrects the OLS estimate in the right direction –probably
comes from the case when

is small. Recall that

= 0 is the valid IV case. So

close to zero means

the IV is "almost" valid and then the conditions of the lemma are likely to hold. If the conditions of the
Lemma do not hold then an IIV will not even identify the direction of the bias in OLS.
Up to this point we did not impose Assumption A4, and were able to get two-sided bounds only if
xz

< 0. We now ask what we get from further imposing Assumption A4. As we said above the hope is

that by bounding

between 0 and 1 we obtain sharper identi…cation results than lemmas 1 and 2. The

following result shows exactly what we get from also imposing Assumption A4.
Proposition 2 Let A1-A4 hold. If

xz

< 0, then
h

B = h

IV
z

IV
v(1)

;

IV
v(1) ;

IV
z

i
i

if

xu

>0

if

xu

<0

where
IV
v(1)

z xy
x(

z x

9

x zy
xz )

.

(3.7)

If, on the other hand,

xz

> 0, then

B = h

IV
z

1; min
IV
v(1) ;

max

;

IV
v(1)

IV
z

;1

i

if
if

xu
xu

>0

< 0.

These bounds are sharp.
The bound

IV
v(1)

has a particularly simple characterization. It is the probability limit of the traditional

IV (2SLS) estimator for
V (1)

zX

x Z.

when V (1) is used as an instrument for X, where V ( ) is as de…ned in (2.2), i.e.

IV
v(1)

can also be written as a weighted average of

IV
v(1)

v(1)y

=

xv(1)

x

xz

1

2 OLS
z x

xv(1)
2
z x

=

In cases where

=

(

x xz
x

and

IV

, since

IV
x xz z

OLS
xz )

z x

OLS

(

xz )

z x

IV
z

.

> 0, Proposition 2 implies that imposing assumption A4 only slightly improves upon the

bound of Lemma 1 (in the sense that the bound is still one sided.) However, when

xz

< 0, Proposition

2 improves, in a somewhat more meaningful way, on the bounds given in Lemma 1. So while Assumption
A3 and A4 jointly bound

between zero and one, they do not in general provide two-sided bounds for the

parameter of interest, . To see why, note that if
bounded
sides. If

might not be bounded. If
xz

< 0 we can rule out

=

xz

=

xz

IV
v(

then

)

is not de…ned, so even though

> 0, we cannot rule out this case and

xz

since 0

1, and

is

is not bounded from both

is bounded from above and below.

While Assumption A4 does not give us two-sided bounds where they did not already exist, it does help
us tighten the bounds. Corollary 2, applies to the case where
two-sided bounds for beta.

xz

< 0, and where Proposition 2 achieves

This corollary characterizes the degree to which use of

the bounds provided by Lemma 1, which are just

OLS

and

IV
z

Corollary 2 If

xz

xz

=

improves upon

. The implication is that the greater the

magnitude of the correlation between x and z, the tighter the bound achieved using
with maximal improvement obtained when

IV
v(1)

IV
v(1)

instead of

OLS

,

1, in which case the size of the bounds is halved.

< 0, then
IV
v(1)
OLS

IV
z
IV
z

=

1
1

.
xz

Our results are consistent with the …nding of Hahn and Hausman (2003a) that if E [ZU ] 6= 0, it is possible
for

OLS

to be closer to

than

IV
z

. However, Proposition 2 further shows that this is possible even if the

10

instrument Z is less correlated with U than is the endogenous regressor X. Consider, for example, the case
i
h
IV
IV
IV
, and OLS
where xu < 0 and xz < 0, so that 2 IV
;
v(1) .
v(1) is a feasible value for , and
v(1)
z
IV
v(1)

is in fact closer to

su¢ ciently close to

OLS

IV
v(1) ,

than X, it is possible that

IV
z

than is

IV
z

because

“over-corrects” for

IV
z

IV
v(1)

OLS

OLS

=

xz

x

IV
v(1)

IV
z

. In this case, if

is

. Thus, even if the instrument is “less endogenous”

lead the researcher further astray than

that the instrumental variables estimator o¤ers an improvement over

3.2

z

OLS

OLS

, and it may not be the case

.

Additional Regressors

This section generalizes beyond the simple linear model, allowing for the presence of additional regressors,
as well as valid instruments in addition to the IIV. The regression of interest is

Y = X + W + U,

where X is univariate, W is a 1

(3.8)

kw vector of additional regressors (possibly including a constant), and

E [U ] = 0. Z is a univariate IIV such that satis…es assumptions A3 and A4 with respect to the endogenous
regressor X.

The additional regressors W may include exogenous and endogenous components, but we

assume that A2 holds, so that there is a 1
nonsingular and E [Z w0 U ] = 0.

kw vector of valid instruments Z w such that E [Z w0 W ] is

If any components of W are exogenous, then those will also be included

as components of Z w . Note that if the dimension of Z w exceeded that of W , there would be more valid
0

instruments than regressors. Then, as long as E (X; W ) Z w had full rank,

=

;

0 0

would be point-

identi…ed and consistently estimable by the usual IV estimation procedures. Thus, we restrict attention to
the case where Z w has the same dimension as W
The remainder of this section …rst generalizes our results from the simple linear model to derive bounds
on . We then construct the identi…cation interval for each individual component of . The identi…cation
results are constructive and the bounds take the form of expressions that are trivially estimable with standard
regression software.
component of

We focus on the case where there is only one IIV, as the identi…ed set for

or any

when there are multiple IIVs is the intersection of the intervals derived from using each of

the multiple IIVs individually, see section 3.3.

11

3.2.1

Bounds on

As shown in section 2.2, assumptions A3 and A4 are equivalent to the assertion that V ( ) =
is a valid instrument for X, for some unknown value of

2 [0; 1], which we denote

. Thus

xZ

zX

is given by

the usual IV formula:
1

0

) ; Z w ) (X; W )

= E (V (

E (V (

0

) ; Zw) Y

(3.9)

The residuals of an IV regression of X and Y on W using Z w as the instruments are given by

Isolating the …rst component of

~
X

X

W E [Z w0 W ]

1

E [Z w0 X] ,

(3.10a)

Y~

Y

W E [Z w0 W ]

1

E [Z w0 Y ] .

(3.10b)

in the IV regression above gives
h
=E V (

~
)X

i

1

h
E V(

i
) Y~ ,

or equivalently that
~ + U.
Y~ = X
Applying our analysis of the simple linear model to this regression then delivers the following bounds for ,
where

z y~

denotes the covariance of Z and Y~ ,

~ etc.
that between Z and X,

zx
~

Proposition 3 Let A1, A3, and A4 hold, and assume that E [Z w0 W ] is nonsingular and E [Z w0 U ] =
0.
(

Assume WLOG that
zx
~ x

x~
x z)

0.

xu

If (

x~
x z)

zx
~ x

zx
~

> 0, then B is a closed interval, while if

0, B is an open interval Speci…cally, if (

zx
~

x~
x z)

zx
~ x

by

B

=

B

If (

zx
~ x

x~
x z)

zx
~

=

h

IV
v(1) ;

h

IV
z

n

IV
z

IV
z

;

IV
v(1)

;
n

IV
v(1)

i

i

if

zx
~

< 0,

if

zx
~

> 0.

0 then

B

=

B

=

h

max

1; min

o

; 1 if
oi
IV
IV
;
if
z
v(1)
12

zx
~

< 0,

zx
~

> 0,

zx
~

> 0 then B is given

where

IV
z

=

IV
v(1)

=

z y~

,

zx
~
v(1)~
y

=

v(1)~
x

z y~ x

x~
y z

zx
~ x

x~
x z

.

Proposition 3 is a straightforward generalization of Proposition 2 from the simple linear regression to
the multiple linear regression model.

IV
z

The bound

corresponds to the probability limit of

an IV regression of Y on (X; W ) using (Z; Z w ) as instruments, and the bound
probability limit of
before V (1)

zX

IV
v(1)

from

corresponds to the

from an IV regression of Y on (X; W ) using (V (1) ; Z w ) as instruments, where as
x Z.

Consistent estimation of B can thus be achieved by employing standard linear

IV regression.
3.2.2

Bounds on Other Coe¢ cients

In this section we shift focus from

to other regression coe¢ cients, and show that these coe¢ cients are also

interval identi…ed. Whether or not their identi…cation regions are one or two-sided corresponds to whether
the identi…cation region for

is one or two-sided.

To facilitate the analysis, de…ne Y

Y

X , so that

Y = W + U.

Given the assumption that the instruments Z w are valid, it follows that

= E [Z w0 W ]

Then the j-th component of

1

E [Z w0 Y ] .

is given by

j

h
i
~j
= E Zjw0 W

1

h
i
E Zjw0 Y~ ,

(3.11)

where
~j
W

Wj

W

jE

Z w0j W

j

Y~

Y

W

jE

Z w0j W

j

13

1

E Z w0j X ,

1

E Z w0j Y

,

and subscript

~ j and Y~ correspond to the
j denotes a vector with its j-th component removed. That is, W

residuals of IV regressions of Wj and Y
infeasible as
for

j

on W

employing Z wj as instruments. The latter regression is

j

and therefore Y are unknown. However,

is interval-identi…ed, and the identi…cation region

can be obtained by tracing out implied values of

j

given in the following proposition, is that the bounds for

j

over admissible value of

. The formal result,

are given by evaluating (3.11) at the endpoints

of the identi…cation region for .
Proposition 4 Let the conditions of Proposition 3 hold.
1; :::; kw is given by the interval ranging from

j0

j1

and where

3.3

L

and

U

h
i
~j
E Zjw0 W
h
i
~j
E Z w0 W
j

j0

to

j1

Then the identi…cation region for any

j,

j =

where

h
i
E Zjw0 Y~
h
i
1
E Z w0 Y~

h
i
~j
E Zjw0 W
h
i
~j
E Z w0 W

1

j

j

h
i
~
E Zjw0 X
h
i
1
~
E Z w0 X

1

j

L,
U,

are the extreme points of B .

Multiple Imperfect Instruments

Up to this point we have assumed that we have a single imperfect IV. We now ask what the researcher
gains from multiple imperfect IVs for the endogenous regressor X. We show that this could help tighten the
identi…cation region for , serve as a speci…cation test of sort, and with additional assumptions helps us get
two sided bounded where they were previously unavailable.
When there are multiple imperfect instruments that satisfy A3 and A4, i.e. kz > 1 and Z = (Z1 ; :::; Zkz ),
then Proposition 3 can be used to derive bounds on

(one or two-sided, depending on the sign of

for each Zr , r = 1; :::; kz .

For each r, denote the bounds implied by Proposition 3 as Br =
h
i
(where one of the two is possibly 1). In addition, let Dj;r = jl;r ; ju;r denote the bounds on
j = 1; :::; kw given by Proposition 4. It follows that the identi…cation region for
the intervals Br , and the identi…cation region for each

j

l;r ;
j

xzr )
u;r

for each

is the intersection of all of

is the intersection over r = 1; :::; kz of the intervals

Dj;r .
Proposition 5 Assume AL and A1-A4. Then the identi…ed set for is B = maxr l;r ; minr u;r , and
h
i
the identi…cation region for j , each j = 1; :::; kw is Dj = maxr jl;r ; minr ju;r . These bounds are sharp.
This proposition is a result of applying Propositions 3 and 4 to each of the instruments Zj , j = 1; :::; J.
Furthermore, this exploits all the identifying power of the multiple IIVs, in the sense that there is no
14

additional identifying power from imposing A3 and A4 jointly with respect to multiple instruments. This
is because for every value of

2 B , there is an admissible data generation process that satis…es all of

our modeling assumptions. The sharpness of the bounds for each element of

are a direct result of their

characterization in Proposition 4 as functions of . Note, that in principle B and the intervals Dj can be
empty, which may be used to serve as a speci…cation test.
A potential drawback is that when (
bound on

.

x~
x z)

zx
~ x

zx
~

< 0, Proposition 5 will only provide a one-sided

In some cases the researcher may be willing to assert that one instrument is better than

another in the sense that it is both more relevant and more valid. In such cases, bringing this knowledge
to bear can achieve tighter identi…cation. In particular, in the case where the bounds of Proposition 5 are
one-sided, such an assumption can provide two-sided bounds.
Let there be two instruments, Z1 and Z2 , each satisfying assumptions A3 and A4, and

xz1

> 0,

xz2

> 0:

De…ne the following weighted average of Z1 and Z2 :

! ( ) = Z2

where

(1

) Z1 ,

2 [0; 1]. For the purpose of exposition in what follows we assume that

xu

> 0, which is with out

loss of generality, as long as we continue to assume A3.
Proposition 6 Let A1, A2, and A3 hold for both Z1 and Z2 , and in addition assume that there exists
2 [0; 1] such that

!(

)u

0 and

)~
x x

!(

x~
x !(

for .
IV
!(

min

)

n

IV
z1

The proposition simply says that if there exists a

!(

)

;

IV
z2

;

0. This yields the following bounds

)~
x

OLS

o

.

such that the conditions on ! (

) are met, then we

can apply Proposition 5 to obtain a two-sided bound. The following Lemma provides more basic conditions
that guarantee the required assumption, and allow one to test it with the data in the case where the additional
regressors W are exogenous.
Lemma 3 Let W = Z w and let A3 hold, for both Z1 and Z2 . Then the following statements are equivalent:
(i) there exists
that

x
~z1

>

x
~z2
!(

)~
x x

1

2 [0; 1] such that
z1 u

>

; (iii)

z2 u
x~
x !(

)

!(

)~
x

!(

)u

z1 y~ x
~z2

<

0 and

!(

z2 y~ x
~z1 .

)~
x

< 0; (ii) there exists a known

Furthermore, a su¢ cient condition for the inequality

0 is that the partial correlation between X and ! (

is negative.
15

2 [0; 1], such

) controlling for W ,

The Lemma shows the assumptions on the unobserved covariances that guarantee that the weighted
average ! (

) both satis…es A3 and the conditions in Proposition 2. More importantly it provides conditions

to test the assumption in the data.
Note that while Proposition 6 provides two-sided bounds, it relies on knowing
by checking if

z1 y~ x
~z2

<

z2 y~ x
~z1

holds, we can test if there exists some value of

conditions hold. However, it does not reveal for which values of

: Lemma 3 shows that
such that the required

this holds, it only reveals that a set of

such values exists. To exploit the results of the proposition, we need to assume a value for
assuming

= 0:5 implies

xz1

>

xz2

and

z1 u

<

in terms of validity. Another natural choice is

3.4

=

z2 u ,

. For example,

so the more relevant variable is also weakly better

z1 = ( z1

+

z2 ).

Relation to Manski and Pepper

Our approach for handling the problem of correlation between instruments and econometric error terms
is in part motivated by the work of Manski and Pepper (2000) on monotone instrumental variables, or
MIVs. They focus on models where the outcome variable is bounded between zero and one, and examine
nonparametric models. We, on the other hand, derive most of our results for the linear regression model.
While their results are nonparametric, an earlier version of their paper, Manski and Pepper (1998), available
through the NBER, devotes a section to linear models as well. However, even in the context of the linear
model, our modeling assumptions neither nest nor are nested by theirs. Here, we examine the implications
of our assumptions relative to those of Manski and Pepper (1998) (henceforth MP).
In section 4 of their NBER paper, MP invoke the following assumptions:
Assumption MP1 (Linear Response Model)1 :

Y =

+ X + U;

E (U ) = 0.

Assumption MP2 (MIV) for all pairs z2 , z1 such that z2

8x 2 supp(X), E ( + x + U jZ = z2 )

z1 :

E ( + x + U jZ = z1 )

The second assumption is equivalent to assuming E (U jZ = z2 )

E (U jZ = z1 ) for all z1 ,z2 pairs where

1 Manski and Pepper in fact do not use an intercept and do not restrict U to have mean zero. This is only a di¤erence in
notation, as including the intercept makes the mean zero restriction on U meaningless.

16

z2

z1 . Under these restrictions, Manski and Pepper derive the following sharp bounds for :
Proposition (Manski and Pepper (1998) Proposition 2) Assume (MP1) and (MP2). Then
E [Y jZ
E [XjZ
E [Y jZ
E [XjZ

= z2 ]
= z2 ]
= z2 ]
= z2 ]

E [Y jZ = z1 ]
if E [XjZ = z2 ]
E [XjZ = z1 ]
E [Y jZ = z1 ]
if E [XjZ = z2 ]
E [XjZ = z1 ]

E [XjZ = z1 ] > 0, and
E [XjZ = z1 ] < 0.

These bounds are sharp.
In this paper, we mostly focus on a linear model, which is equivalent to MP1. Instead of MP2, we assume
A3 and A4, and then assuming that the sign of
inequality
is stronger.

zu

xu

is known, it is WLOG to assume that

xu

zu

0. The

0 is implied by MP1 and MP2, although their restriction of monotonicity of E (U jZ = z)
The case where the two assumptions coincide is that where E (U jZ = z) is linear in z, but

otherwise E (U jZ = z) is a sharper restriction. The MP assumption is a restriction on the distribution of U
conditional on Z for each value of z, while our restriction is a restriction on the average relation between U
and Z over their entire support.
If E (XjZ = z) is monotone then MP get only one sided bounds, just like we would if

xz

to get two sided-bounds they require E (XjZ = z) to be non-monotone, while we require that

4

> 0: In order
xz

< 0:

Estimation and Inference

So far we have focused solely on identi…cation.

However, these identi…cation results are constructive,

naturally leading to consistent estimators since the derived bounds are probability limits of OLS and IV
estimators. Consistent estimators of our bounds can thus be computed using standard regression software.
Regarding statistical inference, there are a variety of methods from the recent literature that appear
applicable in the present context, including Pakes, Porter, Ho, and Ishii (2005), Chernozhukov, Hong, and
Tamer (2007), Andrews and Guggenberger (2007), and the references cited therein. In Section 5, we employ
a variant of the inferential procedure proposed by Chernozhukov, Lee, and Rosen (2008).

Their method

is speci…cally designed for settings where there is interval identi…cation, where the identi…ed set is the
intersection of many intervals, which is precisely the case here.
Speci…cally, we use the method of Chernozhukov, Lee, and Rosen (2008) to construct 95% con…dence
intervals for each of the interval identi…ed parameters in our regressions. In each case, we use a sample analog
estimator for the identi…ed set of the form of [max fLn1 ; :::; LnR g ; min fUn1 ; :::; UnS g], where each Lnr ; Uns
17

are consistent estimators of all the lower and upper bounds on the parameter of interest, respectively. To
construct con…dence intervals, we …rst construct con…dence bands for each of the estimated bounds, and then
take the intersection of these. Intuitively, this adjusts each of the estimates by an amount that depends on
the precision with which it is estimated. Those estimates whose standard errors are high require a larger
adjustment than those whose standard errors are low. To be precise, the con…dence intervals are given by
CI = [L ; U ], where

s^l11 q l (

L

max Ln1

U

min fUn1 + s^u1 q u (

n ) ; :::; LnR
n ) ; :::; UnS

where s^lr ; s^ur are the standard errors of Lnr ; Unr , respectively.

s^lR q l (

+ s^uR q u (

n)

,

n )g ,

q l ( ) and q u ( ) are the

-quantiles of

the maxima of mean zero multivariate normal random vectors with variance matrices equal to the estimated
joint variance covariance matrices [Ln1 ; :::; LnR ], [Un1 ; :::; UnS ], respectively, and are computed via simulation.
The value of

n

is chosen to provide the desired nominal coverage for the object of interest, the identi…ed

set or the parameter of interest. For inference on the identi…ed set we use

n

= 0:975, for coverage for the

parameter we use 0:95, and for uniform asymptotic coverage we use an appropriately de…ned intermediate
value that depends on the size of the estimated identi…ed set, in similar spirit to Imbens and Manski (2004)
and Stoye (2007). A by-product is that this also provides a speci…cation test: if the lower and upper bounds
of the con…dence set computed with

n

= 0:975 cross, then the model is rejected at the 0:05 level.

For

further details we refer to Chernozhukov, Lee, and Rosen (2008).

5

Applications

In this section we provide two applications, both motivated by recent work in the Industrial Organization
literature. First, we examine the estimation of a Cobb-Douglas production function. Next, we examine the
estimation of a di¤erentiated-products demand system.

18

5.1
5.1.1

Estimation of a Production Function
The model

Consider the following Cobb-Douglas production function:

Qit = e Litl Kitk Ritr euit ,

where Qit is the output of …rm i at time t, Lit is labor, Kit is capital, Rit is R&D capital, uit is an error
term, ,

l,

k,

r

are parameters to be estimated. The error term, uit , includes technology or management

di¤erences, measurement errors and variation in external factors.
Taking logs we obtain
yit =
where: yit

log(Qit ), lit

log(Lit ), kit

+

l lit

+

k kit

log(Kit ), rit

+

r rit

+ uit ,

log(Rit ).

A major concern in the literature is that the variable input, lit , is chosen after the error term is observed
and is therefore correlated with it. Capital variables, both physical and R&D, on the other hand, are assumed
to be either exogenous or pre-determined (conditional on a …rm-…xed e¤ect). Assume that uit =
where

i

i +! it +"it ,

and ! it are “transmitted”(i.e., impact the choice of lit ), while "it is white noise that is uncorrelated

with any of the variables. Di¤erent methods have been proposed in the literature to consistently estimate
the parameters of the model. Each model imposes di¤erent restrictions on the error term. We discuss some
of these methods below as we present estimates. For a more detailed discussion see, for example, Griliches
and Mairesse (1998), Ackerberg, Caves, and Frazer (2006) and Bond and Soderbom (2005).
5.1.2

Results

To demonstrate our method we use the data from Griliches and Mairesse (1998) (see Hall (1990) for further
information on the data). The sample includes U.S. R&D performing …rms listed on the major stock exchanges during 1973-1988. The data are at 5 year intervals. Overall, the sample includes 2971 observations
from 4 di¤erent periods for 1400 …rms. Our analysis focuses on the …rms that existed for at least 2 (consecutive) periods. There are 1502 such observations with 820 …rms. The balanced panel, of …rms that were
present for the whole period, consists of 856 observations and 214 …rms. Table 1 provides some summary
statistics.
We provide estimates of the slope coe¢ cients, using di¤erent assumptions. In all cases we focus on the

19

set of …rms that were present in at least two cross sections. We ignore the issue of sample selection.2 Various
corrections for sample selection can easily be included in the analysis. The results are presented in Table 2.
The …rst column presents results using OLS. These results are biased if …rm-speci…c e¤ects,

i;

are present

and correlated with the choice of labor. A standard correction is to di¤erence the equation in order to get
rid of the …rm-speci…c e¤ects. The second column in the table presents the results from …rst di¤erencing.
The change in both the labor and capital coe¢ cients is signi…cant, suggesting that indeed the …rm-speci…c
e¤ects are present and correlated with both the …xed and variable inputs.
One of the problems with the …rst di¤erence model is that it does not allow the transmitted productivity
shock to vary over time. The results in the third column, are based on an Olley and Pakes (1996) speci…cation.3 This estimator sets

i

to 0; but allows for a transmitted time-varying productivity shock, ! it , and

lets this shock vary over time according to a …rst-order Markov process. Note that both the Olley-Pakes
estimator and the …xed e¤ect estimator allow for a non-transmitted time varying shock, "it . The …rst order
Markov process does not allow for more than a one period persistence in the transmitted productivity shocks.
Where this impacts the Olley-Pakes analysis is in the inversion from investment to productivity shock. If
the two …rms are observed to invest the same amounts in the same period (controlling for di¤erences in
stocks), then they are inferred to have the same productivity shock. In reality, however, the …rms’expected
shocks could be di¤erent, which would be the case if the process was more persistent, implying that even
though their investment is the same their current productivity shock is di¤erent. Indeed, the estimates are
much closer to the OLS estimates than to those of the …rst-di¤erence estimator, which probably suggests
that the …rst-order Markov process might not be persistent enough to capture the process in the transmitted
productivity shock.
The dynamic panel literature (e.g., Arellano and Bond (1991) and Blundell and Bond (1998)) o¤ers an
alternative way to estimate the parameters. The results in columns 4 and 5 present the estimates from these
methods. The results from the Arellano and Bond estimator are very noisy and the point estimates are
not reasonable. This is a common problem and is usually attributed to weak instruments. The "system"
estimator of Blundell and Bond aims to address this problem and indeed the results in column 5 are more
reasonable. The estimators in columns 4 and 5 are not consistent if the instruments are not valid, which
2 In

this data set selection does not appear to impact the estimates, despite the patterns observed in Table 1. OLS results
using all the observations, just those that are present 2 or more periods, or the balanced panel, are essentially identical. This
might not be the case for other data sets.
3 Speci…cally, the parameters are estimated in two steps. In the …rst step, the labor co¢ cient is estimated by regressing the
log of output on the log of employment, and a second-order polynominal in the capital, R&D capital and investment. In a
second step the coe¢ cients on capital and R&D capital are estimated exploiting that the unexpected innovation in productivity
is mean independent of lagged capital. See Ackerberg, Caves, and Frazer (2006).

20

would be the case if ! it is autocorrelated. Indeed a test of over-identi…cation of the instruments fails.
The last two columns in the table present estimates from our procedure. The estimated equation is in …rst
di¤erence. Our concern is that labor is not strictly exogenous, and therefore correlated with the transformed
error term. Both economic reasoning and the previous results suggest that the correlation is positive. We
explore two IIVs. In column 6 we use lagged R&D investment and in column 7 we use lagged capital
investment. It is reasonable to assume that lagged investment, conditional on all the other variables and a
…xed e¤ect, is positively correlated with the productivity shock. The logic is similar to that motivating the
Olley-Pakes estimator. Furthermore, both types of investment are negatively correlated with employment
(conditional on the other variables). Regressing the …rst di¤erence in log of employment on lagged R&D,
controlling for the other variables, we get a negative coe¢ cient with a t-value of -3.4. The same regression
using lagged investment yields a negative coe¢ cient with a t-stat of -5.9. Thus, both the variables satisfy
the conditions of Proposition 2 and thus are valid IIVs.
The results in columns 6 and 7 are quite reasonable.

The results on column 6, using lagged R&D as

the IIV suggest that the labor coe¢ cient is between 0.50 and 0.71. In itself this is not a very useful bound
since it includes the OLS estimate and is very close to the …rst-di¤erence estimates. The bounds for both
the capital and R&D coe¢ cients are slightly more informative. For example, the bounds on the capital
coe¢ cients rule out most of the point estimates suggested by alternative methods. The results using lagged
capital investment yield similar results, although the bounds are tighter. For example, the point estimates of
the labor coe¢ cients do not include all but one of the previous estimates, the Blundell-Bond system estimate.
The fact that the two IIV yield somewhat similar regions is assuring. The bounds can be further tightened
by taking the intersection of the regions. The results are presented in the last column. Now the bounds are
both tight and do not include any of the previous estimates.
The table reports standard errors in parentheses, for columns 6-8 we report 95% con…dence intervals (CI)
using the methods described in Section 4: the top number reports the CI for the identi…ed set, the bottom
number is the CI for the parameter and the middle number report the CI with uniform asymptotic coverage.

5.2

Di¤erentiated-Products Demand

In this section, we apply our method to the estimation of the demand for di¤erentiated products. We use
the Logit model. Assume that the indirect utility for consumer i for product j in market t is given by

0
uijt = pjt + wjt
+

21

jt

+

ijt ,

where wjt , pjt , and
in market t.

ijt

jt

are observable characteristics, price, and unobservable characteristics of product j

is an unobservable stochastic term that captures the idiosyncratic portion of consumer

i’s taste for project j in market t. We assume that when making their purchases, each consumer chooses
exactly one good, and also has the option to choose an “outside” good, i.e. not to buy any of the products.
We normalize the mean value of the outside good to be zero so that ui0t =

i0t .

Furthermore,

ijt

is assumed

to be distributed iid extreme value, from which it follows that each product j has market share sjt in market
t, where
sjt =

0
exp pjt + wjt
+ jt
J
P
1+
exp (pkt + wkt +

,
kt )

k=1

and

log (sjt )

0
log (s0t ) = pjt + wjt
+

jt .

If price pjt and market characteristics wjt are uncorrelated with the random unobservable
of this equation,

(5.1)
jt ,

the parameters

and , could be estimated by ordinary least squares. However, it is commonly thought in

these markets that any given product’s price is correlated with unobservable shifters. In general, the error
term may include unobserved product quality or promotional activities, and both are likely to be correlated
with price. In this application, we control for unobserved product characteristics that are …xed over time
by using a product …xed e¤ects. Thus, the error term includes mainly unobserved promotional activities.
We employ scanner data from the ready-to-eat cereal industry at the brand-quarter-MSA (metropolitan
statistical area) level, obtained from the IRI Infoscan Data Base at the University of Connecticut. We have
observations from 20 quarters, and for this application focus attention on the top 25 brands (in terms of
market share), and the San Francisco and Boston markets. The key variables observed for each product,
market, quarter combination are market share, price4 , quantity sold during promotional periods, and brandlevel advertising. For additional information on the data source and the details of the RTE cereal industry,
we refer the reader to Nevo (2000) and Nevo (2001). Table 3 provides a descriptive summary of the observed
data.
The standard approach for dealing with the endogeneity of price in this setting is to use prices of the
product in other markets as an instrumental variable (e.g., Hausman, Leonard, and Zona (1994), Hausman
(1997), and Nevo (2001)). The idea is the IV is correlated with price through common marginal cost shocks.
Assuming that the errors in demand are independent across markets, these instruments are valid. This latter
4 In

order to normalize per portion, we take price to be total revenue divided by quantity.

22

assumption has been challenged (e.g., the discussion of Hausman (1997) by Bresnahan (1997)). The demand
shocks could be correlated across cities for several reasons. For example, advertising could be at the regional
or national levels. Alternatively, the brand preferences could change over time. For instance if in the middle
of the sample …ber-rich cereal are found to be healthy the preferences for these cereals could vary. Any of
these stories would render the IV, and the implied estimates, not valid. There is evidence that despite these
theoretical concerns the IV are valid (e.g., Nevo (2001)), nevertheless, some concerns linger over the validity
of the estimates.
We use prices in other cities as an imperfect IVs. The examples above suggest that usually we worry
about positive association between demand errors in di¤erent markets. Thus, it is natural to assume that
correlation of prices in other cities with the error term is positive. Unfortunately, in our data it is also the
case that prices in other markets are positively correlated with price. Therefore, these IIV will only yield one
sided bounds. However, we can exploit the fact that we have multiple cities to generate a valid IIV, using
the results in Section 3.3. For each of our markets, Boston and San Francisco, we use two IIVs. Denote by
Z1 the average price in the other markets in the region, New England for Boston and Northern California
for San Francisco, and by Z2 the average price in the other city. In Appendix B we provide a model that
justi…es the required assumptions. The intuitive idea is as follows. The average price in the region, Z1 , is
assumed to be more correlated with price because marginal cost shocks are common. It is also assumed to
be less correlated with demand because the composition of demand is assumed to be more similar between
Boston and San Francisco than with their surrounding regions.
In the sample the correlations

pz1

= 0:81 and

pz2

= 0:48 satisfy the …rst of these assumptions. Further-

more, Lemma 3 allows to verify the second assumption. Indeed, we …nd that
the Lemma there exists a range of

such that ! ( ) = Z2

get a two sided bound. We explore two options. We explore
can verify that the correlation between price and ! ( ) = Z2

(1

y~z1 x
~z2

<0<

y~z2 x
~z1 ,

so by

) Z1 satis…es the conditions required to

= 0:5 and
(1

=

z1 = ( z1

+

z2 ) :

For both we

) Z1 is negative.

The results are presented in Table 4. The dependent variable in all columns is log(sjt )

log(s0t ). The

…rst column presents results from regressing this variable on price, brand and quarter dummy variables and
city San Francisco dummy variable. The estimated price coe¢ cient is negative and the advertising coe¢ cient
is positive, as expected. However, the own price elasticities are less than one in absolute value. Once we use
the average regional price as an IV the price coe¢ cient becomes more negative, as expected.
The next four columns use weighted di¤erences between the average regional price and the price in the
other city as IIV. The di¤erence between the columns is in the weight used. Columns (3) and (4) use a weight
23

of 0.5, while the last two columns use

=

z1 = ( z1

+

z2 ) :Columns

(3) and (5) only impose assumption

A3, on the di¤erenced IV, while columns (4) and (6) also impose assumption A4.
The results yield a fairly consistent picture. If we do not impose assumption A4 then the price coe¢ cient
is between -4 and -8.7 (with a con…dence interval of approximately -2.3 and -11.4). On the other hand, if we
impose assumption A4 the price coe¢ cient is between -6 and -8.7 (with a con…dence interval of approximately
-4 and -11.25). In all cases the OLS point estimate is outside the con…dence interval. When we impose
assumption A4, the IV estimate is very close to the boundary of the con…dence interval.
In the Logit model price elasticities are proportional to the price coe¢ cient. So going from column (1)
to (2) doubles the price elasticities by roughly a factor of two. Further moving to the lower bound of the
identi…ed set increase the price elasticities by another factor of two. Generally, the results suggest that the
price elasticties are too low, in absolute value.
There are two common uses for demand elasticities in the IO literature. Often the elasticities are used
in a …rst order condition, typically from a Bertrand pricing game, in order to compute price cost margins
(PCM). PCM computed in this way are used to test among di¤erent supply models (e.g., Nevo (2001)). Our
results suggest that the estimates of PCM using the standard IV assumption might too high. Another use of
demand estimates is for simulation of the e¤ects of mergers (e.g., Hausman, Leonard, and Zona (1994); and
Nevo (2000)). The results in Table 4 suggest that estimates using the standard IV assumption would tend
to underestimate the e¤ects of a merger, because they will tend to underestimate the substitution among
products.

6

Conclusion

In this paper we study identi…cation of the parameters of a single regression equation with endogenous
regressors and instruments that fail to satisfy the usual exogeneity condition.

Instead, we consider cases

where the instruments are assumed to have the same direction of correlation with the error as the endogenous
regressor, but where the instruments are less correlated with the error term than the endogenous regressor.
Under our assumptions, we …rst derive an abstract characterization of the identi…ed set for all parameters,
and then focus primarily on identi…cation of the slope parameter on the endogenous regressor. Consistent
estimates of these bounds can be computed by standard OLS and linear 2SLS regressions under the usual
rank conditions (A5).

We found that the bounds that can be obtained for the slope parameter, and in

particular whether they form an open or closed interval, depend on the correlation between the endogenous

24

regressor and the instrument, which is point identi…ed. Furthermore, depending on both the sign of
its magnitude relative to

xu

and

zu ,

may be closer to either

OLS

or

IV
z

xz

and

even if Z is less endogenous

than X, in the sense that our assumptions A3 and A4 are satis…ed.
Relative to conventional instrumental variable assumptions, the cost of our approach is that the weaker
assumptions we impose generally yield partial identi…cation rather than point identi…cation of model parameters. The bene…t, however, is that inferences made are robust to a lack of instrument exogeneity, and
thus may be more credible in some circumstances. Additionally, for cases in which the applied researcher
wishes to impose instrument exogeneity, our approach provides one answer to the question of how much this
assumption drives their results.
Our focus has been entirely on parametric models, with specialized results for linear models.

While

much empirical work relies on such models, an interesting extension would be to perform a similar analysis
in a nonparametric model. However, with a nonparametric functional form, it is doubtful that our assumptions on the correlations of endogenous regressors and imperfect instruments with econometric errors would
prove anywhere near as fruitful. More promising would be an extension of our assumptions to conditional
expectation analogs.

Indeed, as discussed in section 3.4, the identifying power of MIV assumptions was

examined in a nonparametric context by Manski and Pepper (2000). Their MIV assumption is a conditional
expectation analog of our assumption that the instrument is positively correlated with the error. One could
also posit a conditional mean version of our assumption that the instrument is less correlated with the latent
variate than is the endogenous regressor.

In light of the positive results of Manski and Pepper, it would

seem that such an assumption could have signi…cant identifying power in a nonparametric model.

References
Ackerberg, D. A., K. Caves, and G. Frazer (2006): “Structural Identi…cation of Production Functions,” working paper, UCLA.
Anderson, T., and H. Rubin (1949): “Estimation of the Parameters of a Single Equation in a Complete
System of Stochastic Equations,” Annals of Mathematical Statistics, 20, 46–63.
(1950): “The Asymptotic Properties of Estimates of the Parameters of a Single Equation system
in a Complete System of Stochastic Equations,” Annals of Mathematical Statistics, 21(4), 570–582.

25

Andrews, D. W., and J. H. Stock (2007): “Inference with Weak Instruments,”in Advances in Economics
and Econometrics: Theory and Applications, Econometric Society Ninth World Congress Proceedings Vol.
III, ed. by R. Blundell, W. Newey, and T. Persson. Cambridge University Press.
Andrews, D. W. K., and P. Guggenberger (2007): “Validity of Subsampling and Plug-In Asymptotic
Inference for Parameters De…ned by Moment Inequalities,” working paper, UCLA.
Andrews, D. W. K., and V. Marmer (2008): “Exactly Distribution-Free Inference in Instrumental
Variables Regression with Possibly Weak Instruments,” Journal of Econometrics, 142, 183–200.
Andrews, D. W. K., M. J. Moreira, and J. H. Stock (2006): “Optimal Two-sided Invariant Similar
Tests for Instrumental Variables Regression,” Econometrica, 74, 715–752.
Arellano, M., and S. Bond (1991): “Some Tests of Speci…cation for Panel Data: Monte Carlo Evidence
and an Application to Employment Equations,” Review of Economic Studies, 58, 277–297.
Blundell, R., and S. Bond (1998): “Initial Conditions and Moment Restrictions in Dynamic Panel Data
Models,” Journal of Econometrics, 87, 115–143.
Bond, S., and M. Soderbom (2005): “Adjustment Costs and the Identi…cation of Cobb-Douglas Production Functions,” working paper No. 05/04, Institute for Fiscal Studies.
Bontemps, C., T. Magnac, and E. Maurin (2006): “Set Identi…ed Linear Models,”working paper, IDEI.
Bound, J., D. A. Jaeger, and R. M. Baker (1995): “Problems with Instrumental Variables Estimation
When the Correlation Between the Instruments and the Endogenous Explanatory Variable is Weak,”
Journal of the American Statistical Association, 90(430), 443–450.
Bresnahan, T. F. (1997): “Comment on Valuation of New Goods under Perfect and Imperfect Competition,”in The Economics of New Goods, ed. by T. F. Bresnahan, and R. J. Gordon, pp. 237–247. University
of Chicago Press.
Chernozhukov, V., H. Hong, and E. Tamer (2007): “Estimation and Con…dence Regions for Parameter
Sets in Econometric Models,” Econometrica, 75(5).
Chernozhukov, V., S. Lee, and A. Rosen (2008): “Intersection Bounds, Estimation and Inference,”
working paper, MIT and CEMMAP.

26

Chioda, L., and M. Jansson (2005): “Optimal Conditional Inference for Instrumental Variables Regression,” working paper, U.C. Berkeley.
Conley, T., C. Hansen, and P. E. Rossi (2006): “Plausibly Exogenous,” working paper, Chicago
Graduate School of Business.
Dufour, J.-M. (1997): “Some Impossibility Theorems in Econometrics with Applications to Structural and
Dynamic Models,” Econometrica, 65(6), 1365–1387.
(2003): “Identi…cation, Weak Istruments, and Statistical Inference in Econometrics,” Canadian
Journal of Economics, 36(4), 767–808.
Dufour, J.-M., and J. Jasiak (2001): “Finite Sample Limited Information Inference Methods for Structural Equations and Models with Generated Regressors,”International Economic Review, 42(3), 815–843.
Dufour, J.-M., and M. Taamouti (2005): “Projection-Based Statistical Inference in Linear Structural
Models with Possibly Weak Instruments,” Econometrica, 73(4), 1351–1365.
Frisch, R. (1934): Statistical Con‡uence Analysis By Means of Complete Regression Systems. University
Institute for Economics, Oslo, Norway.
Griliches, Z., and J. Mairesse (1998): “Production Functions: The Search for Identi…cation,”in Econometrics and Economic Theory in the Twentieth Century: The Ragnar Frisch Centennial Symposium, ed.
by S. Strom, pp. 169–203. Cambridge University Press.
Guggenberger, P., and R. J. Smith (2005): “Generalized Empirical Likelihood Estimators and Tests
Under Partial, Weak, and Strong Identi…cation,” Econometric Theory, 21, 667–709.
Hahn, J., and J. Hausman (2002): “A New Speci…cation Test for the Validity of Instrumental Variables,”
Econometrica, 70(1), 163–189.
(2003a): “IV Estimation with Valid and Invalid Instruments,” working paper, MIT.
(2003b): “Weak Instruments: Diagnosis and Cures in Empirical Econometrics,”American Economic
Review, 93(2), 118–125.
Hall, B. (1990): “The Manufacturing Sector Master File: 1959-1987,” NBER working paper.

27

Hausman, J. A. (1997): “Valuation of New Goods under Perfect and Imperfect Competition,” in The
Economics of New Goods, ed. by T. F. Bresnahan, and R. J. Gordon, pp. 209–237. University of Chicago
Press.
Hausman, J. A., G. K. Leonard, and J. D. Zona (1994): “Competitive Analysis with Di¤erentiated
Products,” Annales D’Economie et de Statistique, (34), 159–180.
Imbens, G., and C. F. Manski (2004): “Con…dence Intervals for Partially Identi…ed Parameters,”Econometrica, 72, 1845–1857.
Kleibergen, F. (2005): “Testing Parameters in GMM Without Assuming that They Are Identi…ed,”
Econometrica, 74(4), 1103–1123.
Klepper, S., and E. E. Leamer (1984): “Consistent Sets of Estimates for Regressions with Errors in All
Variables,” Econometrica, 52(1), 163–184.
Leamer, E. E. (1981): “Is It a Demand Curve, or Is It a Supply Curve? Partial Identi…cation through
Inequality Constraints,” Review of Economics and Statistics, 63(3), 319–327.
Manski, C. F., and J. Pepper (1998): “Monotone Instrumental Variables: With an Application to the
Returns to Schooling,” NBER working paper.
Manski, C. F., and J. V. Pepper (2000): “Monotone Instrumental Variables: With an Application to
the Returns to Schooling,” Econometrica, 68(4), 997–1010.
Nelson, C. R., and R. Startz (1990): “Some Further Results on the Small Sample Properties of the
Instrumental Variable Estimator,” Econometrica, 58(4), 967–976.
Nevo, A. (2000): “Mergers with Di¤erentiated Products: the Case of the Ready-to-Eat Cereal Industry,”
Rand Journal of Economics, 31(3), 395–421.
(2001): “Measuring Market Power in the Ready-to-Eat Cereal Industry,” Econometrica, 69(2),
307–342.
Olley, S., and A. Pakes (1996): “The Dynamics of Productivity in the Telecommunications Industry,”
Econometrica, 64, 1263–1295.
Pakes, A., J. Porter, K. Ho, and J. Ishii (2005): “The Method of Moments with Inequality Constraints,”
working paper, Harvard University.
28

Phillips, P. C. (1989): “Partially Identi…ed Econometric Models,” Econometric Theory, 5, 181–240.
Rothenberg, T. (1984): “Approximating the Distributions of Econometric Estimators and Test Statistics,”
in The Handbook of Econometrics, ed. by Z. Griliches, and M. Intriligator, vol. 2, pp. 881–935. Elsevier,
New York: North Holland.
Staiger, D., and J. H. Stock (1997): “Instrumental Variables Regression with Weak Instruments,”
Econometrica, 65(3), 557–586.
Stock, J. H., and J. H. Wright (2000): “GMM with Weak Identi…cation,” Econometrica, 68(5), 1055–
1096.
Stock, J. H., J. H. Wright, and M. Yogo (2002): “A Survery of Weak Instruments and Weak Identi…cation in Generalized Method of Moments,”Journal of Business and Economic Statistics, 20(4), 518–529.
Stock, J. H., and M. Yogo (2005): “Testing For Weak Instruments in Linear IV Regression,” in Identi…cation and Inference for Econometric Models: A Festschrift in Honor of Thomas J. Rothenberg, ed. by
D. W. Andrews, and J. H. Stock. Cambridge University Press, Cambridge, U.K.
Stoye, J. (2007): “More on Con…dence Regions for Partially Identi…ed Parameters,” working paper, New
York University.
Wang, J., and E. Zivot (1998): “Inference on Structural Parameters in Instrumental Variables Regression
with Weak Instruments,” Econometrica, 66(6), 1389–1440.
Zivot, E., R. Startz, and C. R. Nelson (1998): “Valid Con…dence Intervals and Inference in the Presence
of Weak Instruments,” International Economic Review, 39(4), 1119–1144.

Appendix A: Proofs
Proposition 1
Proof. For any …xed value of , the left hand side of the system (2.3a), (2.3b) can be recovered from the
data, under random sampling assumption A1.

Under A2-A4, any value of

restrictions as well as (2.3c) is a feasible value and all such values of

29

that satis…es each of these

are observationally equivalent.

Corollary 1
Proof. Let

=(

and de…ne
,

2

=

0

;

) and

+ (1

=(

)

0

;

) such that both

;

are elements of

. Let

2 [0; 1]

. Because the left hand sides of conditions (2.3a) and (2.3b) are linear in

.

Lemma 1
OLS

Proof. The result follows directly from inspection of the expressions for
(3.6), respectively. If
then

IV
z

OLS

> 0 (< 0), then

xu

and

IV
z

is an upper (lower) bound for . If

given by (3.5) and
zu = xz

> 0 (< 0),

is an upper (lower) bound for .

Lemma 2
Proof. Using expressions (3.5) and (3.6),

OLS

OLS

To show sgn

IV
z

IV
z

xu
2
x

=

OLS

= sgn

zu

OLS

,

=

xz

xu
.
2
x

it is equivalent to show that

OLS

IV
z

OLS

> 0,

i.e.
xu
2
x

Case 1

< 0. By A3

xz

has the same sign as
Case 2

<

xu z = x .

xz ,

xu ,

and

xu

and

xz

> 0.

Substituting into

IV
z

OLS

Isolating

zu

OLS

IV
z

OLS

which has the same sign as

xu

> 0.

are either both non-positive or non-negative. Therefore

zu
OLS

and

2
xu xz
x zu
2
xz
x

(given that

> 0.
in the de…nition of

(equation (2.1)) gives

, it follows that

IV
z

xz

=

2
x zu

xu xz

xu

1

x

> 0) if

30

x

xz

z

,

xz

x z

> 0, or equivalently if

<

xz .

zu

=

=

xz

Proposition 2
Proof. Suppose that

xu

> 0. Then A4 gives

xu

)
,

z

z xu

x zu

2
x

xy

0

zu

x
IV
v(1)

,

(

zy

xz

)

,

where as in (3.7),

IV
v(1)

z xy

=

x

(

x zy
xz )

z x
z x

=

(

z x

xz

OLS
xz )

(

xz )

z x

IV
z

which makes use of the assumption that x and z are not perfectly correlated (implied by A5), as well as
the Cauchy-Schwartz Inequality (i.e.
Note that

IV
v(1)

=

OLS

+ (1

IV
z

)

xz ).

z x

If instead

, where

xu

z x= ( z x

< 0 then
xz )

z xu

= 1= (1

x zu

and

IV
v(1)

.

xz ).

> 0 and 1
> 0, implying that IV
v(1) lies between
i
h
OLS
IV
OLS
IV
. Since in this case we also have that
and z . If xu > 0, Lemma 1 implies that 2 z ;
h
i
IV
IV
OLS
IV
IV
, and v(1)
, it follows that v(1) provides a smaller upper bound for , i.e. 2 IV
v(1)
z ; v(1) .
h
i
IV
If instead xu < 0, then similar logic leads to 2 IV
.
v(1) ; z
n
o
IV
, and Lemma 1 gives
min OLS ; IV
. An
Now suppose xz > 0. Then if xu > 0, v(1)
z
n
o
IV
OLS
immediate implication is that
min OLS ; IV
is redundant in that
z ; v(1) , but it turns out that
n
o
n
o
IV
IV
IV
OLS
min OLS ; IV
= min IV
This is because if OLS < IV
, while
z ; v(1)
z ; v(1) .
z , then v(1)
n
o
OLS
OLS
IV
OLS
clearly if instead OLS < IV
; IV
= IV
< IV
z , then min
z
z . The claim that
z ) v(1)
First consider the case where

holds because

xz

xz

> 0 implies that 1

IV
v(1)

=

OLS

< 0.

Then

=

+ (1

xz = ( z x

)

IV
z

Symmetric reasoning applied to the case where

xz )

OLS

xz

< 0, so that

+ (1

> 0 and

xu

)

OLS

=

OLS

< 0 gives that

.

max

n

IV
z

;

IV
v(1)

o
.

The sharpness of the bounds follows as an implication of Proposition 5, which covers the case of multiple
imperfect instruments and is proven below.

31

Corollary 2
Proof . Using the above notation,

IV
v(1)

IV
z

OLS

=

+ (1

IV
z

)

IV
z

OLS

=

IV
z

.

Therefore
IV
v(1)
OLS

IV
z
IV
z

=

=

1

.

1

xz

Proposition 3
Proof.A3, A4 and

xu

0 give

xu

,
,
where the third line uses Y~ =
provides an upper bound on

x~
y z

0

zu

xu z

zu x

x~
x z

z y~ x

0
zx
~ x

0,

~ + U , which is shown below in Lemma 4 below.
X

if

zx
~ x

x~
x z

The …rst inequality

is negative, and a lower bound if this expression is positive.

The second inequality provides an upper bound if

zx
~

is positive and a lower bound if

zx
~

Combining these inequalities gives the conclusion of the proposition.
~ + U.
Lemma 4 Let the conditions of Proposition 3 hold. Then Y~ = X
Proof.Subtracting W E [Z w0 W ]
Y~

1

E [Z w0 Y ] from both sides of (3.8) gives

= X +W

W E [Z w0 W ]

1

E [Z w0 Y ] + U

= X +W

W E [Z w0 W ]

1

E [Z w0 (X + W + U )] + U

= X +W

W E [Z w0 W ]

1

E [Z w0 X]

~ + U.
= X

32

W E [Z w0 W ]

1

E [Z w0 W ] + U

is negative.

Proposition 4
Proof.Starting with the de…nition of Y~ ,and making use of Y = Y
Y~

where Y~ = Y

= Y

W

= Y

X

= Y~

~ ,
X

W

j

so that

j

W

j

1
j

Z w0j W

jE

1

Z w0j W

jE

Z w0j W

jE

X , we have that

E Z w0j Y
1
j

E Z w0j Y + W

Z w0j W

jE

1
j

E Z w0j X

E Z w0j Y . Now plugging this into (3.11) gives

h
i
~j
= E Zjw0 W
h
i
~j
= E Zjw0 W

h
i
E Zjw0 Y~
h
i
h
i
1
~j
E Zjw0 Y~
E Zjw0 W
1

1

h
i
~ ,
E Zjw0 X

is linear in , which delivers the conclusion of the proposition, since all other components of the

above expression are point-identi…ed.

Proposition 5
To establish sharpness of the bounds in this proposition, we make use of the following corollary to Proposition
3.
Corollary 3 If
while if

xz

xz

> 0 and

< 0, then any
IV
v(1)

Proof . First, write

<

IV
z

2 [0; 1] is feasible.

, then

2 [0;

If

xz

> 0, then if

IV
v(1)

>

IV
z

,

xz ).

zu x

=

xu z

x y~z

x x
~z

z x~
y

z x
~x

,

(6.1)

~ are as de…ned in Lemma 4, so that the above equality follows from U = Y~
where Y~ and X
with respect to

is
d
d

from which we see that

xz ; 1],

as a function of :

=

derivative of

2(

monotone in

=

x
~x y~z
x z

(

z x
~y

in the direction of

33

x
~z x~
y

2,
z x
~x )

x
~x y~z

x
~z x~
y.

~ .
X

The

First suppose the bounds are two-sided, in which case (
z y~

from Proposition 3 are

and

zx
~

and as

z y~ x

x~
y z

zx
~ x

x~
x z

x~
x z)

zx
~ x

> 0. Then the bounds on

zx
~

. These correspond to values of

lies between these values we have that

2 [0; 1]. If instead (

are one-sided, and we can again trace out the feasible values of

of 0 and 1, respectively,
x~
x z)

zx
~ x

0, the bounds

zx
~

as a function of . We now further break

this case into the following subcases:
Case 3

1. If

zx
~

< 0. Then

z y~ x

x~
y z

zx
~ x

x~
x z

>

z y~

(
2. If

as

z y~ x
zx
~ x

bound on
which is

z y~ x

x~
y z

zx
~ x

x~
x z

z y~ x~
x

is 1, when

;1

< 0,

zx
~ x~
y

z y~

x~
x z

=

x x
~z

=

2

z y~ x

x~
y z

zx
~ x

x~
x z

, which is

and

.

zx
~

, then

0.

x~
x z

z y~ x

x~
y z

zx
~ x

x~
x z

; 1 , and

d
d

< 0. Thus

Using L’Hospital’s rule, if follows that the

0 from the inequalities

zx
~ x

x~
x z

0 (since

< 0.

z y~ x~
x

0,

zx
~ x~
y

2

zx
~

is 0, when

=

z y~

. The upper bound on

zx
~

x x
~z

zx
~ x

z x
~x

0) and

zx
~

x~
y z

=

zx
~

, then

! 1 is

x~
x z)

zx
~ x

;

zx
~

the upper bound on
limit of

z y~

2 max

0, again since

zx
~ x

d
0. Thus the lower
d
zx
~
is the limit of expression (6.1) as ! 1,
z y~

; 1 , and

0.

x~
x z

z x
~x

Case 4

zx
~

> 0. Then

same logic as when

zx
~

2

1; min

z y~

;

zx
~

z y~ x

x~
y z

zx
~ x

x~
x z

z y~

< 0, we have that when

<

zx
~

takes values on the interval 0;

x x
~z

. When instead

z x
~x
x x
~z

cases,

z x
~x

2 [0; 1] follows from the inequalities

zx
~ x

and

z y~ x

x~
y z

zx
~ x

x~
x z

,

zx
~ x

d
d

x~
x z

< 0, and

z y~

z y~ x

x~
y z

zx
~

zx
~ x

x~
x z

0 and

x~
x z

zx
~

,

0. Following the
as a function of
x x
~z

2

; 1 . In both

z x
~x

> 0.

Having established Corollary 3, we now provide the proof of Proposition 5.
Proof .

2 B as de…ned in the statement of the proposition follows immediately from Proposition 2 in the

simple linear model, and more generally from Proposition 3. This is because Proposition 3 can be applied
to each Zj individually, yielding that

must fall in the intersection of each of the bounds obtained with each

Zj individually. It remains to show that these bounds are sharp, i.e. that any value of
To this end, we make use of Corollary 3, which gives upper and lower bounds on
any

2 B . Then by (2.3b) there exists for each j a

j

j

2 B is feasible.

for each j. Consider

contained in the bounds given by Corollary 3 such

that
=

y~zj

x

x~
y zj

j

x x
~zj

x
~x zj

j

34

,

(6.2)

~ are as de…ned in (3.10a) and (3.10b). De…ne U = Y~
where Y~ and X
shows that (6.2) )

zu = xu

=

j,

~ . Then straightforward algebra
X

for any j. Since by Corollary 3

j

2 [0; 1], it follows that A3 and A4

hold. Thus the joint distribution of (W; Y; X; Z; U ) satis…es our modeling assumptions, verifying that the
conjectured value of

2 B is indeed feasible.

Lemma 3
Proof . We assume that condition (i) holds, and show it is equivalent to (ii). Condition (i) holds if and only
if there exists

2 [0; 1] such that

z2 u

(1

)

z1 u

0 and

z1 u
z1 u

+

x
~z1

+

x
~z2

(1

)

x
~z1

< 0, or equivalently

0,

(6.3)

1,

(6.4)

z2 u

and
x
~z1

<

x
~z2

from which it follows that
z1 u

x
~z1
x
~z1

Substituting

zj u

=

zj y~

From the inequalities

x
~zj

zj u

+

x
~z2

z1 u +

0.
z2 u

for j = 1; 2 and collecting terms gives

0 and

x
~zj

z1 y~ x
~z2

<

z2 y~ x
~z1 ,

condition (iii).

> 0 it also follows that (iii) ) (i). The equivalence of (i) and (ii)
x
~z1

z u

, and (6.4) holds if and only if
> 1 . That
1
1
z2 u
the inequality delivering two-sided bounds is implied by the partial covariance between X and ! ( ) being
follows since (6.3) holds if and only if

>

x
~z2

negative (which is part of condition (i)) follows from …rst noting that this partial covariance is equal to
and then by using the fact that
and consequently that

!(

)~
x x

x~
x

> 0. This implies that
x~
x !(

)

!(

)~
x

!(

)~
x

<0)

!(

)~
x x

x~
x !(

x
~!(
)

),

< 0,

> 0.

Proposition 6
Proof . The proof follows by application of Proposition 5 with ! (

) as an IIV for X.

Appendix B: A model of IIV in demand
In this appendix, we provide a model of demand in which the IIV assumptions hold. To make the example
as transparent as possible, we consider linear demand for a single product sold by a monopolist. This

35

basic model captures the essential features that make our assumptions plausible. The example extends to
di¤erentiated product markets, where the residual demand curve for any single di¤erentiated product plays
the role of the demand for the homogenous product in our example here.
Consider the demand for the good in four distinct geographic markets, which we denote A1, A2, B1, and
B2. The markets A1 and A2 are in region A and are geographically close to one another, while B1 and B2
are in region B. But region A and B are far away from each other.
Suppose demand in each market m 2 fA1; A2; B1; B2g at time t has the form
Qmt =

m

+ pmt +

where Qmt is quantity demanded, pmt is price, and

mt

mt ,

is an unobservable (to the researcher) demand

shifter, e.g. unobserved promotional activities. Quantity and price are observed for each market. Assume
for simplicity that for each market, V ar (

mt )

=

".

A monopolist maximizing one period pro…ts, with constant marginal cost and facing this demand curve
will set prices
pmt =
where mcmt denotes marginal cost. If

mcmt
2

m

+
2

mt

,

< 0 (downward sloping demand) then Cov(pmt ;

mt )

> 0, and least

squares estimation of the demand equation will yield biased estimates.
Assume that Cov(mcmt ;

nt )

= 0 for all m and n, and that V ar (mcmt ) =

mc .

The covariance between

the price in city m and the the demand error in city n is

Cov(pmt ;

If Cov(
Cov(

mt ; nt )

mt ; nt )

Corr(pmt ;

nt )

=

1
Cov(
2

mt ; nt ),

= 0 then pmt is a valid instrument for pnt in estimating the demand equation. However, if

> 0 then the price in the other city is not a valid IV. If Corr(

nt )

mt ; nt )

< 1 then Corr(pmt ;

mt )

>

> 0 and our assumptions A3 and A4 are satis…ed.

In order to examine whether we get one- or two-sided bounds we examine the covariance of prices in any
two markets m and n given by

cov (pmt ; pnt ) =

1
4

cov (mcmt ; mcnt ) +

36

1

2 cov ( mt ; nt )

.

As long as cov (mcmt ; mcnt )

0 then cov (pmt ; pnt ) > 0, and using pmt as an IIV will yield only a one-sided

bound. To get a two-sided bound we exploit regional di¤erences.
Assume that marginal costs are more correlated within a region than across regions. So, for example,
cov (mcA1;t ; mcA2;t ) > cov (mcA1;t ; mcB1;t )

0: On the other hand assume that demand shocks are more

correlated across similar markets than within regions, so that cov (

A1;t ; B1;t )

the conditions of Proposition 6 are satis…ed.

5 As

we noted in section 3.3, this is actually a stronger assumption than we need.

37

> cov (

A1;t ; A2;t )

0;5 then

Table 1: Summary Statistics Production Data
All …rms

present in 2 periods

balanced panel

Variable

mean

st dev

mean

st dev

mean

st dev

Log sales

5.67

1.96

6.20

1.86

6.91

1.84

Log employment

1.26

1.78

1.71

1.69

2.41

1.62

Log capital

4.47

2.22

5.09

2.11

5.92

2.06

Log R&D capital

3.40

2.03

4.00

1.98

4.89

1.93

Log capital investment

2.67

2.17

3.19

2.14

4.07

2.06

Log R&D

1.79

2.05

2.32

2.07

3.22

1.99

N=

2971

1502

856

Source: date from Griliches and Mairesse (1998) (see Hall (1990) for further information on the data)

38

Table 2: Production Function Estimates

Log employment

Log of capital

Log of R&D Capital

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

OLS

1st di¤

OP

AB

BB

IIV1

IIV2

both IIV

0.54

0.74

0.58

0.14

0.63

[0.50 0.71]

[0.62 0.72]

[0.62 0.71]

(0.01)

(0.02)

(0.01)

(0.41)

(0.09)

(0.07 0.77)

(0.38 0.77)

(0.34 0.78)

(0.10 0.77)

(0.38 0.77)

(0.35 0.78)

(0.14 0.76)

(0.41 0.77)

(0.37 0.77)

0.39

0.12

0.34

0.80

0.31

[0.13 0.23]

[0.12 0.17]

[0.13 0.17]

(0.01)

(0.02)

(0.01)

(0.31)

(0.06)

(0.09 0.44)

(0.09 0.29)

(0.09 0.47)

(0.09 0.43)

(0.09 0.29)

(0.09 0.46)

(0.10 0.41)

(0.10 0.27)

(0.09 0.44)

0.05

0.04

0.06

-0.29

0.01

[0.05 0.08]

[0.04 0.06]

[0.05 0.06]

(0.01)

(0.02)

(0.01)

(0.23)

(0.05)

(0.01 0.16)

(0.01 0.15)

(0.01 0.18)

(0.01 0.16)

(0.01 0.12)

(0.01 0.18)

(0.02 0.15)

(0.02 0.11)

(0.02 0.17)

The dependent variable in all columns is the log of sales. The sample includes 1502 observations and includes only
…rms that were present for 2 or more periods. The regressions also include a dummy variable for the computer industry
(SIC 357), and annual dummy variables interacted with the computer dummy. The column labeled OP presents results
from an Olley-Pakes speci…cation, AB from a Arellano and Bond type estimation (…rst di¤erences instrumented with
lagged values), and BB a Blundell-Bond "system" estimator (where we add moments that instrument for a levels
equation using di¤erences). Standard errors are reported in parentheses. In columns 6-8 we report 95% con…dence
intervals (CI) using the method described in Section 4: the top number reports the CI for the identi…ed set, the
bottom number is the CI for the parameter and the middle number report the CI with uniform asymptotic coverage.

39

Table 3: Summary Statistics Demand Data
Variable

Mean

Median

Standard

Min

Max

Deviation
Price

Brand

City

Quarter

Variation

Variation

Variation

20.5

20.0

4.9

8.5

40.9

88.5%

6.3%

1.8%

3.6

3.0

2.0

0.0

9.8

65.9%

N/A

1.8%

2.2

1.7

1.4

0.3

7.9

90.3%

0.1%

0.0%

(c/ per serving)
Advertising
(Mil.$ per quarter)
% Share within
Cereal Market
Source: IRI Infoscan Data Base, University of Connecticut, Food Marketing Center.

40

Table 4: Logit Demand Estimates

price

advertising/10

…rst stage t-stat:

(1)

(2)

(3)

(4)

(5)

(6)

OLS

IV

IIV

opt IIV

IIV1

opt IIV1

-2.21

-4.08

[-8.69 -4.08]

[-8.69 -5.99]

[-8.55 -4.08]

[-8.55 -5.94]

(0.72)

(0.89)

(-11.44 -2.32)

(-11.44 -4.04)

(-11.25 -2.32)

(-11.25 -4.00)

(-11.00 -2.61)

(-11.00 -4.35)

(-10.82 -2.61)

(-10.82 -4.32)

(-11.00 -2.61)

(-11.00 -4.35)

(-10.82 -2.61)

(-10.82 -4.32)

0.31

0.30

[0.28 0.30]

[0.28 0.29]

[0.28 0.30]

[0.28 0.29]

(0.01)

(0.01)

(0.16 0.41)

(0.16 0.41)

(0.16 0.41)

(0.16 0.41)

(0.16 0.41)

(0.16 0.41)

(0.16 0.41)

(0.16 0.41)

(0.18 0.39)

(0.18 0.39)

(0.18 0.39)

(0.18 0.39)

-19.49

-33.40

-19.99

-34.01

42.42

The dependent variable in all columns is log(sjt )

log(s0t ). The sample includes 990 observation: 25 brands

in two cities, Boston and San Francisco, over 20 quarters (one of the brands was only introduced after 5 quarters).
The regressions also include brand …xed e¤ects, a dummy variable for San Francisco and 20 quarterly time dummy
variables. Column (2) reports results using the average price in the region as an IV. Columns (3) reports results
using the di¤erence between the average price in the other city and the average price in the region as an IIV. Column
(4) optimally combines this IIV with the OLS to sharpen the bounds. Columns (5) and (6) repeat but put a weight,
z1 = ( z1

+

z2 ),

on the price in the other city, and

z2 = ( z1

+

z2 )

on the average price in the region. Standard

errors are reported in parentheses. In columns 3-6 we report 95% con…dence intervals (CI) using the method described
in Section 4: the top number reports the CI for the identi…ed set, the bottom number is the CI for the parameter
and the middle number report the CI with uniform asymptotic coverage.

41

