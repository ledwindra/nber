NBER WORKING PAPER SERIES

IN-TEXT PATENT CITATIONS:
A USER’S GUIDE
Kevin A. Bryan
Yasin Ozcan
Bhaven N. Sampat
Working Paper 25742
http://www.nber.org/papers/w25742

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2019

Parts of this project were supported by the Office of the Director, National Institutes of Health
(OD), Office of Behavioral and Social Sciences Research (OBSSR) and the National Institute on
Aging (AG) under Award Number R24 AG048059 to the National Bureau of Economic
Research. The content is solely the responsibility of the authors and does not necessarily
represent the official views of the NIH or the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2019 by Kevin A. Bryan, Yasin Ozcan, and Bhaven N. Sampat. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

In-Text Patent Citations: A User’s Guide
Kevin A. Bryan, Yasin Ozcan, and Bhaven N. Sampat
NBER Working Paper No. 25742
April 2019
JEL No. O3
ABSTRACT
We introduce, validate, and provide a public database of a new measure of the knowledge
inventors draw on: scientific references in patent specifications. These references are common
and algorithmically extractable. Critically, they are very different from the “front page” prior art
commonly used to proxy for inventor knowledge. Only 24% of front page citations to academic
articles are in the patent text, and 31% of in-text citations are on the front page. We explain these
differences by describing the legal rules and practice governing citation. Empirical validations
suggest that in-text citations appear to more accurately measure real knowledge flows, consistent
with their legal role.
Kevin A. Bryan
University of Toronto
Canada
kevincure@gmail.com
Yasin Ozcan
Sloan School of Management
Massachusetts Institute of Technology
Cambridge, MA 02142
ozcan@alum.mit.edu

Bhaven N. Sampat
Department of Health Policy and Management
Columbia University
600 West 168th Street, 6th Floor
New York, NY 10032
and NBER
bns3@columbia.edu

In-text science citation database is available at http://doi.org/10.7910/DVN/ZEZWBX

1

Introduction

What prior knowledge do inventors and firms use as inputs to their research? These
spillovers are at the core of urban economics, growth, and the economics of innovation.
The empirical challenge is that “knowledge flows...are invisible; they leave no paper trail
by which they may be measured and tracked” (Krugman [1991]). Trying to make these
flows visible, researchers have surveyed firms (Levin et al. [1987], Cohen et al. [2000]),
written qualitative industry histories (von Hippel [1988]), and investigated inventor biographies (Khan et al. [2014], Moser [2005]). However, by far the most commonly-used
measure has been prior art cited on the “front page” of granted patents (Jaffe et al. [1993a],
Narin [1994], Trajtenberg [1990]).
Several pioneering studies, beginning in the 1990s, investigated the impact of science
on industrial innovation by looking at front page citations from private sector patents to
academic patents ([Jaffe et al., 1993b, Henderson et al., 1998]). But patents also cite nonpatent references, including scientific literature which for two reasons may represent an
even more promising way to evaluate the effects of public science. First, non-patent citations are less likely to come from examiners than patent-patent citations [Lemley and
Sampat, 2012]. Moreover, since most academic research is disseminated through publications (rather than patents) patent citations to publications capture a broader range of
potential impact than patent-patent citations [Agrawal and Henderson, 2002].
Recently, several research teams have taken advantage of computational advances
and made progress in extracting front page citations to academic research and linking
them to scientific literature databases (e.g., Marx and Fuegi [2019]). These data have been
used for analyzing the impact of NIH research on private sector patenting (Azoulay et al.
[2015], Li et al. [2017]), the impact of publicly funded energy research on applied technology (Popp [2017]), the economic impact of universities (Jefferson et al. [2018]), and
the distance between science and technology in different fields (Ahmadpoor and Jones
[2017]). Funding agencies such as the NSF and NIH are also increasingly using these
2

indicators for evaluation purposes.
We argue that there is a fundamental problem in interpreting front page citations as
knowledge flows. These citations are not simply a list of earlier patents, academic articles,
and other documents which were relevant to the invention. Rather, they derive from a
legal “duty of disclosure” requiring inventors to list documents material to the patentability of their claims. Material to patentability means there is no need to cite tools that help
build the invention, information used to avoid unpromising paths, basic facts that focus
effort, or research suggesting a technological hole or a market need. That is, front page
citations in patents are not analogous to references in academic papers.1
However, patents contain an alternative measure: citations in the specification text
itself. Patent specifications by law must include enough detail that someone “skilled in
the art” could replicate the invention. As Figure 1 shows, inventors fulfill this requirement in part by citing literature while describing the background of their invention, why
it is novel, and how it is built. These descriptive parts of patents are often largely written
by the inventors themselves, rather than by patent attorneys who focus on the more legally
consequential claims and prior art disclosure. Both their legal purpose and their practical construction suggest that in-text citations should better measure the real knowledge
inventors use to motivate and construct their inventions.
Despite this theoretical advantage in tracking knowledge flows, innovation researchers have not used in-text citations for two reasons.2 First, there is a folk belief, which
we will show is untrue, that citations in the text almost always appear on the front page.
Second, since patents do not have bibliographies and in-text citations have no standard1

See Meyer [2000] on the differences between academic and front page patent citation patterns.
The only previous paper using individual in-text references, by two of the present authors, investigated
citations to articles in 44 medical journals while studying the effect of the NIH open access mandate (Bryan
and Ozcan [2019]). The only large-scale institutional attempt we know of to extract in-text references is an
EPO trial beginning in 2006 to include a “summary of references for the reader’s convenience” with in-text
patent and academic references attached to patent pdfs (EPO [2007]). We are unaware of any research in
economics or innovation that has used this measure. At an aggregate level, Tamada et al. [2006] attempts to
find “regular expressions” in the text that look like references to academic science, then counts these across
various classes in Japanese patents.
2

3

ized format, they are difficult to extract. We develop a practical algorithm for extracting
these citations, and use it to develop a public database of all 2,779,258 front page and
in-text citations to every article since 1984 in 244 journals across 20 fields, available at
http://doi.org/10.7910/DVN/ZEZWBX. The distinction between the two types of citations
is dramatic. Only 31% of in-text citations appear on the front page, and only 24% of front
page citations appear in the patent text.3
After describing the formal and practical differences in the legal origins of in-text
versus front page citations, we perform three empirical investigations. First, we examine
“patent-paper pairs” where a biotechnology patent derives from the same research as an
academic article (Murray and Stern [2007]). References in the underlying academic article
bibliography are cited 68 to 138% more often in the text of corresponding patents than on
the front page. Second, we show that the number of in-text citations to academic research
in a firm’s patents is correlated with the firm R&D manager’s stated reliance on public
sector research and open science, using data from the survey in Roach and Cohen [2013].
. Third, in-text citations actually perform worse than front page citations as a proxy for
value. Patents with more front page scientific citations are more valuable according to
four separate measures, and the link between in-text citations and value is generally either
nonexistent or less strong. This ought not be surprising: even if in-text references better
proxy for knowledge flows, this does not imply that they better proxy for everything front
page references have been used to study. Indeed, we might expect inventors and their
attorneys to perform more comprehensive prior art searches for patents they expect will
be more valuable (Sampat [2010]).
This paper has the primary purpose of introducing researchers to in-text citations
and their properties. We see this tool as complementing the recent broad expansion in
techniques exploiting patent text. The first generation of patent-based studies largely used
count measures like patent classes, the number of forward and backward front page ci3

Our publication data contains all articles in selected journals from 1984 to 2016, and our patent dataset
includes all public US patents as of May 2018.

4

tations, and so on. A series of recent papers uses modern computing power and natural
language processing to develop statistically-usable metrics from the raw text of patents.
For example, Kelly et al. [2017] identifies impactful patents by examining text that is unlike existing patents but similar to future patents, Kuhn and Thompson [2017] uses the
length of patent claims to measure the scope of patents, and Kaplan and Vakili [2015] use
topic modeling to identify breakthrough patents.

2

The Empirics of In-Text Citations

The major practical difficulty with using in-text references is that they have no standard
format. Patents do not have bibliographies, and references to publications are made in
the flow of text. For instance, US6551784 writes that “methods for aligning sequences
using the CLUSTAL program are well described by Higgins and Sharp in Gene, 73: 237244 (1988) and in CABIOS 5: 151-153 (1989)).” Extracting that reference requires knowing
both that there are two references to academic publications in this sentence, and that the
CABIOS article refers to one written by Higgins and Sharp. Some in-text references are
incredibly vague, such as “Genomic DNA was obtained from leaf tissue according to Doyle
and Doyle (1987)” in US6483012.
The most natural approach to follow is a coarsened match between article metadata
and text in a patent. Coarse matches permit mis-spellings, various combinations of metadata, and so on.4 The problem in our setting is that identifying a chunk of text as containing a scientific reference is itself a challenging problem in the absence of a bibliography
or the one-line-represents-one-citation format of front page citations. We would therefore
need to apply the coarsened algorithm directly to over a terabyte of text. In practice, our
algorithm, described in detail in the Appendix B, is much faster and much less likely to
4
E.g., US6190856 has an article by Erkki Koivunen cited as “Korvunen"; these mis-spellings are not uncommon. US6130090 cites a Bradley and Liu paper giving the year as 1996 instead of the correct 1997.
US630824 cites a 1989 paper as being published in “Genetics" when it actually appeared in the journal “Genomics"; ironically, this article was written by one of the inventors!

5

generate false positives. Further, our algorithm captures many citations where metadata
are not located near each other in the patent text. For example, in US6605754, “Comai et al
have previously described a chimeric plant promoter combining elements of the CaMV35S
and the mannopine synthase (mas) promoters (1990, Plant Mol Biol, 15:373-381)” is correctly identified despite the author name being nowhere near the other metadata, and the
Higgins and Sharp paper in CABIOS discussed in the previous paragraph is also found.
We use this procedure to extract all in-text and front page references to every research
article published between 1984 and 2016 in 244 prominent journals drawn from fields as
diverse as biology, medicine, engineering, computer science, and social science. These
3,389,853 articles have been cited collectively 2,779,258 times in patents granted since 1984,
with 1,568,516 citations of the front page and 1,210,742 in-text. 10.1% of the articles are
cited at least once, with the probability of being cited highest for biomedical articles. 6.3%
are cited at least once in-text, and 8.1% are cited at least once on the front page. Very recent
articles are, of course, unlikely to be have been cited yet, so these figures understate the
general citation propensity. For articles published in 2000, nearly 16 percent have been
cited at least once in the full-text and/or on the front-page of issued patents.
The critical fact about in-text citations is their lack of overlap with front page citations:
only 24% of the front page citations are cited in-text in the same patent, and only 31% of
the in-text citations are cited on the front page.5 That is, patentees use the two types of
citations in very different ways.
Table 1 shows summary statistics on front-page and full-text citations. The lack of
overlap between in-text and front page citations occurs across patentee types, geographies,
time, and industry. 24% of front page citations by American inventors appear in-text, and
31% of in-text citations appear on the front page; for foreign inventors, the percentages
are 24% and 32%. Patents assigned to academic research institutions have overlap of 31%
5

This difference is not a result of misclassifications by the matching algorithm. In Section 4, we perform
two robustness checks where in-text and front page citations are classified by hand; within these sets the
overlap is similarly small.

6

and 36%, while those assigned to organizations outside academia have overlap of 21%
and 29%. So-called “triadic” patents, which are filed in the US, Europe, and Japan- (this is
often used as in indicator for more important patents) have overlap of 23% and 32%, while
nontriadic patents have overlap of 26% and 30%.6 Patents in medical or biotechnology
classes have overlap of 27% and 31%, while those in other fields have overlap of 19% and
32%.7 To ensure our results are not being driven by patentees who “flood” examiners
with hundreds of references, we can restrict to patents with fewer than 20 front-page and
20 in-text references; the overlaps in this restricted set are 26% and 30%.
Not only is there little overlap between in-text and front page citations whether or not
we restrict to academic, domestic, biomedical, or “important” triadic inventions, but it is
also the case that these in-text citations are nearly all divulged by the inventor at the time of
their initial patent application. Examining public initial applications which are available
for post-2001 patents, every in-text cite in an application remains in the eventually granted
patent, and only 7% of in-text citations in the grant were not in the initial application.
In Appendix B, we provide complete details on our algorithm and the sample of
journals we attempt to match to patents, show that the relative distributions of in-text and
front-page citations are similar and highly skewed, give examples of how our algorithm
treats various types of citations, and describe more precisely how we classify “university”,
“biomedical” and other groups mentioned above.

3

Why Front Page and In-Text Citations Differ

It has long been known that front page citations may miss references to prior scientific
work used by inventors. Indeed, one of the first papers to empirically examine front page
6
Triadic patents are often considered a proxy for high value patents. It is therefore interesting to note
that while triadic and non-triadic patents have an almost identical number of in-text citations conditional
on having at least one (5.79 and 5.59, respectively), triadics have far more front page citations (6.65 and
4.68). We return to this point in the third empirical exercise in Section 4.
7
Medical patents make up 59% of patents citing at least one article in-text, and 51% of those citing at least
one on the front page.

7

citations notes that in-text references “may be more related to the history, usefulness, and
development of the invention.” Nonetheless, they used front page citations since they
are “far easier to extract” (Narin and Noma [1985]). Summary statistics on these front
page citations, especially for citations to academic research, have been reported in OECD
documents and in the NSF Science and Engineering Indicators since the 1990s. The number
of front page citations is one measure used by funders, including the NIH, to investigate
the impact of their grants. Front page citations to patents are widely used as measures of
knowledge flows between inventors, and as proxies for the importance, value, or quality
of the cited inventions (Jaffe and de Rassenfosse [2017]). Recent research suggests frontpage citations to academic patents are not strongly correlated with survey-based indicators of the extent to which firms rely on public research; front-page citation to non-patent
literature is more strongly correlated [Roach and Cohen, 2013]. However qualitative and
historical studies suggest that even front page citations to science appear to map poorly
into the directly measured prior knowledge of inventors (Tijssen [2002], Meyer [2000]).8
To understand more clearly why patents cite such a radically different set of prior
knowledge in their specification text than on the front page, and what this difference
means for scholars of innovation, let us examine how patentees legally ought to use these
citations, and how they do so in practice.
Consider first front page citations, whose legal origin lies in patentees’ “duty of disclosure”. Everyone involved in filing a patent “has a duty...to disclose to the Office all
information known to that individual to be material to patentability” (37 CFR 1.97). That
is, any individual involved in the filing of the patent, whether the initial inventors, a drafter,
a patent agent, or a patent attorney, must disclose on an Information Disclosure Statement
(IDS) any prior publications they know which are relevant to the novelty and/or non8

Nearly half of front page citations to patents are added by examiners (Alcácer et al. [2009]). Only around
5% of front page citations to academic articles are added by the examiner (Lemley and Sampat [2012]), so
the examiner problem is less severe for these types of citations, though of course it still unclear whether
lawyers, inventors, or someone else inside the inventing firm added a given reference.

8

obviousness of the invention.9 These individuals must cite prior art even if they learn of it
years long after the invention is complete.10 If known prior art is not disclosed, there is a
risk the patent office will find “inequitable conduct,” which is grounds for unenforceability of a patent (Cotropia et al. [2013]). The documents on the IDS, alongside relevant prior
art found by a patent examiner, make up the front page citations in a granted patent. Front
page citations therefore represent a list of prior documents, known by any person involved
in preparing the patent, which might be relevant to the novelty or non-obviousness of the
patent’s claims.
In-text citations have a completely different legal origin. The specification must “enable” the invention by describing its background, showing how it solves a useful problem,
and showing how a person “skilled in the art” can make and use it without excessive experimentation. The applicant is not required to cite anything formally in the patent specification text, since she can simply describe the invention’s background and method of
construction using text and graphics. Often, it is easier to “incorporate by reference” aspects of the background and method.11 For instance, a patent application for a new cancer
drug could describe the method of discovery by writing “we inject our mice with cancer
using the technique developed by Smith (2017).” The reference to Smith replaces lengthy
details on how exactly that injection method works.12 These in-text citations, therefore,
serve a role more like academic citations than front page citations. Knowledge flows like
9

Brasseler, U.S.A. I, L.P. v. Stryker Sales Corp., Fed. Cir. 2001: “Once an attorney, or an applicant has
notice that information exists that appears material and questionable, that person cannot ignore that notice
in an effort to avoid his or her duty to disclose.”
10
Another complicating factor is that there is a strategic aspect to whether applicants search for or cite
prior art (Lampe [2012], Sampat [2010]) and heterogeneity among patent examiners in the extent to which
they do so (Lemley and Sampat [2012]).
11
See 37 CFR 1.71 and 37 CFR 1.57.
12
The situation is slightly different outside the United States. European patents, for instance, do not have
a duty of disclosure, and therefore tend to have fewer front page citations; they also operate under the
requirement that the patent specification is interpretable by a more specialized reader than a U.S. patent, and
hence may also see differences with in-text references. That said, the nature of in-text citations in European
patents may not be much different than in the United States. European specifications must “indicate the
background art which, as far as is known to the applicant, can be regarded as useful to understand the
invention” (EPC Rule 42.1(b)). We have not validated the empirical properties of in-text citations for nonU.S. patents, but at least by the letter of the law, the qualitative distinction between front page and in-text
citations is the U.S. and Europe is not large.

9

basic motivating facts, open scientific puzzles, and tools used to construct the invention,
are often part of an invention’s method and background but not material to patentability.

3.1

Patent strategy and practice

In addition to laws on the books discussed above, patent practice and legal strategy will
shape what we see cited on the front-page vs. in the full-text practice.
Based on our understanding from legal scholars and practitioners, inventors are typically more involved in drafting patent specifications than they are in prior art searches.
And once drafted, the patent specification typically doesn’t change much (technically it
cannot without filing a continuation-in-part, which may or may not benefit from the priority date of the original application; MPEP 201.07). So in-text citations generally are generated around the time the original application is drafted, sometimes based on citations
in provisional applications or scientific articles accompanying the patent.
As noted above, front page citations come from applicant information disclosure
statements (IDS, PTO form 1449) and the examiner search that typically follows (reported
on the PTO Form 892). In contrast to full-text citations, these front page citations come in
over the course of prosecution process, and include inputs from attorneys who prepare the
IDS based on information from inventors and their own prior art searches, and examiners’
own searches at the USPTO.13
Importantly while the "duty of candor" applies to the entire patent process, failure
to enable an invention would not consititute a violation of it (though may result in an enablement rejection) whereas failure to disclose known prior art on an IDS would. (MPEP
37 CFR 1.56). Violation of the duty of candor involves severe penalties for applicants and
their attorneys, and could render the subject patent unenforceable. In this context, applicants (and attorneys) many err on the side of caution in their front page citations, since
13

As an empirical matter front-page citations to non-patent literature are less likely to be listed as "added
by examiner" than front-page citations to patents [Lemley and Sampat, 2012]. Based on published PTO data
about 4 percent of non-patent references are from examiners, compared to 40 percent of patent references.

10

there is no penalty for citing too much. There is also some argument that attorneys may
"flood the patent office" to hide actual relevant references [Taylor, 2012], though there is no
strong evidence on this. On the other hand, it is also known that in some fields a substantial share of patents include little or no applicant provided art, possibly because inventors
don’t read competitors’ patents for fear of willful infringement liability or don’t care much
about the validity of any given patent, but instead about accumulating large portfolios.14
These strategic aspects of front-page citation practice, and the legal meaning of frontpage citations above would seem to call into question some of the early assumptions in citation analysis, such as Trajtenberg’s assumption that the front-page citation process "apparently does generate the right incentives to have all relevant patents cited, and only
those" [Trajtenberg, 1990].
But there are potential strategic aspects to in-text citation as well. Inventors and attorneys may want to provide enough information to satisfy the disclosure requirement, but
not enough to "actually" enable competitors to practice the invention.15 Both legal scholarship and the economics literature provide mixed evidence on how much patents actually
disclose, and how seriously applicants take the disclosure requirement [Ouellette, 2011,
Devlin, 2009, Fromer, 2008, Cohen et al., 2000] though none of the literature focuses on
in-text citation practices per se.
Finally, some attorneys and law firms consider it best legal practice to reference everything in the specification on the front-page because there is little cost to doing so. However, there is no legal requirement to do so, since, as emphasized in the previous section,
prior art citations and citations in the specification have different purposes. Only the intext citations that also bear on novelty and/or non-obviousness need to be actually need
to be cited on the front-page, though actual citing practices may vary by firms, attorneys,
14

The duty of candor does not require affirmative search, only disclosure of known prior art. See Sampat
[2010] for more discussion.
15
As a practical matter, only 35 percent of applications get a rejection on Section 112 grounds - failure to
meet disclosure - while 72 percent do for non-obviousness reasons, i.e. in light of prior art on the IDS or
found by examiners. See Frakes and Wasserman [2017].

11

and even the importance of specific inventions.

4

Validating In-Text Citations

We have shown that in-text citations are algorithmically extractable, have little overlap
with front page citations, and legally ought better track real knowledge flows. To confirm
that final hypothesis empirically, we perform two validations linking both types of citations to non-patent measures of the invention’s underlying science. We also examine how
both types of citations relate to commonly used measures of patent value.

4.1

In Patent-Paper Pairs, In-Text References Better Match the Base Article

Our first validation asks, for patents where there is an academic article describing the
same invention, do in-text or front page citations more closely match the knowledge flows
cited in the article? Murray and Stern [2007] collects 171 articles in the journal Nature
Biotechnology with a related patent filed at least partially on the basis of that article, as
judged by a reader with subject-matter expertise. If in-text citations are a superior measure
of the type of knowledge flows represented by academic citations, the research cited in the
academic article should appear more frequently in the patent text than the front page.
Recall that our algorithmic method for identifying in-text citations requires starting with a fixed list of academic articles. Therefore, for this comparison we instead read
each patent manually, counting the total number of in-text and front page references to
academic articles in any journal, and the number of references in the original article’s bibliography that are also cited in-text or on the front page.16
16

Note that extracting these references by hand means we are able to handle the non-trivial number of
patents with typos on references, such as misspelled author names, misstated years, or obscure journal
abbreviations. Reassuringly, the overwhelming majority of references we find by hand are ones that our
algorithm would match if given the proposed academic article.

12

The biotechnology patents in this sample cite academic work much more heavily
than the modal patent. The 171 patents have a mean of 26.9 (median: 15) front page
references to academic articles, and a mean of 41.5 (median: 29) in-text references. The
majority of references of each type are unrelated to the research cited in the corresponding Nature Biotechnology article; this is both because the patent text is generally very long
and detailed compared to the academic writeup, and because the patent often covers an
invention broader than the particular result in the underlying article.
On average, each Nature Biotechnology article in the Stern-Murray sample has about
30 referenced articles. Of these, an average of 6.9 articles are also mentioned in the text
of the corresponding patent, while only 4.1 are cited on the patent’s front page. That is,
a citation in the underlying Nature Biotechnology article is 68% more likely to be found
in the corresponding patent’s specification text than in the front page citations. For the
median patent-paper pair, the difference is even more stark. The front page of the median
patent contains only 6.3% of the corresponding article’s academic references, while the
text contains 13.0% of these references, a 108% increase.
More than 25% of patents in the Murray-Stern sample have zero front page references
which match a reference in the article bibliography, and 43.3% have no more than a single
such reference. Patents with only zero or one in-text citation matching the article bibliography are far less common, at 10.5% and 25.7% respectively. That is, a researcher who
relied on front page citations rather than in-text citations to investigate knowledge flows
would be almost 2.5 times more likely to incorrectly conclude that patent did not rely on
any of the knowledge contained in the corresponding academic paper’s references. The
correlation of the total number of in-text and front page references matching the article
bibliography for a given patent-paper pair is only 0.48, though this correlation overstates
the overlap; even when there are, for instance, 3 in-text and 2 front page citations that
match the article’s bibliography, those 5 citations are often entirely distinct. Indeed, the
in-text academic references and front page academic citations are identical in only 3 of the

13

171 patents.
Do in-text citations contain more of the corresponding article’s academic citations
simply because the inventor has lazily copy-and-pasted parts of the background from the
article into the patent? In our experience manually reading both the article and the patent,
it was very rare to find identical language. Only 5 of the 171 patents contained every
academic reference from the corresponding article in the patent text, and in only 12.9%
of the patents were even half of the underlying article’s citations included in the patent
text. A reader may ask why patents that make up a patent-paper pair do not cite all of
the references in the original article. There are two reasons. First, the patent in general
does not describe precisely the same invention and claims as the result described in the
original article; rather, the original article often describes a single claim of the invention.
Second, when manually examining these patent-paper pairs, similar basic science is often
cited with different yet scientifically-equivalent references in the article and the patent.

4.2

References Compared to Survey Evidence of Knowledge Transfers

Our second validation asks, are front page or in-text citations of academic research better correlates of firms’ stated reliance on public sector research in a large survey? The
Carnegie Mellon Survey (Cohen et al. [2002]) of industrial R&D managers asked how
much their firm relies on public sector spillovers for their inventions, as well as a series of
questions about their reliance on “open science” like conferences, books and articles, versus “closed science” like contract work with academics. A follow-up study counted front
page citations to public sector patents and non-patent literature in surveyed firm’s patents
(Roach and Cohen [2013]). The former doesn’t correlate at all with the R&D manager’s
stated response on the percent of a firm’s research using public sector knwledge, and the
latter correlates relatively weakly.
To check whether in-text citations to academic research may better predict firm’s
actual stated use of public sector knowledge, we manually count all in-text and front page
14

references to journal publications in all 6,148 patents filed by 614 surveyed firms between
1991 and 1993. There are 8,307 total front page citation of academic journal articles, and
9,296 in-text cites. The raw correlation between the two count measures, at the individual
patent level, is .52.
Figure 2 plots the correlation between the number of in-text citations or front page
citations to academic research and the R&D manager’s estimate of whether less than 10%,
10-40%, 40-60%, 60-90%, or greater than 90% of their research projects rely on public sector
knowledge. This plot is monotonically and strongly increasing for the in-text measure, and
increasing though imprecise for the front page measure.
In Table 2, we show that, in line with Figure 2, the in-text measure explains more of
the survey response variance across a variety of specifications. The literature on Bayesian
model selection provides a formal test of that statement (Raftery [1995], Kass and Raftery
[1995]). The idea is the following. Take two potentially non-nested models, such as two
regressions of different measures of citations on a survey measure of actual public sector knowledge transfer. Consider the relative likelihood of the data given the model in
question, and adjust for the sample size and number of explanatory variables. A good
model makes the data more likely while being parsimonious. A particular measure, the
Bayesian Information Criterion (BIC), is identical to considering the posterior likelihood
of two models with a “unit information” prior (Raftery [1998]).
A difference in the BIC of 6, by a standard rule of thumb (Raftery [1995]), is “strong”
evidence for one model over another. In particular, when the difference is BIC is more than
6, one model is at least 20 times more likely to explain the data observed than another.
Note the final row in Table 1: in-text citations are more strongly predictive for every model,
whether without controls, or after controlling for covariates like industry and the number
of scientists at each firm.17
17

Appendix Table A.1 shows that in-text citations are also a better proxy for the “open science” factor in
Roach and Cohen [2013], measuring the reliance of a firm’s R&D on publicly available science.

15

4.3

In-text References and the Value of Patents

The previous two validations suggest that in-text citations more accurately represent
knowledge flows, in line with the formal legal purpose of front page versus in-text citations. This does not mean that front page citations have no use for scholars of innovation. Prior research suggests that front page scientific references can serve as a proxy
for high-value patents, as measured by forward citations or other metrics (Fleming and
Sorenson [2004], Sorenson and Fleming [2004].18 While the interpretation of this result is
unclear (for example, Sampat [2010] suggests that firms have incentives to search for prior
art more diligently for more important inventions), comparing how front page references
and in-text references to science respectively correlate with patent value can help us better
understand the information contained in each measure.
To do so, we collect data on all front page and in-text citations from 489,346 patents
issued between 2006 and 2008 to articles published in the 244 journals described in Section
2. Of these patents, most (93 percent) cite no scientific articles from our set. Of patents
with front page references to a scientific article, 57 percent also cite at least one scientific
article in text. And of the patents with a full text reference, 69 percent cite at least one
article on the front page.
We also collected data on four different measures of invention value: (1) forward
citations in later patents; (2) the stock market reaction to patent issuance (Kogan et al.
[2017]); (3) whether the patents were renewed to at least year 8; and (4) whether the
patents are part of triadic patent families. Prior research has used each of these measures
as an indicator of patent value.
Table 3 shows summary statistics on each of the variables in this model. Tables 4, 5,
and Appendix Tables 2 and 3 show results from OLS regressions relating the value mea18

Other research shows a weak or even negative relationship between extent of science citation in firms
patents and forward citations (Trajtenberg et al. [1992], Gittelman and Kogut [2003], Cassiman et al. [2008]).
Patent-to-patent citations by inventors/attorneys tend to be focused on canonical inventions in an area and
high-quality prior patents, while examiner-added citations focus on similarity (Moser et al. [2018]).

16

sures to the number of front page and in-text references (Models 1-3) and to indicators
for whether there were any front page or in-text references (Models 4-6). We find front
page backward citations to science are positively correlated with forward citations (Table 4) and with whether the patent is part of a triadic patent family (Table 5), consistent
with prior research (Sorenson and Fleming [2004], Fleming and Sorenson [2004]). To our
knowledge the relationship between front page science references and stock market reaction to patent issue nor maintenance decisions has been examined before, and here the
relationships are less robust across specifications (Appendix Tables 2 and 3). That said,
for all four measures of value, in most specifications, front page citations are more strongly
related to value than in-text citations.19
The precise mechanisms for this are unclear. It may be that a patent’s similarity or
proximity to science, captured by front page science citations cited as prior art material to
patentability, is more predictive of the private value of a patent to a firms than is whether
the patent is based on science. This could be true, for example, if scientific inputs cited in
text were in the public domain and available to competitors as well. Alternatively, it may
be that applicants submit more front-page prior art or search more intensively for their
more important inventions, to “bulletproof” these patents against validity challenges or
guard against duty of candor violations, whereas for reasons discussed above this is not
necessary to do for in-text citations. Whatever the reasons, this final validation emphasizes
that front-page and full-text citations are fundamentally different, and each potentially
useful for measuring different concepts.

5

Concluding Remarks

Our results should not be interpreted as saying that the oft-used front page citation measure has no valid use. It is, after all, true that front page citations help measure patent
19
Further, a formal Bayesian model selection procedure as in the previous subsection strongly prefers
models using front page citations to proxy for forward citations and triadic patents.

17

value, and that these citations are useful in investigating the similarity of patents (e.g., Ahmadpoor and Jones [2017]). That said, front page citations in the strict legal sense neither
measure underlying knowledge used in making an invention, nor delineate knowledge
known by the inventor themselves as opposed to that known by their lawyer. The situation is very different with in-text citations, which are used explicitly to point to prior
literature relevant to a patent’s method and background. Assuming that front page citations are simply a noisy measure of in-text citations is incorrect: the overlap between the
two measures is only 24% to 31%, and the magnitude and significance of each type of citation as proxies for various real outcomes in Section 4 vary enormously even with large
N sample sizes.
In addition to having completely different legal uses, in-text citations possess two
practical benefits compared to front page citations. First, non-granted patent applications
do not have any front page citations listed.20 For studies that require the use of contemporaneous data, it is often infeasible to wait five or more years for patents to be granted.
In-text citations appear in applications, alloing that contemporaneous data to be examined. Second, pre-1947 U.S. patents do not have front page citations, while in-text citations can, in theory, be extracted for patents going back to the 1800s. For example, U.S.
patent 2,295,481 A, applied for in 1939 by a scientist at Merck, contains no front page at
all, but cites in the specification text just like modern patents: “Thus, Domagk (Deutsche
Med. Wochsch., 61, 250, 1935) claimed that Prontosil, a derivative of diazotized sulphanilamide, was moderately effective against pneumococci, especially of Type III.”
We have shown that in-text citations can be accurately and comprehensively extracted from patents, and that these citations closely correlate with actual knowledge
flows in multiple empirical validations. Therefore, we suggest that future work relying on
patents as a “paper trail of knowledge” should use in-text rather than front page citations.
20

The information disclosure statements with applicant prior art citations can be filed throughout the
application process, and examiner searches are conducted after the application is filed. More practically,
neither of these is readily available in machine readable form.

18

A public database covering 244 journals for over three decades is available alongside this
paper. That said, an institutional project establishing a more complete and open-access
database along the lines of the existing NBER front page citation database would be particularly useful.
As for future research, the actual text of patents remains an incredibly underutilized
resource. Rather than relying on count measures or features like a patent’s class, machine learning methods (e.g., Mullainathan and Speiss [2017], Gentzkow et al. [2017])
can “read” the text of the patent and hence uncover information on precisely what knowledge a patent recombines, the exact way certain types of knowledge were used in the invention, and so on. In-text citations should prove value not just in better capturing actual
knowledge flows, but in the ability to use the words around those citations to understand
exactly how, when, and why inventors build on the past.

19

References
Ajay Agrawal and Rebecca Henderson. Putting patents in context: Exploring knowledge
transfer from mit. Management science, 48(1):44–60, 2002.
Mohammad Ahmadpoor and Benjamin F. Jones. The dual frontier: Patented inventions
and prior scientific advance. Science, 2017.
Juan Alcácer, Michelle Gittelman, and Bhaven Sampat. Applicant and examiner citations
in U.S. patents: An overview and analysis. Research Policy, 38(2):415–427, 2009. ISSN
00487333. doi: 10.1016/j.respol.2008.12.001.
Pierre Azoulay, Joshua S Graff Zivin, Danielle Li, and Bhaven N Sampat. Public r&d investments and private-sector patenting: evidence from nih funding rules. The Review of
Economic Studies, 2015.
Kevin A. Bryan and Yasin Ozcan. The Impact of Open Access Mandates on Invention.
2019.
Bruno Cassiman, Reinhilde Veugelers, and Pluvia Zuniga. In search of performance effects
of (in) direct industry science links. Industrial and Corporate Change, 17(4):611–646, 2008.
Wesley Cohen, Richard Nelson, and John Walsh. Links and impacts: The influence of
public research on industrial r&d. Management Science, 2002.
Wesley M Cohen, RR Nelson, and John P Walsh. Protecting Their Intellectual Assets:
Appropriability Conditions and Why U.S. Manufacturing Firms Patent (or Not). NBER
Working Paper, (7552):50, 2000. ISSN 17561663. doi: 10.1093/dnares/dsr014. URL www.

nber.org/papers/w7552.
Christopher A. Cotropia, Mark A. Lemley, and Bhaven Sampat. Do applicant patent citations matter? Research Policy, 42(4):844–854, 2013. ISSN 00487333. doi: 10.1016/j.respol.
2013.01.003.
20

Alan Devlin. The misunderstood function of disclosure in patent law. Harv. JL & Tech., 23:
401, 2009.
EPO.

Cited References in European Patent Documents, 2007.

URL http:

//www.wipo.int/export/sites/www/cws/en/taskforce/citation{_}practices/
docs/epo{_}citation{_}practice{_}summary.pdf.
Lee Fleming and Olav Sorenson. Science as a map in technological search. Strategic Management Journal, 25(8-9):909–928, 2004.
Michael D. Frakes and Melissa F. Wasserman. Is the time allocated to review patent applications inducing examiners to grant invalid patents? evidence from microlevel application data. Review of Economics and Statistics, 99(3):550–563, 2017.
Jeanne C Fromer. Patent disclosure. Iowa L. Rev., 94:539, 2008.
Matt Gentzkow, Bryan Kelly, and Matt Taddy. Text as data. NBER Working Paper, 2017.
Michelle Gittelman and Bruce Kogut. Does good science lead to valuable knowledge?
biotechnology firms and the evolutionary logic of citation patterns. Management Science,
49(4):366–382, 2003.
Rebecca Henderson, Adam B Jaffe, and Manuel Trajtenberg. Universities as a source of
commercial technology: a detailed analysis of university patenting, 1965–1988. Review
of Economics and statistics, 80(1):119–127, 1998.
Adam Jaffe, Manuel Trajtenberg, and Rebecca Handerson. Geographic Localization of
Knowledge Spillovers as Evidenced by Patent Citations Author ( s ): Adam B . Jaffe ,
Manuel Trajtenberg and Rebecca Henderson. The Quarterly Journal of Economics, 108(3):
577–598, 1993a. ISSN 0033-5533. doi: 10.2307/2118401.
Adam B. Jaffe and Gaetan de Rassenfosse. Patent citation data in social science research:

21

Overview and best practices. Journal of the Association for Information Science and Technology, 2017.
Adam B Jaffe, Manuel Trajtenberg, and Rebecca Henderson. Geographic localization of
knowledge spillovers as evidenced by patent citations. the Quarterly journal of Economics,
108(3):577–598, 1993b.
Osmat A Jefferson, Adam Jaffe, Doug Ashton, Ben Warren, Deniz Koellhofer, Uwe Dulleck,
Aaron Ballagh, John Moe, Michael DiCuccio, Karl Ward, et al. Mapping the global
influence of published research on industry and innovation. Nature biotechnology, 36(1):
31, 2018.
Sarah Kaplan and Keyvan Vakili. The double-edged sword of recombination in breakthrough innovation.

Strategic Management Journal, 36(10):1435–1457, 2015.

ISSN

10970266. doi: 10.1002/smj.2294.
Robert E. Kass and Adrian E. Raftery. Bayes factors. Journal of the American Statistical
Association, 1995.
Bryan Kelly, Dimitris Papanikolaou, Amit Seru, and Matt Taddy. Measuring Technological
Innovation over the Long Run. Working Paper, pages 1–57, 2017.
B Zorina Khan, Lee Branstetter, Colleen Chien, Claude Diebolt, Rochelle Dreyfuss, Naomi
Lamoreaux, Petra Moser, Adam Mossoff, Tom Nicholas, Alessandro Nuvolari, Patricio
Saíz, and Ted Sichelman. Inventing in the Shadow of the Patent System: Evidence from
19th-centrury Patents and Prizes for Technological Innovations. NBER Working Paper
#20731, 2014. doi: 10.3386/w20731.
Leonid Kogan, Dimitris Papanikolaou, Amit Seru, and Noah Stoffman. Technological innovation, resource allocation, and growth. The Quarterly Journal of Economics, 132(2):
665–712, 2017.

22

Paul R. Krugman.

Geography and trade.

MIT Press, Cambridge, MA, 1991.

ISBN

9780262111591.
Jeffrey Kuhn and Neil Thompson. The Ways We’ve been Measuring Patent Scope are
Wrong: How to Measure and Draw Causal Inferences with Patent Scope. 2017.
Ryan Lampe. Strategic citation. Review of Economics and Statistics, 2012.
Mark A. Lemley and Bhaven Sampat. Examiner Characteristics and Patent Office Outcomes. Review of Economics and Statistics, 94(3):817–827, 2012. ISSN 0034-6535.
Richard C Levin, Alvin K Klevorick, Richard R Nelson, and Sidney G Winter. Appropriating the Returns from Industrial Research and Development; Comments and Discussion. Brookings Papers on Economic Activity, (3):783, 1987. ISSN 0007-2303. doi:
10.2307/2534454.
Danielle Li, Pierre Azoulay, and Bhaven N Sampat. The applied value of public investments in biomedical research. Science, 356(6333):78–81, 2017.
Matt Marx and Aaron Fuegi. Reliance on science in patenting. Working Paper, 2019.
Martin Meyer. What is special about patent citations? Differences between patent and
scientific citations. Scientometrics, 49(1):93–123, 2000. ISSN 01389130 (ISSN). doi: 10.
1023/A:1005613325648. URL http://dx.doi.org/10.1023/A:1005613325648.
Petra Moser. How do patent laws influence innovation? Evidence from nineteenthcentury world’s fairs, 2005. ISSN 00028282.
Petra Moser, Joerg Ohmstedt, and Paul Rhode. Patent citations - an analysis of quality
differences and citing practices in hybrid corn. Management Science, 2018.
Sendhil Mullainathan and Jann Speiss. Machine learning: An applied econometric approach. Journal of Economic Persepectives, 2017.
23

Fiona Murray and Scott Stern. Do formal intellectual property rights hinder the free flow
of scientific knowledge?. An empirical test of the anti-commons hypothesis. Journal of
Economic Behavior and Organization, 63(4):648–687, 2007. ISSN 01672681. doi: 10.1016/j.
jebo.2006.05.017.
F. Narin. Patent bibliometrics. Scientometrics, 30(1):147–155, 1994. ISSN 01389130. doi:
10.1007/BF02017219.
F. Narin and E. Noma. Is technology becoming science? Scientometrics, 7(3-6):369–381,
1985. ISSN 01389130. doi: 10.1007/BF02017155.
Lisa Larrimore Ouellette. Do patents disclose useful information. Harv. JL & Tech., 25:545,
2011.
David Popp. From science to technology: the value of knowledge from different energy
research institutions. Research Policy, 46(9):1580–1594, 2017.
Adrian E. Raftery. Bayesian model selection in social resarch. Sociological Methodology,
1995.
Adrian E. Raftery. Bayes factors and bic: Commets on weakliem. University of Washington
Technical Report, 1998.
Michael Roach and Wesley M. Cohen. Lens or Prism? Patent Citations as a Measure of
Knowledge Flows from Public Research. Management Science, 59(2):504–525, 2013. ISSN
0025-1909. doi: 10.1287/mnsc.1120.1644. URL http://pubsonline.informs.org/doi/

abs/10.1287/mnsc.1120.1644.
Bhaven Sampat. When do patent applicants search for prior art? Journal of Law and Economics, 2010.
Olav Sorenson and Lee Fleming. Science and the diffusion of knowledge. Research policy,
33(10):1615–1634, 2004.
24

Schumpeter Tamada, Yusuke Naito, Fumio Kodama, Kiminori Gemba, and Jun Suzuki.
Significant difference of dependence upon scientific knowledge among different technologies.

Scientometrics, 68(2):289–302, 2006.

ISSN 01389130.

doi: 10.1007/

s11192-006-0112-2.
Robert Brendan Taylor. Burying. Mich. Telecomm. & Tech. L. Rev., 19:99, 2012.
Robert J.W Tijssen.

Science dependence of technologies: evidence from inventions

and their inventors. Research Policy, 31(4):509–526, 2002. ISSN 00487333. doi: 10.
1016/S0048-7333(01)00124-X. URL http://linkinghub.elsevier.com/retrieve/pii/

S004873330100124X.
Manuel Trajtenberg. A Penny for Your Quotes: Patent Citations and the Value of Innovations. The RAND Journal of Economics, 21(1):172, 1990. ISSN 07416261. doi:
10.2307/2555502. URL http://doi.wiley.com/10.2307/2555502.
Manuel Trajtenberg, Rebecca Henderson, and Adam Jaffe. Ivory tower versus corporate
lab: An empirical study of basic research and appropriability. Technical report, National
Bureau of Economic Research, 1992.
Eric von Hippel. The Sources of Innovation. Oxford University Press, 1988.

25

26
Figure 1: Example of front page citations (left) versus in-text citations (right)

Figure 2: Survey response is per firm to “what fraction of your unit’s R&D projectors
rely on public sector knowledge”, on a five point scale: 0-10%, 10-40%, 40-60%, 60-90%,
90-100%.

27

Table 1: Summary statistics on in-text versus front-page citations

28

N of Patents
Avg. # of In-Text
Avg. # of Front Page
Share of In-Text on FP
Share of FP In-Text

All

US

Non-US

Univ

Non-Uni

Triadic

Non-Tri

Biomed

Non-BM

341799
3.55
4.60
31.1
24.0

226742
4.05
5.22
30.9
24.0

115057
2.54
3.34
32.0
24.3

77959
5.28
6.21
35.6
30.1

263840
3.03
4.11
28.7
21.1

178191
3.83
5.41
32.0
22.7

163511
3.23
3.70
30.0
26.2

168472
5.42
6.24
30.7
26.7

173230
1.72
2.98
32.4
18.6

Table 2: Ordered logit models relating percent of firms’ R&D projects using public research to science references
1
In-Text Cites per Patent

2

0.0882∗∗∗
(0.0122)

3
0.0619∗∗∗
(0.0171)

0.0892∗∗∗
(0.0140)

Front-Page Cites per Patent

4

5

6

0.0582∗∗∗
(0.0161)
0.0470∗
(0.0223)

0.0404
(0.0228)

Total Firm Patents

0.133
(0.0878)

0.143
(0.0887)

Fraction Scientists

1.589∗∗∗
(0.326)
614
0.053
1628.4
Yes

1.555∗∗∗
(0.334)
614
0.050
1634.4
Yes

Observations
Pseudo R2
BIC
Industry Controls

615
0.020
1680.7
No

615
0.015
1687.8
No

615
0.046
1629.6
Yes

615
0.043
1635.7
Yes

Standard errors in parentheses
Firm-level ordered logit with s.e. clustered by industry; depvar is % of firms’ R&D projects using public research
∗
p < 0.05, ∗∗ p < 0.01, ∗∗∗ p < 0.001

29

Table 3: Summary statistics for value vs. science reference analyses
VARIABLES
Number of front page science refs
Number of full text science refs
Number of overlapping science refs
Any full text science refs?
Any front page science refs?
Forward citations
Maintained at 8?
Stock Reaction
Triadic Patent?

(1)
N

(2)
mean

(3)
sd

489,346 0.332 2.533
489,346 0.331 2.568
489,346 0.178 1.772
489,346 0.0513 0.221
489,346 0.0596 0.237
489,346 9.577 24.36
489,346 0.572 0.495
199,986 10.94 30.40
489,346 0.285 0.451

30

(4)
min

(5)
max

0
195
0
224
0
170
0
1
0
1
0
2,120
0
1
0.000237 1,457
0
1

Table 4: OLS models relating forward citations to science references
VARIABLES
Number of front page science refs

(1)
Forward

(2)
Forward

(3)
Forward

0.1***
(0.01)

0.3***
(0.02)
0.007
(0.01)

0.3***
(0.02)

Number of full text science refs
Any front page science refs?

(4)
Forward

31

issyear = 2008
Constant

Observations
R-squared
Patent class FE
BIC

(6)
Forward

3.9***
(0.4)
-1.9***
(0.08)
-3.9***
(0.08)
11***
(0.06)

6.1***
(0.3)
0.7*
(0.4)
-1.9***
(0.08)
-3.9***
(0.08)
11***
(0.06)

489,346
0.090
Yes
4467184.33

489,346
0.092
Yes
4466101.66

6.4***
(0.3)

Any full text science refs?
issyear = 2007

(5)
Forward

-1.9***
(0.08)
-3.9***
(0.08)
11***
(0.06)

-1.9***
(0.08)
-3.9***
(0.08)
11***
(0.06)

-1.9***
(0.08)
-3.9***
(0.08)
11***
(0.06)

-1.9***
(0.08)
-3.9***
(0.08)
11***
(0.06)

489,346
489,346
489,346
489,346
0.091
0.090
0.091
0.092
Yes
Yes
Yes
Yes
4467047.51 4467491.42 4467060.39 4466099.53
Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

Table 5: OLS models relating whether a patent is in a triadic family to science references
(1)
Triad?

VARIABLES
Number of front page science refs

(2)
Triad?

(3)
Triad?

-0.0002
(0.0003)

0.007***
(0.0003)
-0.003***
(0.0003)

0.006***
(0.0003)

Number of full text science refs
Any front page science refs?

(4)
Triad?

32

issyear = 2008
Constant

Observations
R-squared
Patent class FE
BIC

(6)
Triad?

0.04***
(0.004)
-0.006***
(0.001)
-0.01***
(0.001)
0.3***
(0.001)

0.1***
(0.004)
-0.01***
(0.005)
-0.007***
(0.001)
-0.01***
(0.001)
0.3***
(0.001)

489,346
0.113
Yes
551301.72

489,346
0.115
Yes
550318.84

0.1***
(0.003)

Any full text science refs?
issyear = 2007

(5)
Triad?

-0.007***
(0.001)
-0.01***
(0.001)
0.3***
(0.001)

-0.006***
(0.001)
-0.01***
(0.001)
0.3***
(0.001)

-0.007***
(0.001)
-0.01***
(0.001)
0.3***
(0.001)

-0.007***
(0.001)
-0.01***
(0.001)
0.3***
(0.001)

489,346
489,346
489,346
489,346
0.114
0.113
0.114
0.115
Yes
Yes
Yes
Yes
550821.01 551418.98 550739.87 550319.26
Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

Appendix A: Additional Results

33

Table A.1: Bayesian Model of Patent Citations Predicting Firms’ Use of Open Science in Research
In-Text Cites per Patent

1
0.0338∗∗∗
(0.00583)

2

3
0.0255∗∗
(0.00721)

0.0304∗∗∗
(0.00504)

Front-Page Cites per Patent

4

5
0.0216∗∗∗
(0.00535)

0.0163∗∗
(0.00518)

6

0.0117∗
(0.00538)

Total Firm Patents

0.102∗∗
(0.0298)

0.107∗∗
(0.0294)

Fraction Scientists

0.625∗∗
(0.188)

0.643∗∗
(0.198)

-0.167∗∗∗
(0.0245)
614
0.145
1465.6
Yes

-0.170∗∗∗
(0.0256)
614
0.138
1470.9
Yes

Constant
34

Observations
R2
BIC
Industry Controls

-0.0295
(0.0505)
615
0.037
1534.0
No

-0.0287
(0.0530)
615
0.025
1541.6
No

-0.0454∗∗∗
(0.00245)
615
0.122
1470.4
Yes

-0.0433∗∗∗
(0.00211)
615
0.113
1476.8
Yes

Standard errors in parentheses
All regressions are firm-level OLS with s.e. clustered by industry; depvar is continuous factor in Roach and Cohen [2013]
∗
p < 0.05, ∗∗ p < 0.01, ∗∗∗ p < 0.001

Table A.2: OLS models relating stock market reaction to science references
VARIABLES
Number of front page science refs

(1)
Stock

(2)
Stock

(3)
Stock

0.02
(0.04)

0.10**
(0.04)
-0.004
(0.04)

0.10**
(0.04)

Number of full text science refs
Any front page science refs?

(4)
Stock

35

issyear = 2008
Constant

Observations
R-squared
Patent class FE
BIC

(6)
Stock

2.8***
(0.7)
1.5***
(0.1)
6.7***
(0.2)
8.3***
(0.08)

-0.7
(0.5)
3.2***
(0.8)
1.5***
(0.1)
6.7***
(0.2)
8.3***
(0.08)

199,986
0.126
Yes
1906298.57

199,986
0.126
Yes
1906307.13

0.3
(0.5)

Any full text science refs?
issyear = 2007

(5)
Stock

1.5***
(0.1)
6.7***
(0.2)
8.4***
(0.08)

1.5***
(0.1)
6.7***
(0.2)
8.4***
(0.08)

1.5***
(0.1)
6.7***
(0.2)
8.4***
(0.08)

1.5***
(0.1)
6.7***
(0.2)
8.4***
(0.08)

199,986
199,986
199,986
199,986
0.126
0.126
0.126
0.126
Yes
Yes
Yes
Yes
1906330.95 1906339.77 1906343.14 1906339.67
Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

Table A.3: OLS models relating whether maintained to year 8 to science references
VARIABLES
Number of front page science refs

(1)
Maintained

(2)
Maintained

(3)
Maintained

-0.002***
(0.0003)

0.001***
(0.0003)
-0.002***
(0.0003)

0.0006*
(0.0003)

Number of full text science refs
Any front page science refs?

(4)
Maintained

36

issyear = 2008
Constant

Observations
R-squared
Patent class FE
BIC

(6)
Maintained

-0.06***
(0.004)
0.0004
(0.002)
-0.007***
(0.002)
0.6***
(0.001)

-0.03***
(0.004)
-0.04***
(0.005)
0.0004
(0.002)
-0.007***
(0.002)
0.6***
(0.001)

489,346
0.076
Yes
661365.09

489,346
0.076
Yes
661328.82

-0.04***
(0.004)

Any full text science refs?
issyear = 2007

(5)
Maintained

0.0003
(0.002)
-0.007***
(0.002)
0.6***
(0.001)

0.0003
(0.002)
-0.007***
(0.002)
0.6***
(0.001)

0.0003
(0.002)
-0.007***
(0.002)
0.6***
(0.001)

0.0005
(0.002)
-0.007***
(0.002)
0.6***
(0.001)

489,346
489,346
489,346
489,346
0.076
0.076
0.076
0.076
Yes
Yes
Yes
Yes
661556.99
661525.07
661520.23
661408.7
Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

Figure A.1: Articles in Web of Science dataset across 244 journals by year.

37

Appendix B: Data Construction
We begin with a list of academic articles and patents. The patent data comes from the
publicly available USPTO Patent Application and Grant Publication Full Text files. These
files include the full text of the patent applications and grants, as well as bibliographic
information, including the application and publication dates, and the inventor names and
locations.
For articles, we begin with a list of the 20 most-cited journals in 16 fields, gathered
from Google Scholar. These fields are Chemicals & Materials, Nanotechnology, Biochemistry, Oil Petroleum & Natural Gas, Engineering & Computer Science, Artificial Intelligence, Robotics, Mechanical Engineering, Operations Research, Structural Engineering,
Sustainability Technology, Health and Medical Science, Biomedical Technology, Oncology, Physics and Mathematics, and Probability and Statistics. 26 of the journals on these
lists are duplicates, and 30 are not catalogued in Web of Science (largely ArXiv working series and conference proceedings), leaving 264 journals. Twenty further journals had very
few articles on Web of Science, leaving 244. Removing these leaves 244 unique journals,
listed in Appendix C.21
From this set, we gather metadata for list of articles from a predefined set of journals
from Thomson Reuters’ Web of Science, for all articles published between 1984 and 2016.
Second, we standardize special characters and drop ambiguous words from titles (e.g., the
chemical formula for Carbon-14, which can appear as 14 C, C-14, C14, and so on).22 Third,
we algorithmically construct a list of potential journal abbreviations using the full journal
title, the standard Web of Science abbreviation, and alternative abbreviations for common
words (algorithm available on request). For instance, the WOS abbreviation for the American Economic Review is Am Econ Rev, but patents also contain many references to Amer
Econ Rev, Amer Econ Review, and AER. Fourth, we take all paragraphs in the patent text
which contain a four-digit number from 1900 to 2017, and search indexed versions of those
paragraphs for a combination of metadata in any article in our sample as described below.
The most natural way to match is with a coarsened matching procedure. For instance,
in Marx and Fuegi [2019] or Ahmadpoor and Jones [2017], front page patent citations
are matched to scientific articles in this manner. The important difference is that front
page citations appear in one known line of text. Therefore, an algorithm can operate on
exactly that one line. In our case, citations appear in arbitrary formats throughout the
full specification text of patents, without a bibliography. It is often ex-ante non-obvious
where these citations might appear. We therefore need an algorithm that limits the space
of text to be searched, does not require the analyst to know ex-ante where a citation might
appear, and nonetheless makes few errors.
Patents are provided as xml files. A single line in this xml file may contain an entire
paragraph in the patent application text, hence a line may contain thousands of characters.
Investigating a subset of the files, we have identified that there are very few lines longer
21

We are planning to add 7 of these journals back following corrections to the algorithm, where the low
number of articles is due to a cataloging error on our part. The remaining 13 are generally new journals, or
conference proceedings only partially cataloged by the Web of Science.
22
Indeed, the exact format of titles of the same article in PubMed, Web of Science, and Google Scholar is
often completely different, largely due to how special characters are handled.

38

than 7000 characters in length; therefore, we have kept only the first 7000 characters of
each line in the xml file. Patents from earlier years are provided as text files rather than
XML, with a single paragraph divided into multiple lines; in this case we appended up to
10 consecutive lines to each other and treated them as a single paragraph. In the minority
of cases where a paragraph was divided into more than 10 lines, we split the paragraph
into subparagraphs each made of 10 lines.
Each line in the xml file starts with an xml tag identifying the information in that line.
Through investigation of a subset of the files, we have found that references are nearly
always included in lines with certain tags such as li and p. Therefore, we dropped the
remainder of the files, and kept only lines with these tags. The remaining portions of the
files also contain a minimal amount of citations, but investigation by hand suggests that
these are mostly repetitions of citations also made elsewhere within the same document.
Using the article list and the queryable patent text dataset, we now run the following
algorithm:

1) Eliminate any lines not containing the four digits of at least one year from 1986 to
2017. The underlying assumption is that when a journal article is cited, then its year must
exist in the citing paragraph.
2) From these remaining lines, to speed up the process of journal name lookup in
this still large search space, we create an index of the words contained in each line in each
file. In other words, we create word - line number - file number tuples, representing every
instance of where each word appears in which line of which file. This allows us to query
the index rather than perform operations on the direct xml and text of patents, which are
collectively over a terabyte of data.23
3) Identify lines that contain any of the journal names in our list of 244 journals. For
a given journal name, we take the words from the journal name that have two or more
characters, identify the word-line number-file number tuple set for each word, and take
the intersection of those sets. For example, for New England Journal of Medicine, we
intersect the tuple sets for the four words New, England, Journal, and Medicine.
For the purposes of this search, the journal list is augmented by various common
abbreviations of the same journal name, using the algorithm mentioned previously. For
example, to capture New England Journal of Medicine, many different abbreviations were
searched for, including the following: “NEJM”, “N.E.J.M", “N. Engl. J. Med", and “New
England J. Medicine". We now move from the journal level to the article level search.
4) Consider the lines that contain a given journal-year pair, recalling that “line” in
the patent files generally refers to paragraph of text. We search for the article first author
last name close to the journal name. Article title lengths vary across articles, and the full
title may be present in the citation. Therefore, we identify proximity to the journal name as
being within 150 characters plus the length of the article title before and after the journal
name location. We eliminate lines that do not contain the first authorâĂŹs last name or
23

We also considered dropping all paragraphs which do not include [, {, <li, “et al”, “et. al.” or <i. Doing
so modestly reduces the size of the file to be queried, and captures 99.9% of the citations we otherwise recover
in our primary algorithm. The speed improvement was minor, but researchers considering expanding our
algorithm to a larger journal list may wish to consider the speed-up.

39

the year within this proximity. In this step, we are only identifying the first citation to a
single journal within a single line. In other words, if two different articles from the same
journal are cited within a single line of the patent application, then we may or may not
capture the second one depending on how far apart it is located from the first citation. We
have no reason to believe that missing such citations would bias our results.
5) Among the matches identified so far, we keep matches that include either the
article page numbers or the first four words of the article in the proximity (i.e. within
150+article title length characters of the journal title).

Although the described algorithm can be applied to majority of the articles in our
set, we have applied some modifications due to foreign characters, punctuations, or data
quality issues.

6) Special Characters in the title: If the article title contains a special character such
as a punctuation, then we modify step 4. Instead of using the first four words of the title, we use the first four words without a punctuation and require at least five out of the
first six words to be present individually (i.e. instead of searching six consecutive words,
we search for each word separately, and check if at least five out of six exists within the
proximity). Note that if article page numbers match, then there is no need to resort to
this modification as the page number match will capture the citation in the original algorithm.24
7) Authors with multi-word last names: Some authors have last names consisting of
more than a single word. In these cases, we run the algorithm using only the last word in
the author’s last name.
8) Data Reporting Issue 1: For some articles from the WOS data, the article author
appears to be a study group or an institution. In these observations, unlike the rest of the
data, the author name is not a quoted string. For these observations we are not able to
use the author last name to conduct the match. So, instead of requiring the author last
name match in step 5, we change the condition in step 4 from an OR to an AND condition:
both title first four words AND the article page no have to exist within the patent line to
be considered a match.
9): Data Reporting Issue 2: Occasionally, for corrections and other errata, the WOS
data includes the original article’s “pageno” at the end of the title field. When both the
original article and errata page numbers are included in the patent, we count this as a
citation to both articles.

24
Umlauts and special characters in Author name: Some author names include foreign characters that
may be spelled in more than one way in the English alphabet. Therefore, we attempted the following three
changes in first author last names: ae into a, oe into o, and ue into u. We then repeated the algorithm with
the updated author last names. The rate of false positives this induces is high, but could conceivably be
manually handles: e.g., changing the name Xu to Xue, the rerunning algorithm, picks up a false positive.
This can perhaps be fixed in future versions with a dictionary of common names including special characters.

40

Any algorithm of this type needs to balance between Type I and Type II errors. In
this context, a Type I error is erroneously claiming the existence of a citation. Investigation by hand suggests that the matches identified by the algorithm contain less than one
percent Type I errors. A Type II error happens if the algorithm fails to identify an existing
citation. For instance, “In 1989 Stephan J. Weiss in the New England Journal of Medicine
conducted bacterial sensitivity studies on E. Coli and toxicity on tissue in guinea-pigs” in
patent application 12/101,775 is too vague, lacking both an article title and a journal issue
number, for our algorithm to match it with a specific article. The extent of Type II errors
of this kind is difficult to quantify. We investigated a number of less restrictive algorithms,
but generally they resulted in many more Type I errors with very few additional legitimate
matches. We discuss this further, with examples, in the following subsection.
Finally, when searching for front page citations, we use the exact same algorithm as
above. It goes without saying that a coarsened matching approach would generate fewer
false negatives on front page citations; however, for comparability of in-text and front-page
citations, it makes sense to use the most similar possible matching algorithm. Note that in
our first empirical exercise in the main text, we count both types of citations by hand, and
find a similar pattern of non-overlap.
It is difficult therefore to directly compare our algorithm to other matches of front
page citations. However, in our data, 274,082 patents have at least one front page cite. In
Ahmadpoor and Jones [2017], using a coarsened match of all 32 million post-1945 articles
in Web of Science to all post-1976 articles, they find roughly 759,000 total patents with at
least one front-page cite. That is, though we only use post 1976 pubs and 244 journals,
we nonetheless are capturing 36% of the front page cites in Ahmadpoor and Jones [2017].
Our match also finds roughly 267,000 articles with at least one citation, versus 1.41 million
in the longer and much larger dataset matched by Ahmadpoor and Jones [2017]. This
suggests that the journals we focus on include many of those which are most likely to be
cited by an inventor.

Some notes on matches our algorithm misses and catches
All matching algorithms balance between type I and type II references. Below are a
sample of in-text references which our current algorithm is unable to find.

1) Wrong author name: US6,190,856 has Erkki Koivunen cited as ”Kolvunen” in-text
(“Kolvunen, E. et al., J. Cell Biol. 124:373 (1994)”); US6,423,693 has a paper by Dominic
Wells as “Wells” correctly in front page but as “Walls” in the specification text (“Walls,
1993, FEBS Lett. 332:170-182”)
2) Wrong year: US6,130,090 has a Bradley and Liu paper as 1997 not 1996, when
1996 is correct; US6,143,551 has a Hauf paper with the year ”in press” but of course our
algorithm needs the actual year
3) Too vague: US6,008,016 just cites “Li et al” with no context or reference in
other part of the patent text (“THPs were purified from the resulting filtrate using
41

chromatographic procedures that are standard for the isolation of fish AFPs from serum
(Fourney et al., 1984; Li et al., 1985; Ng et al., 1986)”); US6,483,012 cites “Genomic DNA
was obtained from leaf tissue according to Doyle and Doyle (1987)” with no further detail.
4) Outright typos: US6,265,535 has year of one in-text citation as 19994 (“cells were
grown and differentiated into adipocytes as described previously (Garcia de Herreros et
al., 1989, J. Biol. Chem. 264:19994)”).
5) Wrong journal: US6,309,824 has a 1989 paper listed as being published in
”Genetics” when the actual journal is called Genomics; ironically, this particular article
was written by the inventor himself!
In our experience, typos are more frequent in-text than in prior art, partially justifying the assumption that lawyers are not too careful about checking in-text cites (e.g., a
citation to a paper by Paradkar in US5,914,367 is misspelt in-text but not in the front page
NPL).
On the other hand, our algorithm does correctly match a number of challenging intext citations. For example, in US6,605,754 (“Comai et al have previously described a
chimeric plant promoter combining elements of the CaMV35S and the mannopine synthase (mas) promoters (1990, Plant Mol Biol, 15:373-381)”, the reference is found despite
the author name Comai being very far from the reference, and no title being included.

Categorizing University, Medical and other patentees
We refer to an article as “medical” if it appears in a journal categorized as “Oncology”,
“Health and Medical Science”, “Biomedical Technology” or “Biochemistry” in the Google
Scholar journal rankings.
We refer to a patent assignee as “university-based” if the assignee contains any of a
series of references to universities or university-affiliated teaching hospitals. This list, also
used in Bryan and Ozcan [2019], is based on manual examination of patents in a large
number of languages.
“University” was a designation given to patents with any of the following in one
of their patent assignee strings: “university”, “alumni”, “ univ”, “national cancer”,
“brigham”, “jackson lab”, “research center”, “akademie”, “vib ”, “RIKEN”, “Eye & Ear”,
“medical school”, “national jewish health”, “eth zurich”, “Center for”, “univeristy”,
“higher education”, “cold spring harbor”, “akadamie”, “centre for”, “fundacio”, “Université”, “centre”, “planck”, “universuty”, “Universitât”, “fundacion”, “UNIVERSITÀ”,
“agence nationale”, “insitute”, “UNIVERSITÉ”, “eye and ear infirmary”, “Society for”,
“Unversity”, “cancer centre”, “universite”, “institue”, “istituto”, “cancer center”, “fondation”, “universiteit”, “universitet”, “universitaet”, “city of hope”, “educational fund”,
“zentrum”, “consejo”, “ecole”, “universtiy”, “centro”, “kettering”, “mayo”, “schule”,
“institucio”, “centrum”, “hospital for sick”, “children’s hospital”, “academisch”, “universita”, “universit´’at”, “unviersity”, “georgia tech”, “school of”, “consiglio nazionale”,
“intellectual properties”, “fondazione”, “national centre”, “centro nacional”, “centre national”, “foundation”, “regents”, “council”, “fred hutchinson”, “general hospital corpo42

ration”, “universidade”, “research hospital”, “medical center”, “foundation”, “universitat”, “universidad”, “colegio”, “univerisite”, “institut”, “institute”, “instituto”, “trustees”,
“academia”, “academy”, or “college”. These strings were picked following manual investigation in order to limit type I and type II errors, and attempt to capture academic research
hospitals as well as universities themselves.

43

Figure A.2: The distribution of front page and in-text citations per patent are both highly
skewed.

44

Appendix C: List of Covered Journals
Accounts of Chemical Research
ACI Structural Journal
ACS Applied Materials & Interfaces
ACS Nano
Acta Biomaterialia
Acta Mechanica
Advanced Energy Materials
Advanced Functional Materials
Advanced Materials
Angewandte Chemie-International Edition
Annals of Applied Probability
Annals of Applied Statistics
Annals of Biomedical Engineering
Annals of Oncology
Annals of Operations Research
Annals of Probability
Annals of Statistics
Annals of Surgical Oncology
Annual Review of Biochemistry
Antioxidants & Redox Signaling
Applied Energy
Applied Physics Letters
Applied Soft Computing
Artificial Intelligence
Astronomy & Astrophysics
Astrophysical Journal
Autonomous Robots
Bernoulli
Biochemical Journal
Biochimica et Biophysica Acta-Bioenerget
Biochimica et Biophysica Acta-General Subjects
Biochimica et Biophysica Acta-Molecular
BioEnergy Research
Biofabrication
Biofuels Bioproducts & Biorefining - BIOFPR
Bioinspiration & Biomimetics
Biomass & Bioenergy
Biomaterials
Biomechanics and Modeling in Mechanobiology
Biomedical Materials
Biomedical Microdevices
Biometrika
Bioresource Technology
45

Blood
British Journal of Cancer
British Medical Journal
Cancer
Cancer Cell
Cancer Discovery
Cancer Letters
Cancer Research
Cell
Chemical communications
Chemical Reviews
Chemical Society Reviews
Chemistry of Materials
Circulation
Clinical Cancer Research
Cochrane Database of Systematic Reviews
Composite Structures
Computational Mechanics
Computational Statistics & Data Analysis
Computer Methods in Applied Mechanics and Engineering
Computers & Industrial Engineering
Computers & Operations Research
Computers & Structures
Current Opinion in Structural Biology
Earthquake Engineering & Structural Dynamics
EMBO Journal
Energies
Energy & Environmental Science
Energy
Energy and Buildings
Energy Conversion and Management
Energy for Sustainable Development
Engineering Analysis with Boundary Elements
Engineering Applications of Artificial Intelligence
Engineering Failure Analysis
Engineering Structures
European Cells & Materials
European Journal of Cancer
European Journal of Mechanics A-Solids
European Journal of Operational Research
Expert Systems with Applications
FEBS Journal
FEBS Letters
Finite Elements in Analysis and Design
Free Radical Biology and Medicine
46

Gastroenterology
Global Change Biology Bioenergy
IEEE Robotics & Automation Magazine
IEEE Transactions on Biomedical Engineering
IEEE Transactions on Cybernetics
IEEE Transactions on Fuzzy Systems
IEEE Transactions on Haptics
IEEE Transactions on Industrial Electronics
IEEE Transactions on Neural Networks
IEEE Transactions on Neural Networks and Learning Systems
IEEE Transactions on Pattern Analysis and Machine Intelligence
IEEE Transactions on Power Electronics
IEEE Transactions on Robotics
IEEE Transactions on Sustainable Energy
IEEE Transactions On Systems Man And Cybernetics Part B, Cybernetics
Immunity
International Journal for Numerical Methods in Engineering
International Journal of Biochemistry & Cell Biology
International Journal of Cancer
International Journal of Energy Research
International Journal of Engineering Science
International Journal of Hydrogen Energy
International Journal of Mechanical Sciences
International Journal of Non-Linear Mechanics
International Journal of Operations & Production Management
International Journal of Production Economics
International Journal of Production Research
International Journal of Radiation Oncology Biology Physics
International Journal of Robotics Research
International Journal of Social Robotics
International Journal of Solids and Structures
JAMA - Journal of the American Medical Association
Journal of Applied Mechanics - Transactions of the ASME
Journal of Biological Chemistry
Journal of Biomedical Materials Research-Part A
Journal of Biomedical Materials Research-Part B
Journal of Biomedical Nanotechnology
Journal of Business & Economic Statistics
Journal of Canadian Petroleum Technology
Journal of Clinical Investigation
Journal of Clinical Oncology
Journal of Composites for Construction
Journal of Constructional Steel Research
Journal of Econometrics
Journal of Engineering for Gas Turbines and Power - Transactions of the ASME
47

Journal of Field Robotics
Journal of High Energy Physics
Journal of Intelligent & Robotic Systems
Journal of Machine Learning Research
Journal of Materials Chemistry
Journal of Materials Chemistry B
Journal of Mechanical Design
Journal of Nanomaterials
Journal of Nanoparticle Research
Journal of Nanoscience and Nanotechnolog
Journal of Natural Gas Chemistry
Journal of Neural Engineering
Journal of Nuclear Materials
Journal of Operations Management
Journal of Petroleum Geology
Journal of Petroleum Science and Engineering
Journal of Physical Chemistry C
Journal of Power Sources
Journal of Purchasing and Supply Management
Journal of Statistical Software
Journal of the American Chemical Society
Journal of the American College of Cardiology
Journal of the American Statistical Association
Journal of the Mechanical Behavior of Biomedical Materials
Journal of the Mechanics and Physics of Solids
Journal of the National Cancer Institute
Journal of the Royal Statistical Society: Series B (Statistical Methodology)
Journal of Thoracic Oncology
Journal of Tissue Engineering and Regenerative Medicine
Journal of Turbomachinery - Transactions of the ASME
Journal of Vibration and Acoustics - Transactions of the ASME
Knowledge-Based Systems
Lancet
Lancet Oncology
Leukemia
Marine and Petroleum Geology
Mathematical Finance
Mathematical Programming
Mathematics of Operations Research
Meccanica
Mechanism and Machine Theory
Mechatronics
Medical & Biological Engineering & Computing
Medical Engineering & Physics
Molecular and Cellular Biology
48

Molecular Biology of the Cell
Monthly Notices of the Royal Astronomical Society
Nano Energy
Nano Letters
Nano Research
Nano Today
Nanomedicine
Nanoscale
Nanoscale Research Letters
Nanotechnology
Nanotoxicology
Nature Chemical Biology
Nature Chemistry
Nature Genetics
Nature Materials
Nature Medicine
Nature Nanotechnology
Nature Photonics
Nature Physics
Nature Reviews Cancer
Nature Reviews Clinical Oncology
Nature Structural & Molecular Biology
Neural Networks
Neurocomputing
Neuron
New England Journal of Medicine
NPG Asia Materials
Nucleic Acids Research
Oil & Gas Journal
Oil & Gas Science and Technology - Revue D IFP Energies Nouvelles
Oncogene
Operations Research
Petroleum Exploration and Development
Petroleum Geoscience
Petroleum Science and Technology
Physical Review B
Physical Review D
Physical Review Letters
Physics Letters B
Proceedings of the National Academy of Sciences
Production and Operations Management
Progress in Photovoltaics
Renewable & Sustainable Energy Reviews
Renewable Energy
Robotics and Autonomous Systems
49

Robotics and Computer-Integrated Manufacturing
Small
Solar Energy
SPE Drilling & Completion
SPE Journal
SPE Production & Operations
SPE Reservoir Evaluation & Engineering
Statistics and Computing
Statistics in Medicine
Structural and Multidisciplinary Optimization
Structural Control & Health Monitoring
Structural Safety
Thin-Walled Structures
Tissue Engineering Part A
Tissue Engineering Part B-Reviews
Tissue Engineering Part C-Methods
Transportation Science
Trends in Biochemical Sciences
Tribology International
Tribology Letters
Vehicle System Dynamics
Wear
Wind Energy

50

