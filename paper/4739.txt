NBER WORKING PAPER SERIES

THE BAYESIAN FOUNDATIONS
OF LEARNING BY DOING

Boyan Jovanovic
Yaw Nyarko

Working Paper No. 4739

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 1994

We thank the C.V. Starr Center for Applied Economics at New York University for technical
and financial help, and Chung Tse for help with the research. This paper is part of NBER's
research program in Productivity. Any opinions expressed are those of the authors and not
those of the National Bureau of Economic Research.

NEER Working Paper #4739
May 1994
THE BAYESIAN FOUNDATIONS
OF LEARNING BY DOING

ABSTRACT
This paper explores a one-agent Bayesian model of learning by doing and technological
choice. To produce output, the agent can choose among various technologies. The beneficial

effects of learning by doing are bounded on each technology, and so long-run growth in output
can take place only if the agent repeatedly switches to better technologies.

As the agent repeatedly uses a technology, he learns about its unknown parameters, and
this accumulated expertise is a form of human capital. But when the agent switches technologies,

part of this human capital is lost. It is this loss of human capital that may prevent the agent from

moving up the quality ladder of technologies as quickly as he can, since the loss is greater the
bigger is the technological leap.

We analyze the global dynamics. We find that a human-capital-rich agent may find it
optimal to avoid any switching of technologies, and therefore to experience no long-run growth.
On the other hand, a human-capital-poor agent, who because of his lack of skill is not so attached

to any particular technology, can find it optimal to switch technologies repeatedly, and therefore

enjoy long-run growth in output. Thus the model can give rise to overtaking.

Boyan Jovanovic
Department of Economics
New York University
269 Mercer Street
New York, NY 10003
and NBER

Yaw Nyarko
Deparunent of Economics
New York University
269 Mercer Street
New York, NY 10003

Table of Contents

I. Introduction

1

II. Model....

2

III. The Transfer of Human Capital
a. The Human Capital Transition Equation
b. The Parente and LPSY Conditions.
c. Switching Constraints

3
7
11

IV. Myopically Optimal Time Paths in the "No Jump Case.

12

V. Myopically Optimal Time Paths in the "Full-Menu" Model

24

VI. Dynamically Optimal Policies in the No-Jump Model
a. The Basic Structure and Notation
b. Dynamic Paths for Small x and for large x

35
35
38
39
42

c. Dynamic Paths for large ö
d. Dynamic Paths for Small ô
VII. Positive Discount Factor in Full-Menu Model
Appendix
Appendix
Appendix
Appendix

1. The Proofs
2. Verification that all the CASES I-fl' are non-empty
3. Proof that the Conditions in Proposition 6.8 Rule Out Case IV
4. The No-Recall Assumption

46
46
62

68

References
List of Figures

Figure 1: The Mappings h1, h2 and h
Figure 2: LPSY Fails for Large x
Figure 3: LPSY Holds for all x
Figure 4: The Payoffs to Using the Current or the New Technologies
Figure 5: The Four Possible Regimes
Graph of Case hA
Graph of Case fiB
Figure 6: A Two-Period Cycle
Graph of Case LIlA
Graph of Case BIB
Figure 7: Full Menu Model in Case I
Figure 8: Full Menu Model in Case II
Figure 9: Full Menu Model in Case III
Figure 10: The g Functions

5

9
9
14

14
17
18
19
21

21

28
29
30
31

I. Introduction
This paper explores a one-agent Bayesian model of learning-by-doing and technological

choice. In thisframework, the more a technology is used, the more productive it gets. Once
the productivity gains on a given technology have been achieved, further improvement can be

had only by switching to a new technology.
After the switch, how useful an agent's prior experience will be on the new activity will

depend on how similar the new activity is to the old. In the Bayesian framework, this depends

on how correlated their respective uncertain parameters are. Information that is in this sense

transferable fits the notion of general human capital, while information about an unknown
parameter that is independent of other unknowns, is exactly like specific human capital.
Our model is like that of Parente (1991), but his formulation is not information theoretic,

and he, like Chari and Hopenhayn (1991). looks only at constant growth paths. The outcome
that in our model corresponds to steady-state growth is the situationin which the agent switches

to a new technology at equally-spaced intervals, and in which the size of the jump (measured
in vintages) is the same each time.

An agent can also get stuck in an old technology for ever, and experience no long run
growth in output. As in Chari's and Hopenhayn's model, each new technology dominates the
previous one at any given level of expertise of its users. The crucial difference is that here, the

more remote one's current knowledge is from "frontier knowledge", the less expertise one has

with the frontier technology. So, even though the frontier technology keeps getting belier,
expertise shrinks. Generally, this prevents the agent from upgrading his technology too fast.
And if successively better technologies differ enough in the type of expertise needed to operate

them properly, an agent will understand them so poorly that he will stick with the old one he

understands well. Paradoxically, the type of agent to whom this may happen is one that has
learned a particular technology so well that he will not switch to a new, untried one. Such an

agent may in the long run be overtaken by an agent that is initially less productive dn the
technology at hand, and who therefore is more willing to try a new one.

1

2
H. Model
A risk-neutral agent can produce a good with one of several technologies indexed by n

=

1, 2

If he uses technology n at date t, a decision z yields net output q via the

production functio&

q=

yft[1(yz)9.

(1)

Here ye,, is a random variable that acts as an unknown "target", and is observed after z is

chosen. Since y 1, a larger n denotes a better technology. Let E) denote the conditional
expectation at date t. The decision that maximizes E1(q) in (1) is

z=

E1(,y_)

(2)

.

The random target fluctuates around a technology-specific parameter O:

= o+w

(3)

.

The agent does not know O. He can observe y1, but only if at date t he uses technology n!

Assume that w is an i.i.d variate, with mean zero and variance o.

Since

E(w,) =

0.

equation (2) implies that the optimal decision is

This type of production function has been analyzed by Prescott (1972) and Wilson (1975).
2 The

information that the agent gets depends on what vintage he chooses to operate, but not
on the value of z. Therefore equation (2) holds even in a multi-period maximization problem.

3
=

z

(4)

E(O) ,

and (1), (3) and (4) imply that expected net output is

E(q) = yD l

—

—

Var1(00)

uj ,

(5)

where Var1() denotes the conditional variance. If he uses technology n, he also observes y

and learns more about O, which allows him to make a better decision z. This reduces
Var1(OJ, and raises his expected net output. However this learning process is bounded: Using

technology n forever allows the agent to learn O completely so that E(q) —.

-

which is finite for fixed n.

III. The Transfer of Human CapitaJ.
There is no direct cost of switching to a different technology, and no adjustment costs in z.
The only link between technologies is informational. Let

=

for all n, where

+ n+i

is an i.i.d. normal variate with mean zero and variance a2. If the agent

has not yet tried technologies n+ 1, n+2

Var1(O,1)

equation (6) implies that

= aVar,(8)

+

'4

.

(7)

The earlier equations in the model allow us to think of the posterior precision on O as

4
an index of human capital. Equation (6) adds a further dimension and lets us evaluate some
hypotheses that are connected to human capital — general and specific. If a = 1 and a

0 and °k is unity, for all k, which corresponds to
the case where human capital is general and freely transferable across technologies. But if a
= 0, the correlation coefficient between

= 0, human capital is technology-specific.
We choose the AR-i formulation in (6) to model the transfer of knowledge because by
varying a, we capture many types of evolution of technologies:

i.

When O<a< 1, note that the 0 process has a tendency toward zero;

ii.

When a=1 then

so the technology parameter tends to where it was in the

previous vintage.

iii.

When a> 1 then there is drift towards infinity.

Notice that a has the interpretation of a human capital transfer parameter. For let;'
denote the variance of the parameter 0. Then

from (6), o8+i'—aa02+oI. We may therefore

write aa+j'=czàan2 where Au? represents a "change in a,,." Hence a unit change in human
capital on technology n results in a units of change in the human capital on technology n+1.
We assume that the prior over O at date 1 is normally distributed. Eqs. (3) and (6), and

the normality assumptions made on wN imply that the posterior belief at each

date

over the

parameter of any vintage, 0, will also be normally distributed.
We define the following functions of x:

h1(x)

a2x/(a + x);

(updating)

h2(x)

ax+a42; and

(transfer of knowledge)

h(x) = h1(h,(x)).

(tmnsfer and updating)

These functions have the following interpretations: Suppose that vintage n is the newest
of date t and suppose the agent has a
vintage that the agent has worked with at the

posterior of ;, over O. Then h,(x.) is the agent's pjjg1 at date t over O.
agent

Suppose the

uses vintage n at date t+1. The agent will then observe y,1+1 after which the posterior

5

variance over vintage n becomes, via Bayesian updating, h1(x0J. Suppose instead that at date

t+l the agent chooses vintage n+1. The agent will then observe

The agent's posterior

variance over 0,.,' will then be LI(X,,J.
We define i to be the fixed point of the Li2 map. This fixed point exists and is unique

whenever a C
the h map.

1;

when a1 we take Ito be +.

We defme x1"' to be the fixed point of

Since h is as drawn in Figure 1 (i.e., since h(O)>O and h is bounded and

concave), x exists and is unique.

+
2

x

Figure 1: The Manninzs h1, Li, and h.

The following property of h will be used later: Suppose that at the end of date t the
agent has a posterior over a "status quo" vintage n equal to x0. Suppose further that at each
date he switches to the next technology. Then his posterior over the most recent vintage is given

by iterates of h from x0. That is, his posterior over 00+1 at the end of date t+1 is x1 =
h(x0),

the end of date t+k is the k-tb iterate of h, ; =
(k-times), and so on. For any ;, the sequence {xk}k_I converges

his posterior over 0a+k at

h(h(. . .(h(x0))

monotonically to xt.

a. The Human Capital Transition Equation. Several authors have discussed the question of
how human capital at date t depends on the nature of prior experience, and on the content of

6

previous human capital. The specific functional form implied by our model depends in a crucial

way on how we define things.

One way to think of this equation is in linking per unit productivity at date t+ 1 when
vintage n4-1 is being used for the first time, with the history of outputs from dates 1 through
t.

This is, formally speaking, the approach in Lucas (1993). Since in our model there is a

one-to-one relationship between productivity and variance this is equivalent to looking at the way

in which the variances at those dates relate to each other.

In our model the relationship is

Markov. The date t+ 1 variance of vintage n+l is a function of only the variance at date
of vintage n. In particular the date t variance of vintage n+1 is related to the history of the
variances of all previous vintages by the Markov relationship x11=h2(x,1).
An alternative way of thinking about the human capital transition equation is look for the

function linking the experience in previous vintages to the productivity on the current vintage.

This is the language Lucas actually uses. In particular suppose that at some date T, vintage 1

was used for the first r periods, then vintage 2 was used for the next 2 periods

and

vintage n-i was used for r1 periods. Then the human capital equation will have the
productivity on vintage n equal to a function of the numbers t through TD.1:
Variance on Vintage n =

x,=h2(l?' (h2(hT.2 (... h2(h' (x1))))),

(8)

where x1 is the initial date 1 prior variance over the date 1 status quo technology, and where.

via Bayes' rule
h17(x) = c1xJ[a2 + Tx]

(9)

gives the effect of r units of experience on the variance of a vintage.

We now show that a geometrically-declining weights model can be obtained as an
approximation of our model.Although in this exercise r is an integer, h( is defined for all r

in [O,oo). Now differentiate (8) with respect to; where h1t is as in (9). This differentiation

7
exercise asks: if we raise by a unit the experience level on vintage k, what is the effect on the
human capital level (or more appropriately, the variance of) vintage n?

dxjOrk = a.hiT (x,,.i).hT2 (x).. .h' (xJ,

(10)

where Xr is the argument of h17' in (10) above and denotes the variance of vintage r when vintage

r is just about to be used for the first time. Suppose that to a first approximation,

TkTk.1... =r,

and xk=xk+l=...=x(=x say).

Then from (9) . b1T(x) is equal to a constant, E say, for all r. So from (10) we obtain ôx,J3;

= (aE)°.

This in turn implies that, to a first approximation,

;=

r1,- (aE)°'r1

Hence the productivity measure for vintage a is a function of the experience levels of agents

with geometrically declining weights. This is of a form similar to that of eq. (4.7) of Lucas
(1993). We obtain the same general formulation as in Lucas if (aE)c 1. Here, however, aE
can exceed unity, in which case vintages further in the past have a stronger effect on today's

output than more recent vintages. This of course can happen only when a> 1.

b. The Parente and LPSY Conditions. Parente (1991) assm.i that when an agent switches

to jy other activity, his human capital depreciates, and the bigger is the jump the greater is the
fall in human capital. In our framework if x is the posterior varianceon the current technology
(vintage n, say) then h2k(x) (the k-th iterate of the function h2) is the prior variance over vintage

n+k. The depreciation of human capital is therefore given by

8

D(k) = h2k(x)x.

From figure 1 whenever x <1, D(k) >0 for all k= 1,2,... Further, D(k) is bigger the bigger
is k. Hence the Parente assumption is equivalent to the following:

Uefn: The Parente condition, or condition P. holds at x if xci.

If we define x_5t,then condition P holds at each
Lucas (1993), Parente (1991), Stokey (1991) and Young (1993) emphasize a different
condition - that human capital in some future vintage will be larger if today a higher rather than

a lower vintage is chosen. For example, suppose that N>n2>n1 and tomorrow an agent will
be using vintage N. Then human capital in vintage N tomorrow will be higher if vintage n1 is

used today than if vintage n1 is used. Surprisingly, this is not always true in our model. Fix
an n and

set n1 = n and n1 =n+ 1.

Consider two agents with the sante knowledge in the sense

that each has Var((Ofl) = x. We shall call them agent S and agent F (for 'Slow" and 'Fast"

resp.). Assume that in period t+ 1 agent S operates technology n while agent F operates
technology n+1. Which agent will be better prepared for technology n+2 in period t+2?

Well, let 5(x) (resp, $Ø))

be

the variance of agent S's (resp. agent F's) beliefs over O,+:

h2(h1(x)) and 4,(x)

h1(h2(x)).

DeEn: The Lucas-Parente-Stokey-Young, or condition LPSY, holds at x if 4i(x) > 4(x). We
also define XLpy = Sup {x0 the LPSY condition holds at x}.

When LPSY holds, agent F is better prepared for technology n+2 from x. The shapes

of the 4 and 4F functions and xy are illustrated in figures 2 and 3 below and described in the
lemma below. Surprisingly, we see that it is indeed possible for condition LPSY to fail.

9

w

I Ill III Ill

Ill Ill

II

22
+

UwUe

x

x

Figure 2: LPSY Fails for Lane x.

45

aa÷a
a
w

x

Figure 3: LPSY Holds for all x.

10

Lemma 3.t.
(I)

When iCc,), Ocx12< , the LPSY condition holds at each x<xL and is violated
at each XXLnY.

(ii)

When ia,),

and

hence in particular when

Xijy= and the LPSY condition

holds at each xO.

(iii)

£ c x1.

In particular the LPSY condition holds at each x

j.

We may refer to our earlier condition LPSY as a "one-step ahead LPSY," since it
involved comparisons of the use of a vintage n with a vintage n+ 1. Below is the "many-step"

ahead version - a kind of first-order dominance resultin vintage levels - which is implied by
condition LPSY:

Proposition 3.2. Suppose that at date 1 agents S and F both start from the same prior variance
that
over the initial date 1 status quo technology, and this obeys the LPSY condition. Suppose

at each of dates t= 1,2

T, agent S chooses a technology of lower (or equal) vintage than agent

F, and suppose that their choice differs at least in one period. Let N be any technology of
vintage greater than or equal to the maximum that any of the two agents have chosen by date
T. Then at date T+1 agent F will have more human capital (i.e., lower posterior variance) on
vintage N than does agent S.

From any given x, neither condition P nor LPSY necessarily holds. (See fig. 2).

However, part (iii) of lemma 3.1 means that Condition P implies Condition LPSY.
(Equivalently, xP,FCxWY.) The reverse claim, namely that condition LPSY implies condition
P. is false — as figure 2 shows.

In summary we see that if a C 1 and x is large both the Parente and the LPSY condition

fail. 1fa1 thenbothx andxequal sothetwoconditionsholdateachfiflitex. Let
us now pursue the Parente condition a little further. When x> I (which can only happen when

cx< 1) iterates of the h2 map from any x are decreasing. This means that the prior variances

11

over later vintages are decreasing the further out is the vintage. The agent has higher human
capital on vintages which are further away! This of course is precisely the meaning of the

violation of the Parente condition.

One may be dissatisfied with our framework because it allows for this potentially nonintuitive feature. However, in that case, it should be stressed that what one is really dissatisfied

with is the assumption that a < I and x is large. For note what this implies: When x is large,
the variance of e, a,1, is relatively small so for each n, O1=a"2O0 approximately. A large x
implies that O is large relative to its mean. Hence when a< 1,

is a fraction of O so with

high probability will be much smaller than O so will have a smaller variance. The assumption

that a< 1 implies that the process O1=a"2O+u42 has a tendency toward zero when the noise
term

is small. This explains the non-intuitive feature mentioned earlier. When a

1

the

process no longer tends towards zero and the non-intuitive feature (i.e., the violation of the
Parente condition) disappears. Further, although condition P does not hold for x >

i, the set

of beliefs [0, k] is in fact absorbing — starting from any initial belief in this set and following

policy implies that beliefs always remain in this set. Moreover, since x** is strictly less
than *, it is also easily shown that under io policy, starting instead from any initial beliefs
exceeding A, beliefs will enter the set [O,A] in fmite time, and remain in it thereafter.

(This

can be seen by observing the shapes of the h1, h2 and h maps and noting that the beliefs of any

vintage at any date are iterates of some combinations of these maps.)

c. Switching Constraints. We now study the dynamics of our model. There are at least three
interesting ways of constraining technological switches:

i.

(No Jump Model) The first is to assume that the agent can not skip intermediate
vintages when switching, so that if he wishes to advance from vintage n, he must use

vintage n+1 before he can use any higher vintage. We shall refer to this as the "No
Jump Case". This case is the easiest to analyze, but it begs the question of why it is
impossible to skip vintages when switching.

ii.

(Chari-Hopenhayn Mode!) The second type of constraint on switching allows jumps,

12

but only up to some frontier that advances exogenously. This is the case that Chari and

Hopenhayn analyzed. This switching constraint is only partially satisfactojy in that the
exogenous outward movement of the frontier, similar to the Solow growth model, is left
unexplained.

iii.

(Full-Menu Model) The third approach is to leave the choice of vintage unconstrained.

This is the approach that Pat-ente took, and we refer to it as the "Full Menu Case".
Although the rate of growth is endogenous in all three cases, only this third case is free
of any arbitrarily imposed constraint on the rate at which future technologies are chosen.

Section IV will cover the "No Jump Case", section V will take up the Full Menu Case",

and section VI reports results that relate the two cases. Both cases will be analyzed under the
following constraint:

The no recall constraint: Once a vintage has been passed over for a higher vintage, it is never

recalled. Hence an agent who chooses a vintage n at date t, can not choose a lower vintage

n' <n at any future date t' > t.
We prove in the appendix that, at least for the myopic and the two-horizon versions ofthe

model, it is actually pj optimal to ever exercise such a recall option.
IV. Myopically Optimal Time Paths In the "No Jump" Case.
This section analyzes the optimal behavior of a myopic agent who can upgrade his vintages only

one at a time -

the No Jump model.

Our reason for starting the analysis with myopically

optimal policies and time-paths is that first, they are the simplest to characterize, and that
second, they share similar broad features with dynamically optimal policies and time-paths.

At any date the agent has a status ouo technology - the most recent one that he tried.

Define the status quo technology for the initial period, date 1, to be vintage 1. At each date

13

there also is a frontier technology, one vintage higher than the status quo vintage. That is, if

the status quo technology is vintage n, the frontier technology is vintage n+ 1. We refer to
the decision to use the status quo technology as "NO SWITCH", and the decision to move to
the frontier technology as "SWITCH". At each date the agent must choose between the status

quo vintage and the frontier vintage. He can not recall vintages earlier than the status quo
vintage. "The variance of vintage a" will mean the variance of 9. At the beginning of date
1 the agent has a posterior variance x over vintage 1. This is his "prior belief" about vintage
one.
Define

t(x)
Once

1- x -

,

and

r(x)

yfi - ax

-

o?

- ai.

chosen, the optimal "organization" of a vintage is given in (4). Therefore when he has

a prior belief x over vintage n, y"t(x) is the agent's expected net output on vintage n, and
y°r(x) is his expected net output on vintage n+i. Let x denote his posterior variance over

O at date t. Let x" be the unique point where 1(x) crosses r(x); i.e., 1(x*) = r(x*).
The immediate gain to switching technologies is

A=

r(x) - t(x) = y-1 + (1-ay)x -

- (j).2

There are two parameters -- a and a12 -- that positively affect the depreciation of human capital
by raising the variance of 0 on the frontier technology, and each parameter indeed does reduce

a.

The

third parameter that reduces a is a_2. One certainly would have expected an increase

in this parameter to slow down the rate at which the frontier technology is learned, and therefore

to reduce the dynamic incentive to switch, but it is somewhat surprising that thisparameter

14

Expected Payoff

1-

2

lv
(x)

Ill
4ntagen payoff

x

" II

Figure 4: The Payoffs to Using the Current or the New Technolo2ies,

ya>1
1 -

1 -

2

a,

> y(l -

2

< 'y(l —

2

Ill

I

Initial Beliefs Affect
Long-Run Growth

Choose Old Vintage
Always
2
— a)

IV

II

Cycles or
eventually always switch

Figure 5: The Four Possible Re2irnes.

Switch to Next
Vintage at Each Date

15

should reduce the immediate returns too. The reason why it does so in our model is that the

amount by which a rise in u,2 reduces the expected output of a technology is greater for the
frontier technology than for the status quo technology. So the immediate and the dynamic effects

of a rise in a2 both work in the same direction.
When y increases, the effect on t is ambiguous. This is because a higher y raises expected

net output at lower levels of x, but it actually lowers expected net output at high levels of x.
An increase in y therefore raises the incentive to switch at low levels of x and lowers it at high
levels of x.
Finally, the effect of a rise in x on

is also ambiguous, and depends entirely on whether

ay bigger or less than unity. This condition determines whether high human capital (i.e., a tow
x) makes switching more attractive, and the answer is that it does

only if ay exceeds one.
When this condition is met, an extra unit of human capital raises output on the frontier
so

technology by more than it raises the output on the status quo technology. Whether this condition

is likely to be met in a given technological area will depend on how technologically linked the
successive vintages are -- this determines the magnitude of a. For example, if each generation

of computer chips is defmed as a different technological vintage, then because each generation

of chip builds on the previous one, a should be high.
With these remarks out of the way, we can now analyze myopically optimal paths.

There are lour regimes; the parameters determined which one will prevail. These regimes are

determine by whether ay is less than or greater than one, and whether r(O) is greater than or

less than 1(0). In Figure 4, the solid line is 1(x), while the dashed lines depict four possible

schedules for r(x).

(In all of this discussion we ignore the non-generic cases where ay= 1

and/or t(0)=r(0).)
Analysis of the Four Cases for the No Jump Myopic Model:

Case I (Agent is stuck at old vintage): In this case, 1(x) > r(x) for all x 0, so that
whatever the value of x at the end of date t, vintage n yields a higher expected profit than
vintage n + 1. He therefore chooses vintage n which causes ; to decrease. But, since 1(x)

16

> r(x) for all x, vintage n will remain preferred over vintage n+1 at date t+1, and indeed
in each subsequent period. Hence the agent will choose the older vintage n at each date, and

;• converges to zero.
Case IV (Agent always "switches"): In this case, r(x) > 1(x) for all x 0, so that whatever

the posterior variance, x, over the parameter 8, of y vintage a at the end of

date t,

vintage n+1 yields a higher expected net output than vintage a. Hence he will always switch
to the newest vintage at each date, and x converges to x"4'. Log output will then have a trend

on In y, and its deviations of around this trend will be i.i.d.

Case IT. In this case, x C x's' implies 1(x) < r(x). and x > x' implies 1(x) > r(x).
Suppose that at date t, the agent must choose between a status quo vintage n and a frontier

vintage n+1, and let ,ç, be his posterior over 6,.
First, let

> x". Then he chooses vintage n. He then sees y, which lowers his

posterior variance over O. He optimally uses vintage a until the variance over vintage n

falls below x, which it eventually must. Suppose that this occurs after r periods, at date

T = t+r. Since the posterior over O

is then less than x's, he chooses vintage n+I at that

date.

Second, let x, C x's. Then he chooses vintage n+1 immediately at t. This is
equivalent to the setup of the previous paragraph when r = 0 so that T = t. So from now

onwemaysupposethatweareatadate T with xa< P. with T=t+r, andwhere r
is an integer and may be zero.

To determine what happens in the subsequent periods, i.e., from date T+ 1 on. we

consider two sub-cases: P C x, and P > x'.

Case HA: x >

x

'7
(Use inferior technoloay for r

0 Deriods. then "switch" forever.)

Assume x" > x. We saw earlier that at some date T the agent will have a posterior, x,7,

over 8

smaller

than x". He then chooses vintage n+1, sees y+' and his posterior over

O÷ becomes x1,11 = h(x,). Since iterates of h converge monotonically to the x,
and ;T are less than x', so is
;11.1 is closer to x than Xa,T was. Since both

%(r(x)
9(x)

x
switch

stick

Graph of Case HA

;+L,T+I Hence, at the end of T+1 he switches to the frontier technology, n+2. Repeating
this logic we see that at each subsequent date he switches to the newest frontier technology.
To summarize Case HA: There is an integer
agent chooses the inferior vintage
technology at each date.

r

(which could be zero) such that the

n for r periods. Thereafter he switches to the frontier

l8
Case IIB:

x C x' ("Cycles")

r(x)

(x)

'C

switch

Graph of Case fiB

Again, at date T the agent's posterior over O

is X.,T C

xt. He then switches to vintage

n + 1, and the posterior over O+ is Xn+IT4I = h(x.4T). Since iterates of h converge

;T. If Xn+IT+l is still less than xt he
switches to vintage n+2, and ;+2.T+2 = h(x11) is even closer to x. He will keep
monotonically to x4"', this means that ;+IT+l >

switching until the posterior gets larger than x which it eventually must since iterates of h

converge to x.
He then begins to forsake frontier technologies and stays with the relatively inferior

vintage. But then we are back where we started in CASE II: he stays with the inferior
technology until its variance falls below x. He then switches to the frontier technology. He

then keeps switching to each latest frontier technology, the variance of which continually

increases towards xa and eventually exceeds x". So we get "cycling": The agent "sticks"
with an inferior technology for a while, then continually "switches" to the newest frontier one,
then "stays" with an inferior one for a while, then continually "SWitches" to the newest one, etc,

etc, ad infinitum.

An example with parameter values that satisfy the restrictions of case II is described in

19

figure 6. In this example, x" = 0.129, and therefore for any smaller value of x it is optimal to

SWITCH. In particular, this is optimal at the value x0 =

.0896. Having used the new

technology, say technology n+ 1 for one period, it remains optimal for the agent to use it for

one additional period, because h(xnj exceeds x, as shown in figure 6. But after two periods
of using technology n+ 1 • the agent's posterior variance on n+ 1 is once again ;, and so it

is now optimal for him to switch to technology n +2, where the whole process repeats itself,
and so on3.

h1(x)

h(x)

0.3

0-25

Di
0.15

0.1

0.05

0

0

0.03

0.08

0.08

0.12

0.16

0.13

0.21

0.24

0.27

0.3

x

x0-.0898 x'-.129 h(x0)a.139

Figure 6: A Two-Period Cycle.

The parameter values underlying this example were o = a2 = 0.25,

a = 0.75.

y=

1.54 and

20

Case III. In this case, x > x" implies t(x) C r(x) and x C x implies t(x) > r(x).
Suppose that at t, the frontier vintage is n+1, and the "staWs quo" vintage is n. Let ;,
again be the posterior over O•

First, let ;, C x. Then the agent chooses vintage n, sees y,

and

his variance on

O falls and therefore remains below x. Hence he uses vintage n for ever even though

vintage n+l is always available.

Second, let ;, > x.

Then he uses the frontier vintage n+1, and then sees y0+1.

Let x1 be the posterior over 00+1
on whether

remains

at the end of date t+1. What happens then depends

larger than x' or not. This in Wru depends on the map of h.

We need to consider two sub-eases:

x' (Beliefs affect lon2 run growth catastrophicallv.
x so that at t the agent switches to the frontier technolo'. Now ;++

Case lIlA: x C
Suppose x0. >

= h(xJ is closer to x than x, was. Since x1, and x exceed x", so does x111+1
= h(x0J. Hence at the end of date t+1, after using vintage n+1, he switches to vintage

n+2. Repeating this logic we see that if x,, > x, he will at each date switch to the newest
frontier technology.

To summarize Case lIlA: If initial beliefs are less than x, the agent chooses the
inferior technology at each date. But if they exceed x, he will at each date switch to the
newest frontier technology. This is a bifurcation or a catastrophe situation: radically different
long-run behavior occurs depending on whether initial posterior variance is less than or greater

than x4.

21

D(x)

switch

stick

Graph of Case lilA

P (x)

xx

stick

switch

Graph of Case TUB.

22

Case IIJB: x" > x'"' (Switch for r 0 periods then "stick" with a vinta2e).
Suppose that XflL > x". Since t(x1) C r(x,,j, the agent will then choose vintage n + I at
date t+l. The posterior variance of the agent is given by h, whose iterates from ;.
decrease

monotonically to x. Hence he switches to the frontier vintages for a finite number

of periods r 1, after which the posterior variance falls below xt. The date will then be
T = t+r and the vintage N = n+r will have just been used. But when x C x, 1(x) >
r(x), so he will prefer vintage N = n+r to vintage N+1 at date T+1. The posterior

variance on vintage N then decreases, and so remains below x". Hence he will use vintage
N at T+2 as well. Repeating this logic we see that he will use vintage N in each subsequent
period.

To summarize case JIIB: Depending upon the initial belief, the agent will "switch" to

a new frontier technology in each of a finite number of periods r

in the set [0, xt), then r = 0. Otherwise r >

0.

Afterthe r

0. If the initial belief is

periods, he will remain with

the status quo technology at that date (vintage n+r) forever thereafter. Hence there is some
initial "growth" in the vintages, after which there is "no growth" in the vintages.

Summary of all the Cases.

We now list the types of behavior that arise, roughly in increasing order of long-mn
growth rates. At the extremes, staying with the oldest vintage is the "slowest growth rate" while

always switching is the "highest."

Case I

"Stick" to an old vintage forever.

Case TuB

"Switch" for r

Case LIlA

Beliefs affect long run growth. When initial posterior variance is low
agent is stuck with initial old vintage; when initial posterior is high, he
switches to the frontier technology at each date.

Case JIB

"Cycles." Stay with a technology for a finite number of periods, then
continually switch to the frontier technology at each date for a finite
number of periods, then stay with a technology for a finite number of

0

periods then "stick" with a vintage.

23

periods, etc.

Case hA

Use inferior technology for r

0 periods then "switch" to frontier

technology at each subsequent date.

Case IV

Agent always "switches" to the frontier technology at each date.

Discussion of the Results.
Cases I and IV are straightforward. In case one, new vintage technologies do not represent

an improvement that is big enough to offset the loss of informational human capital that
switching to them entails, and therefore there is no switching, and no growth. In case IV,
exactly the reverse is true.
Cases

II and Ill, on the other hand, are a mix of cases I and IV in the above sense. At some

levels of human capital, a switch pays, and for others it does not. Case II obtains when it is the

human capital-rich agent that will switch, white in case Ill it is the human capital-poor agent that

will do so. The latter is perhaps counter-intuitive in that human capital is usually thought of as
being conducive to growth.

The most complicated dynamics arise in case JIB where cycles occur. We have illustrated
a two-period cycle in figure 6, but we have not ruled out other more complicated ones. The most

interesting, substantively, is probably case lIlA. Here, small differences in initial beliefs can
have huge effects on long run outcomes, and perpetually widening inequality can arise among
agents that are initially not too dissimilar.

24

V. Myopically Optimal Time Paths in the "Full-Menu" Model
In section III we remarked that there were three possible switching constraints one could impose.

In the previous section we analyzed the first of those switching constraints - the NO JUMP
model, where the agent may only choose between vintage between n and n+l. The NO-JUMP

model is the most restrictive of the three switching constraints defined in section 3. We now
study the 'full-menu" model where at each date the agent may choose between a vintage n and

and where j is referred to as the jump size. All technologies are
vintages n+j for j = 1,2,3
therefore always available, and the agent is aware of their existence, even though he may
understand most of them extremely poorly in the sense that he may know virtually nothing about

the relevant 0's. The full-menu model is the least restrictive of the switching constraints of
section III.

Terminology and Assumptions. Recall the definition of h2 in section III. Fix any date and
refer to the status quo vintage at that date as vintage 0. If x is the posterior variance on the
status quo vintage then h1(x) is the prior variance on vintage 1. The k-th iterate of h2 from x,
i.e., h2k(x), gives the prior variance on vintage k.

Define G(x,k) to be the return from initial posterior variance x when a jump of size k
is chosen. Note that G(x,O) is the return to choosing the status quo vintage and is equal to what

was earlier referred to as e(x). G(x,l) is the return to switching to the next vintage, with a jump

of one; it is equal to what was earlier referred to as r(x). It should be easy to verify that

G(x,k) = y"[1-a2-h(x)] and

= yk[l_aZkx.hik(0)]
where h2k(O) is the k-th iterate of h2 from 0 and where h20(x)=x.

To make the problem interesting we shall impose the following assumptions:

A.!

la,,,2>O.

25

A.2. 1-cç-2CO.

If A. 1 is violated the return in each period, regardless of the jump size, is negative. The
surnof expected discounted returns will then be negative regardless of the strategy chosen. A. 1

rules this out. Condition £2 states that as the agent upgrades his technology, his human capital
depreciates fast enough to prevent him from attaining an arbitrarily large net output by choosing

a large jump size. Indeed, suppose that A.2 is violated and in particular that 1-a,2-k>0. Since

i is the fixed point of the map h2, from i iterates of h2 remain at 1. The return to a jump of

size k from initial posterior k will be yk(1.at.h?(k)] =7k(10jj -. oc as k-soc. Hence when
£2 is violated it is possible to choose a jump size to obtain arbitrarily high return. Even the
myopic problem is not well-defined that case. Condition A.2. together with A.!, ensure that
the myopic problem is well-defined. (We will later on impose additional conditions to ensure
that the infinite-horizon problem is also well defmed.)

From assumption A. 1, G(0,0) = 1-ç >0 so there is at least one integer k such that
G(O,k)>0. Now h2k(O) converges inonotonically from below to i as k—c'. Hence from A.2,

there exists a unique K< oc such that 1-a2-h?(0)>0 for all kK, and

for all

k>K. In particular, G(0,k) is positive for kK and is non-positive for k>K. Since h2t(0)
is monotone non-decreasing in k,

1-a2-h21(0) >0 1-a2-h2"''(0)> .. > l-cç1-h2'"(0)> 1-ci2-h21"'(0)> - . Since -y>

1

this in turn implies that

0 G(0,K+1)> ... > G(0,K+j) > G(0,K+j+1)> ...
For each k= 1,2

(11)

G(x, Ic-!) and G(x, Ic) are linear in x and have slopes which are

respectively (a-y) and (a.y)k.

Hence

so long as ay 1, the two functions will have an

intersection point (which may be negative). Define Xk to be the point of intersection of the two

26

functions of x, G(x,k-1) and O(x,k); i.e.,

a

the

unique x such that G(x,k-1)G(x,k).

Notice that x is what in the NO JUMP model we referred to as x".

The Optimal Myopic Policy.
Recall that CASES I-IV were defmed in section IV. The optimal policy functions for these cases

in the NO JUMP model are as in fig. 4. We now provide, in the propositions below and in
figures 7-9, the equivalent in the full-menu model. The reader may find it useful to compare
fig. 4 with the corresponding figures 7-9. (As in section IV we ignore the knife-edge situations

where either ay=1 or r(O)=t(O).)
Proposition 5.1. (CASE I). Suppose that we are in CASE I. Then the payoff functions are
as in fig. 7. In particular, G(O.k)>G(O,k-l-1) for all k. Hence the optimal myopic action is

to choose a jump size of zero (i.e., NO SWITCH) at each date from each initial pdsterior
variance.

Proposition 5.2. (CASE H). Suppose that we are in CASE II. Then the payoff functions are

as in fig. 8. In particular, there exists an integer ME{1 K} such that
I.

G(O,O)<G(O,1)<... <G(O,M); and

ii.

G(O,k)G(O,M) for all k>M.

iii.

The following jump sizes are optimal for the myopic problem from initial posterior

variance xO:

iv.

a.

choose jump size 0 (i.e., action NO SWITCH) for x in [x1,);

b.

jump size m if xE[xmti*.x_*] for some m=1,2

c.

jump size M if xE[O,x1,]. So,

The agent will never choose a jump size greater than M.

M-1; and

27

Proposition 5.3. (CASE ifi). Suppose that we are in CASE Ill. Then the payoff functions are

as in fig. 9. In particular,
I.

G(O,k)>G(O,k+1) for all kO; and

ii.

x<xL*cx2*<...,andlml...Sxk=co.

Hence,

iii.

the optimal myopic action from any xO is to choose a jump size k=O,1,2

where

k is any integer such that xE[xk*,xk+Ii (where x0teO); and

iv.

for any x and x' with xx

the optimal myopic jump size from initial posterior

variance x is no less than the optimal myopic jump size from initial posterior variance

Proposition 5.4. (CASE IV). Under assumption A.l CASE IV can not occur.

28

0(0,0)
0(0, 1)

0(0,2)

.
0(0, P9

x

0(0, K + I)

0(0, K + 2)
G(x. 0)

3(0, K + 3)
S
S
S

30c I)

Figure 7: Full Menu Model in Case I.

29

0(0,m)
G(O,ru-I)

0(0,m-2)

.

0(0,1)
0(0,0)

a(0,Iq
x

xl
0(0, K + I)

0(0, 1< + 2)

0(0, K -+ 3)

G(x, m -2)

G%m)

GQc,m•l)

0(x, K 4 I)

.0(x,K+2)
0Cc, K +3)

Figure 8: Full Menu Model in Case II.

30

0(0,0)
0(0,1)
0(0,2)

0(0, K-I)

G(0, ig

xIc+I XKfl Sc.,

G(O, K +

I'

1)

6(0, K + 2)

0(0, K + 3)

GQçl)
OCXC)

— I)

Figure 9: Full Menu Model in Case III.

31

Dynamics in the Myopic Full-Menu Model

Define for k1,

g(x) a h1(h(x)).
An agent with initial posterior variance x who chooses a jump size k will after using the new
technology have a posterior variance of &(x) over the new status quo technology. The map h1

is concave while h2k is linear so g(x) is concave in x. It is clearly increasing in x. Further,

g(O) >0. Further, since h1(x) a,2, g(x) o,, for all x. Hence &(x) has a unique positive
fixed point which we shall refer to as xk**. Note that what we referred to in section IV as xt

is what we are now referring to as x1.
Lemma 5.6: i.

Xk**<Xk+1**

forallk1;

and ii.

=

h1(k).

Corollary 5.7.: From any x > h1(k) the posterior variance of the status quo technology in the
next period will be less than x.

45°

x

Figure 10: The 2.. Functions.

32
We now describe the dynamics in the full-menu model using the classification of CASES

that was used in the NO JUMP model. Our results will be very similar to the results in the
analogous cases. We state our results in a collection of propositions. The proofs should be
obvious from the figure (fig. 7-9) of the optimal policy corresponding to the case.

Proposition 5.8. (CASE I). Suppose that we are in CASE I. Then the optimal myopic action

is to choose a jump size of zero (i.e., NO SWITCI-l) at each date from each initial posterior
variance.

Proof: Follows immediately from fig. 7. •
CASE hA': x1 <x11 ("eventually always choose positive jump size")

Recall that what we referred to in the NO JI.JMP MODEL as x' (resp.x**) is what we now refer

to as x1
** <x1

(resp.

. In

x1**). In the NO JUMP model we referred to CASE HA as the case where

the NO JUMP model we showed that in this case eventually the agent will always

choose to SWITCH. We now impose a condition slightly stronger than this. In particular, let
M be as in Proposition 5.2 (or fig. 8); we assume that XM'C x1".

If M= I then this condition

is the same as what was previously called CASE HA. It is a stronger condition when M> 1.
We shall call this stronger condition CASE HA' to distinguish it from the previous condition

in section IV. Under this condition we shall show that the agent will (for all but perhaps
finitely many periods) choose in each period a jump size greater than or equal to one. Hence
we obtain a result in the same spirit as the analogous case in the NO JUMP model. However.
whereas in the NO JUMP MODEL eventually the jump size is exactly one, here eventually the

jump size is at each date greater than or equal to one and may vaiy over time. Formally we
have the following:

Proposition 5.9. (CASE HA'): Suppose that we are in CASE HA' (i.e., x,4**<x1*). Then
for all but possibly finitely many periods the agent wiu choose at each date t a jump size which

is greater than or equal to one (and may depend on the date). In particular for all but perhaps
finitely many periods, the action NO SWITCH will not be chosen.

33

CASE 11Th x15<X15 ("Cycles")

What was in the NO JUMP model referred to as CASE JIB is the situation where x1<x1.
In the NO JUMP model the dynamics were characterized by "cycles." We now show that

under the same condition we obtain cycles in the Full menu model as well. The only difference

is that whereas in the NO JUMP model the cycles are between NO SWITCH and jump size 1,

the cycles in this case will be between NO SWITCH and jumps of sizes j 1.

Proposition 5.10. (Case HE):

Suppose that we are in CASE HE (x15<x155). Then the

dynamics are characterized by cycles: In particular, the action NO SWITCH is chosen for some

time, then the agent decides to choose positive jumps for a while (with possibly time-varying

jump sizes greater than or equal to one) then NO SWITCH is again chosen for a while then
positive jumps occurs for a while, etc.

CASE lIlA: XIS <x1° (Beliefs affect long run). We now impose the condition used in

defining case lilA in the NO JUMP model: x15<x155. In the NO JUMP model we obtained
the conclusion that beliefs matter catastrophically.

in particular, in the NO JUMP model for

initial posterior variance x in [O,;J it is optimal to choose the action NO SWITCH at each date

while for x in (x1*, ) then it is optimal to SWITCH (or jump size one) at each date. Under
the same condition we shall show that in the FULL MENU model a very similar result is

obtained: for initial posterior variance x in [O.x15] it is optimal to choose the action NO
SWITCH at each date; and for x in (x15,00) it is optimal to choose a jump size, j, greater than

or equal to one at each date.

Proposition 5.11. (CASE WA): Suppose that we are in CASE mA. (I) If the initial posterior
variance lies in [O,x,j the optimal action is NO SWITCH (or jump size of zero) at each date.

34

(ii) lithe initial posterior variance lies in (x1*,oo) the optimal action is a jump size of one or
greater at each date (with the size of jump possibly dependent on the date).

CASE 1MB': h1(*) <XIS (Switch for r periods then "stick" with a vintage).

Recall that CASE 11Th in the NO JUMP model was the condition that XI**<XI*. We now
define a stronger condition and refer to this as CASE TUB': h1(k)<x15. Recall from lemma 5.6
that Xk55 converges from below to x,. =h1(i). Hence case IIIB' is the condition that

lim,L.ext**<xI* and is in general stronger than CASE TUB, x155<x,5. For the NO JUMP

model in case fuR we showed that for all but possibly finitely many periods the agent will
choose the action NO SWITCH. The posterior variance therefore converges to zero. We shall
show that in the full-menu model the same result is true under the stronger condition of CASE
111W.

Proposition 5.12. (CASE 11Th'): Suppose we are in CASE TUB' (i.e., h,(i)<x1).
(I)

From (x1*.) the posterior variance of the agent will enter the set [0,;'] in finite time.

(ii)

Once the posterior variance is in the set [0,;'] the optimal action is to choose jwnp size
0 (or action NO SWITCH) in each and every period.

35

vi.

DynainicaHy Optimal Policies in the No-Jump Model.

We now treat the case where the future matters, and in particular the agent's discount factor

is positive. We will begin with the No-Jump model. We show that optimal policies exist, and

are stationary in two senses: First, they do not depend on calendar time, and second, whether
or not the agent holds on to his current (status quo) technology or switches to the next vintage
does not depend on the numerical value of the vintage, in other words, whether or not the agent

stays with vintage n or switches to n+ 1 depends only on his beliefs about vintage n, and is
independent of the numerical value of n. We then characterize the dynamics under the positive
discount factor assumption.

a. The Basic Structure and Notation.
At any date t the agent will have a history of previous vintages chosen and the observations

associated with their use. A oolicv is a sequence r =

where

; maps the initial date

o variance and the observed history at t into a date I decision SWITCH or NO SWITCH.
Fix a policy ii-. Let m(t) be the vintage chosen at t under r. At the start of date

t+ I the agent chooses between the status quo vintage in(t) and the frontier vintage m(t) +

1. If the policy prescribes the action SWITCH at date H-i then m(t+1) = m(t) + 1; and
if the action is NO SWITCH then m(t+1) m(t). The agent has a discount factor 6 in
(0,1). From initial posterior variance x, a policy r generates a sum of discounted expected
payoffs given by

V1(x) = g,.1°'ot'f'°(l

- Var1
O$)

- a1)

where

Var1

O=

-

I x, r]

,

(12)

36

the variance of O) under the agent's initial belief and policy r, which has expectations
operator given by ft I x,r] with initial posterior variance x over U. We let P denote
is

the set of all policies. A policy ir is said to be optimal if it attains supremum of SUPrit VT(X)

forall

x 0.
From initial posterior variance x=x'", the strategy of switching in every period results

in a sum of discounted net outputs equal to r(xt4)/[1-yâ] whenever 6<1/7 and is infinite
whenever 6 iJy. To ensure that the sum of discounted payoffs in (12) is bounded, we impose
the following

bound on the discount factor: 6 < 1/y.
Implicit in the Bayes' rule mapping is the following bound on the variances over time.

Fix any initial posterior variance over the status quo vintage in the first period. If the agent
decides NO SWITCH in the first period then the posterior variance of the status quo vintage
becomes h,(x). If the agent decides to SWITCH then the status quo vintage becomes vintage

2 and will have a posterior variance given by h(x). More generally, the future posterior
variances of the status quo vintage at that date will be given by iterates of the maps h1() and
h(S). The precise order and number of the iterates depends upon the decisions, SWITCH or NO

SWITCH, chosen by the agent. Since h1(x) x for all x, iterates of the map h1 cause the
posterior variance over the status quo vintage to fall. We defmed earlier x4' to be the fixed
point of the h mapping and indicated that iterates of this map converge inonotonically to x.

If x1 is the date 1 posterior variance over the date 1 status quo technology, vintage 1, then

it should be clear that any number of iterates of h and h1 from x1 will be bounded above
by the maximum of x1 and x. In particular, we obtain the following bound on the posterior
variances over time:

Var O

Max {x1, x**) for all t.

37
Next we show that optimal policies exist by casting our model into a standard dynamic

programming framework. The action space is (SWiTCH, NO SWITCH}. Under the no recall
assumption stated at the end of section III, the state variable is the pair (ii, x) made up of the

vintage, n, of the current status quo technology and the posterior variance x over the
parameter 0,, of the status quo technology. The transition function from the date t state
variable (n, x) space and the action "SWITCH" or "NO SWITCH" into the date t+1 state
variable - either (n+1, h(x)) or (n, h1(x)) - is continuous since h1 and h are continuous.
Hence standard dynamic programming arguments ensure the existence of an optimal policy under

our boundedness assumptions.

When technology n is the status quo technology, the payoffs to any policy are
proportional to if. This means that the optimal policies will not depend on n, and that the value

of the optimized objective will be proportional to if. This is the content of the next lemma.
Let V,(x) be the value, under the optimal policy, of the sum of discounted payoffs when

the status quo vintage is vintage a.

Proposition 6.1 (Stationarity)
(1) The optimal policy may be chosen to be independent of the numerical value of the status quo

vintage and to depend only upon the variance of the status quo vintage.
(ii)

V1(x) = yV(x).

Proof: Obvious.
Under this proposition, V,(x) = y1V1(x) for all n. Let V(x) denote V1(x), the value
function in the "first" period, when the status quo technology is vintage one. Defme

L(x) a

1(x)

+

SV(h1(x))

and R(x) a r(x) ÷ &yV(h(x)).

L(x) (resp. R(x)) is the sum of discounted payoffs when the initial posterior variance over
vintage 1 is x, when the action NO SWITCH (resp. SWITCH) is taken at date 1 and from

38

date 2 onwards the optimal decision is chosen. The functional or Bellman equation is:

V(x) = Max {L(x), R(x)}.
We now have the following:

Proposition 6.2 (Convexity). L(x), R(x) and V(x) are each downward-sloping, convex and
continuous in x.

b. Dynamic Paths for Small x and for Large x.

In cases H and IV, for low values of x it is myopically optimal to switch, as shown in

Figure 4. The proposition that one may have hoped to prove is "whenever it is myopically
optimal to switch (i.e., whenever r(x) 1(x)) then it is also dvnwnkally optimal to switch." The

next proposition proves a somewhat weaker claim, but one that is in the same spirit.

Proposition 6.3: Fix any initial posterior variance x and suppose that r(x) 1(x) and x 1.
Then from x the strategy of choosing the action NO SWITCH at th

is g optimal. In

particular there exists an x' E (O,x) such that from x' the optimal action is SWITCH.

All that this proposition is ruling out is the possibility that the agent chooses action NO
SWITCH at fQcfr

It however allows for NO SWITCH at some date so long as the agent

also chooses SWITCH at some other date. A stronger claim however is true when x=O:

Corollary 6.4. Suppose that r(O)t(O). (Note that this occurs in CASES Hand IV.) Then
the optimal action from x=O is SWITCH.

Remark:

It should be clear from the proof of Corollary 6.4 that the corollary can be made

to hold even when r(O) <1(0) so long as r(0) is not "too much smaller than" 1(0). By

39

continuity, the action SWITCH is taken in a neighborhood of x = 0.

The previous two results provide some insight into the dynamics for small values of x,

the initial posterior. We now say something about the large x situation. The next proposition
follows from a property illustrated in figure 1: h1 and h are both bounded above by a2. This
means that the informational value of current decisions is bounded. And since the current payoffs

are unbounded as x gets large, this means that for large enough x, current considerations will
dominate relative to future ones, and they alone will determine the optimal action. This is the
content of the next proposition, although it should be taken with some restraint since for large
x the value function is negative so perhaps production will not even take place!

Proposition 6.5: Fix a discount factor 6>0. There exists an 1>0 sufficiently large such that

i

for all x > the optimal action for the infinite horizon 6>0 problem is the same as that of the
myopic problem.

c. Dynamic Paths for Large S
When the discount factor gets large, the critical feature of the model becomes the value of

r(x**). Since x** is the limit of x for an agent who switches technologies in every period,
this means that if an agent switches at the maximal rate, this policy will sustain a positive net

output oniy if r(x**) is positive. In this case, a policy that maximizes the rate of growth will
indeed be optimal for large enough discount factors, and this is the content of proposition 6.6.
But when r(x**) is negative, switching at the maximal rate yields negative long run net

output, and can not be optimal. To sustain positive long-mn output, the agent must pause after

switching, at least occasionally. Corollary 6.4 implies that it may not be optimal to pause
forever, in which case there will be cycles (in the same sense as case UB), and this is the content

of proposition 6.8.
It is straightforward (but tedious) to show that

40

r(x**) =

0

=

as

1

-

(l+a)u2 + aa.,1.

In particular, r(x**) can be either positive or negative depending upon the values ofa, °? and
Mf2

Proposition 6.6: Assume that r(x**) > 0.

Fix , 2 <

Then there exists a 6 in
(0, l/y) such that for all 6€ (6,1/y), the optimal action from any initial posterior variance

x in [0, 9

is SWITCH.

The restriction that r(xt)

0 can in fact coexist with all six cases: I, HA, JIB, lilA,

HID, and IV. That is, the set of parameters for which r(x**) 0 has a non-empty intersection

with each of the six subsets of the parameter space. Appendix 2 reports six combinations of

parameters, one for each of the six cases, each of which satisfies the restriction r(x**) 0.
This means that when r(x**) is positive, optimal policies behave very differently when 6 is

large compared to how they look when 6 is small or zero. When S is small, continual
switching is optimal only when we are in case IV, whereas when S is large, switching is

optimal for all parameters satis'ing r(x**) 0.
One of the differences between the myopic model and the dynamically optimal (i.e.
positive discount factor) model is the following. In the myopic model we have:

Proposition 6.7: For the myoDic model the agent's expected output is an increasing function
of time.

The proof of this proposition is the following: Suppose that at date t the agent chooses

a vintage ii and obtains an expected output level of Y1. At date t+1 if the same vintage n is

chosen, since the agent will have better information on it, the output level from the use of

41

vintage n at date t+1, Y'1+1 say, will be higher than Y1.

For the myopic model, at date

t+1 the agent will only choose a vintage different from vintage n if that vintage yields a higher
expected output.

This means that the date t+l output level can not be less than Y'1÷1.

Combining these arguments shows that

Y1.

In summary, for the myopic model an

agent either sticks to the same vintage (which because of declining variances results in higher
expected output) or switches to another vintage if that vintage results in a yet higher expected

output. In either case expected outputs must rise over time.
This is not the case when the discount factor is positive. In particular, in the positive
discount factor model an agent may sacrifice current output in order to attain experience with
a better vintage. This is an important difference between the positive discount factor and zero

discount factor models. We now illustrate this possibility with the aid of Proposition 6.6.
Suppose that r(x**) >0. Choose the discount factor sufficiently large so that Proposition

6.6 holds from all posterior variances x Ct. In particular for such a discount factor it will
be optimal for the agent to SWITCH at each and every date from any beginning of period

posterior variance x C4. Consider an agent who begins with initial posterior variance on
the status quo vintage, vintage 1, equal to zero. Under the optimal policy the dates one and
two expected output levels will be

y1 = y[1-a2-a,11 and

Y2 = y2[1-cç1-ah1(a2)-a9.

Define

It is easy to verify that for <y, y1 > y2. In particular as long as the parameter is not too
large, for this agent the optimal strategy will initially result in a reduction in output over time!

Of course these declines in output can not persist over time. Indeed, let Y, denote the

date t expected output and let ; denote the date t posterior variance of vintage chosen at date

42
t. Then the difference in expected output levels is given by

-

Hence

= yr(x11) - r(x.,)

-. (y-1)r(x) > 0 as t-. .

in the limit the expected output, 'Y, increases at the rate .
We provide a result which shows what may happen when r(x**) <0.

Proposition 6.8: Suppose that r(0)> 1(0)

r(x**) < 0. Then there exists a 6 in (0,

1/y) such that for all ôE(ô,1/y), from any initial posterior variance, the process of actions of
agents will be characterized by cycles: The agent will choose NO SWITCH for a while, then
SWITCH for a while, then NO SWITCH for a while, etc.

Proposition 6.8 assumes the restriction r(0) >1(0), which rules out cases I and ifi. The

additional restriction r(x**) < 0 also rules out case IV. This last assertion is proved in
Appendix 3. After an extensive computer search, we suspect that these restrictions also rule out

case hA, although we have not proved this claim. We do know, however, that the restrictions
hold on a non-empty subset of parameters satisf'ing case UB. A point in this subset is the vector

(a2 = 0.5, a2 =

0.28,

a=

0.9,

y = 2.3). Therefore, as far as we can tell, Proposition 6.8

applies only to a subset of case ILk, and here the outcome is 'cycling" for large 6 just as it
was for small 6.

d. Dynamic Paths for Small 6
If the discount factor is strictly positive but small, one would expect that the dynamically

optimal policies and time-paths will resemble the myopically optimal ones. This section shows

that this is indeed so.
To avoid uninteresting details, in the proposition below we suppose that the parameter
values (a,-y,a1,c12) are in the generic set

43

G {(a,y,aw2,a): a 1 and [1 - uJ

'y[1 - a12 -

Let a&*(x) denote the optimal current period action, either SWITCH or NO SWITCH, for the

infinite horizon problem with discount factor & > 0 when the initial posterior variance over
denote the optimal current period action for

the current status quo technology is x. Let

the myopic problem from the initial posterior variance x.

Proposition 6.9. (Small 6).
(i)

Suppose thatwe are 1nCASEIorCASEIV. Thenthereexistsa 6>0 suchthatfor

all 6 in [0, 6) and for all x

0, ;*(x) = ii*(x);

i.e., the optimal action from

beginning of period posterior variance x with discount factor 6 is the same as the
optimal current period action in the myopic problem with beginning of period posterior

variance x.
(ii)

Suppose that we are in either CASE II or CASE HI. Then for all E > 0 there exists

a6>

0

such that for all 6 in [0, 6) and for all x0 outside of the neighborhood

(x* - E,x* + E) of x,

a5t(x) =

a0*(x).

The proposition above merely states the optimal action in the current period for the small

discount factor problem is the same as that of the myopic or zero discount factor problem. It
does not say what happens over time. The proposition is true only for a set of initial posterior

variances in a subset, [0, x* - E]U[x* + E, ), of the real line. If the dynamics of the
problem never cause the posterior variance of any vintage at any date to enter the set (x4 -E.

x* + E) then we may conclude that the entire dynamic process for the small discount factor

problem is the same as that of the myopic problem. This is the case in the situations listed
below. Hence in these situations the myopic model and the small discount factor problem have

identical actions at each and every date. We omit the proofs as these may be easily verified
from observing the figures associated with each of the cases mentioned.

44

Corollary 6.10 (Dynamics with small ). Let x denote the initial date one posterior variance
over the initial technology, vintage 1. Fix any E > 0. Then there exists a 6 > 0 such that

for all

6

in [0, 6) the infinite horizon problem with discount factor 6 and the myopic

problem result in the same optimal decisions at each date in each of the following situations:

lnCASEIorIVforalI x 0;
(hA) In CASE hA for all x x" (I)

E. However, even when x >

x-

E.

the myopic

problem and the small discount factor can differ in optimal actions for only finitely many

periods. The long run behavior of the two models is the same (and in particular in all
periods except for possibly finitely many initial periods, the agent will SWITCH in each

period).

(lilA) In Case lIlA for all x in [0, xt - E]L.'[x4 + E. oo) (where we suppose E

may be

chosen sufficiently small so that x" > x" + ).
(IIIB) In CASE IIIB for all x x* - E. (However, even when x > x* - E. the myopic
problem and the small discount factor can differ in optimal actions for only finitely many

periods. The long run behavior of the two models are the same. In particular in all
periods except for possibly finitely many initial periods, the agent will choose NO
SWITCH in each period).

The only situation where the corollary above does not apply' is in CASE IIB. Note that

The corollary does not deal with the non-generic case, which may be handled as follows:

Suppose that the parameter values are outside of the set 0. Then either a = 1 or [1 - a.?]
= y[l - a2 - a,,2]. We consider the three possibilities: (i) Suppose fast that ya = 1 &zd
[1 - c)] = y[l - a? - a2J. l'hen 1(x) = r(x) for all x 0, and so both actions SWITCH
and NO SWITCH are optimal for the myopic problem. The conclusions of the corollary
therefore hold trivially for all x 0. (II) Next suppose that ya = I and [1 - a9 y[1 a,2 a9• It is straightforward to check that the proof of Part (1) of Proposition 6.9 only used
the requirement that [1 - a._]
i'll - a2 - a,,9. So the corollary above holds in this situation.
= 7(1 - o,,]. The intersection of r(x)
(lii) Finally, suppose that ya 1 and [1 and 1(x) is now x* = 0. We therefore necessarily have x xtI. Hence we are essentially
inCASEIIB(if ya > 1)0rCASEfflA(if cry < 1),butwith xt = 0. Part(ii) of the
Proposition then applies but for x in (x* + E. co). Also, and the analogous parts of the

45
the problem is that in the neighborhood of radius E around

the intersection x" of 1(x) and

r(x), the optimal current period actions of the myopic and the infinite horizon problem may

differ. In case

118

it is in principal possible that from some given initial posterior variance x

> 0, the subsequent posterior variances will visit that neighborhood infinitely often and hence

in principle it is possible that the myopic and infinite horizon optimal actions may differ at
infinitely many dates.

Remark. The one real difference we have noticed between the myopic case and the small 6>0
case

is the following: Suppose we are in CASE ifi and suppose that xt<i. In the myopic

model, from initial posterior variance equal to x it is optimal to choosethe action NO SWITCH

at each and every date. However, from Proposition 6.3 we know that so long as the discount
factor is positive, however small that might be, it is

SWITCH at each and every date.

corollary then hold.

optimal to choose the action NO

46

VII. Positive Discount Factor in Full-Menu Model
Boundedness of the Value Function:
Recall that from the definition of K in (11), l-a2-h21"1(O)O. Define t:R—.R

t(x)

by

and

We impose the following two assumptions:

A.3. fr.1K+I<l; and
A.4.

l_a2.h2K*I(O)+o#yx4xt<o.

It should be clear that A.3 will hold when 6 is small. Also since 1-a2-h'(O)O, A.4 will
also hold for sufficiently small 6. Under A.3 the function t(x) is a linear function with slope
less than one and with unique fixed point x.

Define VT(x) to be the value function of the T-horizon problem when the current
posterior variance is x and the status quo technology is vintage 0. Note that if instead the status
quo vintage is some vintage k then the T-horizon value function becomes y'VT(x).

Lemma 7.1 (Bound on Value Function). VT(x) x. for all T and for all x.
Since the value function for the infmite horizon model is equal to the limit as T-.oo of the Thorizon value functions, the above result implies the boundedness of the former.

Appendix 1. The Proofs.
Proof of Lemma 3.1.: We begin by proving a stronger version of (iii):
Claim 3.1.1. For all n=l,2

and for all xi, h1(h?(x))<lQ'(h1(x)).

47

Proof of Claim 3.1.1. Fix any n= 1,2,..., and define Ø0(x) e h1(h20(x)) and 4'5(x) a l½a(h(x))

It should be clear that $,(O) h1(h110)) C ht(O) = $O). Also, taking derivatives we
conclude that #F.,(x) —tf'h'(h (x)) and i5'(x) =a'h1 '(x). For x 1, h(x) x. Since h1

with strict inequality for x<i.

is strictly concave this implies that for

I

This proves that for x *, Ffl(x)

Proof of Lemma 3.1 (cont'd): We shall prove this lemma in reverse order.

(iii)

Part (iii) is the same as claim 3.1.1 above with n=1.

(ii)

From part (iii) we know that condition LPSY holds for all xk. So it remains only to

show that the condition holds at any x> it. So fix such an x. Then by definition of 1, x> h2(x)
so

h1(x)>h1(h2(x))aØ,(x).

Since

(13)

when ka,2 we conclude that h1(x)1; i.e., h1(x) lies to the "left" of the

fixed point * of the h2 map. Hence h,(x) h2(h1(x)) 5(x). (13) therefore implies that
condition LPSY holds at x.

(i) It is easy to check that (with obvious abuse of notation)
aa2+a.2 and F(oo)=hl(hZ(co))=aW2.
so s(co)ChF(o3).

(co)=h2(h1(.))=h2(a_2)=

Hence under the hypothesis of this part of the lemma,

Hence x1,< . Since *>O we conclude from part (iii)

that xL}SY>O. Hence O<x1251< .

Next, fix any x x1. Now, 4'(x)=ah1t(h2(x)) and ,'(x)=ah1'(x). Part (iii) of this
lemma implies that for x>x, x>i. This in turn implies that x>h2(x). Since h1 is concave

this implies that F'(x)>S'(x) at each x>x. Since

F(x)>tS(x) for all x>x1. •
Proof of Proposition 3.2. We proceed via two lemmas:

Lemma 3.2.1. Fix any x<x. Then for each n1,2

we conclude that

48

Proof: Fromclaim3.1.1 intheproofofLemma3.1 we knowthatthislemma is trueforxj.

So fix any x in the interval (i,xL).

Since

iterates of the h2 map are decreasing for any x>i,

if x <x then so too is hf(x) <XLnY. In particular condition LPSY holds at h?(x) so
(h2(x)) < 5(h2(x)) or
h1 (h2(h2(x)) C h2(h1(h?(x)).

We proceed by induction. The lemma is trivially true for n1 since this is implied by the
definition of

Suppose that the conclusion of this lemma holds for some n. In particular

suppose that for some n, h1(h2(x)) <hf(h1(x)). Applying the h2 operator to both sides of this
inequality implies that
h2(h1(h20(x))) < h2(h(h1(x))).

The previous two inequalities imply that h1(h2"'(x)) Ch2 '(h1(x)), so the lemma holds for n+ 1.

Hence by induction the lemma is true for all n.

Lemma 3.2.2. Fix any two agents A and B. Suppose that the date 1 variance on vintage 1
obeys condition LPSY. Fix any date T and any vintage ii. Suppose that at the beginning of

date T neither agent has sampled any technology of vintage nii. Let VarA O
denote

and

Var5 O

the beginning of date T posterior variances over vintage of the two agents A and B

respectively. Suppose that VarA O

Var3 O. Fix any two vintages n' and n" with

Suppose that at date T agent A samples vintage a" while agent B samples the "lower" vintage

n'.

Fix any N n". Let Var

Cu'>] and Var5 [°N I <ii'>] denote the posterior

variances of agents A and B respectively over vintage N. Then

VarA EON

I <n'>] Var5 [O I <n'>],

with strict inequality if either VarA Oj < Var5 O- or n'

<a'.

49

Proof of Lemma 3.2.2.: It is easy to verify that

VarA [O" I <n">] = hL(h((VarA O))=hi(h[°'(m.)) where mA=hl (VarA Of); and
Var3 [On"

I

Ca'>) = h2'(h1(h(°(Var8 Oj))) =h2''(h1(m5)) where m3=h2'°( Var3 03.

Now, VaIA 0 VarB

0 implies that

Hence we may apply lemma 3.2.1 to conclude

the proof of this lemma. (The application of lemma 3.2.1 requires condition LPSY to hold for

the date T variances. Note that since [0,1] C [O,x.,1, the latter interval is a stable set in the
sense that if the date 1 variances of vintage 1 lie in this set, so too will all subsequent variances

of all subsequent technologies.

Since this lemma assumes date 1 variances obey condition

LPSY. the same will be true of the date T variances.)

Proof of Proposition 3.2 (cont'd): We shall prove this by induction on the date. The case for
T = 1 is handled by the Lemma 3.2.2. So assume that this proposition is mie for some T for any

individuals F and S satisfying the hypotheses of this proposition. Since the posterior variance

at date T+ I of any agent is independent of the order in which the vintages were sampled, we
may suppose that agents sample vintages in a non-decreasing order so that the vintage chosen

at any date t is no less than that chosen at date t-1. Let i denote the vintage chosen at date T

by agent F. Let n" (resp. a') be the vintage chosen by agent F (resp. 5) at date T+1. From
the induction hypothesis, the date T variance over vintage i of agent F, Var F,T

than or equal to that of agent S. Var

above, Var

0,.

Var

S.T+I

O-.

Suppose

will be less

tim that if n. Then from lemma 3.2.2

°u' which is the induction hypothesis for T+ 1. Suppose

instead that n' <ii. Consider another agent, who we shall call agent who behaves like agent
S in periods 1 through T, but at date 1+1 chooses vintage ii. From the argument we just made
above we know that for agent S.

Var F.T+I

Var

LT+I On-.

50

However from Lemma 3.2.2 we may conclude that

Var

0,. < Var

Hence Var F.T+I O,, < Var s,T+l On., which again is the induction hypothesis for T+1. Hence

by induction the proposition is true for all 1.

(It should be clear how we obtain the strict

inequality asserted in this proposition from the strict inequalities obtained in Lemma 3.2.2.) I
Proofs of Propositions 5.1-5.4: We begin with the following lemma:

Lemma 5.5. Assume
i.

Then for each k= 1,2

;*=hj(x1*). In particular, ; is the (k-1)-th iterate of the

inverse of the function h2 from x1.

ii.

If ;0 for some k, then ;.<O for all lc'>k.

Proof:

(i) By definition x1" is the unique point of intersection of the functions G(x,O) and

G(x,1). Fix any integer k. From the definition of;, G(x,k-l)=G(;,k). Hence from the
definition of the G(x,k) functions, [1_aW2_hz(xk*)] =y[1g2_h2(h2k(;*))] In particular, at

x=htl(xt*) we have G(x,0)=G(x,l). Hence h(xt*)=x1*, from which part (i) of this lemma
follows.
('ii) From

(i) we know that the ;*'s are iterates of the map hj'. The slope of the latter is 1/cr.

When cr< 1, lIcz>1 so iterates from any x4'O converge monotonically to -.

If a=1 the

h' mapping has slope of one but is everywhere below the 45 degree line. Again, iterates from

any ;'O converge monotonically to -. Finally, ii a> 1, the fixed point of h24 is the point
a,2/(l-a) which is negative. From ;0, iterates of hi' converge monotonically to this point.
In either case, part (ii) of the lemma follows. I
Proof of Proposition 5.1. (CASE 1). In case I cry> 1. Also O(O,O)=t(0) >r(0)=G(0.1).

So x,*<O.

From

lemma 5.5(u) this implies that ;*<0 for all k. If for some k

G(0,k) G(0,k+ 1) then, since the absolute value of the slope of G(x,k+ 1) exceeds that of

51

G(x,k) when cry>!, their point of intersection, xk+i*, will bepositive. This is a contradiction.
Hence G(O,k) > G(0,k + I) for all k from which the proposition follows. •

Proof of Proposition 5.2. (CASE II).

In case II ay>1 and G(0,O)=t(O)<r(O)=G(O,!).

Hence

x1 * >0. Define M to be the largest integer m such that G(0,k-1) <G(O,k) for

k= 1,2

m. From the defmition of M, G(O,M) G(O,M+1). Since the absolute values of the

slopes of the G(x,k) functions are increasing in k when cry>!, this implies that xM+l*O.
From lemma 5.5(11) this in turn implies that ;*0 for all k>M. Suppose, per absurdem, that

Let k' be the

for some k>M, G(O,k)>G(0,M).

first

such k.

Then

G(0,k'-l) G(0,M) <G(0,k'). This then implies that ;.*, the point of intersection of G(x,k'-l)
and G(0,k'), is positive. This contradicts our earlier assertion that ;* O for all k> M. Hence

G(O,k)G(O,M) for all k>M. Since the slope of G(x,k) is greater in absolute value than the

for allxO. This proves the Proposition. I

that of G(x,M), we conclude that

Proof of Proposition 5.3. (CASE llfl. In case Ill cry< 1, so the absolute values of the slopes

of the G(x,k) functions are decreasing in k. If for some k, G(O,k)

G(O,k-l) then ;*O.

Lemma 5.5(u) would then imply that ;*<O for all large k. However, from (1!) for all large
Ic

G(0,k) G(0,k-l), so ;*O for all large It. This is a contradiction. Hence we conclude

that G(O,k) < G(O.k-!) for all k=!,2

This proves part (i) of the lemma.

Since ay< 1, a< lIy <1. From Lemma 5.5(i) the x4 's are iterates of the hj'
function. This function has fixed point i = a12f(!-a) >0. and slope 1/a> I. From the definition

of x1 it is easy to check that x can never be equal to 1. Iterates of this function from any
x1'

converge monotonically to either + oo

or -.

Since

we have just shown that the ;*'s

are positive for all large k, we conclude that the monoconic convergence is to + .

from which

part (ii) of the proposition follows. The remaining parts of the proposition then follow

immediately. •

52

Proof of Proposition 5.4. (CASE IV). In CASE IV ay < i and G(0,O) =t(O) c r(O,O)=G(0, 1).

Hence x1t must be negative. From Lemma 5.5(u) this implies that ;* is negative for all Ic.
However from (11), G(0,lc) G(O,k-l) for all large Ic. Since the slopes of the functions G(x,k)

are decreasing in k this implies that x is positive for all large k. This is a contradiction.
Hence case 4 is incompatible with our assumptions (and in particular assumption A.2, from
which (11) was derived).

Proof of Lemma 5.6: (i)

Since for all Ic, g(k) =h1(h2(k)) =h1(I) <k and g(O) >0, we

conclude that xk**c(O,i). However, for any x in (0,t), gk(x)<g1(x). It is easy to see that this
implies that Xk**<XtI**. This proves the first part of the lemma.

(ii) We argued in the previous paragraph that ;*+€(O,*) for all Ic. Hence k(x$*) Ci which

implies that ;** hi(h2k(x**)) <h1(k) for all

Ic,

so lim_ ;** h1(i).

Also,

= h1(h2k(x**)) h(h2k(0)), and IiWk.. h2k(O) =, so li1nk. ;** h1(k). Combining our
results shows that limk. ;**=h(A) •
Proof of Proposition 5.9: If the initial posterior variance lies in [x1*,00) the action NO
SWITCH will be chosen. The posterior variance will in finite time enter the set [0,xt*). From

lemma 5.6 and the hypothesis of CASE HA', ;**XMxI* for all

Hence once the

posterior variance process enters the set [O,;), it will stay there forever after. In the set
[O,x1*) the optimal jump size is greater than or equal to one.

Proof of Proposition 5.10. (Case IIB): Under CASE II, and lemma 5.6 above
x1*cx1**<x2**<x3**<... Whenever the posterior variance is inthe set Ex1*,oo) the action
NO SWITCH is chosen. This causes the posterior variance to decrease monotonically. After
some finite date the posterior variance will fall below x1'. At this time a jump of size j equal

one or larger will be chosen. This causes the posterior variance to move toward ;fl. Since

> x1 for all j 1, evenwally the posterior varaince will enter again the set [;*, cc), and the
process described above is repeated; ad infinitum. •

53

Proof of Proposition 5.11. (CASE lilA): (i) This should be obvious from fig. 9 of CASE III.
(ii) If the initial posterior variance lies in the set (x1,00), a jump size of j

1 will be chosen.

The hypothesis of CASE lilA and lemma 5.6 imply that x<xt for all k. Hence if the
initial posterior variance lies in the set (x1, oo) andj 1 is chosen the posterior variance process

will remain in the set (x1*,00). By induction we see that the posterior variance process will

indeed be in the set (x1*.) for each date and hence a jump size greater than or equal to one

will be chosen at each date. I

Proof of Proposition 5.12. (CASE 0W'): (1) Under the assumptions of CASE ifiB' and
lemma 5.6 Xk h1(i) < x for all Ic. Hence from any initial posterior variance, the posterior

variance wilt enter the set [O.;9 in finite time. (ii) It should be obvious from fig. 9 that if the
initial posterior variance lies in [0, x1 ] the optima] action is NO SWITCH (or jump size of zero)

at each date.

I

Proof of Proposition 6.2.: The continuity of L(x), R(x) and V(x) follow from the dynamic

programming arguments mentioned earlier and the continuity of h(x), h1(x), e(x) and r(x).

To prove the other parts of the proposition we adapt the following arguments from
Nyarko (1994). Let a *poljcv to be a policy which is independent of both the date one posterior

variance x and the history of observations at date t; a *.policy may however depend upon the

date. (In particular,a *_policy is a deterministic rule for choosing actions as a function of the

date.) Recall that t is the set of all policies. Let 'I's be the set of all *.policies. Since
V(x) = Sup,1. V(x). and since W c 'p.

V(x) Sup. V(x).

(14)

We showed in proposition 6.1 that the optimal decision at each date may be chosen to
be a deterministic function of the status quo vintage and posterior variance of that vintage at each

54

date. But the Dosterior variance over any vintage at any date is a deterministic function of the

initial posterior variance x, and the sequence of decisions chosen up to that date. Hence the
optimal decision at any date is a deterministic function of the initial date one variance, x, over

vintage 1. Hence if we LIA a posterior variance x over initial vintage 1, there will exist a policy which attains the same sum of discounted returns as the optimal policy. Hence for each

x, V(x) Sup. VT(X). Combining this with (14) implies that

V(x) =
The use of any *..policy,

SUPTit.

V(x).

(15)

r, results in a fixed deterministic sequence of decisions

SWITCH or NO SWITCH over time and hence a fixed deterministic sequence of vintages
chosen at each date. This sequence is independent of the date one posterior variance x. The
sequence of variances of the chosen vintages at each date is a sequence of iterates of the maps

h() and h1() defined earlier. Now, both h(x) and h1(x) are strictly increasing and strictly
concave functions of x. Hence any finite sequence of iterates of h and h1 are also strictly
increasing and strictly concave in x. Hence, the same is true of the variance of the vintage,

m(t), used at any given date t under the -policy r, Var, O. Now, the payoff at each date

is y"[1 - VarL Oi) - a2].

The discounted sum of payoffs, V(x) is a strictly convex and

strictly decreasing function of x. Eq. (15) therefore implies that V(x) is the supremum of a
collection of strictly convex and strictly decreasing functions of x. It is easy to verify that since

the supremum in (15) is attained for each x, V(x) is therefore also a strictly convex and
strictly decreasing function of x.
Next define ,p*L (resp. t*Jt) to be the set of all *..policies which choose the action NO

SWITCH (resp. SWITCH) at date 1. Following the previous arguments it is easy to show that

L(x) = Sup {VT(x): r e t'} and

R(x) =

Sup

VT(x): r e

55
and

so L(x) and R(x) are each strictly decreasing and strictly convex in x.

Proof of Proposition 6.3.:

Let x and 6 be as in the proposition. Let r denote the policy of

choosing the action NO SWITCH in each period, and let V(x) denote the return from this
policy. Let ?T' denote the policy where the action SWITCH is chosen at date 1, but where in

each subsequent period the action NO SWITCH is chosen. Let V.(x) denote the return from

this policy. Clearly it suffices to show that VT<Vr.

Under the policy ir, the date t priQr variance over the date t status quo technology
(which of course is vintage 1) is h1tA(x) where h10(x)x and h1'(x) is the t-1 times iterate of the

function h1 from x. Under the policy 1, the date 1 prior over vintage 2 is ax+a2. The date
2 prior variance over vintage 2 is h(ax+a1); and the date t prior variance over vintage 2 is
h1'1(ax+a2). Hence the difference in discounted payoffs of the two policies is

= E ; 61A where

\ y[ I awZhjt1(ax +a.2)][1az_h1H(x)] = (y_l)(1_a2) + [h1E1(x)yh1l(ax +a,1)]

Note that r(x)-e(x)=1,

so

[h1'1(x)-yh1''(cix+a,2)] (which

is

£S1 0 by assumption.

We will now show that

negative) is strictly monotone increasing in t (so is becoming

less negative as t increases). This will imply that A>0 for alit>

that Vr(X)Vr(X) >0 which will prove this proposition.

[hi(x)yhjt(ax + a,2)] =A1+B1 where A1

1. This in turn will prove

Now, we may write

[h1'(x)-h1"(x+a)1 and B1

Since h1 has slope everywhere less than one, I

I

is non-increasing in t.

Since for xi,

hiL(x) C h1'(ax+a2) we conclude that A, is non-decreasing in t. Since h1(ax+a,2) is strictly

decreasing in t, B1 is strictly increasing in t. Hence A,+B, is strictly increasing in t.

•

Proof of corollary 6.4: If from x=O the action NO SWITCH is chosen then the posterior

56

variance of the status quo technology will be x=O in the next period as well. Hence from the

stationarity of the problem, if from x =0 it is optimal to choose the action NO SWITCH at date

1, then it is optimal to choose that action in each and every subsequent date. However
Proposition 6.3 implies that it is iii optimal to choose the action NO SWITCH in each period.

Hence the optimal action from x=O is SWITCH. •

Proof of Proposition 6.5: The variance from period 2 onwards always lies between zero and
as). Hence the discounted future sum of returns (from dates 2 and onwards) is bounded between

V(0) and V(a2). However, as x-" the difference between the current period rewards, r(x) and

t(x) goes to infinity. Hence, there exists an i such that for all x>i,
I

ÔV(h1(x))-V(h(x))

I

r(x)-f(x) j > Sup1

. Using the Bellman equation therefore proves the proposition. •

Proof of Proposition 6.6: Recall that a Icpolicy is nothing other than a sequence of decisions,

SWITCH or NO SWITCH, for each date, with the decisions being made as a function of the
date but independently of the posterior variance at that date. We begin with the following claim:

Claim: Define M 1/[1 - Max{a,

1I'y}]. Fix

and x". i. For any fixed *.policy r,

any two initial date I posterior variances x'

VT(x') - V1(x")

I

M x' - C

I

and

ii. V(x')-V(x") -M x'-x"
Proof of Claim:

(i) Let ir, x' and C be as in the claim. Let m(t) denote the vintage of

the technology chosen at date t and let a1'2 (resp. oy'2) be the prior variance at the beginning

of date t of the vintage chosen at date t under the *..policy r from initial date 1 posterior

variance x' (resp. x").

I

Suppose

Define for each t,

(1

—

a1'2 — a..)) — (1

—

0n2 — a.)) I

=

I aj2 — a1u12 I

that at date t the action SWITCH is chosen. Then m(t+l) = m(t) + 1.

Also,

57

=
a"2

ah1(a1'2)

+ a12 and a1.1"2 =

ah1(a1"2)

+ a,, so

01+112 —

u1i"2

°' —

I

Hence

w=

a1.1'2 - o1j'2 = a(&y)ö''y°'

Max {a, lIy}.w1,

cr1'2 — "2

where we use the fact that fry < I for the last inequality above. Alternatively, suppose that

at date t the action NO SWITCH is chosen. Then m(t+1) = m(t). Also, o"2

=

h1(a1"2)

so (since 0h1(x)IOx <1),

6L7Th(LIM

where

a1.1'2

— o+N2 I

I

- ai"2 = ö.&y'

a1'2 — cr1"2

I '2 — Q"2

= h1(cr1'2)
.

and

Hence

Max {a, 1/}.w1

again we use the fact that ô < lIy for the last inequality. We therefore see that
Max {a, 1/y}.w1. Hence, w1 (Max

regardless of the decision chosen at date t. w141

(a. 1/y})twi for all t > 1, so
S w1/[1 - Max {a, 1/y}] = w1M.

Now w1 =

a1'2 - a1"2

If the decision NO SWITCH was chosen at date 1 then m(I)

= I, a'2 = x' and al2 = C so w1 = Ix' -x"

atdatelthen m(1)=2, g1'2=ax' +a, and

S x'-x". Ineithercaseweseethat

If the decision SWITCH was chosen

a1"=ax" +a sow1 alx'-x"I

w1 Ix'-x"I.

Puttingthisintheabove

equation and recalling the definition of w1 implies the conclusion of part (i) the claim.

(ii) Let r be the *.policy which is optimal from initial posterior C. Then V(x') V,(x') and

V(x") =V(x"). Hence V(x')-V(x")

V.(X')Vr(C). An application of part (I) of this lemma

therefore proves part (ii). •
Proof of Proposition 6.6 (cont'd): Since x 0, h(x) S a2 and

and since VC) is

58
monotone decreasing,
V(h(x)) - V(h1(x))

V(a2) -

V(O).

(16)

Part (ii) of the claim above implies that V(a2) - V(O) -Ma2. (16) therefore implies that

forall x

0,

- V(h1(x))

V(h(x))

-Mcç.

(17)

Fix any ? > Q2 Define

M = Maxflt(x)-r(x)I: xE [0,9}.
Then

M < .
Suppose

that

+ E) > . We now
initial

E.

r(x**) > 0.

Then there exists

compute the return

posterior x=cç2. Let {x.}1

Since x, —.

>

If

x',

to the

a E

>0

sufficieutiy small such that

policy, irncn,

of switching in each

be the associated posterior

of

M is as in (18) above, the discounted sum

r(x**

period from

variance process from

there exists a T C Co such that for all t > T, ; C

necessarily exceed -TM + E1,1(67)'E = -TM
5 —'

(18)

x"' + E.

7H•
so

r(x.)

returns to this policy will then

+ E(&y)TI(1 - &y) 'This tends to infinity as

1/')'. Hence V(a2) tends to infinity as S — 1/y.
Since for all x

0,

h(x)

a,2, V(h(x))

V(a,,2)

Hencewemaychoosea 5< 1/y suchthatforall S

-

where

1)V5(h(x))

>

we subscript the value function V

&

so V(h(x)) tends

andforall x

to

as S —'

0,

Ma2 + M,
by S to emphasize its

lly.

(19)

dependence on

5,

and where

M and M are as in (17) and (18), respectively, (and are independent of 6). Using (17) and

59

(18) in (19) implies that for all such 6, and for all x

ö'yV5(h(x)) 6V6(h1(x))

=

(0, 9,

ô(y - 1)V6(h(x)) ÷ &[V3(h(x)) - V3(h1(x))]

> M + 6Ma2 - 6Ma2
= M > 1(x) -

so

R(x) = r(x) + &yV5(h(x)) > 1(x) + 6V(h1(x)) = L(x).
Hence the optimal action from such & and x is SWITCH. •
Proof of Proposition 6.8: It suffices to show that from any initial posterior variance the agent

chooses each action, SWITCH and NO SWITCH, infinitely often.

Suppose that from initial posterior variance x the optimal action is SWITCH. Then
since the posterior variance in the next period will remain at xt, it will be optimal to SWITCH

in each and every period. Since r(x**) C 0, this will result in a negative payoff in each
period. As 6 converges to 1/y this payoff can be easily seen to converge to -.

If on the

other hand the agent chooses the action NO SWITCH in each period, the agent will have a

return of at least f(x**)I(lô) which converges to the finite number 1(x**)/(l1/y) as &-'lIy.
Hence

there will exist a 6 in (0, lI-j) such that for all 6E(Ô,lIy) it is not optimal to SWITCH

from x. Under obvious continuity of the L(x) and R(x) functions the optimal action
within a neighborhood of x4 is also NO SWITCH. If the agent chooses the action SWITCH

for all but finitely many periods, the variance process will converge to x**. This will
contradict the earlier assertion that from a neighborhood of x** the optimai action is NO
SWITCH. Hence the agent will choose the action NO SWITCH infinitely often.

Using Corollary 6.4. from initial posterior variance x = 0, and hence from a
neighborhood of c = 0, the optimal action is SWITCH. If from some initial posterior variance

x1 > 0 the agent chooses the action NO SWITCH for all but finitely many dates then the

posterior variance process will converge to zero. This will contradict the fact that from a
neighborhood of zero the optimal action is SWITCH. Hence the action SWITCH will be chosen

60

infinitely often.

In summary we have shown that from any initial posterior variance the optimal policy

will choose both actions, SWITCH and NO SWITCH, infinitely often. Hence we have

"cycles." I

Proof of Proposition 6.9. (small 6): We prove part (ii) first. Fix any E > 0.

,c(x)

I

1(x)-r(x)

I

forall x

Define

0.

Under the assumption that the parameter values lie in the generic set G both 1(x) and r(x)
are linear functions with different slopes and different intercepts and with a strictly positive

intersection x'. It is therefore easy to see that

x(x)

,c(x*+E) = ic(x-E) > Oforall xE [0,x*_E)U(x*+E. oa).

Now, hL(x) = a2xJ(x + a2) ct,,,2

and

(20)

hence h(x) = h1(h2(x)) a,,,,2. Hence regardless

of the current period decision, SWITCH or NO SWITCH, the next period posterior variance will

be bounded above by a2. This will be true for the posterior variance at each date. Hence
absolute value of the expected payoff in each period is uniformly bounded, by some number

K say. Hence

I

V5(h1(x))

I

K/(1 -

6)

and

yVa(x)) I

yK/(1 - 6), where we now

index the value function by the subscript S to denote its dependence on 6. This in turn implies

that Sup10ô V/h1(x))-1V3(h(x))l -0 as 6—0. Inparticularwemaychoosea S > 0
such that

S I V6(h1(x))

- 7V6(h(x))

I

< ,c(x' - E)/2

Combining this with (20) above implies that

for all S < 5.

(21)

61

p1(x) - r(x)

> 6I

I

V6(h1(x)) -

yV(h(x))

j

vô C Ôand Yx in [0, x - flU(x* + E.

oo).

It is then easily verified that this in turn means that

1(x) > r(x) implies

that 1(x) + 5V6(h1(x)) > r(x) ÷ yV3(h(x)) and

1(x) < r(x) implies that 1(x) + 6V3(h1(x)) C r(x) + yV8(h(x)).

(22)

Note that L(x) = f(x) + 6V6(h1(x)) (resp. R(x) = r(x) + yV5(h(x))) is the return to the agent
that chooses the action NO SWITCH (resp. SWITCH) in the current period and behaves
optimally in each subsequent period. (22) therefore implies that the decision which maximizes

the myopic return also maximizes the infinite horizon return with discount factor 6. This of
course is part (ii) of the proposition.

Part (1): To prove part (i) of the proposition observe that 4x) s

1(x) - r(x)

non-decreasing in x in CASES land IV. Further, [1 - a9 ,#Ei - a? - r(0) > 0. Hence we may replace (20) with sc(x) a J 1(x) - r(x)

is monotone
ic(O)

I

sc(O) > 0. and

proceed analogously to the proof of part (ii) above to obtain the proof of part (i) of the
proposition. •
Proof of Lemma 7.1.: In the myopic problem from initial posterior variance x=0 the agent
will never choose a jump size greater than K+ I since this will result in a negative payoff while

choosing no jump in each period results in a payoff of 1a2>0 in each period. The return to

choosing a jump size of kK+1 results in a payoff no greater than y'"'[1-c,2]. From the

definition of x it is easy to see that y[1-aj]x. Hence
We proceed by induction: suppose that for some T=1.2
VT(O)

x.

we have shown that

The value function of the T+ 1 horizon problem from initial posterior variance x=0

is:

VT+ '(0) = Max_012• .yk{ 1-a2-h(O)+öW(h,(h21(O))}.

62

Ifajump size of k>K+1 is optimal for this T+i horizon problem from x=O, then the return
will be no greater than yk{lawZh(o)+&VT(0)}, which from the induction hypothesis is no
greater than 7k{ 1-aj-h"(O)+bx.j.

This latter expression is, from (21), negative for all

k>K+l. However, if a jump size of zero is chosen at each date the return at each date will

be l-cj which is positive. Hence it is not optimal to choose a jump size k>K+1. With this
result we may conclude from the definition of w a above that

VT'(0) yK#l(lo2)+frYK+IiT(O) B t(V1O)).
Since VT(O)

x,, we conclude from the obvious properties of 'P that t('V'O)) x. So

V1(O)x. •
Appendix 2. Verification that all the CASES I-IV are non-empty.

It should be obvious that there exist parameter values such that CASES I and IV hold.

Set al =

= 0.25. Then

[(1 - a - ç_2) - (1 - a2)] = [O.5y -0.75] =

[2y - 3]/4 and

= [y(l - a,2 - a2) - (1 - a2)]/['ya - 1] = [2y - 3]/[4(ya - 1)].
Also,

= [a..)(ax"' + a,2)]/[a2 + (** + al)]
Hence

a2a2/(a2 +

1/8 x'

1/4.

a) x** ,2 S
(23)

63

CASE

hA x > x". Fix any a. Let y tend to infmity. Then x = 0.25[2y - 3]/[c.ry -

l/(2a). Hence for any fixed a C 1, we may choose a 7 sufficiently large so that (ay)
so that we are in CASE hA.
> 1, 0.25[2y - 3] > 1 and xt > 1/(2a) > 1/4 >

11

—.

x,

CASE HB x C

x'4t.

Take a sequence {7k}kl converging to 3/2 from above. Let a

be any sequence converging to 3/4 from above. Then akyk —' 9/8 > 1 and O.25(27t - 3) >

0 for all k. Hence we are in CASE II for all k sufficiently large. Further, ;* =
for all k sufficiently large, which implies CASE RB.
3]/[crkyk - II —. 0 so xk* C 1/8 C

x

Case hlL&; x < x. Now consider a sequence {7t}k-a converging to 3/2 from below.
Define ak = "27k' in which case c converges to 1/3. Also at'y& =
3

1/2

C

1

and 2Tk -

converges to zero from below so for all k sufficiently large we are in CASE III. Now, in

this case x' =

- 3]/[akyk - 1]

-.0 so for k sufficiently large x' C 1/8 C

x

so

we are in CASE lilA.

Case RIB: x > x. Fix any a C

1.

Pick any sequence of y's converging to one from

above. Then eventually, (ay) < I and [y(1 - a - 2) - (1 - a2)] = O.25[2y - 3] < 0 so
we are indeed in case III. Also x" = O.25(2y - 3]/(ay - 1) converges to 0.25/(1 - a) >

0.25, so from equation (23) we conclude that x > x' so we are in CASE IJIB.
Each of the above cases can coexist with the restriction, made in proposition 6.6, that

r(x**) 0. The following six sets of parameters do the job:

a2 = 0.30, a2 = 0.25, a = 0.75,7 = 1.55.
Case HA: a,2 = 0.25, 2 = 0.25, a = 0.75, y = 1.55.
Case hIB: cc2 = 0.25, a? = 0.25, a = 0.75, y = 1.54.
Case lilA: a) = 0.20, a? = 0.30, a = 0.50, y 1.55.
Case hUB: a) = 0.20,
= 0.30, a = 0.60, y = 1.55.
Case I:

a

64
Case IV:

a2 =

0.10,

a2 =

0.30,

a = 0.60, y =

1.55.

Appendix 3. Proof that the Conditions in Proposition 6.8 Rule Out Case IV. It is enough
- a12) > (1 - a2) is impossible when ay C 1. First,
to show that r(x") C 0 and y(l
note that

=

x

aXax ' + a)
_________

+ (ax"

+

a)

[(at, + a

-

a,a)2

the solution of which is

-

{ —(a

+

—

aa,)

+

+4a4a]Ih2 }

2a

The negative root is inadmissable because x 0. Now r(x") = 7(1 - a2 implies that

1

- a,2 - a2

- ax") C 0

< ax'. Substitution for C into the above inequality and (very

tedious) rearrangement gives

y(l -

- a) C

ycw,(1 — o,)

C aAl-c4)

(1—a)

(We assume

since a < 1.
since a,
1.

a21 since otherwise net outputs are always negative.) So r(0)<f(0). •

Appendix 4. The No-Recall Assumption:

The analysis of this paper assumed the following no-recall constraint: An agent who chooses

a vintage nat date t,

can

not choose a lower vintage n'<nat any future date t'>t. We now

proceed to show that if we are in the myopic model, it is never optimal to exercise the recall

65
option and choose a vintage that was previously passed over. Our conjecture is that the same
result is true in the positive discount factor problem. Our conjecture is given support by the fact
that we have a proof that it is not optimal to exercise the recall option in the two-horizonversion

of the problem with positive discount factors.

To proceed we will require some notation:
covariance matrix over (01,02....)

is

Suppose that at date 1 the variance-

given by E=({xJ4..12J.

Lemma A4.O: Then alter observation of y=0+w1 the posterior variance of °k is given by

Var (O I

= xx2/[x+aw1.

Proof': Let St denote the posterior variance-covariance matrix after observation of Ym=Om+W.
Then from Chow (1983, p. 13), S*=S_SI2Ej%It, where S12 is the matrix of covariances
between Ym and (01,02,0

)

and where S, is the variance of y,,,. Now. Var y,,, =

for any j = 1,2
Coy (0.y,J=E[(O-E0)(y-EyJ] =E[(Oj-EO)(Om+wm-EOJ] =x. Hence
applying the formula we see that
Et=S(Xirui,Xzm,. .

I[x+c9.

The (k,k) element of this matrix can easily be seen to be x-xfr/(x,,,,,+u_2). I

Let q and

denote the dates 1 and 2 output levels respectively.

Let

Q1( C k> ) = E[q1 I <k> I denote the expected date 1 output level if vintage k is chosen at date

<lc1,k>] denote the date 2 output level if vintage k1 is chosen
at date 1 and vintage Ic2 is chosen at date 2. Let R(<k11k2>)Q1(<k1>)+SQ(<ki,kz>)be
1. Let Q2( C k1,k1> ) =

the discount sum of net outputs when vintage k1 is chosen at date 1 and vintage 1c2 is chosen at

date 2.

Lenuna 44.1: Suppose that it is optimal to choose vintage nat date 1 and vintage 1 at date 2.

66

Then R(<n,1>)-R(<1,n>)0.
Proof: Suppose agent A chooses vintage n followed by vintage 1 • while agent B does the
reverse and chooses vintage 1 followed by vintage n. If each began with the same date 1 prior
each agent will have at the beginning of date 3 the same variance-covarianee matrix since they

receive the same information, although in different orders. In the no-jump model each agent
will also have at the beginning of date 3 the same maximal vintage chosen. Hence from date

3 onwards the decision problems of the two agents will be identical.

Suppose each agent

chooses the optimal policy from dates 3 onwards. By hypothesis of the lemma, agent Ks policy

is optimal. Since agents A and B will have the same return from dates 3 onward, agent A's

return in the first two periods can not be less than that of B's in the first two periods. The
conclusion of the lemma follows from this observation. •

Lemma A4.2: R( Cn,1 >)-R(< l,n>)=[1-b+ôfl[Q(<n>)-Q(C 1 >)1-o(X'-1)

>0.

where

Proof: Since
Var [O

<1 >]=x

- xi/(xii+orl) fl,j

Var [O

<n>]=x1 -

x102I(x,,,+c2), one may easily verify that

R(<n,1>) = X0l{1_a2_xj

+ S{1-a_2-x11+ xi,?I(x.,,+a2)} and

R( <1 ,n> ){1-a2-x11} + öX'{1ow2x,m+ x1,,I(x,,,+u2)}
from which the lemma follows immediately. •

LemniaA43: R(<n,1>)-R(<1,n>)O implies that
Proof: This follows immediately from lemma A4.2. •

67

Lemma A4.4: Q1(<n>)Q1(<1>) implies that Q2(Cn,n>)>Q(<n,1>).
Proof:

Q2(<n,n>)-Q2(<n,1>)=X°4{1-a2- x + x.$/(x,.0+u2)} - {1-a' - x11 + x12/(x+o2)}.
The Cauchy-Schwartz inequality implies that X122X,aXlj. Hence the above is

(X°- 1)( 1-a.)) - (A'1x-x1.1)(1- xJ(x+a.)))

= Q1( C n > )-Qi( <1>) + (X'x,s-xll)xJ(xM+t7W2).

(1
(**)

If (X"'x,-;1) O then the RHS of (*) is non-negative from which the lemma follows. If (X'iç,,x1j>O then the lemma follows from (**)• •
Proposition A4.5 (No Recall): Suppose that we are either in the (a) myopic model or (b) two-

horizon model. Then an agent will never use the recall option.
Proof: If the agent uses the recall option then (by rescalling) we may assume that at some date

I the agent uses a vintage n> 1. and at date T-l-1 uses vintage 1.
(a)

Suppose we are in the myopic model. Then at date T the return from using vintage n,

QT(<n>), must exceed that of using vintage 1, Qc1>). From lemma A4.4 this
implies that the date T+1 return from using vintage n, Q1(Cn,n>), exceeds that of

using vintage 1, Q,+1(<n,1 >). However, for the myopic model, this implies that
vintage n is used in period T+1, which contradicts our earlier assertion.

(b)

Now suppose that we are in the two period model. Then R(<n,1>)R(<1,n>).
Lemmas A4.3 and A4.4 imply that 04(<n,n>)>Q(<n,i>). But this in turn implies
that for the two period model, at date T+1 vintage n is chosen. This contradicts our

earlier assertion. •

68
References:

Chari, V.V., and Hugo Hopenhayn, "Vintage Human Capital," Journal of Political Economy
99, no. 6 (December 1991): 1142-1165
Chow, Gregory, Econometrics, New York, N.Y.: McGraw Hill (1983).
Lucas, Robert F

Making a Miracle," &otjo,netrica 61, no. 2 (March 1993): 251-72.

Nyarko, Yaw, "On the Convexity of the Value Function in Bayesian Optimal Control
Problems," Economic Theory, (1994).

Parente, Stephen. "Technology Adoption, Learning by Doing, and Economic Growth,"
unpublished paper, Northeastern University, October 1991.

Prescott, Edward, "The Multi-Period Control Problem Under Uncertainty," Econometrica 40,
no. 6 (November 1972): 1043-58.
Stokey, Nancy, "Human Capital, Product Quality, and Growth," Quarterly Journal of Economics
106 (1991): 587-616.
Wilson, Robert, "Informational Economies of Scale," Bell Journal of Economics (Spring 1975):
184-95.
Young, Alwyn, "Invention and Bounded Learning by Doing," Journal of Political &onomy 101,
no. 3 (June 1993): 443-72.

