NBER WORKING PAPER SERIES

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS, WITH AN
APPLICATION TO THE DISTRIBUTIONAL EFFECTS OF TRADE
Denis Chetverikov
Bradley Larsen
Christopher Palmer
Working Paper 21033
http://www.nber.org/papers/w21033

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
March 2015

We thank Moshe Buchinsky, Ivan Canay, Brigham Frandsen, Antonio Galvao, Wenshu Guo, Jerry
Hausman, Rosa Matzkin, Whitney Newey, and Christopher Taber for helpful comments; and Yuqi
Song and Caio Waisman for meticulous research assistance. We are especially grateful to Jin Hahn
for many useful discussions. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
¬© 2015 by Denis Chetverikov, Bradley Larsen, and Christopher Palmer. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including ¬© notice, is given to the source.

IV Quantile Regression for Group-level Treatments, with an Application to the Distributional
Effects of Trade
Denis Chetverikov, Bradley Larsen, and Christopher Palmer
NBER Working Paper No. 21033
March 2015
JEL No. C21,C31,C33,C36,F16,J30
ABSTRACT
We present a methodology for estimating the distributional effects of an endogenous treatment that
varies at the group level when there are group-level unobservables, a quantile extension of Hausman
and Taylor (1981). Because of the presence of group-level unobservables, standard quantile regression
techniques are inconsistent in our setting even if the treatment is independent of unobservables. In
contrast, our estimation technique is consistent as well as computationally simple, consisting of group-by-group
quantile regression followed by two-stage least squares. Using the Bahadur representation of quantile
estimators, we derive weak conditions on the growth of the number of observations per group that
are sufficient for consistency and asymptotic zero-mean normality of our estimator. As in Hausman
and Taylor (1981), micro-level covariates can be used as internal instruments for the endogenous group-level
treatment if they satisfy relevance and exogeneity conditions. An empirical application indicates that
low-wage earners in the US from 1990--2007 were significantly more affected by increased Chinese
import competition than high-wage earners. Our approach applies to a broad range of settings in labor,
industrial organization, trade, public finance, and other applied fields.

Denis Chetverikov
UCLA, Department of Economics
315 Portola Plaza
Bunche Hall, Room 8283
Los Angeles, CA 90095-1477
chetverikov@econ.ucla.edu
Bradley Larsen
Department of Economics
Stanford University
579 Serra Mall
Stanford, CA 94305
and NBER
bjlarsen@stanford.edu

Christopher Palmer
Haas School of Business
University of California at Berkeley
545 Student Services Building
Berkeley, CA 94720-1900
cjpalmer@berkeley.edu

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

1

1. Introduction
In classical panel-data models for mean regression, fixed effects are commonly used to obtain
identification when time-invariant unobservables are correlated with included variables. While
this approach yields consistent estimates of the coefficients on time-varying variables, it precludes
identification of the coefficients of any time-invariant variables, as these variables are eliminated by
the within-group transformation. In an influential paper, Hausman and Taylor (1981) demonstrated
that exogenous between variation of time-varying variables can help to identify the coefficients of
time-invariant variables after their within variation has been used to identify the coefficients on
time-varying variables, thus yielding identification of the whole model without external instruments.
Our paper provides a quantile extension of the Hausman and Taylor (1981) classical linear panel
estimator.
We present our model in Section 2. To clarify the range of potential applications of our estimator, we depart in the model from the usual panel-data terminology and refer to panel units as
groups (instead of as individuals; groups might be states, cities, schools, etc.) and to within-group
observations as individuals or micro-level observations (instead of as time observations; individuals
might be students, families, firms, etc.).1 The model is of practical significance when the researcher
has data on a group-level endogenous treatment and has microdata on the outcome of interest
within each group. For example, a researcher may be interested in the effect of a policy which
varies across states and years (a ‚Äúgroup‚Äù) on the within-group distribution of micro-level outcomes.
In Section 2, we also explain how the problem we solve differs from others in the quantile regression
literature, and we demonstrate that, as in Hausman and Taylor (1981), micro-level covariates can
be used as internal instruments for the endogenous group-level treatment if they satisfy relevance
and exogeneity conditions. This last feature of the model is especially appealing because in practice
it may be difficult to find external instruments.
We introduce our estimator in Section 3. The estimator is computationally simple to implement
and consists of two steps: 1) perform quantile regression within each group to estimate effects of
micro-level covariates, or, if no micro-level covariates are included, calculate the desired quantile for
the outcome within each group; and 2) regress the estimated group-specific effects on group-level
covariates using either 2SLS, if the group-level covariates are endogenous, or OLS, if the grouplevel covariates are exogenous, either of which cases would render standard quantile regression
(e.g. Koenker and Bassett 1978) inconsistent.2 Section 3 also highlights a variety of applied
micro settings in which our estimator is useful (with detailed example applications discussed in
1
2

Similar terminology is used, for example, by Altonji and Matzkin (2005).
Even in the absence of endogeneity, the Koenker and Bassett (1978) estimator will be inconsistent in our setting

because of group-level unobservables, akin to left-hand side measurement error; see Section 2 for details on our
setting. While posing no problems for linear models, left-hand side errors-in-variables can bias quantile estimation
(see Hausman (2001) and Hausman, Luo, and Palmer (2014)).

2

CHETVERIKOV, LARSEN, AND PALMER

Appendix A) and discusses Monte Carlo simulations (found in Appendix B) that demonstrate that
our estimator has much lower bias than that of the standard quantile regression estimator when
the group-level treatment is endogenous, even in small samples, and at larger sample sizes our
estimator outperforms quantile regression even when the treatment is exogenous. Section 3 also
highlights additional computational benefits of our estimator.
We derive theoretical properties of the estimator in Section 4. The results are based on asymptotics where both the number of groups and the number of observations per group grow to infinity.
While linear panel models, including Hausman and Taylor (1981), admit a simple unbiased fixed
effects estimator and hence do not require asymptotics in the number of observations per group,
quantile estimators are biased in finite samples leading to inconsistency of our estimator if the
number of observations per group remains small as the number of groups increases, and making the
estimator inappropriate in the settings with a small number of observations per group and a large
number of groups. However, since quantile estimators are asymptotically unbiased, we are able to
employ Bahadur‚Äôs representation of quantile estimators to derive weak conditions on the growth of
the number of observations per group that are sufficient for the consistency and asymptotic zeromean normality of our estimator. Importantly, the attractive theoretical properties of the estimator
remain valid even if the number of observations per group is relatively small in comparison with
the number of groups. We demonstrate that standard errors for the proposed estimator can be
obtained using traditional robust variance estimators for 2SLS (heteroskedasticity-robust and clustered), making inference particularly simple. Finally, we show how to construct confidence bands
for the coefficient of interest which hold uniformly over a set of quantiles of interest via multiplier
bootstrap procedure.
Section 5 presents an empirical application which studies the effect of trade on the distribution
of wages within local labor markets. We build on the work of Autor, Dorn, and Hanson (2013), who
studied the effect of Chinese import competition on average wages in local labor markets. Using the
grouped IV quantile regression approach developed here, we find that Chinese import competition
reduced the wages of low-wage earners (individuals at the bottom quartile of the conditional wage
distribution) more than high-wage earners, particularly for females, heterogeneity which is missed
by focusing on traditional 2SLS estimates.
To the best of our knowledge, our paper is the first to present a framework for estimating
distributional effects as a function of group-level covariates. There is, however, a large literature
studying quantile models for panel data when the researcher wishes to estimate distributional effects
of micro-level covariates. See, for example, Koenker (2004), Abrevaya and Dahl (2008), Lamarche
(2010), Canay (2011), Galvao (2011), Kato and Galvao (2011), Ponomareva (2011), Kato, Galvao,
and Montes-Rojas (2012), Rosen (2012), Arellano and Bonhomme (2013), and Galvao and Wang
(2013). Our paper also contributes to the growing literature on IV treatment effects in quantile
models, such as Abadie, Angrist, and Imbens (2002), Chernozhukov and Hansen (2005, 2006, 2008),

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

3

Lee (2007), Chesher (2003), and Imbens and Newey (2009). Our paper differs, however, in that this
literature focuses on the case where individual-level unobserved heterogeneity is correlated with an
individual-level treatment, whereas we focus on the case where a group-level, additively separable
unobservable is correlated with a group-level treatment.
Throughout the paper, we use the following notation. The symbol k ¬∑ k denotes the Euclidean
norm. The symbol ‚áí signifies weak convergence, and l‚àû (U) represents the set of bounded functions
on U. With some abuse of notation, `‚àû (U) also denotes the set of component-wise bounded vectorvalued functions on U. All equalities and inequalities concerning random variables are implicitly
assumed to hold almost surely. All proofs and some extensions of our results are contained in the
Appendix.
2. Model
We study a panel data quantile regression model for a response variable yig of individual i in
group g. We first present the model in its most general form in equations (1) and (2) below and
then discuss a particular operationalization of the model in equation (3) that will be particularly
appealing for applied work. In the general model, we assume that the uth quantile of the conditional
distribution of yig is given by
0
Qyig |zig ,xg ,Œ±g (u) = zig
Œ±g (u), u ‚àà U

Œ±g,1 (u) = x0g Œ≤(u) + Œµg (u), u ‚àà U,

(1)
(2)

where Qyig |zig ,xg ,Œ±g (u) is the uth conditional quantile of yig given (zig , xg , Œ±g ), zig is a dz -vector
of observable individual-level covariates (which we sometimes refer to as micro-level covariates),
Œ±g = {Œ±g (u), u ‚àà U } is a set of group-specific effects with Œ±g,1 (u) being the first component of the
vector Œ±g (u) = (Œ±g,1 (u), . . . , Œ±g,dz (u))0 , xg is a dx -vector of observable group-level covariates (xg
contains a constant), Œ≤(u) is a dx -vector of coefficients, Œµg = {Œµg (u), u ‚àà U} is a set of unobservable
group-level random scalar shifters,3 and U is a set of quantile indices of interest. Thus, we assume
that the response variable yig satisfies the quantile regression model in (1) with group-specific
effects Œ±g (u). We are primarily interested in studying how these effects depend on the group-level
covariates xg , and, without loss of generality, we focus on Œ±g,1 (u), the first component of the vector
Œ±g (u). To make the problem operational, we assume that Œ±g,1 (u) satisfies the linear regression
model (2), in which we are interested in estimating the vector of coefficients Œ≤(u).
In empirical work, we envision that the most useful variant of the model (1)-(2) would be case
where the first element of zig corresponds to a constant and where coefficients on micro-level
3One interpretation of the term Œµ (u) in (2) is that it accounts for all unobservable group-level covariates Œ∑ that
g
g

affect Œ±g,1 (u) but are not included in xg . In this case, Œµg (u) = Œµ(u, Œ∑g ). Note that we do not impose any parametric
restrictions on Œµ(u, Œ∑g ), and so we allow for arbitrary nonlinear effects of the group-level unobservable covariates that
can affect different quantiles in different ways.

4

CHETVERIKOV, LARSEN, AND PALMER

covariates do not vary by group, given by the model
0
Qyig |ezig ,xg ,Œµg (u) = zeig
Œ≥(u) + x0g Œ≤(u) + Œµg (u), u ‚àà U,

(3)

which is obtained from (1)-(2) by assuming that (Œ±g,2 (u), . . . , Œ±g,dz (u))0 = Œ≥(u) for some nonstochastic (dz ‚àí 1)-vector Œ≥(u) and all g = 1, . . . , G, setting zig = (1, zeig )0 , and substituting (2) into
(1). This model allows for the analysis of location-shift effects of the group-level covariates xg on
the conditional distribution of yig in the group g.
As an example of where the above modeling framework is useful, consider a case in which a
researcher wishes to model the effects of a policy, contained in xg , which varies at the state-by-year
level (a ‚Äúgroup‚Äù in this setting) on the distribution of micro-level outcomes (such as individuals‚Äô
wages within each state-by-year combination), denoted yig , conditional on micro-level covariates,
such as education level, denoted zig . The framework in (3) would model the location-shift effect of
the policy on conditional quantiles of wages within a group, given by Œ≤(u). The additional flexibility
of (1)-(2) would also allow for interaction effects. For example, a policy xg may have differential
effects on lower wage quantiles for the less-educated than for the higher-educated; model (1) would
capture this idea by allowing the researcher to specify a linear regression model of the form of (2)
for the component of Œ±g that is the coefficient on education level, allowing the researcher to study
how the effect of education level on the wage distribution varies as a function of xg , the policy.4
In many applications, it is likely that the group-level covariates xg may be endogenous in the
sense that E[xg Œµg (u)] 6= 0, at least for some values of the quantile index u ‚àà U. Therefore, to
increase applicability of our results, we assume that there exists a dw -vector of observable instruments wg such that E[wg Œµg (u)] = 0 for all u ‚àà U, E[wg x0g ] is nonsingular, and yig is independent
of wg conditional on (zig , xg , Œ±g ).5 The first two conditions are familiar from the classical linear instrumental variable regression analysis, and the third condition requires the distribution of
yig to be independent of wg once we control for zig , xg , and Œ±g . It implies, in particular, that
0 Œ± (u) for all u ‚àà U.6
Qyig |zig ,xg ,Œ±g ,wg (u) = zig
g
4If the researcher is interested in modeling several effects, for example location-shift and some interaction effects,

she can specify a linear regression model of the form (2) for each effect.
5To understand the assumption that E[w Œµ (u)] = 0 holds jointly for all u ‚àà U, assume, for example, that
g g
Œµg (u) = Œµ(u, Œ∑g ) where Œ∑g is a vector of group-level omitted variables in regression (2). Then a sufficient condition for
the assumption E[wg Œµg (u)] = E[wg Œµ(u, Œ∑g )] = 0 is that E[Œµ(u, Œ∑g )|wg ] = 0. In turn, the restriction of the condition
E[Œµ(u, Œ∑g )|wg ] = 0 is that E[Œµ(u, Œ∑g )|wg ] does not depend on wg , which occurs (for example) if Œ∑g is independent of
wg . Once we assume that E[Œµ(u, Œ∑g )|wg ] does not depend on wg , the further restriction that E[Œµ(u, Œ∑g )|wg ] = 0 is a
normalization of the component of the vector Œ≤(u) corresponding to the constant in the vector xg .
6The setting we model differs from other IV quantile settings, such as Chernozhukov and Hansen (2005, 2006,
2008). Consider, for simplicity, our model (3) and assume that U = [0, 1]. Then the Skorohod representation implies
0
that yig = zeig
Œ≥(uig ) + x0g Œ≤(uig ) + Œµg (uig ) where uig is a random variable that is distributed uniformly on [0, 1] and

is independent of (e
zig , xg , Œµg ). Here, one can think of uig as unobserved individual-level heterogeneity. In this model,
the unobserved group-level component Œµg (¬∑) is modeled as an additively separable term. In contrast, the model in

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

5

We assume that a researcher has data on G groups and Ng individuals within group g = 1, ..., G.
Thus, the data consist of observations on {(zig , yig ), i = 1, . . . , Ng }, xg , and wg for g = 1, . . . , G.
Throughout the paper, we denote NG = min1‚â§g‚â§G Ng . For our asymptotic theory in Section 4, we
will assume that NG gets large as G ‚Üí ‚àû. Specifically, for the asymptotic zero-mean normality of
our estimator Œ≤ÃÇ(u) of Œ≤(u), we will assume that G2/3 (log NG )/NG ‚Üí 0 as G ‚Üí ‚àû; see Assumption 3
below. Thus, our results are useful when both G and NG are large, which occurs in many empirical
applications, but we also note that our results apply even if the number of observations per group
is relatively small in comparison with the number of groups.
We also emphasize that, like in the original panel data mean regression model of Hausman and
Taylor (1981), an important feature of our panel data quantile regression model is that it allows for
internal instruments. Specifically, if some component of the vector zig , say zig,k , is exogenous in the
‚àí1/2 PNg
sense that E[zig,k Œµg (u)] = 0 for all u ‚àà U, we can use, for example, Ng
i=1 zig,k as an additional
instrument provided it is correlated with xg , including it into the vector wg . Since in practice it is
often difficult to find an appropriate external instrument, allowing for internal instruments greatly
increases applicability of our results.
Our problem in this paper is different from that studied in Koenker (2004), Kato, Galvao, and
Montes-Rojas (2012), and Kato and Galvao (2011).7 Specifically, they considered the panel data
quantile regression model

0
Qyig |zig ,Œ±g (u) = zig
Œ≥(u) + Œ±g (u), u ‚àà U,

(4)

and developed estimators of Œ≥(u). Building on Koenker (2004), Kato, Galvao, and Montes-Rojas
(2012) suggested estimating Œ≥(u) in this model by running a quantile regression estimator of
Koenker and Bassett (1978) on the pooled data, treating {Œ±g (u), g = 1, . . . , G} as a set of parameters to be estimated jointly with the vector of parameters Œ≥(u) (the same technique can be
used to estimate Œ≥(u) in our model (3) by setting Œ±g (u) = x0g Œ≤(u) + Œµg (u)). They showed that their
estimator is asymptotically zero-mean normal if G2 (log G)3 /NG ‚Üí 0 as G ‚Üí ‚àû. Making further
progress, Kato and Galvao (2011) suggested an interesting smoothed quantile regression estimator

Chernozhukov and Hansen (2005, 2006, 2008) assumes that Œµg (u) = 0 for all u ‚àà [0, 1] and instead assumes that uig
is not independent of (e
zig , xg ). Thus, these two models are different and require different analysis.
7Our paper is also related to but different from Graham and Powell (2012) who studied the model that in our
0
notation would take the form yig = zig
Œ±g (uig ) where uig represents (potentially multi-dimensional) random unob-

served heterogeneity, and developed an interesting identification and estimation strategy for the parameter E[Œ±g (uig )],
achieving identification when the number of observations per group remains small as the number of groups gets large
and, under certain conditions, allowing Œ±g (¬∑) = Œ±ig (¬∑) to depend on i.

6

CHETVERIKOV, LARSEN, AND PALMER

of Œ≥(u) that is asymptotically zero-mean normal if G/NG ‚Üí 0.8 These papers do not provide a
model for our estimator of Œ≤(u), our primary object of interest, but instead focus solely on Œ≥(u).
Our model is also different from that studied in Hahn and Meinecke (2005), who considered an
extension of Hausman and Taylor (1981) to cover non-linear panel data models. Formally, they
considered a non-linear panel data model defined by the following equation:


0
E œï(yig , zig
Œ≥ + x0g Œ≤ + Œµg ) = 0
where œï(¬∑, ¬∑) is a vector of moment functions and x0g Œ≤ + Œµg is the group-specific effect. As in this
paper, the authors were interested in estimating the effect of group-level covariates (coefficient Œ≤)
without assuming that Œµg is independent (or mean-independent) of xg but assuming instead that
there exists an instrument wg satisfying E[wg Œµg ] = 0. Importantly, however, they assumed that
œï(¬∑, ¬∑) is a vector of smooth functions, so that their results do not apply immediately to our model.
In addition, Hahn and Meinecke (2005) required that NG /G > c for some c > 0 uniformly over all
G to prove that their estimator is asymptotically zero-mean normal. In contrast, as emphasized
above, we only require that G2/3 (log NG )/NG ‚Üí 0 as G ‚Üí ‚àû, with the improvement coming from
a better control of the residuals in the Bahadur representation.9
3. Estimator
In this section we develop our estimator. Our main emphasis is to derive a computationally
simple, yet consistent, estimator. The estimator consists of the following two stages.
Stage 1: For each group g and each quantile index u from the set U of indices of interest, estimate
uth quantile regression of yig on zig using the data {(yig , zig ) : i = 1, ..., Ng } by the classical quantile
regression estimator of Koenker and Bassett (1978):
Œ±ÃÇg (u) = arg min

a‚ààRdz

Ng
X

0
œÅu (yig ‚àí zig
a),

i=1

8To clarify the difference between the growth condition in our paper, which is G2/3 (log N )/N ‚Üí 0, and the
G
G

growth condition, for example, in Kato, Galvao, and Montes-Rojas (2012), which is G2 (log G)3 /NG ‚Üí 0, assume,
for simplicity, that dx = 1, dz = 2, and xg and the second component of zig are constants, that is, xg = 1 and
zig = (e
zig , 1)0 . Then our model (1)-(2) reduces to Qyig |ezig ,Œµg ,Œ±g (u) = zeig (Œ≤(u) + Œµg (u)) + Œ±g (u), which is similar to the
model (4) studied in Kato, Galvao, and Montes-Rojas (2012) with the exception that we allow for additional groupspecific random shifter Œµg (u). When Œµg (u) is present, our estimator Œ≤ÃÇ(u) of Œ≤(u) satisfies G1/2 (Œ≤ÃÇ(u)‚àíŒ≤(u)) ‚áí N (0, V1 )
for some non-vanishing variance V1 ; see Section 4. When Œµg (u) is set to zero, however, V1 vanishes, making the limiting
distribution degenerate and leading to faster convergence rate of the estimator Œ≤ÃÇ(u). In fact, when V1 vanishes, one
1/2

obtains (GNG )1/2 (Œ≤ÃÇ(u) ‚àí Œ≤(u)) ‚áí N (0, V2 ) for some non-vanishing variance V2 . An additional NG

factor in turn

appears in the residual terms of the Bahadur representation of the estimator Œ≤ÃÇ(u), which eventually lead to stronger
requirements on the growth of the number of observations per group NG relative to the number of groups, explaining
the difference between the growth condition in Kato, Galvao, and Montes-Rojas (2012) and our growth condition.
9Appendix F contains additional discussion of the model, including an extension to a random coefficients setting.

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

7

where œÅu (x) = (u ‚àí 1{x < 0})x for x ‚àà R. Denote Œ±ÃÇg (u) = (Œ±ÃÇg,1 (u), . . . , Œ±ÃÇg,dz )0 .
Stage 2: Estimate a 2SLS regression of Œ±ÃÇg,1 (u) on xg using wg as an instrument to get an estimator
Œ≤ÃÇ(u) of Œ≤(u), that is,
Œ≤ÃÇ(u) = X 0 PW X

‚àí1 

X 0 PW AÃÇ(u)



where X = (x1 , ..., xG )0 , W = (w1 , ..., wG )0 , AÃÇ(u) = (Œ±ÃÇ1,1 (u), . . . , Œ±ÃÇG,1 (u))0 , and PW = W (W 0 W )‚àí1 W 0 .
Intuitively, as the number of observations per group increases, Œ±ÃÇg,1 ‚àíŒ±g,1 shrinks to zero uniformly
over g = 1, . . . , G, and we obtain a classical instrumental variables problem. The theory presented
below provides a mild condition on the growth of the number of observations per group that is
sufficient to achieve consistency and asymptotic zero-mean normality of Œ≤ÃÇ(u).
Several special cases of our estimator are worth noting. First, when the model is given by
equation (3), the steps of our estimator consist of 1) group-by-group quantile regression of yig
on zÃÉig and on a constant, saving the estimated coefficient Œ±ÃÇg,1 (u) corresponding to the constant,
Œ±g,1 (u) = x0g Œ≤(u) + Œµg (u), in each group; and 2) regressing those saved coefficients Œ±ÃÇg,1 (u) on xg via
2SLS using wg as instruments. Second, if zig contains only a constant, the first stage simplifies to
selecting the uth quantile of the outcome variable yig within each group. Third, if xg is exogenous,
that is, E[xg Œµg (u)] = 0, OLS of Œ±ÃÇg,1 (u) on xg may be used rather than 2SLS in the second stage.
In this latter case, the grouped quantile estimation approach provides the advantage of handling
group-level unobservables (or, alternatively, left-hand-side measurement error), which would bias
the traditional Koenker and Bassett (1978) estimator. When zig only includes a constant and xg is
exogenous, the grouped IV quantile regression estimator Œ≤ÃÇ(u) simplifies to the minimum distance
estimator described in Chamberlain (1994) (see also Angrist, Chernozhukov, and Fernandez-Val
2006).
This estimator has several computational benefits relative to alternative methods. First, note
that when the model is given by equation (3), another approach to perform the first stage of
our estimator would be to denote Œ±g,1 (u) = x0g Œ≤(u) + Œµg (u) and estimate parameters Œ≥(u) and
{Œ±g,1 (u) : g = 1, . . . , G} jointly from the pooled dataset as in Kato, Galvao, and Montes-Rojas
(2012). This would provide an efficiency gain given that in this case, individual-level effects Œ≥(u)
are group-independent. Although the method we use is less efficient, it is computationally much
less demanding since only few parameters are estimated in each regression, which can greatly
reduce computation times in large datasets with many fixed effects.10 Second, even if no grouplevel unobservables exist (consider model (3) with Œµg (u) = 0 for all g = 1, . . . , G), the grouped
estimation approach can be considerably faster than the traditional Koenker and Bassett (1978)
10In Monte Carlo experiments in Appendix B, we find that jointly estimating group-level effects can take over 150

times as long as the grouped quantile approach when G = 200. With G > 200, the computation time ratio drastically
increases further, with standard optimization packages often failing to converge appropriately.

8

CHETVERIKOV, LARSEN, AND PALMER

estimator (though both estimators will be consistent). This computational advantage occurs when
the dimension of xg is large: standard quantile regression estimates Œ≤(u) in a single, nonlinear step,
whereas the grouped quantile approach estimates Œ≤(u) in a linear second stage.11
Monte Carlo simulations in Appendix B highlight the performance of our estimator for Œ≤(u) in
(3) relative to the traditional Koenker and Bassett (1978) estimator (which ignores endogeneity of
xg as well as the existence of Œµg (u)). Even when NG and G are both small, the grouped IV quantile
approach has lower bias than traditional quantile regression when xg is endogenous. When xg is
exogenous but group-level unobservables Œµg (u) are still present, the bias of the grouped quantile
approach shrinks quickly to zero as NG grows but the bias of traditional quantile estimator does not.
When no group-level unobservables are present, and hence both the grouped estimation approach
and traditional quantile regression should be consistent, our estimator still has small bias, although
traditional quantile regression outperforms our method in this case.
As we demonstrate in Section 4 below, standard errors for our estimator Œ≤ÃÇ(u) may be obtained
using standard heteroskedasticity-robust or clustering approaches for 2SLS or OLS as if there were
no first stage.12 Section 4 also describes a multiplier bootstrap procedure that is suitable for
constructing uniform confidence bands for the case when the researcher is interested in the set U
of quantile indices u.
To conclude this section, we note that our estimator applies to a wide variety of settings in labor,
industrial organization, trade, public finance, development, and other applied fields. Appendix A
illustrates examples from Angrist and Lang (2004), Larsen (2014), Palmer (2011), and Backus
(2014).
4. Asymptotic Theory
In this section, we formulate our assumptions and present the main theoretical results of the
paper.
4.1. Assumptions. Let cM , cf , CM , Cf , CL be strictly positive constants whose values are fixed
throughout the paper. Recall that NG = ming=1,...,G Ng . We start with specifying our main
assumptions.
A1 (Design). (i) Observations are independent across groups. (ii) For all g = 1, . . . , G, the pairs
(zig , yig ) are i.i.d. across i = 1, . . . , Ng conditional on (xg , Œ±g ).
A 2 (Instruments). (i) For all u ‚àà U and g = 1, . . . , G, E[wg Œµg (u)] = 0. (ii) As G ‚Üí ‚àû,
P
PG
0
‚àí1
0
G‚àí1 G
g=1 E[xg wg ] ‚Üí Qxw and G
g=1 E[wg wg ] ‚Üí Qww where Qxw and Qww are matrices with
11One such example would be a case where a group is a state-by-year combination, and x contains many state
g

and year fixed effects, in addition to the treatment of interest, as in Example 2 of Appendix A.
12Note that clustering in the second stage refers to dependence across groups, not within groups. For example,
if a group is a state-by-year combination, the researcher may wish to use standard errors which are clustered at the
state level.

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

9

singular values bounded in absolute value from below by cM and from above by CM . (iii) For all
g = 1, . . . , G and i = 1, . . . , Ng , yig is independent of wg conditional on (zig , xg , Œ±g ). (iv) For all
g = 1, . . . , G, E[kwg k4+cM ] ‚â§ CM .
A3 (Growth Condition). As G ‚Üí ‚àû, we have G2/3 (log NG )/NG ‚Üí 0.
Assumption 1(i) holds, for example, if groups are sampled randomly from some population of
groups. This assumption precludes the possibility of clustering across groups (for example, if a
group is a state-by-year combination, there may be clustering on the state level). Since clustered
standard errors are important in practice, however, we derive an extension of our results relaxing
the independence across groups condition and allowing for clustering in Appendix E. Assumption
1(ii) allows for inter-dependence (clustering) within groups but imposes the restriction that the
inter-dependence between observations within the group g is fully controlled for by the group-level
covariates xg and the group-specific effect Œ±g . Assumption 2 is our main identification condition.
‚àí1/2 PNg
Note that Assumption 2 allows for internal instruments. In particular, if wg = Ng
i=1 zig,k
for some k, then Assumption 2(iii) automatically follows from Assumption 1(ii). Assumption 3
implies that the number of observations per group grows sufficiently fast as G gets large, and gives
a particular growth rate that suffices for our results. Note that our growth condition is rather weak
and, most importantly, allows for the case when the number of observations per group is small
relative to the number of groups.13
Next, we specify technical conditions that are required for our analysis. Let Eg [¬∑] = E[¬∑|xg , Œ±g ],
and let fg (¬∑) denote the conditional density function of y1g given (z1g , xg , Œ±g ) (dependence of fg (¬∑) on
0 Œ± (u)‚àíc, z 0 Œ± (u)+c)
z1g is not shown explicitly for brevity of notation). Also denote Bg (u, c) = (z1g
g
1g g

for c > 0. We will assume the following regularity conditions:
A4 (Covariates). (i) For all g = 1, . . . , G and i = 1, . . . , Ng , random vectors zig and xg satisfy
0 ] are bounded
kzig k ‚â§ CM and kxg k ‚â§ CM . (ii) For all g = 1, . . . , G, all eigenvalues of Eg [z1g z1g

from below by cM .
A5 (Coefficients). For all u1 , u2 ‚àà U and g = 1, . . . , G, kŒ±g (u2 ) ‚àí Œ±g (u1 )k ‚â§ CL |u2 ‚àí u1 |.
A6 (Noise). (i) For all g = 1, . . . , G, E[supu‚ààU |Œµg (u)|4+cM ] ‚â§ CM . (ii) For some (matrix-valued)
P
0
function J : U √ó U ‚Üí Rdw √ódw , G‚àí1 G
g=1 E[Œµg (u1 )Œµg (u2 )wg wg ] ‚Üí J(u1 , u2 ) uniformly over u1 , u2 ‚àà
U. (iii) For all u1 , u2 ‚àà U, |Œµg (u2 ) ‚àí Œµg (u1 )| ‚â§ CL |u2 ‚àí u1 |.
A7 (Density). (i) For all u ‚àà U and g = 1, . . . , G, the conditional density function fg (¬∑) is continuously differentiable on Bg (u, cf ) with the derivative fg0 (¬∑) satisfying |fg0 (y)| ‚â§ Cf for all y ‚àà Bg (u, cf )
13Using the more common notation of panel data models, where N is the number of individuals (groups) and T is

the number of time periods (individuals within the group), Assumption 3 would take the form: N 2/3 (log T )/T ‚Üí 0
as N ‚Üí ‚àû.

10

CHETVERIKOV, LARSEN, AND PALMER

0 Œ± (u))| ‚â• c . (ii) For all u ‚àà U and g = 1, . . . , G, f (y) ‚â§ C for all y ‚àà B (u, c ) and
and |fg0 (z1g
g
g
g
f
f
f
0 Œ± (u)) ‚â• c .
fg (z1g
g
f

A8 (Quantile indices). The set of quantile indices U is a compact set included in (0, 1).
Assumption 4(i) requires that both individual and group-level observable covariates zig and xg are
bounded. Assumption 4(ii) is a familiar identification condition in regression analysis. Assumption
5 is a mild continuity condition. Assumption 6(i) requires sufficient integrability of the noise
Œµg (u), which is a mild regularity condition. In fact, under Assumption 6(iii), which is also a mild
continuity condition, Assumption 6(i) is satisfied as long as E[|Œµg (u)|4+cM ] ‚â§ CM for some u ‚àà U
(with a possibly different constant CM ). Assumption 6(ii) is trivially satisfied if the pairs (wg , Œµg )
are i.i.d. across g. Assumption 7 is a mild regularity condition that is typically imposed in the
quantile regression analysis. Finally, Assumption 8 excludes quantile indices that are too close to
either 0 or 1 (when the quantile index u is close to either 0 or 1, one obtains a so called extremal
quantile model, which requires a rather different analysis; see, for example, Chernozhukov (2005)
and Chernozhukov and FernaÃÅndez-Val (2011)).
4.2. Results. We now present our main results. We start by deriving the asymptotic distribution
of our estimator in Theorem 1. Further, we show how to estimate the asymptotic covariance of
our estimator in Theorem 2. Finally, we demonstrate how to obtain uniform over u ‚àà U confidence
bands for the parameter of interest {Œ≤(u), u ‚àà U } via a multiplier bootstrap method in Theorem
3. The first theorem derives the asymptotic distribution of our estimator.
Theorem 1 (Asymptotic Distribution). Let Assumptions 1-8 hold. Then
‚àö
G(Œ≤ÃÇ(¬∑) ‚àí Œ≤(¬∑)) ‚áí G(¬∑), in `‚àû (U)
where G(¬∑) is a zero-mean Gaussian process with uniformly continuous sample paths and covariance
‚àí1
0
function C(u1 , u2 ) = SJ(u1 , u2 )S 0 where S = Qxw Q‚àí1
Qxw Q‚àí1
ww Qxw
ww , Qxw and Qww appear in
Assumption 2, and J(u1 , u2 ) in Assumption 6.
Remark 1. (i) This is our main convergence result that establishes the asymptotic behavior of our
estimator. Note that we provide the joint asymptotic distribution of our estimator for all u ‚àà U.
In addition, Theorem 1 implies that for any u ‚àà U,
‚àö
G(Œ≤ÃÇ(u) ‚àí Œ≤(u)) ‚áí N (0, V )
where V = SJ(u, u)S 0 , which is the asymptotic distribution of the classical 2SLS estimator.
(ii) In order to establish the joint asymptotic distribution of our estimator for all u ‚àà U, we have
to deal with G independent quantile processes {Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u), u ‚àà U}. Since G ‚Üí ‚àû, classical
functional central limit theorems do not apply. Therefore, we employ a non-standard but powerful
Bracketing by Gaussian Hypotheses Theorem, which is also related to majorizing measures for
Gaussian processes; see Theorem 2.11.11 in Van der Vaart and Wellner (1996).

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

11

(iii) Since quantile regression estimators are biased in finite samples, our estimator Œ±ÃÇg,1 (u) of
Œ±g,1 (u) does not necessarily satisfy E[(Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u))wg ] = 0. For this reason, our estimator
Œ≤ÃÇ(u) of Œ≤(u) is not consistent if Ng is bounded from above uniformly over g = 1, . . . , G and
G ‚â• 2. We note, however, that quantile estimators are asymptotically unbiased, and so we use the
Bahadur representation of quantile estimators to derive weak condition on the growth of NG =
min1‚â§g‚â§G Ng relative to G, so that consistent estimation of Œ≤(u) is indeed possible. Specifically,
we prove consistency and asymptotic zero-mean normality under Assumption 3 that states that
G2/3 (log NG )/NG ‚Üí 0 as G ‚Üí ‚àû, which is a mild growth condition. In principle, it is also possible
to consider bias correction of the quantile regression estimators. This would further relax the growth
condition on NG relative to G at the expense of stronger side assumptions and more complicated
estimation procedures.
(iv) The requirement that NG ‚Üí ‚àû as G ‚Üí ‚àû is in contrast with the classical results of Hausman
and Taylor (1981) on estimation of panel data mean regression model. The main difference is
that the fixed effect estimator in the panel data mean regression model is unbiased even in finite
samples leading to consistent estimators of the effects of group-level covariates with the number of
observations per group being fixed.



The result in Theorem 1 derives asymptotic behavior of our estimator. In order to perform
inference, we also need an estimator of the asymptotic covariance function. We suggest using an
ÀÜ ¬∑) that is defined for all u1 , u2 ‚àà U as
estimator C(¬∑,
ÀÜ 1 , u2 ) = SÃÇ J(u
ÀÜ 1 , u2 )SÃÇ 0
C(u
where
G


X
ÀÜ 1 , u2 ) = 1
J(u
(Œ±ÃÇg,1 (u1 ) ‚àí x0g Œ≤ÃÇ(u1 ))(Œ±ÃÇg,2 (u2 ) ‚àí x0g Œ≤ÃÇ(u2 ))wg wg0 ,
G
g=1

0
0
‚àí1
‚àí1
0
SÃÇ = (QÃÇxw QÃÇ‚àí1
ww QÃÇxw ) QÃÇxw QÃÇww , QÃÇxw = X W/G, and QÃÇww = W W/G. In the theorem below, we
ÀÜ 1 , u2 ) is consistent for C(u1 , u2 ) uniformly over u1 , u2 ‚àà U.
show that C(u

ÀÜ 1 , u2 ) ‚àí C(u1 , u2 )k = op (1)
Theorem 2 (Estimating C). Let Assumptions 1-8 hold. Then kC(u
uniformly over u1 , u2 ‚àà U.
Remark 2. Theorems 1 and 2 can be used for hypothesis testing concerning Œ≤(u) for a given
quantile index u ‚àà U. In particular, we have that
‚àö
ÀÜ u)‚àí1/2 (Œ≤ÃÇ(u) ‚àí Œ≤(u)) ‚áí N (0, 1).
GC(u,

(5)

Importantly for applied researchers, Theorems 1 and 2 demonstrate that heteroskedasticity-robust
standard errors for our estimator can be obtained by the traditional White (1980) standard errors
where we proceed as if Œ±ÃÇg,1 (u) were equal to Œ±g,1 (u), that is, as if there were no first-stage estimation
error. Appendix E extends this result for clustered standard errors.



12

CHETVERIKOV, LARSEN, AND PALMER

Finally, we show how to obtain confidence bands for Œ≤(u) that hold uniformly over U.14 Observe
that Œ≤(u) is a dx -vector, that is, Œ≤(u) = (Œ≤1 (u), . . . , Œ≤dx (u))0 . Without loss of generality, we focus
on Œ≤1 (u), the first component of Œ≤(u). Let Œ≤ÃÇ1 (u), V (u), and VÃÇ (u) denote the first component of
ÀÜ u), respectively. Define
Œ≤ÃÇ(u), the (1, 1) component of C(u, u), and the (1, 1) component of C(u,
‚àö
T = sup G|VÃÇ (u)‚àí1/2 (Œ≤ÃÇ1 (u) ‚àí Œ≤1 (u))|,
(6)
u‚ààU

and let c1‚àíŒ± denote the (1 ‚àí Œ±) quantile of T . Then uniform confidence bands of level Œ± for Œ≤1 (u)
could be constructed as
s

s

Ô£Æ
Ô£∞Œ≤ÃÇ1 (u) ‚àí c1‚àíŒ±

VÃÇ (u)
, Œ≤ÃÇ1 (u) + c1‚àíŒ±
G

Ô£π
VÃÇ (u) Ô£ª
.
G

(7)

These confidence bands are infeasible, however, because c1‚àíŒ± is unknown. We suggest estimating
c1‚àíŒ± by the multiplier bootstrap method. To describe the method, let 1 , ..., G be an i.i.d. seS denote the 1st
quence of N (0, 1) random variables that are independent of the data. Also, let wÃÇg,1

component of the vector SÃÇwg . Then the multiplier bootstrap statistic is
G


X
1
S
g (Œ±ÃÇg,1 (u) ‚àí x0g Œ≤ÃÇ(u))wÃÇg,1
T M B = sup q
u‚ààU
GVÃÇ (u) g=1
The multiplier bootstrap critical value cÃÇ1‚àíŒ± is the conditional (1 ‚àí Œ±) quantile of T M B given the
data. Then a feasible version of uniform confidence bands is given by equation (7) with cÃÇ1‚àíŒ±
replacing c1‚àíŒ± . The validity of the method is established in the following theorem using the results
of Chernozhukov, Chetverikov, and Kato (2013).
Theorem 3 (Uniform Confidence Bands via Multiplier Bootstrap). Let Assumptions 1-8 hold. In
addition, suppose that all eigenvalues of J(u, u) are bounded away from zero uniformly over u ‚àà U.
Then
Ô£´

Ô£Æ

P Ô£≠Œ≤1 (u) ‚àà Ô£∞Œ≤ÃÇ1 (u) ‚àí cÃÇ1‚àíŒ±

s

s
VÃÇ (u)
, Œ≤ÃÇ1 (u) + cÃÇ1‚àíŒ±
G

Ô£π

Ô£∂

VÃÇ (u) Ô£ª
for all u ‚àà U Ô£∏ ‚Üí 1 ‚àí Œ±
G

as G ‚Üí ‚àû.
Remark 3. Uniform confidence bands are typically larger than the point-wise confidence bands
based on the result (5). The reason is that uniform confidence bands are constructed so that
the whole function {Œ≤(u), u ‚àà U } is contained in the bands with approximately 1 ‚àí Œ± probability
whereas point-wise bands are constructed so that for any given u ‚àà U, Œ≤(u) is contained in the
bands with approximately 1 ‚àí Œ± probability. Which confidence bands to use depends on the specific
purposes of the researcher.



14In addition, Appendix C presents an approach for uniform inference on the {Œ± (u)} in the model (1)‚Äì(2). In
g,1
l
r
particular, we construct the confidence bands [Œ±ÃÇg,1
(u), Œ±ÃÇg,1
(u)] that cover the true group-specific effects Œ±g,1 for all

g = 1, . . . , G simultaneously with probability approximately 1 ‚àí Œ±.

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

13

5. The effect of Chinese import competition on the local wage distribution
5.1. Background on wage inequality. Over the past 40 years, wage inequality within the United
States has increased drastically.15 Economists have engaged in heated debates about the primary
causes of the rising wage inequality‚Äîsuch as globalization, skill-biased technological change, or
the declining real minimum wage‚Äîand how the importance of these factors has changed over the
years.16 Recent work in Autor, Dorn, and Hanson (2013) (hereafter ADH) focused on import
competition and its effects on wages and employment in US local labor markets. ADH studied the
period 1990‚Äì2007, when the share of US spending on Chinese imports increased dramatically from
0.6% to 4.6%. For identification, the authors used spatial variation in manufacturing concentration,
showing that localized US labor markets which specialize in manufacturing were more affected by
increased import competition from China. The authors found that those markets which were more
exposed to increased import competition in turn had lower employment and lower wages.
We contribute to this debate by studying the effect of increased trade, in the form of increased
import competition, on the distribution of local wages (rather than on the average local wages as in
ADH). Given that we exploit the same variation in import competition as in ADH, we first describe
the ADH framework below and then present our results.
5.2. Framework of Autor, Dorn, and Hanson (2013). To study the effect of Chinese import
competition on average domestic wages, ADH used Census microdata to calculate the mean wage
within each Commuting Zone (CZ) in the United States.17 The authors then estimated the following
regression:
‚àÜln wg = Œ≤1 ‚àÜIP WgU + Xg0 Œ≤2 + Œµg

(8)

where ‚àÜln wg is the change in average individual log weekly wage in a given CZ in a given decade,
Xg are characteristics of the CZ and decade, including indicator variables for each decade. Note
that we have changed the notation slightly from that in ADH in order to improve clarity for our
application‚Äîa ‚Äúgroup‚Äù g in this setting is a given CZ in a given decade. The variable of interest is
‚àÜIP WgU , which represents the decadal change in Chinese imports per US worker for the CZ and
decade corresponding to group g.18
15Autor, Katz, and Kearney (2008) documented that, from 1963 to 2005, the change in wages for the 90th percentile

earner was 55% higher than for the 10th percentile earner.
16
See, for example, Leamer (1994), Krugman (2000), Feenstra and Hanson (1999), Katz and Autor (1999), as well
as many other papers cited in Feenstra (2010) or in Haskel, Lawrence, Leamer, and Slaughter (2012).
17
The United States is covered exhaustively by 722 Commuting Zones (Tolbert and Sizer 1996), each roughly
corresponding to a local labor market.
18Due to data limitations, ADH proxy for the change in actual local imports per worker with the weighted average
of industry-level changes in the value of Chinese imports to the US with the weights corresponding to the beginning
of decade employment share of each industry in each CZ.

14

CHETVERIKOV, LARSEN, AND PALMER

To address endogeneity concerns (i.e. that imports from China may be correlated with unobserved labor demand shocks), the authors instrumented for imports per last-period worker using
‚àÜIP WgO , a measure of import exposure that replaces the change in Chinese imports to the US in
a given industry with the change in Chinese imports to other similarly developed nations for the
same industry and uses one decade lagged employment shares in calculating the weighted average.
Using this 2SLS approach, the authors found that a $1,000 increase in Chinese imports per worker
in a CZ decreases average log weekly wage by -0.76 log points, corresponding to decrease in wages
for the average CZ of 0.9% from 1990‚Äì2000 and 1.4% from 2000‚Äì2007. When estimated separately
by gender, the effect was more negative for males (-0.89 log points) and less so for females (-0.61
log points).19

5.3. Distributional effects of increased import competition. We build on the ADH framework to analyze whether low-wage earners were more adversely affected than high-wage earners by
Chinese import competition. To apply the grouped IV quantile regression estimator to this setting,
we replace ‚àÜln wg , the change in the average log weekly wage in equation (8) with ‚àÜ ln wgu , the
change in the u-quantile of log wages in the CZ and decade corresponding to group g. We calculate
these quantiles using micro-level observations from the Census Integrated Public Use Micro Samples
for 1990 and 2000 and the American Community Survey for 2006-2008, matching these observations
to CZs following the strategy described in ADH.20 We instrument for ‚àÜIP WgU using ‚àÜIP WgO as
described above. Recall that existing methods for handling endogeneity in quantile models are
suited for the case where the individual-level unobserved conditional quantile itself is correlated
with the treatment and would be inconsistent in this setting because the endogeneity consists of a
group-level treatment being correlated with the group-level unobservable additive term.
Figures 1, 2, and 3 display the results of the grouped IV quantile regression estimator for the
full sample, for males only, and for females only. Each figure displays u-quantile estimates for
u ‚àà {0.05, 0.1, ..., 0.95}, along with pointwise 95% confidence bands about each estimate. The
figures also display the 2SLS effect found in ADH and 95% confidence intervals corresponding to
their IV estimate of Chinese import penetration on the change in CZ-level average wages.

19As discussed by ADH, the existence of an extensive-margin labor supply response‚Äîimports affecting whether

individuals are employed‚Äîmakes these results likely a lower-bound for the effect on all workers because we don‚Äôt
observe wages for the unemployed population.
20The thought experiment behind the asymptotics in this application is that the estimator is consistent as the
number of groups (G = 722 CZs √ó two decades) and the number of individuals within each group (NG = 543,
the size of the smallest group) both grow large. We follow ADH by clustering at the state level and weighting by
start-of-decade CZ population in the second stage of our estimator. To cluster, we are relying on Appendix E, which
relaxes Assumption 1 to allow for observations to be dependent across groups. We also follow the ADH individual
weighting procedure in the first stage given that not all individuals can be mapped to a unique CZ.

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

15

Each figure provides evidence that Chinese import competition affected the wages of low-wage
earners more than high-wage earners, demonstrating how increases in trade can causally exacerbate local income inequality. For all three samples, the magnitude of the estimated causal effect
of Chinese import penetration is much larger for lower quantiles of the conditional wage distribution. The point estimates suggest that the average negative effect of Chinese import penetration
estimated by ADH is primarily driven by large negative effects for those in the bottom tercile,
where the effect is twice as large as the average effect.21 Wages not in the bottom tercile were less
affected than the average‚ÄîFigure 1 shows that for most wage-earners (from the 0.35 quantile and
above) the effect of Chinese import competition was one-third smaller in magnitude than the effect
on the average estimated by ADH. Comparing the pattern of the coefficients across two gender
subsamples in Figures 2 and 3, there is more distributional heterogeneity for females than males,
a finding that additional testing shows is even more pronounced for non-college educated females.
For each sample, we can reject an effect size of zero for almost all quantiles below the median but
cannot for all quantiles above the median.

21A coefficient of -1.4 log points, e.g. for the lower quantiles of Figure 1, corresponds to a 2.6% decrease in wages

from 2000‚Äì2007 for the average commuting zone‚Äôs change in Chinese import exposure.

16

CHETVERIKOV, LARSEN, AND PALMER

References
Abadie, A., Angrist, J., and Imbens, G. (2002). Instrumental variables estimates of the effect of
subsidized training on the quantiles of trainee earnings. Econometrica, 70, 91‚Äì117.
Abrevaya, J. and Dahl, C. (2008). The effects of birth inputs on birthweight. Journal of Business
and Economic Statistics, 26, 379‚Äì397.
Altonji, J. and Matzkin, R. (2005). Cross section and panel data estimators for non separable
models with endogenous regressors. Econometrica, 73, 1053‚Äì1102.
Angrist, J. and Lang, K. (2004). Does school integration generate peer effects? Evidence from
Boston‚Äôs Metco Program. American Economic Review, 94, 1613‚Äì1634.
Angrist, J., Chernozhukov, V., and Fernandez-Val, I. (2006). Quantile regression under misspecification, with an application to the US wage structure. Econometrica, 74, 539‚Äì563.
Arellano, M. and Bonhomme, S. (2013). Random Effects Quantile Regression. Working paper.
Autor, D., Dorn, D., and Hanson, G. (2013). The China syndrome: Local labor market effects of
import competition in the United States. American Economic Review, 103(6), 2121‚Äì2168.
Autor, D. H., Katz, L. F., and Kearney, M. S. (2008). Trends in U.S. wage inequality: Revising the
revisionists. Review of Economics and Statistics, 90, 300‚Äì323.
Backus, M. (2014). Why is productivity correlated with competition? Working paper.
Baum-Snow, N. (2007). Did highways cause suburbanization? Quarterly Journal of Economics,
122, 775-805.
Belloni, A., Chernozhukov, V., and Hansen, C. (2006). Conditional quantile processes based on
series or many regressors. Working paper.
Canay, I. (2011). A simple approach to quantile regression for panel data. Econometrics Journal,
14, 368‚Äì386.
Chamberlain, G. (1994). Quantile regression, censoring, and the structure of wages. Advances in
Econometrics, Sixth World Congress, 171‚Äì209.
Chernozhukov, V. (2005). Extremal quantile regression. The Annals of Statistics, 33, 806‚Äì839.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2013). Gaussian approximations and multiplier
bootstrap for maxima of sums of high-dimensional random vectors. The Annals of Statistics, 41,
2786‚Äì2819.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2014a). Gaussian approximation of suprema of
empirical processes. The Annals of Statistics, 42, 1564-1597.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2014b). Anti-concentration and honest adaptive
confidence bands. The Annals of Statistics, forthcoming.
Chernozhukov, V., Chetverikov, D., and Kato, K. (2014c). Comparison and anti-concentration
bounds for maxima of Gaussian random vectors. Probab. Theory Related Fields, forthcoming.
Available at arXiv:1301.4807v3.

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

17

Chernozhukov, V., Chetverikov, D., and Kato, K. (2014d). Central limit theorems and bootstrap
in high dimensions. Available at arXiv:1412.3661v2.
Chernozhukov, V. and FernaÃÅndez-Val, I. (2011). Inference for extremal conditional quantile models,
with an application to market and birthweight risks. The Review of Economic Studies.
Chernozhukov, V. and Hansen, C. (2005). An IV model of quantile treatment effects. Econometrica,
73, 245‚Äì261.
Chernozhukov, V. and Hansen, C. (2006). Instrumental quantile regression inference for structural
and treatment effect models. Journal of Econometrics, 132, 491‚Äì525.
Chernozhukov, V. and Hansen, C. (2008). Instrumental variable quantile regression: A robust
inference approach. Journal of Econometrics, 142, 379‚Äì398.
Chesher, A. (2003). Identification in nonseparable models. Econometrica, 71, 1405‚Äì1441.
Feenstra, R. C. (2010). Offshoring in the global economy: Microeconomic structure and macroeconomic implications. Cambridge, MA: MIT Press.
Feenstra, R. C. and Hanson, G. H. (1999). The Impact of outsourcing and high-technology capital
on wages: Estimates for the U.S., 1979‚Äì1990. Quarterly Journal of Economics, 114(3), 907‚Äì940.
Florens, J. P., Heckman, J., Meghir, C., and Vytlacil, E. (2008). Identification of treatment effects using control functions in models with continuous endogenous treatment and heterogeneous
effects. Econometrica, 76, 1191‚Äì1206.
Galvao, A. (2011). Quantile regression for dynamic panel data with fixed effects. Journal of Econometrics, 164, 142‚Äì157.
Galvao, A. and Wang, L. (2013). Efficient minimum distance estimator for quantile regression fixed
effects panel data. Working paper.
Graham, B. and Powell, J. (2012). Identification and estimation of average partial effects in ‚Äúirregular‚Äù correlated random coefficient panel data models. Econometrica, 80, 2105‚Äì2152.
Hahn, J. and Meinecke, J. (2005). Time-invariant regressor in nonlinear panel model with fixed
effects. Econometric Theory, 21, 455‚Äì469.
Haskel, J., Lawrence, R., Leamer, E. E., and Slaughter, M. J. (2012). Globalization and U.S. wages:
Modifying classic theory to explain recent facts. Journal of Economic Perspectives, 26(2): 119‚Äì
40.
Hausman, J. (2001). Mismeasured variables in econometric analysis: Problems from the right and
problems from the left. Journal of Economic Perspectives, 15, 57‚Äì67.
Hausman, J. and Taylor, W. (1981). Panel data and unobservable individual effects. Econometrica,
49, 1377‚Äì1398.
Hausman, J., Luo, Y., and Palmer, C. (2014). Errors in the dependent variable of quantile regression
models. Working paper.
Heckman, J. and Vytlacil, E. (1998). Instrumental variables methods for the correlated random
coefficient model: Estimating the average rate of return to schooling when the return is correlated

18

CHETVERIKOV, LARSEN, AND PALMER

with schooling. The Journal of Human Resources, 33, 974-987.
Imbens, G. and Angrist, J. (1994). Identification and estimation of local average treatment effects.
Econometrica, 62, 467-475.
Imbens, G. and Newey, W. (2009). Identification and estimation of triangular simultaneous equations models without additivity. Econometrica, 77, 1481‚Äì1512.
Kato, K. and Galvao, A. (2011). Smoothed quantile regression for panel data. Working paper.
Kato, K., Galvao, A., and Montes-Rojas, G. (2012). Asymptotics for panel quantile regression
models with individual effects. Journal of Econometrics, 170, 76‚Äì91.
Katz, L. F. and Autor, D. (1999). Changes in the wage structure and earnings inequality, in Orley
Ashenfelter and David Card, eds., Handbook of Labor Economics, Vol. 3A, Amsterdam: Elsevier
Science, 1463‚Äì1555.
Koenker, R. (2004). Quantile regression for longitudinal data. Journal of Multivariate Analysis, 91,
74‚Äì89.
Koenker, R. (2005). Quantile regression. Econometric Society Monographs.
Koenker, R. and Bassett, J. (1978). Regression quantiles. Econometrica, 46, 33‚Äì50.
Krugman, P. (2000). Technology, trade and factor prices. Journal of International Economics ,
50(1), 51‚Äì71.
Lamarche, C. (2010). Robust penalized quantile regression estimation for panel data. Journal of
Econometrics, 157, 396‚Äì408.
Larsen, B. (2014). Occupational licensing and quality: Distributional and heterogeneous effects in
the teaching profession. Working paper.
Leamer, E. E. (1994). Trade, wages and revolving door ideas. NBER working paper no. 4716.
Lee, S. (2007). Endogeneity in quantile regression models: A control function approach. Journal of
Econometrics, 141, 1131‚Äì1158.
Lehmann, E. and Romano, J. (2005). Testing statistical hypotheses. Springer Texts in Statistics.
Masten, M. and Torgovitsky, A. (2014). Instrumental variables estimation of a generalized correlated
random coefficients model. Working paper.
Palmer, C. (2011). Suburbanization and urban decline. Working paper.
Ponomareva, M. (2011). Identification in quantile regression panel data models with fixed effects
and small T . Working paper.
Powell, J. (1984). Least absolute deviations estimation for the censored regression model. Journal
of Econometrics, 25, 303-325.
Rosen, A. (2012). Set identification via quantile restrictions in short panels. Journal of Econometrics, 166, 127‚Äì137.
Tao, T. (2012). Topics in random matrix theory. American Mathematica Society.
Tolbert, C. M. and Sizer, M. (1996). U.S. commuting zones and labor market areas. A 1990 update.
Economic Research Service Staff Paper No. 9614.

IV QUANTILE REGRESSION FOR GROUP-LEVEL TREATMENTS

19

Van der Vaart, A. (1998). Asymptotic Statistics. Cambridge University Press.
Van der Vaart, A. and Wellner, J. (1996). Weak convergence and empirical processes. Springer
Series in Statistics.
White, H. (1980). A Heteroskedasticity-consistent covariance matrix estimator and a direct test for
heteroskedasticity. Econometrica, 48, 817‚Äì838.

20

Figures

Figure 1. Effect of Chinese Import Competition on Conditional Wage Distribution:
Full Sample

Notes: Figure plots grouped IV quantile regression estimates of the effect of a $1,000 increase in Chinese imports
per worker on the conditional wage distribution (Œ≤1 in equation (8) in the text when the change in average log
wages for the commuting zone and decade corresponding to group g, ‚àÜln wg , is replaced with the change in the
u-quantile of log wages ‚àÜ ln wgu ). The dashed horizontal line is the ADH estimate of Œ≤1 in equation (8). 95%
pointwise confidence intervals are constructed from robust standard errors clustered by state and observations are
weighted by CZ population, as in ADH. Units on the vertical axis are log points.

Figures

21

Figure 2. Effect of Chinese Import Competition on Conditional Wage Distribution:
Males Only

Notes: Figure plots grouped IV quantile regression estimates for the male-only sample of the effect of a $1,000
increase in Chinese imports per worker on the male conditional wage distribution (Œ≤1 in equation (8) in the text
when the change in average log wages for the commuting zone and decade corresponding to group g, ‚àÜln wg , is
replaced with the change in the u-quantile of log wages ‚àÜ ln wgu ). The dashed horizontal line is the ADH estimate of
Œ≤1 in equation (8). 95% pointwise confidence intervals are constructed from robust standard errors clustered by
state and observations are weighted by CZ population, as in ADH. Units on the vertical axis are log points.

22

Figures

Figure 3. Effect of Chinese Import Competition on Conditional Wage Distribution:
Females Only

Notes: Figure plots grouped IV quantile regression estimates for the female-only sample of the effect of a $1,000
increase in Chinese imports per worker on the female conditional wage distribution (Œ≤1 in equation (8) in the text
when the change in average log wages for the commuting zone and decade corresponding to group g, ‚àÜln wg , is
replaced with the change in the u-quantile of log wages ‚àÜ ln wgu ). The dashed horizontal line is the ADH estimate of
Œ≤1 in equation (8). 95% pointwise confidence intervals are constructed from robust standard errors clustered by
state and observations are weighted by CZ population, as in ADH. Units on the vertical axis are log points.

Appendix

23

Appendix A. Examples of Grouped IV Quantile Regression
To help the reader envision applications of our estimator, in this section, we provide several
motivating examples of settings for which our estimator may be useful. Example 2 also provides
additional discussion of computational advantages of our estimator. Note that each of the following
examples involves estimation of a treatment effect that varies at the group level with all endogeneity
concerns also existing only at the group level.22
Example 1: Peer Effects of School Integration. Angrist and Lang (2004) studied how suburban student test scores were affected by the reassignment of participating urban students to
suburban schools through Boston‚Äôs Metco program. Before estimating their main instrumental
variables model, the authors tested for a relationship between the presence of urban students in
the classroom and the second decile of student test scores by estimating
Qyigjt |mgjt ,sgjt ,Œægjt ,Œ±g ,Œ≤j ,Œ≥t (0.2) = Œ±g + Œ≤j + Œ≥t + Œ¥mgjt + Œªsgjt + Œægjt

(9)

where the left-hand-side represents the second decile of student test scores within a group, where
each group is a grade g √ó school j √ó year t cell. The variables sgjt and mgjt denote the class size
and the fraction of Metco students within each g √ó j √ó t cell, and Œ±g , Œ≤j , and Œ≥t represent grade,
school, and year effects. The unobserved component, Œægjt , is analogous to the Œµg (0.2) of the special
form (3) of our model (1)‚Äì(2).
Angrist and Lang (2004) estimated equation (9) by OLS, which is equivalent to the non-IV
application of our estimator with no micro-level covariates. Similar to their OLS results on average
test scores, they found that classrooms with higher proportions of urban students have lower second
decile test scores. Once they instrumented for a classroom‚Äôs level of Metco exposure, the authors
found no effect on average test scores. However, by not estimating model (9) by 2SLS, they were
unable to address the causal distributional effects of Metco exposure.
In estimating (9), Angrist and Lang (2004) used heteroskedasticity-robust standard errors, which
we demonstrate in Section 4 is valid. The extension in Appendix E implies that the authors
could have instead allowed for clustering across groups in computing standard errors (for example,
clustering at the school level).
Example 2: Occupational Licensing and Quality. Larsen (2014) applied the estimator developed in this paper to study the effects of occupational licensing laws on the distribution of quality
within the teaching profession. This application uses a difference-in-differences approach. Similar
to Example 1, the explanatory variable of interest is treated as exogenous and the researcher is
concerned that there may be unobserved group-level disturbances. In this application, a group is
22

This is in contrast to settings where the endogeneity exists at the individual level, i.e. when the individual

unobserved heterogeneity is correlated with treatment. Such situations require a different approach than the one
presented here, e.g. Chernozhukov and Hansen (2005), Abadie, Angrist, and Imbens (2002), or other approaches
referenced in Section 1.

24

Appendix

a state-year combination (s, t), and micro-level data consists of teachers within a particular state
in a given year.
Let qist represent the quality of teacher i in state s who began teaching in survey year t, where
quality is proxied for by a continuous measure of the selectivity of the teacher‚Äôs undergraduate
institution. The conditional uth quantile of quality is modeled as
0
Qqist |Lawst ,Œµst (u) = Œ≥s (u) + Œªt (u) + Lawst
Œ¥(u) + Œµst (u)

(10)

where Œ≥s is a state effect; Œªt is a year effect; Lawst is a three-element vector containing dummies
equal to one if a subject test, basic skills test, or professional knowledge test was required in state
s in year t; and Œµst (u) represents group-level unobservables.
Because no micro-level covariates are included, the first stage of the grouped quantile estimator
is obtained by simply selecting the uth quantile of quality in a given state-year cell. The second
stage is obtained via OLS, and the author used heteroskedasticity-robust standard errors, which
are valid by the results in Section 4. Using the grouped quantile estimator, Larsen (2014) found
that, for first-year teachers, occupational licensing laws requiring teachers to pass a subject test
lead to a small but significant decrease in the upper tail of quality, suggestive that these laws may
drive some highly qualified candidates from the occupation.
In this setting, if micro-level covariates, zist , were included in the first stage of estimation, the
researcher could also estimate interaction effects of the group-level treatment and a micro-level
covariate, such as the percent of minority students at the teacher‚Äôs school. This would be done by
1) estimating quantile regression of qist on zist (which includes the percent of minority students
measure) separately for each (s, t) group and 2) saving each group-level estimate for the coefficient
corresponding to the percent minority variable, and then estimating a linear regression of these
coefficients on Lawst and on the state and year fixed effects.
This example highlights another useful feature of grouped IV quantile regression. Including many
variables in a standard quantile regression drastically increases the computational time (see Koenker
(2004), Lamarche (2010), Galvao and Wang (2013), and Galvao (2011) for further discussion) and,
in our experience, can often lead standard optimization packages to fail to converge. The grouped
quantile approach, on the other hand, can handle large numbers of variables easily when these
variables happen to be constant within group, as in the case of state and year fixed effects in this
example, because the coefficients corresponding to these variables can be estimated in the secondstage linear model, greatly reducing the number of parameters to be estimated in the nonlinear
first stage and hence reducing the computational burden significantly. Furthermore, this specific
computational advantage of the grouped quantile regression estimator exists even in cases where
both standard quantile regression and the grouped approach are valid (i.e. when no group-level
unobservables are present). Larsen (2014) found that the grouped approach was significantly faster
than estimating parameters in a single quantile regression.

Appendix

25

Example 3: Distributional Effects of Suburbanization. Palmer (2011) applied the grouped
quantile estimator to study the effects of suburbanization on resident outcomes. This application
illustrates the use of our estimator in an IV setting. In this application, a group is a metropolitan
statistical area (MSA), and individuals are MSA residents. As an identification strategy, Palmer
(2011) used the results of Baum-Snow (2007) in instrumenting suburbanization with planned highways.23
The model is
‚àÜQyigt |xg ,sg ,Œµg (u) = Œ≤(u) ¬∑ suburbanizationg + x0g Œ≥1 (u) + Œµg (u)
suburbanizationg = œÄ(u) ¬∑ planned highway raysg + x0g Œ≥2 (u) + vg (u)
where ‚àÜQy|xg ,sg ,Œµg (u) is the change in the uth quantile of log wages yigt within an MSA between
1950 and 1990 and xg is a vector of controls (including a constant) conditional upon which planned
highway raysg is uncorrelated with Œµg (u) and vg (u). The variable suburbanizationg is a proxy
measure of population decentralization, such as the amount of decline of central city population
density. Œ≤(u) is the coefficient of interest, capturing the effect of suburbanization on the withinMSA conditional wage distribution. For example, if the process of suburbanization had particularly
acute effects on the prospects of low-wage workers, we may expect Œ≤(u) to be negative for u = 0.1.
For a given u, the grouped IV quantile approach estimates Œ≤(u) through a 2SLS regression.
Example 4: The Relationship Between Productivity and Competition. Backus (2014)
studied the relationship between competition and productivity in the ready-mix concrete industry.
The author discussed the fact that competition and productivity are positively correlated, and
studied whether this relationship is similar for firms of all productivity levels (e.g. through encouraging better monitoring of firm managers or better investments), or whether increased competition
primarily affects the lower tail of the productivity distribution (driving out less productive firms).
Let œÅimt represent a measure of productivity of firm i in market m and time period t. Using
our notation, define a group as a pair m √ó t. The author assumes that œÅimt satisfies the following
quantile regression model:
QœÅmt |cmt ,nmt ,Œµmt (u) = Œ≤t (u) + cmt Œ≤c (u) + g(nmt , u) + Œµmt (u)

(11)

where cmt is a group-level measure of competition, nmt is the number of firms in the group, g(nmt , u)
is the third order polynomial of nmt ), and Œµmt is an unobserved group-level disturbance, which is
possibly correlated with cmt .
Backus (2014) instrumented for cmt using group-level measures which shift the demand for concrete. Thus, the IV regression in (11) represents an application of our estimator when group-level
23Baum-Snow (2007) instrumented for actual constructed highways with planned highways and estimated that

each highway ray emanating out of a city caused an 18% decline in central-city population.

26

Appendix

shocks are endogenous and no micro-level covariates are present. The author found some evidence that the effect of competition on the left tail of the productivity distribution may be more
positive than at some quantiles in the middle of the distribution (consistent with selection of lowproductivity firms out of the industry), but was unable to reject the hypothesis of a constant
effect.
Appendix B. Simulations
In order to investigate the properties of our estimator and compare to traditional quantile regression, we generate data according to the following model:
yig = zig Œ≥(uig ) + Œ¥(u) + xg Œ≤(uig ) + Œµg (uig )
xg = œÄwg + Œ∑g + ŒΩg
u
Œµg (u) = uŒ∑g ‚àí
2

(12)
(13)
(14)

where wg , ŒΩg , and zig are each distributed exp(0.25‚àó N [0, 1]); uig and Œ∑g are both distributed U [0, 1];
and random variables wg , ŒΩg , zig , uig , and Œ∑g are mutually independent. Note that the form
Œµg (u) = uŒ∑g ‚àí

u
2

implies E[Œµg (u)|wg ] = E[uŒ∑g ‚àí u/2|wg ] = E[uŒ∑g ‚àí u/2] = u/2 ‚àí u/2 = 0. The

quantile coefficient functions are Œ≥(u) = Œ≤(u) = u1/2 and Œ¥(u) = u/2. The parameter œÄ = 1.
We employ three variants of the data generating process described in (12)‚Äì(14). The first case is
exactly as in (12)‚Äì(14), with the group-level treatment of interest, xg , being endogenous (correlated
with Œµg through Œ∑g ). We estimate Œ≤(u) in this case using the grouped IV quantile estimator as well
as standard quantile regression (which ignores the endogeneity as well as the existence of Œµg ). In
the second case xg is exogenous, where we set xg = wg in (13). We estimate Œ≤(u) again in this
case using the grouped quantile approach as well as standard quantile regression, where the latter
ignores the existence of Œµg . In the third case xg is exogenous and no group-level unobservables are
included, where we set xg = wg and Œµg = 0. In this latter case, both grouped quantile regression
and standard quantile regression should be consistent.
We perform these exercises with the number of groups (G) and the number of observations per
group (N ) given by (N, G) =(25,25), (200,25), (25,200), (200,200). 1,000 Monte Carlo replications
were used. The results are displayed in Table I. Each panel displays the bias from the procedure
for each decile (u = 0.1, ..., 0.9) as well as the average absolute value of that bias, averaged over the
nine deciles.
The top panel of Table I demonstrates that in the endogenous group-level treatment case the
magnitude of the bias is much smaller in our estimator than in standard quantile regression, and the
bias of our estimator disappears as N and G increase, while the bias of quantile regression remains
constant (0.196 on average). The middle panel considers the case where xg is exogenous but grouplevel unobservables are present (or, equivalently, left-hand-side measurement error exists in the
quantile regression). At some quantiles, standard quantile regression has a bias which is smaller in

Appendix

27

magnitude than the grouped approach, in particular in the cases where N = 25. However, as N
increases, the magnitude of the bias of the grouped estimator falls close to zero on average while
that of standard quantile regression remains about three times as high at 0.01. Finally, the bottom
panel focuses on the case in which no group-level unobservables exist and hence standard quantile
regression is unbiased. In this case, we find that the bias of standard quantile regression is indeed
lower than that of the grouped quantile approach, but the bias of the grouped quantile method
also diminishes rapidly as N and G grow.
To illustrate the computational burden which our estimator overcomes, we redid the first stage
estimation with Œ≥(¬∑) and group-level fixed effects‚ÄîŒ±g from Section 2‚Äîestimated jointly in one large
quantile regression rather than estimating group-by-group quantile regression. We performed 100
replications due to the computational burden of the joint estimation. We found that in the (N, G) =
(25, 25) case the joint estimation took only slightly longer than than the group-by-group approach;
with (N, G) = (200, 25) the group-by-group approach was ten times faster; with (N, G) = (25, 200)
the group-by-group approach was over forty times as fast; and in the (N, G) = (200, 200) the groupby-group approach was over 150 times as fast, with estimation on a single replication sample for
the nine deciles taking over three minutes, while the the grouped quantile approach performed the
same exercise in 1.22 seconds.24 This exercise illustrates the benefit of the group-by-group approach
to estimating Œ±g and also illustrates that, in general, standard quantile regression can be very slow
when a large number of explanatory variable is included. The grouped quantile approach can
greatly reduce this computational burden by handling all group-level explanatory variables linearly
in the second stage (implying that the grouped quantile approach can be especially beneficial if the
dimension of xg is large).
Appendix C. Joint Inference on Group-Specific Effects
In this section, we are concerned with inference on group-specific effects Œ±g,1 (u), g = 1, . . . , G,
in the model (1)-(2) defined in Section 2. In particular, we are interested in constructing the
l , Œ±ÃÇr ] for Œ± (u) that are adjusted for multiplicity of the effects, that is, we
confidence bands [Œ±ÃÇg,1
g,1
g,1

would like to have the bands satisfying
l
r
P (Œ±g,1 (u) ‚àà [Œ±ÃÇg,1
, Œ±ÃÇg,1
] for all g = 1, . . . , G) ‚Üí 1 ‚àí Œ±.

(15)

l , Œ±ÃÇr ] cover the true group-specific effects Œ±
Thus, the confidence bands [Œ±ÃÇg,1
g,1 for all g = 1, . . . , G
g,1

simultaneously with probability approximately 1 ‚àí Œ±.
The main challenge here is that we have G parameters Œ±g,1 (u), g = 1, . . . , G, and only Ng observations to estimate Œ±g,1 where Ng is potentially smaller than G (recall that we impose Assumption
24With G > 200, the computation time ratio drastically increases further, with standard optimization packages

often failing to converge appropriately.

28

Appendix

3, according to which G2/3 (log NG )/NG ‚Üí 0 as G ‚Üí ‚àû where NG = ming=1,...,G Ng ). To decrease
technicalities, in this section we assume that U = {u}, that is, U is a singleton.
1/2

It is well-known that as Ng ‚Üí ‚àû, Ng (Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u)) ‚áí N (0, Ig ) where Ig is the (1, 1)th ele0 ]J (u)‚àí1 ; see, for example, Koenker (2005). Therefore,
ment of the matrix u(1 ‚àí u)Jg (u)‚àí1 Eg [zig zig
g

letting c1‚àíŒ± be the (1 ‚àí Œ±) quantile of |Y | where Y ‚àº N (0, 1), we obtain
s
s #!
"
Ig
Ig
P Œ±g,1 (u) ‚àà Œ±ÃÇg,1 (u) ‚àí c1‚àíŒ±
, Œ±ÃÇg,1 (u) + c1‚àíŒ±
‚Üí 1 ‚àí Œ± as Ng ‚Üí ‚àû.
Ng
Ng

(16)

In practice, Ig is typically unknown, however, and has to be estimated from the data. For example,
one can use a method developed in Powell (1984). Letting IÀÜg denote a suitable estimator of Ig , it
is standard to show that (16) continues to hold if we replace Ig with IÀÜg as long as IÀÜg ‚Üíp Ig .
The drawback of the confidence bands in (16), however, is that they do not take into account
multiplicity of the effects Œ±g,1 (u), g = 1, . . . , G. This is especially important given that G is large.
To fix this problem, we would like to adjust the constant c1‚àíŒ± in (16) so that the events under the
probability sign in (16) hold simultaneously for all g = 1, . . . , G with probability asymptotically
equal to 1 ‚àí Œ±. The theorem below shows that this can be achieved by replacing c1‚àíŒ± with cM
1‚àíŒ± ,
the (1 ‚àí Œ±) quantile of max1‚â§g‚â§G |Yg | where Y1 , . . . , YG are i.i.d. N (0, 1) random variables. To
decrease technicalities, we assume in the theorem that all Ig ‚Äôs are known.
Theorem 4 (Joint Inference on Group-Specific Effects). Let Assumptions 1-8 hold. In addition,
suppose that Ig ‚â• cM for all g = 1, . . . , G and NÃÑG /NG ‚â§ CM where NG = min1‚â§g‚â§G Ng and
NÃÑG = max1‚â§g‚â§G Ng . Let cM
1‚àíŒ± be the (1 ‚àí Œ±) quantile of max1‚â§g‚â§G |Yg | where Y1 , . . . , YG are i.i.d.
N (0, 1) random variables. Then
"
P

Œ±g,1 (u) ‚àà Œ±ÃÇg,1 (u) ‚àí

s

cM
1‚àíŒ±

Ig
, Œ±ÃÇg,1 (u) + cM
1‚àíŒ±
Ng

s

Ig
Ng

#

!
for all g = 1, . . . , G

‚Üí1‚àíŒ±

as G ‚Üí ‚àû.
Appendix D. Sub-gaussian Tail Bound
In this section, we derive the sub-gaussian tail bound for the quantile regression estimator. This
bound plays an important role in deriving the asymptotic distribution of our estimator, which is
given in Theorem 1.
Theorem 5 (Sub-Gaussian Tail Bound for Quantile Estimator). Let Assumptions 1-8 hold. Then
there exist constants cÃÑ, c, C > 0 that depend only on cM , cf , CM , Cf , CL such that for all g = 1, ..., G
and x ‚àà (0, cÃÑ),

P


2
sup kŒ±ÃÇg (u) ‚àí Œ±g (u)k > x ‚â§ Ce‚àícx Ng .

u‚ààU

(17)

Appendix

29

Remark 4. The bound provided in Theorem 5 is non-asymptotic. In principle, it is also possible
to calculate the exact constants in the inequality (17). We do not calculate these constants because
they are not needed for our results. Since Œ±ÃÇg,1 (u) is the classical Koenker and Bassett‚Äôs (1978)
quantile regression estimator of Œ±g (u), Theorem 5 may also be of independent interest. The theorem
implies that large deviations of the quantile estimator from the true value are extremely unlikely
under our conditions.


Appendix E. Clustered Standard Errors

In this section, we consider the model from the main text, which is defined in equations (1)‚Äì(2),
but we seek to relax the independence across groups condition appearing in Assumption 1(i). In
particular, in this section we allow for cluster sampling and derive the results that are analogous
to Theorems 1 - 3 in the main text.
We assume that the data consist of M = MG clusters of groups, and that there exists a correspondence CG : {1, . . . , M } ‚áí {1, . . . , G} such that (i) for each m = 1, . . . , M , CG (m) denotes
the set of groups corresponding to cluster m, (ii) for m, m0 = 1, . . . , M with m 6= m0 , the set
CG (m) ‚à© CG (m0 ) is empty, and (iii) for any g = 1, . . . , G, there exists m = 1, . . . , M such that
g ‚àà CG (m). Thus, the correspondence CG (¬∑) partitions groups into M clusters. Using this notation, we replace Assumption 1 with the following condition:
A10 (Design). (i) Observations are independent across clusters m = 1, . . . , M . (ii) For all g =
1, . . . , G, the pairs (zig , yig ) are i.i.d. across i = 1, . . . , Ng conditional on (xg , Œ±g ). (iii) For each
m = 1, . . . , M , the number of elements in the set CG (m) is bounded from above by some constant
CÃÑ, which is independent of G.
Assumption 10 (i) relaxes Assumption 1(i) from the main text by requiring independence across
clusters instead of independence across groups. Assumption 10 (ii) is the same as Assumption 1(ii).
Assumption 10 (iii) imposes the condition that the number of groups within each cluster remains
small as the number of groups gets large.
In addition, we replace Assumption 6 with the following condition:
A60 (Noise). (i) For all g = 1, . . . , G, E[supu‚ààU |Œµg (u)|4+cM ] ‚â§ CM . (ii) For some (matrix-valued)
function J CS : U √ó U ‚Üí Rdw √ódw ,
Ô£ÆÔ£´
Ô£∂Ô£´
M
X
X
X
1
E Ô£∞Ô£≠
Œµg (u1 )wg Ô£∏ Ô£≠
G
m=1

g‚ààCG (m)

Ô£∂Ô£π
Œµg (u1 )wg0 Ô£∏Ô£ª ‚Üí J CS (u1 , u2 )

g‚ààCG (m)

uniformly over u1 , u2 ‚àà U. (iii) For all u1 , u2 ‚àà U, |Œµg (u2 ) ‚àí Œµg (u1 )| ‚â§ CL |u2 ‚àí u1 |.
Assumptions 60 (i) and 60 (iii) are the same as Assumptions 6(i) and 6(iii). Assumption 60 (ii) is a
P
modification of Assumption 6(ii) adjusting the asymptotic covariance function of G‚àí1/2 G
g=1 Œµg (¬∑)wg

30

Appendix

to allow for clustering. When CG (m) contains only one group for each m = 1, . . . , M , Assumption
60 (ii) reduces to Assumption 6(ii).
Like in the classical cross-section cluster sampling setup, allowing for clustering in our model
does not require adjusting the estimator. Therefore, we study the properties of the estimator Œ≤ÃÇ(u)
of parameter Œ≤(u), u ‚àà U, defined in Section 3. Our first theorem in this section describes the
asymptotic distribution of Œ≤ÃÇ(u).
Theorem 6 (Asymptotic Distribution under Cluster Sampling). Let Assumptions 10 , 2-5, 60 , 7,
and 8 hold. Then

‚àö

G(Œ≤ÃÇ(¬∑) ‚àí Œ≤(¬∑)) ‚áí GCS (¬∑), in `‚àû (U)

where GCS (¬∑) is a zero-mean Gaussian process with uniformly continuous sample paths and covari0
‚àí1
‚àí1
ance function C CS (u1 , u2 ) = SJ CS (u1 , u2 )S 0 where S = (Qxw Q‚àí1
ww Qxw ) Qxw Qww , Qxw and Qww

appear in Assumption 2, and J CS (u1 , u2 ) in Assumption 60 .
Next, we discuss how to estimate the covariance function C CS (¬∑, ¬∑) of the limiting Gaussian process
GCS (¬∑). We suggest estimating C CS (¬∑, ¬∑) by CÀÜCS (¬∑, ¬∑) defined for all u1 , u2 ‚àà U as
CÀÜCS (u1 , u2 ) = SÃÇ JÀÜCS (u1 , u2 )SÃÇ 0
where
Ô£´
Ô£∂Ô£´
Ô£∂
M
X
X
X
1
Ô£≠
JÀÜCS (u1 , u2 ) =
(Œ±ÃÇg,1 (u1 ) ‚àí x0g Œ≤ÃÇ(u1 ))wg Ô£∏ Ô£≠
(Œ±ÃÇg,2 (u2 ) ‚àí x0g Œ≤ÃÇ(u2 ))wg0 Ô£∏ ,
G
m=1

g‚ààCG (m)

g‚ààCG (m)

0
‚àí1
‚àí1
0
0
SÃÇ = (QÃÇxw QÃÇ‚àí1
ww QÃÇxw ) QÃÇxw QÃÇww , QÃÇxw = X W/G, QÃÇww = W W/G. In the theorem below, we show
that CÀÜCS (u1 , u2 ) is consistent for C CS (u1 , u2 ) uniformly over u1 , u2 ‚àà U.

Theorem 7 (Estimating C CS under Cluster Sampling). Let Assumptions 10 , 2-5, 60 , 7, and 8 hold.
Then kCÀÜCS (u1 , u2 ) ‚àí C CS (u1 , u2 )k = op (1) uniformly over u1 , u2 ‚àà U.
Finally, we show how to obtain confidence bands for Œ≤(u) that hold uniformly over U. Observe
that Œ≤(u) is a dx -vector, that is, Œ≤(u) = (Œ≤1 (u), . . . , Œ≤dx (u))0 . As in the main text, we focus on Œ≤1 (u),
the first component of Œ≤(u), and we suggest constructing uniform confidence bands via multiplier
bootstrap method. An important difference from the results in the main text is that now we should
bootstrap on the cluster level.
Specifically, let Œ≤ÃÇ1 (u), V CS (u), and VÃÇ CS (u) denote the 1st component of Œ≤ÃÇ(u), the (1, 1)st
component of C CS (u, u), and the (1, 1)st component of CÀÜCS (u, u), respectively. Define
‚àö
T = sup

G|VÃÇ (u)‚àí1/2 (Œ≤ÃÇ1 (u) ‚àí Œ≤1 (u))|,

(18)

u‚ààU

and let c1‚àíŒ± denote the (1 ‚àí Œ±) quantile of T . As in the main text, we estimate c1‚àíŒ± by the
multiplier bootstrap method. Let 1 , ..., M be an i.i.d. sequence of N (0, 1) random variables that

Appendix

31

S denote the 1st component of the vector SÃÇw . Then the
are independent of the data. Also, let wÃÇg,1
g

multiplier bootstrap statistic is
1

M
X

Ô£´

Ô£∂
X

S Ô£∏
T M B = sup q
m Ô£≠
(Œ±ÃÇg,1 (u) ‚àí x0g Œ≤ÃÇ(u))wÃÇg,1
u‚ààU
GVÃÇ (u) m=1
g‚ààCG (m)

The multiplier bootstrap critical value cÃÇ1‚àíŒ± is the conditional (1 ‚àí Œ±) quantile of T M B given the
data. Our final theorem in this section explains how to construct uniform confidence bands using
cÃÇ1‚àíŒ± .
Theorem 8 (Uniform Confidence Bands via Multiplier Bootstrap under Cluster Sampling). Let
Assumptions 10 , 2-5, 60 , 7, and 8 hold. In addition, suppose that all eigenvalues of J CS (u, u) are
bounded away from zero uniformly over u ‚àà U. Then
s
s
Ô£π
Ô£∂
Ô£´
Ô£Æ
VÃÇ (u)
VÃÇ (u) Ô£ª
, Œ≤ÃÇ1 (u) + cÃÇ1‚àíŒ±
for all u ‚àà U Ô£∏ ‚Üí 1 ‚àí Œ±
P Ô£≠Œ≤1 (u) ‚àà Ô£∞Œ≤ÃÇ1 (u) ‚àí cÃÇ1‚àíŒ±
G
G
as G ‚Üí ‚àû.
Appendix F. Further Discussion of the Model in Section 2
In this section, we provide further discussion of our model in Section 2, give a structural interpretation, and outline possible extensions.
F.1. Structural Model Justifying the Model in Section 2. Consider the following structural
model:
0
yig = zig
Œ±
eg (e
uig )

(19)

where yig is the response variable of individual i in group g, zig is a vector of observable individuallevel covariates, u
eig is unobserved scalar heterogeneity with values in [0, 1], and Œ±
eg = {e
Œ±g (u), u ‚àà
[0, 1]} is a group-specific effect. We assume that the group-specific effect Œ±
eg is determined by
vectors of observable and unobservable group-level covariates xg and œàg , respectively, that is,
Œ±
eg (u) = Œ±
e(u, xg , œàg ) for some function Œ±
e.
In many empirical settings, it is natural to expect that the distribution of u
eig varies across groups,
so that the distribution function Fg : [0, 1] ‚Üí [0, 1] of u
eig in group g is indexed by g. We assume that
Fg is determined by a vector of unobservable group-level covariates ŒΩg , that is, Fg (u) = F (u, ŒΩg )
for some function F . Let F ‚àí1 (u, ŒΩg ) denote the (generalized) inverse of the function u 7‚Üí F (u, ŒΩg ).
Further, we assume that u
eig is independent of zig conditional on (xg , œàg , ŒΩg ), which can be
considered analogous to the usual independence condition of quantile regression analysis for crosssectional data adapted to group/panel data as considered here. Under this condition,
u
eig = F ‚àí1 (uig , ŒΩg )

32

Appendix

for a random variable uig that is distributed uniformly on [0, 1] and that is independent of (zig , xg , œàg , ŒΩg ).
Therefore, denoting
Œ±g (u) = Œ±(u, xg , œàg , ŒΩg ) = Œ±
e(F ‚àí1 (u, ŒΩg ), xg , œàg ),
rewriting the model (19) as
0
yig = zig
Œ±(uig , xg , œàg , ŒΩg ),
0 Œ±(u , x , œà , ŒΩ ) is strictly increasing with probability one,
and assuming that the function u 7‚Üí zig
ig g
g g

we obtain the following quantile regression model:
0
Qyig |zig ,xg ,œàg ,ŒΩg (u) = zig
Œ±g (u), u ‚àà [0, 1],

which in turn implies that
0
Qyig |zig ,xg ,Œ±g (u) = zig
Œ±g (u), u ‚àà [0, 1],

(20)

where Qyig |zig ,xg ,œàg ,ŒΩg (u) denotes the uth quantile of the conditional distributional of yig given
(zig , xg , œàg , ŒΩg ) and Qyig |zig ,xg ,Œ±g (u) denotes the uth quantile of the conditional distribution of yig
given (zig , xg , Œ±g ) with Œ±g = {Œ±g (u), u ‚àà [0, 1]}.
Equation (1) with any U ‚äÇ [0, 1] in Section 2 follows from (20). In turn, equation (2) in Section
2 arises if Œ±1 (u, xg , œàg , ŒΩg ), the first component of the vector Œ±(u, xg , œàg , ŒΩg ), can be reasonably
well approximated by x0g Œ≤(u) + Œµg (u) where Œµg (u) = Œµ(u, œàg , ŒΩg ), which is a typical assumption in
applied regression analysis. This provides a structural interpretation of the model in Section 2.
An advantage of this interpretation is that it yields additional intuition behind the condition
that E[wg Œµg (u)] = 0 for all u ‚àà U imposed on the instrument wg in Section 2. In particular, as
explained in footnote 5, as long as the vector xg contains the constant, this condition follows if
wg is independent of Œ∑g where Œ∑g is such that Œµg (u) = Œµ(u, Œ∑g ). In this section, we have Œµg (u) =
Œµ(u, œàg , ŒΩg ), so that Œ∑g = (œàg , ŒΩg ). Thus, the instrument wg should be independent both of œàg , a
vector of unobserved group-level covariates governing group-specific effects Œ±
eg (u) = Œ±
e(u, xg , œàg ),
and of ŒΩg , a vector of unobserved group-level covariates governing the distribution of unobserved
heterogeneity Fg (u) = F (u, ŒΩg ). Both of these conditions are reasonable in our empirical application
in Section 5.
F.2. Extension based on a Random Coefficient Model. One of the conditions we used in
the discussion above is a functional form assumption that Œ±1 (u, xg , œàg , ŒΩg ) can be reasonably well
approximated by a linear form x0g Œ≤(u) + Œµg (u) where Œµg (u) = Œµ(u, œàg , ŒΩg ). Here linearity in xg is a
rather flexible assumption because we can always replace xg by a set of different transformations
of xg whose linear combinations can approximate the function xg 7‚Üí Œ±1 (u, xg , œàg , ŒΩg ) sufficiently
well. On the other hand, additive separability of x0g Œ≤(u) and Œµg (u) may be difficult to justify on
theoretical grounds. If this is the case, a better approximation of Œ±1 (u, xg , œàg , ŒΩg ) can be given by

Appendix

33

x0g Œ≤g (u) where Œ≤g (u) = Œ≤(u, œàg , ŒΩg ). Therefore, in this section, we briefly comment on how one can
estimate the model given by
0
Qyig |zig ,xg ,Œ±g (u) = zig
Œ±g (u), u ‚àà U,

Œ±g,1 (u) = x0g Œ≤g (u), u ‚àà U,

(21)

where we use the same notation as above and where (21) can be thought of as a random coefficient
model since Œ≤g (u) = Œ≤(u, œàg , ŒΩg ). Throughout this section, we assume that the instrument wg is
independent of the pair (œàg , ŒΩg ), which, as explained above, strengthens the condition E[wg Œµg (u)] =
0 for all u ‚àà U used in Section 2. Observe that this assumption implies that Œ≤g (u) is independent
of wg .
In this model, one can use the same first stage procedure to estimate group-specific effects
Œ±g (u), that is, one can run a quantile regression on the data {(zig , yig ), i = 1, . . . , Ng } separately in
each group g to find the estimators Œ±ÃÇg (u) of Œ±g (u). If the number of observations per group grows
sufficiently fast as the number of groups gets large, Œ±ÃÇg (u) will consistently estimate Œ±g (u) uniformly
over g = 1, . . . , G. In the second stage, we will have to replace the 2SLS estimator suitable for (2) by
an estimator suitable for (21). Given that Œ≤g (u) is independent of wg , several approaches developed
in the literature can be applied to learn some features of the distribution of Œ≤g (u) = Œ≤(u, œàg , ŒΩg )
depending on what side conditions we impose on the model; see, for example, Imbens and Angrist
(1994), Heckman and Vytlacil (1998), Florens, Heckman, Meghir, and Vytlacil (2008), and Masten
and Torgovitsky (2014). For concreteness, we describe here the approach developed by Masten and
Torgovitsky (2014), which, under certain control variable assumptions and some other technical
assumptions, yields consistent estimates of Œ≤ÃÑ(u) = E[Œ≤g (u)].
To explain their procedure, assume, for simplicity, that there is only one endogenous covariate
eg = (xg,2 , . . . , xg,dx ‚àí1 )0 is
among the vector of covariates xg , that is, xg = (1, x
eg , xg,dx )0 where x
independent of (œàg , ŒΩg ). Assume that xg is continuously distributed, and xg,dx = h(wg , vg ) where
the function v 7‚Üí h(wg , v) is increasing with probability one, and the (scalar) random variable
vg is such that wg is independent of (œàg , ŒΩg , vg ) (control variable assumption). Then Masten and
Torgovitsky (2014) show that under some further technical conditions, Œ≤ÃÑ(u) = E[Œ≤g (u)] can be
consistently estimated by
Z
Œ≤ÃÇ(u) =

1

Œ≤ÃÇ(u, r)dr
0

where
Ô£∂‚àí1 Ô£´
Ô£∂
G
G
X
X
1
1
Œ≤ÃÇ(u, r) = Ô£≠
kÃÇg (r)xg x0g Ô£∏ Ô£≠
kÃÇg (u)xg Œ±g (u)Ô£∏ ,
G
G
Ô£´

g=1

(22)

g=1

kÃÇg (r) = h‚àí1 K(h‚àí1 (RÃÇg ‚àí r)), h is the bandwidth value satisfying h = hG ‚Üí 0 as G ‚Üí ‚àû, K
is the kernel function, RÃÇg = FÃÇ (xg,dx |wg ), and FÃÇ (x|w) is an estimator of F (x|w), the conditional
probability that xg,dx ‚â§ x given wg = w.

34

Appendix

Note, however, that Œ±g (u) is unknown in our setting, and so this estimator is infeasible. To
obtain a feasible estimator, one can substitute Œ±ÃÇg (u) calculated in the first stage instead of Œ±g (u) in
(22). Using the same techniques as those developed in this paper, it is then possible to show that
the feasible estimator is asymptotically equivalent to the infeasible estimator under weak condition
on the growth of the number of observations per group as the number of groups gets large, and
so the feasible estimator has the same asymptotic properties as those of Œ≤ÃÇ(u), which are in turn
developed in Masten and Torgovitsky (2014).
Appendix G. Proofs
In this Appendix, we first prove some preliminary lemmas. Then we present the proofs of the
theorems stated in the main text as well as the proof of Theorems 4 and 5 stated in Appendices
C and D. In all proofs, c and C denote strictly positive generic constants that depend only on
cM , cf , CM , Cf , CL whose values can change at each appearance.
We will use the following notation in addition to that appearing in the main text. Let
A(u) = (Œ±1,1 (u), ..., Œ±G,1 (u))0 ,
e
Œ≤(u)
= (X 0 PW X)‚àí1 (X 0 PW A(u)),

(23)

0
0
Jg (u) = Eg [z1g z1g
fg (z1g
Œ±g (u))].

For Œ∑, Œ± ‚àà Rdz , and u ‚àà U, consider the function fŒ∑,Œ±,u : Rdz √ó R ‚Üí R defined by
fŒ∑,Œ±,u (z, y) = (z 0 Œ∑) ¬∑ (1{y ‚â§ z 0 Œ±} ‚àí u).

(24)

Let F = {fŒ∑,Œ±,u : Œ∑, Œ± ‚àà Rdz ; u ‚àà U}; that is, F is the class of functions fŒ∑,Œ±,u as Œ∑, Œ± vary over Rdz
and u varies over U. For Œ± ‚àà Rdz and u ‚àà U, let the function hŒ±,u : Rdz √ó R ‚Üí Rdz be defined by
hŒ±,u (z, y) = z(1{y ‚â§ z 0 Œ±} ‚àí u),
and let hk,Œ±,u denote kth component of hŒ±,u . Let Hk = {hk,Œ±,u : Œ± ‚àà Rdz ; u ‚àà U }. Note that
Hk ‚äÇ F for all k = 1, ..., dz .
We will also use the following notation from the empirical process literature,
Ng
1 X
Gg (f ) = p
(f (zig , yig ) ‚àí Eg [f (zig , yig )])
Ng i=1

for f ‚àà F, H, or Hk , k = 1, . . . , dz .
Preliminary Lemmas. In all lemmas, we implicitly impose Assumptions 1-8.
Lemma 1. As G ‚Üí ‚àû,
G

QÃÇxw

1 X
=
xg wg0 ‚Üíp Qxw ,
G
g=1

(25)

Appendix

35

G

QÃÇww =

1 X
wg wg0 ‚Üíp Qww
G

(26)

g=1

where Qxw and Qww appear in Assumption 2.
Proof. We only prove (25). The proof of (26) is similar. To prove (25), observe that G‚àí1

PG

0
g=1 E[xg wg ]

Qxw by Assumption 2. Therefore, it suffices to prove that
G

1 X
xg wg0 ‚àí E[xg wg0 ] ‚Üíp 0.
G

(27)

g=1

In turn, (27) follows from Assumptions 2(iv) and 4(i) and Chebyshev‚Äôs inequality. Hence, (25)
follows. This completes the proof of the lemma.



Lemma 2. As G ‚Üí ‚àû,
G

1 X
Œµg (u1 )Œµg (u2 )wg wg0 ‚Üíp J(u1 , u2 )
G
g=1

uniformly over u1 , u2 ‚àà U.
Proof. Observe that we cannot apply a uniform law of large numbers with bracketing directly
because the data are not necessarily i.i.d. across g. Therefore, we provide a complete proof.
Since

G


1 X 
E Œµg (u1 )Œµg (u2 )wg wg0 ‚Üí J(u1 , u2 )
G
g=1

uniformly over u1 , u2 ‚àà U by Assumption 6(ii), it suffices to prove that
G

1 X
(Œµg (u1 )Œµg (u2 )wg,k wg,l ‚àí E [Œµg (u1 )Œµg (u2 )wg,k wg,l ]) ‚Üíp 0
G

(28)

g=1

uniformly over u1 , u2 ‚àà U for all k, l = 1, . . . , dw .
To this end, fix u1 , u2 ‚àà U and k, l = 1 . . . , dw . We first show (28) for these values of u1 , u2 ,
k, and l. Note that we cannot use Chebyshev‚Äôs inequality here because E[(Œµg (u1 )Œµg (u2 )wg,k wg,l )2 ]
is not necessarily finite. Instead, we use a more delicate method as presented in Theorem 2.1.7 of
Tao (2012). Let Œ¥ = cM /4. Then by HoÃàlder‚Äôs inequality,

1/2
E[|Œµg (u1 )Œµg (u2 )wg,k wg,l |1+Œ¥ ] ‚â§ E[|Œµg (u1 )Œµg (u2 )|2+2Œ¥ ] ¬∑ E[|wg,k wg,l |2+2Œ¥ ]
.
In turn,
E[|Œµg (u1 )Œµg (u2 )|

2+2Œ¥



4+4Œ¥



] ‚â§ E sup |Œµg (u)|
u‚ààU

h
i
E[|wg,k wg,l |2+2Œ¥ ] ‚â§ E kwg k4+4Œ¥ ‚â§ CM
by Assumptions 6(i) and 2(iv). Hence,
E[|Œµg (u1 )Œµg (u2 )wg,k wg,l |1+Œ¥ ] ‚â§ CM ,

‚â§ CM ,

‚Üí

36

Appendix

and so denoting Xg = Œµg (u1 )Œµg (u2 )wg,k wg,l ‚àí E[Œµg (u1 )Œµg (u2 )wg,k wg,l ], we obtain
E[|Xg |1+Œ¥ ] ‚â§ C.
P
With this notation, (28) is equivalent to G‚àí1 G
g=1 Xg ‚Üíp 0.

(29)

Now for N > 0 to be chosen later, denote Xg,‚â§N = Xg ¬∑ 1{|Xg | ‚â§ N } and Xg,>N = Xg ¬∑ 1{|Xg | >
N }. Then by Fubini‚Äôs theorem and Markov‚Äôs inequality,
Z ‚àû
|E[Xg,>N ]| ‚â§ E[|Xg,>N |] =
P (|Xg | ¬∑ 1{|Xg | > N } > t)dt
0

Z

N

Z

P (|Xg | > t)dt
N

0

E[|Xg |1+Œ¥ ]
‚â§N¬∑
+
N 1+Œ¥
=

‚àû

P (|Xg | > N )dt +

=

|1+Œ¥ ]

E[|Xg
NŒ¥

+

Z

‚àû

N

E[|Xg |1+Œ¥ ]
dt
t1+Œ¥

E[|Xg |1+Œ¥ ]
‚â§ CN ‚àíŒ¥
Œ¥N Œ¥

where in the last inequality we used (29). Hence, by Markov‚Äôs inequality, for any Œµ > 0,
G
G
 1 X

C
1 X
Xg,>N > Œµ ‚â§
E[|Xg,>N |] ‚â§
P
,
G
ŒµG
ŒµN Œ¥
g=1

g=1

and since |E[Xg,‚â§N ]| = |E[Xg,>N ]| ‚â§ CN ‚àíŒ¥ ,
P

G
G
 1 X

 1 X

Xg,‚â§N > Œµ + CN ‚àíŒ¥ ‚â§ P
(Xg,‚â§N ‚àí E[Xg,‚â§N ]) > Œµ
G
G
g=1

g=1

‚â§

G
1 X
N2
2
E[X
]
‚â§
.
g,‚â§N
ŒµG2
ŒµG
g=1

Thus, setting N = G1/3 , we obtain G

PG
‚àí1

g=1 Xg

‚Üíp 0, which is equivalent to (28) for given u1 ,

u2 , k, and l.
Next, to show that (28) holds uniformly over u1 , u2 ‚àà U, for Œ¥ > 0, let UŒ¥ be a finite subset of U
such that for any u ‚àà U, there exists u0 ‚àà UŒ¥ satisfying |Œµg (u) ‚àí Œµg (u0 )| ‚â§ Œ¥. Existence of such a set
UŒ¥ follows from Assumption 6(iii). Then
G

sup
u1 ,u2 ‚ààU

1 X
(Œµg (u1 )Œµg (u2 )wg,k wg,l ‚àí E[Œµg (u1 )Œµg (u2 )wg,k wg,l ])
G
g=1

G

‚â§ max

u1 ,u2 ‚ààUŒ¥

2Œ¥
+
G

1 X
(Œµg (u1 )Œµg (u2 )wg,k wg,l ‚àí E[Œµg (u1 )Œµg (u2 )wg,k wg,l ])
G

G 
X
g=1

g=1





sup |Œµg (u)| ¬∑ |wg,k wg,l | + E sup |Œµg (u)| ¬∑ |wg,k wg,l |
u‚ààU

= op (1) + Œ¥ ¬∑ Op (1)

u‚ààU

by the result above and Chebyshev‚Äôs inequality. Since Œ¥ is arbitrary, this completes the proof.



Appendix

37

Lemma 3. As G ‚Üí ‚àû,
G

1 X
‚àö
wg Œµg (¬∑) ‚áí G0 (¬∑), in `‚àû (U)
G g=1
where G0 is a zero-mean Gaussian process with uniformly continuous sample paths and covariance
function J(u1 , u2 ) for all u1 , u2 appearing in Assumption 6.
Proof. For any finite set U 0 ‚äÇ U, it follows from Assumption 6(ii), Lindeberg‚Äôs Central Limit
Theorem, and the CrameÃÅr-Wold device (see, for example, Theorems 11.2.5 and 11.2.3 in Lehmann
and Romano (2005)) that
G

 1 X
‚àö
wg Œµg (u)
‚áí (N (u))u‚ààU 0
u‚ààU 0
G g=1

where (N (u))u‚ààU 0 is a zero-mean Gaussian vector with covariance function J(u1 , u2 ) for all u1 , u2 ‚àà
U 0 . Therefore, it follows from the second part of Theorem 14 that the asserted claim of the lemma
holds if for any k = 1, . . . , dw and Zg (u) = G‚àí1/2 wg,k Œµg (u), g = 1, . . . , G and u ‚àà U, the sequence
PG
PG
‚àû
g=1 Zg (¬∑) is
g=1 Zg (¬∑) is asymptotically tight in ` (U). Fix k = 1, . . . , dw . To prove that
asymptotically tight in `‚àû (U), we apply the first part of Theorem 14 with Gaussian-dominated
semi-metric œÅ : U √ó U ‚Üí R+ defined by œÅ(u1 , u2 ) = C|u2 ‚àí u1 | for sufficiently large constant C > 0;
see discussion in front of Theorem 14 for the definition of Gaussian-dominated semi-metrics.
Condition (i) of Theorem 14 holds because for any Œ∑ > 0 and Œ¥ = 1 + cM /2,
G
X







E sup |Zg (u)| ¬∑ 1 sup |Zg (u) > Œ∑
u‚ààU

g=1

‚â§

u‚ààU

1
Œ∑ Œ¥ G1/2+Œ¥/2

‚â§

1
Œ∑ Œ¥ G1/2+Œ¥/2

G
X



1+Œ¥

E sup |Œµg (u)|

g=1

1+Œ¥



|wg,k |

u‚ààU


G  
i1/2
h
X
‚Üí0
E sup |Œµg (u)|2+2Œ¥ ¬∑ E |wj,k |2+2Œ¥
g=1

u‚ààU

by HoÃàlder‚Äôs inequality and Assumptions 2(iv) and 6(i).
Condition (ii) of Theorem 14 holds because for any u1 , u2 ‚àà U,
G
X

G

E[(Z(u2 ) ‚àí Z(u1 ))2 ] =

g=1

1 X
E[(wg,k Œµg (u2 ) ‚àí wg,k Œµg (u1 ))2 ]
G
g=1
G

CX
2
‚â§
E[wg,k
|u2 ‚àí u1 |2 ] ‚â§ C|u2 ‚àí u1 |2 ‚â§ œÅ2 (u1 , u2 )
G
g=1

by Assumptions 2(iv) and 6(iii) since the constant C in the definition of œÅ(u1 , u2 ) is large enough.
Finally, condition (iii) of Theorem 14 holds because by Markov‚Äôs inequality for any  > 0,
!
G
X
sup
t2 P
sup
|Zg (u2 ) ‚àí Zg (u1 )| > t
t>0 g=1

œÅ(u1 ,u2 )‚â§2

38

Appendix
G

1 X
‚â§
E
G
g=1

"

#
sup

|wg,k Œµg (u2 ) ‚àí wg,k Œµ(u1 )|2 ‚â§ C

œÅ(u1 ,u2 )‚â§2

|u2 ‚àí u1 |2 ‚â§ 2

sup
œÅ(u1 ,u2 )‚â§2

by Assumptions 2(iv) and 6(iii) since the constant C in the definition of œÅ(u1 , u2 ) is large enough.
P
‚àû
Therefore, Theorem 14 implies that the sequence G
g=1 Zg (¬∑) is asymptotically tight in ` (U).
The asserted claim follows.



Lemma 4. There exist constants c, C > 0 such that (i) for all u ‚àà U and g = 1, . . . , G, all
eigenvalues of Jg (u) are bounded from below by c, and (ii) for all u1 , u2 ‚àà U and g = 1 . . . , G,
kJg‚àí1 (u2 ) ‚àí Jg‚àí1 (u1 )k ‚â§ C|u2 ‚àí u1 |.
Proof. For any u ‚àà U and Œ± ‚àà Rdz with kŒ±k = 1,
0
Œ±0 Jg (u)Œ± ‚â• cf Œ±0 Eg [z1g z1g
]Œ± ‚â• cf cM

(30)

where the first inequality follows from Assumption 7(ii) and the second from Assumption 4(ii).
This gives the first asserted claim.
To prove the second claim, observe that
kJg‚àí1 (u2 ) ‚àí Jg‚àí1 (u1 )k ‚â§ kJg‚àí1 (u1 )kkJg‚àí1 (u2 )kkJg (u2 ) ‚àí Jg (u1 )k ‚â§

kJg (u2 ) ‚àí Jg (u1 )k
(cf cM )2

where the second inequality follows from (30). Hence, it suffices to show that kJg (u2 ) ‚àí Jg (u1 )k ‚â§
C|u2 ‚àí u1 | for some C > 0. To this end, note that
0
0
|z1g
Œ±g (u2 ) ‚àí z1g
Œ±g (u1 )| ‚â§ kz1g kkŒ±g (u2 ) ‚àí Œ±g (u1 )k ‚â§ CM CL |u2 ‚àí u1 |

where the second inequality follows from Assumptions 4(i) and 5. Thus, if |u2 ‚àí u1 | < cf /(CM CL ),
0 Œ± (u ) ‚àà B (u , c ), and so
then z1g
g 2
g 1 f
0
0
0
kJg (u2 ) ‚àí Jg (u1 )k ‚â§ Eg [z1g z1g
¬∑ fg (z1g
Œ±g (u2 )) ‚àí fg (z1g
Œ±g (u1 )) ]
0
3
‚â§ Cf CM CL |u2 ‚àí u1 | ¬∑ kEg [z1g z1g
]k ‚â§ Cf CM
CL |u2 ‚àí u1 |

where the second inequality follows from Assumption 7(i) and the derivation above, and the third
from Assumption 4(i). On the other hand, if |u2 ‚àí u1 | ‚â• cf /(CM CL ), then
0
kJg (u2 ) ‚àí Jg (u1 )k ‚â§ kJg (u1 )k + kJg (u2 )k ‚â§ 2Cf kEg [z1g z1g
]k
2
3
‚â§ 2Cf CM
‚â§ c‚àí1
f Cf CM CL |u2 ‚àí u1 |

where the first inequality follows from the triangle inequality, the second from Assumption 7(ii),
and the third from Assumption 4(i). This gives the second asserted claim and completes the proof
of the lemma.



Lemma 5. There exist constants c, C > 0 such that for all g = 1, . . . , G,
kEg [hŒ±,u (z1g , y1g )] ‚àí Jg (u)(Œ± ‚àí Œ±g (u))k ‚â§ CkŒ± ‚àí Œ±g (u)k2 ,

(31)

Appendix

39

Eg [(Œ± ‚àí Œ±g (u))0 hŒ±,u (z1g , y1g )] ‚â• ckŒ± ‚àí Œ±g (u)k2 .

(32)

for all u ‚àà U and Œ± ‚àà Rdz satisfying kŒ± ‚àí Œ±g (u)k ‚â§ c.
Proof. Second-order Taylor expansion around Œ±g (u) and the law of iterated expectation give
0
0
Eg [hŒ±,u (z1g , y1g )] = Eg [z1g (1{y1g ‚â§ z1g
Œ±} ‚àí u)] = Eg [z1g (Fg (z1g
Œ±) ‚àí u)]
0
= Eg [z1g (Fg (z1g
Œ±g (u)) ‚àí u)] + Jg (u)(Œ± ‚àí Œ±g (u)) + rn (u),

where rn (u) is the remainder and Fg (¬∑) is the conditional distribution function of y1g given (z1g , Œ±g ).
0 Œ± (u)) ‚àí u)] = 0, which holds because
The first claim of the lemma follows from Eg [z1g (Fg (z1g
g
0 Œ± (u) is the uth quantile of the conditional distribution of y , and from kr (u)k ‚â§ CkŒ±‚àíŒ± (u)k2
z1g
g
1g
n
g

for some C > 0, which holds by Assumptions 4(i) and 7(i).
To prove the second claim, note that if kŒ±‚àíŒ±g (u)k is sufficiently small, then k(Œ±‚àíŒ±g (u))0 rn (u)k ‚â§
ckŒ± ‚àí Œ±g (u)k2 for an arbitrarily small constant c > 0. On the other hand,
(Œ± ‚àí Œ±g (u))0 Jg (u)(Œ± ‚àí Œ±g (u)) ‚â• ckŒ± ‚àí Œ±g (u)k2
by Lemma 4. Combining these inequalities gives the second claim.



Lemma 6. The function class F, defined in the beginning of this section, is a VC subgraph class
of functions. Moreover, for all k = 1, ..., dz , Hk is a VC subgraph class of functions as well.
Proof. A similar proof can be found in Belloni, Chernozhukov, and Hansen (2006). We present the
proof here for the sake of completeness. Consider the class of sets {x ‚àà Rdz +1 : a0 x ‚â§ 0} with a
varying over Rdz +1 . It is well known that this is a VC subgraph class of sets; see, for example,
exercise 14 of chapter 2.6 in Van der Vaart and Wellner (1996). Further, note that

{(z, y, t) : fŒ∑,Œ±,u (z, y) > t} = {y ‚â§ z 0 Œ±} ‚à© {z 0 Œ∑ > t/(1 ‚àí u)}

‚à™ {y > z 0 Œ±} ‚à© {z 0 Œ∑ < ‚àít/u} .
Therefore, the first result follows from Lemma 2.6.17(ii,iii) in Van der Vaart and Wellner (1996).
The second result follows from the fact that Hk ‚äÇ F.



Lemma 7. For any œï ‚â• 1, there exists a constant C > 0 such that for all g = 1, . . . , G


g
œï
Eg sup kG (hŒ±g (u),u )k ‚â§ C.
u‚ààU

Proof. Observe that




Eg sup kGg (hŒ±g (u),u )kœï ‚â§ C
u‚ààU

dz
X
k=1





Eg sup |Gg (hk,Œ±g (u),u )|œï ‚â§ C
u‚ààU

dz
X
k=1

"
Eg

#
sup |Gg (f )|œï .
f ‚ààHk

40

Appendix

Further, all functions in Hk are bounded by some constant C > 0 by Assumption 4(i) and the set
of functions Hk is a VC subgraph class by Lemma 6. Therefore, combining Theorems 9 and 11
gives Eg [supf ‚ààHk |Gg (f )|] ‚â§ C, and so Theorem 13 shows that
"
#
Eg

sup |Gg (f )|œï ‚â§ C.
f ‚ààHk

The asserted claim follows.



Lemma 8. There exist constants c, C > 0 such that for all g = 1, . . . , G,
"
#
sup

Eg

u2 ‚ààU :|u2 ‚àíu1 |‚â§

kGg (hŒ±g (u2 ),u2 ) ‚àí Gg (hŒ±g (u1 ),u1 )k4 ‚â§ C

for all  ‚àà (0, c) and u1 ‚àà U.
Proof. Fix some u1 ‚àà U. Observe that
"
Eg

sup
u2 ‚ààU :|u2 ‚àíu1 |‚â§

‚â§C

#

g

dz
X

g

kG (hŒ±g (u2 ),u2 ) ‚àí G (hŒ±g (u1 ),u1 )k

4

"

#

Eg

sup
u2 ‚ààU :|u2 ‚àíu1 |‚â§

k=1

g

g

|G (hk,Œ±g (u2 ),u2 ) ‚àí G (hk,Œ±g (u1 ),u1 )|

4

.

Consider the function F : Rdz √ó R ‚Üí R given by

F (z, y) = C 1{|y ‚àí z 0 Œ±g (u1 )| ‚â§ C} + 
0 (Œ± (u ) ‚àí Œ± (u ))| ‚â§ C|u ‚àí u |
for some sufficiently large C > 0. By Assumptions 4(i) and 5, |zig
g 2
g 1
2
1

for some C > 0. Therefore, for all u2 ‚àà U satisfying |u2 ‚àí u1 | ‚â§ ,
hk,Œ±g (u2 ),u2 (zig , yig ) ‚àí hk,Œ±g (u1 ),u1 (zig , yig ) ‚â§ F (zig , yig )
by Assumption 4(i). Note that Eg [F 2 (zig , yig )] ‚â§ C for some C > 0 by Assumption 7(ii) if  ‚â§ 1.
Also, for M = max1‚â§i‚â§Ng F (zig , yig ), we have E[M 2 ] ‚â§ Cn. Further, by Lemma 6, Hk is a
VC subgraph class of functions, so that the function class HÃÉk = {hk,Œ±g (u2 ),u2 ‚àí hk,Œ±g (u1 ),u1 : u2 ‚àà
[u1 ‚àí , u1 + ]} is a VC type class by Theorem 9. So, applying Theorem 11 with F as an envelope
yields
"

#

Eg

sup
u2 ‚ààU :|u2 ‚àíu1 |‚â§

‚àö
|Gg (hk,Œ±g (u2 ),u2 ) ‚àí Gg (hk,Œ±g (u1 ),u1 )| ‚â§ C ,

and so Theorem 13 shows that
"
Eg

sup
u2 ‚ààU :|u2 ‚àíu1 |‚â§

The asserted claim follows.

#
|Gg (hk,Œ±g (u2 ),u2 ) ‚àí Gg (hk,Œ±g (u1 ),u1 )|4 ‚â§ C.


Appendix

41

Lemma 9. There exist constants c, C > 0 such that for all g = 1, . . . , G,
"
#


g
g
2
sup
kG (hŒ±,u ) ‚àí G (hŒ±g (u),u )k ‚â§ C  log(1/) + Ng‚àí1 log2 (1/)
Eg sup
u‚ààU Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§

for all  ‚àà (0, c).
Proof. Observe that
"

#

Eg sup

sup

u‚ààU Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§

‚â§C

dz
X

kGg (hŒ±,u ) ‚àí Gg (hŒ±g (u),u )k2

(33)

"

#

Eg sup

sup

u‚ààU Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§

k=1

g

g

2

|G (hk,Œ±,u ) ‚àí G (hk,Œ±g (u),u )|

.

(34)

Consider the function class
HÃÉk = {hk,Œ±,u ‚àí hk,Œ±g (u),u : u ‚àà U; Œ± ‚àà Rdz ; kŒ± ‚àí Œ±g (u)k ‚â§ }.
By Lemma 6 and Theorem 9, F is a VC type class, and so Theorem 10 implies that HÃÉk ‚äÇ F ‚àí F
is also a VC type class. In addition, all functions from HÃÉk are bounded in absolute value by some
constant C > 0 by Assumption 4(i). Moreover, for any f ‚àà HÃÉk , Eg [f (zig , yig )2 ] ‚â§ C if  ‚â§ 1.
Thus, applying Theorem 11 with the function class HÃÉk yields
"
#
Eg sup

sup

u‚ààU Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§

|Gg (hk,Œ±,u ) ‚àí Gg (hk,Œ±g (u),u )| ‚â§ C

and so Theorem 13 gives
"
Eg sup

p

 log(1/) + Ng‚àí1/2 log(1/) ,

#

sup

u‚ààU Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§



|Gg (hk,Œ±,u ) ‚àí Gg (hk,Œ±g (u),u )|2 ‚â§ C  log(1/) + Ng‚àí1 log2 (1/) .

The asserted claim follows.



Lemma 10. Uniformly over u ‚àà U,
G

1 X ‚àí1
‚àö
Jg (u)Gg (hŒ±g (u),u )wg0 = Op (1).
G g=1
Proof. To prove this lemma, we use Theorem 14 with the semi-metric œÅ(u1 , u2 ) = C|u2 ‚àí u1 |1/4
defined for all u1 , u2 ‚àà U and some sufficiently large constant C > 0. Clearly, œÅ is Gaussiandominated; see discussion before Theorem 14 for the definition. Define vg (u) = Jg‚àí1 (u)Gg (hŒ±g (u),u )
and

‚àö
Zg,k,m (u) = vg,k (u)wg,m / G

where vg,k (u) and wg,m denote kth and mth components of vg (u) and wg , respectively. Then the
asserted claim is equivalent to the statement that
G
X
g=1

Zg,k,m (u) = Op (1) uniformly over u ‚àà U

(35)

42

Appendix

for all k and m. To prove (35), observe first that by Assumptions 1(i) and 2(iii), zero-mean processes
Zg,k,m (¬∑) are independent across g. Also, for any a > 0,
G
X






E sup |Zg,k,m (u)| ¬∑ 1 sup |Zg,k,m (u)| > a
u‚ààU

g=1

‚àí1

‚â§a

u‚ààU
G
X
g=1


E

2
sup Zg,k,m
(u)
u‚ààU




¬∑ 1 sup |Zg,k,m (u)| > a
u‚ààU




G
‚àö
1 X
2
E sup(vg,k (u)wg,m ) ¬∑ 1 sup |vg,k (u)wg,m | > Ga .
‚â§
aG
u‚ààU
u‚ààU

(36)

g=1

Further, pick some 0 < œï < 2. The expression under the sum in (36) is bounded from above by
Lemma 4 by


C
g
2+œï
2+œï
E sup kG (hŒ±g (u),u )k
kwg k
aœï Gœï/2
u‚ààU
 2‚àíœï
 
4
4(2+œï)

 2+œï
C
C
g
4
E kwg k4
‚â§ œï œï/2 ‚Üí 0
‚â§ œï œï/2 E sup kG (hŒ±g (u),u )k 2‚àíœï
a G
a
G
u‚ààU
uniformly over g = 1, . . . , G where the second line follows from HoÃàlder‚Äôs inequality, Assumption
2(iv), and Lemma 7. This gives condition (i) of Theorem 14.
Next, we verify condition (ii) of Theorem 14. For any u1 , u2 ‚àà U,
G
X

2



E (Zg,k,m (u2 ) ‚àí Zg,k,m (u1 ))

g=1



G
1/2
1/2
1 X
4
=
E[wg,m
]
¬∑ E[(vg,k (u2 ) ‚àí vg,k (u1 ))4 ]
.
G
g=1

Further, using an elementary inequality (a + b)4 ‚â§ C(a4 + b4 ) for all a, b ‚àà Rp gives
Eg [(vg,k (u2 ) ‚àí vg,k (u1 ))4 ] ‚â§ CEg [kJg‚àí1 (u2 )k4 ¬∑ kGg (hŒ±g (u2 ),u2 ‚àí hŒ±g (u1 ),u1 )k4 ]
+ CEg [kJg‚àí1 (u2 ) ‚àí Jg‚àí1 (u1 )k4 ¬∑ kGg (hŒ±g (u1 ),u1 )k4 ]
‚â§ CEg [kGg (hŒ±g (u2 ),u2 ‚àí hŒ±g (u1 ),u1 )k4 ]
+ CEg [kGg (hŒ±g (u1 ),u1 )k4 ] ¬∑ |u2 ‚àí u1 |4
where the second inequality follows from Lemma 4. In addition,
Eg [kGg (hŒ±g (u2 ),u2 ‚àí hŒ±g (u1 ),u1 )k4 ] ‚â§ C|u2 ‚àí u1 | and Eg [kGg (hŒ±g (u1 ),u1 )k4 ] ‚â§ C

(37)

where the first inequality follows from Lemma 8 and the second is easy to check directly. Therefore,
Eg [(vg,k (u2 ) ‚àí vg,k (u1 ))4 ] ‚â§ C|u2 ‚àí u1 |,
and so
G
X
g=1



E (Zg,k,m (u2 ) ‚àí Zg,k,m (u1 ))2 ‚â§ C|u2 ‚àí u1 |1/2 ‚â§ œÅ2 (u1 , u2 )

Appendix

43

by Assumption 2(iv) since the constant C in the definition of œÅ(u1 , u2 ) is sufficiently large. This
gives condition (ii) of Theorem 14.
Finally, condition (iii) of Theorem 14 holds because for any  > 0 and u1 ‚àà U,
!
G
X
2
sup
t P
sup
|Zg,k,m (u2 ) ‚àí Zg,k,m (u1 )| > t
t>0 g=1

‚â§

u2 ‚ààU :œÅ(u1 ,u2 )‚â§
G
X

#

"
E

2

|Zg,k,m (u2 ) ‚àí Zg,k,m (u1 )|

sup
u2 ‚ààU :œÅ(u1 ,u2 )‚â§

g=1
G

1 X
=
E
G

"

g=1

#
sup

u2 ‚ààU :œÅ(u1 ,u2 )‚â§

2
|vg,k (u2 ) ‚àí vg,k (u1 )|2 wg,m
‚â§ 2

where the second line follows from Markov‚Äôs inequality, and the last inequality follows by selecting
sufficiently large constant C in the definition of œÅ and using the same argument as that in verification
of condition (ii) since the first inequality in (37) used in the verification of condition (ii) can be
replaced by
"
Eg

#
sup
u2 ‚ààU :œÅ(u1 ,u2 )‚â§

kGg (hŒ±g (u2 ),u2 ‚àí hŒ¥g (u1 ),u1 )k4 ‚â§ c4

for arbitrarily small c > 0 by selecting the constant C in the definition of œÅ(u1 , u2 ) large enough
and using Lemma 8. The claim of the lemma now follows by applying Theorem 14.



Proofs of Theorems.
‚àö
e
= op (1)
Proof of Theorem 1. The proof consists of two steps. First, we show that G(Œ≤ÃÇ(u) ‚àí Œ≤(u))
‚àö
e
e ‚àí Œ≤(¬∑)) ‚áí G(¬∑)
uniformly over u ‚àà U where Œ≤(u)
is defined in (23). Second, we show that G(Œ≤(¬∑)
in `‚àû (U). Combining these steps gives the result.
Step 1. Denote QÃÇxw = X 0 W/G and QÃÇww = W 0 W/G. Then

‚àí1

‚àö 
‚àö
0
‚àí1
0
e
G(Œ≤ÃÇ(u) ‚àí Œ≤(u))
= QÃÇxw QÃÇ‚àí1
QÃÇ
QÃÇ
QÃÇ
W
(
AÃÇ(u)
‚àí
A(u))/
G .
xw ww
ww xw
By Lemma 1, X 0 W/G ‚Üíp Qxw and W 0 W/G ‚Üíp Qww where matrices Qxw and Qww have singular
values bounded in absolute values from above and away from zero by Assumption 2(ii), and so

‚àí1
‚àí1
0
0
SÃÇ = QÃÇxw QÃÇ‚àí1
QÃÇ
QÃÇxw QÃÇ‚àí1
Qxw Q‚àí1
(38)
ww xw
ww ‚Üíp Qxw Qww Qxw
ww = S.
Therefore, to prove the first step, it suffices to show that
G

1 X
(Œ±ÃÇg (u) ‚àí Œ±g (u))wg0 = op (1)
S(u) = ‚àö
G g=1
uniformly over u ‚àà U. To this end, write S(u) = S1 (u) + S2 (u) where
G
p
1 X ‚àí1
S1 (u) = ‚àí ‚àö
Jg (u)Gg (hŒ±g (u),u )wg0 / Ng ,
G g=1

44

Appendix
G

p
p
1 X  ‚àí1
S2 (u) = ‚àö
Jg (u)Gg (hŒ±g (u),u ) + Ng (Œ±ÃÇg (u) ‚àí Œ±g (u)) wg0 / Ng .
G g=1

Since NG = ming=1,...,G Ng ‚Üí ‚àû by Assumption 3, Lemma 10 implies that S1 (u) = op (1) uniformly
over u ‚àà U.
Consider S2 (u). Let
Kg = C

q

Ng‚àí1 log Ng

(39)

for sufficiently large constant C > 0 so that Theorem 5 implies that


P sup kŒ±ÃÇg (u) ‚àí Œ±g (u)k > Kg ‚â§ CNg‚àí3 .
u‚ààU

Let DG be the event that
max sup kŒ±ÃÇg (u) ‚àí Œ±g (u)k ‚â§ Kg ,

g=1,...,G u‚ààU

c be the event that D does not hold. By the union bound, P (D c ) ‚â§ CGN ‚àí3 . By
and let DG
G
g
G

Assumption 3, CGNg‚àí3 ‚Üí 0. Therefore,
c
S2 (u) = S2 (u)1{DG } + S2 (u)1{DG
} = S2 (u)1{DG } + op (1)

uniformly over u ‚àà U. Further, kS2 (u)k1{DG } ‚â§ C
r1,g = sup
u‚ààU

r2,g = sup
u‚ààU

p
+ r2,g + r3,g )/ GNg where

g (u)k‚â§Kg

1
Jg‚àí1 (u) ‚àö

Ng

r3,g = sup

g=1 (r1,g

Jg‚àí1 (u)(Gg (hŒ±,u ) ‚àí Gg (hŒ±g (u),u )) kwg k,

sup
Œ±‚ààRdz :kŒ±‚àíŒ±

PG

Ng
X

hŒ±ÃÇg (u),u (zig , yig ) kwg k,

i=1

sup

Eg

u‚ààU Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§Kg

hp
i
Ng (Jg‚àí1 (u)hŒ±,u (zig , yig ) ‚àí (Œ± ‚àí Œ±g (u))) kwg k.

We bound the three terms r1,g , r2,g , and r3,g in turn. By Lemma 4 and HoÃàlder‚Äôs inequality,
#!1/2

"
1/2
E[r1,g ] ‚â§ E[kwg k ]
2

E sup

sup

u‚ààU Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§Kg

s
‚â§C

log Ng
log Ng
Ng

!1/2
=

g

g

G (hŒ±,u ) ‚àí G (hŒ±g (u),u )

2

(log Ng )3/4
1/4

Ng

where the second line follows from the definition of Kg , Assumption 2(iv), and Lemma 9. Further,
using Lemma 4 again gives
sup Jg‚àí1 (u) ‚àö

u‚ààU

Ng
Ng
1 X
1 X
C
hŒ±ÃÇg (u),u (zig , yig ) ‚â§ C sup ‚àö
hŒ±ÃÇg (u),u (zig , yig ) ‚â§ p
Ng
N g i=1
N g i=1
u‚ààU

Appendix

45

by the optimality of Œ±ÃÇg (u) and since yig has a continuous conditional distribution. Hence, E[r2,g ] ‚â§
p
C/ Ng . Finally, by Lemmas 4 and 5,
E[r3,g ] ‚â§ C

p

Ng Kg2 ‚â§

C log Ng
p
.
Ng

Hence, by Assumption 3,
‚àö

C G(log NG )3/4
= o(1),
E sup kS2 (u)k1{DG } ‚â§
3/4
u‚ààU
NG


‚àö

e
G(Œ≤ÃÇ(u) ‚àí Œ≤(u))
= op (1) uniformly over u ‚àà U and completing the first step.
‚àö
e ‚àí Œ≤(¬∑)) ‚áí G(¬∑) in `‚àû (U), observe that
Step 2. To prove that G(Œ≤(¬∑)

implying that

G
X
‚àö
e ‚àí Œ≤(¬∑)) = SÃÇ ¬∑ ‚àö1
G(Œ≤(¬∑)
wg Œµg (¬∑).
G g=1

As explained in Step 1, SÃÇ ‚Üíp S. Also, by Lemma 3,
G

1 X
‚àö
wg Œµg (¬∑) ‚áí G0 (¬∑), in `‚àû (U)
G g=1
where G0 is a zero-mean Gaussian process with uniformly continuous sample paths and covariance
function J(u1 , u2 ). Therefore, by Slutsky‚Äôs theorem,
‚àö
e ‚àí Œ≤(¬∑)) ‚áí G(¬∑), in `‚àû (U)
G(Œ≤(¬∑)

(40)

where G is a zero-mean Gaussian process with uniformly continuous sample paths and covariance function C(u1 , u2 ) = SJ(u1 , u2 )S 0 . Combining (40) with Step 1 gives the asserted claim and
completes the proof of the theorem.



Proof of Theorem 2. Equation (38) in the proof of Theorem 1 gives SÃÇ ‚Üíp S. Therefore, it suffices to
ÀÜ 1 , u2 ) ‚àí J(u1 , u2 )k = op (1) uniformly over u1 , u2 ‚àà U. Note that Œ±g,1 (u) ‚àí x0 Œ≤(u) =
prove that kJ(u
g

Œµg (u). Hence,
Œ±ÃÇg,1 (u) ‚àí x0g Œ≤ÃÇ(u) = (Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u)) ‚àí x0g (Œ≤ÃÇ(u) ‚àí Œ≤(u)) + Œµg (u)
= I1,g (u) ‚àí I2 (u) + Œµg (u)
where I1,g (u) = Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u) and I2 (u) = x0g (Œ≤ÃÇ(u) ‚àí Œ≤(u)). Further, we have
G

1 X
Œµg (u1 )Œµg (u2 )wg wg0 ‚Üíp J(u1 , u2 )
G
g=1

uniformly over u1 , u2 ‚àà U by Lemma 2. In addition, it was demonstrated in the proof of Theorem
1 that

P


max sup kŒ±ÃÇg (u) ‚àí Œ±g (u)k > Kg

g=1,...,G u‚ààU

‚â§ CGNg‚àí3 = o(1)

46

Appendix

by Assumption 3 where Kg = C(Ng‚àí1 log Ng )1/2 for sufficiently large constant C. Thus, setting
KG = maxg=1,...,G Kg , we obtain
G
G
2 X
KG
1 X
0
I1,g (u1 )I1,g (u2 )wg wg ‚â§
kwg k2 + op (1)
G
G
g=1

g=1

2
‚â§ Op (KG
) + op (1) = op (1)

uniformly over u1 , u2 ‚àà U by Assumption 2(iv) and Chebyshev‚Äôs inequality. Further,
G
G
1 X
KG X
0
I1,g (u1 )Œµg (u2 )wg wg ‚â§
|Œµg (u2 )|kwg k2 + op (1)
G
G
g=1

g=1

‚â§

G
KG X
sup |Œµg (u)|kwg k2 + op (1) = op (1)
G
u‚ààU
g=1

uniformly over u1 , u2 ‚àà U by same argument as that used in the proof of Lemma 2 since HoÃàlder‚Äôs
inequality implies that

  
1/2
1/2
2
2
E sup |Œµg (u)|kwg k ‚â§ E sup |Œµg (u)|
E[kwg k4 ]
‚â§C
u‚ààU

u‚ààU

by Assumptions 2(iv) and 6(i). Similarly,
G

G

g=1

g=1

G

G

g=1

g=1

1 X
CX
I2 (u1 )I2 (u2 )wg wg0 ‚â§
kwg k2 sup kŒ≤ÃÇ(u) ‚àí Œ≤(u)k2 = op (1),
G
G
u‚ààU
1 X
CX
I2 (u1 )Œµg (u2 )wg wg0 ‚â§
|Œµg (u2 )|kwg k2 sup kŒ≤ÃÇ(u) ‚àí Œ≤(u)k = op (1)
G
G
u‚ààU
uniformly over u1 , u2 ‚àà U by Assumption 4(i). Finally,
G
G
1 X
CKG X
I1,g (u1 )I2,g (u2 )wg wg0 ‚â§
kwg k2 k sup kŒ≤ÃÇ(u) ‚àí Œ≤(u)k + op (1) = op (1)
G
G
u‚ààU
g=1

g=1

uniformly over u1 , u2 ‚àà U. Combining these inequalities gives the asserted claim.



Proof of Theorem 3. Observe that the statement
s
s
Ô£Æ
Ô£π
VÃÇ
(u)
VÃÇ
(u)
Ô£ª for some u ‚àà U
Œ≤1 (u) ‚àà
/ Ô£∞Œ≤ÃÇ1 (u) ‚àí cÃÇ1‚àíŒ±
, Œ≤ÃÇ1 (u) + cÃÇ1‚àíŒ±
G
G
is equivalent to the statement that T > cÃÇ1‚àíŒ± . Therefore, it suffices to prove that
P (T > cÃÇ1‚àíŒ± ) ‚Üí Œ±.

(41)

Appendix

47

To prove (41), recall the process G(¬∑) = (G1 (u), . . . , Gdx (u))0 appearing in Theorem 1. Define a
e on U with values in R by
Gaussian process G(¬∑)
e
G(u)
= V (u)‚àí1/2 G1 (u), u ‚àà U
where V (u) = C1,1 (u, u), the (1, 1)st component of C(u, u) = SJ(u, u)S 0 . It follows from conditions
of the theorem that V (u) is bounded away from zero uniformly over u ‚àà U. Therefore, since G(¬∑)
e
has uniformly continuous sample paths, the process G(¬∑)
also has uniformly continuous sample
e is
paths. The covariance function of the process G(¬∑)
e 1 , u2 ) = V (u1 )‚àí1/2 C1,1 (u1 , u2 )V (u2 )‚àí1/2 .
C(u
b G (¬∑) and G
e G (¬∑) on U with values in R by
Further, for G ‚â• 1, define processes G
b G (u) = q 1
G
GVÃÇ (u)
e G (u) = p 1
G
GV (u)

G 
X


S
g (Œ±ÃÇg,1 (u) ‚àí x0g Œ≤ÃÇ(u))wÃÇg,1
, u‚ààU

g=1
G
X

S
g Œµg (u)wg,1
, u‚ààU

g=1

S and wÃÇ S are the 1st component of the vectors Sw and SÃÇw , respectively, and VÃÇ (u) =
where wg,1
g
g
g,1
ÀÜ
C1,1 (u, u).

Observe that cÃÇ1‚àíŒ± is the (1 ‚àí Œ±) conditional quantile of supu‚ààU |GÃÇG (u)| given the data. Also,
e
for Œ≤ ‚àà (0, 1) and V ‚äÇ U, let c0 be the Œ≤th quantile of supu‚ààV |G(u)|,
and let cŒ≤,V,G be the Œ≤th
Œ≤,V

e G (u)| given the data.
quantile of supu‚ààV |G
e has uniformly continuous sample paths, it follows that supu‚ààU |G(u)|
e
Now, since the process G(¬∑)
<
e
‚àû, and so Theorem 2.1 of Chernozhukov, Chetverikov, and Kato (2014b) implies that supu‚ààU |G(u)|
has continuous distribution. Therefore, for any Œ¥ > 0, there exists Œ∑ > 0 such that


0
e
P sup |G(u)| > c1‚àíŒ±‚àíŒ∑,U ‚àí Œ∑ ‚â§ Œ± + Œ¥,
u‚ààU


P

e
sup |G(u)|
> c01‚àíŒ±+Œ∑,U + Œ∑


‚â• Œ± ‚àí Œ¥.

u‚ààU

e
In addition, Theorem 1 combined with continuous mapping theorem implies that T ‚áí supu‚ààU |G(u)|,
and so
P (T > c01‚àíŒ±‚àíŒ∑,U ‚àí Œ∑) ‚â§ Œ± + Œ¥ + o(1),
P (T > c01‚àíŒ±+Œ∑,U + Œ∑) ‚â• Œ± ‚àí Œ¥ + o(1).
Hence, to prove (41), it suffices to show that for any Œ∑ > 0,
P (c01‚àíŒ±‚àíŒ∑,U ‚àí Œ∑ ‚â§ cÃÇ1‚àíŒ± ‚â§ c01‚àíŒ±+Œ∑,U + Œ∑) ‚Üí 1.

(42)

48

Appendix

e
To prove (42), fix some Œ∑ > 0. Since G(¬∑)
has uniformly continuous sample paths, there exists a
finite U(Œ∑, 1) ‚äÇ U such that
c01‚àíŒ±‚àíŒ∑,U ‚àí Œ∑ ‚â§ c01‚àíŒ±‚àíŒ∑/2,U (Œ∑,1) ‚àí Œ∑/2,

(43)

c01‚àíŒ±+Œ∑,U + Œ∑ ‚â• c01‚àíŒ±+Œ∑/2,U (Œ∑,1) + Œ∑/2.

(44)

Further, let AG be the event that G‚àí1

PG

S 2
g=1 (wg,1 )

‚â§ C for some sufficiently large C > 0. Note

that P (AG ) ‚Üí 1 as G ‚Üí ‚àû. Also, on AG , for any u1 , u2 ‚àà U,
G
G
h 1 X
2 i
1 X
S
S 2
E ‚àö
g (Œµg (u2 ) ‚àí Œµg (u1 ))wg,1
=
(Œµg (u2 ) ‚àí Œµg (u1 ))2 (wg,1
) ‚â§ C|u2 ‚àí u1 |2
G
G g=1
g=1

by Assumption 6(iii) where E [¬∑] denotes expectation with respect to the distribution of 1 , . . . , G
(and keeping everything else fixed). Therefore, combining Borell‚Äôs inequality (see Proposition of
Van der Vaart and Wellner (1996)) and Corollary 2.2.8 of Van der Vaart and Wellner (1996) show
that one can find finite U(Œ∑, 2) ‚äÇ U such that on AG ,
c1‚àíŒ±+Œ∑/2,U (Œ∑,2),G + Œ∑/3 ‚â• c1‚àíŒ±+Œ∑/3,U ,G + Œ∑/4,

(45)

c1‚àíŒ±‚àíŒ∑/2,U (Œ∑,2),G ‚àí Œ∑/3 ‚â§ c1‚àíŒ±‚àíŒ∑/3,U ,G ‚àí Œ∑/4.

(46)

Now, observe that whenever the inequalities (43) - (46) are satisfied, the same inequalities are also
satisfied with U(Œ∑, 1) and U(Œ∑, 2) replaced by U(Œ∑) = U(Œ∑, 1) ‚à™ U(Œ∑, 2).
e G (u))u‚ààU (Œ∑) is a zero-mean Gaussian vector with covariance
Next, conditional on the data, (G
function
G
1 X

S 2
CeG (u1 , u2 ) = V (u1 )‚àí1/2
Œµg (u1 )Œµg (u2 )(wg,1
) .
G
g=1

eG (u1 , u2 ) ‚ÜíP C(u
e 1 , u2 ) uniformly over u1 , u2 ‚àà U(Œ∑) where C(u
e 1 , u2 ) is the covariBy Lemma 2, C
e
ance function of a zero-mean Gaussian vector (G(u))
u‚ààU (Œ∑) . Hence, by Lemma 3.1 of Chernozhukov,
Chetverikov, and Kato (2013),
P (c01‚àíŒ±+Œ∑/2,U (Œ∑) + Œ∑/2 > c1‚àíŒ±+Œ∑/2,U (Œ∑),G + Œ∑/3) ‚Üí 1,
P (c01‚àíŒ±‚àíŒ∑/2,U (Œ∑) ‚àí Œ∑/2 < c1‚àíŒ±‚àíŒ∑/2,U (Œ∑),G ‚àí Œ∑/3) ‚Üí 1.
Combining this with inequalities (43) - (46) where we replace U(Œ∑, 1) and U(Œ∑, 2) by U(Œ∑) gives
P (c01‚àíŒ±+Œ∑,U + Œ∑ > c1‚àíŒ±+Œ∑/3,U ,G + Œ∑/4) ‚Üí 1,
P (c01‚àíŒ±‚àíŒ∑,U ‚àí Œ∑ < c1‚àíŒ±‚àíŒ∑/3,U ,G ‚àí Œ∑/4) ‚Üí 1.
To complete the proof, it suffices to show that
P (c1‚àíŒ±‚àíŒ∑/3,U ,G ‚àí Œ∑/4 ‚â§ cÃÇ1‚àíŒ± ‚â§ c1‚àíŒ±+Œ∑/3,U (Œ∑) + Œ∑/4) ‚Üí 1.

(47)

Appendix

49

To prove (47), observe that
G

G

1 X
1 X
S
S
sup ‚àö
g x0g (Œ≤ÃÇ(u) ‚àí Œ≤(u))wg,1
‚â§ sup kŒ≤ÃÇ(u) ‚àí Œ≤(u)k ¬∑ ‚àö
g wg,1
xg ‚ÜíP 0
G g=1
G g=1
u‚ààU
u‚ààU
since supu‚ààU kŒ≤ÃÇ(u) ‚àí Œ≤(u)k ‚ÜíP 0 by Theorem 1 and kG‚àí1/2

PG

S
g=1 g wg,1 xg k

= OP (1) by Assump-

tions 2(iv) and 4(i). Also,
G

1 X
S
sup ‚àö
g (Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u))wg,1
‚ÜíP 0
G
u‚ààU
g=1
by the same argument as that used in Step 1 of the proof of Theorem 1. Therefore, since Œµg (u) =
Œ±g,1 (u) ‚àí x0g Œ≤(u), supu‚ààU |VÃÇ (u) ‚àí V (u)| ‚ÜíP 0 by Theorem 2, V (u) is bounded away from zero
uniformly over u ‚àà U, and SÃÇ ‚ÜíP S as in the proof of Theorem 1, we obtain
e G (u) ‚àí G
b G (u)k ‚Üíp 0.
sup kG
u‚ààU

b
Since cÃÇ1‚àíŒ± is the (1 ‚àí Œ±) conditional quantile of supu‚ààU |G(u)|
given the data and cŒ≤,U ,G is the Œ≤th
e
conditional quantile of supu‚ààU |G(u)|
given the data, (47) follows. This completes the proof of the
theorem.



Proof of Theorem 4. We split the proof into two steps.
Step 1. Here we wish to show that for sufficiently large C > 0,
P

max

1‚â§g‚â§G

Jg‚àí1 (u)Gg (hŒ±g (u),u )

p
C(log NG )3/4
+ Ng (Œ±ÃÇg ‚àí Œ±g ) >
1/4
NG

!
‚Üí0

Set Kg = C(Ng‚àí1 log Ng )1/2 for sufficiently large C > 0 so that Theorem 5 implies that
P (kŒ±ÃÇg (u) ‚àí Œ±g (u)k > Kg ) ‚â§ CNg‚àí3 .
Let DG be the event that
max kŒ±ÃÇg (u) ‚àí Œ±g (u)k ‚â§ Kg

1‚â§g‚â§G

c be the event that D does not hold. By the union bound, P (D c ) ‚â§ CGN ‚àí3 ‚Üí 0.
and let DG
G
g
G

Now, on the event DG ,
Jg‚àí1 (u)Gg (hŒ±g (u),u ) +

p

Ng (Œ±ÃÇg ‚àí Œ±g ) ‚â§ r1,g + r2,g + r3,g

where
r1,g =

sup
Œ±‚ààRdz :kŒ±‚àíŒ±

kJg‚àí1 (u)(Gg (hŒ±,u ) ‚àí Gg (hŒ±g (u),u ))k,

g (u)k‚â§Kg

Ng
1 X
r2,g = Jg‚àí1 (u) p
hŒ±ÃÇ (u),u (zig , yig ) ,
Ng i=1 g

(48)

50

Appendix

r3,g =

kEg [

sup
Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§Kg

p
Ng (Jg‚àí1 (u)hŒ±,u (zig , yig ) ‚àí (Œ± ‚àí Œ±g (u)))]k.

By Lemma 4 and optimality of Œ±ÃÇg (u),
r2,g

Ng
C
C X
hŒ±ÃÇg (u),u (zig , yig ) ‚â§ p .
‚â§ p
Ng i=1
Ng

Also, by Lemmas 4 and 5,
r3,g ‚â§ C

p
C log Ng
.
Ng Kg2 ‚â§ p
Ng

Finally, by Lemma 4 and Talagrand‚Äôs inequality (see, for example, Theorem B.1 in Chernozhukov,
Chetverikov, and Kato (2014b)),
r1,g ‚â§ C sup

sup
Œ±‚ààRdz :kŒ±‚àíŒ±g (u)k‚â§Kg

kGg (hŒ±,u ) ‚àí Gg (hŒ±g (u),u )k ‚â§ C

p
C log3/4 Ng
Kg log G =
1/4
Ng

with probability at least 1 ‚àí G‚àí2 . Combining these bounds gives (48) and completes this step.
Step 2. Here we complete the proof. For g = 1, . . . , G and i = 1, . . . , NÃÑG , define qig as follows.
If i > Ng , set qig = 0. If i ‚â§ Ng , set
0
qig = (NÃÑG /Ng )1/2 Ig‚àí1/2 zÃÑig (1{yig ‚â§ zig
Œ±g (u)} ‚àí u)

where zÃÑig denotes the first component of the vector Jg‚àí1 (u)zig . By Step 1 and assumptions that
Ig ‚â• cM and NÃÑG /NG ‚â§ CM , it follows that


q
M
P max
Ng /Ig |Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u)| ‚â§ c1‚àíŒ±
1‚â§g‚â§G
Ô£´
Ô£∂
NÃÑG
3/4
X
C log Ng Ô£∏
1
(qig ‚àí Eg [qig ]) ‚â§ cM
‚â§ P Ô£≠ max p
+ o(1)
1‚àíŒ± +
1/4
1‚â§g‚â§G
NÃÑG g=1
Ng

(49)

In turn, since under our assumptions |qig | ‚â§ C, by Corollary 2.1 in Chernozhukov, Chetverikov,
and Kato (2014d), the probability in (49) is bounded from above by
!
C log3/4 NG
M
+ o(1)
P max |Yg | ‚â§ c1‚àíŒ± +
1/4
1‚â§g‚â§G
NG


C(log3/4 NG ) ¬∑ (log1/2 G)
M
‚â§ P max |Yg | ‚â§ c1‚àíŒ± +
+ o(1) = 1 ‚àí Œ± + o(1)
1/4
1‚â§g‚â§G
NG
where in the second line we used Theorem 3 in Chernozhukov, Chetverikov, and Kato (2014c).
Thus,



q
M
max
Ng /Ig |Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u)| ‚â§ c1‚àíŒ± ‚â§ 1 ‚àí Œ± + o(1).

(50)

Similar arguments also give


q
M
P max
Ng /Ig |Œ±ÃÇg,1 (u) ‚àí Œ±g,1 (u)| ‚â§ c1‚àíŒ± ‚â• 1 ‚àí Œ± ‚àí o(1).

(51)

P

1‚â§g‚â§G

1‚â§g‚â§G

Appendix

51

Rearranging the terms under the probability signs in (50) and (51) completes the proof of the
theorem.



Proof of Theorem 5. Recall the definition of the function fŒ∑,Œ±,u in (24). Since x 7‚Üí œÅu (x) = (u ‚àí
I{x < 0})x is convex, for x > 0, kŒ±ÃÇg (u) ‚àí Œ±g (u)k ‚â§ x for all u ‚àà U if
inf

inf

Ng
X

u‚ààU Œ∑‚ààRdz ;kŒ∑k=1

fŒ∑,Œ±g (u)+xŒ∑,u (zig , yig )/Ng > 0.

(52)

i=1

Now, since fŒ∑,Œ±,u = Œ∑ 0 hŒ±,u , Lemma 5 implies that
inf

inf

u‚ààU Œ∑‚ààRdz ;kŒ∑k=1

Eg [fŒ∑,Œ±g (u)+xŒ∑,u (zig , yig )] > cx

if the constant cÃÑ in the statement of the theorem is sufficiently small. Therefore, it follows that
(52) holds if
inf

inf

u‚ààU Œ∑‚ààRdz ;kŒ∑k=1

Ng
X


fŒ∑,Œ±g (u)+xŒ∑,u (zig , yig ) ‚àí Eg [fŒ∑,Œ±g (u)+xŒ∑,u (zig , yig )] /Ng ‚â• ‚àícx,

i=1

which in turn follows if
inf

inf

u‚ààU Œ∑,Œ±‚ààRdz ;kŒ∑k=1

p
Gg (fŒ∑,Œ±,u ) ‚â• ‚àícx Ng .

(53)

Note that for any Œ∑ ‚àà Rdz satisfying kŒ∑k = 1, |fŒ∑,Œ±,u | ‚â§ 2kzig k ‚â§ C for some C > 0 by Assumption
4(i). In addition, it follows from Lemma 6 and Theorem 9 that the conditions of Theorem 12 hold
for the function class {fŒ∑,Œ±,u ‚àà F : u ‚àà U; Œ∑, Œ± ‚àà Rdz ; kŒ∑k = 1}. Therefore, Theorem 12 shows that
(53) holds with probability not smaller than
1 ‚àí C exp(‚àícx2 Ng )
for some c, C > 0. The asserted claim follows.



Appendix H. Proofs of Theorems 6-8
The proofs are analogous to those of Theorems 1-3. Therefore, we only discuss important differences. First, the constants c, C > 0 in the proofs now depend on cM , cf , CM , Cf , CL , and CÃÑ.
Second, among Lemmas 1 - 10, Lemmas 4 - 9 deal with within group variation, and so apply under
our conditions without changes. The statement of Lemma 1 holds without changes but in the proof,
Chebyshev‚Äôs inequality applies on cluster level, that is, for k = 1, . . . , dx and l = 1, . . . , dw ,
E

G
h 1 X

G

g=1

M
2 i
1 X h
(xg,k wg,l ‚àí E[xg,k wg,l ])
= 2
E
G
m=1

‚â§

M
C X h
E
G2
m=1

X

2 i
(xg,k wg,l ‚àí E[xg,k wg,l ])

g‚ààCG (m)

X
g‚ààCG (m)

(xg,k wg,l ‚àí E[xg,k wg,l ])2

i

52

Appendix

=

G
C X
E[(xg,k wg,l ‚àí E[xg,k wg,l ])2 ] ‚Üí 0
G2
g=1

where in the second line we used Assumption 10 (iii) that the number of groups in each cluster is
bounded from above by CÃÑ.
Lemma 2 should be replaced with the statement that G ‚Üí ‚àû,
M
1 X
G
m=1

X

Œµg (u1 )wg



X


Œµg (u1 )wg0 ‚ÜíP J CS (u1 , u2 )

(54)

g‚ààCG (m)

g‚ààCG (m)

uniformly over u1 , u2 ‚àà U. To prove this statement, observe that by Assumption 60 (ii),
M
1 X h
E
G
m=1

X

Œµg (u1 )wg

g‚ààCG (m)



X

Œµg (u1 )wg0

i

‚Üí J CS (u1 , u2 )

g‚ààCG (m)

uniformly over u1 , u2 ‚àà U. Further, for Œ¥ = cM /4 and k, l = 1, . . . , dw ,
 1+Œ¥ i
 X
h X
Œµg (u2 )wg,l
Œµg (u1 )wg,k
E
g‚ààCG (m)

g‚ààCG (m)

‚â§ CE

h

‚â§ CE

h

X

|Œµg (u1 )wg,k Œµg0 (u2 )wg0 ,l |1+Œ¥

i

g,g 0 ‚ààCG (m)

X



|Œµg (u1 )wg,k |2+2Œ¥ + |Œµg0 (u2 )wg0 ,l |2+2Œ¥

i

‚â§ C,

g,g 0 ‚ààCG (m)

where the last inequality can be proven by the same argument as that used in the proof of Lemma
2. From this point, the proof of 54 is analogous to the proof used in Lemma 2.
The statement of Lemma 3 holds with J(u1 , u2 ) replaced by J CS (u1 , u2 ). To prove the new
statement, first observe that for any finite U 0 ‚äÇ U,
G
 1 X

‚àö
wg Œµg (u)
‚áí (N (u))u‚ààU 0
u‚ààU 0
G g=1

where (N (u))u‚ààU 0 is a zero-mean Gaussian vector with covariance function J CS (u1 , u2 ) for all
u1 , u2 ‚àà U 0 . The rest of the proof follows from Theorem 14 by the same arguments as those used
in Lemma 3 and those explained above where we replace Zg (u) = G‚àí1/2 wg,k Œµg (u) by Zm (u) =
P
G‚àí1/2 g‚ààCG (m) wg,k Œµg (u), and we replace sums over g = 1, . . . , G by sums over m = 1, . . . , M
where appropriate.
The statement of Lemma 10 holds without changes but in the proof, we replace Zg,k,l (u) =
‚àö
‚àö
P
vg,k (u)wg,l / G by Zm,k,l (u) = g‚ààCG (m) vg,k (u)wg,l / G and we replace sums over g = 1, . . . , G
by sums over m = 1, . . . , M where appropriate, and employ the arguments explained above.
With the new versions of Lemmas 1 - 10, the proof of Theorem 6 is the same as the proof of
Theorem 1. The proof of Theorem 7 is analogous to that of Theorem 2 where, using the same

Appendix

53

notation as that in the proof of Theorem 2, we employ the bound
M
1 X
G
m=1

1
‚â§
G

X

I1,g (u1 )wg



X

I1,g (u2 )wg0



g‚ààCG (m)

g‚ààCG (m)

M
X

X

kI1,g (u1 )I1,g0 (u2 )wg wg0 k

m=1 g,g 0 ‚ààCG (m)

G
Kg2 X
‚â§
kwg k2 + oP (1) = oP (1),
G
g=1

and we bound all other terms in the proof similarly. The proof of Theorem 8 is analogous to that
of Theorem 3.
Appendix I. Tools
In Appendix G, we used several results from the empirical process theory. For ease of reference,
we describe these results in this section.
Let (T, œÅ) be a semi-metric space. For Œµ > 0, an Œµ-net of (T, œÅ) is a subset TŒµ of T such
that for every t ‚àà T , there exists a point tŒµ ‚àà TŒµ with œÅ(t, tŒµ ) < Œµ. The Œµ-covering number
N (Œµ, T, œÅ) of T is the infimum of the cardinality of Œµ-nets of T , that is, N (Œµ, T, œÅ) = inf{Card(TŒµ ) :
TŒµ is an Œµ net of T }.
Let F be a class of measurable functions defined on some measurable space (S, S). For any
probability measure Q on (S, S) and p ‚â• 1, let Lp (Q) denote the space of functions f on S with
R
the norm kf kQ,p = ( |f (s)|p dQ(s))1/p < ‚àû. The function class F is called VC-subgraph class if
the collection of all subgraphs of the functions in F forms a VC-class of sets; see Section 2.6.2 of
Van der Vaart and Wellner (1996) for the definitions. In addition, we say that the function class
F is VC type class of functions with an envelope F : S ‚Üí R+ and constants A ‚â• e, and v ‚â• 1 if
all functions in F are bounded in absolute value by F and the following condition holds:
sup N (ŒµkF kQ,2 , F, L2 (Q)) ‚â§ (A/Œµ)v
Q

for all Œµ ‚àà (0, 1) where the supremum is taken over all finitely discrete probability measures Q on
(S, S).
Finally, let X1 , . . . , Xn be an i.i.d. sequence of random variables taking values in (S, S) with a
common distribution P . Define the empirical process:
n

1 X
Gn (f ) = ‚àö
f (Xi ) ‚àí E[f (Xi )] , f ‚àà F.
n
i=1

The following theorems are used in Appendix G:
Theorem 9. There exists a universal constant K such that for any VC subgraph class F of functions with an envelope F , any p ‚â• 1, and 0 < Œµ < 1,
sup N (ŒµkF kQ,p , F, Lp (Q)) ‚â§ KV (F)(16e)
Q

V (F )

 r(V (F )‚àí1)
1
Œµ

54

Appendix

where V (F) is a finite constant that depends only on the function class F (and called VC dimension
of the class F). Thus, any VC-subgraph class of functions F is also a VC type class of functions
with some constants A ‚â• e and v ‚â• 1 depending only on F.
Proof. See Lemma 19.15 in Van der Vaart (1998).



Theorem 10. Let F1 , . . . , Fk be classes of measurable functions S ‚Üí R to which measurable
envelopes F1 , . . . , Fk are attached, respectively, and let œÜ : Rk ‚Üí R be a map that is Lipschitz in the
sense that
2

|œÜ ‚ó¶ f (s) ‚àí œÜ ‚ó¶ g(s)| ‚â§

k
X

L2j (s)|fj (s) ‚àí gj (s)|2 ,

j=1

for every f = (f1 , . . . , fk ), g = (g1 , . . . , gk ) ‚àà F1 √ó. . . Fk = F and every s ‚àà S, where L1 , . . . , Lk are
non-negative measurable functions on S. Consider the class of functions œÜ(F) = {œÜ ‚ó¶ f : f ‚àà F}.
P
Denote ( kj=1 L2j Fj2 )1/2 by L ¬∑ F . Then we have
sup N (ŒµkL ¬∑ F kQ,2 , œÜ(F), L2 (Q)) ‚â§
Q

k
Y

sup N (ŒµkFj kQj ,2 , Fj , L2 (Qj ))

j=1 Qj

for every 0 < Œµ < 1.
Proof. See Lemma A.6 in Chernozhukov, Chetverikov, and Kato (2014a).



Theorem 11. Let F be a VC type class of functions with an envelope F and constants A ‚â• e and
v ‚â• 1. Denote œÉ 2 = supf ‚ààF E[f (X1 )2 ] and M = max1‚â§i‚â§n F (Xi ). Then
s
"
#


!

AkF
k
AkF
k
vkM
k
P,2
P,2
2
E sup |Gn (f )| ‚â§ K
vœÉ 2 log
+ ‚àö
log
œÉ
œÉ
n
f ‚ààF
for some absolute constant K where kM k2 = (E[M 2 ])1/2 .
Proof. See Corollary 5.1 of Chernozhukov, Chetverikov, and Kato (2014a).



Theorem 12. Let F be a class of functions f : X ‚Üí [0, 1] that satisfies
 V
K
sup N (Œµ, C, L2 (Q)) ‚â§
, for every 0 < Œµ < K
Œµ
Q
where supremum is taken over all probability measures Q. Then for every t > 0,
! 

Dt V ‚àí2t2
‚àö
P sup |Gn (f )| > t ‚â§
e
V
f ‚ààF
for a constant D that depends on K only.
Proof. See Theorem 2.14.9 in Van der Vaart and Wellner (1996).



Appendix

55

Theorem 13. Let X1 , . . . , Xn be independent, zero-mean stochastic processes indexed by an arbitrary index set T with joint probability measure P . Then

p
‚â§K
+
kSn k
kSn k
log p
P,p
P,1


max kXi k

1‚â§i‚â§n

P,p

for any p > 1 where Sn = X1 + ¬∑ ¬∑ ¬∑ + Xn , kSn k = supt‚ààT |Sn (t)|, kXi k = supt‚ààT |Xi (t)|, and K is
a universal constant.
Proof. See Proposition A.1.6 in Van der Vaart and Wellner (1996).



Finally, we provide a reference for Central Limit Theorem with bracketing by Gaussian hypotheses, which we use several times in Section G. A semi-metric œÅ : F √ó F ‚Üí R+ is called Gaussian if
it can be defined as
1/2
œÅ(f, g) = E[(G(f ) ‚àí G(g))2 ]
where G is a tight, zero-mean, Gaussian random element in l‚àû (F). A semi-metric œÅ is called
Gaussian-dominated if it is bounded from above by Gaussian metric. In particular, it is known
that any semi-metric œÅ satisfying
Z

‚àûp

log N (Œµ, F, œÅ)dŒµ < ‚àû

0

is Gaussian-dominated; see discussion on page 212 in Van der Vaart and Wellner (1996).
Theorem 14 (Bracketing by Gaussian Hypotheses). For each n, let Zn1 , ..., Znmn be independent
stochastic processes indexed by an arbitrary index set F. Suppose that there exists a Gaussiandominated semi-metric œÅ on F such that
(i)

mn
X

E [kZni kF ¬∑ 1{kZni kF > Œ∑}] ‚Üí 0, for every Œ∑ > 0,

i=1

(ii)

mn
X



E (Zni (f ) ‚àí Zni (g))2 ‚â§ œÅ2 (f, g), for every f, g,

i=1

(iii)

sup
t>0

mn
X

!
2

t P

i=1

sup |Zni (f ) ‚àí Zni (g)| > t

‚â§ Œµ2 ,

f,g‚ààB(Œµ)

for every œÅ-ball B(Œµ) ‚äÇ F of radius less than Œµ and for every n. Then the sequence
E[Zni ]) is asymptotically tight in

l‚àû (F).

Pmn

i=1 (Zni

‚àí

It converges in distribution provided it converges marginally.

Proof. See Theorem 2.11.11 in Van der Vaart and Wellner (1996).



56

Appendix

Table A1. Bias of Grouped IV Quantile Regression vs. Standard Quantile Regression
(N,G) = (25, 25)

(N,G) = (200, 25)

(N,G) = (25, 200)

(N,G) = (200, 200)

Quantile True
(u)
Coeff.
0.1
0.316
0.2
0.447
0.3
0.548
0.4
0.632
0.5
0.707
0.6
0.775
0.7
0.837
0.8
0.894
0.9
0.949
Avg. abs. bias

I. Mean Bias for Endogenous Group-level Treatment
Grouped
Grouped
Grouped
Grouped
Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg.
0.042
-0.055
0.040
-0.007
0.038
0.018
0.039
-0.005
0.076
0.015
0.078
-0.003
0.077
0.008
0.077
0.000
0.116
-0.024
0.116
-0.044
0.117
0.005
0.116
-0.003
0.155
-0.128
0.154
-0.031
0.154
0.007
0.155
-0.002
0.194
-0.182
0.193
-0.023
0.192
0.010
0.194
-0.006
0.236
-0.192
0.233
-0.039
0.228
0.003
0.232
-0.006
0.273
-0.161
0.270
-0.067
0.267
-0.002
0.270
-0.004
0.312
-0.106
0.311
-0.056
0.306
-0.010
0.309
-0.003
0.365
-0.106
0.361
-0.060
0.360
-0.013
0.362
-0.001
0.197
0.108
0.195
0.037
0.193
0.008
0.195
0.003

Quantile True
(u)
Coeff.
0.1
0.316
0.2
0.447
0.3
0.548
0.4
0.632
0.5
0.707
0.6
0.775
0.7
0.837
0.8
0.894
0.9
0.949
Avg. abs. bias

II. Mean Bias for Exogenous Group-level Treatment
Grouped
Grouped
Grouped
Grouped
IV Q. Reg. Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg.
0.010
-0.004
-0.016
0.002
-0.011
0.001
-0.006
0.027
0.001
-0.010
0.002
-0.018
0.003
-0.008
-0.006
0.006
-0.012
0.003
-0.017
0.005
-0.005
-0.021
0.007
-0.010
0.005
-0.017
0.007
0.002
-0.039
0.008
-0.002
0.007
-0.020
0.009
0.003
-0.021
0.009
-0.004
0.009
-0.015
0.011
0.002
-0.011
0.007
-0.003
0.009
-0.014
0.011
0.000
-0.007
-0.011
-0.001
-0.011
-0.008
-0.011
0.000
0.008
-0.038
0.003
-0.028
-0.009
-0.031
-0.001
0.017
0.010
0.007
0.009
0.014
0.010
0.003

Q. Reg.
0.005
0.005
0.006
0.011
0.008
0.004
0.006
-0.010
-0.031
0.010

III. Mean Bias for Exogenous Group-level Treatment and No Group-level Unobservables
Quantile True
Grouped
Grouped
Grouped
Grouped
(u)
Coeff. Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg. Q. Reg. IV Q. Reg.
0.1
0.316
0.002
0.019
0.001
-0.006
0.000
-0.009
0.000
-0.004
0.2
0.447
0.008
0.009
0.003
-0.002
0.000
-0.008
-0.001
-0.007
0.3
0.548
0.005
-0.023
0.004
0.000
0.001
-0.010
-0.001
-0.007
0.4
0.632
0.007
-0.015
0.004
-0.003
0.002
-0.001
0.000
-0.005
0.5
0.707
0.005
-0.027
0.000
-0.003
0.001
-0.002
0.000
-0.004
0.6
0.775
0.004
-0.037
0.001
-0.011
0.000
-0.002
0.000
-0.002
0.7
0.837
0.003
-0.027
0.000
-0.005
0.000
-0.002
0.000
0.000
0.8
0.894
0.000
-0.022
0.000
-0.003
0.001
0.000
0.000
0.002
0.9
0.949
-0.003
-0.023
0.000
-0.003
-0.001
-0.005
0.000
0.001
Avg. abs. bias
0.004
0.023
0.002
0.004
0.001
0.004
0.000
0.004
Notes: Table shows mean bias for estimation of Œ≤(u) from 1,000 Monte Carlo simulations using standard quantile
regression (Q. Reg.) and our estimator (Grouped IV Q. Reg.) for cases where (N, G) = (25,25), (200,25), (25,200),
(200,200). Panel I displays results when the group-level treatment is endogenous, panel II displays results when the
group-level treatment is independent of group-level unobservables, and panel III displays results when there are no
group-level unobservables. Each panel displays results for quantiles u ‚àà {0.1, ..., 0.9} as well as the average absolute
value of the bias, averaged over the nine deciles.

