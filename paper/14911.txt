NBER WORKING PAPER SERIES

ABILITY-GROUPING AND ACADEMIC INEQUALITY:
EVIDENCE FROM RULE-BASED STUDENT ASSIGNMENTS
C. Kirabo Jackson
Working Paper 14911
http://www.nber.org/papers/w14911

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2009

The author is grateful for feedback received from Ron Ehrenberg, Roland Fryer, Kevin Hallock, Caroline
Hoxby, Bob Hutchens, Clement Jackson, Lawrence Katz, Jordan Matsudaira and Henry Schneider.
The author is also grateful for useful comments received from participants of the Labor Economics
workshop at Cornell University. The author is deeply grateful to Marcia Riley and would like to thank
Yvonne Lewis, Rosaline Mendez and Simone Rawlins of the Trinidad and Tobago Department of
Education Research and Evaluation for allowing him to access their data, their assistance and generosity.
The views expressed herein are those of the author(s) and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2009 by C. Kirabo Jackson. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

Ability-grouping and Academic Inequality: Evidence From Rule-based Student Assignments
C. Kirabo Jackson
NBER Working Paper No. 14911
April 2009
JEL No. I20
ABSTRACT
In Trinidad and Tobago students are assigned to secondary schools after fifth grade based on achievement
tests, leading to large differences in the school environments to which students of differing initial levels
of achievement are exposed. Using both a regression discontinuity design and rule-based instrumental
variables to address self-selection bias, I find that being assigned to a school with higher-achieving
peers has large positive effects on examination performance. These effects are about twice as large
for girls than for boys. This suggests that ability-grouping reinforces achievement differences by assigning
the weakest students to schools that provide the least value-added.

C. Kirabo Jackson
Cornell University, ILR School
Department of Labor Economics
Ives Hall East
Ithaca, NY 14853-3901
and NBER
ckj5@cornell.edu

“ABILITY-GROUPING AND ACADEMIC INEQUALITY: EVIDENCE FROM
RULE-BASED STUDENT ASSIGNMENTS”
C. Kirabo Jackson¥
Cornell University (Draft date: 14 April, 2009)
In Trinidad and Tobago students are assigned to secondary schools after fifth grade based on achievement tests,
leading to large differences in the school environments to which students of differing initial levels of achievement
are exposed. Using both a regression discontinuity design and rule-based instrumental variables to address selfselection bias, I find that being assigned to a school with higher-achieving peers has large positive effects on
examination performance. These effects are about twice as large for girls than for boys. This suggests that abilitygrouping reinforces achievement differences by assigning the weakest students to schools that provide the least
value-added.

I

Introduction and Background
In Trinidad and Tobago, students take an exam at the end of fifth grade that is used to

assign them to secondary school. Students list their secondary school choices, and the likelihood
of being assigned to their first-choice school increases with their score. Since students usually
rank higher-achieving schools higher on their lists, high-achieving students typically attend highperforming secondary schools while low-achieving students typically attend the poorestperforming schools. Since school ability-grouping groups students by achievement, it has a
profound effect on the peers to which students are exposed — lowering average peer quality for
low-achievement students and increasing average peer quality of high-achievement students.
This is important because several studies have found that students tend to have better outcomes
when they are exposed to higher-achieving peers.1 Further, the quality of school inputs may be
endogenous to the quality of peers because schools with bright, motivated students may attract
better teachers, and may have more affluent alumni networks leading to better facilities and
better funding. 2 As such, ability-grouping may engender large differences in the quality of
¥

I am grateful for feedback received from Ron Ehrenberg, Roland Fryer, Kevin Hallock, Caroline Hoxby, Bob
Hutchens, Clement Jackson, Lawrence Katz, Jordan Matsudaira and Henry Schneider. I am also grateful for useful
comments received from participants of the Labor Economics workshop at Cornell University. I am deeply grateful
to Marcia Riley and I would like to thank Yvonne Lewis, Rosaline Mendez and Simone Rawlins of the Trinidad and
Tobago Department of Education Research and Evaluation for allowing me to access their data, their assistance and
generosity. All errors are my own.
1
Several studies find that students tend to have better outcomes on average when their peers are brighter on average
[Hoxby (2000), Hoxby and Weingarth (2005), Sacerdote (2001), Zimmerman (2003)] while others provide mixed
evidence [Katz, Kling Liebman (2007), Angrist and Lang (2004), Burke and Sass (2006)].
2
Supporting this notion, Jackson (forthcoming) finds that a quasi-exogenous repatriation of low-income black
students into schools at the end of school desegregation was associated with decreases in teacher quality.

1

schools students of different initial achievement levels attend.
Researchers have linked differences in school quality to differences in labor market
outcomes (Card and Krueger 1992a;1992b, Betts 1995, and Grogger 1996) and higher test scores
to higher subsequent earnings (Murnane, Tyler and Willet 2000), suggesting that school abilitygrouping may reinforce achievement differences by assigning low-achievers to schools that
provide the least value-added. Ability-grouping across schools is currently practiced in several
nations worldwide3 and elements of ability-grouping exist in the United States where several
districts have highly selective secondary schools.4 Ability-grouping is likely to reinforce preexisting achievement differences, on the margin, as long as all students benefit from attending
better schools. However, the broader question of whether students benefit from attending
“better” schools remains unresolved.
The empirical difficulties in uncovering the causal effect of attending a better school lie
in the fact that students may self-select into schools. Students with the same incoming test scores
who attend different schools may have different preferences or levels of motivation. Since
preferences and motivation are typically not observed, researchers have most recently dealt with
this issue by relying on plausibly exogenous variation in school attendance. Using lottery
assignment to schools, Cullen, Jacob and Levitt (2005) find that Chicago students who transfer to
high-achieving schools show no improvement in test scores while Hastings and Weinstein (2007)
find that students in Charlotte-Mecklenburg who transfer to substantially better schools
experience sizable improvements in test scores. Other studies have used Regression
Discontinuity (RD) designs that compare the outcomes of students with test scores just above
and just below some exogenously set cut-off above which admission to a high-achievement
school is very likely and below which admission to such a school is unlikely. Clark (2008) finds
that gaining admission to selective secondary schools in the United Kingdom does not improve
test scores, while Pop-Eleches and Urquiola (2008) find that students in Romania who gain
admission to better schools have better test score performance.5 It is apparent that there is no
consensus on whether students benefit from attending better schools.
3

This includes Austria, Germany, Japan, Hungary, the United Kingdom, the Slovak Republic, the Czech Republic,
Jamaica, Barbados and others.
4
Notable examples are Boston Latin School and Stuyvesant High School in New York City. There also exist
magnet schools that admit students based on prior achievement.
5
Using an RD design, Duflo, Dupas and Kremer (2008) find that marginal students who gain admission to high
ability classrooms within tracked schools have similar outcomes to those students who do not.

2

In an attempt to provide some clarity to this literature, I use data from Trinidad and
Tobago to investigate the following empirical questions: (1) Do students, on average, benefit
from attending schools with higher-achieving peers on a range of academic outcomes? (2) Does
ability-grouping across schools increase educational inequality, on the margin, by assigning lowachievement students to low value-added schools while assigning high-achievement students to
high value-added schools? (3) Do the marginal effects vary by gender, and (4) Are the marginal
effects non-linear (i.e. does attending a school with marginally higher-achieving peers have
larger effects at low or high peer achievement levels)? Trinidad and Tobago data are well suited
to identifying school ability-grouping effects on the margin because: (a) the student assignment
mechanism creates exogenous variation in school attendance, (b) there is a national curriculum
so that school effects are not confounded with large curricular differences,6 and (c) all schools
have homogenous student populations so that school effects are not confounded with a
“homogeneous student body” effect.7 As such, differences in school value-added in Trinidad and
Tobago will primarily reflect differences in peer quality and differences in teacher and input
quality endogenous to peer quality.
To address the self-selection bias that often makes it difficult to obtain credible causal
effects when comparing observationally similar students who attend different schools, I use rulebased instrumental variables in the spirit of Campbell (1969) and Angrist and Lavy (1999) based
on the student school assignment rules used by the Ministry of Education. The assignment rules
(described in Section II) are largely deterministic, non-linear, non-monotonic functions of
student preferences and incoming test scores that lead to test score cut-offs for each school below
which admission is unlikely. As suggested in Fisher (1976), I use the deterministic portion of the
assignment rules to obtain rule-based assignments, which are complicated non-linear functions of
test scores and preferences, as exogenous instruments while directly controlling for smooth
6

Ability-grouping is often coupled with a dual education system where certain schools have an academic focus
while others have a vocational focus. Malamud and Pop-Eleches (2007) find that students in Romania were less
likely to work in manual or craft-related occupations when they received a general education. While selective
schools in Trinidad and Tobago may teach at a faster pace than non-selective schools, the core material covered will
largely be the same so that curricular differences, if any, are small.
7
The main theoretical justification for ability-grouping (both at the school and classroom level) is that a
homogeneous student body may lead to improved student outcomes by allowing for more student cohesion, greater
teacher focus, and a curriculum and pace more closely tailored to the particular ability level of the students.
Researchers have studied the distributional and efficiency effects of classroom ability-grouping, and the results are
mixed [studies include Betts and Shkolnik (1999); Rees, Brewer and Argys (1999), Figlio and Page (1998, 2002);
Hoffer (1992)]. Using experimental data, Duflo, Dupas and Kremer (2008) find that the classroom homogeneity
created by ability-grouping may benefit both high and low-achieving students.

3

functions of these same underlying covariates. The rule based assignments are, in essence, an
interaction between students’ preferences and student test scores, resulting in two distinct
sources of plausibly exogenous variation: (a) the variation in schools attended among students
with the same preferences and similar scores because some scored just above the rule-based cutoff while others scored just below (conditional on their test scores); and (b) the variation in
schools attended among students with the same test scores because they had slightly different
preferences for schools (conditional on the actual preferences). A unique feature of these data is
that I can observe, and control for, a student’s desired schools so that I can credibly compare the
outcomes of students who attend different schools even if they did not score near a test score cutoff. To show that my identification strategy is valid, I present falsification tests showing that,
conditional on test scores and preferences, the instruments are not correlated with incoming
student characteristics such as religion, gender, and primary school district. As a further check on
the strategy, I also show that a more conventional RD strategy (using only the variation due to
the cut-offs) yields similar, but much less precise, estimates.
This paper is closely related to the school ability-grouping (often referred to as tracking)
literature as I estimate the effects of attending a school with marginally higher-achieving peers
on students in a an ability-grouped schooling system. Researchers generally find that school
ability-grouping is associated with increased educational and socio-economic inequality. 8
However, much of this evidence relies on comparisons between observationally similar students
in ability-grouped and non-ability-grouped school systems. As documented by Dustmann (2004)
and argued by Manning and Pischke (2006), much of the evidence may not reflect causal
relationships since students may select into schools based on unobserved characteristics that also
affect outcomes. As such, the effect of ability-grouping on students remains unclear. Even
though I do not identify the effect of moving from an ability grouped system to an ungrouped
system, because the full effect of ability-grouping will reflect, in part, the effect of abilitygrouping on the margin, credible evidence on how students in an ability-grouped education
system are affected by ability-grouping contributes to this literature.
While school effects likely reflect a combination of peer, teacher, and school input
quality effects, it is helpful categorize schools by the achievement level of the students. The

8

Atkinson, Gregg and McConnell (2006); Ariga, Brunello, Iwahashi and Rocco (2005); Brunello and Checci
(2006); Hanushek and Woessmann (2007); Maurin and McNally (2007).

4

results indicate that there is student self-selection such that OLS estimates overstate the benefits
to attending schools with higher-achieving peers. However, instrumental variables and RD
estimates show that students who attend schools with higher-achieving peers are more likely to
stay in school to take the secondary leaving exams, have high test scores, pass more exams, and
earn the prerequisites for admission to tertiary education. The findings suggest that abilitygrouping may increase educational inequality on a broad range of outcomes by reinforcing preexisting achievement differences. I find that the marginal effects are about twice as large for girls
than for boys, indicating that girls benefit more from attending schools with higher-achieving
peers than boys. The results suggest that there are benefits to attending better schools at all points
in the school quality distribution. However, I find that the effect of attending a school with
marginally higher-achieving peers is very low among schools with low-achieving students.
The remainder of the paper is as follows: Section II describes the Trinidad and Tobago
education system and the data used. Section III describes the empirical strategy. Section IV
presents the results, and Section V concludes.

II

The Trinidad and Tobago Education System and the Data.
The Trinidad and Tobago education system evolved from the English education system.

Secondary school begins in first form (the equivalent of grade 6, hereinafter referred to as 6th
grade) and ends at fifth form (the equivalent of grade 10, hereinafter referred to as 10th grade)
when students take the Caribbean Secondary Education Certification (CSEC) examinations.
These are the Caribbean equivalent of the British Ordinary levels (O-levels) examinations.9 The
CSEC exams are externally graded by examiners appointed by the Caribbean Examinations
Council. Students seeking to continue their education typically take five or more subjects, and
the vast majority of testers take the English language and mathematics exams.10
In Trinidad and Tobago, there are eight educational school districts. Unlike in many

9

There are 31 CSEC subjects covering a range of purely academic subjects such as Physics, Chemistry and
Geography, and more work and vocationally related subjects such as Technical Drawing and Principles of Business
and Office Procedures.
10
The CSEC examinations are accepted as an entry qualification for higher education in Canada, the United
Kingdom and the United States. After taking the CSEC, students may continue to take the Caribbean Advanced
Proficiency Examinations (CAPE), at the end of sixth form (the equivalent of grade 12), which is considered tertiary
level education but is a prerequisite for admission to the University of the West Indies (the largest University in the
Caribbean and is the primary institution of higher learning for those seeking to continue academic studies). The
CAPE is the Caribbean equivalent of the English Advanced Levels (A-Levels) examinations.

5

countries where private schools are often of higher perceived quality, private schools in Trinidad
and Tobago account for a small share of student enrollment and tend to serve those who “fall
through the cracks” in the public system.11 There are three types of public secondary schools:
Government schools, Government Assisted schools and Comprehensive schools. Government
schools are secondary schools that provide instruction from 6th through 10th grade and often
continue to 12th grade (called upper-sixth form). These schools teach the national curriculum and
are fully funded and operated by the Government. Government Assisted schools, often the more
elite schools, are like Government schools but differ along a few key dimensions. They are run
by private bodies (usually a religious board) and, while capital expenses are publicly funded,
their teacher costs are not paid for by the Government. Along all other dimensions, Government
and Government Assisted schools are identical. The third type of schools, Comprehensive
schools, are Government schools that were historically vocational in focus. In the past, students
with low test scores after 5th grade were assigned to such schools and after 3 years took an exam
to gain admission to a senior secondary school (or possibly a regular Government school) which
would prepare them for the CSEC examinations. This third type of schools has been phased out
so that in 2000, the relevant sample period, all schools taught the same academic curriculum and
only a handful of Comprehensive schools did not provide instruction through to the CSEC
exams.12
II.1.

Data and Summary Statistics:
I aim to identify the effects of attending a secondary school with higher-achieving peers

on students’ CSEC examination performance. The data used come from two sources: the official
SEA test score data (from 5th grade) for the 2000 cohort and the official 2004 and 2005 CSEC
test score data. The 2000 cohort SEA data contain each of the nation's 31,593 student’s SEA test
scores, their list of preferred secondary schools, their gender, age, religion code,13 primary school
district, and the secondary school to which they were assigned by the Ministry of Education. The

11

This is evidenced by the fact that students who attend private secondary schools have test scores that are a third of
a standard deviation lower than the average SEA taking student, and half a standard deviation lower than the average
among those students who take the CSEC exams.
12
In those few junior Comprehensive schools that do not provide instruction through to the CSEC exams the vast
majority of students would attend the senior secondary school associated with their junior secondary school. For
example, a typical student who is assigned to Arima junior secondary school will take the CSEC examinations at
Arima senior secondary school, provided the student does not drop out of the system.
13
To preserve confidentiality I was not given access to the actual religion, but a code that identified students’
religions.

6

SEA exam is comprised of five subjects that all students take: math, English, science, social
studies, and an essay. To track these 5th grade students through to secondary school in 10th grade,
I link the SEA data with the 2005 and 2004 CSEC examination data. Of the 31,593 SEA test
takers in 2000, 22,876 students were linked to CSEC exam data five years later (or four years for
early takers). 14 The CSEC data contain each student's test grades on each CSEC exam and
secondary school they attended. In the data, there are 123 public secondary schools and several
small test taking centers and private schools. Among those students linked to CSEC data, 1,364
(just under six percent) attended a private institution, were home schooled, or were unaffiliated
with any public education institution. With the CSEC data, I determine whether a student took
the CSEC exams, compute the number of examinations taken and passed, and determine if they
obtained the pre-requirements for tertiary education (passing five CSEC exams including English
and mathematics). I also report students’ grades on the English and Mathematics CSEC exams.
In its raw form, lower scores on the CSEC examinations denote better performance. For ease of
interpretation, the CSEC scores have been recoded so that higher scores reflect better
performance.
Table 1 summarizes the final dataset, broken up by the secondary schools’ rankings in
incoming SEA scores (i.e. the school with the highest average incoming total SEA scores is
ranked first and the school with the lowest average total SEA scores is ranked last). The SEA
scores have been normalized to have a mean of zero and a standard deviation of one. As one can
see in Table 1, there is substantial variation in school and peer quality in Trinidad and Tobago.
The average total SEA scores are 1.78 standard deviations higher at the top 40 schools than the
bottom 40 schools. The difference between the top and bottom ranked schools is a full 4.93
standard deviations. Schools ranked in the top 40 had students with over one standard deviation
higher incoming math and English SEA scores than schools ranked between 41 and 80, which in
turn had students with average math and English incoming scores over half a standard deviation
higher than schools ranked below 80. To provide a deeper sense of the variation in peer quality
across schools in Trinidad and Tobago, Appendix Figure A1 shows the distribution of total SEA
scores for schools with different ranks in mean peer quality.

14

Students were matched based on name, gender and date of birth. The match rate was just over 70 percent, which is
consistent with the national high school dropout rate of one third.

7

Table 1
Summary Statistics: By School Rank in Average Incoming Total SEA Scores
Rank Range (by incoming peer scores)

1-40

SEA Cohort Year

41-80

81+

2000

Normalized SEA Score Total (incoming)
Normalized SEA Score Math (incoming)
Normalized SEA Score English (incoming)
Female
Take CSEC
Exams Taken
Exams Passed
English Grade (1=lowest , 7=highest)
Math Grade (1=lowest , 7=highest)
Certificate a
Admitted Cohort Size
Government Assisted School
Government School

Observations

1.26

0.12

-0.52

(0.67)

(0.76)

(0.80)

1.11

0.01

-0.59

(0.68)

(0.83)

(0.77)

1.16

0.06

-0.51

(0.67)

(0.81)

(0.81)

0.53

0.52

0.55

(0.50)

(0.50)

(0.50)

0.90

0.75

0.65

(0.30)

(0.43)

(0.48)

6.38

4.43

2.96

(2.37)

(2.82)

(2.69)

5.45

2.26

1.03

(2.61)

(2.43)

(1.73)

5.73

3.68

2.65

(1.94)

(2.08)

(1.88)

5.36

3.13

2.36

(1.98)

(1.88)

(1.59)

0.70

0.18

0.05

(0.46)

(0.38)

(0.22)

179.24

389.18

544.75

(150.87)

(232.58)

(203.32)

0.65

0.00

0.00

(0.48)

(0.00)

(0.00)

0.35

0.65

0.64

(0.00)

(0.47)

(0.47)

5337

10016

16240

Standard deviations are reported below the sample means.
a Certificate denotes passing five CSEC exams including English and math. This is a prerequisite to most tertiary education
institutions.

As is becoming increasingly common in many countries, females make up slightly more
than half of students in each school group. As one might expect, those schools that have the
brightest peers also have the best outcomes. In 2000, 90 percent of students at schools ranked
better than 40 took the CSEC exams compared to 75 percent for schools ranked 41 to 80, and 65
percent for schools ranked below 80. Students in the top 40 schools take several more exams and
pass several more exams than students at lower ranked schools, such that the average student at a
8

top 40 school takes 6.38 exams and passes 5.45 of them, compared to taking 4.43 exams and
passing 2.2 exams in schools ranked between 41 and 80 and taking 2.93 exams and passing only
1.03 at schools ranked below 80. Some of these differences reflect the fact that students who do
not take the CSEC exams have no passes or exams attempted.15 There are also large differences
in math and English grades earned by these students on the CSEC exams. The CSEC grades go
from 1 through 7, with 1 being the lowest score and 7 being the highest. A one point difference
represents the difference between an A and a B. Students who have not taken the CSEC exams
are given a grade of 7. Students at top 40 schools score on average 2.05 grade points better in
math and 2.2 grade points better in the English CSEC exams than students in schools ranked 41
through 80. They also score 3.08 grade points better in math and 3 grade points better in English
than students at schools ranked below 80. This three grade point difference is the distance from
an A to a D, such that if the average student at a top 40 school earns a B, the average student at
schools ranked between 41 and 80 earns a D and a student in a school ranked below 80 earns an
F. The last outcome is obtaining a certificate. This variable denotes passing five CSEC subjects
including math and English. This is a common prerequisite for continuing education. There are
clear differences in this outcome across schools such that 70 percent of students at the top 40
schools earn a certificate, compared to only 18 percent at schools ranked between 41 and 80 and
5 percent at schools ranked below 80. Surprisingly, virtually no student who attends a school
ranked below 80 satisfies the requirement to continue to 11th and 12th grades.
Table 1 documents that schools with the highest achieving students are on average
smaller and disproportionately Government Assisted schools, while the schools with the weakest
performing students are disproportionately Comprehensive schools. Roughly two thirds of the
top 40 schools are Assisted while none are Comprehensive, and about one third of schools
outside of the top 40 are Comprehensive schools. In Trinidad and Tobago, as in many nations,
the schools that attract the brightest students typically have the best school resources. The one
input for which there is aggregate data across school types is teachers. In 1999, 86 percent of
teachers at Government Assisted schools had a bachelor’s degree compared to 70 percent for
Government schools and only 64 percent for Comprehensive schools. Similarly, 31 percent of
Government Assisted school teachers had an education degree compared to 28 percent for
15

In section IV.1, I decompose the full effect of attending a better school into the effect associated with an increased
likelihood of taking the CSEC exams and the effect due to improving CSEC performance among students who
would have taken the CSEC irrespective of the school they attended.

9

Government schools and 12 percent for Comprehensive schools (National Institute of Higher
Education and Science and Technology 1999).
To get a sense of the distribution of mean peer quality across schools, Appendix Figure
A2 shows the distribution of mean incoming SEA scores for the schools to which students were
assigned. This measure is not identical to the peer quality students are actually exposed to since
not all students remain in their assigned school. While there are a few schools with mean peer
test scores lower than one standard deviation below the mean, the remaining schools are
relatively evenly distributed between 1 standard deviation below the mean and 2 standard
deviations above the mean.
II.2.

Student Assignment Rules (Algorithm): Due to a disparity between the number of

secondary-school places and the number of school-age children, students compete for a limited
number of premium slots. After grade five, students take the SEA examinations. Each student
lists four ordered secondary school choices. These choices and their SEA score are used by the
Ministry of Education to assign them to schools using the following algorithm. Each secondary
school has a predetermined number of open slots each year and these slots are filled sequentially
such that the most highly subscribed/ranked school fills its spots first, then the next highly
ranked school fills is slots and so on and so forth until all school slots are filled. This is done as
follows: (1) Each student is tentatively assigned to their first choice school. The school that is
oversubscribed with the highest “cut off” score fills its slots first. For example, suppose both
school A and school B have 100 slots, and 150 students list each of them as their top choice. If
the 100th student at school A has a score of 93% (its “cut-off” score) while the 100th student at
school B has a score of 89%, school A is ranked first and fills all its spots first. (2) Those filled
school slots and the students who are assigned to the highest ranked school are removed from the
applicant pool and the process is repeated, where a student’s second choice now becomes their
first choice if their first choice school has been filled.
This process is used to assign over 95 percent of all students. However, there is a group
of students for whom this mechanism may not be used. Government Assisted schools (which
account for about 16 percent of school slots) are allowed to admit 20 percent of their incoming
class at the principal’s discretion. As such, the rule is used to assign 80 percent of the students at
these schools, while the remaining 20 percent are hand picked by the school principal before the

10

next highest ranked school fills any of its slots. For example, suppose the highest ranked school
has 100 slots and is a Government Assisted school. The top 80 students will be assigned to that
school while the principal will be able to hand pick 20 other students who listed the school as
their top choice. The remaining 20 students would be chosen based on family alumni
connections, being relatives of teachers or religious affiliation (Since Government assisted
schools are often run by religious bodies). Only after all the spots (the assigned 80 percent and
the hand-picked 20 percent) at the highest ranked school have been filled will the process be
repeated for the remaining schools. As such, the school assignments are based partly on a
deterministic function of student test scores and student preferences (which is beyond students’
control after taking the SEA exams), and partly on the hand-picking of students by school
principals (which can potentially be manipulated by students).
Since student preferences are an important part of the assignment process, it is important
to better understand them. Students’ school choices are based largely on their own perceived
ability, geography, and religion. Specifically, higher ability students tend to have higher
achievement schools in their list, students often request schools with the same religious
affiliation as their own, and students typically list schools that are geographically close to their
homes. Since Trinidad and Tobago is small, attending school far from home is uncommon but
feasible. Figure 2 shows the cumulative distribution of the mean peer incoming SEA scores of
students’ school choices. As one would expect, the distribution of mean SEA scores of first
choice schools is to the right of the second choice schools which is to the right of the third choice
schools which, in turn, is to the right of the fourth choice schools. In other words, students tend
to put schools with higher-achieving peers higher up on their preference ranking. In fact, on
average the difference between the mean incoming SEA scores at a student’s top choice school
and second choice school is 0.277 standard deviations, between the top choice school and the
third choice school is 0.531 standard deviations, and between the top choice school and the
fourth choice school is 0.82 standard deviations. Roughly 15 percent of students make their top
choice school, and for those students who did not, the difference in mean total SEA scores
between their actual school and their top choice school is 0.87 standard deviations.

11

1

Distribution of mean SEA scores of school choices

Empirical cumulative density
.2
.4
.6
.8

Fourth Choice

Third Choice
Top Choice

0

Second Choice

-1

0
1
Mean SEA score of school choice

2

Figure 1
Distribution of Peer Quality by School Choice Rank

III

Identification Strategy
I aim to estimate the effect of attending a better school on students’ academic

performance. First, in sub-section III.1, I describe a naïve baseline empirical model and point out
its limitations. I then describe the rule-based instruments, and show that they are a good
approximation of the real assignment algorithm in sub-section III.2. In sub-section III.3, I discuss
the sources of exogenous variation in students’ school assignments that are generated by the rulebased instrument. In sub-section III.4, I outline a regression discontinuity based 2SLS
identification strategy that isolates part of the exogenous variation due to the rule-based
instruments, and a 2SLS identification strategy that uses all of the exogenous variation generated
by the rule-based instruments. Finally, in sub-section III.5, I present specification and
falsification tests to show the validity of the two identification strategies.
III.1

Naïve Baseline model: To estimate the effect of attending a school with higher-

achieving peers, the basic empirical strategy is to compare the outcomes of students with similar
incoming test scores at different schools using cross-sectional variation from the 2000 SEA
cohort. For the naïve baseline specification, I model the outcome of student i at a school s with
12

the following equation.
[1]

Yi , s  SEAi    SEAs  X i   i , s

In [1], SEAs is the mean total SEA scores for incoming students at school s, SEAi is a matrix of
incoming test scores (the student’s total SEA score, total SEA score squared, total SEA score
cubed , total SEA score to the fourth power, math SEA score, math SEA score squared, English
SEA score and English SEA score squared), X i includes student gender, religion, and primary
school district, and i,s is the idiosyncratic error term. Naïve OLS estimates of π from [1] may be
biased since (1) students who are unhappy with their initial school assignment can appeal and
have their assignment changed, (2) students may be able to transfer across schools, and (3)
Government Assisted schools can admit 20 percent of their incoming class at the discretion of
the school principal. Because there is ample opportunity for students to self-select into schools, I
propose a rule-based instrumental variables strategy to deal with this endogeneity concern.

III.2

Rule-Based Instrument: To remove self-selection bias from the actual school

attendance, one needs the school assignment that would prevail if students could not self-select
into schools. Such an assignment can be constructed by “tweaking” the school assignment
mechanism to impose the deterministic portion of the assignment mechanism on all students.
Since the deterministic portion of the assignment mechanism is used to assign most students to
schools, the school assignments based on the “tweaked” assignment mechanism should be
correlated with the schools students actually attend. However, since the deterministic portion of
the assignment mechanism cannot be manipulated by students or school principals, the
“tweaked” assignments should be uncorrelated with unobserved student characteristics such as
motivation and ability, conditional on student test scores and school choices. As such, I propose
two instrumental variables strategies based on these “tweaked” assignments.
The rule-based instrumental variables strategies are in the spirit of Campbell (1969),
Angrist and Lavy (1999) and Andrabi, Das and Khwaja (2007). I exploit the fact that the school
attended, and therefore the mean SEA scores of students at the school attended, is partly based
on a deterministic function of the student’s total SEA score and the student’s school preferences.
Since this deterministic function is non-linear and non-monotonic, it can be used as an
instrument while directly controlling for smooth functions of the underlying covariates

13

themselves (Fisher 1976). For each school student pair, I use the following rule for whether
student i is assigned to school s.
[2]

0 if SEAi  cs
Ruleis  0 if s  { pref i }
1 if SEAi  cs and j  { prefi } and Ruleis '  1 s ' i s

Where cs is the cut-off score for school s, prefi is the set of school choices for student i, and
s ' i s if student i prefers school s’ over school s. The first condition captures the fact that
schools use cut-off scores to assign students. The second condition captures the fact that students
are not assigned to schools that are not in their choice set. The third condition shows that a
student is assigned to a school if they have a score above the schools cut-off, the school is in
their choice set, and the student has not already been assigned to a school they prefer. Ruleis is, in
essence, the deterministic portion of the student assignment algorithm. Ruleis shows that the
school assignments are not only determined by student test score or student preferences, but also
by the interaction between the two. This plays a central role in my identification strategy.
As discussed in section II, the cut-offs are unknown to educators, principals and students
while the SEA exams are being taken – precluding any gaming of the cut-offs. The cut-offs are
set to fill all of a school’s available slots each year based on the assignment algorithm. Since I
want the cut-off that would prevail in the absence of any self-selection or hand-picking, I model
the cut-off score for school s as the cut off score that would prevail if all students were assigned
to schools according to Ruleis . Specifically the cut-off for school s is
[3]

cs  [ SEArankis Ts | s  { prefi } and Ruleis '  1 s ' i s ]

Where Rankis is the rank of student i among those who are in the admission pool for school s, so
that SEArankis Ts is the SEA score of the Tth ranked students in school s’s applicant pool. Ts is the
fixed capacity of school s.
The rule-based instrument is constructed sequentially as follows: (1) All secondary
school sizes are given,16 (2) all students are tentatively assigned to their top choice school, (3) the
school for which the first rejected student has the highest test score fills all its slots (with the
16

School sizes are not endogenous to the application process and are based on strict capacity rules. School sizes are
determined before students are assigned to schools and based on their predetermined school sizes the algorithm is
applied. As such, the number of students assigned to a particular school (even if they do not attend) is the actual
number of predetermined slots at the school.

14

highest scoring students who listed that school as their first choice), (4) the students who were
rejected from the top choice school are sent back into the applicant pool and their second choice
school becomes their first choice school, (5) Steps 2 through 5 are repeated, excluding assigned
students and assigned school slots until the lowest ranked school is filled. The only difference
between how students are actually assigned and the “tweaked” rule-based assignment is that at
step (3) the “tweaked” rule does not allow any students to be hand-picked while, in fact, some
students are hand-picked by principals only at Government Assisted schools. The resulting

Ruleis variables correctly identify the school assignment for 16,705 students. Since students who
list schools above their score range will not be assigned based on their preferences, there are
6,177 students with no simulated assignment. Among students assigned to schools within their
choice set, the rule is correct about two thirds of the time.
Since I aim to identify the effect of attending a better school using only credibly
exogenous variation, the final estimation sample is limited to students who (a) were assigned to a
school that provides instruction through to the CSEC exams and (b) had a simulated school
assignment. This sample restriction excludes 6,177 students without a simulated school
assignment, and 2,119 students who were assigned to the three junior secondary schools that
have no associated senior secondary school and do not provide instruction through to 10th grade
(form 5). 17 Of the 123 public secondary schools in Trinidad and Tobago, 98 of them have
students who are simulated to be assigned to them.18 As such, the final data set used comprises of
23,322 students at 98 schools.
It is clear from equation [2], that if the simulation works well so that the simulated cutoffs are close to the actual cut-offs, among those students who apply to any given school, the
likelihood of attending that school should increase relatively sharply for those above the
simulated cut-off relative to those who score below the cut-off. To provide evidence of this, I
follow an approach used in Pop-Eleches and Urquoila (2008) for combining several
discontinuities into one. Specifically, for each school I find all students who list that school as

17

To ensure that the results were not being driven by the exclusion of these schools from the sample, I ran models
that used the modal secondary school attended by student from these junior secondary schools and included them.
The results were not appreciably different.
18
The remaining schools are schools that nobody lists in their preferences, either because they are new schools, or
because they are undesirable. Since students with low scores will be assigned to the local high school that has
available space if they “fail” out of their choice schools, students have no incentive to list these schools if they
believe they have a chance of gaining entry to a higher ranked school.

15

the top choice, re-center all those students' test scores around the cut-off for that school, and then
create a sample of applicants for each school. I then remove students who were admitted to their
top choice schools, replace students’ first choice with their second choice, and repeat this process
with the second choice, third choice, and fourth choice. The applicant samples for all schools are
then stacked so that every student has one observation for each school for which they were an
actual applicant. For example, a student who attends their top choice school will only be in the
data once for their top choice school, while a student who gets into their second choice school
will be in the data twice (once for their top choice school and once for their second choice
school). With this stacked dataset, one can see if the likelihood of being admitted to a school
increases suddenly for those applicants with scores above the cut-off relative to applicants with
scores below the cut-off.
Likelihood of being assigned to preferred school

0

.2

.4

.6

.8

by total SEA score (relative to simulated cut-off of preferred school)

30

35
40
45
50 quantiles of relative score

50

Note: Each dot represents the sample averege of the outcomes for the quartile group of the relative score. The linear
fit is shown on either side of the simulated cut-off. The actual cut-off is dentoded by the vertical line. Since the cutoff is simulated and therfore not exact, the outcome at the cut-off point (and 2 points on either side) is exluded.

Figure 2
Likelihood of being Assigned to Preferred School

Figure 2 shows the likelihood of being assigned to the most preferred school for groups
of students defined by their score relative to the cut-off for the preferred school. The location of
the simulated cut-off (a relative score of zero) is indicated by the vertical line. Figure 2 provides

16

compelling visual evidence that there were cut-off rules used, and the simulated cut-offs are
approximately in the same areas as the real cut-offs. A regression predicting the likelihood of
being assigned to one’s preferred school as a function of scoring above the threshold for the
preferred school and a linear, quadratic, cubic and quartic in the relative score yields a
coefficient of 0.72 (se=0.0096). The standard error is adjusted for clustering at the student level.
In words, on average, an applicant with a test score just above the cut-off for their preferred
school is 72 percentage points more likely to be assigned to their preferred school than an
applicant with a test score just below the cut-off. The same model, using mean peer test scores
yields a coefficient of 0.2 with a standard error of 0.014. This suggests that, on average, an
applicant with a test score just above the simulated cut-off for their preferred school attends a
school where mean peer test scores are one fifth of a standard deviation higher than an applicant
with a test score just below the simulated cut-off.
The second important aspect of the rule is that students be assigned to schools that are in
their choice set, and are not assigned to schools that are not in their choice set unless they fail out
of all their listed schools. Some statistics will show that this is the case. First, of the 31,620
students who took the SEA exams, 21,466 were assigned to schools in their choice set. Second,
as shown in Figure 2, students were more likely to be assigned to their preferred school the
higher their score. Third, among those students who were assigned to schools not in their choice
set, average mean peer test scores were 0.638 standard deviations lower in the actual school
assigned than in the student’s fourth ranked school.
Taken together, the evidence strongly suggests that the assignment mechanism operates
as described by equation [2], that the simulated rule is a good approximation of the actual
mechanism, and the assignment rule results in the expected treatment differential.

III.3

Sources of Variation: Conditional on incoming test scores and preferences,

Ruleis captures two plausibly exogenous sources of variation. The first source comes from
comparing the outcomes of students at different schools who score just above and just below a
school’s cut-off. The logic behind this source of variation is the familiar regression discontinuity
logic. Specifically, the likelihood of attending one’s preferred school increases in a sudden and
discontinuous manner as one’s score goes from below the cut-off to above the cut-off for that
school. If the location of the cut-off is exogenous to student characteristics, one can reasonably

17

attribute any discontinuous jumps in the outcomes as one’s score goes from below to above the
cut-offs to the increased likelihood of attending one’s preferred school.
The second source of variation comes from comparing the outcomes of students with the
same test scores at different schools because they have different school preference orderings.
Since preferences are directly observed, and the cut-offs generate exogenous variation in school
assignments among students with the same preferences, one can directly control for a student’s
preferences (a unique feature of the Trinidad and Tobago data). To make this more salient,
consider two students (A and B) with the same test score X at different schools. Suppose both A
and B list the same first choice school, but list different second choice schools. If they both just
missed the cut-off for their top choice school, then they will both end up attending their second
choice schools. A comparison of the outcomes of A and B across their different schools will
reflect both differences in preferences and differences in schools. Consider now, two other
students (A' and B') such that A' has the same preferences as A, and B' has the same preferences
as B, but A' and B' have the same score X' that is higher than X. If X' is above the cut-off for the
top choice school, then A' and B' will both attend the same top choice school even though they
listed different second choice schools. Any difference in outcomes between A' and B' must
reflect their preferences, since they have the same test scores and attend the same school. Under
the assumption that differences in outcomes due to preferences are the same across all levels of
achievement, one can subtract the difference between A' and B' from the difference between A
and B to isolate the differences in outcomes associated with different schools.
More generally, since students with the same test scores and different preferences can and
do end up in the same school, one can control for the effect of preferences on outcomes directly
– allowing one, in principle, to compare the outcomes of students who have the same test scores
but who attend different schools even if they did not score just above or below a cut-off.

III.4

Econometric Models

In this section, I discuss the two instrumental variables estimation strategies used based
on the two sources of variation described above. The first method exploits only the variation in
school attendance driven by the location of the simulated cut-offs, resulting in a fuzzy-RD design.
Because the simulated cut-offs are not exactly the real cut-offs, the RD method is sensitive to
functional form assumptions, and there are other useful sources of variation and, I also use a

18

rule-based instrumentation strategy based on all the clean variation. The second method, my
preferred strategy, relies on both the variation in school attendance due to the cut-offs and also
that due to students having different preferences. These methods are discussed in turn.
Regression Discontinuity Instrument

As an intermediate specification between the naïve OLS model and the rule-based
instrumentation strategy, I implement an RD methodology based solely on variation driven by
the cut-offs. Figure 2 demonstrates that having a score above the cut-off for one’s preferred
school is associated with a relatively sharp increase in the likelihood of attending the preferred
school. If there is a causal relationship between attending a better school and CSEC performance,
then scoring above the cut-off should be associated with improved outcomes. Using the stacked
dataset as described previously, I can use scoring above the cut-off as an instrument for attending
a school with higher-achieving peers. Specifically, I estimate [4] and [5] with 2SLS.
[4]

SEAs  f ( SEAi ,t 1 )  1  Aboveij  1   s1   i , s ,t ,1

[5]

Yi , s ,t  f ( SEAi ,t 1 )   2  SEAs s ,2   s 2   i ,s ,t ,2

All variables are defined as in [1], SEAs is the mean total SEA scores for incoming students at
school s, Aboveij is an indicator variable that is equal to 1 if student i has a SEA score above the
cut-off for school j and 0 otherwise, and  s is a fixed effect for each cut-off (preferred school).
Since we know ex ante that Government Assisted school do not comply with the cut-offs, I
present results that exclude estimates based on cut-offs for Government Assisted schools. The
excluded instrument Aboveij yields a first stage F-statistic greater than 100. Appendix Figure A3
presents a visual representation of the RD model. Specifically, it shows a relatively sharp
increase in peer quality right around the simulated cut-offs and also shows relatively sharp
improvements in outcomes at the simulated cut-offs. While the figure shows a linear fit on either
side of the cut-off, the actual model includes smooth non-linear functions of the total score. For
all the results presented in the body of this paper, I limit the sample to all students who score
within 50 points of the cut-off. The choice of the bandwidth used does not change the results a
great deal and I present the sensitivity test of this sample choice in Appendix Table A2.
Rule-Based Instrument

As explained above, the RD design ignores a large source of credibly exogenous
variation due to preferences. One way to exploit all the clean variation is to use the rule based

19

assignments as instruments. To do this, I use the rule-based school assignments as instruments to
isolate exogenous variation in mean SEA scores of the actual schools attended in a two-stage
least squares (2SLS) regression. Specifically, I estimate the following system of equations.
[6]

98

SEAs  SEAi ,t 1  1   Ruleij  X i1   I i , p  p1   i , s ,t ,1
j 1

[7]

p 1

Yi , s ,t  SEAi ,t 1   2  SEAs s ,2  X i 2   I i , p  p 2   i , s ,t ,2
p 1

All variables are defined as in [1], SEAs is the mean total SEA scores for incoming students at
school s, I i , p is an indicator variable equal to 1 if a student’s rank ordering are preference group

p and equal to zero otherwise19 and the rule-based school assignment Ruleij is excluded in the
second stage equation. Standard errors are clustered at the school level. The first stage yields an
F-statistic on the excluded instruments over 100.

III.5

Specification Tests and Falsification Tests:

To show that my identification strategies are valid, I first present evidence that the RD
based model is likely to yield consistent and unbiased estimates of the effect of attending a
school with higher-achieving peers. The first test of the exogeneity of the cut-off is to see if there
is less density than would be expected by random chance right below a cut-off and more density
right above the cut-off than would be expected by random chance. Such a pattern would be
consistent with gaming of the cut-offs. Figure 3 shows the density of incoming test scores and
the vertical line is the cut-off. There is little evidence of such a pattern visually. Following
McCrary (2009), I test for discontinuity in the density of the total score at the simulated cut-off
while controlling for the relative score, and the quadratic, cubic and quartic of the relative score.
Where the dependent variable is the empirical density, the coefficient on an indicator variable
denoting “above cut-off” is a statistically and economically insignificant -0.003. Since gaming
would imply a positive and statistically significant coefficient, this test suggests no gaming. To
further ensure that the RD results are not driven by gaming or sorting around the cut-offs, and
because the cut-offs are approximate, I remove all points within 3 points of the simulated cut-off
19

Each preference group is defined by a distinct preference ordering of schools. All students who list schools
A,B,C,D in that order form a group, while students who list schools B,A,C,D are in a different group because even
though they have the same list of schools, the ordering is different. There are 4561 preference groups with more than
one student.

20

in all regression models. This does not affect the results in any meaningfull way.

Frequency of test scores within 20 points of simulated cut-off

Frequency of scores relative to simulated cut-off

each point is a separate score

0

0

100

100

Frequency
200

frequency of score
200
300

300

400

500

400

simulated cut-off is at 0

-20

-10
0
10
score relative to simulated cut-off

20

-300

-200
-100
0
100
score relative to simulated cut-off

200

Figure 3
Evidence of No Gaming of the Cut-Offs

Another good test of the validity of the RD design is to see if scoring above the cutoff is
associated with a sihft in preferences. If the RD is working correctly, then preferences should be
roughly balanced above and below the cut-off. If there is sorting around the cut-offs however,
since having preferences for higher-achievement schools is associated with better outcomes
(even conditional on test scores and school effects), one would expect that being above the cutoff is associated with having preferences for higher-achieving schools. Unlike most contexts
where an RD strategy is employed, I do not have to assume that preferences are balanced around
a cut-off, and I can test for it directly (and even control for it). To test for differences in
preferences, I include as the dependent variable the mean peer quality of the student top choice
school. Such a model yields a coefficient on scoring above the threshold of -0.035 with a
standard error of 0.026. The same exercise with the second, third, and fourth choice schools yield
coefficients of -0.012 (se 0.027), -0.004 (se 0.032), and -0.095 (0.051). Only the coefficient for
the fourth choice school is even marginally statistically significant. Also, all the point estimates
have negative coefficients which, if interpreted causally, would imply negative selection. As
21

such, the results suggest that there is little or no selection, and if there were selection, the RD
results are likely to be biased downward.20
Since the rule-based instrumental variables strategy is my preferred strategy, I present
evidence of the validity of this method also. I argue that since the rule-based instruments are
deterministic non-smooth functions of student test scores and preferences, conditional on test
scores and student preferences, the rule-based school assignments are exogenous to unobserved
student attributes. While this should be true by construction, I test the validity of this assumption
by seeing if the instruments are correlated with other observable student characteristics before
entering secondary school. If the rule-based instruments were correlated with observable student
characteristics such as gender, religion, and primary school district, it would cast doubt on the
assertion that they isolate exogenous variation that is free from self-selection bias. On the other
hand, if the instruments are not correlated with these pre-treatment student characteristics it
would lend credibility to the identifying assumption.
I carried out these tests formally by estimating equations [6] and [7] while using student
religion, gender and primary school district as outcomes. The 2SLS regression coefficients show
that mean peer total SEA scores, as predicted by the rule-based instruments, are not associated
with any pre-treatment student characteristics. The p-values associated with the null hypothesis
that peer achievement (as predicted by the rule-based instrument) is correlated with the pretreatment characteristics are all above 0.98. Because student religion is explicitly used by
principals when hand-picking students at religious schools, the fact that student religion is not
correlated with the instruments lends credibility to the exogeneity of the rule-based instruments.

IV

Main Results:

To show how the results differ across various models, I present the effects of attending a
school with higher-achieving peers (on the margin) using different specifications. For the main
results, I present the results separately for each outcome (taking the CSEC exams, the number of
CSEC exams passed, and obtaining a certificate). While categorizing schools by the achievement
level of the peers is helpful, these results do not only reflect the effect having higher-achieving
20

Scoring above the cut-off does not predict student gender. Of the ten religion indicator variables, nine had p-value
assoaited with scoring above the threshold greater than 0.3 and one had a p-value of 0.07 (with an economically
insignificant point estimate of 0.004). Of the eight school district indicator variables, one yeilded a statstically
significant and small effect, while the remaining seven had p-values above 0.2.

22

peers, but rather the effect of attending schools with higher-achieving peers. These effects will
reflect a variety of differences across schools such as teacher quality, input quality and peer
quality.
Table 2 shows the results on CSEC taking. The dependent variable is an indicator
variable equal to 1 if a student took the CSEC exams and equal to zero otherwise. Column 1
shows the basic relationship between mean peer test scores and CSEC taking with no control
variables. The coefficient on mean peer test scores is 0.134 with a standard error of 0.003. The
difference in peer achievement between a student’s top choice school and their third choice
school is roughly half a standard deviation. As such, I use this difference as my measure of the
typical difference in peer achievement that a student may face. The point estimate suggests that
attending a school where peer test scores are half a standard deviation higher is associated with a
6.15 percentage point increase in CSEC exam taking. Columns 2 through 4 present the OLS
model with additional controls for incoming test scores, religion, gender, primary-school district
and student preferences. As one can see, including controls for incoming test scores (in column 3)
explains away about half of the estimated effect. Specifically, conditional on incoming test
scores, attending a school with where students test scores are half a standard deviation higher is
associated with a statistically insignificant 3 percentage point increase in CSEC exam taking.
Column 4 shows that including indicator variables for students' school preferences in the OLS
model leads to a small reduction in the estimated coefficient. This implies that while preferences
may “explain away” some of the effect, conditional on test scores, student preferences do not
explain a huge amount of the "better school" effect.
The first method for addressing possible self-selection bias is the 2SLS-RD model that
uses scoring above the desired school’s threshold as an instrument for attending a school with
higher-achieving peers. Column 5 presents the 2SLS-RD model for all schools, and column 6
presents the 2SLS-RD results without government assisted schools (since there may be some ex

ante concern over gaming of the cut-offs at assisted schools). Both models include cut-off fixed
effects and adjust the standard errors for clustering at the student level. The 2SLS-RD results in
column 5 and 6 are similar to the estimated OLS effect in column 4, yielding coefficients of
0.053 and 0.04 respectively. The reduced form coefficients (not shown in the Table) on scoring
above the cut-off are 0.029 (se 0.0165) and 0.01 (se 0.022) for models 5 and 6 respectively.

23

Table 2
Effect on the likelihood of taking the CSEC exams
Mean SEA Scores

1

2

3

4

5

6

7

8

9

10

OLS

OLS

OLS

OLS

2SLS-RD

2SLS-RD

2SLS

2SLS

2SLS

2SLS

0.134

0.137

0.061

0.052

0.053

0.04

0.064

0.049

0.052

0.033

[0.038]**

[0.038]**

[0.038]

[0.042]

[0.070]

[0.089]

[0.043]

[0.050]

[0.061]

[0.067]

Controls

No

Yes

Yes

Yes

No

No

Yes

Yes

Yes

Yes

Test scores

No

No

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Preference dummies

No

No

No

Yes

No

No

Yes

Yes

Yes

Yes

Assisted included

Yes

Yes

Yes

Yes

Yes

No

Yes

Yes

No

No

Order of score

2

2

2

2

4

4

2

4

2

4

Observations

23322

23322

23322

23322

29429

16282

15796

15796

13136

13136

-

-

-

3424

-

-

3424

3424

2911

2911

Number of groups

Excluded Instrument
Abovei
Abovei
Ruleij
Ruleij
Ruleij
Ruleij
+ significant at 10%; * significant at 5%; ** significant at 1%. Robust standard errors in brackets. Standard errors are clustered at the school level
in all models except the RD model where they are clustered at the student level. The dependent variable is an indicator variable that is equal to 1
if a student took the CSEC exams and equal to 0 otherwise.
The 2SLS-RD model is based on the Regression Discontinuity model that uses the indicator for attending the preferred school as an instrument
for the mean scores. The RD model uses a bandwidth of 50 points and excludes point within 2 point of the simulated cut-off and excludes
government assisted school that may have gaming around the cut-off. All RD models control for the school cut-off fixed effects.

Because the 2SLS-RD design ignores all of the information on student preferences for
identification, and does not explicitly control for student preferences, one might expect that the
rule-based instrument strategy would yield more precise estimates and would possibly be less
subject to self-selection bias. I first present the rule based results using a quadratic in the total
score in column 7, and then the total score, its quadratic, cubic and quartic in column 8. In
columns 7 and 8, attending a school where peers have half a standard deviation higher test scores
is associated with statistically insignificant 3.2 and 2.45 percentage point increases in the
likelihood of taking the CSEC exams respectively. The results are similar to the 2SLS-RD results,
however the standard errors are about two-thirds as large. The efficiency gains over the 2SLSRD model are apparent. In columns 9 and 10, I restrict the estimation sample to those students
who were not predicted to be assigned to Government Assisted schools to roughly mimic the
clean RD sample. In these models, while using a quadratic (column 9) and a quartic (columns 10)
in the total score, attending a school with half a standard deviation higher peer achievement is
associated with statistically insignificant 2.6 and 1.65 percentage point increases in the likelihood
of taking the CSEC exams respectively. Since all the specifications yield positive estimates of
similar orders of magnitude, and the standard errors are about 0.067, I am cautious not to
interpret this as no effect, but rather as an imprecisely estimated positive effect.

24

In sum, models that control for student test scores and student preferences, regression
discontinuity models and rule based instrumental variables models all indicate that attending a
school where mean peer achievement is half a standard deviation higher would be associated
with between a 1.65 and 3.2 percentage point increase in the likelihood of taking the CSEC
exams. This difference in peer quality is roughly the difference between attending one’s top
choice school and attending one third choice school.
The next main outcome of interest is the number of exams passed, presented in Table 3.
For the number of exams passed, all specifications yield a statistically significant positive
relationship between attending a school with higher-achieving peers and the number of exams
passed. Specifically, in the descriptive regression (column 1), a half a standard deviation increase
in peer quality is associated with passing 1.2 more exams. However, conditional on incoming
test scores and preferences (column 4) this increase is only 0.75 more exams. Columns 5 and 6
present the 2SLS-RD results for the full sample and then only for those schools that adhere to the
cut-off rules respectively. The coefficient for the full sample is 1.61 (larger than the OLS
estimate) while it is only 0.83 (smaller than the OLS estimate) for the clean RD sample. This
implies one of two things: (1) there is gaming around the cut-offs for the Government Assisted
schools that lead to an upwards bias or (2) there is non-linearity such that the assisted schools
provide higher value-added on the margin. I will address the issue of non-linearity in section IV.
The reduced form coefficients (not shown in the Table) on scoring above the cut-off are 0.323
(se 0.123) and 0.1873 (se 0.123) for models 5 and 6 respectively.
Columns 7 and 8 of Table 4 present the rule-based instrumentation results that include
controls for a quadratic and quartic of the total SEA score respectively. The coefficient of 0.91 in
both columns 7 and 8 indicate that a student who attends a school where the peers have half a
standard deviation higher test scores will pass about 0.45 more exams. However, the rule based
instrument results excluding students who were assigned to Government Assisted schools in
columns 9 and 10 indicate that a student who attends a school where the peers have half a
standard deviation higher test scores will only pass between 0.29 and 0.32 more exams. While
the point estimates differ somewhat from specification to specification, they all yield positive
point estimates that are statistically significant at the one percent level, and they all lie within 1.5
standard errors of each other. The more conservative estimates suggest that having peers with
half a standard deviation higher test scores will lead to passing between 0.29 and 0.45 more

25

exams. This difference in peer quality is roughly the difference in the mean test score between
students’ top choice school and their third choice school. The difference in mean peer scores
between students’ top choice schools and the schools they actually attend is 0.87 standard
deviations - implying that students who miss their top choice schools will, on average, pass
between 0.51 and 0.79 fewer exams.
Table 3
Effect on the number of CSEC exams passed

Mean SEA Scores

1

2

3

4

OLS

OLS

OLS

OLS

2.41

2.407

1.321

1.497

5

6

2SLS-RD 2SLS-RD

[0.071]** [0.060]** [0.139]** [0.147]**

1.61

0.83

[0.459]**

[0.524]

7

8

9

10

2SLS

2SLS

2SLS

2SLS

0.91

0.9

0.588

0.634

[0.204]** [0.188]** [0.193]** [0.193]**

Controls

No

Yes

Yes

Yes

No

No

Yes

Yes

Yes

Test scores

No

No

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Preference dummies

No

No

No

Yes

No

No

Yes

Yes

Yes

Yes

Assisted included

Yes

Yes

Yes

Yes

Yes

No

Yes

Yes

No

No

Order of score

2

2

2

2

4

4

2

4

2

4

Observations

23322

23322

23322

23322

29429

16282

15796

15796

13136

13136

-

-

-

3424

-

-

3424

3424

2911

2911

Number of groups

Yes

Abovei
Ruleij
Ruleij
Ruleij
Ruleij
Excluded Instrument
Abovei
Robust standard errors in brackets. Standard errors are clustered at the school level in all model except the RD model where they are clustered at
the student level.
+ significant at 10%; * significant at 5%; ** significant at 1%. Robust standard errors in brackets. Standard errors are clustered at the school level
in all models except the RD model where they are clustered at the student level. The dependent variable is the number of SEA exams passed.
This variable is equal to zero for student who do not take the CSEC exams.
The 2SLS-RD model is based on the Regression Discontinuity model that uses the indicator for attending the preferred school as an instrument
for the mean scores. The RD model uses a bandwidth of 50 points and excludes point within 2 point of the simulated cut-off and excludes
government assisted school that may have gaming around the cut-off. All RD models control for the school cut-off fixed effects.

The last main outcome, obtaining a certificate, is presented in Table 4. Because passing at
least five CSEC exams including mathematics and English (that is, earning a certificate) is the
prerequisite to pursuing tertiary education, this outcome is a good measure of the likelihood that
a student continues on to tertiary education. As with the number of exams passed, all
specifications show a positive and statistically significant relationship between attending a
school with higher-achieving peers and obtaining a certificate. In the descriptive regression in
column 1, an increase in peer quality of half a standard deviation is associated with being 17.6
percentage points more likely to earn a certificate. However, conditional on incoming test scores
and preferences, this increase is only 10.45 percentage points. Columns 5 and 6 present the
2SLS-RD results for the full sample and then only for those schools that adhere to the cut-off

26

rules. The coefficient for the full sample is 0.283 (larger than the OLS estimate) while it is only
0.19 (smaller than the OLS estimate) for the clean RD sample. The reduced form coefficients
(not shown in the table) on scoring above the cut-off are 0.0568 (se 0.0027) and 0.0428 (se 0.02)
for models 5 and 6 respectively. The 2SLS-RD coefficient of 0.19 for the clean sample suggests
that an increase in peer quality of half a standard deviation due to scoring above a schools cut-off
is associated with being 9.5 percentage points more likely to earn a certificate.
Table 4
Effect on the Likelihood of Earning a Certificate
1
Mean SEA Scores

2

3

4

OLS

OLS

OLS

OLS

0.353

0.351

0.18

0.209

5

6

2SLS-RD 2SLS-RD
0.283

[0.012]** [0.012]** [0.027]** [0.025]** [0.078]**

0.19
[0.090]*

7

8

9

10

2SLS
0.189

2SLS

2SLS

2SLS

0.163

0.139

0.12

[0.035]** [0.036]** [0.035]** [0.033]**

Controls

No

Yes

Yes

Yes

No

No

Yes

Yes

Yes

Test scores

No

No

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes
Yes

Preference dummies

No

No

No

Yes

No

No

Yes

Yes

Yes

Yes

Assisted included

Yes

Yes

Yes

Yes

Yes

No

Yes

Yes

No

No

Order of score

2

2

2

2

4

4

2

4

2

4

Observations

23322

23322

23322

23322

29429

16282

15796

15796

13136

13136

-

-

-

3424

-

-

3424

3424

2911

2911

Number of groups

Excluded Instrument
Abovei
Abovei
Ruleij
Ruleij
Ruleij
Ruleij
+ significant at 10%; * significant at 5%; ** significant at 1%. Robust standard errors in brackets. Standard errors are clustered at the school level
in all model except the RD model where they are clustered at the student level. The dependent variable is an indicator variable that is equal to 1 if
a student passed five CSEC exams including English and math and equal to 0 otherwise.
The 2SLS-RD model is based on the Regression Discontinuity model that uses the indicator for attending the preferred school as an instrument
for the mean scores. The RD model uses a bandwidth of 50 points and excludes point within 2 point of the simulated cut-off and excludes
government assisted school that may have gaming around the cut-off. All RD models control for the school cut-off fixed effects.

The rule-based instrument model on the full sample (columns 7 and 8) yields results that
indicate that a student who attends a school where the peers have half a standard deviation higher
test scores will be between nine and seven percentage points more likely to obtain a certificate.
However, the results obtained while excluding students assigned to Government Assisted schools
(columns 9 and 10) yield coefficient estimates on mean peer test scores of 0.139 and 0.12
respectively. These estimates suggest that a student who attends a school where peers have half a
standard deviation higher test scores will be between six and seven percentage points more likely
to obtain a certificate. All these effects are statistically significant at the one percent level. While
the exact point estimates differ across models, the conservative estimates result indicate that a
student who attends their third choice school as opposed to their first choice school would be
between 6 and 9 percentage points less likely to obtain the prerequisites to pursue a tertiary

27

education, while a student who missies their top choice school would be between 16 and 10
percentage point more likely to obtain the prerequisites to pursue a tertiary education.

IV.1

Effects on the Intensive Margin:

The results presented in Tables 2, 3 and 4, show that students who attend schools with
higher-achieving peers are slightly more likely to take the CSEC exams, they pass more exams,
and they are more likely to obtain a certificate. Since students who do not take the CSEC exams
necessarily pass zero exams and do not earn a certificate, these outcomes are equal to zero for all
students who did not take the CSEC exams so that the outcomes can be written as below.

Y  I take 1  (Y | I take 1  1)  0 .

[8]

Where I take 1 is equal to one for CSEC takers and zero otherwise. Equation [8] makes explicit
that changes in the number of passing grades or the likelihood of obtaining a certificate reflect
the effects on both the intensive margin (improvements in CSEC performance for students who
would have taken the CSEC exams irrespective of the school they attend) and the extensive
margin (the effect of taking the CSEC exams and potentially having some CSEC passes). Using
the product rule, the expected change in outcomes due to attending a “good” school as opposed
to a “bad” school can be written as
E[Y ]  [ P( I take 1  1)]  (Y0 | I take 1  1)  P0 ( I take 1  1)  (Y | I take 1  1) .

[9]

Where Y0 is the outcome of CSEC taking students at the “bad” school, and P0 is the likelihood
of taking the CSEC in the “bad” school. Equation [9] shows that changes in outcomes will reflect
an

effect

from

increasing

the

likelihood

of

taking

the

CSEC

exams

[ P( I take 1  1)]  (Y0 | I take 1  1) , and an effect from improvements in the outcomes among those
students who would have taken the CSEC exams regardless of their assigned school

P0 ( I take 1  1)  (Y | I take 1  1) .21 To get a lower bound of the effect on the intensive margin, I
multiply the estimated increase in CSEC taking by the average outcomes of all students who take
the CSEC exams. Since marginal students are likely to have worse outcomes than the average
CSEC taker, this calculation will overstate the contribution of the extensive margin yielding a
lower bound of the effect of attending a better school conditional on taking the CSEC exams.

21

This approach is similar to that use in Jackson (2009) and Lavy (2009).

28

The average CSEC taker passes 3 exams and obtains a certificate with probability 0.278.
Given that attending a school with 1 standard deviation higher-achieving peers increases CSEC
taking by about 5 percent, the extensive margin could at most be responsible for a 0.05*3=0.15
increase in the number of exams passed and a 0.05*0.278=0.014 increase in the likelihood of
earning a certificate. Given that attending a school with 1 standard deviation higher-achieving
peers increases the number of CSEC exams passed by between 0.6 and 0.9 and increases the
likelihood of earning a certificate by between 0.12 and 0.19, it is clear that most of the
improvements are experienced by students on the intensive margin. Subtracting the contribution
of the extensive margin from the full effect and then dividing by the likelihood of taking the
CSEC exams (0.73) yield implied intensive margin coefficients between 0.6 and 1 for the
number of exams passed and between 0.14 and 0.23 for obtaining a certificate. In other words, a
lower bound estimate of the effect of attending a school where peers have half a standard
deviation higher test scores, among student who take the CSEC exams, is between a 0.3 and 0.5
increase in the number of exams passed and between a 7 and 12 percentage point increase in the
likelihood of earning a certificate.
Another approach to uncovering the effect of attending a better school, conditional on
taking the CSEC exams, is to use only the sample of CSEC takers while conditioning on the
likelihood of taking the CSEC exams (Angrist 1995). The results of this method are very similar
to those of the decomposition above and are, as such, not presented here. Since the effect on the
participation margin is small, the fact that most of the effect can be attributed to the intensive
margin is not surprising.
IV.2

Effects by gender:

There is a growing literature documenting that females often benefit from interventions
while males are unaffected and in some cases perform worse.22 To investigate the effects of
attending a school with higher-achieving peers by student gender, I estimate the rule-based
instrumental variables model for the samples of females and males separately. Since the 2SLSRD methodology requires large data sets and results in imprecise estimates, I only preset the
rule-based instrumental variables results here. The 2SLS-RD results are qualitatively similar and
are presented in Appendix Table A1. Table 5 presents (1) the result of the model that uses the
22

For example Kling, Ludwig, and Katz (2005); Anderson (2007); Angrist, Lang, and Oreopoulos (2007); Angrist
and Lavy (2007); Hastings, Kane and Staiger (2006a; 2006b).

29

full sample while controlling for a quadratic in the total score, (2) the result of the model that
uses the full sample while controlling for a quartic in the total score, and (3) the result of the
model that omits those student who were assigned to assisted schools (all for males and females
separately). Each model (indicated by a number) represents a different regression. The results for
males are presented in models 1 through 9, and those for females are in models 10 thought 18.
All three outcomes are presented in the same table.
Models 1 through 3 show the effect on males of attending a school with higher-achieving
peers on SCEC taking. The results are largely the same across specifications. The point estimates
indicate that a male who attends a school where the peers have incoming test scores half a
standard deviation higher will be between 3.5 and 4.3 percentage points more likely to take the
CSEC exams. However, only the model using the full sample and controls for the quadratic in
test scores yields a marginally statistically significant estimate. The same results for females in
models 10,11, and 12, yield similar results to the males with slightly smaller point estimates. In
particular, females attending schools where peers have incoming test scores half a standard
deviations higher will be between 2.2 and 3.6 percentage points more likely to take the CSEC
exams. Since the results on CSEC taking by gender are rather imprecise, the slightly larger
participation response for males is merely suggestive.
Turing to the number of exams passed (models 4 through 6 for males and models 13
through 15 for females), large gender differences begin to emerge. Specifically, for males,
attending a school where peers have incoming test scores half a standard deviation higher results
in passing between 0.2 and 0.35 additional CSEC exams. In contrast, for females, attending a
school where peers have incoming test scores half a standard deviation higher results in passing
between 0.5 and 0.62 additional CSEC exams. The marginal effects are about twice as large for
females than for males. The point estimates are sufficiently different and precisely enough
estimated that these differences by gender are both economically and statistically meaningful.
The gender differences in obtaining a certificate are similar to those for the number of
exams passed. For males (models 7 though 9), attending a school where peers have incoming test
scores half a standard deviation higher increases the likelihood of obtaining a certificate by
between 2.25 and 6.4 percentage points. However, if one takes out the Government Assisted
schools, the estimated coefficient of 0.45 is not statistically significant. Given that the standard
errors are relatively large, this lack of significance likely reflects a lack of power for effect sizes

30

of that magnitude. In contrast, for females (models 16 though 18), attending a school where peers
have incoming test scores half a standard deviation higher increases the likelihood of obtaining a
certificate by between 9.3 and 10.9 percentage points. As with the number of exams passed, the
marginal effects are about twice as large for females than for males, and the point estimates are
sufficiently different and precisely enough estimated that these differences are both economically
and statistically meaningful.

Table 5
Rule based 2SLS results by gender
Male

Mean Peer Scores

1

2

3

4

5

6

7

8

9

Take

Take

Take

Passes

Passes

Passes

Cert.

Cert.

Cert.

0.086

0.075 0.079

0.716

0.627

0.408

0.128

0.101

0.045

[0.047]+ [0.050] [0.060] [0.241]** [0.214]** [0.232]+ [0.034]** [0.034]** [0.034]
Polynomial order

2

4

4

2

4

4

2

4

4

Assisted included

Yes

Yes

No

Yes

Yes

No

Yes

Yes

No

Observations

6165

6165

5053

6165

6165

5053

6165

6165

5053

Number of groups

1569

1569

1322

1569

1569

1322

1569

1569

1322

Female

Mean Peer Scores

10

11

12

13

14

15

16

17

18

Take

Take

Take

Passes

Passes

Passes

Cert.

Cert.

Cert.

0.073

0.054 0.044

1.232

1.242

1.043

0.218

0.198

0.186

[0.052] [0.052] [0.066] [0.255]** [0.225]** [0.237]** [0.044]** [0.040]** [0.042]**
Polynomial order

2

4

4

2

4

4

2

4

4

Assisted included

Yes

Yes

No

Yes

Yes

No

Yes

Yes

No

Observations

8484

8484

6952

8484

8484

6952

8484

8484

6952

Number of groups

2000

2000

1721

2000

2000

1721

2000

2000

1721

+ significant at 10%; * significant at 5%; ** significant at 1%.
Robust standard errors in brackets are adjusted for clustering at the school level.

IV.3

Effect on Grades Earned

Much of the literature on the effect of attending a better school has found benefits on
non-cognitive outcomes such as the number of subjects taken, being suspended, and other
behavioral outcomes. However, the findings on the effects on test scores or grades have been
31

mixed. Most studies that look at the effects of attending a better school on student test scores, do
so in contexts where all students take the tests. To be comparable, I need to estimate the effect of
attending a school with higher-achieving peers on performance on a particular exam, conditional
on taking the exam. Because virtually all students who take the CSEC exams take both math and
English, there is almost no selection to taking these exams conditional on taking the CSEC
exams. However, since there may be some selection into taking the CSEC exams, one needs to
take this into account when determining the effect of attending a better school on students math
and English exam performance for those students who would have taken the CSEC exams
irrespective of their school attended. I use the two methods described previously. First, I estimate
the model on all students, assigning the lowest possible grade to students who do no take the
subject exam, and find a lower bound of the intensive margin effect using the decomposition
discussed previously. In the second approach, I condition on the likelihood of taking the CSEC
exams and estimate the model only on those individuals who took the CSEC exams. Since the
effect of attending a better school on the CSEC participation margin is relatively small, both
strategies to account for selection yield similar results.
Table 6 presents the rule-based instrumental variables estimates of attending a school
with higher-achieving peers on math and English grades. Models 1 through 5 present the results
for English and models 6 through 10 present the results for math. Columns 1 and 2 show the
effects on reading while controlling for the quadratic and quartic of total SEA scores respectively.
These results are based on the entire sample of students (including those who do not take the
CSEC exams). Both models 1 and 2 yield the same statistically significant point estimate of
0.467. These estimates suggest that a student who attends a school where peers have half a
standard deviation higher test scores will score 0.23 grade points higher in the English exam.
This represents about a quarter of the distance between an A and a B (or a B and a C). According
to the decomposition, a student who would have taken the CSEC exams regardless of the school
assignment would have scored 0.2 grade points (twenty percent of a grade point) higher in the
English CSEC exam at a school where peer test scores were half a standard deviation higher.23

23

The average CSEC taking students earns a grade of 4.45 on the English exam, while students who do not take the
CSEC have a grade of 1. As such the 5 percent increase in CSEC taking could explain at most 0.05*(4.44-1)=0.1725
of the marginal effect. Removing this effect and dividing by the likelihood of taking the CSEC exams, yields an
intensive margin coefficient of 0.41.

32

Table 6
Rule-Based 2SLS Estimates of attending a better school on exam performance
Mean of Total SEA

Non CSEC takers included
Polynomial order
Assisted School included
Control for selection
Observations

Mean of Total SEA
Observations

1

2

4

5

0.467
[0.149]**

3
English Grade
0.364
[0.170]*

0.467
[0.144]**

0.486
[0.136]**

0.603
[0.166]**

Yes
2
Yes
No
15796

Yes
4
Yes
No
15796

Yes
4
No
No
13136

No
4
Yes
Yes
11638

No
4
No
Yes
9312

6

7

9

10

0.335
[0.133]*
15796

0.286
[0.137]*
15796

8
Math Grade
0.073
[0.153]
13136

0.239
[0.137]+
11638

0.122
[0.165]
9312

Non CSEC takers included
Yes
Yes
Yes
No
No
Polynomial order
2
4
4
4
4
Assisted School included
Yes
Yes
No
Yes
No
Control for selection
No
No
No
Yes
Yes
Observations
15796
15796
13136
11638
9312
+ significant at 10%; * significant at 5%; ** significant at 1%. Robust standard errors in brackets are adjusted for clustering at the
school level. All regressions use the Ruleij variables as the excluded instruments.

Model 3 shows the results of the same model excluding those students who do not take
the CSEC exams, while model 4 shows the same model excluding those students who do not
take the CSEC exams with the estimated likelihood of taking the CSEC included as a covariate.
As one would expect, the coefficient in model 3 (that does not control for selection to CSEC
taking) is slightly smaller than those in model 2 – indicating that there is a negative sample
selection bias. However, the results in column 4 where the estimated likelihood of taking the
CSEC is included as a covariate are similar to those in models 1 and 2. Column 5 shows the
selection corrected model using the sample of CSEC takers who were not assigned to
Government Assisted schools. The estimated coefficient is higher than all the rest at 0.6 –
suggesting that attending a school where peer test scores are half a standard deviation higher
increases the English grade by 0.3 grade points (about 1.5 times the lower bound estimate).
The results for math in models 6 through 10 are less robust than those for English. The
results in models 6 and 7 based on the entire sample of students have estimated coefficients of
0.335 and 0.286 respectively – suggesting that attending a school where peers test scores are half
a standard deviation higher increases the math grade by between 0.14 and 0.17 grade points.
33

According to the decomposition, a student who would have taken the CSEC exams regardless of
the school assignment would have scored 0.1 grade points (a tenth of the difference between an
A and a B) higher in the math CSEC exam at a school where peer test scores were half a standard
deviation higher.24
While, the coefficient on the model that excludes non-CSEC takers in column 8 is a
statically insignificant 0.073, when one controls for selection to CSEC taking, the coefficient is a
marginally statistically significant 0.239 (in model 9). Similar to the decomposition, this suggests
that a student who would have taken the CSEC exams regardless of the school assignment would
have scored 0.12 grade points higher in the math CSEC exam at a school where peer test scores
were half a standard deviation higher. Excluding students assigned to Government Assisted
schools, the estimated coefficient is a statistically insignificant 0.122. Since the point estimates
are positive for all models, and the standard errors are about 0.15, there may be positive effect on
math grades that is too small to be detected with these data. The results imply that a lower bound
estimate for the effect of attending a school with half a standard deviation higher peer quality is
about 0.06 grade points in math and 0.2 grade points in English.
Effects on Grades Earned by Gender:

To test for gender differences in exam grades, I estimate the preferred 2SLS specification
for the test score outcomes (using the sample of CSEC takers and controlling for the likelihood
of taking the CSEC) separately for males and females. The effects on Math and reading grades
by gender exhibit similar patterns to the other outcomes. Table 7 presents the effects of attending
a school with higher-achieving peers for those students who take the CSEC exams. Columns 1
through 4 present the results for males. Columns 1 and 2 show that males who attend better
schools have better grades on the English CSEC exams. These effects are only marginally
statistically significant and are smaller than those for the entire sample. Columns 5 and 6 show
strong evidence that female English performance is improved by attending a better school. The
point estimates are about twice the size of those for males and are statistically significant at the
one percent level. Specifically the estimates suggest that a female who attends a school with
peers that have half a standard deviation higher test scores will score about 0.29 grade points

24

Since the average math grade among CSEC takers is 3.9, the extensive margin could explain as much as 0.05(3.91)=0.145. Removing this effect and dividing by the likelihood of taking the CSEC exams, yields an intensive margin
coefficient of 0.205.

34

higher on her English CSEC exams, while a male would only score between 0.12 and 0.18 grade
points higher.
The results for math (columns 5 through 8) show even starker differences by gender. The
results indicate that while a female who attends a school with peers that have half a standard
deviation higher test scores will score between 0.148 and 0.18 grade points higher on her Math
CSEC exams, males do not appear to benefit at all. In fact, the point estimates in columns 3 and
4 are negative, suggesting that males could actually have worse math performance when
attending a school with higher-achieving peers. Since these negative point estimates for males
are not statistically significant this effect is largely suggestive.

Table 7
Effect of attending a better school on English and Math CSEC grades by gender
1

2

3

4

5

Male CSEC takers only
English
Grade
Mean of Total SEA

English
Grade

Math
Grade

6

7

8

Female CSEC takers only
Math
Grade

English
Grade

English
Grade

Math
Grade

Math
Grade

0.241

0.363

-0.092

-0.217

0.575

0.585

0.373

0.286

[0.181]

[0.205]+

[0.194]

[0.216]

[0.168]**

[0.203]**

[0.164]*

[0.199]

Observations

3994

3039

3994

3039

6813

5458

6813

5458

Number of groups

1088

869

1088

869

1667

1411

1667

1411

Control for selection

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Assisted School included?

Yes

No

Yes

No

Yes

No

Yes

No

+ significant at 10%; * significant at 5%; ** significant at 1%.
Robust standard errors in brackets are adjusted for clustering at the school level.

IV.4

Elite schools or bad Schools?

Proponents of school ability-grouping support ability-grouping based on the belief that it
creates excellent schools at the top of the achievement distribution, while opponents of school
ability-grouping are concerned that it creates an underclass of schools with high concentrations
of low-achieving students that produce very low value-added. Much research on school quality
has focused on the effect of attending high-achieving or “elite” schools. Since the rule-based
instruments provide exogenous variation in school attendance for all schools, I can test whether
the benefits to attending a school with higher-achieving peers, on average, are driven by large
benefits to elite schools at the top of the school achievement distribution, large ill-effects to
attending low-achievement schools at the bottom of the school achievement distribution, or if the
35

effect is roughly linear.
To test for such non-linearly, I put schools into groups based on their rank in incoming
test scores (top third, middle third, and bottom third). I estimate the rule based 2SLS model for
subsamples of students assigned to different schools within these groups. These results are
presented in models 1 through 18 of Table 8. I also present the reduced form RD estimates of the
effect of scoring above the cut-off for the preferred school for schools in the different groups in
models 19 through 27 of Table 8. All models in table 8 include the quartic of the total SEA score.

Table 8

Effect of attending a school with better peers within schools of different ranks
Rule Based 2SLS variables results
1
2

3

Take CSEC
Middle
Bottom
Top third third
third
Mean of Total SEA -0.086
0.052
0.204
[0.089] [0.069]
[0.118]+
Observations
2299
4551
7951
Yes
Yes
Yes
Assisted included
10

11
12
Take CSEC
Middle
Bottom
Top third third
third
Mean of Total SEA
0.079
0.205
[0.078]
[0.117]+
Observations
354
4239
7915
Assisted included
No
No
No

4

5

Exams Passed
Middle
Top third
third
1.635
1.424
[0.715]* [0.437]**
2299
4551
Yes
Yes
13

14
Exams Passed
Middle
Top third
third
1.795
[0.466]**
354
4239
No
No

6
Bottom
third
-0.232
[0.427]
7951
Yes
15
Bottom
third
-0.233
[0.424]
7915
No

7

8

Certificate
Middle
Top third
third
0.386
0.249
[0.121]** [0.076]**
2299
4551
Yes
Yes
16

17
Certificate
Middle
Top third
third
0.278
[0.079]**
354
4239
No
No

9
Bottom
third
-0.06
[0.053]
7951
Yes
18
Bottom
third
-0.06
[0.052]
7915
No

Regression Discontinuity Estimates
19
20
21
22
23
24
25
26
27
Take CSEC
Exams Passed
Certificate
Middle
Bottom
Middle
Bottom
Middle
Bottom
Top third third
third
Top third
third
third
Top third
third
third
Above Cut-off
-0.004
0.005
0.059
0.206
0.215
0.06
0.022
0.041
0.009
[0.015] [0.017]
[0.039]
[0.187] [0.116]+
[0.104]
[0.033]
[0.021]*
[0.010]
Observations
13024
13744
5396
13024
13744
5396
13024
13744
5396
Assisted included
No
No
No
No
No
No
No
No
No
+ significant at 10%; * significant at 5%; ** significant at 1%.
Robust standard errors in brackets are adjusted for clustering at the school level in rule based models and clustering at the student
level in the RD models. Models 10, 13, and 16 are not reported because the sample sizes are too small to produce a first stag Fstatistic above 10.

Models 1 through 3 suggest that the marginal effect of attending a school with higherachieving peers is highest at low levels of peer achievement. The point estimate among the top
36

third of schools is a statically insignificant -0.086, while that for the middle third is a statistically
insignificant 0.052, and that for the bottom third is a marginally statistically significant 0.205.
Given that the CSEC taking rate is very low at low levels of incoming achievement, the fact that
the marginal effects on CSEC taking are larger at lower school rank ranges is not surprising. This
may reflect the fact that there are more marginal CSEC takers at schools with lower-achieving
peers than at schools with higher-achieving peers. In models 19 through 21, I use the reduced
form RD model to estimate the effect of scoring above the cut-off for one’s preferred school for
these same school groups. These results omit the Government Assisted schools. The point
estimates in models 19 and 20 are both small and statistically insignificant – indicating that just
gaining admission to a better school has no effect on CSEC taking for the top two thirds of
schools. In contrast, the point estimate for scoring above the cut-off among the bottom third of
schools in model 21, is 0.059 (with a p-value of 0.12). While the RD evidence is imprecise, the
results are consistent with the rule-based 2SLS results suggesting that students benefit more on
the CSEC taking margin from improvements in school quality lower down in the achievement
distribution.
Models 4 through 6, 13 thought 15, and 22 through 24 show the same specifications for
the number of exams passed. In both the 2SLS and the RD results, there are larger benefits on the
margin of attending a school with higher-achieving peers among school in the upper end on the
achievement distribution. The rule based 2SLS estimates in models 4 through 6 indicate that
attending a school with half a standard deviation higher peer achievement is associated with
passing 0.8 more exams within the top third of schools, passing 0.7 more within the middle third
of schools, and a small statistically insignificant negative effect within schools in the bottom
third. The RD results are consistent with this pattern. Scoring above the cut-off for a school in
the top two thirds is associated with passing about 0.2 additional exams. However, scoring above
the cut-off for a school in the bottom third is not associated with passing more exams.
Finally, models 7 through 9, 16 thought 18, and 25 through 27 show the same
specifications for obtaining a certificate. The results are very similar to those for the number of
exams passed. In both the 2SLS and the RD results, there are larger benefits, on the margin, of
attending a school with higher-achieving peers among schools in the upper end on the
achievement distribution. The rule based 2SLS estimates in models 7 through 9 indicate that
attending a school with half a standard deviation higher peer achievement is associated with a 19

37

percentage point increase in the likelihood of earning a certificate in the top third of schools, a 12
percentage point increase in the likelihood of earning a certificate in the middle third of schools,
and a small and statistically insignificant negative effect in the bottom third of schools. The RD
results in models 25 through 27 indicate that scoring above the cut-off is associated with a
statistically insignificant 2.2 point increase in the likelihood of earning a certificate in the top
third of schools, a statistically significant 4.1 point increase in the likelihood of earning a
certificate in the middle third of schools, and a statistically insignificant 0.9 point increase in the
bottom third of schools.
In sum, the results suggest that attending a better school may increase the likelihood of
taking the CSEC exams among low-achievement schools. The larger marginal effects on the
CSEC taking margin among these schools likely reflect the fact that students who attend such
school are more likely to be marginal CSEC takers than those students who attend high
achievement schools. For the number of exams passed and obtaining a certificate, the results
suggest that the marginal effects of attending a better school are largest within the top two thirds
of schools. This may reflect the fact that the top two thirds of schools are better at improving
student outcomes than schools in the bottom third, or it may reflect that fact that there are more
marginal certificate earners at these schools. Lastly, the results do not provide any strong
evidence that the marginal effects of attending better schools are larger among the top third of
schools than in the middle third. The result suggest that there are benefits to attending better
schools at all points in the school quality distribution, but that improvements in school quality at
low levels of achievement improve low level outcomes such as CSEC taking, while
improvements at higher school quality levels improve higher level outcomes such as passing
more exams and obtaining a certificate. Insofar as there is any non-linearity, it would appear that
for the main outcomes of interest, the marginal effects are low at low levels of school peer
achievement, and are higher at medium and high levels of school peer achievement.

V

Conclusions

Ability-grouping, by grouping students by ability, has a profound effect on the peers to
which students may be exposed. Since peer quality may be a determinant of other school inputs
such as funding levels, and teacher quality, ability-grouping may engender large differences in
the quality of schools to which students of differing initial levels of achievement are exposed. I

38

argue that if students benefit from attending schools with higher-achieving peers, abilitygrouping will tend to exacerbate pre-existing achievement differences, on the margin.
Unfortunately, the empirical evidence on whether students benefit, on average, from attending
"better" schools is mixed.
To better understand if students benefit from attending better schools, and to deepen our
understanding of ability-grouping, I use Trinidad and Tobago data, where there are no curricular
differences across schools, to identify an ability-grouping effect on the margin. Specifically, I
test whether students benefit from attending schools with higher-achieving peers. Since students
with higher initial achievement attend schools with higher-achieving peers under abilitygrouping, this is also a test for whether ability-grouping increases educational inequality, on the
margin, by assigning high-achieving students to schools that produce the most value-added while
consigning students with low initial achievement to schools that provide the least value-added. I
exploit the rules used by the Ministry of Education to assign students to secondary schools to
implement both a RD based and a rule-based instrumentation strategy to remove self-selection
bias that could affect my findings. Both methods yield similar results, and I present falsification
tests indicating that the identification strategies are likely valid. After taking self-selection bias
into account, I show that students benefit on several outcomes from attending schools with
higher-achieving peers ─ implying that those schools with the highest-achieving peers produce
more value-added than schools with lower-achieving peers. The findings present compelling
evidence that students do benefit from attending better schools, and suggest that, on the margin,
ability-grouping may lead to increased educational inequality on a broad range of academic
outcomes such as test scores, the number of examinations passed, and years of educational
attainment.
I also show that the marginal effect of attending a school with higher-achieving peers is
non-linear so that the benefits to attending schools with marginally brighter peers are low at the
lower end of the peer achievement distribution. However, I do not find evidence that attending
schools with marginally brighter peers is higher at high-achievement levels than in the middle of
the peer achievement distribution. Adding to a growing literature documenting stronger benefits
to interventions for females than for males, I find that females benefit more from attending
schools with high-achieving peers than do boys on all outcomes. In fact, the marginal effects are
about twice as large for females than those for males. One implication of this result is that

39

ability-grouping could increase the male-female achievement gap. Given the growing concern
that boys may be falling behind, particularly in the Caribbean, further research is needed to better
understand these gender differences.
Since I estimate the effect of ability-grouping on the margin, (that is, the effect of being
assigned to a school with marginally higher-achieving peers) these findings do not speak to the
efficiency implications, or the overall effect, of ability-grouping. However, the results show that
school ability-grouping could have sizable distributional effects on the margin. If low-income
students are more likely to have low incoming test scores, they will be systematically placed in
schools that provide less value-added than those attended by more affluent higher-achieving
students. Whether ability-grouping leads to increased educational inequality and reinforces
socioeconomic differences overall is still an unresolved question. However, this paper provides
credible evidence that the large differences in school quality to which high and low achieving
students are exposed engendered by ability-grouping will tend to reinforce and exacerbate preexisting differences in academic achievement.

References

Angrist, Joshua “Conditioning on the Probability of Selection to Control Selection Bias”, (1995)
, NBER Technical Working Paper No. 181. Cambridge, Massachusetts.
Angrist, Joshua D. and Kevin Lang, 2004. "Does School Integration Generate Peer Effects?
Evidence from Boston's Metco Program," American Economic Review, vol. 94(5), pages
1613-1634, December.
Angrist. Joshua and Victor Lavy, "Using Maimonides' Rule To Estimate The Effect Of Class
Size On Scholastic Achievement," (1999). The Quarterly Journal of Economics, MIT Press,
vol. 114(2), pp 533-575.
Ariga, Kenn., Giorgio Brunello, Roki Iwahashi, Lorenzo Rocco, "Why Is the Timing of School
Tracking So Heterogeneous?" (November 2005). IZA Discussion Paper No. 1854.
Atkinson, A., P. Gregg, and B. McConnell. “The Result of 11 Plus Selection: An Investigation
Into Opportunities and Outcomes for Pupils in Selective Schools,” (2006). Centre for Market
and Public Organization Working Paper 06/150, Bristol University, England.
Betts, Julian. “Does School Quality Matter? Evidence from the National Longitudinal Survey of
Youth” (1995) The Review of Economics and Statistics, Vol. 77, No. 2, pp. 231-250.
Betts, Julian R., and Jamie L. Shkolnik, “The effects of ability-grouping on student math
achievement and resource allocation in secondary schools.” (1999a), Economics of Education
Review, 19, 1–15.
__________ , “Key difficulties in identifying the effects of ability-grouping on student
achievement” (1999b). Economics of Education Review, Volume 19, Issue 1, Pages 21-26.
Brunello, Giorgio, and Deniele Chechi, “Does School Tracking Affect Equality of Opportunity?”
New International Evidence.” (2006), Institute for the Study of Labor Discussion Paper 2346.
40

Burke, Mary .A . and Tim R. Sass. "Classroom Peer Effects and Student Achievement," (2006)
Working Papers wp2006_02_02, Department of Economics, Florida State University.
Campbell, Donald T. “Reforms and experiments.” (1969), American Psychologist 24:409-29.
Card, David E.., and Alan B. Krueger, Alan. “School Quality and Black-White Relative Earnings:
A Direct Assessment.” (February 1992a), Quarterly Journal of Economics.
____________ “Does School Quality Matter? Returns to Education and the Characteristics of
Public Schools in the United States” The Journal of Political Economy, Vol. 100, No. 1 (Feb.,
1992b), pp.1-40.
Clark, Damon. “Elite Schools and Academic Performance” (2007) Institute for the Study of
Labor (IZA) Discussion Paper 3182.
Cullen, Julie., Brian Jacob, and Levitt Steven. “The Impact of School choice on Student
Outcomes: An Analysis of the Chicago Public Schools.” (2005), Journal of Public Economics.
89(5-6), 729-760.
_____________. “The Effect of School choice on Student Outcomes: Evidence from Randomized
Lotteries.” (2006), Econometrica, 74(5), 1191-1230.
Das, Jishnu, Tahir Andrabi, and Asim I. Khwaja (2006) “Students Today, Teachers Tomorrow:
Identifying Constraints for the Provision of Education.” Processed.
Duflo, Esther, Pascaline Dupas, and Michael Kremer “Peer Effects and the Impact of Tracking:
Evidence from a Randomized Evaluation in Kenya” Working Paper
Dustmann, Christian. “Parental Background, Secondary School track Choice and Wages.” (2004),
Oxford Economic Papers. 56. 209-230.
Figlio, David N. and Marianne E. Page. "School Choice and the Distributional Effects of
Achievement Tracking: Does Separation Increase Inequality?," (May 2002) Journal of Urban
Economics, Elsevier, vol. 51(3), pages 497-514.
Fisher, Gary. 1976. "The Identification Problem in Econometrics." Robert E. Kreiger Publishing
Company, Huntington, New York.
Galindo-Rueda, Fernando, and Anna Vignoles, "The Heterogeneous Effect of Selection in
Secondary Schools: Understanding the Changing Role of Achievement," (2004) Institute for
the Study of Labor Discussion Paper 1245
Gould Eric D., Victor Lavy, and Daniele M. Passerman. “Immigrating to Opportunity: Estimating
The Effect of School Quality Using A Natural Experiment on Ethiopians in Israel” (May
2004), Quarterly Journal of Economics.
Grogger, Jeff: “School Expenditures and Post-Schooling Earnings: Evidence from High School
and Beyond” (Nov., 1996), The Review of Economics and Statistics, Vol. 78, No. 4, pp. 628637.
Hastings, Justine S., Thomas Kane and Douglas Staiger (2006b), “Gender, Performance and
Preferences: Do Girls and Boys Respond Differently to School Environment? Evidence from
School Assignment by Randomized Lottery,” American Economic Review Papers and
Proceedings, 96 (2): 232-236.
Hastings, Justine S., Thomas J. Kane and Douglas O. Staiger "Gender and Performance: Evidence
from School Assignment by Randomized Lottery", American Economic Review 96(2), pp.
232-236.
Hastings, Justine S. and Jeffrey M. Weinstein. (2007) “No Child Left Behind: Estimating the
Impact on Choices and Student Outcomes", NBER Working paper 13009.
Hanushek Eric A, and Ludger Woessman,. “Does Educational Tracking Affect Performance and
Inequality? Differences in Differences Evidence across Countries.” (2006), Economic Journal,

41

116(510), C63-C76.
Heckman, James, Anne Layne-Farrar, and Petra Todd. “Does Measured School Quality Really
Matter? An Examination of the Earnings-Quality Relationship.” (1996), In Does Money
Matter? The Effect of School Resources on Student Achievement and Adult Success. G.
Burtless, editor. Washington D.C. Brookings Institution.
Horowitz, Joel L. and Charles F. Manski,., 1998. "Censoring of outcomes and regressors due to
survey nonresponse: Identification and estimation using weights and imputations," Journal of
Econometrics, Elsevier, vol. 84(1), pages 37-58, May.
Hoxby, Caroline. “The Effects of Class Size and Composition on Student Achievement: New
Evidence from Natural Variation.” (1998), NBER WP 6869.
Hoxby, Caroline. “Peer Effects in the Classroom: Learning from Gender and Race Variation.”
(2000), National Bureau of Economic Research Working Paper 7867.
Hoxby, Caroline M., and Weingarth, Gretchen, (2006). Taking Race Out of the Equation: School
Reassignment and the Structure of Peer Effects. Working Paper.
Jackson. C. Kirabo (forthcoming). "Student Demographics, Teacher Sorting and Teacher Quality:
Evidence from the End of School Desegregation" The Journal of Labor Economics.
Jackson, C. Kirabo. (2009) “A Stitch in Time: Evaluating the Effects of an AP Incentive
Program on College Outcomes”, Cornell University, mimeo.
Katz, Lawrence and Jeffrey Kling and Jeffrey Liebman. (2007). "Experimental Analysis of
Neighborhood Effects," Econometrica, Econometric Society, vol. 75(1), pages 83-119, 01.
Lavy, Victor (2009) “Performance Pay and Teachers' Effort, Productivity and Grading Ethics”
The American Economic Review, forthcoming.
Malamud, Ofer and Cristian Pop-Eleches: "General Education versus Vocational Training:
Evidence from an Economy in Transition," (forthcoming) Review of Economics and Statistics.
Manning, Alan, and Jörn-Steffen Pischke. “Comprehensive versus Selective Schooling in
England and Wales: What Do We Know,” (2006) NBER Working Paper 12176.
Maurin, Eric, and Sandra McNally. “Educational Effects of Widening Access to the Academic
Track: A Natural Experiment” (2007). CEE Discussion Papers with number 0085.
McCrary, Justin. (2005) Manipulating the running variable in the regression discontinuity design.
University of Michigan, mimeo.
OECD, 2004, the PISA , Paris.
Pop-Eleches, Christian and Miguel Urquiola (2008) “The Consequences of Going to a Better
School,” Department of Economics. Columbia University. Mimeo.
Rangvid, Beatrice S. “Educational Peer Effects: Regression Evidence from Denmark with
PISA2000 data.” (2003), Copenhagen: AKF Institute for Local Government Studies.
Sacerdote, Bruce. “Peer Effects with Random Assignment: Results for Dartmouth Roommates.”
(2001), Quarterly Journal of Economics, 116 (2): 681 - 704.
Summers, Anita A. and Barbara L. Wolfe,. “Do Schools Make a Difference?” (1977), American
Economic Review, 67, 639-652.
Tyler, John H., Richard J. Murnane and John B. Willett. "Do The Cognitive Skills Of School
Dropouts Matter In The Labor Market?," Journal of Human Resources, 2000, v35(4,Fall),
Zimmerman, David. “Peer Effects in Academic Outcomes: Evidence from a Natural
Experiment.” (2003), Review of Economics and Statistics, Volume 85, Issue 1 (November).

42

Appendix:
Table A1
Regression Discontinuity based 2SLS results by gender

Mean Peer Scores

Polynomial order

Mean Peer Scores

1
Take
-0.072
[0.098]

2
Take
-0.027
[0.218]

Male
3
Passes
0.37
[0.500]

4
Passes
-0.128
[1.117]

5
Cert.
0.133
[0.086]

6
Cert.
0.211
[0.195]

2

4

2

4

2

4

7
Take
-0.01
[0.054]

8
Take
0.111
[0.095]

Female
9
Passes
0.955
[0.340]**

10
Passes
1.591
[0.609]**

11
Cert.
0.172
[0.059]**

12
Cert.
0.213
[0.104]*

2

4

Polynomial order
2
4
2
+ significant at 10%; * significant at 5%; ** significant at 1%

4

Obs.
6961

Obs.
9321

Table A2
Robustness of RD to bandwidth smooth functions of the total score
The independent variable is mean peer scores. All models are 2SLS-RD models and exclude assisted schools.
Dependent variable
Take CSEC

Exams Passed

Certificate

Control for total score

Bandwidth

Coef.

SE

Coef.

SE

Coef.

SE

quadratic

full sample

0.082

[0.027]**

0.996

[0.152]**

0.211

[0.026]**

quadratic

200

0.078

[0.027]**

1.019

[0.151]**

0.212

[0.026]**

quadratic

100

0.037

[0.030]

1.039

[0.173]**

0.209

[0.030]**

quadratic

50

-0.039

[0.049]

0.662

[0.282]*

0.156

[0.048]**

quadratic

30

-0.037

[0.080]

0.413

[0.463]

0.162

[0.080]*

quadratic

20

-0.024

[0.147]

0.685

[0.875]

0.178

[0.151]

quartic

full sample

0.076

[0.036]*

0.788

[0.206]**

0.156

[0.036]**

quartic

200

0.06

[0.035]+

0.823

[0.204]**

0.167

[0.036]**

quartic

100

-0.056

[0.046]

0.76

[0.267]**

0.16

[0.046]**

quartic

50

0.04

[0.089]

0.83

[0.524]

0.19

[0.090]*

quartic

30

-0.022

[0.213]

0.706

[1.260]

0.273

[0.221]

quartic

20

-0.746

[0.660]

4.651

[4.110]

0.807

[0.693]

+ significant at 10%; * significant at 5%; ** significant at 1%

43

Kernel density of total scores by school rank
0
.2
.4
.6
.8
1

Distributions of total SEA scores by school rank

-2

-1
0
Normalized total SEA score
Rank 1 to 40
Rank 80+

1

2

Rank 41 to 80

Figure A1
Distribution of total SEA scores by school rank

0

5

Frequency
10
15

20

25

Distribution of mean SEA scores among assigned students
155 school assignments

-2

-1
0
1
Mean total SEA scores among assigned students

Figure A2
Distribution of mean SEA scores across actual school assigents

44

2

Graphical Representation of RD Results
The cut-off is denoted by the vertical line
Taking the CSEC
4

Math Grade
3
2

0

10
20
30
40
50
50 quantiles of total score

1
0

-1

.4

.5

-.5

.6

0

.7

.5

.8

1

.9

Mean Peer Scores

0

10
20
30
40
50
50 quantiles of total score

Earning a Certificate
.1 .2 .3 .4 .5

3

3

2

2

0

0

0

1

1

0

Exams Passed
4

4

English Grade

10
20
30
40
50
50 quantiles of total score

0

10
20
30
40
50
50 quantiles of total score

0

10
20
30
40
50
50 quantiles of total score

0

10
20
30
40
50
50 quantiles of total score

Dotes represent sample means for each test score quantile group. A linear fit os shown for both sides of the simulated cut-off.

Figure A3
Graphical Evidence of the Dicontintuity at the Simulated cut-off

45

