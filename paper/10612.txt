NBER WORKING PAPER SERIES

TARGETING VS. INSTRUMENT
RULES FOR MONETARY POLICY
Bennett T. McCallum
Edward Nelson
Working Paper 10612
http://www.nber.org/papers/w10612
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2004

We thank Lars Svensson, Mark Gertler, Ricardo Rovelli, and Javier Valles for comments on an earlier draft.
The views expressed are those of the individual authors and do not necessarily reflect official positions of the
Federal Reserve Bank of St. Louis, the Federal Reserve System, the Board of Governors, or CEPR. The views
expressed herein are those of the author(s) and not necessarily those of the National Bureau of Economic
Research.
©2004 by Bennett T. McCallum and Edward Nelson. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is
given to the source.

Targeting vs. Instrument Rules for Monetary Policy
Bennett T. McCallum and Edward Nelson
NBER Working Paper No. 10612
June 2004
JEL No. E52, E58
ABSTRACT
Svensson (JEL, 2003) argues strongly that specific targeting rules – first order optimality conditions
for a specific objective function and model – are normatively superior to instrument rules for the
conduct of monetary policy. That argument is based largely upon four main objections to the latter
plus a claim concerning the relative interest-instrument variability entailed by the two approaches.
The present paper considers the four objections in turn, and advances arguments that contradict all
of them. Then in the paper’s analytical sections, it is demonstrated that the variability claim is
incorrect, for a neo-canonical model and also for a variant with one-period-ahead plans used by
Svensson, providing that the same decision-making errors are relevant under the two alternative
approaches. Arguments relating to general targeting rules and actual central bank practice are also
included.
Bennett T. McCallum
Tepper School, Posner 256
Carnegie Mellon University
Pittsburgh, PA 15213
and NBER
bmccallum@cmu.edu
Edward Nelson
Research Division
Federal Reserve Bank of St. Louis
St. Louis, MO 63102
edward.nelson@stls.frb.org

1. Introduction
In the recent literature on monetary policy analysis, several writers have emphasized
the distinction between instrument rules—i.e., formulae for setting controllable instrument
variables in response to current conditions—and targeting rules, as proposed by Svensson
(1997, 1999).1 In a major contribution, Svensson (2003) has presented a sophisticated and
comprehensive case for the use of targeting rules, arguing that “monetary-policy practice is
better discussed in terms of targeting rules than instrument rules” (2003, p. 429).2 The
superiority of targeting rules is, moreover, claimed to pertain to both normative and positive
perspectives (pp. 428–430). Svensson’s paper is rich in both analytical and practical content,
and provides insights that can be usefully pondered by all students of monetary policy
analysis. It is our belief, nevertheless, that the paper seriously overstates the relative
attractiveness of targeting rules, from both normative and positive perspectives, and
describes inaccurately the properties of instrument rules. To develop this argument is the
purpose of the present paper. As a major part of our argument, one concrete and important
claim of Svensson’s, regarding interest rate variability induced by instrument rules with
strong feedback, is studied in detail. In the wide variety of cases considered, we find all
results to be inconsistent with the claim.
The outline of the present paper is as follows. Section 2 presents explanations of the
basic concepts and an introduction to the issues. Section 3 then takes up, and disputes, four
particular criticisms of instrument rules that are central to the argument in Svensson (2003),
after which Section 4 does the same for two additional criticisms. In Sections 5 and 6, the
1

See, for example, Svensson (1997, 1999, 2003), Svensson and Woodford (2002), Rudebusch and Svensson
(1999), Clarida, Galí, and Gertler (1999), Cecchetti (2000), Giannoni and Woodford (2003a, 2003b), Jensen
(2002), Walsh (2003), and Woodford (2003).

1

paper turns to the precise analytical claim mentioned above and develops results in a number
of settings that show it to be incorrect. Finally, Section 7 provides a very brief recapitulation.
2. Basic Ideas
What is the distinction between instrument and targeting rules? A rule of the former
type refers, quite simply, to some formula prescribing instrument settings as a function of
currently observed variables. Well known examples include the Taylor rule (1993), several
interest rate rules studied by Henderson and McKibbin (1993a, 1993b), and the activist
monetary base rules of McCallum (1988) and Meltzer (1987). Precisely which variables are
observable is of course a matter that can be debated in practical analyses, but is one on which
the analyst has to take some explicit position. Note that expectations (based on current
information) of present or future variables may be among the variables that the rule responds
to.3 The definition of targeting rules is somewhat more complex. There has been some
evolution since Svensson’s (1997, 1999) introduction of the concept,4 but his current
terminology recognizes both general and specific variants. Basically, a general targeting rule
is the specification of a central bank objective function,5 whereas a specific targeting rule is
an optimality condition implied by an objective function together with a specified model of
the economy (pp. 448−460).6 Initially, optimization was presumed to be of the discretionary

2

In what follows, quotations with page-number indications but no author or year indication, refer to that paper,
i.e., Svensson (2003).
3
In cases in which expectations are based on current-period information, however, Svensson refers to this type
of policy rule as an “implicit instrument rule.”
4
In particular, only specific (not general) targeting rules were considered in Svensson (1997) and they were
called “target rules.”
5
Svensson (2003, p. 430) further requires that these be “operational objectives” (italics in original), i.e.
numerical targets for particular variables, rather than a general concept such as “price stability.”
6
Svensson has explained to us that he does not require that a specific targeting rule necessarily expresses an
optimality condition, as he has in the past (1997, p. 1136), and his definition on p. 429 conforms to that
explanation. On p. 430, however, he states that “… specific targeting rules essentially specify operational
Euler equations.” Also, on p. 455 Svensson states that “A specific targeting rule specifies a condition … [that]
may be an optimal first-order condition, or an approximate first-order condition.” In the remainder of this
2

type, with period-by-period re-optimization based on prevailing “initial conditions,” but in
Svensson (2003) the possibility of optimization from a “timeless perspective” (see
Woodford, 1999) is also considered.
It is not our intention to argue that analysis with instrument rules is in all respects
preferable to the use of targeting rules. Even if we held that belief, moreover, we would not
think it socially desirable for all researchers to employ the same approach. Nevertheless, we
are more attracted to analysis with instrument rules than with targeting rules and believe that
a few words should be included to indicate why—especially since Svensson’s numerous
writings argue so strongly in favor of the targeting-rule position.
First, it seems terminologically inappropriate to refer to the specification of the
policymaker’s objective function as a rule. Obviously, for a given objective function
desirable instrument settings—i.e., policy actions—can be very different under the same
prevailing conditions depending on the policymaker’s preferred model or models of the
economy. There are words available to describe policymakers’ objectives—for example,
“policymakers’ objectives”—so there is nothing analytical to be gained by reference to them
as “general targeting rules.” It is terminologically useful, rather, for objectives and rules to
be clearly distinguished. Next, from the substantive perspective, the adoption of an objective
function is innocuous if the function accurately represents the central bank’s true preferences.
But if it does not represent the true preferences and is made public, as in the scheme
suggested in Svensson’s Section 5.3.3, then the central bank will be describing its objectives
dishonestly to the public, which seems inconsistent with Svensson’s emphasis on

paper, accordingly, we shall follow Svensson’s practice by typically treating specific targeting rules as firstorder optimality conditions.
3

transparency.7
Second, the problem with specific targeting rules—i.e., first-order optimality
conditions—is that they are obviously model-dependent.8 It is unclear which portion of
today’s macroeconomic models are most questionable, but it is entirely clear that there is
much dispute among leading scholars concerning the proper specification of several of the
crucial relationships. Yet a condition that implies policy optimality in one model may be
highly inappropriate under other specifications. Consequently, an attractive approach to
policy design, promoted (e.g.) by McCallum (1988, 1999), is to search for an instrument rule
that performs at least moderately well—avoiding disasters—in a variety of plausible models.
In other words, it is our belief that it is unwise to restrict policy analysis to optimal-policy
exercises, which will typically be optimal only for the single model being utilized. Yet such
analysis is precisely what is contemplated by focus on specific targeting rules.
A good illustration of the model-dependence of optimality conditions is provided in a
recent paper by Levin and Williams (2003), which is a follow-up to the robustness study of
Levin, Wieland, and Williams (1999). The initial experiments of Levin and Williams (2003)
involve calculation of the consequences of using a policy rule, designed to be optimal in one
model, in other models. The three models in their introductory example are (i) a “New
Keynesian” baseline model (NKB) that is highly prominent in recent theoretical research, (ii)
an alternative specification (denoted FHP) with more sources of inertia utilized by Fuhrer
(2000), and the empirically-oriented (RS) model of Rudebusch and Svensson (1999).
Suppose a specific targeting rule is optimal in a calibrated version of the NKB model, with a

7

Svensson has informed us that he would have the central bank explain the discrepancy between its objective
function and preferences to the public. We consider that such a need reflects a substantial degree of nontransparency.
8
The existence of model dependency is recognized by Svensson (p. 450).
4

loss function that assigns output gap variability a weight of λ (as in Section 5 below) and also
gives interest rate variability a weight of 0.1, both in relation to inflation variability relative
to target. If that optimality condition is used instead in the FHP model, the loss values are 95
or 150 percent higher (for λ values of 0.0 and 0.5, respectively) than the minimum loss in
that model. Even more strikingly, if this NKB optimality condition is transferred to the RS
model, the combination generates explosive oscillations—an “infinite” percentage
deterioration. Next, a specific targeting rule that is optimal in the FHP model produces
losses that are 173 or 130 percent greater than minimum in the NKB model, and explosive
oscillations in the RS model. Finally, a rule that is optimal in the RS model generates
analogous loss increases of 219 or 254 percent in the NKB model and 146 or 128 percent in
the FHP model.
As an extension of our position, we would suggest that it is not desirable always to
limit analysis to cases in which an explicit objective function has been specified.
Explicitness is itself a virtue, of course, other things equal. But it is unclear what weights
actual central bankers assign to various terms in their objective functions as well as to the
specification of the terms. It is also unclear what weights and terms should appear, since
there is professional disagreement over proper model specification.9 Accordingly, it can be
useful to explore the way in which different properties of a modelled economy (e.g.,
variances of key endogenous variables) are related to policy rule parameters, leaving it to
actual policymakers to assign the relevant weights. Examples of this approach appear in
some of our previous papers, e.g., McCallum and Nelson (1999a, 1999b), as well as in
Bryant, Hooper, and Mann (1993).
9

Our position does not deny the attractiveness in principle of basing policymaker objective functions on the
preferences of individual agents.
5

3. Four Main Objections
After some preliminary discussion, Svensson considers the case of central bank
(henceforth, CB) commitment to an optimal instrument rule (which he terms an implicit
reaction function when the rule includes any current endogenous variables) and concludes
that the implied approach is “completely impractical.” Indeed, Svensson states that
“commitment to an optimal instrument rule has no advocates, as far as I know” (p. 439).
With this particular judgment we have no serious disagreement; see McCallum (1999, pp.
1490–1495), for example. Consequently, Svensson moves on to consideration of simple
instrument rules (pp. 439–441), with one subsection entitled “Problems of a commitment to a
simple instrument rule” (pp. 441–444). We now examine that subsection’s arguments in
some detail, since they evidently constitute the most important ingredients of Svensson’s
position.
In the subsection in question, there are four main objections to instrument rules that
are identified and discussed. The first is “(1) the simple instrument rule may be far from
optimal in some circumstances” (p. 441). In particular, “[a] first obvious problem for a
Taylor-style rule … is that, if there are other important state variables than inflation and the
output gap, it will not be optimal… For a smaller and more open economy [than the U.S.],
the real exchange rate, the terms of trade, foreign output, and the foreign interest rate seem to
be the minimal essential state variables that have to be added” [for the rule to be optimal] (p.
442). But Taylor rules do not comprise the entire class of simple instrument rules; nominal
income growth rules provide just one obvious counter-example. Thus the foregoing is not
actually an argument against simple instrument rules, but merely an objection to one
particular class. Furthermore, it is not clear that the supposed departure from optimality

6

resulting from the absence of the other state variables, pertaining to open economies, is
quantitatively or even qualitatively important. Indeed, in Clarida, Galí, and Gertler’s (2001)
small open economy model there are no additional terms in the welfare function besides the
two Taylor-rule state variables—inflation and the output gap—provided that the former is
defined in terms of domestic-goods price inflation. Similarly, the McCallum-Nelson (1999a,
2000b) open-economy model can be formulated entirely in terms of CPI inflation, output,
and the real interest rate, with openness only changing the interpretation of the model
parameters.
“A second problem,” Svensson states, “is that a commitment to an instrument rule
does not leave any room for judgmental adjustments and extra-model information…” (p.
442). This claim is difficult for us to understand, since there seem to be various ways in
which judgmental adjustments to instrument rule prescriptions could be made. For example,
the interest rate instrument could be set above (or below) the rule-indicated value when
policymaker judgments indicate that conditions, not adequately reflected in the CB’s formal
quantitative models, imply different forecasts and consequently call for additional policy
tightening (or loosening). This way of incorporating judgment is not the same as the one
proposed by Svensson, which he represents by the inclusion in the structural equations of the
CB’s macroeconomic model of an unobservable exogenous stochastic variable that is not
generated by a simple process such as “an exogenous autoregressive process” (p. 433).
These exogenous deviations appear in the model’s structural equations. “Judgment” is then
the CB’s estimate of these deviation variables. But it is unclear that this approach reflects the
only, or even the best, way of representing the role of judgment in policymaking.10 Thus the

10

Svensson also states that “a commitment to a simple instrument rule does not provide any rules for when
discretionary departures from the simple instrument rule are warranted” (p. 442). But a procedure that did do
7

fact that the above-mentioned way of incorporating judgment is different from Svensson’s
seems to be beside the point, i.e., does not justify his quoted statement.11
Svensson suggests that “a third problem with simple instrument rules would seem to
be that a once-and-for-all commitment to an instrument rule would not allow any
improvement of the … rule when new information about the transmission mechanism, the
variability of shocks, or the source of shocks arrives” (p. 442). But the words “would seem”
appear in the foregoing quotation because Svensson does not actually make the foregoing
argument. After mentioning it, he goes on to recognize that Woodford’s (1999) “timeless
perspective” type of commitment does permit modification of rules when new information is
developed.12 Such rules can, as is indicated below, be implemented by means of an
instrument rule. Furthermore, the implied type of commitment—to a procedure rather than a
formula—could be applied to instrument rules obtained by other procedures.
Finally, switching from a normative to a positive point of view, Svensson states that
“an obvious fourth problem is that commitment to a simple instrument rule is far
from an accurate description of current monetary policy” as practiced by inflation-targeting
or other CBs. He continues: “No central bank has (to my knowledge) announced and
committed itself to an explicit instrument rule” (p. 444). But, as McCallum and Nelson
(2000a, p. 15) have argued previously, no actual central bank has announced or committed
itself to an explicit objective function, which is a necessary condition for either the general or

this would hardly seem to reflect what most analysts would think of as “judgment”. It would be, rather, a
complex rule.
11
We do not mean to deny that Svensson has insightful and constructive observations to make regarding
incorporation of judgment; our objection is to the asymmetry that he paints with respect to such incorporation
via targeting and instrument rules.
12
For discussions, see Woodford (1999) and Svensson and Woodford (2003).
8

specific type of targeting rule promoted by Svensson.13 Indeed, commitment to an optimal
specific targeting rule would in addition entail commitment to be bound by the output of a
new optimal control exercise, conducted with a particular quantitative macroeconomic
model, each decision period (e.g., each month). Such exercises could, Svensson says, be
modified by judgment. But are they actually conducted by the CBs that he identifies as the
world’s leaders in this regard, those of the United Kingdom, New Zealand, and Sweden? If
so, what is the value of the weight λ on output-gap variability announced and utilized by
each of these CBs? What is the specification of the model utilized?
In short, it seems appropriate to conclude that all four of the objections to instrument
rules emphasized by Svensson are equally applicable—or equally inapplicable—to targeting
rules.
4. Additional Objections
Two other debatable points deserve some brief attention, before we turn to a major
analytical issue in Sections 5 and 6. One of these concerns Svensson’s argument against the
view that “simple instrument rules fit actual central-bank behavior well” (p. 444). In
opposition to this idea, Svensson states that “even the best empirical fits leave one third or
more of the variance of changes in the [interest instrument] rate unexplained.” In this regard
it is important to note that the statement pertains to the variability of first differences of the
interest rate, as found in the study by Judd and Rudebusch (1998). In terms of levels, the
fraction of the variance that is unexplained is approximately 0.02 (i.e., about 2 percent).14
Neither of these measures is “correct,” of course, but to put matters in perspective, we note
13

Note that at a minimum it would be necessary for the CB to state explicitly its value for the objective function
parameter labeled λ below and in Svensson’s eq. (2.2).

9

that 33 percent would be a comparatively small unexplained variance fraction for the first
difference of most important variables in typical quarterly macroeconometric models. In the
well-known Rudebusch and Svensson (1999) model, for example, the unexplained variance
fractions for changes in inflation and the output gap are about 71 percent and 87 percent,
respectively.15
Our second point concerns Svensson’s contention that actual central banks noted for
their inflation-targeting regimes, including the Reserve Bank of New Zealand, the Bank of
Canada, and the Bank of England, use in practice procedures that are more reasonably
characterized by the notion of a targeting rule rather than an instrument rule. We have
already mentioned than none of these central banks has publicly adopted an explicit objective
function. But furthermore, we find that descriptions of their policy procedures provided by
officials and economists of these central banks read more like instrument rules than specific
targeting rules.
As a first example, there are several short articles describing the policy procedures of
the Bank of Canada that appear in the Summer 2002 issue of the Bank of Canada Review.
These do not refer to targeting rules or optimal control exercises, but discuss instrument rules
quite explicitly—see, e.g., Cote, Lam, Liu, and St-Amant (2002). Another relevant reference
to the use of instrument rules in Canadian policy is provided by Longworth and O’Reilly
(2002). At the risk of being excessively repetitive, let it be said explicitly that we do not
claim that the Bank of Canada—or any actual central bank—strictly follows an instrument
14

Judd and Rudebusch (1998, p. 14) report a residual standard deviation of 0.27 for the Greenspan period 1987
Q3−1997 Q4. Over that span, the standard deviation of the quarterly average funds rate is 1.93 (annual
percentage units). Thus the unexplained fraction of variability is (0.27/1.93)2 = 0.0196.
15
These figures pertain to the model’s “inflation equation” and “output equation,” for which the reported
residual standard errors are 1.009 and 0.819 (Rudebusch and Svensson 1999, p. 208). The sample standard
deviations for first differences of the relevant inflation and output gap series over the 1961.1-1996.2 sample
period are 1.197 and 0.877 so we have (1.009/1.197)2 = 0.711 and (0.819/0.877)2 = 0.872.
10

rule, but rather that their practices are closer to the analytical representation of an instrument
rule than to the analytical representation of a targeting rule.
For the Bank of England, a natural starting place is a publication by Bean and
Jenkinson (2001) entitled “The Formulation of Monetary Policy at the Bank of England,”
which describes the role of forecasts in policy decisions (made individually by members of
the Monetary Policy Committee). This paper’s discussion explains that a variety of models
and techniques are used in the process, but recognizes the special status of the “MM”
quarterly macroeconometric model. In the publication Economic Models at the Bank of
England: September 2000 Update, there are several examples of policy experiments with
MM involving alternative instrument rules (Bank of England 2000, pp. 13−20). The more
recent discussion by Allsopp (2002, Section 3) suggests that “the broad features of the
reaction function in place in the UK increasingly seem to be publicly-understood and built
into expectations.”
A still more recent discussion of the UK policy framework is that in a document
prepared by the UK Treasury (2003). That study uses a comparison of “interest rate
decisions [with] those that a Taylor rule would suggest” as one measure of whether “the
current frameworks have allowed monetary policy to perform a stabilizing role” (2003, pp.
33, 35). By contrast, there is no attempt to evaluate policy using a numerically-specified loss
function or Euler equation. The study does note criticisms of the instrument-rule approach,
citing Svensson (2003) in that regard. But it characterizes the deviation of actual policy from
the Taylor rule as reflecting discretionary adjustments: “[prescriptions from] Taylor rules…
are typically different from the actual rates chosen by central banks, which use discretion to
determine rates based on a wider range of information” (2003, p. 36). In addition, in a

11

speech accompanying the release of this study, the Chancellor of the Exchequer (who sets the
target for monetary policy in the UK and appoints several of the members of the Monetary
Policy Committee) was explicit in characterizing actual policy in a Taylor-rule manner:
“For a 1 per cent rise in British inflation, the British interest rate would, other things being
equal, tend to rise by 1.5 per cent” (Brown, 2003).
In the case of New Zealand, descriptions of the Reserve Bank’s policy procedures
(e.g., Hampton, 2002) make no mention of optimal control exercises, but clearly refer to a
role for an instrument rule in use of the Forecasting and Policy System. In addition, it is
interesting to note that Svensson’s own extensive and authoritative independent review of
New Zealand monetary policy (2001, p. 66) suggests that “The Reserve Bank may want to
consider some further developments of its Forecasting and Policy System (FPS). Alternative
interest rate reaction functions and alternative interest rate paths could be used and presented
systematically to the MPC to provide a larger menu of policy choices for discussions and
consideration.”
5. Volatility from Instrument Rules?
We now turn to our main analytical discussion. Svensson’s subsection 5.5 expresses
sharp and specific disagreement with a crucial argument made by McCallum (1999, p. 1493)
and McCallum and Nelson (2000a) concerning the relationship between targeting and
instrument rules. In particular, these two papers argue that an instrument rule can be written
so as to entail instrument responses that would tend to bring about the satisfaction of any
specific target rule (which usually amounts to a first-order condition for CB optimality). By
increasing the response coefficient attached to the discrepancy between the relevant
prevailing conditions and the desired first-order condition, the average discrepancy can be

12

made arbitrarily small.16 Thus, in a sense one can accomplish with an instrument rule
anything that can be accomplished with a specific targeting rule, according to our argument.
Svensson (p. 461) has objected to this argument, however, on the grounds that “this is a
dangerous and completely impracticable idea. It is completely inconceivable in practical
monetary policy to have reaction functions with very large response coefficients, since the
slightest mistake in calculating the argument of the reaction function would have grave
consequences and result in extreme instrument-rate volatility.” A similar objection is
expressed, in milder language, by Svensson and Woodford (2003).
Our intuition was that imbedding a first-order condition in an instrument rule with a
large but finite reaction coefficient (such as µ1 below) would typically entail less severe
instrument movements than would imposition of the relevant specific targeting rule, since the
latter is equivalent to use of an “infinite” reaction coefficient.17 In other cases, large µ1 values
might entail somewhat greater interest volatility but in such cases the magnitude of this
volatility would approach that obtained with the targeting rule as µ1 grows without bound. In
our paper (2000a) we did not, however, explore the effects of mistakes in calculating the
argument of the reaction function. In the following paragraphs we shall, accordingly,
investigate the validity of Svensson’s conjecture.
For this exercise, suppose initially that the economy is represented by the following
model, which is a version of the neo-canonical specification used by Bullard and Mitra

16

The sign of the response coefficient must, of course, be appropriate—so that policy is tightened when
aggregate demand needs to be reduced, etc.
17
It is important to note that—in contrast to Svensson’s suggestion on p. 461—we actually do not recommend
the adoption of a large reaction coefficient; see McCallum and Nelson (2000a, pp. 20–24). Our point, instead,
is that an instrument rule with a large reaction coefficient is less open to Svensson’s objection than is its
associated specific targeting rule.
13

(2002), Clarida, Galí, and Gertler (1999), Jensen (2002), Woodford (1999, 2003), McCallum
and Nelson (1999b, 2000a), and many others:
(1)

yt = Etyt+1 + b1(Rt − Etπt+1) + ξt,

b1 < 0

(2)

πt = αyt + βEtπt+1 + ut.

α > 0, 0 < β < 1

Here, yt is the output gap, πt is the inflation rate, and Rt is the one-period nominal interest
rate. Equation (1) is the now-familiar expectational IS function and (2) is the Calvo price
adjustment relation—both consistent under well-known assumptions with optimizing
behavior by individuals in the economy (e.g., Woodford, 2003).
Supposing that the CB wishes to minimize the loss function
Et Σj=0∞ βj (πt+j2 + λyt+j2),
the optimum first-order condition in the absence of commitment is πt = −(λ/α)yt, or,
(3)

πt + (λ/α)yt = 0.18

This is the specific targeting rule that is implied for this model, assuming the absence of
commitment, by Svensson’s approach. The corresponding instrument rule proposed in
McCallum and Nelson (2000a) is
(4)

Rt = (1−µ2){ r + πt + µ1[πt + (λ/α)yt]} + µ2Rt−1,

where r is the average long-run real rate of interest. The term r , which is included along
with πt so as to express (4) in a Taylor-style form, is normalized to zero by expressions (1)
and (2). For present purposes the interest-rate smoothing coefficient µ2 may also be set equal
to zero, yielding Rt = πt + µ1[πt + (λ/α)yt].

18

See the papers cited in the previous paragraph. Note that while we use Svensson’s symbol λ for the weight
on the output gap in the objective function, our other choices for symbols do not follow Svensson’s notation, as
the latter is somewhat non-standard.
14

To incorporate mistakes of the type contemplated by Svensson, we modify (3) and (4)
to become
(3’)

πt + (λ /α)yt + et = 0

and
(4’)

Rt = (1−µ2){ r + πt + µ1[πt + (λ/α)yt + et]} + µ2Rt−1,

where et represents a stochastic mistake term. We have included the same mistake term et
into both the targeting and instrument rule, a step that seems necessary to provide a
reasonable basis for comparison. Since the issue is whether use of an instrument rule (with a
large µ1 parameter) leads to excessive variability (when there are policy errors) in

comparison to the corresponding targeting rule, it would make no sense to omit the errors
from the targeting rule.
In our experiments, we shall treat et as a first-order autoregressive (AR(1)) process—
usually as white noise—with AR parameter ρe and innovation εt (standard deviation σε).
Various values for σε and ρe are considered. Behavioral parameter values for the model are
taken to be b1 = −0.5, α = 0.03, and β = 0.99. Also, the stochastic shock term ξt in (1)
includes a term reflecting yt − Et yt +1 , which must be included—in addition to a white noise
preference shock vt —because (1) and (2) are expressed in terms of the output gap rather than
output. The natural-rate value yt is assumed to follow a first-order autoregressive process
with AR parameter 0.95 and innovation standard deviation 0.007. The white noise
preference shock has standard deviation 0.02 and the shock term ut in the price adjustment
equation (2) is taken to be white noise with standard deviation 0.005. For the results given
below, the value of the CB preference parameter λ is set at 0.1.

15

We begin by reporting in Table 1 results of using different values for the feedback
parameter µ1 (setting µ2 = 0 here and in subsequent cases). The first column pertains to the
µ1 value of 0.5, as suggested by Taylor (1993). Successive columns then use values of 5.0
and 50.0. Finally, the last column includes results for “µ1 = ∞,” i.e., for the targeting rule
(3’). In each cell, two values are reported. The first is the unconditional expected value of
the loss function, which is (with β = 0.99) 100 times the unconditional expectation of the
single-period loss. The second is the standard deviation of Rt, the interest rate instrument.
These values are based on analytical expressions for the unconditional variances of πt, yt,
and Rt implied by the model-plus-rule systems.
The first row of Table 1 gives results for the reference case in which there is no et
mistake term. The pattern is similar to those in McCallum and Nelson (2000a, Table 4) in
that the value of the loss function with the instrument rule (4’) approaches the value with the
target-rule first-order condition (3’). Here, however, the Rt standard deviation (SD) values
are also reported. Not surprisingly, they also show the instrument-rule values approaching
the targeting-rule value smoothly as µ1 grows without bound. In the second row the mistake
or error term et is included as white noise with a SD of 0.002. With this small variability, the
results are not much affected. Then in row three the SD of et is increased to a magnitude that
is similar to that of the other model shocks. In this case again, nevertheless, there is no
tendency for the large µ1 values to generate poor performance. Indeed, the variability of Rt is
slightly smaller with µ1 = 50 than with the targeting rule holding exactly. (The same remains
true if we set µ1 = 500.) For more stringent tests, we increase the SD of the error term by a
factor of ten in the fourth row and then, in row five, revert to 0.02 for the innovation SD but
with an autoregressive parameter of σe = 0.8. In both these cases the SD of the interest rate

16

increases slightly as we switch from a large µ1 coefficient value of 50 in the instrument rule
to the use of the analogous targeting rule.
Table 2 repeats the same experiments from Table 1 but with the first-order targeting
rule and its instrument-rule version pertaining to policy behavior of the “timeless
perspective” type of commitment, rather than discretion.19 In this case, the optimality
condition is
(5)

πt + (λ /α)(yt − yt−1) + et = 0

and the analogous instrument rule (with µ2 = 0) is
(6)

Rt = r + πt + µ1[πt + (λ/α)(yt – yt−1) + et]

when the et mistake terms are included. Here the values and patterns are quite different than
in Table 1, but the same finding vis-à-vis Svensson’s conjecture is obtained. There is, in
other words, no tendency for large µ1 values in (5) to lead to high Rt volatility or to poor
performance, in comparison with the specific targeting-rule results of condition (5).
6. Model with Predetermined Output and Inflation
There are various modifications to the model (1)-(2) that could be examined,20 to
determine whether the foregoing results obtain generally, but one in particular is of special
relevance. This modification stems from recognition that the examples in Svensson’s (2003)
paper are worked out in terms of models (pp. 432−435) in which agents’ actions in period t
have no effect on output or inflation until period t+1. Accordingly, we now modify our
model (1)−(2) so as to possess that property. Thus consider the following specification, in
which symbols are the same as above.21
19

This is the type of rule recommended by Woodford (1999, 2003) and by Svensson and Woodford (2003).
We have verified that inclusion of serial correlation in the ut shock process does not alter our basic result.
21
Our specification is equivalent to Svensson’s, in which t +1 is used wherever we use t, etc.
20

17

(7)

yt = Et−1yt+1 + b1(Et−1Rt − Et−1πt+1) + vt,

b1 < 0

(8)

πt = αEt−1yt + βEt−1πt+1 + ut.

α > 0, 0 < β < 1

Here we have used the law of iterated expectations, e.g., Et−1(EtXt+1) = Et−1Xt+1. With this
modification, the optimal discretionary first-order condition imposed in period t—i.e., the
specific targeting rule—becomes
(9)

Etπt+1 + (λ/α) Etyt+1 = 0

instead of (3). (See Svensson, p. 452.) Accordingly, the implied instrument rule with µ2 = 0
and r = 0 is
(10)

Rt = Et−1πt + µ1[Et−1πt + (λ/α)Et−1yt].

Again the relevant experiment, designed to compare these two approaches with policy
mistakes, entails specifications with random error terms included in both rules. The model to
be solved then consists of equations (7), (8), and either
(11)

Et−1πt + (λ/α)Et−1yt + et−1 = 0

or
(12)

Rt = Et−1πt + µ1[Et−1πt + (λ/α)Et−1yt + et−1].

Here the random mistake terms are dated t−1 so as to respect the notion that output and
inflation in t are predetermined. (For discussion of an alternative timing, see the Appendix.)
Before turning to more complex cases, let us consider an analytical solution for the
simple special case in which discretion obtains and the three disturbance terms are all white
noises. Then the MSV solution to the system (7), (8), and (11) is of the form
(13a) πt = φ11ut + φ12vt + φ13et−1
(13b) yt = φ21ut + φ22vt + φ23et−1
(13c) Rt = φ31ut + φ32vt + φ33et−1.
18

With this specification, we have Et−1πt = φ13et−1, Et−1πt+1 = 0, Et−1yt = φ23et−1, and Et−1yt+1 = 0.
Undetermined coefficient calculations then yield φ11 = 1, φ12 = 0, φ13 = −α/[α+(λ/α)], φ21 = 0,
φ22 = 1, φ23 = −1/[α+(λ/α)], φ31 = 0, φ32 = 0, and φ33 = −1/b1[α+(λ/α)].
For comparison we need to solve with the instrument rule (12) in place of the
targeting rule (11). The solution is again of the form (13) and now the undetermined
coefficient calculations yield φ11 = 1, φ12 = 0, φ13 = αb1µ1/[1−(1+µ1)αb1−(λ/α)µ1b1], φ21 = 0,
φ22 = 1, φ23 = b1µ1/[1− (1+µ1)αb1−(λ/α)µ1b1], φ31 = 0, φ32 = 0, and φ33 =
µ1/[1−(1+µ1)αb1−(λ/α)µ1b1] > 0. Then to compare the variability of Rt under the two types
of policy behavior, we need only to calculate the magnitude of φ33 for the two cases, since
Var(Rt) = φ332 σe2 in both cases. But with µ1 > 0, it is just a matter of algebra to verify that
φ33 is smaller in the second case, with the instrument rule. So again we find that mistakes
involving the first-order optimality condition are less serious (in terms of interest rate
variability) with use of the instrument rule than the corresponding targeting rule. Also, it is
straightforward to verify that as µ1 → ∞, the instrument-rule expression for φ33 approaches
the targeting-rule expression.
The case just examined is, however, excessively special. Indeed, inspection of the
solutions given above shows that, for the discretionary case with all white noise shocks, there
is no effect of different µ1 values on the mean value (unconditional expectation) of the
objective function. In other words, with no source of serial correlation in the model, and the
existence of an information lag, the discretionary policy rule has no stabilizing properties for
πt and yt in the model (7)−(8). Thus we need to consider cases with autocorrelated
disturbances and/or with TP optimization. For the latter case we find, from Svensson’s
equation (5.28), that the relevant targeting and instrument rules are, respectively,
19

(14)

Et−1πt + (λ/α)[Et−1yt − Et−2yt−1] + et−1 = 0

and
(15)

Rt = Et−1πt + µ1[Et−1πt + (λ /α)(Et−1yt − Et−2yt−1) + et−1].
In Tables 3 and 4 we report numerical results with the model (7)−(8). Again we

report standard deviations based on analytical covariances. In most of the cases, the
standard deviation of the policy-error term is kept at σε = 0.02. For Table 3, which pertains
to discretionary behavior, the policy specifications are (11) and (12) for the targeting and
instrument rules whereas in Table 4, with timeless perspective behavior, the relevant rules
are (14) and (15). In both tables the first three rows apply to cases with white noise shocks
so we see that, as in the analytical solution given above, policy activism is not helpful in
achieving policy objectives. Indeed, when policy errors are included, as in rows 2 and 3, the
activist rules tend to be harmful. This should not be greatly surprising, since there are no
general optimality results pertaining to the formulations being considered. In the final two
rows of each table serially correlated shocks are present, however, so policy activism can
potentially be helpful.22 Indeed, in Table 4 we see that larger values of µ1 lead to reduced
values of the loss function.
Be that as it may, with regard to the issue at hand the results are clear-cut: there is no
tendency for the variability of Rt to grow alarmingly with large values of µ1. Indeed, the
variability of Rt is smaller with large values of µ1 used in the instrument rule than with the
associated specific targeting rule. In addition, the results provided by the targeting rules (11)
and (14) are, as before, very closely approximated by those of the instrument rules (12) and
(15) for large values of µ1.
22

Where autocorrelation is included in the ut process, the innovation variance is kept at 0.0052.
20

7. Conclusion
Svensson (2003) argues strongly that general and specific targeting rules, which
amount to commitments to specified objective functions and first-order conditions
(respectively), are normatively superior to instrument rules for the conduct of monetary
policy. By contrast, we suggest that it is unhelpful to refer to “general targeting rules” as
policy rules, from a terminological perspective, and that substantively their adoption is either
innocuous or else represents a departure from transparency. Most of the present paper’s
discussion is focused, accordingly, upon specific targeting rules—i.e., the first-order
optimality conditions implied by the combination of a specific objective function and a
specific model.
Svensson’s argument that specific targeting rules are superior to instrument rules is
based largely upon four main objections to the latter plus a claim concerning the relative
interest-instrument variability entailed by the two approaches. Our Section 3 considers the
four objections in turn, and advances arguments that contradict all of them. Then in the
paper’s analytical sections (5 and 6), it is demonstrated that the variability claim is incorrect,
for a neo-canonical model and also for a variant with one-period-ahead plans used by
Svensson, providing that the same decision-making errors are relevant under the two
alternative approaches.
We suggest, then, that despite its large quantity of meticulous analysis, Svensson
(2003) does not develop any compelling reasons for preferring targeting rules over
instrument rules, from a normative perspective. We also suggest, regarding the positive
perspective, that no actual central bank has expressed explicitly the magnitude of objective
function parameters that are essential for the utilization of a targeting rule.

21

Appendix
In correspondence, Svensson has argued, “I don’t think your exercise [of Sections 5
and 6] actually gets to the problem and gives a good representation of the issue. One reason
is that I think your approach assumes that everyone immediately knows what the centralbank error [et−1] is and takes that into account in the expectations formation. It would be
more relevant to consider the equilibrium when expectations are formed without knowing the
error.” To evaluate this suggestion, we must consider what is meant by the “error.” What we
have in mind is precisely the type defined by Svensson (2003, p. 461), namely, “a mistake in
calculating the argument of the reaction function.” Since the central bank’s decision
regarding Rt is made in period t−1 in Svensson’s analysis—see his p. 435—the error must be
realized in period t−1; hence our use of et−1 in equations (11), (12), (14), and (15).
Furthermore, Svensson assumes that private agents possess the same information as the
central bank (p. 432) and that actual and privately-expected interest rates coincide (p. 435).
Accordingly, we contend that the analysis of Section 6 above does accurately reflect the issue
spelled out in Svensson’s Section 5.5, so that his objection given above is inapplicable.
An alternative formulation would be to assume some type of policy error that affected

Rt but not Et−1Rt, representing private expectations, a case mentioned by Svensson and
Woodford (2003, p. 57). An implementation error, brought about by imperfect interest-rate
control, would be one such possibility. Analytically, the location of the error term in this
case would be outside the square brackets in expressions (14) and (15), however, so that the
multiplying effect of a large µ1 coefficient would not occur. The other relevant possibility is
that the central bank uses information not possessed by private agents in making its decision.
In that case it is true that large µ1 coefficients would yield large variability of Rt, but this case

22

is apparently inconsistent with the information assumptions of Svensson (2003) and
Svensson and Woodford (2003, pp. 12−13). Furthermore, the rationale for assuming that
actions by private agents in period t depend upon lagged information does not carry over to
the case of Rt, since asset market prices are in reality observable on a day-to-day or hour-tohour basis.

23

Table 1
Results with Model (1)−(2), Discretionary Policy, λ = 0.1
Entries are loss times 103 and SD of Rt
Inst. rule (4’)

Inst. rule (4’)

Inst. rule (4’)

Target rule (3’)

µ1 = 0.5

µ1 = 5.0

µ1 = 50

µ1 = ∞

σε = 0.0

3.70

2.52

2.48

2.48

ρe = 0.0

.0191

.0360

.0397

.0402

σε = 0.002

3.70

2.53

2.48

2.48

ρe = 0.0

.0191

.0360

.0397

.0402

σε = 0.02

3.77

2.81

2.83

2.83

ρe = 0.0

.0198

.0375

.0414

.0419

σε = 0.20

11.02

30.93

37.31

38.16

ρe = 0.0

.0572

.1121

.1240

.1255

σε = 0.02

4.42

3.58

3.58

3.59

ρe = 0.80

.0192

.0361

.0398

.0403

24

Table 2
Results with Model (1)−(2), Timeless Perspective Policy, λ = 0.1
Entries are loss times 103 and SD of Rt
Inst. rule (6)

Inst. rule (6)

Inst. rule (6)

Target rule (5)

µ1 = 0.5

µ1 = 5.0

µ1 = 50

µ1 = ∞

σε = 0.0

11.26

2.83

2.30

2.31

ρe = 0.0

.0336

.0403

.0401

.0401

σε = 0.002

11.27

2.86

2.34

2.33

ρe = 0.0

.0336

.0403

.0401

.0401

σε = 0.02

11.71

5.99

5.88

5.92

ρe = 0.0

.0337

.0403

.0401

.0401

σε = 0.20

55.62

319.47

359.99

364.75

ρe = 0.0

.0449

.0417

.0428

.0430

σε = 0.02

54.37

60.70

59.17

59.05

ρe = 0.80

.0396

.0463

.0460

.0460

25

Table 3
Results with Model (7)−(8), Discretionary Policy, λ = 0.1
Entries are loss times 103 and SD of Rt
Inst. rule (12)

Inst. rule (12)

Inst. rule (12)

Target rule (11)

µ1 = 0.5

µ1 = 5.0

µ1 = 50

µ1 = ∞

σε = 0.0, ρe = 0.0

7.03

6.99

6.99

6.99

ρu = 0.0

.0025

.0022

.0021

.0021

σε = 0.02, ρe = 0.0

7.10

7.27

7.34

7.35

ρu = 0.0

.0060

.0108

.0119

.0121

σε = 0.2, ρe = 0.0

14.4

35.4

41.8

42.7

ρu = 0.0

.0539

.1061

.1175

.1189

σε = 0.02, ρe = 0.0

772

779

780

780

ρu = 0.9

.0841

.0847

.0848

.0849

σε = 0.02, ρe = 0.8

773

780

780

780

ρu = 0.9

.0840

.0841

.0841

.0841

26

Table 4
Results with Model (7)(8), Timeless Perspective Policy, λ = 0.1
Entries are loss times 103 and SD of Rt
Inst. rule (15)

Inst. rule (15)

Inst. rule (15)

Target rule (14)

µ1 = 0.5

µ1 = 5.0

µ1 = 50

µ1 = ∞

σε = 0.0,
ρe = 0.0
ρu = 0.0

8.58
.0058

7.01
.0025

6.99
.0022

6.99
.0021

σε = 0.02,
ρe = 0.0
ρu = 0.0

9.02
.0065

10.2
.0027

10.6
.0026

10.6
.0026

σε = 0.2,
ρe = 0.0
ρu = 0.0

52.9
.0304

324
.0113

365
.0152

369
.0156

σε = 0.02,
ρe = 0.0
ρu = 0.9

446
.0392

308
.0098

306
.0128

306
.0131

σε = 0.02,
ρe = 0.8
ρu = 0.9

488
.0444

362
.0249

360
.0260

360
.0261

27

References
Allsopp, Christopher (2002). “Macroeconomic Policy Rules in Theory and in Practice.”
External MPC Unit Discussion Paper No. 10, Bank of England.
Bank of England (2000). Economic Models at the Bank of England: September 2000
Update. London: Bank of England.
Bean, Charles, and Nigel Jenkinson (2001). “The Formulation of Monetary Policy at the
Bank of England,” Bank of England Quarterly Bulletin 41, 434−441.
Brown, Gordon (2003). “Statement by the Chancellor of the Exchequer on UK Membership
of the Single Currency.” House of Commons speech, London, June 9.
Bryant, Ralph C., Peter Hooper, and Catherine L. Mann (eds.) (1993). Evaluating Policy
Regimes: New Research in Empirical Macroeconomics. Washington, D.C.: Brookings
Institution.
Bullard, James, and Kaushik Mitra (2002). “Learning About Monetary Policy Rules,”
Journal of Monetary Economics 49, 1105−1129.
Clarida, Richard, Jordi Galí, and Mark Gertler (1999). “The Science of Monetary Policy: A
New Keynesian Perspective,” Journal of Economic Literature 37, 1661–1707.
Clarida, Richard, Jordi Galí, and Mark Gertler (2001). “Optimal Monetary Policy in Open
versus Closed Economies: An Integrated Approach,” American Economic Review (Papers
and Proceedings) 91, 248–252.
Cote, Denise, Jean-Paul Lam, Ying Liu, and Pierre St-Armant. (2002) “The Role of Simple
Rules in the Conduct of Canadian Monetary Policy,” Bank of Canada Review (Summer),
27−35.
Fuhrer, Jeffrey C. (2000). “Habit Formation in Consumption and Its Implications for
Monetary-Policy Models,” American Economic Review 90, 367−390.

28

Giannoni, Marc P., and Michael Woodford (2003a). “Optimal Interest-Rate Rules I: General
Theory.” NBER Working Paper No. 9419.
Giannoni, Marc P., and Michael Woodford (2003b). “Optimal Interest-Rate Rules II:
Applications.” NBER Working Paper No. 9420.
Hampton, Tim (2002). “The Role of the Reserve Bank’s Macro-Model in the Formation of
Interest Rate Projections,” Reserve Bank of New Zealand Bulletin 65, 5−11.
Henderson, Dale W., and Warwick J. McKibbin (1993a). “A Comparison of Some Basic
Monetary Policy Regimes for Open Economies: Implications of Different Degrees of
Instrument Adjustment and Wage Persistence,” Carnegie-Rochester Conference Series on
Public Policy 39, 221−317.
Henderson, Dale W., and Warwick J. McKibbin (1993b). “An Assessment of Some Basic
Monetary-Policy Regime Pairs: Analytical and Simulation Results from Simple Multregion
Macroeconomic Models.” In R.C. Bryant, P. Hooper, and C.L. Mann (eds.), Evaluating
Policy Regimes: New Research in Empirical Macroeconomics. Washington, D.C.:
Brookings Institution. 45−218.
Jensen, Henrik (2002). “Targeting Nominal Income Growth or Inflation?,” American
Economic Review 92, 928−956.
Judd, John P., and Glenn D. Rudebusch (1998). “Taylor’s Rule and the Fed: 1970-1997,”
Federal Reserve Bank of San Francisco Economic Review 24, 3−16.
Levin, Andrew T., Volker Wieland, and John C. Williams (1999). “Robustness of Simple
Monetary Policy Rules under Model Uncertainty.” In J.B. Taylor (ed.), Monetary Policy
Rules. Chicago: University of Chicago Press. 263–299.
Levin, Andrew T., and John C. Williams (2003). “Robust Monetary Policy with Competing
Reference Models,” Journal of Monetary Economics 50, 945−975.
Longworth, David, and Brian O’Reilly (2002). “The Monetary Policy Transmission
Mechanism and Policy Rules in Canada.” In N. Loayza and K. Schmidt-Hebbel (eds.),

29

Monetary Policy: Rules and Transmission Mechanisms. Santiago: Central Bank of Chile.
357−392.
McCallum, Bennett T. (1988). “Robustness Properties of a Rule for Monetary Policy,”
Carnegie-Rochester Conference Series on Public Policy 29, 173–203.
McCallum, Bennett T. (1999). “Issues in the Design of Monetary Policy Rules.” In J.B.
Taylor and M. Woodford (eds.), Handbook of Macroeconomics, Volume 1C. Amsterdam:
North Holland. 1483–1530.
McCallum, Bennett T., and Edward Nelson (1999a). “Nominal Income Targeting in an
Open-Economy Optimizing Model,” Journal of Monetary Economics 43, 553–578.
McCallum, Bennett T., and Edward Nelson (1999b). “Performance of Operational Policy
Rules in an Estimated Semi-Classical Structural Model.” In J.B. Taylor (ed.), Monetary
Policy Rules. Chicago: University of Chicago Press. 15–45.
McCallum, Bennett T., and Edward Nelson (2000a). “Timeless Perspective vs. Discretionary
Monetary Policy in Forward-Looking Models.” NBER Working Paper No. 7915. (Revised
version published in Federal Reserve Bank of St. Louis Review 86 (no. 2), 2004, 43-56.)
McCallum, Bennett T., and Edward Nelson (2000b). “Monetary Policy for an Open
Economy: An Alternative Framework with Optimizing Agents and Sticky Prices,” Oxford
Review of Economic Policy 16, 74–91.
Meltzer, Allan H. (1987). “Limits of Short-Run Stabilization Policy,” Economic Inquiry 25,
1−14.
Rudebusch, Glenn D., and Lars E.O. Svensson (1999). “Policy Rules for Inflation
Targeting.” In: J.B. Taylor (ed.), Monetary Policy Rules. Chicago: University of Chicago
Press. 203–246.
Svensson, Lars E.O. (1997). “Inflation Forecast Targeting: Implementing and Monitoring
Inflation Targets.” European Economic Review 41, 1111–1146.

30

Svensson, Lars E.O. (1999). “Inflation Targeting as a Monetary Policy Rule,” Journal of
Monetary Economics 43, 607–654.
Svensson, Lars E. O. (2001). Independent Review of the Operation of Monetary Policy in
New Zealand: Report to the Minister of Finance. (www.princeton.edu/~svensson)
Svensson, Lars E.O. (2003). “What is Wrong with Taylor Rules? Using Judgment in
Monetary Policy through Targeting Rules,” Journal of Economic Literature 41, 426−477.
Svensson, Lars E.O., and Michael Woodford (2003). “Implementing Optimal Policy
Through Inflation-Forecast Targeting.” NBER Working Paper No. 9747.
Taylor, John B. (1993). “Discretion versus Policy Rules in Practice,” Carnegie-Rochester
Conference Series on Public Policy 39, 195−214.
UK Treasury (2003). Policy Frameworks in the UK and EMU. www.hm-treasury.gov.uk
Walsh, Carl E. (2003). “Speed Limit Policies: The Output Gap and Optimal Monetary
Policy,” American Economic Review 93, 265−278.
Woodford, Michael (1999). “Commentary: How Should Monetary Policy Be Conducted in
an Era of Price Stability?” In: New Challenges for Monetary Policy: A Symposium
Sponsored by the Federal Reserve Bank of Kansas City. Federal Reserve Bank of Kansas
City. 277–316.
Woodford, Michael (2003). Interest and Prices: Foundations of a Theory of Monetary
Policy. Princeton: Princeton University Press.

31

