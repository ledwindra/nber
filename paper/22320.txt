NBER WORKING PAPER SERIES

KEEPING COLLEGE OPTIONS OPEN:
A FIELD EXPERIMENT TO HELP ALL HIGH SCHOOL SENIORS
THROUGH THE COLLEGE APPLICATION PROCESS
Philip Oreopoulos
Reuben Ford
Working Paper 22320
http://www.nber.org/papers/w22320

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2016
This project would not have been possible without the support and enthusiasm of many people.
The Ministry of Training, Colleges, and Universities (MTCU), partnered with the Ministry of
Education and the Social Research and Demonstration Corporation (SRDC) to fund and
implement the experiment. We are especially grateful to Noah Morris, Jean-Pierre Voyer, Sam
Andrey, Chris Ste-Croix, Travis Coulter, Galina Buryak, Jennifer Da Silva, Lisa Stanley, Noemi
Varga and Doug Calderwood-Smith from MTCU for championing the research. SRDC staff
members Dominique Leonard, Sheila Currie, Heather Smith Fowler, Claudia Nicholson, Danielle
Patry, Isaac Kwakye, Natalie Conte, Bart Millson, Taylor Shek-wai Hui provided expert field
operational and data analytical experience. We are grateful to both Tony Tullio and Inorbital as
well as Honrio Cham and Radii for helping develop the program's website in different phases,
Laurie Labelle for designing the program's brochures and other materials, Ryan Dunn and Jason
Rogers for developing the financial aid calculator, Matt Boire and Sabina Dobrer for developing
the 'Where Would You Go' tool and Boaz Beeri for producing its videos. We also greatly
benefited from the facilitators who delivered the program and Shayne Hillier who provided IT
field support. And we are indebted to all the principals, counselors, teachers, and students who
participated in the program as well as the staff at OSAP, OUAC and OCAS who supported the
application processes. Comments and feedback from several seminars and conferences were also
greatly appreciated. Any errors or omissions are the sole responsibility of the authors. The views
expressed herein are those of the authors and do not necessarily reflect the views of the National
Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2016 by Philip Oreopoulos and Reuben Ford. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.

Keeping College Options Open: A Field Experiment to Help All High School Seniors Through
the College Application Process
Philip Oreopoulos and Reuben Ford
NBER Working Paper No. 22320
June 2016
JEL No. I20,I23,I28,J20
ABSTRACT
Recent research suggests that the college application process itself prevents access. This paper reports
results from a large school-based experiment in which application assistance is incorporated into the
high school curriculum for all graduating seniors at low-transition schools. Over three workshops,
students were guided to pick programs of interest that they were eligible for, apply for real, and complete
the financial aid application. The goal was to create a college option for exiting students to make the
transition easier and more salient. On average, the program increased application rates from 64 to 78
per cent. College enrolment increased the following school year by 5.2 percentage points with virtually
all of this increase in two-year community college programs. The greatest impact was for students
who were not taking any university-track courses in high school: the application rate for these students
increased by 24 percentage points with a nine per cent increase in two-year college enrolment. A second
experiment was conducted two years later to explore several variations of the program. Offering personal
assistance without waiving application fees had a negligible or even negative impact on applications
and enrollment. Using laptops in homeroom classrooms instead of sending students to computer labs
while combining the initial 2 workshops into one full-morning session increased application rates.
However, subsequent enrollment effects were negligible. We provide some evidence consistent with
the possibility that decreased guidance in choosing eligible programs was responsible for the second-experiment's
decline in enrollment impacts.

Philip Oreopoulos
Department of Economics
University of Toronto
150 St. George Street
Toronto, ON M5S 3G7
CANADA
and NBER
philip.oreopoulos@utoronto.ca
Reuben Ford
Social Research and Demonstration Corporation
789 West Pender Street
Suite 440
Vancouver, British Columbia, V6C 1H2
rford@srdc.org

I. Introduction

In most school systems, the transition from Grade 7 to 8 is straightforward. Students who
complete Grade 7 are automatically enrolled in Grade 8 and can show up the following
September at the same school, confident that there will be a spot waiting for them. Even for the
transition from Grade 8 to 9, when students switch from elementary to high school, resources are
provided to make the adjustment simple. Since all students experience this transition, much of
the process has become automatic, and school staff guide students (often in class) and parents
through any remaining non-automatic choices, such as choosing courses or choosing schools
outside default catchment areas. Administrators help ensure everyone gets to the right place the
following year.
The same cannot be said for moving from Grade 12 to college. Students who plan to
attend college must complete prerequisite courses in high school with sufficient grades to qualify
for acceptance into a program. But sufficient grades do not guarantee a spot: even qualified
students still must choose which programs and colleges to apply, complete each application and
pay application fees, and often must take standardized readiness assessment tests (like the ACT
or SAT) and write entrance essays. Those in financial need must complete an application for
federal assistance and may benefit from applying elsewhere for scholarships, awards, and
additional financing. Finally, at the end of the transition period, students must receive and accept
an offer, receive and manage financial aid, register and pay fees, choose courses, and upend their
daily routine to begin classes at their new school.
Historically, the majority of students ended their education with high school. College
was left to a small elite, and if an exceptional student wanted to go to college, she was left to

figure things out on her own. But times have changed. Most developed countries have seen a
steady rise in the number of youth with college intentions: for example, by 2015, 70 percent of
recent high school graduates in the United States were enrolled in postsecondary education. 1
Despite this trend, the transition process from high school to college has largely remained
unchanged. Support varies greatly by school and region, with less support often in poorer
neighborhoods. 2
Transition barriers to college and other programs are usually ignored in economics and
public policy. For decisions such as college attendance involving large, long-term costs and
benefits, the marginal costs of taking action and applying are often perceived as “too small to
matter.” However, research in behavioral economics, psychology, and neuroscience provides
clear evidence to the contrary. 3 It is in our nature to sometimes focus too much on the present,
or stick too much to routine. 4 Actions that require taking time out of our routine, that are
complex and without social support, and whose benefits are very long-term and uncertain are
tempting to put off. Stress -- for example, from lack of time or money -- exacerbates these
leanings. 5
The FAFSA (Free Application for Federal Student Aid) provides a prototypical example
of how seemingly small differences in take-up procedures can lead to differences in
participation. 6 The form contains more than 100 questions, including ones about parents' exact
1

Bureau of Labor Statistics, Economic News Release, April 28, 2016.
See, for example, New York Times article, "Guiding a First Generation to College," April 26, 2016, by Tina
Rosenberg.
3
See, for example, Stanovich et al., 2012, and Frederick et al., 2002,
4
See McClure et al., 2004; Kable and Glimcher, 2007; Kable and Glimcher, 2010, Stanovich et al., 2012.
5
Lavecchia, Liu, and Oreopoulos (2016) provide a more detailed theoretical and empirical overview of behavioral
economics in the education context.
6
The need to save for retirement is commonly mentioned as another example. Standard models assume that
individuals are forward looking, able to forecast how much they will need to save (or that they have access to
services that help them do this), and face little difficulty following through with their plans. Simply changing the
default action (from having to opt-into pension plans to being automatically enrolled), or requiring individuals to
2

income, social security numbers, highest level of education, students' savings, working income
and other untaxed income. Anyone needing college aid must complete this form. Researchers
and government officials have speculated that some fail to apply and to go to college because
they are either unaware of the FAFSA, or cannot overcome its complexity or inconvenience. 7
To test this theory, Bettinger et al. (2012) partnered with H&R Block, a large tax
preparation company that helps millions of low-income households file tax forms each year in
the United States. Much of the information needed to complete the FAFSA -- including the most
difficult to collect -- is the same information collected during a visit at H&R Block. Parents
whose income likely qualified their Grade 12 children for college aid were randomly selected
into the FAFSA assistance group. They were invited to continue to work with a tax professional
for an extra 10 minutes to receive help with the FAFSA for their child. 8 Complete or nearcomplete FAFSAs were then sent home with a pre-paid envelope and instructions for the child to
sign and mail the form to the Department of Education. Parents selected into the control group
were given only a booklet about college, and parents selected into the information group were
given an outline of tuition costs at local public colleges along with the likely grant and loan aid
available if a FAFSA was filed, but were not given filing assistance.

Grade

12

students

whose parents were assigned to the information group were no more likely to file a FAFSA or
attend college the following school year than the control group. Those assigned to the FAFSA
assistance group, however, were 16 percentage points more likely to file and 8 percentage points

make an active decisions regarding their contributions, or just simplifying the application process increases savings
significantly (Beshears et al., 2013; Carroll et al., 2009; Chetty et al., 2014).
7
The 2005 Congressional Advisory Committee on Student Financial Assistance concluded that "millions of students
and adult learners who aspire to college are overwhelmed by the complexity of student aid. Uncertainty and
confusion rob them of its significant benefits. Rather than promote access, student aid often creates a series of
barriers - a gauntlet that the poorest students must run to get to college".
8
The FAFSA study also examined impacts from offering application assistance to young adults out of school with
no more than a high school education. The assistance increased college enrollment by about 2 percentage points.

more likely to attend. They were also just as likely to attend for two years, which is notable
given that the FAFSA assistance was only provided during the transition year.
Offering personal assistance to complete the FAFSA in this way can affect college
enrollment through several channels. The assistance increases visibility of the form and
makes parents more aware of financial aid possibilities. It reduces complexity by avoiding

the need to review detailed instructions and uncertainty around whether the form is filled

out correctly. Offering support while already at an office minimizes disruption and lowers
the opportunity cost of time. It generates reassurance and encouragement from having a

professional promote the form. The assistance also makes the FAFSA more salient, reminding
parents of the time-sensitive benefits of filling it out.

The program examined in the FAFSA study, however, only helped with one component
of the transition to college - applying for financial aid. Applicants still had to determine which
colleges and programs to apply to. They still had to pay program application fees, register for
courses, and complete the SAT or ACT. And only children of parents visiting H&R Block who
agreed to receive $20 to participate in a study vaguely about college were affected.
This paper presents results of an experiment motivated by the FAFSA study to explore a
more scalable program called LifeAfterHighSchool, which offered personal assistance for both
financial aid and program applications, and provided this support directly to students at lowtransition high schools (where fewer than half of graduating seniors enter college the following
school year). The first pilot of the experiment was conducted in 2011-12 across the Canadian
province of Ontario, where there are typically no additional essay or standardized test
requirements for postsecondary applications. Principals agreed to give up 3 classes over the
school year for the program. During the first class, Grade 12 students were guided through

browsing local college programs for which they would likely be accepted into, and were asked to
choose up to 5 for which they would like to keep the option to attend open. They also walked
through a simple financial aid and budget calculator to determine how they could afford to go to
college. In the second class (about three weeks later), students were guided through completing
their applications on the actual central application website, with LifeAfterHighSchool waiving
the regular application fees. In the final class, students were guided to begin an application for
government student aid. Parents were mailed and emailed instructions on how to complete the
remainder of the form.
LifeAfterHighSchool increased the college application rate for graduating seniors from
64 to 78 percent, with most of this increase coming from 2-year college applications. College
enrollment correspondingly increased the following school year by 5.2 percentage points, and
virtually all of this increase was due to additional enrollment at 2-year colleges. The program
had similar effects for males and females, and for rural and urban schools. Its largest effects
were on graduating students who were not taking any university-track courses. The application
rate for these students increased by 24 percentage points. The 2-year college enrollment
rate for them increased by 9 percentage points..

A second LifeAfterHighSchool experiment was conducted two years later to explore

variations on the first program setup. Offering personal assistance without waiving application
fees had a negligible or even negative impact on applications and enrollment. Offering fee
waivers and providing only instructions to school staff for how to implement the program led to
similar increases in applications and enrollment as in the first program.

Using laptops in

homeroom classrooms instead of sending students to computer labs, while simultaneously
combining the initial 2 classes into one full-morning session, increased application rates.

However, subsequent enrollment effects were negligible. We provide some evidence consistent
with the possibility that decreased guidance in choosing eligible programs was responsible for
the decline in enrollment impact. Better guidance in picking appropriate programs and waiving
application fees are clearly important conditions for providing college transition support directly
to low-transition high schools.
The next section provides more details of the LifeAfterHighSchool program design. In
section III, we discuss actual program fidelity to the original design. Section IV describes our
data and randomized difference in differences methodology. Sections V and VI present results
from the experiment's first and second pilots respectively. We discuss results in Section VII,
placing them in context with other recent studies and discussing their implications for scaling up
given relatively low implementation costs.

II. Program Design

The underlying goal of the LifeAfterHighSchool program was to help, during class time,
virtually all graduating seniors at low transition schools through the college application process
so that they left school in June with an offer of acceptance from a program they helped choose,
and with guaranteed financial aid. The premise was that the program would make crossing the
bridge from high school to college an easier path to take.

The program was deliberately

inclusive: all students at participating schools with at least 4 years of high school education (call
them Grade 12 students) were eligible to receive the program's application assistance. We
adopted this inclusive approach to make the program easier for schools to implement; rather than

having to target individual students on the basis of their likelihood of graduating, whole classes
could be scheduled together. The use of class time as well as the covering of application fees
minimized students' opportunity cost.

We also targeted all students regardless of their

postsecondary intentions to avoid stigmatizing students who were not on track to continue on to
college, but also to expose students at the margin to possible positive peer effects. We tried to
communicate the message that whether a student was sure she wanted to go to college or not, she
could not keep open the option to go without applying now.

Hence, the slogan of the

LifeAfterHighSchool program was 'Keep Your Options Open'.

School Selection
The LifeAfterHighSchool pilot was funded and supported by the Ontario Ministry of
Training, Colleges, and Universities (MTCU) in partnership with the Ministry of Education.
The province of Ontario is a particularly attractive region to consider application assistance
because no additional standardized tests or essays are required to be considered for most

college and university programs. In theory, students need only identify which programs they
wish to be considered for, and agree to have their high school transcripts sent for evaluation. In

reality, students are usually invited to attend college information sessions outside class time to
learn how to navigate through the program and financial aid applications. Two centralized
application services offer websites - one for 2-year community colleges and one for 4-year
universities – for applying to virtually all programs in the province, with one fee covering up to

five applications. 9 A separate website allows students to create accounts to apply for Ontario
student aid.
We targeted schools with the lowest college transition rates in the province, conditional
on 1) being commuting distance from a college (within 50km), 2) having at least 100 Grade 12
students recorded in 2007-08 (the latest data we had at the time of recruiting), and 3) not being
an adult or alternative education center. 126 schools, generally with under half of Grade 12
students going on to college the following year, were invited to participate for a random chance
to be offered LifeAfterHighSchool. Most of the principals responded enthusiastically, although
12 declined to participate for various reasons, including resource or timing concerns, insufficient
computer lab space, or feeling that the program was not appropriate for their particular school.
Some failed to respond in time to the offer to be in the study. A few additional schools were
dropped for budgetary reasons, leaving a total of 86 schools.
Half of these schools were randomized to receive the program, and the other half were
assigned to the control group. In cases where there was more than one school within a district, at
least one school was assigned to the program, and at least one was assigned to the control group.
Table 1 provides descriptive means for the cohort of Grade 12 students at program and control
schools in the year prior to the program's implementation, and shows that random assignment
successfully balanced mean characteristics between the two groups. The data are from student
files from the Ministry of Education, aggregated at the school level (and described in more detail
in Section IV). In column one, Grade 12 course grades in 2010-11, weighted by student size,
averaged 64.7 percent for control schools, compared to 64.3 percent for program schools. Only
about half these students took university-level courses, which are required pre-requisites for
9

In Canada, the term ‘college’ typically refers to 2-year community colleges while ‘university’ refers to 4-year
colleges. If not specified in the paper, ‘college’ refers to any postsecondary institution, as the term is used in the
United States.

admission into 4-year programs. 10 Less than half applied to postsecondary programs that year,
and 30 percent subsequently enrolled by the following school year.
Note that only 52.4 percent of the entire 2010-11 Grade 12 sample in the control group
actually graduated and left high school the following year. The main reason appears to be that
many had fewer than 21 credits at the start of the year, making it unlikely they would have
attained the 30-credit graduation requirement by the end of the year. Another reason is that some
graduates stay for another year to boost their grade average before applying to college. Since we
cannot directly help these students apply or get accepted into a program the following year,
average treatment effects with them in the sample will be smaller than without. Consequently,
we estimate treatment effects for students with at least 21 credits at the start of Grade 12, and for
students that left high school the following year (a behavior that we show that is not determined
by the treatment). In all sample specifications, background characteristics appear to be well
balanced between program and control schools, as is expected with random assignment.

The Workshops
The LifeAfterHighSchool program included three classes, or 'workshops', each about 60
to 70 minutes in length, in which Grade 12s were directed to computer labs instead of their
10

In Ontario, it is more difficult to enroll in university-level courses in Grade 12 for students who did not follow
academic level course progressions throughout high school. Grade 9 students choose whether to take 'applied' or
'academic' level courses, such as in English or Math. Students that successfully complete the Grade 9 academic
course may proceed to either the Grade 10 academic or the Grade 10 applied course. Those who successfully
complete the Grade 9 applied course may proceed to the Grade 10 applied course, but must successfully complete
a transfer course if they wish to proceed to the Grade 10 academic course. The Grade 10 academic and applied
courses prepare students for particular destination-related courses in Grade 11. The Grade 11 and 12 mathematics
curriculum offers preparation courses for university, college, and the workplace. These courses affect the
postsecondary programs students are eligible to apply for. Students cannot apply to university programs without
university-level courses. Students taking workplace-type courses still have 2-year community college options, but
far fewer than if they had taken college-type courses instead.

regularly scheduled classes. Schools were asked to keep students grouped together with their
regular classmates, so that each teacher could redirect their entire class to a computer lab to
participate. A key tool used in the workshops was the LifeAfterHighSchool website, which was
designed to provide students a ‘one-stop-shop’ with directed access to application websites,
informational videos, tools for identifying suitable programs for each student, and a financial aid
and budget calculator.
The class that was most often substituted with LifeAfterHighSchool workshops was
English – an obvious choice, being the only mandatory Grade 12 course in Ontario.
Unfortunately, not all Grade 12 students were enrolled in English in the first semester, and some
had already completed the course.

Staff, therefore, tried to schedule workshops as direct

substitutes for classes as much as possible, but sometimes invited only a subset of students from
a class to attend a workshop. Make-up workshops were added when possible for students who
missed earlier ones. Schools were given the choice to have workshops administered by external
facilitators (many of whom had teaching degrees) or to deliver the program with internal staff
after receiving training. Approximately half of the treated schools chose each option.

Workshop One
Delivery of the first workshop began in October 2011. Students were first shown a 5
minute video promoting the possible benefits of college, and describing the program. 11 The
video emphasized a variety of fields of study, especially vocational options. Students then
created a personal account using an assigned registration card. After verifying their email
11

The introductory video can be located here: https://vimeo.com/30165296 (accessed on May 4, 2016). The
material was based, in part, on the information experiment used by Oreopoulos and Dunn (2013), which generated
increased educational aspirations, aid expectations, and interest in obtaining further college information.

addresses, students were shown a follow-up video introducing them to the first workshop. On
the LifeAfterHighSchool website, they were instructed to click on the link 'Where Would You
Go?' and enter previous Grade 11 and expected Grade 12 course marks (transcripts were
provided by facilitators in case students could not remember). The website then produced a
comprehensive list of 2- and 4-year programs at nearby colleges and universities (within 40km)
for which students likely met eligibility requirements. 12 Each program included a link to its
official website, the name of the associated college (and a link to the college’s main site), the
degree type, program requirements for eligibility, and a list of the most common occupations
associated with workers with the same degree. Students could filter or expand their list to show
programs by length (2 years or less versus more than 2 years), programs farther than 40km away,
programs based on their personalized interests, and programs that would (or would not) lead to
office-type jobs. They were asked to click on programs of possible interest and indicate their
preferred choice and other favorites in a personal folder on the web page and email it to
themselves.
A second component of Workshop 1, for students that had time, involved exploring a
simple financial aid and budget calculator. After clicking 'How Would You Go?', students were
asked five questions that could be answered using a drop-down menus about family status,
number of siblings and number already attending college, approximate parents' income, and
whether they would live at home or in residence during college. The calculator produced a
rough estimate of the students' grant and loan eligibility, and displayed these amounts as part of
an overall monthly and annual budget specific to enrolling in the students' preferred program of

12

Many students seemed pleasantly surprised with the variety of options listed. They may have initially associated
college mostly with a bachelor's program in Arts. Initially listing only programs for which students would likely be
accepted if they applied may have helped reduce anxiety and other challenges surrounding sorting through longer
lists. Students could relatively quickly assess which interesting programs would be worth seriously considering.

interest. Students could then modify cost and revenue assumptions to see how their overall
budget would be affected, and could then email a copy of the budget to themselves.

Workshop Two
To allow time for students to browse possible college programs outside of class,
Workshop 2 was scheduled several weeks after Workshop 1, in November and December. 13 All
Grade 12 students were again assigned to computer labs instead of attending regularly scheduled
classes. They were shown a 5 minute video introducing the actual application process, and were
asked to log on to the LifeAfterHighSchool website and click on either a link to OCAS (the
Ontario College Application Service) for applying to 2-year community colleges or to OUAC
(the Ontario Universities' Application Centre) for 4-year universities.

The website offered

guidance and videos to help students through the process. Facilitators were also on hand to
answer questions and help out during the workshop. Like the FAFSA, many questions – such as
date of birth and address – were straightforward to answer, but other questions – such as
students' Ontario Education Number – may have required the assistance of a guidance counselor
or facilitator. Uncertainty about how to navigate through sections asking questions about work
experience (which usually students need not complete), type of program, expected start dates, or
citizenship may have also slowed students down or caused hesitation. With the facilitators’
assistance, most students were able to apply to multiple programs during the workshop.
Programs could be added, deleted, or changed until the application deadline in January (OUAC)
or February (OCAS).
An important part of Workshop Two was the waiving of the application fee. Students
could apply for up to five community college or three university programs and bypass the
13

Few students, however, logged into the web site between workshops.

approximately $100 fee. This component was expected be especially important to persuade
students that they had “nothing to lose” by applying, especially for those who were doubtful
about wanting to enroll in post-secondary education. The application fee could act as a
significant barrier to disadvantaged students’ learning about their actual eligibility and likelihood
of acceptance. To administer the fee waiver, students were asked to indicate on their application
an option to pay via online banking. Online banking payments were not due immediately.
Students could then copy their application number (whether the application was finalized or not)
and paste it into the 'Pay for Free' section of the LifeAfterHighSchool webpage, and not have to
pay on their own.

Workshop Three
The third workshop took place shortly after the Ontario Student Aid Program (OSAP)
website became available in May.

This session focused on guiding students through the

financial aid application process. In the same year that the program was implemented, the
province introduced a tuition tax credit for any student with household income less than
$150,000. The application process for the credit and for the financial aid was similar, so
virtually all students at program schools could be motivated to attend Workshop 3 to keep their
financial aid options open. Parents were notified in advance through a school letter that during
the workshop their Grade 12 child would partially complete the financial aid application form,
and that their input would likely be required to enter the remaining information (such as
household income).
Students watched a short video about college affordability and the OSAP application.
The workshop emphasized at least opening an account to start an application, and completing the

form as far as possible. Opening an account required entering a students' Social Insurance
Number (SIN). Email, snail mail, and morning announcements were used to remind students to
bring their SIN. Students that did not were sometimes given the option of sitting in on the
session and observing another student, or were told to attend a later workshop with their SIN, or
to follow-up directly with a guidance staff once they had obtained it.

Additional Support
In cases where students did not attend a workshop or were not able to finish an
application, school counselors provided rescheduled opportunities or even one-on-one assistance
(at the counselors' discretion, and depending on time constraints). Counselors were informed of
students who had registered but not yet completed a program application and were encouraged to
follow-up, especially with those thought to benefit. Counselors at about half of the program
schools reported using active individual follow-up to help students complete applications.
Promotional material was used to advertise LifeAfterHighSchool. Posters were displayed
at the start of the school year. Brochures describing the program and its goals were distributed to
students in advance of the workshops, and personalized letters were sent to all parents of Grade
12 students to inform them about the workshops.
The LifeAfterHighSchool website could be accessed at any time with an account. In
addition to material for the workshops, it contained links to additional financial resources (such
as non-governmental scholarships and bursaries) and videos labelled 'True Stories' about the
experiences of other young people who had applied and registered for postsecondary education
programs across Ontario.

III. Implementation 14

Designing and implementing the LifeAfterHighSchool program involved making
thousands of decisions. We paid attention to many small details, such as the content of each
video, the hiring and training of facilitators, the design of posters and brochures, the script used
for talking with principals and counselors, and the availability of on-site delivery and technical
support. We also took measures to block web access to social media, ensure that internet
bandwidth was sufficiently high during workshops, communicate with each schools' program
coordinator, respond to early program feedback, avoiding students applying to programs and
getting rejected, and obtain all useful data for analysis. With only one treatment arm in the first
phase of the pilot and five additional treatment arms in the second phase (discussed in Section
VI), knowing which of the other decisions mattered to the overall results is not possible. In cases
where trade-offs may have existed, priority was given to making make the college application
free, attractive, and more convenient for students at the margin of applying, while avoiding
coming across as patronizing to any student.
Table 2 displays online workshop activity at program schools and provides some
indication of the program fidelity. Panel A shows that a total of 11,356 students at the 43
program schools in 2011-12 had taken at least 4 years of high school. Only about half began the
school year with at least 21 credits, which largely explains why only 6,950 Grade 12 students
actually completed 30 credits by the end of the year to graduate and exit grade-school education.
Panel B shows that 7,436 students created an account on the LifeAfterHighSchool website.
While this is more than the total number of graduates that left high school that year, it is far
14

More implementation details can be found in Reuben et al., 2016a

fewer than the total number of Grade 12s who were eligible to participate in the program. There
are a few possible explanations for this less-than-full participation. Counselors may have placed
more emphasis on ensuring graduating seniors attended the workshops. There were portions of
students for whom staff believed participation would not be appropriate, including students with
learning disabilities and other special needs, and those who were in Grade 12 but who were far
short of the number of credits required to graduate. Another explanation is that some students,
when asked to move from a classroom to computer lab, went elsewhere. Others did not attend
because they were not at school on the day of their scheduled workshop.
Conditional on creating a LifeAfterHighSchool account, participation in Workshop 1 was
relatively high. Almost 90 percent of account holders worked at the 'Where Would You Go?'
exercise and entered previous or expected grades, and almost half had time to try out the
financial aid calculator after choosing their lists of programs of interest. Most importantly, a full
three-quarters of LifeAfterHighSchool registered account holders used the site to pay for a
college application (by entering their application number).

Around half applied to 2-year

community colleges, and the other half applied to 4-year universities.
A relatively small fraction of students in Workshop 3 emailed a parent or recorded their
financial aid application numbers on our website. These outcomes may not be representative as
indicators of overall participation because they were not required to actually complete the aid
application. Still, other feedback from the field suggests there were limitations in trying to
simplify the aid application process in class. A month delay in the launch of the online OSAP
application form created scheduling challenges and led to Workshop 3 competing with many
end-of-year activities. Guidance personnel reported that teachers were much less eager to allow
their students to miss a class to attend the workshop, and students were also reluctant to do so,

especially those who had not applied to college earlier. Students also needed to use their Social
Insurance Numbers to open an OSAP account, and – despite emails sent to LifeAfterHighSchool
account holders, letters sent to parents, and school reminders – many did not have them on hand.
Students were instead given a paper version of the application and were encouraged to complete
the form at home, or asked to follow-up with staff once they had obtained the information.
Overall, 35 percent of school coordinators said that Workshop 3 attendance of graduating Grade
12 students was higher than 80 percent, and 55 percent said that attendance levels were at least
50 percent. In comparison, 80 and 70 percent of coordinators said that Workshop 1 and 2
attendances rates were at least 80 percent, respectively.
The overall reaction to LifeAfterHighSchool was quite positive.

We surveyed 99

counselors, principals, and vice-principals from all 43 program schools about their perceptions of
students' impressions of the program, and about their own perceptions. Respondents said that
graduating students had high levels of interest in the program. A large majority said that
graduating students found each workshop useful in helping them 1) locate a postsecondary
program to apply for, 2) apply to a postsecondary program, and 3) understand the associated
costs and benefits of postsecondary. Even for Workshop 3, 83 percent of respondents agreed
that it helped students understand and apply for financial aid. Several educators noted that
LifeAfterHighSchool had “kick-started” students’ thinking about postsecondary education,
helped them become more aware and informed about their options, and encouraged them to
explore more programs and ask many more questions. Several respondents noted how this in turn
had increased students’ confidence about applying to postsecondary education and OSAP, and
decreased related anxiety for both students and parents.

Educators reported that they liked the resources and structure of the program. Some also
implied the program had desirable behavioral effects. For example, some stated that having
workshops in class time allowed counselors to ensure students received immediate or timely
answers to their questions, “as opposed to [them] doing it at home and having to come to me for
help the next day.” Similarly, one said, “We went through the process as a group, so a sense of
community, ‘we’re in this together’ mindset was established – this provided some
encouragement for our reluctant (less confident) students as well.” According to educators, this
structured approach particularly helped students who were indecisive or lacked the confidence or
motivation to engage in the application process, and those who were otherwise disadvantaged:
“[LifeAfterHighSchool] forces students to start the process rather than relying on their initiative
– [this is] especially helpful for those who don’t have parents urging them to apply.”
Many counselors emphasized how important the payment of the application fee was to
their students, many of whom lived in lower-income households. One Guidance Head said their
application numbers were “way up”, and another said, “This has been so great for our kids. I
wish you could see our neighborhood — there are boarded up houses all over the place… For
them to hear, ‘you have potential, you can do this.’ And when they saw the OSAP calculation,
and realized, ‘I can do this,’ you should see their faces light up.”

IV. Data and Methodology

The Ontario Ministry of Education keeps individual high school records on students in
Grades 9 to 12 on a range of demographic and achievement variables. Individual level secondary

and postsecondary application and registration data were linked at the Ministry of Education and
made available for the purpose of analyzing the effectiveness of LifeAfterHighSchool. We
received data for all Grade 12 students (with at least 4 years of high school) at program and
control schools in the academic years 2009-10, 2010-11, 2011-12 (the year the program was
administered), and 2012-13, including all of their associated achievement records for the
academic years preceding and during their respective Grade 12 enrollment.
Three data sets were supplied, all linkable via a depersonalized student identification
numbers. The first dataset comprised the Student Biographical File, with information on student
gender, year of birth, whether a diploma was issued (and if so, when), and an indicator for
students who were in Grade 12 for the first time. The second dataset was the Student Marks File,
with information on each course taken, the credit value for each course, and the final course
marks earned. The third file was the Student Application and Registration to Postsecondary
Education in Ontario File, with information on the number of postsecondary applications filed
each year and on any postsecondary registrations. “Registering” for a program means having
paid the college tuition fees for the program (usually due by mid-September) and not dropping
out by November 1st of the school year. For first-year students, being registered is very similar
to being enrolled, since “enrollment” is a count of every student still registered in a program on
November 1. We therefore use registered and enrolled outcomes interchangeably. The linked
file does not contain information on students who applied to colleges outside the province of
Ontario, though this number is likely small.
Unfortunately, we were unable to obtain reliable information regarding who applied for
financial aid.

The OSAP application does not systematically collect information about an

applicant's high school, nor does it require an applicant's Ontario Education Number, which

could have been used to link with our files. The Ministry of Training, Colleges, and Universities
tried to link their administrative data on OSAP recipients attending college with other data in
order to identify students from our program and control schools, but researchers concluded that
the match quality was too poor to be of use. Our main outcomes, therefore, are college program
applications college enrollment, but not financial aid applications.
The main econometric model for estimating average program effects is the following
randomized difference-in-differences model:

Yisc = δ s + δ c + βTsc + eisc

(1)

where Yisc is the outcome for student i, from school s, in the Grade 12 cohort c, and Tsc is an
indicator variable for whether LifeAfterHighSchool was administered at school s for cohort c
and eisc is the residual. For the 2011-12 cohort, since Tsc was randomly assigned, estimating
program effects by comparing differences in mean outcomes between program and control
schools that year generates unbiased results.

But with only 86 schools and school-level

heterogeneity, we can increase precision by conditioning on prior school-level differences using
school ( δ s ) and cohort ( δ c ) fixed effects, and by clustering standard errors at the school level.
Figure 2A displays this approach graphically. In the 2011-12 school year, the college
application rate among graduating seniors from control schools was 65.4 percent. For program
schools, the rate was 11.9 percentage points higher (77.3 percent). The standard error around
this difference using student-level data is 2.5 percentage points. In the two years prior to
LifeAfterHighSchool, application rates were slightly lower for program schools, though not by
much (64.8 versus 66.0 percent). Taking these lower rates into account using equation (1)

above, the estimated average program effect is an increase in application rates by 13.5
percentage points, with a standard error of 1.5 percentage points (a 40 percent decrease
compared to the standard error using only one cohort). A similar pattern arises when looking at
college enrollment rates in Figure 2B. The enrollment rate for graduating seniors in program
schools in the program year was 5.3 percentage points higher than that for seniors in control
schools (57.5 versus 52.2 percent with a standard error of 3.5 percentage points). Using equation
(1) instead, the standard error is smaller at 1.3 percentage points, and the estimated effect is an
increase in college enrollment by 5.0 percentage points.
Given the binary nature of our two main outcomes, we estimate equation (1) using a
probit model, and present implied discrete changes in the probability of applying or enrolling in
college due to receiving the program. Appendix Tables A3 and A4 present alternative estimates
(which are similar to our main ones) using only the program year (comparing mean outcome
differences), and using the randomized difference in differences approach but while also
including the following linear control variables: a dummy for having taken university-track
courses in high school interacted with high school grade average, number of credits earned at the
start of a student's last year of high school, total number of courses failed in high school, age
fixed effects, and dummy variables for gender, for taking university-track or workplace-track
courses in grade 11, for whether the student was ever in special education classes, for being an
immigrant, and for whether their mother tongue is neither French nor English.
We do not use subsequent cohorts as part of the estimating equation in case younger
students benefit from having older schoolmates go through the program. Interestingly, we do
not observe this impact: after the program ends in 2011-12, application and college enrollments

rates for the next cohort of graduating seniors in program schools drop back to previous levels,
similar to the observed rates for the next cohort of seniors in control schools.

V. Results

We begin by exploring whether LifeAfterHighSchool had any impact on high school
outcomes. For example, it is possible that the program increased interest or awareness in
postsecondary options, and led some seniors to strive for better grades, take different courses, or
adjust their graduation plans. Table 3 shows estimated program effects on high school outcomes
on all Grade 12 students using the randomized difference-in-differences approach outlined
previously. The first column indicates the mean of the outcome variable for Grade 12 seniors in
the control schools in 2011-12. The second column shows the estimated program effects, which
are generally zero and insignificant. LifeAfterHighSchool caused no discernible change to the
type of courses taken (e.g. university-track or college-track courses) or the number of courses
taken. This is not surprising given that most students picked their course schedule well before
the start of the first workshop. What is surprising is an estimated negative program effect on
average grades (5 percent of a standard deviation lower). It is not clear why the program would
have led to students performing worse. Given the 12 separate estimates in the table and the
unintuitive direction of the effect, we suspect this result is due to chance.
The program also had no noticeable impact on time to high school completion or
graduation outcomes. In the control group, the fraction of Grade 12 students that graduated by
the end of the school year was 62.9 percent, and nearly all of them exited high school (53.2

percent of all Grade 12s). Some stayed, along with other Grade 12s who did not satisfy enough
requirements to graduate (30.9 percent stayed overall). The program effects on graduation and
leaving high school are both estimated with small confidence bands around zero.
Table 4 shows the overall program effects of LifeAfterHighSchool on postsecondary
application and enrollment rates. For reference, Columns 1, 3, and 5 list these rates for the
control schools in the 2011-12 Grade 12 cohort. Among all Grade 12s, applications to any
college or university increased 13.9 percentage points, relative to the control application rate of
39.5 percent. Most of this increase came from applications to 2-year colleges (a 10.4 percentage
point increase compared to only a 3.6 percentage point increase in 4-year programs applications).
The program did not significantly change the small rate at which students applied to both college
and university application centers.

Turning

to

enrollment,

the

program

increased

postsecondary attendance the following year by 2.9 percentage points among all Grade 12
students (with a standard error of 0.8 percentage points).

As with the concentrated 2-year

college application effects, all of the enrollment effects come from increased enrollment at 2year community colleges (with no increase in 4-year university enrollment).
These effects, averaged over the entire Grade 12 sample, are diminished by the fact that
many students have not yet met graduation requirements, and stay in high school another year.
Thus, in Columns 3 and 4, we condition on the pre-program characteristic of beginning Grade 12
with at least 21 credits. Students in this category are far more likely to graduate after taking a
full course load than students with less than that amount. The overall college application rate
effect for this group is slightly higher than that for the full sample, at 19.1 percentage points. As
expected, enrollment effects is also higher, with an estimated increase in postsecondary

attendance of 4.4. percentage points. This increase occurs almost exclusively through changes in
community college enrollment.
Even for students that start the year with 21 credits, some fail courses and cannot
graduate. Some may take a smaller load and spread their remaining courses over two years.
And some may prefer to stay another year to take additional courses and increase their grade
averages. Motivated by these cases and the earlier finding that the program had no impact on
high school exit or graduation, the rest of our main results focus on the sample of students that
left school with a high school certificate, since only these students could apply and go to college
in the subsequent school year. 15 For these Grade 12 graduates, LifeAfterHighSchool increased
college applications by 13.6 percentage points (relative to the control group rate of 64.2 percent)
and college enrollment by 5.2 percentage points (relative to the control group rate of 53.0
percent).
Table 5 shows applications and enrollment effects for different subgroups of exiting
Grade 12 graduates.

By gender, it is interesting to note the much higher application and

enrollment rates for females over males –almost a 20 percentage point difference in both cases.
The program effects by gender, however, are similar. College enrollment increases by 5.4
percentage points for males and 4.4 percentage points for females. Effects split by urban and
rural high schools also lead to similar results: a 5.6 percentage point increase in enrollment at
urban schools and a 4.6 percentage point increase at rural, although the rural estimate is less
precisely estimated and significant only at the 10 percent level. 16

15

For sensitivity analysis, we also show the estimated program effects for the full sample and for students
beginning Grade 12 with at least 21 credits, because these students are more likely to have met the requirements
to graduate by the end of the year.
16
A rural high school is defined as a high school with zero as its 2nd alpha-numeric digit in its postal code, in line
with Canada Post's definition.

Ontario provides three types of courses in Grade 12 - university, college, and workplace –
which are catered to preparing students for these respective next destinations. University courses
are more academic and theoretical, while College and Workplace courses are more applied.
University programs in Ontario require at least some university-type course prerequisites. Most,
but not all, Grade 12 graduates taking university-type courses applied and went to postsecondary
the following year (83.0 and 70.3 percent respectively for the control group).

Still,

LifeAfterHighSchool raises application rates for these students by 7.9 percentage points, and
enrollment by 3.6 percentage points. Fewer students without university-type courses applied and
enrolled, but the program has a significantly larger impact on them. College application rates
increase from 40.9 to 64.4 percent, and enrollment increases from 31.8 to 40.9 percent (a 9
percentage point increase).

And for the small subset of students that take vocational-type

courses in Grade 12 (1,753 out of 38,352),significantly limiting their postsecondary program
options, LifeAfterHighSchool doubles relative application and enrollment rates (from 16.7 to
33.0 percent for application rates, and from 10.8 to 20.7 percent for enrollment).
Cut by grade average, LifeAfterHighSchool significantly affect three broad groups.
Those with low Grade 12 grade averages - lower than 60 percent - see increases to application
rates by 16 percentage points and enrollment rates by 5.8 percentage points. Those with grade
averages at least 75 percent experience application increases from 77.7 to 88.6 percent and
enrollment increases from 66.8 to 70.2 percent. The largest enrollment effects are for the group
in the middle - with grade averages between 60 and 75 percent. Their enrollment effect is 6.4
percentage points. 17

17

This is notably larger than the impacts found in a rigorous evaluation of a popular academic program for US high
schools that targets middle-achieving youth called AVID, that requires 3-4 years of weekly classroom time (Ford et
al 2014)

In summary, LifeAfterHighSchool was broadly influential in raising enrollment rates
across all different types of students at low-transition high schools. It was impressively effective
for students 'in the middle' - neither with above nor below-average grades, and neither taking
courses that put them on a university or workplace trajectory.

VI. Phase Two 18

LifeAfterHighSchool increased Grade 12 college application rates from about 65 to 80
percent. From an operational perspective, these results were initially disappointing, since the
goal of the program was to simplify the process to help virtually all exiting seniors to apply to
and get accepted into at least one program they helped choose, and to secure financial aid
packages. It is possible that the remaining 20 percent of students who did not apply never
would, regardless of how simple the process was. On the other hand, given the implementation
issues we experienced such as workshop absences and running out of time, perhaps we could
have done better in helping these students become more interested in postsecondary options.
To explore this and a number of additional efficiency issues, the Ontario Ministry of
Training, Colleges, and Universities supported our efforts to implement a second pilot two years
later, which we call Phase II. We changed the baseline design of LifeAfterHighSchool to use
wireless laptops, instead of school computer labs, so that we could better deliver the program in
classrooms that students were supposed to be in. 19 We also combined the first two workshops to
deliver them simultaneously to all Grade 12s over an entire morning in the Fall. This reduced
18
19

More operation and implementation details of Phase Two are provided in Ford et al. (2016b).
Internet access was undertaken via Wifeless Hub Hotspots provided to each school.

disruption and increased total workshop time by not having students transition between morning
classes. Students were given headphones to proceed through choosing programs, learning more
about financial aid, and applying at more of their own speed. Social media and other distracting
websites were blocked. Another feature of the Phase II program is that it relied on third-party
career planning software for helping students choose programs to apply. The 'Where Would You
Go?' component of the program in Phase I that provided a list of local college options based on
student grades and minimum requirements was deemed too expensive to redevelop, so instead
we directed students to software already available in schools. As discussed, below, this may
have altered the types of programs participants considered and applied for.
Phase II was also implemented to test four more variants of the program model for scaleup consideration. The first was 1) Baseline + 'Mop-up', in which paid facilitators returned to
schools after the workshops to offer additional individual or small-group help to the students
who had not completed their applications in class. This intervention was set up to explore how
much more application rates would increase from providing additional support outside the
workshops. The second was 2) Internal Staff + Fee Waivers, in which schools were provided
access to the program web site and fee-waiver system, but not external support was provided to
administer the program (including no laptops). This treatment arm was to explore whether
school staff could be used to implement LifeAfterHighSchool instead of paid external
facilitators. School staff were given instructions on how to implement the program, and were
left on their own to do so. The third was 3) Baseline But No Fee Waiver, in which students
received the full baseline program and external facilitator support, but were required to pay for
college applications with credit or debit cards, or to ask their parents to do so. Since the largest
cost item of the program was covering the approximate $100 fee per student, the Ontario

government wanted to test whether application rates would change if students received in-class
assistance but were left to pay on their own. Finally, the fourth was 4) Internal Staff with No Fee
Waiver, in which access to the LifeAfterHighSchool web site was made available but without fee
waivers, and school staff were required to implement the program.
These variant models were tested by returning to 66 of the 86 Phase I schools (a smaller
number for budget reasons).

Rather than re-randomizing program and control groups, the

original program schools were switched to control group status. We switched statuses (a) in
order to still operate in the lowest-transition schools; (b) in order to avoid asking Phase I schools
to implement modifications on the design they were used to (possibly asking them to no longer
receive outside assistance or allow for fee waivers), and (c) after observing application rates fall
back to control group levels between Phase I and Phase II (as displayed in Figure 2A). Statistical
power in Phase II is lower than Phase I because of the smaller number of total schools and the
smaller number of schools testing each variant (7 baseline schools, 4 in the Baseline + 'Mop-up'
model, 5 for Internal Staff + Fee Waivers, 3 for Baseline But No Fee Waiver, and 9 for Internal
Staff + No Fee Waiver).

We employ the same randomized difference in differences

methodology using additional data for the new treatment year (2013-14) and the two Grade 12
cohort years prior to Phase I treatment (2009-10 and 2010-11) to allow for school fixed effects.
Table 6 shows the different Phase II program effects on postsecondary applications for
Grade 12 graduates leaving high school. 20 The new baseline model met its goal of generating a
larger application rate increase than the Phase I treatment did (a 19.3 percentage point compared
to a 13.6 percentage point increase), although 16.0 percent of students still did not apply even
under the new approach of entire morning workshops with laptops. Under the ‘Baseline + ‘Mop20

Similar results for the sample of Grade 12 students beginning the year with at least 21 credits are shown in
Appendix Tables A5 and A6.

up’” model, when we provided facilitators to return to schools to offer additional assistance for
students who had not applied during workshops, application rates increased 20.7 percentage
points – only a marginal improvement to the estimated effect without 'Mop-up', and not a
statistically significant difference. Encouragingly, school staff in the 'Internal Staff + No Fee
Waivers' group were able to increase applications by as much or more than schools that were
provided facilitators and laptops. In particular, applications for students with no university-track
courses in Grade 12 increased by 38.7 percentage points - almost double - at schools with no
external help. All three of these models also generated similar increases in applications for
students taking university-track courses in Grade 12, and for students taking vocational courses.
But the Internal Staff + No Fee Waivers model did not fare as well. Offering application
assistance while still requiring students to pay the $100 fee had a zero, or even negative, impact
on application rates. Perhaps students felt that the task they were being encouraged to do should
have been free and became offended when they realized it was not. Or perhaps, after being
notified about the program, parents relied more on the school to get their children through the
process. The point estimates for college enrollment the following year at schools without fee
waivers (shown in Table 6) are correspondingly negative and, in some cases, significant at the 10
percent confidence level. Removing application fees appears to be an important necessary
condition for encouraging more students to apply.
Surprisingly, although Phase II models with fee waivers raised application rates more
than Phase I effects, college enrollment effects were mostly not significantly different from zero.
Table 7 shows these effects for the different Phase II treatment arms for Grade 12 graduates and
other subgroups. The baseline estimated effect was -.036 with a standard error of 0.025. The
Baseline + 'Mop-up' effect was exactly zero with a standard error of 0.03, and the estimate for

the model with Internal staff + Fee waivers was 0.031 with a standard error of 0.37. The
combined sample generates an estimated effect within a 95 percent confidence interval of -4.1 to
2.6 percentage points. The only positively significant impact came from the schools with
internal staff running the program and with fee waivers provided: for these schools, the main
sample effect and the effect on students with no university-track courses (an 8.1 percentage point
increase) were closest in line with the program effect estimates in Phase I.
The larger college application effects in Phase II juxtaposed against the smaller
enrollment effects raises the interesting question, 'why the difference?'. One possibility is that
the program effects are actually equal for all versions of LifeAfterHighSchool with fee waivers,
and that we can obtain a more precise estimate by combining the two samples. Assuming this,
the program effect is a 2.3 percentage point increase in enrollment, with a standard error of 1.0
percentage points. However, we easily reject equal effects (0.044 (se=0.013) for Phase I, -0.007
(se=0.019) for Phase II), especially for the sample of students with no university-track courses
(0.086 (se=0.016) for Phase I, -0.011 (se=0.020) for Phase II). Another possibility is that
economic conditions changed between the two treatment years, and students in Phase II were
less interested in going to college. This also seems unlikely, since the province's unemployment
rate fell only by .6 percentage points between the two years. 21
A more plausible reason is that although Phase II further increased application rates, it
may also have inadvertently affected the types of programs where students applied. One key
difference between the two phases was the tool used for helping students choose where they
might go. In Phase I, we asked students their grades and developed software to display a
comprehensive list of local programs for which students would likely be accepted; in contrast, in
Phase II we relied on external software that required students to sift through programs based on
21

From Statistics Canada's Labour Force Survey: 7.9 percent in 2012 and 7.3 percent in 2014.

their career interests. To explore whether this made a difference to where students applied, we
make use of available data separating 2- and 4-year colleges (we do not have data on program of
study). Table 8 shows estimated effects for Phase I and Phase II designs (that included fee
waivers), separated by whether students took university-level or vocational courses in Grade 12
and whether effects are for 2- or 4-year programs. Among students taking no university-level
courses, the entire application impact was on 2-year colleges and not 4-year colleges. The higher
application rate increase in Phase II also led to a proportional increase in 2-year applications.
The same happened for students with only vocational courses - all of the increase in overall
application rates was driven by increases in 2-year college applications, which is reassuring since
these students were unlikely to be accepted to any university programs.
In contrast, Phase I and Phase II application effects differ for students with universitylevel courses. In Phase I, both 2- and 4-year college applications increased for students with
university-level courses (by 3.7 and 6.7 percentage points respectively), but in Phase II, only
applications to 4-year colleges increased significantly (by 14.2 percentage points). We also
observe a significant decrease in 2-year college enrollment for these students [-0.049 (se=0.018)]
and an offsetting increase in 4-year enrollment [0.036 (se=0.027)]. The greater emphasis Phase
II appears to have placed on 4-year colleges may have led students to submit applications to
programs that were subsequently rejected from, or to programs from which they received offers
and declined.
We do not have information on application rejections at the 4-year postsecondary level,
but we do at the 2-year level from the Ontario College Application Service (OCAS). Table 9
shows estimated Phase I and II program effects for the total number of students in a school who
applied to a 2-year college, applied and received at least one offer, applied and received no

offers, and applied and accepted one offer. In Panel A, the outcome (at the school-year level) is
regressed on a treatment dummy, along with cohort and program school fixed effects, weighted
by Grade 12 school size. For Phase I, the cohorts are 2009/10, 2010/11, and 2011/12 (the year of
treatment). For Phase II, the cohort years are 2009/10, 2010/11, and 2013/14 (the year treated).
In Panel B, the outcome variables are divided by Grade 12 school size (the number of Grade 12s
in each school, calculated from Ministry of Education data) to convert the estimated effects into
percentage point changes.
LifeAfterHighSchool in Phase I, on average, increased applications to 2-year colleges by
35 students per school, and following-year college enrollment by 15 students per school. This
translates to an estimated increase in applications by 9 percentage points and in enrollment by
3.4 percentage points, which is very similar to the results reported in Table 4 (which used
Ministry of Education Data). Importantly, Phase I did not significantly affect the number of
students applying and receiving no offers. In contrast, although we estimate that Phase II
increased the fraction of college applications by more than in Phase I, some of these additional
applications were rejected. On average, Phase II increased the number of students who applied
but received no offers by 11 per school, or 3.3 percentage points.
In short, relatively small changes in implementation of LifeAfterHighSchool successfully
increased college application rates even further, but may also have altered the types of programs
participants considered and applied for. Supporting evidence includes the finding that, for Phase
II university-track students, application effects were driven only by increases in 4-year college
applications, whereas we saw no subsequent enrollment effects in Phase I or II. For nonuniversity track students, more students applied due to exposure to the Phase II over Phase I
program, but some of these additional applicants were rejected. Guidance in choosing programs

that will accept students, along with application fee waivers, therefore appear to be important
prerequisites for successfully helping with the college transition.

VII. Conclusion

This paper presents results from a school-level randomized trial evaluating a new
program that incorporates college application assistance directly into the high school classroom
activities. Students at low-transition schools are encouraged to keep options open by going
through the actual application process. Those who do may realize a variety of programs of
interest exist that they were not initially aware of, or become more informed about college costs
and opportunities. Over three classes, students were guided to choose college programs they
would likely be eligible for, shown a basic college budget and financial aid calculator, given help
applying without having to pay the fee, and introduced to the financial aid application (with
follow-up requests sent to parents). Among all Grade 12 graduates, the program increased
program application rates by 13 percentage points, and college enrollment rates by about 5
percentage points. Impacts were concentrated among those not already taking university-track
courses.
These results are quite comparable to those of studies examining other ways to simplify
the college transition. In the FAFSA study by Bettinger et al. (2012), low-income parents who
went to H&R Block received assistance in completing their Grade 12 child's financial aid
application, and were provided information about local colleges. Application rates and college
enrollment increased by 15 and 8 percentage points, respectively. Another study by Carrell and

Sacerdote (2013) involved counselors identifying particular Grade 12 students as possible

beneficiaries from receiving individual support with undergraduate students to help and
encourage them through all application steps, along with application fee waivers. Program
applications increased 29 percentage points and college enrollment 5 percentage points.
Castleman and Page (2015) examined sending text reminders and offering phone-support for

getting through remaining college transition tasks over the summer. Fall enrollment rates for
recent high school graduates who had at least started the FAFSA increased, on average, by 3
percentage points. A related study by Hoxby and Turner (2013) looked at helping disadvantaged
students with high SAT scores transition to more selective schools. Mailing these Grade 12
students suggestions for selective schools they were likely to be accepted into, along with fee
waiver vouchers, increased the number of applications sent and the enrollment rate at more
selective colleges by 5 percentage points.
Collectively, these studies clearly demonstrate that complexity and lack of support in the
college transition process affect whether some individuals enroll or not. It remains to be seen
whether those affected by simplifying the transition benefit. We cannot tell for sure at the
individual level or even the average level since no experiment has yet looked at longer-term
outcomes like arnings. But the finding that low-cost assistance matters suggests for some

students enrollment decisions do not represent well-thought-out investments decisions.
Reviews of existing research on returns to higher education suggests high rates of return to

college, even for marginal students (Oreopoulos and Peteronjevic, 2013, Hout, 2012,

Barrow and Malamud, 2015). 22 The FAFSA study also shows students than enrolled in
22

http://www.annualreviews.org/doi/full/10.1146/annurev.soc.012809.102503,
http://www.annualreviews.org/doi/abs/10.1146/annurev-economics-080614-115510

college because of the program persisted into second year and had to navigate subsequent
financial aid and registration requirements on their own.

To maintain even an option of going to college when exiting high school, students must

get through the application process. How best to help students do so depends on context and
feasibility.

Some changes, like sending text reminders, are relatively straightforward to

introduce without significant disruption to the process' existing framework. Other changes, like
using parental income information from tax files instead of asking for it on applications, require
reinvention and even new legislation. Small details matter as well: our inability to assist some
students in opening a financial aid application because they did not have on hand their Social
Insurance Number is but one example; not being able to assist all Grade 12s in class at the same
time is another.

We also learned that waiving application fees is an important necessary

condition for making in-class assistance worthwhile, as students were not willing to respond to
in-class support if required to pay to submit an application. Clearly the effectiveness of a
program in simplifying the application process depends on addressing multiple potential
bottlenecks simultaneously.
Personalization matters too, as we learned from implementing LifeAfterHighSchool a
second time. Completing the financial aid application only involves answering factual questions,
but completing the program application involves considering what programs will accept and
interest students. The degree of personal assistance in helping students find suitable programs to
apply seems to make a large difference for actual enrollment outcomes. Students given a
succinct set of program options that would accept them if they applied were much more likely to
later enroll than those left to consider minimum requirements on their own. Other personalized

variants of the program, such as adding follow-up text reminders, may also be useful and could
be evaluated based on cost-effectiveness, operational feasibility, and experience.
For

schools

that

wish

to

offer

in-class

college

transition

assistance,

the

LifeAfterHighSchool experiments suggest two starting points. Firstly, waiving application fees
for at least the first 3 applications can be very helpful and encouraging for students, especially
those in low-transition schools. Secondly, a simple 'one-stop' website that guides students and
parents through each step (including identifying best program matches, and help with the
financial aid process) can be helpful in simplifying and de-mystifying the application process.
These two changes could enable high schools to incorporate effective application assistance
during class time, and help students keep the “college option” open.

References
Advisory Committee on Student Financial Assistance. (2005). The Student Aid Gauntlet: Making
Access to College Simple and Certain: Final Report of the Special Study of Simplification of
Need Analysis and Application for Title IV Aid. Advisory Committee on Student Financial
Assistance, Washington, DC.
Barrow, L., & Malamud, O. (2015). Is College a Worthwhile Investment? Annual Review of
Economics, 7(1), 519-555.
Beshears, J., Choi, J. J., Laibson, D., & Madrian, B. C. (2013). Simplification and
saving. Journal of Economic Behavior & Organization, 95, 130-145.
Bettinger, E. P., Long, B. T., Oreopoulos, P., & Sanbonmatsu, L. (2012). The role of application
assistance and information in college decisions: Results from the H&R block FAFSA
experiment. The Quarterly Journal of Economics, 127(3), 1205-1242.
Carrell, S. E., & Sacerdote, B. (2013). Late interventions matter too: The case of college
coaching New Hampshire (No. w19031). Cambridge, MA: National Bureau of Economic
Research.
Carroll, Gabriel D., James J. Choi, David Laibson, Brigitte C. Madrian, and Andrew Metrick.
2009. “Optimal Defaults and Active Decisions.” The Quarterly Journal of Economics, 124 (4):
1639–1674.
Castleman, B. L., & Page, L. C. (2015). Summer nudging: Can personalized text messages and
peer mentor outreach increase college going among low-income high school graduates?. Journal
of Economic Behavior & Organization, 115, 144-160.
Chetty, R., Friedman, J. N., Leth-Petersen, S., Nielsen, T., & Olsen, T. (2014). Active vs. passive
decisions and crowdout in retirement savings accounts: Evidence from Denmark. The Quarterly
Journal of Economics, 129(3), 1141-1219.
Frederick, S., Loewenstein, G., & O'donoghue, T. (2002). Time discounting and time preference:
A critical review. Journal of Economic Literature, 40(2), 351-401.
Hout, M. (2012). Social and economic returns to college education in the United States. Annual
Review of Sociology, 38, 379-400.
Hoxby, C., & Turner, S. (2013). Expanding college opportunities for high-achieving, low income
students. Stanford Institute for Economic Policy Research Discussion Paper, (12-014).
Kable, J. W., & Glimcher, P. W. (2007). The neural correlates of subjective value during
intertemporal choice. Nature neuroscience, 10(12), 1625-1633.

Kable, J. W., & Glimcher, P. W. (2010). An “as soon as possible” effect in human intertemporal
decision
making:
behavioral
evidence
and
neural
mechanisms. Journal
of
Neurophysiology, 103(5), 2513-2531.
Lavecchia, A. M., Liu, H., & Oreopoulos, P. (2014). Behavioral economics of education:
Progress and possibilities (No. w20609). National Bureau of Economic Research.
McClure, S. M., Laibson, D. I., Loewenstein, G., & Cohen, J. D. (2004). Separate neural systems
value immediate and delayed monetary rewards. Science, 306(5695), 503-507.
Oreopoulos, P., & Dunn, R. (2013). Information and College Access: Evidence from a
Randomized Field Experiment. The Scandinavian Journal of Economics, 115(1), 3-26.
Oreopoulos, P., & Petronijevic, U. (2013). Making college worth it: A review of the returns to
higher education. The Future of Children, 23(1), 41-65.
Reuben, E., Sapienza, P., & Zingales, L. (2014). How stereotypes impair women’s careers in
science. Proceedings of the National Academy of Sciences, 111(12), 4403-4408.
Rosenberg, T. (2016, April 26). Guiding a first generation to college. The New York Times.
Retrieved from http://opinionator.blogs.nytimes.com/2016/04/26/guiding-a-first-generation-tocollege/?_r=0
Stanovich, K. E., West, R. F., & Toplak, M. E. (2012). Judgment and decision making in
adolescence: Separating intelligence from rationality. American Psychological Association, xviii,
337-378.
Statistics Canada. No date. Labour force characteristics (table). Summary Tables. Last updated
http://www.statcan.gc.ca/tables-tableaux/sumJanuary
8,
2016.
Retrieved
from
som/l01/cst01/econ10-eng.htm
U.S. Bureau of Labor Statistics. (2016, April 28). College enrollment and work activity of high
school graduates. Retrieved from http://www.bls.gov/bls/newsrels.htm

Table 1
Descriptive Statistics for Program and Control Schools
2010-11 (one year before program was introduced)
All Grade 12 Students

Graduating Grade 12 Students

Control School
Mean

Program School
Difference

Control School
Mean

Program School
Difference

Grade 12 Grade Average

64.664

-0.238
[1.464]

72.745

0.951
[0.790]

Taking University-Track Courses

0.459

-0.016
[0.037]

0.577

0.016
[0.034]

At least 21 credits at start of Grade 12

0.57

-0.027
[0.041]

0.766

-0.007
[0.030]

Fraction Female

0.458

0.011
[0.010]

0.501

0.01
[0.012]

Age

18.885

-0.098
[0.280]

18.635

-0.09
[0.093]

Home Language Not English

0.08

-0.001
[0.036]

0.069

0
[0.030]

Received High School Certificate

0.636

-0.041
[0.031]

1

Took Additional Years of High School

0.318

0.018
[0.018]

0

Graduated and Left High School

0.524

-0.035
[0.027]

1

Applied to Postsecondary Program

0.389

-0.025
[0.026]

0.658

-0.006
[0.026]

Applied to College Program

0.223

-0.022
[0.016]

0.376

-0.023
[0.020]

Applied to University Program

0.194

-0.007
[0.022]

0.33

0.012
[0.033]

Enrolled in Postsecondary Program

0.295

-0.022
[0.022]

0.545

-0.007
[0.025]

Enrolled in College Program

0.159

-0.019
[0.013]

0.29

-0.02
[0.018]

Enrolled in University Program

0.136

-0.003
[0.016]

0.255

0.014
[0.028]

Number of Grade 12 Students

380.969

-35.387
[35.525]

203.709

-24.917
[21.290]

43

43

43

43

Number of Schools

Notes: Data are from Ontario Ministry of Education student records linked, aggregated at the school level for LifeAfterHighSchool
treated and control schools. The first two columns show control means, weighted by school size, and program differences for the
sample of all students with at least 4 years of high school. The last two columns show control means and program differences for
the sample of students that exited high school by the following year with a high school degree. Standard errors for the difference
between program and control school means are shown in square brackets (none of which are statistically significant at the 10
percent level or less).

Table 2
Online Workshop Activity at Program Schools
Fraction of All
Grade 12 Students

A. Ministry of Education Data

Fraction of Online
Account Holders

Total Grade 12 Students at Program Schools
Beginning with at least 21 credits
Graduated and left immediately following school year

11356
6336
6950

0.558
0.612

Applied to college
Applied to university
Applied to any postsecondary program

3499
2640
5749

0.308
0.232
0.506

Workshop 1 Activities
Registered account
Entered previous courses taken and grades
Identified at least one favorite program
Identified fav. program and tried aid calculator

7436
6500
4807
3457

0.655
0.572
0.423
0.304

1.000
0.874
0.646
0.465

Workshop 2 Activities
Applied to college
Applied to university
Applied to any postsecondary program

2869
2670
5539

0.253
0.235
0.488

0.386
0.359
0.745

Workshop 3 Activities
Entered application Number for Storage
Follow-up email sent to parent

940
573

0.083
0.050

0.126
0.077

B. Website Data

Notes: Panel A reports student counts from Ministry of Education student records for program schools in the year of
being treated. Panel B reports counts of students registered on the LifeAfterHighSchool website and recorded activity
on that website in relation to the program's three workshops. See text for more details.

Table 3
Estimated Program Effect on Average High School Outcomes for All Grade 12 Students
Control School
Mean in
2011/12

Treated School
Mean Difference
[standard error]

4.9
(sd=3.37)

-0.043
[0.068]

Taking Gr12 college or university-track courses

0.503

-0.016
[0.013]

Taking Gr12 university-track English

0.294

-0.004
[0.009]

Taking Gr12 college-track English

0.324

0.011
[0.009]

Taking Gr12 university-track math

0.323

-0.006
[0.008]

Taking Gr12 college-track math

0.169

0.004
[0.009]

Taking Any Gr12 science course

0.418

0.005
[0.008]

70% or more in Gr12 science course

0.276

0.005
[0.007]

64.7
(sd=20.6)

-1.079
[0.448]**

Graduated and left immediately following school year

0.629

-0.012
[0.012]

Took additional high school

0.309

-0.006
[0.010]

Left school with high school certificate

0.532

0.004
[0.011]

Gr12 Course Credits Earned

Average Gr12 grade

Notes: Data are from Ontario Ministry of Education student records. The sample of 75,032
students includes all students with at least 4 years of high school at program and control schools
in 2009/10, 2010/11 and 2011/12 (the year treated). The control mean reported is for the
2011/12 year. The effects are estimated from a probit model of the outcome variable regressed
on a treatment dummy, along with fixed effects for cohort year and school. Marginal effects at
mean values are reported. Standard errors are clustered by school and shown in square brackets.
sd = standard deviation. *, **, and *** indicate statistical significance at the 10, 5, and 1 percent
levels respectively.

Table 4
Estimated Program Effect on the Probability a Student Applied to or Enrolled in a Postsecondary Program
All Grade 12 Students

Students Beginning Grade 12
With >=21 Credits

Grade 12 Graduates

Control
Mean

Program
Difference

Control
Mean

Program
Difference

Control
Mean

Program
Difference

Applied to College or University

0.395

0.139
[0.013]***

0.561

0.191
[0.016]***

0.642

0.136
[0.014]***

Applied to College

0.227

0.104
[0.011]***

0.303

0.137
[0.014]***

0.365

0.125
[0.013]***

0.2

0.036
[0.008]***

0.304

0.063
[0.011]***

0.319

0.023
[0.013]*

Applied to College and University

0.321

0.004
[0.003]

0.047

0.006
[0.005]

0.048

0.007
[0.006]

Enrolled in College or University

0.301

0.029
[0.008]***

0.443

0.044
[0.013]***

0.53

0.052
[0.013]***

Enrolled in College

0.166

0.029
[0.006]***

0.231

0.038
[0.010]***

0.284

0.05
[0.010]***

Enrolled in University

0.136

0
[0.006]

0.213

0.007
[0.008]

0.238

0.002
[0.012]

Applied to University

Total Sample Size

75,030

41,645

38,130

Notes: Data are from Ontario Ministry of Education student records. The sample includes students with at least 4 years of high school at
program and control schools in 2009/10, 2010/11 and 2011/12 (the year treated). The control mean reported is for the 2011/12 year. The
increase in probability of applying or enrolling from exposure to the program is estimated from a probit model of the outcome variable
regressed on a treatment dummy, along with fixed effects for cohort year and school. Marginal effects at mean values are reported.
Standard errors are clustered by school and shown in square brackets. *, **, and *** indicate statistical significance at the 10, 5, and 1
percent levels respectively.

Table 5
Estimated Program Effect on Grade 12 Graduates by Subgroup
Sample
Size

Applied to Postsecondary
Program

Enrolled in Postsecondary
Program

Control
Mean

Program
Difference

Control
Mean

Program
Difference

Males

0.568

0.145
[0.022]***

0.463

0.054
[0.018]***

18,978

Females

0.743

0.122
[0.012]***

0.624

0.044
[0.017]***

19,374

Urban Schools

0.65

0.135
[0.015]***

0.539

0.05
[0.015]***

32,832

Rural Schools

0.668

0.135
[0.024]***

0.553

0.046
[0.025]*

5,520

Taking At Least One Gr12
University Track Course

0.83

0.079
[0.010]***

0.703

0.036
[0.014]**

22,226

Taking No Gr12
University Track Course

0.409

0.235
[0.020]***

0.318

0.091
[0.017]***

16,126

Taking Gr12 Vocational
Math or English

0.167

0.33
[0.069]***

0.108

0.099
[0.051]*

1,753

Taking No Gr12
Vocational Math or English

0.681

0.129
[0.013]***

0.566

0.05
[0.013]***

36,599

Grade Average<60%

0.413

0.166
[0.034]***

0.3

0.058
[0.026]**

5,150

Grade Average Btw. 60-75%

0.598

0.156
[0.018]***

0.483

0.064
[0.018]***

16,777

Grade Average>=75%

0.777

0.109
[0.010]***

0.668

0.044
[0.017]***

16,425

Notes: Same as in Table 4.

Table 6
Phase II Program Effects on Postsecondary Application Rates for Grade 12 Graduates

Program Design

No G12
Full Sample
Univ. Track Courses
(control mean = 0.627) (control mean = 0.401)

Took At Least 1
G12 Univ. Course
(control mean = 0.762)

Took At Least 1
Vocational Course
(control mean = 0.212)

Baseline

0.193
[0.024]***

0.288
[0.033]***

0.132
[0.019]***

0.282
[0.085]***

Baseline +
"Mop-up"

0.207
[0.023]***

0.294
[0.052]***

0.135
[0.010]***

0.475
[0.112]***

Internal Staff +
Fee waivers

0.236
[0.093]**

0.387
[0.111]***

0.145
[0.063]**

0.207
[0.217]

Baseline with
No fee waiver

-0.041
[0.050]

-0.137
[0.038]***

0.021
[0.021]

-0.033
[0.042]

Internal Staff with
No fee waiver

-0.038
[0.026]

-0.018
[0.045]

-0.046
[0.026]*

-0.003
[0.049]

All schools with
Fee waivers

0.204
[0.022]***

0.301
[0.031]***

0.136
[0.017]***

0.319
[0.078]***

All schools with
No fee waiver

-0.039
[0.025]

-0.055
[0.040]

-0.03
[0.024]

-0.016
[0.040]

Sample Size for All
Schools with Fee waivers

26,330

10,598

15,732

1,747

Notes: Data are from Ontario Ministry of Education student records. The sample includes students with at least 4
years of high school at program and control schools in 2009/10, 2010/11 and 2013/14 (the year Phase II was
implemented). The control mean reported is for the 2013/14 year. The increase in probability of applying from
exposure to the program is estimated from a probit model of the outcome variable regressed on a treatment
dummy, along with fixed effects for cohort year and school. Marginal effects at mean values are reported.
Standard errors are clustered by school and shown in square brackets. *, **, and *** indicate statistical significance
at the 10, 5, and 1 percent levels respectively.

Table 7
Phase II Program Effects on Postsecondary Enrollment Rates for Grade 12 Graduates
Full Sample
(control mean = 0.488)

No G12
Univ. Track Courses
(control mean = 0.297)

Took At Least 1
G12 Univ. Course
(control mean = 0.602)

Took At Least 1
Vocational Course
(control mean = 0.130)

Baseline

-0.036
[0.025]

-0.01
[0.029]

-0.032
[0.032]

0.017
[0.039]

Baseline +
"Mop-up"

0
[0.030]

-0.026
[0.028]

0.013
[0.031]

0.045
[0.068]

Internal Staff +
Fee waivers

0.031
[0.037]

0.081
[0.035]**

0.02
[0.047]

0.01
[0.034]

Baseline with
No fee waiver

-0.027
[0.042]

-0.085
[0.051]*

-0.015
[0.016]

0.02
[0.074]

Internal Staff with
No fee waiver

-0.042
[0.026]

-0.04
[0.039]

-0.034
[0.030]

-0.057
[0.030]*

All schools with
Fee waivers

-0.015
[0.021]

-0.007
[0.022]

-0.008
[0.025]

0.023
[0.036]

All schools with
No fee waiver

-0.038
[0.023]*

-0.054
[0.033]

-0.03
[0.025]

-0.032
[0.034]

26,330

10,598

15,732

1,721

Program Design

Sample Size for All
Schools with Fee waivers

Notes: Data are from Ontario Ministry of Education student records. The sample includes students with at least 4
years of high school at program and control schools in 2009/10, 2010/11 and 2013/14 (the year Phase II was
implemented). The control mean reported is for the 2013/14 year. The increase in probability of enrolling from
exposure to the program is estimated from a probit model of the outcome variable regressed on a treatment dummy,
along with fixed effects for cohort year and school. Marginal effects at mean values are reported. Standard errors are
clustered by school and shown in square brackets. *, **, and *** indicate statistical significance at the 10, 5, and 1
percent respectively.

Table 8
Phase I and Phase II Effects on Applications and Enrollment
Same Sample of Schools (with fee waivers), Same Time Frame
No University Courses
Phase I
Phase II
with fee waivers

University Courses
Phase I
Phase II
with fee waivers

Vocational Courses
Phase I
Phase II
with fee waivers

Applied to Any College

0.225
[0.021]***

0.28
[0.029]***

0.089
[0.013]***

0.151
[0.020]***

0.217
[0.041]***

0.351
[0.065]***

Applied to 2-year

0.224
[0.021]***

0.28
[0.029]***

0.037
[0.015]**

0.026
[0.021]

0.226
[0.039]***

0.326
[0.073]***

Applied to 4-year

0.001
[0.002]

0
[0.002]

0.067
[0.017]***

0.142
[0.028]***

-0.008
[0.007]

0.023
[0.014]

Enrolled in Any College

0.077
[0.018]***

-0.016
[0.023]

0.042
[0.017]**

-0.014
[0.027]

0.056
[0.032]*

0.025
[0.037]

Enrolled in 2-year

0.077
[0.018]***

-0.015
[0.023]

0.017
[0.014]

-0.049
[0.018]**

0.063
[0.031]**

0.013
[0.037]

Enrolled in 4-year

0.001
[0.000]

-0.001
[0.001]*

0.025
[0.016]

0.036
[0.027]

-0.007
[0.005]

0.011
[0.007]*

Sample Size

12,926

10,206

17,583

15,014

2,212

1,657

Notes: Data are from Ontario Ministry of Education student records. The sample includes students with at least 4 years of high school at program and
control schools in 2009/10, 2010/11 and 2011/12 for Phase I (with the program introduced in 2011/12) and 2009/10, 2010/11 and 2013/14 for Phase II
(when the program was introduced in 2013/14). Columns 1-2 show results for students that had not taken any university track courses, columns 3-4 show
the opposite. Columns 5-6 show results for students taking at least some workplace/vocational courses. The increase in probability of applying or
enrolling from exposure to the program is estimated from a probit model of the outcome variable regressed on a treatment dummy, along with fixed
effects for cohort year and school. Marginal effects at mean values are reported. Standard errors are clustered by school and shown in square brackets. *,
**, and *** indicate statistical significance at the 10, 5, and 1 percent levels respectively.

Table 9
Phase I and Phase II Effects on 2-year Applications and Enrollment Counts
Same Sample of Schools (with fee waivers), Same Time Frame
2-year College Application Data
Phase I

Phase II
with fee waivers

Applied to
2-year College

35.29
[6.175]***

33.332
[10.675]***

Applied and
received offer

36.321
[6.165]***

22.07
[10.546]**

1.031
[3.644]

11.262
[5.736]*

14.664
[4.557]***

-3.738
[6.895]

Fraction
Applied

0.091
[0.015]***

0.138
[0.028]***

Frac. Applied and
received offer

0.09
[0.012]***

0.105
[0.026]***

Frac. Applied and
received no offer

0.001
[0.008]

0.033
[0.014]**

Frac. Applied and
Accpeted

0.034
[0.009]***

0.008
[0.017]

172

100

Panel A

Applied and
received no offer
Applied and
Accepted
Panel B

School Sample Size

Notes: Data are from the Ontario College Application Centre, at the school level. In
Panel A, the outcome variable is regressed on a treatment dummy, along with
cohort and program school fixed effects, weighted by Grade 12 school size. For
Phase I schools the cohorts are 2009/10, 2010/11, and 2011/12 (the year of
treatment). For Phase II schools the cohort years are 2009/10, 2010/11, and
2013/14 (the year treated). In Panel B the outcome variable is divided by the
fraction of Grade 12 Graduates in that school, calcuated from Ministry of Education
data. Standard errors are in square brackets, clustered by school. *, **, and ***
indicate statistical significance at the 10, 5, and 1 percent levels respectively.

Appendix Table A1
Estimated Program Effect on All Grade 12 Students by Subgroup
Applied to Postsecondary
Program

Enrolled in Postsecondary
Program

Control
Mean

Program
Difference

Control
Mean

Program
Difference

Males

0.323

0.139
[0.016]***

0.239

0.026
[0.010]***

33,699

Females

0.481

0.133
[0.016]***

0.376

0.03
[0.013]**

40,107

Urban Schools

0.382

0.136
[0.014]***

0.29

0.028
[0.008]***

65,540

Rural Schools

0.441

0.147
[0.017]***

0.343

-0.003
[0.014]

9,490

Taking At Least One Gr12
University Track Course

0.623

0.157
[0.016]***

0.483

0.034
[0.014]**

33,699

Taking No Grade 12
University Track Course

0.194

0.139
[0.014]***

0.141

0.038
[0.007]***

41,331

Taking Gr12 Vocational
Math or English

0.102

0.185
[0.044]***

0.051

0.032
[0.019]*

4,061

Taking No Grade 12
Vocational Math or English

0.4116

0.138
[0.013]***

0.3001

0.03
[0.008]***

70,969

Grade Average<60%

0.137

0.074
[0.014]***

0.083

0.015
[0.007]**

22,528

Grade Average Btw. 60-75%

0.419

0.183
[0.019]***

0.309

0.047
[0.011]***

28,319

Grade Average>=75%

0.575

0.175
[0.016]***

0.467

0.046
[0.017]***

24,183

Sample
Size

Notes: Same as in Table 4. The only difference in setup for this table compared to Table 5 is the sample population of all
students with at least 4 years of high school, instead of the subset of all existing students with a high school degree.

Appendix Table A2
Estimated Program Effect on Grade 12 Students Beginning with At Least 21 Credits by Subgroup
Applied to Postsecondary
Program

Enrolled in Postsecondary
Program

Sample
Size

Control
Mean

Program
Difference

Control
Mean

Program
Difference

Males

0.476

0.2
[0.022]***

0.367

0.042
[0.017]**

21132

Females

0.652

0.178
[0.016]***

0.525

0.044
[0.018]**

20513

Urban Schools

0.559

0.187
[0.017]***

0.44

0.04
[0.014]***

35407

Rural Schools

0.567

0.208
[0.013]***

0.452

0.047
[0.023]**

6,238

Taking At Least One Gr12
University Track Course

0.371

0.165
[0.016]***

0.535

0.031
[0.015]**

27,344

Taking No Gr12
University Track Course

0.362

0.26
[0.022]***

0.279

0.084
[0.016]***

15,375

Taking Gr12 Vocational
Math or English

0.12

0.339
[0.090]***

0.082

0.062
[0.044]

1,624

Taking No Gr12
Vocational Math or English

0.581

0.186
[0.015]***

0.46

0.043
[0.013]***

41,095

Grade Average<60%

0.27

0.225
[0.046]***

0.183

0.051
[0.032]

3,951

Grade Average Btw. 60-75%

0.49

0.206
[0.021]***

0.372

0.051
[0.015]***

20,205

Grade Average>=75%

0.692

0.173
[0.015]***

0.569

0.043
[0.018]**

18,563

Notes: Same as in Table 4. The only difference in setup for this table compared to Table 5 is the sample population of all
students with at least 4 years of high school starting the year with at least 21 credits, instead of the subset of all existing
students with a high school degree.

Appendix Table A3
Estimated Program Effects on Grade 12 Graduates with Added Individual Control Variables
Applied to Postsecondary
Program

Enrolled in Postsecondary
Program

Sample
Size

Control
Mean

Program
Difference

Control
Mean

Program
Difference

Full Sample

0.654

0.155
[0.012]***

0.549

0.063
[0.012]***

38,352

Males

0.568

0.181
[0.021]***

0.463

0.073
[0.016]***

18,978

Females

0.743

0.126
[0.011]***

0.624

0.051
[0.016]***

19,374

Urban Schools

0.65

0.156
[0.014]***

0.539

0.063
[0.013]***

32,832

Rural Schools

0.668

0.159
[0.021]***

0.553

0.07
[0.036]*

5,520

Taking At Least One Gr12
University Track Course

0.83

0.077
[0.009]***

0.703

0.038
[0.014]***

22,226

Taking No Gr12
University Track Course

0.409

0.242
[0.021]***

0.318

0.085
[0.016]***

16,126

Taking Gr12 Vocational
Math or English

0.167

0.377
[0.068]***

0.108

0.112
[0.047]**

1,753

Taking No Gr12
Vocational Math or English

0.681

0.144
[0.012]***

0.566

0.06
[0.012]***

36,599

Grade Average<60%

0.413

0.188
[0.034]***

0.3

0.067
[0.029]**

5,150

Grade Average Btw. 60-75%

0.598

0.179
[0.019]***

0.483

0.077
[0.017]***

16,777

Grade Average>=75%

0.777

0.103
[0.009]***

0.668

0.041
[0.016]**

16,425

Notes: Same as in Table 4. The only difference in setup for this table compared to Table 5 is that the regression also
includes the following conditional variables: : a dummy for having taken university-track courses in high school interacted
with high school grade average, number of credits earned at the start of a student's last year of high school, total number
of courses failed in high school, age fixed effects, and dummy variables for gender, for taking university-track or
workplace-track courses in grade 11, for whether the student was ever in special education classes, for being an
immigrant, and for whether their mother tongue is neither French nor English.

Appendix Table A4
Estimated Program Effect Using Program Year Only (2011-12)
All Grade 12 Sample Versus Graduate Only Sample, With and Without Individual Controls
All Grade 12
Students

Grade 12
Graduates

Grade 12
Graduates

No Controls

No Controls

With Controls

Full Sample

0.01
[0.024]

0.035
[0.024]

0.036
[0.015]**

Males

0.015
[0.021]

0.045
[0.027]

0.048
[0.018]***

Females

0
[0.030]

0.02
[0.023]

0.024
[0.016]

Urban Schools

0.021
[0.027]

0.039
[0.027]

0.04
[0.016]**

Rural Schools

-0.04
[0.041]

0.005
[0.041]

0.023
[0.023]

Taking At Least One Gr12
University Track Course

0.019
[0.024]

0.022
[0.019]

0.021
[0.017]

Taking No Gr12
University Track Course

0.019
[0.017]

0.061
[0.024]**

0.056
[0.020]***

Taking Gr12 Vocational
Math or English

0.014
[0.014]

0.048
[0.033]

0.057
[0.032]*

Taking No Gr12
Vocational Math or English

0.006
[0.024]

0.027
[0.022]

0.032
[0.015]**

Grade Average<60%

0.007
[0.009]

0.053
[0.027]*

0.056
[0.024]**

Grade Average Btw. 60-75%

0.016
[0.021]

0.032
[0.025]

0.037
[0.018]**

Grade Average>=75%

0.04
[0.039]

0.035
[0.027]

0.027
[0.018]

Notes: Estimated effects are simply differences in mean outcomes between progran and control
schools in 2011-12, the year the Phase I program was implemented. Standard errors are in square
brackets. The additional control variables used in Column 3 are the same as those used in Appendix
Table A3. *, **, and *** indicate statistical significance at the 10, 5, and 1 percent levels
respectively.

Appendix Table A5
Phase II Program Effects on Application Rates for Grade 12 Students Beginning with At Least 21 Credits

Program Design

No Gr12
Full Sample
Univ. Track Courses
(control mean = 0.603) (control mean = 0.371)

Took At Least 1
Gr12 Univ. Course
(control mean = 0.729)

Took At Least 1
Vocational Course
(control mean = 0.209)

Baseline

0.234
[0.020]***

0.323
[0.037]***

0.199
[0.028]***

0.271
[0.124]**

Baseline +
"Mop-up"

0.26
[0.032]***

0.351
[0.054]***

0.207
[0.035]***

0.642
[0.129]***

Internal Staff +
Fee waivers

0.261
[0.100]***

0.43
[0.109]***

0.177
[0.096]*

0.218
[0.321]

Baseline with
No fee waiver

0.003
[0.066]

-0.077
[0.057]

0.063
[0.026]**

-0.026
[0.053]

Internal Staff with
No fee waiver

-0.033
[0.027]

0.01
[0.050]

-0.062
[0.020]***

-0.035
[0.052]

All schools with
Fee waivers

0.247
[0.023]***

0.341
[0.033]***

0.199
[0.025]***

0.343
[0.113]***

All schools with
No fee waiver

-0.025
[0.028]

-0.012
[0.043]

-0.036
[0.025]

-0.034
[0.046]

Sample Size for All
Schools with Fee waivers

26,996

9,456

17,534

1,257

Notes: Data are from Ontario Ministry of Education student records. The sample includes students with at least 4
years of high school with at least 21 credits at the start of the cohort year at program and control schools in
2009/10, 2010/11 and 2013/14 (the year Phase II was implemented). The control mean reported is for the
2013/14 year. The increase in probability of applying from exposure to the program is estimated from a probit
model of the outcome variable regressed on a treatment dummy, along with fixed effects for cohort year and
school. Marginal effects at mean values are reported. Standard errors are clustered by school and shown in square
brackets. *, **, and *** indicate statistical significance at the 10, 5, and 1 percent levels respectively.

Appendix Table A6
Phase II Program Effects on Enrollment Rates for Grade 12 Graduates Beginning with At Least 21 Credits
Full Sample
(control mean = 0.465)

No Gr12
Univ. Track Courses
(control mean = 0.273)

Took At Least 1
Gr12 Univ. Course
(control mean = 0.570)

Took At Least 1
Vocational Course
(control mean = 0.108)

Baseline

-0.027
[0.018]

-0.013
[0.027]

-0.015
[0.028]

-0.032
[0.036]

Baseline +
"Mop-up"

0.038
[0.034]

-0.003
[0.034]

0.056
[0.028]**

0.014
[0.067]

Internal Staff +
Fee waivers

0.003
[0.028]

0.066
[0.062]

-0.031
[0.030]

0.048
[0.068]

Baseline with
No fee waiver

0.004
[0.030]

-0.056
[0.033]*

0.043
[0.026]

0.074
[0.096]

-0.055
[0.025]**

-0.026
[0.038]

-0.07
[0.022]***

-0.038
[0.037]

All schools with
Fee waivers

-0.003
[0.019]

-0.003
[0.023]

0.006
[0.023]

-0.007
[0.038]

All schools with
No fee waiver

-0.042
[0.023]*

-0.034
[0.031]

-0.046
[0.024]*

-0.023
[0.038]

26,996

9,456

17,534

1,176

Program Design

Internal Staff with
No fee waiver

Sample Size for All
Schools with Fee waivers

Notes: Data are from Ontario Ministry of Education student records. The sample includes students with at least 4
years of high school at 21 credits at the start of the cohort year at program and control schools in 2009/10, 2010/11
and 2013/14 (the year Phase II was implemented). The control mean reported is for the 2013/14 year. The increase
in probability of enrolling from exposure to the program is estimated from a probit model of the outcome variable
regressed on a treatment dummy, along with fixed effects for cohort year and school. Marginal effects at mean
values are reported. Standard errors are clustered by school and shown in square brackets. *, **, and *** indicate
statistical significance at the 10, 5, and 1 percent levels respectively.

.6

.65

.7

.75

.8

Figure 2A
Control and Program School Postsecondary Application Rates for Grade 12 Graduates
2009-10 to 2012-13

2009-10

2010-11
2011-12
Grade 12 School-Year
Control Schools

2012-13

Program Schools

Notes: The fraction of Grade 12 graduates applying to any postsecondary institution is calculated for
each control and program school. The values in the figure show the average application rates for
control and treated schools, weighted by the sample size in each school.

.5

.52

.54

.56

.58

Figure 2B
Control and Program School Postsecondary Enrollment Rates for Grade 12 Graduates
2009-10 to 2012-13

2009-10

2010-11
2011-12
Grade 12 School-Year
Control Schools

2012-13

Program Schools

Notes: The fraction of Grade 12 graduates enrolling in any postsecondary institution is calculated for
each control and program school. The values in the figure show the average enrollment rates for
control and treated schools, weighted by the sample size in each school.

