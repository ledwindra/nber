NBER WORKING PAPER SERIES

STICKY EXPECTATIONS AND CONSUMPTION DYNAMICS
Christopher D. Carroll
Edmund Crawley
Jiri Slacalek
Kiichi Tokuoka
Matthew N. White
Working Paper 24377
http://www.nber.org/papers/w24377

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
March 2018

The computational results in this paper were constructed using tools in the Econ-ARK/HARK
toolkit. The toolkit can be cited by its digital object identifier, 10.5281/zenodo.1001068, in the
references as Carroll, White, and Econ-ARK (2017). Thanks to Robert King, Bartosz Maćkowiak,
Kathrin Schlafmann, Gianluca Violante and seminar participants in the NBER Summer Institute,
the Copenhagen Conference on Heterogeneity, the McMaster University, the University of
Michigan, and the University of Delaware for constructive and insightful comments which
substantially improved this paper. The views presented in this paper are those of the authors, and
should not be attributed to the European Central Bank, the Japanese Ministry of Finance, or the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Christopher D. Carroll, Edmund Crawley, Jiri Slacalek, Kiichi Tokuoka, and Matthew
N. White. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted
without explicit permission provided that full credit, including © notice, is given to the source.

Sticky Expectations and Consumption Dynamics
Christopher D. Carroll, Edmund Crawley, Jiri Slacalek, Kiichi Tokuoka, and Matthew N.
White
NBER Working Paper No. 24377
March 2018
JEL No. D83,D84,E21,E32
ABSTRACT
Macroeconomic models often invoke consumption “habits” to explain the substantial persistence
of aggregate consumption growth. But a large literature has found no evidence of habits in
microeconomic datasets that measure the behavior of individual households. We show that the
apparent conflict can be explained by a model in which consumers have accurate knowledge of
their personal circumstances but ‘sticky expectations’ about the macroeconomy. In our model, the
persistence of aggregate consumption growth reflects consumers’ imperfect attention to aggregate
shocks. Our proposed degree of (macro) inattention has negligible utility costs, because aggregate
shocks constitute only a tiny proportion of the uncertainty that consumers face.

Christopher D. Carroll
Department of Economics
Mergenthaler 441
Johns Hopkins University
Baltimore, MD 21218
and NBER
ccarroll@jhu.edu
Edmund Crawley
Department of Economics
Johns Hopkins University
edmundcrawley@gmail.com

Kiichi Tokuoka
Ministry of Finance
Japan
kiichi.tokuoka@gmail.com
Matthew N. White
Department of Economics
University of Delaware
Newark, DE 19702 USA
mnwhite@gmail.com

Jiri Slacalek
European Central Bank
D-60640 Frankfurt am Main
Germany
jiri.slacalek@ecb.int

A data appendix is available at http://www.nber.org/data-appendix/w24377
A Code and LaTeX is available at http://econ.jhu.edu/people/ccarroll/papers/cAndCwithStickyE.zip

1 Introduction
Starting with Campbell and Deaton (1989), the macroeconomics, finance, and international economics literatures have concluded that aggregate consumption exhibits ‘excess
smoothness’ compared with the benchmark Hall (1978) random walk model of consumption.1 Over the past two decades many papers in these fields have responded to
this problem by incorporating ‘habit formation’ in the utility function of a representative
agent.
This literature typically measures excess smoothness with a parameter conventionally
labeled as the ‘habit formation coefficient’ (which we denote as χ). A recent comprehensive meta-analysis of 597 published estimates (Havranek, Rusnak, and Sokolova (2017))
reports that studies based on macro data find that χ = 0.6 on average; see Figure 1.2
If habits are a true structural characteristic of people’s utility functions, we should
see their effects in microeconomic data as well as macroeconomic aggregates. But
empirical studies using household-level data strongly reject the existence of habits of the
magnitude necessary to explain aggregate consumption dynamics. The modal estimate
from Havranek, Rusnak, and Sokolova (2017)’s survey of the micro literature is a ‘habit’
parameter of 0; the mean estimate is about 0.1 (see Figure 1).3 Even among studies
that have found evidence against the random walk proposition in micro data,4 few claim
to have found more than a few percentage points’ worth of household-level spending
growth to be predictable at any measured horizon. Roughly speaking, the predictability
of aggregate spending growth is around an order of magnitude larger than predictability
of household-level spending growth (say, 0.30 versus 0.03 in an adjusted R2 sense).
We propose a simple solution to this puzzle. Instead of having consumption habits,
microeconomic consumers experience a modest informational friction: Not everybody
instantaneously notices all macroeconomic developments. Instead, households’ macroeconomic expectations are “sticky,” as in Mankiw and Reis (2002) and Carroll (2003).
Specifically, while each consumer perfectly (‘frictionlessly’) perceives his own personal
circumstances (employment status, wage rate, income received, etc), consumers’ information about macroeconomic quantities like aggregate productivity growth arrives only
occasionally (as in the Calvo model of firms’ price updating).
1 In

finance, e arly r eferences a re A bel ( 1990) a nd C onstantinides ( 1990); i n i nternational e conomics, G ruber (2004).
examples of such studies, see results and references in Fuhrer (2000) or Christiano, Eichenbaum, and Evans

2 For

(2005).
3Dynan (2000) is the best known micro study; many others are reported in Havranek, Rusnak, and Sokolova (2017).
It is well-known that household-level data on consumption are subject to substantial measurement error. Consequently,
some attenuation of the micro estimates of χ might be expected (even though many studies use estimation techniques
robust to measurement error). But an extreme amount of noise would be required for the estimated coefficient to be as close
to 0 as estimated for the many micro studies in Figure 1.
4See the detailed discussion in Section 6.2.

1

Frequency (Number of estimates in studies)
0
20
40
60
80

Figure 1 Distribution of Estimates of Habit Persistence in Macro and Micro Studies

-1

-0.5

0

0.5

1

1.5

Habit persistence χ
Macro

Micro

Notes: Reproduced from Havranek, Rusnak, and Sokolova (2017), Figure 2. The figure shows the distribution of estimates
of habit persistence in studies based on macro and micro data. Solid and dashed lines show the median estimates in micro
(0.0) and macro (0.6) studies, respectively.

2

Consumption sluggishness a la Campbell and Deaton (1989) arises as follows. As
in the standard (frictionless) setup, sticky-expectations households perfectly observe
their market resources (wealth, debt, etc) and income. However, a consumer whose
beliefs about the state of the aggregate economy are out of date will behave in the
ways that would have been macroeconomically appropriate (for the consumer’s currently
observed level of wealth etc) at the time of their last perception of macroeconomic
circumstances. The model thus generates a lag in the response of aggregate spending to
aggregate developments; the amount of sluggishness will depend on the frequency with
which consumers update. When our model’s updating frequency is calibrated to match
conventional estimates of the degree of inattention measured using expectations data
on other aggregate variables (e.g., inflation expectations), the model’s implications for
the persistence in aggregate consumption growth match well the estimates of the ‘excess
smoothness’ of consumption growth in the macro literature.
Despite aggregate sluggishness, at the level of individual households, high-frequency
consumption growth has little predictability. This can be reconciled with aggregate
smoothness because the rationally appropriate contribution of the consumer’s perception
of the macroeconomic environment to their individual spending choices is swamped by
the importance of fluctuations in idiosyncratic components of income which we assume
consumers have no difficulty observing (and to which we assume they are perfectly
attentive).5
In our model, the sticky updating of beliefs about the aggregate economy takes the
same form (and has the same magnitude) as proposed in Carroll (2003) as a microfoundation for the Mankiw and Reis (2002) model. An advantage compared to those papers
is that because we are using an optimizing model, we are able to calculate an explicit
utility cost of stickiness. Consistent with a theme in the literature on inattentiveness
all the way back to Akerlof and Yellen (1985), we find that the utility penalty from
inattention is low, so that, under our calibrated parameters, our consumers would not
be willing to pay much for even the most perfect information about the macroeconomic
state: They would be willing to pay roughly one two-thousandth of their lifetime income
to be perfectly informed in every future period of their lifetime.
Our results are essentially the same in a partial equilibrium model (in which factor
prices are constant) and a heterogeneous-agents DSGE model with aggregate shocks
(which affect factor prices).6 Data simulated from our models reproduce what we take
to be the main stylized facts about individual and aggregate consumption dynamics.
When estimated on simulated individual data (corresponding to microeconomic evidence), regressions in the spirit of Hall (1978) and Campbell and Mankiw (1989) find that
consumption growth exhibits little persistence. This result is essentially identical across
all variants of our models: partial or general equilibrium, with or without inattention.
It comports well with the conclusions of a micro literature that was already large when
5 Over long spans of time—say, over a life cycle—models with uncertainty and impatience imply that consumption
growth parallels income growth. The theory has bite only when applied to high frequency movements in income—say, at
the quarterly or annual frequency.
6 In both environments we calibrate households’ income processes to be consistent with evidence from both
microeconomic and macroeconomic data.

3

Deaton (1992) surveyed it and has remained consistent since then in finding little
persistence. In this respect (and all others), the micro implications of the model are
standard for models of this type (with uninsurable uncertainty as well as precautionary
saving and perhaps liquidity constraints), which have been extensively studied in the
micro literature.7
We then analyze Hall (1978)/Campbell and Mankiw (1989) regressions with simulated
aggregate data. Thanks to the law of large numbers, the idiosyncratic shocks that
dominate the household data cancel out upon aggregation, leaving only the residual
systematic factors, which generate the much greater predictability in aggregate than in
idiosyncratic data. Campbell and Mankiw (1989) proposed that such predictability
arises because some people just spend all their income, and income growth is predictable. The habit formation literature has argued instead that predictability reflected
the sluggishness of consumption growth itself. Horserace regressions that pit these two
possibilities against each other produce a clear winner: Almost all of the predictability
of consumption growth is explained by its correlation with lagged consumption growth;
only a small portion comes from the predictable component of aggregate income growth
– both in the data and in our model.
After a brief review of the extensive relevant literature, we begin explaining our ideas
with a ‘toy model’ (section 3) in which the key mechanisms can be derived analytically,
thanks to extreme simplifying assumptions like quadratic utility and constant factor
prices. We next (section 4) present the full versions of our models, which abide by the
more realistic assumptions (CRRA utility, aggregate as well as individual shocks, time
varying factor prices, etc) that have become conventional respectively in the micro and
macro literatures.
After calibrating the model (section 5), we describe the stylized facts from both
the micro and macro literatures that need to be explained by a good microfounded
macroeconomic model of consumption, and show that all of the various versions of our
model (partial versus general equilibrium, etc) robustly reproduce those facts (section
6). This robustness indicates that our results are not a fragile implication of any highly
specific framework but instead flow from the underlying structure of inattention that
is the common element across all versions of our model (including the quadratic utility
‘toy model’ where the consequences can be seen most clearly). We then (section 7)
calculate how much a fully informed consumer would be willing to pay at birth to enjoy
instantaneous and perfect knowledge of aggregate developments as they live their life
(not much, it turns out).
With our model’s quantitative results in hand, we describe the quantitative and qualitative differences between our model and the other ‘imperfect information’ approaches
to explaining aggregate consumption smoothness that have been explored in the prior
literature (section 8). Our conclusion suggests directions for future research.

7 For example, the model reproduces the robust pattern of evidence since Zeldes (1989a) has documented that
consumption growth is faster for people with very low cash-on-hand (who may be near a liquidity constraint or below
their desired precautionary buffers—or both).

4

2 Relation to the Literature
No review of the empirical literature is needed; Havranek, Rusnak, and Sokolova (2017)
have done an admirable job. Our only critique is that they have followed much of the
prior literature in casually referring to the parameter of interest as the ‘habit coefficient.’
A better choice would have been to call it the ‘excess smoothness’ coefficient; ours is
not the first paper to suggest that habits are not the only possible explanation for why
consumption growth might be too smooth (compared to the Hall (1978) benchmark).
Our ‘sticky expectations’ approach is related to several strands of the burgeoning
literature on models of imperfect information processing. A major strand in that
literature is models of ‘rational inattention’ in the spirit of Sims (2003), in which agents
have a limited ability to pay attention and allocate it optimally, recently embodied
(for example) in the work of Maćkowiak and Wiederholt (2015). They study a DSGE
model with inattentive consumers and firms using a simple New Keynesian framework
in which they replace all sources of slow adjustment (habit formation, Calvo pricing and
wage setting) with rational inattention. The setup with rational inattention can match
the sluggish responses observed in aggregate data, in response both to monetary policy
shocks and to technology shocks.
A challenge to this approach has been the extraordinary complexity of solving models
that aim to work out the full implications of the fact that everyone else is working out
the full implications of the fact that everyone else is rationally inattentive.8 In response,
Gabaix (2014) has recently proposed a framework that is much simpler than the full
rational inattention framework of Sims (2003), but aims to capture much of its essence.
This approach is relatively new, and while it does promise to be more tractable than the
full-bore Simsian rational inattention framework, even the simplified Gabaix approach
would be formidably difficult to embed in a model with a rich treatment of transitory
and persistent income shocks, precautionary motives and other complexities entailed
in modern models of microeconomic consumption decisions. It would be similarly
challenging to determine how to apply the approaches of Woodford (2002) or Morris
and Shin (2006) to our question.9
Another way to dial back the complexity of the rational inattention approach is to
radically simplify the model’s assumptions about decisionmaker’s problem. In that spirit
Reis (2006a) considers a model in which consumers with a linear consumption function
and a conveniently simple environment optimally choose to be inattentive because of
explicit (fixed monetary) costs of attention.10 In this framework, Reis (2006a) is able
to calculate an explicit analytical formula for the tradeoff between the disutility from
the increase in uncertainty caused by inattention, and the monetary savings due to
infrequent payment of the cost of information. Reis shows that in his model, inattention
is manifested in the fact the his consumers only gather new information (and therefore
8 For example, the literature on rational inattention has adopted a more stylized setup of idiosyncratic and aggregate
income shocks and, to our knowledge, has so far not solved the full Krusell and Smith (1998) framework.
9 Arguably, our Calvo-style updating is not too different from what one might get in a suitably adapted version of
the Morris and Shin (2006) model.
10 Reis (2006b) presents a similar setup with a producer setting prices subject to information processing constraints.

5

only update their consumption) at fixed intervals whose length depends on the cost of
obtaining information versus the costs of remaining ignorant.
One of our objectives is to faithfully match microeconomic data. In such data there
is incontrovertible evidence—most recently from millions of datapoints from the Norwegian population registry examined by Fagereng, Holm, and Natvik (2017)—that the
consumption function is not linear. It is concave, as the general theory suggests (Carroll
and Kimball (1996)), and this concavity matters greatly for matching the main micro
facts. There is also nothing that looks either like the Reis model’s prediction that there
will be extended periods in which consumption does not change at all, nor its prediction
that there will be occasional periods in which it moves a lot (at dates of adjustment)
and then remains constant at that newer level for some extended period. This critique
applies generically to models that incorporate a convex cost of adjustment—whether to
the consumer’s stock of information (Reis (2006a)) or to the level of consumption as in
Chetty and Szeidl (2016). All such models imply counterfactually ‘jerky’ behavior of
spending at the microeconomic level.11
To better match the micro data, we use the now-conventional microeconomic formulation in which utility takes the Constant Relative Risk Aversion form and uncertainty
is calibrated to match micro estimates. Our assumption that consumers can perfectly
observe the idiosyncratic components of their income allows us to use essentially the same
solution methods as in the substantial recent literature exploring models of this kind; our
assumption that macroeconomic expectations are sticky makes no material difference to
the solution of the model.12 Implementing the state of the art in the micro literature
adds a great deal of complexity and precludes a closed form solution for consumption
like the one used by Reis; its virtue is that the model is quantitatively plausible enough
that, for example, it might actually be usable by policymakers who wanted to assess the
likely dynamics entailed by alternative fiscal policy options.
Given our choice to embrace the challenge of matching micro data, it was essential to
keep the rest of the model as simple as possible, in the spirit of Akerlof and Yellen (1985),
Cochrane (1991), Mankiw and Reis (2002) and as forcefully advocated by Browning and
Crossley (2001). In pursuit of such simplicity, we adopt the Calvo (1983)-like framework
of Carroll (2003) in which updating is a Poisson event.13
Inattention is not the only alternative to habits as an explanation for excess smoothness. Information itself can be imperfect, even for a perfectly attentive consumer. The
11 This pattern does match consumers’ purchases of durable goods like automobiles; but the ‘excess smoothness’ facts
hold as strongly for aggregate nondurables as for durable goods. The fixed-adjustment-cost framework matches many other
economic decisions well—for instance, individual investors adjust their portfolios sporadically even though the prices of
many assets experience large fluctuations at high frequency—and Alvarez, Guiso, and Lippi (2012) find “a robust pattern
consistent with the assumption that a component of adjustment costs is information gathering” (p. 2273).
12 A fascinating study that does not fit neatly into this analysis is Johnson, Parker, and Souleles (2006), who show that
spending in the U.S. responded strongly to the random idiosyncratic variation in the timing of tax refunds. Their results
might possibly be consistent with a model in which households can see the contents of their bank accounts but do not
pay attention to tax policy, which has the flavor of the model proposed here. Similarly, Kueng (2015) argues that excess
sensitivity of consumption is consistent with households following near-rational plans and that to model macroeconomic
policies, such as economic stimulus programs, near-rational alternatives can perform better than standard consumption
models.
13 Browning and Collado (2001) speculate that the differing results in the micro literature can be resolved if consumers
are not perfectly attentive even to all the details of their own personal income processes, an explanation which could
easily be interpreted using framework proposed here.

6

seminal work contemplating this possibility was by Muth (1960), whose most direct
descendant in the consumption literature is Pischke (1995) (building also on Lucas
(1973)). The idea is that (perfectly attentive) consumers face a signal extraction problem
in determining whether a shock to income is transitory or permanent. When a permanent
shock occurs, the immediate adjustment to the shock is only partial, since agents’ best
guess is that the shock is partly transitory and partly permanent. With the right
calibration, such a model could in principle explain any amount of excess smoothness.
But we argue that when a model of this kind is calibrated to the actual empirical data,
it generates only a modest amount of excess smoothness, far less than exhibited by the
empirical data.
Moving from theory to evidence, there is an interesting and growing literature that
uses expectations data from surveys in an attempt to directly measure sluggishness in
expectations dynamics.14 For example, Coibion and Gorodnichenko (2015) find that the
implied degree of information rigidity in inflation expectations is high, with an average
duration of six to seven months between information updates. Fuhrer (2017a) and Fuhrer
(2017b) find that even for professional forecasters, forecast revisions are explainable using
lagged information, which would not be the case under perfect information processing.

3 A Quadratic Utility ‘Toy Model’
Here we briefly introduce concepts and notation, and motivate the key result using a
simple framework with quadratic utility. We start with the classic Hall (1978) random
walk model, with the standard assumption of time separable utility and geometric
discounting by factor β. Overall wealth o (the sum of human and nonhuman wealth)
evolves according to the dynamic budget constraint
ot+1 = (ot − ct )R + ζt+1 ,

(1)

where R = (1 + r) is the interest factor and ζt+1 is a shock to (total) wealth.
With no informational frictions, the usual derivations lead to the standard Euler
equation:


u0 (ct ) = Rβ Et u0 (ct+1 ) ,
where Et denotes an assumption of instantaneous perfect frictionless updating of all
information. Quadratic u and Rβ = 1 imply Hall’s random walk proposition:
∆ct+1 = εt+1 .
Consumers spend
ct = (r/R)ot ,
because this is exactly the amount that maintains expected wealth unchanged:
Et [ot+1 ] = (ot − ct )R = ot .
14 We

omit a fuller survey of this interesting literature because expectations data will not be our focus here.

7

Sticky Expectations
Now suppose consumers update their information about ot , and therefore their behavior,
only occasionally. A consumer who updates in period t obtains precisely the same
information that a consumer in a frictionless model would receive, forms the same
expectations, and makes the same choices. Nonupdaters, however, behave as though
their former expectations had actually come true (since by definition these are the
persons who have learned nothing to disconfirm their prior beliefs). For example,
consider a consumer who updates in periods t and t + n but not between. Designating
e as the consumer’s perception of wealth:
o
et+j ≡ Et [ot+j ] = ot
o

for 1 ≤ j < n,

the consumer spends according to perceived wealth so that
ct+j = (r/R)e
ot+j = (r/R)ot = ct

for 1 ≤ j < n.

The dynamics of actual (as distinct from perceived) wealth are given by (1),
= (ot −ct )R

z}|{
ot+1 =
ot
+ζt+1
ot+2 = ot+1 + ζt+2 = ot + ζt+1 R + ζt+2
..
..
.
.
n
X
ot+n = ot +
Rn−s ζt+s ,
|s=1 {z

≡ ∆n ot+n

}

so for a consumer who updates in periods t and t + n but not between, the change in
consumption is
ct+n − ct = (r/R)∆n ot+n ,
where ∆n ot+n is white noise because it is a weighted sum of the white noise errors ζ.
Thus, consumption follows a random walk across updating periods; consumers who were
only observed during their updating periods would never be seen to deviate from the
predictions of Hall (1978).
Aggregation
The economy is populated by consumers indexed by i, distributed uniformly along the
unit interval. Aggregate (or equivalently, per capita) consumption is
Z 1
Ct =
ct,i di.
0

Whether the consumer at location i updates in period t is determined by the realization
of the binary random variable πt,i , which takes the value 1 if consumer i updates in period
t and 0 otherwise. Each period’s updaters are chosen randomly such that a constant

8

proportion Π update in each period:
E[πt+1,i ] = Π
Z 1
πt,i di = Π

∀ t and i,
∀ t.

0

Aggregate consumption is the population-weighted average of per-capita consumption
of updaters Cπ and nonupdaters Cπ :
 ,
Ct+1 = ΠCπt+1 + (1 − Π) Cπt+1
| {z }

(2)

= Ct

 = Ct because the nonupdaters at time t + 1 are a
where per-capita consumption Cπt+1
random subset of the population at time t. The first difference of (2) yields

∆Ct+1 = (1 − Π)∆Ct + Π∆Cπt+1
| {z }
≡ εt+1

and Appendix C.1 shows that εt+1 is approximately mean zero.15 Thus, in the quadratic
utility framework the serial correlation of aggregate per-capita consumption changes is
an approximate measure of the proportion of nonupdaters.
This is the mechanism behind the exercises presented in Section 6. While the details of
the informational friction is different in the more realistic models we will set up in Section
4, the same logic and quantitative result holds: the serial correlation of consumption
growth approximately equals the proportion of non-updaters.
Note further that the model does not introduce any explicit reason that consumption
growth should be related to the predictable component of income growth a la Campbell
and Mankiw (1989). In a regression of consumption growth on the predictable component of income growth (and nothing else), the coefficient on income growth would entirely
derive from whatever correlation predictable income growth might have with lagged
consumption growth. This is the pattern we will find below, both in our theoretical and
our empirical work.

4 Real Models
One of the lessons of the consumption literature after Hall (1978) is that his simplifying
assumptions (quadratic utility, perfect capital markets, Rβ = 1) are far from innocuous;
more plausible assumptions can lead to very different conclusions. In particular, a
host of persuasive theoretical and empirical considerations has led to the now-standard
assumption of constant relative risk aversion utility, u(c) = c1−ρ /(1 − ρ). When utility
is not quadratic, solution of the model requires specification of the exact stochastic
structure of the income and transition processes.
Below, we present two models that will be used to simulate the economy under
frictionless and sticky expectations. First, we specify a small open economy (or partial
15 Intuitively, this term mainly reflects the behavior of updating consumers, and is therefore unpredictable with respect
to sufficiently delayed information.

9

equilibrium) model with a rich and empirically realistic calibration of idiosyncratic
and aggregate risk but exogenous interest rates and wages. Second, we extend the
SOE model to a heterogeneous agents dynamic stochastic general equilibrium (closedeconomy) model that endogenizes factor returns, at the cost of a more burdensome
computational task.16

4.1 General Modeling Assumptions
Several features are common across all our models. A continuum of agents care about
expected lifetime utility derived from CRRA preferences over a unitary consumption
good; they geometrically discount future utility flows by discount factor β. These
agents inelastically supply one unit of labor, and their only decision in each period t
is how to divide their market resources m between consumption c and saving in a single
asset a. We assume agents are Blanchard (1985) “perpetual youth” consumers: They
have a constant probability of death D between periods, and upon death they are are
immediately replaced, while their assets are distributed among surviving households in
proportion to the recipient’s wealth.
4.1.1 Output, Income, and Productivity
Output is produced by a Cobb–Douglas technology using capital Kt and (effective) labor
Lt ; capital depreciates at rate δ immediately after producing output, leaving portion
k = 1 − δ intact, and as usual the effectiveness of labor depends on the level of aggregate
labor productivity.
We represent both aggregate and idiosyncratic productivity levels as having both transitory and permanent components. Large literatures have found that this representation
is difficult to improve upon much in either context, and the simplicity of this description
yields considerable benefits both in the tractability of the model, and in making its
mechanics as easy to understand as possible.
In more detail, aggregate permanent labor productivity Pt grows by factor Φt , subject
to mean one iid aggregate permanent shocks Ψt , so the aggregate productivity state
evolves according to:
Pt+1 = Φt+1 Pt Ψt+1 , where

Prob[Φt+1 = Φk |Φt = Φj ] = Ξj,k .

(3)

The productivity growth factor Φt follows a bounded random walk, as in (for example)
Edge, Laubach, and Williams (2007), which is part of a literature whose aim is to capture
in a simple statistical way the fact that underlying rates of productivity growth seem
to vary substantially over time (e.g., fast in the 1950s, slow in the 1970s and 1980s,
moderate in the 1990s, and so on; see also Jorgenson, Ho, and Stiroh (2008)).17 We
16 Appendix A presents a model that abstracts from idiosyncratic income risk (essentially, setting σ 2 = σ 2 = 0), and
ψ
θ
which produces results similar to those of our ‘realistic’ models. The simplification enables general equilibrium analysis
at a small fraction of the computational cost. However, it is neither a recognizable representative agent model nor a
respectable heterogeneous agents model, which may reduce its appeal to both audiences.
17 We capture the process by discretizing the range of productivity growth rates within our bounds, and calibrate the
Markov transition probability matrix Ξ so that the statistical properties of productivity growth rates exhibited by our
process match the corresponding properties measured in U.S. data since the 1950s.

10

introduce these slow-moving productivity growth rates not just for realism but also
because we need to perform, in our simulated data, exercises like those Campbell and
Mankiw (1989) performed in empirical data, in which consumption growth is regressed
on the component of income growth that was predictable using data lagged several
quarters. We therefore need a model in which there is some predictability in income
growth several quarters in the future.
The transitory component of productivity in any period is represented by a mean-one
variable Θt , so the overall level of aggregate productivity in a given period is Pt Θt .
Similarly, each household has an idiosyncratic labor productivity level pt,i , which
(conditional on survival) evolves according to:
pt+1,i = pt,i ψt+1,i ,

(4)

and like their aggregate counterparts, idiosyncratic permanent productivity shocks are
mean one iid (Et [ψt+n,i ] = Et [Ψt+n ] = 1 ∀ n > 0).18 Total labor productivity for
the individual is determined by the interaction of transitory idiosyncratic (θ), transitory
aggregate (Θ), permanent idiosyncratic (p), and permanent aggregate (P ) factors. When
the household supplies one unit of labor, this contributes effective labor equal to:
≡ θ t,i

` t,i

z }| {
= θt,i Θt pt,i Pt .
| {z }

(5)

≡ p t,i

Here, θ can be thought of as reflecting, for example, individual unemployment spells,
while Θ captures, e.g., disruptions in output due to bad weather. Just like aggregate
transitory shocks, θt,i is mean one and iid, so that Et [θt+n,i ] = Et [Θt+n ] = 1 ∀ n > 0.
The idiosyncratic transitory shock has a minimum possible value of 0 (corresponding to
an unemployment spell) which occurs with a small finite probability ℘. This has the
effect of imposing a ‘natural borrowing constraint’ (cf. Zeldes (1989b)) at zero.
4.1.2 Perceptions and Behavior
For understanding the decisions of an individual consumer in a frictionless (i.e., perfect
information) world the aggregate and idiosyncratic transitory shocks can be combined
into a single overall transitory shock indicated by the boldface θ , and the aggregate and
idiosyncratic levels of permanent income can be combined as p (likewise, the combined
permanent shock is boldface ψ t,i ≡ ψt,i Ψt ). However, a key feature of the models used
here is that a household does not necessarily know the true value of the aggregate
productivity state variables (Pt , Φt ), as they might not have (stochastically) observed it
in the current period. Instead, each household has perceptions about the aggregate state
e t,i ). Our key behavioral assumption is twofold:
(Pet,i , Φ
e t,i )
1. Household agents always act as if their perception of the aggregate state (Pet,i , Φ
were the true aggregate state (Pt , Φt ).
18 Because we did not have any modeling purpose for which we needed a slow-moving persistent component to
idiosyncratic productivity growth, we omitted it. If we wanted a completely parallel representation of the aggregate
and idiosyncratic processes, we could introduce a term φt,i ≡ 1 ∀ t.

11

2. Households form their perception of the aggregate state according to the expectation of today’s state given the last observed aggregate state.
Given the assumption that productivity growth Φt follows a random walk, the second
part of the behavioral assumption says that an agent who last observed the true aggregate
state n periods ago perceives:


e t,i ) = Et−n (Pt , Φt ) (Pt−n , Φt−n ) = (Φn Pt−n , Φt−n ).
(Pet,i , Φ
(6)
t−n

That is, our assumed random walk in productivity growth means that the household
believes that aggregate productivity has grown at the last observed growth rate for the
past n periods.19 For households who observed the true aggregate state this period,
e t,i ) = (Pt , Φt ). The household perceives that their
n = 0 and thus (6) says that (Pet,i , Φ
overall permanent productivity level is pet,i = pt,i Pet,i .
Households in our models always correctly observe the level of all real variables—they
are able to read their bank statement and paycheck. But (as will be shown below)
consumers’ optimal behavior in the frictionless model depends on the ratios of those
real variables to productivity. That is, for some state variable x (like market wealth),
the optimal choice would depend on x ≡ x/pp, where our definition of nonboldface x
reflects our notational convention that when a level variable has been normalized by
the corresponding measure of productivity, it loses its boldness. The same applies for
aggregate variables X ≡ X/P .
p differs from actual productivity,
When a household’s perception of productivity e
we denote the perceived ratio as, e.g., x
e ≡ x/e
p = x/(pPe) where the last equality
reflects our assumption that the household perceives the idiosyncratic component of
their productivity p without error.
The behavior of a ‘sticky expectations’ consumer thus differs from that of a frictionless
consumer only to the extent that the ‘sticky expectations’ consumer’s perception of
aggregate productivity is out of date.
4.1.3 Transition Dynamics
Infinitely-lived households with a productivity process like (4) would generate a nonergodic distribution of idiosyncratic productivity—as individuals accumulated ever more
shocks to their permanent productivities, those productivities would spread out indefinitely with time. To avoid this inconvenience, we make the Blanchard (1985) assumption:
Each consumer faces a constant probability of mortality of D (with complementary
survival probability D). We track death events using a binary indicator:
(
0 if consumer at location i survives from time t to t + 1
dt+1,i =
1 if consumer at location i dies between t and t + 1.
We refer to this henceforth as a ‘replacement’ event, since the consumer who dies is
replaced by an unrelated newborn who happens to inhabit the same location on the
19 Because

of the boundedness of the random walk in productivity growth, this holds only approximately.

12

number line. The ex ante probability of death is identical for each consumer,
R 1 so that
the aggregate mass of consumers who are replaced is time invariant at D = 0 dt,i di.
Under the assumption that ‘newborns’ have the population average productivity level
of
mean of the idiosyncratic component of permanent income is always
R 1 1, the population
20
p
di
=
1.
Our
earlier equation (4) for the idiosyncratic productivity transition rule
0 t,i
for the inhabitant of location i on the number line is thus adjusted to:21
(
pt,i ψt+1,i if dt+1,i = 0
pt+1,i =
1
if dt+1,i = 1.
Along with its productivity level, the household’s primary state variable when the
consumption decision is made is the level of market resources mt,i , which captures both
current period labor income yt,i (the wage rate times the household’s effective labor
supply) and the resources that come from the agent’s capital stock kt,i (the value of the
capital itself plus the value of the capital income it yields):
mt,i = Wt` t,i + Rt kt,i .
| {z } |{z}
≡ yt,i

(7)

k+rt

The transition process for m is broken up, for convenience of analysis, into three steps.
‘Assets’ at the end of the period are market resources minus consumption:
at,i = mt,i − ct,i .

(8)

Next period’s capital is determined from this period’s assets via
(
at,i /D if dt+1,i = 0
kt+1,i =
0
if dt+1,i = 1,
where the first row’s division of a by the survival probability D reflects returns to
survivors from the Blanchardian insurance scheme in which the dying agents’ assets
are distributed to the survivors. More compactly we can write:
kt+1,i = dt+1,i · 0 + (1 − dt+1,i )at,i /D.

(9)

4.1.4 Aggregation
The foregoing assumptions permit straightforward aggregation of individual-level variables. Aggregate capital is the population integral of (9):
Z 1
Z 1
Z 1

Kt =
kt,i di =
(1 − dt,i )at−1,i /D di =
at−1,i di = At−1 .
(10)
0

0

0

20 The dynamics and steady state of the population variance of the idiosyncratic component of permanent income p
are derived in Appendix C.2. The variance will exist so long as 
D E[ψ 2 ] < 1, which imposes a loose restriction on the
magnitude of the idiosyncratic permanent shocks.
21 The constant population size permits the analytical convenience of replacing the dying with newborns, but it is
important to understand that there is no relationship between successive persons at the same location on the number
line; this is not a dynastic model.

13

R1
The third equality holds because D−1 0 (1 − dt,i ) di = 1 and dt,i is independent of at−1,i .
R1
R1
Because 0 θt,i = 0 pt,i = 1, aggregate labor supply is
Z 1
`t,i di = Θt Pt .
(11)
Lt =
0

Aggregate market resources can be written as per-capita resources of the survivors
times their population mass D, plus per-capita resources of the newborns times their
population mass D:
Mt

per-capita m for survivors

per-capita m for newborns

z
}|
{
= At−1 Rt /D + Θt Pt W D +
= At−1 Rt + Θt Pt Wt
= Kt Rt + Lt Wt .

z }| {
Θt P t W t

D
(12)

This identity can also be derived directly as the population integral of (7).
The productivity-normalized version of (12) says that
Mt = At−1 Rt /(Ψt Φt ) + Θt Wt .

(13)

Because the households in our model do not necessarily observe the true aggregate
productivity level, their perception of normalized aggregate market resources is
ft,i = Mt /Pet,i = (Pt /Pet,i )Mt .
M
(14)
We will sometimes refer to the factor Pt /Pet,i as the household’s ‘productivity misperception,’ the scaling factor between actual and perceived market resources. As discussed
below, this same misperception factor applies to individual market resources as well.

4.2 Small Open Economy (SOE) Model
Our first realistic model considers a small open economy with perfect international
capital mobility, so that factor prices rt and Wt are exogenously determined (at constant
values r and W). These assumptions permit a partial equilibrium analysis using only
the solution to the individual households’ problem. The frictionless consumer’s state
variables are simply (mt,i , pt,i , Pt , Φt ). Because we assume that the sticky expectations
consumer behaves according to the decision rules that are optimal for the frictionless
consumer but using perceived rather than true values of the state variables, we need
only to solve for the frictionless solution.
4.2.1 Model and Solution
The household’s problem in levels can be written in Bellman form as:22



v(mt,i , pt,i , Pt , Φt ) = max u(ct,i ) + β Et (1 − dt+1,i )v(mt+1,i , pt+1,i , Pt+1 , Φt+1 ) .
ct,i

(15)
22 Subject

to definitions (3), (4), (5), (7), (8) and (9).

14

Our assumption that the aggregate and idiosyncratic productivity levels both reflect
a combination of transitory and purely permanent components now permits us to make
a transformation that considerably simplifies analysis and solution of the model: When
the utility function is in the CRRA class, the problem can be simplified by dividing
by p 1−ρ
= (pt,i Pt )1−ρ while converting to normalized variables as above (e.g., mt,i =
t,i
mt,i /ppt,i ).23 This yields the normalized form of the problem, which has only mt,i and Φt
as state variables:



v(mt,i , Φt ) = max u(ct,i ) + Dβ Et (Φt+1ψ t+1,i )1−ρ v(mt+1,i , Φt+1 )
(16)
ct,i

at,i
kt+1,i
mt+1,i

s.t.
= mt,i − ct,i ,
= at,i /(DΦt+1ψ t+1,i ),
= Rkt+1,i + Wθθ t+1,i .

Defining R = R/D, the main requirement for this problem to have a solution is an
impatience condition:24
ψ −ρ ] < 1.
Rβ E[ψ
Designating the converged normalized consumption function that solves (16) as
c(m, Φ), the level of consumption for the frictionless consumer can be obtained25 from
ct,i = p t,i c(mt,i , Φt ).
Because the model is homothetic in p t,i = pt,i Pt , this can be equivalently written with
the un-normalized consumption function ĉ as:
ct,i = ĉ(mt,i , pt,i , Pt , Φt ).
4.2.2 Frictionless vs Sticky Expectations
Following the same notation as in the motivating Section 3, we define an indicator
variable for whether household i updates their perception to the true aggregate state in
period t:26
(
1 if consumer i updates in period t
πt,i =
0 if consumer i does not update in period t.
The Bernoulli random variable πt,i is iid for each household each period, with a
probability Π of returning 1. Consistent with (6), household beliefs about the aggregate

23 This

is well understood in the literature; for a full exposition, see, e.g., Carroll (2016).
parametric restrictions are also necessary, but for typical parameterizations are not likely to be binding; see
Carroll (2016) for details. Note that the relevant interest factor is the within-period productivity of capital R adjusted
for both of the influences (δ and 
D ) that intervene between the amount of assets with which the consumer ends period t
and the amount of productive capital owned when capital income is received in period t + 1.
25 Appendix B.1 provides details for numerically solving the model.
26 For simplicity, newborns begin life with correct beliefs about the aggregate state. This assumption about newborns’
beliefs is numerically inconsequential because the quarterly replacement rate is so low; see Section 5 for details.
24 Other

15

state evolve according to:
(
if πt,i = 1
e t,i ) = (Pt , Φt )
(Pet,i , Φ
e
e
e
(Φt−1,i Pt−1,i , Φt−1,i ) if πt,i = 0.

(17)

Under the assumption that consumers treat their belief about the aggregate state as
if it were the truth, the relevant inputs for the normalized consumption function c(m, Φ)
are the household’s perceived normalized market resources m
e t,i = mt,i /e
p t,i = (Pt /Pet,i )mt,i
e t,i . The household chooses their level of
and perceived aggregate productivity growth Φ
consumption by:
e t,i ) = ĉ(mt,i , pt,i , Pet,i , Φ
e t,i ).
ct,i = pet,i c(m
e t,i , Φ
(18)
The behavior of the ‘sticky expectations’ consumer converges to that of the frictionless
consumer as Π ↑ 1; conveniently, we can use the same simulation code for both kinds of
consumers by simply setting Π = 1 to generate the behavior of the frictionless economy.
Because households in our model never misperceive the level of their own market
e t,i = mt,i ), they can never choose consumption that would violate the
resources (m
budget constraint.27 But their misperceptions of aggregate permanent income do cause
them to make systematic errors. See below for calculations showing that for the value
of Π that we estimate, those errors are very small.

4.3 Dynamic Stochastic General Equilibrium (HA-DSGE) Model
Our second model relaxes the simplifying assumption of a frictionless global capital
market. In this closed economy, factor prices Wt and rt are determined in the usual
way from the aggregate production function and aggregate state variables, including
the stochastic aggregate shocks, putting the model in the (small, but growing) class of
heterogeneous agent DSGE models.
4.3.1 Model and Solution
We make the standard assumption that markets are competitive, and so factor prices
are the marginal product of (effective) labor and capital respectively. Denoting capital’s
share as γ, so that Yt = Kγt L1−γ
, this yields the usual wage and interest rates:
t
∂Yt
= (1 − γ)(Kt /Lt )−γ ,
∂Lt
∂Yt
rt =
= γ(Kt /Lt )γ−1 .
| {z }
∂Kt

Wt =

(19)

= Kt /Θt

Net of depreciation, the return factor on capital is Rt = 1 − δ + rt = k + rt .
27 Households observe both their level of income y
t,i and its idiosyncratic components θt,i and pt,i . If they wanted to
do so, households could therefore calculate the aggregate component Θt × Pt , which would correspond with the reports
of a statistical agency. Our assumption is simply that households neither perceive nor attempt to extract an estimate of
the decomposition of that aggregate state into transitory and permanent components.

16

An agent’s relevant state variables at the time of the consumption decision include
the levels of household and aggregate market resources (mt,i , Mt ), as well as household
and aggregate labor productivity (pt,i , Pt ) and the aggregate growth rate Φt . We assume
that agents correctly understand the operation of the economy, including the production
and shock processes, and have beliefs about aggregate saving—how aggregate market
resources Mt become aggregate assets At (equivalently, next period’s aggregate capital
Kt+1 ). Following Krusell and Smith (1998) and Carroll, Slacalek, Tokuoka, and White
(2017), we assume that households believe that the aggregate saving rule is linear in
logs, conditional on the current aggregate growth rate:

E[At ] = ℵ(Mt , Φt = Φj ) ≡ exp κj,0 + κj,1 log(Mt ) .
(20)
The growth-rate-conditional parameters κj,0 and κj,1 are exogenous to the individual’s
(partial equilibrium) optimization problem, but are endogenous to the general equilibrium of the economy. Taking the aggregate saving rule ℵ as given, the household’s
problem can be written in Bellman form as:28



v(mt,i , Mt , pt,i , Pt , Φt ) = max u(ct,i ) + β E (1 − dt,i )v(mt+1,i , Mt+1 , pt+1,i , Pt+1 , Φt+1 ) .
ct,i

(21)
As in the SOE model, the household’s problem can be normalized by the combined
productivity level p t,i , reducing the state space by two continuous dimensions. Dividing
(21) by p 1−ρ
t,i and substituting normalized variables, the reduced problem is:



v(mt,i , Mt , Φt ) = max u(ct,i ) + β D E (Φt+1ψ t+1,i )1−ρ v(mt+1,i , Mt+1 , Φt+1 )
ct,i

at,i
kt+1,i
mt+1,i

s.t.
= mt,i − ct,i ,
= at,i /D,
= Rt+1 kt+1,i /(Φt+1ψ t+1,i ) + θ t+1,i Wt+1 .

(22)

Because household beliefs about the aggregate saving rule are linear in logs, (20) holds
with normalized market resources and aggregate assets as well as in levels.
The equilibrium of the HA-DSGE model is characterized by a (normalized) consumption function c(m, M, Φ) and an aggregate saving rule ℵ such that when all households
believe ℵ, the solution to their individual problem (22) is c; and when all agents act
according to c, the best log-linear fit of At on Mt (conditional on Φt ) is ℵ. The model is
solved using a method similar to Krusell and Smith (1998).29
4.3.2 Frictionless vs Sticky Expectations
The treatment of sticky beliefs in the HA-DSGE model is the natural extension of what
we did in the SOE model presented in section 4.2.2: Because the level of Mt now affects
ft,i = Mt /Pet,i
future wages and interest rates, a consumer’s perceptions of that variable M
28 Subject
29 Details

to definitions (3), (4), (5), (7), (8), (9), (10), (11), (12), (19) and (20).
are in Appendix B.1.2.

17

now matter. Households in the DSGE model choose their level of consumption using
their perception of their normalized state variables:
ft,i , Φ
e t,i ) = ĉ(mt,i , Mt , pt,i , Pet,i , Φ
e t,i ).
ct,i = pet,i c(m
e t,i , M
Households who misperceive the aggregate productivity state will incorrectly predict
aggregate saving at the end of the period, and thus aggregate capital and the distribution
of factor prices next period.30
Because households who misperceive the aggregate productivity state will make
(slightly) different consumption–saving decisions than they would have if fully informed,
aggregate saving behavior will be different under sticky than under frictionless
expectations. Consequently, the equilibrium aggregate saving rule ℵ will be slightly
different under sticky vs frictionless expectations. When the HA-DSGE model is solved
under sticky expectations, we implicitly assume that all households understand that all
other households also have sticky expectations, and the equilibrium aggregate saving
rule is the one that emerges from this belief structure.

5 Calibration
To calculate the quantitative consequences of sticky expectations, we must calibrate
model parameters to match the received wisdom of the literature about empirical magnitudes. We begin by calibrating market-level and preference parameters by standard
methods, then specify additional parameters to characterize the idiosyncratic income
shock distribution.

5.1 Macroeconomic Calibration
We assume a coefficient of relative risk aversion of 2, in the middle of the range usually
considered plausible. The quarterly depreciation rate δ is calibrated by assuming annual
depreciation of 6%, i.e., k4 = 0.94. Capital’s share in aggregate output takes its usual
value of γ = 0.36.
We calibrate our aggregate income process as follows. We set the variances of the
quarterly transitory and permanent shocks at the approximate values respectively:
2
σΘ
= 0.00001,
2
σΨ = 0.00004,

to match the high persistence in aggregate labor income.31 These values are consistent
with papers such as Jermann (1998), Boldrin, Christiano, and Fisher (2001), and Chari,
Kehoe, and McGrattan (2005), considered standard exercises in the RBC literature.
These authors model the state of technology as either a highly persistent AR(1) process
or a random walk; the underlying calibrations come from the autocorrelation properties
30 This incorrect prediction is short-lived: all households will learn the true levels of next period’s aggregate capital
and output.
31 We measure labor income using U.S. NIPA data as wages and salaries plus transfers minus personal contributions
for social insurance.

18

of measured aggregate dynamics which closely correspond to our specification of the
income process. We calibrated the process for aggregate productivity growth Φ to
match measured U.S. productivity data. A Markov process with eleven states ranging
between −3.0% and +3.0% (annual), and in which the state changes on average every two
quarters, allowed us to fit both the high frequency autocorrelation evidence cited above
and the low-frequency component of productivity growth obtained, e.g., by Staiger,
Stock, and Watson (2001), Figure 1.9 and Fernald, Hall, Stock, and Watson (2017),
Figure 10.
To finish the calibration, we consider a simple perfect foresight model (PF-DSGE),
with all aggregate and idiosyncratic shocks turned off. We set the perfect foresight
steady state aggregate capital-to-output ratio to 12 on a quarterly basis (corresponding
to the usual ratio of 3 for capital divided by annual income). Along with the calibrated
values of γ and k, this choice implies values for the other steady-state characteristics of
the PF-DSGE model:32
K̆ = 121/(1−γ) ,
W̆ = (1 − γ)K̆ γ ,
R̆ = k + γ K̆tγ−1 .
A perfect foresight representative agent would achieve this steady state if his discount
factor satisfied R̆β = 1. For the HA-DSGE model, we thus set the discount factor to
βDSGE = R̆−1 , roughly matching the target capital-to-output ratio.33 For the SOE model
we choose a much lower value of β (0.97). This results in agents with wealth holdings
around the median observed in the data.34 The two values of β are chosen to span the
rather wide range of calibrations found in the micro and macro literatures. Further
alternative calibrations are possible, but experimentation has indicated that results are
not sensitive to such choices.

5.2 Calibration of Idiosyncratic Shocks
The annual-rate idiosyncratic transitory and permanent shocks are assumed to be
σθ2 = 0.03,
σψ2 = 0.012.
These figures are conservative in comparison with standard raw estimates from the

the SOE model, we fix the interest factor R and wage rate W to these PF-DSGE steady state values.
addition of aggregate and idiosyncratic risk implies that the capital-to-output ratio will be higher in the HADSGE model than the PF-DSGE calibration.
34 The exact value of the median is depends in part on whether housing equity should be viewed as part of the
precautionary buffer stock, the age range of the households being matched, the measure of permanent income, and many
other extraneous issues.
32 In

33 The

19

micro data;35 using data from the Panel Study of Income Dynamics, for example, Carroll
and Samwick (1997) estimate σψ2 = 0.0217 and σθ2 = 0.0440; Storesletten, Telmer, and
Yaron (2004) estimate σψ2 ≈ 0.017, with varying estimates of the transitory component.
But recent work by Low, Meghir, and Pistaferri (2010) suggests that controlling for job
mobility and participation decisions reduces estimates of the permanent variance somewhat; and using very well-measured Danish administrative data, Nielsen and VissingJorgensen (2006) estimate σψ2 ≈ 0.005 and σθ2 ≈ 0.015, which presumably constitute
lower bounds for plausible values for the truth in the U.S. (given the comparative
generosity of the Danish welfare state).
Since the variance of the annual permanent innovation is four times the variance of
the quarterly innovation, this calibration implies that the variance of the idiosyncratic
permanent innovations at the quarterly frequency is about 100 times the variance of
the aggregate permanent innovations (4×0.00004 divided by 0.012). This is a point
worth emphasizing: Idiosyncratic uncertainty is approximately two orders of magnitude
larger than aggregate uncertainty. While reasonable people could differ a bit from our
calibration of either the aggregate or the idiosyncratic risk, no plausible calibration of
either magnitude will change the fundamental point that the aggregate component of
risk is tiny compared to the idiosyncratic component. This is why assuming that people
do not pay close attention to the macroeconomic environment is plausible.36
We assume that the probability of unemployment is 5 percent per quarter. This
approximates the historical mean unemployment rate in the U.S., but model unemployment differs from real unemployment in (at least) two important ways. First, the model
does not incorporate unemployment insurance, so labor income of the unemployed is
zero. Second, model unemployment shocks last only one quarter, so their duration is
shorter than the typical U.S. unemployment spell (about 6 months). The idea of the
calibration is that a single quarter of unemployment with zero benefits is roughly as
bad as two quarters of unemployment with an unemployment insurance payment of half
of permanent labor income (a reasonable approximation to the typical situation facing
unemployed workers). The model could be modified to permit a more realistic treatment
of unemployment spells; this is a promising topic for future research, but would involve
a considerable increase in model complexity because realism would require adding the
individual’s employment situation as a state variable.
The probability of mortality is set at D = 0.005 which implies an expected working life
of 50 years; results are not sensitive to plausible alternative values of this parameter, so
long as the life length is short enough to permit a stationary distribution of idiosyncratic
permanent income.
We calibrate the probability of updating at Π = 0.25 per quarter, for several reasons.
First, this is the parameter value assumed for the speed of expectations updating by
Mankiw and Reis (2002) in their analysis of the consequences of sticky expectations
35 See Table 1 in the ECB working paper version of Carroll, Slacalek, and Tokuoka (2015) for a comprehensive
overview of estimates of variances of idiosyncratic income shocks; Carroll, Christopher D., Jiri Slacalek, and Kiichi
Tokuoka (2014): “Buffer-Stock Saving in a Krusell–Smith World,” working paper 1633, European Central Bank, https:
//www.ecb.europa.eu/pub/pdf/scpwps/ecbwp1633.pdf.
36 For further details of how we construct our quarterly numbers, see Appendix C.3.

20

for inflation. They argue that an average frequency of updating of once a year is
intuitively plausible. Second, Carroll (2003) estimates an empirical process for the
adjustment process for household inflation expectations in which the point estimate of
the corresponding parameter is 0.27 for inflation expectations and 0.32 for unemployment
expectations; the similarity of these figures suggests 0.25 is a reasonable benchmark, and
provides some insulation against the charge that the model is ad hoc: It is calibrated in
a way that corresponds to estimates of the stickiness of expectations in a fundamentally
different context. Finally, empirical results presented below will also suggest a speed of
updating for U.S. consumption dynamics of about 0.25 per quarter.

5.3 Equilibrium Characteristics
This section briefly characterizes some of the equilibrium characteristics of the solutions
to the models under the parameters specified above. Results are reported in Table 2.
Note first the considerable difference between the mean level of assets in the HADSGE and SOE models (first row of the table). As indicated above, this reflects our
goal of presenting results that span the full range of calibrations in the micro and macro
literatures; the micro literature has often focused on trying to explain the wealth holdings
of the median household, which are much smaller than average wealth holdings.
The table suggests a broad generalization that we have confirmed with extensive
experimentation: With respect to either cross section statistics, mean outcomes, or idiosyncratic consumption dynamics, the frictionless expectations and sticky expectations
models are virtually indistinguishable using microeconomic data, and very similar in
most aggregate implications aside from the dynamics of aggregate consumption.

6 Results
The calibrated models can now be used to evaluate the effects of sticky expectations on
consumption dynamics. We begin this section with an empirical benchmark on U.S. data
that will guide our investigation of the implications of the model. We then demonstrate
that simulated data from the sticky expectations models quantitatively and qualitatively
reproduces the key patterns of aggregate and idiosyncratic consumption data.

6.1 U.S. Empirical Benchmark
The random walk model provides the framework around which both micro and macro
consumption literatures have been organized. Reinterpreted to incorporate CRRA utility
and permit time-varying interest rates, the random walk proposition has frequently been
formulated as a claim that µ = 0 in regressions of the form:
∆ log Ct+1 = ς + ν Et [rt+1 ] + µXt + t+1 ,

21

(23)

where Xt is any variable whose value was known to consumers when the period-t
consumption decision was made, and t+1 is white noise.
For macroeconomic models (including the HA-DSGE setup in Section 4.3), simulation
analysis shows that the relationship between the normalized asset stock At and the
expected interest rate Et [rt+1 ] is nearly linear, so (23) can be reformulated with no loss
of statistical power as
∆ log Ct+1 = ς + αAt + µXt + t+1 .
This reformulation is convenient because the literatures on precautionary saving and
liquidity constraints since at least Zeldes (1989a,b) have argued that the effects of capital
market imperfections can be captured by incorporating a lagged measure of resources
like At in consumption growth regressions.
Campbell and Mankiw (1989) famously proposed a modification of this model in
which a proportion η of income goes to rule-of-thumb consumers who spend C = Y in
every period. They argued that η can be estimated by incorporating the predictable
component of income growth as an additional regressor. Finally, Dynan (2000) and
Sommer (2007) show that in some habit formation models, the size of the habit formation
parameter can be captured by including lagged consumption growth as a regressor.
These considerations lead to a benchmark specification of the form:
∆ log Ct+1 = ς + χ∆ log Ct + η Et [∆ log Yt+1 ] + αAt + t+1 .

(24)

There is an extensive existing literature on aggregate consumption dynamics, but
Sommer (2007) is the only paper we are aware of that estimates an equation of precisely
this form in aggregate data. Sommer (2007) interprets the serial correlation of consumption growth as reflecting habit formation.37 However, Sommer’s choice of instruments,
estimation methodology, and tests do not correspond precisely to our purposes here, so
we have produced our own estimates using U.S. data.
In Table 3 we conduct a simple empirical exercise along the lines of Sommer’s work,
modified to correspond to the testable implications of our model for aggregate U.S.
data.38 Three points are worth emphasizing here.
First, while the existing empirical literature has tended to focus on spending on
nondurables and services, there are reasons to be skeptical about the measurement of
quarterly dynamics (or lack of such dynamics) in large portions of the services component
of measured spending.39 Hence, we report results both for the traditional measure of
nondurables and services spending, and for the more restricted category of nondurables
spending alone. Fortunately, as the table shows, our results are robust to the measure of
spending. Indeed, similar results hold even when the measure of spending is the broader
37 Weber

(2002) makes a similar point using a different methodology.
Sommer, and Slacalek (2011) provide analogous estimates in international data.
39 In particular, imputed rent on housing is the largest component of services spending, but even a careful examination
of the published documentation on the construction of this data series leaves it unclear what causes quarterly variation
in the imputations, since the most important data sources seem to be annual; similar concerns apply to other important
types of services spending. See Wilcox (1992) for a detailed discussion of the data measurement issues and their connection
to theoretical questions.
38 Carroll,

22

measure of total personal consumption expenditures, or for an even stricter version of
nondurables spending.
Second, Sommer (2007) emphasizes the importance of taking account of the effects
of measurement error and transitory shocks on high frequency consumption data. In
principle, measurement error in the level of consumption could lead to a severe downward
bias in the estimated serial correlation of measured consumption growth as distinct from
‘true’ consumption growth. The simplest solution to this problem is the classic response
to measurement error in any explanatory variable: Instrumental variables estimation.
This point is illustrated in the fact that instrumenting drastically increases the estimated
serial correlation of consumption growth.
Finally, we needed to balance the desire for the empirical exercise to match the theory
with the need for sufficiently powerful instruments. This would not be a problem if, in
empirical work, we could use once-lagged instruments as is possible for the theoretical
model. However, empirical consumption data are subject to time aggregation bias
(Working (1960), Campbell and Mankiw (1989)), which can be remedied by lagging
the time-aggregated instruments an extra period. To increase the predictive power
of the lagged instruments, we augmented with two variables traditionally known to
have predictive power: The Federal Funds rate and the expectations component of the
University of Michigan’s Index of Consumer Sentiment (cf. Carroll, Fuhrer, and Wilcox
(1994)).40
The table demonstrates three main points. First, when lagged consumption growth is
excluded from the regression equation, the classic Campbell and Mankiw (1989) result
holds: Consumption growth is strongly related to predictable income growth. Second,
when predictable income growth is excluded but lagged consumption growth is included,
the serial correlation of consumption growth is estimated to be in the range of 0.7–0.8,
consistent with Havranek, Rusnak, and Sokolova (2017) survey of the ‘habits’ literature
and very far from the benchmark random walk coefficient of zero. Finally, in the
‘horse race’ regression that pits predictable income growth against lagged consumption
growth, lagged consumption growth retains its statistical significance and large point
estimate, while the predictable income growth term becomes statistically insignificant
(and economically small).
None of these points is a peculiarity of the U.S. data. Carroll, Sommer, and Slacalek
(2011) performed similar exercises for all eleven countries for which they could obtain the
required data, and robustly obtained similar results across almost all of those countries.

6.2 Simulated Micro Empirical Estimation
Havranek, Rusnak, and Sokolova (2017)’s meta-analysis of the micro literature is consistent with Dynan (2000)’s early finding that there is little evidence of serial correlation
in household-level consumption growth. Such a lack of serial correlation is a direct
implication of the canonical Hall (1978) certainty-equivalent model with quadratic utility.
40 An extensive literature has found a broad range of other variables with predictive power for spending growth; our
experience is that results similar to those in the table can be obtained with any collection of instruments with a statistically
robust predictive capacity for consumption growth.

23

But in principle, even without habits, a more modern model like ours with precautionary
saving motives predicts that there will be some positive serial correlation in consumption
growth. To see why, think of the behavior of a household whose wealth, leading up to
date t, was near its target value (for a proof that such a target value will exist in
models of the class we are using, see Carroll (2016)). Now in period t this household
experiences a large negative transitory shock to income, pushing buffer stock wealth far
below its target. The model says the household will cut back sharply on consumption to
rebuild its buffer stock, and during that period of rebuilding the expected growth rate of
consumption will be persistently above its long-term rate (but declining asymptotically
toward that rate). That is, in a univariate analysis, consumption growth will exhibit
serial correlation.
But as the foregoing discussion suggests, the model says there is a much more direct
indicator than lagged consumption growth for current consumption growth: The lagged
value of a, the buffer stock of assets.
The same fundamental point holds for a model in which there is an explicit liquidity
constraint (our model has no such constraint, but the precautionary motive induces
something that looks like a ‘soft’ liquidity constraint). Zeldes (1989a) pointed out long
ago that the Euler equation on which the random walk proposition is based fails to
hold for consumers who are liquidity constrained; if consumers with low levels of wealth
(relative to their permanent income) are more likely to be constrained, then low wealth
consumers will experience systematically faster consumption growth than otherwisesimilar high-wealth consumers. Zeldes found empirical evidence of such a pattern, as
has a large subsequent literature.
It is less clear is whether models in this class imply that any residual serial correlation
will remain once the lagged level of assets has been controlled for. In numerical models
like ours, such quantitative questions can be answered only by numerically solving and
simulating the model, which is what we do here.
The model predicts that the relationship between Et [∆ log ct+1,i ] and at,i will be
nonlinear and downward sloping, but theory does not imply any specific functional
form. We experimented with a number of ways of capturing the role of at,i but will
spare the reader the unedifying discussion of those experiments because they all reached
conclusions similar to those of a particularly simple case, inspired by the original analysis
of Zeldes (1989a): We simply include a dummy variable that indicates whether last
period’s at,i is low. Specifically, we define āt,i as 0 if household i’s level of a in period
t is in the bottom 1 percent of the distribution, and āt,i = 1 otherwise. (We could
have chosen, say, 10 or 20 percent with qualitatively similar, though less quantitatively
impressive, results).
So, in data simulated from our SOE model, we estimate regressions of the form:41
∆ log ct+1,i = ς + χ∆ log ct,i + ηEt,i [∆ log yt+1,i ] + αāt,i + t+1,i .

(25)

Results for the frictionless model are presented the upper panel of Table 4.42 For
41 Details
42 An

of the simulation procedure are in Appendix B.2.
analogous table for the HA-DSGE model shows similar results and is available upon request.

24

our purposes, the most important conclusion is that the predictable component of
idiosyncratic consumption growth is very modest. In the version of the model that
corresponds to the thought experiment above, in which consumption growth should
have some positive serial correlation, the magnitude of that correlation is only 0.019.43
The second row of the table presents the results of a Campbell and Mankiw (1989)type exercise regressing ∆ log ct+1,i = η Et,i [∆ log yt+1,i ]. From our definitions above,
Et,i [∆ log yt+1,i ] = Et,i [log pt,i Φt+1 ψt+1,i Ψt+1 θt+1,i Θt+1 ] − log pt,i θt,i Θt ,
= log pt,i Φt − log pt,i θt,i Θt ,
= log Φt − log θt,i Θt .
Predictable income growth thus has two components: One deriving from the consumer’s
beliefs about the underlying aggregate productivity growth rate, and one deriving from
the expectation that transitory shocks will revert to their mean value of E[θΘ] = 1.
But as noted earlier, our idiosyncratic shocks are vastly larger than aggregate ones, so
virtually all of the variation in predicted income growth comes from the − log θt,i Θt term.
This explains why the η coefficient, while positive, is close to zero: The model says that
the quarterly MPC out of a known-to-be-transitory shock is small, so knowledge that
the shock will reverse itself quickly yields only modest predictability.
The existing micro literature has typically found much larger Campbell–Mankiw coefficients than ours. However, much of that literature has made little effort to determine
the extent to which the predictable component of income growth reflects permanent
underlying growth rates like Φt versus the extent to which that predictability comes
from purely transitory movements. If we were to use instruments that had no power for
the transitory component but did have power for Φt , our estimated η coefficient would
be close to 1 (because consumption growth in models of this kind settles down in the
long run to something close to the underlying growth rate of permanent income). Thus,
our view is that little can be learned from the magnitude of the η coefficient.
The third row confirms the proposition articulated above: For people with very low
levels of wealth, the model implies rapid consumption growth as they dig themselves out
of their hole.
The final row presents the results when all three terms are present. Interestingly, the
coefficient on lagged consumption growth actually increases, to about 0.06, when we
control for the other two terms. But this is still easily in the range of estimates from
0.0 to 0.1 that Havranek, Rusnak, and Sokolova (2017) indicate characterizes the micro
literature.
The final point to note from the frictionless model is the very small values of the R̄2 ’s.
Even the version of the model including all three explanatory variables can explain only
about 2 percent of the variation in consumption growth.
The table’s lower panel contains results from estimating the same regressions on the
sticky expectations version of the model. These results are virtually indistinguishable
from those obtained for the frictionless expectations model. As before, aside from the
43 We do not report standard errors because in exercises like this the only source of such errors should be the finiteness
of the sample of simulated agents; we have taken care to always simulate enough agents that the regression standard
errors are essentially zero.

25

precautionary component captured by α, idiosyncratic consumption growth is largely
unpredictable.

6.3 Simulated Small Open Economy Empirical Estimation
Table 3 presents the results that an econometrician would obtain from estimating an
equation like (24) using aggregate data generated by the same models whose micro
results are presented in Table 4. In short, it shows that even though simulated households
with sticky expectations do not exhibit any meaningful predictability of idiosyncratic
consumption growth, aggregate consumption growth in an economy populated by such
consumers exhibits a high degree of serial correlation (similar to that in empirical data).
To generate these results, we simulate the small open economy model for 200 quarters,
tracking aggregate dynamics to generate a dataset whose size is similar to the 57 years
of NIPA data used for Table 3. Because there is some variation in coefficient estimates
depending on the random number generator’s seed, we repeat the simulation exercise
100 times. Table 5 reports average point estimates and standard errors across those 100
samples.
Given the relatively long time frame of each sample, and that the idiosyncratic
shocks to income are washed away by the law of large numbers, it is feasible to use
instrumental variables techniques to obtain the coefficient on the expected growth term.
This is the appropriate procedure for comparison with empirical results in any case,
since instrumental variables estimation is the standard way of estimating the benchmark
Campbell–Mankiw model. As instruments, we use lags of consumption growth, income
growth, the wealth–permanent income ratio, and income growth over a two-year span.44
Finally, for comparison to empirical results, we take into account Sommer (2007)’s
argument (based on Wilcox (1992)) that transitory components of aggregate spending45 (hurricanes, etc) and high-frequency measurement problems introduce transitory
components in measured NIPA consumption expenditure data. Sommer finds that measurement error produces a severe downward bias in the empirical estimate of the serial
correlation in consumption growth, relative to the ‘true’ serial correlation coefficient. To
make the simulated data comparable to the measurement-error-distorted empirical data,
we multiply our model’s simulated aggregate spending data by a white noise error ξt :
C∗t = Ct × ξt .

(26)

The standard deviation of ξt is set to the value that would cause the difference between
the OLS and IV estimates of χ in the univariate regression in Table 3 (χOLS = 0.468
and χIV = 0.830): std(log(ξ)) = 0.375 × std(∆ log Ct ).
The top panel of Table 5 estimates (24) on simulated data for the frictionless economy.
The second and third rows indicate that consumption growth is moderately predictable
44 Specifically,
instruments Zt
=
{∆ log Ct−2 , ∆ log Ct−3 , ∆ log Yt−2 , ∆ log Yt−3 , At−2 , At−3 , ∆8 log Ct−2 ,
∆8 log Yt−2 }, where ∆8 log xt−2 ≡ log xt−2 − log xt−10 .
45 It is worth pointing out here that in Friedman (1957)’s original statement of the Permanent Income Hypothesis,
transitory shocks to expenditures were given equal billing with transitory shocks to income. The subsequent literature
deemphasized expenditure shocks, perhaps inappropriately.

26

by (instrumented versions of) both its own lag and expected income growth, of comparable magnitude to the empirical benchmark. However, the ‘horse race’ regression in the
bottom row reveals that neither variable is significantly predictive of consumption growth
when both are present as regressors – contrary to the robust empirical results from the
U.S. and other countries (cf Carroll, Sommer, and Slacalek (2011)). The problem is that
for both consumption growth and income growth, most of the predictive power of the
instruments stems from the serial correlation of productivity growth Φt in the model, so
the instrumented versions of the variables are highly correlated with each other. Thus
neither has distinct statistical power when they are both included.
In the sticky expectations specification (the lower panel of the table), the secondstage R̄2 ’s are all much higher than in the frictionless model, and more in keeping with
the corresponding statistics in NIPA data. This is because high frequency aggregate
consumption growth is being driven by the predictable sticky expectations dynamics.
The first two rows show that when we introduce measurement error as described above,
the OLS estimate is biased downward significantly. As suggested by the analysis of our
‘toy model’ above, the IV estimate of χ in the second row is close to the (1 − Π) = 0.75
figure that measures the proportion of consumers who do not adjust their expectations
in any given period; thus the intuition derived from the toy model survives all the
subsequent complications and elaborations. The third row reflects what would have been
found by Campbell and Mankiw had they estimated their model on data produced by
the simulated ‘sticky expectations’ economy: The coefficient on predictable component
of perceived income growth term is large and highly statistically significant.
The last row of the table presents the ‘horse race’ between the Campbell–Mankiw
model and the sticky expectations model, and shows that the dynamics of consumption
are dominated by the serial correlation in the predictable component of consumption
growth stemming from the stickiness of expectations. This can be seen not only from
the magnitude of the coefficients, but also by comparison of the second-stage R̄2 ’s,
which indicate that the contribution of predictable income growth to the predictability
of consumption growth is negligible, increasing the R̄2 from 0.261 to 0.263.

6.4 Simulated General Equilibrium Model Estimation
Table 6 reports the results of estimating regression (24) on data generated from the HADSGE model of Section 4.3; results are substantially the same as the previous analysis
for the SOE model.46
The model with frictionless expectations (top panel) implies aggregate consumption
growth that is moderately (but not statistically significantly) serially correlated when
examined in isolation (second row), but the effect “washes out” when expected income
growth and the aggregate wealth to income ratio are included in the horse race regression
(fourth row). As expected in a closed economy model, the aggregate wealth-to-income
46 Essentially similar results are obtained if we assume that households have heterogeneous discount factors, in the
style of Carroll, Slacalek, Tokuoka, and White (2017). Using a calibration of the distribution of β that approximately
matches the distribution of net worth in the U.S., the results presented in Table 6 are effectively unchanged (table available
upon request). The main results hold whether β is chosen to match aggregate asset holdings, the wealth of the median
household, or the entire distribution of wealth; it is not sensitive to the particular calibration of the model.

27

ratio At is negatively correlated with consumption growth, but its predictive power is
so slight that it is statistically insignificant in samples of only 200 quarters.
The model with sticky expectations (bottom panel) again implies a serial correlation
coefficient of consumption growth not far from 0.75 in the univariate IV regression
(second row). As in the SOE simulation, the horserace regression (fifth row) indicates
that the apparent success of the Campbell–Mankiw specification (third row) reflects the
correlation of predicted current income growth with instrumented lagged consumption
growth.

7 The Utility Costs of Sticky Expectations
To this point, we have taken Π to be exogenous (though reasonably calibrated), but the
probability of updating could depend at least partly on costs and benefits, as in ‘rational’
inattention models. In this section, we briefly examine the tradeoffs by imagining that
newborns make a once-and-for-all choice of their idiosyncratic value of Π, yielding an
intuitive approximating formula for the optimal updating frequency.47 We then conduct
a numerical exercise to compute the cost of stickiness for the calibrated models. The
utility costs of having Π equal to our calibrated value of 0.25, rather than updating every
period, are on the order of one two-thousandth of lifetime consumption, so that even
small informational costs would justify updating aggregate information only occasionally.
In the first period of life, we assume that the consumer is employed and experiences
no transitory shocks, so that market resources are nonstochastically equal to Wt ; value
can therefore be written as v(Wt , ·). There is no analytical expression for v; but, fixing
all parameters aside from the variance of the permanent aggregate shock, theoretical
considerations suggest (and numerical experiments confirm) that the consequences of
permanent uncertainty for value can be well approximated by:
2
v(Wt , ·) ≈ v̀(Wt , ·) − κσΨ
,

(27)

where v̀(Wt , ·) is the value that would be generated by a model with no aggregate
permanent shocks and κ is a constant of approximation that captures the cost of
aggregate permanent uncertainty (effectively, it is the coefficient on a first order Taylor
2
expansion of the model around the point σΨ
= 0).
Suppose now (again confirmed numerically—see Figure 2 below) that the effect of
sticky expectations is approximately to reduce value by an amount proportional to the
inverse of the updating probability:
2
e
v(Wt , ·) ≈ v̀(Wt , ·) − (κ/Π)σΨ
.

(28)

This assumption has appropriate scaling properties in three senses:
2
• If σΨ
= 0 so that there are no permanent shocks, then the cost of stickiness is zero
(given our assumption that initial perceptions are correct).
47 For

a more thorough theoretical examination of the tradeoffs in a related model, see Reis (2006a).

28

• If the probability of updating is Π = 1 so that perceptions are always accurate,
value is the same as in the frictionless model.
• If expectations never adjust, then Π = 0 and the utility cost of stickiness is
infinite, which is appropriate because consumers would be making choices based
on expectations that would eventually be arbitrarily far from the truth.
Now imagine that newborns make a once-and-for-all choice of the value of Π; a higher
Π (faster updating) is assumed to have a linear cost ι in units of normalized value.48
The newborn’s objective is therefore to choose the Π that solves:
2
max v̀(Wt , ·) − (κ/Π)σΨ
− ιΠ.
Π

(29)

The first order condition is:
2
0 = Π−2 κσΨ
− ι,
2
Π2 = (κσΨ
)/ι,

which leads to the conclusion that the consumer will pick the Π satisfying:
Π = (κ/ι)0.5 σΨ .

(30)

Thus, the speed of updating should be related directly to the utility cost of permanent
uncertainty (κ), inversely to the cost of information (cheaper information induces faster
updating), and linearly to the standard deviation of permanent aggregate shocks.
Our calibrated models can be used to numerically calculate the welfare loss from
our specification of sticky expectations as an agent’s willingness to pay at birth in
order to avoid having Π = 0.25 for his entire lifetime.49 Specifically, we calculate the
percentage loss of permanent income that would make a newborn indifferent between
being frictionless while taking the loss versus having sticky expectations.50
Using notation from the theoretical exercise above, define a newborn’s average lifetime
(normalized) value at birth under frictionless and sticky expectations as respectively:




v0 ≡ E v(Wt , ·) ,
e
v0 ≡ E e
v(Wt , ·) ,
where the expectation is taken over the distribution of state variables other than mt,i
that an agent might be born into (as well as the wage rate, in the HA-DSGE model).
We compute these quantities by averaging the discounted sum of consumption utilities
experienced by households over their simulated lifetimes. A newborn’s willingness to
pay (as a fraction of permanent income) to avoid having sticky expectations can then

48 Think of this as utility costs of paying attention to macroeconomic news instead of, say, sports news or other more
pleasurable news items; since we are examining a model that has been normalized by productivity, this could alternatively
be loosely interpreted as a time cost of gathering information.
49 Additional numeric details of the cost of stickiness calculation can be found in Appendix B.3.
50 The measure of the cost of stickiness we report is almost surely larger than the willingness to pay of an agent at a
random period of life. As newborns do not yet have a buffer stock and are on the steeper portion of their consumption
function than they will generally find themselves, consumption errors from sticky expectations are larger in the first few
periods of life, and so the utility costs of stickiness are somewhat front-loaded.

29

Figure 2 Costs of Stickiness ω and Probability of Aggregate Information Updating Π

35

Cost of stickiness (10 4)

30
25
20
15
10
5
0

2

4
6
8
10
12
Expected periods between information updates

14
1

16

Notes: The figure shows how the utility costs of updating ω depend on the probability of updating of aggregate information
Π in the SOE model.

be calculated as:

ω = 1−

e
v0
v0

1
 1−ρ

.

(31)

The bottom row of Table 2 reports the cost of stickiness for the SOE and HA-DSGE
models. A newborn in either model is willing to give up about 0.05 percent of his
permanent income to remain frictionless. These values are comparable to the findings of
Maćkowiak and Wiederholt (2015), who construct a model in which, as in Reis (2006a),
agents optimally choose how much attention to pay to economic shocks by weighing off
costs and benefits. They find (p. 1519) that the cost of suboptimal tracking of aggregate
shocks is 0.06 percent of steady state consumption.
Now that we have explained how to compute the cost of stickiness numerically, we can
test our supposition in equation (28) that the cost of stickiness might have a roughly
inverse linear relationship to Π. Figure 2 plots numerically computed ω for various
values of Π−1 and is close to linear, as we speculated.

30

8 Muth–Lucas–Pischke and Reis (2006a) Redux
Now that our calibrations and results have been presented, we are in position to make
some quantitative comparisons of our model to two principal alternatives to habit
formation (or our model) for explaining excess smoothness in consumption growth.
The longest-standing rival to habit formation as an explanation of consumption sluggishness is what we will call the Muth–Lucas–Pischke (henceforth, MLP) framework.
The idea is not that agents are inattentive, but instead that they have imperfect information on which they (perfectly attentively) perform an optimal signal extraction
problem.
Muth (1960)’s agents could observe only the level of their income, but not the split
between its permanent and transitory components. He derived the optimal (meansquared-error-minimizing) method for estimating the level of permanent income from
the observed signal about the level of actual income. Lucas (1973) applied the same
mathematical toolkit to solve a model in which firms are assumed to be unable to
distinguish idiosyncratic from aggregate shocks. Pischke (1995) combines the ideas of
Muth and Lucas and applies the result to the analysis of micro data: His consumers
have no ability at all to perceive whether income shocks that hit them are aggregate
or idiosyncratic, transitory or permanent. They see only their income, and do signal
extraction on it.
Pischke calibrates his model with micro data in which he calculates that transitory
shocks vastly outweigh permanent shocks.51 So, when a shock arrives, consumers always
interpret it as being almost entirely transitory and change their consumption by little.
However, macroeconometricians have long known that aggregate income shocks are close
to permanent. When an aggregate permanent shock comes along, Pischkian consumers
spend very little of it, confounding the aggregate permanent shock’s effect on their
income with the mainly transitory idiosyncratic shocks that account for most of the
total variation in their income. This misperception causes sluggishness in aggregate
consumption dynamics in response to aggregate shocks. (See below for a more precise
formulation of this point).
In its assumption that consumers fail to perceive aggregate shocks immediately and
fully, Pischke’s model resembles ours. However, few papers in the literature after Pischke
(1995) have adopted his assumption that households have no idea, when an idiosyncratic
income shock occurs, whether it is transitory or permanent. Especially in the last decade
or so, the literature instead has almost always assumed that consumers can perfectly
perceive the transitory and permanent components of their income.52
51 Pischke’s estimates constructed from the Survey of Income and Program Participation are rather different from the
magnitudes of transitory and permanent shocks estimated in the extensive literature—mostly subsequent to Pischke’s
paper—cited in our calibration section above.
52 The presumption that permanent idiosyncratic shocks are easily observed is bolstered by the work of Low, Meghir,
and Pistaferri (2010), who find that most ‘permanent’ changes to individual income income are concentrated in periods
when people change jobs or become unemployed or reemployed. It is simply not plausible to assume that consumers are
not aware their income has permanently changed when they take a new job or are fired from an existing one. Furthermore,
there are at least some shocks whose transitory nature is impossible to misperceive; the best example is lottery winnings
in Norway, see again Fagereng, Holm, and Natvik (2017). The consumption responses to those shocks resemble the
responses measured in the previous literature to shocks that economists presumed (contra Pischke) that consumers knew

31

Granting our choice to assume that consumers correctly perceive the events that are
idiosyncratic to them (job changes, lottery winnings, etc), there is still a potential role
for application of the MLP framework: Instead of assuming sticky expectations, we
could instead have assumed that consumers perform a signal extraction exercise on
only the aggregate component of their income, because they cannot perceive the transitory/permanent split for the (tiny) part of their income change that reflects aggregate
macroeconomic developments.
In principle (and more plausibly than under Pischke’s assumption of complete ignorance), such confusion could generate excess smoothness. To see how, note that in the
Muth framework, agents update their estimate of permanent income according to an
equation of the form:53
P̂t+1 = ΠYt+1 + (1 − Π)P̂t ,

(32)

We can now consider the dynamics of aggregate consumption in response to the arrival
of an aggregate shock that (unbeknownst to the consumer) is a permanent shock. The
consumer spends Π of the shock in the first period, leaving (1 − Π) unspent because
that reflects the average transitory component of an undifferentiated shock. However,
since the shock really was permanent, income next period does not fall back as the
consumer guessed it would on the basis of the mistaken belief that (1 − Π) of the
shock was transitory. The next-period consumer treats this surprise as a positive shock
relative to expected income, and spends the same proportion Π out of the perceived
new shock. These dynamics continue indefinitely, but with each successive perceived
shock (and therefore each consumption increment) being smaller than the last by the
proportion (1 − Π). Thus, after a true permanent shock received in period t, the fullinformation prediction of the expected dynamics of future consumption changes would
be ∆Ct+n+1 = (1 − Π)∆Ct+n + t+n .54
At first blush, this predictability in consumption growth would appear to be a violation
of Hall (1978)’s proof that, for consumers who make rational estimates of their permanent
income, consumption must be a random walk. The reconciliation is that what Hall proves
is that consumption must be a random walk with respect to the knowledge the consumer
to be transitory. If consumers respond to such shocks in ways similar to their responses to unambiguously transitory
shocks like lottery winnings, it seems hard to accept Pischke’s crucial assumption that consumers treat all income shocks
identically because they cannot perceive whether any given shock is transitory or permanent. A further motivation for
our choice to assume that consumers perceive their idiosyncratic shocks is that our strategy has been to deviate as little as
possible from the well-understood benchmark models in the micro consumption literature, which has become sufficiently
widely used that they are the natural base upon which to build. A final piece of evidence comes from some newly
collected data from the Federal Reserve Bank of New York’s Survey of Consumer Expectations. Karahan, Mihaljevich,
and Pilossoph (2017) report on results from an experiment in which consumers were asked to forecast their future income.
The actual realizations of the same consumer’s income were collected in a subsequent wave of the survey. The principal
result is that consumers’ mean forecast error was very close to zero. The authors of the post (entitled “Understanding
Permanent and Temporary Income Shocks”) present the results as a confirmation of modern models’ standard assumption
that consumers have accurate perceptions of the dynamics of their income.
53 P̂ is used to denote that households do an optimal signal-extraction (as opposed to having sticky expectations
t
resulting in Pet ).
54 The reciprocal logic would apply in the case of a shock that was known by the econometrician to be perfectly
transitory, generating the same serial correlation in predictable consumption growth as in the case of the known-to-bepermanent shock. The only circumstance under which this serial correlation does not arise is when the econometrician
has exactly the same beliefs as the consumer about the breakdown of the shock between transitory components. More
precisely, it is still the case that the serial correlation coefficient on the predictable component of consumption growth is
(1 − Π). But that predictable component itself is now zero, and (1 − Π) × 0 = 0.

32

has. The random walk proposition remains true for consumers whose knowledge base
contains only the perceived level of aggregate income. Our thought experiment was to
ask how much predictability would be found by an econometrician who knows more than
the consumer about the level of aggregate permanent income.
The in-principle reconciliation of econometric evidence of predictability/excess
smoothness in consumption growth, and the random walk proposition, is therefore that
the econometricians who are making their forecasts of aggregate consumption growth
use other variables in addition to the lagged history of aggregate income itself (and that
those variables have useful predictive power).55
We now turn to the question of whether the Muth–Lucas–Pischke story is a good
quantitative explanation of the size of aggregate excess smoothness. Appendix C.4 shows
that, defining the signal-to-noise ratio τ = σΨ /σΘ , Muth’s derivations imply that the
optimal updating coefficient is:56
p
(33)
Π = ϕ 1 + ϕ2 /4 − (1/2)ϕ2
Plugging our calibrations of σΨ and σΘ from section 5 into (33), the model yields a
predicted value of (1 − Π) ≈ 0.17—very far below the approximately 0.6 estimate from
Havranek, Rusnak, and Sokolova (2017) and even farther below our estimate of roughly
0.7–0.8 for U.S. data. This reflects the well-known fact that aggregate income is hard to
distinguish from a random walk; if it were perceived to be a perfect random walk with
no transitory component at all, the serial correlation in its growth would be zero.57
Considerations similar to the foregoing apply, at least to some degree, to the Reis
(2006a) model. Moreover, that model has a further disadvantage relative to any of the
other three stories (habits, MLP, or our model). In Reis’s model consumers update
their information on a regular schedule; under a plausible calibration of the model,
once a year. One implication of the model is that the change in consumption at the
next reset is unpredictable; this implies that aggregate consumption growth would be
unpredictable at any horizon beyond, say, the one-year horizon. But, the habit formation
assumption was incorporated into macroeconomic models in large part to explain the
fact that consumption growth is forecastable over extended periods—well beyond the
one year horizon. A calibration of the Reis model in which consumers update once a
year therefore leaves much of the original puzzle in place.58
55 This is logically identical to Pischke’s analysis of the case where the macroeconometrician knows that aggregate
shocks are permanent, but the microeconomic consumers do not perceive those aggregate permanent shocks.
56 As always in a Muth-type model, the consumer is assumed to know σ and σ .
Ψ
Θ
57 A further problem with the MLP approach is that it seems implausible to assume that the typical consumer would
do a sophisticated Muthian signal extraction problem (really, a special case of the Kalman filter) on a single observed
aggregate variable (aggregate income), when they could do much better either by adding a few more variables that
are equally easy to observe (interest rates, past consumption growth, etc). If they were really so intently focused on
understanding where the aggregate economy is, they could do better yet, and much more easily, just by reading the
available news stories reporting on professional forecasters’ forecasts. Discomfort with this somewhat schizophrenic set of
assumptions is why in work after Lucas (1973), Lucas moved away from his assumption that microeconomic agents have
imperfect information about aggregate data.
58 A final critique of the Reis model is that, while its simplifying assumptions yield elegant and intuitive results, it
is too stylized to be of much practical use in answering many questions beyond its narrow focus on matching aggregate
smoothness. A fiscal policymaker who wants to understand how various alternative policies might play out over the
course of the business cycle would have a difficult time extracting plausible answers to questions like “how much difference
would it make to consumption if our fiscal stimulus took the form of extended unemployment benefits versus a temporary

33

9 Conclusion
Using a traditional utility function that does not incorporate habits, the literature on
the microfoundations of consumption behavior has made great strides over the past
couple of decades in constructing models that are faithful to many of the microeconomic
facts about consumption, income dynamics, and the distribution of wealth. But over
roughly the same interval, habit formation has gone from an exotic hypothesis to a
standard assumption in the representative agent macroeconomics literature, because
habits allow representative agent models to match the measured smoothness in aggregate
consumption growth. This conflict, thrown into sharp focus by the recent meta-analysis
of both literatures by Havranek, Rusnak, and Sokolova (2017), is arguably the most
important puzzle in the microfoundations of macroeconomic consumption behavior.
Our argument is that this conflict can be resolved by applying insights from the
literature on ‘inattention’ that has developed robustly since the early contributions of
Sims (2003), Woodford (2002), Mankiw and Reis (2002), and others. In the presence
of such inattention, aggregation of the behavior of microeconomic consumers without
habits generates aggregate consumption dynamics that match the ‘excess smoothness’
facts that have induced the representative agent literature to embrace habits.
The sticky expectations assumption is more attractive for modeling consumption than
for other areas where it has been more widely applied, because in the consumption
context there is a well-defined utility-based metric for calculating the cost of sticky
expectations (in contrast, say, with models in which households’ inflation expectations
are sticky; the cost of misperceiving the inflation rate is unclear). The cost to consumers
of our proposed degree of macroeconomic inattention is quite modest, for reasons that
will be familiar to anyone who has worked with both micro and macro data: Idiosyncratic variation is vastly greater than aggregate variation. This means that the small
imperfections in macroeconomic perceptions proposed here have very modest utility
consequences. So long as consumers respond appropriately to their idiosyncratic shocks
(which we assume they do), the failure to keep completely up-to-date with aggregate
developments simply does not matter much.
While some previous papers have mooted the idea that inattention (or imperfect
information) might generate excess smoothness, the modeling question is a quantitative
one (‘how much excess smoothness can a sensible model explain?’). We argue that
the imperfect information models and mechanisms proposed in the prior literature are
quantitatively unable simultaneously to match the micro and macro quantitative facts,
while our model matches all the main stylized facts from both literatures.
In future work, it would be interesting to enrich the model so that it has plausible
implications for how the degree of attention might vary over time or across people,
and to connect the model to the available expectations data (for example, measures
of consumer sentiment, or measures of uncertainty constructed from news sources, cf
income tax cut.” Our model’s much greater fidelity to the microeconomic data means it might be able to provide at
least somewhat plausible answers to these kinds of questions. (Our model is an example of the broader movement in
macroeconomics in recent years from the provision of stylized analytical toy models like Reis’s to the construction of
models that attempt to be taken seriously for a reasonable range of quantitative as well as qualitative predictions.)

34

Baker, Bloom, and Davis (2016)). Such work might be particularly useful in any attempt
to understand how behavioral dynamics change between normal times (in which news
coverage of macroeconomic dynamics is not front-page material) and crisis times (in
which it is).

35

Table 1 Calibration

γ
k
2
σΘ
2
σΨ

K̆/K̆ γ
K̆
W̆
r̆
R̆

0.36
0.941/4
0.00001
0.00004

Macroeconomic Parameters
Capital’s Share of Income
Depreciation Factor
Variance Aggregate Transitory Shocks
Variance Aggregate Permanent Shocks

Steady State of Perfect Foresight DSGE Model
(σΨ = σΘ = σψ = σθ = ℘ = D = 0, Φt = 1)
12.0
SS Capital to Output Ratio
48.55
SS Capital to Labor Productivity Ratio (= 121/(1−γ) )
2.59
SS Wage Rate (= (1 − γ)K̆ γ )
0.03
SS Interest Rate (= γ K̆ γ−1 )
1.015
SS Between-Period Return Factor (= k + r̆)

βSOE
βDSGE
Π

2.
0.970
0.986
0.25

Preference Parameters
Coefficient of Relative Risk Aversion
SOE Discount Factor
HA-DSGE Discount Factor (= R̆−1 )
Probability of Updating Expectations (if Sticky)

σθ2
σψ2
℘
D

0.120
0.003
0.050
0.005

Idiosyncratic Shock Parameters
Variance Idiosyncratic Tran Shocks (=4× Annual)
Variance Idiosyncratic Perm Shocks (= 14 × Annual)
Probability of Unemployment Spell
Probability of Mortality

ρ

36

Table 2 Equilibrium Statistics
SOE Model
Frictionless
Sticky
Means
A
C

7.49
2.71

Standard Deviations
Aggregate Time Series (‘Macro’)
log A
0.332
∆ log C
0.010
∆ log Y
0.010
Individual Cross Sectional (‘Micro’)
log a
0.926
log c
0.790
log p
0.796
log y|y > 0
0.863
∆ log c
0.098
Cost of Stickiness

HA-DSGE Model
Frictionless Sticky

7.43
2.71

56.85
3.44

56.72
3.44

0.321
0.007
0.010

0.276
0.010
0.007

0.272
0.005
0.007

0.927
0.791
0.796
0.863
0.098

1.015
0.598
0.796
0.863
0.054

1.014
0.599
0.796
0.863
0.055

4.82e–4

4.51e–4

Notes: The cost of stickiness is calculated as the proportion by which the permanent income of a
newborn frictionless consumer would need to be reduced in order to achieve the same reduction of
expected value associated with forcing them to become a sticky expectations consumer.

37

Table 3 Aggregate Consumption Dynamics in US Data
∆ log Ct+1 = ς + χ∆ log Ct + η Et [∆ log Yt+1 ] + αAt + t+1
Measure of Consumption
Independent Variables

OLS
or IV

2nd Stage
R̄2

Nondurables and Services
∆ log Ct ∆ log Yt+1
At
∗∗∗
0.468
OLS
0.216
(0.076)
0.830∗∗∗
IV
0.278
(0.098)
0.587∗∗∗
IV
0.203
(0.110)
−0.17e−4 IV
−0.005
(5.71e−4)
∗∗∗
∗
0.618
0.304
0.305 −4.96e−4∗ IV
(0.159)
(0.161)
(2.94e−4)
Memo: For instruments Zt , ∆ log Ct = Zt ζ, R̄2 = 0.358
Nondurables
∆ log Ct ∆ log Yt+1
0.200∗∗∗
(0.058)
0.762∗∗∗
(0.284)
0.849∗∗
(0.357)

KP p-val
Hansen J p val

0.222
0.439
0.263
0.319
0.081
0.181
0.415
0.825

At
OLS

0.036

IV

0.083

IV

0.061

9.09e−4 IV
0.008
(9.05e−4)
0.620∗∗
0.313 −3.25e−4 IV
0.077
(0.292)
(0.286)
(8.32e−4)
Memo: For instruments Zt , ∆ log Ct = Zt ζ, R̄2 = 0.080

0.504
0.727
0.398
0.731
0.118
0.446
0.523
0.821

Notes: Data source is NIPA, 1960Q1–2016Q. Robust standard errors are in parentheses. Instruments
Zt = {∆ log Ct−2 , ∆ log Ct−3 , ∆ log Yt−2 , ∆ log Yt−3 , At−2 , At−3 , ∆8 log Ct−2 , ∆8 log Yt−2 , lags 2
and 3 of differenced Fed funds rate, lags 2 and 3 of the Michigan Index of Consumer Sentiment
Expectations}.
The penultimate column reports the R̄2 from a regression of the dependent
variable on the RHS variables (instrumented, when indicated); the final column reports two tests
of instrument validity: The p-value from the Kleibergen–Paap Wald rk F statistic of first-stage
instrument validity (top), and the p-value from the Hansen–Sargan overidentification test (bottom).
{∗ , ∗∗ , ∗∗∗ } = Statistical significance at {10, 5, 1} percent.

38

Table 4 Micro Consumption Regression on Simulated Data

∆ log ct+1,i = ς + χ∆ log ct,i + ηEt,i [∆ log yt+1,i ] + αāt,i + t+1,i .
Model of
Expectations

χ

η

R̄2

α

Frictionless
0.019
(–)

0.000
0.011
(–)

0.061
(–)

0.016
(–)

0.004
−0.190
(–)
−0.183
(–)

0.010
0.017

Sticky
0.012
(–)

0.000
0.011
(–)

0.051
(–)

0.015
(–)

0.004
−0.191
(–)
−0.185
(–)

0.010
0.016

Notes: Et,i is the expectation from the perspective of person i in period t; ā is a dummy variable indicating
that agent i is in the top 99 percent of the normalized a distribution. Simulated sample size is large enough
such that standard errors are effectively zero. Sample is restricted to households with positive income in
period t. The notation “(—)” indicates that standard errors are close to zero, given the very large simulated
sample size.

39

Table 5 Aggregate Consumption Dynamics in SOE Model
∆ log Ct+1 = ς + χ∆ log Ct + ηEt [∆ log Yt+1 ] + αAt + t+1
Expectations : Dep Var
Independent Variables

OLS
or IV

2nd Stage
R̄2

Frictionless : ∆ log C∗t+1 (with measurement
At
∆ log C∗t ∆ log Yt+1
•••
0.295
OLS
(0.066)
0.660••
IV
(0.309)
0.457••
IV
(0.209)
−6.92e–4
IV
(5.87e–4)
0.420
0.258
0.45e–4
IV
(0.428)
(0.365)
(9.51e–4)
Memo: For instruments Zt , ∆ log C∗t = Zt ζ,

KP p-val
Hansen J p-val

error C∗t = Ct × ξt );
0.087
0.040

0.237
0.600
0.035
0.059
0.421
0.026
0.000
0.365
0.041
0.516
0.529
R̄2 = 0.039; var(log(ξt )) = 5.99e–6

Sticky : ∆ log C∗t+1 (with measurement error C∗t = Ct × ξt );
∆ log C∗t ∆ log Yt+1
At
•••
0.508
OLS
0.263
(0.058)
0.802•••
IV
0.260
0.000
(0.104)
0.554
•••
0.859
IV
0.198
0.060
(0.182)
0.233
−8.26e–4•• IV
0.066
0.000
(3.99e–4)
0.002
0.660•••
0.192
0.60e–4
IV
0.261
0.359
(0.187)
(0.277)
(5.03e–4)
0.546
∗
2
Memo: For instruments Zt , ∆ log Ct = Zt ζ, R̄ = 0.260; var(log(ξt )) = 5.99e–6
Notes: Reported statistics are the average values for 100 samples of 200 simulated quarters each.
Bullets indicate that the average sample coefficient divided by average sample standard error is
outside of the inner 90%, 95%, and 99% of the standard normal distribution.
Instruments Zt =
{∆ log Ct−2 , ∆ log Ct−3 , ∆ log Yt−2 , ∆ log Yt−3 , At−2 , At−3 , ∆8 log Ct−2 , ∆8 log Yt−2 }.

40

Table 6 Aggregate Consumption Dynamics in HA-DSGE Model
∆ log Ct+1 = ς + χ∆ log Ct + ηEt [∆ log Yt+1 ] + αAt + t+1
Expectations : Dep Var
Independent Variables

OLS
or IV

2nd Stage
R̄2

Frictionless : ∆ log C∗t+1 (with measurement
At
∆ log C∗t ∆ log Yt+1
•••
0.189
OLS
(0.072)
0.476
IV
(0.354)
0.368
IV
(0.321)
−0.34e–4
IV
(0.98e–4)
0.289
0.214
0.01e–4
IV
(0.463)
(0.583)
(1.87e–4)
Memo: For instruments Zt , ∆ log C∗t = Zt ζ,

KP p-val
Hansen J p-val

error C∗t = Ct × ξt );
0.036
0.020

0.318
0.556
0.017
0.107
0.457
0.015
0.000
0.433
0.020
0.572
0.531
R̄2 = 0.023; var(log(ξt )) = 4.16e–6

Sticky : ∆ log C∗t+1 (with measurement error C∗t = Ct × ξt );
∆ log C∗t ∆ log Yt+1
At
•••
0.467
OLS
0.223
(0.061)
0.773•••
IV
0.230
0.000
(0.108)
0.542
•••
0.912
IV
0.145
0.105
(0.245)
0.187
−0.97e–4• IV
0.059
0.000
(0.56e–4)
0.002
0.670•••
0.171
0.12e–4
IV
0.231
0.460
(0.181)
(0.363)
(0.86e–4)
0.551
∗
2
Memo: For instruments Zt , ∆ log Ct = Zt ζ, R̄ = 0.232; var(log(ξt )) = 4.16e–6
Notes: Reported statistics are the average values for 100 samples of 200 simulated quarters each.
Bullets indicate that the average sample coefficient divided by average sample standard error is
outside of the inner 90%, 95%, and 99% of the standard normal distribution.
Instruments Zt =
{∆ log Ct−2 , ∆ log Ct−3 , ∆ log Yt−2 , ∆ log Yt−3 , At−2 , At−3 , ∆8 log Ct−2 , ∆8 log Yt−2 }.

41

References
Abel, Andrew B. (1990): “Asset Prices under Habit Formation and Catching Up with the
Joneses,” American Economic Review, 80(2), 38–42.
Akerlof, George A., and Janet L. Yellen (1985): “A Near-rational Model of the
Business Cycle, with Wage and Price Intertia,” The Quarterly Journal of Economics, 100(5),
823–38.
Alvarez, Fernando, Luigi Guiso, and Francesco Lippi (2012): “Durable Consumption
and Asset Management with Transaction and Observation Costs,” American Economic
Review, 102(5), 2272–2300.
Baker, Scott R, Nicholas Bloom, and Steven J Davis (2016): “Measuring economic
policy uncertainty,” The Quarterly Journal of Economics, 131(4), 1593–1636.
Blanchard, Olivier J. (1985): “Debt, Deficits, and Finite Horizons,” Journal of Political
Economy, 93(2), 223–247.
Boldrin, Michele, Lawrence J. Christiano, and Jonas D. Fisher (2001): “Habit
Persistence, Asset Returns and the Business Cycle,” American Economic Review, 91(1),
149–66.
Browning, Martin, and M. Dolores Collado (2001): “The Response of Expenditures
to Anticipated Income Changes: Panel Data Estimates,” American Economic Review, 91(3),
681–692.
Browning, Martin, and Thomas F. Crossley (2001): “The Life-Cycle Model of
Consumption and Savings,” Journal of Economic Perspectives, 15(3), 3–22.
Calvo, Guillermo A. (1983): “Staggered Contracts in a Utility-Maximizing Framework,”
Journal of Monetary Economics, 12(3), 383–98.
Campbell, John, and Angus Deaton (1989): “Why is Consumption So Smooth?,” The
Review of Economic Studies, 56(3), 357–373, http://www.jstor.org/stable/2297552.
Campbell, John Y., and N. Gregory Mankiw (1989): “Consumption, Income, and
Interest Rates: Reinterpreting the Time-Series Evidence,” in NBER Macroeconomics Annual,
1989, ed. by Olivier J. Blanchard, and Stanley Fischer, pp. 185–216. MIT Press, Cambridge,
MA, http://www.nber.org/papers/w2924.pdf.
Carroll, Christopher D. (2003): “Macroeconomic Expectations of Households and
Professional Forecasters,” Quarterly Journal of Economics, 118(1), 269–298, http:
//econ.jhu.edu/people/ccarroll/epidemiologyQJE.pdf.
(2016):
“Theoretical
Foundations
of
Buffer
Stock
Saving,”
manuscript, Department of Economics, Johns Hopkins University, Available at
http://econ.jhu.edu/people/ccarroll/papers/BufferStockTheory.

42

Carroll,
Christopher
D.,
Jeffrey
C.
Fuhrer,
and
David
W.
Wilcox
(1994):
“Does
Consumer
Sentiment
Forecast
Household
Spending?
If So, Why?,” American Economic Review, 84(5), 1397–1408,
http://econ.jhu.edu/people/ccarroll/SentAERCarrollFuhrerWilcox.pdf.
Carroll,
Christopher D.,
and Miles S. Kimball (1996):
Concavity of the Consumption Function,”
Econometrica,
64(4),
http://econ.jhu.edu/people/ccarroll/concavity.pdf.
Carroll, Christopher D., and Andrew A. Samwick (1997):
Precautionary Wealth,” Journal of Monetary Economics, 40(1), 41–71.

“On the
981–992,

“The Nature of

Carroll,
Christopher
D,
Jiri
Slacalek,
and
Kiichi
Tokuoka
(2015):
“Buffer-Stock Saving in a Krusell–Smith World,” Economics Letters,
132,
97–100,
At
http://econ.jhu.edu/people/ccarroll/papers/cstKS/;
extended
version
available
as
ECB
Working
Paper
number
1633,
https://www.ecb.europa.eu/pub/pdf/scpwps/ecbwp1633.pdf.
Carroll, Christopher D., Jiri Slacalek, Kiichi Tokuoka, and Matthew N. White
(2017): “The Distribution of Wealth and the Marginal Propensity to Consume,” Quantitative
Economics, 8, 977–1020, At http://econ.jhu.edu/people/ccarroll/papers/cstwMPC.
Carroll, Christopher D., Martin Sommer, and Jiri Slacalek (2011): “International
Evidence on Sticky Consumption Growth,” Review of Economics and Statistics, 93(4), 1135–
1145, http://econ.jhu.edu/people/ccarroll/papers/cssIntlStickyC/.
Carroll, Christopher D, Matthew N White, and Team Econ-ARK (2017):
“econ-ark/HARK: 0.8.0,” Available at via doi:10.5281/zenodo.1001068 or at https:
//doi.org/10.5281/zenodo.1001068.
Chari, V. V., Patrick J. Kehoe, and Ellen R. McGrattan (2005): “A Critique of
Structural VARs Using Real Business Cycle Theory,” working paper 631, Federal Reserve
Bank of Minneapolis.
Chetty, Raj, and Adam Szeidl (2016):
Formation,” Econometrica, 84, 855–890.

“Consumption Commitments and Habit

Christiano, Laurence J., Martin Eichenbaum, and Charles L. Evans (2005):
“Nominal Rigidities and the Dynamic Effects of a Shock to Monetary Policy,” Journal of
Political Economy, 113(1), 1–45.
Cochrane, John H. (1991): “The Sensitivity of Tests of the Intertemporal Allocation of
Consumption to Near-Rational Alternatives,” American Economic Review, 79, 319–37.
Coibion, Olivier, and Yuriy Gorodnichenko (2015): “Information Rigidity and the
Expectations Formation Process: A Simple Framework and New Facts,” American Economic
Review, 105(8), 2644–2678.
Constantinides, George M. (1990): “Habit Formation: A Resolution of the Equity
Premium Puzzle,” Journal of Political Economy, 98(3), 519–543.

43

Deaton, Angus S. (1992): Understanding Consumption. Oxford University Press, New York.
Dynan, Karen E. (2000): “Habit Formation in Consumer Preferences: Evidence from Panel
Data,” American Economic Review, 90(3), http://www.jstor.org/stable/117335.
Edge, Rochelle M, Thomas Laubach, and John C Williams (2007): “Learning and
shifts in long-run productivity growth,” Journal of Monetary Economics, 54(8), 2421–2438.
Fagereng, Andreas, Martin B. Holm, and Gisle J. Natvik (2017):
Heterogeneity and Household Balance Sheets,” discussion paper, Statistics Norway.

“MPC

Fernald, John G., Robert Hall, James Stock, and Mark Watson (2017): “The
Disappointing Recovery of Output after 2009,” Brookings Papers on Economic Activity,
Spring.
Friedman, Milton A. (1957): A Theory of the Consumption Function. Princeton University
Press.
Fuhrer, Jeffrey C. (2000): “Habit Formation in Consumption and its Implications
for Monetary Policy Models,” American Economic Review, 90(3), 367–390, http:
//www.jstor.org/stable/117334.
(2017a): “Expectations as a Source of Macroeconomic Persistence: Evidence from
Survey Expectations in a Dynamic Macro Model,” Journal of Monetary Economics, 86, 22–
55.
(2017b): “Intrinsic Persistence in Expectations: Evidence from Micro Data,”
Presentation at NBER Summer Institute, Federal Reserve Bank of Boston.
Gabaix, Xavier (2014): “A Sparsity-Based Model of Bounded Rationality,” The Quarterly
Journal of Economics, 129(4), 1661–1710.
Gruber, Joseph W. (2004): “A Present Value Test of Habits and the Current Account,”
Journal of Monetary Economics, 51(7), 1495–1507.
Hall, Robert E. (1978): “Stochastic Implications of the Life-Cycle/Permanent Income
Hypothesis: Theory and Evidence,” Journal of Political Economy, 96, 971–87, Available
at http://www.stanford.edu/~rehall/Stochastic-JPE-Dec-1978.pdf.
Havranek, Tomas, Marek Rusnak, and Anna Sokolova (2017): “Habit formation in
consumption: A meta-analysis,” European Economic Review, 95, 142–167.
Jermann, Urban J. (1998): “Asset Pricing in Production Economies,” Journal of Monetary
Economics, 42(2), 257–75.
Johnson, David S., Jonathan A. Parker, and Nicholas S. Souleles (2006):
“Household Expenditure and the Income Tax Rebates of 2001,” American Economic Review,
96(5), 1589–1610.
Jorgenson, Dale W., Mun S. Ho, and Kevin J. Stiroh (2008): “A Retrospective Look at
the U.S. Productivity Growth Resurgence,” Journal of Economic Perspectives, 22(1), 3–24.

44

Karahan, Fatih, Sean Mihaljevich, and Laura Pilossoph (2017): “Understanding
Permanent and Temporary Income Shocks,” URL link retrieved on 03/02/2018 here.
Krusell, Per, and Anthony A. Smith (1998): “Income and Wealth Heterogeneity in the
Macroeconomy,” Journal of Political Economy, 106(5), 867–896.
Kueng, Lorenz (2015): “Explaining Consumption Excess Sensitivity with Near-Rationality:
Evidence from Large Predetermined Payments,” working paper 21772, National Bureau of
Economic Research.
Low, Hamish, Costas Meghir, and Luigi Pistaferri (2010): “Wage Risk and
Employment Over the Life Cycle,” American Economic Review, 100(4), 1432–1467.
Lucas, Robert E. (1973): “Some International Evidence on Output-Inflation Tradeoffs,”
American Economic Review, 63, 326–334.
Maćkowiak, Bartosz, and Mirko Wiederholt (2015): “Business Cycle Dynamics under
Rational Inattention,” The Review of Economic Studies, 82(4), 1502–1532.
Mankiw, N. Gregory, and Ricardo Reis (2002): “Sticky Information Versus Sticky Prices:
A Proposal to Replace the New Keynesian Phillips Curve,” Quarterly Journal of Economics,
117(4), 1295–1328.
Morris, Stephen, and Hyun Song Shin (2006): “Inertia of Forward-Looking
Expectations,” The American Economic Review, 96(2), 152–157.
Muth, John F. (1960): “Optimal Properties of Exponentially Weighted Forecasts,” Journal
of the American Statistical Association, 55(290), 299–306.
Nielsen, Helena Skyt, and Annette Vissing-Jorgensen (2006): “The Impact of Labor
Income Risk on Educational Choices: Estimates and Implied Risk Aversion,” Manuscript.
Pischke, Jörn-Steffen (1995): “Individual Income, Incomplete Information, and Aggregate
Consumption,” Econometrica, 63(4), 805–40.
Reis, Ricardo (2006a): “Inattentive Consumers,” Journal of Monetary Economics, 53(8),
1761–1800.
(2006b): “Inattentive Producers,” Review of Economic Studies, 73(3), 793–821.
Sims,
Christopher
(2003):
“Implications
of
Rational
Inattention,”
Journal
of
Monetary
Economics,
50(3),
665–690,
available
at
http://ideas.repec.org/a/eee/moneco/v50y2003i3p665-690.html.
Sommer, Martin (2007): “Habit Formation and Aggregate Consumption Dynamics,”
Advances in Macroeconomics, 7(1), Article 21.
Staiger, Douglas, James H. Stock, and Mark W. Watson (2001): “Prices Wages and
the US NAIRU in the 1990s,” in The Roaring Nineties: Can Full Employment Be Sustained?,
ed. by Alan B. Krueger, and Robert Solow. The Russell Sage Foundation and Century Press,
New York.

45

Storesletten, Kjetil, Chris I. Telmer, and Amir Yaron (2004): “Consumption and
Risk Sharing Over the Life Cycle,” Journal of Monetary Economics, 51(3), 609–633.
Weber, Christian E. (2002): “Intertemporal Non-Separability and ‘Rule-Of-Thumb’
Consumption,” Journal of Monetary Economics, 49, 293–308.
Wilcox, David W. (1992): “The Construction of U.S. Consumption Data: Some Facts and
Their Implications for Empirical Work,” American Economic Review, 82(4), 922–941.
Woodford, Michael (2002): “Imperfect Common Knowledge and the Effects of Monetary
Policy,” in Knowledge, Information and Expectations in Modern Macroeconomics, ed. by
P. Aghion, R. Frydman, J. Stiglitz, and M. Woodford. Princeton University Press, Princeton.
Working, Holbrook (1960): “Note on the Correlation of First Differences of Averages in a
Random Chain,” Econometrica, 28(4), 916–918.
Zeldes, Stephen P. (1989a): “Consumption and Liquidity Constraints: An Empirical Investigation,” Journal of Political Economy, 97, 305–46, Available at http:
//www.jstor.org/stable/1831315.
(1989b): “Optimal Consumption with Stochastic Income: Deviations from Certainty
Equivalence,” Quarterly Journal of Economics, 104(2), 275–298.

46

Appendix
A Representative Agent (RA) Model
This appendix presents a representative agent model for analyzing the consequences of
sticky expectations in a DSGE framework while abstracting from idiosyncratic income
shocks and the death (and replacement) of households. It builds upon the modeling
assumptions in Section 4.1 to formulate the representative agent model, then presents
simulated results analogous to Section 6. The primary advantage of this model is
that it allows fast analysis of sticky expectations in a closed economy, yielding very
similar results to the heterogeneous agents DSGE model with less than a minute of
computation, rather than a few hours. However, the model is not truly “representative
agent” under sticky expectations, as the representative household’s perception of the
aggregate state is “smeared” over the state space. As presented below, the realized level
of consumption represents the average level of consumption chosen by the “multiple
minds” of the representative household.

A.1 Model and Solution
The representative agent’s state variables at the time of its consumption decision are
the level of market resources Mt , the productivity of labor Pt , and the growth rate
of productivity Φt . Idiosyncratic productivity shocks ψ and θ do not exist, and the
possibility of death is irrelevant; aggregate permanent and transitory productivity shocks
Ψ and Θ are distributed as usual.
The representative agent’s problem can be written in Bellman form as:59



V(Mt , Pt , Φt ) = max u(Ct ) + E V(Mt+ 1 , Pt+1 , Φt+1 )
Ct

At

s.t.
= Mt − Ct .

Normalizing the representative agent’s problem by the productivity level Pt as in the
SOE and HA-DSGE models, the problem’s state space can be reduced to:60



V(Mt , Φt ) = max u(Ct ) + β Et (Φt+1 Ψt+1 )1−ρ V(Mt+1 , Φt+1 )
(34)
Ct

At

s.t.
= Mt − C t .

Noting that the return to (normalized) end-of-period assets for next period’s market
t+1
= Rt+1 /(Φt+1 Ψt+1 ), (34) has a single first-order condition that is
resources is dM
dAt

59 Subject
60 Subject

to definitions (3), (10), (11), (12) and (19).
to definitions (3), (13) and (19).

47

sufficient to characterize the solution to the normalized problem:


Ct−ρ − β E Rt+1 (Φt+1 Ψt+1 )−ρ VM (At Rt+1 /(Ψt+1 Φt+1 ) + Θt+1 Wt+1 , Φt+1 ) = 0
|
{z
}

(35)

≡ VA (At ,Φt )

=⇒ Ct = VA (At , Φt )−1/ρ .
The representative agent model can be solved using the endogenous grid method, following the same procedure as for the SOE model described in Appendix B.1, yielding
normalized consumption function C(M, Φ).61

A.2 Frictionless vs Sticky Expectations
The typical interpretation of a representative agent model is that it represents a continuum of households that face no idiosyncratic shocks, and thus all find themselves with the
same state variables; idiosyncratic decisions are equivalent to aggregate, representative
agent decisions. Once we introduce sticky expectations of aggregate productivity, this
no longer holds: different households will have different perceptions of productivity, and
thus make different consumption decisions.
To handle this departure from the usual representative agent framework, we take
a “multiple minds” or quasi-representative agent approach. That is, we model the
representative agent as being made up of a continuum of households who all correctly
perceive the level of aggregate market resources Mt , but might have different perceptions
of the aggregate productivity state. Each household chooses their level of consumption
based on their perception of the productivity state; the realized level of aggregate
consumption is simply the sum across all households.
Formally, we track the distribution of perceptions about the aggregate productivity
state as a stochastic vector ϕt over the current growth rate Φt ∈ {Φ}, representing
the fraction of households who perceive each value of Φ, and a vector Pet representing
the average perceived productivity level among households who perceive each Φ. As
in our other models, agents update their perception of the true aggregate productivity
state (Pt , Φt ) with probability Π; likewise, the distinction between frictionless and sticky
expectations is simply whether Π = 1 or Π < 1.
Defining ejN as the N -length vector with zeros in all elements but the j-th, which has
a one, the distribution of population perceptions of growth rate Φt evolves according to:
ϕt+1 = (1 − Π)ϕt + ΠejN when Φt+1 = Φj .

(36)

That is, a Π proportion of households who perceive each growth rate update their
perception to the true state Φt+1 = Φj , while the other (1 − Π) proportion of households
maintain their prior belief (which might already be Φj ).
The vector of average perceptions of aggregate productivity for each growth rate can

61 The only differences in solution method are that the RA model uses N
Ψ = NΘ = 7 point approximations to the
aggregate shock distribution, expected marginal value of assets is calculated using (35), and the upper bound of A is 120.

48

then be calculated as:
Pet+1 = (1 − Π)ϕt

Pet + ΠejN Pt+1



ϕt+1 .

(37)

That is, the average perception of productivity in each growth state is the weighted
average of updaters and non-updaters who perceive that growth rate.62
Households who perceive each growth rate Φ act as a partial representative agent,
choosing their level of consumption according to their perception of normalized market
ftj = Mt /Petj as perceived normalized market resources for houseresources. Defining M
holds who perceive the aggregate growth rate is Φj , aggregate consumption is:
X j
ftj , Φj )ϕjt .
Ct =
Pet C(M
(38)
Φj ∈{Φ}

This represents the weighted average of per-state consumption levels of the partial
representative agents.
When the representative agent frictionlessly updates its information every period (Π =
1), equations (36) and (37) say that ϕt = ejN and Petj = Pt (with irrelevant values in the
other vector elements), so that the representative agent is truly representative. When
expectations are sticky (Π < 1), the representative agent’s perceptions of the growth
rate become “smeared” across its past realizations; its perceptions the productivity level
likewise deviate from the true value, even for the part of the representative agent who
perceives the true growth rate.63

A.3 Simulation Results
We calibrate the RA model using the same parameters as for the HA-DSGE model
(see Section 5.1 and Table 1), except that there are no idiosyncratic income shocks
(σψ2 = σθ2 = ℘ = 0) and the possibility of death is irrelevant (D = 0). After solving
the model, we utilize the same simulation procedure described in Section 6, taking 100
samples of 200 quarters each; average coefficients and standard errors across the samples
are reported in Table 7.
The upper panel of Table 7 shows that under frictionless expectations, consumption
growth in the representative agent model cannot be predicted to any statistically significant degree under any specification. The lower panel, under sticky expectations,
yields results that are strikingly similar to the SOE model in Table 5. Both (instrumented) lagged consumption growth and expected income growth are significant
predictors of aggregate consumption growth, but the ‘horse race’ regression reveals that
62 The Hadamard operators
and
represent element-wise multiplication and division, respectively. As a numeric
detail, Petj is reset to 1 when ϕjt = 0, which would otherwise cause it to be undefined. When no households perceive
growth rate Φj , the average perception of productivity does not exist for this state and is quantitatively irrelevant, but
must exist for (37) to not fail in the next period.
63 An alternative method for modeling sticky expectations with a representative agent would be to track the perceptions
of the segments of households who last updated n = {0, 1, . . . , 200} periods ago, compute consumption for each segment,
and take the weighted average across the segments to yield aggregate consumption. This approach would only be slightly
more complicated to implement, and we believe it would yield quantitatively similar results.

49

the predictability is dominated by serially correlated consumption growth, confirming
the results of the two heterogeneous agents models.

B Numerical Methods
B.1 Solution Methods
B.1.1 Small Open Economy Solution Details
Consider the household’s normalized problem in the SOE model, given in (16). Substituting the latter two constraints into the maximand, this problem has one first order
condition (with respect to ct,i ), which is sufficient to characterize the solution:


−ρ m
R/(Φt+1ψ t+1,i )at,i + Wθθ t+1,i , Φt+1 = 0
c−ρ
(39)
t,i − RDβ Et (Φt+1ψ t+1,i ) v
|
{z
}
≡ va (at,i ,Φt )

=⇒ ct,i = va (at,i , Φt )−1/ρ .
We use the endogenous grid method to solve the model by iterating on the first order
condition. Eliding some uninteresting complications, our procedure is straightforward:
1. Construct discrete approximations to the lognormal distributions of θ, Θ, ψ, and
Ψ, adjusting for the point mass at 0 for θ with probability ℘. We use equiprobable
Nψ = Nθ = 7 point approximations for the (lognormal portion of) the idiosyncratic
shocks and NΨ = NΘ = 5 point approximations for the aggregate shocks.
2. Choose an exogenous grid of end-of-period normalized assets-above-naturala
borrowing-constraint A = {Naj }N
j=1 , spanning the range values that an agent
might reasonably encounter in a simulated lifetime. We use a triple-exponential
grid spanning Na ∈ [10−5 , 40] with Na = 48 gridpoints. The natural borrowing
constraint is zero because of the possibility of θ = 0, so assets-above-naturalborrowing-constraint is simply assets a.
3. Initialize the guess of the consumption function to c(m, ·) = m, the solution for an
agent who has no future.
4. Define the marginal value function vm (·) as u0 (c(·)), as determined by the standard
envelope condition.
5. Use the discrete approximations to the shock processes and the Markov transition
matrix Ξ to compute va (aj , Φk ) for all (aj , Φk ) ∈ A × {Φ}.
6. Use (39) to find the level of consumption that would make ending the period with
aj in assets optimal (when aggregate growth is Φk ): cj,k = va (aj , Φk )−1/ρ .
7. Calculate beginning of period market resources mj,k = aj,k + cj,k for all j, k.

50

8. For each k, construct c(m, Φk ) by linearly interpolating cj,k over mj,k , with an
additional point at (m = 0, c = 0).
9. Calculate the supnorm distance between the newly constructed c and the previous
guess, evaluated at the Na ×||{Φ}|| gridpoints. If the distance is less than  = 10−6 ,
STOP; else go to step 4.
The numerically computed consumption function can then be used to simulate a
population of households, as described in Appendix B.2.
B.1.2 Dynamic Stochastic General Equilibrium Solution Details
Consider the household’s normalized problem in the HA-DSGE model, given in (22).
Recalling that we are taking the aggregate saving rule ℵ as given, optimal consumption
is characterized by the solution to the first-order condition:


−ρ
= 0 (40)
c−ρ
t,i −β E Rt+1 (Φt+1ψ t+1,i ) v Rt at,i /(DΦt+1ψ t+1,i ) + θ t+1,i Wt+1 , Mt+1 , Φt+1
{z
}
|
≡ va (at,i ,Mt ,Φt )

=⇒ ct,i = va (at,i , Mt , Φt )−1/ρ .
Solving the HA-DSGE model requires a nested loop procedure in the style of Krusell
and Smith (1998), as the equilibrium of the model is a fixed point in the space of
household beliefs about the aggregate saving rule. For the outer loop, searching for the
equilibrium ℵ, we use the following procedure:
M
1. Construct a grid of (normalized) aggregate market resources M = {Mj }N
j=1 . We
use a NM = 19 point grid centered around the steady state of the perfect foresight
DSGE model M̆ , spanning the range M ∈ [0.1M̆ , 5M̆ ].

2. For each Φk ∈ {Φ}, initialize the aggregate saving rule to arbitrary values. We use
κk,0 = 0 and κk,1 = 1; there exist more efficient initial guesses.
3. In the inner loop, solve the household’s optimization problem for the current guess
of ℵ, using the procedure described below.
4. Simulate many households for many periods, using the procedure described in
Appendix B.2, yielding a long history of aggregate market resources, productivity
growth, and assets H = {(Mt , Φt , At )}Tt=0 .
5. For each k, define Hk ≡ {H|Φt = Φk }. Regress At on Mt on the set Hk , yielding
coefficients that provide updated values of κk,0 and κk,1 for ℵ.
6. Calculate the supnorm distance between the new and previous values of aggregate
saving rule coefficients κ. If it is less than ` = 10−4 , STOP; else go to step 3.
The inner solution loop (step 3) proceeds very similarly to the SOE solution method
above, with differences in the following steps:

51

2. The set A spans [10−5 , 120] because of the higher β in the HA-DSGE model.
5. End-of-period marginal value of assets is calculated as va (aj , Mk , Φ` ) for all
(aj , Mk , Φ` ) ∈ A × M × {Φ}.
6. Use (40) to calculate cj,k,` = va (aj , Mk , Φ` )−1/ρ .
8. For each `, construct c(m, M, Φ` ) by linearly interpolating cj,k,` over mj,k,` for each
k, then interpolating the linear interpolations over M.

B.2 Simulation Procedures
This appendix describes the procedure for generating a history of simulated outcomes
once the household’s optimization problem has been solved to yield consumption function
c(·) (or C(·) in the representative agent model). We first describe the procedure for the
SOE and HA-DSGE models from the body of the text, then summarize the simulation
method for the representative agent model of Appendix A.
In any given period t, there are exactly I = 20, 000 households in the simulated
population. At the very beginning of the simulation, all households are given an initial
level of capital: kt,i = 0 in the SOE model (as if they were newborns) and kt,i = K̆ in the
HA-DSGE model. Likewise, normalized aggregate capital is set to the perfect foresight
steady state Kt = K̆. At the beginning of time, all households have pt,i = 1 and correct
perceptions of the aggregate state. We initialize Pt = 1 and Φt = 1, average growth.
Time begins in period t = −1000, but the reported history begins at t = 0 following a
1000 period “burn in” phase to allow the population distribution of pt,i and at,i to reach
its long run distribution. In each simulated period t, we execute the following steps:
1. Draw aggregate shocks Θt and Ψt and productivity growth Φt , then calculate the
new level of aggregate permanent productivity Pt and factor returns Wt and Rt
using (19) (HA-DSGE model) or assigning the constant global values (SOE).
2. Randomly select DI = 100 household indices i to die and be replaced: di,t = 1.
Newborns get pt,i = 1, kt,i = 0, and a correct perception of the aggregate state.
Survivors receive the capital of the dead via the Blanchardian scheme.
3. Randomly select ΠI household indices to update their aggregate information:
e t,i ) are set according to (17).
πt,i = 1. Agents’ perceptions (Pet,i , Φ
4. The economy produces output. All agents draw idiosyncratic shocks ψt,i and θt,i ,
with newborns automatically drawing ψt,i = θt,i = 1,64 then observe their true mt,i
(and Mt in the HA-DSGE model).
5. Agents compute their perception of normalized idiosyncratic market resources m
e t,i
ft,i in HA-DSGE).
(and aggregate M
64 This prevents newborns from being unemployed in their first period of life and thus getting c
t,i = 0. It also simplifies
the calculation of the cost of stickiness.

52

6. Agents choose their level of consumption ct,i according to their consumption function and their perceived state, and end the period with at,i = mt,i − ct,i in assets.
7. Aggregate assets At and consumption Ct are calculated by taking population
averages across the I households. This period’s assets become next period’s
aggregate capital Kt+1 , and the next period begins.
We simulate a total of about 21,000 periods, so that the final period is indexed by
t = T = 20, 000. The time series values reported in Table 2 are calculated on the span
of the history, t = 0 to t = T ; the cross sectional values in this table are averaged across
all within-period cross sections. The time series regressions in Tables 5 and 6 partition
the history into 200 samples of 100 quarters each; the tables report average coefficients
and statistics across 100 sample regressions.
When simulating the representative agent model of Appendix A, only a few changes are
necessary to the procedure above. The vectors of perceptions are initialized to Pet = 111
and ϕ = e611 , so the “entire” representative agent has correct perceptions of the aggregate
state. No households are ever “replaced” in the RA simulation, idiosyncratic shocks do
not exist; only aggregate market resources are relevant. The vectors of perceptions evolve
according to (36) and (37), and aggregate consumption is determined using (38).
The microeconomic (or cross sectional) regressions in Table 4 are generated using a
single 4000 period sample of the history, from t = 0 to t = 4000, using 5000 of the
20,000 households. After dropping observations with yt,i = 0, this leaves about 19
million observations, far larger than any consumption panel dataset that we know of.
Standard errors are thus vanishingly small, and have little meaning in any case, which
is why we do not report them in the table summarizing our microsimulation results.
When making their forecasts of expected income growth, households are assumed to
forecast that the transitory component of income will grow by the factor 1/θt,i , which
is the forecast implied by their observation of the idiosyncratic transitory component
of income. Substantively, this assumption reflects the real-world fact that essentially
all of the predictable variation in income growth at the household level comes from
idiosyncratic components of income.

B.3 Cost of Stickiness Calculation
After simulating a population of households using the procedure in Appendix B.2,

I
we have a history of micro observations {ct,i , dt,i }Tt=0 i=1 and a history of aggregate
permanent productivity levels {Pt }Tt=0 . Each household index i contains the history of
many agents, as the agent at i dies and is replaced at the beginning of any period
P with
dt,i = 1. Let τi,n be the n-th time t index where dt,i = 1; further define Ni = Tt=0 dt,i ,
the number of replacement events for household index i.
A single consumer’s (normalized) discounted sum of lifetime utility is then:
τi,n+1 −1

vi,n =

Pτρ−1
i,n

X
t=τi,n

53

β t−τi,n u(ct,i ).

(41)

Normalizing by aggregate productivity at birth Pt is equivalent to normalizing by the
consumer’s total productivity at birth p t,i because pt,i = 1 at birth by assumption.
The total number of households who are born and die in the history is:
NI =

I
X

(Ni − 1).

(42)

i=1

The overall expected lifetime value at birth can then be computed as:
v0 = NI−1

I N
i −1
X
X

vi,n .

(43)

i=1 n=1

Because we use T = 20, 000 and I = 20, 000, and agents live for 200 periods on
average (D = 0.005), our simulated history includes about NI ≈ IT D = 2 million
v0 are
consumer lifetimes. The standard errors on our numerically calculated v0 and e
thus negligible and not reported.
In the SOE model, we use the same random seed for the frictionless and sticky
specifications, so the same sequence of replacement events and income shocks occurs
in both. With no externalities or general equilibrium effects, the distribution of states
that consumers are born into is likewise identical, so the “value ratio” calculation is valid.
The cost of stickiness in the HA-DSGE model is slightly more complicated. If we
used the generated histories of the frictionless and sticky specifications to compute v0
v0 , the calculated ω would represent a newborn’s willingness-to-pay for everyone to
and e
be frictionless rather than sticky. We are interested in the utility cost of just one agent
having sticky expectations, so an alternate procedure is required.
v0 in the HA-DSGE model the same as in the SOE model. However, v0 is
We compute e
calculated as the expected lifetime (normalized) value of a newborn who is frictionless but
lives in a world otherwise populated by sticky consumers. To do this, we simulate a new
history of micro observations using the consumption function for the sticky HA-DSGE
economy, but with all I households updating their knowledge of the aggregate state
frictionlessly. Critically, we do not actually calculate At = Kt+1 each period; instead,
we use the same sequence of At that occurred in the ordinary sticky simulation. Thus
our simulated population of I households represents an infinitesimally small portion
of an economy made up (almost) entirely of consumers with sticky expectations. The
calculated ω is thus the willingness-to-pay to be the very first agent to “wake up”.
The formula for willingness-to-pay (31) arises from the homotheticity of the household’s problem with respect to pt,i . If a consumer gives up an ω portion of their
permanent income at the moment they are “born”, before receiving income that period,
then his normalized market resources will still be mt,i = Wt , and he will make the same
normalized consumption choice that he would have, had he not lost any permanent
income. In fact, he will make the exact same sequence of normalized consumption
choices for his entire life; the level of his consumption will be scaled by the factor (1 − ω)
in every period. With CRRA utility, this means that utility is scaled by (1 − ω)1−ρ in
every period of life, which can be factored out of the lifetime summation. The indifference

54

condition between being frictionless and losing an ω fraction of permanent income versus
having sticky expectations (and not losing) can be easily rearranged into (31).

C Additional Calculations
C.1 Quadratic Utility Consumption Dynamics
This appendix derives the equation (3) asserted in the main text. Start with the
definition of consumption for the updaters,
Z 1
π
−1
πt,i ct,i di
Ct ≡ Π
0
Z 1
−1
πt,i (r/R)ot,i di
= Π
0
Z 1
−1
πt,i ot,i di
= Π (r/R)
0

= Π−1 (r/R)ΠOt
= (r/R)Ot ,
where the penultimate line follows from the fact that the updaters are chosen randomly
among members of the population so that the average per capita value of o among
updaters is equal to the average per capita value of o for the population as a whole.
The text asserts (equation (3)) that
Ct+1 = Π∆Cπt+1 + (1 − Π)∆Ct
≈ (1 − Π)∆Ct + ξt+1 .
To see this, define market resources Mt = Yt + RAt where Yt is noncapital income
in period t and At is the level of nonhuman assets with which the consumer ended the
previous period; and define Ht as ‘human wealth,’ the present discounted value of future
noncapital income. Then write

Cπt+1 = (r/R) Mt+1 + Ht+1

Cπt = (r/R) Mt + Ht

Cπt+1 − Cπt = (r/R) Mt+1 − Mt + Ht+1 − Ht

Cπt+1 − Cπt = (r/R) R(Yt + Mt − Ct ) − Mt + Ht+1 − Ht .
(44)
What theory tells us is that if aggregate consumption were chosen frictionlessly in
period t, then this expression would be white noise; that is, we know that

(r/R) R(Yt + Mt − Cπt ) − Mt + Ht+1 − Ht = ξt+1
for some white noise ξt+1 . The only difference between this expression and the RHS of
(44) is the Π superscript on the Ct . Thus, substituting, we get

Cπt+1 − Cπt = (r/R) R (Yt + Mt − (Ct + Cπt − Cπt )) − Mt + Ht+1 − Ht

55


Cπt+1 − Cπt = (r/R) R(Yt + Mt − Cπt ) − Mt + Ht+1 − Ht + (r/R)(Cπt − Ct )
= ξt+1 + (r/R)(Cπt − Ct ).
So equation (3) can be rewritten as
∆Ct+1 = (1 − Π)∆Ct + Π (r/R)(Cπt − Ct ) + ξt+1



where ξt+1 is a white noise variable. Thus,

∆Ct+1 = (1 − Π) 1 + (r/R) ∆Ct + Πξt+1
| {z }
| {z }

(45)

≡ t+1

≈0

for a white noise variable t+1 , and (r/R) ≈ 0 for plausible quarterly interest rates. (45)
leads directly to (3).

C.2 Population Variance of Idiosyncratic Permanent Income
This appendix follows closely Appendix A in the ECB working paper version of Carroll,
Slacalek, and Tokuoka (2015).65 It computes dynamics and steady state of the square
of the idiosyncratic component of permanent income (from which the variance can be
derived). Recalling that consumers are born with pt,i = 1:
pt+1,i = (1 − dt+1,i )pt,i ψt+1,i + dt+1,i
2
p2t+1,i = (1 − dt+1,i )pt,i ψt+1,i + (1 − dt+1,i )dt+1,i 2pt,i ψt+1,i + d2t+1,i
{z
}
|
=0

and because

Et [d2t+1,i ]

= D we have
Et [p2t+1,i ] = Et [((1 − dt+1,i )pt,i ψt+1,i )2 ] + D

= Dp2t,i E[ψ 2 ] + D.
R1
Defining the mean operator M[•t ] = 0 •t,ι dι, we have


M p2t+1 = DM[p2t ] E[ψ 2 ] + D,
so that the steady state expected level of M[p2 ] ≡ limt→∞ M[p2t ] can be found from
M[p2 ] = D E[ψ 2 ]M[p2 ] + D
D
=
.
1 − D E[ψ 2 ]
Finally, note the relation between p2 and the variance of p:
σp2 = M[(p − M[p])2 ]
= M[(p2 − 2pM[p] + (M[p])2 )]
= M[p2 ] − 1,
where the last line follows because under the other assumptions we have made, M[p] = 1.
65 Carroll, Christopher D., Jiri Slacalek, and Kiichi Tokuoka (2014): “Buffer-Stock Saving in a Krusell–Smith World,”
working paper 1633, European Central Bank, https://www.ecb.europa.eu/pub/pdf/scpwps/ecbwp1633.pdf.

56

For the preceding derivations to be valid, it is necessary to impose the parameter
restriction D E[ψ 2 ] < 1. This requires that income does not spread out so quickly among
survivors as to overcome the compression of the distribution that arises because of death.

C.3 Converting Annual to Quarterly Variances for Idiosyncratic Shocks
If the quarterly transitory shock is θt , define the annual transitory shock as:
θta

=

4
X
θt+i

4

i=1

for t = 0, 4, 8, . . . Then the variance of the annual transitory shock is 41 of the variance
4
var(θ) = 14 var θ. We therefore multiply
of the quarterly transitory shock: var(θa ) = 16
our calibrated annual transitory shock (0.03) by 4 to get a quarterly number.
Let ψt be the quarterly permanent shock. Define the annual permanent shock as:
ψta

=

4
Y

ψt+i

i=1

4
for t = 0, 4, 8, . . . Then the variance of the annual permanent shock is 1 + var(ψ) ≈
4 × var(ψ) for small var(ψ). Therefore we divide our calibrated annual permanent shock
(0.012) by 4 to get a quarterly number.

C.4 Muth (1960) Signal Extraction
Muth (1960), pp. 303–304, shows that the signal-extracted estimate of permanent income
is
Pet = v1 Yt + v2 Yt−1 + v3 Yt−2 + ...
(46)
for a sequence of v’s given by
vk = (1 − λ1 )λk−1
1

(47)

for k = 1, 2, 3, .... So:
Pet = (1 − λ1 )(
Yt + λ1 Yt−1 + λ21 Yt−2 ...)
Pet+1 = (1 − λ1 )(Yt+1 + λ1 Yt + λ2 Yt−1 + λ3 Yt−2 ...)
1

1
λ21 Yt−1

= (1 − λ1 ) Yt+1 + λ1 (1 − λ1 )(Yt +
|
{z

+

(48)
λ31 Yt−2 ...)

(49)
(50)

}

Pet

= (1 − λ1 )Yt+1 + λ1 Pet

(51)

This compares with (32) in the main text
Pet+1 = ΠYt+1 + (1 − Π)Pet

(52)

so the relationship between our Π and Muth’s λ1 is:
λ1 = 1 − Π

57

(53)

Defining the signal-to-noise ratio ϕ = σψ /σθ , starting with equation (3.10) in Muth
(1960) we have
p
λ1 = 1 + (1/2)ϕ2 − ϕ 1 + ϕ2 /4
p
(1 − Π) = 1 + (1/2)ϕ2 − ϕ 1 + ϕ2 /4
p
−Π = (1/2)ϕ2 − ϕ 1 + ϕ2 /4
(54)
yielding equation (33) in the main text.

58

Table 7 Aggregate Consumption Dynamics in RA Model
∆ log Ct+1 = ς + χ∆ log Ct + ηEt [∆ log Yt+1 ] + αAt + t+1
Expectations : Dep Var
Independent Variables

OLS
or IV

2nd Stage
R̄2

Frictionless : ∆ log C∗t+1 (with measurement
At
∆ log C∗t ∆ log Yt+1
−0.015
OLS
(0.077)
0.387
IV
(0.390)
0.390
IV
(0.311)
−0.26e–4
IV
(1.11e–4)
0.122
0.267
0.16e–4
IV
(0.519)
(0.575)
(2.12e–4)
Memo: For instruments Zt , ∆ log C∗t = Zt ζ,

KP p-val
Hansen J p-val

error C∗t = Ct × ξt );
0.002
0.014

0.367
0.570
0.016
0.084
0.475
0.016
0.000
0.493
0.018
0.547
0.572
R̄2 = 0.018; var(log(ξt )) = 3.33e–6

Sticky : ∆ log C∗t+1 (with measurement error C∗t = Ct × ξt );
∆ log C∗t ∆ log Yt+1
At
•••
0.412
OLS
0.179
(0.063)
0.788•••
IV
0.183
0.001
(0.138)
0.532
•••
0.641
IV
0.128
0.085
(0.163)
0.171
−0.47e–4
IV
0.075
0.000
(0.52e–4)
0.027
0.632•••
0.118
0.10e–4
IV
0.184
0.321
(0.223)
(0.280)
(0.79e–4)
0.480
∗
2
Memo: For instruments Zt , ∆ log Ct = Zt ζ, R̄ = 0.186; var(log(ξt )) = 3.33e–6
Notes: Reported statistics are the average values for 100 samples of 200 simulated quarters each.
Bullets indicate that the average sample coefficient divided by average sample standard error is
outside of the inner 90%, 95%, and 99% of the standard normal distribution.
Instruments Zt =
{∆ log Ct−2 , ∆ log Ct−3 , ∆ log Yt−2 , ∆ log Yt−3 , At−2 , At−3 , ∆8 log Ct−2 , ∆8 log Yt−2 }.

59

