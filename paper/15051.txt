NBER WORKING PAPER SERIES

GENERALIZED AGENCY PROBLEMS
Randall Morck
Working Paper 15051
http://www.nber.org/papers/w15051

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2009

I am grateful for suggestions from Malcolm Baker, Nick Barberis, Andrei Shleifer, and Jeff Wurgler.
The views expressed herein are those of the author(s) and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2009 by Randall Morck. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

Generalized Agency Problems
Randall Morck
NBER Working Paper No. 15051
June 2009
JEL No. D02,D03,D72,D87,G3,K0,P37
ABSTRACT
Agency problems in economics virtually always entail self-interested agency exhibiting “insufficient”
loyalty to principal. Social psychology also has a literature, mainly derived from work by Stanley Milgram,
on issues of agency, but this emphasizes excessive loyalty – people undergoing a so-called “agentic
shift” and forsaking rationality for loyalty to a legitimate principal, as when “loyal” soldiers obey orders
to commit atrocities. This literature posit that individuals experience a deep inner satisfaction from
acts of loyalty – essentially a “utility of loyalty” – and that this both buttresses institutions organized
as hierarchies and explains much human misery. Agency problems of excessive loyalty, as when boards
kowtow to errant CEOs and controlling shareholders, may be as economically important in corporate
finance as the more familiar problems of insufficient loyalty of corporate insiders to shareholders.
Overt conflict between rival authorities is shown to reverse the “agentic shift” – justifying institutions
that formalize argumentation such as the adversary system in Common Law courts; the Official Opposition
in Westminster democracies; discussants and referees in academia; and independent directors, non-executive
chairs, and proxy contests in corporate governance.

Randall Morck
Faculty of Business
University of Alberta
Edmonton, CANADA T6G 2R6
and NBER
randall.morck@ualberta.ca

1.

Introduction

Wherever human beings are organized into hierarchies – command economies,
governments, armies, or corporations – principals, situated at the top of the hierarchy,
make decisions; and agents, located in lower positions, obey orders. To operationalize
this, agents often have a duty of loyalty to principals. Thus, peasants must be loyal to
Party leaders; soldiers to the military high command; civil servants to the government;
and top corporate managers to the shareholders, the legal owners of a corporation.
In economics-based disciplines, agency problems describe rational utility
maximizing agents whose self-interest leaves them insufficiently loyal to principals. Thus,
a self-interested CEO runs her firms to maximize her own utility, rather the wealth of her
principals, the shareholders.

Agency in Economics
Virtually all economics work on agency problems adopts, implicitly or explicitly, the
framework of Jensen and Meckling (1976). They posit an entrepreneur, initially the 100%
owner of her firm, contemplating an initial public offering (IPO) in which she would sell
some shares, selling to passive outside shareholders, retaining the rest, and stays on as
CEO. The CEO can divert corporate resources to augment her utility – for example,
using corporate funds to buy unnecessary Lear jets, hire unqualified cronies, advance
personal political agendas, fund pet charities, etc. Prior to the IPO, she bears the full
cost of such things; but afterwards public shareholders share these costs. A rationally
self-interested CEO therefore diverts more corporate funds after the IPO than before.
Public shareholders anticipate the magnitude of this governance problem and
correspondingly devalue the shares.
In other hierarchies, command and control mechanisms limit agents’ freedom of
action. Disloyal peasants or soldiers risk quartering; disloyal civil servants risk
prosecution. Monitoring and control costs limit these mechanisms’ effectiveness, so
agency problems are mitigated, not eliminated. Corporations, and the economic
institutions surrounding them, provide analogous mechanisms: transparency, board
oversight, independent audits, independent directors, and the like. These mechanisms
are costly to design, monitor, and enforce, and are employed to the extent that their
benefits outweigh their costs. The cost of using mechanisms plus the remaining
depression in firm valuation equals what Jensen and Meckling call the agency cost. Most
of the agency literature in corporate finance evaluates the effectiveness of such “loyalty
enhancing” mechanisms in mitigating agency costs, as evidenced by corporate
valuations (Shleifer and Vishny 1997).

Agency in Social Psychology
Similar terminology arises in social psychology. Most notably, Milgram (1974) defines an
agentic shift as occurring when one individual subordinates her actions to the judgment
of another. However, social psychologists see problems when agents exhibit “excessive
loyalty” to the principal. For example, social welfare would have been enhanced were
Nazi guards less faithful agents of their Führer. The agency problem here is that the
guards obeyed orders they should have defied: “I was only obeying orders” was not a
defense at Nuremburg. The agency cost here is the loss due to that excessive loyalty –
the loss due to the holocaust.

2

From this perspective, social psychology sees the agency problem documented
in the corporate finance literature as “excessive loyalty” to the CEO or controlling
shareholder, rather than “insufficient loyalty” to public shareholders (Morck, 2008). For
example, an excessive loyal board might support a takeover the CEO misguidedly
advocates because of an agentic shift – the directors subordinating their decisionmaking to the CEO. Here too, firm value falls – due to the misguided takeover – and the
countermeasures are possible: mandating that directors meet without the CEO, order an
independent analysis of takeovers, etc. However, these are now “loyalty blocking”
mechanisms, not “loyalty enhancing” mechanisms.

Generalized Agency Problems
Generalizing the term agent to include anyone from whom loyalty is expected, and
principal to encompass anyone to whom that loyalty is due, a generalized agency
problem entails an agent exhibiting non-optimal loyalty to the principal – too little or too
much. This covers the self-interested agent of corporate finance and the blindly loyal
agent of social psychology. The key insight for financial economists is that behavioral
considerations permit welfare losses from insufficient or excessive loyalty.

2.

Agency Problems Generalized

Agency theory in social psychology derives primarily from a series of social psychology
experiments begun in 1961 by Stanley Milgram (1963, 1974), then an Assistant
Professor of psychology at Yale, and replicated extensively thereafter (Blass, 2004).1
Milgram’s experiments followed the Nuremburg War Crimes Trials of senior Nazis, at
which the defense “I was only obeying orders” came up repeatedly. This renewed
interest in the historical observation that “loyalty” motivates many atrocities (Laski, 1919).

Figure 1.

Experimental Design

The design of Milgram’s obedience experiments at Yale in the early 1960s.

Panel A. The bogus
shock generator contains
a buzzer and has wires
running to the “teacher’s”
seat.

Panel B. The “teacher”
(real experimental
subject) helps strap in the
“learner” (actor) and
apply bogus electrodes

Source: Milgram (1974).

1

Much of what follows draws extensively from Morck (2008).

3

Panel C. The teacher is
taught to operate the
bogus shock generator

Milgram’s Experiment
The experiment features a box, in Figure 1A, with switches labeled “15 volts”, “30 volts”,
“45 volts”, and so on up to “450 volts”. The voltages are also labeled from “slight”
through “danger severe”, and “XXX”. Wires connect this box to various parts of the body
of a professional actor, the “learner” in Figure 1B. A noise maker inside the box mimics
the buzz of electric current.
Each subject is told (falsely) the “learner” is the subject of an experiment on “the
effects of punishment on learning and memory” and asked to assist. The real subjects,
citizens of New Haven, CT. attracted by advertisements of cash for participation in
psychology experiments, thus feel a financial obligation to Milgram and a sense of
participating in important research. Milgram wore a lab coat to impress this image.
The subject is instructed to be the “teacher” and seated before the box. Milgram
asks a series of questions, and the “learner” sometimes answers incorrectly. Each time
this occurs, the “teacher” is told to apply a larger electric shock to the actor, who feigns
increasing pain. Milgram (1974, p. 4) describes the actor’s script: “At 75 volts, the
“learner” grunts. At 120 volts he complains verbally; at 150 he demands to be released
from the experiment. His protests continue as the shocks escalate, growing increasingly
vehement and emotional. At 285 volts his response can only be described as an
agonized scream.”

Figure 2.

Obedience Rates, Basic Milgram Experiment

Fraction of ordinary Connecticut residents who directed high voltage electric
shocks through the bodies of perfect strangers when ordered to do so by a
psychologist.
100%
90%
80%
70%

Obedience

60%
50%
40%
30%
20%
10%
0%
15 30 45

60 75 90 105 120 135 150 165 180 195 210 225 240 255 270 285 300 315 330 345 360 375 390 405 420 435 450

Slight

Moderate

Strong

Very strong

Intense

Extreme intensity Danger: Severe

XXX

Voltage and Description

Source: Milgram (1974).

Milgram believed Americans would disobey, and intended to replicate the
procedure in Germany to see if cultural proclivity to obedience explained complicity in

4

Nazi war crimes. He was astonished after a “test run” of Yale students dutifully
electrocuting perfect strangers when told to, but dismissed this as “Yalies”. But the full
experiment gave similar results. Ordinary Americans obediently electrocuted strangers
at his command.
Figure 2 summarizes his main results. One hundred percent of ordinary
Americans electrocute the “learner” through 135 volts, when he demands release. There,
about twenty percent stop obeying. Eighty percent continue administering shocks
labeled “very strong” and “intense”, up through two hundred and eighty-five volts, when
the “learner” screams in agony. A bit over sixty percent obediently administer shocks
through four hundred and fifty volts, despite labels like “extreme intensity”, “danger
severe”, and “XXX” by the voltage figures.

Robustness
Milgram repeats the experiment varying several parameters. He finds no difference in
between male and female subjects. Moving the experiment from New Haven to
Bridgeport has little effect. Placing the “learner” (actor) in more direct proximity to the
“teacher” (true subject) reduces obedience only marginally.
Numerous researchers, including this author, replicate Milgram’s results. A
substantial majority of subjects obediently administer maximal shocks across countries,
including Germany (Miller, 1986); and across a wide range of subject pools and
experimental designs (Blass 1998, 2000, 2004; see also Merritt and Helmreich 1996;
Tarnow 2000).
Responding to concerns Milgram’s subjects complied because they sensed the
actor was acting, Sheridan and King (1972) use actual shocks to a puppy. Twenty of
their 26 subjects comply fully – six of thirteen males and all thirteen of females, though
some of the latter exhibit distress (Blass, 1998, 2004).

Figure 3.

Replicating Milgram

The most recent replication terminated the experiment once a subject obeyed
instructions to administer a shock above 150V. Results for the 30 subjects are
consistent across the 18 males and 22 females in the sample.
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%

16

Subject continued
beyond 150V

6

6

Subject stopped at
or before 150V

Male Subjects

Female Subjects

28

12

12
All Subjects

Source: Burger (2009).

5

Most recently, Burger (2009) reproduces Milgram’s finding stopping at 150V (see
Packer, 2008) and excluding anxious subjects – with both alterations designed to avoid
causing subjects lasting psychological harm – a major criticism of Milgram’s initial
experiments (Baumrind, 1964; Fischer, 1968; Kaufmann, 1967; Mixon, 1972). Milgram’s
follow-up interviews suggest this discomfort afflicted his peers more than his subjects,
for “the vast majority of participants not only were glad they had participated in the study
but said they had learned something important from their participation and believed that
psychologists should conduct more studies of this type in the future” (Burger, 2009, p. 2).
Nonetheless, such restrictions are required by university ethics reviews (Elms, 1995),
implemented largely in response to social scientists’ distress with Milgram’s experiment
(Blass, 2000). Figure 3 illustrates Burger’s (2009) baseline findings.
These direct replications are buttressed by “natural experiments” – incidents in
which people, acting as agents, engage in obviously cruel or inappropriate behavior.
Loyal soldiers shoot strangers and loyal bomber pilots incinerate cities – simply because
they are ordered to.

3.

The Agentic Shift and Alternative Explanations

Given this abundance of evidence, the generality of Milgram’s finding’s as a description
of human nature is beyond doubt. Psychological and economic explanations are needed.
Milgram (1974) posits an agentic shift, we suspend our autonomy and literally becoming
agents of another. In doing this, he proposes a psychological pleasure of being loyal to a
legitimate authority occludes personal ethical responsibility. However, other explanations
are possible. Milgram’s preferred explanation follows, and then alternatives are reviewed.

Milgram’s Theory of the Agentic Shift
Milgram, appalled by his findings, never repeated the experiment in Germany. He
concluded instead that we have an intrinsic loyalty response – an urge to obey authority
(Blass, 2004).
Milgram (1974) suggests this has a genetic basis. Animals that hunt in packs, like
wolves, sort themselves into hierarchies, headed by so-called alpha males. De Waal
(2005) describes hierarchical social structures under alpha males (e.g. chimpanzees) or
alpha females (e.g. bonobos), who command obedience from other apes in the troop.
Early hominids obeying alpha males (or females) might survive a charging mastodon
better than otherwise biologically identical lone hominids.
Thus, an agentic shift, like other behavioral decision-making short cuts that seem
irrational a priori, might contribute to individual or group survival (Bernardo and Welch,
2001). Certainly, the hypothesis accords with early work in political economy, such as
Hobbes (1651) proposal that submission to organized tyranny is preferable to
independent savagery. That obedience to authority triggers psychological wellbeing
explains much of the misery and atrocity overlaying human history.
Milgram follows up with his subjects to explore why they behaved as they did
(Blass, 2004). Most complied because they “gave their word” or felt a duty of “loyalty”.
Many indicated they were “doing what was expected of them”. When Milgram (1974, p. 7)
asked for a “moral judgment” on what his subjects should have done, they “unfailingly
see disobedience as proper.” Asked why they behaved otherwise, the subjects cite

6

politeness, the inviolability of one’s word, the awkwardness of conflict, engulfment in the
technical details of the experiment, and so on.
But the most universal response was the virtue of loyalty. Milgram (1974, p. 188)
despairs that “virtues of loyalty, discipline, and self-sacrifice that we value so highly in
the individual are the very properties that create destructive engines of war and bind
men to malevolent systems of authority.” Since similarly deep emotions are associated
with other biological drives, Milgram’s postulate of a neurological basis seems plausible.
Milgram (1974, p. 8) concludes the subjects did not abandon moral reasoning,
but “instead, it acquires a radically different focus. He does not respond with a moral
sentiment to the actions he performs, Rather, his moral concern now shifts to a
consideration of how well he is living up to the expectations that the authority has of
him.”
This is the essence of Milgram’s agentic shift. The subject switches from the
teleological (consequences-based) decision-making framework familiar to economists to
a deontological (duty-based) framework. Right and wrong are reframed as doing or
failing to do one’s duty. Philosophy has long weighed duties as guiding ethics (Broad,
1930, pp. 277-278). Milgram provides empirical support for deontological considerations
affecting human decisions, and that this need not induce behavior we ex post consider
ethical.
Milgram (1974, p. 145-6) argues that this agentic shift is a previously
unrecognized fundamental component of human nature; and that “the most far-reaching
consequence of the agentic shift is that a man feels responsibility to the authority
directing him, but feels no responsibility for the content of the actions that the authority
prescribes.” In economics jargon, we frequently forsake the rational weighing of
consequences and act out of loyalty because “being loyal” makes us feel good about
ourselves.
This might be modeled as a behavioral bias in the form of a deontological reflex –
an instinctive pressure to do one’s duty. Or it might be modeled as a deontological
component of utility individuals gaining utility from acts of loyalty and losing utility from
acts of disloyalty. New theoretical constructs might well be needed in complete
economic models of this phenomenon and its consequences.

Evoked Socialized Aggression
Although Milgram concluded that an agentic shift best explains his findings, he concedes
other possibilities. One common allegation is that he detects a sadistic impulse, and this
view triggered many social scientists’ discomfort with Milgram’s experiment (Blass,
2000). This perhaps reflects a conflation of Milgram’s work with the famous Stanford
prison experiments (Haney et al. 1973), conducted about the same time. In these,
university students in a mock prison were cast as either “prisoners” or “guards”. Within
days, the “guards” inflicted rapidly escalating cruelty on increasingly cowering “prisoners”.
The prison experiment elicited aggressive behavior by the “guards” in the
absence of an authority figure. After the experimenters sought (ultimately unsuccessfully)
to restrain this behavior by imposing their authority, they concluded they had to
terminate the experiment abruptly. Thus, while both experiments imply a surprising
situational flexibility to ethical constraints and clearly expose unflattering aspects of
human nature, it is far from clear they expose the same ignominy.

7

Subsequent variation on Milgram’s experiment reinforces his rejection of an
innate sadistic impulse as an explanation for his findings. Martin et al. (1976) modified
his experimental design by directing their subjects, secondary school boys, to raise a
noise generator to a level indicating “a 50% risk” of permanent hearing loss. Since the
subjects were actually closer to the noise generator than the actor feigning pain, the
subjects were obviously exposing themselves to the greater danger. The near alignment
of their findings to Milgram’s would appear to preclude a normally hidden enjoyment at
inflicting pain on others as a general explanation.
Still, the refusal of some subjects to administer higher voltages suggests that
heterogeneity in personality traits such as empathy might play a role, and some follow
up work also points in this direction (Blass, 1991). Pursuing this hypothesis, Burger
(2009) finds no correlation between subjects’ “empathy” scores and propensities to
administer large shocks.

Conformity to Perceived Norms
Social norms are important constraints on economic behavior (Smith, 1759); constitute a
major part of what we now call economic institutions (North, 1990); and exert an
experimentally verified influence individuals’ decision-making (Cialdini et al.1991;
Cialdini, 1998). We leave tips at restaurants in cities we will never visit again, surrender
seats to the elderly, and deal honestly with strangers – all because doing otherwise
violates social norms.
The social psychology literature shows that we tend to go along with the group.
Asch (1951) asked his experiment subject which “comparison line – A, B, or C – is the
same length as the line on the left side of Figure 4. If others in the room volubly agreed
on line B, most subjects would agree, even though the correct answer is obviously C.
From a series of such experiments, Asch concludes that people are remarkably prone to
go along with a “group consensus” – even one rigged to be obviously wrong.

Figure 4.

The Asch Conformity Experiments

Subjects are shown a card with a line on it and asked which comparison line – A,
B, or C – is the same length. In this case, the correct answer is C. However, if
others (actually confederates) assert a different answer, most subjects conform to
the apparent group consensus, despite its obvious absurdity.

Source: Asch (1955)

8

Milgram’s baseline subjects were alone with the experimenter, not in a group. If
their compliance reflects conformity, the distinction from obedience is perhaps
problematic.

Changing Prospects
A final class of alternative explanations attributes the obedience Milgram observes to the
small incremental (15V) increases in shocks (Gilbert, 1981). This evokes the foot-in-thedoor effect known to students of marketing – slowly escalating a subject’s commitment is
an effective way of modifying attitudes and behavior (Cialdini and Goldstein, 2004). This
effect appears to derive from an innate need for consistency – refusing to administer a
315V shock is difficult once one has administered a 300V shocks – or a change in selfperception – administering successively higher voltages causes the subject to recast
herself as the sort of person who faithfully follows instructions (Burger, 2009).
This class of explanations relates to the work of Kahneman and Tversky (2000),
who shows that people’s decisions depend critically on how their options are “framed”.
Thus, gradually increasing the voltages changes the baseline against which the subject
judges the severity of the next electric shock. This implication – that subjects would not
administer a 450V shock immediately, but can be induced to do so by successive
reframings of the situation – is, as yet, untested.

Asymmetric Information and Information Cascades
Another class of alternative explanations turns on the subjects’ perception that the
experimenter has superior information (Morelli, 1983). The experimenter, merely by
placing the experiment in an academic setting, signals the experiment’s importance and
legitimacy.
This class of arguments is familiar to students of financial economics, for it
underpins the literatures on rational herding and information cascades (Banerjee, 1992;
Bikhchandi, Hirshleifer, and Welch, 1992). If “becoming informed” is costly, a rational
actor sometimes opts to follow another who appears well-informed. Specifically, if the
cost of becoming informed exceeds the expected cost of occasionally mistakenly
following an uninformed actor, it is rational to remain ignorant. Information cascades are
readily triggered in groups of laboratory subjects (Anderson and Holt, 1997); and daily
life examples abound: we presume more crowded restaurants have better food; we
praise oeuvres of abstraction by already lauded modern artists.
From this perspective, Milgram’s subjects infer that the experimenter is informed
and rationally opt not to become informed themselves. They participate without
gathering information about the effect of electricity on human physiology and the
academic value of the experiment, and without incurring the mental cost of weighing that
information and coalescing it into a decision.
The importance of information cascades in actual financial decision-making
remains unclear. Alevy et al. (2007) find professional options traders markedly less
prone to information cascades than students, the typical subjects of experimental
economics studies; but Drehmann et al. (2002) report no significant difference in this
regard between experts at an international consulting firm and ordinary experimental
subjects. Consistent with information cascades, Amihud et al. (2003) find a bimodal
distribution of Israeli IPO subscriptions – either massively oversubscribed or pitifully

9

undersubscribed. Consistent with Gul and Lundholm’s (1995) model of endogenous
timing given information cascades, which predicts waves of similar decisions as
uninformed actors free-ride on apparent fresh information, Rao et al. (2001) find financial
analysts initiating and discontinuing coverage of particular stocks en masse. Elsewhere
in economics, evidence of information cascades is found in hiring decisions (Kübler and
Weizsäcker, 2003), artistic success (Crossland and Smith, 2002) motion pictures
becoming either runaway hits or flops (De Vany and Walls, 1996; though see also De
Vany and Lee, 2001).
Information cascades may well play a role in Migram’s experiment and its
replicates. Milgram (1983) acknowledges this, but counters that erroneous presumptions
of superior information characterize many instances of profoundly costly excess loyalty.
In the parlance of economics, excessive obedience can have negative externalities:
interrogators waterboarding prisoners perhaps erroneously presume their leaders have
superior information, but the social cost of this mistaken presumption greatly exceeds
the psychic burden on the ex-interrogators. A tally of personal costs and benefits to
becoming informed may well induce rationally ignorant interrogators, but fails to account
for costs to others. Likewise, the cost to corporate directors of loyally approving a huge
misbegotten corporate takeover because they presume the CEO advocating it to be
well-informed is clearly not its full social cost of such a major corporate misadventure. In
short, socially excessive loyalty resulting from information cascades is, nonetheless,
excessive.
But rationality amid information cascades seems an inadequate explanation for
the full scope of evidence. Few people are unaware of the danger in high voltage
electricity, and the stated purpose of the experiment – to see if people learn faster when
punished for mistakes – is obviously not a matter of life and death. Moreover, the
subjects in Martin et al. (1976) were told they risked permanent damage to their own
hearing, yet continued to administer increasing blasts of noise. An innate and unthinking
obedience reflex seems more consistent with such behavior.

4.

Voice and Loyalty: Disengaging the Agentic Shift

Perhaps deriving utility from acts of `loyalty` elevated our ancestors` survival odds by
facilitating hierarchical social organization. Hierarchical structures – corporations,
governments, or economies – are found throughout modern economies. Such an effect
would inoculate hierarchies against self-interested agents, and might explain their
ubiquity despite the monitoring and control costs neoclassical economic casts against
them.
Clearly, the immunity is incomplete, for the economics and finance literatures on
agency problems of insufficient loyalty are theoretically compelling and empirically wellsupported. Under a wide range of economically important circumstances, insufficiently
loyal agents clearly impose large costs.
However, the arguments and evidence above suggest excessively loyal agents
might also impose important economic and social welfare costs. Understanding what
circumstances evoke stronger or weaker utility of loyalty is therefore important, and quite
unexplored by economists.
The corporate finance literature is perhaps at its most convincing when
explaining how insufficient agentic loyalty can be augmented by institutions` – legal

10

systems, regulation, accounting standards, tax authorities, enforceable contrasts,
incentive schemes, customary business practices, and others. If excessive agentic
loyalty can also pose problems, our institutions might also need to assume forms that
deter loyalty in situations where it tends to excess. To appreciate such institutions, we
need to understand how our innate loyalty reflex might be directed, modulated or
interrupted.

Bias Awareness
If a behavioral bias causes irrational decisions, perhaps informing people about those
biases can let them correct for that bias so that rational decision-making is restored
(Gergen, 1973, p. 313). The Milgram experiments were highly publicized in the 1960s
and 1970s, yet Schurz (1985) find no time trend in the numerous subsequent
replications.
Proponents of “education as liberation” from behavioral biases may
underestimate the difficulty of this. Still, university ethics committees ended Milgram
experiments in the 1980s, and popular knowledge of them faded. Thus, recent
replications such as Burger (2009) need not falsify the hypothesis that awareness of
behavioral factors reduces their effects.

Figure 5.

Variant Experimental Designs

When the “teacher” had to hold the “learner’s” hands against metal plates to
administer shocks, obedience rates declined somewhat. At higher voltages, the
“learner” feigns cries of agony.

Source: Milgram (1974).

Proximity
In variants of his experiment, illustrated in Figure 5, where Milgram has subjects
physically hold the actor’s hands to electrodes, compliance declines – slightly. This
suggests more direct connection to the victim reduces loyalty to authority somewhat.
In other variants, Milgram (1974, p. 62) removes the experimenter from the lab,
and has the “teacher” and “learner” receive instructions over a telephone. Obedience
dropped to about one third of the baseline level. Also, several subjects who continued
administering shocks surreptitiously delivered lower voltage shocks than ordered to; and

11

some even lied that they were delivering the shock levels required. If the experimenter
reentered the lab, this behavior ended and subjects resumed compliance.
Milgram concluded that “subjects seemed able to resist the experimenter far
better when they did not have to confront him face to face. … The physical presence of
an authority figure was an important force.” Remarkably, proximity to the authority figure
ordering the abuses appears far more important than proximity to the victims of the
abuse.
This would seem to have immediate application in corporate governance. The
directors and managers of a corporation are proximate to the CEO or controlling
shareholder – he is there to direct all major decisions – and public shareholders are a
relatively remote abstraction. Regulations mandating meetings of directors absent the
CEO or controlling shareholder might thus make sense as ways to “remove the authority
from the room”. If the Milgram experiment variants are a guide, distancing the decision
makers from the CEO might be more important than bringing them closer to the
shareholders. Yet these issues remain largely virgin territory for students of corporate
finance.

Figure 6.

Obedience Rates, Dissenting Peers Variant

Fraction of ordinary Connecticut residents directing electric shocks through
perfect strangers, despite voiced concerns of two peers, when ordered to do so
by a psychologist.
100%
90%
80%

Obedience

70%
60%
50%
40%

Two dissenting peers

30%

Baseline

20%
10%
0%
15

30 45 60
Slight

75 90 105 120 135 150 165 180 195 210 225 240 255 270 285 300 315 330 345 360 375 390 405 420 435 450
Moderate

Strong

Very strong

Intense

Extreme intensity Danger: Severe

XXX

Voltage and Description

Source: Milgram (1974).

Dissenting Peers
Although most variants of the baseline Milgram experiment elicit similar levels of
obedience, a few specific alternatives do not. One features “dissenting peers”.
This variant features three “teachers” – one reads the question aloud, the second
indicates if the answer was correct, and the third (the actual subject) throws the switch to

12

initiate the shock. At 150 volts, the first “teacher” objects and walks out. The psychologist
tells the subject to ask the questions and throw the electric switches. At 210 volts, the
second “teacher” also refuses to continue. The psychologist then tells the subject to go
on. The fraction of real subjects who continue administering shocks falls sharply when
these “peers” began voicing “dissent”. Milgram (1974, p. 118) notes that “the effects of
peer rebellion are very impressive in undercutting the experimenter’s authority.” Figure 6
illustrates.
In the most recent replication of Milgram’s experiments, Burger (2009, p. 8)
includes a “dissenting peer” variant, described thus: “The confederate showed no signs
of hesitation until hearing the learner’s ”ugh!” after pressing the 75-volt switch. At that
point, the confederate paused for a few seconds before continuing. After pressing the
90-volt switch and hearing another ”ugh!,” the confederate glanced at the experimenter
and said, “I don’t know about this.” The experimenter responded with his initial prod,
“Please continue.” The confederate paused a few seconds, then said, “I don’t think I can
do this,” and pushed his or her chair a few inches back from the table. The experimenter
then asked the real participant to continue the test, picking up where the other teacher
had left off. The confederate sat silently throughout the rest of the study and avoided
making eye contact with the participant.” Figure 7 summarizes the results.

Figure 7.

Replicating Peer Dissent

The most recent replication terminated the experiment once a subject obeyed
instructions to administer a shock above 150V. A “peer” administers increasing
shocks until the actor exhibits discomfort at 90V, whereupon the peer says “I
don’t think I can do this” and the experimenter instructs the subject to take over.
Results for the 40 baseline runs and 30 “peer dissent” runs are statistically
indistinguishable. A lower fraction of male than female subjects comply fully in
the “peer dissent” variant, but these differences are statistically insignificant.
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%

28

19

12

6

12

11

6

5

All Subjects
(Baseline)

All Subjects Male Subjects Male Subjects
(Peer Dissent) (Baseline) (Peer Dissent)

Subject stopped at or before 150V

16

13

6

6

Female
Subjects
(Baseline)

Female
Subjects
(Peer Dissent)

Subject continued beyond 150V

Source: Burger (2009).

However, findings concordant with Figure 6 emerge from Asch’s (1951) studies
of conformity. If all the other people present concurred that line A was the same length
as the line on the left in Figure 4, the majority of subject concurred even though this was
obviously incorrect. However, if one person dissented from the incorrect consensus, the
subjects always supported the dissident. Burger’s (2009) failure to replicate Milgram’s
findings in Figure 7 is thus unexpected, and this discrepancy requires explanation.

13

Milgrim’s dissenting peers were more dramatic than Burger’s, so the emotional
volume of voiced dissent might be important. Burger used lower voltages, so perhaps
peer dissent is more important where stakes are higher. Burger eliminated subjects he
judged might find the experiment disturbing, so perhaps these are the sort of people
“peer dissent” might affect most. Further work to explain this discrepancy is clearly
needed.
If Milgram is correct is positing “dissenting peers” as mitigating the agentic shift –
in economists’ parlance, reducing subjects’ utility of loyalty – this explains resources
devoted to suppressing dissident voices by repressive regimes, or by elected political
leaders bent certain policies. In either situation, rational decision making suffers.
A large literature on “groupthink” demonstrates how solidly ensconced a clearly
wrongheaded consensus can become. Janis (1972) attributes various political disasters
– Kennedy’s Bay of Pigs invasion of Cuba, Japan’s attack on Pearl Harbor, and
America’s misadventures in Korea and Vietnam – to groupthink, defined as a
psychological predisposition to conform to group expectations. While each of these
fiascos might be attributed to an information cascade, detailed post-mortems expose
clear psychological underpinnings – a feeling of wellbeing associated with conformity to
others’ expectations. Echoing Milgram, Janis argues that groupthink can be mitigated if
groups assign members roles as critical evaluators, group leaders remain impartial, and
multiple groups analyze issues independently. Surowiecki (2004) develops these
concepts further, arguing that independence and freely voiced dissent let groups make
superior decisions while the suppression of dissent induces groupthink.
The “groupthink” literature goes far beyond agency problems. It is nonetheless
clearly relevant to corporate finance because management teams and boards are
“groups” and make important decisions (Shefrin, 2007, c. 9; Bénabou, 2008). This
literature, though influential in other fields, has remarkably little traction in mainstream
economics and finance, even within behavioral subfields. Financial economists studying
decision-making by corporate boards are well-placed to correct this oversight.

Rival Authority Figures
Another Milgram experiment variant led to a complete cessation of obedience halfway
through the experiment. As in the baseline experiment of Figure 2, it featured only one
“teacher”. However, it now included two supervising psychologists “of approximately the
same age and height.” At one hundred and fifty volts, one began a scripted argument
that higher voltage was unnecessary, while the other argued for continuing the
experiment to its end (p. 105). Confronted with discordant authority figures, the
“teachers” sided with the psychologist who proposed ending the experiment in every
case. Milgram (1974, p. 107) notes that “Not a single subject ‘took advantage’ of the
opportunity to continue the shocks, and that “action was stopped dead in its tracks.”
Figure 8 summarizes.
This is the most startling of all the variants Milgram reports, for it suggests that
conflict between rival authority figures might blunt the subject’s utility of loyalty
sufficiently to induce rational decision-making. It raises the disturbing possibility that
destructive behavior by agents loyal to a misguided or criminal principal might be
prevented if a rival principal criticizes what’s going on sufficiently sharply.

14

Figure 8.

Obedience Rates, Disagreeing Authority Figures Variant

Fraction of ordinary Connecticut residents directing electric shocks through
perfect strangers when two psychologists disagree about the need to complete
the experiment.
100%
90%
80%
70%

Obedience

60%
50%
40%
30%

Two rival authorities
20%

Baseline

10%
0%
15

30 45

60 75

Slight

90 105 120 135 150 165 180 195 210 225 240 255 270 285 300 315 330 345 360 375 390 405 420 435 450
Moderate

Strong

Very strong

Intense

Extreme intensity Danger: Severe

XXX

Voltage and Description

Source: Milgram (1974).

Similar situations clearly arise in economics: corporate shareholder meetings can
disconcertingly resemble the parliaments of one-party states. Board elections typically
permit only one candidate for each board position and shareholders can often only vote
“yes” or abstain. The overt absence of alternative authority figures in these situations
raises the clear possibility of excessive loyalty to the party in charge: whether a CEO,
controlling shareholder, or business family patriarch.
Figure 8 suggests that merely hearing a rival authority voice objections can, in
some cases at least, fully blunt the subject’s utility of loyalty, undo the agentic shift, and
restore what economists consider normal rational decision-making. Disputes between
rival authority figures seem to undermine our willingness to obey authority and revitalize
our willingness to weigh alternatives rationally and ethically. Observing authorities in
conflict seems to evoke independent thought.
Behavioral corporate finance might fruitfully explore the extent to which CEOs
value harmonious board meetings. Does harmony signify good governance or a board
incapable of tackling difficult issues?

5.

Dissent as Loyalty

If generalized agency problem occur throughout the economy and society, individuals
can err either by acting for themselves when they should act as agents of others, or by
acting as agents when they should be thinking for themselves. Soldiers pilfering from
army stores exemplify our standard agency problems of insufficient loyalty, might
soldiers killing merely because they are ordered to constitute an agency problem of

15

excessive loyalty? Bureaucrats diverting taxpayers’ money for kickbacks exhibit
insufficient loyalty to the government; but might bureaucrats obeying their superiors’
orders to violate core civil rights represent excessive loyalty? Judges misusing their
offices to extract bribes are thought insufficiently loyal to the rule of law; but are judges
who rigidly enforce legalistic absurdities perhaps excessively loyal to that abstraction?
If excessive agentic loyalty is as big a potential problem as insufficient loyalty, we
should see institutional mechanisms designed, or evolved, to restrict loyalty to authority
where it is potentially most costly. The following are proposed as possible examples of
institutional arrangements that successfully check excessive loyalty to authority.

The Holy Office of the Devil’s Advocate
An early example is the Holy Office of the Devil’s Advocate, also called the Promoter of
the Faith, a senior position in the Roman Catholic Hierarchy established by Pope Sixtus
V in 1587 for a leading scholar of Canon Law. This early Counterreformation reform
sought to cleanse the Roman Church of its Renaissance practice of canonizing powerful
individuals, their friends, and their relatives. The Devil’s Advocate needed a profound
knowledge of canon law, for his duty was to challenge vigorously the character and
miraculous credibility of all sainthood candidates. Like the second psychologist in Figure
8, the Devil’s Advocate was required to vociferously oppose all proposed saints through
the lengthy and legalistic process of canonization.
Devil’s Advocates did much to refurbish the Church’s reputation. The Holy Office
of the Devil’s Advocate remained a prominent position in the Church until abolished by
John Paul II in 1983. The Polish Pope proceeded to canonize fivefold more saints than
all other 20th century pontiffs combined, suggesting that the Devil’s Advocate was a
significant hindrance to the advocates of prospective new saints.

The Common Law and the Adversary System
Common Law judicial systems – used in Britain and its ex-colonies, charge judges with
interpreting general legal principles. This avoids making judges excessively obedient to
political authorities. This limits agency problem of excessively loyal judges, but risks
judges abuse their discretion to advance their self-interest. In contrast, the Napoleonic
Code, the basis of the French legal system, requires judges to administer minutely
detailed regulations, severely restricting judicial discretion, and hence judges’ scope for
abuse of power, but renders the entire legal system vulnerable to excessively loyal
judges enforcing executive or legislative measures Common Law judges would have
rejected as unconstitutional.
Glaeser and Shleifer (2002) argue that France’s more tumultuous early history
exposed judges to bribes and threats from powerful litigants, escalating agency
problems of insufficient loyalty to the nation. In they argue that judges were less subject
to such pressures, and could therefore be trusted with more discretion.
Hostettler (2006) goes further, arguing that the English Civil War saw a judiciary
divided between Royal Courts, with judges appointed by the King, and resembling
continental courts, and relatively independent Courts of Common Law, whose judges
ruled by precedent and tradition. The victory of the Parliamentary army, augmented by
popular revulsion at the excesses of some Royal Courts, notably the Court of Star

16

Chamber, left the commanding heights of England’s judiciary to its Courts of Common
Law.
A fundamental difference in the ways the Napoleonic Code and Common Law
envision the law itself illustrates how the French system removes discretion while the
English system embraces it. The Napoleonic Code and its successors in France and
elsewhere seek to banish all ambiguity by preconceiving of every possible case and its
correct resolution. The purpose of the French Code is to let a judge resolve any case by
turning to the appropriate page of the Code and reading off the correct judgment. France,
and countries that inherited or adopted French legal systems, thus have extraordinarily
long legal codes that, in minutely intricate detail, describe in advance all possible
permutations of conflicts and the correct decision in every conceivable case. Common
Law countries tend instead to have relatively brief codified laws that often turn on
whether or not a litigant acts like reasonable man or a prudent man. The Common Law
judge, or jury, thus has wide discretion to apply common sense in resolving the case.
As Figure 8 indicates, one potential way to limit excessive obedience is to charge
one authority figure with the explicit duty of criticizing another. French courts employ an
inquisitorial system: the judge summons and grills witnesses, orders investigations, and
actively runs his court. This gives the judge a wide scope to ascertain facts so the
appropriate section of the Code is applied. However, there is but one authority figure in
the court – the judge.
Common Law courts, in contrast, are organized around the so-called adversary
system: each lawyer has an unassailable loyalty to her client and an active duty to
undermine the case advanced by the other side (Langbein, 2006). Thus, neither side
has a duty to pursue or reveal the truth, and scholars of the Continental legal traditions
often dispute the virtue of this. However, the adversary system inserts two rival authority
figures into each case – perhaps so the judge, and the jury are forced into a mode of
thought conducive to rationally weighing of the evidence. Casting the lawyers as direct
and active adversaries makes their rivalry the center of attention, evoking the rival
authorities in Figure 8 and perhaps eliciting rational decision-making in the passive judge
and jury. This accords with the observation of Hostettler (2006) that the adversary
system limits judges’ ability to influence the direction of arguments.
The strength of the inquisitorial system is that the judge is charged with revealing
the truth, while the adversary system instead charges lawyers with destroying each
others’ cases. The strength of the adversary system is that it features rival authority
figures, which might evoke rational decision making in observers – the judge and jury,
while the inquisitorial system puts a single author figure, risking excessive deferral to the
judge by the litigants and their counsels. How these pluses and minuses net out, in
different branches of the Law and in different circumstances, is an empirical question as
yet unexplored.
The Law and Finance literature shows substantially larger and more active
financial systems in Common Law countries (La Porta et al. 2008). Might the adversary
system provide better quality outcomes to litigation regarding securities law? Might the
weaknesses of an inquisitorial system be especially troublesome for such litigation?

17

The Leader of Her Majesty’s Loyal Opposition
The Westminster model of parliamentary democracy likewise charges a Leader of the
Official Opposition with the explicit duty of persistently criticizing the party power. This
position evolved slowly after the Glorious Revolution as a way to limit first the power of
the Kings and then the power of elected Prime Ministers (Fourd, 1964). From the 18th
century on, Leaders of the Loyal Opposition have been duty bound to criticize all
government policies, and failing to do so came to be seen as disloyalty to the electorate
(O’Gorman, 1982). A purer application of Milgram’s Figure 8 findings is hard to imagine.
Multi-party democracy spread to America, the European Continent, the
Commonwealth, and beyond. In countries adhering closely to the Westminster Model –
Australia, Canada, India, Israel, and other former British colonies that remain
democracies – a Leader of the Official Opposition sits in Parliament directly across from
the Prime Minister, a Finance Critic in the Official Opposition sits directly across from the
Finance Minister, and so on. In the United States, the most senior politician in the
legislature from a party other than the president’s serves as de facto leader of the
opposition, and majority and minority members of various Congressional committees
argue with each other.
Different countries designate their leaders of the opposition differently, but the
existence and importance of this position is now universal among functioning
democracies. It seems likely that these formalizations of a duty to criticize the
government underlie, at least to some extent, the superior provision of public goods and
services evident in democracies.

Academic Discussants and Referees
Each speaker at an academic economics or finance conference must usually endure a
subsequent ten minute critique by a discussant – another academic charged by the
conference organizers with highlighting any and all the speaker’s errors. Researchers
seeking to publish must subject their work to the merciless criticism of anonymous
academic referees, whose explicit duty is to expose errors in the research. Work failing
either test is generally not accepted as valid by other researchers.
Peer review in academia is a recent innovation, dating only back to the 1960s in
many fields. Although the first recorded peer review process was administered by Henry
Oldenburg, the founding editor of Philosophical Transactions of the Royal Society, and
the first peer reviewed journal was Medical Essays and Observations, published by the
Royal Society of Edinburgh in 1731, other fields took little notice (Benos et al. 2007).
None of Albert Einstein’s major papers was peer reviewed, for example. The bottleneck
may have been readily generating multiple copies of manuscripts, and Spier (2002)
argues that the advent of the Xerox machine in the 1960s made peer review practical
across all fields. Editors who charge a referee with criticizing a paper are, in essence,
designating a rival authority the duty of criticizing the original researchers – evoking once
again the situation in Figure 8. Prominent researchers may still have an easier time
publishing, but the process at least the big name author is no longer an unchallenged
authority figure.
Peer review is often, and probably rightly, criticized for inflicting a conservatism
bias (Samuelson and Zeckhauser, 1988) upon academic journals (Editors of Nature,

18

2003). Does the advantage of conflicting authorities outweigh the costs peer review
imposes? This too is an empirical question, as yet unresolved.

6.

Agentic Shift as a Behavioral Factor in Economics

Each of the examples sketched out in Section 5 involved institutions explicitly organized
to evoke criticism of authority. The development of these institutions took centuries,
perhaps millennia, and their success is not yet complete. America’s adversary system
did not preclude Guantanamo Bay, Robert Mugabe’s Zimbabwe inherited a Westminster
model parliament, and peer review rejects the occasional path-breaking insight. But
much of the world still uncritically obeys religious, political, judicial, and academic
authorities – and remains largely aloof from the social and technological progress of the
current era.
Business corporations, in this respect, tend to resemble one-party states rather
than parliamentary democracies (Bebchuk, 2007). It therefore seems plausible that
agentic shifts might induce excessive obedience in business corporations. Such an
agentic shift might entail, for example, directors enchanted by a powerful CEO feeling a
profound duty to live up to the CEO’s expectations, but giving little thought to how their
actions might affect shareholders, or other stakeholders’ welfare for that matter. Mace
(1986) presents evidence that CEOs cultivate such loyalty, and that it renders corporate
boards largely ineffective as checks on errant CEOs.

The Scope for Agency Problems of Excess Loyalty in Economics
Jensen (1993, pp. 862-3), in his Presidential Address to the American Finance
Association, observes that “the problems with corporate internal control systems start
with the board of directors. The board, at the apex of the internal control system, has the
final responsibility for the functioning of the firm. Most importantly, it sets the rules of the
game for the CEO. The job of the board is to hire, fire, and compensate the CEO, and to
provide high-level counsel. Few boards in the past decades have done this job well in
the absence of external crisis. This is particularly unfortunate given that the very purpose
of the internal control mechanism is to provide an early warning system to put the
organization on track before difficulties reach a crisis stage. The reasons for the failure
of the board are not completely understood ….”
The Milgram results, applied to boardrooms, suggest directors obtain positive
feelings from acts of loyalty to a proximate CEO perceived as a “leader”. This reflexive
obedience to authority is a plausible answer to Jensen’s (1993) puzzlement. The primary
focus in the corporate finance literature has been enhancing seemingly insufficient
loyalty to shareholders. The analysis above suggests that curtailing seemingly excessive
loyalty to CEOs or controlling shareholders might be at least as important.
In a modern liberal democracy, few jobs provide more scope for unfettered
“leadership” than that of corporate CEO. Checks and balances constrain politicians and
judges. Corporate CEOs essentially appoint the boards that set CEO pay and preside
over uncontested elections at shareholder annual meetings that are worthy of any Cold
War people’s republic. CEOs can hire and fire as they please; direct capital where they
wish; and organize and reorganize their firms as they like.
This system does not ensure optimal decision making. A huge literature in
corporate finance attests to share prices abruptly plummeting when boards approve

19

obviously misguided mergers (Morck et al. 1990; Moeller et al. 2005). Misguided
takeovers are but one example of wrongheaded capital spending, or free cash flow
agency problems, which Jensen (1986) would counter by enhancing directors’ loyalty to
shareholders. But curtailing their excessive loyalty to the CEO seems at least as
plausible a solution. Akerloff and Shiller (2009) resurrect Keynes’ (1936) theory that
psychologically-based “animal spirits” drive waves of over and under-investment,
reiterating Keynes’ (c. 12) explanation that underlings reinforce these costly economywide resource misallocations by loyally telling CEOs what they want to hear. This, they
argue, induces booms and busts that destabilize economic growth, with considerable
welfare loss (Akerlof and Shiller 2009).
Loyalty is a highly valued characteristic in most corporate cultures (Akerlof and
Yellen, 1986). However, loyalty towards an abstraction, like a corporation or an
anonymous public shareholder, may be less viable than loyalty toward a leader – indeed,
this is the gist of much of the “leadership” literature (add cite).2 Corporate whistle blowers,
even those who expose serious frauds, are often rewarded with broken lives (Alford,
2000); and terms like rat, tattletale and snitch attest to the social opprobrium of disloyalty.
Prospective whistleblowers must be given pause by motion picture mogul Samuel
Goldwyn’s famous bluster, “I don’t want any yes-men around me! I want everyone to tell
me the truth – even if it costs him his job!”
The case of Enron is especially instructive. 3 The chairman, Kenneth Lay,
testifying at the House Energy and Commerce Committee explained that Enron “was a
very large corporation. It would be impossible to know everything that was going on.”
Sherron Watkins, a financially savvy Enron executive, testified that she repeatedly tried
to explain the situation to him, but that he either would not listen or simply “didn’t get it.”
Addressing a congressional committee, the bankrupt firm’s new president, Jeffrey
McMahon described “a corporate climate in which anyone who tried to challenge
questionable practices of Enron’s former chief financial officer, Andrew S. Fascow, faced
the prospect of being reassigned or losing a bonus.” Ms Watkins went on to describe a
culture of intimidation in which there was a widespread knowledge of the company’s
tenuous finances, but no-one felt confident enough to confront Mr. Skilling or other
senior officials about it. After the déluge, Enron employees at all levels protested "I was
only doing my job" (Cohan, 2002).

Voice as Loyalty
Eliminating all agency problems of excessive loyalty is surely as impossible as
eliminating all agency problems of insufficient loyalty, so tradeoffs are unavoidable. The
evolution of economic institutions should bring us towards more nuanced tradeoffs.
Firms and countries that better limit the dual problems of insufficient and excessive
loyalty should prosper more consistently, and their institutions should inspire imitation.
This potential for a better balance seems especially great in corporate governance.

2

Fama (1980) and Fama and Jensen (1983) argue that directors seek to build reputations as effective
monitors. However, such reputations may not be the key to successful careers as directors. A reputation
as a “loose cannon” or a “troublemaker” may be a bigger impediment than a reputation as a “yes man”
(Mace, 1971; Westphal and Stern, 2006, 2007).
3
The quotes and synopses in this paragraph are from Cohan ( 2002).

20

The Milgram experiment variants involving rival authorities and dissenting peers
argue for some analog in the boardroom to a Leader of the Official Opposition in
Parliament or an academic discussant at the American Economic Association. At
present, the form this analog will ultimately take is unclear, for which arrangements most
effectively check excessively agentic behavior while imposing the least drag on
economic activity remain ambiguous.

Regulation
The Enron scandal and other instances of excessive obedience to misguided authority at
the time prompted various measures to reshape corporate governance in America –
most prominently, the Sarbanes Oxley Act. This reorganized the accounting industry,
forces senior executives to sign various financial statements, and requires companies to
establish internal control systems. Sarbanes-Oxley may well be too expensive, as its
opponents charge (Leuz et al. 2007; Marosi and Massoud, 2007; Zhang, 2007; and
others), and may soon be undone (Romano, 2005). The act had no apparent effect in
limiting the scope of a second round of governance scandals in the financial sector that
came to light in 2007 and 2008.
Perhaps this is because the Act merely reinforces existing penalties on errant
CEOs and CFOs; who – entirely convinced of the rightness of their policies (Festinger,
1957) – are unlikely to do anything differently absent overt criticism that highlights
looming errors. A better balance may emerge from responses to the current round of
scandals in the financial sector. Theoretical and empirical work informed by both
economics and social psychology is needed to guide such responses. More
comprehensive legislation to protect legitimate whistle blowers is one possible route.

Dissent and Rival Authority Figures on the Board
The corporate governance literature places much stress on non-executive chairs and
independent directors (Herman, 1981; Mace, 1971; Weisbach, 1988; Morck, Shleifer,
and Vishny 1989; Rosenstein and Wyatt 1990). While the finance literature frames these
as mechanisms to enhance director loyalty to public shareholders; they are also
defensible as mechanisms to disrupt director loyalty to CEOs.
Non-executive chairs and independent directors correlate with CEO departures
after poor performance, but not firm valuations (Kang and Sorensen, 1999; Hermalin and
Weisbach, 2003).4 Moreover, these mechanisms were in place at Enron – the CEO did
not chair the board and the board contained a healthy proportion of independent
directors. Although the chair or independent directors might have acted like the second
psychologist or dissenting peers in Enron board meetings, they did not.
The Higgs Report, a British corporate governance study, suggests a reason for
this. The biographies of British independent directors and nonexecutive chairs of
corporate boards show that most are friends of the CEO who pass various tests of
independence. For instance, a college room-mate, fellow club member, or neighbor
4

The efficacy of independent directors is also criticized conceptually. Adams et al. (2005) argue that the
CEO can manipulate agendas to frame issues most easily if she is the only insider on the board, and that
boards entirely composed of independent directors actually strengthen the CEO’s power. Ocasio (1994)
argues that other corporate insiders on boards can emerge as alternative “leaders” if they feel they can
usurp the CEO’s position. In either case, outsiders are advanced as potentially better dissidents.

21

qualifies if he has no financial dealings with the corporation; and CEOs can play games
of tit-for-tat (Axelrod, 1984) by serving as “independent” directors on each others’ boards.
The Higgs Report recommends stronger standards of “independence” that preclude
personal or family relationships as well as financial ties.
One option is to have directors certify their own independence, and face severe
liability for misstatements. Another would remove the process of nominating directors
from the CEO to shareholders (Shivdasani and Yermack 1999). Still another would add
a mandate that elections for board positions always be contested.
Such measures must be weighed against their costs. Adams et al. (2005) show
powerful CEOs raise firm performance variation: some outperform and others
underperform. Always constraining CEOs may thus be inappropriate. Good governance
requires appropriate disloyalty – voiced criticism when the CEO is making an obvious
mistake, but not when she is enacting a visionary strategy. In practice, this distinction is
difficult, and further research is needed to develop and resolve these issues.

Dissent and Rival Authority Figures in the Shareholders Meeting
Another way interrupting loyalty to the CEO might be to encourage voiced dissent or
rival authority figures at shareholder meetings. One option would reorganize share
ownership to more strongly favor institutional investors (pension funds, insurance funds,
etc.) over individual shareholders (Shleifer and Vishny, 1986) via tax or regulatory
reforms (Cheffins, 2009). This envisions sophisticated fund managers calling out
underperforming CEOs, and even organizing proxy contests – opposition candidates to
replace underperforming boards (Shleifer and Vishny, 1997). Board election systems
that make this easier do correlate with superior valuations (Bebchuk and Cohen 2005;
Faleye, 2007). Black and Coffee (1994) point to Britain as an economy relying heavily on
this approach.
These mechanisms also have costs. Fund managers, like CEOs, control other
people’s money, and might likewise divert funds to maximize their own utility (Romano,
1993). Fund managers may also be less sophisticated than commonly believed
(Lakonishok et al. 1992).

Takeovers
An active market for corporate control is often advocated as governance improving, and
this seems empirically founded in 1980s America (Morck et al. 1989) and more generally
in Britain (Cheffins, 2009). This circumvents the whole issue of board loyalty to the CEO:
weak governance depresses share prices rendering misgoverned firms “bargains” for
raiders who buy them, fix them up, and resell them – a sort of corporate gentrification.
From the 1990s on, most American CEOs convinced their boards to approve
effective takeover defenses, like poison pills and staggered director elections; and
corporate funded lobbying changed state laws to obstruct takeovers. Firms with stronger
takeover barriers have lower valuations (Gompers et al. 2003). Failure to account for
excessively loyal boards may blunted takeovers as a governance-enhancing mechanism
in America.

22

Behavioral Biases to Counter Behavioral Biases
Information cascades – seemingly excessive conformity by rational agents economizing
on information costs – are a potentially viable rational explanation for Milgram’s results.
This literature explains other behavioral biases as helping damp information cascades.
Noth and Weber (2003) see individually irrational overconfidence inducing agents to
make their own decisions and deterring information cascades. Kübler and Weizsäcker
(2004) observe experimental subjects overpaying for signals, and suggest this
apparently irrational behavior likewise damps information cascades. Arya et al. (2006)
propose that noisy information can sometimes be better than clear signals. Directors
unsure what the CEO thinks might think for themselves.

7.

Conclusions

Milgram’s (1974) experiments suggest human nature includes an Agentic shift: a
reflexive obedience to legitimate authorities whereby people recast themselves as
agents, rather than autonomous decision makers. Where this reflex disposes
subordinates and boards to support CEOs advancing wrongheaded strategies, a
behaviorally-grounded agency problem of excessive loyalty imposes economic costs.
Because it connects to morally charged concepts like loyalty, trust, and duty, this
subservience is difficult to overcome. Its moral overtone also lets people behave in
overtly unethical ways, yet justify their behavior in terms of these charged concepts.
Thus, managers and directors justify acquiescence to corporate fraud as loyalty, trust,
and duty to a powerful CEO.
Effective governance reform overcomes both the standard economic agency
problem of insufficient loyalty (Jensen and Meckling 1976) and this behaviorally based
agency problem of excessive loyalty. Milgram reports that distant authorities, dissenting
peers, and rival authorities reinitiate subjects’ rational reasoning.
Corporate governance reforms that distance the CEO from the board, induce
constructive dissent at board meetings, or create rival authority figures to challenge
errant CEOs suggest key committees suggest themselves. These include excluding
CEOs from key board committees, populating boards with outspokenly independent
directors, and charging a nonexecutive chair or lead independent director with a duty to
challenge the CEO. These mechanisms are not empirically strongly correlated with
superior corporate performance. One possible explanation is that CEOs choose
independent directors, non-executive chairs, etc. who are likely to be loyal. Another is
that the behavioral impulse to loyalty is hard to overcome.

References
Adams, Renée, Heitor Almeida and Daniel Ferreira. 2005. “Powerful CEOs and Their Impact on
Corporate Performance.” Review of Financial Studies 18:4, 1403-32.
Akerlof, George and Janet Yellen. 1986. Efficiency Wage Models of the Labor Market. Place?:
Academic Press.
Akerlof, George and Robert Shiller. 2009. Animal Spirits: How Human Psychology Drives the
Economy, and Why It Matters for Global Capitalism. Princeton University Press.
Alevy, Jonathan, Michael Haigh, and John List. 2007. “Information Cascades: Evidence from a
Field Experiment with Financial Market Professionals.” Journal of Finance 62:1, 151.

23

Alford, C. Fred. 2000. Whistleblowers: Broken Lives and Organizational Power. Place?: Cornell
University Press.
Amihud, Yakov and Shmuel Hauser, Amir Kirsh. 2003. “Allocations, Adverse Selection, and
Cascades in IPOs: Evidence from the Tel Aviv Stock Exchange.” Journal of Financial
Economics 68:1, 137-58.
Anderson, Lisa and Charles Holt. 1997. “Information Cascades in the Laboratory.” American
Economic Review 87:5, 847-62.
Arya, Anil, Jonathan Glover, and Brian Mittendorf. 2006. “Hierarchical Reporting, Aggregation,
and Information Cascades.” Managerial and Decision Economics 27:5, 355.
Asch, Solomon. 1951. “Effects of Group Pressure upon the Modification and Distortion of
Judgment.” In H. Guetzkow (ed.) Groups, Leadership, and Men. Pittsburgh: Carnegie
Press.
Asch, Solomon. 1955. “Opinions and Social Pressure.” Scientific American 193, 31-35
Axelrod, R. 1984. The Evolution of Cooperation. Place?: Basic Books.
Banerjee, Abhijit. 1992. “A Simple Model of Herd Behavior.” Quarterly Journal of Economics
107:3, 797-817.
Baumrind, D. 1964. “Some Thoughts on Ethics of Research: After reading Milgram’s “Behavioral
Study of Obedience.” American Psychologist 19 421-423.
Bebchuk, Lucian and Alma Cohen. 2005. “The Costs of Entrenched Boards.” Journal of Financial
Economics 78:2, 409-33.
Bebchuk, Lucian. 2007. “The Myth of the Shareholder Franchise.” Virginia Law Review 93, 675.
Bénabou, Roland. 2008. Groupthink: Collective Delusions in Organizations and Markets.
Princeton University working paper.
Benos, Dale J., Edlira Bashari, Jose M. Chaves, Amit Gaggar, Niren Kapoor, Martin LaFrance,
Robert Mans, David Mayhew, Sara McGowan, Abigail Polter, Yawar Qadri, Shanta
Sarfare, Kevin Schultz, Ryan Splittgerber, Jason Stephenson, Cristy Tower, R. Grace
Walton and Alexander Zotov. 2007. “The Ups and Downs of Peer Review.” Advances in
Physiology Education 31, 145–152.
Bernardo, Antonio, and Ivo Welch. 2001. “On the Evolution of Overconfidence and
Entrepreneurs.” Journal of Economics and Management Strategy 10:3, 301-30.
Bikhchandaqni, Sahil, David Hirschleifer, and Ivo Welch. 1992. “A Theory of Fashion, Custom,
and Cultural Change.” Journal of Political Economy 100:5, 992-1026.
Black, Bernard and Jack Coffee. 1994. “Hail Britannia? Institutional investor behavior under
limited regulation.” Michigan Law Review 92, 1999-2088.
Blass, Thomas. 1998. “A Cross Cultural Comparison of Studies of Obedience using the Milgram
Paradigm.” Unpublished.
Blass, Thomas. 2000. “The Milgram Paradigm After 35 years: Some Things We Know about
Obedience to Authority.” In Thomas Blass, ed. Obedience to Authority – Current
Perspectives on the Milgram Paradigm. Mahwah, NJ: Lawrence Erlbaum.
Blass, Thomas. 2004. The Man Who Shocked the World: The Life and Legacy of Stanley Milgram.
Place?: Basic Books.
Broad, Charlie. 1930. Five Types of Ethical Theory. Place?: Harcourt, Brace and Co.
Burger, Jerry. 2009. “Replicating Milgram: Would People Still Obey Today?” American
Psychologist 64, 1-11.
Brian R. Cheffins, Brian. 2008. Corporate Ownership and Control: British Business Transformed.
Oxford University Press.
Cialdini, Robert. 1998. Influence: The Psychology of Persuasion. Place?: Quill.
Cialdini, Robert, Kallgren, Carl and Raymond Reno. 1991. “A focus theory of normative conduct.”
Advances in experimental social psychology 24 201-234.
Cialdini, Robert and Noah Goldstein. 2004. Social influence: Compliance and conformity. Annual
Review of Psychology 55 591-621.

24

Cohan, John Alan. 2002. "I didn't know” and "I was only doing my job": Has Corporate
Governance Careened Out of Control? A Case Study of Enron’s Information Myopia.”
Journal of Business Ethics 40:2, 275-99.
Crossland, Philip and Faye Smith. 2002. “Value Creation in Fine Arts: A System Dynamics Model
of Inverse Demand and Information Cascades.” Strategic Management Journal 23:5,
417-34.
De Vany, Arthur and Cassey Lee. 2001. “Quality Signals in Information Cascades and the
Dynamics of the Distribution of Motion Picture Box Office Revenues.” Journal of
Economic Dynamics & Control 25:3/4, 593-614.
De Vany, Arthur and David Walls. 1996. “Bose-Einstien Dynamics and Adaptive Contracting in
the Motion Picture Industry.” Economic Journal 106:439, 1493-1514.
De Waal, Frans. 2005. Our Inner Ape: A Leading Primatologist Explains Why We Are Who We
Are. Place?: Penguin.
Drehmann, Mathias, Jörg Oechssler, and Andreas Roider. 2002. “Herding and Contrarian
Behavior in Financial Markets: An Internet Experiment.” American Economic Review 95:5,
1403-26.
Editors of Nature. 2003. “Coping with Peer Rejection.” Nature, 425 645.
Elms, A. C. 1995. “Obedience in Retrospect.” Journal of Social Issues 51, 21–31.
Faleye, Olubunmi. 2007. “Classified Boards, Firm value, and Managerial Entrenchment.” Journal
of Financial Economics 83, 501-529.
Fama, Eugene. 1980. “Agency Problems and the Theory of the Firm.” Journal of Political
Economy 88, 288-307.
Fama, Eugene and Michael Jensen. 1983. “The Separation of Ownership and Control.” Journal of
Law and Economics 26, 301-25.
Festinger, Leon. 1957. A Theory of Cognitive Dissonance. Stanford: Stanford University Press.
Fischer, C. T. 1968. “Ethical Issues in the Use of Human Subjects.” American Psychologist 23,
532.
Fourd, Archibald. 1964. His Majesty’s Opposition, 1714 – 1830. Place?: Oxford University Press.
Gergen, K.J. 1973. “Social Psychology as History.” Journal of Personality and Social Psychology
26, 309-320.
Gilbert, Steven.1981. “Another look at the Milgram obedience studies: The role of a graduated
series of shocks.” Personality and Social Psychology Bulletin 7 690-95.
Glaeser, Edward and Andrei Shleifer. 2002. “Legal Origins.” Quarterly Journal of Economics
117:4, 1193.
Packer, Dominic. 2008. Identifying Systematic Disobedience in Milgram’s Obedience
Experiments: A Meta-Analytic Review.” Perspectives on Psychological Science 3(4) 3014.
Gompers, Paul, Joy Ishii and Andrew Metrick. 2003. “Corporate Governance and Equity Prices.”
Quarterly Journal of Economics 118:1, 107-55.
Gul, Faruk, and Russel Lundholm. 1995. “Endogenous Timing and the Clustering of Agents’
Decisions.” Journal of Political Economy 103:5, 1039.
Haney, C., Banks, W. C., and Zimbardo, P. G. 1973. “Study of Prisoners and Guards in a
Simulated Prison.” Naval Research Reviews 9, 1–17.
Hermalin, Benjamin and Michael Weisbach. 2003. “Boards of Directors as an Endogenously
Determined Institution: A Survey of the Economic Literature.” Economic Policy Review Federal Reserve Bank of New York 9:1, 7.
Herman, Edward. 1981. Corporate Control. Corporate Power. Place?: Cambridge University
Press.
Hobbes, 1651. Leviathan, or the Matter, Forme, and Power of a Commonwealth Ecclesiasticall
and Civil. London: Andrew Crooke.

25

Hostettler, John. 2006. Fighting for Justice: The History and Origins of Adversary Trial. Place?:
Waterside Press.
Janis, Irving. 1972. Victims of Groupthink: A Psychological Study of Policy Decisions and Fiascoe.
Place?: Houghtom-Muffin.
Jensen, Michael and William. Meckling. 1976. “Theory of the Firm: Managerial Behaviour, Agency
Costs and Ownership Structure.” Journal of Financial Economics 3, 305-60.
Jensen, Michael. 1993. “The Modern Industrial Revolution, Exit and the Failure of Internal Control
Systems.” Journal of Finance 48:3, 831-880.
Kahneman, Daniel and Amos Tversky. 2000. “Choices, Values, and Frames.” Place?: Cambridge
University Press.
Kang, David and Aage Sorensen. 1999. “Ownership Organization and Firm Performance.” Annual
Review of Sociology 25, 121 -144.
Kaufmann, H. 1967. “The Price of Obedience and the Price of Knowledge.” American
Psychologist 22, 321–322.
Keynes, John Maynard. 1936. The General Theory of Employment, Interest and Money. Place?:
Macmillan.
Kübler, Dorothea and Georg Weizsäcker. 2003. “Information Cascades in the Labor Market.”
Journal of Economics 80:3, 211-229.
Kübler, Dorothea and Georg Weizsäcker. 2004. “Limited Depth of Reasoning and Failure of
Cascade Formation in the Laboratory.” Review of Economic Studies 71:2, 425-441.
La Porta, Rafael,
Florencio Lopez-de-Silanes, Andrei Shleifer. 2008. The Economic
Consequences of Legal Origins. Journal of Economic Literature 46(2) 285–332.
Lakonishok, Josef, Andrei Shleifer, Richard Thaler, and Robert Vishny. 1992. “The Structure and
Performance of the Money Management Industry.” Brookings Papers on Economic
Activity 1992:1, 339-92.
Langbein, John. 2006. The Origins of Adversary Criminal Trial. Place?: Oxford University Press.
Laski, Harold J. 1919. “The Dangers of Obedience.” Harper’s Monthly Magazine 159, 1-10.
Leuz, Christian, Alexander Triantis, and Tracy Wang. 2008. “Why Do Firms Go Dark? Causes
and Economic Consequences of Voluntary SEC Deregistrations.” Journal of Accounting
and Economics 45:2-3, 181-208.
Mace, Myles. 1971. Directors: Myth and Reality. Place?: Harvard Business School Press.
Marosi, András and Nadia Massoud. 2007. “Why Do Firms Go Dark?” Journal of Financial and
Quantitative Analysis 42:2, 421.
Martin, J, B. Lobb, Chapman, G. and R. Spillane. 1976. “Obedience Under Conditions
Demanding Self-Immolation.” Human Relation 29:4, 345.
Merritt, A. and R. Helmreich. 1996. “Human Factors of the Flight Deck: The Influence of National
Culture.” Journal of Cross-Cultural Psychology 27, 5-24.
Milgram, Stanley. 1963. “Behavioral Study of Obedience.” Journal of Abnormal and Social
Psychology 67, 371–378.
Milgram, Stanley. 1974. Obedience to Authority. Place?: Harper and Row.
Miller, A.G. 1986. The Obedience Experiment: A Case Study of Controversy in Social Science.
Praeger: New York.
Mixon, D. 1972. “Instead of Deception.” Journal for the Theory of Social Behavior 2, 145–177.
Moeller, Sara, Frederik Schlingemann & René M. Stulz. 2005. “Wealth Destruction on a Massive
Scale? A Study of Acquiring-Firm Returns in the Recent Merger Wave.” Journal of
Finance 60:2, 757-82.
Morck, Randall. 2008. “Behavioral Finance in Corporate Governance: Economics and Ethics of
the Devil’s Advocate.” Journal of Management and Governance 12:2, 179-200.
Morck, Randall, Andrei Shleifer, and Robert Vishny. 1989. “Alternative Mechanisms for Corporate
Control.” American Economic Review. 79:4, 842-852.

26

Morck, Randall, Andrei Shleifer, and Robert Vishny. 1990. “Do Managerial Objectives Drive Bad
Acquisitions.” Journal of Finance 45, 31-48.
Morelli, Mario. 1983. Milgram’s dilemma of obedience. Metaphilosophy 14, 183–89.
North, Douglass. 1990. Institutions, Institutional Change and Economic Performance. Oxford
University Press.
Noth, Markus and Martin Weber. 2003. “Information Aggregation with Random Ordering:
Cascades and Overconfidence.” Economic Journal 113:484, 166-189.
O’Gorman, Frank. 1982. The Emergence of the British two-Party System: 1760 – 1832. Place?:
Edward Arnold.
Ocasio, W. 1994. “Political Dynamics and the Circulation of Power: CEO Succession in U.S.
Industrial Corporations, 1960-1990.” Administrative Science Quarterly 39, 285-312.
Rao, Hayagreeva, Henrich R Greve, and Gerald F Davis. 2001. “Fool’s Gold: Social Proof in the
Initiation and Abandonment of Coverage by Wall Street Analysts.” Administrative Science
Quarterly 46:3, 502-26.
Romano, Roberta. 2005. “The Sarbanes-Oxley Act and the Making of Quack Corporate
Governance.“ Yale Law Journal 114, 1521.
Romano, Roberta. 1993. “Public Pension Fund Activism in Corporate Governance
Reconsidered.” Columbia Law Review 93 795.
Rosenstein, Stuart and Jeffrey Wyatt, “Outside Directors, Board Independence, and Shareholder
Wealth,” Journal of Financial Economics 26, 1990, pp. 175-192.
Samuelson, William and Robert Zeckhauser. 1988. “Status Quo Bias in Decision
Making.“ Journal of Risk and Uncertainty 1, 7-59.
Schurz, G. 1985. “Experimentelle Uberprüfüng des Zusammenhangs Zwischen
Persönlichkeitsmerkmalen und derBereitschaft zum Destruktiven Gehorsam Gegenüber
Autoritäten.“ Zeitschrift für Experimentelle und Angewandte Psychologie 32, 160-77.
Sheridan, C.L. and King, K.G. 1972. “Obedience to Authority with an Authentic
Victim.“ Proceedings of the 80th Annual Convention of the American Psychological
Association 7, 165-6.
Shivdasani, Anil and David Yermack. 1999. “CEO Involvement in the Selection of New Board
Members: An Empirical Analysis.“ Journal of Finance 54, 1829-53.
Shleifer, Andrei and Robert Vishny. 1986. “Large Shareholders and Corporate Control.” Journal
of Political Economy 94(3) 461-88.
Shleifer, Andrei and Robert Vishny. 1997. “A Survey of Corporate Governance.” Journal of
Finance 52:2, 737-84.
Smith, Adam. 1759. The Theory of Moral Sentiments. London: A. Millar
Spier, Ray. 2002. “The History of the Peer-Review Process.” Trends in Biotechnology 20:8, 357358.
Surowiecki, James. 2004. The Wisdom of Crowds. Place?: Doubleday.
Tarnow, Eugen. 2000. “Self-Destructive Obedience in the Airplane Cockpit and the Concept of
Obedience Optimization.” In Thomas Blass (ed.), Obedience to Authority – Current
Perspectives on the Milgram Paradigm. Place?: Publisher.
Weisbach, Michael S. 1988. “Outside Directors and CEO Turnover.” Journal of Financial
Economics 20, 431-460.
Westphal, James and Ithai Stern. 2006. “The Other Pathway to the Boardroom.” Administrative
Science Quarterly 51, 169-204.
Westphal, James and Ithai Stern. 2007. “Flattery Will Get You Everywhere (Especially if You are
a Male Caucasian).” Academy of Management Journal 50:2, 267-88.
Zhang, Ivy Xiying. 2007. “Economic Consequences of the Sarbanes-Oxley Act of 2002.” Journal
of Accounting & Economics 44:1/2, 74.

27

