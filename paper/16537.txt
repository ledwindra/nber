NBER WORKING PAPER SERIES

INFORMATION RIGIDITY AND THE EXPECTATIONS FORMATION PROCESS:
A SIMPLE FRAMEWORK AND NEW FACTS
Olivier Coibion
Yuriy Gorodnichenko
Working Paper 16537
http://www.nber.org/papers/w16537

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2010

We are grateful to Bob Archibald, Christopher Crowe, Zeno Enders, Ulrich Fritsche, Pierre-Olivier
Gourinchas, Ed Knotek, Javier Reyes, David Romer and Chris Sims for helpful comments as well
as seminar participants at the Bank of France, CESifo/LMU Conference on Macroeconomics and Survey
Data, College of William and Mary, Duke, George Washington University, IMF, Minnesota Fed, Richmond
Fed and University of Arkansas. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2010 by Olivier Coibion and Yuriy Gorodnichenko. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.

Information Rigidity and the Expectations Formation Process: A Simple Framework and New
Facts
Olivier Coibion and Yuriy Gorodnichenko
NBER Working Paper No. 16537
November 2010
JEL No. E2,E3,E4
ABSTRACT
We propose a new approach to test of the null of full-information rational expectations which is informative
about whether rejections of the null reflect departures from rationality or full-information. This approach
can also quantify the economic significance of departures from the null by mapping them into the
underlying degree of information rigidity faced by economic agents. Applying this approach to both
U.S. and cross-country data of professional forecasters and other economic agents yields pervasive
evidence of informational rigidities that can be explained by models of imperfect information. Furthermore,
the proposed approach sheds new light on the implications of policies such as inflation-targeting and
those leading to the Great Moderation on expectations. Finally, we document evidence of state-dependence
in the expectations formation process.

Olivier Coibion
Department of Economics
College of William and Mary
115 Morton Hall
Williamsburg, VA 23188
ocoibion@wm.edu
Yuriy Gorodnichenko
Department of Economics
549 Evans Hall #3880
University of California, Berkeley
Berkeley, CA 94720-3880
and NBER
ygorodni@econ.berkeley.edu

I

Introduction

Expectations matter. How much to consume or save, what price to set, and whether to hire or fire
workers are just some of the fundamental decisions underlying macroeconomic dynamics that hinge upon
agents’ expectations of the future. Yet how those expectations are formed, and how best to model this
process, remains an open question. From the simple automatons of adaptive expectations to the allknowing agents of modern full-information rational expectations models, macroeconomists have
considered a wide variety of frameworks to model the expectations formation process, yielding radically
different results for macroeconomic dynamics and policy implications.

Recent work on rational

expectations models with informational frictions such as Mankiw and Reis (2002), Woodford (2001), and
Sims (2003) has emphasized how informational rigidities can account for otherwise puzzling empirical
findings but these same frictions can also lead to policy prescriptions that differ from those under models
with full-information.1 Despite a growing body of work studying the implications of possible departures
from full-information rational expectations, the empirical evidence against this assumption underlying
most modern macroeconomic models has been limited. In particular, while statistical evidence against
the null is commonly uncovered, the economic significance of these rejections remains unclear.
Building from the predictions of rational expectations models with informational rigidities, we
propose a novel approach to test the null of full-information rational expectations in a way that sheds new
light on possible departures from the null. Our baseline specification relates ex post mean forecast errors
to the ex ante revision of the average forecast across agents. While this specification is just a special case
of the traditional test of full-information rational expectations (FIRE) in which one assesses whether
previously available information can predict ex post mean forecast errors, our specification possesses
multiple advantages over this traditional approach.2 First, we rely on the predictions of theoretical models
of informational rigidities to guide our choice of the relevant regressors. This mitigates the data-mining
concern associated with the traditional approach in which, after trying enough potential regressors, one is
bound to reject the null of FIRE. Second, models of informational rigidities make specific predictions
about the sign of the coefficient on forecast revisions, so that our specification provides guidance not only
about the null of FIRE but also about alternative models. As a result, our framework can help determine
1

For example, Ball et al. (2005) show that price-level targeting is optimal in sticky-information models whereas
inflation targeting is optimal in a sticky-price model. Paciello and Wiederholt (2010) document how rational
inattention as in Sims (2003) alters optimal monetary policy. Likewise, Mankiw and Reis (2002) argue that the
observed delayed response of inflation to monetary policy shocks is not readily matched by New Keynesian models
without the addition of informational rigidities or the counterfactual assumption of price indexation. Roberts (1997,
1998) and Adam and Padula (2003) demonstrate that empirical estimates of the slope of the New Keynesian Phillips
Curve have the correct sign when conditioning on survey measures of inflation expectations while this is typically
not the case under the assumption of full-information rational expectations. Piazzesi and Schneider (2008),
Gourinchas and Tornell (2004) and Bachetta et al. (2008) all identify links between systematic forecast errors in
survey forecasts and puzzles in various financial markets.
2
See Pesaran and Weale (2006) for a survey of this literature.

1

whether rejections of the null should be interpreted as rejecting either the rationality of expectations or the
full-information assumption. Third, we show that the coefficient on forecast revisions maps one-to-one
into the underlying degree of information rigidity. Our approach can therefore not only test the null of
FIRE against well-specified alternatives but also provide a metric by which to assess the economic
significance of departures from the null of FIRE.
Two theoretical rational expectations models of informational frictions motivate our empirical
specification.

In the sticky-information model of Mankiw and Reis (2002), agents update their

information sets infrequently as a result of fixed costs to the acquisition of information. When they do
update their information sets, they acquire full-information rational expectations.

The degree of

information rigidity in this model is then the probability of not acquiring new information each period.
The second class of models we consider consists of imperfect information models such as Woodford
(2001), Sims (2003), and Mackowiak and Wiederholt (2009). Here, agents continuously update their
information sets but, because they can never fully observe the true state, they form and update beliefs
about the underlying fundamentals via a signal extraction problem.3 Strikingly, both models predict the
same relationship between ex post mean forecast errors and the ex ante mean forecast revision such that
the coefficient on forecast revisions depends only on the degree of information rigidity in each model.
The resulting empirical specification can be applied to study informational rigidities for a variety
of economic agents such as consumers, firms, central banks and financial market participants for whom
forecast data are available. As a first step, we focus on inflation forecasts from the U.S. Survey of
Professional Forecasters (SPF) for two reasons. First, inflation forecasts have received the most attention
in the literature so that these results are more readily comparable to previous work. Second, because
professional forecasters are some of the most informed economic agents, uncovering significant
informational rigidities for these agents likely presents a lower bound on the importance of informational
rigidities for other less-informed economic agents. From 1969-2010, we can strongly reject the null of
FIRE and find that the estimated coefficient on forecast revisions is positive, consistent with the
prediction of rational expectations models incorporating informational rigidities. Additional coefficient
restrictions implied by these models cannot be rejected and past information incorporated in other
economic variables loses much of its predictive power for ex post mean forecast errors once the forecast
revision is controlled for. Furthermore, the implied degree of information rigidity is high: in the context
of sticky-information models, it implies an average duration of six to seven months between information
updates, while in imperfect information models it implies that new information receives less than half of
the weight that it would under full information when agents are updating their forecasts. We document
3

Earlier work in this tradition includes Lucas (1972) and Kydland and Prescott (1982). A related approach
emphasizes differences in agents’ priors about parameter values rather than differences in information sets. See for
example Patton and Timmermann (2010).

2

that qualitatively similar results obtain for different subsets of professional forecasters, such as academics,
commercial banks, and non-financial businesses, as well as for consumers and financial market-based
inflation expectations. Thus, our results are unlikely to be driven by either strategic behavior on the part
of professional forecasters or reputational considerations.
In addition, we apply our specification to a much broader set of forecasted macroeconomic
variables. First, the SPF includes historical forecasts for four other macroeconomic variables going back
to 1968, including real GDP and unemployment, at multiple forecasting horizons. Our approach can
exploit both the multiple forecasting horizons and different macroeconomic variables, allowing us to
extract more precise estimates of informational rigidities than in previous work. Pooling across these
variables and forecasting horizons leads to even stronger rejections of the null of FIRE, again in the
direction predicted by models of informational rigidities. Second, starting in 1981, the SPF includes
forecasts of seven additional macroeconomic variables, again at multiple forecasting horizons. Using this
larger set of variables confirms the baseline finding: we can reject the null of FIRE in exactly the
direction predicted by models with informational frictions and the estimates point to economically
significant degrees of informational rigidities. Third, we utilize an additional survey of professional
forecasters constructed by Consensus Economics which includes quarterly historical forecasts since 1989
of five macroeconomic variables for the G-7 and five additional industrialized countries, again at multiple
forecasting horizons. Pooling across these countries, variables and horizons, yields an almost identical
coefficient on forecast revisions, providing further evidence that professional forecasters are subject to
significant informational rigidities.
Our approach can also shed light on the relative merit of different models of informational
rigidities. For example, the sticky-information model implies a common rate of information updating for
all macroeconomic variables, whereas imperfect information models imply that the degree of information
rigidity associated with a macroeconomic variable should vary according to the persistence of each
variable and the signal-noise ratio associated with it. Across datasets, we find robust evidence that the
degree of information rigidity varies systematically across macroeconomic variables and that this crosssectional variation is consistent with the predicted determinants of imperfect information models: the
persistence of a variable and measures of the signal-noise ratio can account for about 20-30 percent of the
variation in the estimated degree of information rigidity across countries and macroeconomic variables in
the Consensus Economics dataset.

Thus, imperfect information models appear to be a reasonable

description of the underlying expectations formation process for professional forecasters.
Because our empirical specification allows us to recover estimates of the underlying degree of
information rigidity, we also consider some policy determinants of the expectations formation process.
For example, the monetary policy changes enacted by Volcker contributed to the Great Moderation
3

(Clarida et al. (2000), Coibion and Gorodnichenko (2009)), the period of diminished macroeconomic
volatility since the early to mid-1980s. According to models with informational rigidities, such a decline
in volatility should result in a higher degree of inattention. We study the low-frequency time variation in
the estimated degree of information rigidity among U.S. professional forecasters and find evidence that
accords remarkably well with this intuition: the degree of information rigidity fell consistently throughout
the 1970s and early 1980s when macroeconomic volatility was high, reaching a minimum around 198384.

Since then, the degree of information rigidity has been consistently rising as macroeconomic

volatility has been subdued. One interpretation of this result could be that the changes in monetary policy
enacted by Volcker helped stabilize the economy in the Great Moderation, but this economic stabilization
also promoted greater inattention on the part of economic agents, thereby, in the end, making the
economy more susceptible to economic shocks. This suggests an additional mechanism, along with
increased risk-taking on the part of financial market participants, through which the Great Moderation
may have contributed to the severity of the Great Recession.
Our approach is also well-suited to evaluate and quantify the effect of policy or institutional
changes on the expectations formation process. To illustrate, we first study the effect of central bank
independence on the expectations formation process and we find a strong positive relationship between
central bank independence and information rigidity. We also consider the adoption of inflation-targeting
by central banks within our cross-country data, a policy explicitly expected to stabilize or “anchor”
agents’ inflation expectations. Such regimes should, if credible, increase inattention to inflation on the
part of economic agents leading to lower volatility in expectations of future outcomes. We find that the
effect of adopting an inflation-targeting regime on the degree of inattention in inflationary expectations of
professional forecasters is small and not statistically significant, casting doubt on the efficacy of this
policy, at least among the already-stable set of countries in our sample. This approach could readily be
extended to a larger set of countries and other policy issues such as exchange rate regimes which are
predicted to have important effects on expectations. Thus, an additional contribution of the paper is to
provide a framework for analyzing the effects of different policy regimes on the expectations formation
process of economic agents.
While research on sticky information and imperfect information typically expresses these notions
in a time-dependent setting, one might naturally expect large and visible shocks to affect the rate of
information-acquisition and processing by economic agents, i.e. state-dependence should be characteristic
in the face of large shocks as theoretically documented in Gorodnichenko (2008). We consider this
possibility by studying the time-variation in the degree of informational rigidities in two cases. First, we
estimate the average effect of recessions on the degree of information rigidity in the U.S. since 1969. We
find that the degree of information rigidity declines substantially after a few quarters of being in a
4

recession and gradually recovers over time. Second, we consider the natural experiment provided by the
attack of September 11th, 2001, which was an immediately recognizable and economically potent shock
leading to large forecast revisions by professional forecasters thereafter. Because of the visibility of this
shock, one might expect that these forecast revisions would not have been subject to the same degree of
informational rigidities as normal business cycle conditions. Consistent with this prior, we find that
professional forecasts in the U.S. and other countries were not subject to important informational
rigidities shortly after the 9/11 shock. In short, we document clear evidence of state-dependence in the
expectations formation process in the presence of large economic shocks, a feature of the data which is
not commonly incorporated into models of information rigidities.
This paper is closely related to recent empirical work trying to ascertain the nature of the
expectations formation process. For example, Mankiw et al. (2004) assess whether a sticky-information
model can replicate some stylized facts about the predictability of forecast errors by professional
forecasters while Andolfatto et al. (2007) consider whether imperfect information with respect to the
inflation target of the central bank can account for observed deviations from FIRE. Khan and Zhu (2006),
Kiley (2007), and Coibion (2010) assess the validity of sticky information using estimates of its predicted
Phillips curve. One advantage of our approach is that we can directly recover an estimate of the degree of
information rigidity without having to make auxiliary assumptions about the model, such as the nature of
price-setting decisions. Furthermore, our approach allows us to differentiate between sticky-information
and imperfect information models. Coibion and Gorodnichenko (2008) study the evidence for stickyinformation and imperfect information models but do so by estimating the response of forecast errors and
disagreement to structural shocks whereas our approach does not require the identification of any shock.
In the same spirit, Branch (2007) compares the fit of sticky-information and model-switching
characterizations of the expectations formation process while Carroll (2003) tests an epidemiological
model of expectations in which information diffuses over time from professional forecasters to
consumers. However, these papers focus almost exclusively on inflationary expectations whereas we
utilize forecasts for a wide variety of macroeconomic variables as well as cross-country data.
Furthermore, we study the deeper determinants of information rigidity such as the effects of
macroeconomic volatility and institutions.
The paper is structured as follows. Section 2 presents the predicted relationship between ex post
mean forecast errors and ex ante mean forecast revisions in sticky-information and imperfect information
models.

Section 3 describes the empirical strategy and provides results for inflation forecasts of

professional forecasters and other agents, as well as broader evidence from forecasts of other
macroeconomic variables. Section 4 presents evidence on the underlying macroeconomic and policy

5

determinants of informational rigidities and documents a likely role for state-dependence in the
expectations formation process. Section 5 concludes.

II

Forecast Errors, Forecast Revisions and Informational Rigidities

In this section, we present two models of informational rigidities and derive their respective predictions
for the relationship between ex post mean forecast errors and ex ante mean forecast revisions.
2.1

Sticky Information

Mankiw and Reis (2002) proposed a model of inattentive agents who update their information sets each
period with probability 1

but acquire no new information with probability , so that

interpreted as the degree of information rigidity and 1/ 1

can be

is the average duration between

information updates. When agents update their information sets, they acquire full information and have
rational expectations. Reis (2006) shows how this time-dependent updating of information sets obtains
when firms face a fixed cost to updating their information. The average time t forecast across agents ( )
of a variable

at time

expectations forecasts (

is a weighted average of current and past full-information rational
) of the variable such that
∑∞

1

.

(1)

The average forecast at time t-1 can similarly be written as
1

∑∞

(2)

which implies that the current average forecast is just a weighted average of the previous period’s forecast
and the current rational expectation of variable
1

at time
.

(3)

Full-information rational expectations are such that
(4)

,

where

,

is the rational expectations error and is thus uncorrelated with information dated t or earlier.

Combining (3) and (4) yields the predicted relationship between the ex post mean forecast error
across agents and the forecast revision
∆
where ∆

,

(5)

. Importantly, the coefficient on the forecast revision depends only

the degree of information rigidity . In the special case of no informational frictions,

0 and the

specification collapses to equation (4), i.e. the average forecast error is unpredictable using information
dated t or earlier. Because the sticky-information model implies a single rate of information acquisition,

6

equation (5) holds for any macroeconomic variable and any forecasting horizon.4 In addition, this
specification will hold regardless of the structure of the rest of the model.
2.2

Imperfect Information

We also consider models in which agents know the structure of the model and underlying parameter
values, continuously update their information sets, but never fully observe the state. This class of models
includes most famously the Lucas (1972) islands model but also a wide variety of limited information
settings considered in the literature. For example, Kydland and Prescott (1982) assume that the level of
technology reflects both permanent and transitory shocks but that agents cannot separately identify these
two components. More recently, Woodford (2001) considers an environment in which firms observe
aggregate demand subject to idiosyncratic errors, which combined with strategic complementarity in
price-setting, can account for the persistent effect of monetary policy shocks.

Suppose that a

macroeconomic variable follows an AR(1) process
(6)
where 0

1. Agents cannot directly observe x but instead receive a signal

such that
(7)

where

represents noise which may be correlated across agents. Each agent i then generates optimal

forecasts

given their information sets via the Kalman filter
1

(8)
,

where

is the Kalman gain which represents the relative weight placed on new information relative to

previous forecasts. When the signal is perfectly revealing about the true state,
of noise induces

1. Thus, 1

1; while the presence

can be interpreted as the degree of information rigidity in this

model.5

4

Carroll (2003) proposes an epidemiological model of information diffusion in which consumers acquire rational
expectations forecasts in a time dependent setting from occasional activities such as reading the newspaper. It is
conceivable in Carroll’s model for sticky information agents to have different rates of information updating for
different macroeconomic variables since the full-information rational expectations are formulated by other agents.
However, because we focus primarily on professional forecasters who do not have access to superior forecasts from
other agents, we assume that these forecasters formulate the full-information rational expectations updates
themselves. Because the latter requires solving for all variables simultaneously, the rate of information updating
must be common across variables. The same logic applies for different forecasting horizons.
5
In general, the persistence of macroeconomic variables is also a function of the degree of information rigidity. We
focus on the equilibrium outcome where the effect of information rigidity is fully incorporated in the persistence of
the series. Since the persistence of macroeconomic variables is increasing in information rigidities and the degree of
information rigidity is decreasing in the persistence, there will be unique equilibrium levels of persistence and
information rigidity in the model.

7

Averaging across agents and rearranging, one can show that the following relationship between
ex post mean forecast errors and ex ante mean forecast revisions holds when the average of the noise
across agents is zero
(9)

,

where

,

∑

is the rational expectations error and F denotes the average forecast across

agents.6 Thus, while individual forecasts are optimal conditional on each agent’s information set, the ex
post mean forecast error is systematically predictable using ex ante mean forecast revisions.
specification is identical to that obtained under sticky-information, when 1
degree of information rigidity.

This

is interpreted as the

In contrast to equation (5) derived under sticky information, the

coefficient on forecast revisions need not be the same for different macroeconomic variables or forecast
horizons in imperfect information models. Instead, the coefficient will vary with the determinants of the
Kalman gain, e.g. the persistence of the series and the signal-noise ratio.

III

Tests of FIRE and New Evidence on Informational Rigidities

This section a) describes our empirical strategy and relates it to previous literature; b) applies our
approach to inflation forecasts of U.S. professional forecasters, consumers, and financial market
participants; c) considers broader evidence of informational rigidities pooled across macroeconomic
variables as well as d) cross-country evidence on informational rigidities.
3.1

A New Approach for Assessing the Nature of the Expectations Formation Process

The sticky information and imperfect information models both point to the same relationship between ex
post mean forecast errors and ex ante mean forecast revisions such that the coefficient on forecast
revisions maps one to one into the underlying degree of informational rigidities. This relationship can be
readily estimated for a given macroeconomic variable x, mean forecasts across agents Fx and forecasting
horizon h using the following empirical specification:
(10)
This specification is just a special case of the more general test of FIRE commonly employed in the
literature in which the forecast error is regressed on a subset of the information available to agents at the
time the forecast was made, i.e.
.

(11)

Under the null of FIRE, forecast errors (the LHS) should be uncorrelated with all past information (any
variable z dated t or earlier) and should have a constant of zero. Our empirical specification in contrast
6

When the average noise is nonzero, this introduces another component to the error term, dated time t and
uncorrelated with information from
1 and earlier. In this case, our baseline empirical specification cannot be
estimated by OLS. We generated equivalent results as those in the paper using instrumental variables dated by
1
and earlier and reached nearly identical conclusions. Hence, we focus on the simpler OLS case.

8

imposes that the RHS variable be the revision in forecasts of the relevant time horizon. Despite the fact
that our specification appears to just be a special case of the more general test, it addresses several
important shortcomings of traditional tests.
The first limitation comes from the absence of any theoretical guidance in traditional applications
of (11) as to which variables should be included on the RHS. This leads to important data-mining
concerns: if a researcher tries enough macroeconomic variables and lags thereof, the null hypothesis of a
zero coefficient is bound to be rejected. Consider a typical exercise applying (11) to inflation forecasts.
Following much of the literature, we focus on mean inflation forecasts for the current and next three
quarters from the Survey of Professional Forecasters from 1969 to 2010. Forecast errors are constructed
using forecasts made at the relevant date and real-time data available one year after the relevant date. A
common first step in the literature is to include the contemporaneous forecast of future inflation on the
RHS of (11) to verify that the coefficient is zero, i.e. that forecasts are unbiased. As shown in Table 1
(Panel A), this yields estimates of the constant and

that are insignificantly different from zero, a finding

which is consistent with the null of FIRE. A reasonable second step is to introduce additional variables in
professional forecasters’ information sets to determine whether this information has been fully
incorporated in their forecasts, i.e. if forecasts are efficient. Columns (2)-(5) of Panel A in Table 1
present results from using real-time measures of inflation, 3-month Tbills, the change in real oil prices,
and the unemployment rate, all lagged one quarter to ensure that these values were available to
forecasters. All four variables are statistically significant predictors of ex post mean forecast errors,
contrary to the null of FIRE. For three out of four, the coefficient on forecasts also becomes different
from zero once these additional variables are included.7
Second, even if we observe a rejection of the null hypothesis that is not driven by data-mining,
such a rejection is not directly informative about alternative models of the expectations formation process.
Does the finding of predictive power from lagged inflation or unemployment point to a rejection of
rational expectations and therefore possibly toward models with adaptive expectations or does it point to a
rejection of the full-information assumption, as in sticky information or imperfect information models?
In the absence of clear theoretical predictions from these models about the estimated coefficients in these
empirical specifications, little insight about the expectations formation process is gained from statistical
rejections of the null hypothesis.
Third, and most fundamentally, these tests are uninformative about the economic significance of
the results. The assumption of FIRE is easy to disprove: as emphasized by Mankiw et al. (2003), the fact

7

This selection of variables is not a random sample but rather is deliberately based on previous evidence of
departures from the null of FIRE identified in Thomas (1999), Mehra (2002), Mankiw et al. (2003) and Pesaran and
Weale (2006).

9

that economic agents systematically disagree about expected outcomes is inherently inconsistent with all
agents knowing the true structure of the model and observing all economic variables and shocks perfectly
in real-time. What matters of course for economists is not whether the assumption is literally true, since it
clearly is not, but rather whether the deviations from FIRE are significant enough to have important
economic implications. The statistical rejection of the null of FIRE arising from the predictability of
forecast errors by certain macroeconomic variables over different time periods does not directly shed light
as to whether these rejections are economically significant.
Our approach can address most of these concerns. First, because we derive predictions from
models of informational rigidities that nest the full-information assumption, we have guidance from the
theory as to what the relevant RHS variable should be, namely the revision in forecasts for the relevant
time horizon. Thus, the incentive for data-mining is reduced since the relevant RHS variable is motivated
by theoretical considerations. Second, there is a well-defined alternative hypothesis from models of
informational rigidities given by the prediction that

0, as well as additional testable restrictions,

which allow us to ascertain whether rejections of the null of FIRE indicate rejections of rationality or of
the full-information assumption. Third, because both theoretical models of informational rigidities imply
that the coefficient on forecast revisions maps directly into the underlying parameters governing the
degree of information rigidity, our approach can recover direct estimates of informational frictions and,
hence, can help assess the economic significance of any rejections of the null hypothesis of FIRE.
3.2

Evidence from U.S. Inflation Forecasts of Professional Forecasters

As a first step to applying our approach, we again follow most of literature on survey measures of
expectations and focus on historical inflation forecasts by U.S. professional forecasters. Both stickyinformation and imperfect information models predict a relationship between the mean ex post inflation
forecast errors and the mean inflation forecast revisions such that
(12)
where

0 if informational rigidities are present. From 1969-2010, we find

1.23 0.50 as shown

in Panel B of Table 1. As a result, we can reject the null of FIRE at the 5% level of statistical significance
in a manner that is directly informative about the expectations formation process. First, the rejection of
the null goes exactly in the direction predicted by models of informational rigidities, so that this finding
presents direct evidence in favor of these models. Second, because

maps into the degree of information

rigidity from each model, we can extract an estimate of informational frictions: e.g.
0.55. In the context of sticky-information models, this estimate of

/ 1

would imply that agents update their

information sets every six to seven months on average. Alternatively, one can interpret this estimate of
under imperfect information models as implying that agents put a weight of less than one-half on new
10

information and more than one-half on their previous forecasts. Coibion and Gorodnichenko (2008) find
similar, albeit slightly higher, estimates of information rigidity using the conditional response of forecast
errors to economic shocks. As documented in theoretical work (e.g., Reis 2009), this magnitude of
informational frictions should have important quantitative implications for macroeconomic dynamics.
Thus, our approach implies that informational frictions are economically as well as statistically
significant.8
We can also test a restriction implied by these models, namely that the coefficients on the
contemporaneous forecast and on the lagged forecast are equal in absolute value. To implement this
additional test, we decompose the forecast revision into two terms as follows
.
Under models of informational rigidities, we expect
equation (13) from 1969-2010, we find

(13)
0,

1.24 0.51 and

0, and

0.

Estimating

1.27 0.51 . The signs on both

coefficients conform to the theoretical predictions of models of informational rigidities, and we cannot
reject the null that the sum of the two coefficients is equal to zero. The results therefore provide
additional evidence consistent with the notion that the expectations formation process of professional
forecasters is subject to information constraints.
Panel B of Table 1 revisits the predictive power of other lagged variables for ex post mean
forecast errors when one accounts for the forecast revisions. The two models of informational rigidities
imply that once forecast revisions are included on the RHS of (12), other variables in forecasters’
information sets should have no additional predictive power, i.e. forecast revisions are a sufficient statistic
for characterizing the predictability of ex post forecast errors. Columns (2)-(5) assess this prediction
using the same four variables previously found to have predictive power for ex post forecast errors. For
three of the variables, inflation, interest rates and changes in real oil prices, the coefficients are not
statistically significant which is consistent with the predictions of models of informational rigidities. The
result is, on the other hand, at odds with adaptive expectations: if agents were forming their forecasts of
inflation using only past values of inflation, then forecast errors should be predictable using other
macroeconomic determinants of inflation. Strikingly, this result obtains despite the fact that we picked
these variables specifically because previous work has identified them as variables for which the null of
FIRE is rejected. Of course, one should again be wary of placing too much weight on this kind of test.
As with tests of FIRE, trying enough RHS variables is bound to lead to a rejection of the null hypothesis.
8

This finding implies that the mean forecast across professional forecasters can be adjusted by the forecast revision
to systematically reduce forecast errors. Crowe (2010) shows that the MSE of consensus forecasts could have been
reduced by approximately 5% between 2007 and 2009 by applying this adjustment. However, because forecasters
in the SPF do not observe the mean forecast when making their own forecasts, this feature of the data cannot be
exploited by forecasters in real-time.

11

Indeed, we find one such rejection of the null under models of informational rigidities when controlling
for lagged unemployment: high unemployment is systematically associated with negative ex post
inflation forecast errors even after controlling for the forecast revisions. One interpretation, as with
traditional tests of FIRE, is that this finding indicates a direct rejection of models of information rigidities.
Another view suggests that this finding could be a statistical anomaly. A third interpretation comes from
the fact that regressing ex post forecast errors on unemployment comes close to estimating an
expectations-augmented Phillips curve. For example, a New Keynesian-type Phillips curve would relate
the difference between current inflation and the current mean forecast of future inflation (

) to

a measure of real economic conditions such as the unemployment rate or the output gap. Because our ex
post forecast errors are highly correlated with the gap between current inflation and the forecast of future
inflation (correlation of 0.66), this Phillips curve relationship could account for the apparent predictive
power of unemployment for ex post forecast errors observed in Table 1 in small samples.
3.3

Information Rigidities, Model Heterogeneity or Forecast Smoothing?

The sticky information and imperfect information models both point to a systematic relationship between
ex post mean forecast errors and ex ante mean forecast revisions which, at least for professional
forecasters, is consistent with historical survey data of inflation expectations. However, differences in the
information sets of economic agents need not be the only possible explanation for these patterns. One
alternative is heterogeneity in the models used by these agents to process common information and
generate forecasts. This alternative includes models with learning, in which agents have different priors
about the parameters of the underlying data-generating process (DGP), and models in which agents have
different beliefs about the DGP. However, these models are at odds with two stylized facts about
professional forecasts. First, model heterogeneity implies that some forecasters should systematically
outperform the mean forecast because these agents employ models that are closer to the true DGP than
models of other agents. Yet one of the most robust empirical findings from the empirical forecasting
literature contradicts this prediction: mean forecasts consistently outperform the forecasts of any
individual forecaster (e.g. Bauer et al., 2003). Second, one could imagine a setting in which no model
used by forecasters is systematically better than others, but some forecasters have models which better
characterize the response of the economy to certain shocks than others, e.g. forecaster A has a good model
for oil price shocks while forecaster B has a better model for nominal shocks. In such a setting, the top
forecaster after an oil price shock would likely be the agent with the better model of oil price shocks.
Given the persistent effects of economic shocks, the top forecaster from one period should then be more
likely to have a top forecast in subsequent periods than other forecasters. However, this prediction is also
at odds with the empirical evidence: Brian and Molloy (2007) document that top forecasters in one period

12

are no more likely to be top forecasters in the next period than others. This mean reversion in the quality
of forecasts cannot readily be reconciled with model heterogeneity being the primary source of
differences in short-run forecasts across professionals.9
A second possibility is that the observed deviations from FIRE reflect objective functions on the
part of forecasters that depart from minimizing mean-squared errors. This notion seems particularly
probable under the sticky-information interpretation of the results: taken literally, the sticky-information
model implies that professional forecasters do not update their forecasts, or incorporate any new
information, for extended periods of time. This literal interpretation would seem to be implausible.10 On
the other hand, one could take a broader view of the model relying on the fact that what professional
forecasters do is not just estimate an econometric model every month or quarter and distribute the results;
a key service they supply to their clients is a comprehensive overview and interpretation of current
macroeconomic developments and possible future outcomes. One could then interpret sticky-information
not as the actual rate of information updating but more broadly as the rate at which professional
forecasters revise their interpretation of the data.
One could argue that this broader view, while more palatable, is no longer an argument about
informational rigidities per se but rather about reputational considerations leading to forecast smoothing
by professional forecasters (as in Laster el. (1995)) who would want to provide their clientele with
“stories” consistent over time. To see how these reputational considerations could be misinterpreted as
informational rigidities, consider a stylized optimization problem for a forecaster i who knows the current
full-information rational expectations forecast of a variable x at time t+j (
choose a current forecast (

). The forecaster must

) to minimize the MSE of forecasts subject to a penalty that is increasing

in the difference between the current forecast and that of the previous period
min

.

This simple setup highlights the conflicting objectives of professional forecasters: providing good
forecasts (the first component) while maintaining a consistent story over time (the second term,

0).

The first order condition with respect to the contemporaneous forecast yields the following relationship
between ex post forecast errors and the ex ante forecast revision of the professional forecaster:
9

For longer-horizon forecasts, model-heterogeneity is likely to be more important than individual information sets.
For example, long-run unemployment rate forecasts should depend primarily on whether forecasters accord any
weight to hysteresis. Similarly, current 2-3 year-ahead inflation forecasts for the U.S. should hinge on whether
forecasters use a Keynesian-type model, in which the current large output gaps should point to low inflationary
pressures, or a monetarist-type model, in which the expansion of the Fed’s balance sheet is likely to presage
increased inflationary pressures in the future. Because our focus is on forecasts at relatively short-horizons (up to
one year ahead), these considerations are likely to be dominated by informational factors, as documented in the text.
10
Andrade and Le Bihan (2010) use individual forecasts of professional forecasters in Europe to quantify how
frequently forecasters do not change their forecasts at all and find a frequency of updating forecasts of
approximately 0.75 per quarter, of which only a fraction is likely to be due to rounding errors.

13

∆
where

,

,

is the rational expectations error as defined in (4) and ∆

.

Averaged across forecasters, this expression yields an identical relationship between mean forecast errors
and forecast revisions as that implied by both sticky information and imperfect information models, but
the coefficient on forecast revisions would now be interpreted as the marginal cost of changing the
forecasts due to reputational considerations on the part of professional forecasters. Hence, the results in
Table 1 could be interpreted as stemming from informational rigidities or from reputational concerns by
professional forecasters.
To disentangle these different interpretations of the data, we consider several additional tests of
inflation expectations. As a first step, we study forecasts from different types of professional forecasters.
The Livingston Survey of Professional Forecasters, a biannual survey first established in 1946 by the
columnist Joseph Livingston and maintained since 1990 by the Philadelphia Fed, provides individual
inflation forecasts from economists at academic institutions, commercial banks, and non-financial firms,
among others.11 For each forecaster, the survey includes their forecasts of the CPI in 6 months and in 12
months.12 Thus, we can apply our empirical specification at the 6-month forecasting horizon. Table 2
presents the results from 1969 to 2010 for the mean forecasts across all professional forecasters as well as
using the mean forecasts across subsets of professional forecasters.

Using all forecasters in the

Livingston survey, the coefficient on forecast revisions is slightly above one as found using the SPF.
There are substantial differences across forecaster types however: academic economists have the smallest
estimated coefficient while commercial banks have a significantly higher coefficient estimate than
academics. This result is at odds with what one would expect to find if the results were driven by
reputational considerations: the forecasts of academics are entirely for external distribution, hence one
would expect the reputational considerations to be particularly important for these agents, while forecasts
from industry are primarily for internal profit-generating activities such that one would expect
reputational factors to be subordinate to minimizing forecasting errors. Because the data point to greater
rigidity of forecasts on the part of private industry forecasters than academics, we interpret this finding as
more suggestive of informational rigidities than reputational considerations.13
As a second step, we consider two additional sources of expectations for which maintaining
credibility should play little to no role in determining forecasts: consumer expectations and expectations
11

The categories of forecasters also include investment banks, government forecasters, the Federal Reserve, labor
organizations, and “other.” We do not look at these in detail because of how few forecasters there are in each of
these groups over time. The data is available on the website of the Federal Reserve Bank of Philadelphia.
12
Forecasts are of the seasonally-unadjusted CPI prior to December 2004 and seasonally adjusted thereafter.
13
Private sector forecasts could still be subject to reputational considerations within the firm (i.e. if forecasters need
to defend their forecasts to other individuals in the firm) but these considerations should probably be less important
than reputational considerations pertinent to forecasts aimed at the general public.

14

derived from asset prices. For the former, we rely on the Michigan Survey of Consumers. Each month,
the University of Michigan surveys 500-1,500 households and asks them about their expectation of price
changes over the course of the next year. For the latter, we use the inflation expectations data from the
Cleveland Fed based on the method developed in Haubrich, Pennacchi and Ritchken (2008) who rely on
the term structure of interest rates and inflation swaps to extract measures of market expectations of CPI
inflation at multiple yearly horizons starting in 1982. Both market-based and consumer expectations of
inflation should be independent of reputational considerations (anonymous forecasts for consumers;
money on the table for asset prices) and therefore should help distinguish between informational rigidities
and forecast smoothing arising from concerns about maintaining credibility. Figure 1 plots these two sets
of inflation forecasts, as well as the corresponding year-ahead CPI inflation forecasts from the Survey of
Professional Forecasters. All three series are highly correlated, but the financial market and professional
forecasts exhibit particularly strong comovement.
Table 3 presents the root mean squared forecast errors from 1982 to 2009 for all three forecasts.
The Survey of Professional Forecasters has the smallest MSE, although the difference with respect to
market-based forecasts is not statistically significant. Nonetheless, if professional forecasts were smooth
because of reputational considerations, one would expect these forecasts to be worse on average than
market-driven expectations. Ang et al. (2007) similarly find that professional forecasts outperform a
variety of model-based forecasts, asset-pricing implied forecasts and consumer forecasts. Table 3 also
presents results of regressions designed to assess the information content of each type of forecast.
Specifically, we regress ex post CPI inflation on the ex ante forecasts. When both professional forecasts
and consumer forecasts are included, the coefficient on professional forecasts is large, statistically
significantly different from zero but not from one, while that on consumer forecasts is small and not
statistically different from zero. Hence, there appears to be little additional informational content in
consumer forecasts relative to professional forecasts. When this exercise is repeated with market-based
expectations of inflation in place of consumer forecasts, the results are even more pronounced. Again,
this result is inconsistent with reputational considerations accounting for smooth forecasts on the part of
professional forecasters since one would then expect market-based and possibly consumer forecasts to
have significantly more explanatory power than professional forecasts.
We can also estimate the coefficient on forecast revisions for each type of forecast to assess
whether this coefficient is significantly lower for consumers and market-based forecasts, as would be
expected if reputational concerns account for smoothing on the part of professional forecasters. However,
because the Michigan Survey of Consumers as well as the market-based expectations are only available at
a forecasting horizon of one year, we replace the forecast revision with the change in the year-ahead
forecast, yielding the following specification
15

,

where

,

,

,

,

denotes the inflation rate between t+4 and t. In this case, the error term will consist of the

rational expectations forecast error, as in equation (12), and

because the

forecasts do not have perfectly overlapping time horizons across periods. As a result, this specification
cannot be estimated by OLS. Instead, we estimate this specification by GMM, using as instruments
innovations to oil prices at time t.14

These innovations are valid instruments because they are

uncorrelated with both past information (t-1 and earlier) as well as the rational expectations error.
Furthermore, because oil prices have significant effects on CPI inflation, these should be instrumental
variables with the desired properties. As illustrated in Table 4, these oil price innovations are statistically
significant predictors of contemporaneous changes in inflation forecasts for all three measures of inflation
expectations and can account for an important share of their volatility. Applying this estimation approach
to a common time sample of 1982 to 2009, we find a coefficient on forecast revisions of 1.3 for
professional forecasters, a finding that closely mirrors our previous results. For consumers, the point
estimate is smaller but also highly statistically significant which conforms to the findings of Coibion and
Gorodnichenko (2008). For market expectations, the point estimate is even higher than for professional
forecasters, but it is also less precisely estimated which is likely a result of the reduced predictive power
of oil price innovations on market-based forecast revisions. As with the previous tests, the evidence
continues to point primarily toward informational rigidities as the likely source of the positive coefficient
on forecast revisions rather than reputational considerations since we find qualitatively similar results for
consumers and market-based forecasts as with professional forecaster data.15
3.4

Pooled U.S. Evidence on Informational Rigidities among Professional Forecasters

While much of the empirical literature on the expectations formation process has focused on inflation
forecasts, our approach is readily applicable to different macroeconomic variables. Furthermore, we can
14

Specifically, we run an AR(2) on the first difference of the log of nominal oil prices and define the residuals as oil
price innovations.
15
There are two other pieces of evidence favoring an information rigidity interpretation of the coefficient on forecast
revisions. First, as presented in section 4.1, the cross-sectional heterogeneity in coefficients on forecast revisions
across countries and macroeconomic variables can be well-accounted for using the predicted determinants of
imperfect information models. Second, the observational equivalence of the relationship between ex post mean
forecast errors and ex ante mean forecast revisions in models of informational rigidities versus forecast smoothing
motives obtains only when the forecast smoothing is modeled in a static fashion. In general, if forecasters wish to
minimize changes in their forecasts, then they will also take into account the fact that the current choice of their
forecast will affect the cost of changing forecasts next period. If one includes this dynamic element, ex post forecast
errors should depend positively on the current forecast revision but also negatively on the expected forecast revision
. This specification
in the next period, i.e.
can be estimated by GMM after substituting ex post values for ex ante expectations under the null of fullinformation rational expectations. Empirical estimates of this augmented specification using SPF forecasts
consistently yield positive estimates on future forecast revisions, with varying degrees of statistical significance,
which is inconsistent with the sign restrictions imposed by the dynamic forecast smoothing model.

16

also exploit the multiple forecasting horizons available in the data to further expand the power of our
tests. In this section, we apply our method to professional forecasts for a multitude of macroeconomic
variables and forecasting horizons.
As a first step, we exploit the fact that the Survey of Professional Forecasters (SPF) contains
quarterly forecasts for four additional macroeconomic variables going back to 1968Q4: besides the GDP
price deflator, these include real output, industrial production, housing starts, and the unemployment
rate.16 Furthermore, each of these variables is available at multiple forecasting horizons, ranging from
forecasts of the current quarter to 4 quarters ahead. To exploit this additional dimension, we utilize each
of the individual quarterly forecasting horizons in our estimation. Thus, we estimate a pooled regression
,

,

,

(14)

, ,

where xi indicates which macroeconomic variable is included and h denotes the specific forecasting
horizon ranging from 0 (forecasts of the current quarter) to 3 (forecasts for 3 quarters ahead). We
consider direct estimates of equation (14) as well as estimates augmented to include cross-sectional and
time fixed effects. While the SPF includes forecasts up to 4 quarters ahead, the horizon is limited to 3
quarters in the empirical specification because forecast revisions call for an additional forecasting
horizon, e.g. when h=3, the forecast revision is

,

,

. To construct forecast errors, we use

real-time values available one year after the relevant time horizon. For the first three series, forecasts of
annualized quarterly percent changes are constructed from the underlying mean forecasts of the levels.
Table 5 presents the results of this pooled regression over 3,240 observations as well as when we include
cross-sectional fixed effects (for both the forecasting horizon and macroeconomic variable) and both
cross-sectional and time fixed effects.17 In each case, the estimate of β is positive and statistically
significant so that we can reject the null of FIRE in exactly the direction predicted by models of
informational rigidities. The point estimates of β imply that the average duration between information
updates is four months (in the context of sticky-information models) or that new information moves
forecasts by 70% of what it would be under full-information (in the context of imperfect information
models). The standard errors are now smaller than when the degree of information rigidity was based
only on forecasts of one-year ahead inflation rates, which reflects the increased precision arising from

16

Output is measured by GNP prior to 1992 and GDP thereafter. The price deflator is the implicit GNP deflator
before 1992, implicit GDP deflator from 1992 to 1996, and the chained GDP deflator thereafter. The SPF also
includes historical forecasts of corporate profits. However, the quality of this data is much worse than for other
variables, reflecting sensitivity to factors like TVA adjustments. Private communications with Tom Stark, the
manager of the SPF dataset, confirmed that individuals often report forecasts of corporate profits using definitions at
odds with the SPF definition, so that mean forecasts are excessively volatile as a result of measurement issues.
17
For each pooled dataset, we identify and remove outliers using jackknife and Cook’s distance. Removing outliers
makes estimates more stable and precise. The qualitative results do not change when outliers are not removed.

17

pooling across multiple macroeconomic variables and forecasting horizons.18 Furthermore, when we
decompose the forecast revision into two components, the contemporaneous forecast and the lagged
forecast, as in equation (13), each coefficient is of the sign predicted by theoretical models of
informational rigidities and we cannot reject the null hypothesis from these models that the sum of the
two coefficients is equal to zero at the five percent level of statistical significance.
Starting in 1981, the SPF includes forecasts of 8 additional macroeconomic variables: the 3month Treasury bill (Tbill) rate, the AAA interest rate, real consumption expenditures, real residential
investment, real non-residential investment, real federal government expenditures, real state/local
government expenditures, and the overall CPI. For each NIPA series and CPI inflation, we construct
forecasts of annualized quarterly percent changes and use real-time data to construct forecast errors, while
the two interest rates are measured in levels. The forecast horizons again run from h=0 to h=3. Thus,
pooling across all of the variables available in the SPF since 1981 and all forecasting horizons yields
5,793 observations. The results from estimating equation (14), presented in Table 5, again point to an
estimate of β which is positive and statistically different from zero, whether or not fixed effects are
included. The point estimate is larger than in the previous case, pointing to average durations between
information updates of approximately five months in the context of sticky information models, or a
weight of 60% being assigned to new information in the formation of forecasts in the context of imperfect
information models. Furthermore, a decomposition of the forecast revision into current versus lagged
forecasts again yields the result predicted by models of informational rigidities that we cannot reject the
sum of the two coefficients being equal to zero nor can we reject the sign restrictions implied by these
models.
3.5

Cross-Country Evidence on Informational Rigidities among Professional Forecasters

In addition to the U.S. Survey of Professional Forecasters, we have constructed a dataset of quarterly
forecasts from the international survey of professional forecasters done by Consensus Economics. This
dataset covers twelve countries: the G-7 countries of U.S., U.K., France, Germany, Italy, Japan and
Canada as well as Spain, Norway, the Netherlands, Sweden and Switzerland.19 Data for the G-7 countries
spans 1989 to 2010 while data for other countries begin primarily in 1994.20 For each country, forecasts
for five macroeconomic variables are available: consumer price inflation, real GDP growth, interest rates,
18

Because the errors are likely to be correlated over time as well as across macroeconomic variables and forecasting
horizons, we use Driscoll-Kraay (1998) standard errors which are robust to both time and cross-sectional correlation
of the error terms.
19
Consensus Economics provides forecasts for many more countries than the twelve included in our sample, often at
the monthly frequency, but these forecasts are restricted to the calendar year time horizon. While our method is
well-suited to these fixed forecasting horizons, we focus on this restricted set of countries because of the larger set
of forecasting horizons available.
20
Forecasts for Norway and Switzerland only become available in 1998.

18

industrial production growth and real consumption growth. Forecasts are available for the current quarter
and for the subsequent 5-6 quarters. As a first step, we estimate the average degree of information
rigidity pooled across all macroeconomic variables, countries and forecast horizons, i.e.
, ,

, ,

, ,

(15)

, , ,

where i denotes the macroeconomic variable, j the country and h the forecasting horizon. Based on
22,347 observations, the results again point to an estimate of β, presented in Table 5, that is positive and
statistically significant, confirming our finding from U.S. professional forecasters. This occurs when
equation (15) is estimated by OLS or including cross-sectional fixed effects for different countries,
variables, and forecasting horizons, as well as with both cross-sectional and time fixed effects. The
implied degree of information rigidity is very close to the estimates for the U.S. using the wider set of
variables from 1982 to 2010. When we decompose the forecast revision (Panel B), each coefficient has
the same sign as predicted by models of informational rigidities and we again cannot reject the null
hypothesis that the sum of the two coefficients is equal to zero at the five percent level of statistical
significance.
In addition, we consider country-specific estimates of the degree of information rigidity, pooled
over macroeconomic variables and forecasting horizons. Figure 2 plots the resulting estimates of β for
each country. The countries with the highest degrees of informational rigidities are Spain and Sweden,
while the lowest are Canada and Norway. All of the estimates are statistically significantly positive so we
can reject the null of FIRE for every country and this rejection of the null goes exactly in the direction
predicted by models of informational rigidities.

The substantial cross-country heterogeneity in

information rigidity, ranging from estimates of 0.3 for Canada to almost one for Spain, point to a potential
role for policy and institutions in determining country levels of information rigidity, an issue to which we
return in section 4.2.

IV

Determinants of Informational Rigidities

The empirical results pooled across macroeconomic variables and forecasting horizons are strongly
supportive of models with informational frictions: the estimated coefficients on forecast revisions are
consistently positive as predicted by these theories and large enough to affect macroeconomic dynamics.
Given these findings, we turn to the question of differentiating between sticky information and imperfect
information models of the expectations formation process, as well as evaluating the underlying
macroeconomic and policy determinants of informational rigidities.
4.1

Differentiating by Forecast Horizon and Forecasted Variable

In the sticky-information model of Mankiw and Reis (2002) and Reis (2006), firms update their
information sets infrequently, but when they do so, they acquire full-information rational expectations.
19

As a result, there is a single parameter governing the frequency of updating information which is common
across macroeconomic variables and forecasting horizons. Thus, a testable implication of the stickyinformation model is that the estimated degree of information rigidity is invariant to the forecasting
horizon and the variable being forecasted. In imperfect information models, on the other hand, the
coefficient on forecast revisions for a given macroeconomic variable will be governed by the Kalman
gain associated with that variable, which will depend on factors such as the persistence of the series and
the strength of the signal observed with respect to that macroeconomic variable. The signal-noise ratio
could vary across variables for a variety of reasons, such as the magnitude of data revisions and the
frequency of data releases.

Both factors would affect the strength of the signal observed for a

macroeconomic variable when forecasts are done at the quarterly frequency. One way to assess the
relative merits of these two models in accounting for the expectations formation process of professional
forecasters is therefore to compare the estimated degrees of information rigidity across macroeconomic
variables being forecasted as well as across forecasting horizons.
We provide two decompositions of our pooled estimates from each dataset: one by forecasting
horizon (left column of Figure 3) and one by macroeconomic variable (right column of Figure 3). For the
U.S. SPF, we cannot reject the null hypothesis of equal coefficients across forecasting horizons, as
predicted by both models of informational rigidities for quarterly forecasts (p-values of 0.15 and 0.23 for
1968 variables and 1981 variables respectively), but we can strongly reject (p-value < 0.001) the null of
equality across macroeconomic variables for the thirteen variables available since 1981 and weakly so for
the five variables available since 1968 (p-value = 0.06). With the cross-country Consensus Economics
data, we can again strongly reject the null of equality across macroeconomic variables (p-value < 0.001)
and, unlike with the U.S. SPF data, we can also strongly reject the null of equality across forecast
horizons (p-value < 0.001).
One clear result is that the degree of information rigidity is not equal across macroeconomic
variables: an implication at odds with sticky-information models. On the other hand, the fact that
heterogeneity in information rigidity exists across macroeconomic variables does not imply that imperfect
information models can account for this cross-sectional variation. In the simple imperfect information
model of section 2.2, the degree of information rigidity depends on the Kalman gain, which is a function
of the persistence of the underlying macroeconomic process as well as the precision of the signal received
by economic agents. More persistent processes imply, holding all else constant, that agents should pay
more attention to current signals since forecast errors for a persistent process convey more information
about the future than when the underlying process is less persistent. A more precise signal naturally
implies that agents should place relatively more weight on the current signal than on past forecasts. Thus,

20

imperfect information models imply that the degree of information rigidity should be decreasing in the
persistence of the series being forecasted and increasing in the amount of noise in the signal.
To assess these predictions, we construct measures of each as follows. First, for each country j
and macroeconomic variable i in the Consensus Economics survey of professional forecasters, we fit an
autoregressive process which yields an estimate of both the persistence of the variable (ρi,j) and the
volatility of its innovations (σi,j). Second, we generate a measure of the noise associated with each series
from a) the standard deviation of revisions to this series or b) the standard deviation of forecast
disagreement for this series.21 Third, we construct a measure of the noise-signal ratio (κi,j) by taking the
ratio of a measure of the noise to the standard deviation of the innovations to the variable from the first
step.

Given these measures of the predicted determinants of information rigidity, we assess their

importance by regressing our estimates of the coefficients on forecast revisions for each countrymacroeconomic variable pair, pooled across forecasting horizons, in the cross-country Consensus
Economics dataset set
,

,

,

,

(16)

where i denotes a specific variable, j denotes the country, and βi,j is the estimated coefficient on forecast
revisions for each country-variable pair in the cross-country data-set.22
The results are presented in Table 6. The coefficients on the persistence are consistently negative
across specifications. When using the noise-signal ratio measured using data-revisions (i.e. exploiting
only common sources of noise), the coefficient is positive, as expected, but not significantly different
from zero. Appendix Figure 1 shows that this is sensitive to outliers. As a result, we also consider
estimates of (16) based on robust S-regressions, which automatically identify and account for outliers, and
the results point to a positive and statistically significant effect of the noise-signal ratio, as predicted by
the imperfect information model. Simply dropping the outliers identified by the S-regression leads to
similar results. When we use the cross-sectional dispersion of forecasts, which includes both common
and idiosyncratic information among forecasters, to measure noise, the coefficient on the noise-signal
ratio of each country-variable pair is positive and statistically significant whether or not we control for
outliers. Strikingly, this simple specification can account for about 20-30 percent of the heterogeneity in
informational rigidities. Thus, not only are the theoretical predictions of imperfect information models
21

Specifically, for each time period, we take the difference between measures of the variable available two quarters
and four quarters later, then compute the standard deviation of these revisions across the entire sample. Alternative
time horizons for measuring revisions yield the same qualitative results. Real-time data, including revisions over the
course of a year, are included in the Consensus Economics dataset. Data on cross-section dispersion of forecasts
(forecast disagreement) are available for the growth rate of GDP, consumption and industrial production as well as
inflation.
22
Because the cross-section of forecasted macroeconomic variables in the U.S. Survey of Professional Forecasters is
relatively small (13 variables consistently available since 1981), we only apply this analysis to the cross-country
data.

21

qualitatively consistent with the observed heterogeneity in informational rigidities across countries and
variables, but this model can also quantitatively account for a considerable share of the observed crosssectional variation.
The fact that we can reject the null of equality across forecast horizons using the Consensus
Economics data but not for the U.S. SPF is also useful to differentiate between the models. As presented
in Section 2, both models predict that the estimated coefficient on forecast revisions should be identical
for different forecasting horizons when forecasts are for quarterly changes. However, the forecasts of
GDP, consumption and industrial production growth in the Consensus Economics survey are for year-onyear percent changes, and the inflation rate is measured by year-on-year percent changes in the price
level. This distinction makes no difference under sticky-information, and the prediction remains that the
coefficient on forecast revisions be equal across forecasting horizons, contrary to what we observe in the
data. For imperfect information models, on the other hand, this distinction is important. Consider, for
example, the forecast for the current quarter year-on-year GDP growth: the forecasters have observed
values for at least two, and likely three, of the four quarters over which they are forecasting. Hence, they
have already received very strong signals about the value of current year-on-year GDP growth. When, on
the other hand, they must forecast year-on-year GDP growth in four quarters, they will not have observed
any of the quarterly values over which the forecast is made and therefore the available signals will be
much weaker. Thus, the strength of the signal is falling over the first four forecasting horizons (h = 0 to
3) so that one would expect the estimated coefficient on forecast revisions to be rising over these
horizons, which is exactly the pattern observed in Figure 3.23 We have verified in Monte Carlo
simulations of the imperfect information model in section 2.2 that this feature of the Consensus
Economics surveys can indeed account for the rising estimated coefficients across forecasting horizons.
Further evidence that the large increase in estimated coefficients with the forecasting horizon is driven by
this feature of the Consensus Economics forecasts is that, if we estimate the coefficient on forecast
revisions at different horizons specifically for interest rate forecasts, which are not measured in year-onyear changes, the rising pattern of estimated coefficients is substantially dampened.
23

The drop in the estimated coefficients at longer forecasting horizons in Figure 2, which occurs in both the SPF and
Consensus data, appears to be driven entirely by finite sample issues combined with some variables not being very
persistent. This is because, with low persistence, forecasts of distant values will be near constant, so that
contemporaneous forecast revisions will have very little explanatory power for ex post forecast errors, pushing the
estimated coefficient toward zero in small samples. This is true under both sticky-information and imperfect
information models and is thus not informative about the relative merit of the two approaches. We have verified in
Monte Carlo simulations that this persistence issue can reproduce the observed decline in estimated coefficients in
Figure 2. Furthermore, when we reproduce the decomposition across forecasting horizons for variables measured in
changes (GDP growth, consumption growth, etc) which are not very persistent versus those variables measured in
levels which are much more persistent on average, we find that the decline in estimated coefficients at longer
forecasting horizons is non-existent for the latter but particularly pronounced for the former. Results are available
upon request.

22

4.2

Policy and Institutional Determinants of Information Rigidity

The previous section presents evidence that the varying degrees of information rigidity associated with
macroeconomic variables are well-explained by the persistence and noise-signal ratios of these variables.
However these determinants are themselves functions of policy and institutional characteristics. In this
section, we consider the possible effect of three sets of monetary policy institutions and actions on the
degree of information rigidity. First, we assess whether informational rigidities in the U.S. changed with
the onset of the Great Moderation, the dramatic decline in macroeconomic volatility commonly associated
with the monetary policy changes enacted under Fed Chairman Paul Volcker. Second, we assess to what
extent the independence of the central bank affects the expectations formation process across countries.
Third, we consider whether the official adoption of inflation targeting by central banks affects the degree
of information rigidity in inflation forecasts.
4.2.1.

Great Moderation

McConnell and Perez-Quirós (2000) and others have documented a substantial decrease in
macroeconomic volatility both in the U.S. and other developed countries since the early to mid-1980s.
Figure 4 plots the time-varying standard deviation of real GDP growth for the U.S., for example, which is
rising throughout the 1970s, peaks in the very early 1980s, then exhibits a very sharp decline in the mid1980s, declining by more than half relative to the average level during the 1970s. While the source of this
phenomenon remains a point of contention, one prominent explanation emphasizes the changes in
monetary policy put in place under Volcker, either in terms of a stronger endogenous response to
macroeconomic fluctuations as in Clarida et al. (2000) or because of the Volcker disinflation as in
Coibion and Gorodnichenko (2009). At the same time, there is only mixed evidence that microeconomic
volatility declined over this time period. For example, Davis et al. (2006) report that the volatility of
employment has fallen since the 1970s for non-publicly traded firms while Comin and Mulani (2004) and
Comin and Philippon (2005) show that volatility increased for publicly traded firms over the same period.
Furthermore, volatility at the household level appears to have been trending up over time (see Davis and
Kahn (2008) for a review). As a result of the reduction in the volatility of macroeconomic variables
relative to microeconomic variables, one might expect that economic agents would choose to allocate
relatively more resources to tracking micro rather than macro-level shocks since these shocks become
quantitatively more important for profits and utility. Thus information rigidity should have increased
with the arrival of the Great Moderation.
To explore this hypothesis, we estimate equation (10) for each quarter separately using SPF data
and then compute non-parametrically a local average of the estimated

’s for each period to provide a

sense of the low frequency variation in the degree of informational rigidities. Figure 4 plots the dynamics

23

of the local averages of

as well as associated standard errors. The figure shows that informational

rigidities were falling from the late 1960s to the early 1980s as the volatility of macroeconomic variables
was rising.24 The minimum level of information rigidity is reached in 1983-84, which closely matches the
start of the Great Moderation identified in McConnell and Perez-Quirós (2000), and since then, the
estimated degree of information rigidity has consistently been increasing. The changes in the level of
informational rigidities over time are statistically and economically significant, especially when one
compares mid-1980s and in late 2000s.
This significant low-frequency variation in the estimated coefficients on forecast revisions
suggests that one should be wary of treating informational rigidities at the macroeconomic level as a
structural parameter since these rigidities can vary over time in response to changes in macroeconomic
conditions.

Specifically, more tranquil times should be ceteris paribus associated with greater

informational rigidities. However, the rising degree of inattention over the course of the 1990s and 2000s
implies that the same sized shock would have larger real effects towards the end of the sample because
informational rigidities, like nominal rigidities, amplify the response of the economy to a given set of
shocks. Thus, this observation suggests an additional mechanism, along with increased risk-taking on the
part of financial market participants, through which the Great Moderation may have contributed to the
severity of the Great Recession.25
4.2.2

Central Bank Independence

The evolution of U.S. monetary policy under Volcker can be characterized as a change in the policy rule
decided upon internally by members of the FOMC. To the extent that that this reform contributed to the
Great Moderation, it appears to have had large effects on the degree of information rigidity faced by
economic agents.

But people’s incentive to allocate resources to keeping track of macroeconomic

conditions also depends on the institutional characteristics of the central bank. For example, in the
seminal Barro and Gordon (1983) exposition of the time inconsistency problem, the inflation bias
associated with discretionary monetary policy hinges upon the central bank’s target unemployment rate
being less than the natural rate of unemployment. This policy objective is more likely to occur when
central banks are subject to the influence of elected officials whose job security hinges disproportionately
on the state of the real economy. As a result, minimizing this influence by making central banks more
24

Although we do not have SPF forecast data before 1968, we conjecture that the relatively high informational
rigidities in the late 1960s can be explained by the relatively tranquil period experienced by the U.S. economy
during the 1960s.
25
The figure also suggests that the high volatility of the 1970s led to a gradual increase in attention on the part of
economic agents, making the economy become progressively less sensitive to any given shock. This decline in
information rigidity may therefore also have contributed to onset of the Great Moderation. More generally, the
figure points to the possibility of low-frequency cycles in volatility arising from the endogenous response of
information rigidities to volatility and the feedback effect of changing information rigidity on volatility.

24

independent of elected officials has been one of the defining institutional reforms of central banks
pursued by numerous developed and developing countries alike.
With greater central bank independence and the associated reduced incentives by this institution
to deviate from pre-announced policies, the incentive of economic agents to closely monitor the actions of
the central bank and macroeconomic conditions more generally should be reduced. Consequently, if
central bank independence is effective, one of the metrics along which one should be able to quantify this
success is via its effect on the degree of information rigidity associated with the expectations formation
process of economic agents. Because our approach allows us to directly quantify the latter, it provides a
novel dimension to assess the efficacy of this institutional characteristic. To quantify the degree of
central bank autonomy, we use the measure constructed by Arnone et al. (2007). Each country’s score,
between 0 and 1, reflects a combination of the degree of political autonomy (which measures the
involvement of the government in selecting governors and directors of the central bank as well as the
ability of the central bank to implement its desired policies without government approval) and economic
autonomy (which measures operational autonomy, such as how involved the central bank is in purchasing
government debt) as of 2003. The twelve countries in our Consensus Economics data vary substantially
in terms of their scores, with Japan having the lowest rating of 0.44 (driven mainly by a very low political
autonomy rating) while Sweden, Switzerland and France have the highest scores (0.94).26 The U.S. has
the fourth lowest rating in this sample of countries (tied with Norway) primarily because of a low political
autonomy score.
To quantify the effect of central bank independence on the expectations formation, we regress our
country-specific estimate of the coefficient on forecast revisions (as in Figure 2) on each country’s central
bank independence rating. Figure 5 presents a scatter plot of these data. There is a strong positive
relationship between central bank independence and the country-specific estimate of the coefficient on
forecast revisions, although Japan appears to be a clear outlier because of its central bank’s weak political
independence. Using a Huber robust regression, which controls for outliers, we can reject the null of no
relationship between central bank independence and information rigidity at standard levels of statistical
significance. However, the quantitative implications of central bank independence for the expectations
formation process are likely to be limited: given the estimated slope, if the U.S. were to achieve the same
level of central bank independence as Sweden, the change in information rigidity would be equivalent to
an increase in the average duration between information updates of half a month in the context of stickyinformation models.

26

Countries in the Euro-area do not have the same ratings because of the different procedures they use in
determining who will be appointed to the ECB governing board, among other political autonomy factors.

25

4.2.3

Inflation targeting

Another policy which has received particular attention is inflation targeting, or the official commitment
by a central bank to achieving a numerical target for the inflation rate over some time horizon. This
mechanism, if credible, should lead to a reduction in both the level and the volatility of inflation. The
latter implies that, with increased stability, economic agents should devote fewer resources to forecasting
inflation.

As a result, an implication of credible inflation-targeting regimes should be increased

inattention to inflation on the part of forecasters, thereby generating “anchored” expectations.

For

example, in an extreme case of perfect targeting, all volatility in the inflation rate would be eliminated
and therefore economic agents should not allocate any attention to this variable.
However, previous work has had to rely on indirect methods to assess the anchoring of
expectations. For example, Levin et al. (2004) find that in countries without an explicit inflation target,
private sector inflation forecasts at horizons up to 10 years are significantly correlated with a three‐year
moving average of lagged inflation, but this correlation is largely absent from the five IT countries in their
sample. Similarly, Gürkaynak et al. (2006) find that long-horizon market-based inflation forecasts were
invariant to domestic economic news in the UK and Sweden after these countries adopted inflationtargeting, but that this was not the case in the UK prior to adopting inflation-targeting or in the U.S.,
which has never officially adopted an inflation target While indicative of a qualitative effect of inflationtargeting, these methods cannot directly assess the quantitative implications of inflation-targeting on the
expectations formation process. Our approach, on the other hand, can readily be applied to study the
effect of this type of policy on the expectations formation process with a firm theoretical footing, To do
so, we can relate ex post inflation forecast errors to ex ante forecast revisions augmented with a timedummy for inflation-targeting and an interaction term
,

,

∆

where j and t index countries and time,

,

∆

,

is the inflation rate,

,

,

,

(17)

is a dummy variable equal to one if a

country targets inflation at time t and zero otherwise, and γ, the coefficient on the interaction term, will
measure the change in information rigidity associated with inflation targeting, if any. This specification
thus allows one to assess not just the possibility that inflation-targeting affects the expectations formation
process but also quantify the effect of the policy in terms of its effects on the degree of information
rigidity.
Within our cross-country sample, there is a set of countries who became unambiguous inflation
targeters over the course of time sample: the Bank of Canada officially adopted inflation-targeting in
February of 1991, the Bank of England in October of 1992, the Swedish Riksbank in Janurary of 1993,

26

the Spanish Banco de Espana in January of 1995 and the Norwegian Norges Bank in March of 2001.27
However, other countries in the dataset are close to being inflation-targeting regimes. For example, the
European Central Bank (ECB) has an official inflation target of less than, but close to, 2% a year but,
because it also has other objectives, is not as clear a case of an inflation-targeting regime as the first
group. If the ECB is included as an inflation-targeting regime, then all of the countries joining the Euroarea in 1999 can be viewed as adopting an inflation target. Other countries are also sometime considered
de facto inflation targeters. Germany, prior to the Euro, and Switzerland have been officially targeting
monetary aggregates since the late 1970s, but Bernanke and Mishkin (1997) argue that they should best
be thought of as hybrid inflation-targeting regimes. Similarly, while the Federal Reserve is legally
subject to the dual mandate and has never officially acknowledged an official inflation target, it is
frequently viewed as a de facto inflation-targeting regime.28 In light of the de jure versus de facto
distinction, we consider three definitions of a country targeting inflation: i) narrow which covers only
countries officially declaring inflation targeting; ii) broad which includes countries in the narrow
definition and countries implementing inflation targeting de facto (i.e., Euro area, USA, Germany and
Switzerland); iii) intermediate which consists of countries in the narrow definition and countries in the
Euro area.29
Results reported in Table 7 suggest that there is no robust evidence that inflation targeting leads
to greater information rigidity with respect to the inflation rate, regardless of whether we apply a narrow
or broad definition of inflation-targeting. While the point estimates of γ are consistently positive, such
that inflation-targeting leads to higher degrees of inattention, none are statistically different from zero at
the five percent level. Only in the case of the intermediate definition, i.e. including official inflationtargeting regimes and the ECB, is the estimate significant at the ten percent level. Importantly, the point
estimates of γ are all small, on the order of 0.1. This finding implies that, even if these coefficients were
statistically significant, the implied effect on informational rigidities would not be economically large. As
a result, there is little evidence that inflation-targeting has had important effects on the expectations
formation process among these countries.30
27

See Little and Romano (2008) and Roger (2010) for detailed lists of inflation-targeting countries.
For example, a special survey question in the 2007Q4 Survey of Professional Forecasters asked respondents
whether they believed that the FOMC had an unofficial inflation target. Approximately half of the respondents
answered yes.
29
The only country which does not qualify as inflation-targeting at some point in time under the broad definition is
Japan. However, even this case is ambiguous: Little and Romano (2008) classify Japan as a hybrid inflation-targeter
as of March 2006.
30
There are several reasons why our results differ from previous findings. First, we focus on relatively short-run
forecasting horizons, while Levin et al. (2004) and Gürkaynak el al (2006) emphasize the effects of inflationtargeting on long-run inflation expectations. Second, Capistran and Ramos-Francia (2010) argue that the full effect
of inflation-targeting on expectations, which they measure via dispersion of forecasts, is not observed until three
years after implementation, whereas we assume that the effect is immediate. Nonetheless, our results are consistent
28

27

4.3

State-Dependence in informational rigidities

Figure 4 documents important low-frequency time variation in the degree of information rigidity for the
U.S. consistent with the large changes in macroeconomic volatility observed over this time period. This
finding points to the possibility that the acquisition of processing of information may be more statedependent than commonly assumed. In this section, we investigate whether informational rigidities
exhibit state dependence over the course of the business cycle as well as in response to a large, visible
shock at the aggregate level.
4.3.1.

Information rigidity over the business cycle

Our results in the previous section indicate that calm times are associated with stronger informational
rigidities. In light of this evidence, one may expect that recessions, as periods of increased volatility,
should be times when economic agents update and process information faster than in expansions since the
(relative) cost of ignoring macroeconomic shocks in recession rises. Gorodnichenko (2008), for example,
shows in a theoretical model that the acquisition of information endogenously increases shortly after the
occurrence of an aggregate shock as economic agents face increased uncertainty about the current state of
the economy and consequently find it beneficial to devote more resources to learning about current
macroeconomic conditions. Using estimates of

computed for each quarter separately as in the previous

section, we consider the following econometric specification
∑

,

(18)

is a dummy variable equal to one in the first quarter of each recession, as identified by the

where

NBER, and zero otherwise. By varying index , we construct a sequence of estimated

which may be

interpreted as an impulse response of informational rigidities to a recession. To smooth the path of
coefficients

, we fit a polynomial distributed lag model with the polynomial order equal to 4 and

20. Figure 6 shows the path of the estimated

over four years after the economy slides into a

recession. We assume that the economy starts at an average level of information rigidity which is equal to
. At the start of a recession, informational rigidities are and remain relatively high. However, as time
passes, informational rigidities become less severe to the point where we cannot reject the null of FIRE
one to two years after the start of the recession. The degree of information rigidity stays low about two
years and then it starts to recover to the level observed before the start of a recession.
These dynamics of information rigidity pose a challenge for popular models of informational
frictions such as the sticky information and imperfect information models. In both types of models the
choice of frequency of updates or allocation of attention is made given the “average” behavior of the
with Dovern et al. (2010), who rely on dispersion of forecasts and find, that central bank independence plays a more
important role in anchoring expectations than inflation targeting among a similar set of countries.

28

economy rather than a specific contingency. Agents in these models do not reoptimize every period how
much attention should be allocated to tracking macroeconomic conditions and the degree of information
rigidity does not vary over the business cycle. Accounting for the business-cycle variation in information
rigidity observed in Figure 6 will require models with state-dependent acquisition of information, such as
Gorodnichenko (2008), to qualitatively generate variation of informational rigidities over the business
cycle and, more generally, in response to aggregate shocks.31
4.3.2.

The 9/11 Attacks

Both models of informational rigidities considered in section 2 imply that the current mean forecast is a
weighted average of the previous mean forecast and the current full-information rational expectation
forecast, where the weights used in computing the average current forecast in the classical formulations of
these models are fixed and thus the diffusion of information is largely time-dependent. For example,
under the sticky-information model of Reis (2006), if firms face a fixed cost to acquiring new
information, then information updates will be infrequent and time-dependent if no new information can
be acquired without paying the fixed cost. But if a large shock occurs which is visible to economic
agents, this would induce a state-dependent response and synchronized updating of information as in a
state-dependent imperfect information model of Gorodnichenko (2008).

As a result, the degree of

information rigidity should be much lower after a large and visible shock than during normal periods.
The time period of our analysis includes one such unambiguously visible and economically
potent shock: the attacks of September 11th, 2001. As shown in Figure 7, the 9/11 attacks were followed
by very large downward revisions to U.S. macroeconomic forecasts. For example, in the survey done in
August 2001, the consensus forecast for the growth rate of the year-on-year real GDP for 2002Q1 was
approximately 2%. In the special October forecasts of professional forecasters organized by Consensus
Economics in response to the September 11th attacks, the consensus forecast for the same time period was
revised down to -0.5%. Forecasts of industrial production were similarly substantially lowered as a result
of the attacks. However, by February 2002, forecasters had raised their projected growth rates of real
GDP back up substantially whereas forecasts of industrial projection growth remained very similar to the
initial post-9/11 forecasts. The latter points to a rapid adjustment of expectations in line with the FIRE
assumption, whereas the former actually points to overshooting expectations.

31

The substantial decrease in information rigidity during recessions could also be consistent with models in which
agents have ambiguity aversion, as in Epstein and Schneider (2008) and Ilut (2010). In these models, rational agents
face uncertainty about the true data generating process and place more weight on the less favorable data generating
processes. As a result, these models point to information rigidity being insensitive to good news and decreasing
strongly in response to bad news, such as recessions.

29

To quantitatively assess whether the degree of information rigidity varied during the periods
immediately following the 9/11 attacks, we create a dummy variable (It9/11) equal to one in the fourth
quarter of 2001 and the first two quarters of 2002. We then consider the following specification
,

,

∆

,

∆

,

/

/

, ,

.

(19)

The coefficient γ on the interaction term of forecast revisions and the 9/11 dummy indicates the difference
in the degree of information rigidity associated with the forecast revisions during these three quarters.
Results from applying this method to U.S. professional forecasters for those macroeconomic variables
available since 1968 as well as the estimates using the larger set of variables from 1982 are presented in
Table 8 (columns (1)-(4)) as well as results from applying this test to the cross-country data-set, pooled
across all countries, variables, and forecasting horizons (columns (5) and (6)).

In each case, the

coefficient γ is negative and statistically significant, indicating that the degree of information rigidity was
lower during the forecast revisions following the 9/11 attacks, as expected in the face of a large and
visible shock. In fact, point estimates of
estimates of

are, if anything, larger in absolute value than the point

, so that the forecast revisions can be characterized as either FIRE or even overshooting

expectations in the case of the U.S.32 Thus, consistent with the predictions of state-dependent models of
informational rigidities, large and highly visible economic shocks will lead to much more rapid
adjustment of expectations than during run-of-the-mill periods. The fact that our empirical approach can
identify and differentiate between these types of forecast revisions lends further credence to the notion
that informational frictions are the source of the underlying rigidity in the expectations formation process.

V

Conclusion

Building from the predictions of models of informational rigidities, we provide a new test of the null of
full-information rational expectations which is informative about the economic significance of departures
from the null as well as the models that can account for these departures. The core of the proposed
approach is a tight theoretical link between ex post mean forecast errors and ex ante mean forecast
revisions. Applying this approach to professional forecasters in the U.S. and other industrialized
countries, we document widespread rejections of full-information rational expectations in exactly the
direction predicted by models of informational rigidities. Consistent with these models, when one takes
into account forecast revisions, other macroeconomic variables lose much of their ability to predict
forecast errors. One interpretation of our results is that commonly observed rejections of the null of fullinformation rational expectations most likely reflect deviations from full-information rather than
departures from rational expectations. The estimates also point to economically significant estimates of
informational rigidities, thereby providing support for the recent body of work studying the integration of
32

Similar results obtain if we focus on U.S. forecasts in the Consensus Economics data.

30

informational frictions into macroeconomic models. In addition, our approach can shed light on how best
to model the expectations formation process: we document a variety of evidence indicating that
professional forecasters can adequately be modeled via imperfect information models.
While we have focused primarily on professional forecasters, this approach can be applied to
other economic agents.

For example, we document qualitatively similar results using the inflation

forecasts from the Michigan Survey of Consumers as well as with the inflation forecasts extracted from
financial market prices. The former could be extended to study the properties of consumer forecasts of
other macroeconomic variables to assess which model best characterizes the expectations formation
process of consumers. With financial markets, one could also go beyond implied inflation expectations to
assess the importance of informational rigidities using exchange rate and commodity futures prices.
Beyond these types of agents, our approach is also well-suited to study informational rigidities on the part
of central banks.

The Greenbook forecasts of the Federal Reserve, for example, include multiple

forecasting horizons for a wide range of macroeconomic variables. Assessing the nature and degree of
informational frictions faced by the U.S. central bank could help interpret the historical experience and
have implications for optimal policy. In short, our approach can shed new light on the nature of the
expectations formation process for different economic agents, as well as quantify the importance of these
informational rigidities.
In addition, one can apply our approach to study the implications of different policies on the
expectations formation process.

For example, we document that the Great Moderation, frequently

attributed to the monetary policy changes enacted by Volcker, was associated with a pronounced and
persistent increase in the degree of information rigidity for professional forecasters. This finding suggests
a new mechanism through which, along with increased risk-taking behavior on the part of financial
market participants, the Great Moderation may have played a role in generating the Great Recession.
Similarly, our empirical specification can help quantify the effect of policy changes on the expectations
formation process, thereby providing a more theoretically grounded notion of otherwise vague concepts
such as “anchored” expectations. For example, we provide evidence that central bank independence has
had a discernible impact on the expectations formation process among industrialized countries, whereas
the adoption of inflation-targeting regimes has had little to no effect on the estimated degree of
information rigidity among professional forecasters, thereby casting doubt on the quantitative importance
of this policy for expectations. Importantly, this approach can be applied to study a wide variety of other
policies such as exchange rate regimes or extended to developing countries and thereby shed new light on
one of the key mechanisms via which these policies are supposed to affect dynamics, namely through the
expectations formation process.

31

References
Adam, Klaus and Mario Padula, 2003. “Inflation Dynamics and Subjective Expectations in the United
States,” European Central Bank Working Paper 222.
Andolfatto, David, Scott Hendry, and Kevin Moran, 2007. “Are Inflation Expectations Rational?”
Journal of Monetary Economics 55(2), 406-422.
Andrade, Philippe, and Herve Le Bihan, 2010. “Inattentive Professional Forecasters,” mimeo.
Ang, Andrew, Geert Bekaert, and Min Wei, 2007. “Do macro variables, asset markets or surveys forecast
inflation better?” Journal of Monetary Economics 54(4), 1163-1212.
Arnone, Marco, Bernard J. Laurens, Jean-François Segalotto, and Martin Sommer, 2009. “Central Bank
Autonomy: Lessons from Global Trends,” IMF Staff Papers 56(June), 263-296.
Bacchetta, Philippe, Elmar Mertens, and Eric van Wincoop. 2008. “Predictability in Financial Markets:
What Do Survey Expectations Tell Us?” Forthcoming in Journal of International Money and
Finance.
Ball, Laurence, N. Gregory Mankiw and Ricardo Reis, 2005. “Monetary Policy for Inattentive
Economies,” Journal of Monetary Economics 52 (4), 703-725.
Barro, Robert J., and David B. Gordon, 1983. “Rules, discretion and reputation in a model of monetary
policy,” Journal of Monetary Economics 12(1), 101-121.
Bauer, Andy, Robert A. Eisenbeis, Daniel F. Waggoner, and Tao Zha, 2003. “Forecast Evaluation with
Cross-Section Data: The Blue Chip Surveys,” Federal Reserve Bank of Atlanta Economic Review
Second Quarter 2003, 17-31.
Bernanke, Ben S. and Frederic S. Mishkin, 1997. “Inflation Targeting: A New Framework For Monetary
Policy?” Journal of Economic Perspectives 11(2), 97-116.
Branch, William A., 2007. “Sticky information and model uncertainty in survey data on inflation
expectations,” Journal of Economic Dynamics and Control 31, 245-276.
Bryan, Michael F. and Linsey Molloy, 2007. “Mirror, Mirror, Who’s the Best Forecaster of Them All?”
Federal Reserve Bank of Cleveland Economic Commentary 3-15-2007.
Capistran, Carlos, and Manuel Ramos-Francia, 2010. “Does Inflation Targeting Affect the Dispersion of
Inflation Expectations,” Journal of Money, Credit and Banking, 42(1), 113-134.
Carroll, Christopher D. 2003. “Macroeconomic Expectations of Households and Professional
Forecasters,” Quarterly Journal of Economics 118(1), 269-298.
Clarida, Richard, Jordi Galí, and Mark Gertler, 2000. “Monetary Policy Rules and Macroeconomic
Stability: Evidence and Some Theory,” Quarterly Journal of Economics 115(1), 147-180.
Coibion, Olivier and Yuriy Gorodnichenko, 2008. “What can survey forecasts tell us about informational
rigidities?” NBER Working Paper 14586.
Coibion, Olivier and Yuriy Gorodnichenko, 2009. “Monetary Policy, Trend Inflation, and the Great
Moderation: An Alternative Interpretation,” forthcoming in American Economic Review.
Coibion, Olivier, 2010. “Testing the Sticky-Information Phillips Curve,” Review of Economics and
Statistics 92(1), 87-101.
Comin, D. and S. Mulani, 2004. “Diverging Trends in Aggregate and Firm-level Volatility.” Review of
Economics and Statistics 88(2), 374-383.
Comin, D. and T. Philippon, 2005. “The Rise in Firm-Level Volatility: Causes and Consequences,”
NBER Macroeconomics Annual, 167-228
Davis, S., J. Haltiwanger, R. Jarmin, J. Miranda, 2006. “Volatility and Dispersion in Business Growth
Rates: Publicly Traded versus Privately Held Firms,” NBER WP #12354.
Davis, Steven J., and James A. Kahn, 2008. “Interpreting the Great Moderation: Changes in the Volatility
of Economic Activity at the Macro and Micro Levels,” Journal of Economic Perspectives 22(4),
155–180.
Dovern, Jonas, Ulrich Fritsche, and Jiri Slacalek, 2010. “Disagreement among Forecasters in G-7
Countries,” mimeo.
32

Driscoll, John C. and Aart C. Kraay, 1998. “Consistent Covariance Matrix Estimation With Spatially
Dependent Panel Data,” The Review of Economics and Statistics 80(4) 549-560.
Epstein, Larry G. and Martin Schneider, 2008. “Ambiguity, Information Quality and Asset Pricing,”
Journal of Finance 63(1), 197-228.
Gorodnichenko, Yuriy, 2008. “Endogenous Information, Menu Costs, and Inflation Persistence,” NBER
WP #14184.
Gourinchas, Pierre-Olivier and Aaron Tornell, 2004. “Exchange-Rate Puzzles and Distorted Beliefs”
Journal of International Economics 64, 303-333.
Gürkaynak, Refet S., Andrew T. Levin and Eric T. Swanson, 2006. “Does Inflation Targeting Anchor
Long-Run Inflation Expectations? Evidence from Long-Term Bond Yields in the U.S., U.K., and
Sweden,” forthcoming in Journal of the European Economic Association.
Haubrich, Joseph, George Pennacchi, and Peter Ritchken, 2008. “Estimating Real and Nominal Term
Structures using Treasury Yields, Inflation, Inflation Forecasts and Inflation Swap Rates,” Federal
Reserve Bank of Cleveland Working Paper 08-10.
Ilut, Cosmin, 2010. “Ambiguity Aversion: Implications for the Uncovered Interest Rate Parity Puzzle,”
mimeo.
Khan, Hashmat, and Zhenhua Zhu. (2006) “Estimates of the Sticky-Information Phillips Curve for the
United States," Journal of Money, Credit and Banking 38(1), 195-207.
Kiley, Michael T., 2007. “A Quantitative Comparison of Sticky Price and Sticky Information Models of
Price Setting.” Journal of Money, Credit, and Banking, 39(1), 101-125.
Kydland, Finn E. and Edward C. Prescott, 1982. “Time to Build and Aggregate Fluctuations,”
Econometrica 50(6), 1345-1370.
Laster, David, Paul Bennett, In Sum Geoum, 1999. “Rational Bias in Macroeconomic Forecasts,”
Quarterly Journal of Economics 114(1) 293-318.
Levin, Andrew T., Fabio M. Natalucci, and Jeremy M. Piger, 2004. “The Macroeconomic Effects of
Inflation Targeting,” Federal Reserve Bank of St. Louis Review 86(4), 51-80.
Little, Jane Sneddon and Teresa Foy Morano, 2008. “Inflation Targeting – Central Bank Practice
Overseas,” Federal Reserve Bank of Boston Working Paper 08-1.
Lucas, Robert E., 1972. “Expectations and the Neutrality of Money,” Journal of Economic Theory 4(2),
103-124.
Mackowiak, Bartosz and Mirko Wiederholt, 2009. “Optimal Sticky Prices under Rational Inattention,”
American Economic Review 99(3), 769-803.
Mankiw, N. Gregory and Ricardo Reis, 2002. “Sticky Information Versus Sticky Prices: A Proposal to
Replace the New Keynesian Phillips Curve,” Quarterly Journal of Economics 117(4), 1295-1328.
Mankiw, N. Gregory, Ricardo Reis, and Justin Wolfers, 2004. “Disagreement about Inflation
Expectations,” NBER Macroeconomics Annual 2003, 209-248.
McConnell, Margaret, and Gabriel Perez-Quirós. 2000. “Output Fluctuations in the United States: What
Has Changed since the Early 1980s?” American Economic Review 90(5), 1464-76.
Mehra, Yash P., 2002. “Survey Measures of Expected Inflation: Revisiting the Issues of Predictive
Content and Rationality,” Federal Reserve Bank of Richmond Economic Quarterly 88(3), 17-36.
Paciello, Luigi and Mirko Wiederholt, 2010. “Imperfect Information and Optimal Monetary Policy,”
mimeo.
Patton, Andrew J. and Allan Timmermann, 2010. “Why do forecasters disagree? Lessons from the term
structure of cross-sectional dispersion,” forthcoming in Journal of Monetary Economics.
Pesaran, M. Hashem and Martin Weale. 2006. “Survey Expectations,” in Handbook of Economic
Forecasting, G. Elliott, C.W.J. Granger, and A. Timmermann (eds.), North-Holland Press.
Piazzesi, Monika and Martin Schneider, 2008. “Bond Positions, Expectations, and the Yield Curve,”
Working Paper 2008-02, Federal Reserve Bank of Atlanta.
Reis, Ricardo, 2006. “Inattentive Producers,” Review of Economic Studies 73(3), 793-821.
Reis, Ricardo, 2009. “Optimal Monetary Policy Rules in an Estimated Sticky-Information Model,”
American Economic Journal: Macroeconomics 1(2), 1-28.
33

Roberts, John M., 1997. “Is Inflation Sticky?” Journal of Monetary Economics 39(1), 173-196.
Roberts, John M., 1998. “Inflation Expectations and the Transmission of Monetary Policy,” Finance and
Economics Discussion Series 1998-43, Board of Governors of the Federal Reserve System.
Roger, Scott, 2010. “Inflation Targeting Turns 20,” Finance and Development 47(1) 46-49.
Sims, Christopher A., 2003. “Implications of Rational Inattention,” Journal of Monetary Economics
50(3), 665-690.
Thomas, Lloyd B., 1999. “Survey Measures of Expected U.S. Inflation,” Journal of Economic
Perspectives 13(4) 125-144.
Woodford, Michael, 2001. “Imperfect Common Knowledge and the Effects of Monetary Policy,”
published in P. Aghion, R. Frydman, J. Stiglitz, and M. Woodford, eds., Knowledge, Information,
and Expectations in Modern Macroeconomics: In Honor of Edmund S. Phelps, Princeton Univ.
Press, 2002.

34

Table 1. Tests of the Inflation Expectations Process
Additional Control:

None

Inflation

Average
quarterly
3-month
Tbill rate

(1)

(2)

(3)

Panel A:
-0.18
(0.28)
0.07
(0.09)

Constant
,

,

,

Additional Control:

Observations
R-squared

163
0.005

Constant
,

,

Panel B:
0.04
(0.15)
1.23**
(0.50)

Additional Control:

Observations
R-squared

157
0.195

Quarterly
change in
the log of
the real oil
price
(4)

(5)

,

-0.02
(0.26)
-0.26*
(0.15)
0.29**
(0.14)

0.05
(0.29)
0.23**
(0.11)
-0.15**
(0.07)

-0.12
(0.26)
0.05
(0.08)
1.73**
(0.83)

162
0.064

162
0.050

163
0.035

,

Average
unemployment
rate

,

,

-0.01
(0.21)
1.21**
(0.49)
0.01
(0.05)

0.25
(0.23)
1.23**
(0.51)
-0.04
(0.04)

0.03
(0.15)
1.17**
(0.50)
0.63
(0.72)

157
0.189

157
0.197

157
0.194

2.35***
(0.64)
0.22**
(0.09)
-0.52***
(0.12)
163
0.282

,

1.77***
(0.52)
1.02**
(0.48)
-0.28***
(0.07)
157
0.282

Notes: The table reports coefficient estimates for the specified equations at the top of each panel. The
additional controls (z) are lagged by one quarter. Newey-West standard errors are in parentheses. ***,
**, * denote significance at 0.01, 0.05, and 0.10 levels.

35

Table 2. Information rigidity in inflation forecasts by forecaster types.

Forecast revision
Sample
Observations

Academic
Institutions
(1)
0.448*
(0.245)
1969-2010
83

Livingston survey
NonCommercial
financial
Banks
Businesses
(2)
(3)
0.820***
0.616**
(0.202)
(0.228)
1969-2010
1969-2010
83
83

All
Forecasters
(4)
1.023***
(0.250)
1969-2010
83

Note: The table reports estimates of equation (10) using inflation forecasts from the
Livingston Survey of Professional Forecasters. Columns (1)-(3) report estimates using
subsets of the forecasters while column (4) reports estimates using all forecasters in the
survey. All estimates are done by OLS with Newey-West HAC standard errors in
parentheses. ***, **, * denote significance at 0.01, 0.05, and 0.10 levels.

36

Table 3. Properties of inflation forecasts

MSE
p-value of equality
Observations

Panel A: Comparison of Mean Squared Error (MSE)
Survey of
Michigan
Financial
Professional
Survey of
markets
forecasters
Consumers
(FIN)
(SPF)
(MSC)
(1)
(2)
(3)
1.190
2.437
1.429
(0.212)
(0.561)
(0.211)
0.039
0.426
112

112

112

Panel B: Predictability of ex post CPI inflation ,
(1)
(2)
(3)
SPF,

,

MSC,
FIN,

,

0.750**
(0.364)
0.139
(0.310)

,

R-squared
Observations

0.297
111

0.957***
(0.281)

-0.040
(0.270)

0.777*
(0.409)
0.148
(0.319)
-0.037
(0.283)

0.277
111

0.285
111

Notes: In Panel A, figures in parentheses are the standard errors of the MSE estimates. The last row in
Panel A reports the p-value of the t-test of equality of MSE for SPF and an alternative source of forecasts.
In Panel B, standard errors are in parentheses. ***, **, * denote significance at 0.01, 0.05, and 0.10
levels.

37

Table 4. Information rigidity in inflation forecasts across surveys.
Instrumental variable regression
Survey of
Michigan
Financial
Professional
Survey of
markets
forecasters
Consumers
(FIN)
(SPF)
(MSC)
(1)
(2)
(3)
Forecast revision
s.e.e.
Observations
First stage
Oil price shock
R2
F-stat

1.255**
(0.486)
1.155
111

0.738***
(0.194)
1.258
111

2.013*
(1.069)
1.651
111

1.964
(0.496)
0.283
15.707

2.674
(0.458)
0.383
34.092

1.340
(0.575)
0.104
5.421

Notes: The table reports estimated specifications (10) with inflation forecasts. The dependent variable is
the ex post mean forecast error. Newey-West robust standard errors are in parentheses. ***, **, * denote
significance at 0.01, 0.05, and 0.10 levels. Panel B reports the first stage fit. The instrumental variable is
oil price shocks which are residuals from projecting changes in the oil prices on its own two lags.

38

Table 5. Pooled Estimates of the Expectations Formation Process
U.S. SPF
1968-2010
5 Variables

Dependent variable
Forecast error

Forecast revision
∆
Observations
R-squared

p-value (
Observations
R-squared

0

OLS

FE

(1)

(2)

U.S. SPF
1982-2010
13 Variables
FE
+ time
dummies
(3)

Cross-Country Professional
Forecasters
1989-2010
5 Variables
12 countries
FE
OLS
FE
+ time
dummies
(7)
(8)
(9)

OLS

FE

(4)

(5)

FE
+ time
dummies
(6)

0.307***
(0.118)

Panel A
0.653***
(0.188)

0.653***
(0.188)

0.634***
(0.134)

0.690***
(0.143)

0.635***
(0.139)

0.512***
(0.072)

0.387**
(0.178)

0.382**
(0.177)

3,240
0.019

3,240
0.018

3,240
0.129

5,793
0.030

5,793
0.032

5,793
0.080

22,341
0.047

22,341
0.043

22,341
0.234

0.421**
(0.173)
-0.481**
(0.171)

0.429**
(0.174)
-0.530***
(0.184)

0.359**
(0.111)
-0.483***
(0.074)

Panel B
0.651***
(0.179)
-0.576***
(0.181)

0.670***
(0.179)
-0.506**
(0.202)

0.631***
(0.154)
-0.491**
(0.180)

0.721***
(0.140)
-0.782***
(0.119)

0.663***
(0.131)
-0.736***
(0.096)

0.525***
(0.106)
-0.541***
(0.082)

0.135
3,240
0.022

0.234
3,240
0.023

0.257
3,240
0.135

0.258
5,793
0.032

0.104
5,793
0.039

0.207
5,793
0.086

0.073
22,341
0.0731

0.233
22,341
0.046

0.625
22,341
0.234

Notes: The table reports estimated specifications (10) and (12) in Panels A and B respectively. Driscoll-Kraay (1998) standard errors are in
parentheses in columns (1), (2), (4), (5), (7), (8). Robust standard errors clustered by forecasted variable are in parentheses in columns (3), (6) and
(9). Fixed effects in columns (2), (3), (5), (6), (8) and (9) are for each combination of country, variable, and forecast horizon. Time dummies in
columns (3), (6) and (9) are for each time period (calendar quarter). ***, **, * denote significance at 0.01, 0.05, and 0.10 levels.

39

Table 6. The Macroeconomic Determinants of Informational Rigidities
Dependent variable:
estimated coefficient on
forecast revisions for
country-variable pairs
Persistence of Series,
Noise-Signal Ratio,
Observations
R-squared

,
,

Revisions in data releases as
a measure of noise
OLS
Robust
OLS
exclude
regression
outliers
(1)
(2)
(3)
-0.802***
-0.833***
-0.628*
(0.282)
(0.248)
(0.317)
0.153
0.464**
0.506*
(0.304)
(0.201)
(0.255)
60
56
60
0.153
0.326

Forecast disagreement as
a measure of noise
OLS
(4)
-1.068***
(0.269)
0.871**
(0.425)
48
0.196

Robust
regression
(5)
-1.146***
(0.354)
0.790*
(0.476)
48

is estimated as
Note: The table reports estimated specification (16). The persistence of each series
,
the sum of AR(4) coefficients. In columns (1)-(3), standard deviation of the difference between first and
final data releases is taken as a measure of noise in the series. In columns (4) and (5), the average standard
deviation of forecast disagreement is taken as a measure of noise in the series. In column (1), four
observations are identified as outliers: consumption growth rates for Italy, France, Germany and Japan.
These outliers are dropped in estimation in column (2). In columns (3) and (5), robust S-regression is run
with no dummies for outliers and all available observations included. Robust standard errors are in
parentheses. ***, **, * denote significance at 0.01, 0.05, and 0.10 levels.

40

Table 7. Informational rigidities and inflation targeting.
Dependent variable
Forecast error
,

,

∆
∆

,
,

Observations
R-squared

Canada, 1991-present
UK, 1992-present
Sweden, 1993-present
Norway, 2001-present
Spain, 1995-1998

Canada, 1991-present
UK, 1992-present
Sweden, 1993-present
Norway, 2001-present
Spain, 1995-1998
Euro area, 1999-present

OLS
(1)
0.200*
(0.111)
0.062
(0.140)
4,541
0.019

OLS
(3)
0.121
(0.109)
0.177*
(0.105)
4,541
0.018

FE
(2)
0.168
(0.105)
0.057
(0.144)
4,541
0.015

FE
(4)
0.088
(0.107)
0.137
(0.095)
4,541
0.030

Canada, 1991-present
UK, 1992-present
Sweden, 1993-present
Norway, 2001-present
Spain, 1995-1998
Euro area, 1999-present
USA, 1989-present
Germany, 1989-present
Switzerland, 1989-present
OLS
FE
(5)
(6)
0.139
0.119
(0.130)
(0.135)
0.114
0.078
(0.153)
(0.151)
4,541
4,541
0.019
0.029

Notes: The table reports estimated specification (17).
is the dummy variable equal to one if a country
targets inflation in a given time period and zero otherwise. In columns (1) and (2) the set of inflation
targeting countries includes only countries with an explicit mandate to target inflation. In columns (3) and
(4), the set of inflation countries is augmented with countries in the Euro area since the European Central
Bank admits an inflation target. In columns (5) and (6), the set of inflation countries is further augmented
with the USA, Germany and Switzerland. Driscoll-Kraay (1998) standard errors are in parentheses. ***,
**, * denote significance at 0.01, 0.05, and 0.10 levels.

41

Table 8. 9/11.

Dependent variable
Forecast error

∆
∆
p-value (
Observations
R-squared

/

0

U.S. SPF
1968-2010
5 Variables
OLS
(1)
0.414***
(0.049)
-0.894**
(0.222)
< 0.01
3,240
0.022

FE
(2)
0.407***
(0.045)
-0.851**
(0.219)
< 0.01
3,240
0.021

U.S. SPF
1982-2010
13 Variables
OLS
FE
(3)
(4)
0.713*** 0.732***
(0.139)
(0.148)
-1.041*** -1.011***
(0.274)
(0.267)
< 0.01
< 0.01
5,793
5,793
0.035
0.036

Cross-Country
Professional
Forecasters
1989-2010
5 Variables
12 countries
OLS
FE
(5)
(6)
0.736*** 0.681***
(0.060)
(0.058)
-0.826*** -0.828***
(0.129)
(0.117)
0.467
0.209
22,341
22,341
0.051
0.047

/

Notes: The table reports estimated specification (19).
is a dummy variable equal to one in 2001Q4,
2002Q1, and 2002Q2 and zero otherwise. p-value (
0 shows the probability value for the null
/
and ∆
sum up to zero. Driscoll-Kraay (1998) standard
that the coefficients on ∆
errors are in parentheses. ***, **, * denote significance at 0.01, 0.05, and 0.10 levels.

42

Figure 1: Inflation Forecasts from Professional Forecasters, Consumers and Financial Markets
9
Consumers
8

Year-Ahead Inflation Forecasts

7

Professional Forecasters
Financial

6
5
4
3
2
1
0
-1
1981Q1 1984Q1 1987Q1 1990Q1 1993Q1 1996Q1 1999Q1 2002Q1 2005Q1 2008Q1

Note: The figure plots the one-year ahead CPI forecasts from the Survey of Professional Forecasters, the
Michigan Survey of Consumers, and financial markets. See section 3.3 for details.

43

0

Estimated coefficient on forecast revisions
.25
.5
.75
1
1.25

1.5

Figure 2: Country-Specific Estimates of Informational Rigidities

CA

CH

DE

FR

IT

JP

ND

NW

SP

SW

UK

US

Notes: The figure plots estimated coefficient β on forecast revisions in specification (10) for each country
separately. Each circle presents a point estimate for a given country and whiskers show the 95%
confidence interval. The solid red line is the point estimate of the coefficient on forecast revisions in
specification (10) on pooled (across countries) sample with the shaded region showing the associated 95%
confidence interval. All standard errors are Driscoll and Kraay (1998). CA = Canada, CH = Switzerland,
DE = Germany, FR = France, IT = Italy, JP = Japan, ND = Netherlands, NW = Norway, SP = Spain, SW
= Sweden, UK = United Kingdom, US = USA.

44

0

-.5

Estimated coefficient on forecast revisions
.5
1

Estimated coefficient on forecast revisions
0
.5
1
1.5

2

1.5

Figure 3: Estimates of Information Rigidity by Macroeconomic Variable
Panel A: U.S. SPF Variables Available 1968-2010

0

1

2

3

Forecasting horizon

GY

HS

IP

DEFL

UE

0

1

2

3

-.5

-.5

Estimated coefficient on forecast revisions
0
.5
1
1.5

Estimated coefficient on forecast revisions
0
.5
1
1.5

2

2

Panel B: U.S. SPF Variables Available 1982-2010

Forecasting horizon

GY

HS

IP

DEFL UE

3TB AAA CPI

C

GF

GS

NRI

RI

0

-.5

Estimated coefficient on forecast revisions
.5
1

Estimated coefficient on forecast revisions
0
.5
1
1.5

2

1.5

Panel C: Variables Available in Cross-Country Panel Data

0

1

2
3
Forecasting horizon

4

5
Cons. growth

IP growth

GDP growth

Interest rate

Inflation

Notes: The figure plots estimated coefficient β on forecast revisions (left column) and macroeconomic variables (right column) in
specification (10) for each variable separately. Each circle presents a point estimate for a given country and whiskers show the 95%
confidence interval. The solid red line is the point estimate of the coefficient on forecast revisions in specification (10) on pooled
(across variables) sample with the shaded region showing the associated 95% confidence interval. All standard errors are Driscoll and
Kraay (1998). GY = real GDP growth rate, HS = Housing starts, IP = Growth rate of industrial production index, DEFL = Inflation rate for
GDP deflator, UE = Unemployment rate, 3TB = 3 month treasure bill interest rate, AAA = Interest rate on AAA debt, CPI = Inflation rate for
the consumer price index, C = Consumption growth rate, GF = growth rate of federal government consumption expenditures, GS = Growth
rate of state government consumption expenditures, NRI = Growth rate of non-residential investment; RI = growth rate of residential
investment.

45

6
1

0

2
3
4
5
Standard deviation of GDP growth rate

Estimated coefficient on forecast revisions
.5
1
1.5

2

Figure 4: Information Rigidity and the Great Moderation

1970

1980

1990

2000

2010

Notes: the figure plots the time series of two variables. The first is the standard deviation of the U.S. real
GDP growth rate (annualized) over a five year moving window (red dash line; right axis). The second is
the smoothed coefficient βt on forecast revisions in specification (10) estimated for each quarter
separately on the SPF data (black thick solid line; left axis). The shaded region is the 95% confidence
interval. The smoother is a local average which uses Epanechnikov kernel with bandwidth equal to five.

46

Estimated coefficient on forecast revisions
.4
.6
.8

1

Figure 5: Central Bank Independence and Information Rigidity

sp

sw

jp
de

nd
uk

us

it

fr
ch

beta = 1.07
s.e. = .37
nw

.2

ca

.4

.6
.8
Central Bank Independence Score

1

Notes: The figure plots estimated coefficient β on forecast revisions in specification (10) for each country
separately against the Central Bank Independence Score constructed in Arnone et al. (2007). Each circle
represents a country. The solid red line is the fitted line from the Huber robust regression. CA = Canada,
CH = Switzerland, DE = Germany, FR = France, IT = Italy, JP = Japan, ND = Netherlands, NW =
Norway, SP = Spain, SW = Sweden, UK = United Kingdom, US = USA.

47

-.5

Estimated coefficient on forecast revisions
0
.5
1
1.5

2

Figure 6: Information Rigidity during a Business Cycle

-1

0

1

2

3 4 5 6 7 8 9 10 11 12 13 14 15 16
Time (quarters) since the start of a recession

Notes: the figure plots the response of the coefficient βt on forecast revisions in specification (10)
estimated for each quarter separately on the SPF data. The response is estimated as in specification (18).
The response is normalized to be at the average value of the coefficient βt one period before a recession
starts. The shaded region is the 95% confidence interval. The horizontal, thin, dashed line shows the
average value of the coefficient βt. The vertical, thin, dashed line shows the time when economy moves
into a recession.

48

Figure 7: Forecasts of U.S. Production Before and After the September 11th, 2001 Attacks:
Panel A: Real GDP Growth Rate

Forecast of Year/Year Growth Rate

4

August 2001 Forecasts

3.5
3

October 2001 Forecasts

2.5
February 2002 Forecasts

2
1.5
1
0.5
0

‐0.5
‐1
2001Q1

2001Q3

2002Q1

2002Q3

Panel B: Industrial Production Growth Rate

Forecast of Year/Year Growth Rate

4
3

August 2001 Forecasts

2
1
0

October 2001 Forecasts
February 2002 Forecasts

‐1
‐2
‐3
‐4
‐5
‐6
2001Q1

2001Q3

2002Q1

2002Q3

Note: The figure plots consensus forecasts of real GDP growth rates (top panel) and industrial production
growth rates (bottom panel) from thee different surveys of professional forecasters by Consensus
Economics.

49

-.5

Estimated coefficient on forecast revisions
0
.5
1
1.5

Appendix Figure 1: Noise-Signal Ratios and Estimated Coefficients on Forecast Revisions

0

.2

.4
Noise/Signal ratio
regular observations

.6

.8

outliers

Note: The table plots the noise/signal ratio for each country/variable pair (horizontal axis) where noise is
measured using the size of revisions to the data, as discussed in section 4.1. The vertical axis indicates
the coefficient on forecast revisions from estimating (15) for each country/macroeconomic variable pair.
The empty circles are outliers as identified by robust S-regression of (16) in the text.

50

