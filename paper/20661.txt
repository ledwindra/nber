NBER WORKING PAPER SERIES

DOES CONFLICT OF INTEREST LEAD TO BIASED COVERAGE? EVIDENCE
FROM MOVIE REVIEWS
Stefano DellaVigna
Johannes Hermle
Working Paper 20661
http://www.nber.org/papers/w20661

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2014

A previous version of this paper circulated in 2011 with the title `Does Media Concentration Lead
to Biased Coverage? Evidence from Movie Reviews' with Alec Kennedy as collaborator. Ivan Balbuzanov,
Natalie Cox, Tristan Gagnon-Bartsch, Jordan Ou, and Xiaoyu Xia provided excellent research assistance.
We thank Marianne Bertrand, Saurabh Bhargava, Fanny Camara, Lucas Davis, Casey Dougal, David
Dranove, Matthew Ellman, Ignacio Franceschelli, Matthew Gentzkow, Fabrizio Germano, Austan
Goolsbee, Emir Kamenica, Brian Knight, Jesse Shapiro, Noam Yuchtman, Joel Waldfogel and audiences
at Brown University, Boston University, Chicago Booth, the Paris School of Economics, UC Berkeley,
and at the 2011 Media Conference in Moscow for very helpful comments. We also thank Bruce Nash
for access to data from the-numbers, as well as helpful clarifications about the industry. The views
expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau
of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2014 by Stefano DellaVigna and Johannes Hermle. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.

Does Conflict of Interest Lead to Biased Coverage? Evidence from Movie Reviews
Stefano DellaVigna and Johannes Hermle
NBER Working Paper No. 20661
November 2014
JEL No. D72,L41
ABSTRACT
Media outlets are increasingly owned by conglomerates, inducing a conflict of interest: a media outlet
can bias its coverage to benefit companies in the same group. We test for bias by examining movie
reviews by media outlets owned by News Corp.—such as the Wall Street Journal—and by Time Warner—
such as Time. We use a matching procedure based on reported preferences to disentangle bias due
to conflict of interest from correlated tastes. We find no evidence of bias in the reviews for 20th Century
Fox movies in the News Corp. outlets, nor for the reviews of Warner Bros. movies in the Time Warner
outlets. We can reject even small effects, such as biasing the review by one extra star (out of four)
every 13 movies. We test for differential bias when the return to bias is plausibly higher, examine
bias by media outlet and by journalist, as well as editorial bias. We also consider bias by omission:
whether the media at conflict of interest are more likely to review highly-rated movies by affiliated
studios. In none of these dimensions do we find systematic evidence of bias. Lastly, we document
that conflict of interest within a movie aggregator does not lead to bias either. We conclude that media
reputation in this competitive industry acts as a powerful disciplining force.

Stefano DellaVigna
University of California, Berkeley
Department of Economics
549 Evans Hall #3880
Berkeley, CA 94720-3880
and NBER
sdellavi@econ.berkeley.edu
Johannes Hermle
University of Bonn
Bonn, Germany
johannes.hermle@uni-bonn.de

1

Introduction

On Dec. 13, 2007, News Corp. oﬃcially acquired Dow Jones & Company, and hence the Wall
Street Journal, from the Bancroft family. The acquisition was controversial in part because of
concerns about a conflict of interest. Unlike the Bancroft family whose holdings were limited
to Dow Jones & Company, Murdoch’s business holdings through News Corp. include a movie
production studio (20th Century Fox), cable channels such as Fox Sports and Fox News, and
satellite televisions in the Sky group, among others. The Wall Street Journal coverage of
businesses in these sectors may be biased to benefit the parent company, News Corp.
The Wall Street Journal case is hardly unique. Media outlets are increasingly controlled by
large corporations, such as Comcast, which owns NBC and Telemundo, the Hearst Corporation,
which owns a network of newspapers and ESPN, and Time Warner, which owns HBO, CNN,
and other media holdings. Indeed, in the highly competitive media industry, consolidation
with the ensuing economies of scale is widely seen as a necessary condition for survival.
But is this consolidation without cost for the quality of coverage given the induced conflict
of interest? Addressing this question is important, since potential biases in coverage can
translate into a policy concern in the presence of sizeable persuasion eﬀects from the media
(e.g., DellaVigna and Kaplan, 2007; Enikolopov, Petrova, and Zhuravskaya, 2011).
Yet should we expect coverage to be biased due to consolidation? If consumers can detect
the bias in coverage due to cross-holdings and if media reputation is paramount, no bias should
occur. If consumers, instead, do not detect the bias perhaps because they are unaware of the
cross-holding, coverage in the conglomerate is likely to be biased.
Despite the importance of this question, there is little systematic evidence on distortions in
coverage induced by cross-holdings. In this paper, we study two conglomerates–News Corp.
and Time-Warner–and measure how media outlets in these groups review movies distributed
by an aﬃliate in the group–such as 20th Century Fox and Warner Bros. Pictures, respectively.
The advantage of focusing on movie reviews is that they are frequent, quantifiable, and are
believed to influence ticket sales (Reinstein and Snyder, 2005), with monetary benefits to the
studio distributing the movie. As such, they are a potential target of distortion.
To identify the bias, we adopt a diﬀerence-in-diﬀerence strategy. We compare the review
of movies distributed by 20th Century Fox by, say, the Wall Street Journal to the reviews by
outlets not owned by News Corp. Since the Wall Street Journal may have a diﬀerent rating
scale, we use as a further control group the reviews of movies distributed by diﬀerent studios,
such as Paramount. If the Wall Street Journal provides systematically more positive reviews
for 20th Century Fox movies, but not for Paramount movies, we infer that conflict of interest
induces bias.
Still, a legitimate worry is that this comparison may capture correlation in taste, rather
than bias. The Wall Street Journal may provide more positive reviews to, say, action movies
of the type distributed by 20th Century Fox because this reflects the tastes of its audience (or
1

of its journalists), not because of conflict of interest. When estimating the impact of conflict
of interest, one would like to compare the reviews of a given 20th Century Fox movie only to
reviews of movies by other studios which share the same style. In principle, one could attempt
to find movies with similar features such as genre. This approach however is infeasible because
users may like (or dislike) movies based on fine features or details which are not observable.
Instead, we propose a reported preference approach. We say that movies A and B are
comparable if viewers that like movie A also like movie B, and vice versa users who dislike movie
A also dislike movie B. This approach does not require any information on movie characteristics,
since preferences already distill the relevant features. It does however require a rich individuallevel data set of movie ratings by potential audience members.
We take advantage of three rich such data sets by Netflix, Flixster, and MovieLens. Using
the individual user ratings, we find, for each 20th Century Fox and Warner Bros. movie, the ten
movies distributed by other studios which are most comparable by the above reported preference criterion. In a validation test, we show that matching movies are likely to share the genre,
the MPAA rating, and the average rating by movie reviewers, among other characteristics. We
thus use these matching movies as comparison group.
We start from a data set of half a million professional reviews of movies released from 1985
(the year in which News Corp. acquired 20th Century Fox) until 2010 (the year in which the
user ratings data ends). The data sources are the online aggregators Metacritic and Rotten
Tomatoes. We compare the reviews by 324 outlets with no conflict of interest (known to us)
to the reviews issued by 12 media outlets with cross-holdings. Eight media outlets are owned
by News Corp. during at least part of the sample–the U.S. newspapers Chicago Sun-Times
(owned until 1986), New York Post (owned until 1988 and after 1993), and Wall Street Journal
(owned from 2008), the U.K. newspapers News of the World, Times and Sunday Times, the
weekly TV Guide (owned from 1988 until 1999) and the website Beliefnet (owned from 2007
to 2010). Four media outlets are owned by Time Warner–the weeklies Entertainment Weekly
and Time as well as CNN and the online service Cinematical (owned from 2004 until 2009).
We provide six pieces of evidence on the extent, type, and channel of bias. In the first
test, we compare the reviews of movies distributed by the studios at conflict of interest to the
reviews of the ten matching movies. We test for average bias in outlets at conflict of interest,
such as the Wall Street Journal and Time magazine.
We find no evidence of bias for either the News Corp. or Time Warner outlets. In the
benchmark specification we estimate an average bias of -0.2 points out of 100 for News Corp.
and of 0 points for Time Warner. The richness of the data ensures tight confidence intervals for
the finding of no bias. We can reject at the 95% level a bias of 1.9 points for News Corp. and of
1.7 points for Time Warner, corresponding to a one-star higher review score (on a zero-to-four
scale) for one out of 13 movies at conflict of interest. We find similar results on the binary
‘freshness’ indicator employed by Rotten Tomatoes.
We underscore the importance of the matching procedure for the estimates of bias: cross2

sectional regressions on the whole sample of movies yield statistical evidence of bias for News
Corp. This seeming bias depends on the inclusion in the control group of movies that are
not comparable to the movies at conflict of interest, thus biasing the estimates. Further, we
provide direct evidence on correlated tastes: News Corp. outlets provide more positive reviews
to movies distributed by other studios when they are similar to the 20th Century Fox movies.
Second, while there appears to be no bias overall, a bias may be detectable for movies where
the return to bias is plausibly larger, holding constant the reputational cost of bias to the media
outlets. While we do not have measures of the return to bias, we consider dimensions which
are likely to correlate with it. We expect that movies with generally higher review scores are
likely to have higher return to bias, as an extra star is likely to matter more if it is the 4th star
out of 4, as compared to the second star. Also, movies distributed by the mainstream studios,
movies with larger budgets or larger box oﬃce sales are likely to have higher returns to bias.
We find no systematic pattern of diﬀerential bias in this respect.
Third, the overall result of no bias may mask heterogeneity in bias by the individual outlets.
We find no overall statistical evidence in the twelve outlets, with more precise null eﬀects for
the New York Post and TV Guide (News Corp.) as well as for Entertainment Weekly and
Time (Time Warner). Given that each outlet employs a small number of reviewers, we go
further and test for bias by journalist, and again do not find any systematic evidence of bias.
Fourth, we test for bias at the editorial level by examining the assignment of movies to
reviewers. Since reviewers diﬀer in the average generosity of their reviews, even in the absence
of bias at the journalist level, assignment of movies to more generous reviewers would generate
some bias. We find no evidence that aﬃliated movies are more likely to be assigned to reviewers
who are on average more positive, confirming the previous results.
So far we tested for bias by commission: writing more positive reviews for movies at conflict
of interest. In our fifth piece of evidence, we examine bias by omission. A reviewer that intends
to benefit an aﬃliated studio may selectively review only above-average movies by this studio,
while not granting the same benefit to movies by other studios. This type of bias would not
appear in the previous analysis, which examines bias conditional on review. Bias by omission
is generally hard to test for, since one needs to know the universe of potential news items.
Movie reviews is a rare setting where this is the case, and thus allows us to test for this form
of bias which plays a role in models of media bias (e.g., Anderson and McLaren, 2012).
We thus examine the probability of reviewing a movie as a function of the average review the
movie obtained in control outlets. The reviewing patterns do not diﬀer for movies at conflict
of interest versus the matching movies of other studios, thus providing no evidence of omission
bias. We show how apparent evidence of omission bias for Time magazine reflects a spurious
pattern, since it appears also before Time became part of the Time Warner conglomerate.
The sixth and final piece of evidence on bias examines conflict of interest for the movie
aggregator itself. Rotten Tomatoes was independent when launched in 1998, was then acquired
by News Corp. in September 2005, only to be divested in January of 2010. This ownership
3

structure generates an incentive for Rotten Tomatoes to assign more positive reviews (its
‘freshness’ indicator) to 20th Century Fox movies during the period of News Corp. ownership.
This test of bias is particularly powerful: bias is identified within a media outlet and by
comparison of the Rotten Tomatoes review versus the Metacritic score for the same movie
review. Further, the public is likely to be largely unaware of the cross-ownership, making bias
harder to detect by the audience. Once again, we find no evidence of bias, even where bias
would be hardest to detect (and hence presumably most likely), for unscored reviews which
are evaluated qualitatively by the Rotten Tomatoes staﬀ.
Overall, reputation-based incentives appear to be eﬀective at limiting the occurrence of
bias: we find no evidence of bias by commission, no evidence of editorial bias, no systematic
evidence of bias by omission, and no evidence of bias among the aggregators.
Using these results, we compute a back-of-the-envelope bound for the value of reputation.
Assume that an extra star (out of 4) persuades 1 percent of readers to watch a movie, an
eﬀect in the lower range of estimates of persuasion rates (DellaVigna and Gentzkow, 2010) and
smaller than the estimated impact of media reviews of Reinstein and Snyder (2005), though
admittedly we have no direct evidence.1 Under this assumption, an extra star in a single movie
review for a 20th Century Fox movie in a newspaper like the New York Post with a circulation
of about 500,000 readers would add approximately $40,000 in profits for News Corp.2 If the
New York Post had biased by one star all reviews for the 448 20th Century Fox movies released
since 1993, the profit could have been nearly $20m. The fact that such systematic bias did
not take place indicates a higher value of reputation. The potential returns are about an order
of magnitude larger for a periodical like Time magazine, with an average of 4 million readers,
and so is the value of the reputation.
This paper relates to a vast literature on conflict of interest and most specifically in the
media (e.g., Hamilton, 2003; Ellman and Germano, 2009). Reuter and Zitzewitz (2006) and Di
Tella and Franceschelli (2011) find that media outlets bias their coverage to earn advertising
revenue. We conjecture that the diﬀerence from our result of no bias is likely due to two
factors. First, the revenue from the ads directly benefits the media outlet, while the revenue
from increased movie attendance would accrue to the shareholders of the conglomerate, a
more indirect link. Second, movie reviews are easy to compare across a number of outlets
while coverage of mutual fund performance and of scandals are less so.
1

The average 20th Century Fox and Warner Bros. movie has a total domestic box oﬃce audience of around
7 million viewers, that is, about 3 percent of the relevant US population. Newspapers and magazine readers
are likely to have higher rates of movie attendance, which could be 5 percent. The 1 percent persuasion rate
thus implies that, say, a very positive review (4 stars out of 4) compared to a positive review (3 stars) increases
the share of readers who decide to watch the movie from, say, 5 to 6 percent, a magnitude we find plausible.
Of course, the potential eﬀect of reviews on attendance is larger for high-profile movies, and smaller for more
indie-type movies, a diﬀerence that we consider in the paper.
2
The studios receive about half of the box oﬃce sales (at an average price of $8 per ticket), and about another
half from higher DVD and TV royalties. Personal communication with Bruce Nash, founder of the-numbers.com.

4

A small number of papers considers media bias due to consolidation, as we do. Gilens and
Hertzman (2000) provide some evidence that the coverage of the debate on TV deregulation
is biased by conflict of interest. Goolsbee (2007) and Chipty (2001) examine the extent to
which vertical integration in the entertainment industry aﬀect network programming and cable
oﬀering. Dobrescu, Luca, and Motta (2013) estimate the bias in 1,400 book reviews due to
aﬃliation with the outlet reviewing the book; consistent with our findings, their evidence of
apparent bias is most consistent with correlated tastes, not conflict of interest. Rossman (2011)
and Ravid, Wald, and Basuroy (2006) examine the extent of bias in movie reviews, including
due to conflict of interest. Both papers use a small sample of reviews–about 1,000 reviews
for Rossman (2011) and about 5,000 reviews for Ravid et al. (2006). Relative to these papers,
the granularity of information embedded in half a million reviews and the matching procedure
allow us to obtain more precise measures and study the bias in a number of novel directions,
such as editorial bias and bias by omission. Camara and Dupuis (2014) estimate a cheap talk
game using movie reviews, including in the estimates a parameter for conflict of interest.
This paper also relates to the economics of the media (Strömberg 2004; George and Waldfogel, 2006; DellaVigna and Kaplan, 2007; Mullainathan, Schwartzstein, and Shleifer, 2008;
Knight and Chiang 2011; Enikolopov, Petrova, and Zhuravskaya 2011; Dougal et al., 2012),
and in particular to papers on media bias (Groseclose and Milyo, 2005; Gentzkow and Shapiro,
2010; Larcinese, Puglisi and Snyder, 2011; Durante and Knight 2012). Within the context of
movie reviews we address questions that have arisen in this literature–such as whether bias
occurs by omission or commission and the role of journalists versus that of editors–about
which there is little evidence.
Finally, the paper relates to the literature on disclosure, such as reviewed in Dranove and
Jin (2010). In our settings, media outlets do not withhold reviews for low-quality aﬃliated
movies, consistent with the Milgrom and Roberts (1986) unraveling result. Brown, Camerer,
and Lovallo (2012) instead provide evidence of strategic movie releases by studios with cold
openings for low-quality movies.
The remainder of the paper is as follows. In Section 2 we introduce the data and explain
the movie matching procedure, in Section 3 we present the results of the tests of bias due to
conflict of interest, and in Section 4 we conclude.

2
2.1

Data
Movie Reviews

Media Review Aggregators. The data used in this paper comes from two aggregators,
metacritic.com and rottentomatoes.com. Both sites collect reviews from a variety of media and
publish snippets of those reviews, but they diﬀer in their scoring rules. Metacritic assigns a
score from 0 to 100 for each review, and then averages such scores across all reviews of a movie

5

to generate an overall score. For reviews with a numeric evaluation, such as for the New York
Post (0-4 stars), the score is a straightforward normalization on a 0-100 scale. For reviews
without a numerical score, such as primarily for Time magazine, Metacritic staﬀers evaluate
the review and assign a score on the same 0-100 scale (typically in increments of 10).
Rotten Tomatoes does not use a 0-100 score, though it reports the underlying rating for
reviews with a score. It instead classifies each movie as ‘fresh’ or ‘rotten’, and then computes
a score for each movie — the tomatometer — as the percent of reviews which are ‘fresh’. For
quantitative reviews, the ‘freshness’ indicator is a straightforward function of the rating: for
example, movies with 2 stars or fewer (out of 4) are ‘rotten’, movies with 3 or more stars are
‘fresh’, and movies with 2.5 stars are split based on a subjective judgment. For reviews with
no quantitative score, the movie is rated as ‘fresh’ or ‘rotten’ by the staﬀ.
The two data sets have diﬀerent advantages for our purposes. Metacritic contains more
information per review, since a review is coded on a 0-100 scale, rather than with a 0 or 1
score. Rotten Tomatoes, however, contains about five times as many reviews as Metacritic,
due to coverage of more media (over 500 compared to less than 100) and a longer time span.
We take advantage of both data sets and combine all reviews in the two data sets for movies
released since 1985 and reviewed up until July 2011 in the Metacritic website and until March
2011 on the Rotten Tomatoes website. We eliminate earlier reviews because the review data
for earlier years is sparse, and before 1985 there is no conflict of interest: Newscorp. acquired
20th Century Fox in 1985 and the conglomerate Time Warner was created in 1989.
We merge the reviews in the two data sets in two steps. First, we match the movies by
title, year and studio with an approximate string matching procedure, checking manually the
imperfect matches. Then, we match reviews of a given movie by media and name of the
reviewer.3 We then exclude movies with fewer than 5 reviews and media with fewer than 400
reviews, for a final sample of 540,799 movie reviews.
To make the two data sets compatible, we then apply the Metacritic conversion into a 0-100
scale to the Rotten Tomatoes reviews which report an underlying quantitative score. To do
so, we use the reviews present in both data sets and assign to each Rotten Tomatoes score the
corresponding median 0-100 score in the Metacritic data, provided that there are at least 10
reviews present in both samples with that score. For a small number of other scores which are
common in Rotten Tomatoes but not in Metacritic, we assign the score ourselves following the
procedure of the Metacritic scoring rules (e.g., a score of 25 to a movie rated ‘2/8’).
Media Outlets. The data set includes eight media outlets within the News Corp. conglomerate: the American newspapers Chicago Sun-Times (owned by News Corp. only up until
1986), New York Post (owned until 1988 and after 1992), and Wall Street Journal (owned
from 2008), the British newspapers News of the World, Times and Sunday Times (all owned
throughout the period), the magazine TV Guide (owned from 1988 until 1999) and the website
3

We allow for the year of the movies in the two data sets to diﬀer by one year.

6

Beliefnet (owned from 2007 to 2010). The number of reviews and the data source diﬀer across
these outlets. The British newspapers are represented only in Rotten Tomatoes and have less
than 1,000 reviews each. The New York Post is represented in both data sets and has the most
reviews (5,657). TV Guide and Wall Street Journal have a relatively high number of reviews,
but only a minority while owned by News Corp. All but one of these eight media (the Wall
Street Journal) have quantitative scores in the reviews. These media employ as reviewers a
small number of journalists who stay on for several years, and often for the whole time period.
Therefore, within each media the two most common reviewers (three for the New York Post)
cover the large majority of the reviews, with two media using essentially only one reviewer:
Chicago Sun-Times (Roger Ebert) and the Wall Street Journal (Joe Morgenstern).
The second media conglomerate, Time Warner, includes four media: the weekly magazines
Time and Entertainment Weekly (both owned by Time Warner from 1990 on), CNN (owned
from 1996) and the web service Cinematical (owned between 2007 and 2010). The reviews in
these media are at conflict of interest with Warner Bros. movies, since the studio was acquired
in 1989 by Time, Inc. Two of the four outlets — CNN and Time — use only qualitative reviews;
since the reviews from CNN are only in the Rotten Tomatoes data set, there is almost no
0-100 score for these reviews, but only a freshness rating. Most of the observations are from
Entertainment Weekly, with more than 4,000 reviews. These outlets, like the News Corp.
outlets, employ only one or two major reviewers.
Studios. Dozens of diﬀerent studios distribute the 11,832 movies reviewed in our data
set, including the 6 majors 20th Century Fox, Columbia, Disney, Paramount, Universal, and
Warner Bros. Among the distributors owned by News Corp., 20th Century Fox movies are the
largest group (426 movies), followed by Fox Searchlight which distributes movies in the ‘indie’
category. Among the studios owned by Time Warner, the largest distributor is Warner Bros.,
followed by a number of distributors of ‘indie’ movies: Fine Line, New Line, Picturehouse, and
Warner Independent. In most of the following analysis, we group all the studios into those
owned by News Corp., which we call for brevity 20th Century Fox, and those owned by Time
Warner, which we call Warner Bros.
Additional Movie Information. We also merge this data set to additional information
on movies from the-numbers.com, including the genre and the MPAA rating.

2.2

Matching Procedure

User Ratings. We employ user-generated movie ratings from Netflix, Flixster, and MovieLens
to find the movies most similar to a 20th Century Fox or Warner Bros. movie.
Netflix is an online movie streaming service. Users rate movies on a scale from 1 to 5 with
1-point increments, typically right after watching a movie. Netflix made public a large data set
of (anonymized) reviews as part of its Netflix prize competition. This dataset contains roughly
100 million ratings by 480,000 users of 17,700 movies released up to 2005.

7

Flixster is a social network for users interested in the film industry. Besides other services,
Flixster oﬀers movie recommendations based on user ratings. We use a subset of this data
which is available at http://www.cs.ubc.ca/˜jamalim/datasets/. The rating scale ranges from
.5 to 5 in .5 steps. The dataset contains about 8 million ratings by 150,000 users on 48,000
movies released up to 2010.
MovieLens is an online movie recommendation service launched by GroupLens Research at
the University of Minnesota. The service provides users with recommendations once a suﬃcient
number of ratings has been entered (using the same .5 to 5 scale as in Flixster). The dataset,
which can be downloaded at http://www.grouplens.org/datasets/movielens/, was designed for
research purposes. It provides 7 million ratings by roughly 70,000 users on more than 5,000
movies released up to 2004.
Online Appendix Table 1 summarizes the key features of the three samples. Netflix has
the most comprehensive data set of reviews but, like MovieLens, it does not cover more recent
movies. Flixster covers the most recent years but it is a smaller data set and has a small
number of ratings per user. We use all three data sets, and perform the matches separately
before aggregating the results.4
To determine the movie matches for a particular 20th Century Fox or Time Warner movie
based on the user-generated reviews, we use the following procedure. Given movie  by 20th
Century Fox, we narrow down the set of potential matching movies  according to four criteria:
(i) the distributing studio of a movie  ∈  is not part of the same conglomerate as  in order
to provide a conflict-of-interest-free comparison; (ii) at least 40 users reviewed both movie 
and movie  so as to guarantee enough precision in the similarity measure; (iii) movie  is
represented in either the Metacritic or Rotten Tomatoes data set; (iv) movies  and  are close
on two variables: the diﬀerence in release years does not exceed 3 years, and the absolute
log-diﬀerence of the number of individual user ratings is not larger than .5.
Among the remaining potential matches  ∈  for movie , we compute the mean absolute
P
diﬀerence in individual ratings between movie  and a movie  as  = 1  | −  |, where
we aggregate over all users  who reviewed both movies (hence the requirement  ≥ 40). We
then keep the 10 movies with the lowest distance measure  .
To determine the overall best ten matches for movie , we pool the matching movies across
the three data sets. If movie  is present in only one data set, say because it was released after
2006 and thus is only in Flixster, we take the ten matches from that data set. If movie  is
present in multiple data sets, we take the top match in each data set, then move to the second
best match in each data set, and so on until reaching ten unique matches.5 We denote as a
4

Within each of the three data sets, we match the movies to the movies in the Metacritic/Rotten Tomatoes
data set using a parallel procedure to the one used when merging the Metacritic and Rotten Tomatoes data.
This allows us also to import the information on the year of release of the movie, used below.
5
We take matches from Netflix first, then MovieLens, then Flixster. Notice that to identify the top 10
matches overall, one may need to go down to, say, the top 5 matches or lower even with three data sets, given
that the diﬀerent data sets may yield the same matching movie .

8

movie group the set of 11 movies consisting of movie  and its ten closest matches. Later, we
examine the robustness of the results to alternative matching procedures.
Main Sample. We illustrate the sample construction with an example in Table 1. For
the 20th Century Fox movie Black Knight, the movie group includes movies of similar genre
like Down To Earth and Snow Dogs. We combine the movie-group information with the
review information from MetaCritic and Rotten Tomatoes. We thus form movie-media groups
consisting of reviews in a given media outlet of any of the 11 movies in the movie group. The
first movie-media group in Table 1 consists of reviews by the New York Post of Black Knight
and its 10 matches. The diﬀerence within this group between the review of Black Knight and
the review of the matching movies contributes to identify the eﬀect of conflict of interest. The
next movie-media group consists of reviews by Entertainment Weekly magazine of the same 11
movies. These reviews by a ‘control’ media outlet contribute to identify the average diﬀerential
quality of a 20th Century Fox movie. In the specifications we include movie-media group fixed
eﬀects, thus making comparisons within a movie group for a particular media outlet.
Note two features of the procedure. First, each media typically reviews only a subsample
of the 11 movies and thus a movie-media group can consist of fewer than 11 observations.
Second, a movie can be a match to multiple 20th Century Fox or Warner Bros. movies and as
such will appear in the data set multiple times. In Table 1, this is the case for 102 Dalmatians
which is a match for both Black Knight and Scooby-Doo. In the empirical specifications, we
address this repetition by clustering the standard errors at the movie level.
The initial sample for the test of conflict of interest in the News Corp. conglomerate includes
all movie-media groups covering movies distributed by 20th Century Fox and all media outlets
in the sample. We then drop matching movies which were not reviewed by at least one News
Corp. media outlet. A movie group has to fulfill two conditions to remain in the final sample:
(i) there has to be at least one review with conflict of interest (e.g., one review of the 20th
Century Fox movie by an outlet owned by News Corp.) and (ii) the movie group has to contain
at least one movie match (which was reviewed by a News Corp. outlet).
Appendix Table 1, Panel A reports summary statistics on the sample for the News Corp.
conglomerate (top panel) and for the Time Warner conglomerate (bottom panel). The data
set covers reviews from 335 diﬀerent media outlets. Appendix Table 1, Panel B presents
information on the studios belonging to News Corp. and to Time Warner.

3
3.1

Bias in Movie Reviews
Validation of Matching Procedure

In the analysis of potential bias due to conflict of interest, we compare the reviews of movies
by 20th Century Fox (and by Warner Bros.) to the reviews of the ten most comparable movies
distributed by other studios, according to the matching procedure discussed above. This

9

procedure is designed to address the concern that movies distributed by, say, 20th Century
Fox may have special features that not all movies have.
Does the matching procedure work? Figures 1a-f document the similarities between the
movies distributed by 20th Century Fox and Warner Bros. and the ten matching movies by
other studios with respect to three characteristics: movie genre, MPAA rating, and number
of theaters at opening. Since the match procedure did not use any of these features, we can
interpret the similarity, or lack thereof, as a validation of the approach. Furthermore, we
choose features that are pre-assigned and thus cannot be aﬀected by the reviews themselves.
Figure 1a shows that 20th Century Fox movies are most likely to be action, comedy, and
drama, and unlikely to be documentaries. The matching movies display a similar pattern,
while the movies that are never a match to a 20th Century Fox movie are more likely to be
documentaries. Figure 1b displays parallel findings for the Warner Bros. movies. Turning to
the MPAA rating (Figures 1c-d), the 20th Century Fox and Warner Bros. movies and their
respective matches are very similar, while the non-matching movies are more likely to be rated
R and less likely to be rated PG-13. Figures 1e-f display a third feature, the number of theaters
on the opening weekend, sorted in quintiles in 5-year bins. The 20th Century Fox and Warner
Bros. movies are close to their matches, while the non-matching movies follow an opposite
pattern.
In the online appendix we provide further evidence on the quality of the match. We
document that the same match pattern holds for a micro level comparison, namely matching
movies are disproportionately likely to share the genre, rating, and theaters at opening of the
movie they are matched to, compared to the general population of movies (Online Appendix
Figure 1a-f). We also document that matching movies resemble the movies at conflict of
interest with respect to two key outcomes of interest, the average 0-100 review score (Online
Appendix Figure 2a-d) and the probability of review (Online Appendix Figures 3a-d). Hence,
the matching procedure appears to be successful in identifying broadly comparable movies.
Building on this evidence, we now turn to the comparison outlined above.

3.2

Overall Bias

Graphical Evidence. We examine whether conflict of interest induces a bias on average,
starting with the 20th Century Fox movies. The bars on the right of Figure 2a indicate the
average review score for media not owned by News Corp. (the ‘placebo’ group). In this group,
the average review score for the 20th Century Fox movies (dark blue bar) and for the matching
movies distributed by other studios (light blue bar) is indistinguishable. The matching movies
appear to provide a good counterfactual: in the absence of conflict of interest, their average
score is essentially identical to the one of the 20th Century Fox movies.
The left bars in Figure 2a present the average score for reviews in News Corp. media outlets,
like the Wall Street Journal. The score for the matching movies (light blue bar) is somewhat

10

lower than in the non-News Corp. media, indicating that the News Corp. media outlets are
on average somewhat harsher in their reviews. The key question is whether this pattern is
the same for the movies distributed by 20th Century Fox, or whether those movies receive a
more generous treatment. The leftmost bar provides no evidence of bias: the average score
for the 20th Century Fox movies is essentially identical to the one for the matching movies by
other studios, with tight confidence intervals. A diﬀerence-in-diﬀerence estimator indicates a
diﬀerence of -0.12 points (out of 100, with p-value of .908 of the test of equality to zero).
Figure 2b presents the evidence for Time Warner. Once again, the reviews in non-Time
Warner media outlets are scored in about the same way for Warner Bros. movies and for
matching movies (right panel). Turning to the reviews in the Time Warner outlets (left panel),
the score is also essentially the same for the Warner Bros. movies and for the matching movies.
In this second conglomerate we also find no evidence of bias due to conflict of interest.
Regressions. To present a formal test and to examine the impact of control variables, we
estimate a regression-based specification. For the 20th Century Fox movies we estimate the
diﬀerence-in-diﬀerence OLS regression:
 =  +     +      +      + () + 

(1)

Each observation is a review for movie  by outlet . The dependent variable  is a 0 to
100 score, or an indicator for ‘freshness’. The coeﬃcient    captures the average diﬀerence
in reviews for movies distributed by 20th Century Fox, compared to the matching movies
distributed by other studios. The coeﬃcient    captures the average diﬀerence in reviews for
outlets owned by News Corp. at the time of the movie release, compared to the other outlets.
The key coeﬃcient,   , indicates the estimated impact of the conflict of interest, that is, the
average rating diﬀerence for a 20th Century Fox movie when reviewed by a media owned by
a News Corp. outlet, compared to the counterfactual. We include a fixed eﬀect  for each
movie-media group, where we denote with  () the 11 movies in the group for movie 
The standard errors are clustered at the movie level to allow for correlation of errors across
multiple reviews of a movie.6 We run a parallel specification for the Time Warner group.
Panel A of Table 2 reports the results for the score variable. Considering first the 20th
Century Fox movies (Columns 1-2), we present the results first with no controls and then with
fixed eﬀects for each movie-media group (see Table 1). In this second specification, regression
(1) is a matching estimator, comparing reviews for a 20th Century Fox movie to reviews for
the 10 matched movies. The result is similar in the two specifications, so we mostly discuss the
estimates with fixed eﬀects (Column 2). The estimated coeﬃcient on 20th Century Fox movies
in Column 2, ̂   = −075, is close to zero indicating, consistent with Figure 2a, that the
20th Century Fox movies and the matched movies are comparable in quality. The estimated
coeﬃcient on the News Corp. outlets in Column 1, ̂   = −434 is negative, again consistent
6

In Table 3 we show that alternative forms of clustering lead to comparable or lower standard errors.

11

with Figure 2a.7 The key coeﬃcient, ̂  = −019 indicates a null eﬀect of the conflict of
interest for News Corp. outlets: 20th Century Fox movies receive slightly less positive reviews
by News Corp. outlets by 0.2 points out of 100. The small standard errors imply that we can
reject at the 95% confidence level an eﬀect of bias of 1.92 points out of 100, equivalent to an
increase of one star (on a zero-to-four scale) for one out of 13 movies reviewed.
In Columns 3 and 4 we estimate the impact of conflict of interest on the Warner Bros.
movies. The results are parallel to the ones for the News Corp. conglomerate: we find no
evidence of an impact of conflict of interest: ̂  = −002. Given the larger sample of Warner
Bros. movies, we can reject even smaller eﬀects, corresponding to 1.72 points out of 100,
equivalent to an increase of one star (out of 4) for one out of 14.5 reviews.
In Panel B of Table 2 we present parallel specifications with the ‘freshness’ indicator as
dependent variable. The results for the ‘freshness’ variable are parallel to the results for the
score variable: we find no evidence of bias for either of the two conglomerates. For the rest
of the paper we focus on the 0-100 score variable given the higher statistical power given by a
continuous variable, the results are parallel with the freshness indicator.
Robustness. In Table 3 we present alternative specifications of the benchmark results
(Columns 2 and 4 of Table 2), reporting only the conflict-of-interest coeﬃcient. We examine
alternatives for: (i) standard errors, (ii) additional controls, (iii) the underlying data source,
(iv) the matching procedure. Clustering the standard errors by studio and by media outlet lead
to lower standard errors (Columns 2 and 3, compared to the benchmark clustering reproduced
in Column 1). Adding movie fixed eﬀects has a small impact on the estimates (Column 4).
Estimating the eﬀect separately for the Metacritic database (Column 5) and in the Rotten
Tomatoes database (Column 6) yields similar results. (Movie reviews which are in both data
sets are present in both samples).
We also investigate the robustness of the matching procedure. Restricting the match to
only the best 3 movie matches (rather than 10) does not change the estimate appreciably
but, predictably, lowers the precision somewhat (Column 7). Changing the closeness measure
to maximizing the correlation in reviews yields similar results (Column 8). Not using any
observable variable (year of release and number of reviews) in the match procedure also has
little impact (Column 9). In Online Appendix Table 2 we show that the results are robust to
computing matches using only one of the user reviews data sets, and using as a criterion for
closeness a likelihood ratio measure of the probability of rating a movie.
Cross-Sectional Estimates. In Table 4 we compare the matching estimates to crosssectional estimates for specification (1) using all reviews in the MetaCritic and Rotten Tomatoes data, making no use of the matching procedure. The estimates of the eﬀect of conflict
of interest for Time Warner are negative but close to zero, similar to the main specification
(Table 2). Instead, the estimate of the conflict of interest eﬀect for the News Corp. outlets
7

In Column 2 this coeﬃcient is identified oﬀ of media outlets that change ownership within our sample.

12

indicate a statistically significant, if quite small, 2.04 points of bias in the specification with
movie and media fixed eﬀects (Column 2).8 The next columns reconcile this estimate with the
matching estimate. The diﬀerence is not due to excluding movies that are not reviewed by
outlets at conflict of interest (Column 3) or to the fact that some of the 20th Century Fox and
Warner Bros. movies are not present in the Flixster/Netflix/MovieLens data set (Column 4),
and thus dropped from our matching analysis. Instead, the main diﬀerence is the inclusion of
control movies that are not matches to a 20th Century Fox or Warner Bros. movie. When we
drop these movies (Column 5), the estimate is very similar to the benchmark estimate.9
Given the evidence that non-matching movies diﬀer from matching movies in several dimensions like genre, rating, and opening weekend (Figures 1a-f), this suggests that reviewers
in the News Corp. outlets have specific tastes that it is important to control for in the analysis.
To more directly document this, we show that movies that are distributed by other studios
but are matches to 20th Century Fox movies are indeed reviewed more positively by the News
Corp. outlets (Online Appendix Table 3). We find similar evidence for correlated tastes when
considering movies similar in genre to the Fox movies, though not for similarity of MPAA
rating and budget. Given the evidence of the confound due to correlated tastes, we use the
matching estimator in the rest of the paper.

3.3

Bias by Movie Quality and Type

So far, we presented evidence on bias for the average movie. Yet, bias should be larger for
movies with a higher return to bias, holding constant the reputational cost. While we do not
have direct measures of return to bias, we consider two dimensions which are likely to correlate
with it. We expect that movies with generally higher review scores are likely to have higher
return to bias, as an extra star is likely to matter more if it is the 4th star out of 4, as compared
to the first star. We also assume that high-profile movies are likely to have higher returns given
the larger potential audience (holding constant the persuasive impact of a review).
Bias by Movie Quality. In Figure 3a we present evidence on potential bias as function
of movie quality for the 20th Century Fox movies. We assign to each movie the average review
score computed excluding the reviews in media at potential conflict of interest. We then display
a polynomial plot of the review score in the News Corp.-owned media outlets for the movies
distributed by 20th Century Fox (dark blue line) and for the matching movies distributed by
8

A previous working paper version of this paper estimated a bias of similar magnitudes using this specification.
Notice that this last specification still diﬀers from the matching one because (i) the set of fixed eﬀect diﬀers
and (ii) in the benchmark specification reviews for a matching movie appear multiple times if the movie is a
match to multiple, say, 20th Century Fox movies; instead, in the cross-sectional specification each movie review
appears only once. Column (5) shows that this diﬀerence is immaterial to the results. Furthermore, the estimate
in Column (5) is similar to the estimate in Column (4) in Table 3 where movie fixed eﬀects are included as
additional controls.
9

13

other studios (light blue line).10 The plot for the matching movies indicates that the News
Corp. outlets largely follow the other outlets in their review. The plot for the movies at conflict
of interest hovers around the one for the matching movies, with no evidence of deviation for
movies of higher, or lower, quality. For Time Warner as well (Figure 3b), the average score for
aﬃliated movies tracks very closely the score for the non-aﬃliated movies, with no systematic
deviation for higher-quality movies. Thus we do not find evidence of diﬀerential bias.
Bias by Movie Profile. In addition to the mainstream studios 20th Century Fox and
Warner Bros., the News Corp. and Time Warner conglomerates include indie studios like Fox
Searchlight, Fine Line, and New Line (see Appendix Table 1B). Figures 4a and 4b plot, for
each studio, the average review score in media outlets at conflict of interest (y axis) and in
other outlets (x axis). To make the comparison clear, we plot the same measure for the other 9
major studios.11 There is no evidence of diﬀerential bias, which consists of points lying above
the 45 degree line, for the mainstream studio compared to the indie studios.
In Online Appendix Table 4, we present additional evidence. We re-estimate specification
(1) allowing for a diﬀerential eﬀect of conflict of interest for four proxies of return to bias: (i)
distribution by a mainstream studio, (ii) production budget, (iii) number of theaters at opening
and (iv) domestic box oﬃce.12 We find no statistically significant evidence of diﬀerential bias
by the four proxies, even though directionally the sign of the eﬀects is as expected for the 20th
Century Fox movies. Overall, there is no clear evidence of diﬀerential bias for movies with
plausibly higher return to bias.

3.4

Bias by Media and Journalist

The previous evidence indicates the apparent lack of bias due to conflict of interest, even when
considering separately movies with plausibly higher incentives for bias. These results reject
the scenario of widespread bias across all outlets within a conglomerate. Still, it is possible
that some media outlets, or some journalists, bias their reviews, but this is balanced by the
lack of bias in other outlets in the same conglomerate, or perhaps even by negative bias (to
avoid criticism). We thus examine the occurrence of bias by media and by journalist.
Bias By Media. The scatter plot in Figure 5a reports for each media outlet the average
review for the 20th Century Fox movies and the average review for the matching movies by
other studios. To provide a counterfactual, we also plot these measures for the 200 largest
media outlets not owned by News Corp.13 No News Corp. media outlet deviates substantially
10

We use an Epanechnikov kernel and a 1st degree polynomial, with a kernel of 5 rating points. We truncate
movies with average movie score below 30 or above 80, since such movies are rare.
11
Dot Sizes are proportional to the square root of the number of reviews by News Corp. or Time Warner
outlets. We do not use the matching procedure in order to ensure a larger sample of movies by other studios.
12
For the last three proxies, we use deciles, formed within 5-year periods, of the variable to adjust for changes
over time and skewness.
13
We only include outlets with at least 15 reviews of 20th Century Fox movies while owned by News Corp.

14

on the positive side of the trend line, the indication for bias.14 We estimate a specification like
(1) for each outlet at conflict of interest separately, and find no significant evidence of bias for
any of the outlets (Online Appendix Table 5).
Figure 5b provides parallel evidence for the Time Warner conglomerate, with Entertainment
Weekly, Time magazine and Cinematical right on the regression line indicating no bias, a
finding that is replicated in regression format (Online Appendix Table 5). Thus, the pattern
for the individual outlets is similar to the overall pattern of no bias.
Bias By Journalist. We further take advantage of the fact that most media have only
a small number of movie reviewers, and these journalists typically stay on for years, if not
decades. This long tenure allows us to estimate journalist-specific patterns which, as far as
we know, is a rare feature within the media economics literature (Dougal et al., 2012). In
Appendix Figures 1a-b we provide parallel plots to Figures 5a-b, but by journalist. In addition
to the journalists working in the two conglomerates, we include the 500 other journalists with
the most reviews. Only one journalist stands out, Maitland McDonagh (at TV Guide), with a
statistically significant estimate of bias (Online Appendix Table 6). Yet, given that the pattern
appears for only one out of 12 journalists, it is plausible that this pattern is due to chance.

3.5

Editorial Bias

In the previous section we tested for bias in the presence of conflict of interest, focusing
on the role of journalists. Conversely, we now examine the role of editors. An editor who
intends to bias the review process can do so in at least two ways: by putting pressure on the
journalists, or by assigning the aﬃliated movies to journalists who on average assign higher
review scores.15 We examine the latter mechanism, which is well-suited to test for biased
coverage as a managerial policy of the conglomerate. While journalists could resist managerial
pressure to bias the content of their reviews, this form of bias only requires the assignment of
movies to diﬀerent reviewers.
We provide graphical evidence on this test for the reviewers in News Corp. media outlets
in Figure 6a. We plot for each reviewer the average generosity in review score (relative to
the media outlet average) (x axis) and the share of their reviews of 20th Century Fox movies
(y axis).16 As the scatter shows, movie reviewers diﬀer sizably in generosity within a given
outlet. Yet, there is no evidence that the more generous reviewers are more likely to review
14

The Sunday Times and Wall Street Journal are outliers below the line, but the estimate of bias is imprecise
for these outlets given the small number of reviews at conflict of interest.
15
A third form of editorial influence is the hiring of more favorable journalists and firing of less favorable ones.
We observe no evidence of elevated turn-over for the outlets after a change in ownership.
16
To compute the average generosity, we only take into account score reviews (on a 0-100 scale) and generate for
each review an idiosyncratic review score defined as the score minus the average review score of the corresponding
movie. We then compute the average of this variable for all journalists and their aﬃliated outlets. The measure
of the average generosity of a journalist (relative to the aﬃliated outlet) is calculated as the diﬀerence between
the two means. Here, we do not use the matching procedure in order to preserve a larger sample of movies.

15

20th Century Fox movies. Indeed, the regression line points to a slight negative relationship
between generosity and review probability.
In Figure 6b we report the parallel evidence for the Time Warner outlets. As for the News
Corp. outlets, we find no evidence of a systematic pattern of assignment of movies to reviewers
in order to benefit the aﬃliated studio.

3.6

Bias by Omission

The previous evidence rules out sizable bias in the movie quality assessed in reviews, whether
due to editorial or journalistic decisions. But this evidence does not cast light on a potentially
more insidious form of bias: bias by omission. The media can selectively display items of
information, as in Anderson and McLaren (2012). In our setting, an outlet may decide to not
review a below-average movie by an aﬃliated studio, but make sure to review an above-average
movie by the same studio. A media outlet following this strategy would not display any bias
conditional on review; hence, bias by omission would not be detected by the previous analysis.
In Figure 7a we present evidence on omission bias for the News Corp. media. We test
whether News Corp. outlets are more likely to review 20th Century Fox movies with high
predicted review (as proxied by high average rating by other reviewers), compared to their
reviewing patterns for non-20th Century Fox movies. We display a polynomial smoother of
the review probability as a function of the average review score of a movie (in the range between
30 and 80).17 The average probability of review by News Corp. media outlets of 20th Century
Fox movies is barely increasing in the review score (darker continuous line). By comparison,
the probability of review of the matching movies by other studios (lighter continuous line) is
more clearly increasing in the movie review, suggesting if anything a negative bias by omission.
To strengthen the inference, we also compare these patterns to the probability of review
by other media outlets not owned by News Corp. In doing so, we need to take into account
that media outlets diﬀer in their reviewing propensity. Thus, for each media outlet owned by
News Corp. we choose the ten media outlets which display the closest pattern in the review
probability of non-20th Century Fox movies.18 The dotted lines in Figure 7a display the
17

The sample for the omission bias test in this section is determined as follows. For each of the 8 News Corp.
outlets, like the New York Post, we determine all 20th Century Fox movies and their movie matches which
were released during News Corp. ownership of the respective outlet. For each movie in this subsample and
outlet-either the News Corp. or one of the control outlets (see below)-we generate a dummy of whether it was
reviewed (0-100 score or ‘freshness’ indicator). Thus, there is only one observation per movie and media outlet.
We use this data set when testing for omission bias for that particular outlet. To obtain the sample for the
overall test pooling across all 8 outlets, we repeat this procedure for all 8 News Corp. outlets and append the
data sets. We follow a parallel procedure for the Time Warner test.
18
The matching outlets are the ten outlets with the smallest distance in the probability of review for the
matching movies. We form bins with a width of 5 points of the average review score and determine the average
distance between two media outlets in the review probabilities within each bin. The overall distance is computed
averaging the distance across the bins, weighting by the number of movies in a bin.

16

probability of review by these matched media of 20th Century Fox movies (dotted darker line)
and of the matching movies (dotted lighter line). The dotted lines track remarkably well the
continuous lines for the matching movies, suggesting that the matching media provide a good
counterfactual to the News Corp. media. Overall, Figure 7a suggests no evidence of omission
bias. Online Appendix Figures 4a-d show that the same pattern holds when considering the
News Corp. media outlets individually.
The corresponding figure for the Time Warner outlets (Figure 7b) instead provides some
evidence consistent with omission bias. The probability of review of Warner Bros. movies
in Time Warner outlets is increasing in the measured quality of the movie, more so than in
the matched media. Yet, this increasing pattern is similar for matching movies in the Time
Warner media (lighter continuous line), suggesting that the pattern may be due to a reviewing
strategy in the Time Warner media outlets, rather than to bias.
To provide more evidence, in Online Appendix Figures 5a-d we disaggregate the eﬀect
by the four Time Warner media outlets. The evidence suggestive of omission bias is almost
entirely due to Time magazine. To ascertain whether the pattern in the data is due to intended
omission bias or an idiosyncratic reviewing strategy by Time, we exploit two placebos. First,
we take advantage of the fact that in years 1985-89 Time magazine was not yet part of the
Time Warner conglomerate. Second, we exploit the fact that 20th Century Fox movies share
some characteristics with Warner Bros. movies (see Figures 1a-f), but there is no conflict of
interest in place with those movies at Time magazine. As Online Appendix Figures 6b and 6c
show, these two placebos show a similar reviewing pattern to the one in the main sample. This
suggests that the pattern at Time magazine should not be interpreted as bias by omission.
To further put these findings in context, we compare the extent of selective reviewing in
the media at conflict of interest with the same phenomena for the largest 200 other outlets.
Figures 8a-b display for each media outlet the estimated sensitivity of the review probability
to the average score for the movies at conflict of interest (y axis) versus the same movies in
the matching outlet (x axis). The two sensitivity coeﬃcients are just the slope coeﬃcient
of separate linear regressions of the review probability on the average review score. Bias by
omission would manifest itself as an outlier above the regression line: an outlet is more sensitive
to quality when reviewing a movie at conflict of interest. The patterns confirm the findings
above. None of the News Corp. outlets stand out for omission bias, while among the Time
Warner outlets, only Time magazine stands out, a case we discussed above.
To provide a statistical test of omission bias, we estimate a linear probability model in
Table 5, which we illustrate for the case of media owned by News Corp.:
 =  +      + Γ    ̄ +     +

(2)

    ̄ +      +      ̄ + ̄ + () +  
An observation is a possible review of a 20th Century Fox movie or of a matching movie by
one of the News Corp. or matching outlets with similar probability of review. The dependent
17

variable is the indicator  which equals 1 if media outlet  reviews movie  The key
coeﬃcient is Γ on the interaction of the conflict of interest variable with the mean rating
score ̄ . This coeﬃcient indicates how the probability of a review varies with the average
review score, in the presence versus absence of a conflict of interest. The regression includes
movie-media group fixed eﬀects. A key assumption made in equation (2) is that the probability
of movie review is linearly increasing in the average movie score; we adopt this assumption
given the evidence of approximate linearity in Figures 7a-b.
Table 5 provides no evidence of selective review consistent with omission bias for the News
Corp. or for the Warner Bros. media. For News Corp. outlets, we can reject that a onestandard deviation increase in movie quality (14 points in overall score) for a 20th Century
Fox movie increases the probability of review (diﬀerentially) by more than 1.7 percentage
points. Similarly, for Time Warner we can reject for a similar increase in movie quality an
increase in review probability of more than 2.2 percentage points. In Online Appendix Table
7 we present the results separately for each media outlet. The relevant coeﬃcient   on the
interaction between conflict of interest and average review score is significantly positive only
for Time Magazine, a special case we discussed above. Overall, we conclude that it is unlikely
that any of the outlets is explicitly adopting a strategy of bias by omission.19

3.7

Bias in Movie Aggregator

So far we have focused on the conflict of interest induced by the consolidation of studios like
20th Century Fox and Warner Bros. into media conglomerates which employ movie reviewers.
But consolidation aﬀects the review aggregators themselves. Rotten Tomatoes, independent
when launched in 1998, was acquired by IGN Entertainment in June 2004, and IGN itself was
purchased by News Corp. in September 2005. IGN, and hence Rotten Tomatoes, was then
sold in January of 2010 by News Corp. and acquired in April 2011 by Time Warner.
This ownership structure generates an incentive for Rotten Tomatoes to post more positive
reviews of 20th Century Fox movies during the period of News Corp. ownership (2006-2009).
Since the reviews are posted quickly on the Rotten Tomatoes site and then rarely updated20 ,
we use the year of release of the movie to test the hypothesis of conflict of interest. We estimate
 =  +    2006−09
+    +  +  +  


(3)

where  is the ‘freshness’ indicator on Rotten Tomatoes for movie  in media outlet . The
coeﬃcient of interest,    captures how movies distributed by the 20th Century Fox studio
19

We also examined a form of partial omission: whether media at conflict of interest are more likely to
display delayed reviews and shorter reviews for low-quality aﬃliated movies. Using a smaller data set (since
the information on date of review and length of review is not in Metacritic or Rotten Tomatoes) we do not find
evidence of such bias.
20
Consistent with this, two separate scrapes of the site at 3 month distance yielded no change in the reviews
for older movies.

18

( = 1) are characterized in years 2006-2009, compared with the years before and
after. We allow for a baseline diﬀerence in reviews for 20th Century Fox movies (captured by
 ) and fixed eﬀects for year  and for the movie-media group. Most importantly, we control
for the MetaCritic scoring  for the same movie review21 .
Column 1 in Table 6 shows that the eﬀect of conflict of interest is a precisely estimated zero
= 00031), a result that replicates when using all reviews, rather than just the matched
sample (Column 2). We can reject as an upper bound that conflict of interest increases the
probability of a fresh score by 0.6 percentage points (Column 2), a small eﬀect. In Figure 9a,
using the matched sample, we present graphical evidence using a local polynomial estimator
of the Rotten Tomatoes ‘freshness’ indicator on the 0-100 quantitative score. We run the
non-parametric regressions separately for the 20th Century Fox movies (the continuous lines)
and the matching movies by other studios (dotted lines), split by the period of News Corp.
ownership (dark blue line) and the remaining time period (light blue line). The two continuous
as well as the two dotted lines are very close on the graph, again indicating no bias.
(̂ 

While we detect no bias on average, bias may have been present in some years, for example
when News Corp. just acquired Rotten Tomatoes and awareness of the conflict of interest was
presumably lower. We estimate an event study specification:
 =  +    +  (1 −  ) +  +  
The specification is parallel to (3) except that, instead of separating the years into a period of
ownership (2006-09) and all else, we interact the year fixed eﬀects  with an indicator for 20th
Century Fox movie and an indicator for the complement. Figure 9b shows that the residual
freshness score for the 20th Century Fox movies ( ) tracks the series for other movies ( )
also during the years of ownership, providing no evidence of bias. Since bias may still be
present in a subset of the data, we analyze separately reviews with a quantitative score (i.e.
stars) and qualitative reviews for which the freshness score is determined by a staﬀ reading.
For the quantitative reviews, we focus on reviews with scores between 50 and 70, for which
Rotten Tomatoes appears to use qualitative information to assign the ‘freshness’ rating. Even
in this sample (Column 3), we detect no bias.
However, bias should be most likely for reviews without a quantitative score since the
probability of detection is particularly low. Yet, we find no evidence of bias in this sample either
(Column 4). We replicate this result on the smaller sample of qualitative reviews stored in both
aggregators, so as to include as a control the score attributed by the Metacritic staﬀ (Column
5), again finding no eﬀect of the conflict of interest on bias, with more precise estimates.
Despite the conflict of interest, there is no semblance of bias in the movie aggregator Rotten
Tomatoes, even for the types of reviews for which detection of bias would be hardest.
21

The quantitative scoring is as reported by Rotten Tomatoes, translated into the 0-100 score. If the Rotten
Tomatoes score is missing, for example for qualitative reviews, we use the score in MetaCritic if available. We
confirm that Rotten Tomatoes does not bias this quantitative score by regressing it on the corresponding score
for the same review in MetaCritic, when both are available.

19

4

Conclusion

Consolidation in the media industry is considered by many a condition for survival in an
industry hit hard by the loss of advertising. Yet, consolidation does not come without potential
costs. In addition to the potential loss of diversity (George and Waldfogel, 2003), consolidation
increases the incidence of conflict of interest due to cross-holdings, and possible ensuing bias.
We focus on conflict of interest for movie reviews, such as when the Wall Street Journal
reviews a 20th Century Fox movie. The holding company, News Corp., can potentially benefit
financially from a more positive review, and hence higher movie attendance, creating a conflict
of interest.
Using a data set of over half a million movie reviews from 1985 to 2010, we find no statistical
evidence of media bias due to conflict of interest in either the News Corp. conglomerate or
the Time Warner conglomerate. The null finding is not due to imprecision. We can reject
small estimates of bias, such as one extra star (out of 4) in one out of every 13 movies at
conflict of interest. Moreover, we are able to examine bias at a high level of detail, including
bias by media outlet and journalist, comparative statics in the return to bias, bias in editorial
assignment, bias by omission as opposed to commission, and bias by the aggregator. In the
end, we feel confident of the overall estimate.
As we discussed in the introduction, these estimates imply a back-of-the-envelope bound for
the value of a reputation for the media outlets. Under the assumption that an extra star (our
of 4) convinces 1 percent of readers to watch a movie, an extra star in a single movie review
for a 20th Century Fox in the New York Post would add approximately $40,000 in profits for
News Corp. The correspondent figure for an extra star in a review of a Warner Bros. movie
in Time magazine is approximately $300,000. The fact that such systematic bias did not take
place in either outlet indicates that the value of their respective reputations is larger.
Within the context of movie reviews, we addressed questions that have arisen in the economics of the media, such as whether bias occurs by omission or commission, about which we
have limited information. We view this contribution as a step forward in better understanding
the functioning of media outlets, which play a key role in the formation of public opinion.
In particular, this paper provides some evidence on how media outlets navigate the tradeoﬀ between professional journalism and revenue maximization for the owners. In this case,
professionalism and reputation concerns appear to trump possible short-term revenue gains.
As we discussed above, our results diﬀer from the impact of conflict of interests for advertising. In the latter case, both Reuter and Zitzewitz (2006) and Di Tella and Franceschelli (2011)
document sizable distortions. We conjecture that two diﬀerences likely play a role. First, the
benefits from the ads directly benefit the media outlet, while in the case at hand the benefits
accrue to the shareholders of the conglomerate, a more indirect link. Second, movie reviews
are easy to compare across a number of outlets while coverage of scandals and of mutual fund
performance are less so. More research will hopefully clarify these diﬀerences.

20

References
[1] Anderson, Simon and John McLaren. 2012. “Media Mergers and Media Bias with Rational
Consumers.” Journal of the European Economic Association, 10(4), 831-859.
[2] Brown, Alexander L., Camerer, Colin F. and Lovallo, Dan. 2012. “To Review or Not
to Review? Limited Strategic Thinking at the Movie Box Oﬃce”, American Economic
Journal: Microeconomics, 4(2), 1-26.
[3] Camara, Fanny and Nicolas Dupuis. 2014. “Structural Estimation of Expert Strategic
Bias: the Case of Movie Reviewers” Working paper.
[4] Chipty, Tasneem. 2001. “Vertical Integration, Market Foreclosure, and Consumer Welfare
in the Cable Television Industry”, The American Economic Review, 91 (3), 428-453.
[5] DellaVigna Stefano and Matthew Gentzkow. 2010. “Persuasion: Empirical Evidence.”
Annual Review of Economics, 2, 643-669.
[6] DellaVigna Stefano, Ethan Kaplan. 2007. “The Fox News eﬀect: Media Bias and Voting.”
Quarterly Journal of Economics, 122(3), 1187-234.
[7] Di Tella, Rafael, and Ignacio Franceschelli. 2011. “Government Advertising and Media
Coverage of Corruption Scandals.” American Economic Journal: Applied Economics 3(4),
119-151.
[8] Dobrescu, Loretti, Michael Luca, and Alberto Motta. 2013. “What makes a critic tick?
connected authors and the determinants of book reviews.” Journal of Economic Behavior
and Organization, 96, 85-103.
[9] Dougal, Casey, Joseph Engelberg, Diego Garcia, and Christopher Parsons. 2012. “Journalists and the Stock Market” Review of Financial Studies, 25(3), 639-679.
[10] Dranove, David and Ginger Zhe Jin. 2010. “Quality Disclosure and Certification: Theory
and Practice,” Journal of Economic Literature, 48(4), 935-63.
[11] Durante, Ruben and Brian Knight. 2012. “Partisan Control, Media Bias, and Viewer
Responses: Evidence from Berlusconi’s Italy.”Journal of the European Economic Association, 10(3), 451-481.
[12] Ellman, Matthew and Fabrizio Germano. 2009. “What do the Papers Sell? A Model of
Advertising and Media Bias”, Economic Journal, 119(537), 680-704.
[13] Enikolopov, Ruben, Maria Petrova, and Ekaterina V. Zhuravskaya. 2011. “Media and
Political Persuasion: Evidence from Russia.”American Economic Review, 101(7), 32533285.
[14] Gentzkow, Matthew and Jesse Shapiro. 2006. “Media Bias and Reputation ”Journal of
Political Economy, 114(2), 280-316.
[15] Gentzkow, Matthew and Jesse Shapiro. 2010. “What Drives Media Slant? Evidence from
U.S. Daily Newspapers ”Econometrica, 78(1), 35-71.
[16] George, Lisa and Joel Waldfogel. 2003. “Who Aﬀects Whom in Daily Newspaper Markets?” Journal of Political Economy, 111(4), 765-784.
[17] George, Lisa and Joel Waldfogel. 2006. “The New York Times and the Market for Local
Newspapers” American Economic Review, Vol. 96(1), 435-447.
21

[18] Gilens, Martin and Craig Hertzman. 2000. “Corporate Ownership and News Bias: Newspaper Coverage of the 1996 Telecommunications Act ” Journal of Politics 62(2), 369-86.
[19] Gooslbee, Austan. 2007. Vertical Integration and the Market for Broadcast and Cable
Television Programming. Working paper.
[20] Groseclose, Tim and Jeﬀrey Milyo. 2005. “A Measure of Media Bias”. Quarterly Journal
of Economics, 120(4), 1191-1237.
[21] Hamilton, James T. 2003. All the News That’s Fit to Sell: How the Market Transforms
Information into News. Princeton: Princeton University Press.
[22] Knight, Brian and Chun-Fang Chiang. 2011. “Media Bias and Influence: Evidence from
Newspaper Endorsements.” Review of Economic Studies, 78(3), 795-820.
[23] Larcinese, Valentino, Ricardo Puglisi, and James M. Snyder. 2011. “Partisan Bias in
Economic News: Evidence on the Agenda-Setting Behavior of U.S. Newspapers.”Journal
of Public Economics, 95(9-10): 1178-1189.
[24] Milgrom, Paul and John Roberts. 1986. “Relying on the Information of Interested Parties”,
RAND Journal of Economics, 17(1), 18-32.
[25] Mullainathan, Sendhil, Joshua Schwartzstein, and Andrei Shleifer. 2008. “Coarse Thinking
and Persuasion.” Quarterly Journal of Economics, 123(2), 577-619
[26] Reinstein, David and Christopher Snyder. 2005. “The Influence of Expert Reviews on
Consumer Demand for Experience Goods: A Case Study of Movie Critics” Journal of
Industrial Economics, 53(1), 27-51.
[27] Ravid, S. Abraham, John Wald, and Suman Basuroy. 2006. “Distributors and film critics:
does it take two to Tango?” Journal of Cultural Economics, 30(3), 201-218.
[28] Reuter, Jonathan and Eric Zitzewitz. 2006. “Do Ads Influence Editors? Advertising and
Bias in the Financial Media.”The Quarterly Journal of Economics, 121(1): 197-227.
[29] Rossman, Gabriel. 2011. The Influence of Ownership on the Valence of Media Content:
The Case of Movie Reviews. Working Paper #27, Fall 2011.
[30] Strömberg, David. 2004. “Radio’s Impact on Public Spending.”Quarterly Journal of Economics, 119(1): 189-221.

22

Figures 1a-1f. Documenting the Quality of Movie Matches
Figure 1a-b. Similarity to Match: Movie Genre

Figure 1c-d. Similarity to Match: MPAA Rating

Figure 1e-f. Similarity to Match: Number of Theaters in Opening Weekend

Notes: Figures 1a-b display the distribution of movie genre for the movies by 20th Century Fox and Warner Bros., the movie matches,
and movies which are not matches. Figures 1c-d and 1e-f display parallel evidence for the distribution of MPAA ratings and the
number of theaters at opening. For the purpose of assigning movies to a particular quintile in Figures 1e-f, 5-year bins are formed and
the quintile of a particular movie is determined within each bin.

23

Figure 2a. Average bias in movie ratings: News Corp.-affiliated outlets

Figure 2b. Average bias in movie ratings: Time Warner-affiliated outlets

Notes: Figures 2a and 2b report the average review score on a 0 to 100 scale. Figure 2a is split by whether the movies are reviewed by
News Corp. or other outlets. Each subpanel shows two differently colored bars indicating either movies distributed by 20th Century
Fox (dark blue bar) or movie matches (light blue bar). Figure 2b displays parallel evidence for Time Warner outlets and Warner Bros.
movies.

24

Figure 3a-b. Bias by Quality: News Corp.-owned outlets (3a) and Time Warnerowned outlets (3b)

Notes: Figures 3a reports local polynomial regressions with Epanechnikov kernel with bandwidth of 5 and 1st degree polynomial of
the average review score (on a 0 to 100 scale) by News Corp. outlets on the average movie review score by all other outlets. We do
separate regressions for 20th Century Fox movies (dark blue line) and the matching movies distributed by other studios (light blue
line). Figure 3b reports the same polynomial regressions for Time Warner outlets and Warner Bros. movies. The sample only contains
movies with an average review score in the range of 30 to 80.

25

Figure 4a-b. Bias by Studio: News Corp.-owned outlets (3a) and Time Warnerowned outlets (3b)

Notes: Figure 4a displays the average review score (on a 0 to 100 scale) by News Corp. outlets against the average review score by
other outlets conditional on the distributing studio of the movies reviewed. Colors indicate whether a particular studio is owned by
News Corp. (red dots) or is one of the other nine biggest studios (excluding Time Warner studios) (gray dots). Dot sizes are
proportional to the square root of the number of reviews by News Corp. outlets. Studios with a number of reviews by News Corp.
outlets less than 20 are excluded. Figure 4b shows parallel evidence for Time Warner outlets and Warner Bros. movies. Both figures
use the Metacritic/Rotten Tomatoes dataset without matches.

26

Figure 5a-b. Bias by Media Outlet: News Corp.-owned outlets (5a) and Time
Warner-owned outlets (5b)

Notes: Figure 5a displays the average review score (on a 0 to 100 scale) of 20th Century Fox movies against the average review score
of the associated movie matches for News Corp. outlets and outlets not owned by News Corp. Colors indicate whether a particular
outlet is owned by News Corp. (red dots) or is one of the other 200 biggest control outlets (gray dots). Outlets with a number of
reviews of 20th Century Fox movies less than 15 are excluded. Figure 5b displays parallel evidence for Warner Bros. movies and Time
Warner outlets.

27

Figure 6a-b. Editorial Bias in Assignment of Reviews

Notes: Figure 6a displays the share of score reviews (on a 0 to 100 scale) of 20th Century Fox movies for a given journalist employed
at a News Corp. outlet versus a measure for the journalist generosity. For each review an idiosyncratic score is calculated as the
review score minus the average review score for the corresponding movie. The mean of this variable is computed for each journalist
and outlet to calculate a measure of absolute generosity. The journalist generosity (relative to the media outlet average) is then defined
as the difference between the absolute generosity of a journalist minus the absolute generosity of the affiliated outlet. Dot sizes are
proportional to the square root of the number of reviews by a particular journalist. Journalists with a number of reviews less than 50
are excluded. Figure 6b displays the same relationship for journalists employed at a Time Warner outlet. For each journalist the
associated outlet is indicated in parentheses: BN: Beliefnet; CST: Chicago Sun-Times; CM: Cinematical; CNN: CNN; NOTW: News
of the World; EW: Entertainment Weekly; NYP: New York Post; ST: Sunday Times; Time: Time; Times: Times; TVG: TV Guide;
WSJ: Wall Street Journal.

28

Figure 7a-b. Selective coverage -- Probability of review by movie quality (rating)

Notes: Figure 7a reports local polynomial regressions with Epanechnikov kernel with a bandwidth of 5 and 1st degree polynomial of
an indicator for whether the movie was reviewed (score on a 0 to 100 scale or ‘freshness’ indicator) on the average movie review
score. Colors distinguish separate polynomials for either 20th Century Fox movies or associated movie matches. Solid lines
characterize regressions for outlets owned by News Corp., dashed lines those for the ten best matching media. For each News Corp.
outlet those are determined by minimizing the distance to the particular News Corp. outlet in the review probability only for the
matching movies. For this purpose, bins with a width of 5 score points are formed and the distance in the review probability for each
bin is weighted by the number of matching movies in the particular bin. We only keep movies released in the time period of News
Corp. ownership of a particular outlet. Figure 7b displays parallel evidence for Warner Bros. movies and Time Warner outlets. The
sample only contains movies with an average review score in the range of 30 to 80. For additional information on how the data is
generated see text.

29

Figure 8a-b. Selective coverage -- Probability of review by movie quality,
Comparison to other media

Notes: Figure 8a depicts the sensitivity of the review probability of 20th Century Fox movies to the average review score for all outlets
owned by News Corp. as well as for 200 control outlets (selected as those with the highest number of reviews). Sensitivity is measured
as the slope coefficient of a linear regression of the review probability on the average review score of a movie. The y-axis shows the
sensitivity in a particular outlet while the x-axis measures the sensitivity in the 10 outlet matches determined as for Figure 7. A
positive (negative) sensitivity measure indicates that the review probability is increasing (decreasing) in the average movie review
score. Additionally, the graph contains a linear fit. Dots above the line indicate that the likelihood of a particular outlet reviewing a
20th Century Fox movie increases more strongly in the average review score relative to its outlet matches. Figure 8b shows parallel
evidence for Warner Bros. movies and Time Warner outlets.

30

Figures 9a-9b. Conflict of Interest in Rotten Tomatoes (Newscorp 2006-09)

Notes: Figure 9a reports a local polynomial regression with Epanechnikov kernel with a bandwidth of 5 and a 1st degree polynomial of
an indicator for ‘freshness’ rating of a movie in Rotten Tomatoes on the corresponding movie review score. The sample includes the
period in which Rotten Tomatoes is owned by News Corp. (2006-09, continuous lines) and the remaining period (dotted lines), and
plots separate regressions for 20th Century Fox movies (dark blue lines) and movie matches (light blue lines). Figure 9b reports the
estimated coefficients from an event study regression of the freshness score in Rotten Tomatoes on the quantitative score and year
fixed effects interacted with an indicator for a 20th Century Fox movie (dark blue lines) and year fixed effects interacted with an
indicator for movie matches (light blue lines).

31

Table 1. Data set Formation, Example

Notes: Table 1 shows the construction of the main sample. For every movie distributed by a News Corp. studio (for simplicity called
20th Century Fox) or Time Warner studio (for simplicity called Warner Bros.) which is covered by at least one of the three datasets
Netflix, Flixster, or MovieLens the ten best movie matches are determined as those with the minimum distance in individual user
ratings. This data provides movie groups consisting of a particular 20th Century Fox or Warner Bros. movie and its 10 best matches.
The information is combined with the movie reviews provided by MetaCritic and Rotten Tomatoes. The resulting movie-media groups
contain all reviews of movies in a certain movie group by a particular outlet. The upper part of Table 1 illustrates this formation for
the example of the comedy movie “Black Knight” by 20th Century Fox. Gray color indicates that an outlet, in this case New York Post,
belongs to the same conglomerate. Darker gray color indicates that a certain review is at conflict of interest. The lower part of Table 1
shows the equivalent for the comedy movie “Scooby-Doo” by Warner Bros. Note that a certain movie can be a match to several
movies, and thus its reviews can be appear more than once in the main sample, as is the case for the comedy movie “102 Dalmatians”
by Walt Disney.

32

TABLE 2
THE EFFECT OF CONFLICT OF INTEREST ON MOVIE REVIEWS: AVERAGE BIAS
Specification:
Panel A. Dep. Var.: 0-100 Score for Movie
Indicator for Fox Movie on News Corp.-Owned Outlet
(Measure of Conflict of Interest for News Corp.)
Indicator for 20th Century Fox Movie

(1)
-0.1288
[1.1166]
-0.4033
[1.0131]
-4.3446***
[0.6234]

Indicator for Media Outlet Owned by News Corp.

OLS Regressions
(2)
(3)

Indicator for Warner Bros. Movie on TW-Owned Outlet
(Measure of Conflict of Interest for Time Warner)
Indicator for Warner Brothers Movie
Indicator for Media Outlet Owned by Time Warner

-0.4368
[0.9468]
-0.8251
[0.9017]
2.5421***
[0.5382]

-0.0188
[0.8762]
-0.6220
[0.4413]
-26.2505***
[5.6107]

0
685
450699

0.47
685
450699

-0.0068
[0.0216]
-0.0227
[0.0179]
0.0103
[0.0133]

-0.0113
[0.0227]
-0.0188**
[0.0093]
-0.5340***
[0.1026]

0
642
435242

0.38
642
435242

X

Movie-Media Group Fixed Effects
R2
Number of reviews at conflict of interest
N (number of reviews)

(4)

-0.1898
[1.0596]
-0.7560
[0.5297]
0.3348
[1.2639]

0
421
291124

0.45
421
291124

0.0330
[0.0277]
-0.0005
[0.0215]
-0.0790***
[0.0149]

0.0156
[0.0286]
-0.0138
[0.0115]
0.0304
[0.0520]

X

Panel B. Dep. Var.: Freshness Score
Indicator for Fox Movie on News Corp.-Owned Outlet
(Measure of Conflict of Interest for News Corp.)
Indicator for 20th Century Fox Movie
Indicator for Media Outlet Owned by News Corp.
Indicator for Warner Bros. Movie on TW-Owned Outlet
(Measure of Conflict of Interest for Time Warner)
Indicator for Warner Brothers Movie
Indicator for Media Outlet Owned by Time Warner
X

Movie-Media Group Fixed Effects
R2
Number of reviews at conflict of interest
N (number of reviews)

0
360
280797

0.37
360
280797

X

Notes: An observation is a movie review by a media outlet from 1985 to 2010. The dependent variable is a movie review converted on the 0-100 scale devised by metacritic.com . The
standard errors are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

33

TABLE 3
THE EFFECT OF CONFLICT OF INTEREST ON MOVIE REVIEWS: ROBUSTNESS
Specification:
Dep. Var.:

OLS Regressions
Movie Review on a 0-100 Scale for Movie m in Media Outlet o
(3)
(4)
(5)
(6)
(7)

(1)

(2)

Panel A. Newscorp. Media
Indicator for Fox Movie on News Corp. Outlet
(Measure of Conflict of Interest for News Corp.)

-0.1898
[1.0596]

-0.1898
[0.8868]

-0.1898
[1.0230]

0.713
[1.0134]

0.3875
[1.1291]

-0.3810
[1.2089]

R2
Number of reviews at conflict of interest
N (number of reviews)

0.45
421
291124

0.45
421
291124

0.45
421
291124

0.6
421
291124

0.39
300
72610

Panel B. Time Warner Media
Indicator for Warner Bros. Movie on TW Outlet
(Measure of Conflict of Interest Time Warner)

-0.0188
[0.8762]

-0.0188
[0.5170]

-0.0188
[0.4886]

-0.0558
[0.8233]

0.47
685
450699

0.47
685
450699

0.47
685
450699

X

X

X

R2
Number of reviews at conflict of interest
N (number of reviews)
Control Variables:
Movie-Media Group Fixed Effects
Movie Fixed Effects
Robustness Check:

Specification:

Standard Errors

Benchmar
k

Cluster by Cluster by
Studio
Media

(8)

(9)

0.1913
[1.3622]

0.2261
[1.1532]

-0.5384
[1.2192]

0.46
350
239994

0.64
411
106941

0.45
420
278433

0.55
460
163993

0.4248
[0.8739]

-0.0184
[1.0742]

0.6316
[1.0787]

0.8640
[0.9181]

0.6458
[1.0126]

0.6
685
450699

0.42
594
115940

0.48
485
359201

0.64
657
163937

0.46
685
413953

0.56
711
237182

X
X
Extra
Controls

X

X

X

X

X

Extra
Controls

Sample
MetaCritic
Sample
Only

Rotten
Tomatoes
Sample
Only

Matching Procedure
Match Uses
Match Does
3 (not 10) Match Uses Not Use Year
Best
Correlation and Ratings
Matches in Reviews
No.

Notes: An observation is a movie review by a media outlet from 1985 to 2010. The dependent variable is a movie review converted on the 0-100 scale devised by metacritic.com . The standard errors are clustered by movie unless stated otherwise. In Columns
(2)-(3) robustness to alternative ways of clustering is tested. In Column (4) movie fixed effects are added to the regression as additional controls. In column (5)-(6) only reviews either of the Metacritic or the Rotten Tomatoes dataset are included. Column (7)
uses three compared to the 10 best movie matches as control movies. In Column (8) movie matches are determined based on the correlation of the individual user ratings compared to the minimum distance measure in the benchmark specification. Restrictions
on potential matches explained in Section 2.2. are applied in determining the movie matches. In column (9) we do not restrict the set of potential movie matches based on the closeness in the release year and number of user ratings as explained in section 2.2.
* significant at 10%; ** significant at 5%; *** significant at 1%

34

TABLE 4
THE EFFECT OF CONFLICT OF INTEREST ON MOVIE REVIEWS: CROSS-SECTIONAL ESTIMATES
OLS Regressions
Movie Review on a 0-100 Scale for Movie m in Media Outlet o
(1)
(2)
(3)
(4)
(5)

Specification:
Dependent Variable:
Panel A. News Corp.
Indicator for Fox Movie on News Corp.-Owned Outlet
(Measure of Conflict of Interest for News Corp.)
Indicator for 20th Century Fox Movie
Indicator for Media Outlet Owned by News Corp.
R2
Number of Reviews at Conflict of Interest
N
Panel B. Time Warner
Indicator for Warner Bros. Movie on TW-Owned Outlet
(Measure of Conflict of Interest Time Warner)
Indicator for Warner Brothers Movie
Indicator for Media Outlet Owned by Time Warner
R2
Number of Reviews at Conflict of Interest
N
Control Variables:
Movie Fixed Effects
Media Outlet Fixed Effects
Sample:
Include only movies with at least one review by an outlet at potential
conflict of interest
Exclude Fox/TW movies not in Filixter/Netflix/MovieLens data set
Exclude movies that are never matches to a Fox/TW movie

1.2906
[0.9450]
-2.4572***
[0.7556]
-4.4576***
[0.2357]
0
620
469252
-0.9727
[0.7597]
-2.9171***
[0.6546]
3.5985***
[0.2688]
0
842
469252

2.0460***
[0.7410]

2.0720***
[0.7382]

1.8516**
[0.8741]

0.618
[0.9372]

-1.7134***
[0.4544]
0.45
620
469252

-1.5201***
[0.4567]
0.45
620
408695

-1.5688***
[0.4602]
0.45
421
401595

-1.2759*
[0.7293]
0.46
421
154572

-0.4512
[0.6606]

-0.4515
[0.6563]

-0.8342
[0.7209]

0.0866
[0.7864]

1.6477
[1.4247]
0.45
842
469252

0.2341
[1.7685]
0.45
842
369490

0.217
[1.8088]
0.45
685
361575

-11.3558***
[1.1743]
0.46
685
185262

X
X

X
X

X
X

X
X

X

X

X

X

X
X

Notes: An observation is a movie review by a media outlet from 1985 to July 2011. The dependent variable is a movie review converted on the 0-100 scale devised by metacritic.com . The standard errors are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

35

TABLE 5
CONFLICT OF INTEREST AND OMISSION BIAS: PROBABILITY OF REVIEW
Specification:
Dependent Variable:

OLS Regressions
Indicator variable for review of a movie m by outlet o
News Corp. Conflict of Interest
Time Warner Conflict of Interest
(1)
(2)
(3)
(4)

Indicator for Conflict of Interest *
Average Movie Rating
Distributed by Conglomerate*
Average Movie Rating
Media Owned by Conglomerate*
Average Movie Rating
Indicator for Conflict of Interest

-0.00026
[0.00069]
-0.00033
[0.00074]
-0.00009
[0.00033]
0.01137
[0.03947]
0.02843
[0.04327]
0.0064
[0.01911]
0.00412***
[0.00037]

Distributed by Conglomerate
Media Owned by Conglomerate
Average Movie Review Score
Control Variables:
Movie-Media Group Fixed Effects
Sample:
R2
Number of potential reviews at conflict of
interest
N

-0.00008
[0.00067]
-0.00065
[0.00058]
-0.00003
[0.00039]
0.00598
[0.03960]
0.05148
[0.03256]

0.00310***
[0.00033]

0.00011
[0.00068]
-0.00073
[0.00069]
0.00108***
[0.00037]
0.00583
[0.03774]
0.06177
[0.03833]
-0.05288**
[0.02122]
0.00565***
[0.00037]

0.00034
[0.00060]
-0.00080*
[0.00043]
0.00041
[0.00043]
-0.00294
[0.03330]
0.07236***
[0.02410]

0.00413***
[0.00033]

X
X
Potential review in featured media and in each of 10 matched media, with
match based on minimum distance in probability of review.
0.01

0.55

0.03

0.48

1142
120692

1142
120692

2020
234388

2020
234388

Notes: Each column is a separate regression including as observations potential movie reviews by the featured media outlets, or by any of 10 matched media, with match based
on minimum distance in the probability of review as described in Figure 7. The sample only includes years in which the media featured in the relevant column are owned by
News Corp. or Time Warner. The average score is computed as the average 0-100 score for a movie from all media outlets. All specifications include fixed effects for the moviemedia group. The standard errors are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

36

TABLE 6
BIAS IN REVIEW AGGREGATORS: EFFECT OF NEWSCORP. OWNERSHIP OF ROTTEN TOMATOES
Specification:
Depedent Variable:
(1)
Indicator for 20th Century Fox Movie *
(RottenTomatoes owned by Newscorp.: 2006-09)
Indicator for 20th Century Fox Movie
0-100 Review Score

0.00315
[0.00832]
-0.00204
[0.00436]
0.0188***
[0.000140]

OLS Regressions
RottenTomatoes 0-1 "Freshness" indicator
(2)
(3)
(4)
-0.00816
[0.00685]
-0.00638*
[0.00372]
0.0183***
[0.0000535]

0.000352
[0.00822]
-0.00579
[0.00477]
0.0409***
[0.000131]

-0.0572
[0.0352]
-0.0474**
[0.0184]

Sample:
R2
N

-0.00338
[0.0183]
-0.0271**
[0.0106]

0.0173***
[0.0000928]

0-100 MetaCritic Review Score
Control Variables:
Year Fixed Effects
Media Outlet Fixed Effects
Movia-Media Group Fixed Effects

(5)

X

X
X

X
X

X
X

X
X

X
All Reviews,
Only Reviews
Matching Group All Reviews
with
Sample
Scored in RT 50<=Score<=70 Only Reviews Unscored in RT
0.74
295400

0.65
397420

0.59
153229

0.05
97940

0.56
28225

Notes: An observation is a movie review from 1985 to July 2011. Column (1) uses the FOX sample of the matching dataset while column (2)-(5) use the full Metacritic/ Rotten Tomatoes data set. The
dependent variable is an indicator variable for 'freshness' of a movie according to review in Rotten Tomatoes. The key indepedendent variables are indicators for movies distributed by 20th Century Fox and an
interaction of this indicator with the years in which Rotten Tomatoes is owned by News Corp. (2006-09). The standard errors are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

37

Sample

Media Outlet

APPENDIX TABLE 1, PANEL A
SUMMARY STATISTICS: MEDIA SOURCES OF MOVIE REVIEWS
Score Variable
Fresh Indicator
Data Source (MC Score (0No. Reviews
100)/ MC Fresh Ind. - RT
Most Common Reviewers
No. Reviews
No. Reviews
No. Reviews
Usual Rating
While Owned
Score (0-100)/ RT Fresh
(Reviews Score (0-100)/ Reviews
While Owned
Owner
While Not
While Not
System
(At Conflict of
Ind. - Both Score (0-100)/ (At Conflict of
Fresh Ind.)
Owned
Owned
Interest)
Both Fresh Ind.)
Interest)

Media Type

Years

335 media

1985-2010

Varies
News Corp.
from '08 to '10
News Corp.
until 1986
News Corp.
from 1993
News Corp.
News Corp.

News Corp.

All Reviews

News Corp.

Beliefnet

Website

1994-2010

News Corp.

Chicago Sun-Times

Newsp.

1985-2010

News Corp.

New York Post

Newsp.

1989-2010

News Corp.
News Corp.

News Of The World
Sunday Times

Newsp. (UK)
Newsp. (UK)

1985-2010
1985-2009

News Corp.

TV Guide

News Corp.

Times

News Corp.

Wall Street Journal

News Corp.

Weekly

1985-2009

Newsp. (UK)

1985-2010

Newsp.

1985-2010

Other Reviews

327 media

Time Warner

All Reviews

Time Warner

Cinematical

Time Warner
Time Warner

CNN.com
Entertainment Weekly

Time Warner

Time

Time Warner

Other Reviews

Varies

A to F (+/allowed)
0 to 4 stars (1/2
allowed)
0 to 4 stars (1/2
allowed)
1 to 5 stars
0 to 5 stars (1/2
allowed)
New Corp. 1988- 0 to 4 stars (1/2
99
allowed)
News Corp.
0 to 5 stars
Qualitative

1985-2010

News Corp.
from 2008
-

335 media

1985-2010

Varies

Varies

Website

2004-2010

Website/Radio
Weekly

1996-2007
1990-2010

Weekly

1990-2010

0 to 5 stars (1/2
allowed)
Qualitative
A to F (+/allowed)
Qualitative

331 media

1985-2010

Time Warner
until 2009
Time Warner
Time Warner
from 1990
Time Warner
from 1990
-

Varies

Varies

75326/49208 270147/280797 54349/49208
0/0 - 302/289 - 0/0

4058 (421)

287066

3410 (360)

277387

241 (21)

61

230 (21)

59

Nell Minow (302/289)

2176/1622 - 2436/1930 2103/1622
2168/1990 - 2159/2088 2085/1990
0/0 - 87/84 - 0/0
0/0 - 206/162 - 0/0

67 (13)

2442

54 (13)

1876

Roger Ebert (2281/1706)

2241 (218)

1

2088 (211)

-

87 (8)
206 (27)

-

84 (8)
162 (27)

-

Lou Lumenick (1087/1029), Kyle
Smith (485/477)
Robbie Collin (87/84)
Shannon J. Harvey (156/117)

2632/1855 - 2015/1897 1969/1855
0/0 - 437/495 - 0/0

588 (78)

2090

129 (21)

1768

437 (40)

-

495 (45)

-

1197/328 - 345/336 345/328
67153/43413 262160/273516 47847/43413
118538/76549 417346/435242 85185/76549
0/0 - 584/689 - 0/0

191 (16)

1006

168 (14)

168

-

281466

-

273516

6168 (685)

444531

5461 (642)

429781

575 (61)

9

676 (76)

13

42 (5)
4302 (463)

-

929 (120)
3240 (349)

-

1249 (156)

-

616 (97)

-

-

444522

-

429768

0/0 - 42/929 - 0/0
4171/3140 - 3445/3240 3314/3140
1249/474 - 507/616 507/474
113118/72935 412768/429768 81364/72935

Notes: The sources of the movie review data are www.metacritic.com (abbreviated MC) and www.rottentomatoes.com (abbreviated RT). The data covers reviews available from 1985 until 2010. See text for additional information.

38

Maitland McDonagh (1388/1104),
Ken Fox (473/405)
Wendy Ide (132/159), James
Christopher (185/222)
Joe Morgenstern (1045/282)

James Rocchi (127/159), Scott
Weinberg (123/122)
Paul Clinton (0/596)
Owen Gleiberman (2038/1483),
Lisa Schwarzbaum (1626/1318)
Richard Corliss (654/328), Richard
Schickel (568/269)

APPENDIX TABLE 1, PANEL B
SUMMARY STATISTICS: STUDIOS
Sample
News Corp.
News Corp.
News Corp.
News Corp.
Time Warner
Time Warner

Distributor of Movie
(Studio)
All Studios
20th Century Fox
Fox Searchlight
Other Studios
All Studios
Warner Bros.

Studio Type
Varies
Major
Independent
Varies
Varies
Major

1990-2010

Time Warner

Fine Line

Independent

1991-2005

Time Warner

HBO

Other

1997-2003

Time Warner

New Line

Independent

1992-2008

Time Warner

Picturehouse

Independent

2005-2008

Time Warner
Time Warner

Warner Independent
Warner Home Video

Independent
Other

2004-2006
1994-1999

Time Warner

Other Studios

Varies

1985-2010

Years
1985-2010
1985-2010
1995-2010
1985-2010

Owner
Varies
News Corp.
News Corp.
Varies
Time Warner
from 1989
Time Warner
from 1989
Time Warner
from 1989
Time Warner
from 1996
Time Warner
from 1989
Time Warner
Time Warner
from 1989
-

No. of Reviews (Score 0100/ Fresh Ind.)
291124/280797
21080/20500
8020/8221
262024/252076
450699/435242
30195/30808

No. of Movies (Score 0100/ Fresh Ind.)
1593/1278
236/189
72/61
1285/1028
1847/1532
288/243

2474/1968

33/20

76/30

3/1

12135/12431

114/98

892/998

8/8

1444/1591
63/149

11/11
2/4

403420/387267

1388/1147

Notes: The sources of the movie review data are www.metacritic.com (abbreviated MC) and www.rottentomatoes.com (abbreviated RT). The data covers reviews available from 1985 until 2010. See text for additional information.

39

Appendix Figure 1a-b. Bias by Journalist: News Corp.-owned outlets (1a) and Time
Warner-owned outlets (1b)

Notes: Appendix Figure 1a displays the average review score (on a 0 to 100 scale) of 20th Century Fox movies against the average
review score of the associated movie matches for News Corp. journalists and journalists not employed at a News Corp. outlet. Colors
indicate whether a particular journalist is employed at a News Corp. outlet or is one of the other 500 journalists with the most reviews.
News Corp. journalists with a number of reviews of 20th Century Fox movies less than 15 are excluded. Appendix Figure 1b displays
the parallel evidence for journalists employed at a Time Warner outlet and Warner Bros. movies.

40

Online Appendix Figures 1a-1f. Documenting the Quality of Movie Matches: Micro-level
Comparison
Online Appendix Figure 1a-b. Similarity to Match: Movie Genre

Online Appendix Figure 1c-d. Similarity to Match: MPAA Rating

Online Appendix Figure 1e-f. Similarity to Match: Theaters at Openings

Notes: Online Appendix Figures 1a-b display the fraction of movie matches in a particular genre conditional on the genre of the associated movie
distributed by 20th Century Fox or Warner Bros. Online Appendix Figures 1c-d display the fraction of movie matches with a particular MPAA
rating conditional on the MPAA rating of the associated movie distributed by 20th Century Fox or Time Warner. Online Appendix Figures 1e-f
report local polynomial regressions with Epanechnikov kernel with bandwidth of 250 and 1st degree polynomial of the number of theaters at
opening of movie matches on the number of theaters at opening of associated movies distributed by 20th Century Fox or Warner Bros.

Online Appendix Figures 2a-d. Documenting Quality of Movie Matches on Outcomes: 0100 Review Score

Notes: Online Appendix Figure 2a displays the fraction of movies in the quintiles of the average review score from critical review for 20th
Century Fox movies, the associated movie matches, and movies which are not matches. For the purpose of assigning movies to a particular
quintile, 5-year bins are formed and the quintile of a particular movie is determined within a bin. Online Appendix Figure 2b presents the parallel
evidence for the Warner Bros. movies. Online Appendix Figure 2c reports a local polynomial regression with Epanechnikov kernel with a
bandwidth of 5 and 1st degree polynomial of the average review score of movie matches on the average review score of the associated 20th
Century Fox movies. Online Appendix Figure 2d displays the same relationship for Warner Bros. movies.

Online Appendix Figures 3a-d. Documenting Quality of Movie Matches on Outcomes:
Probability of Review

Notes: Online Appendix Figure 3a displays the fraction of movies in the quintiles of the review probability for the movies by 20th Century Fox,
the associated movie matches, and movies which are not matches. For the purpose of assigning movies to a particular quintile, 5-year bins are
formed and the quintile of a particular movie is determined within a bin. Online Appendix Figure 3b presents the parallel evidence for the Warner
Bros. movies. Online Appendix Figure 3c reports a local polynomial regression with Epanechnikov kernel with bandwidth of 0.05 and 1st degree
polynomial of the review probability of movie matches on the review probability of the associated 20th Century Fox movies. Online Appendix
Figure 3d displays the same relationship for Warner Bros. movies.

Online Appendix Figure 4a-d. Selective coverage -- Probability of review by movie quality:
News Corp. outlets

Notes: Online Appendix Figures 4a-d segregates the evidence of Figure 7a for News Corp. outlets. Outlets with less than 50 potential movies to
review are not included.

Online Appendix Figure 5a-d. Selective coverage -- Probability of review by movie quality:
Time Warner outlets

Notes: Online Appendix Figures 5a-d segregates the evidence of Figure 7b for Time Warner outlets.

.Online

Appendix Figure 6a-c. Selective coverage for Time magazine, Placeboes

.Online

Appendix Figure 6a-b. Period of Time Warner Ownership (6a) and pre-period (6b)

.Online

Appendix Figure 6c. Probability of Review of 20th Century Fox movies

Notes: Online Appendix Figure 6 presents a placebo test for potential omission bias in the Time Warner outlet Time. Online Appendix Figure 6a
reproduces the evidence in Online Appendix Figure 5d. Online Appendix Figure 6b shows a placebo test for the period before 1990 in which the
Time Warner conglomerate has not been established. For this purpose, movie matches are determined for movies distributed by studios which
merged or were acquired by the Time Warner conglomerate at the time of establishment. For simplicity these movies are labeled as TW. Figure
6c shows a placebo test of omission bias by Time of 20th Century Fox movies during ownership.

Online Appendix Table 1. Documenting the Netflix, Flixter data

Notes: Online Appendix Table 1 reports summary statistics for the three user rating datasets Flixster, MovieLens, and Netflix. Only movies are kept which can be identified with a movie title.
Furthermore, for the MovieLens and Netflix datasets for which information on the release year of the movie is available, we only keep movies for which this information is provided.

ONLINE APPENDIX TABLE 2
THE EFFECT OF CONFLICT OF INTEREST ON MOVIE REVIEWS: ADDITIONAL ROBUSTNESS
Specification:
Dependent Variable:
(1)
Panel A. Newscorp. Media
Indicator for Fox Movie on News Corp. Outlet
(Measure of Conflict of Interest for News Corp.)

OLS Regressions
Movie Review on a 0-100 Scale for Movie m in Media Outlet o
(2)
(3)
(4)

(5)

-0.1898
[1.0596]

0.4393
[1.2296]

0.4966
[1.1706]

0.8704
[1.4028]

-0.0394
[1.0478]

R2
Number of reviews at conflict of interest
N (number of reviews)

0.45
421
291124

0.49
233
169575

0.42
358
253726

0.55
189
129111

0.39
514
322808

Panel B. Time Warner Media
Indicator for Warner Bros. Movie on TW Outlet
(Measure of Conflict of Interest Time Warner)

-0.0188
[0.8762]

-0.8084
[1.1111]

0.8813
[1.0275]

-1.3899
[1.1943]

0.6058
[0.8355]

0.47
685
450699

0.51
433
289958

0.41
567
376283

0.54
349
225849

0.4
772
490668

X

X

X

X

X

R2
Number of reviews at conflict of interest
N (number of reviews)
Control Variables:
Movie-Media Group Fixed Effects

Robustness Check:

Benchmark

Match Uses
Match Uses Only Match Uses Only Match Uses Only Likelihood Ratio
Netflix Data
Flixter Data
MovieLens Data
Method

Notes: An observation is a movie review by a media outlet from 1985 to 2010. The dependent variable is a movie review converted on the 0-100 scale devised by metacritic.com . The standard errors are clustered by movie.
Columns (2)-(4) only use one of the three user rating datasets to determine the ten best movie matches of 20th Century Fox or Warner Bros. movies. In column (5) movie matches are determined for each of the three user rating
datasets based on a probability measure: For each potential movie match M and 20th Century Fox or Warner Bros. movie F, we calculate the probability of rating M condititional on rating F as P(M|F), as well as the unconditional
rating probability P(M) . For each F we select the ten movies with the highest value of P(M|F)/P(M) as movie matches. We apply the constraints on the matching procedure explained in Section 2.2, but do not restrict the sample of
potential movie matches on those with at least 40 common user ratings. Compared to the baseline scenario this mathing procedure does not take into account the closeness of ratings but the probability of rating.
* significant at 10%; ** significant at 5%; *** significant at 1%

ONLINE APPENDIX TABLE 3
CONFLICT OF INTEREST IN MOVIE REVIEWS: EVIDENCE ON CORRELATED TASTES
Specification:
Dependent Variable:
(1)
Panel A. News Corp.
Indicator for News Corp.-Owned Outlet
Indicator for News Corp.-Owned Outlet *
Movie Match to a 20th Century Fox Movie
Indicator for News Corp.-Owned Outlet *
Predicted Prob. Of Being a 20th Century Fox Movie Based on
Characteristic (Standardized)
R2
First Stage Chi 2
N (number of reviews)
Panel B. Time Warner
Indicator for Time Warner-Owned Outlet
Indicator for Time Warner-Owned Outlet *
Movie Match to a Warner Bros. Movie
Indicator for Time Warner-Owned Outlet *
Predicted Prob. Of Being a Warner Bros. Movie Based on
Characteristic (Standardized)
R2
First Stage Chi 2
N (number of reviews)
Sample:
Proxy Used and Controls:
Characteristic of Movie Used to Predict Probability of Being a
20th Century Fox (Warner Bros.) Movie
Movie and Media Fixed Effects

-2.1225***
[0.4972]
1.5952***
[0.4680]

0.45
429994
2.2712
[1.4649]
-1.4856***
[0.4882]

OLS Regressions
Movie Review on a 0-100 Scale for Movie m in Media Outlet o
(2)
(3)
(4)

(5)

-2.0614***
[0.5158]

-1.6554***
[0.4968]

-2.0787***
[0.6664]

-1.8792***
[0.5135]

0.4868**
[0.2251]

-0.1505
[0.2178]

-0.1873
[0.3137]

0.2459
[0.2169]

0.45
147.31
351293

0.45
60.53
378975

0.46
17.51
224816

0.45
151.05
358940

1.0276
[1.5769]

1.7354
[1.5121]

0.2018
[2.0935]

0.4371
[1.5784]

-0.5626**
[0.2264]

-0.5647**
[0.2271]

-0.0197
[0.3297]

0.1692
[0.2409]

0.45

0.45
0.45
0.46
0.45
104.74
29.31
100.64
338.48
409096
332649
358257
210258
340145
Excludes Movies at Conflict of Interest (20th Century Fox movies in Panel A and Warner Bros. movies in
Panel B)

X

Genre

MPAA Rating

X

X

Decile of Budget of
Production
X

Decile of No. of
Theaters at Opening
X

Notes: An observation is a movie review by a media outlet from 1985 to 2010. In column (1) a 0-1 indicator for whether a movie is a match to a 20th Century Fox or Warner Bros. movie is interacted with the dummy indicating News Corp. or Time Warner
ownership. In columns (2)-(5) the ownership variable is interacted with a probability measure of being a 20th Century Fox or Warner Bros. movie. This measure is obtained after predicting from a probit regression and standardized by subtracting the mean and
dividing by the standard deviation. In columns (4)-(5) the probability is estimated from a probit regression of an indicator for a 20th Century Fox or Warner Bros. movie on the decile of the budget of production and the number of theaters at opening as a
categorical variable. Deciles are determined within 5-year intervals. In columns (2)-(3) the probability is estimated using the categories for genre and MPAA Rating respectively. Standard errors are clustered at the movie level.
* significant at 10%; ** significant at 5%; *** significant at 1%

ONLINE APPENDIX TABLE 4
CONFLICT OF INTEREST IN MOVIE REVIEWS: COMPARATIVE STATICS ON RETURN TO BIAS
Specification:
Dependent Variable:
Panel A. News Corp.
Indicator for Fox Movie on News Corp.-Owned Outlet
(Measure of Conflict of Interest for News Corp.)
Indicator for Fox Movie on News Corp.-Owned Outlet *
Proxy for Higher Return to Biased Review
R2
Number of reviews at conflict of interest
N (number of reviews)
Panel B. Time Warner
Indicator for Warner Bros. Movie on TW Outlet
(Measure of Conflict of Interest Time Warner)
Indicator for Warner Bros. Movie on TW Outlet*
Proxy for Higher Return to Biased Review
Proxy Used and Controls:
Proxy for Higher Return to Biased Review
Movie-Media Group Fixed Effects
Interaction of Proxy with Fox Movie Indicator and with
Newscorp Outlet Dummy
R2
Number of reviews at conflict of interest
N (number of reviews)

OLS Regressions
Movie Review on a 0-100 Scale for Movie m in Media Outlet o
(1)
(2)
(3)
(4)
-1.1754
[2.0402]
1.4372
[2.3503]
0.45
421
291124

-0.4953
[2.2611]
0.2996
[0.3845]
0.45
308
231731

-2.4027
[2.0722]
0.3916
[0.3529]
0.45
410
282908

-3.1797
[2.2124]
0.5539
[0.3730]
0.45
416
285171

-0.6096
[1.2862]
[10.3605]
0.9219

-2.6253
[1.9628]
0.3941
[0.3088]

-0.4526
[1.6518]
0.1042
[0.2626]

-0.7714
[1.8568]
0.1568
[0.2824]

Indicator for Major Decile of Budget of
Decile of No. of
Decile of Domestic
Studio
Production
Theaters at Opening
Box Office
X

X

X

X

X

X

X

X

0.47
685
450699

0.47
508
362124

0.47
651
437617

0.47
664
438888

Notes: An observation is a movie review by a media outlet from 1985 to 2010. In column (1) in each movie group an indicator for whether the 20th Century Fox or Warner Bros. movie is distributed by a major studio is
interacted with the independent variables. In column (2)-(4) for each movie group the decile of the 20th Century Fox or Warner Bros. movie (on a 1-10 scale) is interacted with the independent variables. Deciles are
determined by grouping the 20th Century Fox or Time Warner movies in 5-year bins and calculating the deciles within each bin. Note that the indicator or decile is unique in each movie group, and thus drops out given the
movie-media group fixed effects. The standard errors are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

ONLINE APPENDIX TABLE 5
THE EFFECT OF CONFLICT OF INTEREST ON MOVIE REVIEWS: BY MEDIA
OLS Regressions
Movie Review on a 0-100 Scale for Movie m in Media Outlet o

Specification:
Dependent Variable:
Panel A.

Indicator for Conflict of Interest
Control Variables:
Movie-Media Group Fixed Effects
R2
Number of reviews at conflict of interest
N
Panel B.

Indicator for Conflict of Interest
Control Variables:
Movie-Media Group Fixed Effects
2
R
Number of reviews at conflict of interest
N

News Corp. Conflict of Interest
News of the
Wall Street
World
TV Guide Times (UK)
Journal
(3)
(4)
(5)
(6)
-6.1731
1.9354
0.8042
-4.9835
[5.2753]
[1.9623]
[3.5214]
[6.1281]

Chicago
SunTimes
(1)
1.1914
[11.8712]

New York
Post
(2)
0.9127
[1.3914]

X

X

X

X

X

0.73
13
796

0.45
218
243400

0.56
7
2146

0.51
73
24535

0.5
39
22372

Beliefnet
(7)
6.2866*
[3.3805]

Sunday
Times
(8)
-12.3594
[8.6897]

X

X

X

0.55
16
9741

0.43
21
11184

0.69
16
3129

Time Warner Conflict of Interest
Entertainme
CNN.com
nt Weekly
Time
Cinematical
(1)
(2)
(3)
(4)
0.2035
0.4245
-1.1355
-0.0143
[7.5661]
[1.0085]
[1.8649]
[3.1377]
X

X

X

X

0.48
2
553

0.47
463
446840

0.52
146
79944

0.53
60
30074

Notes: An observation is a movie review by a media outlet from 1985 to 2010. Each column is a separate regression including as observations only movies with at least one review by the featured outlet, and as independent
variables indicator variables for the outlet and for production by the conflicted distributing company (20th Century Fox and Warner Bros.). All specifications include fixed effects for the movie-media group.The standard
errors in parentheses are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

ONLINE APPENDIX TABLE 6
THE EFFECT OF CONFLICT OF INTEREST ON MOVIE REVIEWS: BY REVIEWER
OLS Regressions
Movie Review on a 0-100 Scale for Movie m in Media Outlet o
News Corp. Conflict of Interest

Specification:
Dependent Variable:
Panel A.

Lou Loumenick
(1)
Indicator for Conflict of Interest
Control Variables:
Movie-Media Group Fixed Effects
R2
Number of reviews at conflict of interest
N
Panel B.

Indicator for Conflict of Interest
Control Variables:
Movie-Media Group Fixed Effects
R2
Number of reviews at conflict of interest
N

1.8109
[1.9946]

New York Post
Jonathan
Kyle Smith
Foreman
(2)
(3)
0.339
[4.2489]

-3.8099
[4.3026]

Megan
Lehmann
(4)

TV Guide
Maitland
McDonagh
(5)

-0.368
[4.1527]

6.3402**
[2.9709]

Nell Minow
(6)

Times (UK)
James
Christopher
(7)

Wall Street
Journal
Joe
Morgenstern
(8)

6.2866*
[3.3805]

0.7005
[6.6586]

-4.5947
[6.4825]

X
0.64
18
6814

X
0.61
15
7794

Beliefnet

X

X

X

X

X

X

0.5
103
73641

0.51
46
24666

0.68
28
10115

0.68
20
8249

0.54
29
7818

0.43
21
11184

Time Warner Conflict of Interest
Entertainment Weekly
Time
Owen
Lisa
Richard
Gleiberman
Schwarzbaum Richard Corliss
Schickel
(1)
(2)
(3)
(4)
0.7818
[1.5304]

0.7173
[1.5697]

1.423
[2.6838]

-5.9921*
[3.4257]

X

X

X

X

0.55
225
117097

0.56
174
100662

0.56
74
33894

0.67
50
15064

Notes: An observation is a movie review by a journalist from 1985 to 2010. Each column is a separate regression including as observations only movies with at least one review by the featured journalist and as independent variables indicator variables for the outlet and for production by the
conflicted distributing company (20th Century Fox and Warner Bros.). Reviews by other journalist from the same conglomerate are taken out. All specifications include fixed effects for the movie-media group.The standard errors in parentheses are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

ONLINE APPENDIX TABLE 7
CONFLICT OF INTEREST AND OMISSION BIAS: BY MEDIA OUTLET
Specification:
Dependent Variable:
Panel A.

Conflict of Interest *
Average Rating
Conflict of Interest
Control Variables:
Movie-Media Group F.E.
Sample:
R2
Number of Fox movies in sample
N

Chicago
SunTimes
(1)
-0.02578***
[0.00857]
1.67750***
[0.49981]

CNN.com
(1)

Control Variables:
Movie-Media Group F.E.
Sample:
R2
Number of Warner Bros. movies in sa
N

Beliefnet
(7)
-0.00315
[0.00542]
0.17137
[0.29734]

Sunday Times
(8)
0.00048
[0.00107]
-0.01561
[0.05892]

X
X
X
X
X
X
X
X
Potential review in featured media and in 10 matched media (match based on minimum distance in review probability)
0.37
0.37
0.24
0.34
0.26
0.27
0.2
0.28
19
285
44
161
193
35
35
370
1045
32285
3036
16940
20537
2695
2684
41470

Panel B.

Conflict of Interest *
Average Rating
Conflict of Interest

New York Post
(2)
0.00186
[0.00124]
-0.10598
[0.07619]

OLS Regressions
Indicator variable for review of movie m by media outlet o
News Corp. Conflict of Interest
News of the
Wall Street
Journal
World
TV Guide
Times (UK)
(3)
(4)
(5)
(6)
-0.00164
-0.00041
-0.00232
-0.0013
[0.00375]
[0.00150]
[0.00207]
[0.00448]
0.12088
0.00573
0.13175
-0.01133
[0.21264]
[0.08316]
[0.11634]
[0.23296]

0.00088
[0.00129]
-0.03184
[0.07376]

Time Warner Conflict of Interest
Entertainment
Weekly
Time
(2)
(3)
-0.00097
[0.00072]
0.06471
[0.04185]

0.00239**
[0.00109]
-0.09498*
[0.05696]

Cinematical
(4)
-0.00426
[0.00288]
0.1907
[0.16413]

X
X
X
X
Potential review in featured media and in 10 matched media
(match based on minimum distance in review probability)
0.28
0.44
0.34
0.26
517
660
660
183
58916
78529
78529
18414

Notes: Each column is a separate regression including as observations potential movie reviews by the featured media outlet, or by any of 10 matched media, with match based on minimum distance in probability of reviews as described in Figure 7.
The sample only includes years in which the media featured in the relevant column is owned by News Corp. or Time Warner. The average score is computed as the average 0-100 score for a movie from all media outlets. The standard errors in
parentheses are clustered by movie.
* significant at 10%; ** significant at 5%; *** significant at 1%

