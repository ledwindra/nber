NBER WORKING PAPER SERIES

QUANTILE TREATMENT EFFECTS OF COLLEGE QUALITY ON EARNINGS:
EVIDENCE FROM ADMINISTRATIVE DATA IN TEXAS
Rodney J. Andrews
Jing Li
Michael F. Lovenheim
Working Paper 18068
http://www.nber.org/papers/w18068

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2012

We would like to thank John DiNardo, Nicole Fortin, Doug Almond, Mark Hoekstra, Jeff Smith, Trevon
Logan, and Lock Reynolds as well as seminar participants at the Institute for Research on Poverty
Summer Workshop, the NBER Summer Institute Education Workshop, the University of Rochester,
the IFS-STICERD Public Economics Seminar, the University of British Columbia, Ohio State University,
Emory University and the University of Texas at Arlington, the University of Texas at Dallas for helpful
comments and suggestions. We thank Priyanka Singh for excellent research assistance. Rodney Andrews
gratefully acknowledges the support of grants from both the Bill and Melinda Gates Foundation and
the Smith Richardson Foundation. This research was made possible through data provided by the University
of Texas at Dallas Education Research Center. The conclusions of this research do not necessarily
reflect the opinions or official position of the Texas Education Agency, the Texas Higher Education
Coordinating Board, or the State of Texas. The views expressed herein are those of the authors and
do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2012 by Rodney J. Andrews, Jing Li, and Michael F. Lovenheim. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

Quantile Treatment Effects of College Quality on Earnings: Evidence from Administrative
Data in Texas
Rodney J. Andrews, Jing Li, and Michael F. Lovenheim
NBER Working Paper No. 18068
May 2012
JEL No. I21,J24
ABSTRACT
This paper uses administrative data on schooling and earnings from Texas to estimate the effect of
college quality on the distribution of earnings. We proxy college quality using the college sector from
which students graduate and focus on identifying how graduating from UT-Austin, Texas A\&M or
a community college affects the distribution of earnings relative to graduating from a non-flagship
university in Texas. Our methodological approach uses the rich set of observable student academic
ability and background characteristics in the data to adjust the earnings distributions across college
sectors for the fact that college sector quality is correlated with factors that also affect earnings. Although
our mean earnings estimates are similar to previous work in this area, we find evidence of substantial
heterogeneity in the returns to college quality. At UT-Austin, the returns increase across the earnings
distribution, while at Texas A\&M they tend to decline with one's place in the distribution. For community
college graduates, the returns relative to non-flagship four-year graduates are negative across most
of the distribution of earnings, but they approach zero and become positive for higher earners. Our
data also allow us to estimate effects separately by race and ethnicity, and we find that historically
under-represented minorities experience the highest returns in the upper tails of the earnings distribution,
particularly among UT-Austin and community college graduates. While we focus on graduates, we
also show our estimates are robust to examining college attendees as well as to many other changes
in the sample and to the estimation strategy. Overall, these estimates provide the first direct evidence
of the extent of heterogeneity in the effect of college quality on subsequent earnings, and our estimates
point to the need to consider such heterogeneity in human capital models that incorporate college quality.

Rodney J. Andrews
7KHUniversity of Texas at Dallas
800 West Campbell Road
MS WT21
Richardson, TX 75080
and NBER
rodney.j.andrews@utdallas.edu
Jing Li
The University of Tulsa
800 South Tucker Drive
Chapman Hall Room 235
Tulsa, OK 74104
jing-li@utulsa.edu

Michael F. Lovenheim
Department of Policy Analysis and Management
Cornell University
135 Martha Van Rensselaer Hall
Ithaca, NY 14853
and NBER
mfl55@cornell.edu

1

Introduction

A growing body of work in economics seeks to identify the eﬀect of college quality on future
labor market outcomes. This literature is motivated by the large amount of heterogeneity in
college quality in the United States, both across the two-year, four-year and public, private
sectors, but also within each of these sectors. While the average return to college is high
and growing (Autor, Katz and Kearney, 2008), these returns may be going largely to those
students who attend a high-quality, elite postsecondary school. Because the opportunity cost
of attendance, in terms of tuition, fees, and forgone wages, are large, understanding how the
choices of college students along dimensions of postsecondary quality aﬀect future earnings is
of primary importance.
The previous literature on the returns to college quality have found evidence that students
who attend or graduate from higher quality schools earn more in the labor market.1 Black
and Smith (2004, 2006) use matching estimators on National Longitudinal Survey of Youth
data to show that students who attend schools with higher observed quality subsequently
earn more. Hoekstra (2009) exploits an admissions rule based on GPA and SAT scores at
a large ﬂagship state university. Using a regression discontinuity approach, he demonstrates
that students attending a state ﬂagship earn 24% more than those who do not. Due to data
limitations, however, he cannot specify a clear counterfactual because he does not observe
enrollment among those not admitted to the ﬂagship institution. Using longitudinal data from
three surveys conducted by the National Center for Education Statistics, Brewer, Eide and
Ehrenberg (1999) employ a selection on observables model and ﬁnd that students who attend
an elite public or private school earn 26-39% more than those who attend a bottom-ranked
public school.
Somewhat in contrast, Dale and Krueger (2002, 2011) employ a matching estimator that
compares earnings among students who got into or applied to the same set of schools but
who attended schools of diﬀerent quality. While they ﬁnd little evidence of an average eﬀect
of college quality on earnings when quality is proxied by average SAT scores, they do ﬁnd
evidence that students attending higher tuition schools earn more subsequently. Furthermore,
1 See

Hoxby (2009) for a review of this literature.

1

lower-income and minority students experience higher average returns to quality. This result is
suggestive that the average eﬀects estimated in previous work may not accurately characterize
the eﬀect of college quality on earnings for many students.
In this paper, we add to the previous literature by estimating how earnings premia of college
quality vary across the income distribution using unconditional quantile treatment eﬀect methods. This paper is the ﬁrst to identify the distribution, rather than the mean, of college quality
premia, which is important for several reasons. First, examining average returns to quality
may miss substantial heterogeneity across students in the eﬀect of college quality on earnings.
College tuition could exacerbate these diﬀerences, as tuition and fees at higher-quality schools
typically are higher than at low-quality schools.2 If earnings premia from college quality only
ﬂow to certain students, some students may actually be hurt by enrolling in a high-quality
university. Second, with large public subsidies for higher education, it is important to understand how higher education choice aﬀects the earnings distribution, not just average earnings.
If returns are heterogeneous, the desirability of public support for higher education may rest
on what types of students experience the largest returns and on what part of the earnings
distribution is shifted due to graduating from a more elite university. Third, identifying the
distribution of the eﬀect of college quality on earnings may suggest ineﬃciencies in the process
by which students are matched to postsecondary schools. Understanding the nature of any
mismatch is a ﬁrst step to identifying policies that can help induce students to make optimal
attendance decisions.
Previous work on the returns to college quality has focused solely on estimating average
(or local average) eﬀects due primarily to data limitations: surveys that contain suﬃcient
background information to control for selection of students into schools typically are too small
to be used to identify distributional impacts. In this paper, we use administrative data on all
male high school and public college graduates in Texas between 1996 and 2002 that are linked
to earnings data from unemployment insurance (UI) records in that state. While we focus on
graduates due to the fact that graduation is the salient feature of the postsecondary system
observed by employers, we also perform our analysis for college attendees and ﬁnd similar results
2 For low-income students, this relationship may not hold as many high-quality schools give very generous ﬁnancial aid packages
to lower-income students.

2

that lead to very similar conclusions. Overall, we observe 94,071 male graduates in our sample.
Because these men all attended high school in Texas, we are able to link them to their high
school records, which include standardized test scores, information about their academic track,
as well as the high school from which they graduated. This data set is unique in the size of the
sample and the richness of the background characteristics we observe about each individual.
Our methodological approach follows the unconditional quantile treatment eﬀects (QTE)
methods outlined in DiNardo, Fortin and Lemieux (1996) and Firpo (2007). DiNardo, Fortin
and Lemieux (1996) show that, if one has a set of observable characteristics with which to plausibly control for selection, one can construct counterfactual outcome distributions by reweighting
the control group earnings distribution by the log odds ratio of treatment generated from a
regression of the probability of treatment on the observables. As described in Firpo (2007), the
quantile treatment eﬀects3 can be estimated by taking the diﬀerence between the actual treated
distribution and the counterfactual untreated distribution at a given quantile. Identiﬁcation
of the QTE also requires a “rank permanence” assumption, which we argue is plausible in the
given context. Even without the rank permanence assumption, however, we still are able to
identify the eﬀect of college quality on the distribution of earnings, which is of high importance
for policy purposes in its own right.
We proxy for college quality by partitioning the Texas higher education system into four
groups: University of Texas at Austin (UT-Austin), Texas A&M University at College Station
(TAMU), all other four-year public universities, and all public two year colleges. The ﬁrst two
groups represent the two ﬂagship schools in the state of Texas, and we split them up because
UT-Austin is typically higher-ranked and because TAMU is highly focused on engineering
and agriculture. Examining these schools separately allows us to measure more precisely the
educational environments faced by students in the highest quality public schools in Texas. Fouryear public universities outside of UT-Austin and TAMU represent our control group, and we
also examine how community college graduates’ earnings compare to this control group.
Our estimates point to large amounts of heterogeneity in the returns to college quality. While
our mean estimates are similar to those from previous work, the quantile treatment eﬀects are
3 Firpo (2007) distinguishes between the “quantile treatment eﬀect,” which is the quantile analog to the average treatment eﬀect
and the “quantile treatment on the treated” that is the quantile analog to the average treatment eﬀect on the treated. We will use
the term quantile treatment eﬀect to refer to the quantile treatment eﬀect on the treated, as that is the parameter we are able to
identify.

3

suggestive that the means do not accurately characterize the returns for most students. For UTAustin graduates, the earnings premiums are mostly increasing across the earnings distribution,
from a low of 2.7% at the 9th percentile to a high of 31.7% at the 97th percentile. Among Texas
A&M graduates, there is less heterogeneity in returns. However, for these graduates the returns
decline across the earnings distribution, from a peak of 36.4% at the 1st percentile to 17.6%
at the 84th percentile. We present evidence that diﬀerences in college majors between UT and
TAMU graduates is a plausible explanation for the diﬀerences in returns experienced by these
students. For community college graduates, the returns are mostly negative and tend to increase
with one’s place in the earning’s distribution. Notably, for about 15% of the distribution, the
estimated returns to community college versus non-ﬂagship four-year graduation are close to
zero in magnitude and are not statistically diﬀerent from zero at the 5% level. Furthermore,
the estimated returns to community college graduation are under 5% in absolute value for the
upper third of the earnings distribution. Given the large cost diﬀerences between two-year and
four-year schools, these results suggest that community colleges may be optimal for a signiﬁcant
subset of students who are relatively high potential earners and who are choosing between a
less-selective four-year school and a community college.
We also examine the distribution of college quality returns separately by race and ethnicity.
This is among the ﬁrst evidence on the returns to college quality by race, because most data
sets used in previous work lack minority samples of suﬃcient size to estimate such parameters
with any precision.4 At Texas A&M and at UT-Austin, the heterogeneity in returns across
the earnings distribution is much larger for whites than for black, Hispanic or Asian students.
The returns are low for black and Hispanic students at UT-Austin across the majority of the
distribution but are universally large for these Texas A&M graduates. At community colleges,
we document a substantial earnings penalty for Asian graduates, while for black and Hispanic
students the returns are positive and sizable at the top of the earnings distribution. These
estimates indicate that for historically under-represented minority groups, the higher earners
at community colleges earn substantially more than their counterparts who graduated from a
non-ﬂagship public university. For these groups, the average earnings estimates do a poor job
4 The only other paper of which we are aware that examines returns to college quality by race and ethnicity is Dale and Krueger
(2011). They estimate average returns, rather than the distribution of returns, for these groups. They ﬁnd that African American
and Hispanic students experience higher returns to college quality than other students on average.

4

of describing the returns faced by a large proportion of students. Using the average treatment
eﬀect on the treated estimates for policy purposes, for example to justify inducing students to
attend (non-ﬂagship) four-year rather than two-year schools, may lead to reductions in earnings
for many of these students.
Our estimates show substantial heterogeneity in the returns to graduating from postsecondary institutions of diﬀerent quality, both overall and by racial/ethnic groups. These results
are suggestive that mean impacts do not accurately characterize the returns a given student
can expect to face when making decisions over colleges of diﬀering quality and point to the need
to understand how the variance of expected returns, rather than just the mean, aﬀect student
postsecondary attendance decisions across the quality spectrum.

2

Data

The data used in this study are derived from three sources: administrative data from the Texas
Education Agency (TEA), administrative data from the Texas Higher Education Coordinating
Board (THECB), and quarterly earnings data from the Texas Workforce Commission (TWC).
The data are housed at the Texas Schools Project, a University of Texas at Dallas Education
Research Center (ERC). The data from the TEA and THECB allow a researcher to potentially
follow a Texas student from Pre-Kindergarten through college. The data from the TWC are
unemployment insurance records and provide information on earnings for Texas residents who
work. We use a unique identiﬁer based on an individual’s social security number to link the
data from these three sources.
Because college quality is diﬃcult to measure with a single variable or set of variables (Black
and Smith, 2006), we follow much of the previous literature in proxying college quality by
college sector (Brewer, Eide and Ehrenberg, 1999; Hoekstra, 2009; Bound, Lovenheim and
Turner, 2010; Bound, Lovenheim and Turner, forthcoming; Lovenheim and Reynolds, 2011).
Due to data availability constraints, we focus only on public university graduates, and we
split them into four comprehensive and mutually exclusive sectors: UT-Austin, Texas A&M
at College Station,5 other four-year public universities (i.e., non-ﬂagship public universities)
5 Hereafter, we will refer to Texas A&M at College Station only as “Texas A&M” or “TAMU.” This university is to be distinguished from the other Texas A&M campuses, which are part of the the other four-year sector.

5

and community colleges. We examine UT-Austin and Texas A&M separately because they are
the ﬂagship universities of the State of Texas. Table 1 shows the observable characteristics of
the universities across these sectors. Both UT-Austin and Texas A&M have higher resources
and quality measures than the other four-year and community college sectors. They both have
much higher SAT scores and faculty-student ratios as well as spending per student that is twice
the amount spent in the non-ﬂagship universities. The two ﬂagship universities also graduate
over twice the proportion of students as the other four-year colleges. However, in-state tuition
(unadjusted for ﬁnancial aid) is about $1,000 more per year to attend the ﬂagship schools.
Community colleges are cheaper to attend than four-year schools as well, but they have far
fewer resources than the public four-year sector. Thus, our four sectors have large diﬀerences in
resources and measurable college quality associated with them, and they also deﬁne the relevant
college choices for most students in Texas due to the dominance of public universities in that
state.6
We focus on male graduates from Texas’ public colleges and universities who graduated from
high school during the years 1996–2002. The total sample size includes 94,071 male graduates,
with 9,837 graduates from the University of Texas at Austin, 13,436 graduates from Texas A&M
University-College Station, 47,935 graduates from Texas’s other four-year public colleges and
universities, and 22,863 graduates from Texas’s community colleges. We only include males in
the analysis because of the concern that many female college graduates are endogenously missing
from the sample due to fertility decisions. The sample includes males who meet the following
restrictions: 1) No missing data for any of the covariates, 2) The student must graduate before
the age of 25, 3) The graduate’s earnings for a given year are included only if he worked for four
consecutive quarters in the year, with the exception of 2009 where the requirement for inclusion
is three consecutive quarters as we only have three quarters of available earnings data for 2009,
and 4) The student must not be currently enrolled in graduate school when the earnings are
measured.7 These restrictions are meant to isolate the earnings of full-time working males, and
6 Unfortunately,

we do not have information about students who graduate from private universities. However, public postsecondary schools dominate the higher education market in Texas. In the National Longitudinal Study of 1988, only 9.6% of Texas
high school graduates who went to college attended a private college. In the National Longitudinal Survey of Youth 1997, 11.5%
of students attended a private college. Thus, our focus on public schools, while necessitated by the data, is appropriate given the
small proportion of students who enroll in private universities in Texas.
7 Students who earn a graduate degree are included. The fourth restriction ignores earnings while students are enrolled in
graduate school because they likely are not reﬂective of the student’s permanent earnings.

6

they are similar to the sample restrictions imposed by Hoekstra (2009).
We obtained records of each individual’s quarterly earnings from the TWC and examine
earnings data for the years 2007–2009. Because these students graduated from high school
between 1996 and 2002, they will be between 23 and 31 post-graduation when we observe
their earnings. Examining earnings of graduates in their early 20s may be problematic if
college quality increases the returns to experience. In such a circumstance, we will understate
the earnings of college graduates from higher-quality schools relative to lower-quality schools.
However, in Section 4.4 we estimate eﬀects for the older sample who graduated from high
school in 1996-1998. The results using this sample are similar to the estimates for the sample
as a whole, which is suggestive that the relative inexperience of our sample is not driving
our results. The use of data from 2007-2009 also is potentially problematic because of the
large increase in unemployment rates during this period in the U.S.. Since our data only
include full-time workers, the recession may cause us to miss many workers, and in particular
may cause us to overstate quality premiums to the extent that unemployment increases were
inversely proportional to college quality. However, the recession in Texas was relatively mild:
the average unemployment rate was 5.4% between 2004-2006 and was 5.6% between 2007-2009.
In contrast, for the U.S. as a whole, the unemployment rate increased from 5.1% to 6.6% across
these two periods. Furthermore, we show below that our results and conclusion are robust to
including all earnings observations, not just those from those employed full-time. This ﬁnding
suggests that recession-driven unemployment is not generating a misleading picture of earnings
distributions in Texas.
We observe more than one quarter of earnings for all sample members. In order to generate
one earnings estimate for each respondent, we stack log quarterly earnings observations (subject
to the inclusion criteria above) and regress them on year dummies, quarter-of-year dummies,
and a series of cohort dummies that indicate when an individual graduated from high school. We
use the within graduate average of the residuals from this regression as the earnings measure
in our empirical models. This method isolates the constant component of earnings for each
individual over the period for which we observe his earnings and allows us to control for timeand cohort-speciﬁc shocks as well as for seasonality.

7

The data from the TEA consists of both individual and high school level information. The
individual level data include variables such as race/ethnicity, an indicator for whether the
student has a college plan, participation in Title 1, whether the child receives free or reduced
price meals, and the scores from the 11th grade reading, writing, and mathematics sections
of the Texas Assessment of Academic Skills (TAAS). Examples of the high school level data
include enrollment, the ethnic composition of the school, and the percentage of the school that
participates in talented and gifted programs. We obtain graduation status and timing from the
THECB for each student as well.
The odd columns of Table 2 present summary statistics of individual characteristics for our
analysis sample, separately by school type. As expected, the UT-Austin and TAMU graduates
have higher high school test scores in every subject, and the community college students have
the lowest average high school test scores. The ﬂagship university graduates also are more likely
to be in the top 10th percentile of their school in each of these tests. The ﬂagship universities
have fewer black and Hispanic students than non-ﬂagship universities and community colleges,
and they also have a much smaller proportion of economically disadvantaged students. Overall,
Table 2 demonstrates that students attending these diﬀerent school types diﬀer on important
observable characteristics that are likely to aﬀect earnings. Our empirical strategy described
below seeks to eliminate the diﬀerences in the earnings distributions across sectors that are due
to the diﬀerences in these observable characteristics.
A main limitation of the data we use is the fact that individuals only are in our sample
if they graduated both from a Texas high school and a public Texas college. They also need
to have at least three quarters of complete earnings data in Texas, which could be a limiting
factor if students are in graduate school, if they leave the state or if they do not work. Because
both UT-Austin and Texas A&M have more of a national proﬁle than other universities in
Texas, if these graduates are more likely to take a job in another state or if they are more likely
to be attending graduate school, then our earnings distributions will be biased. Especially if
the most high-skilled students are those who leave the state, the Texas A&M and UT-Austin
earnings distributions will be biased downward. Furthermore, if college quality has an eﬀect on
the extensive margin of labor supply, it could create endogenous sample biases in our estimates.

8

Table 3 shows the characteristics of those included and excluded from our analysis sample
among graduates of each school type. Excluded observations are graduates for whom we never
observe full time work. As the table demonstrates, those excluded from the sample are very
similar to those included. Those who are in the top 10 percent of their high school class
in reading and writing are slightly more likely to be excluded, but the diﬀerence is only 3
percentage points and this diﬀerence is present in all school sectors. Even within school type
there are few diﬀerences in the observable characteristics of graduates included and excluded
from the sample, and comparing the ﬂagship and community college sectors to the non-ﬂagship
sector, there are no discernible diﬀerential patterns of exclusion. The fact that our sample is
balanced with respect to whether earnings are present is summarized with the mean of predicted
log earnings in Table 3. The predicted earnings are calculated by estimating a regression of
log earnings residuals on all observable characteristics, separately by sector. We then predict
log earnings using the resulting coeﬃcients for the samples with and without earnings in each
sector. As the estimates in Table 3 indicate, these means are extremely similar, which suggests
that the sample of men for which we observe earnings is not systematically diﬀerent from the
sample of men for which we do not observe earnings.
Finally, at the bottom of Table 3, we show the number and proportion of students included
and those excluded because they attend graduate school. While the proportion included declines
across the table (and thus with observable college quality), particularly within the four-year
sectors, the diﬀerences are not large. As the rest of the table shows, these diﬀerent inclusion
rates are uncorrelated with the rich set of observable characteristics in our data. The percentage
of students excluded due to graduate school attendance also is very similar for UT-Austin and
Texas A&M, and it actually is slightly higher in the non-ﬂagship sector.8 The sum total of
the evidence in Table 3 indicates that the sample restrictions we make are unlikely to create
systematic biases in our earnings distributions for each school type. Tabulations by race and
ethnicity, which are available upon request, show that observable characteristics among included
and excluded students by school type do not diﬀer substantially either for any of these groups.
The critical missing variable in Table 3 is earnings; because our earnings data only cover
8 This result may be due, in part, to the fact that we only observe graduate school attendance if it is within the state of Texas.
More graduates from non-ﬂagship universities who attend graduate schools probably do so in-state.

9

Texas residents, we are unable to determine whether students who move out of Texas after
graduating are higher (or lower) earners. This problem is particularly salient for the state
ﬂagships, where the most capable students may compete in a more lucrative national job
market. In order to generate some information on earners among those who stay in Texas
(and thus who are in our sample) and those who leave, we examine log earnings in the 2000 US
Census among BA recipients who report having lived in Texas ﬁve years prior and who would
have been of college age at the time (18-21). Panel A of Figure 1 shows the distribution of
earnings in 2000 among BA recipients who are 23-26 and who lived in the Austin, TX MSA
in 1995. The earnings distributions for those in Texas in 2000 versus those not in Texas in
2000 are virtually identical. Although there is a slight divergence at the top of the distribution,
earnings are higher among those currently residing in Texas. A similar pattern holds for 23-26
year old BA recipients who lived in the College Station, TX MSA in 1995 (Panel B). While outof-state workers earned more at the bottom 20% of the distribution,9 the rest of the earnings
distributions are very similar. We show below that the returns for Texas A&M are highest for
lower earners. Panel B of Figure 1 suggests we may understate these returns slightly because
we are unable to observe earnings from Texas A&M graduates who leave Texas. Finally, in
Panel C, the earnings distributions for those who were in other areas of Texas are the same
regardless of whether they currently live in Texas.10 Overall, Figure 1 presents little evidence of
systematic attrition by higher or lower earning students, which suggests our inability to observe
earnings for non-Texas-resident workers is not driving our results.

3

Methodology

The goal of this analysis is to estimate unconditional quantile treatment eﬀects of college quality on earnings. This method diﬀers from the conditional quantile treatment eﬀects literature
(Koenker and Bassett, 1978; Abadie, Angrist and Imbens, 2002; Chernozhukov and Hansen,
9 The diﬀerence at the bottom of the distribution could be due to the inclusion of Blinn College students. Blinn College is a
two-year school with a very high four-year transfer rate. If those students are lower earners and are more likely to remain in-state,
the presence of these students in this sample could cause a divergence in earnings at the bottom of the distribution.
10 We also do not ﬁnd evidence of diﬀerences in the likelihood of having any earnings in the Census by school type. For example,
the diﬀerence in the likelihood of having any earnings between UT Austin and other four-year graduates is -0.008 percentage points.
For Texas A&M, this diﬀerence is larger at about 4 percentage points, but this diﬀerence still is small relative to the large returns we
estimate for Texas A&M graduation. In addition, these diﬀerences are unadjusted for covariates, and if we were able to do control
for the observables in our administrative data, we suspect there would be even smaller diﬀerences in labor force participation by
school type.

10

2005) in the examination of treatment eﬀects for each quantile of the marginal earnings distributions rather than the quantiles conditional on the covariates. The conditional quantiles are
more diﬃcult to interpret for policy purposes because they are unobserved, and thus conditional
quantile treatment eﬀects cannot be mapped simply into unconditional quantile treatment effects. We estimate the latter since we are interested in understanding how college quality aﬀects
the observed distribution of earnings.11
We estimate quantile treatment eﬀects associated with graduation from each college sector
relative to the public non-ﬂagship four-year sector. We focus on graduation rather than attendance because graduation is the outcome most likely to be observed (and rewarded) by the
labor market. Furthermore, estimates of the eﬀect of college quality attended on earnings is
complicated by the fact that many dropouts do not accumulate a lot of credits. So, even at
high-quality schools, they will be relatively untreated by the university’s quality. Since college
quality is associated with higher rates of graduation, even conditional on student background
characteristics and preparation for college (Bound, Lovenheim and Turner, 2010; Rouse, 1995),
college graduates may constitute an endogenous sample. In Section 4.4, we show our results
are robust to analyzing college attendees rather than graduates, particularly among four-year
schools, but our main analysis focuses on graduates because we believe college graduation to
be a more relevant post-secondary outcome for the labor market.
To estimate the quantile treatment eﬀects of graduating from a particular college sector on
earnings, ﬁrst consider a two-sector higher education system where students choose to attend
UT-Austin or a non-ﬂagship, four-year university. Let T=1 if the student graduates from UTAustin and T=0 if not. As described in Firpo (2007), the quantile treatment eﬀect on the
treated for quantile τ can be written:
QT T = q1,τ |T =1 − q0,τ |T =1 .

(1)

The inference problem faced in this analysis is that the counterfactual quantile for the treated
sample, q0,τ |T =1 , is unobserved. In order to estimate q0,τ |T =1 , we generate counterfactual earnings distributions that show what the earnings distribution would be among the untreated group
11 See Angrist, Chernozhukov and Fernandez-Val (2006) for conditional quantile treatment eﬀects of education on wages. Carneiro,
Hanson and Heckman (2003) also show substantial heterogeneity and uncertainty in the returns to attending college.

11

if the distribution of their observable characteristics were the same as in the treated group. Following DiNardo, Fortin and Lemieux (1996), each graduate can be described by earnings, w,
a vector of observable characteristics, x, and a treatment status, T . The joint distribution of
earnings and observables conditional on treatment status is given by:
F (w, x|T = t).

(2)

The density of earnings at each school type then can be calculated by integrating over the distribution of observable characteristics, separately by treatment status. For UT-Austin graduates,
the earnings density can be written:
∫

dF (w, x|T = 1)

f (w|T = 1) =

(3)

∫x

=
x

f (w|X = x1 , T = 1)dF (x|T = 1)

≡ f (w; X = x1 , T = 1),
where x1 is the distribution of observable characteristics among the treated. We want to
estimate f (w; X = x1 , T = 0), which is the counterfactual earnings distribution among those
who were not treated that we would expect if their observable characteristics were identical to
the observable characteristics of the treated group. DiNardo, Fortin and Lemieux (1996) show
that:
∫

f (w; X = x1 , T = 0) =
=

f (w|x, T = 0)dF (x|T = 1)

(4)

∫

f (w|x, T = 0)ψ(x)dF (x|T = 0),

where
ψ(x) =

dF (x|T = 1)
.
dF (x|T = 0)

(5)

Applying Bayes’ rule, equation (5) can be written:
ψ(x) =

P (T = 1|x) P (T = 0)
∗
.
P (T = 0|x) P (T = 1)

12

(6)

Because p(T = 1|x) = 1−p(T = 0|x), equation (6) is the odds ratio of the conditional likelihood
of treatment and ψ(x) are weights. Using our rich set of background characteristics, we use
equation (4) to generate a counterfactual distribution of earnings that would have been expected
if the observable characteristics of students who graduated from non-ﬂagship public universities
in Texas were distributed the same as the observables of UT-Austin graduates.12 This method
is akin to the “aggregate decomposition” described in Firpo, Fortin, and Lemieux (2010). To
our knowledge, this is the ﬁrst analysis to use this reweighting method to estimate quantile
treatment eﬀects.13
The estimated quantile treatment eﬀect then can be written as:
QT T = {infq P [f (w; X = x1 ; T = 1) ≤ q] ≥ τ } − {infq P [f (w; X = x1 ; T = 0) ≤ q] ≥ τ } (7)
Equation (7) is simply the diﬀerence between the unconditional quantiles of two marginal
distributions: the observed treated distribution and the counterfactual untreated distribution.
This diﬀerence identiﬁes the quantile treatment eﬀect for quantile τ under two assumptions.
The ﬁrst is “selection on observables:” the observable characteristics in our re-weighting function given by equation (6) must be suﬃcient to control for the fact that UT-Austin graduates
have a diﬀerent earnings distribution than non-ﬂagship graduates because they have diﬀerent
characteristics that are rewarded by the labor market. The second assumption is rank permanence: the treatment must not change individuals’ place in the earnings distribution. We
discuss both of these assumptions in turn below.
In order to adjust the non-ﬂagship public university earnings distribution for the fact that
students who graduate from these universities diﬀer systematically from UT-Austin graduates
in ways that aﬀect future earnings, we leverage the extensive information in our administrative
data on student backgrounds. We estimate the following models of the probability a student
graduates from a school in sector j (j ∈ {UT-Austin, TAMU, Community College}) relative to
12 This interpretation of this counterfactual earnings distribution also relies on the treated and untreated groups facing the same
potential earnings structure. Given that these graduates all are working in the same state in the same time period, we believe this
assumption is reasonable.
13 Firpo (2007) discusses the feasibility of this approach for estimating quantile treatment eﬀects, but he does not use this method.

13

a non-ﬂagship four-year university:
I(j)i = α + γXi + θTi + ϕEi + δHSi + ϵi ,

(8)

where X is a vector of individual background characteristics, T is a vector of high school
test score controls, E is a set of high school education variables, and HS contains observed
high school characteristics in the year the student graduated. The variables in X are student
ethnicity/race (white, black, Asian, Hispanic), Title I status, English proﬁciency, and free and
reduced price lunch status.14 We include ﬂexible controls for high school test scores, including
quartics of student scores on the Texas state math, reading and writing standardized exams
all students take in high school. Using the high school students attend, we also control for
each student’s relative rank within his or her school on each exam. Because we cannot observe
GPA or class rank in our data, the relative rank variables control for the fact that higher-ranked
students in each high school, conditional on test scores, are more likely to be admitted to higherquality schools. The vector E contains information on high school educational programs, such
as enrollment in gifted programs, special education, career and technology courses, whether the
student had a college plan, and whether he was at risk of dropping out. Finally, we control for
high-school variables that measure the educational environment from which students came. We
include in equation (8) the ethnic composition of the high school, the percentage of students
in each economic status group, the percentage of gifted students and students at risk, the
percentage of title I eligible students, and total school enrollment.15
While the above description pertains to UT-Austin and non-ﬂagship universities, we use the
same methodology for each of the three “treatment” school types: UT-Austin, Texas A&M
and community colleges. For each treatment sector, we estimate a separate version of equation
(8) that includes the same independent variables but that uses separate indicator variables for
whether a student graduated from a school in a given sector relative to a non-ﬂagship public
school. All versions of equation (8) are estimated using logit models, and the predicted values
14 Notably, we cannot observe parental education and income for many students. These variables come from college application
material, and only the more selective schools asked students for this information. In Section 4.4, we show our estimates are robust
to using these variables, however, suggesting that the detailed demographic characteristics in our model are suﬃcient to control for
selection based on family background characteristics.
15 We also have controlled for high school ﬁxed eﬀects in some speciﬁcations. The drawback of high school ﬁxed eﬀects is that
they perfectly predict UT and TAMU non-attendance for many schools. However, they are potentially powerful in controlling for
unobserved student ability that is correlated with college sector and earnings. Estimates with school ﬁxed eﬀects do not produce
qualitatively or quantitatively diﬀerent answers and are discussed in Section 4.4.

14

from these logit models are used to construct the weights shown in equation (6).16
In the even columns of Table 2, we show descriptive statistics for the non-ﬂagship group
that are weighted by the relative odds of graduating from each sector in Texas. Because our
propensity score model contains a large number of variables and because we assume a logistic
functional form, it is not assured that the methodology described above will balance each
observable across treatment and control sectors. Comparing the even and odd columns in Table
2, however, shows that our method fully balances the covariates in each sector; in no case is there
a large or statistically signiﬁcant diﬀerence between the observed mean and the re-weighted
control group mean. At the bottom of the table, we calculate predicted log earnings in each
sector using the observed graduates from that sector and all observed characteristics. We then
predict log earnings for the treatment and control groups using the sector-speciﬁc coeﬃcients.
One can interpret these predicted log earnings as summary statistics of the diﬀerence between
the characteristics of the treatment and control groups as they relate to earnings. As the
table demonstrates, not only are the means identical among the treated and weighted control
groups, but the distributions are the same as well. Thus, our propensity score model balances
the covariates such that there is no predicted diﬀerence in the distribution of earnings across
treatment and control groups. Any observed diﬀerence in the distribution of earnings must thus
be due to school quality or to unobserved factors that are uncorrelated with the observables in
our model.
The variables we include in our model we believe represent powerful controls for the fact
that students of higher academic ability are more likely to attend a higher-quality school and
to earn more. Although “student ability” is very diﬃcult to account for perfectly, our ﬂexible
controls for standardized test scores in three diﬀerent subjects, each student’s place in their
high school’s test score distribution for each exam, and a detailed set of information about
each student’s high school composition and academic track are much stronger ability controls
than have been used previously (Brewer, Eide and Ehrenberg, 1999; Black and Smith, 2004;
16 Because students make one decision over a set of schools, it may be more appropriate to estimate the weighting function using
a multinomial logit model of the choice between all college sectors. We have implemented this model for the choice among our
three four-year public school sectors and the estimates, which are available upon request, are indistinguishable from those shown
below. We only estimated this model using four-year schools due to the limited overlap in observable characteristics between
ﬂagship university graduates and community college graduates. We present results that use weights generated from treating each
schooling decision as a binary choice between a given sector and the non-ﬂagship public sector in order to be consistent across all
“treatments” examined in this analysis, but our estimates are unchanged if we treat college sector choice among four-year sectors
as a multivalued treatment.

15

Black and Smith, 2006). Conditional on these observable characteristics, the critical remaining
question is what drives the residual selection of students into colleges of diﬀering quality. If these
choices are based on unobservables that also are correlated with earnings potential, it will bias
our estimates. Currently, there is little understanding of why students select diﬀerent school
types. Although students are sensitive to quality diﬀerences among schools (Long, 2004; Avery
and Hoxby, 2004), this is not the only factor that matters. Choices also rely on idiosyncratic
preferences (such as whether a relative attended the school, the quality of the campus visit,
the quality of the sports teams in that year), the behavior of one’s peers (i.e., whether many
peers attend this school) and, in our data, the change in access to ﬂagship universities that
accompanied the implementation of the Top Ten Percent Rule in 1998.17 Due to the detailed
set of controls for student academic ability and background we include in our model, we argue
these three sources of variation are the predominant residual determinants of college sector
selection. Crucially, these factors all are unlikely to be correlated with underlying earnings
potential.
Variation in particular from the Top Ten Percent Rule is important to consider because
it had a large change on the admissions regime in Texas. Unfortunately, our data do not
include class rank, so we cannot exploit this change directly. However, post-1998, the data
include an indicator of whether students are admitted to a given university under the Top Ten
Percent Rule. This indicator on its own is highly predictive of attending UT-Austin and Texas
A&M. However, conditional on the relative test score rank controls in our model, this variable
loses its predictive power, suggesting that controlling for relative rank on standardized tests is
suﬃcient to account for the top 10% rule and for the eﬀects of student relative rank on ﬂagship
admission. This result also suggests that our controls are indeed highly correlated with college
sector choices of students. Furthermore, if we control for whether one is admitted through the
Top Ten Percent Rule as well as interactions of all variables with a post-1998 indicator variable,
17 The Top Ten Percent Rule – Texas House Bill 588 – is an admissions algorithm. It grants automatic admission to any public
college or university in Texas to Texas high school graduates who ﬁnish in the top decile of their graduating class and apply to
college within two years of ﬁnishing high school. Texas House Bill 588 also permits each college or university to decide, on an annual
basis, whether or not to oﬀer automatic admission to students who ﬁnish in the top quartile. The law further lists characteristics
that public universities can use in making admissions decisions. Examples of such factors include the applicant’s socioeconomic
background, the performance level of the applicant’s high school, the ﬁnancial status of the applicant’s school district, parental
income, parental education, and whether the applicant has bilingual proﬁciency. Prior to 1998, admissions included aﬃrmative
action considerations, which allowed colleges to consider factors such as the applicant’s race, academic performance, class rank,
curriculum, and standardized test scores. To our knowledge, there were no strict formulas relating these factors to admission
decisions.

16

our estimates are unchanged.18 Thus, there is little evidence in our data that the imposition
of the Top Ten Percent Rule biases our estimates by altering the relationship between student
ability and college choice in a manner that we cannot measure.
In addition to the factors discussed above, it also is possible that unobserved factors, such
as “student motivation” or “non-cognitive” skills that are related to earnings also drive some
of the college quality variation. We believe our estimates are inconsistent with the existence of
biases from these omitted variables because of the small eﬀect of our observables on earnings
distributions, because of the diﬀerent shapes of the quantile treatment eﬀects across school
types, and because of the robustness of our estimates to controlling for factors that are likely
to be correlated with these unobservables, such as parental income and education as well as
high school ﬁxed eﬀects. With observational data, it is not possible to control directly for
these diﬃcult-to-measure student attributes, which highlights the importance of studies that
use natural experiments with exogenous school quality variation (e.g., Hoekstra, 2009). Such
natural experiments are exceedingly rare, however, which necessitates using observational data
with extensive student background controls. That our mean estimates are similar to, if somewhat smaller than, the estimates from previous work (see Table 4) suggests these variables are
suﬃcient to control for the selection of students with higher earnings power into high-quality
colleges.
As implied by equation (6), the estimated propensity scores must be less than 1 because
the weights are not deﬁned for those who are predicted with certainty to attend a given type
of college.19 Our propensity score models generate predicted probabilities of less than one for
every individual in our sample. Similar to matching estimators, there also must be overlap
of the propensity score distributions among the treated and control observations.20 Without
overlap of the propensity scores, there will be individuals in the treated group for whom there
are no observably equivalent individuals in the control group. Thus, it would not be possible
to construct a counterfactual earnings distribution that would occur if the distribution of observables in the control group was the same as in the treated group because there would be
parts of the joint distribution of observable characteristics in the treated group that are absent
18 These

estimates are available from the authors upon request.
as well that those with zero predicted likelihood of attending each college type will receive a weight of zero. These
observations are eﬀectively excluded from the analysis, which is why we are estimating treatment eﬀects on the treated.
20 See Smith and Todd (2005) for a detailed discussion of this issue with respect to matching estimators.
19 Note

17

in the control group. The presence of such non-overlap in observable characteristics will cause
a bias in the estimation of the counterfactual earnings distributions.
Figure 2 presents estimated propensity scores from equation (8), estimated for each school
type separately with the non-ﬂagship universities as the control group. Each panel shows
the number of individuals in each grouping of estimated propensity scores among treated and
control observations. Due to conﬁdentiality concerns, we are unable to present means calculated
with fewer than 10 individuals, so these propensity score groups are the smallest equal-sized
bins we could construct between 0 and 1. For no school types are there gaps in the estimated
propensity scores, and even for those who have very high and low estimated probabilities of
attending each school type there are those in the same propensity score range in both the
treated and control groups. Although our propensity score models are based on a large number
of observable characteristics that are designed to control for student selection into diﬀerent
school quality types, we have suﬃcient overlap of the predicted likelihood of treatment among
treated and control groups to estimate equation (7).21
The second assumption needed to estimate quantile treatment eﬀects in this setting is rank
permanence (Doskum, 1974; Lehmannn, 1974; Firpo, 2007; Bitler, Gelbach and Hoynes, 2006).
Rank permenance imposes the condition that the treatment does not change an individual’s
relative place in the distribution of earnings. We believe this assumption is reasonable in the
context of this analysis because, conditional on the selection on observables assumption holding,
any rank switches would have to be symmetric. For example, if a ﬂagship graduate at the 50th
percentile of the earnings distribution would have been in the 80th percentile if he had graduated
from a non-ﬂagship, if the selection on observables assumption is valid then another student at
the 80th percentile of the UT distribution would have to be at the 50th percentile if he graduated
from a non-ﬂagship. Though possible, there is little reason to believe such rank switching should
occur due to diﬀerences in college quality. Furthermore, as Bitler, Gelbach and Hoynes (2006)
stress, even without the rank preservation assumption, we are able to estimate the eﬀect of
21 Flores

and Mitnik (2009) present a method for generating common support among treatment and control groups when there
are multiple treatments. They emphasize that in order to compare estimates for diﬀerent treatments, the same sample with general
common support needs to be used. Their method is to delete observations sequentially that are not in the common support for
each treatment, such that the ﬁnal sample is the sample for which there is support with respect to each treatment individually.
Because we do not exclude any observations for any treatment due to the lack of common support among treatment and controls,
this sequential support method leaves exactly the same analysis sample as we use in the analysis. Because of this feature of our
data, comparisons of the quantile treatment eﬀects across treatment sectors are valid.

18

college quality on the entire distribution of earnings. That is, our estimates show how college
quality aﬀects each quantile of the earnings distribution regardless of whether rank permanence
holds. This distributional change is what is needed for welfare analysis, and we are the ﬁrst in
the literature to estimate how college quality aﬀects the earnings distribution.22 While we focus
on estimating quantile treatment eﬀects, an additional value of our methodological approach is
that the eﬀect of college quality on the earnings distribution is estimated as well. Thus, even
without the rank permanence assumption, our estimates are of general policy interest.

4

Results

4.1

Earnings Distributions

Figure 3 shows the observed earnings distributions for each treatment-control grouping as well
as the counterfactual earnings distributions if the observable characteristics in the non-ﬂagship
schools were the same as in each of the treatment sectors. Comparing the observed earnings
distribution in the treated schools and the counterfactual control school distributions shows the
eﬀect of college quality on the entire distribution of earnings, which does not require assumptions
about rank permanence.
As shown in Panel A, the UT-Austin distribution is above the counterfactual non-ﬂagship
distribution, and this diﬀerence grows as one moves higher up in the earnings distribution.
Thus, under the assumption that our observable characteristics are suﬃcient to control for
selection of diﬀerent-skilled individuals into higher quality universities, Panel A of Figure 3
indicates that graduating from UT-Austin shifts out the earnings distribution and that this
shift is larger higher up in the distribution.
In Panel B, we show similar distributions among Texas A&M graduates and non-ﬂagship
public university graduates. As with UT-Austin, the Texas A&M earnings distribution is above
the counterfactual control group distribution, but here, the outward shift is more uniform. To
the extent there is change in the shape of the distribution, it is a ﬂattening of the distribution
due to larger returns at the lower end than at the upper end.
Graduating from a community college rather than a four-year non-ﬂagship public university
22 See

Heckman, Smith and Clements (1997) for a discussion of heterogeneous treatment eﬀects and social welfare.

19

has a substantial eﬀect on the shape of the earnings distribution. For nearly the entire distribution of earnings, earnings for community college graduates are below those of non-ﬂagship
public university graduates. However, the estimates steadily asymptote towards zero as we
move across the earnings distribution. Graduating from a community college is particularly
deleterious for the bottom of the distribution. These estimates are suggestive that the previous
literature that estimates negative eﬀects of community college attendance or graduation on
earnings is driven by the lower part of the earnings distribution (Reynolds, 2009; Kane and
Rouse, 1995).
In all three panels of Figure 3, the counterfactual earnings distributions are quite similar
to the observed other 4-year distributions. The diﬀerence between these distributions can be
interpreted as the contribution of observable diﬀerences among students in each schooling sector
to the diﬀerences in earnings across sectors.23 That the controls explain so little of the observed
earnings diﬀerences across school sectors is suggestive that the diﬀerences in earnings across
school types is not being driven by selection on unobserved components of student ability.
Given the comprehensive set of covariates included in the propensity score models, one would
expect these variables to explain a large proportion of the observed earnings diﬀerentials across
school types if the returns to college quality were small and the ability/skill diﬀerences were
driving the observed earnings diﬀerences. Unobserved factors that are correlated with both
college quality and earnings, such as non-cognitive skills and student academic ability, would
have to be uncorrelated with our extensive set of controls and highly correlated both with
school sector choice and subsequent earnings to be signiﬁcantly biasing our estimates. But,
these unobservables are likely to be correlated with the background, school environment and
test score measures in the propensity score models. Thus, that our observable variables explain
little of the observed earnings diﬀerences across school types is suggestive that it is the college
environment that is causing the shift in earnings distributions shown in Figure 3 rather than
unobserved factors correlated with both college quality and earnings.
23 This

decomposition interpretation assumes that the eﬀect of each observable is the same in each school type. For example, the
eﬀect of a 1 standard deviation change in math test scores is assumed to be the same for a student who graduates from UT-Austin
as for a student who graduates from a non-ﬂagship 4-year university.

20

4.2

Quantile Treatment Eﬀect Estimates

Before estimating the quantile eﬀects, it is instructive to examine mean eﬀects of college quality
on earnings as a point of comparison with the rest of the literature. Table 4 shows estimated
mean impacts, regressing log earnings residuals on treatment indicators while adding in controls
sequentially. We add in the controls in this manner in order to show how correlated they are
with school type and with earnings. We ﬁrst show estimates from bivariate regressions, and the
mean eﬀects all are large and statistically signiﬁcantly diﬀerent from zero at the 1% level. When
we add in our test score controls, the estimates become smaller in absolute value, suggesting
these test scores measures are able to control for at least some of the selection on student ability
that drives the large bivariate estimates. We then add in student demographic characteristics
and school experience controls (i.e., limited English proﬁciency, gifted and talented, at risk for
dropping out) and ﬁnally include school average demographic characteristics. These variables
all attenuate the estimates further, although conditional on the test score controls the other
variables do not have large impacts on the estimates. We interpret this as evidence that our test
score measures are powerful controls for selection into school types, because the demographic,
school experience and school composition variables all are correlated with college sector and
with future earnings.24 These correlations are mostly in common with the test scores, however,
which highlights the value of our set of test controls in this analysis.
Focusing on the estimates with a full set of controls, the mean eﬀect for UT-Austin is 11.5%.
This estimate is somewhat smaller than in previous work that estimates the returns to attending
an elite public university,25 however it is still positive, statistically diﬀerent from zero at the 1%
level, and sizable in magnitude. The mean eﬀect for Texas A&M relative to non-ﬂagship public
universities is much higher, at 21.2%. This estimate is similar to the results from the existing
literature. Finally, for community colleges we estimate a mean eﬀect of -10.0% on earnings,
which is somewhat larger in magnitude relative to previous ﬁndings of the eﬀects of community
24 A pooled regression of log earnings on our full set of non-school-type controls for all Texas graduates in our sample yields an
R2 of 0.06. Thus, our observable characteristics explain a non-trivial proportion of the earnings variation.
25 Hoekstra (2009) estimates the earnings eﬀect of attending an un-named ﬂagship state university is 24%. Brewer, Eide and
Ehrenberg (1999) estimate a mean return of 26%. Note that both of these papers focus on attendance, while we examine the eﬀect
of graduation. This diﬀerence may reduce our estimates if part of the return to attending a ﬂagship university is increasing the
likelihood of ﬁnishing. Furthermore, in the Hoekstra (2009) analysis, the counterfactual for those not attending the ﬂagship is a
mix of lower-ranked four-year attendance, community college attendance, and non-college attendance. This counterfactual may
cause the estimated earnings returns to be higher than if a counterfactual of non-ﬂagship four-year universities is used. Similarly,
in Brewer, Eide and Ehrenberg (1999), the counterfactual is “bottom public” universities, which are likely to be of lower quality
on average than the non-ﬂagship public universities in Texas. This will serve to increase the estimated earnings returns.

21

college enrollment on earnings.26 Overall, the similarity of our mean estimates to prior work
is inconsistent with the existence of large biases due to unobserved student attributes in our
results. But, we emphasize that this conclusion is only suggestive due to the sample diﬀerences
and the diﬀerences in counterfactuals that make cross-study comparisons diﬃcult.
The motivating question of this analysis is to understand how well these mean eﬀects characterize the returns to quality experienced by most students. We now turn to quantile treatment
eﬀects to estimate the distribution of returns rather than just the mean. The quantile treatment
eﬀects of college quality on earnings from estimation of equation (7) are shown in Figure 4. In
each panel, the solid line is comprised of 99 quantile treatment eﬀects for each percentile between
1 and 99 that are the diﬀerence between the observed UT-Austin/TAMU/community college
distributions and the associated counterfactual other 4-year earnings distributions. The dashed
lines show the bounds of the 95% conﬁdence intervals that are estimated by bootstrapping the
entire estimation procedure and plotting the 2.5th and 97.5th percentiles of the bootstrapped
earnings diﬀerences at each percentile. Quantile treatment eﬀects for each 5th percentile of the
distribution together with bootstrapped conﬁdence intervals are shown in column (i) of Tables
5-7 for UT-Austin, Texas A&M and community colleges, respectively. Finally, the horizontal
dotted lines are the 95% conﬁdence intervals of the mean estimates from the “All Controls”
speciﬁcation shown in Table 4.
As shown in Panel A of Figure 4, the mean estimates do a poor job of characterizing the
earnings premiums experienced by most UT-Austin graduates: the quantile treatment eﬀects
are outside the mean conﬁdence interval for over 70% of the distribution. The eﬀect of UTAustin graduation relative to non-ﬂagship graduation is decreasing in the ﬁrst decile, from
12.0% to 3.4%. However, these estimates are not statistically diﬀerent from zero at the 5%
level. After the 10th percentile, the returns to UT-Austin graduation increase dramatically
across the earnings distribution. From the 10th percentile return of 3.4%, the returns increase
to 6.3% at the 25th percentile, 12.1% at the median, 16.8% at the 75th percentile, and are
over 19% above the 90th percentile. The returns are largest at the 97th percentile, at 31.6%.
Thus, across most of the earnings distribution, the returns to UT-Austin graduation increase
26 Reynolds (2009) estimates a decline in earnings of about 5% due to community college relative to four-year attendance. Kane
and Rouse (1995) ﬁnd that community college and four-year credits are equally valued by the labor market but that community
college students earn less than four-year students because they earn fewer college credits.

22

with one’s place in the earnings’s distribution, suggesting that this university is particularly
lucrative for relatively higher earners.
The shape of the returns to Texas A&M graduation in Panel B is much diﬀerent from the
UT-Austin graph. For Texas A&M, the highest returns are at the bottom of the distribution,
with a return of 36.4% at the 1st percentile. While the estimates at the lowest part of the
distribution are not very precisely estimated, the lower bound of the 95% conﬁdence interval
is 25.4% at the 1st percentile and the bottom 20% of the distribution is larger than the upper
conﬁdence interval bound of the mean. The returns decline until the 30th percentile, where they
are 20.6%. They remain fairly stable between the 28th and 90th percentiles, ranging between 17.6
and 21.8 percent, after which they increase to 22.8% at the 99th percentile. The mean accurately
characterizes the earnings premium for Texas A&M for the majority of the distribution. The
returns to TAMU graduation are clearly much more stable than for UT-Austin graduation.
The standard deviation of the returns across quantiles in Panel B is 0.037, while in Panel A it
is 0.066 (a 78% diﬀerence in the standard deviations).
That the slope of returns with respect to earnings is opposite for Texas A&M relative to UTAustin is further evidence against biases from omitted student characteristics. For example,
it might be the case that those at the top of the earnings distribution are more motivated,
attend higher-quality schools, and earn more. While such a story would explain the upward
sloping returns at UT-Austin, it cannot explain why the returns largely decline with earnings at
Texas A&M, especially because students at the two ﬂagship schools are similar on observables
(see Table 2). Similarly, if student motivation is a substitute for college quality, it should
produce the pattern of returns for TAMU but not the one observed at UT-Austin. In short,
we view the diﬀerent shapes of earnings premia across the two ﬂagship schools as evidence
against large biases from omitted variables, because these omitted variables are likely to be
distributed similarly across the income distribution in the two schools, which would force the
earnings patterns to be similar.
A question of interest then is why the Texas A&M estimates are diﬀerent than those for
UT-Austin. As Tables 1–3 show, the observable characteristics of these two ﬂagship schools
and the students who graduate from them are similar. However, students who graduate from

23

these schools major in very diﬀerent subjects, as shown in Figure 5. For example, over 44% of
the undergraduate degrees awarded at Texas A&M are in engineering and agriculture, whereas
only 19% of the degrees awarded to undergraduates at UT-Austin are in those subjects. In
contrast, 62% of the degrees at UT-Austin are in liberal arts, social sciences, communication,
math/computer science and science, while only 36% of the undergraduate degrees awarded
by TAMU are in these subjects. Using the same log earnings residuals used in the quantile
treatment eﬀect estimates for all male college graduates in Texas, Table 8 shows that agriculture
and engineering majors earn more on average but have a lower variance of earnings than those in
the majors favored by UT-Austin graduates. Consequently, when we control for college major
dummies in the weighting logits, the diﬀerences in the quantile treatment eﬀect estimates
between Texas A&M and UT-Austin largely disappear. These estimates are shown in Figure 6
along with the associated mean conﬁdence interval bands. While the Texas A&M distribution is
very similar to the one shown in Panel B of Figure 4, the bottom of the UT-Austin distribution
has been shifted upward signiﬁcantly. Although the earnings premia at the top of the UTAustin distribution still are higher than at Texas A&M, from an accounting standpoint, the
vast majority of the diﬀerences across the ﬂagship universities can be explained by diﬀerences in
college majors, with UT-Austin students majoring in areas that have lower average earnings and
higher earnings variance. Of course, major selection is itself endogenous, and we are hesitant to
draw too strong a conclusion from Figure 6 because of the strong assumption embedded in these
estimates that our controls are suﬃcient to account for the selection of students into majors
across schools.27 But, these estimates are suggestive that both quality of the school as well as
one’s major is very important in driving college quality premiums. That the returns to both
ﬂagships are universally positive and are almost universally statistically diﬀerent from zero at
the 5% level suggests that all students graduating from either school can expect positive gross
earnings returns to the investment. However, the size and variance of the expected premium is
a function of one’s major as well.
In Panel C of Figure 4, we show the eﬀect of graduating from a community college relative to
27 Arcidiacono (2004) ﬁnds large diﬀerences in returns to diﬀerent majors and argues that much of the ability sorting is due to
student preferences rather than monetary returns. However, Arcidiacono, Hotz and Kang (2011) and Wiswall and Zafar (2011)
both ﬁnd evidence from direct surveys of students about subjective beliefs regarding returns to and preferences for majors that
expected returns are a driver of student preferences for majors. These ﬁndings highlight the diﬃculty in interpreting the estimates
in Figure 6 as causal, but they still are interesting as descriptive evidence of the importance of college majors for the distribution
of earnings diﬀerentials across college sectors.

24

graduating from a non-ﬂagship public university on the distribution of earnings returns. The
estimated eﬀect of community college graduation increases across the earnings distribution.
The estimates are negative and statistically signiﬁcant below the 84th percentile, ranging from
-21% to -1%. From the 85th through the 91st percentiles, the returns continue to be negative,
but they are small in magnitude and are not statistically diﬀerentiable from zero. The returns
for the 92nd through the 97th percentiles are positive, with the returns for the 95th and 96th
percentiles being statistically diﬀerent from zero at the 5% level. While these positive estimates
are relatively small in magnitude, the results in Panel C suggest that the earnings penalty from
community college versus non-ﬂagship four-year graduation only applies to the lower part of the
earnings distribution.28 In addition, the mean estimate of -10.0% is a very imprecise estimate
of the expected return for a randomly selected community college graduate. Those lower in
the earnings distribution experience a much higher penalty, and those at the top experience
similar earnings to non-ﬂagship graduates. Given the large price diﬀerences between the twoyear sector and the four-year sector, which the tuition estimates in Table 1 likely understate
due to the higher prevalence of commuter students at community colleges, the results in Panel
C of Figure 4 suggest that it may be optimal for a non-trivial proportion of students to attend
a community college in Texas rather than a four-year non-ﬂagship university in Texas.29
An important question in seeking to understand who beneﬁts from graduating from a more
elite college is whether the earnings premium varies across the socioeconomic distribution.
Although we do not observe parental income for a proportion of our sample, we can observe
student race and ethnicity, which is correlated with socioeconomic status. Due to the large
disparities in higher education attainment for African American and Hispanic students relative
to white and Asian students, the diﬀerential returns to college quality faced by these groups
are of much interest. Such diﬀerences could be driven by mismatch,30 diﬀerences in academic
28 It is very unlikely that the relatively higher returns at the top of the distribution for community colleges are due to transferring.
Recall that these estimates are for graduates, so any transfers to four-year schools who obtain a BA are counted as four-year
graduates in our analysis. If some of the community college graduates transfer to a four-year school but do not obtain a BA, their
earnings could increase. But, they still likely would earn less than comparable BA recipients, which is at odds with the equivalent
earnings of non-ﬂagship four-year and community college graduates at the top of the earnings distribution shown in Figure 4.
29 Note that controlling for majors in the community college estimates is diﬃcult, because many community college degrees are
in areas that are not oﬀered in four-year schools. Thus, we do not estimate community college models with major controls as we
do for the public ﬂagships.
30 Arcidiacono et al. (2011) shows evidence from Duke University that aﬃrmative action leads to mismatch based on private
information that the university has about students. Cortes (2010), however, ﬁnds little evidence that the Texas Top Ten Percent
Rule led to changes in minority graduation rates and persistence due to mismatch. Rothstein and Yoo (2008) also ﬁnd little evidence
of aﬃrmative action-based mismatch in law school.

25

preparation for college, diﬀerences in major selection, and labor market discrimination. Most
previous work has not been able to identify how college quality earnings premiums vary across
racial and ethnic backgrounds because of data limitations. Despite the fact that the proportion
of black and Hispanic students at UT-Austin and Texas A&M is low (see Table 2), we are able
to present some of the ﬁrst evidence of college quality returns for these groups.
4.3

Quantile Treatment Eﬀects by Race/Ethnicity

Table 4 presents mean eﬀects of college sector on earnings for white, black, Asian and Hispanic
students. At UT-Austin, white and Asian students have the highest mean returns, at about
12.9% and 13.8%, respectively. Black and Hispanic students experience the lowest earnings
premiums —3.4% for black graduates and 3.5% for Hispanic graduates. The mean return
for Hispanic students is statistically diﬀerent from zero at the 5% level, while the mean for
black graduates is statistically indistinguishable from zero. At Texas A&M, however, the mean
returns are both higher and more similar across groups, ranging from 17.9% to 21.9%. The
diﬀerences between the earnings premiums for black and Hispanic students across UT-Austin
and TAMU mirror those for the whole sample show in Section 4.2. Among white, black and
Hispanic community college graduates, the returns are between -8.5% and -12.3%. However,
for Asian students, the average earnings penalty for community college graduation relative to
non-ﬂagship public four-year graduation is -27.1%.
These mean estimates are suggestive of a large amount of heterogeneity across sector and
student groups in the returns to college quality. We now present quantile treatment eﬀects for
each sector and student race/ethnic group to examine how well these mean eﬀects describe the
earnings premiums for these students. Estimates for each decile along with bootstrapped 95%
conﬁdence intervals are shown in Appendix Table A-1.31
Figure 7 shows quantile treatment eﬀect estimates for UT-Austin separately for white, black,
Asian and Hispanic graduates. The distribution of returns for white students is very similar
to the overall sample. For black graduates, who are shown in Panel B, the estimates are
generally higher than for white graduates below the 20th percentile. Although the standard
31 We also have generated propensity score distributions akin to Figure 2 separately by race and school type. These distributions
show that there is common support between treatment and control across all school types and race and ethnic groups. These graphs
are available from the authors upon request.

26

errors are large, the point estimates for the 1st to the 4th percentiles range from 44.0% to 73.7%.
The returns for black UT graduates are much lower for the remainder of the distribution and
generally are indistinguishable from both the mean and from zero: between the 11th and the
90th percentile, the estimates range from about -4% to 10.5%. While the returns rise for the
top decile, the estimates still are imprecisely estimated. These results are suggestive that it
is black graduates at the top and bottom of the earnings distribution who experience sizable
earnings premiums due to UT-Austin graduation; for the rest of the distribution the returns
are small.32
The returns to UT-Austin are universally high for Asian graduates, ranging from a minimum
of 8.5% to a high of 42.3%. As with black students, the returns for Asian graduates are highest
at both the bottom and top of the earnings distribution. Unlike black graduates, however, the
estimated quantile treatment eﬀects are—for the most part—statistically diﬀerent from zero.
In contrast, earnings premiums for the lowest Hispanic earners are small, often with negative
coeﬃcients that are not statistically distinguishable from zero. The estimates then rise; they
become consistently positive above the 30th percentile and become statistically signiﬁcant at
the 50th percentile. The estimates take on a value of 4.5% at the median and reach a high
of 33.2% percent at the 99th percentile. Especially for white and Hispanic students, the mean
estimates do a poor job of characterizing the quality earnings premium students experience.
And, for historically under-represented minorities, while the average returns are rather low, for
portions of the earnings distribution they are quite large.
Similar to the estimates in Figure 4, the estimates across all four groups exhibit less variability for Texas A&M than for UT-Austin, as shown in Figure 8. Again, the white distribution
is very similar to the overall distribution shown in Figure 4, which is not surprising given that
Texas A&M is over 88% white. For black graduates, the returns at the bottom of the distribution are very high. They decline across the distribution of earnings, going below 30% at the
16th percentile and remaining between 10.8% and 27.8% for the remainder of the distribution.
Earnings premiums for Asian graduates of Texas A&M are high in the lower tail of the the
distributions as well. The maximum estimate is at the 4th percentile, with a value of approx32 Note that the distribution of majors is remarkably similar across race and ethnic groups, such that diﬀerences in majors across
groups are unlikely to account for the diﬀerences in estimated returns. Major distributions are available from the authors upon
request.

27

imately 50%. The estimates decline below 20% at the 12th percentile, remain between 13.2%
and 19.3% for the 13th through the 89th percentiles and climb above 20% as we move into the
top decile. The treatment eﬀects for Hispanic graduates from TAMU follow a pattern similar
to the returns for Asian graduates. The largest treatment eﬀect occurs at the 2nd percentile, a
value of 36.7%; the earnings drop below 20% at the 11th percentile, remain between 15.2% and
19.6% for the 12th through the 95th percentiles, and exceeds 20% for the 96th through the 99th
percentiles.
Figure 9 shows earnings penalties from ﬁnishing at a community college rather than ﬁnishing at a four-year non-ﬂagship university stratiﬁed by race and ethnicity. We obtain negative
estimates of the returns to graduating from a community college for whites from the 1st percentile to the 93rd percentile, with the estimates from the 3rd percentile to the 78th percentile
being statistically signiﬁcantly diﬀerent from zero. The returns rise as we move across the
distributions of earnings, become positive but statistically insigniﬁcant at the 93rd percentile,
and fall below zero at the 96th percentile. The distribution of returns for black community
college graduates relative to their four-year non-ﬂagship counterparts follow a similar pattern
to that of the returns white community college graduates experience. Black community college
graduates experience negative returns from the 1st percentile to the 91st percentile, with the
estimates from the 7th percentile to the 86th percentile being statistically signiﬁcant. Relative
earnings rise as we move across the distributions of earnings; they are positive, rising, and statistically insigniﬁcant between the 91st and 96th percentiles and become statistically signiﬁcant
for the 97th percentile and above. The positive returns at the top of the distribution are large,
reaching 15.5% at the 99th percentile. Thus, while most black community college graduates
earn less than their counterparts at four-year non-ﬂagship universities, for the very top of the
earnings distribution this relationship is reversed. Adding in the lower time and direct costs
of community colleges, the net returns to community college graduation are likely positive for
much of the upper portion of the earnings distribution for black college graduates.
The community college returns are almost universally negative for Asian students, and although the conﬁdence intervals are large, the negative returns are more pronounced in the lower
part of the earnings distribution. As with whites, the low mean community college returns are

28

driven predominantly by the lowest earners. The distribution of returns for Hispanic students,
however, are quite similar to those for black students. The returns are negative below the
84th percentile and then are positive and statically signiﬁcantly diﬀerent from zero at the 96th
percentile and above. For the top decile of the distribution, the returns to community college
graduation are between 2% and 6%. While typically lower than the returns for the African
American sample, these results point to positive gross (and thus higher net) returns to community college enrollment for high-earning Hispanic students. The ﬁnding that mean returns are
negative but are positive for the upper portion of the distribution of earnings, particularly for
black and Hispanic students, highlights the importance of examining the entire distribution of
returns rather than focusing on just the mean returns. In particular, the lower mean returns
for black and Hispanic students relative to white students shown in Table 4 mask the fact that
returns are lower for these groups at the bottom of the distribution but are larger at the top.
4.4

Robustness Checks

As discussed in Section 3, the validity of our estimates rests on the ability of the observable characteristics in our model to control for the selection of students with higher underlying earnings
power into higher-quality schools. In this section, we assess the robustness of our estimates
to several diﬀerent modeling assumptions. First, we include high school ﬁxed eﬀects in the
propensity score model. Because one’s high school likely is correlated with unobserved ability,
motivation and non-cognitive skills, these results will lend insight into remaining selection bias
in our preferred estimates. The drawback of this model is that we lose many control group
observations because there are numerous high schools in Texas that send no students to Texas
A&M and\or UT-Austin. Column (iii) of Tables 5–7 contains the quantile treatment eﬀects for
this model, and for all three school types the estimates are virtually identical to those without
high school ﬁxed eﬀects (column (i)).
While our data contain a rich set of covariates with which to control for selection, we do not
include parental income and education in our baseline estimates. This omission stems from the
large volume of missing data for these variables due to the fact that only students who apply
to elite schools in Texas are required to supply such information. In columns (iv) and (v) of

29

Tables 5 and 6, we show estimates for the sample of students that have parental income and
education data but excluding these variables (column (iv)) and then for this sample including
these variables (column (v)). We are unable to do this robustness check for community college
students because too few students provide parental background information. However, as Tables
5 and 6 show, the estimates for the sample of students who provide this information are virtually
unchanged when parental income and education are included or excluded. Furthermore, despite
the endogeneity of the reporting of these variables, the estimates for this sample are very
similar to the baseline estimates. Given the strong correlation between family background,
schooling and earnings, that adding parental education and income does not inﬂuence the
quantile treatment eﬀect estimates suggests that our controls do a good job of controlling for
the selection of more earnings-capable students into higher-quality colleges.
Due to the structure of our data, the earnings data we use for this analysis come from
earnings when graduates in our sample are in their mid 20s and early 30s. However, if college
quality aﬀects the returns to experience, examining earnings diﬀerences for recent graduates
may yield misleading estimates of the eﬀect of college quality on long-run earnings. In order
to examine whether our estimates are sensitive to the timing of when earnings are measured,
column (ii) of Tables 5-7 show quantile treatment eﬀects using the oldest cohorts: those who
graduate between 1996 and 1998 and thus who are between 27 and 31 years old in 2007-2009
when earnings are measured. These students also are unaﬀected by the Texas Top Ten Percent
Rule, so these estimates provide a check that this admissions regime change does not seriously
bias our estimates. For UT-Austin (Table 5) and Texas A&M (Table 6), the estimates using the
older sample match the estimates from the whole sample very closely above the 40th percentile
of the earnings distribution. Below the 40th percentile, the older workers experience slightly
lower returns, suggesting that our baseline sample understates the amount of heterogeneity in
returns. For UT-Austin, the estimates are negative below the 15th percentile; however, these
estimates are statistically insigniﬁcant. Aside from the estimates below the 15th percentile for
UT-Austin, the quantile treatment eﬀects of UT-Austin and Texas A&M graduation are similar
for the 1996-1998 sample and for the full sample.
Among community college graduates, the diﬀerences are somewhat larger between the two

30

samples, as shown in column (ii) of Table 7. As with the estimates for TAMU and UT-Austin,
the estimates for the 1996-1998 sample are below those for the full sample at the bottom
of the distribution. Between the 10th and 65th percentiles, the estimates are very similar.
However, above the 65th percentile, the early cohort estimates approach zero and then become
more negative at the very top, while the full sample estimates approach zero higher up in
the distribution. Despite these diﬀerences, these estimates are qualitatively similar, and the
diﬀerences in magnitudes of the returns at the top of the earnings distribution are small. Using
the early cohort versus the full sample does not alter the main conclusions drawn from the
community college results that for the upper portion of the earnings distribution the returns
to community college graduation relative to four-year non-ﬂagship graduation are close to zero
and likely are positive once one accounts for the cost diﬀerences across school types.
We also examine the eﬀect of college attendance rather than college graduation on subsequent
earnings. On the one hand, college attendance is a compelling margin to examine because
college sector can aﬀect the likelihood of graduation (Bound, Lovenheim and Turner, 2010;
Rouse, 1995). On the other hand, college graduation is more appropriate because this is the
more salient signal for employers and because examining only enrollment means the intensity
of treatment varies signiﬁcantly across individuals based on how many credits they receive.
Furthermore, for community college students, the graduate sample is likely to be much more
similar to BA recipients than is the attendee sample, as many community college students who
drop out have loose attachments to the postsecondary sector and do not intend to obtain a BA.
Column (vi) in Tables 5-6 and column (iv) in Table 7 show results when we use all college
attendees and assign school types based on the institution in which each individual earned
the most credits.33 For UT-Austin and Texas A&M graduates, the results using attendees are
similar to those using graduates. The main diﬀerences come at the bottom of the distributions, where the returns for attendees are around 3-5 percentage points higher. But, the main
qualitative and quantitative results remain, with the returns for UT-Austin students increasing
across the income distribution and the returns for Texas A&M students declining.34
For community college attendees, there is more of a divergence from the baseline estimates.
33 Estimates

are very similar when we assign students based on the ﬁrst college attended after high school.
Table A-2 presents estimates by race and ethnicity for the attendee sample. The same diﬀerences apply to these
samples: returns are higher at the lower end of the distribution among attendees at UT-Austin and Texas A&M. The only substantive
diﬀerence comes from black UT-Austin attendees, who experience returns of over 10% below the 30th percentile.
34 Appendix

31

Below the 40th percentile, the returns for community college attendees lie above the returns for
college graduates, while above the 45th percentile the returns for community college attendees
are lower than the returns for two-year graduates. However, near the top of the distribution, the
returns among attendees approaches zero, with returns higher than -5% above the 90th percentile
of the earnings distribution. The diﬀerences in these results most likely can be attributed to
the fact that completion rates at community colleges are very low.35 Thus, graduates and noncompleters are likely to diﬀer substantially with respect to future earnings, with the inclusion of
community college dropouts shifting the community college earnings distribution downwards.
The low completion rates at community colleges also makes the selection problem more diﬃcult
to solve among the attendee sample, as the community college dropouts are probably less similar
to four-year college attendees on observable characteristics. These estimates show that for
community college students there are diﬀerences in returns between graduates and attendees.
While we ﬁnd evidence that the returns to community college graduation may be positive
for the upper part of the earnings distribution, this ﬁnding is weaker when one examines all
attendees. Although the top of the attendee distribution approaches zero and the estimates
become statistically indistinguishable from zero, the attendee returns approach zero higher in
the distribution than in the graduate sample and never become positive. One implication of
this ﬁnding is that there may be substantial returns to increasing completion rates among
community college students. This issue deserves more attention in future research.
Finally, we include in our analysis all earnings for individuals who are not contemporaneously
enrolled in graduate school (column (vii) in Tables 5-6 and column (v) in Table 7). In eﬀect,
this robustness check relaxes the constraint that an individual must work for three to four
consecutive quarters for their earnings to be included. We do not favor this method of measuring
earnings because we want to measure lifetime earnings diﬀerences as best we can with our
data. Including earnings of those who may work very few hours part time or who may work
part time and then leave the state or the labor market may yield a misleading picture of
permanent earnings diﬀerences by school type. Using all earnings reduces the returns among
UT-Austin graduates at the bottom of the distribution. Thus, we are understating the amount
35 In the National Educational Longitudinal Study of 1988 (NELS:88), only 20% of community college attendees earned an AA
among those who attended within two years of high school graduation. In our sample, only 14% percent of attendees who started
at a community college ﬁnished with any type of degree, be it from a community college or otherwise. The analogous completion
rates for UT Austin and TAMU are 77% and 82%, respectively.

32

of heterogeneity in returns by examining only full-time earnings. The Texas A&M returns
are extremely similar in column (vii) to those in column (i), and for community colleges the
returns are less negative at the bottom of the distribution. However, we still ﬁnd that the
returns become positive at the top of the distribution for community college graduates in this
sample. These estimates demonstrate that our main results and conclusions are not being
driven by analyzing earnings from full-time workers only.36

5

Conclusion

This paper estimates quantile treatment eﬀects of college quality on earnings using administrative data on schooling and earnings from the state of Texas. We measure quality using public
college sector in Texas, examining the eﬀects of UT-Austin, Texas A&M and community college
graduation on the distribution of earnings relative to earnings for non-ﬂagship public four-year
university graduates. While our mean estimates are consistent with previous work in this area,
our quantile estimates demonstrate a large amount of heterogeneity in the earnings premium
from college quality. At UT-Austin, the premia are roughly increasing with earnings, while the
opposite pattern is exhibited among Texas A&M graduates. We argue that diﬀerences in the
courses of study across these schools is a potential explanation for this diﬀerence, but these results indicate that much work remains in understanding how the characteristics of a particular
university map into the distribution of earnings for graduates. At community colleges, we ﬁnd
an overall negative eﬀect on earnings but show that there is signiﬁcant heterogeneity in the
returns and uncover evidence of positive returns at the very top of the distribution.
Our data also allow us to examine returns separately by race and ethnicity, which previous
work has not been able to do because of data limitations. Particularly for black and Hispanic
students, who are historically under-represented in higher education in general and at highquality universities in particular, earnings premia are low for UT-Austin graduates except at
the very top of the earnings distribution, but they are consistently high among Texas A&M
graduates. The returns to community college graduation is negative on average; however, for
black and Hispanic community college graduates we ﬁnd large and positive returns relative
36 We have generated estimates using all non-graduate school earnings for the attendee sample as well, and those estimates are
similarly robust to the use of this alternative earnings measure. These results are available upon request from the authors.

33

to non-ﬂagship public graduates of the same race and ethnicity at the top of the earnings
distribution.
In drawing attention to the large amount of heterogeneity in college quality earnings premia
and the diﬀerences in the quantile treatment eﬀects across school types, this paper demonstrates
the importance of considering more than the average treatment eﬀect of college quality on earnings. Even if educational choices made by students are based on such averages, our estimates
suggest that these averages mask signiﬁcant uncertainty of the returns for any given student.
The main policy implication of this work is that policies seeking to induce students to attend
four-year universities and more selective colleges should pay attention to the distribution of returns, not simply the average, in order to target students who will beneﬁt most from changing
their attendance behavior. Future analyses that focus on identifying which students face the
largest predicted returns are needed to help guide the development of such policy interventions.

34

References
[1] Abadie, Alberto, Joshua Angrist and Guido Imbens, 2002. “Instrumental Variables Estimates of the Eﬀect
of Subsidized Training on the Quantiles of Trainee Earnings.” Econometrica 70(1): 91–117.
[2] Angrist, Joshua, Victor Chernozhukov and Ivan Fernandez-Val, 2006. “Quantile Regression under Misspeciﬁcation, with an Application to the U.S. Wage Structure.” Econometrica 74(2): 539–563.
[3] Arcidiacono, Peter, 2004. “Ability Sorting and the Returns to College Major.” Journal of Econometrics
121(1-2): 343-375.
[4] Arcidiacono, Peter, V. Joseph Hotz and Songman Kang, 2011. “Modeling College Major Choice using Elicited
Measures of Expectations and Counterfactuals.” Journal of Econometrics.
[5] Arcidiacono, Peter, Esteban M. Aucejo, Hanming Fang and Kenneth I. Spencer, 2011. “Does Aﬃrmative
Action Lead to Mismatch? A New Test and Evidence.” Quantitative Economics 2(3): 303-333.
[6] Autor, David H., Laurence F. Katz and Melissa S. Kearney, 2008. “Trends in U.S. Wage Inequality: Revising
the Revisionists.” Review of Economics and Statistics 90(2): 300-323.
[7] Avery, Christopher and Caroline M. Hoxby, 2004. “Do and Should Financial Aid Packages Aﬀect Students’
College Choices?” In Caroline M. Hoxby (Ed.) College Choices: The Economics of Where to Go, When to
Go, and How to Pay for It. Chicago: University of Chicago Press.
[8] Bitler, Marianne P., Jonah B. Gelbach and Hilary W. Hoynes, 2006. “What Mean Impacts Miss: Distributional Eﬀects of Welfare Reform Experiments .” American Economic Review 96(4): 988-1012.
[9] Black, Dan A. and Jeﬀrey A. Smith, 2004. “How Robust is the Evidence on the Eﬀects of College Quality?
Evidence from Matching.” Journal of Econometrics 121(1-2): 99–124.
[10] Black, Dan A. and Jeﬀrey A. Smith, 2006. “Estimating the Returns to College Quality with Multiple
Proxies for Quality.” Journal of Labor Economics 24(3): 701–728.
[11] Bound, John, Michael F. Lovenheim and Sarah Turner, 2010. “Why Have College Completion Rates Declined? An Analysis of Changing Student Preparation and Collegiate Resources.” American Economic
Journal: Applied Economics 2(3): 1-31.
[12] Bound, John, Michael F. Lovenheim and Sarah Turner, Forthcoming. “Increasing Time to Baccalaureate
Degree in the United States.” Education Finance and Policy.
[13] Brewer, Dominik, Eric Eide and Ronald Ehrenberg, 1999. “Does it Pay to Attend an Elite Private College?
Cross-Cohort Evidence on the Eﬀects of College Type on Earnings.” Journal of Human Resources 34(1):
104-123.
[14] Carneiro, Pedro, Karsten T. Hansen and James J. Heckman, 2003. “Estimating Distributions of Counterfactuals with an Application to the Returns to Schooling and Measurement of the Eﬀect of Uncertainty on
Schooling Choice.” International Economic Review 44(2): 361–422.
[15] Chernozhukov, Victor and Christian Hansen, 2005. “An IV Model of Quantile Treatment Eﬀects.” Econometrica 73(1): 245–261.
[16] Cortes, Kalena E., 2011. “Do Bans on Aﬃrmative Action Hurt Minority Students? Evidence from the
Texas Top 10% Plan.” Economics of Education Review 29(6): 1110–1124.
[17] Dale, Stacey Berg and Alan B. Krueger, 2011. “Estimating the Return to College Selectivity over the Career
Using Administrative Earnings Data.” National Bureau of Economic Research Working Paper 17159.
[18] Dale, Stacey Berg and Alan B. Krueger, 2002. “Estimating the Payoﬀ to Attending A More Selective
College: An Application of Selection on Observables and Unobservables.” Quarterly Journal of Economics
117(4): 1491-1527.
[19] DiNardo, John, Nicole Fortin and Thomas Lemieux, 1996. “Labor Market Institutions and the Distribution
of Wages, 1973-1992: A Semiparametric Approach.” Econometrica 64(5): 1001-1044.

35

[20] Doksum, Kjell, 1974. “Empirical Probability Plots and Statistical Inference for Nonlinear Models in the
Two-Sample Case.” The Annals of Statistics 2: 267-277.
[21] Firpo, Sergio. “Eﬃcient Semiparametric Estimation of Quantile Treatment Eﬀects.” Econometrica 75(1):
259-276.
[22] Firpo, Sergio, Nicole Fortin and Thomas Lemieux, 2010. “Decomposition Methods in Economics” NBER
Working Paper No. 16045.
[23] Flores, Carlos A. and Oscar A. Mitnik, 2009. “Evaluating Nonexperimental Estimators for Multiple Treatments: Evidence from Experimental Data ” IZA Discussion Paper No. 4451.
[24] Hoekstra, Mark, 2009. “The Eﬀect of Attending the State Flagship University on Earnings: A DiscontinuityBased Approach.” Review of Economics and Statistics 91(4): 717–724.
[25] Heckman, James J., Jeﬀrey Smith and Nancy Clements, 1997. “Making the Most Out of Programme
Evaluations and Social Experiments: Accounting for Heterogeneity in Programme Impacts.” Review of
Economic Studies 64(4): 487–537.
[26] Hoxby, Caroline M., 2009. “The Changing Selectivity of American Colleges.” Journal of Economic Perspectives 23(4): 95–118.
[27] Kane, Thomas J. and Cecilia Elena Rouse, 1995. “Labor-Market Returns to Two- and Four-Year College.”
American Economic Review 85(3): 600–614.
[28] Koenker, Roger and Gilbert Bassett Jr., 1978. “Regression Quantiles.” Econometrica 46(1): 33–50.
[29] Lehmann, Erich L., 1974. Nonparametrics: Statistical Methods Based on Ranks. San Francisco: Holden-Day.
[30] Long, Bridget Terry, 2004. “How Have College Decisions Changed Over Time? An Application of the
Conditional Logistic Choice Model.” Journal of Econometrics 121(1-2): 271-296.
[31] Lovenheim, Michael F. and C. Lockwood Reynolds, 2011. “The Eﬀect of Housing Wealth on College Choice:
Evidence from the Housing Boom.” Mimeo.
[32] Reynolds, C. Lockwood, 2009. “Where to Attend? Estimating the Eﬀects of Beginning College at a Twoyear Institution.” Mimeo.
[33] Rothstein, Jesse and Albert Yoon, 2008. “Mismatch in Law School.” NBER Working Paper No. 14275.
[34] Rouse, Cecilia E., 1995. “Democratization or Diversion? The Eﬀect of Community Colleges on Educational
Attainment.” Journal of Business and Economic Statistics 13(2): 217-224.
[35] Wiswal, Matthew and Basit Zafar, 2011. ”Determinants of College Major Choice: Identiﬁcation using an
Information Experiment.” Mimeo.

36

Table 1: Means of Texas Public College Resource and Quality Measures by Higher
Education Sector

25th Percentile Math SAT
75th Percentile Math SAT
Faculty-Student Ratio
Expenditures Per Student
Instructional Expenditures Per Student
Graduation Rate
In-state Tuition
1

2

UT
Austin
535
650
0.045
25081
6900
0.710
3212

Texas A&M
College Station
520
630
0.041
27449
8931
0.750
3187

Other Public
Four-year
440
549
0.034
10981
3648
0.338
2001

Community
College

0.023
5756
2317
1217

Source: 1997-2003 IPEDS data. All monetary ﬁgures are in real $2007 and are weighted by total undergraduate
enrollment. All per-student means are per total enrollment. Graduation rates are for BA degrees within six years
of initial enrollment.
SAT scores and graduation rates are reported for a small percentage of two-year schools. Because of the openadmission mandate of community colleges and the fact that many students do not intend to obtain a BA, we do
not report means for SAT scores and graduation rates for these schools.

37

Table 2: Summary Statistics of Analysis Variables

UT
Austin
(i)
0.167
(0.657)
56.084
(5.836)
45.022
(4.304)
37.046
(3.834)
21.829
(0.934)

Weighted
NonFlagship
(ii)
0.045
(0.595)
56.015
(6.096)
44.964
(4.550)
37.014
(3.974)
22.242
(1.036)

TAMU
College
Station
(iii)
0.248
(0.546)
52.429
(5.712)
44.623
(4.381)
36.393
(3.978)
22.098
(0.860)

Weighted
NonFlagship
(iv)
0.032
(0.574)
55.415
(5.734)
44.615
(4.413)
36.383
(3.984)
22.286
(1.013)

Community
College
(v)
-0.168
(0.603)
48.505
(11.283)
39.670
(8.950)
32.138
(7.630)
21.304
(1.743)

Weighted
NonFlagship
(vi)
-0.075
(0.564)
49.039
(10.293)
40.138
(8.075)
32.518
(6.965)
22.632
(1.008)

Un-Weighted
NonFlagship
(vii)
-0.023
(0.564)
52.831
(6.680)
43.031
(4.978)
34.999
(4.499)
22.438
(1.0083)

51.22
31.33
17.44

51.31
31.28
17.41

45.31
33.40
21.29

45.24
33.37
21.39

15.34
27.24
57.41

15.68
27.83
56.49

27.15
32.93
39.91

43.40
31.86
24.74

43.94
31.49
24.57

39.21
33.63
27.16

39.18
33.67
27.15

13.81
25.42
60.77

14.24
25.95
59.81

25.16
31.01
43.83

40.55
32.78
26.66

41.09
32.52
26.39

34.18
32.88
32.93

34.14
32.83
33.04

12.56
23.25
64.20

13.03
23.99
62.98

21.91
29.72
48.37

68.82
12.36
2.56
16.01
42.39
4.74
93.77

67.65
12.49
2.60
16.98
43.36
4.96
93.53

88.59
7.14
1.50
2.58
32.84
5.03
87.08

88.62
7.09
1.49
2.69
32.99
5.12
96.69

60.68
29.56
6.40
2.02
7.90
32.28
77.05

61.15
29.29
7.00
2.04
8.21
31.73
77.10

67.03
19.45
8.33
4.99
18.55
14.89
87.08

Predicted Log Earnings:
Mean
10th Percentile
25th Percentile
50th Percentile
75th Percentile
90th Percentile
95th Percentile

0.167
-0.025
0.080
0.184
0.269
0.334
0.367

0.167
-0.019
0.082
0.182
0.266
0.329
0.367

0.248
0.127
0.192
0.257
0.315
0.361
0.386

0.248
0.127
0.193
0.257
0.314
0.360
0.385

-0.168
-0.356
-0.265
-0.143
-0.065
-0.012
0.016

-0.168
-0.352
-0.264
-0.143
-0.067
-0.015
0.012

Observations

9,837

47,935

13,436

47,935

22,863

47,935

Log Quarterly Earnings
TAAS Math Score
TAAS Reading Score
TAAS Writing Score
Age at Graduation
Tabulations (Percentage):
Math Rank
Top 10 Percentile
70th-90th Percentile
Below 70th Percentile
Reading Rank
Top 10 Percentile
70th-90th Percentile
Below 70th Percentile
Writing Rank
Top 10 Percentile
70th-90th Percentile
Below 70th Percentile
Ethnic
White
Hispanic
Afr. American
Asian
Gifted (Yes)
At Risk (Yes)
Not Disadvantaged

47,935

Source: Authors’ tabulations from the University of Texas at Dallas Education Research Center data and administrative earnings records as
described in the text. Standard deviations are in parentheses. 38

39

68.82
12.36
2.56
16.01
42.39
4.74
93.77

68.36
9.90
1.98
19.51
43.46
4.45
95.75
0.181

Predicted Log Earnings

0.255

87.98
6.72
1.60
3.47
36.65
4.35
96.97

37.11
32.15
30.74

43.37
33.18
23.45

46.82
34.15
19.04

Excluded
55.64
44.90
36.64

0.248

88.59
7.14
1.50
2.58
32.84
5.03
96.69

34.18
32.88
32.93

39.21
33.63
27.16

45.31
33.40
21.29

Included
55.43
44.62
36.39

TAMU
College Station

-0.018

67.34
18.55
6.91
6.97
1.14
14.11
87.60

24.33
29.30
46.36

28.54
31.47
39.99

29.30
33.37
37.33

Excluded
53.13
43.28
35.20

-0.023

67.03
19.46
8.33
4.99
18.55
14.89
87.08

21.91
29.72
48.37

25.16
31.01
43.83

27.15
32.93
39.91

Included
52.83
43.03
35.00

Other NonFlagship

-0.124

59.43
28.60
7.46
3.25
8.61
32.36
75.93

13.33
23.24
63.43

16.32
24.55
59.14

17.19
27.29
55.52

Excluded
48.59
39.66
32.08

-0.168

60.68
29.56
6.40
2.02
7.90
32.28
77.05

12.56
23.25
64.20

13.81
25.42
60.77

15.34
27.24
57.41

Included
48.51
39.67
32.14

Community
College

Observations
5598
9837
4759
13436
14511
47935
5733
22863
Observations Included (Percentage)
63.73
73.84
76.76
79.98
Observations are excluded if they never have 3-4 consecutive quarters of earnings in Texas when not enrolled in graduate school. This could
occur because one does not work, because one leaves the state, or because one is enrolled in graduate school during all periods of observation.

0.167

40.55
32.78
26.66

43.40
31.86
24.74

45.96
30.99
23.04
42.28
32.07
25.65

51.22
31.33
17.44

51.00
31.42
17.58

TAAS Math Score
TAAS Reading Score
TAAS Writing Score
Math Rank
Top 10 Percent
70th-90th Percentile
Below 70th Percentile
Reading Rank
Top 10 Percent
70th-90th Percentile
Below 70th Percentile
Writing Rank
Top 10 Percent
70th-90th Percentile
Below 70th Percentile
Ethnic
White
Hispanic
Afr. American
Asian
Gifted (Yes)
At Risk (Yes)
Economic Status (Not Disadvantaged)

Included
56.08
45.02
37.05

Excluded
56.19
45.17
37.18

UT
Austin

Table 3: Summary Statistics of Analysis Variables for Included and Excluded Observations Among Texas College Graduates

Table 4: OLS Estimates of the Eﬀect of College Sector
on Earnings
UT
Austin

Texas A&M
College Station

Community
College

0.190∗∗
(0.006)

0.272∗∗
(0.005)

-0.145∗∗
(0.005)

Test Score Controls:
0.141∗∗
Full Sample
(0.007)

0.237∗∗
(0.006)

-0.106∗∗
(0.005)

No Controls:
Full Sample

Test Score, Demographic, School Experience Controls:
0.128∗∗
0.217∗∗
-0.099∗∗
Full Sample
(0.007)
(0.006)
(0.005)
All Controls:

0.212∗∗
(0.006)

-0.100∗∗
(0.005)

All Controls, By Race and Ethnicity:
0.129∗∗
0.219∗∗
White Sample
(0.008)
(0.006)
0.034
0.206∗∗
Black Sample
(0.040)
(0.043)
0.138∗∗
0.179∗∗
Asian Sample
(0.022)
(0.034)
0.035∗∗
0.180∗∗
Hispanic Sample
(0.018)
(0.019)

-0.085∗∗
(0.006)
-0.107∗∗
(0.019)
-0.271∗∗
(0.034)
-0.123∗∗
(0.010)

Full Sample

1

2

3

0.115∗∗
(0.007)

Source: Authors’ calculations from the University of Texas at Dallas
Education Research Center data and administrative earnings records
as described in the text. Each cell represents a separate regression,
and each coeﬃcient shows the mean adjusted earnings diﬀerence between the students graduating from each school type and the students
graduating from a non-ﬂagship public university.
Test score controls are quartics in the state math, reading and writing
tests as well as each student’s relative rank in their high school on each
exam. Demographic and school experience controls include student
ethnicity/race, Title I status, English proﬁciency, free and reduced
price lunch status, enrollment in gifted programs, special education,
career and technology courses, whether the student had a college plan,
and whether he was at risk of dropping out. All controls add high
school variables in the year of graduation: the ethnic composition of the
high school, the percentage of students in each economic status group,
the percentage of gifted students and students at risk, the percentage
of title I eligible students, and total school enrollment.
Robust standard errors are in parentheses: ∗∗ indicates statistical signiﬁcance at the 5% level and ∗ indicates statistical signiﬁcance at the
10% level.

40

Table 5: Quantile Treatment Eﬀects of College Sector on Earnings - UT Austin

Quantile
1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90
95
99

Baseline
(i)
0.120
[-0.051, 0.288]
0.049
[-0.026, 0.115]
0.034
[-0.013, 0.075]
0.037
[0.007, 0.075]
0.047
[0.023, 0.074]
0.063
[0.038, 0.087]
0.074
[0.056, 0.091]
0.080
[0.060, 0.097]
0.092
[0.074, 0.110]
0.108
[0.092, 0.125]
0.121
[0.102, 0.141]
0.135
[0.118, 0.155]
0.150
[0.134, 0.167]
0.162
[0.142, 0.177]
0.164
[0.145, 0.177]
0.168
[0.152, 0.179]
0.165
[0.147, 0.184]
0.176
[0.159, 0.196]
0.189
[0.173, 0.217]
0.280
[0.244, 0.313]
0.278
[0.208, 0.326]

1996-1998
Cohort
(ii)
-0.159
[-0.349, 0.136]
-0.063
[-0.184, 0.039]
-0.042
[-0.099, 0.008]
-0.004
[-0.040, 0.041]
0.018
[-0.018, 0.051]
0.039
[0.006, 0.066]
0.056
[0.031, 0.074]
0.063
[0.037, 0.084]
0.078
[0.057, 0.110]
0.120
[0.090, 0.151]
0.149
[0.115, 0.175]
0.164
[0.135, 0.189]
0.178
[0.154, 0.200]
0.179
[0.157, 0.209]
0.186
[0.155, 0.215]
0.188
[0.163, 0.213]
0.190
[0.162, 0.217]
0.201
[0.167, 0.229]
0.229
[0.187, 0.268]
0.336
[0.273, 0.386]
0.191
[0.058, 0.332]

HS Fixed
Eﬀects
(iii)
0.117
[-0.036, 0.251]
0.075
[-0.019, 0.193]
0.073
[0.017, 0.137]
0.077
[0.039, 0.115]
0.085
[0.054, 0.119]
0.099
[0.063, 0.126]
0.100
[0.071, 0.121]
0.097
[0.074, 0.117]
0.107
[0.085, 0.127]
0.126
[0.105, 0.145]
0.144
[0.121, 0.163]
0.157
[0.135, 0.173]
0.170
[0.147, 0.191]
0.178
[0.154, 0.197]
0.177
[0.154, 0.195]
0.171
[0.148, 0.193]
0.175
[0.149, 0.198]
0.186
[0.166, 0.202]
0.194
[0.162, 0.226]
0.278
[0.236, 0.314]
0.302
[0.258, 0.357]

Family Background Sample
Without BackWith Background Variables ground Variables
(iv)
(v)
0.258
0.258
[-0.070, 0.476]
[-0.051, 0.480]
0.136
0.162
[-0.002, 0.294]
[0.015, 0.325]
0.067
0.081
[-0.026, 0.158]
[-0.016, 0.172]
0.071
0.083
[0.014, 0.125]
[0.019, 0.133]
0.068
0.083
[0.018, 0.118]
[0.036, 0.135]
0.096
0.109
[0.050, 0.130]
[0.060, 0.145]
0.087
0.097
[0.063, 0.116]
[0.067, 0.130]
0.088
0.097
[0.063, 0.117]
[0.064, 0.123]
0.090
0.095
[0.060, 0.119]
[0.067, 0.124]
0.100
0.102
[0.072, 0.122]
[0.072, 0.125]
0.102
0.105
[0.074, 0.131]
[0.075, 0.136]
0.125
0.127
[0.096, 0.151]
[0.100, 0.154]
0.136
0.139
[0.109, 0.162]
[0.111, 0.165]
0.132
0.132
[0.111, 0.159]
[0.112, 0.161]
0.141
0.139
[0.122, 0.162]
[0.115, 0.165]
0.145
0.141
[0.128, 0.168]
[0.122, 0.162]
0.156
0.153
[0.140, 0.178]
[0.134, 0.174]
0.168
0.166
[0.148, 0.189]
[0.142, 0.186]
0.186
0.181
[0.155, 0.219]
[0.150, 0.217]
0.257
0.255
[0.197, 0.304]
[0.185, 0.299]
0.326
0.337
[0.269, 0.409]
[0.270, 0.415]

College
Attendees
(vi)
0.126
[-0.031, 0.310]
0.122
[0.052, 0.193]
0.115
[0.070, 0.162]
0.100
[0.073, 0.139]
0.109
[0.086, 0.142]
0.114
[0.092, 0.140]
0.113
[0.096, 0.136]
0.108
[0.089, 0.127]
0.115
[0.096, 0.139]
0.135
[0.117, 0.156]
0.146
[0.127, 0.163]
0.154
[0.139, 0.174]
0.166
[0.152, 0.181]
0.169
[0.152, 0.185]
0.170
[0.156, 0.187]
0.174
[0.160, 0.190]
0.168
[0.154, 0.186]
0.173
[0.157, 0.191]
0.181
[0.161, 0.204]
0.247
[0.210, 0.283]
0.238
[0.135, 0.287]

All
Earnings
(vii)
-0.320
[-0.583, -0.137]
-0.099
[-0.213, -0.006]
-0.050
[-0.112, 0.013]
-0.023
[-0.083, 0.029]
0.008
[-0.028, 0.048]
0.016
[-0.020, 0.052]
0.027
[-0.009, 0.059]
0.044
[0.012, 0.064]
0.050
[0.023, 0.071]
0.074
[0.050, 0.092]
0.087
[0.066, 0.103]
0.096
[0.078, 0.115]
0.116
[0.095, 0.135]
0.123
[0.105, 0.138]
0.135
[0.114, 0.154]
0.147
[0.128, 0.167]
0.156
[0.135, 0.172]
0.161
[0.140, 0.177]
0.175
[0.154, 0.197]
0.221
[0.182, 0.247]
0.236
[0.173, 0.288]

The table shows quantile treatment eﬀect estimates with the bounds of bootstrapped 95% conﬁdence intervals in brackets.
All models control for quartics in the state math, reading and writing tests as well as each student’s relative rank in their
high school on each exam, student ethnicity/race, Title I status, English proﬁciency, free and reduced price lunch status,
enrollment in gifted programs, special education, career and technology courses, whether the student had a college plan, and
whether he was at risk of dropping out. The estimates also control for high school characteristics in the year of graduation:
the ethnic composition of the high school, the percentage of students in each economic status group, the percentage of gifted
students and students at risk, the percentage of title I eligible students, and total school enrollment.

41

Table 6: Quantile Treatment Eﬀects of College Sector on Earnings - Texas A&M

Quantile
1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90
95
99

Baseline
(i)
0.364
[0.254, 0.499]
0.314
[0.267, 0.345]
0.279
[0.253, 0.304]
0.247
[0.226, 0.267]
0.214
[0.201, 0.231]
0.205
[0.192, 0.219]
0.208
[0.196, 0.220]
0.209
[0.199, 0.222]
0.213
[0.202, 0.225]
0.215
[0.202, 0.225]
0.218
[0.207, 0.228]
0.215
[0.206, 0.224]
0.211
[0.200, 0.221]
0.206
[0.196, 0.217]
0.194
[0.183, 0.204]
0.187
[0.175, 0.196]
0.181
[0.172, 0.192]
0.177
[0.166, 0.190]
0.178
[0.163, 0.194]
0.201
[0.180, 0.224]
0.192
[0.152, 0.240]

1996-1998
Cohort
(ii)
0.422
[0.234, 0.642]
0.242
[0.185, 0.306]
0.231
[0.203, 0.265]
0.200
[0.172, 0.225]
0.178
[0.153, 0.199]
0.171
[0.151, 0.187]
0.181
[0.162, 0.197]
0.191
[0.176, 0.205]
0.207
[0.190, 0.220]
0.221
[0.206, 0.237]
0.229
[0.215, 0.246]
0.231
[0.216, 0.247]
0.226
[0.209, 0.241]
0.219
[0.203, 0.233]
0.208
[0.190, 0.224]
0.195
[0.178, 0.211]
0.187
[0.167, 0.205]
0.186
[0.161, 0.205]
0.191
[0.166, 0.213]
0.234
[0.194, 0.265]
0.173
[0.086, 0.258]

HS Fixed
Eﬀects
(iii)
0.315
[0.214, 0.452]
0.300
[0.250, 0.368]
0.285
[0.253, 0.325]
0.254
[0.229, 0.277]
0.227
[0.211, 0.246]
0.211
[0.197, 0.227]
0.209
[0.195, 0.224]
0.212
[0.202, 0.227]
0.215
[0.203, 0.230]
0.223
[0.210, 0.239]
0.228
[0.217, 0.241]
0.223
[0.213, 0.237]
0.223
[0.213, 0.237]
0.218
[0.209, 0.231]
0.210
[0.200, 0.221]
0.203
[0.192, 0.213]
0.195
[0.183, 0.205]
0.189
[0.176, 0.202]
0.187
[0.169, 0.202]
0.207
[0.182, 0.235]
0.206
[0.166, 0.255]

Family Background Sample
Without BackWith Background Variables ground Variables
(iv)
(v)
0.360
0.367
[0.143, 0.505]
[0.154, 0.515]
0.341
0.341
[0.262, 0.411]
[0.262, 0.415]
0.314
0.310
[0.256, 0.363]
[0.251, 0.357]
0.292
0.291
[0.245, 0.318]
[0.244, 0.317]
0.253
0.253
[0.228, 0.279]
[0.228, 0.278]
0.238
0.238
[0.214, 0.265]
[0.214, 0.265]
0.226
0.225
[0.205, 0.251]
[0.204, 0.250]
0.222
0.221
[0.203, 0.238]
[0.202, 0.238]
0.212
0.211
[0.196, 0.231]
[0.194, 0.230]
0.211
0.209
[0.194, 0.228]
[0.192, 0.227]
0.213
0.211
[0.199, 0.227]
[0.195, 0.226]
0.207
0.205
[0.192, 0.221]
[0.189, 0.219]
0.209
0.206
[0.192, 0.223]
[0.190, 0.221]
0.196
0.193
[0.182, 0.213]
[0.180, 0.209]
0.189
0.186
[0.175, 0.204]
[0.173, 0.202]
0.182
0.178
[0.166, 0.195]
[0.162, 0.193]
0.176
0.172
[0.162, 0.191]
[0.158, 0.188]
0.175
0.170
[0.154, 0.190]
[0.150, 0.187]
0.166
0.163
[0.146, 0.186]
[0.141, 0.183]
0.165
0.163
[0.140, 0.201]
[0.136, 0.198]
0.184
0.182
[0.134, 0.247]
[0.134, 0.241]

College
Attendees
(vi)
0.398
[0.299, 0.516]
0.370
[0.319, 0.413]
0.359
[0.328, 0.394]
0.320
[0.299, 0.340]
0.292
[0.276, 0.311]
0.264
[0.251, 0.283]
0.252
[0.241, 0.266]
0.247
[0.235, 0.260]
0.243
[0.231, 0.254]
0.243
[0.232, 0.258]
0.244
[0.234, 0.257]
0.240
[0.231, 0.250]
0.232
[0.221, 0.244]
0.226
[0.216, 0.237]
0.210
[0.201, 0.220]
0.197
[0.188, 0.206]
0.193
[0.182, 0.204]
0.184
[0.175, 0.198]
0.176
[0.161, 0.191]
0.198
[0.175, 0.223]
0.170
[0.138, 0.206]

All
Earnings
(vii)
0.101
[-0.120, 0.346]
0.300
[0.210, 0.382]
0.295
[0.240, 0.351]
0.300
[0.257, 0.332]
0.271
[0.250, 0.292]
0.251
[0.234, 0.269]
0.225
[0.211, 0.243]
0.220
[0.206, 0.233]
0.218
[0.205, 0.231]
0.221
[0.211, 0.235]
0.223
[0.209, 0.234]
0.221
[0.208, 0.233]
0.218
[0.206, 0.229]
0.212
[0.200, 0.229]
0.203
[0.192, 0.213]
0.191
[0.180, 0.202]
0.184
[0.174, 0.197]
0.186
[0.173, 0.201]
0.180
[0.165, 0.196]
0.185
[0.170, 0.202]
0.182
[0.143, 0.228]

The table shows quantile treatment eﬀect estimates with the bounds of bootstrapped 95% conﬁdence intervals in brackets.
All models control for quartics in the state math, reading and writing tests as well as each student’s relative rank in their
high school on each exam, student ethnicity/race, Title I status, English proﬁciency, free and reduced price lunch status,
enrollment in gifted programs, special education, career and technology courses, whether the student had a college plan, and
whether he was at risk of dropping out. The estimates also control for high school characteristics in the year of graduation:
the ethnic composition of the high school, the percentage of students in each economic status group, the percentage of gifted
students and students at risk, the percentage of title I eligible students, and total school enrollment.

42

Table 7: Quantile Treatment Eﬀects of College Sector on Earnings - Community College

Quantile
1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90
95
99

Baseline
(i)
-0.098
[-0.203, 0.055]
-0.132
[-0.192, -0.090]
-0.193
[-0.226, -0.162]
-0.207
[-0.229, -0.185]
-0.197
[-0.216, -0.174]
-0.177
[-0.198, -0.160]
-0.156
[-0.174, -0.144]
-0.136
[-0.151, -0.124]
-0.120
[-0.133, -0.107]
-0.101
[-0.114, -0.091]
-0.086
[-0.095, -0.075]
-0.072
[-0.082, -0.059]
-0.059
[-0.070, -0.047]
-0.048
[-0.059, -0.036]
-0.037
[-0.049, -0.025]
-0.030
[-0.043, -0.018]
-0.019
[-0.032, -0.008]
-0.014
[-0.026, 0.000]
-0.008
[-0.019, 0.004]
0.015
[0.002, 0.029]
-0.040
[-0.070, -0.004]

1996-1998
Cohort
(ii)
-0.291
[-0.455, -0.114]
-0.194
[-0.307, -0.106]
-0.223
[-0.288, -0.139]
-0.232
[-0.263, -0.182]
-0.206
[-0.227, -0.168]
-0.177
[-0.202, -0.147]
-0.150
[-0.170, -0.127]
-0.129
[-0.147, -0.106]
-0.112
[-0.127, -0.091]
-0.092
[-0.112, -0.070]
-0.064
[-0.082, -0.045]
-0.047
[-0.062, -0.026]
-0.036
[-0.051, -0.018]
-0.022
[-0.039, -0.003]
-0.014
[-0.030, 0.008]
-0.016
[-0.034, 0.007]
-0.019
[-0.037, 0.002]
-0.030
[-0.049, -0.007]
-0.038
[-0.062, -0.008]
-0.039
[-0.063, -0.013]
-0.212
[-0.289, -0.138]

HS Fixed
Eﬀects
(iii)
-0.113
[-0.228, 0.120]
-0.130
[-0.180, -0.068]
-0.197
[-0.233, -0.155]
-0.206
[-0.233, -0.181]
-0.205
[-0.222, -0.182]
-0.185
[-0.200, -0.164]
-0.165
[-0.177, -0.148]
-0.141
[-0.155, -0.124]
-0.128
[-0.140, -0.113]
-0.112
[-0.127, -0.100]
-0.092
[-0.104, -0.081]
-0.076
[-0.090, -0.063]
-0.064
[-0.076, -0.053]
-0.050
[-0.064, -0.037]
-0.039
[-0.053, -0.024]
-0.028
[-0.041, -0.016]
-0.020
[-0.036, -0.007]
-0.017
[-0.032, -0.003]
-0.011
[-0.028, 0.001]
0.012
[-0.006, 0.030]
-0.043
[-0.080, -0.008]

College
Attendees
(iv)
-0.076
[-0.192, 0.035]
-0.061
[-0.109, -0.032]
-0.099
[-0.125, -0.064]
-0.121
[-0.141, -0.101]
-0.123
[-0.145, -0.098]
-0.129
[-0.146, -0.096]
-0.126
[-0.142, -0.101]
-0.124
[-0.138, -0.108]
-0.119
[-0.130, -0.101]
-0.115
[-0.125, -0.099]
-0.113
[-0.123, -0.099]
-0.104
[-0.112, -0.092]
-0.095
[-0.104, -0.085]
-0.086
[-0.096, -0.075]
-0.078
[-0.090, -0.068]
-0.072
[-0.082, -0.062]
-0.068
[-0.077, -0.058]
-0.058
[-0.068, -0.049]
-0.050
[-0.060, -0.038]
-0.038
[-0.051, -0.025]
-0.045
[-0.072, -0.013]

All
Earnings
(v)
0.142
[-0.089, 0.319]
-0.092
[-0.158, -0.011]
-0.095
[-0.138, -0.054]
-0.140
[-0.173, -0.108]
-0.147
[-0.179, -0.124]
-0.153
[-0.174, -0.129]
-0.133
[-0.153, -0.118]
-0.123
[-0.138, -0.107]
-0.106
[-0.120, -0.089]
-0.092
[-0.105, -0.079]
-0.075
[-0.086, -0.061]
-0.061
[-0.073, -0.049]
-0.049
[-0.060, -0.037]
-0.036
[-0.047, -0.027]
-0.023
[-0.035, -0.014]
-0.017
[-0.029, -0.004
-0.005
[-0.017, 0.006]
0.004
[-0.009, 0.017]
0.015
[0.001, 0.027]
0.034
[0.015, 0.051]
0.011
[-0.024, 0.044]

The table shows the quantile treatment eﬀects for each school type with the bounds of the 95% conﬁdence intervals
that are calculated using 250 bootstrap replications in brackets. The table shows quantile treatment eﬀect estimates
with the bounds of bootstrapped the 95% conﬁdence intervals in brackets. All models control for quartics in the state
math, reading and writing tests as well as each student’s relative rank in their high school on each exam, student
ethnicity/race, Title I status, English proﬁciency, free and reduced price lunch status, enrollment in gifted programs,
special education, career and technology courses, whether the student had a college plan, and whether he was at risk of
dropping out. The estimates also control for high school characteristics in the year of graduation: the ethnic composition
of the high school, the percentage of students in each economic status group, the percentage of gifted students and
students at risk, the percentage of title I eligible students, and total school enrollment.

43

Table 8: Average Residual Log Earnings by
Major from Male College Graduates
in Texas
Major
Agriculture
Liberal Arts
Social Science
Communication
Math/Computer Science
Science
Business
Engineering

Mean
0.008
-0.293
-0.105
-0.242
0.091
-0.020
0.112
0.234

Std. Deviation
0.514
0.642
0.622
0.632
0.569
0.650
0.545
0.529

The table shows the mean and standard deviation of residualized log earnings among male college graduates from all schools
in Texas. The log wage residuals are the same as those used to
generate the quantile treatment eﬀects.

44

Figure 1: Distribution of Log Earnings in the 2000 Census Among BA Recipients of College Age
5 Years Prior by Location of Residence 5 Years Prior and by State of Current Residence

12

Panel A: Austin MSA
Out of Texas

6

8

Log Earnings
10

In Texas

0

10

20

30

40

50
60
Percentile

70

80

90

100

80

90

100

90

100

12

Panel B: College Station MSA
Out of Texas

7

8

Log Earnings
9
10

11

In Texas

0

10

20

30

40

50
60
Percentile

70

Panel C: All Other Areas of Texas
Out of Texas

4

6

Log Earnings
8
10

12

In Texas

0

10

20

30

40

50
60
Percentile

70

80

Each panel shows log earnings distributions for respondents 23-26 years old with a BA in the 2000 Census who reported living
in the Austin MSA (Panel A), the College Station MSA (Panel B) or in any other part of Texas (Panel C) in 1995. Among
those who reported living in each area in 1995, the ﬁgures show log earnings distributions by whether the respondent lives in
Texas in 2000 or not.

45

Figure 2: Distribution of Propensity Scores Among Treated and Control Observations by School
Treatment Type

Panel A: UT−Austin
2031

1625

1187

649

329

35

886

345

84

10

0

1644

2328

2146

−10000

4587

−30000

−20000

10626

29185

0

.2

.4
.6
Propensity Score
UT−Austin

.8

1

Other four−year public

5000

Panel B: TAMU
3312

3221

2361

2558
1055

811

0

103
69

−5000

900
3062

−15000 −10000

6398

10061
13081
14298

0

.2

.4
Propensity Score

TAMU

.6

Other Four−year Public

5000

Panel C: Community College
3345

3121

2437

1797

1254

959

477

565

176

30

0

1717

−20000−15000−10000 −5000

1456
3250
7181

15690
19525

0

.2

.4
.6
Propensity Score

Community College

.8

1

Other Four−year Public

Each panel shows propensity score distributions from estimation of equation (8) in the text for each treatment school type and
non-ﬂagship universities. Each set of bars show the estimated probability of graduating from the treatment school relative to
non-ﬂagship schools, separately by the type of school from which the individual actually graduated. The range of the bars in
each panel are constrained by the conﬁdentiality agreement we signed for data use that restricts any reported results to be
based on 10 or more observations.

46

Figure 3: Observed and Counterfactual Earnings Distributions, by School Type

2

Panel A: UT−Austin
Other 4 Year−Counterfactual

−2

Log Earnings Residual
−1
0
1

UT Austin−Observed
Other 4 Year−Observed

0

10

20

30

40

50
60
Percentile

70

80

90

100

2

Panel B: Texas A&M
Other 4 Year−Counterfactual

−2

Log Earnings Residual
−1
0
1

TAMU−Observed
Other 4 Year−Observed

0

10

20

30

40

50
60
Percentile

70

80

90

100

2

Panel C: Community Colleges
Other 4 Year−Counterfactual

−2

Log Earnings Residual
−1
0
1

Community College−Observed
Other 4 Year−Observed

0

10

20

30

40

50
60
Percentile

70

80

90

100

Source: Authors’ calculations from the University of Texas at Dallas Education Research Center data and administrative
earnings records as described in the text. Each earnings distribution consists of 99 percentile cut-points from the empirical
cumulative distribution. The other 4 year counterfactual distribution is the re-weighted other 4 year distribution, where the
weights are estimated from equation (8) in the text.

47

Figure 4: Quantile Treatment Eﬀects of College Sector Choice on Earnings

−.3

−.2

Log Earnings Residual
−.1
0
.1
.2

.3

.4

Panel A: UT−Austin

0

10

20

30

40

50
60
Percentile

70

80

90

100

80

90

100

80

90

100

−.3

−.2

Log Earnings Residual
−.1
0
.1
.2
.3

.4

Panel B: Texas A&M

0

10

20

30

40

50
60
Percentile

70

−.3

−.2

Log Earnings Residual
−.1
0
.1
.2

.3

.4

Panel C: Community Colleges

0

10

20

30

40

50
60
Percentile

70

Source: Authors’ calculations from the University of Texas at Dallas Education Research Center data and administrative
earnings records as described in the text. Each estimated point is the diﬀerence between the observed earnings at each
percentile for UT-Austin (Panel A), Texas A&M (Panel B) and community colleges (Panel C) and the associated earnings
at that percentile from the counterfactual earnings distribution. The dotted lines show the bounds of the 95% conﬁdence
intervals for each percentile point. The horizontal dashed lines show the 95% conﬁdence interval of the mean eﬀect from the
“All Controls” speciﬁcation in Table 4.

48

Figure 5: Distribution of Majors at UT-Austin and Texas A&M

UT−Austin

Texas A&M

Agriculture
Business
Communication
Engineering
Liberal Arts
Math/Comp. Sci
Science
Social Science
0

5

10

15
Percent

20

Source: Authors’ calculations from the University of Texas at Dallas Education Research Center data.

49

25

Figure 6: Quantile Treatment Eﬀects of Four-year College Sector Choice on Earnings, Including
College Major Controls

0

.1

Log Earnings Residual
.2
.3
.4

.5

Panel A: UT−Austin

0

10

20

30

40

50
60
Percentile

70

80

90

100

80

90

100

0

.1

Log Earnings Residual
.2
.3
.4

.5

Panel B: Texas A&M

0

10

20

30

40

50
60
Percentile

70

Source: Authors’ calculations from the University of Texas at Dallas Education Research Center data and administrative
earnings records as described in the text. Each estimated point is the diﬀerence between the observed earnings at each percentile
for UT-Austin (Panel A) and Texas A&M (Panel B) and the associated earnings at that percentile from the counterfactual
earnings distribution. The dotted lines show the bounds of the 95% conﬁdence intervals for each percentile point. The
horizontal dashed lines show the 95% conﬁdence interval of the mean eﬀect, calculated using all observables as well as college
major controls.
50

Figure 7: Quantile Treatment Eﬀects of Graduating from UT-Austin on Earnings by Race

−.1

0

Log Earnings Residual
.1
.2
.3

.4

Panel A: White

0

10

20

30

40

50
60
Percentile

70

80

90

100

70

80

90

100

70

80

90

100

70

80

90

100

−.5

Log Earnings Residual
0
.5
1

1.5

Panel B: Black

0

10

20

30

40

50
60
Percentile

0

Log Earnings Residual
.2
.4
.6

.8

Panel C: Asian

0

10

20

30

40

50
60
Percentile

−.4

Log Earnings Residual
−.2
0
.2

.4

Panel D: Hispanic

0

10

20

30

40

50
60
Percentile

Source: Authors’ calculations from the University of Texas at Dallas Education Research Center data and administrative
earnings records as described in the text. Each estimated point is the diﬀerence between the observed earnings at each
percentile for UT-Austin (Panel A), Texas A&M (Panel B) and community colleges (Panel C) and the associated earnings at
that percentile from the counterfactual earnings distribution. The dotted lines show the bounds of the 95% conﬁdence intervals
for each percentile point. The horizontal dashed lines show the 95% conﬁdence interval of the mean eﬀect from Table 4.

51

Figure 8: Quantile Treatment Eﬀects of Graduating from Texas A&M - College Station on Earnings by Race

0

.1

Log Earnings Residual
.2
.3
.4

.5

Panel A: White

0

10

20

30

40

50
60
Percentile

70

80

90

100

70

80

90

100

70

80

90

100

70

80

90

100

0

Log Earnings Residual
.5
1

1.5

Panel B: Black

0

10

20

30

40

50
60
Percentile

0

.2

Log Earnings Residual
.4
.6
.8

1

Panel C: Asian

0

10

20

30

40

50
60
Percentile

−.2

Log Earnings Residual
0
.2
.4

.6

Panel D: Hispanic

0

10

20

30

40

50
60
Percentile

Source: Authors’ calculations from the University of Texas at Dallas Education Research Center data and administrative
earnings records as described in the text. Each estimated point is the diﬀerence between the observed earnings at each
percentile for UT-Austin (Panel A), Texas A&M (Panel B) and community colleges (Panel C) and the associated earnins at
that percentile from the counterfactual earnings distribution. The dotted lines show the bounds of the 95% conﬁdence intervals
for each percentile point. The horizontal dashed lines show the 95% conﬁdence interval of the mean eﬀect from Table 4.

52

Figure 9: Quantile Treatment Eﬀects of Graduating from a Community College on Earnings by
Race

−.2

Log Earnings Residual
−.1
0
.1

.2

.3

Panel A: White

0

10

20

30

40

50
60
Percentile

70

80

90

100

70

80

90

100

70

80

90

100

70

80

90

100

−.4

−.2

Log Earnings Residual
0
.2
.4

.6

Panel B: Black

0

10

20

30

40

50
60
Percentile

−.6

−.4

Log Earnings Residual
−.2
0
.2

.4

Panel C: Asian

0

10

20

30

40

50
60
Percentile

−.4

−.3

Log Earnings Residual
−.2
−.1
0

.1

Panel D: Hispanic

0

10

20

30

40

50
60
Percentile

Source: Authors’ calculations from the University of Texas at Dallas Education Research Center data and administrative
earnings records as described in the text. Each estimated point is the diﬀerence between the observed earnings at each
percentile for UT-Austin (Panel A), Texas A&M (Panel B) and community colleges (Panel C) and the associated earnins at
that percentile from the counterfactual earnings distribution. The dotted lines show the bounds of the 95% conﬁdence intervals
for each percentile point. The horizontal dashed lines show the 95% conﬁdence interval of the mean eﬀect from Table 4.

53

Table A-1: Quantile Treatment Eﬀects of College Sector on Earnings by Race/Ethnicity – Graduates

Quantile
1
5
10
20
30
40
50
60
70
80
90
95
99

Quantile
1
5
10
20
30
40
50
60
70
80
90

White
(i)
0.118
[-0.054, 0.320]
0.039
[-0.053, 0.117]
0.021
[-0.032, 0.074]
0.049
[0.022, 0.079]
0.090
[0.067, 0.106]
0.111
[0.088, 0.132]
0.140
[0.122, 0.156]
0.168
[0.148, 0.187]
0.181
[0.164, 0.199]
0.187
[0.169, 0.209]
0.220
[0.196, 0.253]
0.315
[0.270, 0.356]
0.289
[0.222, 0.348]

Panel A: UT-Austin
Black
Asian
(ii)
(iii)
0.601
0.423
[-0.304, 1.385]
[-0.053, 0.727]
0.175
0.171
[-0.094, 0.978]
[-0.013, 0.529]
0.018
0.095
[-0.189, 0.371]
[-0.012, 0.302]
0.061
0.136
[-0.112, 0.236]
[0.020, 0.223]
0.024
0.105
[-0.089, 0.117]
[0.032, 0.156]
-0.017
0.123
[-0.088, 0.060]
[0.073, 0.185]
-0.017
0.160
[-0.100, 0.052]
[0.118, 0.206]
0.030
0.180
[-0.104, 0.091]
[0.121, 0.216]
0.061
0.168
[-0.032, 0.117]
[0.121, 0.206]
0.042
0.172
[-0.021, 0.123]
[0.123, 0.211]
0.028
0.184
[-0.053, 0.152]
[0.124, 0.237]
0.136
0.227
[-0.045, 0.432]
[0.152, 0.298]
0.184
0.288
[-0.136, 0.604]
[-0.058, 0.378]

Hispanic
(iv)
-0.247
[-0.762, 0.033]
-0.092
[-0.256, 0.148]
-0.035
[-0.149, 0.110]
-0.045
[-0.100, 0.014]
0.007
[-0.040, 0.052]
0.025
[-0.002, 0.059]
0.044
[0.012, 0.078]
0.070
[0.032, 0.108]
0.081
[0.044, 0.127]
0.091
[0.051, 0.134]
0.069
[0.033, 0.109]
0.104
[0.044, 0.177]
0.332
[0.089, 0.476]

Panel B:
White
(i)
0.367
[0.255, 0.514]
0.309
[0.256, 0.370]
0.290
[0.259, 0.317]
0.225
[0.210, 0.241]
0.216
[0.205, 0.231]
0.222
[0.210, 0.235]
0.224
[0.212, 0.234]
0.216
[0.204, 0.228]
0.196
[0.183, 0.207]
0.181
[0.171, 0.195]
0.178

Texas A&M - College Station
Black
Asian
(ii)
(iii)
0.988
0.433
[0.408, 1.521]
[-1.674, 0.966]
0.507
0.344
[0.063, 0.957]
[0.067, 0.725]
0.402
0.253
[0.109, 0.577]
[0.007, 0.446]
0.219
0.180
[0.130, 0.327]
[0.071, 0.295]
0.164
0.147
[0.064, 0.257]
[0.069, 0.243]
0.123
0.155
[0.039, 0.243]
[0.091, 0.237]
0.145
0.170
[0.059, 0.219]
[0.088, 0.248]
0.131
0.159
[0.074, 0.176]
[0.104, 0.241]
0.114
0.144
[0.047, 0.208]
[0.090, 0.231]
0.139
0.178
[0.055, 0.296]
[0.112, 0.243]
0.220
0.200

Hispanic
(iv)
0.161
[-0.166, 0.567]
0.256
[0.110, 0.463]
0.207
[0.094, 0.304]
0.169
[0.103, 0.215]
0.156
[0.112, 0.198]
0.163
[0.124, 0.196]
0.161
[0.131, 0.188]
0.179
[0.131, 0.218]
0.177
[0.141, 0.218]
0.173
[0.131, 0.221]
0.157

54

95
99

Quantile
1
5
10
20
30
40
50
60
70
80
90
95
99

[0.160, 0.195]
0.203
[0.179, 0.227]
0.186
[0.147, 0.244]

[0.099, 0.316]
0.182
[0.097, 0.402]
0.229
[-0.051, 0.637]

[0.129, 0.262]
0.156
[0.105, 0.247]
0.219
[0.040, 0.377]

Panel C: Community College
White
Black
Asian
(i)
(ii)
(iii)
-0.063
-0.091
-0.016
[-0.244, 0.297]
[-0.375, 0.546]
[-1.474, 0.380]
-0.121
-0.102
-0.199
[-0.192, -0.043] [-0.299, 0.090]
[-0.723, 0.358]
-0.176
-0.183
-0.290
[-0.222, -0.140] [-0.263, -0.056] [-0.649, 0.058]
-0.160
-0.157
-0.358
[-0.185, -0.141] [-0.212, -0.085] [-0.547, -0.113]
-0.124
-0.162
-0.281
[-0.142, -0.107] [-0.213, -0.098] [-0.467, -0.175]
-0.090
-0.150
-0.283
[-0.107, -0.077] [-0.201, -0.108] [-0.434, -0.175]
-0.060
-0.139
-0.240
[-0.073, -0.045] [-0.170, -0.095] [-0.409, -0.156]
-0.043
-0.093
-0.198
[-0.056, -0.029] [-0.138, -0.052] [-0.402, -0.120]
-0.032
-0.090
-0.157
[-0.048, -0.017] [-0.128, -0.053] [-0.377, -0.082]
-0.021
-0.082
-0.134
[-0.035, -0.010] [-0.121, -0.042] [-0.245, -0.067]
-0.010
-0.006
-0.107
[-0.027, 0.008]
[-0.059, 0.065] [-0.180, -0.056]
0.002
0.074
-0.074
[-0.016, 0.026]
[-0.011, 0.130]
[-0.182, 0.030]
-0.091
0.155
-0.063
[-0.133, -0.033]
[0.028, 0.248]
[-0.150, 0.011]

[0.116, 0.211]
0.196
[0.114, 0.290]
0.287
[0.130, 0.425]

Hispanic
(iv)
-0.125
[-0.344, 0.046]
-0.135
[-0.238, 0.057]
-0.215
[-0.297, -0.131]
-0.262
[-0.301, -0.199]
-0.192
[-0.234, -0.132]
-0.151
[-0.176, -0.114]
-0.125
[-0.151, -0.089]
-0.091
[-0.107, -0.057]
-0.045
[-0.060, -0.023]
-0.009
[-0.031, 0.012]
0.021
[-0.008, 0.055]
0.030
[0.001, 0.063]
0.058
[-0.036, 0.092]

The table shows the quantile treatment eﬀects for each school type by race/ethnic group
with the bounds of the 95% conﬁdence intervals that are calculated using 250 bootstrap
replications in brackets.

55

Table A-2: Quantile Treatment Eﬀects of College Sector on Earnings by Race/Ethnicity – Attendees

Quantile
1
5
10
20
30
40
50
60
70
80
90
95
99

Quantile
1
5
10
20
30
40
50
60
70
80
90

White
(i)
0.096
[-0.076, 0.327]
0.091
[0.012, 0.125]
0.097
[0.039, 0.148]
0.110
[0.086, 0.142]
0.125
[0.104, 0.150]
0.131
[0.111, 0.160]
0.166
[0.148, 0.190]
0.186
[0.170, 0.206]
0.190
[0.176, 0.209]
0.193
[0.176, 0.214]
0.216
[0.191, 0.245]
0.297
[0.257, 0.345]
0.290
[0.220, 0.331]

Panel A: UT-Austin
Black
Asian
(ii)
(iii)
0.203
0.663
[-0.719, 1.140]
[0.182, 1.084]
0.388
0.351
[0.084, 0.691]
[0.075, 0.606]
0.254
0.135
[0.029, 0.477]
[0.033, 0.342]
0.241
0.130
[0.114, 0.355]
[0.054, 0.232]
0.129
0.112
[0.033, 0.246]
[0.060, 0.174]
0.108
0.132
[0.027, 0.186]
[0.079, 0.204]
0.041
0.153
[-0.007, 0.124]
[0.104, 0.200]
-0.009
0.159
[-0.054, 0.123]
[0.118, 0.199]
0.055
0.154
[-0.040, 0.162]
[0.115, 0.191]
0.077
0.141
[-0.003, 0.133]
[0.102, 0.182]
0.027
0.121
[-0.078, 0.123]
[0.064, 0.194]
0.083
0.147
[-0.047, 0.248]
[0.078, 0.239]
0.313
-0.055
[-0.018, 2.301]
[-0.110, 0.185]

Hispanic
(iv)
-0.123
[-0.898, 0.178]
-0.012
[-0.176, 0.189]
0.111
[0.011, 0.211]
0.063
[0.003, 0.144]
0.077
[0.026, 0.137]
0.080
[0.046, 0.121]
0.082
[0.038, 0.122]
0.094
[0.057, 0.132]
0.111
[0.073, 0.139]
0.109
[0.076, 0.140]
0.073
[0.048, 0.125]
0.120
[0.055, 0.183]
0.235
[0.024, 0.389]

Panel B:
White
(i)
0.409
[0.309, 0.547]
0.355
[0.311, 0.414]
0.365
[0.332, 0.393]
0.295
[0.278, 0.314]
0.259
[0.244, 0.273]
0.250
[0.238, 0.261]
0.253
[0.242, 0.266]
0.238
[0.227, 0.251]
0.211
[0.202, 0.223]
0.194
[0.184, 0.203]
0.180

Texas A&M - College Station
Black
Asian
(ii)
(iii)
0.599
0.695
[-2.349, 1.181]
[0.226, 1.116]
0.256
0.381
[-0.014, 0.611]
[0.097, 0.661]
0.364
0.258
[0.081, 0.594]
[0.056, 0.450]
0.373
0.212
[0.214, 0.485]
[0.090, 0.270]
0.253
0.135
[0.183, 0.362]
[0.054, 0.230]
0.214
0.173
[0.133, 0.317]
[0.070, 0.227]
0.221
0.149
[0.121, 0.300]
[0.078, 0.198]
0.198
0.115
[0.112, 0.260]
[0.061, 0.185]
0.156
0.115
[0.112, 0.251]
[0.054, 0.182]
0.182
0.132
[0.086, 0.299]
[0.055, 0.196]
0.232
0.129

Hispanic
(iv)
0.229
[-0.128, 0.575]
0.287
[0.113, 0.528]
0.307
[0.211, 0.431]
0.267
[0.191, 0.326]
0.232
[0.184, 0.274]
0.199
[0.157, 0.233]
0.201
[0.172, 0.235]
0.192
[0.154, 0.235]
0.193
[0.160, 0.230]
0.173
[0.140, 0.211]
0.162

56

95
99

Quantile
1
5
10
20
30
40
50
60
70
80
90
95
99

[0.164, 0.195]
0.203
[0.176, 0.227]
0.179
[0.143, 0.213]

[0.098, 0.353]
0.242
[0.086, 0.357]
0.205
[-0.192, 0.655]

[0.057, 0.191]
0.074
[-0.014, 0.201]
-0.082
[-0.269, 0.182]

Panel C: Community College
White
Black
Asian
(i)
(ii)
(iii)
-0.165
0.025
-0.143
[-0.249, -0.052] [-0.230, 0.232]
[-0.552, 0.254]
-0.167
-0.108
-0.068
[-0.199, -0.103] [-0.243, 0.041]
[-0.317, 0.163]
-0.192
-0.074
-0.173
[-0.208, -0.118] [-0.152, 0.014] [-0.297, -0.019]
-0.174
-0.088
-0.159
[-0.193, -0.154] [-0.013, -0.022] [-0.285, 0.074]
-0.147
-0.083
-0.208
[-0.163, -0.136] [-0.118, -0.041] [-0.290, -0.059]
-0.131
-0.089
-0.190
[-0.144, -0.118] [-0.128, -0.062] [-0.264, -0.117]
-0.102
-0.100
-0.208
[-0.113, -0.092] [-0.133, -0.075] [-0.254, -0.141]
-0.080
-0.095
-0.199
[-0.091, -0.069] [-0.119, -0.073] [-0.240, -0.140]
-0.069
-0.093
-0.173
[-0.081, -0.060] [-0.116, -0.070] [-0.227, -0.117]
-0.055
-0.098
-0.181
[-0.069, -0.046] [-0.125, -0.072] [-0.235, -0.128]
-0.042
-0.075
-0.135
[-0.055, -0.027] [-0.092, -0.057] [-0.209, -0.087]
-0.026
-0.037
-0.143
[-0.041, -0.009] [-0.066, -0.005] [-0.205, -0.035]
-0.053
0.013
-0.218
[-0.092, -0.008] [-0.069, 0.086]
[-0.416, 0.102]

[0.121, 0.192]
0.179
[0.101, 0.240]
0.224
[0.055, 0.367]

Hispanic
(iv)
-0.118
[-0.295, 0.148]
-0.024
[-0.093, 0.036]
-0.021
[-0.078, 0.023]
-0.079
[-0.110, -0.042]
-0.107
[-0.134, -0.078]
-0.100
[-0.122, -0.076]
-0.100
[-0.124, -0.077]
-0.110
[-0.128, -0.089]
-0.099
[-0.113, -0.081]
-0.080
[-0.097, -0.062]
-0.069
[-0.100, -0.044]
-0.061
[-0.085, -0.031]
-0.057
[-0.083, -0.018]

The table shows the quantile treatment eﬀects for each school type by race/ethnic group
with the bounds of the 95% conﬁdence intervals that are calculated using 250 bootstrap
replications in brackets.

57

