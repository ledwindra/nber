NBER WORKING PAPER SERIES

HOSPITAL CHOICES, HOSPITAL PRICES AND FINANCIAL INCENTIVES TO
PHYSICIANS
Kate Ho
Ariel Pakes
Working Paper 19333
http://www.nber.org/papers/w19333
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2013

We thank Mark Shepard, Lucia Tian Tian and Zach Brown for excellent research assistance. Thanks
to participants at numerous seminars and to four helpful referees for their comments and suggestions.
All remaining errors are our own. We declare that we have no relevant or material financial interests
that relate to the research described in this paper. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2013 by Kate Ho and Ariel Pakes. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

Hospital Choices, Hospital Prices and Financial Incentives to Physicians
Kate Ho and Ariel Pakes
NBER Working Paper No. 19333
August 2013, Revised April 2014
JEL No. I11,L1
ABSTRACT
We estimate an insurer-specific preference function which rationalizes hospital referrals for privatelyinsured births in California. The function is additively separable in: a hospital price paid by the insurer,
the distance traveled, and plan and severity-specific hospital fixed effects (capturing hospital quality).
We use an inequality estimator that allows for errors in price and detailed hospital-severity interactions
and obtain markedly different results than those from a logit. The estimates indicate that insurers with
more capitated physicians are more responsive to price. Capitated plans send patients further to utilize
similar-quality lower-priced hospitals; but the cost-quality trade-off does not vary with capitation rates.
Kate Ho
Columbia University
Department of Economics
1133 International Affairs Building
420 West 118th Street
New York, NY 10027
and NBER
kh2214@columbia.edu
Ariel Pakes
Department of Economics
Harvard University
Littauer Room 117
Cambridge, MA 02138
and NBER
apakes@fas.harvard.edu

Hospital Choices, Hospital Prices and Financial Incentives to
Physicians
Kate Ho and Ariel Pakes
February 2014

Abstract
We estimate an insurer-speci…c preference function which rationalizes hospital referrals for
privately-insured births in California. The function is additively separable in: a hospital price
paid by the insurer, the distance traveled, and plan and severity-speci…c hospital …xed e¤ects
(capturing hospital quality). We use an inequality estimator that allows for errors in price and
detailed hospital-severity interactions and obtain markedly di¤erent results than those from a
logit. The estimates indicate that insurers with more capitated physicians are more responsive
to price. Capitated plans send patients further to utilize similar-quality lower-priced hospitals;
but the cost-quality trade-o¤ does not vary with capitation rates.

The Patient Protection and A¤ordable Care Act of 2010 includes provisions to establish Accountable Care Organizations (ACOs) in the Medicare program. These are groups of health care
providers that o¤er services to a large number of patients and are eligible to share in any cost
savings they achieve for the Medicare program1 . Private sector ACOs are forming in parallel to
this initiative, often with very similar structures and payment arrangements. The proportion of
savings ACOs keep is linked to their performance on quality standards. The goal of the initiative
is to reduce health care costs in both Medicare and private insurance and to improve coordination
of care. The tying of cost savings to quality standards is designed to mitigate the concern that an
increase in incentives to control costs might lead to a decrease in the quality of care.
The health policy literature has noted that similar cost control incentives are currently utilized
by some health maintenance organizations (HMOs) in California and elsewhere.2 In this paper
we investigate the impact of these incentives on the cost and quality of care provided to patients,
focusing in particular on the choice of hospital for privately insured patients giving birth. We use
Ho: Economics Department, Columbia University, 420 West 118th Street, New York NY 10027,
kh2214@columbia.edu.
Pakes: Economics Department, Harvard University, Cambridge MA 02138,
apakes@fas.harvard.edu. We thank Mark Shepard, Lucia Tian Tian and Zach Brown for excellent research
assistance. Thanks to participants at numerous seminars and to four helpful referees for their comments and
suggestions. All remaining errors are our own. We declare that we have no relevant or material …nancial interests
that relate to the research described in this paper.
1
See Berwick (2011) and Department of Health and Human Services (November 2012).
2
See, for example, Hammelman et al (2009).

1

hospital discharge data for managed care enrollees from California in 2003 to estimate a hospital
referral model which posits that referrals are a plan speci…c function of the prices insurers pay to
the hospitals, distance from home to hospital, and a severity-speci…c measure of “hospital quality”.
The results are used …rst to study the relationship between referrals to hospitals, hospital prices,
and di¤erences in the cost-control incentives used by di¤erent insurers. We then re…ne our estimates
in a way that allows us to analyze how the implicit trade-o¤s between price, our severity-speci…c
measure of hospital quality, and distance di¤er with these incentives.
The question of whether patients enrolled in insurers that give physician groups an incentive to
control hospital costs are admitted to low-priced hospitals is important for several reasons. Hospital
costs make up more than 30% of national health care spending so our …ndings are potentially
important for the overall impact of ACOs on costs. Moreover any analysis of the e¤ect of hospital
mergers on hospital prices will require an assumption regarding the e¤ect of price increases on
referrals. Assuming away this e¤ect will likely result in an over-estimate of the price increases that
will result from a merger. Similarly a merger analysis that does not take into account price e¤ects
will likely over-estimate the merged entity’s incentives to invest in new high-cost technologies and
under-estimate its incentives to invest in cost-reducing technologies.
The process by which a patient chooses a hospital involves multiple players. Decisions are made
by referring physicians in consultation with their patients. Insurers often attempt to in‡uence
physician choices through direct …nancial incentives. In California in particular, they often remunerate the physician group through …xed (capitated) monthly payments per patient to cover the
cost of patient services3 . The most common type of capitation involves payments covering only services provided by the physician group but when this is the case "shared risk arrangements" almost
always apply, under which a target is set for total (including hospital) spending and cost savings
or overruns relative to the target are shared between the physician group and the insurer. Less
commonly, global capitation payments cover the cost of all services received by patients, including
inpatient hospital stays. Both types of capitation contracts generate incentives for physician groups
to refer their patients to low-cost hospitals. Physician groups often pass the …nancial incentives on
to their member physicians, for example through pro…t-sharing arrangements and bonuses based
on costs per enrollee. They may also make physicians’promotion on the pay scale contingent (formally or informally) on their management of costs. Thus, if we assume that higher quality hospitals
negotiate higher prices, physicians in groups receiving capitation payments face a trade-o¤ between
incentives to reduce costs and other aspects of the choice such as quality of care and convenience.
Moreover the extent to which patients and/or doctors care about these factors is likely to vary with
the severity of illness.
The incentives for ACOs and for the California insurers in our data are similar in that the
provider group either bears the …nancial risk for hospital payments or bene…ts from hospital savings
relative to a benchmark4 . Also in both cases the incentives are based on the costs incurred by the
3

Several previous papers describe the contractual arrangements between insurers and physicians in California,
including Rosenthal et al (2001, 2002) and Grumbach et all (1998a and b).
4
The A¤ordable Care Act also introduces other provider payment mechanisms that are designed to control costs,

2

group (rather than by individual physicians), with no formal guidance on how these incentives are
passed down to individual physicians or patients. Approximately 430 ACOs had been set up by
January 2013 (Muhlestein (2013)). The details of their payment arrangements are evolving over
time, but they all involve some form of shared savings when costs are less than a benchmark5 .
Their structure also varies: in 2013, 189 were integrated with a hospital system, while most of
the remainder were sponsored by physician groups which contracted with hospitals outside the
organization. We come back to some of the likely implications of our results for these distinctions
below.
Our analysis uses hospital discharge data to estimate an insurer-speci…c choice function which
rationalizes hospital referrals for women giving birth in California. Unfortunately our dataset does
not identify the physician referring each patient to her hospital; we therefore cannot directly observe
physician behavior. However we do observe each patient’s insurance carrier and the extent to which
each carrier uses capitation payments. In 2003 73% of payments made to primary physicians by the
six largest carriers in our data were capitation payments; the proportions varied substantially across
carriers from 97% for Paci…care to 38% for Blue Cross (more detail on the data underlying these
numbers is given below). We ask whether the observed referrals for patients whose insurers have
di¤erent capitation rates indicate di¤erent trade-o¤s between price, quality and patient convenience
factors. We view the allocation of a patient to a hospital as the outcome of a multi-stage process
that includes, for example, the patient’s choice of obstetrician and the obstetrician’s allocation to
a¢ liated hospitals as well as the obstetrician’s choice of hospital for the particular patient. We
do not model the protocol that leads to these choices; rather we estimate the relative weights on
di¤erent factors that emanate from that protocol and the extent to which these weights are related
to capitation rates.
The analysis builds on the previous literature on hospital demand. Previous papers consider
the factors a¤ecting patients’ hospital choices in some detail but almost exclusively make the
simplifying assumption that the hospital is chosen without regard for the price paid by the insurer.
To include the price variable one has to address three problems. First, the observed price is a
“list price” for the relevant hospital discharge. Prices actually paid by the insurer are discounted
versions of these list prices. To address this issue we import data on the average hospital discount
from hospital …nancial reports. The true discount could vary across insurers and we treat that
in two complementary ways: we allow for errors in our price variable and present results which
use additional data to estimate the variation in discounts across insurers. Second the expected
price that generates hospital choices is inherently unobservable. We assume that expectations are
on average correct, and construct a price variable which is the average realized price for patients
admitted with the same diagnosis and similar co-morbidities at that hospital. Those predictions
such as the replacement of fee-for-service payments with “bundled" payments where providers receive a …xed fee for
an episode of care rather than for each individual service. As noted by a referee, the e¢ cacy of these arrangements
is also likely to be a¤ected by the extent of capitation, but these relationships are beyond the scope of this paper.
5
See the Department of Health and Human Services (November 2012). Initial arrangements for Medicare ACOs
were largely based on shared savings with no requirement to share in any losses relative to the benchmark, but as
time passes they increasingly involve physician groups bearing at least some …nancial risk.

3

will have estimation error, but the estimation procedure we develop averages those errors out.6
The third problem relates to price endogeneity: the expected price for a patient with a particular
diagnosis is likely to be correlated with the unobserved hospital quality for that diagnosis. We
control for these unobservables by developing an estimation procedure which allows for hospital
…xed e¤ects that vary freely with severity of diagnosis.
We begin with a standard logit model for hospital choice. This does not allow for errors in the
price variable and has a limited ability to allow for hospital …xed e¤ects that vary with severity
of diagnosis. We expect the omission of hospital severity interactions to bias the price coe¢ cient
upwards, and measurement error in the price measure to bias the price coe¢ cient towards zero.
When we pool all delivery and birth discharges we obtain a positive and signi…cant coe¢ cient
on price. However, when we narrow the sample to more homogenous diagnosis groups the price
coe¢ cient becomes negative. We then allow the price coe¢ cient to vary by insurance carrier and
…nd that the carriers with the highest proportion of payments to physicians made through capitation
contracts have price coe¢ cients that are signi…cantly more negative than those of other carriers with
a higher proportion of fee-for-service contracts. Since neither endogeneity nor errors in variables
are fully addressed by this technique we doubt that the estimates obtained here accurately measure
the true responses to price.
So we develop a methodology that addresses these problems. It is based on revealed preference:
we assume that the hospital chosen for each patient is preferred to any of the other hospitals in
her choice set. The choice function is assumed to be additively separable in the price paid by the
insurer, distance, and an insurer and severity speci…c hospital quality. We identify pairs of patients
who have the same severity and are enrollees in the same insurer but who chose di¤erent hospitals.
By de…ning the alternative of each patient as the chosen hospital of the other and summing the
two patients’ inequalities, we di¤erence out the severity-speci…c hospital quality terms from the
utility equation. By averaging the resulting inequalities over patients and hospitals we eliminate
the e¤ects of errors in price measurement. The result is a relatively straightforward estimator of
bounds on the (normalized) price coe¢ cient.7
The estimates indicate that the price coe¢ cients are far more negative than in the logit analysis
and are ordered with respect to the plans’capitation rates. That is, the price paid by insurers to
hospitals does impact referrals, and the price response is more elastic for insurers whose physician
groups are more highly capitated. We show that these results are robust to a number of perturbations to the speci…cation used in the estimation. We then use the price coe¢ cients to back
out bounds on the plan, hospital, and severity speci…c quality terms and …nd them to be highly
6
Our baseline results assume no measurement error in distance. Later we consider a speci…cation which is robust
to errors generated by the distance between the centroids of our geographic areas and true locations, and …nd no
major di¤erence in results.
7
The analysis is similar in spirit to previous papers that match treatment to control groups based on observable
data and assume that unobserved information does not a¤ect response to treatment. The propensity score literature
(see Rosenbaum and Ruben (1983)), and di¤erence-in-di¤erences analyses more generally, fall into this category. A
di¤erence is that we base our estimates on averages of the moment inequalities implied by our model, as in Pakes,
Porter, Ho and Ishii (2011) and Pakes (2010).

4

correlated across plans. We therefore add structure and estimate a model where the quality terms
for the di¤erent plans are a¢ ne transforms of one another. This allows us to represent preferences
as a linear function of price, quality, and distance which di¤ers across plans only in the coe¢ cients
of these variables. We can then examine how the trade-o¤s between price, quality and distance
vary with capitation rates. Though in absolute value the price coe¢ cient varies directly with the
capitation rate, the ratio between the price and quality coe¢ cients, or trade-o¤ between price and
quality, is evaluated in much the same way across plans. In contrast the trade-o¤ between distance and price is evaluated di¤erently. That is highly capitated more price sensitive plans tend
to send their patients longer distances to obtain the same quality service at a lower price (but do
not trade-o¤ costs against quality di¤erently). To the extent that “hospital quality” is related to
health outcomes, we can examine the relationship of quality to capitation rates directly by importing data on measures of health outcomes for the mothers and infants into our data. Conditional on
patient severity, there is no evidence that capitation rates are related to any of our health outcome
measures.
The remainder of the paper is structured as follows. In Section I we discuss the relevant previous
literature. Section II describes important features of the market and Section III describes the data.
Section IV sets out the full model we wish to analyze, Sections V and VI summarize the restrictions
required for the logit and inequalities methods and set out their results, Section VII considers the
trade-o¤ between price, quality and distance, and Section VIII concludes.

I

Previous Literature

Two sets of previous papers are relevant for our analysis. The …rst, summarized by Glied (2000),
considers HMO gatekeeping and cost controls. Glied’s summary suggests that HMOs have lower
inpatient admissions and costs than other insurers; however these papers do not analyze the relationship between hospital price and referrals.8 There are a few more recent studies that consider
similar questions. For example, Cutler, McClellan and Newhouse (2000) compare the treatment
of heart disease in HMOs and traditional insurance plans and …nd that HMOs have 30% to 40%
lower expenditures. Virtually all the di¤erence comes from lower unit prices rather than di¤erences
in actual treatments. However they do not investigate whether price reductions are due to lower
negotiated prices within a hospital or to referring patients to cheaper hospitals (the focus of our
study). Gaynor, Rebitzer and Taylor (2004) look in more detail at how HMOs achieve cost savings.
They analyze physician responses to group-based …nancial incentive contracts within a single HMO.
They …nd that spending on medical utilization, particularly for outpatient services, increases with
the size of the physician group receiving group-based incentives. That is, spending is negatively
correlated with the power of incentives to limit these expenditures.9
8

More recent reviews by Chandra, Cutler and Song (2012) and McClellan (2011) come to similar conclusions.
Other recent papers considering the responsiveness of health care providers to …nancial incentives include
Ketcham, Leger and Lucarelli (2012), Limbrock (2011) and Bajari et al (2012).
9

5

There are also some papers evaluating recent initiatives that implement cost-control incentives
like those that may be used for Accountable Care Organizations. For example the Alternative
Quality Contract (AQC) was adopted by Blue Cross Blue Shield of Massachusetts in 2009. It
introduced physician incentives similar to those created by the global capitation contracts in our
data. Physician groups entered into …ve year global budget contracts under which they received a
budget per enrolled patient and were accountable for costs of all services provided to those patients,
including inpatient care. Song et al (2011) use a di¤erence-in-di¤erence analysis (where the …rst
di¤erence is across time and the second is between intervention and control groups) to analyze the
impact of this initiative. They …nd that, in the …rst year, it was associated with reduced growth
in spending on outpatient services and improved quality of care and that most of the savings came
from referring patients to lower-priced providers. We also conducted a preliminary analysis of the
response of the hospital referrals of physicians to capitation payments in Ho and Pakes (2011).
There we regressed a severity-adjusted price measure on the proportion of the insurer’s payments
to primary physicians that were capitated and market …xed e¤ects10 . The coe¢ cient on capitation
was negative and statistically signi…cant; consistent with the hypothesis that insurer capitation
payments in‡uence physician referrals. However, simple regressions like these cannot provide more
than suggestive evidence since they do not account for the trade-o¤s made between price, other
hospital characteristics, and convenience factors in the hospital choice equation.11
The second relevant literature estimates discrete choice models of hospital demand: see Gaynor
and Vogt (2000) for a survey.12 Almost all of these papers exclude the price paid by the insurer
to the hospital from the utility equation. One exception is Gaynor and Vogt (2003) which uses
assumptions to de…ne a single price index for each hospital that is included in the utility equation.
However, that paper assumes away interactions between patient and hospital characteristics in
determining procedures and therefore prices. It also does not consider the impact of physician
incentives on the price coe¢ cient.

II

Background on the Market

The analysis in this paper focuses on enrollees of health maintenance organizations (HMOs).13
The seven largest HMOs had 87% of the California HMO market at the end of 2002. Our analysis
focuses on six of these seven: we exclude Kaiser Permanente because the prices paid by this vertically
We adjusted for severity by constructing the following price ratio measure: 
=  where  was the hospital


price for patient  and  was the average of that variable for same-severity patients across all hospitals in the sample.
11
Duggan (2000) considers hospital referrals for Medicaid patients. He …nds that private hospitals in California
responded to new …nancial incentives to treat Medicaid patients by cream-skimming the most pro…table Medicaid
patients from publicly-owned hospitals. The reallocation was especially pronounced for pregnant women.
12
Examples include Luft et al (1990), Burns and Wholey (1992), Town and Vistnes (2001), Capps, Dranove and
Satterthwaite (2003)and Ho (2006), all of which either omit price entirely or include only the list price.
13
The 2003 California medical care market is described in detail in Baumgarten (2004). Several previous papers
describe the contractual arrangements between health plans and physicians in California, including Rosenthal et al
(2001) and Grumbach et al (1998a. and b.).
10

6

integrated insurer to its hospitals are not observed in our data.14
Each HMO contracts with a network of providers (physicians and hospitals); enrollees seek care
within that network. Each pregnant woman chooses an obstetrician from within the network and
is referred to one of the small number of network hospitals with which the obstetrician is a¢ liated.
Our analysis controls for any variation in networks across insurers by conditioning on the observed
provider network when estimating the choice equation15 . While HMOs could, in theory, further
in‡uence hospital referrals for their enrollees by requiring patient cost sharing for within-network
hospitals, in practice this is not usually the case. There are two exceptions. One is the use of
out-of-pocket payment schemes that require the consumer to share in hospital costs. Most out-ofpocket payments are fees (or co-pays) which would not a¤ect hospital choice since they are …xed
across hospitals and much smaller than hospital costs. However a minority of patients pay a coinsurance rate; i.e. a …xed percentage of hospital costs. Our data does not contain information
on co-insurance rates, but we know from industry reports that they were used by only a small
fraction of enrollees in 2003, and to the extent they were used, they were used disproportionately
by the low capitation insurers in our data set, and therefore do not explain our …ndings on the
di¤erences in price sensitivities across insurers16 . The second exception is the possible existence of
tiered networks. These are arrangements where insurers group hospitals into categories based on
costs and patients pay more for services from higher-cost hospitals. They were …rst introduced in
California in 2002-3. We do not observe the details of any tiered networks and so cannot condition
on them. However the available evidence indicates that only Blue Shield had more than 2% of its
enrollees in a tiered network. This and the fact that Blue Shield is the only not-for-pro…t insurer
in our data help explain the estimates below which, in turn, will induce us to treat Blue Shield
di¤erently in the rest of the paper17 .
HMOs in California do not generally use hospital payment mechanisms that provide incentives
either to control costs or improve quality. Most hospitals in California are paid by the insurance
carrier on a per service or per diem basis.18 Payment arrangements for physicians, in contrast, are
often structured to generate cost-control incentives. Most HMOs contract on a non-exclusive basis
14

The insurers we do consider are Blue Cross, Blue Shield, Health Net, Paci…care, Aetna and Cigna. Blue Cross
of California is independent of other Blue plans, including Blue Shield of California.
15
Melnick and Ketcham (2008) …nd that 55% of hospitals were include in an HMO’s network in California in 2003
on average. Ho (2006) …nds a higher proportion: 83% of hospitals were included on average in a sample of 43 large
markets (including seven in California) in the same year.
16
The Kaiser Family Foundation Employer Health Bene…ts Survey 2003 reports that 5% of covered workers in an
HMO paid a co-insurance rate for hospital admissions while 49% paid a deductible or copay; the remaining enrollees
paid neither. In contrast 14% of PPO enrollees paid a co-insurance rate, 26% paid a deductible or copay and the
remainder paid neither. Our data contains only HMO enrollees for four out of six insurers. However we note below
that for Blue Shield and Blue Cross only we observe admissions from PPO as well as HMO plans, since both are
included in the Knox Keene plan for these two insurers. Blue Shield (a not-for-pro…t) and Blue Cross have the lowest
capitation rates in our data. This use of patient cost-sharing is therefore negatively correlated with capitation, so
it is likely to bias our estimates towards …nding no di¤erence in price coe¢ cients between high- and low-capitation
insurers. See Section III and Online Appendix 1 for details.
17
Paci…care, Health Net and Blue Shield were the earliest adopters of tiered networks (in 2002) and only Blue
Shield made the tiered product mandatory for any employers. See Yegian (2003) and Robinson (2003) for details.
18
Hospital capitation payments existed but were uncommon in 2003. See Online Appendix 1 for more details.

7

with large physician groups,19 making capitated (…xed) monthly payments to the group for every
enrollee who uses it as his or her primary care clinic. The most common alternative is a fee-forservice payment arrangement. The extent of …nancial risk passed to the medical group varies across
capitated contracts. In around 20% of cases the monthly (“global capitation") payment covers all
services needed by the physician group’s patients including inpatient hospital stays. These physician
groups have a clear incentive to refer their patients to lower-cost hospitals. The remaining 80% of
capitation contracts involve payments that cover only the cost of services provided by physicians
within the group, perhaps with the addition of ancillary services like outpatient medical tests.
The HMO makes separate payments to hospitals for providing secondary care. However physician
groups again have incentives to control hospital costs because “shared risk arrangements" almost
always apply, under which a spending or utilization target is set and cost savings or overruns
relative to the target are shared between the physician group and the HMO.20 These arrangements
are very similar to the “shared savings" arrangements that are often instituted for Accountable
Care Organizations.
Our dataset does not distinguish between global and non-global capitation arrangements. We
investigate the extent to which referrals from physician groups with more highly capitated contracts
of any kind are more (or less) sensitive to price. We also do not observe the physician or physician
group referring each patient to a hospital. We do see the name of each patient’s insurer and the
percent of each insurer’s primary services and other medical professional services that are capitated.
In the analysis below we compare the importance of price in determining the hospital choice for
patients enrolled in high-capitation insurers to its importance for those in low-capitation insurers.
Our …nding that referrals from high capitation insurers tend to be to less costly hospitals could
be due to individual physicians referring capitated patients to cheaper hospitals and non-capitated
patients to others (which is consistent with Melichar, 2009), or to highly-capitated physician groups
using lower-priced hospitals on average. Physicians in more highly capitated physician groups could
use lower-priced hospitals either because they respond to incentives they face in those groups, or
because inherently cost conscious doctors gravitate towards high capitation groups. Our data does
not allow us to distinguish between these alternative mechanisms, although it is clear that more
highly capitated physician groups have increased incentives to make all their doctors aware of, and
responsive to, monetary trade-o¤s.
19

There are two types of physician groups: medical groups and Independent Practice Associations (IPAs). See
Online Appendix 1 for details.
20
Rosenthal et al (2001) note that 85-90% of non-global capitation revenues were generated from contracts with
shared hospital risk. Robinson and Casalino (2001) report similar …ndings. According to this literature, fee-for-service
contracts at the time of our data did not generally involve shared hospital risk arrangements.

8

III
A

The Dataset
Data Sources and the Price Measure

We use …ve datasets. The …rst is hospital discharge data covering all patient discharges from hospitals in California in the year 2003 from the state’s O¢ ce of Statewide Planning and Development
(OSHPD). This provides information on each patient’s zip code, demographic characteristics, health
insurer, the hospital chosen and patient diagnosis details: both the "principal" diagnosis recorded
as the major cause of admission and a list of up to 24 other diagnoses for each patient. We link this
to OSHPD hospital …nancial data, to the OSHPD Birth Cohort …le which contains outcome variables for both mother and infant, and to hospital characteristics data from the American Hospital
Association for 2003. Finally we have access to the State of California Department of Managed
Health Care Annual Financial Reporting Forms for 2003. These include balance sheets, income
statements and some information on enrollment, utilization and types of payment to providers for
all Knox Keene plans (essentially the same as HMOs) in California. We consider only birth and
delivery-related admissions records and only private Knox Keene enrollees.21 Our analysis covers
only the six largest insurers other than Kaiser Permanente: these make up approximately 90% of
the non-Kaiser observations in the data. We infer the hospital network of each insurer using the
discharge data by assuming that a hospital is in the network if at least 3 patients are admitted from
the particular insurer.22 Consistent with Kessler and McClellan (2000), we assume that patients
consider traveling up to 35 miles to visit a general hospital and up to 100 miles to visit a teaching
hospital.23
We do not observe the price charged to the insurer by the hospital, and, as a result, have to
construct our price variable. Our data does include the list price for every discharge. List prices
are a standard set of prices listed by hospitals in each year for all their services. All patients
are quoted the same list price for the same service. However, only uninsured patients and some
patients using an out-of-network provider are actually asked to pay the list price, and even they
are frequently o¤ered a discount by the hospital. Each insurance company has a contract with each
21

Knox Keene plans are de…ned as plans that are overseen by the California Department of Managed Health
Care (DMHC) and subject to the Knox Keene Act. They are not precisely the same as HMOs: while most insurers
designate only their HMO plans as Knox Keene plans, Blue Shield and Blue Cross PPO products were also included
in this category in 2003. We cannot distinguish between PPO and HMO enrollees for these two insurers at the
individual discharge level. Capitation rates are also reported for the full Knox Keene plan. This likely generates some
of the cross-insurer variation in capitation rates in the data. To account for the di¤erences between HMO and PPO
plan types we drop hospitals to which very few patients are admitted for these two insurers (thereby removing from
the data the hospitals that are most likely to be out-of-network). To the extent that we have not dropped all those
PPO patients who pay a coinsurance rate rather than a …xed copay, we bias our estimates against …nding a positive
relationship between price-sensitivity and capitation rates. This because Blue Shield and Blue Cross are the lowest
capitation insurers in our dataset. See discussion in Online Appendix 1 for details.
22
We check the implied network de…nitions against hand-collected data (described in detail in Ho (2006)) from
seven California markets in 2003. The de…nition is conservative: that is, the networks implied by our methodology
contain fewer hospitals than the networks in the hand-collected data and if an implied network contains a particular
hospital it is also included in the hand-collected data in the vast majority of cases.
23
We repeated the analysis using a 20 mile radius for low-risk pregnancies in Los Angeles, since a 35 mile radius
could be too large in this urban area. The results were very similar to those reported below. Still we note that our
market de…nitions may mask some remaining variation in the data.

9

provider in its network that de…nes the price it actually pays for services for its enrollees. We also
observe the average negotiated discount at the hospital level, calculated as the total contractual
adjustments from private managed care payors divided by the total charges (the sum of list prices
for all inpatient and outpatient episodes) for the relevant hospital-year. Both variables are recorded
in the hospital’s …nancial statements24 .
The price we need to construct is the price that the decision-makers expect to pay for a patient
entering the hospital in a given condition, de…ned below by a combination of diagnosis, age, and
comorbidity information known at the time the patient is admitted to the hospital. We assume
that expected prices are on average correct, and construct a baseline price variable as the average
realized list price for a given condition in a particular hospital multiplied by 1 minus the average
hospital discount. Since the estimation methodology we rely on for our conclusion averages over
agents, any remaining expectational error should average out when we sum across severities.25
We demonstrate below that there is meaningful variation in this price measure both across
patients admitted with di¤erent conditions and across hospitals for a given condition. However,
it is clearly subject to measurement problems. There is a trade-o¤ between aggregation error, if
our groups of similar patients for the expected list price calculation are de…ned too broadly, and
measurement error if they are too narrow implying small sample problems. We return to this issue
below. There may also be speci…cation error since we observe the discount at the hospital rather
than the hospital-insurer level.26 We examine the robustness of our results to speci…cation error
in the price variable in Section VI and Online Appendix 2. There we use additional data on the
share of each hospital’s total inpatient revenues coming from each insurer to estimate a model of
the discount as a function of hospital, insurer and market characteristics. We then repeat our
inequalities analysis using price measures derived from the estimated discount, and …nd only minor
di¤erences in our results.

B

Summary Statistics

Tables 1 and 2 set out summary data on the six insurers included in the analysis; data for Kaiser
are also included for comparison. These data give a broader picture of the insurers we consider
than can be provided by our speci…c dataset. Since the e¤ect of capitation payments on the price
coe¢ cient will be identi…ed from variation across these six insurers, our goal here is to summa24

The fee-for-service arrangement is not the only way hospitals are reimbursed. Per diem and DRG or case-based
payments are also possible: see Online Appendix 1 for details. In principle we have the right average discount
regardless of the form of reimbursement since contractual adjustments are de…ned as the sum of charges for the
hospital’s private managed care patients less its total revenue for those patients. However since the discount applies
to all such patients and we only analyze Knox Keene inpatient labor and delivery admissions, there may be some error
in it. In our main analysis we average over patients in di¤erent hospitals which, under assumptions to be speci…ed
below, addresses the measurement error issue.
25
Gaynor and Vogt (2003) use a similar methodology, de…ning price as the observed list price multiplied by 1
minus the average discount.
26
Speci…cation error may also be generated because the observed discount is an average for both inpatient and
outpatient services and for all managed care payors (including Point of Service plans) rather than just for Knox Keene
inpatient events. An examination of the robustness of our results to this source of error is given in Section VI and
Online Appendix 2.

10

rize the di¤erences between them on other relevant dimensions. Table 1 provides enrollment data,
showing that of the insurers we consider, Blue Cross and Blue Shield have the largest commercial
plan enrollment while Aetna and Cigna have the smallest. Every insurer in our dataset has over
70% of its enrollment in commercial plans. The fourth column of Table 1 lists the number of
delivery discharges included in our analysis for each plan; the breakdown is approximately proportionate to the commercial enrollment numbers. The …rst column of Table 2 lists the percent of
each Knox Keene insurer’s primary services that are capitated.27 There is considerable dispersion
across insurers, from Paci…care with 97% capitated payments to Blue Cross with 38%. The simple
correlation between percent capitation and premiums is negative (around -0.44), consistent with
more highly-capitated insurers having lower hospital costs and therefore lower prices28 . The rest of
the table demonstrates that insurers with a high percent of capitated payments are not obviously
di¤erent from other insurers on several observable dimensions. In particular, inpatient utilization
and prescription drug costs are not highly correlated with capitation rates. That is to the extent
that these variables re‡ect which types of patients choose which insurers, this suggests that patient
selection into insurers is not related to capitation rates.
******Tables 1 and 2 approximately here******
Blue Shield and Blue Cross, which have the lowest proportion of capitated payments, were
historically di¤erent from other insurers. They were 501(c)(4) tax exempt as social welfare plans,
acting as administrators of Medicare and providing coverage to state and federal government employees. By 2003, however, Blue Cross and Blue Shield companies were franchisees, independent
of the association and each other. They were no longer tax exempt and could be for-pro…t corporations. In California Blue Cross was an investor-owned for-pro…t organization with a lower
medical loss ratio (de…ned as medical and hospital expenses divided by premium revenues for the
whole insurer) and similar inpatient utilization to other insurers in the market. Blue Shield was
still quite di¤erent from the other insurers we consider. It was the only not-for-pro…t company we
analyzed and had relatively high inpatient utilization …gures (although its premiums and medical
loss ratio were quite low). As a result Blue Shield’s administrators and physicians may have been
less receptive to …nancial incentives than those of other insurers, an issue we return to below.
27

Capitation payments for primary professional services are de…ned in the Knox Keene insurers’Annual Financial
Statements as "capitation costs incurred by the reporting entity to primary care physicians, dentists and other
professionals for the delivery of medical services". They include capitation payments to obstetricians. The statements
also record capitation payments for other medical professional services, de…ned as including, for example, services
provided by optometrists, nurses, ambulance drivers and technicians.
28
The simple correlations from our main dataset (described in detail below) also have the same qualitative features
as our …ndings. The simple correlation between the weighted average distance traveled and insurer percent capitation
(where the average is taken across severity groups and the weight is the number of Blue Cross patients in the relevant
severity) is 0.57. The correlation between the weighted average price paid to hospitals and the percent capitation is
-0.22. Both correlations are consistent with enrollees in higher-capitation insurers traveling further to access lowerpriced hospitals. However patient locations and insurers’ hospital networks, both of which are endogenous to the
supply side of the market, will a¤ect these correlations. The full model set out below conditions on these aspects of
the environment and then provides a quantitative analysis of how the trade-o¤ between price and distance is related
to capitation.

11

Table 3 provides summary statistics on the discharges in the dataset. There are 88,157 patients
and 195 hospitals.29 There are 38 hospitals in the average patient’s choice set. 27% of discharges are
from teaching hospitals. The average price paid (approximated as list price*(1-average discount)) is
$4,317 for birth admissions. The average length of stay is 2.5 days. The importance of the distance
between the patient’s home and her hospital is clear from the raw data. The average distance
between a patient and a hospital in her choice set is 24.6 miles; the average distance to the chosen
hospital is 6.7 miles. Distance will be an important variable in the utility equation estimated
below.
******Table 3 approximately here******
The table also records means for three potential measures of outcomes: death while in hospital,
transfer to an acute care setting (at this hospital or a di¤erent hospital) and transfer to a skilled
nursing facility (again at either this or a di¤erent hospital). These are useful inputs to an initial
investigation of the patterns in the data although we will not use them in our full model. The
average probability of each event is low for delivery admissions: 0.01% for death, 0.3% for acute
care transfer and 1.5% for transfer to a skilled nursing facility.
Table 4 demonstrates that the variation in price and in outcomes across patient ages and
comorbidities is intuitive. Here we add both data on infant outcome variables and data that follows
both mother and baby over time which enables us to calculate the probability of readmission within
a 12 month period30 . We also aggregate the probabilities of death, acute care transfer and skilled
nursing facility transfer into a single probability of discharge to a location other than home.
******Table 4 approximately here******
Comparing older to younger women who give birth, we …nd that the delivery episodes of women
who are aged over 40 are signi…cantly more expensive and that these older women have higher
probabilities of readmission within 12 months and of discharge to “other than home" than younger
women. Also the infants of the older woman incur signi…cantly larger hospital expenses and are
signi…cantly more likely to be discharged to “other than home”. Interestingly infant readmission
probabilities are not signi…cantly di¤erent across these two groups31 .
29

This is the sample used for the logit analysis. We follow the previous literature by accounting for all hospitals
in the choice set for that analysis. Average discount data is missing for some hospitals; we …ll it in using regression
analysis. We exclude these hospitals from the inequalities analysis because only pairwise comparisons between
hospitals on which we have complete price information are required for the inequality estimation procedure. For
similar reasons we also exclude the small number of hospitals reporting more than 5% capitated revenues. We are
left with 64,691 patients and 157 hospitals. Using this smaller sample for the logits has no qualitative e¤ect on the
estimates.
30
The data are taken from the OSHPD Birth Cohort File for 2003. All summary statistics are very similar to
those of our main dataset.
31
Our price sensitivity analysis includes only the expenses charged to the mother. Infant health, and therefore
expected expenses, are generally not known when the hospital is chosen and therefore are not relevant for this part of
the analysis. However hospital quality for the infant as well as the mother should be an input to the hospital choice.
So we consider both infant and maternal outcomes in Section VII where we ask whether health outcomes di¤er by
insurer (conditional on severity).

12

We use the Charlson score (Charlson et al, 1987) as a measure of patient severity: this assigns
integer-valued weights (from 0 to 6) to comorbidities other than principal diagnosis where higher
weights indicate higher severity. The weights are summed to generate a single integer-valued index.
For example, patients with comorbidities indicating that they have diabetes or mild liver disease
would receive a Charlson score of 1; those with renal disease or any malignancy would have a
Charlson score of 2; those with a metastatic solid tumor or AIDS would have a Charlson score
of 6. A patient with both diabetes and renal disease would have a score of 3. The index was
developed by physicians and is widely used to measure severity based on diagnoses listed in patient
records. Table 4 indicates that women with higher Charlson scores in our data, and their infants,
had more costly deliveries and higher probabilities of adverse outcomes than women with lower
Charlson scores. All of these di¤erences are signi…cant at p=0.05. Our main analysis will allow
the Charlson score, interacted with other severity measures such as age and principal diagnosis, to
a¤ect preferences for di¤erent hospitals.

IV

The Model

As noted the hospital chosen is a result of a complex decision process. The woman …rst chooses
an obstetrician, typically with knowledge of which hospitals the obstetrician can admit patients to,
and then the obstetrician, in consultation with the patient, chooses among the hospitals where he
(or she) has admitting privileges. We assume this process generates an ordering of the hospitals in
the insurer’s network which is derived from the patient’s and doctor’s preferences. The patient’s
preferences are a¤ected by the distance from her home to the hospital, her assessment of the
severity of her condition, and by the hospital’s characteristics (some of which we, the researchers,
may not have measures of). The physician’s choice is in‡uenced by the patient’s preferences, their
assessment of the severity of the patient’s condition and the quality of the hospital services for that
severity, and the price charged by the hospital to the insurer. The potentially observable part of
the hospital referral function whose maximum determines the hospital () that patient  of insurer
is allocated to, is assumed to take the additively separable form

i;

(1)



=

p;

(   ) +  ( ()  ) +  ((   ))

where
(   ) is the price insurer

is expected to pay at hospital  for a patient who enters in

condition (which includes diagnosis)  ,
 is a measure of the severity of the patient’s condition,
 () is a vector of perceived qualities of hospital , one for each di¤erent severity,

13

 ( ()  ) is the plan and severity speci…c function which determines the impact of the
quality of a hospital for the given severity on the choice of hospitals, and
 is patient i’s location,  is hospital h’s location, ( ) provides the distance between the two
locations, and  ( ) is an increasing function of that distance which may di¤er by plan.
for  = 1     

 ,

 = 1     , and

= 1     . The condition of the patient on admission

(our  ) will determine the expected price associated with that admission at di¤erent hospitals and
therefore will sometimes be referred to as the price group. The severity groups ( ) are aggregates of
the admission conditions  (so there is variance in price conditional on severity). Both these terms
are de…ned based on information in the discharge data. Their precise de…nitions di¤er somewhat
across estimation strategies and will be de…ned below32 . Also when implementing these alternative
estimation strategies we will have to add an unobserved (or disturbance) term whose properties
will be assumed to di¤er across those strategies.
In its most general form, which will be our preferred form, the function  ( ) is allowed to di¤er
arbitrarily: across plans, among sickness levels for a given hospital, and across hospitals. This
allows particular hospitals to have higher quality for some diagnoses and/or sickness levels than
for others. So di¤erent aspects of a hospital’s characteristics can be di¤erentially important for
hospital choice for di¤erent severities33 . It also permits physicians to di¤er in their intensity of
preferences for quality relative to price and distance when considering patients of di¤erent sickness
levels, and allows the referral process in di¤erent insurers to di¤er in both the quality assessment
of hospitals and the weight given to quality relative to price and distance. Finally keep in mind
that the ordering implicit in equation (1) is an outcome of a decision making protocol that involves
both the physicians’ and the patients’ preferences, so the analysis allows for patient (as well as
physician) di¤erences across plans.
For some of the speci…cations we will have to constrain  ( ) to be a parametric function of
patient and hospital characteristics. To the extent that the parametric assumption does not capture
all the variance in  ( ) the residual variance will create an additional unobservable that may bias
the other parameters of interest. In particular if the “unobserved quality” represented by this
residual is correlated with price we would expect it to cause a positive bias in the price coe¢ cient.
This is the reason that our preferred mode of analysis starts by not constraining  ( ) in any way.
Only after estimating the price coe¢ cients for each plan do we come back to asking whether there
are constraints that the hospital-severity-plan speci…c quality estimates seem to satisfy.
32
In the main analysis, which is the inequality analysis in Section VI, severity groups (our  ) are de…ned by unique
combinations of age, principal diagnosis, and other factors observed in the discharge data including the severity rank
(de…ned on a scale from 1 to 3 by obstetrical experts) of the most serious comorbidity in the patient’s discharge
record. Price groups (our  ) are severity groups subdivided by the number of most seriously-ranked comorbidities.
See Section VI for details.
33
For example, Goldman and Romley (2008) …nd evidence that amenities such as food quality and sta¤ attentiveness play an important role in hospital demand, and their relative importance in the hospital choice equation may
di¤er by severity of illness.

14

V

Logit Analysis

We begin with a multinomial logit model of hospital choice, as it provides a familiar starting point
for investigating the patterns in the data. The logit model makes the following assumptions.
(   ) =

(2)

 
  (  )

where  (  ) is the average list price of patients who enter hospital  with condition  and




is

one minus the average discount rate hospital  gives managed care providers,
 ( ()  ) =  +  ( )

(3)

where  are hospital …xed e¤ects, ( ) are functions of the sickness level of the patient and  are
hospital characteristics, both of which are speci…ed below, and
 ((   )) =

(4)
Adding the disturbance i;
(5)

i;



=

p;

 ,

1 (   )

+

2
2 (   ) 

and substituting into equation (1) the logit model becomes

(   ) +  ( ()  ) +

1 (   )

+

2
2 (   )

+ i;

 

The properties of the model are completed by assuming our composite agent knows i;



at the

time the hospital choice is made, and the vector of disturbances has a distribution, conditional on
the other right hand side variables, which is i.i.d. Type 1 extreme value. Notice that since we have
not indexed an “outside” option, the logit analysis conditions on women who only consider giving
birth at a hospital. We estimate this model using maximum likelihood.
We consider three di¤erent assumptions regarding the price coe¢ cient
(6)

()

p;

=

;

()

p;

=

p;

;

()

p;

=

0

+

p;

, in the estimation

1 

where  is the insurer’s capitation rate.
Equation (2) states that the price is exactly equal to our measure of the expected list price for the
patient’s diagnosis multiplied by one minus the observed average discount. I.e. this speci…cation
assumes no measurement or expectational error in price. We de…ne the expected list price to
be the average list price for the particular hospital over patients in categories de…ned by unique
combinations of: age (categories 11-19, 20-39, 40-49 and 50-64), principal diagnosis (21 categories
for women giving birth including, for example, “normal delivery", “previous Cesarean Section" and
“early labor"), Charlson score and diagnosis generating the Charlson score. Both principal diagnosis
and Charlson score are based only on diagnoses known on admission. We are constrained to using

15

these fairly broad de…nitions of similar patients because we encounter small sample problems when
we de…ne narrower groups. To the extent that either the aggregation generates measurement error in
our price measure, and/or the small cell sizes generate estimation error in our estimate of expected
price, we expect an attenuation bias in the estimated price coe¢ cient.
Equation (3) restricts the  ( ) term in a way consistent with the previous literature: we assume
it is determined by a hospital …xed e¤ect plus interactions between hospital characteristics and
patient characteristics that are known on admission and expected to be correlated with severity.
In the inequalities analysis below we de…ne over 100 patient severity groups and allow these to
freely interact with hospital …xed e¤ects. We can not do this in the logit analysis because it would
imply estimating almost 20,000 coe¢ cients and a similar number of expected price terms (without
error), putting us in a range of values where an incidental parameter problem, similar to that
described in Neyman and Scott (1948), would make coe¢ cient estimates very unreliable. So we
assume the interaction terms are determined by linear interactions between hospital and consumer
diagnostic characteristics. Included in  are the number of nurses per bed and indicators for
teaching hospitals, for-pro…t hospitals and hospitals that o¤er transplant services (a proxy for
high-tech hospitals). We also include a measure of the quality of delivery and birth services taken
from Ho (2006): hospitals were rated on a scale from 0 to 1, where 0 indicated that no delivery/birth
services were provided and a higher rating indicated that a less common (assumed to be highertech) service was o¤ered. The patient characteristics in  are the expected probabilities of death
in hospital and of transfer to acute care setting or skilled nursing facility given the patient’s age
group, principal diagnosis and Charlson score.
While these interactions, like those used in the previous literature, are sensible given the constraints imposed by the methodology, we do not expect them to be su¢ cient to fully address the
price endogeneity issue noted above. To the extent they do not there will be an error in the
approximation in equation (3) so that equation becomes
 ( ()  ) =  +  ( ) +  ( ()  )
The logits assume  ( ()  )

0. If this is not the case and hospital quality is both regarded

as more important for more severely ill women and is positively correlated with hospital price,
we expect this error to bias the price coe¢ cient upwards. Note, however, that if we restrict the
analysis to a subsample of the data which only contains women with similar severities, i.e. for
whom 

 , then when estimating the logit on this subsample the e¤ect of severity is almost

captured by the hospital …xed e¤ect (it would be captured if severity was exactly the same for all
women in the subsample). So a separate analysis for women with similar severities should mitigate
this source of omitted variable bias.
The logit analysis assumes that both the distance coe¢ cient and the quality-severity interaction terms do not vary across insurers. We begin the analysis of all the subsamples we consider
by assuming a common price coe¢ cient across insurers, and then provide separate results where
this coe¢ cient di¤ers across insurers, paying particular attention to the relationship of the price
16

coe¢ cient to the insurer’s capitation rate. After presenting the results from the full sample, we
provide another set of results which partially controls for the omitted variation in patient-severity
hospital-quality interactions by restricting our attention to the least sick patients in our data. For
comparison we also estimate separately on the rest of the sample, a group with a more diverse set of
severity conditions. As noted we do not have enough data to obtain meaningful results if we allow
for hospital-severity speci…c …xed e¤ects, but we can push the subsampling a bit further by looking
at the results from subsamples that have only the largest six severity groups in both less-sick and
sicker subsamples of the data set.

A

Logit Results

A summary of the results is reported in Table 5. The price coe¢ cients, price interaction terms and
distance coe¢ cients are reported, together with the sample size, for each speci…cation. In each case
the distance coe¢ cient is negative and highly signi…cant, with a magnitude that is consistent with
estimates from the previous literature34 .
******Table 5 approximately here******
The price coe¢ cient from the full sample of delivery/birth discharges is positive and signi…cant
with a t-value of approximately 5. Recall that we would expect a positive bias in that coe¢ cient if
high priced hospitals were high quality hospitals, and the severity-hospital interactions we included
were not su¢ cient to control for hospital quality conditional on the severities that determined
hospital choice. To see if this might be the source of a problem, the next column provides the results
from the same speci…cation when we restrict the sample to the least-sick women. We identi…ed
these women with the help of obstetrical experts at Columbia Presbyterian hospital. They are the
subset of patients who are aged 20-39, have a Charlson score of 0, and whose principal diagnosis
and comorbidities were de…ned by the obstetricians to be “routine". Our sample contains 43,742 of
these patients. Since they have similar severities we would expect there to be less variance across
patients in the importance of hospital quality di¤erences, and this should mitigate the omitted
variable bias.
When we use the sample of less sick women, the price coe¢ cient becomes negative (magnitude
-0.017) and marginally signi…cant (standard error 0.009). The same speci…cation on the subsample
with the sickest patients, the group of patients where we think the quality severity interactions are
likely to be both more variant and more important in determining hospital choice, yields a positive
price coe¢ cient again (of .012), and this time with a t-value that increases to 6 (despite the fact
that this subsample is only about half the size of the full sample). We conclude that we need a
better way to control for hospital quality/patient severity interactions.
Next we look for interactions between price and insurer …xed e¤ects. Insurers in the table are
sorted by declining proportion of capitated payments to primary physicians. When we use the
34

See, for example, Gaynor and Vogt (2003) and Ho (2006).

17

sample with the least sick patients, Blue Cross and Blue Shield, the plans which have the lowest
proportions of capitated payments, have small, positive and insigni…cant price coe¢ cients. All
four of the remaining insurers have price coe¢ cients less than 0. The negative price coe¢ cients
are signi…cant for Paci…care and Health Net, two of the three carriers that favor capitation the
most (97% of payments for Paci…care and 80% for Health Net). The remaining carriers, Aetna and
Cigna, have relatively small sample sizes (6291 and 8097 birth discharges respectively, compared
to 15,479 for Paci…care and 16,950 for Health Net), which helps explain the larger standard errors
on their price coe¢ cients. When we remove the price-insurer interactions and instead include an
interaction between price and the percent capitation in the insurer, the price coe¢ cient is positive
and the interaction term negative with almost twice the magnitude of the price coe¢ cient. Both
are highly signi…cant; the t-value of the capitation interaction is 7.7.
When we do the same exercise with the subsample of sicker patients, the price-insurer interaction
term is still negative for Paci…care, although insigni…cant at p=0.05 and smaller in magnitude than
for the healthier population. All other insurers’ price coe¢ cients are positive and three out of
…ve are statistically signi…cant, again pointing to the need for a better way to control for hospital
quality/patient severity interactions. The third speci…cation, including a price-percent capitation
interaction, again generates a positive price coe¢ cient and a negative interaction term (implying
that insurers that favor capitated payments generate physician referrals that are more price-based
than those of other physicians). However, the magnitudes are much smaller than for the least sick
sample and the implied overall price coe¢ cient is positive even for insurers with 100% capitated
payments to primary physicians.
Online Appendix 3 takes the logit analysis one step further. We now restrict our attention to
the six largest severities in either the less-sick or the sicker subsample of patients. The incidental
parameters problem prevents us going further than this: indeed we have to use only the four largest
markets, in which the number of patients per hospital-severity is relatively large, to obtain these
estimates35 . The …rst column for each subsample (sick and less-sick) sets out the estimates in a
speci…cation identical to that in column 1 of Table 5 except that we remove the squared distance
term, since this makes the results more comparable to the inequalities analysis, and include only
the four largest markets. As in Table 5 the price coe¢ cient for the less-sick sample is negative
and insigni…cant while that for the sicker sample is positive and very signi…cant. We also report
results that include an interaction between price and the percent capitation of the insurer. As
before the interaction term is negative and signi…cant in both samples, but for the less-sick sample
it is much larger than the price coe¢ cient (price coe¢ cient 0.10, price-capitation interaction -0.17)
while for the sicker sample the two coe¢ cients are essentially the same magnitude (0.03 and -0.03
respectively).
The next set of results for each subsample drops all but the six largest severities. This has very
little impact on the less sick sample (we lose only 10% of observations) but a marked e¤ect on the
35

The four largest markets are Los Angeles, Orange, San Diego and the Bay Area. We use the same severity
de…nitions as in the inequalities analysis in Section VI.

18

sick sample (we lose 65% of the original sample). Accordingly, and because the less-sick sample
is already fairly homogenous in terms of severity, restricting to the six largest less-sick severities
has very little e¤ect on the estimates. However in the sicker sample the price coe¢ cient moves
from positive and signi…cant to negative (although still insigni…cant). When we go further with
these subsamples and allow the price coe¢ cient to di¤er across insurers by including an interaction
between price and percent capitation, the price-capitation interaction for the sicker sample triples
in value when we include only the six largest severities, from -.034 (.010) to -.092 (.038), and is
now quite a bit larger than the price coe¢ cient which is .059 (.033).
There were too few patients per hospital-severity pair for us to restrict the logit sample to a
smaller number of severities36 . However we did use a related procedure to investigate whether
measurement error in price was likely to also pose a problem for logit estimators. In particular we
repeated the analysis of the six largest severities using only the hospital-severity pairs with more
than 30 observations. Since the variance of the measurement error should be inversely proportional
to the number of patients, dropping the small hospital-severity pairs ought to mean dropping those
pairs with the most problematic price measures. Restricting the subsamples for the six largest
severities in this way excluded about 15% of the less sick subsample, but about half of the sicker
subsample. For both subsamples the uninteracted price coe¢ cient changed very little, but once we
allowed insurers to di¤er in their price response by including a price-percent capitation interaction,
in both subsamples the price coe¢ cient became more positive and the price-capitation interaction
more negative and both were highly signi…cant. Most noticeably the price-capitation interaction
for the sicker population tripled in value once again and the price e¤ects in the sick and less sick
samples became similar: the less sick sample had a price coe¢ cient 0.162 (.028), and a pricecapitation interaction -0.250 (.025), while the sicker sample had a price coe¢ cient 0.183 (.073),
and a price-capitation interaction -0.264 (.053). By now, however, we had dropped over 65% of
our original sample and still had reason to believe we had not fully eliminated either the omitted
variables or the errors in variables bias.
Before leaving the logit analysis we go back to the full sample of the least sick patients and
look for the implications of the logit results on the relative magnitudes of the distance and price
e¤ects. Consider …rst the distance coe¢ cient. We calculate the impact of a one mile increase in
distance for hospital , holding all else …xed, on the probability that a particular patient  visits
that hospital. We then take the average over patients and a weighted average over hospitals. The
average e¤ect of the one mile distance increase is a 13.7% reduction in the probability that the
hospital is chosen37 . Next we conduct a similar exercise to evaluate the magnitude of the price
36
More formally for consistency in this speci…cation we require the number of observations for each hospital to
grow large and this is not a reasonable approximation for samples based on a single severity group. In addition, since
there have to be multiple price groups in each analysis, use of the separate logit …xed e¤ect analysis for each severity
group would require us to use more detailed price groups than in the logits reported here and therefore accentuate
the price measurement problem.
37
The average distance to the chosen hospital for the less-sick patients included in the sample is 6.45 miles; the
standard deviation is 10.11 miles. The weighted average probability that a particular hospital is chosen is 2.7%,
where the weight is the number of discharges.

19

e¤ect. Consider Paci…care’s referrals for its least sick patients; the insurer with the most negative
estimated price coe¢ cient. The implied average e¤ect of a $1000 increase in a hospital’s price,
holding all other prices constant, is a 5.2% reduction in the probability that the hospital is chosen.
So the price increase we would require in order to compensate for a one mile increase in distance
would be approximately $2,600. This is more than two thirds the average price for the less-sick
patients (which is $3380 and has a standard deviation of $1870.) All the other insurers’ price
coe¢ cients are considerably less negative, implying a considerably larger price distance trade-o¤.
These numbers, together with the results we obtain when we use subsamples, accentuate our worry
that omitted variables and errors in observed variables may be causing important biases in the logit
estimators.

VI

Inequalities

As noted we are worried that the logit analysis does not fully control for variation in quality conditional on severity and that this might cause a positive bias in the price coe¢ cient. In addition
that analysis compels us to use average prices within quite broadly-de…ned patient groups because
narrower groups would increase the variance in our estimated price accentuating the impact of
measurement error in price. The estimates in Table 5 and Online Appendix 3 show that restricting
the sample to relatively similar severity groups, and dropping hospital-severity pairs where measurement error is likely to be large, has the expected e¤ects on the estimates. However we cannot
fully address either omitted variable bias or measurement error in a multinomial logit framework.
We now provide an alternative estimation technique that addresses both issues38 .
The method is based on a revealed preference inequality: it is assumed that the chosen hospital is
preferred to feasible alternative hospitals. Consider again the referral function in equation (1 ) where
patients are assigned to detailed severity groups  (the same groups used to de…ne samples in Online
Appendix 3) and price groups  . We consider all couples of same-insurer, same-severity patients
whose chosen hospitals di¤er but both of whose choices were feasible for both agents. Within each
couple we sum the inequalities obtained from the fact that each patient’s choice is preferred to
the choice made for the other. Since the severity-hospital interactions from the two inequalities
are equal but opposite in sign, when we sum the inequalities the interaction terms di¤erence out.
Revealed preference implies that this sum is positive, and this constrains the remaining parameters.
More formally let  ( 0  ) be the set of patients from plan
 but had hospital

0

with severity  who chose hospital

in their choice set. For notational simplicity let

for  =  ( ) or price, and let

(  0 ) =  ¬ 0

 (    0 ) =  ((   )) ¬  ((  0 )) provide the di¤erence

between the distance from patient 0  home to hospitals  and 0 . Then the observable part of our
38
In addition to the logits reported above we also tried Chamberlain (1980)’s conditional likelihood estimator.
At least under particular distributional assumptions this addresses the absence of quality controls, though not the
measurement error in price. However the conditional likelihood estimator is not suitable for our problem because
its computational burden grows as the combinatorial formula for the number of ways the total patients in a severity
group can be divided among the hospitals conditional on the given number of patients (in the severity group) and
hospitals. The number of patients and hospitals in our study is just too large to make this feasible.

20

inequalities is formed by taking couples of patients  2  ( 0  ) and 0 2  (0   ) and using
equation (1 ) to form

 (  0 ) +

(7)
p;

h

(   0 ) +

 (0  0  ) =

i h
(0  0  ) +
 (    0 ) +

i
 (0  0   )] 

Revealed preference implies that this equation is expected to be greater than zero when we evaluate
it at the true value of

and the expected prices. We then average over all couples  2  ( 0  )

and 0 2  (0   ) for all 0 6= , and this averages out the expectational and measurement errors

in price.

Since we have removed the quality/severity interaction terms and no longer need to estimate
their coe¢ cients we can de…ne our severity groups at a more detailed level than was possible in the
logit analysis. Moreover since we average over all such couples in all severity groups we eliminate
the e¤ect of estimation error in price so we can de…ne the price terms in as narrow a set of price
groupings as we like. Note, however, that this procedure does rely on the expected price varying
within a hospital across patients who have the same severity of illness; otherwise the price terms
will be di¤erenced out along with the interaction terms.

A

Severity and Price Groups

Our severity groups are assumed to be de…ned in su¢ cient detail that the severity-hospital interactions absorb all unobserved variation, other than price and distance, that a¤ects choices and
may be correlated with price. That is though we require price variation across patients in di¤erent
price groups within a given severity, that variance cannot a¤ect choices except through the price
variable itself. We now provide details of our severity and price de…nitions and consider whether
these requirements are satis…ed. Our de…nitions are chosen following the advice of the obstetricians
we consulted at Columbia Presbyterian Hospital. As one input to the de…nitions, these experts
assessed the list of principal diagnoses and comorbidities in our data, assigning each a rank from 1
to 3. A “1” indicated a routine diagnosis (such as normal birth or immunization of the newborn)
and “3” indicated something more serious; see Online Appendix 4 for a complete list.
We use narrower de…nitions for severity and price than were used in the logit analysis. Severity groups are now de…ned by a unique combination of age, principal diagnosis, Charlson score,
diagnosis generating the Charlson score and the rank of the most serious comorbidity, other than
principal diagnosis, that is listed in the discharge record.39 Our expected list price, on the other
hand, is now de…ned as the average list price for the particular hospital across women with the same
39
For example a woman aged 25 with a normal delivery, Charlson score of 1 caused by diabetes and a maximum
rank of 2 would be in a di¤erent severity group from a woman with the same age, principal diagnosis and maximum
rank but whose Charlson score of 1 was caused by mild liver disease. A woman aged 25 with a normal delivery,
Charlson score of 0 and maximum rank of 1 would have a di¤erent severity group from a similar woman whose
maximum rank was 2 (but where that co-morbidity was not severe enough to trigger a Charlson score above 0).

21

severity (as just de…ned) who also have the same number of most seriously-ranked comorbidities.40
That list price is interacted with 1 minus the average hospital discount to calculate our baseline
price variable.41 These de…nitions generate many more groups than those used in the logit analysis. For example, for the …rst insurer in our data, there are 63 populated groups de…ning prices
using the logit-based categories (recall that the logits did not allow severity groups to interact with
the hospital …xed e¤ects). There are 106 severities and 272 price groups under the more detailed
de…nitions.
The obstetrical experts we interviewed advised us that these detailed price groups, conditional
on severity, were unlikely to be important in terms of hospital choice. The price groupings are
more detailed than those used for severity only in that they break out patients by the number of
comorbidities of the highest rank as well as the identity of that rank. The number of comorbidities
of a given rank, conditional on severity, was considered unlikely to a¤ect the hospital choice. While
a physician might refer a pregnant woman with a normal delivery but a comorbidity of rank 2 (such
as a viral infection or a thyroid disorder) to a di¤erent hospital from a similar patient with only rank1 comorbidities, this would be a hospital well-equipped to deal with high-risk pregnancies rather
than the speci…c comorbidity, and the presence of two rather than one rank-2 comorbidities would
not a¤ect the referral decision. In contrast, our experts agreed that the number of comorbidities of
a particular rank would be likely to a¤ect the tests performed and drugs prescribed and therefore
the price.
The price variation used in the inequality analysis is a di¤erence in price di¤erences. More
precisely it is a di¤erence in expected price di¤erences, where an expected price is measured by
average prices associated with a given admission condition (de…ned by a combination of diagnosis,
age, and comorbidities) at a hospital. Take patients  who goes to hospital  and 0 who goes to
hospital 0 . Assume they both have access to each other’s chosen hospital and both have the same
severity and plan. Then when we add the inequalities for the two of them the severity-speci…c
hospital quality terms di¤erence out. Patient  who goes to  faced an expected price di¤erence of
(  ) ¬ (  0 ) while patient 0 who goes to 0 faced (0  0 ) ¬ (0  ). These are the only price
comparisons across hospitals that are used in the analysis and they are comparisons for exactly the
same admission price group. The estimates of the price coe¢ cient come from …nding out just how
much further the patient with the highest price di¤erences is willing to travel than the patient with
the lowest price di¤erence42 .
40

For example if two women have the same age and principal diagnosis and a zero Charlson score but one has
a migraine (a rank 1 comorbidity) and one has a viral infection (rank 2), the women have di¤erent severities and
di¤erent prices. If neither woman had a migraine but one had a viral infection and the other had a viral infection
and also a thyroid disorder (both rank 2 comorbidities), they would have the same severity but di¤erent prices.
41
Provided expectations are unbiased the average of actual prices will converge to the average of expected prices,
so we could have used actual and not a measure of expected prices in our inequalities. However the expected price
variable we do use has the advantage that it uses the information from all same plan same price group patients in
comparisons across couples of hospitals, not just those for whom there was a feasible switch.
42
The intuition of the method is somewhat similar to including …xed e¤ects at the severity-hospital level in a linear
regression. However the regression approach would not average out the error in the price measure and therefore would
have an errors-in-variables problem.

22

Table 6 provides summary statistics on the price di¤erences used in the analysis. The data
used in the table are from patients who have a Charlson score of 0 and a given maximum rank
but di¤erent numbers of most seriously-ranked comorbidities. 63450 out of 64691 patients in our
inequalities sample have a Charlson score of 043 . Cells in the table correspond to a particular
maximum rank and number of diagnoses of that rank, but average over four age groups and 21
diagnoses which are disaggregated in the actual analysis44 . The di¤erence across hospitals for a
patient who is admitted in a given price group is quanti…ed in the columns labelled SD which give
the standard deviation for that price group across hospitals (averaged over age and diagnosis).
There clearly are di¤erences across hospitals in a given price group and these di¤erences increase as
we move down the rows of the table within a panel (i.e. as we increase the number of comorbidities
of maximum rank). The second di¤erence is across price groups within a severity group (de…ned by
diagnosis, age, and the maximum rank of the comorbidities). This is illustrated by the di¤erences
across rows in the columns labelled Price ($) within each panel of Table 6 (again averaged over age
and diagnosis). Clearly the mean prices are ordered as expected, and the di¤erences are usually
highly signi…cant (the bracketed numbers provide the standard error of the mean).
******Table 6 approximately here******
Finally we note that when we go to the actual disaggregated groups (disaggregated further
by age and diagnosis), an analysis of variance indicates that moving from severity to price groups
explains an additional 12% of the variance in price (from 50% to 62% of the total variance), ensuring
there is meaningful variance in price after we fully condition on our severity groups. In addition to
requiring that there is variance in price conditional on severity we are also assuming that hospital
“quality” does not di¤er across price groups within a severity. There may be many dimensions
of quality but expected health outcomes are clearly among them. Online Appendix 5 provides
the analogue of Table 6 when the four mother and infant outcome measures used in Table 4 are
substituted for the “Price ($)” columns in Table 645 . There we see that as we move from max
rank 1 to 2 and then max rank 2 to 3 in a given row (i.e. conditional on a given number of max
rank comorbidities) 19 out of 20 of the di¤erences are of expected sign (the single di¤erence with
the wrong sign is not signi…cant) and most are statistically signi…cant (17 out of 19)46 . When we
consider di¤erences in outcomes across entries that correspond to di¤erent numbers of comorbidities
conditional on the same maximum rank (illustrating the di¤erences across price groups within a
severity), 6 out of 28 are decreases when we expect increases (though none are signi…cant decreases),
and of the remaining 22 only 8 are signi…cant. Though the latter di¤erences (those across rows
43
We exclude a few patients who have no comorbidities known on admission besides the principal diagnosis and
therefore have 0 diagnoses of maximum rank.
44
We use aggregated groups because for many of the hospitals there are no patients in some of our actual severity
groups and these hospital severity pairs would not be used in the inequality analysis which follows.
45
As for Table 4 we use a slightly di¤erent dataset that includes infant outcome variables. We exclude a small
number of patients with no comorbidities known on admission other than the principal diagnosis.
46
These numbers only consider di¤erences where both entries are based on more than 400 patients. We thank
Jesse Shapiro for suggesting this table.

23

within a given column) are small relative to those across columns, they are large enough to induce
us to check for di¤erences in outcome measures when we condition on the more detailed severity
groups actually used in the analysis. When we further disaggregate by diagnosis and age (i.e. to
the severity groups we actually use) and perform

2

tests for the outcome di¤erences across price

groups conditional on severity groups and hospitals (to correspond to our severity speci…c hospital
e¤ects) we …nd no signi…cant di¤erences.

B

Inequality Analysis

We work with each plan’s data separately, so we omit the plan (our

) index from the notation

below, with the understanding that all coe¢ cients are plan speci…c. The inequality model makes
the following assumptions:
(  ) =

(8)
 
  (  )

 
  (  )

¬

( )

 (   ) ¬

( ) 

was assumed equal to expected price in the logit analysis, so the di¤erence between this

speci…cation and that used in the logit analysis is that the inequality analysis allows for an error
in price and the logit analysis did not. Also
( ()  ) =   ( ()  ) ¬

(9)

  

i.e., the inequality analysis places no restrictions on the quality severity interactions and allows
for classi…cation error in those interactions. The only assumption we will need on the two errors,
(

( )    ),

is that they be mean zero conditional on the patient’s chosen plan and hospital and

independent of the distance travelled to the hospital (we consider the robustness of our estimates
with respect to these assumptions below).
Finally
 ((   )) =

(10)

 (   )

which di¤ers from the speci…cation in the logit analysis in that the squared term in distance has
been eliminated because it did not a¤ect any of the parameters of interest and would complicate
the algebra below.
Substituting into equation (7) for a same-plan same-severity couple who could have chosen each
other’s hospital and are in di¤erent price groups (an  2 ( 0   ) and 0 2 (0    =    6=  ))

our revealed preference inequality becomes
0

(11)


where

h

 (   0 ) +
0



 (  0 ) +

i
 (0  0  ) +

( )0

+

0 0  .



h

 (0  0  ) =

(    0 ) +

24

i
(0 0   ) ¬

0

¬

0 0 

Our inequalities for hospital  and insurer

are simply averages of equation (11) across switches

between patients who chose hospital  and those who chose another hospital but could have chosen
 and had the same severity and insurer, but di¤erent a price group, as the patient who chose

0
0
 . Formally, let 
0  be the number of switches between patients  2 (    ) and  2

(0    =    6=  ) and for any ( ) de…ne

X

1

( 0  )

(12)

X



0 
2(0 ) 0 2(0 6= )

(  0 )

Then averaging equation (11) over switches we get
( 0  ) +

p;

(0   ) +

( 0  ) +

d;

(0   ) ¬

( 0  ) ¬

(0   )

0

The moment inequalities we use in estimation are weighted averages of these inequalities where
the weights are given by the fraction of comparisons that each contributes, or
( 0  )

 0
P P   


0  0 

If we let ! read converges in probability, and note that our assumptions imply
X

0 

( 0  ) ¬

then our model implies that at

=

(0   ) ! 0

0

( )

(13)
X

( 0  ) ¬

( 0  )

0 

"



( 0  ) +

(0   ) +



( 0  ) +

(0   )

#

!

0

The inequality in equation (13) is in terms of observables and the parameters of interest. Since
it is an inequality, if a particular [  

]

satis…es (13), then so will [

implies that there is a free normalization, so we set
the ratio
47 .

 jj  jj,





]

for any

 0. This

= ¬1. Thus we will only be able to estimate

which at the risk of some notational confusion, we will henceforth simply call

47



Though the inequality in equation (13) allows for detailed hospital quality/patient severity interactions and
errors in the price variable, it does rule out determinants of choice that are patient-hospital speci…c and are both: (i)
not controlled for by the severity/quality interactions, price, or distance, and (ii) not di¤erenced out by adding the
di¤erence in preference for hospital  over 0 for one patient to the di¤erence in preference for hospital 0 over  for
the other. The logit model does not allow for patient severity/hospital quality interactions or errors in the measure
of price, but does allow for unobservables that are patient and hospital speci…c provided they are independently
and identically distributed across both patients and hospitals and have an extreme value distribution. To the extent

25

The inequality in (13) bounds



. We can generate additional inequalities, and therefore

bounds, by multiplying each inequality in equation (11) with an “instrument”, say , whose sign is
the same for all observations. The additional moments will generate lower bounds if the expected
value of [ ( 0  ) +

(0   )]  is positive and upper bounds otherwise. For a variable to be

an instrument it must be known by the agents when their decisions are made and mean independent
of the measurement errors. Our assumption that (

( )    )

are independent of the distance

travelled implies that we can use as instruments the positive and negative parts of the distance
di¤erences, that is:
analogously,

(    0 )+

(0  0   )+ 

(  ).

f(    0 ) 0g

(    0 )¬

f(    0 ) 0g and

(0  0   )¬ . We label the additional inequalities for instrument ,

Details. As noted we conduct the initial analyses separately by insurer. This allows all hospital
quality - patient severity interactions as well as the price coe¢ cient to di¤er by plan. The left hand
side of equation (13) is computed separately for each hospital and instrument. We then weight
each of these terms by its estimated standard error. For small hospitals we are concerned that the
average error either in the inequality, or more likely in the estimate of its standard error, may not
be close to zero. As a result we develop a separate inequality for each hospital that has more than
1000 patient switches but average over all hospitals with less than 1000 patient switches. Overall
we have between 78 and 285 moments per insurer: one for each combination of an instrument
and a major hospital and an additional moment per instrument that includes hospitals with fewer
patients48 .
Our model tells us that at the true
should reject any value of
prefer one value of

0

each of the weighted moments should be positive, so we

which makes any moment negative. However we have no reason to

that generates positive moments over another that does also. So we form the

“negative”part of the moments, say (  )¬ = (0 (  ), weight them by their standard
errors, and accept any value of

which makes them all zero. If m( )¬ is the vector obtained after

weighting each moment by its estimated standard error and then arranging them into a vector, and
P 2
for any vector , kk
which is in
  , then this is formally identical to accepting any
(14)

^ =  km( )¬ k

^ could be a set of values all of which make all the moments zero, or it could be a point, indicating
that no value of

satis…es all the moment conditions. If it is a point then we test whether the fact

that the inequality model does not account for all the patient/hospital speci…c determinants of choice there will be a
selection problem in the resulting estimates which would be expected to narrow the estimated bounds. If the selection
term is important we should expect a (non-random) fraction of our inequalities to switch signs, and if selection is
important enough we will reject the null that there are values of which satisfy all the inequalities. In fact we accept
below. Moreover, as we will see, there is no evidence at all of a disproportionate number of negative inequalities.
48
We exclude from the analysis hospitals that have fewer than 150 switches with all other hospitals in the sample
combined (when instruments are included, each pair of hospitals is required to have at least 150 switches whose
value of the instrument is non-zero). We also tried estimating the coe¢ cients keeping the smaller-hospital moments
separate. The estimated coe¢ cients were almost always smaller in magnitude than our baseline results, consistent
with small hospitals introducing measurement error, but in qualitative terms the story did not change.

26

that no value of
is

satis…es all the constraints is a result of sampling error or is because the model

mis-speci…ed49 .

C

Robustness Tests.

As noted, there are possible issues with price measurement that could a¤ect the analysis. In
particular we do not observe the actual discount negotiated by each hospital-insurer pair. We do
observe the average negotiated discount for private managed care patients at each hospital, so were
each inequality obtained by averaging over all private managed care patients we would have the
correct average price. There are at least two possible problems. First our inequalities are insurer
speci…c, and insurers’contracts with the same hospital can di¤er in ways that generate di¤erences
in average discounts. Second we consider only birth episodes and the average discount for birth
episodes may di¤er from the overall average. In addition we did not allow for errors in the distance
measure when in fact we only have information on the zip code in which the patient resides and
calculate distances from the centroid of that zip code. We now develop procedures for checking
whether our conclusions might be a¤ected by these problems.
C.1

Allowing for Insurer-Speci…c Average Hospital Discounts.

Our data include the average negotiated discount at each hospital, our  . Our procedure for testing
whether our results are robust to insurer-speci…c average hospital discounts begins by writing 
as a share weighted average of the average insurer discount at each hospital. We substitute into
this equation data on insurer-speci…c revenue shares at each hospital and a parameteric model for
the insurer-speci…c average hospital discounts. This generates an estimable model for the needed
discounts. The additional data on the insurer-speci…c share of hospital revenues needed for this
analysis comes from the OSHPD hospital discharge and …nancial records for 2003. The average
discounts are modelled as a function of hospital, plan, and market characteristics.
The model for the average insurer-speci…c hospital discount, our 

 ,

is the sum of two com-

ponents; one for the average hospital discount and one for the insurer-speci…c deviation from that
average. There are two ways to use the estimates to generate a prediction for   . First we can use
the model’s prediction directly; we denote this ^1 . Alternatively we can subtract the predicted


average discounts of other insurers (appropriately weighted) from the observed  to generate a
second prediction ^2  . The …rst prediction will not account for errors in predicting the hospital’s
average discount. The second prediction does account for hospital speci…c prediction errors but
does not account for the insurer-speci…c prediction errors of the other insurers. The two predictions
are used to de…ne price measures 1 ( ) = (1 ¬ ^1 ) (  ) and 2 ( ) = (1 ¬ ^2 ) (  ) which




are substituted for our estimates of price in equation (8) in the inequality analysis. Recall that the
49

The test uses the moment shifting technique in Andrews and Soares (2009), and for computational reasons we
use a related technique for 95% con…dence intervals developed in Pakes, Porter, Ho and Ishii (2011). Both require
development of the variance covariance of the inequalities across moments, and the formula for that matrix is available
upon request.

27

predicted insurer-speci…c hospital discount in our baseline model is just the actual average hospital
discount. The error in the moment conditions that the use of the di¤erent price measures generates
is the di¤erence between the predicted and actual average insurer-speci…c hospital discount times
the average price.
We specify a logistic functional form for 

 .

The explanatory variables that are interacted

with plan revenue shares at the hospital include indicators for for-pro…t hospitals and hospitals
that are members of systems (groups of providers that bargain jointly with insurers), indicators
for teaching hospitals, and both insurer and market …xed e¤ects. However we also estimate other
speci…cations that replace the …xed e¤ects with market and insurer characteristics to check that
our results are consistent with previous papers analyzing the impact of those characteristics on
hospital prices. Details on both the models estimated and their coe¢ cient estimates are provided
in Online Appendix 2. Though the …ts are not extraordinary (with 2 s just under 0.5), the results
are intuitive and accord with the prior literature (for example discounts increase with the number
of hospitals per population and decrease with the number of insurers per population).50
C.2

Allowing for Variation in Discounts Across Diagnoses

The discount analysis just described makes the assumption that discounts are …xed across diagnoses
within a hospital-insurer pair. In reality discounts may vary across services within a hospital.
To ensure that ignoring this variation was not biasing our results we went back to our discount
model and allowed the discount for deliveries to di¤er from that for other diagnoses. We also
ran speci…cations allowing the labor/birth discount to di¤er across di¤erent types of hospitals: for
example hospitals with high-tech delivery services could have a particularly good reputation for
obstetrics and therefore negotiate low discounts. Augmenting our baseline analysis to allow for a
separate discount for delivery episodes generated a signi…cant coe¢ cient which implied that births
had a 6% higher discount than the average for other diagnoses. However we did not …nd signi…cant
di¤erences in this discount across hospitals. When we substituted the delivery-speci…c discounts
into the inequality analysis the coe¢ cients di¤ered very little from the baseline speci…cation. We
also tried estimating a di¤erent discount for Cesarean sections but the estimated coe¢ cient was
not statistically signi…cant. See Online Appendix 2 for further details.
50
Dranove and Satterthwaite (2000) and Gaynor and Vogt (2000) provide good reviews of the literature on discounts. Several other speci…cations were investigated. For example we replaced the insurer …xed e¤ects with the
plan percent capitation. This coe¢ cient was positive and the other coe¢ cient estimates were qualitatively una¤ected
by this change, foreshadowing our results that accounting for variation in discounts across insurers does not change
the major results of our inequalities analysis. We also investigated whether the proportion of the insurer’s patients
sent to a particular hospital was correlated with the discount by including an interaction of this proportion with
insurer …xed e¤ects in the model. This relationship between the “channeling" of patients to a particular provider
and the prices negotiated with that provider is analyzed in Sorensen (2003). When we excluded market …xed e¤ects
we estimated a signi…cant positive relationship between patient channeling and discounts (a negative relationship
between channeling and prices) for just one insurer, Blue Shield. The coe¢ cient became insigni…cant when we added
market …xed e¤ects. We repeated the inequalities analysis for Blue Shield using this discount speci…cation and the
results changed very little.

28

C.3

Allowing for Errors in Our Distance Measure

Our measure of the distance between patients and hospitals is the distance between the centroid
of the patient’s home zip code and the zip code of the hospital. It therefore contains measurement
error.51 Assuming the error is mean zero implies that it does not a¤ect the properties of our original
inequality (equation 13) as that simply averages out the estimation error. However when we take
the positive and negative parts of the distance and use them as instruments, those instruments will,
in general, contain an error which is correlated with the error in distance in the original equation,
and this can generate biases in our estimate of

.

To ensure that this was not having a major impact on our results we modi…ed our distance
instruments ( (    0 )+ 
using

(    0 )¬  (0  0   )+ 
~     0 )+ where
(    0 )+ we used (
~     0 )+ = 1 if
(

(    0 )+

3 and

(0  0   )¬ ) as follows. Instead of
~     0 )+ = 0 otherwise
(

We did the analogous transform to the other distance instruments. This addresses the problem
if we assume that the error in the distance is not greater than three miles, so that we know the
incremental distance between hospitals is positive (negative) if the observed di¤erences are greater
than three miles.

D

Inequality Results

Tables 7 and 8 report results from the inequalities analysis. The …rst column of Table 7 reports
our main results. These assume that the price measure obtained by multiplying hospital speci…c
discounts by the expected list price is correct up to an error which is mean zero conditional on the
plan and the choice of hospital. The second column uses the modi…ed distance measure described
above to check for the possible impacts of errors in the distance measure. Table 8 reports results
using 1 () and 2 () respectively (and assuming no errors in the distance measure). Their validity
requires additional assumptions on the prediction errors generated when forming these variables,
but they allow us to investigate whether our results are robust to allowing for plan-speci…c discounts
within hospitals.
******Tables 7 and 8 approximately here******
There is no value for

p;

that satis…es all the inequality constraints in any speci…cation except

one (Blue Shield in column 4 of the table). When this occurs the estimation algorithm produces
a point estimate: the value of

p;

that minimizes the sum of squares of the negative part of the

(standardized) moments. Given the number of inequalities we have for each of our plans we are
51
Latitudes and longitudes of the hospital’s and patient’s zip codes are taken from the Bureau of Census 1999
zip code …le. Additional measurement error is caused by the fact that, if the zip code could not be located in the
Bureau’s internal database, the county internal point was assigned to the zip code. Multiple zip codes therefore have
the same recorded latitude and longitude in some cases.

29

not surprised to …nd point estimates. In …nite samples when each moment is evaluated at the true
value of the parameter vector it generates a variable which distributes approximately normally.
Consequently the greatest of the values from the moments which provide lower bounds has a
positive bias. Similarly the least upper bound has a negative bias. So depending on the magnitude
of the biases the bounds can easily cross producing a point estimate. The expected magnitude of
these biases increases with the number of moments.
There is a standard statistical test for whether sampling errors of this form exist and the results
always indicated that we could accept the null that there were values of

that satis…ed all the

inequalities. Table 9 makes it clear why we accept the null. It provides estimates of the t-statistics
obtained when we evaluate all moments used at the estimated value of

p:

for each plan. The

model predicts that the expectation of all moments are non-negative. Our results indicate that of
the 977 moments evaluated only 60, or about 6%, are less than zero, and only 7 out of 977, or 0.7%
of the moments, have t-values less than -2. In four of the six plans studied none of the moments
are signi…cantly negative at the traditional p-value of .05. Health Net has 2 out of 182 moments
with t-value less than -2 and Blue Cross has 5 out of 285 with t-values less than -2. For these two
insurers we re-estimate

p;

after dropping the moments with t-statistics less than -2. The results

are reported in the rows of Tables 7 and 8 labeled "Drop   ¬2".
******Table 9 approximately here******
In the …rst column of Table 7 the price coe¢ cients for all insurers other than Blue Shield
are negative and statistically signi…cant at p=0.05. That for Blue Shield is small, negative and
statistically insigni…cant. As is traditional for set estimators, we focus on con…dence intervals for
p;

. These are illustrated for each insurer in Figure 1. The coe¢ cients for all insurers except

Blue Shield are “set ordered” by decreasing percent capitation; that is, the upper bound of the
con…dence interval for one insurer is below the lower bound for the insurer with the next-highest
percent capitation. The picture is less clear for Blue Shield. Its con…dence interval is above that
for Blue Cross and crosses zero.
******Figure 1 approximately here******
The results from substituting 1 () and 2 ( ) for the  ( ) in the inequality analysis are provided
in Table 8. They are similar to the results in our main speci…cation. The two major di¤erences occur
when using 2 ( ); then the Health Net coe¢ cient estimated when we drop the two negative moments
is larger in absolute value, and the Blue Shield coe¢ cient is positive with a con…dence interval that
crosses zero (instead of being negative with a con…dence interval crossing zero). We conducted a
number of other robustness tests that involved the price variable, but none had anything but the
expected e¤ect on the results52 .
52

We repeated the inequalities analysis using just the list price (rather than its interaction with the discount).
The pattern of results was unchanged in that high-capitation insurers had more negative price coe¢ cients in general
than other insurers. However all price coe¢ cients were closer to zero than those in Table 7, consistent with our
expectation that measurement error should a¤ect these results.

30

Column 2 of Table 7 provides the results using the modi…ed distance instrument that takes
~ ) instruments de…ned in
account of the possibility of error in our distance measure (it uses the (
the prior subsection). The results are very similar to those above. All coe¢ cients but those for Blue
Shield, and to a lesser extent Health Net are similar to those in column 1. The con…dence interval for
Blue Shield indicates that the data are not informative about the Blue Shield price coe¢ cient, and
the Health Net coe¢ cient, though always signi…cantly negative, varies in magnitude with whether
or not we keep the two inequalities that are signi…cantly negative.
With the possible exception of Blue Shield, these results indicate that the allocation of patients
to hospitals responds to the prices the insurer pays those hospitals. Moreover insurers with more
capitated payments to physicians have hospital referral processes that place a more negative weight
on prices than other insurers. We cannot say much about Blue Shield. The bounds for its coe¢ cient
are large and vary quite a bit across the speci…cations we tried. Recall that Blue Shield is the only
not-for-pro…t insurer in our data, and so might be expected to di¤er53 . As a result we disregard
Blue Shield in the analysis that follows.
The di¤erence between the inequality results and those from the logit analysis are striking.
To get an idea of the importance of this di¤erence Table 10 compares the elasticity of price with
respect to distance computed using the logit estimates for the least sick patients (Table 5), to those
same elasticities computed using the price coe¢ cient estimated from the inequalities (column 1 of
Table 7). That is, we measure on average how much further the consumer would have to drive (in
percentage terms) to just o¤set a one percent price increase.
******Table 10 approximately here******
Consider …rst the comparison of elasticities derived from the logit price coe¢ cients to those
derived from the inequality estimates for the plans where the logits estimated a negative price
coe¢ cient. All the elasticities obtained from the inequality estimates are more than an order of
magnitude larger than those obtained from the logit estimates, and some are more than two orders
of magnitude larger. In addition two of the elasticities obtained from the logit estimates have the
wrong sign. Notice also that the inequality estimates indicate that the average elasticity increases
by almost a factor of four when we move from the least capitated for pro…t insurer (Blue Cross)
with a capitation rate of 38% to Paci…care whose capitation rate is 97%.

VII

Cost, Quality, and Distance Trade-O¤s

This section is divided into two parts. In the …rst we derive insurer and severity speci…c estimates
of quality di¤erences across hospitals. The estimated qualities are quite similar across insurers. We
illustrate this by estimating a model which requires the within-severity ratings of di¤erent plans to
be linear transforms of each other, and then providing a plot of the restricted on the unrestricted
53
As noted above, it is also the only insurer that mandated tiered networks by 2003, and the available evidence
indicates that it is the only insurer with a noticeable fraction of enrollees on a tiered network in that year. This is
yet another reason to think the analysis for Blue Shield should be di¤erent.

31

quality estimates. The next subsection examines implications of these results. When the withinseverity orderings are linear transforms of each other each plan’s preference ordering over hospitals
(equation 1) is a di¤erent linear function of price, distance, and a common quality index. This
allows us to investigate how the quality-price-distance trade-o¤ varies across insurers. We conclude
this subsection by comparing our results on these trade-o¤s to the implications of the data on
health outcomes (the data that underlies Table 4). This reinforces our results and provides some
external validity for our quality controls.

A

Plan and Severity Speci…c Hospital Quality Terms

The revealed preference inequality in equation (11) implies that any given value of

p;

generates

a set of bounds for di¤erences in the quality terms across hospitals. We evaluate these di¤erences
at the estimates of

p;

given in column 1 of Table 7.54 Since we can only recover di¤erences in

quality and we can only compare hospitals within a market, we estimate quality coe¢ cients that
are: plan, severity, and market speci…c. To ease notation we will omit the plan and market indices
below.
( 0  ) is the average of

Recall that

(  0 ) among the patients with severity  who

chose hospital  but could have chosen 0 . Then since every one of those patients chose  over 0
revealed preference implies
(  ) ¬ (0  )

¬



( 0  ) +

with ^( 0  ) observable. Moreover since the

( 0  ) +
0 

0 

^( 0  ) +

0  

are mean zero conditional on the hospital

choice
(15)

^( 0  )

 N

( 0  )

2

( 0  )0   where ( 0  )

“ ” reads converges in distribution to,
variance of (¬



(   0 ) +

(  ) ¬ (0  )

N (  ) is the normal distribution,

2 ( 0  )

is the

(    0 )) across observations in ( 0  ), and 0  is the

cardinality of that set.
Each couple of hospitals generates two quality bounds of this form: one from the patients who
chose  but could have chosen 0 and one from those that chose 0 and could have chosen . The
former provides a lower bound and the latter an upper bound to the di¤erence in quality between
 and 0 . So if there are  hospitals in a market, there are ( ¬ 1) estimates of quality bounds
for each severity.

Estimating the quality bounds.

Recall that we can only bound di¤ erences in hospital quality.

So we set one hospital’s quality to be zero (the same hospital for each insurer for a given severity
and market). Indexing that hospital by  one can show that the inequalities that relate to hospital
54

The correlation of the quality terms across di¤erent values within the con…dence intervals of
so it makes little di¤erence which of the values in the con…dence intervals reported there we use.

32

p;

is nearly one,

 are given by
(16)
( )

h
i
0
0
min

¬

^
(


)
¬

^
(


)
0

 6=

(  )

h
i
0
0
max


^
(


)
+

^
(


)
0
 6=

( )

We stack these inequalities for each hospital, weight each by its estimated standard error, and then
…nd the (set) estimator that minimizes the squared inequality violations.
Recall that we used very detailed severity groups for the estimation of price coe¢ cients so as
to ensure we eliminated biases that might be caused by unobserved quality terms. The sample
sizes associated with those groups are quite small and to obtain the quality estimates we do not
average over severity groups as we did to obtain the price coe¢ cient estimates. Moreover we are
not interested in orderings of hospitals at that …ne a level of severity. We therefore use the severity
classi…cations given to us by the obstetricians we consulted to aggregate into …ve “super-severity”
groups. These consist of four groups all of whose patients have identical principal diagnosis and
comorbidity rankings, and a …fth group which contains all the remaining patients55 . Finally the
actual estimates of the quality bounds depend on the prior estimates of

p;

. The results presented

below use the point estimates from the …rst column of Table 7, but the implied quality bounds
varied very little when we considered other points within their respective con…dence intervals.
In computing the quality estimates we included moments for patients who went to hospital
 but could have chosen hospital 0 for a given severity if there were …ve or more patients who
were admitted to hospital  and had hospital 0 in their choice set. Over our 12 markets and …ve
severity groups, we obtained 1176 quality estimates56 . Almost all of these estimates, 1078 of them,
come from our …ve largest markets (Los Angeles, Orange County, Inland Empire, the Bay Area,
and San Diego), so we con…ne the remainder of the analysis to these …ve markets.
Does the implied order make logical sense?

For the ordering across hospitals to make logical

sense it must obey transitivity. There are at least two ways we can check this, one of which does
not rely on our estimates of the price coe¢ cient and one of which does.
Temporarily ignore estimation error. Then if both

( 0  ) and

( 0  ) are positive the

perceived quality of  for severity  must be higher than that of 0 . This because patients chose
hospital  over 0 despite the fact that  was both more distant and had higher prices. This fact
generates a partial ordering across hospitals that does not require either estimates of the price
coe¢ cients or estimates of the quality terms. Alternatively we could use our estimate of
55

p;

to ask

The super-severity groups are: Group I contains 55% of patients who have a rank 1 (routine) principal diagnosis,
rank 1 comorbidities and are young; Group II has 11% of patients who have rank 2 principal diagnosis, rank 1
comorbidities and young; Group III has 15% of patients who have rank 1 principal diagnosis, maximum rank 2
comorbidities and are young; Group IV has 12% of patients and they have a rank 2 principal diagnosis, maximum
rank 2 comorbidities and young; and Group V has 6% of patients that are not included in the other groups.
56
477 of these were sets and 699 were points. We tested whether the points satis…ed the appropriate vector of
moment inequality constraints (the sets necessarily do). Slightly more than half did. However when we go to switches
between individual hospitals for a given severity and plan there is a limited amount of data per moment. So the
asymptotic approximation inherent in the moment inequality test statistic is questionnable. Moreover, as we show
below the actual estimates satisfy most of the properties our priors might associate with them.

33

whether the partial order obtained from the sign of

(

( 0  ) ¬

p;

( 0 ) obeys transitivity.

( 0  )) for each pair

The estimation procedure we use does not guarantee that the order we obtain from using either
of these sets of inequalities satis…es the logical condition of transitivity. I.e. there could be cycles
of the form
1

2   2

3  but 3

1 

or even more simply we could …nd that
1

2 but 2

1 

To check this we compute all possible cycles from both the “non-parameteric” bounds and the
bounds that use our estimates of



for each of our …ve insurers, in each of our …ve markets for

each of our …ve severities. The non-parametric procedure yields only 543 possible orderings, and
none violate transitivity. When we use our estimates of



and the estimation algorithm described

above there are 10,526 possible orderings, and of these 1069, or about 11% actually cycle. However
almost all of these are associated with bounds that are estimated imprecisely. Only 3 or .03% of
the possible cycles are signi…cantly negative at the 5% level. We take this as evidence that the data
generates a hospital ordering that satis…es rationality constraints. We now consider that ordering
in more detail.
1078 estimates is still too many to examine

Similarity of the implied orders across plans

individually, and our primary interest is not in the quality estimates per se but in the implied
trade-o¤ between price, quality, and distance. Moreover the similarity in the estimated rankings of
hospitals across insurers within our severity groups is striking, and this implies that some aggregation across plans is warranted. Note that since patients are assigned to a unique insurer, there is no
statistical relationship between the moments used for the di¤erent insurers (except the relationship
due to our using the same price measure across insurers). The similarity in ranks is a result of the
similarity in (almost) statistically independent quality estimates generated by the referral processes
of the di¤erent plans.
Figure 2 illustrates this similarity. This …gure plots the estimates obtained from imposing the
constraints that the plan speci…c orderings for our …ve severity groups in our …ve largest markets
are linear transforms of one another. That is, reintroducing the plan ( ) and market () indices,
we substitute
(17)

 (  ) =

0



+

 

for the quality terms into equation (16), and re-estimate. When we do this the

0

coe¢ cients can

not be separated from the quality of the reference hospital in each market and, since we can only
compare quality estimates across plans, the



34

can only be analyzed proportionately to those

of a base plan. Consequently in what follows we set the



coe¢ cient for Blue Cross equal to

one in each market and severity.
******Figures 2 and 3 approximately here******
When we impose the constraints in equation (17) we reduce the number of coe¢ cients estimated
from 1078 to 452 coe¢ cients. Figure 2 plots the constrained against the unconstrained estimates57 .
The …tted line captures 98.2% of the variance of the unconstrained estimates. We then imposed
the futher constraint that
(18)



=



This reduced the number of parameters estimated to 380. Figure 3 plots the constrained against the
unconstrained estimates after imposing the additonal constraint. The …tted line now captures 95.7%
of the unconstrained variance. Though the di¤erence in …t between …gures 2 and 3 is noticeable, it
is rather small; we lose about three hundredths of one percent of the …t per additional constraint.
Moreover if we impose the constraint in equation (18) there is a straightforward way to compare
the way di¤erent plans trade-o¤ costs, quality and distance.

B

Trade-O¤s

We now accept the constraints in equations (17) and ( 18) and substitute the results into the
equation which determines hospital choice (equation 1). To get directly at the price-quality and
distance-quality trade-o¤s we divide the resulting equation by
(19)

i;



/

p;

!

(   ) ¬

1

!

so

(   ) +  +

1

!

i;  

Table 11 provides the plan-speci…c estimates of the coe¢ cients in equation (19).
******Table 11 approximately here******
The …rst two rows of the table reproduce the capitation rates and price coe¢ cients from prior
tables. As noted the (absolute value of the) price coe¢ cients are ordered by the capitation rates.
The third row shows that the quality coe¢ cients are ordered in exactly the same way. As a result
the ratio of the price coe¢ cient to the quality coe¢ cient is virtually constant across plans. The
fourth row shows that this ratio lies between -0.29 and -0.30 for all …ve plans. In addition this
ratio is estimated quite precisely. If we take upper and lower bounds to that ratio obtained by
57

When the unconstrained quality estimate was a set the error in the …t of the point was set to zero if the line
went through the set, and was set to the distance between the set’s bound and the line when it did not. 62 of the
452 constrained coe¢ cients were sets. When the constrained estimate was a set and the line went through the set,
we placed the point on the line in the …gures, and when the line did not go through the set we chose the closest value
to the line from the set.

35

dividing the upper (lower) limit of the con…dence interval for
con…dence interval for 1=

p;

by the lower (upper) limit of the

, we …nd that the lower limit only varies between -0.31 and -0.40 while,

with the exception of Health Net, the upper bounds vary only between -0.22 and -0.25 (Health Net
has an upper bound of -0.15, and as noted earlier our estimates of its values are somewhat sensitive
to the precise speci…cation of the price and distance terms).
Table 12 provides the estimates of

p;

=

before we impose the constraint in equation (18);

i.e. for each market and severity separately. There we see that Table 11 does hide some variance in
the estimates of the parameter determining the cost-quality trade-o¤ across markets and severities.
However the di¤erence between these numbers and those for

p;

=

in Table 11 is largely in the

smaller markets and severities. As a result when we impose the constraint in (18), the LA, Bay
Area, and (to a lesser extent) Orange County moments for the …rst three severities dominate, and
they do not di¤er much across either plans or severities.
******Table 12 approximately here******
The ratio of the price to the quality coe¢ cient represents the trade-o¤ between costs and
quality. What the estimates are telling us is that the cost-quality trade-o¤ is, as far as we can
tell, independent of the capitation rate. This despite the fact that the higher the capitation rate
the more sensitive hospital referrals are to price. Apparently though the high capitation plans are
willing to send their patients to relatively far-o¤ hospitals to save on hospital costs, they are not
willing to sacri…ce quality for cost savings. The trade-o¤ between cost, quality and distance only
di¤ers between plans in the trade-o¤ between patient convenience and cost, not between quality
and cost.
Of course our “quality”measure is simply whatever is implicit in the referral process: it captures
everything that makes the hospital attractive after accounting for price and distance. The results
we report above indicate that the quality rankings are similar across insurance plans. Online
Appendix 6 shows that there is fairly substantial variation in our measure of quality. There we
convert the quality variable to $000 by calculating

 =

p;

, and then we calculate its value for

each patient-hospital pair. We take the standard deviation across hospitals for each patient and
then average over patients in each super-severity group and each market. The average variation in
this quality measure is of the same order of magnitude as the variation in price within each market
and super-severity group. Also, perhaps not surprisingly, the estimates indicate that the variation
in both price and the quality variable increases with the severity of illness58 .
This variance in our quality measure could be attributable to many things: patient preferences
for hospital amenities, physician perceptions of clinical quality, and any other factors (other than
price and distance) that a¤ect referrals. We have separate work in progress to investigate which
58

Online Appendix 6 summarizes the variation in quality and in price faced by the typical patient across hospitals.
The table records, for each super-severity group and each market where quality terms were estimated, the crosspatient average of the standard deviation in expected price (in $000) and in quality (measured in the units described
above) across hospitals in the choice set. The variance in both variables increases with severity of illness and the two
are comparable in magnitude (for example for the least-sick super-severity the average standard deviation in quality
in Los Angeles is $1,136 while the average price standard deviation is $1,278).

36

observable characteristics are most related to it. We can however make one connection which throws
further light on our focus here: the relationship between capitation rates and the trade-o¤ between
price, convenience and quality. Table 4 showed that older and sicker women had signi…cantly higher
probabilities of readmission within 12 months and of discharge to “other than home", and their
infants were also more likely to be discharged to "other than home". We calculated

2

test statistics

for di¤erences across plans in the probability of each adverse outcome conditional on each of our
…ve super-severity groups. Not one of the forty test statistics (ten pairwise comparisons of insurers,
for four outcomes each) was signi…cant at the traditional 5% level.

VIII

Conclusions

The results of this paper indicate that the prices paid by insurers to hospitals for obstetric care:
(i) a¤ect allocations of patients across the hospitals in the network, and (ii) have an impact which
is greater the more highly capitated the insurer. Our second major …nding relates to the trade-o¤s
made between price, quality and patient convenience. We …nd that, in the more highly-capitated
insurers, price reductions are achieved by sending patients to relatively far-o¤ hospitals. There
is no evidence that quality of care, or health outcomes, su¤er as a result of this behavior: the
trade-o¤ between quality and price is constant across plans while that between convenience and
price is not. Our estimates summarize the preferences generated by a complicated decision-making
process which involves both physician and patient choices. The data do not allow us to investigate
the extent to which particular mechanisms drive the estimates, so we have to leave that question
to future research.
At least in the context of obstetrics, these …ndings have obvious implications for the impact of
the ongoing institutional changes in the health care sector. Most importantly the use of capitation
payments in Accountable Care Organizations is likely to reduce costs and is unlikely to result in
a reduction in quality of care. There are also several other possible implications. For example,
as noted earlier, currently just under half of Accountable Care Organizations include a member
hospital. There may be a bene…t to such vertical integration through improvements in coordination
of care. However, if providers favor within-ACO hospitals, vertical integration is likely to limit the
cost reductions that would otherwise result from capitation. This is one of several trade-o¤s that
merit further investigation. Also the capitation incentives used to reimburse ACOs are supposed to
condition on quality, and the right measure of quality is unclear. Our methods result in a measure of
hospital quality that re‡ects patient and physician preferences. There is a question worth exploring
about whether our quality measure would be helpful in this context.
References
1. Bajari, Patrick, Han Hong, Minjung Park and Robert J. Town. 2012. "Regression Discontinuity Designs with an Endogenous Forcing Variable and an Application to Contracting in
Health Care." NBER working paper 17643.
37

2. Baumgarten, Allan. 2004. "California Health Care Market Report 2004." Prepared for the
California HealthCare Foundation, http://www.chcf.org/topics/view.cfm?itemID=114640
3. Berwick, Donald M. 2011. "Making Good on ACOs’ Promise - The Final Rule for the
Medicare Shared Savings Program." The New England Journal of Medicine, 365(19): 1753-6.
4. Burns, Lawton R., and Douglas R. Wholey. 1992. "The Impact of Physician Characteristics
in Conditional Choice Models for Hospital Care." Journal of Health Economics, 11: 43-62.
5. Capps, Cory, David Dranove, and Mark A. Satterthwaite. 2003. "Competition and Market
Power in Option Demand Markets." RAND Journal of Economics. 34(4): 737-763.
6. Card, David, and Alan B. Krueger. 1994. "Minimum Wages and Employment: A Case Study
of the Fast Food Industry in New Jersey and Pennsylvania." American Economic Review.
84(4): 774-5.
7. Chamberlain, Gary. 1980. "Analysis of Covariance with Qualitative Data." Review of Economic Studies. XLVII, 225-238.
8. Chandra, Amitabh, David M. Cutler, and Zirui Song. 2012. "Who Ordered That? The
Economics of Treatment Choices in Medical Care." In Handbook of Health Economics Volume
2. Eds M. Pauly, T. McGuire and Pedro P. Barros, North-Holland, 397-432.
9. Charlson, Mary E., Peter Pompei, Kathy L. Ales, and C. Ronald MacKenzie. "A new method
of classifying prognostic comorbidity in longitudinal studies: development and validation." J
Chronic Dis. 1987;40:373–83.
10. Cutler, David M., Mark B. McClellan, and Joseph P. Newhouse. 2000. "How Does Managed
Care Do It?" RAND Journal of Economics, 31(3): 526-548.
11. Department of Health and Human Services. November 2012. "Accountable Care Organizations: What Providers Need to Know." Medicare Learning Network, ICN 907406.
12. Duggan, Mark G. 2000. "Hospital Ownership and Public Medical Spending." Quarterly
Journal of Economics, 1343-1374.
13. Dranove, David, and Mark A. Satterthwaite. 2000. "The Industrial Organization of Health
Care Markets." In: Schmalensee R., Willig RD. (eds.), Handbook of Industrial Organization,
edition 3, volume 2, chapter 20, Elsevier, Amsterdam.
14. Gaynor, Martin, James B. Rebitzer, and Lowell J. Taylor. 2001. "Physician Incentives in
Health Maintenance Organizations." Journal of Political Economy, 112(4): 915-931.
15. Gaynor, Martin, and William B. Vogt. 2003. "Competition among Hospitals." RAND
Journal of Economics. 34(4): 764-85.

38

16. Gaynor, Martin, and William B. Vogt. 2000. "Antitrust and competition in health care
markets." in: A. J. Culyer & J. P. Newhouse (ed.), Handbook of Health Economics, edition
1, 1(27): 1405-1487 Elsevier.
17. Glied, Sherry. 2000. "Managed Care." Handbook of Health Economics, in: A. J. Culyer & J.
P. Newhouse (ed.), Handbook of Health Economics, edition 1, volume 1, chapter 13, pages
707-753 Elsevier.
18. Goldman, Dana P., and John A. Romley. 2008. "Hospitals as Hotels: The Role of Patient
Amenities in Hospital Demand." NBER Working Paper Number 14619.
19. Grumbach, Kevin, Janet Co¤man, Karen Vranizan, Noelle Blick, and Edward H. O’Neil.
1998. "Independent Practice Association Physician Groups in California." Health A¤ airs,
17(3): 227-237.
20. Grumbach, Kevin, Denis Osmond, Karen Vranizan, Deborah Ja¤e, and Andrew B. Bindman. 1998. "Primary Care Physicians’Experience of Financial Incentives in Managed-Care
Systems." The New England Journal of Medicine, 339(21): 1516-1521.
21. Hammelman, Eric, Narda Ipakchi, Jennifer Snow, and Bob Atlas. 2009. “Reforming Physician Payments: Lessons from California." California HealthCare Foundation www.chcf.org.
22. Ho, Kate. 2006. "The Welfare E¤ects of Restricted Hospital Choice in the U.S. Medical Care
Market." Journal of Applied Econometrics 21(7): 1039-1079.
23. Ho, Kate, and Ariel Pakes. 2011. "Do Physician Incentives A¤ect Hospital Choice? A
Progress Report." International Journal of Industrial Organization 29: 317-322.
24. Kessler, Daniel P., and Mark B. McClellan. 2000. "Is Hospital Competition Socially Wasteful?" Quarterly Journal of Economics, 115: 577-615.
25. Ketcham, Jonathan D., Pierre-Thomas Leger, and Claudio Lucarelli. 2012. "Standardization
Under Group Incentives." Working paper, Arizona State University.
26. Limbrock, Frank. 2011. "Pecuniary and Non-Pecuniary Incentives in Prescription Pharmaceuticals: The Case of Statins." The B.E. Journal of Economic Analysis and Policy, 1(2):
1.
27. Luft, Harold S., Deborah W. Garnick, David H. Mark, Deborah J. Peltzman, Ciaran S.
Phibbs, Erik Lichtenberg, and Stephen J. McPhee. 1990. "Does Quality In‡uence Choice of
Hospital?" The Journal of the American Medical Association, 263(21): 2899-2906.
28. McClellan, Mark B. 2011. "Reforming Payments to Health Care Providers: The Key to Slowing Healthcare Cost Growth While Improving Quality?" Journal of Economic Perspectives
25(2): 69-92.
39

29. Melichar, Lori. 2009. "The e¤ect of reimbursement on medical decision making: Do physicians
alter treatment in response to a managed care incentive?" The Journal of Health Economics,
28: 902-907.
30. Melnick, Glenn A., and Jonathan D. Ketcham. 2008. "Have HMOs Broadened Their Hospital
Networks? Changes in HMO Hospital Networks in California, 1999-2003." Medical Care 46(3):
339-342.
31. Muhlestein, David. 2013. "Continued Growth of Public and Private Accountable Care Organizations." Health A¤ airs Blog. Available at http://healtha¤airs.org/blog/2013/02/19/
continued_growth_of_public_and _private_accountable_care_organizations/.
32. Neyman, J., and Elizabeth L. Scott. 1948. "Consistent Estimation based on Partially Consistent Observations." Econometrica 16, 1-32.
33. Pakes, Ariel. 2010. “Alternative Models for Moment Inequalities.” Econometrica 78, 17831822.
34. Pakes, Ariel, Jack Porter, Kate Ho, and Joy Ishii. 2011. "Moment Inequalities and Their
Application." Harvard University working paper.
35. Robinson, James C. 2003. "Hospital Tiers in Health Insurance: Balancing Consumer Choice
with Financial Incentives." Health A¤ airs Web Exclusive W3: 135-146.
36. Robinson, James C., and Lawrence P. Casalino. 2001. "Reevaluation of Capitation Contracting in New York and California." Health A¤ airs Web Exclusive, W11-W19.
37. Rosenbaum, Paul R., and Donald B. Rubin. 1983. "The Central Role of the Propensity Score
in Observational Studies for Causal E¤ects." Biometrika. 70: 41-55.
38. Rosenthal, Meredith B., Richard G. Frank, Joan L. Buchanan, and Arnold M. Epstein. 2001.
"Scale and Structure of Capitated Physician Organizations in California." Health A¤ airs,
20(4): 109-119.
39. Rosenthal, Meredith B., Richard G. Frank, Joan L. Buchanan, and Arnold M. Epstein. 2002.
"Transmission of Financial Incentives to Physicians by Intermediary Organizations in California." Health A¤ airs, 21(4).
40. Song ZS, Safran DG, Landon BE, He Y, Ellis RP, Mechanic RE, Day MP and ME Chernew.
2011. "Health Care Spending and Quality in Year 1 of the Alternative Quality Contract."
The New England Journal of Medicine , 365(10): 909-918.
41. Sorensen. Alan T. 2003. "Insurer-Hospital Bargaining: Negotiated Discounts in Post-Deregulation
Connecticut." Journal of Industrial Economics, LI(4): 469-490.

40

42. Town, Robert J., and Gregory S. Vistnes. 2001. "Hospital Competition in HMOs." Journal
of Health Economics 20: 733-753.
43. Yegian, Jill M. 2003. "Tiered Hospital Networks: Re‡ections from the California HealthCare
Foundation." Health A¤ airs Web Exclusive W3: 147-153.

Figure 1: Correlation of Estimated Price Coe¢ cient with Insurer’s Percent Capitation
Payments

Notes: Graph to illustrate con…dence intervals for insurer price coe¢ cients, reported in Table 7.
Estimates are from model where () = (1 ¬  )(  ).

41

Figure 2: Graph of Constrained against Unconstrained Quality Estimates

Figure 3: Adding a Constraint to the Quality Estimates

Notes: Figure 2 plots constrained quality estimates against unconstrained estimates, where
unconstrained are  ( ) and constrained are de…ned as
exercise but de…nes constrained estimates as

42

0



+

0



+

  .

Figure 3 repeats the

 . See Section VII for details.

Table 1: Enrollment Data by Insurer
2002 enrollment

Birth

Commerc

Medicare

Medi-Cal

discharges

485,787

37,312

0

6,291

Blue Cross

3,486,358

251,299

1,099,044

25,038

Blue Shield

2,231,350

67,049

0

16,302

634,568

0

0

8,097

Health Net

1,665,221

101,317

349,826

16,950

Paci…care

1,543,000

386,076

0

15,479

Aetna

Cigna

Kaiser
5,790,348
671,858
104,844
0
Notes: Enrollment data on the six insurers in our analysis and on Kaiser Permanente. Source for
2002 enrollment: Baumgarten (2004). 2002 enrollment listed for commercial plans, Medicare
plans and Medi-Cal/Healthy Families plans. "Birth discharges": discharges in our data sample.

Table 2: Summary Statistics by Insurer
% Prim

Tax

Premium

Admin

Medical

Capitn

Status

pmpm

expense

loss ratio

discharges

days

drugs

Aetna

0.91

FP

152.42

19.33

86.2%

38.4

139.8

23.15

Blue Cross

0.38

FP

186.86

21.22

78.9%

38.4

142.4

20.92

Blue Shield

0.57

NFP

146.33

22.72

83.5%

50.3

176.4

20.51

Cigna

0.75

FP

-*

27.07

84.6%

39.8

137.1

15.63

Health Net

0.80

FP

184.92

18.60

86.3%

39.0

137.8

21.08

Paci…care

0.97

FP

149.92

24.51

88.4%

44.5

156.5

20.48

NFP

163.44

5.23

97.7%

49.1

158.1

0.44

Kaiser

Inpatient utilizn

Prescrip

Notes: Data on the six insurers in our analysis and on Kaiser Permanente. Source for all …elds
except percent capitation: Baumgarten (2004). "% Prim Capitn": percent of 2003 payments to
primary providers made on capitated basis (source: State of California Department of Managed
Health Care Annual Financial Reporting Forms). "Premium pmpm": HMO commercial premium
revenue per member per month (pmpm) (* information for Cigna not included in source data).
"Admin expense": 2002 pmpm administrative expenses for entire insurer, "Medical loss ratio":
2002 medical and hospital expenses / premium revenues for entire insurer. Inpatient utilization
and prescription drug data are for 2002 commercial plan; "discharges" is 2002 discharges per 1000
members, "days" is acute days per 1000 members and "Prescrip drugs" is outpatient prescription
drug expenses pmpm.
43

Table 3: Summary Statistics by Discharge
Birth only
Mean
Number of patients

88,157

Number of hospitals

195

Number of insurers

6

Hospitals per patient choice set

38

Std. Devn.

Teaching hospital

0.27

Distance to all hospitals (miles)

24.6

25.6

Distance to chosen hospital

6.7

10.3

List price

$13,312

$13,213

Discounted price

$4,317

$4,596

2.54

2.39

Died

0.01%

0.004%

Acute transfer

0.3%

0.02%

Skilled Nursing Transfer

1.5%

0.04%

Length of stay

Notes: Summary statistics for dataset comprising private enrollees of the six largest HMOs
excluding Kaiser who are admitted for delivery-related diagnoses. "Discounted price" is list
price*(1-discount). "Died" is the probability of death while in hospital, "Acute Transfer" the
probability of transfer to an acute care setting (in this or a di¤erent hospital) and "Skilled
Nursing Transfer" the probability of transfer to a skilled nursing facility (again at this or a
di¤erent hospital). "Std Devn" for "Died", "Acute transfer" and "Skilled Nursing Transfer" are
calculated under the assumption that the 0/1 variable is binomially distributed.

44

45

71074

2044

 40

1314

0
0.000

6227 (8135)

4256 (4265)
0.000

5.78% (0.6%)

2.33% (0.1%)

0.000

3.52% (0.4%)

2.36% (0.1%)

2.39% (0.06%)

Readmission

0.000

3.42% (0.5%)

1.58% (0.1%)

0.038

2.10% (0.3%)

1.60% (0.1%)

1.62% (0.05%)

Not Home

0.000

5735 (27745)

2619 (18101)

0.000

4337 (24787)

2627 (18103)

2675 (18324)

Price*(1-disc)

0000

12.3% (0.9%)

9.36% (0.1%)

0.365

9.64% (0.6%)

9.41% (0.1%)

9.42% (0.1%)

Readmission

Infant

0.000

10.5% (0.9%)

6.53% (0.1%)

0.000

9.88% (0.7%)

6.50% (0.1%)

6.60% (0.1%)

Not Home

of a t-test for price*(1-discount) and a z-test assuming two binomial distributions for Readmission and Not Home.

states signi…cance level at which we cannot reject the hypothesis that the means in the two samples are the same; these are the results

hospital) other than principal diagnosis where higher weight indicates higher severity. Value 0-6 are observed in the data. "Signif di¤"

assuming that the 0/1 variables are binomially distributed. Charlson scores assign weights to comorbidities (known on admission to

advice and death. Standard deviations in parentheses; for Readmission and Not Home we report standard errors which are calculated

somewhere other than home; this includes transfer to acute care setting, transfer to skilled nursing facility, discharge against medical

is percent of patients readmitted to hospital within 12 months of birth episode. "Not Home" is percent of patients discharged

Notes: Data taken from OSHPD Birth Cohort 2003 (a slightly di¤erent dataset that includes infant outcome variables). "Readmission"

Signif di¤

71804

0

Charlson

0.000

5420 (5571)

4259 (4329)

4291 (4373)

73118

 40

Signif di¤

Age

Overall

Price*(1-disc)

N

Mother

Table 4: Prices and Outcomes by Patient Type

46
88,157

Y

Y

43,742

Y

Y

0.001** (0.000)

43,742

Y

Y

0.001** (0.000)

43,742

Y

Y

0.001** (0.000)

44,059

Y

Y

0.001** (0.000)

44,059

Y

Y

0.001** (0.000)

-0.216** (0.002)

44,059

Y

Y

0.001** (0.000)

-0.216** (0.002)

-0.025** (0.008)

0.028** (0.006)

Notes: N = # of patients. **: signi…cant at the 5 percent level, *: signi…cant at the 10 percent level. Least sick: aged 20-39 with zero
Charlson scores and "routine" principal diagnoses and comorbidities (see Online Appendix 1). Sickest: all other patients.   :
interactions between hospital characteristics (teaching hospitals, for pro…t hospitals and hospitals that o¤er transplants, number of
nurses per bed, a variable summarizing quality of delivery services provided) and patient characteristics (probabilities of death while in
hospital, transfer to an acute care facility and transfer to a skilled nursing facility conditional on principal diagnosis, age category and
Charlson score). Sample sizes for sickest and least sick populations do not sum to total N because a small number of hospitals with
very few admissions were dropped when estimating on each subsample; patients choosing these hospitals were also dropped.

(194 coe¤ts)

Hospital F.E.s

(15 coe¤ts)

  controls

0.001** (0.000)

Distance squared

N

-0.217** (0.002)

0.014** (0.003)

0.008 (0.011)

Blue Cross
-0.215** (0.002)

0.024** (0.004)

0.018 (0.011)

Blue Shield

-0.215** (0.001)

0.004 (0.007)

-0.021 (0.014)

Cigna

Distance

0.007 (0.005)

-0.038** (0.011)

Health Net

-0.006 (0.006)
0.021** (0.008)

-0.215** (0.002)

0.012** (0.002)

-0.011 (0.016)

-0.127** (0.016)

0.069** (0.014)

Aetna

-0.215** (0.002)

-0.017* (0.009)

Sickest patients

-0.077** (0.012)

0.010** (0.002)

Least sick patients

Paci…care

Percent Capitated

Price interactions:

Price

All birth patients

Table 5: Logit Analysis Results

Table 6: Price Variance Across Aggregated Price and Severity Groups
Panel A: Max Rank 1
Number diags
of max rank

Pats

Price ($)

SD

1

23029

3431 (15)

1612

2

11757

4145 (28)

2180

3

4077

4682 (60)

2356

4

1179

5505 (149)

2590

5

331

6189 (254)

3123

5

95

7663 (936)

4896

Total

40468

3857 (15)

Panel B: Max Rank 2
Number diags
of max rank

Pats

Price ($)

SD

1

13128

4968 (42)

2476

2

4196

6019 (88)

2785

3

1274

7428 (212)

3609

4

380

8602 (462)

5283

5

110

10186 (1002)

6084

5

55

13365 (1596)

8880

Total

19143

5488 (40)

Panel C: Max Rank 3
Number diags
of max rank

Pats

Price ($)

SD

1

1273

7448 (356)

4256

2

64

11536 (2337)

20370

3

8

12733 (4009)

11338

4

1

25573 (-)

-

5

0

-

5

0

-

Total

1346

7687 (13065)

Notes: Distribution of patients from inequalities sample who have a Charlson score of 0 across
comorbidity ranks. “Pats” shows the number of patients in each "max rank" group and each
"number diags of max rank" group. Here "Max rank j" means the maximum rank of a
comorbidity for this patient, as de…ned by obstetrical experts at Columbia Presbyterian Hospital,
is j. "Number diags of max rank" groups patients according to the number of comorbidities in
their discharge record with the relevant max rank. Patients in di¤erent rows of a particular
column of the table within a panel will have di¤erent price groups. "Price ($)" is the average
47

observed price*(1-discount) for patients in this group; standard errors in parentheses. "SD" is the
cross-hospital standard deviation of the mean observed price*(1-discount) in this hospital for the
patients in this group.

Table 7: Results of Inequalities Analysis
Column 1
percent
capitated

() = (1 ¬  )(  )
^
[    ]

Column 2
~    0 )+
(
^

[ 

  ]

Paci…care

0.97

-1.50**

[-1.68,

-1.34]

-1.42**

[-1.66,

-0.94]

Aetna

0.91

-0.92**

[-0.95,

-0.86]

-0.73**

[-0.77,

-0.66]

0.80

-0.17**

[-0.27,

-0.13]

-0.60**

[-0.71,

-0.51]

-0.78**

[-0.80,

-0.44]

-2.16**

[-2.26,

-1.13]

Health Net

Baseline
Drop t

-2

Cigna

0.75

-0.35**

[-0.40,

-0.33]

-0.66**

[-0.71,

-0.58]

Blue Shield

0.57

-0.06

[-0.15,

0.23]

set

[-0.95,

0.65]

0.38

-0.10**

[-0.24,

-0.01]

-0.27**

[-0.31,

-0.25]

Blue Cross

Baseline

Drop t -2
-0.29** [-0.31, -0.25] -0.31** [-0.34, -0.27]
Notes: Results of inequalities analysis. **: signi…cant at the 5 percent level, *: signi…cant at the
10 percent level. We include 157 hospitals in total. Estimated coe¢ cient is the ratio of the price
coe¢ cient to the distance coe¢ cient in the utility equation, where prices are measured in $000
and distance in tens of miles. Price calculated using the observed average hospital discount.
Speci…cation includes four distance-based instruments (positive and negative parts of
(  ) ¬ (  0 ) for each patient) plus a constant in the instrument set. In Column 2 these

instruments are replaced with indicators for distance di¤erences being greater than 3 miles. The
rows labeled "drop t

-2" report results when we dropped moments whose t-statistic values were

less than -2 (2 out of 182 for Health Net; 5 out of 285 for Blue Cross) and repeated the estimation
process. "set" for Blue Shield in Column 2 indicates a range of values.

48

Table 8: Inequalities Analysis, Di¤erent Price Measures

percent

Column 1
() = (1 ¬ ^1 )(  )
^

[ 

  ]

Column 2
() = (1 ¬ ^2 )(  )
^

[ 

  ]



capitated



Paci…care

0.97

-1.07**

[-1.52,

-0.62]

-1.47**

[-1.64,

-1.32]

Aetna

0.91

-0.68**

[-0.72,

-0.62]

-0.77**

[-0.81,

-0.71]

0.80

-0.11**

[-0.23,

-0.07]

-0.20**

[-0.30,

-0.17]

-0.41

[-0.43,

0.94]

-1.87**

[-1.89,

-1.33]

Health Net

Baseline
Drop t

-2

Cigna

0.75

-0.35**

[-0.39,

-0.33]

-0.32**

[-0.36,

-0.30]

Blue Shield

0.57

0.18

[-0.16,

0.79]

0.004

[-0.28,

0.70]

0.38

-0.03

[-0.18,

0.39]

-0.09**

[-0.22,

-0.01]

-0.12**

[-0.14,

-0.05]

-0.18**

[-0.21,

-0.14]

Blue Cross

Baseline
Drop t

-2

Notes: Results of inequalities analysis using di¤erent price measures. See notes to Table 7 for
details. **: signi…cant at the 5 percent level, *: signi…cant at the 10 percent level. Price measures
are calculated using the two estimated hospital-insurer level discounts discussed in Section VI.
Rows labeled "drop t

-2" report results when we dropped moments whose t-statistic values

were less than -2 (2 out of 182 for Health Net; 5 out of 285 for Blue Cross) and repeated the
estimation process.

49

Table 9: Summary of t-statistics from Inequalities Analysis

Paci…care

Aetna

Health Net

Cigna

Blue Shield

Blue Cross

Number positive

152

75

173

93

170

254

Ave value of positive

12.7

22.5

17.1

19.5

19.1

21.5

Number negative

11

3

9

2

4

31

Number t < -2

0

0

2

0

0

5

Summary of t-statistics

Notes: Summary of estimated t-statistics of the moments used in inequalities analysis. T-statistic
= value of the moment at the estimated



(for speci…cation where () = (1 ¬  )(  )).

Under the model all moments should be non-negative.

Table 10: Magnitudes of Logit and Inequality Results

percent

Logits

Inequalities

(less-sick patients)

(all patients)

capitated

average

average



Paci…care

0.97

0.33

11.08

Aetna

0.91

0.10

11.47

Health Net

0.80

0.15

6.52

Cigna

0.75

0.10

2.49

Blue Shield

0.57

-0.08

0.51

Blue Cross

0.38

-0.03

3.24

Notes: Estimated cross-patient average value of



=

 
 



for each insurer implied by logit and

inequality analyses. Logit model uses less-sick population as de…ned in notes to Table 5.
Inequality model uses price de…ned using discount

50



(Column 1 of Table 7).

Table 11: Trade-o¤s Aggregated Over Markets and Severities.
Insurer
% cap
p;

p;

=

1=

P-care

Aetna

HNet

Cigna

BC

0.97

0.91

0.80

0.75

0.38

-1.50

-0.92

-0.78

-0.35

-0.29

5.13

3.12

2.63

1.20

1.00

-0.293

-0.295

-0.297

-0.291

-0.290

0.20

0.32

0.38

0.83

1.00

Upper and Lower Bounds on C.I.

p;

=

Lower

-0.38

-0.36

-0.35

-0.40

-0.31

Upper

-0.23

-0.23

-0.15

-0.22

-0.25

Calculated as lower bound (upper bound)



divided by upper bound (lower bound)

.

Table 12: Cost-Quality Trade-o¤s By Market and Severity
Insurer
LA S1
LA S2
LA S3
LA S4
LA S5
Bay S1
Bay S2
Bay S3
Bay S4
Bay S5
Ora S1
Ora S2
Ora S3
Ora S4
Ora S5
SD S1
SD S2
SD S3
SD S4
SD S5
IE S1
IE S2
IE S3
IE S4
IE S5

P-care
-0.29
-0.33
-0.28
-0.31
-0.29
-0.34
-0.44
-0.37
-0.38
n/a
n/a
n/a
n/a
n/a
n/a
-0.42
-2.07
-0.40
-0.28
-1.31
-2.02
-1.37
-1.02
-0.52
n/a

Aetna
-0.29
-0.31
n/a
-0.30
n/a
-0.32
-0.89
-0.35
-0.31
n/a
-0.28
-0.21
-0.24
-0.41
n/a
-0.55
-0.88
-0.43
-0.23
n/a
-0.68
n/a
n/a
n/a
n/a

HNet
-0.29
-0.31
-0.30
-0.32
n/a
-0.32
-0.48
-0.39
-0.29
-0.19
n/a
n/a
n/a
n/a
n/a
-0.41
-0.50
-0.51
-0.28
-56.5
-0.81
-0.78
-0.50
-0.67
n/a

Cigna
-0.29
-0.39
-0.29
-0.34
n/a
-0.30
-0.43
-0.33
-0.33
-0.35
-0.28
-0.31
-0.30
-0.40
-0.69
-0.26
-107.9
-0.31
-0.73
n/a
-0.46
n/a
n/a
n/a
n/a

BC
-0.29
-0.29
-0.29
-0.29
-0.29
-0.29
-0.29
-0.29
-0.29
-0.29
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
-0.290
n/a

LA=Los Angeles, Bay=Bay Area, Ora=Orange County, SD=San Diego,IE=Inland Empire.
51

