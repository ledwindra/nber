NBER WORKING PAPER SERIES

THE DECLINING EFFECTS OF OSHA INSPECTIONS ON
MANUFACTURING INJURIES: 1979 TO 1998

Wayne B. Gray
John M. Mendeloff

Working Paper 9119
http://www.nber.org/papers/w9119

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2002

We are grateful to several agencies for financial support: to the National Institute of Occupational Safety and
Health (R01-OH03895-03) for this analysis and the creation of the 1992-98 data set, to the National Science
Foundation (SES-8420920) for creation of the 1979-85 data, and to the Bureau of Labor Statistics (research
contract J-9-J-5-0085) for creation of the 1987-91 data. We would also like to thank John Ruser, John Scholz,
and David Weil for valuable comments on an earlier draft of this manuscript, and Nichola Thomson for
research assistance. The research was conducted with restricted access to Bureau of Labor Statistics (BLS)
data on-site at the BLS. The views expressed here are those of the authors, and do not necessarily reflect the
views of the BLS or other supporting agencies. The views expressed herein are those of the authors and not
necessarily those of the National Bureau of Economic Research.

© 2002 by Wayne B. Gray and John M. Mendeloff. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is
given to the source.

The Declining Effects of OSHA Inspections on Manufacturing Injuries: 1979 to 1998
Wayne B. Gray and John M. Mendeloff
NBER Working Paper No. 9119
August 2002
JEL No. J28
ABSTRACT
This study compares the impact of OSHA inspections on manufacturing industries using data
from three time periods: 1979-85, 1987-91, and 1992-98. We find substantial declines in the impact of
OSHA inspections since 1979-85. In the earliest period we estimate that having an OSHA inspection that
imposed a penalty reduces injuries by about 15%; in the later periods it falls to 8% in 1987-91 and to 1%
(and statistically insignificant) in 1992-98. Testing for different effects by inspection type, employment
size, and industry, we find differences across size classes, but these cannot explain the overall decline.
In fact, we find reductions in OSHA’s impact over time for nearly all subgroups we examine, so shifts
across subgroups cannot explain the whole decline. We examine various other hypotheses concerning
the declining impact, but in the end we are not able to provide a clear explanation for the decline.

Wayne B. Gray
Economics Department
Clark University
950 Main Street
Worcester, MA 01610
and NBER
wgray@clarku.edu

John Mendeloff
Graduate School of Public and
International Affairs
University of Pittsburgh
3E34 Forbes Quad
Pittsburgh, PA 15260
jmen@birch.gspia.pitt.edu

1.Introduction
Congress established the Occupational Safety and Health Administration (OSHA) in
1970 to prevent occupational injuries and illnesses, and there has been considerable debate
since then over the effectiveness of the program. OSHA does tens of thousands of
inspections, and imposes millions of dollars in penalties each year, but most workplaces are
only rarely visited, penalties are low relative to the cost of abating many workplace hazards,
and many injuries are unrelated to OSHA standards.
Many empirical studies examining OSHA have found little evidence of an impact on
injuries (e.g. Smith (1979), Viscusi (1979, 1986), McCaffrey (1983), Bartel and Thomas
(1985), Ruser and Smith (1991)). By contrast, a series of studies by Scholz and Gray found
significant impacts, using a large plant-level database for the 1979-85 period. Depending on
the analytical technique used, having an OSHA inspection which imposed a penalty was
associated with a 15-22% decline in injuries over a three year period (Scholz and Gray
(1990), Gray and Scholz (1993)).
The present study extends these analyses to more recent years. To the 1979-85
dataset used by Scholz and Gray we add a 1987-91 dataset created earlier by one of the
authors (Gray (1996)), and a final 1992-98 data set created for this study. Although there
are some differences in sample composition across the three data sets, we use the same
variables and analyses for all three data sets to make the results as comparable as possible.
We find that the average impact of OSHA inspections on changes in injury rates has
declined substantially over time, especially in the most recent data set, where the overall
impact is no longer statistically significant. Using our basic model, the point estimate of the
impact of an OSHA penalty inspection declines from 15% in the early 1980s to 8% in the

1

late 1980s and about 1% in the 1990s. Models which include all OSHA inspections (with
and without penalties) show smaller impacts, but these impacts also decline across the three
periods.
We looked for different impacts across various subgroups: inspection types,
establishment sizes, and industries. We do observe smaller impacts in the largest
establishments. However, we observe declines over time in the impact of OSHA
inspections on injuries within nearly all subgroups we examine, although the declines occur
to different degrees and at different times. The paper also examines a variety of possible
explanations for the decline in impact, but we aren’t able to provide a clear explanation for
the decline.
The following section of the paper provides some background on the determinants of
occupational injuries and OSHA’s activity. Section 3 discusses the data and some
econometric issues affecting the analysis. Section 4 presents the results, and Section 5
summarizes the findings.

2. Background and Theory

Figure 1 shows the injury rate per 100 full-time manufacturing workers from 1972 to
1999. The numbers are based on reporting to the annual Survey of Occupational Injuries
and Illnesses, conducted by the Bureau of Labor Statistics (BLS). The “lost workday case
rate” is divided into two categories: cases with days away from work and cases with only
restricted work activity. The rate for all lost workday cases changed relatively little from
1972 until the early 1990s, except for the expected cyclical changes. Injury rates typically

2

fall in recessions and increase in booms, primarily because of the changes in the number of
newly hired, inexperienced workers (Robinson (1988)). However, in the 1990s the
manufacturing injury rate dropped by about 25% despite continuous prosperity during those
years. We also see in Figure 1 that the rate of injuries with restricted work activity rose
substantially after the mid-1980s while the rate for cases with days away from work
accounted for the decline in the 1990s (we return to this issue later).
OSHA may affect injuries through several possible mechanisms (Mendeloff (1979)).
The agency enforces a set of safety and health standards and may create new standards. It
also provides information to employers and employees, both directly through consultations
and training activities and through the provision of educational materials. Most of OSHA’s
resources are devoted to its enforcement program. Inspections, backed up by the threat of
penalties for non-compliance, may push employers to comply with standards or even to
improve their overall safety programs. The threat of inspection may also generate
compliance actions in order to avoid expected penalties. Even though most workplaces are
inspected infrequently, especially in industries with low injury rates, the ability of workers
to request OSHA inspections enhances their potential deterrent effect.
Equation (1) below summarizes a variety of factors that may influence the riskiness
of working at plant i in year t (RISKit). We begin with the inherent hazardousness of the
plant which may change over time (HAZARDit), the average experience or inexperience of
the plant’s workforce (EXPERit), and the degree of worker fatigue (FATIGUEit). In
addition we have three factors affecting the attention paid by the plant to safety issues. The
degree of general deterrence achieved by OSHA inspections at other plants in the same area
and industry (GENit) depends on both the expected probability of being inspected and the

3

expected penalty for a violation (with penalty and probability getting equal weight if the
firm is risk-neutral). There may be a separate impact of current or past inspections
happening at this specific plant (INSPit-s), either because having an inspection leads the plant
to revise its expectations on the probability of future inspections or because OSHA follows
up some inspections to ensure that hazards are corrected, with the possibility of much higher
‘failure to abate’ penalties. ATTENit includes any other factors such as plant unionization
or workers compensation costs which could affect attention to safety.

(1)

RISKit = f(HAZARDit, EXPERit, FATIGUEit, GENit, INSPit-s, ATTENit).

The actual number of injuries occurring in a workplace in a given year will depend
strongly on the underlying riskiness, along with some random error term. These errors may
be greater (in percentage terms) in smaller workplaces. To the extent that unusually high
injuries at time t-1 leads to increased attention to safety issues at time t, we would expect
some degree of negative autocorrelation in the unobserved random element of injuries.

3. Data and Econometric Issues
The basic sample universe for the data sets has remained unchanged from the
original Scholz and Gray data set: establishments that are in manufacturing industries and
are located in states where OSHA has primary enforcement responsibility (the 29 “FederalOSHA” states, which include about 60% of the national work force). Manufacturing
workplaces have long been a focus of OSHA activity and are longer-lived and better-defined
than workplaces in other sectors (such as construction). This is important, since we allow

4

OSHA inspections to affect injuries over several years. Information on injuries at the
establishments is merged with characteristics of OSHA inspections at those establishments
to create the analysis data sets.
Our injury data comes from the Bureau of Labor Statistics (BLS) Survey of
Occupational Injuries and Illnesses which gathers data for hundreds of thousands of
establishments each year in a stratified sampling process that results in larger establishments
being more likely to be in the sample. Since we look at changes in an establishment’s
injuries over time we focus on those establishments that have BLS injury data for
consecutive years. This necessarily results in large establishments being over-represented in
our data sets, relative to all manufacturing establishments. We use the total number of lostworkday injuries during the year as our injury measure. Earlier work with the first two data
sets also examined a measure of the seriousness of the injuries, the total number of days of
work lost due to injuries at the plant; but that information is not present in the revised
version of the BLS Survey which was begun in 1992.
The BLS data is combined with information on OSHA inspections from OSHA’s
Integrated Management Information System (IMIS). Our key measure of inspection activity
(in addition to the year of the inspection) is whether or not a penalty was imposed.1 We
consider only two types of inspections: programmed inspections, targeted by OSHA based
on industry hazardousness, and complaint inspections, where OSHA is responding to a
written worker complaint. These two types account for over 80% of all inspections during
the time period studied.2 For almost all of the period examined in this paper, OSHA
targeted its programmed inspections by first identifying all establishments that were in 41

As reported in Scholz and Gray (1990), having a serious violation cited during the inspection is essentially
equivalent to having a penalty (95-99% overlap in our data).

5

digit SICs with rates above a state’s manufacturing average (Siskind (1993)). Then, it chose
inspection sites randomly within this set, excluding only those workplaces with fewer than
11 workers or those where OSHA had conducted a comprehensive inspection within the
previous 2 years. Complaint inspections were initiated by a written (formal) or oral
(informal) notice from a worker (or a union representative) about an alleged violation or
hazard at a workplace
The OSHA and BLS records were linked together, using name and address
information to identify records that referred to the same establishment in a technique
developed by Fellegi and Sunter (1969) that calculates the probabilities of two records
matching, based on agreement or disagreement on their characteristics. The matching
methodology is explained in more detail in Gray (1996).
Since our analysis focuses on injury changes, two consecutive years of BLS data are
needed to generate one observation for analysis. Table 1 describes some features of the 3
data sets. The original Scholz and Gray data set was restricted to those manufacturing
establishments which had BLS injury data available for all 7 of the years from 1979 and
1985, but a broader definition was needed in the later samples due to substantial cuts in the
BLS Survey sample size later in the 1980s. The 1987-91 dataset included all plants with at
least 2 consecutive years of BLS Survey data; the 1992-98 dataset includes all plants with at
least 3 consecutive years. If we had instead insisted on 7 years of BLS Survey data in 199298, the size distribution would have been seriously skewed: of the 860 establishments with
7 years of data, only 21 had fewer than 100 employees and only 60 had fewer than 250.
This would have precluded any analysis of OSHA’s impact in those smaller size groups
which receive the majority of OSHA inspections.
2

Calculated from OSHA IMIS data for inspections of manufacturing plants in federal OSHA states.
6

The basic model estimated by Scholz and Gray took the following form:
(2) DINJi t = at + b0INSPi t + b1INSPi t-1 + b2INSPi t-2 + b3INSPi t-3 +
c1DEMPit + c2DHRSit + SIC2i + uit

The dependent variable (DINJ) is the log of the change in the number of injuries, so the
coefficients show the impact on the percentage change in injuries. Gray and Scholz (1993)
report extensive tests with alternative specifications. Since OSHA targets inspections at
high-injury-rate establishments, regressions of injury levels on inspections show a positive
(endogenous) relationship. They find that using injury changes greatly reduces the
endogeneity problem, and we follow this specification.
Our focus is on the specific deterrence impact of OSHA inspections at this particular
plant. This impact is captured with four inspection dummies (from INSPit to INSPit-3), so
the 1983-84 change in injuries depends on four years of inspections (from 1981 to 1984).
An alternative OSHA measure, IPEN, refers to inspections which imposed a penalty
(following Scholz and Gray (1990)). In some models we allow for different impacts for
different inspection types, IPRG and ICMP for any programmed and complaint inspections,
and IPRGP and ICMPP for programmed and complaint inspections imposing penalties.
Relating the other explanatory factors to those in Equation (1), we use changes in
employment (DEMPit) to measure changes in the experience of the workforce and changes
in hours (DHRSit) to measure changes in worker fatigue. To the extent that innate
hazardousness is fixed at a workplace, it will be differenced out of the model in change

7

form. Trends in industry hazardousness or changes in general deterrence are measured by
industry dummies (SIC2i). In some of our analyses we allow for differences in the impacts
of OSHA inspections for establishments in different employment size categories (1-99, 100249, 250-499, and 500+). When we do so, we include three employment size dummies in
the regressions.
In some models we estimate different impacts of OSHA inspections for each 2-digit
SIC industry in each period. We then compare the estimated impacts with three different
industry-specific factors. First is the extent of general deterrence, measured by the number
of OSHA inspections per 1000 production workers in the federal OSHA states.3 Second is
the industry hazardousness, measured by the industry lost workday injury rate (taken from
the BLS web site, www.bls.gov). Third is the industry’s new capital investment divided by
its existing capital stock, since newer machinery is expected to be safer.4
One issue that arises when comparing the results here with the published results of
the earlier studies is the choice of estimation method. All of the results presented here are
based on ordinary least squares regressions. Earlier studies (such as Scholz and Gray
(1990)) allowed for autoregressive errors, recognizing the possibility that shocks to injuries
in one year might increase attention to safety, generating negative autocorrelation or
regression to the mean in the injury generating process. We experimented with estimating
an autoregressive model with the newest data set, and found that while the autoregressive
terms were estimated to be significant, the results for the inspection variables were
essentially unchanged from those reported here (results available on request).

3

OSHA inspection totals from website: http://www/osha.gov. Data on production workers from Employment
and Earnings, various issues.
4
The data came from the NBER-CES Manufacturing Industry Database, which contains data only through
1996, so the 1992-98 period uses the 1992-96 average instead.

8

More importantly, some of the earlier analyses of data from 1979-85 and 1987-91
used a ‘Chamberlain’ model (Chamberlain (1982, 1984)), which allows for the possibility
that inspection targeting leads the set of plants selected for inspections to include more
plants with poor performance in terms of injury growth (Gray and Scholz (1993), Gray
(1996)). Correcting for this selection effect results in a greater (negative) impact of
inspections on injury growth, with the model concluding that the inspected plants would
have done even worse if they had not been inspected. In the earlier research, using the
Chamberlain method increased the estimated impact of an inspection with penalty in the
1979-1985 period by 7%, from 15% to 22%. Using the 1987-1991 period the comparable
impact also rose by 7%, from 8% to 15%.
Preliminary estimates of the Chamberlain model for the most recent period suggest a
similar impact (the reduction in injuries after a penalty inspection increases in magnitude
from about 1% using ordinary regression to about 7% using the Chamberlain model). Thus
the comparison across time periods gives a similar conclusion to the ordinary regression
results presented here, with a substantial reduction in the impact of an inspection with
penalty between Period 1 and Period 3. We concentrate on ordinary regression results in
this paper primarily because the Chamberlain estimation method requires complete injury
data, and hence can only be calculated for a small and unrepresentative minority of the
plants in the 1992-1998 period (860 plants, nearly all of them in the larger size categories,
with more than 250 employees).

9

4. Results
Table 1 presents the means of the variables in the three data sets. There is a decline
in injuries over time (negative DINJ) within each of the three data sets. However, this does
not mean that rates declined continuously from Period 1 to Period 3. Each period happens
to begin when rates were fairly high and end when they were lower. The establishment size
distribution differs somewhat between the three data sets, based on changes in the BLS
Survey coverage and the number of years of injury data required for inclusion. The period 2
data set contains more small plants, since it only required two consecutive years of injury
data; the latest data set contains a higher proportion of large plants, due to the steady
shrinkage in the BLS Survey sample size.
Table 1 also reveals some substantial changes in OSHA inspection activity across
the three data sets. In the earliest data set there were relatively high rates of inspections
(INSP), especially programmed inspections (IPRG). These inspections commonly failed to
impose penalties; only about one-third of all years with inspections had any inspections that
imposed penalties (IPEN), but in the later two periods this ratio was reversed. This pattern
can be explained by the existence of “records-check” inspections during the early 1980s;
these inspections began with a check of the plant’s injury rate records and stopped there if
the plant’s injury rate was below the average rate for manufacturing (Siskind (1993)). This
led to a large set of programmed inspections that did not impose a penalty (and did not
perform a ‘real’ inspection of the workplace).
There was also some variation in the composition of inspections across the periods.
Because of the prevalence of programmed inspections (IPRG) in the first period, they
greatly outnumbered complaint (ICMP) inspections (.19 to .06). In the later periods the

10

probability of a complaint inspection rose slightly (to .07), while the probability of a
programmed inspection fell dramatically (to .03). There was also an increase in the fraction
of complaint inspections which imposed penalties (ICMPP) over time, though not as
dramatic as the increase noted above for programmed inspections (IPRGP).
Table 2 shows the basic regressions of injury changes on inspections and inspections
with penalty. The first column presents results from the original Scholz and Gray data set
from 1979-85. The second and third columns present results from the 1987-91 and 1992-98
data sets. As expected, growth in employment and hours worked increases the number of
injuries. Perhaps due to the ‘random’ nature of workplace accidents, the models only
explain about 12% of the variance in injury changes across plants in the earlier two periods,
declining to about 9% in the latest period.
As found in the Scholz and Gray analysis, inspections with penalties have a larger
impact than other inspections (comparing IPEN with INSP). The main result in Table 2 is
that both IPEN and INSP coefficients became smaller in each succeeding period. Adding
up the cumulative IPEN effect in each period, it declines from 15.7% to 9.4%, then to 1.4%,
with the last period’s impact not statistically significant. We also combined data from all 3
periods in order to formally compare the IPEN coefficients across periods. The results (not
shown) confirm that the Period 3 results are significantly different from those in Period 1.
In Table 3 we see the impact of combining the four years of OSHA inspections into
a single variable. IPENX shows the average impact of an inspection over a four year period,
so the cumulative impact is falling from 19.2% to 12.0% to 1.2% across the three periods.
Comparable regressions for each period including both IPENX and inspections with no
penalty (NOPENX) always found insignificant coefficients on NOPENX (results available).

11

The initial regression results presented in Tables 2 and 3 provide evidence of a
substantial decline in the measured impact of OSHA inspections on manufacturing
industries. We now consider different categories of inspections and establishments to see
how widespread the decline is. Looking at inspection type, Scholz and Gray (1997) found
that both complaint and programmed inspections affected injuries, but that complaint
inspections were less dependent on penalties for their impact. Table 4 shows the impact of
complaint and programmed inspections on injuries in each of the periods, confirming that
programmed inspections are more dependent on penalties for their impact. The impact of
complaint inspections with penalties declines more in the 1980s, while the impact of
programmed inspections with penalties declines more in the 1990s. However, these
differences between the inspection types were not statistically significant.
Next we allow the impact of OSHA inspections to differ depending on
characteristics of the establishment. Table 5 examines the effects of inspections with
penalties in 4 different establishment employment size categories: small, under 100;
medium, 100-249; big, 250-499; and very big, over 500. We find much weaker preventive
effects of inspections in the largest establishments compared to the smaller establishments
(similar to results reported in Gray and Scholz (1991)). As expected, the model does a
better job of explaining the variation in number of injuries for larger workplaces. More
importantly we have declines in the estimated impact across the periods for nearly all cases,
and always smaller impacts in Period 3 than in Period 1. The timing of the decline varies
across size classes, but the decline is statistically significant for all but the medium plants.
Next we allowed for different OSHA impacts across different industries, shown in
Table 6. Examining the model for all 3 periods together, we added interaction terms

12

between IPENX and two-digit SIC manufacturing industry dummies. Each interaction term
provides an estimate of the effect at an establishment in that industry of having at least 1
inspection with penalty over a four year period. There are a few significant industry
coefficients, but there is no industry where the effect of inspections with penalties is
significant in more than one period. Not surprisingly, there is no significant correlation
across industries in their coefficients for different periods.
Table 7 tests whether these industry-period coefficients are correlated with three
factors that might affect OSHA’s impact: the average lost workday injury rate in the
industry (bigger effects if there are more injuries per worker to prevent), the average
inspection rate in the industry (smaller effects when firms are expecting OSHA inspections),
and the average investment rate in the industry (smaller effects where there is newer, safer
machinery). These correlations are relatively small, and only two approach significance.
For industry coefficients based on all workplaces, higher investment rates were weakly
linked to smaller inspection impacts. Looking at workplaces with fewer than 250 workers
(where the effects were relatively larger in the last period), the link with investment rates
disappears but a weak negative relationship appears with the industry inspection rate.
Finally, we consider the possibility that OSHA inspections have different impacts on
different types of injuries. Table 8 shows the results for our basic model, separated into
cases with days away from work (DAW) and cases with only restricted work activity
(RWA). One clear finding is that, even in Period 1, all of the impact of inspections with
penalties was on DAW injuries. There was no impact on RWA injuries. In Period 2, there
is even some indication that inspections were linked to increases in RWA injuries, but this
disappears in Period 3.

13

5. Discussion and Conclusions
The initial regression results presented in Tables 2 and 3 provide evidence of a
substantial decline between 1979 and 1998 in the measured impact of OSHA inspections on
manufacturing industries: from a 15% reduction over the three years after an inspection with
penalty in Period 1, to a 1% reduction in Period 3. In this section we consider several
possible explanations for the decline, based on changes in OSHA policy and injury reporting
during this time, and relate them to our statistical results.
One explanation for the decline could be a composition effect, with the data for
Period 3 inspections containing more observations where OSHA’s impact is small. Table 5
does show a smaller impact for large plants, which are more common in our data for Period
3 than they were in Period 1. This turns out to be offset by shifts in other groups, so the
predicted average impact is actually higher in Period 3.5 More importantly, the results for
all subgroups of the data show that the decline in OSHA’s impact is wide-spread, affecting
different inspection types, plant sizes, and industries, so it is unlikely that any composition
effects could tell the whole story.
Other explanations for the decline could arise from measurement issues. During
most of Period 1 (1981-86) OSHA inspectors on programmed inspections followed a
“records- check” procedure: first checking a workplace’s lost workday injury and illness
rate, and terminating the inspection if the rate was below the manufacturing average. Such
“records-only” inspections never imposed penalties, so firms wishing to avoid OSHA

5

The predicted impact was obtained by multiplying the Period 1 coefficients for each size group in Table 5 by
that group’s share of plants in each of the periods from Table 1.

14

inspections had an incentive to under-report injuries. Ruser and Smith (1988, 1991) found
evidence that lost workday rates fell for some plants subject to these inspections, but only
for uninspected establishments. This would lead our results to understate (not overstate) the
impact of inspections on injuries in the earlier period.
Injury reporting might also have been affected by OSHA’s “egregious case” policy,
which started levying extremely large and highly publicized fines for recordkeeping
violations in 1986; if underreporting declined more at inspected establishments than
uninspected ones this would translate into a smaller observed OSHA impact. Still, this
seems unlikely to have played a large role in the observed decline, since it would explain
only the Period 2 changes, not the continuing decline in Period 3.
Another reason why OSHA’s records-check policy might affect our cross-period
comparison is that plants with penalty inspections would include a disproportionate number
with unusually high pre-inspection injury rates (since they weren’t records-only). These
high rates might then be expected to decline in the years following the inspection (a
phenomenon known as “regression to the mean”). Scholz and Gray (1990) account for this
using a model with autoregressive errors and find that there was evidence of negative
autoregression (consistent with regression to the mean), but that the estimated OSHA
impacts were not affected. As noted earlier, we also examined autoregressive models and
found they didn’t affect our results. Even if regression to the mean led us to overstate our
Period 1 results, that should have led the decline in OSHA’s impact in later periods to be
concentrated in the results for programmed inspections, and to happen by Period 2. Table 4
shows a greater decline in the 1980s for complaint inspections with penalty, which were not

15

subject to the records-check policy; the decline in impact for programmed inspections
doesn’t come until the 1990s, well after the records-check policy was being discontinued.
A final reporting issue arises due to the steady growth since the mid-1980s in the
percentage of lost workday injuries that are classified as “restricted work activity” cases
rather than as cases with “days away from work.” As Figure 1 showed, the rate of RWA
cases grew very slowly until the mid 1980s, then almost doubled in the 2 years from 1986 to
1988 and continued growing at over 10% per year until 1995. Thus by 1996 about ½ of all
lost workday cases in manufacturing did not involve days away from work. We saw in
Table 8 that in every period, even 1979-85, OSHA inspections with penalties had no
preventive impact on the percentage change in the number of RWA injuries. Based on an
assumption of zero impact on RWA cases, over one-third of the drop in OSHA’s impact
could be accounted for by the growth of RWA cases. Of course, this is an explanation only
in an accounting sense; it provides no causal insights about why RWA cases have not been
affected. Indeed, since the growth in RWA cases in the more recent periods presumably
comes from cases that formerly would have been DAW cases, it is a puzzle why they are not
affected similarly by OSHA inspections.
We now turn to explanations for the decline in OSHA’s impact that do not rely on
reporting changes or mismeasurement issues. A large increase in general deterrence could
in theory weaken the impact of specific deterrence that we measure, but the evidence in
Table 7 goes the other way: higher industry inspection rates are associated with more
negative (larger) inspection-specific impacts. This reversed sign (if believable) could
explain a small part of the decline in impact by the 1990s, when the number of inspections
fell by more than one-third and total penalties fell as well.

16

Another possible explanation is declining marginal effectiveness of repeated
inspections at the same workplace. Evidence for this has been found in past research (Weil
(2001), Gray and Jones (1991)). Since larger establishments are inspected more frequently,
the greater erosion in effectiveness that we find in the largest size group from Period 1 to
Period 2 and then in the next largest from Period 2 to Period 3 is consistent with declining
marginal effectiveness. The problem with this explanation is that OSHA had been
conducting inspections for nearly a decade before our Period 1, and the declining impact of
repeated inspections is most pronounced in the first few inspections, so most of the decline
in impact at large, frequently inspected plants should have already occurred by the start of
our data in 1979.
A somewhat different explanation for declining effectiveness of inspections could be
that the standards that OSHA enforces have become less relevant to injury prevention over
time. Most of these standards date from the 1960s or earlier. Changes in manufacturing
technologies may have left many of the standards outdated or irrelevant. As a result, we
could find either that fewer violations are being detected or that inspections are relevant to a
shrinking percentage of injuries. The number of violations cited per manufacturing
inspection was substantially lower in the first period (2.4) than in the latter two periods (5.2
and 4.7), contradicting the first of these predictions. The second is harder to assess. The
results in Table 7 on investment rates provide a bit of support, since high-investment
industries (with newer, safer equipment) show a smaller impact from OSHA inspections, but
the effect disappears for those establishments with fewer than 250 workers (the only size
group with substantial effects in the last period).

17

Rising costs for workers’ compensation may have stimulated employers to increase
their efforts to a) prevent injuries, b) discourage workers from making claims, and c)
manage the disability process more closely to reduce the costs of claims. The costs of
workers’ compensation benefits per days away from work injury rose steadily during the
1980s and peaked in the early 1990s (Statistical Abstract (2001)). Greater attention to
workplace safety due to workers’ compensation programs may diminish the extra incentives
provided by OSHA inspections, but the impact of worker compensation should be on
injuries in general, rather than on injuries connected to OSHA standards. Since 1992, the
reduction in days away from work injuries (the only category for which we have injury type
data) occurred fairly uniformly across different injury types in manufacturing, as shown in
Table 9. To the extent that there were differences, the injury types generally believed to be
more related to standards such as “caught-in” injuries and falls from heights had less of a
decline than those believed to be less related to standards such as “bodily reaction”
(overexertion) injuries. This is consistent with a hypothesis that general financial incentives
like workers’ compensation, rather than inspections, were responsible for the injury decline.
Finally, there may have been some changes in what actually goes on during
inspections. In the 1990s, especially after mid-1995, OSHA management de-emphasized
the importance of numerical measures of inspection activities (e.g., violations cited). It
placed more emphasis on problem solving and being more creative in encouraging firms to
reduce workplace hazards. This has led overall to fewer inspections taking more hours of
inspector time. These changes might have been expected to make individual inspections
more effective, but we find a declining impact of inspections instead.

18

After examining a variety of reasons for the decline in impact of OSHA inspections
on injuries, we have only found partial explanations. Some possibilities, such as changes in
data composition, OSHA’s records-check policy, and general deterrence, explain very little
or even go the other way. The growth in restricted work activity injuries can explain onethird of the decline in an accounting sense, but this doesn’t explain why these injuries are
less affected. The increases in workers’ compensation costs in the 1980s may have led
employers to pay more attention to safety hazards, reducing the incremental incentives to
improve safety provided by OSHA inspections. We plan to explore these issues further with
more detailed analyses of the 1992-98 data, where we can test OSHA’s impact on specific
types of injuries.

19

References
Bartel, Ann P. and Lacy Glenn Thomas, “Direct and Indirect Effects of OSHA Regulation:
A New Look at OSHA's Impact”. Journal of Law and Economics. 1985;28:1-25.
Bureau of Labor Statistics, Nonfatal Injuries and Illnesses . Available at http://
ww.bls.gov/iif/oshwc/osh/os/osnr0011.
Chamberlain, Gary, “Multivariate Regressions Models for Panel Data.” Journal of
Econometrics. 1982;18:5-46.
_____________, “Panel Data.” In: Griliches Z, Intrilligator M, eds. Handbook of
Econometrics. Amsterdam: North-Holland; 1984:1247-1318.
Fellagi, Ivan P. and Alan B. Sunter, “A Theory of Record Linkage.” Journal of the
American Statistical Association. 1969;64:1183-1210.
Gray, Wayne B., “Construction and Analysis of BLS-OSHA Matched Data Set: Final
Report.” Prepared under contract to the Bureau of Labor Statistics, June 22, 1996.
Gray, Wayne B. and Carol A. Jones, “Are OSHA Health Inspections Effective? A
Longitudinal Study in the Manufacturing Sector.” Journal of Human Resources
1991;36:623-653.
Gray, Wayne B and John T. Scholz, “Analyzing the Equity and Efficiency of OSHA
Enforcement.” Law and Policy 1991;13185-214.
_____________, “Does Regulatory Enforcement Work?: A Longitudinal Study
of OSHA Enforcement.” Law and Society Review 1993;27:177-213.
McCaffrey, David P., “An Assessment of OSHA's Recent Effects on Injury Rates.”
Journal of Human Resources. 1983;18:131-146.
Mendeloff, John M., Regulating Safety: The Politics and Economics of Occupational
Safety and Health Policy. Cambridge, Ma: MIT Press; 1979.
NBER-CES Manufacturing Industry Database, available at the NBER web site:
http://www.nber.org/nberces/nbprod96.htm.
Occupational Safety and Health Administration website: http://www/osha.gov.
Robinson, James C., The Rising Long-Term Trend in Occupational Injury Rates. Am J Pub
Hlth. 1988;78:276-281.

20

References (cont.)

Ruser, John W. and Robert S. Smith, “The Effect of OSHA Records-Check Inspections on
Reported Occupational Injuries in Manufacturing.” Journal of Risk and Uncertainty.
1988;1:415-435.
____________ “Re-estimating OSHA's Effects: Have the Data Changed? Journal of
Human Resources.” 1991;26:212-235.
Scholz, John T. and Wayne B. Gray, “OSHA Enforcement and Workplace Injuries: A
Behavioral Approach to Risk Assessment.” Journal of Risk and Uncertainty. 1990;3:283305.
____________, “Can Government Facilitate Cooperation? An Informational Model of
OSHA Enforcement,” American Journal of Political Science, 1997.
Siskind, Fred B., “Twenty Years of OSHA Federal Enforcement Data.” U.S. Department
of Labor, Office of the Assistant Secretary for Policy. January 1993.
Smith, Robert S., “The Impact of OSHA Inspections on Manufacturing Injury Rates.”
Journal of Human Resources. 1979;14:145-170.
U.S. Bureau of Labor Statistics, Employment and Earnings, monthly.
U.S. Census Bureau, Statistical Abstract of the United States, 2000. Washington DC:
Government Printing Office, 2001.
Viscusi, W. Kip, “The Impact of Occupational Safety and Health Regulation.” Bell Journal
of Economics. 1979;10:117-140.
Viscusi, W. Kip, “The Impact of Occupational Safety and Health Regulation, 1973-1983.”
Rand Journal of Economics. 1986;17:567-580.
Weil, David, “Assessing OSHA Performance: New Evidence from the Construction
Industry.” Journal of Policy Analysis and Management. 2001;20:651-674.

21

Table 1
Database Description
1979-1985
Number of Observations
Number of Plants
Plants in BLS Dataset for all years
Required Continuous Years of BLS Data

27,368
6,842
6,842
7 years

1987-1991 1992-1998
32,765
14,386
3,118
2 years

25,603
8,161
860
3 years

Variable Means by Period
1979-1985

1987-1991 1992-1998

Continuous Variables
DINJ
log change in injuries
DHOUR
log change in hours
DNUM
log change in employment
DDAW
log change in DAW injuries
DRWA
log change in RWA injuries

-0.046
-0.024
-0.046
-0.075
0.036

-0.029
-0.032
-0.029
-0.029
0.059

-0.043
-0.011
-0.043
-0.082
0.040

Employment Size
SMALL
employment <100
MEDIUM employment 100-249
BIG
employment 250-499
VERY BIG employment 500+

0.196
0.332
0.239
0.232

0.325
0.300
0.181
0.194

0.221
0.222
0.240
0.316

OSHA Inspection Dummy Variables (years t through t-3)
INSP
any inspection in year
0.244
IPEN
any penalty inspection
0.080
IPRG
programmed inspection
0.193
ICMP
complaint inspection
0.061
IPRGP
programmed with penalty
0.063
ICMPP
complaint with penalty
0.018

0.119
0.082
0.045
0.073
0.035
0.046

0.082
0.052
0.026
0.069
0.034
0.035

OSHA Combined Inspections – (Value of Any of the 4 lagged dummy variables equal 1)
INSPX
INSP-INSPL3
0.625
0.383
0.258
IPENX
IPEN-IPENL3
0.283
0.245
0.194
IPRGX
IPRG-IPRGL3
0.522
0.228
0.112
ICMPX
ICMP-ICMPL3
0.229
0.207
0.171
IPRGPX
IPRGP-IPRGPL3
0.221
0.141
0.093
ICMPPX
ICMPP-ICMPPL3
0.086
0.124
0.113

22

Table 2
Impact of OSHA Inspections on Injuries
(current and last 3 years)
PERIOD

1979-85 1987-91 1992-98

1979-85 1987-91 1992-98

INTERCEP

-0.097
(-6.91)

0.088
(6.63)

-0.044
(-2.92)

-0.094
(-6.53)

0.087
(6.46)

-0.045
(-2.97)

IPEN

-0.058
(-4.09)

0.004
(0.33)

-0.002
(-0.13)

IPENL1

-0.046
(-3.22)

-0.036
(-2.76)

0.010
(0.58)

IPENL2

-0.048
(-3.46)

-0.016
(-1.18)

-0.016
(-0.97)

IPENL3

-0.005
(-0.42)

-0.046
(-3.37)

-0.006
(-0.38)

INSP

-0.019
(-2.13)

0.014
(1.28)

0.01
(0.67)

INSPL1

-0.025
(-2.76)

-0.023
(-2.19)

0.006
(0.43)

INSPL2

-0.024
(-2.63)

0.003
(0.28)

-0.012
(-0.84)

INSPL3

(-0.005) (-0.025) (-0.008)
-0.52
-2.61
-0.55

DEMP

0.451
(16.36)

0.391
(18.82)

0.447
(20.25)

0.452
(16.39)

0.391 0.447
(18.81) (20.25)

DHOUR

0.362
(16.43)

0.291
(16.48)

0.172
(9.52)

0.38
(16.37)

0.291 0.172
(16.48) (9.52)

R2

0.116

0.116

0.088

0.115

0.116

0.088

Note: “t” statistics in parentheses; regressions include year and SIC2 dummies.

23

Table 3
Impact of OSHA Inspections on Injuries
(any in current or last 3 years)
PERIOD

1979-85 1987-91 1992-98

INTERCEP -0.096
(-6.86)

0.089
(6.68)

-0.045
(-2.95)

IPENX

-0.030
(-3.63)

-0.003
(-0.27)

-0.048
(-5.47)

1979-85 1987-91 1992-98

INSPX

-0.096
(-6.49)

0.087
(6.38)

-0.047
(-3.07)

-0.026
(-3.15)

-0.013
(-1.72)

0.003
(0.37)

DEMP

0.451
(16.36)

0.392
(18.85)

0.447
(20.26)

0.452 0.392 0.447
(16.39) (18.84) (20.26)

DHOUR

0.381
(16.41)

0.291
(16.47)

0.172
(9.52)

0.381 0.291 0.172
(16.38) (16.47) (9.52)

R2

0.116

0.116

0.088

0.115

0.115

0.088

Note: ‘t’ statistics in parentheses; regressions include year and SIC2 dummies.

24

Table 4
Impact of OSHA Inspections by Inspection Type
PERIOD

1979-85 1987-91 1992-98

INTERCEP -0.096
(-6.88)

0.089
(6.71)

-0.044
(-2.90)

IPRGPX

-0.043
(-4.55)

-0.035
(-3.38)

-0.005
(-0.36)

ICMPPX

-0.043
(-3.15)

-0.019
(-1.73)

-0.005
(-0.43)

1979-85 1987-91 1992-98
-0.096
(-6.56)

0.087
(6.38)

-0.046
(-3.01)

IPRGX

-0.016
(-2.00)

-0.010
(-1.18)

0.004
(0.28)

ICMPX

-0.033
(-3.55)

-0.012
(-1.36)

-0.001
(0.10)

DEMP

0.451
(16.36)

0.392
(18.86)

0.447
(20.26)

0.451 0.392 0.447
(16.35) (18.84) (20.26)

DHOUR

0.381
(16.40)

0.291
(16.47)

0.172
(9.53)

0.381 0.291 0.172
(16.38) (16.47) (9.52)

R2

0.116

0.116

0.088

0.115

0.115

0.088

Note: ‘t’ statistics in parentheses; regressions include year and SIC2 dummies.

25

Table 5
Impact of OSHA Inspections by Employment Size
SMALL
<100

MEDIUM
100-249

BIG
250-499

VERY BIG
500+

INTERCEPT

-0.045
(-1.77)

-0.117
(-5.88)

-0.105
(-5.19)

-0.117
(-6.19)

IPENX 1979-85

-0.063
(-2.78)

-0.037
(-2.39)

-0.058
(-3.46)

-0.034
(-2.23)

IPENX 1987-91

-0.033
(-1.87)

-0.021
(-1.36)

-0.057
(-3.16)

-0.020
(-1.30)

IPENX 1992-98

0.006
(0.22)

-0.029
(-1.24)

0.003
(0.16)

0.010
(0.71)

DEMP

0.361
(14.21)

0.469
(17.35)

0.466
(15.30)

0.449
(18.18)

DHOUR

0.174
(8.64)

0.319
(14.08)

0.324
(12.59)

0.348
(15.94)

R2

.067

.111

.120

.150

N

21,261

24,424

18,570

20,738

Note: ‘t’ statistics in parentheses; regressions include year and SIC2 dummies.
Regressions for all 3 periods, separately by employment size category.

26

Table 6
Impact of OSHA Inspections by Industry
PERIOD

1979-85 1987-91 1992-98

SIC20PENX

-0.050
(-2.18)
-0.073
(-1.52)
-0.080
(-1.10)
-0.012
(-0.41)
-0.058
(-1.44)
0.026
(0.77)
-0.099
(-1.78)
-0.014
(-0.38)
-0.073
(-1.06)
-0.058
(-1.34)
-0.097
(-1.68)
-0.094
(-2.92)
-0.105
(-3.98)
-0.030
(-1.44)
-0.071
(-3.05)
-0.064
(-1.88)
0.022
(0.63)
0.023
(0.29)
-0.012
(-0.28)

SIC22PENX
SIC23PENX
SIC24PENX
SIC25PENX
SIC26PENX
SIC27PENX
SIC28PENX
SIC29PENX
SIC30PENX
SIC31PENX
SIC32PENX
SIC33PENX
SIC34PENX
SIC35PENX
SIC36PENX
SIC37PENX
SIC38PENX
SIC39PENX

0.025
(1.09)
-0.006
(-0.13)
-0.078
(-1.35)
-0.101
(-3.88)
-0.016
(-0.41)
-0.007
(-0.18)
-0.045
(-0.93)
0.008
(0.16)
-0.033
(-0.41)
-0.061
(-1.83)
-0.079
(-1.20)
0.004
(0.14)
-0.031
(-1.20)
-0.041
(-2.10)
-0.040
(-1.64)
-0.066
(-1.91)
-0.038
(-1.21)
0.073
(1.04)
0.005
(0.91)

-0.021
(-0.80)
0.026
(0.38)
-0.050
(-0.93)
-0.008
(-0.21)
0.027
(0.56)
0.019
(0.44)
-0.084
(-1.69)
-0.047
(-0.89)
-0.104
(-1.01)
0.010
(0.26)
-0.059
(-0.78)
0.059
(1.22)
-0.015
(-0.45)
-0.002
(-0.05)
-0.003
(-0.09)
0.044
(1.15)
0.044
(1.23)
0.026
(0.45)
-0.037
(-0.80)

Note: ‘t’ statistics in parentheses; coefficients from one regression combining all 3 periods.
SIC 21 contains few establishments, so it’s combined with SIC 20.

27

Table 7
Correlations of Industry-Specific Inspection Effects with Other Variables
Industry
Investment
Rate

Industry
Industry
Lost Workday Inspection
Injury Rate
Rate

Inspection Impact
by Industry
(all establishments)

.22
(.11)

.05
(.71)

-.05
(.73)

Inspection Impact
by Industry
(employment<250)

-.05
(.71)

.02
(.89)

-.21
(.12)

Notes:
‘p’ values in parentheses.
Inspection impact by industry measured by coefficients in Table 6
(and similar estimates for the subsample of establishments with employment<250).
The sample included 19 industries in 3 time periods (N=57).

28

Table 8
Impact of OSHA Inspections on Injury Types:
Days Away from Work (DAW) vs. Restricted Work Activity (RWA)
DAW Rate

RWA Rate

INTERCEPT

-0.120
(-11.08)

0.069
(6.35)

IPENX 1979-85

-0.050
(-5.62)

-0.003
(0.29)

IPENX 1987-91

-0.038
(-4.50)

0.017
(2.01)

IPENX 1992-98

-0.014
(-1.33)

0.004
(0.35)

DEMP

0.413
(29.98)

0.161
(11.60)

DHOUR

0.233
(20.28)

0.107
(9.26)

R2

.086

.016

N

84,993

84,993

Notes: ‘t’ statistics in parentheses; regressions include year and SIC2 dummies.
Regression includes all 3 periods of data.

29

Table 9
Declines in Specific Injury Types, 1992-98
Total

A

B

C

All
Injuries

Bodily
Reaction

Falls
Same-level

Struck
Against

1992

352.1

163.8

25.4

27.3

216.5

1998

204.9

92.8

17.0

15.5

125.3

43%

33%

43%

42%

D

E

F

G

H

Caught
In

Falls
Struck
Lower-level By

Eye
abrasions

Harmful
exposures

1992

27.5

11.6

47.0

8.8

18.1

113.0

1998

18.6

6.9

29.5

4.6

10.0

69.6

41%

37%

48%

45%

38%

Decrease
(%)
42%

Decrease
(%)
32%

Sum
A+B+C

Sum
D+E+F+G+H

Note:
Event types A, B, and C were identified by OSHA staff as those less likely to have injuries
related to OSHA standards. The case is strongest for category A.
Event types D, E, F, G, and H were identified as types more likely to have injuries related to
OSHA standards. The case is strongest for categories D and G.
Combined, these 8 categories included 95% of all days away from work injuries in 1998.

30

Figure 1
Changes in the Manufacturing Lost Workday Injury Rate per 100 Full-time
Workers and Its Components

10
8

Lost Workday Case
Rate
Days Away from Work
Case Rate

6

Restricted Work Activity
Case Rate

4

Unemployment Rate

2

Year

31

98
19

96
19

94
19

92
19

90
19

88
19

86
19

84
19

82
19

80
19

78
19

76
19

74
19

72

0

19

Injury Rate/Unemployment Rate

12

