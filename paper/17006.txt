NBER WORKING PAPER SERIES

DURABLE FINANCIAL REGULATION:
MONITORING FINANCIAL INSTRUMENTS AS A COUNTERPART TO REGULATING FINANCIAL INSTITUTIONS
Leonard Nakamura
Working Paper 17006
http://www.nber.org/papers/w17006

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2011

The views expressed here are those of the author and do not necessarily reflect those of the National
Bureau of Economic Research, the Federal Reserve Bank of Philadelphia or the Federal Reserve System.
I would like to thank Viral Acharya, John Bell, Mitchell Berlin, Robert Bliss, John Bottega, Paul Calem,
Satyajit Chatterjee, Larry Cordell, Ronel Elul, Jose Fillat, Jeff Fuehrer, Josh Gallin, Itay Goldstein,
Chris Henderson, Bob Hunt, Tor Jacobson, George Kauffman, Arthur Kennickell, Bill Lang, Jamie
McAndrews, Susan McIntosh, Greg Nini, Kasper Roszbach, Tom Stark, Todd Vermilyea, Larry Wall,
Christian Wang, and participants in seminars at the Sveriges Riksbank and at the Federal Reserve
Banks of Boston, New York, and Philadelphia, the Federal Reserve System Conference on Real-Time
Policy Issues and the System Committee on Financial Structure on Regulation for many helpful comments.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2011 by Leonard Nakamura. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

Durable Financial Regulation: Monitoring Financial Instruments as a Counterpart to Regulating
Financial Institutions
Leonard Nakamura
NBER Working Paper No. 17006
May 2011
JEL No. G28
ABSTRACT
This paper sets forth a discussion framework for the information requirements of systemic financial
regulation. It specifically describes a potentially large macro-micro database for the U.S. based on
an extended version of the Flow of Funds. I argue that such a database would have been of material
value to U.S. regulators in ameliorating the recent financial crisis and could be of aid in understanding
the potential vulnerabilities of an innovative financial system in the future. I also suggest that making
these data available to the academic research community, under strict confidentiality restrictions, would
enhance the detection and measurement of systemic risk.

Leonard Nakamura
Economic Research
Federal Reserve Bank of Philadelphia
10 Independence Mall
Philadelphia PA 19106-1574
USA
leonard.nakamura@phil.frb.org

2
Durable Financial Regulation: Monitoring Financial Instruments as a
Counterpart to Regulating Financial Institutions

I. Introduction: A Financial Regulatory Database for Durable Financial Regulation
In the wake of the recent financial crisis, an effort is underway to redesign the regulation
of financial institutions. As part of the new regulatory structure, a new information framework
may be desirable. In particular, I here describe a system for monitoring financial instruments as
a complement to the regulation of financial institutions. If a system of financial regulation is to
be durable, it must evolve with the development of new institutions and instruments. A main
purpose of this paper is to begin a dialogue on an intellectual framework for the analysis of
systemic risk data collection. In particular, I discuss how to construct a macro-micro database
that links our knowledge of sectoral financial assets, liabilities, and flows to underlying microdatabases with data on individual instruments and the holdings and liabilities of individual
economic actors (households, firms, states). This database represents one way to implement the
Squam Lake proposal for a new information infrastructure for financial markets (French, et al,
2010, chapter 3.)
What is meant by such a macro-micro financial instrument database? The macro side of
the database would have summary aggregate data on the nominal quantities of financial
instruments and both the debtors and the current asset holders, by broad sector. I argue that this
macro side is best understood as an extension of the Flow of Funds database already collected by
the U.S. Federal Reserve. The micro side of the database would have micro-data samples of
individual instruments and economic actors. The two sides of the database could then be
interconnected so that the micro-data can be interpreted as a (possibly weighted) sample of
portions of the aggregates. The proposed macro-micro database would make it possible to detect,
understand, and mitigate potential systemic risks.
In the 2007-2009 financial crisis, financial regulators were surprised both by the size of
the potential losses and by the types of institutions that were affected. Regulators moved to
protect investment banks, insurance companies, mutual funds, and government-sponsored
enterprises, as well as traditional depository institutions. More detailed knowledge of the risks of
financial instruments and the holders of these risks might have permitted regulators to move
more aggressively in advance of the crisis and would have made regulators better informed once
the crisis was at hand. I examine some of the risks that arose in the recent crisis and how we
could have known more about them as they were arising.
The database I describe is intended to be of substantial use to supervisors in identifying
risk at regulated institutions. It would also be used to help them know when financial risks are
being held by unregulated financial institutions, generating new systemic risks. U.S. and

3
European regulators are already taking steps to improve data availability. Eichner et al. (2010)
argue that while macro-data may be useful for discerning trends in financial risks, it is desirable
to have more specialized information to further illuminate them. My framework would take a
step toward facilitating this side-by-side use of macro- and more specialized data.
An important consideration in any such database is that it create a cost-effective means of
collecting and organizing the micro-data, that is, the individual financial instruments, so that the
evolution of the underlying risks can be followed. For this reason, we consider how to best use
and improve existing databases, as well as how to develop new ones. Just as the Flow of Funds
permits us to observe how much the sectors own and owe by a broad class of instruments, we
also need links across the micro databases that help us observe the distribution of individuals,
firms, and agencies that own and owe, by individual instruments.
In this paper I set forth a framework in which a U.S. financial data office could be the
central datakeeper for information on U.S.-originated financial instruments and could be active
in making the data available to academic researchers as well as economists from regulatory
agencies. Such an office has been provided for in the Dodd-Frank Act as the Office of Financial
Research (OFR). The OFR would actively share data (within the limits of confidentiality) and
research results on the risks of specific financial instruments with financial regulators and with
risk managers within financial institutions. It would thus strengthen the ability of financial
institutions to recognize and manage their own risk, conceivably reducing the burden on
regulation.
II. How Monitoring Financial Instruments Can Aid in the Regulation of Financial Institutions
The task I am describing has two central pieces: One is finding out who holds these
instruments and the other is measuring the risks of the instruments and of the holders. Before
addressing precisely how these objectives will be achieved, let us use examples from the 20072009 financial crisis to consider further how this informational database will aid the systemic
regulator and all financial regulators.
In this part, we make several points. (1) The database could aid in detecting buildups of
systemic risk outside the regulated financial system. (2) It could reduce the opacity of
institutional portfolios. (3) It could support studies of the changing risks of instruments, in
particular, by permitting investigation of the actions of agents along the full life cycle of
instrument creation, distribution, and servicing. (4) It could support pricing analysis that would
bring financial, economic, and econometric theory to bear in the determination of potential
systemic risk. (5) It could engage a broader, more creative, and potentially more objective
community in systemic risk analysis. (6) It could enable regulators to observe counterparty risk
and to undertake regular systemic stress testing. (7) It could be used to improve estimation of
long-term relationships across variables that may be useful in identifying potential asset bubbles.

4
(1) Following the risk off balance sheet. U.S. financial institutions are regulated
piecemeal. This system avoids excessive concentration of regulatory power and provides
avenues of regulatory competition: Regulators who regulate efficiently can be rewarded.
However, the system has weaknesses. One is that regulated financial entities may shop for weak
regulators and, by finding the most complacent regulator, may weaken the system as a whole.
Another is that financial activities and instruments may be created or moved outside the purview
of regulation.
When a financial asset such as a mortgage is created, it can be created within a tightly
regulated financial entity, such as a commercial bank, or a loosely regulated one, such as a
mortgage subsidiary or a freestanding mortgage company. The regulatory treatment of the
mortgage may depend on the form in which it is held. For example, the AAA tranche of a
collateralized debt obligation may have much lower regulatory capital requirements than a
mortgage loan held in portfolio. Depending on the relevant costs and benefits of the regulatory
treatments and the risks of the assets, the form in which the asset is held may change, and this
form may have little to do with underlying economic efficiency.
A mortgage asset can be moved off the originator’s balance sheet by placing it in a
separate legal entity, such as a special investment vehicle or an entity that issues asset-backed
commercial paper. This vehicle may reproduce the characteristics of a financial intermediary, by
issuing short-term liabilities that are money-like while it holds long-term instruments that are
subject to some risk. These entities generally have standby lines of credit issued by the financial
intermediary. If the entity’s asset risk increases, the holders of its short-term liabilities may
refuse to roll over the debt, creating a run on the entity and a drawdown on the standby line of
credit. Thus, the risks from the vehicle can be easily transferred to the financial intermediary,
while the capital of the financial intermediary may be inadequate, since these assets and
liabilities were not on its books. The risks and consequences of asset-backed commercial paper
are documented in Covitz et al. (2010).
This and other examples of the creation of a “shadow banking” system point out the
value to financial regulators of continuing to monitor financial assets after they are removed
from the balance sheets of closely regulated financial intermediaries. Note that such a system
would permit innovation – it would not block new institutions or new instruments from arising.
Rather, it would seek to monitor these novelties and perhaps bring them under regulation if they
reach systemic importance.
As the case of AIG illustrates, the migration of systemic risk to a lightly regulated or
unregulated entity contains the seeds of systemic financial crisis. To contain the 2007-09
financial crisis, the regulatory process would have had to identify that AIG was a systemic risk,
ascertain the quantitative scale of those risks, and bring AIG under greater regulatory discipline,
including preparing a means for unwinding AIG with minimal systemic risk.

5
(2) Another issue is opacity. An important aspect of the recent financial crisis was that
many financial institutions themselves lost track of the total real estate exposure of their
portfolios. This reflected, in part, the fact that regulation created incentives for opacity. An
institution may change an instrument from a loan to one or more securities that it continues to
hold, to reduce capital requirements, although no risk has been transferred. The resulting
increase in opacity may cause an institution to lose track of its true vulnerabilities.
If financial instruments are opaque to the financial institution holding them, then they
must be even more opaque to a regulator. To the extent that instruments can be finely
categorized and characterized, and their risks more precisely measured, both regulators and
internal risk monitors at financial institutions will be better able to avoid crises. Steps to reduce
opacity are being taken to the extent that customized instruments that are not exchange traded
will have higher risk capital requirements. To the extent that instruments are exchange traded,
they will be easier to categorize and quantify, and measuring their risk will be easier.
To the extent that financial instruments and securities based on them are priced on
exchanges, then similar customized instruments and securities may be evaluated and priced
based on a model of the values of their financial characteristics. When trades or acquisitions of
such assets are observed, the quality of the mark-to-model pricing may be verified.
(3) Following the full life cycle of instrument creation, distribution, and servicing. There
are many facets to the creation and maintenance of financial instruments. The characteristics of
the financial instrument may be influenced by many institutions and agents. Actions of one set of
agents may affect instruments so as to exacerbate systemic vulnerabilities. In the losses
associated with the recent financial crisis, the actions of a panoply of agents were at work in
increasing the risk of mortgages. The severity of the risks of real estate finance might have been
recognized earlier if regulators had been more aware of changes taking place across a variety of
institutions.
The risks of mortgages were compounded because a number of the agents were subject to
uncorrected weaknesses, many of them well recognized by relevant players. For example,
persistent and significant upward bias in home appraisals was recognized as early as the mid1990s (Cho and Megbolugbe, 1996). According to this analysis, some 95 percent of home
purchase mortgages in the Fannie Mae mortgage database had appraisals at or above the sale
price. Having been recognized, this bias was tracked through automated valuation models
(AVMs) by Fannie Mae and Freddie Mac. It was well known among those actively using these
AVMs that these biases were particularly strong for refinancing and for subprime lending.
However, these biases were not widely known or understood outside this circle. In particular,
many regulators were not aware of the risks thereby posed to mortgage refinancing, since
upward appraisal bias resulted in understated loan-to-value ratios.

6
Upward biases are also widely believed to have applied to refinancing, which would have
the consequence of allowing homeowners to refinance with too small a cushion against the risk
of home price decline. Unfortunately, the databases of the government-sponsored enterprises
have not been available for study by academics; their information has been considered the
intellectual property of these entities. The losses at these entities – which perhaps might have
been mitigated if scholars and regulators had had better access to these databases – have far
exceeded the value of the intellectual property of these entities. Moreover, it is by no means
obvious that these entities should have exclusive rights to the data generated by government
sponsorship.
Micro-data have been used to analyze the behavior of subprime mortgage lending
standards (Demyanyk and Van Hemert, forthcoming), the behavior of securitizers (Elul, 2009).
and the behavior of mortgage brokers (Garmaise, 2008, and Keys et al., 2009).
Demyanyk and Van Hemert (forthcoming) found that subprime mortgage lending
standards – as measured ex post by delinquencies and foreclosures – deteriorated monotonically
from 2001 to 2006. The decline in lending standards is revealed in differential performance rates
detectable within a year of origination. However, aggregate default rates were somewhat
masked by the rise of housing prices from 2003 to 2005.
Elul (2009) finds that prime mortgage loans that were securitized were of lower quality
than loans that were held in portfolio. He does not find a similar effect for subprime loans, but
the vast majority of subprime loans were intended for securitization.
Garmaise (2008) presents evidence that mortgage brokers’ lending standards deteriorated
over time so that experienced mortgage brokers’ loans performed worse. Keys et al. (2009)
show that states with stricter regulation of mortgage brokers had better performing subprime
loans.
We use these examples to illustrate the types of data that could have permitted regulators
to detect changes in the risks of mortgages. That in turn, we are arguing, could have resulted in
an earlier and more measured response to the impending crisis.
Financial regulators and academic financial researchers are now assembling micro-data
sets for forensic reasons, to attempt to understand the causes, consequences, and the scale of the
financial crisis. However, it is widely recognized that the data collected to date have serious
weaknesses. In particular, commercial databases often have crucial identifiers missing or
encoded so that associating observations across data sets has been difficult or impossible. In
addition, financial institutions, servicers, and other parties whom the systemic regulator needs to
be able to identify are often contractually anonymous within these databases. Permitting the
database to obtain these identifiers may require regulatory action or possibly legislation.

7
In addition, certain agency problems appear to have worsened significantly as time
passed. The rise of mortgages with very high combined (reported) loan-to-value ratios (100 or
higher) was another warning sign of difficulties. These data were partially available in, for
example, LoanPerformance micro-data sets on second mortgages based on information gathered
from mortgage servicers. But it was often difficult for the holders of first mortgage portfolios to
know the extent to which second liens had made their mortgage assets riskier.
(4) Systemic risk pricing in the market. Economic theory suggests that financial payoffs
that will occur in periods when the marginal utility of consumption is high have a greater present
value than payoffs in periods when the marginal utility of consumption is low. Systemic risks
offer low payoffs in bad economic states, when the marginal utility of consumption is high.
Instruments with embedded systemic risks thus have lower value and require compensatingly
higher rates of return in equilibrium.
Coval et al. (2009a,b) have pointed out that structured finance created strong incentives
to concentrate systemic risks in financial instruments that otherwise were of very low risk.
These financial instruments had inherently high expected returns because of the risks involved.
As long as the systemic risks did not emerge, such instruments had a high rate of return and
appeared to be earning excess returns. Coval et al. (2009b) then go on to develop a pricing
kernel for structured finance instruments that have little idiosyncratic risk but high systemic risk
and argue that, in fact, such economic catastrophe bonds that were issued in the period just
before the financial crisis were overpriced. In this case, bonds appeared to be paying a high rate
of return and thus represented a financial arbitrage opportunity with positive excess return, but in
fact, they had a negative excess return and were fundamentally loss-making to the holders.
This pair of papers shows how data on financial instruments can reveal the existence of
systemic risk and may be of help to regulators in requiring the holders of such assets to hold
higher capital, offsetting the apparent reward to holding these assets. To the extent that the
systemic regulator is held responsible for minimizing the likelihood of a systemic crisis, a
paradox arises. As the likelihood of systemic risk declines, the price of holding the systemic risk
will fall. This in turn encourages the creation of more instruments of this type, until a systemic
crisis does occur. The consequence may be that the crisis, when it occurs, may be surprisingly
large. Maintaining a watch over this potential dynamic will be an important task of the systemic
regulator.
(5) Engaging a broader and more objective community in monitoring. To the extent
consistent with privacy considerations, permitting academics and investment advisors to access
and analyze the financial database would enhance the capacity to identify cyclic and systemic
risks within the U.S. financial structure.
This broader community can bring new insights from financial research to bear on these
issues and also offer a counterweight to the authority of the private financial institutions. One of

8
the difficulties regulators have faced in the recent period is that employees at private financial
institutions have been compensated on a scale with which public authorities cannot hope to
compete. While higher compensation may not strictly imply higher marginal product, the
possibility that it does so may cause less-well-paid regulators to sometimes defer to the judgment
of extremely well-paid regulatees. (Indeed, part of the Basel II structure was constructed on the
assumption that complex financial institutions were better positioned to measure their own risks
compared with outside regulators.)
Moreover, internal risk managers are often in a similarly weak position, as risk
management is a cost center, while the departments creating the risks are profit centers that can
richly reward their employees. The regulatory database can provide empirical models of risk
that enable bank supervisors and internal risk managers to more aggressively challenge the views
of risk takers.
By opening up the measurement of risk in the financial database to a wider group,
regulatory risk measurement can be done at the frontier of financial science. Indeed, the
systemic regulator could have built into its structure a research steering group composed of
leading academic experts, as well as funding for grants and conferences to identify the structure
of risks underlying the database. In addition, if the systemic regulator should hire a full-time
staff of research economists to undertake financial risk studies, this might well help in
identifying data shortcomings, as these researchers would gain privileged, hands-on views of the
data. If that knowledge can be freely shared with regulators, the regulators could ask the
financial institutions originating the data to improve their data management processes as needed.
One potentially important first research task of the systemic regulator could be a full
quantitative accounting of the sources of the financial crisis. One possibility would be to set up a
contest for the best paper providing such a full quantitative accounting, to be judged by a
prestigious academic panel with the reward being a substantial sum (say, $1 million). The
academic panel could also be charged with assessing the weaknesses of the best paper, and
additional, smaller awards would be given to subsequent papers that eliminated these
shortcomings.
(6) Counterparty risk and systemic stress testing. Simulating the impact of systemic risks
on the financial system would be greatly facilitated by a clear view of which financial
institutions are holding which financial instruments.
In a financial crisis, the identification of counterparty exposure comes to the fore.
However, in the current complex financial environment, counterparty exposure has become far
from transparent. Large complex financial institutions have hundreds, even thousands, of
subsidiary institutions. Thus, in the recent crisis, financial institutions considering the possibility
of a default by some threatened bankruptcy were unable to accurately estimate the size of their

9
exposures. This is a problem that large financial institutions are now very aware of, and steps
are being taken to link subsidiaries to their parents through institutional identifiers.
More broadly, while tools for mapping the dynamic conditional correlations across
financial instruments are being rapidly developed (for example, Engle, 2009), these mappings
are being traced out by trades made by agents who themselves typically lack detailed knowledge
of the dynamic interrelations of financial institutions. An important task of the systemic
regulator will be to understand the volatile pattern of institutional relationships, as they are
revealed in quarterly or daily snapshots of institutional cross-exposure.
(7) Addressing bubble-like risks. The identification of financial bubbles remains a
difficult art. It is often impossible to clearly identify a bubble in advance. While we can identify
key historical ratios between measures of price and measures of return, for example, and
historical mean-reverting relationships, it is very difficult to be sure that a structural change has
not occurred. However, it is relatively easy to model the possibility that a bubble has been
created and the consequences of the bubble bursting; that is, we can assume that historical
averages will be maintained and that reversion to the mean occurs over some short period of
time. We can then perform stress simulations under such scenarios using the database. These
simulations could then be brought to the relevant financial regulators and internal risk monitors,
and perhaps to Congress, if additional statutory authority appears necessary.
Such simulations are instructive stress tests in that the case of no structural change is hard
to rule out, and thus placing very low weight on this case is generally unconvincing. In addition,
outside researchers could be allowed to (or be paid to) conduct their own simulations, offering
useful alternative scenarios to regulators.
III. Expanding the Flow of Funds Framework: The Macro Side of the Database
The macro side of the database helps regulators know, for example, which types of
financial institutions are funding a given financial instrument. Because the totality of such
transactions is so vast and variegated, it is vital to have an intellectual framework for organizing
and aggregating them. I argue that the Flow of Funds is such an intellectual framework.
How can we use the Flow of Funds as a framework for the envisioned database? Most
fundamentally, the Flow of Funds provides an accounting framework that includes all the assets
and liabilities of nonfinancial and financial institutions. The Flow of Funds (a part of the system
of national accounts that is compiled by the Federal Reserve System) establishes a framework
that accounts for the financial assets and liabilities of all U.S. parties (including households,
nonprofits, firms, governments, and the rest-of-the-world). 1 The Flow of Funds has a fluid
conceptual framework that can be expanded to reflect derivative and synthetic instruments. The
U.S. Flow of Funds relates to the system of U.S. national accounts; individual agents and sectors
1

For a description of the Flow of Funds and its relationship to the national accounts, see Bond et al. (2007).

10
borrow and lend as part of the national, sectoral, and individual imbalances between savings and
investment. To the extent that financial instrument risk is tied to agents, sectors, and markets,
this framework facilitates the economic analysis of risk. Similar to the national income accounts,
the Flow of Funds framework can accommodate a series of satellite accounts to extend the value
of the framework. These, some of which are discussed below, could include mark-to-market or
mark-to-model pricing, agents behind the scenes (such as exchanges and rating agencies), and
measures of risk. Finally, the micro databases and statistics that underlie the aggregate measures
could be associated with the Flow of Funds as a linked library, in which the aggregate categories
of the Flow of Funds organize the micro-data as a set of reference headings.
The U.S. Flow of Funds has two intimately related parts. One part is a set of flows, net
new borrowing and lending, and the other is a set of outstanding stocks, assets, and liabilities.
(The quarterly net flows are defined to be the difference in the quarterly level of outstanding
stocks.2) These are presented as aggregates by sector (lenders and borrowers, such as banks,
households, governments, and corporations) and by instrument (equity, mortgages, loans,
commercial paper, consumer credit, and securities). The Flow of Funds reflects the financial
assets and liabilities and financial activities of both financial and nonfinancial entities in the U.S.
It thus provides a natural framework from which a systemic regulator could observe the types of
risks distributed across the financial system.
The first column in Table 1 shows the credit market borrowing by nonfinancial sectors in
2008, taken from the Flow of Funds, Annual Flows, as published June 11, 2009. In this table,
they are organized by instrument, such as commercial paper and home mortgages, and by sector,
such as household sector and nonfinancial corporate business. It also shows borrowings by
foreigners. The second and third columns show the debt levels owed by the nonfinancial sectors
for the same instruments and sectors at year-end 2007 and 2008. Adding column one to column
two gives column three; the net borrowing flow during 2008 added to the level of debt at the end
of 2007 gives the level of debt at the end of 2008. Other summary tables in the Flow of Funds,
not presented here, show financial sector borrowing and total liabilities and their relationship to
total financial assets. Yet others relate the Flow of Funds to national savings and investment and
the national income accounts.
Through its ties to the national income and accounts, the Flow of Funds obtains a
benchmark measure of the total borrowing and lending by a given sector necessary to balance net
cash flows. This provides an indirect estimate of the completeness of direct measures of total
borrowing and lending.
The efficiency of the borrowing and lending of the nonfinancial sector provides a prime
economic rationale for the activities of the financial sector. An important rationale for systemic
2

In practice, the Flow of Funds levels are not always consistent and contain breaks resulting from incomplete or
inconsistent underlying data. When there is a break, the quarterly flow is defined as the flow associated with a
consistently defined level and may not be equal to the reported difference between quarterly levels.

11
regulation is to ensure this two-way flow of financial transactions. It is of fundamental
importance that the financial transactions of the nonfinancial sector come under the scrutiny of
the systemic regulator. Table 1 presents a compact view of the total borrowing of the
nonfinancial sector from the Flow of Funds, year-end 2007 and 2008.
Less aggregated tables in the Flow of Funds – there are 31 sector tables and 31
instrument tables – show holdings of instruments by different sectors. In short, the Flow of
Funds relates instruments to the assets and liabilities of institutions. The assets and liabilities of
each individual agent are naturally organized within this Flow of Funds framework. Moreover,
the databases in which samples or the universe of agent outstandings or flows are captured
naturally map into this framework as well. For example, if an agency is using samples of a credit
bureau’s data on individuals and households, this database can be mapped into and benchmarked
with the household balance sheet from the Flow of Funds.
What the Existing U.S. Flow of Funds Lacks: Creating an Expanded Framework with Satellite
Accounts
In many cases, the existing U.S. Flow of Funds lacks crucial detail that would have been
helpful to know during the financial crisis. For example, an important question was: Which
sectors were holding the nonagency jumbo and subprime securitized mortgages? The table on
residential mortgages does have an entry that shows the total quantity of home mortgages that
were the assets of ABS issuers – nonagency pools of $2.2 trillion in 2007 (Table L.218).
However, the table on Issuers of Asset-Backed Securities (L.125) has their assets as $4.5 trillion
(including credit cards, commercial mortgages, and agency and GSE-backed securities) and
liabilities divided into commercial paper ($0.6 trillion) and corporate bonds ($3.9 trillion).
Corporate bonds are also in Table L.212, Corporate and Foreign Bonds, which shows the holders
of $11.4 trillion of bonds, of which $2.2 trillion are nonagency ABS. There, we can find the
various sectors that hold corporate and foreign bonds, but we don’t know which sectors are
holding nonagency ABS. One significant exception is for U.S.-chartered commercial banks,
which divides corporate and foreign bonds into (1) private mortgage pass-through securities, (2)
CMOs and other structured MBS, and (3) other. In any event, it appears that banks and thrifts
were holding about one-quarter of the nonagency ABS, while they held only 10 percent of other
corporate and foreign bonds.
Satellite Accounts. National income accounts can be expanded in ways that may not
easily be accommodated into the complete framework. For example, if quarterly data are not
available for a set of statistics, or if, say, prices are not available, then a satellite account can be
created. Similarly, it would be useful for an expanded macro-micro financial database to have a
number of satellite accounts.
Net financial flows could be further decomposed into the sum of gross new originations,
repayments, defaults, and revaluations, but these sub-elements are not shown separately within

12
the Flow of Funds. From a regulatory perspective, it would be preferable to track these
subcomponents, particularly for longer-term debt. Doing so would facilitate tracking
instruments by vintage and would also contribute to data quality.
Gross flows may be tracked by and matched with micro-data sets on loan originations,
including regulatory data sets such as HMDA data, financial industry data such as Fannie Mae
and Freddie Mac data sets on agency securitizations or daily data on market transactions, and
data collected by statistical agencies. The aggregate stocks, the U.S. Flow of Funds assets and
liabilities, could be matched with micro-data on households (credit bureau, statistical agencies,
regulatory data) and firms (Compustat, call reports, statistical agencies, SEC filings, Survey of
Terms of Bank Lending).
The matching of the aggregate statistics with historical and current micro-data would
permit regulators to examine the default risks associated with financial instruments as they
evolve. Having measured variances and covariances of financial instruments, the systemic
regulator can use the augmented Flow of Funds to identify the sectors in which the risks
associated with the financial instruments are lodged. In turn, the micro-data will aid the systemic
regulator in examining the sectors and observing the distribution of risks across financial firms.
Another important satellite account would have prices. The national accounts framework
can accommodate valuation changes, but the U.S. national income accounts, by their very nature,
capture flows of production and not capital gains. Similarly, the U.S. Flow of Funds primarily
carries assets and liabilities at nominal book value. For risk analysis, it is highly desirable to have
the mark-to-market prices for exchange-traded instruments. It would also be useful to be able to
mark-to-model instruments that are not frequently traded.
It is crucial for the systemic regulator to have a broad picture of the risks of the set of
financial instruments and their consequences for the system of financial institutions. To support
the database, one aspect of the new regulatory structure could be a requirement that financial
institutions – regardless of their direct regulator – provide information to the systemic regulator
to facilitate construction of the database. Indeed, the regulatory structure should have the
provision of such information as part of the transparency requirement of all financial regulation.
One example of missing data is the portfolios of hedge funds; these are not shown in the Flow of
Funds separately because of lack of data and are implicitly included in households.
The U.S. (and the worldwide) financial system is in constant flux due to innovations in
the world economy and to financial innovations. Undeniably, many of these financial
innovations have reduced the transactions and information costs associated with borrowing and
lending and thus have improved the efficiency of consumption and investment. However,
financial market participants, left to pursue their private interests, will not take fully into account
the knock-on effects of their actions on others. In particular, financial markets include both
sophisticated and unsophisticated borrowers and lenders and informed and uninformed

13
borrowers and lenders. The information asymmetries have their beneficial aspect — it is
valuable to have specialization. But financial agents may be tempted to use these information
asymmetries for private, inefficient gain.3 As a consequence, they need to be and are regulated,
but regulation then creates an ongoing temptation to escape regulatory burden. Profitmaximizing financial innovation can create socially desirable efficiencies, or it can be a socially
undesirable means of evading regulatory constraints.
Financial regulators are typically called upon to regulate financial institutions that are the
sites of existing financial activity. New financial instruments and institutions may evolve outside
the scope of regulation. By creating an evolving financial monitoring framework, regulatory
agencies can bring these new instruments and institutions into view and, as necessary, under the
regulatory umbrella. In particular, this monitoring system may limit the creation of unregulated
intermediaries that hold systemic risk and whose rescue might become necessary in a financial
crisis. For example, if an investment vehicle has assets that carry systemic risk (identifiable by
covariance and possibly excess return) and short-term liabilities (e.g., AA commercial paper),
then the investment vehicle prima facie is liable to runs and may transmit systemic risk to
regulated entities if those regulated entities provide back-up lines of credit and/or credit risk
insurance (Acharya and Richardson, 2009). If the new combination of instruments reduces
capital requirements, then capital requirements for the new entities may need to be increased.
Another valuable step would be to require that whenever risk is removed from a regulated
financial institution’s balance sheet, then that institution should be responsible to inform the
systemic regulator of the counterparty that has taken on the risk. Such notification could have
revealed to regulators the buildup of systemic risk at AIG’s UK offices.
One concern about setting up a financial regulatory database is the increasingly global
nature of finance. Debts originated in one country can be held on the other side of the world.
Can we keep track of enough U.S. financial assets to make a difference, beginning with U.S.
financial borrowings? Fortunately, the U.S. financial structure is unusual in that a substantial
proportion of U.S. financial liabilities are held abroad (15 percent, 2008 year-end), but only a
relatively small proportion of U.S. financial assets are owed by the rest of the world (4 percent,
2008). As seen in Table 1, of the $35.4 trillion owed by the nonfinancial sector, only $1.9
trillion is owed by foreigners. Thus, most of the nonfinancial holdings of the U.S. financial
system can be understood based on micro-data from U.S. entities. This means that as a first
approximation, beginning with financial instruments originating in the U.S. will be a reasonable
place for understanding U.S. nonfinancial risks. It would be of value, of course, if other countries
carried out similar efforts to expand this macro-micro database across the globe. Other

3

In taking advantage of these information asymmetries, the agents may not be aware that they are not acting in the
interests of the principals. As we shall see below, agents who took advantage of the apparent gains from holding
“economic catastrophe” bonds may have thought they were simply doing efficient arbitrage between mispriced
instruments.

14
countries’ financial regulatory databases can perhaps be more easily built once the U.S. financial
regulatory database is in place.
IV. Drilling Beneath the Flow of Funds to the Micro Database
We envision a micro-database that is attached to the Flow of Funds and its satellite
accounts. Ideally, clicking on a given cell in the Flow of Funds macro accounts would reveal the
underlying micro-data that are used to create the aggregate, as well as databases linked to this
primary sampling data. The Flow of Funds section of the Federal Reserve has already developed
a prototype system for showing the data source for all the cells of the Flow of Funds. As these
data sources themselves are typically based on micro-data surveys, this is a first step in the
direction we envision.
The micro-data part of the database could be built up with existing databases, including
existing academic, government, and commercial databases (e.g., CRSP, Compustat,
LoanPerformance, Equifax, call reports, HMDA, Quarterly Terms of Bank Lending, Shared
National Credit, Census, IRS, Fannie Mae and Freddie Mac); and data from existing
depositories, exchanges, and registries (e.g., Depository Trust and Clearing Corporation, Federal
Reserve Depository).
These databases collectively show that it is feasible to collect data and to aggregate them
along a variety of dimensions. For existing databases, as argued above, each could be mapped to
corresponding entries in the Flow of Funds. For example, a micro-data set of credit bureau data
on households could be viewed as a sample of the universe of households, and the entries used to
estimate the universe. The estimate of total mortgages could then be compared against the
estimate of total mortgage borrowing by households in the Flow of Funds. Doing this across
data sets will result in a more reliable aggregate estimate of household mortgage borrowing and
will allow researchers and decision-makers to see relatively transparently how representative a
given micro-data set is and, therefore, how trustworthy results from analysis of the micro-data
are likely to be.
Record linkage. A key improvement to these databases could be automated record
linkage. The econometric studies discussed in Section II rely on the ability of the
econometrician to identify instruments and agents across data sets and over time, known
generically as record linkage. There are now relatively standard computational techniques for
optimizing record linkage (Herzog et al., 2007), but these techniques have not been used in
economic and financial studies.
For example, a mortgage origination in a credit bureau’s data on a given household will
permit the identification of other mortgages held by the same household, and the possibility that
the home and its mortgage is actually a speculative investment rather than for an owner-occupied
residence. However, to follow the ongoing current loan-to-value ratio of the mortgage, a key
element in the evaluation of the credit risk of the mortgage, requires knowing the location of the

15
home and home price inflation at that location since purchase, with a link to the local home price
index. Depending on the regulator’s concerns, it may be useful to know the broker, the appraisal
value, the interest rate on the mortgage, the originator, whether the mortgage is held in portfolio
or securitized, and the servicer. Each of these may be available from a different data set or
within the same data set at a different point in time. Establishing procedures to automate these
linkages would be of value to regulators and would facilitate new and updated econometric
analyses of risks.
If individual financial instruments are given unique identifiers so that they can be linked
from data set to data set, that would clearly facilitate cross-checks in financial monitoring. A
consistent form of instrument identification would be of aid to the finance industry itself, which
would be better able to merge portfolios (as a consequence of mergers and acquisitions) while
retaining a deep understanding of their characteristics. Linking permanent identifiers to financial
instrument characteristics will facilitate bottom-up analysis of portfolios and permit complex
stress test simulations. Establishment of a set of unique identifiers has apparently been hampered
by coordination issues; in this situation, regulators can take a strong stance in favor of
implementation and benefit both regulation and private parties.
All financial instruments that represent direct claims against nonfinancial institutions —
firms, households, or other legal entities such as governments — could be registered, provided
with a unique identifier, and accompanied by summary data on its characteristics, such as its
legal form, the issuer or debtor, type of debt or equity, and so forth. These financial instruments
are the fundamental financial instruments; their provision is an important rationale for concern
about systemic risk. The summary data could be coded in a uniform system, following the
experience of database providers and depositories. The American Securitization Forum’s ASF
LINC (Loan Identification Number Code) is a mechanism that seeks to provide unique
identifiers for mortgages, credit cards, auto loans, and other retail debt. These unique identifiers
would be linked to a database that would have characteristics of the instrument. The Enterprise
Data Management Council, with the support of the financial industry and data management
firms, has taken important steps toward developing a system that codes a wide variety of
financial instruments, fundamental and otherwise.
A crucial step is to see where micro-data are not yet available; in particular, it would be
valuable to map out areas where the Flow of Funds aggregate data rely on estimates or where the
underlying data are inadequately reported. For example, repo data are reported on a net basis
rather than on a gross basis (Eichner et al., 2010).
It would be desirable to map the micro-data geographically, to the extent possible. In the
absence of unique identifiers and with data where identities of lender and borrower have been
scrubbed, much can still be learned by associating micro-data geographically. It is often possible
to identify scrubbed data through such a procedure. Even if that is not the goal or not possible,
missing data (such as income in credit bureau data) can be usefully estimated using geography

16
together with geocoded census information. To the extent that geocoded micro-data can be
obtained, this information provides a more detailed cross-check on the accuracy and quality of
data.
Measures of the quality of the data, both for aggregate estimates and for the micro-data,
could be integrated into metadata provided as a standard feature of the database. Quarterly
vintages of the data, once vetted, could be archived, to create a real-time database.
One efficient form for gathering micro-data is presented by the U.S. Survey of Terms of
Bank Lending, a quarterly survey that collects information on all loans granted by the surveyed
banks in the first week in the middle month of each quarter. The survey draws voluntary
responses on 30 to 40 thousand loans from 648 banks and, according to the Office of
Management and Budget’s Information Collection Review, requires 6,840 annual burden hours
from respondents. (A limitation of this survey is that it collects information on loans only at
origination and does not follow them over time.) Another efficient alternative may be to have a
third-party registry collect data on financial instruments as the Depository Trust and Clearing
Corporation does. Third-party vendors are also efficient providers of data; for example, servicer
data – e.g., the First American LoanPerformance mortgage and home equity loan data sets – are
another efficient way to collect data. It should also be noted that sampled loan data are routinely
used as part of bank examinations in the U.S.; the systematic compilation of loan data may
require little additional burden on banks.
An interesting pioneering step has been taken by the Sveriges Riksbank, the Swedish
central bank, in collecting micro-data on loans at Swedish banks together with gathering credit
bureau information. This data collection is discussed in Jacobson, et al., 2006. Nakamura and
Roszbach (2010) provide a methodology for comparing the quality of bank loan ratings to credit
bureau ratings using this data set.
Derivative securities, including derivatives, options, exchange-traded funds, asset-backed
securities, and the like, should be provided with unique identifiers and accompanied with
summary data on the fundamental financial instruments to which the derivative security is
linked. As mentioned before, the Enterprise Data Management Council has been taking
important steps in developing methodologies and semantics for these tasks.
Some difficult questions arise from intellectual property in databases and in unique
identifiers. Private third-party databases are efficient forms of collecting and organizing data,
which moreover have the advantage of having already been created, so that their creation is a
sunk cost, and their profitability makes it likely that the data will be collected moving forward.
However, such data have drawbacks as well. First, the databases are expensive. And regulatory
use of the data, by validating it, may make it more valuable. Second, key attributes of the data –
such as the entity providing the data – may not be available to the users of the database as a
condition of the entity’s participation. Third, the licenses to use the databases that are purchased

17
typically come with restrictions on how the data may be used and shared. If regulators are to
view these third-party vendors as providing a conduit by which a regulated entity fulfills part of
its data-reporting requirements, then it would appear natural that some of these license
restrictions should be annulled. And the databases could be required to be made available to the
regulator on a marginal cost basis.
Regulated financial institutions that hold, acquire, or sell financial instruments or
derivatives as assets could be required to ensure that the financial monitor is provided with
quarterly information on the current holder of these assets and the current status of the
instrument. Fulfilling this requirement would be facilitated by the use of depositories and
exchanges. As time passes, the data received quarterly will become a historical micro database.
V. Access to the Data
Access to the micro-data supporting the financial monitoring database would be made
available to the staff of the financial monitor and to other regulators. It might also be made
available to academic and government specialists who wish to use the data to make studies of
risk characteristics of the instruments and of the holders of the instruments. Such studies would
be made public, with public data screened for confidentiality, and would also be made available
to financial regulators.
An academic advisory board composed of leading financial and economic professors and
researchers could be established to advise the financial monitor and the regulatory community
about the advisability of extensions to data collection and of extensions of regulation to
additional institutions that are potential sources of systemic risk.
The academic advisory board could also designate studies to be conducted to measure
alternative aspects of systemic risk. This would naturally be accompanied by open access of the
database (conditional on strict confidentiality) to academic researchers who wish to investigate
questions related to systemic risk. Finally, the systemic regulator could ideally have a substantial
research department of economic and finance researchers of the highest academic quality. This
research department could devote most of its time to frontier research on finance and economics
and also conduct policy studies on systemic risk. Having access to the database will help the
research department attract top researchers.
These researchers would, as a byproduct of their research, analyze the quality of the data
being supplied by regulated financial intermediaries and other data providers. It might be useful
for the database office or the analytical group to have the authority and the responsibility to
monitor the quality of the data. The systemic regulator and other regulators could be empowered
to require that regulated financial intermediaries maintain high-quality data. This would help
ensure that regulators and internal risk managers have access to the information they need to
provide high-quality analysis.

18
VII. Summary
I have discussed how to assemble and maintain a database of financial instruments and
derivatives with both macro and micro components. Such a database would have been of
material aid to regulators and to financial institutions in measuring the accumulating risks that
led up to the financial crisis of 2007-2009, and it would be designed to be of aid in enabling
regulators to anticipate and mitigate future financial crises.
The U.S. Office of Financial Research will have the authority to obtain data from
financial institutions. An important element of this would be requiring that individual financial
instruments and institutions have unique identifiers linked to machine-readable contract
characteristics. The office could be responsible for establishing quality standards for the data
obtained and would advise financial institution supervisors when institutions were failing to live
up to those standards. It would be desirable from the standpoint of monitoring systemic risk to
establish readily usable links across these data sets, a process that would be facilitated by efforts
currently underway to standardize identifiers for instruments and entities, and to provide
machine-readable contractual terms. It would be useful in the long run to establish data links and
methods to create accessible archival data that could be accessed from multiple secure data
centers.

19
References:
Acharya, Viral V. and Matthew Richardson, editors, Restoring Financial Stability: How to
Repair a Failed System, New York: NYU Stern School of Business, 2009.
Bond, Charlotte Ann, Teran Martin, Susan Hume McIntosh, and Charles Ian Mead, 2007,
“Integrated Macroeconomic Accounts for the United States,” Survey of Current Business,
February, 14-31.
Cho, Man, and Isaac F. Megbolugbe. “An Empirical Analysis of Property Appraisal and
Mortgage Redlining,” Journal of Real Estate Finance and Economics, 13 (1996), 45-55.
Coval, Joshua, Jakub Jurek, and Erik Stafford, 2009a, “The Economics of Structured Finance,”
Journal of Economic Perspectives 23 Winter, 3-25
Coval, Joshua, Jakub Jurek, and Erik Stafford, 2009b, “Economic Catastrophe Bonds,” American
Economic Review 99 June, 628-666.
Covitz, Daniel M., Liang, Nellie and Suarez, Gustavo, “The Evolution of a Financial Crisis:
Panic in the Asset-Backed Commercial Paper Market,” Working Paper, 2010.
Demyanyk, Yuliya, and Otto Van Hemert. “Understanding the Subprime Mortgage Crisis,”
Review of Financial Studies (forthcoming).
Eichner, Matthew J., Donald L. Kohn, and Michael G. Palumbo, “Financial Statistics for the
United States and the Crisis: What Did They Get Right, What Did They Miss, and How Should
They Change?” Finance and Economics Discussion Series Working Paper 2010-20, Federal
Reserve Board.
Elul, Ronel, “Securitization and Mortgage Default: Reputation vs. Adverse Selection,” Federal
Reserve Bank of Philadelphia Working Paper No. 09-21, 2009.
Engle, Robert, Anticipating Correlations: A New Paradigm for Risk Management, Princeton, NJ:
Princeton University Press, 2009.
French, Kenneth, et al, The Squam Lake Report: Fixing the Financial System, Princeton, NJ:
Princeton University Press, 2010.

20
Garmaise, Mark, “After the Honeymoon: Relationship Dynamics between Mortgage Brokers and
Banks,” UCLA Working Paper, 2008.
Herzog, Thomas N., Fritz J. Scheuren, and William E. Winkler, Data Quality and Record
Linkage Techniques, New York: Springer, 2007.
Jacobson, Tor, Jesper Linde, and Kasper Roszbach, “Internal Rating Systems, Implied Credit
Risk, and the Consistency of Banks’ Risk Classification Policies,” Journal of Banking and
Finance 30, 2006, 1899-1926.
Keys, Benjamin J., Tanmoy Mukherjee, Amit Seru, and Vikrant Vig, “Financial Regulation and
Securitization: Evidence from Subprime Loans,” Journal of Monetary Economics, July 2009,
700-720.
Nakamura, Leonard, and Kasper Roszbach, “Credit Rating and Bank Monitoring Ability,”
Federal Reserve Bank of Philadelphia Working Paper No. 10-21, 2010.

21

Table 1. Credit Market Borrowing and Debt Owed by Nonfinancial Sectors, 2007
and 2008
Billions of dollars
Annual Flows and Levels
(1)
(2)
(3)
Tables F.2 and L.2
Net Borrowing Year-End Debt Year-End Debt
2008
2007
2008
Domestic
1873.2
31707.1
33580.3
By instrument
1873.2
31707.1
33580.3
Commercial paper
7.7
123.8
131.5
Treasury securities
1239.0
5099.2
6338.2
Agency and GSE-backed
0.2
23.1
23.3
securities
Municipal securities
63.2
2618.9
2682.1
Corporate bonds
204.6
3558.9
3763.5
Bank loans, n.e.c.
195.2
1648.9
1844.1
Other loans and advances
62.0
1674.5
1736.6
Mortgages
57.3
14407.8
14465.1
Home
-109.0
11137.2
11036.6
Multifamily residential
53.8
820.0
878.2
Commercial
109.3
2342.8
2439.2
Farm
3.3
107.8
111.1
Consumer Credit
44.0
2551.9
2595.9
By sector
1873.2
31707.1
33580.3
Household sector
49.5
13778.4
13832.9
Nonfinancial business
544.1
10614.5
11153.7
Corporate
362.6
6809.3
7167.0
Nonfarm noncorporate
170.2
3591.2
3761.4
Farm
11.3
214.0
225.3
State and local government
40.4
2191.8
2232.2
Federal government
1239.2
5122.3
6361.5
Foreign credit market debt
held in U.S.
Commercial paper
Bonds
Bank loans n.e.c.
Other loans and advances

-152.1

2017.3

1864.9

-71.0
-84.7
5.1
-1.6

413.0
1478.1
102.8
23.4

342.0
1393.4
107.9
21.5

Domestic and foreign

1721.1

33724.4

35445.2

