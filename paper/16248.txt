NBER WORKING PAPER SERIES

THE PERFORMANCE EFFECTS OF IT-ENABLED KNOWLEDGE MANAGEMENT
PRACTICES
Peter Cappelli
Working Paper 16248
http://www.nber.org/papers/w16248

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2010

This study was supported by the US Department of Education's National Center on Post-Secondary
Improvement. Thanks to Matthew Bidwell for helpful comments and to Rocio Bonet for careful research
assistance. The data for this project is housed at the Center for Economic Studies of the US Bureau
of the Census. The views expressed herein are those of the author and do not necessarily reflect the
views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2010 by Peter Cappelli. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

The Performance Effects of IT-Enabled Knowledge Management Practices
Peter Cappelli
NBER Working Paper No. 16248
August 2010
JEL No. L23,O31
ABSTRACT
The extensive literature on knowledge management spans several fields, but there are remarkably
few studies that address the basic question as to whether knowledge management practices improve
organizational performance. I examine that question using a national probability sample of establishments,
clear measures of IT-driven knowledge management practices, and an experimental design that offers
a unique approach for addressing concerns about endogeneity and omitted variables. The results indicate
that the use of company intranets, data warehousing practices, performance support systems, and employee
competency databases have significant and meaningful effects on a range of relevant business outcomes.

Peter Cappelli
The Wharton School
Center for Human Resources
University of Pennsylvania
Philadelphia, PA 19104-6358
and NBER
cappelli@wharton.upenn.edu

The Performance Effects of IT-Enabled Knowledge Management Practices
Abstract
The extensive literature on knowledge management spans several fields, but there are remarkably
few studies that address the basic question as to whether knowledge management practices improve
organizational performance. I examine that question using a national probability sample of
establishments, clear measures of IT-driven knowledge management practices, and an experimental
design that offers a unique approach for addressing concerns about endogeneity and omitted variables.
The results indicate that the use of company intranets, data warehousing practices, performance support
systems, and employee competency databases have significant and meaningful effects on a range of
relevant business outcomes.
Introduction:
The concept of knowledge management (KM) goes back to the earliest studies in economics,
more recently spanning other disciplines as well (see, e.g., Polyani 1958, Argote 1999, Dierkes, et al.

2001). What counts as “knowledge” has been the subject of a long conceptual debate (see, e.g., Ackoff
1989 and Guo and Sheffield 2008 for reviews), and while there is no consensus on a simple definition, the
idea that knowledge is information that has meaning seems central to most definitions. In the context of
business and organizations, knowledge refers to information that helps the organization meet its goals.
The practices that govern how such knowledge is produced, captured, and then used are therefore the
essence of knowledge management and will serve as the definition here.
The explosion of interest in knowledge management spawned best-selling books, practitioneroriented journals, and extensive research activities. 1 The interest stemmed in large measure from the
claim that knowledge management can explain organizational success, an assertion that makes it central
to the interests of organization, strategy, and economic researchers (Nelson 1991). Despite this interest,

1 See, e.g., Senge (1990) and new practitioner journals like the Journal of Knowledge Management Practice. As of 2010, there were over 3000 journal
articles about knowledge management as measured by those featuring the term “knowledge management” in the abstract of the article.

there has been remarkably little evidence as to whether knowledge management practices actually have
any effect on organizational outcomes. Arguably the most serious efforts to assess the effects of
knowledge management practices have been in the MIS field in part because information technology
offers concrete examples of knowledge management and in part because MIS already had a strong
tradition of examining the effects of technology.
In the arguments below, I identify information technology applications associated with
knowledge management practices and observe their relationships with various measures of organizational
outcomes. This analysis represents an advance over the few prior attempts to assess the effects of
knowledge management in several ways. First, these IT-based applications of KM are objective and
readily applicable across organizations. Second, the data are nationally representative, improving the
generalizability of the findings. Third, the design of the analysis makes it possible to address estimation
problems present in previous attempts. The study also contributes to the much more extensive MIS
literature on the effects of information technology by adding to the growing literature on the effects of
specific IT practices. The ability to examine specific practices with nationally-representative data with
multiple measures of performance and a longitudinal design for addressing estimation challenges is
reasonably unique even in the extensive MIS literature.
Knowledge Management Research:
Interest in knowledge management in an organizational and business context goes back at least to
Scientific Management and its effort to codifying the tacit knowledge that craft workers possessed and
teaching parts of it to less skilled, cheaper workers. Contemporary research on knowledge management is
sometimes dated from Nelson and Winter (1982) and their focus on how organizations create knowledge,
how they learn. Much of the research on knowledge management since then has been in the field of
management, initially with a focus on how tacit knowledge is developed and then used. Knowledge in
this context was typically seen as embedded in each organizational context, operating at the level of the
individual worker, and was transferred through social relationships (e.g.,Argote, Beckman, and Epple
1990). Examples include how technicians and craft workers learn to get the most out of new equipment

and how they pass such knowledge informally onto colleagues. A branch of this literature examined the
structure and practices of organizations as they affect the ability to learn (e.g., Cohen and Levinthal 1990;
Sorensen 2003), although it is probably fair to say that most of the research examined social and group
mechanisms rather than organizational factors. Reviews of the management-based KM literature make
clear that the focus of interest has been on describing how knowledge is created, retained, and transferred
(see, e.g., Argote, McEvily, and Reagans 2003). Assessing the impact of KM was of secondary
importance, and the few such studies look at the individual job level for outcomes (e.g., Darr, Argote, and
Epple 1995).
Prusac (2001) suggests that the recent focus on firm-level knowledge management was driven by
improvements in information technology, which are more of a firm-level issue. It is not surprising, then,
that a related set of research on KM developed in the MIS field (see Alavi and Leidner 2001 for an
overview). These studies sees specific IT tools as embodying knowledge management, as opposed to the
focus on social relationships in the management field. Another point of contrast with the management
literature is that researchers in the MIS tradition have been more concerned about the payoffs from
practices. 2
Very little is known about the effects of knowledge management practices on performance,
however. As Tanriverdi (2005) notes, there are few studies in either the MIS or management fields that
actually demonstrate a relationship between knowledge management, even broadly defined, and
performance. His study shows a link between IT readiness, knowledge management capabilities, and
then financial performance in a cross-section of healthcare providers. Lee and Choi (2003) find a
relationship between IT support, knowledge management practices, the performance of tasks and, in turn,
overall organizational performance in a cross-section of Korean firms. Economics and operations
research has a growing interest in KM and its outcomes as well. Here the measures of KM used often
2 These are not the only fields with an interest in knowledge management. Edwards, Hall, and Shaw
(2009), for example, review studies about knowledge management in operations research, although it is
fair to conclude that the OR research is much more limited than in management or MIS and focuses
mainly around the application of Problem Structuring Methods to knowledge-related issues.

range far and wide. Chen, Lu, and Yang (2009), for example, use data envelop techniques to argue that
the presence of a “think tank” leads to better performance among electricity generators; Yang (2010)
asserts that CEO perceptions of the KM orientation of their firm relate to the competitive position of their
firm in a cross-sectional sample of hi-tech Chinese companies; Loof and Heshmati (2002) use research
and development expenditures to proxy KM and relate it to innovation outcomes in a cross-section of
firms. And in a study that may be the most similar to the one here in terms of data, Kremp and Mairesse
(2004) use a representative cross-sectional sample of French manufacturers to examine the relationship
between a knowledge management orientation and measures of innovation and productivity in an
exploratory study. Some of their measures of KM are quite broad (e.g., having a knowledge management
culture), others extend beyond KM (e.g., incentives to retain employees), and none overlap with the IT
applications here. But they find significant effects on firm performance.
The challenge of investigating the relationship between knowledge management practices and
organizational outcomes begins with establishing what knowledge management means and
operationalizing it for analysis. As one can see from the KM studies cited above, the variables used to
measure KM vary widely across studies. But they are often quite indirect measures, and many have
construct validity challenges in that they may well be capturing effects from other phenomenon (e.g.,
employee retention saves turnover costs as well as knowledge). A recent review lamented that it was
possible to read a book-length account of KM and not have a sense of how the term was defined (Prentice
2009). In fact, though, there is some consensus as to how KM should be defined. Argote (1999) and
Argote, McEvily, and Reagans (2003) survey the voluminous research on knowledge management,
particularly from an organization and management perspective, and concluded that there are three basic
aspects to knowledge management: The creation of knowledge, its retention, and its transfer. Alavi and
Leidner (2001) do a similar review, emphasizing the MIS perspective and the separate body of research in
that field, coming up with a reasonably similar taxonomy: knowledge creation, sharing (including
retrieval and storage), transfer, and a fourth category of application. The first three items are virtually
identical in both reviews. It seems clear that any attempt to operationalize the general concept of
knowledge management should address these three aspects. (“Application” in Alavi and Leidner‟s (2001)

taxonomy, is a broader concept that is dependent on the context where it is applied and therefore may be
hard to measure across situations.) If knowledge in an organizational context is information that helps the
organization achieve its goals, then we can define knowledge management practices as those that help
create knowledge, retain it in the organization, and transfer it to where it is useful.
The other challenges of examining the effects of KM practices on organizational outcomes are
similar to those in any observational study. They include having appropriate measures of outcomes.
Measures used in prior studies are limited and include indirect measures such as participant satisfaction
with KM and perceived measures of success. While all these are useful, they are not necessarily the most
important measures of performance, especially in for-profit business operations. Arguably the most
common limitation to prior studies is that they all use cross-sectional research designs that limit the
ability to address questions of endogeneity (i.e., are the already best performers using more KM practices)
and omitted variables (i.e., are factors associated with the use of KM actually driving better performance).
Assessing Performance Effects: There has been an explosion of research in the past decade
exploring how various management practices affect organizational productivity and performance. Such
studies have been especially prominent in this journal (e.g., Corbett, Montes-Aancho, and Kirsch 2005;
Frei and Kalakota 1999; MacDuffie 1997). Systems of work organization may have been the most
prominent topic (e.g., Handel and Levine 2002) although the list now includes topics like organizational
structures (e.g., Bloom and Van Reenan 2007).
The literature on the payoffs from information technology (IT) is also extensive and closely
related to this analysis because the measures used to estimate KM practices are IT-related. That literature
is too extensive to review here (see Tanriverdi 2005 for a recent survey), but a brief summary begins with
noting that that there was an initial back-and-forth between studies that did not find a payoff to IT
spending, especially in economy-wide studies, and those that found positive effects, especially at the
firm-level (e.g., Bharadwaji et al. 1999). Since then studies have advanced considerably in terms of data
and methods. For example, Brynjolfsson and Hitt (2003) use longitudinal data and note that the return on
IT investments depends on the lag structure of investments. Recognition that expenditures per se can be a

noisy measure (e.g., accounting systems differ, and expenditures and use may not be perfectly correlated)
has led more recent studies to focus on the effects of specific IT systems: Mukhopadhvav and Kekre
(2002), for example, use a field study to examine the consequences of introducing IT-driven B2B
procurement systems; Bartel, Ichniowksi, and Shaw (2007) find that the introduction of computer
controlled machines improves productivity in the value industry. Aral, Brynjolfsson, and Wu (2010)
examine the introduction of Enterprise Resource Planning (ERP) systems and attempt to pin down the
causality of effects by observing that productivity rises when ERP system begin to be used but not when
they are purchased. Not all these studies find strong relationships: Heim and Peng (2010), for example,
find that the effect of statistical process control management practices overshadow those of related IT
investments, Ping (2010) finds no advantage to cutting edge IT investments, and perhaps most important
for our purposes, Devaraj and Kohli (2003) argue that the lack of relationship between IT expenditure
and performance outcomes they observe is because of the missing mediating effect of KM applications.
Studies of the effects of IT applications are much further advanced than the nascent research on
the effects of KM. But they have also become more fragmented in that findings about the effect of a
particular IT application may say little about the effects of a different IT application will be. That is not
surprising given that these applications – ERP, SPC, B2B, etc. – each enable different management
practices . Further, in order to get information on specific IT applications, virtually all the studies have by
necessity used narrow sampling frames that limit their generalizability.
While we may not learn much about the possible effects of KM applications from the IT studies,
the methodological issues are similar. The general framework underlying all these studies is that the
practices alter the production function in ways that allow capital and labor to be used more efficiently.
The goal of changing the production function seems central to the basic idea of knowledge management.3
Although it seems to be a straight-forward question conceptually, attempts to estimate the effects of
3 It is also possible that knowledge management practices might be directed at idiosyncratic outcomes
that cannot neatly be linked to production function-type outcomes (e.g., creating breakthrough or
“blockbuster” products that change the basic production function), although those goals seem less
common.

knowledge management practices, or indeed any practice, on organizational performance raise some of
the classic problems in observational studies. The challenges begin with the fact that the practices being
considered are choice variables where organizations must make a conscious decision to introduce the
practices being examined. Such a decision is not a random event, and one problem this raises is
endogeneity: Better performing firms may be the ones most able to afford and therefore choose to
innovate or perhaps those that are performing poorly may be the most motivated to innovate. In either
case, estimates of the effect of introducing knowledge management practices and performance will be
biased if the decision to introduce them is influenced by prior performance.
A second problem comes from the fact that many of the factors that could cause establishments to
introduce such practices may themselves have an independent effect on performance, the problem of
omitted variables or sample heterogeneity. It could be, for example, that organizations that innovate in
many aspects of management are also more likely to introduce knowledge management systems. There
could be a statistical association between the introduction of knowledge management practices and
organizational performance because firms that introduce those practices are doing many things that also
influence performance.
Both problems appear in analyses based on cross-sectional data. A standard approach for
addressing both the problem of endogeneity and of sample heterogeneity, therefore, is to use panel data.
The basic approach with panel data is to examine the use of a practice like knowledge management
techniques and organizational performance at time t and then again at t+1, comparing changes in practices
with the change in performance. Fixed effects models based on this approach draw comparisons within
organizations over time and are perhaps most effective in addressing omitted variable problems, to the
extent that unobserved variables within the organizations do not change within the period being examined
and that there is variation in practices and performance across the two periods. These models can also
help in dealing with endogeneity issues across establishments. But they do not necessarily eliminate them.

Fixed effects models look at the changes in practices and see how those changes affect
subsequent performance. Consider, for example, the fact that organizations that adopt practices

also make decisions as to when to do so, e.g., early in the evolution of the practices, where they
are still novel, or later when they are well-established. Organizations that adopt them earlier, in
period t, may be systematically different from those that adopt them in t+1. Late adopters have
less time to put the practices to use; they may also be less innovative than early adopters or
perhaps the practices are simply less important for them. For example, Ping, (2010) focuses on
early adopters of IT innovations and finds that they appear to get no advantage from their
investments as compared to those who do not adopt them.

Where practices are already well-established, the fixed effects models of panel data will focus
disproportionately on late adopters; when practices are relatively new, as they might more likely be for
the knowledge management practices considered here (see below), such an approach will
disproportionately focus on early adopters. (Capturing not only whether organizations introduced
practices but when they did so would help, but doing so often has to rely on the retrospective memory of
respondents, which is less than precise.) Further, virtually all fixed effect models are driven by changes
in practices, and they treat the introduction of practices and their abandonment as equivalent decisions.
While it is possible to examine these two pathways separately, doing so should be based on some
understanding of how they differ.
A related and more fundamental problem with panel data is that it exacerbates measurement error
in both the dependent and independent variables, where the latter is especially important because it can
lead to biased estimates. Panel data relies on differences in responses between periods, each one of which
is measured with error. The difference between two responses, each measured with error, therefore
compounds the error, making it greater than what we otherwise would observe in the cross section. The
problem is worse when the panel is relatively short: The true rate at which practices actually change is
likely to be less across a small period of time, and assuming that measurement error happens when
responses are given, the ratio of erroneously reported change to actual change will be higher in a shorter
period. In the context here, the biggest issue is with the independent variables that measure knowledge

management practices. Reports of changes in those practices will compound the measurement error, and
such error in independent variables creates biased estimates (see, e.g., Freeman 1984 for a discussion).
The problem should be less severe the farther apart the observations are in time because the rate of
misclassification should remain the same while the number of true changers should be greater where more
time is passed.4 If panel data estimates of the effects of practices are smaller (in absolute value) than
cross-section estimates, we cannot tell without additional information whether this result is due to a
reduction of the bias from heterogeneity or an exacerbation of the bias from measurement error.
In the arguments that follow, we rely on a unique set of information that allows us to examine the
effect of IT-related knowledge management practices on organizational performance with a research
design that represents a considerable improvement over most prior studies. First, we can examine those
knowledge management practices with reasonably objective measures that are comparable across
organizations, industries, and contexts. Because the data are based on a national probability sample, we
can draw conclusions that have reasonably clear external validity. Second, the longitudinal nature of the
data allows us to use the basic fixed effect design to address omitted variable issues. Third and most
important, the structure of the data allows us to control for performance before the knowledge
management practices were introduced, addressing some of the more intractable endogeneity problems
described above that are otherwise difficult or impossible to address. Although the focus is on KM, the
study can also contribute to the larger literature on IT applications by using a representative sampling
frame and a novel approach to addressing endogeneity and omitted variable issues.
Data and Methods:
The information for this study comes from the National Employers Survey (NES III) conducted
in 2000/2001, which was in part designed to examine knowledge management issues. The National
Employer Surveys have been administered by the Bureau of the Census as telephone surveys using
Computer Assisted Telephone Interviewing (CATI) where the interviewer entered responses directly into

4 The extent to which this is the case, and whether it negates the advantages of addressing heterogeneity, depends on the extent of measurement error, its
correlation over time, and the magnitude of the heterogeneity bias.

a database. The survey was delivered to a nationally representative sample of private establishments with
20 or more employees. It is drawn from the Standard Statistical Establishment List (SSEL), a listing of
establishments taken from Internal Revenue Service records and based on the mandatory tax reporting by
employers. As such, it is the definitive list of employers, which is superior in its representativeness to
other commonly used employer sampling frames.
Establishments represent a coherent location where operations take place whereas the firm or
company is based on a legal definition that may encompass many separate locations. Using
establishments as the unit of analysis provides a more accurate measure of actual practices because
practices vary across operations and locations within firms, especially larger firms. Performance measures
at the establishment level are also more likely to reflect factors unique and limited to the establishment.
A potential downside is that some financial measures of performance, especially overall profitability, are
typically only collected at the firm level. The benefits of better knowledge management practice are
likely to include synergies across establishments that show up at the firm level but not at the
establishment level. Our results therefore will miss such benefits.
The survey over-sampled establishments in the manufacturing sector and establishments with
more than 100 employees. Public-sector employers, non-profit institutions, and corporate headquarters
were excluded from the sample, as were establishments with fewer than 20 employees. Establishments
with fewer than 20 employees are numerous but account for only approximately 25 percent of all
workers. The choice of restricting the survey to larger establishments was made not only because smaller
establishments come and go quickly but also because the management and workplace practices of very
small establishments are often so informal and variable, changing day-to-day in response to otherwise
routine developments such as absenteeism, as to make it difficult to respond in a meaningful way to
questions about practices and policies.
In administering the NES, the target respondent was the plant manager in the manufacturing
sector and the local business site manager in the non-manufacturing sector. The goal of this survey,
however, was to measure what was actually done in the facility, not the policies that might exist in

employee handbooks. For some topics, such as knowledge management practices, there may be a big
difference between actual and stated policies. The best person to ask about actual operating practices is
the person in charge of the establishment. The questionnaire was designed to allow for multiple
respondents so that, for example, information could be obtained from establishments that kept financial
data in a separate office, typically at corporate headquarters for multi-establishment enterprises.
The usual reason given by employers for non-participation in the survey was that they did not
participate in voluntary surveys or were too busy to do so. Analysis of the characteristics of respondents
and non-respondents from the sampling frame indicates that there was no significant pattern of
differences at the two-digit industry level in the likelihood of participating in the survey (Lynch and Black
1998). The only differentiating characteristic of establishments less likely to participate was that
manufacturing establishments with more than 1000 employees, constituting 0.1 percent of the sample,
were less likely to do so. Larger establishments have more resources and may be more likely both to
afford the costs of implementing KM practices and to see benefits from them. To the extent that we lose
larger establishments, we may be losing observations that would improve our results. On the other hand,
because the sampling frame bypasses the very smallest establishments, we may also lose observations that
are less likely to use and to see benefits from KM practices.
The survey was conducted in 1994, repeated in 1997 and then again in 2001 when questions
about knowledge management were included. The sampling frame for the 2001 was drawn from the
establishments that responded to the 1997survey. It includes 2,825 establishments with more than 20
employees with a response rate of 85 percent. 1225 of the 2001 establishments were surveyed in the 1994
as well. A downside of surveying only those establishments that are still operating in 2001 is that the data
miss establishments that failed between 1994 and 2001. The question that we cannot answer given the
design of the sample is whether the use of knowledge management practices was associated with the risk
that an establishment would fail. If so, the results could be biased because the sample would lose poor
performing establishments (i.e., those that failed), biasing measures of effects upward if those making
greater use of knowledge management practices failed or downward if those making less use of the

practices failed.5 The 1994 and 1997 data have been used in a number of studies (there were no KM
questions on those surveys), but the 2001 data have never been used before. The most relevant of the
prior NES studies are Lynch and Black (2001), which shows that having more employees using
computers raised organizational productivity.
The structure of the data combined with the history of developments in knowledge management
makes it possible for us to address some of the above statistical problems using a unique approach that
improves on the standard fixed effects technique based on panel data. Specifically, we are able to form a
panel in which the first wave was conducted before the specific knowledge management practices being
considered existed, at least in the form that they are operationalized here. We also know the performance
level of the establishment before the practices were introduced. This gives us an initial measure of
performance that is exogenous and unrelated to the introduction of knowledge management practices.
We can use this measure to generate a fixed effect/first difference estimate by comparing it with
performance in a latter period when knowledge management practices were measured. (Cappelli and
Neumark 2001 use this approach as well.) This approach has the general advantage of fixed effects
estimates in addressing omitted variable problems. Further, having an initial estimate of performance that
is independent of the use of knowledge management practices avoids the problem of exacerbating
measurement error associated with panel data: If the practices did not exist in the first period, there
should be no exacerbation of measurement error because there can be no error in the first measure.
The most important advantage of this approach, however, is in addressing the endogeneity
problem. Arguably the biggest concern for estimation is if establishments that already are performing
well are more likely to introduce these knowledge management practices. (If the reverse was true, poor
performing establishments being more likely to introduce them, this would lead to a downward bias in the
estimate, making it more difficult to find a significant, positive relationship between practices and
performance and producing a more conservative test.) If the initial measure of performance can be
structured so as to be free from any association with the incidence of knowledge management practices, it
5 Because the 2001 survey interviewed only a subset of the respondents from 1997, it is quite difficult without access to Census‟ internal interview reports to learn
anything about the respondents who failed and how they differed from the survivors.

provides a very effective means – superior to standard fixed effects models - to control for the possibility
that good performing establishments disproportionately introduced these practices.6
The above arguments rely on the assumption that the practices being examined did not exist
before the beginning of the panel, when the first measure of performance was gathered, and there are
many caveats to such a claim. First, it is impossible to prove with certainty that practices did not exist in
any given operation, in part because attempts to measure practices almost never are made until such
practices are reasonably well-known. Second and more important, even if the specific practice under
consideration did not exist, some related practice with a similar mission may have been in operation.
Consider, for example, the practice of having a company intranet. Such practices could not exist before
the IT systems behind them existed, but it was possible for organizations to use other technologies to
facilitate the information sharing that is the goal of intranets: an information billboard where questions are
posted, e.g., or even a company library could serve that purpose.
If related practices existed before the specific knowledge management practice being measured
here, then some part of any possible performance enhancing effect was also operating in the earlier
period. Our estimate of the effect of introducing the knowledge practices would therefore be biased
downward as it would be net of the prior performance effects. The explanation is similar if the actual
practice being measured was somehow in place before the beginning of the panel. In other words, the
analyses here do not rest on the claim that the knowledge management practices did not exist before 1993.
It is only the claim that this empirical approach reduces biases in the estimate that relies on that assertion.
This situation represents somewhat good news for analyzing whether knowledge management practices

6 Another possibility, more difficult to address, is that the decision to introduce these practices is based on future
performance: Establishments that anticipate changes in performance might be more or less likely to introduce them
now. For example, an establishment might believe that business will boom in the future and therefore will require
better knowledge management practices to keep up. It is not completely obvious how such a situation affects an
analysis of the relationship between these practices and current performance. If the estimate of future performance
is truly independent from current performance, then it should have no effect on the former estimate.

improve performance as the downward bias in estimating positive effects makes for a more conservative
test.
To determine whether the relevant knowledge management practices existed before the first
survey, we conducted an extensive review of the practitioner literature using two different databases that
each captures thousands of publications. Specifically, we looked to see when the practice in question was
first mentioned. As noted above, it is possible that the practice existed even before there was a name for
it, but such a situation is unlikely to be common. Business and practitioner publications are interested in
reporting on new developments, and if they have yet to identify any organization using a practice, it is not
likely that the practice is widespread. If the practice has yet to be described or discussed, let alone having
examples of organizations using it, then it is even less likely that it is present in our

establishments. (See Appendix for details.)7
The above approach is not the only technique for addressing endogeneity problems, of
course. Statistical techniques for addressing endogeneity include using instrumental variables as
a substitute for the potentially endogenous independent variable, in this case the KM practices.
Good instruments are variables that would be correlated with the use of knowledge management
practices but uncorrelated with the error term in the original equation. It is difficult to find
instruments that meet that test, however, and there are no obvious candidates in these data. A
different approach is to use “switching” models where the change from one regime or set of
practices to another is endogenous with respect to the outcome variables. Such models require
knowing in this case when practices were introduced, information that is not available here. The
Heckman selectivity model is a special case of a switching model for situations where only one

7 We should be clear, however, that even controlling for performance before knowledge management practices could have existed does not completely
eliminate the concern about endogeneity. It is possible, for example, for an establishment to have its performance spike up because of some change in its market after
1993 that leads to higher performance in 2001. That higher performance might make it more likely for them to introduce knowledge management practices before
2001. As an empirical matter, performance as measured in the 1994 survey is strongly related with performance in 2000 (see below), suggesting that there may not be
many establishments where the above scenario could hold. The unique variation in performance across establishments in 2001 will be less when controlling for 1993
performance, therefore, which makes it more difficult to find a statistically significant relationship between performance and any independent variable.

regime can be observed as in cross-sectional data.8 Experimental designs like the one used here that
help rule out endogeneity are preferable to statistical adjustments to data with endogenous attributes.
While the above design rests on assumptions about the use of KM practices in 1994, the alternative
statistical adjustments also rely on assumptions that are more difficult to test (e.g., normal distribution of
the variables in the underlying population).
Knowledge Management Variables: The NES 2000/01 asked establishments about their use of
knowledge management practices that span the three categories of the knowledge management terrain
identified above in prior research: Creating knowledge, retaining it in the organization, and transferring it
within the organization. These survey questions follow the MIS tradition in that they ask about specific IT
tools and practices that drive knowledge management actions. The advantages of using IT systems to
measure of knowledge management practices include the fact that having or not having such systems is a
more objective measure than, say, whether individual employees share information, and they are also
reasonably consistent to interpret across organizational contexts. The answers are therefore more likely to
be valid.
The questions we use in the analysis are as follows: 9
Does your establishment…
maintain a formal system, such as a database, for identifying which employees are good at which
tasks? Yes/No
maintain an intranet, a computer-based network within your organization? Yes/No
use data warehousing, systematically collecting data related to operations for analysis later?
Yes/No
use electronic performance support systems, a computer application that guides users in
performing tasks as they do them? Yes/No
Each question included a help screen that provided respondents with further explanation of the concept
and examples of the practices in question.
8 For a discussion of switching models as a solution to endogeneity problems, see Dutoit 2007.
9 These questions were generated with the help of Linda Argote at Carnegie Mellon University.

The “data warehousing” item falls under the heading of creating and capturing knowledge, which
is arguably the most basic and best-known aspect of knowledge management (see, e.g., Argote 1999).
Data warehousing are systems for extracting data and storing it in for later use in analyses that support
management decisions (Watson and Hurley 1997). These systems might be thought of as the first step in
sophisticated analyses to understand an organization‟s business environment through data it produces.
While the best-known applications of such analyses may be in marketing, they touch every aspect of
business. The “database on employee competencies” variable is an example of a knowledge retention
practice. Identifying and then recording which employees are good at what allows the employer to assign
individuals to tasks in ways that improve performance (Reagans, Argote, and Brooks, 2005).

“Performance support systems” are software controlled by employees that helps them perform tasks by
providing access to information, tools, or advice that aid in addressing problems (Lee and Liu, 2006). A
simple example might be a pop-up menu that provides formulas or calculators to aid in answering
financial questions. (The infamous Microsoft “clippy” icon may be the best-known example.) Research
on the effects of these systems on performance outcomes, almost always at the task and individual level,
has been limited to case studies (e.g., Chang, 2007). Intranets use internet technology, typically
protected via firewalls, as a tool for communication within a specific group or community (Skok and
Kalmanovitch 2005). The knowledge sharing that is facilitated by intranets cuts across all aspects of
performance. Here as well, prior research on the effects of intranets on performance focuses almost
entirely on individual outcomes and case studies (e.g., Lee and Kim 2009). In our context, intranets
operate within the establishment, possibly beyond to the broader firm in multi-establishment operations.
Both performance support systems and intranets fall under the “transferring knowledge” aspect of
knowledge management.
It is worth noting the construct validity issues of using specific IT practices like these to measure
KM. For example, it is certainly possible to have knowledge sharing without an intranet. The estimation
here, therefore, captures the marginal effect of having an intranet beyond the effects of other information
sharing arrangements that might be in place without IT support. If we consider the estimates here as

measuring overall KM practices, they may be conservative measures. Because these measures clearly do
not exhaust the possible set of knowledge management practices, the failure to find relationships between
them and performance outcomes would not dismiss the general claim that knowledge management
practices improves performance. Evidence of such relationships, though, would support the more general
hypothesis that these practices affect organizational outcomes.
It is also possible that the IT practices used here may facilitate performance improvements
through channels other than KM. That concern is most likely with the “intranet” measure. Martini et al.
2009 note in their review of case studies that intranets in business are used almost entirely for transferring
information. But they can also facilitate distributed software and computing services that can reduce
costs, and some of the effects on performance we observe could be attributable to that channel.
As noted above, we assert that these IT-enabled manifestations of knowledge management
practices effectively did not exist for most establishments when the first measure of performance was
taken in the 1994 survey. The information we have is only when the practices were first discussed, and
the assertion is that they would not become common in establishments until well after then. Their first
appearance in the business and academic literature was as follows: For company intranet, the first
mention of any company using an internal intranet is in 1995; the first mention of any database (electronic
or otherwise) capturing employee competencies is in 1994; the first mention of “electronic performance
support” in companies was in mid-1992 as a tool to support a specific training program; although data
storage certainly existed earlier, the concept of “data warehousing” as something that could be used to aid
management decisions (as opposed to simply retrieve data) is first mentioned in a conceptual sense a
technical journal in 1992. The particular citations where these practices appeared are available on
request. For the purposes of estimation, our claim is simply that the use of these practices by the
establishments in our dataset before 1993 is likely to be rare and therefore inconsequential to our effort to
limit the bias in our estimation.10

10 If the practices existed in any establishment before 1993 and had a positive effect on
performance – the relationship we are testing – then the fixed effect estimates would be biased downward.

Dependent Variables: We have three measures of establishment performance. The first and most
important is annual revenue or sales per employee (“Salesln” in log form). While measures of physical
productivity have some advantages as being more proximate to any changes in production functions, this
measure has the important advantage of being comparable across industries and contexts. Sales per
employee has been used in many other contexts to measure establishment performance. In addition, we
have two other measures, unique to the manufacturing context, that tell us a great deal about operating
efficiency. These are scrap costs per employee (“Scrapcosts”) – the value of failed assemblies or other
material that cannot be repaired or restored – and cycle time (“cycletime”) – the period of time required to
complete one cycle of the manufacturing process. Both of these variables are expressed as negative
values in the data. Lower scrap rates, other things equal, mean less waste, an important measure of
production efficiency. Equivalent operations with lower cycle times are more efficient in that they
produce more in the same amount of time (for more about the relevance of these two measures to the
production process, see Hopp and Spearman 2001). When combined with controls for industry type,
these variables measure aspects of relative operating performance that may be different from sales per
employee.
Control Variables: Important control variables are first the industry in which the establishment
operates (three-digit SIC code) as that has a largely determinant effect on the production process. The
book value of capital stock (“Bookvalue”) is a standard control variable in studies based on production
functions as more capital, other things equal, should make establishments more effective. This measure
captures investments of all kinds, including expenditures on IT. And size of the establishments as
measured by the number of employees. Size affects scale economies, among other things, and is captured
in the dependent variable in the sale equation, included as a control in the scrap cost and cycle time
regressions.

The concern would be more with the endogeneity issues noted above, the possibility that more effective
establishments were more likely to adopt them.

We add one more very important control variable in an attempt to address further the omitted
variable issue - that something like a general innovative capability or good overall management could be
driving both overall higher performance as measured in 2001 and the introduction of knowledge
management practices. Performance in 1994 should capture any effect of innovation on performance that
is constant between the two periods, so the concern is really whether there is any change in overall
operating effectiveness or innovativeness after 1994 and before 2001 that could confound how we
interpret the relationship between the knowledge management variables and establishment performance.
The measure we use to address that concern is whether or not the establishment received ISO
9000 certification. This certification has been seen as measuring the effectiveness of internal
management systems, especially in the area of quality and productivity. Corbett, Montes-Aancho, and
Kirsch (2005) find that certification is associated with superior financial performance at the firm level.
They use a matched-pair control group for their analysis. We can replicate their analysis with our data
and a more traditional regression model. Specifically, we can see whether there is a relationship between
ISO 9000 certification and establishment performance and then also whether that relationship holds up
when controlling for performance in the earlier period. (Because ISO 9000 certification was introduced
before 1994, we cannot make the same claim as for our knowledge management variables, viz., that our
1994 performance measure is independent of the decision to secure certification.) For the purposes of this
paper, however, the more important idea is that ISO 9000 certification is a good measure for how
sophisticated a firm is in its management practices. Including that certification provides a good control
for the omitted variable of the overall sophistication of an establishment‟s management. And because the
certification took a few years to become popular, it might be especially important as a means of capturing
any change in overall management effectiveness after 1994.
Analyses and Results:
The analyses that follow and straight-forward and rely largely on the experimental design of the
data to address the statistical challenges associated with inferring causation. Table 1 presents variables,
means, standard deviations, and a correlation matrix of the variables used in the analyses. Because there

are no prior assessments of the extent to which these IT practices were used in the economy, it is difficult
to know what to expect. But the rank order of the extent of use of the practices seems sensible: Given that
intranets are often seen as one of the first IT applications in a system, the fact that intranet use is roughly
twice as great (80 percent use them) as the other practices is reasonable. The least common practice is the
employee database, with a third of establishments using them. That also seems reasonable given that such
practices require not only an IT system but also detailed assessments of employee performance by task,
which is a management challenge that not many employers undertake. What is perhaps more surprising
is that the KM practices are not strongly correlated with each other. The strongest relationship (.27) is
between intranet and performance support systems, and others are close to zero. Among other things, the
lack of correlation suggests that the other three KM practices do not necessarily rely on intranets.
Conceptually because the practices occur separately suggests the appropriateness of estimating each KM
practice independently.
The first analyses are presented in Table 2 where we examine the relationship between
establishment sales per employee in the cross-section. Each of the IT-knowledge management practices
exhibits a statistically significant relationship with the sales variable except for the employee competency
database, and all the signs are in the expected, positive direction. When we add 1993 sales as a control
variable, the significance pattern is unchanged. As one might expect, sales in 1993 is significantly and
strongly associated with sales in 2000/2001, and the magnitude of the IT-knowledge management effects
diminishes, suggesting that part of the effect one observes in cross-sectional analysis is more accurately
attributable to factors that were quite likely in existence before the knowledge management practices were
introduced. An important conclusion from this finding is that cross-sectional estimates of performance
effects are biased upward, suggested the need for alternative approaches in these and in prior analyses
conducted elsewhere. But the size of the relationships is still reasonably large. When controlling for
previous performance, having a system of performance support is associated with roughly seven percent
greater sales; a data warehousing system with 10 percent greater sales; and an intranet with 14 percent
greater sales. These are certainly meaningful effects for a business operation.

We repeat the same general approach in Table 3 with a new dependent variable, the value of
scrap costs per employee. This is a standard measure of operating efficiency in manufacturing operations.
Because it is only relevant for manufacturing, we restrict the sample to those establishments. The sample
size is smaller as a result, making it more difficult to estimate effects with precision, yet all four of the
knowledge management variables show significant relationships with the dependent variable, and the
effect sizes are substantially bigger that with the sales per employee measure. Again, because scrap costs
are expressed in negative form, greater use of these practices is associated with lower scrap costs. We
have no prior measure of scrap costs, but we can add the 1994 sales per employee measure as a general
control for the variation in performance across establishments. When we do so, the coefficients on the
knowledge management variables remain significant, and their magnitudes change only slightly. To
illustrate the magnitude of these effects, the use of an intranet is associated with 57 percent lower scrap
costs, and the use of electronic performance support systems are associated with even bigger reductions,
64 percent.
In Table 4 we conduct the same analyses for cycle time. The number of observations here falls
even further because of missing values, and perhaps for that reason the coefficients are not estimated as
precisely. The relationships with all the KM variables are in the expected direction, although when we
add the 1993 sales per employee control variable, only the electronic performance support and data
warehousing are significant. For those variables, the effects appear sizeable: Data warehousing, for
example, is associated with 52 percent less cycle time. The scrap cost and the cycle time equations
explain far less of the overall variance than does the sales per employee measure, which suggests
measurement or omitted variables may be more important in the former models. We might expect KM
practices to have bigger effects on scrap costs and cycle time than on sales per employee because the
former are measures of operating efficiency, the focus of most KM, while sales per employee and revenue
more generally is driven in part by market prices and by marketing and sales practices that are less the
focus of KM. Nevertheless, it is useful to see that KM has significant and meaningful effects both on the
cost and the revenue side of these operations.

We add the ISO 9000 variable in Table 5 to control for general operating effectiveness and
innovation, replicating the earlier study by Corbett, Montes-Aancho, and Kirsch (2005). As with their
study, we find that IS0 9000 certification is associated with superior financial performance in the form of
establishment sales. But the significance of the effect disappears when we add 1993 sales, and the
magnitude of the coefficient shrinks sharply. When including the ISO 9000 measure as an additional
control, the knowledge management variables are still significant. When 1993 sales are added as another
control variable, the KM variables retain the same general pattern of significance as before with
coefficient sizes basically unchanged. These results give us confidence that that the relationship between
performance and knowledge management is not driven by the omitted variable of overall innovation
effectiveness or operating excellence. We also examine the above relationships with other specifications
(available on request). When we include all the KM variables in the same equation, not surprisingly, the
significance of each individual relationship although the overall variance explained remains similar,
reflecting collinearity among those variables in the context of these models. When we combine the KM
variables to form principal components, the significance and effect sizes are at least as large as with the
individual analyses. But there is no justification for interpreting the KM variables simultaneously given
the fact that they do not have to occur together, as illustrated by the earlier finding that their presence in
the establishments is not closely correlated.11
Conclusions and Managerial Implications:
The widespread and growing interest across fields in the topic of knowledge management rests
heavily on the idea that organizational performance can be improved through explicit attempts to manage
the creation, retention, and transfer of knowledge about performance issues. While the literature on
knowledge management is now vast and spans the MIS and management fields, there are remarkably few
studies that address this basic empirical question as to whether knowledge management practices

11 It is not unusual for the presence of variables across observations to be relatively uncorrelated in a sample and to be collinear in the context of a
particular regression model because the two exercises capture something different. For example, the bivariate correlations here represent relationships between only
two variables while collinearity is driven by the common variation among any and all of the KM variables (i.e., including three-way and four-way correlations).
Further, the common variation that causes collinearity in the regression model is only with respect to the relationship with the dependent variables and to the
component of variation that is independent of the variation associated with the control variables.

contribute to improved effectiveness and efficiency. The above study represents a considerable advance
over prior research in this area and adds to the more general research on the effects of IT practices.
The results across the different measures of organizational performance suggest that these
knowledge management practices have significant and meaningful effects on organizational performance.
Data warehousing has the biggest effect on cycle time, electronic performance support systems have their
largest effect on scrap rates, and the use of an intranet use has the biggest effect on sales. The results for
maintaining a data base of employee competencies were much more mixed, showing a significant
relationship only for scrap rates. Comparing the different practices, data warehousing and intranets are
the most general purpose knowledge management practices in that they can be used in several KM tasks
and contexts. Maintaining a database on employee competencies is arguably the most specific and
narrow of the practices. It is used to make better matches between employees and jobs, but presumably
those matches only happen when employees move to new positions. In an industry like consulting, those
assignments are project or engagement-based and happen frequently, these arrangements may pay off, as
Ofek and Sarfary (2001) speculate. But in most organizations, they are relatively rare events that happen
only when employees are promoted or otherwise move to different jobs. The scope for improving
organizational effectiveness therefore may be less and may explain why this practice had the weakest
effects on organizational performance.
Overall, the effects are quite large, especially in the case of cycle time where the use of these
practices is associated with a 50 percent or more reduction in cycle time. They only apply to
manufacturing operations, and cycle time is only one aspect of production efficiency, which is in turn
only one aspect of performance for businesses. Nevertheless, cycle time matters a great deal for
organizations, and these effects are very meaningful in magnitude. That leads directly to implications for
management application. Whether or not to pursue formal KM practices has been the topic of recent
research at the conceptual level (e.g., Lee and Steen 2010). The empirical results here seem to suggest
that IT-driven KM practices can have big effects on performance. Before leaving that conclusion,
however, we should acknowledge several limitations. For example, we cannot be sure whether the higher

performance on sales, scrap rates, and cycle time are offset by more intensive use of other resources
besides those we control for here. Specifically, we do not know what it costs to put these KM practices in
place. We have controls for capital, but there may be other costs – training employees, for example – that
we cannot measure. Variables measuring profitability would be preferable in this regard, but using such
measures would require collecting data at the level of analysis where profit is calculated, typically the
firm. And that would create the problem noted earlier, that it is hard to establish clearly what practices
are in use in firms, which often have multiple locations and operations.

And we cannot be sure that the

intranet effects in particular only relate to KM outcomes as intranets can facilitate functions other than
information management and communication.
Having prior measures of performance and a good measure of innovative practices other than
knowledge management as controls certainly helps make the case for the results. Omitted variables are
always a concern, however, especially in models where the total amount of variance explained is
relatively small as with the scrap and cycle time models. What we are measuring here is the IT
application of knowledge management practices, but it is important to recognize that these applications
stand as proxies for management approaches that can be quite systematic. Electronic performance
support systems, for example, change the way tasks are performed, standardizing them across the
organization. Data warehousing can be an essential component of quality control practices and root cause
analysis. Intranets are the most general purpose of the applications and facilitate an array of information
transfer and communication efforts within organizations. The effects we observe, therefore, are likely
associated with approaches to managing operations that are systematic and arguably fundamentally
different from those that came before. The relationships we see are likely capturing new ways of
managing associated with KM practices, not simply the effects of these IT systems per se. And in that
context, the large effect sizes we observe seem reasonable.
Knowledge management continues to be an important topic for managers as they seek to deal
with the loss of knowledge from greater employee attrition, with the extension of operations to global
markets that stretches the limits of coordination around standard practices, and more generally the basic

strategy concern of finding sources of competitive advantage inside their operations. The notion that
knowledge management can be driven or at least assisted by IT systems seems to be advanced by these
developments as compared to the alternative view of seeing it reside in social relationships given that
globalization and increasing employee mobility tears at the heart of the relationship model. These results
give us substantially greater confidence that IT-related knowledge management practices of the kind
described here have a meaningful effect on important aspects of organizational performance.

Table 1 Descriptive Statistics

Mean

S.D.

Employee Database
Intranet
Data Warehouse
Performance Support System

.33
.81
.57
.40

(.47)
(.39)
(.49)
(.49)

Sales (millions)
Sales 1993 (millions)
Capital Book Value (millions)
Scrap Costs/Sales
Cycle Time (hours)
ISO 9000

5.21
4.93
10.78
-3.16
-1.93
.38

(.77)
(.72)
(1.62)
(1.75)
(2.2)
(.48)

Correlation Matrix
1
2
3
4
5
6
7
8
9
10
1. Employee Database
1.00
2. Intranet
.01 1.00
3. Data Warehouse
.13 .22 1.00
4. Performance Support System .18 .27 .13 1.00
5. Sales per employee
.01 .13 .21 .12 1.00
6. Sales 1993 per employee
-.02 .11 .16 .21 .66 1.00
7. Book Value
.00 .07 .13 .10 .46 .36 1.00
8. Scrap Costs
-.08 -.05 -.22 -.20 -.17 -.20 -.12 1.00
9. Cycle Time
-.05 -.06 -.15 -.08 -.24 -.20 -.15 .40 1.00
10. ISO 9000
.19 .11 .15 .06 .19 .19 .22 -.19 -.12 1.00

Table 2
(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

Sales(ln) Sales(ln) Sales (ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln)
BookValue

0.173

0.108

0.177

0.109

0.171

0.107

0.172

0.108

0.174

0.108

(0.030)** (0.024)** (0.030)** (0.024)** (0.030)** (0.024)** (0.029)** (0.023)** (0.029)** (0.023)**
Sales1993(ln)

0.578
(0.040)**

Sys/dbase good which jobs?

0.581
(0.040)**
0.007
(0.049)

0.574
(0.040)**

0.569
(0.040)**

0.007
(0.039)

Electronic perform supp systems?

0.161
0.078
(0.046)** (0.039)*

Use data warehousing?

0.209
0.106
(0.047)** (0.042)*

Maintain an intranet?
Constant

0.573
(0.040)**

2.724

0.825

2.770

0.831

2.764

0.850

2.646

0.806

0.224
0.140
(0.056)** (0.048)**
2.582
0.739

(0.442)** (0.274)** (0.440)** (0.274)** (0.416)** (0.270)** (0.419)** (0.266)** (0.429)** (0.270)**
Observations

891

891

891

891

891

891

891

891

891

891

R-squared

0.28

0.50

0.27

0.50

0.28

0.50

0.29

0.50

0.29

0.51

Robust standard errors in parentheses. Industry control variables suppressed.
+ significant at 10%; * significant at 5%; ** significant at 1%

Table 3
(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

Scrapcost(ln Scrapcost(ln Scrapcost(ln Scrapcost(ln Scrapcost(ln Scrapcost(ln Srapcost(ln Scrapcost(ln Scrapcost(ln Scrapcost(ln
BookValue

-0.142

-0.092

-0.149

-0.093

-0.132

-0.084

-0.151

-0.100

-0.114

-0.075

(0.049)**

(0.050)+

(0.049)**

(0.050)+

(0.048)**

(0.049)+

(0.049)**

(0.051)*

(0.046)*

(0.048)

Sales1993(ln)
Sys/dbase good
which jobs?
Electronic
perform supp
system?
Maintain an
intranet?
Use data
warehousing?
Constant

-0.445

-0.481

-0.426

-0.443

-0.358

(0.116)**

(0.115)**

(0.114)**

(0.115)**

(0.113)**

-0.290
(0.139)*

-0.307
(0.136)*
-0.688
(0.131)**

-0.639
(0.131)**
-0.639
(0.168)**

-0.575
(0.168)**

-2.286
(0.548)**

-0.716
(0.658)

-2.348
(0.556)**

-0.634
(0.663)

-2.353
(0.541)**

-0.839
(0.652)

-1.899
(0.566)**

-0.372
(0.661)

-0.635
(0.142)**
-1.829
(0.531)**

Observations

685

685

685

685

685

685

685

685

685

685

R-squared

0.06

0.08

0.05

0.08

0.08

0.10

0.07

0.09

0.12

0.14

Robust standard errors in parentheses. Industry and size control variables suppressed.
+ significant at 10%; * significant at 5%; ** significant at 1%

-0.588
(0.141)**
-0.600
(0.645)

Table 4
(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

Cycletime Cycletime Cycletime Cycletime Cycletime Cycletime Cycletime Cycletime Cycletime Cycletime
BookValue

-0.248

-0.184

(0.078)** (0.083)*
Sales1993(ln)

-0.273

-0.196

(0.078)** (0.084)*

-0.265

-0.195

(0.078)** (0.084)*

-0.251

-0.187

(0.079)** (0.085)*

-0.199

(0.078)** (0.084)*

-0.441

-0.511

-0.480

-0.451

-0.489

(0.152)**

(0.152)**

(0.151)**

(0.154)**

(0.152)**

Sys/dbase good which jobs?

-0.307
(0.195)

-0.319
(0.192)+

Electrnc perform supp syss?

-0.395
(0.191)*

-0.337
(0.188)+

Use data warehousing?

-0.593
-0.520
(0.187)** (0.189)**

Maintain an intranet?
Constant

-0.271

-0.395
(0.229)+

-0.336
(0.231)

0.768

2.141

0.722

2.324

0.699

2.202

0.742

2.149

0.931

2.427

(0.878)

(0.923)*

(0.883)

(0.923)*

(0.881)

(0.918)*

(0.896)

(0.929)*

(0.892)

(0.927)**

Observations

562

562

562

562

562

562

562

562

562

562

R-squared

0.12

0.13

0.10

0.12

0.10

0.12

0.11

0.13

0.10

0.12

Robust standard errors in parentheses. Industry and size control variables and establishment size suppressed.
+ significant at 10%; * significant at 5%; ** significant at 1%

Table 5
(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln) Sales(ln)
BookValue

0.162

0.106

0.160

0.105

0.165

0.106

0.161

0.105

0.161

0.105

(0.031)** (0.025)** (0.031)** (0.025)** (0.031)** (0.025)** (0.030)** (0.024)** (0.030)** (0.024)**
received ISO 9000 certification? 0.141
0.042
(0.055)* (0.046)
Sales1993(ln)

0.135
0.036
(0.054)* (0.046)

0.165
0.049
(0.054)** (0.046)

0.128
0.032
(0.052)* (0.045)

0.147
0.042
(0.052)** (0.044)

0.577

0.574

0.578

0.569

0.571

(0.041)**

(0.041)**

(0.040)**

(0.041)**

(0.040)**

Electronic perform supp systems?

0.137

0.071

(0.048)** (0.041)+
Sys/dbase good which jobs?

-0.032

-0.006

(0.051)

(0.041)

Use data warehousing?

0.195

0.109

(0.049)** (0.043)*
Maintain an intranet?

0.222

0.141

(0.057)** (0.048)**
Constant

2.861

0.862

2.887

0.879

2.907

0.872

2.773

0.833

2.713

0.778

(0.449)** (0.286)** (0.428)** (0.281)** (0.447)** (0.285)** (0.427)** (0.276)** (0.436)** (0.281)**
Observations

852

852

852

852

852

852

852

852

852

852

R-squared

0.29

0.51

0.29

0.51

0.28

0.51

0.30

0.51

0.30

0.51

Robust standard errors in parentheses
+ significant at 10%; * significant at 5%; ** significant at 1%

Bibliography:

Ackoff, R.L. 1989. "From data to wisdom", Journal of Applied System Analysis, Vol. 16: 3-9.
Alavi, M. and D. E. Leidner 2001. "Review: Knowledge Management and Knowledge Management
Systems: Conceptual Foundations and Research Issues." MIS Quarterly. 25(1): 107-136.
Aral, S., Brynjolfsson, E., Wu, D.J., 2010. Which Came First, IT or Productivity? Virtuous Cycle of
Investment and Use in Enterprise Systems. Available at SSRN: http://ssrn.com/abstract=942291
Argote, L. 1999. Organizational Learning: Creating, Retaining and Transferring Knowledge. Kluwer,
Norwell, MA.
Argote,L., McEvily, B., and Reagans, R. 2003. Managing Knowledge in Organizations: An Integrative
Framework and Review of Emerging Themes. Management Science 49(4): 571-582.
Argote, L., Beckman. S.. and Epple. D. 1990. The Persistence and Transfer of Learning in Industrial
Settings, Management Science (36), 1750-1763.
Bartel, A. C. Ichniowski, and K. Shaw. 2007. How Does Information Technology affect Productivity?
Plant-Level Comparisons of Product Innovation, Process Improvement and Worker Skills. Quarterly
Journal of Economics, Vol. 122 (4): 1721-1758.
Bharadwaj, A. S., Bharadwaj, S. G., and Konsynski, B. R. 1999. Information Technology Effects on Firm
Performance as Measured by Tobin's „Q‟. Management Science 45(7): 1008-1024.
Blasi, Joseph and Douglas L. Kruse. 2006.U.S. High-Performance Work Practices at Century's End.
Industrial Relations 45(4): 547-578.
Bloom, Nicholas and John Van Reenen. 2007. Measuring and Explaining Management Practices Across
Firms and Countries. Quarterly Journal of Economics, 122(4): 1351-1408.
Brynjolfsson, E. 1996. Paradox Lost? Firm-Level Evidence on the Returns to Information Systems
Spending. Management Science 42(4), 541-558.
Brynjolfsson, Erik and Lorin M. Hitt. 2003. Computing Productivity: Firm-Level Evidence. Review of
Economics & Statistics, 85(4): 793-808.
Cappelli, P. and D. Neumark. 2001. “Do „High Performance” Work Practices Improve EstablishmentLevel Outcomes?” Industrial and Labor Relations Review, 54(4): 737-775.
Chang, C.C. 2007. A Study of the Quantitative Analysis of the Development and Implementation for
Electronic Performance Support Systems. International Journal of Instructional Media 34(3): 275-284.
Chen, L-C.; Lu, W-M.; Yang, C.. 2009. Does knowledge management matter? Assessing the performance
of electricity distribution districts based on slacks-based data envelopment analysis Journal of the
Operational Research Society, Vol. 60(11): 1583-1593.
Cohen, W M,. and Levinthal D, A. 1990. , "Absorptive Capacity: A New Perspective on Learning and
Innovation," Administrative Science Quarterly (35): 128-152,

Corbett, Charles J., Maria J. Montes-Aancho, and David A. Kirsch. 2005. The Financial Impact of ISO
9000 Certification in the United States: An Empirical Analysis. Management Science. 51(7): 1046-1059.
Darr, E. D,. Argote. L.. and Epple, D. 1995. "The Acquisition, Transfer and Depredation of Knowledge
in Service Organizations: Productivity in Franchises," Management Science 41 (11): 1750-1613.
Devaraj, S., and Kohli, R. 2003. "Performance Impacts of Information Technology: Is Actual Usage the
Missing Link?" Management Science .49(3): 273-289.
Dierkes, M., Antal, A.B., Child, J., Nonaka, I. (Eds) 2001. Handbook of Organizational Learning and
Knowledge. Oxford: Oxford University Press.
Dutoit, L. 2007. Heckman‟s Selection Model, Endogenous and Exogenous Switchings: A Survey.
University of Lausanne working paper. works.bepress.com/laure_dutoit/3/.
Edwards, J.S., B. Ababneh, M. Hall, and D Shaw. 2009. Knowledge management: a review of the field
and of OR's contribution. The Journal of the Operational Research Society 60(S1): S114-126.
Freeman, Richard B. 1984. Longitudinal Analyses of the Effects of Trade Unions. Journal of Labor
Economics, Vol. 2(i): 1-26.
Frei, Frances X. and Ravi Kalakota. 1999. Process Variation as a Determinant of Bank Performance:
Evidence from the Retail Banking Study. Management Science, 45(9):1210-1220.
Fugate, B. , T.P. Stank, and J.T. Mentzer. 2009. Linking improved knowledge management to
operational and organizational performance. Journal of Operations Management. 27(3): 247-264.
Guo, Zining and James Sheffield. 2008. A paradigmatic and methodological examination of knowledge
management research: 2000 to 2004. Decision Support Systems 44:673-688.
Heim and Peng 2010 The impact of information technology use on plant structure, practices, and
performance: An exploratory study. Journal of Operations Management, 28(2): 144-162.
Hopp, W, and M. Spearman 2001. Factory Physics: Foundations of Manufacturing Management, 2nd Ed.
Boston: Irwin McGraw-Hill.
Handel, M. and Levine, D. 2004. “The Effects of New Work Practices on Workers.” Industrial Relations
43:1-43.
Kremp, E. and J. Mairesse. 2004. Knowledge Management, Innovation and Productivity: A Firm-Level
Exploration Based on French Manufacturing CIS3Data. Journal of Financial Transformation, 17: 39-47
Lee, Hung-Wen and Ching-Hsiang Liu. 2006. The Role of Electronic Performance Systems in Improving
Learning and Performance: A Managerial Perspective. International Journal of Management, 23(2): 632639.
Lee, H. and Choi, B.. 2003. Knowledge Management Enablers, Processes, and Organizational
Performance: An Integrative View and Empirical Examination. Journal of Management Information
Systems, 20(1): 179-228.
Lee, S. and B.G. Kim. 2009. Factors Affecting the Usage of Intranet: A Confirmatory Study. Computers
in Human Behavior, 25(1): 191-201.
Lee, D. and E.V.d. Steen. 2010. Managing Know-How. Management Science Vol. 56(2):270-285.
Lynch, Lisa M., and Sandra E. Black, 1998. "Beyond the Incidence of Employer-Provided
Training."Industrial and Labor Relations Review, 52(1): 64-81.

Lynch, L. and S. Black. 2001. How to Compete: The Impact of Workplace Practices and Information
Technology on Productivity. Review of Economics and Statistics 83(3): 434-445.
Loof, H. and A. Heshmati. 2002. Knowledge capital and performance heterogeneity: A firm-level
innovation study. International Journal of Production Economics. 76(1): 61-85.
MacDuffie, J. 1995. "Human Resource Bundles and Manufacturing Performance: Organizational Logic
and Flexible Production Systems in the World Auto Industry." Industrial and Labor Relations Review,
48(2): 197-221.
Martini, A., M. Corso, and L. Pellegrini. 2009. An Empirical Road Map for Internet Evolution.
International Journal of Information Management,(29) 4: 295-308.
Mukhopadhyay, T. and S. Kekre. 2002. Strategic and Operational Benefits of Electronic Integration in
B2B Procurement Processes. Management Science. 48(10): 1301-1313.

Nelson, R. 1991. "Why Do Firms Differ, and How Does It Matter?" Strategic Management Journal (12)
Special Issue: 61-74.
Nelson, R. and S. Winter 1982. An Evolutionary Theory of Economic Change. Boston: Harvard
University Press.
Ofek, E. and Sarvary M. 2001. Leveraging the Customer Base: Creating Competitive Advantage Through
Knowledge Management. Management Science. 47(11): 1441-1456. .
Ping, W. 2010. Chasing the Hottest IT: Effects of Information Technology Fashion on Organizations.
MIS Quarterly, Vol. 34(1): 63-85.
Polanyi, M. 1958. Personal Knowledge. London: Routledge & Kegan Paul.
Prusac, L.2001. Where Did Knowledge Management Come From? IBM System Journal. 40(4): 10021007.
Prentice, A.E.. 2009. Knowledge Management in Practice: Connections and Context. Journal of the
American Society for Information Science & Technology, Mar2009, Vol. 60 Issue 3, p642-642.
Reagans, Ray, Linda Argote, and Daria Brooks. 2005. Individual Experience and Experience Working
Together: Predicting Learning Rates from Knowing Who Knows What and Knowing How to Work
Together. Management Science; 51(6): 869-881.
Senge, P. 1990. The Fifth Discipline: The Art and Practice of the Learning Organization. New York:
Random House.
Simonin, B. 1997. The importance of collaborative know-how: An empirical test of the learning
organization. Academy of Management Journal. 40(5): 509-533.
Skok, W. and C. Kalmanovitch. 2005. Evaluating the role and effectiveness of an intranet in facilitating
knowledge management: A case study at Surrey county council, Information & Management 42: 731–
744.
Sorenson, O. 2003. Interdependence and adaptability: organizational learning and the long-term effect of
integration, Management Science 49(4).

Tanriverdi, H. 2005. "Information technology relatedness, knowledge management capability, and
performance of multibusiness firms." MIS Quarterly. 29(2): 311–334.
Watson, H., and Haley, B. 1997. Data warehousing: A framework and survey of current practices.
Journal of Data Warehousing, 2(1): 10-17.
Yang, J. 2010. The knowledge management strategy and its effect on firm performance: A contingency
analysis. International Journal of Production Economics. Vol. 125(2): 215-223.

Appendix: The History of Knowledge Management Practices
Search method: We searched two separate publication databases for evidence of these practices looking
for the terms anywhere in article text. The ABInform database used goes back to 1970, and the EBSCO
(Business Source Premier) database goes back to 1964.
"Employee competency data base" Searching for “competency”, “competency data”, “competency
database” and “competency data base” (+ the program also automatically gives “competence”). The
first mention of employee competencies comes from 1987 (Higgins, 1987), an article on an interactive
video test that scores managerial competence. “Competency data” does not get mentioned until
December 1992 (Murphy, 1992), in an article that tells about an HR software. There were only two
other relevant articles until January 1995, one from 1993 (on assessing competencies and gathering
competency data, Ulrich, 1993) and another from 1994 (on computer software that helps track nurses’
competencies).
“Does your establishment maintain an intranet?” The first mention of “intranet” is July 1995, in a
technology-centered article that says that this technology is coming. There are a few articles from
August – October 1995 that tell about companies that start to use the intranet.
“Does your establishment use data warehousing?” ABI automatically searches for “data storage” when
searching for “data warehouse”. The first ever mention of data storage is 1989, and there are various
other mentions of this term in 1991. The term “data storage” gets to be widely used in 1991. The first
mention of “data warehouse” is from 1992 (although this is in a highly technical context: What can
various software do?). The first mention outside a technical IT journal mention is also from 1992.
“Does your establishment use electronic performance support systems?” First mention in October
1991 as electronic performance support system; first mention March 1991 as performance support
system; First mention in January 1991 as “human resource information system.” These are conceptual
articles with practitioner-oriented articles appearing much later.

