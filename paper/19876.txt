NBER WORKING PAPER SERIES

REVEALED PREFERENCE, RATIONAL INATTENTION, AND COSTLY INFORMATION
ACQUISITION
Andrew Caplin
Mark Dean
Working Paper 19876
http://www.nber.org/papers/w19876

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2014

We thank Roland Benabou, Dirk Bergemann, Laurens Cherchye, Bram De Rock, Thomas Demuynck,
Federico Echenique, Andrew Ellis, Paola Manzini, Marco Mariotti, Daniel Martin, Filip Matejka,
Alisdair McKay, Stephen Morris, Pietro Ortoleva, Daphna Shohamy, Laura Veldkamp and Michael
Woodford for their constructive contributions. We also thank Samuel Brown, Severine Toussaert and
Isabel Trevino for their exceptional research assistance. An early version was circulated under the
title "Rational Inattention and State Dependent Stochastic Choice". The views expressed herein are
those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2014 by Andrew Caplin and Mark Dean. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

Revealed Preference, Rational Inattention, and Costly Information Acquisition
Andrew Caplin and Mark Dean
NBER Working Paper No. 19876
January 2014
JEL No. D80
ABSTRACT
We develop a revealed preference test for optimal acquisition of costly information. The test encompasses
models of rational inattention, sequential signal processing, and search. We provide limits on the extent
to which attention costs can be recovered from choice data. We experimentally elicit state dependent
stochastic choice data of the form the tests require. In simple cases, tests confirm that subjects adjust
their attention in response to incentives as the theory dictates.

Andrew Caplin
Department of Economics
New York University
19 W. 4th Street, 6th Floor
New York, NY 10012
and NBER
andrew.caplin@nyu.edu
Mark Dean
Department of Economics
Brown University
Box B
Providence, RI, 02912
mark_dean@brown.edu

Revealed Preference, Rational Inattention, and Costly
Information Acquisition∗
Andrew Caplin†and Mark Dean‡
January 2014

Abstract
We develop a revealed preference test for optimal acquisition of costly information.
The test encompasses models of rational inattention, sequential signal processing, and
search. We provide limits on the extent to which attention costs can be recovered
from choice data. We experimentally elicit state dependent stochastic choice data of
the form the tests require. In simple cases, tests confirm that subjects adjust their
attention in response to incentives as the theory dictates.

1

Introduction

Modelling behavior when information is costly to acquire has been central to economic analysis since the seminal work of Stigler [1961]. As the importance of information constraints
have been increasingly recognized,1 so an ever wider array of information gathering technologies have been modelled. For example, McCall [1970] considered the case of sequential
∗

We thank Roland Benabou, Dirk Bergemann, Laurens Cherchye, Bram De Rock, Thomas Demuynck,
Federico Echenique, Andrew Ellis, Paola Manzini, Marco Mariotti, Daniel Martin, Filip Matejka, Alisdair
McKay, Stephen Morris, Pietro Ortoleva, Daphna Shohamy, Laura Veldkamp and Michael Woodford for
their constructive contributions. We also thank Samuel Brown, Severine Toussaert and Isabel Trevino for
their exceptional research assistance. An early version was circulated under the title “Rational Inattention
and State Dependent Stochastic Choice”.
†
Center for Experimental Social Science and Department of Economics, New York University. Email:
andrew.caplin@nyu.edu
‡
Department of Economics, Brown University. Email: mark_dean@brown.edu
1
For example shoppers may buy unnecessarily expensive products due to their failure to notice whether
or not sales tax is included in stated prices (Chetty et al. [2009]), while purchasers limit their attention to a
relatively small number of websites when buying over the internet (Santos et al. [2012]).

1

search; Verrecchia [1982] the choice of variance of a normal signal; and Sims [2003] an unrestricted choice of information structure with costs based on Shannon entropy. Many other
alternatives have been implemented in the literature.2
The information costs faced by a decision maker are rarely known to an outside observer.
This makes it of interest to test a general model of optimal information acquisition that
makes minimal assumptions about these costs. In this paper we introduce precise behavioral tests covering all standard theories of costly information acquisition, including rational
inattention theory as well as static and sequential signal acquisition theories.3 We establish
limits on what choice data can reveal about the costs of information. In an experimental implementation, we confirm that attentional adjustments are well-modeled as rationally
responsive to costs.
The purpose of our tests is to introduce non-parametric methods into the theory of information acquisition. Just as unobservability of preferences motivated the revealed preference
approach to utility (Samuelson [1938], Afriat [1967]), so the unobservability of information
acquisition costs motivates our approach. In the revealed preference spirit, our tests can be
readily applied in practice, and fully characterize optimal behavior for an arbitrary finite
data set.
Enriched choice data plays a central role in our tests. We utilize “state dependent”
stochastic choice data, which describes the decision maker’s probability of choosing each
available action in each state of the world.4 While only recently introduced into revealed
preference analysis (see Caplin and Martin [2014], henceforth CM14), it is standard in the
econometric analysis of discrete choice. For example, Chetty et al. [2009] study how choice
distributions are impacted by an observable state: the inclusion or exclusion of sales taxes
in stated prices. They find evidence of incomplete state awareness among buyers.5
Our key theoretical insight is that the decision maker’s attention strategy is largely revealed by their state dependent stochastic choice data. Using this observation, we describe
two conditions that render such data consistent with optimal acquisition of costly information. A “no improving action switch” (NIAS) condition ensures that choices are optimal
given what was learned about the state of the world, as in CM14. A “no improving attention
cycles” (NIAC) condition ensures that total utility cannot be raised by reassigning atten2

See, for example Reis [2006], van Nieuwerburgh and Veldkamp [2009] and Woodford [2012].
That our conditions characterize so many distinct microeconomic models is striking. It echoes the finding
of Manzini and Mariotti [2007] that identical conditions (“weak WARP”) capture the behavioral content of
many apparently distinct procedural models of boundedly rational behavior.
4
The key role of data enrichment has arisen previously in our use of “choice process” data to test theories
of sequential search (Caplin et al. [2011]).
5
The data set has a long history in psychometric research. It is essential to the formulation of the
Weber-Fechner laws on limits to perceptual discrimination (see Murray [1993]).
3

2

tion strategies across decision problems. Our main result is that these conditions, clearly
necessary for rationality, are also suﬃcient. Any data set in which they are satisfied can be
rationalized with a standard model of costly information acquisition.
We provide limits on the identification of attention costs from choice data, providing
bounds on the relative costs of all chosen attention strategies. We show also that the assumptions that more informative strategies (in the sense of Blackwell) are more costly, that
mixed strategies are feasible, and that inattention is costless put no additional restrictions
on the data.6
We implement our tests by experimentally eliciting state dependent stochastic choice
data. We test for three important forms of optimal information gathering behavior: responsiveness on the extensive margin; responsiveness on the intensive margin; and the presence of
spillover eﬀects. Our experiments demonstrate all three forms of behavior: when incentives
are increased, more is learned; when the relative importance of diﬀerentiating between diﬀerent states changes, subjects focus their attention appropriately; and the introduction of an
action that increases the returns to attention has spillover eﬀects on the choice probabilities
of previously available alternatives. Our data indicates that subjects actively modify their
attention in response to incentives in line with the optimizing model. Alternative theories
in which learning is unresponsive to attentional incentives are clearly rejected.
Our paper is related to a recent literature analyzing specific models of costly information
acquisition. Matejka and McKay [2011] study the implications of rational inattention with
Shannon entropy costs for state dependent stochastic choice data, while Ellis [2012] uses
deterministic state dependent choice to study a model in which a decision maker has a
fixed set of information partitions to choose from. de Oliveira et al. [2013] consider a more
general model of attention using choice over menus as their data. Unlike these papers, our
revealed preference approach provides necessary and suﬃcient conditions in any arbitrary
finite data set. Such approaches have recently been applied to various behavioral models of
individual and group decision making (Crawford [2010], Cherchye et al. [2011], de Clippel
and Rozen [2012]). Our work also fits into a growing literature aimed at identifying the
behavioral implications of models in which the information state of the decision maker is
unknown (Manzini and Mariotti [2012], Masatlioglu et al. [2012], Dillenberger et al. [2012],
Bergemann and Morris [2013b]).
Section 2 introduces the basic model of costly information acquisition. Section 3 provides
our characterization. Section 4 establishes limits on identification of attention costs. Section
5 provides model extensions. Section 6 details our experimental design, with results in section
6

This result is in the spirit of Afriat [1967], and pinpoints limits on the identifiability of cost functions in
behavioral data.

3

7. Section 8 relates our work to the broader literature. Section 9 concludes.

2
2.1

A Model of Costly Information Acquisition
Actions, Prizes, States, and Beliefs

A decision maker (DM) is initially unaware of the consequences attached to available options.
With attention, this uncertainty can be reduced. To formalize, we consider choice between
actions the payoﬀ of which depend on the realization of a state  from a set Ω of cardinality
 Prior beliefs are captured by  ∈ Γ = ∆(Ω). An action  is a mapping from Ω to a prize
space . We use  to denote the grand set of actions.
Our goal is to identify conditions under which choice data can be rationalized as resulting
from maximization of net utility by a Bayesian expected utility maximizer with costs of
acquiring information. For the next two sections we focus squarely on costs of information
acquisition. Hence we treat as known to the outside observer or econometrician both prior
beliefs  ∈ Γ and the expected utility function  :  −→ R, with  denoting the expected
utility of action  in state . In section 5.2 we allow for unknown utility and for an unknown
prior.

2.2

State Dependent Stochastic Choice Data

Let  ⊂ F ≡ { ∈ 2 ∅| is finite} be a finite set of decision problems (defined by the set
of available alternatives) with generic element  ∈ . The idealized data set that we use
to test the model of costly information acquisition is state dependent stochastic choice data.
This describes for each decision problem the likelihood of choosing each available action
in each state of the world. We define Q to be the set of mappings from Ω to probability
distributions over  with finite support. Given  ∈ Q, we let  denote the probability
of the DM choosing action  in state  and denote as  () ⊂  the set of actions chosen
with non-zero probability in some state of the world under state dependent stochastic choice
function . For  ∈ F, we define Q as all data sets with  () ⊂ .
Definition 1 A state dependent stochastic choice data set ( ) comprises a finite set of
decision problems  ⊂ F and a function  :  → Q, with () ∈ Q .

2.3

Attention Strategies and Attention Costs

The DM chooses an attention strategy for each given decision problem that defines the eﬀort
that they put into learning the state of the world. Initially we assume that information
4

processing is static (the extension to sequential choice of information is considered in section
5.1). We define an attention strategy as a stochastic mapping from states of the world
to subjective signals. Since we are characterizing expected utility maximizers, we identify
each subjective signal with its associated posterior beliefs  ∈ Γ, which is equivalent to the
subjective information state of the DM following the receipt of that signal. Having selected
an attention strategy, the DM can condition choice of action only on these signals. Feasible
attention strategies satisfy Bayes’ rule.
Definition 2 Given prior  ∈ Γ, feasible attention strategies Π() comprise all mappings
 : Ω→∆(Γ) that have finite support Γ() ⊂ Γ and that satisfy Bayes’ law, so that for all
 ∈ Ω and  ∈ Γ(),
  ()
,
  = X
   ()
∈Ω

where   () ≡ ()({}) is the probability of posterior beliefs  given state . Let Π̃ ≡
∪ Π() denote all attention strategies.
An attention cost function maps attention strategies to the corresponding level of disutility.
Definition 3 Given prior  ∈ Γ, an attention cost function is a mapping  : Π() → R̄
with () ∈ R for some  ∈ Π(). We let K denote the class of such functions.
Note that we put no restrictions on the cost function , meaning that our model nests all
standard models of static information acquisition, including a ‘rational inattention’ model in
which  would equal the Shannon mutual information between prior and posterior information states (e.g. Sims [2003]). We allow costs to be infinite to nest constraints on information
acquisition - as when a hard limit is imposed on the mutual information between prior and
posteriors (Sims [2003]), or when the DM can choose only certain partitional information
structures (Ellis [2012]) or normal signals (Verrecchia [1982]). To avoid triviality we assume
that finite-cost feasible attention strategies exists.
In sections 2 through 4 we impose no cross-prior restrictions on behavior. Until that
point it simplifies notation to specify arbitrary  ∈ Γ, to limit the state space to satisfy
  0, and to let Π identify feasible attention strategies given this prior.

2.4

Costly Information Representations

We model a DM who chooses an attention strategy to maximize gross payoﬀs net of information costs. The gross payoﬀ associated with attention strategy  ∈ Π in decision problem
5

 ∈ F is calculated assuming that actions are chosen optimally in each posterior state. Let
 : F×Π → R denote the gross payoﬀ of using a particular attention strategy in a particular
decision problem:
"
#
X X
   () ( );
( ) =


∈Γ()

P

where ( ) = max∈     . We make the standard assumption that attention costs
are additively separable from the prize-based utility derived from the actions taken. We
let Π̂ : K × F → Π map cost functions and decision problems into rationally inattentive
strategies. These are the strategies (if any) that maximize gross payoﬀ net of attention
costs,
Π̂( ) = arg max {( ) − ()} 
∈Π

The choice of the DM conditional on the signal received is captured by the function
 : Γ() → ∆(), with   () the probability of action  ∈  given  ∈ Γ(). An attention
strategy is consistent with observed state dependent stochastic choice data in some decision
problem if optimal choice contingent on the signal received could produce such a pattern of
data.
Definition 4 For decision problem , attention strategy  ∈ Π is consistent with  ∈ Q
if there exists  : Γ() → ∆() such that:
1. Final choices are optimal:
  ()  0 =⇒

X


   ≥

X


   all  ∈ 

2. The attention and choice functions match the data:
 =

X

  ()  ()

∈Γ()

A data set admits a costly information representation if there exists an information
cost function such that behavior in each decision problem is consistent with an optimal
information strategy given those costs.
Definition 5 Data set ( ) has a costly information representation (̃ ̃) if there
exists ̃ ∈ K and ̃ :  → Π such that, for all  ∈ , ̃() ≡ ̃  is consistent with ()
and satisfies ̃ ∈ Π̂(̃ ).
6

3

Characterization

We establish two conditions as necessary and suﬃcient for ( ) to have a costly information
acquisition representation. The first ensures optimality of final choice given an attention
strategy and applies to each decision problem separately. The second ensures optimality of
the attention strategy and applies to the collection of decision problems.

3.1

Minimal Attention Strategies

The key to our approach is the observation that, if a DM is behaving optimally, then one
can learn much about their attention strategy from state dependent stochastic choice data.
In particular, one can identify the average posterior beliefs that a DM must have had when
choosing each act.
Definition 6 Given  ∈ Q and  ∈  () define the revealed posterior  () ∈ Γ,
 
 () = X  
 


all  ∈ Ω.
The revealed posterior  () is the probability of state of the world  conditional on
action  being chosen given state dependent stochastic choice data . If the DM chooses
each action in at most one subjective information state then the revealed posteriors are the
same as their true posteriors when  was chosen. If they choose the same action in more
than one subjective state then the revealed posterior is the corresponding weighted average.
We can use the revealed posteriors to construct a “revealed” attention strategy for each
decision problem. We do so by assuming that any action is chosen in at most one subjective
state. Under this assumption we can identify the resulting attention strategy directly from
the data. The probability of posterior  in state of the world  is calculated by adding up
probabilities of choosing all actions that have that revealed posterior.
Definition 7 Given  ∈ Q,  ∈ Ω, and  =  () for some  ∈  (), define the minimal
attention strategy ̄  ∈ Π to satisfy,
X

̄  () =

{∈ ()|  ()=}

7

 

While the minimal attention strategy may not be the same as the DM’s true attention
strategy, a key observation is that it must be weakly less informative (in the sense of statistical
suﬃciency) than any attention strategy consistent with the data. Intuitively, this means
that the minimal attention strategy can be obtained by “adding noise” to the true attention
strategy.
Definition 8 Attention strategy  ∈ Π is suﬃcient for attention strategy  ∈ Π (equivaP
lently  is a garbling of ) if there exists a |Γ()|×|Γ()| matrix  ≥ 0 with   ∈Γ()  = 1
all  and such that, for all   ∈ Γ() and  ∈ Ω,
 (  ) =

X

  ( )

  ∈Γ()

Lemma 1 establishes that any consistent attention strategy must be suﬃcient for the
minimal attention strategy.
Lemma 1 If  ∈ Π is consistent with  ∈ Q, then it is suﬃcient for ̄  
Proof. All proofs can be found in online appendix 1.
Blackwell’s theorem establishes the equivalence of the statistical notion of suﬃciency and
the economic notion “more valuable than”. If attention strategy  is suﬃcient for strategy
, then it yields (weakly) higher gross payoﬀs in any decision problem. This result plays a
significant role in our characterization.
Remark 1 Given decision problem  ∈ F and   ∈ Π with  suﬃcient for ,
( ) ≥ ( )

3.2

No Improving Actions Switches

Our first condition ensures that the DM’s choices are optimal given posterior beliefs. It specifies that, when one identifies in the data the revealed posterior associated with any chosen
action, this action must be optimal at that posterior. CM14 show that this condition characterizes Bayesian behavior regardless of the rationality of attentional choice. The strategic
analog is derived by Bergemann and Morris [2013b] in characterizing Bayesian correlated
equilibria.
Condition D1 (No Improving Action Switches) Data set ( ) satisfies NIAS if, for
every  ∈  and  ∈  (()),
X


 (())  ≥
8

X


 (())  

all  ∈ .

3.3

No Improving Attention Cycles

Our second condition restricts choice of attention strategy across decision problems. Essentially, it cannot be the case that total gross utility can be increased by reassigning attention strategies across decision problems. To illustrate, consider a decision problem with two
equiprobable states and two available actions,  = { }, and with the state dependent
payoﬀs,
(1  2 ) = (10 0); (1  2 ) = (0 20)
Suppose now that the observed choice behavior is,
1 () = 1 − 2 () =

2
= 1 − 1 () = 2 ()
3

Now consider a second decision problem diﬀering only in that the action set is
 = { }, with (1  2 ) = (0 10), with corresponding data,
1 () = 1 − 2 () =

3
= 1 − 1 () = 2 ()
4

The specified data looks problematic with respect to optimal information acquisition.
Action set  provides greater reward for discriminating between states, yet the DM is more
discerning under action set . To crystallize the resulting problem, note that, for behavior
to be consistent with costly information acquisition for some cost function  it must be the
case that,
(  ) − (  ) ≥ (   ) − (  );

(   ) − (  ) ≥ (   ) − (  )

While we do not observe attention strategies directly, it is immediate that (   ) = ( ̄  )
for  ∈ { }. Furthermore, as  is suﬃcient for ̄  , Blackwell’s theorem tells us that
(   ) ≥ ( ̄  ) for  ∈ { } (see Remark 1) Thus we can insert the minimal attention
strategies in the calculation of gross benefits to conclude,
( ̄  ) − ( ̄  ) ≥ (̄  ) − (̄  ) ≥ ( ̄  ) − ( ̄  )
For there to exist a cost function that can rationalize this data, the left hand side of
9

this inequality must be no lower than the right hand side. Using this condition we conclude
that, for this data to be rationalizable, gross benefit must be maximized by the assignment
of minimal attention strategies to decision problems observed in the data,
( ̄ ) + ( ̄  ) ≥ ( ̄  ) + ( ̄  )

(1)

In the above example ( ̄  ) + ( ̄  ) = 17 12 , while ( ̄  ) + ( ̄  ) = 17 11
. Thus,
12
there is no cost function that can be used to rationalize this data. The NIAC condition
ensures precisely that no such cycles of attention strategy raise gross utility.
Condition D2 (No Improving Attention Cycles) Data set ( ) satisfies NIAC if,
for any set of decision problems 1  2    ∈  with  = 1 ,
−1
X
=1



(  ̄ ) ≥

−1
X

(  ̄ +1 )

=1

where ̄  = ̄( ) .
The NIAC condition is analogous to the cyclical monotonicity condition discussed in
Rockafellar [1970], and has been used in other recent work examining the revealed preference
implications of behavioral models (see for example Crawford [2010]).

3.4

Characterization

Our first main result is that, while clearly necessary conditions, NIAC and NIAS together
are also suﬃcient for ( ) to have a costly information acquisition representation. We
establish this by applying the results of Koopmans and Beckmann [1957] concerning the
linear allocation problem. The cost function that we introduce is based on the shadow prices
that decentralize the optimal allocation in their model (see also Rochet [1987]).
Theorem 1 Data set ( ) has a costly information acquisition representation if and only
if it satisfies NIAS and NIAC.

4

Identification

In this section we establish limits on identification of the cost function. We open by considering three natural restrictions on attention cost functions: weak monotonicity with respect to
suﬃciency; feasibility of mixed strategies; and costless inattention. In principle these restrictions might tighten requirements for rationalizability of stochastic choice data, since they
10

constrain costs of unchosen strategies. Theorem 2 establishes that this is not the case: if
state dependent stochastic choice is rationalizable, then it is rationalizable by a cost function
that satisfies these three conditions. Following this we provide limits on the recoverability of
the cost function by characterizing all weakly monotonic cost functions that can rationalize
a given data set.

4.1

Weak Monotonicity

A partial ranking of the informativeness of attention strategies is provided by the notion of
statistical suﬃciency (see definition 8). A natural condition for an attention cost function
is that more information is (weakly) more costly. Free disposal of information would imply
this property, as would a ranking based on Shannon mutual information.7
Condition K1  ∈ K satisfies weak monotonicity in information if, for any   ∈ Π
with  suﬃcient for ,
() ≥ ()

4.2

Mixture Feasibility

In addition to using pure attention strategies, it may be feasible for the DM to mix these
strategies using some randomizing device.
Definition 9 Given attention strategies   ∈ Π, and  ∈ [0 1], the mixture strategy
 ◦  + (1 − ) ◦  ≡  ∈ Π is defined by,
  () =  () + (1 − ) ()
all  ∈ Ω and  ∈ Γ() ∪ Γ().
The definition implies that the mixing is not of the posteriors themselves, but of the odds
of the given posteriors. To illustrate, consider again a case with two equiprobable states. Let
attention strategy  be equally likely to produce posteriors (3 7) and (7 3), with  equally
likely to produce posteriors (1 9) and (9 1). Then the mixture strategy 05◦  + 05 ◦  is
equally likely to produce all four posteriors.
7

While in many ways intuitively attractive, this assumption may not be universally valid. In a world
with discrete signals it may be very costly or even impossible to generate continous changes in information.
Moreover the DM may be restricted to some fixed set of signals in which case less informative structures
are essentially disallowed. It may not be possible to automatically and freely dispose of information once
learned.

11

A natural assumption is that DMs can choose to mix attention strategies and pay the
corresponding expected costs. They could flip a coin and choose strategy  if the coin comes
down heads and strategy  if it comes down tails. In expectation the cost of this strategy
would be half that of  and half that of . Allowing such mixtures puts an upper bound on
the cost of the strategy 05◦  + 05 ◦ . However, it does not pin down the cost precisely,
since there may be a more eﬃcient way of constructing the mixed attention strategy.
Condition K2 Mixture Feasibility: for any two strategies   ∈ Π and  ∈ (0 1), the
cost of the mixture strategy  = ◦  + (1 − ) ◦  ∈ Π satisfies,
 () ≤ () + (1 − )()

4.3

Normalization

It is typical in the applied literature to allow inattention at no cost, and otherwise to have
costs be non-negative. Given weak monotonicity, non-negativity of the entire function follows
immediately if one ensures that inattention is costless.
Condition K3 Define  ∈ Π as the strategy in which  () = 1 all  ∈ Ω. Attentional
cost function  ∈ K satisfies normalization if it is non-negative where real-valued,
with () = 0.

4.4

Theorem 2

Theorem 2 states that, whenever a costly information acquisition representation exists, one
also exists in which the cost function satisfies conditions K1 through K3. Whatever one
thinks of the above assumptions on intuitive grounds, even if any one or all of them are in
fact false, any data set that can be rationalized can equally be rationalized by a function
that satisfies them all.
Theorem 2 Data set ( ) satisfies NIAS and NIAC if and only if it has a costly information acquisition representation with conditions K1 to K3 satisfied.
This result has the flavor of the Afriat characterization of rationality of choice from budget
sets (Afriat [1967]), which states that choices can be rationalized by a non-satiated utility
function if and only if they can be rationalized by a non-satiated, continuous, monotone,
and concave utility function.
Not all restrictions on the form of the cost function can be so readily absorbed. For example, we cannot strengthen condition K1 to cover the case of strict monotonicity with respect
12

to suﬃciency. We show in online appendix 2 that there are data sets satisfying NIAS and
NIAC yet for which there exists no cost function that produces a costly information acquisition representation with a cost function that is strictly monotonic with the informativeness
of the information structure.

4.5

Recoverability

Theorem 1 tells us the conditions under which there exists an attentional cost function that
will rationalize the data. We now provide conditions that identify the set of all such cost
functions, in the spirit of Varian [1984] and Cherchye et al. [2011]. We restrict ourselves
to cost functions that satisfy weak monotonicity, so that we can treat minimal attention
strategies as optimal. The key observation is that the choice of ̄  in decision problem 
puts an upper bound on its cost relative to that of any other strategy  ∈ Π,
(̄  ) − () ≤ ( ̄  ) − ( )

(2)

This directly implies an upper and lower bound on the relative costs of any two revealed
attention strategies ̄  , ̄  for   ∈ .
( ̄  ) − ( ̄  ) ≤ (̄  ) − (̄  ) ≤ ( ̄  ) − ( ̄  )
An obvious corollary of theorem 1 is that a weakly monotonic attentional cost function
can rationalize a data set if and only it satisfies this inequality for every , ∈ , and the
costs of unchosen attention strategies are high enough to satisfy inequality 2.
This condition implies potentially tighter bounds on the relative cost of any two revealed
attention strategies. Consider the corresponding inequalities in string 1  ∈  with
1 =  and  = ,
(̄ 1 ) − (̄ 2 ) ≤ (1  ̄ 1 ) − (1  ̄ 2 );

(̄ 2 ) − (̄ 3 ) ≤ (2  ̄ 2 ) − (2  ̄ 3 );
..
.
(̄ −1 ) − (̄  ) ≤ (−1  ̄−1 ) − (−1  ̄  )
Summing these inequalities yields a bound on (̄  ) − (̄  ) This relative cost must obey

13

such bounds for all cycles, implying
(̄  ) − (̄  ) ≤

min

{1  ∈|1 = =}

−1
X
¤
£
(  ̄ ) − (  ̄ +1 ) ;

(3)

=1

Considering the reverse string 1  ∈  with 1 =  and  =  yields




(̄ ) − (̄ ) ≥

max

{1  ∈|1 = =}

−1
X
¤
£
(  ̄+1 ) − (  ̄  ) 

(4)

=1

Note also that if one considers cost functions for which inattention is free, the above
inequalities can be used to place absolute bounds on the level of costs. Moreover if one ever
sees a switch in attention strategy for decision problems that are “close together”, in that
available vectors of state dependent payoﬀs always fall within   0, then one can bound
cost diﬀerences to within . Hence, with a rich enough data set, arbitrarily tight bounds
can be placed on costs in models in which the data is generated by a finite set of possible
attention strategies.

5

Extensions

Sequential sampling has been the central focus in models of information acquisition since the
work of Wald [1947]. In this section we extend our results to a model of sequential attention,
assuming that only final choices are seen: evolution of learning before choice is not directly
observable. We also extend our results to allow for unobservability of the utility function
and of the prior. In both cases, NIAS and NIAC are unchanged in essentials.

5.1

Sequentially Rational Inattention

We fix a time interval within which a decision is to be made and divide it into  ≥ 1
sub-periods. In each such sub-period the DM must choose whether or not to collect more
information conditional on what has already been learned. In the former case they must
decide what additional information to collect. In the latter, information gathering finishes
and they must choose one of the available actions. The sequence of attention and action
choices is made to maximize the net undiscounted value of final prize utility less sequential
attention costs. Neither attentional inputs nor decision time are observed.
The DM at the start of period 0 is endowed with prior beliefs  ∈ Γ. We use the time
indexed sets  and  to define the DM’s deterministic stopping rule by identifying the
states in which they respectively continue to search and stop searching. If the DM stops
14

searching immediately then 0 = {} and 0 ⊂ 2Γ is empty. If not we define 0 = {}
and 0 ⊂ 2Γ as empty. In this case a first attention strategy  1 ∈ Π() is selected at the
start of period 1, with posterior  1 ∈ Γ( 1 ) realized instantly. The stopping rule in period
1 is defined by 1 ⊂ Γ( 1 ) which contains all the posteriors at which further information is
gathered, and 1 = Γ( 1 )1 the corresponding stopping set.
The process iterates from this point forward. We allow for history dependence by defining
the continuation set  for  ≥ 1 on sequences of posteriors   = (  1     ) ∈ Γ+1 . The
first time that  is empty identifies the maximal stopping time,  =  ≤  . In all earlier
periods, the DM picks a period  + 1 attention strategy,
 +1 :  → Π̃ with  +1 (  ) ∈ Π(  )
The ensuing continuation set and attention strategy are correspondingly defined:
©
ª
+1 ⊂  +1 ∈ Γ+2 |  ∈    +1 ∈ Γ(  (  )) 

with all other sequences of posteriors in +1 ⊂ Γ+2 . The above fully specifies a sequential
attention strategy. Given prior , we let Σ() be the set of such strategies, with generic
element  ∈ Σ().
Note that each strategy  ∈ Σ() induces a probability distribution over sequences of
posteriors. Define  0 =  0 = , and let  (  ) be the probability of   ∈ Γ+1 given strategy
, with  (  ) being the corresponding state dependent probability,
 (  ) =

X

  (  )



We turn to the evaluation of strategies  ∈ Σ(). We assume that choices are made
optimally given posteriors. Thus, when faced with decision problem , for each   ∈ 
for 0 ≤  ≤  , the decision maker will receive utility (   ), maximal expected utility at
the posterior relevant for action choice To count against reward utility are the attentional
costs which we assume to be independent of preferences over prize lotteries and additively
separable across periods.
Definition 10 Given  ∈ Γ, an admissible attention cost function  ∈ E specifies for each
 Π(  ).
 ≥ 0 cost (   ) ∈ R̄ on   = (  1     ) ∈ Γ+1 ∈  , with (   ) = ∞ for  ∈
The above covers all standard sequential models with additive attention costs. In fact
one can enrich the domain of the period attention cost functions to include all past attention

15

levels as well as the past posteriors without changing in any way the ensuing analysis.8 We
define a strategy  as sequentially rational for decision problem  if it solves the following
problem:

 ∈ arg max

∈Σ()


X
=0

⎡
⎣

X

  ∈

 (  )(   ) −

X

  ∈

⎤

 (  )(    +1 (  ))⎦ 

Where such optima exist, Σ̂ : E × F → Σ identifies all sequentially rationally inattentive
strategies.
Our goal is to identify all data sets ( ) that can be rationalized by some fixed  ∈ E
as consistent with sequentially optimal behavior in the face of costly attention. Given  ∈ F,
the definition of consistency of  ∈ Σ() with  ∈ Q is essentially unchanged: it requires
existence of a choice function  : Γ → ∆() such that final choices are optimal for all
1 ≤  ≤  and   ∈  , and that the attention and choice functions match the data,


=

 X
X

 (  )  (  )

=0   ∈

Definition 11 Data set ( ) has a sequential costly information (SCI) representation (̃ ̃) if there exists ̃ ∈ E and ̃ :  → Σ such that, for all  ∈ , ̃() is
consistent with () and satisfies ̃() ∈ Σ̂(̃ ).
The key result is that NIAS and NIAC remain necessary (as well as suﬃcient) for such
a representation despite the richer class of learning behaviors covered. We establish this in
the appendix as a corollary to theorem 1. Intuitively, time consistency reduces the dynamic
problem of sequential choice to a static problem of choice of strategy.
Corollary 1 Data set ( ) has an SCI representation if and only if it satisfies NIAS and
NIAC.

5.2

Unobservability of Prior and Utility Function

Returning to the case of static information acquisition, we now consider the observable
implications of optimal behavior when preferences and prior beliefs are unknown. As in
CM14, theorem 1 extends directly to cases in which the utility function  :  → R and the
prior are both unknown, provided the prior assigns strictly positive probability to all states,
8

While substantively enriching the model by allowing for tiredness resulting from past eﬀort etc., including
these eﬀects greatly complicates notation.

16

 ∈ Γ ≡ { ∈ Γ|  0 all }. To establish this we correspondingly amend key definitions.
We treat (  ) as unknowns and define:
() ( ) ≡

X

∈Γ()

"
X


Π̂( ) ( ) ≡ arg sup

∈Π()

#

   ()  ( );

ª
© ( )
( ) − () ;


P
with  ( ) = max∈     . We amend the definition of a costly information representation to avoid the conditions being satisfied by a constant utility function.
Definition 12 Data set ( ) has a costly information representation with unknown prior and utility function if there exists ̃ :  → R, ̃ ∈ Γ , ̃ ∈ K and
̃ :  → Π such that, for all  ∈ , ̃() ≡ ̃  is consistent with (), ̃  ∈ Π̂(̃̃) (̃ ),
and such that ∃ ∈ ,  ∈ ,  ∈ Γ with   ()  0, and  ∈  such that,
X

  ̃ 



X

  ̃ 



The conditions for existence of such a representation are the precise analog of the NIAS
and NIAC conditions, with the additional requirement of some strict inequality in the value
of acts.
Condition D3 (NIAS∗ ) Data set ( ) satisfies NIAS∗ with respect to  ∈ Γ and  :
 → R if, for every  ∈  and  ∈ ,
X


all  ∈ , where,

 ( ())  ≥

X

 ( ())  



 
 ( ) = X  
 


and there exists  ∈ ,  ∈  (()), and  ∈  such that,
X

 ( ())  



X

 ( ())  



Condition D4 (NIAC∗ ) Data set ( ) satisfies NIAC∗ with respect to  ∈ Γ and

17

 :  → R if, for any set of decision problems 1  2    ∈  with  = 1 ,
−1
X
=1

() (  ̄  ) ≥

−1
X

( ) (  ̄ +1 )

=1

where ̄  = ̄( ) .
The characterization is precisely as expected, as follows from a careful reading of the
original proof: hence this is treated as a corollary.
Corollary 2 Data set ( ) has a costly information representation with unknown prior
and utility function if and only if there exists ̃ :  → R and ̃ ∈ Γ with respect to which
( ) satisfies both NIAS∗ and NIAC∗ .
NIAS∗ and NIAC∗ therefore identify inequality constraints to which a solution must exist
if the data is to be rationalizable with a costly information representation. In the case in
which the prior is known but the utility function is not, these constraints are linear and
easy to check (see CM14 for the implications of NIAS∗ ). If the prior is also unknown, then
the conditions are non-linear, but still non-vacuous. CM14 provide an example of data
that is incompatible with NIAS∗ for any utility function and prior. The following example
demonstrates behavior that is commensurate with NIAS∗ but is not commensurate with
NIAC∗ for any non-degenerate utility function and prior.
Example 1 Let  = { }, Ω = {1 2}  = {  }  = { } with actions defined as
follows
State
Action 1 2
a

x

y

b

y x

c

x

x

We show now that data set 1 () = 2 () = 1, 1 () = 1 () = 2 () = 2 () =
0, 1 () = 2 () = 1 and 1 () = 2 () = 0 does not permit a costly information
representation with unknown prior and utility function.
Intuitively, the DM in the 3 action case (choice set ) perfectly identifies the state and
chooses the action that gives prize  rather than . Since indiﬀerence is not allowed, NIAS∗
requires ()   (). In the two action case (choice set ) the DM always chooses action
, whether it yields  or . The problem with this is that the availability in set  of an action
that yields the better prize without attention implies that the cost of being perfectly informed
18

must be zero, making it impossible to understand why the fully informative attention strategy
was not chosen when facing choice set . Technically, NIAC∗ fails since, with 2  0,
() ( ̄  ) + ( ) ( ̄  ) − () ( ̄  ) − () ( ̄  )
= () + [1  () + 2 ()] − () −  () = 2 ( () − ())  0

6

Experimental Design

6.1

Design

We introduce an experimental design that generates state dependent stochastic choice data
with which we test our conditions. Subjects are shown a screen with 100 balls that are either
red or blue. The state of the world is the number of red balls on the screen. Prior to seeing
the screen, subjects are informed of the probability distribution over states. They choose
among actions whose payoﬀs are state dependent. There is neither an external limit (such
as a time constraint) nor an extrinsic cost associated with understanding the state of the
world. Information constraints derive from agents’ unwillingness to trade cognitive eﬀort for
monetary reward.
A decision problem is defined by the set of available actions. A subject faces each decision
problem 50 times.9 We estimate state dependent stochastic choice functions at the individual
and aggregate level using the observed frequency of choosing each action in each state. In
any given experiment, the subject faces four diﬀerent problems. All occurrences of the same
problem are grouped, but the order of the problems is block-randomized. In estimating the
state dependent stochastic choice function we treat the 50 times that a subject faces the
same decision making environment as 50 independent repetitions of the same event.
The aim of our experiments is to generate environments in which subjects may actively
alter their attention in response to incentives. We focus on three such cases: changes to
the overall reward for attention which should lead to behavioral changes on the extensive
margin; the introduction of new actions to the choice set, which should generate spillover
eﬀects; and changes in the states between which it important to diﬀerentiate, which should
lead to behavioral changes on the intensive margin. These experiments provide a testing
ground for the NIAS and NIAC conditions, as well as allowing us to rule out models in
which attention is fixed.
9

To prevent subjects from learning to recognize patterns, we randomize the position of the balls. The
implicit assumption is that the perceptual cost of determining the state is the same for each possible configuration of balls.

19

Subjects were recruited from the New York University student population.10 Each subject
answered 200 questions as well as 1 practice question. At the end of each session, one question
was selected at random for payment, the result of which was added to the show up fee of
$10. Subjects took on average approximately 45 minutes to complete a session. Instructions
are included in online appendix 4.

6.2

Experiment 1: The Extensive Margin

Experiment 1 tests whether subjects increase overall attentional eﬀort as incentives increase.
It comprises four decision problems with two equally likely states: in state 1 there are 49 red
balls and in state 2 there are 51. In each decision problem there are two actions available
{   } with  indexing the decision problem. In each case,  is superior in state 1 while 
is superior in state 2. Across decision problems the reward for making the correct choice in
each state varies.11 Table 1 describes the available actions in the four decision problems in
this experiment (payoﬀs are in US$).
Table 1: Experiment 1

Table 2: Experiment 2

Payoﬀs

Payoﬀs

DP

1

2

1

2

1
2
3
4

2

0

0

2

10

0

0

10

20

0

0

20

30

0

0

30

DP

1

2

1

2

1

2

5
6
7
9

23

23

21

25

n/a

n/a

23

23

21

25

30

10

23

23

21

25

35

5

23

23

21

25

40

0

Experiment 1 allows us to diﬀerentiate between models in which attention responds to
incentives and those in which it does not. While more typical in psychology (for example
signal detection theory (SDT) - Green and Swets [1966]), fixed information models have
attracted recent attention in the economics literature (e.g. Lu [2013]). SDT is clearly a
special case of our model, and so implies both NIAC and NIAS. However the same signal
structure must rationalize behavior in all decision problems. If attention does not change
as a function of incentives, neither should choice behavior vary across the decision problems
in this experiment, as the optimal action in each posterior state is independent of the
10

46 subjects took part in experiment 1, 45 in experiment 2, and 24 in experiment 3. Each subject took
part in only one experiment.
11
Note that these could be recorded as state dependent dollar prizes rather than direct utilities. Allowing
for risk aversion rather than risk neutrality adds more notational complexity than warranted since results
are unchanged in essentials.

20

precise value of 1 and 2 , as long as the two are equal.12 Increasing attention in response
to incentives also rules out models in which there is a hard constraint to the amount of
information processing instead of a marginal cost (e.g. Sims [2003]).

6.3

Experiment 2: Spillover Eﬀects

Experiment 2 is designed to test whether the introduction of an “attention-inducing” action
can spill over to increase the probability of choosing a previously available alternative. A
theoretical example of this form is introduced in Matejka and McKay [2011] and described
in table 2. It consists of two equally likely states (49 and 51 red balls). Decision problem 5
consists of two actions,  (which pays the same amount in both states) and  (which pays
slightly more in state 2 and slightly less in state 1). Decision problems 6-8 add a further
action , which pays significantly more in state 1 and significantly less in state 2.
When action  and  are available there is little incentive to gather information, meaning
that subjects may choose to remain uninformed and choose  However, with  available also,
it becomes more important to learn the true state, as  provides a high reward in state 1 but
a low reward in state 2 - increasingly so for later decision problems. A rationally inattentive
agent may therefore select a more informative attention strategy. If this learning suggests
to the DM that state 2 is very likely, then it is optimal to choose action .
This experiment allows us to diﬀerentiate between costly information processing and
random utility models (RUMs) (McFadden [1974], Gul and Pesendorfer [2006]) which do not
allow for flexible attention. RUMs take as given a probability measure over some family of
utility functions. Prior to making a choice, one utility function gets drawn from this set
according to the specified measure. The DM then chooses in order to maximize this utility
function.13
A RUM could potentially explain an increase in accuracy as incentives increase in experiment 1, as this increases the value diﬀerence between the two options. However, a general
property of RUMs is monotonicity. Addition of a new action to the set of available choices
cannot increase the probability that one of the pre-existing options will be chosen (Gul and
Pesendorfer [2006], Luce and Suppes [1965]).
Monotonicity Axiom Given  ∈ F,  ∈ ,  ∈  \ and  ∈ Ω,
 () ≥  ( ∪ ) 
12

Assuming that the tie-breaking rule for the case of  1 = 05 also does not change as a function of .
In the case of choice over lotteries, the family of utility functions can be over the lotteries themselves or,
following Gul and Pesendorfer [2006], over the underlying prize space, with the utility of a lottery equal to
its expectation according to the selected utility function.
13

21

Monotonicity is violated by a model of costly inattention that exhibits information
spillovers of the type described above: the introduction of action  increases the probability
of choosing action  in state 2.

6.4

Experiment 3: The Intensive Margin
Table 3: Experiment 3
Payoﬀs
DP

1

2

3

4

1

2

3

4

9
10
11
12

1

0

10

0

0

1

0

10

10

0

1

0

0

10

0

1

1

0

1

0

0

1

0

1

10

0

10

0

0

10

0

10

In experiment 3 we vary the states in which information is valuable and measure the
extent to which subjects focus their attention accordingly. All decision problems in this
experiment involve four equally likely states comprising two identifiable groupings. States
1 and 2 are perceptually hard to distinguish from one another, being defined respectively
by 29 and 31 red balls. States 3 and 4 are also hard to distinguish from another, being
defined respectively by 69 and 71 red balls. There are four decision problems with two
possible actions, still labelled  and . The decision problems diﬀer according to whether it
is important to diﬀerentiate between states 1 and 2 (problem 9), states 3 and 4 (problem
10), neither (problem 11), or both (problem 12), as described in table 2.

7
7.1

Results
Attention is Limited and Flexible

Before implementing the NIAS and NIAC tests, we provide evidence that subjects are neither
fully attentive nor completely inattentive. We also confirm the presence of the attentional
flexibility that SDT and standard RUM models rule out.
The first point to observe is that the experiments produce choice data that is both stochastic and state dependent. Subjects gather some information prior to choice, but this
information is incomplete. Using aggregate data from the simple two action cases of experiments 1 and 3 (in which there is a clear correct choice in each state), subjects made
“mistakes”, choosing the inferior action on 32% of all trials. In all three experiments, choice
behavior is significantly diﬀerent across states (Fisher’s exact test,   00001). For example,

22

in experiment 1, averaging across all 4 decision problems,  was chosen 75% of the time in
state 1 and 38% of the time in state 2. These patterns hold true at the individual level. For
example, of the 46 subjects in experiment 1, 15% made mistakes in less than 10% of questions, while 76% had choice behavior that was significantly diﬀerent between the two states
at the 10% level. These results suggest that our subjects are absorbing some information
about the state of the world, but are not fully informed when they make their choices.
Our data also rules out the fixed-signal SDT model which does not allow subjects to
make better decisions as incentives increase in the symmetric case. As shown in figure 1b
below, our aggregate data clearly exhibits such a change, with higher proportions of correct
choices at higher incentive levels (rising from 62% in decision problem 1 to 77% in problem
4, significant at the 0.1% level while clustering at the individual). At the individual level,
54% of subjects exhibit significant changes in choice probabilities between decision problems
at the 10% level.14
Experiment 2 provides evidence against RUMs with fixed information structures. Table
4 shows that the 44 subjects who took part in the experiment demonstrate clear violations
of monotonicity. The introduction of action  increases the probability of choosing action 
in state 2 from 23% in DP 5 to 39% in DP 8. Across all decision problems, the introduction
of act  increases the choice of  in state 2 by an average of 12pp, significant at the 1% level.
At the individual level, 51% of subjects show a significant violation of monotonicity of the
type predicted by costly information acquisition theory at the 10% level.
Table 4
DP 1 () 2 ()
5
17%
23%
6
15%
31%
7
12%
33%
8
13%
39%

7.2

NIAS and NIAC: Experiment 1

In the two state/two action set up of experiment 1, NIAS implies the existence of a cutoﬀ
posterior probability of state 1 that determines the optimal act. For posterior beliefs above
0.5, action  is optimal, while for lower posteriors, action  is optimal. This cutoﬀ is shown
in figure 1a together with the estimated posteriors associated with the choice of action 
14
All reported standard errors and statistical tests carried out using OLS regression of the choice of act on
each trial on dummies associated with each decision problem. For aggregate data we control for clustering
at the subject level.

23

and action  at the aggregate level. This figure demonstrates that NIAS is satisfied in the
aggregate data. At the individual level, for only 1 subject is there a statistically significant
violation of NIAS (i.e. the estimated posterior is significantly lower than 0.5 when  is chosen
or significantly higher than 0.5 when  is chosen at the 10% level). Moreover, as figure 2a
shows, monetary losses due to NIAS violations are small.15 As a benchmark, these losses are
compared to those that would have been observed from a population of subjects choosing at
random.16 The observed distribution is significantly diﬀerent from the simulated distribution
at the 0.01% level (Kolmogorov-Smirnov test).

Figure 1a - NIAS Experiment 1

Figure 1b - NIAC Experiment 1

The NIAC condition in experiment 1 relates the change in incentives between decision
problems to the change in   , the probability that the correct decision is taken in state
 = 1 2 (action  in state 1, action  in state 2). For two state/two action problems of this
type, NIAC implies the condition,
∆ 1 ∆(1 − 1 ) + ∆ 2 ∆(2 − 2 ) ≥ 0,

(5)

where ∆ indicates the change in  between two decision problems. In experiment 1, equation
5 implies only that  1 +  2 , the total probability of choosing the correct action, should be
monotonic in rewards. Figure 1b shows that indeed the proportion of correct responses rises
from 62% in decision problem 1 to 77% in problem 4. Diﬀerences between all pairs of decision
problems are significant at the 1% level, apart from between problem 2 and 3, for which the
diﬀerence is not significant.
At the individual level 83% of subjects show no significant violation of the NIAC con15

Treating point estimates as each subject’s true posterior beliefs
The use of random benchmarks has been discussed by, for example, Beatty and Crawford [2011]. The
precise procedure used to construct the random behavior is as follows: for each decision problem and for
each state, a random number is drawn for each available action. The probability of choosing each action
from that state is then calculated as the value of the random number associated with that action divided by
the sum of all random numbers.
16

24

dition. Losses resulting from NIAC violations at the individual level are small, as shown in
figure 2b. This figure plots the distribution of the maximal surplus possible by reassigning
attention strategies to decision problems minus the surplus generated by the observed assignment for each individual.17 The NIAC condition demands this number be zero. As a
comparator, we show the distribution obtained from random choice. Again, the observed
distribution is significantly diﬀerent from the simulated distribution at the 0.01% level.

Fig 2a: NIAS losses Experiment 1 Fig 2b: NIAC losses Experiment 1

7.3

NIAS and NIAC: Experiment 2

For experiment 2, NIAS defines regions of acceptable posteriors for the choice of each action
in each decision problem. Table 5 describes these regions, and the aggregate posteriors
observed in the data.
Table 5: NIAS conditions for experiment 2
DP
5
6
7
8


[0 50%]
[0 50%]
[0 50%]
[0 50%]

Range  1

[50% 100%]
[50% 65%]
[50% 60%]
[50% 575%]

Aggregate

 1  1  1
n/a
43 52
[65% 100%]
32 50 85
[60% 100%]
27 51 82
[575% 100%] 25 49 88

The aggregate data shows no significant violations of NIAS. At the individual level 91% of
subjects show no significant violations of NIAS, and the cost of the resulting violations is
small (Figure s1 in online appendix 3).
Applying bilateral NIAC to experiment 2 implies the following ranking on 1 ()−2 ()18 ,
81 (8 ) − 82 (8 ) ≥ 71 (7 ) − 72 (7 ) ≥ 61 (6 ) − 62 (6 )
17
18

The actual surplus of a subject’s attention strategy is calculated assuming no violations of NIAS.
If posterior beliefs when  is chosen in decision problem 5 made it preferable to choose  (if available),

25

In the aggregate the values of 1 () − 2 () are 29%, 18% and 18% for decision problem 8,
7, and 6 respectively. DP 8 is significantly diﬀerent from DP 7 and DP 6, though DP 6 and
DP 7 are not significantly diﬀerent from each other. At the individual level, 65% of subjects
show no significant violations of NIAC, and again losses are small (figure s2 in the online
appendix).

7.4

NIAS and NIAC: Experiment 3

The NIAS conditions for each decision problem in experiment 3 are,
1 ( 1 −  2 ) + 3 ( 3 −  4 ) ≥ 0
Table s2 in the supplemental material shows that this condition holds at the aggregate level.
At the individual level, 92% of subjects show no significant violations of NIAS and, as shown
in figure s1 in the online appendix, the losses amongst those that do not are again small.
With regard to the NIAC condition, the equivalent of condition 5 implies that subjects
should make the right choice in a given state more often when the value of doing so is high.19
More specifically, NIAC implies six inequalities based on binary comparisons of the 4 decision
problems. Table 6 shows these inequalities, the average value of the left hand and right hand
side variables in the aggregate data, and the probability associated with the test that these
two are equal.
Table 6: NIAC conditions for experiment 3
Condition
10
 4 + 91 + 92

10
9
9
10
 10
1 + 2 + 3 + 4 ≥  3 +
11
 93 + 94 ≥  11
3 + 4
11
10
11
 10
1 + 2 ≥  1 + 2
9
12
9
 12
1 + 2 ≥  1 + 2
10
12
10
 12
3 + 4 ≥  3 + 4
12
11
12
12
11
11
11
 12
1 +  2 + 3 + 4 ≥  1 + 2 + 3 + 4

LHS

RHS

P

72.8

64.9

0.01

68.2

63.3

0.38

77.3

66.9

0.02

74.8

63.7

0.02

69.1

66.3

0.33

72.0

65.1

0.10

we additionally have the restriction,
61 () − 62 () ≥ 51 () − 2 ()
However this is not the case is our aggregate data.
19
The precise condition is
∆ 1 ∆(1 − 1 ) + ∆ 3 ∆(3 − 3 ) + ∆ 2 ∆(2 − 2 ) + ∆ 4 ∆(4 − 4 ) ≥ 0

26

In every case the inequality is satisfied by the point estimates in the aggregate data. In three
of the cases the diﬀerences are statistically significant at the 5% level. At the individual
level, 79% of subjects exhibit no significant failures of NIAC and, as table s2 in the appendix
shows, the resulting losses are small. Overall, 75% of subjects exhibit no significant violation
of either NIAS or NIAC.

8

Existing Literature

Many approaches have been taken to modelling costs and constraints on information acquisition in economic applications, including sequential search (McCall [1970]) selection of the
variance of a normal signal (e.g. Verrecchia [1982]), and the binary choice to either be fully
informed or not (Reis [2006]). More recently, Sims [2003] introduced the concept of rational
inattention, in which the decision maker is free to choose any attention strategy they wish,
with costs based on the Shannon mutual information between prior and posterior beliefs.
Our approach allows for all of the above costs functions. The costs of feasible attention
strategies can be captured by , while the cost of inadmissible strategies can be set to infinity. The NIAS and NIAC conditions therefore provide a test of the entire class of costly
information acquisition models currently in use.
A recent wave of literature shares our goal of capturing the observable implications of
optimal acquisition of costly information. Matejka and McKay [2011] analyze the implications of rational inattention with Shannon mutual information costs for state dependent
stochastic choice data. Ellis [2012] works with state dependent deterministic choice data
to characterize choice among available information partitions. Caplin and Dean [2011] and
Caplin et al. [2011] consider the case of optimal sequential information search, using an
extended data set to derive behavioral restrictions. Again our work nests all these models
as special cases. Furthermore, unlike Matejka and McKay [2011] we provide necessary and
suﬃcient conditions for our model, while unlike Ellis [2012] we provide conditions that are
necessary and suﬃcient in finite data sets, making them applicable in practice.
A second decision theoretic approach to identifying optimal behavior in the face of costly
attention is to examine choice over menus, in which attention costs are characterized by an
aversion to contingent planning. de Oliveira et al. [2013] consider a model similar to ours in
this setting.
Our work forms part of a broader eﬀort to characterize choice behavior when the internal
information state of the agent is not directly observable. Caplin and Martin [2014] introduce the NIAS condition to characterize subjective rationality in a single decision problem.
Manzini and Mariotti [2012] consider a model in which the decision maker has a stochastic
27

consideration set, and makes choices to optimize preferences given what they have paid attention to. Masatlioglu et al. [2012] characterize “revealed attention”, using the identifying
assumption that removing an unattended item from the choice set does not aﬀect attention. Lu [2013] models the stochastic choice of a DM who has some unobserved (but fixed)
information structure. Dillenberger et al. [2012] consider a dynamic problem in which the
DM receives information in each period which is externally unobservable, characterizing the
resulting preference over menus. In a strategic setting, Bergemann and Morris [2013b] and
Bergemann and Morris [2013a] consider the related problem of identifying all patterns of
play that are consistent with some underlying information structure for all players.
In approach, our work is related to the recent resurgence in use of revealed preference
methods to understand the observable implications of models of behavior - examples include
sequential application of criteria (Manzini and Mariotti [2007]), habit formation (Crawford
[2010]), and collective consumption behavior (Cherchye et al. [2011]). See also de Clippel
and Rozen [2012] for the explicit application of some of these techniques to finite data.
In the psychology literature, theories to which we are close in spirit are signal detection
theory (Green and Swets [1966]) and categorization theory. A common feature is that the
DM receives a signal and must choose the optimal action at each resulting posterior. These
theories are connected to enormous experimental literatures in psychology that capture state
dependent stochastic choice data. Unlike our model, signal detection theory generally fixes
the attention strategy independent of incentives.
Despite the powerful psychological precedents, there is little experimental work on state
dependent stochastic choice data within economics. One related paper is Cheremukhin et al.
[2011], which uses a formulation similar to Matejka and McKay [2011] to estimate a rationally
inattentive model of lottery choice. However they do not analyze state dependence in the
resulting stochastic choice data.

9

Conclusions

We show that a general model of costly information acquisition is characterized by two simple
and readily testable restrictions on state dependent stochastic choice data. We identify what
can be recovered about information costs from such data. We provide experimental evidence
that subjects do indeed adjust the information that they collect on the basis of the incentives
inherent in their environment. Models that do not take this into account (such as signal
detection theory and random utility models) fail to capture important aspects of the data.
We do not believe rational allocation of attention necessarily describes behavior in all
circumstances. Indeed, one of the strengths of our approach is that it helps to identify when
28

and how standard assumptions on information acquisition need to be relaxed. In this vein,
we are currently exploring behavior of subjects facing important asymmetries in beliefs and
in the cost of mistakes. In contrast, when the model does apply, one can test additional
restrictions on the nature of costs. In this vein, we are currently exploring costs based on
Shannon mutual information and various generalizations (see Caplin and Dean [2013]).

References
S. N. Afriat. The Construction of Utility Functions from Expenditure Data. International
Economic Review, 8(1), 1967.
Timothy K. M. Beatty and Ian A. Crawford. How demanding is the revealed preference
approach to demand? American Economic Review, 101(6):2782—95, October 2011.
Dirk Bergemann and Stephen Morris. The comparison of information structures in games:
Bayes correlated equilibrium and individual suﬃciency. Cowles Foundation Discussion
Papers 1909, Cowles Foundation for Research in Economics, Yale University, September
2013.
Dirk Bergemann and Stephen Morris. Robust predictions in games with incomplete information. Econometrica, 81(4):1251—1308, 07 2013.
Andrew Caplin and Mark Dean. Search, choice, and revealed preference. Theoretical Economics, 6(1), January 2011.
Andrew Caplin and Mark Dean. Behavioral implications of rational inattention with shannon
entropy. NBER Working Papers 19318, National Bureau of Economic Research, Inc,
August 2013.
Andrew Caplin and Daniel Martin. A testable theory of imperfect perception. Economic
Journal, forthcoming, 2014.
Andrew Caplin, Mark Dean, and Daniel Martin. Search and satisficing. American Economic
Review, 101(7):2899—2922, December 2011.
Laurens Cherchye, Bram De Rock, and Frederic Vermeulen. The revealed preference approach to collective consumption behaviour: Testing and sharing rule recovery. Review of
Economic Studies, 78(1):176—198, 2011.
Anton Cheremukhin, Anna Popova, and Antonella Tutino. Experimental evidence on rational inattention. Technical report, 2011.
29

Raj Chetty, Adam Looney, and Kory Kroft. Salience and taxation: Theory and evidence.
American Economic Review, 99(4):1145—77, September 2009.
Ian Crawford. Habits revealed. Review of Economic Studies, 77(4):1382—1402, 2010.
Geoﬀroy de Clippel and Kareen Rozen. Bounded rationality and limited datasets: Testable
implications, identifiability, and out-of-sample prediction. Technical report, 2012.
Henrique de Oliveira, Tommaso Denti, Maximilian Mihm, and M. Kemal Ozbek. Rationally
inattentive preferences. Ssrn working paper, 2013.
David Dillenberger, Juan Sebastian Lleras, Philipp Sadowski, and Norio Takeoka. A theory
of subjective learning. Technical report, 2012.
Andrew Ellis. Foundations for optimal attention. Mimeo, Boston University, 2012.
D. M. Green and J. A. Swets. Signal detection theory and psychophysics. Wiley, New York,
1966.
Faruk Gul and Wolfgang Pesendorfer. Random Expected Utility. Econometrica, 74(1):121—
146, 2006.
Tjalling C. Koopmans and Martin Beckmann. Assignment problems and the location of
economic activities. Econometrica, 25(1):pp. 53—76, 1957.
Jay Lu. Random choice and private information. Mimeo, Princeton University, 2013.
R. Luce and P. Suppes. Handbook of Mathematical Psychology Vol. III, chapter Preference,
utility, and subjective probability. Wiley, New York, 1965.
Paola Manzini and Marco Mariotti. Sequentially Rationalizable Choice. American Economic
Review, pages 1824—1839, 2007.
Paola Manzini and Marco Mariotti. Stochastic choice and consideration sets. IZA Discussion
Papers 6905, Institute for the Study of Labor (IZA), October 2012.
Yusufcan Masatlioglu, Daisuke Nakajima, and Erkut Y. Ozbay. Revealed attention. American Economic Review, 102(5):2183—2205, August 2012.
Filip Matejka and Alisdair McKay. Rational inattention to discrete choices: A new foundation for the multinomial logit model. CERGE-EI Working Papers wp442, The Center for
Economic Research and Graduate Education - Economic Institute, Prague, June 2011.

30

John J McCall. Economics of information and job search. The Quarterly Journal of Economics, 84(1):113—26, February 1970.
Daniel McFadden. Frontiers in Econometrics, chapter Conditional logit analysis of qualitative choice behavior. Academic Press, New York, 1974.
David J. Murray. A perspective for viewing the history of psychophysics. Behavioral and
Brain Sciences, 16:115—137, 2 1993.
Ricardo Reis. Inattentive Consumers. Journal of Monetary Economics, 53(8):1761—1800,
2006.
Jean-Charles Rochet. A necessary and suﬃcient condition for rationalizability in a quasilinear context. Journal of Mathematical Economics, 16(2):191—200, April 1987.
R. Tyrrell Rockafellar. Convex Analysis. Princeton University Press, Princeton, 1970.
P. A. Samuelson. A note on the pure theory of consumer’s behaviour. Economica, 5(17):pp.
61—71, 1938.
Babur De Los Santos, Ali Hortacsu, and Matthijs R. Wildenbeest. Testing models of consumer search using data on web browsing and purchasing behavior. American Economic
Review, 102(6):2955—80, October 2012.
Christopher Sims. Implications of Rational Inattention. Journal of Monetary Economics,
50(3):665—690, 2003.
George J. Stigler. The economics of information. Journal of Political Economy, 69:213, 1961.
Stijn van Nieuwerburgh and Laura Veldkamp. Information immobility and the home bias
puzzle. Journal of Finance, 64(3):1187—1215, 06 2009.
Hal R Varian. The nonparametric approach to production analysis. Econometrica, 52(3):579—
97, May 1984.
Robert E Verrecchia. Information acquisition in a noisy rational expectations economy.
Econometrica, 50(6):1415—30, November 1982.
Abraham Wald. Sequential Analysis. John Wiley and Sons, 1st edition, 1947.
Michael Woodford. Inattentive valuation and reference-dependent choice. Mimeo, Columbia
University, 2012.

31

10
10.1

Appendix 1: Proofs
Lemma 1

Lemma 1 If  ∈ Π is consistent with  ∈ F and  ∈ Q, then it is suﬃcient for ̄  
Proof. Let  ∈ Π be an attention strategy that is consistent with  ∈ Q in decision
problem  . First, we list in order all distinct posteriors   ∈ Γ() for 1 ≤  ≤  =
|Γ()|. Given that  is consistent with , there exists a corresponding optimal choice
strategy  : {1  } → ∆(), with   () denoting the probability of choosing action
 ∈  () with posterior  , such that the attention and choice functions match the
data,

X

  (  )  ()
 =
=1

We also list in order all possible posteriors   ∈ Γ̄ ≡ Γ(̄  ), 1 ≤  ≤ Γ̄, and identify all
chosen actions that are associated with posterior   as ̄  ,
̄  ≡ { ∈  | () =   }

The garbling matrix  sets the probability of   ∈ Γ̄ given   ∈ Γ() as the probability
of all choices associated with actions  ∈ ̄  .
 =

X

  ()

∈̄ 

Note that this is indeed a |Γ()| × |Γ̄| stochastic matrix  ≥ 0 with
Given   ∈ Γ() and  ∈ Ω, note that,

X

   ( ) =

=1


X

  ( )

=1

X

  () =

∈̄ 

X

P

=1

 = 1 all .

 

∈̄ 

by the data matching property. It is definitional that ̄  (  ) is precisely equal to this,
as the observed probability of all actions associated with posterior   ∈ Γ̄. Hence,
̄  (  ) =


X
=1

as required for suﬃciency.

32

   ( )

10.2

Theorem 1 and Corollary 1

Theorem 1 Data set ( ) has a costly information acquisition representation if and only
if it satisfies NIAS and NIAC.
Proof of Necessity. Necessity of NIAS follows much as in CM14. Fix  ∈ , ̃  and
̃ : Γ(̃  ) → ∆() in a costly information acquisition representation, and possible  ∈ .
By definition of a costly information acquisition representation,
X

̃  ()

"
X
∈Ω

∈Γ(̃  )

#

   ≥

X

̃  ()

"
X


∈Γ(̃  )

  

#

all  ∈ 

Substituting,
 ̃  ()
  = X

 ̃  ()


X

 ̃  () in the inequality, substituting () =
cancelling the common denominator

X
X

̃  ()̃ (), and dividing all terms by
 () , we derive,


∈Γ(̃ )

X

 (())  =



⎡

⎤

⎡

⎤

X ⎢  () ⎥
X ⎢  () ⎥
X

 ⎥ 
 ⎥ 
⎢ X
⎢
X


≥
=
 (())  
⎣
⎦ 
⎣
⎦ 


 ()
 ()







establishing necessity of NIAS.
To confirm necessity of NIAC consider any sequence 1  2   ∈  with  = 1
and corresponding attention strategy ̃  for 1 ≤  ≤ . By optimality,
(  ̃  ) − (̃  ) ≥ (   +1 ) − (̃ +1 )∀  ∈ {1  }
so that,
−1
X
=1

(  ̃ ) − (̃  ) ≥

−1
X
=1

(   +1 ) − (̃+1 )

Given that (̃1 ) = (̃  ), note that,
−1
X
=1

(  ̃ ) − (  ̃ +1 ) ≥

33

−1
X
=1

(̃  ) − (̃+1 ) = 0

so that,
−1
X
=1



(  ̃ ) ≥

−1
X

(  ̃ +1 )

=1

To establish that this is inherited by the minimal attention strategies ̄  for 1 ≤  ≤ , note
from lemma 1 that with ̃  suﬃcient for ̄  , ( ̃  ) ≥ ( ̄  ) for all  ∈ F. For  = 
this is an equality since both strategies give rise to the same state dependent stochastic
demand,
XX
 ( )  
(  ̃  ) = (  ̄  ) =
∈



Hence,
−1
X
=1

(  ̄  ) ) =

−1
X
=1

(  ̃  ) ≥

−1
X
=1

(  ̃ +1 ) ≥

−1
X

(  ̄ +1 )

=1

establishing NIAC.
Proof of Suﬃciency. There are three steps in the proof that the NIAS and NIAC conditions are suﬃcient for ( ) to have a costly information acquisition representation. The
first step is to establish that the NIAC conditions ensures that there is no global reassignment
of the minimal attention strategies observed in the data to decision problems  ∈  that
raises total gross surplus. The second step is use this observation to define a candidate cost
function on attention strategies, ̄ : Π → R ∪ ∞. The key is to note that, as the solution
to the classical allocation problem of Koopmans and Beckmann [1957], this assignment is
supported by “prices” set in expected utility units. It is these prices that define the proposed
¡
¢
cost function. The final step is to apply the NIAS conditions to show that ̄ ̄ represents a costly information acquisition representation of ( ), where ̄ comprises minimal
attention strategies.
Enumerate decision problems in  as  for 1 ≤  ≤ . Define the corresponding minimal attention strategies ̄  for 1 ≤  ≤  as revealed in the corresponding data and let
Π̄ ≡ ∪∈ ̄ be the set of all such strategies across decision problems, with a slight enrichment to ensure that there are precisely as many strategies as there are decision problems. If
all minimal attention strategies are diﬀerent, the set as just defined will have cardinality .
If there is repetition, then retain the decision problem index with which identical minimal
attention strategies are associated so as to make them distinct. This ensures that the resulting set Π has precisely  elements. Index elements ̄ ∈ Π̄ in order of the decision problem
 with which they are associated.
We now allow for arbitrary matchings of attention strategies to decision problems. First,
let  denote the gross utility of decision problem  combined with minimal attention strategy

34

,
 = (  ̄  )
with  the corresponding matrix. Define M to be the set of all matching functions  :
{1  } → {1  } that are 1-1 and onto and identify the corresponding sum of gross
payoﬀs,

X
() 
() =
=1

It is simple to see that the NIAC condition implies that the identify map   () = 
maximizes the sum over all matching functions  ∈ M. Suppose to the contrary that there
exists some alternative matching function that achieves a strictly higher sum, and denote this
match  ∗ ∈ M. In this case construct a first sub-cycle as follows: start with the lowest index
1 such that ∗ (1 ) 6= 1 . Define  ∗ (1 ) = 2 and now find (2 ), noting by construction that
(2 ) 6= 2 . Given that the domain is finite, this process will terminate after some  ≤ 
steps with  ∗ ( ) = 1 . If it is the case that ∗ () =  outside of the set ∪
=1  , then we
know the increase in the value of the sum is associated only with this cycle, hence,
−1
X

  

=1

−1
X

 +1 

=1

directly in contradiction to NIAC. If this inequality does not hold strictly, then we know that
∗ 0
0
there exists some  0 outside of the set ∪
=1  such that  ( ) 6=  . We can therefore iterate
the process, knowing that the above strict inequality must be true for at least one such cycle
to explain the strict increase in overall gross utility. Hence the identity map   () =  indeed
maximizes () amongst all matching functions  ∈ M.
With this, we have established that the identity map solves an allocation problem of
precisely the form analyzed by Koopmans and Beckmann [1957]. They characterize those
matching functions  : {1 } → {1 } that maximize the sum of payoﬀs defined by
a square payoﬀ matrix such as  that identifies the reward to matching objects of one set
(decision problems in our case) to a corresponding number of objects in a second set (minimal
attention strategies in our case). They show that the solution is the same as that of the
linear program obtained by ignoring integer constraints,
max

 ≥0

X


  s.t.


X
=1

 =


X

 = 1

=1

Standard duality theory implies that the optimal assignment   () =  is associated with a
35

system of prices on minimal attention strategies such that the increment in net payoﬀ from
any move of any decision problem is not more than the increment in the cost of the attention
strategy.
Defining these prices as ̄ , their result implies that,
 −  = (  ̄  ) − (  ̄  ) ≤ ̄ − ̄ ;
or,
(  ̄  ) − ̄ ≥ (  ̄  ) − ̄ 
The result of Koopmans and Beckmann therefore implies existence of a function ̄ :
Π −→ R that decentralizes the problem from the viewpoint of the owner of the decision
problems, seeking to identify surplus maximizing attention strategies to match to their particular problems. Note that if there are two distinct decision problems with the same revealed
posterior, the result directly implies that they must have the same cost, so that one can in
fact ignore the reference to the decision problem and retain only the posterior in the domain. Set () = ∞ if  6= ̄  . We have now completed construction of a qualifying cost
function ̄ : Π → R ∪ ∞ that satisfies ̄() ∈ R for some  ∈ Π. The entire construction
was aimed at ensuring that the observed attention strategy choices were always maximal,
̄  ∈ Π̂( ) for all  ∈ . It remains to prove that ̄  is consistent with () for all
 ∈ . This requires us to show that, for all  ∈ , the choice rule that associates with
each  ∈ Γ(̄  ) the certainty of choosing the associated action  ∈  () as observed in the
data is both optimal and matches the data. That it is optimal is the precise content of the
NIAS constraint,
X
X
 (()) ≥
 (()) 




for all  ∈ . That this choice rule and the corresponding minimal attention function match
the data holds by construction.

Corollary 1 Data set ( ) has an SRI representation if and only if it satisfies NIAS and
NIAC.
Proof. Suﬃciency is implied by theorem 1 applied to the special case with  = 1. To
prove necessity, we first construct a mapping from sequential to static attention strategies
 : Σ() −→ Π(). Given  ∈ Σ() and  ∈ Γ we specify the corresponding state dependent
probabilities as,
X
 (  )
 () =
{  ∈ |  =, 1≤≤ }

36

We also define a mapping from sequential to static attention cost functions,  : E −→ K.
Given  ∈ E and  ∈ Π(),


 () =

(

P P
inf (∈Σ()| =} () = =0   ∈  (  )(    +1 (  ));
∞ if @ ∈ Σ() s.t.  = 

Given (̃ ̃) that define an SCI representation, we show that (̃ ̃) with ̃ ≡ ̃(̃)

and ̃ ≡ ̃() = (̃()) define a costly information acquisition representation, whereupon
application of the necessity aspect of theorem 1 implies that the data satisfy NIAS and NIAC.
By definition of an SCI representation, we know that for all  ∈ , ̃() is consistent with
() and satisfies ̃() ∈ Σ̂(̃ ). Hence there exists ̃ : Γ → ∆() such that act choices
are utility maximizing for all 1 ≤  ≤  ,   ∈  such that   = , and  ∈  with ̃  ()  0,
and such that the attention and choice functions match the data,
()

=

 X
X

̃() (  )̃  (  )

=0   ∈


Direct substitution using this fixed choice function shows that ̃ ∈ Π() is consistent
with (). Furthermore, given that (̃ ̃) is an SRI representation, we know that,
̃  ∈ arg max

∈Σ()


X
=0

⎡
⎣

X

  ∈

 (  )(   ) −

X

  ∈

⎤

 (  )(    +1 (  ))⎦ 


Substitution shows that this implies that the corresponding property holds for ̃ in relation
to ̃
XX


 ̃ ()( ) − ̃()
̃ ∈ arg max
∈Π()

∈Γ



so that ̃ ∈ Π̂((̃) ), completing the proof.

10.3

Theorem 2

Theorem 2 Data set ( ) satisfies NIAS and NIAC if and only if it has a costly information acquisition representation with conditions K1 to K3 satisfied.
Proof. The proof of necessity is immediate from theorem 1. The proof of suﬃciency
¡
¢
proceeds in four steps, starting with a costly information acquisition representation ̄ ̄
of ( ) of the form produced in theorem 1 based on satisfaction of the NIAS and NIAC
37

conditions. A key feature of this function is that the function ̄ is real-valued only on the
minimal information strategies Π̄ ≡ {̄  | ∈ } associated with all corresponding decision
problems, otherwise being infinite. The first step is the proof is to construct a larger domain
Π̊ ⊃ Π̄ to satisfy three additional properties: to include the inattentive strategy,  ∈ Π̊; to
be closed under mixtures so that   ∈ Π̊ and  ∈ (0 1) implies  ◦  + (1 − ) ◦  ∈ Π̊; and
to be “closed under garbling,” so that if  ∈ Π̊ is suﬃcient for attention strategy  ∈ Π, then
 ∈ Π̊. The second step is to define a new function ̊ that preserves the essential elements
of ̄ while being real-valued on the larger domain Π̊ ⊃ Π̄, and thereby to construct the full
candidate cost function ̊ : Π → R ∪ ∞. The third step is to confirm that ̊ ∈ K and
³ that
´
̊ satisfies the required conditions K1 through K3. The final step is to confirm that ̊ ̄
forms a costly information acquisition representation of ( ).
We construct the domain Π̊ in two stages. First, we define all attention strategies for
which some minimal attention strategy ̄ ∈ Π is suﬃcient;
Π̄ = { ∈ Π|∃ ∈ Π̄ suﬃcient for }
Note that this is a superset of Π̄ and that it contains . The second step is to identify Π̊
as the smallest mixture set containing Π̄ : this is itself a mixture set since the arbitrary
intersection of mixture sets is itself a mixture set.
By construction, Π̊ has three of the four desired properties: it is closed under mixing;
it contains Π̄, and it contains the inattentive strategy. The only condition that needs to be
checked is that it retains the property of being closed under garbling:
 ∈ Π̊ suﬃcient for  ∈ Π =⇒  ∈ Π̊ .
To establish this, it is useful first to establish certain properties of Π̄ and of Π̊. The first is
that Π̄ is closed under garbling:
 ∈ Π̄ suﬃcient for  ∈ Π =⇒  ∈ Π̄ .
Intuitively, this is because the garbling of a garbling is a garbling. In technical terms, the
product of the corresponding garbling matrices is itself a garbling matrix. The second is
that one can explicitly express Π̊ as the set of all finite mixtures of elements of Π̄ ,
Π̊ =

(

=


X
=1

 ◦   | ∈ N (1   ) ∈  −1   ∈ Π̄

38

)



where  −1 is the unit simplex in R To make this identification, note that the set as
defined on the RHS certainly contains Π̄ and is a mixture set, hence is a superset of Π̊.
Note moreover that all elements in the RHS set are necessarily contained in any mixture set
containing Π̄ by a process of iteration, making is also a subset of Π̊, hence finally one and
the same set.
We now establish that if  ∈ Π is a garbling of some  ∈ Π̊, then indeed  ∈ Π̊. The first
step is to express  ∈ Π̊ as an appropriate convex combination of elements of Π̄ as we now
know we can,

X
 ◦  
=
=1

with all weights strictly positive,   0 all . Lemma 2 below establishes that in this case
there exist garblings  of   ∈ Π̄ such that,
=


X
=1

 ◦  

establishing that indeed  ∈ Π̊ since, with Π̄ closed under garbling,   ∈ Π̄ and  a
garbling of   implies  ∈ Π̄ .
We define the function ̊ on Π̊ in three stages. First we define the function ̄ on
the domain Π̄ by identifying for any  ∈ Π̄ the corresponding set of minimal attention
strategies ̄ ∈ Π̄ of which  is a garbling, and assigning to it the lowest such cost. Formally,
given  ∈ Π̄ ,
min
̄()
̄ () ≡
{∈Π̄| suﬃcient for }

0

Note that ̄ () = ̄() all  ∈ Π̄. To see this, consider  0 ∈  with ̄  suﬃcient
0
for ̄  . By the Blackwell property, expected utility is at least as high using ̄  as using ̄ 
for which it is suﬃcient,
0
( ̄  ) ≥ ( ̄ )
¡
¢
At the same time, since ̄ ̄ is a rational attention representation of ( ), we know
that ̄ ∈ Π̂( ), so that,
0

0

( ̄  ) − (̄ ) ≥ ( ̄  ) − (̄ )
0

Together these imply that (̄  ) ≤ (̄  ), which in turn implies that ̄ () = ̄() all
 ∈ Π̄.
Note that ̄ () also satisfies weak monotonicity on this domain, since if we are given

39

  ∈ Π̄ with  suﬃcient for , then we know that any strategy  ∈ Π̄ that is suﬃcient
for  is also suﬃcient for , so that the minimum defining ̄ () can be no lower than that
defining ̄ ().
The second stage in the construction is extend the domain of the cost function from Π̄
to Π̊. As noted above, this set comprises all finite mixtures of elements of Π̄ ,
Π̊ =

(

=


X
=1

 ∗  | ∈ N (1   ) ∈  −1  and   ∈ Π̄

)



Given  ∈ Π̊, we take the set of all such mixtures that generate it and define ̊() to be the
corresponding infimum,
̊() = 

inf



 =1


X

∈N∈ −1 { }
∈
Π̄
|=
 ∗ 

=1






=1


X

 ̄ (  )

Note that this function is well defined since ̄ is bounded below by the cost of inattentive
strategies and the feasible set is non-empty by definition of Π̊. We establish in Lemma 3 that
the infimum is achieved. Hence, given  ∈ Π̊, there exists  ∈ N  ∈  −1  and elements

X

 ◦   such that,
 ∈ Π̄ with  =
=1

̊() =


X

 ̄ (  )

=1

We show now that ̊ satisfies K2, mixture feasibility. Consider distinct strategies  6=
 ∈ Π̊. We know by Lemma 3 that we can find   ∈ N corresponding probability weights


X
X

 ◦  ,  =
 ∗   , and such that,
 ∈   and elements     ∈ Π̄ with  =
=1

=1



̊() =


X

 ̄ ( );

=1


̊() =


X

 ̄ (  )

=1

Given  ∈ (0 1), consider now the mixture strategy defined by taking each strategy  
with probability  and each strategy   with probability (1 − ) . By construction, this
40

mixture strategy generates  = [ ∗  + (1 − ) ∗ ] ∈ Π and hence we know by the infimum
feature of ̊() that,


̊() ≤


X



 ̄ ( )

=1


X
+
(1 − ) ̄ ( ) = ̊() + (1 − )̊()
=1

confirming mixture feasibility.
We show also that ̊ satisfies K1, weak monotonicity in information. Consider   ∈ Π̊
with  suﬃcient for . We know by Lemma 3 that we can find  ∈ N  ∈  −1  and

X

 ∗   and such that,
corresponding elements {  }=1 ∈ Π̄ such that  =
=1

̊() =


X

 ̄ (  )

=1



We know also from Lemma 2 that we can construct { }=1 ∈ Π̄ such that  =


X
=1

 ◦ 

and such that each  is a garbling of the corresponding   . Given that ̄ satisfies weak
monotonicity on its domain Π̄ , we conclude that,
̄ ( ) ≥ ̄ (  )
By the infimum feature of ̊() we therefore know that,
̊() ≤


X
=1



 ̄ ( ) ≤


X

 ̄ (  ) = ̊()

=1

confirming weak monotonicity.
¡
¢
We show now that we have retained the properties that made ̄ ̄ a costly information
acquisition representation of ( ). Given  ∈ , it is immediate that ̄ and the choice
function that involves picking action  ∈  () for sure in revealed posterior  () is consistent with the data, since this was part of the initial definition. What needs to be confirmed
is only that the revealed minimal attention strategies are optimal. Suppose to the contrary
that there exists  ∈  such that,
( ) − ̊()  ( ̄ ) − ̊(̄  )
for some  ∈ Π̊. By Lemma 3 we can find  ∈ N a strictly positive vector  ∈  −1  and
41

corresponding elements


{  }=1

∈ Π̄ , such that  =

̊() =


X


X
=1

 ∗   and such that,

 ̄ (  )

=1

By the fact that  =


X
=1

 ∗   and by construction of the mixture strategy,

( ) =


X

 (   )

=1

so that,

X
=1

¤
£
 (   ) − ̄ (  )  ( ̄  ) − ̊(̄  )

We conclude that there exists  such that,

(   ) − ̄ ( )  ( ̄  ) − ̊(̄ )
Note that each   ∈ Π̄ inherits its cost ̄ (  ) from an element ̄  ∈ Π̄ that is the
lowest cost minimal attention strategy according to ̄ on set Π̄ that is suﬃcient for   ,
̄ ( ) = ̄(̄  )
where the last equality stems from the fact (established above) that ̄ () = ̄() on ̄ ∈ Π̄.
Note by the Blackwell property that each strategy ̄ ∈ Π̄ oﬀers at least as high gross value
as the strategy  ∈ Π̄ for which it is suﬃcient, so that overall,
( ̄  ) − ̄(̄  ) ≥ (   ) − ̄ (  )  ( ̄  ) − ̊(̄  )
To complete the proof it is suﬃcient to show that,
̊() = ̄()
on  ∈ Π̄ With this we derive the contradiction that,
( ̄ ) − ̄(̄  )  ( ̄ ) − ̄(̄  )
42

¡
¢
in contradiction to the assumption that ̄ ̄ formed a costly information acquisition representation of ( ).
To establish that ̊() = ̄() on  ∈ Π̄, note that we know already that ̄ () = ̄()
on ̄ ∈ Π̄. If this did not extend to ̊(), then we would be able to identify a mixture strategy
 ∈ Π̄ suﬃcient for ̄ with strictly lower expected costs, ̊()  ̊(). To see that this
is not possible, note first from Lemma 1 that all strategies that are consistent with  and
() are suﬃcient for ̄  . Weak monotonicity of ̊ on Π̊ then implies that the cost ̊()
of any mixture strategy suﬃcient for ̄  satisfies ̊() ≥ ̊(), as required.
The final and most trivial stage of the proof is to ensure that normalization (K3) holds.
Note that  ∈ Π̄ , so that ̊ () ∈ R according to the rule immediately above. If we
renormalize this function by subtracting ̊() from the cost function for all attention strategies then we impact on no margin of choice and do not interfere with mixture feasibility,
weak monotonicity, or whether or not we have a costly information acquisition representation. Hence we can avoid pointless complication by assuming that ̊() = 0 from the
outset so that this normalization is vacuous. In full, we define the candidate cost function
̊ : Π̊ → R ∪ ∞ by,
(
̊() if  ∈ Π̊
̊() =
∞ if  ∈
 Π̊
Note that weak monotonicity implies that the function is non-negative on its entire domain.
It is immediate that ̊ ∈ K, since ̊() = ∞ for  ∈
 Π̊ and the domain contains the
corresponding inattentive strategy  on which ̊() is real-valued. It is also immediate that
̊ satisfies K3, since ̊() = 0 by construction. It also satisfies K1 and K2, and represents
a costly information acquisition representation, completing the proof.
Lemma 2 If  =


X
1



 ◦   with  ∈ N  ∈  −1 with   0 all , and {  }=1 ∈ Π, then

for any garbling  of , there exist garblings  of   ∈ Π such that,
=


X
=1

 ∗  

Proof. By assumption, there exists a |Γ()| × |Γ()| matrix  with
such that, for all   ∈ Γ(),
X
   ( )
 (  ) =

P



 = 1 all  and

 ∈Γ()

Since  =


X
1

 ◦  , we know that Γ(  ) ⊂ Γ(). Now define compressed matrix   as
43

the unique submatrix of  obtained by first deleting all rows corresponding to posteriors
  ∈ Γ()\Γ(  ), and then deleting all columns corresponding to posteriors   such that
 = 0 all  ∈ Γ()\Γ(  ). Define  ∈ Π to be the strategy that has as its support the set
of all posteriors that are possible given the garbling  of   ,
Γ( ) = {  ∈ Γ()|  0 some   ∈ Γ(  )}
and in which state dependent probabilities of all posteriors are generated by the compressed
matrix   ,
X
  (  )
 (  ) =
  ∈Γ(  )

for all   ∈ Γ( ).
Note by construction that each attention strategy  is a garbling of the corresponding
P
  ∈ Π, since each   is itself a garbing matrix for which   = 1 for all  ∈ Γ(  ). It

X
remains only to verify that  =
 ∗  . This follows since,
=1

 (  ) =

X

  ∈Γ()

   (  ) =

X



  ∈Γ()


X

   ( ) =

=1


X
=1



X

 ∈Γ(  )

  ( ) =


X

  (  )

=1

Lemma 3 Given  ∈ Π̊, there exists  ∈ N  ∈  −1 , and elements  ∈ Π̄ with

X
 ◦   such that,
=
=1

̊() =


X

 ̄ (  )

=1

Proof. By definition ̊() is the infimum of


X
=1

that  =


X
=1



 ̄ (  ) over all lists {  }=1 ∈ Π̄ such

 ∗  . We now consider a sequence of such lists, indicating the order in this
()

sequence in parentheses, { ()}=1 , such that in all cases there are corresponding weights
()
X
()−1
with  =
 () ∗   () and that achieve a value that is heading in the
() ∈ 
=1

44

limit to the infimum,
lim

−→∞

()
X

 ()̄ (  ()) = ̊().

=1

A first issue that we wish to avoid is limitless growth in the cardinality (). The
first key observation is that, by Charateodory’s theorem, we can reduce the number of
 ∗ ()
X
∗ () ∗  () to have cardinality
strictly positive weights in a convex combination  =
=1

 ∗ () ≤  + 1. We confirm now that we can do this without raising the corresponding
 ∗ ()
X
∗ ()̄ (  ()). Suppose that there is some integer  such that the original set
costs,
=1

of attention strategies has strictly higher cardinality ()   + 1. Suppose further that
the first selection of  1 () ≤  + 1 such posteriors for which there exists a strictly positive
 1 ()
X
1
 1 ()∗  () has higher such costs (note WLOG
probability weights   () such that  =
=1

that we are treating these as the first  1 () attention strategies in the original list). It is
convenient to define  1 () = 0 for  1 ()+1 ≤  ≤ () so that we can express this inequality
in the simplest terms,
()
X

 1 ()̄ (  ())

=1



()
X

 ()̄ ( ())

=1

This inequality sets up an iteration. We first take the smallest scalar 1 ∈ (0 1) such
that,
1  1 () =  ()
 1 ()

That such a scalar exists follows from the fact that

X
=1

 1 ()

=

()
X

 () = 1, with all

=1

components in both sums strictly positive and with ()   1 (). We now define a second
set of probability weights 2 (),
2 () =

 () − 1  1 ()

1 − 1

for 1 ≤  ≤ (). Note that these weights have the property that  =

45

()
X
=1

2 () ∗   () and

that,
"
#
()
()
1 1
X
X

()
−


()


2


 ()̄ ( ()) =
 ()̄ (  ()
̄ ( ()) 
1
1
−

=1
=1
=1

()
X

By construction, note that we have reduced the number of strictly positive weights 2 ()
by at least one to () − 1 or less. Iterating the process establishes that indeed there exists a
set of no more than  + 1 posteriors such that a mixture produces that first strategy  and
in which this mixture has no higher weighted average costs than the original strategy. Given
this, there is no loss of generality in assuming that () ≤  + 1 in our original sequence.
With this bound on cardinality, we know that we can find a subsequence of attention
strategies   () which all have precisely the same cardinality () =  ≤  +1 all . Going
∞
further, we can impose properties on all of the  corresponding sequences {  ()}=1 . First,
we can select subsequences in which the ranges of all corresponding attention functions have
the same cardinality independent of ,
¯
¯
¯Γ(  ())¯ =   

for 1 ≤  ≤ . Note we can do this because, for all  and , the number of posteriors in
the attention strategy   () is bounded above by the number of posteriors in the strategy
, which is finite.
With this, we can index the possible posteriors   () ∈ Γ( ()) in order, 1 ≤  ≤  
and then select further subsequences in which these posteriors themselves converge to limit
posteriors,
  () = lim   () ∈ Γ
→∞

which is possible posteriors lie in a compact set, and so have a convergent subsequence.
We ensure also that both the associated state dependent probabilities themselves and the
()
X
 () ∗   () converge,
weights  () in the expression  =
=1

¡
¢
lim     () =  
 ();

→∞

lim  () =  ()

→∞

Again, this is possible because the state dependent probabilities and weights lie in compact
sets.
The final selection of a subsequence ensures that, given 1 ≤  ≤ , each   () ∈ Π̄
46

has its value defined by precisely the same minimal attention strategy ̄  ∈ Π̄ as the least
expensive among those that were suﬃcient for it and hence whose cost it was assigned in
function ̄ . Technically, for each 1 ≤  ≤ ,
̄ (  ()) = ̄(̄  )
for 1 ≤  ≤ ∞: this is possible because the data set and hence the number of minimal
attention strategies is finite.
We first use these limit properties to construct a list of limit attention strategies   () ∈

X
 ◦   for 1 ≤  ≤ . Strategy   () has range,
Π̄ with  =
=1




Γ(  ()) = ∪
=1  ()

with state dependent probabilities,
£  ¤ ¡  ¢
 ()   () =  
 ()
Note that the construction ensures that  =


X
=1

must establish only that,
̊() =


X

 () ◦   (). To complete the proof we

 ()̄ (  ())

=1

We know from the construction that, for each 

X



 ()̄ ( ()) =

=1


X

 ()̄(̄  )

=1

Hence the result is established provided only,
̄ (  ()) ≤ ̄(̄  )
which is true provided ̄  being suﬃcient for all  () implies that ̄  is suﬃcient for the
corresponding limit vector   (). That this is so follows by defining   () = [ ()] to be
the limit of any subsequence of the |Γ(̄ )| ×   stochastic matrices   () = [ ()] which

47

have the defining property of suﬃciency,
X
£  ¤
 ()  (  ()) =
[ ()] ∗ ̄  (̄  )
̄  ∈Γ(̄ )

for all   () ∈ Γ(  ()) and  ∈ Ω. It is immediate that the equality holds up in the limit,
establishing that indeed ̄  is suﬃcient for each corresponding limit vector  (), confirming
finally that ̄ ( ()) ≤ ̄(̄ ) and with it establishing the Lemma.

11

Appendix 2: No Strong Blackwell

A simple example with data on one decision problem with two equally likely states illustrates
that one cannot further strengthen the result in this dimension. Suppose that there are three
available actions  = {  } with corresponding utilities,
(1  2 ) = (10 0) ; (1  2 ) = (0 10) ; (1  2 ) = (75 75) 
Consider the following state dependent stochastic choice data in which the only two chosen
actions are  and ,
3
1 = 2 = = 1 − 1 = 1 − 2 
4
Note that this data satisfies NIAS; given posterior beliefs when  is chosen,  is superior to
 and indiﬀerent to , and when  is chosen it is superior to  and indiﬀerent to . It trivially
satisfies NIAC since there is only one decision problem observed. We know from theorem
2 that is has a costly information acquisition representation with the cost of the minimal
attention strategy  (̄) ≥ 0 and that of the inattentive strategy being zero, () = 0.
Note that ̄ is suﬃcient for  but not vice versa, hence any strictly monotone cost function
would have to satisfy  (̄)  0. In fact it is not possible to find a representation with this
property. To see this, note that both strategies have the same gross utility,
( ) =

1 3
1 3
∗ ∗ 10 + ∗ ∗ 10 = 1 ∗ 75 = ( )
2 4
2 4

where we use the fact that the inattentive strategy involves picking action  for sure. In
order to rationalize selection of the inattentive strategy, it must therefore be that ̄ is no
more expensive than , contradicting strict monotonicity.

48

12

Appendix 3: Further Details of NIAS and NIAC
Tests

Tables s1 and s2 show the subject level distribution of losses due to NIAC and NIAS violations
in dollar terms, compared to a benchmark simulated distribution of random choice. Losses
due to NIAC are calculated assuming that the point estimate of posterior beliefs upon
the the choice of each act are the subject’s true posterior beliefs, and then comparing the
expected value of the chosen act to that of the optimal act at each posterior. Losses below
are summed across all chosen acts in all decision problems. NIAS losses are calculated by
treating each subject’s estimated choice probabilites in each decision problem as their true
choice probabilities, and calculating the maximal surplus that could be obtained by correctly
assigning strategies to decision problems. This is compared to the surplus obtained from the
subject’s actual assignment, assuming NIAS to be satisfied.
In all 6 cases, the distributions of actual and simulated subjects are significantly diﬀerent
at the 0.001% level (Kolmogorov-Smirnov test).

49

Experiment 1

Experiment 2

Experiment 3
Figure s1: $ losses due to NIAS violations - actual and simulated subjects

50

Experiment 2

Experiment 1

Experiment 3
Figure s2: $ losses due to NIAC violations - actual and simulated subjects
Table s1: NIAS conditions for Experiment 3
Decision Problem 1 ( 1 −  2 ) + 3 ( 3 −  4 )
9

1.8

10

2.6

11

0.3

12

3.9

Table s1 describes the NIAS test for experiment 3. As discussed in the text, NIAS is
satisfied in each decision problem if 1 ( 1 −  2 ) + 3 ( 3 −  4 ) is greater than zero. Table
s2 shows the value of this expression in the aggregate data. For each decision problem the
condition is satisfied.

51

Appendix 4: Example Instructions

1/27/2014

Instructions

Individual Decision-Making Experiment
Instructions
This experiment is designed to study decision making, and consists of 4 sections. Each section will
consist of 50 questions. At the end of the experiment, one question will be selected at random from
those you answered. The amount of money that you get at the end of the experiment will depend
on your answer to this question. Anything you earn from this part of this experiment will be added
to your show-up fee of $10.
Please turn off cellular phones now.
The entire session will take place through your computer terminal. Please do not talk or in any way
communicate with other participants during the session.
Please do NOT use the forward and back buttons in your browser to navigate. Only use the
links at the bottom of each page to move forward or back.
We will start with a brief instruction period. During this instruction period, you will be given a
description of the main features of the session and will be shown how to use the program. If you
have any questions during this period, please raise your hand.
After you have completed the experiment, please remain quietly seated until ev eryone has
completed the experiment.

← Home

http://samuel-brown.com/infoexp12/instructions.php?p=1

Next →

1/1

1/27/2014

Instructions

Individual Decision-Making Experiment
Instructions
For each question you will be shown 100 dots on a screen. Some of these dots will be red, while
some will be blue. Here is an example of such a screen:

The number of red dots will be determined at random. You will be told how likely each number of
red dots is. So, for example you might be told that there is a 75% chance of there being 49 red
dots and a 25% chance of there being 51 red dots. In this case there is a 3/4 chance that there will
be 49 red dots on the screen, and a 1/4 chance that there will be 51 red dots. There will never be
any other number of red dots on the screen. The number of red dots in each question is
determined independently of the number of red dots that have appeared in previous questions.

← Previous

http://samuel-brown.com/infoexp12/instructions.php?p=2

Next →

1/1

1/27/2014

Instructions

Individual Decision-Making Experiment
Instructions
You will be asked to make a choice between two or more options. Each of these options will pay
out different amounts of money, depending on how many red dots are on the screen.

Option

Pay if there are 49 red dots

Pay if there are 51 red dots

A

10

0

B

0

10

C

5

5

In this case, if you chose option A (and this question was the one selected for payment) then you
would get $10 if there were 49 red dots on the screen and $0 if there were 51 red dots. If you
chose option B you would get $10 if there were 51 red dots on the screen and $0 if there were 49
red dots. If you chose option C you would receive $5 regardless of the number of red dots on the
screen.
You will now have the chance to try an example question. You will not be paid depending on your
answer to this question - it is just for practice.

← Previous

http://samuel-brown.com/infoexp12/instructions.php?p=3

Next →

1/1

1/27/2014

Instructions

Individual Decision-Making Experiment
Instructions
Example Question
You are about to see a screen with 100 dots on it. These dots will be either red or blue. The
likelihood of the number of red dots is as follows:
With 50% probability there will be 49 red dots
With 50% probability there will be 51 red dots
You will then be asked to choose between a number of alternatives. These alternatives will pay
money depending on the number of dots on the screen.

← Previous

http://samuel-brown.com/infoexp12/instructions.php?p=4

Next →

1/1

1/27/2014

Instructions

Individual Decision-Making Experiment
Instructions
Example Question
Remember:
With 50% probability there will be 49 red dots
With 50% probability there will be 51 red dots

Please select from the following options:

Option

Pay if there are 49 red dots

Pay if there are 51 red dots

A

10

0

B

0

10

C

5

5

← Previous

http://samuel-brown.com/infoexp12/instructions.php?p=5

Next →

1/1

1/27/2014

Instructions

Individual Decision-Making Experiment
Instructions
Payment
For this question, you chose the following option:

Option

Pay if there are 49 red dots

Pay if there are 51 red dots

A

10

0

There were 49 red dots on the screen.
If this were the question that had been selected for payment, you would have received $10 in
addition to your show up fee.

← Previous

http://samuel-brown.com/infoexp12/instructions.php?p=6

Next →

1/1

1/27/2014

Instructions

Individual Decision-Making Experiment
Instructions
Here is a description of the questions that you will face in each of the 4 sections of the experiment.

Block 1
With 50% probability there will be 49 red dots
With 50% probability there will be 51 red dots
You will be asked to choose between the following options:

Option

Pay if there are 49 red dots

Pay if there are 51 red dots

A

23

23

B

21

25

C

40

0

Block 2
With 50% probability there will be 49 red dots
With 50% probability there will be 51 red dots
You will be asked to choose between the following options:

Option

Pay if there are 49 red dots

Pay if there are 51 red dots

A

23

23

B

21

25

Block 3
With 50% probability there will be 49 red dots
With 50% probability there will be 51 red dots
You will be asked to choose between the following options:
http://samuel-brown.com/infoexp12/instructions.php?p=7

1/2

1/27/2014

Instructions

Option

Pay if there are 49 red dots

Pay if there are 51 red dots

A

23

23

B

21

25

C

35

5

Block 4
With 50% probability there will be 49 red dots
With 50% probability there will be 51 red dots
You will be asked to choose between the following options:

Option

Pay if there are 49 red dots

Pay if there are 51 red dots

A

23

23

B

21

25

C

30

10

REMEMBER: Each section consists of 50 questions, each with the same probabilities and
av ailable options. You will be reminded in each question what the probabilities and
av ailable options are for that question.
Again, please do NOT use the forward and back buttons in your browser to navigate. Only
use the links at the bottom of each page to move forward or back.
If you have any questions, please raise your hand now, otherwise click to the lower right to return
to the Home Page and begin the experiment.

← Previous

http://samuel-brown.com/infoexp12/instructions.php?p=7

Home →

2/2

