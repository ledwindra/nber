NBER WORKING PAPER SERIES

USING INSTRUMENTAL VARIABLES FOR INFERENCE ABOUT POLICY RELEVANT
TREATMENT EFFECTS
Magne Mogstad
Andres Santos
Alexander Torgovitsky
Working Paper 23568
http://www.nber.org/papers/w23568

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
July 2017

We thank Liran Einav, Derek Neal, Ed Vytacil, Chris Walters, and seminar participants at several
universities and conferences for valuable feedback and suggestions. Bradley Setzler provided
excellent research assistance. We are grateful to Pascaline Dupas for her help in accessing the
data and in understanding the institutional details. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2017 by Magne Mogstad, Andres Santos, and Alexander Torgovitsky. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

Using Instrumental Variables for Inference about Policy Relevant Treatment Effects
Magne Mogstad, Andres Santos, and Alexander Torgovitsky
NBER Working Paper No. 23568
July 2017
JEL No. C21,C36
ABSTRACT
We propose a method for using instrumental variables (IV) to draw inference about causal effects
for individuals other than those affected by the instrument at hand. Policy relevance and external
validity turns on the ability to do this reliably. Our method exploits the insight that both the IV
estimand and many treatment parameters can be expressed as weighted averages of the same
underlying marginal treatment effects. Since the weights are known or identified, knowledge of
the IV estimand generally places some restrictions on the unknown marginal treatment effects,
and hence on the values of the treatment parameters of interest. We show how to extract
information about the average effect of interest from the IV estimand, and, more generally, from
a class of IV-like estimands that includes the two stage least squares and ordinary least squares
estimands, among many others. Our method has several applications. First, it can be used to
construct nonparametric bounds on the average causal effect of a hypothetical policy change.
Second, our method allows the researcher to flexibly incorporate shape restrictions and
parametric assumptions, thereby enabling extrapolation of the average effects for compliers to the
average effects for different or larger populations. Third, our method can be used to test model
specification and hypotheses about behavior, such as no selection bias and/or no selection on
gain. To accommodate these diverse applications, we devise a novel inference procedure that is
designed to exploit the convexity of our setting. We develop uniformly valid tests that allow for
an infinite number of IV--like estimands and a general convex parameter space. We apply our
method to analyze the effects of price subsidies on the adoption and usage of an antimalarial bed
net in Kenya.
Magne Mogstad
Department of Economics
University of Chicago
1126 East 59th Street
Chicago, IL 60637
and NBER
magne.mogstad@gmail.com
Andres Santos
Department of Economics
University of California - Los Angeles
8283 Bunche Hall, 315 Portola Plaza
Los Angeles, CA, 90095
andres@econ.ucla.edu

Alexander Torgovitsky
Department of Economics
Northwestern University
2001 Sheridan Rd, Room 302
Evanston, IL 60208-2600
a-torgovitsky@northwestern.edu

1

Introduction

In an influential paper, Imbens and Angrist (1994) provided conditions under which an
instrumental variables (IV) estimand can be interpreted as the average causal effect for
the subpopulation of compliers, i.e. for those whose treatment status would be affected
by an exogenous manipulation of the instrument. In some cases, this local average
treatment effect (LATE) is of intrinsic interest, for example if the instrument itself
represents an intervention or policy change of interest. On the other hand, in many
situations, the causal effect for individuals induced to treatment by the instrument at
hand might not be representative of the causal effect for those who would be induced
to treatment by a given policy change of interest to the researcher. In these cases, the
LATE is not the relevant parameter for evaluating the policy change.
In this paper, we show how to use instrumental variables to draw inference about
treatment parameters other than the LATE, thereby learning about causal effects for
individuals other than those affected by the instrument at hand. Policy relevance and
external validity turn on the ability to do this reliably. Our setting is the canonical program evaluation problem with a binary treatment D ∈ {0, 1} and a scalar, real-valued
outcome, Y .1 Corresponding to the two treatment arms are unobservable potential
outcomes, Y0 and Y1 . These represent the realization of Y that would have been experienced by an individual had their treatment status been exogenously set to 0 or 1.
The relationship between observed and potential outcomes is given by
Y = DY1 + (1 − D)Y0 .

(1)

Following Heckman and Vytlacil (1999, 2005), we assume that treatment is determined by the weakly separable selection or choice equation
D = 1[ν(Z) − U ≥ 0],

(2)

where ν is an unknown function, U is a continuously distributed random variable, and
Z is a vector of observable regressors. Suppose that Z is independent of (Y0 , Y1 , U ),
perhaps conditional on some subvector X of Z. Under this assumption, the IV model
given by (1)–(2) is equivalent to the IV model used by Imbens and Angrist (1994) and
1

For discussions of heterogeneous effects IV models with multiple discrete treatments, we refer to
Angrist and Imbens (1995), Heckman, Urzua, and Vytlacil (2006), Heckman and Vytlacil (2007b), Heckman
and Urzua (2010), Kirkeboen, Leuven, and Mogstad (2016), and Lee and Salanié (2016), among others.
Heterogeneous effects IV models with continuous treatments have been considered by Angrist, Graddy, and
Imbens (2000), Chesher (2003), Florens, Heckman, Meghir, and Vytlacil (2008), Imbens and Newey (2009),
Torgovitsky (2015), Masten (2015), and Masten and Torgovitsky (2016), among others.

2

many subsequent authors (Vytlacil, 2002). In particular, the instrument monotonicity
condition of Imbens and Angrist (1994) is embedded in the separability of U and Z in
the latent index ν(Z) − U . An important feature of the model is that treatment effects
Y1 − Y0 can vary across individuals with the same observable characteristics, X, in a
way that depends on the unobservable component of treatment choice, U .
Our goal is to develop a method that uses a random sample of (Y, D, Z) together
with the structure of the model to draw inference about a parameter of interest, β ? ,
that a researcher has decided is relevant for evaluating a hypothetical policy change or
intervention. Our method builds on the work of Heckman and Vytlacil (1999, 2001a,b,c,
2005, 2007a,b). Those authors showed that many different treatment parameters can
be expressed in terms of the marginal treatment effect (MTE) function
MTE(u, x) ≡ E [Y1 − Y0 |U = u, X = x] .

(3)

The MTE can be interpreted as the average treatment effect indexed as a function
of an individual’s latent propensity to receive treatment, U , and conditional on other
covariates, X. Heckman and Vytlacil (2005) showed that common parameters of interest can be expressed as weighted averages of the MTE function, with weights that are
either known or identified. They showed that the same is also true of the IV estimand.
These insights suggest that even if the IV estimand is not of direct interest, it
still carries information about the underlying MTE function, and hence about the
parameter of interest, β ? . In particular, since the weights for both the IV estimand
and the parameter of interest are identified, knowledge of the IV estimand generally
places some restrictions on the unknown MTE function, and hence on the range of
values for β ? that are consistent with the data. This can be seen by writing:
Z
βIV
|{z}

MTE(u) ×
| {z }

≡

identified IV estimand

β?
|{z}

unknown

Z
≡

unknown target parameter

MTE(u) ×
| {z }
unknown

ωIV (u)
| {z }

du

identified IV weights

ω ? (u)
| {z }

du,

(4)

identified target weights

where we are assuming for the moment that there are no covariates X, just for simplicity. Equation (4) suggests that we can extract information about the parameter
of interest, β ? , from the IV estimand, βIV , by solving an optimization problem. In
particular, β ? must be smaller than
Z
max
MTE

MTE(u)ω ? (u) du subject to

3

Z
MTE(u)ωIV (u) du = βIV ,

(5)

where the maximum is taken over a set of potential MTE functions that also incorporates any additional a priori assumptions that the researcher chooses to maintain.
Similarly, β ? must be larger than the solution to the analogous minimization problem.
The optimization problem (5) has only the single constraint involving βIV . Using
the same logic, one can also include similar constraints for other IV estimands that
correspond to different functions of Z. Upon doing so, the bounds on β ? will necessarily
tighten, because each new IV estimand reduces the feasible set in (5). We show that,
more generally, any cross moment between Y and a known function of D and Z can
also be written as a weighted average of the two marginal treatment response (MTR)
functions that constitute an MTE function. We refer to this class of cross moments as
“IV–like” estimands.
The class of IV–like estimands is general enough to contain the estimands corresponding to any weighted linear IV estimator. This includes, as special cases, the
two stage least squares (TSLS), optimal generalized method of moments, and ordinary least squares (OLS) estimands. Each moment in this class provides a different
weighted average of the same underlying MTR functions, and therefore carries some
distinct information about the possible values of the parameter of interest, β ? . We
show how these IV–like estimands can be chosen systematically so as to provide the
tightest possible bounds on β ? .
Our method has several applications. First, it can be used to construct nonparametric bounds on the average causal effect of a hypothetical policy change. Second, our
method enables extrapolation of the average effects for compliers to the average effects
for different or larger populations. Third, our method can be used to perform tests of
model specification and of individual behavior, such as testing the null hypotheses of
no selection bias and/or no selection on gains. In all of these applications, our method
provides a researcher the option to impose parametric and/or shape restrictions, if
desired.
To accommodate these diverse applications, we develop a novel inference framework
that allows for (but does not require) nonparametric and/or shape constrained specifications for the MTR functions, as well as an infinite number of IV–like estimands.
Our approach is specifically designed to take advantage of the convexity of our setting.
We show that it satisfies two key requirements. First, it provides uniform size control
over a wide class of distributions, a feature which is critically important in partially
identified settings (Imbens and Manski, 2004). Second, implementing our procedure
involves solving optimization problems for which there exist algorithms that provably
converge to the global optimum. The generality of our inference results make them of
independent interest, and we state them in a manner that facilitates their portability.

4

We apply our method using data from Dupas (2014). This data comes from a
randomized pricing experiment for a preventative health product, conducted in Kenya.
The goal of our empirical analysis is to assess how a class of potential subsidy regimes
can promote the use of the health product, and to compare increases in usage to the
costs of subsidization. For example, we measure the effect of a policy that offers free
provision to each household as compared to a policy under which all households can
purchase the product at a given price. This comparison does not correspond to the
variation in prices induced by the experiment. As a result, it is not point identified
under standard instrumental variables assumptions. However, our method can be used
to estimate bounds on the average causal effect of this comparison. Our results show
that these bounds can be very informative.
Our paper contributes to several literatures. A large body of work is concerned
with using instrumental variables to draw nonparametric inference about treatment
parameters other than the LATE. Heckman and Vytlacil (2005) observe that if Z is
continuously distributed and has a sufficiently large impact on treatment choices D,
so that the propensity score P (D = 1|Z = z) varies over the entire [0, 1] interval, then
the MTE function is nonparametrically point identified. As a consequence, any target
parameter β ? is also nonparametrically point identified. In practice, however, instruments have limited support and are often discrete or even binary. For these situations,
many common target parameters of interest, such as the average treatment effect, are
not nonparametrically point identified. Analytic expressions for sharp bounds on the
average treatment effect have been derived by Manski (1989, 1990, 1994, 1997, 2003),
Balke and Pearl (1997), Heckman and Vytlacil (2001b) and Kitagawa (2009), among
others.2
Analytic expressions for bounds are useful because they provide intuition on the
source and strength of identification. However, it can be difficult to derive analytic
bounds for more complicated parameters, such as the policy relevant treatment effects
(PRTEs) studied by Heckman and Vytlacil (2001a, 2005) and Carneiro, Heckman, and
Vytlacil (2010, 2011). Our methodology is particularly useful in such settings. In addition, our method provides a unified framework for imposing shape restrictions such
as monotonicity, concavity, monotone treatment selection (Manski, 1997; Manski and
Pepper, 2000, 2009) and separability between observed and unobserved factors in the
MTE function (Brinch, Mogstad, and Wiswall, 2015). It can be especially difficult to
2
Note that Manski’s analyses did not impose the separable first stage equation (2), see Heckman and
Vytlacil (2001b) and Kitagawa (2009) for further discussion. Also related is work by Shaikh and Vytlacil
(2011), Bhattacharya, Shaikh, and Vytlacil (2012), and Mourifié (2015), who augment (2) with a similar
assumption for the potential outcomes, (Y0 , Y1 ).

5

derive analytic bounds for treatment parameters that incorporate these types of assumptions in flexible combinations. In contrast, our general computational approach
allows one to flexibly adjust the parameter of interest, as well as the maintained assumptions, without requiring additional identification analysis.
In addition, our paper is related to recent work that considers extrapolation in instrumental variables model under additional assumptions. While our method delivers
bound on the target parameter in general, these bounds nest important point identification results as special cases. For example, our method nests existing approaches that
extrapolate by assuming no unobserved heterogeneity in the treatment effect (Heckman
and Robb, 1985; Angrist and Fernandez-Val, 2013), and those that parameterize this
unobserved heterogeneity (Heckman, Tobias, and Vytlacil, 2003; Brinch et al., 2015).3
One attractive feature of our method is that the constraints in (5) require an MTE
function to also yield the usual, nonparametrically point identified LATE. Hence, our
method allows for extrapolation to other parameters of interest without sacrificing the
internal validity of the LATE.
Our paper also relates to a literature on specification tests in settings with instrumental variables. To see this, suppose that (5) is infeasible, so that there does not
exist an MTE function that can both satisfy the researcher’s assumptions and lead
to the observed IV estimand. Then the model is misspecified: Either the researcher’s
assumptions are invalid, Z is not exogenous, the selection equation (2) is rejected by
the data, or some combination of the three. Balke and Pearl (1997) and Imbens and
Rubin (1997) noted that (2) has testable implications, while Machado, Shaikh, and
Vytlacil (2013), Huber and Mellace (2014), Kitagawa (2015), and Mourifié and Wan
(2016) have developed this observation into formal statistical tests. Our method builds
on the work of these authors by allowing the researcher to maintain additional assumptions, such as parametric and/or shape restrictions. In addition to testing whether the
model is misspecified, our method can also be used to test null hypotheses such as no
selection bias and/or no selection on gains.
Lastly, our paper contributes to a growing literature on inference for functionals of
partially identified parameters. Our inference procedure is based on a profile statistic.
Romano and Shaikh (2008) and Bugni, Canay, and Shi (2015) proposed using profile statistics for moment inequality models, while Chernozhukov, Newey, and Santos
(2015) considered models with conditional moment inequalities. Our model contains
additional structure not present in moment inequality models.4 We utilize this spe3

For a completely different Bayesian approach to extrapolation in instrumental variables models, see
Chamberlain (2011).
4
Loosely speaking, in a moment inequality model, the inequalities are random, whereas in our context

6

cial structure to develop distributional approximations that are uniformly valid under
low level conditions, and which only require the parameter space to be convex. An
important alternative to profiling test statistics has been recently proposed by Kaido,
Molinari, and Stoye (2016), who instead construct confidence regions through an adjusted projection algorithm. Their work, in common with many other papers in the
moment inequalities literature, focuses on finite dimensional parameters and a finite
number of moment restrictions. Both of these conditions are restrictive for our applications of interest. Our analysis is also related to Beresteanu and Molinari (2008),
Bontemps, Magnac, and Maurin (2012), and Kaido and Santos (2014), who also exploit
convexity for statistical inference.
The remainder of the paper is organized as follows. In Section 2, we present the
model and develop our method for bounding a target parameter of interest while potentially maintaining additional shape constraints. In Section 3, we discuss key applications of our method, which we illustrate in Section 4 through a numerical example.
We develop our statistical inference procedure in Section 5. In Section 6, we apply our
method to study the effects of price subsidies on the adoption of preventative health
products. We provide some concluding remarks in Section 7. Proofs for all results
presented in the main text are contained in Appendices A and C.

2

Identification

Throughout this section, we assume that the researcher knows the joint distribution of
the observed data (Y, D, Z). We address issues of statistical inference in Section 5.

2.1

Model

Our analysis uses the IV model consisting of (1)–(2), which is also often referred to as
the two-sector generalized Roy model. The observable variables in the model are the
outcome Y ∈ R, the binary treatment D ∈ {0, 1}, and a vector of observables Z ∈ Rdz .
We decompose Z into Z = (X, Z0 ), where Z0 ∈ Rdz0 are exogenous instruments and
X ∈ Rdx are control variables. The unobservables are the potential outcomes (Y0 , Y1 ),
and the variable U in the selection equation, which represents unobservable factors
that affect treatment choice.
We maintain the following assumptions throughout the paper.
Assumptions I
I.1 U ⊥
⊥ Z0 |X, where ⊥
⊥ denotes (conditional) statistical independence.
the inequalities are deterministic, because they arise from the specification of the parameter space.

7

I.2 E[Yd |Z, U ] = E[Yd |X, U ] and E[Yd2 ] < ∞ for d ∈ {0, 1}.
I.3 U is continuously distributed, conditional on X.
Assumptions I.1 and I.2 require Z0 to be exogenous with respect to both the selection
and outcome processes. Vytlacil (2002) showed that, given I.1, the assumption that
the index of the selection equation is additively separable as in (2) is equivalent to
the assumption that Z0 affects D monotonically in the sense introduced by Imbens
and Angrist (1994). Hence, I.1 combined with (2) imposes substantive restrictions on
choice behavior. Assumption I.2 imposes an exclusion restriction that the conditional
means of Y0 and Y1 depend on Z = (Z0 , X) only through the covariates X.
Assumption I.3 is a weak regularity condition that enables us to impose a standard
normalization. As is well known, equation (2) may be rewritten as


e ≤ νe(Z)],
D = 1 FU |X (U |X) ≤ FU |X (ν(Z)|X) ≡ 1[U

(6)

where we are using the notation FU |X (u|x) ≡ P (U ≤ u|X = x) and we have defined
e ≡ FU |X (U |X) and νe(Z) ≡ FU |X (ν(Z)|X). Under Assumptions I.1 and I.3, U
e is
U
uniformly distributed on [0, 1], conditional on Z = (Z0 , X). Working with this normalized model simplifies the analysis and does not affect its empirical content. Hence, we
drop the tilde and maintain throughout the paper the normalization that U itself is
distributed uniformly over [0, 1] conditional on Z. A consequence of this normalization
is that
p(z) ≡ P (D = 1|Z = z) = FU |Z (ν(z)|z) = ν(z),

(7)

where p(z) is the propensity score.
It is important to observe what is not being assumed under Assumptions I. First, we
do not impose any conditions on the support of Z: Both the control (X) and exogenous
(Z0 ) components of Z may be either continuous, discrete and ordered, categorical, or
binary. Second, the IV model as specified here allows for rich forms of observed and
unobserved heterogeneity. In particular, it allows Y1 − Y0 to vary not only across
individuals with different values of X, but also among individuals with the same X.
The treatment D may be statistically dependent with Y0 (indicating selection bias),
or Y1 − Y0 (indicating selection on the gain), or both, even conditional on X. Third,
the model does not specify why individuals make the treatment choice that they do,
in contrast to a stylized Roy model in which D = 1[Y1 > Y0 ]. However, the model also
does not preclude the possibility that individuals choose treatment with full or partial
knowledge of the potential outcomes (Y0 , Y1 ). Any such knowledge will be reflected

8

through dependence between the potential outcomes, (Y0 , Y1 ), and the unobserved
component treatment choice, U . Assumption I does not restrict this dependence.

2.2

What We Want to Know: The Target Parameter

As observed by Heckman and Vytlacil (1999, 2005), a wide range of treatment parameters can be written as weighted averages of the underlying MTE function. We use a
slight generalization of their observation. Instead of working with the MTE function
(3) directly, we consider treatment parameters that can be expressed as functions of
the two marginal treatment response (MTR) functions, defined as
m0 (u, x) ≡ E [Y0 | U = u, X = x]

m1 (u, x) ≡ E [Y1 | U = u, X = x] .

and

(8)

Of course, each pair m ≡ (m0 , m1 ) of MTR functions generates an associated MTE
function MTE(u, x) ≡ m1 (u, x)−m0 (u, x). One benefit of working with MTR functions
instead of MTE functions is that it allows us to consider parameters that weight m0
and m1 asymmetrically. Another benefit is that it allows the researcher to impose
assumptions on m0 and m1 separately.
We assume that the researcher is interested in a target parameter β ? that can be
written for any candidate pair of MTR functions m ≡ (m0 , m1 ) as
?

Z

β ≡E

1

m0 (u, X)ω0? (u, Z) dµ? (u)



Z
+E

0

1



m1 (u, X)ω1? (u, Z) dµ? (u)

,

(9)

0

where ω0? and ω1? are identified weighting functions, and µ? is an integrating measure
that is chosen by the researcher and usually taken to be the Lebesgue measure on [0, 1].
For example, to set β ? to be the average treatment effect (ATE), observe that
Z

1

E[Y1 − Y0 ] = E[m1 (U, X) − m0 (U, X)] = E


Z
m1 (u, X)du − E

0

1


m0 (u, X)du ,

0

take ω1? (u, z) = 1, ω0? (u, z) = −1, and let µ? be the Lebesgue measure on [0, 1]. Similarly, to set β ? to be the ATE conditional on X lying in some known set X ? , take
ω1? (u, z) ≡ ω1? (u, x, z0 ) =

1[x ∈ X ? ]
,
P (X ∈ X ? )

ω0? (u, z) = −ω1? (u, z), and let µ? be as before. The resulting target parameter is then
the population average effect of assigning treatment randomly to every individual with
covariates x ∈ X ? , assuming full compliance.

9

Table 1: Weights for a Variety of Target Parameters
Weights
Expression

ω0 (u, z) ≡ ω0 (u, x, z0 )

ω1 (u, z) ≡ ω1 (u, x, z0 )

Measure µ?

Average Untreated Outcome

E[Y0 ]

1

0

Leb.[0, 1]

Average Treated Outcome

E[Y1 ]

0

1

Leb.[0, 1]

Average Treatment Effect
(ATE)

E[Y1 − Y0 ]

−1

1

Leb.[0, 1]

Average Treatment Effect
(ATE) given X ∈ X ?

E[Y1 − Y0 |X ∈ X ? ]

?
−ω1
(u, z)

Average Treatment on the
Treated (ATT)

E[Y1 − Y0 |D = 1]

?
(u, z)
−ω1

Average Treatment on the
Untreated (ATU)

E[Y1 − Y0 |D = 0]

?
−ω1
(u, z)

Marginal Treatment Effect at u

E[Y1 − Y0 |U = u]

-1

Local Average Treatment Effect
for U ∈ [u, u] (LATE(u, u))

E[Y1 − Y0 |U ∈ [u, u]]

?
−ω1
(u, z)

Target Parameter

10

Policy Relevant Treatment
Effect (PRTE) for new policy
(p? , Z ? )

E[Y ? ] − E[Y ]
E[D ? ]

− E[D]

?
−ω1
(u, z)

PRTE with Z ? = Z and
p? (z) = p(z) + α

?
−ω1
(u, z)

Proportional PRTE with
magnitude α

PRTE with Z ? = Z and
p? (z) = (1 + α)p(z)

?
−ω1
(u, z)

PRTE with Z ? = Z + αej and
p? (z) = p(z)

?
−ω1
(u, z)

?
?
βA
+ βB

?
?
ωA,0
(u, z) + ωB,0
(u, z)

?
?
Sum of two quantities βA
, βB
with common measure µ?

1[u ≤ p(z)]
Average Selection Bias
Average Selection on the Gain

E[Y0 |D = 1] − E[Y0 |D = 0]
E[Y1 − Y0 |D = 1] − E[Y1 − Y0 |D = 0]

P (D = 1)

−

1[u ≤ p(z)]
P (D = 1)
1[u > p(z)]
P (D = 0)
1

Additive PRTE with magnitude
α

PRTE for an additive α shift of
the j th component of Z

1[x ∈ X ? ]
P (X ∈ X ? )

Leb.[0, 1]

Leb.[0, 1]

Dirac(u)

1[u ∈ [u, u]]
(u − u)
1[u ≤ p? (z ? )] − 1[u ≤ p(z)]
E[p? (Z ? )] − E[p(Z)]
1[u ≤ p(z) + α] − 1[u ≤ p(z)]
α
1[u ≤ (1 + α)p(z)] − 1[u ≤ p(z)]
αE[p(Z)]
1[u ≤ p(z + αej )] − 1[u ≤ p(z)]
E[p(Z + αej )] − E[p(Z)]

Leb.[0, 1]

Leb.[0, 1]

Leb.[0, 1]

Leb.[0, 1]

Leb.[0, 1]

?
?
ωA,1
(u, z) + ωB,1
(u, z)

Common µ?

0

Leb.[0, 1]

1[u > p(z)]
P (D = 0)

?
−ω1
(u, z)

Leb.[0, 1]

1[u ≤ p(z)]
P (D = 1)

−

1[u > p(z)]
P (D = 0)

Leb.[0, 1]

In Table 1, we provide formulas for the weights ω0? and ω1? that correspond to a
variety of different treatment parameters. Any of these can be taken to be the target
parameter β ? . Examples include (i) the average treatment effect for the treated (ATT),
i.e. the average impact of treatment for individuals who actually take the treatment;
(ii) the average treatment effect for the untreated (ATU), i.e. the average impact of
treatment for individuals who do not take treatment; (iii) LATE[u, u], i.e. the average
treatment effect for individuals who would take the treatment if their realization of
the instrument yielded p(z) = u, but not if it yielded p(z) = u; and (iv) the policy
relevant treatment effect (PRTE), i.e. the average impact on Y (either gross or per
net individual affected) due to a change from the baseline policy to some alternative
policy.
For most of the parameters in Table 1, the integrating measure µ? is taken to
be Lebesgue measure on [0, 1]. However, researchers are sometimes interested in the
MTE function itself. For example, Carneiro et al. (2011) and Maestas, Mullen, and
Strand (2013) both report estimates of the MTE function for various values of u. Our
specification of β ? accommodates this by replacing µ? with the Dirac measure (i.e.,
a point mass) at some specified point u and taking ω0? (u, z) = −ω1? (u, z) = −1. The
resulting target parameter is the MTE function averaged over X, i.e. E[m(u, X)].

2.3

What We Know: IV–Like Estimands

A key point for our method is that a set of identified quantities can also be written
in a form similar to (9). Consider, for example, the IV estimand that results from
using Z as an instrument for D in a linear instrumental variables regression that
includes a constant term, but which does not include any other covariates X. Assuming
Cov(D, Z) 6= 0, this estimand is given by
βIV ≡

Cov(Y, Z)
.
Cov(D, Z)

(10)

For example, if Z ∈ {0, 1} is binary, then βIV reduces to the standard Wald estimand
βIV =

E [Y | Z = 1] − E [Y | Z = 0]
.
E [D | Z = 1] − E [D | Z = 0]

(11)

Heckman and Vytlacil (2005) show that βIV can also be written in the form (9) as a
weighted average of the MTE function. This observation forms the foundation for our
intuition that useful information about β ? can be extracted from knowledge of βIV .
The next proposition shows that, more generally, any cross moment of Y with a known
or identified function of (D, Z) ≡ (D, X, Z0 ) can also be expressed as the weighted sum

11

of the two MTR functions, m0 and m1 . We refer to such cross moments as IV–like
estimands.
Proposition 1. Suppose that s : {0, 1} × Rdz 7→ R is a known or identified function of
(D, Z) that is measurable and has a finite second moment. We refer to such a function
s as an IV–like specification and to βs ≡ E[s(D, Z)Y ] as an IV–like estimand. If
(Y, D) are generated according to (1) and (2) under Assumptions I, then
Z
βs = E

1


Z
m0 (u, X)ω0s (u, Z) du + E

0

1


m1 (u, X)ω1s (u, Z) du ,

(12)

0

where ω0s (u, Z) ≡ s(0, Z)1[u > p(Z)]
and ω1s (u, Z) ≡ s(1, Z)1[u ≤ p(Z)].
The weights in Proposition 1 can be shown to reduce to the weights for βIV derived
by Heckman and Vytlacil (2005) by taking
s(d, z) ≡ s(d, x, z0 ) =

z0 − E[Z0 ]
,
Cov(D, Z0 )

(13)

which is an identified function of D (trivially) and Z. As we elaborate further in
Appendix B, Proposition 1 applies more broadly to include any well-defined weighted
linear IV estimand that uses some function of D and Z as included and excluded
instruments for a set of endogenous variables also constructed from D and Z.5 For
example, the ordinary least squares (OLS) estimand corresponds to taking s to be
s(d, z) =

d − E[D]
.
Var(D)

More generally, any subvector of the TSLS or optimal GMM estimands can also be
written as an IV–like estimand. Table 2 contains expressions for some notable IV–like
estimands.

2.4

From What We Know to What We Want to Know

We now show how to extract information about the target parameter β ? from the general class of IV-like estimands introduced in Section 2.3. Let S denote some collection
of IV–like specifications (i.e. functions s : {0, 1} × Rdz 7→ R) chosen by the researcher,
that each satisfy the conditions set out in Proposition 1. Corresponding to each s ∈ S
is an IV–like estimand βs ≡ E[s(D, Z)Y ]. We assume that the researcher has restricted
5

The phrases “included” and “excluded” instrument are meant in the sense typically introduced in
textbook treatments of the linear IV model without heterogeneity.

12

the pair of MTR functions m ≡ (m0 , m1 ) to lie in some admissible set M, which incorporates any a priori assumptions that the researcher wishes to maintain about m, such
as parametric or shape restrictions. Our goal is to characterize bounds on the values
of the target parameter β ? that could have been generated by MTR functions m ∈ M
that also could have delivered the collection of identified IV–estimands through (12).
To this end, we denote the weighting expression in Proposition 1 as a linear map
Γs : M 7→ R, defined for any IV–like specification s ∈ S as
Z
Γs (m) ≡ E

1

1


Z
m0 (u, X)ω0s (u, Z) du + E

0


m1 (u, X)ω1s (u, Z) du ,

(14)

0

where we recall that ω0s (u, z) ≡ s(0, z)1[u > p(z)] and ω1s (u, z) ≡ s(1, z)1[u ≤ p(z)].
By Proposition 1, if (Y, D) are generated according to (1) and (2) under Assumptions
I, then the MTR functions m ≡ (m0 , m1 ) must satisfy Γs (m) = βs for every IV–like
specification s ∈ S. As a result, m must lie in the set
MS ≡ {m ∈ M : Γs (m) = βs for all s ∈ S} .
The target parameter, β ? , can also be expressed as an identified linear map of the
MTR functions. From (9), we define this map as Γ? : M 7→ R, with
?

Z

Γ (m) ≡ E

1



m0 (u, X)ω0? (u, Z)dµ? (u)

Z
+E

0

1



m1 (u, X)ω1? (u, Z)dµ? (u)

. (15)

0

It follows that if (Y, D) is generated according to (1) and (2) under Assumptions I,
then the target parameter must belong to the identified set
BS? ≡ {b ∈ R : b = Γ? (m) for some m ∈ MS }.
Intuitively, BS? is the set of values for the target parameter that could have been
generated by MTR functions that are consistent with the IV–like estimands. The next
result shows that if M is convex, then BS? is an interval that can be characterized by
solving two convex optimization problems.
Proposition 2. Suppose that M is convex. Then either MS is empty, and hence BS?
?

is empty, or else the closure of BS? (in R) is equal to the interval [β ? , β ], where
β ? ≡ inf Γ? (m)
m∈MS

and

?

β ≡ sup Γ? (m).
m∈MS

13

(16)

Table 2: Notable IV–Like Estimands

Estimand

IV slope

IV (jth component)

OLS slope

OLS (jth component)

TSLS (jth component)

2.5

e0j

βs

s(D, Z)

Notes

Cov(Y, Z0 )
Cov(D, Z0 )

Z0 − E[Z0 ]
Cov(D, Z0 )

Z0 scalar

eX
e 0 ]−1 E[ZY
e ]
e0j E[Z

eX
e 0 ]−1 Z
e
e0j E[Z

e ≡ [1, D, X 0 ]0
X
e ≡ [1, Z0 , X 0 ]0
Z
Z0 scalar

Cov(Y, D)
Var(D)

D − E[D]
Var(D)

—

eX
e 0 ]−1 E[XY
e ]
e0j E[X

eX
e 0 ]−1 X
e
e0j E[X

e ≡ [1, D, X 0 ]0
X

eX
e 0 ])−1 ΠZ
e
e0j (ΠE[Z

eZ
e0 ]E[Z
eZ
e0 ]−1
Π ≡ E[X
e
Included variables X
e
Instruments Z


−1 

eX
e 0]
e ]
ΠE[Z
ΠE[ZY

Sharpness and Point Identification

The set MS consists of all MTR functions in M that are consistent with the IV–like
estimands chosen by the researcher. However, MS does not necessarily exhaust all of
the information available in the data. In particular, MS may contain MTR functions
that would be ruled out if S were expanded to include additional IV–like specifications.
If this is the case, then incorporating these further specifications could shrink BS? .
We examine this issue by considering the conditional means of Y that would be
generated through (1) and (2) under Assumptions I by a given MTR pair m = (m0 , m1 ).
Whenever 0 < p(Z) < 1, these conditional means can be written as
Z 1
1
m0 (u, X) du,
(1 − p(Z)) p(Z)
Z p(Z)
1
E[Y |D = 1, Z] = E[Y1 |U ≤ p(Z), Z] =
m1 (u, X) du.
p(Z) 0
E[Y |D = 0, Z] = E[Y0 |U > p(Z), Z] =

and

(17)
(18)

MTR pairs that (almost surely) satisfy (17)–(18) are compatible with the observed
conditional means of Y . Our next result shows that any such MTR pair will be in MS
for any choice of S. Moreover, we show that if S is chosen correctly, then MS will
contain only MTR pairs that are compatible with the observed conditional means of
Y.

14

R1
Proposition 3. Suppose that every m ∈ M satisfies E[ 0 md (u, X)2 du] < ∞ for
d ∈ {0, 1}. If S contains functions that satisfy the conditions of Proposition 1, then
{m ∈ M : m satisfies (17) and (18) almost surely} ⊆ MS .

(19)

Moreover, suppose that S ≡ {s(d, z) = 1[d = d0 ]f (z) for (d0 , f ) ∈ {0, 1} × F}, where
F is a collection of functions. If the linear span of F is norm dense in L2 (Z) ≡ {f :
Rdz 7→ R s.t. E[f (Z)2 ] < ∞}, then
{m ∈ M : m satisfies (17) and (18) almost surely} = MS .

(20)

Proposition 3 shows that if S is a sufficiently rich class of functions, then MS
is sharp in the sense of being the smallest subset of M that is compatible with the
observed conditional means of Y . It follows that BS? is also the smallest set of values
for the target parameter that are consistent with both the conditional means of Y and
the assumptions of the model. For example, if D ∈ {0, 1} and Z ∈ {0, 1}, then (20)
holds if we take F = {1[z = 0], 1[z = 1]}, so that
S = {1[d = 0, z = 0], 1[d = 0, z = 1], 1[d = 1, z = 0], 1[d = 1, z = 1]} .
The information contained in the corresponding IV–like estimands is the same as that
contained in the coefficients of a saturated regression of Y on D and Z. More generally,
if Z is continuous, then (20) can be satisfied by taking F to be certain parametric
families of functions of Z. For example, if Z ∈ Rdz , then one such family is the set of
half spaces, F = {1[z ≤ z 0 ] : z 0 ∈ Rdz }. Other examples can be found in e.g. Bierens
(1990) and Stinchcombe and White (1998).
While we view partial identification as the standard case, we emphasize that our
analysis does not preclude point identification. Letting |S| denote the cardinality of S,
notice that the restrictions
Γs (m) = βs for all s ∈ S

(21)

constitute a linear system of |S| equations in terms of m. Thus, if M is finite dimensional, then point identification of the MTR functions is determined by the rank of this
linear system. Note that if the MTR functions are point identified, then any target
parameter β ? is also point identified.
These observations about point identification are implicit in the work of Brinch et al.
(2015). Those authors show that if M is restricted to be a set of polynomials, then point

15

identification of the MTR functions can be established by considering regressions of Y
on p(Z) and D. Their results allow for Z to be discrete, but require the specification of
M to be no richer than the support of p(Z). For example, if Z is binary, their results
require M to only contain MTR pairs that are linear in u.6 In contrast, our results
allow the researcher to specify M independently of the data.
In some situations, point identification of the target parameter, β ? , can also be
established when both |S| and M are infinite dimensional. Indeed, relationships similar
to (17) and (18) have been used previously to establish point identification of the
MTE function. For example, Heckman and Vytlacil (1999, 2001c, 2005) and Carneiro
et al. (2010, 2011) show that if Z0 is continuously distributed, then the MTE is point
identified over the support of the propensity score. As a consequence, any target
parameter β ? whose weights have support contained within the interior of the support
of the propensity score will also be point identified. Proposition 3 implies that the same
is true in our framework if S is chosen to be a sufficiently rich collection of functions.

2.6

Nonparametric Shape Restrictions

Our method allows researchers to easily incorporate nonparametric shape restrictions
into their specification of the MTR functions. These restrictions can be imposed either
on the MTR functions m = (m0 , m1 ) or directly on the MTE function m1 − m0 .
For example, to impose the monotone treatment response assumption considered by
Manski (1997), i.e. that Y1 ≥ Y0 with probability 1, the set M should be specified
to only contain MTR pairs for which m1 − m0 is non-negative. Similarly, one could
assume that m(·, x) is weakly decreasing for every x. This restriction would reflect the
assumption that those more likely to select into treatment (those with small realizations
of U ) are also more likely to have larger gains from treatment. This is similar to the
monotone treatment selection assumption of Manski and Pepper (2000). Maintaining
combinations of assumptions simultaneously (e.g. both monotone treatment response
and monotone treatment selection) is simply a matter of imposing both restrictions on
M at the same time.
Another type of nonparametric shape restriction that can be used to tighten the
bounds is separability between the observed (X) and unobserved (U ) components.
Although restrictive, separability of this sort is standard (often implicit) in applied
work using instrumental variables. In our framework, separability between X and U
can be imposed by restricting M to only contain MTR pairs (m0 , m1 ) that can be
6

Recently, Kowalski (2016) has applied the linear case, studied in depth by Brinch et al. (2015), to
analyze the Oregon Health Insurance Experiment.

16

decomposed as
X
md (u, x) = mU
d (u) + md (x)

for d = 0, 1,

(22)

X
where mU
d and md are some other functions that can themselves satisfy some shape

restrictions. This type of separability implies that the slopes of the MTR functions
with respect to u do not vary with x. Alternatively, it is straightforward to interact u
and x fully or partially if complete separability is viewed as too strong of a restriction.
Specifications like (22) can also be used to mitigate the curse of dimensionality, for
example by specifying mX
d (x) to be a linear function of x.

2.7

Computing the Bounds

Proposition 2 provides convenient numerical methods for computing bounds on the
target parameter. In this section, we focus on a particularly tractable computational
approach in which we replace the possibly infinite dimensional admissible set of functions M by a finite dimensional subset Mfd ⊆ M. The upper bound for the target
parameter with this finite dimensional subset is given by
?

β fd ≡ sup {Γ? (m) s.t. Γs (m) = βs for all s ∈ S},

(23)

m∈Mfd

while β ?fd is defined as the analogous infimum.
Suppose that we specify Mfd as the finite linear basis
(
Mfd ≡

(m0 , m1 ) ∈ M : md (u, x) =

Kd
X

)
θdk bdk (u, x) for d ∈ {0, 1} ,

(24)

k=1
0
0 0
d
where {bdk }K
k=1 are known basis functions and θ ≡ (θ0 , θ1 ) parameterizes functions in

Mfd with θd ≡ (θd1 , . . . , θdKd )0 . The admissible set M generates an admissible set
(
Θ≡

K0

(θ0 , θ1 ) ∈ R

K1

×R

:

K0
X
k=1

θ0k b0k ,

K1
X

!
θk1 b1k

)
∈M ,

k=1

for the finite dimensional parameter θ. Using the linearity of the mappings Γ? and Γs

17

defined in (14) and (15), we write (23) as
?
β fd

≡

sup

K0
X

θ0k Γ?0 (b0k )

(θ0 ,θ1 )∈Θ k=1

s.t.

K0
X

+

K1
X

θ1k Γ?1 (b1k )

k=1
K1
X

θ0k Γ0s (b0k ) +

k=1

θ1k Γ1s (b1k ) = βs for all s ∈ S,

(25)

k=1

where we have decomposed Γ? (m) ≡ Γ?0 (m0 ) + Γ?1 (m1 ) with
Γ?d (md ) ≡ E

Z

1


md (u, X)ωd? (u, Z)dµ? (u) ,

0

and similarly for the map Γs . If Θ is a polyhedral set, then (25) is a linear program.
Linear programs are used routinely in empirical work involving quantile regressions, e.g.
Abadie, Angrist, and Imbens (2002), in part because they can be solved quickly and
reliably. Whether a given shape restriction on M translates into Θ being polyhedral
depends on the basis functions. In Appendix F, we discuss the Bernstein polynomial
basis, which is particularly attractive in this regard.
In some situations, M can be replaced by a finite dimensional set Mfd without
?

?

affecting the bounds on the target parameter, i.e. while ensuring β fd = β . This
can be interpreted as an exact computational approach for determining nonparametric
bounds on the target parameter. For example, suppose that Z has discrete support
and that the weight functions ωd? (u, z) for the target parameter are piecewise constant
in u. Then define a partition {Aj }Jj=1 of [0, 1] such that ωd? (u, z) and 1[u ≤ p(z)] are
constant (as functions of u) on each Aj .7 Let {x1 , . . . xL } denote the support of X and
then use
bjl (u, x) ≡ 1[u ∈ Aj , x = xl ] for 1 ≤ j ≤ J and 1 ≤ l ≤ L

(26)

as the basis functions employed in the construction of Mfd in (24), with Kd = JL.
The basis formed by the functions defined in (26) is known as a constant spline, or a
Haar basis.
The element of the Haar basis that provides the best mean squared error approximation to a given function md (u, x) can be shown to be
Πmd (u, x) ≡

J X
L
X

E[md (U, X)|U ∈ Aj , X = xl ]bjl (u, x).

(27)

j=1 l=1
7

For example, take A1 ≡ [u0 , u1 ] and Aj ≡ (uj−1 , uj ] for 2 ≤ j ≤ J, where {uj }Jj=0 are the ordered
unique elements of the union of {0, 1}, supp{p(Z)}, and the discontinuity points of {ωd? (·, z) : d ∈ {0, 1}, z ∈
supp{Z}}.

18

This corresponds to taking θd(j,l) = E[md (U, X)|U ∈ Aj , X = xl ] for an element of
(24), with the slight abuse of notation that k = (j, l). The next proposition uses (27)
to show that the Haar basis, despite being a finite basis, reproduces nonparametric
bounds on the target parameter.
Proposition 4. Suppose that Z has discrete support and that ωd? (u, z) are piecewise
constant in u. Let {Aj }Jj=1 be a partition of [0, 1] such that ωd? (u, z) and 1[u ≤ p(z)]
are constant on u ∈ Aj for any z. Suppose that Mfd ⊆ M and that (Πm0 , Πm1 ) ∈ M
?

?

for every (m0 , m1 ) = m ∈ M. Then β fd = β and β ?fd = β ? .
Proposition 4 shows that one can solve the infinite dimensional problems defining
?

?

β and β exactly by solving (23) with a Haar basis for Mfd . Besides requiring Z to
have discrete support, the result also requires (Πm0 , Πm1 ) ∈ M for every m ∈ M,
as well as Mfd ⊆ M. Intuitively, this requires an MTR pair formed from the Haar
basis to itself be admissible, as well as to maintain the restrictions encoded in M. For
certain restrictions, such as boundedness or monotonicity, this is immediately implied
by (27). We demonstrate the use of the Haar basis in both the numerical illustration
in Section 4 and the empirical application in Section 6.

3

Applications of the Method

3.1

Partial Identification of Policy Relevant Treatment Effects

The policy relevant treatment effect (PRTE) is the mean effect of changing from a
baseline policy to an alternative policy that provides different incentives to participate
in treatment (Heckman and Vytlacil, 1999, 2005). In many situations, this policy
comparison does not directly correspond to the variation in treatment induced by the
instrument, so the PRTE is not point identified. In such cases, researchers can use our
method to construct bounds on the PRTE.
To see how one can use our method to draw inference about PRTEs, consider a
policy a that operate by changing factors that affect an agent’s treatment decision.
We follow Heckman and Vytlacil (1999, 2005) in assuming that a has no direct effect
on the potential outcomes (Y0 , Y1 ), and in particular that it does not affect the set M
of admissible MTR functions. This assumption is similar to the exclusion restriction.
The policy can then be summarized by a propensity score and instrument pair (pa , Z a ).
Treatment choice under policy a is given by
Da ≡ 1[U ≤ pa (Z a )],

19

where U is the same unobservable term as in the selection equation for the status quo
policy, D. The outcome of Y that would be observed under the new policy is therefore
Y a = Da Y1 + (1 − Da )Y0 .
The PRTE of policy a1 relative to another policy a0 is defined as
PRTE ≡

E[Y a1 ] − E[Y a0 ]
E[Da1 ] − E[Da0 ]

(28)

where we assume that E[Da1 ] 6= E[Da0 ].8
In Table 1, we provide weights ω0? and ω1? that can be used to express the PRTE as
a target parameter β ? with the form given in (9) for different policies a0 and a1 . The
choice of weights depends on the policies being compared. The way in which different
policy comparisons translate into different weights is illustrated in Table 1 through the
three specific examples considered by Carneiro et al. (2011). Each of these comparisons
is between a hypothetical policy a1 and the status quo policy a0 , the latter of which
is characterized by the pair (pa0 , Z a0 ) = (p, Z) observed in the data. The comparisons
are: (i) an additive α change in the propensity score, i.e. pa1 = p+α; (ii) a proportional
(1 + α) change in the propensity score, i.e. pa1 = (1 + α)p; and (iii) an additive α shift
in the distribution the jth component of Z, i.e. Z a1 = Z + αej , where ej is the jth
unit vector. The first and second of these represent policies that increase (or decrease)
participation in the treatment by a given amount α or a proportional amount (1 + α).
The third policy represents the effect of shifting the distribution of a variable that
impacts treatment choice. In all of these definitions, α is a quantity that could either
be hypothesized by the researcher, estimated from some auxiliary choice model, or
predicted from the estimated p(Z) under parametric assumptions.
After choosing the weights that correspond to the policy comparison of interest, the
procedure in Section 2.7 can be used to estimate bounds for the PRTE. These bounds
can be fully nonparametric, but they can also incorporate a priori parametric or shape
restrictions if desired. Our statistical inference results in Section 5 allow us to build
confidence intervals for the target parameter. In Section 6, we apply these insights to
evaluate the PRTEs of alternative subsidy regimes for malaria bed nets.
8

If this assumption is concerning, one can also define the PRTE as E[Y a1 ] − E[Y a0 ], see Heckman and
Vytlacil (2001a) or pp. 380–381 of Carneiro et al. (2010). Our approach directly applies to this definition
as well.

20

3.2

Extrapolation of Local Average Treatment Effects

Imbens and Angrist (1994) showed that the LATE is point identified under the assumptions considered in this paper. As argued by Imbens (2010, pp. 414–415), it is desirable
to report both the LATE, with its high degree of internal validity, but possibly limited
external validity, and extrapolations of the LATE to larger or different populations.
We now show how to use our method to perform this type of extrapolation, thereby
allowing researchers to assess the sensitivity of a given LATE estimate to an expansion
(or contraction) of the complier subpopulation.
To extrapolate the LATE, it is useful to connect the LATE parameter to the PRTE.
To see the relationship, suppose that there are no covariates X, i.e. Z = Z0 , and
suppose that Z0 is binary. Consider the PRTE that results from comparing a policy
a1 under which every agent receives Z = 1 against a policy a0 under which every agent
receives Z = 0. Choices under these policies are
Da0 ≡ 1[U ≤ p(0)]

and

Da1 ≡ 1[U ≤ p(1)],

where p(1) > p(0) are the propensity score values in the observed data. The PRTE for
this policy comparison is
E [(Da1 − Da0 )(Y1 − Y0 )]
E[Y a1 ] − E[Y a0 ]
= E [Y1 − Y0 | U ∈ (p(0), p(1)]] , (29)
=
E[Da1 ] − E[Da0 ]
p(1) − p(0)
where we used Da1 − Da0 = 1[U ∈ (p(0), p(1)]]. The right-hand side of (29) is precisely
the LATE as defined by Imbens and Angrist (1994).
Extrapolation of the LATE amounts to changing p(0), p(1), or both. For example,
suppose that the researcher wants to examine the sensitivity of the LATE to an expansion of the complier subpopulation that includes individuals with lower willingness
to pay for treatment. This sensitivity check corresponds to shifting p(1) to p(1) + α
for α > 0. Arguing as in (29), the extrapolated LATE can be shown to be
PRTE(α) = E [Y1 − Y0 | U ∈ (p(0), p(1) + α]] .

(30)

This PRTE is still a LATE as defined by Heckman and Vytlacil (2005), but one that
is not point identified by the IV estimand unless α = 0.
While PRTE(α) is not point identified, we show in Table 1 that it can be expressed
as a target parameter β ? in the form (9). As a result, we can use our approach to

21

bound PRTE(α). To gain some intuition into such approach, we write PRTE(α) as
PRTE(α)


 Z p(1)+α

α
p(1) − p(0)
LATE +
{m1 (u) − m0 (u)} du,
=
α + p(1) − p(0)
α + p(1) − p(0)
p(1)
where LATE is the usual point identified LATE in (29). This decomposition shows
that the conclusions that can be drawn about PRTE(α) depend on what can be said
about m1 (u) − m0 (u) for u ∈ [p(1), p(1) + α]. Therefore, restrictions on the set M
of admissible MTR pairs translate directly into restrictions on the possible values of
PRTE(α). For example, if we possess an a priori bound on the support of Y , e.g. Y is
binary, then even nonparametric bounds can be informative about PRTE(α).
Our method allows a researcher to formally and transparently balance their desire for robust assumptions against their desire for broader extrapolation. Stronger
assumptions are reflected through a more restrictive set of admissible MTR pairs, M.
Less ambitious extrapolations are reflected through smaller values of α. For a given α,
more restrictive specifications of M yield smaller bounds, while for a given specification
of M, smaller values of α also yield smaller bounds. Both margins can be smoothly
adjusted, with point identification obtained as a limiting case as α → 0. We illustrate
this tradeoff in our numerical example in Section 4.

3.3

Testable Implications

If the set MS is empty, then the model is misspecified: There does not exist a pair of
MTR functions m that is both admissible (m ∈ M), and which could have generated
the observed data. If M is an unrestricted class of functions, then this is attributable
to a falsification of selection equation (2) together with Assumptions I. The testable
implications of these assumptions for the IV model are well-known, see e.g. Balke and
Pearl (1997), Imbens and Rubin (1997) or Kitagawa (2015). On the other hand, if
other restrictions have been placed on M, then misspecification could be due either to
the failure of Assumptions I, or the specification of M, or both. Our inference results
in Section 5 provide a formal test of the null hypothesis that MS is nonempty.
This test can also be used to test a variety of null hypotheses about the underlying
MTR functions. For example, Table 1 reports the weights that correspond to the
quantity E[Y0 |X, D = 1] − E[Y0 |X, D = 0]. This quantity is often described as a
measure of selection bias, since it captures the extent to which average untreated
outcomes differ solely on the basis of treatment status, conditional on observables.
? (m) for the amount of selection bias under
The weights provide a linear mapping βsel

22

an MTR pair m. Suppose that we restrict M to contain only MTR pairs m for
? (m) = 0. Then rejecting the null hypothesis that M is nonempty could be
which βsel
S

interpreted as rejecting the hypothesis that there is no selection bias, at least as long
as Assumptions I and any other restrictions on M are not deemed suspect.
Alternatively, one might be interested in testing the joint hypothesis that there is
no selection on unobservables; that is, no selection bias and no selection on the gain.
Weights for a typical measure of selection on the gain are provided in Table 1. These
?
too provide a linear mapping βgain
on the set of MTR pairs M. The hypothesis that

there is no selection on unobservables would be rejected if we were to reject the null
hypothesis that MS is nonempty when M is restricted to contain only MTR pairs m
? (m) = β ? (m) = 0.
for which βsel
gain

4

Numerical Illustration

In this section, we illustrate how to use our method to construct nonparametric bounds
on treatment parameters of interest, and how shape restrictions and parametric assumptions can be used to tighten these bounds.

4.1

The Data Generating Process

We consider a simple example with a trinary instrument, Z ∈ {0, 1, 2}, with P (Z =
0) = .5, P (Z = 1) = .4, and P (Z = 2) = .1. The propensity score is specified as
p(0) = .35, p(1) = .6, and p(2) = .7. We take the outcome Y ∈ {0, 1} to be binary and
restrict M to contain only MTR pairs that are each bounded between 0 and 1. The
data is generated using the MTR functions
m0 (u) = .6b20 (u) + .4b21 (u) + .3b22 (u)
and m1 (u) = .75b20 (u) + .5b21 (u) + .25b22 (u),

(31)

where b2k is the kth Bernstein basis polynomial of degree 2.9

4.2

IV Estimand, Weights, and Parameter of Interest

Figure 1 contains two plots with two vertical axes. The left plot is for d = 0, while
the right plot is for d = 1, and both vertical axes apply to both plots. The left axis
measures weight functions, which are indicated with colored curves and, for the sake of
clarity, are not drawn over regions where they are zero. The blue weights correspond
9

Appendix F contains the definition of the Bernstein polynomials, along with a discussion of some useful
properties of the Bernstein polynomial basis.

23

Figure 1: MTRs Used in the Data Generating Process (DGP)
Weights
(where 6= 0)

MTR

d=1

d=0

1
4
0.75

2
0

0.5

−2

0.25

−4
0

0.2

0.4

0.6

0.8

1

0

0.2

u
DGP MTRs

LATE(0.35, 0.90)

0.4

0.6

0.8

u
IV slope

to ωds when s(D, Z) is taken to be (13) so that βs is the IV slope coefficient estimand
(10) from using Z as an instrument for D. These weights are positive between the
smallest and largest values of the propensity score, i.e. from p(0) = .35 to p(2) = .7,
and they change value at p(1) = .6.
As shown by Imbens and Angrist (1994), three LATEs are nonparametrically point
identified in this setting: LATE(.35, .6), LATE(.35, .7) and LATE(.6, .7). Suppose that
the researcher wants to examine the sensitivity of these average causal effects to an
expansion of the complier subpopulation. Then they might be interested in the target
parameter
LATE(.35, .9) ≡ E [Y1 − Y0 |U ∈ [.35, .9]] .
The weights for this parameter are drawn in red in Figure 1. As shown in Table 1, the
weights are constant over [.35, .9] with magnitude (.9 − .35)−1 ≈ 1.81.
The right vertical axis in Figure 1 measures MTR functions for both the d = 0 and
d = 1 plots. The MTR functions that were used to generate the data, i.e. (31), are
plotted in black. These MTR functions imply a value of approximately .074 for the IV
slope coefficient. By Proposition 1, this value is equal to the integral of the product
of the black and blue curves, summed over the d = 0 and d = 1 plots. Similarly,
these MTR function imply a value of approximately .046 for LATE(.35, .9) through an
analogous sum of integrals using the red curves.

24

1

0

Figure 2: Maximizing MTRs When Using Only the IV Slope Coefficient
Nonparametric bounds: [-0.421,0.500]
Weights
(where 6= 0)

MTR

d=1

d=0

1
4
0.75

2
0

0.5

−2

0.25

−4
0

0.2

0.4

0.6

0.8

1

0

0.2

u
Maximizing MTRs

4.3

LATE(0.35, 0.90)

0.4

0.6

0.8

1

0

u
IV slope

Bounds on the Target Parameter

We now illustrate how the researcher can extract information about the target parameter LATE(.35, .9) from the class of IV-like estimands introduced in Section 2.3.
Figure 2 is like Figure 1, except the MTR functions that are plotted yield the
nonparametric upper bound on LATE(.35, .9). The nonparametric upper bounds are
computed using the Haar basis discussed in Section 2.7.10 The pair m ≡ (m0 , m1 ) in
this plot is generated by trying to make m1 as large as possible, and m0 as a small
as possible, on the support of the red weights, while still yielding a value of .074 for
the IV slope coefficient determined by the blue weights. These MTR functions imply
a value of .5 for the target parameter LATE(.35, .9), which is the largest value that is
consistent with the IV slope estimand. There are multiple pairs of MTR functions with
this property. In particular, notice that neither weights are positive over the region
[0, .35], so that MTR pairs may be freely adjusted on this region without changing the
implied values of the IV slope estimand or LATE(.35, .9). The lower bound of −.421
indicated in Figure 2 is obtained through an analogous minimization problem that
follows the same logic as the upper bound.
Figure 3 repeats this exercise while including a second IV–like estimand. The second
10

As discussed in Section 2.7, this amounts to solving two linear programs. We used Gurobi (Gurobi Optimization, 2015) to solve all linear programs reported in the paper.

25

Figure 3: Maximizing MTRs When Using Both the IV and OLS Slope Coefficients
Nonparametric bounds: [-0.411,0.500]
Weights
(where 6= 0)

MTR

d=1

d=0

1
4
0.75

2
0

0.5

−2

0.25

−4
0

0.2

0.4

0.6

0.8

u
Maximizing MTRs

1

0

0.2

0.4

0.6

0.8

1

0

u
LATE(0.35, 0.90)

IV slope

OLS slope

Figure 4: Maximizing MTRs When Breaking the IV Slope into Two Components
Nonparametric bounds: [-0.320,0.407]
Weights
(where 6= 0)

MTR

d=1

d=0
6

1

4
0.75
2
0

0.5

−2
0.25
−4
−6

0

0.2

0.4

u
Maximizing MTRs

0.6

0.8

0

1

0.2

0.4

0.6

0.8

1

u
LATE(0.35, 0.90)

IV slope (1[Z = 2])

26

IV slope (1[Z = 3])

0

Figure 5: Maximizing MTRs When Using All IV–like Estimands (Sharp Bounds)
Nonparametric bounds: [-0.138,0.407]
Weights
(where 6= 0)

MTR

d=1

d=0

1
2
0.75
0.5

0

0.25
−2
0

0.2

0.4

0.6

u
Maximizing MTRs
(1 − D)1[Z = 3]

0.8

1

0

0.2

0.4

0.6

0.8

u
LATE(0.35, 0.90)
D1[Z = 1]

(1 − D)1[Z = 1]
D1[Z = 2]

(1 − D)1[Z = 2]
D1[Z = 3]

estimand is the OLS slope coefficient, whose weights are drawn in light blue. Notice
that, whereas the blue and red weights are symmetric between d = 0 and d = 1 in the
sense of having different signs, but the same magnitude, the light blue weights for the
OLS slope coefficient are asymmetric. A maximizing or minimizing MTR pair must
yield the implied values for both the IV slope coefficient and the OLS slope coefficient,
which is approximately .253 in the simulation. In this DGP, the additional constraint
from the OLS slope coefficient has no effect on the upper bound of LATE(.35, .9), but
does tighten the lower bound slightly from −.421 to −.411. In Figure 4, instead of
using Z as a single instrument, we split Z into two binary indicators, 1[Z = 2] and
1[Z = 3], to create two IV slope estimands. This tightens both bounds on LATE(.35, .9)
considerably. The tightest possible nonparametric bounds are obtained in Figure 5,
which includes a collection of six IV–like specifications that is rich enough to satisfy
the conditions of Proposition 3. The resulting bounds of [−.138, .407] are the sharp
nonparametric bounds for LATE(.35, .9).
The bounds in Figure 5 can be tightened considerably by imposing nonparametric
shape restrictions. For example, in Figure 6, the MTR functions are restricted to be
decreasing like the DGP MTR functions shown in Figure 1. This tightens the sharp
identified set for LATE(.35, .9) by ruling out non-decreasing MTR pairs like the one
shown in Figure 5.

27

1

0

Figure 6: Maximizing MTRs When Restricted to be Decreasing
Nonparametric bounds, MTRs decreasing: [-0.095,0.077]
Weights
(where 6= 0)

MTR

d=1

d=0

1
2
0.75
0.5

0

0.25
−2
0

0.2

0.4

0.6

u
Maximizing MTRs
(1 − D)1[Z = 3]

0.8

1

0

0.2

0.4

0.6

0.8

u
LATE(0.35, 0.90)
D1[Z = 1]

(1 − D)1[Z = 1]
D1[Z = 2]

(1 − D)1[Z = 2]
D1[Z = 3]

Even tighter bounds can be obtained by also requiring the MTR functions to be
smooth. This may be a desirable a priori assumption if one believes that the jumpdiscontinuous MTR pairs in Figure 6 are sufficiently poorly behaved as to be an unlikely
description of the relationship between selection unobservables, U , and potential outcomes, Y0 and Y1 . For example, in Figure 7, the MTR functions are restricted to be
decreasing and characterizable by a polynomial of order 10 or lower. This eliminates
the possibility of non-smooth MTR functions like those in Figure 6, and in this example
reduces the bounds to [0, 0.067].

4.4

Tradeoffs between Tightness and the Target Parameter

Figure 8 illustrates how the bounds change as the parameter of interest changes. In
particular, instead of LATE(.35, .9), we construct bounds on
LATE(.35, u) ≡ E [Y1 − Y0 |U ∈ [.35, u]] ,
for different values of u, using the same specification as in Figure 7. Sharp lower and
upper bounds on this parameter are given by the blue and red curves, respectively.
As evident from Figure 8, the bounds collapse to a point for u = .6 and .7, i.e the
two other points of support for the propensity score. For these values of u, LATE(.35, u)

28

1

0

Figure 7: Maximizing MTRs When Further Restricted to be a 10th Order Polynomial
Order 9 polynomial bounds, MTRs decreasing: [0.000,0.067]
Weights
(where 6= 0)

MTR

d=1

d=0

1
2
0.75
0.5

0

0.25
−2
0

0.2

0.4

0.6

u
Maximizing MTRs
(1 − D)1[Z = 3]

0.8

1

0

0.2

0.4

0.6

0.8

u
LATE(0.35, 0.90)
D1[Z = 1]

(1 − D)1[Z = 1]
D1[Z = 2]

(1 − D)1[Z = 2]
D1[Z = 3]

is a usual point identified LATE as in Imbens and Angrist (1994). For other values of
u this parameter is not point identified, such as for u = .9, which is indicated by the
dotted vertical line. For u between .6 and .7 the bounds are very tight, as shown in
the magnified region. As u decreases from .6 or increases above .7, the bounds widen.
This reflects the increasing difficulty of drawing inference about a parameter the more
dissimilar it is from what was observed in the data.

5

Statistical Inference

In this section, we develop a general testing procedure that enables us to conduct
statistical inference for the methods and applications described in Sections 2 and 3.

5.1

Notation and Null Hypothesis

Our results will be sufficiently flexible to allow for possible nonparametric specifications
of M, potentially with additional shape restrictions, as well as a finite or infinite
collection of IV–like specifications, S. To accommodate these possibilities formally,
we abstract from finite dimensional Euclidean spaces and work with general complete
normed vector spaces, i.e. Banach spaces. For the MTR functions, we assume that M
is a subset of a Banach space M with norm k · kM .

29

1

0

5

Figure 8: Bounds on a Family of PRTEs

Upp
Low
Act

Bounds on LATE(.35, u)
Upper Bound
Lower Bound
Actual Value

.125
.1
.075
.05
.025
0
−.025

.4

.45

.5

.55

.6

.65

.7

.75

.8

.85

.9

.95

1

u

For the IV–like estimands, we identify the relationship between βs and its specification s ∈ S with a function s 7→ βs that maps each s ∈ S into βs ≡ E[s(D, Z)Y ]. As
a notational device, it will sometimes be convenient to extend the domain of the map
s 7→ βs . For example, when testing whether a target parameter β ? ∈ R is equal to
zero, we let β ≡ {βs : s ∈ S} ∪ {0} so that β then represents the collection of IV–like
estimands together with the hypothesized value for the target parameter. On the other
hand, when conducting a specification test, we only need to set β = {βs : s ∈ S}. As
another example, if we were testing the joint hypothesis of no unobserved heterogeneity, we might augment β with two additional elements—one for selection bias and the
other for selection on the gain—as per our discussion in Section 3.3. In order to accommodate these different applications, as well as a finite or infinite number of IV–like
specifications S, we will view β as an element of a Banach space B with norm k · kB .
A primary concern in our development of a statistical procedure is uniform validity
in the underlying distribution of the data. As argued by Imbens and Manski (2004),
uniformity considerations are of particular concern when conducting inference in the

.5

.55

.6

.65

.7

.75

.8

presence of partial identification. In order to discuss uniformity formally, we now
explicitly denote the dependence of various quantities on the distribution of the data,

u

P . So, for example, we now write the IV–like estimand βs ≡ E[s(D, Z)Y ] as βP,s to
emphasize its dependence on the distribution of (Y, D, Z). Similarly, we now write β

30

.85

.

with a subscript as βP . We assume that P lies in a set P of possible distributions
which satisfy regularity conditions that are introduced subsequently.
As discussed in Section 2, both the IV–like estimands and the target parameter are
linear functions of the admissible MTR pair m = (m0 , m1 ) ∈ M ⊆ M. We denote
these linear functions by a single map ΓP : M 7→ B. For example, if S = {s1 , . . . , s|S| }
is finite and βP = (βP,s1 , . . . , βP,s|S| )0 , then B = R|S| and
ΓP (m) ≡ (ΓP,s1 (m), . . . , ΓP,s|S| (m))0 ,
where ΓP,s is as defined in (14), but now carries a P subscript to emphasize its dependence on the distribution of the data. To test whether a target parameter is equal to
a given hypothesized value β0? , we let βP = (βP,s1 , . . . , βP,s|S| , β0? )0 and
ΓP (m) ≡ (ΓP,s1 (m), . . . , ΓP,s|S| (m), Γ?P (m))0 ,

(32)

where Γ?P is as defined in (15), but now carries a P subscript as well.
Given the flexibility of the parameter βP ∈ B and the map ΓP : M 7→ B, we can
encompass the applications discussed in Section 3 as special cases of the null hypothesis
H0 : P ∈ P0

H1 : P ∈ P \ P0 ,

(33)

where the set P0 is defined as
P0 ≡ {P ∈ P : ΓP (m) = βP for some m ∈ M}.

(34)

The set P0 consists of distributions of the observed data for which there exists an
admissible MTR pair that generates βP . In the following, we propose a test of (33)
that provides uniform size control over the set of distributions P.
By specifying βP appropriately, we can use our test of (33) for a variety of purposes.
For example, a confidence region for a target parameter can be obtained by setting ΓP
as in (32) and conducting test inversion of (33) for βP = ((βP,s1 , . . . , βP,s|S| , β0? )0 over
different hypothesized values β0? of the target parameter. Alternatively, to conduct a
specification test that employs an infinite collection of moments, we would let βP =
{βP,s : s ∈ S} and ΓP (m) = {ΓP,s (m) : s ∈ S}.11
11

We discuss this application more formally in Example 5.2.

31

5.2

The Test Statistic

The applications in Section 3 highlight both the wide array of empirically relevant
hypotheses encompassed by (33) and the importance of being flexible in the definitions
of βP ∈ B and M ⊆ M. To ensure that our general results apply to such examples,
we will simply assume that we posses estimators β̂ ∈ B for the parameter βP and
Γ̂ : M 7→ B for the map ΓP : M 7→ B. Given such estimators, we then construct a
minimum distance test statistic for the null hypothesis in (33) as
Tn ≡ inf

m∈Mn

√

nkβ̂ − Γ̂(m)kB ,

(35)

where Mn is a subset of M that grows dense in M. When M is finite dimensional,
we can set Mn = M. We note that, provided Γ̂ is linear and Mn is convex, as they
are in our applications of interest, Tn is the solution to a convex optimization problem.
In Appendix G.2, we describe situations in which (35) can be reformulated as a linear
program.
Our analysis uses some properties of convex sets. In order to introduce these properties, we need some additional notation. Let B∗ denote the dual space of B, i.e.
B∗ ≡ {b∗ : B 7→ R s.t. b∗ is linear and continuous},
endowed with the norm kb∗ kB∗ ≡ supkbkB ≤1 |b∗ (b)|. By definition, every b∗ ∈ B∗ is a
linear map on B. Note too, that every b ∈ B also induces a linear map on B∗ given by
b∗ 7→ b∗ (b). We emphasize this bilinear relationship with the notation hb∗ , bi ≡ b∗ (b).
The weak topology on B is then the weakest topology under which all of the linear
maps b∗ ∈ B∗ (i.e. all hb∗ , ·i) are continuous. The weak topology is important for our
purposes because it arises naturally in the study of both linear maps and convex sets.
Let M∗ denote the dual space of M. The adjoint of a linear map ΓP : M 7→ B is
defined as the unique linear map Γ∗P : B∗ 7→ M∗ that satisfies
hb∗ , ΓP (m)i = hΓ∗P (b∗ ), mi

(36)

for every b∗ ∈ B∗ and m ∈ M. For example, if M = Rdm and B = Rdβ , then ΓP can
be identified with a dβ × dm matrix, and its adjoint Γ∗P is simply its dm × dβ transpose.
Similarly, we denote the adjoint of Γ̂ as Γ̂∗ . If ΓP : M 7→ B is continuous, then the
bilinear maps (b∗ , m) 7→ hb∗ , ΓP (m)i and (b∗ , m) 7→ hΓ∗P (b∗ ), mi are bounded on any

32

bounded subsets D × M ⊂ B∗ × M. Hence, these maps are elements of
(
∞

` (D × M) ≡

)

f : D × M 7→ R s.t.

|f (b, m)| < ∞ .

sup

(37)

(b,m)∈D×M

For our purposes, it will be useful to let D be the unit ball in B∗ , so we define
D ≡ {b∗ ∈ B∗ : kb∗ kB∗ ≤ 1}.
Intuitively, one can interpret b∗ ∈ D as a “direction” in the original space B.
For any convex set C ⊆ B, we define its support function ν(·, C) : D 7→ R as
ν(b∗ , C) ≡ suphb∗ , bi.

(38)

b∈C

Intuitively, ν(b∗ , C) indicates how far one can move in the direction b∗ while staying
within the set C. Letting Γ̂(Mn ) ≡ {b ∈ B : b = Γ̂(m) for some m ∈ Mn }, we obtain
by duality (see, e.g., Theorem 5.13.1 of Luenberger (1969))
Tn = sup

b∗ ∈D

o
√ n ∗
n hb , β̂i − ν(b∗ , Γ̂(Mn )) = sup

inf

b∗ ∈D m∈Mn

o
√ n ∗
n hb , β̂ − Γ̂(m)i .

(39)

In other words, the minimum distance test statistic Tn can also be computed by finding
the direction b∗ ∈ D for which β̂ is the farthest away from its projection onto Γ̂(Mn ).
We will heavily rely on the dual characterization in (39) in our analysis.
We illustrate our results with two examples that we will return to throughout our
discussion. The first example is extremely simple and intended to exposit the nature
of our statistical approximations, while the second example uses infinite dimensional
spaces, and is used to clarify the more abstract aspects of our analysis.
Example 5.1. Suppose that there are no covariates (Z = Z0 ), Y ∈ {0, 1} is binary, we
have chosen a single IV–like specification (S = {s}), and we have modeled the MTR
functions as md (u) = θd u for θd ∈ R and d = 0, 1. A given MTR function (m0 , m1 ) is
then fully characterized by a pair (θ0 , θ1 ). Therefore, we set M = R2 and define
M ≡ {(θ0 , θ1 ) ∈ R2 : θd ∈ [0, 1] for d ∈ {0, 1}},

(40)

where the restriction θd ∈ [0, 1] reflects Y ∈ {0, 1}. Suppose that our goal is to test
whether the specified model is compatible with the single chosen IV–like restriction
(recall S = {s}). To do this, we set B = R, so that βP = E[s(D, Z)Y ], and use some

33

calculus to write the map ΓP : R2 7→ R as
X

ΓP (m) =

Z
E

=


θd u ωds (u, Z) du

0

d∈{0,1}

"

1

1
2
2 E[s(0, Z)(1 − p (Z))]
1
2
2 E[s(1, Z)p (Z)]

#0 " #
θ0
θ1

≡

"
#0 " #
ΓP,0
θ0
ΓP,1

θ1

≡ ΓP θ.

(41)

Hence, the linear map ΓP is just the two dimensional row vector ΓP ≡ (ΓP,0 , ΓP,1 )
defined in (41). Given a parametric or nonparametric estimator p̂(Z) for p(Z), we
then set β̂ ∈ R to be the sample analog of E[s(D, Z)Y ] and take Γ̂ ≡ (Γ̂0 , Γ̂1 ) ∈ R2 to
be the sample analog of ΓP . For this example, the duality result in (39) states that
n√

o
n|β̂ − Γ̂(m)| s.t. θd ∈ [0, 1]
m=(θ0 ,θ1 )0
n√
o
= sup inf
nb∗ (β̂ − θ0 Γ̂0 − θ1 Γ̂1 ) s.t. θd ∈ [0, 1] ,

Tn =

inf

−1≤b∗ ≤1 θ0 ,θ1

(42)

where we used that B∗ = B = R, and D = {b∗ ∈ R : |b∗ | ≤ 1}. 
Example 5.2. As in Example 5.1, we assume that there are no covariates (Z = Z0 )
and that Y ∈ {0, 1} is binary. However, now we consider testing the null hypothesis
that agents more likely to select into treatment also have a higher expected benefit
from treatment. To this end, we take M to be the infinite dimensional set of functions
M = {(m0 , m1 ) s.t. md : [0, 1] 7→ [0, 1], m1 − m0 monotonically increasing} ,

(43)

and Mn ⊂ M a finite dimensional subset, such as pairs of Bernstein polynomials
of finite order K < ∞; see Appendix F. For any m = (m0 , m1 ), we let kmk2M ≡
R
(m0 (u)2 + m1 (u)2 )du and note that M ⊂ M for M ≡ L2 ([0, 1]) × L2 ([0, 1]) where
R1
L2 ([0, 1]) ≡ {f : [0, 1] 7→ R s.t. 0 f (u)2 du < ∞}.
We also consider an infinite set of IV–like specifications S that satisfies the conditions of Proposition 3. By Stinchcombe and White (1998), such a set S can be of the
form
S = {s(·; λ) : λ ∈ Λ ⊂ Rdλ },

(44)

where s(·; λ) : {0, 1} × Rdz 7→ R is known and λ ∈ Λ for Λ ⊂ Rdλ a finite dimensional
compact parameter space.12 We can then identify βP with a function on Λ via
βP (λ) ≡ E[s((D, Z); λ)Y ].
12

(45)

E.g., take s((d, z); λ) = (1 − d) exp{λ0 + z 0 λ1 } + d exp{λ2 + z 0 λ3 } with λ = (λ0 , λ1 , λ2 , λ3 ).

34

Provided λ 7→ E[s((D, Z); λ)] is continuous, we can set B = C(Λ) with C(Λ) ≡ {f :
Λ 7→ R s.t. f is continuous} and k · kB = k · k∞ with kf k∞ ≡ supλ∈Λ |f (λ)|. The map
ΓP : M 7→ C(Λ) assigns to each MTR pair (m0 , m1 ) the continuous function on Λ
defined by
"Z

#

1

ΓP (m)(λ) ≡ E

"Z

#

p(Z)

m0 (u)s0 ((0, Z); λ)du + E

m1 (u)s1 ((0, Z); λ)du . (46)

p(Z)

0

As in Example 5.1, given an estimator p̂(Z) for the propensity score p(Z), we may
obtain estimators β̂ and Γ̂ through the sample analogs of (45) and (46). The dual
space of B = C(Λ) is the set of signed Borel measures with bounded variation, i.e.
R
T(Λ) ≡ {τ : Λ d|τ |(λ) ≤ 1}.13 For this example, the duality result in (39) states that
Tn = inf

√

m∈Mn

= sup

nkβ̂ − Γ̂(m)k∞
Z
√
inf
n (β̂(λ) − Γ̂(m)(λ))dτ (λ)

τ ∈T(Λ) m∈Mn

= sup inf

√

λ∈Λ m∈Mn

n|β̂(λ) − Γ̂(m)(λ)|,

(47)

where the final equality follows after noting that, for any m ∈ Mn , the optimal τ puts
measure plus or minus one on the λ ∈ Λ that maximizes |β̂(λ) − Γ̂(m)(λ)|. 

5.3

Distributional Approximation

In this section, we obtain an approximation for the distribution of the test statistic,
Tn . To do this, we maintain the following assumptions.
Assumptions S
S.1 M ⊆ M is convex and compact in the weak topology.
S.2 The maps ΓP : M 7→ B and Γ̂ : M 7→ B are linear and continuous.
S.3 There are tight and centered jointly Gaussian processes (GP,β , GP,Γ ) ∈ B×`∞ (D×
√
√
M) such that n{Γ̂ − ΓP } = GP,Γ + Op (δnc ) and n{β̂ − βP } = GP,β + Op (δnc )
uniformly in P ∈ P for some sequence δnc ↓ 0.
S.4 The Gaussian processes (GP,β , GP,Γ ) satisfy

sup E[kGP,β kB ] < ∞

and

sup E

P ∈P
13

P ∈P

See, e.g., Corollary 14.15 in Aliprantis and Border (2006).

35


sup kGP,Γ (m)kB < ∞.
m∈M

S.5 For every m ∈ M there is a Πn m ∈ Mn ⊆ M and a sequence δns ↓ 0 such that
√

nkΓP (m − Πn m)kB ≤ δns


sup E sup kGP,Γ (m) − GP,Γ (Πn m)kB ≤ δns .

sup

P ∈P

and

P ∈P

m∈M

Assumption S.1 is our main requirement for M, which is that it is convex and
compact with respect to the weak topology. If M is reflexive (i.e. M = (M∗ )∗ ), as in
Example 5.2, then S.1 is satisfied if M is convex, closed, and bounded under k · kM .
Assumption S.2 formalizes our requirement that the maps ΓP and Γ̂ are linear and
continuous. Our main statistical assumption is S.3, which can be interpreted as requiring that a central limit theorem applies to the estimators β̂ and Γ̂ uniformly in P ∈ P
√
√
at a rate δnc ↓ 0. In our applications, n{β̂ − βP } and n{Γ̂ − ΓP } are asymptotically
equivalent to empirical processes and Assumption S.3 can hold with rates as fast as
√
δnc = log(n)/ n (Koltchinskii, 1994; Rio, 1994); see also Chernozhukov et al. (2015).
Assumption S.4 imposes moment conditions on the processes (GP,β , GP,Γ ). Assumption S.5 requires the approximation error δns introduced from employing Mn in place
of M to vanish sufficiently fast. We note that, due to Assumption S.3, there are no
constraints on the rate of growth of the sieve Mn .
Under the null hypothesis, there exists an m ∈ M such that ΓP (m) = βP . By the
definition of the support function, it follows that
hb∗ , βP i − ν(b∗ , ΓP (M)) ≤ 0

for all b∗ ∈ D.

(48)

Since 0 ∈ D, there is always a b∗ ∈ D for which (48) holds with equality. This suggests
that the supremum in the dual representation of Tn (see (39)) is attained at a b∗ in
DP (κun ) ≡ {b∗ ∈ D : hb∗ , βP i − ν(b∗ , ΓP (M)) ≥ −κun },

(49)

for any positive sequence κun that converges to zero, but not too quickly. The set
DP (κun ) shares a similarity with the moment inequalities literature, in which the set of
moment inequalities that are “close” to binding plays a crucial role in inference; see
Canay and Shaikh (2016) and the references cited therein. Analogously, we use DP (κun )
to define the distributional approximation
UP,n (κun ) ≡

sup

inf

m∈M
b∗ ∈DP (κu
n)



hb∗ , GP,β − GP,Γ (m)i s.t.

√

nhb∗ , βP − ΓP (m)i ≤ δns .

Our next result provides some properties of UP,n (κun ) as an approximation to Tn .

36

Theorem 1. Suppose that Assumptions S.1–S.5 hold. Let κun be any sequence for
√
which nκun ↑ ∞, and define DP (κun ) as in (49). Then, uniformly over P ∈ P,
Tn =

sup
b∗ ∈D

u
P (κn )

inf {hb∗ , GP,β − GP,Γ (m)i +

m∈M

√

nhb∗ , βP − ΓP (m)i} + op (1).

(50)

Moreover, there exists a sequence ξn = Op (δnc + δns ) such that for any P ∈ P0 ,
Tn ≤ UP,n (κun ) + ξn ,

(51)

uniformly over P ∈ P.
The first result in Theorem 1 provides an asymptotic expansion for our test statistic, Tn . We will use this expansion to assess the quality of our subsequent bounds. In
particular, (50) can be used to conclude that the quantiles of the pointwise asymptotic
distribution of Tn can fail to deliver uniform size control without additional assumptions; see Example 5.1 below. As a result, we will instead construct a test with a critical
value based on the quantiles of UP,n (κun ). By showing that UP,n (κun ) is an asymptotic
upper bound for Tn , Theorem 1 lays the foundations for establishing that such a test
can deliver uniform size control. It is worth noting that the results of Theorem 1 hold
for any sequence κun that satisfies the stated conditions. Thus, Theorem 1 actually
establishes a family (indexed by sequences κun ) of uniformly valid upper bounds for Tn .
We now revisit Example 5.1, which is useful for clarifying the nature of our approximations, and then Example 5.2, which helps illustrate the content of our assumptions.
Example 5.1 (continued). Consider a sequence of distributions Pn,γ , such that βPn,γ =
√
√
(1 + γ/ n) and ΓPn,γ = (1, γ/ n) for some γ ≥ 0. Suppose for simplicity that Zβ and
ZΓ are independent standard normal random variables, and that
√

n{β̂ − βPn,γ } = Zβ + op (1)

√
n{Γ̂ − ΓPn,γ } = (0, ZΓ ) + op (1).

Direct calculation shows that for any κun ↓ 0 that satisfies

√

(52)

nκun ↑ ∞, (50) simplifies to

Tn = max {min {Zβ + γ, Zβ − ZΓ } , 0} + op (1).

(53)

It is important to notice that the quantiles of the distributional approximation in (53)
are increasing in γ. As a result, any critical value cn that satisfies
lim Pn,0 (Tn > cn ) = α

n→∞

(54)

will deliver an asymptotic rejection probability larger than α along any contiguous

37

sequence Pn,γ with γ > 0. This result contrasts with, e.g., Andrews and Soares (2010),
in which the pointwise limit is also the “least favorable.” Employing the upper bound
UP,n (κun ) addresses this difficulty. In particular,
UPn,γ ,n (κun ) = max{Zβ − ZΓ , 0} + op (1)

(55)

for any sequence κun ↓ 0. In this example, (55) corresponds to the “least favorable”
value of the local parameter γ in (53), i.e. γ = +∞. 
Example 5.2 (continued). Since M is reflexive, Assumption S.1 is satisfied whenever
M is closed and bounded, which is the case for M in (43). Assumption S.2 is satisfied
for ΓP : M 7→ B as in (46) (and its plug-in analog) by Jensen’s inequality, provided
that S has a square integrable envelope. Sufficient conditions for Assumption S.3 can
be found by establishing a (uniform over P ∈ P) asymptotic expansion
√

n

1 X
n{Γ̂ − ΓP }(m)(λ) = √
ψ(Di , Zi , m, λ) + op (1)
n

(56)

i=1

and ensuring that {f (y, d, z) = ys(d, z) : s ∈ S} and {f (d, z) = ψ(d, z, m, λ) : (m, λ) ∈
M × Λ} are suitably Donsker classes.14 Assumption S.4 reduces to a uniform (in
P ∈ P) moment bound on the supremum of the approximating Gaussian processes.
To verify Assumption S.5, one can apply results on sieve approximation errors, such
as those available in Chen (2007) and the references cited therein. 

5.4

Bootstrap Approximation

The important implication of Theorem 1 is that the quantiles of UP,n (κun ) are valid
critical values for the test statistic Tn . We now address the problem of estimating these
quantiles. For clarity of exposition, we divide our analysis into two steps, each of which
addresses a distinct challenge.
14

Such requirement may necessitate further restricting M by, e.g., imposing a bound on derivatives.

38

5.4.1

An Infeasible Approximation

We first derive an infeasible bootstrap approximation for the distribution of UP,n (κun ).
To this end, we first rewrite UP,n (κun ) as the saddle point problem
UP,n (κun ) = sup inf hb∗ , GP,β − GP,Γ (m)i
b∗ ∈D m∈M

s.t. (i) hb∗ , βP i − ν(b∗ , ΓP (M)) ≥ −κun ,
√
(ii) nhb∗ , βP − ΓP (m)i ≤ δns ,

(57)

where constraint (i) corresponds to b∗ ∈ DP (κun ), as defined in (49). Characterizing
UP,n (κun ) as (57) emphasizes that its distribution is determined by only three essential
unknowns: The objective function and the two constraints of optimization.
The objective function in (57) depends on the unknown distribution P of the data
only through the asymptotic distribution of the chosen estimators, i.e. (GP,β , GP,Γ ).
While the bootstrap is not valid for estimating the distribution of Tn , it can nonetheless
often consistently estimate the distribution of these estimators (Fang and Santos, 2014).
We therefore assume the existence of suitable estimators (Ĝβ , ĜΓ ) of the distribution
of (GP,β , GP,Γ ) as follows.
Assumptions S (continued)
bs
c
∞
S.6 (Ĝβ , ĜΓ ) = (Gbs
P,β , GP,Γ ) + Op (δn ) in B × ` (D × M) uniformly in P ∈ P, with
∞
bs
(Gbs
P,β , GP,Γ ) independent of {(Yi , Di , Zi )}i=1 and equal in law to (GP,β , GP,Γ ).

S.7 Mn ⊆ M is convex and closed.
Assumption S.6 is our main bootstrap requirement. It requires the existence of
a consistent bootstrap procedure that estimates the law of (GP,β , GP,Γ ) uniformly in
P ∈ P at the rate δnc , i.e. the same rate as in Assumption S.3. Typically, for standard
bootstrap analogs β̂ bs and Γ̂bs of β̂ and Γ̂ respectively, the estimators Ĝβ and ĜΓ would
√
√
correspond to setting Ĝβ = n{β̂ bs − β̂} and ĜΓ = n{Γ̂bs − Γ̂}. However, note that
Assumption S.6 also allows for estimation of the law of (GP,β , GP,Γ ) through alternative
resampling procedures, such as a score or weighted bootstrap, subsampling, or the m
out of n bootstrap. Assumption S.7 imposes the regularity condition that Mn is closed
and convex.
Having estimators (Ĝβ , ĜΓ ) enables us to mimic the stochastic behavior of the objective function in (57) by simply employing a plug-in sample analog, i.e. by replacing
hb∗ , GP,β −GP,Γ (m)i with hb∗ , Ĝβ − ĜΓ (m)i. A similar approach is also effective for handling constraint (i) in (57), which corresponds to imposing b∗ ∈ DP (κun ). Specifically,

39

we replace constraint (i) in (57) with the constraint that b∗ ∈ D̂n , where
D̂n ≡ {b∗ ∈ D : hb∗ , β̂i − ν(b∗ , Γ̂(Mn )) ≥ −κ̂un }

(58)

and κ̂un is a bandwidth selected by the researcher. We discuss data-driven choices of
κ̂un in Section 5.5.2. However, we note here that setting D̂n = D (κ̂un = ∞) is always a
valid choice.
Turning to (ii) in (57), we note that using a simple plug-in analog of this constraint
can lead to a lack of size control. Instead, we construct a possibly random set M̂n
that, heuristically, should satisfy the following condition asymptotically:
{m ∈ M : ΓP (m) = βP } ⊆ M̂n .

(59)

Under the null hypothesis, there exists an mP ∈ M such that ΓP (mP ) = βP , and
therefore any m ∈ M̂n that satisfies hb∗ , ΓP (mP − m)i ≤ 0 must also satisfy constraint
(ii) in (57). These observations imply that under the null hypothesis
{m ∈ M̂n : hb∗ , ΓP (m)i = ν(b∗ , ΓP (M̂n ))} ⊆ {m ∈ M : hb∗ , βP − ΓP (m)i ≤ 0} (60)
whenever (59) holds. While setting M̂n = M guarantees condition (59), for power
considerations it may be advisable to instead set
M̂n ≡ {m ∈ Mn : kβ̂ − Γ̂(m)kB ≤ κ̂m
n}

(61)

15 Note that taking κ̂m = ∞
for some bandwidth κ̂m
n that is chosen by the researcher.
n

corresponds to choosing M̂n = M. While we allow κ̂un and κ̂m
n to differ from each
other, these bandwidths are in fact closely related and can often be selected through a
common procedure. See Section 5.5.2 for additional details.
At this point, our discussion suggests that the distribution of
In (ΓP ) ≡ sup

inf

b∗ ∈D̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hb∗ , ΓP (m)i = ν(b∗ , ΓP (M̂n )) , (62)

conditional on the data, should approximate the distribution of UP,n (κun ). Intuitively,
In (ΓP ) imitates (57) but replaces constraint (i) with b∗ ∈ D̂n , and replaces constraint
(ii) with m ∈ {m̃ ∈ M̂n : hb∗ , ΓP (m̃)i = ν(b∗ , ΓP (M̂n ))}. The bootstrap statistic
15

Loosely speaking, we should expect the minimizer of Tn = inf m∈Mn kβ̂ − Γ̂(m)kB to “converge” to
{m ∈ M : βP = ΓP (m)}. We emphasize, however, that the set of distributions P that we consider allows
for the possibility that the set {m ∈ M : βP = ΓP (m)} is not consistently estimable uniformly in P ∈ P.

40

In (ΓP ) is infeasible due to its dependence on the unknown map ΓP : M 7→ B. We
address this challenge in the next section. Nevertheless, establishing the properties of
In (ΓP ) provides us with a useful intermediate result before analyzing the bootstrap
statistic itself. For this purpose, we impose the following requirements on κ̂un and κ̂m
n:
Assumptions S (continued)
S.8 κ̂un satisfies

lim inf inf P
n→∞ P ∈P


κ̂un
> (1 + δ) = 1
κun

√
for some δ > 0 and some non-random sequence κun such that nκun ↑ ∞.
√ m
S.9 κ̂m
n satisfies lim inf C↑∞ lim inf n→∞ inf P ∈P P ( nκ̂n ≥ C) = 1 for every C > 0.
Assumption S.8 allows κ̂un to be random, but requires it to be (asymptotically) larger
than the nonrandom sequence κun , which determines the random variable UP,n (κun )
√
whose distribution we aim to approximate. Assumption S.9 requires nκ̂m
n to diverge
to infinity asymptotically as well. By allowing κ̂un and κ̂m
n to be random, Assumptions
S.8 and S.9 enable us to employ data-driven choices of bandwidths. We discuss possible
choices in Section 5.5.2.
u
Let Ubs
P,n (κn ) be the random variable defined by
u
Ubs
P,n (κn ) ≡

sup

inf

m∈M
b∗ ∈DP (κu
n)

o
n
√ ∗
bs
nhb , βP − ΓP (m)i ≤ δns .
hb∗ , Gbs
P,β − GP,Γ (m)i s.t.

u
u
Notice that, given Assumption S.6, the random variables Ubs
P,n (κn ) and UP,n (κn ) share

the same distribution, and hence the same quantiles. However, in contrast to UP,n (κun ),
u
the random variable Ubs
P,n (κn ) is independent of the data, and hence its quantiles

conditional on the data are equal to the unconditional quantiles of UP,n (κun ) that we
desire for inference. These observations motivate our next intermediate result.
Lemma 5.1. Suppose that Assumptions S.1–S.7 and S.9 hold. Then, for any sequence
√
κun that satisfies Assumption S.8, and for which nκun ↑ ∞, there exists a sequence
ξnbs ∈ R such that ξnbs = Op (δnc ) uniformly over P ∈ P0 , and such that
u
bs
Ubs
P,n (κn ) ≤ In (ΓP ) + ξn

(63)

for any P ∈ P0 .
Together with Theorem 1, Lemma 5.1 suggests that the quantiles of the bootstrap
statistic In (ΓP ), conditional on the data, can be used as critical values for the test

41

statistic, Tn . In the next section, we use Lemma 5.1 to establish an analogous result
for a feasible bootstrap statistic. Before proceeding, we revisit Example 5.1 to illustrate
the approximations in Lemma 5.1, and Example 5.2 to clarify our assumptions.
Example 5.1 (continued). We continue to consider the sequence Pγ,n , which satisfies
√
√
(52) with βPγ ,n = (1 + γ/ n) and ΓPγ ,n = (1, γ/ n) for some γ > 0. Let
Ĝβ = Zbs
β + op (1)

ĜΓ = (0, Zbs
Γ ) + op (1)

(64)

bs
where Zbs
β and ZΓ are independent standard normal random variables. Provided that

κ̂un satisfies Assumption S.8 and converges in probability to zero, it is straightforward
to verify that D̂n converges in probability to [0, 1], which is the set of “directions” b∗ ∈
[−1, 1] satisfying hb∗ , βPγ,n i = ν(b∗ , ΓPγ,n (M)). Similarly, provided that κ̂m
n converges
in probability to zero, it follows that with probability tending to one along Pγ,n
{(θ0 , θ1 ) = m ∈ M : m = (1, θ1 ) for θ1 ∈ [0, 1]} ⊂ M̂n .

(65)

However, (65) implies {m ∈ M̂n : hb∗ , ΓP (m)i = ν(b∗ , ΓP (M̂n ))} = {(1, 1)}, and hence
bs
bs
u
In (ΓPγ,n ) = sup hb∗ , Zbs
β − ZΓ i + op (1) = UPγn ,n (κn ) + op (1),

(66)

b∗ ∈[0,1]

where the final equality follows from (55). Therefore, in this simple example, In (ΓP )
u
and Ubs
P,n (κn ) are asymptotically equivalent. 

Example 5.2 (continued). As in the verification of Assumption S.3, sufficient conditions for establishing Assumption S.6 can be found by guaranteeing that an asymptotically linear expansion such as (56) also holds for the bootstrap estimators. For
verifying Assumption S.7, note that convex sets are closed in the weak topology of M
if and only if they are closed under k · kM . 

5.4.2

The Bootstrap Statistic

The main obstacle to using the statistic In (ΓP ) for inference is that it depends on the
unknown linear map ΓP : M 7→ B. We now address this challenge and construct a
feasible bootstrap statistic. Before proceeding, we present a lemma that makes the
dependence of In (ΓP ) on the unknown map ΓP more transparent. Recall from (36)
that Γ∗P : B∗ 7→ M∗ denotes the adjoint of ΓP .

42

Lemma 5.2. Suppose that Assumptions S.1–S.5, S.7, and S.9 are satisfied. Then
In (ΓP ) = sup

sup

inf

b∗ ∈D̂n m̃∈M̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hΓ∗P (b∗ ), m − m̃i ≥ 0

(67)

with probability tending to one, uniformly over P ∈ P0 .
Lemma 5.2 shows that ΓP enters the optimization problem that defines In (ΓP )
solely through the bilinear constraint involving b∗ , m, and m̃. Given an estimator, Γ̂, it
would be natural to approximate In (ΓP ) by simply employing the plug-in analog In (Γ̂).
However, the feasible set in (67) changes discontinuously in ΓP . As a result of this,
using the quantiles of In (Γ̂) as critical values can fail to control size. For this reason,
we instead consider the least favorable critical value obtained from a “neighborhood”
of our estimator Γ̂.
Defining an appropriate neighborhood of Γ̂ can be challenging when M and/or
B are infinite dimensional. In particular, Assumption S.3 is too weak to guarantee
that Γ̂ is consistent for ΓP with respect to the operator norm.16 Instead, we build
neighborhoods using the weak (operator) topology. Let Mn be the closed linear span
of Mn (in M), and let M∗n denote its dual space. For any b∗ ∈ B∗ , define
Ĝn (b∗ ) ≡ {g ∈ M∗n : |hg − Γ̂∗ (b∗ ), vi| ≤ κ̂gn for all v ∈ Vn }
= {g ∈ M∗n : |hg, vi − hb∗ , Γ̂(v)i| ≤ κ̂gn for all v ∈ Vn },

(68)
(69)

where κ̂gn ↓ 0 and Vn ⊆ M are chosen by the researcher. Typically, we take Vn ⊆ Mn
and use specification (69) in place of (68) so as to avoid having to compute the adjoint
Γ̂∗ . We provide guidance for choosing κ̂gn in Section 5.5.2.
We can now define our feasible bootstrap statistic as
Tnbs ≡ sup

sup

inf

b∗ ∈D̂n (g,m̃)∈Ĝn (b∗ )×M̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0 .

(70)

While (70) looks like an unwieldy optimization problem, we show in Appendix G.3
that it can be reformulated as a bilinear program. While bilinear programs are not
convex, they can be provably solved to global optimality by algorithms that combine
McCormick relaxations (McCormick, 1976) with spatial branch-and-bound strategies.17
16

More precisely, supkmkM ≤1 k{Γ̂ − ΓP }(m)kB need not converge to zero in probability.
A good software implementation of these types of algorithms is the BARON solver developed by
Tawarmalani and Sahinidis (2005). Although not provably convergent to global optimality, we have found
that more common locally optimal solvers, such as KNITRO (Byrd, Nocedal, and Waltz, 2006), almost
always find the global optimum for our problem, and much more quickly than BARON. We use KNITRO
17

43

For our purposes, an attractive property of these algorithms is that termination after a
set amount of time always provides an upper bound on the actual optimal value, Tnbs .
Critical values constructed from these upper bounds may be conservative, however they
will still provide size control.
We use the following two assumptions to establish the properties of Tnbs .
Assumptions S (continued)
√
S.10 κ̂gn satisfies lim inf C↑∞ lim inf n→∞ inf P ∈P P ( nκ̂gn ≥ C) = 1 for every C > 0.
S.11 There exists a λ ∈ R and an mc ∈ Mn such that Vn ⊆ λ(Mn − mc ) for every n.
Assumption S.10 requires the bandwidth κ̂gn (which can be data-dependent) to not
√
converge to zero at a rate faster than n. Assumption S.11 relates the set of functions
Vn used to construct Ĝn (b∗ ) to the sieve Mn . This requirement is imposed as a simple
√
sufficient condition to ensure that the process hb∗ , n{Γ̂ − ΓP }(v)i is asymptotically
S
tight on `∞ (D × V) for V = ∞
n=1 Vn . For applications in which B and M are finite
dimensional, the sets Vn may chosen so that Ĝn (b∗ ) = {g : kg − Γ̂(v)k ≤ κ̂gn }, where
k · k is the standard Euclidean norm. Notice that Assumption S.11 does not place any
requirements on the “rate of growth” of Vn .
The next theorem describes the properties of our proposed bootstrap statistic.
Theorem 2. Suppose that Assumptions S.1–S.7 and S.9–S.11 are satisfied. Then, for
√
any sequence κun that satisfies Assumption S.8, as well as nκun ↑ ∞, there exists a
sequence ξnbs ∈ R, with ξnbs = Op (δnc ) uniformly in P ∈ P0 , and such that
u
bs
bs
Ubs
P,n (κn ) ≤ Tn + ξn

(71)

for any P ∈ P0 .
Theorems 1 and 2 build the foundation for testing the null hypothesis in (33) by
comparing the test statistic Tn to critical values obtained from the quantiles of the
bootstrap statistic Tnbs , conditional on the data. We establish the properties of such a
test in the next section.
Our choice of Tnbs is informed by considerations of computational reliability in realistically sized problems. For simple problems, a less conservative, but computationally
more challenging critical value may also be available. To see this, start by defining the
1 − α quantile of In (Γ) (conditional on the data) as
q1−α (Γ) ≡ inf {c s.t. P (In (Γ)|{Yi , Di , Zi }ni=1 ) ≥ 1 − α} .
c∈R

(72)

for our empirical application in Section 6, but we have checked a subset of the results using BARON and
found them to be nearly identical.

44

In principle, it is possible to use the least favorable critical value given by
sup
Γ:M7→B

n
o
q1−α (Γ) s.t. |hΓ∗ (b∗ ) − Γ̂∗ (b∗ ), vi| ≤ κ̂gn for all (b∗ , v) ∈ D̂n × Vn .

(73)

Intuitively, by using Tnbs , we are computing the quantile of the maximum over a neighborhood of Γ̂, instead of the maximum of the quantile over such a neighborhood.
Whenever (73) is solvable, it will yield a critical value that provides better power than
Tnbs . We illustrate this in Example 5.1 below. Our recommendation is to use (73) when
feasible, but we focus on Tnbs due to its wider (computational) applicability.
We conclude this section by revisiting Examples 5.1 and 5.2.
Example 5.1 (continued). We return again to the sequences Pγ,n , which satisfied
√
√
(52) and (65) with βPγ ,n = (1 + γ/ n) and ΓPγ ,n = (1, γ/ n). In this simple example,
M = R2 and B = R, so that Γ̂∗ : R 7→ R2 and Γ∗P : R 7→ R2 are given by
Γ∗P (b∗ )



γ 0
= b 1, √
n
∗

∗

and

∗

∗

Γ̂ (b ) = b



ZΓ + γ
1, √
n

0
+ op (1)

(74)

for any b∗ ∈ R. Setting Vn = {(1, 0), (0, 1)} implies that for any b∗ ≥ 0,


1
(g1 , g2 ) = g ∈ R : g = (1, c) and |c| ≤ √
n
0

0

2



⊆ Ĝn (b∗ )

(75)

with probability tending to one along Pγ,n . For notational clarity, we also define
L(g) ≡

bs
inf {hb∗ , Gbs
P,β − GP,Γ (m)i s.t. hg, m − m̃i ≥ 0},

sup
(b∗ ,m̃)∈[0,1]×M̂n

(76)

m∈M̂n

and note that the set inclusion in (65) implies that

L(g) =







bs
max{0, Zbs
β − ZΓ }

max{0, Zbs
β

− (Zbs
Γ )+ }
max{0, Zbs
β }

if g2 > 0
if g2 = 0

(77)

if g2 < 0

bs
for any (1, g2 )0 = g ∈ R2 , where (Zbs
Γ )+ = max{ZΓ , 0}. We conclude that
bs
bs
Tnbs = max{0, Zbs
β , Zβ − ZΓ } + op (1).

Note that, at least for this example, the less conservative critical values given in (73)
can actually be solved for analytically. These critical values correspond to the quantiles
bs
u
of max{0, Zbs
β − ZΓ }, which are also equal to the quantiles of UP,n (κn ). 

45

Example 5.2 (continued). We use this example to illustrate the computation of Tnbs
in a more abstract setting. Recall that B = C(Λ) and M = L2 ([0, 1]) × L2 ([0, 1])
so that B∗ = T(Λ) is the set of signed Borel measures of bounded variation, while
M∗ = L2 ([0, 1]) × L2 ([0, 1]). Hence, for this example we obtain

D̂n =

b∗ :

Z

Z

d|b∗ |(λ) ≤ 1 and

β̂(λ)db∗ (λ) ≥ sup
m∈Mn

Λ

Λ

Z


Γ̂(m)db∗ (λ) − κ̂un ,

Λ

n
o
M̂n = m ∈ Mn : |β̂(λ) − Γ̂(m)(λ)| ≤ κ̂m
for
all
λ
∈
Λ
,
n
(
"
)
#
Z 1 X
Z
1
Ĝn (b∗ ) = g ∈ Mn :
gd (u)vd (u) du −
Γ̂(v)(λ)db∗ (λ) ≤ κ̂gn ∀v ∈ Vn ,
0

Λ

d=0

where we used the fact that Mn = M∗n . Therefore, the bootstrap statistic reduces to
Tnbs = sup

Z
inf

sup

b∗ ∈D̂n (g,m̃)∈Ĝn (b∗ )×M̂n m∈M̂n

Z
s.t.

1
1X

{Ĝβ (λ) − ĜΓ (m)(λ)}db∗ (λ)

Λ

[gd (u)(md (u) − m̃d (u))] du ≥ 0.

(78)

0 d=0

We note that, even though b∗ is infinite dimensional, it is possible to instead optimize
Tnbs over a sieve for D. We provide a formal development of this sieve approach for D in
P
Appendix E. A natural choice of a sieve for D would be Dn ≡ {b∗ (A) = Jj=1 wj 1{λj ∈
P
A} : Jj=1 |wj | ≤ 1} for {λj }Jj=1 ⊆ Λ. Similarly, using Mn in place of M renders
all parameters finite dimensional and all constraints bilinear. See Appendix G for
additional discussion of computation. 

5.5

The Test

In this section, we apply the results obtained in Sections 5.3 and 5.4 to construct a
consistent test. We then discuss choosing bandwidths for this test.

5.5.1

Basic Properties

Theorem 1 implies that the unconditional quantiles of UP,n (κun ) could be used as critical
values for the test statistic Tn . While UP,n (κun ) is infeasible, Theorem 2 suggests that
the quantiles of Tnbs conditional on the data can be used instead. We therefore define
the critical value ĉ1−α for our test to be given by
n


o
ĉ1−α ≡ inf c : P Tnbs ≤ c|{Yi , Di , Zi }ni=1 ≥ 1 − α .

46

(79)

In the following, it will also be useful to define the quantiles of UP,n (κun ) itself, which
we denote by
c1−α (UP,n (κun )) ≡ inf{c : P (UP,n (κun ) ≤ c) ≥ 1 − α}.

(80)

As usual, a final regularity condition is required to establish that a distributional
approximation also delivers consistent estimators of the desired quantiles; see, e.g.,
Romano and Shaikh (2012) and Chernozhukov, Lee, and Rosen (2013). In the present
context, this regularity condition is the following.
Assumptions S (continued)
S.12 There is a δ > 0 and sequence ζn with ζn (δnc + δns ) = o(1) and
sup sup sup
η∈[0,δ] 0<<1 P ∈P0


1 
P |UP,n (κun ) − c1−α−η (UP,n (κun ))| ≤  ≤ ζn .


Notice that if ζn is bounded, then Assumption S.12 corresponds to the requirement that
the cumulative distribution functions of UP,n (κun ) are uniformly (in n) continuous in a
neighborhood of their 1 − α quantiles. However, by allowing ζn to diverge, Assumption
S.12 also allows the distribution of UP,n (κun ) to become increasingly discontinuous.
The “rate” of this loss of continuity (ζn ) must be slower than the rate of convergence
of our stochastic approximation (δnc + δns ).
We now state our final and main result on statistical inference.
Theorem 3. Suppose that Assumptions S.1–S.7 and S.9–S.11 are satisfied. Then, for
any sequence κun that satisfies Assumption S.8 and S.12,
lim sup sup P (Tn > ĉ1−α ) ≤ α.
n→∞ P ∈P0

Moreover, under the same assumptions,
lim P (Tn > ĉ1−α ) = 1.

n→∞

for any P ∈ P \ P0 .
Theorem 3 says that our proposed test is consistent and controls size uniformly in
P ∈ P0 . We note that the class P0 over which size control is ensured is fairly broad. In
particular, the class P0 is such that the set of solutions {m ∈ M : kβP −ΓP (m)kB = 0}
cannot even be consistently estimated uniformly in P0 . We believe that this quality
is particularly important when M is defined by linear inequality constraints and the

47

target parameter is partially identified. Moreover, we emphasize that we have not
placed any conditions that prohibit shape restrictions on M, other than requiring M
to be a convex set. As such, we believe Theorem 3 may be of independent interest
for applications other than the one studied in this paper. Finally, we note that in
establishing Theorem 3, we have not assumed that the data is i.i.d. Instead, we have
assumed that there is a bootstrap (Ĝβ , ĜΓ ) that is capable of handling the dependence
structure in the data. This allows for clustering and other types of dependence.

5.5.2

Bandwidth Guidance

Constructing the bootstrap statistic Tnbs requires specifying the bandwidths κ̂un , κ̂m
n , and
κ̂gn . While Assumptions S.8, S.9, and S.10 do not provide much direction in choosing
these bandwidths, it is clear that their values should be related to the distribution of the
data. In the following, we provide some guidance on the selection of these quantities.
In future work, we hope to formalize a data-driven procedure for determining these
bandwidths by applying the insights of Romano, Shaikh, and Wolf (2014). However,
at present we keep the discussion informal.
The sequence κun and its feasible counterpart κ̂un were introduced in the derivation
of the distributional approximation in Theorem 1. The role of κun is related to
b̂∗ ∈ arg max
∗
b ∈D

o
√ n ∗
n hb , β̂i − ν(b∗ , Γ̂(Mn )) ,

(81)

which represents the direction in which β̂ is farthest away from the set Γ̂(Mn ). In
particular, while κun is allowed to converge to zero, it must do so slowly enough for


∗

lim inf inf P b̂ ∈
n→∞ P ∈P0



DP (κun )

= 1,

(82)

where DP (κun ) is the set defined in (49). A bound for the probability in (82) is


∗

lim inf inf P b̂ ∈
n→∞ P ∈P0



DP (κun )


≥ lim inf inf P
n→∞ P ∈P0

sup kGP,β − GP,Γ (m)kB ≤

m∈Mn

√

nκun


,

(83)
where we are assuming that
κ̂un

δns

= 0 for simplicity. This suggests taking

κ̂un

to be





1
n
√
=
× inf c : P
sup kĜβ − ĜΓ (m)kB ≤ c|{Yi , Di , Zi }i=1 ≥ 1 − αn
(84)
n
m∈Mn

for some sequence αn ↓ 0.
The bandwidth κ̂m
n was introduced in Assumption S.9 with the purpose of ensuring

48

that M̂n contained the set {m ∈ M : kβP − ΓP (m)kB = 0} with probability tending
to one. In analogy to (83), it is possible to show that


lim inf inf P Πn m ∈ M̂n for all m ∈ M s.t. ΓP (m) = βP
n→∞ P ∈P0


√ m
≥ lim inf inf P
sup kGP,β − GP,Γ (m)kB ≤ nκ̂n .
n→∞ P ∈P0

(85)

m∈Mn

From (83) and (85), we see that the choices of κ̂un and κ̂m
n are closely related. For
instance, given that κ̂un is selected according to (84), a simple rule is to let κ̂m
n =
√
√
κ̂un + Tn / n. Here, the addition of Tn / n to κ̂un ensures that M̂n 6= ∅.
Lastly, recall that κ̂gn was introduced in the construction of neighborhoods for the
adjoint Γ∗P : B∗ 7→ M∗ in the weak (operator) topology. A natural choice for κ̂gn is
κ̂gn

1
= √ × inf
n

!

(
c:P

∗

sup sup |hb , ĜΓ (v)i| ≤
b∗ ∈D̂n v∈Vn

c|{Yi , Di , Zi }ni=1

)
≥ 1 − αn

, (86)

√
u
where again αn ↓ 0. Together, (84), κ̂m
n = κ̂n + Tn / n, and (86) provide a simple
heuristic way to relate bandwidth selection to features of the distribution of the data.
In Appendix G.4, we show that implementing these bandwidth choices amounts to
solving a large number of small mixed integer linear programs. We leave a more
detailed analysis of bandwidth selection to future work.

6

The Efficacy of Price Subsidies for Bed Nets

In this section, we apply our method to analyze how price subsidies affect the adoption
and usage of a preventative health product.

6.1

Background, Data, and Experiment

According to the World Health Organization (WTO), approximately 5.9 million children under the age of 5 died in 2015. WTO estimates that a majority of these early
childhood deaths could be prevented or treated if households were regularly using existing health products, such as deworming medication, mosquito nets, water treatment
solution, or latrines.18 An important, and largely unanswered, question for developing
countries is how to design cost effective policies that promote access to (and usage of)
preventive health products.
While highly subsidizing health products has been shown to markedly increase
access in developing countries, researchers and policymakers alike have expressed con18

See http://www.who.int/mediacentre/factsheets/fs178/en/.

49

cerns about the cost effectiveness of such policies (see e.g. Cohen and Dupas (2010)
and Dupas and Zwane (2016)). One concern is the financial cost of subsidizing inframarginal consumers who would have still purchased the product under a smaller
subsidy. Another concern is that households that are unwilling to pay a monetary
price for a product might also be unwilling to pay the non-monetary costs associated
with using the product on a regular basis.19 On the other hand, charging a higher
price to screen out non-users may exclude poor or credit-constrained individuals who
would benefit from using the product.20
The goal of our empirical analysis is to assess these tradeoffs by evaluating the
effects of potential subsidy regimes on usage of a preventative health product, taking
into account differences in subsidization costs across the regimes. Building on Dupas
(2014), we use data from a randomized controlled experiment in Kenya that randomly
assigned prices for a new and improved antimalarial bed net called the Olyset net.21
The experimenters randomized prices across a total of 1,200 households in six villages.
Households had a three month opportunity to purchase the Olyset net at their assigned
subsidized price. Prices for the net varied from 0 to 250 Kenyan schillings (250 Ksh,
or approximately $3.80), which is roughly twice the average daily wage for agricultural
work in the area. Seventeen different prices were offered in total, but each area was
assigned only four or five of these prices. For example, if an area was assigned the
price set (Ksh 50, 100, 150, 200, 250), then all of the study households in the area were
randomly assigned to one of these five prices. Price sets for every area included low,
medium, and high prices. Only two areas had a price set that included free provision
for some households.
Two months after the experiment, Dupas (2014) collected data on household purchase and usage of the Olyset net.22 Usage was assessed by whether a household stated
having started using the net, and whether the net was observed hanging above their
bedding at the time of the visit. Table 1 in Dupas (2014) presents summary statistics of
household characteristics and their correlation with the randomized price assignment.
This table suggests that randomization was successful in making the price assignment
19
See, for example, Ashraf, Berry, and Shapiro (2010), who study the provision of chlorine solution for
water treatment. They find that higher prices tend to screen out those who use the product less.
20
For example, Dupas and Zwane (2016) study alternative screening mechanisms for the provision of
chlorine solution. They find that higher prices may prevent many households that would use the product
from obtaining it.
21
Dupas (2014) uses this data to examine how short-run subsidies affect long-run adoption through
learning. We refer to Dupas (2014) for a detailed discussion of the background, data, and experimental
design.
22
To study effects on long-run adoption, Dupas also conducted a one year follow-up. However, the
follow-up survey only included a subset of the villages. We therefore focus on the short-run effects.

50

Figure 9: Impact of Price on the Household’s Purchase of Bed Net
1.0

●

0.8

Share Purchased

●

●

●

0.6

●

●●

0.4

●

●

●

●

●
●

0.2

●

●●

●

0.0
0

50

100

150

200

250

Price (in Ksh)

Notes: This figure plots purchase rates against prices. The size of the circles reflect the relative size of
the sample at each price point. The lines show predicted values from logit regressions of the households’
decision to purchase the bed net on the randomly assigned prices. The dashed lines indicate 90% confidence
intervals.

independent of observable baseline characteristics.
Figure 9 replicates Dupas’ experimental estimates of the impact of price on the
household’s purchase decision. This figure plots purchase rates for the Olyset net
against the price assignment. The sizes of the circles reflect the relative sample sizes
at each price point. The lines indicate predicted values (and confidence intervals) from
logistic regressions of the households’ purchase decisions on their randomly assigned
prices. The demand function is quite steep. The likelihood of purchasing the bed net
increases from .04 to over .23 as the price decreases from Ksh 250 to 150, reaching
nearly .70 at Ksh 50.

6.2

Evaluating a Class of Subsidy Regimes

We use the randomly assigned prices as instruments, and use their exogenous variation,
together with our method, to study the effectiveness of different subsidy regimes.23 As
discussed in Section 3.1, we can use our method to compute bounds on PTREs that
measure the causal effect on usage of one subsidy regime, a0 , relative to another subsidy
23

A possible threat to the exclusion restriction (Assumption I.2) is the psychological “sunk cost” effect,
whereby individuals who have paid more for a product feel more compelled to use it. However, recent
experiments conducted in developing countries find no evidence of a sunk cost effect in settings with health
products (Cohen and Dupas (2010) and Ashraf et al. (2010)).

51

regime, a1 . For example, consider the effect of a policy that offers free provision
of the Olyset net to all households, compared to a policy under which households
have the option to buy the net at a given price. This comparison does not directly
correspond to the variation in prices induced by Dupas’ experiment, and is therefore not
point identified under standard instrumental variables assumptions. Nevertheless, our
method can be used to establish bounds, which we now show can be quite informative.
In the notation of Section 2.1, Z is the randomly assigned price, D is an indicator
for whether the household purchases the Olyset net, and Y is an indicator for whether
the household uses the net. We consider PRTEs that contrast a regime a0 under which
the propensity score is constant at pa0 , to a regime a1 with a constant propensity score
of pa1 . In Table 3, we focus on two particular choices of pa0 and pa1 . The first choice is
pa0 = 0 and pa1 = 1, which can be thought of as the contrast between a regime a1 with
free provision of the Olyset set, and another regime a0 under which there is no access
to the Olyset net. In this case, the PRTE we consider is just the average treatment
effect (ATE). For the second choice, the a0 regime is still free provision, but in the a1
regime the Olyset net is offered at a price of Ksh 150, which is roughly the observed
market price a year after the experiment (Dupas, 2014). To implement this PRTE, we
use the estimated propensity score to predict pa0 and pa1 . As discussed in Section 3.2,
the PRTE in this case can be interpreted as the LATE from a hypothetical experiment
in which households are either freely provided an Olyset net or able to purchase one
at 150 Ksh.
Table 3 demonstrates the way in which our method allows the researcher to transparently substitute the strength of their assumptions with the strength of their conclusions. Comparing the bounds across columns clarifies how the strength of the conclusions (the width of the bounds) depends on two aspects. First, for a fixed set of
assumptions (indexed here by the Bernstein polynomial order, K), bounds based on a
broader class of IV-like estimates are substantially more informative. In the first five
columns, we restrict attention to the information contained in the IV estimand that
uses the propensity score p(Z) as an instrument for D. By comparison, the next five
columns demonstrate that both the OLS and IV estimands carry independent information. The last five columns demonstrate that the bounds can be tightened considerably
by using richer specifications of the multi-valued price instrument.
The other aspect that affects the strength of the conclusions is the set of maintained
assumptions on the MTR functions, m = (m0 , m1 ). In columns (1)-(4), (6)-(9) and
(11)-(14), we model m0 and m1 with Bernstein polynomials of order K for various

52

Table 3: The Effects of Purchase on Net Usage
(1)
Intercept
Linear in p(Z)
OLS
1(Z ≤ 50)
1(Z ≤ 150)
Panel A.
K (polynomial order)
Bounds
Lower
Upper
90% Confidence Interval
Lower
Upper
Panel B.
K (polynomial order)
Bounds
Lower
Upper
90% Confidence Interval
Lower
Upper
Intercept
Linear in p(Z)
OLS
1(Z ≤ 50)
1(Z ≤ 150)

(2)

(3)

(4)

3
3

3
3

3
3

3
3

2

6

10

20

.6521
.6772

.4646
.7269

.3857
.7362

.3275
.7445

.5486
.7462

.3761
.8019

.2995
.8102

.2421
.8139

2

6

10

.6600
.7049

.5881
.8140

.5626
.8469

.5444
.8817

.5417
.7686

.5005
.9161

.4695
.9519

.4479
.9746

(5)

(6)

3
3

Information Specification
3
3
3
3
3
3
3
3
3
3
3
3

(7)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

(15)

3
3
3

3
3
3
3
3

3
3
3
3
3

3
3
3
3
3

3
3
3
3
3

3
3
3
3
3

Population Average Treatment Effect
NP
2
6
10
20
NP

2

6

10

20

NP

.2533
.7515

∅
∅

.6365
.7104

.5602
.7178

.5269
.7229

.4487
.7253

.5206
.7491

.4130
.7910

.3652
.7941

.3260
.7978

6

10

20

NP

∅
∅

.6758
.6895

.6506
.6988

.6214
.7140

.5573
.7492

.5079
.7713

.4755
.9093

.4584
.9291

.4281
.9511

.6521
.6521

.4956
.7269

.4700
.7362

.4537
.7445

.4282
.7516

.4032
.8093

.3511
.8179

.3204
.8209

.3954
.7515

PRTE at Free Provision versus a Price of 150 Ksh
20
NP
2
6
10
20
NP
2

s(d, z) = 1
s(d, z) = p(z)

.4817
.9732

.6600
.6600

.5881
.7085

.5626
.7172

.5444
.7275

.3890
.7732

.3472
.9263

.3414
.9616

.3320
.9838

.4856
.7941

Specifications of the IV-like Estimands
s(d, z) = 1
s(d, z) = p(z)
s(d, z) = d

s(d, z) = 1
s(d, z) = p(z)
s(d, z) = d
s(d, z) = 1(z ≤ 50)
s(d, z) = 1(z ≤ 150)

Notes: This table reports bounds and 90% confidence intervals for the effects of purchase on usage of the
Olyset net. We estimate the propensity score, p, using the fitted logistic regression from Figure 9. K
denotes the order of the Bernstein polynomial specification for the MTR functions. The confidence intervals
are based on 200 bootstrap replicates, and the tuning parameters are specified as 0.05.

53

choices of K.24 In columns (5), (10), and (15), we use the Haar basis (constant spline)
specification discussed in Section 2.7, which was shown in Proposition 4 to provide
exact nonparametric bounds in the sample. As evident from Table 3, the stronger the
restrictions, the tighter the bounds.
At one extreme, it is possible to specify K to achieve point identification. As shown
in Brinch et al. (2015), the information used in column (6)-(15) are sufficient to point
identify the MTE (and hence any PRTE), provided that K = 2, so that the MTR
functions are quadratic. For example, the results in column (6) imply a 65% usage
rate among individuals induced to purchase by a change to free provision from a price
of Ksh 150. However, the bounds for this specification are empty in column (11),
suggesting that K = 2 might be too restrictive in our setting.
At the other extreme, one can impose few or no restrictions on m0 and m1 , which
yields wider, but more robust bounds. However, even with a very flexible specification, the bounds remain quite informative. For example, with a 10th order Bernstein
polynomial (K = 10), the results in column (13) show that the ATE can be bounded
between .56 and .72, whereas the PRTE of free provision compared to a price of Ksh
150 is bounded between .65 and .70. These results imply that the usage rate in the
overall population is relatively similar to that among individuals induced to purchase
by a change to free provision from a price of Ksh 150.
Figure 10 reports bounds on a range of PRTEs. Each PRTE takes pa0 to be
the propensity score associated with a regime in which all households can purchase
the bed net at a uniform price of Ksh 150.25 The alternative policy is specified by
pa1 = pa0 + α. Panel A plots bounds on this PRTE as a function of α. The predicted
price levels associated with a given α (predicted using the logistic regression in Figure
9) are indicated in parentheses. To be conservative, we set K = 10 as in column (13)
of Table 3, which allows a very flexible functional form for m0 and m1 .
If households that are unwilling to pay larger monetary prices for the Olyset net
are less likely to use the net after purchasing it, then we would expect to see the
PRTEs declining in α. In contrast, Panel A of Figure 10 suggests that the PRTEs are
increasing in α. This finding is consistent with higher prices excluding poor or credit
constrained individuals who would use an Olyset net if they were able to purchase one.
For example, among those induced to purchase the net by lowering prices from Ksh
150 to Ksh 80, the usage rate is bounded between .57 and .62. By comparison, among
the larger set of individuals induced to purchase by a change from Ksh 150 to free
provision, the usage rate is bounded between .65 and .70.
24
25

See Appendix F for a definition and discussion of the Bernstein polynomials.
That is, pa0 = p̂(150), where p̂ is the estimated logistic model plotted in Figure 9.

54

Figure 10: Bounds on Policy Relevant Treatment Effects

PRTE on Usage of Bed Net

1.0

0.8

●●
●●●

●●●

●●
●●●
●●●●
●●●●●●●●●●●●●●●●●●●●●●●●● ●●●●●●●●●
●●●
●
●
●●
●
●
●●
●●●
●●●●
●●●●●●●●

0.6

●●
●●●●
●●●●●●●●●●●●●●
●●●●●●
●●●●
●●●
●
●
●
●●●
●●●●

●●●●

0.4

0.2

0.0
0 (150)

0.099 (125)

0.216 (100)

0.338 (75)

0.453 (50)

0.548 (25) 0.621 (0)

α (Ksh)

(a) PRTE: Effect on Usage Rates

PRTE on Usage of Bed Net per 1,000 Ksh

●
●

8

●
●
●
●
●
●

7

●

●

●
●

●
●

●

●

●
●

6

●
●

●
●

●

●

●

●

●●

●●

5

●

●

●●

●

●

●●

●

●

●●

●

●

●●

●●
●●

●●
●●

●●●
●●

●●●

●●

●●

●●
●●

●●
●●

4

●●
●●

●●
●●

●●
●●

●●
●●

●●
●●

●

●

●●

●

●

●●

●
●
●●●●
●●●
●●
●●
●●●●
●
● ●
●
●

3
0 (150)

0.099 (125)

0.216 (100)

0.338 (75)

0.453 (50)

0.548 (25) 0.621 (0)

α (Ksh)

(b) PRTE: Effects Relative to Costs
Notes: Panel A displays bounds on usage for a range of PRTEs. Each PRTE takes pa0 = p̂(150), where p̂ is
the fitted logistic regression from Figure 9. This corresponds to a policy regime under which all households
can purchase the Olyset bed net at a uniform price of Ksh 150. The alternative policy regime is pa1 = pa0 +α.
The x-axis shows how the PRTE varies with changes in α or prices in Ksh (z), where α and z are related
through α = p̂(z)−pa0 . Panel B divides the PRTE on usage by the PRTE on subsidy costs. The specification
of the IV-like estimands and Bernstein polynomial order correspond to column (13) in Panel B of Table 3.

55

Even if a subsidy regime with low prices leads to relatively high usage among those
who purchase the Olyset net, it still comes at the cost of subsidizing inframarginal
consumers who would have also purchased the net at a higher price. To compare the
effects on usage to the costs of lowering prices, we divide the PRTE on usage by the
PRTE on subsidy costs. Panel B of Figure 10 plots the results, which show that subsidy
regimes with low prices or free provision induce relatively few individuals to use the
Olyset net per Ksh spent. For example, if prices are lowered from Ksh 150 to 80, then
each 1,000 Ksh in subsidy costs induces at least 4.70 households (lower bound) to use
the bed net. By comparison, moving from a regime with a price of Ksh 150 to one
with free provision induces at most 3.39 households (upper bound) to use the bed net
for every 1,000 Ksh in subsidy costs.26

7

Conclusion

We proposed a method for using instrumental variables (IVs) to draw inference about
treatment parameters other than the LATE. Our method uses the observation that
both the IV estimand and many treatment parameters can be expressed as weighted
averages of the same underlying marginal treatment effects. Since the weights are
known or identified, this observation implies that knowledge of the IV estimand places
some restrictions on the unknown marginal treatment response functions, and hence
on the possible values of other treatment parameters of interest. We showed how
to extract this information from a class of objects described as IV-like estimands,
which includes the TSLS and OLS estimands, among others. An important aspect of
our method is that it allows the researcher a large degree of flexibility in choosing a
parameter of interest, and in choosing auxiliary identifying assumptions that can be
used to help tighten their empirical conclusions. Another important feature is that it
is computationally straightforward.
We considered three main applications of our method. We showed that it can be
used for counterfactual policy analysis, including extrapolation away from the variation
in treatment induced by the instrument at hand. In addition, we showed that the
general framework facilitates tests of both model specification and economic behavior.
To implement our method, we developed a novel inference procedure that exploits the
convexity of our setting, while remaining uniformly valid and computationally reliable
under weak conditions. We applied our method to analyze how price subsidies affect
26
Of course, high subsidization or free provision of the Olyset net may still be optimal depending on its
effects on health outcomes. Unfortunately, we do not have the data needed to assess the effects on health
outcomes.

56

the adoption and usage of antimalarial bed nets in Kenya. Our results suggest that
generous subsidy regimes encourage usage among individuals who would otherwise
not use a bed net, albeit at a potentially high cost of subsidizing other inframarginal
individuals.
The overall message from our analysis is that it is possible, both in theory and
in practice, to use IVs to draw informative inference about a wide range of treatment
parameters other than the LATE. This enables researchers to learn about causal effects
for a broad range of individuals, not just those who are affected by the instrument
observed in the data. The ability to do this is critical to ensuring that estimates
obtained through IV strategies are both externally valid and relevant to policy.

57

A

Proofs for Section 2

Proof of Proposition 1. Using equation (1), we first note that
βs = E[s(D, Z)DY1 ] + E[s(D, Z)(1 − D)Y0 ].

(87)

Using equation (2) with Assumptions I.1 and I.2, observe that the first term of (87)
can be written as
E[s(D, Z)DY1 ] = E[s(D, Z)1[U ≤ p(Z)]E[Y1 |U, Z]]
≡ E[s(1, Z)1[U ≤ p(Z)]m1 (U, X)],

(88)

where the first equality follows because s(D, Z)D is a deterministic function of (U, Z),
and the second equality uses the definition of m1 and I.2, together with the identity
that
s(D, Z)1[U ≤ p(Z)] ≡ s (1[U ≤ p(Z)], Z) 1[U ≤ p(Z)] = s(1, Z)1[U ≤ p(Z)].
Using the normalization that U |Z is uniformly distributed on [0, 1] for any realization
of Z, it follows from (88) that
E[s(D, Z)DY1 ] = E [E [s(1, Z)1[U ≤ p(Z)]m1 (U, Z)|Z]]
Z 1

=E
s(1, Z)1[u ≤ p(Z)]m1 (u, Z) du
0
Z 1

≡E
ω1s (u, Z)m1 (u, Z) du .
0

The claimed result follows after applying a symmetric argument to the second term on
the right hand side of equation (87).

Q.E.D.

Proof of Proposition 2. Since Γs : M 7→ R is linear for every s ∈ S, it follows
from convexity of M that MS is convex as well. (Note that the empty set is trivially
convex.) If MS is empty, then by definition we also have BS? = ∅. On the other hand,
if MS 6= ∅, then the linearity of Γ? : M 7→ R implies that BS? ≡ Γ? (MS ) ⊆ R is a
?

convex set, and so its closure is [inf m∈MS Γ? (m), supm∈MS Γ? (m)] ≡ [β ? , β ]. Q.E.D.
Proof of Proposition 3. For notational simplicity, we define the set
Mid ≡ {m ∈ M : m satisfies (17) and (18) almost surely}.

58

For any m ≡ (m0 , m1 ) ∈ Mid and s ∈ S we obtain from the definition of βs that
βs = E[s(D, Z)E[Y |D, Z]] =

X

E[1[D = d]s(d, Z)E[Y |D = d, Z]].

(89)

d∈{0,1}

Examining the d = 0 term in the summation, we obtain
"

#
Z 1
1
E[1[D = 0]s(0, Z)E[Y |D = 0, Z]] = E 1[D = 0]s(0, Z)
m0 (u, X)du
1 − p(Z) p(Z)


Z 1
1
= E 1[D = 0]
m0 (u, X)ω0s (u, Z)du
1 − p(Z) 0
Z 1

=E
m0 (u, X)ω0s (u, Z)du ,
(90)
0

where the first equality follows from m ∈ Mid satisfying (17), the second equality
uses the definition ω0s (u, z) = s(0, z)1{u > p(z)}, and the final equality is implied by
P (D = 0|Z) = 1 − p(Z). By analogous arguments, we also obtain
Z

1

E[1[D = 1]s(1, Z)E[Y |D = 1, Z]] = E


m1 (u, X)ω1s (u, Z)du .

(91)

0

Together, (89), (90), and (91) imply that Γs (m) = βs . In particular, since s ∈ S and
m ∈ Mid were arbitrary, we conclude Mid ⊆ MS as claimed.
Next, suppose S = {s(d, z) = 1[d = d0 ]f (z) : (d0 , f ) ∈ {0, 1} × F} and that the
closed linear span of F is equal to L2 (Z). Then note that for any m ∈ MS and s ∈ S
with the structure s(d, z) = 1[d = 0]f (z) we obtain by definition of βs and Γs that
"Z

E[Y 1[D = 0]f (Z)] ≡ βs = Γs (m) = E

#

1

m0 (u, X)duf (Z)

(92)

p(Z)

where the second equality follows from m ∈ MS and the final equality is due to
ω0s (u, z) ≡ 1{u > p(z)}s(0, z) and s(0, z) = 1[0 = 0]f (z). Furthermore, define
∆(Z) ≡ E[Y 1[D = 0]|Z] −

Z

1

m0 (u, X)du

(93)

p(Z)

and note that (92) implies that E[∆(Z)f (Z)] = 0 for all f ∈ F. Since E[Y02 ] < ∞ by
R
Assumption I.2 and E[ m2d (u, X)du] < ∞, Jensen’s inequality implies that ∆ ∈ L2 (Z).
Thus, since E[∆(Z)f (Z)] = 0 for all f ∈ F and the closed linear span of F equals
L2 (Z), we conclude that ∆(Z) = 0 almost surely. Equivalently, since P (D = 0|Z) =

59

1 − p(Z) by definition of p(Z), we obtain whenever 1 − p(Z) > 0 that
1
E[Y |D = 0, Z] =
1 − p(Z)

Z

1

m0 (u, X)du

(94)

p(Z)

almost surely, i.e. m0 satisfies (17). Analogous arguments imply that m1 satisfies (18).
Since (m0 , m1 ) = m ∈ MS was arbitrary, we conclude that MS ⊆ Mid , which together
with (19) establishes (20).

Q.E.D.

Proof of Proposition 4. We prove the proposition for the upper bound of the target
parameter. The proof for the lower bound follows by identical arguments.
?

?

Observe that since Mfd ⊆ M, we can immediately conclude that β fd ≤ β . As for
the opposite inequality, let {z1 , . . . , zK } denote the discrete support of Z. Then notice
that for any (m0 , m1 ) = m ∈ M we have that


J X
K
X
Γds (md ) = E 
1[U ∈ Aj , Z = zk ]md (U, X)ωds (U, Z)
j=1 k=1



J X
K
X
E[md (U, X)|U ∈ Aj , Z = zk ]ωds (U, Z)1[U ∈ Aj , Z = zk ]
=E
j=1 k=1



J X
L
X
E[md (U, X)|U ∈ Aj , X = xl ]ωds (U, Z)1[U ∈ Aj , X = xl ] .
=E
j=1 l=1

(95)
The first equality here follows from {Aj }Jj=1 being a partition of [0, 1]. The second
equality follows because ωds (u, z) is constant on each set {u ∈ Aj , z = zk } given the
assumption that 1[u ≤ p(z)] is constant Aj —recall Proposition 1. The third equality
in (95) follows from X being a subvector of Z = (Z0 , X).
Given the definition of bjl (u, x) in (26), we can conclude from (95) that Γds (md ) =
Γds (Πmd ) for Πmd as defined in (27). An identical argument also yields Γ?d (md ) =
Γ?d (Πmd ). Hence, given the assumption that Πm ≡ (Πm0 , Πm1 ) ∈ Mfd , we have
?

β ≡ sup {Γ? (m) s.t. Γs (m) = βs for all s ∈ S}
m∈M

= sup {Γ? (Πm) s.t. Γs (Πm) = βs for all s ∈ S}
m∈M
?

≤ sup {Γ? (m) s.t. Γs (m) = βs for all s ∈ S} ≡ β fd .

(96)

m∈Mfd

?

?

We conclude that β fd = β .

Q.E.D.

60

B

MTR Weights for Linear IV Estimands

In this appendix, we show that linear IV estimands are a special case of our notion of
an IV–like estimand. For the purpose of this discussion, we adopt some of the standard
textbook terminology regarding “endogenous variables” and “included” and “excluded”
instruments in the context of linear IV models without heterogeneity. Consider a linear
e1 , included instruments Ze1 , and excluded
IV specification with endogenous variables X
0
e ≡ [X
e1 , Ze1 ] and Ze ≡ [Ze2 , Ze1 ]0 . We assume that both E[ZeZe0 ]
instruments Ze2 . We let X
e 0 ] have full rank.
and E[ZeX
e and Ze can be functions
As long as these two conditions hold, all of the variables in X
e1 would include D and possibly some
of (D, Z). Usually, one would expect that X
e would usually
interactions between D and other covariates X. The instruments, Z,
consist of functions of the vector Z, which contains X, by notational convention. The
e i.e. Ze1 , would typically also include a constant term as one
included portion of Z,
of its components. However, whether Ze is actually “exogenous” in the usual sense of
the linear instrumental variables model is not relevant to our definition of an IV–like
estimand or the derivation of the weighting expression (12). In particular, OLS is
e1
nested as a linear IV specification through the case in which Ze1 = [1, D]0 and both X
and Ze2 are empty vectors.
e as in “overidentified” linIt may be the case that Ze has dimension larger than X,
ear models. In such cases, a positive definite weighting matrix Π is used to generate
e A common choice of Π is the
instruments ΠZe that have the same dimension as X.
0
e Ze ]E[ZeZe0 ]−1 which has as its rows the
two-stage least squares weighting ΠTSLS ≡ E[X
e on
first stage coefficients corresponding to linear regressions of each component of X
e We assume that Π is a known or identified non-stochastic matrix
the entire vector Z.
with full rank. This covers ΠTSLS and the optimal weighting under heteroskedasticity
(optimal GMM) as particular cases given standard regularity conditions. The instrue in a regression of Y
mental variables estimator that uses ΠZe as an instrument for X
e has corresponding estimand
on X
βIV,Π



e 0]
≡ ΠE[ZeX

−1 




−1
0
e
e
e
e
ΠE[ZY ] = E ΠE[Z X ]
ΠZY ,

e 0 ])−1 ΠZ.
e
which is an IV–like estimand with s(D, Z) ≡ (ΠE[ZeX

61

C

Proofs for Section 5

Proof of Theorem 1. First, we show in Lemma D.1 that
Tn = sup

b∗ ∈D

o
√ n ∗
n hb , β̂i − ν(b∗ , Γ̂(M)) + Op (δns + δnc ),

(97)

uniformly over P ∈ P. Next, recalling that D is the unit sphere in B∗ and DP (κun ) is
defined as in (49), we define the event
"
Ωn (P ) ≡

n
o
hb∗ , β̂i − ν(b∗ , Γ̂(M)) ≤

sup
b∗ ∈D\DP (κu
n)

sup

#
n
o
hb∗ , β̂i − ν(b∗ , Γ̂(M)) .

b∗ ∈DP (κu
n)

(98)
For any b∗ ∈ B∗ , let
∆n (b∗ ) ≡

√

n
o
n hb∗ , β̂ − βP i − ν(b∗ , Γ̂(M)) − ν(b∗ , ΓP (M)) .

Observe that, since hb∗ , βP i − ν(b∗ , ΓP (M)) ≤ −κun for all b∗ ∈ D \ DP (κun ), we have
sup 2∆n (b∗ ) −

P (Ωn (P )c ) ≤ P

b∗ ∈D


≤P

∗

sup 2∆n (b ) >

b∗ ∈D

√

nκun >

√

nκun

sup
b∗ ∈DP (κu
n)

√

!
n {hb∗ , βP i − ν(b∗ , ΓP (M))}


(99)

where Ωn (P )c denotes the complement of Ωn (P ) and in the final inequality we used
√
0 ∈ DP (κun ). Hence, since nκun ↑ ∞, (99) and Lemma D.2 yield
lim sup sup P (Ωn (P )c ) = 0.

(100)

n→∞ P ∈P

In addition, note that the definition of ν(b∗ , Γ̂(M)) and Assumption S.3 imply
sup

o
√ n ∗
n hb , β̂i − ν(b∗ , Γ̂(M))

b∗ ∈DP (κu
n)

=
=

sup

inf

n
o
√
√
√
hb∗ , n{β̂ − βP } − n{Γ̂(m) − ΓP (m)}i + nhb∗ , βP − ΓP (m)i

sup

inf

 ∗
√
hb , GP,β − GP,Γ (m)i + nhb∗ , βP − ΓP (m)i + Op (δnc )

m∈M
b∗ ∈DP (κu
n)
m∈M
b∗ ∈DP (κu
n)

(101)

uniformly in P ∈ P. The first claim of Theorem 1 now follows from (97), (100), and
(101) together with δnc ↓ 0 and δns ↓ 0 from Assumptions S.3 and S.5.
To establish the second claim, we note that if P ∈ P0 , then the set {m ∈ M :

62

√

nhb∗ , βP − ΓP (m)i ≤ δns } cannot be empty for any b∗ ∈ B∗ , because for such P there

exists an mP ∈ M such that βP = ΓP (mP ). Hence, we conclude from (97), (100), and
(101) that
Tn =

sup
b∗ ∈D

inf

u
P (κn )

m∈M



hb∗ , GP,β − GP,Γ (m)i +

√

nhb∗ , βP − ΓP (m)i + Op (δnc + δnc )

≤ UP,n (κun ) + Op (δnc + δns ) + δns

(102)

uniformly in P ∈ P0 , where the inequality follows by set inclusion and the definition
of UP,n (κun ). This implies the second claim of Theorem 1.

Q.E.D.

Proof of Lemma 5.1. Note that D̂n ⊆ D, M̂n ⊆ M, and |hb∗ , bi| ≤ kb∗ kB∗ kbkB ≤
kbkB for any b∗ ∈ D. These observations with Assumption S.6 imply
sup

sup
b∗ ∈D̂

n

bs
hb∗ , Ĝβ − ĜΓ (m)i − hb∗ , Gbs
P,β − GP,Γ (m)i

m∈M̂n

∗
bs
c
≤ kĜβ − Gbs
P,β kB + sup sup hb , ĜΓ (m) − GP,Γ (m)i = Op (δn )

(103)

b∗ ∈D m∈M

uniformly in P ∈ P. Next, define the event Ωn (P ) ≡ Ω1n (P ) ∩ Ω2n (P ) where
h
i
Ω1n (P ) ≡ DP (κn ) ⊆ D̂n
h
i
and Ω2n (P ) ≡ Πn mP ∈ M̂n for all mP ∈ M s.t. ΓP (mP ) = βP .
Observe that Lemmas D.4 and D.5 imply


c

lim sup sup P (Ωn (P ) ) ≤ lim sup
n→∞ P ∈P0

n→∞


sup P (Ω1n (P ) ) + sup P (Ω2n (P ) ) = 0. (104)
c

P ∈P

c

P ∈P0

Moreover, {m ∈ M : ΓP (m) = βP } 6= ∅ for every P ∈ P0 . It follows that, for any
P ∈ P0 , if Ωn (P ) occurs, then it is also true that M̂n 6= ∅. In this event, Lemma
D.3 implies that for any b∗ ∈ B∗ there exists an m ∈ M̂n such that hb∗ , ΓP (m)i =
ν(b∗ , ΓP (M̂n )), so that In (ΓP ) is indeed well defined. Thus, (103) and (104) yield
In (ΓP ) = sup

inf

b∗ ∈D̂n m∈M̂n

n
bs
hb∗ , Gbs
P,β − GP,Γ (m)i
o
s.t. hb∗ , ΓP (m)i = ν(b∗ , ΓP (M̂n )) + Op (δnc )

(105)

uniformly in P ∈ P0 .
Next, note that, for any b∗ ∈ D, if m̂ ∈ M̂n satisfies hb∗ , ΓP (m̂)i = ν(b∗ , ΓP (M̂n )),
then it also satisfies hb∗ , ΓP (m̂ − m)i ≥ 0 for all m ∈ M̂n . Hence, when Ω2n (P ) is true,

63

we obtain
√

nhb∗ , βP − ΓP (m̂)i ≤
≤

√
√

nhb∗ , ΓP (mP ) − ΓP (Πn mP )i
nkΓP (mP − Πn mP )kB ≤ δns

(106)

for any b∗ ∈ D, any m̂ ∈ Mn satisfying hb∗ , ΓP (m̂)i = ν(b∗ , ΓP (M̂n )), and every
mP ∈ M such that ΓP (mP ) = βP . The second equality in (106) used hb∗ , bi ≤ kbkB
for all b∗ ∈ D, while the third inequality followed from Assumption S.5. Since under
Ω1n (P ) we have DP (κn ) ⊆ D̂n , (106) and Ωn (P ) ≡ Ω1n (P ) ∩ Ω2n (P ) imply that
whenever Ωn (P ) occurs
u
Ubs
P,n (κn ) ≤ sup

inf

b∗ ∈D̂n m∈M̂n

n
o
bs
∗
∗
hb∗ , Gbs
−
G
(m)i
s.t.
hb
,
Γ
(m)i
=
ν(b
,
Γ
(
M̂
))
.
n
P
P
P,Γ
P,β
(107)

The result now follows from (107) together with (104) and (105).

Q.E.D.

Proof of Lemma 5.2. Since {m ∈ M : βP = ΓP (m)} 6= ∅ for all P ∈ P0 , Lemma
D.5 implies that
lim inf inf P (M̂n 6= ∅) = 1.
n→∞ P ∈P0

(108)

Given (108), we establish the claim by showing that (67) holds whenever M̂n 6= ∅.
To this end, note that if M̂n 6= ∅, then by definition of the support function, an m ∈
M̂n satisfies hb∗ , ΓP (m)i = ν(b∗ , ΓP (M̂n )) if and only if it satisfies hb∗ , ΓP (m− m̃)i ≥ 0
for all m̃ ∈ M̂n . Equivalently, since hb∗ , ΓP (m)i = hΓ∗P (b∗ ), mi for all (b∗ , m) ∈ B∗ ×M,
we obtain by set inclusion that
In (ΓP ) = sup

inf

b∗ ∈D̂n m∈M̂n

≥ sup

sup

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hΓ∗ (b∗ ), m − m̃i ≥ 0 for all m̃ ∈ M̂n
inf

b∗ ∈D̂n m̃∈M̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hΓ∗ (b∗ ), m − m̃i ≥ 0 .

(109)

For any (b∗ , m̃) ∈ D̂n × M̂n , define
C(b∗ , m̃) ≡ {m ∈ M̂n : hΓ∗P (b∗ ), m − m̃i ≥ 0}.
Recall that Γ∗P (b∗ ) ∈ M∗ and that M̂n is compact in the weak topology by Lemma D.3.
It follows that, provided M̂n 6= ∅, there exists an mob∗ ∈ M̂n such that hΓ∗P (b∗ ), mob∗ i =
supm∈M̂n hΓ∗ (b∗ ), mi. Such an mob∗ satisfies C(b∗ , mob∗ ) ⊆ C(b∗ , m̃) for all m̃ ∈ M̂n .

64

Using set inclusion and hΓ∗P (b∗ ), mob∗ − m̃i ≥ 0 for all m̃ ∈ M̂n , we obtain
sup
b∗ ∈D̂

inf {hb∗ , Ĝβ − ĜΓ (m)i s.t. hΓ∗ (b∗ ), m − m̃i ≥ 0}

sup

m∈M̂n
n m̃∈M̂n

= sup

hb∗ , Ĝβ − ĜΓ (m)i

inf

(110)

o
∗
b∗ ∈D̂n m∈C(b ,mb∗ )

inf {hb∗ , Ĝβ − ĜΓ (m)i s.t. hΓ∗P (b∗ ), m − m̃i ≥ 0 for all m̃ ∈ M̂n }.

= sup
b∗ ∈D̂

m∈M̂n
n

The claim now follows from (109) and (110).

Q.E.D.

Proof of Theorem 2. For any b∗ ∈ B∗ , define the set
G̃n (b∗ ) ≡ {g ∈ M∗ : |hg − Γ̂∗ (b∗ ), vi| ≤ κ̂qn for all v ∈ Vn }.
and define
T̃nbs ≡ sup
b∗ ∈D̂

inf {hb∗ , Ĝβ − ĜΓ (m)i s.t. hg̃, m − m̃i ≥ 0}.

sup

∗
n (g̃,m̃)∈G̃n (b )×M̂n

(111)

m∈M̂n

Define the event Ωn (P ) ≡ Ω1n (P ) ∩ Ω2n (P ), where
h
i
Ω1n (P ) ≡ Γ∗P (b∗ ) ∈ G̃n (b∗ ) for all b∗ ∈ D̂n
h
i
Ω2n (P ) ≡ Tnbs = T̃nbs .

(112)
(113)

We show that Ωn (P ) occurs with probability approaching 1, uniformly over P ∈ P0 .
Using the definition of G̃n (b∗ ) and Assumption S.10 we have
lim inf inf P (Ω1n (P ))
n→∞ P ∈P

≥ lim inf inf P
n→∞ P ∈P

√
√
sup sup |h n{Γ∗P (b∗ ) − Γ̂∗ (b∗ )}, vi| ≤ nκ̂gn

b∗ ∈D̂n v∈Vn

≥ lim inf lim inf inf P
C↑∞

!

n→∞ P ∈P

√
sup sup |h n{Γ∗P (b∗ ) − Γ̂∗ (b∗ )}, vi| ≤ C

!
.

(114)

b∗ ∈D̂n v∈Vn

Recall that under Assumption S.11, Vn ⊆ λ(Mn − mc ) for some mc ∈ Mn , while
Mn ⊆ M by Assumption S.5, and D̂n ⊆ D by construction. Using these inclusions,

65

we have
√
sup sup h n{Γ∗P (b∗ ) − Γ̂∗ (b∗ )}, vi

b∗ ∈D̂n v∈Vn

≤ sup
b∗ ∈D

sup
m1 ,m2 ∈M

√
h n{Γ∗P (b∗ ) − Γ̂∗ (b∗ )}, λ(m1 − m2 )i

√
≤ sup sup 2|λ| hb∗ , n{Γ̂ − ΓP }(m)i
b∗ ∈D m∈M

= sup sup 2|λ| |hb∗ , GP,Γ (m)i| + Op (δnc )

(115)

b∗ ∈D m∈M

where the second inequality follows from Γ̂∗ and Γ∗P being the adjoints of Γ̂ and ΓP
respectively, while the equality follows from Assumption S.3, and holds uniformly over
P ∈ P. Since |hb∗ , bi| ≤ kbkB for all b∗ ∈ D and b ∈ B, (115) implies that
√
sup sup |h n{Γ∗P (b∗ ) − Γ̂∗ (b∗ )}, vi| ≤ C

lim inf lim inf inf P
C↑∞

n→∞ P ∈P

b∗ ∈D̂n v∈Vn


≥ lim inf inf P
C↑∞ P ∈P

!

C
sup 2|λ|kGP,Γ (m)kB ≤
2
m∈M


=1

(116)

where we have applied Markov’s inequality with Assumption S.4. From (114), (116),
and Lemma D.6 we conclude that


c

lim sup sup P (Ωn (P ) ) ≤ lim sup
n→∞ P ∈P0

n→∞


sup P (Ω1n (P ) ) + sup P (Ω2n (P ) ) = 0. (117)
c

P ∈P

c

P ∈P0

Next, we recall that Lemma 5.1 establishes that for any κun satisfying Assumption
√
S.8 and nκun ↑ ∞, there exists a ξ˜nbs ∈ R satisfying ξ˜nbs = Op (δnc ) uniformly in P ∈ P0
such that
u
˜bs
Ubs
P,n (κn ) ≤ In (ΓP ) + ξn

(118)

for all P ∈ P0 . From Lemma 5.2 we can conclude that In (ΓP ) ≤ T̃nbs whenever the
event Ω1n (P ) occurs, whereas by definition Tnbs = T̃nbs whenever the event Ω2n (P )
occurs. Therefore, the claim of the result follow from (117), (118), and setting ξnbs =
ξ˜nbs + 1{{Yi , Zi }ni=1 ∈ Ωn (P )c }(In (ΓP ) − Tnbs ).
Q.E.D.
Proof of Theorem 3. The proof of the first claim closely follows the arguments in
Lemma D.6 of Chernozhukov et al. (2015).
First, note that Theorems 1 and 2 imply that
Tn ≤ UP,n (κun ) + Op (δnc + δns )

u
bs
c
and Ubs
P,n (κn ) ≤ Tn + Op (δn ),

66

(119)

both uniformly over P ∈ P. Together with Markov’s inequality, this implies that for
any  > 0 and Cn ↑ ∞ we have
 


u
bs
c
n
lim sup sup P P Ubs
(κ
)
>
T
+
C
δ
|{Y
,
D
,
Z
}
>

n n
i
i
i i=1
P,n n
n
n→∞ P ∈P0

≤ lim sup sup
n→∞ P ∈P0


1  bs u
P UP,n (κn ) > Tnbs + Cn δnc = 0.


(120)

In particular, this implies that there is a sequence ηn ↓ 0 (which depends on Cn ↑ ∞)
such that the event
h


i
u
bs
c
n
Ωn (P ) ≡ {Yi , Di , Zi }ni=1 : P Ubs
(κ
)
>
T
+
C
δ
|{Y
,
D
,
Z
}
≤
η
n n
i
i
i i=1
n
P,n n
n

(121)

satisfies supP ∈P0 P (Ωn (P )c ) = o(1). Furthermore, for any t ∈ R,


P Tnbs ≤ t|{Yi , Di , Zi }ni=1 1 [{Yi , Di , Zi }ni=1 ∈ Ωn (P )]


u
bs
c
n
≤ P Tnbs ≤ t and Ubs
(κ
)
≤
T
+
C
δ
|{Y
,
D
,
Z
}
n n
i
i
i i=1 + ηn
P,n n
n


u
c
≤ P Ubs
P,n (κn ) ≤ t + Cn δn + ηn ,

(122)

u
n
where the final inequality used the independence of Ubs
P,n (κn ) and {Yi , Di , Zi }i=1 under

Assumption S.6.
By evaluating (122) at t = ĉ1−α , we obtain



P ĉ1−α + Cn δnc ≥ c1−α−ηn (UP,n (κun )) ≥ P {Yi , Di , Zi }ni=1 ∈ Ωn (P )

(123)

u
where used the equality in distribution of UP,n (κun ) and Ubs
P,n (κn ) under Assumption

S.6. Theorem 1, (123), and supP ∈P0 P (Ωn (P )c ) = o(1) then yield
lim sup sup P (Tn > ĉ1−α )
n→∞ P ∈P0

≤ lim sup sup P UP,n (κun ) + Cn (δns + δnc ) > ĉ1−α



n→∞ P ∈P0


≤ lim sup sup P UP,n (κun ) > c1−α−ηn (UP,n (κun )) − 2Cn (δnc + δns ) .

(124)

n→∞ P ∈P0

Notice, however, that because ζn (defined in Assumption S.12) satisfies ζn (δns + δnc ) =
o(1), we can select Cn ↑ ∞ slowly enough so that ζn Cn (δns + δnc ) = o(1). Since ηn ↓ 0,

67

we conclude that for such a choice of Cn ,


lim sup sup P c1−α−ηn (UP,n (κun )) ≥ UP,n (κun ) > c1−α−ηn (UP,n (κun )) − 2Cn (δnc + δns )
n→∞ P ∈P0

≤ lim sup ζn × 2Cn (δnc + δns ) = 0.

(125)

n→∞

Combining (124) and (125) establishes the first claim, since


lim sup sup P (Tn > ĉ1−α ) ≤ lim sup sup P UP,n (κun ) > c1−α−ηn (UP,n (κun )) ≤ α.
n→∞ P ∈P0

n→∞ P ∈P0

(126)
To establish the second claim, we first note that for any

b∗

∈

B∗ ,

and any sequence

mn that converges (in the weak topology) to an m ∈ M, we have
lim hb∗ , ΓP (mn ) − ΓP (m)i = lim hΓ∗P (b∗ ), mn − mi = 0,

n→∞

n→∞

(127)

which implies ΓP : M 7→ B is continuous when both M and B are equipped with their
respective weak topologies. Also, note that m 7→ kβP − ΓP (m)kB is lower semicontinuous (with respect to the weak topologies), which follows because ΓP : M 7→ B is
continuous, and because the norm functional k·kB is lower semicontinuous with respect
to the weak topology in B (see Lemma 6.22 in Aliprantis and Border (2006)). Since
M is compact in the weak topology by Assumption S.1, we conclude that
∆0 ≡ inf kβP − ΓP (m)kB = min kβP − ΓP (m)kB > 0
m∈M

m∈M

(128)

for any P ∈ P \ P0 .
Next, observe that Lemmas D.1 and D.2 imply that for any P ∈ P \ P0
Tn = sup

b∗ ∈D

= sup

o
√ n ∗
n hb , β̂i − ν(b∗ , Γ̂(M)) + op (1)
√

b∗ ∈D

= inf

m∈M

n {hb∗ , βP i − ν(b∗ , ΓP (M))} + Op (1)

√

nkβP − ΓP (m)kB + Op (1) =

√

n∆0 + Op (1),

(129)

where the third equality holds by Theorem 5.13.1 in Luenberger (1969), and the final
equality in (129) follows from (128). On the other hand, for any C > 0 we have
 


1
P (ĉ1−α > C) ≤ P P Tnbs > C|{Yi , Di , Zi }ni=1 > α ≤ P (Tnbs > C),
α

(130)

where the first inequality follows by definition of ĉ1−α and the second by Markov’s

68

inequality. From D̂ ⊆ D, M̂n ⊆ M, and supb∗ ∈D hb∗ , bi = kbkB for any b ∈ B (see
Lemma 6.10 in Aliprantis and Border (2006)), and Assumption S.6, we obtain
Tnbs ≤ kĜβ kB + sup sup hb∗ , −ĜΓ (m)i
b∗ ∈D m∈M

∗
bs
= kGbs
P,β kB + sup sup hb , −GP,Γ (m)i + op (1)
b∗ ∈D m∈M

bs
= kGbs
P,β kB + sup kGP,Γ (m)kB + op (1).

(131)

m∈M

Assumptions S.4 and S.6 together with (131) then imply that Tnbs = Op (1) under any
P ∈ P. We conclude from (130) that
lim sup lim sup P (ĉ1−α > C) = 0.

(132)

n→∞

C↑∞

The second claim now follows from (129) and (132).

D

Q.E.D.

Proofs of Auxiliary Results

Lemma D.1. If Assumptions S.1, S.2, S.3, and S.5 hold, then

lim sup lim sup sup P
C↑∞

n→∞ P ∈P


o
√ n ∗
∗
c
s
Tn − sup n hb , β̂i − ν(b , Γ̂(M)) > C(δn + δn ) = 0.
b∗ ∈D

Proof of Lemma D.1. Assumption S.5 implies that
inf

m∈Mn

√

nkβ̂ − Γ̂(m)kB ≤ inf

m∈M

≤ inf

m∈M

√
√

nkβ̂ − Γ̂(Πn m)kB

(133)

nkβ̂ − Γ̂(m)kB + sup

√

nkΓ̂(m) − Γ̂(Πn m)kB ,

m∈M

where the first inequality follows from Πn m ∈ Mn for all m ∈ M, and the second
inequality applies the triangle inequality. Note that
kbkB = sup hb∗ , bi

(134)

b∗ ∈D

for any b ∈ B; see, e.g., Lemma 6.10 in Aliprantis and Border (2006). Assumption S.3

69

with (134) imply
√

sup

nkΓ̂(m − Πn m) − ΓP (m − Πn m)kB

m∈M

√
= sup sup hb∗ , n{Γ̂ − ΓP }(m − Πn m)i
m∈M b∗ ∈D

= sup sup hb∗ , GP,Γ (m) − GP,Γ (Πn m)i + Op (δnc )

(135)

m∈M b∗ ∈D

uniformly in P ∈ P. Similarly, Assumption S.5 with (134) imply



sup E sup sup hb , GP,Γ (m) − GP,Γ (Πn m)i
m∈M b∗ ∈D
P ∈P


= sup E sup kGP,Γ (m) − GP,Γ (Πn (m))kB = O(δns ).
∗

P ∈P

(136)

m∈M

Combining (133), (135), and (136) with Assumption S.5 and applying Markov’s inequality, we obtain
inf

√

m∈Mn

nkβ̂ − Γ̂(m)kB ≤ inf

√

m∈M

≤ inf

nkβ̂ − Γ̂(m)kB + Op (δns + δnc )

√

m∈Mn

nkβ̂ − Γ̂(m)kB + Op (δns + δnc )

(137)

uniformly in P ∈ P, where the second inequality in (137) used Mn ⊆ M.
Since Γ̂ : M 7→ B is continuous under Assumption S.2, we can define its adjoint
Γ̂∗

: B∗ 7→ M∗ , so that hb∗ , Γ̂(m)i = hΓ̂∗ (b∗ ), mi. Note that Γ̂∗ (b∗ ) ∈ M∗ , and therefore

hb∗ , Γ̂(m)i = hΓ̂∗ (b∗ ), mi implies m 7→ hb∗ , Γ̂(m)i is continuous in the weak topology.
Then, since M is compact in the weak topology under Assumption S.1, we obtain
Tn = inf sup

m∈M b∗ ∈D

√

nhb∗ , β̂ − Γ̂(m)i + Op (δnc + δns )

√

nhb∗ , β̂ − Γ̂(m)i + Op (δnc + δns )
o
√ n
= sup n hb∗ , β̂i − ν(b∗ , Γ̂(M)) + Op (δnc + δns ),
= sup inf
b∗ ∈D

m∈M

(138)

b∗ ∈D

uniformly in P ∈ P, where the first equality follows from results (134) and (137),
the second equality results from Theorem 4.2 in Sion (1958), and the final equality is
implied by the definition of ν(b∗ , Γ̂(M)). The claim now follows from (138).

70

Q.E.D.

Lemma D.2. If Assumptions S.3 and S.4 hold, then
lim lim sup sup

C↑∞ n→∞ P ∈P

n
o
C
sup sup hb , β̂ − βP i − ν(b∗ , Γ̂(C)) − ν(b∗ , ΓP (C)) > √
∗
n
b ∈D C⊆M

!

∗

P

= 0.

Proof of Lemma D.2. Throughout the proof, we use (134) from Lemma D.1, see
e.g. Lemma 6.10 in Aliprantis and Border (2006). Together with Assumption S.3, this
implies that
sup
b∗ ∈D

√
√
n|hb∗ , β̂ − βP i| = k n{β̂ − βP }kB = kGP,β kB + op (1)

(139)

uniformly in P ∈ P. Similarly,
sup sup
b∗ ∈D

√

n|ν(b∗ , Γ̂(C)) − ν(b∗ , ΓP (C))|

C⊆M

= sup sup
b∗ ∈D

√

n sup hb∗ , Γ̂(m)i − sup hb∗ , ΓP (m)i

C⊆M

m∈C
∗

≤ sup sup |hb ,
b∗ ∈D m∈M

√

m∈C

n{Γ̂ − ΓP }(m)i| = sup kGP,Γ (m)kB + op (1),

(140)

m∈M

uniformly in P ∈ P, where the inequality follows from C ⊆ M, and the final equality
follows from Assumption S.3. From (139) and (140), we conclude that for any C > 0,
C
lim sup sup P sup sup hb∗ , β̂ − βP i − {ν(b∗ , Γ̂(C)) − ν(b∗ , ΓP (C))} > √
n
n→∞ P ∈P
b∗ ∈D C⊆M


C
≤ sup P kGP,β kB + sup kGP,Γ (m)kB >
2
m∈M
P ∈P
so that the result follows from Markov’s inequality with Assumption S.4.

!

Q.E.D.

Lemma D.3. If Assumptions S.1, S.2, and S.7 hold, then M̂n is compact in the weak
topology. Moreover, if M̂n 6= ∅, then for all b∗ ∈ B∗
n
o
m ∈ M̂n : hb∗ , ΓP (m)i = ν(b∗ , ΓP (M̂n )) 6= ∅.
Proof of Lemma D.3. We note that {m ∈ M : kβ̂ − Γ̂(m)kB ≤ κ̂m
n } is closed in the
weak topology of M. This follows by Lemma 6.22 in Aliprantis and Border (2006),
which implies that {b ∈ B : kβ̂ − bkB ≤ κ̂m
n } is closed in the weak topology of B,
and because Γ̂ : M 7→ B is continuous and linear under Assumption S.2. Hence,

71

{m ∈ M : kβ̂ − Γ̂(m)kB ≤ κ̂m
n } being closed, together with Assumption S.7 and
M̂n = Mn ∩ {m ∈ M : kβ̂ − Γ̂(m)kB ≤ κ̂m
n },

(141)

shows that M̂n is closed in the weak topology, and therefore compact in the weak
topology, since M̂n ⊆ M and M is compact under Assumption S.1. Provided that
M̂n 6= ∅, it follows that for any b∗ ∈ B∗
ν(b∗ , ΓP (M̂n )) ≡ sup hb∗ , ΓP (m)i = max hΓ∗P (b∗ ), mi,

(142)

m∈M̂n

m∈M̂n

where attainment in the final equality is guaranteed by the compactness of M̂n in the
weak topology and the continuity of m 7→ hΓ∗P (b∗ ), mi in the weak topology.

Q.E.D.

Lemma D.4. Suppose that Assumptions S.3 and S.4 hold. Then
lim inf inf P (DP (κun ) ⊆ D̂n ) = 1
n→∞ P ∈P

for any non-random sequence κun that satisfies Assumption S.8 and

√

nκun ↑ ∞.

Proof of Lemma D.4. For any b∗ ∈ B∗ and Mn ⊆ M, define
∆n (b∗ ) ≡

√

n
o
n hb∗ , β̂ − βP i − ν(b∗ , Γ̂(Mn )) − ν(b∗ , ΓP (Mn )) .

(143)

Using the definition of DP (κun ), and noting that Mn ⊆ M implies ν(b∗ , ΓP (Mn )) ≤
ν(b∗ , ΓP (M)) for all b∗ ∈ B∗ , we have
inf

b∗ ∈DP (κu
n)


∆n (b∗ )
inf
hb , βP i − ν(b , ΓP (Mn )) − √
n
b∗ ∈DP (κu
n)


∗
∆n (b )
√
≥ − sup
+ κun .
(144)
n
∗
u
b ∈DP (κn )


n
o
hb∗ , β̂i − ν(b∗ , Γ̂(Mn )) ≥

∗

∗

The definition of D̂n , together with (144) and Lemma D.2, then implies that
lim inf inf P (DP (κun ) ⊆ D̂n ) ≥ lim inf inf P
n→∞ P ∈P0

n→∞ P ∈P0


sup
b∗ ∈D

u
P (κn )

∆n (b∗ )
√
+ κun
n

≥ lim inf inf P ((1 + δ)κun ≤ κ̂un ) = 1,
n→∞ P ∈P0

where the final equality follows by Assumption S.8 for some δ > 0.

72



!
≤ κ̂un
(145)
Q.E.D.

Lemma D.5. Suppose that Assumptions S.3–S.5 and S.9 hold. Then
lim inf inf P (Πn mP ∈ M̂n for all mP ∈ M s.t. ΓP (mP ) = βP ) = 1.
n→∞ P ∈P0

Proof of Lemma D.5. Note that if βP = ΓP (mP ), then by the triangle inequality
kβ̂ − Γ̂(Πn mP )kB
≤ kβ̂ − βP kB + kΓP (mP ) − ΓP (Πn mP )kB + kΓP (Πn mP ) − Γ̂(Πn mP )kB . (146)
Using (134) from Lemma D.1 together with Assumption S.3, we have
√
sup k n{Γ̂ − ΓP }(m) − GP,Γ (m)kB = op (1),

(147)

m∈M

uniformly over P ∈ P. Assumptions S.3 and S.5, together with (146) and (147), imply
√

sup

nkβ̂ − Γ̂(Πn mP )kB

mP ∈M:ΓP (mP )=βP

≤

{kGP,β kB + kGP,Γ (Πn mP )kB } + op (1),

sup

(148)

mP ∈M:ΓP (mP )=βP

uniformly over P ∈ P. Then by Assumption S.9, (148), and the definition of M̂n ,
lim inf inf P (Πn mP ∈ M̂n for all mP ∈ M s.t. ΓP (mP ) = βP )
n→∞ P ∈P0

√

≥ lim inf inf P
n→∞ P ∈P0

sup

{kGP,β kB + kGP,Γ (Πn mP )kB } ≤

mP ∈M:ΓP (mP )=βP

nκ̂m
n
2

(149)
!
.

Moreover, by Assumptions S.4, S.9, and Markov’s inequality,
√



nκ̂m
n
2



sup {kGP,β kB + kGP,Γ (m)kB } ≤


≥ lim inf inf P sup {kGP,β kB + kGP,Γ (m)kB } ≤ C = 1.

lim inf inf P
n→∞ P ∈P0

m∈M

C↑∞ P ∈P0

(150)

m∈M

The result follows from (149) and (150).

Q.E.D.

Lemma D.6. Suppose that Assumptions S.2–S.5, S.9, and S.11 hold. Define the set
G̃n (b∗ ) ≡ {g ∈ M∗ : |hg − Γ̂∗ (b∗ ), vi| ≤ κ̂qn for all v ∈ Vn }

73

and the statistic
T̃nbs ≡ sup

sup

inf

b∗ ∈D̂n (g̃,m̃)∈G̃n (b∗ )×M̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hg̃, m − m̃i ≥ 0 .

Then Tnbs = T̃nbs with probability tending to one, uniformly in P ∈ P0 .
Proof of Lemma D.6. Since {m ∈ M : βP = ΓP (m)} 6= ∅ for all P ∈ P0 , Lemma
D.5 implies that
lim inf inf P (M̂n 6= ∅) = 1.
n→∞ P ∈P0

(151)

Hence, the claim follows provided that Tnbs = T̃nbs whenever M̂n 6= ∅.
To show this, note that because Mn ⊆ M, the restriction of any g ∈ M∗ to Mn is
a continuous linear functional on Mn . That is, for any g ∈ M∗ there exists a gn ∈ M∗n
such that hg − gn , mi = 0 for all m ∈ Mn . Since Vn ⊆ Mn by Assumption S.11,
and because ∅ 6= M̂n ⊆ Mn ⊆ Mn , it follows that for any g̃ ∈ G̃n (b∗ ) there exists a
g ∈ Ĝn (b∗ ) such that hg − g̃, mi = 0 for all m ∈ M̂n . As a consequence,
T̃nbs ≤ sup

sup

inf

b∗ ∈D̂n (g,m̃)∈Ĝn (b∗ )×M̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0 . (152)

Conversely, note that any gn ∈ M∗n is a continuous linear functional defined on
Mn , which is a subspace of M. By the Hahn-Banach Theorem (see e.g. Theorem 5.4.1
of Luenberger (1969)), there exists an extension g ∈ M∗ such that hgn − g, mi = 0
for all m ∈ Mn . As before, since Vn ⊆ Mn under Assumption S.11, and because
∅ 6= M̂n ⊆ Mn , we can conclude that for any g ∈ Ĝn (b∗ ) there exists a g̃ ∈ G̃n (b∗ ) such
that hg − g̃, mi = 0 for all m ∈ M̂n . Hence, we conclude that
T̃nbs ≥ sup

sup

inf

b∗ ∈D̂n (g,m̃)∈Ĝn (b∗ )×M̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0 . (153)

The result now follows from (152), (153), and the definition of Tnbs .

E

Q.E.D.

Computation for Infinite B

Whenever B is infinite dimensional, i.e. we are employing an infinite number of IVlike specifications S, the dual space B∗ is infinite dimensional as well. Computing
the bootstrap statistic Tnbs may be challenging in this situation. In this appendix, we
provide a supplemental result that establishes appropriate conditions under which Tnbs
can be approximated by a finite dimensional optimization problem when B∗ is infinite
dimensional.

74

Let Dn ⊆ D be a finite dimensional subset of D and, in analogy to D̂n , define
D̃n ≡ {b∗ ∈ Dn : hb∗ , β̂i − ν(b∗ , Γ̂(Mn )) ≥ −κ̂un }.

(154)

Heuristically, D̃n consists of the set of “directions” b∗ in the sieve Dn that are “close”
to binding. Notice the contrast to D̂n , which contains all such directions in D and
hence is potentially infinite dimensional. Define the bootstrap statistic
Cnbs ≡ sup
b∗ ∈D̃

n

inf {hb∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0},

sup
(g,m̃)∈Ĝn

(b∗ )×M̂

(155)

m∈M̂n
n

where M̂n and Ĝn (b∗ ) remain as defined in (61) and (68), respectively. That is, Cnbs is
identical to Tnbs , with the exception that D̂n has been replaced by D̃n .
In the following, we show that a version of Theorem 2 continues to hold with Cnbs
in place of Tnbs . This implies that Cnbs is also a valid bootstrap statistic. To do this,
we impose the following conditions on the sieve Dn for D:
Assumption U
For every b∗ ∈ D there exists a Πn b∗ ∈ Dn ⊆ D such that
sup sup
P ∈P b∗ ∈D
"

√

n|hb∗ − Πn b∗ , βP i| ≤ δnb ,
sup

sup E
and

#
∗

P ∈P

(b∗ ,m)∈D×M

sup

sup

P ∈P

(b∗ ,m)∈D×M

√

∗

|hb − Πn b , GP,β − GP,Γ (m)i| ≤ δnb ,

n|hb∗ − Πn b∗ , ΓP (m)i| ≤ δnb ,

for some δnb ↓ 0.
Assumption U places conditions on the sieve Dn that are analogous to those required
of Mn by Assumption S.5. We note that Assumption U imposes no constraints on the
rate of growth of Dn . Instead, Assumption U demands that the rate of growth of Dn be
sufficiently fast so that the approximation error introduced from optimizing over Dn in
place of D is asymptotically negligible. This is likely to be the case when computation
is the primary reason for using Dn over D. Our next result provides an analog to
Theorem 2 for situations when a sieve Dn is used in place of D.
Lemma E.1. Suppose that Assumptions S.1–S.7, S.9–S.11, and U hold. Then, for
√
any sequence κun that satisfies Assumption S.8, as well as nκun ↑ ∞, there exists a

75

sequence ξnbs ∈ R, with ξnbs = Op (δnc + δnb ) uniformly in P ∈ P0 , and such that
u
bs
bs
Ubs
P,n (κn ) ≤ Cn + ξn

(156)

for any P ∈ P0 .
Proof of Lemma E.1. We begin by defining an auxiliary lower bound CnL . Note
that since κ̂un satisfies Assumption S.8, there exists an η ∈ (0, 1) such that

lim inf inf P
n→∞ P ∈P


ηκ̂un
L
> (1 + δ ) = 1
κun

(157)

for some δ L > 0. Define
D̂nL ≡ {b∗ ∈ D : hb∗ , β̂i − ν(b∗ , Γ̂(Mn )) ≥ −ηκ̂un }
and ĜnL (b∗ ) ≡ {g ∈ M∗n : |hg, vi − hb∗ , Γ̂(v)i| ≤ ηκ̂gn for all v ∈ Vn },
then let
CnL ≡ sup

sup

inf

L (g,m̃)∈Ĝ L (b∗ )×M̂ m∈M̂n
b∗ ∈D̂n
n
n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0 .

(158)

Note that Assumption S.10 is satisfied with ηκ̂gn replacing κ̂gn , and that (157) implies
that Assumption S.8 is also satisfied with ηκ̂un in place of κ̂un . Hence, from Theorem 2,
we can conclude that
u
L
L
Ubs
P,n (κn ) ≤ Cn + ξn ,

(159)

uniformly over P ∈ P0 , with ξnL = Op (δnc ).
Next, note that because Dn ⊆ D by Assumption U, and since |hb∗ , bi| ≤ kbkB for
any b∗ ∈ D, we have
bs
sup sup |hb∗ − Πn b∗ , Ĝβ − ĜΓ (m)i − hb∗ − Πn b∗ , Gbs
P,β − GP,Γ (m)i|

b∗ ∈D m∈M

∗
bs
c
≤ 2kĜβ − Gbs
P,β kB + sup sup 2|hb , ĜΓ (m) − GP,Γ (m)i| = Op (δn ),

(160)

b∗ ∈D m∈M

uniformly over P ∈ P, where the final equality is due to Assumption S.6. Moreover,
bs
b
sup sup |hb∗ − Πn b∗ , Gbs
P,β − GP,Γ (m)i| = Op (δn )

(161)

b∗ ∈D m∈M

uniformly in P ∈ P by Assumptions S.6, U, and Markov’s inequality. Together, (160),

76

(161) imply that
CnL = sup

sup

inf

L (g,m̃)∈Ĝ L (b∗ )×M̂ m∈M̂n
b∗ ∈D̂n
n
n

n
o
hΠn b∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0

+ Op (δnc + δnb )

(162)

uniformly in P ∈ P.
Define the event Ωn (P ) ≡ Ω1n (P ) ∩ Ω2n (P ), where
h
i
Ω1n (P ) ≡ Πn b∗ ∈ D̃n for all b∗ ∈ D̂nL
i
h
Ω2n (P ) ≡ ĜnL (b∗ ) ⊆ Ĝn (Πn b∗ ) for all b∗ ∈ D .

(163)
(164)

Then note that by definition of D̃n and D̂nL , with η ∈ (0, 1), we obtain
P (Ω1n (P ))


n
o
∗
∗
∗
∗
u
≥ P inf
hΠn b − b , β̂i − ν(Πn b , Γ̂(Mn )) − ν(b , Γ̂(Mn )) ≥ −(1 − η)κ̂n
b∗ ∈D
!
≥P

sup
(b∗ ,m)∈D×M

|hΠn b∗ − b∗ , β̂ − Γ̂(m)i| ≤ (1 − η)κ̂un

.

(165)

By Assumptions S.3, U, and Markov’s inequality we obtain
sup
(b∗ ,m)∈D×M

≤

|hΠn b∗ − b∗ , β̂ − Γ̂(m)i|

sup
(b∗ ,m)∈D×M

(166)

1
√ hΠn b∗ − b∗ , GP,β − GP,Γ (m)i + Op
n



δnc + δnb
√
n




= Op

δnc + δnb
√
n



uniformly in P ∈ P. Since δnc ↓ 0 by Assumption S.3, δnb ↓ 0 by Assumption U, and κ̂un
√
satisfies Assumption S.8 with nκun ↑ ∞, we conclude from (165) and (166) that
lim inf inf P (Ω1n (P )) = 1.

(167)

n→∞ P ∈P

Similarly, the definitions of ĜnL (b∗ ) and Ĝn (Πn b∗ ), η ∈ (0, 1), and Vn ⊆ λ(M − M) yield

P (Ω2n (P )) ≥ P
≥P

∗

∗

sup |hΠn b − b , Γ̂(v)i| ≤ (1 −

η)κ̂gn

for all v ∈ Vn
!
(1 − η) g
∗
∗
sup
|hΠn b − b , Γ̂(m)i| ≤
κ̂n .
2λ
(b∗ ,m)∈D×M

b∗ ∈D

77



(168)

After arguments analogous to those in (166) (evaluated with β̂ = 0), (168) implies
lim inf inf P (Ω2n (P )) = 1.
n→∞ P ∈P

(169)

Since Ωn (P ) ≡ Ω1n (P ) ∩ Ω2n (P ), results (167) and (169) establish that Ωn (P ) occurs
with probability tending to one, uniformly over P ∈ P.
To conclude, observe that when Ωn (P ) occurs, we have
sup

sup

inf

L (g,m̃)∈Ĝ L (b∗ )×M̂ m∈M̂n
b∗ ∈D̂n
n
n

≤ sup

sup

n
o
hΠn b∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0
inf

b∗ ∈D̃n (g,m̃)∈Ĝn (b∗ )×M̂n m∈M̂n

n
o
hb∗ , Ĝβ − ĜΓ (m)i s.t. hg, m − m̃i ≥ 0 .

(170)

The claim now follows from the definition of Cnbs by combining (159), (162), (169), and
(170).

F

Q.E.D.

Bernstein Polynomials

The kth Bernstein basis polynomial of degree K is defined as
bK
k

: [0, 1] 7→ R :

bK
k (u)

≡

K
k

!
uk (1 − u)K−k

for k = 0, 1, . . . , K. A degree K Bernstein polynomial B is a linear combination of
these K + 1 basis polynomials:
B(u) : [0, 1] 7→ R : B(u) ≡

K
X

θk bK
k (u),

k=0

for some constants θ0 , θ1 , . . . , θK . As is well-known, any continuous function on [0, 1]
can be uniformly well approximated by a Bernstein polynomial of sufficiently high
order.
The shape of B can be constrained by imposing linear restrictions on θ0 , θ1 , . . . , θK .
This computationally appealing property of the Bernstein polynomials has been noted
elsewhere by Chak, Madras, and Smith (2005), Chang, Chien, Hsiung, Wen, and Wu
(2007) and McKay Curtis and Ghosh (2011), among others. The following constraints
are especially useful in the current application. Derivations of these properties can be
found in Chang et al. (2007) and McKay Curtis and Ghosh (2011).
Shape Constraints

78

S.1 Bounded below by 0: θk ≥ 0 for all k.
S.2 Bounded above by 1: θk ≤ 1 for all k.
S.3 Monotonically increasing: θ0 ≤ θ1 ≤ · · · ≤ θK .
S.4 Concave: θk − 2θk+1 + θk+2 < 0 for k = 0, . . . , K − 2.
Each Bernstein basis polynomial is itself an ordinary degree K polynomial. The
coefficients on this ordinary polynomial representation (i.e. the power basis representation) can be computed by applying the binomial theorem:
bK
k (u) =

K
X

(−1)i−k

K

i=k

i

!

i
k

!
ui .

(171)

Representation (171) is useful for computing the terms Γ?d (bdk ) and Γds (bdk ) that appear
in the finite-dimensional program (25). To see this note for example that with d = 1,
Z
Γ1s (b1k ) ≡ E

1

"

Z
b1k (u, Z)ω1s (u, Z) du = E s(1, Z)

0

#

p(Z)

b1k (u, Z) du

0

If b1k (u, Z) = b1k (u) is a Bernstein basis polynomial, then

R p(Z)
0

b1k (u) du can be com-

puted analytically through elementary calculus using (171). The result of this integral
is a known function of p(Z). The coefficient Γ1s (b1k ) is then simply the population
average of the product of this known function with s(0, Z), which is also known or
identified. Thus, no numerical integration is needed to compute or estimate the γdks
terms. This conclusion depends on the form of the weights, and may not hold for all
? , although it holds for all of the parameters listed in Table 1. When
target weights ωdk

it does not, one dimensional numerical integration can be used instead.

G

Implementation and Computation

In this appendix, we discuss computation for the sample analog bounds, the test statistic, the bootstrap statistic, and our data-driven choices of tuning parameters for the
bootstrap statistic.

G.1

Estimating Bounds

Consider the finite dimensional problem (25). We assume throughout Appendix G that
Θ is polyhedral, so that it can be represented as
Θ ≡ {θ ∈ Rdθ : Rθ ≤ q}

79

(172)

for a known vector q ∈ Rdq and a known dq × (K0 + K1 ) dimensional matrix R, where
θ ≡ (θ0 , θ1 ), and dθ ≡ K0 + K1 . We also assume throughout Appendix G that Θ ⊂ Rdθ
is a bounded set.
Let Γ̂?d (bdk ) and Γ̂ds (bdk ) denote estimators of Γ?d (bdk ) and Γds (bdk ), respectively.
For the target parameter, these can be constructed as, e.g.
n

Γ̂?d (bdk )

1X
≡
n

1

Z

i=1

bdk (u, Xi )ω̂d? (u, Zi ) dµ? (u),

(173)

0

where ω̂d? is an estimator of the known or identified weighting function, ω̂d? . Depending
on the choices of basis and target parameter, the integral can often be evaluated analytically. An estimator analogous to (173) can also be constructed for each Γds (bdk ).
These require an estimator ω̂ds , which in turn requires an estimator for the propensity
score, p(z), and possibly the functions s(d, z) that define the IV–like estimand. Letting
ŝ(d, z) be the latter estimator, we then define
n

β̂s ≡

1X
ŝ(Di , Zi )Yi
n
i=1

as an estimator of βs .
?

Given these estimators, the bound β fd can be estimated by solving the linear program
K0
K1
X
X
?
ˆ
?
β fd ≡ max
θ0k Γ̂0 (b0k ) +
θ1k Γ̂?1 (b1k )
θ≡(θ0 ,θ1 )

s.t.

k=1
K0
X

k=1
K1
X

θ0k Γ̂0s (b0k ) +

k=1

θ1k Γ̂1s (b1k ) = β̂s for all s ∈ S

k=1

and Rθ ≤ q.

(174)

Solving the analogous minimization problem yields an estimator of the lower bound,
?

β̂ fd . Both of these problems are linear programs with dθ ≡ K0 + K1 variables and
|S| + dq constraints.
It is possible that no solution to (174) exists. This could be an indication that
no solution to the population problem (25) exists either, which would imply that the
model is misspecified. However, it could also be that (25) is feasible, but that (174)
is infeasible due to statistical error in the estimation of the Γds (bdk ) and βs terms.
Our results in Section 5 provide a formal statistical test of the null hypothesis that
the model is not misspecified. Those results also provide a procedure for building a

80

confidence region for β ? . It is possible for this confidence region to be nonempty even
when (174) is infeasible.

G.2

Reformulation of the Test Statistic

We continue to assume that m has been parameterized by some finite dimensional
θ ∈ Θ, where Θ is polyhedral and characterized by the linear constraints Rθ ≤ q, as in
(172). We also assume that β is a finite dimensional parameter so that B = Rdβ .
The test statistic, Tn , is defined by the optimization problem (35). The choice of
norm on B affects the nature of the objective in (35), and will affect both the objective
and constraints for the bootstrap statistic problem discussed in the next section. For
computational reasons, it turns out to be convenient to choose a norm k · kB for which
the unit ball is polyhedral. This suggests taking k · kB to be either the 1–norm or the
max–norm on Rdβ . For concreteness, we will take k · kB to be the 1–norm, so that
Pdβ
kβ̂kB = kβ̂k1 ≡ l=1
|β̂l |.
Given these choices, we can rewrite (35) as
√
Tn = min nkβ̂ − Γ̂θk1
θ

s.t. Rθ ≤ q.

(175)

This problem can be reformulated as a linear program by introducing non-negative
slack variables, w+ , w− ∈ Rdβ . Specifically, it can be shown that (175) is equivalent to
Tn = minθ,w+ ,w−


√ Pdβ +
−
n
w
+
w
l=1 l
l

s.t. Rθ ≤ q
w+ − w− = β̂ − Γ̂θ

(176)

w− , w+ ≥ 0.
For a discussion of this reformulation see e.g. Boyd and Vandenberghe (2004, pg. 294).

G.3

Reformulation of the Bootstrap Statistic

In this section, we show that the optimization problem that defines the bootstrap
statistic, i.e. (70), can be reformulated as a bilinear program. Throughout this section,
u
we assume that the researcher has selected values of the tuning parameters κ̂m
n , κ̂n ,

and κ̂gn . In the next section, we discuss the computational aspects of our data-driven
recommendations for choosing these parameters.
Consider the inner minimization problem in (70). We rewrite this problem here in

81

terms of θ ∈ Θ̂ (replacing m ∈ M̂n ) as
bs
Tn,inner
(b∗ , g, θ̃) ≡ minθ (Ĝβ − ĜΓ θ)0 b∗

s.t. g 0 (θ − θ̃) ≥ 0
Rθ ≤ q

(177)

kβ̂ − Γ̂θk1 ≤ κ̂m
n,
where we continue to use the notation κ̂m
n despite having exchanged m’s for θ’s elsewhere. We write this inner problem as a function of (b∗ , g, θ̃) to emphasize that these
variables are fixed from the outer maximization problem in (70). Using a similar idea
as in the reformulation (176) for the test statistic, we rewrite (177) as the following
linear program:
bs
Tn,inner
(b∗ , g, θ̃) = minθ,w+ ,w−

(Ĝβ − ĜΓ θ)0 b∗

s.t. g 0 (θ − θ̃) ≥ 0
Rθ ≤ q
w+ − w− = β̂ − Γ̂θ
Pdβ +
−
m
l=1 wl + wl ≤ κ̂n

(178)

w− , w+ ≥ 0.
As long as Θ̂n ≡ {θ ∈ Θ : kβ̂ − Γ̂θk1 ≤ κ̂m
n } is nonempty, a feasible solution to
(178) can always be achieved by taking θ = θ̃ since θ̃ ∈ Θ̂n from the outer optimization
constraint in (70). We assume that κ̂m
n has been chosen to be sufficiently large to ensure
√
this is the case, which simply requires κ̂m
n ≥ Tn / n. Together with our assumption
that Θ is bounded, we can conclude that strong duality holds; see, e.g. Corollary 5.3.7
in Borwein and Lewis (2010). The dual of (178) can be shown to be
0
0
bs
Tn,inner
(b∗ , g, θ̃) = maxσ Ĝ0β b∗ + q 0 σ1 + κ̂m
n σ2 − g θ̃σ3 + β̂ σ4

s.t. σ1 , σ2 , σ3 ≤ 0
R0 σ1 + Γ̂0 σ4 − gσ3 = −Ĝ0Γ b∗
σ2 ≤ σ4,l ≤ −σ2

(179)

for l = 1, . . . , dβ ,

where σ = (σ10 , σ2 , σ3 , σ40 )0 with σ1 ∈ Rdq , σ2 ∈ R, σ3 ∈ R, and σ4 ∈ Rdβ . Given (179),

82

we can now write (70) as a single maximization problem:
0
0
Tnbs = maxb∗ ,g,θ̃,σ Ĝ0β b∗ + q 0 σ1 + κ̂m
n σ2 − g θ̃σ3 + β̂ σ4

s.t. σ1 , σ2 , σ3 ≤ 0
R0 σ1 + Γ̂0 σ4 − gσ3 = −Ĝ0Γ b∗
σ2 ≤ σ4,l ≤ −σ2
b∗ ∈ D̂n

(180)

for l = 1, . . . , dβ .

g ∈ Ĝn (b∗ )

Rθ̃ ≤ q
kβ̂ − Γ̂θ̃k1 ≤ κ̂m
n.
Our next task is to reformulate (180) into a bilinear maximization problem. This
involves several steps.
First, we reformulate the constraint b∗ ∈ D̂n . To this end, note that B∗ = Rdβ but
equipped with the max–norm k · k∞ , defined as kb∗ k∞ ≡ maxl |b∗l |. Hence, by definition
of D̂n (see (58)) the constraint b∗ ∈ D̂n is equivalent to
kb∗ k∞ ≤ 1

and β̂ 0 b∗ − ν(b∗ , Γ̂(Θ)) ≥ −κ̂un .

(181)

The first constraint in (181) can be rewritten as the set of linear constraints −1 ≤ b∗l ≤ 1
for l = 1, . . . , dβ . To reformulate the second constraint in (181), we rephrase the
definition of a support function (see (38)) as a minimization problem by applying
strong duality; see, e.g., Corollary 5.3.7 in Borwein and Lewis (2010). That is,
ν(b∗ , Γ̂(Θ)) =

maxθ ((b∗ )0 Γ̂)θ
s.t.

!

Rθ ≤ q

=

minσ5 ≥0

q 0 σ5

s.t.

R0 σ5 = Γ̂0 b∗

!
.

Using the minimization form of the support function, we conclude that the second
constraint in (181) is equivalent to the existence of a σ5 ∈ Rdq such that
σ5 ≥ 0

and R0 σ5 = Γ̂0 b∗

and q 0 σ5 ≤ β̂ 0 b∗ + κ̂un .

(182)

Notice that the constraints in (182) are linear in the variables of optimization, which
now include the dual variables, σ5 .
Second, we reformulate the constraint that g ∈ Gn (b∗ ). To implement this conθ
straint, we take Vn = {±ej }dj=1
, where ej is the jth unit basis vector in Rdθ . Then,

from (69), g ∈ Gn (b∗ ) is equivalent to kg − (b∗ )0 Γ̂k∞ ≤ κ̂gn . As noted above, this max
norm constraint can also be written as a set of linear inequalities.

83

Third, we observe that the transpose of the equality constraint in (180) implies that
σ3 g 0 = σ10 R + σ40 Γ̂ + (b∗ )0 ĜΓ .
We substitute this expression into the term g 0 θ̃σ3 = σ3 g 0 θ̃ in the objective of (180).
This allows us to rewrite the objective as
0
0
∗ 0
0
Ĝ0β b∗ + q 0 σ1 + κ̂m
n σ2 − σ1 Rθ̃ − σ4 Γ̂θ̃ − (b ) ĜΓ θ̃ + β̂ σ4 .

(183)

The benefit of this substitution is that, whereas the term σ3 γ 0 θ̃ in the objective of (180)
is the product of three variables of optimization, every term in (183) is the product of
at most two variables of optimization.
Fourth, we recall the reformulation that we used on the inner problem to move from
(177) to (178). Here, it will be applied to the constraint kβ̂ − Γ̂θ̃k1 ≤ κ̂m
n.
Incorporating these four observations into (180), we reformulate the program as
0
0
∗ 0
0
Tnbs = max Ĝ0β b∗ + q 0 σ1 + κ̂m
n σ2 − σ1 Rθ̃ − σ4 Γ̂θ̃ − (b ) ĜΓ θ̃ + β̂ σ4

as a function of b∗ , g, θ̃, σ1 , σ2 , σ3 , σ4 , σ5 , w̃+ , w̃−
σ5 , w̃+ , w̃− ≥ 0

s.t. σ1 , σ2 , σ3 ≤ 0,

R0 σ1 + Γ̂0 σ4 − gσ3 = −Ĝ0Γ b∗
σ2 ≤ σ4,l ≤ −σ2
−1 ≤

b∗l

≤1

for l = 1, . . . , dβ .

for l = 1, . . . , dβ

R0 σ5 = Γ̂0 b∗

(184)

q 0 σ5 ≤ β̂ 0 b∗ + κ̂un
−κ̂gn ≤ e0j (g − (b∗ )0 Γ̂) ≤ κ̂gn

for j = 1, . . . , dθ

Rθ̃ ≤ q
w̃+ − w̃− = β̂ − Γ̂θ̃
Pdβ +
−
m
l=1 w̃l + w̃l ≤ κ̂n .
This program is almost linear in both its objective and constraints. However, it does
contain the following terms that are bilinear in the sense of being the product of two
different variables of optimization: σ1 Rθ̃, σ40 Γ̂θ̃, (b∗ )0 ĜΓ θ̃, and gσ3 . As a result, (184)
is a bilinear programming problem. Despite being non-convex, bilinear programs like
these can be reliably solved to global optimality, see e.g. Tawarmalani and Sahinidis
(2005) and the references cited therein.

84

G.4

Reformulation of the Tuning Parameter Selection Problems

√
m
u
We use (84) to choose κ̂un , as well as κ̂m
n , which we take as κ̂n = κ̂n + Tn / n. To
do this, we compute supm∈Mn kĜβ − ĜΓ (m)kB . In terms of the finite dimensional
framework used throughout this section, this problem can be written as
max kĜβ − Ĝβ θk1
θ

s.t.

Rθ ≤ q.

(185)

This problem looks superficially similar to the reformulated test statistic problem,
(175), with the important difference that it is a maximization problem, rather than
a minimization problem. Since k · k1 is a convex function, this means that (185) is a
non-convex optimization problem.
However, (185) can be reformulated as a mixed integer linear program (MILP) by
applying a fairly standard argument. The argument is based on the observation that
the nonlinearity of the objective comes from the absolute value function, i.e.:
kĜβ − Ĝβ θk1 ≡

dβ
X



e0l Ĝβ − Ĝβ θ ,

l=1

where el are unit vectors in Rdβ . As a result, the objective can be linearized by
introducing dβ binary variables that indicate whether each absolute value is obtained
for a positive or negative number, together with dβ slack variables to stand in for the
magnitude of the absolute value itself. Specifically, (185) is equivalent to
maxθ,ζ,σ,w

Pdβ

l=1 σl

s.t. Rθ ≤ q
ζl ∈ {0, 1}

for l = 1, . . . , dβ

(186)

w = Ĝβ − Ĝβ θ
wl ≤ σl ≤ wl + (1 − ζl )BigMl
−wl ≤ σl ≤ −wl + ζl BigMl

for l = 1, . . . , dβ
for l = 1, . . . , dβ

In (186), ζ are binary variables, w is a definitional variable that helps with notation,
and BigMl are large numbers, referred to as “big M” parameters in the operations
research literature (e.g. pp. 136-137 of Schrijver (1998)). The big M parameters are
chosen by the researcher in such a way as to ensure that constraints in which they
enter are never binding when BigMl is multiplied by 1. It is important to note that
these parameters are not tuning parameters in the usual statistical sense. In particular,
while the choice of the big M parameters can impact the speed at which (186) is solved,
these parameters can (and should) always be chosen so as not to impact the optimal

85

value of (186).
To see how (186) reformulates (185), first note that we have set wl = e0l (Ĝβ − Ĝβ θ)
in (186) as a (notational) constraint. Next, observe that if wl ≥ 0, then wl ≤ σl ≤ −wl
is a contradiction, so the only feasible solution in this case is to take ζl = 1. However,
with ζl = 1, the constraints enforce σl = wl . Similarly, if wl ≤ 0, then the binary
constraints enforce any feasible solution to have ζl = 0 and hence σl = −wl . In both
cases, σl = |e0l (Ĝβ − Ĝβ θ)|, so that the objective in (186) is always identical to that in
(185).
Using (86) to select κ̂gn involves solving a problem similar to (185), which can also
be reformulated as a MILP. In finite dimensions, and with the choice of Vn discussed
in the previous section, this problem can be written as
max
k(b∗ )0 ĜΓ k∞
∗
b

s.t. kb∗ k∞ ≤ 1

and ν(b∗ , Γ̂(Θ)) ≤ β̂ 0 b∗ + κ̂un .

(187)

We have already shown how to reformulate the constraints in this problem as linear
constraints; recall (182). However, as with (185), the objective in (187) is a nonlinear,
convex function, so maximizing it subject to linear constraints is a non-convex problem.
We reformulate (187) as the following MILP:
max σ1
as a function of b∗ , σ1 , σ2 , w, π, ζ1 , ζ2
s.t. −1 ≤ b∗l ≤ 1

for l = 1, . . . , dβ

σ2 ≥ 0
q 0 σ2 ≤ β̂ 0 b∗ + κ̂un
R0 σ2 = Γ̂0 b∗
ζ1,j , ζ2,j ∈ {0, 1}

(188)

for j = 1, . . . , dθ

w = (b∗ )0 ĜΓ
wj ≤ πj ≤ wj + (1 − ζ1,j )BigM1,j
−wj ≤ πj ≤ −wj + ζ1,j BigM1,j
πj ≤ σ1 ≤ πj + (1 − ζ2,j )BigM2,j
Pdθ
j=1 ζ2,j = 1

for j = 1, . . . , dθ
for j = 1, . . . , dθ
for j = 1, . . . , dθ

The justification of this reformulation is similar to the one discussed for (186). The
constraints involving the ζ1 binary variables ensure that πj is always the absolute value
of wj , which is constrained (defined) as the jth element of (b∗ )0 ĜΓ . The additional
constraints involving the ζ2 binary variables then ensure that σ1 is always the maximum
Pθ
of πj , since dj=1
ζ2,j = 1 can be satisfied if and only if a single ζ2,j is equal to 1.

86

G.5

Some Notes on Computation

We have shown that the main optimization problems in our methodology can all be
reformulated as problems with well-understood properties for which there exist globally
optimal algorithms. Admittedly, this has taken a substantial amount of work. However,
once the theoretical reformulation work has been done once, it does not need to be
performed again by a practitioner. The reformulated problems can be implemented
directly and solved using appropriate software. We are in the process of developing a
software package that processes the necessary optimization problems in the background
without requiring additional input from the user.
We summarize the computational steps involved in statistical inference. First, construct consistent estimators of identified population quantities, as discussed in Section
G.1. The exact definition of the terms involved here will depend on the null hypothesis
of interest. Second, compute the test statistic, Tn , by solving (176). Third, solve the
MILP (186) one time each for a large number of bootstrap draws. Given a choice of
quantile αn , this provides a data-driven choice of κ̂un through (84), as well as a datau
driven choice of κ̂m
n = κ̂n + Tn . Fourth, solve the MILP (188) one time each for a large

number of bootstrap draws. This yields a data-driven choice of κ̂gn . Fifth, with all tuning parameters selected, solve the bilinear maximization problem (184) one time each
for a large number of bootstrap draws. This provides the critical value ĉ1−α defined in
(79). The null hypothesis is then rejected at level α if Tn > ĉ1−α .
In practice, we have found that the part of this procedure that takes the longest is
by far the bilinear program (184). The MILPs used to select the tuning parameters are
relatively small. Even though these programs must be solved a large number of times,
we have found that they can be solved extremely quickly using modern algorithms like
Gurobi (Gurobi Optimization, 2015), which is the software we use for this step in our
empirical application.

References
Abadie, A., J. Angrist, and G. Imbens (2002): “Instrumental Variables Estimates of
the Effect of Subsidized Training on the Quantiles of Trainee Earnings,” Econometrica, 70,
91–117. 18
Aliprantis, C. D. and K. C. Border (2006): Infinite Dimensional Analysis – A Hitchhiker’s Guide, Berlin: Springer-Verlag. 35, 68, 69, 71
Andrews, D. W. and G. Soares (2010): “Inference for parameters defined by moment
inequalities using generalized moment selection,” Econometrica, 78, 119–157. 38
Angrist, J. D. and I. Fernandez-Val (2013): “ExtrapoLATE-ing: External Validity

87

and,” in Advances in Economics and Econometrics: Volume 3, Econometrics: Tenth World
Congress, Cambridge University Press, vol. 51, 401–. 6
Angrist, J. D., K. Graddy, and G. W. Imbens (2000): “The Interpretation of Instrumental Variables Estimators in Simultaneous Equations Models with an Application to the
Demand for Fish,” The Review of Economic Studies, 67, 499–527. 2
Angrist, J. D. and G. W. Imbens (1995): “Two-Stage Least Squares Estimation of Average Causal Effects in Models with Variable Treatment Intensity,” Journal of the American
Statistical Association, 90, 431–442. 2
Ashraf, N., J. Berry, and J. Shapiro (2010): “Can Higher Prices Stimulate Product Use?
Evidence from a Field Experiment in Zambia,” American Economic Review, 100, 2383–2413.
50, 51
Balke, A. and J. Pearl (1997): “Bounds on Treatment Effects From Studies With Imperfect
Compliance,” Journal of the American Statistical Association, 92, 1171–1176. 5, 6, 22
Beresteanu, A. and F. Molinari (2008): “Asymptotic properties for a class of partially
identified models,” Econometrica, 76, 763–814. 7
Bhattacharya, J., A. M. Shaikh, and E. Vytlacil (2012): “Treatment effect bounds:
An application to SwanGanz catheterization,” Journal of Econometrics, 168, 223–243. 5
Bierens, H. J. (1990): “A consistent conditional moment test of functional form,” Econometrica: Journal of the Econometric Society, 1443–1458. 15
Bontemps, C., T. Magnac, and E. Maurin (2012): “Set identified linear models,” Econometrica, 80, 1129–1155. 7
Borwein, J. and A. S. Lewis (2010): Convex analysis and nonlinear optimization: theory
and examples, Springer Science & Business Media. 82, 83
Boyd, S. and L. Vandenberghe (2004): Convex optimization, Cambridge university press.
81
Brinch, C. N., M. Mogstad, and M. Wiswall (2015): “Beyond LATE with a Discrete
Instrument,” Journal of Political Economy, forthcoming. 5, 6, 15, 16, 54
Bugni, F., I. Canay, and X. Shi (2015): “Inference for functions of partially identified
parameters in moment inequality models,” Tech. rep., cemmap working paper, Centre for
Microdata Methods and Practice. 6
Byrd, R. H., J. Nocedal, and R. A. Waltz (2006): “KNITRO: An integrated package for
nonlinear optimization,” in Large-scale nonlinear optimization, Springer, 35–59. 43
Canay, I. and A. Shaikh (2016): “Practical and theoretical advances in inference for partially
identified models,” Tech. rep., cemmap working paper, Centre for Microdata Methods and
Practice. 36
Carneiro, P., J. J. Heckman, and E. Vytlacil (2010): “Evaluating Marginal Policy
Changes and the Average Effect of Treatment for Individuals at the Margin,” Econometrica,
78, 377–394. 5, 16, 20

88

Carneiro, P., J. J. Heckman, and E. J. Vytlacil (2011): “Estimating Marginal Returns
to Education,” American Economic Review, 101, 2754–81. 5, 11, 16, 20
Chak, P. M., N. Madras, and B. Smith (2005): “Semi-nonparametric estimation with
Bernstein polynomials,” Economics Letters, 89, 153–156. 78
Chamberlain, G. (2011): “Bayesian aspects of treatment choice,” The Oxford Handbook of
Bayesian Econometrics, 11–39. 6
Chang, I.-S., L.-C. Chien, C. A. Hsiung, C.-C. Wen, and Y.-J. Wu (2007): “Shape
restricted regression with random Bernstein polynomials,” in Lecture Notes–Monograph Series, ed. by R. Liu, W. Strawderman, and C.-H. Zhang, Beachwood, Ohio, USA: Institute
of Mathematical Statistics, vol. Volume 54, 187–202. 78
Chen, X. (2007): “Chapter 76 Large Sample Sieve Estimation of Semi-Nonparametric Models,” in Handbook of Econometrics, ed. by J. J. Heckman and E. E. Leamer, Elsevier, vol.
Volume 6, Part 2, 5549–5632. 38
Chernozhukov, V., S. Lee, and A. M. Rosen (2013): “Intersection bounds: estimation
and inference,” Econometrica, 81, 667–737. 47
Chernozhukov, V., W. K. Newey, and A. Santos (2015): “Constrained conditional
moment restriction models,” arXiv preprint arXiv:1509.06311. 6, 36, 66
Chesher, A. (2003): “Identification in Nonseparable Models,” Econometrica, 71, 1405–1441.
2
Cohen, J. and P. Dupas (2010): “Free Distribution or Cost-Sharing? Evidence from a
Randomized Malaria Prevention Experiment,” The Quarterly Journal of Economics, 125,
1–45. 50, 51
Dupas, P., H. V. K. M. and A. P. Zwane (2016): “Targeting health subsidies through a
non-price mechanism: A randomized controlled trial in Kenya,” Science, 353, 889–895. 50
Dupas, P. (2014): “ShortRun Subsidies and LongRun Adoption of New Health Products:
Evidence From a Field Experiment,” Econometrica, 82, 197–228. 5, 50, 52
Fang, Z. and A. Santos (2014): “Inference on directionally differentiable functions,” arXiv
preprint arXiv:1404.3763. 39
Florens, J. P., J. J. Heckman, C. Meghir, and E. Vytlacil (2008): “Identification
of Treatment Effects Using Control Functions in Models With Continuous, Endogenous
Treatment and Heterogeneous Effects,” Econometrica, 76, 1191–1206. 2
Gurobi Optimization, I. (2015): “Gurobi Optimizer Reference Manual,” . 25, 87
Heckman, J., J. L. Tobias, and E. Vytlacil (2003): “Simple Estimators for Treatment
Parameters in a Latent-Variable Framework,” Review of Economics and Statistics, 85, 748–
755. 6
Heckman, J. J. and R. J. Robb (1985): “Alternative methods for evaluating the impact of
interventions,” in Longitudinal Analysis of Labor Market Data, ed. by J. J. Heckman and
B. Singer, Cambridge University Press. 6

89

Heckman, J. J. and S. Urzua (2010): “Comparing IV with structural models: What simple
IV can and cannot identify,” Journal of Econometrics, 156, 27–37. 2
Heckman, J. J., S. Urzua, and E. Vytlacil (2006): “Understanding Instrumental Variables in Models with Essential Heterogeneity,” Review of Economics and Statistics, 88, 389–
432. 2
Heckman, J. J. and E. Vytlacil (2001a): “Policy-Relevant Treatment Effects,” The American Economic Review, 91, 107–111. 3, 5, 20
——— (2005): “Structural Equations, Treatment Effects, and Econometric Policy Evaluation,”
Econometrica, 73, 669–738. 2, 3, 5, 9, 11, 12, 16, 19, 21
Heckman, J. J. and E. J. Vytlacil (1999): “Local Instrumental Variables and Latent Variable Models for Identifying and Bounding Treatment Effects,” Proceedings of the National
Academy of Sciences of the United States of America, 96, 4730–4734. 2, 3, 9, 16, 19
——— (2001b): “Instrumental Variables, Selection Models, and Tight Bounds on the Average
Treatment Effect,” in Econometric Evaluations of Active Labor Market Policies in Europe,
ed. by M. Lechner and F. Pfeiffer, Heidelberg and Berlin: Physica. 3, 5
——— (2001c): “Local Instrumental Variables,” in Nonlinear Statistical Modeling: Proceedings
of the Thirteenth International Symposium in Economic Theory and Econometrics: Essays
in Honor of Takeshi Amemiya, ed. by K. M. C Hsiao and J. Powell, Cambridge University
Press. 3, 16
——— (2007a): “Chapter 70 Econometric Evaluation of Social Programs, Part I: Causal Models, Structural Models and Econometric Policy Evaluation,” in Handbook of Econometrics,
ed. by J. J. Heckman and E. E. Leamer, Elsevier, vol. Volume 6, Part 2, 4779–4874. 3
——— (2007b): “Chapter 71 Econometric Evaluation of Social Programs, Part II: Using the
Marginal Treatment Effect to Organize Alternative Econometric Estimators to Evaluate Social Programs, and to Forecast their Effects in New Environments,” in Handbook of Econometrics, ed. by J. J. Heckman and E. E. Leamer, Elsevier, vol. Volume 6, Part 2, 4875–5143.
2, 3
Huber, M. and G. Mellace (2014): “Testing Instrument Validity for LATE Identification
Based on Inequality Moment Constraints,” Review of Economics and Statistics, 97, 398–411.
6
Imbens, G. W. (2010): “Better LATE Than Nothing: Some Comments on Deaton (2009) and
Heckman and Urzua (2009),” Journal of Economic Literature, 48, 399–423. 21
Imbens, G. W. and J. D. Angrist (1994): “Identification and Estimation of Local Average
Treatment Effects,” Econometrica, 62, 467–475. 2, 3, 8, 21, 24, 29
Imbens, G. W. and C. F. Manski (2004): “Confidence intervals for partially identified
parameters,” Econometrica, 72, 1845–1857. 4, 30
Imbens, G. W. and W. K. Newey (2009): “Identification and Estimation of Triangular
Simultaneous Equations Models Without Additivity,” Econometrica, 77, 1481–1512. 2
Imbens, G. W. and D. B. Rubin (1997): “Estimating Outcome Distributions for Compliers
in Instrumental Variables Models,” The Review of Economic Studies, 64, 555–574. 6, 22

90

Kaido, H., F. Molinari, and J. Stoye (2016): “Confidence intervals for projections of
partially identified parameters,” arXiv preprint arXiv:1601.00934. 7
Kaido, H. and A. Santos (2014): “Asymptotically efficient estimation of models defined by
convex moment inequalities,” Econometrica, 82, 387–413. 7
Kirkeboen, L., E. Leuven, and M. Mogstad (2016): “Field of Study, Earnings and SelfSelection,” The Quarterly Journal of Economics, 131, 1057–1111. 2
Kitagawa, T. (2009): “Identification Region of the Potential Outcome Distributions under
Instrument Independence,” Cemmap working paper. 5
——— (2015): “A Test for Instrument Validity,” Econometrica, 83, 2043–2063. 6, 22
Koltchinskii, V. I. (1994): “Komlos-Major-Tusnady approximation for the general empirical
process and Haar expansions of classes of functions,” Journal of Theoretical Probability, 7,
73–118. 36
Kowalski, A. (2016): “Doing More When You’re Running LATE: Applying Marginal Treatment Effect Methods to Examine Treatment Effect Heterogeneity in Experiments,” NBER
Working paper 22363. 16
Lee, S. and B. Salanié (2016): “Identifying Effects of Multivalued Treatments,” Working
paper. 2
Luenberger, D. G. (1969): Optimization by vector space methods, John Wiley & Sons. 33,
68, 74
Machado, C., A. M. Shaikh, and E. J. Vytlacil (2013): “Instrumental Variables and
the Sign of the Average Treatment Effect,” Working paper. 6
Maestas, N., K. J. Mullen, and A. Strand (2013): “Does Disability Insurance Receipt
Discourage Work? Using Examiner Assignment to Estimate Causal Effects of SSDI Receipt,”
The American Economic Review, 103, 1797–1829. 11
Manski, C. (1994): “The selection problem,” in Advances in Econometrics, Sixth World
Congress, vol. 1, 143–70. 5
Manski, C. F. (1989): “Anatomy of the Selection Problem,” The Journal of Human Resources,
24, 343–360. 5
——— (1990): “Nonparametric Bounds on Treatment Effects,” The American Economic Review, 80, 319–323. 5
——— (1997): “Monotone Treatment Response,” Econometrica, 65, 1311–1334. 5, 16
——— (2003): Partial identification of probability distributions, Springer. 5
Manski, C. F. and J. V. Pepper (2000): “Monotone Instrumental Variables: With an
Application to the Returns to Schooling,” Econometrica, 68, 997–1010. 5, 16
——— (2009): “More on monotone instrumental variables,” Econometrics Journal, 12, S200–
S216. 5

91

Masten, M. A. (2015): “Random Coefficients on Endogenous Variables in Simultaneous
Equations Models,” cemmap working paper 25/15. 2
Masten, M. A. and A. Torgovitsky (2016): “Identification of Instrumental Variable Correlated Random Coefficients Models,” The Review of Economics and Statistics, forthcoming.
2
McCormick, G. P. (1976): “Computability of global solutions to factorable nonconvex programs: Part IConvex underestimating problems,” Mathematical programming, 10, 147–175.
43
McKay Curtis, S. and S. K. Ghosh (2011): “A variable selection approach to monotonic
regression with Bernstein polynomials,” Journal of Applied Statistics, 38, 961–976. 78
Mourifié, I. (2015): “Sharp bounds on treatment effects in a binary triangular system,”
Journal of Econometrics, 187, 74–81. 5
Mourifié, I. and Y. Wan (2016): “Testing Local Average Treatment Effect Assumptions,”
The Review of Economics and Statistics, 99, 305–313. 6
Rio, E. (1994): “Local invariance principles and their application to density estimation,”
Probability Theory and Related Fields, 98, 21–45. 36
Romano, J. P. and A. M. Shaikh (2008): “Inference for identifiable parameters in partially
identified econometric models,” Journal of Statistical Planning and Inference, 138, 2786–
2807. 6
——— (2012): “On the uniform asymptotic validity of subsampling and the bootstrap,” The
Annals of Statistics, 40, 2798–2822. 47
Romano, J. P., A. M. Shaikh, and M. Wolf (2014): “A Practical Two-Step Method for
Testing Moment Inequalities,” Econometrica, 82, 1979–2002. 48
Schrijver, A. (1998): Theory of linear and integer programming, John Wiley & Sons. 85
Shaikh, A. M. and E. J. Vytlacil (2011): “Partial Identification in Triangular Systems of
Equations With Binary Dependent Variables,” Econometrica, 79, 949–955. 5
Sion, M. (1958): “On general minimax theorems,” Pacific J. Math, 8, 171–176. 70
Stinchcombe, M. B. and H. White (1998): “Consistent specification testing with nuisance
parameters present only under the alternative,” Econometric theory, 14, 295–325. 15, 34
Tawarmalani, M. and N. V. Sahinidis (2005): “A polyhedral branch-and-cut approach to
global optimization,” Mathematical Programming, 103, 225–249. 43, 84
Torgovitsky, A. (2015): “Identification of Nonseparable Models Using Instruments With
Small Support,” Econometrica, 83, 1185–1197. 2
Vytlacil, E. (2002): “Independence, Monotonicity, and Latent Index Models: An Equivalence Result,” Econometrica, 70, 331–341. 3, 8

92

