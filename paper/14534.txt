NBER WORKING PAPER SERIES

INFLATION DETERMINATION WITH TAYLOR RULES:
IS NEW KEYNESIAN ANALYSIS CRITICALLY FLAWED?
Bennett T. McCallum
Working Paper 14534
http://www.nber.org/papers/w14534

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2008

I am indebted to Miguel Casares, Marvin Goodfriend, and Edward Nelson for many helpful discussions
and comments on an earlier draft. The views expressed herein are those of the author(s) and do not
necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2008 by Bennett T. McCallum. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

Inflation Determination with Taylor Rules: Is New Keynesian Analysis Critically Flawed?
Bennett T. McCallum
NBER Working Paper No. 14534
December 2008
JEL No. E4,E5,E52
ABSTRACT
Cochrane (2007) has strongly questioned the basic economic logic of current mainstream monetary
policy analysis, arguing that the standard notion --that "determinacy" of a rational expectations (RE)
equilibrium suffices to imply that stable inflation behavior will be generated -- is incorrect. This is
because New Keynesian (NK) models are typically consistent with the existence of RE paths with
explosive inflation rates (in addition to one or more stable paths) that normally do not imply explosions
in real variables relevant for transversality conditions. Consequently, the usual logic does not imply
the absence of explosive inflation. That result does not, however, justify negative conclusions about
NK analysis. For there is a different criterion that is logically satisfactory for the purpose at hand.
This is the requirement that, to be plausible, a RE solution must satisfy the property of least-squares
learnability. Adoption of this criterion, which should be attractive to analysts concerned with actual
monetary policy, serves to justify in principle the bulk of current mainstream analysis.

Bennett T. McCallum
Tepper School of Business, Posner 256
Carnegie Mellon University
Pittsburgh, PA 15213
and NBER
bm05@andrew.cmu.edu

1. Introduction
Quite recently, John Cochrane (2007) has strongly questioned the basic economic
logic of current mainstream monetary policy analysis as widely practiced and described
by Clarida, Gali, and Gertler (2000), King (2000), Svensson and Woodford (2005),
Taylor (1999), Woodford (2003a), and many other prominent writers.1 A central
ingredient of this analysis is the assumption that monetary policy is conducted by means
of a central-bank policy rule for period-by-period adjustment of a short-term nominal
interest rate, with the rule calling for adjustments of this policy rate by more than one-forone in response to incipient movements in inflation—thereby satisfying a condition that
is widely referred to as the Taylor Principle.2 Cochrane’s contention is that the standard
notion—that “determinacy” of a rational expectations (RE) equilibrium serves to
guarantee that stable inflation behavior around target will be generated—is incorrect. His
basic reasoning is expressed in the following quote:
“I argue that the Taylor principle, in the context of new-Keynesian models, does
not, in fact, determine inflation or the price level. Nothing in economics rules out
explosive or “non-local” nominal paths. Transversality conditions can rule out
real explosions, but not nominal ones” (Cochrane, 2007, p. 2).
Consideration of Cochrane’s argument indicates that there is much merit in this point.
The concept of determinacy relied upon in the standard analysis is uniqueness of a
dynamically stable (i.e., non-explosive) RE solution in the model under study (which is

1

Other notable items in the literature include Taylor (1993), Clarida, Gali, and Gertler (1999), Goodfriend
and King (1997), King and Wolman (1996), and Rotemberg and Woodford (1997). Goodfriend (2007)
presents a recent overview that links formal analysis and actual central bank practive.
2
The principle is often extended to cases in which policy responds also to incipient movements in the the
output gap. See, e.g., Woodford (2003a, pp. 90-94, 252-261), Taylor (1999).

1

of course intended to depict reality). But the equations of New Keynesian (NK)3 models
are typically consistent with the existence of RE paths with explosive inflation rates, in
addition to one or more stable paths, under the usual specifications. These are “nominal
explosions” that bring about paths along which real money balances tend to decrease in
magnitude, rather than growing without limit. More generally, explosive paths for
inflation rates—or nominal interest rates—do not normally imply explosions in real
variables relevant for transversality conditions, which are crucial for individual agent
optimization. Consequently, the usual logic, in the usual models, does not imply the
absence of explosive inflation.
It is my conclusion that this position of Cochrane’s is in principle correct. That
position as just stated does not, however, justify Cochrane’s negative conclusions about
NK analysis.4 For there is a different criterion—in many (but not all) cases implied by
determinacy and not generally implying determinacy—that is logically satisfactory for
the purpose at hand. This is the requirement that, to be plausible, a RE solution should
satisfy the property of learnability, of the type made prominent in the work of Evans and
Honkapohja (1999, 2001).5 Adoption of this criterion, which should be attractive to any
analyst concerned with actual monetary policy issues, serves to justify the bulk of current
mainstream analysis in principle. Indeed, as argued in McCallum (2003, 2007), it
eliminates some other problematic aspects of the NK analysis.

3

New-Keynesian (NK) models are basically the same as those referred to by Goodfriend and King (1997)
as “New Neoclassical Synthesis” (NNS) models. Some would consider the latter label to be more apt, from
a historical perspective. Nevertheless, I will follow Cochrane in useing the more standard label NK to refer
to the models of current mainstream analysis.
4
It should be said that Cochrane does not use the term “critically flawed” that appears in my title. I would
think, however, that most exponents of NK analysis would regard a model/policy-rule combination, that
does not rule out explosive inflation, to be critically flawed.
5
More precisely, the requirement is least-squares (LS) learnability, as a necessary condition for a RE
equilibrium to be plausible and therefore of potential economic relevance.

2

2. Cochrane’s Critique
Let me begin by outlining the central aspects of Cochrane’s argument in the
context of the basic NK model that he uses for his main presentation. It is common, in
the NK literature, to utilize a three-equation structure that includes an expectational IS
function,6 a Calvo-type price adjustment relation, and a Taylor-style policy rule in a
system that could be written as
(1)

yt = b0 + b1(Rt − Etπt+1) + Etyt+1 + vt

b1 < 0

(2)

πt = βEtπt+1 + κ(yt − y t )

κ>0

(3)

Rt = µ0 + (1 + µ1)πt + µ2(yt − y t ) + et

where yt represents output/consumption, y t is its “natural rate” flexible-price value, πt is
inflation, and Rt is the one-period (nominal) rate of interest.7 Here vt and et are
preference and policy shocks while y t is exogenously generated by an autocorrelated
technology process. Cochrane simplifies by assuming full price flexibility so that yt = y t
in each period, which eliminates the Calvo equation (2) and the output gap term in (3). If
we also let y t be a constant, then the IS relation (1) becomes
(4)

0 = b0 + b1(Rt − Etπt+1) + vt.

Then if the shock term is neglected and r = −b0/b1 is recognized as a constant real rate of
interest, we have the relation that Cochrane calls a “Fisher equation.” From the
perspective of monetary policy, I think it better to describe it as is done here, but there is

6

This function represents a consumption Euler equation together with the economy’s overall resource
constraint.
7
The rule is written assuming a zero target rate of inflation. If it were non-zero, then a non-zero constant
term would appear in the solution equation (7) below.

3

no substantive difference relative to Cochrane.8 Thus the system at hand reduces to (3)
and (4), identical to Cochrane’s (1) and (2) if we delete the shock vt from ours while also
setting µ0 = r in the policy rule, as a sensible central bank would do.
To solve this simple system we combine (3) and (4) to obtain
(5)

0 = b0 + b1[µ0 + (1+µ1)πt + et − Etπt+1] + vt

and conjecture that with vt = 0 and et = ρet-1 + white noise ( ρ < 1) , as in Cochrane
(2007), there will be a solution of the form
(6)

πt = φ0 + φ1et

with expectations therefore obeying Etπt+1 = φ0 + φ1ρet. Substitution in (5) then implies
that this solution is
(7)

πt = 0 −

1
et .
1+ µ1 − ρ

The latter is, of course, the “fundamentals” or “MSV” solution. With ρ < 1 , it
implies that πt is negatively related to et and that larger values of µ1 serve to reduce the
variability of πt around its target. Now suppose, however, that instead of (6) one looks
for a solution of the form
(8)

πt = φ0 + φ1et + φ2πt-1.

Then Etπt+1 = φ0 + φ1ρet + φ2(φ1et + φ2πt-1) and a second solution, in addition to (7), is
(9)

πt = (1/ρ)et + (1+µ1)πt-1.

Clearly, with µ1 > 0, as specified by the Taylor Principle, this expression (9) implies an

8

My preference is to think of the “Fisher equation” as an identity, one which defines the one-period real
rate of interest as a nominal rate minus expected inflation. The item under discussion here is a model of
individual saving behavior together with a market-clearing condition that consumption equals output in the
aggregate plus the assumption that output is constant.

4

explosive process for the inflation rate.9 That is the type of solution referred to by
Cochrane, and it is clear that in the model at hand there is no transversality condition that
would rule out this explosive solution for the inflation rate. Further investigation,
pertaining to models in which the medium-of-exchange properties of money are
explicitly recognized, will appear below in Section 4. Pending that discussion, it appears
appropriate to accept, on a preliminary basis, the validity of Cochrane’s critique of
mainstream monetary policy analysis, with NK models and Taylor-style policy rules.
3. LS Learnability

Several analysts have argued, however, that for any RE solution to be considered
plausible, and thereby relevant for policy analysis, it should be learnable.10 The basic
idea is simple and powerful. It is that in any RE model intended to represent behavior in
an actual market economy, the individual agents should be able to learn quantitative
details concerning the behavior of variables—which they must forecast for decisionmaking purposes—from data generated by the economy itself.11 Cochrane (2007, p. 44)
briefly disputes that contention, as follows: “... a wide variety of almost philosophical
principles have been advocated to prune equilibria. For example, Evans and Honkapohja
(2001) advocate criteria based on least-squares (LS) learnability, and McCallum (2003)
advocates a ‘minimum state variable criterion,’ which he relates to learnability. These
refinements go beyond the standard definitions of economic equilibria. One may argue
that when a model gives multiple equilibria, we need additional selection criteria. I argue

9

It appears from (9) that this solution will not be defined in the measure-zero case with ρ = 0. But in that
case one can add et-1 as an additional state variable in (8) and obtain an infinity of explosive solutions that
could be indexed by the start-up value of πt-1.
10
These writers include Bullard (2006), Evans and Honkapohja (2001, p. 12-13), McCallum (2003, 2007),
and (arguably) Woodford (2003a, pp. 261-276; 2003b, p. 1183).
11
For RE to obtain, the implied forecasting relationships must be quantitatively accurate.

5

instead that we need a different model.” This argument of Cochrane’s has two parts: (i) a
dismissal of learnability (justified only by his use of the word “philosophical”) and (ii)
advocacy of a “different model,” by which he evidently means the fiscal theory of the
price level. I will discuss the latter below, in Section 5. Here I wish to disagree with the
suggestion that LS learnability is a spurious principle.
Let me begin by quoting myself: “The position that learnability (and thus Estability) should be regarded as a necessary condition for the relevance of a RE
equilibrium [sic?] begins with the presumption that individual agents must somehow
learn the magnitudes of parameters describing the economy’s law of motion from
observations generated by the economy; they cannot be endowed with such knowledge
by magic. Of course any particular learning scheme might be incorrect in its depiction of
actual learning behavior. But in this regard it is important to note that the LS learning
process in question assumes that (i) agents are collecting an ever-increasing number of
observations on all relevant variables while (ii) the structure is remaining unchanged.
Furthermore, (iii) the agents are estimating the relevant unknown parameters (iv) with an
appropriate estimator (v) in a properly specified model. Thus if a proposed RE solution
is not learnable by the process in question—the one to which the E&H results pertain—
then it would seem highly implausible that it could prevail in practice” (McCallum, 2007,
p. 1378). Cochrane suggests, to the contrary, that the notion that individual agents should
have some way of obtaining the information, necessary to form expectations in the
manner hypothesized in the analysis, is in some way “additional” to “standard definitions
of economic equilibria.” To me, this suggestion seems misplaced. In standard (i.e., RE)
analysis, for the determination of current endogenous variables we specify information

6

sets that include quantitative features of the system plus, at a maximum, current and past
values of relevant variables.12 That is basically what LS learnability does for current
knowledge of the economy’s structure. Here, I am assuming that our analysis is based on
a model in which there are many individual agents interacting on markets, each agent
acting individually and without knowledge of other agents’ preferences and technologies
(therefore, their demand and supply functions), which can be different from his own—an
assumption that is not relaxed even if the analyst assumes (for simplicity) that all agents
are alike. I seriously doubt that John Cochrane, a dedicated (as well as skillful)
economist, would object to this position, even though it is perhaps “philosophical.” 13
The point, of course, is that application of the LS learnability criterion does, in the
model at hand, eliminate the explosive solution of equation (9) above. That conclusion is
well known from the analyses of Bullard and Mitra (2002) and Honkapohja and Mitra
(2001), and is discussed on p. 1161 of McCallum (2003). The relevant analysis can be
summarized as follows. Consider linear models that can be written as
(10)

x t = AE t x t +1 + Cx t −1 + Dz t

where xt is a n×1 vector of endogenous variables, the system’s exogenous variables zt
being generated by a first-order autoregressive process
(11)

zt = Rzt-1 + εt

with εt white noise and R being a stable matrix. Here A and C are n×n, D is n×n1, and R
is n1×n1. Considering fundamental solutions of the form

12

For some purposes perfect-foresight analysis is useful, of course, but one would not use that assumption
in an analysis that is concerned with (e.g.) the variability of asset prices or macroeconomic variables.
13
My position could alternatively be expressed as admitting that learnability is not part of “standard
definitions” and then arguing that standard definitions are flawed in the context of models appropriate for
monetary policy analysis.

7

(12)

x t = Ωx t −1 + Γz t ,

standard undetermined-coefficient reasoning establishes that Ω must satisfy the quadratic
(13)

AΩ2 − Ω + C = 0.

There are many matrices that satisfy this quadratic; they result from different orderings of
the generalized eigenvalues of a matrix pencil involving parameter matrices A and C; see
McCallum (2007, p. 1380-2). If more than one of the Ωs that satisfies (13) has all its
eigenvalues less than 1 in modulus there are multiple stable solutions, i.e., indeterminacy.
For such a system, Evans and Honkapohja (2001, p. 238) report that E-stability
(and thus LS learnability) obtains if and only if the following matrices have all
eigenvalues with real parts less than 1:
(13a)

F = (I − AΩ) −1 A

(13b) Ω '⊗ F
(13c)

R '⊗ F .

It will be noted that, if there are no lagged endogenous variables in the system, then C = 0
implying that Ω = 0 and F = A. Then the first two conditions amount to the requirement
that the eigenvalues of A all have real parts less than 1. In the basic system summarized
in (5) above, the fundamentals solution has Ω = 0 and A = 1/(1 + µ1). Thus it is clear that
the ES learnability requirements (13a-c) are satisfied. By contrast, the non-fundamentals
solution (9) yields πt = (1/ρ)et + (1+µ1)πt-1, implying that Ω = 1 + µ1 and thus that
F = (I − AΩ) −1 A = [1 − (1 + µ1 ) /(1 + µ1 )]−1 (1/(1 + µ1 )) = [1−1]-1 (1/(1 + µ1 )) = (1/(1 + µ1 )) /0.

Thus in this case F > 1 + µ1 (an understatement) and at least two of the three conditions
(13) are violated. Accordingly, the explosive solution is not learnable. Although it

8

satisfies the orthogonality conditions for a RE solution, it is implausible that an economic
system matching the specification would generate outcomes of the type described by (9).
It should be added explicitly, perhaps, that the analysis of Evans and Honkapohja
(2001, pp. 138-9, 235, 238) includes results implying that, with the addition of a few
appropriate supplementary conditions, the LS learning process will converge to an
explosive path satisfying (9) with probability zero. In that sense, such paths cannot
represent plausible outcomes.
4. Medium of Exchange Money

To this point there has been no explicit recognition of money, i.e., an asset that
serves as a medium of exchange and thus facilitates transactions in the economy under
discussion. It might be thought that such recognition could itself overturn Cochrane’s
basic argument since recognition of a monetary asset would give rise to a transversality
condition pertaining to real money holdings—and transversality conditions tend to rule
out certain explosive paths as equilibria because they violate conditions necessary for
individual optimality. Cochrane is fully aware of the relevant literature, however, which
rules out paths in which the discounted increment to utility provided by future real money
balances fails to approach zero as the horizon considered increases indefinitely. His
presumption, apparently, is that an explosive inflation rate would tend to reduce real
money holdings and, with the T−1 power of the discount factor approaching zero, thus to
induce the relevant product to approach zero. A basic analysis cited by Cochrane is that
of Obstfeld and Rogoff (1983), in which a model with medium-of-exchange money tends
to rule out paths along which the price level approaches zero but not paths along which
the price level explodes.

9

It is possible to object to the model used by Obstfeld and Rogoff on the grounds
that its money-in-the-utility-function specification does not represent money’s
transaction-facilitating properties as adequately as would a shopping-time or transactioncost model in which time or physical resources used up by transactions depend on both
real money holdings and real quantities of transactions. Additional analysis in that
direction has been conducted by Gray (1984). This paper does not consider every
specification that one might desire, but it goes some substantial way toward justifying the
conclusion of Obstfeld and Rogoff (1983, p. 686) that under a regime of pure fiat money
“… explosive price-level paths—speculative hyperinflations—can be ruled out only
when severe restrictions are placed on individual preferences.” 14
Gray’s analysis includes model specifications in which the medium-of-exchange
role of money is represented by an explicit transaction-cost function. The main weakness
that I can see in her argument is that this function specifies that costs depend only upon
real money holdings; I would instead specify that the costs depend also on the quantity of
transactions conducted (per unit of time, of course). To represent that type of extension,
consider the following setup, which is based in part on McCallum (2001).15
The economy consists of a large number of similar but independently-acting
households, each of which has an intertemporal utility function
(14)

u(ct) + βu(ct+1) + β2u(ct+2) + ....

where ct is consumption in period t. Each household supplies one unit of labor
inelastically each period and uses nt units of labor (the excess, if any, coming from the
14

Obstfeld and Rogoff say “preferences” because their way of incorporating transaction costs is to include
real money balances in agents’ utility function. In Gray’s models both preference and transaction-cost
specifications are relevant.
15
In McCallum (2001) there are a few “typos” including the following: In equations (26) and (27), ψ1(c,m)
should be ψ2(c,m).

10

labor market) to produce f(nt, k) units of output. Its budget constraint for period t is
(15)

f(nt, k) − txt – wt(nt−1) = ct + mt – (1+ πt)-1mt-1 + (1+ rt)-1bt+1 – bt + ψ(ct,mt).

Here txt is lump-sum taxes, wt is the real wage, mt is end-of-period real money balances,
1 + πt = Pt/Pt-1 where Pt is the price level in t, bt+1 is real private bonds purchased in t, and
rt is the real rate of interest on these bonds. Finally, transaction costs are given by
ψ(ct, mt), where ψ1 > 0, ψ11 < 0, ψ2 < 0, and ψ22 > 0 Both f and ψ have the Inada
properties, as does u.
In this setting, a household’s first-order optimality conditions include
(16a)

u '(c t ) − λt[1 + ψ1(ct, mt)] = 0

(16b) −λtwt + λtf1(nt, k) = 0
(16c) −λt[1 + ψ2(ct, mt)] + βEtλt+1(1 + πt+1)-1 = 0
(16d) −λt(1 + rt)-1 + βEtλt+1 = 0
where λt is the Lagrangian multiplier attached to (15). There is a transversality condition
(TC) for bonds,
(17)

lim b T +1βT −1λ T = 0

T →∞

and another for money:
(18)

lim m TβT −1λ T = 0 .

T →∞

The latter two will be taken as necessary for individual-household optimality.16
For general equilibrium, we must also have
(19)

nt = 1

16

The TC (18) can be thought of as arising, from a T-period version of the optimization problem, as a
limiting version as T →∞ of the second part of the Kuhn-Tucker condition ∂L/∂mT ≤ 0 plus mT∂L/∂mT = 0,
since ∂L/∂mT = −βT-1λT. (Here L refers to the problem’s Lagrangian expression.)

11

(20)

bt+1 = 0

(21)

mt = Mt/Pt

and the government budget constraint17
(22)

txt + mt – (1+ πt)-1mt-1 = 0.

In the latter we take government consumption to equal zero, for simplicity. Thus money
is injected via lump-sum transfers (negative taxes). With the government exogenously
setting values of Mt, equilibrium paths for the nine endogenous variables ct, mt, λt, nt, wt,
Pt, πt, rt, and bt+1 are given by equations (15), (16a), (16b), (16c), (16d), (19), (20), (21),
and the definition 1 + πt = Pt+1/Pt .
In this economy, the demand for money relation is, from equations (16c) and
(16d),
(23)

1 + ψ 2 (c t , m t ) =

1
1+ R t

where the nominal interest rate Rt satisfies the Fisher identity
(24)

1 + R t = (1 + rt )(1 + π t +1 ) .

(I ask the reader to please include expectation operators where necessary.) With flexible
prices, rt will be a constant and so as πt+1 explodes, 1 + ψ 2 (c t , m t ) will approach zero.
That is, − ψ 2 (c t , m t ) , the marginal benefit from holding money, will approach 1 from
below as mt/ct declines with the increasing cost of holding money.
To get a feel for the situation, let’s consider the specific transaction-cost function
used in McCallum (2001), viz.,

17

By excluding bonds from (22) I am implicitly assuming that bonds are private loans from one household
to another.

12

(25)

ψ (c, m) = a1c(c / m)a 2 ,

a1 > 0, a2 > 0

in which the average transaction cost has a constant-elasticity relationship to c/m. Note
that this function is one in which the average transaction cost grows without limit as real
money balances approach zero. But as inflation explodes, 1 + ψ 2 (c t , m t ) =
1 − a 2 a1 (c / m)1+ a 2 approaches zero and the limiting condition has c / m = (1/ a 2 a1 )1/(1+ a 2 ) so
m does not approach zero; it approaches a limiting value (say) m* > 0. The calibration
adopted in McCallum (2001) has a1 = 0.00102 and a2 = 4, in which case c/m* equals
3.96. This calibration is designed to pertain to the quarterly frequency, suggesting that
real money holdings in this situation are about 1/4 of quarterly spending. In the recent
U.S. data, by contrast, the M1 value of c/m is of the order of magnitude of 1, about four
times this limiting value.
The relevance of all this for the issue at hand is that the transversality condition
(TC) for money holdings does not fail in the model at hand as inflation explodes. The
value of λt in our model is, from (16a),
(26)

λt =

u '(c t )
u '(c t )
=
,
1 + ψ1 (c t , m t ) 1 + (1 + a 2 )a1 (c t / m t )a 2

But from our calculations in above, we see that the latter does not grow without bound as
inflation explodes; the right-hand side of (26) approaches a positive limit. Then with λT
remaining finite, violation of the TC (18) will not occur, since both mT and λT remain
finite while βT-1 approaches zero as the horizon T extends indefinitely.
A heuristic but more general argument can be made without reference to any
specific transaction technology, as follows. Transversality conditions for money holdings
are in general limiting values (as T → ∞) of the product of three terms: βT-1, mT, and λT,

13

where the latter is a Lagrange multiplier on the budget constraint for period T. If this
limit is zero, the TC is satisfied; if it is not for some path, that path is not optimal for the
agent. Now clearly βT-1 approaches zero as T grows, so for the TC to fail, either mT or λT
must explode. Exploding inflation tends, however, to drive the former toward small
values. So the only way that the TC can fail is for λT → ∞ as T → ∞.
But since λT is a multiplier on the budget constraint, with each term in the latter
expressed in real terms, λT represents the increase in utility made possible by a one-unit
decrease in period-T real money holdings, at the margin. This magnitude will tend to
increase as money holdings decrease, but it cannot plausibly increase without bound.
Marginal utility of consumption may → ∞ as ct → 0, but a model specification that drives
consumption to zero (as real money holdings decrease) implies that a barter economy
would necessarily feature zero consumption. That seems to be an inadmissible
assumption, however, even to an enthusiast for the MOE role of money. This, I believe,
is what lies behind Cochrane’s assumption that exploding inflation does not imply the
failure of any TC.
5. Fiscal Theory of the Price Level

Cochrane, to his credit, does not end his paper with a conclusion that “anything
can happen.” Instead, he invokes the “fiscal theory of the price level,” henceforth FTPL.
Specifically, he says “... I conclude that the fiscal theory is the only currently-available
economic model that can do so,” that is, “can determine the price level or inflation rate in
a fiat-money economy with the sort of interest rate targets that we observe central banks
to follow” (2007, p. 44). To do this he must, of course, introduce government bonds.
That necessity is somewhat unfortunate for several reasons, the most important being that

14

one should be able to construct a theory of what happens with a Taylor rule in an
economy in which there is no government debt other than money. But let us nevertheless
take his suggestion and include government bonds. To be distinguishable from money
there must be some transaction-facilitating services provided by the latter but not the
former (or more such services provided by the latter). Probably Cochrane would not
object to that idea.18
Continuing, then, let us consider the equilibrium that obtains in an economy in
which the central bank follows a Taylor rule that satisfies the Taylor Principle—the case
with which we are here concerned—while the fiscal authority is setting government
spending exogenously and setting (lump sum) taxes in response to the quantity of
outstanding bonds according to a rule of the type discussed by Leeper (1991), Sims
(1994), Woodford (1995), and Cochrane (2005). The fiscal authority’s rule may be
“active” or “passive,” in Leeper’s terminology. In the latter case the rule is a sensible
one, i.e., is one that collects enough (lump sum) taxes to decrease the (per capita) debt
[assuming no real growth in output] by some positive fraction from one period to the
next. An “active” policy, by contrast, either taxes so aggresively that debt is reduced to
zero in the “first” period or else so weakly that the debt grows continually from period to
period.19 Neither of these extremes is, I would contend, relevant to actual economies of
decently governed nations, not even the profligate USA of today.20
What happens in such a situation, with an active monetary policy and passive
18

He has, however, discussed the FTPL in the context of an economy with no money. I have argued
elsewhere that this approach negates the whole raison d’etre of the FTPL, which is to provide a logical
mechanism of price level determination that contrasts with the monetary approach, a contrast that is ruled
out by assumption if the model includes no money. On this topic, see McCallum and Nelson (2005).
19
It should be noted that Leeper’s terminology terms monetary policy as “active” when it is sensible, and
fiscal policy as “active” when it is extremely expansionary or extremely contractionary. Thus it is not the
case that there is a symmetry between AM-PF and PM-AF, AM meaning active money, etc.
20
But they will, nevertheless, be considered momentarily.

15

fiscal policy? Evans and Honkapohja (2007) have examined that case, with results
summarized in McCallum and Nelson (2005). In the relevant region, with sensible
monetary and fiscal policy, there is a single stable solution and it is learnable. It features
exactly the equilibrium assumed in standard analysis of the NK type.
If, however, the fiscal authority adopts (for some perverse reason) an active—i.e.,
extreme and non-sensible—rule, then there are two cases. First, with overly aggressive
tax collections there is no learnable equilibrium. The analysis predicts that this
combination of policies would lead to disorderly behavior that rational analysis is poorly
equipped to explain. Secondly, with sensible monetary policy and insufficiently strong
tax policy, there is no stable solution. (There is a small region in which bonds explode
but money and prices are stationary in a learnable equilibrium, and also a still smaller
region in which money, bonds, and prices all explode in a learnable equilibrium21). In
both of these cases, as McCallum and Nelson (2005) explain, the outcome is exactly what
traditional monetarist analysis would predict. Thus the FTPL is not, I contend, helpful in
explaining price level behavior in a fiat money economy.
5. Conclusions

It is clearly important that the logical foundations of the dynamic models used in
current mainstream monetary policy analysis be clearly understood. Accordingly,
Cochrane’s recent paper makes a substantial contribution by pointing out that
determinacy, in the sense of a unique solution that is dynamically stable, does not provide
an adequate foundation for analyses of the standard type. It is the case, however, that a
more satisfactory criterion, that of least-squares learnability, is available. Basic
informational requirements suggest that learnability should be considered necessary for
21

See Evans and Honkapohja (2007, pp. 681-682).

16

the plausibility of any rational expectations equilibrium,22 and acceptance of this view
rules out explosive solutions of the type discussed by Cochrane.23 A useful by-product of
such acceptance is that “indeterminacy” ceases to be a problem in other circumstances,
such as strenuous inflation-forecast targeting, not discussed by Cochrane (2007).24

22

Indeed, probably, for the definition of an equilibrium.
In this paper I have focused on Cochrane’s argument and accordingly have not considered more esoteric
classes of sunspot solutions.
24
This position is argued by McCallum (2003). Woodford’s (2003b) comment stresses objections to
McCallum’s “minimal state variable” solution concept, but features very little disagreement with his
paper’s substantive positions (which do not rely upon that concept).
23

17

References

Bullard, J.B. (2006) “The Learnability Criterion and Monetary Policy.” Federal Reserve
Bank of St. Louis Review 88 (3): 203-217.
Bullard, J.B., and K. Mitra (2002) “Learning about Monetary Policy Rules,” Journal of
Monetary Economics 49, 1105-1129.
Clarida, R., J. Gali, and M. Gertler (1999) “The Science of Monetary Policy: A NewKeynesian Perspective,” Journal of Economic Literature 37, 1661-1707.
Cochrane, J. H. (2005) “Money as Stock,” Journal of Monetary Economics 52, 501-528.
____________ (2007) “Inflation Determination with Taylor Rules: A Critical Review.”
NBER Working Paper 13409.
Evans, G.W., and S. Honkapohja (2001) Learning and Expectations in Macroeconomics.
Princeton University Press.
__________________________ (2007) “Policy Interaction, Learning, and the Fiscal
Theory of Prices,” Macroeconomic Dynamics 11, 665-690.
Goodfriend, M. (2006) “How the World Achieved Consensus on Monetary Policy.”
Journal of Economic Perspectives 21(4), 47-68.
Goodfriend, M., and R.G. King (1997) “The New Neoclassical Synthesis and the Role of
Monetary Policy,” NBER Macroeconomics Annual 12, 231-283.
Gray, J.A. (1984) “Dynamic Instability in Rational Expectations Models: An Attempt to
Clarify,” International Economic Review 25, 93-122.
King, R.G. (2000) “The New IS-LM Model: Language, Logic, and Limits,” Federal
Reserve Bank of Richmond Economic Quarterly 86(3), 45-103.

18

King, R.G., and A.L. Wolman (1996) “Inflation Targeting in a St. Louis Model of the
21st Century,” Federal Reserve Bank of St. Louis Review 78(3), 83-107.
Leeper, E.M. (1991) “Equilibria under ‘Active’ and ‘Passive’ Monetary and Fiscal
Policies,” Journal of Monetary Economics 27, 129-147.
McCallum, B.T. (2001) “Monetary Policy Analysis in Models without Money,” Federal
Reserve Bank of St. Louis Review 83(4), 145-160.
______________ (2003) “Multiple-Solution Indeterminacies in Monetary Policy
Analysis,” Journal of Monetary Economics 50, 1153-1175.
______________ (2007) “E-Stability vis-a-vis Determinacy Results for a Broad Class of
Linear Rational Expectations Models,” Journal of Economic Dynamics and
Control 31, 1376-1391.
McCallum, B.T., and E. Nelson (2005) “Monetary and Fiscal Theories of the Price Level:
The Irreconcilable Differences,” Oxford Review of Economic Policy 21, 565-583.
Obstfeld, M., and K.. Rogoff (1983) “Speculative Hyperinflations in Maximizing
Models: Can We Rule Them Out?” Journal of Political Economy 91, 675-87.
Rotemberg, J.J., and M. Woodford (1997) “An Optimization-Based Econometric Framework for the Evaluation of Monetary Policy,” NBER Macroeconomics Annual 12,
297-346.
Sims, C.A. (1994) “A Simple Model for Study of the Determination of the Price Level
and the Interaction of Monetary and Fiscal Policy,” Economic Theory 4, 381-399.
Svensson, L.E.O., and M. Woodford (2005) “Implementing Optimal Policy Through
Inflation-Forecast Targeting,” in B.S. Bernanke and M. Woodford, eds., Inflation
Targeting. University of Chicago Press.

19

Taylor, John B. (1993) “Discretion versus Policy Rules in Practice,” CarnegieRochester Conference Series on Public Policy 39, 195-214.
____________ (1999) “The Robustness and Efficiency of Monetary Policy Rules as
Guidelines for Interest Rate Setting by the European Central Bank,” Journal of
Monetary Economics 43, 655-679.
Woodford, M. (1995) “Price Level Determinacy without Control of a Monetary
Aggregate,” Carnegie-Rochester Conference Series on Public Policy 43-1-46.
____________ (2003a) Interest and Prices: Foundations for a Theory of Monetary
Policy. Princeton University Press.
____________ (2003b) “Comment,” Journal of Monetary Economics 50, 1177-1188.

20

