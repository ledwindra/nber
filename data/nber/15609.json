{
    "id": 15609,
    "citation_title": "What Happens in the Field Stays in the Field: Exploring Whether Professionals Play Minimax in Laboratory Experiments",
    "citation_author": [
        "Steven D. Levitt",
        "John A. List",
        "David H. Reiley",
        "Jr."
    ],
    "citation_publication_date": "2009-12-23",
    "issue_date": "2009-12-23",
    "revision_date": "None",
    "topics": [
        "\n",
        "Microeconomics",
        "\n",
        "Game Theory",
        "\n",
        "Econometrics",
        "\n",
        "Experimental Design",
        "\n"
    ],
    "program": [
        "\n",
        "Industrial Organization",
        "\n",
        "Labor Studies",
        "\n"
    ],
    "projects": null,
    "working_groups": [
        "\n",
        "Behavioral Finance",
        "\n"
    ],
    "abstract": "\n\nThe minimax argument represents game theory in its most elegant form: simple but with stark predictions.  Although some of these predictions have been met with reasonable success in the field, experimental data have generally not provided results close to the theoretical predictions.  In a striking study, Palacios-Huerta and Volij (2007) present evidence that potentially resolves this puzzle:  both amateur and professional soccer players play nearly exact minimax strategies in laboratory experiments.  In this paper, we establish important bounds on these results by examining the behavior of four distinct subject pools:  college students, bridge professionals, world-class poker players, who have vast experience with high-stakes randomization in card games, and American professional soccer players.  In contrast to Palacios-Huerta and Volij's results, we find little evidence that real-world experience transfers to the lab in these games--indeed, similar to previous experimental results, all four subject pools provide choices that are generally not close to minimax predictions.  We use two additional pieces of evidence to explore why professionals do not perform well in the lab: (1) complementary experimental treatments that pit professionals against preprogrammed computers, and (2) post-experiment questionnaires.  The most likely explanation is that these professionals are unable to transfer their skills at randomization from the familiar context of the field to the unfamiliar context of the lab.\n\n",
    "acknowledgement": "\nWe would like to thank Editor David Levine and three anonymous referees for valuable comments. Ignacio Palacios-Huerta and Jesse Shapiro provided helpful conversations.  Phil Gordon was instrumental in our efforts to recruit world-class poker players.  Omar Al-Ubaydli, David Caballero, Dwyer Gunn, Bill Hessert, Ryan Johnson, Min Lee, Randall Lewis, Andrew Sherman, Alec Smith, Brittany Smith, Dean Strachan, and especially Lisandra Rickards provided fantastic research assistance.  Author affiliations: Levitt and List: Department of Economics, University of Chicago, 1126 E. 59th Street, Chicago, IL 60637.  Reiley: Department of Economics, University of Arizona, 401 McClelland Hall, Tucson, Arizona 85721. The views expressed herein are those of the author(s) and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}