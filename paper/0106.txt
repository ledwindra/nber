NBER WORKING PAPER SERIES

Parametric Integer Programming:
The Right—Hand—Side Case

Roy E. Marsten*
Thomas L. Morin**

Working Paper No. 106

COMPUTER RESEARCH CENTER FOR ECONOMICS AND MANAGEMENT SCIENCE
National Bureau of Economic Research, Inc.
575 Technology Square

Cambridge, Massachusetts 02139

October 1975

Preliminary: not for quotation
NBER working papers are distributed informally and in limited numbers for
comments only. They should not be quoted without written permission.
This report has not undergone the review accorded official NBER publications;
in particular, it has not yet been submitted for approval by the Board of
Directors.
*NBER Computer Research Center and Sloan School of Management, Massachusetts
Institute of Technology. Research supported in part by NSF Grant GJ—1154X3
to the National Bureau of Economic Research, Inc.
**School of Industrial Engineering, Purdue University.

Abstract

A family of integer programs is considered whose right—hand—sides lie

on a given line segment L. This family is called a parametric integer
program(PIP). Solving a (PIP) means finding an optimal solution for every
program in the family. It is shown how a simple generalization of the
conventional branch—and—bound approach to integer programming makes

it possible to solve such a (PIP). The usual bounding test is extended
from a comparison of two point values to a comparison of two functions

defined on the line segment L. The method is illustrated on a small example
and

computational

results for some larger problems are reported.

Acknowledgement

The computer implementation of the algorithm reported here was done
by Lee Aurich and Nancy Kaplan.

Table of Contents

1. Introduction

1

2. A Prototype Branch—and—Bound Algorithm

2

3. The Optimal Return and Lower Bound Functions

5

Figure 1. Typical g(O) and LB(O) functions

6a

Figure 2. Typical B(Q) and uB(0;*) functions

6a

LI. The Upper Bound Functions

7

5. A Branch—and—Bound Algorithm for (PIP)

9

6. Example

.

.

. 13

•

•

. 17

Figure 3.

The optimal return function f(b)..

Figure 4.

The parametric function g(O)

Figure 5.

Branch—and—bound tree for the example

18

Figure 6.

Bounding test for node 1

19

Figure 7.

Bounding test for node 2

19

Figure 8.

Bounding test for node 3

20

Figure 9.

Bounding test for node 6

.

.

17

.

20

Figure 10. Bounding test for node 10 .

21

Figure 11. Bounding test for node 11 .

•

.

7. Computational Results

22

Table 1. Computational Results for Three Test Problems

Table 2. The 5x30 Test Problem
Table 3. The g(O) function for a 10% Increase in b;
5x30 problem
REFERENCES

. 21

23
•

.

. 24
25
26

1. Introduction

The purpose of this paper is to show how a simple generalization of
the conventional branch—and—bound approach to integer programming makes

it possible to solve a parametric integer program. Following Nauss [6]
we shall call the family of programs

r.x.

(P0) max
j=l

subject to

b.+Od.
1
1

a.

x,J
for

{O,l}

a single parametric integer program (PIP). By "solving" (PIP)

we shall mean obtaining an optimal solution of (P0) for every

for

which

(P) is feasible. We assume that (P0) is feasible for at least one value of 0.
Parametric integer programming has only recently emerged as a topic

of research. The pioneering papers include Noltemeier [7], Roodman [9,10],

Piper and Zoltners [8], and Bowman [1]. Nauss [6] has reviewed this earlier
work and

contributed

many new results for parameterizations of the objective

function. The present paper, which has grown out of the authors' work on
synthesizing dynamic programming with branch—and—bound [3,4,5], is devoted
to the right—hand—side case.

—2—

In parametric linear programming, the first step is to solve (P0),

i.e. (P®) for 0=0. Then the direction vector d=(d1, •••
and

the

analysis is performed by driving 0

d)

is specified

from 0 to 1. Critical values of

0 and new optimal solutions are identified one at a time as 0 increases.
In the procedure for parametric integer programming to be presented here,

the direction d must be specified in advance. The (PIP) is solved in one
branch—and—bound

partial

search. The usual bounding test is modified so that a

solution is eliminated only if none of its descendants is optimal

for any (P®),

This means

that some partial solutions must be

retained that could otherwise be eliminated if only (P0) were of interest.
The severity of the resulting computational burden depends on the magnitude
of

d.

The organization of the paper is as follows. A prototype branch—
and—bound algorithm for (P0) is presented in Section 2.
The lower bound and upper bound functions are developed in Sections 3 and

4, respectively. The modified branch—and—bound algorithm for (PIP) is
given in Section 5 and applied to a sample problem in Section 6. Computational
experience with the algorithm is reported in Section 7.

2. A prototype branch—and—bound algorithm

We shall draw upon the framework and terminology of Geoffrion and
Marsten [2] to describe a simple linear programming based branch—and—bound

algorithm for (P0). Problem (P0) is separated, by fixing variables at zero

—3—

and one, into smaller candidate problems (CP)• Each candidate problem
has an associated set of fixed variables
solution

c

J{l,

...,

n}

and partial

That is, (CP') is defined by the conditions x =

for

j

The current set of candidate problems is called the candidate list. If
any feasible solutions of (P0) are known, the best of these
incumbent

is called the

and its value denoted by LB. If we let J'= _q be the set of

"free" variables and

q= A.x
where

A is the jth

written

column of A, then a typical candidate problem may be

as

(P)

rx.

r.x + max

1i
ij j b.—

subject to

a.

x•J (O,1}
An upper bound on the value of (CP) is obtained by solving its LP

relaxation (CP ). It is also helpful to compute a lower bound on the value of
(CP)•

This can

be

done by using

a

heuristic to find a feasible solution

of (CP)• This feasible solution, if it is better than the incumbent,
becomes the new incumbent. A prototype branch—and—bound algorithm may now
be described as follows.

—4—

.

Step 1. Place (P0) in the candidate list and set LB

—

Step 2. If the candidate list is empty, stop. If there is an
incumbent, it is optimal for (P0). Otherwise (P0) is
Step

infeasible.

3. Select a candidate problem and remove it from the candidate

Step 4.

list. Call it (P)
Solve

value.

denote its optimal

the linear program (CP ). Let
LB, go to Step 2.

Step 5. If

Step 6. If the optimal solution of (CP )

is

all integer, make this

and go to iep 2

solution the new incumbent, set LB

Step 7. Use a heuristic to find a feasible solution of

denote its value. If

>

(P)• Let

LB, then make this solution

the new incumbent and set LB =

Step 8. Separate (P) into two new candidate problems (P ) and
=

u{p},

(P )

0,

=1.

by choosing

and setting

Place (P ) and

(P ) in the candidate list and return to

Step 2.

A great many variations on this pattern are described in [2], but this

prototype will suffice for our purposes. Step 5 is the bounding test.
this test is satisfied, then no descendant of

If

is better than the incumbent.

Notice that the bounding test includes the case where (CP ), and hence

(P), is infeasible since then

=

— . If

(cP') does not have to be

separated at Step 8, then we say that it has been fathomed. This occurs

if (P) passes the bounding test or if (CP ) has an all integer solution.
Step 7, the heuristic, is optional. Its purpose is to strengthen the bounding
test by improving the incumbent and increasing LB.

—5—

The modifications that must be made to this prototype algorithm to

solve (PIP) are confined to Steps 5, 6, and 7. The notion of the incumbent
must be generalized from a single value LB to a function LB(6) defined on
o

The upper bound must also be expressed as a function of e:

The bounding test then becomes a comparison of two functions on the
interval

rather than just a point comparison for 00.

3. The optimal return and

lower

bound functions.

In this section we shall investigate the behavior of the optimal

value of an integer program as a function of its right—hand—side. Let
the optimal return function

rx

f(b.a) = max

x
be defined for b

subject to Ax

{0,l}
Rm.

It is apparent that f(b) is nondecreasing in each

component of b. Let {Xk

k E K} be the set of all feasible solutions of

(PIP), i.e. of all (F0) for

irnr.x kif b

j=l

fk(b_) =
I

—

b'

For each k K, define the step function
c'n

L

k

A.x.

j=l

otherwise

for all V Rm.
The optimal return function f(b') is the pointwise maximum of this finite
collection of nondecreasing step functions

f(b) = max {fk(b.) I k c K}

—6—

S
and is therefore itself a nondecreasing step function.

k K) are known, where K C K.

Now suppose that the solutions

A lower approximation of f(b') may be constructed from these known solutions,
namely
= max

{fk(b) k

Clearly f(b) is also a nondecreasing step function and is a lower bound

function for f(b), i.e. (b)

f(b) for all b_€Rm. The approximation

can be improved as new feasible solutions are discovered.

We are interested in a particular "slice" of f(b) and f(b): the
b is the right—hand—side of (P0) and d is

line segment

the given direction vector. Define g(O)f(b+Od) and LB(O)=f(b+Od) for
Then g(e) and LB(e) are both step functions and LB(O)

g(O) for all

If dO, then g(O) and LB(O) are both nondecreasing. (See Figure 1).
There is at least one optimal solution of (PIP) associated with each step

of g(O). Solving (PIP) is equivalent to constructing g(e) by finding at
least one x solution for each of its steps.

The procedure for constructing LB(O) from the known feasible solutions

is as follows. For each k E K define

mm {O

= max {O I

A.x

b + Od}

(3.1)

b + Od}

(3.2)

j=l

where

=

=+

if the indicated set is empty. Then

rx1

LBk(O)

={,
— _

if

otherwise

(3.3)

—6 a—

0

0

Figure 1. Typical g(O) and LB(O) functions.

/ TJB1(O;*)

0

0

1

Figure 2. Typical UB(e) and UB(0;*) functions.

—7—

and

LB(0) = max{LBk(0)

k

i}.

(3.4)

The solutions which determine LB(0) will be called the incumbents. Each one
is incumbent for a particular interval of 0.

4. The upper bound functions.

•

Consider a given partial solution

that no descendant of

In order to demonstrate

could be optimal for any

we need an upper bound

(P0),

on the return achieved by any descendant and this upper bound must depend
on 0. Such an upper bound can be obtained by introducing (Od) into the

relaxed candidate problem (CP ).

rx + max

=

subject

Define

r•x.

to

a. •x
1J J

b.+
Od.—?
1
11

j

E

J

It

so that UB(Q) =
linear on

is well known

that

UB(0) is concave and

piecewise

The function UB(0) could be obtained explicitly by

ordinary parametric linear programming. The computational burden involved
in

doing this for every candidate problem Could be quite substantial, however.

Fortunately any dual

feasible solution of (CP )

a linear upper bound function for UB(B)

can be used to construct

An optimal dual solution of

(CP ), barring degeneracy, yields the first linear segment of UB(0)•

—8—

By linear programming duality we know

rx + mm

=

that;

11

u.(b.+Od.—?) +

1=111

u.a. + v.

subject to

J

i=l

v.

r.
.1

U.

0

V.

0

1

1

For notational convenience we have included all of the v. variables,

in any optimal solution. Let

even though v0 for

denote the

dual feasible region

=

(u,v)0

for

ua1. +

Since the primal variables are all bounded and at least one (P0) is
feasible, we may conclude that

is non—empty. Let {(ut,

and

{(y5, 8)55} denote the sets of extreme points and extreme rays,

Taking e(l, ..., 1) we have

respectively, of

+ vte

rx1 +
J

for all t€T, with equality if (Ut, Vt) is optimal for the objective

function u(b+Od—) + ye. As a function of 0 then, the return achieved by
any descendant of

=

for any

is bounded above by:

(utd)0

+ [

r.x + ut(b_) + vte]
J J

This is a linear function of U and,since uO, it is

nondecreasing if d0.

—9—

In the modified branch—and—bound algorithm for (PIP), linear

programming is applied to (CP ) as usual. The functions UB(@;t)

are

obtained at no extra cost. The function obtained from an optimal dual

solution will be denoted UBC1(S;*). Barring degeneracy, UB(;*) coincides

with the first linear segment of UB(0)• (See Figure 2). As in conventional
branch—and--bound, if the dual simplex method is used, then suboptimal dual

solutions can be used to perform additional weaker tests.

If (CP )

is

infeasible, then the simplex method will terminate

with an extreme point (ut, vt)

0 and an extreme ray (S z5)

0,

such that
S
q
y (b—s )

+ zs e < 0.

If y5dO, then we may conclude that IJB(0) =
then UB'(O) =

0*

—

—

for

for 0O<O* and B(e) UB'(O;t)

all

for

If ySd>O

where

5
5
q
—y (b—s ) — z e
S
yd

5. A branch—and—bound algorithm for (PIP).

Now that the upper and lower bound functions have been derived,

the generalized bounding test may be stated. The partial solution
not have a descendant that is batter than an incumbent jf

does

—10—

LB(8)

for all

or if

for all

LB(O)

This test is the basis for a modified branch—and—bound

for some

algorithm that can solve (PIP).

Step 1. Place (P0) in the candidate list and set LB(O) =

—

for

Step 2. If the candidate list is empty, stop.
LB(0) = g(O) for
Step 3. Select a candidate problem and remove it from the candidate

list. Call it

If

it is infeasible, obtain the appropriate
dual extreme point (u*, v*) and extreme ray (y*, z*).
Otherwise obtain an optimal dual solution (u*, v*).

Step 4. Solve (CP ).

infeasible.

Step 5. I. (CP )

(a) y*d
(b)

0.

y*d > 0.

Go to Step 2.

Set 0* =

If TJB(®;*)

LB(O)

[_y*(b_1)_z*e]

for all

/

y*d.

go to Step 2.

II. (CP ) feasible.

If (Q;*)
Step

LB(0)

for all

go to Step 2.

6. If the optimal primal solution of (CP )
use it to update LB(0).

is

all integer,

Step 7. Use a heuristic to find feasible solutions of (CP) with
right—hand—side (b+Od) for several values of 0. Use these
feasible solutions to update LB(0).
Step 8.

Separate (CP) into two new candidate problems (P ) and
=
u p}
and setting q =
(P) by choosing
=0, x'

=1. Place (P) and (P) in the candidate

list and return to Step 2.

—11—

The validity of the generalized bounding test insures that art
optimal solution for every (P®),

will be found by the search. At

worst, an optimal solution may not be discovered until the bottom of the
branch—and—bound

coincide

tree is reached (F=J)• This guarantees that 12(0) will

with g(0) by the time the algorithm is finished. It remains only

to show how the optimal solutions are identified.

Let {x'kc} be the set of incumbents whenthe algorithm
terminates. Let 0E[O,l] and suppose that (P®) is feasible, g(e) >

From the construction of LB(0), (3.1) —

(3.4),

—

we know that there is some

kd such that
g(0) = LB(0)
=LBk(O)

=j=l rx>—
k

Furthermore, LBk(O) >

A.x

—

means that 0 0 0 ,

or

equivalently that

b+Od.

j=l

Since

that

is feasible for (P®) and its return is equal to g(0), it follows

is optimal for (P®). To summarize, if k€ and 0€[O,1], then

optimal for (P®)

if

and only if

A.x'

i)

b+Od

j=l
and

= g(0)

ii)

j=l

—12—

At Step 6, in contrast to the prototype algotithm,

when the optimal primal solution of (CP )

is

is not fathomed

all integer. This is because

may have other descendants which are optimal for 0>0. The use of heuristics
at Step 7, while in principle optional, is an important part of the algorithm

since integer solutions of (CP ) can only yield LB(0) = LB(0) for
The heuristics are needed to produce stronger values of LB(0) for 0 >

0.

As with the prototype algorithm, the above procedure will admit

considerable variation and refinement. If the dual simplex method is
used, then suboptimal dual solutions can be used to perform additional

bounding tests. Cutting planes can be generated for any candidate
problem to give stronger upper bound functions0 Parametric linear programming
can be used to generate more than the first segment of

If a

candidate problem with an all —integer LP solution has to be separated at
Step 8, then the same LP solution is optimal for one of the two new

candidates and does not have to be recomputed. Extensive experimentation
will be required to determine the most effective computational tactics.

—13—

6.

Example

In this section the algorithm will be applied to a simple example.
In order to illustrate all of the different cases that can

arise,

the

parameterization will be done over a relatively large interval. The test
problem is

max lOx1 + 15x2 + lOx3 + 5x4

subject to
2x1 + 3x2 + 5x3 + 1x4
4x1

+

2x2

4 + 04

+ 1x3 + lx4
E

4

+ 04

{O,l}

Thus b(4,4), d=(4,4) and increasing 0 from zero to one amounts to doubling

the right—hand—side. A picture of the optimal return function f(b) is
given in Figure 3. The dashed line indicates the line segment of interest:

b+Od

It is clear from this picture that three optimal solutions

must be found, with values of 20, 25, and 30. These solutions are (0,1,0,1),
(1,1,0,0), and (1,1,0,1) respectively. The g(0) function, shown in Figure 4, is

2O
g(0) =

for0

25 for 1/2

130 for

3/4

0<1/2
0 <
0

3/4
1.

The optimal LP solution of (F0) is x=(l/2,l,O,0), u=(5,O), v=(O)

with value UB°=20. The rounded down solution has value 15 and is feasible
for e0; the rounded up solution has value 25 and is feasible for 01/2.

—14—

function:

This provides an initial lower bound

LB(O) =

0 <
for 0
ç15
0
125 for 1/2

1/2
1.

The complete branch—and—bound tree is displayed in Figure 5. The nodes
will be discussed in the order in which they were created.

Node 1. LP solution: x(O,l,O,l), u(5,O), 'v(0), UB20. 1B1(0;*)=208+20.
The LP solution is all integer and is feasible for 00. Therefore the lower
bound function may be improved:

LB(0) =

120
125

for 0

for

1/2

0 <
0

1/2

1.

The bounding test for node 1 is shown in Figure 6. Node 1 is not fathomed.

Node 2. LP solution: x(l,0,O,O), u(0,lO), v(O),

13B2(0;*)400+lO.

The bounding test, shown in Figure 7, is not successful. Notice that if we
were only interested in solving (P0) we would be finished. Node 1 has an
all integer solution with value 20 and node 2 has upper bound UB2=lO<20L3(0).

Node 3. LP solution: x=(0,0,315,l), u=(2,O), (0,0,0,3),

=ll.

IJB3(0;*)80+1l. The bounding test, shown in Figure 8, is successful and
node 3 is fathomed.

Node 4. Same as node 1, since optimal LP solution at node 1 has x2 = 1.

flex, Same as node 2, since optimal LP solution at node 2 has

=

0.

—15—

Node 6. LP is infeasible.. The dual extreme point is u=(0,lO), v=(0) and

the

extreme ray is y=(O,l), z(0). The critical value of U is (—y(b—6)—ze.)/yd=l/2.

for

Thus 6(U). —

0O<l/2 and UB6(e;*)=400+5 for

The bounding

test is shown in Figure 9.

Node 7. Same as nodes 1 and 4, since optimal LP solution for node 4 has x30.

Node 8. LP is infeasible. The dual extreme point is u=(5,0), v='(O) and

the extreme ray is y(l,0), z=(0). The critical value of U is (—y(b—8)—ze)/yd=l,
so TJB8(U) =

—

on

and node 8 is fathomed.

Node 9. Same as nodes 2 and 5, since optimal LP solution for node 5 has x3=O.

Node 10. LP is infeasible. The dual extreme point is u(5,0), v=(0) and

the extreme ray is y(l,O), z=(0). The critical value of U is (—y(b—°)—ze)/yd=3/4.

for

Thus UB10(U) —

0U<3/4 and UB(U;*)=20U+5 for

Node 10 is

therefore fathomed. See Figure 10.

Node 11. LP is infeasible. The dual extreme point is u(0,5), v(0) and

the extreme ray is y(O,l), z(0). The critical value of U is (y(b_L)—ze)/ydl/2.
Thus UB11(U) =

—

for

0U<l/2 and 1JB11(U;*)=20U+15 for

Node 11 is

not fathomed. See Figure 11.

Node 12. LP is infeasible. The dual extreme point is u=(5,0), v=(0) and

the extreme ray is y(1,0), z=(0). The critical value of U is (—y(b-2)—ze)/yd1

Therefore 12(U) =

—

for

and node 12 is fathomed.

—16—

S
Nodes 13—18 are all at the bottom level of the search tree. The
solution for node 18, (1,1,0,1), has value 30 and is feasible for O3/4.

The lower bound function may be improved by redefining LB(O)30 for
LB(O) now coincides with g(O) on

The algorithm terminates since the

candidate list is empty.

The amount of extra computation required to solve (PIP), as compared

to (P0), depends on the length of the interval of parameterization. When
this interval is small, the burden imposed by parameterization may be

slight or even negligible. When it is large, however, as illustrated in
this example, the burden can be quite substantial.

—17—

8

7

6
5

4

3
2

1

0

1

2

Figure 3.

3

4

5

6

7

8

The optimal return function f(b).

30

25

20
15

10
5

0

1/4

Figure 4.

1/2

3/4

The parametric function g(O).

1

b1

—18—

=1

x21

x4=O

x4O

x3= 1

x3= 0

x3= 1

x30

x40

x4= 1

Figure 5. Branch—and--bound tree for the example.

—19—

30
25
20

15

10

5
0
1/4

Figure 6.

1/4

1/2

3/4

1

Bounding test for node 1.

1/2

3/4

Figure 7. Bounding test for node 2.

1

—20—

30
LB (6)

25
20
15

10
5
0

1/4

1/2

3/4

Figure 8. Bounding test for node 3.

406+5, 01/2

30

25
20

15

10
5

0
1/4

1/2

3/4

Figure 9. Bounding test for node 6.

1

—21—

30
25

20
15
10
5
0

1/4

1/2

3/4

1

Figure 10. Bounding test for node 10.

200+15, 01/2

0

1/4

1/2

3/4

1

Figure 11. Bounding test for node 11.

—22--

7. Computational Results

The ideas presented above were tested by incorporating them into a

branch—and—bound computer code [3J. The results for three test problems are
presented in Table 1. In each run the direction vector d was taken as some

percentage of the right—hand—side b. For example, if d5%b, then (PIP) has
right—hand—sides b+O(.05)b for

The column headed "solutions" gives

the number of optimal solutions found, or equivalently the number of steps

of the g(O) function. "Heuristic" is the number of (evenly spaced) e values
for which the heuristic is applied at Step 7. The problems are of the capital
budgeting type and the heuristic employed is that of Toyoda [11]. "Pivots"
is the total number of linear programming pivots and "time" is the total
solution time in seconds on an IBM 370/168.

These results illustrate quite clearly how the computational burden

increases as the interval of parameterization is lengthened. In order to
facilitate comparison with our results by other researchers we have included
the data for the 5x30 problem as Table 2 and the corresponding g(O) function
for a 10% increase in b as Table 3.

—23—

Table 1. Computational Results for three test problems.

m

n

5

15

5

10

30

28

d

solutions

heuristic

pivots

time

0

1

1

39

.239

.05b

4

10

62

.541

.lOb

5

10

91

.815

.15b

7

10

124

1.044

.20b

8

10

130

1.170

.25b

10

10

171

1.534

.50b

16

20

315

3.162

0

1

1

153

1.605

.05b

10

10

479

7.280

.lOb

26

10

1958

24.040

0

1

1

67

1.073

.05b

16

10

181

4.192

.lOb

29

20

637

11.970

.15b

42

20

1586

29.204

—24—

Table 2. The 5x30 test problem.
a.

a

188

91
179
146
155
102
112
126

ij
92
6
80

91
44

108
166
171
64
97
35

51
98
36
70
27
94

68
13

13.2
15.1
3.3
7.4
7.0
1.2
7.0
17.0
13.8

b=

zj

21
39
67
29
55
72

17

0

a.

a.4J

a.5J

c.

20
99
95
95

86

164
98

84
136
166
13
20
124
42

936
695
390
1152
980
1000
815
109
807
156
548
335
316
528

58
43
43
44

97
42

2

90

165

101

140
106

3

101

88

34

68

25

84
131

72
96
36
3

4

97

47
45
11
77
36
49

42

2

77

88
55

50

2.8

15.0
2.6
3.5
17.0
3.5

5.1

9.4

16.2
13.2
13.9

800

800

68

14
77

22

6.8

88

8.3

11.3
13.8

8.9

4.5
17.1

3.1
16.5
2.2
9.7
4.7
11.0

11.8
17.1
19.1
5.0
10.2
3.6

700

700

1.8

17

88

15
64
53
30

55
11

3

36

573
38
3

2.9

800
392
92

11.7
19.2
18.1

29
81

3.8
18.0
8.8
3.9
16.9
13.8
800

4

2

40
17
16

30
118

—25—

Table 3. The g(O) function for a 10% increase in b; 5x30 problem.

0

g)

0.0

7515

.44166

7806

.74142

7947

.02750

7578

.52499

7822

.74714

7957

.09666

7607

.59000

7839

.78499

7987

.15428

7612

.64250

7849

.81285

8009

.16875

7633

.64285

7850

.84428

8049

.17125

7696

.65571

7891

.89124

8060

.20374

7725

.68500

7913

.93832

8079

.33625

7726

.70833

7931

.96666

8112

.36666

7777

.71750

7942

0

g(0)

8

g(0)

—26—

REFERENCES

-i..

V.J., "The Structure of Integer Programs under the Hermitian
Normal Form," Operations Research, Vol. 22 No.5 (Sept-Oct), 1974,

BOWMAN,

pp.

2

1067-1080.

GEOFFRION, A.M. and MARSTEN, R.E., "Integer Programming Algorithms: A

Framework and State—of-the-Art-Survey," Management Science,
Vol. 18 (1972), pp. 465—491.
"
A Hybrid Approach to Discrete Mathematical
3. MARSTEN, R.E. and MORIN, T.L.,
Programming," Sloan School of Management, MIT, Cambridge, Mass. July, 1975.

4. MORIN, T.L. and MARSTEN, R.E., "An Algorithm for Nonlinear Knapsack
Problems," Technical Report No. 95, Operations Research Center,
Massachusetts Institute of Technology, Cambridge, Mass., May, 1974.

5. MORIN, T.L. and MARSTEN, R.E., "Branch and Bound Strategies for
Dynamic Programming," WP75O-74, Sloan School of Management,
MIT, Cambridge, Mass., November, 1974.

6. NAUSS, R.M., "Parametric Integer PrograniTling," Ph.D Dissertation,
University of California, Los Angeles, January, 1975.

7. NOLTEMEIER, H., "Sensitivitalsanalyse bei disketen linèaren
Optimierungsporblemen," in M. Beckman and H.P. Kunzi (eds),
Lecture Notes in Operations Research and Mathematical Systems, #30,
Springer-Verlag, New York, 1970.

8. PIPER, C.J. and ZOLTNERS, A.A., "Implicit Enumeration Based Algorithms
for Postoptiniizing Zero-One Programs," Management Sciences Research
Report, No. 313, Graduate School of Industrial Administration, CarnegieMellon University, March, 1973.

9. ROODMAN, G.M., "Postoptimality Analysis in Zero—One Programming by
Implicit Enumeration," Naval Research Logistics Quarterly, Vol. 19,
1972, pp.435—447.

10. ROODMAN, G.M., "Postoptimality Analysis in Integer Programming by Implicit
Enumeration: The Mixed Integer Case," The Amos Tuck School of
Business Administration, Dartmouth College, October, 1973.
11. TOYODA, Y., "A Simplified Algorithm for Obtaining Approximate Solutions to
Zero—One Programming Problems," Management Science, Vol.21, 1975,
pp. 1417—1427.

