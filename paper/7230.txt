NBER WORKING PAPER SERIES

ACCOUNTING FOR HETEROGENEITY,
DIVERSITY AND GENERAL EQUILIBRIUM
IN EVALUATING SOCIAL PROGRAMS
James J. Heckman
Working Paper 7230
http://www.nber.org/papers/w7230

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
July 1999

This paper was prepared for an AEI conference, “The Role of Inequality in Tax Policy,” January 21-22, 1999
in Washington, D.C. I am grateful to Christopher Taber for help in conducting the tax simulations, and to
Jeffrey Smith for help in analyzing the job training data. This paper draws on joint work with Lance Lochner,
Christopher Taber, and Jeffrey Smith as noted in the text. I am grateful for comments received from Lars
Hansen, Kevin Hassett, Louis Kaplow, and Michael Rothschild. This research was supported by NSF-SBR93/21/048, NSF 97-09-873, and a grant from the Russell Sage Foundation. All opinions expressed are those
of the authors and not those of the National Bureau of Economic Research.

© 1999 by James J. Heckman. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to the source.

Accounting For Heterogeneity, Diversity and
General Equilibrium In Evaluating Social Programs
James J. Heckman
NBER Working Paper No. 7230
July 1999
JEL No. C31
ABSTRACT
This paper considers the problem of policy evaluation in a modern society with heterogeneous
agents and diverse groups with conflicting interests. Several different approaches to the policy evaluation
problem are compared including the approach adopted in modern welfare economics, the classical
representative agent approach adopted in macroecononomics and the microeconomic treatment effect
approach. A new approach to the policy evaluation problem is developed and applied that combines and
extends the best features of these earlier approaches.Evidence on the importance of heterogeneity is
presented. Using an empirically based dynamic general equilibrium model of skill formation with
heterogeneous agents, the benefits of the more comprehensive approach to policy evaluation are examined
in the context of examining the impact of tax reform on skill formation and the political economy aspects
of such reform. A parallel analysis of tution policy is presented.

James J. Heckman
Dept. of Economics
University of Chicago
1126 E 59th Street
Chicago, IL 60637
and NBER
jjh@uchicago.edu

Introduction
Coercive redistribution and diversity in the interests of its constituent groups are essential
features of the modern welfare state. Disagreement over perceived consequences of social policy

creates the demand for publically justified "objective" evaluations. If there were no coercion,
redistribution and intervention would be voluntary activities and there would be no need for public

justification of voluntary trades. The demand for publically documented objective evaluations of
social programs arises in large part from a demand for information by rival parties in the democratic

welfare state.' Since different outcomes are of interest to rival parties, a variety of criteria should
be used when considering the full consequences of proposed policies. This paper examines these

criteria and considers the information required to implement them.

Given that heterogeneity and diversity are central to the modern state, it is surprising that
the methods most commonly used for evaluating its policies do not recognize these features. The
textbook econometric policy evaluation model, due to Tinbergen (1956), Theil (1961), and Lucas
(1987), constructs a social welfare function for a representative agent to evaluate the consequences

of alternative social policies. In this approach to economic policy evaluation, the general equilibrium effects and efficiency aspects of a policy are its important features. Heterogeneity across
persons in preferences and policy outcomes are treated as second order problems and estimates of
'Indeed, as discussed by Porter (1995), the very definition of "objective" standards is often the topic of intense
political debate. See also the discussion in Young (1994).

1

policy effects are based on macro time series per capita aggregates.

Standard cost-benefit analysis ignores both distributional and general-equilibrim-n aspects of

a policy and enmnerates aggregate costs and Lenefits at fixed prices. Harberger's paraphrase of

Gertrude Stein that a dollar is a dollar is a dollar" succinctly summarizes the essential features
of his approach (Harberger, 1971). Attempts to incorporate distributional "welfare weights" into

cost-benefit analysis (Harberger, 1978) have an ad hoc and unsystematic character about them.
In practice, these analyses usually reflect the personal preferences of the individuals conducting
particular evaluations.
Access to microdata facilitates the estimation of the distributional consequences of alternative
policies. Yet surprisingly, the empirical micro literature focuses almost exclusively on estimating

mean impacts for specific demographic groups and estimates heterogeneity in program impacts
only across demographic groups. It neglects heterogeneity in responses within narrowly defined
demographic categories - variation shown to be empirically important both in the literature and

in the empirical analysis I present below.

Microdata are no panacea, however, and they must be used in conjunction with aggregate
time-series data to estimate the full general-equilibrium consequences of policies. Even abstracting

from general-equilibrium considerations, the estimates produced from social experiments and the

microeconometric "treatment effect" literature are not those required to conduct a proper costbenefit analysis, anless agents with identical observed characteristics respond identically to the

2

policy being evaluated; or if they do not, their participation in the program being evaluated must
not depend on differences across agents in gains from the program. The estimates produced from

social experiments and the treatment effect literature improve on aggregate time series methods

by incorporating heterogeneity in responses to the policies in terms of observed characteristics
but ignore heterogeneity in unobserved characteristics, an essential feature of the microdata from
program evaluations.

Unlike the macro-general-equilibrium literature, the literature on modern welfare economics

(see. e.g., Sen, 1973) recognizes the diversity of outcomes produced under alternative policies
but adopts a rigid posture about how the alternatives should be evaluated, invoking some form
of "Veil of Ignorance" assumption as the "ethically correct" point of view. Initial positions are

treated as arbitrary and redistribution is assumed to be costless. The political feasibility of a
criterion is treated as a subsidiary empirical detail that should not intrude upon an "ethically
correct" or "moral" analysis. In this strand of the literature, it is not uncommon to have the work

of "contemporary philosophers" invoked as a source of final authority (see, e.g. Roemer, 1996),
although the philosophers cited never consider the incentive effects of their "moral" positions and

ignore the political feasibility of their criteria in a modern democratic welfare state where people
vote on positions in partial knowledge of the consequences of policies on their personal outcomes.

As noted by Jeremy Bentham (1824), appeal to authority is the lowest form of argument. Thus

the appeal to philosophical authority by many economists on matters of "correct distributional
3

criteria" is both surprising and disappointing.

In this essay, I question this criterion. Its anonymity postulates do not describe actual social
decision making in which individuals evaluate oliies by asking whether they (or groups they are

concerned about) are better off compared to a benchmark position.2 Agents know, or forecast,
their positions in the distributions of outcomes under alternative policies and base their evaluations

of the policies on them. From an initial base policy state, persons can at least partially predict

their positions in the outcome distributions of alternative policy states. I improve on modern
welfare theory by incorporating the evaluation of position-dependent outcomes into it, linking the

outcomes under one policy regime to those in another. Such position-dependent outcomes are of

interest to the individuals affected by the policies, to their representatives and to other parties in
the democratic process.
In order to make my discussion specific and useful, I consider the evaluation of human capital

policies for schooling and job training. Human capital is the largest form of investment in a
modern economy. Human capital involves choices at the extensive margin (schooling) and at
the intensive margin (hours of job training). Differences in ability are documented to affect the
outcomes of human capital decisions in important ways. The representative-agent macro-general-

equilibrium paradigm is poorly suited to accommodate these features; the cost-benefit approach

ignores the distributional consequences of alternative human capital policies; and the approach
2Recall Ronald Reagan's devastating rhetorical question in the 1980 campaign: "Are you better off today than
you were four years ago?".

4

taken in modern welfare economics denies that it is interesting to determine how policies affect
movements of individuals across the outcome distributions of alternative policy states.

Using both micro-and macrodata, I establish the empirical importance of heterogeneity in the

outcomes of human capital policies even conditioning on detailed individual and group charac-

teristics. Using data from a social experiment evaluating a prototypical job training program, I
compare evaluations under the different criteria. Theoretically important distinctions turn out to
be empirically important as well and produce different descriptions of the same policy.
I present an approach to policy evaluation that unites the macro-general-equilibrium approach

with the approach taken in modern welfare economics. Using an empirically based generalequilibrium model that combines micro-and macrodata, I examine the distributional consequences

of various tax and tuition policies. I present evidence on the misleading nature of the micro evidence produced from social experiments and the microeconomic treatment effect literature, and

the incomplete character of the representative agent calculations that ignore distributional considerations entirely.
The plan of this paper is as follows. I first present alternative criteria that have been proposed to

evaluate social programs and consider their limitations. I propose a position-dependent criterion

to evaluate policies. I then consider the information requirements of the various criteria. Not
surprisingly, the more interesting criteria are also more demanding in their requirements. I consider

the consequences of heterogeneity in responses to policies by agents for the success of various
5

social experiment with what is required to perform a cost-benefit analysis. There is a surprising
disconnect between the two approaches when agents respond differently to the same program.
I go on to consider the evidence on heterogeneity in program impacts across persons, using data

from a protypical job training program. I use a variety of criteria to evaluate the same program, including revealed preference and self-assessment data and second-order stochastic-dominance com-

parisons as suggested by modern welfare economics. There is a surprisingly wide discrepancy
among these alternative evaluation measures.
I then present an empirically based dynamic overlapping-generations general-equilibrium model

fit on both micro-and macrodata that extends the pioneering analysis of Auerbach and Kotlikoff
(1987) on intergenerational accounting to include human capital formation and heterogeneity in

human ability. These extensions produce a framework that accounts for rising wage inequality
and that can be used to evaluate alternative tax and tuition policies, including their distributional

impacts. The estimates produced from the general-equilibrium framework are contrasted with

those obtained from the widely used social experiment and treatment effect approaches. The
contrasts are found to be substantial, casting doubt on the value of conventional methods that are

6

used to evaluate human capital policies.

I. Alternative Criteria fo Eyaluating Social Programs
In this section, I consider alternative criteria that have been set forth in the literature to
examine the desireability of alternative policies. Define the outcome for person i in the presence

of policy j to be Y and let the personal preferences of person i for outcome vector Y be denoted
U1(Y). A policy effects a redistribution from taxpayers to beneficiaries, and Y represents the flow

of resources to i under policy j. Persons can be both beneficiaries and tax payers. All policies
considered in this paper are assumed to be feasible.

In the simplest case, Y32 is net income after tax and transfers, but it may also be a vector of
incomes and benefits, including provisions of in-kind services. Many criteria have been proposed

to evaluate policies. Let "0" denote the no-policy state and initially abstract from uncertainty.
The standard model of welfare economics postniates a social welfare function W that is defined
over the utilities of the N members of society:

(I-i)

47(j) = l47(U1(Y1), ..., UN(Y3N)).

In the standard macroeconomic policy evaluation problem (I-i) is collapsed further to consider the
welfare of a single person, the representative agent. Policy choice based on a social welfare function

picks that policy j with the highest value for W(j). A leading special case is the Benthamite social
welfare function:

7

(1-2)

B(j) =

Criteria (I-i) and (1-2) implictly assume that social preferences are defined in terms of the private

preferences of citizens as expressed in terms of their own consumption. (This principle is called
welfarism. See Sen, 1979.) They could be extended to allow for interdependence across persons

so that the utility of person i under policy j is U(Y31, ..., Yv) for all i.
Conventional cost-benefit analysis assumes that YF is scalar income and orders policies by their

contribution to aggregate income:
(1-3)

CB(j)=.

Analysts who adopt criterion (1-3) implicitly assume either that outputs can be costlessly redis-

tributed among persons via a social welfare function, or else accept GNP as their measure of value
for a policy.

While these criteria are traditional, they are not universally accepted and do not answer all of

the interesting questions of political economy or "social justice" that arise in the political arena

of the welfare state. In a democratic society, politicians and advocacy groups are interested in
knowing the proportion of people who benefit from policy j as compared to policy k:
(1-4)

1(U()) > U(Y)),

PB(j jj, k) =

where "1" is the indicator function: 1(A) =

1

if A is true; 1(A) =

0

otherwise. In the median

voter model, a necessary condition for j to be preferred to k is that PB(j j, k ) 1/2. Other
persons concerned about "social justice" are concerned about the plight of the poor as measured
8

in some base state k. For them, the gain from policy j

is

measured in terms of the income or

utility gains of the poor. In this case, interest centers on the gains to specific types of persons,

e.g.. the gains to persons with outcomes in thebae state k less than y: jkz = — Yki IYkz
or their distribution
(1-5)

F(zkIYk =Yk,Yk

or the utility equivalents of these variables. Within a targeted subpopulation, there is sometimes

interest in knowing the proportion of people who gain relative to specified values of the base state
k:
(1-6)

Pr (jk > OYk y).

In addition, measures (1-2) and (1-3) are often defined only for a target population and not the
full taxpayer population.

The existence of merit goods like education or health implies that specific components of the

vector 'j are of interest to certain groups. Many policies are paternalistic in nature and implicitly
assume that people make the wrong choices. "Social" values are placed on specific outcomes, often

stated in terms of thresholds. Thus one group may care about another group in terms of whether
it satisfies an absolute threshold requirement:

YY foriES,
where S is a target set toward which the policy is directed, or in terms of a relative requirement

compared to a base state k:
9

for iS.
Uncertainty introduces important additional qonsiderations. Participants in society typically

do not know the consequences of each policy for each person, or for themselves, and do not
know possible states not yet experienced. A fundamental limitation in applying the criteria just
exposited is that, ex ante, these consequences are not known and, ex post, one may not observe
all potential outcomes for all persons. If some potential states are not experienced, the best that
agents can do is to guess about them. Even if, ex post, agents know their outcome in a benchmark

state, they may not know it ex ante, and they may always be uncertain about what they would
have experienced in an alternative state.

In the literature on welfare economics and social choice, one form of decision-making under

uncertainty plays a central role. The "Veil of Ignorance" of Vickrey (1945, 1961) and Harsanyi

(1955. 1975) postulates that decision makers are completely uncertain about their positions in
the distribution of outcomes under each policy, or shotild act as if they are completely uncertain,

and they should use expected utility criteria (Vickrey-Harsanyi) or a maximin strategy (Rawls,
1971) to evaluate welfare under alternative policies. This form of ignorance is sometimes justified

as capturing how an "objectively detached" observer should evaluate alternative policies even

if actual participants in the political process use other criteria. (Roemer. 1996). An approach
based on the veil of ignorance is widely used in practical work in evaluating different income

distributions (see Sen, 1973). It is an empirically tractable approach because it only requires
10

information about the marginal distributions of outcomes produced under different policies. The
empirical literature on evaluating income inequality uses this criterion to compare the consequences

of growing wage inequality in the past two decades (See, e.g. Karoly, 1992). Individual outcomes
under alternative policies are either assumed to be independent or else any dependence is assumed

to be irrelevant for assessing alternative policies. This analysis is intrinsically static, whereas
actual policy comparisons are made in real time: a current base state is compared to a future
potential state.
An empirically more accurate description of social decision making in a democratic welfare

state recognizes that persons act in their own self-interest, or in the interest of certain other
groups (e.g. the poor, the less able) and have at least partial knowledge about how they (or the
groups they are interested in) will fare under different policies, and act on those perceptions, but

only imperfectly anticipate their outcomes under different policy regimes. Even if outcomes in
alternative policy regimes are completely unknown (and hence represent a random draw from the
outcome distribution), the outcomes under the current policy are known. The outcomes in different

regimes may be dependent so that persons who benefit under one policy may also benefit under

another. For a variety of actual social choice mechanisms, both the initial and final positions of
each agent are relevant for evaluation of social policy.3 Politicians, policy makers and participants

in the welfare state are more likely to be interested in how specific policies affect the fortunes
This theme is developed in Heckman, Smith and Clements (1997), Heckman and Smith (1998). Coate (1998)
and Besley and Coate (1998).
11

of specific groups measured from a benchmark state than in some abstract measure of "social

justice" .
However, agents may not possess perfect foresight so that the simple voting criterion may not

accurately predict choices and requires modification. Let I denote the information set available

to agent i, he (she) evaluates policy j against k using that information. Let F(y3, Yk IL) be the
distribution of outcomes (Y3,Yk) as perceived by agent i. Under an expected utility criterion,

person i prefers policy j over k if

E(U() I') > E(U1(Yk) I).
Letting 9 parameterize heterogeneity in preferences, so U(Y) = U(Y3; 0), and using integrals to
simplify the expressions, the proportion of people who prefer j is
(1-7)

PB (jjj, k) = f 1(E (U (; 0)1) > E (U (Yk; 0) II))dF (9,I),

where F(9, I) is the joint distribution of 9 and I in the population whose preferences over outcomes

are being studied.5 The voting criterion previously discussed is the special case where I, =
(Y,, Yk2), so there is no uncertainty about Y and Yk, and
(1-8)

PB(j!j,k)=fl(U(y2;9) >U(yk;O))dF(O,y3,yk).

4j abstract from the problem that politicians are more likely to be interested in voter perceptions of benefits in
different policy states than in actual (post_electoral) realizations.
Sj do not claim that persons would necessarily vote "honestly", although in a binary choice setting they do
and there is no scope for strategic manipulation of votes. See Moulin (1983). PB is simply a measure of relative
satisfaction and need not describe a voting outcome where other factors come into play.

12

Expression (1-8) is an integral version of (1-4) when outcomes are perfectly predictable and when
preference heterogeneity can be indexed by vector 0.

Adding uncertainty to the analysis makes it fruitful to distinguish between ex ante and ex
post evaluations. Ex post, part of the uncertainty about policy outcomes is resolved although
individuals do not, in general, have full information about what their potential outcomes would
have been in policy regimes they have not experienced and may have only incomplete information
about the policy they have experienced (e.g. the policy may have long run consequences extending

after the point of evaluation). It is useful to index the information set I by t, (Ia), to recognize

that information about the outcomes of policies may accrue over time. Ex ante and ex post
assessments of a voluntary program need not agree. Ex post assessments of a program through
surveys administered to persons who have completed it (see Katz, Gutek, Kahn and Barton, 1975)

may disagree with ex ante assessments of the program. Both may reflect honest valuations of the

program but they are reported when agents have different information about it or have their
preferences altered by participating in the program. Before participating in a program. persons
may be uncertain of the consequences of participation in it. A person who has completed program

j may know Y, but can only guess at the alternative outcome Yk which they have not experienced.
In this case, ex post "satisfaction" for agent i is synonymous with the following inequality:

U(Y) > E(U(Yk) 'it),

(1—9)

where

t

is the post-program period in which the evaluation is made. In addition, survey ques-

13

tionnaries about clienf' satisfaction with a program may capture subjective elements of program
experience not captured by "objective" measures of outcomes that usually exclude psychic costs
and benefits.

II. The Data Needed to Evaluate the Welfare State
To implement criteria (I-i) and (1-2), it is necessary to know the distribution of outcomes across

the entire population within each policy state and to know the utility functions of individuals.
In the case where Y refers to scalar income, criterion (1-3) only requires GNP (the sum of the
program j net output). If interest centers solely on the distributions of outcomes of direct program
participants, the measures can be defined solely for populations with D3 = 1. Criteria (1-4), (1-5),
(1-6) and (1-8) require knowledge of outcomes and preferences across policy states. Criterion (1-7)

requires knowledge of the joint distribution of information and preferences across persons. Tables

1A and lB summarize the criteria and the data needed to implement them. The cost-benefit
criterion is the least demanding; the voting criterion is the most demanding in that it requires
information about the joint distributions of outcomes across alternative policy states.

Three distinct types of information are required to implement these criteria: (a) private preferences, including preferences toward the consumption and well being of others; (b) social preferences, as exemplified by social welfare function (I-i) and (c) distributions of outcomes in alternative

states, and for some criteria, such as the voting criterion, joint distributions of outcomes across
policy states. The reasons for the popularity of cost-benefit analysis are evident from these tables.
14

An important practical problem rarely raised in the literature on "social justice" is that many
proposed criteria are not operational with current levels of knowledge.

There is a vast literature on the estimation of individual preferences defined over goods and

leisure although the literature on the determination of altruistic preferences is much smaller.
Within the framework of the microeconomic treatment effect literature, the decisions of the agents

to self select into a program reveal their preferences for it. Much of the standard literature
on estimating consumer preferences abstracts from heterogeneity. However, a growing body of
evidence summarized in Browning, Hansen and Beckman (1999) demonstrates that heterogeneity

in marginal rates of substitution across goods at a point in time, and for the same good over time,
is substantial. This heterogeneity is large across demographic and income groups and is large even

within narrowly defined demographic categories.6 There are surprisingly few estimates of social

welfare function (I-i) (Maital, 1973; Saez, 1998; and Gabaix, 1998 are exceptions), despite the
widespread use of the social welfare function in public economics. The paucity of estimates of it

suggests that the social welfare function is an empirically empty concept. It is a misleading, but
traditional, intellectual crutch without operational content.7
Responses to income shocks, wages and the like vary widely across consumers. The evidence
GSee e.g., Heckman, 1974a.

7Saez and Gabaix assume that tax schedules are set optimally using a social welfare function and derive the
local curvature of the social welfare function that generates policy outcomes. They do not test that proposition.
Ahined and Stern (1984) test the proposition that taxes and subsidies in India are generated by optimizing a social
welfare function.

15

speaks strongly against the representative agent model or the various simplificat ions used to justify

RBC models. The focus of the empirical analysis of this paper is on estimating the distributions
of outcomes across policy states as a first step 'toward empirically implementing the full criteria.

This more modest objective can fit into the framework of Section I by assuming that utilities are

linear in their arguments and identical across persons. Even this more modest goal is a major
challenge, as we shall see.

The policy evaluation problem in its most general form can be written as estimating a vector of

outcomes, for each person in each policy state. Consider policies j and k. The potential outcomes
are
(IT-i)

(yr, Y)

I.

1

Macroeconomic approaches focus exclusively on mean outcomes or some other low dimensional

representation of the aggregate (e.g. geometric means). There are two important cases of this
macro problem: (a) the case where j and k have been experienced in the past and (b) where one

of j or k, or possibly both, have never been observed. The first case requires that we "adjust"
the data on j and k to account for changes in the conditioning variables between the observation
period and the period for which the policy is proposed to be implemented. Such adjustments are
sometimes controversial. If the environment is stationary, no adjustment is required. With panel

data on persons, one could build up the joint distribution of policy outcomes by observing the
same people under different regimes.
16

The classical macroeconomic general-equilibrium policy-evaluation problem considered byKnight

(1921), Tinbergen (1956), Marschak (1953), Theil (1961), Lucas and Sargent (1981) and Lucas
(1987) forecasts and evaluates the impacts of policies that have never been implemented. To do
this requires knowledge of policy-invariant structural parameters and a basis for making proposed
new policies comparable to old ones.8

An entire literature on structural estimation in econometrics has emerged in an attempt to
solve this problem. By focusing on the "representative consumer", this literature simplifies a hard

problem by ignoring the issue of individual heterogeneity in outcomes within each regime.9 If
outcomes were indeed identical across persons, or if the representative consumer were a "reasonably good" representation, from knowledge of aggregate means, one could answer all of the policy

evaluation questions in Tables 1A and lB provided that preferences were known. This is a consequence of the implicit assumption of the representative consumer model that the joint distribution
of (11-1) is degenerate.

The common form of the microeconomic evaluation problem is apparently more tractable. It

considers evaluation of a program in which participation is voluntary although it may not have
been intended to be so. Accordingly, it is not well suited to evaluating programs with universal
A quotation from Knight is apt "The existence of a problem in knowledge depends on the future being different
from the past, while the possibility of a solution of the problem depends on the future being like the past". (Knight.
1921, p. 313.)

9As summarized in Browning, Hansen and Heckman (1999), there is an emerging literature in macroeconomics that recognizes the evidence of microheterogeneity and its consequences for model construction and policy
evaluation.

17

coverage such as a social security program.

Persons are offered a service through a program and may select into the program to receive it.

A distinction is made between direct participation in the program and indirect participation. The

latter occurs when people pay taxes or suffer the market consequences of changed supplies as a
consequence of the program. Eligibility for the program may be restricted to subsets of persons in

the larger society. Many "mandatory" programs allow that persons may attrite from them or fail

to comply with program requirements. Participation in the program is thus equated with direct
receipt of the service, and payments of taxes and general-equilibrium effects of the program are
typically ignored.1°

In this formulation of the evaluation problem, the no-treatment outcome distribution for a
given program is used to approximate the distribution of outcomes in the no-program state. That

is, the outcomes of the "untreated" within the framework of an existing program are used to
approximate outcome distributions when there is no program. This approximation rests on two

distinct arguments: (a) that general-equilibrium effects inclusive of taxes and spillover effects

on factor and output markets can be ignored; and (b) that the problem of selection bias that
arises from using self-selected samples of participants and nonparticipants to estimate population
"The contrast between micro and macro analysis is overdrawn. Baumol and Quandt (1966), Lancaster (1971)
and Domencich and McFadden (1975) are micro examples of attempts to solve what we have called a macro
problem. Those authors consider the problem of forecasting the demand for a new good which has never previously
been purchased.

18

distributions can be ignored or surmounted.1' The treatment effect approach also converts the
evaluation problem into a comparison between an existing program j and a benchmark no-program

st.ate rather than into a comparison between any two hypothetical states j and k.'2

More precisely, let j be the policy regime to be evaluated. Eligible person i in regime j has

two potential outcomes: (Y, Y), where the superscripts denote non-direct participation ("0")
and direct participation ("1"). Ineligible persons have only one option:

These outcomes

are defined at the equilibrium level of participation under program j. All feedback effects are
incorporated in the definitions of the potential outcomes.

Let subscript "0" denote a policy regime without the program. Let D3 =

1

if person i

participates in program j. A crucial identifying assumption that is implicitly invoked in the
microeconomic evaluation literature is

(A-i)
i.e. that the no program outcome for i is the same as the no treatment outcome.

Letting F(a I

F(y3° D =

0,

b)

X) =

denote the conditional distribution of a given b, the assumption implies that
F(yo ID = 0, X) for y2° =

Yo

given conditioning variables X. The outcome

of nonparticipants in policy regime j is the same in the no policy state "0" or in the state where
As we note below, evidence from self-selection decisions can be used to evaluate private preferences for the
program so that in principle we can use the "problem" of self selection as a source of information about private
valuations. See, e.g. Heckman, (1974a,b), and Heckman and Honoré (1990) where this is done.
121n the case of multiple observed treatments, comparisons can be made among observed outcomes as well as
against a benchmark no program state.

19

policy j is operative. This assumption is consistent with a program that has "negligible" general
equilibrium effects and where the same structure of tax revenue collection is used in regimes j and

From data on individual program participation decisions, it is possible to infer the implicit
valuations of the program made by persons eligible for it. These evaluations constitute all of the

data needed for a libertarian program evaluation, but more than these are required to evaluate
programs in the interventionist welfare state. For certain decision rules, it is possible to use the
data from self-selected samples to bound or estimate the joint distributions required to implement
criteria (1-4) or (1-7), as I demonstrate below. I now consider how access to microdata and social
experiments enables one to answer the evaluation questions posed in Section I.

III. What Can Be Learned From Micro Data and Social Experiments?
This section considers the information produced from social experiments and from ordinary

observational data. Even abstracting from the problem that the analysis of these data typically
ignores general-equilibrium effects, the information produced by them is surprisingly limited unless

a strong form of homogeneity is invoked. This homogeneity assumption is implicitly invoked in
most micro studies so there is a closer kinship between micro and representative agent approaches

than might be first thought. The micro studies condition more finely. Both macro and micro
studies ignore well-documented sources of heterogeneity among agents in responses to programs.

20

Consider the analysis of program j and assume that assumption (A-i) is invoked. Within the
framework of the treatment effect" literature, we observe one of the following pair

(}O, }')
for person i. To simplify the notation, I drop the j subscript in this section. At a point in time.

we caimot observe a person simultaneously in the treated and untreated state. In general. we

cannot form the gain of moving from "0" to 1" and L

—

for anyone. The evaluation

problem is reformulated to the population level. The goal becomes to estimate some features of

the distribution of L. To clarify this approach let D = 1 if person i is a direct participant, and

D, = 0 if person i is not a direct participant. We observe Y,

= D1Y' + (1— DZ)Y
for each person.

The potential outcomes for person i can be written as
(111-i)
(111-2)

=

u + 1i

where E(Eo) = E(1) =

0.

The means can be written in terms of observed characteristics X

(1i0(X); 1i1(X)) but for simplicity of notation we suppress this dependence. Thus we can may
write
(111-3)

= /.L0 +

(/

—

+ E, — o)D, + Oj
21

Most of the evaluation literature formulates the parameters of interest as means. Two means
receive the most attention. The first is

E(Y1 - Y°)
the average treatment effect ("ATE") that records the average gain of moving a randomly selected

person from "0" to "1". A second mean is

E(Y1-Y°ID=1)
the effect of treatment on the treated (TT). The two means are the same under one of the following
conditions:
(C-i): E11 =

so

=

(No response heterogeneity given X)

or
(C-2): E(E1, — E0 I D

= 1) = 0

(Agents do not enter the program based on gains from it).
Under (C-i), outcome responses are identical among persons with given observed characteristics

X. Under (C-2), outcomes may differ among persons with identical X characteristics but ex
ante there is no perceived heterogeneity. (Persons place themselves at the mean of the response
distribution for "0" and "1" in making their participation decisions.)

22

To understand these distinctions, it is useful to consider three regression models. Write the
traditional textbook model as:
(A)

+,

Y, = +

E(U) = 0.

In this framework ci is a common coefficient for each i. It embodies assumption (C-i) where

= 02 and a

= = — i-•

There is no idiosyncratic response to treatment among persons

with the same observed characteristics X. This is the textbook model of econometric policy
evaluation and the textbook model of econometrics. Selection or simultaneity bias is said to arise
if E(U, I D, = 1)

0.

In contrast, consider a second model:

E(U) = 0 where E(a,1) = jt1 i.'o but V =

(B) Y = ao+a1D+U,
satisfies E(V I D, =

1)

= 0 or equivalently E(E11 —

I D1

c —E(ai) =

E11

= 1) = 0.

In this framework, responses are different across persons (c has an i subscript) but conditional

on X, persons do not participate in the program based on these differential responses.'3 Again

selection bias is said to arise if E(U, D = 1)

0.

If persons participate in the program based on these differential responses, we obtain

(C) 'c =

+ o1D1 + U,

E(U) =0

1Another way to say this is that
Pr(D1 = 1 Z, V) = Pr(D1 = 1 Zr). This is a "noncausality" condition.

23

E(U, D = 1) OE(E1 60i D, =
Again, selection bias for E(Y1, —

ID=

1).
1)

is said to arise if E(U D = 1)

Under models A and B, the parameters E(Y1 — Y0) and E(Y1 — Yo

D=

0.
1),

are the same.

Under Model C, they are not. These distinctions, first introduced in Heckman and Robb (1985,
1986) and Heckman (1992), have important consequences for what can be learned from micro
evaluations.

Model (A) is the dominant paradigm in the applied literature. If it is true, and if assumption
(A-i) is also true, we can go from a regression estimate of equation (A) to answer all of the policy

questions posed in Section I comparing the policy being evaluated with a benchmark no policy

state. The distribution of gains, , across and within policy regimes is degenerate. Everyone either
benefits or loses from the policy. In this case the inferences obtained from the representative agent
paradigm, the inferences obtained from cost-benefit analysis, and the inferences obtained from the

treatment effect literature are the same.

Model (B) captures heterogeneity but assumes that persons do not act on it. Now the representative agent paradigm should be adjusted to account for variation in individual responses to
the program; the cost-benefit approach is robust to this form of heterogeneity because it consid-

ers only mean outcomes. The treatment effect approach requires estimation of the variances of
outcomes,'4 If outcomes are heterogeneous in the sense of model (B), conventional instrumental
'4See e.g. Heckman, Smith and Clements, 1997.

24

variable and matching methods can be used to secure estimates of mean parameters. As long as
means are the focus of attention, estimation of model (B) raises only well-known and easily solved

heteroscedasticity problems. However, apart from the study by Heckman, Clements and Smith
(1997). there are few studies that estimate the distributions of program impacts.
Model (C) captures a fundamental form of heterogeneity. Agents know more than the observing

economist and they act on this information in deciding whether or not to participate in a program.
E(Y1 — Y0)

E(Y1 — Y0

D=

1).

Estimating the full parameters of the outcome distributions

and their correlations over states is a frontier topic in econometrics with recent developments
surveyed in Heckman (1999). In this case standard instrumental variable methods break down

(see Heckman, 1997 or Heckman and Vytlacil, 1998). Heckman, Smith and Clements (1997)

and Heckman and Smith (1998) present estimates of outcome distributions under Model (C).
Heckinan, Ichimura, Smith and Todd (1998) present evidence that Model (C) describes the data

for the prototypical training program discussed in Section V below. While most of the thinking

about program evaluation is in terms of Model (A) or more recently, in terms of Model (B),
considerable evidence supports Model (C) for many programs.

As noted by Heckman (1992), the enthusiasm for social experiments in the policy evaluation
community is premised on the implicit acceptance of Model (A). Knowing the mean impact c is
enough to answer all of the policy evaluation questions posed in Section I. The joint distribution

of (IT-i) is degenerate when k is the benchmark n&-program state. Even if randomization alters

25

the composition of program participants (i. e. there is "randomization bias"), for any observed X
in the experiment we can obtain c1.
If Model (C) characterizes the data, all we can recover from social experiments administered to

people who apply and are accepted into the program (the common point in the enrollment process

where randomization is administered) are

F(y'ID=1) and F(y°D=1).
We cannot recover the joint distribution F(y',

I

D=

1)

either for persons who seek to participate

in the program or for the general population. Below, we discuss what can be learned in this case.
First, however, we consider what can be learned from participation decisions under Model (C).
Information From Revealed Preference

If agents act on the idiosyncratic gain from the program, so model (C) is the appropriate one,

it is possible to use this information to infer the implicit valuations they place on the gains from
the program being evaluated. If they do not participate on the basis of the gain, then clearly there
is no information on the gain from participation decisions. Participation includes voluntary entry

into a program or attrition from it.'5
'Heckman (1974a,b) demonstrates how access to censored samples on hours of work, wages for workers, and
employment choices identifies the joint distribution of the value of nonmarket time and potential market wages
under a normality assumption. Heckman and Honoré (1990) consider nonparametric versions of this model without
labor supply.

26

The prototypical framework is the Roy (1951) model. In that setup,

D = 1(Y' Y°),

(111-4)

so participation depends only on the net gain from the program:
tions (111-1) and (111-2), we obtain Pr(D =
—(ji1(X)

—

1

X) =

Pr(Y1

—

Y°

=

Y'—Y°. Using equa-

> DIX) =

Pr(E,

—

i0(X))). Under conditions specified in Heckman and Honoré (1990), the joint distri-

bution F(y°, y', D) can be identified nonparametrically.'6 Thus we can form all of the evaluation

parameters presented in Tables 1A and lB if the Roy model describes the data.
The crucial feature of the Roy model is that the decision to participate in the program is made
solely in terms of potential outcomes. No new unobservable variables enter the model that do not

appear in the outcome equations.'7 In this case, information about who participates also informs

us about the distribution of the value of the program to participants F(y1 — y° IY' > Y°, X).
Thus, we acquire the distribution of implicit values of the program for participants, which is all
that is required in a libertarian evaluation of the program. However, in the general case evaluation

of the welfare state requires information about "objective" outcomes and their distributions that
t6Heckman and Honore (1990) demonstrate that if X is independent of(Ei,Eo), Var(Ei) < :- and Var(Eo) < c'c.
and (Ei. EU) are normal, the full model F(y°, y', D IX) is identified even if we only observe Y° or Y1 for any person
and there are no regressors and no exclusion restrictions. If instead of assuming normality, it is assumed that the
supports of (X) and 1i0(X) overlap or contain the supports of El and EU, the full model (i (X), (X)) and the
joint distribution of El. EU are nonparametrically identified up to location normalizations. Precise conditions are
given in Theorem A-i in Appendix A of Heckman and Smith. 1998.
'7V,T could augment decision rule (111-4) to be D = 1(Y1 —
— k(Z) 0). Provided that we measure Z
and condition on it, and provided that (U1 — (Jo) J.L(X. Z), the model remains nonparametrically identified. The
crucial property of the identification result is that no new unobservable enters the model through the participation
equation. However, if we add Z, subjective valuations of gain (Y1 — Y° — k(Z)) no longer equal 'objective" measures
(yl — Y°).

27

are needed to make the interpersonal comparisons that are an essential feature of the welfare state.

Only in the Roy model do the "objective" and "subjective" evaluations coincide.18

Heckman and Smith (1998) extend the Roy model to allow for uncertainty in the outcomes

as perceived by agents. They show that even when Y° and Y1 are independent or even negatively correlated iii the population, purposive decision making produces positive dependence in
the population.
Observe that under the assumptions that make it valid, estimation of a Roy model on ordinary
nonexperimental data produced by the self-selection decisions of participants is more informative

than analysis of experimental data on persons who attempt to enter the program. As noted
by Heckman (1992) and Moffitt (1992), social experiments as typically conducted on persons who

apply and are initially accepted into a program do not provide information about the determinants

of program participation. Nonexperimental data can be used to infer the preferences of agents
who select into the program.

Appendix A presents a discussion of the relationship between the parameters of cost-benefit
analysis and the Roy model. Many of the parameters estimated in the micro evaluation literature
are not the ones needed to conduct a rigorous cost-benefit analysis. For this reason, this literature
'If the Roy model is extended to allow for variables other than Y°, Y1 (and the observed conditioning variables)

to determine participation, then the decision rule is changed to D 1(IN >0) where IN =ij(Y1,Y°, V.X), and
it is not possible to identify the joint distribution F(uo. u1) even if the unobservables V, U0 and U1 are independent
of X. Heckman (1990a) demonstrates that in this more general case, provided that some structure is placed on i
we

can nonparametrically identify F(y°. D X) and F(y'. D X) but not the full joint distribution F(y°. y D X).

A generalization of his proof is given in Theorem A-2 of Appendix A of Heckman and Smith, 1998.

28

is not as informative about the economic aspects of program evaluation as one might hope.
The Problem of Recovering Joint Distributions

In the general case where textbook model (A) does not apply, and responses to programs are
heterogeneous, we encounter a difficult evaluation problem. Unless the Roy model is invoked, we

cannot identify the joint distribution of (Y°, Y'). At best we can extract the marginal distributions
of Y° and Y', even from ideal social experiments. This leaves considerable uncertainty about our

ability to implement the voting criterion and many other position-dependent majority voting
criteria discussed in Section I.
To see this problem, suppose that we have data from an ideal social experiment so that standard

self-selection problems can be ignored. Suppose that there are N treated and N untreated persons

and that the outcomes are continuously distributed. Rank the individuals in each treatment
category in the order of their outcome values from the highest to the lowest. Define

as the 1th

highest-ranked person in the j distribution. Ignoring ties, we obtain two data distributions the
gain:

Treatment Outcome:F(y'D = 1)

Non-Treatment Outcome:F(y°ID

Y()

Y)

N)

N)
29

1)

We know the marginal data distributions F(y'ID =

1)

and F(y°D =

1),

but we do not know

where person i in the treatment distribution would appear in the non-treatment distribution.'9

Corresponding to the ranking of the treatment outcome distribution, there are N! possible
patterns of outcomes in the associated non-treatment outcome distribution. By considering all
possible permutations, one can form a collection of possible impact distributions, i.e., alternative

distributions of the gain:

/=:" —He
where fl is a particuJar N x N permutation matrix of Y° in the set of all N! permutations asso-

ciating the ranks in the Y' distribution with the ranks in the Y° distribution; and , Y1 and Y°
are N x 1 vectors of impacts, treated and untreated outcomes. By considering all possible permu-

tations, one can obtain all possible sortings of treatment,

and non-treatment, Y°, outcomes

using realized values from one distribution as counterfactuals for the other.

Model (A) assumes a constant treatment effect for all persons conditional on characteristics.

I

This model admits only one permutation: H = for each X. The best in one distribution is the
best in the other distribution. In the common effect case, Y' and Y° differ by a constant for each

person. A generalization of that model preserves perfect dependence in the ranks between the
'These distributions can also be defined conditional on X.
30

two distributions but does not require the impact to be the same at all quantiles of the base state
distribution.

In place of ranks, it is easier to work with the percentiles of the Y1 and Y° distributions.
which have much better statistical properties.2° Equating percentiles across the two distributions,

one can form the pairs across the distributions and obtain a deterministic gain function (yi, yo).

This presents the gain in going from benchmark state "0" to outcome state "1". For the case of
absolutely continuous distributions with positive density at y°, the gain function can be written as

(y°) =

F

—
(F0 (y° ID = 1)) y°. One can test non-parametrically for the classical common effect

model by determining if percentiles are uniformly shifted at all points of the distribution. One
can form other pairings across percentiles by mapping percentiles from the Y' distribution into
percentiles from the Y° distribution using the map T : q1 — q0. The data are consistent with all
admissible transformations including q0 = 100

—

q1,

where the best in one distribution is mapped

into the worst in the other. They cannot reject any of these models or more general models where

H is a Markov transition matrix and we consider all possible Markov matrices.
I now consider empirical evidence on the question of the constancy of the gross gain

across

base state quantiles using earnings data from an experimental evaluation of a major U.S. job
training program described in Appendix B. Figure 1 displays the estimate of earnings gains z(yo)

for adult women assuming that the best persons in the "1" distribution are the best in the .rj"
2See Heckman and Smith, 1993, Heckman, Smith and Clements, 1997.

31

distribution. More formally, Figure 1 assumes that the permutation matrix H = I. No conditioning

is made, so the full sample is utilized. Between the 25th and 85th percentiles the assumption of

a constant impact is roughly correct. This evidence supports Model (A). However, the data
are grossly at odds with this model at the highest and lowest percentiles.21 Heckman, Smith and
Clements (1997) and Heckman and Smith (1993, 1998) present a more extensive empirical analysis

of data using different conditioning sets and reach essentially the same conclusion. Observe t.hat

even though the ranks are assumed to be perfectly dependent across the two distributions, there
is substantial heterogeneity in the gains at different points of the base state distribution.

IV. Evidence on Impact Heterogeneity and the Value of Self-Assessments and
Revealed Preference Information
This section of the paper address three questions. Question (1) is: "What is the empirical evidence on heterogeneity in program impacts among persons?" The conventional approach implicitly

assumes impact homogeneity conditional on observables. This assumption greatly simplifies the

task of evaluating the welfare state. Using data on earnings from an experimental evaluation of

a prototypical job training program described in detail in Appendix B, I implement the criteria discussed in Section I to bound or identify the joint distribution of outcomes conditional on

D=

1.

There is considerable evidence of heterogeneity of program impacts, so that conventional

econometric methods do not take one very far in constructing the evaluation criteria discussed
21Staridard errors for the quantiles are obtained using methods described in Csorgo (1993).

32

in Section I. Use of experimental data enables us to avoid the self-selection problems that plague
ordinary observational data, and simplifies our analysis.
Given the evidence on impact heterogeneity, I ask question (2): "How sensitive are the estimates

of the proportion of people who gain from the program - what I have called the voting criterion'
- to alternative assumptions about the dependence between Y° and Y1?" The estimates are very

sensitive to alternative assumptions. At the same time, for adult women, the estimated percentage

that benefit from the program exceeds 50 percent in every case I consider but one, and is close to
100 percent in some cases.

Some of the estimates used to answer question (2) assume that Y° and Y' are positively
dependent given D =

1.

Under purposive selection based on outcomes in the treated and untreated

states, such dependence among participants arises even if Y' and Y° are independent or negatively

correlated in the population as a whole. (Heckman and Smith, 1998). An alternative to imposing
a particular decision rule is to infer it from self-assessments of the program. These assessments are

all that are required for a libertarian evaluation of the welfare state. I examine the implicit value

placed on the program by addressing the following questions: (3a) "Are persons who applied

to the program and were accepted into it but then randomized out of it placed in an inferior
position relative to those accepted applicants who were not randomized out?" I measure ex ante
rational regret using second-order stochastic dominance, which is an appropriate measure under

the assumption that individuals are completely uncertain of both Y' and Y° before going into
33

the program. I also consider ex post evaluations of participants by asking: (3b) How satisfied'
are participants with their experience in the program?" Self-assessments of programs are widely

used in evaluation research (see e.g., Katz, et al., 1975), but the meaning to be placed on them

is not clear. Do they reflect an evaluation of the experience of the program (its process) or an
evaluation of the benefits of the program? The evidence presented here suggests that respondents

report a net benefit inclusive of their costs of participating in the program. Groups for whom the
program has a negative average impact as estimated by the "objective" experimental data express

as much (or more) enthusiasm for the program as groups with positive average impacts. A third
source of revealed preference evaluations uses the revealed choices of attriters from the program.
Econometric models of self-selection since Heckman (1974a,b) have used revealed choice behavior

to infer the evaluations people place on programs either by selecting into them or dropping out of

them. The third part of the third question is thus (3c): "What implicit valuation of the program
do attriters place on it?" I do not examine this question in this paper. Heckman and Smith (1998)
present evidence on it.
Evidence on Heterogeneity

Heckman and Smith (1993, 1998) apply the rionparametric Frechet Bounds of classical proba-

bility theory to the JTPA data to establish that the variance of the gain z is positive for a variety
of conditioning sets. Their estimate for the JTPA data is reported in the first row of Table 6. The
$675 lower bound on the standard deviation is to be compared with a $400 gain and mean $7200
34

base income for women. Heckman and Smith report a variety of other estimates that support
the conclusion that even within narrowly defined conditioning sets, the variance in outcomes is
substantial for women and for other demographic groups.22

Using the sample data from the JTPA experiment (see Orr, et a!., 1995) and discussed in

Appendix A, and in Heckman and Smith (1998), we may pair percentiles of the Y1 and Y°

distributions for any choice of rank correlation r between -1.0 and 1.0. The case of r = 1.0
corresponds to the case of perfect positive dependence, where iTT = I and qi =

qo.

The case where

r = -1.0 corresponds to the case of perfect negative dependence, where q1 = 100— q. The first and
last rows of Table 2 display estimates of quantiles of the impact distribution and other features of

the impact distribution for these two cases.

Heckman, Smith and Clements (1997) show how to obtain random samples of permutations
conditional on values of r between 1.0 and -1.0. Table 2 displays two sets of estimates from their

work. The first set assumes positive but not perfect dependence between the percentiles of Y'
and Y°. with i- = 0.95. Estimates based on a random sample of 50 percentile permutations with

this value of r appear in the second column of Table 2. These results show that even a modest
departure from perfect positive dependence substantially widens the distribution of impacts. More
22The classical solution to bounding a joint distribution from its marginals uses the Frechet-Hoeffding bounds:

Max[F(y1(D 1)±F(y° D = 1).—1,O] <F(i',y° D = 1) <Min(F(y1 D = 1),F(y° D = 1)).
These do not directly apply to the distribution of the gain
the gain. See Heckman and Smith (1993; 1998) for details.

35

= — Y° but can be used to bound the variance of

striking still are the results in the third column of Table 2. which correspond to the case where

r = 0.0.

This value of r is implied by independence between the percentiles of Y' and Y°. Here

(as in the case with r = -1.0) the distribution of estimated impacts is implausibly wide with large
positive values in each distribution often matched with zero or small positive values in the other.

However, the conclusion that a majority of adult female participants benefit from the program is
robust to the choice of r.23
Even though many joint distributions of outcomes are consistent with the marginals produced

from a social experiment, one model is not: common effect model (A). Heckman, Smith and

Clements test and reject the assumption that L(= ai) is a common coefficient, using a variety
of conditioning sets. Heterogeneity is a central feature of the data, even within narrowly defined
demographic categories.

Assuming the Gain Is Independent of the Base

Suppose that random coefficient model (B) of Section III is true. In that framework, suppose

that z is not known at the time decisions to go into the program are made. Then if Y° is known,

Y° is independent of z. Otherwise the coefficient cx1, is correlated with D1. In applying this to
experimental data, let R = 1 if a person who applies and is provisionally accepted into the program
2Heckman, Smith and Clements (1997) present methods for allowing for mass points of zero earnings in the
population, and some evidence derived from such methods. Their qualitative conclusions on variability are similar
to ours.

36

is randomized into the program, and R =

0

if a provisionally accepted applicant is randomized

out. Y = Y° + R, and R is statistically independent of Y°.
In the notation of Section III, we obtain a conventional random coefficient model for a regres-

sion: Y = RY' + (1 — R)Y° = ao + ci1R + £0. Using a components of variance model, one may

— = cj — a so that

write E(z) = and V, =

1=co+a1R+VR1+Eo
where

E(VR, + 60) =0.
Using a standard random coefficient model, we can estimate the variance of V. The first row

of Table 3 presents estimates of the random coefficient using these assumptions. The evidence
supports the hypothesis that VAR(L) > 0, suggesting that a more elaborate approach to estimating the distribution of

based on deconvolution is likely to be fruitful. If we maintain normality

of Y1 and Y° (given D =

1

and X), the distribution of

is normal with mean

and variance

VAR(L) and deconvolution is easy to perform. Under this assumption, we can estimate the voting

criterion and determine the estimated proportion of people who benefit from the program.

More generally, it is not necessary to assume that the distribution of

is normal. I use

the deconvolution procedure presented in Beckman, Smith and Clements (1997), t.o estimate
the distribution of impacts nonparametrically. Table 3 presents parameters calculated from this
37

distribution. The evidence suggests that under this assumption, about 43% of adult women were

harmed by participating in the program. The estimated density is presented in Figure 2 and is
clearly non-normal. Nonetheless, the estimated variance of the nonparametric gain distribution
matches the variance for the gain distribution obtained from the random coefficient model within
the range of the sampling error of the two estimates. The estimates of the proportion who benefit
are in close agreement across the two models when normality is imposed on the random coefficient

model. The fact that a positive density is estimated indicates that the assumption underlying
model (B) of Section III is consistent with the data for women and provides some support for the

hypothesis that agents do not select into the program based on •24
However,

the evidence against matching as a method of evaluating social programs that is

presented in Heckman, Ichimura, Smith and Todd (1998) and in Heckman, Ichimura and Todd
(1997), suggests that in most demographic groups, persons act on unobservable gains in making

program enrollment decisions. Matching assumes a (nonparametric) version of model B. Since

the cited papers test, and reject, the matching assumption using the same JTPA data as used in
this paper. a model of purposive selection on unobserved gains (Model C) is a more appropriate

description of the JTPA data.
Testing For Kr Ante Stochastic Rationality of Participants

If individuals choose whether or not to participate in the program based on the gross gains
24These calculations were first presented in Heckman and Smith (1993).

38

from it, if they possess concave utility functions (not necessarily the same across persons), and

if they know the marginal distribution of outcomes in the participation and non-participation
states, then second-order stochastic dominanceshuld imply that they order the distributions of
outcomes for persons who sought to go into the program. For non-negative

y° this form of

rationality implies that
(IV-i)

f F1(y ID = 1)dy' <f Fo(y°ID = 1)dy° for all E

R.

Draws from the Y' distribution produce higher expected utility than draws from the Y° distribution among participants. The difference between the two integrals is a measure of regret among

persons randomized out from the program and forced into the no-treatment state. This condition
may fail for many reasons: persons may possess more information about their potential outcomes

than just the marginal distributions; or persons may participate in the program on a principle
other than expected utility formulated in terms of gross outcomes. Condition (TV-i) is a sufficient

condition. Agents might still prefer distribution 1 even if it is not satisfied. Thus failure to reject
is informative; rejection is not.

I test condition (IV-1) by comparing the integrals of the empirical CDFs of the control
and treatment group earnings distributions for various values of o. Table 4 displays the re-

sults of tests of the null hypothesis of equality of the integrated distributions in (TV-i) for
adult males and females and male and female youth using self-reported earnings in the eighteen
months after random assignment. The table displays test results for c€{$2, 500, $5, 000, $10, 000,

39

$15, 000, $20, 000, $25, 000}. Standard errors are obtained by bootstrapping. For adult males, the

integrated CDF of earnings for the control group exceeds that for the treatment group at every
point, with a p-value below 0.05 for a <$16. 500. and below 0.10 for a < $22, 500, which includes

most of the supports of the two earnings distributions. The data for adult females provide strong

evidence of rational behavior in the sense of (TV-i), passing the test at the five percent level or
better for every value of a. This evidence suggests that personal objectives and program objectives

are aligned for adult women. Results for youth are mixed. For male youth, for whom the mean
experimental impact is significantly negative, the difference in integrated CDF's is negative for

most values of a, though not statistically significant. For female youth, the difference switches

sign around a = $11,000, but is never close to statistical significance.25
Evidence from Self-Assessments of Program Participants

Self-assessments of program participants are an alternative to comparisons of observed out-

comes as a measure of program impact. Unlike the ex ante measures based on second-order
stochastic dominance, these measures are statements about ex post expectations. There is no
reason why the two measures should agree if people revise their assessments based on what they

learn about a program by participating in it. In this section. I consider the strengths and limitations of self-reported assessments of satisfaction with the program as an evaluation criterion,
2These tests of second order stochastic dominance of treatment distributions were first presented in Heckman
and Smith (1993, 1998) and Heckman, Smith and Clements (1997).
40

and report on self-evaluations by participants in the JTPA experimental treatment group. I also
consider what can be learned from self-assessment data regarding the heterogeneity of individual

treatment effects and the rationality of prograni participants.

Using participant assessments to evaluate a program has two main advantages relative to
the approaches already discussed. First, participants have information not available to external
program evaluators. They typically know more about certain components of the cost of program

participation than do evaluators. Most evaluations, including the National JTPA Study, do not

even attempt to value participant time, transportation. child care or other costs in evaluating
program effectiveness, unless they are paid by the program through subsidies. Participants are
likely to include such information in arriving at their self-assessments of the program. Second,
participant evaluations provide information about the values placed on outcomes by participants

relative to their perceived cost. They have the potential of providing a more inclusive measure
of the programs effects than would be obtained from looking only at gross outcomes—one that
includes "client satisfaction". To some parties in the welfare state, "customer satisfaction' is an

important aspect of a program. They make an input-based measure of program evaluation and
not an output-based measure.
However, participant self-assessments may not be informative on the outcomes of interest to
other parties in the welfare state. In evaluations of medical interventions, for example, treatment.

effects may not be observed by participants or may be difficult for them to assess compared to

41

what observing scientists might report. Participant assessments of the counterfactual state may
be faulty because participants' judgements are based on inputs or on outcome levels rather than

gains over alternative levels. Persons who chose to go into the program may rationalize their
participation in it by responding to questions in a certain way. In addition, self-assessments, like
all utility-based measures, are difficult to compare across individuals.

The top panel of Table 5 reports JTPA participant responses to a question about whether or
not the program made them better off.26 Assuming people answer honestly, and are reporting a
gross impact, the self-assessment data clearly contradict the hypothesis of impact homogeneity.

For all four demographic groups, 65 to 70 percent of self-reported participants give a positive
self-assessment, not the 100% or 0% predicted if impacts were homogeneous. However, if respon-

dents are reporting a perceived net impact, the evidence reported in Table 5 does not necessarily

contradict an assumption of gross impact homogeneity if there is heterogeneity in costs across

participants. The entries in the third row of Table 5 reveal that the fractions reporting a positive impact are far lower than those obtained from all of the analyses using outcome data. This

evidence is consistent with one of two hypotheses: (a) that respondents are reporting net outcomes and that costs borne by participants are a substantial fraction of gross outcomes or (b) that
self-assessments are inaccurate.
26The exact wording of the survey question is 'Do you think that the training or other assistance you got from
the program helped you get a job or perform better on the job?" The question is asked only of treatment group
members who report receiving JTPA services.

42

The evidence suggests that the self-assessments are at least partly based on inputs received
rather than on outputs produced by the program. The lower panel of Table 5 shows the fraction
of persons receiving each type of training whose self-assessment of the program was positive. The
fraction increases with the level of treatment intensity for all four demographic groups. Expensive
and more intensive services such as classroom training in occupational skills (CT-OS) and on-the-

job training at a private firm (OJT) elicit a higher proportion of positive self-assessments than
do less expensive services such as job search assistance (JSA) or basic education. However, the
experimental impact estimates presented in Bloom, et a!. (1993) reveal that treatment effectiveness

and treatment intensity are not positively related. For example, for female youth, classroom
training in occupational skills has a more negative mean impact than the less expensive services

in the "other" treatment stream. This evidence suggests that participants may have difficulty
correctly constructing what would have happened to them in the absence of treatment, and so
rely in part on treatment intensity or program inputs as a proxy for treatment impact.

Finally, for adult women we consider how well the self-assessment data match up with the
analyses considered in earlier sections. The self-assessment data are not consistent with the assumption of perfect positive dependence in outcomes across the two states. As shown in Figure 1,

for adult women the JTPA data indicate that perfect positive dependence in outcomes between

the treated and untreated states implies a strictly positive impact of the program for about 85
percent of participants - all except those with zero earnings in both states. This value far ex43

ceeds the overall self-reported effectiveness rate of 44 percent reported in row 3 of Table 5. The

44 percent rate lies below that found even for the case of perfect negative dependence. Overall,

the self-reported impact data appear to be too negative when compared to our analyses of the
experimental earnings data. This evidence is consistent with participants reporting a net measure

while the experimental "treatment effect" measures gross outcomes. The lower positive rating of
the program from self assessment data than from gross outcome data is all the more striking given
that the self-assessments are recorded only for people who report receiving training while the gross

outcome data for participants include those who leave the program, and the attriters have lower

earnings than the non-attriters.
Heckman and Smith (1998) present additional evidence on the JTPA program using the revealed preferences of program dropouts. They document substantial heterogeneity in participant
evaluations of the program using this information.
Summary of the Evidence on Impact Heterogeneity and Its Consequences
Table 6 presents a summary of the main findings of this section. (1) Under a variety of different

assumptions, there is evidence of substantial heterogeneity in net impacts, . (2) The analysis
of self-assessments suggests that respondents are reporting different impacts from the "objective"
impacts determined from experimental data. This is a further source of heterogeneity and a source
of disparity across studies. (3) Departures from high levels of positive dependence between Y° and

Y' produce absurd ranges of impacts on gross outcomes. (The implicit correlations between Y°
44

and Y' produced under different identifying assumptions are given in the last column of the table).
However, positive dependence is implied by economic models of self selection. These narrow the

range of dependence across outcome states. (4) The range of the estimated proportion of people
benefitting from the program in the sense of gross outcomes (the 'voting criterion") varies widely

under different assumptions about the dependence in outcomes. The data from the self-report

and attrition studies show a lower proportion benefitting - a phenomenon consistent with the
hypothesis that net returns and not gross returns are being reported by participants.

V. Accounting For General Equilibrium and Heterogeneity in Evaluating Human
Capital Policies
A major limitation of the microeconomic treatment effect literature is its failure to consider the

general equilibrium consequences of the programs being evaluated. Many human capital policies

are large scale in nature, and expansion of the stock of skill affects skill prices. Rational agents
will act on that information. This feedback substantially alters the inferences obtained from micro
economic evaluations.

In addition, many policies do not fall into the treatment effect" category at all. A tax on
labor earnings affects everyone, although not uniformly. There are no natural comparison groups
(or control groups) for policies with universal coverage.
Conventional general-equilibrium analysis ignores heterogeneity among agents and so is poorly

suited to analyze distributional issues. An important exception is the class of overlapping gener45

ations models which explicitly consider inequality among generations. The goal of this section of

the paper is to extend the important empirical overlapping generations model of Auerbach and

Kotlikoff by (a) allowing for human capital and b) introducing heterogeneity in ability within
cohorts. Ability is a major determinant of human capital investment, and adding it to a model,
along with human capital, enables one to develop a model of human capital and wage formation
that can explain rising wage inequality and inequality within narrow schooling groups. This model

provides a framework which accounts for heterogeneity and diversity and which enables one to

answer the evaluation questions posed in Section I for a dynamic economy. It is a vehicle for
examining the performance of micro evaluation methods within a general equilibrium setting.
Heckman, Lochner and Taber (HLT, 1998a) formulate and estimate dynamic general equilib-

rium models with endogenous heterogeneous human capital accumulation. Their model explains
rising wage inequality in the U.S. economy. In this section of the paper, I use their model to study

the impacts on skill formation of proposals to switch from progressive taxes to flat income and
consumption taxes.
A Dynamic General Equilibrium Model of Human Capital Accumulation with Heterogeneous
Agents

HLT build on the model of Alan Auerbach and Laurence Kotlikoff (1987) in three ways:
(1) They introduce skill formation and consider both schooling choices and investment in on-

the-job training. (2) They allow for heterogeneity in ability, endowments and skills. Different
46

schooling levels are associated with different skills and different post-school investment functions.

HLT discard the Auerbach-Kotlikoff efficiency units assumption for labor services. Models with

efficiency units for labor services do not explain rising wage inequality among skill groups. (3)

HLT use micro data joined with macro time series evidence to determine the parameters of the

model, rather than picking parameters in an unsystematic fashion from the micro literature or
'calibrating" the model to aggregates, as is commonly done in the empirical general equilibrium

literature.
The HLT model has three sources of heterogeneity among persons: (a) in age; (b) in ability to
learn and in initial endowments of ability and human capital (indexed by 9 below); and (c) in the

economic histories experienced by cohorts. In a transition period, different cohorts face different
skill prices, make different investment decisions and, hence, accumulate different amounts of human

capital and have different wage levels and trajectories. The HLT model extends the analysis of
James Davies and John Whalley (1991) who introduce human capital into the Auerbach-Kotlikoff

model but assume only one skill. HLT allow for multiple skills, incorporate both schooling and
on-the-job training, and allow for rational expectations in calculating transition paths.
In the HLT model, individuals live for a years and retire after aR a years. In the first stage
of the lifecycle, a prospective student chooses the schooling option that gives him the highest level
of lifetime utility. Define Ka5

as

the stock of physical capital held at time t by a person age a:

is the stock of human capital at time t of type S at age a with schooling S. The optimal lifecycle
47

problem can be solved in two stages. First, condition on schooling S and solve for the optimal
path of consumption (C) and post-school investment time (Ia) for each schooling level. Second,
select among schooling levels to maximize lifetime welfare.

Given S, an individual age a at time t has the value function

(V1)

Vat(H,K,S) =

max

(Cs)
at — 1

at, at

where 5 is a time preference discount factor. HLT follow Laurence Kotlikoff, Kent Smetters, and

Jan Walliser (1997, henceforth KSW), by assuming that the tax schedule can be approximated by

a progressive tax on labor income and a flat tax on capital income. This gives a dynamic budget
constraint,
(V-2)
where

K+1+1 K(i + (1 — Tk)Tt) + RH(1 —

I) r (RH(i — i))
—

—

k is the proportional tax rate on capital, r1 is the progressive tax schedule on labor earnings,

R is the price of human capital services of type S at time t, and Tt is the net return on physical

capital at time t. Experiments with other progressive tax schedules produce results similar to
the ones reported here. HLT abstract from labor supply. Estimates of intertemporal substitution

in labor supply estimated on annual data are small, so ignoring labor supply does not affect our

analysis. (Browning, Hansen and Heckman. 1999). This simplification makes the HLT model
comparable to that of Davies and Whalley who also ignore leisure.

On-the-job human capital for a person of schooling level S accumulates through the human
capital production function
48

(V-3)

= As (9)I0SHfj9 + (1 — aS)H,

where the conditions 0 < c < 1 and 0

< 1 guarantee that the problem is concave, and

is the rate of depreciation of skill-S specific human capital. '6" is an ability or heterogeneity
factor, such that different people have different abilities to learn. This functional form is widely

used in both the empirical literature and the literature on human capital accumulation. The c
and 13 are also permitted to be S-specific, which emphasizes that schooling affects the process of
learning on the job in a variety of different ways.

Notably absent from the model are short-run credit constraints that are often featured in
the literature on schooling and human capital accumulation. This model is consistent with the
evidence presented in Cameron and Heckman (1998, 1999) that long-run family factors correlated

with income (the 0 operating through As(O) and the initial condition for (3)) affect schooling, but

that short-term credit constraints are not empirically important. Such long-run factors account
for the empirically well-known correlation between schooling attainment and family income.

At the beginning of life, agents choose the value of S that maximizes lifetime utility:

S = Argmax [PV8(O) — Ds + c]

(V-4)

S

where PVS (0) is the tax-adjusted present value of lifetime earnings given schooling level 5, tuition

costs are Ds, and E5

represents

monetized nonpecuniary benefits of schooling level 5, or else

unobserved components of tuition subsidies (negative costs).27 All values and costs are discounted
27Because of the separation between consumption and investment, the decision to go to school can be formulated
in terms of comparisons among present values of earnings.

49

back to t.he beginning of life.
Tuition costs are permitted to change over time so that different cohorts face different schooling
costs. The economy is a.ssumed to be competitive so that the prices of skills and capital services are

determined as derivatives of an aggregate production function. In order to compute service flow
prices for capital and the different types of human capital, it is necessary to construct aggregates
for each of the factors over each of the ability types and over all cohorts to insert into an aggregate

production function.

Post-school human capital of type S is a perfect substitute for post-school human capital of
the same schooling type, whatever the age or experience level of the agent, but it is not perfectly

substitutable with human capital from other schooling levels. In this model, cohorts differ from

each other on'y because they face different price paths and policy environments within their
lifetimes.

The aggregate production function exhibits constant returns to scale. The equilibrium conditions require that marginal products equal pre-tax prices. In the two-skill economy HLT analyze,

the production function at time t is defined over the inputs H, H? and K, where II' and H? are
aggregates of utilized skills (high school and college, respectively) supplied to production, and K

is the aggregate stock of capital. The technology is

a3

(a2 (ai()Th

+ (1— ai)(?))P21 + (1 —

50

HLT estimate that P2 = 0 but Pi

.693, which yields an elasticity of substitution between high

school and college human capital of 1.441. HLT explore both open economy (world capital market)

and closed economy versions of their model. The latter produces estimates of aggregates closer to

data from the U.S. economy and I use that version.

Human capital accumulation functions (V-3) are estimated using micro data assuming that
taxes are proportional. However, an extensive sensitivity analysis reveals that within the range
of the data for the U.S. economy, misspecification of the tax system does not affect parameter
estimates if the model is recalibrated on aggregate data. (See Heckman, Lochner, Taber, 1998a,
Appendix B). HLT (1998a) also present an array of sensitivity checks to alternative specifications

of their model and find that their estimates are robust to alternative identifying assumptions. I
now use the HLT model to evaluate the effects of alternative tax policies and tuition policies on
efficiency and distribution.

Tax Effects on Human Capital Accumulation
In the absence of labor supply and direct pecuniary or nonpecuniary costs of human capital
investment, there is no effect of a proportional wage tax on human capital accumulation. Both
marginal returns and costs are scaled down in the same proportion. When untaxed costs or returns

to college are added to the model (i.e. non-pecuniary costs/benefits), proportional taxation is no
longer neutral. An increase in the tax rate decreases college attendance if the net financial benefit

before taxes is positive. Letting S =

1

denote college and S =
51

0

denote high schooling, a

person goes to college if PV1 — D'

—

PV° > 0 where PV denotes discounted (to age 0) earnings.

Progressivity reinforces this effect. A progressive wage tax reduces the incentive to accumulate
skills, since human capital promotes earnings growth and moves persons to higher tax brackets. As

a result, marginal returns on future earnings are reduced more than marginal costs of schooling.

Heckman (1976) notes that in a partial-equilibrium model, proportional taxation of interest income with full deductibility of all borrowing costs reduces the after-tax interest rate and.
hence, promotes human capital accumulation. In a time-separable, representative-agent general-

equilibrium model, the after-tax interest rate is unaffected by the tax policy in steady state as
agents shift to human capital from physical capital (see Trostel 1993). In that framework, flat
taxes with full deductibility have no effect on human capital investment. In a dynamic overlapping
generations model with heterogeneous agents and endogenous skill formation and with progressive

rates, taxes have ambiguous effects on human capital and both their quantitative and qualitative
effects can only be resolved by empirical research. I use the empirically groundel model of HLT

to study alternative proposals for tax reform, their consequences for inequality, and their ability
to construct the policy counterfactuals discussed in Section I.
Analyzing Two Tax Reforms28

Following KSW, I assume that the U.S. income tax can be captured by a progressive tax on

labor income and a flat tax on capital income. Each earner has 1.22 children and is single. For
2Thjs section is based in part on Heckman, Lochner, Taber (1998b).
52

each additional dollar beyond $9660, there is an increase in itemized deductions of 7.55 cents. An

individual with labor income Y has taxable income (Y — 9660)(1

—

.0755).

Using the 1995 tax

schedule, the taxes paid on income are computed and approximated by a second order polynomial.

A 0.15 flat tax rate on physical capital is assumed.
Consider two revenue-neutral tax reforms from this benchmark progressive schedule. The first
reform (which I call "Flat Tax") is a revenue-neutral flattening of the tax on labor earnings, holding

the initial flat tax on capital income constant. The second reform ("Flat Consumption Tax") is
a uniform flat tax on consumption. In both flat tax schemes, tuition is not treated as deductible.

(The consequences of making it deductible are discussed below.) For each tax, I consider two
models: (1) a partial-equilibrium model in which skill prices and interest rates are fixed, and (2)
a closed-economy general-equilibrium model where skill prices and interest rates adjust.

A tax policy with universal coverage does not produce natural "comparison" or "control"

groups. For that reason, I do not consider estimates based on methods from the "treatment
effect" literature because that approach is ineffective in this context.
Table 7 presents both partial-equilibrium and general-equilibrium results measured relative to

a benchmark economy with the KSW tax schedule. I first discuss the partial-equilibrium effects
of a move to a "Flat Tax," which eliminates progressivity in wages and stimulates skill formation.
College attendance rises dramatically as the higher earnings associated with college graduation are

no longer taxed away at higher rates. The amount of post-school on-the-job training (OJT) also
53

increases for each skill group (as measured by the stocks of human capital per worker of each skill).

The aggregate stock of high school human capital declines while the aggregate stock of college
human capital increases as a result of the rise in college enrollment. The college-high school wage

differential increases slightly as does another widely used measure of inequality - the standard

deviation of log wages. The effects of the reform on aggregates of consumption and output are
modest at best. However, capital formation is greatly reduced as the tax code now favors human
capital compared to the benchmark economy.
In general equilibrium, the effects of the reform on skill formation are, in general, qualitatively

similar, but they are greatly diminished. The effects on aggregate consumption and output are
weak, as they are in the partial-equilibrium case. Furthermore, the negative effects of the reform

on physical capital are muted, since the return to capital increases. The rise in the after-tax
interest rate chokes off skill investment. Per capita post-school OJT accumulation still increases
for both skill groups, although the increase is dampened compared to the partial-equilibrium case.

Aggregate stocks of both high school and college human capital now rise, since college enrollment increases much less. The distinction between partial equilibrium and general equilibrium is

especially striking for the fraction attending college. In general equilibrium, college attendance
increases only for the most able, whereas in the partial-equilibrium case, it increases for all ability

groups. Changes in skill prices and interest rates virtually offset the removal of the disincentives
of progressive taxes on schooling enrollment. The college-high school wage differential (at 10 years

54

of experience) now declines slightly, and the increase in the standard deviation of log wages is less.

The Gini coefficient, which is the preferred measure in modern welfare economics, is ordered in

the same way. By this measure of welfare, flat tax reform is not to be preferred. In general equilibrium, the increase in the standard deviation is smaller, because skill prices adjust and because
higher after-tax interest rates flatten wage profiles.

Figure 3 shows how the reform affects the utility of the current generation. It lowers the
overall utility of the least able and the least schooled, and raises the overall utility of the most
able and the most skilled. This is a consequence of the pro-human-capital bias of the tax reform

and the interaction between ability and human capital in producing human capital. On a strict
voting criterion for those in the current generation, the reform would not pass (43% in favor; 57%

against). Evaluated at the final steady state, the reform would not be favored. (See the numbers
in Table 8).

Next, consider a move to a "Flat Consumption Tax." This reform is more pro-capital and is
less favorable to human capital. It raises output, capital and consumption more than a "Flat Tax

reform, and it reduces the aggregate stock of high skill human capital and the stock of human
capital per worker for each skill group. The fraction attending college declines. The reform raises
wage inequality as measured by the college-high school wage premium but lowers it as measured
by the standard deviation of log wages, and in terms of the Gini coefficient.
In general equilibrium, this reform is slightly less favorable to human capital formation than the

55

"Flat Tax," since the after-tax rate of return on capital rises more. College attendance increases
slightly, but the increase is concentrated among the least and most able persons. Wage inequality

increases slightly by both conventional measures. Real wages rise for both skill groups, and the

rise is greater than in the "Flat Tax" reform. This is due to a larger increase in capital under
proportional consumption taxation. Since capital is a direct complement with both forms of human

capital, and there is no evidence of skill bias in this complementarity relationship, the increase in

capital raises skill prices about equally for both skill groups. The greater increase in real wages

in this case is not due to a larger increase in per capita human capital accumulation within skill
groups.

Figure 4 reveals that across ability and schooling groups, the consumption tax reform produces

more winners among contemporary voters than does the flat tax reform. On a voting criterion,
the consumption reform would be barely favored (52% in favor; 48% against). Comparing steady

states, the reform would be passed by a substantial majority.
When deductibility of tuition is introduced in both reforms, and revenue neutrality is preserved,

there is virtually no effect on skill formation (or anything else) in general equilibrium. This is
consistent with Heckman, Lochrier and Taber (1998b) and the analysis presented below which
shows that general-equilibrium effects of tuition subsidies are small. The lessons from partialequilibrium analyses are substantially misleading guides in analyzing the effects of tax and tuition

policy on skill formation. Changes to proportional taxation are unlikely to have large effects on

56

skill formation or output. A change to a flat consumption tax has the largest effect on.output.
consumption, and real wages, but it also slightly raises wage inequality. These conclusions also
hold for open economy simulations in which tife interest rate is set in world markets. (Heckman,
Lochner and Taber, 1999). They are robust to a variety of tax schedules and empirically grounded

parameter estimates. However, the welfare criteria disagree. On the basis of a voting criterion, the
switch to a consumption tax would be preferred. On the basis of the "Veil of Ignorance" evaluation

criterion applied to steady states population it would not be.29 I now turn to an analysis of tuition
policy.

B. General-equililbrium Treatment Effects: A Study of Tuition Policy
This section of the paper uses the general equilibrium model developed by HLT to consider

the effects of changes in tuition on schooling and earnings, accounting for general-equilibrium
effects on skill prices and considering how the reform would be evaluated under different criteria.

The typical microeconometric evaluation estimates the response of college enrollment to tuition
variation using geographically dispersed cross-sections of individuals facing different tuition rates.

These estimates are then used to determine how subsidies to tuition will raise enrollment. The
impact of tuition policies on earnings is evaluated using a schooling-earnings relationship fit on
pre-intervention data which does not account for the effects of anticipated skill price changes on
29Recall that second order stochastic dominance and Gini ranking are equivalent. See Rothschild and Stiglitz
(1970).

57

enrollment and on the job training decisions or the response to the taxes raised to finance the
tuition subsidy. Kane (1994) exemplifies this approach.

The danger in this widely used practice is that what is true for policies affecting a small
number of individuals need not be true for policies that affect the economy at large. A national
tuition-reduction policy that stimulates substantial college enrollment will likely compress skill
prices, as advocates of the policy claim. However, agents who account for these changes will not

enroll in school at the levels calculated from conventional procedures which ignore the impact of

the induced enrollment on earnings. As a result, standard policy evaluation practices are likely
to be misleading about the effects of tuition policy on schooling attainment and wage inequality.

The empirical question is how misleading? Heckman, Lochner and Taber (1998c) show that
these practices lead to estimates of enrollment responses that are ten times larger than the long-

run general-equilibrium effects. HLT also improve on current practice in the treatment effects
literature by considering both the gross benefits of the program and the tax costs of financing the

treatment as borne by different groups.
Evaluating the general-equilibrium effects of a national tuition policy requires more information

than the tuition-enrollment parameter that is the centerpiece of partial-equilibrium policy analysis.
v1ost policy proposals extrapolate well outside the range of known experience and ignore the effects
of induced changes in skill quantities on skill prices. I apply the closed economy general-equilibrium

framework to evaluate tuition policies that attempt to increase college enrollment.

58

Conventional Models of Treatment Effects

As noted in Section IL the standard frame)vork for microeconometric program evaluation is

partial equilibrium in character. For a given individual j y'1 is defined to be the outcome the
individual receives if he participates in the program, and Y° is the outcome he receives if he

does not participate. The treatment effect for person i is z =

— /O When interventions

have general-equilibrium consequences, these effects depend on who else is treated and the market

interaction between the treated and the untreated.

To see the problems that arise in the standard framework, consider instituting a national
tuition policy. In this case, Y° is person i's wage if he does not attend college, and Y' is his wage

if he does attend. The "parameter" z. then represents the impact of college, and it can be used to

estimate the impact of tuition policies on wages. It is a constant, or policy-invariant, parameter

only if wages (Y°, Y') are invariant to the number of college and high school graduates in the
economy.

In a general-equilibrium setting, an increase in tuition increases the number of individuals who

attend college, which in tarn decreases the relative wages of college attendees. In this case, the
program not only impacts the wages of individuals who are induced to move by the program, but

it also has an impact on the wages of those who do not. For two reasons, then, the "treatment
effect" framework is inadequate. First, the parameters of interest depend on who in the economy is

"treated" and who is not. Second, these parameters do not measure the full impact of the program.
59

For example, increasing tuition subsidies may increase the earnings of uneducated individuals who

do not take advantage of the subsidy. To pay for the subsidy, the highly educated would be taxed

and this may affect their investment behavior: Additional educated workers enter the market as
a result of the policy, depressing the earnings of other college graduates. Conventional methods
ignore the effect of the policy on nonparticipants. In order to account for this effect, it is necessary

to conduct a general-equilibrium analysis.

Exploring Increases in Tuition Subsidies in a
General-Equilibmum Model

Heckman, Lochner and Taber (1998c) simulate the effects of a revenue-neutral $500 increase

in tuition subsidy (financed by a proportional tax) on enrollment in college and wage inequality

starting from our baseline economy described in the previous section. The partial-equilibrium
model predicts an increase in college attendance of 5.3 percent in the new steady state. This is
in the range of effects reported by Kane (1994) and Cameron and Heckman (1999). This analysis
holds skill prices, and therefore college and high school wage rates, fixed — a typical assumption

in microeconomic 'treatment effect" analyses of tuition policies.
When the policy is evaluated in a general-equilibrium model, the estimated effect falls to 0.49

percent. Because the college-high school wage ratio falls as more individuals attend college, the

returus to college are less than when the wage ratio is held fixed. Rational agents understand
this effect of the tuition policy on skill prices and adjust their college-going behavior accordingly.
60

Policy analysis of the type offered in the "treatment effect" literature ignores the responses of
rational agents to the policies being evaluated. There is substantial attenuation of the effects of
tuition policy on capital and the stocks of the different skills in our model. Simulating the effects

of this policy under a number of additional alternative assumptions about the parameters of the
economic model, including analysis of a case where tuition costs rise with enrollment, reproduces

the basic result of substantial partial-equilibrium effects and much weaker general-equilibrium
effects.

The steady state results are long-run effects. When HLT simulate the model with rational
expectations. the short-run enrollment effects are also very small, as agents anticipate the effects
of the policy on skill prices and calculate that there is little gain from attending college at higher
rates. When they simulate using myopic expectations, the short-run enrollment effects are much

closer to the estimated partial-equilibrium effects. Of course, the steady state results are not

affected and are large under either myopic or rational expectations. All of these results are
qualitatively robust to the choice of different tax schedules. Progressive tax schedules choke off
skill investment and lead to even lower enrollment responses in general equilibrium. Using the Gini

coefficient. as a measure of welfare, both partial-equilibrium and general-equilibrium simulations

suggest that the reform is welfare improving. In general equilibrium, the overall variance of log
wages is reduced.

Next consider the impact of a policy change on discounted earnings and utility. Decompose the

61

total effects into benefits and costs, including tax costs for each group. Table 9 compares outcomes

in two steady states: (a) the benchmark steady state and (b) the steady state associated with
the new tuition policy. Given that the estimated schooling response to a $500 subsidy is small,
we instead use an extremely high $5,000 subsidy for the purpose of exploring general-equilibrium
effects. The rows High School - High School report the changes in a variety of outcome measures

for those persons who would be in high school mder the benchmark or new policy regime; the
High School - College rows report the changes in the same measures for high school students in

the benchmark who are induced to attend college only by the new policy; College - High School
outcomes refer to those persons in college in the benchmark economy who only attend high school

after the new policy is put in place; and so forth.
By the measure of the present value of earnings (column 3), some of those induced to change
are worse off. Contrary to the monotonicity assumption built into the LATE parameter of Imbens
and Angrist (1994), defined in this context as the effect of tuition change on the earnings of those
induced to go to college, HLT find that the tuition policy produces a two-way flow. Some people

who would have attended college in the benchmark regime no longer do so. The rest of society

also is affected by the policy—again, contrary to the implicit assumption built into LATE that
only those who change status are affected by the policy. People who would have gone to college
without the policy and continue to do so after the policy are financially worse off for two reasons:

(a) the price of their skill is depressed and (b) they must pay higher taxes to finance the policy.

62

However, they now receive a tuition subsidy and for this reason, on net, they are better off both
financially and in terms of utility. Those who would abstain from attending college in both steady

states are also better off in the second steady state. They pay higher taxes, but their skill becomes

more scarce and their wages rise. Those induced to attend college by the policy are better off in

terms of utility but are not always better off in terms of income. For example, individuals from
ability quartiles 2 and 3 have lower net incomes as a result of the tuition policy; however, their
utility rises due to a strong taste for college education. While most groups gain about the same in

ternis of utility, there is substantial variation in the effects on lifetime earnings. Note that neither
category of non-changers is a natural benchmark for a "difference in differences" estimator. The
movement in their wages before and after the policy is due to the policy and cannot be attributed

to a benchmark "trend" that is independent of the policy. The implicit assumptions that justify

the widely used difference in differences estimator do not apply here. The tax system and the
market make the "nontreated" affected by the policy. (See the discussion in Heckman, LaLonde
and Smith, 1999). These conclusions are robust as to whether a closed-economy or open-economy

model is used. (Heckman. Lochner and Taber, 1999).

C. General-Equilibrium vs. Partial-Equilibrium Approaches
The sharp contrast between the general-equilibrium estimates of program impacts and the
estimates from partial-equilibrium approaches highlights the potential benefit of applying the
general-equilibrium approach to conduct evaluations. Not only is the general-equilibrium approach
63

appropriate for the evaluation of programs with economy-wide effects, it also offers an economically

interpretable evaluation of a policy, As discussed in Appendix A, many of the parameters estimated

in the micro_economic "treatment effect" literature, are not those required for the cost-benefit
evaluations.

Critics of the general-equilibrium approach dismiss it because it is based on "questionable"
empirical foundations. They ignore, or trivialize, the use of economic theory to produce counter-

factual policy states, and they assume that empirically credible general-equilibrium models are
not possible to construct. Careless calibration exercises often used to produce empirical estimates

for general equilibrium models have called the entire enterprise of using applied general equilibrium as a tool for policy evaluation into question. Reacting to this casual empiricism, many
microeconomists dismiss the general enterprise as an empirically unfounded exercise built on weak
foundations.

These criticisms ignore the emerging field of empirically grounded general-equilibrium theory

that unites microevidence, macro time series and general-equilibrium theory to produce credible
parameter estimates of models to evaluate counterfactual states. Browning, Hansen and Heckman

(1999) summarize current developments in this field and present an agenda for research in uniting micro evidence with macro general-equilibrium models. The empirical analysis presented in

Heckman, Lochner and Taber (1998a) uses micro data and macro data to estimate the dynamic
general-equilibrium model that is used to present the counterfactual simulations reported in this
64

paper.

There is, no doubt, much room for improvement in producing the empirical foundations used
in general-equilibrium models. At the same time, there is room for substantial improvement in the

micro "treatment effect" literature that entirely ignores the general-equilibrium consequences of
the policies it evaluates. Even if the estimated general-equilibrium effects presented here are scaled

down by 50%, they are still substantial. An evaluation literature that ignores price adjustment,
and the investment responses to price adjustment, is likely to err substantially in forecasting policy
impacts.

VI. Summary and Conclusions
Diversity, heterogeneity and involuntary redistribution are the defining features of the modern

welfare state. Disagreements over outcomes and their valuation gives rise to the demand for
publicly justified evaluations of social programs.

This paper critically examines the main criteria proposed in the modern literature in welfare

economics, in the theory of policy evaluation in macroeconomics, and in cost-benefit analysis.
Cost-benefit analysis and macro policy evaluation ignore distributional features of policies treat-

ing heterogeneity of program impacts as either uninteresting or empirically irrelevant. Modern
welfare economics explicitly recognizes heterogeneity in outcomes but focuses on one measure of

alternative policies because of its "ethical correctness". All of the measures proposed in the modern literature on welfare economics ignore or deplore self-interested agents who evaluate policies
65

by comparing their initial positions under current policies with their positions under proposed
alternative policies. A measure that enumerates gainers or losers and quantifying the magnitudes

of their losses comes closer to capturing the information useful in a modern democracy than a

criterion based on axioms of correct behavior that assume that positions in the distribution of
outcomes are independent across policies or that any such dependence should be ignored and that

persons (or their elected agents) ignore their initial position in evaluating policies.

This paper considers the information required to implement the various criteria and how dif-

ferent evaluation methods obtain them. Cost-benefit and "treatment effect" approaches ignore
general-equilibrium considerations, which are also left implicit in the approach of modern welfare

economics. General equilibrium is center stage in the macro policy evaluation model. Virtually

all methods ignore the heterogeneity in program impacts that is a major source of demand for
evaluations in the welfare state.
Using data from an influential social experiment, I demonstrate that heterogeneity in program

outcomes is an empirically important feature of the data even after conditioning on the observed

characteristics. Combining micro and macro data, I draw on my work with Lochner and Taber
to develop an empirically based general-equilibrium model of human capital accumulation that
can be used to analyze the consequences of heterogeneity and diversity for the evaluation of social

programs. The benefits of this approach are examined in evaluating several proposed tax reforms
and in evaluating a proposed tuition policy.

66

Accounting for heterogeneity, diversity and general equilibrium has important implications

for the way we evaluate social policies. An evaluation criterion that counts gainers and losers

produces a very different asssesment of the suitability of policies than the "ethically correct"

criteria advocated in modern welfare economics, and one that is more closely attuned to the
requirements of positive political economy.

67

References
[1]

Aakvik, A., J. Heckman and E. Vytlacil (1998), "Local Instrumental Variables and Latent
Variable Models For Estimating Treatment Effects," unpublished manuscript, University of
Chicago.

[2] Ahmad, and N. Stern (1984), The Theory of Tax Reform and Indian Indirect Taxes", 25(3),
259-298.
[31

Auerbach, A. and L. Kotlikoff (1987), Dynamic Fiscal Policy, Cambridge: Cambridge Uni-

versity Press.

[4] Baumol, W. and Quandt, R. (1966), "The Demand For Abstract Transport Modes: Theory
and Measurement," Journal of Regional Science, 6, 13-26.
[5] Bell, S. and C. Reesman (1987), "AFDC Homemaker - Health Aide Demonstration: Trainee
Potential And Performance" (Abt Associates: Cambridge, Massachusetts).

[6] Bentham, J., (1824), Handbook of Political Fallacies, republished by Johns Hopkins Press,
1952.

[7] Besley, T. and S. Coate (1998), "The Public Choice Critique of Welfare Economics: An
Exploration," unpublished manuscript, London School of Economics, December.
[8] Bloom, H., L. Orr, G. Cave, S. Bell, and F. Doolittle (1993), The National JTPA Study: Title
11-A Impacts on Earnings and Employment at 18 Months. Bethesda, MD: Abt Associates.
[9] Boadway. R. and Bruce, N. (1984), Welfare Economics. Oxford, England: Basil Blackwell.

[10] Browning, M., Hansen, and L, Heckman, J. (1999), "Estimating Dynamic General Equilibrium Models," forthcoming in Handbook of Macroeconomics, ed. by J. Taylor and M. Woodford. Amsterdam: North Holland.
[11] Cameron, S. and J. Heckman (1999), "Can Tuition Policy Combat Rising Wage Inequality,"
ed. by M. Kosters, in Financing College Tuition: Government Policies and Social Priorities,
AEI Press: Washington, DC., 75-125.

[12] Chipman, J. and J. Moore (1976), "Why An Increase in GNP Need Not Imply An Improvement in Potential Welfare," Kyklos, 29, 391-418.
[13] Coate, S. (1998), "Welfare Economics and The Evaluation of Policy Changes," unpublished
paper, Department of Economics, Cornell University.
68

[141 Couch, K. (1992), "New Evidence on the Long-Term Effects of Employment Training," Jour-

nal of Labor Economics, 10:4. 380-388.
[15] Csorgo (1993), Quantile Processes with Statistical Applications. Philadelphia: Society for
Industrial and Applied Mathematics.
[16] Davies, J. and J. Whalley (1991), "Taxes and Capital Formation: How Important Is Human
Capital?," in B. Bernheim and J. Shoven, eds., National Saving and Economic Performance,
Chicago: University of Chicago Press.

[17] Domencich, T. and D. McFadden (1975), Urban Travel Demand: A Behavioral Analysis.
North Holland: Amsterdam.
[18] Frechet, M. (1951), "Sur Les Tableux de Correlation Dont Les Marges Sont Donnes," Ann.

University Lyon: Sect. A, 14, 53-77.
[19] Gabaix, X., (1998), "Cost of Inequality" unpublished manuscript, Department of Economics,
MIT.
[20] Gueron, J. and E. Pauly (1991), From Welfare to Work, New York: Russell Sage Foundation.

[21] Harberger, A. (1971), "Three Basic Postulates for Applied Welfare Economics: An Interpre-

tive Essay," Journal of Economic Literature, 9, 785-797.
[22]

(1978), "on the Use of Distributional Weights in Social-Cost Benefit Analysis,"
Journal of Political Economy, 86, S87-S120.

[23] Harsanyi, J. (1955), "Cardinal Welfare, Individualistic Ethics and Interpersonal Comparisons

of Utility," Journal of Political Economy, 63, 309-321.
[24]

(1975), "Can the Maximin Principle Serve as a Basis for Morality? A Critique of
John Rawis' Theory," American Political Science Review, 69(2), 594-606.

[25] Heckman, J. (1974a), "The Effect of Child Care Programs on Women's Work Effort," Journal
of Political Economy, 82(2), 5136-5163. Reprinted in Economics of the Family: Marriage,
Children, and Human Capital, ed. by T.W. Schultz. Chicago: University of Chicago Press.

(1974b), "Shadow Prices, Market Wages and Labor Supply," Econometrica, 42(4)

[26]

679-94.
[27]

(1976), "A Life Cycle Model of Earnings, Learning and Consumption," Journal of
Political Economy, 84(4, pt.2), S11-S44.
69

[281

(1978), "Dummy Endogenous Variables In A Simultaneous Equation System."
Econometrica, 46(4), 931-959.
(1990a), "Varieties of Selection Bias." American Economic Review, 80(2), 313-

[29]

318.
[30]

(1992), "Randomization and Social Program Evaluation," in Evaluating Welfare
and Training Programs, ed. by C. Manski and I. Garflnkel. Boston: Harvard University Press,
201-230.

[311

[321

(1997), "Instrumental Variables: A Study of Implicit Behavioral Assumptions in
One Widely-Used Estimator Used in Making Program Evaluations," Journal of Human
Resources, Summer.
(1999), "Econometric Evaluation of Social Programs," forthcoming in Handbook of
Econometrics, Vol. V, Amsterdam: North Holland.

[331 Heckman, J., L. Lochner and C. Taber (1998a), "Explaining Rising Wage Inequality: Explorations With A Dynamic General Equilibrium Model of Labor Earnings With Heterogeneous

Agents," Review of Economic Dynamics, 1(1), January.
[34] Heckman, J., N. Hohmann, M. Khoo and J. Smith (1997), "Did We Learn the Right Lesson
from the National JTPA Study? Substitution Bias in Social Experiments," Mimeo, University

of Chicago, under revision, Quarterly Journal of Economics.
[35] Heckman, J. and B. Honoré (1990), "The Empirical Content of the Roy Model," Econometrica, 58(5), 1121-1149.

[36] Heckman, J., H. Ichimura, J. Smith and P. Todd. (1998), "Characterizing Selection Bias
Using Experimental Data," Econometrica, 66(5), 1017-1098.
[37] Heckman, J., H. Ichimura and P. Todd (1997a), "Matching As An Econometric Evaluation
Estimator: Evidence on Its Performance Applied To The JTPA Program, Part I. Theory and

Methods," Review of Economic Studies, October.
(1998), "Matching As An Econometric Estimator: Evidence on Its Performance Ap-

[381

plied to the JTPA Program, Part II. Empirical Evidence," Review of Economic Studies,
April.

[39] Heckman, J. and R. Robb (1985), "Alternative Methods For Evaluating The Impact of Interventions," in Longitudinal Analysis of Labor Market Data, ed. by J. Heckman and B. Singer.
New York: Cambridge University Press, 156-245.
70

[40] Heckman, J. and J. Smith (1998), "Evaluating The Welfare State," in S. Strom, ed,Ecoriometrics and Economic Theory in the Twentieth Century, Econometric Monograph Series, 31
Cambridge: Cambridge University Press.
[41]

(1993), "Assessing The Case For Randomized Evaluation of Social Programs," in
Measuring Labour Market Measures: Evaluating the Effects of Active Labour Market Policies,
ed. by K. Jensen and P. K. Madsen. Copenhagen: Danish Ministry of Labor, 35-96.

[42]

(1995), "Assessing The Case For Social Experiments," Journal of Economic
Perspectives, 9, 85-110.

[43]

(1996), "Experimental and Nonexperimental Evaluation," in International Handbook of Labor Market Policy and Evaluation, ed. by G. Schmidt, J.O' Reilly and K. Schomann.
Cheltenham, U.K: Elgar Publishers.

[44] Heckman, J., R. LaLonde, and J. Smith (1999), "The Economics and Econometrics of Active
Labor Market Programs," in 0. Ashenfelter and D. Card, eds.. Handbook of Labor Economics,
Vol. III, North Holland.

[45] Heckman, J., J. Smith and N. Clements (1997), "Making The Most Out of Program Evaluations and Social Experiments: Accounting for Heterogeneity in Program Impacts," Review

of Economic Studies, October.
[46] Heckman, J. and E. Vytlacil (1998), "Instrumental Variable Estimation of A Correlated
Random Coefficient Model," Journal of Human Resources, Fall.
[47]

(1999), "Local Instrumental Variables And Latent Variable Models For Identifying

and Bounding Treatment Effects", forthcoming in The Proceedings of The National
Academy of Sciences of the USA.
[48] Imbens, G. and J. Angrist (1994), "Identification and Estimation of Local Average Treatment
Effects," Econometrica, 62, 467-471.

[49] Kane, T., (1994). "College Entry by Blacks Since 1970: The Role of College Costs, Family
Background and the Returns to Education," Journal of Political Economy, 102, 878-911.
[50] Karoly, L. (1992), "Changes In the Distribution of Individual Earnings in the United States:
1967-1988," Review of Economics and Statistics, 74(1), 107-115.

[51] Katz, D., B. Gutek, R. Kahn and E. Barton (1975), Bureaucratic Encounters: A Pilot Study
in the Evaluation of Government Services. Ann Arbor, MI: Institute for Social Research.
71

[52] Knight, F. (1921), Risk, Uncertainty and Profit. New York: Houghton Muffin Company.
[53] Kotlikoff, L., K. Smetters, and J. Walliser (1997), "The Economic Impact of Privatizing Social
Security," unpublished manuscript, Boston University.

[54] Laffont, J. J. (1989), Fundamentals of Public Economics. Cambridge, MA: MIT Press.
[55] Lancaster, K. (1971), Consumer Demand: A New Approach. New York: Columbia University.
[56] Lewis, H. Gregg (1963), Unionism and Relative Wages, Chicago: University of Chicago Press.

[57] Lucas, R. (1987), Models of Business Cycles, Oxford: Basil Blackwell.

[58] Lucas, R. and T. Sargent (1981), "Introduction," in Essays on Rational Expectations and
Econometric Practice. Minneapolis: University of Minnesota Press, xi-xl.
[59] Maital, Schiomo (1973), "Public Goods and Income Distribution: Some Further Results,
Econometrica, 41(3), 561-568.
[60] Marschak, J. (1953), "Economic Measurements For Policy and Prediction," in Studies in
Econometric Method, ed. by W. Hood and T. Koopmans. New York: John Wiley, 1-26.
[61] Moffitt, R. (1992), "Evaluation of Program Entry Effects," in Evaluating Welfare and Training
Programs, ed. by C. Manski and I. Garfinkel. Boston: Harvard University Press, 231-252.

[62] Moulin, H. (1983), The Strategy of Social Choice. Amsterdam: North Holland.

[63] Orr, L., H. Bloom, S. Bell, W. Lin, G. Cave, F. Doolittle (1995), The National JTPA Study:
Impacts, Benefits and Costs of Title 11-A. Bethesda, MD: Abt Associates.
[64] Rawls, J., (1971), A Theory of Justice. Cambridge, MA: Harvard University Press.
[65] Roemer, J., (1996), Theories of Distributive Justice, Cambridge: Harvard University Press.

[66] Rothschild, M. and J. Stiglitz (1970), "Increasing Risk I: A Definition," Journal of Economic Theory, 2, 225-243.

[67] Roy, A. (1951): "Some Thoughts on the Distribution of Earnings," Oxford Economic
Papers, 3, 135-146.
[68] Saez, E. (1998), "Using Elasticities to Derive Optimal Income Tax Rates," unpublished paper,
MIT, Department of Economics.

72

[691 Sen, A. (1973), On Economic Inequality. Oxford: Clarendon Press.

[70] ____ (1979), "Strategies and Revelation: Informational Constraints in Public Decisions"
in Aggregation and Revelation of Preferences, ed. by J. J. Laffont. Amsterdam: North Holland.

[71] Smith, J. (1997), "The JTPA Selection Process: A Descriptive Analysis," in Performance
Standards in a Federal Bureaucracy: Analytical Essays on the JTPA Performance Standards
System, ed. by J. Heckman. Kalamazoo, MI: W.E. Upjohn Institute.
[72] Theil (1961), Economic Forecasts and Policy, Amsterdam: North Holland.

[73] Tinbergen, J. (1956), Economic Policy: Principles and Design. Amsterdam: North Holland.
[741

Trostel, P. (1993), "The Effect of Taxation on Human Capital," Journal of Political Econ-

omy, 101(2), 327-50.
[75] U.S. General Accounting Office (1996): "Job Training Partnership Act: Long-Term Earnings
and Employment Outcomes." GAO/HEHS-96-40.

[76] Vickrey, W. (1945), "Measuring Marginal Utility By Reactions To Risk," Econometrica,
13, 319-333.
[77]

(1961), "Risk Utility and Social Policy," Social Research.

[78] Young, P. (1994), Equity in Theory and Practice, Princeton: Princeton University Press.

73

</ref_section>

Appendix A
The Relationship Between The Requirements of Cost-Benefit Analysis and The
Information Produced From Social Experiments and The Microeconometric
"Treatment Effect" Literature
In this appendix I relate the parameters estimated in the micro-econometric evaluation literature or the literature on social experiments to the parameters needed to perform cost-benefit
analysis. I follow the literature in cost-benefit analysis and assume that the policy being evaluated
has a voluntary component and that valid evaluations of a policy can be derived from looking at
the impact of the policy on self-selected participants and nonparticipants.
I postulate the following framework. For a given program associated with policy j, there are two
discrete outcomes corresponding to direct receipt of treatment (D3 = 1, for program participation)
or not (D = 0), and a set of program intensity variables defined under policy j that affect

outcomes in the two states and the allocation of persons to "treatment" or nontreatment. The
may be discrete or continuous. Policy "0" is a no-intervention
program intensity variables
benchmark with program intensity y.
Assuming that costless lump-sum transfers are possible, that a single social welfare function
governs the distribution of resources and that prices reflect true opportunity costs, traditional costbenefit analysis (see, e.g., Harberger (1971) or Boadway and Bruce (1984)) seeks to determine the
impact of programs on the total output of society. Efficiency becomes the paramount criterion in
this framework, with the distributional concerns assumed to be taken care of through lump sum

transfers and taxes. In this framework, impacts on total output, as in the evaluation criterion
(1-3), are the only objects of interest in evaluating policies.
For policy j let Y and Y be individual output for person i in the direct participation (D1 = 1)
and direct non-participation (D3 = 0) state, respectively. The vector of program intensity variables
operates on all persons within the context of program j, although its effect need not be uniform.

It determines, in part, participation in the program. One may write D() as the indicator for
participating in program j when program intensity is . To simplify notation I keep implicit
any conditioning on personal characteristics that may affect both participation and outcomes. I
define c3 ()

as the social cost of

denominated in units of output. In general, policies could be
designed for specific persons but we do not consider that possibility here. I assume that c (0) = 0
and that c is convex and increasing in . The value defines another benchmark policy, "0", in
which there is no program and therefore no participants. This policy has associated cost function

When
0, there might be effects of policy j on output that distinguish that policy from the
no policy regime "0". A law that is universally assented to and accepted may raise output at no
cost (e.g., adopting a convention about driving on the right hand side of the road). Output could
be different in a policy without the law (policy "0") but the direct costs of enforcement would be
74

the same under both policies.

Letting N1(,o) be the number of direct program participants and N0() be the rest of the
population, the total output of society under policy j at program intensity level

is

=O,3)—c(),
where

N1() + N0() =

N

is

the total number of persons in society. ""

appears twice in

the conditioning arguments: as a determinant of D and as a determinant of the output levels in
the different states. Vector p is general enough to include financial incentive variables as well as
mandates that assign persons to a particular treatment state. Recall that I keep conditioning on
personal characteristics implicit.
Assume for simplicity the differentiability of the treatment choice and mean outcome functions
and further assume that is a scalar, a simplifying assumption that is easily relaxed. The change
in output in response to a marginal increase in the policy intensity parameter p, from any given
position is:

=

a(
+N1 ()

+No()

(Y'ID()

=

[E
(y°D() = °'

-

[E

The first term arises from the change in the number of participants induced by the policy change.

The second and third terms arise from changes in output among participants and nonparticipants
induced by the policy change. The fourth term is the marginal direct output cost of the change
in the intensity of policy
In principle, this measure could be estimated from time-series data on the change in aggregate
GNP occurring after the policy intensity parameter is varied. Under the assumption of a welldefined social welfare function with interior solutions and the additional assumption that prices
are constant at initial values, an increase in GNP at base period prices raises social welfare.'
If marginal program intensity changes under policy regime j have no effect on intra-sector
mean output, the bracketed expressions in the second and third terms are zero. In this case, the
parameters of interest are:
'See, e.g., Laffont (1989, p. 155), or the comprehensive discussion in Chipman and Moore (1976).
75

the number of people induced into
program j by the change in

ON1 (o)

3pj

(ii) E (y1ID(.) = 1,
(iii) c

)

—E

(°ID3(y) =

o) the mean output difference between

()

participants and nonparticipants.
the direct social marginal cost of policy
j at program intensity level

It is revealing that nowhere on this list are the parameters that receive the most attention in
the micro econometric policy evaluation literature or the literature on social experiments. (See,
e.g., Heckman and Robb, 1985, 1986 or Heckman, LaLonde and Smith, 1999). These are:

(a) E (}'' — }'PD(co) = 1,
(b)

E ('7 —

=

)

The effect of "treatment on the treated" for persons
in regime j at policy intensity
where

= sets N1(t) = N. This is the effect of

universal direct participation in program 3 compared
to universal nonparticipation in 3 at level of program

intensity .
(c)

E (y —

The effect of randomly selecting a single person for direct

treatment and forcing their compliance with this treatment
compared to their position in the no participation state
under policy j at program intensity level p3.
Parameter (ii) can be obtained from simple mean differences between the treated and the
nontreated. No adjustment for selection bias is required. Parameter (i) can be obtained from
knowledge of the net movement of persons into or out of direct participation in the program in
response to the policy change, something usually not measured in micro policy evaluations orsocial
experiments (for discussions of this problem, see Moffitt, 1992 or Heckman, 1992). Parameter (iii)
can be obtained from cost data. It should include full social costs of the program, including the
welfare cost of raising public funds, although these are often ignored.
It is informative to place additional structure on this model. This leads to a representation
of a criterion that is widely used in the literature on microeconomic program evaluation and
also establishes a link with the discrete choice literature in econometrics. Assume a binary choice
random utility framework like that used in the Roy model. Suppose that under policy regime 3 with
program intensity level p agents make choices to directly participate or not based on net utility
76

and that policies affect participant utility through an additively-separable term, k(,o), that is
assumed scalar and differentiable. Net utility from participating in the program is U3 = X+k(),
where k is monotonic in
and where the joint distributions of (', X) and (°, X) are F(y', X)
and F(y?, X), respectively.2 In the special case of the Roy model, X = Y31— Y° and k = 0. In

general, D(o) = 1(U3 0) = 1(X —k(p)), so

N1() =NPr(U 0)=Nf(f(x)dx
N0() =NPr(U <0)=Nff(x)dx.
Total output is
•

Nf Yfk( f(

y

+Nf: y0fk3)f(Y0,xIdxdY0 — ().

Under standard conditions, one may differentiate under the integral sign to obtain the following

expression for the marginal change in output with respect to a change in intensity parameters
within policy regime j:

M()=

f

Nk' () (_k ()) [E (7D() = 1,X = —k () ,) — E(°D(ç) = 0,X = —k (cj)
Of
— c (),
+N fff y' f() Of (y',xI) dxdy' + f y°-k(f .
where f, the marginal density of X, is evaluated at X = —k(ço3).

dxdYo]

This model has a well-defined marginal entry condition: X —k(). The first set of terms
corresponds to the gain arising from the movement of persons at the margin (the term in brackets) weighted by the proportion of the population at the margin, f(—k()), times the number
of people in the population. This term is the net gain from switching from nonparticipant to participant status. The expression in brackets in the first term is a limit form of the "local average
treatment effect" of Imbens and Angrist (1994). This term is estimated in Aakvik, Heckman and
Vytlacil (1998) and further analyzed in Heckman and Vytlacil (1999). The second set of terms is
the within-treatment-status change in output resulting from the change in the program intensity
parameter. This term is ignored in many microeconomic evaluation studies. It describes how
people who do not switch their participation status are affected by the policy change. The third
term is the direct marginal social cost of the policy change, which is rarely estimated. At a social
planner's optimum, M() = 0, provided standard second order conditions are satisfied. Marginal

benefit should equal the marginal cost. Either a cost-based measure of marginal benefit or a
2These are assumed to be absolutely continuous with respect to Lebesgue measure.

77

benefit-based measure of cost can be used to evaluate the marginal gains or costs of the change in
policy intensity.
Observe that the local average treatment effect is simply the effect of treatment on the treated
for persons at the margin (X = —k(cp1))

E (y1ID() = i,X = —k ()

—E

=

(°ID() = O,X = —k (j) ,)

is the indifference set for this problem. Thus, the LATE parameter is a marginal version of the conventional
"treatment on the treated" evaluation parameter for gross outcomes. This parameter is but one
of the three ingredients required to produce an evaluation of social welfare under the cost-benefit

The proof of this resuft is immediate once it is recognized that the set X =

—k(cp3)

criterion.
The conventional evaluation parameter "treatment on the treated"

E(7 — °lD ()

=

produced in the microeconometric program evaluation or from social experiments does not incor-

porate costs, does not correspond to a marginal change and includes the effect of intramarginal
changes. This parameter is in general inappropriate for evaluating the effect of a policy change
on GNP. If model (A) of Section III is true, however, then treatment on the treated is the same
as the average treatment effect and it is correct economic parameter for conducting a cost-benefit
analysis. Under certain conditions which I now make precise, the treatment on the treated parameter is sometimes informative about the gross gain accruing to the economy from the existence
of program j at level compared to the alternative of shutting it down and switching to policy
"0". The social cost associated with policy "0" is co(0), which we assume is zero: co(p0) = 0.
The essential condition is assumption (A-i) in Section II.
is
The appropriate criterion for an all or nothing evaluation of a policy at level

=

{N1

() E (hID() =

+ N0 () E (°jD() = o,) — c

()}

—NE(YoI0).
In the no policy regime. there is only one output Y0 and everyone is in the "no program" state.
If A() > 0, total output is increased by establishing program j at level . In the special case
where the outcome in the nonparticipation state under regime j,Y°, is the same as the outcome
in the no-program state (Y0) both for participants and nonparticipants under regime j, we have
0,
(AA-1)
E(P D() = 0, = E(Y0
and

)

78

D() =

)

)

D() =

).

1,
(AA-2)
E(Y° D() = 1, = E(Y0
The right hand sides of both expressions describe hypothetical conditional expectations. The

right hand side of (AA-i) is what the outcome in the no-program state would be for persons
who do not directly participate in the program under policy j with parameters , i.e., those for
whom D) () = 0. The right hand side of (AA-2) is the corresponding expression for persons
who would participate in the program under policy j with intensity parameters , i.e., those
for whom D3() = 1. These conditioning statements select out, respectively, non-participants
and participants in policy regime j and compute the expected values of output in the policy "0"
regime.

Assuming that the probability of participation in regime j under program intensity level
does not depend on the value of p in the no-program state:

iI, ) = Pr

Pr (D =
(D =
(A-2)
under assumption (A-i) we may use the law of iterated expectations to write
E(Y°

)=

=

E(YoD() =

From (AA-1) and (AA-2) and (A-2) one obtains

E(Y°

t,O)

E(Y3P

=

D() = 1,

))

)

=0,o)Pr(D() =0).

+ E(}P D() = 0, o) Pr(D = 0
Pr(D(cc) = 1
in the expression for A(), we obtain
=
A(co) = N(cc)E(}'

Substituting for E(Y3°
(AA-3)
which vindicates the use of the parameter "treatment on the treated" as an evaluation parameter

l,)

in the case in which there are no general equilibrium effects in the sense of assumption (A-i).
This important case is applicable to small-scale social programs with partial participation. For
evaluating the effect of "fine-tuning" the intensity levels of existing policies, measure M() is more
appropriate. Neither parameter captures the distributional consequences of the policy change.
As a matter of practice the treatment effect literature focuses its exclusion attention on gross
gains and rarely measures the full costs of the program it evaluates. Beckman and Smith (1998)
demonstrate the empirical importance of adjusting for costs in evaluating job training programs.
Accounting for full costs substantially revises the estimates of the returns.

79

Appendix B
The data analyzed in Sections III and IV of this paper were gathered as part of an experimental
evaluation of the training programs financed under Title IT-A of the Job Training Partnership Act
(JTPA). The experiment was conducted at a sample of sixteen JTPA training centers around the
country. Data were gathered on JTPA applicants randomly assigned to either a treatment group
allowed access to JTPA training services or a control group denied access to JTPA services for 18
months. Random assignment covered some or all of the period from November 1987 to September
1989 at each center. A total of 20,601 persons were randomly assigned.
Follow-up interviews were conducted with each person in the experimental sample during

the period from 12-24 months after random assignment. This interview gathered information
on employment, earnings, participation in government transfer programs, schooling, and training
during the period after random assignment. The response rate for this survey was around 84
percent. The sample used here includes only those adult women who (1) had a follow-up interview
scheduled at least 18 months after random assignment, (2) responded to the survey, and (3) had
useable earnings information for the 18 months after random assignment.

The sample was chosen to match that used in the 18-month experimental impact study by
Bloom, et.al. (1993). As in that report, the earnings measure is the sum of self-reported earnings
during the 18-months after random assignment. This earnings sum is constructed from survey
questions about the length, hours per week, and rate of pay on each job held during this period.
Outlying values for the earnings sum are replaced by imputed values as in the impact report.
However, imputed earnings values used in the report for adult female non-respondents are not
used. For a more complete description of this data, see Heckman and Smith (1998) or Heckman,
Ichimura, Smith and Todd (1998).

80

Criterion

Require

Cost
Benefit

Population Means

E(), E(Yk)

Table 1A

General Social Welfare Function With

Selfish

Nee I

U(Y,

No

0),

F'(y3, tJk'

f l(U(u1,O) U(yk,O))
(IF(?j,, !/k, 0) >)

Voting

W(j) > W(k)

W(I?) =

YN,))

Interdependent Peferences

Population Data Requirements To Implement Criterion
General Population (Compulsory Programs)
Program j compared to program k
Benthamite
Criterion

=

E(U(YJ, 0))E(U(Yk,O)) 0
E(U(Y,,O))

f =j,k

I'V(Ul(Yle,...,YNe),...,Upv(Yic

f U(y, O)dF(ye,0)

Need each
..., }j,) for all i.
Need outcomes for each persoll*
No, except in time special cases
previously considere(l.

U(Y,, 0) and (listril)ution
of (Y(, 0)F(y,, 0)

F=j,k

Estimable on
Yes, if data exist on No, unless 0 the same
Aggregate Time aggregate economy for everyone (homogeneity);
Series
in both regimes and U(Ye, 0) known and the
can eliminate trend moment f U(y, 0)dF(ye)
known or estimable

Notes:
* In
speia1 cases, surntiia.ry statistics of the (listribution of Y may
suffice
** This includes the
special case where individual utility depends
only on individual consumption.

For altruistic voting, U depends on Y1, ..., Yv, or various sub-

aggregators.

Criterion

Require

Estimable on
Aggregate Time
Series Data?

Cost
Benefit
E(Y

j

==

1)—

E(YkID3=1)

Criterion

1)

=

D
1,

Table lB

1)

E(U(Y,,O 1D = 1))—
E(U(Yk,O) D3 = 1)) > 0
where

U(Y,0) forD, =

P=j,k

fU(ye,O)dF(y,,O

E(U(Y,O) 1D =

I

Benthamite

W(j) > W(k)

W() = W(U1(Y1,, ...,
UN(Ylf,...,YN)

Need each U(Y1,, ..., Yv,)
for whom D I
Need idei itity of outcomes
for each persons*
No, except in the special cases
previously consi(lered.

No

U(Y, 0),

Need

(1F(y3, 1Jk, 0

____________

1)

D = 1)

=

>0

I l((J(yj3,O) > (J(y,O))

Function With Interdependent Selfish
Preferences
Voting

General Social Welfare

Population Data Requirements To Implement Criterion
General Population (Compulsory Programs)
Program j compared to program k

What participants
gain over state k

Population
Conditional Means

E(ID=1),
E(YkIDJ=1)
Yes, if aggregate
No, unless 0 the same
data for participants for everyone (homogeneity);
exist iii both regimes, U(Y,, 0) known and the
:;ni eliitiniate trend.
tflOIII(Tll I U(y,, 0)dF'(j, I I), =
lçijowji OI (Sii1fliI)IC

Notes:
* This criterion is not well defined with restricted to subsets of the
population. If only the utility of voluntary participants is considered, sonic position a.l)out the utility of nonparticipants must be
takeii, and the feedback between participants and flonparticil)ants
niuist be explicitly modeled. When individual utility only depends
individual consumption, the criterion is well defined.
OIL

TABLE 2
ESTIMATED PARAMETERS OF THE IMPACT DISTRIBUTION
PERFECT POSITIVE DEPENDENCEPOSLTIVE DEPENDENCE WITH r = 0.95,
INDEPENDENCE AND PERFECT NEGATIVE DEPENDENCE CASES

National JTPA Study 18 Month Impact Sample
Adult Females

Statistic
5th Percentile
25th Percentile

50th Percentile
75th Percentile
95th Percentile
Percent Positive

ImpactStdDev
Outcome Correlation

Perfect
Positive
Dependence
(r = 1.0)

Positive
Dependence

with r = 0.95
0.00
(360.18)

0.00
(47.50)
572.00
(232.90)
864.00
(269.26)
966.00
(305.74)
2003.00
(543.03)

1415.50
(391.51)

100.00
(1.60)
1857.75
(480.17)
0.9903
(0.0048)

96,00
(3.88)
6005.96
(776.14)
0.7885
(0.0402)

125.50
(124.60)

616.00
(280.19)
867.00
(272.60)

Independence
of Y' and Y°

(r = 0.0)
-18098.50
(630.73)
-6043.00
(300.47)
0.00
(163.17)
7388.50
(263.25)
19413.25
(423.63)
54.00
(1.11)
12879.21
(259.24)
-0.0147
(0.0106)

Perfect
Negative
Dependence

(r = -1.0)

-22350.00
(547.17)
-11755.00
(411.83)
580.00
(389.51)
12791.00
(253.18)
23351.00
(341.41)

52.00
(0.81)
16432.43
(265.88)
-0.6592
(0.0184)

TABLE 3

RANDOM COEFFICIENT AND DECONVOLUTION ESTIMATES
IMPACT ON EARNINGS IN THE 18 MONTHS AFTER RANDOM ASSIGNMENT

National JTPA Study 18 Month Impact Sample
Adult Females

Impact

Estimated
Impact
Std Dev

Estimated
Percent
Positive

601.74
(201.63)
614.00

2271.00
(1812.90)
1675.00

60.45

Estimated
Mean
Analysis
Random coefficient model
Deconvolution

56.35

TABLE 4

TESTS OF SECOND ORDER STOCHASTIC DOMINANCE OF
EXPERIMENTAL TREATMENT GROUP OVER EXPERIMENTAL CONTROL
GROUP EARNINGS IN THE 18 MONTHS AFTER RANDOM ASSIGNMENT

National JTPA Study 18 Month Impact Sample

Earnings

Adult

Adult

Value (cx)

Males

Females

0.8836

1.0296
(0.2978)
[0.0005]
1.9343
(0.5955)
[0.0012]
2.7811
(0.8933)
[0.0019]
3.7315
(1.1504)

2,500

5,000

7,500

10,000

15,000

20,000

25,000

(0.3162)
[0.0052]
1.8067
(0.6582)
[0.0061]
2.3903
(0.99 83)
[0.0166]
2.9839
(1.3334)
[0.0252]
4.0191
(1.9826)
[0.0435]
4.4428
(2.5434)
[0.0807]
4.6171
(2.9192)
[0.1137]

[0.00 12]

5.2659
(1.5768)
[0.0008]
6.2660
(1.8551)
[0.0007]
7.0279
(1.9980)
[0.0004]

Male
Youth

Female
Youth

-0.3357
(0.4250)
[0.4296]
-1.0482
(0.9344)
[0.2620]
-1.8742
(1.4610)
[0.1995]
-2.8489
(1.9790)
[0.1500]
-4.0631
(2.8333)
[0.1516]
-5.8554
(3.5386)
[0.0980]
-6.3804
(4.0905)
[0.1188]

0.6674
(0.5094)
[0.1901]
0.7137
(1.0022)
[0.4764]
0.4428
(1.4507)
[0.7602]
0.1308
(1.8486)
[0.9436]
-0.2717
(2.4032)
[0.9100]
-0.4484
(2.1750)
[0.86881
-0.4503
(2.864 1)
[0.8751]

TABLE 5
SELF-ASSESSMENTS OF JTPA IMPACT
EXPERIMENTAL TREATMENT GROUP

National JTPA Study 18 Month Impact Sample

Male Female
Males Females Youth Youth
Adult

Adult

Full Sample Percentages
Percent who self-report participating:

Percent of self-reported participants with a
positive self-assessment:

61.63
(0.81)

68.10
(0.68)

62.62
(1.29)

66.29
(1.09)

62.46
(1.04)

65.21
(0.85)
44.41
(0.73)

67.16
(1.59)
42.06
(1.32)

71.73
(1.29)
47.55
(1.16)

Overall percent with positive self-assessments: 38.49
(0.81)

Percent of Self-Reported Participants with a Positive Self-Assessment
by Primary Treatment Received
None (dropouts)

Classroom training in occupational skills
On-the-job training at private firm

Job search assistance
Basic education
Work experience

Other

48.89
(2.07)
74.10
(2.15)
75.13
(2.18)
59.57
(2.27)
62.96
(4.67)
66.67
(9.83)

51.44
(1.85)
73.47
(1.36)
78.90
(2.14)
59.80
(2.18)
56.55
(3.84)
68.75
(5.84)

58.90
(3.33)
72.73
(3.60)
71.00
(4.56)
68.09
(3.94)
70.97
(4.09)
82.76
(7.14)

61.56
(2.79)
75.28
(2.30)
75.00
(4.04)
68.94
(4.04)
78.44
(3.19)
73.17
(7.01)

58.47

66.40

62.50

77.98

(3.65)

(2.98)

(4,77)

(3.99)

Y'

=

1

lvidence of heterogeneity?
Yes, the impact standard
deviation is bounded away
from iero.2

Yes, the average minimum
is -$14504 and the average
is $48544.2

Yes, the averageminimum
is -$44175 while the average
maximum is$60599.2

maximum

Yes, the impacts vary between
-$48606 and $34102.2

$0 and $3250.2

Yes, the impacts vary between

T4ble

6

Standard I)eviation of Impacts
Rounded between $675 and

$14969.2

$1857.2

$16432.2

Average standard deviation

of $480).23

of$1857 (with standard
deviation

. Averagestandard deviation

of$ 12879 (with standard
deviationof$259).2''

—

3

i)ependcnce Between Y1aiid
Product-monieiit cou'elaiiiin
Y° hounded

p between Y'and

between -0.760 and 0.998.

percentiles ofthe two
disin hutions.2,t

deviation of0.0106). Kendall's
rank correlation T fixed at 0.0.
Both are calculated using the

p of -0.0147 (with standard

Average product-moitient

of the two distributions

a standard deviation otO.t)402).
Kendall's rank correlation T
fixed at 0.95. Roth are
calculated using the percentiles
2,3

correlation of 07885 (with

Average product-unuiueut

of the two distributions.2

Product-moment correlation
= --0.6592 and Kendall's rank
correlation is lixed at -— 1.00. Roth
are calculated using the percentiles

of' the two distributions.2

are calculated using the percentiles

I'rod uct—nioiueiitcoo e latioii
p = 0.9903 and Kendall's rank
correlation is fixed at 1.00. Roth

—

lvidence on Voting Criterion
'l'he bounds do not apply
to the indicator function

Averageof 54 percent
positive (with standard
deviation of l,ll).21

Averageof 93 percent
positive (with standard
deviation of 3,88).23

52 percent positive.2

100 percent of participants
benefit or are indifferent.2

lunction is not super- or
sub-additive. Thus, the
voting criterion cannot he
i)t)Lillded.2

1(Y' > Y°) as this

Summaryof Empirical Evidence on Impact Heterogeneity, The Mting Criterion and the Dependence Betwecii Y'aiid Y°
National JTPA Study 18 onth Experimental Impact Sample

I)ec ription nt Analysis
Statist cal bounds on Ihe joilit

q

given

=

P=

Assuiiies that the percentiles
ofY 'and Y° given
1
have a raiik correlation of
0.95. lstimates are based on

Y 0 distribution.

a
of V4'
P = 1.
percentile
given
Conditional on D
1, the
etiunterlictuaI for each qth
distribution
percentile 01 the
is the I ()0_qtJ! percentile in the

'j

= 100 — q0
Assumes
where
is a percentile of
q,
Y
P = I and is

percentile in the Y° distribution.

countertlictual lbr each percentile
in the Y distribution is the same

=

q, is a percentile of
given L) = I and qo is a
1.
percentile otY°given D
Conditional on D
1, the

functions of the joint
disiiihiititni. Sec e(luatioll
(17) iii tile tcI.
Asuiiies q — 'ji, where

super—

F(q°,y'L) =

d ist iihulion01 outcomes,
1), and on
and sub—additive

_____________________
l:rcch,e, Btniiids

Positive Percentile

l)ependence

Perfect Negative
Percentile

I)ependence

l'crl'ect Positive
Percentile

____________

,
Dependence with
Rank Correlation
T = 0.95
a random sample of 50 such
permutations,

of 1' 'and Y° given 1)

Assumes that the percentiles

Independence of
I'ercentiles of

rank correlation T

have

sun, pie 01' 50 such perirnitat ions.

of' 0.0. which is implied
by independencebetween them.
Istimatcs arc based on a random

a

Y'and Y°,Whicli
Implies a
Percentile Rank
Correlation T of' 0.1)

Random Coehliciettt
Model

Dcconvoluiioit

Seif-assessnients

.

l)ropouts

.

2.

2.

Yes, some participants
reported a benefit
and others did not.

Yes, see Figure

Evidence of heterogeneity?
Yes. see Figure

Evidence on VotingCriterion

If the random coefficient

Dependence RctweenYLn1

ilic product-moment
correlation = 0.9595.'

Varies from a low of 39.49

NA.5

ihie product-,nonient
correlation p = 0.977 I

NA.5

NA.5

A is assumed lobe normally
distributed then 60.45 percent
have positive impacts.4
56.35 percent positive.4

NA.5

percent positive for adult
men to a high of 47.55
percent positive for
kmale youth.
Dropping out ranges from
a low of 34.3 percent for
male youth to a high of
40.92 percent for adult
males.

$I675.

Standard deviation is

$2271.'

Standard Deviation of Impacts
Standard deviation is

Table 6 (emit.)
Summary of Empirical Evidence on Impact Heterogeneity, the Voting Criterion and the Dependence Between Y land V°
National JTPA Study 18 Month Experimental Impact Sample
I )escription of Analysis
Assumes that

I) = I

A 1IY0ID=I.

I

Assuii,es that

A ti

Ex post self-evaluations
by particip;tnts based
on a survey question
regarding whether or not
the program provided a benelit.
Attrition decisions aller

application and acceptance
into the program.

Yes. ihere arc non-zero attrition
rates and the evidence on the
discount rates required tojusitfy
a common coefficient model
suggests that this model is iilse.

(Y)

'A function k(.r, y) is superadditive ifx > x' and y > y' implies that k(x, y) + k(;r', y') > k(x, y') + k(x', y). Subadditivity reverses the inequality.
2Results are br adutt wonien only. Similar results are obtained for adult men and for male and lmale youth.
ll,e standard deviation is calculated overthe random sample of 50 permutations with Ike indicated value ofT.
'Results are fur adult wonmen only. For the remaining demographic groups Vtr
< Vu'r (Y°) which indicates that neither the random coefficient model nor deconvohution is appropriate.
5N.A. = not applicable.

Table 7
Closed Economy Effects of Alternative Tax Proposals
General Equilibrium (Steady State) and Partial Equilibrium Effects
Percentage Difference from Progressive Caset
Flat Taxi
PE
GE
After Tax Interest Rate
Skill Price College HC
Skill Price HS HC
Stock of Physical Capital
Stock of College HC
Stock of HS HC
Stock of College HC per College Graduate
Stock of HS HC per HS Graduate
Aggregate Output
Aggregate Consumption
Mean Wage College
Mean Wage HS
Standard Deviation Log Wage
College/HS Wage Premium at 10 Yrs Exp*
Fraction attending college
Type 1: Fraction Attending College
Type 2: Fraction Attending College
Type 3: Fraction Attending College
Type 4: Fraction Attending College
Tpe 1: College HC Gain First 10 Years**
Type 2: College HC Gain First 10 Years**
Type 3: College HC Gain First 10 Years**
Type 4: College HC Gain First 10 Years**
Type 1: HS HC Gain First 10 Years**
Type 2: HS HG Gain First 10 Years**
Type 3: HS HG Gain First 10 Years**
Type 4: HS HG Gain First 10 Years**

Table continues on next page

0.00
0.00
0.00

1.96
-1.31
-0.01

Flat Cons. Taxi
PE
GE
17.65
0.00
0.00

3.31

-15.07 -0.79 86.50
22.41 2.82 -15.77

19.55
1.85
0.08
1.72
0.16
4.98
3.66
6.96
6.82
0.69
0.18
-1.92
2.14
-7.88

-9.94
3.04
1.84
-0.09
-0.08
3.39
2.44
4.09
1.92
18.79

0.90
2.55
1.07
1.15
0.16
2.60
2.44
1.56
-0.45

1.88

-4.08
-5.23
15.76
7.60
0.12
0.25
-1.94
3.10

0.26 -12.18
50.29 -1.25 -42.57
28.50 -5.89 -15.60
14.13 -6.93 -5.20
15.27 6.13 -11.77
5.81
5.33
5.60
6.85
3.42
4.49
5.36
5.29

3.12
2.86
3.10
4.17
1.06
1.97
2.67
2.5.5

-7.53
-6.84
-6.70
-6.41
-7.79
-7.60
-7.62
-7.95

3.38
4.65

-9.56
7.50
1.51

1.38
1.61
2.56

-0.34
0.46
1.06
0.92

Notes:
§General equilibrium (GE) effects allow skill prices to change, while partial equilibrium
(PE) effects hold prices constant.
tJ the progressive case we allow for a progressive tax on labor earnings, but assume
a fiat tax on capital at 15%.

In the flat tax regime we hold the tax on capital fixed to the same level as the
progressive tax, but the tax on labor income is fiat as is calculated to balance the budget

in the new GE steady state. This yields a tax rate on labor income of 7.7%. In the
consumption regime, we tax only consumption at a 10.0% rate, again balancing the budget

in steady states.
*The college - high school wage premium measures the differences in log mean earnings

between college graduates and high school graduates with ten years of experience.
**These rows present changes in the ratio of human capital at ten years of experience
versus human capital upon entering the labor force.
Source: Heckman, Lochner and Taber, 1999.

Table 8A
Votes for Policy Reform in the Initial State and
Outcomes in Final Steady State
Movement to Flat Movement to Flat
Income Tax
Consumption Tax
% in Favor in Initial State
43%
52%

Final Steady State Utility Gain
High School Ability 1:
High School Ability 2:
High School Ability 3:
High School Ability 4:
College Ability 1:
College Ability 2:
College Ability 3:
College Ability 4:

-0.61
-0.20
0.09
-0.13
-0.53
-0.32
-0.18
0.23

0.27
0.71
0.93
0.78
0.35
0.58
0.72
1.16

Ability 1
Ability 2
Ability 3
Ability 4

-0.57
-0.28
-0.03

0.30
0.64
0.85
1.05

0.11

Table SB

Votes for Policy Reform in Initial State
with Introduction of Technical Change
and Outcomes in Final Steady State
Movement to Flat Movement to Flat
Income Tax
Consumption Tax
% in Favor in Initial State
66%
65%

Final Steady State Utility Gain
High School Ability 1:
High School Ability 2:
High School Ability 3:
High School Ability 4:
College Ability 1:
College Ability 2:
College Ability 3:
College Ability 4:

0.33
0.76
0.99
0.83
0.48
0.74
0.89

Ability 1
Ability 2
Ability 3
Ability 4

0.39

1.39

0.7.5

0.95
1.25

1.07
1.54
1.78
1.61

1.22
1.50
1.66
2.17
1.13
1.52
1.71

2.03

Table 9
Simulated Effects of $5000 Tuition Subsidy on Different Groups
Steady State Changes in Present Value of Lifetime Wealth
(Thousands of 1995 Dollars)

Group(Proportion)t
High School-High School (0.5210)
High School-College (0.023)
College-High School (0.0003)
College-College (0.447)

Ability Quartile 1
High School-High School (0.844)
High School-College (0.045)
College-High School (0.000)
College-College (0.111)

Ability Quartile 2
High School-High School (0.689)
High School-College (0.033)
College-High School (0.000)
College-College (0.277)

After-Tax
After-Tax
Earnings
Using Base Taxi Earnings
(1)
(2)

After-Tax
Earnings
Net of Tuitions
(3)

17.520
9.757
-37.874
1.574

6.849
-0.372
-49.528
-10.233

6.849
14.669
-45.408
8.412

14.696
30.587
0.000
1.273

5.673
21.043
0.000
-8.271

5.673
36.179
0.000
10.353

18.571
-5.356
0.000
1.308

7.269
-15.874
0.000
-9.210

7.269
-0.841
0.000
9.428

20.691
-22.046
0.000
1.4010

8.181
-33.156
0.000
-9.6910

8.181
-18.409
0.000
8.946

Ability QuarUe 3
High School-High School (0.446)
High School-College (0.014)
College-High School (0.000)
College-College (0.541)

Ability Quartile 4
High School-High School (0.139)

19.286
7.633
7.633
0.000
0.000
0.000
High School-College (0.000)
-37.874
-49.528
-45.408
College-High School (0.001)
1.802
-11.152
7.498
College-College (0.859)
The
groups denote counterfactual groups. For example, the High School-High School group consist.s
(t)
of individuals who would not attend college in either steady state, and the High School-College
group would not attend college in the first steady state, but. would in the second, etc.
() Column (1) reports the after-tax present value of earnings in thousands of dollars discounted
using the after-tax interest rate where the tax rate used for the second steady state is the base tax rate.
Column (1) reports just the effect. on earnings, column (2) adds the effect. of taxes, column (3)
adds the the effect of tuition subsidies.

Difference
4000

3000

2000

1000

0

—1000
2Ott2Oth

4Ott4Oth

8O8Oth

Dependence Case

50th/50th

Adult Females

Perfect Positive

3Ottv3Oth

70th/701h

BOtWBOlh

Figure 1
Treatment — Control Differences at Percentiles of the
18 Month Earnings Distribution

lOttVlOth

(13).

Percentile (Control/Treatment)
1. Sample consist. of ABle expodmental 18—month study sample.
2. ABT Imputed values woco Used In place of outlying values.
3. Standard errors for the quanillee are obtained usinU methods deecilbed In Ceorgo

90th/901h

(I)

U)

a)
4-.

a)

Co

ta

c.'J

Q

c

0

0

(0
a 0

E

0

a)
4-.
CU

E

Ci)

4-.

w
c'Jj

0
0
0
-15

-5

I

I

I

I

10

I

15

I

I

I

5

I

0

1

'I
II
II

I

II
II

II

Figure 2 - Impact Densities Under Alternative Identifying Assumptions
Adult Females

Deconvolution
Coefficient

Tau=-1.0

-10

Impact in $1000

0.6

Figure 3A
Changes in Utility from the Reform in the Current Generation: Flat Tax
I

I

I

— College Ability 1

0.5

— — College Ability 2

0.4 -

College Ability 3
—. - College Ability 4

0.3

\•\•\

0.2

.•...

/

0.1

0

0o

.

,
. ..

/

23b0

40

50

Age

0

70

80

0.2

Figure 3B
Changes in Utility from the Reform in the Current Generation: Flat Tax
•

...

/

0

-0.1-

...

.

0.1 -

'I/ /
/

I'

————

/

—--...---.-...••...

/

—0.2 -

—0.3 -

— High School Ability 1

—0 4

— — High School Ability 2

High School Ability 3

—0 5

—. - High School Ability 4
—0.6

10

I

I

I

I

I

20

30

40

50

60

Age

70

80

Figure4A

Changes in Utility from the Reform in the Current Generation: Consumption Tax
1

1

College Ability 1

.

2

— — College Ability 2

College Ability 3

\•\•

1

—. - College Ability 4

I.
O.8

.

.\.

—

0.6

..........

0

20

30

50

40
Age

607080

0.6 -

/

FiQure 4B
Changes in Utility from the Reform in the Current Generation: Consumption Tax

0.5 -

0.4-

,.—--

/
0.3

I

I

High School Ability 1
— — High School Ability 2

High School Ability 3

\.

• — - High School Ability 4

\ \\\

\\

0.2

\ \ \•

0.1 -

/
—0.2

10

I

20

30

\ \.

\\

40

50

Age

60

70

80

Fig 5A:Utility Changes from Reform in a Generation Experiencing Tech Change: Inc Tax
0.6

— High School Ability 1
0.5 -

— — High School Ability 2

High School Ability 3

.

0.4

—. - High School Ability 4

0.3

\
0.2

\\ .

\ \.

\ \.
.

0.1

......
— ..-.

0

20

30

-...

4050
Age

Fig 5B:Utility Changes from Reform in a Generation Experiencing Tech Change: Inc Tax
1 .6

1.4 .

I

,

— College Ability 1

\

— — College Ability 2

1.2

College Ability 3
—. - College Ability 4

1
...

0.8

-

...

.........

Age

Fig 6A:Utility Changes from Reform in a Generation Experiencing Tech Change:Cons Tax
1

— High School Ability 1
— — High School Ability 2

0.8
—--

High School Ability 3
..'

\

• —. - High School Ability 4

0.6

\ \.

\

0.4

0.2 -

0-

—0.2

10

20

30

50

40

Age

60

70

80

Fig 6B:Utility Changes from Reform in a Generation Experiencing Tech Change:Cons Tax
2

/ \.

— College Ability 1

/

— — College Ability 2

1.5

\
•

College Ability 3
— • - College Ability 4

.

80
Age

