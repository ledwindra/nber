NBER WORKING PAPER SERIES

BOOKS OR LAPTOPS? THE COST-EFFECTIVENESS OF SHIFTING FROM PRINTED TO
DIGITAL DELIVERY OF EDUCATIONAL CONTENT
Rosangela Bando
Francisco Gallego
Paul Gertler
Dario Romero
Working Paper 22928
http://www.nber.org/papers/w22928

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2016

Randomized evaluations like this require the contributions of a large number of people. While it
would be impossible to recognize everyone who made a contribution to this project, we would
like to thank Alejandra Aponte for superb field work, Ryan Cooper for help with the
implementation of the evaluation, and several members of the Ministry of Education of Honduras
and the Inter-American Development Bank for their involvement in discussions and
implementation. We are also grateful to Emiliana Vegas, Javier Luque, Ada Kwan, and seminar
participants at the Inter-American Development Bank for their comments throughout the
development of this manuscript. Gallego also thanks Fondecyt (through Grant No. 1141111) for
funding support. All authors have no conflicts of interests to disclose. The views expressed herein
are those of the authors and do not necessarily reflect the views of the National Bureau of
Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
¬© 2016 by Rosangela Bando, Francisco Gallego, Paul Gertler, and Dario Romero. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including ¬© notice, is given to the source.

Books or Laptops? The Cost-Effectiveness of Shifting from Printed to Digital Delivery of
Educational Content
Rosangela Bando, Francisco Gallego, Paul Gertler, and Dario Romero
NBER Working Paper No. 22928
December 2016
JEL No. I21,I28,J24,O15
ABSTRACT
Information and communication technologies, such as laptops, can be used for educational
purposes as they provide users with computational tools, information storage and communication
opportunities, but these devices may also pose as distractors that may tamper with the learning
process. This paper presents results from a randomized controlled trial in which laptops replaced
traditional textbook provision in elementary schools in high poverty communities in Honduras in
2013 through the program Educatracho. We show that at the end of one school year, the
substitution of laptops for textbooks did not make a significant difference in student learning. We
additionally conducted a cost-effectiveness analysis, which demonstrated that given the low
marginal costs of digital textbook provision, the substitution of three additional textbooks in the
program (for a total of five) would guarantee computers to be more cost-effective than textbooks.
Therefore, textbook substitution by laptops may be a cost-effective manner to provide classroom
learning content.
Rosangela Bando
Inter-American Development Bank
rosangelab@iadb.org
Francisco Gallego
Instituto de Econom√≠a
Pontificia Universidad Catolica de Chile
Av. Vicuna Mackenna 4860
Macul, Santiago
Chile
and EH Clio Lab
fgallego@puc.cl

Paul Gertler
Haas School of Business
University of California, Berkeley
Berkeley, CA 94720
and NBER
gertler@haas.berkeley.edu
Dario Romero
Columbia University
420 West 118th
New York, NY 10027
dr2879@columbia.edu

Research Highlights:
‚Ä¢

Options to access reading resources are increasingly shifting from print to electronic
versions that can be viewed on digital devices, such as computers. In education in
particular, research studies have shown that providing digital content on computers has
lower marginal costs but higher fixed costs in comparison to textbooks for schools.

‚Ä¢

Information and communication technologies (ICT), such as computers and laptops,
provide users with computational tools, information storage and communication
opportunities. However, these devices may also pose as distractors that tamper with the
learning process.

‚Ä¢

Using a randomized controlled trial in elementary schools in Honduras, we show that at
the end of one school year, the substitution of laptops for textbooks did not make a
significant difference in student learning.

‚Ä¢

A cost-effectiveness analysis we conducted demonstrated that the substitution of three
more textbooks would guarantee computers to be more cost-effective than textbooks.
This suggests that textbook substitution with laptops may be a cost-effective manner to
provide content information in elementary schools.

Page 2 of 33

1.Introduction
Over the past 20 years, the use of technology to deliver education has increased in many regions
of the world (World Bank, 2016). This is especially true in Latin America and the Caribbean.
Thirty one countries in Latin America and the Caribbean had information and communication
technology (ICT) policies implemented in schools by 2012 (UNESCO, 2012). Moreover,
government and private providers have distributed about 10 million laptops to public schools
(Arias-Ortiz and Cristia, 2014).
However, it is unclear the extent to which introducing computers or laptops

into

classrooms affects what students learn compared to traditional ways of teaching and learning.
Some studies have shown that laptops may support teacher instruction by offering individualized
instruction, providing learning opportunities outside of the classroom and complementing other
inputs of the educational process (Machin et al., 2004; Banerjee et al., 2007; He et al. 2008;
Linden, 2008; Barrow et al., 2009). Moreover, ICT such as computers provide users with
computational tools, information storage and communication opportunities. These features open
the possibility of additional gains. For example, students may become digitally literate;
communication costs may decrease; and a wide range of information may become accessible
through the World Wide Web. However, recent evidence suggests that computers may pose as
distractors that tamper with the learning process (Beuermann et al., 2015 and Malamud and PopEleches, 2010) or may decrease peer-to-teacher interactions that may be relevant for learning
(Banerjee and Duflo, 2014).
Given the expansion of resources using computers and software, a key question is
whether laptop distribution is cost effective for educational service provision. A dimension
mostly over-looked in the education policy literature is the shift of a significant amount of
pedagogical contents from print to digital versions as a result of increased computer usages and
the implications of the shift on learning outcomes. In Latin America, educational content is
traditionally provided through textbooks. Recent evidence from low performance students in
elementary schools in the United States shows that the provision of textbooks leads to gains in
student learning (Holden, 2016). However, computers may allow for electronic provision of
information, and electronic formats may decrease the marginal cost of providing content.
Therefore, they may decrease the burden of education costs taken on by providers and

Page 3 of 33

households. On the other hand, computers have large fixed and maintenance costs relative to
textbooks.
In this paper, we specifically study whether laptops may be a cost-effective way to
provide educational content. We first explore whether replacing textbooks with laptops affects
student learning. Then, we conduct a cost-effectiveness analysis to assess scenarios in which
such replacement would be cost-effective. We take advantage of data that come from a
randomized controlled trial in 271 elementary schools in Honduras. About half of the schools
were randomly selected to receive laptops with digital content and Internet access. These schools
did not receive Spanish or Mathematics textbooks. The other half of the schools received
textbooks, but did not receive laptops. The study focuses on grades 3 and 5.
We find that at the end of the school year, both laptops and books allowed for students to
achieve similar gains, particularly in Mathematics and Spanish test scores. At the end of the
school year, both groups improved test scores by 0.46 standard deviations. This implies that the
provision of books or laptops did not cause differences in terms of student learning. Our results
suggest this is true for third and fifth graders and for academic and non-academic outcomes. We
also show that there seems to be a significant effect of the program on improving digital-related
skills.
Then, we move to the cost-effectiveness analysis. We consider the actual costs of the
program, and we assume a one percent premium to digital literacy (a very conservative scenario
given the digital premiums reported in several papers). Our results suggest the distribution of
laptops with digital content provides gains of one standard deviation for US$100, and textbooks
provide 1.6 standard deviations per US$100. This is a result of the fact that while digital
provision of educational content has lower marginal costs than textbooks, the use of computers
involves much higher fixed and maintenance costs. Given that the program we evaluated
provided the content of two textbooks, we find that the substitution of three more textbooks (for
a total of five) in the Educatracho intervention would guarantee computers to be more costeffective than textbooks.
This paper makes several contributions to the existing literature on technology in
education. First, to our knowledge, this is the only randomized evaluation to explore the effects
of replacing textbooks with laptops in a real setting. Indeed, many studies have explored the
effects of introducing technology to enhance student learning, but in those settings, computers
Page 4 of 33

were typically introduced as complements to other inputs to education (with the exception of
Linden, 2008, who assessed the substitution of teacher-delivered curricula using computers).
Additionally, we are unaware of any studies that have explored how the substitution of textbooks
by laptops has an effect on learning despite its relevance in evaluating the effects of a specific
dimension of the transition from traditional to online instruction using massive online open
courses (MOOCS) and other technologies on student learning (Banerjee and Duflo, 2014). Our
results suggest that there are no differences in cognitive dimensions between using digital or
textbook content in classrooms, at least at the primary school level.
Second, we estimate the relative effects of digital and textbook content delivery within
the same randomized controlled trial (a limitation of the Linden, 2008 study is that two separate
randomized controlled trials are used to identify whether computers substitute or complement
teachers). This strategy allows us to observe students with textbooks and with laptops in the
exact same context (i.e., our study groups worked with the same curriculum and within the same
administration and institutional setting, among other factors).
Third, the aforementioned contributions combined with cost estimates of pedagogical
content provision using computers and of digital premiums allow us to analyze the costeffectiveness of the substitution of laptops for textbooks. Indeed, several education systems face
limited resources and low performance. This is important as this paper could assist decision
making on how to allocate educational resources. Some educational systems are fast expanding
educational resources in digital format. Coupled, the cost of laptops has decreased in the last
years. In addition, educational systems aim to align student abilities with those demanded by the
labor market. Digital abilities are one such skill. Moreover, adding premium for digital contest is
important as the labor market is increasing the demand for digital skills (World Bank, 2016).
The organization of this paper is as follows. Section 2 provides a summary of the
literature on the provision of educational content through textbooks or computers. Section 3
describes the Educatracho program which provided an opportunity to assess the substitution of
textbooks with laptops. Section 4 describes the data. Section 5 describes the methodology
applied to compare student learning in both groups. Section 6 describes results of the impact and
cost-effectiveness analyses of the intervention. Section 7 concludes.

Page 5 of 33

2. What we know about how laptops and books compare to promote student learning
In this section, we review literature on how substituting laptops with physical books could affect
student learning. Then, we discuss the experimental evidence on the cost-effectiveness of books
and laptops. Finally, we discuss features of delivering content through print and digital means
that seem to play a determinant role in the effectiveness of teaching.
The evidence on how substituting books with laptops is scarce. We only found two
quantitative studies in the United States. Wells (2012) study the use of tablets or printed
materials to read a passage in one class period in North Carolina using performance outcomes of
140 students in middle and high school. The results suggest that the program did not have an
effect on reading skills, comprehension or motivation. Daniel and Woody (2013) study the
performance of approximately 300 US college students who read a chapter of a psychology
textbook using digital or traditional textbooks in both lab and in-home experiments. They found
no big differences in learning outcomes, but students using electronic materials spent more time
reading, especially in the in-home setting. The authors provide some evidence that, especially in
the in-home environment, this is consistent with multi-tasking. They also argue that there is some
evidence that subjects use different strategies when reading electronic content compared to
traditional content. Other descriptive studies support the idea that substituting books with laptops
does not have an effect on learning (Wright et al., 2013; Merkt et al., 2011; Baron, 2015). We
found no published evidence on substitution effects at the elementary school level or in
developing countries.
Several studies explore the effects of laptops or books on student learning in different
types of programs. However, using this evidence to infer how laptop substitution would affect
learning is difficult. The reason is that the effectiveness of both books and laptops vary and also
because studies consider very different ways of providing computers and/or books. For example,
McEwan (2014) reviewed 15 computer or other technology related programs. He calculated a
mean average effect size of 0.15 standard deviations (p=0.003). Similarly, Glewwe et al. (2011)
reviewed high quality studies from 1990 to 2010 and found five randomized controlled trials.
They concluded the results were inconclusive. What is more, Kremer et al. (2013) compared the
cost-effectiveness of several education interventions. They found that a reading program in the
Philippines led to gains of 1.18 standard deviations per US$100 in the short-term (Abeberese et
Page 6 of 33

al., 2016). They also found an adaptive software program in India led to 1.54 standard deviations
per US$100 (Banerjee et al., 2007). However, Kremer et al. (2013) also included two other
programs that explored laptop or book provision. One assessed laptop provision in Peru
(Beuermann et al., 2015). Another assessed book provision in Kenya (Glewwe et al., 2009).
These two programs did not lead to any improvements in student learning.
There are two features of laptops or books that influence their relative efficacy to
promote student learning. First, relative to books, computers may facilitate the provision of
information to students. More specifically, laptops may provide software that adapts to the needs
of the student. Indeed, Banerjee et al. (2007) and Barrow et al. (2009) explored the effects of
laptop distribution with adaptive software. Both studies find positive effects on student learning
in India and the United States, respectively. Moreover, Barrow et al. (2009) found some
suggestive evidence that the impact of the adaptive software was stronger for kids not located in
the top quartile of baseline test scores. In contrast, Glewwe et al. (2009) estimated the effects of
book provision in Kenya. They find gains only for those students that had higher achievement
levels before book distribution. Therefore, our reading of the evidence is that the use of laptops
jointly with software that adapts to students seem to have an advantage relative to books. Thus,
laptops can assist users to find pertinent and relevant information.
Second, laptops may pose as distractors to users. As a result, they may demand support
by facilitators to guide their use. For example, Malamud and Pop-Eleches (2010) explored the
effects of computer use at home in Romania. They found that computers had a negative effect on
student learning. However, they found that those students for whom parents mediated computer
use showed no effects. Similarly, Beuermann et al. (2015) evaluated the One Laptop per Child
program in Peru. They found that students were less likely to read a book yet there was an
association of computer use with playing computer games and listening to music. They did not
find effects of laptops on academic performance. As already discussed, Daniel and Woody (2013)
documented the existence of multi-tasking especially in more flexible environments for college
students. For these cases, facilitators are important. An extreme case is the study by BarreraOsorio and Linden (2009). They evaluated a program that provided laptops in Colombia. They
found no effects on student learning and that teachers did not use laptops to teach or as a
resource to enhance learning.

Page 7 of 33

Facilitators are also important to determine the efficacy of books. For example, Borkum
et al. (2012) found that the provision of a library to schools in India resulted in low use. On the
contrary, Abeberese et al. (2016) analyzed a program that led to improvements in student reading.
They evaluated a program in the Philippines that provided age-appropriate reading materials and
enhanced student reading in a 31-day read-a-thon. Teachers received training, and the curriculum
was adapted to facilitate change. Therefore, neither laptop nor book provision alone has an effect
on student learning. Computers and books seem to require mediation by teachers or parents to
enhance learning.
This discussion clarifies the contribution of our work to the existing literature. The
evidence on how replacing books with laptops is scarce. In addition, indirect comparisons are
difficult. Features such as adaptability to students needs and moderation of use vary. Therefore,
our work contributes to this literature. We assess a replacement of books with laptops in a
context in which the program did not change contents. Laptops had textbooks pre-loaded and
pre-loaded fiction books in pdf format. The program did not change the role of teachers or
parents as facilitators.
3. The Educatracho Program
The Honduras Government introduced the Educatracho program in 2013. It was part of
an effort to improve the quality of education provision in elementary schools in poor areas. The
program provided an XO 1.75 laptop equipped with Fedora 17 and Open Office 3 software. The
laptops had Mathematics and Spanish textbooks stored in its memory. The textbook contents
were adapted for on-screen use. In addition, the laptops were equipped with interactive exercises
that were not designed to adapt to users' learning patterns. Nonetheless the computers' home
screens did have a link to a learning site. Students could do exercises and access additional Math
or Spanish information online. In addition, the laptops included a chat program, a drawing
program, and a word processor. Children were not allowed to take the laptops home because of
security reasons.
The program targeted public schools in poor communities, and school selection and
program implementation occurred in five stages. Honduras had 10,906 public schools in 2013.
First, the implementation team restricted the list to 3,695 schools based on the following
Page 8 of 33

eligibility criteria: schools were eligible if they had access to electricity, one teacher available for
each of the study groups, and students enrolled in 3rd and 5th grades. In the second stage, the
team ordered the 3,695 schools eligible from the first stage by the percentage of poor households
in the community using information on poverty rates from the cash transfer program Programa
Bono Diez Mil (Bono 10,000). In the third stage, the team scheduled the allocation and delivery
of 120,000 laptops over a two-year period. Schools located in communities with higher
percentages of poor had priority than those with lower percentages. The distribution resulted in
1,503 targeted elementary schools. All communities with targeted schools had a poverty rate of
58% or higher. In the fourth stage, the team confirmed using administrative data that 1,198 out of
the 1,503 met the targeting criteria. In the fifth stage, the team selected 272 schools to implement
and evaluate the first year of the program. Selection of the 272 schools was random and with
equal probability. One school had to be excluded because of safety concerns surrounding data
collection. As a result, the evaluation focused on 271 schools with 9,600 students.
Figure 1 presents a timeline of the program implementation. The school year in Honduras
runs from early February until late November. The Ministry of Education delivered Mathematics
and Spanish textbooks to the control schools in January and February 2013 and laptops to the
treatment schools in February and March 2013. Teacher training on the use of technology in the
classroom took place from April to August and was received by teachers for both treatment and
control schools. At least half of the teachers had started using computers by April. However,
some teachers started using laptops as late as June. Students in the treatment group had access to
computers for an average of seven months. Before the use of laptops, it is likely students used
old textbooks, which were available to students in treatment and control schools. As for
treatment schools, new textbooks were delivered towards the end of the school year
(Mathematics textbooks in September and October to only about one fourth of treatment schools
and Spanish textbooks in November and December to all treatment schools).
In terms of the actual implementation of Educatracho, we collected administrative data
on laptop delivery, and survey information from principals, teachers, and students on computers
and Internet use at the school. Principals and teachers reported that all the schools in the
treatment group had computers available, in contrast with just 40% in the control group.
Similarly, principals reported that Internet access increased from about 34% in the control
schools to 100% in the treatment schools. Moreover, there was a sharp difference in the type of
Page 9 of 33

available computers, because the presence of computers in the control group can be explained
mainly by the existence of computer labs in the schools (in 33% of the control schools).
Interestingly, there is no significant difference in the existence of computer labs between
treatment and control groups. However, in terms of computer use, the differences are more
marked. While 99% of the teachers in the treatment group reported to use computers at school,
just about 20% of the teachers in the control group said they use computers at school. In sum, all
this evidence suggests that Educatracho affected both the extensive and intensive margins of the
availability of technology in the schools. Additionally, we collected administrative data that
reports with high fidelity the delivery of the laptops and textbooks and other materials to the
schools.
Students also reported significant changes in computer use in the school. The program
increased the share of students who used computers at school from 43% in the control group to
98% in the treatment group. The use of technology in Math or Spanish class increased from 34%
to 99%. In addition, the use of laptops during recess increased from 7% to 39%. Accordingly, the
number of students that used Internet increased from 7% to 55%. Moreover, 87% of the students
in treatment schools reported using computers as a tool to do homework (versus 38% in the
control group), and the use of computers increased from 44% to 97% for computing functions.
The program also increased access to online content from 10% to 90%. This confirms that the
increase in availability of computers reported by principals and teachers translated to an actual
increase in use by students in general and especially as educational tools.3
4. Data
We collected data at two points in time during the 2013 Honduran school year. The
baseline round took place in March of 2013. The follow-up round took place in October in the
same school year. The sample includes 9,600 students enrolled in the 271 targeted schools. Out
of these students, 4,563 students were in 3rd grade, and 5,037 students were enrolled in 5th grade.
Our data collection process included the application of instruments with five modules.
The first module consisted of standardized Mathematics and Spanish tests. These tests aimed to
3

We also have access to information about computer and Internet use at home and we did not find that students who
attended treatment schools changed computer ownership and use in a significant manner. This is important as these
results suggest that the intervention was mainly related to the schools and have no impact on other margins related to
technology use at home.

Page 10 of 33

assess progress according to the curriculum for the corresponding grade. The second module
consisted of a verbal fluency test. This test aimed to measure verbal ability and executive control.
The score on this test correlates to vocabulary size and lexical access speed (Shao et al., 2014).
In addition, it correlates to updating and inhibition ability (Shao et al., 2014). Updating ability is
one process involved in working memory which refers to the capacity to change the focus of
attention. The third module consisted of a coding test. This test aimed to measure processing
speed and working memory. Other studies had suggested that laptops may have an effect on
cognitive skills (Cristia et al., 2012, Malamud and Pop-Eleches, 2011). The fourth module
included a test for digital literacy. This module was only applied to half of the students in
treatment schools (with randomly selected students). The final module consisted of a student
questionnaire aimed to collect information on student characteristics, including questions on age,
gender and experience with laptops and technology. It also included questions on household
characteristics, such as asset holdings and the parental literacy. We also surveyed 504 teachers
and 271 principals. These surveys collected data to assess the technology experience of the
schools. Program administrative records facilitated information on program cost (BID, 2015).
Table 1 summarizes the number of students, teachers, principals and schools in the
sample. The baseline sample included most of the principals, teachers, and students included in
the original study sample. Attrition rates between the baseline and the follow-up surveys vary
depending on the instrument. While attrition for student questionnaires was below 2%, attrition
for the tests increases to between 3% and 8%, depending on the instrument. In all, attrition rate in
the sample for which we run the regressions was 7% and was not correlated with treatment status
(p=0.859).
Table 2 presents a summary of the characteristics of the students included in the sample.
Students were on average 10 years old, with 88% having a literate mother. About half of the
students were 3rd graders and the other half were 5th graders. Teachers had an average age of 38
years and 15 years of experience, and 35% were male. Schools had 181 students on average. The
student-to-teacher ratio was 30. Among the schools, 79% were rural and had high poverty rates.
In addition, 26% of the families in the school received the poverty alleviation program Bono
10,000.

Page 11 of 33

5. Methodology
The empirical framework for our main analysis uses observations on children who attend
schools that were randomly assigned to the treatment and control groups. In particular, we
estimate the following regression model:
ùë¶!"# = ùúá! + ùõºùëá!" + ùêó‚Ä≤!"# ùõÉ + ùúÄ!"#

(1)

where ùë¶ denotes the score of student i in school s, strata c, T is a dummy variable that
takes a value of 1 if the school is part of the treatment group, X is a vector of control variables,
and Œµ is the error term that is clustered at the school level j in each regression. Then, estimates of
Œ± quantify the differences in means between students attending schools that receive laptops but
did not receive textbooks and those that did not receive it and received textbooks.
We use strata fixed effects given that the we chose schools to receive laptops through
stratified random selection. We use four strata to group schools by size and poverty using the
medians of size and poverty. We chose school size to define the strata, because (i) household
income is one of the main determinants of educational outcomes and (ii) school size summarizes
organizational demands and community size (Duflo et al., 2008; Bando, 2013, Duflo et al., 2011
and Urquiola, 2006).
We implement two additional exercises to study the robustness of our results. First, we
also estimate differences-in-differences models to control for pre-treatment differences across
treatment and control schools to take into account a few differences we identify at baseline in test
scores. Second, given that we include a series of outcomes, we may face an inference problem
related to multiple hypotheses testing (i.e., significant coefficients may emerge simply by chance,
even if there are no treatment effects). Then, we calculate adjusted p-values that correct the pvalue for the family-wise error rate (FWER, the probability of making a Type I error) using a
Westfall and Young (1993) type correction (we follow Haushofer and Shapiro, 2013). We call
these FWER p-values.
Table 2 shows descriptive statistics of student, teacher, school and community
characteristics at baseline.4 Columns (1) and (2) present averages by treatment status. Column (3)

4

See Table A1 in Appendix A for a detailed definition of all the variables.

Page 12 of 33

presents differences between the two groups. Column (4) presents p-values for a test of
differences in means. For most variables, differences between treatment and control groups are
not statistically different. However, we find differences for the rural status of the community, the
age or education of the teacher and the literacy of the student‚Äôs mother.
We address these differences in two ways. First, we test if the full set of variables can
predict treatment. We reject this possibility (p=0.616). Second, we estimate differences after we
control for the rural status of the community. Column (5) presents p-values for tests of
differences across treatment and control groups controlling for rural status. We find no
significant differences after we control for rural status.
Therefore, we analyze program effects with and without the inclusion of rural and
frontier statuses. In addition, we estimate program impacts controlling for all baseline variables
reported in Table 1. These alternative specifications allow us to assess if school characteristics
bias estimates of program effects.
Table 3 compares student performance at baseline for students in the treatment and
control groups. We focus on academic tests in Mathematics and Spanish and also combine them
by calculating an average of both standardized scores. We label this average ‚Äúacademic tests‚Äù. In
addition, we analyze differences in the non-academic verbal and codes tests and we summarize
the information of these tests in an index labeled ‚Äúnon-academic tests‚Äù, which is an average of
the standardized verbal and coding test scores. Columns (1) and (2) present averages by
treatment status. Column (3) presents differences including strata fixed effects. Columns (4) and
(5) present differences including controls for rural or frontier status and all variables listed in
Table 2, respectively. We reject the null of baseline differences for all variables but for verbal
correct fields for 3rd grade. However, this difference is not robust to the inclusion of controls.
We conclude there are no systematic differences before program intervention.
6.

Results

This section discusses first the results of estimating equation (1) under different
specifications. In summary, we find that the substitution of textbooks by laptops did not have a
statistically significant effect on student performance by the end of the school year. Next, in a
second subsection, we discuss the implications of the results and estimate and discuss the costPage 13 of 33

effectiveness of laptops relative to books. We conclude laptops are as effective as books if they
substitute at least five textbooks.
6.1 Treatment Effects on Student Performance
Table 4 presents estimates of program effects on student performance. We observe
academic, verbal and code tests after an average of seven months of exposition to laptops.
Column (1) presents the performance level for students in the group of students who received
textbooks. Column (2) presents the difference between the two groups when controlling for strata
fixed effects. Columns (3) and (4) present estimates including controls. Results under the three
specifications are not statistically different. However, the introduction of controls or individual
fixed effects renders some effects statistically significant. We cannot reject the null of no
program effects for Spanish and coding tests. We find a positive effect on verbal scores for 6th
grade students. In addition, we cannot rule out a negative effect on Mathematics scores for both
3rd and 6th grade students.
As a robustness exercise, we check if findings could be biased by non-observable
characteristics that do not change with time and estimate program impacts on differences in
student learning while controlling for individual fixed effects. Column (4) presents the results.
We do not find qualitative changes to the previous results.
Next, we test if the effects we observe are a result of multiple hypothesis testing. Indeed,
we perform tests on 12 variables in four different models. Therefore, we perform 48 tests. We
would expect Type 1 error rejections in about five tests with a 10 percent significance level. We
address this issue by focusing on adjusting p-values for family-wise error rate (FWER) as in
Haushofer and Shapiro (2013). Column (6) shows that we cannot reject the null of no effects
once multiple inference issues are accounted for. Indeed, academic and non-academic tests are
not statistically significant for either grade.
Therefore, we conclude from these exercises that the substitution of textbooks by laptops
did not have an effect on student performance in a statistically significant way. Moreover, if we
aggregate the academic and non-academic performance measures into one average indicator, we
find that the effect is precisely estimated around zero. For instance, when considering the
estimates using the specification of Column (3), we find a treatment effect of -0.05 for 3rd

Page 14 of 33

graders and 0.01 for 5th graders, which are not statistically different from zero even without
considering the FWER p-values.
A threat to our findings is that the substitution of textbooks by laptops may have caused a
change in student composition. Two scenarios could make this the case. First, families may have
transferred their children to a different school because of the program. However, we find this to
not have been the case as there were 2% of new students in schools with textbooks, and schools
with laptops had 0.8 percentage points fewer students (p=0.074). This small difference in student
composition probably cannot explain our results. Second, it could be that the substitution
affected dropout rates, and if that were the case, the remaining students would differ not only by
textbook or laptop position. They would also differ on their characteristics. We find that the
dropout rate between the baseline and follow-up rounds was 7%. The difference was not
statistically different between the two groups (p-value=0.859). Thus, we conclude that changes
in student composition did not affect our results.
We also analyze if effects vary across subgroups. However, we do not find heterogeneity
on the impact of substitution textbooks by laptops. More specifically, we test if effects vary
across students according to pre-intervention performance, socioeconomic status of the students,
pre-intervention dispersion in class performance, and age and education of the teacher. Yet, we
do not find any difference across any of these dimensions.5 Our interpretation of these results is
that this program mainly has an effect on the margin of substitution between digital and
traditional content, as the laptops did not have adaptive components or software (as emphasized
in the previous literature). Therefore, any difference between treatment and control groups comes
mainly from this feature.
6.2

Cost-effectiveness

In this section, we discuss the implications of our results through the lens of a costeffectiveness analysis. Our previous results imply that there are no differences in student
performance with laptop provision relative to the provision of textbooks. We now follow the
methodology suggested by Dhaliwal et al (2012) to estimate the cost-effectiveness of the
program. We state marginal costs to laptop provision relative to textbooks. Next, we describe
benefits. Finally, we discuss how program characteristics affect cost-effectiveness and include a
5

Results on heterogeneity effects are available upon request.

Page 15 of 33

sensitivity analysis. We conclude the intervention is most likely cost-effective. Considering a
very conservative scenario, we find that the substitution of three additional textbooks would
guarantee the intervention to be cost-effective.
Table 5 presents a list of marginal benefits and costs relative to textbook provision. In
Panel A, we present a list of differential costs. We assume that laptops depreciate linearly over
four years and assume that the rental price of a laptop is one fourth of its price, or US$76. We
also consider other costs including technical assistance provided at US$5 per student. In addition,
Internet and laptop running costs were US$9 per student, and principal training was US$5 per
student. We do not include costs for teacher training because both treatment and control teachers
received training. Panel B lists differential benefits. We start by considering the differential cost
of savings by replacing textbooks by laptops. Each textbook had a cost of US$14 per child per
year. Laptops replaced two books. Thus, this replacement implies savings of US$28.
Next, we estimate a digital literacy premium derived from the program. The
questionnaires present information on digital literacy for treated students. The results imply that
students that received laptops were familiar with basic applications. Indeed, over 90% of them
could write a word and draw a circle using a computer, as well as access online materials. In
addition, over 90% of students could access information on the server on a specific subject for
their grade. We do not have information available for the students who did not receive laptops,
but given the much lower use of computers and Internet in these schools, it is highly likely that
these abilities are not present to this extent for most students in the control group. For instance,
as we mentioned above, just 7% of students in the control group reported to use Internet at
school.
Next, we estimated the returns to digital literacy. There is much literature on the topic
starting from the influential study by Krueger (1993) that finds a high correlation between
computer use and wage. More recently, the World Bank (2016) also cites high correlations
between computer use and Internet use and wages in different places. However, a more
complicated challenge is to find the causal impact of digital literacy, as DiNardo and Pischke
(1997) argue. One interesting paper that tries to deal with this point is Blanco and L√≥pez-Boo
(2010), who implemented an audit study in two Latin American cities in which they send fake
curricula that randomly signal digital literacy. They find increases in callback rates from 11-12%.
Page 16 of 33

Thus, we take from this paper that there seems to be causal effect of digital literacy on wages in
Latin America. We take a very conservative stand and assume a one percent wage premium for
digital literacy, which corresponds to a very low number in comparison to the correlations
reported in Krueger (1993), the World Bank (2016) and other papers. We then perform
sensitivity analysis on this premium.
We assume students are 10 years old at the moment of evaluation. We assume they will
work as adults for 30 years starting when they are 18 years old. Students achieve the average
years of schooling for the country at 11 years, and 4.5% of them will be unemployed (CIA,
2015). Therefore, the expected wage for a student is US$206. We use an interest rate of 10% and
an exchange rate of 20 lempiras per USD. We assume that only individuals in the labor market
get returns from digital literacy, and we use the observed participation rate in the labor market in
2013 in Honduras of 53.7%.6 Under the base scenario, the expected estimated gain in wages
provided by digital literacy was US$35.
Therefore, the difference between laptop benefits and costs in this program results in a
deficit of US$32 per child per year, and in this scenario, the substitution of three additional
textbooks would ensure the intervention to be cost-effective.
Table 6 presents the sensitivity of the calculations to changes in the interest rate and the
wage premium to digital literacy. Gains for digital literacy are realized during the work life of an
individual, and as a result, high discount rates decrease the value of benefits today. A wage
premium of 5% or higher would ensure gains of interest rates up to 12%. On the other hand, no
digital gains ever imply the intervention to be cost-effective.7
We would like to highlight three intervention characteristics relevant to this result. First,
we consider a scenario where laptops replace more textbooks. Indeed, laptops require a large
fixed cost. However, the marginal cost of providing contents is lower. The substitution of three
more printed books would guarantee computers to be more cost-effective in this program. Indeed,
the laptops had 23 reading books preloaded in pdf format. If teachers and students use these
6

Observatorio Econ√≥mico y de Emprendimiento, Universidad de Honduras. http://oee.iiesunah.org/index.php/mercado-laboral/tasa-de-participacion retrieved on July 2, 2015. Assume all individuals in or out
of the labor market benefit from digital literacy. Then, the cost of laptop provision per child-year is US$10.
7
We implemented other sensitivity analyses that we do not report. For instance, if computers last about 7 years
(instead of 4 as we assume in our base scenario), even the substitution of two textbooks using laptops would be costeffective.

Page 17 of 33

books to replace printed books, then the gains are enough to make the intervention efficient.
Unfortunately, we do not have data to check if this was indeed the case.
Second, we would like to highlight that the cost of laptops is variable and decreasing. For
example, the cost of computers for the Open Learning Exchange Program (OLE) in Nepal in
2010 was US$225 each. The provision of laptops in Montevideo in 2009 was US$260 each, and
the provision of computers in Honduras in 2013 was US$303 per laptop. Laptops have become
less costly over time. Barsyk and MacDonald (2001) estimated that between 1996 and 2000
prices dropped by 0.5% monthly. Nelson et al. (1994) estimated an annual decline in average
computer price of 25% between 1984 and 1991. Indeed, many laptop providers expect this trend
to continue. For example, the OLPC started with a cost of US$188 in 2006, and the CEO
announced as a goal to provide laptops for US$100 by 2008 and of US$50 by 2010. 8 However,
these targets have not yet been met.
Third, evaluation after a few months of exposure to laptops may bias cost-effectiveness
towards zero. This would be true under two scenarios. To start with, the costs of
complementarities can almost double the cost when laptops are delivered the first time. For
example, the provision of One Laptop per Child (OLPC) in India had a cost of US$461 per
laptop. However, the laptop itself was only a part of this cost. Indeed, each laptop had a cost of
US$229. The rest of the cost covered shipping, chargers, maintenance (10% yearly), training,
servers, procurement and back office support.9 Running costs were lower. They were estimated
at 10% of laptop costs yearly. This is important for our analysis. It is unlikely that future
provision of the Educatracho program will demand principal training in the use of technology. If
this is the case, the substitution of two more books would be enough to make the intervention
cost-effective.
Another reason is that educational programs usually take time to have an impact on
educational outcomes. Changes in the school community usually imply an adjustment cost. This
results in an offsetting effect of performance gains. In such scenario, our estimation provides a
lower bound. In addition, exposure to laptops was shorter than that of new books. Assume new
books are at least as effective to aid learning as old books. In this case, any gains in the control
8

Source: http://www.theverge.com/2014/1/7/5286050/olpc-xo2-xo-10-tablets-vivitar retrieved July 2nd, 2015
Source: http://www.olpcnews.com/sales_talk/price/490_per_xo_laptop_the_real_cos.html as retrieved July 2nd,
2015
9

Page 18 of 33

group associated with new books was compensated by laptop exposure. Thus, our estimation in
this scenario also provides a lower bound.
We conclude that the replacement of three more textbooks by laptops would make the
intervention cost-effective. We believe this is likely the case. As we mentioned above, laptops
included 23 books in pdf formats. In addition, laptops increased Internet access which may
further bring other benefits. Moreover, evidence shows that laptop cost and provision in the
future is likely to decrease. As a result, future laptop provision will probably be more costefficient.
7.

Conclusions

The use of laptops in schools has become popular under the premise that laptops will
facilitate student learning, and therefore, technology will improve the quality of education
(World Bank, 2016). Indeed, laptops may provide access to more resources. Laptops may
provide many texts in electronic format in its memory. In addition, laptops may allow for access
to the World Wide Web. However, laptops may be distractive to learning tasks. How students
would be affected by replacing books with laptops remained an empirical question. We answered
the question for elementary school students in Honduras.
We found textbook replacement with laptops did not affect student learning after one
school year using a randomized controlled trial with 271 schools and 6,500 students. We also
implemented a cost-effectiveness analysis to compare expected results of this replacement of
textbooks using laptops. Laptops have a higher initial fixed cost than books and impose variable
costs, such as electricity, Internet and maintenance. However, the marginal cost of providing
additional content decreases.
We estimate that minimum gains for laptops to be cost-effective relative to books.
Assuming a very conservative 1% wage return on digital literacy associated to the program, we
estimate that laptops need gains additional to books of US$32 per year. This is equivalent to the
cost of 2.3 extra books. Thus, this work contributes to the literature that explores how to provide
educational services in a cost-effective manner.
Our research highlights limitations relevant for future work. First, our results correspond
to one year of program exposure. The impact of the program during a longer exposure may
Page 19 of 33

enhance our understanding on how technology affects student learning. In particular, it would be
interesting to explore the effects of laptops after its four years of working life. Second, some
literature points to adaptability of software as a determinant to learning efficiency. We only
explore how format provision changed student learning. Future work may test how specific
software features affect its role in providing content information. Third, our results are sensitive
to assumptions on student‚Äôs benefits derived from Internet access, communication technologies
and digital literacy. However, we do not have good causal estimates of the returns on these
computer features. More information on how students benefit from computer use in the long run
would provide useful information to inform policy regarding laptop provision. Fourth, a relevant
area to explore is how freedom of choice may impose a cost control on users. More specifically,
laptops may make it difficult for students to focus on learning tasks. Students may get distracted
by games, music or social communication features.
Finally, the developed world has shifted a significant amount of reading resources from
printed to electronic versions (Liu, 2006). Laptops may provide opportunities to students in
developing countries. However, more work is needed to understand how to ensure benefits. Our
study is consistent with quantitative and qualitative studies in that laptop provision can be as
effective to deliver content as textbooks. In addition, laptops provide access to more information
through the internet. Laptops also allow for communication. In addition, they are computing
tools. We find that these additional features do not distract students from learning in the short run.
If this is the case in the long run, then computer provision may soon become more cost effective
than textbook provision.

Page 20 of 33

References
Ama Baafra Abeberese, Todd J. Kumler. and Leigh L. Linden. "Improving Reading Skills by
Encouraging Children to Read in School: A Randomized Evaluation of the Sa Aklat Sisikat
Reading Program in the Philippines." Journal of Human Resources 49.3 (2014): 611-633.
Arias Ortiz, Elena and Cristia, Julian P. 2014. ‚ÄúThe IDB and Technology in Education: How to
Promote Effective Programs?‚Äù Technical Note No. IDB-TN-670. Inter-American
Development Bank. Washington, DC. http://publications.iadb.org/handle/11319/6550?localeattribute=en
Bando, Rosangela. 2013. ‚ÄúGuideliness for Impact Evaluation in Education Using Experimental
Design‚Äù. Technical Note No. IDB-TN-519. Inter-American Development Bank. Washington,
DC.
Banerjee, Abhijit, Shawn Cole, Esther Duflo and Leigh Linden (2007) ‚ÄúRemedying Education:
Evidence from Two Randomized Experiments in India‚Äù, Quarterly Journal of Economics
Volume 122, Issue 3, pp. 1235-1264.
Banerjee, Abhijit and Esther Duflo (2014) ‚Äú(Dis)organization and success in an economics
MOOC‚Äù American Economic Review, Vol 104, No.5.
Baron, Naomi S. (2015) "How E-Reading Threatens Learning in the Humanities," Chronicle of
Higher Education, February 24.
Barrera-Osorio, Felipe and Leigh Linden (2009) "The Use and Misuse of Computers in
Education: Evidence from a Randomized Controlled Trial of a Language Arts Program.".
Mimeo, UT-Austin.
Barrow, Lisa, Lisa Markman and Cecilia Elena Rouse (2009). "Technology's Edge: The
Educational Benefits of Computer-Aided Instruction," American Economic Journal:
Economic Policy, American Economic Association, vol. 1(1), pages 52-74, February.
Barsyk and MacDonald (2001) ‚ÄúThe Treatment of Quality Change for Computer Price Indexes.
A Review of Current and Proposed Practices‚Äù. Statistics Canada ‚Äì Catalogue No.
62F0014MPB, Series No. 16.
Beuermann, Diether W., Julian Cristia, Santiago Cueto, Ofer Malamud, and Yyannu CruzAguayo. 2015. "One Laptop per Child at Home: Short-Term Impacts from a Randomized
Experiment in Peru." American Economic Journal: Applied Economics, 7(2): 53-80. DOI:
10.1257/app.20130267
Blanco, Mariana and L√≥pez B√≥o, Florencia, 2010. "ICT Skills and Employment: A Randomized
Experiment," IZA Discussion Papers 5336, Institute for the Study of Labor (IZA).
Borkun, Evan, Fang He, and Leigh Linden (2012) ‚Äú"The Effects of School Libraries on
Language Skills: Evidence from a Randomized Controlled Trial in India.". Mimeo, UTAustin.

Page 21 of 33

CIA: Central Intelligence Agency. 2015 ‚ÄúThe World Factbook‚Äù Central Intelligence Agency of
the United States of America. Electronic link: https://www.cia.gov/about-cia/todayscia/index.html as consulted on June 28th, 2015.
Cristia, Juli√°n P., Ibarrar√°n, Pablo; Cueto, Santiago; Santiago, Ana; Severin, Eugenio. 2012
‚ÄúTechnology and Child Development: Evidence from the One Laptop per Child Program‚Äù.
IDB Working Paper Series No. IDB-WP-304. Inter-American Development Bank,
Washington, DC.
Daniel, David B. and Woody, W. D. ‚ÄúE-textbooks at what cost? Performance and use of
electronic v. print texts‚Äù Computers and Education. Volume: 62 Pages: 18-23.
Dhaliwal, Iqbal; Duflo, Esther; Glennerster, Rachel; and Tulloch, Caitlin. 2012. ‚ÄúComparative
Cost-Effectiveness Analysis to Inform Policy in Developing Countries: A General
Framework with Applications for Education‚Äù. Abdul Latiff Jameel Poverty Action Lab (JPAL). MIT. Cambridge, MA.
DiNardo, John and Jorn-Steffen Pischke. S. (1997) ‚ÄúThe Returns to Computer Use Revisited:
Have Pencils Changed the Wage Structure Too? Quarterly Journal of Economics, Vol. 112
(February 1997): 291-303.
Duflo, E., Dupas, P., & Kremer, M. (2011). Peer effects, teacher incentives, and the impact of
tracking: Evidence from a randomized evaluation in Kenya. American Economic Review,
101, 1739‚Äì1774. doi:10.1257/aer.101.5.1739
Duflo, Esther, Rachel Glennerster, and Michael Kremer. 2008. Using Randomization in
Development Economics Research: A Toolkit, Handbook of Development Economics, vol. 4,
chap. 61. Elsevier, 3895‚Äì3962. URL http://ideas.repec. org/h/eee/devchp/5-61.html.
Fernald, Lia C. H., Paul J. Gertler, and Lynnette M. Neufeld. 2008. ‚ÄúThe Importance of Cash in
Conditional Cash Transfer Programs for Child Health, Growth and Development: An
Analysis of Mexico‚Äôs Oportunidades‚Äù. Lancet. Mar 8, 2008; 371(9615): 828‚Äì837.
Gilbert, R. J. 2015. ‚ÄúE-books: A Tale of Digital Disruption‚Äù Journal of Economic Perspectives.
Volume: 29 Issue: 3 Pages: 165-184
Glewwe, Paul, Michael Kremer, and Sylvie Moulin. 2009. "Many Children Left Behind?
Textbooks and Test Scores in Kenya." American Economic Journal: Applied Economics,
1(1): 112-35.
Glewwe, Paul; Hanushek, Erick Alan; Humpage, Sarah D. and Ravina, Renato. 2011. ‚ÄúSchool
resources and educational outcomes in developing countries : a review of the literature from
1990 to 2010‚Äù NBER working paper series 17554. National Bureau of Economic Research,
Inc. https://ideas.repec.org/p/nbr/nberwo/17554.html
Grace Jeremy and Kenny, Charles (2003), ‚ÄúA Short Review of Information and Communication
Technologies and Basic Education in LDCs ‚Äì What is Useful, What is Sustainable?‚Äù
International Journal of Educational Development 23 (2003) 627-636.

Page 22 of 33

Haushofer and Shapiro (2013). ‚ÄúHousehold Response to Income Changes: Evidence from an
Unconditional Cash Transfer Program in Kenya‚Äù. Forthcoming.
He, Fang, Leigh L. Linden, and Margaret MacLeod (2008) ‚ÄúHow to Teach English in India:
Testing the Relative Productivity of Instruction Methods within the Pratham English
Language Education Program‚Äù. Mimeo. UT-Austin.
Holden, J. L. 2016. ‚ÄúBuy the Book? Evidence on the Effect of Textbook Funding on SchoolLevel Achievement.‚Äù American Economic Journal: Applied Economics 8(4): 100-127.
Kremer M., Brannen C, Glennerster R. 2013. ‚ÄúThe challenge of education and learning in the
developing world‚Äù. Science. 2013 Apr 19;340(6130):297-300. doi: 10.1126/science.1235350.
Krueger, Alan B., "How Computers Have Changed the Wage Structure: Evidence from
Microdata, 1984-1989," Quarterly Journal of Economics, CVIII (1993), 33-60.
Linden, L. (2008) ‚ÄúComplement or Substitute? The Effect of Technology on Student
Achievement in India‚Äù. Mimeo, UT-Austin.
Liu, Ziming, Print vs. electronic resources: A study of user perceptions, preferences, and use,
Information Processing & Management, Volume 42, Issue 2, March 2006, Pages 583-592,
ISSN 0306-4573, http://dx.doi.org/10.1016/j.ipm.2004.12.002.
Machin, Stephen, Sandra McNally, and Olmo Silva (2007). "New Technology in Schools: Is
There a Payoff?," Economic Journal vol. 117(522), pages 1145-1167, 07.
Malamud, O., and C. Pop-Eleches. 2011. ‚ÄúHome Computer Use and the Development of Human
Capital.‚Äù Quarterly Journal of Economics 126: 987-1027.
McEwan, Patrick J. ‚ÄúImproving Learning in Primary Schools of Developing Countries. A MetaAnalysis of Randomized Experiments‚Äù Review of Educational Research. October 7, 2014
doi:10.3102/0034654314553127
Merkt, Martin, Sonja Weigand, Anke Heier, Stephan Schwan, Learning with videos vs. learning
with print: The role of interactive features, Learning and Instruction, Volume 21, Issue 6,
December 2011, Pages 687-704, ISSN 0959-4752,
http://dx.doi.org/10.1016/j.learninstruc.2011.03.004.
Nelson, Randy A., Tim L. Tanguay and Christopher D. Patterson. ‚ÄúA Quality-Adjusted Price
Index for Personal Computers‚Äù. Journal of Business & Economic Statistics Vol. 12, No. 1
(Jan., 1994) , pp. 23-31 Published by: Taylor & Francis, Ltd. on behalf of American
Statistical Association Stable URL: http://www.jstor.org/stable/1391921
Raine, Lee; Zickuhr, Kathryn; Purcell, Kristen; Madden, Mary; and Brenner, Joanna. 2012. ‚ÄúThe
Rise of E-reading‚Äù. Pew Research Center. April, 5, 2012. Washington, DC.
http://libraries.pewinternet.org/2012/04/04/the-rise-of-e-reading/
Shao, Zeshu, Esther Janse, Karina Visser, and Antje S. Meyer (2014) ‚ÄúWhat do verbal fluency
tasks measure? Predictors of verbal fluency performance in older adults‚Äù Frontiers in
Psychology 5: 772.

Page 23 of 33

UNESCO, 2012. ‚ÄúICT in Education in Latin America and the Caribbean. A Regional Analysis of
ECT Integration and E-Readiness.‚Äù Institute of Statistics, United Nations Educational,
Scientific and Cultural Organization. Montreal, Canada.
http://www.uis.unesco.org/Communication/Documents/ict-regional-survey-lac-2012-en.pdf
[July 26th, 2016].
Urquiola, M. (2006). Identifying class size effects in developing countries: Evidence from rural
Bolivia. Review of Economics and Statistics, 88, 171‚Äì177. doi:10.1162/rest.2006.88.1.171
Wells, Casey Lee. 2012. ‚ÄúDo Students Using Electronic Books Display Different Reading
Comprehension and Motivation Levels than Students Using Traditional Print Books?‚Äù Ph. D.
Dissertation. Liberty University, Lynchburg, VA. November.
http://digitalcommons.liberty.edu/cgi/viewcontent.cgi?article=1663&context=doctoral
Westfall, P. H. & Young, S. S. (1993). Resampling-Based Multiple Testing: Examples and
Methods for p-Value Adjustment. John Wiley and Sons
Wook Ji, Sung, Sherri Michaels, David Waterman, Print vs. electronic readings in college
courses: Cost-efficiency and perceived learning, The Internet and Higher Education, Volume
21, April 2014, Pages 17-24, ISSN 1096-7516,
http://dx.doi.org/10.1016/j.iheduc.2013.10.004.
World Bank (2016) Digital Dividends. World Development Report 2016. The World Bank.
Wright, Sandra, April Fugett and Francine Caputa. Journal of Educational Technology & Society,
Vol. 16, No. 1, Innovative Technologies for the Seamless Integration of Formal and Informal
Learning (January 2013), pp. 367-379 Stable URL:
http://www.jstor.org/stable/jeductechsoci.16.1.367

Page 24 of 33

Beginning of classes

C

Math and
Spanish
textbook
delivery

T
Month:

End of classes

Jan

Laptop
delivery
Feb Mar

Math textbook
delivery (To
25% of
schools)

Apr

May

Jun
Jul
Aug
School year 2013

‚Üë
Ba s el i ne da ta
col l ecti on

Sep

Oct

Spanish
textbook
delivery

Nov

Dec

‚Üë
Follow up data
collection

Figure 1. Program and data collection timeline

Page 25 of 33

Table 1. Baseline and Follow-Up Sample Sizes
Instrument

Target

Baseline

Follow-up

Panel

Attrition

Principals

272

270

271

269

99.63%

Teachers

505

504

502

497

98.61%

Students

9601

9600

9318

8954

93.27%

Spanish
Math

9619
9620

9619
9620

9160
9209

8814
8869

91.63%

III. Non-academic tests
Verbal

9399

9121

9304

8859

9399

9104

9311

8850

I.Survey

II. Academic Test

Codes
Source: Own calculations

92.19%

97.13%
97.21%

Page 26 of 33

Table 2. Baseline Descriptive Statistics and Balance of Community, School and Teacher Characteristics

Variable

Control
(1)

Treatment
(2)

Difference
(3)

P-value
(4)

0.74
(0.44)

0.84
(0.37)

0.10
(0.05)

0.030

Border

0.11
(0.32)

0.12
(0.32)

-0.04
(0.04)

0.923

Number families beneficiary of
the Bono 10,000 program

22.73
(35.81)

27.82
(34.13)

5.09
(4.26)

0.182

0.562

195.05
(196.55)

165.82
(148.73)

-29.23
(21.22)

0.171

0.545

Students per teacher

29.16
(9.30)

30.76
(10.25)

1.60
(1.19)

0.157

0.231

Merienda Escolar lunch program

0.95
(0.21)

0.96
(0.21)

0.01
(0.03)

0.984

0.930

Principal with at least
technical/bachelor‚Äôs degree

0.89
(0.32)

0.91
(0.28)

0.02
(0.04)

0.493

0.558

39.26
(9.86)

37.29
(10.61)

-1.97
(0.92)

0.081

0.213

Male

0.32
(0.47)

0.38
(0.49)

0.06
(0.04)

0.184

0.356

Primary teacher degree

0.28
(0.45)

0.36
(0.48)

0.08
(0.04)

0.072

0.124

Teaching experience

15.60
(8.95)

14.14
(9.27)

-1.46
(0.82)

0.166

0.403

Assets index (PCA)

-0.000
(1.41)

0.00
(1.58)

-0.00
(0.13)

0.951

0.720

10.08
(1.89)

10.14
(1.84)

0.06
(0.04)

0.265

0.330

Enrolled in 3rd grade

0.52
(0.50)

0.52
(0.50)

0.00
(0.01)

0.895

0.633

Male

0.50
(0.50)

0.50
(0.50)

0.00
(0.01)

0.928

0.960

Mother can read

0.89
(0.31)

0.87
(0.34)

-0.02
(0.01)

0.089

0.294

Assets index (PCA)

0.11
(1.75)

-0.11
(1.70)

-0.22
(0.04)

0.161

0.961

Panel A. Community characteristics
Rural

Panel B. School characteristics
School size

Panel C. Teacher characteristics
Age

Panel D. Student characteristics
Age

P-value*
(5)

Page 27 of 33

Notes: P-values are for tests of the null hypothesis of equality of means. P-values include strata fixed effects.
The p-value for the joint prediction to allocation of treatment is 0.422 for the community and principal
variables, 0.357 for the community variables and 0.616 for the student‚Äôs variables.
* Estimation includes control for the rural status of the community.
Source: Authors' calculations.

Page 28 of 33

Table 2. Baseline Descriptive Statistics and Balance of Student Test Scores
Averages
Variable

Differences in means
Controls for
Controls for
students, teachers
rurality and
and school
frontier status
characteristics
(4)
(5)

Control

Treatment

No controls

(1)

(2)

(3)

0.02
(0.86)

-0.06
(0.84)

0.01
(1.00)
0.04
(0.98)

-0.02
(1.01)

-0.08
(0.07)
-0.03
(0.08)

0.01
(0.06)
0.05
(0.07)

0.03
(0.06)
0.07
(0.07)

-0.12
(0.07)

0.00
(0.78)

-0.08
(0.94)
-0.09
(0.76)

-0.10
(0.07)

-0.02
(0.06)
-0.04
(0.06)

-0.00
(0.06)
-0.05
(0.07)

Verbal

0.00
(1.00)

-0.16
(0.95)

-0.16**
(0.08)

-0.11
(0.08)

-0.10
(0.08)

Codes

0.01
(1.01)

-0.02
(0.97)

-0.03
(0.09)

0.03
(0.09)

0.01
(0.09)

0.03
(0.82)

-0.01
(0.84)

-0.05
(0.07)

0.02
(0.06)

0.01
(0.06)

Math

0.02
(1.00)

-0.01
(1.03)

-0.04
(0.09)

0.03
(0.08)

0.01
(0.08)

Spanish

0.03
(0.94)

-0.02
(0.94)

-0.05
(0.06)

0.00
(0.05)

0.01
(0.05)

0.00
(0.80)

-0.11
(0.67)

-0.11
(0.07)

-0.09
(0.06)

-0.09
(0.06)

Verbal

-0.00
(1.00)

-0.10
(0.88)

-0.10
(0.08)

-0.09
(0.08)

-0.10
(0.07)

Codes

-0.00
(1.00)

-0.11
(0.87)

-0.11
(0.08)

-0.10
(0.08)

-0.08
(0.08)

Panel A. 3rd grade
Academic tests
Math
Spanish
Non-academic tests

Panel B. 6th grade
Academic tests

Non-academic tests

Notes: Based on a sample of 9,600 students. The estimation of differences in columns (3) to (5) includes strata fixed
effects. The controls for column (5) are all the variables listed in Table 2.
Source: Authors' calculations.

Page 29 of 33

Table 4. Impact of substituting textbooks with laptops on student performance.
Difference of means of group with laptops minus group with
textbooks
Means in
group with
textbooks

No
controls

Controls
for rural
and
frontier
status

Controls for
students,
teachers and
school
characteristics

Difference
in
differences

P-value
FWER

(1)

(2)

(3)

(4)

(5)

(6)

0.59
(0.80)

-0.13**
(0.07)

-0.06
(0.06)

-0.08**
(0.04)

-0.07*
(0.04)

0.161

Math

0.63
(0.92)

-0.13*
(0.08)

-0.06
(0.07)

-0.09
(0.06)

-0.11**
(0.06)

0.303

Spanish

0.59
(0.86)

-0.14**
(0.07)

-0.06
(0.06)

-0.06
(0.04)

-0.04
(0.04)

0.303

Non academic
tests

-0.00
(0.61)

-0.05
(0.05)

-0.03
(0.05)

-0.02
(0.04)

0.05
(0.06)

0.938

Verbal

0.14
(0.95)

-0.07
(0.07)

-0.07
(0.07)

-0.01
(0.06)

0.09
(0.08)

0.938

Codes

-0.04
(0.66)

-0.04
(0.05)

-0.02
(0.05)

-0.03
(0.05)

-0.02
(0.09)

0.873

0.39
(0.79)

-0.10
(0.06)

-0.06
(0.06)

-0.08**
(0.04)

-0.07
(0.04)

0.139

Math

0.56
(1.03)

-0.13
(0.09)

-0.10
(0.09)

-0.14**
(0.06)

-0.10*
(0.06)

0.139

Spanish

0.32
(0.84)

-0.09
(0.06)

-0.05
(0.06)

-0.06
(0.04)

-0.05
(0.04)

0.303

Non academic
tests

-0.12

0.01

0.03

0.06

0.10

0.532

(0.60)

(0.05)

(0.05)

(0.05)

(0.06)

Verbal

-0.04
(0.82)

0.06
(0.07)

0.08
(0.07)

0.11**
(0.06)

0.15*
(0.08)

0.237

Codes

-0.17
(0.71)

-0.03
(0.06)

-0.01
(0.06)

0.02
(0.06)

0.07
(0.08)

0.938

Variable

Panel A. 3rd grade
Academic tests

Panel B. 6th grade
Academic tests

Notes: Based on a sample of 9,600 students. All estimation of differences in columns (3) to (5) include strata fixed
effects. The controls for column (4) are all the variables listed in Table 2. The p-values in column (6) are familywise error rate estimated following the methodology described in Haushofer and Shapiro (2013).
Source: Authors' calculations.

Page 30 of 33

Table 5: Benefits and costs for laptop and textbook provision per child-year.
Panel A. Costs
Laptop provision

-76

Laptop related technical assistance

-5

Internet and laptop running costs

-9

Principal training for the use of technology

-5

Panel B. Benefits
Textbook savings (2 books at US$14 each)

28

Digital literacy wage premium

35

Total

-32

Notes: Amounts expressed in 2013 USD. Environmental, computational or communicational
gains are assumed to be null.
Source: Authors‚Äô calculations.

Table 6. Scenarios for net present values for shifting from
textbooks to computers
Interest rate
3%

5%

10%

12%

0%

-67

-67

-67

-67

1%

136

63

-18

-32

5%

949

583

177

106

10%

1964

1234

422

278

20%

3996

2535

910

624

Wage premium to digital literacy

Notes: Amounts expressed in 2013 USD.
Source: Authors‚Äô calculations.

Page 31 of 33

APPENDIX A. Definitions of Variables Used in Tables in Text
Table A1: Definitions of Variables Used in Tables in Text
Individual outcomes

Definition

Spanish test score

Standardized score for Spanish.

Math test score

Standardized score for Mathematics.

Verbal test score
Code test score

Standardized number of correct answers in the
verbal test.
Standardized number of correct answers in the
codes test.

Individual characteristics
Age

Age in years.

Gender

1 if male, 0 if female.

Mother can read

1 if student‚Äôs mother writes and reads, 0
otherwise.
Index created, following Fernald et al. (2008),
using the first principal component of the

Assets index (PCA)

following assets present in the student‚Äôs house:
radio, television, refrigerator, stove, car,
computer and cellular phone

Teacher characteristics
Age

Age in years

Gender

1 if male, 0 if female
1 if the teacher has a bachelor degree in

Teacher has a bachelor degree in teaching

primary teaching, 0 otherwise (other advanced
bachelor or advanced degrees)

Teaching experience

Number of years working as a teacher
Index created, following Fernald et al. (2008),

Assets index (PCA)

using the first principal component of the
following assets present in the teacher‚Äôs house:

Page 32 of 33

radio, television, refrigerator, stove, car,
computer and cellular phone.
School characteristics
Total number of students

Total number of students in the school as
reported by the principal.
Total number of students over total number of

Students per teacher

teachers in the school as reported by the
principal.
1 if the principal reports that the children

Merienda Escolar

receive the Merienda Escolar lunch program at
the school, 0 otherwise
1 if the principal has a bachelor degree in

Principal with technical or bachelor

primary teaching, 0 otherwise (other advanced
bachelor or advanced degrees)

Community characteristics
Rural

1 if rural, 0 if urban.

Number families Bono 10.000

Total number of families within the
community that receive Bono 10.000 as
reported by the principal.

Page 33 of 33

