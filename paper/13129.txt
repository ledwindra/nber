NBER WORKING PAPER SERIES

THE FORWARD PREMIUM IS STILL A PUZZLE
Craig Burnside
Working Paper 13129
http://www.nber.org/papers/w13129
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2007

I thank John Cochrane, Martin Eichenbaum, Ravi Jagannathan, Sergio Rebelo, Michael Weber and
an anonymous referee for helpful comments, and the National Science Foundation for financial support
(SES-0516697). The usual disclaimer applies. The views expressed herein are those of the author(s)
and do not necessarily reflect the views of the National Bureau of Economic Research.
© 2007 by Craig Burnside. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.

The Forward Premium Is Still a Puzzle
Craig Burnside
NBER Working Paper No. 13129
May 2007, Revised July 2007, Revised June 2011
JEL No. F31,G12
ABSTRACT
Lustig and Verdelhan (2007) argue that the excess returns to borrowing US dollars and lending in
foreign currency "compensate US investors for taking on more US consumption growth risk," yet
the stochastic discount factor corresponding to their benchmark model is approximately uncorrelated
with the returns they study. Hence, one cannot reject the null hypothesis that their model explains
none of the cross-sectional variation of the expected returns. Given this finding, and other evidence,
I argue that the forward premium puzzle remains a puzzle.

Craig Burnside
Department of Economics
Duke University
213 Social Sciences Building
Durham, NC 27708-0097
and NBER
burnside@econ.duke.edu

Hanno Lustig and Adrien Verdelhan (2007) claim that aggregate consumption growth risk
explains the excess returns to borrowing U.S. dollars to …nance lending in other currencies.
They reach this conclusion after estimating a consumption-based asset pricing model using
data on the returns of portfolios of short-term foreign-currency denominated money market
securities sorted according to their interest di¤erential with the U.S. Based on their evidence
and additional U.S. data, I argue that consumption risk explains none of the cross-sectional
variation in the expected returns of their portfolios.
Standard theory predicts that the expected excess return of an asset, E(Rte ), is given by
cov(Rte ; mt ), where mt denotes some proposed stochastic discount factor (SDF). Therefore,
any risk-based explanation of the cross-section of returns relies on signi…cant spread, across
portfolios, in the covariance between the returns and the SDF. For the SDFs that Lustig
and Verdelhan (henceforth, LV) calibrate and estimate in their 2007 article, it is impossible
to reject that there is no spread in these covariances. In fact, it is impossible to reject that
these covariances are all zero.
LV’s SDF is linear in a vector risk factors, so they implement a widely-used two-pass
procedure to estimate its parameters. The …rst pass is a series of time series regressions
of each portfolio’s excess return on the risk factors. These regressions determine the factor
betas,

. When there are n portfolios and k risk factors,

is an n

k matrix. In LV’s
case n = 8 and k = 3. None of the individual elements of LV’s estimate, ^ , is statistically
di¤erent from zero. For each of the three factors, we also cannot reject the hypothesis that
all eight of the relevant elements of ^ are jointly zero. Confronted with this evidence, alone,
it would be reasonable to conclude that LV’s model does not explain currency portfolios
sorted on interest rates.
The statistical insigni…cance of the factor betas implies that LV’s measure of the SDF is
also uncorrelated with the excess returns that they study. To demonstrate this, I consider
three calibrations of the parameters of the SDF in order to construct time series for mt :
(i) the SDF parameters corresponding to LV’s two-pass estimates, (ii) LV’s Generalized
Method of Moments (GMM, Lars P. Hansen 1982) estimates of the SDF parameters, and
(iii) Motohiro Yogo’s (2006) estimates of the SDF parameters based on stock returns. I then
run a series of time series regressions of each portfolio’s excess return on the resulting mt
series. In each case, I …nd that estimated SDF betas are jointly statistically zero. This,
again, suggests that LV’s model does not explain the returns to their currency portfolios.

1

The second pass component of LV’s estimation procedure is a cross-sectional regression
of average portfolio returns on the betas. This regression determines the lambdas, , a k

1

vector of factor risk premia. There are two problems with LV’s estimates of . First, they
focus almost entirely on standard errors for ^ that treat the betas, , as known regressors,
rather than generated regressors. With these standard errors ^ appears to be statistically
signi…cant, so LV draw favorable inference about their model.1 But treating

as known leads

to a misleading level of con…dence in the model. With conventionally calculated standard
errors (Shanken, GMM) none of the estimated factor risk premia in LV’s benchmark model,
and none of the parameters of the corresponding estimated SDF are statistically signi…cant,
except in cases where the model has very poor …t. Bootstrapped 95 percent con…dence regions
for these parameters always encompass zero. Consequently, I draw unfavorable inference
where they do not.
Second, for
to be identi…ed,
must have full column rank. Because most of the
elements of ^ are statistically close to zero, statistical tests indicate that the rank of is
very low, perhaps as low as 0. The identi…cation problem raises two important issues. First,
and most importantly, it weakens inference in the sense that tests of the pricing errors based
on the second pass regressions have little power to reject misspeci…ed models (Raymond
Kan and Chu Zhang, 1999a; Craig Burnside, 2010). Second, con…dence regions for estimates
of the factor risk premia,

, generated using asymptotic standard errors become unreliable

(Kan and Zhang, 1999b). Using methods that are robust to weak identi…cation, I show that
LV’s data contain almost no information about . This reinforces the unfavorable inference
I draw regarding their model.
In their reply, LV defend their …ndings on four main grounds. First, they discard most of
my comment as an obscure discussion of sampling uncertainty as opposed to point estimates.
It is true that I do not dispute their point estimates; this comment is not a trivial report on
errors in LV’s code for ordinary least squares (OLS). Unfortunately, however, until data sets
are in…nitely large, inference will involve both point estimates and standard errors. In their
original article, LV clearly recognize the importance of statistical signi…cance for inference.
They repeatedly refer to the statistical signi…cance of their estimates and to the results of
1

There are seven tables of parameter estimates in the original article. The standard errors computed in
the …rst six tables treat the betas as known. The standard errors computed in the last table e¤ectively treat
the betas as unknown, but they cannot be compared to the standard errors in the rest of the article, because
they are calculated for a di¤erent model (one without a constant). They are also calculated incorrectly, as I
explain below.

2

statistical tests. Once inference is conducted properly, however, there is little support for
LV’s model.
Second, they appeal to a robustness check, described in their article, in which additional
tests assets (six equity portfolios and …ve bond portfolios) are included in the model estimation. The inclusion of these test assets, however, has little e¤ect on my conclusions. One
still cannot reject the null hypothesis that the covariances between the excess returns of LV’s
currency portfolios and the SDF are all zero. Thus, regardless of the statistical signi…cance of
the parameters that determine the factor loadings in the SDF, I cannot reject that the model
predicts that E(Rte ) = 0 for all of the currency portfolios. Including more test assets leads
to modest improvement on the identi…cation front, largely because the equity portfolios are
correlated with one of the model’s risk factors: the return to the aggregate US stock market.
Not surprisingly, this leads to some estimates of the model parameters being statistically
signi…cant. However, the model still does not explain the cross-section of foreign currency
risk premia. The R2 for the currency portfolios alone is at best roughly zero, indicating that
the model cannot explain why some currency portfolios have signi…cantly positive returns
while others have signi…cantly negative returns.
Third, LV refer to empirical evidence not in their original article. As in their more
recent paper with Nick Roussanov (2009), they construct a new set of seven portfolios from
their original set of eight portfolios by considering strategies whereby the investor short
sells the low interest rate portfolio while going long in one of the seven higher interest
rate portfolios. Evidence regarding the seven “di¤erenced” portfolios a¤ects none of my
conclusions. Most importantly, since these portfolios are linear combinations of the original
portfolios one cannot reject the null hypothesis that the covariances between the excess
returns of the “di¤erenced” portfolios and the SDF are all zero, and, therefore, one cannot
reject the null hypothesis that the model predicts E(Rte ) = 0 for all of the “di¤erenced”
portfolios. Also, because the “di¤erenced”portfolios are smaller in number, and are formed
as linear combinations of the original portfolios, working with these portfolios can only make
the identi…cation problem worse.
Finally, LV bring to bear additional evidence based on the recent …nancial crisis. They
argue that the …nancial crisis, alone, is su¢ cient evidence that their consumption-based
model works. Indeed, the …nancial crisis is a single observation that suits their hypothesis.
Consumption growth fell, and currency returns were negative, in late 2008. However, I show

3

that carry trade returns and consumption growth are uncorrelated over the full post-Bretton
Woods period. Carry trade returns are correlated with stock returns in the post-Bretton
Woods period, but the market beta of the carry trade is far too small to explain its high
average return. I also establish that there is only a very weak tendency of the market beta
of carry trade returns to increase during US recessions, and periods of stock market turmoil.
This casts doubt on any simple explanation of the returns to the carry trade based on market
risk.
I conclude that, taken as a whole, the evidence for LV’s consumption-based model is
extremely weak. I cannot reject that the model-predicted expected returns of the currency
portfolios they study are all zero. In their reply, LV conclude by arguing that had the
researchers of 25 years ago been confronted with their results, there would never have been
a “forward premium puzzle.” I am alive now, and I have read their article. The forward
premium is still a puzzle.
In Section 1 I brie‡y review LV’s model, data and methodological approach. In Section
2, I present the …rst-pass estimates of the betas that underlie their estimates of the factor
risk premia and demonstrate that there is little evidence of signi…cant covariance between
the portfolio returns and the risk factors. In Section 3, I discuss the second-pass estimates
of the factor risk premia and the interpretation of the pricing errors, and calculate standard
errors for factor risk premia that correctly account for estimation of the betas. I discuss
robustness of my negative …ndings in Section 4. Section 5 concludes.

1

Model, Data, Estimation and Inference

LV work primarily with a log-linearized version of Motohiro Yogo’s (2006) model, in which
the stochastic discount factor is given by
mt = [1

b c ( ct

c)

bd ( dt

d)

br (rW t

r )]:

(1)

Here ct represents the logarithm of a representative household’s consumption of nondurable
goods, dt is the logarithm of the household’s durable consumption, rW t is the logarithm of
the gross aggregate return to wealth,

c

= E ( ct ),

d

= E( dt ) and

r

= E(rW t ).

LV study the returns to borrowing U.S. dollars in the money market to …nance shortterm securities denominated in foreign currency. They form eight portfolios of such positions,
which are created by sorting the currencies according to their interest di¤erential versus the
4

U.S. I refer to these portfolios as P1, P2, : : : , P8 with the order running from low interest
rate currencies to high interest rate currencies.2
LV estimate the model by exploiting the null hypothesis that the approximated stochastic
discount factor (SDF), mt , prices the n 1 vector of portfolio excess returns, Ret . The pricing
equation is
E(Ret mt ) = 0:

(2)

I rewrite (1) generically as
mt = [1
where ft is a k

1 vector of risk factors,

)0 b],

(ft

(3)

= E(ft ), b is a k

1 vector of coe¢ cients, and

is a scalar representing the mean of the SDF.

1.1

The Beta Representation and Two-Pass Regressions

It follows from (3) and (2) that

where

is a n

E(Ret ) = cov(Ret ; ft )b = cov(Ret ; ft )
|
{z

k matrix of factor betas,

is a k

f

1
f b:
}|{z}

1 vector of factor risk premia, and

(4)

f

is the covariance matrix of ft .
LV estimate

and

using a two-pass procedure associated with Eugene Fama and James

D. MacBeth (1973). The …rst pass is a time series regression of each portfolio’s excess return
on the vector of risk factors:
eRite = ai + ft0
Here

0
i

i

+

it ,

t = 1; : : : ; T , for each i = 1; : : : ; n:

(5)

represents the ith row in . LV estimate the system of equations represented by (5)

using equation-by-equation OLS. Given (4), the second pass is a cross-sectional regression
of average portfolio returns on the estimated betas:
0
Rie = ^ i +

i,

i = 1; : : : ; n;

PT

(6)

Rite , ^ i is the OLS estimate of i obtained in the …rst stage, and i is a
0
0
pricing error. Let the OLS estimator of be ^ = ( ^ ^ ) 1 ^ Re , where Re is an n 1 vector
where Rie =
2

1
T

t=1

Further details of the model, portfolio formation, and data sources can be found in LV’s article.

5

formed from the individual mean returns. The model’s predicted mean returns are ^ ^ and
the pricing errors are the residuals, ^ = Re ^ ^ .
The model’s …t is assessed using the following statistic:
(Re
(Re

R2 = 1
•e =
where R

1
n

Pn

i=1

^ ^ )0 (Re
• e )0 (Re
R

^ ^)
;
•e)
R

(7)

Rie is the cross-sectional average of the mean returns in the data.

The model is tested on the basis of the estimated pricing errors using the statistic C ^ =
p
T ^ 0 ^ 1 ^ , where ^ ^ is a consistent estimator for the asymptotic covariance matrix of T ^
^

and the inverse is generalized. John H. Cochrane (2005) discusses how to form ^ ^ and shows
d

that C ^ !

2
n k.

It is common to include a constant in the second-pass regression as follows:
Rie =

0

+ ^ i + ui ,

i = 1; : : : ; n:

(8)

The constant, , is often interpreted as the model’s pricing error for the risk free rate, but
this error is shared by all assets. The statistical argument for running the regression without
the constant is that we know with certainty that the excess return to a risk free asset, or any
other zero-beta asset, is zero. One argument for including the constant is the notion that
the risk free rate is imperfectly measured as the real return on T-bills.

1.2

GMM Estimation

Cochrane (2005) describes a GMM procedure that produces the same point estimates as the
two pass regression method, but allows for heteroskedasticity-robust inference. When the
constant is included in the model the moment restrictions are
E(Rite
E[(Rite

0
i ft )

= 0,

i = 1; : : : ; n:

(9)

0
0
i ft )ft ]

= 0,

i = 1; : : : ; n:

(10)

) = 0,

i = 1; : : : ; n:

(11)

ai
ai

0
i

E(Rite

When the constant is excluded from the model, the last set of moment restrictions is replaced
by
E(Rite

0
i

) = 0,

i = 1; : : : ; n:

In both cases, an identity matrix is used to weight the moment conditions.
6

(12)

The model can also be estimated using a GMM procedure that treats the SDF as the
primary object of interest. This procedure, described in more detail in Cochrane (2005),
estimates the model, (3), using the moment conditions:
EfRet [1

(ft

)0 b]g = 0

(13)

) = 0

(14)

E(ft
The parameter

is unidenti…ed and is set equal to 1. The moment condition (13) can also

be modi…ed to allow for a common pricing error across assets:
EfRet [1

)0 b]

(ft

g = 0:

(15)

As described in the online appendix, the GMM procedure based on (14) and (15) can be set
up so that it is numerically identical to the two-pass regression method in terms of pricing
errors.3

2

First-Pass Estimates of Betas

Like LV, I compute …rst-pass estimates of the betas by running the least squares regressions
described by (5). I compute standard errors using standard system OLS formulas, as well
as GMM-based procedures. I also calculate 95 percent con…dence regions using a bootstrap
procedure. Using any of the these procedures, none of the 24 estimated betas is individually
statistically signi…cant at the 5 percent level.4 More importantly, when there is spread in
the expected returns across portfolios, there should also be statistically signi…cant spread
in the betas across portfolios. With this in mind, we can test whether for each factor the
eight factor betas are jointly signi…cantly di¤erent from zero. As Table 1(a) indicates, at
conventional signi…cance levels one cannot reject the hyptheses that

ij

=

j

8i, and

ij

=0

8i, for each factor j = 1, : : : , k. Since the contribution of factor j to the vector of modelpredicted expected returns is

j j

the latter hypothesis tests imply that one cannot reject

the null that each factor’s risk premium contributes nothing to the model-predicted expected
returns.
^ where ^ f sample covariance matrix of ft , this estiIf an estimate of
is computed as ^ = ^ f b,
mate is identical to the two-pass estimate of . The equivalence of the GMM and two-pass procedures is
demonstrated in the online appendix.
4
Due to space limitations I report full tables of betas in the online appendix. The GMM-based standard
errors I present are computed using a variant of the VARHAC procedure described by Wouter J. den Haan
and Andrew T. Levin (2000). I use VARHAC standard errors to take into account possible serial correlation
in GMM errors.
3

7

In their reply, LV mistakenly argue that I have only looked at individual betas, when,
in fact, in every version of my comment, including this one, I have tested for spread in
the betas. Second, they argue that I should have looked at univariate betas rather than
multivariate betas. This is puzzling, given that multivariate betas are what appears in the
beta representation, (4), and what enters into the second-pass regression. Certainly, one can
de…ne the matrix of univariate betas,

u

= cov(Ret ; ft )Df 1 , where Df is a matrix with the

variances of the factors on the diagonal, and zeros o¤-diagonal. This leads to an alternative
beta representation in which E(Ret ) =

u

u

u

and

= Df b. It is perhaps more straightfor-

ward, however, to work with the SDF representation E(Ret ) = cov(Ret ; ft )b. The columns of
cov(Ret ; ft ) are proportional to the columns of
cov(Ret ; ft )

u

. We can directly estimate the elements of

by GMM and then test whether cov(Reit ; fjt ) = cj 8i, and cov(Reit ; fjt ) = 0 8i. As

Table 1(b) indicates, these hypotheses cannot be rejected at conventional signi…cance levels.

It makes little di¤erence which betas we use, however, because what matters in the end
is how these betas are re‡ected in the covariance between the SDF and the portfolio returns.
Using (3), (2) can be rewritten as
E(Ret ) =
With the normalization

m

(16)

= 1, (3) implies that E(mt ) = 1, so we can rewrite (16) as
E(Ret ) =

where

cov(Ret ; mt )=E(mt ):

cov(Ret ; mt )=

2
m,

m

of mt ,
m

=

cov(Ret ; mt ) =
2
m

and

cov(Ret ; ft0 )b
2
m

2
m

is the variance of mt . Given the de…nition
u

=

(17)

m m;

2
m

=

2
m

u

(18)

:

Which set of factor betas we consider is immaterial, since the SDF betas,

m,

derived from

either are identical, and what matters is whether there is su¢ cient spread in the SDF betas.
To measure the SDF betas, we need data for mt , which can be constructed using (3), and
values for the elements of the vector b. Here I use three versions of b taken directly from
LV’s article.
In Table 2(i) I use the b vector corresponding to LV’s two pass estimates of : bc =

21,

bd = 130 and br = 4:5. Table 2(ii) uses the b vector corresponding to LV’s GMM estimates
of b: bc = 37, bd = 75 and br = 4:7. Table 2(iii) repeats the exercise using the b vector
corresponding to the calibrated model discussed in section I.E of LV’s article: bc = 6:7,
8

bd = 23 and br = 0:31. As Table 2 indicates, in all of these cases the null hypotheses that
im

=

m

for all i and

im

= 0 for all i cannot be rejected. In other words, there is no spread

in the betas, and they are jointly zero. Tests based directly on cov(Ret ; mt ) rather than

m

reach the same conclusion but are not reported in the table.
Given that the SDF betas are jointly statistically insigni…cant, I conclude that LV’s model
does not explain the cross-section of the expected returns of their portfolios. In Section 4 I
show that this …nding is robust to (i) estimates of the SDF based on an expanded set of test
assets including equities and bonds, (ii) using the seven “di¤erenced”portfolios emphasized
in their reply, and (iii) a higher frequency, post-Bretton Woods, developed-country, database
that extends through the recent …nancial crisis. Thus, the message of this comment is immune
to the points emphasized by LV in their reply.

3

Second Pass and GMM Estimates of the Model

The second pass and GMM estimates of the model provide us another opportunity to assess
LV’s proposed explanation of the cross-section of returns to foreign currency portfolios. Of
and b, the R2 measure of …t and the tests of

particular interest are the point estimates of
the pricing errors.

LV’s second pass regression, which includes the constant , is reproduced in Table 3.
When presenting their …ndings they show OLS standard errors, which assume that the …rstpass betas are known. Given these standard errors, the factor risk premia for consumption
and durables are both positive and highly statistically signi…cant. The R2 of the model is
0:87 and the p-value for the test for signi…cance of the pricing errors is 0:48. These results
are a key basis of LV’s positive assessment of the model.
There are three reasons our assessment should be less sanguine. The main one is that
OLS standard errors are inappropriate given the estimation of the betas, and this turns
out to matter a great deal for inference. Once standard errors are computed appropriately,
estimates of

and b are statistically insigni…cant. The latter …nding is especially important

because it suggests that the consumption factors do not help price currency returns. The
second reason to be skeptical is that the model performs much more poorly when we impose
the restriction that the constant is equal to zero. The b parameters remain insigni…cant, and
the …t of the model deteriorates substantially. The third reason to be doubtful about the
model estimates is that there is a severe identi…cation problem. Under non-identi…cation or
9

weak identi…cation, asymptotic standard errors (even arguably appropriate ones) are likely
to understate the degree of uncertainty about the model parameters.

3.1

Inference About Model Parameters

As Cochrane (2005) points out, the fact that the betas are estimated in the …rst pass matters
for inference about the factor risk premia, and this remains true asymptotically. There are
three standard ways to deal with this problem. One is to use the correction of the standard
errors suggested by Jay Shanken (1992). Another is to compute standard errors using the …rst
of the two GMM procedures described above, because it produces the same point estimates.
A third is to construct con…dence regions for the parameters using bootstrap methods. By
construction, the alternative approaches to calculating standard errors do not a¤ect the point
estimates of the factor risk premia. The three procedures lead to similar inference regarding
the model, and using them, rather than OLS standard errors, matters both qualitatively and
quantitatively.
The Shanken and GMM-corrected standard errors for the model with the constant (Table
3) are roughly two to three times larger than the OLS standard errors that ignore estimation
0 0
of the betas. Why is the Shanken correction so big? Let = (
),
= E( t 0t ) and
let ~ f be a matrix with a leading column and row of zeros, and f in the lower right corner.
p
When the betas are treated as known the covariance matrix of T (^
) is

=(

^

Here

+

) and

= (

+0

+

)

is an n

1

+0

+

(

+0

+

)

1

+ ~f:

(19)

1 vector of ones. With the Shanken correction the

covariance matrix is
^

= (1 +

0

1
f

)(

+0

+

)

1

+0

+

(

+0

+

)

1

+ ~f:

(20)

In some …nance applications the Shanken correction is small. For example, for the CAPM
estimated using the annual returns of Fama and Kenneth R. French’s (2003) 25 portfolios
sorted on size and book-to-market value over the period 1953–2002, the Shanken-correction
term, 1 +

2

=

2
f,

is estimated to be 1:03. In LV’s case the estimate of 1 +

0

1
f

is 6:79.

Although the individual s in LV’s model are of the same order of magnitude as for the
CAPM, the consumption factors have much smaller variance than the market return. This
blows up the size of the Shanken correction substantially.
10

Using either the Shanken or GMM standard errors, none of the estimated factor risk
premia in Table 3 are statistically signi…cant at the 5 percent level. The bootstrap-based 95
percent con…dence regions for the parameters also encompass 0. These results do not imply
that the price of consumption risk is zero. Instead, they indicate that the joint behavior of the
currency returns and consumption factors is uninformative about the price of consumption
risk.
LV defend the statistical signi…cance of their …ndings on three grounds. First, they appeal
to Ravi Jagannathan and Zhenyu Wang (1998) to defend the use of OLS standard errors
rather than the Shanken correction. This is inappropriate. Jagannathan and Wang’s point
is that under heteroskedasticity, the Shanken correction is inappropriate, and that more
general GMM errors are appropriate. Shanken’s proof that corrected standard errors are
necessarily bigger than OLS standard errors does not work for GMM standard errors. GMM
errors could be smaller than OLS standard errors, but in LV’s case they are not. Second,
in their footnote 11, they argue that the OLS standard errors are close in magnitude to the
GMM standard errors. This is because they inappropriately compare GMM standard errors
for the model without a constant, to the OLS standard errors for a model with a constant.5
The appropriate GMM standard errors are actually close in magnitude to the Shanken
standard errors. Third, they argue that standard errors from a bootstrap procedure are
small enough to make the estimated risk premia signi…cant. Rather than focus on bootstrap
standard errors, I use the entire distribution of bootstrapped estimates to show that 95
percent con…dence regions easily encompass 0.
It is especially important to know whether the consumption factors help to price the
currency returns. This requires us to focus on the parameter vector b. GMM estimates of b
for the model with the constant are found in Table 4. The …rst stage of GMM is equivalent
to the second-pass regression in terms of point estimates. I also show GMM estimates from
the second stage, and after iterating over the weighting matrix to convergence. At all stages
of GMM, the estimates of b are statistically insigni…cant for every risk factor. Bootstrapped
con…dence regions also easily encompass zero. Thus we cannot reject the null hypothesis that
consumption factors do not help price the cross-section of currency returns. The statistical
insigni…cance of the estimates of

is also robust to using this GMM procedure to estimate

the model (Table 5).
5

When LV report Shanken and HAC standard errors for the model without the constant, they appear to
use incorrect formulas, as detailed in the online appendix.

11

3.2

Imposing a Zero Intercept

Given the estimates in Table 3 the R2 of the model is 0:87, the cross-sectional mean absolute
pricing error (MAE) is 0:44 percent, and the test of the pricing errors fails to reject the
model regardless of how standard errors are calculated. The model’s high R2 is attributable
to the inclusion of the common pricing error parameter ^ that, by convention, is treated as
part of the model’s predicted expected returns. The theoretical model does not include a
constant and predicts that the expected returns depend only on the covariance between the
factors and the returns. So, whenever a constant is included in the second-pass regression
it is important to consider its economic and statistical signi…cance. In fact, as Table 3
indicates, the constant is big, implying a

3 percent per annum pricing error for the risk

free rate. Measurement error in the estimated betas, and resulting downward bias in the
estimated factor risk premia, can explain a positive pricing error for the risk free rate. So can
a liquidity premium in T-bills. But a large negative pricing error for the risk free rate is bad
news for the model. Like the other model parameters, however, the constant is statistically
insigni…cant when standard errors are calculated appropriately.
Table 6 presents two-pass estimates of the model obtained by imposing the restriction
that the constant is zero. In this case the factor risk premia for the consumption factors are
much smaller, none of factor risk premia are statistically signi…cant, the R2 is only 0:34, and
the mean absolute pricing error of the model is 1:17 percent.
Tables 7 and 8 present GMM estimates of the model without the constant. In the …rst
stage of GMM, none of the b coe¢ cients is individually signi…cant, nor are any of the elements
of . The R2 of the model is 0:34 and the MAE is 1:17 percent. Turning to the second stage
of GMM, I reproduce LV’s point estimates (their Table 14, Column C). Importantly, the R2
of the model is now negative ( 0:66), and the MAE is 1:86 percent. This is very bad news,
because it indicates that a constant would do a better job explaining the cross-sectional
distribution of the returns than the model does. While the individual s associated with
consumption and durables are statistically signi…cant, the b parameter is only signi…cant for
durables, and none of the parameters appears to be signi…cant based on the bootstrapped
95 percent con…dence regions. Further iterations on the weighting matrix lead to a further
deterioration of the model’s performance. The R2 of the model drops to

1:45 and the MAE

rises to 2:28 percent. The factor risk premium for durables is statistically signi…cant, but
none of the b parameters are signi…cant, and none of the parameters appears to be signi…cant
12

based on the bootstrapped 95 percent con…dence regions. In summary, the model …ts very
poorly absent the constant.

3.3

Weak Identi…cation

In this section I argue that we should be skeptical of LV’s model because it is very weakly
identi…ed as a consequence of the sampling uncertainty associated with ^ . In the second-pass
regression with the constant, the parameters
that
if

+

and

are identi…ed under the assumption

has full column rank. In the second-pass regression with no constant,

is identi…ed

has full column rank. When the rank conditions fail, conventional inference drawn from

second pass regressions and GMM is unreliable because standard asymptotic theory does not
^ have non-standard distributions,
apply. As Burnside (2010) discusses, t-statistics for ^ and b
and, most importantly, pricing-error tests cannot reliably detect model misspeci…cation.
The online appendix contains an extended discussion of the identi…cation problem. In it
I show that it is straightforward to test whether LV’s model is identi…ed using a rank test
from Jonathan H. Wright (2003). I show that it is not possible to reject that rank( ) = 1
+

and rank(

) = 2 at conventional signi…cance levels. This implies that both the model

without the constant, which needs rank( ) = 3, and the model with the constant, which
needs rank(

+

) = 4, are grossly underidenti…ed.

A standard tool for conducting inference under weak identi…cation is to construct con…dence sets for the weakly identi…ed parameters using the objective function corresponding
to the continuously updated (CU) GMM estimator. In the online appendix, I construct CUGMM based con…dence sets for the price of SDF risk,
set for

m

m.

The robust 95 percent con…dence

encompasses almost the entire real line. Thus currency portfolios are virtually

uninformative about the price of risk associated with LV’s SDF.

4

Robustness

In this section I consider the robustness of my …ndings to three considerations emphasized by
LV in their reply. First, I ask whether adding information from equity and bond portfolios
improves identi…cation and sheds additional light on whether the SDF prices the currency
portfolios. Second, I check whether considering a set of “di¤erenced” currency portfolios
a¤ects my conclusions. Third, I discuss additional evidence from higher frequency data in
the post-Bretton Woods period, including the relevance of the recent global …nancial crisis.
13

4.1

Equity and Bond Portfolios

LV, in their reply, argue that the results in Section IV.C of their original article are important,
because these show that the same SDF that prices currency portfolios also prices other test
assets, such as Fama and French’s (1993) six equity portfolios created by sorting stocks on
the basis of size and value, and …ve Fama bond portfolios (Center for Research in Security
Prices, 2007) created by sorting bonds on the basis of maturity. Indeed, additional test assets
could be useful because they might alleviate the identi…cation problem alluded to in Section
3.3. However, I …nd that these additional test assets have no e¤ect on my main conclusion,
that currency portfolios do not appear to be priced by consumption factors.
The main reason that adding additional portfolios does not change my conclusions is that
it does not change the factor betas for the currency portfolios. The tests in Section 2 still
apply. So, adding the equity and bond portfolios does not change my conclusion, based on
betas alone, that the model cannot explain di¤erences in expected returns across currency
portfolios.
Adding the six Fama-French equity portfolios to the set of test assets slightly alleviates
the identi…cation problem because equities have statistically signi…cant betas with respect
to the market return factor, rW . However, the rank tests presented in the online appendix
indicate that the

matrix still appears to have reduced rank. The identi…cation problem

does not go away with the further addition of the …ve Fama bond portfolios.
Estimates of the model without the constant using the currency and equity portfolios as
test assets are presented in the online appendix. As indicated there, with su¢ cient iterations
over the weighting matrix the factor risk premia for consumption growth and durables growth
are statistically signi…cant. However, the …t of the model with respect to currency portfolios
is very poor. When the R2 statistic is calculated just for currency portfolios it ranges from
0:03 (at the …rst stage of GMM) to

0:76 (for iterated GMM). The mean absolute pricing

error for the currency portfolios ranges from 1:44 (at the …rst stage of GMM) to 1:88 (for
iterated GMM).
Why do I compute these statistics just for currency portfolios? First, the goal is to
explain the cross-section of returns of currency portfolios. The R2 across all assets does
not tell us whether the model explains why some currency portfolios earn high returns and
others earn low returns. Instead, the R2 across just the currency portfolios tell us whether
the model explains why some currency portfolios (like P7) earn high returns, and other
14

currency portfolios (like P1) earn low returns, on average. Second, we are not trying to
explain why the currency portfolios all have relatively low returns (the average excess return
across LV’s eight currency portfolios is 0:1 percent) compared to the equity portfolios (the
average excess returns of the six Fama-French portfolios are all above 6 percent, and they
are centered near 9 percent). That is not a puzzle, given that currency portfolios are only
weakly correlated with risk factors that price equity portfolios. The puzzle is why the low
interest rate currency portfolio, P1, has an average return of

2:3 percent, and why the high

interest rate currency portfolios, P7 and P8, have average returns in excess of 2 percent.
Adding the …ve Fama bond portfolios does not improve the situation. At the …rst two
stages of GMM the results are quite similar to those obtained using only the currency and
equity portfolios, although further iterations over the weighting matrix eventually drive out
consumption growth and durables growth as signi…cant risk factors. Once again, the …t of
the model with respect to currency portfolios is very poor. If the R2 statistic is calculated
just for currency portfolios it ranges from 0:03 (at the …rst stage of GMM) to

1:35 (for

iterated GMM). The mean absolute pricing error for the currency portfolios ranges from 1:40
(at the …rst stage of GMM) to 1:64 (for iterated GMM).

4.2

Di¤erenced Currency Portfolios

In their reply, LV argue that they can explain the excess returns to the strategy of holding
Pi and shorting P1, for i = 2, : : : , 8. They claim that their article is really about these
seven “di¤erenced”portfolios, which I refer to as D2, D3, : : : , D8, and not really about the
original eight portfolios. Given that the entire article is about the P-portfolios this comment
is surprising, especially given the following statement in the original article: “consumptionbased models can explain the cross-section of currency excess returns if and only if high
interest rate currencies typically depreciate when real US consumption growth is low, while
low interest rate currencies appreciate”. Notice that these statements are not about whether
there is a di¤erence between the rates of return of the portfolios, it is a statement about the
rates of return themselves.
LV also argue for working with the D-portfolios on the basis that “large swings in the
dollar make it hard to accurately estimate the constant”, the constant being

in the model

for the P-portfolios. This argument is not persuasive because the intercept can be “estimated”with perfect accuracy. We know that the mean excess return of a zero beta asset is

15

zero, so we can set

equal to zero without even having to estimate it.

Nonetheless, what of LV’s point that the constant no longer plays an important role in
explaining the cross-section once we consider the seven D portfolios? LV are right, but this
point can easily be made without new tables of point estimates. Consider the model with
the constant. The estimates of the second pass regression satisfy:
0

Rie = ^ + ^ i ^ + u^i ;
This is equation (8) with

and

(21)

i = 1; : : : ; n:

replaced by ^ and ^ (the two-pass estimates) and ui

replaced by u^i (the idiosyncratic pricing error or residual). Now suppose we consider the
R1e , for i

new set of excess returns, Rid = Rie

2. Given the de…nition of Rid and equation

(21), it follows that the sample mean of Rid is given by:
Rid = ( ^ i

0^
1)

+ u^i

u^1 ;

(22)

i = 2; : : : ; n:

P1 is not just any asset. It happens to be an asset for which the SDF beta is roughly zero
u1 = 0). Using these facts in
( 01 ^ = 0) and the idiosyncratic pricing error is very small (^
equation (22), we have
0
Rid = ^ i ^ + u^i ;

(23)

i = 2; : : : ; n:

Now, since u^1 = 0 it also follows that the average value of u^i across i = 2; : : : ; n, is
roughly zero. Thus, the same ^ obtained by running the cross-sectional regression for the
P-portfolios, can approximately …t the cross-sectional distribution of Rid without a constant.
In their reply, it seems that LV concede that their model does not price the original
portfolios. But this means they have not identi…ed the true SDF. All of the portfolios (the
P and D-portfolios) should be priced by the same SDF. E¤ectively this means there must
be a missing factor that prices P1. Since this factor is responsible for the …t of the original
portfolios we are back to square one.
Are the D-portfolios priced by consumption growth? On the basis of factor betas the
answer is clearly “no”. The beta matrix for the D-portfolios is the same transformation of
the P-portfolios used to test whether they are equal to a common constant: i.e.,
where

=(

In

1

) and is an (n

not reject the null hypotheses that
hypotheses that

D
ij

=

P
ij

P
1j

P
ij

1)

D

=

P

1 unit vector. Not surprisingly, since we could

= 0 for all i, and each j, we also cannot reject the null

= 0 for all i, and each j. As Table 9 indicates, the p-values

associated with the test are 0:818 for consumption growth, 0:471 for durables growth and
16

0:186 for the market return. The SDF betas associated with the D-portfolios are also jointly
statistically insigni…cant (Table 10).
Working with the D-portfolios also does not alleviate the identi…cation problem. The
identi…cation problem arises because there exists at least one non-zero k

x = 0, statistically.

In fact, the identi…cation problem gets worse, because the transformation

is not invertible.

x = 0, statistically. Given the de…nition of

Any x such that
D

P

x = 0 implies that

x = 0 for which

P

D

D

1 vector x such

D

that

P

it follows that

x = 0. But there may be additional x such that

x 6= 0. This is hardly surprising, since throwing away information

is never likely to improve identi…cation. Formal test statistics verifying this are provided in
the appendix.

4.3

The Post-Bretton Woods Era

My comment mainly discusses the conclusions we should draw from LV’s evidence. Additional evidence from the post-Bretton Woods era, similar to the evidence introduced by LV
in their reply, casts further doubt on a consumption-based explanation of carry trade returns.
Here I discuss evidence gleaned from a sample of 21 developed-country currencies over the
period 1976–2010. The same sample of currencies is used by Burnside, Martin Eichenbaum,
Isaac Kleshchelski and Sergio Rebelo (2011) for the period 1976–2009, and similar samples
are used by Lustig, Roussanov and Verdelhan (2009) and Lukas Menkho¤, Lucio Sarno,
Maik Schmeling, and Andreas Schrimpf (forthcoming), for the period after 1983, to study
carry trade portfolios.
My data set consists of spot and forward exchange rates from Reuters/WMR and Barclays, available on Datastream. The raw data are daily observations of spot and one-month
forward exchange rates. I use end of month values of these data to create monthly observations. The data span the period January 1976 to December 2010, with the sample varying
by currency. As in Lustig, Roussanov and Verdelhan (2009), in each period, the available
currencies in my sample are sorted into six bins according to their forward discount against
the US dollar. The …rst bin includes those currencies with the smallest forward discounts
(the lowest interest rates), the second bin the next smallest, etc., with the sixth bin consisting
of those currencies with the largest forward discounts (and, therefore, the highest interest
rates). I then compute the payo¤ associated with borrowing one dollar in order to invest
equally in the riskless securities of the constituent currencies of each bin. This procedure

17

produces six currency portfolios that I refer to as Q1, Q2, : : : , Q6. Then, I follow the procedure advocated by LV in their reply. I construct the …ve di¤erenced portfolios, DQ2, DQ3,
: : : , DQ6, which involve holding Qi and shorting Q1, for i = 2, : : : , 6. I measure payo¤s to
these portfolios on a monthly basis, and then compute quarterly excess returns. To assess
the model I use data for consumption growth, durables growth and the market return that
are available from 1976Q2 to 2010Q1 (sources for these data are described in Burnside et
al., 2011, and in the online data archive).
Using these portfolios I …nd even stronger evidence against a consumption-based explanation of currency returns. As the detailed results in the appendix indicate, none of the
betas of the di¤erenced portfolios with respect to consumption growth and durables growth
are individually signi…cant. The point estimates also do not display any pattern of increasing
with the interest di¤erential. Not surprisingly, as Table 11 indicates, we cannot reject the
null hypotheses that

ij

= 0 for all i, for the consumption and durables factors. In this

sample, the currency portfolios are correlated with the market return, but the market betas
are small. They are roughly 0:08 for DQ2, DQ3 and DQ4, and 0:16 for DQ5 and DQ6.
The average excess returns of these …ve portfolios in the period 1976–2010 were, however,
about 1:75, 2:25, 3, 5:25 and 6 percent per annum, as compared to about 7 percent for the
stock market. The market betas would need to be …ve times larger for the CAPM to explain
currency returns. Finally, the SDF betas associated with these portfolios are also jointly
statistically insigni…cant (Table 12).
In their reply, LV make much of the fact that carry trades lost money during the recent
global …nancial crisis and other times of market turmoil. But I have never claimed that
…nancial turmoil and currency returns are unrelated. My comment centers on the fact
that currency returns and consumption growth are approximately uncorrelated with one
another. The global …nancial crisis is an observation that suits LV’s hypothesis, because it
is also an episode in which US consumption growth was low. The other crises (Mexican,
Asian, Russian, and Argentinian) that they mention in their reply are not, because they
did not coincide with periods of low US consumption growth. According to LV’s data,
durables growth was well above average through all of the latter episodes, while nondurable
consumption growth was well above average during two and slightly below average in two.
Overall, however, there is little evidence that average carry trade returns can be explained
by increased exposure to stock market risk during periods of recession, market downturns,

18

or market volatility. To demonstrate this, I …rst regress the monthly returns to the DQ6
portfolio (equivalent to LV’s HML carry trade portfolio) on the monthly excess returns of
the value-weighted US stock market (the CAPM factor). The market beta of DQ6 in the
period 1976M2–2010M12 is 0:18 and is statistically signi…cant. As in the quarterly sample,
this beta is much too small (by a factor of more than 5) to explain the average return of the
carry trade.
I then divide my data into recessions and expansions as de…ned by the NBER, periods
of high and low stock market volatility, and periods of high and low stock market returns.
To measure volatility, I use the daily standard deviation of the market excess return in each
month. Months in which this measure of volatility is more than one standard deviation
above its mean are denoted as “high volatility”. To divide the data into periods of high
and low stock returns, I denote months in which the market excess return is more than one
standard deviation below its mean as “low return”months. The market beta of DQ6 is 0:14
during expansions and 0:26 during recessions. It is 0:25 in periods of high volatility and 0:11
in other periods. It is 0:33 in periods of low stock returns and 0:15 in other periods. In each
case, however,the di¤erence between the two betas is not statistically signi…cant, and the
betas certainly remain insu¢ ciently large to explain the average returns of the carry trade.

5

Conclusion

To explain cross-sectional variation in expected returns, a risk-based story requires that assets with non-zero returns be correlated with the proposed SDF. As Section 2 demonstrates,
however, LV’s consumption-based SDF is approximately uncorrelated with all of the returns
they study. Given this fact, one cannot reject that LV’s estimates are consistent with consumption risk explaining none of the cross-sectional variation in the expected returns they
studied.
I have argued that the statistical insigni…cance of the SDF betas leads to two additional
problems with LV’s conclusions. First, it implies that one cannot ignore sampling uncertainty
in the betas when conducting inference about factor risk premia. The statistical signi…cance
LV point to largely vanishes when standard errors appropriately re‡ect this uncertainty.
Second, the degree of uncertainty about the betas implies that the factor risk premia are
very weakly identi…ed. This makes asymptotic inference less reliable. Con…dence sets that
are robust to weak identi…cation suggest that LV’s data are approximately uninformative
19

about consumption risk.
Finally, I have argued that LV are able to report strikingly high R2 measures of …t
because their model includes a constant pricing error, which is treated as part of the model’s
predicted expected returns. When this constant is excluded from the model, the R2 statistics
are much smaller and, in many cases, negative.
A central point of my discussion is that the betas of consumption factors are very poorly
estimated. This is why a consumption-based model is di¢ cult to reject using a formal test
of the pricing errors. If a great deal more data were collected, one might obtain su¢ ciently
precise estimates of the betas to enable sharper conclusions about the model. But with the
data we have, both LV’s data and high frequency data from the post-Bretton Woods period,
there is no justi…cation for drawing a strong conclusion in favor of a consumption-based
model. Burnside et al. (2011) have argued that out-of-sample risk is a potential explanation
for the returns to the carry trade. If these currently out-of-sample events occur in the future,
it may well turn out that a consumption-based model works. At the moment, however, a
model based on in-sample variation in consumption does not work.

20

REFERENCES
Burnside, Craig. 2010. “Identi…cation and Inference in Linear Stochastic Discount Factor
Models.”National Bureau of Economic Research Working Paper 16634.
Burnside, Craig, Martin Eichenbaum, Isaac Kleshchelski and Sergio Rebelo. 2011. “Do
Peso Problems Explain the Returns to the Carry Trade?”Review of Financial Studies,
24(3): 853–91.
Cochrane, John H. 2005. Asset Pricing, Revised edition. Princeton: Princeton University
Press.
Center for Research in Security Prices. 2007. “CRSP Monthly Treasury US Database
Guide.”http://www.crsp.com/documentation/pdfs/monthly_treasury.pdf.
den Haan, Wouter J. and Andrew T. Levin. 2000. “Robust Covariance Matrix Estimation with Data-Dependent VAR Prewhitening Order.” National Bureau of Economic
Research Technical Working Paper 255.
Fama, Eugene and Kenneth R. French. 1993. “Common Risk Factors in the Returns on
Stocks and Bonds.”Journal of Financial Economics, 33(1): 3–56.
Fama, Eugene and James D. MacBeth. 1973. “Risk Return and Equilibrium: Empirical
Tests.”Journal of Political Economy, 81(3): 607–36.
Hansen, Lars P. 1982. “Large Sample Properties of Generalized Method of Moments Estimators.”Econometrica, 50(4): 1029–54.
Jagannathan, Ravi and Zhenyu Wang. 1998. “An Asymptotic Theory for Estimating
Beta-Pricing Models Using Cross-Sectional Regressions.” Journal of Finance, 53(4):
1285–309.
Kan, Raymond and Chu Zhang. 1999a. “GMM Tests of Stochastic Discount Factor Models
with Useless Factors.”Journal of Financial Economics, 54(1): 103–27.
Kan, Raymond and Chu Zhang. 1999b. “Two-Pass Tests of Asset Pricing Models with
Useless Factors.”Journal of Finance, 54(1): 203–35.
Lustig, Hanno, Nikolai Roussanov, and Adrien Verdelhan. 2009. “Common Risk Factors
in Currency Markets.”Social Science Research Network Paper 1139447.
Lustig, Hanno and Adrien Verdelhan. 2007. “The Cross-Section of Foreign Currency Risk
Premia and Consumption Growth Risk.”American Economic Review, 97(1): 89–117.
Menkho¤, Lukas, Lucio Sarno, Maik Schmeling, and Andreas Schrimpf. Forthcoming.
“Carry Trades and Global Foreign Exchange Volatility.”Journal of Finance.
21

Shanken, Jay. 1992. “On the Estimation of Beta-Pricing Models.” Review of Financial
Studies, 5(1): 1–33.
Wright, Jonathan H. 2003. “Detecting Lack of Identi…cation in GMM.”Econometric Theory, 19(2): 322–30.
Yogo, Motohiro. 2006. “A Consumption-Based Explanation of Expected Stock Returns.”
Journal of Finance, 61(2): 539–80.

22

TABLE 1: Factor Betas and Covariances: Tests for Spread and Against Zero
(a) Betas
c
Standard error type
System-OLS
GMM-VARHAC

d

(b) Covariances
rW

c

d

rW

Tests for no spread (p-values)
0.738 0.563 0.273
–
–
–
0.838 0.596 0.437 0.611 0.901 0.405
Joint tests vs. zero (p-values)

System-OLS
GMM-VARHAC

0.813 0.623 0.365
–
–
–
0.799 0.668 0.511 0.447 0.682 0.510

Annual data, 1953–2002. In part (a) the regression equation is Rite = ai + ft0 i + it , where Rite
dt rW t )0 , c is real per household
is the excess return of portfolio i at time t, ft = ( ct
consumption (nondurables & services) growth, d is real per household durable consumption
growth, and rW is the value weighted US stock market return. The portfolios are equallyweighted groups of short-term foreign-currency denominated money market securities sorted
according to their interest di¤erential with the United States, where P1 and P8 are the
portfolios with, respectively, the smallest and largest interest di¤erentials. The table reports
p-values for tests of the hypotheses that ij = j 8i and ij = 0 8i for each factor j.
In part (b) the covariances between the excess returns of the portfolios and the factors,
cov(Rie ; fj ), are estimated by GMM. The table reports p-values for tests of the hypotheses
that cov(Rie ; fj ) = cj 8i and cov(Rie ; fj ) = 0 8i for each factor j.

23

TABLE 2: SDF Betas: Tests for Spread and Against Zero
Model (i) Model (ii) Model (iii)
Standard error type

Tests for no spread (p-values)

System-OLS
GMM-VARHAC

0.508
0.688

0.477
0.589

0.575
0.602

Joint tests vs. zero (p-values)
System-OLS
GMM-VARHAC

0.469
0.306

0.443
0.170

0.505
0.329

Annual data, 1953–2002. The regression equation is Rite = ai mt im + it , where mt =
1 (ft f )0 b, f is the sample mean of ft , and the vector b takes on one of the following
three values: (i) b = ( 21:0 129:9 4:46 )0 (corresponds to LV’s two pass estimate with
a constant), (ii) b = ( 37:0 74:7 4:65 )0 (corresponds to LV’s GMM estimate with no
constant) and (iii) b = ( 6:74 23:3 0:31 )0 (the calibrated model). Here Rite is a portfolio
return, and ft is the vector of factors, described in Table 1. The table reports p-values for
tests of the hypotheses that im = m 8i and im = 0 8i.

24

TABLE 3: Second-Pass Regression with a Constant
Factor Prices ( )
Constant

-2.94
(0.86)
[2.23]
{2.66}
<-4.9,2.5>

Nondurables

Durables

Market

( c)

( d)

(rW )

2.19
(0.83)
[2.11]
{2.48}
<-1.8,4.7>

4.70
(0.97)
[2.42]
{2.41}
<-3.8,7.8>

3.33
(7.59)
[18.8]
{23.1}
<-32,28>

R2

p-value

0.87

MAE

0.44
(0.483)
[0.972]
{0.994}

Annual data, 1953–2002. The table reports results from running the cross-sectional regression
0
Rie = + ^ i + ui .where Rie is the mean excess return of portfolio i and ^ i is the vector of
factor betas of portfolio i estimated in the …rst pass regression. The portfolios and factors are
described in Table 1. For the factor risk premia ( ^ ) OLS standard errors are in parentheses,
Shanken standard errors are in square brackets, and GMM-VARHAC standard errors are in
braces. Bootstrapped 95 percent con…dence regions are in angled brackets. For the tests of
the pricing errors I compute the test statistic for each of the three methods of computing
the covariance matrix of u
^ (OLS, Shanken and GMM-VARHAC), and report the associated
p-value. The R2 statistic from the second-pass regression is reported along with the mean
absolute pricing error (MAE).

25

TABLE 4: GMM Estimates of the Model with the Constant
Model Parameters (b)
Stage

R2

Nondurables

Durables

Market

p-value MAE

( c)

( d)

(rW )

1st

-21.0
(87.7)
<-291,304>

129.9
(97.4)
<-199,296>

4.46
(4.83)
<-11,13>

0.87

2nd

27.2
(76.2)
<-201,253>

108.3
(97.3)
<-147,227>

2.53
(4.38)
<-8.7,10>

0.81

0.703

0.42

Iterated

59.5
(74.2)
<-206,268>

88.4
(76.4)
<-155,228>

0.15
(4.03)
<-9.5,11>

0.50

0.915

0.66

0.44

Annual data, 1953–2002. The table reports GMM estimates of b obtained by exploiting the
)0 b]
g = 0 and E(ft
) = 0, where Ret is the vector
moment restrictions EfRet [1 (ft
of currency portfolio returns, and ft is the vector of risk factors, described in Table 1. GMMVARHAC standard errors are in parentheses. Bootstrapped 95 percent con…dence regions
are in angled brackets. For the test of the pricing errors I report the p-value associated with
the test-statistic.

26

TABLE 5: GMM Estimates of the Model with the Constant
Factor Prices ( )
Stage

Constant

Nondurables

Durables

Market

( c)

( d)

(rW )

1st

-2.94
(2.63)
<-4.9,2.5>

2.19
(1.88)
<-1.8,4.7>

4.70
(3.16)
<-3.8,7.8>

3.33
(13.0)
<-32,28>

2nd

-3.02
(2.23)
<-4.2,1.4>

2.73
(1.81)
<-1.1,4.2>

4.85
(3.15)
<-2.6,6.4>

0.78
(10.9)
<-25,24>

Iterated

-3.56
(2.01)
<-4.3,1.5>

2.94
(1.59)
<-1.3,4.6>

4.81
(2.62)
<-2.9,6.6>

-3.87
(11.8)
<-28,31>

Annual data, 1953–2002. The table reports GMM estimates of and obtained by exploiting
)0 b]
g = 0, E(ft
) = 0 and E[(ft
)(ft
the moment restrictions EfRet [1 (ft
0
e
)
f ] = 0, where Rt is the vector of currency portfolio returns, and ft is the vector
of risk factors, described in Table 1. GMM-VARHAC standard errors are in parentheses.
Bootstrapped 95 percent con…dence regions are in angled brackets.

27

TABLE 6: Second-Pass Regression without a Constant
Factor Prices ( )
Nondurables

Durables

Market

( c)

( d)

(rW )

0.59
(0.73)
[1.01]
{1.17}
<-1.7,3.4>

1.10
(1.02)
[1.40]
{1.69}
<-3.0,5.9>

11.7
(7.40)
[10.1]
{10.6}
<-24,24>

R2

p-value

0.34

MAE

1.17
(0.001)
[0.059]
{0.173}

Annual data, 1953–2002. The table reports results from running the cross-sectional regression
0
Rie = ^ i + i .where Rie is the mean excess return of portfolio i and ^ i is the vector of factor
betas of portfolio i estimated in the …rst pass regression. The portfolios and factors are
described in Table 1. For the factor risk premia ( ^ ) OLS standard errors are in parentheses,
Shanken standard errors are in square brackets, and GMM-VARHAC standard errors are in
braces. Bootstrapped 95 percent con…dence regions are in angled brackets. For the tests of
the pricing errors I compute the test statistic for each of the three methods of computing
the covariance matrix of ^ (OLS, Shanken and GMM-VARHAC), and report the p-value
associated with the test-statistic. The R2 statistic from the second-pass regression is reported
along with the mean absolute pricing error (MAE).

28

TABLE 7: GMM Estimates of the Model with no Constant
Model Parameters (b)
Stage

R2

Nondurables

Durables

Market

p-value MAE

( c)

( d)

(rW )

1st

-22.0
(62.9)
<-237,235>

45.5
(50.3)
<-155,231>

5.16
(2.88)
<-8.4,11>

0.34

2nd

37.0
(45.2)
<-183,213>

74.7
(33.0)
<-129,187>

4.65
(2.70)
<-7.0,9.4>

-0.66

0.068

1.86

Iterated

25.8
(40.6)
<-191,235>

66.0
(47.4)
<-138,193>

-2.14
(2.94)
<-8.0,11>

-1.45

0.281

2.28

1.17

Annual data, 1953–2002. The table reports GMM estimates of b obtained by exploiting the
)0 b]g = 0 and E(ft
) = 0, where Ret is the vector of
moment restrictions EfRet [1 (ft
currency portfolio returns, and ft is the vector of risk factors, described in Table 1. GMMVARHAC standard errors are in parentheses. Bootstrapped 95 percent con…dence regions
are in angled brackets. For the test of the pricing errors I report the p-value associated with
the test-statistic.

29

TABLE 8: GMM Estimates of the Model with no Constant
Factor Prices ( )
Stage

Nondurables

Durables

Market

( c)

( d)

(rW )

1st

0.59
(1.07)
<-1.7,3.4>

1.10
(1.64)
<-3.0,5.9>

11.7
(8.26)
<-24,24>

2nd

2.37
(1.00)
<-1.2,3.4>

3.48
(1.13)
<-2.4,5.0>

10.2
(7.37)
<-21,25>

Iterated

1.72
(0.93)
<-1.4,3.7>

3.41
(1.52)
<-2.6,5.2>

-10.6
(8.80)
<-24,31>

Annual data, 1953–2002. The table reports GMM estimates of obtained by exploiting the
moment restrictions EfRet [1 (ft
)0 b]g = 0, E(ft
) = 0 and E[(ft
)(ft
)0
f ] = 0,
e
where Rt is the vector of currency portfolio returns, and ft is the vector of risk factors,
described in Table 1. GMM-VARHAC standard errors are in parentheses. Bootstrapped 95
percent con…dence regions are in angled brackets.

30

TABLE 9: Factor Betas and Covariances for Annual Di¤erenced Portfolios, Tests
for Spread and Against Zero
(a) Betas
c
Standard error type
System-OLS
GMM-VARHAC

d

(b) Covariances
rW

c

d

rW

Tests for no spread (p-values)
0:646
0:728

0:644
0:567

0:371
0:350

0:517

0:845

0:503

Joint tests vs. zero (p-values)
System-OLS
GMM-VARHAC

0:738
0:818

0:563
0:471

0:273
0:186

0:560

0:895

0:402

Annual Data, 1953–2002. In part (a) the regression equation is Rite = ai + ft0 i + it , where
ft is the vector of factors described in Table 1, and Rite is a portfolio return. The portfolios
are D2, D3, : : : , D8, the returns to holding long positions in LV’s portfolios P2, P3, : : : ,
P8 (described in Table 1) while holding a short position in portfolio P1. The table reports
p-values for tests of the hypotheses that ij = j 8i and ij = 0 8i for each factor j. In part
(b) the covariances between the excess returns and the factors, cov(Rie ; fj ), are estimated by
GMM. The table reports p-values for tests of the hypotheses that cov(Rie ; fj ) = cj 8i and
cov(Rie ; fj ) = 0 8i for each factor j.

31

TABLE 10: SDF Betas for Annual Di¤erenced Portfolios, Tests for Spread and
Against Zero
Model (i) Model (ii) Model (iii)
Standard error type

Tests for no spread (p-values)

System-OLS
GMM-VARHAC

0:672
0:668

0:664
0:475

0:660
0:485

Joint tests vs. zero (p-values)
System-OLS
GMM-VARHAC

0:508
0:404

0:477
0:162

0:575
0:321

Annual Data, 1953–2002. The regression equation is Rite = ai mt im + it , where mt =
1 (ft f )0 b, f is the sample mean of ft , and the vector b takes on one of the following
three values: (i) b = ( 21:0 129:9 4:46 )0 (corresponds to LV’s two pass estimate with
a constant), (ii) b = ( 37:0 74:7 4:65 )0 (corresponds to LV’s GMM estimate with no
constant) and (iii) b = ( 6:74 23:3 0:31 )0 (the calibrated model). Here, Rite and ft are the
returns and factors described in the note to Table 10. The table reports p-values for tests of
the hypotheses that im = m 8i and im = 0 8i.

32

TABLE 11: Factor Betas and Covariances for Quarterly Di¤erenced Portfolios,
Tests for Spread and Against Zero
(a) Betas
c
Standard error type
System-OLS
GMM-VARHAC

d

(b) Covariances
rW

c

d

rW

Tests for no spread (p-values)
0:629
0:542

0:499
0:615

0:085
0:044

0:494

0:402

0:072

Joint tests vs. zero (p-values)
System-OLS
GMM-VARHAC

0:763
0:685

0:618
0:681

0:016
0:049

0:640

0:470

0:113

Quarterly Data, 1976Q2–2010Q1. In part (a) the regression equation is Rite = ai + ft0 i + it ,
where Rite is the excess return of portfolio i at time t, and ft is the vector of risk factor
described in Table 1. The portfolios are DQ2, DQ3, : : : , DQ5, the returns to holding long
positions in the …ve quarterly portfolios Q2, Q3, : : : , Q6 while holding a short position in the
quarterly portfolio Q1. The table reports p-values for tests of the hypotheses that ij = j
8i and ij = 0 8i for each factor j. In part (b) the covariances between the excess returns
and the factors, cov(Rie ; fj ), are estimated by GMM. The table reports p-values for tests of
the hypotheses that cov(Rie ; fj ) = cj 8i and cov(Rie ; fj ) = 0 8i for each factor j.

33

TABLE 12: SDF Betas for Quarterly Di¤erenced Portfolios, Tests for Spread and
Against Zero
Model (i) Model (ii) Model (iii)
Standard error type

Tests for no spread (p-values)

System-OLS
GMM-VARHAC

0:333
0:280

0:185
0:103

0:273
0:301

Joint tests vs. zero (p-values)
System-OLS
GMM-VARHAC

0:409
0:332

0:168
0:139

0:399
0:431

Quarterly Data, 1976Q2–2010Q1. The regression equation is Rite = ai mt im + it , where
mt = 1 (ft f )0 b, f is the sample mean of ft , and the vector b takes on one of the following
three values: (i) b = ( 21:0 129:9 4:46 )0 (corresponds to LV’s two pass estimate with
a constant), (ii) b = ( 37:0 74:7 4:65 )0 (corresponds to LV’s GMM estimate with no
constant) and (iii) b = ( 6:74 23:3 0:31 )0 (the calibrated model). Here, Rite and ft are the
returns and factors described in the note to Table 12. The table reports p-values for tests of
the hypotheses that im = m 8i and im = 0 8i.

34

