NBER WORKING PAPER SERIES

EMPIRICAL IMPLEMENTATION OF NONPARAMETRIC FIRST-PRICE AUCTION
MODELS
Daniel J. Henderson
John A. List
Daniel L. Millimet
Christopher F. Parmeter
Michael K. Price
Working Paper 17095
http://www.nber.org/papers/w17095

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2011

The authors have benefited greatly from comments made by four anonymous referees, Zongwu Cai,
Han Hong, Subal Kumbhakar, Harry Paarsch and Robin Sickles, participants in seminars at Cornell
University, Drexel University, the State University of New York at Albany, the University of California,
Merced, the University of California, Riverside, the University of Nevada, Reno, Utah State University
and University LUISS, as well as from participants at NY Camp Econometrics III, the Conference
on Auctions and Games held at Virginia Polytechnic Institute and State University and the 2010 North
American Winter Meetings of the Econometric Society in Atlanta, GA. All GAUSS code used in the
paper is available from the authors upon request. The usual disclaimer applies. The views expressed
herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
Â© 2011 by Daniel J. Henderson, John A. List, Daniel L. Millimet, Christopher F. Parmeter, and Michael
K. Price. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without
explicit permission provided that full credit, including Â© notice, is given to the source.

Empirical Implementation of Nonparametric First-Price Auction Models
Daniel J. Henderson, John A. List, Daniel L. Millimet, Christopher F. Parmeter, and Michael
K. Price
NBER Working Paper No. 17095
May 2011
JEL No. C12,C14,D44
ABSTRACT
Nonparametric estimators provide a flexible means of uncovering salient features of auction data.Although
these estimators are popular in the literature, many key features necessary for proper implementation
have yet to be uncovered. Here we provide several suggestions for nonparamteric estimation of first-price
auction models. Specifically, we show how to impose monotonicity of the equilibrium bidding strategy;
a key property of structural auction models not guaranteed in standard nonparametric estimation. We
further develop methods for automatic bandwidth selection. Finally, we discuss how to impose monotonicity
in auctions with differering number of bidders, reserve prices, and auction-specific characteristics.
Finite sample performance is examined using simulated data as well as experimental auction data.

Daniel J. Henderson
Dept. of Economics
State University of New York at Binghamton
Binghamton, NY 13902-6000
djhender@binghamton.edu
John A. List
Department of Economics
University of Chicago
1126 East 59th
Chicago, IL 60637
and NBER
jlist@uchicago.edu
Daniel L. Millimet
Southern Methodist University
Department of Economics
Box 0496
Dallas, TX 75275-0496
and IZA
millimet@mail.smu.edu

Christopher F. Parmeter
University of Miami
cparmeter@bus.miami.edu
Michael K. Price
Department of Economics
University of Tennessee
515 Stokely Management Center
Knoxville, TN 27996
and NBER
mprice21@utk.edu

1

Introduction

Nonparametric kernel methods are advantageous in many empirical settings because they are largely
immune, relative to parametric alternatives, to concerns regarding mis-specification of functional forms.
In light of this, as well as the logic set forth in McAfee and Vincent (1992) suggesting that policy
conclusions should hinge on distribution-free methods when knowledge of the underlying distribution is
vacuous, nonparametric methods have thus become a cornerstone of structural estimation of auctions.
Despite this popularity, however, nonparametric methods possess theoretical and computational deficiencies; notably, the â€™curse of dimensionalityâ€™ and derivations of asymptotic properties. Yet, even ignoring
these unavoidable issues, other empirical issues remain unresolved in the nonparametric estimation of
first-price auction models.
In this paper, we address two of these issues: bandwidth selection and imposition of smoothness
constraints (e.g., monotonicity). We do so in the context of the seminal first-price auction estimator of
Guerre, Perrigne, and Vuong (2000; GPV hereafter); although the methods proposed should also extend
naturally to other auction settings. Moreover, the increasing popularity of identifying and constructing
nonparametric, structural microeconometric estimators should benefit from the discussion here.
In terms of bandwidth selection, we are unaware of any automated selection procedures that have been
proposed in the structural auction literature. Even though bandwidth selection mechanisms are wellstudied in nonparametric density and regression estimation, and are considered of the utmost importance,
there is a noticeable void in the first-price auction setting (Athey and Haile 2008). There is a good
explanations for this void: the values of interest are unobserved, thus making it difficult to formulate
a criterion for smoothing the equilibrium bidding strategy. Nonetheless, we attempt to fill this void by
proposing a least-squares cross-validation procedure to obtain bandwidths. In contrast to the widely
used rule-of-thumb estimates employed in the first-price auction literature, which attempts to provide
an optimal bandwidth for the bid density, we provide a framework for automated selection of the
bandwidth for the bid-value relationship. The intuition for the proposed approach is identical to that in
the density estimation context. While the density values are unobserved (as are the underlying values in
our setting), the use of a leave-one-out estimator helps to circumvent this lack of important information
when constructing the squared error criterion. We note that the optimal bandwidth for the bid density
may not be suitable for the bid-value relationship. In fact, in our empirical example, we show how using
a rule-of-thumb bandwidth can lead to poor estimates.
The second issue we address concerns the imposition of smoothness constraints such as monotonicity. In constrast to parametric alternatives, the imposition of such constraints to ensure theoreticallyconsistent estimates in nonparametric settings is not straightforward. In an empirical structural auction
setting, this is a primary concern as smoothness conditions are implied by the underlying structure
of the equilibrium bidding behavior. Moreover, the underlying theory for the GPV first-price auction
estimator is but one of a number of theoretical reasons why the monotonicity assumption is important

2

in a structural model, among them being the â€˜single-crossingâ€™ property recognized in Athey (2001) and
Athey and Haile (2002, 2008).
Our approach involves tilting the empirical distribution of the data by the least amount, relative to
a benchmark, to achieve the desired smoothness constraints (monotonicity in our case). This approach,
known as constraint weighted bootstrapping (Hall, Huang, Gifford, and Gijbels, 2001; Hall and Huang,
2001), is firmly entrenched in the statistics literature. Furthermore, the constrained approach proposed
here will produce a monotonically-constrained estimator regardless of the bandwidth deployed. Finally,
our proposed constrained estimator has the nice feature that it is numerically identical to the GPV
estimator when the latter is monotonic. Nonetheless, it is generally the case that the constrained
estimator will differ from that of GPV in small sample settings.
Beyond the general case of imposing smoothness constraints in a nonparametric setting, we discuss
how to impose monotonicity in auctions with differing numbers of bidders, reserve prices, and auctionspecific characteristics. We further discuss bandwidth selection with these features and believe that
our paper provides necessary tools to perform proper empirical applications of structural models. We
showcase our methods in simple settings using both simulated and experimental data. We find that
there are often finite sample gains when resorting to constrained estimation and that the constrained
and unconstrained estimators tend towards one another as the sample size increases. Specifically, our
simulated evidence shows that imposing monotonicity can produce improved estimates of the bid-value
relationship as well as policy relevant variables, such as (but not limited to) the optimal reserve price.
Moreover, using experimental auction data we show how the rule-of-thumb bandwidth can easily be
misleading relative to our data-driven approach.
Prior to continuing, it is worth re-emphasizing that our estimator should also be of interest not only
in an auction setting, but also in other areas where structural approaches are employed to recover the
primitives of economic models. For example, the ability to constrain nonparametric estimators should
prove indispensable for those who wish to use monotone comparative statics (e.g., Athey 2001, 2002) to
recover structural parameters in stochastic optimization problems or games of incomplete information.
We also show that the semiparametric, optimal reserve price estimator of Li, Perrigne, and Vuong (2003)
can be improved in certain dimensions when monotonicity is imposed on the bid-value relationship.
More generally, constrained nonparametric estimation has important implications within economics
as a whole, as there are many instances where economic theory provides some information about the
model being estimated (e.g., Hotz and Miller 1993; Olley and Pakes 1996). In addition to these applications, the approach described here should be of interest to econometricians interested in constrained
nonparametric methods (Gallant 1981; Matzkin 1994) and our approach complements recent work that
examines the imposition of curvature conditions in nonparametric settings (Beresteanu 2007; Chak,
Madras, and Smith 2005; Chernozhukov, Fernandez-Val, and Galichon 2009; Du, Parmeter, and Racine
2010). The constraint weighted bootstrapping approach advocated here is similar in spirit to the empirical likelihood methods developed in Owen (1988) and the information theoretic approaches to GMM

3

presented in Imbens, Spady, and Johnson (1998). In addition to the papers discussed above, a substantial amount of consideration has been paid to the issue of monotonicity by statisticians; see the citations
in Henderson and Parmeter (2009).
The remainder of the paper is laid out as follows. In Section 2 we briefly review the theory underyling
the first-price auction setup within the independent private value paradigm (IPVP) as well as the
nonparametric estimator proposed by GPV. Section 3 discusses the importance of the bandwidth on the
GPV estimator and proposes a data-driven method to select the bandwidth. In Section 4 we describe
how to implement the constraint weighted bootstrapping theory developed in the statistics literature
to create a generalized estimator that imposes monotonicity. Additionally, we discuss how to extend
this methodology to a variety of auction settings likely to arise in practice. Section 5 provides a small
simulation study to illustrate that the method performs well when monotonicity is violated, as well as
simulations to showcase how estimation of the optimal reserve price can be improved when monotonicity
is imposed. A formal application of the method to experimental first price auction data that was recently
used to adjudicate opposing structural estimators is also presented to highlight the importance of which
bandwidth is used in practice. In Section 6 we emphasize the usefulness of this style of nonparametric
estimation beyond structural auctions and indicate several lines of possible future research.

2

Theoretical Background and Estimation

2.1

Preliminaries

Within the IPVP each player knows his or her value of the product to be auctioned, v, but no other
playerâ€™s value. Playersâ€™ values are assumed to be independent draws from F (v) (the CDF), which is
taken as common knowledge. Players select their bidding strategy to maximize their expected payout,
given by Ï€ e (Â·). This leads to the following maximization problem:
max
b

Ï€ e (b) = (v âˆ’ b)F (Ïƒn )nâˆ’1 ,

(1)

where b is the playerâ€™s corresponding bid when there are n total participants in the auction and Ïƒn =
Î²nâˆ’1 (b) denotes the inverse of the bid function, Î²n (v), used by the player. The first order condition is
given by:
âˆ’F (Ïƒn )nâˆ’1 + (n âˆ’ 1)(v âˆ’ Î²n )F (Ïƒn )nâˆ’2 f (Ïƒn )Ïƒn0 = 0.

(2)

The assumption that the bid function is monotonic implies dÏƒn /db = 1/Î²n0 (v). Furthermore, with
symmetry of the bidders, Î²(v) = b. These features allow us to simplify the solution to
Î²n0 +

(n âˆ’ 1)f (v)
(n âˆ’ 1)vf (v)
Î²n =
,
F (v)
F (v)

4

(3)

which is a linear differential equation with solution given by
Rv
Î²n (v) = v âˆ’

F (u)nâˆ’1 du

v

F (v)nâˆ’1

,

(4)

assuming the absence of a reserve price,1 , where v represents the minimum of the support of the value
distribution. If we allow for a reserve price, then the differential equation has the solution
Rv
Î²n (v) = v âˆ’

F (u)nâˆ’1 du

r

F (v)nâˆ’1

where

r â‰¤ v.

(5)

Assuming that all potential bidders place bids, the only difference between equations (4) and (5) are the
limits of integration. In essence the reserve price acts as a boundary condition in exactly the same way
that v does in the no reserve setting. Paarsch and Hong (2006) provide a more detailed description of
this derivation and the IPVP in general.

2.2

Nonparametric Estimation in First-Price Auctions

In the seminal paper on the nonparametric structural identification and estimation of a first-price auction, GPV provide a natural setting in which to think about the distribution of valuations within the
IPVP in a nonparametric framework. Their analysis spurred (perhaps started) the growth of nonparametric structural estimation of auctions across paradigms, including affiliated private values (Li,
Perrigne, and Vuong 2002), unobserved heterogeneity with independent values (Krasnokutskaya 2009)
and conditionally independent private information (Li, Perrigne, and Vuong 2000). We describe their
method under the situation of no reserve price.
The structural equilibrium bidding strategy derived in GPV is given as
v i = bi +

G(bi )
= Î¾(bi , n, G),
(n âˆ’ 1)g(bi )

(6)

where vi and bi are the value and bid for agent i, respectively. G(bi ) is the cumulative distribution
function (CDF) of the bid density and g(bi ) is the probability density function (pdf) of bids. Only the
vector of bids is observed by the econometrician. Once the functional forms of G(Â·) and g(Â·) are assumed
or estimated, then the values (vi ) can be estimated along with the corresponding CDF and pdf, F (Â·)
and f (Â·), respectively.
The nonparametric estimation approach given in GPV is as follows:
1

A reserve price is such that all submitted bids must be greater than this price.

5

1. Estimate g(b) using kernel methods.
n

T

1 XX
gb(b) =
K
nT h i=1 t=1



b âˆ’ bit
h


,

(7)

where bi t is the bid for agent i in auction t. Thus, we are pooling bids from multiple auctions with
the identical number of bidders to increase the sample size. K(Â·) is a kernel function required to be a
non-negative, bounded and symmetric density function with compact support. The bandwidth, h,
depends on the sample size and converges to zero as T goes to infinity. The standard bias-variance
tradeoff exists when considering the choice of the bandwidth.
2. Estimate G(b) using the empirical CDF
n
T
1 XX
b
G(b)
=
1{bit â‰¤ b},
nT i=1 t=1

(8)

where 1{A} is the indicator that the event A is true.
b using the above estimates to recover the values.
3. Construct vbit = Î¾(bit , n, G)
4. Estimate the density and distribution of values, f (b
vit ) and F (b
vit ), using equations (7) and (8)
above with the same bandwidth, with bit and b replaced with vbit and v, respectively.
The above discussion omits three important details. First, the GPV estimator needs to trim the
sample near the boundaries of the pseudo-values, vbit ; see equation (6) on page 531 in GPV). Kernel
density estimators are well known to be inconsistent near the edge of the support of the variable of
interest. This contaminates the second-stage recovery of the distribution of values. GPV propose
trimming observations that are within one bandwidth of b and bÌ„, the upper and lower bounds of the
support for bids. This yields a consistent estimator on the interior of I = [b, bÌ„]. Second, no formal
method is provided to select the bandwidth used for smoothing the bid-value function even though
it is well known in applied nonparametric research that the bandwidth employed can have a serious
impact on the results. Section 3 provides a data-driven bandwidth selection technique that is similar in
spirit to the common data-driven methods used for bandwidth selection in the kernel density estimation
literature. Third, GPV show that Î¾(bi , n, G) is strictly increasing for all bit âˆˆ I (condition C2 of
Theorem 1 in GPV). Their nonparametric approach, however, does not formally impose this condition
in the estimation. To fill this void, Section 4 proposes a method to impose this monotonicity condition.

3
3.1

Bandwidth Choice
Monotonicity and Bandwidth Selection

To highlight the importance of bandwidth choice, we begin by showing that there exists a bandwidth
such that any estimated equilibrium bidding strategy is monotonic. Formally, our claim is that if I

6

is a compact interval, then for all sufficiently large bandwidth h, Î¾b0 (Â·|h) > 0 on int(I), guaranteeing
monotonicity of the estimated equilibrium bidding strategy. To justify this statement, we assume that
the kernel function, K(Â·), has two continuous derivatives in a small neighborhood of the origin, with
K 0 (0) = 0.2 We note that as h â†’ âˆ, the following two relations hold:

K

b âˆ’ bit
h




â‰ˆ K(0) +

b âˆ’ bit
h



K 0 (0) + op (hâˆ’2 )

and
K

0



b âˆ’ bit
h



âˆ’1

â‰ˆh



0

K (0) +

b âˆ’ bit
h2



K 00 (0) + op (hâˆ’3 ).

Together, these relations imply
gb(b|h) â‰ˆ hâˆ’1 K(0)
and
0

âˆ’3

gb (b|h) â‰ˆ h

00

âˆ’1

K (0) Â· (nT )

n X
T
X

(b âˆ’ bit ) + op (hâˆ’3 )

i=1 t=1

uniformly over b âˆˆ I since h â†’ âˆ implies that |bit âˆ’ b|/h â†’ 0. From this it follows that gb(b)2 > |b
g 0 (b)|
âˆ€ b âˆˆ I for sufficiently large h. However, consistent nonparametric estimation requires that h shrinks
to zero as n gets large. Hence, we cannot choose a very large h to achieve a monotone estimation result
asymptotically.
This shows that the numerator of the derivative of the GPV estimator will be positive everywhere
given a sufficiently large bandwidth; the denominator is always positive. This is intuitive since h â†’ âˆ
implies that gÌ‚(b) is flat for all b and thus the derivative is zero everywhere.3
This result is discouraging since bandwidth selection has, up to this point, been arbitrary in this
setting. While asymptotically optimal bandwidth are available for a given sample size and kernel, they
are at best â€˜asymptoticallyâ€™ optimal. Alternatively, the smallest bandwidth that guarantees monotonicity
could be employed. However, such arbitrary selection of the bandwidth is not suggested. Further,
choosing an arbitrarily large bandwidth to guarantee monotonicity may mask interesting and essential
information about a density. In general, most economic applications require automated criteria for
bandwidth choice and a separate means by which to impose monotonicity.

3.2

Automated Bandwidth Selection

Automated bandwidth selection in structural auction settings has been largely unexplored even though
these issues have taken place under the mantle of nonparametric density and regression estimation
(Athey and Haile 2008). It might be posited that automated selection has not been addressed because
2
3

This property holds for all standard kernels used in the auction literature (Gaussian,
Epanechnikov,
and triweight).


0
âˆ’1
âˆ’1
0
2
Ë†
An alternative proof may be given by noting that Î¾ (Â·) = 1+(nâˆ’1) +(nâˆ’1)
GÌ‚(Â·)gÌ‚ (Â·)/gÌ‚(Â·) , which implies that gÌ‚(Â·)

becomes flat as h â†’ âˆ, meaning gÌ‚ 0 (Â·) â†’ 0 so that Î¾Ë†0 (Â·) is positive everywhere for large h. We are indebted to an anonymous
referee for this point.

7

the values, v, are unobserved, making it difficult to formulate a criterion for smoothing of the equilibrium
bidding strategy. Instead, researchers often resort to rule-of-thumb bandwidths or asymptotic bandwidth
selection criteria which are based on assumptions of the underlying distribution.
GPV use the triweight kernel, K(u) = (35/32)(1 âˆ’ u2 )3 1(|u| â‰¤ 1), and recommend the rule-of-thumb
bandwidth 1.06b
Ïƒb (N T )âˆ’1/5 , which is optimal for estimating the density of bids if they were normally
distributed. Of first note is that this bandwidth actually leads to undersmoothing, as (4/3)1/5 is the
asymptotically optimal scale factor for the Gaussian kernel, not the triweight kernel. The asymptotically
optimal scale factor for the triweight kernel is 2.978 Â· (4/3)1/5 = 3.154. This scaling factor comes from
the theory on canonical kernels found in Marron and Nolan (1989). Essentially, to guarantee that the
same degree of smoothing is present when different kernels are used, the bandwidth must be adjusted by
a specific factor, in our case 2.978.4 Li, Perrigne, and Vuong (2003) advocate for this rescaled bandwidth
and apply it when studying optimal reserve price estimation.
However, even with an appropriately modified rule-of-thumb bandwidth, it is desirable to have data
driven methods to obtain the appropriate smoothness. For example, if the density of bids were lognormally normally distributed (as in Paarsch, 1992) with unit variance as opposed to normally distributed, the optimal scale factor would then be 0.7069, which is nearly 4.5 times smaller than the
bandwidth for normally distributed data. Given the result in the previous sub-section, this is one possible explanation for why monotonicty is often found in empirical studies. A separate point of note is
that it is not clear that selection of the bandwidth based on optimal estimation for the density of bids
will necessarily be suitable for estimation of the bid-value relationship.
Although there exist many bandwidth selection criteria in both the density and regression settings,
least-squares cross-validation (LSCV) is a popular empirical choice. The idea behind the method is to
minimize the integrated square error of the estimator. For
fb of an unknown density
Z a given estimator
2
f , the integrated square error (ISE) can be written as
fb(x) âˆ’ f (x) dx. An analog estimator is
Z
easily constructed noting that the
f (x)2 dx is independent of the bandwidth. While this approach
automates the selection of the bandwidth in order to optimally smooth the bid density, it is unknown
whether this is the appropriate amount of smoothing for the equilibrium bidding strategy. Further, if we
b
were to smooth the CDF instead of using the empirical distribution function to estimate G(Â·),
it is not
clear how to select a bandwidth when both the distribution and density are smoothed simultaneously
(i.e., using the same bandwidth).
Here, we argue that given the primary aim of most structural work is to recover the underlying
pseudo-values to perform policy experiments that will enable the researcher to identify the optimal
reserve price and/or auction format, the objects of interest to dictate appropriate smoothing are the
pseudo-values, vbit = Î¾b(bit , n, G), used to construct the density of values, a bandwidth which is optimal
for the density of bids may not be adequate for construction of the pseudo-values. As these are our
objects of interest, we choose to minimize the LSCV function focusing on the estimation of Î¾(Â·). It may
4

See equation 2.5 in Marron and Nolan (1989).

8

seem that an appropriate estimator of the bandwidth for Î¾b(bit , n, G) would be to compare the squared
differences between Î¾ (b, n, G) and Î¾b(b, n, G) over all feasible bids. However, given that we do not observe
Î¾ (b, n, G) it would seem reasonable to replace it with a leave-one-observation or leave-one-bidder out
estimate. Unfortunately, in this context the bandwidth that minimizes this function is h = âˆ because
the differences between the actual estimator and the leave-one-out estimator diminish as the smoothness
increases.
In light of this, we propose to using the bandwidth which minimize the sample analog of the ISE,
Z h

i2
Î¾b(b, n, G) âˆ’ Î¾ (b, n, G) db
Z
Z
Z
2
2
= Î¾b(b, n, G) db âˆ’ 2 Î¾b(b, n, G) Î¾ (b, n, G) db + Î¾ (b, n, G) db.

ISE(h) =

(9)

The last term is independent of the bandwidth and so we focus on the construction of analog versions
of the first two terms in our decomposition of ISE. For the unknown Î¾ (b, n, G) appearing in the second
term, we replace it with a leave-one-bidder-out estimator instead of a leave-one-observation-out estimator
(i.e., we are using Î¾bâˆ’i (bit , n, G) instead of Î¾bâˆ’it (bit , n, G)).5 This gives us
Z

Z
2
Î¾b(b, n, G) db âˆ’ 2 Î¾b(b, n, G) Î¾ (b, n, G) db
#
Z "
2bGÌ‚(b)
GÌ‚(b)2
2
=
b +
+
db
(n âˆ’ 1)gÌ‚(b) (n âˆ’ 1)2 gÌ‚(b)2
#
Z "
bGÌ‚âˆ’i (b)
GÌ‚âˆ’i (b)2
bGÌ‚(b)
2
+
+
db
âˆ’2
b +
(n âˆ’ 1)gÌ‚(b) (n âˆ’ 1)gÌ‚âˆ’i (b) (n âˆ’ 1)2 gÌ‚âˆ’i (b)2
#
Z "
GÌ‚(b)2
2bGÌ‚âˆ’i (b)
2GÌ‚âˆ’i (b)2
2
=
âˆ’b +
âˆ’
âˆ’
db.
(n âˆ’ 1)2 gÌ‚(b)2
(n âˆ’ 1)gÌ‚âˆ’i (b) (n âˆ’ 1)2 gÌ‚âˆ’i (b)2

ISE(h) =

(10)

The first term in ISE(h) also does not depend upon the bandwidth and so our final decomposition of
the integrated squared error becomes
ISE(h) =

e n, G) =
where Î¾(b,

GÌ‚(b)
(nâˆ’1)gÌ‚(b)

via
min
h

Z h
i
e n, G)2 âˆ’ 2bÎ¾eâˆ’i (b, n, G) âˆ’ Î¾eâˆ’i (b, n, G)2 db,
Î¾(b,

and Î¾eâˆ’i (b, n, G) =

GÌ‚âˆ’i (b)
(nâˆ’1)gÌ‚âˆ’i (b) .

(11)

Data-driven bandwidths can then be obtained

n X
T h
i
X
e it , n, G)2 âˆ’ 2bit Î¾eâˆ’i (bit , n, G) âˆ’ Î¾eâˆ’i (bit , n, G)2 .
Î¾(b

(12)

i=1 t=1

The benefit of using estimated values is that these bandwidths also control the smoothing of the density
of the bids. However, it is not naÄ±Ìˆve to the fact that we must also calculate the distribution of the bids
and then use both of these estimates to obtain the values. Hence, we are able to use a data driven
5
This is a common approach when dealing with panel type data (e.g., Henderson, Li, and Carroll 2008; Kneip and Simar
1996).

9

approach to obtain estimates of our objects of interest.
This type of approach could be used to select bandwidths in other auction settings where the values
are not observed. This would include the nonparametric estimator of the affiliated private value auction
proposed in Li, Perrigne, and Vuong (2002). In fact, for any of the nonparametric estimators proposed
that involve the standard first order differential equation as in GPV equation (3), it is hypothesized
that a similar type of LSCV criteria could be constructed to obtain data-driven bandwidths focused on
estimation of the unknown values.

4

Monotone Estimation of the Bid Function

4.1

Baseline Case

Once an automated procedure is used to choose the bandwidth, there is no guarantee that the GPV estimator will produce a monotonic result. Rather than reverting to parametric methods in such instances,
we instead show how a modified version of the GPV estimator can be constrained to be monotonically
increasing. To do so, we utilize the constraint weighted bootstrap technique from the statistics literature.
In this literature, it is becoming commonplace to impose monotonicity when estimating survival
functions. Noting that Î¾(Â·) is similar to a survival function, our approach is as follows:
1. Estimate g(b) as
n

T

1 XX
gb(b|p) =
pit K
h i=1 t=1



b âˆ’ bit
h


,

(13)

where the pit are observation-specific weights. Note, the GPV estimator is a special case of our
estimator where each weight is set equal to 1/nT .6
2. Estimate G(b) as
Zb
b
G(b|p)
=

gb(u|p)du.

(14)

âˆ’âˆ

Thus, we are not constructing the CDF of the bids using the empirical distribution function. To
ensure that our CDF corresponds to the pdf estimated in equation (13), we need to integrate the
pdf as opposed to simply estimating the CDF by the empirical distribution function. This step is
not done in GPV, nor is it a common approach in studies that use both a CDF and a pdf in the
estimation.7 One may think that the reason for this is twofold. First, the asymptotic arguments are
most likely easier to prove given widely known properties of the empirical distribution estimator.
6

The terminology constraint weighted bootstrap stems from the fact that we are introducing probability weights to shift the
true observations so that the constraint(s) of interest are satisfied. This is consistent with the notion of biased bootstrapping.
Even though no resampling is occurring, the weights act as though the data have been resampled in a manner which delivers
the constrained surface. We mention here that this methodology also has intimate links with empirical likelihood. We elect
to use the terminology constraint weighted bootstrapping for the remainder of our discussion.
7
See Martins-Filho and Yao (2008) for a recent example that does.

10

Second, the empirical distribution estimator is easier to construct than an integral of an estimated
probability density.8
b it , n, G|p) using equation (6) to recover the values. Employ the truncation
3. Construct vbit = Î¾(b
strategy of GPV (page 531, equation (6)).
4. Estimate the density and distribution of values, f (b
vit ) and F (b
vit ), using equations (7) and (8) above,
with vbit and v in the place of bit and b, respectively. Note, because we have a two-step estimator,
the recovery of the density and distribution of the values does not require the incorporation of any
constraint weights. This is because monotonicity has been imposed on the estimator of the bid
function which is used to create the pseudo-values; the resulting pseudo-values can then be treated
as they are in GPV.
The crucial feature of our estimator is that the weights, pit , are selected to ensure that the estimated values are monotonically increasing in the bids. To select the vector of weights, we choose p =
{p11 , p12 , . . . , p1T , p21 , . . . , pnT } to minimize a distance metric subject to the constraint that Î¾b0 (bit , n, G|p) â‰¥
0 on I. If we desire to impose strict monotonicity, Î¾b0 (bit , n, G|p) > 0 on I, then we need to pick some
small number Î´ such that Î¾b0 (bit , n, G|p) > Î´ on I so that this becomes computationally feasible.9 We
n P
T
P
also impose the regularity conditions pit â‰¥ 0 âˆ€i, t and
pit = 1. These conditions make the weights
i=1 t=1

act as though they are drawn from a density and will prove useful when making comparisons to the
uniform weights, 1/nT , used in GPV. For simplicity, we choose to impose our nonnegativity constraint
on
b
Î¾Ë†1 = nb
g (b|p)2 âˆ’ G(b|p)b
g 0 (b|p).

(15)

Noting that Î¾Ë†0 /Î¾Ë†1 is always nonnegative, this implies that both have the same sign.
Our distance metric is the power divergence measure introduced in Cressie and Read (1984) and
proposed in Hall, Huang, Gifford, and Gijbels (2001) for monotone estimation of a hazard rate.10 The
power divergence measure is
n

DÏ (p) =

T

XX
1
[nT âˆ’
(nT pit )Ï ],
Ï(1 âˆ’ Ï)
i=1 t=1

âˆ’âˆ < Ï < âˆ.

(16)

where Ï 6= 0, 1. We need to take limits for Ï = 0 or 1. They are given as

D0 (p) = âˆ’

n X
T
X

log(nT pit );

D1 (p) =

i=1 t=1

n X
T
X

pit log(nT pit ).

(17)

i=1 t=1

8

This does not preclude the use of kernel estimation of the CDF. See Bowman, Hall, and Prvan (1998) or Li and Racine
(2007) for a discussion of CDF estimation via kernel methods. Additionally, this approach may allow us to avoid numerical
Rb
integration all together as the integration sign can be brought inside the summations and typically
K(u)du is known. We
âˆ’âˆ

thank an anonymous referee for making this computational connection.
9
This is also suggested in Hall and Huang (2001).
10
It is also used in Hall and Huang (2001) for nonparametric monotone estimation of a regression function.

11

A value of Ï = 0.5 corresponds to Hellinger distance. Note, for all Ï we have DÏ (p) â‰¥ 0 âˆ€p and
DÏ (p) = 0 if and only if pit = 1/nT âˆ€i, t. This suggests that departures from uniformity of the weights
will correspond to a positive divergence measure, indicating the presence of regions of non-monotonicity.
Regardless of the sampling distribution for the values of the players across auctions and the choice
of I, it is entirely plausible that Î¾b1 will have a zero crossing on I. An example can easily be constructed
where a point lies both a bandwidth away from the boundary and from its nearest point. The probability
of this event is strictly positive given minimal assumptions about the bid density. Fortunately, data sets
that produce this event or a similar event are pathological in nature. Even if we cannot find a set of
weights that guarantees a monotonic estimator, this should pose no problem. In fact, we can view this
event as providing information about the true equilibrium bidding strategy or as evidence that other
features of the auction are being ignored by the econometrician (Athey and Haile 2008).
While it may be argued that this procedure is entirely heuristic given the fact that many papers
have confirmed monotonicity between bids and values, the ability to easily impose this condition when
estimating models using auction data is important from an economic standpoint.11,12 Indeed, even if the
weights are uniform, the researcher can be confident that the estimated equilibrium bidding strategy is
monotonic. This is more formal than visual inspection of the estimated surface. Additionally, while it
may appear that monotonicity holds unconditionally between bids and values, the presence of covariates
renders visual inspection useless in higher dimensions.
Theoretically, this estimator (ignoring truncation) is consistent following only minor modifications
of the proof in Hall, Huang, Gifford, and Gijbels (2001). Given that the pseudo-values are constructed
identically to GPV, the theoretical properties of the value density estimator should follow directly. We
do not consider asymptotic normality of this estimator and leave that for future research.

4.2

Heterogeneous Auctions and Reserve Prices

Many auctions are characterized by differing numbers of bidders, the use of reserve prices, and auctionspecific heterogeneity. We discuss an extension to the baseline case encapsulating all of these features
to highlight the ease by which the constraint weighted bootstrap technique discussed above may be
generalized. The GPV estimator in this auction setting relies on the following first order condition
(written in terms of the actual bids):
1
vit = bit +
N âˆ’1



G(bit |Xt )
H(rt |Xt )
+
g(bit |Xt )
[1 âˆ’ H(rt |Xt )]g(bit |Xt )


,

(18)

where N is the number of potential bidders, rt is the reserve price in auction t, and Xt is a d Ã— 1 vector
of auction-specific observables.
11

We note that this confirmed monotonicity may have been arrived at by employing a rule-of-thumb bandwidth that was
too large.
12
b is locally but not globally monotonic in outer
See Figure 2 of Li, Perrigne, and Vuong (2000) for an example where Î¾(Â·)
continental shelf wildcat auctions.

12

Within the IPVP, the number of actual bidders in auction t, nt , has a binomial distribution with
parameters N and 1 âˆ’ H(rt |Xt ). A natural candidate estimator for N is (GPV; Paarsch and Hong 2006)
b = max nt .
N

(19)

t=1,...,T

Our approach to estimating H(rt |Xt ) follows GPV and uses the fact that H(rt |Xt ) = 1 âˆ’ E[nt |Xt ]. To
that end, we use the standard local-constant kernel estimator

HÌ‚(rt |Xt ) = 1 âˆ’

1

T
X

b T (h1 Â· Â· Â· hd )
N

t=1

nt At (x),

(20)

where
At (x) =

Kh (x, Xt )
T
P
Kh (x, Xt )

(21)

t=1

and hl , l = 1, ..., d, is the bandwidth associated with the lth element in X.
Before proceeding to estimation, we mention that the observed bids, bit , must be transformed as
âˆš
âˆš
sit = bit âˆ’ rt (see GPV) due to the proportionality between the actual bid density, g(b), and 1/ b âˆ’ r
as b approaches r. This transformation prevents the density of bids from becoming unbounded near the
reserve price. Using this transformation, we can write the first order condition in equation (18) as
vit = rt +

s2it

2sit
+
N âˆ’1



Gâˆ— (sit |Xt )
H(rit |Xt )
+
âˆ—
g (sit |Xt )
(1 âˆ’ H(rit |Xt ))g âˆ— (sit |Xt )



= Î¾(sit , N , Gâˆ— , rt , Xt ),

(22)

where Gâˆ— (Â·) and g âˆ— (Â·) are the CDF and pdf, respectively, of the transformed bids. The GPV estimator
then follows by pooling bids across auctions and estimating the unobserved valuations using the following
algorithm:
1. Estimate N and H(rt |Xt ) as indicated above. The bandwidths used to construct H(rt |Xt ) can be
obtained via standard least-squares cross-validation.
2. Estimate g âˆ— (s|x) as


T nt
1 XX
s âˆ’ sit
gb (s|p, x) =
pit K
At (x).
hs t=1 i=1
hs
âˆ—

(23)

3. Estimate Gâˆ— (s|x) as
b âˆ— (s|p, x) =
G

nt
T X
X


pit KÌƒ

t=1 i=1

s âˆ’ sit
hs


At (x),

(24)

where KÌƒ is the corresponding CDF kernel. For example, the CDF kernel corresponding to the
triweight kernel, K(u) = (35/32)(1 âˆ’ u2 )3 1(|u| â‰¤ 1), is
KÌƒ(u) = (35/32)(1 + u)4 (16/35 âˆ’ (29/35)u + (4/7)u2 âˆ’ (1/7)u3 )1(|u| â‰¤ 1).

13

(25)

Notice that we are not integrating the estimated pdf as we did in the baseline auction setting.
Due to the smoothing of the auction covariates, we can select a CDF kernel whose derivative
is equivalent to the kernel we use to construct our conditional pdf. Thus, we have exactly the
definition of a conditional pdf, f (u|w) =

âˆ‚F (u|w)
.
âˆ‚u

b it , N , Gâˆ— , rt , Xt |p) using the above estimates to recover the values following the
4. Construct vbit = Î¾(s
truncation strategy of GPV (page 550).
5. Estimate the density and distribution of values, f (b
vit |Xt ) and F (b
vit |Xt ), as in GPV (page 550).
To minimize the computational burden in selecting the weights, we choose to impose our nonnegativity constraint on
b gbâˆ— (s|p, x)2 + sG
b âˆ— (s|p, x) (1 âˆ’ 2b
b
b
Î¾b1 = 2sN
g âˆ—0 (s|p, x)) + H(r|x)s(b
g âˆ— (s|p, x) âˆ’ 2)/(1 âˆ’ H(r|x)).
We also maintain the regularity conditions pit â‰¥ 0 âˆ€i, t and

n P
T
P

(26)

pit = 1, consistent with use of the

i=1 t=1

power divergence metric.
Finally, this approach could be extended to allow for differing reserve prices across auctions or to
map the arguments here to other auction settings such as the affiliated private values paradigm where
Li, Perrigne, and Vuong (2002) developed a similar nonparametric estimator. Again, their estimator
must be monotonic in the bids (see their Proposition 1). Applying our methodology to this estimator
is straightforward given that it has the same form, but involves a multivariate density as opposed to a
univariate one.
Following our earlier approach in the simple auction setting, a bandwidth can be obtained for the
bids in the heterogenous auction setting. This would follow from:
LSCV (hs ) =

Z 

Ë† N , Gâˆ— , r, X) âˆ’ Î¾(s, N , Gâˆ— , r, X)
Î¾(s,

2

ds.

This estimator represents a trivial extension beyond the homogeneous auction setting given that the
Ë†
bandwidths for the covariates are obtained prior to construction of Î¾(Â·).
However, an alternative strategy
would be to select the bandwidths for X simultaneously with the smoothing parameter for the bids.
This can be handled by minimizing LSCV (h) over both hs and the vector of smoothing parameters for
the covariates.

4.3

Optimal Reserve Price

The optimal reserve price is one of the few pieces of an auction that a seller can manipulate (outside of
improving the quality of the product being auctioned) to increase revenues. This optimal reserve price
is important to learn from a policy standpoint. Let f (v) continue to denote the pdf of values for the
bidders with CDF F (v). The seller places value v0 on the good to be auctioned. The optimal reserve
price, râˆ— , is determined by maximizing total expected revenue (utility), which for an auction with n

14

bidders is

ZvÌ„

n

Î (r) = v0 F (r) + n

[vf (v) + F (v) âˆ’ 1] F (v)nâˆ’1 dv

(27)

r

where vÌ„ represents the maximum of the support of f (v).13 The first term in Î (r) is the expected value
the seller obtains if no bids are placed which exceed r. The second term is the expected revenue from
each bidder submitting a bid higher than r so that the object is sold.
To find the optimal reserve price, we differentiate total expected revenue with respect to r to obtain14
nv0 F (r)nâˆ’1 f (r) âˆ’ n [rf (r) + F (r) âˆ’ 1] F (r)nâˆ’1 (r) = 0.

(28)

Solving (28) for the optimal reserve yields:
r âˆ— = v0 +

1 âˆ’ F (râˆ— )
.
f (râˆ— )

(29)

While this is a simple and elegant solution to determining the optimal reserve price, it depends upon
the unknown distribution and density of values. In empirical settings, only the bids are observed.
Recently, Li, Perrigne and Vuong (2003) propose a semiparametric estimation method to determine
the optimal reserve price that depends upon the observed bids as opposed to the unobserved values.
We briefly describe their method here. As is typical, we will have observations for T auctions and will
observe bids bit for bidder i in auction t. Let Bit = max bjt denote the largest bid in auction t not equal
j6=i

to the bid by agent i. Corollary A.1 in Li, Perrigne, and Vuong (2003) shows that the optimal reserve
price satisfies râˆ— = Î¾(x0 ) where x0 maximizes expected profit, defined as:
Î (x) = E [v0 1 {B1 â‰¤ x} 1 {b1 â‰¤ x}
"
#
nâˆ’1 #

G(x)
1 {B1 â‰¤ b1 } 1 {b1 â‰¥ x} .
+n b1 + (Î¾(x) âˆ’ x)
G(b1 )

(30)

Note that for any given reserve price x, the sellerâ€™s expected profit is composed of the likelihood that
the reserve price is higher than any bids submitted, resulting in the value of the good being auctioned
off as the profit, while the second piece is the value in excess of the initial value of the good that results
from the reserve price being set so that qualifying bids are placed generating additional value. x0 is the
value which will maximize the overall sum of these pieces.
13
14

We assume here that the reserve price does not cause bidders to exit the auction.
The derivative of the integral was determined via Leibnizâ€™s rule:
d
dÎ±

b(Î±)
Z

db(Î±)
da(Î±)
f (x, Î±)dx =
f (b(Î±), Î±) âˆ’
f (a(Î±), Î±) +
dÎ±
dÎ±

a(Î±)

b(Î±)
Z

a(Î±)

15

âˆ‚
f (x, Î±)dx.
âˆ‚Î±

Replacing Î¾(x) with its formal definition in (6) we have
Î (x) =E [v0 1 {B1 â‰¤ x} 1 {b1 â‰¤ x}
"
#


nâˆ’1 #
G(x)
G(x)
+n b1 +
1 {B1 â‰¤ b1 } 1 {b1 â‰¥ x}
(n âˆ’ 1)g(x)
G(b1 )
=E [v0 1 {B1 â‰¤ x} 1 {b1 â‰¤ x}




G(x)n
+n b1 +
1 {B1 â‰¤ b1 } 1 {b1 â‰¥ x} .
(n âˆ’ 1)g(x)G(b1 )nâˆ’1

(31)

The insight of Li, Perrigne, and Vuong (2003) is to replace G(x) and g(x) with nonparametric
estimates. Thus, determination of x0 requires an analog estimator for expected profit. Using the density
and distributional estimators proposed earlier, we can average over all bids in all auctions to construct
an estimated profit function for which the maximum can be easily determined given the one dimensional
nature of the problem. We have
n
T
1 XX
b
Î (x)
=
(v0 1 {Bit â‰¤ x} 1 {bit â‰¤ x} + nbit 1 {Bit â‰¤ bit } 1 {bit â‰¥ x}
nT i=1 t=1

+

!

nGÌ‚(x)n
(n âˆ’ 1)gÌ‚(x)GÌ‚(bil )nâˆ’1

1 {Bit â‰¤ bit } 1 {bmax âˆ’ h â‰¥ bit â‰¥ x} .

(32)

Trimming is introduced for the last term since, as noted by Li, Perrigne and, Vuong (2003), gÌ‚(x) is not
well estimated near bÌ„. Here, h is the bandwidth used to construct the kernel density estimator of g(Â·).
Li, Perrigne, and Vuong (2003, Corollary A.2) show that any xÌ‚0 âˆˆ [bmin + h, bmax âˆ’ h] which maximizes
b
expected profit Î (x),
is a consistent estimator for x0 .
The beauty of determining the optimal reserve price is that this can be done after monotonicity of the
equilibrium bid-value relationship is imposed. In this case, the weights can be used in the construction
of both gÌ‚(Â·) and GÌ‚(Â·) prior to creating the expected profit function from which xÌ‚0 will be determined.

5

Empirical Demonstration

To illustrate our approach, we begin by examining simulated data where we specify the exact form
of the value distribution and create corresponding equilibrium bids. Next, we show that for certain
distributions the monotonically-constrained GPV estimator can result in improved performance of the
optimal reserve price in small settings. We then assess experimental data obtained from a laboratory
setting to see if monotonicity arises in an artificial setting where bids are submitted by participants.
This is useful because we know both the value distribution and the actual values, and can therefore more
adequately address the criticisms of detecting monotonicity raised in Athey and Haile (2002, 2008).

16

5.1
5.1.1

Simulated Data
Estimation of the Bid-Value Relationship

Our simulation experiments examine monotonic distributions that are theoretically consistent with an
equilibrium bidding strategy. We consider T = 100 auctions, each with n = 5 bidders, yielding 500
observed bids. We replicate each scenario 100 times.
We choose the true distribution of private values to be either log-normal with parameters zero and
one or gamma with parameters one and three. For the log-normal case, we follow the truncation strategy
in GPV, discarding those value draws that are below 0.055 and above 2.5. Similarly, for the gamma
distribution, we discard values that are below 0.0455 and above 4.982. For every replication, we first
draw nT values from the truncated distribution. We then compute the bids, bit , using
1
bit = vit âˆ’
F (vit )nâˆ’1

Zvit
F (u)nâˆ’1 du,

(33)

v

where v is the smallest value drawn from the truncated distribution for the given replication.
Using these generated data, we apply our estimation procedure to each replication. We use (13)
and (14) to estimate the density and distribution of the bids for a given set of weights. We employ the
triweight kernel with the rule-of-thumb bandwidth using the triweight scaling (as opposed to the 1.06
normal reference scaling) to speed up computing time. The weights are determined using Ï = 0, 0.5,
and 1 and are found using the sequential quadratic programming routine SQPSolve in the programming
language GAUSS 8.0. While our problem is not a quadratic programming problem, this type of solver
uses a modified quadratic program to find the step length for moving in the direction of a minimum.
As expected, each iteration takes longer to run than GPV. In addition to computation time issues, one
problem that we encountered several times was that the program would not return feasible results. This
was easily remedied, however, by changing the starting values.15
The simulation results are given in Figures 1 and 2. Panel (a) of each figure plots the true equilibrium
bidding strategy along with the estimates from the GPV estimator and our estimator. The curves
correspond to the 95th percentile of the distance metric. Panel (b) of each figure depicts the envelopecurves of the weights after the constraints have been achieved. It is clear that the true data generating
process provides a monotonic equilibrium bidding strategy. However, the finite sample results of the
GPV estimator show regions where the derivative is negative. Our estimator corrects for these regions
of non-monotonicity by changing the weights. In Panel (b) of each figure we see that the corresponding
weights deviate from 1/nT in the bid region where the GPV estimator is non-monotonic.
Of particular interest is whether or not the constrained estimator provides finite sample gains relative
to the unconstrained GPV estimator. It turns out that the fit improves when the unconstrained function
15
Our starting values were selected at random from a uniform distribution and divided by the sum of the starting values to
preserve the summation constraint.

17

deviates further from monotonicity. For example, in the figures corresponding to the 95th percentile of
the distance metric, the median value for the ratio of the absolute bias between the unconstrained and
constrained estimators is greater than unity. Specifically, in the log-normal case, this ratio is 1.0011
when Ï = 0, 1.0013 when Ï = 0.5, and 1.0176 when Ï = 1. While this is a relatively minor improvement,
in the gamma case the ratios are 1.1311, 1.2907 and 1.2145 for Ï = 0, 0.5, and 1, respectively. This
limited evidence shows that the constrained estimator is at least as good as the unconstrained estimator
and sometimes better in terms of bias.

5.1.2

Estimation of the Optimal Reserve Price

While it may be interesting from an econometric standpoint that the bias of the bid-value relationship
is smaller with the constrained estimator, it may not be overly important from an economic standpoint.
It is perhaps more important to discuss whether or not gains are made with respect to the estimation of
a parameter of economic interest. Here, we consider estimation of the optimal reserve price by both the
unconstrained and constrained estimators. Specifically, we again generate data from a log-normal and
gamma distribution, but also consider data generated from a negatively skewed distribution, Beta(5,1).
The purpose for the last distribution is that we expect the reserve price to lie in a region with fewer
data points and hence we should get additional finite sample gains for the constrained estimator.
Table 1 presents the results of this exercise. We calculate the optimal reserve price as in Section 4.3
for both the unconstrained and constrained estimators. Given that Li, Perrigne, and Vuong (2003) prove
theoretically that the estimates of the optimal reserve price are consistent as the number of auctions
tends towards infinity, we start with relatively small numbers of auctions (t = 5 and 10). Even though
the number of observations is relatively small in each run as compared to the previous sub-section,
auctions of this size are common in the literature. We carry over the remaining settings from Section
5.1.1, but only report the results for Ï = 0.5 as the results for other values of this parameter did not
qualitatively alter the results.
Although it is not obvious from the table, we did find that as the number of auctions increased,
the bias, variance, and MSE decreased substantially. Hence, we find evidence to suggest that their
asymptotic results hold. With respect to our table, we look at the median value for the ratio of the
absolute bias, variance, and MSE between the unconstrained and constrained estimators. Values greater
than unity suggest that the constrained estimator has finite sample gains.
Overall, the results are consistent with the fact that the constrained estimator can produce gains in
the optimal reserve price estimator in small samples. However, we do not witness uniform gains across
the three distributions because, as dictated by Theorem 4.3 of Hall and Huang (2001) and Theorem
2.2 of Du, Parmeter, and Racine (2010), outside of a diminishing interval, the GPV estimator and
the constrained GPV estimator are exact. If the reserve price happens to fall in these areas, then
the estimators produce identical results. What is interesting is that while there are minimal gains to
estimating the bid-value relationship for the log-normal case in our earlier simulations, we see that the

18

bias of the optimal reserve price is considerably lower.
Examining the individual results, we find that each of the three different distributions gives a different
result. For the log-normal distribution, there are large gains in bias at a cost of an increase in the
variance for the constrained estimator. The MSE, however, is close to unity and each number tends
towards unity as the number of auctions grows (as hypothesized). For the gamma distribution, there
are improvements in variance at a (very minor) cost of bias and the MSE for the constrained estimator
appears to be worse as compared to the unconstrained estimator, but this (and the other measures)
tend towards one as the number of auctions increases. Finally, for the negative skewed, Beta (5,1))
distribution, we see improvements in bias, variance, and MSE, but these improvements are relatively
small and the ratio tends towards unity as the number of auctions increases.

Table 1: Ratio of median bias, variance and MSE between unconstrained versus constrained estimator.
A value above unity implies that the constrained estimator has a better finite sample performance at the
median value.

5.2

Log-Normal

Gamma(1,3)

Beta(5,1)

n = 5, t = 10
Bias
Variance
MSE

1.2210
0.9513
0.9917

0.9888
1.0332
0.9782

1.0139
1.0092
1.0283

n = 5, t = 20
Bias
Variance
MSE

1.1154
0.9734
1.0061

0.9897
1.0292
0.9793

1.0025
1.0016
1.0045

Experimental Data

Our experimental data were originally collected by Dyer, Kagel, and Levin (1989). Since the data are
used in Bajari and HortacÌ§su (2005) and are discussed there as well, we provide only limited details.
MBA students at the University of Houston participated in a series of first-price sealed bid auctions over
the course of two hours. Subjects submitted contingent bids based on the number of other bidders in
the auction (either 2 or 5). However, we are treating the submitted bids (with either 3 or 6 bidders) as
the actual bids for our purposes. Values were drawn from a U[0, 30] density. As in Bajari and HortacÌ§su
(2005), we drop the submitted bids for the first five auctions of a given run of the experiment. This
leaves us with 23 auctions over three experimental runs. We have a total of 414 bids, regardless of
the number of bidders, since we are ignoring the contingent bidding aspect of the experiment. In our
analysis, we focus on the six bidder case.
We employ the triweight kernel as advocated in Guerre, Perrigne, and Vuong (2000) using both
the rule-of-thumb bandwidth and the data-driven selection method described above. The rule-of-thumb

19

bandwidth is 7.044, whereas our method provides a bandwidth of 1.522. The gross difference in the
bandwidths is most likely due to the fact that a rule-of-thumb bandwidth is arrived at assuming the
unknown density is that of a normal random variate. However, given the experimental nature of the
data, we know that the underlying value and bid distributions are both uniform. Thus, it is quite natural
that our bandwidths differ.
The magnitude of the rule-of-thumb bandwidth produces a globally monotonic bid-value relationship (the dotted line in Panel (a)), whereas our data-driven method yields a non-monotonic relationship
(the solid line in Panel (a)). This appears to be a case where previous research would suggest that a
constrained estimator is unnecessary. However, we see that the ability to impose monotonicity here is
important. Using Ï = 0.5, we obtain a distance metric of 0.870. Our estimated bid-value relationships
are provided in Figure 3, Panel (a). The true relationship, plotted as the dashed-dotted line, is reasonably tracked by both our data-driven estimated relationship as well as the monotonically-constrained
relationship (dashed line) for values approximately less than 20. The rule-of-thumb bandwidth produces
an estimated bid-value relationship that is clearly infeasible.
We see that the use of the rule-of-thumb bandwidth produces a very inaccurate bid-value relationship
compared to the true uniform relationship. While this estimator does a poor job of tracking values, it
does produce a linear relationship, consistent with the true shape of the bid value relationship. The
curve using the data-driven bandwidth does a better job tracking values for low values, but is less reliable
for high values, producing a curve that is non-monotonic and swoops away from the true values near the
upper end of the plot. Our constrained estimator fixes the pockets of non-monotonicity that appear for
the unconstrained estimator and appears to almost exactly mimic the unconstrained curve for low value
draws. The allure of the procedures outlined here is that the user has two avenues which to impose
smoothness on the underlying bid-value relationship, the bandwidths as well as the constraint weighting
to ensure a monotonic relationship. The rule-of-thumb approach precludes this second option.
Panel (b) plots the uniform and constraint weights used in the analysis. We see that for values away
from the regions of non-monotonicity, the constraint weights are constant and almost identical to the
uniform weights, whereas the weights near the regions of non-monotonicity fluctuate around the uniform
weights. A similar pattern is observed in the examples in Hall, Huang, Gifford, and Gijbels (2001).

6

Conclusion

In this paper, we extend a nonparametric method originally proposed for estimating a survival function
that can accommodate theoretical restrictions, such as monotonicity, to structural auction settings. The
flexibility of the approach permits estimation using data drawn from heterogenous auctions and auctions
with reserve prices and differing numbers of bidders. We further extend the method by introducing an
automated bandwidth selection process for each of these settings. This is particularly important given
that we show that monotonicity, in an empirical auction setting, is directly linked to the bandwidth used

20

in current nonparametric approaches. This lends further support to the argument that is well-known
throughout the statistics and econometrics literature: bandwidth selection is critical, regardless of the
setting.
Our work also reveals that errors in bidding by experimental subjects can yield theoretically-inconsistent
conclusions. Specifically, applying our estimator, along with our proposed data-driven bandwidth algorithm, to the data collected in Dyer, Kagel, and Levin (1989) yields several small, non-monotonic
portions of the estimated equilibrium strategy. At the same time, when using a rule-of-thumb bandwidth, the estimator produces a bid-value relationship which is linear, consistent with the true shape
of the bid-value relationship. Unfortunately, this bandwidth also produces a very inaccurate estimate.
The primary reason for this difference is that the rule-of-thumb bandwidth assumes that the unknown
density is normally distributed.
As stated above, we believe that both the automated bandwidth selection and the ability to impose theoretical constraints on the estimated bidding relationship have value beyond that of structural
auctions. Given the importance of monotone comparative statics in economics (Athey 2001, 2002),
these techniques should prove indispensable in the application of nonparametric estimation to structural
settings.
While we have laid out the framework for constrained nonparametric analysis of auctions, much
remains to be done. Future research is needed to extend these methods both within the IPVP, as well as
beyond. Within the IPVP, the methods need to be augmented to allow for auction-specific heterogeneity
in terms of risk aversion and learning. Outside of the IPVP, these methods can be tailored to the affiliated
private value, common value, and conditionally independent private information paradigms that have
been developed.

21

References
[1] Athey, S., 2001. Single crossing properties and the existence of pure strategy equilibria in games of
incomplete information. Econometrica 69, 861-890.
[2] Athey, S., 2002. Monotone comparative statics under uncertainty. Quarterly Journal of Economics
108, 187-223.
[3] Athey, S., Haile, P.A., 2002. Identification of standard auction models. Econometrica 70, 2107-2140.
[4] Athey, S., Haile, P.A., 2008. Nonparametric approaches to auctions, in Handbook of Econometrics,
Volume 6, edited by J.J. Heckman and E. Leamer. Elsevier: Amsterdam.
[5] Bajari, P., 2001. Comparing competition and collusion: A numerical approach. Economic Theory
18, 187-205.
[6] Bajari, P., HortacÌ§su, A., 2005. Are structural estimates of auction models reasonable? Evidence
from experimental data. Journal of Political Economy 113, 703-741.
[7] Bajari, P., L. Ye, 2003. Deciding between competition and collusion. Review of Economics and
Statistics 85, 971-989.
[8] Beresteanu, A., 2004. Nonparametric estimation of regression functions under restrictions on partial
derivatives. Duke University working paper.
[9] Bowman, A. W., P. Hall, T. Prvan, 1998. Bandwidth selction for the smoothing of distribution
functions. Biometrika 85, 799-808.
[10] Chak, P.M., N. Madras, B. Smith, 2005. Semi-nonparametric estimation with Bernstein polynomials. Economics Letters 89, 153-156.
[11] Chernozhukov, V., I. Fernandez-Val, and A. Galichon, 2009. Improving point and interval estimates
of monotone functions by rearrangement. Biometrika 96(3), 559-575.
[12] Cressie, N.A.C., Read, T.R.C., 1984. Multinomial goodnes-of-fit tests. Journal of the Royal Statistical Society, Series B 46, 440-464.
[13] Du, P., Parmeter, C.F., Racine, J.S., 2010. Constrained Nonparametric Kernel Regression: Estimation and Inference. Working Paper, Department of Statistics, Virginia Tech.
[14] Dyer, D., Kagel, J. H., Levin, D., 1989. Resolving uncertainty about the number of bidders in
independent private-value auctions: an experimental analysis. RAND Journal of Economics 20,
268-279.
[15] Gallant, A. R. 1981. On the bias in flexible functional forms and an essentially unbiased form: the
Fourier flexible form. Journal of Econometrics 15, 211-245.
[16] Guerre, E., Perrigne, I., Vuong, Q., 2000. Optimal Nonparametric estimation of first-price auctions.
Econometrica 68, 525-574.

22

[17] Hall, P., Huang, L.-S., 2001. Nonparametric kernel regression subject to monotonicity constraints.
Annals of Statistics 29, 624-647.
[18] Hall, P., Huang, L.-S., Gifford, J.A., Gijbels, I., 2001. Nonparametric estimation of hazard rate
under constraint of monotonicity. Journal of Computational and Graphical Statistics 10, 592-614.
[19] Henderson, D.J., Carroll, R.J., Li, Q., 2008. Nonparametric estimation and testing of fixed effects
panel data models. Journal of Econometrics 144, 257-275.
[20] Henderson, D.J., Parmeter, C.F., 2009. Imposing economic constraints in nonparametric regression: Survey, implementation and extension. Advances in Econometrics: Nonparametric Methods,
Elsevier Science, Volume 25, edited by Q. Li and J. S. Racine, 433-469.
[21] Hotz, V.J., Miller, R.A., 1993. Conditional choice probabilites and the estimation of dynamic
models. Review of Economic Studies 60, 497-529.
[22] Imbens, G., Spady, R.H., Johnson, P., 1998. Information theoretic approaches to inference in conditional moment condition models. Econometrica 66, 333-357.
[23] Kneip, A., Simar, L., 1996. A general framework for frontier estimation with panel data. Journal
of Productivity Analysis 7, 187-212.
[24] Krasnokutskaya, E., 2009. Identification and estimation in highway procurement auctions under
unobserved auction heterogeneity. Review of Economic Studies, forthcoming.
[25] Levitt, S., List, J.A. 2007. What do laboratory experiments measuring social preferences reveal
about the real world? Journal of Economic Perspectives 21, 153-174.
[26] Li, Q., Racine, J. 2007. Nonparametric Econometrics: Theory and Practice, Princeton University
Press.
[27] Li, T., Perrigne, I., Vuong, Q., 2000. Conditionally independent private information in OCS wildcat
auctions. Journal of Econometrics 98, 129-161.
[28] Li, T., Perrigne, I., Vuong, Q., 2002. Structural estimation of the affiliated private value auction
model. RAND Journal of Economics 33, 171-193.
[29] Li, T., Perrigne, I., Vuong, Q., 2003. Semiparametric estimation of the optimal reserve price in
first-price auctions. Journal of Business & Economic Statistics 21(1), 53-64.
[30] McAfee, R. P., D. Vincent, 1992. Updating the reserve price in common-value auctions. American
Economic Review, Papers and Proceedings 82, 512-518.
[31] Marron, J.S., Nolan, D., 1989. Canonical kernels for density estimation. Statistics and Probability
Letters 7, 195-199.
[32] Martins-Filho, C., Yao, F., 2008. A smooth nonparametric conditional quantile frontier estimator,
Journal of Econometrics 143, 317-333.

23

[33] Matzkin, R., 1994. Restrictions of economic theory in nonparametric methods, Handbook of Econometrics, vol. 4 (R.F. Engle and D. L. McFadden eds.) North-Holland: The Netherlands, chapter
42, 2524-2558.
[34] Olley, G. S., Pakes, A., 1996. The dynamics of productivity in the telecommunications equipment
industry, Econometrica 64(6), 1263-1297.
[35] Owen, A., 1988. Empirical likelihood ratio confidence intervals for a single functional. Annals of
Statistics 22, 300-325.
[36] Paarsch, H., 1992. Deciding between the common and private value paradigms in empirical models
of auctions. Journal of Econometrics 51, 191-215.
[37] Paarsch, H., Hong, H., 2006. An introduction to the structural econometrics of auction data. MIT
Press: Cambridge.

24

Figure 1: Monotonization for data simulated from a truncated log-normal distribution. Panel (a) represents
the 95th percentile of D0 (pÌ‚) = 1.811407, the long-dashed line, the GPV estimator, the solid line, as well
as the constrained GPV estimator for the same dataset with Ï = 0.5, D0.5 (pÌ‚) = 1.846482 represented by
the short-dashed line, and with Ï = 1, D1 (pÌ‚) = 0.003746 represented by the dotted line. Panel (b) depicts
the envelope curves of the values of pÌ‚ after the monotonicity constraint had been achieved with Ï = 0, 0.5,
and 1, again with the respective line types.

25

Figure 2: Monotonization for data simulated from a truncated gamma distribution. Panel (a) represents
the 95th percentile of D0 (pÌ‚) = 0.615096, the long-dashed line, the GPV estimator, the solid line, as well
as the constrained GPV estimator for the same dataset with Ï = 0.5, D0.5 (pÌ‚) = 0.622522 represented by
the short-dashed line, and with Ï = 1, D1 (pÌ‚) = 0.001259 represented by the dotted line. Panel (b) depicts
the envelope curves of the values of pÌ‚ after the monotonicity constraint had been achieved with Ï = 0, 0.5,
and 1, again with the respective line types.

26

30

Figure 3: Plots of the Dyer, Kagel, and Levin (1989) first price auction experimental data with six bidders.

15
0

5

10

value

20

25

LSCV Estimates
CWB Estimates
RoT Estimates
True BidÃ¯Value

0

5

10

15

20

bid

(a) Estimated Bid-Value Relationships

0.0025
0.0020
0.0015

p.uniform

0.0030

Uniform Weights
CWB Weights

0

5

10

15
bid

(b) Weights

27

20

25

