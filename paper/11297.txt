NBER WORKING PAPER SERIES

THE TIME-SERIES PROPERTIES OF AGGREGATE CONSUMPTION:
IMPLICATIONS FOR THE COSTS OF FLUCTUATIONS
Ricardo Reis
Working Paper 11297
http://www.nber.org/papers/w11297
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2005

I am grateful to Gadi Barlevy, Per Krusell, Yves Nosbusch, Jonathan Parker, Chris Sims, Lars Svensson, and
Mark Watson for useful comments. Contact: rreis@princeton.edu. First draft: November 2004. The views
expressed herein are those of the author(s) and do not necessarily reflect the views of the National Bureau
of Economic Research.
©2005 by Ricardo Reis. All rights reserved. Short sections of text, not to exceed two paragraphs, may be
quoted without explicit permission provided that full credit, including © notice, is given to the source.

The Time-Series Properties of Aggregate Consumption: Implications for the Costs of Fluctuations
Ricardo Reis
NBER Working Paper No. 11297
April 2005
JEL No. E32, E21, E60

ABSTRACT
While this is typically ignored, the properties of the stochastic process followed by aggregate
consumption a.ect the estimates of the costs of fluctuations. This paper pursues two approaches to
modelling aggregate consumption dynamics and to measuring how much society dislikes
fluctuations, one statistical and one economic. The statistical approach estimates the properties of
consumption and calculates the cost of having consumption fluctuating around its mean growth. The
paper finds that the persistence of consumption is a crucial determinant of these costs and that the
high persistence in the data severely distorts conventional measures. It shows how to compute valid
estimates and confidence intervals. The economic approach uses a calibrated model of optimal
consumption and measures the costs of eliminating income shocks. This uncovers a further cost of
uncertainty, through its impact on precautionary savings and investment. The two approaches lead
to costs of fluctuations that are higher than the common wisdom, between 0.5% and 5% of per capita
consumption.
Ricardo Reis
Princeton University
Department of Economics
324 Bendheim Hall
Princeton, NJ 08544-1021
and NBER
rreis@princeton.edu

1

Introduction

In a famous contribution, Robert Lucas Jr. (1987) asked: what would be the eﬀect on welfare of eliminating economic fluctuations? As Lucas (1987, page 3) put it, answering this
question would allow us “to get a quantitative idea of the importance of stabilization policy
relative to other economic questions.” To reach an answer, Lucas made three assumptions.
First, he assumed that society’s preferences can be represented by a welfare function that
depends on the time path of consumption per capita alone. That is, he assumed not only
that there is a representative consumer, but also that her utility function represents society’s normative preferences. Second, he assumed that this welfare function is time-separable
and iso-elastic. Third, he assumed that the log of annual per capita consumption is serially uncorrelated and normally distributed around a linear trend. These three assumptions
produced a surprising result: society would be willing to sacrifice a meagre 0.05% of consumption to get rid of fluctuations. The economic fluctuations that macroeconomists have
focused so much attention on cost each person on average only $12 per year.
A large literature has followed focusing especially on the first two assumptions. Imrohoroğlu (1989), Atkeson and Phelan (1994), Krusell and Smith (1999), Storesletten, Telmer
and Yaron (2001), Beaudry and Pages (2001), and Krebs (2003, 2004) measured the costs
of fluctuations in economies where agents are heterogeneous and markets are incomplete, so
that there is not a representative consumer whose preferences are a valid measure of welfare.
While it is conceivable that the costs of fluctuations would be higher, as bad income shocks
hurt a few households severely, the typical finding from these studies is that the costs of
fluctuations are only slightly higher or even lower than the Lucas benchmark. Other studies
looked at the second assumption of iso-elastic preferences. Dolmas (1998), Otrok (1999),
Tallarini (2000), and Epaulard and Pommeret (2003) assumed diﬀerent utility functions,
while Alvarez and Jermann (2004) used asset prices to elicit rather than assume preferences over risk. While many of these studies found much larger estimates of the costs of
fluctuations, this came typically at the expense of assuming people are extremely averse to
risk, which appears to be inconsistent with the risk-taking that we observe in their choices
(Lucas, 2003).
The focus of this paper is on the third assumption that consumption is serially uncorrelated. I will present alternative models of consumption dynamics and study their impact

2

on estimates of the costs of fluctuations. I will consider statistical models of aggregate consumption and show that if consumption is very persistent, as is the case in the U.S. data,
Lucas’ (1987) estimates are severely downward-biased. A methodological contribution of
this paper is to show how to construct reliable estimates of the costs of fluctuations when
there is persistence of the degree that we observe.
Together with statistical models, I will also consider economic models in which consumption fluctuations are an optimal response to shocks. One virtue of having endogenous
consumption choices is that it uncovers a cost of fluctuations that is typically ignored in
the literature: the existence or not of fluctuations aﬀects the level and growth rate of consumption by aﬀecting the desire for precautionary savings and for risky investment. The
discipline imposed across the diﬀerent models is that they must all match the main features
of the aggregate consumption data.
The Lucas assumption that shocks to consumption are serially uncorrelated is clearly
dismissed by the data. More surprisingly, either interpreted through an economic model
or using an estimated statistical model, the adequate process for aggregate consumption
implies that the costs of fluctuations are actually one or two orders of magnitude than Lucas
argued. The estimates in this paper suggest that the costs of fluctuations are between 0.5%
and 5% of per capita consumption.
It is important to be clear about how these estimates should be used. This paper
measures the costs of eliminating the uncertainty that makes consumption fluctuate. These
numbers do not distinguish between fluctuations due to productivity or monetary shocks,
or between those that correspond to business cycles and those that are due to uncertainty
about long-run growth. In terms of economic theories, what these large numbers suggest
is that focusing attention on deterministic growth models, as it happened at least partly
in response to Lucas’ original results, will be missing out on a significant part of welfare.
Section 6 of this paper will discuss how the results in this can be used to assess the costs
associated with business cycles more specifically.
Even though the assumption that consumption is serially uncorrelated is clearly at odds
with the data, it has received little attention in the literature. A few studies have modelled
consumption instead as a random walk (Dolmas, 1998, Tallarini, 1999, and Epaulard and
Pommeret, 2003), but their focus was on the other assumptions behind the Lucas’ calculations. This paper instead systematically investigates the eﬀect of the stochastic properties
3

of the consumption data on the costs of fluctuations. This focus leads the paper to address
some problems with making inferences about the costs of fluctuations, which the literature
has so far ignored. More related to this paper is Obstfeld (1995), who found that modeling consumption as a random walk only slightly increased the costs of fluctuations. I will
show that this conclusion hinges on the way in which Obstfeld calibrated the parameters
of his model; an alternative approach, which is more in accord with the data, gives the
opposite result. On the side of theory, this paper shares with Barlevy (2004) the emphasis
on measuring the costs of fluctuations without excluding the possibility that these may
have long-lasting eﬀects, either through long-lived fluctuations or through an impact on the
average growth rate.
The paper proceeds as follows. Section 2 presents some simple models of consumption
that highlight the main determinants of the costs of fluctuations. These involve choosing
some key parameters, and section 3 discusses the evidence that will guide the choice of
values for these parameters. Section 4 estimates the costs of fluctuations across a variety of
statistical models for consumption, while section 5 uses instead economic models. Section
6 concludes by interpreting the economic significance of the estimates.

2

Models of consumption and the costs of fluctuations

A central tenant of most theories of choice under uncertainty is that people dislike risk. If
society faced a choice between its current risky consumption series {Ct } and a “suitably
modified” consumption series {C̄t } that is purged from fluctuations, it is assumed that
society would choose the latter. As Lucas (1987) emphasized, it is important to go one step
further and be able to quantify this preference for stability. He suggested measuring the
costs of fluctuations by the fraction of annual consumption that society would be willing to
pay to eliminate these fluctuations. Maintaining his assumptions of a utility function that
is time-separable (with discount rate ρ) and iso-elastic (with a coeﬃcient of relative risk
aversion γ), the costs of fluctuations (λ) are defined as the solution to:1

E

1

"

∞
X
t=0

−ρt

e

Ã

(Ct (1 + λ))1−γ − 1
1−γ

!#

=

∞
X
t=0

−ρt

e

µ

C̄t 1−γ − 1
1−γ

E[.] denotes the expectation operator conditional on information at time 0.

4

¶

.

(1)

Solving this equation requires two pieces of information. First, one needs the stochastic
process for the risky consumption path in order to evaluate the expectation. Second, one
must define precisely what the counterfactual “suitably modified” consumption series is.
Both of these requirements are met by having a model for consumption. This paper will
consider two distinct approaches to modelling consumption: one consists of estimating a
statistical process for consumption; the other consists of assuming an economic environment
in which society optimally chooses how much to consume.
Statistical models of consumption
From a statistical perspective, a natural choice for the counterfactual consumption series
is expected consumption. The exercise of eliminating fluctuations then corresponds to
eliminating the variability of consumption, while keeping its mean unchanged. One of
the stylized facts about economic growth in the United States in the past century is that
consumption, like income, has grown at an approximately constant rate. An appropriate
model for counterfactual consumption is: C̄t = E[Ct ] = C0 egt .
I will maintain the assumption that consumption is log-normally distributed. The U.S.
data is consistent with this assumption and it is analytically convenient since it leads to the
following simple expressions for the costs of fluctuations:2
⎧
⎨ 0.5(1 − eg−r ) P∞ e(g−r)t V ar(ct )
if γ = 1
t=0
ln(1 + λ) =
£
P
⎩ 1 ln (1 − eg−r ) ∞ e(g−r)t e0.5γ(γ−1)V ar(ct ) ¤
γ−1

t=0

(2)
if γ 6= 1.

Small letters denote the natural logarithm of the respective capital letter, e.g., ct = ln(Ct ).
In the expressions, I replaced the (unobservable) discount rate by the (observable) average
real interest rate r, using Ramsey’s result that with iso-elastic preferences, γg ∼
= r − ρ.
Estimating the costs of fluctuations now requires only calculating the forecast error variance of consumption at diﬀerent horizons. This, in turn, requires a model of consumption
dynamics. One simple model of de-trended consumption is
ct = ηct−1 + εt ,

(3)

where εt is normally distributed with mean zero and variance σ 2 . This representation fits
2

The calculations leading to this and most other results are in the appendix.

5

the post-war U.S. consumption data well: lagged consumption can account for 84% of the
variability of present consumption when η equals the least squares estimate 0.92. Moreover,
special cases of (3) correspond to two important processes. Lucas (1987) assumed that η = 0
and I will correspondingly call this the Lucas consumption process. Hall (1978) showed that
optimally chosen consumption dynamics approximately follow a random walk and that the
U.S. data is consistent with this assumption. This corresponds to the case η = 1, which I
will label the Hall consumption process.
With this AR(1) model and if |η| ≤ 1, the costs of fluctuations approximately equal:
λ ∼
=
=

0.5γσ 2
r − g + 1 − η2
¶
µ
0.5γ(1 − η 2 )
σ2
.
×
r − g + 1 − η2
1 − η2

(4)
(5)

These formulae shows clearly the role of diﬀerent parameters on the costs of fluctuations.
The roles of γ and r − g and their calibration will be discussed in section 3. The focus of
this paper is on the properties of the stochastic process for consumption on the costs of
fluctuations. In this case, these are captured by the two parameters σ 2 and η.
The first expression (4) shows that λ increases with both the variability and the persistence of consumption. The larger is the variability of shocks to consumption, the more
society finds these shocks costly, so the more it is willing to pay to eliminate consumption
fluctuations. The more persistent are shocks to consumption, the more long-lived is their
impact on consumption, and thus the larger their cost.3 Still, for r −g = 0.02, which section
3 will justify, even when η is as high as 0.8 so that a shock to consumption takes about
two years to dissipate by half, the costs of fluctuations are only twice higher than those
with a process with no persistence. As persistence increases further though, the costs of
fluctuations increase quite rapidly. If η is 0.9, the costs are already 7 times larger than with
a Lucas process, and if η = 0.95 they are 14 times higher. The impact of the persistence on
the costs of fluctuations is more dramatic when we shift from the Lucas to the Hall models.
If r − g = 0.02, then the Hall consumption model predicts costs of fluctuations that are 51
3
When ρ = 0, the formula in (4) diﬀers from the one derived by Lucas (1978) by a factor of 1/(1 + r − g).
This diﬀerence arises because I evaluate expected utility conditional on information at time 0, whereas
Lucas computes the unconditional expectation. Since r − g is close to zero, this diﬀerence is quantitatively
negligible. I focus on the conditional rather than the unconditional expectations, since in the latter case the
costs of fluctuations would be infinite when ρ = 1 and would be severely downward biased when ρ is close
to 1 since the unconditional variance would be estimated using the relatively short post-war U.S. sample.

6

times larger than those estimated by Lucas. If r − g = 0.01, another value that section 3
will show is consistent with the data, the costs of fluctuations are two orders of magnitude
larger than what Lucas estimated.
These calculations assumed that σ 2 was held fixed while η varied. It might be argued
that Lucas (1987) instead measured the unconditional variance of consumption, which corresponds to σ 2 /(1 − η 2 ). In expression (5), the first term actually decreases as η rises. The
reason is that keeping the unconditional variance fixed, raising η increases the predictability
of consumption by lowering its forecast error variance. The consumer therefore faces less
risk so the costs of fluctuations fall. However, rather than undermining the argument of
the previous paragraph, instead this alternative view of the Lucas (1987) calculation provides an alternative demonstration of its limitations. Lucas (1987) used a finite sample to
gauge the unconditional variance of consumption. This implies that if consumption is very
persistent, his estimate is severely downward biased. This is particularly clear in the case
where consumption follows a random walk: while in a finite sample one obtains a finite estimate of the variance of consumption, the actual variance is infinite. Even if consumption
is stationary, if it is very persistent, one will obtain a very downward-biased estimate of its
variance using the post-war U.S. sample.
Whichever way you look at it, what these calculations show is that it is crucial to jointly
estimate both the volatility of shocks to consumption and their persistence. One needs a
statistical model for consumption to calculate the costs of fluctuations. Section 4 will attack
this estimation problem directly using diﬀerent statistical approaches.
Economic models of consumption
An economic model of consumption starts with a specification of the environment facing
a representative consumer earning a random income stream.4 The consumption process is
then whatever is optimally chosen. The counterfactual consumption with no fluctuations is
what the consumer would choose if income was stable.
4

To focus solely on the third of the Lucas (1987) assumptions, I will maintain the assumption of a
representative consumer. It would be interesting in future work to both model the consumption process
carefully and to take into account the large idiosyncratic risks facing households (Parker and Preston, 2004).

7

In this section, I consider a simple economic environment. The consumer solves:

max E
{Ct }

"∞
X

e−ρt

t=0

Ã

Ct1−γ − 1
1−γ

!#

s.t.: Kt+1 + Ct = Rt Kt .

(6)
(7)

The budget constraint states that savings (Kt+1 ) plus consumption equals income. Last
period’s savings are the only source of income through investment in a risky technology
with positive marginal return Rt , which is log-normally distributed with mean r − 0.5σ 2
and variance σ 2 . The consumer starts at time 0 with some positive amount of capital K0 .
The appendix shows that the solution to this problem is:
ct = ct−1 + g − 0.5σ 2 + εt ,

(8)

where g = (r − ρ)/γ + 0.5(γ + 1)σ 2 − σ 2 ,
¡
¢
with initial condition C0 = 1 − eg−r R0 K0 .
In this model, consumption follows a random walk as in the Hall statistical model. However, there is one important diﬀerence between the two models. Now, both the level and the
growth rate of consumption are functions of σ 2 . Income uncertainty not only causes fluctuations in consumption but also has two eﬀects on the level and growth rate of consumption,
captured by the two terms on the right-hand side of the expression for g. The first eﬀect
is due to precautionary savings: the rational consumer reacts to the uncertainty by saving
more. This allows her to accumulates a stock of precautionary savings to safeguard against
unexpected future bad shocks. The second eﬀect is due to investment risk: the risk-averse
consumer will shy away from the investing in the risky technology. In this model, as long
as relative risk aversion exceeds one, the combined precautionary-investment eﬀect is such
that eliminating fluctuations would raise the level of consumption and reduce growth.5
The counterfactual C̄ therefore diﬀers from average consumption both in the level of
initial consumption and in its growth rate. While one can follow Lucas and calculate the
gains from eliminating fluctuations in consumption, one needs a theory of consumption
choices to calculate the costs of fluctuations in income. The latter aﬀect not just the
5

Barlevy (2004) has suggested a complementary channel through which fluctuations aﬀect growth. Eliminating uncertainty may raise investment in innovative activities and consequently long-run growth.

8

fluctuations in consumption, but also the level and growth rate of consumption through the
precautionary-investment motive.
Moreover, note that this precautionary-investment eﬀect is more general than the model
in this section. It will be present in most economic models of consumption under uncertainty,
regardless of their predictions for the persistence of consumption.6 Likewise, while growth
may be higher or lower without uncertainty, welfare will always be higher. By ignoring this
eﬀect, statistical models will necessarily underestimate the costs of fluctuations.
Initial estimates of the costs of fluctuations
Table 1 presents estimates of the costs of fluctuations for the diﬀerent models that I have
discussed so far. The value of σ 2 for each model is estimated using U.S. annual data from
1947 to 2003 on real per capita consumption of non-durables and services from the Bureau
of Economic Analysis. This will be the measure of consumption used in this paper. Quarterly data leads to very similar results; total consumption, which inappropriately includes
expenditure on durables as current consumption, approximately doubles the estimate of σ 2
and so doubles all of the estimates of the costs of fluctuations. As for the choice of values
for γ and r − g, it will be discussed at length in section 3.
Panel A displays the estimates with the Lucas model of consumption. As Lucas (1987)
originally concluded, fluctuations cost very little, between 0.04% and 0.2% of per capita
consumption. Panel B presents estimates for the AR(1) statistical model fitted to the U.S.
data. The estimated η implies a considerable amount of persistence, with a half-life of
deviations from trend growth after a shock of 8 years. However, the estimated costs still
lie in the same range as the Lucas estimates.7 These results should be interpreted with
great care though; section 4 will show that these estimates are statistically inconsistent and
severely downward biased.
Panel C shifts to the economic model presented in this section. The infinite persistence
of shocks and the precautionary savings eﬀect combine to generate substantially larger costs
of fluctuations, between 0.2% and 3.1%. This upper bound is almost 80 times larger than
6

Epaulard and Pommeret (2003) find an eﬀect of volatility on growth in an AK-growth model, but
interpret it as being specific to endogenous growth models. Actually, this eﬀect is present in most models
of consumption and uncertainty.
7
The reader may be surprised that the estimates in panel B are actually lower than those in panel A, in
spite of the higher persistence. The reason is that the estimated volatility of shocks is lower for the AR(1)
than for the Lucas model, which drives down the costs of fluctuations.

9

the smallest number in Panel A that Lucas focused on.
Table 1 — Estimates of the costs of fluctuations in three simple models
Panel A: The Lucas statistical model
γ=1

γ=3

γ=5

0.04%
($9)

0.12%
($28)

0.20%
($46)

Panel B: The AR(1) statistical model estimated by least squares

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.03%
($8)
0.04%
($8)
0.04%
($9)

0.10%
($24)
0.11%
($25)
0.12%
($27)

0.17%
($40)
0.18%
($43)
0.19%
($45)

Panel C: The random walk economic model

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.21%
($48)
0.31%
($73)
0.63%
($147)

0.62%
($145)
0.94%
($219)
1.88%
($441)

1.03%
($242)
1.56%
($365)
3.14%
($735)

Each cell shows the per capita costs of fluctuations as a fraction of consumption
and, in brackets, in 2003 dollars. The standard deviation of shocks is 0.028, 0.011,
and 0.011, for panels A to C respectively.

After a brief detour in the next section to discuss the calibration of γ and r − g, the
remainder of this paper explores more refined estimates of the costs of fluctuations. Section
4 estimates statistical models that deal with the high persistence of consumption data, while
section 5 builds more elaborate economic models of consumption. To preview the results,
most models will suggest that the costs of fluctuations are closer to those in Panel C.

3

Choice of parameters

Risk aversion

10

The extent to which society dislikes risk is measured by the coeﬃcient of relative risk
aversion γ. While this parameter is at the center of many economic models, there is some
disagreement on its value. The wider disagreement comes from looking at either data on
consumption choices, or data on financial market prices.
Data on consumption choices suggests a value for relative risk aversion between 1 and
5. Arrow (1971) originally made a case for relative risk aversion equal to 1 on theoretical
grounds. Friend and Blume (1975) looked at variation in portfolio allocations between
households and found values between 2 and 4. The consumption of leisure can also be
used to elicit preferences towards risk. Chetty (2005) shows that the choices by consumers
facing the risk of unemployment combined with plausible values for the income and wage
elasticities of labor supply imply that the coeﬃcient of relative risk aversion is at most 2.
People’s choice of careers with risky income profiles also runs against very high risk aversion
(Saks and Shore, 2004), as does their choice to hold most of their wealth in illiquid housing
that carries a significant amount of risk (Cocco, 2003).
Starting with Mehra and Prescott (1985), economists have realized that financial market
prices imply much higher risk aversion. In order to account for the large premium that
equity pays over Treasury bills requires that relative risk aversion is at least 50 and close
to 200. This paper oﬀers no solution to this disparity between consumption and financial
price data. The approach taken here (as the title indicates) is to use consumption data to
measure the costs of fluctuations, so I will use values for relative risk aversion between 1
and 5. The hope is that these measurements are more robust to advances in the theory
linking consumption choices to financial markets.8
Discounting future costs
The diﬀerence between the return on savings and the growth rate of consumption, r − g,
equals the growth rate of the marginal utility of consumption. This is the eﬀective rate
at which consumers discount the impact of shocks on future consumption. The smaller is
r − g, the less people discount the future costs of a shock that persists for at least a few
periods. Thus, the larger the overall costs of fluctuations.
8

A few recent papers oﬀer some hints at reconciling a reasonable degree of risk aversion with asset prices
using precisely observations on consumption. Gabaix and Laibson (2003) and Chetty and Szeidl (2004) show
that the infrequent adjustment of plans regarding total or parts of consumption, due to either inattentive
behavior or consumption commitments, can explain the equity premium.

11

The average return on savings and the average consumption growth rate are both observable in the data, so calibrating r−g is a relatively easy matter. Poterba (1998) estimates
the after-tax return on capital in the United States in the period 1959-1996 to be either
3.9% or 5%, depending on whether one includes property taxes or not. McGrattan and
Prescott (2003) use data from 1880 to 2002 and find returns of 4% on accounting capital,
and 5.4% on equity. As for the average annual growth rate of per capita consumption, it
equals 2.2%. These point estimates therefore suggest a value for r − g somewhere between
1.7% and 2.2%. Correspondingly, I will consider the values of 1%, 2%, and 3% for r − g.
The role of the intertemporal elasticity of substitution
Obstfeld (1995) argued that it is important to distinguish between risk aversion and intertemporal substitution when calculating the costs of fluctuations. He noted that while risk
aversion determines the per-period cost of volatility, intertemporal substitution determines
the weights given to the future cumulative per-period costs.
To investigate this claim, I consider the specification of preferences due to Epstein and
Zin (1989) and Weil (1990). Utility at time t, Vt , is defined by the recursion:
¤(1−θ)/(1−γ)
¤(1−θ)/(1−γ)
£
£
= (1−e−ρ )Ct1−θ +e−ρ 1 + (1 − e−ρ )(1 − γ)Et [Vt+1 ]
.
1 + (1 − e−ρ )(1 − γ)Vt
(9)

The parameter γ still equals the coeﬃcient of relative risk aversion. Nevertheless, now the
intertemporal elasticity of substitution equals 1/θ. With the expected utility preferences in
(8), the elasticity of intertemporal substitution equals the inverse of relative risk aversion,
so the two concepts cannot be distinguished. (You can see this by noting that if γ = θ,
then (9) becomes (6).)
Solving for optimal consumption and for the costs of fluctuations in the economic model
in (9) and (7) is an easy matter. The appendix contains the calculations, which lead to the
following surprising result: The costs of fluctuations with Epstein-Zin-Weil preferences (9)
are the same as the costs with iso-elastic preferences (6) up to a term in O(σ 4 ). Therefore,
distinguishing between intertemporal substitution and risk aversion does not aﬀect the
estimates of the costs of fluctuations. Moreover, the intertemporal elasticity of substitution
does not enter the formula for the costs of fluctuations.
How can this finding be reconciled with Obstfeld’s (1995) conclusion? The explanation
12

lies in the following expression that holds with the preferences in (9):
r = ρ + θg − 0.5γσ 2 (θ − 1).

(10)

This paper used the available direct observations on r, the parameter that directly aﬀects
the costs of fluctuations. Obstfeld (1995) instead chose a value for ρ. Therefore, his choice
of the elasticity of intertemporal substitution aﬀected the value attributed to the return on
capital via expression (10), which in turn aﬀected the estimates of the costs of fluctuations.
Because Obstfeld (1995) set ρ at 0.05, and θ between 2 and 20, he implicitly attributed a
value for the average after-tax return to capital between 9% and 49% per annum. Thus,
his calculations heavily discounted the future costs arising from persistent shocks, which
explains why he found that going from the Lucas to the Hall consumption models had little
eﬀect on the costs of fluctuations.

4

Statistical models of consumption

Which process for consumption? Lucas versus Hall
Section 2 showed that the Lucas and Hall statistical models of consumption imply very
diﬀerent costs of fluctuations. Because these models impose a rigid structure on the timeseries of consumption, one can test which best describes the data.
Table 2 shows the results from diﬀerent tests of the null hypothesis that consumption
has a unit root: the original (augmented) test of Dickey and Fuller (1979), the alternative
due to Phillips and Perron (1988), the point-optimal test of Elliott, Rothenberg and Stock
(1996), and finally the modified Phillips-Perron (MZt ), point-optimal (MPt ), and Barghava
statistic (MSB) tests combined with a modified Schwarz criteria to select the lag length.
These last three test were suggested by Ng and Perron (2001) in order to account for size
distortions if the underlying data process is stationary. The results are clear: the null
hypothesis corresponding to the Hall process is never rejected at the 5% significance level.
The last row of the table presents the result of a test, by Kwiatkowski et al (1992), of
the null hypothesis that consumption is trend stationary. The data rejects this hypothesis
at the 5% significance level.

13

Table 2 — Statistical tests of whether consumption has a unit root
Test

Test statistic

5% critical value

Decision

Dickey-Fuller

-1.88

-3.49

not rejected

Phillips-Perron

-1.74

-3.49

not rejected

Elliott-Rothenberg-Stock

10.95

5.71

not rejected

MZt

-2.02

-2.91

not rejected

MSB

0.24

0.17

not rejected

MPt

10.83

5.48

not rejected

0.17

0.15

rejected

Null hypothesis: Unit Root

Ng-Perron:

Null hypothesis: Stationarity
Kwiatkowski et al

The modified Schwarz criterion of Ng and Perron (2001) with a maximum lag of 10 selected the
lag length of the regressions. For the Phillips-Perron and the Kwiatkowski et al tests, I estimated
the spectral density at frequency zero with a Bartlett kernel.

There is a simple way to understand why the data clearly favors the Hall process over
the Lucas process. It is possible to nest the two models in a single regression equation:
ct − ct−1 = const. + ut − βut−1 ,

(11)

where ut is the residual. The Lucas process imposes the restriction β = 1, while the Hall
process requires that β = 0.
The 1947-2003 U.S. data produces an estimate of β of −0.36 with a standard error of
0.13. Not only is the estimate lower than one, it is not even positive — thus the strong
statistical rejection of the Lucas model. However, note that while the Hall model is closer
to the data, it is also rejected at the 5% significance level. Consumption growth is positively
serially correlated, a fact that has inspired most modern research on consumption.9 Fitting
the facts requires richer models of consumption dynamics; the rest of this section investigates
diﬀerent possibilities.

9

See Fuhrer (2000) and Reis (2004) for two alternative models that try to account for this positive serial
correlation, either by appealing to habits or to costs of processing information.

14

Estimating the persistence of U.S. consumption
A statistical model for consumption that is more general than either the Lucas or the
Hall models is the AR(1) in (3), where η is not restricted to necessarily equal either one
or zero. A naive application of this model would be to estimate η by least squares and, if
this estimate is below 1, apply the formula in (4). This was the procedure that led to the
estimates in panel B of table 1.
However, it is well-understood that for very persistent series like consumption, the leastsquares estimate of η is downward-biased. For example, if the true model is a random walk,
then the least squares estimate of η will be below 1 with a probability of 68%. Given how
steeply costs increase with η when it is close to 1, this can lead to severely under-estimating
the costs of fluctuations.
The most popular way to deal with this problem is to model η as lying within a circle of
radius c/n around 1, where n is the size of the available sample. The estimate of the new
parameter c (a “Pitman” drift) has a distribution that can be characterized using local-tounity asymptotics (Stock, 1994). Since deterministic formulae link c to η and in turn to λ,
this characterizes the distribution of the estimate of the costs of fluctuations.
In the data, the confidence intervals for η include a large region well above one. The
formula in (2) would then imply that the costs of fluctuations are estimated to be infinity
with a probability of more than 30%. This result arises because forecast error variances far
ahead shoot quickly to infinity. This highlights one weakness of directly applying the formula
in (2) if consumption follows an explosive process. The estimate of the costs of fluctuations
in this case is dominated by estimates of the variability of consumption at horizons very far
ahead, well above the size of the finite sample in which they were estimated.
The local-to-unity model suggests a natural way to deal with this issue. That model
assumes that as the sample size increases, consumption becomes closer to a random walk;
likewise, one can calculate the costs of fluctuations assuming that after the sample horizon,
the forecast error variance is indistinguishable from that of a random walk. Focusing for
now on the case of log utility, one estimator that formalizes this suggestion is
g−r

L̂ = 0.5(1 − e

)

" n
X
t=0

(g−r)t

e

v̂(ct ) +

∞
X

t=n+1

(g−r)t

e

#

[v̂(cn ) + v̂(c1 )(t − n)] ,

(12)

where v̂(ct ) is the least squares estimator of the the forecast error variance t steps ahead.
15

This estimator replaces v̂(ct ) for horizons that exceed the size of the sample, by the nth
step-ahead forecast error variance for a random walk.10 As n → ∞, this estimator coincides
with the exact value the costs of fluctuations: L̂ → ln(1 + λ). In a finite sample, under
the maintained local-to-unity model, this is the estimator that is within 1/n of the costs of
fluctuations.11
In the AR(1) model, straightforward but tedious algebra shows that, using the approximation 1 + c/n = exp(c/n) + O(1/n2 ):
L̂ = 0.5σ̂ 2 eg−r

" n
X
t=0

#

e(g−r+2c/n)t + e(g−r)n /(1 − eg−r ) ,

(13)

where σ̂ is the least-squares estimate of the standard error of shocks. It is simple to show
that as n → ∞, σ̂ 2 → σ 2 . Applying the functional central limit theorem:
n

1 X (g−r−2c/n)t
e
⇒
n t=0

Z

1

e(g−r+2U)s ds,

(14)

0

where ⇒ denotes weak convergence. U equals the random variable

³R
1
0

´ .³R
´
1
2 ds ,
J(s)dW (s)
J(s)
0

where J(.) is an Orstein-Uhlenbeck process dJ(s) = cJ(s)ds+dW (s) and W (.) is a standard
Brownian motion. The continuous mapping theorem then implies that:
eg−r+2U − 1
L̂
⇒ 0.5σ 2 eg−r
,
n
g − r + 2U

(15)

which fully describes the asymptotic distribution of the estimate of the costs of fluctuations.
According to this asymptotic result, the least squares estimate of the costs of fluctuations
is not only an inconsistent estimate of the true costs, but moreover, it converges to a random
variable. The reason is that as n grows, the least squares estimation errors persist for
longer rather than dying oﬀ. This implies that the estimates in panel B of table 1 were
downward-biased. Yet using the formula in (15), constructing median-unbiased estimates
and confidence intervals for the costs of fluctuations is possible.12
10

For a random walk, V ar(ct ) = σ2 t, so V ar(ct ) = V ar(cn ) + V ar(c1 )(t − n).
This approach has a close relative in Phillips’s (1998) construction of confidence intervals for far-ahead
impulse responses in the local-to-unity model.
12
The distribution of U is not only non-normal but it also depends on the (unknown) value of c. It
therefore requires many numerical simulations to characterize this distribution for each value of c. Stock
(1991) has already done the work of tabulating the distribution of U . Since L̂/n increases monotonically
with U, one use his tables to construct confidence intervals for the estimates of the costs of fluctuations.
11

16

In the appendix, I extend the calculations in this section in two directions. First, I
consider the case when relative risk aversion is diﬀerent from one. Second, I extend the
statistical model to the Dickey-Fuller regression form:

∆ct = κ0 + κ1 t + ct−1 +

k
X

ψ j ∆ct−j + ut .

(16)

j=1

Now, it is the largest autoregressive root that is modelled as 1 + c/n. This allows for a more
flexible characterization of log consumption, as a k + 1th order autoregressive process with
a drift and a time trend.
Table 3 presents median-unbiased estimates and 90% confidence intervals for the estimated costs of fluctuations if consumption dynamics are described by (16). The costs are
now much higher than the naive estimates in table 1. They range from 0.2% to 3.2% of
per capita consumption and even the lower bounds of the confidence intervals are higher
than those in the panel B of table 1. According to these calculations, society substantially
dislikes the current variability in consumption.
Table 3 — The costs of fluctuations when consumption is persistent
Panel A: Costs in percentages of annual per capita consumption

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.21%
(0.19 ; 0.21)
0.31%
(0.29 ; 0.32)
0.63%
(0.60 ; 0.64)

0.63%
(0.57 ; 0.64)
0.95%
(0.87 ; 0.96)
1.90%
(1.81 ; 1.92)

1.05%
(0.95 ; 1.07)
1.58%
(1.46 ; 1.61)
3.19%
(3.03 ; 3.22)

Panel B: Costs in annual per capita 2003 dollars

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

$49
(44 ; 50)
$74
(68 ; 75)
$148
(140 ; 149)

$147
(133 ; 150)
$222
(204 ; 225)
$446
(423 ; 450)

$246
(223 ; 256)
$371
(341 ; 377)
$747
(709 ; 755)

Each cell shows the median unbiased estimate and, in parenthesis, the 90% confidence
interval. The Ng and Perron (2001) modified BIC picked the autoregression’s order.

17

Parametric unrestricted estimates
The evidence at the beginning of this section strongly suggested that consumption is
not stationary. The data does not reject the null hypothesis that the first diﬀerence of
consumption is stationary however. (The unit root tests are not reported here for brevity.)
Wold’s theorem states that any stationary series has a moving average representation. A
general statistical model for consumption then is
∆ct = const. + A(L)ut ,
where ∆ct = (1 − L)ct and A(L) =

P∞

i
i=0 ai L ,

(17)

and L is the lag operator Li ut = ut−i .

If consumption follows this process, the costs of fluctuations in (2) become:
⎧
´
³
⎨ 0.5σ 2 (1 − eg−r ) P∞ e(g−r)t Pt−1 Pj a2
if γ = 1
t=1
j=0
i=0 i
´i
h
³
ln(1 + λ) =
St−1 Sj
P
2
⎩ 1 ln (1 − eg−r ) 1 + ∞ e(g−r)t e0.5σ γ(γ−1) j=0 i=0 a2i
t=1
γ−1

if γ 6= 1.
(18)

It is impossible to estimate the infinite number of parameters ai with a finite number of
observations. However, it has long been known that an ARMA model
B(L)∆ct = const. + C(L)εt ,

(19)

where B(L) and C(L) are lag polynomials of low order, typically provides a good approximation to the dynamics of most macroeconomic series. Given estimates of the ARMA
model, one can easily recover the parameters ai using the relation A(L) = B(L)−1 C(L).
Estimating (19) requires choosing the order of B(L) and C(L). I restricted the range
of admissible models to a maximum of 3 AR and/or MA parameters. ARMA processes
with many parameters are notoriously diﬃcult to estimate and the experience with ARMA
modelling has been that low-order ARMA processes typically have a superior forecasting
performance. I estimated the 16 admissible models by maximum likelihood.13 To pick
between them, I used the Bayesian information criterion (BIC). This criterion picks the
model with the highest likelihood, while imposing a penalty that increases with the number
13
One important concern with estimating ARMA models is that the likelihood functions are often multipeaked or nearly flat for a wide range of parameter values, so numerical procedures can converge on incorrect
estimates. To safeguard against this possibility, I plotted the likelihood functions, examined their gradients
at the proposed optima, and started the numerical maximizations from diﬀerent initial values.

18

of parameters being estimated. One advantage of the BIC is that, as the sample size goes
to infinity, it consistently picks the true underlying model. The BIC picked the ARMA(2,2)
as the best model, followed by the ARMA(1,0) and by the ARMA(0,1).
Table 4 — Estimates of the costs of fluctuations from ARMA models
Panel A: Estimated ARMA (2,2) model
(1 − 0.66L − 0.32L2 )∆ct = (1 + 1.03L + 0.56L2 )ut , σ u = 0.011
r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.31%
($72)
0.47%
($109)
0.94%
($220)

0.94%
($219)
1.43%
($334)
2.93%
($687)

1.60%
($375)
2.47%
($579)
5.33%
($1248)

Panel B: Estimated ARMA (1,0) model
(1 − 0.34L)∆ct = ut , σ u = 0.010
r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.40%
($94)
0.61%
($144)
1.25%
($292)

1.23%
($288)
1.89%
($442)
3.94%
($923)

2.13%
($498)
3.33%
($780)
7.40%
($1734)

Panel C: Estimated ARMA (0,1) model
∆ct = (1 + 0.36L)ut , σ u = 0.011

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.34%
($79)
0.51%
($120)
1.03%
($242)

1.02%
($240)
1.56%
($366)
3.23%
($752)

1.76%
($412)
2.73%
($638)
5.92%
($1388)

Each cell shows the per capita costs of fluctuations as a fraction of consumption
and, in brackets, in 2003 dollars.

Table 4 shows the costs of eliminating fluctuations in consumption for these three statistical models. The first conclusion to take from the table is that the estimates are all
larger than the corresponding estimates in Panel C of table 1. The positive serial correlation in consumption growth implies that shocks propagate by more over time than what
19

the Hall model predicted. A second conclusion is that across the three empirical consumption processes, the estimates of the costs of fluctuations are roughly similar. The results
are robust in the sense that moving between models that fit the data almost equally well
does not drastically aﬀect the estimates. This leads to the third conclusion: the costs of
fluctuations are approximately between 0.5% and 5% of per capita consumption, similar to
the estimates in table 3.
Non-parametric unrestricted estimates
The key empirical inputs into the formula for the costs of fluctuations in (2) are the
forecast error variances of consumption. So far, I have estimated these by fitting parametric
models to the observations of consumption. A natural alternative is to estimate the forecast
error variances directly imposing as little structure as possible on the model of consumption.
Since these variances are conditional on information at time zero, then V ar(ct ) =
V ar(ct − c0 ). It is diﬃcult to estimate these without specifying what the conditioning
information at time 0 is. However, doing so is close to specifying a parametric model for
consumption, precisely what this section is trying to avoid. I overcome this dilemma by
estimating the unconditional variance of the tth diﬀerence in log consumption. The conditional and unconditional variances will be the same in the case of the AR(1); otherwise,
the unconditional variance will be higher. The estimates in this section therefore provide
non-parametric upper bounds on the costs of fluctuations.
Cochrane (1987) showed that the unconditional variance of the tth diﬀerence in consumption equals:

⎛

tσ 2∆c ⎝1 + 2

t−1
X
t−j
j=1

t

⎞

Rj ⎠ .

(20)

Rj is the j th order autocorrelation of the first diﬀerence of consumption; σ 2∆c is its variance.
The quantity in parenthesis is the Bartlett estimator of the spectrum of the first-diﬀerence of
consumption at frequency zero using a lag window of length t. The sample autocorrelations
and the sample variance of the first diﬀerence of consumption provide consistent estimates
of these moments, so it is an easy mater to evaluate this expression.14
One diﬃculty is that it is impossible to compute the variance of the tth diﬀerence in
14
I multiply the expression in parenthesis by n/(n − t + 1) to improve the performance of the estimator
in a small sample (Cochrane, 1987).

20

consumption if t is larger than the sample size. Even if t is smaller than n, as long as
it is close to it, the estimator of Rt will be using only a few observations. I tackle this
problem in the same way that I did earlier when deriving the asymptotic distribution of
the costs of fluctuations. I use an estimator like L̂ in (12), with the only diﬀerence that
the first sum now includes terms only up to a fraction of n. This way, the estimator only
requires computing the variances of consumption diﬀerences up to a fraction of the sample.
As before, this estimator asymptotically converges to the true costs of fluctuations and it
provides a good approximation in a finite sample if consumption is very persistent.
Table 5 — Estimates of costs of fluctuations from variance estimates
Panel A: Estimating correlations of order up to 25% of the sample

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.25%
($59)
0.36%
($85)
0.68%
($160)

0.76%
($179)
1.10%
($257)
2.10%
($492)

1.29%
($303)
1.87%
($440)
3.68%
($863)

Panel B: Estimating correlations of order up to 50% of the sample

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.26%
($61)
0.37%
($86)
0.69%
($161)

0.78%
($183)
1.12%
($262)
2.12%
($496)

1.33%
($311)
1.91%
($447)
3.71%
($871)

Panel C: Estimating correlations of order up to 75% of the sample

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.16%
($37)
0.22%
($52)
0.48%
($112)

0.48%
($113)
0.68%
($159)
1.47%
($346)

0.81%
($189)
1.15%
($271)
2.60%
($610)

Each cell shows the per capita costs of fluctuations as a fraction of consumption
and, in brackets, in 2003 dollars.

Table 5 contains the new estimates of the costs of fluctuations. From panels A to C, I
21

use increasing fractions of the sample, from 25% to 50% to 75%. The costs of fluctuations
from using this approach are typically in between the random walk estimates and the larger
estimates using ARMA models. They are all larger than the Lucas benchmark of 0.05%.

5

Economic models of consumption

The components of the model
One pervasive model of consumption and fluctuations is the neoclassical stochastic
growth model, in which a representative consumer solves:

max E
{Ct }

s.t.:

"∞
X

Kt+1 =

e−ρt

Ã

t=0
A1−α
Ktα
t

Ct1−γ − 1
1−γ

!#

+ (1 − δ)Kt − Ct .

The new notation refers to: At - stochastic productivity, α - the capital share, and δ - the
depreciation rate.15
I set the depreciation rate at 0.05, the value typically chosen in the literature; close
alternatives do not greatly aﬀect the estimates of the costs of fluctuations. Choosing the
process for productivity and the value of the capital share requires more attention though.
These aﬀect a key determinant of the costs of fluctuations: the persistence of consumption.
All else equal, the faster diminishing returns set in, the more transient the eﬀect of shocks
to consumption. With a Cobb-Douglas production function, the capital share determines
the speed of convergence. The assumption in the model of section 2 was that there were
constant returns to savings. Considering the broad investment possibilities available to
society, this might just be the right assumption (Knight, 1944). Constant returns also
imply that shocks have a permanent eﬀect. Thus, there are no consumption dynamics
associated with the transition to a steady state. Some of the endogenous growth literature
claims that this may be an appropriate approximation of reality; for instance, King and
Rebelo (1993) argued that transitional dynamics likely are quantitatively insignificant.
15
Otrok (2001) also uses an estimated business cycle model to investigate the costs of fluctuations. However, his model has many other features (habits, two sectors of production, etc.) and his approach to
calculating the welfare cost of fluctuations is diﬀerent and does not capture the precautionary-investment
eﬀect that I emphasize.

22

Barro and Sala-i-Martin (2003) instead pointed to the evidence of conditional convergence of income levels across countries as supporting transitional dynamics and diminishing
returns to capital accumulation. As they discuss at length, the existing estimates of the
speed of convergence point to a value of the capital share around 0.75. This is consistent
with a broad vision of capital that includes both physical and human capital. If Kt stands
solely for physical capital though, the U.S. data on factor payments suggest instead that the
capital share is about 0.36. Having considered the case α = 1 in section 2, I now examine
these two alternatives.
The second factor driving the persistence of consumption is the process driving productivity shocks. I will model productivity as:
at = µ + τ (1 − φ)t + φat−1 + wt , with wt ∼ N (0, ω 2 ).

(21)

Prescott (1986) discusses how this process provides a good approximation to the observations of the Solow residual. While these observations imply that productivity is highly
persistent, it is diﬃcult to distinguish in the data between a stationary process, with say
φ = 0.9, or a non-stationary process, in which case φ = 1. Moreover, Kydland and Prescott
(1982) found that a real business cycle model performs equally well with either option. I
will consider both cases.
Aside from persistence, the other key determinant of the costs of fluctuations is the
volatility of consumption. In this economic model, consumption volatility is driven by the
parameter ω. It is diﬃcult to pinpoint this value in the data, since the Solow residual is
likely a very noisy measure of productivity. Consistent with this paper’s overall approach,
I calibrate this parameter to match the properties of consumption. Namely, I set ω so that
the model matches either the standard deviation of log consumption (for the stationary
model), or the standard deviation of its first diﬀerence (for the non-stationary model).
Solving for the costs of fluctuations
I solve the four models corresponding to the diﬀerent assumptions on α and φ by loglinearizing around the non-stochastic steady state. Unfortunately, when productivity is nonstationary, I am only able to solve the model when γ = 1. With non-stationary productivity,
the model does not have a steady state. The variables must then be transformed to employ

23

log-linearizations. In the case when γ = 1, Christiano (1988) found such a transformation,
but for γ 6= 1 there is no available transformation.
The value function V (K, a) gives the expected discounted utility of having an amount of
capital K when the current productivity is a. As long as there are shocks to productivity,
output and consumption will fluctuate. The counterfactual scenario in which there are
no fluctuations in income corresponds to a world in which productivity does not vary but
remains constant at E[At ].
While the costs of fluctuations are defined as before, now one must specify at which
(K, a) pair do they apply. The stationary steady state capital stock of the non-stochastic
economy is a natural choice for K. As for a, I will calculate the expected costs of fluctuations
by taking the expected value of V (K, a) over the diﬀerent possible realizations of a.
The appendix shows that if productivity is stationary, then:

ln(1 + λ) =

⎧
⎪
⎨
⎪
⎩

0.5ω 2
1−φ2
0.5ω 2
1−φ2

[1 − (1 − eg−r ) Vaa ] + O(ω 4 ) if γ = 1
¸
∙
,
2V
1
4)
aa
+
O(ω
+ γ−1
ln 1 + 0.5ω
if
γ
=
6
1
2
(1−φ )V

(22)

while if productivity is non-stationary and γ = 1, then:

ln(1 + λ) = 0.5ω 2

∙

¸
¡
¢
1
g−r
−
1
−
e
−
V
)
+ O(ω 4 ).
(V
aa
a
1 − eg−r

(23)

Subscripts denote partial derivatives and all the functions are evaluated at the non-stochastic
steady state; analytical expressions for each term are in the appendix. Given how small the
ω’s typically are, the error in the expressions should be negligible.
Estimates of the costs of fluctuations in the economic model
Table 6 presents the estimated costs of fluctuations. Panel A has the estimates for the
model with quickly diminishing returns to capital (α = 0.36) and stationary productivity
(φ = 0.9). The costs of fluctuations are small, around 0.09% of consumption. While these
are the smallest numbers in the table, they are already twice larger than the Lucas baseline.
In Panel B, productivity is still stationary, but there are only mildly diminishing returns to scale (α = 0.75). Technology shocks now have a more long-lasting impact, and
correspondingly the costs of fluctuations are two to three times larger. According to these
estimates, each person in the United States would be willing to pay between $31 and $55
24

to eliminate fluctuations in consumption.
Table 6 — The costs of fluctuations in the stochastic growth model
Panel A: Stationary productivity and strongly diminishing returns

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.07%
($16)
0.07%
($17)
0.08%
($19)

0.08%
($19)
0.09%
($21)
0.10%
($24)

0.09%
($22)
0,10%
($24)
0.12%
($27)

Panel B: Stationary productivity and mildly diminishing returns

r − g = 0.03
r − g = 0.02
r − g = 0.01

γ=1

γ=3

γ=5

0.17%
($40)
0.18%
($43)
0.21%
($48)

0.15%
($36)
0.18%
($42)
0.23%
($55)

0.13%
($31)
0.16%
($38)
0.23%
($55)

Panel C: Non-stationary productivity

r − g = 0.03
r − g = 0.02
r − g = 0.01

α = 0.36

α = 0.75

0.55%
($129)
0.85%
($199)
1.76%
($412)

0.26%
($60)
0.39%
($92)
0.81%
($190)

Each cell shows the per capita costs of fluctuations as a fraction of consumption
and, in brackets, in 2003 dollars.

Panel C finally turns to the case when productivity is non-stationary (φ = 1). Consumption fluctuations are now much more costly. With quickly diminishing returns to scale,
they cost between 0.6% and 1.8% of per capita consumption; slowly diminishing returns to
scale lower these estimates by half. Increasing the speed of diminishing returns therefore
raises the costs of fluctuations, the opposite of what happened with stationary productivity. The reason is that with non-stationary productivity, consumption is already a random
walk in steady state, so that with mildly diminishing returns to scale, the model predicts
25

that consumption is too persistent. Fitting the unconditional variance of first-diﬀerenced
consumption predicted then requires a lower calibrated value for the volatility of shocks,
which pushes the costs of fluctuations down.
The class of models analyzed in this section is just one among many diﬀerent possibilities.
Aside from generating estimates of the costs of fluctuations that are interesting in their own
right, these models served a dual purpose. First, they showed how to calculate the costs
of fluctuations within economic models that take the precautionary savings and investment
risk eﬀects into account. Second, they showed that the model’s predicted persistence of
consumption is a key determinant of the costs of fluctuations. This opens the door to
estimating the costs of fluctuations in models that have other mechanisms propagating
shocks over time aside from investment, such as for instance nominal rigidities or credit
market frictions.

6

Conclusion

This paper re-examined the estimation of the costs of fluctuations, by focusing on the
properties of aggregate consumption. It showed that the properties of the stochastic process
describing consumption, and especially the persistence of shocks, are a key determinant of
the costs of fluctuations. While the assumptions made by Lucas (1987) are decisively
rejected by the data, this paper has shown that if one knows with certainty that shocks
to consumption are only mildly persistent, the estimated costs of fluctuations are close to
those that Lucas estimated.
The evidence though suggests that consumption fluctuations are more persistent than
this. As persistence increases, the costs of fluctuations rise substantially. For instance, if
consumption is a random walk, as some theories suggest and the data does not reject, the
costs of fluctuations are fifty times larger than what Lucas estimated. The statistical models
that best fit the data and the economic models that account for the eﬀect of fluctuations
on precautionary savings lead to even larger estimates of the costs of fluctuations, typically
two orders of magnitude larger than Lucas’ benchmark.
The conclusion that the costs of fluctuations are large and that they are driven mostly by
persistent shocks was also suggested by Alvarez and Jermann (2004). This paper and theirs
are very diﬀerent however. First, they use asset pricing data to infer the marginal utility of

26

consumption so they implicitly assign a large value for risk aversion, whereas I consider value
for relative risk aversion of at most 5. Second, they estimate the covariance of consumption
with asset prices, whereas I estimate the persistence of consumption. Third, whereas they
tackle the problem of estimating risk premia, I tackle the problem of estimating persistence
when it is large. And fourth and finally, whereas they emphasize the need for a model of
how consumers trade risk, I emphasize the need for a model of consumption dynamics over
time. It is a demonstration of the power of the science of economics that sometimes, even
if only rarely, we can pursue completely diﬀerent measurement strategies and yet obtain
some convergence in estimates and conclusions.
As the introduction discussed, it is unclear whether the fluctuations behind the estimates
in this paper correspond to business cycles. If business cycles are transitory short-lived
deviations of consumption away from a stable trend, as defined by for instance the use of
band-pass filters, this paper suggests that the costs of business cycles are small. However,
there is an alternative view of business cycles that dates back at least to Burns and Mitchell
(1946) and which defines cycles as a set of regularities in the comovement of macroeconomic
series. Campbell and Mankiw (1987) found that output fluctuations in the United States
are actually very long-lived. In turn, Kydland and Prescott (1982) found that a calibrated
real business cycle model driven by non-stationary productivity shocks fits quite closely
the data on U.S. business cycles, and it predicts infinitely-lived consumption fluctuations.
Under this view of business cycles, the welfare costs may be quite large. Whichever view
one takes of business cycles, the calculations in this paper have at least provided the tools
to estimate the costs of business cycles under diﬀerent scenarios.
The bulk of the estimates in this paper suggest that the costs of fluctuations lie in the
range from 0.5% to 5%. These are significant amounts. To put these numbers into perspective, in 2003 the total amount spent by the U.S. federal government in unemployment
and medical insurance was $53 billions, or 0.8% of consumption; the amount spent in consumption by the federal government excluding national defense was $223 billions (3.3%);
the amount spent in health coverage for low-income families through the Medicaid program
was $265 billions (3.9%).16 The estimates in this paper suggest that eliminating fluctuations
in consumption could be as valuable to society as the current protection against unemployment and the current provision of health care to the poor. If the federal government was
16

Source: National Income and Product Accounts, tables 3.9.5 and 3.12.

27

able to devise some policy that eliminated consumption fluctuations, consumers would be
willing to reward it by almost doubling its non-defense budget.
These estimates still do not overturn the main Lucas (1987) point. Raising the economy’s
growth rate by 1% would have a much larger eﬀect on welfare than eliminating fluctuations
likely ever would. This comparison is only fair though insofar as it is as easy to raise a
country’s growth rate as it is to dampen fluctuations. There is little evidence that the
recommendations of economists have had any eﬀect on growth, let alone a substantial one
(Easterly, 2002), but there is some evidence that advances in economic knowledge have
led to policies that have stabilized the economy (Romer and Romer, 2002). A more fair
comparison may be with other policies that seem within the scope of public policy. As
Lucas (2003) discusses, lowering inflation from 10% to zero would imply a gain of 1% of
consumption. Eliminating capital income taxes would raise per capita consumption by 2
to 4%. The numbers in this paper put an upper bound on the benefits of eliminating
fluctuations (short-run or not) that is in this range as well.
If an economist was able to come up with a policy that, when implemented, made a
country grow 1% faster forever, his work would have a more important on society’s welfare
than probably any other economist has ever had. Until this happens though, lowering
inflation, reducing taxes on capital income, and dampening consumption fluctuations, are
aims that are within the grasp of our knowledge. If better stabilization policy can bring
society a gain of $200 billions, this is a large enough impact on well-being to motivate the
work of a modest economist.

28

Appendix
This appendix contains calculations omitted in the main text.
The costs of fluctuations in statistical models
For the case γ = 1, the definition of the costs of fluctuations in (1) and of the counterfactual in statistical models imply that:
−ρ

ln(1 + λ) + (1 − e

)E

"∞
X
t=0

−ρt

e

#

E (ct ) = (1 − e−ρ )

∞
X

e−ρt (E (ct ) + 0.5V ar(ct )) . (A1)

t=0

This result used the log-normality of Ct to evaluate ln(E(Ct )). Rearranging and substituting
ρ for r − g gives the first expression in (2). For γ 6= 1, log-normality of consumption im-

plies that E(Ct1−γ ) = E(Ct )1−γ e0.5γ(γ−1)V ar(ct ) . Similar rearrangements lead to the second
expression in (2).
The costs of fluctuations in the AR(1) statistical models
For a stationary AR(1), V ar(ct ) = σ 2 (1−η 2t )/(1−η2 ) for t ≥ 1. When γ = 1, evaluating
the sum in (2) shows that
ln(1 + λ) =

0.5σ 2
.
er−g − η 2

(A2)

Using the approximations er−g − 1 ∼
= r − g and ln(1 + λ) ∼
= λ gives the result.
For the case when γ 6= 1, approximate
"
#
∞
X
1
2
2t
2
ln (1 − eg−r )
e(g−r)t e0.5γ(γ−1)σ (1−η )/(1−η )
ln(1 + λ) =
γ−1
t=0

(A3)

around σ 2 = 0 using a first-order Taylor expansion. Terms of order σ 4 or higher are tiny in
the data, so this involves little error. This leads immediately to the same expression as in the
log case, but now multiplied by γ: ln(1 + λ) ∼
= 0.5γσ 2 /(er−g − η 2 ). Similar approximations
to before give the final result.
The costs of fluctuations in the benchmark economic model
The Euler equation for the problem in (6)-(7) is:
h
i
−γ
.
Ct−γ = e−ρ Et Rt+1 Ct+1
29

(A4)

Then, guess that consumption is linear in wealth, Ct = πRt Kt , with a coeﬃcient π to be
determined. The budget constraint implies that:
Ct+1
Rt+1 Kt+1
=
= Rt+1 (1 − π).
Ct
Rt Kt

(A5)

Using this result to replace for Ct+1 /Ct in the Euler equation and the fact that Rt+1 is
log-normally distributed, (A5) becomes:
γ ln(1 − π) = (1 − γ)r − ρ + 0.5γ(γ − 1)σ 2 .

(A6)

This expression does not depend on any state variable, which confirms the initial guess.
Combining (A6) with (A5) and using the definition of g gives the result in (8).
The costs of fluctuations for γ 6= 1 solve the equation:
1−γ

(1 + λ)

g−r 1−γ

(1−e

)

∞
X

2
2
e[−ρ+(1−γ)(g−0.5γσ )]t = (1−eg−r+0.5(1−γ)σ )1−γ

t=0

∞
X

2
e[−ρ+(1−γ)(g+0.5(1−γ)σ )]t .

t=0

(A7)

Use the definition of g in (8) to replace for ρ and obtain:
(1 + λ)1−γ (1 − eg−r )1−γ

∞
X
t=0

2

e(g−r)t = (1 − eg−r+0.5(1−γ)σ )1−γ

∞
X

2
e[g−r+0.5(1−γ)σ )]t . (A8)

t=0

Evaluating the sums and taking logs shows that:
γ
ln
ln(1 + λ) =
γ−1

Ã

er−g − e−0.5(γ−1)σ
er−g − 1

2

!

.

(A9)

The case when γ = 1 follows along the same steps.
The costs of fluctuations in the Epstein-Zin-Weil model
It is easy so show (e.g., see Weil, 1990) that optimal consumption is in (8) but now with:
θg = r − ρ + 0.5(θ − 1)γσ 2 .

(A10)

The expected discounted utility from setting optimal consumption equals:
(1−γ)/(1−θ)

(1 − eg−r )−θ(1−γ)/(1−θ)
(R0 K0 )1−γ (1 − e−ρ )
1
−
.
(1 − e−ρ ) (1 − γ)
(1 − e−ρ ) (1 − γ)
30

(A11)

With the preferences in (9), without fluctuations, discounted utility equals
(1−γ)/(1−θ)

(1 − e−ρ )

(R0 K0 )1−γ (1 − eg−r−(θ−1)0.5γσ
(1 − e−ρ ) (1 − γ)

2 /θ

)−θ(1−γ)/(1−θ)

−

1
(1 − e−ρ ) (1 − γ)

.

(A12)

Given the definition of the costs of fluctuations, (1 + λ)1−γ equals the ratio of the first
terms in (A12) and (A11). After cancelling some terms and taking logs, this equals:
θ
ln
ln(1 + λ) =
θ−1

Ã

er−g − e−0.5(θ−1)γσ
er−g − 1

2 /θ

!

.

(A13)

Finally, note that a linear approximation of the right-hand side of (A13) in σ 2 around zero
is equal to a linear approximation of the right-hand side of (A9).
Asymptotic distributions for the extended auto-regressive model
The first extension is to include the γ 6= 1 cases. The simplest way to do this is to
approximate the definition of the costs of fluctuations in (2) around the point σ 2 = 0. This
shows that up to terms that are O(σ 4 ) the costs of fluctuations with γ 6= 1 just equal γ
times the costs for the log utility case. In the data, the estimates of σ are typically tiny so
the σ 4 terms being ignored are quantitatively insignificant.
The second extension is to the Dickey-Fuller regression. One change is that now =
P
1 + (c/n)(1 − kj=1 ψ j ). Another change is that the distribution of is aﬀected by the
presence of the constant and the trend. Stock (1991) showed that:
⎛

n(ˆ − 1) ⇒ ⎝1 −
where J τ (s) = J(s) −

k
X
j=1

R1
0

⎞"
µZ
⎠
ψj

0

1

¶−1 µZ
τ
2
J (s) ds

0

(2 − 6r)J(r)dr − s

R1
0

1

#
¶
J τ (s)dW (s) + c ,

(A15)

(12r − 6)J(r)dr. The distribution of the

estimate of the costs of fluctuations is otherwise similar to before.
The costs of fluctuations in the stochastic growth model with stationary productivity
The value function is defined as:
#
( "∞
)
X
−ρt
(1−α)at α
V (K, a) = max E
e u(Ct ) s.t. Kt+1 = e
Kt + (1 − δ)Kt − Ct
{Ct }

t=0

31

(A16)

Define z ≡ (µ − φτ )/(1 − φ) and transform the variables using the relation (ãt , c̃t , k̃t ) =
(at − z − τ t, ct − z − τ t, kt − z − τ t). Note that ãt = φãt−1 + wt . The problem then becomes
#
( "∞
)
X
(1−α)ãt α
−ρt
z+τ t
τ
e u(C̃t e
) s.t. e K̃t+1 = et
V (K, a) = max E
K̃t + (1 − δ)K̃t − C̃t
t=0

(A17)
o
i
n hP
(1−α)ãt α
∞
−[ρ−(1−γ)τ ]t ũ(C̃ ) s.t. eτ K̃
e
=
e
+
(1
−
δ)
K̃
−
C̃
Let v(K̃, ã) = max E
K̃
t
t+1
t
t .
t
t
t=0

The new utility function, ũ(.), is a simple monotonic transformation of the utility function
such that ũ(Ct ) = {ct if γ = 1, or Ct1−γ /(1 − γ) if γ 6= 1}; it serves only the purpose of
avoiding carrying one irrelevant additive term throughout. It then follows that
⎧
³
⎨ v(K̃, ã) + 1−ρ z +
1−e
V (K, a) =
⎩ ez(1−γ) v(K̃, ã) −

τ

eρ −1

´

1
(1−γ)(1−e−ρ )

if γ = 1

(A18)

if γ 6= 1.

In the counterfactual case where productivity equals A∗t = E[At ] = exp(z + τ t +
0.5V ar(a)), consider instead the transformation (ã∗t , c̃∗t , k̃t∗ ) = (a∗t − z − τ t − 0.5V ar(a),
c∗t − z − τ t − 0.5V ar(a), kt∗ − z − τ t − 0.5V ar(a)). By taking the exact same steps as in
the previous paragraph, you can see that the transformed value function is the same v(.)
as in the original problem, for the case where ã = 0 and w0 = 0. The value of being in an
economy without fluctuations then is:
⎧
³
´
⎨ v ∗ (K̃, 0) + 1−ρ z + ρτ
e −1 +
1−e
V ∗ (K, a∗ ) =
⎩ e0.5V ar(a) ez(1−γ) v ∗ (K̃, 0) −

0.5V ar(a)
1−e−ρ

1
(1−γ)(1−e−ρ )

if γ = 1

(A19)

if γ 6= 1.

I compute the costs of fluctuations at the steady state capital stock K ss and integrating
over the possible values of a. The definition of the costs of fluctuations in (1) implies:
ln(1 + λ)/(1 − e−ρ ) + Ea [V (K ss , a)] = V ∗ (K ss , a∗ )
(1 + λ)1−γ Ea [V (K ss , a)] +

(1+λ)1−γ −1

(1−γ)(1−e−ρ )

= V ∗ (K ss , a∗ )

if γ = 1

(A20)

if γ 6= 1,

where Ea [.] is the expectations operator over the random variable a. Using the expressions
for the value functions in (A18) and (A19), this becomes:
³ h
i
´
if γ = 1
ln(1 + λ) = 0.5V ar(a) − (1 − e−ρ ) Ea v(K̃ ss , ã) − v ∗ (K̃ ss , 0)
h
h
i
i
1
ln(1 + λ) = 0.5V ar(a) −
ln Ea v(K̃ ss , ã) /v ∗ (K̃ ss , 0)
if γ 6= 1 (A21)
γ−1
32

Finally, a Taylor approximation of v(K̃ ss , ã) around the non-stochastic steady state is:
v(K̃ ss , ã) = v ∗ + va ã +

vaa ã2 vaa ã3
+
+ O(ã4 ),
2
6

(A22)

where va(n) = ∂ (n) v(.)/∂ã(n) and all the functions are evaluated at the non-stochastic steady
state. Integrating over ã and using the fact that it is mean-zero normally distributed:
h
i
Ea v(K̃ ss , ã) = v∗ + 0.5vaa V ar(ã) + O(ω 4 )

(A23)

Replacing this result into the expressions in (A21), using the fact that V ar(ã) = ω 2 /(1 −

φ2 ), and noting that Va = va from (A18), gives the resulting expression for the costs of
fluctuations in (22).
The costs of fluctuations in the stochastic growth model with non-stationary productivity
One appropriate transformation now is (c̃t , k̃t ) = (ct − at , kt − at−1 ) so that:

#
( "∞
)
X
−ρt
α −α(µ+wt )
−(µ+wt )
e u(C̃t At ) s.t. K̃t+1 = K̃t e
+ (1 − δ)K̃t e
− C̃t
V (K, a) = max E
t=0

(A24)

Define v(K̃, w) as in the stationary case, and obtain:

V (K, a) = v(K̃, w) +

∞
X

e−ρt E0 [at ].

(A25)

t=0

The stable economy is the one in which A∗t = E0 [At ] = exp(E0 (at ) + 0.5V ar0 (at )). The
corresponding transformation is (c̃∗t , k̃t∗ ) = (c∗t − a∗t , kt∗ − a∗t−1 ). This now leads to
(

V ∗ (K, a∗ ) = max E0

"∞
X
t=0

#

e−ρt u(C̃t A∗t )

−α(µ+0.5ω2 )

s.t. K̃t+1 = K̃tα e

−(µ+0.5ω 2 )

+ (1 − δ)K̃t e

(A26)

The problem of the consumer in the stable economy then equals the problem of the consumer
in the fluctuating economy when w = 0.5ω 2 , so
V ∗ (K, a∗ ) = v ∗ (K̃, 0.5ω2 ) +

∞
X

e−ρt E[a∗t ].

(A27)

t=0

The costs of fluctuations are still given by the top expression in (A20), but the new
33

− C̃t

)

expressions for the value functions with and without fluctuations now lead to:
ln(1 + λ) = 0.5ω2 (1 − e−ρ )

X

h
³
i
´
e−ρt t − (1 − e−ρ ) Ew v(K̃ ss , w) − v(K̃ ss , 0.5ω 2 ) (A28)

The approximation of v(K̃ ss , w) is now around the point w = 0.5ω 2 . Integrating over w
leads to
ln(1 + λ) =

0.5ω 2
+ 0.5ω 2 (1 − e−ρ ) (vw − vww ) + O(ω 4 )
eρ − 1

(A29)

Finally, the relation linking V (.) and v(.) shows that vw = Va − 1/(1 − e−ρ ), and that
vww = Vaa . Rearranging (A29) gives the expression in (23).
Calculating the derivatives of the value function in the stationary productivity case
Bellman’s principle of optimality implies that the problem defined in v(k̃, ã) has the
following dynamic programming formulation:
n ³
´
h
io
v(K̃, ã) = max ũ e(1−α)ã K̃ α + (1 − δ)K̃ − eτ K̃ 0 + e−ρ+(1−γ)µ E v(K̃ 0 , φã + w0 ) .
k̃0

(A30)

The optimality conditions are:
vk (K̃, ã) = e−ρ−γτ R(K̃, ã)Et [vk (g(K̃, ã), φã + w0 )]

(A31)

vk (K̃, ã) = R(K̃, ã)u0 (c̃(K̃, ã))

(A32)

va (K̃, ã) = (1 − α)e(1−α)ã K̃ α u0 (c(K̃, ã)) + eτ −r φEt [va (g(K̃, ã), φã + w0 )]. (A33)
R(K̃, ã) ≡ αe(1−α)a K̃ α−1 + 1 − δ

(A34)

The first equation is the Euler equation, the second is the envelope theorem condition with
respect to K̃, and the third is the envelope theorem condition with respect to ã. The fourth
equation defines an auxiliary function (that corresponds to the return on capital), which
is useful to reduce the length of the expressions. The optimal choice of K̃ 0 is given by
a function g(K̃, ã). Using the resource constraint, the optimal choice of consumption is
c̃(K̃, ã) = e(1−α)ã K̃ α + (1 − δ) K̃ − g(K̃, ã)eτ .
In the non-stochastic steady state, g(K̃ ss , 0) = K̃ ss , ã = 0 and w0 = 0. The set of
equations above then returns the steady state values of R, vk , va , and K̃ ss . (When a
function is written without its argument, it is being evaluated at the non-stochastic steady
34

state.) Note that r ≡ ln(R) = ρ + γτ . The Bellman equation and the resource constraint
in turn give the solutions for v and C̃ ss . Finally, it is trivial to use the equation defining
R(K̃, ã) to obtain Rk and Ra .
To construct the Taylor approximation, I perturb the system with respect to (k̃, ã)
around the point (k̃ss , 0). Perturbing the Euler equation with respect to k̃ and evaluating
the functions at (k̃ss , 0) gives:
vkk = R−1 Rk vk + vkk gk

(A35)

Rearranging, this gives an expression for gk in terms of only one unknown vkk . Likewise
perturbing the envelope theorem condition with respect to capital gives another equation
for gk and vkk . Using the expression from the perturbed Euler equation to replace for gk in
the perturbed envelope theorem equation and rearranging gives a quadratic in vkk :
£
¤
2
vkk
− R(R − eτ )u00 (css ) + Rk u0 (css ) vkk − Rk u00 (css )vk eη = 0

(A36)

Aside from vkk , all the other elements in this equation are known. It is therefore trivial to
solve this equation for vkk , picking the negative solution, since the value function is concave.
Next perturb (A31) and (A32) with respect to ã. This leads to the system:
vka (1 − φ) = R−1 Ra vk + vkk ga
vka

i
h
³ ´α
= Ra u0 (css ) + Ru00 (css ) (1 − α) k̃ss − ga eτ

(A37)
(A38)

These are two linear equations in two unknowns: vka and ga . It is easy to solve the system
to obtain these two values. Finally, perturbing (A33) with respect to ã and rearranging
gives a simple expression for vaa :

vaa =

³ ´α
i
³ ´α
h
³ ´α
ga eτ −r φvka + (1 − α)2 k̃ ss u0 (css ) + (1 − α) k̃ss u00 (css ) (1 − α) k̃ss − ga eτ
1 − eτ −r φ2

(A39)

All of the terms in the right hand side of this expression are known, so this gives vaa .
Calculating the derivatives of the value function in the non-stationary productivity case

35

.

Bellman’s principle of optimality now implies:
n h
i
h
io
v(K̃, w) = max ln K̃ α e−α(µ+wt ) + (1 − δ)K̃e−(µ+wt ) − K̃ 0 + e−ρt E v(K̃ 0 , w0 ) .
k̃0

(A40)

The set of optimality conditions, in the same order as before is:
vk (K̃, w) = e−ρ R(K̃, w)Et [vk (K̃ 0 , w0 )]

(A41)

vk (K̃, w) = R(K̃, w)u0 (c̃(K̃, ã))

(A42)

vw (K̃, w) = −vk (K̃, w)

(A43)

R(K̃, w) ≡ αe−α(µ+w) K̃ α−1 + (1 − δ) e−(µ+w)

(A44)

The optimal choice of K̃ 0 is still denoted by g(K̃, w), and the optimal consumption amount
now equals c̃(K̃, w) = e−α(µ+w) K̃ α + (1 − δ) K̃e−(µ+w) − g(K̃, w).
Evaluating this set of equations at the non-stochastic steady state, K̃ = K̃ 0 = K̃ ss and
w = ω2 /2, gives the steady state values R, vk , va , k̃ss , and straightforward manipulations
give v, c̃ss , Rk and Ra .
Perturbing (A41) and (A42) with respect to k̃ gives the same expressions as in the
stationary case (though the expressions for R and c̃ss are of course diﬀerent). Again, these
two equations give the solutions for vkk and gk . Perturbing (A43) with respect to k̃ and with
respect to w gives the system of two equations: vwk = −vk − k̃ss vkk and vww = −K̃ ss vkw .
³
´
Solving for vww then gives the solution: vww = K̃ ss vk + K̃ ss vkk .

References
[1] Alvarez, Fernando and Urban J. Jermann (2004) “Using Asset Prices to Measure the
Cost of Business Cycles,” Journal of Political Economy, vol. 112, pp. 1223-1256.
[2] Arrow, Kenneth J. (1971) Essays in the Theory of Risk-Bearing, Amsterdam, North
Holland.
[3] Atkeson, Andrew and Christopher Phelan (1994) “Reconsidering the Costs of Business
Cycles with Incomplete Markets,” NBER Macroeconomics Annual 1994, Cambridge,
MA, MIT Press, pp. 187-207.

36

[4] Barlevy, Gadi (2004) “The Cost of Business Cycles under Endogenous Growth,” American Economic Review, vol. 94 (4), pp. 964-990.
[5] Barro, Robert J. and Xavier Sala-i-Martin (2003) Economic Growth, 2nd edition, Cambridge, MIT Press.
[6] Beaudry, Paul and Carmen Pages (2001) “The Cost of Business Cycles and the Stabilization Value of Unemployment Insurance,” European Economic Review, vol. 45, pp.
1545-1572.
[7] Burns, Arthur F. and Wesley C. Mitchell (1946) Measuring Business Cycles, New York,
National Bureau of Economic Research.
[8] Campbell, John and N. Gregory Mankiw (1987) “Are Output Fluctuations Transitory?” Quarterly Journal of Economics, vol. 102, pp. 857-880.
[9] Chetty, Raj (2005) “Labor Supply and Risk Aversion: A Calibration Theorem,” UC
Berkeley unpublished.
[10] Chetty, Raj and Adam Szeidl (2004) “Consumption Commitments and Asset Prices,”
Harvard University unpublished.
[11] Christiano, Lawrence J. (1988) “Why Does Inventory Investment Fluctuate so Much?”
Journal of Monetary Economics, vol. 21, pp. 247-280.
[12] Cocco, João (2003) “Portfolio Choice in the Presence of Housing,” London Business
School, unpublished.
[13] Cochrane, John (1987) “How Big is the Random Walk in GNP?” Journal of Political
Economy, vol. 96, pp. 893-920.
[14] Dickey, David A. and Wayne A. Fuller (1979) “Distribution of the Estimators for
Autoregressive Time Series with a Unit Root,” Journal of the American Statistical
Association, vol. 74 (1), pp. 427—31.
[15] Dolmas, James (1998) “Risk Preferences and the Welfare Cost of Business Cycles,”
Review of Economic Dynamics, vol. 1 (3), pp. 646-676.
[16] Easterly, William (2002) The Elusive Quest for Growth, Cambridge, MIT Press.
37

[17] Elliott, Graham, Thomas J. Rothenberg, and James H. Stock (1996) “Eﬃcient Tests
for an Autoregressive Unit Root,” Econometrica, vol. 64 (4), pp. 813-836.
[18] Epaulard, Anne and Aude Pommeret (2003) “Recursive Utility, Endogenous Growth,
and the Welfare Cost of Volatility,” Review of Economic Dynamics, vol. 6 (3), pp.
672-684.
[19] Epstein, Larry G. and Stanley E. Zin (1989) “Substitution, Risk Aversion, and the
Temporal Behavior of Consumption and Asset Returns: A Theoretical Framework,”
Econometrica, vol. 57 (4), pp. 937-969.
[20] Friend, Irwin and Marshall E. Blume (1975) “The Demand for Risky Assets,” American
Economic Review, vol. 65 (5), pp. 900-922.
[21] Fuhrer, Jeﬀrey C. (2000) “Habit Formation in Consumption and its Implications for
Monetary Policy,” American Economic Review, vol. 90 (3), pp. 367-390.
[22] Gabaix, Xavier and David Laibson (2003) “The 6D Bias and the Equity Premium
Puzzle,” NBER Macroeconomics Annual 2002, Cambridge, MIT Press, pp. 257-312.
[23] Hall, Robert E. (1978) “Stochastic Implications of the Life-Cycle Permanent Income
Hypothesis: Theory and Evidence,” Journal of Political Economy, vol. 86 (6), pp.
971-987.
[24] Imrohoroğlu, Ayse (1989) “The Cost of Business Cycles with Indivisibilities and Liquidity Constraints,” Journal of Political Economy, vol. 97 (6), pp. 1364-1383.
[25] Kimball, Miles S. (1990) “Precautionary Saving in the Small and in the Large,” Econometrica, vol. 58 (1), pp. 53-73.
[26] King, Robert G. and Sergio T. Rebelo (1993) “Transitional Dynamics and Economic
Growth in the Neoclassical Growth Model,” American Economic Review, vol. 83 (4),
pp. 908-931.
[27] Knight, Frank H. (1944) “Diminishing Returns from Investment,” Journal of Political
Economy, vol. 52, pp. 26-47.
[28] Krebs, Tom (2003) “Growth and Welfare Eﬀects of Business Cycles in Economies with
Idiosyncratic Human Capital Risk,” Review of Economic Dynamics, vol. 6, pp. 846-868.
38

[29] Krebs, Tom (2004) “Job Displacement Risk and the Costs of Business Cycles,” Brown
University working paper.
[30] Krusell, Per and Anthony A. Smith, Jr. (1999) “On the Welfare Eﬀects of Eliminating
Business Cycles,” Review of Economic Dynamics, vol. 2 (2), pp. 245-272.
[31] Kwiatkowski, Denis, Peter C.B. Phillips, Peter Schmidt, and Yongcheol Shin (1992)
“Testing the Null Hypothesis of Stationarity Against the Alternative of a Unit Root:
How Sure Are We that Economic Time Series Have a Unit Root?” Journal of Econometrics, vol. 54, pp. 159-178.
[32] Kydland, Finn E. and Edward C. Prescott (1982) “Time to Build and Aggregate Fluctuations,” Econometrica, vol. 50 (6), pp. 1345-1370.
[33] Lucas, Robert E., Jr. (1987) Models of Business Cycles, New York, Basil Blackwell.
[34] Lucas, Robert E., Jr. (2003) “Macroeconomic Priorities,” American Economic Review,
vol. 93 (1), pp. 1-14.
[35] McGrattan, Ellen R. and Edward C. Prescott (2003) “Average Debt and Equity Returns: Puzzling?” American Economic Review Papers and Proceedings, vol. 93 (2), pp.
292-297.
[36] Mehra, Rajnish and Edward C. Prescott (1985) “The Equity Premium: A Puzzle,”
Journal of Monetary Economics, vol. 15, pp. 145-161.
[37] Ng, Serena and Pierre Perron (2001) “Lag Length Selection and the Construction of
Unit Root Tests with Good Size and Power,” Econometrica, vol. 69 (6), pp. 1519-1554.
[38] Obstfeld, Maurice (1994) “Evaluating Risky Consumption Paths: The Role of Intertemporal Substitutability,” European Economic Review, vol. 38, pp. 1471-1486.
[39] Otrok, Christopher (2001) “On Measuring the Welfare Cost of Business Cycles,” Journal of Monetary Economics, vol. 47, pp. 61-92.
[40] Parker, Jonathan A. and Bruce Preston (2004) “Precuationary Saving and Consumption Fluctuations,” American Economic Review, forthcoming.

39

[41] Phillips, Peter C. B. and Pierre Perron (1988) “Testing for a unit root in time series
regression,” Biometrika, vol. 75 (2), pp. 335-346.
[42] Phillips, Peter C. B. (1998) “Impulse Response and Forecast Error Variance Asymptotics in Nonstationary VARs,” Journal of Econometrics, vol. 83, pp. 21-56.
[43] Poterba, James M. (1998) “The Rate of Return to Corporate Capital and Factor Shares:
New Estimates Using Revised National Income Accounts and Capital Stock Data,”
Carnegie-Rochester Conference Series on Public Policy, vol. 48, pp. 211-246.
[44] Prescott, Edward C. (1986) “Theory Ahead of Business Cycle Measurement,” FRB
Minneapolis Quarterly Review, vol. 10 (4).
[45] Reis, Ricardo (2004) “Inattentive Consumers,” NBER working paper 10883.
[46] Romer, Christina and David Romer (2002) “The Evolution of Economic Understanding
and Postwar Stabilization Policy,” in Rethinking Stabilization Policy, Federal Reserve
Bank of Kansas City, pp. 11-78.
[47] Saks, Raven and Stephen Shore (2004) “Risk and Career Choices,” Harvard University,
unpublished.
[48] Stock, James H. (1991) “Confidence Intervals for the Largest Autoregressive Root in
U.S. Macroeconomic Time Series,” Journal of Monetary Economics, vol. 28, pp. 435459.
[49] Stock, James H. (1994) “Unit Roots, Structural Breaks and Trends,” chapter 46 in
Handbook of Econometrics, edited by R. Engle and D. McFadden, Amsterdam, Elsevier,
pp. 2739-2841.
[50] Storesletten Kjetil, Chris I. Telmer, and Amir Yaron (2001) “The Welfare Costs of
Business Cycles Revisited: Finite Lives and Cyclical Variation in Idiosyncratic Risk,”
European Economic Review, vol. 45 (7), pp. 1311-1339.
[51] Tallarini, Thomas D., Jr. (2000) “Risk-Sensitive Real Business Cycles,” Journal of
Monetary Economics, vol. 45 (3), pp. 507-532.
[52] Weil, Philippe (1990) “Nonexpected Utility in Macroeconomics,” Quarterly Journal of
Economics, vol. 105 (1), pp. 29-42.

40

