{
    "id": 18373,
    "citation_title": "Site Selection Bias in Program Evaluation",
    "citation_author": [
        "Hunt Allcott"
    ],
    "citation_publication_date": "2012-09-13",
    "issue_date": "2012-09-13",
    "revision_date": "2014-09-15",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Experimental Design",
        "\n",
        "Microeconomics",
        "\n",
        "Households and Firms",
        "\n",
        "Industrial Organization",
        "\n",
        "Industry Studies",
        "\n",
        "Development and Growth",
        "\n",
        "Development",
        "\n",
        "Environmental and Resource Economics",
        "\n",
        "Energy",
        "\n"
    ],
    "program": [
        "\n",
        "Environment and Energy Economics",
        "\n",
        "Labor Studies",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\n\"Site selection bias\" can occur when the probability that a program is adopted or evaluated is correlated with its impacts. I test for site selection bias in the context of the Opower energy conservation programs, using 111 randomized control trials involving 8.6 million households across the U.S. Predictions based on rich microdata from the first ten replications substantially overstate efficacy in the next 101 sites. Several mechanisms caused this positive selection. For example, utilities in more environmentalist areas are more likely to adopt the program, and their customers are more responsive to the treatment. Also, because utilities initially target treatment at higher-usage consumer subpopulations, efficacy drops as the program is later expanded. The results illustrate how program evaluations can still give systematically biased out-of-sample predictions, even after many replications.\n\n",
    "acknowledgement": "\nThis paper replaces an earlier version which was titled \"External Validity and Partner Selection Bias.\" The earlier draft was jointly authored with Sendhil Mullainathan, and the project benefited substantially from his insight and collaboration. I thank Josh Angrist, Amitabh Chandra, Lucas Davis, Kyle Dropp, Meredith Fowlie, Xavier Gine, Chuck Goldman, Matt Harding, Joe Hotz, Guido Imbens, Larry Katz, Chris Knittel, Dan Levy, Jens Ludwig, Konrad Menzel, Emily Oster, Rohini Pande, Todd Rogers, Piyush Tantia, Ed Vytlacil, Heidi Williams, five anonymous referees, and seminar participants at the ASSA meetings, Berkeley, Columbia, Harvard, MIT, NBER Labor Studies, NBER Energy and Environmental Economics, NEUDC, the UCSB/UCLA Conference on Field Experiments, and the World Bank for insights and helpful advice. Thanks also to Tyler Curtis, Marc Laitin, Alex Laskey, Alessandro Orfei, Nate Srinivas, Dan Yates, and others at Opower for fruitful discussions. Christina Larkin provided timely research assistance. I am grateful to the Sloan Foundation for financial support of this paper and related research on the economics of energy efficiency. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}