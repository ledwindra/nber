NBER WORKING PAPER SERIES

WHY IS MATH CHEAPER THAN ENGLISH? UNDERSTANDING COST DIFFERENCES
IN HIGHER EDUCATION
Steven W. Hemelt
Kevin M. Stange
Fernando Furquim
Andrew Simon
John E. Sawyer
Working Paper 25314
http://www.nber.org/papers/w25314

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2018

We thank Tom Eleuterio, Xiaohang Zhao, and Ti Yan at the University of Delaware for their
exceptional partnership and willingness to share generously of their deep knowledge of the
Delaware Cost Study. Cassandra Baxter provided invaluable research assistance. The Smith
Richardson Foundation provided critical financial support. This research was also supported in
part by grant R305B150012 from the Institute of Education Sciences to the University of
Michigan. Helpful comments were shared by numerous seminar participants. All errors and any
opinions are our own. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
Â© 2018 by Steven W. Hemelt, Kevin M. Stange, Fernando Furquim, Andrew Simon, and John E.
Sawyer. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted
without explicit permission provided that full credit, including Â© notice, is given to the source.

Why is Math Cheaper than English? Understanding Cost Differences in Higher Education
Steven W. Hemelt, Kevin M. Stange, Fernando Furquim, Andrew Simon, and John E. Sawyer
NBER Working Paper No. 25314
November 2018
JEL No. I21,I22,I23
ABSTRACT
The private return to postsecondary investment varies widely by field, but the resources required
by different fields are not well known. This paper establishes five new facts about college costs
using novel department-level data. First, costs vary widely across field, ranging from electrical
engineering (109 percent higher costs than English) to math (22 percent lower). Costs are
generally higher in fields where graduates earn more and in pre-professional programs. Second,
this pattern is explained statistically by differences in class size and faculty pay, though
differences in production technology enable some fields to offset higher salaries with larger
classes. Third, some STEM fields experienced steep declines in expenditures over the past fifteen
years while others saw increases. Fourth, increases in class size and teaching loads alongside a
shift in faculty composition toward contingent faculty explain these trends. Finally, online
instruction is associated with a modest reduction in cost per student, but only for undergraduate
instruction. Recent policy efforts to promote enrollment in high-earning fields will thus have
important implications for postsecondary costs and the social return on investment in higher
education.
Steven W. Hemelt
Department of Public Policy
University of North Carolina at Chapel Hill
Abernethy Hall, Campus Box 3435
Chapel Hill, NC 27599
hemelt@email.unc.edu
Kevin M. Stange
Gerald R. Ford School of Public Policy
University of Michigan
5236 Weill Hall
735 South State Street
Ann Arbor, MI 48109
and NBER
kstange@umich.edu
Fernando Furquim
University of Michigan
ffurquim@umich.edu

Andrew Simon
University of Michigan
735 S. State Street
Ann Arbor, MI 48109
arsimon@umich.edu
John E. Sawyer
327 Hullihen Hall
University of Delaware
Newark, DE 19716
sawyerj@udel.edu

I.

Introduction
Investment in education fosters human capital development, shapes long-term economic

growth, and influences socioeconomic mobility (Goldin & Katz, 2008; Autor, 2014). At the
postsecondary level, the private return to this investment varies widely by field of study, with
science and engineering fields generally having a higher labor market payoff than the humanities
and social sciences (e.g., Altonji, Arcidiacono, & Maurel, 2016; Kirkeboen, Leuven, & Mogstad,
2016). These outcome differences have prompted policymakers to promote enrollment in highearning fields through various direct and indirect incentives to institutions and students, such as
targeted scholarships and performance-based funding. However, we know very little about the
economic cost of this investment or the resource consequences of steering more students into
these fields.
In this paper we use novel, department-level data on costs (expenditures), outputs, and
factors of production for a large and diverse sample of four-year institutions from 2000 to 2015
to provide a comprehensive descriptive analysis of instructional costs within institutions. We
estimate differences in instructional costs by field, characterize associations between production
factors such as class size and faculty workload and these cost differences, and document trends
over time in field-specific costs. Prior work on college costs largely consists of institution-level
analyses and case studies of elite private institutions, and thus cannot illuminate differences
across fields for the institutions attended by most students.
We establish five new facts about college costs. First, there are substantial cost
differences across fields of study. Using English as a benchmark, instructional costs per student
credit hour (SCH) range from 109percent higher for electrical engineering to 22percent lower for
math. The average English course with 20 students incurs approximately $12,500 in instructional

1

expenses, so these percentage differences reflect substantial levels of resources. Costs are
generally higher in fields where graduates earn more and in pre-professional programs. These
patterns of average cost differences also generally map to marginal cost differences. Second,
most of the cross-discipline patterns can be explained statistically by large differences in class
size and, to a lesser extent, differences in average faculty pay (itself a function of salaries and
mix of faculty type/rank). Teaching loads and other (non-personnel) expenditures explain little of
the instructional cost differences across fields. Further, some fields with highly paid faculty (like
economics) offset high wages with large classes, resulting in costs that are comparable to English
despite higher faculty pay. Differences in production technology that enable some departments to
offset higher salaries with larger classes are thus a key determinant of cost differences in
postsecondary education. Third, cost differences have evolved over time. Some STEM fields â€“
mechanical engineering, chemistry, physics, biology, and nursing â€“ experienced steep declines in
spending over the past fifteen years while others saw increases. Fourth, these trends are
explained by large increases in class size (mechanical engineering, nursing) and increases in
faculty teaching loads (chemistry, biology) alongside a shift in faculty composition toward
contingent faculty. Finally, the extent of online instruction is associated with a modest reduction
in cost per student in undergraduate, but not graduate, education.
A better understanding of cost differences across fields informs several policy domains.
First, institutions and states could explicitly take the large cost differences across fields into
account when setting prices and allocating resources. Many public institutions charge students
differentially by college or field (Stange, 2015), and some states recognize cost differences in
their appropriations formulas, but these cost differences are present even for states and
institutions that do not use such practices. Second, the social return to investment in high-earning

2

fields may be lower than wage premiums suggest because high-return fields also tend to be more
costly to teach. This point was made in earlier work by Altonji and Zimmerman (2016), but we
broaden the scope of institutions for which we now have evidence of this fact. This underscores
the need for policymakers to consider the cost implications of changes in the mix of fields
students study.
Finally, our analysis of cost drivers begins to inform how postsecondary institutions
could temper cost escalation. College prices have grown by 40 percent between 2005 and 2015
(College Board, 2015), increasing the share of postsecondary costs shouldered by students and
their families to nearly half (Desrochers & Hurlburt, 2016) and shifting postsecondary
enrollment away from four-year public universities and toward two-year colleges and less
selective institutions (Hemelt & Marcotte, 2016). Given these trends, a number of initiatives aim
to â€œstretch the higher education dollarâ€ (Kelly & Carey, 2013). In Texas, some colleges
answered Governor Rick Perryâ€™s challenge to offer a $10,000 college degree by creating
programs that combine high school, community college, and four-year college instruction
(Seligman, 2012). The expansion of online learning technology may also lower costs, at least
among the least selective colleges (Deming, Goldin, Katz, & Yuchtman, 2015; Bowen, 2012). In
Wisconsin, Governor Scott Walker proposed increased faculty teaching loads as a way to control
costs (DeFour, 2015). Our work suggests that differences in production technology enable some
departments to take different approaches to cost management, from changing the mix of faculty
ranks to increasing class sizes. This implies that a one-discipline-fits-all approach to addressing
cost escalation is likely misguided and ineffective. An important caveat is that we focus on direct
instructional expenditures and therefore abstract from other forms of expenditures by institutions
that are shared across departments, such as student services or administration.

3

The paper unfolds as follows. The next section situates our study within prior theoretical
and empirical research on postsecondary costs, with a focus on work that goes below the
institution-level. Section III describes our data and samples. Section IV presents cross-sectional
cost differences by field of study, and Section V documents how these differences have evolved
over time. In Sections VI and VII we dig more deeply into these patterns by exploring marginal
cost and the role of instructor type and class size more specifically. Online instruction has been
touted as one way that institutions can bend the cost curve. In Section VIII we describe the
adoption of online instruction and its association with costs for a much larger and diverse sample
than has been examined in prior work. We conclude with a discussion of the implications of our
work in Section IX.
II.

Background
A. Theories of Costs and Implications for Cross-Field Differences
Scholars have long noted the tendency for postsecondary costs to rise faster than

economy-wide costs over the long term (Bowen, 2012). A range of explanations has been posited
for this phenomenon, including the curse of â€œlabor-intensiveâ€ industries in which the relative
capacity to substitute capital for labor is low (Baumol & Bowen, 1966) 1, the proclivity of
colleges to act like â€œrevenue-maximizersâ€ in effort to compete in the murkily defined race of
prestige (Bowen, 1980), the temptation to spend on student amenities (Rubin, 2014; Jacob,
McCall, & Stange, 2018), and the expansion of unnecessary or duplicative administrative

1

This is often termed the â€œcost diseaseâ€ theory, originally proposed in the context of performing
arts (Baumol & Bowen, 1966). Since higher education is labor-intensive and wages are set on a
national market, instructional costs in higher education tend to rise faster than in other industries
that can more easily substitute capital for labor. Productivity gains are not able to offset wage
increases, holding down (or reducing) costs as they do in other industries, particularly
manufacturing. The health care industry faces a similar challenge.

4

positions (Campos, 2015). These theories tend to focus on macro-level phenomena and
institutional behavior. However, they also provide insights relevant to the postsecondary unit
chiefly responsible for instruction: the department. To understand differences across fields within
institutions, we now sketch an informal economic model of decision-making for individual
academic departments (programs), and then detail the implications of these broader theories of
costs to the factors that shape education production at a department level.
Programs produce a set of outputs, such as quality-equivalent units of undergraduate
instruction or research publications, using a large set of inputs, such as faculty of different
types, classrooms, office space, technology, and laboratories. 2 Programs choose inputs and
how to combine them in order to maximize an objective function, which characterizes how
much a department prioritizes different outputs. Programsâ€™ maximization is done subject to a
production function and department-level budget constraint, taking input prices as given.
Programs will seek to equalize the marginal benefit of each input relative to its net cost.
Variation in the cost of instruction per student across programs can thus be due to differences
in production functions, budget constraints, input prices, or objective functions across
programs. We discuss each of these in turn.
The production function that maps inputs to outputs likely varies across fields. Some
subjects require intense interaction between students and faculty to produce a given level of
instructional quality; others may require close supervision of students by faculty; and yet
others may require costly laboratory sessions. Relatedly, some fields may be able to take

2

We consider the quantity of instructional credits produced (e.g., how many classes students
take) and the quality of those instructional credits (e.g., how much students learn) as separate
outputs. The relative value placed on quantity versus quality likely varies across institutions (and
possibly programs) and is determined by the objective function.

5

advantage of economies of scale and scope. Some departments are charged with delivering
general education courses for the entire institution, affecting the portion of the marginal and
average cost curves faced by the department. 3 Departments offering both undergraduate and
graduate programs may experience scope economies, as they can tap graduate students as a
pool of lower-cost instructors (e.g., Dundar & Lewis, 1995). Such differences necessarily
affect optimal class size, faculty mix, faculty teaching load, and non-personnel expenditures â€“
all of which determine costs per unit of instruction.
Budget constraints can also vary importantly by field and institution. On the revenue
side, fields typically housed in separate schools such as Engineering or Business (compared to
the College of Arts and Sciences) have different opportunities for revenue generation due to
the use of differential pricing (Stange, 2015) or decentralized budgeting (often referred to as
â€œresponsibility centered managementâ€). Both dictate how much of tuition revenue specific
departments can keep. Some states, such as Ohio, Texas, and North Carolina, explicitly
provide higher levels of appropriations for certain fields that are perceived to be more costly.
Finally, given the large cross-major earnings differences among graduates, some fields will
have greater opportunities to raise donations from alumni. 4 These factors alter departmentsâ€™
incentives and potential for revenue generation which is used to fund investment. On the cost
side of the budget constraint, programs may differ in the extent to which they internalize
personnel and other expenses at the margin, again depending on institutional budgetary and
cost-sharing practices.

3
4

The data allow us to focus on average instructional costs, but we cannot observe marginal costs.
Monks (2003) finds empirical supports for such differences.

6

Though the â€œcost diseaseâ€ theory refers to patterns of cost growth over time, its logic
easily extends to cross-field differences. Higher input prices â€“ most importantly the salaries that
faculty command on the non-academic market â€“ will make instruction of certain fields more
expensive. However, the extent of substitutability of different inputs in the production process
will determine how influential specific input prices are to overall cost differences. For instance,
an ability to shift to larger classes without a meaningful reduction in quality in response to high
wages would constrain cost differences across fields.
Finally, programs may differ in their objectives. In particular, programs may differ in
the extent to which they value quality versus quantity of instruction and between
undergraduate instruction, graduate training, research output, and public service. We do not
take a stand on programsâ€™ particular objectives, but it is reasonable to assume that most
programs strive to maximize something like the number of quality-adjusted degrees. 5
However, we do not expect meaningful differences in objectives across fields in the same
institution given that reputation, admissions, and faculty research expectations mostly operate
at the level of the institution. For instance, tenure decisions are ultimately approved by
university-wide committees or administrators specifically to enforce institution-wide quality

5

There is some literature on the goals of universities. Rothchild and White (1995) assume
colleges are profit maximizing while Epple and colleagues (2006, 2017) assume that colleges are
quality maximizing. If universities and programs have similar objectives since they are part of
the same organization, assuming programs maximize quality of instruction is consistent with
previous research. However, given our data and the purposes of this article, we need not impose
this assumption, but instead, we discuss how well it fits the findings that emerge. It is also worth
noting that because of our data, we focus on instruction, but programs may also care about other
outputs, like research and public service.

7

standards. Throughout the paper, we attempt to tie relevant findings back to this simplified
model of the academic department. 6
B. Prior Evidence on Costs in Higher Education
Most prior work on costs in higher education uses institution-level measures from the
Delta Cost Project (DCP) and IPEDS, documenting trends over time and differences by type of
institution (e.g., Desrochers & Hurlburt, 2016). 7 For instance, Hoxby (2009) demonstrates that
institutional spending became more stratified across institutions as the college market became
more nationalized, with the most selective institutions increasing spending considerably more
than the least selective institutions over the past forty years. 8
This paper builds on very limited prior work on differences in costs across fields and
within institutions, and is most closely related to three previous papers. Altonji and Zimmerman

6

The department-level focus also ignores spillovers across departments and general equilibrium
effects operating through overall student demand. For instance, students need a fixed number of
classes to graduate so a reduction in course demand in one department will typically be offset by
increased demand in another. Programs housed in separate schools may be less sensitive to this
because they can more easily increase enrollments through their own admissions processes and
demand is likely more inelastic since transferring (within a university) is costly.
7
Desrochers and Hurlburt (2016) use DCP data to document changes in spending between 2003
and 2013. They find large increases in total expenditures at research-intensive universities, with
smaller increases at public and private institutions less focused on research. Education and
related expenses, which include expenditures on instruction, student services, and (prorated)
administration and operation costs, range from almost $38,000 per full-time equivalent (FTE)
student at private research-intensive universities, to around $13,000 per FTE at public masterâ€™s
institutions.
8
Archibald and Feldman (2011) also use aggregate data to explore the numerous explanations
for cost increases, concluding that the â€œcost diseaseâ€ theory goes a long way toward explaining
aggregate cost trends. Other explanations â€“ such as administrative bloat and student amenities â€“
do not seem to hold up to scrutiny. They find that the apparent increase in number of
administrative jobs at colleges is due to changes in how workers are classified in survey data and
increased spending on amenities does not appear to be out of line with similar trends in
residential spending. In the end, Archibald and Feldman (2011) tie the increasing costs of higher
education much more strongly to â€œeconomy-wideâ€ factors that affect higher education as well as
other similar industries rather than to â€œdysfunctional economic behavior at colleges and
universitiesâ€ (p. 113).

8

(2017) estimate the costs of producing graduates at the program level for the Florida State
University System. They report, among other findings, substantive differences in costs by
discipline, bookended by engineering and health sciences at the top (with spending of around
$450 per credit) and social science, math, business, and psychology at the bottom (with costs
ranging from $200 to $250 per credit). 9 These large cost differences cause the earnings
differences across fields to be a misleading indicator of the social return on investment across
fields.
Johnson and Turner (2009) document large differences in students per faculty across
departments for several sets of institutions and the University of Virginia. They find that the
number of faculty relative to undergraduate student demand is much higher in sciences and
humanities than in core social science fields like economics and political science. While
differences in salary, research output, and pedagogy likely explain some of these patterns, they
conclude that political frictions constrain universities from dynamically reallocating resources
across units in response to student demand. More recently, Courant and Turner (2017) examine
how resources are allocated at the University of Michigan and the University of Virginia. They
find that departments facing higher faculty salaries allow larger classes and more non-faculty
teaching. Furthermore, higher-paid faculty within departments teach fewer undergraduates and
specialize in graduate instruction.

9

There are a few earlier studies that focused on a small sample of departments and institutions.
Tierney (1980) found that the sciences (biology, chemistry) have costs per student that are 20
percent to 50 percent higher than programs in the social sciences or humanities in 24 liberal arts
colleges. Examining 17 departments across 18 public research universities, Dundar and Lewis
(1995) find economies of scale for engineering but not for physical sciences. They also found
economies of scope in the social sciences, where offering graduate degrees enables departments
to employ graduate students as teaching assistants, resulting in cost savings.

9

Our study also builds on very detailed case studies of a small number of elite institutions.
Clotfelter (1996) investigates Chicago, Duke, Harvard, and Carleton, concluding that the rise in
costs during the 1980s was only partially attributable to increased prices of inputs such as faculty
salaries and books. Increased spending was mostly explained by broad efforts to improve
institutional quality, expand research output, and improve access via financial aid for needy
students. Greater instructional costs were mostly driven by affirmative decisions by institutions
to pay â€œfor more and better units of the educational services that these institutions always had
produced.â€ (Clotfelter, 1996, p. 13). A specific aspect of this is costly investments in new
technology â€“ such as computers and physics labs â€“ which have benefited students and faculty
and increased research output (Bowen, 2012). Examining Cornell University, Ehrenberg (2002)
reaches a broadly similar conclusion: increasing costs reflect a desire to â€œbe the bestâ€ on the part
of elite research universities, which is consistent with revenue theory and quality maximization,
broadly defined. This behavior is unconstrained by typical market forces, as non-profit and
public entities do not profit-maximize since they cannot keep any residual surplus of revenue
over cost as profit. Ehrenberg (2002) also notes several external and structural forces that fuel
this behavior, such as colleges explicitly being rewarded for higher spending in college rankings
and shared governance making substantial cost-cutting nearly impossible.
We build on this prior work to make four contributions. First, our focus on withininstitution, program-level costs is novel (with the few exceptions noted above) and reflects the
reality that â€œdepartments constitute the fundamental organizational unit of colleges and
universitiesâ€ (Tierney, 1980, p. 454.) 10 Second, we look at a much larger set of institutions

10

Academic programs have a great deal of discretion in defining curricula, setting academic
standards, and hiring and promoting faculty (Lattuca & Stark, 2009) â€“ all of which shape
instructional costs. Adoption of differential tuition (Stange, 2015) and responsibility-centered

10

across more sectors. It is not clear if the patterns seen in prior work generalize nationally or to
other sectors. Third, using this broader sample, we examine the role of several factors of
production such as class size, faculty workload, and online instruction in shaping departmentlevel costs. Finally, we look over a longer and more recent time period. Importantly, Johnson and
Turnerâ€™s (2009) analysis ends before the Great Recession when many states cut higher education
funding considerably.
III.

Data Sources and Samples
A. The Delaware Cost Study Data
We use data from the National Study of Instructional Cost and Productivity from the

University of Delaware (the Delaware Cost Study). Since 1998, the study has collected programlevel data from over 700 four-year public and private non-profit higher education institutions and
some 22,000 programs (institution-CIP4). 11 Each year, institutions report degrees awarded, fall
semester instructional activity, and annual expenditure data for each of their academic programs,
which are identified at the four-digit CIP code level. 12 For degrees awarded, institutions report a
three-year average by level: bachelors, masterâ€™s, professional, and doctorate. Fall instructional
activity is measured by faculty full-time equivalents (FTEs), student credit hours, and organized
class sections. Institutions report overall and instructional FTEs by faculty type: tenured and
tenure eligible, other regular, supplemental, credit-bearing teaching assistants, and non-creditbearing teaching assistants. They also disaggregate student credit hours and class sections by
faculty/instructor type and the course level: lower-division undergraduate, upper-division

management (Priest, Becker, Hossler, & St. John, 2002) lend further support to the importance of
disaggregating measures of cost to the academic program level.
11
Appendix Table A1 lists frequently participating institutions.
12
Appendix Figure A1 provides a copy of the form used by institutions to report these data.

11

undergraduate, and graduate. Finally, institutions report total direct expenditures for instruction,
research, and public service and total undergraduate and graduate student credit hours for the
entire academic year.
In this paper, we work with direct instructional expenditures per student credit hour as
our main measure of costs, which include salaries, benefits, and non-personnel expenses. In
2015, the Delaware Cost Study added a component to the survey to capture information about
online instruction. In that first year of data collection, 5,891 unique programs from 264 fields of
study across 175 institutions completed the questions about online courses â€“ over 94 percent of
participants. The data contain information on online student credit hours by department at the
undergraduate and graduate levels.
Institutions choose whether to report data to the Delaware Cost Study. Therefore, we
assessed how well our sample matched the broader universe of public and private non-profit
four-year institutions operating in the United States. 13 We found that over a third of all
institutions had participated in the Delaware Cost Study at least once (34.2percent) and that these
institutions accounted for 60.1 percent of all the degrees awarded between 1998 and 2015.
However, institutions do not participate every year and some fail to report data for all of their
departments. Accounting for these gaps, we estimate that our sample represents 23.3 percent of
all degrees awarded between 1998 and 2015. Coverage is higher for public institutions than
private (32.2 percent versus 7.8 percent of degrees, respectively). Public research universities
ranked as â€œcompetitiveâ€ or â€œvery competitiveâ€ by Barronâ€™s have the highest rates of survey

13

We defined the relevant universe as public or private non-profit bachelors, masterâ€™s, and
research-intensive doctoral institutions operating in the 50 states and the District of Columbia
between 1998 and 2015, from the IPEDS Completions survey. The final universe includes 1,786
institutions that granted 34.9 million degrees.

12

participation. Finally, we find no association between expenditures and participation, after
controlling for sector, type, selectivity, size, and revenue, but we do find a positive association
for both tuition (among privates) and enrollment (among publics) with survey participation. We
use this participaption analysis to construct a set of analytical weights which adjusts our sample
to resemble the universe of four-year institutions. Appendix B provides a detailed explanation of
the coverage analysis and weighting procedure.
B. Analytic Sample
We limit the analytic sample to data collected between 2000 and 2015 from researchintensive, masterâ€™s, and baccalaureate institutions in the United States. 14 We exclude
observations that were missing critical data or had outlying values for the main variables. 15 Our
analysis focuses on 20 core fields of study; they represent the largest fields in terms of student
credit hours delivered or fields that are particularly salient for institutional leaders and
policymakers. 16 Our final sample contains 32,496 institution-year-CIP-4 observations
representing 552 institutions, 20 disciplines, and 7,150 unique programs. We use the full sample
for our longitudinal analyses and pool years 2013 to 2015 for cross-sectional analyses. The
cross-sectional sample includes 7,245 institution-year-CIP-4 observations representing 314
institutions, 20 disciplines, and 3,950 unique programs. The online sample is restricted to the
2015 survey year and consists of 2,051 programs in 20 disciplines and 173 institutions.

14

We use Carnegie Classification to identify institution type. We exclude 13 special-focus
institutions due to small sample sizes. We also exclude 11 institutions outside the United States
and the District of Columbia. Finally, we drop a small number of observations that did not pass a
series of basic data validity checks (e.g., negative FTE values were provided).
15
We define outliers as values greater than the 99th percentile or lower than the 1st percentile of
all values grouped by Carnegie Classification and 2-digit Classification of Instructional
Programs (CIP) codes.
16
These fields along with CIP codes are listed in Appendix Table A2.

13

Using these data, we construct variables that measure costs, outputs, and inputs. Our
primary outcome of interest is direct instructional spending per student credit hour, which we
construct by dividing annual instructional costs by annual student credit hours. We also calculate
this ratio for the personnel expenditures portion of costs. 17 In terms of candidate cost drivers, we
calculate faculty per student (overall and by faculty rank level), faculty teaching load (overall
and by faculty rank level), and average class size (overall and by student level). Where
necessary, we follow IPEDS guidelines for calculating FTEs for faculty and students. 18 We
construct a measure of faculty teaching load by dividing the total number of class sections by
faculty FTE. To generate a measure of class size, we divide fall student credit hours (excluding
individual instruction) by three, assuming the average class is three credits, and then divide this
student count by the total number of course sections (excluding additional course sections, such
as labs and discussion sections). 19
C. Descriptive Statistics
Table 1 presents summary statistics for the main variables in the full sample, separately
by Carnegie classification. 20 All analyses, summary statistics, figures, and regressions are
weighted by the product of the inverse probability of participating and student credit hours at the
program level. This provides estimates that reflect the average student course enrollment in the
country. Research-intensive institutions spend more per credit hour, on average, than do masterâ€™s

17

Before constructing these variables, we convert all cost data to 2015 dollars using the CPI-U.
The student FTE equals 1/3rd of total adjusted part-time student count plus the count of fulltime students; faculty FTE equals 1/3rd of total adjusted part-time instructional staff plus the
count of full-time instructional staff.
19
We calculated additional class size variables to use for robustness checks that assume the
average course is four credits. Results are similar when we use this higher credit value.
20
Appendix Table A3 presents the same statistics for the pooled, cross-sectional sample of 2013
to 2015. Patterns are similar.
18

14

and baccalaureate institutions. The gap between institutions with the highest research activity
and baccalaureate colleges is about $54 per credit hour. This is a sizeable gap relative to the
average for all institutions in the sample of about $222 per credit hour. Teaching loads are also
lower at research institutions. Compared to faculty at baccalaureate institutions, faculty at high
and moderate research institutions teach about 1.2 and 0.7 fewer classes per semester. Smaller
teaching loads may influence undergraduate class sizes, which are larger at high and moderate
research institutions, respectively, compared to baccalaureate institutions. 21
These differences likely reflect differences in objective functions. If instruction, rather
than research, contributes more to a baccalaureate institutionâ€™s objective, then holding the
production function constant, theory predicts that departments will spend relatively more of their
budgets on instructional quality through smaller classes. Similarly, we expect lower teaching
loads where research output constitutes more to universities objectives.
Figure 1 depicts average instructional costs per student credit hour from 2000 to 2015, in
2015 dollars. Contrary to the narrative of soaring tuition prices, real instructional expenditures
per student credit hour have remained quite flat over the past 15 years. As we show below, this
steady, institution-level average obscures substantial variation in costs over time by field of
study. Figure 2 shows cross-sectional variation in expenditures across different fields. Electrical
engineering averages more than $475 per student credit hour, about $300 more than for math.
What drives these differences across fields? As a prelude to subsequent analyses, Figure
3 depicts variation in four key determinants of costs at a department level: class size, instructor
salary, workload, and non-personnel expenses. There are clearly big differences in these factors
of production across fields, particularly in class size (student credit hours per section) and

21

Graduate classes are about the same size across institution type.

15

average salary. Below we quantify the individual contribution of each factor to explaining the
cross-field cost differences observed in Figure 2.
IV.

Cross-sectional Differences
A. Cross-Field Differences in Instructional Costs
Using a pooled sample from 2013 to 2015 as a single cross-section, we document

differences in average direct instructional costs with the following econometric setup:
ğ‘™ğ‘™ğ‘™ğ‘™(ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ ) = ğ›¼ğ›¼ + ğ›¿ğ›¿ğ‘ğ‘ + ğœ‘ğœ‘ğ‘–ğ‘– + ğœ€ğœ€ğ‘ğ‘ğ‘ğ‘

(1)

Here, ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ is direct instructional expenditures per student credit hour in 2015 dollars for discipline
c (i.e., CIP-4 code) at institution i; ğ›¿ğ›¿ğ‘ğ‘ are CIP-4 fixed effects; ğœ‘ğœ‘ğ‘–ğ‘– are institution fixed effects; and
ğœ€ğœ€ğ‘ğ‘ğ‘ğ‘ is a stochastic error term. We use the most common discipline in our data, English, as the

reference category. Thus, the coefficients on the vector of discipline fixed effects (ğ›¿ğ›¿ğ‘ğ‘ ) represent

the average log difference in instructional costs per credit hour relative to English, controlling for
fixed, time-invariant characteristics of institutions. 22 Alternatively, we can think of these
parameters as the across-field differences within institutions, averaged across institutions.
Figure 4 reports cross-sectional differences in costs across disciplines, after netting out
institutional differences using equation (1). There is substantial variation across fields in average
costs. For example, costs associated with each additional SCH are 109 percent (0.74 log points)
higher for electrical engineering and 22 percent lower for math, relative to English. Most social
science disciplines, math, and philosophy are relatively less costly whereas STEM fields and
those with traditionally large pre-professional programs (e.g., nursing) are relatively more costly.
This broad conclusion holds across institutions of different control, research intensity, and

22

The inclusion of institution fixed effects does not materially alter our estimates of cross-field
cost differences, as most institutions in the data offer a variety of disciplines and this is not
systematically related to costs.

16

selectivity. 23 That is, a field like computer science is moderately more expensive than English no
matter whether it resides in a private comprehensive institution or a public research-intensive
institution. We therefore pool institutions going forward.
Which fields are more expensive? Table 2 catalogues a few characteristics of fields
ordered by their relative cost. Though several of the more costly fields also tend to have high
earnings (e.g., engineering and computer science), there are exceptions to this general pattern.
For instance, education and fine/studio arts are among the most costly programs and also the
lowest paid. Higher-earning fields being more costly to produce is generally consistent with the
university equalizing the ratio of economic benefits and costs across fields, though these
measures do not capture the full extent of costs and benefits, nor do they capture them at the
margin.
More costly fields also are more likely to have access to additional revenue sources than
English departments. In both revenue theory and quality maximization, we expect fields with
access to larger budgets to have greater expenditures. Almost all of the most costly fields are
typically housed in separate schools or colleges from English, permitting them to generate
additional revenue through differential tuition or separate fund-raising efforts from alumni or
industry. Finally, many of the more costly fields receive additional state appropriations in Texas
and North Carolina, two states with large systems of public institutions for which we obtained
detailed information on budgeting formulas. 24

23

Appendix Figures A2 and A3 show cost differences for public relative to private institutions
and for institutions of varying levels of selectivity. The broad conclusions about field-specific
costs are similar to what we see in the pooled sample.
24
Note that the causal direction is unclear. States are aware of cost differences between fields
and thus target additional resources to more costly fields.

17

B. Why Do Costs Differ Across Fields?
To quantify how these cross-field differences can be explained, in a statistical sense, by
individual factors of production, we develop an accounting identity in the spirit of Clotfelter
(1996) and estimate its logged form. We replace the field fixed effects from equation (1) with
terms that capture four cost components: 25
ğ‘‘ğ‘‘ğ‘‘ğ‘‘ğ‘‘ğ‘‘ ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’

ğ‘™ğ‘™ğ‘™ğ‘™(ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ ) = ğœ‘ğœ‘ğ‘–ğ‘– + ln ï¿½

ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘

ï¿½ + ln ï¿½
ğ‘ğ‘ğ‘ğ‘

ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘
ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“

ï¿½ + ln ï¿½
ğ‘ğ‘ğ‘ğ‘

ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“

ï¿½ + ln ï¿½

ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘ğ‘ğ‘ğ‘

ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ 
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†

ï¿½ +ğœ€ğœ€ğ‘ğ‘ğ‘ğ‘ (2)
ğ‘ğ‘ğ‘ğ‘

The first factor captures the importance of personnel expenses relative to all direct instructional
expenditures. The second term represents average faculty salary, which is determined by the mix
of faculty ranks (e.g., tenure-track faculty, fixed-term instructors, adjunct faculty) and average
salary conditional on rank. The third term is an inverse measure of faculty workload (i.e., the
inverse of class sections taught per FTE faculty member). Finally, the last term captures (the
inverse of) class size. Differences in these four cost factors explain variation across programs in
costs to deliver a credit hour, or an approximation of the production function. A given program
may be more expensive than another because it employs more expensive faculty; because its
faculty have a lower average teaching load; because its classes are smaller; or because the
department incurs a greater level of other non-personnel instructional expenses (e.g., laboratory
expenses in the sciences).
Since equation (2) is the log of an accounting identity, the coefficients on the cost drivers
ought to be one and the constant zero. However, the time horizon over which the dependent

25

Average direct instructional costs per student credit hour for any given program can be
decomposed into four distinct components of cost:
ğ‘‘ğ‘‘ğ‘‘ğ‘‘ğ‘‘ğ‘‘ ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’
ğ‘‘ğ‘‘ğ‘‘ğ‘‘ğ‘‘ğ‘‘ ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– ğ‘’ğ‘’ğ‘¥ğ‘¥ğ‘ğ‘
ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ #ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ #ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ 
ï¿½
ï¿½=ï¿½
ï¿½ï¿½
ï¿½ï¿½
ï¿½ï¿½
ï¿½
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†
ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ #ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹
# ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ 
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†
18

variable is measured differs from the horizon over which the components of the cost drivers are
captured, so coefficients will not exactly equal one. 26 Once the four cost drivers are included in
the regression, the coefficients on those measures are indeed quite close to one. 27 In all analyses,
we cluster standard errors by institution and weight observations by the product of total student
credit hours and the inverse probability of participating in the survey. This ensures that the
sample is approximately representative of instruction across all institutions.
We determine the relative importance of each cost driver in explaining cost differences
by field via a series of simulations. Continuing with English as the benchmark field, we predict
costs for each of the 19 other disciplines by varying one cost driver at a time and holding the rest
constant, at the values for English. Table 3 presents the results of this decomposition. The first
column reproduces the unadjusted cost differences from Figure 4. Each subsequent column
estimates the contribution of a particular cost driver to the overall cost difference between a
given field and English. First consider economics, which is approximately 5 percent less
expensive than English. Economics faculty are more highly paid than English, and thus if all cost
drivers other than average pay were equalized between the two fields, economics would be 0.38
log points more expensive (column 2). On the other hand, economics classes tend to be much
larger than English classes, so class size differences make economics 0.50 log points less
expensive than English (column 4). Faculty workload is a little lighter in economics than
English, so if that were the only difference, economics would be 7 percent more expensive than
English. Putting these findings together, we see that economics departments are able to field

26

Specifically, direct instructional expenditures is measured over the full academic year, but the
four cost factors only capture the fall semester of an academic year. Appendix C works out the
implications of these data realities for our estimating equation.
27
Regression results are reported in Appendix Table A4.

19

classes that are large enough to more than offset the higher salary and (slightly) lower workload
of economics faculty, resulting in slightly lower average costs than English.
Mechanical engineering, which is 82 percent more expensive than English (or 0.60 log
points), provides a counter example. Like economics, mechanical engineering professors also
command higher wages and have lower teaching loads than English faculty. As a result, the
average difference in faculty pay across these two fields contributes substantially to the overall
cost difference. Unlike economics, however, classes are only modestly larger in mechanical
engineering than in English. Class size differences are not large enough to offset the higher
salary and lower teaching load, thus mechanical engineering remains much more expensive than
English.
Though each field is slightly different, a few general patterns emerge. Economics,
political science, accounting, and business have high salaries which are offset by large classes,
though not completely for the latter two fields. Engineering and nursing are more expensive than
English due to higher salaries and lower teaching loads without commensurately larger classes.
Workload and non-personnel expenses are important for some of the sciences with laboratory
components, namely biology and chemistry, but otherwise explain relatively little of the
observed cost differences.
More generally, instructional cost differences across fields can mostly be explained by
large differences in class size across disciplines and, to a lesser extent, differences in average
faculty pay. Teaching loads and other (non-personnel) expenditures explain relatively little.
Further, some fields with highly paid faculty (like economics) fully offset salaries via large

20

classes, generating costs that are comparable to English despite the higher pay. 28 One
explanation is that these patterns reflect important differences across field in the production
function of higher education â€“ some fields are more amenable to the large, lecture-based format
needed for large classes without a commensurate reduction in instructional quality. An
alternative interpretation is that fields have different objectives dictating how they value
instructional quality and other outputs. While possible, our within-institution analysis likely
minimizes the role of preference differences as an explanation. Within institution, departments
are overseen by common Provosts and Deans and also compete for students.
V.

Differences in Costs Over Time by Field of Study
Figure 5 plots field-specific trends in instructional costs since 2000 and net of institution-

by-field fixed effects. Several trends are noteworthy. First, there are appreciable declines in costs
in several STEM fields â€“ mechanical engineering, chemistry, physics, and biology â€“ as well as in
nursing. A few fields experienced growth in costs during this time period, including English,
accounting, communication, and fine arts. Finally, several fields â€“ mostly social sciences â€“
experienced declines in expenditures that recovered by the end of the sample period. These
striking differences across fields are masked when one looks at the aggregate spending trend
shown in Figure 1.
Though several fields experience unusual time patterns, we focus on cross-field
differences in the linear time trend over the whole sample period, estimated with the following
setup:
ğ‘™ğ‘™ğ‘™ğ‘™(ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ) = ğœ‘ğœ‘ğ‘ğ‘ğ‘ğ‘ + ğ›½ğ›½1 ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ + ğ›¾ğ›¾ğ‘‘ğ‘‘ (ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ğ‘¡ âˆ— ğ›¿ğ›¿ğ‘ğ‘ ) + ğœ€ğœ€ğ‘ğ‘ğ‘ğ‘
28

(3)

It is worth recalling that these average pay differences already reflect instructor mix
differences across fields, so they likely attenuate market-level pay differences across fields for
instructors of a given rank.

21

Here, ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ is the log of direct instructional expenditures per student credit hour in 2015 dollars

for discipline c (i.e., CIP-4 code) at institution i in year t. This model includes fixed effects at the
program level (field-by-institution, denoted ğœ‘ğœ‘ğ‘ğ‘ğ‘ğ‘ ), controlling for time-invariant characteristics of
academic programs. The coefficients of interest are the field-specific linear time trends in ğ›¾ğ›¾ğ‘‘ğ‘‘ .

They represent annualized changes in costs over the 15 year time period, relative to English.

Thus, ğ›½ğ›½1 captures the annual time trend in costs for English departments. Instead of costs, the

outcome ğ‘¦ğ‘¦ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ can also represent a particular cost driver, such as the log of average class size for
discipline c at institution i in year t.

Figure 6 presents estimates from equation (3) of the average yearly changes in
instructional costs and each of our four cost drivers. Each bar is equal to ğ›½ğ›½1 plus the field-

specific ğ›¾ğ›¾; the average annual change for English is simply ğ›½ğ›½1 . Panel A of Figure 6 arrays

disciplines by the average annual percentage increase in direct instructional expenditures per
SCH between 2000 and 2015. Panels B, C, and D array disciplines by average growth in cost
drivers over the same period. Costs grew for many fields, especially Fine Arts and Education,
while a subset of largely STEM-related fields saw real declines in costs. Changes over time in
costs for most fields are quite linear; however, our approach will be a relatively poorer
approximation of the experiences of fields with non-linear cost changes over time, such as
electrical engineering and computer science. 29 Focusing on one field across these panels allows

one to tell a story about the drivers of field-specific cost changes over time. For example, in
chemistry, the decline in costs over time of about 1.5 percent per year is explained by an increase

29

Appendix Figures A4 to A7 show the full trends over time in instructional costs and cost
drivers by field.

22

in average class size and a large increase in average faculty workload, which together more than
compensate for the modest rise in faculty salaries.
Table 4 decomposes the field-specific linear growth rates show in Figure 6 into the
contribution made by changes in each of the four factors. Column (1) reports the average annual
change in instructional costs for each of our 20 fields. The contribution to overall cost trend for
each driver is reported in columns 2 to 5. 30 The findings that emerge from this panel analysis
largely concord with our cross-sectional analyses: across many fields, changes in faculty salaries
and class sizes over time account for the bulk of changes in instructional costs between 2000 and
2015. For instance, mechanical engineering saw a 2.17 percent reduction in cost each year,
which is more than fully explained by the 2.36 percent annual increase in class size. Costs for
accounting rose by 0.83 percent annually, driven by faculty salary growth of 1.55 percent that
outpaced offsetting increases in workload and class size. Some fields saw notable changes in
faculty workload: Psychology, education, English, and media/communications studies all saw
reductions in faculty workload over this period, which increased costs, while chemistry
experienced a notable increase. For no field did changes in non-personnel expenditures increase
costs, and for a few STEM fields there were appreciable declines in such expenditures â€“ perhaps
reflecting lower technology or lab-related costs.
For a handful of fields, the linear, annualized growth rates are poor approximations of
actual, non-linear trends in costs. One of the clearest examples of such a field is electrical
engineering. Appendix Figures A4 to A7 show the full trends in direct instructional expenditures

30

For example, electrical engineering costs increased by 0.52 percent annually on average.
Changes to salaries alone would have resulted in a 0.93 percent annual increase; reductions in
workload would have resulted in a 0.87 percent increase. These are offset by reductions in cost
due to increasing class sizes (-1.14 percent) and a modest decline in other expenses (-0.13
percent). Summing columns 2 to 5 equals the annual percentage change reported in column 1.

23

and cost drivers over time by field. The inverted-U shaped cost curve visible in Figure 5 for
electrical engineering tightly tracks the trends for average class size and teaching workload in
Appendix Figures A4 and A6. The story for computer science is very similar: a decline in
average class size alongside an increase in average faculty salaries over the first half of our time
period pushed costs up, while an increase in average class size and decline in salaries over the
second half accounts for the bulk of the decline in average instructional costs during those years.
Thus, we encourage readers with particular interests in fields that have highly non-linear cost
trajectories to consult the raw trends in costs and cost drivers available in these appendix figures.
VI.

Average versus Marginal Cost
Our focus so far has been on differences in average costs across fields and over time. Of

additional relevance for institutions, however, is how total cost changes as they provide more (or
less) instruction; marginal cost is highly relevant for decision-making. Providing an additional
credit hour of instructional activity may be more costly for some fields than others due to
differences in production functions. We test this by contrasting average and estimated marginal
cost for each of the 20 fields. Average cost is more straightforward to assess, as it is directly
observed (Figures 2 and 6 show unconditional and conditional estimates, respectively). Table 5
presents estimates of average and marginal cost by field. We assume marginal cost is constant
and we estimate it as the coefficient on total credits when regressing total instructional cost on
total credits, separately by field. 31 Our preferred estimates include program-level fixed effects,
correlating within-program changes in instructional output with changes in instructional cost. It
should be noted that prior work estimating returns to scale relied on cross-sectional variation

31

We explored several ways of relaxing this constant marginal cost (linear total cost)
assumption. Estimates of field-specific piecewise linear total cost curves do not show obvious
patterns of decreasing or increasing marginal cost for most fields.

24

(column (2)), which is quite biased by unobserved factors that are correlated with scale and cost
(comparing (2) to (3)).
Similar to average cost, we find large differences in marginal cost across fields. Patterns
of average and marginal cost are similar, with some exceptions. Electrical engineering has both
the highest estimated marginal cost ($228) and average cost ($410) and many of the lowest
average cost programs (mathematics, sociology, psychology, and philosophy) have very low
marginal cost. Chemistry, however, has the lowest estimated marginal cost of -$72, meaning that
Chemistry program expansion is actually associated with a decrease in total instructional cost in
our data. This could be due extreme economies of scope as in Dunbar and Lewis (1995), changes
in program quality, or changes in the level of other outputs (research or public service output of
faculty) since our cost function estimates incorporate the endogenous responses by programs.
Reductions in program quality (larger classes, less qualified instructors) could then have negative
impacts on student performance.
We test for the possibility of scope economies by estimating the marginal cost functions
separately by the presence of graduate education, shown in the last two columns. 32 We find an
estimated marginal cost of -$115 for chemistry programs with graduate education, and $115 for
those without. This is consistent with a disproportionately greater use of graduate students as
low-cost instructors when programs expand scale. We see a similar story in computer and
information sciences, biology, physics, and psychology. In professional degree fields, like
electrical engineering, nursing, education and business, the marginal cost is much larger when
graduate education is present than in undergraduate-only programs. This is again consistent with

32

Unfortunately our data do not separate costs between graduate and undergraduate instruction.

25

the economies of scope explanation since large master degree programs in those fields do not
typically generate more teaching assistants.
Our four cost drivers play a similar role for marginal cost as they do for average cost.
Programs with high faculty workload, such as chemistry, biology, physics, and computer and
information sciences, tend to have low marginal cost. In these fields, program expansion in
response to increased student demand can be accommodated by current faculty teaching more for
the same salary, with modest increase in instructional cost and an unclear effect on the quality of
instruction.
VII.

Deeper Investigation of Faculty Salary and Class Size
In this section, we further investigate the two factors that account for the bulk of cross-

field differences in costs cross-sectionally and over time: faculty salary and class size.
At the department level, faculty salaries are a function of the mix of faculty (e.g., share
tenure-track, share supplemental/adjunct) and average salary level conditional on type/rank. In
our data, we cannot disaggregate compensation by faculty type; therefore we focus on faculty
mix and its relationship to personnel expenditures. 33 Figure 7 displays cross-sectional differences
in faculty mix by field. There is quite a bit of variation in the share of tenure-track faculty by
field, with only 40 percent of nursing faculty on the tenure track but nearly three-quarters of
mechanical and electrical engineering faculty in tenure-track roles. English, communications,
and math also have relatively low shares of tenure-track faculty. Thus greater use of tenure-track
faculty, which are more expensive, is one explanation for higher personnel costs in engineering,
economics, and the sciences. The greater use of such faculty could reflect a number of things,

33

This means that we cannot formally integrate our disaggregated explorations of this driver (nor
the next) into the accounting identity that guided our decomposition analyses.

26

including how different faculty types enter into the production function or differences in the
availability of non-tenure-track instructors to draw on to teach. 34
In Figure 8, we document trends in faculty mix over time by field. The majority of fields
experienced a clear decline in the share of tenure-track faculty between 2000 and 2015 alongside
offsetting increases in shares of contingent faculty. This drop was especially pronounced for
nursing, where by 2015 the typical nursing program had roughly equal shares of tenure-track and
â€œotherâ€ faculty and a relatively large share of â€œsupplementalâ€ faculty. This change in faculty
rank mix is reflected in the salary trend for nursing, where we see a modest decline. For example,
if tenure-track faculty in nursing became more expensive over this time, programs may have
chosen less expensive faculty types to combat cost growth and satisfy their budget constraints.
The shift in nursing faculty may also reflect changes to nursing instruction itself, toward RN-toBSN programs with greater reliance on contingent faculty.
In economics, the shares of tenure-track, other, and supplemental faculty remained
relatively stable between 2000 and 2015 while average expenditures on faculty salaries trended
upward. This suggests that in economics, changes in salary expenditures were largely related to
increases in salary conditional on rank (likely rising salaries for tenure-track positions) rather
than changes in the mix of faculty types. Costs also increased during this time period, implying
that economics departments must have been able to secure larger budgets or adjust other cost
drivers such as class size, faculty workload, or faculty mix to accommodate higher faculty
salaries, conditional on rank. In panel C of Figure 6, we see a moderate increase in average class
size over this period for economics. In contrast, psychology saw a notable decline in the share of

34

The share of tenure-track faculty will also relate to the programâ€™s desire for research
productivity, which we do not examine.

27

tenure-track faculty from 2000 to 2015 and an increase in the share of non-tenure-track
instructors; yet, average expenditures on psychology faculty salaries increased on par with other
fields over this period. There could be several explanations for such a pattern â€“ from stagnating
salaries for tenure-track faculty in psychology to a smaller gap between tenure-track salaries and
non-tenure-track salaries relative to other fields.
We now turn to the second key cost driver, class size. Differences in class size are a
function of the mix of course types offered (i.e., lower-level undergraduate, upper-level
undergraduate, and graduate) as well as the average class size conditional on type of course.
Figure 9 shows substantial differences in the mix of course types offered, with relatively fewer
lower-division courses in professional fields like nursing, education, and business, and many
lower division courses in the sciences (physics and chemistry) and mathematics. Fields with
relatively little undergraduate instruction, like engineering and nursing, tend to be more
expensive.
Figure 10 presents trends in average class size by course type for each field (Panel A) as
well as trends in the mix of course types by field (Panel B). Pairing findings from these figures
with the overall trends in class size by field yields deeper field-specific insights. For example,
the marked increase in average class size for nursing was partially driven by a decrease in the
share of credits that were lower-division undergraduate and an increase in the share of graduatelevel credit hours. Average class sizes for all types of nursing courses, undergraduate and
graduate, also trended upward over time. In contrast, consider the uptick in overall average class
size for mechanical engineering documented earlier. Figure 10 shows that this increase was
driven by an increase in class sizes among all levels of undergraduate courses, rather than by a
large shift in the mix of courses taught.

28

VIII. Is Online Instruction Cost-Saving?
In recent years, the adoption of online instruction has commanded sustained interest from
policymakers and institutional leaders as a possible means of counteracting the growth in
postsecondary prices (e.g., Deming, Goldin, Katz, &Yuchtman, 2015). Using a new online
survey component that was added to the Delaware Cost Study in 2015, 35 we compute the share
of total credits delivered online by discipline, which are displayed in Figure 11 for undergraduate
and graduate instruction. There is substantial variation in the prevalence of online instruction,
ranging from essentially zero (undergraduate engineering) to as much as a third of all credits
(graduate nursing). Table 6 shows descriptive statistics for programs divided into five groups: no
online enrollment, and (conditional on any online instruction) the quartiles of online shares. In
the 20 disciplines we study, 48 percent of programs have no online enrollment. Online offerings,
as well as exclusively online programs, are more prevalent in graduate education. Private
institutions, those with larger shares of undergraduate credits, and those with larger shares of
tenure-track faculty all have less online enrollment.
To better understand the relationship between online offerings and costs, we present
estimates from regression models in Table 7. The outcome across all columns is the log of direct
instructional expenditures per credit hour in 2015. Estimates come from our preferred
specification, which includes institution and field fixed effects as well as a distantly lagged

35

A wide range of programs and institutions responded to the new online survey component.
Indeed, over 95 percent of the 2,158 programs across 173 institutions and 20 fields of study that
completed the main survey in 2015 also completed the new online section. The remaining 107
programs come from 11 institutions, with 9 of those not completing the online portion for any of
their programs in our sample. Non-respondents were more likely to be private institutions with
moderate levels of research activity.

29

measure of direct instructional expenditures. 36 Since online instruction is relatively new and
nearly non-existent more than 10 years ago, controlling for lagged costs allows us to interpret the
regression coefficients as the within field and institution correlation between change in costs and
the change in online instruction. 37 Taken together, the fixed effects and lagged cost variable
account for many first-order concerns related to selection bias. However, we caution the reader
against a causal interpretation of these findings.
The results in columns 1 and 2 reveal that the presence of any online instruction is
associated with a modest reduction in costs for undergraduate courses. However, column 3
suggests that the intensive margin of online education matters more than the extensive margin.
That is, the mere presence of a few online courses may be unlikely to meaningful alter average
costs, but a program that is substantially online may reduce costs, which is consistent with online
instruction having its own large fixed costs. This is also reflected in column 6, where we find
that only the largest undergraduate online programs have statistically significantly lower costs.
Indeed, the findings in column 3 imply that a fully online program is 29 percent less costly than a
fully in-person program. The estimates in columns 4 to 6 further suggest that this may be
especially true for undergraduate education. We find much less evidence that the presence or
intensity of online instruction in graduate education reduces instructional costs. Contrast this
finding with the fact that online instruction tends to be more prevalent among graduate

36

We compute this lagged control variable of direct instructional expenditures per SCH by
averaging over the available program data from 2000-2005 based on prior survey participation so
that the baseline is at least 10 years ago. When data are missing, we include an indicator to
maintain the full sample. Results are similar in specifications where we drop programs with
missing data. In addition, estimates from unweighted models reveal a similar pattern of findings,
though estimates are a bit more precise.
37
The regression thus approximates a first-difference approach with field- and institutionspecific trends. However, the coefficient on the lagged costs is much less than 1 so it is not
precisely a first difference.

30

coursework (Table 6). While most point estimates are statistically insignificant, most
specifications suggest that greater online enrollment is associated with lower costs. Finally, we
note that there is only one program in our sample that is fully online, and the median program is
5 percent online. Thus, the relevant range of â€œintensityâ€ observed in our sample is modest, which
ought to temper any proclivity to overgeneralize these findings.
The returns to the adoption of new technology such as online courses will depend on a
fieldâ€™s production function, and how online education alters it; moving to online instruction may
decrease quality-adjusted output for some fields more than others. Indeed, recent evidence
suggests that online instruction may harm the performance of lower-achieving students
(Bettinger & Loeb, 2017; Dynarski, 2018). Similarly, some fields may find online education a
more useful tool than others in lowering costs without compromising quality. Better
understanding this element of fieldsâ€™ production functions is a productive path for future
research.
IX.

Conclusions
In this paper we use detailed data on costs, outputs, and factors of production to provide a

comprehensive descriptive analysis of field-level instructional costs in higher education. This
analysis reveals appreciable variation in the cost of delivering a unit of teaching across fields:
relative to English, costs range from 109 percent higher for electrical engineering to 22 percent
lower for math. This variation in costs is a function of large differences in class size and, to a
lesser extent, differences in average faculty pay. We observe different stories across fields in
terms of the trade-offs implied by the cost drivers. Some fields, like economics, offset high
wages with large classes, resulting in costs that are comparable to English despite higher faculty
pay. Other fields, such as mechanical engineering and computer science, do not offset high

31

faculty pay with large classes, resulting in costs that are much greater than English. Still others,
like physics, partially offset higher faculty salaries with heavier faculty workloads, resulting in
costs that are moderately higher than English.
Over the past 15 years, we find that average instructional costs per credit hour have
barely budged. However, this relatively flat trend in average costs obscures variation in such cost
trends by field of study. Some STEM fields experienced steep declines in spending over this time
period as classes became larger and faculty workloads increased. Other fields like nursing also
saw declining costs that reflect a shift in the composition of faculty, with greater reliance on nontenure track staff. Yet other fields, like business and accounting, have experienced escalating
costs driven by rapid growth in faculty salaries. For all its promise, online education, arguably
the highest profile change to the delivery of higher education over this time period, is associated
with only a modest reduction in instructional costs, and only for undergraduate instruction.
The cross-sectional findings highlight the fact that costs associated with instructional
activity vary greatly across disciplines. Analyses of costs at the institution level mask this
heterogeneity. Variation in costs by discipline has important implications for institutional leaders
facing decisions such as differential tuition pricing or the appropriate level of centralization for
managing academic units and budgets (e.g., the adoption of responsibility centered
management). Cost differences by discipline also have implications for institutional or
governmental efforts to encourage student enrollments in certain high-cost disciplines (e.g., the
numerous initiatives aimed at increasing attainment in STEM), and for the distribution of state
appropriations to public universities. The panel analysis suggests ways in which universities and
departments may have sought to manage costs. Institutions have little control over the prevailing
market wages for faculty, but changes in faculty workload, class size, and mix of course types

32

(i.e., undergraduate versus graduate, and in-person versus online) across disciplines show some
of the ways that costs might be kept in check. However, changes along these margins are also
likely to shape other departmental outputs, such as research productivity and the capacity for
public service. Thus, changes aimed at reducing instructional costs must balance potential effects
on other valued outputs of academic departments.
Many of our findings highlight the fact that the production function in higher education is
likely to differ meaningfully by field. Thus, these results highlight the need for additional
research that sheds light on the effects of inputs on field-specific outcomes, including measures
of quality such as student performance and success after college completion. For example,
perhaps the adoption of online instruction reduces average instructional costs without impinging
quality in mathematics, but a similar reliance on online education in chemistry reduces quality. It
is imperative to consider the effect that resource allocation decisions have on learning,
instructional quality, and student outcomes and how this differs by field â€“ especially in light of
recent evidence that ties increases in spending to higher rates of degree completion (Deming &
Walters, 2018). This next step would allow policymakers and institutional leaders to use the
findings related to discipline-specific cost drivers from this paper in a manner most likely to
reduce costs while upholding the quality of postsecondary educational delivery.

33

References
Altonji, J.G., Arcidiacono, P., & Maurel, A. (2016). The analysis of field choice in college and
graduate school: Determinants and wage effects. In E. Hanushek, S. Machin, and
L.Woessmann, eds., Handbook of the Economics of Education, Vol. 5, pp. 305 â€“ 396.
London, UK: Elsevier.
Altonji, J.G., & Zimmerman, S.D. (2017). The costs of and net returns to college major. NBER
Working Paper No. 23029.
Autor, D.H. (2014). Skills, education, and the rise of earnings inequality among the â€œother 99
percentâ€. Science, 344(6186), 843-851.
Bettinger, E., & Loeb, S. (2017). Promises and pitfalls of online education. Evidence Speaks
Reports, 2(15). Washington, DC: Brookings Institution.
Bowen, H.R. (1980). The costs of higher education. Hoboken, NJ: Jossey-Bass.
Bowen, W.G. (2012). The cost disease in higher education: Is technology the answer? The
Tanner Lectures Stanford University.
Bowen, W.G. (2013). Higher education in the digital age. Princeton, NJ: Princeton University
Press.
Campos, P. (2015, April 4). The real reason college tuition costs so much. The New York Times.
Clotfelter, C.T. (1996). Buying the best: Cost escalation in elite higher education. Princeton, NJ:
Princeton University Press.
College Board. (2015). Trends in college pricing. Washington, DC: Author.
Courant, P. N., & Turner, S. (2017). Faculty deployment in Research Universities. NBER
Working Paper No. w23025.
DeFour, M. (2015, January 29). Gov. Scott Walker to UW faculty: Consider teaching one more
class per semester. Wisconsin State Journal.
Deming, D.J., Goldin, C., Katz, L.F., & Yuchtman (2015). Can online learning bend the higher
education cost curve? American Economic Review: Papers & Proceedings, 105(5), 496501.
Deming, D. J., & Walters, C. R. (2017). The impact of price caps and spending cuts on US
postsecondary attainment. NBER Working Paper No. w23736.
Desrochers, D.M., & Hurlburt, S. (2016). Trends in college spending: 2003-2013. Washington,
DC: Delta Cost Project.

34

Dundar, H., & Lewis, D.R. (1995). Departmental productivity in American universities:
Economies of scale and scope. Economics of Education Review, 14(2), 119-144.
Dynarski, S. (2018, January 19). Online courses are harming students who need the most help.
The New York Times, Economic View.
Ehrenberg, R. G. (2002). Tuition rising. Boston, MA: Harvard University Press.
Epple, D., Romano, R., & Sieg, H. (2006). Admission, tuition, and financial aid policies in the
market for higher education. Econometrica, 74(4), 885-928.
Epple, D., Romano, R., SarpÃ§a, S., & Sieg, H. (2017). A general equilibrium analysis of state and
private colleges and access to higher education in the US. Journal of Public Economics,
155, 164-178.
Goldin, C., & Katz, L.F. (2008). The race between education and technology. Boston: Harvard
University Press.
Hemelt, S. W., & Marcotte, D. E. (2016). The changing landscape of tuition and enrollment in
American public higher education. RSF: The Russell Sage Foundation Journal of the
Social Sciences, 2(1), 42-68.
Hoxby, C. M. (2009). The changing selectivity of American colleges. Journal of Economic
Perspectives, 23(4), 95-118.
Johnson, W.R., & Turner, S. (2009). Faculty without students: Resource allocation in higher
education. Journal of Economic Perspectives, 23(2), 169-189.
Kelly, A., & Carey, K. (2013). Stretching the higher education dollar: How innovation can
improve access, equity, and affordability. Boston: Harvard Education Press.
KirkebÃ¸en, L., Leuven, E., & Mogstad, M. (2016). Field of study, earnings and self-selection.
Quarterly Journal of Economics 131(3), 1057-1111.
Lattuca, L.R., & Stark, J.S. (2009). Shaping the college curriculum: Academic plans in context.
Hoboken, NJ: John Wiley and Sons.
Monks, J. (2003). Patterns of giving to oneâ€™s alma mater among young graduates from selective
institutions. Economics of Education Review, 22(2), 121-130.
National Association of State Budget Officers. (2013). Improving postsecondary education
through the budget process: Challenges & opportunities. Washington, DC: Author.

35

Rothschild, M., & White, L. (1995). The analytics of the pricing of higher education and other
services in which the customers are inputs. Journal of Political Economy, 103(3), 573586.
Seligman, L. (2012, November). Did Texas just discover the cure for sky-high tuition? The
Atlantic.
Stange, K. (2015). Differential pricing in undergraduate education: Effects on degree production
by field. Journal of Policy Analysis and Management, 34(1), 107-135.
Stange, K., Jacob, B., & McCall, B. (forthcoming). College as country club: Do colleges cater to
studentsâ€™ preferences for consumption? Journal of Labor Economics.
State Higher Education Executive Officers Association. State higher education finance: FY2016.
Boulder, CO: Author.
Tierney, M.L. (1980). An estimate of departmental cost functions. Higher Education, 9(4), 453468.

36

Figure 1. Average Instructional Cost per Student Credit Hour

Notes: Cost refers to direct instructional expenditures per student credit hour. Sample includes public and private
institutions participating in the Delaware Cost Study between 2000-2015. Only departments in the 20 fields listed in
Table A1 are included. A small number of observations with missing or outlier data are excluded. Program-level
observations are weighted by number of student credit hours multiplied by the inverse of the probability of being
included in the sample (estimated at the institution-year level). Costs are in 2015 dollars.

37

Figure 2. Average Instructional Cost by Field

Notes: Sample includes public and private institutions participating in the Delaware Cost Study between 2013-2015.
Only departments in the 20 fields listed in Table A1 are included. A small number of observations with missing or
outlier data are excluded. Program-level observations are weighted by number of student credit hours multiplied by
the inverse of the probability of being included in the sample (estimated at the institution-year level). Costs are in
2015 dollars.

38

Figure 3. Differences in Cost Drivers Across Fields
A. Workload and Class Size

B. Personnel and Non-personnel expenses

Notes: Sample includes public and private institutions participating in the Delaware Cost Study between 2013-2015.
Only departments in the 20 fields listed in Table A1 are included. A small number of observations with missing or
outlier data are excluded. Program-level observations are weighted by number of student credit hours multiplied by
the inverse of the probability of being included in the sample (estimated at the institution-year level). Costs are in
2015 dollars.

39

Figure 4. Baseline Cross-Field Log Cost Differences, relative to English

Notes: Each column reports the difference in log of direct instructional cost per SCH between the reported field and
English, after controlling for institution and year fixed effects. Positive numbers indicate the field is more expensive
than English. Sample includes public and private institutions participating in the Delaware Cost Study between
2013-2015. Only departments in the 20 fields listed in Table A1 are included. A small number of observations with
missing or outlier data are excluded. Program-level observations are weighted by number of student credit hours
multiplied by the inverse of the probability of being included in the sample (estimated at the institution-year level).
Costs are in 2015 dollars.

40

Figure 5. Direct Instructional Expenditure per SCH Over Time, by CIP4 (2000 = 100),
2000-2015

Notes: Sample includes public and private institutions participating in the Delaware Cost Study between 2000-2015.
Only departments in the 20 fields listed in Table A1 are included. A small number of observations with missing or
outlier data are excluded. Program-level observations are weighted by number of student credit hours multiplied by
the inverse of the probability of being included in the sample (estimated at the institution-year level). Trends are
normalized to the year 2000 and net of institution-by-field fixed effects.

41

Figure 6. Average Annual Percentage Change in Costs and Cost Drivers by Field
A. Instructional Expenditures

B. Class Size

42

C. Faculty Salaries

D. Faculty Workload

Notes: Bars represent annualized rate of change between 2000 and 2015. Estimates include program fixed-effects.
Dollar figures expressed in 2015 dollars. Sample includes public and private institutions participating in the
Delaware Cost Study between 2000-2015. Only departments in the 20 fields listed in Table A1 are included. A small
number of observations with missing or outlier data are excluded. Program-level observations are weighted by
number of student credit hours multiplied by the inverse of the probability of being included in the sample
(estimated at the institution-year level).

43

Figure 7. Cross-Sectional Differences in Faculty Mix by Field, 2013-2015

Notes: Bars report proportion of faculty FTE in each rank. Sample includes public and private institutions
participating in the Delaware Cost Study between 2013-2015. A small number of observations with missing or
outlier data are excluded. Program-level observations are weighted by number of student credit hours multiplied by
the inverse of the probability of being included in the sample (estimated at the institution-year level).

44

Figure 8. Trends in Faculty Mix by Field, 2000-2015

Notes: Lines represent proportion of faculty FTE in each rank over time. Sample includes public and private
institutions participating in the Delaware Cost Study between 2000-2015. Only departments in the 20 fields listed in
Table A1 are included. A small number of observations with missing or outlier data are excluded. Program-level
observations are weighted by number of student credit hours multiplied by the inverse of the probability of being
included in the sample (estimated at the institution-year level).

45

Figure 9. Cross-Sectional Differences in Credit-Level Mix by Field, 2013-2015

Notes: Bars report proportion of total student credit hours in each division. Sample includes public and private
institutions participating in the Delaware Cost Study between 2013-2015. A small number of observations with
missing or outlier data are excluded. Program-level observations are weighted by number of student credit hours
multiplied by the inverse of the probability of being included in the sample (estimated at the institution-year level).

46

Figure 10. Trends in Field-Specific Class Size by Course Type and Credit-Level Mix, 20002015
A. Trends in Class Size by Course Type

B. Trends in Credit-Level Mix

Notes: Class size is calculated as 3 credit hours per student, divided by the number of offered course sections. Mix
of credit levels is calculated as the share of total student credit hours in each division. Sample includes public and
private institutions participating in the Delaware Cost Study between 2000-2015. Only departments in the 20 fields
listed in Table A1 are included. A small number of observations with missing or outlier data are excluded. Programlevel observations are weighted by number of student credit hours multiplied by the inverse of the probability of
being included in the sample (estimated at the institution-year level).

47

Figure 11. Share of Total Instruction Delivered Online by Field (2015)
A. Undergraduate

B. Graduate

Notes: Sample includes public and private institutions participating in the Delaware Cost Study in 2015. A small
number of observations with missing or outlier data are excluded. Program-level observations are weighted by
number of student credit hours multiplied by the inverse of the probability of being included in the sample
(estimated at the institution-year level).

48

Table 1. Summary Statistics for Full Sample
Research High

All
Public Institutions
Total Degrees Awarded
BA as Share of Total Degrees
MA as Share of Total Degrees
Prof as Share of Total Degrees
PhD as Share of Total Degrees
Full-Time Equivalents for All Faculty
Fall Semester Total FTE
Fall Semester Instructional FTE
Tenured Faculty Share of Instructional FTE
Student Credit Hours
Fall Semester SCH by All Faculty
Undergrad Share of All SCH
Organized Class Sections
Fall Semester OCS â€“ All
Undergrad Share of OCS
Grad Share of OCS
Expenditures
Direct Instructional Expenditures ($1000) - includes salary,
benefits, and other expenses
Personnel Spending as a Share of Instructional Spending
Analysis Variables
Total Faculty per Student
Average Class Size
Undergraduate Class Size
Graduate Class Size
Instructional Faculty Course Load - All Courses
Instructional Spending per SCH
Instructional Personnel Spending per SCH
Total Spending per SCH
N (institution-program-year)
Weighted by IPW * SCH

Research Moderate

Masters

Baccalaureate

mean
66%
112
84%
14%
0%
2%

sd
47%
171
21%
19%
1%
6%

mean
89%
179
76%
18%
0%
6%

sd
31%
204
19%
16%
1%
8%

mean
53%
160
75%
23%
0%
2%

sd
50%
234
23%
22%
1%
5%

mean
65%
77
87%
13%
0%
0%

sd
48%
129
21%
21%
0%
1%

mean
21%
33
97%
3%
0%
0%

sd
41%
50
10%
10%
1%
1%

32
31
63%

29
28
19%

52
51
61%

34
34
17%

37
37
62%

27
27
16%

22
21
64%

16
16
19%

10
10
66%

9
9
22%

7,712
93%

7,115
13%

12,602
91%

8,442
11%

8,877
89%

5,922
15%

5,535
94%

4,352
15%

2,203
98%

1,826
7%

97
87%
13%

85
0%
17%

143
79%
21%

103
15%
15%

112
81%
19%

80
18%
18%

77
90%
10%

61
17%
17%

40
97%
3%

32
9%
9%

$3,223

$3,503

$5,758

$4,314

$4,053

$3,626

$1,895

$1,459

$810

$656

94%

6%

93%

7%

92%

9%

96%

5%

95%

6%

0.06
27
29
12
3.7
$ 196
$ 186
$ 201
14,218
43%

0.02
10
11
7
0.9
$
88
$
81
$
95

0.07
0.03
32
17
37
24
12
7
3.4
1.1
$ 222 $ 114
$ 207 $ 101
$ 259 $ 202
32,496
100%

0.07
0.03
43
21
53
31
12
7
2.9
1.0
$ 259 $ 140
$ 238 $ 123
$ 354 $ 292
11,513
34%

0.06
0.02
33
14
38
17
14
8
3.1
0.9
$ 236 $ 102
$ 213 $ 88
$ 258 $ 138
2,987
8%

0.08
0.03
22
7
22
7
11
6
3.9
1.1
$ 205 $
94
$ 193 $
82
$ 207 $
95
3,778
15%

Note: Observations are weighted by the inverse of the likelihood that a given institution participates in the Delaware Cost Study multiplied by a measure of the program's size (total fall student credit hours).

49

Table 2. Characteristics of Fields, Ranked by Cost

Log cost
difference
Field
Electrical Engineering
Nursing
Mechanical Engineering
Education
Fine/Studio Arts
Biz Admin/Mgmt/Operations
Computer/Info Sciences
Accounting
Physics
Chemistry
Biology
English
Poli Sci/Government
Economics
History
Comm/Media Studies
Psychology
Sociology
Philosophy
Mathematics

0.74
0.63
0.60
0.31
0.26
0.23
0.21
0.20
0.16
0.11
0.07
ref
-0.02
-0.05
-0.09
-0.11
-0.18
-0.18
-0.22
-0.25

Typically
Median earnings
% of schools Diff funding in
separate school
Tier in NC
years 11-15 ($1000,
with differential TX funding
from Arts &
funding formula
relative to English)
pricing
formula
Sciences?
42.0
Yes
30%
Yes
IV
12.4
Yes
16%
Yes
IV
38.7
Yes
30%
Yes
IV
-5.4
Yes
11%
II, III
-7.7
Yes
8%
Yes
III
11.1
Yes
32%
II
30.3
Varies
8%
Yes
III
17.6
Yes
32%
II
31.9
11%
Yes
III
16.4
11%
Yes
III
8.8
11%
Yes
III
ref
ref
ref
I
15.5
0%
I
32.2
0%
I
6.5
0%
I
7.9
Varies
6%
I
-1.0
0%
I
1.8
0%
I
1.4
0%
I
21.4
0%
I

Sources: Median earnings come from Hershbein and Kearney (2012) analysis of the ACS, expressed relative to median earnings for English ($46,000). Separate
school refers to whether the field is typically housed in a separate school or college from English, which is traditionally in a School of Arts & Science. Funding
formula difference in Texas refers to difference for upper division courses that is different than that for upper division English courses. Negligible differences for
education are ignored. Funding formula in North Carolina splits fields into four tiers. Differential pricing information comes from Nelson (2008) survey of 165
public research universities.

50

Table 3. What Drives Cost Differences by Field? Cross-Sectional Decomposition
Contribution to Difference

Field of Study
Electrical Engineering
Nursing
Mechanical Engineering
Education
Fine/Studio Arts
Biz Admin/Mgmt/Operations
Computer/Info Sciences
Accounting
Physics
Chemistry
Biology
English
Poli Sci/Government
Economics
History
Comm/Media Studies
Psychology
Sociology
Philosophy
Mathematics

Overall
Difference in
Costs
(1)
0.74
0.63
0.60
0.31
0.26
0.23
0.21
0.20
0.16
0.11
0.07

Salary
(2)
0.58
0.38
0.55
0.07
0.11
0.46
0.31
0.59
0.28
0.27
0.23

-0.02
-0.05
-0.09
-0.11
-0.18
-0.18
-0.22
-0.25

0.18
0.38
0.16
0.06
0.20
0.17
0.08
0.15

Workload
(3)
0.05
0.21
0.09
0.02
-0.01
0.06
-0.05
0.01
-0.18
-0.22
-0.17
(base)
0.05
0.07
0.02
-0.06
0.05
0.05
0.00
-0.03

(4)
0.08
-0.01
-0.08
0.17
0.13
-0.31
-0.07
-0.39
0.03
-0.01
-0.04

Other, NonPersonnel
Expenses
(5)
0.03
0.06
0.04
0.05
0.04
0.03
0.02
0.00
0.03
0.07
0.06

-0.26
-0.50
-0.27
-0.13
-0.44
-0.41
-0.30
-0.37

0.01
0.00
0.00
0.02
0.01
0.00
0.00
0.00

Class size

Notes: Difference in cost measured as log difference from English. We hold 3 of the cost drivers at the values for English and allow
the focal cost driver to take the value for the specific field. All models are weighted by total student credit hours*IPW.

51

Table 4. What Drives Differences in Field-Specific Cost Trends? Longitudinal Decomposition
Contribution to % Change in Costs

Field of Study
Electrical Engineering
Nursing
Mechanical Engineering
Education
Fine/Studio Arts
Biz Admin/Mgmt/Operations
Computer/Info Sciences
Accounting
Physics
Chemistry
Biology
English
Poli Sci/Government
Economics
History
Comm/Media Studies
Psychology
Sociology
Philosophy
Mathematics

Annual %
Change in
Costs
(1)
0.52
-1.97
-2.17
1.51
1.55
1.17
0.29
0.83
-0.87
-1.45
-0.56
1.07
1.36
0.96
1.30
1.11
0.32
0.72
0.78
-0.22

Salary

Workload

Class size

Other
Expenses

(2)
0.93
-0.19
-0.14
0.38
0.64
1.06
0.11
1.55
-0.05
0.24
0.03
0.10
0.41
1.43
0.32
0.66
0.45
0.33
0.21
0.44

(3)
0.87
-0.18
0.36
0.76
0.31
0.18
0.00
-0.12
0.24
-0.87
0.18
0.31
0.67
-0.01
0.26
0.79
0.76
0.51
0.51
-0.12

(4)
-1.14
-1.45
-2.36
0.98
0.73
-0.03
0.33
-0.40
-0.84
-0.63
-0.62
0.79
0.31
-0.33
0.78
-0.16
-0.82
0.01
0.19
-0.43

(5)
-0.13
-0.15
-0.02
-0.60
-0.13
-0.04
-0.15
-0.19
-0.22
-0.20
-0.15
-0.12
-0.04
-0.13
-0.06
-0.18
-0.08
-0.13
-0.14
-0.11

Notes: Annual percent change in cost measured between 2000 and 2015, inclusive of program fixed effects. We calculate annual
percent change for each cost driver and normalize to annual change in instructional costs to estimate contribution of individual
drivers. All calculations are weighted by total student credit hours*IPW.

52

Table 5. Average vs. Marginal Cost, by Field

Field
Electrical Engineering
Nursing
Mechanical Engineering
Education
Physics
Accounting
Fine/Studio Arts
Biz Admin/Mgmt/Operations
Chemistry
Computer/Info Sciences
Poli Sci/Government
Biology
Economics
English
History
Philosophy
Psychology
Comm/Media Studies
Sociology
Mathematics

Average
Cost
(1)
410
364
342
307
283
277
276
256
241
240
231
225
221
201
196
190
184
180
176
167

Marginal Cost
No program Program
FE
FE
(2)
(3)
414
228
295
118
365
49
260
221
367
21
253
170
228
107
322
188
268
-72
295
5
173
116
184
42
226
113
184
88
166
84
180
64
160
27
186
172
142
76
171
54

Marginal Cost (Program FE)
Has graduate No graduate
education
education
(4)
(5)
234
152
117
86
39
73
224
18
-5
104
169
114
112
107
191
70
-115
115
5
171
112
103
25
93
111
73
88
101
84
81
65
47
18
114
161
184
75
80
55
52

Notes: All regressions are weighted by total student credit hours*IPW and include year fixed effects. Sample includes 32,496 programyears. Average cost corresponds to the constant from a field-specific regression of direct instructional expenditure per student credit hour
on a constant and year fixed effects. Marginal cost corresponds to the coefficient on student credit hours from a field-specific regression
of direct instructional expenditure on a constant, the number of student credit hours, year fixed effects, and program fixed effects (for (3)
to (5)).

53

Table 6. Summary Statistics for Online Instruction Sample
No Online
Enrollment
mean
sd
Public Institutions
Total Degrees Awarded
BA as Share of Total Degrees
MA as Share of Total Degrees
Prof as Share of Total Degrees
PhD as Share of Total Degrees
Full-Time Equivalents for All Faculty
Fall Semester Total FTE
Fall Semester Instructional FTE
Tenured Faculty Share of Instructional FTE
Student Credit Hours
Fall Semester SCH by All Faculty
Undergrad Share of All SCH
Total Online Credit Share
UG Online Credit Share in 2015
GR Online Credit Share in 2015
Organized Class Sections
Fall Semester OCS â€“ All
Expenditures
Direct Instructional Expenditures ($1000) - includes salary,
benefits, and other expenses
Personnel Spending as a Share of Instructional Spending
Analysis Variables
Total Faculty per Student
Estimated Class Size
Instructional Faculty Course Load - All Courses
Instructional Spending per SCH
Instructional Personnel Spending per SCH
Total Spending per SCH
N (institution-program-year)
Weighted by IPW * SCH

1st Quartile Online
Enrollment
mean
sd

2nd Quartile
Online Enrollment
mean
sd

3rd Quartile
Online Enrollment
mean
sd

4th Quartile
Online Enrollment
mean
sd

55%
94
88%
10%
0%
2%

50%
128
19%
17%
0%
5%

77%
136
79%
17%
0%
4%

42%
122
20%
19%
0%
7%

79%
135
80%
18%
0%
2%

41%
148
22%
22%
0%
4%

84%
136
82%
16%
0%
2%

37%
156
17%
16%
0%
5%

88%
290
79%
19%
0%
1%

33%
392
24%
22%
3%
3%

24
24
64%

21
20
17%

47
46
55%

33
32
18%

37
36
58%

28
27
15%

38
38
55%

23
23
16%

44
44
52%

43
43
19%

6,421
95%
0.00
0.00
0.00

7,051
9%
0.00
0.00
0.00

12,104
92%
0.01
0.01
0.04

9,481
12%
0.01
0.01
0.11

9,446
92%
0.04
0.04
0.06

7,293
14%
0.01
0.02
0.13

10,424
94%
0.10
0.09
0.11

7,286
8%
0.02
0.03
0.21

11,580
87%
0.28
0.24
0.33

12,374
17%
0.15
0.15
0.34

76

63

147

111

125

116

120

72

129

116

$2,852

$2,920

$4,933

$4,305

$3,660

$3,026

$3,524

$2,505

$4,410

$5,631

94%

7%

94%

7%

95%

5%

93%

8%

90%

13%

0.07
0.02
34
22
3.4
1.1
$ 239 $
99
$ 225 $
92
$ 277 $ 171
989
48%

0.06
0.02
38
22
3.3
1.0
$ 234 $ 133
$ 218 $ 121
$ 285 $ 236
266
13%

0.06
0.02
32
16
3.5
1.2
$ 218 $ 103
$ 205 $
95
$ 244 $ 167
265
13%

0.06
0.02
32
14
3.3
0.9
$ 201 $ 105
$ 188 $ 100
$ 220 $ 126
266
13%

0.07
0.03
30
19
3.3
0.9
$ 206 $ 114
$ 186 $ 105
$ 222 $ 132
265
13%

Note: Observations are weighted by the inverse of the likelihood that a given institution participates in the Delaware Cost Study multipled by a measure of the program's size (i.e., total fall student credit hours).

54

Table 7. Online Courses and Instructional Costs
Outcome = Log instructional cost per student credit hour
Independent variable
A. Presence of Online Instruction
Any online credits in 2015
Any online UG credits in 2015

(1)
-0.0354
(0.0349)

Any online GR credits in 2015

(2)

-0.0502~
(0.0278)
-0.0128
(0.0229)

B. Intensity of Online Instruction
Online as a share of total credits 2015

(3)
-0.0182
(0.0343)

-0.290*
(0.133)

Online share of undergraduate credits 2015
Online share of graduate credits 2015
By Quartile (ref: no online credits)
1st quartile of online credits

(4)

(5)

-0.0413
(0.0264)
0.00780
-0.0312

-0.141
(0.120)
-0.0806
(0.0890)
-0.0255
(0.0399)
-0.0463
(0.0417)
-0.00834
(0.0295)
-0.0918~
(0.0508)

2nd quartile of online credits
3rd quartile of online credits
4th quartile of online credits
1st quartile of undergraduate online credits
2nd quartile of undergraduate online credits
3rd quartile of undergraduate online credits
4th quartile of undergraduate online credits
1st quartile of graduate online credits
2nd quartile of graduate online credits
3rd quartile of graduate online credits
4th quartile of graduate online credits

Observations
R-squared

2,037
0.662

2,037
0.652

2,037
0.664

(6)

2,037
0.653

2,037
0.664

-0.0498
(0.0317)
-0.0461
(0.0386)
-0.00270
(0.0328)
-0.0839*
(0.0389)
-0.0205
(0.0356)
0.00399
(0.0381)
-0.0256
(0.0598)
-0.0559
(0.0528)
2,037
0.665

Notes: All models include institution fixed effects, field fixed effects, and a lagged measure of the outcome variable. Specifically, the lagged measure is
the log of the average instructional cost per student credit hour by program data from 2000-2005. When such data are missing, we include an indicator
variable to maintain the full sample. Standard errors clustered on institution appear in parentheses and all models are weighted by total student credit
hours*IPW . ***p<.001; **p<.01; *p<.05; ~p<0.1

55

Appendix A. Additional Figures and Tables
Appendix Figure A1. Data Collection Template for Delaware Cost Study

APPENDIX - 1

Appendix Figure A2. Cross-Field Cost Differences, by Institution Type
A. Research Institutions

B. Comprehensive Institutions

Notes: Each column reports the difference in log of direct instructional cost per SCH between the reported field and
English, after controlling for institution and year fixed effects. Positive numbers indicate the field is more expensive
than English. Sample includes public and private institutions participating in the Delaware Cost Study between
2013-2015. Only departments in the 20 fields listed in Table A1 are included. A small number of observations with
missing or outlier data are excluded. Program-level observations are weighted by number of student credit hours
multiplied by the inverse of the probability of being included in the sample (estimated at the institution-year level).
Costs are expressed in 2015 dollars.

APPENDIX - 2

Appendix Figure A3. Cross-Field Cost Differences, by Institutional Selectivity

Notes: Each column reports the difference in log of direct instructional cost per SCH between the reported field and
English, after controlling for institution and year fixed effects. Positive numbers indicate the field is more expensive
than English. Sample includes public and private institutions participating in the Delaware Cost Study between
2013-2015. Only departments in the 20 fields listed in Table A1 are included. A small number of observations with
missing or outlier data are excluded. Program-level observations are weighted by number of student credit hours
multiplied by the inverse of the probability of being included in the sample (estimated at the institution-year level).
Costs are expressed in 2015 dollars.

APPENDIX - 3

Appendix Figure A4. Class Size Trends Over Time, by CIP4 (2000 = 100), 2000-2015

Notes: Class size is measured by the number of student credit hours (SCH) per organized class section (OCS).
Sample includes public and private institutions participating in the Delaware Cost Study between 2000-2015. Only
departments in the 20 fields listed in Table A1 are included. A small number of observations with missing or outlier
data are excluded. Program-level observations are weighted by number of student credit hours multiplied by the
inverse of the probability of being included in the sample (estimated at the institution-year level). Trends are
normalized to the year 2000 and net of institution-by-field fixed effects.

APPENDIX - 4

Appendix Figure A5. Faculty Salary Trends Over Time, by CIP4 (2000 = 100), 2000-2015

Notes: Faculty salary is measured by total faculty personnel expenditures per FTE. Sample includes public and
private institutions participating in the Delaware Cost Study between 2000-2015. Only departments in the 20 fields
listed in Table A1 are included. A small number of observations with missing or outlier data are excluded. Programlevel observations are weighted by number of student credit hours multiplied by the inverse of the probability of
being included in the sample (estimated at the institution-year level). Trends are normalized to the year 2000 and net
of institution-by-field fixed effects.

APPENDIX - 5

Appendix Figure A6. Teaching Load Trends Over Time, by CIP4 (2000 = 100). 2000-2015

Notes: Teaching load is measured by the number of course sections taught by FTE. Sample includes public and
private institutions participating in the Delaware Cost Study between 2000-2015. Only departments in the 20 fields
listed in Table A1 are included. A small number of observations with missing or outlier data are excluded. Programlevel observations are weighted by number of student credit hours multiplied by the inverse of the probability of
being included in the sample (estimated at the institution-year level). Trends are normalized to the year 2000 and net
of institution-by-field fixed effects.

APPENDIX - 6

Appendix Figure A7. Non-Personnel Trends Over Time, by CIP4 (2000 = 100). 2000-2015

Notes: Non-personnel expenditures measured as the ratio of direct instructional expenditures to personnel
expenditures. Sample includes public and private institutions participating in the Delaware Cost Study between
2000-2015. Only departments in the 20 fields listed in Table A1 are included. A small number of observations with
missing or outlier data are excluded. Program-level observations are weighted by number of student credit hours
multiplied by the inverse of the probability of being included in the sample (estimated at the institution-year level).
Trends are normalized to the year 2000 and net of institution-by-field fixed effects.

APPENDIX - 7

Appendix Table A1. List of Participating Institutions
Note: Over 700 institutions have participated in the study. Below we only list the 148 institutions that participated in the study
for at least 8 years between 1998 and 2015, though our analysis includes all institutions. Parentheses indicate the number of
years that the institution participated over this period.
Appalachian State University (NC) (19)
Arizona State University (AZ) (13)
Auburn University - Montgomery (AL) (14)
Austin Peay State University (TN) (12)
Baylor University (TX) (16)
Belmont University (TN) (14)
Bowling Green State University (OH) (16)
California State University - San Marcos (CA) (10)
Catholic University of America (DC) (9)
Central Connecticut State University (CT) (14)
Central Michigan University (MI) (17)
Clarkson University (NY) (11)
Clemson University (SC) (18)
Cleveland State University (OH) (11)
College of Charleston (SC) (13)
College of Notre Dame of Maryland (MD) (8)
College of St. Elizabeth (NJ) (9)
College of St. Scholastica (MN) (10)
Columbia College, SC (SC) (9)
Delaware Valley College (PA) (8)
DePaul University (IL) (15)
Drew University (NJ) (11)
East Carolina University (NC) (19)
East Tennessee State University (TN) (10)
Eastern Washington University (WA) (8)
Edinboro University of Pennsylvania (PA) (9)
Elizabeth City State University (NC) (18)
Fayetteville State University (NC) (16)
Ferrum College (VA) (9)
Florida International University (FL) (16)
Florida State University (FL) (15)
Gannon University (PA) (9)
Geneva College (PA) (11)
Georgia Institute of Technology (GA) (8)
Georgia Southern University (GA) (8)
Georgia State University (GA) (11)
Gonzaga University (WA) (13)
Goshen College (IN) (12)
Grand Valley State University (MI) (13)
Hartwick College (NY) (11)
Indiana State University (IN) (11)
Indiana University - South Bend (IN) (12)
Iowa State University (IA) (10)
Ithaca College (NY) (12)
James Madison University (VA) (15)

Seattle University (WA) (8)
Shepherd University (WV) (10)
Slippery Rock University (PA) (15)
South Dakota State University (SD) (10)
Southeastern Louisiana University (LA) (14)
Southern Univ and A&M College - Baton Rouge (LA) (8)
Stonehill College (MA) (8)
SUNY - Stony Brook (NY) (9)
SUNY - University at Buffalo (NY) (12)
Tennessee Technological University (TN) (18)
Union University (TN) (15)
University of Alabama - Birmingham (AL) (9)
University of Alabama - Huntsville (AL) (11)
University of Alabama - Tuscaloosa (AL) (15)
University of Arizona (AZ) (14)
University of Arkansas - Fayetteville (AR) (13)
University of Central Florida (FL) (13)
University of Colorado at Boulder (CO) (11)
University of Colorado at Colorado Springs (CO) (11)
University of Connecticut (CT) (16)
University of Delaware (DE) (17)
University of Houston (TX) (11)
University of Idaho (ID) (14)
University of Kansas (KS) (18)
University of Maine (ME) (11)
University of Mary Washington (VA) (8)
University of Massachusetts - Amherst (MA) (16)
University of Massachusetts - Dartmouth (MA) (11)
University of Memphis (TN) (11)
University of Minnesota - Morris (MN) (8)
University of Mississippi (MS) (15)
University of Missouri - Columbia (MO) (16)
University of Missouri - Kansas City (MO) (16)
University of Missouri - St. Louis (MO) (19)
University of Montevallo (AL) (9)
University of Nebraska - Lincoln (NE) (12)
University of Nebraska at Kearney (NE) (11)
University of Nebraska at Omaha (NE) (11)
University of New Hampshire (NH) (14)
University of North Carolina - Asheville (NC) (15)
University of North Carolina - Chapel Hill (NC) (14)
University of North Carolina - Charlotte (NC) (14)
University of North Carolina - Greensboro (NC) (15)
University of North Carolina - Pembroke (NC) (14)
University of North Carolina - Wilmington (NC) (10)
APPENDIX - 8

John Carroll University (OH) (8)
Kansas State University (KS) (10)
Kent State University (OH) (14)
Lander University (SC) (9)
Louisiana State University (LA) (15)
Loyola University of Chicago (IL) (8)
Lynchburg College (VA) (12)
McMurry University (TX) (8)
Mercer University (GA) (11)
Middle Tennessee State University (TN) (9)
Mississippi State University (MS) (18)
Missouri State University (MO) (11)
Missouri University of Science and Technology (MO) (10)
Montana State University-Billings (MT) (15)
Montana State University-Bozeman (MT) (15)
North Carolina A&T State University (NC) (16)
North Carolina Central University (NC) (18)
North Carolina State University (NC) (15)
Northeastern University (MA) (13)
Northern Arizona University (AZ) (15)
Northwestern State University of Louisiana (LA) (12)
Oakland University (MI) (18)
Ohio Northern University (OH) (8)
Oklahoma State University (OK) (9)
Radford University (VA) (11)
Ramapo College of New Jersey (NJ) (11)
Rowan University (NJ) (12)
Saint Francis University (PA) (10)
Schreiner University (TX) (11)

University of North Dakota (ND) (9)
University of Northern Iowa (IA) (16)
University of Notre Dame (IN) (8)
University of Oregon (OR) (14)
University of Rhode Island (RI) (8)
University of South Carolina - Columbia (SC) (17)
University of South Carolina - Upstate (SC) (9)
University of South Florida (FL) (11)
University of Southern Mississippi (MS) (10)
University of Tennessee - Chattanooga (TN) (12)
University of Tennessee - Knoxville (TN) (16)
University of Tennessee - Martin (TN) (13)
University of Texas at Austin (TX) (8)
University of Toledo (OH) (8)
University of Utah (UT) (19)
University of Vermont (VT) (11)
University of Virginia - Charlottesville (VA) (10)
University of West Florida (FL) (12)
University of West Georgia (GA) (11)
University of Wisconsin - Madison (WI) (10)
Virginia Polytechnic Inst. & State Univ. (VA) (14)
Washington State University (WA) (8)
West Virginia University (WV) (18)
Western Carolina University (NC) (19)
Wichita State University (KS) (14)
Wilkes University (PA) (14)
Winston-Salem State University (NC) (18)
Wright State University (OH) (11)
Youngstown State University (OH) (9)

APPENDIX - 9

Appendix Table A2. Fields of Study in Sample, by Four-Digit CIP Classification
CIP4 Code
0901
1101
1301
1410
1419
2301
2601
2701
3801
4005
4008
4201
4506
4510
4511
5007
5138
5202
5203
5401

Title
Communication and Media Studies
Computer and Information Sciences, General
Education, General
Electrical, Electronics and Communications Engineering
Mechanical Engineering
English Language and Literature, General
Biology, General
Mathematics
Philosophy
Chemistry
Physics
Psychology, General
Economics
Political Science and Government
Sociology
Fine and Studio Arts
Registered Nursing, Nursing Administration, Nursing Research and Clinical Nursing
Business Administration, Management and Operations
Accounting and Related Services
History

APPENDIX - 10

Short title
Comm/Media Studies
Computer/Info Sciences
Education
Electrical Engineering
Mechanical Engineering
English
Biology
Mathematics
Philosophy
Chemistry
Physics
Psychology
Economics
Poli Sci/Government
Sociology
Fine/Studio Arts
Nursing
Biz Admin/Mgmt/Operations
Accounting
History

Appendix Table A3. Summary Statistics for Pooled Cross-Sectional Sample, 2013-2015
All
Public Institutions
Total Degrees Awarded
BA as Share of Total Degrees
MA as Share of Total Degrees
Prof as Share of Total Degrees
PhD as Share of Total Degrees
Full-Time Equivalents for All Faculty
Fall Semester Total FTE
Fall Semester Instructional FTE
Tenured Faculty Share of Instructional FTE
Student Credit Hours
Fall Semester SCH by All Faculty
Undergrad Share of All SCH
Organized Class Sections
Fall Semester OCS â€“ All
Undergrad Share of OCS
Grad Share of OCS
Expenditures
Direct Instructional Expenditures ($1000) - includes salary,
benefits, and other expenses
Personnel Spending as a Share of Instructional Spending
Analysis Variables
Total Faculty per Student
Estimated Class Size
Undergraduate Class Size
Graduate Class Size
Instructional Faculty Course Load including
Labs/Discussions/Recitations
Instructional Spending per SCH
Instructional Personnel Spending per SCH
Total Spending per SCH
N (institution-program-year)
Weighted by IPW * SCH

Research Moderate

Research - High

Masters

Baccalaureate

mean
64%
132
84%
14%
0%
2%

sd
48%
197
20%
19%
1%
6%

mean
91%
207
77%
17%
0%
6%

sd
28%
229
18%
15%
1%
8%

mean
37%
216
78%
21%
0%
1%

sd
48%
317
22%
21%
1%
3%

mean
62%
77
88%
12%
0%
0%

sd
48%
92
21%
20%
1%
2%

mean
21%
31
97%
3%
0%
0%

sd
40%
65
12%
11%
1%
1%

33
33
61%

28
28
18%

54
52
58%

33
32
17%

36
36
59%

24
24
16%

22
22
62%

16
16
18%

9
9
66%

9
9
24%

8,323
93%

7,898
13%

14,035
91%

9,664
11%

8,430
89%

5,316
15%

5,481
94%

4,274
14%

1,869
98%

1,846
9%

102
86%
14%

87
17%
17%

152
79%
21%

106
15%
15%

112
82%
18%

70
19%
19%

78
91%
9%

59
17%
17%

34
98%
2%

30
10%
10%

$3,443

$3,625

$5,921

$4,483

$4,261

$3,515

$1,992

$1,453

$672

$670

94%

7%

92%

8%

94%

5%

96%

5%

95%

6%

0.07
33
38
12

0.03
19
26
7

0.06
45
56
12

0.03
23
33
7

0.07
32
37
14

0.02
15
19
7

0.07
27
28
12

0.02
10
12
7

0.08
21
22
10

0.03
7
8
6

3.4

1.0

2.9

1.1

3.2

0.9

3.6

0.9

4.0

1.1

$
$
$

225 $
211 $
257 $
7,245
100%

111 $
101 $
181 $

246 $
227 $
325 $
2,425
34%

138 $
125 $
258 $

251 $
235 $
277 $
673
12%

106 $
94 $
149 $

209 $
199 $
213 $
3,428
43%

90 $
84 $
94 $

195 $
184 $
195 $
719
11%

Note: Observations are weighted by the inverse of the likelihood that a given institution participates in the Delaware Cost Study multiplied by a measure of the program's size ( total fall student credit hours).

APPENDIX - 11

82
74
82

Appendix Table A4. Approximation of the Accounting Identify

DIE/Personnel
Personnel/FTE (salaries)
Faculty FTE/Class sections (workload)
Class sections/SCH (class size)
Observations
R-squared
Fixed effects

Outcome = Log Instructional costs per SCH
(1)
(2)
0.944***
0.931***
(0.039)
(0.039)
0.927***
0.939***
(0.014)
(0.006)
0.898***
0.909***
(0.015)
(0.006)
0.928***
0.941***
(0.009)
(0.004)
7,191
32,422
0.971
0.970
Institution
Program

Notes: Column 1 reports results for cross-section (2013-2015); column 2 reports results for full panel (2000-2015). All
independent variables are entered as logs. Robust standard errors are clustered at the institution (column 1) or program
(column 2) level. All models are weighted by total student credit hours*IPW. ***p<.001; **p<.01; *p<.05; ~p<0.1

APPENDIX - 12

Appendix B. Detailed Data Overview
In this appendix, we provide more information about the National Study of Instructional
Cost and Productivity, explore coverage of the data, and detail our weighting approach.
I.

The Delaware Cost Study Data
We use data from the National Study of Instructional Cost and Productivity from the
University of Delaware (referred to as the Delaware Cost Study). Since 1998, the study has
collected program-level data from over 700 four-year public and private non-profit higher
education institutions. We provide a list of participating institutions in Appendix Table A1.
Each year, institutions report degrees awarded, fall semester instructional activity, and
annual expenditure data for each of their academic programs, which are identified at the fourdigit Classification of Instructional Program (CIP) code level. Degrees awarded are reported in
rolling three-year averages by level: bachelors, masterâ€™s, professional, and doctorate. Measures
of fall term instructional activity include total faculty FTEs, total student credit hours, and total
organized class sections. These measures are disaggregated in various ways. Faculty FTEs are
categorized by rank: tenured and tenure eligible, other regular, supplemental, credit-bearing
teaching assistants, and non-credit-bearing teaching assistants. 1 Student credit hours and
organized class sections are broken out by course level (undergraduate lower division,
undergraduate upper division, and graduate) and are also associated with a specific faculty rank.
Finally, institutions report total direct expenditures for instruction, research, and public service
and total undergraduate and graduate student credit hours for the entire academic year. We
construct quarterly rescaled measures for some of our analyses to preserve consistency in
numerators and denominators when possible.

The distinction between â€œother regularâ€ and â€œsupplementalâ€ faculty relates to length of contracts and the sources
of funds. Other regular faculty have a recurring relationship with the institution and have a recurring appointment.
Supplemental faculty are paid from temporary funds for non-recurring teaching assignments. Detailed definitions
for each survey item are available online at https://ire.udel.edu/definitions/.

1

APPENDIX - 13

The institutional research department at the University of Delaware uses these data to
develop national cost benchmarks and peer analyses for participating institutions, which may use
the information for their own budgeting and strategic planning.
II.

Coverage of U.S. Institutions
Because participation in the Delaware Cost Study (DCS) is optional, we analyzed the

representativeness of our sample against the universe of public and private non-profit institutions
that are US-based and that report information to the Integrated Postsecondary Education Data
System (IPEDS). 2 The final universe includes 1,786 institutions and 34.9 million degrees. While
the majority of schools were private institutions (67.4%), public schools produced the most
graduates (64.2% of all degrees).
Using the IPEDS Completions survey, we analyze how nationally representative the DCS
is at the two-digit CIP code level. Over one-third of all institutions reported to the Delaware Cost
Study at least once (34.2%), accounting for 60.1 percent of all the degrees awarded between
1998 and 2015. However, institutions do not participate every year and some fail to report data
for all of their departments (CIP2). When participating, institutions report most their departments
to the study (82%) and these departments represent more than 90 percent of the degrees they
award (92.3%). Taking these gaps into account, we estimate that our sample represents 23.3
percent of all degrees awarded over this period. Coverage is significantly higher for public
degrees than for private degrees (32.2% versus 7.8%, respectively), and among public
institutions, those rated very competitive or competitive by Barronâ€™s have the highest
participation rates. The relationship between selectivity and participation reverses among private

We also dropped institutions identified by Carnegie Classification as tribal, special focus (mostly private faithrelated institutions, medical and health professional schools, and schools of art, music, and design), and unclassified
(mostly unaccredited schools). A small number of international and special focus institutions report to the Delaware
Cost Study (n=15), but we decided to drop these institutions because the sample of similar institutions would be too
small to draw meaningful comparisons. We also dropped a small number of institution-year-CIP2 records that were
observed in the Delaware Cost Study, but not in the Completions survey (<1%).

2

APPENDIX - 14

colleges: most competitive and highly competitive institutions are less likely to participate,
compared to noncompetitive private colleges (35.4 and 17.6 percentage points, respectively).
Larger public institutions, as well as private institutions with higher tuition prices, are more
likely to participate. Finally, expenditures per FTE and state and local appropriations are
uncorrelated with participation.
Because certain types of institutions are overrepresented in the data, we construct analytic
weights that improve the representativeness of the sample. For each institution, we estimate a
probability of participating in the DCS for each year. We weight observations by the inverse of
the probability of participation, giving more weight to programs that were underrepresented that
year. Since our analyses are at the CIP-4 level, we then interact that inverse probability weight
with the total student credit hours for each institution at each CIP-4, giving more weight to larger
programs. We model DCS participation by institution (i) and year (t) using the variables
considered in the sampling frame of the National Postsecondary Student Aid Study (NPSAS).
The NPSAS is a survey that is nationally representative at the institution and student level, and
provided a reasonable guide to choosing observable characteristics for inclusion in our model of
DCS participation. We estimate the following model:
Pr(ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒ)ğ‘–ğ‘–ğ‘–ğ‘– = Î¦(ğ›¼ğ›¼ + ğ›½ğ›½ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ‘–ğ‘– + ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ›¾ğ‘™ğ‘™ğ‘–ğ‘–ğ‘–ğ‘– + ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ›¿ğ‘‘ğ‘‘ğ‘–ğ‘–ğ‘–ğ‘– + ğœ€ğœ€ğ‘–ğ‘–ğ‘–ğ‘– )

(1)

Where ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ‘–ğ‘– is a set of indicator variables for unique combinations of institutional control

(public or private), Carnegie Classification (research, masterâ€™s, or baccalaureate), Barronâ€™s

selectivity rating (most/highly competitive, very competitive, or other) 3, and region. We also
include 12-month unduplicated enrollment and expenditures per FTE. The model includes

For masterâ€™s and baccalaureate institutions, we created two selectivity groups (instead of three) to achieve large
enough cell sizes. Specifically, we grouped together very, most, and highly competitive institutions to compare
against â€œotherâ€ institutions. â€œOtherâ€ includes less competitive, noncompetitive, and special institutions. To deal with
missingness in the Barronâ€™s and Carnegie Classification variables (as described in the Coverage section), institutions
missing Barronâ€™s data are grouped with â€œotherâ€ institutions and institutions missing Carnegie Classification data are
grouped with baccalaureate institutions.

3

APPENDIX - 15

polynomials of the latter two variables (quadratic and cubic) and interactions of all terms with
institutional control (public or private). Appendix Table B1 reports some descriptive statistics for
the unweighted and weighted samples across all years, and Appendix Table B2 reports the
average weight given to each observation in an institutional category for select years.

APPENDIX - 16

Appendix Table B1. Descriptive Statistics for IPEDS, DCS Sample, and Weighted Sampl

Institution Group
Research Univ, Most/High Comp, Public
Research Univ, Most/High Comp, Private
Research Univ, Very Comp, Public
Research Univ, Very Comp, Private
Research Univ, Comp, Public
Research Univ, Comp, Private
Masters Univ, Most/High/Very Comp, Publ
Masters Univ, Most/High/Very Comp, Priv
Masters Univ, Comp, Public
Masters Univ, Comp, Private
Bach Univ, Most/High/Very Comp, Public
Bach Univ, Most/High/Very Comp, Private
Bach Univ, Comp, Public
Bach Univ, Comp, Private
Region
New England
MidEast
Great Lakes
Plains
Southeast
Southwest
Rocky Mountains
Far West
Enrollment (12-month, unduplicated)
Total Expenses per FTE

IPEDS

Sample
(unweighted)

1.8%
3.4%
3.1%
1.2%
5.8%
2.1%
2.4%
5.1%
14.5%
16.7%
0.7%
11.3%
7.3%
24.4%

$

9.1%
19.9%
15.6%
10.3%
24.8%
7.4%
3.1%
9.8%
7,939
21,035 $

Sample
(weighted)

5.1%
2.4%
13.4%
2.0%
20.9%
0.8%
5.9%
5.0%
20.3%
10.0%
0.9%
3.4%
4.0%
5.9%
6.2%
17.4%
14.2%
11.6%
34.9%
6.2%
5.0%
4.5%
15,704
20,857 $

1.9%
3.2%
3.1%
1.5%
6.2%
1.5%
2.4%
5.6%
13.8%
17.5%
0.4%
13.8%
5.5%
23.7%
6.2%
23.9%
18.8%
9.3%
20.4%
9.5%
2.6%
9.4%
7,496
20,438

Notes: Table reports summary statistics for IPEDS Completions survey. The second and third columns report
the same characteristics for the DCS sample and then characteristics weighted by the inverse probability of
participating in the DCS times student credit hours.

APPENDIX - 17

Appendix Table B2. Average Weights by Institution Group for Select Years

Research Univ, Most/High Comp, Public
Research Univ, Most/High Comp, Private
Research Univ, Very Comp, Public
Research Univ, Very Comp, Private
Research Univ, Comp, Public
Research Univ, Comp, Private
Masters Univ, Most/High/Very Comp, Public
Masters Univ, Most/High/Very Comp, Private
Masters Univ, Comp, Public
Masters Univ, Comp, Private
Bach Univ, Most/High/Very Comp, Public
Bach Univ, Most/High/Very Comp, Private
Bach Univ, Comp, Public
Bach Univ, Comp, Private

2000
1.8
5.2
2.1
27.2
2.2
9.5
6.2
12.9
5.3
56.2
4.9
75.5
13.2
287.2

IPW only
2007
3.9
3.2
1.6
5.5
2.1
13.8
2.5
5.3
6.2
12.7
2.5
40.7
9.6
22.3

2015
3.0
30.0
2.1
10.1
2.2
5.6
2.2
12.2
5.2
12.8
5.6
40.7
14.7
50.2

IPW*SCH
2000
2007
2015
12,878
25,899
26,086
22,301
15,148 179,245
11,490
10,129
17,665
65,122
29,362
46,887
10,098
11,263
11,533
24,515
48,616
18,869
24,405
11,383
9,721
23,373
9,604
25,260
17,938
20,829
18,480
65,282
18,642
21,067
7,611
4,210
10,172
52,800
55,812
49,108
17,354
23,774
51,844
393,495
25,366
37,073

Notes: Average weights by institution group indicate the analytic weight given to observations in each category under two weighting
schemes: the inverse of the probability of participating in the DCS, and the IPW interacted with number of student credit hours for each
CIP4.

APPENDIX - 18

Appendix C. Details on Measurement of Costs and Cost Drivers
Our goal is to understand the relative importance of each cost driver in generating acrossfield cost differences. We begin with the accounting identity:
ğ·ğ·ğ·ğ·ğ·ğ·
ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†
ğ·ğ·ğ·ğ·ğ·ğ·
ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒ
#ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹
=ï¿½
ï¿½ï¿½
ï¿½ï¿½
ï¿½ï¿½
ï¿½
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†
ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒ #ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†

This would exactly hold for each program if we were able to measure all variables on the
same time scale. However, some variables are measured in only the fall semester while others
are measured for the full year. Whenever possible, we construct our drivers so that the numerator
and denominator of each driver are measured for the same period. Given our units for the
dependent variable, we want to convert all cost drivers to those units using appropriate scaling
factors, Î³ğ‘‘ğ‘‘ , for cost driver element d. Then, letting f denote that the variable was measured for

the fall semester only and y the full year, we can rewrite our accounting identity as:

Î³ #ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ‘“ğ‘“
Î³ ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘“ğ‘“
ğ·ğ·ğ·ğ·ğ·ğ·ğ‘¦ğ‘¦
ğ·ğ·ğ·ğ·ğ·ğ·ğ‘¦ğ‘¦
ğ‘ƒğ‘ƒğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ‘¦ğ‘¦
=ï¿½
ï¿½ï¿½
ï¿½ï¿½ 1
ï¿½ï¿½ 2
ï¿½
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘¦ğ‘¦
ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘¦ğ‘¦
Î³1 #ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ‘“ğ‘“ Î³2 ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶ ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘“ğ‘“
Î³3 ğ‘†ğ‘†ğ¶ğ¶ğ¶ğ¶ğ‘“ğ‘“

If fall and spring semesters were identical across all drivers, then the Î³ğ‘‘ğ‘‘ would not enter

the equation. However, these semesters may be different and the difference may vary by

program. If fall-to-spring differences were identical across programs, then the constant from
equation (2) would be non-zero, but the coefficients on the drivers would be one.
Taking logs, we have:
ğ‘™ğ‘™ğ‘™ğ‘™ ï¿½

ğ·ğ·ğ·ğ·ğ·ğ·ğ‘¦ğ‘¦

ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘¦ğ‘¦

ï¿½ = ln ï¿½

ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘“ğ‘“
ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘$ğ‘¦ğ‘¦
ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“
ï¿½ + ln ï¿½
ï¿½ + ln ï¿½
ï¿½ + ln ï¿½
ï¿½ âˆ’ Î³3
ğ‘ğ‘ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’$ğ‘¦ğ‘¦
ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“ğ‘“
ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘“ğ‘“
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘“ğ‘“
ğ·ğ·ğ·ğ·ğ·ğ·ğ‘¦ğ‘¦

ğ‘ğ‘ğ‘ğ‘

ğ‘ğ‘ğ‘ğ‘

ğ‘ğ‘ğ‘ğ‘

ğ‘ğ‘ğ‘ğ‘

If we knew Î³3 , we could exactly fit this equation. Instead, we appropriate them using field (i.e.,

CIP-4) and institution fixed effects. Some fields may spend relatively more in one semester (i.e.,
fall or spring) than the other â€“ for example, many math and science fields may have higher costs
in the fall than in the spring due to tight course sequences. Since we cannot directly observe such

APPENDIX - 19

field-specific scaling factors, our model is an approximation of the underlying accounting
identity and the coefficients on the four cost drivers in equation (2) will not exactly equal one.
Indeed, the magnitude of the bias is a function of (a) the inverse covariance matrix of the log cost
drivers and the proxies; (b) the covariance of Î³3 with each logged cost driver and the proxies; (c)
and the magnitudes of Î³3 . We use institution and field fixed effects to control for such

unobserved differences and find that the coefficients are very close to one (see Appendix Table
A4).

APPENDIX - 20

