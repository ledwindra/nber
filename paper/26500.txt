NBER WORKING PAPER SERIES

ORIGINS OF THE OPIOID CRISIS AND ITS ENDURING IMPACTS
Abby E. Alpert
William N. Evans
Ethan M.J. Lieber
David Powell
Working Paper 26500
http://www.nber.org/papers/w26500

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2019

We thank Mireille Jacobson, Rosalie Liccardo Pacula, Harold Pollack and seminar and
conference participants at Illinois, Notre Dame, RAND, Temple, Tulane, USC, Health and Labor
Market Effects of Public Policy at UCSB, iHEA, Midwest Health Economics Conference, and
NBER Summer Institute Crime Meeting for helpful feedback. For help obtaining some of the
unsealed court documents, we also thank Caitlin Esch and Marketplace, Judge Booker T.
Stephens of West Virginia, Nicholas Weilhammer in the Office of Public Records for the Office
of the Attorney General of Florida, and La Dona Jensen in the Office of the Attorney General of
Washington. Powell gratefully acknowledges financial support from NIDA (1R21DA041653 and
P50DA046351). Evans gratefully acknowledges financial support from the Institute for
Scholarship in the Liberal Arts at the University of Notre Dame. The views expressed herein are
those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2019 by Abby E. Alpert, William N. Evans, Ethan M.J. Lieber, and David Powell. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.

Origins of the Opioid Crisis and Its Enduring Impacts
Abby E. Alpert, William N. Evans, Ethan M.J. Lieber, and David Powell
NBER Working Paper No. 26500
November 2019
JEL No. I12,I18
ABSTRACT
Overdose deaths involving opioids have increased dramatically since the mid-1990s, leading to
the worst drug overdose epidemic in U.S. history, but there is limited empirical evidence on the
initial causes. In this paper, we examine the role of the 1996 introduction and marketing of
OxyContin as a potential leading cause of the opioid crisis. We leverage cross-state variation in
exposure to OxyContin’s introduction due to a state policy that substantially limited OxyContin’s
early entry and marketing in select states. Recently-unsealed court documents involving Purdue
Pharma show that state-based triplicate prescription programs posed a major obstacle to sales of
OxyContin and suggest that less marketing was targeted to states with these programs. We find
that OxyContin distribution was about 50% lower in “triplicate states” in the years after the
launch. While triplicate states had higher rates of overdose deaths prior to 1996, this relationship
flipped shortly after the launch and triplicate states saw substantially slower growth in overdose
deaths, continuing even twenty years after OxyContin's introduction. Our results show that the
introduction and marketing of OxyContin explain a substantial share of overdose deaths over the
last two decades.
Abby E. Alpert
The Wharton School
University of Pennsylvania
3641 Locust Walk
Philadelphia, PA 19104
and NBER
alpertab@wharton.upenn.edu

Ethan M.J. Lieber
Department of Economics
University of Notre Dame
3049 Jenkins Nanovic Halls
Notre Dame, IN 46556
and NBER
elieber@nd.edu

William N. Evans
Keough-Hesburgh Professor of Economics
Department of Economics
University of Notre Dame
3111 Jenkins Nanovic Halls
Notre Dame, IN 46556-7000
and NBER
wevans1@nd.edu

David Powell
RAND Corporation
1776 Main Street
P.O. Box 2138
Santa Monica, CA 90407
David_Powell@rand.org

1

Introduction
Over the last two decades, there has been a staggering increase in mortality from drug

overdoses in the U.S. Between 1983 and 2017, the drug overdose death rate increased by a
factor of eight with a noticeable inflection point in the mid-1990s, as shown in Figure 1.
Overdose deaths involving opioids are the primary driver of this increase, accounting for 75% of
the growth and, by 2017, two-thirds of all drug overdose deaths were related to opioids. Opioid
overdoses claimed the lives of 47,600 people in 2017 (Scholl et al., 2019) and almost 400,000
since 1999,1 about the same number of U.S. soldiers that died in World War II (DeBruyne,
2018). This massive rise in opioid deaths has contributed to the longest sustained decline in life
expectancy since 1915 (Dyer, 2018).
There are many hypotheses about the initial causes of the opioid crisis. Case and Deaton
(2015, 2017) suggest that demand factors played an important role as worsening cultural and
economic conditions may have sparked a surge in “deaths of despair”: suicides, alcohol-related
mortality, and drug overdoses. Alternative hypotheses, though not mutually exclusive, consider
the role of supply factors such as the dramatic increase in opioid access driven by changing
physician attitudes and practice patterns. Beginning in the 1990s, doctors began to treat pain
more aggressively with opioids (Jones et al., 2018), following widespread concerns that pain had
been “under-treated” (Morgan, 1985; WHO, 1986; Melzack, 1990). The American Pain Society
launched an influential campaign declaring pain as the “fifth vital sign” and, in response, the
Joint Commission on Accreditation of Healthcare Organizations (JCAHO) revised its guidelines
in 2001, requiring that doctors assess pain along with other vitals during medical visits (Phillips,
2000). In addition, the introduction and aggressive marketing of Purdue Pharma’s OxyContin in
1996 has also been implicated as a central cause of the opioid crisis (Van Zee, 2009; Kolodny et
al., 2015; Quinones, 2015).2
Despite the discussion of these hypotheses throughout the literature, there is surprisingly
little empirical evidence on any individual factor’s importance. Existing studies have considered
underlying factors that may be driving opioid misuse such as economic conditions and labor
demand shocks (Hollingsworth et al., 2017; Ruhm, 2019; Betz and Jones, 2018; Charles et al.,
1

https://www.cdc.gov/drugoverdose/epidemic/index.html
As of June 2019, 48 states and 500 cities have filed lawsuits against Purdue Pharma for its deceptive marketing
practices claiming that they have contributed to the opioid crisis (https://www.vanityfair.com/news/2019/06/davidsackler-pleads-his-case-on-the-opioid-epidemic).
2

1

2019; Pierce and Schott, forthcoming). Other studies have tested whether increased access to
opioids, through prescriptions to family members (Khan et al., 2019) or encounters with
physicians with high propensities to prescribe opioids (Barnett et al., 2017), predict long-term
use of opioids. This research is relevant to understanding the role of supply versus demand
factors in driving the ongoing opioid crisis; however, none of these studies evaluate the causes of
the initial rise in opioid deaths in the mid-1990s. Moreover, these studies often find effects
which are too small to explain the massive growth in opioid deaths.
In this paper, we provide the first quasi-experimental evidence on the initial causes of the
opioid crisis. We examine the role of the introduction and marketing of OxyContin as a potential
leading cause, exploring its impacts on drug overdose deaths over the two decades since its
launch. OxyContin is a prescription opioid pain reliever whose active ingredient, oxycodone,
has been in use in the U.S. since the early 1900s. OxyContin’s key technological innovation was
its sustained-release formulation that utilizes a high concentration of the active ingredient to
provide 12 hours of continuous pain relief. However, the timed-release aspect of OxyContin is
contingent on taking the pill whole. Crushing or dissolving the pill allowed users to access the
high dosage of oxycodone all at once, producing an intense high. OxyContin quickly became
one of the leading drugs of abuse in the U.S. (Cicero et al., 2005) and concerns about widespread
abuse of this drug were being reported by 2000 (GAO, 2003).
Since OxyContin was launched nationwide, it is difficult to isolate its effects from other
concurrent changes to prescribing practice patterns, opioid availability, and demand. We address
this issue by exploiting geographic variation in exposure to OxyContin’s introduction due to a
previously unexplored state policy that substantially limited OxyContin’s entry and marketing in
select states. Information on the importance of this state policy was obtained from recentlyunsealed court documents that we collected from multiple settled lawsuits and investigations
involving Purdue Pharma. These documents provide an unprecedented look at the
manufacturer’s internal marketing strategies around the introduction of OxyContin. They reveal
that Purdue Pharma viewed state-based “triplicate prescription programs,” an unusually stringent
early prescription drug monitoring program that required the use of special state-issued
prescription forms for Schedule II opioids, as a significant barrier to prescribing OxyContin. As
a result, they suggested that the company should not target marketing to states with these
programs because of the lower expected returns.
2

Discussions of triplicate programs appear frequently throughout the internal documents
concerning the launch and promotion of OxyContin. Purdue Pharma’s focus group research
found that these programs had a chilling effect on the prescribing of Schedule II opioids such as
oxycodone. Doctors in triplicate states rarely used Schedule II opioids because “writing
triplicate prescriptions was more trouble than others” and providers “did not want to give the
Government an excuse to monitor their activities” (Groups Plus, 1995). They found that “the
doctors in the triplicate states were not enthusiastic about the product [OxyContin] at all, with
only a couple indicating they would ever use it, and then in very infrequent situations” (Groups
Plus, 1995). The research concluded that doctors in these states were unlikely to adopt
OxyContin, leading to the recommendation that “the product [OxyContin] should only be
positioned to physicians in non-triplicate states” (Groups Plus, 1995).
Using a difference-in-differences framework, we take advantage of the variation in
OxyContin supply induced by the triplicate policies to study drug overdose trends in states with
triplicate programs (henceforth “triplicate states”) relative to states without these programs
(“non-triplicate states”). We consider triplicate states less exposed to OxyContin’s introduction
for two reasons: first, there appears to have been less initial marketing targeted to these states
and, second, the triplicate programs themselves were a barrier to prescribing OxyContin.
Together, these two forces provide a source of exogenous geographic variation in exposure to
OxyContin’s introduction. We will also aim to disentangle these two mechanisms.
Consistent with our hypothesis, we find that OxyContin distribution was more than twice
as high in non-triplicate states in the years after the launch. When we compare this to
hydrocodone distribution, another commonly abused opioid that was not subject to triplicate
policies because it was largely classified as a Schedule III drug, we find almost identical levels
of hydrocodone distribution across triplicate and non-triplicate states. Additionally, we find
much higher rates of OxyContin misuse in non-triplicate states relative to triplicate states, but
similar rates of misuse of all other pain relievers. These results are consistent with differences in
overdose death rates being primarily attributable to OxyContin.
Given this variation in OxyContin exposure due to triplicate policies, we turn to
estimating OxyContin’s impacts on the time path of drug overdose deaths over the short and long
run. Figure 2 shows the raw trends in drug overdose deaths per 100,000 people comparing
triplicate and non-triplicate states. Prior to OxyContin’s introduction, the two groups of states
3

were trending similarly, although non-triplicate states had lower rates of drug overdose deaths.
This relationship flipped shortly after OxyContin’s launch as drug overdose deaths increased
much more rapidly in non-triplicate states than in triplicate states, a trend that continued even
twenty years later. We find that this differential growth is driven almost entirely by drug
overdoses involving prescription opioids until 2010. After 2010, when the original formulation
of OxyContin was removed from the market and replaced with an abuse-deterrent version, large
differences in overdose deaths involving heroin and synthetic opioids emerged across triplicate
and non-triplicate states. This is consistent with prior evidence that areas with early exposure to
OxyContin experienced differential transitions to illicit opioids post-reformulation as people
substituted from OxyContin to heroin (Alpert et al., 2018; Evans et al., 2019). Overall, our
estimates imply that non-triplicate states would have had an average of 36% fewer drug overdose
deaths and 44% fewer opioid overdose deaths in 1996-2017 if they had been triplicate states.
Although there were many changes to the opioid environment over this time period, our
results are not explained by adoption of other opioid policies, misuse of other opioid drugs, or
economic shocks targeted differentially to non-triplicate states. We find that differences in stateand county-level characteristics such as urbanicity and population size between triplicate and
non-triplicate states also do not explain differential overdose mortality growth. In permutation
tests, we show that it is statistically rare to observe overdose growth differences between
triplicate and non-triplicate states of a similar magnitude when we randomly assign triplicate
status to other combinations of states, suggesting that triplicate states experienced uniquely low
growth.
This research contributes to our understanding of what initially sparked the opioid crisis.
We demonstrate that the introduction and marketing of OxyContin explains a substantial share of
overdose deaths over the last two decades. Although triplicate programs were discontinued in
the years after OxyContin's launch, their initial deterrence of OxyContin promotion and adoption
had long-term effects on overdose deaths in these states, dramatically decreasing overdose death
rates even today. The triplicate states we study, spread throughout the U.S., currently have some
of the lowest overdose death rates in the country. Our work, therefore, also speaks to the
substantial geographic variation in overdose deaths. Within small regions of the country, there
are widely-varying drug overdose death rates and this variation is difficult to explain based on
demographics, economic conditions, and current policies. Our results suggest the importance of
4

initial conditions—particularly the policy landscape at the beginning of the epidemic—in
inducing variation in overdose rates that persists even decades later.
Finally, our results demonstrate the potentially harmful consequences of pharmaceutical
promotion for controlled substances. Our analysis of mechanisms finds that while triplicate
programs themselves may have independently discouraged OxyContin adoption, the evidence
also suggests that the relative lack of marketing in these states played an important independent
role in reducing exposure to the drug. When triplicate states are compared to other states with
similar initial prescribing practices or even states which had eliminated their triplicate programs
just prior to 1996, they still have uniquely low growth in overdose deaths. We discuss how this
evidence is consistent with marketing practices playing a central role in explaining trends in drug
overdose deaths.
The remainder of the paper proceeds as follows. We provide additional background in
Section 2. Section 3 introduces the data while Section 4 discusses the empirical strategy. We
present the results in Section 5. In Section 6, we discuss the mechanisms for our results,
isolating the effects of triplicate programs and marketing. Section 7 concludes.
2

Background

2.1

OxyContin’s Launch and Promotional Activities
OxyContin is a long-acting formulation of oxycodone, a morphine-like drug, produced by

Purdue Pharma. It is classified as a Schedule II controlled substance given its high potential for
abuse. The Food and Drug Administration (FDA) approved OxyContin in 1995 and the drug
was introduced to the market in January 1996. OxyContin entered the market as Purdue
Pharma’s patent for MS Contin—a long-acting form of morphine used for treating late-stage
cancer pain—was set to expire. Purdue Pharma aimed to replace MS Contin with OxyContin as
well as to expand into additional markets: patients in the earlier stages of cancer (positioning
OxyContin as “the opioid to start with and to stay with”) and the much larger market for noncancer pain. Prior to OxyContin’s launch, patients with non-cancer pain would have been
typically treated (if at all) with non-opioid painkillers (e.g., Tylenol) or short-acting combination

5

products that combine much smaller doses of either oxycodone or hydrocodone with
acetaminophen (e.g., Percocet, Tylox, Vicodin).3
OxyContin’s initial marketing strategy centered on claims that the drug had low abuse
potential and was safer than other opioid drugs, which would later prove to be false. The
original FDA-approved product label for OxyContin included the statement that “delayed
absorption as provided by OxyContin tablets, is believed to reduce the abuse liability of a drug.”
Additionally, marketing materials relied heavily on a 100-word letter to the editor in the New
England Journal of Medicine (Porter and Jick, 1980) to support the claim that the risk of
addiction among opioid users was “much less than one percent.” Some marketing materials
failed to include any information about its addiction potential (Van Zee, 2009). These
misinformed or misleading claims were important for convincing doctors who had been cautious
about prescribing opioids to switch from less potent painkillers to OxyContin for treating noncancer pain. To achieve growth for non-cancer chronic pain—a previously untapped market for
opioids—Purdue Pharma also heavily targeted marketing to primary care physicians, although
this raised concerns given their limited experience and training in pain management. From 1997
to 2002, OxyContin prescriptions increased at a faster rate for non-cancer pain than for cancer
pain (GAO, 2003).
In 2001, the FDA product label for OxyContin was revised to remove the incorrect
statements about its abuse liability and to add a black box safety warning. However, the
indication was also changed from covering patients “where use of an opioid analgesic is
appropriate for more than a few days” to those who require “a continuous around-the-clock
analgesic for an extended period of time.” This may have further expanded the market for
chronic pain. Internal documents show that Purdue Pharma believed that the new label “created
enormous opportunities” and “in effect, the FDA has expanded the indication for OxyContin.”
They further noted that “this broad labeling is likely to never again be available for an opioid
seeking FDA approval” (Purdue Pharma Budget Plan, 2002, p. 47).
Purdue Pharma’s advertising campaign was unusually aggressive for a prescription drug
and unprecedented for an opioid. The promotional budget between 1996 and 2001 for
3

The dosage of the combination oxycodone and hydrocodone products is limited by the maximum safe dosage of
acetaminophen (which can cause liver failure at high dosages). In contrast, OxyContin is made of pure oxycodone,
so there is no ceiling dosage (GAO, 2003). This purity allows OxyContin to be used at much higher dosages to treat
more severe levels of pain than the combination products.

6

OxyContin was six- to twelve-times more than they had spent on advertising for MS Contin
during its first six years on the market, and what Janssen Pharmaceutical Products spent for the
promotion of Duragesic, one of OxyContin’s competitors (GAO, 2003). They employed an
enormous sales force to promote the drug to doctors which doubled in size between 1996 and
2002.4 Additionally, Purdue Pharma promoted OxyContin heavily through a variety of other
channels such as sponsoring pain-related educational programs and conferences, 5 distributing
coupons and gifts,6 and advertising in medical journals. These marketing efforts contributed to
OxyContin’s blockbuster success. Revenue from OxyContin sales skyrocketed from $48 million
in 1996 to $1.1 billion in 2000 (Van Zee, 2009) and $3.1 billion in 2010 (IMS, 2011).
Despite the marketing claims, concerns about widespread abuse of OxyContin grew as
quickly as its sales. Users of the drug quickly learned that they could defeat OxyContin’s
controlled-release delivery system by crushing or dissolving the pill, allowing them to access the
entire store of oxycodone all at once. Some of the earliest reports of OxyContin abuse and
diversion occurred in Appalachia and rural areas. However, by 2001, the DEA Administrator
reported that abuse had also moved to urban areas, especially Boston and Philadelphia. 7
OxyContin became one of the leading prescription drugs of abuse in the U.S., surpassing all
other forms of oxycodone and hydrocodone combined (Cicero et al., 2005). The aggressive
marketing of OxyContin eventually concerned local and state governments, leading to a series of
lawsuits. In 2007, Purdue Pharma agreed to pay over $600 million in fines because of
misleading advertising that minimized the risks of OxyContin.

4

In 1996, Purdue Pharma employed 318 sales representatives themselves and contracted with an additional 300
through a co-promotion deal with Abbott Laboratories. This number increased to 1,067 in 2002 (GAO, 2003).
5
Purdue Pharma funded more than 20,000 pain-related educational programs from 1996-2002 (GAO, 2003). They
also provided significant amounts of funding to several medical societies such as the American Pain Society and
JCAHO (https://ag.ny.gov/sites/default/files/oag_opioid_lawsuit.pdf), organizations which recommended more
aggressive diagnosis and treatment of pain.
6
As noted in the GAO report (2003), “according to DEA, Purdue’s use of branded promotional items to market
OxyContin was unprecedented among schedule II opioids, and was an indicator of Purdue’s aggressive and
inappropriate marketing of OxyContin.”
7
See DEA Administrator Asa Hutchinson’s Testimony on December 11, 2001:
https://www.govinfo.gov/content/pkg/CHRG-107hhrg77734/html/CHRG-107hhrg77734.htm, last accessed
November 4, 2019.

7

2.2

Identifying Variation in Exposure to OxyContin
This study exploits previously unexplored geographic variation in OxyContin’s initial

marketing and supply. To understand how OxyContin was marketed, we made Freedom of
Information Act (FOIA) requests to obtain recently unsealed documents in Florida, 8
Washington,9 and West Virginia10 from settled court cases and investigations involving Purdue
Pharma in these states. These documents provide a rare look at a pharmaceutical firm’s detailed
marketing strategies. Among these documents, we obtained the official launch plan for
OxyContin, the focus group research conducted prior to the launch, and annual itemized budgets
for OxyContin from 1996-2002. Examples of these records are shown in Appendix Figure A1.
We combined this information with court filings available online from Massachusetts. 11
These documents reveal that Purdue Pharma would have difficulty penetrating markets
that had enacted a state policy known as a “triplicate prescription program” and suggested that it
would target less marketing to these states.
2.2.1. What are Triplicate Prescription Programs?
Triplicate prescription programs were among the earliest prescription drug monitoring
programs enacted to reduce the diversion and misuse of controlled substances. Triplicate
programs mandated that doctors use state-issued triplicate prescription forms when prescribing
Schedule II controlled substances (which includes many opioids). The physician was required to
maintain one copy of the triplicate form for their records. The patient was given two copies to
give to the pharmacy; the pharmacy kept one and sent the third copy to the state drug monitoring
agency. The state agency maintained a database from these forms to monitor and investigate
prescribing irregularities and diversion.
Triplicate programs were adopted decades before OxyContin’s launch. California
adopted the first triplicate program in 1939 (Joranson et al., 2002) due to concerns of the
growing diversion of opium-based pharmaceuticals (Simoni-Wastila and Toler, n.d.). California
was also the last state in the country with a triplicate program, ending the program in 2004. They,
8

In November 2001, the Florida Attorney General opened an investigation into Purdue Pharma’s marketing tactics.
The investigation was closed about a year later. Purdue Pharma offered the state of Florida a settlement of $2
million for development of an electronic prescription monitoring program.
9
State of Washington v. Purdue Pharma L.P. et al. (filed September 2017)
10
State of West Virginia v. Purdue Pharma et al. (filed June 11, 2001, settled in 2004)
11
https://www.documentcloud.org/documents/5715954-Massachusetts-AGO-Amended-Complaint-2019-0131.html, last accessed July 22, 2019

8

like other states, adopted an electronic system to work in tandem with the triplicate prescription
forms before eventually eliminating the triplicate requirement. Several other states followed
California’s model including Idaho, Illinois, Indiana, Michigan, New York, and Texas, 12
adopting triplicate programs between 1961 through 1988.13 Indiana and Michigan ended their
triplicate programs shortly before OxyContin’s launch.14
The academic literature on triplicate programs has found that these programs led to
dramatic reductions in the prescribing of drugs subject to the policy (Simoni-Wastila et al., 2004;
Hartzema et al., 1992; Weintraub et al., 1991; Sigler et al., 1984). 15 There are two main reasons
why triplicate programs could deter OxyContin prescribing. First, physicians in triplicate states
were concerned about government oversight of their prescribing behavior (Berina et al., 1985).
As Purdue Pharma observed in their focus group research: “The triplicate laws seem to have a
dramatic effect on the product usage behavior of the physicians….The doctors did not want to
provide the Government with any ammunition to question their medical protocols relative to pain
management. The mere thought of the government questioning their judgement created a high
level of anxiety” (Groups Plus, 1995, p. 24). Although electronic monitoring programs also
involved government oversight, relative to electronic systems, “It was felt that paper forms,
tangible reminders of such scrutiny when handled by the prescribing physician and dispensing
pharmacist, would have a greater effect on reduced prescribing and dispensing than would an

12

In addition, Washington adopted a triplicate program but due to limited funding, triplicate forms were required
only for physicians disciplined for drug-related violations (Simoni-Wastila and Tompkins, 2001; Fishman et al.,
2004).
13
Idaho adopted its program in 1967, switching to a duplicate program in 1997 (Joranson et al., 2002; Fishman et
al., 2004, see also: https://legislature.idaho.gov/wp-content/uploads/OPE/Reports/r9901.pdf). Illinois enacted its
triplicate program in 1961, ending in 2000 when it was replaced by an electronic system (see footnote 85 of
https://www.isms.org/opioidplan/). New York enacted a triplicate program in 1972 (Joranson et al., 2002), which
ended in 2001 (NY Bureau of Narcotic Enforcement, personal communication, May 3, 2019). Texas adopted a
triplicate system in 1982 (Sigler, 1984), converting to an electronic system in 1999 (see
https://www.pharmacy.texas.gov/DPS.asp).
14
Indiana's triplicate program began in 1987, but it was replaced by an electronic and single-copy program in 1994
(Joranson et al., 2002). Michigan enacted a triplicate program in 1988, but it also ended in 1994 (Joranson et al.,
2002, see also: https://www.legislature.mi.gov/documents/2001-2002/billanalysis/Senate/htm/2001-SFA-0660E.htm).
15
One study of an academic teaching hospital in Texas found that there was an immediate 60.4% reduction in
prescribing of Schedule II drugs for outpatients after the state adopted its triplicate program in 1982; prescribing of
non-Schedule II drugs increased over the same time period (Sigler et al, 1984). Another study examined New
York’s unique inclusion of benzodiazepines (a schedule IV drug) in the triplicate program starting in 1989. The
study found that prescribing of these drugs declined in New York (by 30-60% depending on the insurance type),
while prescribing remained stable in a set of control states (Weintraub et al., 1991).

9

electronic system that remained largely invisible to health care practitioners” (Simoni-Wastila
and Toler, n.d.).
Second, the hassle costs to the physician of triplicate programs were especially large.
According to Purdue Pharma’s research: “Writing triplicate prescriptions was more trouble than
others, due to the details of the forms and the various people that need to be copied to them. To
the extent that they [physicians] can avoid this extra effort, they will try to follow alternative
protocols” (Groups Plus, 1995, p. 24). Placing this burden specifically on the prescriber rather
than on the pharmacist suggests a key reason for why triplicate programs are found in the
literature to have substantial effects on prescriptions while some modern electronic prescription
drug monitoring programs (particularly, non-mandate PDMPs) have been shown to have more
muted effects (Buchmueller and Carey, 2018). Also, triplicate programs required the prescriber
to store their copy of the prescription for a number of years, an additional cost unique to
triplicate programs. In contrast, other paper-based systems did not require physicians to keep a
copy, reducing the hassle cost and salience of those programs.
2.2.2. Purdue Pharma’s Views on Triplicate States
“Triplicate states” are mentioned repeatedly in Purdue Pharma’s internal documents, but
there is never any mention of other existing state policies such as electronic, duplicate, or singlecopy monitoring programs. Their concern that the triplicate programs were an especially
important barrier to OxyContin prescribing is founded on the information it obtained when
researching the market for OxyContin. Purdue Pharma's focus group research emphasized that
physicians in triplicate states would be less willing to prescribe OxyContin because of its
Schedule II designation.16 “The PCPs [primary care physicians] and surgeons in the nontriplicate state (New Jersey) indicated a very high likelihood of using OxyContin for selective
treatment of non-cancer related pain, and the rheumatologists in Connecticut also felt it had a
place in their practice” (Groups Plus, 1995, p. 39). In contrast, the response from physicians in
triplicate states was quite negative. The same report notes that “The physicians in the triplicate

16

There were two separate focus group analyses. In one, physicians from New Jersey, Connecticut, and Texas were
surveyed (Groups Plus, 1995). In the other, physicians attending the American College of Osteopathic Family
Physicians meeting in Orlando were surveyed (Strategic Business Research, 1996). In the results from this latter
research study, physicians are divided into whether they practiced in triplicate or non-triplicate states and most of
the results are stratified by triplicate status, suggesting the importance of this designation to Purdue Pharma.

10

state did not respond positively to the drug, since it is a Class II narcotic which would require
triplicate prescriptions. Therefore, only a few would ever use the product, and for them it would
be on a very infrequent basis” (Groups Plus, 1995, p. 36). The lack of enthusiasm for OxyContin
by doctors in triplicate states is repeated dozens of times throughout these documents. 17
Based on this research, Purdue Pharma’s launch plan acknowledges that “these
regulations create a barrier when positioning OxyContin” (Purdue Pharma OxyContin Launch
Plan, 1995, p. 4). Additionally, the focus group study concludes that while “there seems to be a
definite opportunity for OxyContin as a medication for treatment of severe non-cancer pain
among doctors in non-triplicate states. More work might have to be done to determine if the
product is viable in the triplicate states; however, the preliminary evidence is not encouraging”
(Groups Plus, 1995, p. 4). Since there would be lower returns to promoting OxyContin in
triplicate states, they recommended that “the product [OxyContin] should only be positioned to
physicians in non-triplicate states” (Groups Plus, 1995, p. 55). Further they noted that “our
research suggests the absolute number of prescriptions they [physicians in triplicate states] would
write each year is very small, and probably would not be sufficient to justify any separate
marketing effort” (Groups Plus, 1995, p. 49).
Purdue Pharma appears to have also lobbied for the repeal of triplicate state policies. For
example, the 1999 budget plan includes a $750,000 line-item to fund a “Program to impact the
regulatory environment for opioid prescribing in triplicate states” (Purdue Pharma Budget Plan,

17

In a few other representative examples from the focus group research: “The impact of the triplicate laws was
particularly significant when one realizes that the most common narcotic used by the surgeons and PCP's in New
Jersey [a non-triplicate state] was Percocet/Percodan, whereas in Texas [a triplicate state], this was a product/class
of drugs prescribed by most doctors less than five times per year...if at all” (Groups Plus, 1996, p. 24) and “the
overall reactions to OxyContin were very mixed. The most positive were the PCP's and surgeons in New Jersey [a
non-triplicate state] who viewed this to be an important innovation relative to the treatment of noncancer pain, and
definitely would incorporate the product into their medication protocols.” (Groups Plus, 1995, p. 36) “The doctors in
the triplicate states were not enthusiastic about the product at all, with only a couple indicating they would ever use
it, and then in very infrequent situations.” (Groups Plus, 1995, p. 39). Also, “Targeting will be a key element to the
success of OxyContin. Identification of the family practitioners treating hospice patients as well as patients with
moderately severe to severe injury/trauma and post-op pain will lead to faster adoption and use. Unfortunately,
physicians in triplicate states are going to be harder to convince since they use less CII [schedule II] medications”
(Strategic Business Research, 1996, p. 7) and “These triplicate state physicians are far less likely to use an
oxycodone product to treat this level of pain. Only 14% mentioned the use of oxycodone products for moderately
severe pain, whereas almost three times this number of the non-triplicate physicians (37%) utilize this class of
opioid.” (Strategic Business Research, 1996, p. 13)

11

1999, pg. 68). In the following year’s budget plan, they again included $750,000 to fund a
“Regulatory Environment Program,” which may have also been related to triplicate programs. 18
The statements made in these internal documents suggest that Purdue Pharma viewed
triplicate programs as a substantial barrier to OxyContin prescribing and would initially target
less marketing to triplicate states because of the lower expected returns. While we do not have
data that breaks down Purdue Pharma’s initial marketing spending by state to confirm this
directly, we will show that the triplicate states had among the lowest OxyContin adoption rates in
the country.
2.2.3. Classifying Triplicate States at the Time of OxyContin’s Launch
Our empirical strategy compares OxyContin prescribing and fatal overdose trends in
triplicate and non-triplicate states. We consider the non-triplicate states to be more exposed to
OxyContin’s introduction because the barriers to prescribing were lower and there appears to
have been was more initial marketing targeted to these states. We define “triplicate states” as the
five states with active triplicate programs at the time of OxyContin’s launch in 1996: California,
Idaho, Illinois, New York, and Texas.19 All other states are classified as “non-triplicate states.”
The enactment and end years of the triplicate programs are listed in the top row of Table 1. The
triplicate programs were adopted decades before the opioid epidemic began, not in response to
the increased prescription opioid use and abuse that began in the mid-1990s.

18

There are also earlier mentions of triplicate programs beginning with the launch plan in 1996 which earmarked
$200,000 to fund a “Triplicate States Congress” and the 1998 budget plan earmarked $150,000 for “Opioid
Prescribing Regulatory Guidelines CME program,” which is described as providing “physicians with an
understanding of improving trends in regulation of opioid use in non-cancer pain and how to effectively prescribe
within those regulations.”
19
In one instance in the internal documents that we reviewed, there is an incorrect reference to “nine triplicate
states” when discussing retail pharmacy distribution. Since this statement was factually inaccurate at the time it was
written, we cannot be certain which set of states were being referenced. It is possible that they were referring to the
nine states with paper-based monitoring systems (including duplicate and single-copy programs) at that time, since
this statement appears in the context of pharmacists’ concerns about the “voluminous paperwork” required in these
states, which would be a consideration with any paper-based system. To the degree that Purdue Pharma was also
concerned about other paper-based programs (although these were never mentioned elsewhere in the documents)
and also marketed less in these states, our results will be attenuated. That said, triplicate programs and the burdens
for the physician (not the pharmacy) are always the focus of the discussion in the internal documents we obtained.
These documents specifically mention the hassle of triplicate programs to prescribers due to the “various people that
need to be copied to them” which would apply only to states with active triplicate programs and not other paperbased programs. This suggests that the discussions of the triplicate states referenced throughout this paper were
referring to triplicate programs specifically and not a broader set of paper-based programs.

12

Although triplicate programs were eventually discontinued, our coding of triplicate states
is irrespective of later changes. We hold each state’s initial triplicate status in 1996 as fixed over
the entire study period. It is unclear whether and how quickly Purdue Pharma responded to
states transitioning away from triplicate programs. 20 Idaho's program ended in 1997, shortly
after OxyContin's introduction. The other triplicate states all ended their programs by 2004,
replacing them with electronic programs. Therefore, our results will speak to the long-run
effects of the initial targeting of Purdue Pharma’s marketing and barriers to prescribing induced
by triplicate status during the launch.
Two other states (Indiana and Michigan) had triplicate programs which were
discontinued in 1994. Purdue Pharma’s primary concerns with the monitoring and hassles
associated with triplicate programs would no longer be present in these states at the time of the
launch in 1996. While we cannot be certain in knowing exactly how Purdue Pharma treated the
former-triplicate states since we do not observe the full marketing strategy, to the extent that they
also received less marketing, our results will be attenuated. We analyze these states separately in
Section 6. Also, it is notable that, with the exception of Idaho, the triplicate states are among the
largest states in the country and also have some of the largest urban centers. In robustness tests,
we will consider the possible role of these distinct characteristics with special attention to
population size and urbanicity.
3

Data
Our analysis uses data from several sources. We use data on drug overdose deaths and

multiple measures of opioid distribution, prescribing, and misuse.
3.1 Mortality Data
We use a restricted-use version of the National Vital Statistics System (NVSS) Multiple
Cause of Death mortality files from 1983 to 2017 that contains state and county of residence
identifiers.21 These data represent a census of deaths in the U.S. We follow the coding used by
the Centers for Disease Control (CDC) to categorize deaths as drug and opiate-related. The
20

In supplementary analyses, we study state responses to triplicate program discontinuation.
We begin in 1983 because the 1981 and 1982 files do not include all deaths. In select states, only half of deaths
were included and they were included twice. This feature is not necessarily problematic for our purposes, but we
chose to start our sample with the 1983 data given that this already provides a lengthy pre-period.
21

13

1983-1998 data use ICD-9 codes to categorize causes of deaths while the 1999-2017 data use
ICD-10 codes.22 The CDC reports that the transition from ICD-9 to ICD-10 resulted in a small
increase in poisoning-related deaths (not necessarily drug poisonings) of 2% (Warner et al.,
2011). Our time fixed effects help account for this transition given that we would not expect
systematically different effects of the coding change across states. We explore this coding
change in Appendix Figure A2 by examining the national trend in drug overdose deaths around
1999. While we observe an increase in the total drug overdose death rate in 1999, it is
comparable to increases in other time periods when there were no coding changes. The 1999
increase is larger for opioid-related overdose deaths but, again, not uniquely large relative to
other annual changes. Notably, the main estimates are not driven by a large differential overdose
increase in 1999, suggesting that the time fixed effects are appropriately accounting for the
switch to ICD-10 codes.
Given concerns over missing opioid designations on death certificates for drug-related
overdoses (e.g., Ruhm, 2018), we favor using a broader measure of total drug overdose deaths
which should be robust to substance-specific classification errors (Venkataramani and
Chatterjee, 2019). However, we also present complementary results for opioid-related overdose
deaths.
We also study disaggregated measures of drug overdose deaths by the type of opioid
when available. Deaths with code T40.1 indicate poisoning by heroin, T40.2 indicate natural and
semisynthetic opioids (e.g., OxyContin), and T40.4 indicate synthetic opioids excluding
methadone (e.g., fentanyl). It is difficult to link deaths for specific drugs across the entire time
period given differences in ICD-9 and ICD-10 codes, so we will only study overdose deaths by
opioid type for 1999-2017 while highlighting the caveat that this analysis does not include the
pre-OxyContin period.

22

For 1983-1998, we define drug poisonings as deaths involving underlying cause of death ICD-9 codes E850E858, E950.0-E950.5, E962.0, or E980.0-E980.5 (see Table 2 of
https://www.cdc.gov/drugoverdose/pdf/pdo_guide_to_icd-9-cm_and_icd-10_codes-a.pdf, last accessed November
29, 2018.). When we study opioid-related overdoses, we will use deaths involving E850.0, E850.1, E850.2, or
N965.0 (Alexander et al., 2018; Green et al., 2017). For the 1999-2017 data, we code deaths as drug overdoses using
the ICD-10 external cause of injury codes X40-X44, X60-64, X85, or Y10-Y14 (Warner et al., 2011). We use drug
identification codes, which provide information about the substances found in the body at death, to specify opioidrelated overdoses: T40.0-T40.4 and T40.6. Linking opioid overdoses across ICD-9 and ICD-10 codes in this manner
is recommended in Table 3 of https://www.cdc.gov/drugoverdose/pdf/pdo_guide_to_icd-9-cm_and_icd-10_codesa.pdf. One exception is our use of T40.6. The inclusion of this code does not change our results as we will show in
the Appendix.

14

3.2 Opioid Distribution, Prescriptions, and Misuse
We use state-level data on the legal supply of opioids from the Drug Enforcement
Agency’s (DEA) Automation of Reports and Consolidated Orders System (ARCOS). The
Controlled Substance Act of 1970 requires all manufacturers and distributors to report their
transactions and deliveries of all Schedules I and II substances as well as a number of Schedule
III-V substances to the Attorney General. ARCOS is the system that monitors and records the
flows of these controlled substances as they move from manufacturers to retail distributors. In
the public data, only active ingredients are reported so we observe the distribution of oxycodone
by state, but not OxyContin specifically. These data are available online for 2000-2017, 23 and
we were able to collect earlier data for 1997-1999 using the WayBack Machine. 24 Because of
this paper's specific interest in OxyContin, we made a FOIA request for OxyContin distribution
specifically and received these data for 2000-2016. 25 We report all ARCOS measures in
morphine equivalent doses, equal to 60 morphine milligram equivalents.
We also study measures of OxyContin prescriptions. It should be noted that prescription
data from the 1990s and early 2000s are scarce at the state level. 26 We use Medicaid State Drug
Utilization Data (SDUD) for 1996-2005, 27 which reports the number of prescriptions of
outpatient drugs paid for by Medicaid agencies by National Drug Code (NDC), quarter, and
state.28 While the Medicaid population is non-representative, prescriptions among this group are
a potentially useful proxy for state prescribing behavior while also representing an important
population disproportionately affected by the opioid crisis (e.g., CDC, 2009; Sharp and Melnik,
2015; Whitmire and Adams, 2010; Fernandes et al., 2015). Opioid Medicaid prescriptions are
highly-correlated with the opioid supply measures in the ARCOS data. Annual Medicaid

23

The data are found here: https://www.deadiversion.usdoj.gov/arcos/retail_drug_summary/, last accessed
November 30, 2018.
24
https://web.archive.org/web/20030220041015/https://www.deadiversion.usdoj.gov/arcos/retail_drug_summary/
25
Our request for pre-2000 OxyContin data was denied; we were told that these years of data are unavailable.
26
Many of the data aggregators that researchers often use to obtain prescription drug claims data (such as IQVIA)
no longer maintain state-specific records for the 1990s or early 2000s.
27
We end the sample in 2005 due to the introduction of Medicare Part D.
28
We select on state-years reporting in all four quarters (over 94% of state-years). Additionally, while a recent
version of SDUD suppresses the number of prescriptions for a given NDC-state-quarter when that number is smaller
than 10, we rely on an earlier version of the data that is unsuppressed.

15

OxyContin prescriptions per 1,000 beneficiaries 29 and per capita OxyContin supply (ARCOS) in
2000—the first year available—have a correlation coefficient of 0.66.
We also use a restricted version of the Medical Panel Expenditure Survey (MEPS) with
state-identifiers, accessed through the AHRQ Data Facility. The MEPS is a nationallyrepresentative survey of households, including medical and pharmaceutical claims. We
constructed per capita OxyContin prescriptions for 1996-2016. 30 Per capita OxyContin
prescriptions in the 2000 MEPS have a cross-sectional correlation with the 2000 ARCOS of
0.53.
Finally, we study self-reported rates of opioid misuse in the past year for both OxyContin
and all other pain relievers (excluding OxyContin) using the National Study of Drug Use and
Health (NSDUH) for 2004-2012.31 The measure of OxyContin misuse is first available in 2004.
The NSDUH is a nationally-representative household survey of individuals ages 12 and older
and is the largest annual survey collecting information on substance use in the U.S. State-level
metrics are publicly reported in two-year waves. 32 Alpert et al. (2018) showed a strong
correlation between OxyContin misuse and supply measures in the ARCOS data.
3.3 Summary Statistics
In Table 1, we present summary statistics for 1991-1995, representing the pre-OxyContin
period, separately for each triplicate state as well as aggregated means by triplicate status. As
shown previously, drug overdose death rates are higher on average in the triplicate states before
OxyContin’s introduction, including deaths involving opioids. With the exception of Idaho, each
triplicate state had an opioid-related death rate above the median. Some of these differences can
be explained by disproportionately higher rates of cocaine-related deaths in triplicate states.
When overdoses involving cocaine are eliminated, the differences between triplicate and non-

29

We scaled the number of prescriptions by the number of Medicaid beneficiaries using data from the University of
Kentucky Center for Poverty Research (University of Kentucky Center for Poverty Research, 2018).
30
We identify OxyContin prescriptions in the MEPS using NDC codes matched to First Databank as well as
information in the reported prescription drug name field in the MEPS.
31
The NSDUH uses techniques designed to elicit accurate and honest answers from respondents. As one example,
the respondent is shown cards with the names of different types of pain relievers (including OxyContin) and photos
of the pills. They are asked to identify “which of the pain relievers…have you used when they were not prescribed
for you or that you took only for the experience or feeling they caused?” These methods reduce concerns that the
“OxyContin misuse” measure reflects misuse of other types of oxycodone.
32
For more information on these data, see Section II.A of Alpert et al. (2018).

16

triplicate states shrink. With respect to demographic characteristics, 33 triplicate states on average
have larger populations and a much larger share of the population is Hispanic. The age
distribution and educational attainment are similar across triplicate and non-triplicate states.
4

Empirical Strategy
To estimate the impact of OxyContin’s introduction, we use a difference-in-differences

framework comparing outcomes in non-triplicate states relative to triplicate states before and
after the launch of OxyContin. We rely primarily on event-study models due to their
transparency and because the timing of the effect is of interest. We report the differential change
in overdose death rates for non-triplicate states relative to triplicate states given that nontriplicate states were more “exposed” to the introduction of OxyContin. The event study
specification is:
(1)

𝑦 =𝛼 +𝛾 +∑

𝛽 × 1(Non-Triplicate) × 1(Year = 𝑡) + 𝜀 ,

where y represents annual drug overdose deaths per 100,000 people in state 𝑠 in year 𝑡. This
specification includes state (α ) and year (γ ) fixed effects. 1(Non-Triplicate) is an indicator
based on the initial triplicate status of the state in 1996 and is fixed over the entire time period.
This is interacted with a full set of year fixed effects. We present the estimates of β along with
95% confidence intervals graphically. We normalize the β coefficient to equal zero in 1995, the
year before OxyContin was introduced. Our main results are population-weighted, but we also
show unweighted regression results in the Appendix.
We also present difference-in-differences estimates using more aggregated time intervals
for the purpose of quantifying the event study results. The specification is:
(2)

𝑦 = 𝛼 + 𝛾 + 𝛿 × 1(Non-Triplicate) × 1(1996 ≤ Year ≤ 2000)
+𝛿 × 1(Non-Triplicate) × 1(2001 ≤ Year ≤ 2010)
+𝛿 × 1(Non-Triplicate) × 1(2011 ≤ Year ≤ 2017) + 𝑿 𝜃 + 𝜀 .

33

Demographic and population information are calculated from Current Population Study (CPS) data (Ruggles et
al., 2018) and the Surveillance, Epidemiology, and End Results Program (SEER).

17

The excluded category is 1991-1995 as we limit the sample to 1991-2017 for the
difference-in-differences analyses.34 We estimate three separate “post” effects to permit some
heterogeneity while still providing more aggregated effects. The first post-OxyContin time
period is 1996-2000. This period represents the introduction of OxyContin, the launch of
different dosages, and the initial ramp up of marketing by Purdue Pharma. We also estimate a
separate effect for 2001-2010, corresponding to the “first wave” of the opioid crisis when most
opioid-related deaths are attributed to prescription opioids. Finally, we estimate a separate effect
for 2011-2017, representing the second and third waves of the opioid crisis when deaths from
heroin and illicitly-manufactured fentanyl became more prominent.
Our controls (𝑿 ) include the fraction of the population that is white non-Hispanic, black
non-Hispanic, Hispanic, the fraction ages 25-44, 45-64, 65+, the fraction with a college degree,
and log population.35 We do not include some of the typical controls often included in models of
opioid overdoses, including policy variables (e.g., PDMPs, pill mill laws, etc.) and economic
conditions. A motivation of this paper is to understand the initial conditions of the opioid crisis,
which has potentially affected a wide range of outcomes. We remain agnostic about the breadth
of effects and choose not to control for these types of covariates in our main specification given
that these covariates may also be outcomes. However, we will show that our results are robust to
conditioning on subsequent policy adoption and economic conditions.
In addition, some of our outcome variables are only available after 1996, such as
OxyContin supply. Despite the lack of a pre-period, it will be useful to analyze cross-sectional
differences between triplicate and non-triplicate states. For these select outcomes, we estimate
the non-normalized mean differences in each time period as follows:
(3)

𝑦 = 𝛾 + 𝛿 × 1(Non-Triplicate) × 1(1996 ≤ Year ≤ 2000)
+𝛿 × 1(Non-Triplicate) × 1(2001 ≤ Year ≤ 2010)
+𝛿 × 1(Non-Triplicate) × 1(2011 ≤ Year ≤ 2017) + 𝑿 𝜃 + 𝜀 .

34

For the difference-in-differences specification, we condensed the pre-period to 5-years (from the full 13 years
available) to provide a more meaningful comparison with the post-periods. As can be seen in the event-study
results, the estimates are not sensitive to different choices for the pre-period.
35
In the Appendix, we show robustness tests that interact a set of these covariates with year indicators, permitting
them to have differential effects in each year.

18

We will also show how the trajectories of these outcomes differ between triplicate and nontriplicates more flexibly by interacting the non-triplicate indicator in the above specification with
year fixed effects. We present the coefficients on these interaction terms graphically.
Because we have a small number of (un)treated states, traditional cluster covariance
estimators may produce standard error estimates that are too small (Conley and Taber, 2011).
For this reason, we use a restricted wild cluster bootstrap method at the state level to account for
serial correlation in all models.36 We use a 6-point weight distribution as suggested by Webb
(2014) which provides more reliable inference than the typical 2-point Rademacher weights
when there are few clusters. Webb (2014) points out that using Rademacher weights when there
are a small number of clusters will produce too few unique bootstrap samples and t-statistics to
generate meaningful p-values. In a difference-in-differences framework, a related problem
occurs when there are a very small number of treated or untreated clusters (Brewer et al.,
2018).37 The 6-point distribution improves the reliability of the wild bootstrap in both scenarios.
Given p-values for a range of null hypotheses, we construct and report 95% confidence intervals,
which will not be symmetric using this approach. 38 In the Appendix, we show that traditional
“clustered” standard errors produce tighter confidence intervals than the restricted wild bootstrap
method. We also show that permutation tests produce similar results.
5

Results
Our analysis begins by documenting the large differences in OxyContin exposure across

triplicate and non-triplicate states. We then estimate the impact of these differences on drug
overdose deaths over the short and long run. We also investigate alternative explanations for these
patterns including trends in the distribution and misuse of other opioid drugs, differential policy
adoption, and economic shocks. We explore mechanisms for the long-run mortality effects in the
next section.

36

Specifically, we use a restricted wild bootstrap in which a null hypothesis is imposed and then a 𝑡-statistic is
compared to distribution of placebo 𝑡-statistics (this is method 13 on page 418 of Cameron et al. 2008).
37
In this case, the bootstrapped t-statistics are all within the neighborhood of a finite number of values so there is
limited independent variation.
38
We use the boottest package in Stata (Roodman et al., 2018) to implement this procedure.

19

5.1

Effects of Triplicate Status on OxyContin Exposure
We first show that non-triplicate states were more exposed to the introduction of

OxyContin as measured by OxyContin distribution and prescriptions per capita. The raw trends
for these outcomes are presented in Figure 3 using three different data sources. Panel A presents
trends in the distribution of OxyContin measured in morphine equivalent doses (MEDs) per
capita using ARCOS data. These data represent a virtual census of OxyContin distribution in the
U.S. In 2000, there is over two and a half times more OxyContin distribution per capita in nontriplicate states compared to triplicate states. In the first two columns of Table 2, we present
estimates of equation (3) for this outcome with and without time-varying controls. The
differences in OxyContin distribution across triplicate and non-triplicate states are quantitatively
large and statistically significant in all time periods and these differences persist through 2016.
A limitation of the ARCOS data is that it is only available back to 2000. As
complementary measures of OxyContin exposure, we study two other data sources that enable us
to observe OxyContin prescriptions for earlier years. Panel B of Figure 3 shows trends for
Medicaid OxyContin prescriptions per 1,000 beneficiaries from 1996-2005. Panel C shows
OxyContin prescriptions per 1,000 people using the restricted-access MEPS for 1996-2016,
which is noisier due to its small sample size. In both datasets, we observe much higher rates of
OxyContin prescriptions in non-triplicate states. These differences are apparent as early as 1996
in the Medicaid data and 1997 in MEPS.39 OxyContin prescribing increases rapidly during the
first several years after its launch; however, there is a striking reduction in total OxyContin
prescriptions and distribution in 2005-2006, revealing some important dynamics in early
OxyContin sales and promotion.40 OxyContin prescribing decreases again after Purdue Pharma
39

There are no OxyContin prescriptions in the 1996 MEPS. The 1996 MEPS has the smallest number of
individuals, households, and prescriptions of all the MEPS samples. This reduced size combined with the limited
national exposure to OxyContin in 1996 is consistent with not finding any OxyContin prescriptions in the 1996 data.
40
One possible explanation for this decline (which is apparent in both the ARCOS and MEPS data) is the end of a
copromotion agreement with Abbott Laboratories. Abbott provided at least 300 sales representatives through this
agreement to sell OxyContin (GAO, 2003), initialing doubling Purdue Pharma's sales force, and a company
executive documented in 1997 that 25% of OxyContin prescription were written by “Abbott MD’s.” This
agreement with Abbott ended around the time that we see the dramatic drop in OxyContin distribution
(https://www.statnews.com/2016/09/22/abbott-oxycontin-crusade/, last accessed May 8, 2019). Abbott decided not
to renew this relationship given early reports about OxyContin abuse and the federal government's concerns over
these reports. By 2008, Purdue Pharma began to increase its sales force again (p. 72 in Commonwealth of
Massachusetts, 2018). Additionally, Purdue Pharma was under investigation for 5 years before its 2007 settlement
was reached related to misleading marketing practices
(https://www.judiciary.senate.gov/imo/media/doc/Brownlee%20Testimony%20073107.pdf). This investigation may
have also affected the company’s marketing practices and sales over this time period.

20

released an abuse-deterrent version in 2010. However, non-triplicate states continue to
experience differential exposure to OxyContin throughout these downturns.
Finally, we examine how the initial “adoption” of OxyContin varied across triplicate and
non-triplicate states. Panel A of Appendix Figure A3 uses Medicaid data to show the number of
OxyContin prescriptions per 1,000 beneficiaries in 1996 for states reporting data in 1996. The
triplicate states (highlighted in red) largely cluster near the bottom of the distribution. Four of
the triplicate states (CA, IL, NY, TX) are among the five states with the lowest number of
OxyContin prescriptions per capita in 1996, although Idaho is an exception with higher
prescribing.41 While we cannot report state-specific figures from the restricted-use MEPS, Panel
B uses the first available year of ARCOS data. The pattern is similar in ARCOS with four of the
triplicate states positioned among the lowest seven states in the distribution (Idaho is ranked
14th). These results show that triplicate states initially had some of the lowest rates of OxyContin
adoption in the country.
5.2 Effects of Triplicate Status on Exposure to Other Opioids
We next examine whether there are differences in the use of other prescription opioids
across triplicate and non-triplicate states that could also contribute to differences in overdose
death trends. First, we use the ARCOS data to compare trends in the distribution of oxycodone
versus hydrocodone. Unlike oxycodone which is a Schedule II drug, hydrocodone (e.g., Vicodin)
was classified as a Schedule III drug. 42 Therefore, it would not be subject to triplicate programs
which cover Schedule II drugs. Figure 4 shows trends in the distribution of these opioid drugs
starting in 1997, the earliest year of data available. The trends are presented in morphine
equivalent doses (MEDs) which adjust for the different potency of these drugs. Remarkably, per
capita hydrocodone distribution, which should be unaffected by triplicate programs, is nearly
identical in triplicate and non-triplicate states over the entire 1997-2017 time period. In triplicate
states, oxycodone and hydrocodone distribution are also identical. However, there are large
differences in oxycodone distribution between triplicate and non-triplicate states.

41

This may reflect that Idaho was in the process of replacing its triplicate program at the time. We do not know
whether Purdue Pharma anticipated this legislative change and adjusted their promotional activities in response.
42
On October 6, 2014, hydrocodone combinations were switched from Schedule III to Schedule II.

21

The difference in oxycodone distribution between the two sets of states exceeds the
difference observed for OxyContin alone in Figure 3 and grows over time; this growth suggests
possible spillovers of OxyContin’s promotion on the use of other oxycodone combination
products (e.g., Percocet). This would be consistent with Purdue Pharma’s marketing strategies
that aimed to expand the opioid market for chronic pain by making doctors more comfortable
with prescribing strong oxycodone products. This messaging could spill over to other oxycodone
combination products.
In columns (3) and (4) of Table 2, we report the estimated differences in oxycodone
distribution across triplicate and non-triplicate states using equation (3). These differences are
statistically significant and growing from the initial period observed in the data to the last period.
In columns (5) and (6), we do not observe statistically significant differences in hydrocodone at
any point in time.
In Figure 5, we show trends in opioid misuse rates for OxyContin versus all other pain
reliever misuse (excluding OxyContin) using the National Study of Drug Use and Health
(NSDUH) from 2004-2012. Non-triplicate states have about twice as much OxyContin misuse
as triplicate states (Panel A). However, we do not observe any meaningful differences in pain
reliever misuse excluding OxyContin (Panel B). Thus, differences in opioid misuse across
triplicate and non-triplicate states is unique to OxyContin.
Taken together, these results are consistent with any differences in overdose rates being
primarily attributable to OxyContin, since the primary differences between triplicate and nontriplicate states are exposure to and misuse of OxyContin. The differences in OxyContin
distribution and misuse continue even through the most recent years of data, consistent with long
run differences in mortality rates. In Section 6, we will discuss the mechanisms for why
triplicate programs have such persistent effects on OxyContin exposure.
These results also suggest that the broader changes in attitudes towards prescribing
opioids or the adoption of new treatment guidelines for pain (e.g., 2001 JCAHO revisions) that
took place over this time period did not differentially affect triplicate and non-triplicate states,
since we would expect these changes to also impact the prescribing of hydrocodone and other
opioids. Instead, we do not observe differences in trends or even levels across triplicate and nontriplicate states in hydrocodone distribution. We also do not observe meaningful cross-sectional
differences in pain reliever misuse when OxyContin is excluded.
22

5.3 Effects of OxyContin Exposure on Drug Overdose Deaths
Next, we examine whether the differential exposure to OxyContin led to differences in
drug overdose deaths over time. The raw trends in drug overdose deaths for triplicate and nontriplicate states were previously shown in Figure 2. In Figure 6, we present the coefficients from
estimating the event-study specification in equation (1) with 95% confidence intervals. Panel A
shows the rate of total overdose deaths as the outcome and Panel B shows the rate of opioidrelated overdose deaths. Prior to OxyContin’s launch, the coefficients are close to zero and
largely statistically insignificant, suggesting that there were no systematic differences in trends
prior to 1996.43 However, within a few years after the launch, the trends diverge. Drug overdose
deaths increase much more rapidly in non-triplicate states than in triplicate states. The
coefficient estimate in 1997 indicates that overdose deaths in non-triplicate states increased by
0.25 deaths per 100,000 compared to triplicate states. These effects increase to a statistically
significant 2.25 deaths per 100,000 in 2002 and 11.41 deaths per 100,000 in 2017. It is not
surprising that the effects on overdose deaths are delayed given the low levels of OxyContin
sales in the earliest years, expansions in promotion over time, and the FDA’s relabeling in 2001
that expanded the market for chronic use. Additionally, it would take time before OxyContin
users transitioned to misuse and dependence.
In Panel B of Figure 6, we show the analogous event-study results for opioid-related
deaths specifically. The pattern is similar to Panel A, suggesting that the overall mortality effects
are largely driven by opioids. We show results for both overdose death measures throughout the
paper out of concern that opioid deaths may be under-reported. The broader total overdose death
measure will capture some opioid overdose deaths that were not coded as such and provides the
most consistently defined measure over our 35-year study period. The event study results are
also similar without population-weights or when we condition on time-varying covariates (see
Appendix Figure 4). These event-study results strongly suggest a causal relationship between the
introduction of OxyContin and the rise in overdose deaths. We further examine the causality of
this relationship with a battery of robustness tests in Section 5.4.

43

To the extent that the general pain management culture was changing and perhaps systematically across triplicate
and non-triplicate states, we would expect to observe gradual responses beginning even prior to OxyContin’s launch
given concerns about the under-treatment of pain in the 1980s and early 1990s. However, we do not observe preexisting trends reflecting differential responses to changing prescribing practices.

23

To quantify the magnitude of these effects, in Table 3, we present difference-indifferences estimates from equation (2) for the total drug overdose death rate and the opioid
overdose death rate separately. In Column 1 of Table 3, we present unweighted estimates.
Relative to the baseline 1991-1995 period, non-triplicate states experienced a relative annual
increase in total overdose deaths of 1.244 per 100,000 people in the earliest years after the launch
(1996-2000). This effect is statistically significant at the 5% level. 44 By 2011-2017, the relative
increase grew to 6.248 fatal overdoses per 100,000. In Column 2, we present populationweighted estimates. The point estimates are slightly larger in magnitude. Column 3 shows that
the estimates are robust to including time-varying covariates. Non-triplicates experienced a
differential rise in overdoses of 1.125 per 100,000 for 1996-2000. We estimate that the
“counterfactual” fatal overdose rate for non-triplicates during this time period would have been
4.312 per 100,000 if they had been triplicate states, implying that the increase in fatal overdoses
represents a 26% increase.45 The estimated effect grows to 4.221 in 2001-2010, representing a
60% increase, and 6.944 by 2011-2017, representing a 62% increase for non-triplicate states. In
Column 4, we include Census region-by-time interactions to account for geographic differences
in overdose rate growth. The results are generally similar. The three “post” estimates are jointly
significant from zero at the 1% level.
The bottom panel of Table 3 shows the same results for opioid-related overdose deaths.
The patterns are similar. The 1996-2000 estimate in Column 3 implies a 62% increase for nontriplicate states; and the 2011-2017 estimate indicates that initial non-triplicate status increased
opioid-related death rates by over 72%. Thus, proportionally, we find larger effects for opioidrelated deaths than total overdose deaths, consistent with OxyContin exposure having a
disproportionate effect on overdoses that report opioid involvement.

44

If we limit our difference-in-differences analysis to 1991-1998, we still estimate a statistically significant nontriplicate effect on the overdose rate in the shorter post-period. These years of data use only ICD-9 codes, so this is
reassuring that we are not estimating an artifact of the data due to a change in ICD codes. Notably, we also do not
observe a large differential jump in the event study coefficients in 1999 when this switch occurred.
45
The counterfactual is the overdose rate of the non-triplicate states minus the estimated coefficient on the nontriplicate indicator in that time period. Specifically, the “counterfactual” fatal overdose rate in non-triplicate states
(had they been triplicate states) during this period is 4.312 (= 5.437 – 1.125) such that the implied percentage
increase is 1.125 / 4.312 = 0.26.

24

5.3.1 State-Specific Results
The estimated differences between triplicate and non-triplicate states are not due to one
outlier triplicate state experiencing uniquely low growth in overdose deaths. Instead, we observe
this pattern for all triplicate states. In Figure 7, we analyze the rate of growth in overdose death
rates before and after OxyContin’s introduction comparing each triplicate state to its bordering
neighbor states. Specifically, we compare the change in the overdose death rate between the ten
years after OxyContin’s launch (1996-2005) relative to the ten years before (1986-1995). We
find that for four out of the five triplicate states, the triplicate state had the smallest growth rate
relative to all of their bordering states and the one exception – Illinois – had the second-to-lowest
growth rate.46 This pattern is not specific to the chosen set of years. Appendix Figure A5 repeats
this exercise but uses the most recent 10 years of data (2008-2017) as the post-period. The
remarkable consistency of low overdose growth across the triplicate states relative to other states
in their regions strongly suggests that it was the triplicate program and not other characteristics
that drove the relatively slow growth in these states, though we explore alternative explanations
further below.
5.3.2. Heroin and Fentanyl Overdose Deaths
We next examine trends in overdose deaths by the type of opioid. Appendix Figure A6
shows cross-sectional annual differences in opioid-related overdose deaths comparing triplicate
and non-triplicate states for: natural and semisynthetic opioids (e.g., oxycodone and
hydrocodone), heroin, and synthetic opioids (e.g., fentanyl) for 1999-2017. 47 Prior to 2010, the
only meaningful difference in overdose mortality between triplicate and non-triplicate states is
for natural and semisynthetic opioids, the category which includes OxyContin. Interestingly, we
observe a large relative increase in heroin-related fatal overdoses in non-triplicate states starting
in 2011, although the differences are not statistically significant. This is consistent with the
findings in Alpert et al. (2018) and Evans et al. (2019) which showed that areas with high initial
rates of OxyContin misuse or oxycodone supply experienced faster growth in heroin deaths after

46

While Idaho had a higher OxyContin adoption rate than other triplicate states, many of its neighbors did too,
suggesting meaningful regional differences. For Idaho, this higher rate of adoption did not translate into a high
growth rate in overdoses, which might suggest a high demand for legitimate uses of the product in this state.
47
The specific type of opioid involved in overdose deaths is not reliably coded before 1999 in a manner that can be
linked to 1999-2017 data.

25

an abuse-deterrent version of OxyContin was introduced in 2010. We also find that sharp
differences in synthetic opioid overdose death rates emerged in 2014, which is consistent with
reformulation leading to fentanyl use when it became mixed with the United States heroin supply
(Ciccarone, 2017; Pardo et al., 2019).
The timing of these differential drug-specific trends suggests that the introduction of
OxyContin had long-term effects on drug overdose deaths through each wave of the opioid
crisis. Initially, we observe growth in overdose deaths involving prescription opioids. After
OxyContin became hard to abuse and the opioid crisis transitioned first to heroin and then to
fentanyl, states less exposed to OxyContin’s introduction were also less affected by these
transitions.
5.3.3 Non-Fatal Outcomes
As a measure of non-fatal harms resulting from OxyContin’s introduction, in Appendix
Figure A7, we examine differences in substance abuse treatment admissions for opioids using the
Treatment Episode Data Set (TEDS).48 The results are consistent with the drug overdose death
findings. Non-triplicate states experienced sharper growth in substance abuse treatment
admissions for opioids after OxyContin’s introduction. These results help corroborate the
mortality findings while also providing evidence that OxyContin exposure also affected less
extreme outcomes, such as substance abuse.
5.4. Alternative Explanations
In this section, we explore alternative explanations for our findings and test the
robustness of our results. These robustness tests are presented in Table 4. Column 1 repeats the
main baseline estimate (Column 3 of Table 3). We focus our discussion on total overdose deaths
but find generally similar results for opioid overdose deaths (see Appendix Table A1).

48

The TEDS includes all admissions into treatment facilities receiving public funding. While TEDS is often used in
substance use research, there are concerns about underreporting of admissions. Some states may not report in each
year or may not report admissions in the same manner over time (SAMHSA, 2013). Our assumption is that
triplicate states did not systematically change reporting behavior around 1996. We tested this assumption explicitly
by replicating the analysis for other substances (e.g., marijuana, alcohol) and do not observe similar patterns,
suggesting that reporting issues are not driving the results.

26

5.4.1 Population Size
It is notable that four of the triplicate states are among the largest states in the country.
One concern is that states with large populations and major urban cities would have experienced
systematically different trends in overdose deaths independent of their triplicate status. As one
test of this alternative hypothesis, we compare triplicate states to the largest non-triplicate states.
In Column 2 of Table 4, we select the four largest non-triplicate states in terms of 1990
population size (FL, PA, OH, and MI) as comparison states for the four largest triplicate states.
We replicate our difference-in-differences analyses with these select states. 49 The estimates are
much larger than the main estimates which indicate that triplicate states have uniquely low
overdose death rate growth even when compared to the largest non-triplicate states. Despite the
additional noise due to the much smaller sample size, the estimates remain statistically different
from zero. More generally, when we look across all states, we find little correlation between
population size and overdose death rate growth, especially at the top of the distribution.
Appendix Figure A8 shows state-level changes in 10-year growth rates sorted by population size.
A related concern is that the triplicate and non-triplicate states vary in terms of urbanicity
which could also lead to systematically different overdose death trends. In Panel A of Appendix
Figure A9, we replicate our event study design at the county-level for urban counties (826
counties).50 We estimate larger effects for urban counties than our main results, implying that
urban counties in triplicate states have uniquely low fatal overdose growth even compared to
urban counties in non-triplicate states. Within urban counties, there are still some meaningful
size differences, so in Panel B, we further select counties with the largest population size:
“central counties of metro areas of 1 million population or more” (175 counties). 51 Again, the
results are similar, meaning that even when we select on the largest metropolitan areas in the
country, we observe large differences in fatal overdose rate growth based on 1996 triplicate
status. While there may still remain some differences in the characteristics of these metropolitan
areas across triplicate and non-triplicate states, it is notable how insensitive the main results are
to selecting further on these dimensions.

49

We exclude Idaho from this analysis, though results are similar if we include it.
We use the 1993 categorization by the Office of Management and Budget which divides counties into
metropolitan (“urban”) and non-metropolitan (“rural”).
51
This categorization is defined by the Department of Agriculture’s Economic Research Service and we use the
1993 values.
50

27

5.4.2. Adoption of Other Policies
Triplicate states were some of the earliest adopters of drug monitoring programs and so
were potentially also at the frontier of reducing prescription drug abuse in the years following
OxyContin’s introduction. If triplicate states followed different policy paths which addressed
opioid misuse more effectively than those in non-triplicate states, this could be confounding our
results. In Column 3 of Table 4, we examine the drug overdose death rates in triplicate states
compared to outcomes in states with other types of PDMPs in 1996—electronic PDMPs and
duplicate programs. Ten states had implemented these programs by 1996 (Horwitz et al., 2018).
These non-triplicate programs were not mentioned in Purdue Pharma documents, yet if we
believe that some states were simply “ahead of the curve” in moderating opioid misuse, then we
would expect that states with electronic PDMPs and other monitoring programs would also
experience slower growth in overdose death rates. However, the estimates actually increase
when we use this sample, suggesting that triplicate states experienced uniquely small changes in
overdose growth even relative to states with other types of PDMPs. 52
As a complementary approach, in Column 4 of Table 4, we replicate the difference-indifferences analysis for the full sample of states while controlling for a set of opioid-related
policy variables. We include two indicators for PDMPs from Horwitz et al. (2018) concerning
the enactment of a PDMP and enactment of a modern, electronic system. In addition, we also
include indicators for the adoption of “must access” PDMPs, pain clinic regulations, medical
marijuana laws, and legal/operational medical marijuana dispensaries. 53 Again, the results are
similar with these controls, implying that triplicate and non-triplicate states did not adopt
systematically different opioid policies post-1996 which can explain the discrepancy in the
growth rate of overdose deaths.
In addition, we test for differences in PDMP strength over time across triplicate and nontriplicate states using an index introduced in Pardo (2017). 54 Appendix Figure A10, shows
differences in PDMP strength for non-triplicate states relative to triplicate states, selecting on

52

Results are similar if we only use electronic PDMP states as the comparison group.
We code dates for must access PDMPs and pain clinic regulations using the Prescription Drug Abuse Policy
System (PDAPS). Data on marijuana laws and dispensaries are from the RAND Marijuana Policy database (see
Powell et al. (2018) and Williams et al. (2019)).
54
Pardo (2017) introduces an index of PDMP strength for 1999-2015, aggregating several different PDMP
dimensions (e.g., mandatory use, timely reporting, etc.) together and validating the metric by showing that increases
in PDMP strength are related to reductions in opioid-related overdose rates.
53

28

states that had any type of PDMP as of 1996. There is little difference in how PDMP strength
evolved between triplicate and non-triplicate states, yet we found much larger growth in fatal
overdoses in non-triplicate states relative to these other PDMP states, as shown above.
Finally, we compare initial access to substance abuse treatment in triplicate and nontriplicate states. States with more access to substance abuse treatment may have prevented rising
overdose death rates following OxyContin’s introduction. Using the 1997 Uniform Facility Data
Set (UFDS),55 we find that non-triplicate states had 3.938 treatment facilities per 100,000 people;
triplicate states had 4.000. The difference is statistically insignificant (p-value=0.94).
5.4.3 Deaths of Despair
Explaining the growth in fatal drug overdoses is a central theme of the “deaths of
despair” hypothesis discussed in Case and Deaton (2015, 2017), which studies trends in drug
overdoses, suicides, and alcohol-related liver mortality. The hypothesis suggests that we would
have observed an increase in mortality even in the absence of a rise in opioid supply due to
worsening cultural and economic factors. In this section, we study other non-opioid deaths of
despair – specifically, suicides (excluding overdoses) and alcohol-related liver deaths.
Appendix Figure A11 presents the event study estimates. We observe little evidence,
especially of the same magnitude and significance as the overdose death effects, of differential
rises in suicide rates or alcohol-related liver deaths by triplicate status. Suicides, excluding drug
overdoses, trend upward in the non-triplicate states relative to the triplicate states beginning in
the pre-period and continuing through the end of the sample period (Panel A). Alcohol-related
liver deaths also exhibit pre-existing trends that continue throughout the period with some
evidence of a flattening around 2001 (Panel B). 56 Because both of these outcomes have
noticeable systematic trends prior to 1996, we also show detrended estimates in Panels C and D
of Appendix Figure A11.57 Overall, we find little evidence that other deaths of despair follow
the same patterns as drug overdose deaths across triplicate and non-triplicate states, suggesting
55

UFDS is a predecessor to the N-SSATS which records all known private and public substance abuse treatment
facilities. The 1997 UFDS is the first year available from SAMHSA so we assume that treatment facilities did not
open or close immediately due to differential OxyContin exposure.
56
In principle, we might expect a delayed effect for alcohol-related liver deaths relative to those observed for
overdoses if they were both driven by systematic differences in “despair” given the nature of these deaths.
However, we do not observe an immediate or delayed increase in alcohol-related liver mortality.
57
We residualize the outcomes using estimated linear pre-trends (by triplicate status) using only the pre-1996 data
(see Goodman-Bacon, 2016 for an equivalent use of this approach).

29

that the differential supply and access to opioids played a crucial independent role in the opioid
crisis. Moreover, the lack of a decline in suicides and alcohol-related liver mortality of the same
magnitude suggests that fatal opioid overdoses were not substitutes for these types of deaths.
5.4.4. Additional Robustness Tests
We conducted numerous additional robustness tests that are presented and discussed in
Appendices B-D. We briefly summarize our findings here. First, our results are unchanged if
we account for changes in economic conditions (see Appendix B). We obtain similar estimates
when we control for the unemployment rate or exogenous shocks to economic conditions as
proxied by exposure to the decline in manufacturing (Charles et al., 2019), changes in labor
demand (Betz and Jones, 2018), and exposure to trade liberalization policies (Pierce and Schott,
forthcoming). Additionally, we find that the estimates are similar if we interact a set of our timevarying covariates with year indicators to permit the control variables to have different effects
over time.
Second, the results are not affected by differential exposure to the crack epidemic, which
ended shortly before the introduction of OxyContin. Our main results are similar when we
exclude overdoses involving cocaine. The results are also unaffected if we exclude fatal
overdoses involving unspecified narcotics.
Third, our estimates and statistical significance are robust to alternative inference
methods (see Appendix C). We estimate confidence intervals using traditional clustered (by
state) standard errors. This approach produces tighter confidence intervals than the restricted
wild bootstrap method. We also conduct permutation tests. These tests show that it is
statistically rare to observe our main mortality results when we randomly assign triplicate status
to other combinations of states.
Finally, the estimated effects are similar if we use synthetic control estimation (see
Appendix D), further suggesting that the effects are not driven by pre-existing differences in
levels or trends.
6

Mechanisms
The above results show consistent evidence that non-triplicate states were more exposed

to the introduction of OxyContin, causing a large and enduring increase in drug overdose deaths.
30

In this section, we explore possible mechanisms for what drove the differential exposure to
OxyContin. There are two possible channels. First, the triplicate programs themselves may have
independently deterred OxyContin adoption. The effects of these programs could persist over
the long run if the programs caused states to develop a prescribing culture that discouraged the
use of strong opioids. Second, the reduced marketing by Purdue Pharma in triplicate states may
have lessened OxyContin exposure. It is difficult to disentangle these two mechanisms because
the recommendation to not promote OxyContin in triplicate states was based on the belief that
triplicate programs would lead to low rates of OxyContin adoption.
We conduct two tests to provide evidence on these mechanisms. In the first test, we
compare triplicate states to other states which also had low prescribing rates of oxycodone prior
to 1996. In a second test, we compare the five triplicate states to the two former triplicate states
that had discontinued their programs prior to 1996. In both tests, we find that the five triplicate
states have uniquely low exposure to OxyContin and drug overdose rate growth even when
compared to states with more comparable prescribing cultures. This evidence supports the role
of Purdue Pharma’s marketing rather than cultural factors and entrenched prescribing habits in
explaining OxyContin exposure and mortality patterns.
Our first test is shown in Appendix Figure A12. We replicate the main event study
analysis but limit the sample to the five triplicate states and the five non-triplicate states with the
lowest oxycodone prescribing rates58 in the 1991-1995 Medicaid data (see Appendix Table A2
for the list of states). For both OxyContin exposure (Panel A) and overdose death rates (Panel
B), the estimates are remarkably similar to the main results of the paper despite the additional
noise due to the smaller sample size.59 Triplicate states adopted OxyContin at much lower rates
and had uniquely low overdose death growth compared to non-triplicate states that initially had
similar prescribing habits.
Next, we compare the five triplicate states to only the two former triplicate states
(Michigan and Indiana), which had triplicate programs prior to OxyContin’s introduction but
eliminated them in 1994. These former triplicate states serve as useful counterfactuals since they
58

This metric is highly-correlated with oxycodone prescriptions divided by oxycodone plus hydrocodone
prescriptions, and the results are similar when using this metric. This alternative metric has the advantage of
accounting for differences in opioid prescribing more generally, but we do not find that it matters empirically.
59
We have also operationalized this test in alternative ways such as estimating the main event study for all states
while controlling for a linear index of the 1991-1995 Medicaid prescribing rate interacted with time indicators, and
the conclusions of this exercise are not meaningfully affected.

31

would have developed similar prescribing cultures. Indeed, they were among the lowest
prescribers of oxycodone prior to OxyContin’s introduction (see Appendix Table A2) and this
continued in 1995 after they had eliminated their triplicate programs (see Appendix Table A3). 60
In Panel A of Figure 8, we present the cross-sectional differences in OxyContin
distribution using ARCOS data for the two former triplicate states compared to the five triplicate
states (dashed line). The solid line shows the differences for never-triplicate states compared to
the five triplicates. The former triplicates adopted OxyContin at a substantially higher rate than
the triplicate states, although at a lower rate than the never-triplicates (in 2000, the difference is
0.50 morphine equivalent doses per capita in former triplicates versus 0.73 in never triplicates). 61
Overall, the former triplicates appear more like the never-triplicates than the triplicate
states in terms of OxyContin exposure. In Panel B, we estimate the main event study for drug
overdose deaths showing separate coefficients for the former-triplicates and never-triplicates.
Both groups of non-triplicate states experience similar mortality trajectories when compared to
triplicate states. Thus, states with triplicate programs at the time of OxyContin’s launch
experienced uniquely low exposure to OxyContin and drug overdose death rates even when
compared to states which had triplicate programs just two years prior.
We draw two conclusions from these tests. First, prescribing culture alone cannot
explain the lack of OxyContin adoption and fatal overdose patterns in triplicate states. States
with similarly low initial levels of oxycodone prescribing as triplicate states still had much
higher rates of OxyContin adoption and overdose deaths. Second, states that had recently
discontinued triplicate programs adopted OxyContin and experienced subsequent overdose death
growth of similar magnitude as other non-triplicate states. 62 Our five triplicate states, however,
60

Table A3 shows Medicaid oxycodone prescribing rates for 1995, after Indiana and Michigan ended their triplicate
programs. We still see both states near the bottom of the distribution, suggesting persistence in prescribing culture
as they did not respond to the repeal of the triplicate programs by dramatically increasing oxycodone prescribing.
61
OxyContin distribution is skewed so the mean is much higher than the median. We plot median per capita
OxyContin supply for 2000-2016 in Appendix Figure A13. The former-triplicates and never-triplicates have very
similar median OxyContin supply (in 2000, the difference is just 0.1 per capita MEDs), but both have much higher
supply than triplicates.
62
One alternative explanation for this pattern is that the former triplicate states had active triplicate programs for
shorter periods of time than the triplicate states (i.e., CA adopted in 1939). This reduced exposure to the program
may have lessened the persistence of any developed prescribing culture. However, as noted previously, Indiana and
Michigan had oxycodone prescribing rates that were similar to the five triplicate states even in 1995 after
elimination of their program (see Appendix Table A3), suggesting that the triplicate programs induced low and
persistent oxycodone prescribing habits even in that shorter time period. Moreover, Texas, which adopted its
triplicate program in the same decade as Indiana and Michigan, experienced much lower overdose death growth than
these states.

32

continued to experience relatively low rates of OxyContin use and overdose death rates even
after eliminating their own triplicate programs in the late 1990s and early 2000s, suggesting that
the 1996 triplicate states were differentially treated compared to the former triplicate states. An
explanation for these differences is differential marketing exposure targeted to non-triplicate
states at the time of OxyContin’s launch.
Our results suggest that the lack of exposure to OxyContin in the years after its
introduction had enduring effects that can explain differences in drug overdose death rates even
today. The enduring nature of these effects is hard to reconcile with the prescribing culture
mechanism hypothesis since states with a history of low oxycodone prescribing and former
triplicates adopted OxyContin at high rates and experienced lasting increases in overdoses.
Purdue Pharma’s marketing strategy, however, could explain some of the long-term effects of
differential initial exposure. Internal Purdue Pharma documents show that their strategy was to
call and visit the top OxyContin prescribers. The early budget plans for Purdue Pharma annually
dictated that the sales force target calls to the top 1 to 3 (depending on the year) deciles of
physicians in terms of past prescribing behavior. Documents from the Massachusetts case
against Purdue Pharma includes additional evidence from internal communications discussing
this targeting behavior and how it extended until 2018.63 This marketing strategy would generate
serial correlation in OxyContin prescribing given differential initial exposure. Since triplicate
states would have initially attracted less marketing because of their lower prescribing, they
would continue to receive less marketing in future time periods and low prescribing would
persist.
While we have been unable to obtain data on state-level physician detailing behavior
from the 1990s to study these differences directly, we can study Purdue Pharma detailing in
2013-2016 using the CMS Open Payments Data as a measure of persistent differences in
detailing. This database reports payments to physicians for meals, travel, and gifts regarding
promotion of specific drugs. We calculate the total payments to physicians per capita over these
years for OxyContin. Figure 9 shows that there are large (and statistically significant)
differences between triplicate and non-triplicate states. Never-triplicate states receive 42-72%

63

For example, “McKinsey recommended doubling down on Purdue Pharma’s strategy of targeting high prescribers
for even more sales calls…” (p. 212 of Commonwealth of Massachusetts, 2018). Purdue announced in 2018 that
they stopped all opioid promotional activities targeting physicians.

33

more payments per capita than triplicates states in each year. As an alternative metric, we scale
the OxyContin-specific payments by total payments to account for state-level differences in
promotional activities. We present these measures in Appendix Figure A14. The gap between
triplicates and non-triplicates grows even further when using this metric. Similar to other
outcomes, the former-triplicates are much more similar to the never-triplicate states than the five
triplicate states. The evidence of promotional activities for opioids responding to state-level
PDMPs is also consistent with findings in Nguyen et al. (2019) concerning more recent adoption
of mandatory access PDMPs in the 2010s.
This evidence is consistent with persistence based on serial correlation in marketing
practices: greater initial marketing by Purdue Pharma in non-triplicate states, leading to higher
rates of prescribing which, in turn, led Purdue Pharma to target those places more in later years.
It is otherwise difficult to explain why the triplicate states as of 1996 experienced such
enduringly low rates of overdose death growth, but states that had eliminated their programs just
two years prior experienced overdose death trends almost identical to never-triplicate states. If
triplicate programs themselves had such enduring effects, then we would expect to observe
similar (or at least muted) effects for the former triplicate states as well.
One open question is why Purdue Pharma would dedicate resources to eliminating
triplicate programs and then not make a major marketing push in those states when those
programs were eliminated. Unfortunately, there are limits to our ability to discern Purdue
Pharma’s promotional strategies. However, we do not observe a large jump in OxyContin or
oxycodone prescriptions when states eliminate their triplicate programs. 64 In Appendix Figure
A15, we plot the estimates from an event study examining Medicaid prescriptions around the
triplicate repeal dates (conditional on state and time fixed effects). We find a downward trend
over time, consistent with the general separation between non-triplicate and triplicate states over
time and no independent effect of triplicate repeal. While this does not rule out subsequent
targeting of marketing to the triplicate states, it suggests that there may not have been a dramatic
increase in marketing intensity or that the content (and efficacy) of marketing had changed by
this point in time due to growing knowledge of OxyContin abuse and the government’s scrutiny
of the company’s misleading advertising practices. The possibility that advertising did not

64

We use Medicaid prescriptions so we can include all triplicate states in the analysis. With the ARCOS OxyContin
data, only 2 states have data for years prior to repeal (though the patterns are similar using ARCOS).

34

increase to non-triplicate levels is also supported by the findings from the Open Payments data,
discussed previously, showing that advertising differences across triplicate and non-triplicate
have continued until the present day.
Overall, the results in this section are consistent with Purdue Pharma’s initial marketing
decisions contributing to persistent differences in overdose deaths across states. The evidence of
triplicate programs independently inducing differential and enduring prescribing of OxyContin is
not well supported.
7

Discussion and Conclusion
Despite the importance of the opioid crisis and the desire to understand its origins, there

is little empirical work exploring its initial causes. We study the effects of the introduction of
OxyContin in 1996, exploiting early variation in its promotion and market entry based on preexisting state policies known as triplicate prescription programs. These state policies were
adopted decades earlier and became outdated soon after OxyContin's launch. However, their
initial deterrence of OxyContin promotion and use had long-term effects on overdoses in these
states, dramatically decreasing overdose death rates even today.
Our results imply striking differences throughout the opioid crisis stemming from
variation in initial policy conditions. States with more exposure to OxyContin's introduction
experienced higher growth in overdose deaths in almost every year since 1996. In the first wave
of the opioid crisis, this disproportionate growth is driven primarily by deaths from prescription
opioids. After the reformulation of OxyContin in 2010, overdose deaths involving heroin and
fentanyl also play a critical role. Our estimates (using Table 3, Column 3) show that nontriplicate states would have experienced 4.49 fewer drug overdose deaths per 100,000 on average
from 1996-2017 if they had been triplicate states and 3.04 fewer opioid overdose deaths per
100,000.65 We first consider the implications of these changes on overdose rate levels for this
time period. Over this time period, non-triplicates had an average of 12.32 fatal overdoses per
100,000 annually and 6.97 of those involved opioids. This implies that if non-triplicate states had
the same initial level of exposure to OxyContin as triplicate states, they would have had 36%

65

We take the three post estimates and weight each by the sum of the non-triplicate population size over the relevant
time periods (i.e., longer time periods receive more weight).

35

fewer drug overdose deaths and 44% fewer opioid overdose deaths on average in each year from
1996-2017.
We use our results to provide a back-of-the-envelope calculation of how much of the
dramatic growth in drug overdose deaths can be accounted for by the introduction and marketing
of OxyContin. On average, the national drug overdose death rate increased by 6.89 deaths per
100,000 since 1996, comparing the mean during the 1996-2017 time period (11.33 deaths per
100,000) relative to the 1991-1995 baseline mean (4.44). The additional exposure to
OxyContin’s launch and marketing for non-triplicate states led to 4.49 more deaths per 100,000,
which is equivalent to 65% (4.49/6.89) of the national growth in overdose death rates since
1996. As an additional benchmarking exercise, we consider the additional deaths that could be
attributed to an increase in initial OxyContin exposure moving from no exposure to the national
level of exposure. To make this calculation, we need to scale our mortality results by the
difference in OxyContin exposure between non-triplicate and triplicate states. 66 This
extrapolation suggests that moving from no OxyContin exposure to the national average would
lead to 5.56 more deaths per 100,000, which is 81% of the rise in the overdose death rate since
1996. We note that this extrapolation is far out-of-sample since no part of the United States was
unexposed, so we interpret it with caution. However, these calculations suggest that exposure to
OxyContin may explain a large share of the growth in drug overdose deaths since the mid-1990s.
The estimates are large because they capture both the direct and indirect consequences of
initial exposure to OxyContin, including spillovers of OxyContin promotion to other opioid
drugs and transitions to heroin and fentanyl in the later waves of the epidemic. They also
internalize downstream indirect effects of OxyContin’s introduction on the behaviors of other
entities in the supply chain— distributors, pharmacies, and doctors—which may have further
66

For the purposes of this extrapolation, we assume that differences in initial OxyContin supply serve as a summary
metric reflecting differences in exposure from the launch and marketing. Our extrapolation exercise can be
summarized as follows. First, we scale our mortality estimate by the additional initial OxyContin exposure
experienced in non-triplicate states. We calculate the difference in OxyContin exposure between non-triplicate and
triplicate states as 1.09 morphine equivalent doses (MEDs) per capita, using the first available year of ARCOS data
in 2000. This implies that one additional MED per capita of initial OxyContin exposure led to an additional 4.12
(4.49/1.09) drug overdose deaths per 100,000 annually. Next, we linearly extrapolate from this estimate to calculate
the effects of moving from the national average initial OxyContin exposure (1.35 MEDs per capita in 2000) to no
exposure. This implies that there would be 5.56 (4.12*1.35) fewer drug overdose deaths per 100,000 each year if
there had been no OxyContin exposure nationally. Relative to the average national growth in the drug overdose
death rate of 6.89 deaths per 100,000 from 1996-2017, this represents an 81% (5.56/6.89) decline. Alternative
scaling factors are also possible (e.g., ARCOS for the full 2000-2016 period, MEPS prescriptions, Medicaid
prescriptions) and typically generate larger estimates.

36

amplified OxyContin’s effects. Prior evidence showed that the removal of the abusable
formulation of OxyContin led to a striking national rise in heroin deaths after 2010. Consistent
with that evidence, this paper suggests that the introduction of OxyContin had significant effects
on overdose deaths from the beginning of the opioid crisis.
Our findings do not rule out the possibility that economic and cultural factors also
contributed to a meaningful share of the rise in drug-related mortality. However, we find that
the effects of the supply-side shock studied in this paper persist even when we account for
demand-side factors. While these results help quantify the harms associated with OxyContin
exposure, our analysis does not speak to the potential benefits of improved opioid access through
the introduction of OxyContin. Opioids may be effective pain management tools in some cases,
and we do not attempt to estimate the direct or indirect gains from pain reduction stemming from
OxyContin’s launch.
Finally, the evidence in this paper is consistent with Purdue Pharma’s marketing practices
playing an important role in explaining growth in drug overdose rates. When triplicate states are
compared to other states with similar prior oxycodone prescribing rates or even states which had
just recently eliminated their triplicate programs, they still have uniquely low overdose death rate
growth. This suggests that it is less likely that triplicate programs independently influenced
OxyContin adoption. Instead, the evidence is more consistent with differences in local
marketing leading to persistent differences in overdose death growth due to the nature of Purdue
Pharma’s marketing techniques. Overall, we find strong evidence that the marketing practices of
OxyContin interacted with state-level policy conditions led to dramatically reduced overdose
death rates in triplicate states. By deterring OxyContin's widespread introduction in 1996,
triplicate programs appear to have protected some states against the long-term fatal overdose
trends experienced by most other states.

37

References
Alexander, Monica J, Mathew V Kiang, and Magali Barbieri, “Trends in black and white
opioid mortality in the United States, 1979-2015," Epidemiology (Cambridge, Mass.), 2018, 29
(5), 707.
Alpert, Abby, David Powell, and Rosalie Liccardo Pacula, “Supply-side drug policy in the
presence of substitutes: Evidence from the introduction of abuse-deterrent opioids," American
Economic Journal: Economic Policy, 2018, 10 (4), 1-35.
Barnett, Michael L, Andrew R Olenski, and Anupam B Jena, “Opioid-prescribing patterns of
emergency physicians and risk of long-term use,” New England Journal of Medicine. 2017, 376
(7): 663-673.
Berina, Leslie F, Brock G Guernsey, James A Hokanson, William H Doutre, and Lonnie E
Fuller, "Physician perception of a triplicate prescription law." American Journal of HealthSystem Pharmacy, 1985, 42 (4), 857-860.
Betz, Michael R and Lauren E Jones, “Wage and employment growth in America’s drug
epidemic: Is all growth created equal?” American Journal of Agricultural Economics, 2018, 100
(5), 1357-1374.
Brewer, Mike, Thomas F Crossley, and Robert Joyce, “Inference with difference-indifferences revisited,” Journal of Econometric Methods, 2018, 7 (1).
Buchmueller, Thomas C, and Colleen Carey, “The effect of prescription drug monitoring
programs on opioid utilization in Medicare.” American Economic Journal: Economic
Policy, 2018, 10 (1), 77-112.
Cameron, A Colin, Jonah B Gelbach, and Douglas L Miller, “Bootstrap-based improvements
for inference with clustered errors," The Review of Economics and Statistics, 2008, 90 (3), 414427.
Case, Anne and Angus Deaton, “Rising morbidity and mortality in midlife among white nonHispanic Americans in the 21st century," Proceedings of the National Academy of Sciences,
2015, 112 (49), 15078-15083.
_ and _ , “Mortality and morbidity in the 21st century," Brookings Papers on Economic
Activity, 2017, 2017, 397-443.
Centers for Disease Control and Prevention (CDC). “Overdose deaths involving prescription
opioids among Medicaid enrollees-Washington, 2004-2007.” MMWR: Morbidity and Mortality
Weekly Report, 2009, 58 (42), 1171-1175.
Charles, Kerwin Kofi, Erik Hurst, and Mariel Schwartz, "The transformation of
manufacturing and the decline in US employment." NBER Macroeconomics Annual 33, no. 1,
2019: 307-372.
Ciccarone, Daniel, “Fentanyl in the US heroin supply: a rapidly changing risk environment.”
The International Journal on Drug Policy. 2017. 46, 107-111.
38

Cicero, Theodore J, James A. Inciardi, and Alvaro Munoz, “Trends in Abuse of OxyContin®
and Other Opioid Analgesics in the United States: 2002-2004,” The Journal of Pain. 2005, 6
(10), 662-672.
Commonwealth of Massachusetts, “Commonwealth of Massachusetts v. Purdue Pharma L.P.,
Purdue Pharma Inc., Richard Sackler, Theresa Sackler, Kathe Sackler, Jonathan Sackler,
Mortimer D.A. Sackler, Beverly Sackler, David Sackler, Ilene Sackler Lefcourt, Peter Boer,
Paulo Costa, Cecil Pickett, Ralph Snyderman, Judy Lewent, Craig Landau, John Stewart, and
Mark Timney.” June 12, 2018.
https://www.mass.gov/files/documents/2018/06/12/Purdue%20Complaint%20FILED.pdf
Conley, Timothy G and Christopher R Taber, “Inference with ‘difference in differences’ with
a small number of policy changes," The Review of Economics and Statistics, 2011, 93 (1), 113125.
DeBruyne, Nese F. “American War and Military Operations Casualties: Lists and Statistics.”
Congressional Research Service. 2018.
Dyer, Owen, “US Life Expectancy Falls for Third Year in a Row,” BMJ, 2018, 363, k5118.
Evans, William N, Ethan Lieber, and Patrick Power, “How the Reformulation of OxyContin
Ignited the Heroin Epidemic," Review of Economics and Statistics. 2019. 101(1), 1-15.
Fernandes, Jessie C, David Campana, Todd S Harwell, and Steven D Helgerson. "High
mortality rate of unintentional poisoning due to prescription opioids in adults enrolled in
Medicaid compared to those not enrolled in Medicaid in Montana." Drug and Alcohol
Dependence, 2015, 153, 346-349.
Fishman, Scott M, Jennifer S Papazian, Susana Gonzalez, Paul S Riches, and Aaron
Gilson, “Regulating opioid prescribing through prescription monitoring programs: Balancing
drug diversion and treatment of pain," Pain Medicine, 2004, 5 (3), 309-324.
Government Accountability Office (GAO), “Prescription Drugs: OxyContin Abuse and
Diversion and Efforts to Address the Problem: Report to Congressional Requesters,” DIANE
Publishing, 2003.
Goodman-Bacon, Andrew, “The long-run effects of childhood insurance coverage: Medicaid
implementation, adult health, and labor market outcomes.” No. w22899. National Bureau of
Economic Research, 2016.
Green, Carla A, Nancy A Perrin, Shannon L. Janoff, Cynthia I Campbell, Howard D
Chilcoat, and Paul M Coplan, “Assessing the accuracy of opioid overdose and poisoning codes
in diagnostic information from electronic health records, claims data and death records.”
Pharmacoepidemiology & Drug Safety. 2017, 26 (5), 509-517.
Groups Plus, “Purdue Pharma Company Focus Group Research & Findings Oxycontin for NonCancer Pain Management," Technical Report 1995.
Hartzema, Abraham G, Miquel S Porta, Hugh H Tilson, Sergio G Zullich, Thaddeus H
Grasela Jr, Jill B Fiedler-Kelly, and Francis M Gengo, “Impact of triplicate prescription

39

program on psychotropic prescribing patterns in long-term care facilities," Annals of
Pharmacotherapy, 1992, 26 (4), 539-546.
Hollingsworth, Alex, Christopher J Ruhm, and Kosali Simon, “Macroeconomic conditions
and opioid abuse," Journal of Health Economics, 2017, 56, 222-233.
Horwitz, Jill, Corey S. Davis, Lynn S. McClelland, Rebecca S. Fordon, and Ellen Meara,
“The problem of data quality in analyses of opioid regulation: The case of prescription drug
monitoring programs.” National Bureau of Economic Research, No. w24947, 2018.
IMS Institute for Healthcare Informatics, “The use of medicines in the United States: Review
of 2010," 2011.
Jones, Mark R, Omar Viswanath, Jacquelin Peck, Alan D Kaye, Jatinder S Gill, and
Thomas T Simopoulos. “A brief history of the opioid epidemic and strategies for pain
medicine,” Pain and Therapy. 2018, 7 (1), 13-21.
Joranson, David E, Grant M Carrow, Karen M Ryan, Linda Schaefer, Aaron M Gilson,
Patricia Good, John Eadie, Susan Peine, and June L Dahl, “Pain management and
prescription monitoring," Journal of Pain and Symptom Management, 2002, 23 (3), 231-238.
Khan, Nazleen F, Brian T Bateman, and Joan E Landon. “Association of opioid overdose
with opioid prescriptions to family members,” JAMA Internal Medicine. 2019, 179 (9), 11861192.
Kolodny, Andrew, David T Courtwright, Catherine S Hwang, Peter Kreiner, John L Eadie,
Thomas W Clark, and G Caleb Alexander, “The prescription opioid and heroin crisis: A
public health approach to an epidemic of addiction," Annual Review of Public Health, 2015, 36,
559-574.
Melzack Ronald. “The tragedy of needless pain.” Scientific American.1990, 262 (2), 27–33.
Morgan John P. “American opiophobia: customary underutilization of opioid analgesics.” Adv
AlcoholSubst Abuse. 1985, 5 (1-2), 163–73.
Nguyen, Thuy D, W David Bradford, and Kosali I Simon, “How do opioid prescribing
restrictions affect pharmaceutical promotion? Lessons from the Mandatory Access Prescription
Drug Monitoring Programs.” NBER Working Paper 2019.
Pardo, Bryce, "Do more robust prescription drug monitoring programs reduce prescription
opioid overdose?" Addiction, 2017, 112(10): 1773-1783
Pardo, Bryce, Jonathan P. Caulkins, Beau Kilmer, Rosalie Liccardo Pacula, Peter Reuter,
and Bradley D. Stein. "The synthetic opioid surge in the United States." RAND Publication
2019. https://www.rand.org/pubs/research_reports/RR3116.html
Phillips, Donald M, “JCAHO pain management standards are unveiled," JAMA, 2000, 284 (4),
428-429.
Pierce, Justin and Peter Schott. “Trade liberalization and mortality: Evidence from U.S.
counties.” American Economic Review: Insights, forthcoming.

40

Porter J, Jick H. “Addiction rare in patients treated with narcotics.” New England Journal of
Medicine. 1980, 302 (2), 123.
Powell, David, Rosalie Liccardo Pacula, and Mireille Jacobson, “Do medical marijuana laws
reduce addictions and deaths related to pain killers?” Journal of Health Economics, 2018, 58, 2942.
Purdue Pharma, “OxyContin Launch Plan," Technical Report 1995.
_ , “1997 Budget Plan," Technical Report 1997.
_ , “1998 Budget Plan," Technical Report 1998.
_ , “1999 Budget Plan," Technical Report 1999.
_ , “2001 Budget Plan," Technical Report 2001.
_ , “2002 Budget Plan," Technical Report 2002.
Quinones, Sam. “Dreamland: The True Tale of America’s Opiate Epidemic.” New York:
Bloomsbury Publishing. 2015.
Roodman, David Malin, James G MacKinnon, Morten Ørregaard Nielsen, and Matthew
Webb, “Fast and wild: bootstrap inference in Stata using Boottest," Technical Report, Queen's
Economics Department Working Paper 2018.
Ruggles, Steven, Sarah Flood, Ronald Goeken, Josiah Grover, Erin Meyer, Jose Pacas, and
Matthew Sobek, “IPUMS USA: Version 8.0 [dataset]," 2018.
Ruhm, Christopher J, "Corrected US opioid‐involved drug poisoning deaths and mortality
rates, 1999–2015." Addiction, 2018, 113 (7), 1339-1344.
Ruhm, Christopher J, “Drivers of the fatal drug epidemic." Journal of Health Economics 64,
2019, 25-42.
Scholl, Lawrence, Puja Seth, Mbabazi Kariisa, Nana Wilson, and Grant Baldwin, "Drug
and opioid-involved overdose deaths—United States, 2013–2017." Morbidity and Mortality
Weekly Report 67, no. 5152, 2019: 1419.
Sharp, Mark J., and Thomas A. Melnik. "Poisoning deaths involving opioid analgesics—New
York State, 2003–2012." MMWR. Morbidity and Mortality Weekly Report, 2015, 64 (14): 377.
Sigler, KA, BG Guernsey, NB Ingrim, AS Buesing, JA Hokanson, E Galvan, and WH
Doutre, “Effect of a triplicate prescription law on prescribing of Schedule II drugs," American
Journal of Health-System Pharmacy, 1984, 41 (1), 108-111.
Simoni-Wastila, Linda and Wendy Toler, “State-Issued Prescription Forms," n.d.
https://cdn.ymaws.com/www.safestates.org/resource/resmgr/imported/Simoni%20Wastila.pdf,
last accessed March 11, 2019.
Simoni-Wastila, Linda and Christopher Tompkins, “Balancing diversion control and medical
necessity: The case of prescription drugs with abuse potential," Substance Use & Misuse, 2001,
36 (9-10), 1275-1296.
41

_ , Dennis Ross-Degnan, Connie Mah, Xiaoming Gao, Jeffrey Brown, Leon E Cosler,
Thomas Fanning, Peter Gallagher, Carl Salzman, and Stephen B Soumerai, “A
retrospective data analysis of the impact of the New York triplicate prescription program on
benzodiazepine use in Medicaid patients with chronic psychiatric and neurologic disorders,"
Clinical Therapeutics, 2004, 26 (2), 322-336.
Strategic Business Research, Inc., “OxyContin: Quantitative Research," Technical Report
1996.
Substance Abuse and Mental Health Services (SAMHSA) Center for Behavioral Health
Statistics and Quality, “Treatment Episode Data Set (TEDS): 2001-2011. State Admissions to
Substance Abuse Treatment Services,” 2013.
University of Kentucky Center for Poverty Research, “UKCPR National Welfare Data, 19802017," 2018.
Van Zee, Art, “The promotion and marketing of OxyContin: Commercial triumph, public health
tragedy," American Journal of Public Health, 2009, 99 (2), 221-227.
Venkataramani, Atheendar S and Paula Chatterjee, "Early Medicaid Expansions and Drug
Overdose Mortality in the USA: A Quasi-Experimental Analysis." Journal of General Internal
Medicine 34.1, 2019: 23-25.
Warner, Margaret, Li Hui Chen, Diane M Makuc, Robert N Anderson, and Arialdi M
Miniño, “Drug poisoning deaths in the United States, 1980-2008," NCHS data brief, 2011, (81),
1-8.
Webb, Matthew D, “Reworking wild bootstrap based inference for clustered errors," Technical
Report, Queen's Economics Department Working Paper 2014.
Weintraub, Michael, Satesh Singh, Louise Byrne, Kumar Maharaj, and Laurence
Guttmacher, “Consequences of the 1989 New York State triplicate benzodiazepine prescription
regulations," JAMA, 1991, 266 (17), 2392-2397.
Whitmire, J. Timothy, and Glenda Waslaski Adams, “Unintentional overdose deaths in the
North Carolina Medicaid population: prevalence, prescription drug use, and medical care
services.” Center for Health Statistics, 2010.
https://schs.dph.ncdhhs.gov/schs/pdf/schs_162_web_081310.pdf, last accessed March 11, 2019
Williams, Jenny, Rosalie Liccardo Pacula, and Rosanna Smart, “De Facto or De Jure?
Ethnic Differences in Quit Responses to Legal Protections of Medical Marijuana Dispensaries.”
No. w25555. National Bureau of Economic Research, 2019.
World Health Organization (WHO), “Cancer Pain Relief," 1986.

42

Figures
Figure 1: National Drug Overdose Death Rates
20

Deaths per 100,000

All Drug Overdoses
15

10
Opioid

5
Non−opioid

19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

0

Year

Notes: We use geocoded NVSS data to construct total overdose and opioid overdose deaths per 100,000. See Section 3.1 for ICD
codes used in each period. Opioid overdoses are deﬁned as overdoses which report opioid involvement (including natural/semisynthetic opioids, heroin, and synthetic opioids). Non-opioid overdoses are deﬁned as overdoses that do not report opioid
involvement.

20

20

25

Figure 2: Drug Overdose Death Rates By Triplicate State Status

Deaths per 100,000
10
15

Deaths per 100,000
10
15

Non−Triplicate

5

Triplicate

Non−Triplicate

A: All Drug Overdose Deaths

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

19

19

85

0

83
19

17

15

20

13

20

11

20

09

20

07

20

05

20

20

03

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

19

83

0

5

Triplicate

B: Opioid Overdose Deaths

Notes: We use geocoded NVSS data to construct total overdose and opioid overdose deaths per 100,000. See Section 3.1 for
ICD codes used in each period. The vertical line marks the introduction of OxyContin in 1996.

43

16
20

14
20

12
20

10
20

08
20

06
20

04
20

02
20

20

00

Morphine Equivalent Doses Per Capita
0
.5
1
1.5

Figure 3: OxyContin Distribution and Prescriptions by Triplicate State Status

Year
Non−Triplicate States
Triplicate States

19
9
19 6
9
19 7
9
19 8
9
20 9
0
20 0
0
20 1
0
20 2
0
20 3
0
20 4
0
20 5
0
20 6
0
20 7
0
20 8
0
20 9
1
20 0
1
20 1
1
20 2
1
20 3
1
20 4
1
20 5
16

OxyContin Prescriptions Per 1,000
0
5
10
15
20
25

05
20

04
20

03
20

02
20

01
20

00
20

99
19

98
19

97
19

19

96

OxyContin Prescriptions per 1,000 Benes
0
20
40
60
80

A: OxyContin Distribution (ARCOS)

Year

Year

Non−Triplicate States
Triplicate States

Non−Triplicate States
Triplicate States

B: OxyContin Prescriptions (Medicaid)

C: OxyContin Prescriptions (MEPS)

Notes: In Panel A, we use ARCOS data and construct morphine equivalent doses per capita. OxyContin data are only available
for 2000-2016. In Panel B, we report the number of prescriptions per 1,000 beneﬁciaries from the Medicaid SDUD. We end this
time series in 2005 due to the introduction of Medicare Part D. In Panel C, we report the number of prescriptions per 1,000
people in the MEPS. We use the MEPS survey weights.

44

17
20

15
20

13
20

11
20

09
20

07
20

05
20

03

01

20

99

20

19

19

97

Morphine Equivalent Doses Per Capita
0
2
4
6

Figure 4: Oxycodone and Hydrocodone Distribution by Triplicate State Status

Year
Oxycodone in Non−Triplicate States
Oxycodone in Triplicate States
Hydrocone in Non−Triplicate States
Hydrocodone in Triplicate States

Notes: We use ARCOS data to construct morphine equivalent doses per capita by substance.

Year
Non−Triplicate

12
20

10
20

08
20

06
20

04
20

12
20

10
20

08
20

06
20

20

04

3.8

.3

.4

Misuse Rate (%)
.5
.6
.7

Misuse Rate (%)
4
4.2
4.4

.8

4.6

Figure 5: Non-Medical Use Rates by Triplicate State Status

Year
Triplicate

Non−Triplicate

A: OxyContin

Triplicate

B: Pain Relievers excluding OxyContin

Notes: Misuse rates are calculated from the National Survey on Drug Use and Health using the years available. Each year
refers to a two-year wave such that “2004” refers to 2004-2005, “2006” refers to 2006-2007, etc.

45

Estimate

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

0

0

Coefficient Estimate
5
10

Coefficient Estimate
5
10

15

15

Figure 6: Event Study: Drug Overdose Death Rate

95% Confidence Interval

Estimate

A: All Drug Overdose Deaths

95% Confidence Interval

B: Opioid Overdose Deaths

Notes: We use geocoded NVSS data to construct overdoses and opioid overdose deaths per 100,000. See Section 3.1 for exact
ICD codes used in each period. 95% conﬁdence intervals are generated using a clustered (at state) wild bootstrap. Estimates
are normalized to 0 in 1995. Weighted by population.

Figure 7: Drug Overdose Death Rate Changes: Triplicate States vs. Bordering States
6

8

Change in Deaths per 100,000
2
4

y
uc
k

Ke
nt

ur

i

n
M

is

so

ga
hi
ic

o
ic

a
M
N

ew

kl
O

ex

ah
om

na
ia
Lo
ui
s

Ar

ka

Te
x

ns
a

as

s

0

ut
tic
ne
c

on

us
et
ts
C

M

as

sa
ch

ey

an
ia

Je
rs

lv

ew

Pe
nn
sy

N

an
d

on
t

Is
l
ho
de

R

Ve
rm

N

ew

Yo
rk

0

Change in Deaths per 100,000
2
4
6

Change in Deaths per 100,000
1
2
3
4
5

8

M

co

ns

na

W

W

is

s
oi
Ill
in

In
di
a

a
w
Io

in

0

ta
h

as
h

in

on
t
M

yo
W

U

gt
on

a
an

g
m

in

ah
Id

N

Ar

ev

iz

on

ad
a

a

n
go
re
O

C

al
if

or
n

ia

0

o

0

Change in Deaths per 100,000
2
4
6

Change in Deaths per 100,000
2
4
6

8

1996-2005 Relative to 1986-1995

Notes: We construct the change in overdose deaths per 100,000 for 1996-2005 relative to 1986-1995. We plot this change for
each triplicate state relative to its bordering states.

46

7

5

20
1

3

20
1

1

20
1

9

7

20
1

20
0

5

20
0

3

20
0

1

20
0

9

Year

20
0

7

19
9

5

19
9

3

19
9

1

19
9

9

19
9

7

19
8

5

19
8

19
8

3
19
8

6
20
1

4
20
1

2
20
1

0
20
1

8
20
0

6
20
0

4
20
0

2
20
0

20
0

0

0

0

.2

Coefficient Estimate
5
10

Coefficient Estimate
.4
.6
.8

15

1

Figure 8: Event Study: Comparing Former Triplicate States to Never Triplicate States

Year

Never Triplicates

Former Triplicates

Never Triplicates

A: OxyContin Distribution

Former Triplicates

B: Drug Overdose Deaths

Notes: We estimate our primary event study using the triplicate states as controls and estimating eﬀects separately for nevertriplicate states and former-triplicate states. State and year ﬁxed eﬀects included. The outcome in Panel A is OxyContin
morphine equivalent doses per capita. The Panel B outcome is drug overdose deaths per 100,000.

Payments ($) per 100,000
100
150
200

250

Figure 9: OxyContin Promotional Payments to Physicians

Former Triplicates

Never Triplicates

16
20

15
20

14
20

20

13

50

Triplicates

Year

Notes: We used CMS Open Payments Data to calculate total payments and gifts made to physicians regarding OxyContin. We
scaled this measure by population. The outcomes correspond to August 2013 – December 2016. Because the 2013 data only
cover a partial year, we annualize the rate in that year.

47

Tables
Table 1: Summary Statistics for 1991-1995
Statistics for 1991-1995

California

Idaho

Illinois

New York

Texas

Triplicate

Non-Triplicate

Triplicate Program
First Year
Last Year

1939
2004

1967
1997

1961
2000

1972
2001

1982
1999

Annual Overdose Death Rates
Overdoses per 100,000
Overdose Rate Rank
Overdoses (excluding cocaine) per 100,000
Overdose (excluding cocaine) Rate Rank
Opioid Overdoses per 100,000
Opioid Overdose Rate Rank

7.10
3
5.65
4
2.95
5

2.92
30
2.74
23
0.47
34

4.58
16
2.74
21
2.27
10

6.14
9
2.78
20
3.82
2

3.86
20
2.73
24
0.77
21

5.72
–
3.88
–
2.52
–

3.86
–
3.15
–
1.00
–

Demographics
% White, Non-Hispanic
% Black, Non-Hispanic
% Hispanic
% Ages 25-44
% Ages 45-64
% Ages 65+
% College Degree
Population (in thousands)

54.9%
6.0%
28.8%
34.1%
17.6%
10.6%
24.5%
31,180

72.7%
16.2%
8.4%
32.3%
19.2%
12.5%
23.5%
1,109

72.7%
16.2%
8.4%
32.3%
19.1%
12.5%
23.5%
11,799

69.2%
14.5%
12.1%
32.4%
20.0%
13.0%
24.5%
18,346

57.5%
12.6%
26.8%
32.8%
17.7%
10.2%
21.4%
18,168

61.8%
10.8%
21.2%
33.1%
18.4%
11.3%
23.6%
16,120

78.9%
13.1%
4.1%
31.8%
19.6%
13.2%
21.2%
3,167

Notes: All summary statistics are population-weighted means, except the population variable which is unweighted.

Table 2: Diﬀerences in Opioid Distribution (ARCOS)
Non-Triplicate x
1996 −

2000†

2001 − 2010
2011 − 2017†
Time-Varying Covariates
N

OxyContin

Oxycodone

Hydrocodone

(1)

(2)

(3)

(4)

(5)

(6)

0.707***
[0.521, 0.922]
0.615***
[0.309, 0.991]
0.461***
[0.222, 0.776]
No
867

0.765***
[0.355, 1.000]
0.661***
[0.321, 0.994]
0.517**
[0.150, 0.845]
Yes
867

0.637***
[0.472, 0.824]
2.259***
[1.198, 3.443]
2.949***
[0.979, 4.532]
No
1,071

0.699*
[-0.061, 1.512]
2.434***
[1.413, 3.641]
3.117***
[1.347, 4.738]
Yes
1,071

-0.017
[-0.261, 0.325]
0.052
[-0.552, 0.696]
0.101
[-0.569, 1.107]
No
1,071

-0.138
[-0.813, 0.199]
0.005
[-0.794, 0.427]
0.077
[-0.638, 0.648]
Yes
1,071

Notes: ***Signiﬁcance 1%, **Signiﬁcance 5%, *Signiﬁcance 10%. The outcome is the per capita morphine equivalent
doses of the substance listed. Estimated speciﬁcations include year ﬁxed eﬀects. The reported coeﬃcients refer to the
interaction of the given time period and an indicator for whether the state did not have a triplicate program in 1996.
95% conﬁdence intervals reported in brackets are estimated by wild bootstrap. Regressions are population-weighted.
Time-varying covariates include the fraction non-Hispanic white, fraction non-Hispanic black, fraction Hispanic, log
of population, fraction with college degree, fraction ages 25-44, fraction ages 45-64, and fraction ages 65+.
† OxyContin data only cover 2000-2016 and, therefore, the 1997-2000 category only refers to 2000; the 2011-2017
category refers to 2011-2016.

48

Table 3: Diﬀerence-in-Diﬀerences Estimates: Drug Overdose Death Rate
A: Overdose Deaths per 100,000
(2)
(3)

Non-Triplicate ×

(1)

1996-2000

Joint P-Value
Weighted
Covariates
Region-Time Dummies
Mean 1991-1995
N

1.244**
[0.443, 2.463]
3.758**
[1.612, 6.399]
6.248**
[3.012, 9.486]
0.016
No
No
No
3.874
1,377

Non-Triplicate ×

(5)

1996-2000

0.702**
[0.136, 1.648]
2.675**
[1.130, 4.527]
5.133**
[1.551, 8.417]
0.038
No
No
No
1.173
1,377

2001-2010
2011-2017

2001-2010
2011-2017
Joint P-Value
Weighted
Covariates
Region-Time Dummies
Mean 1991-1995
N

1.323***
[0.453, 2.533]
4.566***
[2.206, 6.600]
7.903***
[4.136, 10.496]
0.000
Yes
No
No
4.436
1,377

1.125**
[0.045, 2.705]
4.221**
[1.344, 6.953]
6.944***
[4.429, 8.886]
0.002
Yes
Yes
No
4.436
1,377

(4)
1.452**
[0.297, 2.844]
4.445***
[2.557, 6.245]
6.816***
[4.278, 9.014]
0.001
Yes
Yes
Yes
4.436
1,377

B: Opioid Overdose Deaths per 100,000
(6)
(7)
0.631**
[0.112, 1.672]
2.993***
[1.195, 4.384]
5.946***
[1.805, 8.919]
0.011
Yes
No
No
1.476
1,377

0.821*
[-0.154, 1.892]
2.766**
[0.042, 4.918]
4.789***
[1.893, 6.879]
0.018
Yes
Yes
No
1.476
1,377

(8)

1.044**
[0.003, 2.075]
3.011***
[0.988, 4.932]
4.543***
[1.830, 6.645]
0.013
Yes
Yes
Yes
1.476
1,377

Notes: ***Signiﬁcance 1%, **Signiﬁcance 5%, *Signiﬁcance 10%. Outcome is overdose deaths or
opioid overdose deaths per 100,000. The reported coeﬃcients refer to the interaction of the given
time period and an indicator for whether the state did not have a triplicate program in 1996.
Estimates are relative to pre-period 1991-1995. 95% conﬁdence intervals reported in brackets are
estimated by wild bootstrap. All models include state and year ﬁxed eﬀects. Covariates include
the fraction non-Hispanic white, fraction non-Hispanic black, fraction Hispanic, log of population,
fraction with college degree, fraction ages 25-44, fraction ages 45-64, and fraction ages 65+. “Joint
P-Value” refers to the p-value from a joint hypothesis test that all three non-triplicate post eﬀects
are equal to zero and is also estimated using a restricted wild bootstrap.

49

Table 4: Robustness Tests

Non-Triplicate ×
1996-2000
2001-2010
2011-2017
Joint P-Value
Mean 1991-1995
N

Baseline
Results
(1)
1.125**
[0.045, 2.705]
4.221**
[1.344, 6.953]
6.944***
[4.429, 8.886]
0.002
4.436
1,377

Overdose Deaths per 100,000
Select on
Select on PDMP
Population Size
States in 1996
(2)
4.104**
[1.444, 6.443]
8.204***
[4.874, 11.118]
10.487**
[0.759, 19.929]
0.012
5.134
216

(3)
1.831*
[-0.165, 3.826]
6.137***
[2.972, 9.303]
10.698***
[7.607, 13.789]
0.001
5.346
405

Control for
Policy Variables
(4)
1.557**
[0.345, 2.714]
5.448***
[2.913, 7.372]
8.811***
[5.863, 11.689]
0.000
4.436
1,377

Notes: ***Signiﬁcance 1%, **Signiﬁcance 5%, *Signiﬁcance 10%. Outcome is overdose deaths per 100,000.
The reported coeﬃcients refer to the interaction of the given time period and an indicator for whether
the state did not have a triplicate program in 1996. Estimates are relative to pre-period 1991-1995. 95%
conﬁdence intervals reported in brackets are estimated by wild bootstrap. All models include state and
year ﬁxed eﬀects and time-varying covariates (see Table 3 for details). Column (1) repeats the Column
(3) results from Table 3. Column (2) selects on the four non-triplicate states with the largest populations
in 1990 along with the four largest triplicate states. Column (3) selects on states with some form of
PDMP (triplicate, duplicate, electronic) in 1996. Column (4) includes policy controls for PDMPs (any
PDMP and electronic PDMP), “must access” PDMPs, pain clinic regulation, medical marijuana laws,
and operational/legal medical marijuana dispensaries. “Joint P-Value” refers to the p-value from a joint
hypothesis test that all three non-triplicate post eﬀects are equal to zero and is also estimated using a
restricted wild bootstrap.

50

Appendix A
Appendix Figures
Figure A1: Example of Purdue Pharma Focus Group Recommendations

51

Year

03
20

02
20

01
20

00
20

99
19

98
19

97
19

96
19

03
20

02
20

01
20

00
20

99
19

98
19

97
19

19

96

5

2

6

2.5

Deaths per 100,000
3
3.5

Deaths per 100,000
7
8

4

9

4.5

Figure A2: ICD Code Change in 1999

Year

A: Drug Overdose Deaths per 100,000

B: Opioid Overdose Deaths per 100,000

Notes: We use geocoded NVSS data to construct overdose deaths per 100,000. These ﬁgures study the transition from ICD-9
to ICD-10 codes in 1999.

52

Illinois
New York
Iowa
Wyoming
California
South Dakota
Texas
North Dakota
Nebraska
Minnesota
Kansas
New Mexico
Colorado
Idaho
Oklahoma
Arkansas
D.C.
Hawaii
Utah
Wisconsin
Tennessee
Montana
Mississippi
Louisiana
Georgia
Indiana
New Jersey
Michigan
Virginia
North Carolina
Vermont
Oregon
Washington
Arizona
Nevada
Rhode Island
Massachusetts
South Carolina
Alabama
Ohio
Maryland
Kentucky
Delaware
Pennsylvania
Connecticut
New Hampshire
Missouri
Maine
Florida
West Virginia
Alaska

0

.5

OxyContin Adoption
1
1.5
2
South Dakota
California
Illinois
Texas
New York
North Carolina
D.C.
Mississippi
South Carolina
Louisiana
Nebraska
Kentucky
Indiana
Oregon
Alabama
Oklahoma
Wyoming
Minnesota
Colorado
North Dakota
Michigan
New Mexico
Virginia
Georgia
Arkansas
Montana
Iowa
Missouri
West Virginia
Rhode Island
Delaware
Nevada
Washington
Ohio
New Jersey
Florida
Kansas
Vermont
Massachusetts
Idaho
Wisconsin
Maryland
Maine
Hawaii
Utah
Pennsylvania
New Hampshire
Connecticut
Alaska

0

2

OxyContin Adoption
4
6
8

Figure A3: OxyContin Adoption by State

A. Medicaid OxyContin Prescriptions per 1,000 Benes in 1996

B. ARCOS Per Capita OxyContin Morphine Equivalent Doses in 2000

Figure A4: Overdose Death Rate Event Studies
15
Coefficient Estimate
5
10
0
Estimate

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

0

Coefficient Estimate
5
10

15

Unweighted

95% Confidence Interval

Estimate

A: Drug Overdoses per 100,000

95% Confidence Interval

B: Opioid Overdoses per 100,000
15
Coefficient Estimate
5
10
0

95% Confidence Interval

Estimate

C: Drug Overdoses per 100,000

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

83
19

17

15

20

13

20

11

20

09

20

07

20

05

20

03

−5
Estimate

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

19

83

−5

0

Coefficient Estimate
5
10

15

Unweighted, With Covariates

95% Confidence Interval

D: Opioid Overdoses per 100,000
15
Coefficient Estimate
5
10
0

95% Confidence Interval

Estimate

E: Drug Overdoses per 100,000

17

20

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

19

97

19

95

19

93

19

91

19

89

19

87

85

19

19

83
19

17

20

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

−5
Estimate

19

97

19

95

19

93

19

91

19

89

19

87

85

19

19

19

83

−5

0

Coefficient Estimate
5
10

15

Weighted, With Covariates

95% Confidence Interval

F: Opioid Overdoses per 100,000

Notes: We use geocoded NVSS data to construct overdose and opioid overdose deaths per 100,000. See text for exact ICD
codes used in each period. 95% conﬁdence intervals are generated using a clustered (at state) wild bootstrap. Estimates are
normalized to 0 in 1995. All models include state and year ﬁxed eﬀects. When covariates are speciﬁed, the models include
the fraction non-Hispanic white, fraction non-Hispanic black, fraction Hispanic, log of population, fraction with college degree,
fraction ages 25-44, fraction ages 45-64, and fraction ages 65+. Panels E and F are population-weighted; the others are not.

54

55
o

a

om

ah

ic

ex

a

an

si

M

kl

O

ew

N

ui

Lo

as

ns

ka

Ar

0

d

ni
a

s

xa

Te

lv
a

ut

ct
ic

et
ts

Is
la
n

sy

de

ho

R

nn

Pe

ne

t

on

rm

us

ch

on

C

sa

as

M

ey

rs

rk

Yo

Je

Ve

ew

N

ew

N
0

Change in Deaths per 100,000
5
10
15

20

Change in Deaths per 100,000
5
10
15
20

ky

a

an

n

i

ur

uc

nt

Ke

di

s
in

ga

so
hi
In

ic

M

is

M

ns

oi

a

w
in

0

h

g

U
ta

Io

co

is

o

na

in

m

yo

Ill

W

ta

on

M

ah

Id

n

0

to

ng

a

ad

hi

as

W

W

ev

N

a

n

go

on

Ar
iz

re

O

ia

rn

ifo

al

C

0

Change in Deaths per 100,000
5
10
15
20

Change in Deaths per 100,000
5
10

Change in Deaths per 100,000
5
10

15

15

Figure A5: Drug Overdose Death Rate Changes: Triplicate States vs. Bordering States
(2008-2017 Relative to 1986-1995)

Notes: We construct the change in overdose deaths per 100,000 for 2008-2017 relative to 1986-1995. We plot this change for
each triplicate state relative to its bordering states.

17

16

20

15

20

14

20

13

20

12

20

11

20

10

20

09

20

08

20

07

20

06

20

05

20

04

20

03

20

02

20

01

20

20

20

99
19

Estimate

00

−4

17

16

20

15

20

14

20

13

20

12

20

11

20

10

20

09

20

08

20

07

20

06

20

05

20

04

20

03

20

02

20

01

20

00

20

20

19

99

−2

−2

Coefficient Estimate
0
2

Coefficient Estimate
0
2

4

4

Figure A6: Overdose Death Rate Diﬀerences by Type of Opioid for 1999-2017

95% Confidence Interval
Estimate

A: Natural and Semisynthetic Opioids
(T40.2)

95% Confidence Interval

−5
19
99
20
00
20
01
20
02
20
03
20
04
20
05
20
06
20
07
20
08
20
09
20
10
20
11
20
12
20
13
20
14
20
15
20
16
20
17

Coefficient Estimate
0
5
10

15

B: Heroin (T40.1)

Estimate

95% Confidence Interval

C: Synthetic Opioids (T40.4)
Notes: We use geocoded NVSS data to construct overdose deaths per 100,000 for the reported opioid types (see text for
additional information). We show estimates from a regression which includes year ﬁxed eﬀects and non-triplicate indicators
interacted with year estimates. 95% conﬁdence intervals are generated using a clustered (at state) wild bootstrap.

56

16

14

20

12

20

10

20

08

20

06

20

04

20

02

20

00

20

98

20

96

19

94

19

19

19

92

Substance Abuse Treatment Admissions
for Pain Relievers per 100,000
20
40
60
80
100
120

Figure A7: Opioid-Related Substance Abuse Treatment Admissions

Year
Non−Triplicate States
Triplicate States

Pain Reliever Substance Abuse Treatment
Admissions per 100,000
Notes: Substance abuse treatment admissions are calculated using the Treatment Episode Data Set.

57

Wyoming
Alaska
Vermont
D.C.
North Dakota
Delaware
South Dakota
Montana
Rhode Island
Idaho
New Hampshire
Hawaii
Nevada
Maine
New Mexico
Nebraska
Utah
West Virginia
Arkansas
Kansas
Mississippi
Iowa
Oregon
Oklahoma
Connecticut
Colorado
South Carolina
Arizona
Kentucky
Alabama
Louisiana
Minnesota
Maryland
Tennessee
Washington
Wisconsin
Missouri
Indiana
Massachusetts
Virginia
Georgia
North Carolina
New Jersey
Michigan
Ohio
Illinois
Pennsylvania
Florida
Texas
New York
California

0

Change in Deaths per 100,000
2
4
6
8
10

Figure A8: Drug Overdose Death Rate Changes Sorted by Population Size: 1996-2005
Relative to 1986-1995

Notes: We construct the change in overdose deaths per 100,000 for 1996-2005 relative to 1986-1995. States are sorted by
population size from lowest to highest.

58

Figure A9: County-Level Overdose Death Rate Event Studies By Metropolitan Area Size

Estimate
Estimate

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

19

7

5

20
1

3

20
1

1

20
1

9

20
1

7

20
0

5

20
0

3

20
0

1

20
0

9

20
0

7

19
9

5

19
9

3

19
9

1

19
9

9

19
9

7

19
8

5

19
8

19
8

19
8

3

83

−5

−10

0

Coefficient Estimate
0
10

Coefficient Estimate
5
10
15

20

20

Overdose Deaths per 100,000

95% Confidence Interval

95% Confidence Interval

B: Central counties of metro areas of 1
million population or more

A: Counties of metro areas

Notes: The outcome is county-level overdose deaths per 100,000. 95% conﬁdence intervals are generated using a clustered (at
state) wild bootstrap. Estimates are normalized to 0 in 1995. Counties are categorized by the United States Department of
Agriculture’s Economic Research Service in 1993. We estimate the main event study speciﬁcation at the county-level. County
and year ﬁxed eﬀects included in all models. N = 28,910 (826 counties) for Panel A; N = 6,125 (175 counties) for Panel B.

59

5

4

20
1

3

20
1

2

20
1

1

20
1

0

20
1

9

20
1

8

20
0

7

20
0

6

20
0

5

20
0

4

20
0

3

20
0

2

20
0

1

20
0

0

20
0

20
0

19
9

9

−10

Difference in PDMP Score
−5
0
5

10

Figure A10: Comparing PDMP Strength by Triplicate State Status

Year
Year Estimate

95% Confidence Interval

Notes: Each estimate represents the cross-sectional diﬀerence in the outcome variable, comparing non-triplicate states relative
to triplicate states, for the available years of the index (1999-2015). The outcome is the Pardo (2017) index of PDMP strength.
95% conﬁdence intervals generated using wild bootstrap clustered by state. We select on states with any type of PDMP in
1996.

60

Figure A11: Diﬀerences in Other Deaths of Despair by Triplicate State Status

Estimate

95% Confidence Interval

Estimate

A: Suicides

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

83
19

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

19

83

−2

−10

Coefficient Estimate
0
2

Coefficient Estimate
−5
0

5

4

Main Estimates

95% Confidence Interval

B: Alcohol-Related Liver Diseases

Coefficient Estimate
0

19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

−2

−1

Coefficient Estimate
0
1

2

5

3

Detrended

Estimate

95% Confidence Interval

Estimate

C: Suicides

95% Confidence Interval

D: Alcohol-Related Liver Diseases

Notes: We use geocoded NVSS data to construct suicides (excluding those involving overdoses) and alcohol-related liver disease
deaths per 100,000. These ﬁgures report event study estimates from a population-weighted regression which includes state and
year ﬁxed eﬀects. 95% conﬁdence intervals are generated using a clustered (at state) wild bootstrap. Estimates are normalized
to 0 in 1995. In Panel C and D, we show estimates after detrending. We detrend by ﬁrst estimating a model with state ﬁxed
eﬀects, year ﬁxed eﬀects, and a linear time trends interacted with non-triplicate status. This model is estimated using only
pre-1996 data. We then subtract oﬀ the value of the trend term multiplied by the estimated coeﬃcient for the entire period.
This detrended variable is used as the outcome to estimate the event study.

61

Year
Estimate

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

83
19

16
20

14
20

12
20

10
20

08
20

06
20

04
20

02
20

20

00

−10

0

Coefficient Estimate
.5
1

Difference in Overdoses
0
10
20

1.5

30

Figure A12: Event Study: Comparing States with Low Initial Oxycodone Prescribing

Year
95% Confidence Interval

Estimate

A: OxyContin Distribution

95% Confidence Interval

B: Overdose Deaths per 100,000

Notes: We compare “low oxycodone” non-triplicate states to triplicate states. “Low oxycodone” states are deﬁned as in terms
of oxycodone Medicaid prescriptions per 1,000 beneﬁciaries in 1991-1995. Figure A relies on ARCOS data for 2000-2016. Figure
B uses mortality data for 1983-2017. All speciﬁcations include state and time ﬁxed eﬀects. Conﬁdence intervals are generated
by a wild bootstrap.

62

16
20

14
20

12
20

10
20

08
20

06
20

04
20

02
20

20

00

0

Median Per Capita OxyContin Supply
Morphine Equivalent Doses
.5
1
1.5
2

Figure A13: Median OxyContin Supply for Never-Triplicates, Former-Triplicates, and 1996
Triplicates

Year
Never Triplicates
Former Triplicates
1996 Triplicates

Notes: We calculate the median OxyContin distribution, measured in morphine equivalent doses, using the ARCOS data by
former and 1996 triplicate status.

63

OxyContin Payments / All Payments
.0001
.0002
.0003

.0004

Figure A14: OxyContin Promotional Payments to Physicians – Scaled by Total Size of
Payments in State

Former Triplicates

Never Triplicates

20
16

20
15

20
14

20
13

0

Triplicates

Year

Notes: We used CMS Open Payments Data to calculate total payments and gifts made to physicians regarding OxyContin. We
scaled this measure by total payments and gifts made to physicians across all drugs. The outcomes correspond to August 2013
– December 2016.

200
Year Relative to Triplicate Repeal
Estimate

5+

4

3

2

1

0

−1

−2

−400

+
−3

5+

4

3

2

1

0

−1

−2

−3

+

−150

−100

Coefficient Estimate
−200
0

Coefficient Estimate
−50
0
50

100

Figure A15: Event Study: Eﬀects of Triplicate Repeal

Year Relative to Triplicate Repeal

95% Confidence Interval

Estimate

A: OxyContin Prescriptions

95% Confidence Interval

B: Oxycodone Prescriptions

Notes: We study Medicaid OxyContin and oxycodone prescriptions per 1,000 beneﬁciaries. We exclude the former triplicate
states since they repealed prior to OxyContin’s introduction. The sample period for OxyContin prescriptions is 1996-2005; the
sample for oxycodone prescriptions is 1991-2005. We include state and time ﬁxed eﬀects in addition to the time-relative-to-event
indicators. Conﬁdence intervals are generated by a wild bootstrap.

64

Appendix Tables
Table A1: Robustness Tests: Opioid-Related Overdose Deaths per 100,000
Non-Triplicate ×
1996-2000
2001-2010
2011-2017
Joint P-Value
Mean 1991-1995
N

Baseline
Results

Select on
Population Size

Select on PDMP
States in 1996

Control for
Policy Variables

(1)
0.821*
[-0.154, 1.892]
2.766**
[0.042, 4.918]
4.789***
[1.893, 6.879]
0.018
1.476
1,377

(2)
2.880**
[0.973, 5.496]
5.798***
[2.632, 8.877]
6.946*
[-1.036, 14.747]
0.042
1.881
216

(3)
1.032
[-0.802, 2.867]
4.374***
[1.311, 7.436]
7.590***
[4.533, 10.647]
0.009
2.050
405

(4)
1.297*
[-0.235, 2.729]
3.396*
[-0.255, 5.661]
5.712***
[1.962, 8.192]
0.023
1.476
1,377

Notes: ***Signiﬁcance 1%, **Signiﬁcance 5%, *Signiﬁcance 10%. Outcome is opioid overdose deaths per 100,000. The reported
coeﬃcients refer to the interaction of the given time period and an indicator for whether the state did not have a triplicate
program in 1996. Estimates are relative to pre-period 1991-1995. 95% conﬁdence intervals reported in brackets are estimated by
wild bootstrap. All models include state and year ﬁxed eﬀects and time-varying covariates (see Table 3 for details). Column (1)
repeats the column 3 results from Table 3. Column (2) selects on the four non-triplicate states with the largest populations in
1990 along with the four largest triplicate states. Column (3) selects on states with some form of PDMP (triplicate, duplicate,
electronic) in 1996. Column (4) includes policy controls for PDMPs (any PDMP and electronic PDMP), “must access” PDMPs,
pain clinic regulation, medical marijuana laws, and operational/legal medical marijuana dispensaries. “Joint P-Value” refers to
the p-value from a joint hypothesis test that all three non-triplicate post eﬀects are equal to zero and is also estimated using a
restricted wild bootstrap.

65

Table A2: Initial State Oxycodone Prescribing Prevalence, 1991-1995
State

Medicaid Prescriptions per 1,000 Benes
(1991-1995)

Texas
Illinois
California
Kentucky
Michigan
New York
Idaho
Indiana
Washington
South Dakota
Rhode Island
Arkansas
Minnesota
Mississippi
Iowa
Oklahoma
North Dakota
Nebraska
Tennessee
Alabama
South Carolina
District Of Columbia
Kansas
Georgia
Missouri
West Virginia
Oregon
Florida
North Carolina
Louisiana
Ohio
Wyoming
Wisconsin
Virginia
Colorado
Nevada
New Jersey
New Mexico
Pennsylvania
Hawaii
Delaware
Montana
Utah
Alaska
Maryland
Maine
New Hampshire
Vermont
Massachusetts
Connecticut
Arizona

1.684214
2.726036
7.61223
8.034977
10.25393
11.24532
19.17949
21.00094
21.43061
22.43416
23.02265
25.87149
26.95233
27.55857
30.33542
30.39548
30.90121
34.75153
36.05626
36.32855
38.62302
39.77379
40.51961
40.60681
41.19653
42.2592
43.85831
44.15401
44.5726
45.27365
45.36346
52.09373
56.44076
61.32657
62.02119
62.78103
65.51067
68.59366
69.93497
72.25409
74.05332
76.1264
91.15158
93.21341
97.37042
111.5184
125.8811
131.2651
132.7475
133.5888
No Data

Notes: This table sorts states by Medicaid oxycodone prescriptions per 1,000 beneﬁciaries for
1991-1995. Triplicate states as of 1996 are bolded; former triplicate states are italicized. In a few
circumstances, states are missing data for one or more quarters within a year. In these cases, we
annualize the data within that year by multiplying the number of prescriptions by four divided by
the number of quarters in the data. If a state is missing data for an entire year, we simply take
the average over the years with data.

66

Table A3: Initial State Oxycodone Prescribing Prevalence, 1995
State

Medicaid Prescriptions per 1,000 Benes
(1995)

Texas
Illinois
California
Michigan
Kentucky
New York
Idaho
South Dakota
Indiana
Arkansas
Mississippi
Oregon
Minnesota
Iowa
Oklahoma
North Dakota
Alabama
Florida
Georgia
Rhode Island
South Carolina
Wyoming
Missouri
District Of Columbia
Kansas
Louisiana
North Carolina
Nebraska
West Virginia
Ohio
Nevada
New Jersey
Washington
Virginia
New Mexico
Wisconsin
Hawaii
Pennsylvania
Montana
Utah
Delaware
Alaska
Maryland
Vermont
Connecticut
Maine
Massachusetts
New Hampshire
Colorado
Tennessee
Arizona

1.437183
2.27907
9.870143
9.947494
12.64413
12.85399
17.5283
17.94079
24.38553
26.55574
27.12157
29.42524
30.09379
31.56931
34.66857
34.84678
37.23684
38.72538
39.09127
39.72491
41.21292
42.08354
42.2024
43.54829
45.58431
46.14725
48.32907
49.51213
50.46479
50.68425
53.44331
60.28119
61.43809
63.08407
63.87621
66.39986
72.76386
77.99833
79.24383
82.10937
88.18026
95.17448
114.2299
133.3962
146.5896
148.8184
156.795
157.518
No Data
No Data
No Data

Notes: This table sorts states by Medicaid oxycodone prescriptions per 1,000 beneﬁciaries for
1995. Triplicate states as of 1996 are bolded; former triplicate states are italicized. In a few
circumstances, states are missing data for one or more quarters in 1995. In these cases, we
annualize the data within that year by multiplying the number of prescriptions by four divided by
the number of quarters in the data.

67

B. Additional Robustness Tests
We explore the robustness of our main results to including additional controls. First, Jaeger
et al. (2018) suggest that it may be important in diﬀerence-in-diﬀerences analyses to permit the control variables to have diﬀerent eﬀects over time. We interact a subset of our
covariates with year indicators to allow for this additional ﬂexibility.1 The estimates, presented in Appendix Table B1, generally increase in magnitude when these interactions are
included.
Next, we study the role of economic conditions and labor demand shocks. These
results are included in Appendix Table B2. First, we include the annual unemployment rate
(from the Bureau of Labor Statistics) as a control in Column (1). While this covariate is potentially endogenous if opioid misuse aﬀects labor supply, the estimates are generally larger
in magnitude. Next, we control for economic shocks that provide an exogenous source of
variation in economic conditions. Charles et al. (2019) use a shift-share (Bartik) instrument
to predict changes in manufacturing employment share, ﬁnding that reductions in manufacturing jobs increase drug overdose rates. We construct a shift-share instrument using
the Current Population Study, ﬁxing industry composition by state at its 1995 levels, and
interacting these 1995 compositions with national-level industry-speciﬁc employment levels
(excluding each state’s own employment). Column (2) of Table B2 presents the results for
overdose deaths per 100,000, controlling for this variable. The results are not meaningfully
aﬀected by the inclusion of this extra control. In Column (3), we add a shift-share instrument
related to all industries (similar to Betz and Jones (2018)). The inclusion of both shift-share
measures permits manufacturing shifts to have diﬀerential eﬀects relative to broader labor
demand shocks. Again, the results are similar.
Finally, Pierce and Schott (forthcoming) show that areas disproportionately harmed
by international trade policy (speciﬁcally, the granting of Permanent Normal Trade Relations
(PTNR) by the United States to China in 2000), experienced faster growth in fatal drug
overdoses and other deaths of despair. We interact their metric of exposure to trade liberation
with year indicators. The results are generally unaﬀected when we control for these variables.
Columns (5)-(8) provide the same sensitivity tests for opioid overdose deaths.
In addition, we estimate our event study in equation (1) controlling for the PierceSchott measure of exposure to trade policy interacted with year ﬁxed eﬀects. Figure B1
shows the estimates for the non-triplicate interaction terms (Panels A and C) and the trade
policy interaction terms (Panels B and D) estimated jointly. The non-triplicate pattern is
unaﬀected by the inclusion of the trade exposure variable, suggesting that our main estimates
are not driven by diﬀerential exposure to PTNR.
1

We use only a subset since this approach adds a considerable amount of controls to the regression so
there may be concerns of overﬁtting. We included covariates which varied substantially across triplicate and
non-triplicate states in Table 1: fraction non-Hispanic white, fraction non-Hispanic black, fraction Hispanic,
and log of population.

68

Finally, in Table 1, we found notable diﬀerences in cocaine overdoses between triplicate and non-triplicate states for the baseline period 1991-1995. In Appendix Figure B2,
we present event study estimates for cocaine overdoses, excluding opioids. We observe a
transitory decline in cocaine overdoses in non-triplicate states relative to triplicate states
prior to 1996. However, in general, we observe little evidence of any long-term relationship
between triplicate status and cocaine overdoses, and it does not match the pattern observed
for overdoses more generally or overdoses involving opioids.
Given the initial diﬀerences in cocaine overdoses, we test whether cocaine overdoses
are confounding our estimates. In Appendix Figure B3, we present results for overdoses
excluding cocaine (Panel A) and opioid-related overdoses excluding cocaine (Panel B). The
results are generally unaﬀected by excluding cocaine. The estimates decrease in magnitude since we are excluding overdoses potentially impacted by OxyContin exposure, but
the patterns are similar to the main event studies. In Panel C of Appendix Figure B3, we
study opioid overdoses but exclude unspeciﬁed narcotics. Again, the results are generally
unaﬀected.

69

Figure B1: Event Study: Controlling for Pierce-Schott Trade Exposure Eﬀect

Estimate

Estimate

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

95% Confidence Interval

19

83

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

19

83

−5

−.5

0

Coefficient Estimate
5
10

Coefficient Estimate
0
.5
1

15

1.5

Overdose Deaths per 100,000

95% Confidence Interval

Estimate

19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

−.5

0

Coefficient Estimate
0
.5
1

Coefficient Estimate
5
10

1.5

15

A: Non-Triplicate Eﬀect
B: Trade Eﬀect
Opioid Overdose Deaths per 100,000

95% Confidence Interval

Estimate

C: Non-Triplicate Eﬀect

95% Confidence Interval

D: Trade Eﬀect

Notes: We use geocoded NVSS data to construct overdose and opioid overdose deaths per 100,000. See text for exact ICD codes
used in each period. Panels A and B are estimated jointly. Panel A shows the non-triplicate eﬀect; Panel B shows the eﬀect
of exposure to trade liberalization. Panels C and D are also estimated jointly. Trade policy changed in 2000 and the exposure
to the policy is deﬁned in the same manner as Pierce and Schott (forthcoming). All regressions include state and year ﬁxed
eﬀects. 95% conﬁdence intervals are generated using a clustered (at state) wild bootstrap. All estimates are normalized to 0 in
1995.

70

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

Estimate

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

19

83

−1

Coefficient Estimate
−.5
0
.5

1

Figure B2: Event Study: Cocaine Overdose Death Rates, Excluding Opioids

95% Confidence Interval

Notes: We use geocoded NVSS data to construct cocaine overdose deaths (excluding opioids) per 100,000. We report event
study estimates from a regression which includes state and year ﬁxed eﬀects. 95% conﬁdence intervals are generated using a
clustered (at state) wild bootstrap. Estimates are normalized to 0 in 1995.

71

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

−5
19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

0

Coefficient Estimate
5
10

Coefficient Estimate
0
5

15

10

Figure B3: Event Studies: Excluding Cocaine or Unspeciﬁed Category

Estimate
Estimate

95% Confidence Interval

95% Confidence Interval

B: Opioid overdose deaths excluding
cocaine

Estimate

7

5

20
1

3

20
1

1

20
1

9

20
1

7

20
0

20
0

5

20
0

3

1

20
0

9

20
0

7

19
9

5

19
9

3

19
9

1

19
9

9

19
9

7

19
8

5

19
8

19
8

19
8

3

−5

0

Coefficient Estimate
5
10

15

A: Overdose deaths excluding cocaine

95% Confidence Interval

C: Opioid overdose deaths excluding T40.6
Notes: We use geocoded NVSS data to construct overdose deaths per 100,000. In Panel A and B, we exclude overdoses also
involving cocaine. In Panel C, we study opioid-speciﬁc overdose deaths excluding unspeciﬁed narcotics (coded T40.6 in ICD-10).
Event study estimates include state and year ﬁxed eﬀects. 95% conﬁdence intervals are generated using a clustered (at state)
wild bootstrap. Estimates are normalized to 0 in 1995.

72

Table B1: Diﬀerence-in-Diﬀerences Analyses: Interacting Covariates with Year Indicators
Outcome:
Non-Triplicate ×

Overdoses
(1)

Opioid Overdoses
(2)

1996-2000

2.277***
[0.478, 4.051]
5.747**
[1.477, 10.082]
6.769***
[3.938, 10.339]
0.009

1.442**
[0.083, 2.751]
3.558**
[0.548, 6.679]
3.619**
[0.678, 7.141]
0.143

2001-2010
2011-2017
Joint P-Value

Notes: N = 1,377. ***Signiﬁcance 1%, **Signiﬁcance 5%, *Signiﬁcance 10%. Outcomes are overdose and
opioid overdose deaths per 100,000 people. The reported coeﬃcients refer to the interaction of the given
time period and an indicator for whether the state did not have a triplicate program in 1996. Estimates
are relative to pre-period 1991-1995. 95% conﬁdence intervals reported in brackets are estimated by wild
bootstrap. All models include state and year ﬁxed eﬀects. We also interact fraction non-Hispanic white,
fraction non-Hispanic black, fraction Hispanic, and log of population with year indicators. This approach
permits these covariates to have a diﬀerent relationship with the outcomes in each year. We limit the
covariates in these regressions to those which vary the most across the triplicate and non-triplicate states
given that they are each interacted with year dummies. “Joint P-Value” refers to the p-value from a joint
hypothesis test that all three non-triplicate post eﬀects are equal to zero and is also estimated using a
restricted wild bootstrap.

73

Table B2: Diﬀerence-in-Diﬀerences Analyses: Controlling for Unemployment and Economic
Shocks
Non-Triplicate ×
1996-2000
2001-2010
2011-2017
Joint P-Value
Non-Triplicate ×
1996-2000

(1)

Overdose Deaths per 100,000
(2)
(3)

(4)

1.004*
1.100**
0.952*
1.154**
[-0.135, 2.687] [0.013, 2.653] [-0.055, 2.436] [0.204, 2.620]
3.921**
4.235**
4.179**
4.486**
[1.240, 6.694] [1.421, 6.934] [1.396, 6.790] [1.648, 7.267]
6.770***
6.937***
6.841***
6.953***
[4.384, 8.689] [4.408, 8.878] [4.342, 8.771] [4.536, 8.876]
0.001
0.001
0.002
0.001
Opioid Overdose Deaths per 100,000
(5)

0.814*
[-0.136, 1.871]
2001-2010
2.750**
[0.205, 4.974]
2011-2017
4.779***
[1.857, 6.896]
Joint P-Value
0.017
Unemployment Rate
Yes
Bartik Manufacturing
No
Bartik All Industries
No
Trade Exposure
No

(6)
0.829*
[-0.181, 1.915]
2.762**
[0.050, 4.917]
4.791***
[1.859, 6.884]
0.020
No
Yes
No
No

(7)

(8)

0.857*
0.964**
[-0.051, 1.939] [0.163, 2.009]
2.773**
3.096**
[0.046, 4.951] [0.453, 5.316]
4.809***
4.889***
[1.913, 6.935] [2.120, 6.943]
0.017
0.011
No
No
Yes
Yes
Yes
Yes
No
Yes

Notes: N = 1,377. ***Signiﬁcance 1%, **Signiﬁcance 5%, *Signiﬁcance 10%. Outcomes are overdose and
opioid overdose deaths per 100,000. The reported coeﬃcients refer to the interaction of the given time period
and an indicator for whether the state did not have a triplicate program in 1996. Estimates are relative to
pre-period 1991-1995. 95% conﬁdence intervals reported in brackets are estimated by wild bootstrap. All
models include state and year ﬁxed eﬀects as well as the fraction non-Hispanic white, fraction non-Hispanic
black, fraction Hispanic, log of population, fraction with college degree, fraction ages 25-44, fraction ages
45-64, and fraction ages 65+. In Columns (1) and (5), we add the unemployment rate. In the rest of the
columns, we include labor demand shocks. First, we include a shift-share instrument related speciﬁcally to
manufacturing. Next, we also add a more general shift-share instrument which uses all industries. Finally,
we also include a measure of exposure to trade interacted with year dummies. “Joint P-Value” refers to the
p-value from a joint hypothesis test that all three non-triplicate post eﬀects are equal to zero and is also
estimated using a restricted wild bootstrap.

74

C. Alternative Inference Methods
In this section, we consider the sensitivity of our results to alternative statistical inference
methods. First, we show our main results with cluster-robust standard errors, the most commonly used method for accounting for serial correlation within states. This method may produce standard errors that are too small when there are too few clusters (or treated/untreated
units). These results are presented in Appendix Table C1. As expected, conﬁdence intervals
are much tighter when using this traditional approach.
We also compute p-values using permutation-style tests. We randomly-assign triplicate status to 5 non-triplicate states and re-estimate equation (2). We repeat this procedure
10,000 times. In each permutation, we estimate the t-statistic for each of the three postperiods. Then we compare the placebo estimates to the non-triplicate t-statistic when the
5 triplicate states are correctly assigned and determine the rank. This approach is recommended in MacKinnon and Webb (forthcoming). In Appendix Figure C1, we show the
distribution of the placebo t-statistics for each of the three time periods while marking the
2.5 and 97.5 percentiles with vertical dashed lines. The actual estimate is shown as a solid
line. We also report the rank of this t-statistic (one-sided test) and the rank of the absolute
value of the t-statistic (two-sided test). We ﬁnd that it is statistically rare to observe our
main overdose patterns for triplicate versus non-triplicate states using other combinations of
states. For the earliest time period (1996-2000), the coeﬃcient for non-triplicate states ranks
239 out of 10,000 (statistically signiﬁcant at the 5% level). For later time periods, the nontriplicate estimate ranks second and ﬁrst out of 10,000, respectively. When we jointly test
the estimates for the three time periods, we ﬁnd that it is extremely rare to observe three
t-statistics at the magnitude observed for our main eﬀects. Appendix Figure C2 repeats
this exercise but creates a distribution of placebo coeﬃcient estimates instead of t-statistics.
Again, the observed pattern of results is statistically rare.

75

Figure C1: Permutation Tests using T-Statistics

−6

−5

−4

−3

−2

−1

0

1

2

3

4

.08
Fraction
.06
.04
.02
0

0

0

.02

.02

.04

Fraction
.04

Fraction
.06

.06

.08

.1

.1

.08

Overdose Deaths per 100,000

−7

−6

−5

−4

−3

−2

−1

0

1

2

Rank of T1 : 239/10,000
Rank of |T1 |: 743/10,000

Rank of T2 : 2/10,000
Rank of |T2 |: 78/10,000

A: 1996-2000

B: 2001-2010

(k)
Joint Test (one-sided): P̂ (T1 < T1 , T2
(k)
Joint Test (two-sided): P̂ (|T1 | < |T1 |, |T2 |

3

4

−8 −7 −6 −5 −4 −3 −2 −1

0

1

2

3

4

5

6

7

8

Rank of T3 : 1/10,000
Rank of |T3 |: 3/10,000

C: 2011-2017
<
<

(k)
(k)
T2 , T3 < T3 ) = 0.0000
(k)
(k)
|T2 |, |T3 | < |T3 |) = 0.0000

−5

−4

−3

−2

−1

0

1

2

3

4

.4
0

.1

Density
.2

.3

.4
.3
Density
.2
.1
0

0

.1

Density
.2

.3

.4

Opioid Overdose Deaths per 100,000

−6

−5

−4

−3

−2

−1

0

1

2

Rank of T1 : 279/10,000
Rank of |T1 |: 1010/10,000

Rank of T2 : 79/10,000
Rank of |T2 |: 478/10,000

D: 1996-2000

E: 2001-2010

(k)
Joint Test (one-sided): P̂ (T1 < T1 , T2
(k)
Joint Test (two-sided): P̂ (|T1 | < |T1 |, |T2 |

3

4

−8

−6

−4

−2

0

2

4

Rank of T3 : 1/10,000
Rank of |T3 |: 50/10,000

F: 2011-2017
<
<

(k)
(k)
T2 , T3 < T3 ) = 0.0000
(k)
(k)
|T2 |, |T3 | < |T3 |) = 0.0004

Notes: The dashed vertical lines represent the 2.5 and 97.5 percentiles of the placebo t-statistics. The solid blue vertical line is
the t-statistic when the ﬁve triplicate states are assigned correctly. The x-axis represents the value of the t-statistics; the y-axis
represents the density. Estimating equation (2), regressions include state and time ﬁxed eﬀects as well as fraction non-Hispanic
white, fraction non-Hispanic black, fraction Hispanic, log of population, fraction with college degree, fraction ages 25-44, fraction
ages 45-64, and fraction ages 65+. t-statistics are calculated using clustered (by state) standard errors as recommended by
MacKinnon and Webb (forthcoming). In the joint tests, k indexes the placebo t-statistics.

76

Figure C2: Permutation Tests using Coeﬃcient Estimates

−4

−3

−2

−1

0

1

2

.08
.06
Fraction
.04
.02
0

0

0

.02

.02

Fraction
.04

Fraction
.04

.06

.06

.08

.08

Overdose Deaths per 100,000

−9

−7

−5

−3

−1

0

1

3

Rank of δ1 : 356/10,000
Rank of |δ1 |: 2228/10,000

Rank of δ2 : 1/10,000
Rank of |δ2 |: 760/10,000

A: 1996-2000

B: 2001-2010

(k)
Joint Test (one-sided): P̂ (δ1 < δ1 , δ2
(k)
Joint Test (two-sided): P̂ (|δ1 | < |δ1 |, |δ2 |

−14

−12

−10

−8

−6

−4

−2

0

2

4

6

Rank of δ3 : 1/10,000
Rank of |δ3 |: 188/10,000

C: 2011-2017
<
<

(k)
(k)
δ2 , δ3 < δ3 ) = 0.0000
(k)
(k)
|δ2 |, |δ3 | < |δ3 |) = 0.0053

−3

−2

−1

0

1

2

Density
0

0

0

.05

.05

.2

.1

Density

Density
.15

.1

.4

.2

.15

.6

.25

Opioid Overdose Deaths per 100,000

−10

−9

−8

−7

−6

−5

−4

−3

−2

−1

0

1

Rank of δ1 : 421/10,000
Rank of |δ1 |: 2544/10,000

Rank of δ2 : 27/10,000
Rank of |δ2 |: 1562/10,000

D: 1996-2000

E: 2001-2010

(k)
Joint Test (one-sided): P̂ (δ1 < δ1 , δ2
(k)
Joint Test (two-sided): P̂ (|δ1 | < |δ1 |, |δ2 |

2

3

−15

−12

−9

−6

−3

0

3

6

Rank of δ3 : 4/10,000
Rank of |δ3 |: 939/10,000

F: 2011-2017
<
<

(k)
(k)
δ2 , δ3 < δ3 ) = 0.0000
(k)
(k)
|δ2 |, |δ3 | < |δ3 |) = 0.0259

Notes: The dashed vertical lines represent the 2.5 and 97.5 percentiles of the placebo estimates. The solid blue vertical line is
the coeﬃcent estimate when the ﬁve triplicate states are assigned correctly. The x-axis represents the value of the coeﬃcient
estimates; the y-axis represents the density. Estimating equation (2), regressions include state and time ﬁxed eﬀects as well
as fraction non-Hispanic white, fraction non-Hispanic black, fraction Hispanic, log of population, fraction with college degree,
fraction ages 25-44, fraction ages 45-64, and fraction ages 65+. In the joint tests, k indexes the placebo estimates.

77

Table C1: Table 3 with Clustered (not bootstrapped) Conﬁdence Intervals
Non-Triplicate ×

(1)

1996-2000

Weighted
Covariates
Region-Time Dummies
N

1.244***
[0.495, 1.994]
3.758***
[1.918, 5.597]
6.248***
[3.637, 8.860]
No
No
No
1,377

Non-Triplicate ×

(5)

1996-2000

0.702**
[0.147, 1.257]
2.675***
[1.320, 4.030]
5.133***
[2.381, 7.885]
No
No
No
1,377

2001-2010
2011-2017

2001-2010
2011-2017
Weighted
Covariates
Region-Time Dummies
N

Overdose Deaths per 100,000
(2)
(3)
1.323***
[0.626, 2.021]
4.566***
[2.856, 6.275]
7.903***
[5.349, 10.457]
Yes
No
No
1,377

1.125**
[0.034, 2.217]
4.221***
[2.074, 6.368]
6.944***
[5.103, 8.786]
Yes
Yes
No
1,377

Opioid Overdose Deaths per 100,000
(6)
(7)
0.631**
[0.066, 1.197]
2.993***
[1.689, 4.297]
5.946***
[3.036, 8.855]
Yes
No
No
1,377

0.821*
[-0.041, 1.684]
2.766***
[0.844, 4.689]
4.789***
[2.811, 6.766]
Yes
Yes
No
1,377

(4)
1.452***
[0.508, 2.397]
4.445***
[2.976, 5.913]
6.816***
[5.012, 8.620]
Yes
Yes
Yes
1,377
(8)
1.044**
[0.232, 1.856]
3.011***
[1.490, 4.532]
4.543***
[2.700, 6.386]
Yes
Yes
Yes
1,377

Notes: ***Signiﬁcance 1%, **Signiﬁcance 5%, *Signiﬁcance 10%. This table replicates Table
3 while reporting traditional clustered 95% conﬁdence intervals instead of those generated by a
wild bootstrap. The reported coeﬃcients refer to the interaction of the given time period and an
indicator for whether the state did not have a triplicate program in 1996. Estimates are relative
to pre-period 1991-1995. All models include state and year ﬁxed eﬀects. Covariates include the
fraction non-Hispanic white, fraction non-Hispanic black, fraction Hispanic, log of population,
fraction with college degree, fraction ages 25-44, fraction ages 45-64, and fraction ages 65+.

78

D. Synthetic Control Estimates
While we observed little evidence of pre-existing trends in our results, the triplicate states
did begin with higher levels of overdoses. One way to address diﬀerences in pre-treatment
levels is to construct synthetic controls for each treated state using the synthetic control
method (Abadie et al. (2010, 2015)).2 Here, we estimate synthetic controls for each triplicate state using non-triplicate states as potential components of the synthetic controls. In
our diﬀerence-in-diﬀerences analyses, we aggregate overdoses to the annual level since all of
our time-varying covariates only vary annually and since diﬀerence-in-diﬀerences only uses
the (adjusted) means. Synthetic control estimation, however, beneﬁts from the additional
information in more disaggregated data (even if serially-correlated) so we use quarterly overdoses rates here.3
The “treatment” is triplicate state status in 1996 (unlike the prior analyses where
the treatment was non-triplicate state status in 1996) since it makes more sense to use
the 46 non-triplicate states to construct synthetic controls for the 5 triplicate states than
vice versa. We then present the negative of the average weighted diﬀerence in the triplicate
states relative to their synthetic controls, where the weights are the inverse of the variance in
the pre-treatment period. This approach upweights states with more appropriate synthetic
controls. The negative sign makes the estimates comparable to those presented throughout
the paper. We also present the time series overdose rates for the triplicate and synthetic
triplicate states, using these same weights. Thus, the time series trends will not match those
shown earlier in the paper.
The results are shown in Figure D1. The synthetic control weights are shown in Table
D2. We estimate similar overdose reductions as our main estimates. These estimates are
summarized for our three aggregate time periods in Table D1. We multiply these estimates
by 4 to make them comparable to the annual estimates in the main text. For inference,
we use a permutation test, randomly-assigning triplicate status to non-triplicate states and
then reporting the rank of the main estimate to the 999 placebo estimates. The estimates
are similar to the diﬀerence-in-diﬀerences estimates and generally statistically signiﬁcant at
the 1% level. These results suggest that our main estimates are not driven by any initial
outcome diﬀerences in overdose rates between the triplicate and non-triplicate states.

2

Concerns about synthetic control estimation and some possible modiﬁcations are discussed in BenMichael et al. (2018); Arkhangelsky et al. (2019); Abadie (forthcoming); Powell (2018); Ferman and Pinto
(2016); Doudchenko and Imbens (2016) among others. We use the traditional approach here.
3
Given that we have a relatively long pre-period consisting of 52 quarters, we are less concerned about
overﬁtting in this context and construct the synthetic controls based on the value of the outcome in each
quarter in the pre-period.

79

17

15

17

15

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

19

Synthetic Triplicate States

19

19

83

Year
Triplicate States

85

20

13

20

11

20

09

20

07

20

05

20

03

20

01

20

99

20

97

19

95

19

93

19

91

19

89

19

87

19

85

19

19

19

83

0

0

Difference in Overdoses per 100,000
.5
1
1.5

Overdose Deaths per 100,000
2
4

2

6

Figure D1: Synthetic Control Results: Overdose Deaths

Year

A: Triplicate and Synthetic Triplicate States

B: Diﬀerence

7

0

20
1

5

3

20
1

1

20
1

20
1

9

20
0

7

20
0

5

3

20
0

20
0

1

20
0

9

19
9

7

5

19
9

3

19
9

19
9

1

19
9

9

19
8

7

5

19
8

19
8

19
8

3

0

Difference in Opioid Overdoses per 100,000
1
2
3

Opioid Overdose Deaths per 100,000
1
2
3
4
5

Synthetic Control Results: Opioid Overdose Deaths

19
83
19
85
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
20
09
20
11
20
13
20
15
20
17

Year
Triplicate States

Synthetic Triplicate States

Year

C: Triplicate and Synthetic Triplicate States

D: Diﬀerence

Notes: We construct a synthetic control for each triplicate state. We then take a weighted (by the “ﬁt” of the synthetic control
before 1996) average of the triplicate states and a weighted average of the synthetic control. These are plotted in Panel A (and
C). The diﬀerence is shown in Panel B (and D). See Table D2 for the synthetic control weights.

80

Table D1: Synthetic Control Results
Non-Triplicate ×

Overdoses per 100,000

Opioid Overdoses per 100,000

1996-2000

1.099
[1/1000]
3.201
[1/1000]
5.405
[2/1000]

0.415
[149/1000]
2.230
[8/1000]
6.954
[1/1000]

2001-2010
2011-2017

Notes: We estimated synthetic controls for each triplicate state and report the weighted average of the
synthetic control outcomes (which are non-triplicates) minus the triplicate state outcomes. We annualized
the quarterly estimates by multiplying by four. The weights are the inverse of the variance before 1996. This
approach considers the triplicate states as “treated” given that it would be diﬃcult to construct synthetic
controls for each non-triplicate state using only the 5 triplicate states. Below each estimate, we report
the rank of that estimate relative to the 999 placebo estimates and the main estimate itself, produced by
randomly-assigning states to “triplicate” status and repeating the entire strategy. We multiply the point
estimates by four to make the quarterly estimates comparable to the annual estimates in the main text.

81

82

0
0
0
0
0
0
0
0.184
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.562
0
0
0.091
0
0
0
0
0.163
0
0
0
0
0
0
0
0
0
0
0
0
0.112

ALABAMA
ALASKA
ARIZONA
ARKANSAS
COLORADO
CONNECTICUT
DELAWARE
DISTRICT OF COLUMBIA
FLORIDA
GEORGIA
HAWAII
INDIANA
IOWA
KANSAS
KENTUCKY
LOUISIANA
MAINE
MARYLAND
MASSACHUSETTS
MICHIGAN
MINNESOTA
MISSISSIPPI
MISSOURI
MONTANA
NEBRASKA
NEVADA
NEW HAMPSHIRE
NEW JERSEY
NEW MEXICO
NORTH CAROLINA
NORTH DAKOTA
OHIO
OKLAHOMA
OREGON
PENNSYLVANIA
RHODE ISLAND
SOUTH CAROLINA
SOUTH DAKOTA
TENNESSEE
UTAH
VERMONT
VIRGINIA
WASHINGTON
WEST VIRGINIA
WISCONSIN
WYOMING

“Fit” Weight

0.304

0
0
0
0
0
0
0.06
0
0
0
0
0
0.227
0
0
0
0
0.082
0
0
0
0
0
0
0.273
0
0
0.07
0
0.036
0
0
0
0
0
0
0
0
0
0
0
0.247
0
0
0
0.006

IDAHO

1.226

0
0.075
0
0
0
0
0.006
0.023
0.082
0
0
0
0
0
0
0
0
0.061
0
0
0
0
0
0
0.132
0
0
0
0.147
0.032
0
0
0
0.15
0
0
0
0
0.034
0.092
0.043
0
0
0.124
0
0

Overdoses
ILLINOIS

0.342

0
0
0
0
0
0.285
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.051
0
0
0
0.346
0
0
0
0.121
0
0
0
0
0
0
0
0
0
0
0.057
0
0.141

NEW YORK

1.952

0
0.071
0
0.121
0
0
0
0
0
0
0
0.042
0.095
0
0
0
0
0
0
0
0
0.069
0
0.036
0.053
0
0.069
0
0.121
0.002
0
0
0.008
0.057
0.065
0
0.142
0.022
0
0
0
0
0
0
0
0.027

TEXAS

0.189

0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.386
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.614
0
0
0

CALIFORNIA

3.165

0.49
0
0
0.083
0
0
0
0
0
0
0
0
0.042
0
0
0
0
0
0
0
0
0
0
0.167
0
0.066
0
0.009
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.086
0
0.057
0.866

0
0
0.044
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.021
0
0
0
0
0.049
0
0
0
0
0
0.199
0
0.206
0.465
0
0
0.016
0.689

0
0
0
0
0
0.103
0
0
0
0.006
0
0
0
0
0
0
0
0
0.086
0
0
0.118
0
0
0
0
0
0
0.475
0
0
0
0
0
0
0
0
0
0
0.099
0.053
0
0
0
0
0.06

Opioid Overdoses
IDAHO
ILLINOIS
NEW YORK

12.641

0
0
0
0
0
0
0
0
0
0
0
0.192
0
0
0.124
0
0
0
0
0
0.062
0
0.109
0
0.048
0.076
0.038
0
0
0
0.012
0
0
0.07
0.049
0
0.094
0
0
0
0
0
0
0.089
0
0.037

TEXAS

Notes: This table reports the weights assigned to the state in the row to construct a synthetic control for the triplicate state listed in the column
header. Each column adds to one. The last row reports the overall “ﬁt” weight which is used to aggregate the 5 triplicate estimates together based
on the strength of the synthetic control ﬁt (the inverse of the sum of the squares of the diﬀerence between the outcome and the synthetic outcome
in the pre-period).

CALIFORNIA

State

Table D2: Synthetic Control Weights

Appendix References
Abadie, Alberto, “Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects,” Journal of Economic Literature, forthcoming.
, Alexis Diamond, and Jens Hainmueller, “Synthetic control methods for comparative case studies: Estimating the eﬀect of California’s tobacco control program,” Journal
of the American Statistical Association, 2010, 105 (490), 493–505.
, , and , “Comparative politics and the synthetic control method,” American Journal
of Political Science, 2015, 59 (2), 495–510.
Arkhangelsky, Dmitry, Susan Athey, David A Hirshberg, Guido W Imbens, and
Stefan Wager, “Synthetic diﬀerence in diﬀerences,” Technical Report, National Bureau
of Economic Research 2019.
Ben-Michael, Eli, Avi Feller, and Jesse Rothstein, “New perspectives on the synthetic
control method,” Technical Report, Technical report, UC Berkeley 2018.
Betz, Michael R and Lauren E Jones, “Wage and employment growth in America’s drug
epidemic: Is all growth created equal?,” American Journal of Agricultural Economics,
2018, 100 (5), 1357–1374.
Charles, Kerwin Koﬁ, Erik Hurst, and Mariel Schwartz, “The transformation of
manufacturing and the decline in US employment,” NBER Macroeconomics Annual, 2019,
33 (1), 307–372.
Doudchenko, Nikolay and Guido W Imbens, “Balancing, regression, diﬀerence-indiﬀerences and synthetic control methods: A synthesis,” Technical Report, National Bureau of Economic Research 2016.
Ferman, Bruno and Cristine Pinto, “Revisiting the synthetic control estimator,” 2016.
Jaeger, David A, Theodore J Joyce, and Robert Kaestner, “A Cautionary Tale of
Evaluating Identifying Assumptions: Did Reality TV Really Cause a Decline in Teenage
Childbearing?,” Journal of Business & Economic Statistics, 2018, pp. 1–10.
MacKinnon, James G and Matthew D Webb, “Randomization inference for diﬀerencein-diﬀerences with few treated clusters,” Technical Report forthcoming.
Pardo, Bryce, “Do more robust prescription drug monitoring programs reduce prescription
opioid overdose?,” Addiction, 2017, 112 (10), 1773–1783.
Pierce, Justin R and Peter K Schott, “Trade liberalization and mortality: Evidence
from US counties,” American Economic Review: Insights, forthcoming.
Powell, David, “Imperfect Synthetic Controls,” Technical Report, RAND 2018.

83

