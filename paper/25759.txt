NBER WORKING PAPER SERIES

IS BLINDED REVIEW ENOUGH? HOW GENDERED OUTCOMES ARISE EVEN
UNDER ANONYMOUS EVALUATION
Julian Kolev
Yuly Fuentes-Medel
Fiona Murray
Working Paper 25759
http://www.nber.org/papers/w25759

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2019

We are grateful to the Bill and Melinda Gates Foundation for providing access to their internal
data and procedures, and for their overall support. We thank Cecilia Testart Pacheco for her
invaluable assistance with the text analysis portion of the paper. We also thank Pierre Azoulay,
Scott Stern, Philippe Aghion, Ray Reagans, Michael Cima, Joshua Krieger, Daniel Fehder,
Michael Bikard, Annamaria Conti, seminar participants at MIT and NBER, and conference
attendees at the Academy of Management, the American Economic Association, and the REER
conference for their helpful comments and suggestions. The views expressed herein are those of
the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2019 by Julian Kolev, Yuly Fuentes-Medel, and Fiona Murray. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

Is Blinded Review Enough? How Gendered Outcomes Arise Even Under Anonymous Evaluation
Julian Kolev, Yuly Fuentes-Medel, and Fiona Murray
NBER Working Paper No. 25759
April 2019
JEL No. D70,J16,M14,O31,O32
ABSTRACT
For organizations focused on scientific research and innovation, workforce diversity is a key
driver of success. Blinded review is an increasingly popular approach to reducing bias and
increasing diversity in the selection of people and projects, yet its effectiveness is not fully
understood. We explore the impact of blinded review on gender inclusion in a unique setting:
innovative research grant proposals submitted to the Gates Foundation from 2008-2017. Despite
blinded review, female applicants receive significantly lower scores, which cannot be explained
by reviewer characteristics, proposal topics, or ex-ante measures of applicant quality. By contrast,
the gender score gap is no longer significant after controlling for text-based measures of
proposals’ titles and descriptions. Specifically, we find strong gender differences in the usage of
broad and narrow words, suggesting that differing communication styles are a key driver of the
gender score gap. Importantly, the text-based measures that predict higher reviewer scores do not
also predict higher ex-post innovative performance. Instead, female applicants exhibit a greater
response in follow-on scientific output after an accepted proposal, relative to male applicants. Our
results reveal that gender differences in writing and communication are a significant contributor
to gender disparities in the evaluation of science and innovation.
Julian Kolev
Dept. of Strategy and Entrepreneurship
SMU Cox School of Business
6212 Bishop Blvd
Dallas, TX 75275
jkolev@smu.edu

Fiona Murray
MIT Sloan School of Management
100 Main Street, E62-470
Cambridge, MA 02142
and NBER
fmurray@mit.edu

Yuly Fuentes-Medel
yuly@yfuentes-medel.com

A data appendix is available at http://www.nber.org/data-appendix/w25759

I.

Introduction

Diversity and inclusion are key goals for society at large and specifically within the scientific and
innovative communities across corporate, government, and academic organizations (Robinson and
Dechant 1997, Bilimoria et al 2008, Østergaard et al 2011). Diversity of individuals and ideas
leads to better outcomes (Azoulay et al 2011) and higher levels of productivity (Reagans and
Zuckerman 2001). This is particularly important in the context of innovation-driven organizations:
in such contexts, diversity offers not only the usual benefits of greater efficiency as bias is
eliminated, but also the potential to improve an organization’s innovative capacity as individuals
and teams benefit from the introduction of new ideas and perspectives (Tasheva and Hillman
2018). At the core of any attempt to increase diversity and inclusion lies the selection of projects
and people, which are the building blocks for any dimension of diversity. Organizations pursing
these goals must decide how best to structure their internal processes in such a way as to ensure
diversity and inclusion at all stages of selection – hiring (Fernandez and Fernandez-Mateo 2006),
promotion (Castilla and Benard 2010), and resource allocation (Boudreau et al 2016).
Organizations seek to design processes that maximize the selection of the best individuals, teams
and ideas, while minimizing opportunities for biased evaluation (especially bias based on
ascriptive characteristics). A wide range of approaches exist for improving selection: organizations
and individuals have generated superior outcomes by emphasizing objective measures of
candidates’ ability and past performance (Reuben et al 2014), building institutional support for
equality (Monroe et al 2008), mitigating the impact of differences in professional networks (Wold
and Wenneras 2010), increasing the diversity of evaluators (Kunze and Miller 2017), and adopting
accountability and transparency procedures (Castilla 2015).
While the above approaches are beneficial, they usually fall short of fully eliminating biased
evaluation. By contrast, within a variety of settings, blinded review has often been considered as

2

the ‘gold-standard’ process to remove opportunities for bias in evaluation and selection. In the
emerging literature on ‘blinded-ness”, more diverse outcomes have been predicated on the notion
that differences typically emerge from patterns of bias that can be identified from names (on CVs
or scripts, as in McIntyre et al 1980), or in person (musical auditions in Goldin and Rouse 2000,
entrepreneurial pitches in Brooks et al 2014); the introduction of blinded review can lead to a
significant increase in diversity and inclusion (Goldin and Rouse 2000). However, within the
scientific community – the community which pioneered double-blinded review as a central process
used to eliminate the role of biased perception in its own activities – evidence suggests that many
organizational practices do not in fact lead to unbiased evaluations (Shen et al 2013, Witteman et
al 2017). In light of this discrepancy, it is worth considering the impact of blinded review in the
context of innovation and scientific activity, as it seems to be a necessary condition for the
elimination of bias. We attempt to evaluate whether blinded review is sufficient to overcome all
aspects of under-representation, or whether there are significant barriers to diversity that remain
after its implementation.
Our paper explores the degree to which gender shapes outcomes even in a blinded setting, and
seeks to evaluate the drivers of gender disparity in science and innovation, in terms of both access
to key inputs and subsequent output. We take advantage of data covering a blinded grant-review
process from the Bill and Melinda Gates Foundation that has several critical characteristics:
reviewers evaluate anonymous proposals, the reviewing process enables multiple individual
reviewers to provide independent scores, it provides scoring data at the reviewer-proposal level,
and it allows us to trace individual applicants’ later activities through scientific publications, NIH
grant receipts, and other measures of innovation.
Using a sample of 6,794 proposals submitted to the Gates Foundation between 2008 and 2017, we
analyze two major components of the interplay between diversity and innovation. First, we

3

examine the determinants of diversity in innovative organizations, by examining the role of gender
in explaining reviewer evaluations of innovative proposals. Second, we construct a difference-indifference estimator to explore the interaction between funding and applicant gender, in order to
identify the differential impact of funding across applicants. In these analyses, we focus on a
homogeneous sample of US-based life science researchers, and take advantage of the features of
our setting to identify the causal impact of gender on both reviewer scores and subsequent
outcomes.
Our results offer important new insights into the relationship between diversity and innovation.
We find that even in an anonymous review process, there is a robust negative relationship between
female applicants and the scores assigned by reviewers. This disparity persists even after
controlling for proposal topics, reviewer demographics, applicant publication histories, and
applicants’ prior applications. However, the gender disparity becomes insignificant after
controlling for text-based measures of applicants’ proposals. Specifically, building on the text
analysis methods of previous studies (Schmader et al 2007, Kaatz et al 2015), we show that female
applicants use fewer of the words favored by reviewers when describing their proposals, and more
of the words associated with low reviewer scores. Exploring this pattern further, we show that
female applicants have a tendency to choose more “narrow” (i.e. topic-specific), words and fewer
“broad” words. Both of these tendencies lead to lower scores for female applicants, with their use
of narrow words having the greater negative effect. After controlling for the impact of word choice,
the gender-based score disparity is no longer significant, and its effect size drops by over 50%.
Our findings therefore suggest that a focus on writing style and word choice can offer mechanisms
through which innovative organizations may seek to improve their evaluation and selection
processes.

4

Having shown how communication style influences the evaluation of innovative proposals, we
then turn our attention to follow-on innovative outcomes. Specifically, we explore how male and
female applicants differ in their innovative output subsequent to their application, across measures
such as academic publications and NIH grant awards. We begin by establishing that the text-based
measures which were a major driver of selection by (blinded) reviewers do not also predict an
increase in follow-on innovation. Most prominently, we show that the use of the broad words
favored by reviewers actually predict a decrease in ex-post outcomes, suggesting that reviewers
may be overly credulous to broad descriptions that are likely to reflect style more than substance.
Next, we find that across a range of outcomes, being selected by the Gates Foundation leads to a
bigger impact for female applicants, primarily through “leveling the playing field” relative to male
applicants. Specifically, female applicants are disadvantaged relative to male applicants if they are
not selected; by contrast, successful female applicants generate innovative outcomes that are either
indistinguishable from or better than those of successful male applicants. Indeed, the
disappearance of disparities after being selected and receiving Gates Foundation funding suggests
that from the perspective of impact, female applicants may well generate a greater “return” on
Gates Foundation resources. This effect is strongest for the outcome of NIH grant funding, where
successful female applicants not only catch up but significantly outperform their male
counterparts.
Overall, our results identify two major areas where gender and innovation interact: first, the choice
of (excessively narrow) words by female applicants to describe their innovations can lead to a
significant reduction in their perceived quality (even when the proposed innovations are actually
high-quality!). Second, the failure to be selected for funding acts as a disproportionate barrier to
the follow-on innovation of female applicants, while successful female applicants exhibit
outcomes that are either indistinguishable from or superior to those of their male counterparts.

5

These findings suggest that there is significant scope for improvement at innovation-driven
organizations, in terms of both increasing the selection of high-quality projects, and allocating
resources to the innovators for whom they would have the greatest impact.
II.

Diversity, Gender, and Innovation
A.

Definitions: Diversity, Innovation, Efficiency, and Bias

Diversity and Innovation: In this paper, we approach the topic of organizational diversity by
focusing on just one of its many dimensions, namely, gender. While our analysis is on the level of
individuals, our findings on gender disparities can lead to increased diversity for any organization
where women are underrepresented. Indeed, this pattern exists for many knowledge-based
organizations, including our own empirical setting. In addition to identifying mechanisms that
increase diversity by expanding the inclusion of women in such organizations, we also seek to
estimate the impact of gender on innovative output. We measure innovation through a combination
of proposal-based metrics, article publications, and NIH grant awards. We also perform text-based
analysis using Medical Subject Heading (MeSH) terms in order to capture the direction of
innovation as well as its quantity and quality.
Equity, Equality, and Efficiency: It is important to differentiate between equity, equality, and
efficiency. The concept of equity is referenced most often in aid-focused organizations, which tend
to pursue the goal sending the most resources to places with the highest needs, e.g. by helping
eradicate malaria in Africa. Importantly, this is in contrast to the goal of equality, which would
dictate a similar level of resource allocation to all regions and projects, irrespective of need.
Finally, both equality and equity are distinct from efficiency, which is defined as allocating
resources to the most productive or promising projects, even if those projects do not necessarily
line up with the areas of greatest need. In most cases, a balance of both equity and efficiency is
required for an organization to effectively impact its priorities. In the case of the Gates Foundation,

6

the main target of impact is the quality of life of disadvantaged groups, with a particular focus on
health and infectious diseases in our sample. We measure progress toward these goals by tracking
the publications and grants that result from the Gates Foundation’s funding decisions.
Bias and Demographic Disparity: We take our definition of bias from Poppenhaeger (2017):
The definition of bias is a positive or negative unconscious belief about a particular
category of people. This allows quick, but sometimes inaccurate, processing of
information...Biases are not the same as discrimination; discrimination can happen
if a person actually acts on their biases...If biases go unchecked, they can have
multiple detrimental effects for groups against which negative biases exist, for
example in performance evaluations, hiring, and career progression.
Importantly, this definition highlights the fact that evaluators may be unaware of any potential bias
they possess. Prior work indicates that bias can interact with structural elements of organizations
(Murray and Graham 2007, Kelly et al 2010, Ding, Murray, and Stuart 2012) to generate
significant disparities in outcomes across demographic groups. If such bias-driven mechanisms
are the dominant driver of organizational demographics, one might expect that the adoption of
double-blind evaluations would suffice to overcome both explicit and implicit bias, and lead to
greater inclusion for women and other under-represented groups. However, bias, either explicit or
implicit, may not be the sole driver of demographic disparities. Differences in interests, experience,
risk tolerance, or other factors may generate a disparity across demographic groups, even under a
completely unbiased review process. Thus, while organizations should certainly aim to remove
bias from their evaluations, this may not be sufficient if their goal is to eliminate the demographic
disparities that have limited their diversity.
B.

Diversity in Knowledge-Based Organizations

A number of recent studies have focused on the under-representation of women, racial minorities,
and other demographic groups in innovative fields (Cook and Kongcharoen 2010, Lincoln et al
2012, Bell et al 2017, Marschke et al 2018) and knowledge-based organizations (Fernandez and
Campero 2014, Gompers and Wang 2017). The academic attention has been complemented by
7

discussion of workforce diversity in the popular press, leading top technology companies like
Google and Apple to begin disclosing the demographic statistics of their employees. While such
reports can spur greater awareness of the lack of diversity in knowledge-based organizations, these
group-level statistics do not offer an opportunity to identify the mechanisms behind the patterns
of diversity, because they do not capture outcomes at the individual level. By adopting the
perspective of individual innovators, we add to the growing literature seeking to track the presence
and impact of demographic disparities over the course of individuals’ entire careers (McKown and
Weinstein 2002, Hengel 2017, Lerchenmueller and Sorenson 2018).
C.

The Structure of Gender Disparity and its Potential Drivers

The structure of gender disparities has been the subject of considerable recent research, spanning
a wide range of contexts. Some studies have focused on direct mechanisms such as bias and
discrimination, where it is possible to observe that an individual belongs to a disfavored group
(Castilla 2008, Brooks et al 2014, Cook et al 2018), and this leads to a disparity in outcomes. This
stands in contrast to studies focusing on indirect mechanisms, where a disparity in outcomes exists
despite the lack of direct discrimination (Ginther et al 2016, Fernandez and Campero 2017). In this
latter group, disparities can be driven by self-selection, conforming to stereotypes, or avoidance of
competition, rather than the direct impact of ascriptive bias. Our own focus is on this latter form
of disparity: we are able to exclude the role of bias thanks to the blinded review process used in
our empirical setting. This allows us to not only estimate the magnitude of the gender disparities
that persist after eliminating traditional forms of bias and discrimination, but also to highlight the
precise mechanisms which drive any remaining gender disparities. Indeed, our setting is meant to
complement the approach described by Goldin and Rouse (2000), who show that anonymous
applications are sufficient to significantly reduce disparities faced by female musicians in
symphony orchestras. By contrast, in our setting, significant differences in outcomes persist even

8

under an anonymous evaluation process, suggesting the need for further analysis of the indirect
drivers of gender disparity.
D.

The Interaction of Demography and Innovation

Innovation is a particularly challenging context for demographic diversity and inclusiveness:
unlike other fields, it has a number of features which make it difficult for standard efficiency-based
effects to push out discriminatory tendencies.2 Specifically, the following features of innovation
make it more likely than other fields to harbor a persistent lack of diversity:
● Outcomes are unpredictable, and there are long lags before success is realized
● Outcomes are only observable for funded or attempted innovations
● An individual’s contribution is hard to separate, esp. in cumulative innovation
● Teamwork is often required to push past the current state of the art, and some team
members might prefer working with those similar to them
These challenges are significant, and innovative fields do often generate greater disparities than
other sectors (Magua et al 2017). At the same time, diversity, while lacking, may be uniquely
valuable in the context of innovation (Robinson and Dechant 1997, Østergaard et al 2011).
Innovative organizations would stand to gain not only the usual efficiency benefits from a
reduction in discrimination, but they would also have the potential to introduce new ideas, or
recombine existing ideas in new ways. We therefore seek to evaluate both sides of this question in
our context, as we focus specifically on the dimension of gender: what mechanisms can lead
innovative organizations to become more diverse, and what are the potential benefits of such an
increase in diversity?
III.

2

Data and Methods

For a full discussion of the traditional perspective on discrimination and (in)efficiency, see Becker (2010).

9

A.

Empirical Strategy and Regression Specifications

In analyzing the relationship between gender and innovation-related outcomes, there are a number
of challenges that normally interfere with attempts to estimate causal effects. To capture an
organization’s ability to evaluate innovations, an ideal empirical design would take ideas of
comparable ex-ante quality, and randomly assign each idea to multiple applicants across a range
of demographic groups. These applicants, also of comparable ex-ante quality, would develop and
submit proposals based on the ideas to the organization. If the proposals were submitted
anonymously, it would be possible to remove the direct elements of bias and identify any indirect
or underlying causes of gender disparity. Ideally, these proposals would then be (independently)
evaluated by a diverse set of reviewers, in order to examine the relative impacts of applicant and
reviewer demographics. We can approximate this ideal empirical design in our setting by
attempting to control for idea and applicant quality while comparing the scores that different
reviewers give to a single proposal. Thus, the regression specification we would like to estimate
is:
!"#$"%"&_()*&"+,= /0 0+,- + /1 2334$)5678"69"&, + /2 !"#$"%"&8"69"&- + /12 :67"&5)7$*6,+ ;+,In the above equation, we estimate the score of idea i, from applicant j, as evaluated by reviewer
k. The vector of covariates 0+,- varies by specification, and can include fixed effects for the time
of submission and the subject area of the idea, text-based measures of the idea’s title and
description, and a range of applicant and reviewer characteristics. The demographic variables
capture the gender for both applicants j and reviewers k, and the interaction term identifies the
impact of shared demographic characteristics between applicants and reviewers (e.g. a female
reviewer evaluating a proposal from a female applicant). The primary coefficient of interest in
these specifications is /1 , the impact of applicant gender on the score received from reviewers;
10

specifically, we will track how this coefficient changes based on the inclusion of controls for
covariates that might be correlated with both applicant gender and reviewers’ evaluations.
Turning to the second portion of our empirical design, we encounter the additional challenge of
analyzing the relationship between gender and innovative outcomes. In an ideal research setting,
we would like to take a single idea and assign it to “twin” applicants of identical quality and from
the same demographic group, and randomly assign funding to one but not the other. We would
then want to compare the funded idea with the one that did not receive funding, and perform a
difference-in-differences analysis across demographic groups whose ideas also receive the same
random assignment of funding. In this context, we approximate this ideal design through a
regression-discontinuity approach. Specifically, we compare funded proposals to proposals that
received high scores from reviewers but did not receive funding. Our estimated equation becomes:
:66*#57$#"<=7)*>"+,
= /0 0+, + /1 ?=69$6@+ + /2 2334$)5678"69"&, + /12 :67"&5)7$*6+, + ;+,
In the above equation, we analyze our sample at the level of idea i from applicant j, and 0+, captures
key covariates including fixed effects for the time of submission and the subject area of the idea,
as well as key applicant characteristics such as innovative output during the ex-ante period. While
the direct effects of funding and applicant gender are valuable for interpreting the overall pattern
of results, the primary coefficient of interest is /12 , which captures the differential impact of
funding across applicant gender.3 In effect, this is a difference-in-differences estimator of the
impact of diversity on innovation, and allows us to draw conclusions regarding the efficiency of
the innovative process.
B.

Empirical Setting: The Gates Foundation’s GCE Program

3

In some specifications, we focus solely on applicants who successfully obtained funding; in this setting, rather than
a difference-in-differences approach, we instead draw conclusions from the direct effects of gender on innovative
outcomes.

11

In the previous section, we identified a set of ideal experimental settings that would allow
researchers to estimate the impact of diversity on innovation, both in terms of understanding the
drivers of diversity in innovative organizations, and in terms of the impact of diversity itself on
innovative outcomes. While the expectation of random assignment of funding is not likely to be
satisfied in any well-run organization, our empirical setting does offer a number of valuable
features that allow us to estimate the relationship between diversity and innovation. Our empirical
setting is the Global Challenges: Exploration (GCE) Program at the Bill and Melinda Gates
Foundation (subsequently, the Gates Foundation), providing a sample 6,794 anonymous proposals
submitted by US-based researchers from 2008-2017. While this program offers valuable internal
information on the decisions of individual reviewers, it also differs from more “traditional” grant
review institutions (e.g. the NIH or NSF): these organizations use a non-blind review process and
send proposals only to reviewers within the proposal’s narrow subfield. Further, traditional grantreview institutions often engage in consensus-based collective decisions, where reviewers discuss
proposals together and at a collective evaluation representing the views of the entre reviewer panel
(NIH 2008). By contrast, the GCE Program implements a review process with the following key
characteristics: diverse panels of reviewers, anonymous proposals, and champion-based funding
decisions.
● Anonymous proposals - reviewers have no information on the candidate beyond the
proposal details
● Diverse pool of reviewers - reviewers are drawn from a wide range of scientific fields and
may be from non-academic backgrounds such as the private sector or government
● Independent evaluations - reviewers do not confer with each other when assigning scores

12

● “Champion-based” review - rather than relying on consensus across multiple reviewers,
strong support from a single reviewer can greatly increase the odds of being funded4, while
strong negative reviews are treated as identical to neutral reviews
The above features reflect the priorities of the Gates Foundation in its search for solutions to major
challenges in global health and development. At the same time, they introduce a richness of
variation in both reviewers and proposals, allowing for detailed analysis of reviewer decisions and
project outcomes.
C.

Data Sources and Key Variables

The data for our analysis comes from the first nineteen rounds of the GCE program, which includes
a total of 17,311 proposals focused on infectious disease research submitted between 2008 and
2017. In order to ensure a homogeneous pool of applicants, we focus on the 6,794 proposals
submitted by applicants who have both an academic or non-profit research affiliation and a US
contact address.5 These proposals, submitted by 5,058 unique applicants, were allocated across
subsets of 132 innovation-panel reviewers, leading to a total of 21,453 reviewer-proposal pairs.
From the Gates Foundation, we obtain identifying information on the identities of proposers and
reviewers, the substance of the proposals, and the reviewer scores and funding outcomes resulting
from the program. We calculate probabilistic measures of gender for both applicants and reviewers
using the techniques of Sood and Laohaprapanon (2018). Reviewer evaluations in our sample are
simple but highly skewed: from an average portfolio size of over 100 proposals per round,
reviewers can choose a single proposal to receive their highest level of support (categorized as a
“Gold” rating by the GCE program), and can award up to five other proposals with a high level of

4

While a single reviewer can greatly increase the funding odds for any single project, their highest level of
endorsement can only be given to one of the approximately 100 proposals that they review during each round of the
program.
5
In the interest of analyzing a homogeneous sample, we also drop the small fraction applicants that we identify as
members of under-represented minorities.

13

support (categorized as a “Silver” rating).6 Our empirical approach employs an ordered-logit
specification to capture this decision process. Based on these reviewer evaluations, a total of 635
proposals (~9.4%) received grants of $100,000 each during the first nineteen rounds of the GCE
program.
We use the identifying information on reviewers and applicants to obtain information on
institutional affiliation, gender, country of residence, and area of expertise. Notably, even at the
proposal stage, we find a significant gender gap: our sample of US-based academic applicants is
66% male. In addition to obtaining demographic information, we obtain applicants’ full
publication histories in order to estimate research productivity both before and after the peer review
process. Table 1 lists summary statistics for these and other key variables, while Figure 1 presents
the distribution of proposals and ratings across topic areas. Using this data, we proceed to
investigate the role of gender in the peer review process, and the ability of peer review to both
evaluate and select promising research projects and innovations.
TABLE 1 & FIGURE 1 HERE
IV.

Analysis and Results
A.

Determinants of Reviewer Evaluations: Evidence of Disparity

Our results begin with Table 2, which examines the impact of gender on the scores received by
applicants’ proposals. Columns 1 through 4 evaluate the overall impact of applicant gender across
all reviewers in our sample, while column 5 decomposes the effect between male and female
reviewers by adding an interaction between applicant and reviewer genders. All specifications
include fixed effects by GCE round; specification 2 adds reviewer characteristics, and
specifications 3 through 5 include reviewer fixed effects. In addition, specifications 4 and 5 include

6

It is worth noting that this rating system does not offer the opportunity for reviewers to send negative signals:
proposals not receiving support from a given reviewer all receive the same rating (effectively, a score of zero),
regardless of the reviewer’s degree of disapproval.

14

topic area fixed effects. In all specifications, we find consistent negative disparities for female
applicants: such applicants are significantly less likely to receive high scores from reviewers. The
effect size we estimate reflects our ordered-logit specification, reflecting a log-odds ratio that is
approximately 16% lower than male applicants. In separate calculations, we find that this overall
effect is driven by female applicants being approximately 15% less likely to receive a “silver”
rating and 20% less likely to receive a “gold” rating from reviewers. In specification 5, we also
include the interaction of female applicants and female reviewers; we find a strong positive effect
for this variable. Importantly, this should not be interpreted to conclude that female reviewers have
an affirmative preference for proposals from female applicants: the sum of the direct effect and the
interaction is positive, but not significantly different from zero.7 Effectively, the direct effect
captures the lower scores that female applicants receive from male reviewers, while the interaction
term indicates that female reviewers do not exhibit a similar disparity in reviewer evaluations
across gender.
Since the impact of applicant gender in Table 2 is robust to including topic-area fixed effects, our
results suggest that the gender disparities we observe are not driven by applicants choosing lessvalued areas of study. We explore this question further in Figure 2, which compares the prevalence
of female applicants against average proposal scores across the topic areas in our sample. We find
that there is significant variation across topics in both dimensions; further, we find a weak positive
relationship between the rate of female applicants and the average of reviewer scores across topic.
The patterns in Figure 2 therefore lend additional support that the choice of topic is not a significant
driver of the gender disparities in our sample.
TABLE 2 & FIGURE 2 HERE

7

Only 20 of 132 (~15%) reviewers in our sample are female, and in combination with the low proportion of female
applicants, we lack the statistical power to precisely estimate the interaction between female reviewers and applicants.

15

In Table 3, we continue our analysis of demographic disparities in reviewer scores, adding explicit
controls for applicant quality using the measure of pre-period publications.8 Panel A explores a
range of publication-based metrics, and finds that the female applicants in our sample are at a
disadvantage relative to male applicants across all measures. We begin with career length in
specifications 1 and 2, where we find that female applicants are approximately 30% less senior
than male applicants, as measured by the number of years from an applicant’s first academic
publication. This result is robust to adding topic fixed effects in specification 2. We perform similar
analyses for the number of publications, and the share of top-journal and last-author publications,
all in the three years prior to applying to the GCE program. Across all three measures, we find that
female applicants are at a significant disadvantage, though this effect diminishes significantly after
controlling for topic-area fixed effects and applicant career length. Overall, these results suggest
the possibility that within our sample, female applicants have weaker publication histories, and
may therefore have less ability to generate a high-scoring proposals.
We evaluate the impact of this difference in prior publications in Panel B, where we repeat the
analysis of Table 2 while controlling for the details of applicants’ publication history. We find a
significant positive impact of prior publications on reviewer scores in specification 2; after
including additional measures, we find that the share of top-journal publications is the strongest
predictor of reviewer scores in our setting. Overall, we find strong evidence for the hypothesis that
applicants with a superior publication history tend to generate higher-scoring proposals. However,
even after controlling for a range of measures of applicants’ prior publications, we continue to find
a significant disadvantage for female applicants in all specifications. This pattern of results

8

Specifically, we define the “pre-period” as the three years prior to the proposal’s application year.

16

suggests that the ex-ante differences in publication patterns across gender do not explain a
significant portion of the outcome disparities we find in the proposal-evaluation process.
TABLES 3A & 3B HERE
B.

Mechanisms Driving Disparity: Repeat Applications

Having presented evidence for consistent gender disparities in reviewer scores, we now proceed
to evaluate the mechanisms through which they might emerge even under a blinded-review
process. The first potential mechanism is that of persistence: might female applicants be more
easily discouraged if their first proposal is rejected? We evaluate this dimension in Panel A of
Table 4, where we find that female applicants are significantly less likely to reapply after an initial
rejection. This negative association becomes insignificant in specifications 3 and 4 after
controlling for career length, suggesting that experience can lead to increased persistence that
mitigates this aspect of gender disparity. We then proceed to evaluate the impact of this difference
in Panel B; we show that repeat applicants receive significantly higher scores than first attempts.
This effect is both strong and highly robust, persisting in all specifications as we include topic
fixed effects, publication characteristics, and interaction effects. Our results therefore serve as a
reminder of the value of persistence in the face of rejection; in light of the results in Panel A, this
is advice that is particularly important for female researchers and innovators at the early stages of
their career.9 However, controlling for this repeat-applicant effect does not meaningfully reduce
the gender disparity we identified in Tables 2 and 3. Thus, while repeat applicants are expected to
receive significantly higher scores from reviewers, this dimension does not explain a significant
portion the female score disparity in our sample.
TABLES 4A & 4B HERE

9

While repeat applicants receive a significant boost in terms of their expected scores from reviewers, the interaction
between female applicants and repeat applicants in specifications 5 and 6 are insignificant. Thus, there is no additional
boost to female applicants who re-apply after rejection, relative to male applicants who do the same.

17

C.

Mechanisms Driving Disparity: Word Choice

A second potential mechanism to explain demographic disparities in an anonymous review process
is the set of words that applicants use to describe their proposals. Specifically, we analyze the
words present in the title and descriptions of applicants’ proposals, after removing standard
conjunctions, pronouns, and linking words. In Figures 3 and 4, we plot words based on their
relative rates of use by male and female applicants, and include 45-degree lines to clearly separate
“male” from “female” words in our data. We present the 100 most frequent of the remaining words
in Figure 3, in order to show that word use rates are strongly correlated across applicant gender.
While the overall correlation is strong, there is nevertheless significant variation in the gender use
rates of some words. Figure 4 highlights this trend by focusing on words that have a significant
correlation with reviewer scores, and also identifies the difference between “narrow” words (those
which appear significantly more often in some topics than others), and “broad” words (which
appear at similar rates in all topic areas). The latter figure suggests that male applicants tend to
favor broad words, while female applicants have a tendency to use narrow words. Overall, these
figures identify the similarities and difference in word choice across applicant gender, and set the
stage for analyzing whether the differences we find can explain the gender score gap in our sample.
FIGURES 3 & 4 HERE
In addition to disparities in use rates across applicant gender, the frequent words in our sample
also have significant disparities in their tendencies to appear within high- and low-scoring
proposals. We highlight these score disparities in Figure 5, plotting frequent (i.e. top-100) words
that are disproportionately associated with male or female applicants based on their rates of use
within high- and low-scoring proposals. While there is a reasonable amount of variation across
words, the overall pattern suggests that words falling well below the 45-degree line (i.e. those with
strongly negative score disparities) are much more likely to be used disproportionately by female

18

applicants. By contrast, most “male” words are likely to be near or above the 45-degree line,
indicating a positive score disparity. We follow up the binary analysis of gender in Figure 5 with
a full two-dimensional exploration of gender- and score-based disparities in Figure 6. This figure
highlights the positive relationship between words used more often by male applicants, and words
associated with high-scoring proposals. Importantly, while most “male” words have a positive
score disparity, there are “female” words with both positive and negative score disparities. This
effect seems to be associated with the difference between broad and narrow words: the broad words
in Figure 6 seem to be driving the high scores of male applicants, while the narrow words seem to
be associated with the lower scores of female applicants. This suggests that there is significant
scope for female applicants to improve their scores by altering the words they use to describe their
proposals.
FIGURES 5 & 6 HERE
In light of the patterns described above, we now proceed to explore the impact of word choice on
reviewer scores using a regression framework in Table 5. We begin with Panel A, which highlights
some of the basic patterns of word choice in our sample, focusing on the top 1,000 most frequent
words used in the proposals in our sample. We examine the differences in word use between male
and female applicants, and in specification 1, we show that the total number of frequent words
does not differ across gender. By contrast, we find significant differences across applicant gender
in all remaining word-choice measures: female applicants use fewer high-scoring words and more
low-scoring words in specifications 2 and 3, and this result is robust to identifying high- and lowscoring words using only male applicants’ proposals in specifications 4 and 5. Finally, in
specifications 6 and 7, we classify words as “broad” and “narrow” based on whether they are used
at similar or different rates across topic areas, and show that female applicants use fewer broad
words and more narrow words when describing their proposals.

19

Having established these basic patterns, we next construct text-based measures of each proposal’s
quality as perceived by reviewers. Specifically, we predict a proposal’s reviewer scores based only
on the presence or absence of the top 500 most score-influencing words in each proposal’s title
and description. Importantly, to avoid circular reasoning, we calibrate our text-based reviewer
score predictions using only the proposals from male applicants. Thus, the high-and low-scoring
words we identify are those with which male applicants receive high and low scores from
reviewers, with no information regarding the use of these words by female applicants. We
normalize score predictions to a mean of zero and unit standard deviation, and proceed to use them
as dependent variables in Panel B, and explanatory variables in Panel C.
In Panel B, we analyze the relationship between applicant gender and our text-based measures of
proposal quality. Specifications 1 through 3 demonstrate this result using the full set of 500 words,
while specifications 4 and 5 explore the division between high-scoring and low-scoring words,
respectively Finally, in specifications 6 and 7, we focus solely on broad and narrow words,
respectively. In all cases, we find strong evidence that female applicants use words that diminish
their chances of receiving high scores from reviewers. In addition, we find that female applicants
are at a greater disadvantage in their use of narrow words, compared to their disadvantage in the
use of broad words.
Having established the baseline result that female applicants’ word choices put them at a
disadvantage, we now turn to the impact of those word choices on reviewer scores in Panel C. Our
analysis begins in specification 2, where we control for a wide range of text-based metrics such as
the count of unique frequent words, grammatical composition, and the grade level10 of proposal
text. While a number of these measures have a significant association with reviewer scores, they

10

Our measure of grade level is a composite rating based on the arithmetic average of the Flesch-Kincaid, GunningFog, and SMOG measures. See Hengel (2017) for details.

20

do not significantly reduce the observed gender gap in our sample. However, when we add the
text-based score predictions starting in specification 3, we see a large drop in the coefficient on
female applicants. The inclusion of the score prediction based on narrow words again seems to be
a major driver of the gender gap, as it renders the applicant gender effect insignificant, while the
score prediction based on broad words fails to do so. When controlling for both measures, we
continue to find no significant effect of applicant gender on reviewer scores, even as we add
controls for topic areas and applicant publications. Notably, these measures do not eliminate the
interaction between female applicants and female reviewers, which remains positive and
significant.11 Table 5 therefore highlights word choice as a crucial driver of gender disparities,
even under blinded review.
TABLES 5A, 5B, & 5C HERE
Having covered a range of mechanisms individually, we now synthesize our prior analyses of
reviewer scores to examine the relative impact of each dimension in contributing to gender -based
disparities. Table 6 presents our results, beginning with the baseline analysis in column 1, which
controls only for the round of the program, reviewer fixed effects, and reviewer-cross-round
characteristics. Adding gender-based interactions between applicants and reviewers in column 2
increases the magnitude of the applicant gender effect, which now reflects the scoring patterns of
male reviewers. Moving to column 3, we add topic-area fixed effects, which reduce the magnitude
of the gender gap by approximately ten percent. In column 4, we add publication characteristics,
which lead to only a marginal 3% further decline in the gender gap. In column 5, we add the
mechanism of repeat applications, which also explains only 3% of the gender score-gap. In column
6, we introduce a range of text-based controls such as word count, grammatical composition, the

11

Indeed, in this specification, the sum of the baseline effect and the interaction is positive and significant, indicating
that female reviewers have an affirmative preference for female applicants, after controlling for text-based score
predictions derived from male applicants’ proposals.

21

rate of scientific words, and the grade level of proposal text; these measures offer only a 2%
decrease in the gender gap. Finally, in column 7, we control for word choice in the form of our
text-based score prediction; this eliminates over 50% of the remaining gender score gap, and
renders the overall disparity insignificant. Importantly, these controls do not reduce the interaction
effect that we find between female applicants and reviewers, suggesting that female reviewers are
not influenced by word choice in the same way as male reviewers. Thus, the main conclusion of
Table 6 is that the gender score-gap is driven in large part by the choice of words female applicants
use to describe their proposals; after controlling for this dimension, the disparity falls by more than
50% and is no longer statistically significant.
TABLE 6 HERE
D.

The Impact of Gender on Innovative Outcomes

So far, our results have focused on explaining the disparities in reviewer scores received by female
applicants. While this is inherently valuable as a means of identifying the underlying causes of the
lack of demographic diversity in innovative fields, it does not address questions related to
efficiency: does the lack of gender diversity in high-scoring applicants reflect an inefficient
disparity and unreasonable barriers, or is it a reflection of the fact that female applicants face
challenges that are likely to interfere with their performance, even if they were selected by
reviewers? To address these questions, we analyze ex-post outcomes for our sample of applicants,
looking specifically at publications, NIH grants, and Phase-2 outcomes within the GCE program.
Our results begin in Table 7, which focuses specifically on funded applicants: conditional on
funding, how did different demographic groups perform? This “treatment-on-treated” analysis is
meant to capture the organizational perspective: did the evaluation process select the strongest
applicants, regardless of demographic characteristics? We consider a wide range of outcomes, and
show that in most cases, the review process did indeed select a pool where there were no significant

22

differences between demographic groups. In particular, in columns 1 through 7, after controlling
for proposal scores and pre-period outcomes, we find no ex-post disparities in publication-related
outcomes across applicant gender. By contrast, in columns 8 and 9, we find (weak) evidence of
gender’s impact on innovative outcomes. Focusing on the outcome of NIH grants in column 8, we
find that female applicants are slightly more likely to obtain such grants in the post-proposal
period; we also find a large but insignificant point-estimate for the high-value R01 grants that
cover multiple years of research in column 9. Importantly, all specifications also control for word
choice, which has a different impact here relative to our earlier tables. Previously, we highlighted
that male applicants seemed to benefit in terms of reviewer scores by using general words more
often, while female applicants tended to use topic-specific words, which tended to lead to lower
reviewer scores. By contrast, Table 7 suggests that while using broad words may help obtain high
scores from reviewers, such proposals do not tend to perform as well in terms of ex-post outcomes.
In effect, reviewers may well be overly credulous to the broad claims of such proposals, which
tend to under-perform across multiple measures if selected for GCE funding.
TABLE 7 HERE
The focus on the sub-sample of funded applicants is valuable, but it is not always the correct
perspective for evaluating the relationship between demography and innovation. While Table 7
captures the effectiveness of the selection process, it does not offer insight into the impact of
funding on the applicants in our sample. It may well be the case that some of the applicants
receiving funding would have done just as well without it, perhaps because of access to other
sources of money or support. To evaluate the causal impact of funding, we therefore need to
compare funded applicants against those who (just barely) did not receive funding. In Table 8, we
establish a difference-in-differences estimator by focusing on the sub-sample of proposals, which

23

received positive reviews from at least one reviewer. Within this “high-scoring” sample, we
examine not only the baseline impact of funding, but also its differential impact across genders.
We begin our analysis in columns 1 and 2, focusing on all published articles and on articles
published in top journals,12 respectively. We find that while funding has only a weakly-positive
and insignificant impact on publications, there is a significant positive interaction between funding
and female applicants, particularly for top-journal publications. This suggests that Gates
foundation funding has a significantly greater impact when it is allocated to female applicants,
relative to male applicants. The reason for this difference seems to be driven in part by the negative
baseline effect for female applicants: without funding, they under-perform male applicants, and
this effect is once again stronger for top-journal publications. A similar pattern appears in columns
3 through 5, which track novelty and exploration by tracking new journals, coauthors, and MeSH
terms derived from applicants’ publications. In all three outcome measures, we find that the
baseline effect of being a female applicant is significantly negative, indicating that unfunded
women are likely to perform worse than unfunded men. However, we also find positive interaction
effects between funding and female applicants, leading to no significant difference across gender
between funded applicants. Once again, our difference-in-differences results come not from
funded women outperforming men, but from unfunded women significantly under-performing
unfunded men. In effect, securing funding from the GCE program can “level the playing field” for
female applicants, and generates a larger impact than the funding devoted to male applicants.
In line with our earlier results on the importance of funding, we turn to the results focusing on NIH
grants in columns 6 and 7. The overall pattern of results is similar in both cases, but the strongest
effects can be seen in column 7, which focuses on the coveted multi-year R01 grants. For this

12

We define top journals as those in the top decile of impact factor. Our results are robust to redefining top journals
as either top-5% or top-25% by impact factor.

24

outcome, we see negative but insignificant baseline effects for female applicants. More
importantly, we find strong positive interactions between female applicants and GCE funding, with
the positive interaction effects more-than-compensating for the negative baseline impacts of
demographics. We can therefore conclude that female applicants’ careers are more responsive to
funding in this outcome dimension: the GCE program’s impact is most beneficial to these groups
when it leads them to obtain additional funding from the NIH, especially through its R01 program.
This implies that GCE funding can lead to a “multiplier effect,” where it allows successful
applicants to be more effective at raising external funding as their careers progress.
Finally, revisiting the impact of proposal text, we once again find that the use of broad and narrow
words, do not predict an increase in any of our ex-post outcomes. By contrast, the metric of
proposal text grade level, which did not predict reviewer scores in Tables 5C and 6, is now a
significant positive predictor of virtually all measures of follow-on innovation. This suggests that
while communication style does offer valuable information on the quality of applicants’ ideas,
reviewers are focusing on the wrong metrics when evaluating the innovative proposals in our
sample.
TABLE 8 HERE
V.

Discussion and Conclusions

In this paper, we addressed two primary research questions: first, how can innovative organizations
become more diverse along the dimension of gender, and second, what are the potential impacts
on innovation from an increase in gender inclusion? By taking advantage of our unique empirical
setting and its blinded-review process, we were able to eliminate the direct effects of bias and
discrimination, and focus exclusively on the indirect mechanisms that contribute to the gender
disparities in our sample. Our main contributions are the identification of word choice as an
important driver of negative outcomes for female innovators, and the finding that women may

25

offer a greater return on an organization’s resources, in terms of future innovative outcomes. Our
findings suggest a number of important outstanding questions for future research.
First, our analysis of innovative outcomes only offers a limited duration of ex-post data following
GCE funding decisions, particularly for applicants in later rounds. In this timeframe, we saw
evidence that female applicants were able to obtain significantly more additional NIH funding as
a result of a successful application. While obtaining funding from the NIH or similar organizations
is not an end-goal by itself, this additional funding can be reasonably expected to serve as an input
to future research and innovation. While our sample period is too short to capture these dynamics,
allocating more resources to female innovators may well lead to improved career trajectories and
greater innovative output, especially over longer horizons. Indeed, if the findings in our sample
apply to the broader scientific and innovative communities, it is likely that female innovators are
systematically under-funded relative to the quality of their ideas. Future work could explore these
patterns across longer time horizons and in other stages of the innovation ecosystem.
Second, our text-based analysis focuses on the relatively straightforward measure of the presence
or absence of commonly-used words; a more sophisticated analysis of a larger sample would offer
the opportunity to identify detailed patterns in the types of words that either help or harm
evaluations, particularly for female innovators. Finally, we were unable to effectively explore
dimensions of diversity other than gender in our sample, due to low number of applicants in other
under-represented categories (e.g. racial minorities.) More work is needed to determine whether
our results are generalizable to other dimensions of organizational diversity. Thus, we would
encourage future research to look to other dimensions of diversity, such as ethnicity, national
origin, and socio-economic status, as key drivers of the innovative process.

26

References
Azoulay, P., Graff Zivin, J. S., & Manso, G. (2011). Incentives and creativity: evidence from the
academic life sciences. The RAND Journal of Economics, 42(3), 527-554.
Becker, G. S. (2010). The economics of discrimination. University of Chicago press.
Bell, A. M., Chetty, R., Jaravel, X., Petkova, N., & Van Reenen, J. (2017). Who Becomes an
Inventor in America? The Importance of Exposure to Innovation (No. w24062). National Bureau
of Economic Research.
Bilimoria, D., Joy, S., & Liang, X. (2008). Breaking barriers and creating inclusiveness: Lessons
of organizational transformation to advance women faculty in academic science and
engineering. Human Resource Management, 47(3), 423-441.
Boudreau, K. J., Guinan, E. C., Lakhani, K. R., & Riedl, C. (2016). Looking across and looking
beyond the knowledge frontier: Intellectual distance, novelty, and resource allocation in
science. Management Science, 62(10), 2765-2783.
Brooks, A. W., Huang, L., Kearney, S. W., & Murray, F. E. (2014). Investors prefer entrepreneurial
ventures pitched by attractive men. Proceedings of the National Academy of Sciences, 111(12),
4427-4431.
Castilla, E. J. (2008). Gender, race, and meritocracy in organizational careers. American Journal
of Sociology, 113(6), 1479-1526.
Castilla, E. J. (2015). Accounting for the gap: A firm study manipulating organizational
accountability and transparency in pay decisions. Organization Science, 26(2), 311-333.
Castilla, E. J., & Benard, S. (2010). The paradox of meritocracy in organizations. Administrative
Science Quarterly, 55(4), 543-676.
Cook, L. D., & Kongcharoen, C. (2010). The idea gap in pink and black (No. w16331). National
Bureau of Economic Research.
Cook, C., Diamond, R., Hall, J., List, J. A., & Oyer, P. (2018). The Gender Earnings Gap in the
Gig Economy: Evidence from over a Million Rideshare Drivers. Working paper. Available at:
https://web.stanford.edu/~diamondr/UberPayGap.pdf
Fernandez, R. M., & Campero, S. (2014). Does Competition Drive Out Discrimination? In New
Haven, CT: Presentation at Economy and Society@ Yale Conference.
Fernandez, R. M., & Campero, S. (2017). Gender sorting and the glass ceiling in high-tech
firms. ILR Review, 70(1), 73-104.
Fernandez, R. M., & Fernandez-Mateo, I. (2006). Networks, race, and hiring. American
sociological review, 71(1), 42-71.
Ginther, D. K., Kahn, S., & Schaffer, W. T. (2016). Gender, race/ethnicity, and National Institutes
of Health R01 research awards: is there evidence of a double bind for women of color? Academic
medicine: journal of the Association of American Medical Colleges, 91(8), 1098.
Goldin, C., & Rouse, C. (2000). Orchestrating impartiality: The impact of" blind" auditions on
female musicians. American economic review, 90(4), 715-741.
Gompers, P. A., & Wang, S. Q. (2017). Diversity in innovation (No. w23082). National Bureau of
Economic Research.

27

Hengel, E. (2017). Publishing while Female. Are women held to higher standards? Evidence from
peer review. Working paper.
Kaatz, A., Magua, M. W., Zimmerman, D. R., & Carnes, M. (2015). A quantitative linguistic
analysis of National Institutes of Health R01 application critiques from investigators at one
institution. Academic medicine: journal of the Association of American Medical Colleges, 90(1),
69.
Kelly, E. L., Ammons, S. K., Chermack, K., & Moen, P. (2010). Gendered challenge, gendered
response: Confronting the ideal worker norm in a white-collar organization. Gender &
Society, 24(3), 281-303.
Kunze, A., & Miller, A. R. (2017). Women helping women? Evidence from private sector data on
workplace hierarchies. Review of Economics and Statistics, 99(5), 769-775.
Lerchenmueller, M. J., & Sorenson, O. (2018). The gender gap in early career transitions in the
life sciences. Research Policy, 47(6), 1007-1017.
Lincoln, A. E., Pincus, S., Koster, J. B., & Leboy, P. S. (2012). The Matilda Effect in science:
Awards and prizes in the US, 1990s and 2000s. Social studies of science, 42(2), 307-320.
Magua, W., Zhu, X., Bhattacharya, A., Filut, A., Potvien, A., Leatherberry, R., ... & Kaatz, A.
(2017). Are female applicants disadvantaged in National Institutes of Health peer review?
Combining algorithmic text mining and qualitative methods to detect evaluative differences in
R01 reviewers' critiques. Journal of Women's Health, 26(5), 560-570.
Marschke, G., Nunez, A., Weinberg, B. A., & Yu, H. (2018). Last Place? The Intersection between
Ethnicity, Gender, and Race in Biomedical Authorship.
McIntyre, S., Moberg, D. J., & Posner, B. Z. (1980). Preferential treatment in preselection
decisions according to sex and race. Academy of Management Journal, 23(4), 738-749.
McKown, C., & Weinstein, R. S. (2002). Modeling the Role of Child Ethnicity and Gender in
Children's Differential Response to Teacher Expectations 1. Journal of Applied Social
Psychology, 32(1), 159-184.
Monroe, K., Ozyurt, S., Wrigley, T., & Alexander, A. (2008). Gender equality in academia: Bad
news from the trenches, and some possible solutions. Perspectives on politics, 6(2), 215-233.
Murray, F., & Graham, L. (2007). Buying science and selling science: gender differences in the
market for commercial science. Industrial and Corporate Change, 16(4), 657-689.
Østergaard, C. R., Timmermans, B., & Kristinsson, K. (2011). Does a different view create
something new? The effect of employee diversity on innovation. Research Policy, 40(3), 500509.
Poppenhaeger, K. (2017). Unconscious Gender Bias in Academia: from PhD Students to
Professors. arXiv preprint arXiv:1711.00344.
Reagans, R., & Zuckerman, E. W. (2001). Networks, diversity, and productivity: The social capital
of corporate R&D teams. Organization science, 12(4), 502-517.
Reuben, E., Sapienza, P., & Zingales, L. (2014). How stereotypes impair women’s careers in
science. Proceedings of the National Academy of Sciences, 201314788.
Robinson, G., & Dechant, K. (1997). Building a business case for diversity. Academy of
Management Perspectives, 11(3), 21-31.

28

Schmader, T., Whitehead, J., & Wysocki, V. H. (2007). A linguistic comparison of letters of
recommendation for male and female chemistry and biochemistry job applicants. Sex roles, 57(78), 509-514.
Shen, H. (2013). Mind the gender gap. Nature, 495(7439), 22.
Sood, G., & Laohaprapanon, S. (2018). Predicting Race and Ethnicity from the Sequence of
Characters in a Name. arXiv preprint arXiv:1805.02109.
Tasheva, S. N., & Hillman, A. (2018). Integrating diversity at different levels: multi-level human
capital, social capital, and demographic diversity and their implications for team effectiveness.
Academy of Management Review, (ja).
Witteman, H. O., Hendricks, M., Straus, S., & Tannenbaum, C. (2017). Female grant applicants
are equally successful when peer reviewers assess the science, but not when they assess the
scientist. bioRxiv, 232868.
Wold, A., & Wenneras, C. (2010). Nepotism and sexism in peer-review. In Women, science, and
technology (pp. 64-70). Routledge.

29

Figure 1: Distribution of Proposals, Applicants, and Scores by Topic
Observations: 6794 Total Proposals, 1933 Silver Ratings, 409 Gold Ratings
HIV
Discovery Core
Malaria
Reproductive & Neonatal Health
Tuberculosis
Diarrhea
Other
Miscellaneous Diseases
Agriculture & Nutrition
Pneumonia
0
All Proposals

.05

.1

Silver Ratings

.15

.2

Gold Ratings

Figure 2: Rates of Female Applicants and Average Scores by Topic
.03

Note: Circle areas represent the number of proposals in each topic. Total Proposals: 6794

Other

Average Reviewer Score by Topic
.01
.02

Miscellaneous Diseases
Diarrhea
Agriculture & Nutrition

Malaria

Discovery Core
Reproductive & Neonatal Health
Tuberculosis
HIV

0

Pneumonia

.25

.3

.35
.4
% Female Applicants by Topic

30

.45

.5

t

ity

un

m

im

os

-c

w

lo

al

os

uc

m

-2.5

-4

se

Log(Male Word Use Rate)
-3
-2
-1

l
al
er
ov

o
rp

v

p
lo
ve

l
ve

e
un
m
im

ito
qu
os
m

n
io
ct
te
de

he

al

th

n
ei
ot
pr

e
os
op
pr

l
e
od
m

ce
vi
de

a

s
ru
vi

dt
pida
ra

l
ro
nt
co

ol
to

ge

t

n
ai
br

e
iv
pt
ce
ra
nt n
co ssio
i
m
ns
tra
te
ea
cr

us
io
ct
fe
in

al

gu

is
s
no
ag

os
op
pr

ne

di

l
el
t-c

e
in

ed
us

rs
to
bi
hi

ct
te
de

in

rm
te
de

Log(Male Word Use Rate)
-3.5
-3

t
ec
oj
pr
pu

de
hi
no
e
in
cc
va

ia
ar
al ll
mce

y
ap
er
th

ia
er
ct
ba

y

ud

ity

un
m
m
co

st

al

or

31

Broad Words

Narrow Words

-2.5

-3.5
-3
Log(Female Word Use Rate)

-4

0
-1
-2
Log(Female Word Use Rate)
-3
-4

e
t
gs
inu
en
us
pm
seelo t
w eaev teosn
nedis d cti
fe
in

ug
dr

t
os
-c
n
th
w
lo al my a eal
h
os hnuit
uc u
nt
m imm
y
tif infah
e n oac
id
pisr
es psne
in ualou
el
cc rc m
iocd
va ube im
o insmt
t nce uit otenyo m s lt y
e
a q r gr r ut on
ov
st s p iae fo irn oe og
e
si motb edliv lat evovese tmt nonl g
iv
pr
pnt
en
re
p rp a h i
m
d
i
p
e
o
ro tre teclop
ile
om
acsi
n p
e
r
s
w
t
i
ob
io
dva
gn cosnm
m
ct
pdaiet
si
n
n
te
ity
d rad
dee
de
traate atio
se
un
icl
e
m n
ba
l ova
cr racin
m re
d
c
s
rodge ting
ceo childy
nt
vabus
o
n
e
i
c
e
co
cte nes u in stu
rg l t
tvairrgae nhfoeogdscacltltiiovs redrm
it h oia d i te
al
ta
l
paet pfrfoeeoos gye
rlrya erionn
mparncoeitenbeolgsnt tated
eao aetnt
a r
gbe dhi gsut ll
d emv
e
y
pcl e use pr aim
ap
mtsi
er
rs
th
togh
bi hi e
hi cye ces
incanhsanns
ia
fi
o
o
er
efspesnepct ted
ct
redreet fec c
in uti
e
ap
er
ba

th

-4

0

Figure 3: Male vs. Female Word Use Rates for All Frequent Words

Figure 4: Male vs. Female Word Use Rates for Broad vs. Narrow Words

Note: Words selected based on high use frequency and significant correlation with proposal score.
Narrow (broad) words are defined based on a high (low) variance in use rate across proposal topics.

Figure 5: High-Scoring vs. Low-Scoring Word Use Rates for Gendered Frequent Words
Note: Words selected based on high use frequency and significant correlation with applicant gender.
m

-2

ia
ar
al

an

st
te

m

Log(High-Score Word Use Rate)
-4
-3.5
-3
-2.5

ug
dr

hu

n
io
ct
te

an
st
si
re

de

ce

m
in
nt

l
tro

fa

d
se
ba
el

od

n
cool
to

ba
m
ntse
treaa
cr

ia
er
ct

he

e
et ov
rg pr
ta im

on
si
is

al
th

e
th
y

e
tiv

l en
na e v
er pr c
at uti
pe
ra

p
ce
tra

p
ra

n
co

m

e
th

n
re
ild
ch
rly

ea

m

n
tio

e
uc

a
in
cc
va

d
re

einle
omob
wm

ai

de
ai
n

e

al

in

br

m

r
no

r
te

tio

ity

un

m

m

co
y

ud

-4.5

st

-4

-3.5

-3
-2.5
Log(Low-Score Word Use Rate)
Male Words

-2

Female Words

ia

er

ct

ba

Score Disparity (Excess High-Scoring Frequency)
-1
-.5
0
.5
1

Figure 6: Frequent Words with Disparities in Reviewer Scores and Gender-Based Use

cr
de
te

l

n

io

ro

ct

nt

eln
odio
miss
m

ns

te

co

ea

tra
ol
to

er
th
y

ap

e

iv

in
rm
te
de

pt
ce
ra
nt
co ral
o

e

he
al
th
n

ai

br

i
un

m

m
co
ty
y

ud

st

-.6

-.4

-.2
0
.2
Gender Disparity (Excess Male Frequency)
Narrow Words

32

Broad Words

.4

.6

Table 1: Summary Statistics
Variable

N. of Obs.

APPLICANT CHARACTERISTICS
Female Applicant Probability
Applicant Publication History Indicator
PROPOSAL CHARACTERISTICS
GCE Round
Funding Indicator
High-Score Indicator
Reviewer Count
Repeat-Applicant-After-Failure Indicator
Proposal Text Characteristics:
Unique Frequent Word Count
Noun Share
Adjective Share
Verb Share
Proposal Text Grade Level
Normalized Text-Based Score: Broad Words
Normalized Text-Based Score: Narrow Words
Conditional on Identifying Publication History:
Pre-Period Publications
Post-Period Publications
Pre-Period NIH Grants
Post-Period NIH Grants
REVIEWER CHARACTERISTICS
Female Reviewer Probability
Avg. Proposals per Round (All-GCE)
Avg. Proposals per Round (US Academics)
REVIEWER X ROUND CHARACTERISTICS
Proposals Under Review
Reviewer Round Sequence
REVIEWER X PROPOSAL CHARACTERISTICS
Proposal Sequence
Silver Rating
Gold Rating

33

Mean

Std. Dev.

Min

Max

5,058
5,058

0.343
0.785

0.475
0.411

0
0

1
1

6,794
6,794
6,794
6,794
6,794

6.083
0.093
0.174
3.158
0.204

5.198
0.291
0.379
1.324
0.403

1
0
0
1
0

19
1
1
7
1

6,794
6,794
6,794
6,794
6,794
6,794
6,794

11.032
0.370
0.163
0.121
15.954
0.000
0.000

4.530
0.096
0.079
0.062
3.035
1.000
1.000

0
0.00
0.00
0
1.78
-9.01
-15.26

75
1.00
0.75
0.5
30.65
1.22
3.88

5,448
5,448
5,448
5,448

9.980
16.122
0.571
0.857

10.915
20.513
1.199
1.672

0
0
0
0

117
287
20
17

132
132
132

0.161
117.312
47.950

0.355
43.185
24.964

0
31
5.5

1
206
99

429
429

116.9
3.3

50.5
2.5

31
1

210
13

21,453
21,453
21,453

71.6
0.049
0.011

48.9
0.215
0.103

1
0
0

208
1
1

Table 2: Impact of Applicant and Reviewer Gender on Reviewer Scores
(1)

(2)

VARIABLES
Female Applicant
Female Reviewer

(3)
(4)
DV = Reviewer Score

-0.165*** -0.163*** -0.163***
(0.062)
(0.062)
(0.063)
0.052
(0.053)

-0.141**
(0.064)

Female Applicant X Female Reviewer
Reviewer X Round Characteristics:
Log(Proposals Under Review)
Log(Reviewer Round Sequence)
Log(Proposal Sequence)

Round FEs
Reviewer FEs
Topic Area FEs

(5)

-0.194***
(0.071)

0.364***
(0.138)
-0.812*** -0.840*** -0.658*** -0.759*** -0.764***
(0.104)
(0.107)
(0.137)
(0.149)
(0.149)
0.008
-0.006
0.188**
0.145*
0.141*
(0.038)
(0.038)
(0.086)
(0.086)
(0.085)
-0.088** -0.088** -0.091** -0.090** -0.090**
(0.036)
(0.036)
(0.036)
(0.037)
(0.037)
Y
N
N

Y
N
N

Y
Y
N

Y
Y
Y

Y
Y
Y

Observations
21,453
21,453
21,453
21,453
21,453
Pseudo R-squared
0.0315
0.0317
0.0392
0.0432
0.0435
Ordered logit specification; Robust standard errors clustered by reviewer in parentheses
*** p<0.01, ** p<0.05, * p<0.1

34

Table 3A: Impact of Applicant Gender on Pre-Period Publications
(1)

VARIABLES
Female Applicant

(2)

DV = Log(Applicant
Career Length)
-0.377***
(0.034)

-0.385***
(0.034)

(3)

DV = Log(Pre-Period
Publications)
-0.310***
(0.035)

Log(Applicant Career Length)

Round FEs
Topic Area FEs

(4)

-0.112***
(0.031)

(5)
(6)
DV = Share of TopJournal Pre-Period
Publications
-0.023***
(0.008)

0.512***
(0.014)
Y
N

Y
Y

Observations
4,005
4,005
Pseudo R-squared
0.043
0.054
OLS specification; Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

Female Applicant

Y
N

Y
Y

Y
N

Y
Y

4,005
0.025

4,005
0.249

4,005
0.012

4,005
0.030

4,005
0.037

4,005
0.220

-0.163***
(0.063)

-0.164**
(0.065)

-0.159**
(0.065)

-0.134**
(0.066)

-0.187***
(0.070)
0.359***
(0.139)

(3)
(4)
DV = Reviewer Score

-0.040
(0.131)
-0.067*
(0.040)
0.088**
(0.043)

-0.015
(0.129)
-0.079*
(0.042)
0.067
(0.046)
0.349**
(0.138)
0.102
(0.111)

0.018
(0.129)
-0.067
(0.042)
0.063
(0.046)
0.346**
(0.139)
0.092
(0.115)

0.017
(0.129)
-0.067
(0.042)
0.063
(0.046)
0.344**
(0.139)
0.091
(0.115)

Y
Y
N
Y

Y
Y
N
Y

Y
Y
Y
Y

Y
Y
Y
Y

Female Applicant X Female Reviewer

Log(Pre-Period Publications)
Share of Top-Journal Pubs
Share of Last-Author Pubs

Round FEs
Reviewer FEs
Topic Area FEs
Reviewer X Round Controls

Y
Y
N
Y

0.133***
(0.003)

Y
Y

(2)

Log(Applicant Career Length)

-0.022**
(0.009)

Y
N

(1)

Publication History Not Available

-0.071***
(0.010)

0.028***
(0.004)

Table 3B: Impact of Applicant Gender and Publication History on Reviewer Scores

VARIABLES

-0.011
(0.008)

(7)
(8)
DV = Share of LastAuthor Pre-Period
Publications

Observations
21,453
21,453
21,453
21,453
Pseudo R-squared
0.0391
0.0396
0.0402
0.0441
Ordered logit specification; Robust standard errors clustered by reviewer in parentheses
*** p<0.01, ** p<0.05, * p<0.1

35

(5)

21,453
0.0444

Table 4A: Applicant Propensity to Re-Apply After Rejection

VARIABLES
Female Applicant

(1)
(2)
(3)
(4)
DV = Repeat Applicant After Rejection
-0.186**
(0.084)

-0.177**
(0.084)

-0.098
(0.086)
0.256***
(0.049)

-0.100
(0.086)
0.262***
(0.057)
0.059
(0.047)
-0.389**
(0.195)

Y
N
N

Y
Y
N

Y
Y
N

Y
Y
Y

4,462
0.0940

4,462
0.0952

Log(Applicant Career Length)
Log(Pre-Period Publications)
Share of Top-Journal Pubs

Round FEs
Topic Area FEs
Additional Publication Characteristics

Observations
4,496
4,462
Pseudo R-squared
0.0813
0.0860
Logit specification; Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1
Table 4B: Impact of Repeat Applicants on Reviewer Scores
(1)

(2)

(3)
(4)
DV = Reviewer Score

-0.163***
(0.063)

-0.151**
(0.063)

-0.130**
(0.064)

0.256***
(0.061)

0.252***
(0.064)

VARIABLES
Female Applicant

(5)

(6)

-0.127*
(0.065)

-0.121*
(0.070)
-0.022
(0.182)

-0.174**
(0.078)
-0.020
(0.182)
0.358**
(0.139)

0.256***
(0.064)

0.262***
(0.080)

0.262***
(0.080)

-0.079*
(0.042)
0.062
(0.046)
0.349**
(0.139)
0.092
(0.115)

-0.079*
(0.042)
0.062
(0.046)
0.349**
(0.139)
0.092
(0.114)

-0.078*
(0.042)
0.062
(0.046)
0.347**
(0.139)
0.091
(0.114)

Y
Y
Y
Y
Y

Y
Y
Y
Y
Y

Y
Y
Y
Y
Y

21,453
0.0455

21,453
0.0458

Female Applicant X Repeat Applicant
Female Applicant X Female Reviewer

Repeat Applicant After Rejection

Log(Applicant Career Length)
Log(Pre-Period Publications)
Share of Top-Journal Pubs
Share of Last-Author Pubs

Round FEs
Reviewer FEs
Topic Area FEs
Additional Publication Characteristics
Reviewer X Round Controls

Y
Y
N
N
Y

Y
Y
N
N
Y

Y
Y
Y
N
Y

Observations
21,453
21,453
21,453
21,453
Pseudo R-squared
0.0392
0.0406
0.0445
0.0455
Ordered logit specification; Robust standard errors clustered by reviewer in parentheses
*** p<0.01, ** p<0.05, * p<0.1

36

Table 5A: Applicant Characteristics and Proposal Word Choice

VARIABLES
Female Applicant

(1)

(2)

All Frequent
Words

High-Scoring
Words

0.007
(0.007)

-0.026***
(0.007)

0.055***
(0.014)

-0.019***
(0.007)

-0.027
(0.045)
0.573***
(0.051)
0.554***
(0.063)
0.036***
(0.002)

1.123***
(0.014)
-0.317***
(0.039)
0.484***
(0.046)
0.328***
(0.057)
-0.005***
(0.001)

1.075***
(0.025)
0.584***
(0.076)
-0.950***
(0.095)
-0.592***
(0.115)
0.014***
(0.003)

-0.009*
(0.004)
0.005
(0.016)

-0.003
(0.004)
0.051***
(0.015)

Y
Y
Y
Y

Log(Frequent Word Count)
Noun Share
Adjective Share
Verb Share
Proposal Text Grade Level

Log(Applicant Career Length)
Share of Top-Journal Pubs

Round FEs
Topic Area FEs
Additional Text-Based Controls
Applicant Publication Characteristics

Observations
6,794
R-squared
0.212
Poisson Specification; Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

(3)
(4)
(5)
DV = Proposal Text Unique Word Count
Low-Scoring
Male HighMale LowWords
Scoring Words Scoring Words

(6)

(7)

Broad Words

Narrow Words

0.040***
(0.014)

-0.014**
(0.007)

0.024**
(0.011)

1.119***
(0.013)
-0.362***
(0.038)
0.402***
(0.045)
0.264***
(0.056)
-0.001
(0.001)

1.084***
(0.025)
0.684***
(0.079)
-0.799***
(0.097)
-0.448***
(0.116)
0.006**
(0.003)

1.139***
(0.013)
-0.330***
(0.038)
0.303***
(0.046)
0.418***
(0.057)
-0.003*
(0.001)

1.060***
(0.024)
0.481***
(0.062)
-0.443***
(0.075)
-0.602***
(0.093)
0.006***
(0.002)

0.007
(0.009)
-0.116***
(0.035)

-0.005
(0.004)
0.046***
(0.015)

0.009
(0.009)
-0.103***
(0.033)

0.003
(0.004)
0.011
(0.015)

-0.005
(0.007)
-0.019
(0.026)

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

6,794
0.286

6,794
0.134

6,794
0.281

6,794
0.146

6,794
0.270

6,794
0.147

Table 5B: Applicant Characteristics and Text-Based Score Predictions
The dependent variable is the fitted probability of an ordered-logit regression predicting a proposal score from reviewers, based purely on the words
contained in the proposal's title and description, and calibrated using only the proposals of male applicants. Specifically, the outcome variable predicts
reviewer scores based on the presence or absence of the 500 frequent words with the greatest impact on reviewer scores, further subdivided across words
with a positive impact ("high-scoring") and words with a negative impact ("low-scoring") on reviewer scores in specifications 4 and 5, and across broad and
narrow words (based on the standard deviation of word use across topics) in specifications 6 and 7.
(1)

VARIABLES
Female Applicant

(3)
(4)
(5)
DV = Text-Based Reviewer Score Prediction
Basis: HighBasis: LowBasis: All Frequent Words
Scoring Words Scoring Words

-0.139***
(0.029)

Log(Frequent Word Count)
Noun Share
Adjective Share
Verb Share
Proposal Text Grade Level

(2)

Observations
6,794
R-squared
0.069
OLS Specification; Robust standard errors in parentheses
*** p<0.01, ** p<0.05, * p<0.1

Basis: Broad
Words

Basis: Narrow
Words

-0.106***
(0.029)

-0.095***
(0.029)

-0.084***
(0.029)

-0.060**
(0.029)

-0.155***
(0.032)

-0.335***
(0.044)
-0.277*
(0.155)
0.540***
(0.168)
0.166
(0.199)
-0.007
(0.005)

-0.337***
(0.044)
-0.266*
(0.155)
0.533***
(0.168)
0.166
(0.199)
-0.007
(0.005)

-0.359***
(0.045)
-0.221
(0.149)
0.371**
(0.162)
0.250
(0.191)
0.002
(0.006)

-0.419***
(0.044)
-0.316**
(0.153)
0.456***
(0.166)
0.181
(0.197)
-0.009*
(0.005)

-0.076*
(0.044)
-0.199
(0.166)
0.437**
(0.180)
-0.098
(0.216)
-0.016***
(0.005)

0.532***
(0.047)
0.065
(0.200)
0.472**
(0.199)
-0.199
(0.254)
0.001
(0.005)

0.018
(0.019)
0.054
(0.056)

0.034*
(0.018)
-0.043
(0.057)

0.022
(0.019)
0.049
(0.055)

-0.016
(0.020)
0.163***
(0.056)

-0.027
(0.017)
0.036
(0.061)

Y
Y
Y
N

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

6,794
0.094

6,794
0.095

6,794
0.121

6,794
0.104

6,794
0.018

6,794
0.086

Share of Top-Journal Pubs

Y
N
N
N

(7)

-0.116***
(0.029)

Log(Applicant Career Length)

Round FEs
Topic Area FEs
Additional Text-Based Controls
Additional Publication Characteristics

(6)

37

Table 5C: Impact of Proposal Text on Reviewer Scores
This table takes the outcome variables for "broad" and "narrow" words from Table 5A and uses them to predict reviewer scores alongside the effect of being a female
applicant. Importantly, the text-based score predictions are calibrated based only on proposals from male applicants, and then calculated for all proposals based on the
presence or absence of the 500 frequent words with the greatest impact on reviewer scores in each proposal's title and description, sub-divided into broad and narrow words
based on the standard deviation of word use rates across topics.
(1)

(2)

(3)

-0.163***
(0.063)

-0.156**
(0.064)

-0.116*
(0.065)

VARIABLES
Female Applicant

(4)
(5)
DV = Reviewer Score

(6)

(7)

(8)

-0.075
(0.064)

-0.052
(0.064)

-0.033
(0.064)

-0.027
(0.066)

-0.085
(0.069)
0.400**
(0.157)

0.663***
(0.060)

0.403***
(0.110)
0.584***
(0.063)

0.401***
(0.109)
0.580***
(0.065)

0.397***
(0.108)
0.578***
(0.066)

0.398***
(0.109)
0.579***
(0.065)

-0.619***
(0.143)
-0.630*
(0.380)
-0.419
(0.434)
0.349
(0.609)
-0.007
(0.015)

-0.589***
(0.145)
-0.553
(0.381)
-0.544
(0.438)
0.346
(0.616)
-0.001
(0.015)

-0.610***
(0.148)
-0.490
(0.384)
-0.372
(0.461)
0.369
(0.627)
-0.005
(0.015)

-0.614***
(0.148)
-0.456
(0.383)
-0.376
(0.460)
0.372
(0.629)
-0.006
(0.015)

-0.615***
(0.148)
-0.454
(0.382)
-0.365
(0.460)
0.366
(0.629)
-0.006
(0.015)

-0.045
(0.043)
0.263*
(0.147)

-0.044
(0.043)
0.261*
(0.147)

Female Applicant X Female Reviewer

Score Prediction from Broad Words

0.904**
(0.378)

Score Prediction from Narrow Words

Log(Frequent Word Count)

-0.122
(0.136)
-0.795**
(0.383)
-0.213
(0.433)
0.259
(0.610)
-0.005
(0.016)

Noun Share
Adjective Share
Verb Share
Proposal Text Grade Level

-0.182
(0.142)
-0.616
(0.383)
-0.435
(0.442)
0.293
(0.613)
0.003
(0.016)

Log(Applicant Career Length)
Share of Top-Journal Pubs

Round FEs
Reviewer FEs
Topic Area FEs
Additional Text-Based Controls
Additional Publication Characteristics
Reviewer X Round Controls

Y
Y
N
N
N
Y

Y
Y
N
Y
N
Y

Y
Y
N
Y
N
Y

Observations
21,453
21,453
21,453
Pseudo R-squared
0.0392
0.0401
0.0538
Ordered logit specification; Robust standard errors clustered by reviewer in parentheses
*** p<0.01, ** p<0.05, * p<0.1

38

Y
Y
N
Y
N
Y

Y
Y
N
Y
N
Y

Y
Y
Y
Y
N
Y

Y
Y
Y
Y
Y
Y

Y
Y
Y
Y
Y
Y

21,453
0.0667

21,453
0.0726

21,453
0.0757

21,453
0.0763

21,453
0.0766

Table 6: Combined Effects of All Explanatory Variables on Reviewer Scores
(1)

(2)

(3)

-0.163***
(0.063)

-0.214***
(0.069)
0.348**
(0.143)

-0.194***
(0.071)
0.364***
(0.138)

VARIABLES
Female Applicant
Female Applicant X Female Reviewer

(4)
(5)
DV = Reviewer Score

(6)

(7)

-0.180**
(0.070)
0.358**
(0.139)

-0.173**
(0.070)
0.358**
(0.140)

-0.076
(0.069)
0.398**
(0.157)

0.256***
(0.064)

0.257***
(0.064)
-0.136
(0.141)
-0.711*
(0.384)
-0.006
(0.451)
0.322
(0.613)
-0.012
(0.016)

0.259***
(0.063)
-0.618***
(0.149)
-0.447
(0.380)
-0.322
(0.457)
0.434
(0.624)
-0.006
(0.015)
0.397***
(0.108)
0.580***
(0.066)

-0.066
(0.042)
0.062
(0.046)
0.342**
(0.139)
0.092
(0.115)

-0.078*
(0.042)
0.062
(0.046)
0.348**
(0.139)
0.091
(0.115)

-0.078*
(0.042)
0.058
(0.046)
0.347**
(0.139)
0.096
(0.115)

-0.055
(0.043)
0.032
(0.048)
0.259*
(0.147)
0.127
(0.116)

Y
Y
Y
N
Y

Y
Y
Y
N
Y

Y
Y
Y
Y
Y

Y
Y
Y
Y
Y

21,453
0.0458

21,453
0.0466

21,453
0.0779

-0.186***
(0.070)
0.357**
(0.139)

Repeat Applicant After Rejection
Log(Frequent Word Count)
Noun Share
Adjective Share
Verb Share
Proposal Text Grade Level
Score Prediction from Broad Words
Score Prediction from Narrow Words

Log(Applicant Career Length)
Log(Pre-Period Publications)
Share of Top-Journal Pubs
Share of Last-Author Pubs

Round FEs
Reviewer FEs
Topic Area FEs
Additional Text-Based Controls
Reviewer X Round Controls

Y
Y
N
N
Y

Y
Y
N
N
Y

Y
Y
Y
N
Y

Observations
21,453
21,453
21,453
21,453
Pseudo R-squared
0.0392
0.0395
0.0435
0.0445
Ordered logit specification; Robust standard errors clustered by reviewer in parentheses
*** p<0.01, ** p<0.05, * p<0.1

39

Table 7: Impact of Applicant Gender on Post-Period Outcomes
(1)

(2)

(3)

Phase 2
Applications

Phase 2
Successes

Article Count

Female Applicant

-0.022
(0.104)

-0.109
(0.511)

0.011
(0.082)

-0.009
(0.145)

Average Proposal Score

0.010
(0.206)
0.030
(0.049)
0.006
(0.020)
0.009
(0.010)

1.294
(1.069)
-0.214
(0.234)
-0.026
(0.122)
0.020
(0.042)

-0.090
(0.201)
0.015
(0.038)
0.021
(0.014)
0.015*
(0.008)

0.036
(0.045)

0.178
(0.172)

Y
Y
Y
Funded &
Active

VARIABLES

Score Prediction from Broad Words
Score Prediction from Narrow Words
Proposal Text Grade Level

Pre-Period Article Count

(4)

(6)

(7)

(8)

(9)

New
Coauthor
Count

New MeSH
Count

NIH Grant
Count

NIH R01
Count

0.001
(0.116)

0.010
(0.112)

-0.014
(0.108)

0.373*
(0.218)

0.339
(0.303)

-0.210
(0.342)
-0.128**
(0.063)
0.038
(0.030)
0.030**
(0.014)

-0.070
(0.281)
0.050
(0.047)
-0.009
(0.018)
0.023**
(0.011)

0.111
(0.316)
-0.187**
(0.080)
0.037*
(0.021)
0.015
(0.012)

-0.034
(0.229)
0.016
(0.041)
0.012
(0.022)
0.018*
(0.010)

0.749
(0.493)
-0.223***
(0.075)
-0.074***
(0.027)
0.038
(0.026)

-0.157
(1.128)
-0.261**
(0.118)
0.046
(0.058)
0.015
(0.031)

0.836***
(0.043)

0.383***
(0.102)
0.584***
(0.089)

0.164*
(0.099)
0.458***
(0.115)

0.229**
(0.093)
0.561***
(0.069)

0.320***
(0.092)
0.331***
(0.083)

0.367***
(0.132)
0.719***
(0.141)

0.676***
(0.162)
0.742***
(0.285)

Y
Y
Y

Y
Y
Y

Y
Y
Y

Y
Y
Y

Y
Y
Y

Y
Y
Y

Y
Y
Y

Y
Y
Y

Funded &
Active

Funded &
Active

Funded &
Active

Funded &
Active

Funded &
Active

Funded &
Active

Funded &
Active

Funded &
Active

500
0.337

500
0.225

500
0.628

500
0.490

500
0.377

500
0.350

Top-Journal New Journal
Article Count
Count

Pre-Period Focal Outcome
Additional Controls:
Round FEs
Topic Area FEs
Applicant Career Length FEs
Sample of Applicants:

(5)

Observations
500
500
500
Pseudo R-squared
0.0525
0.368
0.476
Poisson specification; Robust standard errors clustered by applicant in parentheses
*** p<0.01, ** p<0.05, * p<0.1

40

Table 8: Effectiveness of Funding by Applicant Gender
(1)
VARIABLES

Female Applicant

Article Count

(2)

(3)

Top-Journal New Journal
Article Count
Count

(4)
New
Coauthor
Count

(5)

(6)

(7)

New MeSH
Count

NIH Grant
Count

NIH R01
Count

-0.086
(0.067)
0.195**
(0.095)

-0.265**
(0.113)
0.404**
(0.160)

-0.200**
(0.092)
0.378***
(0.131)

-0.259**
(0.102)
0.376***
(0.134)

-0.199**
(0.087)
0.302**
(0.133)

-0.022
(0.182)
0.411*
(0.237)

-0.208
(0.252)
0.868**
(0.397)

Funding Indicator

0.053
(0.054)

0.139
(0.093)

-0.032
(0.074)

0.187**
(0.085)

0.067
(0.067)

0.113
(0.161)

-0.143
(0.262)

Average Proposal Score

-0.113
(0.233)
0.030
(0.031)
0.007
(0.013)
0.015**
(0.006)

-0.659
(0.436)
-0.028
(0.043)
0.034
(0.022)
0.029***
(0.010)

0.104
(0.356)
0.033
(0.034)
0.001
(0.018)
0.020**
(0.008)

-0.223
(0.345)
-0.035
(0.082)
0.018
(0.021)
0.021**
(0.010)

-0.132
(0.271)
0.054
(0.040)
0.004
(0.015)
0.022***
(0.008)

-0.508
(0.512)
-0.171***
(0.064)
-0.020
(0.025)
0.038**
(0.019)

-1.265
(1.160)
-0.143*
(0.087)
0.018
(0.031)
0.024
(0.026)

0.841***
(0.027)

0.532***
(0.071)
0.435***
(0.069)

0.217***
(0.065)
0.426***
(0.084)

0.240***
(0.059)
0.480***
(0.042)

0.309***
(0.064)
0.341***
(0.064)

0.423***
(0.086)
0.878***
(0.102)

0.475***
(0.121)
1.561***
(0.218)

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

Y
Y
Y
Y

High-Scoring
& Active

High-Scoring
& Active

High-Scoring
& Active

High-Scoring
& Active

High-Scoring
& Active

High-Scoring
& Active

High-Scoring
& Active

1,163
0.509

1,163
0.407

1,163
0.274

1,163
0.283

Female Applicant X Funding

Score Prediction from Broad Words
Score Prediction from Narrow Words
Proposal Text Grade Level

Pre-Period Article Count
Pre-Period Focal Outcome
Additional Controls:
Round FEs
Topic Area FEs
Applicant Career Length FEs
Pre-Period Applicant Characteristics
Sample of Applicants:

Observations
1,163
1,163
1,163
Pseudo R-squared
0.438
0.282
0.178
Poisson specification; Robust standard errors clustered by applicant in parentheses
*** p<0.01, ** p<0.05, * p<0.1

41

