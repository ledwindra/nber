{
    "id": 28886,
    "citation_title": "Synthetic Controls with Staggered Adoption",
    "citation_author": [
        "Eli Ben-Michael",
        "Avi Feller",
        "Jesse Rothstein"
    ],
    "citation_publication_date": "2021-06-07",
    "issue_date": "2021-06-04",
    "revision_date": "None",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Estimation Methods",
        "\n",
        "Health, Education, and Welfare",
        "\n",
        "Education",
        "\n",
        "Labor Economics",
        "\n",
        "Labor Relations",
        "\n"
    ],
    "program": [
        "\n",
        "Economics of Education",
        "\n",
        "Labor Studies",
        "\n",
        "Public Economics",
        "\n",
        "Technical Working Papers",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nStaggered adoption of policies by different units at different times creates promising opportunities for observational causal inference. Estimation remains challenging, however, and common regression methods can give misleading results. A promising alternative is the synthetic control method (SCM), which finds a weighted average of control units that closely balances the treated unit\u2019s pre-treatment outcomes. In this paper, we generalize SCM, originally designed to study a single treated unit, to the staggered adoption setting. We first bound the error for the average effect and show that it depends on both the imbalance for each treated unit separately and the imbalance for the average of the treated units. We then propose \"partially pooled\" SCM weights to minimize a weighted combination of these measures; approaches that focus only on balancing one of the two components can lead to bias. We extend this approach to incorporate unit-level intercept shifts and auxiliary covariates. We assess the performance of the proposed method via extensive simulations and apply our results to the question of whether teacher collective bargaining leads to higher school spending, finding minimal impacts. We implement the proposed method in the augsynth R package.\n\n",
    "acknowledgement": "\nWe would like to thank Alberto Abadie, Howard Bloom, Peng Ding, Arin Dube, Guido Imbens, Skip Hirshberg, Brian Jacob, Luke Keele, Luke Miratrix, Joe Ornstein, Agustina Paglayan, Sam Pimentel, Jake Soloff, Panos Toulis, Chelsea Zhang, and Ben Zipperer for useful discussion and comments, as well as participants at the 2019 Atlantic Causal Inference Conference. We also thank the associate editor and reviewers for constructive feedback. This research was supported in part by the Opportunity Lab and the Institute for Research on Labor and Employment at UC Berkeley, as well as the Institute of Education Sciences, U.S. Department of Education, through Grant R305D200010.  The opinions expressed are those of the authors and do not represent views of the Institute, the U.S. Department of Education, or the National Bureau of Economic Research.\n\n\n"
}