{
    "id": 2861,
    "citation_title": "Choosing Among Alternative Nonexperimental Methods for Estimating the Impact of Social Programs: The Case of Manpower Training",
    "citation_author": [
        "James J. Heckman"
    ],
    "citation_publication_date": "1989-02-01",
    "issue_date": "1989-02-01",
    "revision_date": "None",
    "topics": [
        "\n",
        "Labor Economics",
        "\n"
    ],
    "program": [
        "\n",
        "Labor Studies",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nThe recent literature on evaluating manpower training programs demonstrates that alternative nonexperimental estimators of the same program produce a array of estimates of program impact. These findings have led to the call for experiments to be used to perform credible program evaluations. Missing in all of the recent pessimistic analyses of nonexperimental methods is any systematic discussion of how to choose among competing estimators. This paper explores the value of simple specification tests in selecting an appropriate nonexperimental estimator. A reanalysis of the National Supported Work Demonstration Data previously analyzed by proponents of social experiments reveals that a simple testing procedure eliminates the range of nonexperimental estimators that are at variance with the experimental estimates of program impact.\n\n",
    "acknowledgement": "\n"
}