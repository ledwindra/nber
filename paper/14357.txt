NBER WORKING PAPER SERIES

DESIGN LIMITS AND DYNAMIC POLICY ANALYSIS
William A. Brock
Steven N. Durlauf
Giacomo Rondina
Working Paper 14357
http://www.nber.org/papers/w14357
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2008

This research has been supported by National Science Foundation grant SES-0518274 and the University
of Wisconsin Vilas Trust and Graduate School. We are thankful to the Editor and to three anonymous
referees for their comments and suggestions. We have also benefitted from comments by Lars Hansen,
Christopher Sims and Volker Wieland. Nonarit Bisonyabut, Hon Ho Kwok, and Xiangrong Yu have
provided excellent research assistance. The views expressed herein are those of the author(s) and do
not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2008 by William A. Brock, Steven N. Durlauf, and Giacomo Rondina. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.

Design Limits and Dynamic Policy Analysis
William A. Brock, Steven N. Durlauf, and Giacomo Rondina
NBER Working Paper No. 14357
September 2008, Revised July 2013
JEL No. C6,E52
ABSTRACT
This paper characterizes the frequency domain properties of feedback control rules in linear systems
in order to better understand how different policies affect outcomes frequency by frequency. We are
especially concerned in understanding how reductions of variance at some frequencies induce increases
in variance at others. Tradeoffs of this type are known in the control literature as design limits. Design
limits are important in understanding the full range of effects of macroeconomic stabilization policies.
We extend existing results to account for discrete time bivariate systems with rational expectations.
Application is made to the evaluation of monetary policy rules.
William A. Brock
Department of Economics
University of Wisconsin
1180 Observatory Drive
Madison, WI 537061393
wbrock@ssc.wisc.edu
Steven N. Durlauf
Department of Economics
University of Wisconsin
1180 Observatory Drive
Madison, WI 53706-1393
and NBER
sdurlauf@ssc.wisc.edu

Giacomo Rondina
Department of Economics
University of California at San Diego
La Jolla, CA 92093
grondina@ucsd.edu

1. Introduction

This paper explores a set of constraints on the effects of control policies on
fluctuations from the perspective of the frequency domain. Aspects of these constraints
were initially discussed in Brock and Durlauf (2004,2005) and Brock, Durlauf, and
Rondina (2008a) but otherwise do not appear to have been previously explored in
economics contexts. The constraints we study represent fundamental limits on the effects
of alternative policies in the sense that they describe how frequency-specific tradeoffs in
volatility generically apply to linear feedback rules.
Frequency-specific fluctuations represent an aspect of the effects of policies that
has received little attention from economist. Suppose one is considering how different
controls affect the stochastic process of a state variable x t . Underlying the statistic

var (xt C ) , the variance of the process given a control C , is the spectral density of x
given the control, fx C (w ) , because the variance is the integral of the spectral density, i.e.

(

)

p

var xt C = ò fx C (w )d w .
-p

(1)

In fact, the spectral representation of the variance of the state means one can understand
the state variance as the sum of the variances from random and orthogonal sines and
cosines of different frequencies. By implication, calculations of the effects of a rule on
the overall variance mask the effects on fluctuations at the different frequencies in

[-p, p ] . Further, eq. (1) hints at the idea that a rule that minimizes the overall variance
may exacerbate fluctuations at certain frequencies. A major goal of this paper is to
determine under what circumstances this must happen and what forms such fundamental
tradeoffs take. In the control literature, these tradeoffs are known as design limits.
Design limits are a well established area of study in control theory.1 An important
class of results of this type are sometimes known as Bode integral constraints, after
1

Our description of linear systems owes much to the formulation in Kwakernaak and
Sivan (1972), especially chapter 6, and Skogestad and Postlethwaite (1996), as well as
1

Hendrik Bode who first proposed them in the 1930’s. One methodological contribution of
this paper is that we derive frequency tradeoffs for multiple-input multiple-output
(MIMO) systems for both forward and backward looking systems. Some of our discrete
time results for backwards-looking systems appear to be new to economics, although they
naturally follow from existing results. In contrast, the work on forward looking systems
is entirely new. We defer consideration of systems with arbitrary dimensions to future
work, noting here that the 2 ´ 2 cases we study capture a range of important contexts,
most notably the evaluation of macroeconomic stabilization policy.
In addition to presenting abstract results on frequency specific tradeoffs, we apply
our methods to the analysis of monetary policy rules. This work provides a supplement to
studies such as Judd and Rudebusch (1998) which focus on regime-specific tradeoffs
between overall inflation and output gap volatility. Here we engage in two exercises.
First, we examine the frequency by frequency differences in the effects of the monetary
policy rules followed by Arthur Burns, Alan Greenspan, and Paul Volcker. As a positive
exercise, we are able to show how differences in the inflation and the output gap in the
different regimes involve specific tradeoffs frequency by frequency. One example of an
insight gained from our approach is that the Volcker regime’s major difference from the
other two regimes involves the reduction of inflation at the cost of increased low
frequency output gap volatility. Second, we demonstrate how one can supplement the
conventional inflation/output gap Phillips curve with frequency-specific Phillips curves.
The frequency-specific Phillips curves allow one to assess the monetary policy regimes in
terms of their efficiency, as measured by their distance from the trade-off frontier. These
exercises, of course, are dependent on an assumed model of the joint proves of inflation
and output determination. We in fact consider different models indexed by the role of
expectations. The behavior of the rules across different models is also informative. For
example, the Volcker low frequency output gap “sacrifice” is inefficient when
expectations of future inflation on current inflation are small, but is efficient when these
expectations matter.

Seron, Braslavsky, and Goodwin (1997) and various articles, e.g. Chen and Nett (1993,
1995) and Wu and Jonckheere (1992).
2

In addition to providing new positive insights into the structure of tradeoffs
between different stabilization objectives, we further believe that frequency-specific
tradeoffs have normative interest in evaluating monetary policies. One reaction to the
recognition that a Central Bank face frequency-by-frequency constraints might be that
these constraints are irrelevant if the objective of a policymaker is to minimize the overall
variance of some combination of states and controls of the system, Such loss functions
are standard in the literature on evaluating monetary policy rules. We argue that our
results are of interest for several reasons. First, there is no principled reason why a
Central Bank’s loss function should only depend on the overall variances of variables of
interest, and in fact time-nonseparable preferences can lead to the assignment of different
loss function weights across frequency-specific fluctuations. Examples of this property
are found in Otrok (2001) and Otrok, Ravikumar, and Whiteman (2002).

Second,

differences in the approximation value of a given model to fluctuations at different
frequencies may lead to a focus on higher versus lower frequency fluctuations using a
model to assess policies; this type of reasoning is developed in Onatski and Williams
(2003). Third, frequency-specific fluctuations can matter for structural reasons. Meltzer
(2003 pg. 65-66) describes how a major reason for the creation of the Federal Reserve in
1914 was the magnitude of seasonal fluctuations associated with the agricultural sector.
Diminution of these types of fluctuations thus had distributional consequences in the
reduction of risk for farmers. More interesting for contemporaneous issues, as we will
see, different monetary policy rules, because of design limits, can reduce overall variance
at the expense of enhancing the role of low frequency fluctuations and so provide a
different perspective on whether high booms and busts are persistent. Fourth, there are
classes of problems for which the frequency restrictions matter, even if loss functions
only depend on unconditional variances. Specifically, evaluating the robustness of policy
rules in the face of model uncertainty may be facilitated using the constraints we
describe; an initial example of such an analysis is Brock and Durlauf (2005).
In our judgment, the most important contribution of this paper is its introduction
of the idea that macroeconomic stabilization policies involve tradeoffs that are hidden
when a policy is evaluated by calculation of its effects on the variances of the standard
macroeconomic aggregates. This kind of result is sometimes also called a “conservation

3

law” or “waterbed” result in the engineering literature. Indeed we will exhibit various
conservation laws and waterbed results and illustrate their consequences for a set of two
sector macroeconomic models of inflation and the output gap that are commonly used in
the macroeconomics literature.
The use of frequency domain methods is not original per se, of course. One
classic example is Hansen and Sargent’s (1980,1981) use of z -transform methods to
translate time domain expectations into the frequency domain and thereby solve for
testable restrictions of rational expectations models. Another important contribution is
Bowden’s (1977) and Whiteman’s (1985,1986) work on spectral utility and the frequency
domain analysis of the effects of policies; Whiteman’s work is close in spirit to ours,
although it does not address the issue of frequency-specific tradeoffs. More recently,
frequency methods have proven to be important in the development of the growing
macroeconomic literature on robustness, cf. Sargent (1999), Kasa (2000), Hansen and
Sargent (2007, Chapter 8)). That being said, frequency domain approaches continue to
be far less popular than time domain methods for analyzing macroeconomic dynamics.
We believe the methods developed here complement these other papers in demonstrating
that frequency domain approaches have an important role in understanding stabilization
policy. While, in principle, one can always translate results from the frequency domain to
the time domain and vice versa, the results we exploit are an example in which working
in the frequency domain is relatively straightforward whereas it would appear that the
same analysis in the time domain may well be intractable.2
Section 2 provides design limits for a general two equation linear system. Section
3 applies our methods to the evaluation of monetary policy rules. Section 4 contains
summary and conclusions. An Appendix follows which contains proofs of our main
theorems.

2. Design limits in multivariate systems

i. Basic ideas
2

The Bode integral constraint, which we exploit in our analysis, has an extremely
convoluted time domain representation, cf. Iglesias (2001) equation 3.2.
4

Before proceeding to formal propositions, we outline the basic ideas underlying
the construction of design limits. Letting x t denote a 2 ´ 1 vector of states, ut a 2 ´ 1
vector of controls, and et a 2 ´ 1 vector of disturbances that is second-order stationary
across time, the canonical law of motion we study is the system

A0xt = bE t xt +1 + A (L) xt -1 + B (L) ut + et .

(2)

where b is a 2  2 matrix, Et (⋅) is the expectational operator conditional on information
up to time t 3 and A (L ) , B (L ) are polynomial matrix lag operators in non-negative
powers of L . We assume et can be written in the moving average form below where
the second order stationary stochastic process wt has mean vector zero and identity
variance matrix,

et = W (L )wt ,

(3)

with W (L ) a rational polynomial matrix lag operator in non-negative powers of L . We
do not require the moving average representation to be fundamental. The reason for this
is that our interpretation of the model is that it is a structural description of a system as
opposed to vector autoregression representation. We note that there is now a long
tradition of working with linear or log linear approximations to microfounded
macroeconomic models which take the form (2), Woodford (2003, Chapter 8) is a good
example. Other examples in which microfounded linear systems are studied include the
backwards looking model in Onatski and Stock (2002) and forwards-looking model in
Giannoni (2002)4.
3

We do not need to be specific about the information set upon which the expectational
operator in (2) conditions upon. Our results apply under any information set at time t as
long as it contains at most the entire state of the world up to time t .
4
Work on the general use of these approximations starts with Magill (1977).
5

We study feedback rules of the form

ut = U (L) xt -1 .

(4)

where U (L) is a polynomial matrix lag operator in non-negative powers of L . We
assume that the elements of A(L) , B (L ) , W (L) and U (L ) can always be written as the
ratio of two finite degree polynomials.
Under rational expectations, the equilibrium law of motion of this system will
possess a moving average representation5

xt = DU (L) wt .

(5)

where DU (L ) is a rational polynomial matrix lag operator in non-negative powers of L ,
and associated spectral density matrix
fx |U (w ) =

1 U
¢
D (w ) Sw DU (w ) ,
2p

(6)

where Sw is the variance covariance matrix of w and DU    DU  e  i  . Note that for
any matrix function N , N ¢ is its conjugate transpose. Each choice of the polynomial

U (L ) produces an associated spectral density matrix for the state variable vector. We
restrict ourselves to feedback rules for which the spectral density matrix fxU| (w) exists.
One way to understand the effects of a control rule is by considering the way that

fxU| (w) depends on the feedback rule U (L) . The feasible set of control rules, i.e. those
of the form (4) and for which a spectral density matrix exists, determines the feasible
spectral density matrices for the state variables. Our goal is to use the feasible set for

5

The superscript U denotes the dependence of the function D (L ) on a specific feedback

rule U (L ) .
6

fxU| (w) to understand the opportunity set faced by a policymaker; design limits refer to
restrictions on this opportunity set. Since our objective is to compare policies, we state
our theorems in terms of how different policy rules affect state variables relative to some
baseline control rule U (L ) = u

B

(L) .

The baseline system is characterized by

A0xt = bEtxt +1 + A (L) xt -1 + B (L) u B (L) xt -1 + et .

(7)

and the solution x tB (when it exists and is unique) will have a moving average
representation

xtB = DB (L) wt .

(8)

and spectral density
fx B ( w ) =

1 B
¢
D (w ) Sw D B (w ) .
2p

(9)

From the vantage point of a baseline rule, one can think of policy comparisons as
deriving from

(

)

A0x t = b Et x t +1 + A (L ) + B (L ) u B (L ) x t -1 + B(L)uC (L ) x t -1 + et .

(10)

C
B
where u (L ) denotes the deviation of a feedback rule from u (L ) 6. We assume that
C
the baseline rule has eliminated unit or explosive roots7. Each choice of u (L ) will

produce an associated process

6

B
The control theory literature typically treats the baseline as u (L ) = 0 and so compares

controlled and uncontrolled systems. We do not follow this convention both because we
wish to provide tools for policy comparisons and because no control systems can exhibit
unit or explosive roots; these roots are uninteresting in terms of policy comparison since
any sensible policy will eliminate them. Note that by employing
7

xt = DC (L) wt ,

(11)

and spectral density matrix

fx C (w ) =

1 C
¢
D (w ) Sw D C (w ) .
2p

(12)

From the vantage point of rule-specific spectral density matrices for the state
B
variables, deviations from u (L ) may be interpreted as the transformation of fx B (w )

into fx C (w ) . To understand this transformation, we follow the control theory literature
B
and define a sensitivity matrix S (L) via the way in which the control transforms D (L)
C
into D (L) , i.e.
-1

S (L) = DC (L) D B (L) ,

(13)

¢
fx C (w ) = S e-iw fx B (w ) S e-iw .

(14)

which in turn implies that

( )

( )

 (L) = A(L) + B (L) u B (L) and treating (10) as application of control uC (L ) to the
A
 (L) one can usefully think of
“uncontrolled” system with autoregressive polynomial A
the baseline as an uncontrolled system.
7
The design of controls that eliminate a unit or explosive root is subjected to frequency
specific tradeoffs that can be characterized using the same approach that we employ in
this paper (see Freudenberg and Looze (1988)). By restricting ourselves to comparing
tradeoffs across classes of policies that have already achieved the stabilization of a
system we abstract from frequency specific tradeoffs that originate solely from
stabilization.
8

This formulation makes clear why, in the control literature, the sensitivity function is said
C
to shape the behavior of the state vector. As each D (L) corresponds to some S (L) ,

one can think of the choice of a control relative to the baseline as the choice of a
C
sensitivity function; any constraints on D (L) in turn may be translated into constraints

on S (L) .
The theory of design limits involves identifying restrictions on S (L) . Assuming
variance at any frequency and any state variable is undesirable, it is obvious that a
policymaker would want to choose a control so that S (L) = 0 . Such a control would
assume that the policymaker can condition on the current shock et before it affects x t .
By construction we have assumed that no feedback rule can alter the effect of et on x t ,
which makes the above control unfeasible. Our assumption is meant to capture the idea
that a policymaker is facing some irreducible uncertainty when implementing a policy,
which is clearly a feature of real world policymaking. One might consider more
sophisticated (i.e. less reduced form) setups to introduce uncertainty about the state of the
economy on the part of the policymaker. As long as perfect conditioning on the current
state is not possible, the results we present will immediately extend to such setups. Our
analysis will provide a full characterization of the set of feasible sensitivity functions and
thereby indicate what limits a policymaker faces in the shaping the spectral density of
state variables.
In our analysis we distinguish between the performance and the fragility of a
policy. The performance of a policy relates to what the policy can achieve in terms of the
objective function that is it designed to optimize. The fragility of a policy relates to the
way a policy modifies the frequency structure of a system to achieve a given
performance. In sections 2.ii and 2.iii we provide our two main theorems on design limits
in MIMO systems. In section 3 we put our theorems to work in a linear dynamic
monetary economy.

ii. design limits in MIMO systems: the backwards looking case

9

In this section, we provide a result for purely backwards looking versions of (2).
This result is mathematically new as it concerns backwards looking system in discrete
time. A continuous time version of the result has been already established (see Skogestad
and Postlethwaite, 1996). We are able to provide a discrete time result by extending the
results in Wu and Jonckheree (1992) to multivariate systems. In isolation, the
mathematical advance is a minor one. However, it serves two purposes. First, it allows us
to formulate design limits in ways that are relevant to the economics literature, which has
focused on discrete time systems. Second, it will lead us to formulate a more general
result on systems with both forwards and backwards elements, which is an unexplored
direction relative to all existing results.

Theorem 1. Design limits in a backwards-looking MIMO model
B
Assume b = 0 . The sensitivity function, S (L) = DC (L) D B (L) , where D (L) and
-1

DC (L) are as in (8) and (11) respectively, must obey
æ
log çç det S e-iw
çè
-p

ò

p

( )

2

÷ö÷d w = 0 ,
÷ø

(15)

B
C
for all stabilizing controls u (L) and u (L) .

Proof: See Appendix.
The proof of Theorem 1 relies on showing that

æ
U
-i w
ò-p log çççè det D e
p

( )

10

2

ö÷
÷d w = K
ø÷

(16)

where K is a constant that does not depend on the control parameters U (L ) . Theorem 1
immediately suggests a corollary.

Corollary 1. Conservation law of fragility in backwards-looking MIMO models

Under the assumptions of Theorem 1

ò

p

-p

(

)

(

p

)

log det fx C (w ) d w = ò log det fx B (w ) d w
-p

(17)

B
C
for all stabilizing controls u (L) and u (L) .

Proof: Since

ò

p

-p

(

)

log det fx C (w ) d w =

æ
-i w
ò-p log çççè det S e
p

( )

2

p
ö÷
÷÷d w + ò log det fx B (w ) d w,
-p
ø

(

)

(17) follows immediately from (15).

Theorem 1 and Corollary 1 give the following substantive conclusions. First, in
the scalar case, (17) implies that any change in control from a baseline control that
decreases power on some set of frequencies will end up magnifying spectral power at
some other set of frequencies. We call this result a “conservation law of spectral power”;
sometimes is also referred to as “waterbed effect”. Second, for the multivariate case, (17)
still implies a type of conservation law of spectral power, albeit in a somewhat weaker
sense (hence the term “fragility”). Recall that the spectral density matrix fx C (w ) is a
positive semi-definite Hermitian matrix (Priestley (1981, page 668)) and

det fx|C (w) = fx|C ,11 (w) fx|C ,22 (w) - fx|C ,12 (w) fx|C ,21 (w) ,

11

where fx|C ,11 (w) and fx |C ,22 (w) are the spectral densities for the stochastic variables in
C
the vector x t , while fx|C ,12 (w) and fx|C ,21 (w) are cross-spectral densities. Corollary 1

says that the integral over all frequencies of the log of the modulus of the determinant

(

)

det fx C (w ) is constant for all stabilizing controls uC (L ) .
In most applications, the focus of a policy is in minimizing some linear
combination of the spectral densities fx|C ,11 (w) and fx |C ,22 (w) . One might think that if
C
B
control u (L ) dominates control u (L ) in the sense that

fx|C ,11 (w) < fx|B,11 (w) and fx|C ,22 (w) < fx|B,22 (w)

(18)

at all frequencies w Î éêë-p, p ùúû , then uC (L ) would contradict Corollary 1. However, this
C
is not so. A control u (L ) that reduced fx |C ,11 (w ) and fx |C ,22 (w ) can in principle be

offset by changes in fx |C ,12 (w ) or fx |C ,21 (w ) so that Corollary 1 is satisfied even when
dominance of the form (18) holds. Of course if the cross spectral densities are zero at all
frequencies, then dominance cannot occur because it would contradict Corollary 1.
Projecting this result into an economic framework, one can think at the existing
correlation across the elements of x t as, for instance, the slope of the Phillips curve in a
canonical monetary policy model. Corollary 1 warns that such slope can substantially
influence the ability to reduce both the variance of inflation and output over the same
frequency range. The application in Section 3 shows that this can well be the case.
The conservation law of fragility emerging from Theorem 1 can be thought as
being the consequence of the policymaker being unable to condition on the current
realization of shocks that are perturbing the economy. If such a policy rule was feasible,
then it would be possible to isolate the dynamics of the system from any stochastic
variation. In absence of such a rule, the policymaker is bound to allocate the variation
across frequencies in search for a desirable outcome.
12

We turn now to a closely related design limit. To fix ideas it is useful to isolate
the steady state response of the controlled system to a vector input under the baseline
policy when the baseline system consists of fluctuations at a single frequency w , i.e. let
x tB = x B (w )e i wt ,

(

)

where x B (w ) = x 1B (w ) , x 2B (w ) is a vector of real numbers8. When the input xtB is fed
into the system represented by S (L ) one obtains the vector output xtC ; formally this can
be expressed as

( )

x C (w ) = S e -iw x B (w ) ,

2
where e i wt does not appear as it cancelled on both sides. Defining x (w ) º x (w )¢ x (w ) ,

we have the following result.

Lemma 1. Singular values of sensitivity matrix
Let s and s denote, respectively, the minimum and the maximum singular values9 of

( )

the sensitivity matrix S e -i w . Then

8

We have implicitly assumed that the phase of the two components of the vector x is
equal to zero. This does not have to be the case, and usually it is not, but the presence of a
phase shift does not affect the interpretation of the singular values of the sensitivity
matrix and so, for simplicity, we omit its consideration. See Kwakernaak and Sivan
(1972, page 457) on this point.
9
Recall that any matrix M may be factored so that M  N V where  is diagonal and N
and V are unitary matrices, i.e. each multiplied by its conjugate transpose produces an
identity matrix. The elements of  are the singular values of the matrix.
13

( ( ))

s S e -iw

2

£

x C (w )

2

(w )

2

x

B

( ( )) .

£ s S e -iw

2

Proof: See Appendix.

To see the relevance of Lemma 1 for our purposes, notice that the total steady
state variance over the frequency band (w, w + d w ) for the stationary process x Ut is

2
2
2ö
æ
xU (w ) d w = ççxU1 (w ) + xU2 (w ) ÷÷d w = fx |U ,11 (w ) + fx |U ,22 (w ) d w ,
è
ø

(

)

(19)

where fx |U ,11 (w ) and fx |U ,22 (w ) are, once again, the spectral densities of the individual
elements of x Ut . The interpretation of the bounds imposed by the singular values of the
sensitivity matrix in Lemma 1 relies on the notion of “input direction”. Given the spectral
power of the input at a given frequency, one can think of allocating that spectral power in
any proportion across the input variables at that particular frequency. The vector that
describes the allocation weights is known as the input direction in control theory. For
example, using (19) we can write the lower bound of Lemma 1 as

( ( )) ( f

s S e -iw

2

x |B ,11

(w ) + f

x |B ,22

(w ))d w = inf

{v ¢S (e ) ' S (e ) v}( f (w ) + f
-i w

v =1

-i w

x |B ,11

x |B ,22

(w ))d w.

This expression says that, given the sum of the spectral densities of the variables in x B at
a particular frequency, if one were to consider allocating such spectral power in any
proportion (i.e. in any direction v ) across the two variables in x B at the same frequency,
the minimum total spectral power of the controlled system x C at that frequency would be
proportional to the initial sum of the spectral densities in reason of the minimum singular
value of the sensitivity matrix.

14

Loosely speaking, the notion of direction is not immediately related to the
probability measure of the input variables, x B in our case, but more so to the support of
such probability measure. The variables in x B can realize in a particular direction at a
given frequency, with an intensity bounded by the total spectral power of the vector at
that frequency, but with a probability that is not necessarily related to the total spectral
power. The lower bound given by Lemma 1 can then be interpreted as providing the best
case scenario for the alternative policy performance at a given frequency. If the direction
of the system under the benchmark policy happens to be equal to the direction that
delivers the minimal response under the alternative policy, the total spectral power of the
control system will be at its minimum. On the other hand, the upper bound of Lemma 1
informs about the worst-case scenario for the alternative policy performance. If the
direction of the system under the benchmark policy happens to be equal to the direction
that corresponds to the maximal response, the performance of the alternative policy can
achieve the upper bound. In this sense, the upper bound can be considered as a measure
of the fragility of the controlled system to a particular combination of events. For
instance, an alternative policy that keeps the upper bound low across a set of frequencies
is robust to any possible realizations of the benchmark system within that frequency
range. On the other hand, an alternative policy that allows a high value of the upper
bounds at a specific frequency range is fragile to a combination of shocks that happens to
realize in that specific direction. In section 3 we will apply this criterion to evaluate the
performance of alternative monetary policy rules. This type of exercise is completely
novel to the monetary policy literature.
Lemma 1 will be useful in interpreting the following Corollary, which follows
immediately from Theorem 1 and the fact that

æ
¢
det çççS e -iw S e -iw
è

ö

( ) ( )ø÷÷÷÷ = s (S (e )) s (S (e )).
-i w

-i w

Corollary 2. Design bounds for a backwards looking MIMO model.

Under the assumptions of Theorem 1,
15

ò

p

-p

(

( ( )) d w + ò

log s S e -iw

)

(

2

p

-p

( ( )) d w = 0,

log s S e -iw

2

(20)

)

where s S (e -iw ) and s S (e -iw ) are the singular values of the sensitivity matrix

( )

S e-iw .
Considering the above interpretation for the singular values of the sensitivity
matrix, Corollary 2 describes the following design limit: if a policy is designed so to
reduce the response of the system at a particular frequency range – for any direction of
the output under the original policy (e.g. s < 1 over a frequency range) – then one
cannot avoid: (i) an increase in the minimal response of the system at the same frequency
at any direction (a higher s at the same frequency range); (ii) an increase in the maximal
response of the system at any direction outside the targeted frequency range (a higher s
at a different frequency range). In terms of a monetary policy application, if a policy
regime is designed to work well under a given realization of shocks – say a shock to
inflation at low frequencies – then the same policy could be fragile to shocks to output at
business cycle frequencies. The evaluation of the singular values of the sensitivity matrix
across frequencies will provide such valuable information.
In addition, since
p
æ
0 = ò log ççs S e-iw
-p
èç

ö

æ
log ççs S e-iw
-p
èç

( ( )) s (S (e )) ø÷÷÷d w £ 2ò
2

-i w

2

p

ö

( ( )) ø÷÷÷d w
2

(21)

one sees that there exists a “fragile” set of frequencies where total variance over that set
is magnified if application of control happened to be in the direction that delivers the
maximal response to the benchmark system according to Lemma 1. In interpreting the
results of our application in section 3, it will be useful to think of the design limits
characterized by (20) as a restriction in the achievable performance under the alternative
policy, while interpreting equation (21) as measuring the fragility intrinsic in a particular
control policy. Notice that, under such an interpretation, a given policy can achieve a

16

performance improvements (a situation where s is very low) together with a fragility
enhancement (by simultaneously making s very high). Corollary 2 also suggests that a
similar tradeoff can obviously appear not only at a given frequency but also across
frequencies.

iii. design limits in MIMO systems: the role of forward looking expectations
We now turn to the case where expectations affect the state variables, i.e. b ¹ 0 .
We have the following result.

Theorem 2. Design limits for a general MIMO model
U
Assume that a Rational Expectations Equilibrium (REE) solution D (L ) exists and is
B
C
unique under both the baseline control u (L) and the alternative control u (L) . The
B
C
sensitivity function, S (L) = DC (L) D B (L) , where D (L) and D (L) are as in (8)
-1

and (11) respectively, must obey

æ
-iw
ò-p log çççè det S e
p

( )

2

ö÷
C
B
÷d w = K (u | u ) ,
ø÷

(22)

C
B
where K(u | u ) denotes a constant that depends on both the baseline and the

alternative control rules.
Proof: See Appendix.
The proof of Theorem 2 relies on showing that, contrary to the case with b = 0 ,

æ
U
-i w
log
ò-p çççè det D e
p

( )

17

2

ö÷
÷d w = K (U ),
ø÷

(23)

where K (U ) is now a constant that depends upon the control parameters in U (L ) . In
contrast with Theorem 1, Theorem 2 implies that for forward looking systems, the
C
B
constant K(u | u ) is not restricted to be non-negative. In particular, conditional on
C
B
stability being ensured, a set of policies can result in positive values for K(u | u ) ,

while another set of policies can result in negative values. As a consequence, while an
analogue to Corollary 1 is not available for forward looking systems, Theorem 2 still
provides a useful metric to evaluate alternative dynamic policies. Consider a scalar case
first. Theorem 2 implies that there exist policies under which the spectral power of the
output variable can be reduced at all frequencies. It still remains true that a policy cannot
reduce the variance of the states to 0 (this follows from the fact that the policymaker
cannot condition on current shocks), so a conservation law of spectral power is still
present in some form, but cannot be characterized as sharply as for the b = 0 case.
The intuition behind the difference between the results of Theorems 1 and 2 can
be found in the interplay between the forward looking behavior of the agents and the
possibility of committing to a policy rule. As it was the case for Theorem 1, the
policymaker is still unable to condition on the current realizations of the shocks in setting
her control policy. In contrast to the earlier situation, however, by committing to a
permanent application of the rule, the policymaker can affect the expectations of agents
about the future behavior of the economy. Since agents can condition on current shocks
when forming their expectations, the policymaker can indirectly condition on such shocks
and escape some of the unavoidable tradeoffs faced in Theorem 1.
To elaborate further on this, notice that the constant K (U ) depends on the control
parameters. This dependence is induced through the forward looking behavior of the
U
equilibrium moving average coefficients D (L) . One might think that this dependence

implies that the design limit constraint imposes no restrictions on the change in spectral
power induced by a change in control. However, since the space of possible control
changes is higher dimensional while K (U ) is one dimensional, Theorem 2 provides a
metric that partitions the space of possible control changes into “equivalence classes”

18

each with the same value of K (U ) . Within each equivalence class, the design limits
characterized by Theorem 1 and Corollary 2 continue to hold. We can state an
“equivalence class” result analogue to Corollary 2 as follows.

Corollary 3. Design bounds for a general MIMO model.
Under the assumptions of Theorem 2, for all the control rules uC (L ) belonging to the
equivalence class K , i.e. such that K (uC | u B ) = K ,

ò

p

-p

(

)

( ( )) d w + ò

log s S e -iw

(

2

p

-p

( ( )) d w = K ,

log s S e -iw

2

(24)

( )

)

-iw
.
where s S (e -iw ) and s S (e -iw ) are the singular values of the matrix S e

An immediate implication of Corollary 3 is the following
p
æ
K = ò log ççs S e-iw
çè
-p

ö

æ
log ççs S e-iw
-p
èç

( ( )) s (S (e )) ÷÷÷ød w £ 2ò
2

-iw

2

p

ö

( ( )) ÷÷÷ød w.
2

(25)

The interpretation of the bounds identified by (24) and (25) parallels the one outlined for
Corollary 2, both in terms of performance and fragility of alternative policy rules. The
difference is that the evaluation of the performance and the fragility is now conditional to
the rules belonging to a given equivalence class K . Hence, we should still expect a
“conditional waterbed” type of result to hold when conducting simulations of the impact
of a change of control in models with forward looking components. In terms of our
application, Theorem 2 and Corollary 3 suggest that the characterization of design
bounds for alternative policy rules should be complemented by the analysis of the
“structure” of the space of equivalence classes as the parameters of the policy rules are
changed. For example, within a given class, one policy rule could be preferred to another
because it achieves a more desirable balance in terms of performance and fragility. As a

19

consequence, in presence of two rules that display either a similar performance or similar
fragility across frequencies but belong to two different classes, the above results suggest
that the policymaker should look for a third policy within each class that might improve
upon the original one in both performance and fragility.

3. Application: monetary policy regimes and design limits

Much of the modern literature on monetary policy evaluation involves the
analysis of linear systems of the type we have abstractly characterized; see Taylor and
Williams (2010) for a recent review that illustrates how systems of the form (2) are
canonical in the monetary policy evaluation literature. We illustrate the value of design
limits analysis by considering the frequency domain implications of deviations from the
Taylor Rule for monetary policy. Specifically, we compare the Taylor Rule to the actual
monetary policy regimes that have prevailed in the United States. The last 40 years of
monetary policy can to some extent be understood as consisting of three periods: the pre1979 or Burns period, the 1979-1987 or Volcker period and the post-1987 or Greenspan
period10. We study the performance of the three regimes with respect to the original
Taylor rule (henceforth “OTR”) in order to expose the “hidden tradeoffs” forced by the
conservation laws derived in section 2. We develop our exercise as follows. First, we
compute the performance of the three regimes at different frequency bands to show how
the usual focus on the overall unconditional variance masks interesting frequency specific
effects of alternative monetary policies. Second, we use the underlying model of the
economy to define equivalence classes of monetary policy rules according to the fragility
measure they entail as formalized by Theorems 1 and 2. We then categorize the three
10

We follow Judd and Rudebusch (1998) and Sims and Zha (2006) in working with
distinct Volcker and Greenspan regimes rather than Clarida, Gali and Gertler (2000) or
Taylor (1999) who combine them into a common one. There is no consensus on the
number of monetary policy regimes for the post-war US. Sargent, Williams, and Zha
(2006) provide evidence that changes in government beliefs about the nature of the
Phillips curve explain changes in monetary policy; their evidence on time series of these
beliefs suggests that it is sensible to distinguish between the Volcker and Greenspan
years
20

policy regimes above according to the class they belong. Finally, we provide a design
bounds analysis, using Corollaries 2 and 3, to evaluate the location and the magnitude of
the fragility implicit in each of the three regimes above.
We explore the limits encountered by a policymaker trying to design the response
of output and inflation at different frequencies conditional on the now standard twoequation New-Keynesian class of inflation/output models. In what follows pt denotes
inflation, yt denotes output gap, rt denotes the real interest rate and it denotes the
nominal interest rate. The system consists first of a Phillips curve equation

4

pt = mEt pt +1 + (1 - m) å ai pt -i + gyt + et ,

(26)

i =1

where the error term is assumed to be AR(1), et = re et -1 + v1t , and of an Euler-IS
equation for output,

4

yt = df Et yt +1 + (1 - df ) å diyt -i - srt + ht .

(27)

i =1

The error term is also assumed to be AR(1), ht = rh ht -1 + v2t .
We focus on two forms of this model. The first specification we consider is the
backwards-looking model elaborated by Rudebusch and Svensson (1999) which sets

m = 0 , imposes

4

åa
i =1

i

=1 to ensure a long run vertical Phillips curve, and measures the
4

real interest rate as rt = .25å (it -i - pt -i ) . We employ their parameter estimates. The
i =1

second specification, comprehensively studied in Woodford (2003), assumes m > 0 ,

ai = 0 "i (which essentially rules out any exogenous persistence to the inflation rate),
and rt = it - Et pt +1 . For this model specification, which we will refer to as “hybrid”, we
take parameter estimates for the Phillips curve from Gali, Gertler and Lopez-Salido

21

(2005, Table 1) and parameter estimates of the IS equation from Linde (2005, Table 5).
Table 1 reports the parameter values for the two cases.
In order to operationalize the comparison of the regimes, we employ estimates
due to Judd and Rudebusch (1998) that describe these different monetary policy regimes
in terms of changes in the parameters of interest rate rules. Judd and Rudebusch (1998)
consider two specifications of the monetary policy rule for each regime. One is a
generalized Taylor rule

it = gp pt -1 + gy1yt -1 + gy 2yt -2,

(28)

which does not contain any persistence of the policy instrument. They interpret this as a
“recommended rule” (henceforth “RR”) for interest rates. They consider both the case
where the Federal Reserve can implement its recommended rule as well as a second
“measured” rule (henceforth “MR”) of the form
it = gp pt -1 + gy 1yt -1 + gy 2yt -2 + gi 1it -1 + gi 2it -2 .

(29)

The use of 2 lags in interest rates, following Judd and Rudebusch, is done to allow for the
possibility that the observed interest rate does not coincide with the policymaker’s
preferred interest rate, but rather adjusts towards this preferred interest rate via an error
correction model.

In addition, interest rate inertia may have desirable stabilization

properties. The values of the coefficients for (29) and (30) for the three regimes are
reported in Table 2. We follow Judd and Rudebusch (1998, p. 4) and omit any discussion
of the William Miller’s time as FRB chairman (1978.Q2-1979.Q2) because of his short
tenure. The main reason to consider both forms of the regimes (with and without interest
rate persistence) is to study the effect of the persistence in interest rate on the design
limits tradeoffs. The original Taylor rule takes the form of (29) with g p = 1.5 , gy 1 = 0.5
and gy 2 = 0 .
Tables 3 reports the behaviors of output and inflation variances under the three
regimes. Note that the variances under the Burns reaction function are infinite as the
22

model evaluated at the Burns reaction function is nonstationary.

This finding is

consistent with Judd and Rudebusch (1998, Table 2, page 12) where they observe that the
model did not converge for their estimated Burns reaction function. Convergence does
occur for the hybrid case. Contrasts are also drawn with the original Taylor rule, which
plays the role of the baseline rule in our theoretical results.
To put our discussion in context, we review the performance properties of the
three regimes across the two models for the economy. As indicated by Table 3, for the
backwards model both Greenspan and Volcker perform better than OTR. However, most
of the difference in Volcker’s performance is due to lower inflation volatility – 9.6
against 12.2 – while output volatility is essentially the same as OTR – 5.4 against 5.6. On
the other hand, Greenspan’s better performance is split between lower inflation volatility
and lower output volatility, 11.3 against 12.2 and 4.6 against 5.6, respectively. Turning to
the hybrid model, for both the preferred and recommended cases, one finds that the
Volcker regime performs slightly better in terms of inflation volatility but much worse in
terms of output volatility than the Burns and Greenspan regimes. The OTR performs
very similarly to Volcker’s regime. We note that for the hybrid model the distinction
between the preferred and measured rules is second-order, in particular in terms of
inflation variance implications.
How do the different monetary regimes compare when frequency-specific effects
are considered? To answer this question we turn to Table 4. We consider the backwards
case first. For the RR rule, the Volcker regime outperforms OTR at low frequencies for
inflation and at business cycle frequencies for output; while it underperforms in output at
low frequencies. According to Theorem 1, the deterioration in performance at low
frequencies in output variance (.5) is the price the Volcker regime pays with respect to
OTR to achieve a better performance at other frequencies (2.6 in inflation variance at low
frequencies and .6 in output variance at business cycle). For the Greenspan regime the
variance in inflation at low frequencies is only slightly below OTR, which results in a
gain of performance at low frequencies in output and an equivalent performance at
business cycle frequencies in both output and inflation with respect to OTR.

The

tradeoffs highlighted by the MR case are very similar to the RR case with the only
difference that now the tradeoff between inflation at low frequencies and output at low

23

frequencies is much more severe. For an improvement of .5 in inflation variance at low
frequencies, Volcker now pays 1.6 in output variance at low frequencies. In this
particular case, persistence in the policy rule worsens the design limits.
Next we consider the hybrid case. Theorem 2 states that tradeoffs in this case
depend on the specific policy under consideration. An immediate example of this
principle can be found in comparing the performance of the Burns regime and the
Greenspan regime with respect to OTR. In both cases the variance for inflation both at
low and business cycle frequencies is maintained very close to OTR while both regimes
clearly outperform OTR in the variance of output at low and business cycle frequencies.
Although tradeoffs are policy dependent in the hybrid case, they can still be severe at the
margin. This is illustrated by the Volcker regime performance for the hybrid case.
Volcker obtains a gain in the volatility of inflation at low frequencies of .3 compared to
OTR, but the price to pay is an increase of 3.1 in the variance of output at low
frequencies.
Corollary 2 offers an additional perspective on the overall tradeoffs across
different frequencies in a multivariate system. Figures 1 and 2 report the behavior of the
lowest and the highest singular values of the sensitivity matrices for the three regimes
with respect to the benchmark policy OTR. Focusing on the RR rule under the Volcker
regime (Figure 1, upper left panel) one can clearly see that the regime increases the
performance compared to OTR at frequencies between 2 to 8 years. As Corollary 2
suggests, this comes at a price: a lower performance at cycles shorter than 2 years and at
cycles around 16 years. Interestingly, the upper and lower bounds never diverge more
than .2 in value, which means that the Volcker regime does not really operate an increase
in fragility compared to OTR. Looking at the Greenspan regime (Figure 1, lower left
panel) one sees that there is a remarkable increase in performance at cycles between 4
and 16 years. In this range s is very close to 1, while s is constantly declining. The
improved performance comes at a price, per Corollary 2. Such price takes two forms. On
the one hand, there is a mild deterioration of performance at frequencies between 2 to 4
years. On the other hand there is an important increase in fragility at low frequencies,
where s and s spread out by a value of .9 with s reaching an increase of around 55%
at the lowest frequency. When the measured rule is considered for the Volcker regime the

24

same type of features can be noticed: improved performance at 4 to 8 years cycles, with
deterioration at 16 years cycles, but no increased fragility. For the Greenspan regime it is
more difficult to argue for an improved performance at cycles of duration 4 years and
higher, while the increase in fragility is now bigger: depending on the relative relevance
of inflation and output shock at low frequencies under OTR, the Greenspan regime can
almost completely annihilate such shock or amplify it by a factor of almost 5.
When the hybrid model is considered, Theorem 2 together with Corollary 3
suggest that tradeoffs are still possible, but that their importance is related to the
equivalence class to which a regime is associated. An examination of the different policy
regimes compared to the benchmark represented by OTR allows us to operationalize the
idea of equivalence classes suggested by the result of Theorem 2. Theorem 1 defines one
equivalence class, that of policies that deliver a stationary solution and that, as a
consequence, face design limits summarized by K = 0 . Theorem 2, on the other hand,
defines an equivalence class for any value of K , in particular for values of K < 0 . Table
5 reports the values for K across different regimes, models and policy rule
representations. Interestingly, the Volcker and the Greenspan regimes belong to a very
similar class as the values for K is -.41 and -.46 in the RR case and -.11 and -.19 in the
MR case. Overall, a negative value for K indicates a class of policies that face looser
design limits. The values for K reported in Table 5 are consistent with the results of
Figure 2 when compared to those of Figure 1. Both the Volcker and Greenspan regimes
do not imply an increase in fragility as strong as for the backwards case. Remarkably, the
Greenspan regime under the RR case operates a reduction in fragility across all
frequencies. Both performance and fragility deteriorate under the MR representation,
which is consistent with higher values for K , for both the Greenspan and Volcker
regime. Finally, the Burns regime seems to belong to a different equivalent class. In
particular, the Burns regime under RR belongs to a similar class as Volcker and
Greenspan under MR. This is in line with the bounds reported in Figure 2 where the RR
panel for Burns looks very similar to the MR panels for Volcker and Greenspan.
We turn next to the analysis of the performance of the monetary policy regimes
with respect to a frequency-specific Phillips curve. The original Phillips hypothesis of a
long-run negative tradeoff between the level of inflation and the level of output has been

25

fundamentally modified by theoretical and empirical advances since Phillips’ time.
Contemporary research focuses on the existence of a tradeoff between variance of
inflation and the variance of output deviations from its natural level. As policies are
computed to minimize different linear combinations of variance for the output gap and
inflation, a negatively sloped frontier emerges. Any point in the frontier corresponds to
the unconditional variance of inflation and output that emerges for a given value for l
under the policy that minimizes the value for the loss function J . From the perspective
of design limits, it is natural to ask how whether a similar frontier exists at different
frequency ranges and how the monetary regimes locate with respect to such frontiers.
To compute the variance tradeoff frontiers for inflation and output we proceed as
follows. For each point on the frontier, parameters are chosen for the interest rate rule
it = g p pt -1 + gyyt -1 + giit -1

(30)

so that feedbacks are restricted to t - 1 levels of output, inflation, and the interest rate.
Points on the frontier are chosen to minimize
J = l var (pt ) + (1 - l ) var (yt ) .

(31)

By varying l between 0 and 1, one traces out the efficient frontier of inflation/output
variance pairs from which a policymaker may choose. For each point on the frontier we
report an associated decomposition of the variance values into components corresponding
to the same division between low frequencies (cycles of 8 years or more), business cycle
frequencies (cycles of 2 to 8 years), and high frequencies (cycles of less than 2 years).
The resulting frequency-specific Phillips curves are reported in Figures 3 and 4. The
frequency-specific tradeoffs in these Figures indicate how the unconditional variance
frontier contains additional frontiers where efficiency no longer applies. The shape of the
frontier is obviously related to the structural model acting as a constraint on the
optimization problem of the policy maker. The existence of design limits shapes the
frontiers at different frequencies.

26

We consider first the frontiers under the backwards looking model in Figure 3.
The general shape of the overall variance tradeoff found for the backwards model is
replicated for the variance at the low frequency bands, but not for the others. The
frequency interval tradeoffs indicate some unpleasant implied tradeoffs at the business
cycle frequencies and high frequencies. Suppose that the policy rule is initially optimally
set by a policymaker D (for “Dove”) who possesses a relative distaste for output variance
over inflation variance, so that l = 0.05 . Suppose that a new policymaker H (for
“Hawk”) replaces the first policymaker and that H possesses a relative distaste for
inflation variance over output variance, so that l = 0.95 . As one would expect, the
transition from D to H moves along the frontier as indicated in the upper left panel of
Figure 3 as lower inflation variance is substituted for higher output variance. This overall
tradeoff masks interesting frequency-specific effects. For low frequencies, the qualitative
finding of an inflation/output variance tradeoff is preserved, although a substantially
larger reduction in inflation variance may be obtained from a given increase in output
variance when the low frequencies are considered in isolation. Tradeoffs are very
different for the business cycle frequencies, as shown in the lower left panels of Figure 3.
Both the variance of inflation and output increase as the policy shifts from D to H. While
it is relatively cheap to reduce inflation variance at low frequencies (measured in terms of
low frequency output variance), a price is paid at the business cycle frequencies, where
the variance of inflation is increased. At high frequencies, on the other hand, both
inflation and output variances decline when the policy shifts from D to H, although the
magnitude is very small compared to the rest of the spectrum.
Figure 4 reports the same exercise when a policymaker faces a hybrid model.
Note that while the shape of the variance frontier at low frequencies is similar to the
backwards looking case, the shape of the business cycle and high frequency frontiers are
now different. With respect to overall variance, the qualitative difference between the
backwards and hybrid models is that the marginal rate of substitution between output and
inflation variance is considerably smaller than the backwards-looking case. In other
words, moving along the variance frontier entails a smaller cost under the hybrid model.
The upper right and lower left panels of Figure 4 shows that this difference in costs is a
consequence of differences in the tradeoffs associated with the business cycle

27

frequencies. For this case, as the variance of inflation is reduced at low frequencies, a
similar reduction happens at business cycle frequencies since the frontier is now
downward sloping. The cost of reducing the variance for inflation is higher at high
frequencies but the relative importance of those frequencies in terms of overall variance
remains small.
How do the monetary policy regimes perform relative to the inflation/output
variance frontiers? Figures 3 and 4 include the locations of outcomes under the Burns
(when Burns converges), Volcker and Greenspan rules relative to the inflation/output
frontiers.

In terms of overall variance there are no surprises except possibly the

domination of Burns by Greenspan in the hybrid model. For the hybrid model the
performance of all three regimes is about the same for the implied frontier at high
frequencies. But the “conservation law of fragility” suggests that the volatility must end
up somewhere at the business cycle frequencies and the lower frequencies. For the
hybrid model the important difference shows up at the low frequencies. Burns suppresses
output volatility in return for a high price in terms of inflation volatility at low
frequencies while Volcker does almost the exact opposite; from this perspective
Greenspan may be regarded as a compromiser between the two. Note that, at business
cycle frequencies for the hybrid model, the three chairmen are much closer together.
These important contrasts and similarities are completely masked by the standard
frontier.
To conclude our discussion we turn to study the behavior of K across different
policy parameter values. Figure 5 reporst surface plots of K against values for the policy
parameter on inflation and on output. The upper panel considers the case of a zero
persistence in the interest rate, while the lower panel is derived under a positive
persistence of the interest rate. For simplicity, when the combination of parameter values
is such that the system has no stationary solution or multiple solutions, the value assigned
to K is arbitrarily high (to denote the undesirability of such a situation). Consider the
upper panel first. Interestingly, from Figure 5 it is clear that the value for the inflation
policy parameter gp does not affect much the severity of the design limits faced by the
policymaker. On the other hand, the design limits become more severe for low values of

28

the output policy parameter gy . Overall, a weak response of the interest rate to both
inflation and output seems to be the worst possible combination in terms of the severity
of the design limits across frequencies. Consider now the lower panel of Figure 5.
Introducing persistence in the policy parameter improves the ability to achieve a better
tradeoff across the board as the entire surface essentially shifts down. Because we do not
allow persistence in the output policy parameter, the interst rate persistence is achieving
the improvement by essentially increasing the steady state reaction to both output and
inflation. In addition, interest rate inertia tends to loosen the design limits for the hybrid
model homogeneously across the other two dimensions of monetary policy as the shape
of the surface in the lower panel is essentially equal to the shape in the upper panel.
Finally, the bold light countour lines in the top panel of Figure 5 represent the set
of policies that are equivalent to, respectively, the regimes under the backwards model
(for K = 0 ), and the Volcker and Greenspan regime under the hybrid model (for
K = - 0.45 ). Notice how the set of policies that are equivalent, in a design limits sense,

to the Greenspan and Volcker regimes under the hybrid model, are those for which a
increase in the inflation policy parameter is counterbalanced by only a small decrease in
the output policy parameter. In other words, the design limits are much more sensitive to
the policy reaction to output than to the reaction to inflation in both regimes.
Summarizing, the application of the results of section 2 to a standard dynamic
monetary economy revealed some novel insights in terms of monetary policy rules
evaluation. For the class of rules with no interest rate inertia (RR), the Greenspan regime
displays an excellent control performance at all frequencies with respect to OTR, and it
displays a remarkable low level of fragility in presence of forward looking components,
while fragility is really high at low frequencies in absence of those components. On the
other hand, for the class of rules with interest rate inertia (MR) the Greenspan regime
maintains desirability in terms of performance, but it displays remarkable fragility at
business cycle frequencies in presence of forward looking components and at low
frequencies in the absence of those components. In summary, because of the existence of
design limits, if the policymaker was particularily concerned about shocks at business
cycle frequencies, the above analysis would suggest that the Greenspan regime would
make the outcome much more fragile with respect to such shocks compared to OTR or

29

even the Volcker regime when the economy is believed to behave according to the hybrid
model. However, such fragility might be unavoidable as the price to pay to achieve a
remarkable improvement in the performance at lower frequencies for any combination of
shocks.

4. Summary and conclusions

This paper has argued the case for introducing macroeconomics to the theory of
design limits in control theory. The general theory of design limits (e.g. Skogestad and
Postlewaite (1996)) stresses limitations on the ability of control design to move variance
across frequencies (expressed in the form of various “conservation laws”) as well as
limitations on the ability of control design to cope with measurement error and
robustification against various forms of model uncertainty. We have only touched on one
feature of the general theory of design limits in this paper in that we have focused all
attention on the basic conservation laws which give precise content to the intuitive idea
that attempts to reduce variance down at one frequency band can cause variance to
increase at some other frequency band.
Many outstanding questions exist. For example, we have said nothing about

( )

-iw
, is
good designs to cope with measurement error. While the sensitivity function, S e

the function from which one can design good policies to cope with outside shocks to the

( )

-i w
dynamics, the complementary sensitivity function, T e
, is relevant in coping with

separate issues that arise in the presence of measurement error. See Skogestad and

( )

-i w
Postlethwaite (1996, Section 2.2.2 and Section 6.2) for the definition of T e
as well

( )

( )

-iw
+ T e-iw = I and its use in uncovering design
as the design limits constraint, S e

limits

( )

constraints

in the

presence

of measurement

error.

The

constraint

( )

S e-iw + T e-iw = I plays a key role in showing that measurement error results in
another type of conservation law that constrains placement of volatility across different

30

frequency bands. We are developing this line of research in a sequel to the current paper.
Further, there is a close connection between the robust control literature (e.g. Hansen and
Sargent (2007)) and the theory of design limits. Design limits theory focuses on control
design to robustify against (i.e. moderate) outside shocks. Robust control theory focuses
on control design to robustify against a lack of confidence in analyst’s ability to specify
the dynamics of the system under study. Design limits theory should be useful to robust
control theorists because it uncovers frequency bands where model uncertainty can do the
most damage to the designer’s goal. Thus, using this information, the designer can
design a control to mitigate damage at the most vulnerable frequency bands; Brock and
Durlauf (2004) provide an example. Yet another important set of questions concern the
generalization of design limits theory to nonlinear systems; Pataracchia (2008) provides
an analysis of this type for switching regime models. For these reasons we believe that
design limits theory is an unusually rich area for future research.

31

Table 1. Model Parameter Values

Phillips Curve
Backwards

m
g

Output Equation

Hybrid

0.635

a1

0.14
0.70

0.013
0

a2

0.10

0

a3
a4

0.28
0.12

0
0

0
1.009

0.75
0.7957

s

2
v

Hybrid

0
1.16

0.430
1.275

0.25

0.253

df
d1
d2
d3

0

re

Backwards

d4
s
rh
s

2
u

0

0.012

0

0.012

0.10

0.087

0

0.35

0.819

0.4006

Table 2. Monetary Policy Regimes

RR

MR

gp

g1y

g 2y

gp

gy 1

gy 2

gi 1

gi 2

Burns

0.85

0.16

0.72

0.16

0.09

0.40

0.69

-0.25

Volcker

1.69

2.40

-2.04

2.40

0.86

-0.73

0.56

0.08

Greenspan

1.57

1.10

-0.12

1.10

0.30

-0.03

1.16

-0.43

Table 2 reports the measures of the Burns (1970Q1-1978Q1), Volcker (1979Q3-1987Q2)
and Greenspan (1987Q3-1997Q4) regimes of Judd and Rudebush (1998).

32

Table 3. Overall Regime Performance

Backwards

Taylor (OTR)

Hybrid

v  t 

v  yt 

v  t 

v  yt 

12.2

5.6

3.1

9.4

Recommended Rule (RR)
Burns





3.4

4.1

Volcker

9.6

5.4

2.8

10.9

Greenspan

11.3

4.6

3.2

4.5

Measured Rule (MR)
Burns





3.4

4.7

Volcker

11.7

6.8

2.6

14.4

Greenspan

12.1

5.5

3.1

6.6

Note: Table 3 reports the unconditional variances for Inflation and Output computed
using the backwards and hybrid models under 4 alternative policy rules. The first row
reports the results for the Original Taylor Rule. Rows 2-4 report the results for the 3
regimes - Burns, Volcker and Greenspan - under the specification RR for the policy rule
(see Table 2). Rows 5-7 report the results for the three regimes under the specification
MR for the policy (see Table 2).

33

Table 4. Frequency-Specific Regime Performance

Backwards

v  t 

Taylor (OTR)

Hybrid

v  yt 

v  t 

v  yt 

Low

BC

Low

BC

Low

BC

Low

BC

11.0

0.7

3.0

2.2

1.3

1.4

4.1

4.8

Recommended Rule(RR)
Burns









1.5

1.5

1.2

2.3

Volcker

8.4

0.6

3.5

1.6

1.0

1.4

7.2

3.4

Greenspan

10.1

0.6

2.0

2.2

1.4

1.4

1.8

2.3

Measured Rule (MR)
Burns









1.5

1.5

1.3

2.7

Volcker

10.5

0.6

4.6

1.8

0.8

1.4

8.9

5.1

Greenspan

10.8

0.7

2.4

2.8

1.4

1.3

2.1

3.9

Note: Table 4 reports the variance for Inflation and Output computed using the
backwards and hybrid model under 4 alternative policy rules at different frequency
ranges. Low stands for the variance generated at cycles of period 8-year and longer; BC
stands for the variance generated at cycles of period 2 to 8 years. The first row reports the
results for the Original Taylor Rule. Rows 2-4 report the results for the 3 regimes - Burns,
Volcker and Greenspan (see Table 2). Rows 5-7 report the results for the three regimes
under the specification MR for the policy (see Table 2).

34

Table 5. Equivalence Classes, Values for K

Backwards

Hybrid

Recommended Rule
Burns

0

-.12

Volcker

0

-.46

Greenspan

0

-.41
Measured Rule

Burns

0

.04

Volcker

0

-.11

Greenspan

0

-.19

C
B
Note: Table 5 reports the values for K (u | u ) of Theorem 2 where u B is the original

Taylor Rule and uC are in turn the Burns, Volcker and Greenspan regimes as specified in
Table 2.

35

Figure 1: Design Bounds for Backwards Looking Model
Recommended Rule

Measured Rule
Volcker Regime

1.6

1.6

1.4

1.4

1.2

1.2

1

1

0.8

0.8

0.6

0.6

0.4

8

4

2
Cycle Period in Years

0.4

1

8

4

2
Cycle Period in Years

1

8

4

2
Cycle Period in Years

1

Greenspan Regime
5
4.5

1.6

4
1.4

3.5
3

1.2

2.5
1

2
1.5

0.8

1
0.6
0.4

0.5
8

4

2
Cycle Period in Years

0

1

Note: Figure 1 and Figure 2 plot the maximum and the minimum singular values for the

( ( )) and s (S (e )) , under the three different policy regimes

sensitivity matrix, s S e -iw

-i w

uC of Table 2 (provided a given regime implies stationary behavior for Inflation and
Output Gap). The benchmark policy u B is the original Taylor rule. To facilitate the
reading of the plots, the frequency range for Figure 1 is from cycles of 1 year (4 quarters)
and cycles of arbitrary duration, while the range from Figure 2 is from cycles of ½ year
(2 quarters) and cycles of arbitrary duration.

36

Figure 2: Design Bounds for Hybrid Model
Recommended Rule

Measured Rule
Burns Regime

1.6

1.6

1.4

1.4

1.2

1.2

1

1

0.8

0.8

0.6

0.6

0.4

8

4

2

1
Cycle Period in Years

0.4

0.5

8

4

2

1
Cycle Period in Years

0.5

8

4

2

1
Cycle Period in Years

0.5

4

2

1
Cycle Period in Years

0.5

Volcker Regime

1.6

1.6

1.4

1.4

1.2

1.2

1

1

0.8

0.8

0.6

0.6

0.4

8

4

2

1
Cycle Period in Years

0.4

0.5

Greenspan Regime

1.6

1.6

1.4

1.4

1.2

1.2

1

1

0.8

0.8

0.6

0.6

0.4

8

4

2

1
Cycle Period in Years

0.4

0.5

37

8

Figure 3. Frequency-Specific Phillips Curves: Backwards Model

Overall Variance

Variance at Low Frequencies

25

25
g =1.5 gy =0.5 gi=0


20

Hawk
Dove
Volcker
Greenspan

15

Inflation

Inflation

20

10
5
0

15
10
5

2

4

6

8
10
Output

12

14

0

16

0

1

1.1

0.56

1

0.54
Inflation

Inflation

0.58

0.9
0.8

0.5
0.48

0.6

0.46
4

6
Output

5

0.52

0.7

2

4

Variance at High Frequencies

Variance at Business Cycle Frequencies

0

3
Output

1.2

0.5

2

8

10

0.44
0.35

12

0.4

0.45

0.5
0.55
Output

0.6

0.65

0.7

Note: The four panels report aspects of the inflation and output processes that correspond
to the minimization of the loss function (66) as  is varied between 0 and 1, under the
backwards-looking model. The upper left panel reports the frontier for the overall
variance of inflation and output. The upper right panel reports the implied tradeoffs for
the variance of inflation and output at frequency of 8 years or more for the different pairs
in the variance frontier. The bottom panels report the implied tradeoffs for the variance of
inflation and output at business cycle frequencies (2-8 years) and at higher frequencies
(less than 2 years). Each panel also locates the variances of output and inflation for the
relative frequency range that result under five policy rules: (i) the Original Taylor Rule
(circle), (ii) the “Dove” Optimal Policy (diamond), (iii) the “Hawk” Optimal Policy
(star), (iv) the Volcker regime, (v) the Greenspan Regime. The Burns regime results in a
non-stationary system and therefore is not reported. The optimal policies correspond to
rules of the form (66) with coefficients chosen to minimize (66) with   0.05 (D) and
  0.95
(H). The coefficients are derived using a grid search over the space
g   0.0,10.0 , g y   0.0,10.0
gi   0.9, 0.9 .
and
The
two
policies
are
g  4, g y  8.2, g i  0.9 (D) and g  10.0, g y  4.0, g i  0.3 (H).

38

Figure 4. Frequency-Specific Phillips Curves: Hybrid Model
Overall Variance

Variance at Low Frequencies

3.8

1.8
g =1.5 gy =0.5 gi=0


3.6

1.6

Hawk
Dove
Volcker
Greenspan
Burns

Inflation

Inflation

3.4
3.2
3

1.4
1.2

2.8
1

2.6
0

5

10
Output

15

0.8

20

0

Variance at Business Cycle Frequencies

5

10
Output

15

20

Variance at High Frequencies

1.6

0.395

1.55
0.39
Inflation

Inflation

1.5
1.45
1.4

0.385

1.35
1.3
1.25

0

1

2

3
Output

4

5

0.38

6

0

0.2

0.4
0.6
Output

0.8

1

Note: The four panels report aspects of the inflation and output processes that correspond
to the minimization of the loss function (66) as  is varied between 0 and 1, under the
hybrids model. The upper left panel reports the frontier for the overall variance of
inflation and output. The upper right panel reports the implied tradeoffs for the variance
of inflation and output at frequency of 8 years or more. The bottom panels report the
implied tradeoffs for the variance of inflation and output at business cycle frequencies (28 years) and at higher frequencies (less than 2 years). Each panel also locates the
variances of output and inflation for the relative frequency range that result under five
policy rules: (i) the Original Taylor Rule (circle), (ii) the “Dove” Optimal Policy
(diamond), (iii) the “Hawk” Optimal Policy (star), (iv) the Volcker regime, (v) the
Greenspan Regime and (vi) the Burns regime. The optimal policies correspond to rules of
the form (65) with coefficients chosen to minimize (66) with   0.05 (D) and   0.95
(H). The coefficients are derived using a grid search over the space g   0.0,10.0 ,
g y   0.0,10.0 and gi   0.9, 0.9 . The optimal policies are g  0.1, g y  10.0, g i  0.0 (D) and
g  1.6, g y  1.0, g i  0.5 (H).

39

Figure 5: Equivalence Classes for the Hybrid Model

gi = 0
K 0
K  0.45

gi = 0.5

Figure 3 displays the values for K across different policy parameters of the monetary
policy rule it = g p pt -1 + gyyt -1 + giit -1 applied to the hybrid model. For combination of
parameters such that the underlying model is either non-stationary or it displays multiple
solutions an arbitrarily high value for K is assigned.
40

Appendix

Many of our derivations employ the following lemma, due to Wu and Jonckheere
(1992), which we report for convenience.

Lemma A.1. (Wu and Jonckheere)

ò

p

-p

2

log e iw - r d w = 0 if r £ 1;

= 2plog r

2

if r > 1.

(A.1)

The original proof of this result is a substantial simplification of an alternative approach
that would employ contour integration and the Cauchy’s Integral Theorem to achieve the
same conclusion. We direct the interested reader to the paper for details. Here we notice
that one can think of the above integral as measuring the Wold fundamental innovation
variance of a stochastic process with dynamics given by 1 - lL .11 Below we will
2

compute the integral of log 1 - le -iw . In the complex domain the integral takes the
form

1
2pi

ò log éêë(1 - lz )(1 - lz )ùúû
-1

dz
1
=
z
2pi

dz

ò log (1 - lz ) z

+

1
2pi

dz

ò log (1 - lz ) z
-1

For l < 1 the first term on the RHS is zero by Cauchy’s residue theorem since the
argument is analytic inside the unit disk. The second term might seem more problematic,
but with the change of variable v > z -1 the argument is also analytic inside the unit disk,
with the direction of the integration reversed. The case of l > 1 instead implies a
positive residue. In this case the innovation implicit in the process represented by 1 - lL
is non-fundamental in the Wold sense. To transform the innovation into a fundamental
one it is enough to apply the Blaschke factor

11

l -z
. Because the Blaschke factor has
1 - lz

We are thankful to a referee for pointing out this interesting connection.

41

measure 1 under contour integration, the only factor left to integrate will be

(

)(

log l 2 1 - l-1z 1 - l-1z -1

)

which will result in 2p log l

2

by the Cauchy residue

theorem, which is exactly what (A.1) is stating.
Proof of Theorem 1.
Without loss of generality assume A0 = I . We may write the controlled system

(

U
as xt = I -C (L) L

)

-1

æ
U
Since det ççç I - C (z ) z
è

(

W (L) wt = DU (L) wt where C U (L) º A(L) + B (L)U (L) .

)

-1

ö
W (z )÷÷÷ = detW (z ) / det I - C U (z ) z , we consider each
ø

(

)

term in turn. By the fundamental theorem of algebra

(

det I - C

U

m

CU

)

(

(z ) z =  1 - lCj z
j =1

U

)

(A.2)

where mC U is the degree of the characteristic polynomial of the system controlled by

U (L) and liC

U

are the eigenvalues of C U (L ) .

Since the system is stable, all
U

eigenvalues are inside the unit circle in the complex plane, i.e. lCj < 1 for
j = 1, 2,..mCU . Lemma A.1 applied to (A.2) when z = e-iw gives

ò

p

-p

m

CU

log  1 - l e
j =1

C U -i w
j

2

m

CU

p

d w = å ò log e iw - lCj
j =1

-p

U

2

dw = 0 .

(A.3)

Given our assumptions on the structure of W (L ) we have

P j =MA1 (1 - w j z )
w

detW (z ) = w

P j =AR1 (1 - r j z )
w

where w is a real constant, ri ’s are the autoregressive roots of the characteristic
polynomial of W (z ) and wi ’s the moving average roots. Since W (L) is assumed

42

second-order stationary, r j < 1 for

j = 1,2,..wAR . On the other hand, W ( L ) is not

necessarily fundamental and so it might display moving average roots with modulus
greater than one. From Lemma A.1 it follows that

ò

p

-p

w

log w

Let K º

2

P j =MA1 1 - w je -iw
P

ò

p

-p

wAR
j =1

1 - r je

-i w

( )

2

2

d w = 4p log w + 4p å log wu , j Î {u j } if w j > 1
uj

j

2

log detW e -iw d w ; because the constant does not depend on the control

parameters in U (L ) it cancels out when computing (15) and the result of Theorem 1
follows.

Proof of Lemma 1

Adapting the result of Skogestad and Postlethwaite (1996, pages 71-72, Appendix A) to
our setting one can show that

( ( ))

2

s S e -iw

2

{ ( ) ( )}

2

x B (w ) = x B (w ) inf v =1 v ¢S e -iw ' S e -iw v
¢
£ x B (w ) S e -iw ' S e -iw x B (w )

( ) ( )

2

= x C (w ) ,

and

( ( ))

s S e -iw

2

2

{ ( ) ( )}

2

x B (w ) = x B (w ) sup v =1 v ¢S e -iw ' S e -iw v
¢
³ x B (w ) S e -iw ' S e -iw x B (w )

( ) ( )

2

= x C (w ) .

Combining these inequalities produces the Lemma.

Proof of Theorem 2.
43

Let
æ v (L ) v (L )÷ö
çç n ,11
n ,12
÷÷
ç
v12 (L )÷ö çç vd ,11 (L ) vd ,12 (L ) ÷÷÷
÷÷ = çç
÷÷
v22 (L )÷÷ø çç vn ,21 (L ) vn ,22 (L )÷÷
÷÷
çç
çç v (L ) v (L )÷÷÷
è d ,21
ø
d ,22

æv (L )
ç
V (L ) = V -1W (L ) = çç 11
çèçv21 (L )

(A.4)

where V (0) = I . Using Whiteman (1983) solution procedure (for a more detailed
description see Brock, Durlauf and Rondina (2008b)) the unique REE solution DU (L )
can be written as
æ
ö÷
dnU,11 (L )
dnU,12 (L )
çç
÷÷
çç
÷
1 çç vd ,11 (L ) vd ,21 (L ) vd ,12 (L ) vd ,22 (L )÷÷÷
DU (L ) = U
ç
÷÷ .
dnU,21 (L )
dnU,22 (L )
dd (L ) çç
÷÷
çç
÷
çç v (L ) v (L ) v (L ) v (L )÷÷÷
è d ,11
ø
d ,21
d ,12
d ,22

where ddU (L ) is a finite degree polynomial in non-negative powers of L with all the
roots inside the unit circle and dnU,ij (L ) are finite degree polynomials in non-negative
powers of L with unrestricted roots. It follows that

det D (z ) =

dnU,11 (L )dnU,22 (L ) - dnU,21 (L )dnU,12 (L )

1

U

vd ,11 (z ) vd ,21 (z ) vd ,12 (z ) vd ,22 (z )

ddU (z )

2

.

And, therefore,

æ
U
-i w
log
ò-p çççè det D e
p

p

( )

2

ö÷
÷d w =
ø÷
2

( ) ( )
( ) ( ) dw
ò
-2 ò log d (e ) d w - å ò log v (e ) d w
-p

log dnU,11 e -iw dnU,22 e -iw - dnU,21 e -iw dnU,12 e -iw
p

-p

U
d

-i w

2

2

p

i , j =1,2

-i w

(A.5)

2

d ,ij

-p

The stationarity of the solution and the stationarity of the innovation process together
with

Lemma

åò

i , j =1,2

p

-p

( )

A.1

imply

that

2

ò

p

-p

( )

U
d

log d

(e )

( )

-i w

2

2

dw = 0

( )

and

( )

log vd ,ij e -iw d w = 0 . The term dnU,11 e -iw dnU,22 e -iw - dnU,21 e -iw dnU,12 e -iw

44

on the other hand, might contain roots inside the unit circle, and, more interestingly, such
roots are now a function of the control parameters in U (L ) , unlike the backwards
U
n ,11

looking case. Let d

mU

(z )d (z ) - d (z )d (z ) = d (1 - d z )
U
n ,22

U
n ,21

U
n ,12

U
n

j =1

U
n, j

where dnU is a

positive constant and mU is the degree of the polynomial. Using Lemma A.1 and letting

K (U ) º 4p log dnU + 4p å log dnU,u , j Î {u j } if dnU,u > 1 one obtains (23). Finally,
j

uj

æ
-i w
ò-p log ççèç det S e
p

( )

2

j

2ö
p
p
ö÷
æ
æ
C
-i w
÷÷d w log çç det D B e -i w
÷÷d w = ò log ççç det D e
ò
÷
-p
-p
ø
è
ø
èç
C
B
C
B
= K u - K u º K (u | u ),

( )

( )
( )

( )

2

ö÷
÷d w
ø÷

where the last step defines the constant K (uC | u B ) of Theorem 2.

Bibliography
Bowden, R., (1977), “Spectral Utility Functions and the Design of a Stationary System,”
Econometrica, 45, 2, 1007-1012.
Brock, W. and S. Durlauf, (2004) “Elements of a Theory of Design Limits to Optimal
Policy,” The Manchester School, 72, Supplement 2, 1-18.
Brock, W. and S. Durlauf, (2005), “Local Robustness Analysis: Theory and Application,”
Journal of Economic Dynamics and Control 29, 2067-2092.
Brock. W., S. Durlauf, and G. Rondina, (2008a), “Frequency-Specific Effects of
Stabilization Policies,” American Economic Review: Papers and Proceedings, 98, 2, 241245.
Brock, W., S. Durlauf, and G. Rondina, (2008b), “Design Limits and Dynamic Policy
Analysis,” National Bureau of Economic Research Working Paper no.14357.
Chen, J. and C. Nett, (1993), “Bode Integrals for Multivariable Discrete Time Systems,”
Proceedings of the 32nd IEEE Conference on Decision and Control, IEEE, San Antonio,
TX, 811-816.
Chen, J. and C. Nett, (1995), “Sensitivity Integrals for Multivariate Discrete-Time
Systems,” Automatica, 31, 8, 1113-1124.

45

Clarida, R., J. Gali and M. Gertler, (2000), “Monetary Policy Rules and Macroeconomic
Stability: Evidence and Some Theory,” Quarterly Journal of Economics, 115, 1, 147-180
Freudenberg, J. and D. Looze, , (1988), “Frequency Domain Properties of Scalar and
Multivariable Feedback Systems,” in Lecture Notes in Control and Information Sciences
104, Springer-Verlag Berlin, Heidelberg.
Gali, J., M. Gertler and J. Lopez-Salido, (2005), “Robustness of the Estimates of the
Hybrid New Keynesian Phillips Curve,” Journal of Monetary Economics, 52, 6, 11351107-1118.
Giannoni, M. (2002), “Does Model Uncertainty Justify Caution? Robust Optimal
Monetary Policy in a Forward-Looking Model,” Macroeconomic Dynamics, 6, 1, 111144.
Giannoni, M. and M. Woodford, (2003), “How Forward-Looking is Optimal Monetary
Policy?,” Journal of Money, Credit, and Banking, 35, 6, 1425-1469.
Hansen, L. and T. Sargent, (1980), “Formulating and Estimating Dynamic Linear
Rational Expectations Models,” Journal of Economic Dynamics and Control, 2, 7-46.
Hansen, L., and T. Sargent, (1981), “A Note on Wiener-Kolmogorov Prediction
Formulas for Rational Expectations Models,” Economics Letters, 8, 3, 255-260.
Hansen, L. and T. Sargent, (1983), “The Dimensionality of the Aliasing Problem in
Models with Rational Spectral Densities,” Econometrica, 51, 2, 377-388.
Hansen, L. and T. Sargent, (1991), “Exact Linear Rational Expectations Models:
Specification and Estimation,” in Rational Expectations Econometrics, L. Hansen and T.
Sargent, eds., Westview Press.
Hansen, L. and T. Sargent, (2007), Robustness. Princeton: Princeton University Press.
Iglesias, P., (2001), “Tradeoffs in Time-Varying Linear Systems: An Analogue of Bode’s
Sensitivity Integral,” Automatica, 37, 1541-1550.
Ito, T. and D. Quah, (1989), “Hypothesis Testing with Restricted Spectral Density
Matrices, with an Application to Uncovered Interest Parity,” International Economic
Review, 30, 1, 203-215.
Judd, J. and G. Rudebusch, (1998), “Taylor’s Rule and the Fed: 1970-1997, Federal
Reserve Bank of San Francisco Economic Review, 3, 3-16.
Kasa, K., (2000), “Forecasting the Forecasts of Others in the Frequency Domain,”
Review of Economic Dynamics, 3, 726-756.

46

Kwakernaak, H. and R. Sivan, (1972), Linear Optimal Control Systems, New York: John
Wiley and Sons.
Linde, J., (2005), “Estimating New-Keynesian Phillips curves: A full information
maximum likelihood approach,” Journal of Monetary Economics, 52, 6, 1135-1149.
Magill, M., (1977), “A Local Analysis of Capital Accumulation Under Uncertainty,”
Journal of Economic Theory, 15:211-218.
Meltzer, A., (2003), A History of the Federal Reserve, vol. 1: 1913-1951, Chicago:
University of Chicago Press.
Onatski, A. and J. Stock, (2002), “Robust Monetary Policy Under Model Uncertainty in a
Small Model of the U.S. Economy,” Macroeconomic Dynamics, 6, 85-110.
Onatski, A. and N. Williams, (2003), “Modeling Model Uncertainty,” Journal of the
European Economic Association, 1, 1087-1122.
Otrok, C., (2001), “Spectral Welfare Cost Functions,” International Economic Review,
42, 2, 345-367.
Otrok, C., B. Ravikumar, and C. Whiteman, (2002), “Habit Formation: A Resolution of
the Equity Premium Puzzle, Journal of Monetary Economics, 49, 1261-1288.
Pataracchia, B., (2008), “Design Limits in Regime-Switching Cases,” mimeo, University
of Siena.
Priestley, M., (1981), Spectral Analysis and Time Series, San Diego: Academic Press.
Rondina, G., (2008), “Variance Frequency Decomposition for Optimally Controlled
Multivariate Linear-Quadratic Models,” mimeo, University of California at San Diego.
Rudebusch, G. and L. Swensson, (1999), “Policy Rules for Inflation Targeting.” In
Monetary Policy Rules, J. Taylor, ed., Chicago: University of Chicago Press.
Sargent, T., (1987), Macroeconomic Theory, San Diego: Academic Press.
Sargent, T., (1999), “Comment,” in Monetary Policy Rules, J. Taylor, ed. Chicago:
University of Chicago Press.
Sargent, T., N. Williams and T. Zha, (2006), “Shocks and Government Beliefs: The Rise
and Fall of American Inflation,” American Economic Review, 96, 4, 1193-1224.
Seron, M., J. Braslavsky, and G. Goodwin, (1997), Fundamental Limitations in Filtering
and Control, New York: Springer-Verlag.

47

Sims, C., (2007), “On the Genericity of the Winding Number Criterion for Linear
Rational Expectations Models,” Department of Economics, Princeton University.
Sims, C. and T. Zha, (2006), “Were There Regime Switches in U.S. Monetary Policy?.”
American Economic Review, 96, 1, 54-81.
Skogestad, S. and I. Postlethwaite, (1996), Multivariable Feedback Control: Analysis and
Design, New York: John Wiley.
Taylor, J., (1993), “Discretion Versus Policy Rules in Practice,” Carnegie-Rochester
Conference Series on Public Policy, 39, 195-214.
Taylor, J., (1999), “A Historical Analysis of Monetary Policy Rules,” in Monetary Policy
Rules, J. Taylor, ed., Chicago: University of Chicago Press.
Taylor, J. and J. Williams, (2010), “Simple and Robust Rules for Monetary Policy,” in
Handbook of Monetary Economics, v. 3, B. Friedman and J. Taylor, eds., Amsterdam:
North Holland.
Whiteman, C. (1983), Linear Rational Expectations Models, Minneapolis: University of
Minnesota Press.
Whiteman, C., (1985), “Spectral Utility, Wiener-Hopf Techniques, and Rational
Expectations,” Journal of Economic Dynamics and Control, 9, 225-240.
Whiteman, C., (1986), “Analytical Policy Design Under Rational Expectations,”
Econometrica, 54, 6, 1387-1405.
Woodford, M., (2003), Interest and Prices, Princeton: Princeton University Press.
Wu, B.-F. and E. Jonckheere, (1992), “A Simplified Approach to Bode’s Theorem for
Continuous and Discrete Time Systems,” IEEE Transactions on Automatic Control, 37,
100, 1797-1802.
Zhou, K., J. Doyle, and K. Glover, (1996), Robust and Optimal Control, New Jersey:
Prentice Hall.

48

