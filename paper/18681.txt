NBER WORKING PAPER SERIES

REVISITING THE MINIMUM WAGE-EMPLOYMENT DEBATE:
THROWING OUT THE BABY WITH THE BATHWATER?
David Neumark
J.M. Ian Salas
William Wascher
Working Paper 18681
http://www.nber.org/papers/w18681
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2013

We are grateful to Marianne Bitler, Charles Brown, Lawrence Kahn, Jeffrey Thompson, Rob Valletta,
seminar participants at UCSD, and anonymous referees for helpful comments, and to Arin Dube and
his co-authors for sharing their data and computer code. Neumark and Salas’ work on this project
received support from the Employment Policies Institute (EPI). The views expressed in this paper
do not necessarily reflect the views of EPI or of the Board of Governors of the Federal Reserve System,
and the authors have retained full editorial control of the paper’s content and conclusions. All data
and programs used in this research will be available from the authors upon request when the research
is completed. This paper was prepared for presentation at the conference “Celebrating the Centennial
of the U.S. Department of Labor,” November 9, 2012, Washington, DC. The views expressed herein
are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2013 by David Neumark, J.M. Ian Salas, and William Wascher. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

Revisiting the Minimum Wage-Employment Debate: Throwing Out the Baby with the Bathwater?
David Neumark, J.M. Ian Salas, and William Wascher
NBER Working Paper No. 18681
January 2013, Revised May 2013
JEL No. J23,J38
ABSTRACT
We revisit the minimum wage-employment debate, which is as old as the Department of Labor. In
particular, we assess new studies claiming that the standard panel data approach used in much of the
“new minimum wage research” is flawed because it fails to account for spatial heterogeneity. These
new studies use research designs intended to control for this heterogeneity and conclude that minimum
wages in the United States have not reduced employment. We explore the ability of these research
designs to isolate reliable identifying information and test the untested assumptions in this new research
about the construction of better control groups. Our evidence points to serious problems with these
research designs. Moreover, new evidence based on methods that let the data identify the appropriate
control groups leads to stronger evidence of disemployment effects, with teen employment elasticities
near -0.3. We conclude that the evidence still shows that minimum wages pose a tradeoff of higher
wages for some against job losses for others, and that policymakers need to bear this tradeoff in mind
when making decisions about increasing the minimum wage.
David Neumark
Department of Economics
University of California at Irvine
3151 Social Science Plaza
Irvine, CA 92697
and NBER
dneumark@uci.edu
J.M. Ian Salas
Department of Economics
University of California, Irvine
3151 Social Science Plaza
Irvine, CA 92697
jmisalas@uci.edu

William Wascher
Federal Reserve Board
Stop 66
Washington, DC 20551
william.l.wascher@frb.gov

I. Introduction
Debates about the economic effects and the merits of the minimum wage date back at least as far
as the establishment of the Department of Labor as a cabinet-level agency in 1913. Given the absence of
empirical evidence on the effects of minimum wages in the early 1900s, the initial debates were largely
based on theoretical reasoning. The neoclassical school (including John Bates Clark, H. B. Lees-Smith,
and Frank Taussig) argued that wage levels were determined by workers’ productivity and that minimum
wages would reduce employment among low-skilled workers. In contrast, the progressives (such as
Sidney Webb, Rogers Seager, and John Commons) argued that minimum wages were necessary to
prevent the widespread exploitation of lower-skilled workers by employers with greater bargaining power
over wages, would encourage workers to increase their efforts, and would boost consumers’ purchasing
power and thus raise aggregate demand.
A similar debate erupted after the federal minimum wage was enacted in 1938. The main
protagonists at that time were George Stigler (1946) and Fritz Machlup (1946), representing the
“marginalist” school of economists, and Richard Lester (1946), who was considered an “institutionalist”
economist. Again, the debate was primarily about the appropriate theoretical model of the labor market,
although both sides also attempted to bolster their arguments with empirical analyses. Stigler and
Machlup took the neoclassical position that minimum wages reduce employment, while Lester argued
that product demand rather than wage rates was by far the most important factor determining employment
so that fairness was the more appropriate consideration in setting a wage floor.1
Economists and statisticians from the Department of Labor have contributed importantly to the
empirical literature on the economic effects of minimum wages over the past century. One of the first
statistical analyses of minimum wages in a U.S. state was conducted in 1915 by Marie Obenauer and
Bertha von der Nienburg of the Bureau of Labor Statistics (BLS), who examined the effects of a
minimum wage for women that was introduced in Oregon between October 1913 and February 1914. For
1

Stigler acknowledged the possibility that minimum wages could raise employment in a labor market with a
monopsonistic employer, an idea that would become more prominent in the 1990s. However, his own view was that
low-wage markets were generally competitive in nature and thus that such monopsony effects were unlikely to be
important in U.S. labor markets.

1

this study, which was a precursor to the case study approach that constitutes a key branch of the empirical
literature that blossomed after 1990, the BLS collected data on employment and wages by age and sex, as
well as sales, from 40 retail stores in Oregon for March and April of 1913, about five months prior to the
introduction of the minimum wage in the state, and for March and April of 1914, about five months after
the minimum wage took effect. The study then compared the changes in the employment of women and
men over that period. Although quite cautious about the power of their difference-in-differences
statistical approach (for example, the analysis was complicated by a recession in 1914 and by a legislated
reduction in working hours for women), the study concluded that the minimum wage had a positive effect
on wages and little or no effect on women’s employment in the aggregate, but that stores substituted
teenage girls (who were subject to a lower minimum wage) for adult women in lesser-skilled jobs.
Similarly, some of the first empirical analyses of the federal minimum wage law enacted in 1938
were undertaken by analysts from the Wage and Hours and Public Contracts Division of the Department
of Labor. In particular, the Department conducted a series of studies examining the effects of the new
minimum wage on wages and employment in certain industries, either by comparing changes in wages
and employment in plants in low-wage southern states with their counterparts in higher-wage northeastern
states or by comparing employment changes in plants with different levels of average wages before the
federal minimum wage took effect. These studies, which tended to find modest disemployment effects,
were followed by similar efforts by the Department to assess the effects of increases in the federal
minimum wage in the 1940s and 1950s. The findings of these studies were at the center of a vigorous
debate between Richard Lester and John Peterson on the merits of the minimum wage in the late 1950s
and early 1960s (Lester, 1960; Peterson, 1957, 1959, 1960).
Over time, empirical analyses, especially the time-series studies conducted in the 1960s and
1970s, increasingly found that minimum wages tended to reduce employment among teenagers, who were
viewed as a proxy for low-skilled labor more generally. A famous paper by Charles Brown, Curtis
Gilroy, and Andrew Kohen, published in 1982, surveyed the existing literature on minimum wages and
established the “consensus” that a 10 percent increase in the minimum wage would reduce teenage

2

employment by 1 to 3 percent (Brown et al., 1982). Following that study, economists began to coalesce
around the idea that minimum wages have adverse effects on low-skilled employment.
That consensus turned out to be relatively short-lived. After a decade of near-silence, the debate
over the employment effects of the minimum wage reemerged in the early 1990s with the publication of a
special issue of the Industrial and Labor Relations Review (ILRR). This issue featured four studies that
used different analytical approaches and that took advantage of the increasing divergence of minimum
wages at the state level to estimate the employment effects of minimum wages. These studies, which
formed the basis for what is sometimes termed the “new minimum wage research,” were diverse in their
findings, ranging from disemployment effects similar to the earlier consensus (Neumark and Wascher
1992), to no effect on employment (Card 1992a) to a positive effect of the minimum wage on
employment (Card 1992b; Katz and Krueger 1992).
The ILRR symposium launched a new body of contemporary research on the minimum wage,
much of which was summarized in our 2008 book Minimum Wages (Neumark and Wascher, 2008). In
that book, our evaluation and summary of the evidence concluded that “… [M]inimum wages reduce
employment opportunities for less-skilled workers, especially those who are most directly affected by the
minimum wage” (Neumark and Wascher, 2008, p. 6). This paper, in part, extends this evaluation and
summary to the present by evaluating two recent studies that have questioned the empirical methods and
conclusions in much of the recent literature (Allegretto et al., 2011; Dube et al., 2010).
The key question raised by these recent studies is how researchers can best identify the
employment effects of the minimum wage – a question that is nearly as long-running as the debate over
the minimum wage. In particular, the identification of minimum wage effects requires both a sufficiently
sharp focus on potentially affected workers and the construction of a valid counterfactual “control group”
for what would have happened absent increases in the minimum wage. The latter is critical to account for
other influences on the employment of potentially affected workers that may be confounded with the
effects of changes in the minimum wage. In the research of the past two decades, economists have
frequently used state variation in minimum wages to generate comparisons between states with different

3

minimum wage levels or changes at the same point in time, to avoid confounding minimum wage effects
with other aggregate influences on the labor market (e.g., the national business cycle).
Dube et al. (2010, hereafter DLR) and Allegretto et al. (2011, hereafter ADR) have put forward a
severe critique of the state panel-data approach, including the work discussed at length in Neumark and
Wascher (2008). The essence of the argument in DLR and ADR is summarized in a review of Minimum
Wages by Dube (2011), which draws heavily on the findings from the two papers he co-authored:
“…[V]ariation over the past two decades in minimum wages has been highly selective spatially,
and employment trends for low-wage workers vary substantially across states … This has tended
to produce a spurious negative relationship between the minimum wage and employment for low
wage workers – be it for sectors such as restaurant and retail or for demographic groups such as
teenagers” (Dube, 2011, p. 763).
Commenting on the econometric evidence more specifically, Dube writes: “Even simple regional
controls and trends produce employment effects close to zero, as do more sophisticated approaches such
as comparing contiguous counties across policy boundaries – which essentially embeds the “case study”
approach within panel data analysis …” (pp. 763-4). Dube defines his and his co-authors’ studies as “a
fourth generation of recent work that tries to make sense of the sometimes contradictory evidence” (p.
763), and argues that their work raises serious questions about the conclusions drawn by Neumark and
Wascher – and much of the broader literature – regarding the employment effects of minimum wages.
Echoing Dube, ADR assert without reservation that their results overturn the conclusion that
minimum wages reduce employment of low-skilled workers: “Interpretations of the quality and nature of
the evidence in the existing minimum wage literature … must be revised substantially. Put simply, our
findings indicate that minimum wage increases – in the range that have been implemented in the United
States – do not reduce employment among teens” (ADR, 2011, p. 238). Similarly, DLR conclude that
there are “no detectable employment losses from the kind of minimum wage increases we have seen in
the United States” (DLR, 2010, p. 962).
Our principal goal in this paper is to evaluate this new research because of the strong challenge it
poses to the large body of prior research that found that minimum wages reduce employment of lowskilled workers. As the description of the work above suggests, the central element of this new research
is the issue of how to construct counterfactuals for the places where minimum wages are increased. The
4

authors of both studies argue that one must compare places that are geographically proximate to have
valid controls, because, according to them, minimum wage changes are correlated with unobserved
economic shocks to areas that can confound the estimation of minimum wage effects. Consequently,
much of the analysis in this paper focuses on the validity of this criticism, and on the approaches these
studies take to address this potential problem. The overriding concern we have with these studies is that
their research designs, out of concerns about avoiding minimum wage variation that is potentially
confounded with other sources of employment change, discard a great deal of valid identifying
information – throwing out the identifying “baby” along with, or worse yet instead of, the contaminated
“bathwater.” Our findings, in a nutshell, indicate that neither the conclusions of these studies nor the
methods they use are supported by the data.
II. Recent Research Challenging the Conclusion that Minimum Wages Reduce the Employment of LowSkilled Workers
Of the two papers by Dube and his colleagues, the analysis in ADR is the most direct extension of
the state panel-data approach used extensively in the existing research on the employment effects of
minimum wages. In this study, ADR focus on standard specifications of minimum wage effects on the
employment of teenagers, using information on state-level minimum wages and individual-level data
from the Current Population Survey (CPS) from 1990-2009. When they estimate a model that includes
state and period fixed effects along with other standard controls, they find a negative employment effect
of minimum wages. However, when they include either state-specific linear trends or Census division ×
period interactions (or both), the estimated employment effects of minimum wages fall to approximately
zero and are statistically insignificant.
In contrast, DLR’s analysis focuses primarily on restaurant employment using county-level
Quarterly Census of Employment and Wages (QCEW) data from 1990-2006. Although they present
some results from panel data models that include state-specific trends and Census division × period
interactions (along with county fixed effects), their core analysis uses a research design based on crossborder county pairs. Their specification includes county pair × period interactions intended to control for
shocks common to both counties, and thus identifies the effect of minimum wages from differences in
5

employment changes in paired counties on either side of a state border. This narrowing of identification
to within-county-pair comparisons causes the employment effects to go from negative and sometimes
statistically significant to small and insignificant.
Closely related findings are reported in Addison et al. (2012). They also use QCEW data,
focusing on nearly the same period (1990-2005) and on nearly the same sector. With regard to DLR’s
first set of analyses, about the only difference is that the authors include county-specific linear trends.
However, the qualitative conclusion is the same: they find negative employment effects when they
include only county and quarter fixed effects, but no evidence of employment effects when they include
county-specific trends. Similarly, in a 2009 paper these same co-authors estimate these models for
various parts of the retail sector with county-specific time trends, and also do the same border-county
analysis as in DLR, with similar findings.2
To put this new evidence in context, it is useful first to assess the implications of these results for
the existing state-level panel studies, especially since ADR and DLR have explicitly used their findings to
cast doubt on the evidence from these studies. With regard to DLR’s paper, it is worth noting that very
little of the existing work is on the restaurant sector or the retail sector more broadly, so new evidence on
restaurant or retail employment does not address the far more pervasive evidence on teens or other very
low-skilled workers. For one thing, the evidence from the earlier research is strongest for individuals
most directly affected by the minimum wage, and many workers within the restaurant or retail sector earn

2

Addison et al. (2011) use similar methods to try to estimate the effects of minimum wages in the United States
during the Great Recession, and conclude that there is not evidence of disemployment effects. However, perhaps
because of the short time period studied and the large movements in aggregate labor market outcomes during that
period, the standard errors on the point estimates are so large as to be uninformative. For example, in some cases
(e.g., teens) the authors find negative employment effects that are in the earlier “consensus” range but that are not
statistically significant. We have similar concerns about the results reported in Hirsch et al. (2011), who study the
effects of the recent federal minimum wage increases on employment at “quick-service” restaurants in Georgia and
Alabama. They report estimated employment elasticities, with respect to the wage cost increases induced by the
higher minimum wage, that are sometimes positive and sometimes negative, but that also have large standard errors
(about 0.4-0.5). They also estimate the effects of the cumulative increase – which are not reported in the paper but
were supplied in a personal communication from Barry Hirsch – and find negative and sometimes large effects
(ranging from −0.12 to −0.92) that are statistically insignificant (with standard errors of 1.2), suggesting that the
main problem may be uninformative data.

6

well more than the minimum wage. For another, the minimum wage can lead employers to substitute
higher-skilled workers for lower-skilled workers without reducing net employment very much.3
ADR’s research focuses primarily on teenagers and can therefore be viewed as posing more of a
direct challenge to the findings from the state-level panel data approach. Even in this case, however, the
potential for labor-labor substitution among teenagers with different skill levels means that the effects of
minimum wages on overall teenage employment can be difficult to detect; for example, larger gross
disemployment effects among the least-skilled teens may be masked by inflows of other teens into
employment.4 Indeed, the most recent estimates Neumark and Wascher have presented for teenagers
show negative effects only for male teens when disaggregating by sex, and only for black or Hispanic
male teens when disaggregating male teens into whites vs. black or Hispanic (Neumark and Wascher,
2011). And other work, focused on the lowest-wage workers rather than on teenagers per se, finds
negative employment effects for them as well (Neumark et al., 2004). Nonetheless, a negative effect of
minimum wages on employment of the lowest skilled ought to imply negative effects for at least some
groups of teenagers, and for the sample period they study, ADR do find that a panel data model with only
state and year fixed effects produces evidence of disemployment effects in the range of past estimates.
Thus, their finding that this conclusion is sensitive to whether state-specific linear trends or region ×
period interactions are included in the specification poses a challenge to the conventional view of

3

DLR acknowledge this possibility, noting that “… [O]ur data do not permit us to test whether restaurants respond
to minimum wage increases by hiring more skilled workers and fewer less skilled ones” (p. 962). However, the
existing literature suggests that such labor-labor substitution is important. For example, Fairris and Bujanda (2008)
find evidence of labor-labor substitution by city contractors in response to the Los Angeles living wage ordinance –
a different kind of mandated wage floor. In addition, in a study of personnel records from over 600 establishments
of a single large retail firm, Giuliano (forthcoming) finds that large minimum wage-induced increases in the wage
rates of teenagers relative to adults were associated with increases in employment for teenagers from higher
socioeconomic status zip codes and decreases in the employment of young adults (ages 20-22). Moreover, data on
the individual workers who were laid off and on store performance indicated that at some stores the teens that were
hired were of higher quality than teens already employed at the stores, and of higher quality than the young adults at
the stores. Similar evidence consistent with this substitution from low-skilled adults to possibly higher-skilled
teenage students (in food-service occupations) is reported in Lang and Kahn (1998). Finally, Neumark and Wascher
(1996) find evidence of this substitution among teens, with a higher minimum wage drawing those enrolled in
school and working part-time into full-time work, while pushing those working full-time and not enrolled in school
out of jobs into “idleness” (neither working nor employed).
4
The focus on teenagers is, to some extent, a vestige of the old time-series literature. Because labor economists had
to aggregate employment data by age group, it made sense to look mainly at teenagers because minimum wage
workers comprised such a small share of older age groups.

7

minimum wage employment effects. We next turn to a more thorough explanation of their analysis, as
well as an evaluation of it; we then do the same for the DLR study.
III. Evaluation of the Evidence
Allegretto et al. (2011)
As noted above, ADR find that the negative effects estimated from standard state-level panel data
specifications of the effects of minimum wages on the employment of teenagers are sensitive to including
either state-specific linear trends or Census division × period interactions (or both). This leads them to
conclude that models with only state and year fixed effects “fail to account for heterogeneous
employment patterns that are correlated with selectivity among states with minimum wages. As a result,
the estimates are often biased and not robust to the sources of the identifying information” (p. 205). More
specifically, they argue that “Lack of controls for spatial heterogeneity in employment trends generates
biases toward negative employment elasticities in national minimum wage studies” (p. 206).
We re-examine these findings with the same CPS data, using a specification with the same
aggregate variables they include. The sample is extended to take account of newer data (which does not
change the basic conclusions), and, whereas ADR use individual-level data with clustering at the state
level, we aggregate the data to the state level by quarter, also clustering at the state level.5 The minimum
wage, here and throughout, is defined as the higher of the state and federal minimum.
As can be seen in Table 1, the results closely mirror what ADR found (their Table 3). In the
model that includes the standard labor market controls along with state and time fixed effects,6 the
estimated employment elasticity with respect to the minimum wage is −0.165, significant at the 1% level
(ADR estimate an elasticity of −0.12, significant at the 5% level).7 When either state-specific linear
trends are added, region × quarter interactions are added, or both are added simultaneously, the estimated

5

Aggregated data are used because this form is more convenient for some of the analyses that follow, particularly
those that focus on the time-series patterns in the data by state. Moreover, because the identifying information is the
state-level minimum wage variation, the use of state-level data for the other variables should be inconsequential.
6
Because ADR use micro-data rather than state-level data, they also include controls for individual demographic
characteristics.
7
The specification is in logs so the estimated coefficient is the elasticity; in contrast, ADR estimate linear
probability models for employment with the log of the minimum wage on the right-hand side. They report the
magnitude and statistical significance of the estimated linear probability coefficients, and then the implied elasticity.

8

elasticities become considerably smaller (ranging from −0.098 to 0.009) and are statistically insignificant.
The same is true in the ADR results (their Table 3), where the estimates are statistically insignificant and
the estimated elasticities range from −0.036 to 0.047.8
This evidence suggests that conclusions about the effects of minimum wages on teenagers may
not always be robust to the type of identifying variation used to estimate these effects: differences in
within-state variation associated with minimum wage changes relative to other states in the same year;
differences in within-state variation relative to other states in the same year that is also net of statespecific linear trends; or (essentially) differences in within-state variation relative to states in the same
Census division.
Interestingly, the only time ADR question the validity of their approach is with regard to their
evidence of statistically significant negative effects on hours of Hispanic teens. In response to these
findings, they write “the puzzling and somewhat fragile evidence for Hispanic teens may be driven by the
concentration of Hispanic teens in a small number of Census divisions, on the one hand, and the small
number of Hispanic teens in most states at the beginning of the sample period. These patterns reduce the
ability to estimate effects for this group robustly within our methodology” (2011, p. 234). Similarly, they
argue that “[I]ncluding spatial controls renders the estimates for Latinos particularly imprecise and
fragile” (p. 208). But in their Table 7, on which this discussion is based, the estimates are actually more
precise for Hispanics than for blacks, yet they conclude that “controlling for spatial heterogeneity by
using within-Census division variation is particularly important when looking at African-American
employment effects” (p. 234).
Rather than judgmentally deciding where and when to include area-specific time trends or region
× period dummies based on unclear criteria like these, researchers should examine what sources of
variation provide better estimates of the effects of minimum wages. In the context of this paper, this

8

We also experimented with a specification that added controls for the adult wage and adult employment-topopulation ratio, and defining these variables (and the adult unemployment rate) for skilled adults aged 25-64 with
more than a high school education. The estimated minimum wage effects were very similar to those reported in
Table 1.

9

preferred approach entails exploring the implications of including state-specific trends or region × time
interactions and whether doing so results in more or less reliable estimates of minimum wage effects.
State-Specific Trends. We first focus on the evidence regarding state-specific trends, which are
intended to control for longer-run influences not captured in the other control variables. It has become
standard practice to assess the robustness of panel data estimates of state policy effects to the inclusion of
state-specific trends, including in the minimum wage literature (e.g., Neumark and Wascher, 2004 and
2011). If these kinds of analyses deliver robust results that are insensitive to the inclusion of these trends,
then they can clearly bolster the evidence. If, however, they point to different evidence, then the
researcher has to seriously explore which analysis is most convincing, rather than simply relying on a
priori hunches.
The first thing to note is that Neumark and Wascher (2011), using data from 1994-2007, found
that the estimated effects of minimum wages on teen employment are negative and significant in
specifications that include state-specific trends.9 This result raises the question as to whether there is
something different about the sample period ADR studied that makes it problematic to include linear
state-specific trends. An obvious candidate is the severe recession at the end of their sample period, as is
the recession at the beginning of their sample period (in 1990 and 1991). In models that include statespecific trends, the recessions at the beginning and end of ADR’s sample period could have a large
influence on the estimated state-specific trends – so-called “endpoint bias.” If the recessions have purely
an aggregate influence that is common across all states, this will not happen, as the year effects will
absorb this common influence. But if the recessions led to cross-state deviations between teen
employment rates and aggregate labor market conditions, then the estimated longer-term trends in teen
employment could be biased. This, in turn, could lead to misclassification of periods in which teen
employment was high or low relative to the predicted values net of the minimum wage, and hence
influence the estimated minimum wage effects for reasons having nothing to do with the longer-run
trends for which the specification is trying to control.
9

Although not reported in a table, we verified that with the data used here, this result still holds. Estimating the
model from Table 1 with data from 1994-2007:Q2, the minimum wage effect (standard error) is –0.148 (0.060)
without state linear trends, and –0.229 (0.095) with them.

10

To illustrate the potential problem, Figure 1 displays some results for California. The model is
first estimated including the state-specific trends, for the period excluding the recessions (1994-2007:Q2).
The upper-left panel shows the actual residuals for this period, and then the prediction errors for the two
recessionary periods. There are sizable deviations of teen employment from the model’s predicted values
during these two recessionary periods, which could have a strong influence on the estimated state-specific
trends in samples that included those periods. In particular, teen employment was considerably higher
than would have been predicted by the regression model in the early-1990s recession, whereas the
opposite was true during the Great Recession (presumably reflecting the different industries affected by
the two recessions).
The consequences of including the recessionary periods are illustrated in the remaining three
panels of the figure, which show the residuals from the fitted regression model when the estimation
period is extended to include one or both recessionary periods. In these panels, the deviations of the
actual values of teen employment from the fitted values (i.e., the residuals) are much smaller for the
recessionary periods than in the upper-left panel, and these residuals are more centered on zero.
Correspondingly, the estimates of the state-specific trends over the non-recessionary period are strongly
influenced by the inclusion of the recessionary periods. For example, in the upper-right and two lower
panels the regressions of the residuals on a time trend for the 1994-2007:Q2 subperiod have slopes that
are quite different from zero, indicating that the residuals from the recessionary periods are influencing
the estimated trends.10 Thus, including the strong recessionary periods of the early 1990s and the Great
Recession in the estimation could bias the state-specific trend estimates away from the values associated
with longer-term factors not captured by the other controls and thus potentially confound the estimates of
the employment effects of minimum wages.
One approach to this problem is to allow the state-specific trends to be of a higher order than
linear. Higher-order trends should be better than linear trends at capturing the variation induced by the
recessions – especially third-order and higher polynomials that allow for multiple inflection points.
10

In the upper-left panel, where the model is estimated for 1994-2007:Q2, a regression of the residuals for this
period on a time trend will, by construction, yield a zero coefficient, because the model includes a separate time
trend for each state, and OLS residuals are orthogonal to the regressors.

11

Estimates for the full sample period that include these higher-order trends are reported in columns (1)-(4)
of Table 2. (The comparable estimates with no state-specific trends and with linear trends are in columns
(1) and (2) of Table 1.) The table shows that as long as third-order polynomials or higher are used, the
estimated effects of the minimum wage on teen employment are negative and significant, with point
estimates very similar to the estimates for the standard model that excludes state-specific trends – and
similar to the estimates for the subsample excluding the beginning and ending recessionary periods.11 In
each column, we tested the statistical significance of the higher-order terms added relative to the previous
column (in column (1) we tested the significance of the squared time interactions). These were
significant for the 2nd-, 3rd-, 4th- and 5th-order terms (p-values < 0.001). Thus, linear state-specific trends
are too restrictive.
An alternative approach is to estimate the state-specific linear trends using only the data from the
subsample that excludes the recessionary periods and then include those trend estimates in a regression
over the full sample period. To implement this approach, note that the standard regression model with
state-specific linear trends is:
(1)

Yit = α + πMWit + Xitβ + Siγ + Ttδ + Si·t·θ + εit .

We can simply estimate this model with OLS. If we knew θ, however, we could instead form the
dependent variable Yit − Si·t·θ, and estimate the model
(2)

Yit − Si·t·θ = α + πMWit + Xitβ + Siγ + Ttδ + εit .

This specification will give us the same estimates, although the standard errors would be understated
because the sampling variation in estimating θ would be ignored.
Following this intuition, we can define a subperiod of the sample, t1 to t2, and estimate equation
(1) for this subsample. The estimated state-specific trends for this subsample can be retained, denoted by
the vector ߠ෠ଵଶ . The dependent variable for the full sample period can then be detrended using ߠ෠ଵଶ , and
equation (2) estimated over the full sample for the detrended data. This lets us remove the state-specific
11

The results are very similar using the slightly shorter sample period that ADR use. The point estimates are also
similar, although a bit less precise, with 6th- or 7th-order polynomials; for these specifications, the estimated
minimum wage elasticity ranges from −0.14 to −0.17, and is significant at the ten-percent level in three out of four
cases (including both specifications using ADR’s sample).

12

linear trends estimated for the subperiods excluding the steep recessions, rather than the whole sample
period, while still using the whole sample to estimate minimum wage effects. The only complication is
that the standard errors have to be corrected to account for the sampling variation in ߠ෠ଵଶ . This is done by
using block-bootstrapping by state, to account for the non-independence of observations within states.
As reported in column (5) of Table 2, when the panel data model with state-specific trends is
estimated in this way the estimated effects of minimum wages are much more strongly negative and are
statistically significant: The estimated minimum wage effect is –0.178, compared with –0.165 in Table 1
without the state-specific linear trends and –0.074 (and insignificant) with them. Thus, removing the
state-specific trends in a way that excludes the recessions at the beginning and end of the sample leads to
stronger evidence of disemployment effects.12
A third approach is to estimate the model over the full sample period after pre-filtering the data to
remove state-specific trends. This pre-filtering is done in two ways: (1) calculating the trend in each
variable as a linear spline between consecutive business cycle peaks as defined by the NBER (and
extrapolating the trends over the relevant range of the sample before the first business cycle peak and
after the last business cycle peak);13 and (2) passing each data series (by state) through a Hodrick-Prescott
filter using the standard smoothing parameter for quarterly data and extracting the non-trend component
of the series.14 Estimates of the model using the data detrended in each of these ways are shown in

12

We also estimated a slightly more complicated version of this specification by allowing the state-specific trends to
differ before and after 2000:Q4 (near the peak of the economy before the 2001 recession). In this specification, the
trend lines are restricted to be joined in that quarter so that the trend can shift, but not the state effects. The
estimates from this augmented specification were very similar to those in column (5) of Table 2.
13
The rationale for this is perhaps best illustrated by the problem demonstrated in Figure 1, namely that recessions
can produce quite different patterns in the teen employment variable. Doing this calculation from peak-to-peak is a
simple way to avoid this problem.
14
The Hodrick-Prescott (or HP) filter is a common technique used in the empirical macroeconomics literature to
remove stochastic trends from aggregate time-series data prior to estimation by statistical procedures that assume
stationarity (see, for example, Hodrick and Prescott, 1997). It is effectively a two-sided symmetric moving average
filter that extracts the trend by smoothing the time series, with the degree of smoothing specified in advance by the
researcher. The smoothing parameter (λ) penalizes variations in the growth rate of the trend component and can
range from zero (in which case there is no smoothing) to ∞ (in which case the smoothed trend is linear). For
quarterly data, λ is typically set to 1600, based on research by Ravn and Uhlig (2002) on how the optimal smoothing
parameter changes for data of varying frequencies. Cogley and Nason (1995) find that the HP filter performs well
for time-series that are stationary or trend stationary, but can generate spurious business cycle periodicity for time
series that are difference stationary. Accordingly, each series in the regression was tested at the state level for the
presence of a unit root using the standard Dickey-Fuller test, and in most cases we were able to characterize the time
series as stationary or trend stationary.

13

columns (6) and (7) of Table 2. Similar to the results in column (5), the coefficients on the minimum
wage variable are more strongly negative than when linear trends are included in the model estimated
over the full sample period (as in the second column of Table 1).
Thus, among the analyses we have carried out, the only way to generate the results in ADR
(2011) – that inclusion of state-specific time trends eliminates the negative effects of minimum wages – is
to include in the sample period the recessionary period of the early 1990s or the recent Great Recession,
and to let these periods have a strong influence on the estimated trends by use of a highly restrictive
specification for those trends. Moreover, the evidence suggests that the linear state-specific trends used
by ADR for these sample periods are influenced by the recessions in ways that apparently contaminate
their estimates of minimum wage effects on teen employment.15 More generally, our evidence shows that
the estimated effects of minimum wages on teen employment are negative and significant with or without
the inclusion of controls for long-term trends in teen employment when those long-term trends are
estimated in ways that are not highly sensitive to the business cycle. This evidence invalidates ADR’s
(2011) conclusion that “Lack of controls for spatial heterogeneity in employment trends generates biases
toward negative employment elasticities in national minimum wage studies” (p. 206).16
To support their inclusion of linear trends, ADR point to various longer-term influences on teen
employment that are not included in the standard specification. Specifically, they cite research by Smith
(2010) suggesting that technological change may have led to an increased supply of adult workers for
low-skill jobs that had been commonly held by youth (their footnote 2). And they cite research by
Aaronson et al. (2007) and the CBO (2004) suggesting that teen employment may have been influenced
15

Addison et al. (2009) also discuss this issue. They note that Sabia (2008) estimates models for retail employment
(using CPS data from 1979-2004) and finds negative employment effects without state trends, but not when trends
are included (in which case the estimates become positive). They write that Sabia argues against including these
trends, quoting him as saying that the trends may reduce “potentially important identifying information” (p. 88, cited
in footnote 18). However, they go on to argue that because the standard errors fall when the trends are included, this
is not a concern. This argument is sophistic. If the state-specific trends are mis-estimated because of the
recessionary periods, they may still lead to more precise estimates – even though their inclusion may not yield
reliable estimates of minimum wage effects.
16
We also considered whether using more flexible functions of the regression controls would reduce the sensitivity
of the state-specific trends to the recessionary periods. We added second- and third-order terms of the controls and
cross-products of the controls. The addition of these variables did not qualitatively alter the estimates reported in
Table 1. The estimates without the state-specific linear trends were similar to those in Table 1, as were the (smaller,
in absolute value) estimates with the trends added.

14

by changes in financial aid for college students, the attractiveness of college, or technological shifts that
have lowered market wages for teens. However, given the problems we have identified with simply
assuming that these kinds of factors can be captured in linear state-specific trends, it would clearly be
preferable to incorporate data on the potentially omitted factors rather than simply including trends and
interpreting the results as reflecting these factors.
Division × Period Interactions. The preceding analysis suggests that ADR’s claim that
underlying trends that vary by state generate spurious evidence of negative minimum wage effects on teen
employment is clearly not true. However, Table 1 also shows that the inclusion of Census division ×
period interactions renders the estimated minimum wage effects smaller and statistically insignificant. As
a prelude to delving into what to make of this result, we start by considering the arguments that ADR use
to support their view that including these interactions is necessary to account for the spatial heterogeneity
that they think biases estimates of minimum wage effects in the standard panel data approach. In this
regard, they appeal to Figure 1 and Table 1 (from their paper) to argue that “employment rates for teens
vary by Census division and differentially so over time” (p. 206).
One particular hypothesis they suggest is that the endogeneity of minimum wages increases
generates a bias towards finding negative employment effects. As evidence, they cite Reich (2009), who
ADR claim shows that minimum wages “are often enacted when the economy is expanding and
unemployment is low. But, by the time of implementation, the economy may be contracting and
unemployment increasing, possibly leading to a spurious time series correlation between minimum wages
and employment” (p. 212, italics added). In fact, Reich actually argues the opposite, based on his
evidence: “Minimum-wage increases are voted almost without exception and are mostly implemented in
times of growing employment. This pattern holds for both federal and state increases” (p. 366, italics
added). Thus, if anything, Reich’s evidence points to possible spurious positive correlations that would
bias estimated minimum wage effects toward zero. Even putting aside this point, ADR’s argument does
not speak to biases in the estimated effect of minimum wages on teen employment in the kinds of models
estimated in the literature (which they critique), because these models already control for aggregate statelevel labor market conditions via the unemployment rate, and includes time dummies that will capture
15

aggregate changes not picked up in the state-level controls. Instead, what is relevant is whether shocks to
teen employment conditional on aggregate labor market changes affect minimum wages. With regard to
this point, the evidence points to positive endogeneity bias. A recent study by Baskaya and Rubinstein
(2011) that looks specifically at the endogeneity problem using an instrumental variables approach – and
which conditions on the adult male unemployment rate – supports the hypothesis that state minimum
wage increases respond positively to increases in teen employment, so that failure to account for
endogeneity biases the estimated employment effect towards zero, masking the negative effect of
minimum wages.17
That said, there could be other omitted factors that drive patterns of teen employment
differentially by Census division, and these could be correlated with minimum wage changes in any
direction. And the sensitivity of the estimates to the inclusion of the division × period interactions is
something that is important to understand further – in particular whether the disappearance of minimum
wage effects when these interactions are included is evidence of the need to control for spatial
heterogeneity, as ADR argue.
An important concern with their approach, though, relates to the implications of augmenting the
specification to include more than 1,900 Census division × period interactions (there are 20 years of
monthly data for 9 divisions). When the Census division × period interactions are included, all of the
identifying information about minimum wage effects comes from within-division variation in minimum
wages. An obvious concern is that this extensive set of controls captures a lot more than just the
unobserved regional variation, and in particular may remove a good deal of valid identifying information
on the effects of minimum wages; moreover, the identifying information that remains is not obviously
better than the identifying information that has been removed. This is an issue that is never explored by
ADR.

17

Earlier work by Watson (1996) looking at state minimum wages reaches the same conclusion: “[T]een
employment rates positively affect legislator’s decisions on reforming minimum wage legislation” (p. 29).
However, Watson only conditions on the adult wage and year fixed effects, not an adult employment or
unemployment rate in the state, so it is possible that her results reflect responses to overall state economic
conditions, rather than the teen labor market per se. Regardless, the results contradict ADR’s claims (but not
Reich’s actual conclusion).

16

Figure 2 provides a picture of the identifying information that is available across and within
Census divisions. The top panel plots the average quarterly minimum wage by division from 1990-2011,
and the nine lower graphs plot the minimum wage by state, within division; all values are shown relative
to the federal minimum. The graph shows that within some Census divisions there is virtually no
variation relative to the federal minimum (e.g., East South Central), in some divisions there is more
variation but little within-division identifying information (e.g., Mountain), and in other divisions there is
both variation over time and across states (e.g., New England). Conversely, as the top panel shows, the
across-division variation is rather extensive.
Thus, when ADR estimate their much more saturated model, the identifying information is
substantially reduced and comes from a much more restricted set of comparisons. Before concluding that
this more restricted identification provides more convincing evidence on the effects of minimum wages, a
number of questions should be asked. To begin, what do we find if we estimate the models separately by
Census division? In ADR’s saturated specification the effect of the minimum wage (and all other
controls) is constrained to be the same in each division. However, if we think that the patterns of
unobserved shocks to divisions differ (or that the effects of the same observed shocks – like technological
change – differ), why not also allow the effects of the observed variables to differ by division?
The results, which are reported in Table 3, reveal that the estimated effects of the minimum wage
differ substantially across Census divisions, and – just as importantly – that our ability to obtain a precise
estimate of the minimum wage effect varies substantially across divisions. In particular, for the New
England, West North Central, West South Central, and Mountain divisions there are significant
disemployment effects, with elasticities ranging from −0.15 to −0.64, a rather large range. For three other
divisions – East North Central, East South Central, and South Atlantic – the estimated effects are also
negative, although these are not statistically significant, and the estimates for East South Central are
implausibly large. Finally, for the Mid-Atlantic division the estimated elasticities are positive but
insignificant, and for the Pacific divisions the estimates are near zero.
Looking at the standard errors, and having in mind as a plausible range of elasticities from prior
evidence something like −0.1 to −0.3 or perhaps somewhat larger, it is clear that only three divisions –
17

New England, West North Central, and West South Central – yield sufficiently precise estimates to detect
a statistically significant elasticity in this range.18 Thus, looking division-by-division, which in the spirit
of ADR’s study seems like the best way to control for spatial heterogeneity across Census divisions,
yields one of two things – either precise estimates that point to disemployment effects, or estimates too
imprecise to be informative. In and of itself, these results lead to a very different conclusion than the one
reached by ADR.
Our finding that estimating the models separately by Census division often leads to very
imprecise estimates naturally raises the question of whether, in controlling for spatial heterogeneity, it is
really necessary to throw out information on other potential comparison states. The assumption that ADR
make is that the states within a Census division are better controls for states where minimum wages
increase than are states in other Census divisions. In particular, they argue that because minimum wage
changes are correlated with economic shocks at the regional level, the models should include “…Census
division-specific time effects, which sweeps out the variation across the nine divisions and thereby
control for spatial heterogeneity in regional economic shocks …” (p. 206). However, they do not test this
hypothesis directly and, indeed, provide no convincing evidence that the counterfactual employment
growth that comes from states in other Census divisions does not provide a good control.19 Moreover,
there is considerable heterogeneity among states within Census divisions (e.g., Maryland vs. South
Carolina, West Virginia vs. Florida, or Connecticut vs. Maine), and some divisions have many states and
cover huge areas (e.g., the Mountain division), so the a priori argument for why the within-division states
provide better controls is unclear.20

18

This would not necessarily have been predicted from looking at the variation in Figure 2. On the one hand, New
England and West North Central exhibit a fair amount of within-division variation in minimum wages. But West
South Central has only one change, for Arkansas. In contrast, other divisions that display substantial variation –
such as South Atlantic – do not yield precise estimates. Much of the variation in the South Atlantic division is
driven by Delaware and Washington, DC.
19
ADR (and DLR) present some indirect evidence that their specification better captures spatial heterogeneity.
However, as we show later in the paper, this indirect evidence is much less persuasive than the authors claim.
20
For example, even if one accepted the notion that geographically-proximate states provide better controls, there is
still a question of whether states within a Census division are better controls than closer states in other Census
divisions.

18

To address this shortcoming in ADR’s analysis, we use two empirical approaches to determine
which states are good controls for the states with minimum wage increases in any particular period. Our
first approach uses the initial step of the Abadie et al. (2010) synthetic control approach to estimating
treatment effects. This method can be applied to simple settings when a discrete treatment (like
implementing a program) is applied to one unit (such as a geographic area) and not to others. The latter –
which are the potential control units (referred to as “donor” units) – are then sorted according to a
matching estimator intended to measure the quality of each unit as a control. The choice of variables on
which to match is subject to the choice of the researcher; most typical, perhaps, would be to match on
prior values or percent changes (where there are level differences) in the outcome of interest.21
To draw a comparison with the literature on minimum wages, suppose we want to estimate the
effect of a specific state minimum wage increase in this setting. If we had a time period when only one
state raised its minimum wage, the standard panel data approach would use the other 49 states as controls.
In contrast, the “case study” approach, typified by Card and Krueger (1994), would choose another state
(or even a subset of that state) based on geographic contiguity. In this context, ADR’s approach
essentially restricts the set of control states to those in the same Census division. However, nothing in
ADR’s study establishes that states in the same division are better controls (just as nothing in the Card
and Krueger study establishes that Pennsylvania is a good – let alone the best – control for New Jersey).
The synthetic control approach provides us with empirical evidence on which states are the best control
states.22
We apply this synthetic control approach to the CPS data used in the preceding analyses. We first
define the set of treatment observations as state-quarter observations with minimum wage increases of at
21

After ascertaining the match quality of each potential control unit, the method is then used to estimate the
treatment effect by weighting control units based on quality of the match. In this section of the paper, we focus on
the identification of which states are better matches as controls. Implementing the second step is more complicated
than with a single discrete treatment because in the minimum wage setting there is continuous variation in the
treatment, and there are multiple increases. Later in the paper, we propose a procedure to implement the second step
and provide estimates of minimum wage effects based on that procedure.
22
Sabia et al. (2012) use the synthetic control approach to estimate the effects of the increase in the minimum wage
in New York in 2004. In particular, they compare estimates using geographically proximate states to those that
instead use control states picked by the synthetic control method. In their case the approach puts much of the weight
on the geographically proximate states, although some states outside of the Census division get substantial weight in
the employment regression (Maryland and Ohio).

19

least 5 cents in that quarter and no minimum wage increase in the previous four quarters, yielding a set of
129 potential minimum wage treatments to analyze. For each of these treatments, we define a set of
potential donor units (state-quarter observations) as states with no minimum wage increase in the same
quarter and the succeeding three quarters, and no minimum wage increase in the previous four quarters.
In these analyses, a variable is chosen on which to match over the four quarters prior to the treatment,23
and then the weights that the matching estimator assigns to each of these donor units are computed.
The validity of ADR’s approach can be assessed by looking at how much of this weight is
assigned to states in the same Census division. A finding that most of the estimation weight is on donor
states in the same Census division as the treatment state would rationalize ADR’s approach; states in
other divisions would not match as well because those other regions have different prior trends.
Conversely, if only a little weight is put on state-quarter pairs in the same division, this would tell us that
there is no good rationale to restrict (or even focus) attention on the states in the same Census division,
either because spatial heterogeneity is not important, or if it is, because it is not specific to the Census
divisions used by ADR.24
The synthetic control approach requires a choice of variables on which to match, and we used
four different alternatives to implement the procedure. Three of these involve matching on forms of the
dependent variable: the log of the teen employment-to-population ratio, as well as the one-quarter change
and the four-quarter change in that variable, each of these defined over the four pre-treatment quarters.25
We also matched on the residuals from the standard panel data estimator for teen employment (Table 1,
column (1)), again for the prior four quarters. This is not a standard type of variable on which to match,
23

In the matching process for each treatment case, the relative importance of each value of the matching variable
over the four previous quarters is included in the optimization routine, but it can also be specified in advance. To
obtain standardized results across all treatment cases and to economize on computational requirements, we treated
lags one through four of the matching variable as equally important, although relaxing this restriction does not affect
the results.
24
In some cases, there were no potential donor units in a division because all other states in the division had a
minimum wage increase in the current quarter, the next three quarters, or the previous four; these cases were thrown
out since no weight can be assigned to state-quarter pairs in the Census division if there are no donors in the division
for that particular treatment. As a result, we look to see whether there is substantial weight on donor states in the
same division only when there are such donor states, to avoid overstating the extent to which donor states come
from other divisions.
25
As explained in the notes to Table 4, when matching on the one- and four-quarter changes, treatment observations
are lost at the beginning of the sample period.

20

primarily because there typically is not a regression model underlying the application of the synthetic
control approach; rather, the synthetic control estimator is typically used instead of a regression model.
However, matching on the residuals is informative about the spatial heterogeneity arguments that ADR
put forward, as their contention is that the residuals for states in the same Census division share common
features that are correlated with minimum wage changes. Consequently, matching on the residuals
provides information on whether the residuals for states in the same region share these commonalities and
hence whether these states are good controls – and as in ADR’s approach, should be isolated as the
control states by including division × period dummy variables.
The results are summarized in Table 4. As noted, there are 129 unique treatments that are defined
for this analysis. Of these, 50 have potential donors in the same Census division, covering six divisions.
The key results are reported in columns (1)-(4); these are the weights from the matching process on states
in the same division. With the exception of West North Central, these weights are generally well below
one. In 14 out of the 24 cases they are below 0.25, and in some cases they are quite close to zero.26
Columns (5)-(7) report on the average number of divisions and states in the donor pool, and the average
number of states in the same division. One thing we see from these columns is that the low weight on
states in the same division is not attributable to a small number of potential donor states from the same
division. For example, East North Central has the second highest average number of potential donor
states from the same division but weights close to zero, while West North Central has one of the lowest
number of potential donor states from the same division but the highest weights.
In addition, the average weight assigned to same-division states in the donor pool by the synthetic
control method is no higher – and indeed is generally lower – than the average weight assigned to states
in other divisions that are in the donor pool. For example, computations not reported in the table show
that the average weight per same-division donor states in column (1) is 0.159, almost identical to the

26

Code is Stata was used for the state analysis, and code in R for the similar county analysis described later (because
of a far greater number of potential donors). The software is available at
http://www.mit.edu/~jhainm/synthpage.html (viewed July 30, 2012).

21

average weight per non-same-division donor state of 0.160.27 Moreover, in only 16 of 50 cases are the
average weights per same-division donor state higher than the random threshold of 1/(number of potential
donors).28
These results provide striking evidence against ADR’s choice to restrict the control states to those
in the same Census division. For most Census divisions, states outside the Census division tend to be
better controls for treatment observations, whether matched on regression residuals or on levels or growth
rates of teen employment. In cases where most of the weight is on states outside the division, the
conventional panel data estimator may provide more reliable estimates of minimum wage effects than the
specification that includes division x period controls.
A second, more transparent method, which we term the “ranked prediction error” approach, is
also used to address the question of which states are good controls for the states with minimum wage
increases. The synthetic control approach finds a weighted average of the potential donor states to best
match the treatment unit. The second method, instead, matches up the treatment unit to each potential
donor unit one-by-one. For each of these potential controls, the root mean squared prediction errors
(RMSPE) of the exact same matching variables used for the synthetic control approach are calculated for
the donor unit relative to the treatment unit in the pre-treatment period (the four quarters prior to the MW
change in the treatment unit).29 The analysis then asks whether the donors in the same division are better
controls than the donors outside the division by comparing the RMSPEs for the same-division states with
the RMSPEs for other states.
Some notation helps to clarify the method and the difference between the two approaches.
Denote a specific treatment unit by T,30 the potential donors in the same division Ds1, …, DsJ, and the
potential donors in other divisions Do1, …, DoK. The synthetic control approach finds a weight for each
27

We view the results for the regression residuals as most pertinent to the critique in ADR (and DLR), as explained
earlier. If we compare these averages for the other three columns, they average 0.199 per same-division donor state,
and 0.148 per non-same-division donor state – only slightly less.
28
This is for column (1). For columns (2)-(4), the corresponding numbers are 24, 17, and 19 (these last two are
relative to 49 and 44 unique minimum wage treatments, owing to some loss of observations from the lagged
variables).
29
The RMSPE here refers to the root-mean-squared prediction error when using the donor observations to predict
the treatment observations for the four quarters prior to the minimum wage increase.
30
The treatment unit is a particular state in a particular quarter; the time subscript is omitted.

22

donor, ws1, …, wsJ and wo1, …, woK, to best match the treatment unit during the pre-treatment period,
using an RMSPE criterion. What was done before, then, was to sum up the weights for the donor states in
the same division, Ws = Σjwsj, and ask whether this weight was large.
In the ranked prediction error approach, we calculate the RMSPE separately for each potential
donor, for the same-division and other-division donor states respectively (denoted rsj, j = 1,…, J, or rok, k
= 1,…, K). These r’s are then pooled, and ordered based on how well they match the treatment unit
according to an RMSPE criterion. Finally, a percentile in this ranking is assigned to each donor unit,
denoted Pm, m = 1,…, (J + K), where the highest rank is given to the donor with lowest r.31
The percentile assigned to a donor state is defined as the percentage of donor states with a higher
RMSPE – i.e., a worse match. Thus, a percentile of 100 (or near 100 with a smaller number of states)
would imply that a particular donor unit provides the best match. A percentile near zero would imply that
it provides the worst match. And a percentile near 50 would suggest that it provides about as good a
match as a randomly chosen control unit.
If ADR are correct that same-division states provide better controls than states in other divisions,
then the percentile ranking should be higher, on average, for states in the same division as a treatment unit
than for states in other divisions. To test this, the percentiles for same-division states are collected after
doing this analysis for every possible treatment unit and the associated matching variables (exactly as in
the synthetic control analysis), and histograms for these percentiles are constructed to see if the samedivision states are clustered at higher percentiles than would be expected if these states were, on average,
no better or worse controls than other states (or, equivalently, if the distributions of the percentiles appear
approximately uniform).
To help explain, Figure 3 displays an example of the first step of this process for one treatment
unit – California in 2001:Q1. The potential same-division donor states are Alaska, Hawaii, and Oregon;
Washington is also in the Pacific division but had a minimum wage increase in the same quarter. For
each of the four matching variables, the corresponding figure is the histogram of RMSPEs for all potential
31

For example, if there are 50 donor units, then the unit with the lowest RMSPE gets a rank of 50. The Weibull rule
is used to convert ranks to percentiles. With N units, the percentile is (100 × rank)/(N+1).

23

donor states, with the three same-division states highlighted with the thin vertical lines that extend to the
top of the box. As the figure reveals, states within the same division can provide quite good matches,
with low RMSPEs relative to other states (e.g., Alaska in the upper-right panel), or they can provide quite
bad matches, with relatively high RMSPEs (e.g., Hawaii in the upper-left panel).32
Figure 4 then presents the analysis aggregating across all of the treatment units, plotting the
histogram for the percentiles in the RMSPE distribution for each same-division state that ever appears as
a potential donor in this analysis. The figure indicates no tendency of these percentiles to be clustered
towards the upper end of the distribution for any of the matching variables. Instead they look much closer
to uniform, and the medians are around 50. The implication is that the same-division control states are,
on average, no better than the control states from other divisions, contrary to ADR’s identification
strategy.
We also examined the medians of these percentiles for each of the Census divisions. The only
division where other states in that division consistently stand out as generally providing the best controls
– in the sense that the percentile rankings are above the median – is the West North Central region.
Looking back at Table 4, notice that the synthetic control approach also indicated a high weight on samedivision states only for this division. Thus, the two analyses lead to a qualitatively similar conclusion:
Both raise doubts about the validity of ADR’s restriction that identifying information be confined to states
in the same division, with one notable exception – the West North Central division.
Finally, it is instructive to compare the division-specific minimum wage estimates in Table 3 with
the results from the synthetic control or ranked prediction error approach. Both approaches show that the
only Census division for which there is a strong indication that most of the control states should come
from within the division is West North Central. Table 3 shows that when minimum wage effects are
estimated for this division in isolation, there is statistically significant evidence of a negative employment
effect of minimum wages, with an estimated elasticity −0.19, very much in line with much of the existing
evidence on minimum wages.
32

The figure also shows that, for a particular minimum wage treatment, whether a particular state provides a good
match can depend on the matching variable, not surprisingly. This is much less of an issue for the aggregated
analysis below.

24

Furthermore, Table 4 also indicates that New England and the Pacific regions assign nonnegligible weight to states in the same region. Of the two, the estimates in Table 3 for New England are
precise, as noted above, and these estimates also point to negative employment effects (with a larger
disemployment effect). In contrast, Table 4 indicates that especially for the matching on residuals –
which seems most pertinent to ADR’s argument – states in the same division get essentially no weight for
the Middle Atlantic and East North Central divisions. These are two cases that, in Table 3, do not provide
any evidence of disemployment effects. Thus, while this analysis does not pin down one “best”
estimator, it does indicate that (a) in most cases, there is little rationale for ADR’s choice to focus only on
the within-division variation to identify minimum wage effects; and (b) when there is a good rationale for
doing this, the evidence shows negative and statistically significant effects of minimum wages on teen
employment, with elasticities that are in or near the −0.1 to −0.2 range.
Dube et al. (2010)
As noted earlier, Dube et al. (DLR) focus on restaurant employment with county-level QCEW
data from 1990-2006. They show that the standard panel data model with county and period fixed effects
yields negative employment effects, with elasticities in the conventional range, whereas these effects
become small and insignificant when either state-specific linear time trends or Census division × quarter
interactions (or both) are added. As noted above, the inclusion of these additional controls is problematic.
However, the main focus of DLR is on a research design based on cross-border county pairs.
When they include unique dummy variables for cross-border contiguous county pairs interacted with
period, they identify the effect of minimum wages from differences in employment changes in these
paired counties on either side of a state border – using the within-county-pair variation in the same way
that including division × period dummy variables in the specifications in ADR relies on the withinCensus division variation. Given that this identification strategy is the key contribution of this paper, we
focus on their cross-border analysis of the effects of minimum wages on restaurant employment rather
than on their analyses that more closely parallel ADR.
The key estimates from this approach are reported in Table 5, replicating the results in DLR
(Table 2, specifications 5 and 6); the estimates are nearly identical to theirs. The first two columns use
25

the balanced panel of the subset of counties in the contiguous border county-pair analysis, but include
only county and period (quarter) fixed effects. As in DLR, two specifications are reported – with and
without a control for total private-sector employment. The estimated minimum wage effects on restaurant
employment are negative and in the old “consensus range,” with the first significant at the ten-percent
level. In columns (3) and (4), county-pair × period interactions are added to replicate DLR’s method of
controlling for spatial heterogeneity. As the table shows, the estimated minimum wage effects are
slightly positive and statistically insignificant.
Prior to getting to our main line of inquiry regarding this paper, we first note that DLR
substantially overstate the number of cross-border county pairs that are used to identify the effects of
minimum wages in their approach. Their Figure 2 claims to show all the state borders – and counties
along them – that are used in their analysis. This figure is replicated in Panel A of Figure 5, and shows 81
distinct state border pairs. However, many of the borders highlighted in this figure are for pairs of states
that did not have a minimum wage higher than the federal minimum during their sample period. Panel B
shows the corrected figure, which clearly includes far fewer state borders. For example, while the top
panel suggests that there is identifying information along the Michigan, Indiana, and Ohio borders, the
bottom panel shows that there is in fact no minimum wage variation along these borders. As it turns out,
their sample includes only 48 distinct state border pairs with identifying information.33
However, the main question concerns the underlying assumption in DLR’s identification strategy
– that the cross-border contiguous county in the bordering state that did not raise its minimum wage is the
best control for the county in the state that did raise its minimum.34 As they point out, this has close
parallels to the type of analysis in Card and Krueger (1994), who studied the effects of the 1992 minimum

33

Note that Panel B has the counties on the North and South Dakota border shaded, whereas Panel A does not.
There was a higher minimum wage in North Dakota (by five cents) in the first three months of 1990, so this is one
border that DLR missed. There is also another slight discrepancy. DLR’s data includes a higher minimum wage in
Maryland in the first six months of 2006 – $6.15, instead of the $5.15 federal minimum wage that actually prevailed.
This correction would eliminate two additional state border pairs (Maryland’s border with Virginia and West
Virginia). However, in this paper we use their original data and making this correction to the data did not materially
change the results. Finally, note that to maintain consistency with DLR’s analysis, we use the balanced sample of
counties with data in all periods. That restriction drops some counties along the borders shown in the figures.
34
For some treatment counties, there are more than one cross-border contiguous county.

26

wage increase in New Jersey by comparing employment changes in the fast food industry in that state to
areas in Pennsylvania – where the minimum wage stayed fixed – on or near the border with New Jersey.
There is some intuitive appeal to the idea that cross-border counties are good controls because of
their geographic proximity. And we might expect that, on a priori grounds, the case for using contiguous
counties as controls is stronger than for using states in the same Census division (as in ADR).
Nonetheless, it is not obvious, without evidence, that cross-border counties are appropriate controls. For
example, spillover effects can certainly contaminate the control observations. If workers displaced by the
minimum wage find jobs on the other side of the border, employment will expand in the control areas;
this, however, implies that we should find larger disemployment effects when restricting attention to
cross-border controls. The same would apply to price effects, if higher prices in the county with the
minimum wage led to higher product demand in the cross-border county. But there are other
possibilities. Workers could cross into the state that raises its minimum wage to search for jobs (à la
Mincer, 1976), reducing employment in the cross-border state as well as in the state where the minimum
wage increased, muting the effects. And, in principle, price-setting could also be affected: When the
minimum wage goes up across the border, firms may raise prices because the elasticity of product
demand has effectively fallen. Moreover, geographic proximity does not necessarily imply that crossborder counties experience the same shocks,35 especially given that the relevant shocks in DLR are those
that affect restaurant employment conditional on aggregate economic activity.
The bottom line is that the assumptions underlying this vast narrowing of potential controls
should be tested. Is there evidence in support of DLR’s assumption that cross-border contiguous counties
provide appropriate control groups? As before, we address the question of the quality of cross-border
contiguous counties as controls using the synthetic control matching estimator – this time to calculate the
weight that the matching puts on the contiguous cross-border counties relative to the weight it puts on
other potential control counties.

35

Addison et al. (2009), who do a similar analysis, acknowledge this issue. Although, they still use this method to
estimate minimum wage effects, they give an example of a cross-border county match that is quite bad, with a 3.5%
unemployment rate for one treatment county and a 7.7% unemployment rate for the contiguous cross-border county,
and they suggest that “such examples of poor matches across state borders could be rather common” (p. 406).

27

The analysis exactly parallels the state-level analysis. Potential donors to the control group are all
counties in the states that were identified as potential donors in the previous analysis.36 The estimator is
then implemented, and the weights put on the cross-border control counties that DLR actually use are
computed. The criteria for defining treatments and controls are the same as before, but now done at the
county level. In particular, the set of treatment counties are border counties with a minimum wage
increase and where there was no minimum wage increase in the previous four quarters. Potential donor
units are county-quarter observations with no minimum wage increase in the same quarter and the
succeeding three quarters, and similarly no minimum wage increase in the previous four quarters. Two
different analyses are done. The first includes all potential donor counties. In the second analysis, we
restrict the set of donor counties on which the synthetic control calculation has to match. In particular, we
first calculate, for each treatment and the potential donor counties, the RMSPE of each donor county for
the four quarters prior to the minimum wage increase. We then use the 50 donor counties with the lowest
RMSPE as potential donors, adding in DLR’s contiguous cross-border counties if they are not already in
this set of 50.
The match is done on the same types of variables as before defined over the four previous
quarters: regression residuals (from a regression of the log of the ratio of restaurant employment to county
population on the log of the minimum wage and state and period (quarter) dummy variables); the log of
county restaurant employment relative to county population; and the one-quarter and four-quarter
differences in logs of restaurant employment relative to county population.37 As before, in some cases
there were no potential contiguous cross-border donor units for a county, and these cases are thrown out.
The results are reported in Table 6, and the analysis reveals that the weight assigned to the crossborder contiguous counties as controls – the only controls DLR use – is very small. In Panel A, where
there are typically just over 50 possible controls for each treatment, the weight on the cross-border
contiguous counties is, on average, 0.036 in column (1), and of a similar or smaller magnitude in the other
36

The set of potential donors is restricted to the counties in the balanced sample of counties (with non-missing
employment data) that DLR use.
37
Note that this dependent variable differs from that used in Table 5, by dividing by county population. We do this
because we do not want to match on levels of county restaurant employment, which can vary tremendously across
counties.

28

columns. (As for ADR, we view the results for the regression residuals as most pertinent to the critique in
DLR.) The table also shows the percentiles of the distribution of weights. The distribution is highly
skewed. For example, in column (1) of Panel A, the median is only 0.006, compared with the mean of
0.036, and the 75th percentile is below the mean (0.027). In Panel B (also column (1)), the 90th percentile
is below 0.01.
Going through a similar calculation to what we did for states, the average weight assigned to
contiguous cross-border counties by the synthetic control method is again generally lower than the
average weight assigned to all other potential donor counties. Computations not reported in the table
show that the average weight per contiguous cross-border county in column (1) – for the analysis of the
full donor pool in Panel B of Table 6 – is only 0.0050, only slightly more than the average weight per all
other donor counties 0.0040.38 Moreover, in only 16 of 121 cases are the average weights per contiguous
cross-border county higher than the random threshold of 1/(number of potential donors).39 We reach the
same conclusion if we do these computations for the restricted set of donors in Panel A; indeed in this
case the evidence is even stronger that the contiguous cross-border counties do not provide better
controls. Thus, Table 6 and these computations indicate quite clearly that for almost all treatment
counties, the cross-border county is a poor match – no better than a county chosen at random from the list
of all potential comparison counties. Given this evidence, it seems difficult to argue that throwing out the
information on other potential comparison counties, as DLR do, is preferable to using the standard panel
data estimator.
Because there is some a priori appeal to the idea that cross-border counties are useful controls
(even if the evidence to this point does not bear this out), we also looked more closely at cross-border
counties for MSAs that straddle two states, to see whether within these more integrated labor markets the
cross-border counties were better controls. Out of our 121 unique minimum wage treatments considered

38

If we compare these averages for the other three columns, the average across columns is 0.0058 per contiguous
cross-border county, and 0.0035 per all other donor counties.
39
This is for column (1). For columns (2)-(4), the corresponding numbers are 13, 19, and 13 (these last two are
relative to 114 and 109 unique minimum wage treatments, owing to some loss of observations from the lagged
variables).

29

in Table 6, 31 have cross-border controls that are in other states but in the same MSA.40 We compared
the weights we calculated for the cross-border counties in this subsample to the weights implied by a
randomly chosen county. Specifically, if there was only one cross-border county in the MSA we
compared the weight on that county to 1/(number of potential donors), and if there was more than one
cross-border county we averaged the weight across these counties and did the same comparison. In only
seven cases out of 120 possible matches was there a much higher weight for the cross-border county; four
of these were in the New York-Newark-Edison, NY-NJ-PA MSA, two were in the Lewiston, ID-WA
MSA, and one was in the Philadelphia-Camden-Wilmington, PA-NJ-DE-MD MSA. In 18 other cases the
average weight for the cross-border county was higher, but trivially so; the within-MSA weights were in
the 0.001-0.019 range, and the differences relative to a randomly chosen county were less than 0.001.
Thus, even within MSAs there is no evidence that cross-border counties provide better controls.
We also used the ranked prediction error approach to assess whether contiguous cross-border
counties are better controls than other counties. The method is the same as before, but now examines the
percentiles for the matched contiguous cross-border counties (analogous to the previous examination of
same-division states). Figure 6 shows the percentiles for these matched counties. There is perhaps a
slight tendency for these percentiles to be clustered above 50, but, in general, the histograms seem fairly
close to uniform. Again, there is little in the data to support the assumption made by DLR that the
contiguous cross-border counties are the appropriate controls.
One might argue that it is not surprising that in our two types of analyses the contiguous crossborder counties get so little weight or fail to stand out as the best control areas. After all, as shown in
column (5) in Panel B of Table 6, there is typically a very large number of potential donor counties for
any one county’s minimum wage increase. But that is precisely the point: With the large set of potential
donor counties, why throw away so much potential identifying information without assessing which
counties are in fact the best controls?

40

Examples are Nez Perce County, ID, in the Lewiston, ID-WA MSA, and Westchester County, NY, in the New
York-Newark-Edison, NY-NJ-PA MSA.

30

Nonetheless, one might be concerned that when there is a very large number of potential donors,
noise in the data will cause the weight assigned by the synthetic control method to “valid” controls (the
contiguous cross-border counties, according to DLR) to be smaller than the weight assigned to the
“invalid” controls. That is, with a large number of potentially donor counties, a weighted average of
“invalid” controls picked out by the synthetic control method could provide a better fit to the pretreatment observations on the treated county – even if these invalid controls would not be good predictors
of the post-treatment “counterfactual.” However, we have already seen two types of evidence indicating
that this is not what is driving our results. First, we found similar results from the synthetic control
analysis for states as for counties, even though there are far fewer potential donors in the state-level
analysis. Similarly, the analysis of the 50 counties with the best fit led to the same conclusion as the
analysis of all counties. Second, the ranked prediction error approach does one-to-one comparisons
between each control that ADR and DLR use and other potential controls, so nothing in this approach
leads to putting inordinate weight on what – according to ADR and DLR – would be invalid controls.
Is there other evidence that justifies the approach in ADR and DLR?
ADR and DLR present two analyses that are intended to show that their identification strategy is
valid and that the more conventional panel data approach, which uses a much broader set of controls
(states or counties), leads to spurious evidence of negative minimum wage effects because of spatial
heterogeneity. The first is an analysis of employment changes prior to the implementation of minimum
wages, and the second is pitched as a falsification test showing that county employment appears to
respond to cross-border minimum wage changes.
In the first analysis, ADR estimate dynamic models for employment and earnings with long leads
and lags, and then present figures showing cumulative effects at these leads and lags based on the
coefficients from these models. For example, in their Figure 2, ADR plot the cumulative effects from
leads of two years to lags of four years for the standard panel data specification with fixed state and
period effects, as well as for the specification that adds both the state-specific linear time trends and the
Census division × interactions. The replication of their graphs for employment effects appear in the
upper-left and upper-right panels of Figure 7. According to ADR, the evidence of leading effects in the
31

upper-left panel, in comparison with the evidence in the upper-right panel, provides “strong evidence
against the model without controls for heterogeneity across states …” (p. 220).
However, this evidence is both overstated and misleading. First, note that the figure also suggests
that the inclusion of state-specific linear time trends and the division × period interactions produces fairly
substantial positive estimates of the effect of the minimum wage on teen employment – with elasticities of
about 0.2 – three to four years after the minimum wage increase. Although ADR do not remark on this, it
seems unlikely that those estimates represent the real effects of minimum wages and hence they could be
viewed as providing evidence against the model that includes those controls.
Second, although the regression estimates for their main analyses are based on quarterly data, the
graphs they show in their Figure 2 (replicated here in the top row of Figure 7) are generated from a model
specified with leads and lags on an annual basis. The bottom two panels of the figure show the graphs
from a less constrained model that specifies the leads and lags at a quarterly frequency. Not surprisingly,
the plots are noisier. However, the quarterly graphs appear to show three things: (1) they do not give a
clear indication of any kind of pre-trend in the standard panel data model; (2) they point to negative
employment effects in the two years after the minimum wage increase that look quite distinct from
anything occurring in the data prior to the minimum wage increase; and (3) they show significant positive
employment effects (with elasticities in the 0.4 to 0.5 range) more than three years after the minimum
wage increase in the model with state-specific linear trends and division × period interactions, which
again could be construed as evidence against that model.
DLR also present evidence suggesting that the inclusion of state-specific linear trends and Census
division × period interactions in panel-data models eliminates spurious negative estimates of the effects of
minimum wage for periods without a minimum wage increase. This analysis is captured succinctly in
their Table 3, which – for the model with just county and period fixed effects – reports the “effect” three
years prior to the minimum wage increase, one year prior, and the “pre-trend” based on the difference
between the cumulative effects at these two points.41 The replication of their results is reported in column

41

These models include a contemporaneous effect of the minimum wage, two leads at three years (12 quarters) and

32

(1) of Table 7; again, the results are nearly identical to theirs. The evidence points to a fairly large
cumulative negative “effect” at a four-quarter lead, and also a negative trend 12 quarters to four quarters
prior to the minimum wage increase; both estimates are significant at the ten-percent level. These same
results, in somewhat more detail, are reported in their Figure 4, which shows a growing cumulative
negative effect up to the minimum wage increase, although this cumulative leading “effect” is never
statistically significant. This is replicated in the upper-left panel of Figure 8.
Note, however, that their figure also shows a positive cumulative leading effect for the model
with state-specific linear trends and division × period interactions, and in this case the cumulative effect is
sometimes statistically significant; see the upper-middle panel of Figure 8, which also replicates their
Figure 4. Not only do DLR fail to remark on this result; they essentially deny it, claiming (on p. 956) that
this specification shows “relatively stable coefficients for the leads centered around 0.”42
DLR also omit the estimates of this specification from their Table 3, which they use to criticize
the “canonical” panel data model as showing a pre-existing negative trend. However, we computed the
corresponding estimates for the model including the state-specific linear trends and the division × period
interactions (their specification 3) and report the results in column (2) of Table 7. These estimates show a
significant positive “pre-trend” of the same magnitude as the negative pre-trend obtained from the
standard model. And since negative anticipatory effects of a minimum wage are at least in principle
plausible (as acknowledged by ADR, p. 220), one might argue that the positive pre-trend raises particular
doubts about the specification with state-specific trends and division × period interactions.
Moreover, there is no obvious rationale for focusing only on the pre-trend calculated between the
4th and the 12th quarters. If the results were robust to which interval was used, it would be of little
consequence. However, Panel A of Table 8, which retains the specification with 12-quarter leads, but
computes the pre-trend between the 2nd, 6th, 8th, and 10th quarters as well, shows that this is not the case.

one year (4 quarters), but no lagged minimum wage effects. The results discussed below for this specification and
variants thereof are very similar if the intervening semi-annual leads (which they include in the specification on
which the figure discussed below is based) are included as well.
42
To be precise, this quote refers to a different specification (specification 6), but they then say that the results in
question are similar: “Intermediate specifications … with coarser controls for heterogeneity in employment show
similar results to the local specification (6)” (p. 956).

33

As columns (1) and (2) show, it is only for the 4th-to-12th quarter interval that the “canonical” or standard
panel-data model (column (1)) generates a statistically significant pre-trend, and for many of the other
intervals it is quite small. In contrast, for the model with county and period fixed effects, state-specific
linear trends, and division × period interactions, the pre-trend is significant and positive in every case.
Column (3) shows the similar estimates for the contiguous border county-pair sample. These estimates
are all statistically insignificant; however, the standard errors are large, and in some cases the coefficient
estimates are of roughly the same absolute magnitude as the estimates in column (1).
As Panel B of Table 8 shows, the evidence for their claim is even weaker in regression models
that correspond to their Figure 4 but that include leads only up to 8 quarters. In this case, the canonical
model shows no evidence of pre-trends, with estimates that are small and statistically insignificant.
However, for the model with county and period fixed effects, state-specific linear trends, and division ×
period interactions, there is again robust evidence of a positive pre-trend. And for the contiguous border
county-pair sample, the point estimates in two of three cases are large and positive, although insignificant
given the very large standard errors.
The table highlights in bold and italics the two estimates reported in DLR’s Table 3 for this
specification.43 It is quite clear that the estimates DLR emphasized are the ones that most strongly make
their case, and that there are many more equally plausible analyses of the issue of pre-trends that produce
much weaker evidence, and indeed sometimes support the opposite conclusion.
Finally, Figure 4 in DLR – replicated in the top three panels of Figure 8 – parallels the figure in
ADR by using data at a smoother semi-annual frequency than the quarterly frequency used in all their
model estimates. As shown in Panel B of Figure 8, when the figures are replicated using the data on a
quarterly basis, the figure for specification 1 is much less suggestive of any kind of pre-treatment trend.44
In fact, the only pronounced negative estimate is one quarter before the treatment. In contrast, the figure
for specification 3 still shows a pronounced upward trend prior to the treatment. And, to us at least, it is

43

There are alternative specifications with a control for private-sector employment added, but the results are similar.
How one views these graphs is partly subjective. But this interpretation appears to be more accurate than DLR’s
claim that “Using leads and lags for every quarter, as opposed to every other quarter, produces virtually identical
results” (p. 956, footnote 24).
44

34

not obvious that the pre-trend apparent for specification 6 – DLR’s preferred contiguous border countypair analysis – is less problematic. It is true that the estimates are much less precise, as indicated by the
wider confidence intervals. But there is a noticeable increase in employment in the two quarters
preceding the minimum wage increase, and the decline subsequent to that is of roughly the same order of
magnitude as the decline in the figure for specification 1.
In a second analysis, DLR present results from what they refer to as a falsification test, which
they argue supports their view that spatial heterogeneity is responsible for the negative effects of
minimum wages on employment found in conventional panel data estimates (p. 958). In particular, they
define a narrow sample of all border counties where the minimum wage was never above the federal
minimum wage in the sample period, and then estimate the standard panel data specification (with county
and period fixed effects) for this sample, substituting the cross-border counties’ minimum wages. When
they do this, their estimated “placebo” minimum wage effect is negative, albeit smaller than its standard
error, and it is about 60 percent of the estimated minimum wage effect for the counties bordering the
placebo sample but using their actual minimum wages.45 These estimates are replicated in column (1) of
Table 9.
However, DLR do not have a valid falsification test. For most county pair-quarter observations
in the sample they use (96 percent), both the cross-border minimum wage and the own-county minimum
wage are the same – equal to the federal minimum wage. Thus, in most cases the placebo minimum wage
assigned to the county is equal to the actual minimum wage prevailing in the county, which of course can
affect employment.46 In other words, DLR assume that the null hypothesis of no spatial heterogeneity
implies that the effect of the placebo minimum wage is zero, and then reject this null because their
estimated placebo minimum wage effect is negative. But because the “placebo” minimum wage they use
is often the same as the actual minimum wage, we would expect a negative minimum wage effect in their
placebo analysis even if there is no spatial heterogeneity – invalidating their falsification test.
45

See their Appendix B for further information on how they implemented their falsification test.
Note that the effect of federal minimum wage variation is still identified in their placebo sample when county and
period fixed effects are included as long as the federal minimum wage is not binding in some states. The minimum
wage change induced by federal variation will vary across placebo counties depending on the level of the state
minimum wage in the cross-border county.
46

35

Confirming this problem, we do not find a placebo effect when the sample used for DLR’s
falsification test is modified to avoid having a contaminated placebo sample. Specifically, we restrict the
sample to observations after the federal minimum wage increase in 1997, so that there is no federal
minimum wage variation in the placebo counties that is captured by the counties matched to them.47 As
shown in column (2) of Table 9, in this case the estimated minimum wage effect in what DLR term the
“actual minimum wage” sample is large, negative, and statistically significant, while the estimate for the
placebo sample is much smaller and statistically insignificant.48 In this placebo sample, there are still
many counties paired with cross-border counties that have the same federal minimum wage (although
now it does not vary); only 7 percent of the county pair-quarters have a minimum wage difference. It is
possible to further restrict attention to an even more informative placebo sample by focusing on county
pairs where there is at least one minimum wage difference in this sample period between the true
minimum wage in the placebo county and the cross-border minimum wage that is used in the falsification
test; after all, it is this variation that is informative about their falsification test. As shown in column (3),
in this case the estimated minimum wage effect in the placebo sample falls to zero, while the estimated
minimum wage effect in the actual minimum wage sample is little changed. These estimates provide yet
additional evidence refuting DLR’s claim that spatial heterogeneity generates spurious evidence of
disemployment effects of minimum wages.49

47

Their sample ends before the most recent round of federal increases beginning in 2007. In this exercise, we use
data beginning in 1998:Q3, one year after the last federal minimum wage increase, to avoid lagged effects of federal
minimum wages. But the results were very similar if the sample starts in 1997:Q4, the first quarter after the last
federal increase.
48
The standard errors in both samples are a good deal smaller, likely because there is much more state minimum
wage variation in the latter part of the sample.
49
Additional evidence in Thompson suggests that ADR’s and DLR’s conclusion that spatial heterogeneity generates
spurious evidence of disemployment effects is wrong. His analysis is at the county level, because there is
considerable within-state heterogeneity in wage levels and local labor market conditions, and because, he argues,
counties better represent labor markets for teens than do entire states given constraints that keep teens close to where
they live. Thompson finds substantial negative effects of federal minimum wage increases in the low-earnings (or
high-impact) counties. This analysis considers the types of factors that DLR and ADR suggest can lead to spurious
evidence of disemployment effects of minimum wages. First, by identifying the effects from differences between
counties with low versus high teen earnings, it controls for state-specific changes or trends that could be correlated
with minimum wage changes. Moreover, because the minimum wage variation comes from federal legislation, and
the identification comes from cross-county variation within states, any endogeneity of state minimum wages is
unlikely to be a confounding influence. Second, in a “placebo test,” Thompson uses the same methods to estimate
minimum wage effects two years later when the federal minimum wage did not change. He finds no effect, which
suggests that differential trends for low- and high-earnings counties do not drive the results.

36

IV. What is the Right Estimate of the Minimum Wage Effect?
The standard panel data estimate of the employment effect of the minimum wage for teenagers is
negative and significant, with an estimated elasticity of −0.165. In contrast, the alternative estimates that
ADR report are insignificant, and often close to zero. The same is approximately true for the estimates
for restaurant workers from the standard panel data model and those reported by DLR. We have shown
that: (i) the assumptions underlying the approaches used by ADR and DLR are not supported by the data;
(ii) testing these assumptions indicates that the standard panel data estimator that uses all potential
controls is unlikely to be problematic; and (iii) in the isolated cases when the assumptions ADR and DLR
use are supported by the data, the estimates of the employment effects of minimum wages are again
negative and statistically significant. In addition, we have shown that the evidence that ADR and DLR
report to argue that the standard panel model is misspecified and leads to negatively biased estimates is
overstated and misleading. In and of itself, this evidence indicates that there is no reason to discard the
standard panel data estimates that lead to minimum wage employment elasticities very much in line with
the earlier consensus.
But having raised the issue of what the best controls are for the states that raise their minimum
wage, and having suggested how we can use the data to answer this question, it is of interest to ask
whether we can extend these methods to arrive at an estimated elasticity that uses the data to construct the
controls. In this section, we discuss such an approach and the resulting estimates. We do not claim to
have completely resolved the econometric issues involved, but we do think our approach has some
intuitive, heuristic appeal.
Our approach to some extent follows Autor et al. (2006). In studying the effects of the adoption
of wrongful-discharge laws on employment, they restrict attention to a subset of observations across
states and over time, including some periods before and after the adoption of these laws in some states,
and the same periods for other states that did not adopt such laws.50 The idea is to identify the effects of
laws from relatively short-term changes in treatment states relative to control states. We adopt the same

50

They actually study three different kinds of laws, but this does not alter the basic approach.

37

approach here. Because the regression models we (and ADR and DLR) used estimate contemporaneous
effects of minimum wages, we focus on one-quarter treatment periods defined by the state and quarter in
which the minimum wage is increased. And given that we want to incorporate information from the
synthetic control analysis discussed earlier, we use the period four quarters prior to a minimum wage
increase as the pre-treatment period.
Specifically, we first define the set of potential treatment observations as states and quarters when
the minimum wage increased, and the four previous quarters for such states. (We discuss our methods in
the context of the state × quarter analysis in ADR; it carries over fully to the county × quarter analysis in
DLR, to which we return below.) Each observation in this sample is characterized by the employment
rate, the minimum wage, and the control variables, Oit = (Eit, MWit, Xit).51 We want to construct a
control or counterfactual observation for each state and quarter in this subsample, defined as Cit = (Ecst,
MWcst, Xcst), where the c superscript indicates that the data represent an average, possibly weighted, of
other states that serve as controls; Cit could also be a single state (think of the Pennsylvania control in the
Card and Krueger fast-food study). The observations on Oit and Cit corresponding to each experiment
span five quarters, as just mentioned; denote the vectors corresponding to these five quarters for any
particular minimum wage increase (experiment “e”) as Oie and Cie. We will return in a moment to how
Cie might be constructed. The data set is now doubled in size, and includes all of the original observations
for an identified set of treatments, plus a counterfactual observation for each original observation.
Stacking the data to combine these observations, we can then run the standard minimum wage
employment regression on all of these observations. In these regressions, we include quarter dummy
variables as in the standard panel data model. In addition, we include dummy variables for each set of
five observations on a treatment state in each unique experiment e (Oie), and each set of ten observations
on either the treatment states or the counterfactual observations in each unique experiment (Oie and Cie).
The latter sets of dummy variables allow the counterfactual observations to have their own intercepts in
each experiment, whether or not the composition of the counterfactual states varies for different minimum
51

Note that this implies that when there are minimum wage increases in a state fewer than four quarters apart
observations on treatment states can be repeated, unlike in the standard panel data model.

38

wage increases for the same treatment state. In addition, the experiment-specific treatment state dummy
variables allow the level of the dependent variable to differ between the treatment and counterfactual
states prior to the increase in the minimum wage in the treatment state.
The key question, of course, is how to construct the counterfactual observations. Consider first
the standard panel data estimator. With the only difference that we now restrict attention to the period of
a minimum wage increase and the four preceding observations for states with an increase, the standard
panel data case would involve constructing the counterfactual as the equally-weighted average of other
states.52 Given that the sample includes the 50 states and Washington, DC, these weights would equal
1/50 if we were trying to “match” the standard panel data estimator in which we do not weight the state
observations.
In contrast, the analysis in ADR effectively restricts the identifying information to states in the
same Census division (by including Census division × period interactions). We can accommodate this
restriction in our approach by constructing the counterfactual observations only from the same-division
states, with weights equal to one divided by the number of states in the division.
Finally, we can also use the weights obtained from the synthetic control analysis to construct the
counterfactual observations. To do this, we first consider the 129 “clean” minimum wage treatments and
their associated controls that we used in the analysis in Table 4, consisting of state-by-quarter
observations with average quarterly minimum wage increases of at least 5 cents, with no increase in the
previous four quarters, and controls with no minimum wage increases in the previous four quarters or the
next three.53 As it turns out, however, this subset of minimum wage increases (there are a total of 544

52

This does not exactly parallel the standard panel data estimator when the data are weighted. However, as
explained below, we are ultimately going to use the observations weighted by the synthetic control weights to
construct the counterfactual observation, in which case one does not want to use population weights but rather let the
data dictate which states – large or small – best match the pre-treatment observations. Having constructed the
observations, though, in the regression estimation we use teen population to weight the treatment observations; we
apply the same weights to the corresponding counterfactual observations, because these are supposed to estimate
what would have happened in the treatment observations absent the treatment.
53
In that table, because we were focusing on the validity of restricting controls to states in the same Census division
(as in ADR), we focused on a subset of 50 of these 129 minimum wage increases where there was at least one
potential control in the same division.

39

minimum wage increases in our sample period) appears to be unusual, in that it does not generate a
negative minimum wage effect using the modified standard panel data estimator described above.
We therefore instead use the synthetic control approach for all of the minimum wage increases in
the sample period.54 This means that the counterfactual observations can include observations with
minimum wage increases. However, because these counterfactual observations contribute to both the
estimated employment rate and the estimated minimum wage variables (as well as the other controls), this
is not problematic. When there is less minimum wage variation between the treatment and counterfactual
observations, we would correspondingly expect less of an employment response (if there is one). Note
that this is no different from what ADR do when they focus on minimum wage variation within the same
Census division, in which case all of the states in the same division serve as potential controls,
contributing no identifying information if the minimum wage change is the same, and less identifying
information if the minimum wage change is similar but not equal to the treatment state. Because we want
to weight the counterfactual observations by how well they match the treatment observations in the four
quarters prior to the minimum wage increase, and the counterfactual observations can now have minimum
wage increases of their own, we use the synthetic control weights that we get from the matching on
residuals; these residuals will be net of minimum wage effects and the effects of the other controls.
There are three econometric issues with our matched panel data estimator that are potentially
problematic. First, there is a potential circularity here, because we need an estimated minimum wage
effect to compute these residuals, and that effect is in dispute. We therefore compute residuals in two
ways – first using the estimated minimum wage effect from the standard panel data estimator, and then
restricting that effect to be zero. The method of computing the residuals turns out to have little effect on
the estimates, although we recognize that we have not determined a way to simultaneously estimate the
minimum wage effect and the weights on the counterfactual observations. Second, there is no way to
cluster the standard errors at the state level anymore, because the counterfactual observations can be made
up of different states. We therefore instead cluster the standard errors at the level of either the treatment
54

We actually exclude the minimum wage increases induced by the federal minimum wage increase in 1990:Q2 for
which there are not four preceding quarters in the sample period. However, excluding these increases and
constructing the counterfactual observations using the available quarters did not affect the results.

40

state or the counterfactual observation in each experiment.55 Third, our counterfactual observations are
constructed based on estimated weights, and we have not accounted for this estimation in the construction
of the standard errors, which are therefore downward biased. However, the main issue concerns the point
estimates, and as we will see our matched panel data estimator based on the synthetic control weights
gives point estimates very similar to those of the standard panel data estimator.
The results of this analysis are reported in Table 10. For purposes of comparison, column (1)
repeats the standard panel data estimates. Column (2) shows the estimates using the 129 “clean”
minimum wage experiments that were the starting point for the Abadie et al. (2010) synthetic control
analysis; the states used to construct the counterfactual are equally weighted. One can view this as
applying the Autor et al. (2006) methods to this subset of minimum wage increases. In this case the
estimated minimum wage effect falls and is not statistically significant. In contrast, column (3) reports
estimates using the same methods, but incorporating all of the minimum wage increases (except those
occurring in 1990:Q2) and all of the control states; this is most like the standard panel data estimator in
that all of the minimum wage variation is used. The estimated elasticity is now larger, at −0.199. The
difference between this estimate and that in column (2) indicates that, as noted earlier, the subset of
increases that we used for the earlier synthetic control analysis are different from the overall set of
minimum wage increases.
In column (4), we mimic what ADR did by including the period × division interactions, which
restricts the identifying information to minimum wage variation within Census divisions. In our set-up,
we do this by using only the states within the same division to construct the counterfactual observations.
Paralleling their findings, the minimum wage effect is diminished and is no longer statistically significant.
Of course we have called into question this restriction, because the synthetic control analysis indicated
that same-division states were not the appropriate control states.
Finally, we turn to the estimates that use the weights from the synthetic control method. Based
on the results above, we focus on the estimates using all of the minimum wage increases. Column (5)
55

Note that this implies that the treatment states are clustered at a lower level than in the standard panel data case
where we cluster states. We do this to be symmetric with the counterfactual observations.

41

reports estimates from a procedure in which the residuals used for the matching and computation of
weights are based on the standard panel data model including the minimum wage. The estimated
minimum wage effect is noticeably stronger – an elasticity of −0.295. Column (6) reports estimates when
the minimum wage effect used to construct the residuals is restricted to be zero – more in line with the
conclusions of ADR and DLR. As the table shows, this restriction has almost no effect on the estimated
elasticity of teen employment with respect to the minimum wage, which is now −0.281. Thus, the
evidence indicates that when we let the data determine the appropriate control states to use for estimating
the effects of state minimum wage increases, we find stronger evidence of disemployment effects, with
teen employment elasticities near −0.3.56
In Table 11 we report estimates from the same approach applied to the QCEW data from DLR.
We report both unweighted and weighted estimates (by county population). DLR do not weight their
county-level estimates, although the estimates in ADR, because they are at the individual level, are
effectively weighted by state population. Column (1) reports standard panel data estimates, which yield
elasticities in the −0.1 to −0.2 range. Column (2) restricts the sample to the paired (contiguous crossborder) counties that are the focus of DLR. The estimated employment effects of minimum wages
become smaller, and insignificant for the unweighted case. Column (3) reports our Autor et al.-type
estimator, restricting attention to the quarter of each minimum wage increase and the four preceding
quarters, and constructing the counterfactual observation as the equally-weighted average across all
border counties in other states; we restrict attention to the bordering counties so that we can also estimate
the counterfactual observations using only the contiguous cross-border counties. Interestingly, the
estimates fall to zero.
Column (4) instead mimics the DLR research design, using only the paired cross-border counties
as controls. This has no effect on the estimates relative to column (3), indicating that it is not the
restriction to cross-border contiguous counties as controls that eliminates the disemployment effects of

56

We also did this estimation without using population weights for the treatment and corresponding counterfactual
observations. The pattern of how the estimated minimum wages effects change across the columns was similar. But
all of the estimated minimum wage effects were larger, so that they were significant in columns (2) and (4). For
what we regard as the best estimates – in columns (5) and (6) – the estimated elasticities were −0.36.

42

minimum wages. Rather, the key difference (thus far) is between columns (2) and (3), with the difference
being the restriction to observations including only the contemporaneous minimum wage increase and the
previous four quarters (i.e., identifying information from long differences is eliminated).57 In other
words, for the county-level analysis we are not successful at finding an Autor et al.-type panel data
estimator that matches the standard panel data estimator. Finally, we report the estimates using the
synthetic control weights (based on the “top 50” donors as in Panel A of Table 6). For the unweighted
results the estimates are positive, near zero, and statistically insignificant. The weighted estimates, in
contrast, are small, but negative and statistically significant (at the ten-percent level).
What do we conclude? First, we clearly do not obtain as strong evidence of disemployment
effects when using the synthetic control weights as for teen employment in the CPS. As noted earlier,
this is not surprising, nor is it in any way contradictory with the existing literature. Most of the existing
evidence focuses on teenagers or other low-skill groups, rather than on any particular industry; and at the
industry level, labor-labor substitution can mask gross disemployment effects for the least-skilled.
Second, the evidence suggests that it may not be the “spatial heterogeneity” that DLR (and ADR)
emphasize that is the important factor here, as the restriction to contiguous cross-border control counties
to construct the counterfactual (relative to the broader set of all border counties) does not change the
estimates. Finally, and perhaps most significantly, when we weight the estimates we actually find some
evidence of disemployment effects when the synthetic control weights are used. These are, arguably, the
most defensible estimates.58
Finally, we consider two extensions of the ADR and DLR estimates that might be more appealing
than what they do. First, as we already noted, states can be quite distant within the same division, and
ADR’s specification rules out using bordering states as controls if the state are in different divisions.
Thus, it may be of interest to revisit the analysis of teen employment using the CPS data, but with the
border state strategy of DLR. On the other hand, DLR throw out lots of data in using only bordering

57

Other work suggests that these longer differences may be relevant for identifying adverse effects of minimum
wages (Baker et al., 1999).
58
We do not find these negative estimates if we exclude the private-sector employment control. But that exclusion
does not seem defensible.

43

counties, so it may be of interest to look at restaurant employment in the QCEW data at the state level,
using the same bordering state controls.
Table 12 reports these estimates – using the DLR approach of adding interactions between
dummy variables for state-border pairs and quarter. The QCEW estimates at the state level that
correspond most closely to DLR are the unweighted estimates in Panel A. In this case, both estimated
minimum wage effects are negative, and neither is statistically significant, although the estimate with the
interactions included is closer to zero. Based on these estimates, though, one would not argue that adding
the state-pair × period interactions has a substantive effect on the estimates. However, when the estimates
are weighted (Panel B) the results are more in line with DLR’s county-level analysis.
A much sharper contrast emerges from the CPS analysis. In this case, adding the state-pair ×
period interactions has essentially no effect on the estimated minimum wage effects, although in Panel B
the standard error increases so the estimate becomes insignificant. We would argue that this state-border
analysis has much more in common with the identification strategy in DLR, and is more sensible on a
priori grounds than the same-division controls used in the ADR paper that was published (and presumably
written) later.59
Of course we have argued that assumptions about appropriate controls should be based on the
data, rather than just a priori assumptions. If we instead let the CPS data tell us which states to match on,
we are back to the estimates in columns (5) and (6) of Table 10, providing even stronger evidence of
negative employment effects of minimum wages. The only missing analysis, then, is the estimation of
minimum wage effects using the state-level QCEW data in which we use the synthetic control weights.
These estimates, which parallel the county-level analysis in Table 11, are reported in Table 13.60 The
estimates are similar to those in Table 11. Specifically, there is not consistently strong evidence of
disemployment effects of minimum wages on restaurant employment, although the estimates are negative

59

Similarly, although not reported in a table, when we estimated the Autor et al.-type specification using only paired
states as controls (paralleling Table 10, column (4), using cross-border states instead of same-division states) we
also obtained a negative estimate (−0.212 with a standard error of 0.097).
60
The only difference is that there is no version of Table 11’s column (2) in Table 13, because Table 11 shows the
difference between using all counties and border counties.

44

and significant when the synthetic control weights are used and the data are weighted by county
population.
V. Conclusions
Throughout the long-running debate about the employment effects of minimum wages, the
empirical evidence has focused on similar questions: How does a minimum wage affect employment?
Which workers are affected? And how do we ensure that we are getting a valid comparison that isolates
the effect of the minimum wage?
Given the ongoing ebb and flow of this debate, it would have been shortsighted to think that the
2008 book that two of us wrote (Neumark and Wascher, 2008), despite surveying a massive amount of
evidence, would have settled the issue. And indeed it has not. In particular, echoing long-standing
concerns in the minimum wage literature, Dube et al. (2010) and Allegretto et al. (2011) attempt to
construct better counterfactuals for estimating how minimum wages affect employment. When they
narrow the source of identifying variation – looking either at deviations around state-specific linear trends
or at within-region or within-county-pair variation – they find no effects of minimum wages on
employment, rather than negative effects. Based on this evidence, they argue that the negative
employment effects for low-skilled workers found in the literature are spurious, and generated by other
differences across geographic areas that were not adequately controlled for by researchers.
The analysis in this paper, however, provides compelling evidence that their methods are flawed
and lead to incorrect conclusions. In particular, the methods advocated in these studies do not isolate
more reliable identifying information (i.e., a better counterfactual). In one case – the issue of statespecific trends – we explicitly demonstrate the problem with their methods and show how more
appropriate ways of controlling for unobserved trends that affect teen employment lead to evidence of
disemployment effects similar to that reported in past studies. In the other case – identifying minimum
wage effects from the variation within Census divisions or, even more narrowly, within contiguous crossborder county pairs – we show that the exclusion of other regions or counties as potential controls is not
supported by the data.

45

We think the central question to ask is whether, out of their concern for avoiding minimum wage
variation that is potentially confounded with other sources of employment change, ADR and DLR have
thrown out so much useful and potentially valid identifying information that their estimates are
uninformative or invalid. That is, have they thrown out the “baby” along with – or worse yet, instead of –
the contaminated “bathwater”? Our analysis suggests they have. Moreover, despite the claims made by
ADR and DLR, the evidence that their approaches provide more compelling identifying information than
the standard panel data estimates that they criticize is weak or non-existent.
In addition, when the identifying variation they use is supported by the data, the evidence is
consistent with past findings of disemployment effects. Moreover, when we let the data determine the
appropriate control states to use for estimating the effects of state minimum wage increases in the CPS
data, we find stronger evidence of disemployment effects, with teen employment elasticities near −0.3.
The findings from similar analyses of restaurant employment in the QCEW data are a bit more mixed, but
the weighted estimates again point to negative employment effects (with smaller elasticities of around
−0.05). Thus, our analysis substantially undermines the strong conclusions that ADR and DLR draw –
that there are “no detectable employment losses from the kind of minimum wage increases we have seen
in the United States” (DLR, 2010, p. 962), and that “Interpretations of the quality and nature of the
evidence in the existing minimum wage literature …, must be revised substantially” (ADR, 2011, p.
238).
Can one come up with a dataset and an econometric specification of the effects of minimum
wages on teen and low-skilled employment that does not yield disemployment effects? As in the earlier
literature, the answer is yes. But prior to concluding that one has overturned a literature based on a vast
number of studies, one has to make a much stronger case that the data and methods that yield this answer
are more believable than the established research literature, and convincingly demonstrate why the studies
in that literature generated misleading evidence. Our analysis demonstrates that the studies by Allegretto
et al. (2011) and Dube et al. (2010) fail to meet these standards. As a result, we continue to view the
available empirical evidence as indicating that minimum wages pose a tradeoff of higher wages for some

46

against job losses for others, and that policymakers need to bear this tradeoff in mind when making
decisions about increasing the minimum wage.
We also believe that there are more general lessons to be learned from this paper. Although the
results in the paper focus on the evidence on the employment effects of minimum wages, a similar set of
issues carries over to the analysis of essentially any kind of policy that might be studied with panel data
on geographic regions over time. When doing these kinds of panel data studies, researchers often make
the same choices as ADR and DLR – such as including state-specific linear time trends, or narrowing the
scope of the geographic areas used for controls by either restricting the sample or estimating a more
saturated model that reduces the identifying information to variation within a smaller region. Our
evidence suggests that these kinds of analyses, even if well motivated, can deliver misleading evidence of
either the presence or absence of effects. We do not advocate ignoring the potential biases introduced by
differences in the regions where policies are enacted. We do, however, advocate using the data to explore
more fully what specifications provide the most reliable counterfactuals, and we discuss some methods
for doing this. After all, in other contexts – such as instrumental variables estimation – we generally ask
hard questions about the validity of the identifying assumptions used in those analyses.
In particular, if these kinds of sensitivity analyses deliver robust results that are insensitive to
detrending or to the narrowing of identifying information by restricting the set of control areas, then they
can clearly bolster the evidence. If, however, they point to different evidence, then the researcher has to
seriously explore which analysis is most convincing. In the case of removing long-term trends from panel
data over time, we have suggested methods that increase the likelihood that business cycle movements are
not confounded with long-term trends. And in the case of restricting the set of control areas, we have
shown how to obtain evidence on which areas are better controls, and have suggested a way to
incorporate this evidence in estimating policy effects. We believe these kinds of approaches – and others
more appropriate to different types of analyses – should be incorporated into what can otherwise be a
somewhat blind approach to sensitivity analysis. And we would suggest that these kinds of approaches
are imperative in cases where a particular sensitivity analysis is claimed to overturn a large body of
existing evidence.
47

References
Aaronson, Daniel, Park, Kyung-Hong, and Daniel Sullivan. 2007. “Explaining the Decline in Teen Labor
Force Participation.” Chicago Fed Letter, Number 234, January, The Federal Reserve Bank of Chicago.
Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2011. “Comparative Politics and the Synthetic
Control Method.” Working Paper No. 2011-25, MIT Political Science Department.
Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2010. “Synthetic Control Methods for
Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program.” Journal of
the American Statistical Association, Vol. 105, No. 490, June, pp. 493-505.
Addison, John T., McKinley L. Blackburn, and Chad D. Cotti. 2012. “The Effect of Minimum Wages on
Labour Market Outcomes: County-Level Estimates from the Restaurant-and-Bar Sector.” British Journal
of Industrial Relations, Vol. 50, No. 3, September, pp. 412-435.
Addison, John T., McKinley L. Blackburn, and Chad D. Cotti. 2011. “Minimum Wage Increases in a Soft
U.S. Economy.” Economic Series No. 273, Institute for Advanced Studies, Vienna.
Addison, John T., McKinley L. Blackburn, and Chad D. Cotti. 2009. “Do Minimum Wages Raise
Employment? Evidence from the U.S. Retail-Trade Sector.” Labour Economics, Vol. 16, No. 4, August,
pp. 397-408.
Allegretto, Sylvia A., Arindrajit Dube, and Michael Reich. 2011. “Do Minimum Wages Really Reduce
Teen Employment? Accounting for Heterogeneity and Selectivity in State Panel Data.” Industrial
Relations, Vol. 50, No. 2, April, pp. 205-240.
Autor, David H., John J. Donohue III, and Stewart J. Schwab. 2006. “The Costs of Wrongful-Discharge
Laws.” Review of Economics and Statistics, Vol. 88, No. 2, May, pp. 211-231.
Baker, Michael, Dwayne Benjamin, and Shuchita Stanger. 1999. “The Highs and Lows of the Minimum
Wage Effect: A Time-Series Cross-Section Study of the Canadian Law.” Journal of Labor Economics.
Vol. 17, No. 2, April, pp. 318-50.
Baskaya, Yusuf Soner, and Yona Rubinstein. 2011. “Using Federal Minimum Wage Effects to Identify
the Impact of Minimum Wages on Employment and Earnings Across U.S. States.” Unpublished paper,
Central Bank of Turkey.
Brown, Charles, Charles Gilroy, and Andrew Kohen. 1982. “The Effect of the Minimum Wage on
Employment and Unemployment,” Journal of Economic Literature, Vol. 20, No. 2, June, pp. 487-528.
Card, David. 1992a. “Using Regional Variation in Wages to Measure the Effects of the Federal Minimum
Wage.” Industrial and Labor Relations Review, Vol. 46, No. 1, October, pp. 22-37.
Card, David. 1992b. “Do Minimum Wages Reduce Employment? A Case Study of California, 19871989.” Industrial and Labor Relations Review, Vol. 46, No. 1, October, pp. 38-54.
Card, David, and Alan B. Krueger. 1994. “Minimum Wages and Employment: A Case Study of the FastFood Industry in New Jersey and Pennsylvania.” American Economic Review, Vol. 84, No. 4, September,
pp. 772-93.
Cogley, Timothy, and James M. Nason. 1995. “Effects of the Hodrick-Prescott Filter on Trend and
Difference Stationary Time Series: Implications for Business Cycle Research.” Journal of Economic
Dynamics and Control, Vol. 19, Nos. 1-2, January-February, pp. 253-278.
Congressional Budget Office. 2004. “What Is Happening to Youth Employment Rates?” Available at
http://cbo.gov/sites/default/files/cbofiles/ftpdocs/60xx/doc6017/11-18-youthemployment.pdf (viewed
March 12, 2011).
Douty, H. M. 1960. “Some Effects of the $1.00 Minimum Wage in the United States.” Economica, Vol.
27, No. 196, May, pp. 137-47.

Dube, Arindrajit, T. William Lester, and Michael Reich. 2010. “Minimum Wage Effects Across State
Borders: Estimates Using Contiguous Counties.” Review of Economics and Statistics, Vol. 92, No. 4,
November, pp. 945-64.
Fairris, David, and Leon Fernandez Bujanda. 2008. “The Dissipation of Minimum Wage Gains for
Workers through Labor-Labor Substitution: Evidence from the Los Angeles Living Wage Ordinance.”
Southern Economic Journal, Vol. 75, No. 2, October, pp. 473-96.
Giuliano, Laura. “Minimum Wage Effects on Employment, Substitution, and the Teenage Labor Supply:
Evidence from Personnel Data.” Forthcoming in Journal of Labor Economics.
Hirsch, Barry T., Bruce E. Kaufman, and Tetyana Zelenska. 2011. “Minimum Wage Channels of
Adjustment.” Andrew Young School of Policy Studies Research Paper Series No. 11-34.
Hodrick, Robert J., and Edward C. Prescott, 1997. “Postwar U.S. Business Cycles: An Empirical
Investigation.” Journal of Money, Credit and Banking, Vol. 29, No. 1, February, pp. 1-16.
Katz, Lawrence F., and Alan B. Krueger. 1992. “The Effect of the Minimum Wage on the Fast-Food
Industry.” Industrial and Labor Relations Review, Vol. 46, No. 1, October, pp. 6-21.
Lang, Kevin, and Shulamit Kahn. 1998. “The Effect of Minimum-Wage Laws on the Distribution of
Employment: Theory and Evidence.” Journal of Public Economics, Vol. 69, No. 1, July, pp. 67-82.
Lester, Richard A. 1960. “Employment Effects of Minimum Wages: Comment.” Industrial and Labor
Relations Review, Vol. 13, No. 2, January, pp. 254-64.
Lester, Richard A. 1946. “Shortcomings of Marginal Analysis for Wage-Employment Problems.”
American Economic Review, Vol. 36, No. 1, March, pp. 63-82.
Machlup, Fritz. 1946. “Marginal Analysis and Empirical Research.” American Economic Review, Vol.
36, No. 4, September, pp. 519-54.
Mincer, Jacob. 1976. “Unemployment Effects of Minimum Wages.” Journal of Political Economy, Vol.
84, No. 3, Part 2, August, pp. S87-S104.
Neumark, David, Mark Schweitzer, and William Wascher. 2004. “Minimum Wage Effects Throughout
the Wage Distribution.” Journal of Human Resources, Vol. 39, No. 2, Spring, pp. 425-50.
Neumark, David, and William Wascher. 2011. “Does a Higher Minimum Wage Enhance the
Effectiveness of the Earned Income Tax Credit?” Industrial and Labor Relations Review, Vol. 64, No. 4,
July, pp. 712-46.
Neumark, David, and William L. Wascher. 2008. Minimum Wages. Cambridge, MA: MIT Press.
Neumark, David, and William Wascher. 2004. “Minimum Wages, Labor Market Institutions, and Youth
Employment: A Cross-National Analysis.” Industrial and Labor Relations Review, Vol. 57, No. 2,
January, pp. 223-46.
Neumark, David, and William Wascher. 1996. “The Effects of Minimum Wages on Teenage
Employment and Enrollment: Estimates from Matched CPS Data.” Research in Labor Economics, Vol.
15, pp. 25-64.
Neumark, David, and William Wascher. 1994. “Employment Effects of Minimum and Subminimum
Wages: Reply to Card, Katz, and Krueger.” Industrial and Labor Relations Review, Vol. 47, No. 3, April,
pp. 497-512.
Neumark, David, and William Wascher. 1992. “Employment Effects of Minimum and Subminimum
Wages: Panel Data on State Minimum Wage Laws.” Industrial and Labor Relations Review, Vol. 46, No.
1, October, pp. 55-81.
Obenauer, Marie L., and Bertha von der Nienburg. 1915. “Effect of Minimum-Wage Determination in
Oregon.” Bureau of Labor Statistics Bulletin No. 176. Washington, DC: United States Department of

Labor.
Peterson, John M. 1960. “Employment Effects of Minimum Wages: Reply.” Industrial and Labor
Relations Review, Vol. 13, No. 2, January, pp. 264-73.
Peterson, John M. 1959. “Employment Effects of State Minimum Wages for Women: Three Historical
Cases Re-Examined.” Industrial and Labor Relations Review, Vol. 12, No. 3, April, pp. 406-22.
Peterson, John M. 1957. “Employment Effects of Minimum Wages: 1938-1950.” Journal of Political
Economy, Vol. 65, No. 5, October, pp. 412-30.
Ravn, Morten O., and Harald Uhlig. 2002. “On Adjusting the Hodrick-Prescott Filter for the Frequency of
Observations.” The Review of Economics and Statistics, Vol. 84, No. 2, May, pp. 371-80.
Reich, Michael. 2009. “Minimum Wages in the United States: Politics, Economics, and Econometrics. In
Labor in the Era of Globalization, Brown, Eichengreen, and Reich, eds. Cambridge, UK: Cambridge
University Press, pp. 353-74.
Sabia, Joseph J. 2009. “The Effects of Minimum Wage Increases on Retail Employment and Hours: New
Evidence from Monthly CPS Data.” Journal of Labor Research, Vol. 30, No. 1, March, pp. 75-97.
Sabia, Joseph J., Richard V. Burkhauser, and Benjamin Hansen. 2012. “Are the Effects of Minimum
Wage Increases Always Small? New Evidence from a Case Study of New York State.” Industrial and
Labor Relations Review, Vol. 65, No. 2, April, pp. 350-76.
Smith, Christopher L. 2010. “The Polarization of the U.S. Adult Labor Market and its Effects on the
Demand for Teenage Labor.” Unpublished paper, Federal Reserve Board of Governors.
Stigler, George J. 1946. “The Economics of Minimum Wage Legislation.” American Economic Review,
Vol. 42, No. 3, January, pp. 347-54.
Thompson, Jeffrey P. 2009. “Using Local Labor Market Data to Re-Examine the Employment Effects of
the Minimum Wage.” Industrial and Labor Relations Review, Vol. 62, No. 3, April, pp. 343-66.
Watson, Nadine. 1996. “Positive Minimum Wage Effects on Employment – Alternative Explanations.”
Ph.D. Dissertation, University of California, San Diego.

.4
.2
0
-.2
-.4

-.4

-.2

0

.2

.4

Figure 1: Residual Plots for California

2000q1

2005q1

2010q1

1990q1

1995q1

2000q1

2005q1

2010q1

1990q1

1995q1

2000q1

2005q1

2010q1

1990q1

1995q1

2000q1

2005q1

2010q1

.2
0
-.2
-.4

-.4

-.2

0

.2

.4

1995q1

.4

1990q1

California

The upper-left panel shows the residuals from estimating the model with state-specific linear trends for
1994-2007:Q2; for the quarters outside this period prediction errors are shown. The lower-left, upperright, and lower-right panels, respectively, show the residuals for the following estimation periods:
1990-2007:Q2; 1994-2011:Q2; and 1990-2011:Q2. These three panels also display the fitted
regression lines of the residuals on the time trend for the 1994-2007:Q2 subperiod.

Figure 2: Between- and Within-Census Division Variation in State Minimum Wages
(Difference Relative to Federal Minimum Wage, in Dollars per Hour)

3

Average minimum wage difference by Census division
East South Central
West South Central
Mountain
Pacific

0

.5

1

1.5

2

2.5

New England
Middle Atlantic
East North Central
West North Central
South Atlantic

1995q1

2000q1
3

2010q1

1990q1

2.5
1.5
1
.5
0
2010q1

2005q1

2010q1

1990q1

2.5
2
1.5
2005q1

2010q1

1990q1

1995q1

2005q1

2010q1

2005q1

2010q1

3
2.5
1.5

2

AK
CA
HI
OR
WA

0

.5

1

2.5
2
1.5

AZ
CO
ID
MT
NV
NM
UT
WY

1
1990q1

2000q1

Pacific

.5
2010q1

2010q1

.5
2000q1

0
2005q1

2005q1

0
1995q1

3

3
1.5
1
.5
0

2000q1

2000q1

AL
KY
MS
TN

Mountain

AR
LA
OK
TX

1995q1

1995q1

1

2.5
2
1

1.5

DE
DC
FL
GA
MD
NC
SC
VA
WV

0
2000q1

1990q1

East South Central

.5

1
.5
0

1995q1

2

2.5

2005q1

3

3
2.5

IA
KS
MN
MO
NE
ND
SD

West South Central

1990q1

2000q1

South Atlantic

1.5

2

1995q1

3

2005q1

IL
IN
MI
OH
WI

2

2.5
2
1
.5
2000q1

West North Central

1990q1

NJ
NY
PA

0
1995q1

2010q1

East North Central

1.5

2.5
.5

1

1.5

2

CT
ME
MA
NH
RI
VT

0
1990q1

2005q1

Middle Atlantic

3

New England

3

1990q1

1995q1

2000q1

2005q1

2010q1

1990q1

1995q1

2000q1

Figure 3: Example of RMSPE Calculation at State Level

Frequency
2 3 4
1
0

0

1

Frequency
2 3 4

5

Log teen employment-topopulation ratio

5

Regression
residuals

0

.05
.1
.15
Pre-treatment RMSPE

.2

0

.6

1

Frequency
2 3 4

AK
HI
OR

0

0

1

Frequency
2 3 4

5

4-quarter diff. in log teen
employment-to-population ratio

5

1-quarter diff. in log teen
employment-to-population ratio

.2
.4
Pre-treatment RMSPE

0

.05

.1
.15
.2
Pre-treatment RMSPE

.25

0

.05

.1
.15
.2
Pre-treatment RMSPE

.25

Treatment state: CA, 2001:Q1. Same-division control states are AK, HI, and OR. (WA is excluded
because it had a minimum wage increase in the same quarter.) The thick bars are the histogram. The
thin vertical lines extending to the top of the graph show the placement of the RMSPEs for each control
state in the same division as the treatment state.

Figure 4: Distributions of Percentiles of Same-Division States’ RMSPEs

Density
0 .02 .04 .06 .08 .1

Log teen employment-topopulation ratio

Density
0 .02 .04 .06 .08 .1

Regression
residuals

0

20
40
60
80
Percentile ranking (Median = 53)

100

0

100

Density
0 .02 .04 .06 .08 .1

4-quarter diff. in log teen
employment-to-population ratio

Density
0 .02 .04 .06 .08 .1

1-quarter diff. in log teen
employment-to-population ratio

20
40
60
80
Percentile ranking (Median = 56)

0

20
40
60
80
Percentile ranking (Median = 50)

100

0

20
40
60
80
Percentile ranking (Median = 53)

Ranks are converted to percentile rankings using the Weibull rule described in the text.

100

Figure 5: Matched County Pairs Along State Borders for DLR Analysis
A. DLR’s Figure 2, eyeballed
(81 state borders with MW differential over 1990:Q1-2006:Q2)

B. Corrected version of DLR’s Figure 2, using their minimum wage data
(48 state borders with MW differential over 1990:Q1-2006:Q2)

Figure 6: Distributions of Percentiles of Contiguous Cross-Border Counties’ RMSPEs

Density
.02 .03
.01
0

0

.01

Density
.02 .03

.04

Log restaurant employment-tocounty population ratio

.04

Regression
residuals

0

20
40
60
80
Percentile ranking (Median = 62)

100

0

100

Density
.02 .03
.01
0

0

.01

Density
.02 .03

.04

4-quarter diff. in log restaurant
employment-to-county pop. ratio

.04

1-quarter diff. in log restaurant
employment-to-county pop. ratio

20
40
60
80
Percentile ranking (Median = 54)

0

20
40
60
80
Percentile ranking (Median = 65)

100

0

20
40
60
80
Percentile ranking (Median = 60)

Ranks are converted to percentile rankings using the Weibull rule described in the text.

100

Figure 7: Time Path of Cumulative Employment Elasticity in Response to
Minimum Wage Change, ADR
Specification 1

Specification 4
.8
.6
.4
.2
0
-.8 -.6 -.4 -.2

-.8 -.6 -.4 -.2

0

.2

.4

.6

.8

A. Annual leads and lags (ADR Figure 2B)

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

8

10

12

14

16

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

.8
.6
.4
.2
0
-.8 -.6 -.4 -.2

-.8 -.6 -.4 -.2

0

.2

.4

.6

.8

B. Quarterly leads and lags

-8

-6

-4

-2

0

2

4

6

“Specification 1” is the specification with state and period fixed effects. “Specification
4” also includes the state-specific linear trends and the division × period interactions.
The top graphs use the data from ADR (2011) and replicate the employment results in
Figure 2 from that paper, with annual leads and lags of the minimum wage variable.
The bottom graphs use the same data but include leads and lags at a quarterly
frequency, which corresponds to the frequency of the minimum wage variable used in
all of the regression analyses in ADR. The dashed lines show 90-percent confidence
intervals.

Figure 8: Time Path of Cumulative Employment Elasticity in Response to Minimum Wage Change, DLR

Specification 1

Specification 3

Specification 6

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

8

10

12

14

16

.8
-.8 -.6 -.4 -.2

0

.2

.4

.6

.8
.6
.4
.2
0
-.8 -.6 -.4 -.2

-.8 -.6 -.4 -.2

0

.2

.4

.6

.8

A. Semiannual leads and lags (DLR Figure 4)

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

-8

-6

-4

-2

0

2

4

6

8

10

12

14

16

-8

-6

-4

-2

0

2

4

6

.8
-.8 -.6 -.4 -.2

0

.2

.4

.6

.8
.6
.4
.2
0
-.8 -.6 -.4 -.2

-.8 -.6 -.4 -.2

0

.2

.4

.6

.8

B. Quarterly leads and lags

“Specification 1” is the specification with county and period fixed effects. “Specification 3” also includes the state-specific linear trends and
the Census division × period interactions. “Specification 6” includes county-pair × period interactions. Specifications 1 and 3 use the allcounty sample, while Specification 6 uses the contiguous border county-pair sample. The top graphs use the data from DLR (2010) and
replicate the employment results in Figure 4 from that paper, with semi-annual leads and lags of the minimum wage variable. The bottom
graphs use the same data but include leads and lags at a quarterly frequency, which corresponds to the frequency of the minimum wage variable
used in all of the regression analyses in DLR. The dashed lines show 90-percent confidence intervals.

Table 1: The Effects of the Minimum Wage on Teen (16-19) Employment,
1990 – 2011:Q2

(1)

(2)

(3)

(4)

Dependent variable: Log
(Employment/Population)
Log(MW)

-.165***
(.041)

-.074
(.102)

-.098
(.097)

.009
(.058)

Unemployment rate

-4.20***
(.427)

-3.83***
(.387)

-3.86***
(.403)

-3.12***
(.397)

.100
(.316)

.218
(.336)

.126
(.360)

.161
(.310)

State effects

Yes

Yes

Yes

Yes

Time effects

Yes

Yes

Yes

Yes

State trends

No

Yes

No

Yes

Region-specific time
effects

No

No

Yes

Yes

R2

.877

.893

.911

.921

N

4386

4386

4386

4386

Relative size of
youth population

Estimates are weighted by teen population. Standard errors are clustered at the
state level. ***, **, and * indicate estimates that are statistically different from
zero at the one-, five-, and ten-percent levels, respectively.

Table 2: Sensitivity of Minimum Wage Effects to Polynomial Order of State-Specific “Trends,” and Estimates Using Alternative
Detrending Methods, 1990 – 2011:Q2

(1)

(2)

(3)

(4)

(5)

(6)

(7)

Single trends,
estimated from
subperiod
excluding severe
recessions

Peak-topeak trends

HP filter
(λ =
1600)

Dependent variable: log(Employment/Population)
Order of polynomial
for state-specific
“trends”

Log(MW)
Unemployment rate
Relative size of youth
population
N

2nd

3rd

4th

5th

Detrendin
g method

-0.051
(0.085)

-0.230***
(0.073)

-0.180**
(0.069)

-0.185**
(0.073)

-.178**
(.090)

-.319**
(.126)

-.184***
(.068)

-3.591***
(0.494)

-2.571**
(0.454)

-2.376**
(0.461)

-2.378***
(0.492)

-3.06***
(.307)

-3.52***
(.760)

-2.38***
(.468)

0.490
(0.296)

0.402
(0.280)

0.412
(0.291)

0.354
(0.308)

.112
(.285)

.650
(.486)

.304
(.280)

4386

4386

4386

4386

4386

4386

4386

Estimates are weighted by teen population. Standard errors are clustered at state level. In columns (1)-(4), models include state
dummy variables interacted with a polynomial in time, with order of polynomial as indicated. In column (5), state-specific trends are
estimated from 1994:Q1-2007:Q2 and then extrapolated to 1990:Q1-2011:Q2. (These estimates are based on equations (1) and (2) in the text.) In
column (6), the peaks are based on NBER business cycle dates. In column (7), as noted in the text, λ is the smoothing parameter for the HP filter
and is set to the value commonly used for quarterly data. For columns (5)-(7), standard errors are block bootstrapped by state using 200
replications. ***, **, and * indicate estimated effects that are statistically different from zero at the one-, five-, and ten-percent levels, respectively
(based on the normal approximation in columns (5)-(7).

Table 3: The Effects of the Minimum Wage on Teen (16-19) Employment,
By Division

(1)

(2)

Dependent variable: Log
(Employment/Population)
1990:Q1-2011:Q2

1990:Q1-2009:Q4
(ADR sample)

New England

-.390***
(.052)

-.384***
(.058)

Mid-Atlantic

.166
(.143)

.105
(.162)

East North Central

-.208
(.284)

-.166
(.272)

West North Central

-.191**
(.082)

-.194***
(.067)

South Atlantic

-.150
(.242)

-.152
(.281)

East South Central

-2.24
(1.41)

-2.02
(1.51)

West South Central

-.217***
(.062)

-.147**
(.053)

Mountain

-.598***
(.139)

-.638***
(.187)

-.002
(.133)

.016
(.143)

Pacific

The specification reported in each row, for a division, includes the
unemployment rate, the ratio of teen population to total population, and state
and time (quarter) fixed effects. Estimates are weighted by teen population.
Standard errors are clustered at the state level. ***, **, and * indicate
estimated effects that are statistically different from zero at the one-, five-, and
ten-percent levels, respectively.

Table 4: Weights on States in Same Census Division from Synthetic Control Method, State-Level CPS Data
Proportion of weight on states in same division
Matching on:
Four-quarter
One-quarter
Log teen
Avg. # states in
Avg. #
Avg. #
difference in log
difference in log
employmentdonor pool in
states in
teen employment- divisions in
teen employmentto-population
Regression
same division
to-population ratio to-population ratio donor pool donor pool
ratio
residuals
Division
(1)
(2)
(3)
(4)
(5)
(6)
(7)
New England
0.168
0.209
0.163
0.185
6.9
30.4
1.9
Middle Atlantic
0.073
0.134
0.455
0.168
5.5
20.0
1.0
East North Central
0.000
0.000
0.016
0.015
9.0
39.5
3.5
West North Central
0.547
0.823
0.698
0.464
3.7
7.7
1.7
South Atlantic
0.123
0.290
0.075
0.222
6.9
26.8
4.9
Pacific
0.322
0.339
0.279
0.297
5.3
21.1
2.1
Aggregate
0.233
0.323
0.264
0.251
6.1
24.0
2.5
Results are reported for the 50 unique minimum wage treatments (out of a total of 129 increases based on criteria described in the text) for which
there is at least one potential donor state from the same Census division. The numbers in columns (5)-(7) refer to the matching on residuals or the
log teen employment-to-population ratio. There are somewhat fewer treatments and donors when matching on the one- or four-quarter differences
in the employment-to-population ratio because the earliest lags are not available at the beginning of the sample period. The aggregate row reports
the means across all treatment units.

Table 5: The Effects of the Minimum Wage on Restaurant Employment,
1990-2006:Q2

(1)

(2)

(3)

(4)

Dependent variable: log (restaurant
employment), DLR contiguous border countypair sample
Without county-pair ×
period interactions
(DLR, Table 2,
specification 5)

With county-pair ×
period interactions
(DLR, Table 2,
specification 6)

Log(MW)

-.137*
(.072)

-.112
(.079)

.057
(.115)

.016
(.099)

Log(population)

.952***
(.073)

.567***
(.103)

1.116***
(.190)

.714***
(.246)

Log(private-sector
employment)

…

.405***
(.067)

…

.393***
(.117)

County effects

Yes

Yes

Yes

Yes

Period effects

Yes

Yes

No

No

County-pair × period
interactions

No

No

Yes

Yes

70,620

70,582

70,620

70,582

N

Standard errors are two-way clustered at the (non-nested) state and border
segment levels; the border segment is the set of all counties on both sides of a
border between two states. ***, **, and * indicate estimates that are
statistically different from zero at the one-, five-, and ten-percent levels,
respectively.

Table 6: Weights on Contiguous Cross-Border Counties from Synthetic Control Method,
County-Level QCEW Data
Proportion of weight on contiguous cross-border counties
Matching on:
Four-quarter
One-quarter
difference in log
difference in log
Log restaurant
restaurant
restaurant
employmentemployment-toemployment-toto-county
county population
county population
Regression
population
ratio
ratio
residuals
ratio
Distribution
(1)
(2)
(3)
(4)
A. Donor pools restricted to 50 counties with lowest RMSPE for four quarters prior to minimum
wage increase
Minimum
0.000
0.000
0.000
0.000
th
10 percentile
0.000
0.000
0.000
0.001
th
25 percentile
0.001
0.002
0.002
0.004
Median
0.006
0.010
0.009
0.010
75th percentile
0.027
0.027
0.027
0.019
th
90 percentile
0.146
0.101
0.065
0.035
Maximum
0.406
0.659
0.496
0.336
Mean
0.036
0.038
0.035
0.017
B. Full donor pools
Minimum
0.000
0.000
0.000
0.000
th
10 percentile
0.000
0.000
0.000
0.000
th
25 percentile
0.000
0.000
0.001
0.001
Median
0.001
0.001
0.001
0.001
75th percentile
0.002
0.002
0.002
0.002
th
90 percentile
0.009
0.007
0.012
0.006
Maximum
0.208
0.308
0.474
0.393
Mean
0.009
0.007
0.015
0.007
County results are reported for the 121 unique minimum wage treatments (out of a total of 129
increases based on criteria described in the text) for which there is at least one potential contiguous
cross-border donor county. In Panel A, for each treatment the donor pool consists of the 50
counties with the lowest RMSPE for the four quarters following the minimum wage increase. If the
contiguous cross-border counties that DLR use as controls are not in this top 50, they are added to
the donor pool. Panel B does not impose this restriction. In both panels, the average number of
contiguous cross-border counties in the donor pool is 1.7, while the average number of counties in
the donor pool is 51.3 in Panel A and 959.6 in Panel B. There are somewhat fewer treatments and
donors when matching on the one- or four-quarter differences in the employment-to-population
ratio because the earliest lags are not available at the beginning of the sample period.

Table 7: The Effects of the Minimum Wage on Restaurant Employment, with
Leading Effects, 1990-2006:Q2

(1)

(2)

Dependent variable: Log(restaurant employment)

All counties (DLR,
Table 3, specification 1)

All counties, with
state-specific linear
trends and Census
division × period
interactions (DLR
specification 3)

Cumulative effect of
log(MW)
12-quarter lead

-.069
(.058)

.070
(.047)

4-quarter lead

-.192*
(.113)

.188*
(.094)

Pre-trend: 4-quarter
lead – 12-quarter
lead

-.122*
(.070)

.117**
(.054)

County effects

Yes

Yes

Period effects

Yes

No

82,800

82,800

N

Estimates correspond to Table 3 of DLR. Standard errors are clustered at the
state level. ***, **, and * indicate estimates that are statistically different from
zero at the one-, five-, and ten-percent levels, respectively.

Table 8: The Effects of the Minimum Wage on Restaurant Employment, with Leading Effects,
1990-2006:Q2

(1)

(2)

(3)

Dependent variable: Log(restaurant employment)

All counties (DLR,
Table 3, specification 1)

All counties, with
state-specific linear
trends, and Census
division × period
interactions (DLR
specification 3)

DLR contiguous
border county-pair
sample, with countypair × period
interactions
(DLR specification 6)

A. 12-quarter leads
Pre-trend:
10-quarter lead –
12-quarter lead

-.004
(.042)

.083***
(.031)

.049
(.072)

8-quarter lead – 12quarter lead

-.047
(.064)

.127**
(.051)

.057
(.095)

6-quarter lead – 12quarter lead

-.067
(.060)

.124**
(.049)

.056
(.121)

4-quarter lead – 12quarter lead

-.122*
(.070)

.117**
(.054)

.040
(.134)

2-quarter lead – 12quarter lead

-.105
(.071)

.088*
(.052)

.058
(.143)

B. 8-quarter leads
6-quarter lead – 8quarter lead

-.015
(.038)

.058**
(.022)

.062
(.092)

4-quarter lead – 8quarter lead

-.055
(.065)

.098**
(.039)

.119
(.125)

2-quarter lead – 8quarter lead

-.040
(.066)

.106***
(.036)

.137
(.125)

Specifications in Panel A, columns (1) and (2) correspond to Table 7, but with the pre-trend estimated over
different periods. Specifications in column (3) do the same for DLR’s specification 6. Specifications in
Panel B are the same, but only include leads up to 8 quarters. The two highlighted estimates are the ones
reported in DLR’s Table 3 for restaurant employment. These specifications exclude the private-sector
employment control, although DLR include this control in the specifications on which their Figure 4 is
based. Standard errors are clustered at the state level. ***, **, and * indicate estimates that are statistically
different from zero at the one-, five-, and ten-percent levels, respectively.

Table 9: The Effects of the Minimum Wage on Restaurant Employment, “Falsification Tests”

(1)

(2)

(3)

Dependent variable: Log (restaurant employment)

DLR sample: 1990:Q12006:Q2 (Table B1,
specification 2)

Sample restricted to
1998:Q3-2006:Q2
(period with no
federal MW
changes)

Sample restricted to
1998:Q3-2006:Q2,
county pairs with
minimum wage
difference for at least one
quarter

Log(MW)

-0.208
(0.150)

-0.247***
(0.042)

-0.260**
(0.097)

N

34,514

21,308

5,180

Log(MW)

-0.123
(0.158)

-0.107
(0.068)

0.005
(0.082)

N

33,726

20,768

4,640

% of county pairquarter observations
with minimum wage
difference between
counties

4.0

7.0

31.2

% of county pairs with
minimum wage
difference between
counties in sample
period

17.8

22.3

100.0

County effects

Yes

Yes

Yes

Period effects

Yes

Yes

Yes

Actual MW sample:

Placebo MW sample:

These specifications include controls for population and private-sector employment. Following DLR’s code,
the sample is restricted to counties that have an area less than 2,000 square miles. In columns (2) and (3), a
balanced panel of counties is used, as in DLR’s other analyses; some counties that are not included in column
(1) can be included in the samples in these columns. In column (3), the subset of county pairs in column (2)
that had one or more minimum wage differences in the period always had at least two quarters of minimum
wage differences. Standard errors are clustered at the state level. ***, **, and * indicate estimates that are
statistically different from zero at the one-, five-, and ten-percent levels, respectively.

Table 10: The Effects of the Minimum Wage on Teen (16-19) Employment, Matched Panel Data Estimates, 1990 – 2011:Q2

(1)

(2)

(3)

(4)

(5)

(6)

Dependent variable: Log (Employment/Population)
Matched panel data estimator, treatment state and experiment fixed effects

Standard
panel data
estimator

129 “clean”
minimum wage
increases, all
states in donor
pool as controls,
equally weighted

All minimum
wage increases,
all states as
controls,
equally
weighted

All minimum
wage increases,
same-division
states as
controls,
equally
weighted

Log(MW)

-0.165***
(0.041)

-0.035
(0.113)

-0.199*
(0.106)

-0.123
(0.092)

-0.295***
(0.101)

-0.281***
(0.097)

Unemployment rate

-4.195***
(0.427)

-1.925**
(0.866)

-1.831***
(0.508)

-0.762
(0.466)

-1.394***
(0.454)

-1.357***
(0.446)

0.100
(0.316)

-0.929
(0.957)

0.424
(0.515)

0.347
(0.461)

0.075
(0.448)

0.001
(0.449)

Number of minimum
wage increases

544

129

502

502

502

502

N

4386

1290

5020

5020

5020

5020

Relative size of
youth population

All minimum wage
increases, synthetic
control weights
based on residuals
including minimum
wage

All minimum wage
increases, synthetic
control weights
based on residuals
excluding minimum
wage

The estimates in column (1) are standard panel data estimates with fixed state and period effects, corresponding to those in column (1) of Table 1. The
remaining estimates use treatment observations for the quarter of a minimum wage increase and four previous quarters, and matched counterfactual
observations as described in Section IV. All specifications beginning with column (2) include dummy variables corresponding to each minimum wage
“experiment” (i.e., the matched treatment and counterfactual observations for each minimum wage increase) and each set of treatment observations in each
experiment. In columns (3) and higher, minimum wage increases in 42 states in 1990:Q2 are excluded because there are not four quarters of observations
available before these increases. Standard errors are clustered at the level of the treatment or counterfactual observations in each experiment.
Observations in columns (2)-(6) are weighted by the teen population in the treatment observations (similarly applied to corresponding counterfactual
observations). ***, **, and * indicate estimates that are statistically different from zero at the one-, five-, and ten-percent levels, respectively.

Table 11: The Effects of the Minimum Wage on Border County Restaurant Employment, Matched Panel Data Estimates, 1990 – 2006:Q2

(1)

(2)

(3)

(4)

(5)

(6)

Dependent variable: Log (Restaurant Employment/County Population)
Matched panel data estimator, treatment county and experiment fixed effects

Standard
panel data
estimator

Standard panel
data estimator,
paired border
counties only

Paired border
counties sample,
all minimum
wage increases,
all border
counties in other
states as
controls, equally
weighted

Paired border
counties
sample, all
minimum wage
increases,
paired border
counties as
controls,
equally
weighted

Paired border
counties sample, all
minimum wage
increases, synthetic
control weights
based on residuals
including minimum
wage

Paired border
counties sample, all
minimum wage
increases, synthetic
control weights
based on residuals
excluding minimum
wage

0.020
(0.028)

0.036
(0.026)

0.039
(0.029)

0.038
(0.029)

A. Unweighted, with private-sector employment control

Log(MW)

-0.174*
(0.100)

-0.080
(0.070)

B. Weighted by county population, with private-sector employment control

Log(MW)
N

-0.120***
(0.042)

-0.104**
(0.050)

0.008
(0.021)

0.001
(0.025)

-0.042*
(0.023)

-0.043*
(0.022)

90,948

25,146

19,200

19,200

19,200

19,200

The estimates in column (1) and (2)?are standard panel data estimates with fixed county and period effects. The remaining estimates use treatment
observations for the quarter of a minimum wage increase and four previous quarters, and matched counterfactual observations as described in Section IV.
All specifications beginning with column (3) include dummy variables corresponding to each minimum wage “experiment” (i.e., the matched treatment
and counterfactual observations for each minimum wage increase) and each set of treatment observations in each experiment. In columns (3) and higher,
minimum wage increases in 42 states in 1990:Q2 are excluded because there are not four quarters of observations available before these increases.
Standard errors are clustered at the level of the treatment or counterfactual observations in each experiment. In panel B, observations in columns (3)-(6)
are weighted by the county population in the treatment observations (similarly applied to corresponding counterfactual observations). ***, **, and *
indicate estimates that are statistically different from zero at the one-, five-, and ten-percent levels, respectively.

Table 12: The Effects of the Minimum Wage on Teen and Restaurant Employment, DLR’s Approach
Using Paired States

(1)

(2)

(3)

(4)

Dependent variable: Log
(Restaurant Employment/State
Population)

Dependent variable: Log
(Employment/Population) for
Teens (16-19)

QCEW 1990-2006:Q2

CPS 1990-2011:Q2

Without statepair × period
interactions
(DLR, Table 2,
specification 5)

Without statepair × period
interactions
(DLR, Table 2,
specification 5)

Without statepair × period
interactions
(DLR, Table 2,
specification 5)

With state-pair
× period
interactions
(DLR, Table 2,
specification 6)

-.079
(.067)

-.029
(.081)

-.231***
(.058)

-.236***
(.074)

-.095**
(.047)

.006
(.074)

-.168***
(.046)

-.162
(.113)

State effects

Yes

Yes

Yes

Yes

Period effects

Yes

No

Yes

No

State-pair × period
interactions

No

Yes

No

Yes

14,124

14,124

18,404

18,404

A. Unweighted
Log(MW)
B. Weighted
Log(MW)

N

Standard errors are two-way clustered at the (non-nested) state and state-pair levels. Columns (1) and (2)
control for private-sector employment. Columns (3) and (4) include controls for the unemployment rate and
the relative size of the youth population. In Panel B, observations in columns (1) and (1) are weighted by total
state population, while observations in columns (3) and (4) are weighted by the state teen population. ***, **,
and * indicate estimates that are statistically different from zero at the one-, five-, and ten-percent levels,
respectively.

Table 13: The Effects of the Minimum Wage on State Restaurant Employment, Matched Panel Data Estimates, 1990 – 2006:Q2

(1)

(2)

(3)

(4)

(5)

Dependent variable: Log (Restaurant Employment/County Population)
Matched panel data estimator, treatment state and experiment fixed effects

Standard
panel data
estimator

All minimum
wage increases, all
states as controls,
equally weighted

All minimum wage
increases, paired
states as controls,
equally weighted

All minimum wage
increases, synthetic
control weights
based on residuals
including minimum
wage

All minimum wage
increases, synthetic
control weights
based on residuals
excluding minimum
wage

0.036
(0.035)

0.040
(0.037)

0.040
(0.037)

A. Unweighted, with private-sector employment control
Log(MW)

-0.120*
(0.067)

0.011
(0.035)

B. Weighted by county population, with private-sector employment control
Log(MW)
N

-0.128***
(0.045)

-0.035
(0.028)

-0.033
(0.028)

-0.060**
(0.025)

-0.052**
(0.024)

3,234

2,580

2,580

2,580

2,580

The estimates in column (1) are standard panel data estimates with fixed state and period effects. The remaining estimates use treatment
observations for the quarter of a minimum wage increase and four previous quarters, and matched counterfactual observations as described in
Section IV. All specifications beginning with column (2) include dummy variables corresponding to each minimum wage “experiment” (i.e.,
the matched treatment and counterfactual observations for each minimum wage increase) and each set of treatment observations in each
experiment. In columns (2) and higher, minimum wage increases in 42 states in 1990:Q2 are excluded because there are not four quarters of
observations available before these increases. Standard errors are clustered at the level of the treatment or counterfactual observations in each
experiment. In panel B, observations in columns (3)-(6) are weighted by the state population in the treatment observations (similarly applied to
corresponding counterfactual observations). Alaska and Hawaii are omitted except as potential controls (which they cannot be in column (3)).
***, **, and * indicate estimates that are statistically different from zero at the one-, five-, and ten-percent levels, respectively.

