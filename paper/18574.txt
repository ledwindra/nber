NBER WORKING PAPER SERIES

FREE TO CHOOSE? REFORM AND DEMAND RESPONSE IN THE ENGLISH
NATIONAL HEALTH SERVICE
Martin Gaynor
Carol Propper
Stephan Seiler
Working Paper 18574
http://www.nber.org/papers/w18574

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2012

We are grateful to the UK Department of Health for financial support. No endorsement by the Department
of Health is intended or implied. Thanks are due for helpful comments to participants at seminars at
a number of universities and conferences. Any errors and all opinions are the responsibility of the
authors alone. The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w18574.ack
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2012 by Martin Gaynor, Carol Propper, and Stephan Seiler. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.

Free to Choose? Reform and Demand Response in the English National Health Service
Martin Gaynor, Carol Propper, and Stephan Seiler
NBER Working Paper No. 18574
November 2012
JEL No. D12,I11,I18,L13,L30
ABSTRACT
The impacts of choice in public services are controversial. We exploit a reform in the English National
Health Service to assess the impact of relaxing constraints on patient choice. We estimate a demand
model to evaluate whether increased choice increased demand elasticity faced by hospitals with regard
to clinical quality and waiting time for an important surgical procedure. We find substantial impacts
of the removal of restrictions. Patients became more responsive to clinical quality. Sicker patients
and better informed patients were more affected. We leverage our model to calculate potential benefits.
We find increased demand responsiveness led to a significant reduction in mortality and an increase
in patient welfare. The elasticity of demand faced by hospitals increased post-reform, giving hospitals
potentially large incentives to improve their quality of care and find suggestive evidence that hospitals
responded strongly to the enhanced incentives due to increased demand elasticity. The results suggests
greater choice can enhance quality.

Martin Gaynor
Heinz College
Carnegie Mellon University
4800 Forbes Avenue, Room 3008
Pittsburgh, PA 15213-3890
and NBER
mgaynor@cmu.edu
Carol Propper
Imperial College Business School
South Kensington Campus
London SW7 2AZ, United Kingdom
and University of Bristol
carol.propper@bristol.ac.uk

Stephan Seiler
Stanford GSB
Knight Management Center
655 Knight Way
Stanford, CA 94305
sseiler@stanford.edu

1

Introduction

Governments facing fiscal pressure have increasingly turned to proposals to create or enhance consumer choice
for public services (see, e.g., Besley and Ghatak 2003, Blöchliger 2008, Hoxby 2003, Le Grand 2003). In health
care, choice is a popular reform model adopted by administrations of different political orientations in many
countries, including the US, the UK, Denmark, Italy (Lombardy), the Netherlands, Germany and Sweden. The
belief is that by increasing choice for patients, providers of care or insurers will become more responsive to
patient demand which, in turn, will drive greater efficiency in the delivery and funding of health care. These
reforms have been controversial, in part due to concerns about adverse impacts on patients’ health in general,
and inequitable impacts on low income individuals specifically. Whether enhanced patient choice will make
hospital choice more responsive to quality is not well established. Consumers may be deterred from exercising
choice due to lack of information about medical care providers, because the measures produced to help consumers
choose may be noisy and difficult to interpret for consumers, or simply because consumers do not value quality
in health care. The consequences of poor quality in health care can be dire. Patients’ health can be severely
compromised by poor quality care, including, as we show below, an increased risk of death. Thus there is a need
to understand the responses of health care consumers when they are offered more choice.
This is exactly the research question we address in this paper: we quantify changes in the elasticity of
demand with respect to quality of service when patients are offered more choice. Furthermore, we analyze how
the changes in patients’ choices translate into changes in the competitive environment hospitals are facing. To
answer these questions we exploit a reform which introduced patient choice in the English National Health
Service (NHS). Beginning in January 2006, the reform mandated that patients in the NHS had to be offered a
choice of 5 hospitals when referred by their physician to a hospital for treatment. At the same time removal of
selective contracting allowed the referring physician flexibility in the choice of hospital for the patients treatment.
Finally, patients and physicians were provided with greater information about hospitals, primarily through a
webpage containing easily accessible performance information across hospitals. Together these three factors
changed the way referrals were made by removing institutional and informational constraints on the patients’
ability to choose between hospitals. The reform thus provides us with exogenous variation in the ability to
exercise choice over time and as the choice set of hospitals is almost constant around the introduction of the
choice reform, it allows us to cleanly identify the impact of choice while holding the underlying market structure
fixed.
We propose a hospital choice function to estimate the elasticity of demand with respect to various dimensions
of hospital service pre- and post-reform. While we show the qualitative change in referral patterns using a simple
reduced-form approach, the focus of the paper is on a structural model of demand. The structure helps us to
aggregate patient-level estimates to the hospital-level as well as quantify the impact of the reform along various
1

dimensions. In the NHS patients face zero price at point of use, therefore quality of service, waiting times, and
distance serve to allocate patients among hospitals in the absence of a price mechanism. We estimate our model
using choice data for Coronary Artery Bypass Graft (CABG) surgery. We find that the reform had a significant
impact on patients’ elasticity of demand with respect to the quality of service (captured by a mortality rate
that we adjust for differences in patient case-mix across hospitals).1 We also find substantial heterogeneity in
the impact of the reform on responsiveness to quality. Sicker patients react more strongly to the reform as well
as patients that were likely to know about the ability to exercise choice. Interestingly, lower income groups
did not benefit less than the average patient, which was a widespread concern when the pro-choice policy was
introduced. The reform had no significant impact on the elasticity of demand with respect to waiting times for
most patients.
Using the estimates from the choice model we estimate that 10 more patients per year would have survived
their CABG surgery (a 3 percent decline in mortality) had patients had free choice in the pre-reform period
(i.e., had demand been as elastic with respect to quality pre-reform as it was post-reform). When we aggregate
patient-level elasticities to the hospital level, our simulation shows that the competitive environment changed
substantially. For the average hospital an increase in mortality by one standard deviation led to a 5 percent
larger drop in market share post- compared to pre-reform. This lends support to the notion that hospitals did
have stronger incentives to improve quality due to the introduction of patient choice.
Analyzing hospital choice is a challenging task for two reasons. First, finding an appropriate measure of
quality is difficult, as health outcomes are affected by patients selecting into hospitals based on their health
status. Second, unobserved hospital quality will influence aggregate demand, which in turn has an impact on
waiting times, creating an endogeneity problem.2 To address the first concern, we introduce an appropriate
measure of quality by explicitly estimating the causal effect of visiting a particular hospital on patient survival.
To this end we estimate a model of health outcome (i.e. patient survival) conditional on visiting a certain
hospital. We use an instrumental variables approach to deal with the issue of patients selecting into hospitals,
following Gowrisankaran and Town (1999) and Geweke, Gowrisankaran, and Town (2003). In this way we
are able to back out a measure of hospital mortality that is not contaminated by patient selection, i.e. casemix. The estimated quality measure is then used as a hospital characteristic in the demand model. To deal
with the possible endogeneity of waiting times, we control for unobserved heterogeneity in a very flexible way.
Specifically, in a first stage we estimate a large set of hospital and time-period specific fixed effects. This enables
us to rigorously control for the effect of unobserved hospital quality and to recover parameters that are identified
by patient-level variation. In a second stage we recover the average effects of the key parameters by projecting
the recovered hospital/time-period fixed effects on hospital characteristics (see Goolsbee and Petrin 2004, for
1 Throughout
2 Note

the paper we will use the terms quality of service and case-mix adjusted mortality rate interchangeably.
that price endogeneity is not an issue in the UK setting, since health care is free at the point of service under the NHS.

2

a similar approach). Relative to other papers that analyze the impact of more choice/stronger competition
on health outcomes,3 we analyze choice more directly by structurally estimating the elasticity of demand with
respect to two key dimensions of hospital service, waiting times and mortality rates. We thereby contribute to
a growing literature analyzing consumer choice in health care markets such as Luft, Garnick, Mark, Peltzman,
Phibbs, Lichtenberg, and McPhee (1990), Tay (2003) and Howard (2005) for the US and Sivey (2008), Beckert,
Christensen, and Collyer (2012), Varkevisser, van der Geest, and Schut (2012) and Moscone, Tosetti, and
Vittadini (2012) for Europe.
The paper is structured as follows. Section 2 describes the model, Section 3 explains the institutional
background, Section 4 describes the data we use, followed by some reduced-form evidence in Section 5. Section
6 presents econometric issues and estimation methods and Section 7 presents the results, including parameter
estimates and elasticities. Section 8 presents the results of some policy analyses using our estimates. The final
section contains concluding remarks.

2

Modeling Approach

We discuss CABG surgery and the institutional setting in Section 3. Here we lay out our framework for analyzing
the impact of the reforms on hospital demand. But before presenting this we need to note three key features
of the institional set-up. First, patients and physicians jointly choose the the hospital for the patient’s surgical
treatment. The physician makes this referral based on their information set and their clinial judgement. This
is standard in a medical setting where the role of the physician is to act as the patient’s agent and to provide
advice on appropriate treatment. Second, in the UK physicians are salaried, therefore the referring physician
does not benefit financially from the referral decision. In fact, a poor clinical choice may have a negative impact
on utility, in terms of loss of reputation and possibly increased workload with no increased financial payment.
Third, the patient incurs no financial cost for medical treatment. This means that the choice of hospital is the
decision of both the patient and the physician but separately identifying patient and physician preferences is not
possible here (as is the case for the health demand literature in general). This is not an issue in evaluating the
impact of the reform on hospital choice and for ease of exposition we maintain the standard terminology and
refer to patient utility and preferences when describing the model.
There are two key ingredients to this model: (1) a model of patient choice as a function of hospital characteristics/dimensions of service, and (2) a hospital-level production function for the quality of clinical care. The
key focus of the paper is the choice model which allows us to pin down how sensitive patients’ decisions are to
different dimensions of service. One of these is the quality of care at the hospital which we compute using a
model for the production of clinical quality. We describe the choice model first.
3 See Kessler and McClellan (2000) for evidence from the US Medicare program and Gaynor, Moreno-Serra, and Propper (2010)
and Cooper, Gibbons, Jones, and McGuire (2011) for evidence from the English NHS.

3

2.1

Choice Model

Consumers choose between hospitals based on their utility from this choice. Price in the NHS is zero for the
consumer, so indirect utility is only a function of patient and hospital characteristics. The key factors which are
likely to affect hospital choice are the quality of care, the amount of time a patient has to wait for surgery and
patient distance from the hospital. We allow for preference heterogeneity across different patient demographics
as well as unobserved heterogeneity in preferences over hospital characteristics. We assume that all people
who require a CABG are sick enough that they get one (after a wait). As a consequence, there is no outside
good. Finally, in order to capture effects of loosening of choice constraints due to the reform, we allow patients’
responsiveness to hospital characteristics to differ pre- and post-reform.
Let a patient i choose between hospitals j in time period t (defined as a quarter) based on the following
indirect utility function,
Vijt = βw,it Wjt + βz,it Zjt + f (Dij ) + ξjt + εijt

(1)

where Wjt denotes the average waiting time for a CABG in time period t at hospital j, Zjt denotes the quality
of clinical care at the hospital, and Dij is the distance from patient i’s location to the location of hospital j. The
function f (Dij ) is a transformation of Dij that reflects the (non-linear) preference for distance to the hospital.
ξjt denotes unobserved hospital quality and εijt is an idiosyncratic shock that is iid extreme value.
To allow the impact of quality of care to differ across patients as well as before and after the reform let the
parameter βz,it be defined as follows,

βz,it

=

[β z,0 + βz,0 Xi + σz,0 vz,i ] · 1(t = 0)

(2)

+[β z,1 + βz,1 Xit + σz,1 vz,i ] · 1(t = 1).

where (t = 0) denotes the pre-reform time period, (t = 1) denotes the time period after the reform, and 1(t)
is an indicator function. β z,t denotes the average effect across consumers of quality of care on patient utility
in period t. Xi is a vector of observable patient demographics and βz,t is a vector of coefficients that capture
differences from the average effect across consumers (implemented as various demographic groups). Finally, σz,t
captures unobserved heterogeneity in preferences for clinical quality across patients. It is the standard deviation
2
of a normal distribution with mean zero and variance σz,t
. In our specific context, patient health status (which

is only partially observable) will most likely affect preferences over the quality of care. The impact of unobserved
health status is therefore captured by the realization of vz,i . Note that we allow for different average effects preand post-reform as well as demographic specific deviations from the average effect pre- and post-reform. In other
words, we allow for overall (average) effects of the freeing of choice and for the freeing of choice to differentially
affect different demographic groups.
4

We capture the effect of the reform and consumer heterogeneity on the impact of waiting times on choice in
a similar fashion,

βw,it

=

[β w,0 + βw,0 Xi + σw,0 vw,i ] · 1(t = 0)

(3)

+[β w,1 + βw,1 Xi + σw,1 vw,i ] · 1(t = 1)

This allows us to rewrite the utility function in the following way,

uijt

=

δjt

(4)

+[βw,0 Xi · 1(t = 0) + βw,1 Xi · 1(t = 1)] · Wjt
+[σw,0 vw,i · 1(t = 0) + σw,1 vw,i · 1(t = 1)] · Wjt
+[βz,0 Xi · 1(t = 0) + βz,1 Xi · 1(t = 1)] · Zjt
+[σz,0 vz,i · 1(t = 0) + σz,1 vz,i · 1(t = 1)] · Zjt
+f (Dij ) + εijt

where δjt captures the effect of hospital characteristics on the average patient pre- and post-reform as well as
the unobserved quality term

δjt

=

[β w,0 · 1(t = 0) + β w,1 · 1(t = 1)] · Wjt

(5)

+[β z,0 · 1(t = 0) + β z,1 · 1(t = 1)] · Zjt
+ξjt

A main concern that drives our choice of estimation method is the possible endogeneity of waiting times in
the utility function (1). Specifically, it is possible that unobservably better hospitals may have longer waiting
times because they attract more patients. By increasing aggregate demand, higher unobserved quality ξjt will
lead to longer waiting times for a given level of capacity, so Corr(Wjt , ξjt ) 6= 0, which implies that we will be
unable to obtain a consistent estimate of the effect of waiting times on hospital choice (βw,it ) without addressing
this issue.4 The issue is very similar to the endogeneity of the price coefficient commonly encountered in the
empirical IO literature. Products with higher unobserved quality will have greater demand, which in turn
leads to higher prices. An analogous mechanism will drive waiting times up in the fixed price (and capacity
constrained) environment of the English NHS. In other words, rationing through waiting times plays a similar
role to the price mechanism in other markets. This will lead to waiting times being positively correlated with
4 We

are less concerned with the endogeneity of Zjt due to the way in which we construct our measure for quality of care.

5

unobserved hospital quality.
In principle this endogeneity problem can be addressed either by using instrumental variables or by controlling
for unobserved heterogeneity via fixed effects to absorb the variation in ξjt . Since there is no obvious good
instrument for waiting times, we use a fixed effects approach.5 Specifically, we estimate a separate hospital fixed
effect for every quarter, represented by δjt in Equations (4) and (5). We therefore control more rigorously for
unobserved hospital quality than approaches that use only hospital (but not time period) specific fixed effects,
i.e. that assume ξjt = ξj for all t. We think that in our context, the assumption of time-invariant fixed effects is
less tenable than in other applications. This is due to the fact that we are analyzing the effect of a reform that
(in principle) could have led to hospitals improving along different dimensions of service. Any improvement on
the unobserved quality dimension would therefore violate an assumption that ξjt = ξj .
This greater degree of flexibility is costly for us in two ways: first, some parameters cannot be identified
when a full set of hospital-quarter fixed effects are included (as can be seen in equation (5)), and second, we
have to estimate a set of almost 300 fixed effects (for about 30 hospitals and 10 quarters) within a non-linear
model, which leads to a considerable increase in the computational burden. We provide details on how we deal
with both issues in the estimation section.

2.2

Production Function for the Clinical Quality of Care (Mortality)

The second component of our modeling strategy involves an empirical model of the hospital’s production of
clinical quality. In the case of CABG where there is a non-negligible risk of dying the patient’s chances of
survival are a primary dimension of quality. Therefore we focus on a “production function of patient survival.”
Here, in contrast to the demand model described above, we take a more reduced form approach to modeling the
production function. This is motivated by the fact that the main purpose of this production function estimation
is simply to deliver an appropriate measure of quality of care to use in the demand model.
Specifically, we specify a linear probability model of patient mortality in which we regress an indicator for
whether the patient died after the surgery (conditional on visiting hospital j) on patient characteristics and a
set of hospital/time period fixed effects. Let the mortality of patient i in period t at hospital j be determined
as follows,

M = JT ψ + H obs γobs + (H unobs γunobs + η)

(6)

where the last two terms in parenthesis denote two components of the econometric error term. M is a vector
of indicator variables. An entry corresponds to a particular patient i receiving a CABG in time period t and is
5 One could consider using waiting times for other procedures at the same hospital as instruments. However, it is likely that
unobserved quality is correlated across procedures. For instance, general hospital reputation might affect demand similarly across
procedures. In addition, NHS hospitals do not operate in multiple, widely dispersed locations. Therefore the common strategy of
using values of the endogenous variable from a distant market therefore is not available here.

6

equal to one if the patient died after receiving treatment in hospital j. JT is a matrix of hospital-time period
dummy variables and the ψ are a set of coefficients. As previously, we define a time period to be a quarter. H obs
is a matrix of patient (i.e. i-specific) characteristics that capture observable health status. H unobs represents
the patient’s unobserved (by the econometrician) health status. γobs is a vector of coefficients that captures
the impact of observed patient characteristics on the probability of death following the surgery, while γunobs
captures the impact of unobservable health status. η is a vector of iid normal error terms. The corresponding
expression for a specific observation is Mit (j) = ψjt + Hiobs γobs + Hiunobs γunobs + ηi .
We use this reduced-form production function regression to estimate the causal impact of visiting a particular
hospital on the patient’s probability of dying. However, simply estimating the relationship by OLS does not allow
us to uncover the true causal relationship. Hospital choice will likely be correlated with unobserved patient health
status, which will be subsumed in the empirical error term when estimating equation (6). More specifically, if
Corr(vz,i , Hiunobs ) 6= 0, then hospital choice will be endogenous. From the demand model described above, we
know that the patient-specific taste parameter vz,i will effect hospital choice, therefore any arbitrary column of
the hospital dummy matrix, JTijt will be a function of vz,i , and so Corr(JTijt (vz,i ), Hiunobs ) 6= 0.6
This endogeneity problem is very closely related to the fact that the hospital’s mortality rate is “contaminated” by differences in patient case-mix. Indeed, when running the above regression without any controls for
observed patient health status, the fitted hospital fixed effects ψb will be equal to the hospital-specific mortality
rates.7 The production function equation therefore recasts the issue of case-mix affecting the mortality rate as
an endogeneity problem.
To obtain the true causal effect of visiting a particular hospital on the survival probability we need to deal
with this endogeneity problem. We rely on the demand model to give us some guidance. In particular, we know
that distance affects hospital choice. Together with the additional assumption that distance is uncorrelated with
unobserved health status Corr(Dij , Hiunobs ) = 0, we can use distance (to each hospital) as an instrument for the
matrix of endogenous hospital dummies. This amounts to assuming that people do not choose where they live
relative to CABG hospitals based on their unobservable health status.8 We provide some supporting evidence
for this later in the paper. This IV approach is very closely related to Gowrisankaran and Town (1999) as well as
Geweke, Gowrisankaran, and Town (2003). Other papers in the health literature such as Luft, Garnick, Mark,
Peltzman, Phibbs, Lichtenberg, and McPhee (1990), Howard (2005), and Tay (2003) use the difference between
expected and observed mortality, where expected mortality is computed based on observed patient case-mix.
write JTijt to denote the entry in column i and row jt of the JT matrix, i.e. the realization of a certain hospital-time period
dummy for patient i.
7 In a linear regression model without a constant the fixed effects are equal to the hospital-specific means of the dependent
variable Mit (j). The average of Mit (j) for a particular hospital j (and time-period t) is therefore simply equal to the number of
death divided by the total number of admissions, i.e. the mortality rate.
8 This assumption is universally employed in estimating models of hospital choice, e.g., Kessler and McClellan (2000),
Gowrisankaran and Town (1999), Capps, Dranove, and Satterthwaite (2003), Gaynor and Vogt (2003), Ho (2009), Beckert, Christensen, and Collyer (2012).
6 We

7

Our IV approach goes further than this and also deals with selection based on unobserved health status. Note
also, that our approach uses distances to all hospitals as instruments and is therefore more flexible than the
differential distance IV approach used elsewhere.9
Having recovered the causal impact of visiting hospital j on the patient’s chances of survival we use this set
of estimated fixed effects in order to capture hospital quality of care in the demand model. We will refer to these
effects as case-mix adjusted mortality rates. This constitutes a slight abuse of terminology as the fixed effects
do not constitute mortality probabilities but rather the hospital’s impact on mortality conditional on observed
case-mix.

3

Institutional Details

3.1

CABG: Medical Background

A coronary artery bypass graft (CABG) is a surgical procedure widely used to treat coronary heart disease. It
is used for people with severe angina (chest pain due to coronary heart disease) or who are at high risk of a
heart attack. It diverts blood around narrowed or clogged parts of the major arteries, to improve blood flow and
oxygen supply to the heart. It involves taking a blood vessel from another part of the body, usually the chest
or leg, and attaching it to the coronary artery above and below the narrowed area or blockage. This new blood
vessel, known as a graft, diverts the flow of blood around the part of the coronary artery that is narrowed or
blocked.10 Successful bypass surgery improves symptoms and lowers the risk of heart attack.
We focus on CABG for three reasons. First, it is a commonly performed procedure. About 13,500 patients
per year receive elective CABGs in England, making CABG one of the most frequently performed elective
treatments.11 The fact that it is commonly performed provides us with statistical power and means that CABG
is quantitatively important. Second, CABG is mostly performed on an elective, as opposed to an emergency,
basis. Therefore, patients can exercise choice among alternatives, which is not usually the case for emergency
treatments. Third, patients who receive heart bypass surgery are very sick, so CABG is among the most risky
elective treatments and mortality is a fairly common outcome.12 The relatively high frequency of death means
mortality is a reliable and easily observed measure of quality. Other dimensions of quality which characterize
other medical procedures are harder to observe and may be less reliably recorded.
Patients in the NHS who present with symptoms of coronary artery disease or angina are referred to a
cardiologist who will perform tests and may perform a non surgical procedure to unblock the artery (angioplasty
9 More

details on the estimation of the IV-regression is provided in the appendix.

10 http://www.nhs.uk/Conditions/Coronary-artery-bypass/Pages/Introduction.aspx
11 In the US the number is 415,000, making CABG one of the top 10 most common non-obstetric surgical procedures (National
Hospital Discharge Survey 2010, http://www.cdc.gov/nchs/nhds/nhds_products.htm).
12 Other procedures commonly used in the health economics literature, such as AMI (acute myocardial infarction) treatment have
higher mortality rates, but are primarily emergency treatments. They are therefore not directly relevant for an analysis of patient
choice.

8

or PCI). If this fails the patient then will be referred for a CABG to be performed by a cardiac surgeon and
put on an elective waiting list for this treatment. The referral is typically made by the cardiologist but in some
cases may be made by the patient’s primary care physician (the General Practitioner). Cardiologists operate in
almost all short term general NHS hospitals but CABGs are performed only at a limited number of hospitals.

3.2

The Choice Reform

In the UK health care is tax financed and free at the point of use. Almost all care is provided by the National
Health Service. Primary care is provided in the community by publicly funded physicians known as General
Practitioners (GPs). Patients have little choice of GP.13 These GPs also act as gatekeepers for hospital-based
(known as secondary) care.14 Secondary care (e.g., cardiology, cardiac surgery) is provided in publicly funded
(NHS) hospitals. NHS hospitals are free standing public organizations (known as NHS Trusts). In these hospitals,
the physicians are salaried employees and generally employed only in a single NHS hospital. Publicly funded
bodies covering specific geographic areas, called Primary Care Trusts (PCTs), have the task of buying hospitalbased health care for their population.
In the pre-reform period, buyers (PCTs) and sellers (the NHS Trusts) negotiated over price, service quality
(but mainly waiting times and not clinical outcomes) and volume on an annual basis. The majority of contracts
were annual bulk-purchasing contracts between the buyers and a limited number of sellers. Patients requiring
secondary care were generally referred by their GPs to the local hospital that provided the service they required
and were not offered choice over which hospital they went to. Instead the hospital to which a patient was sent
was determined by the selective contracting arrangements negotiated by the PCTs.
In late 2002 the government initiated a reform package to bring about hospital competition from 2006
onwards. There were several elements to this policy. After January 2006 patients had to be offered a choice
of five providers for their hospital care (Farrar, Sussex, Yi, Sutton, Chalkley, Scott, and Ma 2007, Gaynor,
Moreno-Serra, and Propper 2010, Cooper, Gibbons, Jones, and McGuire 2011), and GPs were required (and
paid) to ensure that patients were made aware of, and offered, choice.15
There were two other pieces in the reform package to facilitate choice. First, the government introduced a new
information system that enabled paperless referrals and appointment bookings and provided information on the
different dimensions of service (waiting times and some measures of clinical quality) to help patients make more
informed choices. This system, known as “Choose and Book,” allows patients to book hospital appointments
online, with their GP, or by telephone. The booking interface gave the person booking the appointment the
13 Patients

almost always have to choose a GP located near where to they live and practices can choose not to accept new patients.
do not practice in hospitals and therefore have no equivalent of admission rights.
15 The mandated choice was actually for the hospital in which the patient was initially referred to a specialist. In practice, this
generally meant choice of hospital in which treatment took place. In the case of specialised treatments which are not provided in
all hospitals (including CABGs), the patient would then be referred by the hospital specialist to another hospital for some or all of
their treatment.
14 GPs

9

ability to search for hospitals based on geographic distance and to see estimates of each hospital’s waiting
time. From 2007 the government also introduced a website designed to provide further information to help
patients’ choices. This included information collected by the national hospital accreditation bodies, such as riskadjusted mortality rates and detailed information on waiting times, infection rates and hospital activity rates
for particular procedures, as well as information on hospital accessibility, general visiting hours and parking
arrangements (http://www.chooseandbook.nhs.uk/). Thus, patients and their GPs had greater information
on which to make these choices.
Second, from 2006 onwards the NHS adopted a payment system in which hospitals were paid fixed, regulated,
prices for treating patients (a regulated price system that is similar to the Medicare hospital payment system
in the US). This fixed price system covered around 70% of hospital services including CABG.16 This change
in the remuneration system meant that GPs (and hospital specialists making referrals for treatment at to a
hospital other than their own) were no longer restricted in these referral decisions by their PCT’s contractual
arrangements with individual hospitals.
In summary, restrictions on both physicians and patients were removed in order to make referral decisions
more flexible. At the same time all parties were provided with additional information in order to help them in
the decision making process. While a well-informed patient with a strong preference might have been able to
convince the physician to refer her to a specific hospital pre-reform, the effect of the reforms was to make such
choice available and far more explicit for all patients.
In the particular case of CABG, which is a specialised treatment provided at only a few hospitals, the
reforms allowed the patient to choose the intitial hospital at which they saw a cardiologist and allowed that
cardiologist freedom in choice of where they sent patients for a CABG. This choice would have been based on
clinical assessment of what was the best for the patient. The reforms did not change finanical incentives for
the cardiologist (or the patient) in this referral decision as both pre- and post-reform, cardiologists received no
payment for their referral decision and patients do not pay for their medical care.
In terms of timing, the reform did not happen in a discrete way on a certain date for cardiac care. There
were two distinct trial/phase-in periods which we need to take into account when defining the pre- and postreform dates. The 2006 choice reform was preceded by a choice pilot for cardiac patients who were experiencing
particularly long waiting times (over 6 months). Between July 2002 and November 2003 such patients were
allowed to change their provider to get treatment earlier. Since we do not observe which patients were actually
offered the choice to switch providers, it is difficult to analyze this situation explicitly. At the same time, because
patients eligible for this scheme had to have waited for a minimum of six months, this situation is quite different
16 The reforms also promoted use of (mainly) new private providers of care. However, use of these was very limited and accounted
for less than 1% of all NHS care during the period in which we analyse. The main services purchased in the private sector were simple
elective services (primarily hip and knee replacements and cataract removal) rather than complex interventions such as CABG or
cardiac care more generally.

10

from the full choice reform (in which choice was mandated at the point of the referral) as well as from the
situation of no-choice pre-reform. Second, choice was first introduced in a limited way in April 2005 and only
fully rolled out in January 2006. In the introductory period, choice between only 2 hospitals was offered to
patients and decisions were taken locally as to which choice to offer. In order to keep our analysis as clean
as possible we therefore exclude both of these phase-ins of the reform from our analysis. We also allow for
some time (one year) for the reform to settle in and therefore use only data from January 2007 onwards when
analyzing the post-reform time period. These restrictions mean we use the period January 2004 to March 2005
as the pre-reform period and January 2007 to March 2008 as the post-reform period.

3.3

Market Structure

In contrast to many other procedures, CABGs are only offered by a small set of hospitals. Of around 160 short
term general (acute) public hospitals within the NHS just under 30 hospitals offer bypass operations.17 There
was almost no change in market structure around the time of the policy reform.18 The choice set faced by patients
is therefore very similar before and after the reform which allows us to separate the impact of greater choice
from a possible change in market concentration.19 Figure 1 provides a map of locations of CABG-performing
hospitals.
In our econometric modeling, we do not impose a particular geographic market a priori. Post-reform, physicians can refer to any hospital in England that performs CABG. Pre-reform, choice was constrained by selective
contracting but the actual provider used might have been some distance from the patient since few hospitals
provided CABG surgery. We do not know which hospitals were contracted with by each PCT and cannot infer
this from the data. Furthermore, we cannot be sure that the contractual constraints were always binding for
every individual referral. We see that a non-negligible fraction of patients travel a substantial distance in order to
receive treatment even before the introduction of choice. Both pre- and post-reform about 20 percent of patients
traveled more than 50km and 10 percent traveled further than 70km. A small set of patients traveled several
hundred kilometers in both time periods. We do not, therefore, restrict patients’ choices ex ante by imposing
a geographic market but simply allow patients to choose any CABG hospital in England, while controlling for
the impact of distance on choice in a flexible way. Thus we allow the data to tell us where patients want to go
rather than imposing a priori restrictions on choice. Finally, while in principle patients could choose privately
17 These hospitals differ from the average short term general hospital. Two-thirds are teaching hospitals (compared to 15 percent
for all hospitals) and are also are substantially larger, with about 50 percent more yearly admissions across all departments and 80
percent more medical staff than other short term general hospitals in the NHS.
18 The only changes are: (i) the merger of Hammersmith Hospital and St. Mary’s Hospital that became part of Imperial College
Healthcare NHS Trust in 2007, (ii) the opening of the Essex Cardiothoracic Centre at Basildon and Thurrock University Hospitals
in July 2007, and (iii) Royal Wolverhampton Hospital started performing a significant number of CABGs only in the second half of
2004 and is therefore excluded from the choice set before that.
19 Our demand estimation is capable of handling hospital entry and exit but the stable market structure means we isolate the
effect of the change in choice without any potential contamination from change in market structure.

11

funded treatment, in practice they did not.20 For this reason we do not include an outside option in the model
(this is standard in the health care demand literature).

4

Data and Descriptive Statistics

We use data from the UK Department of Health’s Hospital Episode Statistics (HES) dataset, which is a standard
administrative discharge dataset on every English NHS health episode.Overall, HES data contain approximately
13 million inpatient discharges per year at around 240 hospitals per year. The data contain details of the medical
procedures which the patient received (classified according to OPCS codes21 ) and up to 14 diagnoses, classified
according to the ICD-10 classification.22 We have data on the universe of inpatient discharges receiving CABG
surgery from every hospital in the NHS in England from April 2003 to March 2008, which corresponds to the
UK financial years 2003 to 2007. About 25% of all CABGs are performed as part of an emergency treatment and
are excluded from the main analysis. This gives us approximately 13,500 elective CABG discharges performed
at 29 hospitals per year. As explained earlier (Section 3.2) we define January 2004 until March 2005 as the
pre-reform time period and January 2007 to March 2008 as the post-reform time period and therefore do use
only a smaller time-window for our main estimation.
HES contains information on the postal code of the neighborhood in which the patient lives and patient
characteristics such as age, sex, and co-morbidities.23 At the patient-level we observe the time elapsed between
the referral and the actual treatment, i.e. the patient’s waiting time. We also observe whether the patient died
(in the hospital) within 30 days of the treatment. We can therefore compute CABG-specific waiting times and
mortality rates by aggregating the data at the hospital level (over a suitable time period). Finally, from the
hospital location and the patient’s postal code, we can compute the distance to the hospital.
We provide a detailed list of sources for the data used in this paper in Table B in the appendix.

4.1

Hospital Characteristics

In Table 1 we report descriptive statistics for hospitals by (financial) year over the period 2003 - 2007. The
average hospital treated about 500 CABG patients per year, but there is substantial variation in admission rates
between hospitals. The number of admissions decreases slightly over time as does the variance across hospitals.24
20 During our study period four private providers of CABG surgery operated (all located in London). However, the cost of CABG
surgery is such that any patients who might choose to use a private provider would have to have purchased private insurance before
they were diagnosed with a heart problem. The four private providers only performed a very small number of CABGs compared
to public hospitals (for example, only 67 CABG proceedures were undertaken in the four private hospitals in 2007). Therefore, we
think that our data captures the full choice set of patients.
21 OPCS is a procedural classification for the coding of operations, procedures and interventions performed in the NHS. It is
comparable to the CPT codes used for procedural classification in the US.
22 These are the 10th version of the International Classification of Disease (ICD) codes and are the standard codes used internationally for diagnoses.
23 Co-morbidities are additional diagnoses associated with greater sickness, for example, a CABG patient who is also a diabetic.
24 The total number of CABGs in the UK undertaken in our time period fell due to the increased use of angioplasty (PCI).

12

Waiting times fell dramatically over the period. In 2003 and 2004 they were quite long, with averages over 100
days. They decreased substantially in 2005 due to a government policy enforcing waiting time targets (see
Propper, Sutton, Whitnall, and Windmeijer 2008).25 There is considerable variation in waiting times between
hospitals, although somewhat less after 2005. The average mortality rate is approximately 1.9 percent for most
years with a slight decline towards the end of the sample period. There is substantial variation in mortality
rates across hospitals in all years. We also report an adjusted mortality rate which is purged of differences across
hospitals and over time in patients’ severity of illness (case-mix).26 Similar to the raw rate, we can observe a
(slightly stronger) downward trend over time. It is worth noting that the adjusted mortality rate shows a larger
between hospital variance, which is consistent with the notion that better hospitals attract sicker patients (i.e.,
a worse case-mix). Since sicker patients go to better hospitals, this selection effect will compress the distribution
of the raw mortality rate relative to the case-mix adjusted one.
When using the (case-mix adjusted) mortality rate and waiting times in the demand estimation, we aggregate
the patient-level data to the hospital-quarter level. This provides us with variation over time as well as across
hospitals. Using January 2004 until March 2005 as the pre-reform time period and January 2007 to March 2008
as the post-reform time period, we exploit 10 quarters of data, 5 in the pre- and 5 in the post-reform time-period.
Descriptive statistics of the quarterly variation for this time period are reported in Table 2.

4.2

Patient and Area Characteristics

We can determine the neighborhood of the patient, using the patient’s postal code to merge data. We define
the neighborhood as a small area containing around 7,000 individuals (the MSOA).27 We measure patient socioeconomic status as the (negative of) the Index of Multiple Deprivation (IMD). The IMD is a measure of income
deprivation of the patient’s neighborhood and is the best available metric on patient income in our data. This
variable ranks a patient’s local neighborhood from richest to poorest. The range is 0 to 1, with higher values
implying higher deprivation.28 Going forward, we simply refer to this variable as “income.” Also at a local
level, we have data on how well informed patients are about choice of NHS provider. From an NHS patient
satisfaction survey,29 reported at the PCT level, we observe the proportion of patients (of the interviewed
sample) who responded positively to a question as to whether they were offered a choice of hospital at the point
25 Note that the drop in waiting times was primarily due to efficiency improvement and did not have any detrimental effect on
health outcomes (see Propper, Sutton, Whitnall, and Windmeijer 2008).
26 See Section 6.1 for details on the adjustment.
27 The neighborhood is the Middle Layer Super Output Area (MSOA). These are generally smaller in population than US zip
codes. MSOAs are defined to ensure maximum homogeneity of population type. In England each of the 6,780 MSOAs has a
minimum population of 5,000 residents and had an average population of 7,200 residents in 2010. For more information see http://
neighborhood.statistics.gov.uk/dissemination/Info.do?page=userguide/moreaboutareas/furtherareas/further-areas.htm.
28 The IMD is computed by the government for each lower layer super output area (LSOA) in the UK. We aggregate from the
LSOA to the MSOA. Our data are from England only, which on average is richer than the rest of the UK. Effectively in England
the IMD varies over a small range, with most of the sample lying between 0.04 and 0.31 (the 10th and 90th percentile). For more
information, see http://www.communities.gov.uk/communities/research/indicesdeprivation/deprivation10/.
29 See http://www.dh.gov.uk/en/\&Publicationsandstatistics/Publications/PublicationsStatistics/DH_094013 for more
details.

13

of referral. While the question is not asked with respect to a specific procedure (such as CABG) but for any
referral for elective treatment we see no reason why information about choice should vary by procedure and we
think that this is a reasonable proxy for the likelihood that a CABG patient is informed about their possible
choices. Finally, HES provides the number of co-morbidities at the patient-level. For the purpose of estimation
we cap the co-morbidity count at 6, as hospitals differ in the maximum number of co-morbidities they report
and there are only a few cases with a co-morbidity count larger than 6.30
Table 3 presents descriptive statistics on the patient characteristics described above. As can be seen, most
patients are male and over 60 years of age. There is also considerable variation in patients’ general health status,
with a large fraction of patients for which several co-morbidities are reported. The mean value of the IMD is
relatively low, although there is a fair amount of variation. The average probability of being informed about
choice is about 50 percent, showing that not all physicians did offer choice as mandated by the reform. The
IMD, the (capped) co-morbidity count and the probability that the patient was informed about choice are all
used in the demand estimation to analyze how the reform differentially affected different groups of patients.
Table 4 contains descriptive statistics on the distances patients travel for their CABG treatments. We see
that the average patient traveled a substantial distance (over 30 kilometers) and that there is a great deal of
variation across patients in how far they traveled for care. It is also notable that there is very little difference in
any of the descriptives for distance between the pre- and post-reform time periods. Patients didn’t travel any
farther post-reform on average, nor were they more likely to bypass the closest hospital. This could occur if
patients sorted themselves to better hospitals post-reform within approximately the same distance. In the next
section we provide some reduced-form evidence that this is the most likely explanation for the lack of a change
in distance traveled.
Finally, we present some preliminary evidence that patients/physicians select hospitals based on patient
observed health status. Table 5 shows the results of a regression of hospitals’ case-mix adjusted mortality rates
on patients’ co-morbidity counts. Patients with a higher count, i.e. sicker patients, are significantly more likely
to get treated at a hospital with a lower mortality rate. This is very precisely estimated. The effects are
also economically important: on average, a patient with one additional co-morbidity goes to a hospital with
a mortality rate about 0.2 percentage points lower than the mean (1.9 percent).We think that the presence of
selection based on observable characteristics indicates that selection on unobservables is likely to also be an
important factor in our data. The latter is of importance to our demand model and the way we measure quality
in the estimation.
30 Up to 14 co-morbidities fields are available in the HES data set. We also examined the Charlson index, which is a measure of
morbidity for heart treatment. But since there is little variation in this variable, many patients having a value of zero, we do not
use it in estimation.

14

5

Reduced-Form Evidence

Before proceeding to our formal analysis, we look at patterns in the data to provide some simple empirical
evidence on whether patients became more responsive to the hospital mortality rates after the reform. We start
by running a simple linear regression of aggregate market shares on the case-mix adjusted mortality rate. We
aggregate the patient-level data to the hospital-quarter level31 and estimate separate OLS regressions for the
pre- and post-reform time periods. This allows us to examine the impact of the introduction of choice on the
responsiveness of market shares to the case-mix adjusted mortality rate. The results are reported in Table 6
in columns (1) and (2). These show that, pre-reform, higher quality hospitals did not have significantly larger
market shares. In the post-reform period, however, a lower mortality rate is significantly associated with a
higher market share. We replicate these regressions using (separate pre- and post-reform) hospital fixed effects
in columns (5) and (6) and find the same qualitative results. This provides some initial suggestive evidence that
the elasticity of demand with respect to quality rose due to the introduction of choice.
It is possible that this relation has nothing to do with choice but is an artifact of the distribution of market
shares and mortality rates, which are unrelated to the introduction of patient choice. We test this by implementing a placebo test in which we replicate the same regression as in columns (1) and (2) but use emergency CABG
cases instead of elective ones. Choice does not play a role for emergency admissions – patients are simply taken
to the nearest suitable facility. Therefore, if we see a change in the correlation of market shares with mortality
for emergency admissions it should not be due to the reform. Examining the results in Table 6, columns (3) and
(4), we see that hospital mortality rates have no statistically significant impacts on emergency CABG market
shares either pre- or post-reform. We replicate the analysis with a full set of hospital fixed effects and our results
are robust to this (columns (7) and (8)).
An alternative way of analyzing the issue of an increased sensitivity of demand is to look directly at the
expected (hospital-level) mortality rate that the average patient faces at the hospital of his choice. In Table 7 we
report the average mortality rate a patient faces pre- and post-reform (the top row in each of the two panels).
We find a substantial fall (about 20 percent for the raw mortality rate and about 13 percent for the case-mix
adjusted mortality rate). This fall might occur for a number of reasons. For example, it could be due to a secular
downward trend in the mortality rate across all hospitals, to hospitals in high population areas improving more
(so more patients are treated at better facilities without necessarily exercising choice), or to patients deliberately
choosing higher quality hospitals. To try to identify the impact of choice we report the change in the mortality
rate separately for patients that visited the nearest hospital and patients that bypassed the nearest hospital and
traveled further. If the drop in average mortality is simply due to an overall downward secular trend, we should
31 This allows us to illustrate some of the main patterns in the data in a simple OLS setup but we lose data on patient distance
to the hospital in this aggregation.

15

not see differences in mortality between patients who visited the nearest hospital and those who bypassed it.
Similarly, if the decrease in mortality is due to the fact that patients simply had better hospitals closer by after
the reform, we should see most of the drop explained by the group of patients that visited the nearest hospital.
Examining the patterns in Table 7 we find that the opposite is true. The drop in mortality among patients
bypassing the nearest hospital is more than twice as large as the drop for patients that visit the nearest hospital.
This is true both for raw and case-mix adjusted mortality rates. In other words, we observe larger declines in
mortality for patients that decide not to use their local hospital. Consistent with the results in Table (7), this
supports the idea that these patients were not simply lucky that the local hospital improved its quality but,
rather, that they started to deliberately seek out better hospitals once they were allowed a choice of provider.
These patterns in the data provide some initial evidence suggesting that the introduction of patient choice
via the reform increased the responsiveness of demand to cross-hospital differences in quality. We now analyze
patient choice in a structural demand framework.

6

Estimation Methods

To estimate both the choice model and the production function for quality of care we proceed sequentially. We
first estimate the production function relationship and then use the recovered quality measure in the demand
estimation. We relegate most of the description of how we recover the case-mix adjusted mortality rate to
appendix A and focus here on our main object of interest, the choice model.

6.1

Computing a Case-Mix Adjusted Mortality Measure: Estimation of the Production Function
for Clinical Quality

We construct a case-mix adjusted mortality rate by estimating equation ((6)):

M = JT ψ + H obs γobs + H unobs γunobs + η

where M is a vector of dummies which are switched on if the patient died. JT is a matrix of hospital-time
period dummy variables and H obs and H unobs represents the patient’s observed / unobserved health status. In
order to obtain the causal effect on the probability of death of visiting a particular hospital we need to instrument
the hospital dummies JT , which we do using distances to each hospital (Dij ). This regression provides us with
fitted values of the hospital-quarter fixed effects, ψbjt . Appendix A provides the details on the methods and
empirical results, including tests of the validity of our IV strategy. These give us confidence that we are able to
recover an appropriate measure of quality of service and that controlling for case-mix matters. In what follows,

16

the fitted values of the hospital-quarter dummies ψbjt are used as the quality of care measure in the utility
function, i.e. we set Zjt = ψbjt in equation (1).
6.2

Estimating the Choice Model

Having described the methods for estimating our empirical quality of care measure, the adjusted mortality rate,
we now turn to the estimation of the demand model. The primary concern that drives our empirical strategy is
the possible endogeneity of waiting times in the utility function (1) due to correlation with unobserved quality
(ξjt ).32
To deal with this concern, we control for the effect of unobserved quality by estimating a separate hospital
fixed effect for every quarter. This greater degree of flexibility is costly for us in two ways: 1) some parameters
cannot be identified when a full set of hospital-quarter fixed effects are included, and 2) we have to estimate
a set of almost 300 fixed effects (for about 30 hospitals and 10 quarters) within a non-linear model, which
leads to a considerable increase in the computational burden. To deal with the first issue, we employ a 2step estimation approach that allows us to recover further parameters in a second step (e.g., Goolsbee and
Petrin 2004). To deal with the latter concern we leverage a “BLP-style” contraction mapping (see Berry,
Levinsohn, and Pakes 1995) that allows us to concentrate out the vector of fixed effects. We therefore do not
have to engage in a computationally difficult non-linear search over the set of fixed effects. We elaborate on
both issues in what follows.

6.2.1

First Step: Estimating Effects with Heterogeneity and Fixed Effects

In the first step we estimate patient-specific parameters as well as a full set of hospital-quarter fixed effects based
on equation (4),

uijt

=

δjt
+[βw,0 Xi · 1(t = 0) + βw,1 Xi · 1(t = 1)] · Wjt
+[σw,0 vw,i · 1(t = 0) + σw,1 vw,i · 1(t = 1)] · Wjt
+[βz,0 Xi · 1(t = 0) + βz,1 Xi · 1(t = 1)] · Zjt
+[σz,0 vz,i · 1(t = 0) + σz,1 vz,i · 1(t = 1)] · Zjt
+f (Dij ) + εijt

32 One

might also be worried that unobservedly better hospitals attract different patients and this might lead to a correlation of
the quality of care (Zjt )with unobserved quality (ξjt ). However, due to the fact the our quality of care measure is unaffected by
case-mix this issue does not arise (it would however be an issue if we were using the raw mortality rate).

17

We allow distance to enter non-linearly into the utility function in a flexible way,

f (Dij )

=

αd1 Dij + αd2 (Dij )2 + αd3 (Dij )3
+αd4 Closestij + αd5 Closest10kij
+αd6 Closest20kij ,

where Closestij is a dummy equal to one if hospital j is the closest one in the choice set of patient i. The variable
Closest10kij is a dummy equal to one if the hospital is either the closest one or not more than 10 kilometers
further than the closest one. Closest20kij is defined in a similar way for a 20 kilometer radius. In what follows,
when we write out the utility function we continue to use f (Dij ) to economize on notation.
After controlling for δjt , there is still variation left to estimate the β parameters, which utilize variation across
patients. Similarly, distance depends on the location of both the patient and the hospital, so the parameters
of the distance function f (·) can be recovered. However, at this point we cannot identify the effect of hospital
waiting times and quality on utility for the average patient: we only know whether certain types of patients are
more sensitive to waiting times or quality than the average patient and this interaction effect is relative to a yet
unknown average effect.33
Because the set of fixed effects in δ is very large, searching over them non-linearly would be very computationally burdensome. However, for a given guess of the distance parameters, there is a unique vector δ that
matches the predicted aggregate market shares to the market shares in the data. This is essentially the insight
provided in BLP. We therefore use their contraction mapping on the aggregate market shares in order to recover
the vector δ.
Since we are using patient-level data, we first need to aggregate the data at the hospital-quarter level before
applying the contraction mapping. We form the hospital-quarter market shares by aggregating over the patient
population within each quarter,

sb0jt =

1 X
P rit (j|βbw,it , βbz,it , α
bd , δ 0 )
Nt

(7)

i∈It

with

P rit (j|βbw,it , βbz,it , α
bd , δ 0 ) =

Z
dF (vw , vz , εit )

(8)

Aij

where Aij = (vw , vz , εit |uijt > uikt ∀k 6= j) and F (vw , vz , εit ) is the joint density of the random coefficient draws
33 This is particularly relevant when assessing the effect of the reform on different demographic groups. This change will be
composed of a change in the average effect and a change in the interaction effect. Knowing only the latter does not allow us to
make any statement about the direction of the impact of the reform on a particular patient group. We deal with this below.

18

(vw , vz ), which are assumed to be independent standard normal variables, as well as the iid extreme value shocks
εit .
P rit (j|·) is the probability that patient i chooses hospital j in period t. It is computed by integrating over the
distribution of the random coefficient and the shocks εit . The integration over the two dimensions of unobserved
preference heterogeneity is implemented using a 2-dimensional Gauss-Hermite quadrature with 9 nodes. sb0jt is
the predicted market share for hospital j in period t, given the initial guess for the fixed effects vector δ 0 . Nt
denotes the number of patients visiting any hospital in a given time period and It denotes the set of patients
visiting any hospital in a given time period. α
bd denotes the current guess of the parameters entering f (Dij ),
and similarly βbw,it and βbz,it denote the current guesses of the interactions of waiting time and mortality with
patient demographics (including the unobserved heterogeneity terms). In other words, we are averaging over
individual choice probabilities for a given guess of the patient-specific parameters.
We can now employ the contraction mapping

δ k+1 = δ k + [log(s) − log(b
sk (βbw,it , βbz,it , α
bd , δ k ))]
where k denotes the k th iteration of the contraction mapping, s is the observed market-share, and sb denotes the
predicted market-share conditional on the parameters of the model. This is iterated until convergence.
The likelihood function to be maximized is given by

L =

YY
[P rit (j)]yijt
it

j

where yijt , with (j ∈ J), is a variable that takes the value one for the decision actually taken in a particular
period and zero otherwise.34

6.2.2

Second Step: Estimating Average Effects

The second step is the estimation of the average impact of hospital characteristics on patient utility. When
estimating a full set of hospital-quarter fixed effects, all the variation at the hospital-quarter level is absorbed
in the estimated fixed effects. Therefore, we project the fixed effects on hospital characteristics in this second
34 For each individual i that visits a hospital in time period t we can compute the theoretical probabilities for each option j in the
choice set. Multiple CABGs for the same patient are extremely rare, therefore we treat all observations as independent. In other
word, there is a unique t associated to every patient i. With some abuse of notation, multiplying over (it), rather then separately
over i and t, represents this feature.

19

step. Based on our utility specification we can write δjt as a function of hospital characteristics (equation (5))

δjt

=

[β w,0 ∗ 1(t = 0) + β w,1 ∗ 1(t = 1)] ∗ Wjt
+[β z,0 ∗ 1(t = 0) + β z,1 ∗ 1(t = 1)] ∗ Zjt
+ξjt

This is a linear relationship between δjt and the hospital characteristics. In contrast to the first step, where
the fixed effects are time-period specific, in this baseline specification we control for a set of time invariant
hospital fixed effects. Formally, we estimate

δjt

=

[β w,0 ∗ 1(t = 0) + β w,1 ∗ 1(t = 1)] ∗ Wjt
+[β z,0 ∗ 1(t = 0) + β z,1 ∗ 1(t = 1)] ∗ Zjt
+ξ j + ξejt ,

where ξ j is the fixed effect for hospital j and ξejt is the quarter-specific deviation from the average unobserved
hospital quality. The latter is the econometric error term and we assume that it is not correlated with any of
the observed hospital characteristics.35
To address the concern that unobserved hospital quality changed after the introduction of choice, we allow
for a different set of fixed effects pre- and post-reform in a sensitivity check (Table 9).36 The robustness of
our estimates to using separate pre- and post-reform dummies is reassuring and we use time invariant hospital
fixed effects in our baseline as this facilitates the comparison of demand elasticities and market shares pre- and
post-reform.

7

Estimation Results

In this section we first report the estimation results from the choice model (production function results are in
Appendix section A.3), then report how they translate into patient and hospital level elasticities of demand.
35 Since our model does not include an outside option, in the first step we can only estimate (k − 1) hospital fixed effects in each
t
quarter, where kt denotes the quarter-specific number of hospitals in the market. We therefore do not estimate the quarter-specific
fixed effect for one of the hospitals that is present throughout the whole sample period. To implement the second step we compute
the hospital characteristics as the difference relative to the hospital for which we do not have a fixed effect. In other words, we
subtract the waiting time (mortality) of this particular hospital from the waiting times (mortalities) of all the other hospitals for
each of the quarters. After this normalization we run the linear regression outlined above.
36 This sensitivity check (and our baseline) control less conservatively for unobserved quality than the first step of our estimation.
However, we think that the most important change in hospital quality over time will happen with the relaxation of choice constraints
due to the reform.

20

7.1

Choice Model Estimates

7.1.1

First Step: Effects with Heterogeneity

The results from the first step of estimation are reported in Table 8. For economy of exposition, the (large
number of) fixed effect estimates are not reported in the table. Also for the purpose of exposition, all patient
characteristic variables were standardized in order to make the coefficient magnitudes more easily comparable.
Due to the standardization, the interactions can be interpreted as deviations in preferences relative to a patient
with average characteristics.
Examination of the estimates reveals some dramatic results. There are significant changes in almost all
of the interactions between the pre- and post-reform time periods. Poorer patients (higher values of IMD)
pay more attention to waiting times after the introduction of choice.37 The interaction term for waiting times
post-reform is significantly different from zero (and from the pre-reform coefficient). More severely ill patients
(more co-morbidities) care significantly less about waiting times and significantly more about quality in both
time periods. In other words, sicker patients are willing to trade off higher waiting times for a better quality of
service, as one would expect. Relatively speaking, they become more sensitive to both dimensions of hospital
service post-reform. More informed patients are less sensitive to both measures pre-reform, but become relatively
more sensitive post-reform. Post-reform they are significantly more sensitive to waiting times than the average
patient but not significantly different from the average patient with respect to quality. The change in sensitivity,
however, is statistically significant in the case of both dimensions of service.
In the case of patient informedness the change is the most relevant measure. The variable is only defined
in a meaningful way for the post-reform time period, since it refers to information about something that did
not exist pre-reform (being informed about the possibility of choice). We include it in the pre-reform period to
strengthen the identification of the effect of information. The pre-reform interaction effects with informedness
should capture any factors (e.g., unmeasured population characteristics) that are correlated with informedness
across PCTs. This difference-in-difference identification is based on the assumption that the only thing changing
with the introduction of the reform is the provision of information, i.e., any other factors that might be crosssectionally correlated with informedness do not change when patient choice is expanded.
We also find evidence of substantial unobserved heterogeneity in preferences over the adjusted mortality rate,
both pre- and post-reform. This unobserved heterogeneity is essentially unchanged pre- to post-reform. Our
results show little heterogeneity in preferences over waiting times in both time periods. Finally, we also find
that, as expected, distance plays an important role in hospital choice. The effects are clearly nonlinear. Four
of our six distance terms are highly significant, showing the importance of controlling flexibly for the effects of
37 High waiting times are a negative, so a negative coefficient indicates that patients are responsive to waiting times. Similarly,
our measure of quality is mortality, so a negative coefficient indicates greater responsive by avoiding low quality (high mortality)
hospitals.

21

distance on choice.
Overall, Table 8 provides evidence of substantial patient heterogeneity in response to the reform. These
findings regarding the heterogeneity of the treatment effect are highly relevant for policy purposes. We elaborate
more on the policy implications in Section 8 below.

7.1.2

Second Step: Average Effects

The results of the linear regression for the 2nd step of estimating the choice model (obtaining average effects)
are reported in Table 9. We find substantial impacts of the reform. In particular, patients became substantially
more sensitive to the adjusted mortality rate post-reform. The estimated effect is not significantly different
from zero pre-reform and becomes significantly negative post-reform, and approximately twice as large. This
provides evidence on the primary question of this paper. The choice reform did have a substantial impact on
patients’ sensitivity to hospitals’ clinical quality of care, and in the expected direction – patients became much
more responsive to how well hospitals performed in terms of their mortality rate for CABG surgeries.
The estimates with respect to waiting times are not significant either pre- or post-reform. We therefore
conclude that there was no substantial change in the sensitivity with respect to waiting times for the average
patient. This lack of an average effect is possibly due to the large fall in waiting times that occurred just
prior to the full role out of the Choice programme in 2006. In 2001 the government instituted an aggressive
national policy (dubbed “targets and terror”) to reduce waiting times for elective care by 2005. This policy had
considerable success in lowering waiting times (Propper, Sutton, Whitnall, and Windmeijer (2010)) and possibly
meant that post-2006 on average patients were less concerned about waiting times in deciding where to receive
CABG treatment. However, as shown above, some groups of patients did change their behavior with respect to
waiting times after the introduction.
We also relax the assumption that hospital fixed effects are constant and allow them to differ pre- and
post-reform. These estimates are displayed in the second set of columns in the table. As can be seen, the
estimates and conclusions are essentially unchanged – patients are substantially more sensitive to the mortality
rate post-reform.

7.2

Elasticities of Demand

Since the primary focus on the paper is on the quality of care, and we find only weak (mostly insignificant)
results for sensitivity with respect to waiting times, we focus on the elasticity of demand with respect to the
(case-mix adjusted) mortality rate. We start by computing elasticities for individual patients with respect to
the adjusted mortality rate. Analyzing individual-level elasticities is helpful in our context to get a better sense
of how strongly different patient groups were affected by the relaxation of the constraint on choice. Secondly,

22

we compute aggregate demand elasticities for hospitals by integrating over the changes in individual choice
probabilities for each hospital. Ultimately, for assessing the impact of the choice reform, these hospital-level
elasticities are the most crucial factor. If the demand that hospitals face becomes more elastic with regard to
quality, then relaxing the constraint on choice was successful in increasing hospitals’ incentives to provide higher
quality.
7.2.1

Patient-level Elasticities

Table 10 reports the sensitivity of choice probabilities to changes in the mortality rate for different groups of
patients. The first column reports the percentage change in the choice probability following an increase in
the mortality rate by one standard deviation (about 1.11 percentage points). The second column reports the
elasticity of individual-level demand. In order to compute both columns we fix the baseline choice probability of
the patient to be equal to 50 percent.38 A different choice probability would equally scale all values reported in
the table, so any relative comparison between different rows in the table is not affected by this assumption. To
assess the impact on different income groups, we report the elasticity for a patient whose income is 1 standard
deviation lower than the average. Similarly, we report results for more severely ill patients as well as more
informed patients.
We find that with restrictions on choice (prior to the reform) a 1 standard deviation increase in mortality
leads to about a 3 percent drop in the choice probability of the average patient. After the relaxation of choice
constraints (post-reform), we see an effect that is more than twice as large, with a drop of about 7 percent in
the choice probability. Interestingly, we find no real difference in how lower income patients reacted to increased
choice. There are very small differences between their responses to quality and those of the average patient,
both with restricted and free choice (pre- and post-reform). The result is intriguing as there was concern that
the choice reform would not benefit lower income households or that they would be harmed by it.
Sicker patients reacted more strongly to choice than the average patient. This is intuitive as these patients
have a stronger incentive to select a high quality hospital. Note that even pre-reform choices were relatively
more responsive for sicker patients. This is likely to be because physicians pay more attention to quality when
referring a sicker patient, though it is possible that sicker patients gathered more information and managed to
influence their GP to refer them to a better hospital, even before the introduction of patient choice.

More

informed patients are responsive to hospitals’ mortality rates post-reform. The change in responsiveness preto post-reform is quite a bit larger than for other groups. (As discussed previously, we focus on the change in
elasticity for this group rather than the pre- and post-reform levels.)
Finally, we also report the elasticities for patient-level demand in the second column of the table. While
across the board the elasticities are fairly small, they are substantially larger with free choice: the elasticity for
38 Specifically,

we compute the first column as [100 ∗ βx ∗ Stdx ∗ (1 − P r)]. The elasticity is computed as [βx ∗ x ∗ (1 − P r)].

23

the average patient more than doubles pre- to post-reform, while it is substantially larger for sicker and better
informed patients.

7.2.2

Hospital-level Elasticities

We examine hospital-level demand sensitivity by calculating market share impacts and elasticities. We simulate
a one standard deviation change in mortality for each hospital in the choice set and compute the percentage
change in the hospital’s market share. For the elasticity we divide by the percentage change in the mortality
rate.39 The market share and elasticity effects will differ across hospitals depending on the density of patients
in the local area, the demographic composition of the local population, and the locations of other hospitals.
Table 11 reports the distribution of elasticities across all hospitals. We find that when constraints on choice
are relaxed post-reform a one standard deviation increase in the mortality rate leads to a 4.9 percent drop in
market share for the average hospital, relative to a much smaller decrease of 0.36 percent before the reform.
There is substantial heterogeneity in the impacts across hospitals. The market share loss is 6.25 at the 25th
percentile and 2.3 at the 75th percentile of the distribution of elasticity changes.40 We also compute demand
elasticities across hospitals and find the elasticities are generally low, but change substantially due to the freeing
up of choice. The elasticity at the average hospital increases from 0.02 (i.e. close to zero) to -0.12 pre- to
post-reform.41
Overall the results suggest that relaxing the constraint on choice increased hospitals’ incentives to improve
quality. While the effect is not uniformly large across all hospitals, many hospitals experienced substantial
changes in the demand elasticities they faced.

8

Policy Evaluation

We provide an evaluation of the impacts of allowing free choice in several steps. We first estimate the number
of lives that were saved by allocating patients to better hospitals post-reform, as well as provide a broader
analysis of consumer welfare gains due to the relaxation of choice constraints. Both these calculations evaluate
effects of the reform under the assumption that hospitals did not react to the change in demand conditions. The
survival and welfare effects we present are purely due to an efficient resorting of patients. We then proceed to
an analysis of how much the competitive environment changed with the introduction of the reform. Finally, we
39 More specifically, we simulate a small change in the mortality rate when computing the elasticity rather than a one standard
deviation shift.
40 Note that we report percentiles for the distribution of changes, rather than changes for hospitals at certain percentile in the
original distribution of levels. As hospitals change their position in the level-ranking with the introduction of the reform, the two
things are not the same.
41 We have to make some modification to the data in order to compute hospital-level elasticities due to the fact that the adjusted
mortality rate sometimes takes on negative values. We adjust the distribution of the adjusted mortality rate (by shifting the mean
and the variance) so that its minimum and maximum are the same as the minimum and maximum values of the raw mortality rate
distribution.

24

provide some suggestive supply-side evidence which shows that hospitals seem to have reacted to the change in
demand conditions as intended by policy makers. In all but the last step, we simulate counterfactuals in order
to quantify the impact of increased choice. However, contrary to many other applications, we do not simulate
changes caused by a hypothetical policy, but rather simulate behavior for the post-reform population under the
assumption that the reform had not taken place. In this way we leverage the structure of our model to evaluate
and quantify the effects of the policy change.

8.1

The Impact of Choice on Patient Survival

An obvious, and very direct, measure by which to evaluate this policy is the impact on the probability of survival
following a CABG. This is of direct importance to patients. We assess this by calculating how many more patients
would have died had the reform not been implemented, i.e., if patients in the post-reform time period were still
subject to pre-reform choice constraints and therefore choosing according to pre-reform parameters.
Formally, we implement the analysis in the following way. The ex-ante mortality probability42 of any particular patient i in time-period t is given by

P rit (M ortality, θt ) =

X

P rit (j, θt ) · E(M ortality|choice = j, P atientCharacteristics)

j

Both terms on the right-hand side of the above equation can be computed based on the estimated parameters.
The first term denotes the probability of visiting hospital j, which is estimated within the demand model. The
second is given by the estimated probability of death conditional on the observed set of patient characteristics
and the choice of a particular hospital. Specifically, equation (6), which we used to compute the case-mix
adjusted mortality rate, yields the expected probability of dying.
To obtain the expected difference in mortality we simply compute

E(∆M ortality) =

X

[P rit (M ortality, θpost ) − P rit (M ortality, θpre )] · 1(t = post-reform)

it

In other words, we sum up the changes in mortality probability for each patient in the post-reform period
when choice parameters change from post- to pre-reform estimates. Results from this counterfactual are reported
in Table 12. We estimate that 12 fewer patients would have survived had the reform not been implemented
in 2005. This number is calculated is over the entire five post-reform quarters used in the estimation (so
corresponds to roughly 10 lives saved on a annual basis). The lower panels of the table assess the magnitudes
of these changes relative to the total number of admissions and deaths during the relevant time period. The
42 In this context we think of the ex-ante probability as the probability of death before both the error terms of the choice process
and the error term influencing survival are realized, i.e. the patient has not decided which hospital to visit and we do not know the
patient-specific shock to his mortality probability yet.

25

changes amount to about 0.06 percentage points or a 3.1 percent decrease in the mortality rate. If we adopt
the $100,000 benchmark of Cutler and McClellan (2001) for the value of a year of life, and assume that CABG
survivors’ lives are extended by 17 years (van Domburg, Kappetein, and Bogers 2009), the beneficial effects of
the pro-competition reforms are about $17 million yearly in terms of value of life-years saved.43

8.2

Changes in Patient Welfare

In a similar spirit to the analysis of patient survival, we also compute the percentage welfare changes due to
removing restrictions on choice. In order to undertake a welfare calculation we assume that preferences are
identified from the data post-reform. Pre-reform choices are constrained and the parameters we estimate are
therefore the reduced form of preferences and the constraints. Using these assumptions (which play no role
in our estimation) we can assess how much welfare was gained by freeing patient choice from the pre-reform
constraints. We compute the change in consumer surplus in the following way




P rit (j, θ1 ) · uit (j, θ1 ) − P rit (j, θ0 ) · uit (j, θ1 )
E(%∆CS) =
· 1(t = post-reform)
P rit (j, θ0 ) · uit (j, θ1 )
In other words, we compare patient’s utility post-reform when preferences and choice are determined by θ1 .
with the utility they would have received had they chosen according to pre-reform restricted choice parameters
(θ0 ) but if their utility was based on the “true” post-reform preferences (θ1 ).44 The latter would have been the
situation patients would have found themselves in had the reform not been implemented. We simulate over both
the random coefficients and the logit error terms in order to compute the expression above. As the welfare levels
are expressed in normalized utils, only the percentage change in utils is an interpretable measure.
We find that the freeing of choice led to a 7.68 percent increase in welfare. This is a substantial, although not
overwhelming, increase. Note that both the welfare analysis and the change in survival only assess the changes
that are achieved by reallocating patients, i.e. without any supply side adjustment of hospitals to the new
demand conditions. We now turn to the further improvements that can be achieved if the reform also provided
incentives for hospitals to improve quality.

8.3

Change in the Competitive Environment

In this section we perform a counterfactual in order to get a sense of the magnitude of the relaxation of choice
constraints on hospitals’ incentives. We look at how hospital market shares in the pre-reform period would
have been different if patient choices had occurred based on estimated post-reform parameters. This exercise
43 10

× 17 × 100, 000 = 17, 000, 000
that P rit (j, θ1 ) · uit (j, θ1 ) is a standard welfare metric and equal to the logit inclusive-value. However, P rit (j, θ0 ) · uit (j, θ1 )
is specific to our setup and cannot be represented analytically because different parameters determine choice and utility.
44 Note

26

allows us to compute how much re-shuffling of market shares would have happened had patients had free choice
earlier. When implementing the counterfactual, we hold everything fixed except for the choice parameters. In
other words, the same set of patients is exposed to the same set of hospitals as in the “real” pre-reform choice
situation. For the purpose of this counterfactual we therefore do not allow hospitals to adjust to the changes in
demand caused by the parameter change.
Any movement we see in market-shares in the data after the reform will be due to demand changes and
hospitals responding to them. This counterfactual allows us to isolate the former effect in order to assess the
”pressure” on market-shares caused by the reform for a given quality level. The magnitude of the re-shuffling
of market shares is therefore a valuable metric to how much incentives to improve quality changed for hospitals.
The results from this exercise are reported in Table 13. In line with the results presented above, we find that
the introduction of choice has a significant impact on some hospitals. At the extremes of the distribution one
hospital would have lost 8.7 percent of its market share and another would have gained 14.7 percent. There is
a large heterogeneity in the impacts, however, and for most hospitals the effect is more modest.

8.4

Some Assessment of the Supply-Side Response

Having established that the introduction of choice led to a substantial increase in demand elasticities faced by
hospitals, we now provide some evidence for a supply-side response to this change in the competitive environment.
In order to analyze the supply-side in a simple way, we rely on the fact that the reform differentially affected
hospitals due to differences in population density, population demographics, and the location of competitors.
We therefore expect hospitals in areas where demand conditions changed more to improve their quality more
than other hospitals.
We test this hypothesis by regressing the change in the case-mix adjusted mortality rate on the change in the
aggregate elasticity of demand with respect to quality. This simple approach mirrors the difference-in-difference
estimation conducted in Gaynor, Moreno-Serra, and Propper (2010) and Cooper, Gibbons, Jones, and McGuire
(2011). In these papers, a change in the mortality rate is regressed on cross-sectional variation in hospital market
structure. The argument is that the expansion of choice will have a stronger impact in areas with a higher density
of competing hospitals. Using a measure of concentration, like the Herfindahl Index, is a reduced-form way of
capturing that the elasticity of demand is expected to change more in some areas than in others. Here we
compute demand elasticities (and changes in elasticities due to the reform) based on model primitives. Because
CABGs are not offered in all UK hospitals we have only 27 observations available for estimation. For that
reason, and because of the ad hoc nature of the specification, we think of the results presented in this section as
only suggestive and complementary to the evidence provided elsewhere.

27

We estimate the following OLS regression,

∆M ortalityj = λ0 + λ1 ∆Elasticityj,M ortality + ej

(9)

where Elasticityj,M ortality denotes the elasticity of hospital demand with respect to the case-mix adjusted
mortality rate, as reported in Table 11.45 The results from this regression are reported in Table 14. For ease of
interpretation, we use the absolute value of the elasticity in the regression.
We find a negative and significant impact of the change in the demand elasticity on the change in the case-mix
adjusted mortality rate. In other words, hospitals whose demand became more responsive to quality improved
quality disproportionately more than elsewhere. To get a sense of the magnitude of the coefficient, consider a
shift of one standard deviation in the elasticity (roughly 6, as reported in Table 11). This shift implies a drop of
0.7 in the mortality rate, which is roughly equal to 75 percent of the general decrease in the case-mix adjusted
mortality rate over the entire time period from 2003 to 2007 (see Table 1). This is a very substantial impact.
Overall, this suggests that freeing up patient choice elicited a supply side response by hospitals that improved
patient survival. This impact goes beyond the effects presented in the previous analyses. In terms of magnitude,
our point estimate implies that competition could have played a large role in the overall drop in the CABG
mortality rate from 2003 through to 2007.

9

Summary and Conclusions

This paper takes advantage of a “natural experiment” in the English National Health Service which introduced
patient choice among hospitals. This reform allows us to look at the effect of choice on patient behavior
and supplier responses to that behavioral change. We evaluate whether increased choice resulted in increased
elasticity of demand faced by hospitals with regard to two central dimensions of hospital service – clinical
quality of care and waiting times. We estimate a structural model of patient demand, allowing for a different
responsiveness pre- and post-reform in a flexible way. On the methodological side, we show how to deal with
the endogeneity of waiting times in the demand model as well as how to obtain a valid quality measure using
an IV strategy.
We find substantial impacts of the removal of restrictions on patient choice. Patients are more responsive
to the clinical quality of care at hospitals (measured as the hospital’s case-mix adjusted mortality rate) but
on average are not more responsive to waiting times. These is heterogeneity in these impacts, however. More
severely ill patients are more affected by the reform as are better informed patients. We calculate that the
increased demand responsiveness alone led to a significant reduction in mortality and an increase in patient
45 In

the regression we use (the change in) the percentage change in market share following a one standard deviation increase in
mortality instead of the elasticity.

28

welfare. The elasticity of demand faced by hospitals increased post-reform. This gave hospitals (potentially)
large incentives to improve their quality of care and we find suggestive evidence that hospitals responded strongly
to the enhanced incentives due to increased demand elasticity.
Overall, this paper provides evidence that a reform that removed constraints on patient choice worked: patient
flows were more sensitive to clinical quality and patients went to better hospitals. This suggests that there is
potential for choice based reforms to succeed and for competition in health care to enhance quality.

29

References
Anderson, T. W. (1984): An Introduction to Multivariate Statistical Analysis, 2nd ed. Wiley, New York.
Beckert, W., M. Christensen, and K. Collyer (2012): “Choice of NHS-funded Hospital Services in
England*,” The Economic Journal, 122(560), 400–417.
Berry, S., J. Levinsohn, and A. Pakes (1995): “Automobile Prices in Market Equilibrium,” Econometrica,
63(4), 841–890.
Besley, T., and M. Ghatak (2003): “Incentives, Choice, and Accountability in the Provision of Public
Services,” Oxford Review of Economic Policy, 19(2), 235–249.
Blöchliger, H. (2008): “Market Mechanisms in Public Service Provision,” OECD Economics Department
Working Papers, No. 626, Organization for Economic Cooperation and Development, Paris, France.
Capps, C., D. Dranove, and M. Satterthwaite (2003): “Competition and Market Power in Option Demand
Markets,” RAND Journal of Economics, 34(4), 737–763.
Cooper, Z., S. Gibbons, S. Jones, and A. McGuire (2011): “Does Hospital Competition Save Lives?
Evidence from the English Patient Choice Reforms,” Economic Journal, 121(554), F228–F260.
Cutler, D., and M. McClellan (2001): “Is Technological Change in Medicine Worth It?,” Health Affairs,
20(5), 11–29.
Farrar, S., J. Sussex, D. Yi, M. Sutton, M. Chalkley, T. Scott, and A. Ma (2007): “National
Evaluation of Payment by Results - Report to the Department of Health,” Report, Health Economics Research
Unit, University of Aberdeen, http://www.abdn.ac.uk/heru/documents/pbr_report_dec07.pdf (accessed
April 27, 2010).
Gaynor, M., R. Moreno-Serra, and C. Propper (2010): “Death by Market Power: Reform, Competition
and Patient Outcomes in the British National Health Service,” unpublished manuscript, Carnegie Mellon
University, Imperial College.
Gaynor, M., and W. B. Vogt (2003): “Competition Among Hospitals,” Rand Journal of Economics, 34(4),
764–785.
Geweke, J., G. Gowrisankaran, and R. J. Town (2003): “Bayesian Inference for Hospital Quality in a
Selection Model,” Econometrica, 71(4), pp. 1215–1238.
Goolsbee, A., and A. Petrin (2004): “The Consumer Gains from Direct Broadcast Satellites and the Competition with Cable TV,” Econometrica, 72(2), 351–381.
30

Gowrisankaran, G., and R. J. Town (1999): “Estimating the Quality of Care in Hospitals Using Instrumental Variables,” Journal of Health Economics, 18, 747–767.
Hansen, L. (1982): “Large Sample Properties of Generalized Method of Moments Estimators,” Econometrica,
50, 1029–1054.
Ho, K. (2009): “Insurer-Provider Networks in the Medical Care Market,” American Economic Review, 99(1),
393–430.
Howard, D. H. (2005): “Quality and Consumer Choice in Healthcare: Evidence from Kidney Transplantation,” Topics in Economic Analysis and Policy, 5(1), Article 24, 1–20, http://www.bepress.com/ bejeap/topics/vol5/iss1/art24.
Hoxby, C. M. (2003): “School Choice and School Productivity: Could School Choice Be a Tide that Lifts All
Boats?,” in The Economics of School Choice, ed. by C. M. Hoxby, pp. 287–342. National Bureau of Economic
Research, Cambridge, MA.
Kessler, D. P., and M. B. McClellan (2000): “Is Hospital Competition Socially Wasteful?,” Quarterly
Journal of Economics, 155, 577–615.
Le Grand, J. (2003): Motivation, Agency, and Public Policy: Of Knights & Knaves, Pawns & Queens. Oxford
University Press, Oxford, UK.
Luft, H. S., D. W. Garnick, D. H. Mark, D. J. Peltzman, C. S. Phibbs, E. Lichtenberg, and S. J.
McPhee (1990): “Does Quality Influence Choice of Hospital?,” JAMA: The Journal of the American Medical
Association, 263(21), 2899–2906.
Moscone, F., E. Tosetti, and G. Vittadini (2012): “Social interaction in patients hospital choice: Evidence
from Italy,” Journal of the Royal Statistical Society: Series A (Statistics in Society), 175(2), 453–472.
National Hospital Discharge Survey (2010): National Hospital Discharge Survey. National Center for
Health Statistics, Centers for Disease Control, Atlanta, GA.
Propper, C., M. Sutton, C. Whitnall, and F. Windmeijer (2008): “Did Targets and Terror Reduce
Waiting Times in England for Hospital Care?,” The BE Journal of Economic Analysis & Policy, 8(2), 5.
(2010): “Incentives and Accountability in Hospital Care: Evidence from a Natural Experiment,”
Journal of Public Economics, forthcoming.
Sivey, P. (2008): “The Effect of Hospital Quality on Choice of Hospital for Elective Heart Operations in
England,” Unpublished Manuscript, University of Melbourne.
31

Tay, A. (2003): “Assessing Competition in Hospital Care Markets: the Importance of Accounting for Quality
Differentiation,” RAND Journal of Economics, 34(4), 786–814.
van Domburg, R. T., A. P. Kappetein, and A. J. J. C. Bogers (2009): “The Clinical Outcome After
Coronary Bypass Surgery: A 30-year Follow-up Study,” European Heart Journal, 30, 453–458.
Varkevisser, M., S. A. van der Geest, and F. T. Schut (2012): “Do patients choose hospitals with high
quality ratings? Empirical evidence from the market for angioplasty in the Netherlands,” Journal of Health
Economics, 31(2), 371 – 378.

32

Table 1: Descriptive Statistics — Hospital Characteristics
Total Admissions
CABGs

2003
2004
2005
2006
2007

Mean

Std

Mean

Std

502.9
507.5
449.1
425.4
459.9

189.4
200.0
170.8
172.7
169.9

109.1
100.5
67.8
65.6
64.9

32.1
20.7
15.2
17.3
21.4

Mortality Rate
CABGs

2003
2004
2005
2006
2007

Waiting Times
(Days)

Adjusted Mortality
Rate, CABGs

Mean

Std

Mean

Std

1.88
1.93
1.90
1.95
1.51

0.82
0.78
0.57
0.79
0.69

1.67
1.46
1.19
1.40
0.73

1.39
1.45
1.14
1.18
0.90

33

Table 2: Descriptive Statistics — Mortality Rate and Waiting Times at the Quarter Level
Waiting Times
(Days)

Adjusted Mortality
Rate, CABGs

Mean

S.D.

Mean

S.D.

2004q1
2004q2
2004q3
2004q4
2005q1

113.7
106.1
102.5
100.5
93.4

36.3
26.8
26.6
23.6
21.6

1.46
1.76
1.20
1.74
1.14

1.71
3.12
1.96
2.04
1.66

2007q1
2007q2
2007q3
2007q4
2008q1

66.7
66.2
65.3
63.9
66.1

19.0
18.5
22.7
23.9
23.3

1.50
0.55
0.74
0.66
0.94

2.29
1.25
1.35
0.99
2.18

34

Table 3: Descriptive Statistics — Patient Characteristics

Mean

Median

Standard
Deviation

10th
Percentile

90th
Percentile

Age

65.76

66

55.04

53

76

Index of Multiple Deprivation

0.14

0.1

0.11

0.04

0.31

Comorbidity Count

5.42

5

2.81

2

9

Capped Comorbidity Count
(Cap at 6 Comorbidities)

4.57

5

1.61

2

6

Probability of Informedness
About Choice

0.53

0.53

0.07

0.45

0.63

Fraction Male

81.18%

35

Table 4: Descriptive Statistics: Distance

Mean

Median

Standard
Deviation

10%

90%

95%

Pre

34.93

22.34

44.97

4.77

71.40

98.15

Post

32.24

22.91

32.94

4.93

70.58

92.36

Fraction of Patients

Pre

68.14 %

Visiting the Closest Hospital

Post

68.67 %

Distance

36

Table 5: Descriptive Statistics: Hospital Selection Based on Observed Severity1
Adjusted
Mortality Rate

Adjusted
Mortality Rate

Co-morbidity Count

-0.220***
(0.006)

-0.180***
(0.006)

Quarter Fixed Effects
(Flexible Time Trend)

No

Yes

Number of Observations

32,715

32,715

Dependent Variable

1 ***

denotes statistical significance at the 1 percent level, ** denotes statistical significance at the 5 percent level.

37

38

(2)

0.0042
(0.0552)

No
142
29
5

Hospital Fixed Effects

Number of Observations
Hospitals
Quarters

Pre

143
29
5

No

-0.1652***
(0.0622)

Post

Elective CABGs
Market-share

Coefficient
on Case-Mix Adjusted
Mortality Rate

Time Period

Dependent Variable

(1)

(4)

142
29
5

No

0.0488
(0.0531)

Pre

143
29
5

No

-0.0667
(0.0744)

Post

Emergency CABG
Market-share

(3)

(6)

142
29
5

Yes

0.0416
(0.0267)

Pre

143
29
5

Yes

-0.0692**
(0.0321)

Post

Elective CABGs
Market-share

(5)

(8)

142
29
5

Yes

-0.0373
(0.0379)

Pre

143
29
5

Yes

-0.0127
(0.0466)

Post

Emergency CABG
Market-share

(7)

Table 6: Reduced-Form Evidence: Regressions using Aggregate Market-Shares (*** denotes statistical significance at the 1 percent level, ** denotes
statistical significance at the 5 percent level.)

Table 7: Reduced-Form Evidence: Changes in the Expected Mortality Rate

Mortality Rate
(Raw Rate)

Mortality Rate
(Case-Mix Adjusted)

Sample

Mean
Pre

Mean
Post

Difference
in Means

All Patients

1.344

0.948

-0.396

Patients Visiting
the Nearest Hospital

1.287

1.022

-0.265

Patients Not Visiting
the Nearest Hospital

1.462

0.779

-0.683

All Patients

1.471

0.748

-0.723

Patients Visiting
the Nearest Hospital

1.352

0.809

-0.543

Patients Not Visiting
the Nearest Hospital

1.716

0.606

-1.110

39

Table 8: Regression Results from the First Step of the Estimation1

Income
Deprivation
Index
CoMorbidity
Count
Patient
Informedness

Unobserved
Preference
Heterogeneity

Distance

Waiting
Times
Mortality
Rate
Waiting
Times
Mortality
Rate
Waiting
Times
Mortality
Rate
Waiting
Times
Mortality
Rate

Pre
Post
Pre
Post
Pre
Post
Pre
Post
Pre
Post
Pre
Post
Pre
Post
Pre
Post

Linear
Square
Cube
Closest Dummy
Closest ”Plus 10” Dummy
Closest ”Plus 20” Dummy

1 All

Coeff.

S.E.

0.01
-3.85
0.12
-0.02
5.67
4.10
-10.11
-13.18
1.25
-4.41
5.17
0.01
-0.22
-0.26
35.02
39.04

0.68
0.65
0.86
1.13
0.43
0.58
0.56
0.94
0.66
0.65
0.83
1.06
75.36
76.70
0.87
1.81

-14.86
4.91
-0.57
1.07
-0.01
0.01

0.21
0.11
0.02
0.02
0.00
0.05

***

***
***
***
***
**
***
***

***
***

***
***
***
***
**

the patient characteristics used in the regression are standardized in order to make the magnitudes of the coefficients
comparable. *** denotes statistical significance at the 1 percent level, ** denotes statistical significance at the 5 percent level.

40

Table 9: Regression Results from the Second Step of the Estimation
Baseline
Specification

Average
Effect

Hospital Fixed Effects

1 ***

Sensitivity Check

Coeff.

S.E.

Coeff.

S.E.

0.43
13.45

4.09
7.53

-1.63
-11.39

3.81
3.96

Waiting
Times

Pre
Post

-4.24
6.25

3.15
4.74

Quality

Pre
Post

-4.85
-12.40

3.70
4.00

***

Constant Fixed Effects
Pre- and Post-Reform

***

Separate Fixed Effects
Pre- and Post-Reform

denotes statistical significance at the 1 percent level, ** denotes statistical significance at the 5 percent level.

41

Table 10: Patient-Level Elasticities of Demand with Respect to Mortality1
Impact on Patient’s
Purchase Probability
From 1 S.D. Shift
in Adjusted Mortality

Elasticity

Pre-Reform
Average Patient
Lower Income
Higher Comorb
More Informed

-2.69
-2.63
-8.30
0.18

-0.021
-0.021
-0.066
0.001

Post-Reform
Average Patient
Lower Income
Higher Comorb
More Informed

-7.08
-7.09
-14.40
-7.08

-0.056
-0.056
-0.114
-0.056

1 The table reports the elasticity of demand at the patient-level with respect to the case-mix adjusted mortality rate. The
values reported in the first column represent the percentage change in market-share when the hospital increases the mortality rate
by one standard deviation. The second column reports the elasticity of demand. Specifically, we compute the first column as
[100 · βx · Stdx · (1 − P r)]. The elasticity is computed as [βx · x · (1 − P r)].

42

Table 11: Hospital-Level Responsiveness of Demand with Respect to Mortality1
1-S.D. Shift

Mean

S.D.

25th Perc.

Median

75th Perc.

Pre-Reform
Post-Reform

-0.36
-4.83

5.11
4.73

-1.73
-5.66

0.11
-3.14

0.56
-2.34

Change

-5.38

5.81

-6.25

-2.88

-2.28

Elasticities

Mean

S.D.

25th Perc.

Median

75th Perc.

Pre-Reform
Post-Reform

0.02
-0.12

0.16
0.07

-0.03
-0.16

0.00
-0.10

0.01
-0.05

Change

-0.14

0.19

-0.15

-0.07

-0.05

1 The table reports the elasticity of aggregate demand at the hospital-level with respect to the case-mix adjusted mortality rate.
The values reported represent the percentage change in market-share when the hospital increases the mortality rate by one standard
deviation. The impact on market-shares is computed for each hospital individually. The table reports the distribution of changes
within the choice-set of hospitals faced by patients. The lower panel reports elasticities across the hospitals in the choice-set. See
text for more details on how the elasticities are computed.

43

Table 12: Changes in Survival Probability due to the Reform1
Change in Survival when Choices Post-Reform
are Made with Pre-Reform Parameters

-12.17

Post-Reform
(5 Quarters)

20338
393
1.93

Admissions
Deaths
Mortality Rate
Recomputed Mortality Rate

1.87

1 The table reports the change in the number of survivals for a counterfactual scenarios. The lower panel reports what change
in the mortality rate is entailed by the changes in absolute numbers. For the post-reform period the number of admissions, deaths
and the mortality rate are reported for the 5 month period used in the estimation (see text for details on the sample period used
for estimation).

44

Table 13: Impact on Market Shares from an Earlier Adoption of the Reform1
Mean

S.D.

Min

25th Perc.

Median

75th Perc.

Max

0.25

4.56

-8.68

-1.25

-0.30

0.44

14.66

1 The table shows the changes in market-shares across hospitals for the counterfactual scenario of an earlier adoption of the
reform. This counterfactual is conducted by simulating choice in the pre-reform environment using post-reform preferences. This
entails a zero-sum game of market-share ”reshuffling” between hospitals. The distribution of changes over all hospitals is reported.

45

Table 14: Supply-Side Response1
Dependent Variable

Change in Case-Mix
Adjusted Mortality Rate

Change in the Elasticity
of Demand with Respect
to the Mortality Rate

-0.1296***
(0.0209)

Observations

27

1 The table reports results from a difference-in-difference OLS regression. A unit of observation is a hospital that existed both
pre- and post-reform. *** denotes statistical significance at the 1 percent level, ** denotes statistical significance at the 5 percent
level.

46

Figure 1: Map of Hospital Locations

47

Appendix
A

Implementation of the Mortality Rate Adjustment

A.1

Instrumenting Hospital Fixed Effects

We estimate

M = JT ψ + H obs γobs + H unobs γunobs + η

where M is a vector of dummies which are switched on if the patient died. JT is a matrix of hospital-time
period dummy variables and H obs and H unobs represents the patient’s observed / unobserved health status. In
order to estimate the mortality equation above we need to instrument the hospital dummies JT , which we do
using distance to the hospital (Dij ). This regression provides us with fitted values of the hospital-quarter fixed
effects, ψbjt , which are then used as the quality of care measure in the utility function, i.e. we set Zjt = ψbjt in
equation (1).
Since we allow the hospital fixed effects to vary over time, we need to instrument (Jt − 1) variables in
each time period (a set of hospital dummies minus a constant). In order to do this we need at least as many
instruments. We choose to use the distance to each hospital and a set of dummies equal to one for the closest
hospital. This yields a total of (2 · Jt ) instruments for each time period (quarter). As indicated previously, the
identifying assumption that allows us to obtain a causal effect on patient survival is the exogeneity of patients’
locations with respect to their unobserved health status.
Note that our approach uses distances to all hospitals as instruments and is therefore more flexible than the
differential-distance IV-approach used elsewhere (see for example Kessler and McClellan (2000)). If we were to
use differential distances for any of the hospitals in our sample, this would simply amount to a specific linear
combination of the various columns in our matrix of distance instruments. Instead, in our approach the impact
of the distance to each hospital is allowed to be flexibly determined by the data. Also, the differential-distance
approach is often employed using a different functional form. Specifically, differential-distance enters a choice
model which predict hospital market-shares. These predicted shares can then be treated as exogenous (i.e. used
as instruments) as they are only affected by distance. Here we instead use distance directly as an instrument.
In terms of observable health status (H obs ) we include the patient’s age, sex and co-morbidities, which are
widely considered important determinants of patient severity of illness.2 Since there is no reason to constrain
the time period over which we can estimate the impact of hospitals on health outcomes, we use 20 quarters
2 Specifically,

we use a female indicator, age of the patient, the count of co-morbidities (capped at 6), the female indicator
interacted with age, and the interaction of the female indicator with the co-morbidities count.

48

of data from 2003 to 2007.3 We estimate the production function relationship jointly for all quarters. This
is done by arranging the data in a block-diagonal fashion such that each quarter constitutes a block in the
matrix. Both the hospital dummies and the instruments are arranged in this way. Therefore distance and the
closest-hospital dummy are effectively operating as quarter-specific instruments for the hospital dummies of the
particular quarter. This yields twice as many instruments (2 × Jt ) as the number of dummies in each quarter.
γobs is restricted to be the same across all time periods, i.e. the effects of case-mix variables cannot change over
time. This regression provides us with fitted values of the hospital-quarter dummies, ψbjt , which are then used
as the quality of care measure in the utility function, i.e. we set Zjt = ψbjt in equation (1).
A.2

Implementation

In order to obtain adjusted mortality rates we run a linear probability model, regressing a dummy for death on
a set of quarter-specific hospital dummies. The hospital dummies are stacked in a block-diagonal matrix, each
block representing one quarter out of 20 quarter for the time period 2001 to 2005. The case-mix is restricted to
enter in the same way in all quarters.
Specifically, the data are arranged as follows:

X
 1



X=




CM1
X2
..

.
X20





CM2 

.. 

. 

CM20

Where CMt denotes a matrix with various variables capturing the health status of patients within a particular
quarter t. All elements in the matrix other then the matrices X1 to X20 and CM1 to CM20 are equal to zero.
The block-diagonal elements are given by:


xt
 11
 .
 ..

Xt = 
 t
xnt 1


···
..
.
···

xt1kt
..
.









t
xnt kt 


Where nt denotes the number of patients in a particular quarter t, i.e. the number of observations in the
data. kt denotes the number of hospital dummies in each quarter. This number varies across quarters because
of hospital entry, exit and mergers.
The matrix of instruments is arranged in a similar fashion:
3 This is in contrast to the demand estimation for which the institutional setup constrains us to use data only from a selected
period of time (see earlier discussion in Section (3.2).

49


Z
 1



Z=




CM1
Z2
..

.
Z20





CM2 

.. 

. 

CM20

with


zt
 11
 .
 ..

Zt = 
 t
znt 1


···
..
.
···

t
z1l
t
..
.









znt t lt 


Where nt denotes the number of patients in a particular quarter t (as in the X-matrix above). lt denotes
the number of quarter-specific instruments. In general we need the condition lt > kt − 1 to be fulfilled in all
quarters (We do not need an instrument for the constant in each quarter, i.e. the average quarterly death rate
over all hospitals). In practice we use the distance to each hospital available in the quarter and a dummy for
whether this is the closest hospital for the individual patient as instruments. This yields lt = 2 ∗ kt instruments
for each quarter.

A.3

Production Function Estimates

When estimating the production function we obtain a large set of 275 hospital-quarter fixed effects as an outcome
of the regression. It is therefore not convenient to present the parameter estimates here. Instead we give some
simple intuition for how the selection mechanism affects our results and provide several formal specification
checks.
We find that our estimated quality measure has a correlation of 0.584 with the raw mortality rate in the
data. Figure A1 displays a plot of the two measures of quality against each other. One can see that our preferred
quality measure, the case-mix adjusted mortality rate, has a larger variance than the unadjusted mortality rate.
Specifically, when comparing the scatterplot to the 45-degree line, one can see that the adjusted mortality rate
makes good hospitals look even better, and bad hospitals worse. This is precisely what one would expect from
a procedure that adjusts for case-mix selection. In the raw data better hospitals look worse than they actually
are because they attract relatively sicker patients, while the opposite is true for bad hospitals. Our adjustment
leads to a larger spread in the quality distribution by removing the selection effect.
We also provide a set of formal specification tests in Table (A1). We first test for the validity of our
overidentifying restrictions using the Sargan-Hansen overidentification test (Hansen 1982). We fail to reject
the null – that the overidentifying restrictions are valid. We then test for weak instruments using Anderson’s
50

canonical correlation likelihood-ratio test (Anderson 1984) and find that we can strongly reject the null of weak
instruments. Both tests provide statistical evidence in favor of our IV specification. However, we fail to reject
the null hypothesis of the Durbin-Wu-Hausman test, that the hospital dummies are exogenous (more precisely
that the OLS and IV estimates are not statistically different). Despite this we still favor using the case-mix
adjusted hospital mortality rates in order to obtain an appropriate measure of the quality of care.
Finally, we examine our identifying assumption that patient location is uncorrelated with health status
by analyzing whether there is any geographic variation left in unobserved health status after controlling for
observable patient characteristics. To this end we run our mortality regression without instruments and include
(in addition to the hospital dummies and patient characteristics) a set of 6-digit postcode dummies.4 We find
that the postcode dummies are not jointly significant (while the set of hospital dummies is jointly significant)
suggesting that after controlling for observed patient characteristics there is no significant amount of geographic
variation in health status left that might invalidate our IV approach.

4 This

is roughly equivalent to controlling for zipcode dummies in the case of the US. Geweke, Gowrisankaran, and Town (2003)
use a similar test with zipcodes for US data. There are 7,727 6-digit postcode dummies in our sample of 64,082 patients.

51

Table A1: Specification Test Statistics for the Mortality IV Regression
Sargan-Hansen
Overidentification Test

χ2
P-value

585.74
0.20

Anderson Canonical
Correlations Test

χ2
P-value

2,557.67
0.00

Wu-Hausman Test

χ2
P-value

562.05
0.57

Number of Hospitals
Number of Quarters
Number of Patients

28 / 29
20
64,082

(Varies Across Quarters)
(2003-2007)

52

0

Unadjusted (Raw) Mortality Rate
.05
.1

.15

Figure A1: Relationship Between Raw and Adjusted Mortality Rate

-.05

0

.05
.1
Case-Mix Adjusted Mortality Rate

53

.15

B

Data Sources

Patient Choice Data

Hospital Episodes Statistics (HES) dataset. Administrative discharge dataset
that covers all patients the underwent treatment in an NHS hospital.

Index of Multiple Deprivation

UK Census (http://www.communities.gov.uk/communities/research/
indicesdeprivation/deprivation10/).
The measure is defined at the Middle Layer Super Output Area (MSOA). There
are about 6,800 MSOAs in England with an average population of 7,200.

Patient Informedness Data

NHS Patient Choice Survey (http://www.dh.gov.uk/en/
Publicationsandstatistics/Publications/PublicationsStatistics/DH 094013)
This measure is defined at the Primary Care Trust Level (PCT). There are
about 150 PCTs in England

54

