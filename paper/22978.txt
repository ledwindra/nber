NBER WORKING PAPER SERIES

DISCRETE ADJUSTMENT TO A CHANGING ENVIRONMENT:
EXPERIMENTAL EVIDENCE
Mel Win Khaw
Luminita Stevens
Michael Woodford
Working Paper 22978
http://www.nber.org/papers/w22978

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2016

We would like to thank Randy Gallistel for sharing the code for his experiment and for discussion
of his work; Fernando Alvarez, Marty Eichenbaum, Cosmin Ilut, Filip Matejka, Alex Wolman,
and conference and seminar participants at the Barcelona GSE Summer Forum, the NBER
Summer Institute, the University of Maryland, and the JME-SNB-SCG conference for useful
comments on earlier versions of this work; and the National Science Foundation for research
support. The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
¬© 2016 by Mel Win Khaw, Luminita Stevens, and Michael Woodford. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including ¬© notice, is given to the source.

Discrete Adjustment to a Changing Environment: Experimental Evidence
Mel Win Khaw, Luminita Stevens, and Michael Woodford
NBER Working Paper No. 22978
December 2016
JEL No. D84,E03
ABSTRACT
We conduct a laboratory experiment to shed light on the cognitive limitations that may affect the
way decision makers respond to changes in their economic environment. The subjects solve a
tracking problem: they estimate the probability of a binary event, which changes stochastically.
The subjects observe draws and indicate their draw-by-draw estimate. Our subjects depart from
the optimal Bayesian benchmark in systematic ways, but these deviations are not simply the
result of some boundedly rational, but deterministic rule. Rather, there is a random element in the
subjects' response to any given history of evidence. Moreover, subjects adjust their forecast in
discrete jumps rather than after each new ring draw, even though there are no explicit adjustment
costs. They adjust by both large and small amounts, contrary to the predictions of a simple Ss
model of optimal adjustment subject to a fixed cost. Finally, subjects prefer to report "round
number" probabilities, even though that requires exerting additional effort. Each of these
regularities resembles the behavior of firms setting prices for their products. We develop a model
of inattentive adjustment and compare its quantitative fit with alternative models of stochastic
discrete adjustment.
Mel Win Khaw
Department of Economics
Columbia University
420 W. 118th Street
New York, NY 10027
mwk2126@columbia.edu
Luminita Stevens
Department of Economics
University of Maryland
7343 Preinkert Drive
College Park, MD 20742
stevens@econ.umd.edu

Michael Woodford
Department of Economics
Columbia University
420 W. 118th Street
New York, NY 10027
and NBER
mw2230@columbia.edu

1

Introduction
A central problem in macroeconomics is understanding the ways in which households

and firms respond to changing market conditions, with a particular emphasis on how the
immediate (or relatively short-run) effects of new developments differ from the adjustments
that eventually occur. When behavior is observed at the micro level, continuous decision
variables (such as the price that a firm charges for a given product) are often observed to
change only at discrete points in time, even though relevant market conditions are changing
continuously; this is often attributed to fixed costs of adjustment (‚Äúmenu costs‚Äù in the case
of prices), though there is often little direct evidence about the magnitude of such costs.
Here we present evidence for an alternative view, under which such discrete adjustment
economizes on the cognitive resources of decisionmakers.
This paper attempts to shed light on the nature of discrete adjustment dynamics using
a laboratory experiment. While there are obvious questions about the similarities between
the task faced by our subjects and those faced in settings of relevance for macroeconomic
modeling (such as firms‚Äô pricing decisions), a laboratory experiment also has important
advantages. We can treat the decisionmaker‚Äôs objective as known, to the extent that we
assume that our subjects care only about maximizing their monetary payment from the
experiment,1 and can ensure that many complications sometimes supposed to be relevant for
firms‚Äô pricing decisions are not determinants of our subjects‚Äô behavior. We can also be quite
certain about exactly what information the decisionmaker has at each point in time; not only
do we know everything that the experimental subject has had an opportunity to observe,
but we know what she ought to understand about the data-generating process, and hence
what inferences could rationally be drawn from the information presented.
Our experiment is a forecasting exercise in which one of two outcomes can occur on
each trial, and the subject must estimate the probability of a particular outcome. It is
explained that the underlying probability will shift from time to time, but also that it is
likely to remain the same for many successive trials, offering an opportunity to estimate the
current probability from observation of past draws. This kind of exercise allows us to test
1

In the experiment reported here, the subjects are paid for their performance, and we take care to explain
the strategy that would maximize the expected monetary reward.

1

alternative theories of expectation formation, including the familiar benchmark of ‚Äúrational
expectations.‚Äù At the same time, the subjects‚Äô problem can be viewed as an example of
a more general class of problems, in which there is a continuous decision variable (here,
the announced probability estimate), with the payoff from a given action depending on the
current value of a continuous state variable, which varies over time (so that it is necessary to
continue monitoring), but is sufficiently persistent to make attempts to monitor the changing
state variable worthwhile. Viewed in this way, it is an example of the same basic kind of
decision problem faced by a firm that must set a price for its product, where the profits
obtained by charging a given price depend on other state variables (demand conditions and
factor costs) that fluctuate over time.
In fact, despite the differences in the setting, our experimental data exhibit some notable (and puzzling) features of data on individual prices, as we discuss further below. In
particular, our subjects usually leave their decision variable unchanged for periods of time,
despite the receipt of many new pieces of information in the meantime, and despite having
a continuum of possible responses at each point in time. Since there are no true (external)
adjustment costs in our problem, and subjects have (and we believe, are able to understand)
all of the information needed to calculate the optimal Bayesian estimate at each point in
time, we conclude that their failure to track the optimal Bayesian estimate more closely
reflects imperfect attention, limited memory or related cognitive limitations.2
We further demonstrate that our data are in a number of important respects consistent
with the predictions of a particular quantitative model of inattentive choice. This model
generalizes the model of inattentive discrete adjustment developed in Woodford (2009), most
importantly by allowing not only the timing of adjustments but also the choice of where to
set the decision variable conditional on adjustment to be inattentive. We compare the
quantitative fit of our model with other models of random discrete adjustment, such as the
‚Äúgeneralized Ss model‚Äù of Caballero and Engel (1993, 2007) and the optimizing model with
2
Our experimental design differs importantly from that of Magnani, Gorry and Oprea (2016), who study
how well an ‚ÄúSs‚Äù model fits laboratory data on the timing of adjustments. Their experimental setup imposes
an external fixed cost of adjustment, in order to ensure that adjustment will be discrete, but considers
whether adjustments are optimally timed; we are instead interested in observing discrete adjustment even
when subjects are free to adjust the slider at any time. Their setup also requires that when adjustment
occurs, the decision variable is moved to exactly the currently optimal state, whereas we are interested in
where the slider will be set when subjects are free to set it anywhere.

2

random fixed costs of adjustment proposed by Dotsey, King and Wolman (1999) and Dotsey
and King (2005). While the latter models describe the adjustment dynamics that we observe
better than a simple ‚ÄúSs model,‚Äù we find that the rational inattention model outperforms
these alternatives significantly.
Section 2 describes our experiment. Section 3 gives an overview of some of the salient
features of the behavior that we observe, focusing on ways in which subjects‚Äô behavior
resembles or differs from the predictions of the ideal Bayesian (or rational expectations)
benchmark. Section 4 discusses the extent to which various models of discrete adjustment
that have been common in the macroeconomic literature, especially the literature on price
adjustment, can account for our data. Section 5 offers a concluding discussion.

2

The Experimental Design
Our laboratory experiment follows the setup of Gallistel et al. (2014), who study how

well subjects can predict probabilities. We modify their experiment in a number of respects,
because of the different focus of our study, as discussed further below. The subjects‚Äô task is
to estimate the probability that the next draw is a green ring from a box with both green
and red rings. The subjects draw rings with replacement from the box and indicate their
draw-by-draw estimate.
Figure 1 shows a screenshot of the experiment. The screen displays the box with a hidden
number of red and green rings on the left. The slider at the bottom indicates the subject‚Äôs
estimate on the current trial, pÃÇt , with the number in percentage points displayed above the
bar. The box on the right side of the screen displays 1,000 rings that also depict the subject‚Äôs
estimate visually. Whenever the subject moves the slider, this box is adjusted in real time
to reflect the probability indicated by the slider position. The subject begins with a guess
and adjusts the position of the slider to indicate his or her estimate. Each time the subject
clicks the NEXT button, a new ring is drawn randomly from the box and displayed on the
screen. After each ring draw, the subject‚Äôs cumulative score is updated and displayed at the
top of the screen. The subject may then adjust his or her forecast or leave it unchanged,
before drawing the next ring. This process is repeated until the session ends, after 1,000 ring
3

Task: Subjects estimate the hidden probability parameter of
a stepwise non-stationary Bernoulli process outcome by
outcome
!

Figure 1: Experiment screenshot. The box of rings contains an unknown number of green and red
rings. Subjects use the mouse to adjust the slider to their current estimate of the probability that
the next draw from the box is a green ring. Their estimate is displayed numerically above the slider
and visually both using the slider and in the box on the right side of the screen. Subjects click
the NEXT button to draw another ring from the box of rings on the left. After each draw, the
subject‚Äôs cumulative score is updated and displayed at the top of the screen. Each session consists
of 1,000 ring draws.

draws.
For each session, the subject is rewarded with a fixed payment of $10 plus a variable
payment, equal to 2¬¢ √ó the subject‚Äôs cumulative score. For each trial t, if the subject sets
the slider at pÃÇt and the ring drawn is st (equal to 1 for a green ring and 0 for a red ring),
then the reward is
r(pÃÇt ; st ) = 1 ‚àí (st ‚àí pÃÇt )2 .

(1)

The total score is the sum of the rewards for all trials in a session. This payoff structure
generates a non-negative score that is increasing over the life of the session, to avoid loss
aversion. If one believes that a green ring will be drawn with probability pt (however this
forecast might be formed), then the expected reward, p[1 ‚àí (1 ‚àí pÃÇ)2 ] + (1 ‚àí p)[1 ‚àí pÃÇ2 ], is
maximized by setting the slider at pÃÇt = pt .3 The monetary reward is only a function of the
3

We assume that the subjects are risk neutral for the small monetary rewards involved in the experiment.
This kind of quadratic scoring rule is often used in experiments intended to elicit probability beliefs, for the
reason given here (e.g., McKelvey and Page, 1990). In our case, we are not primarily interested in eliciting
subjects‚Äô beliefs about the probability, but simply in their performance on a tracking problem. However,
choosing a task for which the optimal strategy is to report one‚Äôs estimate of the probability makes it easy

4

history of the subject‚Äôs behavior and the sequence of draws thus far. It reveals no information
about the number of green rings in the box, either past or present. Before the start of the
sessions, we explained to the subjects both the reward function and the optimal decision
rule, using both written and verbal instructions.
From time to time, the box of rings is replaced by a new box with a different probability of
drawing a green ring. The probability is initially drawn from a uniform distribution between
0 and 1. After each ring draw, there is a constant probability Œ¥ = 0.5% of a regime change.
If there is a regime change, the new proportion of green rings in the box is an independent
draw from the uniform distribution on the unit interval. The subjects are not told when
a change in the box occurs, but they are told in advance that the box might change, and
they know the probability of a regime change and the distribution from which the new box
is drawn. The frequency of regime changes is small enough relative to the number of noisy
observations that subjects receive, to enable them to learn the underlying probability. But
it is nonetheless changing, so that the subjects should continuously take into account the
fact that there may have been a regime change.
It is important to note that the timing of slider adjustments is completely up to the
subject. We also allow the subjects to control the speed at which they draw rings so that
they may choose how much attention to give to the task, rather than forcing them to make
decisions within an externally imposed time limit. This setup allows us to investigate the
extent to which the subjects choose to update their forecast every time they obtain a new
piece of information. There is no explicit penalty for constant adjustment and new information arrives frequently, which puts the finding of discrete adjustment at odds with a large
set of models, as we discuss in the next section.
As noted above, this design is based on the experiment reported by Gallistel et al. (2014).
We have modified their experimental design in a number of respects, however, to make it more
suitable for our concerns. First, we add a monetary reward that varies with performance (as
discussed above), and display the subject‚Äôs cumulative score in real time, so that they can see
how their strategy affects their reward. The reward function allows us to have more control
for us to explain the task to subjects, and to make sure that any departures from the rational benchmark
do not result from misunderstanding of the optimal strategy.

5

over the objective of our subjects, rather than having to make assumptions about what they
might be maximizing. In addition, we simplify the data-generating process (making each
new choice of the underlying probability pt independent of the previous history), not only
in order to simplify the Bayesian inference problem (analyzed in Appendix A), but more
importantly so that it would be simple for us to fully explain the data-generating process
to subjects. Indeed, another of the important changes in our procedure is to make a point
of explaining all features of the setup, data generating process, and reward function to the
subjects.
One of our most important changes is to modify the functioning of the slider, so that
subjects can only move it continuously, by dragging it with their mouse. The slider in the
experiment of Gallistel et al., 2014, would move in discrete increments of exactly 0.1 to
the left or right if the subject clicked on the slider bar to the left or right of the current
slider position. Because of our interest in subjects‚Äô spontaneous tendency toward discrete
adjustment even when nothing about their decision problem would make discrete adjustment
desirable, it is important that movement in large discrete jumps not be more convenient than
continuous adjustment of the slider. (It is for this same reason that we want subjects to
report their probability estimate using a slider, rather than typing a number; the latter kind
of reporting would make round numbers more convenient, and so provide a possible motive
for discrete adjustment.) We also eliminate the feature of the Gallistel et al. experiment
that asked subjects to press a button at those points in time when they believed that the
underlying probability had changed. While eliciting more aspects of subjects‚Äô beliefs might
seem desirable, this question was posed in a way that required subjects to respond only at
discrete points in time, rather than continuously adjusting an estimate, and we feared that
this could lead them to also adjust the slider only at discrete points in time, for a reason
that would be inapplicable in the case of actual firm decisions such as price-setting.
While we retain the feature of the Gallistel et al. display that shows a visual representation of the subject‚Äôs current probability estimate, we add a numerical readout of the estimate
above the slider, allowing each subject three different ways of seeing what estimate they are
choosing: the location of the slider relative to the endpoints (marked as 0% and 100%), the
visual display of a box of red and green rings with the relative proportions implied by the
6

estimate, and the numerical readout of the estimate (accurate to four digits). We think it
is important to be sure that subjects can understand the probability that they are choosing
without necessarily understanding or thinking in terms of decimals; other experiments have
found that probabilities are difficult to interpret and to communicate without some visual
representation. The box showing them their current estimate is intended to help the subjects
to visualize exactly what they are forecasting. On the other hand, some subjects may want
to know what probability they are setting with more precision than allowed by the visual
representations alone, and for these reasons, we add the numerical readout.4
Our setup is designed to minimize adjustment costs and to eliminate reasons for habit
preferences, so that there would be no reason for subjects not to constantly adjust their forecasts in the absence of cognitive limitations. Additionally, we fully control the information
that subjects have at each point in time, allowing us to test to what extent subjects are
making use of the information that is available to them. Finally, by controlling the true data
generating process and what our subjects know about it, we control what the correct prior
is. Thus we do not need to make conjectures about either the decisionmakers‚Äô objectives or
the information that is available to them, and we can focus instead on what our results indicate about potential cognitive limitations. Since we take care to explain all features of the
setup to the subjects, they are provided with all of the information needed to form a correct
forecast (in accordance with the RE hypothesis), and we can compare their performance to
that of an ideal Bayesian observer.
An important question that arises in any experimental study is that of external validity:
To what degree can we expect the behavioral regularities that we uncover in the experimental
data to persist in other economic environments? The answer to this question depends on
the degree to which the conditions that are relevant remain relatively unchanged across
environments. In our particular setting, even though we place our subjects in a simple
environment, the task that they face is an example of a very general class of tracking problems.
Formally, it is analogous to the problem of a pricing manager who sets the price of a product
4

This modification of the experimental design made it possible for us to observe a cognitive ‚Äúround
number‚Äù bias, discussed below, that did not appear in the data collected by Gallistel et al. (2014), perhaps
because their subjects were unable to observe their own probability estimates with the precision with which
our subjects could.

7

and whose task is to track the profit-maximizing price as closely as possible, subject to any
frictions and limitations that might impede adjustment. There are some key features of
that problem that also apply to our experimental task: it features a continuous decision
variable, it generates profits that depend on other state variables (demand, costs) that
fluctuate continuously over time, and finally, the manager making the decision receives a
steady stream of information about product demand, competitive pressures, cost conditions,
the macroeconomy, and so on, and incorporates these factors in the price of the product.
We conducted the experiment with 11 subjects, who each completed 10 sessions over the
course of several days. Each session had 1,000 ring draws and on average lasted 27 minutes.
The subjects were undergraduate and Master‚Äôs students at Columbia University. At the
start of each session, the subjects received both written and verbal instructions and they
completed a 15-minute practice session to familiarize themselves with the task.

3

Features of Observed Behavior
Figure 2 shows an example of a typical session for a particular subject. The figure

plots the true hidden probability and the subject‚Äôs forecast, compared to that of a Bayesian
decisionmaker who makes full use of all the information available.5 The figure illustrates key
features of the data that we document more systematically below. Both the subject and the
benchmark Bayesian decisionmaker track the hidden probability quite well, and they detect
changes in this probability relatively quickly. However, one major distinction is that while
the Bayesian forecast changes by a small amount after each ring draw, the subject keeps his
estimate unchanged for variable periods of time, and often adjusts by large amounts. On
average, the subject makes much larger and more infrequent adjustments than the Bayesian
decisionmaker. This discreteness arises despite the fact that there is no discreteness in the
set of available actions, nor any explicit cost of adjusting the slider in response to the stream
of new information.
5

The Appendix presents the Bayesian inference problem.

8

1

p‚àót
pÃÇt
pt

Forecast

0.8

0.6

0.4

0.2

0
0

100

200

300

400

500

600

700

800

900

1000

t
Figure 2: Experiment data for subject 11, session 10. The benchmark Bayesian forecast (blue
dashed line) and the subjective estimate (magenta solid) are plotted against the true hidden probability (in black).

3.1

Overall Accuracy

Our subjects demonstrate the ability to track the varying state, although less well than
would be possible given the available information. Figure 3 compares the scores of the
subjects and the Bayesian decisionmaker to two polar benchmarks: the complete information
case in which the subject knows the hidden probability at all times, and the no information
case in which the subject is fully rational but does not see any rings and therefore sets the
slider to the unconditional estimate of 0.5 on all draws. For each observer type, the figure
shows 11 bars, each corresponding to the realized draws seen by each of our 11 subjects
across all unique sessions.6
All subjects outperform the no information benchmark, indicating that they are tracking
the state at least to some extent. They all underperform the Bayesian decisionmaker: on
6

As described in a later section, some of our subjects saw repetitions of the same ring draws for some of the
sessions. In the results presented in this and later sections, we aggregate numbers for unique, independently
drawn sessions only, so as not to over-represent certain realized probabilities. The Appendix presents results
for the full sample, including all the repeated sessions. Results are very similar across the two samples.

9

900
880
860

Average Points

840
820
800
780
760
740
720
700

True Pr.

Bayesian

Observed

Unconditional

Figure 3: Experiment data for all unique sessions. The scores are broken down by subject. ‚ÄúTrue
p‚Äù refers to the score that each subject would have received, given the realized ring draws, had they
known the underlying probabilities at all times. ‚ÄúBayesian‚Äù refers to the scores that would have
been received by each subject, given the realized ring draws, had they acted like the fully rational
optimal Bayesian decisionmaker. ‚ÄúUnconditional‚Äù refers to the scores received under a constant
forecast equal to the unconditional prior of 0.5.

average, the subjects‚Äô scores are 2.5% lower than that of the Bayesian observer. There is
considerable heterogeneity in performance. One driver of this heterogeneity is the noise in
the realized draws, which determines the difficulty of the forecasting problem. This can be
seen in the differences in scores in the full information benchmark. Another driver of the
heterogeneity in scores is the heterogeneity in behavior across the subjects. Some subjects
(such as subject 3) are much closer to the fully rational Bayesian benchmark than others
(for example, subject 8).

3.2

Forecast Bias

A relatively simple way of characterizing the degree to which behavior resembles or differs
from the rational (perfect Bayesian) benchmark is to ask to what extent forecasts correctly
track the true state on average. One familiar diagnostic considers whether forecasts are unbiased, in the sense that E[pÃÇt |pt ] is equal to pt , the true state. Gallistel et al. (2014) emphasize
the extent to which their subjects are close to perfectly unbiased, though they compare the

10

0.8

0.8

0.6
0.4
0.2
0

Mean Forecast

Mean Bayes

1

0.6
0.4
0.2

0

0.5
True p

0

1

1

1

0.8

0.8

Mean True p

Mean Forecast

1

0.6
0.4
0.2
0

0

0.5
Bayes Optimal p

0.5
True p

1

0

0.5
Forecast p

1

0.6
0.4
0.2
0

1

0

Figure 4: Measures of forecast bias. Upper left: E[pÃÇ|p] versus p. Upper right: E[p‚àó |p] versus p.
Lower left: E[pÃÇ|p‚àó ] versus p‚àó . Lower right: E[p|p‚àó ] versus p‚àó .

median forecast conditional on the true p, rather than the mean.7 Robinson (1964) had similarly reported no significant forecast bias (using the more conventional definition based on
the conditional mean) for any value of p, and this had been confirmed by additional studies
summarized in Peterson and Beach (1967).
We examine this question in the case of our data in the upper left panel of Figure 4. We
pool the data from all unique sessions, and sort the data into 21 bins centered on multiples of
0.05, according to the true probability pt on that trial. For each bin, the plot shows the mean
slider position pÃÇt across those trials (as an x), together with the inter-quartile range of slider
positions associated with that bin (shown as a vertical interval).8 As in the corresponding
figure in Gallistel et al.,9 the diagonal (i.e., the predicted location of the means under the
7

Ricci and Gallistel (2016) report a similar finding in a variant of the experiment of Gallistel et al (2014)
with a different data-generating process.
8
The horizontal coordinate of the x that is plotted for each bin is the mean value of pt for the trials
in that bin. Under the hypothesis that E[pÃÇt |pt ] = pt for all values of pt , we should also observe that
E[pÃÇt |pt ‚àà bj ] = E[pt |pt ‚àà bj ], for any bin bj , i.e., that the X for bin bj should lie on the dashed diagonal line.
9
See their Figure 6.

11

Regression: y = Œ± + Œ≤x + 
y x
Œ±
Œ≤
F-stat
pÃÇ p
0.085
0.850
3273
(0.001) (0.002)
0.052
0.893
5674
p‚àó p
(0.001) (0.001)
0.087
0.803
6112
p pÃÇ
(0.001) (0.002)
pÃÇ p‚àó 0.034
0.955
669
(0.001) (0.002)
TABLE 1: Regression tests of forecast bias, with alternative choices of the variables y and x,
corresponding to the four panels of Figure 4. Standard errors are shown in parentheses below
the regression coefficients. The F statistic in each case is for a test of the null hypothesis
that Œ± = 0 and Œ≤ = 1, and under the null hypothesis should be distributed as F (2, 90907).
All null hypotheses have p-values of less than 10‚àí288 .
hypothesis of unbiasedness) is contained within the IQR in nearly every case, over the entire
range of true probabilities. However, it is not quite right to conclude from this that the
average slider position, conditional on any true state, is exactly that value. As indicated in
Table 1, a linear regression of pt on pÃÇt , using our pooled data, yields a regression line with
a slope slightly less than 1; and the null hypothesis that the regression line is the diagonal
can be rejected with a p-value that is indistinguishable from zero (at the precision allowed
by Matlab).
Unbiasedness in this sense is not, however, the only hypothesis of interest, and is not
even a prediction of rationality. Even an ideal Bayesian observer would not be able to track
the hidden true probability perfectly, and as shown in the upper right panel of the figure, the
forecasts of an ideal Bayesian observer would not be ‚Äúunbiased‚Äù in the sense just mentioned:
we should not expect E[p‚àót |pt ] to equal pt . Because of noise in the series of ring draws as
an indication of the true probability, the ideal observer would on average over-estimate the
probability when pt is low, and under-estimate it when pt is high. Bayesian rationality instead
would require that (under the prior implied by our data-generating process) E[pt |p‚àót ] = p‚àót .
In fact, even if subjects do not produce fully optimal forecasts (due for example to memory
limitations), if their forecasts are Bayes-rational conditional on the information used to make
the forecast, they should satisfy the property that E[pt |pÃÇt ] = pÃÇt for all slider positions pÃÇt . We
check for this property in the lower right panel of Figure 4, where the trials are now binned
12

according the value of pÃÇt and the mean value of pt associated with each bin is indicated
by the vertical coordinate of the x. This rationality condition is not grossly rejected; the
diagonal falls within the IQR (if only barely) for each of the bins. However, we note a fairly
clear pattern in the figure, with the mean true p above the forecast whenever pÃÇ is below 0.3,
and below the forecast whenever pÃÇ is above 0.65. And indeed, a regression of pt on pÃÇt using
our pooled data yields a slope coefficient significantly below 1, as shown in Table 1.
The pooled data from our subjects is instead more consistent with an alternative hypothesis, namely that subjects‚Äô forecasts are distributed around the rational forecast, and
equal to it on average ‚Äî that is, that E[pÃÇt |p‚àót ] = p‚àót for all values of p‚àót . This is related to
the hypothesis of unbiasedness that Gallistel et al. test, but recognizes that we can at best
expect subjects‚Äô forecasts to reflect the optimal Bayesian estimate of the state, and not the
hidden state itself. It is also the hypothesis of ‚Äúrational expectations‚Äù as originally proposed
by Muth (1961), though that term has since come to be associated with the hypothesis of
full Bayesian rationality, since the work of Lucas (1972).
This hypothesis is tested in the lower left panel of Figure 4. We see that when the data
are binned according to the value of p‚àót (rather than by the value of pt , as in the upper left
panel), the conditional mean indicated by the x is close to the diagonal for all bins. We can
nonetheless reject that the hypothesis holds exactly in our data through a regression test,
as shown in Table 1; but note that in this case the F statistic is less gigantic than for the
other null hypotheses considered in the table.
Note that even to the extent that this last hypothesis is accepted as an approximate
characterization of our data, this does not mean that our subjects‚Äô forecasts are Bayesrational; if they (always) were, not only would the x marks be exactly on the diagonal, but
the IQR would be an interval of zero length for each bin in the lower left panel of Figure
4, which is not the case. Subjects‚Äô forecasts can be more accurately characterized as equal
to the rational forecast plus random noise (a characterization that also explains the slope
less than 1 in the lower right panel). The extent to which forecasts are consistent with this
simple hypothesis is discussed further below.

13

3.3

Departures from Bayesian Rationality

We now look more closely at some of the ways in which our subjects‚Äô forecasts differ from
the predictions of the rational benchmark. We then use these observations to motivate our
subsequent consideration of a variety of adjustment models.
3.3.1

Stochasticity

Our subjects‚Äô deviations from the Bayesian benchmark are not simply due to the use
of some boundedly rational but deterministic rule (as for example in typical ‚Äúadaptive expectations‚Äù models). Instead, there is a random element in the subjects‚Äô responses to any
given history of evidence.10 This stochasticity is at odds with traditional economic models
in which optimization rules out randomization, as well as with many models of behavioral
heuristics.
1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2
Session 2
Session 6
Session 9

0.1

0
0

100

200

300

400

500

600

700

800

900

1000

Figure 5: Experiment data, subject 1 forecasts, all repeated sessions.

Our observation above that certain statistics can be explained by a hypothesis that
subjects‚Äô forecasts are equal to the optimal Bayesian forecast plus random noise has already
suggested a model of behavior that incorporates random noise. However, the mere fact that
the interquartile ranges shown in the lower left panel of Figure 4 are of non-zero length does
not in itself prove that subjects‚Äô behavior is random; their forecasts might be deterministic
10

Magnani, Gorry and Oprea (2016) reach a similar conclusion in the context of a somewhat related task.

14

functions of some aspect of the sequence of rings that they have seen that is not perfectly
captured by the value of p‚àót (though highly correlated with it). More convincing evidence
of stochasticity is provided by sessions in which subjects experienced precisely the same
sequence of ring draws as they had observed on a previous occasion.

Figure 6: Experiment data, all subjects, all repeated sessions. (a) Individual forecast series, (b)
Bayesian posterior mean in blue, median subject forecast and interquartile range in red, (c) Bayesian
posterior variance in blue (left axis) and subjective forecasts interquartile range in red (right axis).

In 20 out of our 110 sessions, we showed the subjects the same sequence of rings. These
repeated sessions were never conducted on the same day for the same subject, and there
is no evidence that subjects were able to recognize the repetition. We find substantial
heterogeneity in different subjects‚Äô responses to the given ring sequence, but also in the
responses of the same subject across the repeated sessions. Figure 5 shows the forecasts of
subject 1 across the repeated sessions. The three forecast series are correlated, since they
are tracking the same sequence of realized rings, but there is also considerable dispersion.
15

The top panel of Figure 6 shows the cross-sectional dispersion across all 20 repeated
sessions. Throughout the session, there is a wide range of forecasts that depart ‚Äì at times
substantially ‚Äì from the rational expectations benchmark. Cross-sectional dispersion has also
been documented in the pricing literature (see Kaplan and Menzio, 2015, for a recent addition
to this literature). While the price setting literature has largely focused on external frictions
(limits to arbitrage such as trade barriers and search costs) as the source of such dispersion,
our experimental data generates this dispersion in the absence of any such frictions.
Despite the considerable dispersion, the aggregate behavior over the 20 repeated sessions
tracks the RE prediction fairly well, as shown in the middle panel of the figure, which plots
the Bayesian forecast against the median slider position. This evidence, while at odds with
the classic definition of rational expectations (Lucas (1972)), does provide some support
for Muth‚Äôs (1961) hypothesis that while individual behavior may deviate even substantially
from rational expectations, it averages out to the truth. It is important to emphasize,
however, that even though the aggregate appears to track the RE forecast, this finding does
not mean that the RE forecast suffices for macroeconomic analysis. The heterogeneity of
responses implies greater population dispersion in beliefs, and therefore actions, than would
be predicted by the RE model. In turn, this dispersion often matters for welfare, as well as
for statistics like the volume of credit or trade.
We also uncover evidence of endogenous dispersion. The heterogeneity in forecasts does
not simply reflect exogenous noise in decisions, independent of the state. Instead, the dispersion of forecasts is higher when objective uncertainty is higher, as measured by the Bayesian
posterior variance. We show this relationship in the bottom panel of the figure: when the
Bayesian posterior variance spikes, the cross-sectional dispersion also rises. This evidence
suggests that variation in cross-sectional dispersion may be a reasonable proxy for uncertainty shocks, as it is sometimes used in the literature on uncertainty.
3.3.2

Discrete Adjustment

In our experiment, subjects should adjust their forecast after each new ring draw, since
each draw provides additional information about the hidden probability that subjects seek
to track. Instead, our subjects adjust with various lags, even though there are no explicit
16

costs of adjustment. This discreteness is common to all of our subjects, albeit to varying
degrees.
5

1800

√ó10 6

4

4.5

1600

√ó10 5

3.5

4
1400

3
3.5

1200

2.5

3
1000

2

2.5
800

2

1.5

600

1.5
1
400

1

200

0.5

0.5

0

0
1

3

10

32

100

0
1

320

(a) Observed Spell Lengths

3

10

32

100

320

1

(b) Nielsen Spell Lengths

4

3

10

32

100

320

(c) Nielsen Spell Lengths (Filtered)

√ó10 6

4.5

√ó10 5

1200

4

3.5
1000

3.5
3
3

800

2.5
2.5
2

600

2
1.5
1.5

400

1
1
200

0
‚àí1

0.5

0.5

0
‚àí0.8

‚àí0.6

‚àí0.4

‚àí0.2

0

0.2

0.4

0.6

0.8

(d) Observed Adjustment Sizes

1

0
-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

0.8

(e) Nielsen Price Changes

1

-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

0.8

1

(f) Nielsen Price Changes (Filtered)

Figure 7: Discreteness. (a) Distribution of the number of ring draws between adjustments (all
unique sessions). (b) Distribution of the number of weeks between price changes (AC Nielsen
Retail Scanner data; y-axis truncated). (c) The same distribution, but removing transitory price
changes. (d) Distribution of the size of changes in the slider position, counting only trials on which
the slider is moved (all unique sessions). (e) Distribution of the size of price changes, conditional on
adjustment (AC Nielsen Retail Scanner data). (f) The same distribution, but removing transitory
price changes.

As shown in Figure 7, subjects exhibit a wide range of wait times between adjustments,
and there is no evident pattern of time-dependence. There is also considerable variation in
the size of the slider adjustments conditional on adjustment, as shown by the distribution of
adjustment sizes in the lower left panel of the figure. Both of these features of our data diverge
from the predictions of the Bayesian benchmark.11 At the same time, the distribution of
11

They are also both features of subjects‚Äô behavior in the similar experiment of Gallistel et al., (2014).
Ricci and Gallistel (2016) find similar behavior in a variant experiment in which the underlying probability
drifts continuously, rather than jumping on infrequent discrete occasions. This suggests that the discrete
slider adjustments that we observe are not an artifact of our subjects‚Äô knowledge that the true underlying
probability moves in discrete jumps.

17

adjustment sizes is also inconsistent with the bimodal distribution that would be predicted
by a simple ‚ÄúSs model‚Äù of optimal adjustment. Such a model would predict no small
adjustments and also no adjustments larger than a certain magnitude, since one would never
drift that far away from the optimal forecast.
The distribution of step sizes and that of spell lengths resemble instead the distributions
of product-level price changes in micro price data. For comparison, the right panels of
Figure 7 show the distribution of the size of price changes and of the periods between price
changes for products in the AC Nielsen Retail Scanner data, using both raw prices and
regular prices, which exclude transitory price changes. Both our experimental data and the
price data generate a distribution for the size of adjustment that is leptokurtic. However,
in our experiment, this feature arises spontaneously, as a result of the subjects‚Äô behavior,
rather than for the reasons proposed in the pricing literature, such as leptokurtic shocks
or opportunities to adjust that depend on other decisions (such as the repricing of other
products).
3.3.3

Round-Number Bias

Our subjects also exhibit a bias towards selecting ‚Äúround numbers‚Äù when choosing where
to position the slider. As shown in Figure 8, subjects are more likely to estimate the hidden
proportion of green rings using numbers that are multiples of 0.05. This bias is common
to all of our subjects, to varying degrees. Subject 2 is a particularly stark example of this
behavior, as illustrated in the right panel of the figure.
This discreteness in the chosen slider positions is another significant departure from the
RE benchmark, which would predict a flat distribution. It occurs even though there is
no discreteness in the distribution from which the hidden probability is drawn (which is
continuous uniform between 0 and 1), or in the set of available actions (the mouse moves
continuously12 ). There is also no sense in which the experiment makes it either easier or more
profitable to choose certain slider positions over others. Nevertheless, our subjects appear to
exert considerable effort to set the slider at or near these preferred numbers. We conclude
The step size of the mouse is 10‚àí7 , hence much finer than even the estimate that is displayed on the
subjects‚Äô screen (which is on the order of 10‚àí4 )
12

18

0.012

0.08

0.01

0.07
0.008

0.06
0.05

0.006

0.04
0.03

0.004

0.02
0.002

0.01
0

0
0

0.1

0.2

0.3

0.4

0.5
0.6
Forecast p

0.7

0.8

0.9

0

1

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Forecast p

(a) Full sample

(b) Subject 2

Figure 8: Experiment data. Distribution of the subjects‚Äô slider position choices for (a) all unique
sessions and (b) the unique sessions for subject 2.

that these round decimal numbers offer some cognitive advantage that compensates for the
effort needed to select them.
1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

Session 2
Session 7

0
0

100

200

300

400

500

600

700

800

900

1000

Figure 9: Experiment data, Subject 2 forecasts for repeated sessions.

This hypothesis is reinforced by the patterns in Figure 9, which shows the two repeated
sessions for subject 2: during the first session, the subject repeatedly moves the slider to 0.2
and 0.8, while during the second session, the subject largely alternates between 0.3 and 0.7.
This pattern suggests that there is some cognitive advantage to picking a small number of
slider values to consider.
19

The evidence for round number bias also mirrors the patterns found in product-level
retail price data, where prices alternate among a small set of values for fairly long periods
of time (Eichenbaum et al., 2011, and Stevens, 2015), and where 9 is the most frequently
used price-ending for the penny, dime, dollar and the ten-dollar digits, and where multiples
of dimes, dollars and ten-dollars are the most common price changes (Levy et al., 2011).

4

Modeling Discrete Adjustment
We study the degree to which our experimental data conform to the predictions of a

variety of different possible models of discrete adjustment of the decision variable, with a
particular focus on types of models that have been popular in the macroeconomic literature
on price adjustment. Given the evidence that subjects do not adjust continuously, it is useful
to decompose a model of discrete adjustment into two parts: first, a criterion that determines
when the slider will be adjusted, and second, a criterion that determines where the slider
position will be set, conditional on adjustment. We consider a variety of alternative models
of each of these decisions.

4.1

‚ÄúGap-Based‚Äù Models of Adjustment

Under the Bayes-optimal benchmark, no ‚ÄúBayesian gap‚Äù ‚àÜt ‚â° p‚àót ‚àí pÃÇt should ever exist.
This is plainly not the case in our experiment, as we have documented in Section 3. One
might however still hypothesize that the size of the ‚ÄúBayesian gap‚Äù should determine whether
there is sufficient reason to adjust the slider. Such a simple rule of thumb corresponds to
a myopic form of rational choice in which the decisionmaker cares only about the expected
payoff on the current trial when deciding whether to adjust and where to adjust. If the
decisionmaker must pay a fixed cost to adjust, then it would be optimal to plan to set pÃÇt equal
to p‚àót conditional on adjusting, and to adjust if and only if the expected payoff reduction from
non-adjustment exceeds the adjustment cost. The payoff reduction is proportional to the
square of the Bayesian gap, thus myopic rational choice with a fixed cost implies adjustment
of the slider if and only if the Bayesian gap has a large enough absolute value.
More generally, we might hypothesize that adjustment should occur if and only if the gap
20

1

0.9

0.8

0.16

0.8

0.7

0.14

0.7

0.6

0.12

0.6

0.5

0.4

Prob(Change)

0.2

0.18

Prob(Change)

Prob(Change)

1

0.9

0.1

0.08

0.5

0.4

0.3

0.06

0.3

0.2

0.04

0.2

0.1

0.02

0.1

0

0

-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

Bayes p (t+1) - Forecast p (t)

(a) Equal-width bins

0.8

1

0
-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

Bayes p (t+1) - Forecast p (t)

(b) Equal-weight bins

0.8

1

-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

0.8

1

Bayes p (t+1) - Forecast p (t)

(c) Polynomial

Figure 10: Hazard functions for the slider adjustment probability as a function of the Bayesian gap.
(a) Nonparametric empirical hazard plotting the fraction of trials on which adjustment occurs, for
each range of values of the gap, with equal-width bins. (b) Similar plot, but with boundaries chosen
so that each bin contains an equal number of observations. (c) The best-fitting logistic-polynomial
hazard function. (Coefficients given in Table 2.)

is either above some upper threshold or below some lower threshold, as in an ‚ÄúSs model.‚Äù
Even more generally, we might suppose, as in the ‚Äúgeneralized Ss models‚Äù of Caballero and
Engel (1993, 2007), that there are no sharp thresholds, but that instead the probability of
adjustment of the slider in any period is given by some continuous function of the Bayesian
gap Œõ(‚àÜt ), non-increasing for ‚àÜ < 0 and non-decreasing for ‚àÜ > 0. In the case that this
‚Äúhazard function‚Äù Œõ(‚àÜ) is symmetric (i.e., Œõ(‚àí‚àÜ) = Œõ(‚àÜ) for all ‚àÜ), a generalized Ss model
could also be interpreted as resulting from myopic optimization, under the assumption of a
cost of adjustment that is a random draw from a continuous distribution, as in the randommenu-cost models of Caballero and Engel (1999) and Dotsey, King and Wolman (1999).
Figure 10 shows the fraction of trials on which the slider is adjusted, if the data are sorted
into bins according to the value of the Bayesian gap at the time of the decision whether to
adjust the position. In panel (a), the bins are chosen to be of equal width. This leads to
a possibly misleading sense of the degree to which the hazard function is well-estimated in
the case of more extreme Bayesian gaps, since the more extreme bins contain many fewer
observations than do the central bins; panel (b) instead sorts the data into 10 bins each
containing the same number of observations, with the boundaries of each bar indicating the
boundaries of the corresponding bin. Both versions of the figure are consistent with the
existence of a non-uniform hazard function, which is furthermore decreasing for ‚àÜ < 0 and
increasing for ‚àÜ > 0, as assumed by Caballero and Engel. However, our data do not appear
21

to support the further assumption, often made in the empirical work of Caballero and Engel,
that the hazard falls to zero at least when ‚àÜ = 0, if not over some larger ‚Äúzone of inaction.‚Äù
These plots suggest that there is at least some degree of ‚Äústate-dependence‚Äù of the decision
to adjust the slider. We can quantify the degree of state-dependence by computing how
much the likelihood of our data is increased by allowing the adjustment hazard to depend
on the Bayesian gap. If we assume that the adjustment decision Œ±t (taking the value 1
if the slider is adjusted, and zero otherwise) is an independent draw on each trial from a
Bernoulli distribution with probability Œõ(‚àÜt ) of adjustment, then the log likelihood of the
data sequence {Œ±t } is equal to
LL =

X

{Œ±t log Œõ(‚àÜt ) + (1 ‚àí Œ±t ) log(1 ‚àí Œõ(‚àÜt ))} .

(2)

t

We consider parametric families of possible hazard functions Œõk (‚àÜ; Œ∏), where Œ∏ is a vector
of k parameters, and we choose both the family of models (the value of k) and a specific
model within that family (the value of the parameter vector Œ∏) so as to minimize the Bayes
Information Criterion (BIC)13 with N observations,
BIC ‚â° ‚àí2LL + k log N.

(3)

Œõ(‚àÜ)
Suppose that the log odds of adjustment, Œª(‚àÜ) ‚â° log 1‚àíŒõ(‚àÜ)
, is a polynomial function of

‚àÜ, with k ‚àí 1 ‚â• 0 the order of the polynomial,

Œªk (‚àÜ; Œ∏) =

14

k‚àí1
X

Œ∏j ‚àÜj .

(4)

j=0
13

See, for example, Burnham and Anderson (2002, chap. 6) for discussion of this approach to model
selection.
14
The choice of this particular nested sequence of parametric families is motivated by the fact that the
more specific theory based on attention costs that we consider below corresponds to a particular family of
models of this kind, though with a different measure of the relevant ‚Äúgap.‚Äù A further appealing feature
of the assumption that Œª(‚àÜ) is a polynomial function ‚Äî and hence that Œõ(‚àÜ) is a logistic function of a
polynomial function of ‚àÜ ‚Äî rather than simply assuming that Œõ(‚àÜ) is a polynomial function, is that the
former assumption, unlike the latter, implies a hazard between 0 and 1 for all values of the gap, without any
need to truncate the function implied by a given parameter vector. Moreover, this specification implies that
the hazard will be greater than zero and less than 1 for all values of ‚àÜ, so that any sequence of observations
will have a finite log likelihood, regardless of the parameter vector.

22

TABLE 2: Best fitting models
Gap-Based Models
Model
Constant hazard
Polynomial hazard
Symmetric poly.
Model
Ss with errors
Symmetric Ss
Optimizing Models
Model
Constant hazard
Polynomial hazard
Ss with errors
Step function
Inattention Model
Model
Rational inattention

k
1
3
2
k
3
2

Œ∏0
Œ∏1
-2.33
‚Äì
-2.54 -0.22
-2.53
‚Äì

‚àÜ
0.088 -0.64
0.088 -0.88

Œ∏2
‚Äì
7.52
7.58
¬Ø
‚àÜ
0.77
0.88

BIC
54,286
53,112.4
53,111.5
BIC
54,291
54,298

k
1
2
2
3

Œ∏0
-2.33
-2.50
‚Äì
‚Äì

Œ∏1
‚Äì
0.92
‚Äì
‚Äì

1
‚Äì
‚Äì
0.088
0.082

¬Ø
2
‚àÜ
‚Äì
‚Äì
‚Äì
‚Äì
0.912 3.96
0.20 0.58

BIC
54,286
53,247
54,247
53,652

k
2

Œ∏0
-2.07

Œ∏1
0.77

œà1
1.30

ŒõÃÉ
0.112

BIC
52,780

Top panel: Polynomial coefficients and BIC for the best-fitting models within the
Bayesian gap class of models. Middle panel: Coefficients and BIC for the best
fitting models that allow adjustment to depend on the expected value of adjustment,
assuming optimization subject to a random fixed cost of adjustment. Bottom panel:
Model assuming that adjustment economizes on information costs.

In the case of our data (pooling the data from the 91 unique sessions15 ), the BIC is
minimized when Œª(‚àÜ) is a quadratic function, with coefficients {Œ∏j } given in the top panel
of Table 2. The implied hazard function Œõ(‚àÜ) is shown in the last panel of Figure 10. The
best-fitting hazard function reaches its minimum near ‚àÜ = 0, and approaches 1 for large
enough positive or negative values of the gap; but even at its minimum, the probability of
adjustment is positive.
The degree to which the data support these conclusions can be determined by comparing
the minimum values of the BIC statistic for more restrictive families of models. Specifically,
for two model families M1 and M1 , the relative posterior probability that the true model
15

The main text presents results for the unique sessions only, while the Appendix presents corresponding
results using the data from all 110 sessions, including the repeated sessions. The results are fairly similar
with regard to all of the issues discussed below; we prefer to emphasize the results using only the unique
sessions, which represent 91 independent samples from the data-generating process, and do not over-sample
any part of the state space.

23

belongs to one of these families rather than the other, after observing the data, is given by
log

P prior (M1 )
1
P post (M1 )
=
log
‚àí
[BIC(M1 ) ‚àí BIC(M2 )].
P post (M2 )
P prior (M2 )
2

(5)

If we assume a constant hazard function (as in the Calvo (1983) model of adjustment), then
as indicated in Table 2, the minimum BIC statistic is higher by 1,174 natural log points.
Thus the data increases the relative posterior probability that the quadratic log odds model
is correct by a factor greater than 10254 , relative to the hypothesis of no dependence of the
adjustment decision on the Bayesian gap.
As another example, we consider the degree to which the data support the conclusion
that the hazard function is asymmetric, by considering the more restrictive family of only
symmetric polynomials. We again find that the best-fitting polynomial is quadratic, and the
BIC statistic is 0.9 log points lower than in the unconstrained case. Allowing a non-zero
linear term increases the log-likelihood of the data, but not enough to outweigh the penalty
for the additional free parameter.
While we are able to reject the hypothesis of no dependence on the Bayesian gap (the
Calvo model), our data are also inconsistent with the strong degree of state-dependence
assumed in a simple Ss model, in which adjustment never occurs for gaps within some fixed
thresholds, and occurs with certainty for gaps outside them. Any such model will have an
unboundedly large BIC statistic. This exact version of an Ss model may seem a straw man,
so we also consider a generalization in which it is assumed that there will inevitably be some
random error in the execution of any decision with regard to adjustment: that even when
the decision is to keep the slider unchanged, the slider will nonetheless be adjusted with
probability , for some 0 <  < 1/2, and when the decision to adjust is made, the slider
will only be adjusted with probability 1 ‚àí . But even allowing for errors of this kind, the
minimum value of the BIC statistic remains 1,178 log points higher under a model with
sharp thresholds than under the quadratic log odds model (reducing the relative posterior
probability by 10255 , relative to best fitting quadratic hazard function). If we assume that
the thresholds must be symmetric, reducing the number of free parameters by one, the
BIC statistic further increases by 7 log points. Hence, we conclude that the adjustment

24

decision is state-dependent ‚Äî with the Bayesian gap providing at least an imperfect proxy
for the relevant state ‚Äî and furthermore, that the Caballero-Engel hypothesis of a continuous
hazard function fits the data better than a model with sharp thresholds.
We turn next to the question of where the slider is moved when it is adjusted. Caballero
and Engel (1993, 2007) assume, as in the classic ‚ÄúSs‚Äù model, that when the decision variable
is adjusted, it is moved to its current (myopically) optimal value. In the present context,
this would correspond to a hypothesis that pÃÇt is set equal to p‚àót . Panel (a) of Figure 11 shows
a scatter plot of the values of pÃÇt and p‚àót for all of the trials on which the slider is adjusted.
Under the simple hypothesis, all of these points should lie on the diagonal. We do observe
some relationship between the two variables; in fact, a linear regression of pÃÇt on p‚àót yields
a regression line quite close to the diagonal. Nonetheless, there is a great deal of noise in
the relationship, not predicted by the simple hypothesis that the ‚ÄúBayesian gap‚Äù should be

1

1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

Forecast p

Forecast p

eliminated whenever the slider is adjusted.

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0

0
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

0

Bayes p

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Value maximizing p

(a) Bayesian estimate

(b) Value maximizing estimate

Figure 11: The distribution of slider positions that are chosen, conditional on adjustment. (a)
Scatter plot of the slider position [vertical axis] against the Bayesian optimal setting; (b) scatter
plot of the slider position [vertical axis] against the one that would maximize the continuation value
function.

4.2

Optimizing Models with a Fixed Cost of Adjustment

We next consider the extent to which our data are consistent with more explicitly optimizing (and more forward-looking) models in which the decision whether to adjust the slider
25

is assumed to be optimal (expected-payoff maximizing) on each trial, subject to a fixed cost
of adjustment. Note that while there is no cost in terms of points deducted from the subject‚Äôs
score when the slider is moved, one might suppose that there is nonetheless a utility cost of
having to move the mouse to adjust the slider position, a utility cost of the additional delay
before proceeding to the next trial,16 or a cognitive cost of having to decide where to move
the slider.
Consider first the joint hypothesis that there is a constant fixed cost of moving the slider
at all times, and that the slider will be adjusted to its optimal location in the case that the
fixed cost is born, as in classic ‚Äúmenu cost‚Äù models of price adjustment such as the model of
Sheshinski and Weiss (1977, 1983). Then the slider should be adjusted on trial t if and only
if
Vt (pÃÇt‚àí1 ) < max Vt (p) ‚àí Œ∫,
p

(6)

where for any possible slider position 0 ‚â§ p ‚â§ 1, Vt (p) is the expected cumulative payoff
from all remaining trials net of adjustment costs on trials after t, if the slider is set at p at
the end of trial t, and Œ∫ > 0 is the fixed cost of adjustment. Note that the value function
Vt (p) will depend not only on the number of the trial t, but also on the (optimal Bayesian)
posterior œÄt at that time (i.e., the posterior taking into account the rings drawn on trial t
and earlier); the argument œÄt has been suppressed to simplify the notation. Although the
pattern of behavior documented in the previous section rules out models with a fixed cost of
adjustment, we can still determine how well such a model can predict the decision of whether
to adjust the slider.
We can alternatively assume, as in the generalized model of state-dependent pricing
proposed by Dotsey, King and Wolman (1999), that the fixed cost of adjustment is a random
variable, drawn independently on each trial from some distribution with CDF G(Œ∫).17 If we
again assume that the slider will be moved to its optimal location conditional on adjustment,
then the probability of adjustment on trial t should be given by a non-decreasing hazard
16

We note that there is a time cost of slider adjustment for our subjects: on average, subjects take only
1.4 seconds to request the next ring on trials where they do not move the slider, but 4.4 seconds on trials
where they move the slider before requesting the next ring.
17
Caballero and Engel (1999) propose a similar model of optimization with random fixed costs as a
micro-foundation for the type of ‚Äúgeneralized Ss model‚Äù proposed in Caballero and Engel (1993).

26

function
Œõ(‚àÜt ) = G(‚àÜt ),

(7)

where the ‚Äúvalue gap‚Äù ‚àÜt is defined as
‚àÜt ‚â° max Vt (p) ‚àí Vt (pÃÇt‚àí1 ).
p

(8)

If the distribution of fixed costs is continuous (contains no atoms), the hazard function Œõ(‚àÜ)
must be a continuous, non-decreasing function with Œõ(0) = 0. It is possible, however, to
have Œõ(0) > 0 if we suppose that there is a positive probability of a zero fixed cost, as in the
model of Calvo (1983).18
The empirical content of either version of the model depends on evaluating the value
function Vt (p). We would like to compare alternative models of the adjustment decision on
a single trial using a measure of the value gap that is (to the extent possible) independent
of assumptions regarding behavior in later trials. As explained further in the appendix, we
estimate an atheoretical statistical model of subjects‚Äô behavior after any trial t conditional
on the slider setting pÃÇt chosen on that trial and the posterior œÄt at that point, and use
this atheoretical model to compute an implied value function Vt (p). We can then test the
degree to which both the timing of slider adjustments and the new slider positions chosen
are consistent with the predictions above, under any assumption about the distribution of
fixed costs.
In the numerical results presented below, we examine how well the adjustment decision
can be explained by variation in the value gap, when we use a particular measure of the
value based on the best-fitting value gap model. The contour lines associated with equal
magnitudes for the value gap are plotted in Figure 12. We see that the value gap is related
to the Bayesian gap (which corresponds, in the figure, to the distance of points from the
diagonal). If the value gap were purely a monotonic function of the absolute value of the
Bayesian gap, the contour lines would be the family of parallel straight lines with a slope
18

The model of Calvo (1983) also assumes that the cost of adjustment is effectively infinite, except at those
times when a zero adjustment cost is drawn; but one can combine the assumption of a positive probability
of drawing a zero adjustment cost with an assumption that the adjustment cost is finite at all other times,
so that the hazard approaches 1 for all large enough values of the ‚Äúvalue gap,‚Äù contrary to what is assumed
in the Calvo model.

27

1

0.8

p‚àót

0.6

0.4

0.2

0
0

0.2

0.4

0.6

0.8

1

pÃÇt
Figure 12: A contour plot of the average value gap ‚àÜt associated with alternative pairs of values
for the slider position pÃÇt [the horizontal axis] and the Bayesian posterior mean p‚àót [the vertical axis],
when the continuation value function Vt (p) is numerically approximated on the basis of an empirical
model of the subsequent adjustment dynamics.

exactly equal to one. In this case, the predictions of the optimizing model would be identical
to those of the gap-based model with a symmetric hazard function. This is not quite true,
since in the optimizing model, the value of adjusting also takes into account future expected
adjustment costs, in addition to the current gap; nonetheless, the lines are close to those
predicted by the Bayesian gap model.
Figure 13 plots the fraction of trials in which the slider is adjusted, grouping the trials
in bins with an equal number of observations, but now using the value gap, rather than the
Bayesian gap, as the basis for classification.19 The probability of adjustment is monotonically
increasing in the value gap. Moreover, adjustment only occurs with positive probability if
the value gap is positive. On the other hand, there does not appear to be a sharp threshold
of the kind required by an optimizing Ss model of adjustment. Nor is there any indication
19

The value gap is measured, in the horizontal axis of this figure, in terms of the number of additional
points (net of any increase in expected subsequent adjustment costs) that the subject can expect to obtain,
on average, by adjusting the slider, assuming that it is adjusted to the optimal position.

28

1

0.18

0.9

0.16

0.8

0.14

0.7

0.12

0.6

Prob(Change)

Prob(Change)

0.2

0.1

0.08

0.5

0.4

0.06

0.3

0.04

0.2

0.02

0.1

0

0
0

0.1

0.2

0.4

0

6.7

1

2

3

4

5

6

V max - V

V max - V

(a) Equal-weight bins

(b) Polynomial

Figure 13: Adjustment probability as a function of the value gap, computed under an assumption
that if the slider is adjusted, it will be moved to the currently optimal position. (a) Nonparametric
empirical hazard, with boundaries chosen so that each bin contains an equal number of observations.
(b) The best-fitting logistic-polynomial hazard function as a function of the value gap. (Coefficients
given in Table 2.)

that the adjustment hazard falls to zero as the value gap approaches zero, as the random
menu cost model would require in the absence of an atom at zero in the distribution of fixed
costs.
As in the case of the models based on the Bayesian gap, we can estimate a continuous
hazard function using the BIC to penalize excessive flexibility in the family of functions
considered. If we again consider the class of logistic-polynomial hazard functions, we find
that the best-fitting model makes the log odds of adjustment a linear function of the value
gap, with a positive intercept and positive slope, as reported in the middle panel of Table 2.
The implied best-fitting value-based hazard function is shown in Panel (b) of Figure 13. This
corresponds to a random-fixed-cost model in which the distribution of fixed costs has a CDF
also given by the curve in that figure. The implied distribution has an atom at zero fixed
cost (about 8 percent of the total probability), and a continuous distribution otherwise; the
fixed cost can be unboundedly large, but it is finite with probability one.
We again use the BIC to measure the degree to which the data favor this model. The
best-fitting linear function Œª(‚àÜ) achieves a BIC statistic of 53,247 points, which is 1,039
natural log points lower than that of the best-fitting constant hazard. This implies a relative

29

posterior probability that is larger by a factor of 10225 . We also reject the hypothesis of a
constant fixed cost (the optimizing Ss model). Even if we assume that it is not possible to
reduce the probability of adjustment below some 1 > 0 or to raise it above 1 ‚àí 1 (with
1 a free parameter that can be chosen to fit the data), the lowest BIC statistic obtainable
with such a model remains 999 log points higher than that obtained with our preferred
random-menu-cost model.
Alternatively, we can also consider the performance of a step-function variant of the flat
¬Ø the
hazard model, in which we suppose that for value gaps below a certain threshold ‚àÜ,
probability of adjustment is 1 > 0, while above that threshold, the probability rises to
2 > 0 (not necessarily equal to 1-1 ). Allowing for this flexibility significantly improves the
fit over the flat hazard model, but the BIC remains 405 log points higher than under the best
polynomial-hazard model. Thus, the data strongly prefer a model in which the probability
of adjustment increases continuously with the value gap.
While our value gap measure does have some ability to predict the trials on which subjects
are more likely to adjust the slider, it remains a less successful predictor than the Bayesian
gap. This failure of the optimizing model to do better, even when we allow for a very flexible
possible distribution of fixed costs, may indicate that in fact our subjects use a simple rule
of thumb rather than a fully optimal strategy, or perhaps that they are myopic optimizers.
Alternatively, it may simply indicate that our numerical approximation to the value function
Vt (p) is not accurate enough; we should expect our numerical estimates of the Bayesian gap
to be much more accurate, as it does not depend on any approximate characterization of
observed behavior.
The model of optimization subject to a (possibly random) fixed cost also fails in a more
obvious way. It implies that conditional on adjustment of the slider in period t, the new
slider position pÃÇt should be exactly the p that maximizes Vt (p). This is a standard assumption
in state-dependent pricing models (and many models of inattentive adjustment as well, such
as the models of Calvo, 1983, or Woodford, 2009). However, the assumption that upon
adjustment the chosen slider position is a deterministic function of the value maximizing
position is not consistent with our evidence. Panel (b) of Figure 11 shows a scatter plot
of the values of pÃÇt and arg maxp Vt (p). This plot shows a large dispersion in the actual
30

slider positions that are chosen, conditioning on the currently optimal slider position ‚Äî
especially when the currently optimal position is in the middle of the interval of possible
positions. While some of the noise might in this case reflect error in our estimation of the
continuation value function, the noise in the relationship seems too great to be explained
by numerical error alone. It appears that the decision where to move the slider when it
is adjusted involves a significant degree of randomness. The hypothesis of fixed costs of
adjustment (even randomly varying fixed costs) cannot explain why this should be the case.
Instead, the hypothesis of inattentiveness on the part of decisionmakers can equally explain
the randomness of both decisions, as we discuss next.

4.3

A Model of Inattentive Adjustment

We now consider a model of discrete adjustment in which both the decision when to adjust
the slider and the decision where to move it conditional on adjustment are assumed to be
optimal, but in terms of an objective that includes costs of paying closer attention to both
decisions. The particular theory of attention costs that we consider is based on the theory
of ‚Äúrational inattention‚Äù proposed by Sims (2003, 2011) and applied to discrete adjustment
problems by Khaw, Stevens and Woodford (2016).20 The theory generalizes the models of
inattentive adjustment by Woodford (2009) and Stevens (2015) by relaxing the assumption
that agents observe the true state with perfect precision conditional upon deciding to review
the current setting (i.e., to adjust the slider), and by introducing the possibility of intrinsic
preference for particular actions.
We specify a subject‚Äôs behavioral rule by a sequence of functions Œõt (ht ), indicating the
probability of adjusting the slider on trial t for each possible history ht prior to that trial‚Äôs
ring draw, and a sequence of functions ¬µt (ht ), specifying a probability measure ¬µt over
possible new locations for the slider (if adjusted on trial t) for each possible prior history ht .
In addition to assuming that it is costly for a subject to pay closer attention to the history ht ,
we assume that there may also be intrinsic costs or convenience associated with particular
20

See Cheremukhin et al. (2011) for an earlier application of the theory of rational inattention to the
explanation of randomness in experimental data, albeit to a sequence of independent static decision problems
rather than to a dynamic setting like that considered here.

31

actions. For example, there may be an effort cost associated with moving the mouse in
order to adjust the slider position (as in the model with a constant fixed cost considered
above). Or there may be a preference for choosing certain slider positions, independent of the
monetary payoff expected from choosing those positions; our subjects‚Äô apparent preference
for positions corresponding to round numbers suggests that this is the case.
Let the measurable function c(p) denote the cost associated with choice of slider position p, borne only at times when the slider is adjusted; a negative value corresponds to a
positive preference for that position choice. Similarly, let cadj denote the cost associated
with adjustment of the slider, and cnon the cost of non-adjustment (which quantities are also
possibly negative).21 Under the hypothesis of rational inattention, the subject‚Äôs decision rule
maximizes an objective of the form
)
Z
T 
X
E
r(pÃÇt ; st ) ‚àí œà1 I1 ‚àí œà2 Œõt I2 ‚àí Œõt cadj ‚àí (1 ‚àí Œõt )cnon ‚àí Œõt c(p)d¬µt (p) ,
(

(9)

t=1

where I1 is a measure of the amount of information used in deciding on each trial whether
to adjust the slider; I2 is a corresponding measure of the amount of information used in
deciding where to set the slider, on those trials where it is adjusted; œà1 , œà2 > 0 are attention
cost parameters for the two types of information; and E{¬∑} indicates an expectation over
the possible sequences of realizations of ring draws, the possible outcomes of the random
decision whether to adjust the slider each period, and the possible outcomes of the random
decision as to where to set the slider when it is adjusted. Here, the history ht consists of
the complete history of ring draws through trial t ‚àí 1, together with the complete history
of slider positions chosen through trial t ‚àí 1. It does not include the history of evolution of
the underlying state {pt }, as this is not visible to the subject, no matter how closely he may
pay attention.
The solution to this problem is given by an optimal adjustment hazard
log

Œõt
ŒõÃÉ
= Œª(‚àÜt ) ‚â° log
+ œà1‚àí1 ‚àÜt
1 ‚àí Œõt
1 ‚àí ŒõÃÉ

21

(10)

Note that the amount by which cadj differs from cnon may reflect costs of having to decide about where
to move the slider, whether or not it is actually moved, as in Alvarez et al. (2011). Here such costs, if found
to exist, would be purely cognitive.

32

and an optimal measure over new slider positions
¬µt (p) = R

exp{œà2‚àí1 Vt (p)}¬µÃÉ(p)
.
exp{œà2‚àí1 Vt (p0 )}d¬µÃÉ(p0 )

(11)

Here Vt (p) is again the continuation value function, and the ‚àÜt in (10) is now the ‚ÄúRI value
gap‚Äù defined as22
Z
‚àÜt ‚â°

Vt (p)d¬µt (p) ‚àí Vt (pÃÇt‚àí1 ).

(12)

The value of the reference adjustment probability ŒõÃÉ depends on both the unconditional
probability of adjustment and on the intrinsic cost of adjustment relative to non-adjustment
(it would equal the unconditional probability if cadj = cnon ); similarly, the reference measure
¬µÃÉ(p) depends on both the unconditional frequency distribution of slider location choices and
on the intrinsic costs of different locations. In the absence of any independent evidence about
the intrinsic costs, we can treat ŒõÃÉ and ¬µÃÉ(p) as free parameters to be estimated, from which
we can then infer the implied intrinsic costs.
Note that (10) implies that the probability of adjusting is again given by a continuous
hazard function, and indeed that the hazard function must belong to a specific parametric
family: the log odds of adjustment are predicted to be a linear function of ‚àÜt , as in the
case of the best-fitting random-fixed-cost model discussed in section 4.2, though here the
definition of ‚àÜt is different. Unlike the models considered above, (11) implies that the slider
location decision is similarly randomized. Note however that the model reduces to the simple
prediction that the new slider location will be the value of p that maximizes Vt (p) in the
limiting case œà2 ‚Üí 0.
We consider the parameterization of this model that best fits our experimental data. We
wish to determine (i) the values for the information-cost parameter œà1 and the reference
adjustment probability ŒõÃÉ that best fit our data on the timing of slider adjustments, and
(ii) the values for the information-cost parameter œà2 and the reference measure ¬µÃÉ over new
slider positions that best fit our data on the positions to which the slider is moved when it is
adjusted. In the first case, we are choosing parameters for prediction (10) for the adjustment
22

The appendix describes the approximation of the value function and the associated value gap in the
inattentive adjustment model.

33

hazard, and in the second we are choosing parameters for prediction (11) for the distribution
from which the new slider position is drawn. These problems are not independent, however,
since the expected value of adjusting depends on the choice of a distribution of new slider
positions, and likewise, this latter choice depends on the probability of adjustment in future
periods. Hence, we estimate these parameters jointly.
In the work reported here, we do not optimize over a completely unrestricted reference
distribution ¬µÃÉ, and instead consider only distributions of the parametric form ¬µÃÉ(p) = A¬µ(p)Œ≥
for some Œ≥ ‚àà [0, 1], where ¬µÃÑ is the unconditional frequency distribution of slider positions.23
Within this family, the best-fitting reference distribution corresponds to Œ≥ = 0.47. The implied distribution ¬µÃÉ(p) is shown in the left panel of Figure 14; note that that this distribution
is significantly flatter than the empirical distribution of slider location choices, also shown
in the figure.
0.05
0.3

¬µÃÑ(p)
¬µÃÉ(p)

c(p)
0.2

0.04

0.1

0.03

c(p)

0

-0.1

0.02

-0.2

0.01
-0.3

0

-0.4

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

0

1

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

p

p

(a) Reference and empirical distributions

(b) Cost function

Figure 14: Intrinsic costs. (a) The model-implied reference distribution ¬µÃÉ of slider positions and
the empirical distribution ¬µ, conditional on adjustment. (b) The model-implied intrinsic relative
cost function, c(p) associated with different slider positions.

This distribution points to the presence of significant intrinsic gains and costs in the
decision of where to position the slider conditional on adjustment, since in the absence of
such costs the two distributions would be identical. We can go further and use the estimated
reference distribution to infer the intrinsic relative cost c(p) associated with movement to
23

Allowing a more flexible family would necessarily allow an even better fit to our data, at a possible risk
of overfitting. This simple family nests both the cases of zero intrinsic costs (Œ≥ = 1) and a uniform reference
distribution (Œ≥ = 0) as assumed in the ‚Äúlogit dynamics‚Äù model of Costain and Nakov (2014).

34

each possible slider position. The relative cost function is shown in Panel (b) of Figure 14.
Negative values of the intrinsic cost function are associated with preferred slider positions
(which are chosen by subjects more than would be predicted by the rational inattention
model without intrinsic costs), while positive cost values are associated with disliked slider
positions. We find that our subjects prefer extreme slider positions (close to 0 or close
to 1) more than would be predicted by a rational inattention model without any intrinsic
costs or gains from choosing specific slider positions. In addition, subjects are also more
likely to choose certain interior slider positions than others. The associated information cost
parameter for the use of more information in choosing the slider position is œà2 = 0.67.
1

0.9

0.8

0.7

Forecast

0.6

0.5

0.4

0.3

0.2

0.1

0
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Posterior mean

Figure 15: The model-implied joint distribution of slider settings and Bayesian posterior mean,
conditional on adjustment. Blue circles: scatter plot of the actual slider positions [vertical axis]
against the Bayesian optimal setting. Red circles: scatter plot of the simulated RI slider positions
[vertical axis] against the Bayesian optimal setting.

The degree to which this model of the slider location decision matches the experimental
data when œà2 = 0.67 is shown in Figure 15. Here we show again the scatter plot of slider
positions chosen on trials where the slider is adjusted, plotted against that Bayesian posterior
mean for the underlying state on that trial (in blue circles, as in panel (a) of Figure 11),
35

with the corresponding scatter plot from a simulation of the rational inattention model of the
overlaid on it (in red circles). In this simulation, we assume the same sequences of ring draws
(and hence the same evolution of the Bayesian posterior) as in the experimental sessions,
and we suppose that the slider is adjusted on exactly the same trials as in the experimental
sessions (so that the set of Bayesian posteriors associated with trials on which the slider is
adjusted is the same as in the experimental data); but we suppose that when the slider is
adjusted, the new position is drawn from the distribution ¬µt given by equation (11). We
find that the predicted joint distribution of the Bayesian posterior mean and the new slider
position is reasonably similar to the one observed in our data.24
We turn next to the ability of the RI model to account for the timing of adjustments of
the slider. Like the models of the adjustment decision considered in the previous sections,
the RI model implies that the adjustment hazard should be a function of the ‚ÄúRI gap‚Äù
variable. However, the continuation value function is now net of the expected information
and intrinsic costs; and the expected value of adjustment is an average of the continuation
values associated with different slider positions, rather than solely the maximum continuation
value. The value gap implied by the RI model, under our estimated parameter values, is
graphed in Figure 16, using the same format as Figure 12.
As a nonparametric illustration of the degree to which this gap variable is able to explain
the timing of adjustments, Figure 17 plots the fraction of trials in which the slider is adjusted,
grouping the trials in bins with an equal number of observations. We see that the adjustment
probability is monotonically increasing with this gap measure, as predicted by the model.
The RI model makes a very specific prediction, that Œª(‚àÜ) should be an increasing linear
function of the value gap. When we consider polynomials of arbitrary order, but use the BIC
criterion to select the best model family, we find that in fact our data are best fit by a model
according to which the log odds are an increasing linear function of the gap, as predicted
by the theory. The best fitting parameters and the associated BIC value are shown in the
24

We do not provide a quantitative measure of the goodness of fit, as there is no alternative stochastic
model of the slider location decision with which we wish to compare this model. Because of the substantial
stochastic variation in the chosen slider position, the rational inattention model is clearly much more successful in accounting for the data than the deterministic hypotheses considered above (that when the slider
is adjusted, it is set to the current Bayesian posterior mean, or that it is set to the position that maximizes
the continuation value).

36

1

0.8

p‚àót

0.6

0.4

0.2

0
0

0.2

0.4

0.6

0.8

1

pÃÇt
Figure 16: A contour plot of the average RI value gap ‚àÜt associated with alternative pairs of values
for the slider position pÃÇt [the horizontal axis] and the Bayesian posterior mean p‚àót [the vertical axis].

bottom panel of Table 2. The best-fitting parametric hazard function is plotted in the second
panel of Figure 17.
Equation (10) allows us to interpret the coefficients (Œ∏0 , Œ∏1 ) of the logistic-linear hazard
function in terms of the information cost œà1 and the reference frequency of adjustment ŒõÃÉ of
the rational inattention model; the implied values of these two parameters are also given in
Table 2. Interestingly, the information cost œà1 for the decision whether to adjust is estimated
to be roughly twice as large as the information cost œà2 for the decision where to move the
slider conditional on adjustment.25
The estimated reference probability of adjustment, ŒõÃÉ = 11.2% , is larger than the empirical probability of adjustment, ŒõÃÑ = 8.9%. This corresponds to a relative cost cadj ‚àí cnon =
‚àí0.34, meaning an intrinsic preference for adjustment, so that subjects adjust more frequently than would be optimal given the precision of their estimate of where to set the
25

This finding is consistent with the results of Stevens (2015), who finds that the parameterization that
best fits micro price data is one in which the decision whether to review the firm‚Äôs pricing plan is more costly
than the decision about which prices to charge.

37

1

0.18

0.9

0.16

0.8

0.14

0.7

0.12

0.6

Prob(Change)

Prob(Change)

0.2

0.1

0.08

0.5

0.4

0.06

0.3

0.04

0.2

0.02

0.1

0

0
-1.1

-0.5

0

-1

8.1

0

1

2

3

4

5

6

7

V adj - V

V adj - V

(a) Equal-weight bins

(b) Polynomial

Figure 17: Adjustment probability as a function of the value gap implied by the rational inattention
model. (a) Nonparametric empirical hazard with the boundaries chosen so that each bin contains
an equal number of observations. (b) The best-fitting logistic-polynomial hazard function as a
function of the value gap implied by the rational inattention model. (Coefficients given in Table
2.)

slider. In fact, in our data subjects often adjust when the RI value gap is negative.
The BIC statistic implies that the RI model best fits our data on the timing of slider
adjustments, among all of the models considered. Even relative to the best-fitting gap-based
model (the symmetric quadratic polynomial), the BIC of the RI model is lower by 332 log
points, implying a relative posterior probability of the RI model greater than 1072 .
Hence the rational inattention model augmented with intrinsic costs succeeds in capturing the main features of our data, at least as far as the pooled data, describing the average
behavior of our population of subjects, are concerned. It predicts both the timing of adjustments (that these are stochastic, with an adjustment hazard that is a continuously increasing
function of the expected value of adjusting) and the position to which the slider is moved if
adjusted (this is also stochastic, with a probability of movement to each position that is a
continuously increasing function of the expected value associated with that position). Moreover, the specific functional form (10) that is predicted for the adjustment hazard function
fits our data better than any of the other models considered above. And the model allows
(though it does not require) the kind of ‚Äúround-number bias‚Äù observed on the part of our
subjects.

38

5

Discussion
We have used a controlled laboratory setting to study how successful our subjects are in

tracking a changing environmental state, and adjusting their behavior so as to continue to
maximize expected reward. While our experimental setting is very stylized, the pattern of
discrete adjustments that we observe shares some notable features with data on the adjustment of individual goods prices by retailers. This suggests that our findings about adjustment
behavior in our experiment may well be relevant to understanding discrete adjustment in
economically relevant settings as well, such as price-setting behavior.
Moreover, we observe a pattern of discrete adjustment reminiscent of that observed in
micro-level data on prices even in a setting where many factors that might be thought
relevant to price-setting are clearly not present: here, for example, there are no costs of
communicating a new policy to customers, no reasons to doubt whether customers will
recognize and respond to a price change, nor any reasons to fear the emotional reaction
of customers to a price change that they notice. The discreteness thus must result from
some kind of cognitive constraint on subjects‚Äô ability or willingness to more closely track the
reward-maximizing slider setting. And while we might think of this as reflecting decisions
made on the basis of imperfect information, it is not imperfect information that results from
the structure of the physical environment, as in the model of Lucas (1972); instead, behavior
seems to make use of less precise information about the changing environment than has been
presented to the subjects, reflecting some form of inattention, limited memory, or other limit
in information processing capacity.
Our experiment allows us to reject many familiar hypotheses about adjustment to a
changing environment, at least as an explanation of the behavior of our subjects. These include, most obviously, the benchmark of rational expectations (or perfect Bayesian inference
from the available data). Yet our data also clearly reject any model that implies continuous
adjustment each time a subject has a reason to adjust their beliefs, such as the ‚Äústicky information‚Äù models of Mankiw and Reis (2002) or Reis (2006), the ‚Äúnoisy information‚Äù model
of Woodford (2003), or the rational inattention model of Mackowiak and Wiederholt (2009).
We can also reject time-dependent models of discrete adjustment, such as the Taylor (1980)

39

model of staggered adjustment, since our data show that adjustments often occur very soon
after a previous adjustment of the slider (and there is also no evidence of a preferred time
length between adjustments).
Our experimental data on the timing of discrete adjustments are inconsistent with the
assumption of the Calvo (1983) model of price adjustment, according to which an adjustment
is equally likely to occur over any time interval, for we show that it is possible to define
measures of the degree of inappropriateness of the existing slider position which have some
ability to predict the timing of slider adjustments. Yet the kind of state-dependence indicated
by our data is not the kind assumed in a simple ‚ÄúSs‚Äù model. In the case of none of the gap
measures that we consider do we find evidence of sharp thresholds such that adjustment
occurs if and only if a threshold is crossed. Moreover, under an ‚ÄúSs‚Äù model, if adjustments
do not occur constantly, then one should never observe small adjustments, and one should
observe few really large adjustments. The distribution of adjustment sizes that we observe
is inconsistent with an ‚ÄúSs‚Äù model on both counts.
The kinds of models that are instead consistent with at least certain broad features of
our data are models of discrete adjustment in which the timing of adjustment is stochastic,
though the probability of adjustment is a continuous, increasing function of some measure
of the inappropriateness of the current slider setting; such models include those proposed
by Caballero and Engel (1993, 1999), Dotsey, King and Wolman (1999), Woodford (2009),
and Costain and Nakov (2014). Among the several models of this type that we fit to the
timing of slider adjustments in our data, we find that the best-fitting model (under a BIC
criterion) is a generalization of the rational inattention model of Woodford (2009).26 In this
type of model, the randomness of decision whether to adjust the slider at a given point
in time is interpreted as resulting from inattention, or more generally from imprecision in
the subject‚Äôs subjective awareness of the precise situation that has been revealed by the
sequence of ring draws observed to that point (due, perhaps, to a memory limitation).27
This interpretation of the random timing of the slider adjustments is especially appealing in
26

As discussed in Khaw, Stevens, and Woodford (2016), this model can also be viewed as a generalization
of the logit model of Costain and Nakov (2014).
27
Magnani, Gorry and Oprea (2016) document a failure to precisely optimize in a related task, which
can similarly be attributed to inattention, though there is no need to rely on memory in order to make an
optimal decision in their experiment.

40

that it makes it natural to expect that the position of the slider conditional on adjustment
will also be random, unlike a model where discrete adjustment is motivated by (possibly
random) fixed costs but decisionmakers are assumed to be perfectly aware of the state at all
times. Our data are much better fit by a model in which the slider location decision is also
assumed to be stochastic.
The similarity of the pattern of adjustment of the slider in our experiment to retailers‚Äô
adjustments of the prices that they charge raises the possibility that the failure of such prices
to more perfectly track the retailer‚Äôs currently optimal (profit-maximizing) price should be
similarly attributed to rational inattention of the kind that we model. Such a conclusion
would have important consequences for monetary economics, as discussed in Woodford (2009)
and Stevens (2015). We believe that experimental studies such as this one can play an
important role in advancing our understanding, not simply of the general importance of
inattention in adjustment dynamics, but of the specific models of inattentive decisionmaking
that are most consistent with what we know about human capabilities ‚Äî and by doing so,
can contribute to the construction of more empirically realistic macroeconomic models.

41

References
Alvarez, Fernando E., Francesco Lippi & Luigi Paciello (2011), ‚ÄúOptimal Price Setting With Observation and Menu Costs,‚Äù The Quarterly Journal of Economics 126(4): 1909‚Äì1960.
Caballero, Ricardo J. & Eduardo M.R.A. Engel (1993), ‚ÄúMicroeconomic Adjustment Hazards and
Aggregate Dynamics,‚Äù The Quarterly Journal of Economics 108(2): 359‚Äì383.
Caballero, Ricardo J. & Eduardo M.R.A. Engel (1999), ‚ÄúExplaining Investment Dynamics in U.S.
Manufacturing: A Dynamic (S,s) Approach,‚Äù Econometrica 67(4): 783‚Äì826.
Caballero, Ricardo J. & Eduardo M.R.A. Engel (2007), ‚ÄúPrice Stickiness in Ss Models: New
Interpretations of Old Results,‚Äù Journal of Monetary Economics 54(S): 100‚Äì121.
Calvo, Guillermo (1983), ‚ÄúStaggered Prices in a Utility-Maximizing Framework,‚Äù Journal of Monetary Economics 12: 383‚Äì398.
Cheremukhin, Anton, Anna Popova & Antonella Tutino (2011), ‚ÄúExperimental Evidence on Rational Inattention,‚Äù Federal Reserve Bank of Dallas Working Paper 1112.
Costain, James & Anton Nakov (2014), ‚ÄúLogit Price Dynamics,‚Äù European Central Bank Working
Paper 1693.
Dotsey, Michael & Robert G. King (2005), ‚ÄúImplications of State-Dependent Pricing for Dynamic
Macroeconomic Models,‚Äù Journal of Monetary Economics 52(S): 213‚Äì242.
Dotsey, Michael, Robert G. King & Alexander L. Wolman (1999), ‚ÄúState-Dependent Pricing and
the General Equilibrium Dynamics of Money and Output,‚Äù Quarterly Journal of Economics 114:
655‚Äì690.
Eichenbaum, Martin, Nir Jaimovich & Sergio Rebelo (2011), ‚ÄúReference Prices, Costs, and Nominal
Rigidities,‚Äù The American Economic Review 101(1): 234‚Äì262.
Gallistel, Charles R., Monika Krishan, Ye Liu, Reilly Miller & Peter E. Latham (2014), ‚ÄúThe
Perception of Probability,‚Äù Psychological Review 121(1): 96‚Äì123.
Kaplan, Greg & Guido Menzio (2015), ‚ÄúThe morphology of price dispersion,‚Äù International Economic Review 56(4): 1165‚Äì1206.
Khaw, Mel Win, Luminita Stevens & Michael Woodford (2016), ‚ÄúEmpirical Models of Inattentive
Adjustment,‚Äù in progress .
Levy, Daniel, Dongwon Lee, Haipeng Chen, Robert J. Kauffman & Mark Bergen (2011), ‚ÄúPrice
points and price rigidity,‚Äù Review of Economics and Statistics 93(4): 1417‚Äì1431.
Lucas, Jr., Robert E. (1972), ‚ÄúExpectations and the Neutrality of Money,‚Äù Journal of Economic
Theory 4: 103‚Äì124.
MacÃÅkowiak, Bartosz A. & Mirko Wiederholt (2009), ‚ÄúOptimal Sticky Prices under Rational Inattention,‚Äù The American Economic Review 99(3): 769‚Äì803.
Magnani, Jacopo, Aspen Gorry & Ryan Oprea (2016), ‚ÄúTime and state dependence in an Ss decision
experiment,‚Äù American Economic Journal: Macroeconomics 8(1): 285‚Äì310.

42

Mankiw, N. Gregory & Ricardo Reis (2002), ‚ÄúSticky Information versus Sticky Prices: A Proposal
to Replace the New Keynesian Phillips Curve,‚Äù The Quarterly Journal of Economics 117(4):
1295‚Äì1328.
McKelvey, Richard D. & Talbot Page (1990), ‚ÄúPublic and Private Information: An Experimental
Study of Information Pooling,‚Äù Econometrica 58(6): 1321‚Äì1339.
Muth, John F (1961), ‚ÄúRational expectations and the theory of price movements,‚Äù Econometrica:
Journal of the Econometric Society pp. 315‚Äì335.
Peterson, Cameron R. & Lee R. Beach (1967), ‚ÄúMan as an Intuitive Statistician,‚Äù Psychological
Bulletin 68: 29‚Äì46.
Reis, Ricardo (2006), ‚ÄúInattentive Producers,‚Äù The Review of Economic Studies 73(3): 793‚Äì821.
Ricci, Matthew & Randy Gallistel (2016), ‚ÄúAccuracy and Structure Detection in the Perception of
Probability,‚Äù unpublished .
Robinson, Gordon H. (1964), ‚ÄúContinuous Estimation of a Time-Varying Probability,‚Äù Ergonomics
7: 7‚Äì21.
Sheshinski, Eytan & Yoram Weiss (1977), ‚ÄúInflation and Costs of Price Adjustment,‚Äù Review of
Economic Studies 44: 287‚Äì303.
Sheshinski, Eytan & Yoram Weiss (1983), ‚ÄúOptimum Pricing Policy Under Stochastic Inflation,‚Äù
Review of Economic Studies 50: 513‚Äì529.
Sims, Christopher A. (2003), ‚ÄúImplications of Rational Inattention,‚Äù Journal of Monetary Economics 50(3): 665‚Äì690.
Sims, Christopher A. (2011), ‚ÄúRational Inattention and Monetary Economics,‚Äù in Handbook of
Monetary Economics, volume 3A, B.M. Friedman & M. Woodford, eds., Elsevier, Amsterdam.
Stevens, Luminita (2015), ‚ÄúCoarse Pricing Policies,‚Äù unpublished .
Taylor, John B. (1980), ‚ÄúAggregate Dynamics and Staggered Contracts,‚Äù Journal of Political Economy 88: 1‚Äì23.
Woodford, Michael (2003), ‚ÄúImperfect Common Knowledge and The Effects of Monetary Policy,‚Äù in
Knowledge, Information, and Expectations in Modern Macroeconomics: In Honor of Edmund S.
Phelps, J. Stiglitz P. Aghion, R. Frydman & M. Woodford, eds., pp. 25‚Äì58, Princeton University
Press, Princeton, NJ.
Woodford, Michael (2009), ‚ÄúInformation-Constrained State-Dependent Pricing,‚Äù Journal of Monetary Economics 56(S): 100‚Äì124.

43

A

Optimal Bayesian Inference

Given a sample of T observations, we wish to determine the posterior distribution over
(n, p), where p is the most recent probability of drawing a 1 (namely a green ring) and n
is the number of periods for which the current regime has lasted so far. A model of the
data is specified by a probability p of drawing a 1 in the most recent regime and a partition
œÄ = {ni } of the sample into successive regimes, where ni is the length of regime i. Let œÑi
denote the last observation of regime i. The likelihood of the most recent n observations if
the regime has been p over that time is
L(n, p) = pkn (1 ‚àí p)n‚àíkn ,
where kn is the number of successes in the n most recent observations. Let
Z
L(n) ‚â° L(n, p)f (p)dp.

(A.1)

(A.2)

and let LœÑ (n) denote the average likelihood computed using the n observations ending with
observation œÑ . The ex-ante joint probability of the model (œÄ, p) being correct and the data
being a particular observed sequence is given by
N (œÄ)‚àí1

¬µ(œÄ)(

Y

LœÑi (ni ))f (p)L(n, p),

i=1

where N (œÄ) is the number of regimes under partition œÄ and ¬µœÄ is the ex-ante probability of
partition œÄ occurring in a sample of length T ,
¬µ(œÄ) = (1 ‚àí Œ¥)T ‚àíN (œÄ)+1 (Œ¥)N (œÄ)‚àí1 .

(A.3)

Summing over the set Œ†(n) of all possible partitions for which the final regime is of length
n, we define
N (œÄ)‚àí1
X
Y
¬µ(œÄ)
LœÑi (ni ).
(A.4)
Q(n) ‚â°
i=1

œÄ‚ààŒ†(n)

The posterior probability of (n, p) is
P (n, p) =

Q(n)f (p)L(n, p)
.
Œ£n‚â•1 Q(n)L(n)

(A.5)

The expected value of p sums over all n and integrates over p using the measure P (n, p).
The Bayesian estimate for the probability of drawing a 1 on the next observation takes
into account the fact that the regime might change on the next draw, which occurs with
probability Œ¥, and in which case, the estimate of the probability is 0.5:
Z X
Œ¥
B = (1 ‚àí Œ¥)
pP (n, p)dp + .
(A.6)
2
n‚â•1
1

Figure A.1 plots the distribution of the size of slider adjustments in our data and in the
Bayesian benchmark for the sample of unique sessions (top panels) and for the full sample,
including the repeated sessions (bottom panels). In the data, there is considerable variation
in the size of the slider adjustments when they occur, whereas according to the Bayesian
benchmark, the slider should be adjusted on every trial, and the adjustments should seldom
be very large.
4

6

x 10

1200

5
1000

4

800

3

600

400

2

200

1

0
‚àí1

‚àí0.8

‚àí0.6

‚àí0.4

‚àí0.2

0

0.2

0.4

0.6

0.8

0
‚àí1

1

‚àí0.8

(a) Unique sessions

‚àí0.6

‚àí0.4

‚àí0.2

0

0.2

0.4

0.6

0.8

1

(b) Bayes for unique sessions
7

√ó10 4

1200

6
1000

5
800

4
600

3

400

2

200

1

0

0
-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

0.8

-1

1

(c) Full sample

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

0.8

1

(d) Bayes for full sample

Figure A.1: Distribution of the size of changes in the slider position ‚àÜpÃÇt . Left panels: our data,
counting only trials on which the slider is moved (unique sessions in the top panel and all sessions in the bottom panel). Right panel: prediction under the hypothesis of Bayesian rationality,
corresponding to the two samples.

2

B

Approximation of the Value Function

This appendix describes the estimation methods used to compute the value functions for
the random menu cost model and for the inattention model. In each case, we estimate an
atheoretical statistical model of subjects‚Äô behavior after any trial t, conditional on the slider
setting p chosen on that trial and the posterior œÄt at that point, and we use this atheoretical
model to compute an implied value function Vt (p).

B.1

Empirical Model

Using our experimental data, we fit an empirical model of the dynamics for the Bayesian
posterior mean p‚àót , for the Bayesian gap p‚àót ‚àí pt‚àí1 , and for the probability of adjustment Œõt :


1
1
‚àó
‚àó
pt+1 ‚àí = ¬µ pt ‚àí
+ vt , ¬µ < 1
(B.1)
2
2
p‚àó ‚àí pt = Œª (p‚àót ‚àí pt‚àí1 ) + ut , Œª > 0
(B.2)
 t+1 
Œõt
log
= Œ∏0 + Œ∏2 (p‚àót ‚àí pt‚àí1 )2
(B.3)
1 ‚àí Œõt
where vt and ut are two i.i.d. mean-zero random variables with variances œÉu2 and œÉv2 , respectively.
Let us also approximate the CDF G (Œ∫) of fixed costs by a function of the form


G (Œ∫)
log
‚âà Œ≥0 + Œ≥1 Œ∫, Œ≥1 > 0.
(B.4)
1 ‚àí G (Œ∫)

B.2

Random Fixed Cost Model

In the random fixed cost model, the expected value of a slider position p is the expected
value of all future expected monetary rewards, net of the expected value of all future adjustment costs that are incurred:
Vt (p) = Rt (p) ‚àí Kt (p),
(B.5)
where note that the continuation value also depends on œÄt , the distribution of posterior
beliefs at the beginning of trial t, which has been suppressed to reduce notation, and where
" T
#
X
Rt (p) ‚â° E
r (ps ; ss ) pt = p, œÄt ,
(B.6)
"
Kt (p) ‚â° E

s=t
T
X

#
1s Œ∫s pt = p, œÄt ,

(B.7)

s=t+1

where 1s is an indicator variable equal to 1 is the slider is adjusted on trial s and 0 otherwise,
and Œ∫s is the value of the menu cost drawn on trial s. We can alternatively write Rt neglecting
a term that is independent of the position pt , and thus irrelevant to our calculation of the

3

continuation value:
Rt (p) = ‚àí

T
X

h
i
E (ps ‚àí p‚àós )2 pt = p, œÄt + t.i.p.

(B.8)

s=t

For t perceived by the subjects to be far enough away from the terminal trial T , we can
approximate the value of Rt by the value of
R‚àû (p) = ‚àí

‚àû
X

h
i
E (ps ‚àí p‚àós )2 pt = p, œÄt + t.i.p.

(B.9)

s=t

We can now use the empirical model described above, of the joint dynamics of the slider
position and of the Bayesian posterior mean to compute a numerical estimate of R‚àû for any
hypothetical slider position that may be chosen on trial t, given the posterior œÄt at that time:


 2
2Œª¬µ (1 ‚àí ¬µ)
1
2Œª ¬µ
‚àó
‚àû
+
pt ‚àí
(pt ‚àí p‚àót )
R (pt ) =
1 ‚àí Œª2
1 ‚àí Œª¬µ
2
"
2 
2 #
1
1
Œª2
p‚àót ‚àí
‚àí pt ‚àí
‚àí (pt ‚àí p‚àót )2 + t.i.p.
(B.10)
+
1 ‚àí Œª2
2
2
We next consider the numerical estimation of Kt , which we can alternatively write as
Kt (p) =

T
X

i
h
E Œì (Œõs ) pt = p, œÄt ,

(B.11)

s=t+1

where Œõs is the probability of adjustment on trial s, and where, denoting by G the CDF of
fixed adjustment costs,
i
h
(B.12)
Œì (Œõ) ‚â° ŒõE Œ∫ G(Œ∫) ‚â§ Œõ
multiplies the probability of adjustment by the mean adjustment cost conditional on Œ∫ being
below the threshold that is required for adjustment on a trial with that particular probability
of adjustment.
Given an estimate of the function Œì (Œõ), we can use a purely empirical model of the
adjustment hazard (more precisely, of the joint dynamics of the slider position, the Bayesian
posterior, and the probability of adjustment) to obtain a numerical estimate of the function
Kt (p) for each trial. However, the function Œì (Œõ) depends on the distribution of fixed costs
G, which in turn can only be inferred using a measure of the continuation value we are trying
to estimate. Hence we must jointly estimate the parameters of the distribution of fixed costs
and determine the best-fitting model of the adjustment decision, using the estimate of the
continuation value that is implied by this parameterization of Œì (Œõ) .
As above, we can neglect the terms that are independent of the slider position pt , and,

4

as long as t is not too close to T,we can use the approximation
‚àû n h
i
h
io
X
K (p) =
E Œì (‚àÜs ) pt = p, œÄt ‚àí E Œì (‚àÜs ) pt = p‚àót , œÄt .
‚àû

(B.13)

s=t+1

Using the approximation for the distribution of fixed costs G, we have that
Œì (Œõ) ‚âà
where

1
D(Œõ||Œõ),
Œ≥1

 


Œõ
1‚àíŒõ
D(Œõ||Œõ) ‚â° Œõ log
+ (1 ‚àí Œõ) log
.
Œõ
1‚àíŒõ

(B.14)

(B.15)

Using the empirical model of adjustment, we can approximate the relative entropy D by
D(Œõ||Œõ) ‚âà

Œ∏22
exp(Œ∏0 )
(p‚àó ‚àí pt )4 .
2 [1 + exp(Œ∏0 )]2 t+1

(B.16)

Then, using the empirical model for the dynamics of the Bayesian gap, and neglecting terms
that are independent of pt , we obtain
K ‚àû (p) ‚âà

 ‚àó ‚àó

Œ∏22
exp(Œ∏0 )
‚àó
‚àó
p
k(p
(G)
‚àí
p)
+
(1
‚àí
p
)k(p
(R)
‚àí
p)
,
t
t+1
t
t+1
2Œ≥1 [1 + exp(Œ∏0 )]2

(B.17)

where p‚àót+1 (x) is the Bayesian posterior mean p‚àót+1 in the case that the ring draw on trial t
is x, and where
k(p‚àót+1 ‚àí pt ) =

6Œª2 œÉu2
1
‚àó
4
(p
‚àí
p
)
+
(p‚àó ‚àí pt )2 .
t
1 ‚àí Œª4 t+1
(1 ‚àí Œª2 )(1 ‚àí Œª4 ) t+1

(B.18)

The parameters that must be evaluated in order to compute Vt for each trial are
1. The parameters (Œª, ¬µ, œÉu2 ) of the empirical laws of motion (B.1)-(B.2).
2. The parameters (Œ∏0 , Œ∏1 ) of the empirical hazard function in (B.3).
3. The parameter Œ≥1 of the estimated distribution of fixed costs in (B.4).
The parameter Œ≥1 however is estimated using our numerical estimate of the value gap,
‚àÜvalue
‚â° maxp Vt (p) ‚àí Vt (b
pt‚àí1 ). Hence we must solve a fixed point problem: a conjectured
t
value of Œ≥1 is used to compute Vt (p) for arbitrary p, and hence the value of ‚àÜvalue
on each
t
trial; these values are then used to estimate a value of Œ≥1 ,and this value must turn out to be
the same value as was assumed in order to compute ‚àÜvalue
.
t

5

B.3

Inattention Model

In our model with information costs, the continuation value can be written in the form
Vt (p) = Rt (p) ‚àí œà1 H1t (p) ‚àí œà2 H2t (p),

(B.19)

where Rt (p) is defined as in (B.6), and H1t (p) and H2t (p) are the expected cumulative costs
(summing both information costs and the intrinsic costs of different actions) of the two
decisions on subsequent trials, if the slider is set at p on trial t, and the posterior at that
time is œÄt :
" T
#
X
H1t (p) ‚â° E
D(Œõs ||ŒõÃÉ) pt = p, œÄt ,
(B.20)
s=t+1

"
H2t (p) ‚â° E

T
X

#
Œõs D(¬µs ||¬µÃÉ) pt = p, œÄt ,

(B.21)

s=t+1

where Œõs is the probability of adjustment on trial s, ¬µs is the probability distribution over
new slider positions
R if the slider is adjusted on trial s, ŒõÃÉ and ¬µÃÉ are the reference measures,
d¬µ is the Kullback-Leibler divergence between two distributions ¬µ
and D(¬µ||Œª) = log d¬µ
dŒª
and Œª.
As above, we can compute a numerical estimate of the function Rt (p) for each trial, on
the basis of an atheoretical empirical model of the joint dynamics of the slider position and
the Bayesian posterior on trials subsequent to t. The numerical estimate that we use is the
same as in our estimation of the model of optimization subject to a fixed cost of adjustment.
We similarly compute numerical estimates of the functions H1t (p) and H2t (p), using
empirical models of the joint dynamics of the Bayesian posterior, the slider position, the
adjustment probability Œõt , and the time-varying measure over possible new slider positions
¬µt . We proceed as follows: First, using the experimental data, we estimate a value of Œõt for
each value of the Bayesian gap p‚àót ‚àí pt‚àí1 . From this, we compute a value for D(Œõt ||ŒõÃÉ),given
ŒõÃÉ. We then fit a relationship of the form
D(Œõt ||ŒõÃÉ) ‚âà a(p‚àót ‚àí pt‚àí1 )4 + b(p‚àót ‚àí pt‚àí1 )2 + const.

(B.22)

Using this approximation together with the law of motion for the Bayesian gap, we can then
estimate
(B.23)
H1t (p) ‚âà p‚àót h1 (p‚àót+1 (G) ‚àí p) + (1 ‚àí p‚àót )h1 (p‚àót+1 (R) ‚àí p) + t.i.p.
where
h1 (p‚àót+1



6aŒª2 œÉu2
a
b
‚àó
4
‚àí pt ) =
(pt+1 ‚àí pt ) +
‚àí
(p‚àót+1 ‚àí pt )2 .
4
2
4
2
1‚àíŒª
(1 ‚àí Œª )(1 ‚àí Œª ) 1 ‚àí Œª

(B.24)

Similarly, we can obtain an estimate for H2t (p), by first fitting to the data the functional
relationships
Œõt ‚âà m(p‚àót ‚àí pt‚àí1 )2 + n,
(B.25)

6

and


2
1
‚àó
D(¬µt ||¬µÃÉ) ‚âà c pt ‚àí
+ d.
2

(B.26)

We obtain
H2t (p) ‚âà

p‚àót h2



p‚àót+1 (G)

‚àí

p, p‚àót+1 (G)

1
‚àí
2


+ (1 ‚àí

p‚àót )h2



1
‚àó
‚àó
pt+1 (R) ‚àí p, pt+1 (R) ‚àí
+ t.i.p.
2
(B.27)

where
2
Ô£´ ‚àó
Ô£∂
pt+1 ‚àí pt (p‚àót+1 ‚àí 21 )2


2
Ô£¨
Ô£∑
‚àó
1
p
‚àí
p
‚àó
‚àó
‚àí1 Ô£¨
t
Ô£∑,
t+1

h2 pt+1 ‚àí pt , pt+1 ‚àí
= ( mc md 0 nc )(I ‚àí N ) Ô£≠
2
p‚àót+1 ‚àí pt (p‚àót+1 ‚àí 12 ) Ô£∏
(p‚àót+1 ‚àí 12 )2
(B.28)
where the matrix N is given by
Ô£∂
Ô£´ 2 2 2 2
Œª ¬µ Œª œÉv 4Œª¬µœÉuv ¬µ2 œÉu2
Ô£¨ 0
Œª2
0
0 Ô£∑
Ô£∑.
(B.29)
N ‚â°Ô£¨
Ô£≠ 0
0
Œª¬µ
0 Ô£∏
0
0
0
¬µ2
Computing the estimates of H1 (p) and H2 (p) requires values for ŒõÃÉ and ¬µÃÉ (in order to
estimate empirical models of the dynamics of the quantities D(Œõt ||ŒõÃÉ) and D(¬µt ||¬µÃÉ)), while
the estimate of Vt (p) also requires values for œà1 and œà2 . We start with a set of parameters
and compute an estimate of the value function. Once we obtain a numerical estimate of the
function Vt (p), we can find the values of œà2 and ¬µÃÉ that maximize the consistency of observed
slider position choices with the model prediction for the adjustment decision. Using this
estimated model of the slider position decision to estimate Vtadj , we can then find the values
of œà1 and ŒõÃÉ that maximize the consistency of the observed timing of adjustments of the
slider with the prediction for the slider position choice conditional on adjustment. Finally,
we check whether the estimated values for œà1 , œà2 , ŒõÃÉ, and ¬µÃÉ coincide with the values assumed
in computing the value function Vt (p). The numerical estimates reported here represent a
solution to this fixed-point problem. In order to compute the best-fitting distribution of
slider choices, ¬µÃÉ, we assume the parametric form ¬µÃÉ(p) = A¬µ(p)Œ≥ , where A is a normalizing
constant that ensures that ¬µÃÉ is a probability distribution that integrates to 1. The parameter
Œ≥ ‚àà [0, 1] determines how close the model-implied reference distribution is to the empirical
unconditional distribution (Œ≥ = 1, which corresponds to the standard rational inattention
model) versus the uninformative, uniform distribution (Œ≥ = 0).

7

C

Full sample results

In this appendix we present results for the full sample (all 110 sessions), including the
repeated sessions.

C.1

Observed Behavior
900
880
860

Average Points

840
820
800
780
760
740
720
700
True p

Bayesian

Observed

Unconditional

Figure C.1: Experiment data for all subbjects and sessions. The scores are broken down by subject.
‚ÄúTrue p‚Äù refers to the score that each subject would have received, given the realized ring draws,
had they known the underlying probabilities at all times. ‚ÄúBayesian‚Äù refers to the scores that
would have been received by each subject, given the realized ring draws, had they acted like the
fully rational optimal Bayesian decisionmaker. ‚ÄúUnconditional‚Äù refers to the scores received under
a constant forecast equal to the unconditional prior of 0.5.

8

1

0.8

0.8
Mean Bayes

Mean Forecast

1

0.6
0.4
0.2

0.4
0.2

0

0
0

0.2

0.4
0.6
Mean True p

0.8

1

1

1

0.8

0.8
Mean True p

Mean Forecast

0.6

0.6
0.4
0.2

0

0.2

0

0.2

0.4
0.6
Mean True p

0.8

1

0.4
0.6
0.8
Mean Forecast

1

0.6
0.4
0.2

0

0
0

0.2

0.4
0.6
0.8
Mean Bayes p

1

Figure C.2: Measures of forecast bias. Upper left: E[pÃÇ|p] versus p. Upper right: E[p‚àó |p] versus p.
Lower left: E[pÃÇ|p‚àó ] versus p‚àó . Lower right: E[p|p‚àó ] versus p‚àó .

Regression: y = Œ± + Œ≤x + 
y x
Œ±
Œ≤
F-stat
pÃÇ p
0.086
0.849
4056
(0.001) (0.002)
‚àó
p p
0.054
0.894
6901
(0.001) (0.001)
p pÃÇ
0.089
0.818
6273
(0.001) (0.002)
0.952
647
pÃÇ p‚àó 0.033
(0.001) (0.002)
TABLE C.1: Regression tests of forecast bias, with alternative choices of the variables y
and x. Standard errors are shown in parentheses below the regression coefficients. The F
statistic in each case is for a test of the null hypothesis that Œ± = 0 and Œ≤ = 1, and under
the null hypothesis should be distributed as F (2, 109888). All null hypotheses have p-values
of less than 10‚àí279 .

9

1800

1200

1600
1000

1400

1200

800

1000
600

800

600

400

400
200

200

0

0

1

3

10

32

100

320

-1

-0.8

(a) Full Sample Spell Lengths

-0.6

-0.4

-0.2

0

0.2

0.4

0.6

0.8

1

(b) Full Sample Adjustment Sizes

Figure C.3: Discreteness. (a) Distribution of the number of ring draws between adjustments (all
sessions). (b) Distribution of the size of changes in the slider position, counting only trials on which
the slider is moved (all sessions).

0.08

0.012

0.07
0.01

0.06
0.008

0.05

0.04

0.006

0.03
0.004

0.02
0.002

0.01

0

0
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

0

1

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Forecast p

Forecast p

(a) Full sample

(b) Subject 2

Figure C.4: Experiment data. Distribution of the subjects‚Äô slider position choices for (a) the full
sample and (b) subject 2.

10

C.2

Estimated Models of the Timing of Slider Adjustments

Table C.2 presents the full-sample results corresponding to those reported in Table 2 of
the text. The top panel of the table presents the best-fitting Bayesian ‚Äúgap-based‚Äù models
of the adjustment decision. The polynomial coefficients are very similar to those obtained
using only the unique sessions. The only change is that the full sample now suggest very
weak evidence in favor of asymmetry, whereas the unique sessions sample failed to reject
the null of a symmetric hazard function. The different magnitudes of the BIC statistics
reflect the differences in the sample size. The middle panel of the table presents the bestfitting optimizing models of the adjustment decision. Once again, the polynomial coefficients
are very similar to those obtained only using the unique sessions, and the ranking of the
alternative models, in terms of the BIC statistic, is also preserved. The bottom panel gives
results for the best-fitting rational inattention model, and these are again similar to those
obtained using only the non-repeated sessions. Again we find that the rational inattention
model offers by far the best fit to our data on the timing of slider adjustments, in terms of
the BIC statistic.
TABLE C.2: Best-fitting models for the full sample, including repeated sessions.
Gap-Based Models
Model
Constant hazard
Polynomial hazard
Symmetric poly.
Model
Ss with errors
Symmetric Ss
Optimizing Models
Model
Constant hazard
Polynomial hazard
Ss with errors
Step function
Inattention Model
Model
Rational inattention

k
1
3
2
k
3
2

Œ∏0
Œ∏1
-2.34
‚Äì
-2.53 -0.41
-2.53
‚Äì

‚àÜ
0.088 -0.64
0.088 -0.92

Œ∏2
‚Äì
7.37
7.38
¬Ø
‚àÜ
0.74
0.92

BIC
65,473
64,112
64,145
BIC
65,464
65,485

k
1
2
2
3

Œ∏0
-2.34
-2.50
‚Äì
‚Äì

Œ∏1
‚Äì
0.92
‚Äì
‚Äì

1
‚Äì
‚Äì
0.088
0.082

¬Ø
2
‚àÜ
BIC
‚Äì
‚Äì
65,473
‚Äì
‚Äì
64,287
0.912 3.87 65,433
0.20 0.60 64,800

k
2

Œ∏0
-2.07

Œ∏1
0.84

œà1
1.19

ŒõÃÉ
0.112

11

BIC
63,606

