{
    "id": 25548,
    "citation_title": "Discrimination In The Age Of Algorithms",
    "citation_author": [
        "Jon Kleinberg",
        "Jens Ludwig",
        "Sendhil Mullainathan",
        "Cass R. Sunstein"
    ],
    "citation_publication_date": "2019-02-11",
    "issue_date": "2019-02-07",
    "revision_date": "2019-02-18",
    "topics": [
        "\n",
        "Public Economics",
        "\n",
        "Health, Education, and Welfare",
        "\n",
        "Other",
        "\n",
        "Law and Economics",
        "\n"
    ],
    "program": [
        "\n",
        "Children and Families",
        "\n",
        "Development Economics",
        "\n",
        "Economics of Education",
        "\n",
        "Economics of Health",
        "\n",
        "Law and Economics",
        "\n",
        "Labor Studies",
        "\n",
        "Public Economics",
        "\n"
    ],
    "projects": null,
    "working_groups": [
        "\n",
        "Economics of Crime",
        "\n",
        "Household Finance",
        "\n",
        "Personnel Economics",
        "\n",
        "Urban Economics",
        "\n"
    ],
    "abstract": "\n\nThe law forbids discrimination. But the ambiguity of human decision-making often makes it extraordinarily hard for the legal system to know whether anyone has actually discriminated. To understand how algorithms affect discrimination, we must therefore also understand how they affect the problem of detecting discrimination. By one measure, algorithms are fundamentally opaque, not just cognitively but even mathematically.  Yet for the task of proving discrimination, processes involving algorithms can provide crucial forms of transparency that are otherwise unavailable.  These benefits do not happen automatically.  But with appropriate requirements in place, the use of algorithms will make it possible to more easily examine and interrogate the entire decision process, thereby making it far easier to know whether discrimination has occurred.  By forcing a new level of specificity, the use of algorithms also highlights, and makes transparent, central tradeoffs among competing values. Algorithms are not only a threat to be regulated; with the right safeguards in place, they have the potential to be a positive force for equity.\n\n",
    "acknowledgement": "\nThanks to Michael Ridgway for his assistance with data analysis; to Justin McCrary for helpful discussions; to Solon Barocas, James Grenier, Saul Levmore, Karen Levy, Eric Posner, Manish Raghavan, and David Robinson for valuable comments; to the MacArthur, Simons, and Russell Sage Foundations for financial support for this work on algorithmic fairness; to the Program on Behavioral Economics and Public Policy at Harvard Law School; and to Tom and Susan Dunn, Ira Handler and the Pritzker Foundation for support of the University of Chicago Urban Labs more generally. Thanks to Andrew Heinrich and Cody Westphal for superb research assistance. All opinions and any errors are obviously ours alone. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}