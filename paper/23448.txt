NBER WORKING PAPER SERIES

TEMPERED PARTICLE FILTERING
Edward Herbst
Frank Schorfheide
Working Paper 23448
http://www.nber.org/papers/w23448

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2017

Schorfheide gratefully acknowledges financial support from the National Science Foundation
under the grant SES 1424843. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research, the Board of
Governors, or the Federal Reserve System.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
Â© 2017 by Edward Herbst and Frank Schorfheide. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including Â© notice, is given to the source.

Tempered Particle Filtering
Edward Herbst and Frank Schorfheide
NBER Working Paper No. 23448
May 2017
JEL No. C11,C32,E32
ABSTRACT
The accuracy of particle filters for nonlinear state-space models crucially depends on the proposal
distribution that mutates time t-1 particle values into time t values. In the widely-used bootstrap
particle filter, this distribution is generated by the state-transition equation. While straightforward
to implement, the practical performance is often poor. We develop a self-tuning particle filter in
which the proposal distribution is constructed adaptively through a sequence of Monte Carlo
steps. Intuitively, we start from a measurement error distribution with an inflated variance, and
then gradually reduce the variance to its nominal level in a sequence of tempering steps. We show
that the filter generates an unbiased and consistent approximation of the likelihood function.
Holding the run time fixed, our filter is substantially more accurate in two DSGE model
applications than the bootstrap particle filter.

Edward Herbst
Board of Governors of the Federal Reserve System
20th Street and Constitution Avenue N.W.
Washington, DC 20551
edward.p.herbst@frb.gov
Frank Schorfheide
University of Pennsylvania
Department of Economics
3718 Locust Walk
Philadelphia, PA 19104-6297
and NBER
schorf@ssc.upenn.edu

1

1

Introduction

Estimated dynamic stochastic general equilibrium (DSGE) models are now widely used by
academics to conduct empirical research in macroeconomics as well as by central banks
to interpret the current state of the economy, to analyze the impact of changes in monetary or fiscal policies, and to generate predictions for macroeconomic aggregates. In most
applications, the estimation uses Bayesian techniques, which require the evaluation of the
likelihood function of the DSGE model. If the model is solved with a (log)linear approximation technique and driven by Gaussian shocks, then the likelihood evaluation can be
efficiently implemented with the Kalman filter. If, however, the DSGE model is solved using
a nonlinear technique, the resulting state-space representation is nonlinear and the Kalman
filter can no longer be used.
FernaÌndez-Villaverde and Rubio-RamÄ±Ìrez (2007) proposed using a particle filter to evaluate the likelihood function of a nonlinear DSGE model, and many other papers have since
followed this approach. However, configuring the particle filter so that it generates an accurate approximation of the likelihood function remains a key challenge. The contribution
of this paper is to propose a self-tuning particle filter, which we call a tempered particle
filter, that in our applications is substantially more accurate than the widely-used bootstrap
particle filter.
Our starting point is the state-space representation of a potentially nonlinear DSGE
model given by a measurement equation and a state-transition equation in form of
yt = Î¨(st ; Î¸) + ut ,

ut âˆ¼ N 0, Î£u (Î¸)

st = Î¦(stâˆ’1 , t ; Î¸),

t âˆ¼ F (Â·; Î¸).



(1)

The functions Î¨(st ; Î¸) and Î¦(stâˆ’1 , t ; Î¸) are generated numerically when solving the DSGE
model. Here yt is a ny Ã— 1 vector of observables, ut is a ny Ã— 1 vector of normally distributed

measurement errors, and st is an ns Ã— 1 vector of hidden states.1 To obtain the likelihood
increments p(yt+1 |Y1:t , Î¸), where Y1:t = {y1 , . . . , yt }, it is necessary to integrate out the latent

states:

p(yt+1 |Y1:t , Î¸) =
1

Z Z

p(yt+1 |st+1 , Î¸)p(st+1 |st , Î¸)p(st |Y1:t , Î¸)dst+1 dst ,

(2)

In principle both Î¨(Â·) and Î¦(Â·) could depend on the time period t in a deterministic manner. We omit
this dependency in our notation. The ut â€™s do not literally have to be measurement errors. They could
also be innovations to fundamentals. All we require is a non-degenerate distribution of yt |st with a scalable
covariance matrix.

2
which can be done recursively with a filter.
Particle filters represent the distribution of the hidden state vector st conditional on time
t information Y1:t = {y1 , . . . , yt } through a swarm of particles {sjt , Wtj }M
j=1 such that
Z
M
1 X
j
j
h(st )Wt â‰ˆ h(st )p(st |Y1:t , Î¸).
M j=1

(3)

The approximation here is in the sense of a strong law of large numbers (SLLN) or a central
limit theorem (CLT). The approximation error vanishes as the number of particles M tends to
infinity. The filter recursively generates approximations of p(st |Y1:t , Î¸) for t = 1, . . . , T and

produces approximations of the likelihood increments p(yt |Y1:t , Î¸) as a by-product. There
exists a large volume of literature on particle filters. Surveys and tutorials are provided,

for instance, by Arulampalam, Maskell, Gordon, and Clapp (2002), CappeÌ, Godsill, and
Moulines (2007), Doucet and Johansen (2011), Creal (2012), and Herbst and Schorfheide
(2015). Textbook treatments of the statistical theory underlying particle filters can be found
in Liu (2001), CappeÌ, Moulines, and Ryden (2005), and Del Moral (2013).
The conceptually most straightforward version of the particle filter is the bootstrap particle filter proposed by Gordon, Salmond, and Smith (1993). This filter uses the statetransition equation to turn sjtâˆ’1 particles onto sjt particles, which are then reweighted based
on their success in predicting the time t observation, measured by p(yt |sjt , Î¸). While the

bootstrap particle filter is easy to implement, it relies on the state-space modelâ€™s ability to
accurately predict yt by forward simulation of the state-transition equation. In general, the
lower the average density p(yt |sjt , Î¸), the more uneven the distribution of the updated particle
weights, and the less accurate the approximation in (3).

Ideally, the proposal distribution for sjt should not just be based on the state-transition
equation p(st |stâˆ’1 , Î¸) but also account for the observation yt . In fact, conditional on sjtâˆ’1 the
optimal proposal distribution is the posterior2

p(st |yt , sjtâˆ’1 , Î¸) âˆ p(yt |st , Î¸)p(st |sjtâˆ’1 , Î¸),

(4)

where âˆ denotes proportionality. Unfortunately, in a generic nonlinear state-space model,

it is not possible to directly sample from this distribution. Constructing an approximation for
2

It is optimal in the sense that it minimizes the variance of the particle weights conditional on
In importance sampling it is approximately true that the smaller the variance of the
importance weights, the smaller is the asymptotic variance of the Monte Carlo approximation.

j
{sjtâˆ’1 , Wtâˆ’1
}M
j=1 .

3
p(st |yt , sjtâˆ’1 , Î¸) in a generic state-space model is difficult and often involves tedious model-

specific calculations that have to be executed by the user of the algorithm prior to its
implementation.3 The innovation in our paper is to generate this approximation in a sequence
of Monte Carlo steps. The basic idea goes back to Godsill and Clapp (2001). Our starting
point is the observation, that the larger the measurement error variance the more accurate the
filter becomes, because holding everything else constant, the variance of the particle weights
decreases. Building on this insight, in each period t, we generate sjt by forward simulation but
then update the particle weights based on a density p1 (yt |st , Î¸) with an inflated measurement
error variance. In a sequence of tempering iterations we reduce this inflated measurement

error variance to its nominal level. These iterations mimic a sequential Monte Carlo (SMC)
algorithm designed for a static parameter and involve correction, selection, and mutation
steps. Such algorithms have been successfully used to approximate posterior distributions
for parameters of econometric models.4
We show that our proposed tempered particle filter produces a valid approximation of the
likelihood function and substantially reduces the Monte Carlo error relative to the bootstrap
particle filter, even after controlling for computational time. Our algorithm can be embedded into particle Markov chain Monte Carlo algorithms that replace the true likelihood by
a particle-filter approximation; see, for instance, FernaÌndez-Villaverde and Rubio-RamÄ±Ìrez
(2007) for DSGE model applications and Andrieu, Doucet, and Holenstein (2010) for the
underlying statistical theory.
The idea of adding tempering steps to the particle filter dates back to Godsill and Clapp
(2001), but it has not been used in the DSGE model literature. Contemporaneously with our
paper, Johansen (2016) developed a particle filter that involves tempering iterations to track
p(st , stâˆ’1 , . . . , stâˆ’L |Y1:t ). While his algorithm allows for the mutation of particles representing
blocks of lagged states, no clear guidance is provided on how the algorithm should be tailored

in a specific application and whether the additional computational cost of mutating lagged
states is compensated by improvements in the accuracy of the likelihood approximation.
Moreover, the paper does not contain any theoretical results and the numerical illustration
is restricted to a univariate model rather than DSGE models with multidimensional state
3
Attempts include approximations based on the one-step Kalman filter updating formula applied to a
linearized version of the DSGE model. Alternatively, one could use the updating step of an approximate
filter, e.g., the ones developed by Andreasen (2013) or Kollmann (2015).
4
Chopin (2002) first showed how to use sequential Monte Carlo methods to conduct inference on a
parameter that does not evolve over time. Applications to the estimation of DSGE model parameters
have been considered in Creal (2007) and Herbst and Schorfheide (2014). Durham and Geweke (2014) and
Bognanni and Herbst (2015) provide applications to the estimation of other econometric time-series models.

4
spaces. In addition, in each time period t we are choosing the tempering schedule adaptively,
building on work by Jasra, Stephens, Doucet, and Tsagaris (2011), Del Moral, Doucet,
and Jasra (2012), SchaÌˆfer and Chopin (2013), Geweke and Frischknecht (2014), and Zhou,
Johansen, and Aston (2015).
There are essentially two methods of establishing theoretical properties of SMC approximations. On the one hand, Del Moral (2004) and Del Moral (2013) use high-level random
field theory. These authors establish theoretical properties of SMC methods through the
lens of the Feynman-Kac formula and its role in stochastic differential equations. While this
approach is mathematically elegant, it relies on theory that is unfamiliar to most econometricians. On the other hand, Chopin (2004) proves a CLT for SMC approximations recursively,
using familiar (to econometricians) CLTs for non-identically and independently distributed
random variables. In a similar fashion, Pitt, Silva, Giordani, and Kohn (2012) show how
one can prove the unbiasedness of particle filter approximation without making use of the
Feynman-Kac formula. We follow this second route and show how the arguments in Chopin
(2004) and Pitt, Silva, Giordani, and Kohn (2012) can be extended to account for the specific tempering iterations used in our algorithm. While the theoretical results in our paper
are restricted to a non-adaptive version of the filter, theoretical results for adaptive SMC
algorithms have recently been obtained by Beskos, Jasra, Kantas, and Thiery (2014).
The remainder of the paper is organized as follows. The proposed tempered particle
filter is presented in Section 2. We provide a SLLN for the particle filter approximation of
the likelihood function in Section 3 and show that the approximation is unbiased. Here we
are focusing on a version of the filter that is non-adaptive. The filter is applied to a smallscale New Keynesian DSGE model and the Smets-Wouters model in Section 4 and Section 5
concludes. Theoretical derivations, computational details, DSGE model descriptions, and
data sources are relegated to the Online Appendix. To simplify the notation, we often drop
Î¸ from the conditioning set of densities p(Â·|Â·).

2

The Tempered Particle Filter

A key determinant of the accuracy of a particle filter is the distribution of the normalized
weights
WÌƒtj

=

1
M

j
wÌƒtj Wtâˆ’1
PM j j ,
j=1 wÌƒt Wtâˆ’1

5
j
where Wtâˆ’1
is the (normalized) weight associated with the jth particle at time t âˆ’ 1, wÌƒtj is

the incremental weight after observing yt , and WÌƒtj is the normalized weight accounting for

this new observation.5 For the bootstrap particle filter, the incremental weight is simply the
likelihood of observing yt given the jth particle, p(yt |sjt ). It is approximately true that, all

else equal, the larger the variance of WÌƒtj â€™s, the less accurate the Monte Carlo approximations

generated by the particle filter.
One can show that, as the measurement error variance increases the variance of the
particle weights {WÌƒt }M
j=1 decreases. Let Î£u /Ï†n , 0 < Ï†n â‰¤ 1 be an inflated measurement

error covariance matrix. Then,




1
0 âˆ’1
pn (yt |st ) âˆ exp âˆ’ Ï†n (yt âˆ’ Î¨(st )) Î£u (yt âˆ’ Î¨(st )) .
2

(5)

j
Assuming that a resampling step equalized the particle weights Wtâˆ’1
= 1, it is straightfor-

ward to verify that
lim

Ï†n âˆ’â†’0

WÌƒtj

=

1
M

pn (yt |sjt )
= 1.
PM
j
j=1 pn (yt |st )

(6)

Thus, in the limit, the variance of the particle weights is equal to zero. With a bit more
algebra, it can be verified that the variance of the particle weights monotonically decreases as
Ï†n âˆ’â†’ 0 (see Appendix for details). We use this insight to construct a tempered particle filter

in which we generate proposed particle values sÌƒjt sequentially, by reducing the measurement
error variance from an inflated initial level Î£u /Ï†1 to the nominal level Î£u using a sequence
of scale factors
0 < Ï†1 < Ï†2 < . . . < Ï†NÏ† = 1.

The reduction of the measurement error variance is achieved by a sequence of Monte Carlo
steps that we borrow from the literature of SMC approximations for posterior moments
of static parameters (see Chopin (2002) and, for instance, the treatment in Herbst and
Schorfheide (2015)).
By construction, pNÏ† (yt |st ) = p(yt |st ). Based on pn (yt |st ), we can define the bridge

distributions

pn (st |yt , stâˆ’1 ) âˆ pn (yt |st )p(st |stâˆ’1 ).

(7)

In the notation developed subsequently, the tilde on WÌƒtj indicates that this is weight associated with
particle j before any resampling of the particles.
5

6
Integrating out stâˆ’1 under the distribution p(stâˆ’1 |Y1:tâˆ’1 ) yields the bridge posterior density
for st conditional on the observables:
pn (st |Y1:t ) =

Z

pn (st |yt , stâˆ’1 )p(stâˆ’1 |Y1:tâˆ’1 )dstâˆ’1 .

(8)

In the remainder of this section, we describe the proposed tempered particle filter. We do so
in two steps: Section 2.1 presents the main algorithm that iterates over periods t = 1, . . . , T
to approximate the likelihood increments p(yt |Y1:tâˆ’1 ) and the filtered states p(st |Y1:t ). In
Section 2.2, we focus on the novel component of our algorithm, which in every period t uses
NÏ† steps to reduce the measurement error variance from Î£u /Ï†1 to Î£u . We provide specific
guidance for practitioners on tuning the tempered particle filter in Section 2.3. Finally, in
Section 2.4 we briefly discuss the relationship between the tempered and the conditionallyoptimal particle filter.

2.1

The Main Iterations

The tempered particle filter has the same structure as the bootstrap particle filter. In
every period t, we draw innovations t and use the state-transition equation to simulate the
state vector forward; we update the particle weights; and we resample the particles. The
key innovation is to start out with a fairly large measurement error variance, which is then
iteratively reduced to the nominal measurement error variance Î£u . As the measurement error
variance is reduced (tempering), we adjust the innovations to the state-transition equation
as well as the particle weights.
The number of tempering stages may differ for every time period t. However, to keep
the notation as simple as possible, we write NÏ† instead of NÏ†,t . Starting from the distribution p(stâˆ’1 |Y1:tâˆ’1 ) and using a sequence of tempering iterations our filter tracks the bridge

distributions pn (st |Y1:t ) defined in (8) for n = 1, . . . , NÏ† . As our filter cycles through the
j,N

Ï†
tempering iterations and mutates the particle values sj,n
t , it keeps the particle values stâˆ’1

unchanged (except during resampling operations so that st states are not separated from the
j,N

Ï†
corresponding stâˆ’1 states). The filter is designed such that the pairs (sj,n
t , stâˆ’1 ) with their

associated particle weights approximate the distributions
pn (st , stâˆ’1 |Y1:t ) = pn (st |stâˆ’1 , Y1:t )p(stâˆ’1 |Y1:t ) for n = 1, . . . , NÏ† .
Because it is convenient for the implementation of the mutation steps, we will include t

7
in the vector of particle values and track the triplet (st , t , stâˆ’1 ) with the understanding
that this triplet always satisfies the state-transition equation st = Î¦(stâˆ’1 , t ). Algorithm 1
summarizes the iterations over periods t = 1, . . . , T .
Algorithm 1 (Tempered Particle Filter)
iid

1. Period t = 0 Initialization. Draw the initial particles from the distribution sj0 âˆ¼
j,NÏ†

p(s0 ), j = 1, . . . , M . Let s0

j,NÏ†

= sj0 and W0

= 1.

2. Period t Iterations. For t = 1, . . . , T :
(a) Particle Initialization.
j,N

j,N

i. Starting from {stâˆ’1Ï† , Wtâˆ’1Ï† }, generate Ëœj,1
t âˆ¼ F (Â·) and define
j,N

Ï†
sÌƒj,1
Ëœj,1
t = Î¦(stâˆ’1 , 
t ).

ii. Compute the incremental weights:
wÌƒtj,1 = p1 (yt |sÌƒj,1
)
t



1
j,1 0 âˆ’1
j,1
âˆ exp âˆ’ Ï†1 yt âˆ’ Î¨(sÌƒt ) Î£u yt âˆ’ Î¨(sÌƒt ) .
2

(9)

iii. Normalize the incremental weights:
j,N

WÌƒtj,1 =

1
M

wÌƒtj,1 Wtâˆ’1Ï†
PM j,1 j,NÏ†
j=1 wÌƒt Wtâˆ’1

(10)

j,N

j,1
Ï†
to obtain the particle swarm {sÌƒj,1
Ëœj,1
t ,
t , stâˆ’1 , WÌƒt }, which leads to

hÌƒ1t,M

Z
M
1 X
j,1 j,NÏ†
j,1
=
h(sÌƒt , stâˆ’1 )WÌƒt â‰ˆ h(st , stâˆ’1 )p1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1 . (11)
M j=1

Moreover,
M
1 X j,1 j,NÏ†
wÌƒ Wtâˆ’1 â‰ˆ p1 (yt |Y1:tâˆ’1 ).
M j=1 t

iv. Resample the particles:
j,N

j,N

j,1
j,1 j,1
j,1
Ï†
Ï†
{sÌƒj,1
Ëœj,1
t ,
t , stâˆ’1 , WÌƒt } 7â†’ {st , t , stâˆ’1 , Wt },

(12)

8
to obtain the approximation
hÌ„1t,M

Z
M
1 X
j,1
j,1 j,NÏ†
=
h(st , stâˆ’1 )Wt â‰ˆ h(st , stâˆ’1 )p1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1 . (13)
M j=1

(b) Tempering Iterations: Execute Algorithm 2 (see next section) to
i. convert the particle swarm
j,NÏ†

j,N

j,1
j,1
Ï†
{sj,1
t , t , stâˆ’1 , Wt } 7â†’ {st

j,NÏ†

, t

j,N

j,NÏ†

, stâˆ’1Ï† , Wt

}

to approximate
N

M
1 X
j,N
j,N
j,N
h(st Ï† , stâˆ’1Ï† )Wt Ï†
M j=1
Z
â‰ˆ
h(st , stâˆ’1 )p(st , stâˆ’1 |Y1:t )dst dstâˆ’1 ;

Ï†
hÌ„t,M
=

(14)

ii. compute the approximation pÌ‚M (yt |Y1:tâˆ’1 ) of the likelihood increment.
3. Likelihood Approximation
pÌ‚M (Y1:T ) =

T
Y
t=1

pÌ‚M (yt |Y1:tâˆ’1 ). 

(15)

If we were to set Ï†1 = 1, NÏ† = 1, and omit Step 2.(b) for all t, then Algorithm 1
is exactly identical to the bootstrap particle filter: the sjtâˆ’1 particle values are simulated
forward using the state-transition equation; the weights are then updated based on how
well the new state sÌƒjt predicts the time t observations, measured by the predictive density
p(yt |sÌƒjt ); and finally the particles are resampled using a standard resampling algorithm, such
as multinominal resampling, or systematic resampling.6 Once the resampling step has been

executed, the particle weights are equalized and the variance of the particle weights is equal
to zero: Wtj,1 = 1 for j = 1, . . . , N . Thus, in principle, we could drop the Wtj,1 weights from
the formulas.
The drawback of the bootstrap particle filter is that the proposal distribution for the
innovation Ëœjt âˆ¼ F (Â·) is â€œblind,â€ in that it is not adapted to the period t observation yt . This
6

Detailed textbook treatments of resampling algorithms can be found in the by Liu (2001) and CappeÌ,
Moulines, and Ryden (2005).

9
typically leads to a large variance in the incremental weights wÌƒtj , which in turn translates into
inaccurate Monte Carlo approximations. Taking the states {sjtâˆ’1 }M
j=1 as given and assuming

j
that a t âˆ’ 1 resampling step has equalized the particle weights, that is, Wtâˆ’1
= 1, the

conditionally optimal choice for the proposal distribution is p(Ëœjt |sjtâˆ’1 , yt ). However, because
of the nonlinearity in state-transition and measurement equation, it is not possible to directly

generate draws from this distribution. The main idea of our algorithm is to sequentially adapt
the proposal distribution for the innovations to the current observation yt by raising Ï†n from
a small initial value to Ï†NÏ† = 1. This is done in Step 2(b), which is described in detail in
Algorithm 2 in the next section.

2.2

Tempering the Measurement Error Variance

The idea of including tempering iterations into a particle filter dates back to Godsill and
Clapp (2001). These iterations build on Neal (1998)â€™s annealed importance sampling and
mimic the steps of SMC algorithms that have been developed for static parameters (e.g.,
Chopin (2002), Del Moral, Doucet, and Jasra (2006), Durham and Geweke (2014), and
Herbst and Schorfheide (2014, 2015)). The goal of SMC algorithms for static parameters
is to generate draws from a posterior distribution p(Î¸|Y ) by sampling from a sequence of
bridge posteriors pn (Î¸|Y ). These bridge posteriors are either generated by sequentially adding
observations to the likelihood function or by tempering the likelihood function, i.e., pn (Î¸|Y ) âˆ

Ï†n
p(Y |Î¸) p(Î¸), n = 1, . . . , NÏ† . In the latter case, the sequence {Ï†n } is chosen such that the
bridge posterior is equal to the actual posterior for n = NÏ† (i.e, when Ï†NÏ† = 1.) At

each iteration, the algorithm cycles through three stages: particle weights are updated in
the correction step; the particles are being resampled and particle weights are equalized in
the selection step; and particle values are changed in the mutation step. The analogue of

Ï†n
p(Y |Î¸)
in our algorithm is pn (yt |st ) given in (5), which reduces to p(yt |st ) for Ï†n = 1.

Algorithm 2 summarizes the correction, selection, and mutation steps. Note that the number
of stages, NÏ† , is an output of the algorithm that is determined in Step 1(a)iii. in conjunction
with the termination condition n = NÏ† of the do-loop. Thus, the filter is adaptive with
respect to the tempering schedule.
Algorithm 2 (Tempering Iterations) This algorithm receives as input the particle swarm
j,N

j,NÏ†

j,1
j,1
Ï†
{sj,1
t , t , stâˆ’1 , Wt } and returns as output the particle swarm {st

the likelihood increment pÌ‚M (yt |Y1:tâˆ’1 ). Set n = 2 and NÏ† = 0.

j,NÏ†

, t

j,N

j,NÏ†

, stâˆ’1Ï† , Wt

} and

10
1. Do until n = NÏ† :
(a) Correction:
i. For j = 1, . . . , M define the incremental weights
pn (yt |sj,nâˆ’1
)
t
j,nâˆ’1
pnâˆ’1 (yt |st
)
d/2


0
Ï†n
1
)
=
exp âˆ’ yt âˆ’ Î¨(sj,nâˆ’1
t
Ï†nâˆ’1
2



j,nâˆ’1
âˆ’1
Ã—(Ï†n âˆ’ Ï†nâˆ’1 )Î£u yt âˆ’ Î¨(st
) .

wÌƒtj,n (Ï†n ) =

(16)

ii. Define the normalized weights
WÌƒtj,n (Ï†n )

=

1
M

wÌƒtj,n (Ï†n )Wtj,nâˆ’1
,
PM j,n
j,nâˆ’1
j=1 wÌƒt (Ï†n )Wt

(17)

(Wtj,nâˆ’1 = 1 because the resampling step was executed in iteration n âˆ’ 1), and

the inefficiency ratio

InEff(Ï†n ) =

M
2
1 X
WÌƒtj,n (Ï†n ) .
M j=1

(18)

iii. If InEff(Ï†n = 1) â‰¤ râˆ— , then set Ï†n = 1, NÏ† = n, and WÌƒtj,n = WÌƒtj,n (Ï†n = 1).

Otherwise, let n = n + 1, Ï†âˆ—n be the solution to InEff(Ï†âˆ—n ) = râˆ— , and WÌƒtj,n =
WÌƒtj,n (Ï†n = Ï†âˆ—n ).
j,N

iv. The particle swarm {sj,nâˆ’1
, j,nâˆ’1
, stâˆ’1Ï† , WÌƒtj,n } approximates
t
t
M
1 X
j,N
h(sj,nâˆ’1
, stâˆ’1Ï† )WÌƒtj,n
t
M j=1
Z
â‰ˆ
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .

hÌƒnt,M =

(19)

(b) Selection: Resample the particles:
j,N

j,N

j,n
Ï†
{sj,nâˆ’1
, j,nâˆ’1
, stâˆ’1Ï† , WÌƒtj,n } 7â†’ {sÌ‚j,n
Ë†j,n
t
t
t ,
t , stâˆ’1 , Wt },

which leads to Wtj,n = 1 for j = 1, . . . , N . Keep track of the correct ancestry infor-

11
j,N

Ï†
Ë†j,n
mation such that sÌ‚j,n
t ) for each j. This leads to the approximation
t = Î¦(stâˆ’1 , 

hÌ‚nt,M

Z
M
1 X
j,n
j,n j,NÏ†
=
h(sÌ‚t , stâˆ’1 )Wt â‰ˆ h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .
M j=1

(20)

(c) Mutation: Use a Markov transition kernel Kn (st |sÌ‚t ; stâˆ’1 ) with the invariance
property

pn (st |yt , stâˆ’1 ) =

Z

Kn (st |sÌ‚t ; stâˆ’1 )pn (sÌ‚t |yt , stâˆ’1 )dsÌ‚t

(21)

to mutate the particle values (see Algorithm 3 for an implementation). This leads
j,N

j,n
j,n
Ï†
to the particle swarm {sj,n
t , t , stâˆ’1 , Wt }, which approximates

hÌ„nt,M

Z
M
1 X
j,n j,NÏ†
j,n
=
h(st , stâˆ’1 )Wt â‰ˆ h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .
M j=1

(22)

2. Approximate the likelihood increment:

pÌ‚M (yt |Y1:tâˆ’1 ) =

NÏ†
Y
n=1

M
1 X j,n j,nâˆ’1
wÌƒ Wt
M j=1 t

!
(23)

j,N

with the understanding that Wtj,0 = Wtâˆ’1Ï† . 
The correction step adapts the stage n âˆ’ 1 particle swarm to the reduced measurement

error variance in stage n by reweighting the particles. The incremental weights in (16)
capture the change in the measurement error variance from Î£u /Ï†nâˆ’1 to Î£u /Ï†n and yield an
importance sampling approximation of pn (st |Y1:t ) based on the stage n âˆ’ 1 particle values.
N

Ï†
As mentioned earlier, rather than relying on a fixed exogenous tempering schedule {Ï†n }n=1
,

we choose Ï†n to achieve a targeted inefficiency ratio râˆ— > 1. This approach of adaptively
choosing the tempering schedule has been used in the SMC literature by Jasra, Stephens,
Doucet, and Tsagaris (2011), Del Moral, Doucet, and Jasra (2012), SchaÌˆfer and Chopin
(2013), and Zhou, Johansen, and Aston (2015). It also has proven useful in the context of
global optimization of nonlinear functions; see Geweke and Frischknecht (2014). To relate
the inefficiency ratio to Ï†n , we begin by defining
1
j,nâˆ’1
ej,t = (yt âˆ’ Î¨(sj,nâˆ’1
))0 Î£âˆ’1
)).
t
u (yt âˆ’ Î¨(st
2

12
Assuming that the particles were resampled in iteration n âˆ’ 1 and Wtj,nâˆ’1 = 1, we can then

express the inefficiency ratio as

PM
M
1
2
1 X
j=1 exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
j,n
M
WÌƒt (Ï†n ) =  P
InEff(Ï†n ) =
2 .
M j=1
M
1
j=1 exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
M

(24)

It is straightforward to verify that for Ï†n = Ï†nâˆ’1 the inefficiency ratio InEff(Ï†n ) = 1 < râˆ— .
Moreover, we show in the Online Appendix that the function is monotonically increasing
on the interval [Ï†nâˆ’1 , 1], which is the justification for Step 1(a)iii of Algorithm 3. Thus, we
are raising Ï†n as closely to one as we can without exceeding a user-defined bound on the
variance of the particle weights. Note that we can use the same approach to set the initial
scaling factor Ï†1 in Algorithm 1.
The selection step is executed in every iteration n to ensure that we can find a unique
Ï†n+1 based on (24) in the subsequent iteration. Thus, Wtj,n = 1 and in principle we could
drop the weights from the formulas. The equalization of the particle weights allows us to
characterize the properties of the function InEff(Ï†n ).
Finally, in the mutation step, we are using a Markov transition kernel to change the partij,n j,n
cle values from (sÌ‚j,n
Ë†j,n
t ,
t ) to (st , t ) in a way to maintain an approximation of pn (st , stâˆ’1 |Y1:t ).
j,1
In the absence of the mutation step, the initial particle values (sj,1
t , t ) generated in Step 2(a)

of Algorithm 2 would never change and we would essentially reproduce the bootstrap particle
filter by computing p(yt |sÌƒjt ) sequentially under a sequence of measurement error covariance

matrices that converges to Î£u . The mutation can be implemented with NM H steps of a
random walk Metropolis-Hastings (RWMH) algorithm; see Algorithm 3 below. Unlike in
j,N

the algorithm proposed by Johansen (2016), we do not mutate the particle values stâˆ’lÏ† ,
l = 1, . . . , L. The advantage is that the state vector that we are mutating has a smaller
dimension, which tends to increase the probability that a particle value changes during
the mutation step. Thus, our algorithm should be able to attain a desired probability of
mutating the particle values with fewer steps of the RWMH algorithm and therefore be
faster. A potential disadvantage is that we are not adapting as well to the joint distribution
pn (st , stâˆ’1 , . . . , stâˆ’L |Y1:t ).
Algorithm 3 (RWMH Mutation Step) This algorithm receives as input the particle swarm
j,N

j,N

j,n
j,n j,n
j,n
Ï†
Ï†
{sÌ‚j,n
Ë†j,n
t ,
t , stâˆ’1 , Wt } and returns as output the particle swarm {st , t , stâˆ’1 , Wt }.

1. Execute NM H Metropolis-Hastings Steps for Each Particle: For j = 1, . . . M :

13
(a) Set Ë†j,n,0
= Ë†j,n
t
t . Then, for l = 1, . . . , NM H :
i. Generate a proposed innovation:

ejt âˆ¼ N Ë†j,n,lâˆ’1
, c2n In .
t
ii. Compute the acceptance rate:
(
Î±(ejt |Ë†j,n,lâˆ’1
)
t

= min

j,N

1,

pn (yt |ejt , stâˆ’1Ï† )p (ejt )
j,N

)
pn (yt |Ë†j,n,lâˆ’1
, stâˆ’1Ï† )p (Ë†j,n,lâˆ’1
t
t

)
.

iii. Update particle values:
(
Ë†j,n,l
t

=

ejt

with prob. Î±(ejt |Ë†j,n,lâˆ’1
)
t

Ë†j,n,lâˆ’1
with prob. 1 âˆ’ Î±(ejt |Ë†j,n,lâˆ’1
)
t
t

(b) Define
MH
,
j,n
Ë†j,n,N
t
t = 

j,N

j,n
Ï†
sj,n

t = Î¦(stâˆ’1 , t ).

The covariance matrix for the proposal distribution in the RWMH algorithm is simply
the identity matrix In scaled by cn .7 We set adaptively by cn to achieve a desired acceptance
rate. In particular, we compute the average empirical rejection rate RÌ‚nâˆ’1 (cnâˆ’1 ), based on
the mutation phase in iteration n âˆ’ 1. The average is computed across the NM H RWMH
steps. We set c1 = câˆ— and, for n > 2, adjust the scaling factor according to

cn = cnâˆ’1 f 1 âˆ’ RÌ‚nâˆ’1 (cnâˆ’1 ) ,

f (x) = 0.95 + 0.10

e20(xâˆ’0.40)
.
1 + e20(xâˆ’0.40)

(25)

This function is designed to increase the scaling factor by 5 percent if the acceptance rate
is well above 0.40, and decrease the scaling factor by 5 percent if the acceptance rate is well
below 0.40. For acceptance rates near 0.40, the increase (or decrease) of cn is attenuated by
the logistic component of f (x). In our empirical applications, the performance of the filter
was robust to variations on the rule.
7

Herbst and Schorfheide (2014) use the particle approximation of the posterior covariance matrix from
the selection step to specify the stage-n proposal covariance matrix. In the tempered particle filter, the cost
of computing this object tends to outweigh the gains from adapation, so we instead use the identity matrix.

14

2.3

Tuning of the Algorithm

In order to run Algorithm 3, the user has to specify the number of particles M , the initial
measurement error precision scaling Ï†1 in Algorithm 1, the targeted inefficiency ratio râˆ— , the
initial scaling of the proposal covariance matrix câˆ— , and the number of Metropolis-Hastings
steps NM H . In principle, the user can also adjust the target acceptance rate (and potentially
the speed of adjustment) in (25). Each of these tuning parameters affects the statistical
properties of the filter, and can potentially affect the computational cost associated with the
filter. We now discuss some issues in selecting each of these parameters.
The selection of M is an issue for any particle filter. A higher M is associated with a
more precise approximation at the cost of a longer run time of the filter. In practice, this is
usually done through experimentation. If the particle filter is embedded in a Markov chain
Monte Carlo (MCMC) algorithm, a heuristic suggested by Pitt, Silva, Giordani, and Kohn
(2012), is to increase M until the standard deviation of the filterâ€™s log likelihood estimate
at some parameter value is less than one. Particle filter approximations typically satisfy a
CLT according to which the variance is proportional to 1/M .
The initial measurement error precision Ï†1 can either be user-specified or determined
adaptively by targeting a desired variance of particle weights as in Step 1(a)iii of Algorithm 2.
The targeted inefficiency ratio, râˆ— âˆˆ (1, âˆ) controls the targeted degree of â€œunevennessâ€ of

the distribution of particle weights that pins down a particular Ï†n . If râˆ— is close to 1,
loosely speaking, Ï†n will be â€œcloseâ€ to Ï†nâˆ’1 and generally there will be many stages (NÏ†
will be large.) In contrast, if râˆ— is very large, bridge distributions can be very different,
and in general NÏ† will be small. In the limit, as râˆ— âˆ’â†’ âˆ, the algorithm converges to the

resample-move variant of the bootstrap particle filter, where NÏ† = 1 for all t. The particles
are mutated at each time t, but there are no intermediate bridge distributions.

A low râˆ— delivers weighted particles with low variance, which all else equal are associated
with more precise Monte Carlo estimates. Of course, a low râˆ— is also associated with many
bridge distributions, which increases the run time of the filter. At some point, increasing
the number of tempering iterations further, could in principle result in less precise estimates
because of the variability induced by the additional resampling and mutation steps. In
practice, we donâ€™t find this be an issue, and so râˆ— works as a complement to M , with both
having a trade-off between statistical precision and computational cost. In Section 4 we
examine the effects of different choices of M and râˆ— in two DSGE models.

15
The other two tuning parameters, namely, the initial scaling of the proposal covariance
matrix câˆ— and the number of RWMH steps NM H , are less important. If there are many
bridge distributions, the influence of the initial scaling factor câˆ— is diminished because it is
adjusted in each subsequent iteration. While many intermediate RWMH steps help to ensure
that the particles are both diverse and well-adapted to any given bridge distribution, often
this effect can be achieved by choosing a lower râˆ— . Of course, this is not to say that câˆ— and
NM H do not affect the variance of the Monte Carlo estimates. In any particular application,
experimentation with these parameters may enhance the performance of the algorithm. In
Section 4.2 we analyze the effects of increasing NM H .
Finally, we could replace the draws of Ëœj,1
from the innovation distribution F (Â·) in
t
j,N

Ï†
Step 2(a)i of Algorithm 2 with draws from a tailored distribution with density gt1 (Ëœj,1
t |stâˆ’1 )

j,N

1 j,1
and then adjust the incremental weight Ï‰Ìƒtj,1 by the ratio p (Ëœj,1
t |stâˆ’1Ï† ), as it is done
t )/gt (Ëœ

in the generalized version of the particle filter. Here the gt (Â·) density might be constructed
based on a linearized version of the DSGE model or be obtained through the updating steps
of a conventional nonlinear filter, such as an extended Kalman filter, unscented Kalman filter, or a Gaussian quadrature filter; see Herbst and Schorfheide (2015). Thus, the proposed
tempering steps can be used either to relieve the user from the burden of having to construct
j,N

Ï†
a gt1 (Ëœj,1
t |stâˆ’1 ) in the first place, or it could be used to improve upon the accuracy obtained

j,N

Ï†
with a readily available gt1 (Ëœj,1
t |stâˆ’1 ).

2.4

Relationship to Conditionally-Optimal Particle Filter

We mentioned in the introduction that conditional on the sjtâˆ’1 particles it is optimal to
generate draws from the proposal distribution p(st |yt , stâˆ’1 ) given in (4). The tempered

particle filter generates a sequence of approximations pn (st , stâˆ’1 |yt , Y1:tâˆ’1 ) that converge to
p(st , stâˆ’1 |yt , Y1:tâˆ’1 ) as n âˆ’â†’ NÏ† . This raises the question to what extent this filter can

achieve conditionally optimality. Because p(st |yt , stâˆ’1 ) and pn (st , stâˆ’1 |yt , Y1:tâˆ’1 ) are not the
same objects, we provide a comparison of the two approaches by embedding the conditionallyoptimal proposal distribution into Algorithm 1.
Suppose in Step 2(a)i we draw sÌƒj,1
t,âˆ— (we are using the âˆ— subscript to indicate draws and

weights associated with the conditionally-optimal proposal) from
j,N

j,N

p1 (st |yt , stâˆ’1Ï† ) âˆ p1 (yt |st )p(st |stâˆ’1Ï† ),

(26)

16
where p1 (yt |st ) is based on scaling the precision of the measurement errors by Ï†1 .8 The
incremental weights for sÌƒj,1
t,âˆ— are given by

j,N

j,1
wÌƒt,âˆ—

=

p1 (yt |sÌƒj,1
t,âˆ— )

Ï†
p(sÌƒj,1
t,âˆ— |stâˆ’1 )

j,NÏ†
p1 (sÌƒj,1
t,âˆ— |yt , stâˆ’1 )

j,N

= p1 (yt |stâˆ’1Ï† ).

(27)

j,1
For every choice Ï†Ìƒ1 of the measurement error precision, the variance of the wÌƒt,âˆ—
weights is

smaller than the variance of the weights wÌƒtj,1 obtained under the bootstrap proposal, because
the conditionally-optimal proposal is designed to minimize the variance of the particle weights
j,N

j,N

conditional on the swarm {stâˆ’1Ï† , Wtâˆ’1Ï† }. Moreover, we know from (24) that the variance of
the particle weights is an increasing function of Ï†1 . Thus, if we choose Ï†1 adaptively according
to Step 1(a)iii of Algorithm 2 by targeting a specific variance of the particle weights (or the
a particular inefficiency ratio), then it has to be the case that the precision chosen under the
conditionally-optimal proposal, say Ï†1,âˆ— , is larger (and closer to one) than the precision Ï†1
chosen under the bootstrap proposal.
j,1
This leads to the following conclusions: (i) if the variance of the wÌƒt,âˆ—
is sufficiently small,
j,1
then Ï†1,âˆ— = 1 and the tempering iterations become obsolete. (ii) If the variance of the wÌƒt,âˆ—
is

large enough such that Ï†1,âˆ— < 1, then, because Ï†1,âˆ— â‰¥ Ï†1 , the tempered particle filter with the
conditionally-optimal proposal distribution will be more accurate than the tempered particle
filter based on the bootstrap proposal. The former will either use fewer iterations to bridge
the discrepancy between p1 (st , stâˆ’1 |Y1:t ) and p(st , stâˆ’1 |Y1:t ) or it will use the same number of
iterations with smaller gaps between pnâˆ’1 (st , stâˆ’1 |Y1:t ) and pn (st , stâˆ’1 |Y1:t ).

The implementation of the conditionally-optimal particle filter is typically infeasible in
practice. Thus, the tempered particle filter is meant to be a feasible alternative that dominates the widely-used bootstrap particle filter. However, the discussion emphasizes an imj,N

portant point made at the end of Section 2.3: if a better proposal than p(st |stâˆ’1Ï† ) is available,
then it should be used along with the tempering iterations.
8

If one can sample from the conditionally-optimal proposal for Ï†n = 1, then it is reasonable to assume
that one can sample from this density for 0 < Ï†n â‰¤ 1. This is certainly true for normally distributed
measurement errors.

17

3

Theoretical Properties of the Filter

We will now examine asymptotic (with respect to the number of particles M ) and finite
sample properties of the particle filter approximation of the likelihood function. Section 3.1
provides a SLLN, and Section 3.2 shows that the likelihood approximation is unbiased.
Throughout this section, we will focus on a version of the filter that is non-adaptive.9 This
version of the filter replaces Algorithm 2 with Algorithm 4 and Algorithm 3 with Algorithm 5:
Algorithm 4 (Tempering Iterations â€“ Non-Adaptive) This algorithm is identical to
N

Ï†
is pre-determined. The
Algorithm 2, with the exception that the tempering schedule {Ï†n }n=1

Do until n = NÏ† -loop is replaced by a For n = 1 to NÏ† -loop and Step 1(a)iii is eliminated. 
Algorithm 5 (RWMH Mutation Step â€“ Non-Adaptive) This algorithm is identical
N

Ï†
to Algorithm 3 with the exception that the sequence {cn , }n=1
is pre-determined. 

3.1

Asymptotic Properties

Under suitable regularity conditions, the Monte Carlo approximations generated by a particle
filter satisfy a SLLN and a CLT. Proofs for a generic particle filter are provided in Chopin
(2004). We will subsequently establish a SLLN for the tempered particle filter by modifying
the recursive proof developed by Chopin (2004) to account for the tempering iterations of
Algorithm 4. In this paper, we are primarily interested in establishing an almost-sure limit
for the Monte Carlo approximation of the likelihood function:
ï£«

ï£¶
NÏ†
Y
pn (yt |Y1:tâˆ’1 ) ï£¸
a.s.
ï£­p1 (yt |Y1:tâˆ’1 )
pÌ‚M (Y1:T ) =
pÌ‚M (yt |Y1:tâˆ’1 ) âˆ’â†’
= p(Y1:T ).
p (y |Y
)
n=2 nâˆ’1 t 1:tâˆ’1
t=1
t=1
T
Y

T
Y

(28)

Here the last equality follows because pNÏ† (yt |Y1:tâˆ’1 ) = p(yt |Y1:tâˆ’1 ) by definition. The limit

is obtained by letting the number of particles M âˆ’â†’ âˆ. We assume that the length of the
sample T is fixed. As a by-product, we also derive an almost-sure limit for Monte Carlo
approximations of moments of the filtered states:
hÌ„nt,M
9

Z Z
M
1 X
j,n j,NÏ†
j,n a.s.
=
h(st , stâˆ’1 )Wt âˆ’â†’
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .
M j=1

(29)

Some asymptotic results for adaptive SMC algorithms are available in the literature, e.g., Herbst and
Schorfheide (2014) and Beskos, Jasra, Kantas, and Thiery (2014).

18
We use h(Â·) to denote a generic function of both st and stâˆ’1 for technical reasons that will
be explained below.10 Of course, a special case is a function that is constant with respect to
stâˆ’1 . We simply denote such functions by h(st ).
To guarantee the almost-sure convergence, we need to impose some regularity conditions
on the functions h(st , stâˆ’1 ). We define the following classes of functions:
Ht1


Z
=
h(st , stâˆ’1 )
Ep(Â·|stâˆ’1 ) [|h(st , stâˆ’1 )|]p(stâˆ’1 |Y1:tâˆ’1 )dstâˆ’1 < âˆ,


1+Î´
âˆƒÎ´ > 0 s.t. Ep(Â·|stâˆ’1 ) h(st , stâˆ’1 ) âˆ’ Ep(Â·|stâˆ’1 ) [h]
< C < âˆ,

NÏ†
Ep(Â·|stâˆ’1 ) [h] âˆˆ Htâˆ’1

(30)

and for n = 2, . . . , NÏ† :
Htn


=

h(st , stâˆ’1 ) h(st , stâˆ’1 ) âˆˆ Htnâˆ’1 ,

âˆƒÎ´ > 0 s.t. EKn (Â·|sÌ‚t ,stâˆ’1 ) h(st , stâˆ’1 ) âˆ’ EKn (Â·|sÌ‚t ,stâˆ’1 ) [h]

nâˆ’1
EKn (Â·|sÌ‚t ,stâˆ’1 ) [h(st , stâˆ’1 )] âˆˆ Ht
.

(31)
1+Î´


< C < âˆ,

By definition, HtnÌƒ âŠ† Htn for nÌƒ > n. The classes Htn are chosen such that the moment bounds
j,N

Ï†
that guarantee the almost sure convergence of Monte Carlo averages of h(sj,n
t , stâˆ’1 ) are

satisfied. The key assumption here is that there exists a uniform bound for the centered 1+Î´
conditional moment of the function h(st , stâˆ’1 ) under the state-transition density p(st |stâˆ’1 )
and the transition kernel of the mutation step of Algorithm 5, Kn (st |sÌ‚t , stâˆ’1 ). This will allow

us to apply a SLLN to the particles generated by the forward simulation of the model and
the mutation step in the tempering iterations.
N

For the class H11 to be properly defined according to (30), we need to define H0 Ï† . Let
N

H0 = H0 Ï† and note that Ep(Â·|s0 ) [h] is a function of s0 only. Thus, we define

H0 = h(s0 )

Z


|h(s0 )|p(s0 )ds0 < âˆ .

(32)

Under the assumption that the initial particles are generated by i.i.d. sampling from p(s0 ),
10

Spoiler alert: we need the stâˆ’1 because the Markov transition kernel generated by Algorithm 4 (or
Algorithm 2) is invariant under the distribution pn (st |yt , stâˆ’1 ), which is conditioned on stâˆ’1 , instead of the
distribution pn (st |Y1:t ).

19
the integrability conditions ensure that we can apply Kolmogorovâ€™s SLLN. Throughout this
paper, we use C to denote a generic constant. Notice that any bounded function |h(Â·)| < h

is an element of Htn for all t and n. Under the assumption that the measurement errors have a multivariate normal distribution, the densities pn (yt |st ) and the density ratios

pn (yt |st )/pnâˆ’1 (yt |st ) are bounded uniformly in st , which means that these functions are ele-

ments of all Htn .

By changing the definition of the classes Htn and requiring moments of order 2+Î´ to exist,

the subsequent theoretical results can be extended to a CLT following arguments in Chopin
(2004) and Herbst and Schorfheide (2014). The CLT provides a justification for computing
numerical standard errors from the variation of Monte Carlo approximations across multiple
independent runs of the filter, but the formulas for the asymptotic variances have an awkward
recursive form that makes it infeasible to evaluate them. Thus, they are of limited use in
practice.

3.1.1

Algorithm 1

To prove the convergence of the Monte Carlo approximations generated in Step 2(a) of
Algorithm 1, we can use well established arguments for the bootstrap particle filter, which we
a.s.

adapt from the presentation in Herbst and Schorfheide (2015). We use âˆ’â†’ to denote almost-

sure convergence as M âˆ’â†’ âˆ. The starting point is the following recursive assumption:
j,N

j,N

Assumption 1 The particle swarm {stâˆ’1Ï† , Wtâˆ’1Ï† } generated by the period t âˆ’ 1 iteration of

Algorithm 1 approximates:
NÏ†
hÌ„tâˆ’1,M

Z
M
1 X
j,NÏ†
j,NÏ† a.s.
=
h(stâˆ’1 )Wtâˆ’1 âˆ’â†’ h(stâˆ’1 )p(stâˆ’1 |Y1:tâˆ’1 )dstâˆ’1 .
M j=1

(33)

N

Ï†
for functions h(stâˆ’1 ) âˆˆ Htâˆ’1
.

In our statement of the recursive assumption, we only consider functions that vary with
stâˆ’1 , which is why we write h(stâˆ’1 ) (instead of h(stâˆ’1 , stâˆ’2 )). As discussed previously, if the
filter is initialized by direct sampling from p(s0 ), then the recursive assumption is satisfied
for t = 1. Conditional on the recursive assumption, we can obtain the following convergence
result:

20
Lemma 1 Suppose that Assumption 1 is satisfied. Then for h âˆˆ Ht1 :
hÌ‚1t,M
hÌƒ1t,M
hÌ„1t,M

Z Z
M
1 X
j,NÏ† a.s.
j,1 j,NÏ†
=
h(st , stâˆ’1 )p(st , stâˆ’1 |Y1:tâˆ’1 )dst dstâˆ’1
(34)
h(sÌƒt , stâˆ’1 )Wtâˆ’1 âˆ’â†’
M j=1
PM
j,NÏ†
Z Z
j,1
j,1 j,NÏ†
1
a.s.
j=1 h(sÌƒt , stâˆ’1 )wÌƒt Wtâˆ’1
M
=
âˆ’â†’
h(st , stâˆ’1 )p1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1 (35)
PM j,1 j,NÏ†
1
wÌƒ
W
tâˆ’1
j=1 t
M
Z Z
M
1 X
j,1 a.s.
j,1 j,NÏ†
=
h(st , stâˆ’1 )p1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .
(36)
h(st , stâˆ’1 )Wt âˆ’â†’
M j=1

Moreover,
Z
M
1 X j,1 j,NÏ† a.s.
pÌ‚1 (yt |Y1:tâˆ’1 ) =
wÌƒ Wtâˆ’1 âˆ’â†’ p1 (yt |st )p1 (st |Y1:tâˆ’1 )dst .
M j=1 t

(37)

A formal proof of Lemma 1 that verifies the moment conditions required for the almostsure convergence is provided in the Online Appendix. Subsequently, we provide the key steps
of the argument. Because we need to keep track of joint densities (st , stâˆ’1 ), we define
pn (st , stâˆ’1 |Y1:t ) = R

pn (yt |st )p(st |stâˆ’1 )p(stâˆ’1 |Y1:tâˆ’1 )
R

.
pn (yt |st ) p(st |stâˆ’1 )p(stâˆ’1 |Y1:tâˆ’1 )dstâˆ’1 dst

Here we used the fact that, according to the state-space model, the distribution of yt conditional on st does not depend on (stâˆ’1 , Y1:tâˆ’1 ). Moreover, the distribution of st conditional
on stâˆ’1 does not depend on Y1:tâˆ’1 . Thus, integrating with respect to stâˆ’1 yields
Z

pn (st , stâˆ’1 |Y1:t )dstâˆ’1 = pn (st |Y1:t ),

where pn (st |Y1:t ) was previously introduced in (8).
The forward iteration of the state-transition equation amounts to drawing sjt from the
j,N

density p(st |stâˆ’1Ï† ). Use Ep(Â·|sj,NÏ† ) [h] to denote expectations under this density and consider
tâˆ’1

21
the decomposition:
hÌ‚1t,M

âˆ’

Z Z

h(st , stâˆ’1 )p(st , stâˆ’1 |Y1:tâˆ’1 )dst dstâˆ’1

(38)


M 
1 X
j,N
j,1 NÏ†
=
h(sÌƒt , stâˆ’1 ) âˆ’ Ep(Â·|sj,NÏ† ) [h] Wtâˆ’1Ï†
M j=1
tâˆ’1

Z Z
M 
1 X
j,NÏ†
+
h(st , stâˆ’1 )p(st , stâˆ’1 |Y1:tâˆ’1 )dst dstâˆ’1
Ep(Â·|sj,NÏ† ) [h]Wtâˆ’1 âˆ’
M j=1
tâˆ’1
= I + II
j,N

j,N

Both terms converge to zero. First, conditional on the particles {stâˆ’1Ï† , Wtâˆ’1Ï† }, the weights
j,N

Wtâˆ’1Ï† are known, and term I is an average of mean-zero random variables that are indeN

Ï†
pendently distributed. Second, the definition of Ht1 implies that Ep(Â·|sj,NÏ† ) [h] âˆˆ Htâˆ’1
. Thus,
tâˆ’1

we can deduce from Assumption 1 that term II converges to zero. This delivers (34). In

slight abuse of notation, we can now set h(Â·) to either h(st )p1 (yt |st ) or p1 (yt |st ) to deduce
the convergence result required to justify the approximations in (35) and (37). Finally, the
SLLN is preserved by the resampling step, which delivers (36).

3.1.2

Algorithm 4

The convergence results for the tempering iterations rely on the following recursive assumption, which according to Lemma 1 is satisfied for n = 2.
j,N

Assumption 2 The particle swarm {sj,nâˆ’1
, stâˆ’1Ï† , Wtj,nâˆ’1 } generated by iteration n âˆ’ 1 of
t
Algorithm 4 approximates:
hÌ„nâˆ’1
t,M

Z Z
M
1 X
j,nâˆ’1 a.s.
j,nâˆ’1 j,NÏ†
=
h(st
, stâˆ’1 )Wt
âˆ’â†’
h(st , stâˆ’1 )pnâˆ’1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1
M j=1

for functions h âˆˆ Htn .
The convergence results are stated in the following lemma:

(39)

22
Lemma 2 Suppose that Assumption 2 is satisfied. Then for h âˆˆ Htnâˆ’1 :
hÌƒnt,M

=

1
M

a.s.

âˆ’â†’
hÌ‚nt,M

j,nâˆ’1 j,NÏ†
, stâˆ’1 )wÌƒtj,n Wtj,nâˆ’1
j=1 h(st
PM j,n j,nâˆ’1
1
j=1 wÌƒt Wt
M

PM

Z Z

(40)

h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1

Z Z
M
1 X
j,n a.s.
j,n j,NÏ†
=
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .
h(sÌ‚t , stâˆ’1 )Wt âˆ’â†’
M j=1

(41)

Moreover,


pn (y\
t |Y1:tâˆ’1 )
pnâˆ’1 (yt |Y1:tâˆ’1 )



M
1 X j,n j,nâˆ’1 a.s. pn (yt |Y1:tâˆ’1 )
=
wÌƒ Wt
âˆ’â†’
M j=1 t
pnâˆ’1 (yt |Y1:tâˆ’1 )

(42)

and for h âˆˆ Htn ,
hÌ„nt,M

Z Z
M
1 X
j,n j,NÏ†
j,n a.s.
=
h(st , stâˆ’1 )Wt âˆ’â†’
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .
M j=1

(43)

The convergence in (43) implies that the recursive Assumption 2 is satisfied for iteration
n + 1 of Algorithm 4. Thus, we deduce that the convergence in (43) holds for n = NÏ† .
This, in turn, implies that if the recursive Assumption 2 for Algorithm 1 is satisfied at the
beginning of period t, it will also be satisfied at the beginning of period t + 1. A formal proof
of Lemma 2 is provided in the Online Appendix. We will provide an outline of the argument
below.
Correction and Selection Steps. The convergence of the approximations in (40) and
(42), obtained after executing the correction step, follows from the recursive Assumption 2
j,N

j,N

and the fact that h(sj,nâˆ’1
, stâˆ’1Ï† ) âˆˆ Htnâˆ’1 and h(sj,nâˆ’1
, stâˆ’1Ï† )wÌƒtj,n âˆˆ Htnâˆ’1 . Furthermore, it
t
t
relies on the following calculation:

pn (yt |st )
h(st , stâˆ’1 ) pnâˆ’1
p (s , s |Y )dst dstâˆ’1
(yt |st ) nâˆ’1 t tâˆ’1 1:t
R pn (yt |st )
p (s |Y )dst
pnâˆ’1 (yt |st ) nâˆ’1 t 1:t
RR
pn (yt |st ) pnâˆ’1 (yt |st )p(st ,stâˆ’1 |Y1:tâˆ’1 )
dst dstâˆ’1
h(st , stâˆ’1 ) pnâˆ’1
(yt |st )
pnâˆ’1 (yt |Y1:tâˆ’1 )
=
R pn (yt |st ) pnâˆ’1 (yt |st )p(st |Y1:tâˆ’1 )
dst
pnâˆ’1 (yt |st )
pnâˆ’1 (yt |Y1:tâˆ’1 )
RR
h(st , stâˆ’1 )pn (yt |st )p(st , stâˆ’1 |Y1:tâˆ’1 )dst dstâˆ’1
R
=
pn (yt |st )p(st |Y1:tâˆ’1 )dst
Z Z
=
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .

RR

(44)

23
The first equality is obtained by reversing Bayes Theorem and expressing the â€œposteriorâ€
pnâˆ’1 (st , stâˆ’1 |Y1:t ) as the product of â€œlikelihoodâ€ pnâˆ’1 (yt |st ) and â€œpriorâ€ p(st , stâˆ’1 |Y1:tâˆ’1 ) divided by the â€œmarginal likelihoodâ€ pnâˆ’1 (yt |Y1:tâˆ’1 ). We then cancel the pnâˆ’1 (yt |st ) and the

marginal likelihood terms to obtain the second equality. Finally, an application of Bayes
Theorem leads to the third equality.
Recall that pNÏ† (yt |Y1:tâˆ’1 ) = p(yt |Y1:tâˆ’1 ) by construction and that an approximation of

p1 (yt |Y1:tâˆ’1 ) is generated in Step 2(a)iii of Algorithm 1. Together, this leads to the approxi-

mation of the likelihood increment p(yt |Y1:tâˆ’1 ) in (23). Resampling after the correction step

preserves the SLLN, which delivers (41).

Mutation Step. We now outline how to establish (43). Let
Z
EKn (Â·|sÌ‚t ;stâˆ’1 ) [h] =

h(st , stâˆ’1 )Kn (st |sÌ‚t ; stâˆ’1 )dst ,

which is a function of (sÌ‚t , stâˆ’1 ). We can decompose the Monte Carlo approximation from
the mutation step as follows:
Z Z
M
1 X
j,n j,NÏ†
j,n
h(st , stâˆ’1 )Wt âˆ’
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1
(45)
M j=1

M 
1 X
j,n j,NÏ†
h(st , stâˆ’1 ) âˆ’ EK (Â·|sÌ‚j,n ;sj,NÏ† ) [h] Wtj,n
=
n
M j=1
t
tâˆ’1

Z Z
M 
1 X
EK (Â·|sÌ‚j,n ;sj,NÏ† ) [h] âˆ’
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 Wtj,n
+
n
M j=1
t
tâˆ’1
= I + II,

say.
j,N

j,n
Ï†
By construction, conditional on the particles {sÌ‚j,n
t , stâˆ’1 , Wt }, term I is an average of

independent mean-zero random variables, which converges to zero.

The analysis of term II is more involved for two reasons. First, as previously highlighted,
EK

j,n j,NÏ†
n (Â·|sÌ‚t ;stâˆ’1 )

[h] is a function not only of sÌ‚t but also of stâˆ’1 . Second, while the invariance

24
property (21) implies that
Z

EKn (Â·|sÌ‚t ;stâˆ’1 ) [h]pn (sÌ‚t |yt , stâˆ’1 )dsÌ‚t

Z Z
=
h(st , stâˆ’1 )Kn (st |sÌ‚t ; stâˆ’1 )dst pn (sÌ‚t |yt , stâˆ’1 )dsÌ‚t
Z

Z
=
h(st , stâˆ’1 )
Kn (st |sÌ‚t ; stâˆ’1 )pn (sÌ‚t |yt , stâˆ’1 )dsÌ‚t dst
Z
=
h(st , stâˆ’1 )pn (st |yt , stâˆ’1 )dst ,

(46)

j,N

j,n
Ï†
the summation over (sÌ‚j,n
t , stâˆ’1 , Wt ) generates an integral with respect to pn (st , stâˆ’1 |Y1:t )

instead of pn (st |yt , stâˆ’1 ); see (41).

To obtain the expected value of EKn (Â·|sÌ‚t ;stâˆ’1 ) [h] under the distribution pn (sÌ‚t , stâˆ’1 |Y1:t ),

notice that

pn (st , stâˆ’1 |Y1:t ) = pn (st , stâˆ’1 |yt , Y1:tâˆ’1 )

(47)

= pn (st |stâˆ’1 , yt , Y1:tâˆ’1 )p(stâˆ’1 |yt , Y1:tâˆ’1 )
= pn (st |stâˆ’1 , yt )p(stâˆ’1 |yt , Y1:tâˆ’1 ).
The last equality holds because, using the first-order Markov structure of the state-space
model, we can write
pn (yt |st , stâˆ’1 , Y1:tâˆ’1 )p(st |stâˆ’1 , Y1:tâˆ’1 )
p (y |s , s , Y1:tâˆ’1 )p(st |stâˆ’1 , Y1:tâˆ’1 )dst
st n t t tâˆ’1

pn (st |yt , stâˆ’1 , Y1:tâˆ’1 ) = R

pn (yt |st )p(st |stâˆ’1 )
p (y |s )p(st |stâˆ’1 )dst
st n t t

= R

= pn (st |yt , stâˆ’1 ).
Therefore, we obtain
Z Z

EKn (Â·|sÌ‚t ;stâˆ’1 ) [h]pn (sÌ‚t , stâˆ’1 |Y1:t )dsÌ‚t dstâˆ’1

Z Z
=
EKn (Â·|sÌ‚t ;stâˆ’1 ) [h]pn (sÌ‚t |yt , stâˆ’1 )dsÌ‚t pn (stâˆ’1 |yt , Y1:tâˆ’1 )dstâˆ’1

Z Z
=
h(st , stâˆ’1 )pn (st |yt , stâˆ’1 )dst pn (stâˆ’1 |yt , Y1:tâˆ’1 )dstâˆ’1
Z Z
=
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .

(48)

25
The first equality uses (47). The second equality follows from the invariance property (46).
For the third equality, we used (47) again. Thus, under suitable regularity conditions, term
II also converges to zero almost surely, which leads to the convergence in (43).
We can deduce from Lemmas 1 and 2 that we obtain almost-sure approximations of the
likelihood increment for every period t = 1, . . . , T . Because T is fixed and pNÏ† (yt |Y1:tâˆ’1 ) =

p(yt |Y1:tâˆ’1 ), we obtain the following theorem:

Theorem 1 Consider the nonlinear state-space model (1) with Gaussian measurement errors. Suppose that the initial particles are generated by i.i.d. sampling from p(s0 ). Then
the Monte Carlo approximation of the likelihood function generated by Algorithms 1, 4, 5 is
consistent:
ï£¶
NÏ†
Y
pn (yt |Y1:tâˆ’1 ) ï£¸
a.s.
ï£­p1 (yt |Y1:tâˆ’1 )
= p(Y1:T ).
pÌ‚M (Y1:T ) =
pÌ‚M (yt |Y1:tâˆ’1 ) âˆ’â†’
p (y |Y
)
t=1
t=1
n=2 nâˆ’1 t 1:tâˆ’1
T
Y

3.2

T
Y

ï£«

(49)

Unbiasedness

Particle filter approximations of the likelihood function are often embedded into posterior
samplers for the parameter vector Î¸, e.g., a Metropolis-Hastings algorithm or a SMC algorithm; see Herbst and Schorfheide (2015) for a discussion and further references in the context
of DSGE models. A necessary condition for the convergence of the posterior sampler is that
the likelihood approximation of the particle filter is unbiased.
Theorem 2 Suppose that the tempering schedule is deterministic and that the number of
stages NÏ† is the same for each time period t â‰¥ 1. Then, the particle filter approximation of
the likelihood generated by Algorithm 1 is unbiased:
ï£® ï£«
NÏ†
T
Y
Y


ï£°
ï£­
E pÌ‚M (Y1:T ) = E
t=1

n=1

!ï£¶ï£¹
M
X
1
wÌƒj,n Wtj,nâˆ’1 ï£¸ï£» = p(Y1:T ).
M j=1 t

(50)

A proof of Theorem 2 unbiasedness is provided in the Online Appendix. Our proof exploits the recursive structure of the algorithm and extends the proof by Pitt, Silva, Giordani,
and Kohn (2012) to account for the tempering iterations.

26

4

DSGE Model Applications

In this section, we assess the performance of the tempered particle filter (TPF) and the
bootstrap particle filter (BSPF). The principle point of comparison is the accuracy of the
approximation of the likelihood function, but we will also assess each filterâ€™s ability to track
the filtered states. We consider two models in the subsequent analysis. The first is a smallscale New Keynesian DSGE model that comprises a consumption Euler equation, a New
Keynesian Phillips curve, a monetary policy rule, and three exogenous shock processes. The
second model is the medium-scale DSGE model by Smets and Wouters (2007), which is the
core of many of the models that are being used in academia and at central banks.
While the exposition of the algorithms in this paper focuses on the nonlinear state-space
model (1), the numerical illustrations are based on linearized versions of the DSGE models.
Linearized DSGE models (with normally distributed innovations) lead to a linear Gaussian
state-space representation. This allows us to use the Kalman filter to compute the exact
values of the likelihood function p(Y1:T |Î¸) and the filtered states E[st |Y1:t , Î¸].
We assess the accuracy of the particle filter approximations by running the filters repeatedly and studying the sampling distribution of their output across independent runs. To
evaluate the accuracy of pÌ‚M (Y1:T |Î¸) we consider two statistics. The first is the log likelihood

approximation error,

Ë† 1 = ln pÌ‚M (Y1:T |Î¸) âˆ’ ln p(Y1:T |Î¸).
âˆ†

(51)

Because the particle filter approximation of the likelihood function is unbiased (see Theorem 2), Jensenâ€™s inequality applied to the concave logarithmic transformation implies that
Ë† 1 is negative. Second, we consider the following statistic:11
the expected value of âˆ†
Ë† 2 = pÌ‚M (Y1:T |Î¸) âˆ’ 1 = exp[ln pÌ‚M (Y1:T |Î¸) âˆ’ ln p(Y1:T |Î¸)] âˆ’ 1.
âˆ†
p(Y1:T |Î¸)

(52)

Ë† 2 requires us to exponentiate the difference in log-likelihood values,
The computation of âˆ†
which is feasible if the particle filter approximation is reasonably accurate. The unbiasedness
Ë† 2 should be close to zero.
result implies that the sampling mean of âˆ†
In our experiments, we run the filters Nrun = 100 times and examine the sampling
Ë† 1 and âˆ†
Ë† 2 . Because there is always a trade-off between
properties of the discrepancies âˆ†
11

Assessing the bias of the likelihood function pÌ‚M (Y1:T |Î¸) directly is numerically challenging because
exponentiating a log-likelihood value of around âˆ’300 leads to a missing value using standard software.

27
accuracy and speed, we also assess the run-time of the filters.12 The run-time of any particle
filter is sensitive to the exact computing environment used. Thus, we provide details about
the implementation in the Online Appendix. In this regard, it is important to note that
the tempered particle filter is designed to work with a small number of particles (i.e., on a
desktop computer). Therefore, we restrict the computing environment to a single machine,
and we do not try to leverage large-scale parallelism via a computing cluster, as in Gust,
Herbst, Lopez-Salido, and Smith (forthcoming).
As described in Section 2.3, implementing the bootstrap particle filter requires choosing
the number of particles M , while the tempered particle filter requires additionally choosing
the tuning parameters râˆ— , câˆ— , and NM H . We discuss these choices and their effect on the
accuracy of the filters below. Results for the small-scale New Keynesian DSGE model are
presented in Section 4.1. In Section 4.2, the tempered particle filter is applied to the SmetsWouters model.

4.1

A Small-Scale DSGE Model

We first use the BSPF and the TPF to evaluate the likelihood function associated with
the small-scale New Keynesian DSGE model used in Herbst and Schorfheide (2015). The
details about the model can be found in the Online Appendix. From the perspective of the
particle filter, the key feature of the model is that it has three observables (output growth,
inflation, and the federal funds rate). To facilitate the use of particle filters, we augment
the measurement equation of the DSGE model by independent measurement errors, whose
standard deviations we set to be 20% of the standard deviation of the observables.13
Great Moderation Sample. The data span is 1983Q1 to 2002Q4, for a total of 80 observations for each series. We assess the performance of the particle filters for two parameter
vectors, which are denoted by Î¸m and Î¸l and tabulated in Table 1. The value Î¸m is chosen as
a high likelihood point, close to the posterior mode of the model. The log likelihood at Î¸m
is ln p(Y |Î¸m ) = âˆ’306.49. The second parameter value, Î¸l , is chosen to be associated with a

lower log-likelihood value. Based on our choice, ln p(Y |Î¸l ) = âˆ’313.36. The sample and the

parameter values are identical to those used in Chapter 8 of Herbst and Schorfheide (2015).
12

The run-times reported below do not account for the fact that the user of the TPF might experiment
with the choice of tuning constants. Moreover, the computing times for both filters will increase if the linear
solution is replaced by a nonlinear solution. The larger the time it takes to solve the model, the smaller the
percentage reduction in combined run-time for solution and filter attainable by the TPF.
13
The measurement error standard deviations are 0.1160 for output growth, 0.2942 for inflation, and 0.4476
for the interest rates.

28

Table 1: Small-Scale Model: Parameter Values
Parameter
Ï„
Ïˆ1
Ïr
Ïz
Ï€ (A)
Ïƒr
Ïƒz

Î¸m
2.09
2.25
0.81
0.93
3.16
0.19
0.24

Î¸l
3.26
1.88
0.76
0.89
3.29
0.20
0.29

Parameter
Îº
Ïˆ2
Ïg
r(A)
Î³ (Q)
Ïƒg
ln p(Y |Î¸)

Î¸m
0.98
0.65
0.98
0.34
0.51
0.65
-306.5

Î¸l
0.89
0.53
0.98
0.19
0.73
0.58
-313.4

We compare the BSPF with two variants of the TPF, which differ with respect to the
targeted inefficiency ratio: râˆ— = 2 and râˆ— = 3. For the BSPF, we use M = 40, 000 particles,
and for the TPF, we consider M = 4, 000 and M = 40, 000 particles, respectively. In
Algorithm 3, we use NM H = 1 Metropolis-Hastings steps and set the initial scale of the
proposal covariance matrix to câˆ— = 0.3. We also report results for two related algorithms.
The first algorithm is the resample-move variant of the bootstrap particle filter (RMPF)
described in Section 2.3 which sets râˆ— = âˆ. Recall that this algorithm does not utilize
any bridge distributions, but unlike the BSPF it involves a mutation step that changes the

particle values. The second algorithm is the conditionally-optimal particle filter (COPF).
Recall that the implementation of the COPF is generally infeasible for nonlinear DSGE
models. However, in our particular setting in which we are using a linearized DSGE model,
we can directly sample from p(st |yt , sjtâˆ’1 ) using a Kalman filter updating step and compare

the accuracy of the proposed TPF to this infeasible benchmark.

Ë† 1 associated with
Figure 1 displays density estimates for the sampling distribution of âˆ†
the BSPF and the four variants of the TPF for Î¸ = Î¸m (left panel) and Î¸ = Î¸l (right panel).
For Î¸ = Î¸m , the T P F (râˆ— = 2) with M = 40, 000 (the green line) is the most accurate of
Ë† 1 distributed tightly around zero. The distribution of âˆ†
Ë†1
all the filters considered, with âˆ†
associated with T P F (râˆ— = 3) with M = 40, 000 is slightly more disperse, with a larger left
tail, as the higher tolerance for particle inefficiency translates into a higher variance for the
likelihood estimate. Reducing the number of particles to M = 4, 000 for both of these filters
results in a higher variance estimate of the likelihood. The most poorly performing TPF
Ë† 1 that is similar to the
(with râˆ— = 3 and M = 4, 000) is associated with a distribution for âˆ†
one associated with the BSPF that uses M = 40, 000. Overall, the TPF compares favorably
with the BSPF when Î¸ = Î¸m .

29

Figure 1: Small-Scale Model: Distribution of Log-Likelihood Approximation Errors
Î¸ = Î¸m

Î¸ = Î¸l
0.6

0.8

TPF (r âˆ— = 2)M = 40000

0.7

0.5
TPF (r âˆ— = 2), M = 40000

0.6

0.4
TPF (r âˆ— = 3), M = 40000

TPF (r âˆ— = 3), M = 40000
Density

Density

0.5
0.4
0.3

TPF (r âˆ— = 2), M = 4000

0.2

0.3
TPF (r âˆ— = 2), M = 4000

0.2

TPF (r âˆ— = 3), M = 4000

TPF (r âˆ— = 3), M = 4000

0.1

0.1

BSPF , M = 40000

BSPF , M = 40000
0.0

âˆ’10

âˆ’8

âˆ’6

âˆ’4

âˆ’2

0

2

4

0.0

âˆ’15

âˆ’10

âˆ’5

0

Ë† 1 = ln pÌ‚(Y1:T |Î¸m ) âˆ’ ln p(Y1:T |Î¸m ) based on Nrun = 100 runs of
Notes: Density estimate of âˆ†
the particle filter.
The performance differences become even more stark when we consider Î¸ = Î¸l ; depicted
in the right panel of Figure 1. While the sampling distributions indicate that the likelihood
estimates are less accurate for all the particles filters, the BSPF deteriorates by the largest
amount. The TPF, by targeting an inefficiency ratio, adaptively adjusts to account for the
relatively worse fit of Î¸l .
The results are also shown in Table 2, which displays summary statistics for the two
types of likelihood approximation errors as well as information about the average number
Ë† 1 convey essentially the same story
of stages and run time of each filter. The results for âˆ†
Ë† 2 highlights the performance deterioration of the
as Figure 1. The bias associated with âˆ†
BSPF when considering Î¸ = Î¸l . The bias of 2.57 is substantially larger than for any of the
TPFs. Using a resample-move step without the bridge distribution (RMPF) leads to only
a slightly more accurate likelihood estimate than the BSPF, despite having a sustantially
longer run time (we are using NM H = 10 for this algorithm). Finally, the generally infeasible
COPF with M = 400 particles is an order of magnitude more accurate than all the other
filters. Thus, while the use of the tempering iterations leads to a significant improvement in
accuracy, it remains substantially worse than the COPF.
The results in Table 2 are comparable to those reported in Table 8.2 of Herbst and
Schorfheide (2015). For the COPF the numbers are very similar, while for the BSPF the
differences are a bit larger. The discrepancies are due to the fact that we are computing

30

Table 2: Small-Scale Model: PF Summary Statistics

Number of Particles M
Target Ineff. Ratio râˆ—
Ë†1
Bias âˆ†
Ë†1
StdD âˆ†
Ë†2
Bias âˆ†
P
T âˆ’1 Tt=1 NÏ†,t
Average Run Time (s)
Ë†1
Bias âˆ†
Ë†1
StdD âˆ†
Ë†2
Bias âˆ†
P
T âˆ’1 Tt=1 NÏ†,t
Average Run Time (s)

BSPF
40,000

TPF
4,000 4,000 40,000 40,000
2
3
2
3
m
High Posterior Density: Î¸ = Î¸
-1.48
-1.19 -1.48 -0.15 -0.18
1.91
1.39 1.70 0.46 0.58
-0.14
-0.28 -0.28 -0.05 -0.01
1.00
4.31 3.24 4.31 3.24
0.62
0.29 0.23 3.28 2.19
Low Posterior Density: Î¸ = Î¸l
-6.56
-2.67 -4.14 -0.53 -0.72
5.27
2.02 2.57 0.95 1.16
2.57
-0.63 -0.48 -0.07 -0.13
1.00
4.37 3.29 4.35 3.28
0.60
0.30 0.24 2.82 2.33

RMPF COPF
40,000
400
âˆ
-1.42
1.79
-0.16
1.00
2.09

-0.12
0.35
-0.05
1.00
0.02

-5.59
4.07
0.10
1.00
2.08

-0.16
0.40
-0.08
1.00
0.02

Notes: The results are based on Nrun = 100 independent runs of the particle filters. The
Ë† 1 and âˆ†
Ë† 2 are defined in (51) and (52).
likelihood discrepancies âˆ†
the means and standard deviations of the approximation errors based on â€œonlyâ€ Nrun = 100
independent runs of the algorithms. In Table 8.2 of Herbst and Schorfheide (2015) we also
showed results for an auxiliary PF (see Pitt and Shephard (1999) and Doucet and Johansen
(2011)), but we found that the auxiliary PF did not improve much over the BSPF.
P
The row labeled T âˆ’1 Tt=1 NÏ†,t shows the average number of tempering iterations associated with each particle filter. The BSPF has, by construction, always an average of one.
When râˆ— = 2, the TPFs use a bit more than 4 stages per time period. With a higher tolerance for inefficiency, when râˆ— = 3, the average number of stages falls to about 3.25. Note
that when considering Î¸l , the TPF always uses a greater number of stages, reflecting the
relatively worse fit of the model under Î¸ = Î¸l compared with Î¸ = Î¸m . Table 2 also displays
the average run time of each filter (in seconds). When using the same number of particles,
the BSPF runs much more quickly than the TPFs, reflecting the fact that the additional
tempering iterations require many more likelihood evaluations, in addition to the computational costs associated with the mutation phase. For a given level of accuracy, however, the
TPF requires many fewer particles. For instance, using M = 4, 000, the TPF yields more
precise likelihood estimates than the BSPF using M = 40, 000 and takes less than half the

31

Figure 2: Small-Scale Model: Accuracy of Filtered State
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0

BSPF, M=40k
TPF(r*=2), M=40k
TPF(r*=3), M=40k

1984

1989

1994

TPF(r*=2), M=4k
TPF(r*=3), M=4k

1999

Notes: The figure depicts RMSEs associated with EÌ‚[gÌ‚t |Y1:t ]. Results are based on Nrun = 100
independent runs of the particle filters.
time to run.
Finally, we consider the accuracy of the filtered state estimates. We consider the latent
government spending shock as a prototypical hidden state. Using the Kalman filter, we
can compute E[gÌ‚t |Y1:T ], which we compare to the particle filter approximation, denoted by
EÌ‚[gÌ‚t |Y1:T ]. Figure 2 plots root-mean-squared errors (RMSEs) for EÌ‚[gÌ‚t |Y1:T ]. The ranking of
the filters is consistent with the ranking based on the accuracy of the likelihood approxima-

tions. The BSPF performs the worst. Using the TPF with M = 40, 000 particles reduces
the RMSE roughly by a factor of three.
Great Recession Sample. It is well known that the BSPF is very sensitive to outliers.
To examine the extent to which this is also true for the tempered particle filter, we re-run
the previous experiments on the sample 2003Q1 to 2013Q4. This period includes the Great
Recession, which was a large outlier from the perspective of the small-scale DSGE model
(and most other econometric models).
Figure 3 plots the density of the approximation errors of the log likelihood estimates
associated with each of the filters. The difference in the distribution of approximation errors
between the BSPF and the TPFs is massive. For Î¸ = Î¸m and Î¸ = Î¸l , the approximation
errors associated with the BSPF are concentrated in the range of âˆ’200 to âˆ’300, almost two
orders of magnitude larger than the errors associated with the TPFs. This happens because
the large drop in output in 2008Q4 is not predicted by the forward simulation in the BSPF.

32

Figure 3: Small-Scale Model: Distribution of Log-Likelihood Approximation Errors, Great
Recession Sample
Î¸ = Î¸m

Î¸ = Î¸l

0.30

0.25
TPF (r âˆ— = 2), M = 40000

0.25

TPF (r âˆ— = 2), M = 40000

0.20

0.15

TPF (r âˆ— = 3), M = 40000

TPF (r âˆ— = 3), M = 40000

Density

Density

0.20

0.15

0.10
TPF (r âˆ— = 2), M = 4000

0.10

TPF (r âˆ— = 2), M = 4000
0.05

TPF (r âˆ— = 3), M = 4000

0.05

TPF (r âˆ— = 3), M = 4000

BSPF , M = 40000
0.00

âˆ’350

âˆ’300

âˆ’250

âˆ’200

BSPF , M = 40000

âˆ’150

âˆ’100

âˆ’50

0

0.00

âˆ’350

âˆ’300

âˆ’250

âˆ’200

âˆ’150

âˆ’100

âˆ’50

0

Ë† 1 = ln pÌ‚(Y1:T |Î¸m ) âˆ’ ln p(Y1:T |Î¸m ) based on Nrun = 100 runs of
Notes: Density estimate of âˆ†
the particle filters.
In turn, the filter collapses, in the sense that the likelihood increment in that quarter is
estimated using essentially only one particle.
Table 3 tabulates the results for each of the filters. Consistent with Figure 3 the bias
associated with the log-likelihood estimate is âˆ’215 and âˆ’279 for Î¸ = Î¸m and Î¸ = Î¸l ,

respectively, compared with about âˆ’8 and âˆ’10 for the worst performing TPF. For Î¸ = Î¸m ,
the T P F (râˆ— = 2) with M = 40, 000 has a bias only of âˆ’2.8 with a standard deviation of

1.5, which is about 25 times smaller than the BSPF. It is true that this variant of the filter
takes about 6 times longer to run than the BSPF, but even when considering M = 4, 000
particles, the TPF estimates are still overwhelmingly more accurate â€“ and are computed
more quickly â€“ than the BSPF estimates. A key driver of this result is the adaptive nature
of the tempered particle filter. While the average number of stages used is about 5 for râˆ— = 2
and 4 for râˆ— = 3, for t = 2008Q4 â€“ the period with the largest outlier â€“ the tempered particle
filter uses about 15 stages, on average.
Figure 4 provides an illustration of why the TPF provides much more accurate approximations than the BSPF. We focus on one particular state, namely model-implied output growth,
which is observed output growth minus its measurement error. We focus on t = 2008Q4. The
left panel depicts the BSPF approximations pÌ‚(st |Y1:tâˆ’1 ) and pÌ‚(st |Y1:t ) as well as the â€œtrueâ€
density p(st |Y1:t ). The BSPF essentially generates draws from the forecast density pÌ‚(st |Y1:tâˆ’1 )

and reweights them to approximate the density p(st |Y1:t ). In 2008Q4, these densities have

33

Table 3: Small-Scale Model: PF Summary Statistics â€“ The Great Recession

BSPF
40,000

TPF
Number of Particles M
4,000 4,000 40,000 40,000
Target Ineff. Ratio râˆ—
2
3
2
3
m
High Posterior Density: Î¸ = Î¸
Ë†
Bias âˆ†1
-215.63
-5.93 -7.91 -2.84 -4.27
Ë†
StdD âˆ†1
36.74
3.01 3.36 1.55 1.80
Ë†
Bias âˆ†2
-1.00
-0.85 -0.95 -0.71 -0.91
PT
âˆ’1
1.00
5.12 3.87 5.08 3.86
T
t=1 NÏ†,t
Average Run Time (s)
0.38
0.28 0.18 2.28 2.09
Low Posterior Density: Î¸ = Î¸l
Ë†1
Bias âˆ†
-279.12
-7.26 -9.98 -3.81 -5.82
Ë†
StdD âˆ†1
41.74
3.44 4.22 1.68 2.15
Ë†
Bias âˆ†2
-1.00
-0.89 -0.99 -0.86 -0.98
PT
âˆ’1
1.00
5.36 4.04 5.33 4.03
T
t=1 NÏ†,t
Average Run Time (s)
0.37
0.29 0.23 2.40 2.10
Notes: The results are based on Nrun = 100 independent runs of the particle filters. The
Ë† 1 and âˆ†
Ë† 2 are defined in (51) and (52).
likelihood discrepancies âˆ†
Figure 4: Small-Scale Model: BSPF versus TPF in 2008Q4
BSPF
3.5

TPF
3.5

Forecast Density
BSPF Filtered Density
True Filtered Density

3.0
2.5

3.0
2.5
2.0

2.0

1.5

1.5

1.0
0.5

1.0

0.0
1.0

0.5
0.0

4

3

2

1

0

1

2

0.8

0.6

Ï†n

0.4

0.2

0.0 âˆ’4

âˆ’3

âˆ’2

âˆ’1

0

1

2

Notes: Here t = 2008Q4 and st equals model-implied output growth. Left panel: forecast
density pÌ‚(st |Y1:tâˆ’1 ), BSPF filtered density pÌ‚(st |Y1:t ), and true filtered density p(st |Ytâˆ’1 ).
Right panel: forecast density pÌ‚(st |Y1:tâˆ’1 ) (blue), waterfall plot of density estimates pÌ‚n (st |Y1:t )
for n = 1, . . . , NÏ† , and true filtered density p(st |Y1:t ) (red).
very little overlap. This implies that essentially one draw from the forecast density receives
all the weight and the BSPF filtered density is a point mass. This point mass provides a

34
poor approximation of p(st |Y1:t ).
The right panel of Figure 4 displays a waterfall plot of density estimates pÌ‚n (st |Y1:t ) for

n = 1, . . . , NÏ† = 15. The densities are placed on the y-axis at the corresponding value of
Ï†n . The first iteration in the tempering phase has Ï†1 = 0.002951, which corresponds to an
inflation of the measurement error variance by a factor over 300. This density looks similar
to the predictive distribution p(st |Y1:tâˆ’1 ), with a 1-step-ahead prediction for output growth
of about âˆ’1% (in quarterly terms). As we move through the iterations, Ï†n increases slowly

at first and pÌ‚n (st |Y1:t ) gradually adds more density where st â‰ˆ âˆ’2.5. Each correction step of

Algorithm 2 requires only modest reweighting of the particles and the mutation steps refresh

the particle values. The filter begins to tolerate relatively large changes from Ï†n to Ï†n+1 ,
as more particles lie in this region, needing only three stages to move from Ï†n â‰ˆ 0.29 to

Ï†N = 1. Alongside pÌ‚NÏ† (st |Y1:t ) we also show the true filtered density in red, obtained from
the Kalman filter recursions. The TPF approximation at n = NÏ† matches the true density
extremely well.

4.2

The Smets-Wouters Model

We next assess the performance of the tempered particle filter for the Smets and Wouters
(2007), henceforth SW, model. This model forms the core of the latest vintage of DSGE
models. While we leave the details of the model to the Online Appendix, it is important
to note that the SW model is estimated over the period 1966Q1 to 2004Q4 using seven
observables: the real per capita growth rates of output, consumption, investment, wages;
hours worked; inflation; and the federal funds rate. Moreover, the SW model has a highdimensional state space st with more than a dozen state variables. The performance of the
BSPF deteriorates quickly due to the increased state space and the fact that it is much more
difficult to predict seven observables than it is to predict three observables with a DSGE
model. As a consequence, the estimation of nonlinear variants of the SW model has proven
to be extremely difficult.
We compute the particle filter approximations conditional on two sets of parameter values, Î¸m and Î¸l , which are summarized in Table 4. Î¸m is the parameter vector associated with
the highest likelihood value among the draws that we generated with a posterior sampler.
Î¸l is a parameter vector that attains a lower likelihood value. The log-likelihood difference
between the two parameter vectors is approximately 13. The standard deviations of the
measurement errors are chosen to be approximately 20% of the sample standard deviation

35

Table 4: SW Model: Parameter Values
Î¸m
Î²Ìƒ 0.159
Â¯l âˆ’1.078
Ïƒ 1.016
Ï• 6.625
Î¾w 0.752
Î¾p 0.861
Î¹p 0.463
rÏ€ 1.769
ry 0.090
Ïa 0.982
Ïg 0.962
Ïr 0.414
Ïw 0.971
Âµp 0.673
Ïƒa 0.375
Ïƒg 0.428
Ïƒr 0.144
Ïƒw 0.311

Î¸l
0.182
0.019
1.166
4.065
0.647
0.807
0.494
1.827
0.069
0.962
0.947
0.497
0.968
0.741
0.418
0.444
0.131
0.382

Î¸m
Ï€Ì„
0.774
Î±
0.181
Î¦
1.342
h
0.597
Ïƒl
2.736
Î¹w
0.259
Ïˆ
0.837
Ï
0.855
râˆ†y
0.168
Ïb
0.868
Ïi
0.702
Ïp
0.782
Ïga
0.450
Âµw
0.892
Ïƒb
0.073
Ïƒi
0.350
Ïƒp
0.101
ln p(Y |Î¸) âˆ’943.0

Î¸l
0.571
0.230
1.455
0.511
1.217
0.452
0.828
0.836
0.156
0.849
0.723
0.831
0.565
0.871
0.075
0.358
0.117
âˆ’956.1

Notes: Î²Ìƒ = 100(Î² âˆ’1 âˆ’ 1).
of the time series.14 For comparison purposes, the parameter values and the data are identical to the ones used in Chapter 8 of Herbst and Schorfheide (2015). We run each filter
Nrun = 100 times.
Figure 5 displays density estimates of the approximation errors associated with the loglikelihood estimates under Î¸ = Î¸m and Î¸ = Î¸l . We use M = 40, 000 particles for the BSPF.
For the TPF, we use M = 4, 000 or M = 40, 000 and consider râˆ— = 2 and râˆ— = 3. Moreover,
in the mutation step (Algorithm 3), we set NM H = 1 and câˆ— = 0.3. Under both parameter
values, the BSPF exhibits the most bias, with its likelihood estimates substantially below
the true likelihood value. The distribution of the bias falls mainly between âˆ’400 and âˆ’100.

This means that eliciting the posterior distribution of the SW model using, for example, a
particle Markov chain Monte Carlo algorithm with likelihood estimates from the bootstrap

particle filter, would be nearly impossible. The TPFs perform better, although they also
underestimate the likelihood by a large amount.
14

The standard deviations for the measurement errors are 0.1731 (output growth), 0.1394 (consumption
growth), 0.4515 (investment growth), 0.1128 (wage growth), 0.5838 (log hours), 0.1230 (inflation), and 0.1653

36

Figure 5: Smets-Wouters Model: Distribution of Log-Likelihood Approximation Errors
Î¸ = Î¸m

Î¸ = Î¸l
0.016

0.018
âˆ—

TPF (r = 2), M = 40000

0.016

0.014
TPF (r âˆ— = 2), M = 40000

TPF (r âˆ— = 3), M = 40000

0.014

0.012
TPF (r âˆ— = 3), M = 40000
0.010

TPF (r âˆ— = 2), M = 4000

0.010
0.008

Density

Density

0.012

TPF (r âˆ— = 3), M = 4000

0.004

0.004

BSPF , M = 40000

âˆ’600

âˆ’500

âˆ’400

âˆ’300

BSPF , M = 40000

0.002

0.002

âˆ’700

TPF (r âˆ— = 3), M = 4000

0.006

0.006

0.000

TPF (r âˆ— = 2), M = 4000
0.008

âˆ’200

âˆ’100

0

100

0.000

âˆ’600

âˆ’500

âˆ’400

âˆ’300

âˆ’200

âˆ’100

0

100

200

Ë† 1 = ln pÌ‚(Y1:T |Î¸m ) âˆ’ ln p(Y1:T |Î¸m ) based on Nrun = 100 runs of
Notes: Density estimate of âˆ†
the particle filters.
Table 5: SW Model: PF Summary Statistics

BSPF
40,000

TPF
4,000 40,000 40,000
3
2
3

Number of Particles M
4,000
Target Ineff. Ratio râˆ—
2
High Posterior Density: Î¸ = Î¸m
Ë†1
Bias âˆ†
-235.50
-126.09 -144.57
Ë†
StdD âˆ†1
60.30
46.55 44.32
Ë†
Bias âˆ†2
-1.00
-1.00 -1.00
PT
âˆ’1
1.00
6.19
4.75
T
t=1 NÏ†,t
Average Run Time (s)
4.28
2.75
2.11
l
Low Posterior Density: Î¸ = Î¸
Ë†
Bias âˆ†1
-263.31
-138.69 -168.76
Ë†
StdD âˆ†1
78.14
48.18 50.15
Ë†
Bias âˆ†2
-1.00
-1.00 -1.00
PT
âˆ’1
T
1.00
6.25
4.81
t=1 NÏ†,t
Average Run Time (s)
4.17
2.34
2.16

-55.71 -65.94
20.73 23.81
-1.00 -1.00
6.14 4.71
28.83 22.40
-66.92 -83.08
24.26 29.14
-1.00 -1.00
6.21 4.78
26.01 20.14

Ë† 1 and âˆ†
Ë† 2 are defined in (51) and (52). Results are
Notes: The likelihood discrepancies âˆ†
based on Nrun = 100 runs of the particle filters.
Table 5 underscores the results in Figure 5. The best-performing TPF, while three to four
(interest rates).

37

Table 6: SW Model: PF Summary Statistics (NM H = 10)

BSPF
40,000

TPF
Number of Particles M
4,000 4,000 40,000 40,000
âˆ—
Target Ineff. Ratio r
2
3
2
3
High Posterior Density: Î¸ = Î¸m
Ë†1
Bias âˆ†
-235.50
-21.06 -25.20 -6.45 -9.00
Ë†1
StdD âˆ†
60.30
10.55 11.92 4.01 5.55
Ë†
Bias âˆ†2
-1.00
-1.00 -1.00 1.32 -0.61
PT
âˆ’1
T
1.00
6.11 4.69 6.07 4.69
t=1 NÏ†,t
Average Run Time (s)
3.92
8.45 6.07 81.70 62.33
Low Posterior Density: Î¸ = Î¸l
Ë†1
Bias âˆ†
-263.31
-26.41 -34.48 -9.66 -13.72
Ë†1
StdD âˆ†
78.14
10.85 12.66 5.51 6.31
Ë†
Bias âˆ†
-1.00
-1.00 -1.00 0.17 -0.66
PT2
âˆ’1
1.00
6.16 4.74 6.14 4.71
T
t=1 NÏ†,t
Average Run Time (s)
3.69
7.76 6.56 80.52 62.97
Ë† 1 and âˆ†
Ë† 2 are defined in (51) and (52). Results are
Notes: The likelihood discrepancies âˆ†
based on Nrun = 100 runs of the particle filters.
times more accurate than the BSPF, still generates a bias in the log-likelihood approximation
of about âˆ’55 and a standard deviation of about 21 for Î¸ = Î¸m . Moreover, this increased

performance comes at a cost: the T P F (râˆ— = 2), M = 40, 000 filter takes about 29 seconds,

while the BSPF takes only 4 seconds. Even the variants of the TPF, which run more quickly
than the BSPF, still have wildly imprecise estimates of the likelihood; but these estimates
are in general better than those of the BSPF.
It is well known that in SMC algorithms for static parameters the mutation phase is
crucial. For example, Bognanni and Herbst (2015) show that tailoring the mutation step to
model can substantially improve performance. The modification of the mutation step is not
immediately obvious. One clear way to allow the particles to better adapt to the current
density is to increase the number of Metropolis-Hastings steps. While all of the previous
results are based on NM H = 1, we now consider NM H = 10. Table 6 displays the results
associated with this choice for variants of the TPF, along with the BSPF, which is unchanged
from the previous exercise.
The bias shrinks dramatically. For the T P F (râˆ— = 2), M = 40, 000, when Î¸ = Î¸m , the bias
falls from about âˆ’55 to about âˆ’6, with the standard deviation of the estimator decreasing

38
by a factor of 6. Of course, this increase in performance comes at a computational cost.
Each filter takes about three times longer than its NM H = 1 counterpart. Note that this
is less than you might expect, given the fact that the number of Metropolis-Hastings steps
at each iteration has increased by 10. This reflects two things. First, the mutation phase
is easily parallelizable on a multi-core desktop computer. Second, a substantial fraction of
computational time is spent during the resampling (selection) phase, which is not affected
by increasing the number of Metropolis-Hastings steps.

5

Conclusion

We developed a particle filter that automatically adapts the proposal distribution for the
particles sjt to the current observation yt . We start with a forward simulation of the statetransition equation under an inflated measurement error variance and then gradually reduce
the variance to its nominal level. In each step, the particle values and weights change so
that the distribution slowly adapts to p(sjt |yt , sjtâˆ’1 ). We demonstrate that the algorithm

improves upon the standard bootstrap particle filter, in particular in instances in which the
model generates very inaccurate one-step-ahead predictions of yt . The tempering iterations
can also be used to improve a particle filter with a more general initial proposal distribution
than the BSPF. Morever, our filter can be easily embedded in particle MCMC algorithms.

References
Andreasen, M. M. (2013): â€œNon-Linear DSGE Models and the Central Difference Kalman
Filter,â€ Journal of Applied Econometrics, 28(6), 929â€“955.
Andrieu, C., A. Doucet, and R. Holenstein (2010): â€œParticle Markov Chain Monte
Carlo Methods,â€ Journal of the Royal Statistical Society Series B, 72(3), 269â€“342.
Arulampalam, S., S. Maskell, N. Gordon, and T. Clapp (2002): â€œA Tutorial on
Particle Filters for Online Nonlinear/Non-Gaussian Bayesian Tracking,â€ IEEE Transactions on Signal Processing, 50(2), 174â€“188.
Beskos, A., A. Jasra, N. Kantas, and A. H. Thiery (2014): â€œOn the Convergence of
Adaptive Sequential Monte Carlo Methods,â€ arXiv Working Paper.

39
Bognanni, M., and E. P. Herbst (2015): â€œEstimating (Markov-Switching) VAR Models
without Gibbs Sampling: A Sequential Monte Carlo Approach,â€ Finance and Economics
Discussion Paper Series, Board of Governors, 2015-116(116), 154.
CappeÌ, O., S. J. Godsill, and E. Moulines (2007): â€œAn Overview of Existing Methods
and Recent Advances in Sequential Monte Carlo,â€ Proceedings of the IEEE, 95(5), 899â€“
924.
CappeÌ, O., E. Moulines, and T. Ryden (2005): Inference in Hidden Markov Models.
Springer Verlag, New York.
Chopin, N. (2002): â€œA Sequential Particle Filter for Static Models,â€ Biometrika, 89(3),
539â€“551.
(2004): â€œCentral Limit Theorem for Sequential Monte Carlo Methods and Its
Application to Bayesian Inference,â€ Annals of Statistics, 32(6), 2385â€“2411.
Creal, D. (2007): â€œSequential Monte Carlo Samplers for Bayesian DSGE Models,â€
Manuscript, University Chicago Booth.
(2012): â€œA Survey of Sequential Monte Carlo Methods for Economics and Finance,â€
Econometric Reviews, 31(3), 245â€“296.
Del Moral, P. (2004): Feynman-Kac Formulae. Springer Verlag.
(2013): Mean Field Simulation for Monte Carlo Integration. Chapman & Hall/CRC,
Boca Raton.
Del Moral, P., A. Doucet, and A. Jasra (2006): â€œSequential Monte Carlo Samplers,â€
Journal of the Royal Statistical Society, Series B, 68(Part 3), 411â€“436.
(2012): â€œAn AdaptiveSequential Monte Carlo Method for Approximate Bayesian
Computation,â€ Statistical Computing, 22, 1009â€“1020.
Doucet, A., and A. M. Johansen (2011): â€œA Tutorial on Particle Filtering and Smoothing: Fifteen Years Later,â€ in Handook of Nonlinear Filtering, ed. by D. Crisan, and B. Rozovsky. Oxford University Press, Oxford.

40
Durham, G., and J. Geweke (2014): â€œAdaptive Sequential Posterior Simulators for
Massively Parallel Computing Environments,â€ in Advances in Econometrics, ed. by I. Jeliazkov, and D. Poirier, vol. 34, chap. 6, pp. 1â€“44. Emerald Group Publishing Limited, West
Yorkshire.
FernaÌndez-Villaverde, J., and J. F. Rubio-RamÄ±Ìrez (2007): â€œEstimating Macroeconomic Models: A Likelihood Approach,â€ Review of Economic Studies, 74(4), 1059â€“1087.
Geweke, J., and B. Frischknecht (2014): â€œExact Optimization By Means of Sequentially Adaptive Bayesian Learning,â€ Mimeo.
Godsill, S. J., and T. Clapp (2001): â€œImprovement Strategies for Monte Carlo Particle
Filters,â€ in Sequential Monte Carlo Methods in Practice, ed. by A. Doucet, N. De Freitas,
and N. Gordon, pp. 139â€“158. Springer Verlag, New York.

Gordon, N., D. Salmond, and A. F. Smith (1993): â€œNovel Approach to Nonlinear/NonGaussian Bayesian State Estimation,â€ Radar and Signal Processing, IEE Proceedings F,
140(2), 107â€“113.
Gust, C., E. Herbst, D. Lopez-Salido, and M. E. Smith (forthcoming): â€œThe Empirical Implications of the Interest-Rate Lower Bound,â€ American Economic Review.
Herbst, E., and F. Schorfheide (2014): â€œSequential Monte Carlo Sampling for DSGE
Models,â€ Journal of Applied Econometrics, 29(7), 1073â€“1098.
(2015): Bayesian Estimation of DSGE Models. Princeton University Press, Princeton.
Jasra, A., D. A. Stephens, A. Doucet, and T. Tsagaris (2011): â€œInference for LevyDriven Stochastic Volatility Models via Adaptive Sequential Monte Carlo,â€ Scandinavian
Journal of Statistics, 38, 1â€“22.
Johansen, A. M. (2016): â€œOn Blocks, Tempering and Particle MCMC for Systems Identification,â€ Manuscript, University of Warwick.
Kollmann, R. (2015): â€œTractable Latent State Filtering for Non-Linear DSGE Models
Using a Second-Order Approximation and Pruning,â€ Computational Economics, 45(2),
239â€“260.

41
Liu, J. S. (2001): Monte Carlo Strategies in Scientific Computing. Springer Verlag, New
York.
Neal, R. M. (1998): â€œAnnealed Importance Sampling,â€ Technical Report, Department of
Statistics, University of Toronto, 9805.
Pitt, M. K., and N. Shephard (1999): â€œFiltering via Simulation: Auxiliary Particle
Filters,â€ Journal of the American Statistical Association, 94(446), 590â€“599.
Pitt, M. K., R. d. S. Silva, P. Giordani, and R. Kohn (2012): â€œOn Some Properties
of Markov Chain Monte Carlo Simulation Methods Based on the Particle Filter,â€ Journal
of Econometrics, 171(2), 134â€“151.
SchaÌˆfer, C., and N. Chopin (2013): â€œSequential Monte Carlo on Large Binary Sampling
Spaces,â€ Statistical Computing, 23, 163â€“184.
Smets, F., and R. Wouters (2007): â€œShocks and Frictions in U.S. Business Cycles: A
Bayesian DSGE Approach,â€ American Economic Review, 97(3), 586â€“608.
White, H. (2001): Asymptotic Theory For Econometricians. Academic Press, New York.
Zhou, Y., A. M. Johansen, and J. A. Aston (2015): â€œTowards Automatic Model
Comparison: An Adaptive Sequential Monte Carlo Approach,â€ arXiv Working Paper,
1303.3123v2.

Online Appendix

A-1

Online Appendix for
Tempered Particle Filtering
Edward Herbst and Frank Schorfheide

A

Theoretical Derivations

A.1

Monotonicity of Inefficiency Ratio

Recall the definitions
1
j,nâˆ’1
ej,t = (yt âˆ’ Î¨(sj,nâˆ’1
))0 Î£âˆ’1
))
t
u (yt âˆ’ Î¨(st
2
and
wÌƒtj,n (Ï†n )


=

Ï†n
Ï†nâˆ’1

ny /2
exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ].

Provided that the particles had been resampled and Wtj,nâˆ’1 = 1, the inefficiency ratio can
be manipulated as follows:
2
wÌƒtj,n (Ï†n )
InEff(Ï†n ) =  P
2
M
j,n
1
j=1 wÌƒt (Ï†n )
M
PM  Ï†n d
1
exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
j=1 Ï†nâˆ’1
M
= 
2
PM  Ï†n d/2
1
exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
j=1 Ï†nâˆ’1
M
PM
1
j=1 exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
M
=  P
2
M
1
exp[âˆ’(Ï†
âˆ’
Ï†
)e
]
n
nâˆ’1
j,t
j=1
M
1
M

=

PM

j=1

A1 (Ï†n )
.
A2 (Ï†n )

Note that for Ï†n = Ï†nâˆ’1 , we obtain ESS(Ï†n ) = 1. We now will show that the inefficiency
ratio is monotonically increasing on the interval [Ï†nâˆ’1 , 1]. Differentiating with respect to Ï†n

Online Appendix

A-2

yields
(1)

A(1) (Ï†n )A2 (Ï†n ) âˆ’ A1 (Ï†n )A2 (Ï†n )
InEff (Ï†n ) =
,
[A2 (Ï†n )]2
(1)

where
M
2 X
A (Ï†n ) = âˆ’
ej,t exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
M j=1
!
!
M
M
X
X
2
1
A(2) (Ï†n ) =
exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
âˆ’
ej,t exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ] .
M j=1
M j=1
(1)

The denumerator in InEff(1) (Ï†n ) is always non-negative and strictly different from zero. Thus,
we can focus on the numerator:
(1)

A(1) (Ï†n )A2 (Ï†n ) âˆ’ A1 (Ï†n )A2 (Ï†n )

!
!2
M
M
2 X
1 X
=
âˆ’
ej,t exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
M j=1
M j=1
!
!
M
M
2 X
1 X
exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
âˆ’
M j=1
M j=1
!
M
1 X
Ã— âˆ’
ej,t exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
M j=1
!
M
X
1
= 2
exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
M j=1
!
!

M
M
1 X
1 X
Ã—
ej,t exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
M j=1
M j=1
!
!
M
M
1 X
1 X
ej,t exp[âˆ’2(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ]
âˆ’
M j=1
M j=1

To simplify the notation, we now define
xj,t = exp[âˆ’(Ï†n âˆ’ Ï†nâˆ’1 )ej,t ].

Online Appendix

A-3

Note that 0 < xj,t â‰¤ 1, which implies that x2j,t â‰¤ xj,t . Moreover, ej,t â‰¥ 0. We will use these
properties to establish the following bound:
(1)

A(1) (Ï†n )A2 (Ï†n ) âˆ’ A1 (Ï†n )A2 (Ï†n )
!"
!
!
M
M
M
1 X
1 X
1 X 2
= 2
xj,t
ej,t xj,t
x
âˆ’
M j=1
M j=1
M j=1 j,t
!"
!
!
M
M
M
1 X
1 X
1 X 2
â‰¥ 2
xj,t
ej,t xj,t
x
âˆ’
M j=1
M j=1
M j=1 j,t
!
!"
!
M
M
M
1 X 2
1 X
1 X
xj,t
x
ej,t xj,t âˆ’
= 2
M j=1
M j=1 j,t
M j=1

M
1 X
ej,t x2j,t
M j=1

!

M
1 X
xj,t
M j=1

!#

M
1 X
ej,t x2j,t
M j=1

!

M
1 X 2
x
M j=1 j,t

!#

M
1 X
ej,t x2j,t
M j=1

!#

â‰¥ 0.
We conclude that the inefficiency ratio InEff(Ï†n ) is increasing in Ï†n . 

A.2

Proofs for Section 3.1

The proofs in this section closely follow Chopin (2004) and Herbst and Schorfheide (2014).
Throughout this section, we will assume that h(Î¸) is scalar and we use absolute values |h|
instead of a general norm khk. Extensions to vector-valued-h functions are straightforward.
We use C to denote a generic constant. We will make repeated use of the following moment
bound for r > 1


r
r
r
E X âˆ’ E[X]
â‰¤ Cr E X + E[X]

r
â‰¤ 2Cr E X ,

(A.1)

where Cr = 1 for r = 1 and Cr = 2râˆ’1 for r > 1. The first inequality follows from the Cr
inequality and the second inequality follows from Jensenâ€™s inequality.
We will make use of the following SLLN (Markov, see White (2001) p. 33): Let {Zj } be
a sequence of independent random variables with finite means Âµj = E[Zj ]. If for some Î´ > 0,
 1+Î´


PM
Pâˆ 
a.s
1+Î´
1+Î´
/j
< âˆ, then M1
<
j=1 E |Zj âˆ’ Âµj |
j=1 Zj âˆ’ Âµj âˆ’â†’ 0. Note that E |Zj âˆ’ Âµj |
Pâˆ
C < âˆ implies that the summability condition is satisfied because j=1 (1/j)1+Î´ < âˆ.

Online Appendix

A-4

Recall that under a multivariate Gaussian measurement error distribution, the density
pn (yt |st ) can be bounded from above. Thus, pn (yt |st ) âˆˆ HtÌƒnÌƒ and Ï‰Ìƒtj,n âˆˆ HtÌƒnÌƒ for any tÌƒ and nÌƒ.
Moreover, for any h(st , stâˆ’1 ) âˆˆ Htn , we can deduce that hÌƒ(Â·) = h(Â·)Ï‰Ìƒtj,n âˆˆ Htn .

Proof of Lemma 1. (i) (34) can be established as follows. Consider the summands I and
II in (38). Recall that

I=

M

1 X  j j,NÏ†
j,N
h(sÌƒt , stâˆ’1 ) âˆ’ Ep(Â·|sj ) [h] Wtâˆ’1Ï† .
tâˆ’1
M j=1

j,N

j,N

Conditional on the particles {stâˆ’1Ï† , Wtâˆ’1Ï† } the summands in term I form a triangular array
of mean-zero random variables that within each row are independently distributed. In Algorithm 4 the particles were resampled during the t âˆ’ 1 tempering iteration NÏ† , such that
N

Wtâˆ’1Ï† = 1. Using the bound

Ep(Â·|stâˆ’1 ) h(st , stâˆ’1 ) âˆ’ Ep(Â·|stâˆ’1 ) [h(st , stâˆ’1 )]

1+Î´


<C<âˆ
a.s.

implied by the definition of Ht1 , we can apply the SLLN to deduce that term I âˆ’â†’ 0. The
second term in (38) takes the form

Z Z
M 
1 X
II =
Ep(Â·|sj ) [h] âˆ’
h(st , stâˆ’1 )p(st , stâˆ’1 |Y1:tâˆ’1 )dst dstâˆ’1 .
tâˆ’1
M j=1
N

Ï†
By assumption, Ep(Â·|stâˆ’1 ) [h] âˆˆ Htâˆ’1
. The almost-sure convergence to zero of term II can now

be deduced from the recursive Assumption (33). By combining the convergence results for
terms I and II we have established (34).
(ii) The convergences in (35) and (37) follow immediately from the fact that p1 (yt |st ) âˆˆ
Ht1 . Moreover, if h(st , stâˆ’1 ) âˆˆ Ht1 , then h(st , stâˆ’1 )p1 (yt |st ) âˆˆ Ht1 . Finally, p1 (yt |st ) > 0,
which implies that the almost-sure limit of the denominator in (35) is strictly positive.
j,N

j,1
Ï†
(iii) To verify (36), let FÌƒt,1,M denote the Ïƒ-algebra generated by the particles {sÌƒj,1
t , stâˆ’1 , Wt }.

Online Appendix

A-5

Moreover, define
M
1 X
j,NÏ†
j,1
E[h|FÌƒt,1,M ] =
h(sÌƒj,1
t , stâˆ’1 )WÌƒt ,
M j=1

and write
hÌ„1t,M

âˆ’

Z

h(st , stâˆ’1 )p1 (st , stâˆ’1 |Y1:t )dst

(A.2)

M


1 X
j,NÏ†
=
h(sj,1
t , stâˆ’1 ) âˆ’ E[h|FÌƒt,1,M ]
M j=1
 X

Z Z
M
1
j,1
j,1 NÏ†
h(st , stâˆ’1 )p1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1
h(sÌƒt , stâˆ’1 )WÌƒt âˆ’
+
M j=1
M

1 X
j,NÏ†
=
h(sj,1
t , stâˆ’1 ) âˆ’ E[h|FÌƒt,1,M ]
M j=1


Z Z
1
+ hÌƒt,M âˆ’
h(st , stâˆ’1 )p1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1

= I + II.
From (35), we can immediately deduce that term II converges to zero almost surely. Rej,N

Ï†
call that we are resampling the pairs (sÌƒj,n
t , stâˆ’1 ). Thus, under multinomial resampling the

j,NÏ†

h(sj,1
t , st

)â€™s form a triangular array of i.i.d. random variables conditional on FÌƒt,1,M . Using

Kolmogorovâ€™s SLLN for i.i.d. sequences, it suffices to verify for that

j,NÏ†
E h(sj,1
)
t , st


FÌƒt,1,M < âˆ.

We can manipulate the moment as follows

E

j,NÏ†
h(sj,1
t , stâˆ’1 )


FÌƒt,1,M

M
1 X
j,NÏ†
j,1
h(sÌƒj,1
=
t , stâˆ’1 ) WÌƒt
M j=1
Z
a.s
âˆ’â†’
h(st , stâˆ’1 ) p1 (st , stâˆ’1 |Y1:t )dst dstâˆ’1 < âˆ.

Because h âˆˆ Ht1 implies |h| âˆˆ Ht1 , we obtain the almost-sure convergence from (35). 
Proof of Lemma 2. (i) We begin with the correction step. Recall that for any h(st , stâˆ’1 ) âˆˆ

Online Appendix

A-6

Htnâˆ’1 :
pn (yt |st )/pnâˆ’1 (yt |st ) âˆˆ Htnâˆ’1

and h(st , stâˆ’1 )pn (yt |st )/pnâˆ’1 (yt |st ) âˆˆ Htnâˆ’1 .

Thus, the recursive Assumption 2 yields the almost-sure convergence in (40) and (42).
(ii) We proceed with the selection step. The convergence in (41) can be established with
an argument similar to the one used in Step (iii) of the proof of Lemma 1.
(iii) Finally, consider the mutation step. To establish the convergence in (43), we need to
construct moment bounds for the terms I and II that appear in (45). Under the assumption
that the resampling step is executed at every iteration n, term I takes the form:

M 
1 X
j,n j,NÏ†
I=
h(st , stâˆ’1 ) âˆ’ EK (Â·|sÌ‚j,n ;sj,NÏ† ) [h] .
n
M j=1
t
tâˆ’1
Conditional on the Ïƒ-algebra generated by the particles of the selection step, term I is an
average of independently distributed mean-zero random variables. By virtue of h âˆˆ Htn , we
can deduce that, omitting the j and n superscripts,

EKn (Â·|sÌ‚t ;stâˆ’1 ) h(st , stâˆ’1 ) âˆ’ EKn (Â·|sÌ‚t ;stâˆ’1 ) [h]

1+Î´ 

< C < âˆ.

a.s.

Therefore, the SLLN implies that I âˆ’â†’ 0. For term II, we have

Z Z
M 
1 X
II =
EK (Â·|sÌ‚j,n ;sj,NÏ† ) [h] âˆ’
h(st , stâˆ’1 )pn (st , stâˆ’1 |Y1:t )dst dstâˆ’1 .
n
M j=1
t
tâˆ’1
Now define
Ïˆ(sÌ‚t , stâˆ’1 ) = EKn (Â·|sÌ‚t ;stâˆ’1 ) [h].
The definition of Htn implies that Ïˆ(sÌ‚t , stâˆ’1 ) âˆˆ Htnâˆ’1 . Thus, we can deduce from (41) that
a.s.

II âˆ’â†’ 0. 

Online Appendix

A.3

A-7

Proofs for Section 3.2

The subsequent proof of the unbiasedness of the particle filter approximation uses Lemmas 3
j,N

and 5 below. Throughout this section, we use the convention that Wtj,0 = Wtâˆ’1Ï† . Moreover,
we often use the j subscript to denote a fixed particle as well as a running index in a sumP
PM l
j
j
mation. That is, we write aj / M
j=1 a instead of a /
l=1 a . We also define the information
set
Ftâˆ’1,n,M =



j,NÏ†

(s0

j,NÏ†

, W0

j,NÏ†

j,1
), (sj,1
1 , W1 ), . . . , (s1

), . . . ,

(A.3)

M
.
j=1

j,1
j,n
j,n
(sj,1
tâˆ’1 , Wtâˆ’1 ), . . . , (stâˆ’1 , Wtâˆ’1 )

A.3.1

j,NÏ†

, W1

Additional Lemmas

Lemma 3 Suppose that the incremental weights wÌƒtj,n are defined as in (9) and (16) and that
there is no resampling. Then
NÏ†
Y

M
1 X j,n j,nâˆ’1
wÌƒ W
M j=1 T T

n=1

!

ï£¶
ï£«
NÏ†
M
Y
X
1
j,N
ï£­
wÌƒTj,n ï£¸ WT âˆ’1Ï†
=
M j=1 n=1

and
NÏ†
j,N

Ï†
WT âˆ’hâˆ’1

Y
n=1

1
M

M
X

!
wÌƒTj,nâˆ’hâˆ’1 WTj,nâˆ’1
âˆ’hâˆ’1

ï£«

NÏ†

=ï£­

Y

(A.4)

ï£¶
j,N

Ï†
wÌƒTj,nâˆ’hâˆ’1 ï£¸ WT âˆ’hâˆ’2
.

(A.5)

n=1

j=1

Proof of Lemma 3. The lemma can be proved by induction. If there is no resampling,
then Wtj,n = WÌƒtj,n .
Part 1. The inductive hypothesis to show (A.4) takes the form
NÏ†
Y
n=nâˆ—

M
1 X j,n j,nâˆ’1
wÌƒ W
M j=1 T T

!

ï£«
ï£¶
NÏ†
M
X
Y
1
ï£­
=
wÌƒTj,n ï£¸ WTj,nâˆ— âˆ’1 .
M j=1 n=n
âˆ—

(A.6)

Online Appendix

A-8

If the hypothesis is correct, then
NÏ†
Y

!
M
1 X j,n j,nâˆ’1
wÌƒ W
(A.7)
M j=1 T T
n=nâˆ— âˆ’1
ï£«
ï£«
ï£¶
ï£¶
!
NÏ†
M
M
X
X
Y
1
1
ï£­
= ï£­
wÌƒj,n ï£¸ WTj,nâˆ— âˆ’1 ï£¸
wÌƒj,nâˆ— âˆ’1 WTj,nâˆ— âˆ’2
M j=1 n=n T
M j=1 T
âˆ—
ï£¶
ï£«
ï£«
ï£¶
!
NÏ†
M
M
j,nâˆ— âˆ’1
j,nâˆ— âˆ’2
X
X
Y
1
1
wÌƒ
W
j,n
j,n
âˆ’1
j,n
âˆ’2
T
ï£¸
ï£­
= ï£­
wÌƒ ï£¸ 1 PMT j,nâˆ— âˆ’1
wÌƒT âˆ— WT âˆ—
j,nâˆ— âˆ’2
M j=1 n=n T
M
wÌƒ
W
T
j=1 T
j=1
M
âˆ—
ï£«
ï£¶
NÏ†
M
1 Xï£­ Y
wÌƒTj,n ï£¸ WTj,nâˆ— âˆ’2 .
=
M j=1 n=n âˆ’1
âˆ—

The first equality follows from (A.6), and the second equality is obtained by using the
definition of WTj,nâˆ— âˆ’1 .
It is straightforward to verify that the inductive hypothesis (A.6) is satisfied for nâˆ— = NÏ† .
j,N

Setting nâˆ— = 1 in (A.6) and noticing that WTj,0 = WT âˆ’1Ï† leads the desired result.
Part 2. To show (A.5), we can use the inductive hypothesis

j,N

Ï†
WT âˆ’hâˆ’1

NÏ†
Y

M
1 X j,n
wÌƒ
W j,nâˆ’1
M j=1 T âˆ’hâˆ’1 T âˆ’hâˆ’1

n=nâˆ—

!

ï£«
=ï£­

NÏ†
Y

ï£¶
âˆ— âˆ’1
wÌƒTj,nâˆ’hâˆ’1 ï£¸ WTj,n
âˆ’hâˆ’1 .

(A.8)

n=nâˆ—

If the inductive hypothesis is satisfied, then
j,N

Ï†
WT âˆ’hâˆ’1

NÏ†
Y
n=nâˆ— âˆ’1

M
1 X j,n
wÌƒT âˆ’hâˆ’1 WTj,nâˆ’1
âˆ’hâˆ’1
M j=1

NÏ†
Y

!

!
!
M
M
X
X
1
1
j,NÏ†
âˆ— âˆ’1
âˆ— âˆ’2
= WT âˆ’hâˆ’1
WTj,n
wÌƒTj,nâˆ’hâˆ’1 WTj,nâˆ’1
wÌƒTj,nâˆ’hâˆ’1
âˆ’hâˆ’1
âˆ’hâˆ’1
M
M
n=nâˆ—
j=1
j=1
ï£«
ï£¶
!
NÏ†
M
âˆ— âˆ’1
âˆ— âˆ’2
Y
X
wÌƒTj,nâˆ’hâˆ’1
WTj,n
1
j,n
j,n
âˆ’1
j,n
âˆ’2
âˆ’hâˆ’1
âˆ—
âˆ—
= ï£­
wÌƒ
W
wÌƒT âˆ’hâˆ’1 ï£¸ 1 PM j,nâˆ— âˆ’1 j,nâˆ— âˆ’2
M j=1 T âˆ’hâˆ’1 T âˆ’hâˆ’1
j=1 wÌƒT âˆ’hâˆ’1 WT âˆ’hâˆ’1
n=nâˆ—
M
ï£«
ï£¶
NÏ†
Y
âˆ— âˆ’2
= ï£­
wÌƒTj,nâˆ’hâˆ’1 ï£¸ WTj,n
âˆ’hâˆ’1 .
n=nâˆ— âˆ’1

(A.9)

Online Appendix

A-9

For nâˆ— = NÏ† the validity of the inductive hypothesis can be verified as follows:
j,N

Ï†
WT âˆ’hâˆ’1

M
1 X j,NÏ†
j,NÏ† âˆ’1
wÌƒT âˆ’hâˆ’1 WT âˆ’hâˆ’1
M j=1
j,N

=
=

j,N âˆ’1

Ï†
Ï†
wÌƒT âˆ’hâˆ’1
WT âˆ’hâˆ’1
PM j,NÏ†
j,NÏ† âˆ’1
j=1 wÌƒT âˆ’hâˆ’1 WT âˆ’hâˆ’1

1
M
j,NÏ†
j,NÏ† âˆ’1
wÌƒT âˆ’hâˆ’1
WT âˆ’hâˆ’1
.

!
(A.10)
M
1 X j,NÏ†
j,NÏ† âˆ’1
wÌƒT âˆ’hâˆ’1 WT âˆ’hâˆ’1
M j=1

!

Setting nâˆ— = 1 in (A.8) leads to the desired result. 
The following lemma simply states that the expected value of a sum is the sum of the
expected values, but it does so using a notation that we will encounter below.
Lemma 4 Suppose sj , j = 1, . . . , M , is a sequence of random variables with density

QM

j=1

p(sj ),

then
Z

Â·Â·Â·

Z 

 Y

M
M
M Z
1 X
1 X
j
j
1
M
f (s )
p(s ) ds Â· Â· Â· ds =
f (sj )p(sj )dsj .
M j=1
M j=1
j=1

Proof of Lemma 4. The statement is trivially satisfied for M = 1. Suppose that it is true
for M âˆ’ 1, then
Z

 Y

M
M
1 X
j
j
Â·Â·Â·
f (s )
p(s ) ds1 Â· Â· Â· dsM
(A.11)
M j=1
j=1


Z
Z 
M
âˆ’1
M
âˆ’1
X
Y
1
M âˆ’1 1
M
j
M
j
=
Â·Â·Â·
f (s ) +
f (s ) p(s )
p(s ) ds1 Â· Â· Â· dsM
M
M M âˆ’ 1 j=1
j=1
 MY
 Z
âˆ’1 Z
1
=
f (sM )p(sM )dsM
p(sj )dsj
M
j=1

Z
Z
M
âˆ’1
X
M âˆ’1 1
j
j
j
+
f (s )p(s )ds
p(sM )dsM
M M âˆ’ 1 j=1
M Z
1 X
=
f (sj )p(sj )dsj ,
(A.12)
M j=1
Z 

which verifies the claim for all M by induction. 

Online Appendix

A-10

Lemma 5 Suppose that the incremental weights wÌƒtj,n are defined as in (9) and (16) and
that the selection step is implemented by multinomial resampling for a predetermined set of
iterations n âˆˆ N . Then,
ï£®
Eï£°

NÏ†
Y

n=1

M
1 X j,n j,nâˆ’1
wÌƒ W
M j=1 T T

!

ï£¹

M
1 X
j,N
j,N
ï£»
p(yT |sT âˆ’1Ï† )WT âˆ’1Ï†
FT âˆ’1,NÏ† ,M =
M j=1

(A.13)

and
ï£®
NÏ†
M
Y
X
1
j,NÏ†
j,NÏ†
E ï£°p(YT âˆ’h:T |sT âˆ’hâˆ’1 )WT âˆ’hâˆ’1
M j=1
n=1

M
1 X j,n
wÌƒ
W j,nâˆ’1
M j=1 T âˆ’hâˆ’1 T âˆ’hâˆ’1

ï£¹

!

FT âˆ’hâˆ’2,NÏ† ,M ï£» (A.14)

M
1 X
j,NÏ†
j,NÏ†
=
p(YT âˆ’hâˆ’1:T |sT âˆ’hâˆ’2
)WT âˆ’hâˆ’2
.
M j=1

Proof of Lemma 5. We first prove the lemma under the assumption of no resampling, i.e.,
N = âˆ…. We then discuss how the proof can be modified to allow for resampling.
Part 1 (No Resampling). We deduce from Lemma 3 that
Y
NÏ†
E
n=1

M
1 X j,n j,nâˆ’1
wÌƒ W
M j=1 T T

!


FT âˆ’1,NÏ† ,M

ï£¶
ï£«

 Y
NÏ†
M
X
1
j,NÏ†
j,n
wÌƒT ï£¸ WT âˆ’1 FT âˆ’1,NÏ† ,M .
E ï£­
=
M j=1
n=1
(A.15)

The subsequent derivations focus on the evaluation of the expectation on the right-hand
1:M,NÏ† âˆ’1

side of this equation. We will subsequently integrate over the particles sT1:M,1 , . . . , sT

,

to denote the set of particle values
which enter the incremental weights wÌƒTj,n . We use s1:M,n
T
j,N

M,n
Ï†
{s1,n
T , . . . , sT }. Because WT âˆ’1 âˆˆ FT âˆ’1,NÏ† ,M it suffices to show that

ï£«
ï£¶
 Y

NÏ†
j,N
j,n ï£¸
ï£­
E
wÌƒT
FT âˆ’1,NÏ† ,M = p(yT |sT âˆ’1Ï† ).
n=1

(A.16)

Online Appendix

A-11

Recall that the initial state particle sj,1
T is generated from the state-transition equation
j,N

p(sT |sT âˆ’1Ï† ). The first incremental weight is defined as
wÌƒTj,1 = p1 (yT |sj,1
T ).
The incremental weight in tempering iteration n is given by
wÌƒTj,n

pn (yT |sj,nâˆ’1
)
T
=
j,nâˆ’1 .
pnâˆ’1 (yT |sT )

Because we are omitting the selection step, the new particle value is generated in the mutation
step by sampling from the Markov transition kernel
j,N

n j,nâˆ’1
sj,n
, sT âˆ’1Ï† ),
T âˆ¼ Kn (sT |sT

(A.17)

which has the invariance property
pn (sT |yT , sT âˆ’1 ) =

Z

Kn (sT |sÌ‚T ; sT âˆ’1 )pn (sÌ‚T |yT , sT âˆ’1 )dsÌ‚T .

(A.18)

Using the previous notation, we can write
ï£®ï£«
E ï£°ï£­

ï£¶

NÏ†

Y

n=1

ï£¹

wÌƒTj,n ï£¸ FT âˆ’1,NÏ† ,M ï£»

(A.19)

ï£«
Z
=

Â·Â·Â·

Z

ï£¶
NÏ†
j,nâˆ’1
Y
pn (yT |sT )
j,nâˆ’1 j,nâˆ’2 j,NÏ† ï£¸
ï£­
|sT , sT âˆ’1 )
j,nâˆ’1 Knâˆ’1 (sT
p
(y
|s
)
nâˆ’1
T
T
n=3

p2 (yT |sj,1
j,NÏ† âˆ’1
j,1
j,1 j,NÏ†
j,1
T )
Ã—
.
j,1 p1 (yT |sT )p(sT |sT âˆ’1 )dsT Â· Â· Â· dsT
p1 (yT |sT )
The bridge posterior densities were defined as
pn (yt |st )p(st |stâˆ’1 )
pn (st |yt , stâˆ’1 ) =
,
pn (yt |stâˆ’1 )

pn (yt |stâˆ’1 ) =

Z

pn (yt |st )p(st |stâˆ’1 )dst .

(A.20)

Online Appendix

A-12

Using the invariance property of the transition kernel in (A.18) and the definition of the
bridge posterior densities, we deduce that
Z

j,N

j,N

)p(sj,nâˆ’2
|sT âˆ’1Ï† )dsj,nâˆ’2
Knâˆ’1 (sj,nâˆ’1
|sj,nâˆ’2
, sT âˆ’1Ï† )pnâˆ’1 (yT |sj,nâˆ’2
T
T
T
T
T
Z
j,N
j,N
j,N
|yT , sT âˆ’1Ï† )pnâˆ’1 (yT |sT âˆ’1Ï† )dsj,nâˆ’2
=
Knâˆ’1 (sj,nâˆ’1
|sj,nâˆ’2
, sT âˆ’1Ï† )pnâˆ’1 (sj,nâˆ’2
T
T
T
T

(A.21)

j,N

j,N

= pnâˆ’1 (sTj,nâˆ’1 |yT , sT âˆ’1Ï† )pnâˆ’1 (yT |sT âˆ’1Ï† )
j,N

= pnâˆ’1 (yT |sTj,nâˆ’1 )p(sTj,nâˆ’1 |sT âˆ’1Ï† ).
The first equality follows from Bayes Theorem in (A.20). The second equality follows from
the invariance property of the transition kernel. The third equality uses Bayes Theorem
again.
We can now evaluate the integrals in (A.19). Consider the terms involving sj,1
T :
Z

j,1
j,1 j,NÏ† p2 (yT |sT )
j,1
j,1 j,NÏ†
j,1
K2 (sj,2
|s
,
s
)
T
T
T âˆ’1
j,1 p1 (yT |sT )p(sT |sT âˆ’1 )dsT
p1 (yT |sT )
Z
j,1 j,NÏ†
j,1
j,1 j,NÏ†
j,1
=
K2 (sj,2
T |sT , sT âˆ’1 )p2 (yT |sT )p(sT |sT âˆ’1 )dsT

(A.22)

j,N

j,2
Ï†
= p2 (yT |sj,2
T )p(sT |sT âˆ’1 ).

Thus,
ï£®ï£«
E ï£°ï£­

NÏ†
Y
n=1

ï£¶

ï£¹

wÌƒTj,n ï£¸ FT âˆ’1,NÏ† ,M ï£»
ï£¶
NÏ†
j,nâˆ’1
Y
pn (yT |sT )
j,nâˆ’1 j,nâˆ’2 j,NÏ† ï£¸
ï£­
|sT , sT âˆ’1 )
j,nâˆ’1 Knâˆ’1 (sT
p (y |s
)
n=4 nâˆ’1 T T
ï£«

Z
=

Ã—

=

p3 (yT |sj,2
j,NÏ† âˆ’1
j,2
j,2
j,2 j,NÏ†
T )
j,2 p2 (yT |sT )p(sT |sT âˆ’1 )dsT Â· Â· Â· dsT
p2 (yT |sT )
j,NÏ† âˆ’1

pNÏ† (yT |sT

)
j,N âˆ’1
j,N âˆ’1 j,N
j,N âˆ’1
pNÏ† âˆ’1 (yT |sT Ï† )p(sT Ï† |sT âˆ’1Ï† )dsT Ï†
j,NÏ† âˆ’1
pNÏ† âˆ’1 (yT |sT
)
j,NÏ†
p(yT |sT âˆ’1 ).

Z
=

Â·Â·Â·

Z

(A.23)

Online Appendix

A-13

The first equality follows from (A.22). The second equality is obtained by sequentially
j,NÏ†âˆ’2

integrating out sj,2
T , . . . , sT

, using a similar argument as for sj,1
T . This proves the first

part of the lemma.
Part 2 (No Resampling). Using Lemma 3, we write



NÏ† 
M
Y
1 X j,n
j,NÏ†
j,NÏ†
j,nâˆ’1
E p(YT âˆ’h:T |sT âˆ’hâˆ’1 , Î¸)WT âˆ’hâˆ’1
wÌƒT âˆ’hâˆ’1 WT âˆ’hâˆ’1 FT âˆ’hâˆ’2,NÏ† ,M
M
n=1
j=1
ï£¶
ï£«


NÏ†
Y
j,NÏ†
j,NÏ†
j,n
(A.24)
= E p(YT âˆ’h:T |sT âˆ’hâˆ’1 , Î¸) ï£­
wÌƒT âˆ’hâˆ’1 ï£¸ WT âˆ’hâˆ’2 FT âˆ’hâˆ’2,NÏ† ,M
n=1

To prove the second part of the lemma, we slightly modify the last step of the integration
in (A.23):
ï£®

ï£«
j,N

Ï†
E ï£°p(YT âˆ’h:T |sT âˆ’hâˆ’1
)ï£­

NÏ†
Y

n=1

Z
=

j,N

ï£¹

ï£¶

wÌƒTj,nâˆ’hâˆ’1 ï£¸ FT âˆ’2,NÏ† ,M ï£»
j,N âˆ’1

j,N âˆ’1

(A.25)
j,N

j,N âˆ’1

Ï†
Ï†
Ï†
Ï†
Ï†
p(YT âˆ’h:T |sT âˆ’hâˆ’1
)pNÏ† (yT âˆ’hâˆ’1 |sT âˆ’hâˆ’1
)p(sT âˆ’hâˆ’1
|sT âˆ’hâˆ’2
)dsT âˆ’hâˆ’1

j,N

Ï†
= p(YT âˆ’hâˆ’1:T |sT âˆ’hâˆ’2
),

as required.
Part 1 (Resampling in tempering iteration nÌ„). We now assume that the selection step is
executed once, in iteration nÌ„, i.e., N = {nÌ„}. For reasons that will become apparent subsequently, we will use i subscripts for particles in stages n = 1, . . . , nÌ„ âˆ’ 1. Using Lemma 3, we
deduce that it suffices to show:
 nÌ„âˆ’1
 X

M
M
Y 1 X
1
i,n
i,nâˆ’1
j,nÌ„
j,nÌ„âˆ’1
E
wÌƒT WT
wÌƒT WT
M
M
n=1
i=1
j=1



NÏ†
M  Y
1 X
j,n
j,nÌ„
Ã—
wÌƒ
WT
FT âˆ’1,NÏ† ,M
M j=1 n=nÌ„+1 T


M
1 X
j,N
j,N
p(yT |sT âˆ’1Ï† )WT âˆ’1Ï† .
=
M j=1

(A.26)

Online Appendix

A-14
1:M,NÏ†

To evaluate the expectation, we need to integrate over the particles s1:M,1
, . . . , sT
T

as well

as the particles sÌ‚1:M,nÌ„
generated during the selection step. We have to distinguish two cases:
T
j,NÏ†

j,n j,nâˆ’1
Case 1, n 6= nÌ„ : sj,n
, sT
T âˆ¼ Kn (sT |sT

j,NÏ†

j,n j,n
Case 2, n = nÌ„ : sj,n
T âˆ¼ Kn (sT |sÌ‚T , sT

sÌ‚j,n
T

),

j = 1, . . . , M

j = 1, . . . , M ;

âˆ¼ M N s1:M,nâˆ’1
, WÌƒT1:M,n , j = 1, . . . , M
T
),

where M N (Â·) here denotes the multinomial distribution.
In a preliminary step, we are integrating out the particles sÌ‚1:M,nÌ„
. These particles enter the
T
j,N

j,nÌ„
j,nÌ„ 1:M,nÌ„âˆ’1
Ï†
Markov transition kernel KnÌ„ (sj,nÌ„
).
T |sÌ‚T , sT âˆ’1 ) as well as the conditional density p(sÌ‚T |sT

Under the assumption that the resampling step is executed using multinomial resampling,
1:M,nÌ„âˆ’1
p(sÌ‚j,nÌ„
)=
T |sT

M
1 X j,nÌ„ j,nÌ„
WÌƒT Î´(sÌ‚T âˆ’ si,nÌ„âˆ’1
),
T
M i=1

where Î´(x) is the Dirac function with the property that Î´(x) = 0 for x 6= 0 and

R

Î´(x)dx = 1.

Integrating out the resampled particles yields
p(s1:M,nÌ„
|sT1:M,nÌ„âˆ’1 )
T

 X
Z Y
M
M
1
i,nÌ„
j,nÌ„
i,nÌ„âˆ’1
j,nÌ„ j,nÌ„ j,NÏ†
WÌƒT Î´(sÌ‚T âˆ’ sT ) dsÌ‚1:M,nÌ„
=
KnÌ„ (sT |sÌ‚T , sT âˆ’1 )
T
M i=1
j=1
 X

M Z
M
Y
1
j,nÌ„ j,nÌ„ j,NÏ†
i,nÌ„
j,nÌ„
i,nÌ„âˆ’1
=
KnÌ„ (sT |sÌ‚T , sT âˆ’1 )
WÌƒT Î´(sÌ‚T âˆ’ sT ) dsÌ‚j,nÌ„
T
M
i=1
j=1

M 
M
Y
1 X i,nÌ„
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
=
WÌƒ KnÌ„ (sT |sT , sT âˆ’1 ) .
M i=1 T
j=1

(A.27)

In the last equation, the superscript for sT âˆ’1 changes from j to i because during the resampling, we keep track of the history of the particle. Thus, if for particle j = 1 the value sÌ‚1,nÌ„
T
3,N

is set to sT3,nÌ„âˆ’1 , we also use sT âˆ’1Ï† for this particle.

Online Appendix

A-15

We can now express the expected value, which we abbreviate as E, as the following
integral:
 nÌ„âˆ’1
 X

M
M
Y 1 X
1
i,n
i,nâˆ’1
j,nÌ„
j,nÌ„âˆ’1
E = E
wÌƒ W
wÌƒ W
M i=1 T T âˆ’1
M j=1 T T
n=1

(A.28)



 X

NÏ†
M  Y
1
j,n
j,nÌ„
wÌƒ
WT
Ã—
FT âˆ’1,NÏ† ,M
M j=1 n=nÌ„+1 T
 X
 X

NÏ†
Z  nÌ„âˆ’1
M
M
M  Y
Y 1 X
1
1
i,n
i,nâˆ’1
j,nÌ„
j,nÌ„âˆ’1
j,n
wÌƒ W
wÌƒ W
wÌƒ
=
Â·Â·Â·
M i=1 T T âˆ’1
M j=1 T T
M j=1 n=nÌ„+1 T
n=1
 nÌ„âˆ’1
 Y

M
M 
M
YY
1 X i,nÌ„
i,n i,nâˆ’1 i,NÏ†
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
Ã—
Kn (sT |sT , sT âˆ’1 )
WÌƒT KnÌ„ (sT |sT , sT âˆ’1 )
M
n=1 j=1
j=1
i=1
Z

 NY

Ï† âˆ’1 M
Y
1:M,NÏ† âˆ’1
j,n j,nâˆ’1 j,NÏ†
Kn (sT |sT , sT âˆ’1 ) ds1:M,1
Ã—
Â· Â· Â· dsT
.
T
n=nÌ„+1 j=1

For the second equality, we used the fact that WTj,nÌ„ = 1.
Using Lemma 4, we can write
Z

Â·Â·Â·

Z 

 NY

NÏ†
Ï† âˆ’1 M
M  Y
Y
1 X
1:M,NÏ† âˆ’1
j,n j,nâˆ’1 j,NÏ†
j,n
Kn (sT |sT , sT âˆ’1 ) dsT1:M,nÌ„+1 Â· Â· Â· dsT
wÌƒ
M j=1 n=nÌ„+1 T
n=nÌ„+1 j=1

 NY

NÏ†
Z  Y
Ï† âˆ’1
M Z
1 X
j,N âˆ’1
j,n
j,n j,nâˆ’1 j,NÏ†
=
Â·Â·Â·
wÌƒT
Kn (sT |sT , sT âˆ’1 ) dsj,nÌ„+1
Â· Â· Â· dsT Ï†
T
M j=1
n=nÌ„+1
n=nÌ„+1
M
1 X
j,NÏ†
F (sj,nÌ„
=
T , sT âˆ’1 ).
M j=1

(A.29)

Online Appendix

A-16

Now consider the following integral involving terms that depend on s1:M,nÌ„
:
T
 X

M
M

1
1 X
j,nÌ„ j,NÏ†
j,nÌ„
j,nÌ„âˆ’1
F sT , sT âˆ’1
wÌƒ W
(A.30)
=
M j=1
M j=1 T T

M 
M
Y
1 X i,nÌ„
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
Ã—
WÌƒT KnÌ„ (sT |sT , sT âˆ’1 ) ds1:M,nÌ„
T
M
j=1
i=1
 X



M Z
M
 1 X
1
j,nÌ„
j,nÌ„ j,NÏ†
i,nÌ„
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
=
F sT , sT âˆ’1
WÌƒ KnÌ„ (sT |sT , sT âˆ’1 ) dsT
M j=1
M i=1 T
 X

M
1
j,nÌ„
j,nÌ„âˆ’1
Ã—
wÌƒ W
M j=1 T T


M Z
M
 1 X
1 X
j,nÌ„ j,NÏ†
i,nÌ„
i,nÌ„âˆ’1
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
=
F sT , sT âˆ’1
wÌƒT WT
KnÌ„ (sT |sT , sT âˆ’1 ) dsj,nÌ„
T .
M j=1
M i=1
Z 

I1

The first equality is the definition of I1 . The second equality is a consequence of Lemma 4.
The last equality is obtained by recalling that
WÌƒTi,nÌ„ =

1
M

wÌƒi,nÌ„ WTi,nÌ„âˆ’1
.
PMT i,nÌ„
i,nÌ„âˆ’1
i=1 wÌƒT WT

We proceed in the evaluation of the expected value E by integrating over the particle

values s1:M,1
, . . . , sT1:M,nÌ„âˆ’1 :
T


M
1 X i,n i,nâˆ’1
wÌƒ W
E =
Â· Â· Â· I1 Â·
M i=1 T T
n=1

 nÌ„âˆ’1
M
YY
i,n i,nâˆ’1 i,NÏ†
Â· Â· Â· ds1:M,nÌ„âˆ’1
,
Ã—
Kn (sT |sT , sT âˆ’1 ) ds1:M,1
T
T
Z

Z

n=1 j=1

 nÌ„âˆ’1
Y

(A.31)

Online Appendix

A-17

where
 nÌ„âˆ’1
Y


M
1 X i,n i,nâˆ’1
I1 Â·
wÌƒ W
M i=1 T T
n=1



 X
M Z
M
 1 X
1
j,nÌ„
j,nÌ„ j,NÏ†
i,nÌ„
i,nÌ„âˆ’1
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
F sT , sT âˆ’1
wÌƒ W
KnÌ„ (sT |sT , sT âˆ’1 ) dsT
=
M j=1
M i=1 T T
 nÌ„âˆ’1

M
Y 1 X
i,n
i,nâˆ’1
Ã—
wÌƒT WT
M
n=1
i=1
 nÌ„âˆ’1


Z
M
M
M
Y 1 X
 1 X
1 X
j,nÌ„ j,NÏ†
i,nÌ„
i,nÌ„âˆ’1
i,n
i,nâˆ’1
=
F sT , sT âˆ’1
wÌƒ W
wÌƒT WT
M j=1
M i=1 T T
M
n=1
i=1

i,nÌ„âˆ’1 i,NÏ†
Ã—KnÌ„ (sj,nÌ„
, sT âˆ’1 ) dsj,nÌ„
T |sT
T
 nÌ„âˆ’1

M Z
M
Y i,n  i,N
 1 X
1 X
j,nÌ„ j,NÏ†
i,nÌ„
=
F sT , sT âˆ’1
wÌƒ
wÌƒ
WT âˆ’1Ï†
M j=1
M i=1 T n=1 T

j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
Ã—KnÌ„ (sT |sT , sT âˆ’1 ) dsj,nÌ„
T .
The last equality follows from the second part of Lemma 3. Notice the switch from j to i
superscript for functions of particles in stages n < nÌ„. Thus,
 nÌ„âˆ’1
Z
Z  X
M Z
M
Y i,n  i,N

1
1 X
j,nÌ„ j,NÏ†
i,nÌ„
wÌƒT WT âˆ’1Ï†
F sT , sT âˆ’1
Â·Â·Â·
wÌƒT
(A.32)
E =
M j=1
M i=1
n=1
 nÌ„âˆ’1

M
YY
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
i,n i,nâˆ’1 i,NÏ†
Ã—KnÌ„ (sT |sT , sT âˆ’1 )
Kn (sT |sT , sT âˆ’1 ) ds1:M,1
Â· Â· Â· ds1:M,nÌ„âˆ’1
dsj,nÌ„
T
T
T
n=1 i=1



Z Y
M Z
M Z
nÌ„
 1 X
1 X
i,N
j,nÌ„ j,NÏ†
i,n
F sT , sT âˆ’1
Â·Â·Â·
wÌƒT WT âˆ’1Ï†
=
M j=1
M i=1
n=1
i,nÌ„âˆ’1 i,NÏ†
, sT âˆ’1 )
Ã—KnÌ„ (sj,nÌ„
T |sT

nÌ„âˆ’1
Y
n=1

i,nâˆ’1 i,NÏ†
, sT âˆ’1 )dsi,1
Kn (si,n
T
T |sT

Â· Â· Â· dsi,nÌ„âˆ’1
T



dsj,nÌ„
T .

The second equality follows from Lemma 4. The calculations in (A.23) imply that
Z

Â·Â·Â·

Z Y
nÌ„
n=1

wÌƒTi,n



i,N
WT âˆ’1Ï†

nÌ„âˆ’1
Y
n=1

i,N

i,nâˆ’1
i,nÌ„âˆ’2
Kn (si,n
, sT âˆ’1Ï† )dsi,1
T |sT
T Â· Â· Â· dsT
i,N

i,N

= pnÌ„âˆ’1 (yT |si,nÌ„âˆ’1
)p(si,nÌ„âˆ’1
|sT âˆ’1Ï† )WT âˆ’1Ï† .
T
T

(A.33)

Online Appendix

A-18

In turn,

M Z
M Z
 1 X
1 X
j,nÌ„ j,NÏ†
i,nÌ„âˆ’1 i,NÏ†
E =
F sT , sT âˆ’1
KnÌ„ (sj,nÌ„
, sT âˆ’1 )
T |sT
M j=1
M i=1

i,NÏ†
i,nÌ„âˆ’1
i,nÌ„âˆ’1
i,nÌ„âˆ’1 i,NÏ†
dsj,nÌ„
Ã—pnÌ„ (yT |sT )p(sT |sT âˆ’1 )WT âˆ’1 dsT
T
M 
M Z
1 X 1 X
j,NÏ† 
j,nÌ„ i,nÌ„âˆ’1 i,NÏ†
=
F sj,nÌ„
, sT âˆ’1 )dsj,nÌ„
T
T , sT âˆ’1 KnÌ„ (sT |sT
M i=1 M j=1

i,NÏ†
i,nÌ„âˆ’1
i,nÌ„âˆ’1
i,nÌ„âˆ’1 i,NÏ†
Ã—pnÌ„ (yT |sT )p(sT |sT âˆ’1 )WT âˆ’1 dsT

(A.34)

M Z
1 X
i,NÏ†
i,NÏ† 
i,nÌ„
i,nÌ„ i,NÏ†
i,nÌ„
=
,
s
F si,nÌ„
T âˆ’1 pnÌ„ (yT |sT )p(sT |sT âˆ’1 )WT âˆ’1 dsT
T
M i=1
 NY

NÏ†
Z  Y
Ï† âˆ’1
M Z
1 X
j,n j,nâˆ’1 j,NÏ†
j,n
=
Kn (sT |sT , sT âˆ’1 )
Â·Â·Â·
wÌƒT
M j=1
n=nÌ„+1
n=nÌ„+1
j,N

j,N

j,NÏ† âˆ’1

j,nÌ„
j,nÌ„+1
Ï†
Ï†
Ã—pnÌ„ (yT |sj,nÌ„
Â· Â· Â· dsT
T )p(sT |sT âˆ’1 )WT âˆ’1 dsT

M
1 X
j,N
j,N
p(yT |sT âˆ’1Ï† )WT âˆ’1Ï† .
=
M j=1

j,N

j,nÌ„
j,nÌ„
Ï†
pnÌ„ (yT |sj,nÌ„
T )p(sT |sT âˆ’1 )dsT

The second equality is obtained by changing the order of two summations. To obtain the
third equality, we integrate out the si,nÌ„âˆ’1
terms along the lines of (A.21). Notice that the
T
value of the integral is identical for all values of the j superscript. Thus, we simply set j = i
i,NÏ† 
and drop the average. For the fourth equality, we plug in the definition of F si,nÌ„
T , sT âˆ’1 and
replace the i index with a j index. The last equality follows from calculations similar to
those in (A.23). This completes the analysis of Part 1.
Part 2 (Resampling in tempering iteration nÌ„). A similar argument as for Part 1 can be used
to extend the result for Part 2.
Resampling in multiple tempering iterations. The previous analysis can be extended to the
case in which the selection step is executed in multiple tempering iterations n âˆˆ N , assuming
that the set N does not itself depend on the particle system. 

Online Appendix
A.3.2

A-19

Proof of Main Theorem

Proof of Theorem 2. Suppose that for any h such that 0 â‰¤ h â‰¤ T âˆ’ 1
M


1 X
j,NÏ†
j,NÏ†
,
E pÌ‚(YT âˆ’h:T |Y1:T âˆ’hâˆ’1 , Î¸)|FT âˆ’hâˆ’1,NÏ† ,M =
, Î¸)WT âˆ’hâˆ’1
p(YT âˆ’h:T |sT âˆ’hâˆ’1
M j=1

where
pÌ‚(YT âˆ’h:T |Y1:T âˆ’hâˆ’1 , Î¸) =

T
Y

ï£«

NÏ†
Y

ï£­
t=T âˆ’h

n=1

(A.35)

!ï£¶
M
X
1
wÌƒj,n Wtj,nâˆ’1 ï£¸ .
M j=1 t

Then, by setting h = T âˆ’ 1, we can deduce that
M


1 X
j,N
j,N
p(Y1:T |s0 Ï† , Î¸)W0 Ï† .
E pÌ‚(Y1:T |Î¸)|F0,NÏ† ,M =
M j=1

(A.36)

Recall that for period t = 0, we adopted the convention that NÏ† = 1 and assumed that the
j,NÏ†

states were initialized by direct sampling: s0

j,NÏ†

âˆ¼ p(s0 ) and W0

= 1. Thus,







E pÌ‚(Y1:T |Î¸) = E E pÌ‚(Y1:T |Î¸)|F0,NÏ† ,M

(A.37)


 X
M
1
j,NÏ†
j,NÏ†
p(Y1:T |s0 , Î¸)W0
= E
M j=1
Z
=
p(Y1:T |s0 , Î¸)p(s0 )ds0
= p(Y1:T |Î¸),
as desired.
In the remainder of the proof, we use an inductive argument to establish (A.35). If (A.35)

Online Appendix

A-20

holds for h, it also has to hold for h + 1:


E pÌ‚(YT âˆ’hâˆ’1:T |Y1:T âˆ’hâˆ’2 , Î¸)|FT âˆ’hâˆ’2,NÏ† ,M




= E E pÌ‚(YT âˆ’h:T |Y1:T âˆ’hâˆ’1 , Î¸) FT âˆ’hâˆ’1,NÏ† ,M pÌ‚(yT âˆ’hâˆ’1 |Y1:T âˆ’hâˆ’2 , Î¸) FT âˆ’hâˆ’2,NÏ† ,M
M

1 X 
j,NÏ†
j,NÏ†
pÌ‚(yT âˆ’hâˆ’1 |Y1:T âˆ’hâˆ’2 , Î¸) FT âˆ’hâˆ’2,NÏ† ,M
, Î¸)WT âˆ’hâˆ’1
=
E p(YT âˆ’h:T |sT âˆ’hâˆ’1
M j=1
ï£«
ï£¹
ï£®
!ï£¶
NÏ†
M
M
Y 1 X j,n
1 X ï£°
j,NÏ†
j,NÏ†
ï£­
ï£¸ FT âˆ’hâˆ’2,NÏ† ,M ï£»
=
, Î¸)WT âˆ’hâˆ’1
E p(YT âˆ’h:T |sT âˆ’hâˆ’1
wÌƒT âˆ’hâˆ’1 WTj,nâˆ’1
âˆ’hâˆ’1
M j=1
M
n=1
j=1

=

M
1 X
j,NÏ†
j,NÏ†
p(YT âˆ’hâˆ’1:T |sT âˆ’hâˆ’2
, Î¸)WT âˆ’hâˆ’2
.
M j=1

Note that FT âˆ’hâˆ’2,NÏ† ,M âŠ‚ FT âˆ’hâˆ’1,NÏ† ,M . Thus, the first equality follows from the law of iterated expectations. The second equality follows from the inductive hypothesis (A.35). The
third equality uses the definition of the period-likelihood approximation in (23) of Algorithm 2. The last equality follows from the second part of Lemma 5.
We now verify that the inductive hypothesis (A.35) holds for h = 0. Using the definition
of pÌ‚(yT |Y1:T âˆ’1 , Î¸), we can write
ï£®

NÏ†

Y


E pÌ‚(yT |Y1:T âˆ’1 , Î¸)|FT âˆ’1,NÏ† ,M = E ï£°

n=1

=

1
M

M
X

!
wÌƒTj,n WTj,nâˆ’1

j=1

ï£¹
FT âˆ’1,NÏ† ,M ï£» (A.38)

M
1 X
j,N
j,N
p(yT |sT âˆ’1Ï† )WT âˆ’1Ï† .
M j=1

The second equality follows from the first part of Lemma 5. Thus, we can deduce that (A.35)
holds for h = T âˆ’ 1 as required. This completes the proof. 

B

Computational Details

The code for this project is available at http://github.com/eph/tempered_pf. The applications in Section 4 were coded in Fortran and compiled using the Intel Fortran Compiler

Online Appendix

A-21

(version: 13.0.0), including the math kernel library. The calculations in Algorithm 1, part
2(a)ii, Algorithm 2, part 1(a)i, and Algorithm 2, part 2(c) were implemented using OpenMP
(shared memory) multithreading.

C

DSGE Models and Data Sources

C.1
C.1.1

Small-Scale DSGE Model
Equilibrium Conditions

We write the equilibrium conditions by expressing each variable in terms of percentage
deviations from its steady state value. Let xÌ‚t = ln(xt /x) and write
h
i
1 = Î²Et eâˆ’Ï„ cÌ‚t+1 +Ï„ cÌ‚t +RÌ‚t âˆ’zÌ‚t+1 âˆ’Ï€Ì‚t+1




1
1
Ï€Ì‚t
Ï€Ì‚t
0 = e âˆ’1
1âˆ’
e +
2Î½
2Î½
 Ï€Ì‚t+1
 âˆ’Ï„ cÌ‚t+1 +Ï„ cÌ‚t +yÌ‚t+1 âˆ’yÌ‚t +Ï€Ì‚t+1 
âˆ’Î²Et e
âˆ’1 e

1âˆ’Î½
Ï„ cÌ‚t
1
âˆ’
e
+
Î½Ï†Ï€ 2
2
Ï†Ï€ 2 g Ï€Ì‚t
ecÌ‚t âˆ’yÌ‚t = eâˆ’gÌ‚t âˆ’
e âˆ’1
2
RÌ‚t = ÏR RÌ‚tâˆ’1 + (1 âˆ’ ÏR )Ïˆ1 Ï€Ì‚t

(A.39)
(A.40)

(A.41)
(A.42)

+(1 âˆ’ ÏR )Ïˆ2 (yÌ‚t âˆ’ gÌ‚t ) + R,t
gÌ‚t = Ïg gÌ‚tâˆ’1 + g,t

(A.43)

zÌ‚t = Ïz zÌ‚tâˆ’1 + z,t .

(A.44)

Log-linearization and straightforward manipulation of Equations (A.39) to (A.41) yield
the following representation for the consumption Euler equation, the New Keynesian Phillips

Online Appendix

A-22

curve, and the monetary policy rule:
yÌ‚t



1
= Et [yÌ‚t+1 ] âˆ’
RÌ‚t âˆ’ Et [Ï€Ì‚t+1 ] âˆ’ Et [zÌ‚t+1 ]
Ï„
+gÌ‚t âˆ’ Et [gÌ‚t+1 ]

(A.45)

Ï€Ì‚t = Î²Et [Ï€Ì‚t+1 ] + Îº(yÌ‚t âˆ’ gÌ‚t )
RÌ‚t = ÏR RÌ‚tâˆ’1 + (1 âˆ’ ÏR )Ïˆ1 Ï€Ì‚t + (1 âˆ’ ÏR )Ïˆ2 (yÌ‚t âˆ’ gÌ‚t ) + R,t
where
Îº=Ï„

1âˆ’Î½
.
Î½Ï€ 2 Ï†

(A.46)

To construct a likelihood function, we have to relate the model variables to a set of observables yt . We use the following three observables for estimation: quarter-to-quarter per
capita GDP growth rates (YGR), annualized quarter-to-quarter inflation rates (INFL), and
annualized nominal interest rates (INT). The three series are measured in percentages, and
their relationship to the model variables is given by the following set of equations:
Y GRt = Î³ (Q) + 100(yÌ‚t âˆ’ yÌ‚tâˆ’1 + zÌ‚t )

(A.47)

IN F Lt = Ï€ (A) + 400Ï€Ì‚t
IN Tt = Ï€ (A) + r(A) + 4Î³ (Q) + 400RÌ‚t .
The parameters Î³ (Q) , Ï€ (A) , and r(A) are related to the steady states of the model economy
as follows:
Î³ =1+

Î³ (Q)
,
100

Î²=

1
1 + r(A) /400

,

Ï€ =1+

Ï€ (A)
.
400

The structural parameters are collected in the vector Î¸. Since in the first-order approximation
the parameters Î½ and Ï† are not separately identifiable, we express the model in terms of Îº,
defined in (A.46). Let
Î¸ = [Ï„, Îº, Ïˆ1 , Ïˆ2 , ÏR , Ïg , Ïz , r(A) , Ï€ (A) , Î³ (Q) , ÏƒR , Ïƒg , Ïƒz ]0 .

Online Appendix
C.1.2

A-23

Data Sources

1. Per Capita Real Output Growth Take the level of real gross domestic product,
(FRED mnemonic â€œGDPC1â€), call it GDPt . Take the quarterly average of the Civilian
Non-institutional Population (FRED mnemonic â€œCNP16OVâ€ / BLS series â€œLNS10000000â€),
call it P OPt . Then,
Per Capita Real Output Growth
 



GDPt
GDPtâˆ’1
= 100 ln
âˆ’ ln
.
P OPt
P OPtâˆ’1
2. Annualized Inflation. Take the CPI price level, (FRED mnemonic â€œCPIAUCSLâ€),
call it CP It . Then,

Annualized Inflation = 400 ln

CP It
CP Itâˆ’1


.

3. Federal Funds Rate. Take the effective federal funds rate (FRED mnemonic â€œFEDFUNDSâ€), call it F F Rt . Then,
Federal Funds Rate = F F Rt .

C.2
C.2.1

The Smets-Wouters Model
Equilibrium Conditions

The log-linearized equilibrium conditions of the Smets and Wouters (2007) model take the
following form:

Online Appendix

A-24

yÌ‚t = cy cÌ‚t + iy iÌ‚t + zy zÌ‚t + Îµgt
1
h/Î³
cÌ‚tâˆ’1 +
Et cÌ‚t+1
cÌ‚t =
1 + h/Î³
1 + h/Î³
wlc (Ïƒc âˆ’ 1) Ë†
+
(lt âˆ’ Et Ë†lt+1 )
Ïƒc (1 + h/Î³)
1 âˆ’ h/Î³ b
1 âˆ’ h/Î³
(rÌ‚t âˆ’ Et Ï€Ì‚t+1 ) âˆ’
Îµ
âˆ’
(1 + h/Î³)Ïƒc
(1 + h/Î³)Ïƒc t
1
Î²Î³ (1âˆ’Ïƒc )
iÌ‚t =
iÌ‚
+
Et iÌ‚t+1
tâˆ’1
1 + Î²Î³ (1âˆ’Ïƒc )
1 + Î²Î³ (1âˆ’Ïƒc )
1
qÌ‚t + Îµit
+ 2
Ï•Î³ (1 + Î²Î³ (1âˆ’Ïƒc ) )
qÌ‚t = Î²(1 âˆ’ Î´)Î³ âˆ’Ïƒc Et qÌ‚t+1 âˆ’ rÌ‚t + Et Ï€Ì‚t+1

(A.48)
(A.49)

(A.50)

(A.51)

k
+(1 âˆ’ Î²(1 âˆ’ Î´)Î³ âˆ’Ïƒc )Et rÌ‚t+1
âˆ’ Îµbt

yÌ‚t = Î¦(Î±kÌ‚ts + (1 âˆ’ Î±)Ë†lt + Îµat )

(A.52)

kÌ‚ts = kÌ‚tâˆ’1 + zÌ‚t
1âˆ’Ïˆ k
zÌ‚t =
rÌ‚
Ïˆ t

(A.53)
(A.54)

Online Appendix

A-25

kÌ‚t =

(1 âˆ’ Î´)
kÌ‚tâˆ’1 + (1 âˆ’ (1 âˆ’ Î´)/Î³)iÌ‚t
Î³
+(1 âˆ’ (1 âˆ’ Î´)/Î³)Ï•Î³ 2 (1 + Î²Î³ (1âˆ’Ïƒc ) )Îµit

ÂµÌ‚pt = Î±(kÌ‚ts âˆ’ Ë†lt ) âˆ’ wÌ‚t + Îµat
Î²Î³ (1âˆ’Ïƒc )
Î¹p
Ï€Ì‚t =
Et Ï€Ì‚t+1 +
Ï€Ì‚tâˆ’1
(1âˆ’Ïƒ
)
c
1 + Î¹p Î²Î³
1 + Î²Î³ (1âˆ’Ïƒc )
(1 âˆ’ Î²Î³ (1âˆ’Ïƒc ) Î¾p )(1 âˆ’ Î¾p )
âˆ’
ÂµÌ‚pt + Îµpt
(1âˆ’Ïƒ
)
c
(1 + Î¹p Î²Î³
)(1 + (Î¦ âˆ’ 1)Îµp )Î¾p
s
k
Ë†
rÌ‚ = lt + wÌ‚t âˆ’ kÌ‚
t

t

ÂµÌ‚w
= wÌ‚t âˆ’ Ïƒl Ë†lt âˆ’
t

1
(cÌ‚t âˆ’ h/Î³cÌ‚tâˆ’1 )
1 âˆ’ h/Î³

Î²Î³ (1âˆ’Ïƒc )
(Et wÌ‚t+1
1 + Î²Î³ (1âˆ’Ïƒc )
1
+Et Ï€Ì‚t+1 ) +
(wÌ‚tâˆ’1 âˆ’ Î¹w Ï€Ì‚tâˆ’1 )
1 + Î²Î³ (1âˆ’Ïƒc )
1 + Î²Î³ (1âˆ’Ïƒc ) Î¹w
Ï€Ì‚t
âˆ’
1 + Î²Î³ (1âˆ’Ïƒc )
(1 âˆ’ Î²Î³ (1âˆ’Ïƒc ) Î¾w )(1 âˆ’ Î¾w )
âˆ’
ÂµÌ‚w + Îµw
t
(1 + Î²Î³ (1âˆ’Ïƒc ) )(1 + (Î»w âˆ’ 1)w )Î¾w t
= ÏrÌ‚tâˆ’1 + (1 âˆ’ Ï)(rÏ€ Ï€Ì‚t + ry (yÌ‚t âˆ’ yÌ‚tâˆ— ))

(A.55)

(A.56)
(A.57)

(A.58)
(A.59)

wÌ‚t =

(A.60)

rÌ‚t

(A.61)

âˆ—
+râˆ†y ((yÌ‚t âˆ’ yÌ‚tâˆ— ) âˆ’ (yÌ‚tâˆ’1 âˆ’ yÌ‚tâˆ’1
)) + Îµrt .

The exogenous shocks evolve according to

Online Appendix

A-26

Îµat = Ïa Îµatâˆ’1 + Î·ta

(A.62)

Îµbt = Ïb Îµbtâˆ’1 + Î·tb

(A.63)

Îµgt = Ïg Îµgtâˆ’1 + Ïga Î·ta + Î·tg

(A.64)

Îµit = Ïi Îµitâˆ’1 + Î·ti

(A.65)

Îµrt = Ïr Îµrtâˆ’1 + Î·tr

(A.66)

p
Îµpt = Ïr Îµptâˆ’1 + Î·tp âˆ’ Âµp Î·tâˆ’1

(A.67)

w
w
Îµw
= Ïw Îµw
t
tâˆ’1 + Î·t âˆ’ Âµw Î·tâˆ’1 .

(A.68)

Online Appendix

A-27

The counterfactual no-rigidity prices and quantities evolve according to
yÌ‚tâˆ— = cy cÌ‚âˆ—t + iy iÌ‚âˆ—t + zy zÌ‚tâˆ— + Îµgt
1
h/Î³ âˆ—
cÌ‚tâˆ’1 +
Et cÌ‚âˆ—t+1
cÌ‚âˆ—t =
1 + h/Î³
1 + h/Î³
wlc (Ïƒc âˆ’ 1) Ë†âˆ—
âˆ—
+
(l âˆ’ Et Ë†lt+1
)
Ïƒc (1 + h/Î³) t
1 âˆ’ h/Î³ b
1 âˆ’ h/Î³ âˆ—
rt âˆ’
Îµ
âˆ’
(1 + h/Î³)Ïƒc
(1 + h/Î³)Ïƒc t
1
Î²Î³ (1âˆ’Ïƒc )
âˆ—
iÌ‚âˆ—t =
iÌ‚
+
Et iÌ‚âˆ—
1 + Î²Î³ (1âˆ’Ïƒc ) tâˆ’1 1 + Î²Î³ (1âˆ’Ïƒc ) t+1
1
qÌ‚ âˆ— + Îµit
+ 2
Ï•Î³ (1 + Î²Î³ (1âˆ’Ïƒc ) ) t
âˆ—
qÌ‚tâˆ— = Î²(1 âˆ’ Î´)Î³ âˆ’Ïƒc Et qÌ‚t+1
âˆ’ rtâˆ—

(A.69)
(A.70)

(A.71)
(A.72)

kâˆ—
+(1 âˆ’ Î²(1 âˆ’ Î´)Î³ âˆ’Ïƒc )Et rt+1
âˆ’ Îµbt

yÌ‚tâˆ— = Î¦(Î±ktsâˆ— + (1 âˆ’ Î±)Ë†ltâˆ— + Îµat )
âˆ—
kÌ‚tsâˆ— = ktâˆ’1
+ ztâˆ—
1 âˆ’ Ïˆ kâˆ—
rÌ‚
zÌ‚tâˆ— =
Ïˆ t
(1 âˆ’ Î´) âˆ—
kÌ‚tâˆ— =
kÌ‚tâˆ’1 + (1 âˆ’ (1 âˆ’ Î´)/Î³)iÌ‚t
Î³
+(1 âˆ’ (1 âˆ’ Î´)/Î³)Ï•Î³ 2 (1 + Î²Î³ (1âˆ’Ïƒc ) )Îµit

(A.73)
(A.74)
(A.75)
(A.76)

wÌ‚tâˆ— = Î±(kÌ‚tsâˆ— âˆ’ Ë†ltâˆ— ) + Îµat

(A.77)

rÌ‚tkâˆ— = Ë†ltâˆ— + wÌ‚tâˆ— âˆ’ kÌ‚tâˆ—
1
(cÌ‚âˆ— + h/Î³cÌ‚âˆ—tâˆ’1 ).
wÌ‚tâˆ— = Ïƒl Ë†ltâˆ— +
1 âˆ’ h/Î³ t

(A.78)
(A.79)

Online Appendix

A-28

The steady state (ratios) that appear in the measurement equation or the log-linearized
equilibrium conditions are given by

Î³ = Î³Ì„/100 + 1

(A.80)

Ï€ âˆ— = Ï€Ì„/100 + 1

(A.81)

rÌ„ = 100(Î² âˆ’1 Î³ Ïƒc Ï€ âˆ— âˆ’ 1)

(A.82)

k
rss
= Î³ Ïƒc /Î² âˆ’ (1 âˆ’ Î´)
 Î±
 1
Î± (1 âˆ’ Î±)(1âˆ’Î±) 1âˆ’Î±
wss =
k Î±
Î¦rss
ik = (1 âˆ’ (1 âˆ’ Î´)/Î³)Î³
k
1 âˆ’ Î± rss
lk =
Î± wss
(Î±âˆ’1)
ky = Î¦lk

(A.83)
(A.84)
(A.85)
(A.86)
(A.87)

iy = (Î³ âˆ’ 1 + Î´)ky

(A.88)

cy = 1 âˆ’ gy âˆ’ iy

(A.89)

k
zy = rss
ky
k
1 1 âˆ’ Î± rss
ky
wlc =
.
Î»w Î±
cy

(A.90)
(A.91)

The measurement equations take the form:

Y GRt = Î³Ì„ + yÌ‚t âˆ’ yÌ‚tâˆ’1
IN Ft = Ï€Ì„ + Ï€Ì‚t
F F Rt = rÌ„ + RÌ‚t
CGRt = Î³Ì„ + cÌ‚t âˆ’ cÌ‚tâˆ’1
IGRt = Î³Ì„ + iÌ‚t âˆ’ iÌ‚tâˆ’1
W GRt = Î³Ì„ + wÌ‚t âˆ’ wÌ‚tâˆ’1
HOU RSt = Â¯l + Ë†lt .

(A.92)

Online Appendix
C.2.2

A-29

Data

The data cover 1966Q1 to 2004Q4. The construction follows that of Smets and Wouters
(2007). Output data come from the NIPA; other sources are noted in the exposition.
1. Per Capita Real Output Growth. Take the level of real gross domestic product (FRED mnemonic â€œGDPC1â€), call it GDPt . Take the quarterly average of the
Civilian Non-institutional Population (FRED mnemonic â€œCNP16OVâ€ and BLS series
â€œLNS10000000â€) normalized so that its 1992Q3 value is 1 and call it P OPt . Then,
Per Capita Real Output Growth
 



GDPt
GDPtâˆ’1
âˆ’ ln
.
= 100 ln
P OPt
P OPtâˆ’1
2. Per Capita Real Consumption Growth. Take the level of personal consumption
expenditures (FRED mnemonic â€œPCECâ€), call it CON St . Take the level of the GDP
price deflator (FRED mnemonic â€œGDPDEFâ€) and call it GDP Pt . Then,
Per Capita Real Consumption Growth

 
CON St
= 100 ln
GDP Pt P OPt


CON Stâˆ’1
âˆ’ ln
.
GDP Ptâˆ’1 P OPtâˆ’1
3. Per Capita Real Investment Growth. Take the level of fixed private investment
(FRED mnemonic â€œFPIâ€) and call it IN Vt . Then,
Per Capita Real Investment Growth

 
IN Vt
= 100 ln
GDP Pt P OPt


IN Vtâˆ’1
âˆ’ ln
.
GDP Ptâˆ’1 P OPtâˆ’1
4. Per Capita Real Wage Growth. Take the BLS measure of compensation per
hour for the nonfarm business sector (FRED mnemonic â€œCOMPNFBâ€ / BLS series

Online Appendix

30

â€œPRS85006103â€) and call it Wt . Then,
Per Capita Real Wage Growth



 
Wtâˆ’1
Wt
âˆ’ ln
.
= 100 ln
GDP Pt
GDP Ptâˆ’1
5. Per Capita Hours Index. Take the index of average weekly nonfarm business hours
(FRED mnemonic / BLS series â€œPRS85006023â€) and call it HOU RSt . Take the number
of employed civilians (FRED mnemonic â€œCE16OVâ€), normalized so that its 1992Q3 value
is 1 and call it EM Pt . Then,

Per Capita Hours = 100 ln

HOU RSt EM Pt
P OPt


.

The series is then demeaned.
6. Inflation. Take the GDP price deflator, then

Inflation = 100 ln

GDP Pt
GDP Ptâˆ’1


.

7. Federal Funds Rate. Take the effective federal funds rate (FRED mnemonic â€œFEDFUNDSâ€) and call it F F Rt . Then,
Federal Funds Rate = F F Rt /4.

