NBER WORKING PAPER SERIES

EDUCATION AND THE AGE PROFILE OF LITERACY INTO ADULTHOOD
Elizabeth Cascio
Damon Clark
Nora Gordon
Working Paper 14073
http://www.nber.org/papers/w14073

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2008

We thank Youjin Hahn, Laurel Wheeler, and Christine Donnelly for outstanding research assistance.
We also thank seminar participants at Dartmouth and UCSD, Susan Dynarksi, James Hines, John
Meyer, Bruce Sacerdote, Andrei Shleifer, Jeremy Stein, and Timothy Taylor for comments that improved
the paper and Rudolf Winter-Ebner for assistance in preparing the data used in this paper. The views
expressed herein are those of the author(s) and do not necessarily reflect the views of the National
Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2008 by Elizabeth Cascio, Damon Clark, and Nora Gordon. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.

Education and the Age Profile of Literacy into Adulthood
Elizabeth Cascio, Damon Clark, and Nora Gordon
NBER Working Paper No. 14073
June 2008
JEL No. F0,I2
ABSTRACT
It is widely documented that U.S. students score below their OECD counterparts on international achievement
tests, but it is less commonly known that ultimately, U.S. native adults catch up. In this paper, we
explore institutional explanations for differences in the evolution of literacy over young adulthood
across wealthy OECD countries. We use an international cross-section of micro data from the International
Adult Literacy Survey (IALS); these data show that cross-country differences in the age profile of
literacy skills are not due to differences in individual family background, and that relatively high rates
of university graduation appears to explain a good part of the U.S. "catch up." The cross-sectional
design of the IALS prevents us from controlling for cohort effects, but we use a variety of other data
sources to show that cohort effects are likely small in comparison to the differences by age revealed
in the IALS. We go on to discuss how particular institutional features of secondary and postsecondary
education correlate, at the country level, with higher rates of university completion.

Elizabeth Cascio
Department of Economics
Dartmouth College
6106 Rockefeller Hall
Hanover, NH 03755
and NBER
elizabeth.u.cascio@dartmouth.edu
Damon Clark
Department of Economics
University of Florida
P.O. Box 117140
Gainesville, FL 32611-7140
and NBER
damon.clark@cba.ufl.edu

Nora Gordon
Department of Economics
University of California, San Diego
9500 Gilman Drive
La Jolla, CA 92093-0508
and NBER
negordon@ucsd.edu

American teenagers perform considerably worse on international assessments of achievement than
do teenagers in other high-income countries. This observation has been a source of great concern since the
first international tests were administered in the 1960s (for example, Dillon, 2007), not least because of the
correlation found between these test scores and economic growth (Hanushek and Woessmann, 2007). Yet,
little known is the fact that the U.S. achievement gap closes as teenagers enter adulthood. Data from the
first international assessment of adult literacy show that, in the mid 1990s, 16 and 17 year-olds in the
United States ranked behind 16 and 17 year-olds in the twelve other rich countries surveyed (in order of
achievement): Sweden, Finland, Switzerland, Netherlands, Norway, Belgium, Germany, Denmark, United
Kingdom, Ireland, New Zealand, and Italy. But for 26 to 30 year-olds assessed at the same time using the
same test, U.S. adults ranked seventh in this group of countries, and the gap with countries still ahead was
much diminished.
In this paper, we use this assessment to document improvements in test scores from the end of
compulsory education—where other international surveys have historically left off—to the likely end of
formal schooling, both for the United States and other high-income countries. We then explore the role of
higher education in these test-score improvements. We find that countries for which the age profile of test
performance is relatively steep, like the United States, tend to have relatively high rates of university
graduation. In turn, the educational systems of countries with relatively high university graduation rates
share two features: comprehensive secondary education—where all high school students have the option
of taking courses to prepare for university—and a highly accessible university sector.
For most of the twentieth century, the United States led the developed world in participation and
completion of higher education. The United States was the first country to adopt mass education, both at
the higher and secondary levels (Goldin, 2001). In recent years, however, other high-income countries—
many of which established comprehensive secondary schooling in decades prior—have substantially
expanded access to university education. In fact, many countries that significantly lagged the United States
in university graduation only a decade ago—Finland, Sweden, and the United Kingdom among others—
1

now have comparable if not higher graduation rates. Our estimates suggest that these changes will have
striking consequences for the distribution of skill across countries in the years to come.

Comparing Academic Performance across Countries

Press coverage of differences in academic performance across countries is typically based on two
surveys: the Trends in International Mathematics and Science Study (TIMSS, sponsored by the
International Association for the Evaluation of Educational Achievement) and the OECD Programme for
International Student Assessment (PISA). Both of these surveys focus on students who are teenagers or
younger. The TIMSS tested students in fourth and eighth grades in 1995, 1999, 2003, and 2007 (2007 data
are not yet available) in mathematics and science. It includes about 50 countries and is planned to continue
on a four-year testing cycle. The PISA tested 15 year-olds in reading, math, and science in 2000, 2003, and
2006, and is planned to continue on a three-year cycle. 1 In addition to individual student performance on
the relevant assessments, these surveys also collect data on student demographics and school
characteristics.
Our focus here is on changes in skill between the teenage years and adulthood. Two large-scale
assessments have been conducted to permit an analysis along these lines, measuring the informationprocessing skills of populations aged 16–65 in different countries. The International Adult Literacy Survey
(IALS) was organized by Statistics Canada and the Educational Testing Service and administered in
conjunction with national household surveys in 1994, 1996, and 1998. The Adult Literacy and Life Skills
Survey (ALL) included different countries in different years, with testing taking place in 2003 and 2005
(OECD, 2005). In both surveys, respondents were administered the same test, regardless of age. We can

1

The data and a description of the TIMSS are available at <http://timss.bc.edu/#>. Baker (1997)
discusses several weaknesses of the TIMSS, including differences in curricular timing (like teaching
geometry to 14 year-olds in one country and 15 year-olds in another). The data and a description of the
PISA are available at <http://www.pisa.oecd.org>.
2

thus compare how skill changes from age 16—where the TIMSS and the PISA leave off—into adulthood.
Because the IALS covered 17 OECD countries and the ALL covered only five (plus one Mexican state),
we use the IALS for the analysis here.
The design of international assessments for the school-aged population is controversial; designing
an international assessment for adults is even more fraught. What curricular content would be covered?
Would adults be expected to remember high school mainstays like trigonometry? (Would researchers and
policymakers care if they did?) The approach taken in the IALS is to measure practical skills in three
domains—quantitative literacy, prose literacy, and document literacy—rather than academic mastery of
high school content. Quantitative literacy is defined as the application of “arithmetic operations, either
alone or sequentially, to numbers embedded in printed materials.” Prose literacy is defined as the
understanding and ability to use “information from texts.” Document literacy is defined as the ability to
“locate and use information in various formats” (OECD and Statistics Canada, 1995). In each domain,
proficiency is categorized from level one (the ability to locate information in text) to level five (the ability
to locate information in dense text with multiple distractors and to make high-level inferences). The
median performer in each country scores at either level two or level three.
To measure their proficiency, IALS respondents were given several passages of text and, following
each passage, were asked a series of questions, with the proficiency level of each question based on the
proportion of respondents that answered it correctly (OECD and Statistics Canada, 1995). A respondent’s
overall proficiency level in a particular domain was then calculated based on the number of questions at
each level that she answered correctly in that domain; Brown and Micklewright (2004) provide an excellent
discussion of this procedure . For our purposes, it is important to note that the hardest questions were
sufficiently difficult that higher education could affect performance. For example, one level-four
quantitative item gave respondents a table describing compound interest on a given amount of principal
over various time horizons (rows) and for various annual interest rates (columns) and asked for the
minimum annual interest rate required to double the principal within a five-year horizon.
3

International data sets like these can be extremely useful in learning about education production
functions at all ages. When studying primary or secondary education within a country, variation in
measured educational inputs typically is related to unmeasured parental resources and decisions; for
example, smaller class sizes may be more common in communities where parents also emphasize
education in many other ways. As a result, it is difficult to estimate the true effect of smaller classes on
student achievement. Correlations between inputs and achievement across countries may suffer less from
such biases, because otherwise similar children in different countries may attend very different schools.
Researchers have investigated the effect of elementary and secondary educational spending and
organizational structures on test scores using data from the TIMSS or the PISA and this empirical
approach (for example, Woessmann, 2003; Fuchs and Woessmann, 2007; Hanushek and Woessmann,
2006). In a similar spirit, we use the IALS to investigate how the organization and funding of secondary
and higher education influence university graduation and—through university graduation—the skills of
adults.

How Do Countries Differ in the Age Profile of Literacy?

We begin by using the International Adult Literacy Survey to compare the literacy of two age
groups—16–17 year-olds and 26–30 year-olds—across countries. The younger group includes those close
to or at the end of compulsory schooling, which in the countries under investigation (listed below) is
typically either age 15 or 16 (for international compulsory schooling ages, see Murtin and Viarengo, 2007;
for U.S. compulsory schooling ages, see Oreopolous, forthcoming). The older group includes those at or
close to the end of the period of formal education and training. Although reports of the current enrollment
status of the IALS respondents appear inaccurate, data on expected graduation ages suggest that most
individuals will have finished their first university degree (for example, a bachelor’s degree) by age 25. We

4

do not explore the evolution of literacy from age 18 through 25 because of sampling limitations in the
IALS; most notably, the sample excludes U.S. college students residing in dormitories.
As noted, the International Adult Literacy Survey provides distinct measures of prose, document,
and quantitative literacy. Because correlations in performance across the three domains are strong, we
define literacy as an average across the three domains. Previous papers using the IALS have taken a similar
approach (for example, Blau and Kahn, 2005; Devroye and Freeman, 2001; Hanushek and Zhang, 2006),
and the relationships we describe remain substantively unchanged when using literacy defined in any one
domain. We are particularly interested in the role of higher education in the age profile of literacy and
expect university graduation—our measure of higher education—to have the greatest effect on
performance at the top of the score distribution.2 Our analysis therefore focuses on an indicator that is set
to one if an individual’s average score across domains is at or above the test-score threshold for achieving
level-four proficiency (illustrated above in terms of the compound interest question).
We restrict our attention to the subset of International Adult Literacy Survey participant countries
that had GDP per capita exceeding $20,000 in 2002, as these countries could in principle offer the most
similar postcompulsory schooling opportunities. Other OECD countries that participated in the IALS but
are excluded from the analysis because of this income threshold are the Czech Republic, Hungary, and
Poland, which in 2002 had GDP per capita of $16,585, $14,365, and $11,194, respectively. We also exclude
Canada, because the public-use data for Canada do not disclose the age and nativity of respondents. These
variables are necessary for our analysis, since we limit our sample to the native born. This sample
restriction allows us to focus on respondents likely to have been schooled in their current country of
2

This expectation is borne out by the data. As anticipated, we find a strong relationship between university
graduation rates and gains in the fraction of a cohort in the upper part of the test score distribution. We
find a weaker relationship between university graduation rates and differences between test scores (the
averages of the three scores) of the two age groups (16–17 and 26–30), and no relationship between
university graduation rates and gains in the fraction of a cohort achieving proficiency at level one.
However, it is important to note that data constraints force us to use “on-time” university graduation rates
as a measure of the prevalence of higher education in a country. The effects of alternative measures, such
as the fraction of a cohort that attends a university with or without receiving a degree, may be apparent
elsewhere in the test score distribution.
5

residence. It also ensures that our estimates are not influenced by differing compositions of immigrant
populations across countries, for example in terms of skill (Mayda, 2006) or age.
Figure 1 shows shares reaching level-four or -five proficiency on the International Adult Literacy
Survey by country and age group. Countries are ordered from highest to lowest on the basis of the
performance of the younger age group, represented with the darker bars. Only 4.7 percent of native-born
U.S. 16–17 year-olds achieved level-four or -five proficiency—fewer than any other comparison country.
This finding is consistent with the poor performance of U.S. teenagers relative to similar-income countries
on other assessments of the school-aged population.
We next compare how countries rank by performance of 26–30 year-olds (represented by the
lighter bars of Figure 1) relative to 16–17 year-olds. The lighter bars still show a general downward trend,
consistent with the ordering for 16–17 year-olds, but the rank ordering of countries is different. Quite
noticeably, the United States, with 23 percent of 26–30 year-olds achieving at least level-four proficiency,
moves from the bottom to the middle of the distribution.
Three patterns stand out in Figure 1. First, in nearly all countries sampled, the group aged 26–30
performs better than the group aged 16–17. Second, there is considerable variation across these countries
in the difference in test performance between the younger and older groups. In some countries—
Switzerland, the Netherlands, and Italy—performance is broadly the same; in others—Sweden, Belgium,
Germany, Norway, and the United States—the difference in performance between the older and younger
groups is striking. Third, the difference in performance between the older and younger groups is greater in
the United States than in any other country in the sample, except for Norway. For the remainder of the
paper, we refer to the performance differential between the older and younger groups in a country as the
country’s “age profile of literacy.”
Before we consider these facts in more depth, it is important to note that the International Adult
Literacy Survey data are cross-sectional. Because younger and older test takers were born at different
times, the age profiles of literacy that we estimate reflect both life-cycle changes in literacy—including any
6

gains from higher education, as well as potential cognitive gains or losses due to aging—and differences in
literacy across age groups due to cohort-specific differences in learning environments. In this symposium,
Deming and Dynarski document one source of different learning experiences across cohorts in the United
States: age of entry into first grade. They show that test performance at ages nine and thirteen was lower
among U.S. cohorts that, in first grade, had large fractions of “redshirted” students over age six. This
outcome might arise because greater shares of these cohorts had been exposed to one fewer year of formal
schooling by the time they were tested. Following this logic, if the younger U.S. IALS cohort started
school later than the older U.S. IALS cohort then, at age 17, we might expect the younger age cohort to
perform worse. The performance difference between the older and younger age groups measured in the
mid 1990s would then overstate the life-cycle gain in literacy, since it would reflect this gain plus the
difference in test scores at age 17 between the older and younger cohorts.
Because “redshirting” differences between the cohorts under study are small, they are unlikely to
have a large impact on the age profile of literacy in the United States estimated here. In particular, while
2.5 percent of American six year-olds were enrolled in kindergarten as opposed to grade one in 1974 (the
cohort of 26 year-olds in the 1994 IALS), this grew to only 5.6 percent in 1984 (the cohort of IALS 16
year-olds). Consistent with this claim—and consistent with the absence of other cohort-specific shocks to
the learning experience in the United States—differences between the cohorts under study in achievement
at age 17 as measured by the National Assessments of Educational Performance appear small. Certainly,
performance was not lower in the mid 1990s than it was in the early 1980s (Krueger, 1998), which suggests
we are not overestimating life-cycle literacy gains.
Of course, cross-sectional age profiles of literacy may reflect more than purely life-cycle gains for a
myriad of reasons, and these apply to the other countries in the analysis as well as to the United States.
Nevertheless, several pieces of evidence suggest that the differences in test performance across age groups
documented in Figure 1 are rooted in life-cycle changes rather than in cohort effects. First, Hanushek and
Zhang (2006) show that within-country associations between schooling and literacy are essentially the
7

same for 26–35 year-olds and 36–45 year-olds in the IALS, suggesting that the two cohorts attended
schools with comparable levels of productivity. While they do not include data on 16–17 year-olds, as we
do, it is notable that they only identify significantly different literacy “returns” to schooling for cohorts
(and countries) immediately affected by World War II. Second, we reestimated country-specific age
profiles of literacy while holding constant maternal education, a commonly used proxy for the home
learning environment. This made only a small quantitative difference and no qualitative difference to the
age profiles implied by Figure 1 and shown in subsequent figures.3 This finding also suggests that most of
the cross-sectional differences in test scores across age groups are driven by life-cycle differences rather
than cohort effects.
Finally, because several countries—Italy, Norway, Switzerland, and the United States—have data
in both the IALS and the ALL, we were able to examine the age profile of literacy within cohorts. For
example, in the United States, the within-cohort difference in literacy between 16–25 year-olds in the 1994
IALS and 25–34 year-olds in the 2003 ALL closely matches the across-cohort difference in literacy
between 16–25 and 25–34 year-olds in the 1994 IALS.4 This finding once again suggests that cohort
effects are small for the United States. In Norway and the Italian-speaking parts of Switzerland, both
surveyed in the 1998 IALS and the 2003 ALL, the within- and across-cohort differences in test
performance between 16–17 and 21–22 year-olds are also quite similar. For Italy (surveyed in the same
years) and the French and German-speaking regions of Switzerland (surveyed in 1994 and 2003), there is
3

Specifically, we estimated the following regression model:
testscoreic = α c + β c ages 26 _ 30 i + x ′i Γc + ε ic .
The variable testscoreic represents an indicator for whether individual i from country c achieved at least levelfour proficiency, ages26_30i is an indicator variable set to one if i is between the ages 26 and 30, xi is a
vector of indicators for maternal education, and εic is the regression error, which captures all other
determinants of individual test performance. The coefficient βc gives the expected difference in test scores
between 16–17 and 26–30 year-olds in country c, holding constant maternal education. Following
convention, we impute maternal education with age-by-country specific means where missing and include
in the vector x indicators set to one for each variable if imputed. In doing this, we allow the relationship
between test scores and maternal education to differ across countries, because some school systems may
do a better job of compensating for disadvantage than others (Schuetz, Ursprung, and Woessmann, 2005).
4
Age is reported in 10-year intervals in the ALL for the United States, precluding us from following only
the 16–17 year-olds in the 1994 IALS over time.
8

greater divergence between the within- and across-cohort differences in literacy. However, the divergence
is not systematically positive or negative. This suggests that our use of cross-sectional data adds noise but
not bias to our estimates of the true age profile of literacy.

Education and the Age Profile of Literacy

To understand how education shapes the age profile of literacy, individual-level longitudinal data
would be ideal: we could see how individuals’ scores change from their teen years through their twenties,
and how this evolution depends on whether the individual participates in higher education. However, our
cross-sectional data do not permit us to link individual-level literacy scores over time to identify whether
specific 16 or 17 year-olds will go on to higher education or to infer whether sampled 26 year-olds who
attended or graduated from college enjoyed larger literacy gains through the late teens and early 20s than
sampled 26 year-olds that did not attend or graduate from college. Thus, we structure our analysis to
consider how country-level differences in literacy rates over this part of the life cycle are associated with
country-level differences in average educational attainment across age groups.
Among the high-income countries in our sample, there is a great deal of heterogeneity in the age
profile of literacy from the teenage years into adulthood, as already shown. Perhaps surprisingly, these
country-specific age profiles are not strongly correlated with differences between the older and younger
age groups in the conventional measure of educational attainment—years of schooling. We show this in
Figure 2, which plots the difference in the fraction of 16–17 and 26–30 year-olds performing at level-four
or -five proficiency (from Figure 1) against the difference in years of education between the older and
younger age groups for each country in the sample. The least squares line fit to the data is upward sloping,
but quite flat, suggesting at best a weak effect of time spent in school after age 16 on skill levels.
However, Figure 2 does not take into consideration the diversity of postcompulsory programs in
which individuals might participate and which, potentially, have very different effects on skill acquisition.
9

For example, in countries where the gain in years of schooling after age 16 is relatively large, much of the
marginal education may be unproductive. In other countries, the average person might spend less time in
school after age 16, but this time might be spent in types of education that have larger effects on skill
acquisition.
To get a sense of this possibility, Table 1 reports graduation rates from various postcompulsory
programs and the years of full-time enrollment required to complete these programs. Because this type of
information is not available in the International Adult Literacy Survey, we use data from OECD Education
at a Glance from years chosen to correspond as closely as possible to the cohorts observed in the IALS.
The graduation rate is the ratio of program graduates to population at the expected age of graduation, as
reported by OECD (multiplied by 100). The expected duration of a program is the expected number of
years to degree if enrolled (based on midpoints of the ranges of expected graduation ages for each level of
study). In the first four columns of Table 1, we report on four types of programs: general upper secondary
(high school) programs, vocational or apprenticeship upper secondary programs, nonuniversity tertiary
(community college) programs, and university first degree (bachelor’s degree) programs. In the final
column, we combine these numbers to estimate the average total years of schooling acquired between ages
16–17 and 26–30. This total is equal to the sum, over all programs, of the product of the probability of
having graduated from the program and its expected duration. This measure thus excludes years of
schooling that do not lead to degrees and so underestimates years of schooling in the total population.
However, it is the most consistent estimate of program-specific years of schooling available to us for the
entire group of countries. As one would hope, this sum is highly correlated with the difference in years of
completed education between the older and younger age groups in the International Adult Literacy Survey
shown in Figure 2.
Table 1 shows that, in the mid 1990s, great variation existed across countries in how time was
allocated across educational programs after age 16. For example, average years of postcompulsory
education were the same in the United States, the Netherlands, and Sweden (3.2 years). In the United
10

States, the additional years were weighted toward tertiary education, particularly at the university firstdegree level. In the Netherlands and Sweden, by contrast, the additional years were weighted toward upper
secondary education, especially vocational programs. The U.S. advantage in years of university education
was attributable to the high fraction of the U.S. population that graduates from colleges and universities.
The U.S. population also had more expected years of university education (university graduation rate times
expected duration of study) and higher university graduation rates than countries such as Belgium,
Germany, Switzerland, Denmark, Finland, and Norway, all of which had more expected years of education
after age 16.
Of the educational programs described in Table 1, only university education is correlated with the
age profile of level-four or -five proficiency on the IALS assessment, and this correlation is very strong.
Figure 3, Panel A shows this correlation, plotting the difference in high-proficiency performance between
the younger and older age groups against expected years at university (now calculated as the fraction with a
university first degree in the IALS times expected duration of study, from OECD). The regression line
implies that on average, an additional year of university education increases the share of a cohort reaching
at least level-four proficiency as adults by roughly 14 percentage points. This effect is a large one, given
that in most countries in our sample, between 20 and 40 percent of the older age group is proficient at
level four (as shown in Figure 1). A one-year increase in average years of university education is, however,
an enormous change, representing an increase in university graduation rates of 25 percentage points
(assuming an expected duration of 4 years). Such an increase would more than double expected years of
university education in most of the countries listed in Table 1. As shown in Panel B, cross-country
variation in graduation rates appears to explain much of the cross-country variation in the age profile of
high-proficiency test performance; by comparison (graph not shown), very little of this variation is
explained by the duration of university degree programs reported in Table 1.
How should we interpret the correlations shown in Figure 3? If the points plotted on this graph
represented individuals in a given country, we would be very concerned about omitted variables and
11

selection. After all, teenagers who choose to obtain university degrees would likely have different literacy
gains between ages 16–17 and 26–30 whether they received a university degree or not. As a result, it would
be difficult to infer from simple correlations how the skills of the typical adult would evolve if policies
were introduced to encourage teenagers to attend and complete college.
A version of this concern also applies when looking across countries: Are countries with higher
university graduation rates those that would otherwise have larger gains in literacy from the teenage years
into adulthood? Low skill levels for teens within a country may cause two distinct outcomes: 1) marginal
returns to investment in human capital—whether through formal schooling or life experience—may be
relatively high, so the average skill level of a cohort may improve considerably between the teenage years
and adulthood even in the absence of university education, and 2) students may disproportionately obtain
university degrees to compensate for low skills upon graduating from high school. In either of these cases,
the correlation between the age profile of literacy and university graduation rates at the country level would
imply nothing per se about the role of university education in building skill. The data in Figure 1 point away
from these explanations: While a country’s literacy rate at ages 16–17 is positively correlated with its
literacy rate at ages 26–30, the average literacy of a country’s 16–17 year-olds does not predict the literacy
differential between its 16–17 and 26–30 year-olds. 5 Said differently, countries often considered to have
relatively low-performing secondary schools, such as the United States, are not systematically converging
with other countries.
These arguments, while suggestive, do not prove that our estimates are free of bias, and some
doubt remains as to whether policy-induced changes in university graduation would have effects of the
magnitude documented in Figure 3. It is important to understand whether the correlation shown above
between university education and the age profile of literacy should be interpreted as causal. Our estimates
are based on data from the 1990s, and since then, university graduation rates have risen dramatically in a
5

When we regress the age profile of literacy on the university graduation rate or expected time spent in
university studies and control for average performance of 16–17 year-olds, we obtain very similar slopes to
those shown in Figure 3.
12

number of countries. As seen in Table 2, the striking advantage the United States sustained over highincome countries in university graduation rates has largely been eliminated.6 By 2004, nearly all of the
countries considered in this table had higher rates of university graduation than the United States. If even a
portion of the observed relationship between university education and the age profile of literacy were
causal, these recent trends in university graduation rates could have dramatic effects on future literacy
patterns across countries. We next delve deeper into the question of interpretation, examining the sources
of variation across countries and over time in university graduation rates.

Determinants of the Demand for University Education

University graduation rates are equilibrium outcomes in the higher education market. We therefore
discuss possible explanations for why graduation rates vary across countries by first considering those on
the demand side and then in the next section considering factors on the supply side. To make this
discussion tractable, we limit our attention to the United States and high-income countries in Europe. For
completeness, we present statistics in the tables on all countries meeting the income criterion.
How secondary schools are organized has a first-order effect on demand for a university degree by
determining whether all individuals in a country can in principle receive a university education or whether

6

Graduation rates reported in Table 2 for 1970 through 1995 are approximated by taking the ratio of
university first degree (International Standard Classification of Education level 6) graduates to the
estimated country population aged 22 in that year. The number of graduates is from UNESCO at
<http://www.uis.unesco.org/pagesen/DBGTerIsced.asp>. The 22 year-old population in a country is
estimated with births in that country 22 years prior, taken from the Berkeley Mortality Database at
<http://www.demog.berkeley.edu/~bmd/>. This is the source of discrepancy between the university
graduation rates reported for 1995 in Table 1 and Table 2. The number of graduates needed to construct
this ratio is not available for 2000 and 2004. Graduation rates in these years are gross completion rates of
ISCED level 5a, first degree education at
<http://stats.uis.unesco.org/unesco/TableViewer/document.aspx?ReportId=136&IF_Language=eng&B
R_Topic=0>. In 2000 and 2004, U.S. graduation rates are approximated by taking the ratio of bachelor’s
degree recipients to the population of 22 year-olds, estimated as described above. The number of
bachelor’s degree recipients is reported in table 258 of the 2007 National Center for Education Statistics’s
Digest of Education Statistics at <http://nces.ed.gov/programs/digest/d07/tables/dt07_258.asp>.
13

access to universities will be restricted to a privileged few. Among students eligible to enroll in universities,
the enrollment decision then depends on the expected costs and benefits of a university degree. The costs
include both direct costs, like tuition, and indirect costs, like the opportunity cost of foregone earnings; the
benefits are both pecuniary and nonpecuniary. Cultural dimensions of postwar society, such as the
expansion of human rights and the related “education for all” ethos, may also affect university enrollment
decisions independently of these economic considerations (Schofer and Meyer, 2005).
Which of these demand-side factors have contributed to the variation in university graduation rates
documented in Table 2? Consider first the practice of school tracking, whereby students are assigned to
different types of education depending on perceived academic ability. Students assigned to the lower tracks
of these systems typically follow a curriculum that is oriented to the labor market and which might not
include the courses required for university enrollment. Even if these students could take the requisite
courses and become eligible for university after finishing their secondary schooling in a vocational track,
this process may appear too difficult, time-consuming, and costly to accomplish.
Cross-country data support the hypothesis that countries that track have lower university
graduation rates. As seen in Table 3, countries characterized by low university graduation rates, such as
Belgium, Germany, Italy, and the Netherlands, select students into tracks at relatively young ages (12, 10,
14, and 12 respectively) and have relatively small fractions of students graduating from the final stage of
secondary school with degrees that grant them access to higher education. Country-specific studies of
tracking reforms have generally reached much the same conclusion. For example, Aakvik, Salvanes, and
Vaage (2003) show that the expansion of comprehensive schooling in Norway increased the probability
that affected students attended university. Exploiting variation in the timing of its implementation across
municipalities, Meghir and Palme (2005) show that a Swedish reform allowing students to choose their
curricular tracks, rather than assigning them to tracks based on grades, increased average years of
education, especially among students with less-educated parents. However, studying a Romanian reform
that postponed tracking for two years, Malamud and Pop-Eleches (2007) find that the postponement of
14

tracking increased the proportion of students who were eligible to attend university, but did not increase
the proportion of students who completed university, in part because the supply of university slots—
directly controlled by the government—did not change.
These studies have several limitations. In Norway and Sweden, the reduction in tracking was
accompanied by an increase in compulsory schooling, making it difficult to attribute the gain in
educational attainment to the adoption of comprehensive schooling. Malamud and Pop-Eleches (2007), on
the other hand, do not examine the longer-run effects of tracking on university graduation rates, focusing
instead on two adjacent cohorts—one exposed to the old system and the other to the new regime. We
nevertheless surmise that eliminating tracking creates pressure from the rising number of university-eligible
students—pressure that grows stronger with every additional cohort that passes through the untracked
system. After some time, such pressure may persuade governments to expand the number of university
slots, an issue to which we speak in more detail below. This “delayed” demand story is consistent with the
recent increases in university graduation seen in the United Kingdom and the Scandinavian countries, all
of which had abolished tracking by the mid 1970s.
We find less empirical support for other demand-side explanations for the trends in university
graduation shown in Table 2. For example, consider the variation across countries and over time in returns
to education and local labor market conditions. Historically, returns to education in the United States were
not significantly larger than returns to education in European countries (Psacharopoulos, 1973;
Psacharopoulos and Patrinos, 2004). Returns to education for more recent years have also been estimated
to be broadly similar across European countries and do not appear to have increased sharply alongside
rising university graduation rates (Harmon, Walker, and Westergaard-Nielson, 2001). Over the 1970s and
1980s, youth labor markets were also relatively strong in the United States, suggesting that earnings
foregone due to school enrollment were relatively high in the United States during the period of U.S.

15

dominance in higher education.7 Although the recessions in parts of Europe in the early 1990s may explain
some of the growth in European university graduation rates, few studies have established a strong effect of
youth unemployment on university graduation rates (for example, Card and Lemieux, 2001).
Reasonable assumptions also suggest that family background contributed little either to the U.S.
advantage in university graduation in the 1970s and 1980s or to the increase in university graduation in
Europe in recent years. Using data from a sample of adoptees in the United States, Plug (2004) finds that
having a university-educated (adoptive) mother increases the probability of being university educated by
around five percentage points (off a base of 25 percent). Given this estimate and the 15 percentage point
university graduation rate advantage among U.S. parents in the 1970s and 1980s, family background can
explain only three percentage points of the cross-country difference in graduation rates among young
adults over these decades. Similarly, university graduation rates of parents rose around 3 percentage points
in Europe in recent years, suggesting that less than one percentage point of the recent European increases
in university completion can be explained by increases in parental education. If anything, this is likely to be
an upper bound, as the intergenerational transmission of education may be weaker in Europe than in the
United States (for example, Black, Devereux, and Salvanes, 2005).
Tuition, fees, and other out-of-pocket costs of university enrollment also cannot account for these
patterns because they traditionally have been highest in the United States. As shown in Table 4, a larger
share of U.S. students attends (costlier) private institutions of higher education, and those that attend
public institutions pay more in tuition. Although some of the costs of higher education are offset by
scholarships and grants, data from the mid 1990s confirm that public subsidies to households for
education per student enrolled are far higher in European countries (OCED, Education at a Glance: OECD
Indicators, 1997, table B3.1b). Higher out-of-pocket costs of college have been found to deter college
7

For example, using OECD data on the numbers of unemployed who claimed benefits among the group
aged 15–24 in the United States, we calculate that on average, over the period 1980–1989, this represented
8.2 percent of the relevant population. Across the European countries for which comparable data are
available (Finland, France, Germany, Italy, the Netherlands, Norway, Spain, and Sweden), the
corresponding figure was 10.5 percent. Population data are taken from the Berkeley Mortality Database at
<http://www.demog.berkeley.edu/~bmd/>.
16

completion in the United States (Dynarski, 2003; forthcoming), suggesting that with lower tuition and fees,
the historical U.S. graduation advantage would have been greater still. As we discuss below, the apparent
paradox of a positive correlation between fees and graduation rates across countries may be explained by
the fact that low prices in other countries have often been accompanied by shortages of university slots.
The historical U.S. advantage in university graduation may, however, be related to another
fundamental determinant of the cost of university education—the typical number of years required to
obtain a first degree. A degree that takes longer to achieve is less attractive if higher education displays
“sheepskin effects”—that is, if the returns to a degree that students quit halfway through are less than half
of the full return to the completed degree—and if students perceive longer degrees as riskier investments.
In several European countries, the first university degree takes more than five years to obtain, as shown in
Table 1, whereas in the United States it requires four years of full-time enrollment. This demand-side
factor cannot, however, explain recent increases in European graduation rates, as the time required to
obtain a degree has remained relatively constant in Europe.

Determinants of the Supply of University Education

The supply of university education is characterized by a level of government involvement that is
generally high, while varying widely across countries. Governments regulate the education that can be
supplied (like the fields that can be offered), subsidize the education that is supplied, and often supply
some of this education directly via universities that are government owned and government controlled. In
many cases, governments directly determine the number of students who may enroll. Governments also
set prices for many universities and determine standards for financial aid.
Among rich countries, the United States has the least government involvement in the provision of
higher education (as suggested in Table 4 by the relatively high faction of U.S. graduates from private
universities and the relatively high tuition paid by students to attend U.S. public colleges and universities).
17

Well over half of U.S. college and university revenues are derived from private sources—payments of
tuition and other fees. By contrast, in nearly all high-income European countries, higher education is
funded primarily by the government, either directly (through government purchases of educational
resources or grants to institutions) or indirectly (through the provision of grants or loans to students to
offset tuition and living costs). These cross-country patterns are quite stable over time.
The natural first question to ask is how have varying degrees of government involvement in the
provision of higher education historically affected university supply? Card and Lemieux (2001) and Bound
and Turner (2007) provide a useful framework for answering this question and estimating the elasticity of
university supply within the United States. They look at the impact of demographic-driven demand
shocks—that is, sharp changes in the size of the college-age cohort—on university graduation rates. If
supply changed to accommodate these shocks, the graduation rate would remain constant, and hence would
be unrelated to demand shifts measured by cohort size. If, however, the supply of university slots were
fixed, the number of graduates would remain unchanged across cohorts, but the graduation rate would fall as
cohort size increased and rise as cohort size fell. Using variation in cohort size across states and over time,
both studies find that a 10 percent increase in cohort size in the United States reduces the university
graduation rate by about 0.5 percentage points. This finding implies that the university sector expands to
accommodate some, but not all, of the shock to demand for higher education.8
We next provide a parallel estimate for European countries, so we can compare the responsiveness
of supply in Europe to that of the United States. We estimate the impact of cohort size on graduation rates
over the years 1970–2005 using data from the fourteen European countries listed in Tables 2–4 (Ireland,
the United Kingdom, the Continental European, and the Scandinavian countries). Data on graduation
rates cover the period 1970 to 2005.
8

To illustrate, suppose cohort size is steady at 200,000 and the graduation rate is around 20 percent
(40,000 graduates per cohort). Now suppose cohort size rises 10 percent, to 220,000. The estimate above
implies that the graduation rate for the new cohort will be 19.5 percent rather than 20 percent. Said
differently, only 42,900 individuals in the larger cohort will graduate, instead of the 44,000 that would have
been expected to graduate with maintenance of a constant graduation rate, or with full accommodation of
the demand shock.
18

We ran an ordinary least squares regression with university graduation rates by country and by year
as the dependent variable. The key explanatory variable was the natural log of the population 22 years of
age in that country during that year. We also included a constant term and a full set of country- and yearspecific intercept terms. The country intercept accounts for the fact that some countries have persistently
higher rates of college completion, while the year-specific intercept captures trends in university graduation
rates that would have been shared by all of these countries in the absence of changes in cohort size. 9 Our
estimate of the coefficient on the population term is around –0.098 (with a standard error of 0.044). This
estimate implies that a 10 percent increase in cohort size is associated with about a one percentage point
decrease in university graduation rates—roughly double the magnitude of the effect found for the United
States by Card and Lemieux (2001) and Bound and Turner (2007). This finding suggests that the supply of
university slots may be more flexible in the United States than in Europe.
Why might the supply of university slots be more flexible in the United States? Limited and
decentralized public sector involvement in higher education could generate more flexible supply-side
responses, because institutions that generate larger shares of their revenue from tuition and other private
sources can adjust revenues more quickly than institutions relying more heavily on government funding.
(Recall the Malamud and Pop-Eleches (2007) finding on Romania.) Indeed, looking across university types
9

We estimate the following regression model:
GraduationRate ct = α + β ln ( pop 22 ct ) + λc + γ t + ε ct .
In 1970, 1975, and 1980–1998, the dependent variable, Graduation Ratect is calculated as the number of
graduates in country c in year t (from UNESCO at
<http://www.uis.unesco.org/pagesen/DBGTerIsced.asp>) divided by the size of the population aged 22
in year t in country c (estimated as described below). From 1999–2005, Graduation Ratect is reported by
UNESCO (at
<http://stats.uis.unesco.org/unesco/TableViewer/document.aspx?ReportId=136&IF_Language=eng&B
R_Topic=0>). The coefficient of interest is that on the natural log of the number of births 22 years prior
to year t in country c, ln(pop22ct), taken from the Berkeley Mortality Database (at
<http://www.demog.berkeley.edu/~bmd/>). Because this is only an approximation of the number of 22
year-olds in country c in year t, and because not all university graduates are 22 years old, the estimated
effect of cohort size is likely a lower bound on its true effect. The parameters λc and γt represent countryand year-specific intercepts, respectively. To account for differences in the definition of the graduation rate
before and after 1998, we also interact the country fixed effects with an indicator set to one for years 1999
and later. In the estimates reported, we use data on the countries listed in the text in all available years
(1970, 1975, 1980–2005); the total number of observations is 266.
19

within the United States, Bound and Turner (2007) estimate that changes in cohort size have almost no
impact on enrollment rates into private colleges and universities in the United States. In other words,
private-sector supply adjusts immediately to accommodate demand changes. Bound and Turner also find
that public community colleges are quite sensitive in their supply responses. While these colleges do rely
on government funding, access is the central part of their mission, and they expand supply to serve more
students even if it is with significantly fewer resources per student. Only the presence of public universities
generates a negative relationship between cohort size and university enrollment rates in the United States.
Because the European university market is dominated by public universities, this story is consistent with
our results.
In addition, the competition generated by a large private sector and a decentralized public sector
could lead universities to supply education to lower-ability students or to provide the types of education
(for example, short-duration courses in more applied fields) that lower-ability students might prefer,
thereby removing an implicit cap on the number of university slots available. More flexible government
regulations in the United States, such as those allowing students to transfer to four-year universities after
completing courses in two-year colleges (Kane and Rouse, 1999), or allowing universities to determine
permissible courses of study without government approval, likely matter as well.
The relative flexibility of the U.S. supply side, which may be due in part to the decentralized and
deregulated U.S. higher education sector, thus appears to contribute to the historical U.S. graduation rate
advantage. This argument does not imply that a centralized and largely public higher education sector
cannot expand access. Just as some European countries moved from selective to comprehensive
secondary education by the 1970s, many have recently shifted from “elite” higher education to “mass”
higher education, which Trow (1974) characterized as serving at least 15 percent of the “age grade” by
increasing access to both elite university programs and “popular nonelite institutions.” This transition
appears to have occurred because European governments have increased supply—not continuously and
flexibly, but through discrete policy responses to long-standing shortages (for example, Moscati and
20

Rostan, 2000; Greenaway and Haynes, 2000). Combined with declines in the size of college-aged
population brought about by the drop in fertility in Europe in prior decades (see Feyrer, Sacerdote, and
Stern in this symposium), such policy shifts have almost certainly been at the heart of the dramatic
increases in university graduation rates shown in Table 2.

Conclusions

Literacy gains into adulthood vary across countries, and these gains are strongly correlated with
participation in higher education. A country’s university graduation rate is tied to how secondary education
is organized and how higher education is funded. We do not want to claim that all of the correlation
between university graduation and the age profile of literacy into adulthood reflects the causal effects of
university graduation. After all, educational systems are not randomly assigned to countries. Instead, they
reflect the preferences of a country’s citizens and therefore may be correlated with other institutions, such
as labor market regulation, that shape the incentives to acquire skills after compulsory schooling has
ended.
Bearing this limitation in mind, we reach some tentative conclusions. First, the historical advantage
that the United States has enjoyed in college graduation appears to be an important reason why, between
the teen years and the late 20s, American literacy rates appear to catch up with those in other high-income
countries. The share of native-born Americans in the IALS that were able to make high-level inferences
was nearly five times higher among those in their late twenties (23 percent) than among those in their teens
(4.7 percent). Taken at face value, our estimates suggest that much of this difference was driven by the
relatively high rate of university graduation in the United States at the time. If the university graduation
rate in the United States had been 15 percent instead of 30 percent—roughly the average among the
European countries in our data at this time—the literacy difference for Americans in these age groups
would have been roughly half as large, and the United States would have continued to rank near the
21

bottom of the test-score distribution among individuals in their late twenties. Second, and by the same
token, the recent convergence of other high-income countries’ university graduation rates to that of the
United States could push the test scores for U.S. young adults down the international distribution.
Just as the adoption of mass secondary education in Europe in the postwar period shined a light
on the low output of U.S. elementary and secondary schools (Goldin, 2003), this convergence might
increase the performance pressure on U.S. colleges and universities. Examples of such pressure include
attempts by individual institutions and states to test students and hold colleges and universities
“accountable,” as documented and encouraged by a commission headed by Secretary of Education
Margaret Spellings (U.S. Department of Education, 2006). Some other countries have also moved in this
direction, as Rezende (2007) documents in the case of Brazil. If more do, and if data on testing outcomes
were collected and disseminated, it would permit more systematic and more reliable estimation of the
value-added of higher education.

22

References
Aakvik, Arild, Kjell G. Salvanes, and Kjell Vaage. 2003. “Measuring Heterogeneity in the Returns
to Education in Norway Using Educational Reform.” IZA Discussion Paper 815, Institute for the Study of
Labor, Bonn.
Baker, David P. 1997. “Surviving TIMSS: Or, Everything You Blissfully Forgot about International
Comparisons.” Phi Delta Kappan, 78(4): 295–301.
Black, Sandra, Paul Devereux, and Kjell Salvanes. 2005. “Why the Apple Doesn’t Fall Far:
Understanding the Intergenerational Transmission of Education.” American Economic Review, 95(1): 437–49.
Blau, Francine D., and Lawrence M. Kahn. 2005. “Do Cognitive Test Scores Explain Higher U.S.
Wage Inequality?” The Review of Economics and Statistics, 87(1): 184–93.
Bound, John, and Sarah Turner. 2007. “Cohort Crowding: How Resources Affect Collegiate
Attainment.” Journal of Public Economics, 91(5–6): 877–99.
Brown, Georgina, and John Micklewright. 2004. “Using International Surveys of Achievement and
Literacy: A View from the Outside.” UNESCO Institute for Statistics Working Paper.
http://eprints.soton.ac.uk/34630/.
Card, David, and Thomas Lemieux. 2001. “Dropout and Enrollment Trends in the Post-War
Period: What Went Wrong in the 1970s?” In An Economic Analysis of Risky Behavior Among Youth, ed. J.
Gruber, 439–82. Chicago: University of Chicago Press for NBER.
Devroye, Dan, and Richard Freeman. 2001. “Does Inequality in Skills Explain Inequality in
Earnings across Advanced Countries?” NBER Working Paper 8140.
Dillon, Sam. 2007. “Study Compares States’ Math and Science Scores with Other Countries.’” The
New York Times, November 14.
Dynarski, Susan M. 2003. “Does Aid Matter? Measuring the Effect of Student Aid on College
Attendance and Completion.” The American Economic Review, 93(1): 279–88.
Dynarski, Susan M. Forthcoming. “Building the Stock of College-Educated Labor.” The Journal of
Human Resources.
Fuchs, Thomas, and Ludger Woessmann. 2007. “What Accounts for International Differences in
Student Performance? A Re-examination using PISA Data.” Empirical Economics, 32(2): 433–64.
Goldin, Claudia. 2001. “The Human-Capital Century and American Leadership: Virtues of the Past.”
The Journal of Economic History, 61(2): 263–92.
Goldin, Claudia. 2003. “American Leadership in the Human Capital Century: Have the Virtues of the
Past Become the Vices of the Present?” Education Next, 3(1): 73–78.

23

Greenaway, David, and Michelle Haynes. 2000. Funding Universities to Meet National and International
Challenges. School of Economics Policy Report, University of Nottingham. Published electronically July 7,
2000, at http://www.nottingham.ac.uk/economics/funding/.
Hanushek, Eric A., and Ludger Woessmann. 2006. “Does Educational Tracking Affect
Performance and Inequality? Differences-in-Differences Evidence across Countries.” Economic Journal,
116(510): C63-C76
Hanushek, Eric A., and Ludger Woessmann. 2007. “The Role of School Improvement in
Economic Development.” NBER Working Paper 12832.
Hanushek, Eric A., and Lei Zhang. 2006. “Quality-Consistent Estimates of International Returns
to Skill.” NBER Working Paper 12664.
Harmon, Colm, Ian Walker, and Niels Westergaard-Nielson, eds. 2001. Education and Earning in
Europe. UK: Edward Elgar.
Kane, Thomas J., and Cecilia Elena Rouse. 1999. “The Community College: Educating Students at
the Margin between College and Work.” The Journal of Economic Perspectives, 13(1): 63–84.
Krueger, Alan. 1998. “Reassessing the View that American Schools are Broken.” Economic Policy
Review, Federal Reserve Bank of New York, March, 4(1): 29–43.
Malamud, Ofer, and Cristian Pop-Eleches. 2007. “The Effect of Postponing Tracking on Access
to Higher Education.” http://www.columbia.edu/~cp2124/papers/tracking_041307.pdf.
Mayda, Anna Maria. 2006. “Who is against Immigration? A Cross-Country Investigation of
Individual Attitudes toward Immigrants.” Review of Economics and Statistics, 88(3): 510–30.
Meghir, Costas, and Mårten Palme. 2005. “Educational Reform, Ability, and Family Background.”
The American Economic Review, 95(1): 414–24.
Moscati, Roberto, and Michele Rostan. 2000. “Higher Education and Graduate Employment in
Italy.” European Journal of Education, 35(2): 201–209.
Murtin, Fabrice, and Martina Viarengo. 2007. “The Convergence Process of Compulsory
Schooling in Western Europe: 1950–2000.” PSE Working Paper 2007-18, Paris School of Economics.
National Center for Education Statistics, Institute of Education Sciences, U.S. Department of
Education. 2007. Digest of Education Statistics. http://nces.ed.gov/programs/digest/2007menu_tables.asp.
Oreopoulos, Philip. Forthcoming. “Would More Compulsory Schooling Help Disadvantaged Youth?
Evidence from Recent Changes to School-Leaving Laws.” In An Economic Framework for Understanding and
Assisting Disadvantaged Youth, ed. Jonathan Gruber, chap. 4. University of Chicago Press.
OECD. Various years. Education at a Glance: OECD Indicators. Paris: Organisation for Economic Cooperation and Development.
OECD. 1990. Education in OECD Countries 1987–88: A Compendium of Statistical Information. Paris:
Organisation for Economic Co-operation and Development.
24

OECD. 1993. Education in OECD Countries: A Compendium of Statistical Information: 1988–89 and 1989–
90. Paris: Organisation for Economic Co-operation and Development.
OECD. 1995. Literacy, Economy and Society, Results of the First International Adult Survey. Paris and Ottawa:
Organisation for Economic Co-operation and Development, and Statistics Canada.
OECD. 2005. Learning a Living: First Results of the Adult Literacy and Life Skills Survey. Paris: Organisation
for Economic Co-operation and Development.
Plug, Erik. 2004. “Estimating the Effect of Mother's Schooling on Children’s Schooling Using a
Sample of Adoptees.” American Economic Review, 94(1): 358–68.
Psacharopoulos, George. 1973. Returns to Education: An International Comparison. Elsevier: Amsterdam.
Psacharopoulos, George, and Harry Anthony Patrinos. 2004. “Returns to Investment in
Education: A Further Update.” Education Economics, 12(2): 111–34.
Rezende, Marcelo. 2007. “The Effects of Accountability on Higher Education.” Available at SSRN:
http://ssrn.com/abstract=976479.
Schofer, Evan, and John W. Meyer. 2005. “The World-Wide Expansion of Higher Education in the
Twentieth Century.” American Sociological Review, 70(6): 898–920.
Schuetz, Gabriela, Heinrich W. Ursprung, and Ludger Woessmann. 2005. “Education Policy
and Equality of Opportunity.” CESifo Working Paper 1518.
Trow, Martin. 1974. “Problems in the Transition from Elite to Mass Higher Education.” In Policies
for Higher Education: General Report. (General Report on the Conference on Future Structures of PostSecondary Education, 1973), pp. 51–101. Paris: OECD.
U.S. Department of Education. 2006. A Test of Leadership: Charting the Future of U.S. Higher Education.
Washington, D.C.
Woessmann, Ludger. 2003. “Schooling Resources, Educational Institutions, and Student
Performance: The International Evidence.” Oxford Bulletin of Economics and Statistics, 65(2): 117–70.

25

0

Share at Level 4 or 5 Proficiency
.1
.2
.3
.4

.5

Figure 1
Performance on the IALS Test by Age and Country

SWE FIN CHE NLD NOR BEL DEU DEN GBR IRL NZL ITA USA
Ages 16-17

Ages 26-30

Source: International Adult Literacy Survey (IALS). The IALS was conducted in 1994, 1996, and 1998 in conjunction with
national household surveys.
Notes: Figure plots shares of the population for whom average performance across the three IALS test domains exceeds the
test-score threshold for level-four proficiency. See text for more details. SWE=Sweden, FIN=Finland, CHE=Switzerland,
NLD=Netherlands, NOR=Norway, BEL=Belgium, DEU=Germany, DNK=Denmark, GBR=United Kingdom, IRL=Ireland,
NZL=New Zealand, ITA=Italy, and USA=United States.

26

Difference in Level 4 or 5 Proficiency
0
.1
.2

.3

Figure 2
Differences in Test Scores and Years of Schooling
16-17 vs. 26-30 Year-Olds

Norway
USA

Germany
Sweden
Belgium
UK
New Zealand
Ireland

Denmark
Finland
Netherlands

Italy

-.1

Switzerland

0

1

2
3
Difference in Years of Schooling

4

5

Source: International Adult Literacy Survey (IALS).
Notes: The variable on the vertical axis is the difference between 26-30 year-olds and 16-17 year-olds in the estimated
population share achieving at least level-four proficiency on the IALS test. The variable on the horizontal axis is the difference
in estimated average years of completed schooling between the two age groups. The least squares fitted line has a slope of
0.0048 (standard error=0.0106) and an R-squared of 0.0068. See text for more details.

27

Figure 3
Differences in Test Scores and University Education
16-17 vs. 26-30 Year-Olds

Difference in Level 4 or 5 Proficiency
0
.1
.2

.3

(A) Education: Expected Years of University-Level Education

Norway
USA
Germany

Sweden
Belgium
UK

Denmark

New Zealand
Ireland

Finland
Netherlands

Italy

-.1

Switzerland

.2

.4

.6
.8
1
Expected Difference in Years at University

1.2

1.4

Difference in Level 4 or 5 Proficiency
0
.1
.2

.3

(B) Education: Share with University 1st Degree

Norway
Germany
Sweden
Belgium
UK
New Zealand
Ireland

Italy

USA

Denmark
Finland
Netherlands

-.1

Switzerland

.05

.1
.15
.2
.25
Difference in Share with University 1st Degree

.3

Source: International Adult Literacy Survey (IALS). See also Table 1.
Notes: The variable on the vertical axis is the difference between 26-30 year-olds and 16-17 year-olds in the estimated
population share achieving at least level-four proficiency on the IALS test. In Panel (A), the variable on the horizontal axis is
the product of the difference between the two age groups in the university first degree graduation rate (from the IALS) and the
theoretical time to degree (from Table 1). The least squares fitted line has a slope of 0.137 (standard error=0.056) and an Rsquared of 0.315. In Panel (B), the variable on the horizontal axis is the university first-degree graduation rate in the IALS. The
least squares fitted line has a slope of 0.721 (standard error=0.304) and an R-squared of 0.378. See text for more details.

28

Table 1
Graduation Rates and Expected Duration of Studies after Age 16 for OECD Countries
Graduation Rate [Expected Duration of Studies after Age 16 ]
Upper secondary (1991)
Non-university
1st university
Vocational or
tertiary (1995)
degree (1995)
General
apprenticeship
(1)
(2)
(3)
(4)
United States

Other English-speaking
Ireland
New Zealand
United Kingdom
Continental European
Belgium
Germany
Italy
Netherlands
Switzerland
Scandinavian
Denmark
Finland
Norway
Sweden

Expected years of
education after age 16
(5)

73.9b
[2]

c
c

22
[2]

32
[4]

3.2

69.9
[2]
35.5
[2]
58.5
[2]

8.4
[2]
27.6a
[2]
15.9
[2]

14
[2]
17
[3]
17
[2]

20
[4]
21
[3.4]
31
[3]

2.7

34.9a
[2]
24.2
[3]
18.2
[3]
29.2
[3]
17.2
[4]

41.2a
[2]
93.1
[3]
32.6
[3]
53.0
[3]
70.4
[4]

28
[4]
12
[2]
7
[2]
c
c
23
[6]

16d
[5]
16
[7]
12
[4]
19
[4]
9
[6]

3.4

32.0
[4]
46.8
[3]
39.6
[3]
19.8
[3]

68.4
[4]
78.1
[3]
49.7
[3]
60.4
[3]

8
[4]
22
[2.5]
48
[1.5]
9
[2]

21
[6]
21
[5.5]
22
[4.2]
16
[3.8]

5.6

2.5
2.8

4.9
2.1
3.2
5.4

5.5
4.3
3.2

Sources: OECD Education at a Glance (1993, 1995, 1997, 1998).
Notes: Graduation rates are ratios of public and private graduates to population at the expected age of graduation,
multiplied by 100. Expected duration of studies is calculated using midpoints of theoretical graduation age ranges by
level of study. Expected years of education after age 16 are obtained first by calculating theoretical
duration*(graduation rate/100) at each level of study, then summing across the levels.
a Data for 1992.
b Overall upper secondary graduation rate.
c Program does not exist.
d Data for 1996.

29

Table 2
University Graduation as a Share of Age-Appropriate Population across Countries: 1970-2004
1970

1980

1990

1995

2000

2004

United States

0.24

0.22

0.30

0.37

0.37

0.39

Other English-speaking
Australia
Ireland
New Zealand
United Kingdom

0.16
m
0.08
0.07

0.16
m
0.10
0.13

0.24
m
0.15
0.19

0.39
m
0.24
0.36

0.50
0.29
0.42
0.39

0.48
0.39
0.50
0.39

Continental European
Austria
Belgium
France
Germany
Italy
Netherlands
Spain
Switzerland

0.04
m
m
m
0.04
0.04
m
0.04

0.05
m
0.06
0.11
0.07
0.14
0.11
0.07

0.08
0.15
0.08
0.18
0.08
0.19
0.18
0.08

0.12
m
0.23
0.24
0.11
0.31
0.24
0.11

0.16
m
0.38
0.33
0.23
0.34
0.33
0.23

0.21
m
0.46
0.36
0.24
0.65
0.36
0.24

Scandinavian
Denmark
Finland
Norway
Sweden

0.04
0.07
0.02
0.14

0.14
0.13
m
0.15

0.19
0.17
0.27
0.14

0.31
0.26
0.25
0.17

0.34
0.44
0.40
0.33

0.65
0.53
0.49
0.48

Other OECD
Iceland
Japan

0.04
0.09

m
m

m
0.20

0.24
0.24

0.34
0.34

0.53
0.37

Sources: From 1970 to 1995, data on university graduates come from UNESCO. University graduates are defined as
those earning a qualification at International Standard Classification of Education (1970s version) level 6 or above. For
2000 and 2004, data on university graduates for the U.S. come from the Digest of Education Statistics; university graduates
are those receiving a bachelor's degree. Data on the population of 22 year-olds used to normalize these graduation
figures are taken from the Berkeley Mortality Database. For 2000 and 2004, the graduation rate for other countries is
reported by UNESCO; university graduation is the gross completion rate at ISCED (1997 version) level 5a, first degree.
See text for references.
Notes: Countries listed are those OECD countries that satisfy the income criterion for the above analysis (real GDP per
capita>$20,000 in 2002). Countries in italics were not included in the IALS analysis. From 1970 to 1995 (and for the
U.S. in 2000 and 2004), graduation rates are calculated as the number of university graduates divided by the population
aged 22. In some cases, reported years refer to the year before or the year after (e.g. for Australia, the figures reported
for 1980 and 2004 refer to 1981 and 2003). The others are France (1980=1981, 1990=1991), Netherlands (1995=1994),
Denmark (2000=2001), Iceland (1995=1996) and Japan (1990=1989, 2000=2001).
m Data missing.

30

Table 3
Prevalence of Selective versus Comprehensive Secondary Schooling, by Country

Age when first selected,
2003
(1)

Share of population aged
Share of population
graduating from final stage 18-19 with secondary
of secondary education degrees that allow access to
(upper secondary), 2005 higher education, 1987
(2)
(3)

United States

16

76

74.6

Other English-speaking
Australia
Ireland
New Zealand
United Kingdom

16
15
16
m

70
89
72
86

51.9
76.6a
33.5
36.6

Continental European
Austria
Belgium
France
Germany
Italy
Netherlands
Spain
Switzerland

10
12
15
10
14
12
16
15

16
60
m
38
74
58
44
26

25.9
51.0
34.0
28.4
35.7
52.7
35.3
m

Scandinavian
Denmark
Finland
Norway
Sweden

16
16
16
16

59
95b
61
77

71.3
43.6
65.1a
75.7

Other OECD
Iceland
Japan

16
15

55
69

m
87.8

Sources: Education in OECD Countries (1990, 1993), OECD Education at a Glance (2005, 2007)
Notes: Countries listed are those OECD countries that satisfy the income criterion for the above
analysis (real GDP per capita>$20,000 in 2002). Countries in italics were not included in the IALS
analysis.
a Data from 1988.
m Data missing.

31

Table 4
Costs of Enrolling in Public Higher Education, by Country (2003-2004)

% of full-time students
Average annual tuition % of students receiving
enrolled in public
scholarships/grants
higher education
fees ($)
(1)
(2)
(3)
United States

69.2

4587

77

Other English-speaking
Australia
Ireland
New Zealand
United Kingdom

99.9
m
98.1
100

3781
m
2538
1794

27.2
m
31
m

Continental European
Austria
Belgium
France
Germany
Italy
Netherlands
Spain
Switzerland

90
48.8
90
m
94
100
87.4
95

853
540
156 to 462
m
983
1565
668 to 935
566 to 1132

m
22.5
24.6
m
18.9
85
31
12.8

Scandinavian
Denmark
Finland
Norway
Sweden

99.7
87
88
93.3

none
none
none
none

n/a
n/a
n/a
n/a

Other OECD
Iceland
Japan a

87
24.9

none
3747

n/a
0

EducationatataaGlance
Glance (2006)
(2006)
Source:
OECDEducation
Source: OECD
Notes: Countries listed are those OECD countries that satisfy the income criterion for the
above analysis (real GDP per capita>$20,000 in 2002). Countries in italics were not included
in the IALS analysis.
a Annual average tuition in private higher education in Japan: 4767-25468; a negligible number
of students receive scholarships/grants to cover these costs.
m Data missing.

32

