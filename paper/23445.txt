NBER WORKING PAPER SERIES

DOES CHOICE INCREASE INFORMATION? EVIDENCE FROM ONLINE SCHOOL
SEARCH BEHAVIOR
Michael F. Lovenheim
Patrick Walsh
Working Paper 23445
http://www.nber.org/papers/w23445

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2017

We gratefully acknowledge funding for this research from the Cornell Institute for Social Science
and St. Michael’s College. We thank participants at the 2014 CESifo Area Conference on
Economics of Education, the Conference on Competition and Subnational Governments at the
University of Tennessee and the 2015 Association for Education Finance and Policy Annual
Meeting. We also thank Leigh Wedenoja for excellent research assistance. The views expressed
herein are those of the authors and do not necessarily reflect the views of the National Bureau of
Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2017 by Michael F. Lovenheim and Patrick Walsh. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

Does Choice Increase Information? Evidence from Online School Search Behavior
Michael F. Lovenheim and Patrick Walsh
NBER Working Paper No. 23445
May 2017
JEL No. H75,I20,I28
ABSTRACT
We examine whether changes in the local school choice environment affect the amount of
information parents collect about local school quality, using data on over 100 million searches
from greatschools.org. We link monthly data on search frequency in local “Search Units” to
information on changes in open enrollment policies, tuition vouchers, charitable scholarship tax
credits, tuition tax credits, local choice opportunities driven by No Child Left Behind sanctions
and charter school penetration. Our results indicate that expansions in school choice rules and
opportunities in a given area have large, positive effects on the frequency of searches done for
schools in that area. These estimates suggest that the information parents have about local schools
is endogenous to the choice environment they face, and that parental information depends not just
on the availability of data, but also the incentive to seek and use it.

Michael F. Lovenheim
Department of Policy Analysis and Management
Cornell University
102 Martha Van Rensselaer Hall
Ithaca, NY 14853
and NBER
mfl55@cornell.edu
Patrick Walsh
Department of Economics
St. Michael's College
One Winooski Park
Colchester, VT 05439
pwalsh@smcvt.edu

1. Introduction
School choice policies, which allow students to attend local schools other than the ones to which
they are zoned, have grown considerably in popularity in the past several decades. For example,
from 1993 to 2007, the percent of students attending their assigned public school dropped from
80 to 73 (Grady, Bielick and Auld 2010). This shift is driven by the increasing prevalence of
charter schools, intra- and inter-district school choice programs, and private school attendance
that is supported by tuition voucher programs and tax credits. Furthermore, the 2001 No Child
Left Behind Act included provisions that students in “failing” schools that receive Title I funds
should be allowed to attend a nearby non-failing school of their choosing. School choice thus has
become a prevalent feature of American K-12 education that has served to reduce the historic
link between where a family lives and the schools their children attend.
Concurrent with the rise in school choice policies has been a dramatic increase in the
information available to parents about local schools. A combination of publicly-released school
“report cards,” state standardized test results, publicly-released value-added data and online
information aggregators make detailed school quality information easier to access today than
ever before. A core reason behind providing such information to parents is to hold schools
accountable for their performance. Information about school performance can lead parents to put
pressure on schools to improve test scores, or it can induce parents to switch schools, thereby
increasing competition.1 How much parents know about local school quality also can play a
central role in driving school choice effects: heterogeneity in parental knowledge about
schooling options may explain some of the wide variation in results from existing school choice
research.2 Consistent with this hypothesis, some prior work has found that providing choice-

1

Prior research has found that competitive pressures due to schools accountability policies have short- and long-run
positive effects on student outcomes (Rockoff and Turner 2010; Rouse et al. 2007; Deming et al. 2013). School
accountability policies more broadly have been shown to increase student achievement as well (Carnoy and Loeb
2002; Hanushek and Raymond 2005).
2
Existing estimates of the effect of school choice on student outcomes are ambiguous. A large body of work
examines the effect of open enrollment policies (Hastings, Kane and Staiger 2006; Deming et al. 2014; Cullen,
Jacob and Levitt 2006) as well as charter schools (Abdulkadiroğlu et al. 2011; Dobbie and Fryer 2011; Angrist,

1

eligible families with simple and salient information about local school quality leads them to
select higher-quality schools that increase student outcomes (Hastings and Weinstein 2008).
Parental knowledge about local school quality is a core input into the market forces that
drive competition across schools as well as into the effects of school choice policies. It therefore
is important to understand how parents obtain school quality information and what policymakers
can do to facilitate the dissemination of such information. However, little prior research has
examined how much information parents have about local schooling options and the tools that
can be used to expand their knowledge about school quality.
In this paper, we focus on the relationship between parental knowledge about school
quality and the school choice environment. We provide new evidence on how information
acquisition responds to increases in the demand for information driven by school choice policies
in an environment in which school quality data are free and easy to access. Our analysis
constitutes the first direct assessment of how the demand for school quality information responds
to the choice environment by linking unique data from greatschools.org –the largest online
school quality search engine – to variation in the local school choice policies available to
families.
The impact of school choice policies on whether and how parents search for school
quality information is a parameter of interest for three reasons. First, part of the benefits of
school choice may be due to more accurate parental decision-making, driven by the better
information on school quality parents collect in response to choice opportunities. School choice
policies can increase the demand for information, which leads to a more-informed school
selection and thus, potentially, higher student achievement. This may be particularly true for
low-SES families, who face constraints in their ability to move to areas with higher-quality

Pathak and Walters 2013; Bettinger 2005; Bifulco and Ladd 2006; Hanushek et al. 2007; Sass 2006) on student
achievement. These papers do not reach consistent conclusions. There also is some evidence that charter schools
increase students’ behavioral outcomes even when they do not increase test scores (Imberman 2011). A similar
inconsistency exists across studies examining the effect of private school tuition vouchers on student academic
outcomes (Rouse 1998; Howell, Wolf and Campbell 2002; Krueger and Zhu 2004).

2

schools and as a result face low returns to accumulating information absent school choice.
Examining how the demand for school quality information responds to changes in the local
choice environment allows us to provide direct evidence on this core mechanism through which
school choice can influence student achievement.
Second, our results help explain why many parents still appear to have incomplete
information about schools even though such information is ubiquitous. Our estimates
demonstrate that even in an environment in which the cost of information is uniformly low,
substantial disparities in use of that information exist. The reason for this is that information
must not only be easily accessible, but parents also must have an incentive to seek it out. Those
with very limited choice sets may, quite rationally, not access information that is available to
them. The resulting lack of information among many families can render accountability policies
and the vast amount of publicly-available school quality data less effective.3 Thus, making
school quality information publicly available may not be sufficient to undo information
asymmetries, as parents also may need to be induced to collect such information. School choice
policies can provide such incentives, and this paper is the first in the literature to examine
whether they have this effect.
Third, our estimates highlight the potential role for the Internet in lowering informational
costs to families. Hastings and Weinstein (2008) show that when parents are given information
about local schooling quality, it affects their choice of schools. Our results indicate that
providing this type of information online and by a third party induces families to collect the
information themselves when combined with school choice policies. From a policy perspective,
this is an important finding because it suggests online school quality information can enhance the
effectiveness of school choice policies by facilitating information acquisition. Policymakers

3

Prior research has shown that the public release of school quality information has either no effect or a very shortrun effect on property values (Figlio and Lucas 2006; Imberman and Lovenheim 2016; Fiva and Kirkeboen 2011).
These findings are consistent with parents facing constraints in their ability to act on school quality information in
the absence of school choice.

3

could explicitly pair search policies with references to the type of online resource we study to
increase the impact of these policies at a very low cost.
Until now, the lack of data on parental information-gathering patterns has precluded
empirical study of how parents acquire knowledge about the quality of local schools and how
this varies with school choice opportunities. To fill this gap, we use online searching behavior
from GreatSchools Inc., a nonprofit organization whose website provides comparison
information and reviews on all U.S. K-12 schools. The website provides simple and
straightforward information on school test scores, user reviews, and school demographics in a
manner that enables comparisons across schools.
We obtained all search terms entered into their search engine between January 1, 2010
and October 31, 2013, comprising over 100 million individual searches. These data allow us to
measure how frequently searches are performed for schools in each city and in counties outside
of cities that we can identify in the data. We combine the Greatschools search data with statelevel measures of school choice policies that relate to open enrollment, private school vouchers,
charitable scholarship tax credits, and tuition tax credits. We also calculate city- and county-level
proportions of the schools subject to choice under the NCLB provisions for Title I schools for the
39 states that constitute our analysis sample.4 As well, we examine whether online information
searches respond to the entry of charter schools in an area. Together, these variables provide
comprehensive information about the choice environment people face in different areas of the
country at any given time.
We estimate difference-in-difference models in a parametric event study framework that
relate changes in choice policies and opportunities at the state or local level to changes in online
search behavior, allowing for linear trends before and after a change in state school choice
regulations. Our results indicate that parent knowledge about school quality is responsive to

4

As discussed in Section 3, NCLB choice status was only available in our analysis period for 39 states, so we
restrict our analysis to these states.

4

many aspects of the choice environment they face. In particular, we find consistent evidence
across models and different parameterizations of laws that search frequency increases due to
increases in the prevalence of NCLB-based choice, intra- and inter-district open enrollment and
private school tuition vouchers. Our baseline results point to either a small positive or a negative
relationship between tuition tax credits or charitable scholarship tax credits and search
frequency, however.
We additionally examine how charter school entry and exit relates to online school
quality search behavior. There is a strong relationship between charter school entry and search:
adding one more charter school to an area is associated with a 5% increase in online school
search activity. We believe these results are suggestive of a link between charter schools and
school quality information, but we lack explicitly exogenous variation in charter prevalence that
renders these estimates more suggestive than definitive.
Overall, our results indicate that choice policies induce information search behavior and
that this search behavior is greatly facilitated by the availability of online information. The type
of information provided by greatschools.org has been shown by previous studies to lead parents
to choose schools that increase student achievement (Hastings and Weinstein 2008). It is
beyond the scope of this study to determine whether the information search behavior we observe
leads to different school choices or to impacts on academic outcomes. However, that expanding
school choice can lead parents to obtain more information is a novel finding in this literature. It
demonstrates that mere availability of school information is not sufficient to full alleviate
information gaps: parents also must also have an incentive, in the form of expanded choice sets,
to actually seek and use the information available to them. With the increasing cheap availability
of school outcome data, showing that knowledge of these data is far from ubiquitous and
responds to incentives to use these data has important policy implications. To our knowledge, we
are the first to provide evidence on this question. Our results further highlight the potential to

5

pair online search tools with school choice policies to increase the impact of these policies on
students.
2. Previous Literature
Currently there is a paucity of research examining how much parents know about the
attributes of schools in their area and how they acquire school quality information. Our study is
designed to address these questions more directly than has been possible in prior work.
The effects of school choice on student achievement are influenced by differences in the
characteristics of schools that parents value. In survey-based studies, parents across the
socioeconomic spectrum state that academic quality is a high priority (Armor and Peiser 1998;
Schneider et al. 1998; Vanourek et al. 1998; Kleitz et al. 2000). However, Hastings, Kane, and
Staiger (2010) find that higher-income families prefer higher-performing schools, while minority
families trade off preferences for school performance with preferences for schools with
populations that look demographically similar to them. Measures of parental preference based
on housing values reinforce these results: Clapp, Nanda and Ross (2008) find that racial
composition matter at least as much as test scores, while Brasington and Haurin (2009) show that
parental characteristics are stronger predictors of home values than are school inputs. Several
studies indicate that higher school test score levels are capitalized into housing prices (Black
1999; Figlio and Lucas 2004; Bayer Ferreira and McMillan 2007; Black and Machin 2011;
Nguyen-Hoang and Yinger 2011), which also is consistent with parents valuing school quality.
In contrast, value-added information does not appear to be valued by homeowners at the margin
(Imberman and Lovenheim 2016; Brasington & Haurin 2006; Dills, 2004; Downes and Zabel,
2002; Brasington 1999).5 Importantly, the GreatSchools website contains the type of
demographic and test score information that prior research suggests parents value, while it does
not include value-added measures that they appear to value less.

5

In contrast, Gibbons et al. (2013) and Yinger (2015) find that test score levels and changes are similarly capitalized
into home prices.

6

Direct evidence on heterogeneity in parental preferences comes from Schneider and
Buckley (2002), who examine parental search behavior on a website that provided information
on choice schools in Washington D.C. They find that while parents of all backgrounds
demonstrated interest in the composition of student bodies, college-educated parents were much
more likely to “click through” to information on school test scores. Non-college-educated
parents were slightly more likely to investigate school location and facilities.6 One implication of
this study is that providing simple and salient information to families may reduce disparities
across the income distribution in knowledge about school quality.
Results from Hastings and Weinstein (2008) are consistent with this hypothesis. They
perform field experiments in which they manipulate the information environment of families
who are allowed to choose their public school. They find that parents are more likely to exercise
their choice options when they are provided with information about the quality of local schooling
options but that responsiveness is sensitive to proximity to the alternative schools. Furthermore,
parents are equally responsive to information on a broad set of local schools as they are to a
simplified set of information about alternative schools more proximate to their home. The former
is closer to the type of information available on Greatschools.org, which indicates that parents
respond to this type of information when coupled with school choice. These findings suggest that
parents do not have full information about the quality of schools around them and that providing
them with information about local schooling options can help them to make more informed
choices.
This paper is distinguished from Hastings and Weinstein (2008) along a number of
dimensions. First, our study examines how the demand for information changes when choice

6
International evidence has not shown as clear a relationship between socioeconomic status and interest in schools
quality. In the U.K., Burgess et al. (2009) find that the relationship between socioeconomic status and preference for
academic quality is attenuated by controls for each family’s realistic choice set. In Chile, Mizala and Urquiola
(2013) use a regression discontinuity approach to show that receiving a widely-publicized award designation does
not affect a school’s enrollment, tuition, or composition. They argue that this result undermines the value of
information in school markets.

7

increases, rather than how people make decisions when given more information under an
existing choice policy. These are related but distinct parameters that both are of policy interest.
The parameter on which we focus has not received any attention in prior work. Second, our study
is more nationally-representative, which speaks to the generalizability of our results. Third, we
examine a range of choice policies rather than just NCLB-induced choice. And finally, our
analysis points to the complementary nature of information that is publicly available online and
the incentives to seek that information.
3. Data
3.1. Great Schools Search Data
This paper studies parental information-gathering behavior using a new source of data:
search terms entered into the GreatSchools Inc. website (www.greatschools.org) by users. This
website, which is free to use and does not require registration, provides detailed information on
the universe of U.S. public and private schools. The website provides information along a
number of dimensions that may be of interest to parents and that can be difficult to locate from
other sources. Specifically, the website provides information from the most recent year available
on school enrollment, grade levels served and the racial/ethnic distribution of the student body.
Featured prominently are two pieces of information that may be of particular interest to families
with children. The first is a score from 1-10 based on recent standardized test results. Test scores
by grade and demographic subgroup also are provided. These mean test scores have been shown
to be valued by parents in the US as measured by capitalization into housing prices (Black and
Machin 2011), and this website makes it very easy to observe this information and compare this
metric across local schools.
The second piece of information that parents may value is “community ratings” that
ostensibly come from current and former students and their families. Schools are rated from one
to five stars on three factors: teacher quality, principal leadership and parent involvement. There
are direct testimonials from reviewers as well, which are similar to the comments one might
8

observe on Amazon.com for various products. This kind of rating information for schools is
unique to greatschools.org. Furthermore, this website contains much more information than one
would obtain from searching for schools through a more general search engine (such as Google).
Indeed, a Google search for a school or district is unlikely to yield the type of information that is
on the greatschools.org website, except to the extent it leads people to that website. This
highlights the value of the search data we analyze relative to Google Trends data or other online
search statistics.
Our data come from the universe of specific search terms entered by users from January 1
2010 through October 31, 2013. The data contain, for each month in our data, the specific text
string entered into the search bar and frequency of times such a term was entered that month.
Users have the option of entering the name of a city (e.g., Rochester), a school district (e.g.,
Brighton), a school (e.g., Twelve Corners Middle School), or a zip code (e.g., 14810). Users also
can enter addresses and find schools nearby those addresses. Beginning in August 2011, we also
have the state associated with each search from a state dropdown menu on the website. In prior
months, we only have the state if it is entered into the search bar directly. Our data do not reveal
the origin of the search (such as a user’s IP address); only the target of the search is known.
The data are comprised of 102,616,862 individual searches that contain over 3 million
individual search terms over the almost four year study period. The distribution is heavily
skewed: the top 1,000 search terms account for 36 percent of the total searches and the top 2,000
search terms account for 46%. Using these raw search data, we generated counts of searches for
each month for all feasibly-identifiable areas that potentially constitute a school choice zone for
residents. These areas are either a Census Core Based Statistical Area (CBSA) code that defines
a city or it is a county that is not in a CBSA. Searches matched to counties not in CBSAs
typically are for smaller cities and towns that have multiple schools districts in the county but
that are too small to be considered a macro or micro CBSA. Henceforth, we term these
individual CBSAs and counties “Search Units.”
9

We can match about 60% of the search terms, or about 80 percent of the total searches.
We match schools to cities and counties using the terms entered into the search field. In the
majority of searches, users enter a city, zip code, county or school district name. These are fairly
straightforward to match with local areas. We use an address finder to match the approximately
1% of searches that contain address strings.
There are four core reasons why we are unable to match the remaining 20 percent of
searches to cities or counties in our data. First, many searches include typos. However, since the
greatschools.org search tool does not use probabilistic matching, searches with typographic
errors return no results.7 Thus, they are proper to exclude. Second, some users enter only a
school’s name into the search engine without any identifying information about the school
district. While these searches will provide results, they are very difficult to use because all
schools in the US with that name will appear. We think it likely that people searching for
“Lincoln Elementary School” or even just for “high school,” for example, will search again using
a more refined set of terms. We have no way of determining which search terms originate from
the same individual, so to the extent that such searches would lead to a subsequent search,
excluding these vague search terms is appropriate to avoid double counting. Because we have no
way of determining where such searches are targeted, we exclude them. The prevalence of such
searches is unlikely to be correlated with changes in the choice environment, however. Third, we
cannot match some of the addresses in the data to a location, but this is a very small proportion
of our sample given the infrequency of users entering addresses. Finally, we cannot match some
of the search terms because they refer to very small towns or rural areas that are difficult to
locate systematically. These are areas where school choice is not likely to be relevant due to the
lack of local schooling alternatives, so excluding these searches is unlikely to affect our
estimates.

7

Such errors can either come about from misspelling a word or from including the wrong state in the search, for
example by searching for New York, LA. Such errors are very likely to lead to a new, corrected search by the user.

10

The lack of state identifiers in much of the data prior to August 2011 creates some
difficulties in matching searches to locations. Some city names, such as “Springfield” and
“Portland” are represented in multiple states, and the same problem exists for school district and
county names. Our solution to this problem is to assign these searches in the same proportions
pre-August 2011 as they are post-August 2011 when we observe state identifiers. To the extent
that the post-August 2011 proportions are themselves influenced by school choice policies, this
assignment algorithm will cause our estimates to be attenuated. This attenuation stems from the
fact that this assignment mechanism misses some of the within city and county variation in
search frequencies in these geographic regions.
Figure 1 shows the frequency of total searches by month beginning in January 2010,
which is month 1. There is some cyclicality of search frequency, with a higher volume of
searches in January through April and again in July and August and lower search frequency
during the fall. The number of searches also has grown over time, which partially reflects the
increasing popularity of the greatschools.org website. Tabulations in Table 1 show that the mean
number of total searches across areas is 176, but the standard deviation is quite large, at almost
three times the mean. The large standard deviation is driven by the fact that there are several
large cities that generate a lot of searches. Below, we will use log total searches as our dependent
variable in order to guard against our estimates being unduly influence by these large areas.
3.2. School Choice Policies
In order to characterize the school choice environments in the US, we collect state and
local information on policies that facilitate residents attending a school other than their zoned
public school. We consider six different types of school choice policies: intra- and inter-open
enrollment, tuition vouchers, tax credits for donations to private scholarship charities, tuition tax
credits, and open enrollment for Title I schools driven by No Child Left Behind (NCLB)
sanctions. For the first five measures, we create state-year level indices that provide information
about the extent of state rules governing a given choice policy. However, we show that our
11

estimates are robust to using binary measures of the presence of a type of choice policy as well
as takeup-weighted indices that include a larger set of program rules. Appendix Table A-1 shows
all regulation changes used in the main analysis. We also examine charter school prevalence in
an area as an additional measure of school choice. Each of these choice measures is discussed in
turn below.
Data on open enrollment plans were collected at the state level. Although many school
districts have intra-district open enrollment programs, and some metro areas have inter-district
open enrollment plans, the main variation in these policies is driven by state laws allowing or
mandating inter- or intra-district open enrollment. These data were generated by interacting a
“snapshot” of state laws in 2011 from CCSSO (2013) with changes in state open-enrollment laws
before and after this snapshot. We generate two state open enrollment indices that characterize
the number of regulations supporting open enrollment in a given state and month. The first can
potentially vary from zero to four and is the sum of state-level indicators, by month, for i) intradistrict mandatory open enrollment, ii) intra-district voluntary open enrollment, iii) intra-district
open enrollment for failing schools, and iv) intra-district open enrollment for low income
schools. The second index composes an equivalent set of indicators for inter-district open
enrollment. Table 1 shows that the mean state in our sample has 0.73 intra-district open
enrollment laws and 0.86 inter-district open-enrollment laws. The indices range from zero to
two, as no state has open enrollment policies along all 4 dimensions we measure.
We also measure state-level tuition voucher programs. Basic information on the
existence of these programs was obtained from Friedman Foundation (2013), with details
obtained from state websites. We calculate a State Tuition Voucher Index, which is the sum of
state-level indicators for i) whether a state-level voucher program has been announced and ii)
whether a voucher program is active. On average, states have 0.24 of these regulations. A
limitation with this approach is that voucher programs differ considerably in size across states
and often entail detailed program rules that are missed by our more parsimonious index. We
12

therefore construct another index in which we regress yearly state voucher takeup on a series of
program rule measures.8 We predict takeup based on these program rules, and then we construct
an index with mean zero and standard deviation 1 using the predicted values. This method
essentially weights each of the program rules in proportion to its relationship to takeup and
accounts for different program size across states. While we favor the more parsimonious index
based on program announcement and implementation because it is easier to interpret, results
using the enrollment-based index are very similar and are shown in Appendix Table A-3.
A third source of variation in school choice is state-level tax incentives for donations to
private scholarship charities. These charities, in turn, award tuition scholarships for local private
schools to eligible students. Basic information on the existence of these programs was obtained
from Friedman Foundation (2013), with details obtained from state websites. We characterize
these laws using a State Charitable Scholarship Tax Credit Index, which is the sum of three
indicators, by month, for i) whether a state-level charitable scholarship tax credit has been
announced, ii) whether the charitable scholarship tax credit is active, and iii) whether the
donations to the scholarship charity are fully deductible as well as two continues measures of the
percentage of individual and corporate donations that are tax deductible. On average, states have
about one of these laws, but the standard deviation of 1.12 shows there is much variation across
states and over time. As with tuition vouchers, we also construct an index based on a more
comprehensive set of program rules and program takeup.9

8

These program rules are: whether there is a voucher cap amount, the voucher amount cap if there is one, whether
the number of vouchers is capped, the number of vouchers available if there is a cap, whether vouchers are restricted
to students in failing schools, whether vouchers are restricted to free/reduced priced lunch students, the percent of
the poverty line under which students are eligible for vouchers, and an indicator for there being no poverty-based
eligibility cutoff.
9
The program rules we use to construct this index are: whether the scholarships cover full tuition, the cap on the
per-student scholarship amount, the scholarship cap amount, the rate at which $1 of donation reduces individual tax
liability, the maximum donation that can be credited on individual taxes, the rate at which $1 of donation reduces
corporate tax liability, the maximum donation that can be credited on corporate taxes, whether the scholarships are
restricted to students in failing schools, whether the scholarships are restricted to free/reduced price lunch students,
the percent of the federal poverty line under which students are scholarship-eligible, the income cap for scholarship
eligibility, and the state cap for total amount of scholarships.

13

Fourth, we collect state-level tuition tax credits for parents who pay to send their children
to private schools from the Friedman Foundation (2013). Additional details were obtained from
state websites. The State Tuition Credit Index is the sum of indicators by state and month for i)
whether a state-level tuition tax credit has been announced and ii) whether the tuition tax credit is
active. On average, Table 1 shows this index is 0.18. We also construct a takeup-based index that
uses a more comprehensive set of program rules;10 results using this index are shown in
Appendix Table A-3.
The final source of variation in the school choice environment we consider is the districtlevel share of schools that are eligible for public choice under NCLB Title I provisions. Under
NCLB, a school that received Title I funds and fails to meet AYP for two consecutive years must
offer its students the option of transferring out of the school to another local non-failing school.
We calculate, in each Search Unit, the average proportion of schools in each school year and in
each district that is subject to NCLB-induced choice. We calculated these percentages by
collecting information from each state department of education website on the School
Improvement status of each Title I school over our analysis period. All Title I schools in School
Improvement status face NCLB sanctions and must offer open enrollment. Districts then were
geographically matched to CBSAs and counties to establish the Search Unit proportion of
schools eligible for public choice. This measure, which varies at the Search Unit-month level, is
the District NCLB Choice Percentage. These data only are available for 39 states, with the
remaining states not publishing any information on AYP or school improvement outcomes. Our
analysis below focuses only on these states.11 As demonstrated in Table 1, about 21% of schools

10

The program rules we use are: the maximum amount that can be credited, the income cap for credit eligibility, and
whether the credit is capped below tuition.
11
These states are Alaska, Alabama, Arkansas, Arizona, California, Colorado, Georgia, Iowa, Idaho, Illinois,
Indiana, Kentucky, Louisiana, Massachusetts, Maryland, Michigan, Minnesota, Missouri, Mississippi, Montana,
North Carolina, North Dakota, New Hampshire, New Jersey, Nevada, New York, Ohio, Oregon, Pennsylvania,
Rhode Island, South Dakota, Tennessee, Texas, Utah, Virginia, Vermont, Washington, Wisconsin, and Wyoming.
Appendix Table A-8 shows estimates for all 51 states (including DC) are similar in sign and magnitude to estimates
from the 39 analysis states.

14

in our sample have NCLB-induced choice, with considerable variation across areas and over
time.
Table 2 presents correlations among the six school choice variables in our sample. The
policies are clearly correlated with one another, which highlights the importance of controlling
for all of these regulations simultaneously to accurately characterize the choice environment
people in each local area face. However, the correlations also are small enough that there is
sufficient independent variation in each of these laws to examine their separate impacts.
In addition to our main school choice policy variables, we collected data on the number
of charter schools in a search unit in a given year from the Common Core of Data. The mean
number of charter schools in a search unit is 5.4, but the standard deviation is 21.3, which
underscores the large amount of charter school variation that exists over this period.
4. Methodology and Results
4.1. Methodology
The goal of this analysis is to link the six school choice policy measures discussed in
Section 3.2 to online search behavior. Our empirical approach is motivated by the fact that crosssectional state policy variation in these regulations is driven by unobserved local demand for less
constrained schooling options. That is, states with laws that allow more school choice may have
more search behavior because residents have higher demand for choice options. Similarly, using
cross-sectional variation in NCLB-induced choice is problematic because areas in which more
Title I schools are in school improvement are likely to be less wealthy and have populations that
are more location-constrained.
The concerns with using cross-sectional state and NCLB-induced choice variation argue
for estimating a panel model with geographic fixed effects that can account for the fixed
differences across areas that are correlated with latent demand for school choice as well as for
the demographic composition of the area. These fixed effects soak up a lot of the variation in our

15

explanatory variables of interest, but the loss of statistical power is necessary to support a more
credible identification strategy.
We first estimate a fixed effects model that aggregates all of the state regulations into a
single State School Choice Index. This index is constructed by taking the index for each of the
five state regulations discussed in Section 3, standardizing each one such that it has a mean of
zero and a standard deviation of one, and then adding all of the standardized indices together. A
one unit increase in this index thus represents a one standard deviation increase in state
regulations designed to facilitate school choice. We estimate the following fixed effects model,
both with and without the State School Choice Index:
ln

ℎ)

=
+

+

ℎ
ℎ

+
ℎ

ℎ
+

∗
+

+

+

,

(1)

where ln(Search)imt is the log of the total number of searches in Search Unit i (in state s) in
month m and in calendar year t. As discussed in Section 3.1., a Search Unit is defined as a
Census CBSA (i.e., a city) or a county for the areas that are not in a CBSA. Thus, a Search Unit
constitutes a broad area over which families exposed to more school choice options might
search. Our analysis is based on 1,854 Search Units and 50,177 Search Unit-month-year
observations.
The variable NCLB Choice varies at the state-Search Unit-school year level and is the
mean proportion of Title I schools in each school district in the Search Unit that is in school
improvement under NCLB and thus whose students have the option of attending another local
school that is not in school improvement. We also interact Waiver, which is an indicator equal to
one for the school years in which a state has successfully applied for a waiver from NCLB,12
with the pre-waiver NCLB choice percentage. These waivers exempt states from NCLB-based
sanctions, and so the effect of such waivers should be proportional to the percentage of the
population that is subject to NCLB-based choice. The exact impact waiver exemptions have on
12

This information is available at http://www2.ed.gov/policy/elsec/guid/esea-flexibility/index.html. .

16

student choice varies by state. States usually allow students who already have switched schools
to continue their enrollment, but they eliminate the school choice options for other students in
Title I schools previously labeled as being in school improvement. Thus, we code NCLBinduced choice to be zero in the post-waiver period. We note our results are robust to leaving the
NCLB-induced choice percentage at its pre-waiver level as well.
Equation (1) also contains month fixed effects (

), year fixed effects ( ) and Search

Unit fixed effects ( ).13 The Search Unit fixed effects control for fixed differences across cities
that may confound search behavior with unobserved heterogeneity in the composition of local
residents. For example, these fixed effects control for the differences in school-age population
between Search Units, assuming that changes in those populations are minor in the four-year
window examined. The year fixed effects control for the upward trend in search prevalence
shown in Figure 1 that is in part due to the growth of the Greatschools website. The month fixed
effects account for seasonal patterns in search behavior that may be correlated with the timing of
law changes or with changes in NCLB school improvement status.
Equation (1) combines all of the state regulations into one index, but the various school
choice policies we consider are rather different from one another and thus are worthy of
individual examination. We use each policy index to estimate a model similar to equation (1):
ln

ℎ)

=
+
+

+

ℎ

+

ℎ

+

+
+

+

+

∗
ℎ

+

+

ℎ

ℎ

.

(2)

The OE, Voucher, Scholarship, and TuitCred variables are the regulation indices described in
section 3.2 and vary by state, month, and year. All other variables are as previously defined. We
also estimate versions of equation (2) in which we use indicator variables for whether the state
has any regulation that permits the use of each type of choice.

13

We will use the terms “Search Unit” and “city” interchangeably throughout the remainder of the paper.

17

Conditional on the Search Unit, month and year fixed effects, parameters
equation (1) and parameters

-

-

in

in equation (2) are identified using within-Search Unit

variation over time in choice regulations and NCLB sanctions, relating these changes in the
search environment to changes in city-level search prevalence. The assumptions underlying
identification of the parameters in equations (1) and (2) are akin to any difference-in-difference
model: 1) changes in the choice environment are uncorrelated with prior trends in search
prevalence and 2) the timing of changes in the choice environment are uncorrelated with
unobserved local shocks that independently influence search behavior.14
For the NCLB Choice estimates, the most likely source of bias comes from unobserved
trends in local demographic characteristics. A locality that is attracting relatively low-SES
families might as a result experience declining search behavior as well as increasing NCLBbased choice. This effect will bias the estimate on NCLB Choice towards zero, however. The
possibility that passage of state school choice regulations could be correlated with secular trends
in search behavior is a more serious threat to identification. If searches are increasing for reasons
other than choice policies when these policies are passed, it will produce a positive bias in our
results. In order to control more directly for differential secular trends in search, we estimate the
following parametric version of an “event study” model:15
ln

ℎ)

=

+

ℎ

+

ℎ

∗

+

ℎ _

+

+

ℎ _

+

ℎ _

+

+

ℎ _

14

Although we do not control for local business cycle measures (such as unemployment and real income per capita),
we do not find it very plausible that such variables would be independently correlated with search prevalence or
with regulations that affect the choice environment. Also note that if business cycle variation causes changes in the
choice environment, then we would not want to include local macroeconomic controls in our models because they
are endogenous. The identification concern thus is that search behavior independently varies over the business cycle
and that the timing of changes in the choice policies we examine happens to be correlated with macroeconomic
fluctuations.
15
This model is akin to an event study model in which we have constrained the pre- and post-treatment trends to be
linear for each choice policy. We do not have the statistical power to estimate non-parametric event study models for
all policies simultaneously.

18

+

ℎ _

+

+

ℎ _

+

+

ℎ _

+

+

+

+
+

ℎ
ℎ

+
+

ℎ _
ℎ _

+

ℎ _

,

(3)

where month_pre is the number of months prior to a given regulation changing and months_post
is the number of months after a regulation changes in a state. As shown in Appendix Table A-1,
there are a couple of cases in which a state changes more than one component of a given
regulation. These multiple changes occur close together, however, and we construct the relative
time measures with respect to the first change. When the treatment measures are indicators for
the existence of a regulation, the relative time measures are simply the number of months to or
since a change in the choice policy, coded as zero if a state does not make a change. In
specifications that use the regulatory indices, we interact the regulation index for the policy in
the state and month with relative time. All other variables in equation (2) are as previously
defined.
In equation (3), the

coefficients show whether passage of state laws is related to pre-

change trends in search. Thus, the months_pre variables control for any such differential trends.
The

coefficients show whether there are linear time-varying treatment effects. In the case in

which the

estimates are non-zero, it becomes more difficult to characterize the treatment

effects in a simple manner. We focus on estimating the effect after 12 months ( + 12 ) because
the average state that changes a regulation has almost 12 months of post-change observations and
because the effect after one year is a natural way to scale the time-varying treatment effects.
Although it is more complicated, equation (3) is our preferred model because it is more flexible
and controls for pre-law-change trends that we show attenuate the estimates from equations (1)
and (2).
Note that equation (3) does not include time-varying controls for the NCLB choice
percentage. This is because this variable is continuous and contains multiple changes within each
19

Search Unit over time, which does not lend itself well to the event study framework. There are
two concerns regarding the endogeneity of NCLB-based choice changes. The first is that NCLB
choice is simply picking up trends in the demand for school choice. To test for this possibility,
we estimate models in which we control for one-year leads of NCLB Choice Percentage and prewaiver NCLB Choice Percentage interacted with Waiver. If our estimates are biased by
unobserved trends, these leads should be of similar sign and magnitude as the contemporaneous
measures, and the effect of the contemporaneous measures should be attenuated. Our results are
inconsistent with such patterns.
The second identification concern with the NCLB choice estimates is that they are
picking up parents’ reaction to finding out their school is failing under NCLB. That parents
respond to negative information by searching for local school quality is of interest in its own
right, but this finding would have a different policy interpretation. In order to provide some
evidence on this potential problem, we collected district report card data in 10 states for which
we could find such information back to 2009. We show that controlling for these report card
grades has little impact on our estimates, which suggests the school quality search behavior
related to NCLB choice is related to the expansion of choice rather than negative information
about school quality.
Second, we show that changes in city-level choice driven by NCLB generate higher
search behavior in May and August. Since these are both months in which parents select schools
for their children, this evidence is consistent with families responding to the increased
availability of school choice by collecting information through greatschools.org.
We estimate equations (1)-(3) for the 39 states for which we have collected NCLBinduced choice data. Due to the potential for serial correlation within areas over time in search
behavior and because most of our choice measures vary at the state level or higher, we cluster all
standard errors at the state level.
4.2. Baseline Results
20

The results from estimation of equations (1)- (3) are shown in Table 3.16 In column (i),
we show results only including the NCLB variables. There is a clear positive effect of the
percentage of schools eligible for choice under NCLB and the number of searches. A 10
percentage point increase in NCLB-based choice eligibility increases the number of searches by
7.2%.17 A one standard deviation increase in NCLB choice of 21 percentage points thus would
imply a 15.1% increase in search frequency. Additionally, the results show that post-waiver,
search declines by 4% for each 10% increase in pre-waiver choice percentage. Thus, waivers
reduce the effect of NCLB choice by over half. Importantly, this finding is inconsistent with our
NCLB choice estimates being driven by unobserved constant trends in the underlying
population, as such trends would force these coefficients to have the same sign.
To put the size of these estimates into perspective, it is helpful to benchmark them against
the proportion of families moving into the search area in a given year. These families are much
more likely to engage in school search and are the most likely to use the Greatschools website in
the absence of school choice. Furthermore, comparing changes in search rates to mobility rates
provides a lower bound on the amount of choice-induced online search behavior that is done by
existing residents. Using the 2010-2014 American Community Survey, we calculate the
proportion of families with a 5-17 year old in each search unit that did not live in the area the
prior year. On average, about 5% of search unit families are new entrants in each year. Thus,
even under the extreme assumption that all families entering an area would use the Greatschools
website, our estimates suggest large amount of search induced by NCLB-based choice among
existing resident families.

16

Appendix Table A-2 presents estimates that do not contain Search Unit fixed effects. These results show the
importance of controlling for fixed differences across areas, as those in lower-income areas are more likely to have
school choice but are less likely to have access to the Internet and thus engage in fewer searches. This creates a
negative bias in the estimates, which is why the results in Table A-2 differ so starkly from those in Table 3.
17
Note that this does not imply that 72% of families newly eligible for choice log on to GreatSchools. The
hypothetical 10% increase in NCLB eligibility is relative to the base of all schools in the Search Unit. The 7.7%
increase is relative to the base of underlying search activity in a Search Unit. That is, the denominators of these two
percentages are different.

21

In column (ii), we add the State School Choice Index to the model, which combines all
state policies into a single standardized index. The coefficient on this index is very close to zero
and is not statistically significant at conventional levels. Furthermore, the inclusion of this
variable has very little effect the NCLB choice variables. It thus appears from column (ii) of
Table 3 that state choice policies do not impact online school quality search behavior. This
aggregate index could be masking significant heterogeneity across policies, however. We show
suggestive evidence that this is the case in column (iii). This column presents estimates of
equation (2) and shows that inter-district open enrollment and tuition voucher policies are
positively related to online search while the other three policies negatively affect online search
prevalence. Though none of the estimates is statistically significant, the point estimates for open
enrollment policies, tuition vouchers and tuition tax credits are sizable in magnitude.
Column (iv) contains our preferred estimates that include measures for all of our school
choice policies and allow for time-varying treatment effects and linear pre-treatment trends for
state policies. The effects of NCLB choice and waivers on searches are almost identical to those
in column (i): a one standard deviation increase in the NCLB choice percentage leads to an
increase of 15.7% in search frequency.
Allowing for time-varying effects of state policies provides stronger evidence of an effect
of several choice policies on online search behavior, although few of the point estimates is
statistically significant. Search frequency increases immediately by 13.5% due to an intra-district
open enrollment regulation change. As shown in Appendix Table A-1, the only state intra-district
choice policy change over our sample is a repeal. This is the only choice policy repeal in our
data. The post-change estimate for intra-district open enrollment therefore indicates how online
search changes after intra-district choice is eliminated. That the estimate is negative suggests that
restricting intra-district choice leads to a reduction over time in search frequency for school
quality information. For inter-district open-enrollment, there is an initial negative effect of 15%
and then a positive post-treatment trend that is significant at the 10% level. The passage of an
22

additional inter-district open enrollment regulation increases search by 9% after 12 months. Put
differently, a one standard deviation increase in inter-district open enrollment regulations18
increases search prevalence by 7.7% a year after passage.
There is clear evidence that tuition vouchers lead to increased search frequency, with an
initial effect of 8% that grows by 0.8% on average (significant at the 10% level) each additional
month post law change. Taken together, these results indicate that an additional tuition voucher
law increases search by 17.6% after a year, which translates into a 4.2% effect for a standard
deviation increase. There is little evidence of a relationship between charitable scholarship tax
credits and search prevalence, while tuition tax credits reduce search. A year after a tuition tax
credit increase, online search is reduced by 12.5%. This implies a 2.25% reduction in search
frequency for each standard deviation increase in tuition tax credits. The results from Table 3
provide suggestive evidence that voucher provision increases search while tax credits either have
no or a slightly negative effect. This could be because vouchers increase choice among lowerincome families who may engage in more online search behavior as a result, whereas tax credits
tend to subsidize higher-income families who may already be using the private school system.19
The reason the state policy effects are somewhat stronger in column (iv) than in column
(iii) is shown in the pre-trend estimates at the bottom of the table. For tuition vouchers and
charitable scholarship credits, there are negative pre-treatment trends that suggest state
regulatory changes are negatively correlated with search trends. This attenuates the estimates in
column (iii). While the pre-trend estimate on inter--district enrollment is positive and sizable in

18

Note that the open enrollment variable is an index from 0 to 2 (no policy; announced but not operating; announced
and operating), so it is not a binary variable with a standard deviation that is defined by the mean.
19
Choice policies may impact low-income families more because of a larger pre-existing information deficit and
because school choice policies tend to target more disadvantaged students. While we cannot examine differential
effects across different families, Appendix Table A-6 shows estimates for more- and less-disadvantaged areas. The
first two columns split the sample in half based on CBSA median family income. The second two columns perform
a similar split based on area poverty rates. Observables are taken from the 2012-2014 ACS. The estimates are not
sufficiently precise for these sample splits to be informative. There is little difference in estimates across search area
poverty rates. Those in higher income areas respond more to NCLB-based choice, but since we cannot determine
who in these areas is responding, these results should be interpreted with caution.

23

magnitude,20 the overall effect of the pre-treatment trends is to attenuate the estimates due to the
correlation across policies (Table 2).
The estimates presented in Table 3 indicate that NCLB-based school choice, open
enrollment policies, and private school tuition vouchers have large, positive effects on the
prevalence of searches for local school quality. These results embed a potentially strong
assumption that each law change has the same proportional effect on search frequency. After the
first law passes, though, subsequent regulations may not have a large influence on search
behavior. In Table 4, we alter the parameterization of state laws such that they are indicators
equal to one if the state has any regulation allowing the choice policy.21 The identifying variation
for the estimates in this table therefore comes only from states passing their first regulation of
each type.22
The results from this model are consistent with those from Table 3 in showing positive
effects of NCLB-based choice, intra- and inter-district open enrollment, and tuition vouchers on
search prevalence.23 The one notable difference across specifications is that Table 4 shows
evidence of a positive immediate effect of charitable scholarship tax credits that declines over
time. After a year, these tax credits reduce search by 7.2%.
4.3. Robustness Checks
In this section, we present a series of robustness checks that show our results and
conclusions are robust to altering a series of modeling assumptions. The estimates in Tables 3

20
We show in Section 4.3 that this pre-trend is attenuated when we control flexibly for month-year trends. However,
the estimated effect of inter-district open enrollment on search frequency remains similar when we add these
controls.
21
The State School Choice Index in this specification is a sum of all the state law type indicators in each state and
year.
22
As discussed in Section 3, we also construct takeup-based indices that use a larger set of program rules for tuition
vouchers, charitable scholarship credits, and tuition credits. These indices take account not only of all of the
regulations for each policy but also the different takeup rates of these policies across states. Results using these
indices are shown in Appendix Table A-3. The results are similar to those shown in Table 3 and indicate that our
results and conclusions are not sensitive to the specific way in which we construct the state regulatory indices.
23
As in Table 3, search is lower after a state intra-district open enrollment change, but this effect reflects a repeal
rather than passage of such a law. A negative coefficient therefore is consistent with a positive effect of intra-district
open enrollment on search frequency.

24

and 4 indicate that any pre-trends related to passage of state school choice regulations bias our
estimates towards zero. That is, states tend to pass school choice laws when searches are
declining in the state. While the parametric event study estimates handle selection on linear pretreatment trends for state laws, we are not able to test for such selection with respect to changes
in the District NCLB Choice Percentage.
In order to examine whether our NCLB choice estimates are being driven by secular
trends, in columns (i) and (ii) of Table 5 we include one-year leads of the District NCLB Choice
Percentage and NCLB Waiver interacted with the pre-waiver choice percentage. Note that these
specifications do not allow us to use outcomes from the last 12 months of our data, which is why
the sample sizes are smaller. If we are simply picking up secular search frequency trends, the
effects should load on the lead variables rather than on the contemporaneous measures. In
column (i), we examine only the NCLB-based choice measures. For NCLB Choice Percentage,
the lead variable is opposite signed and is not statistically significant. The contemporaneous
estimate of 0.802 is larger than the estimate in column (i) of Table 3, suggesting that any
remaining trends bias our results towards zero. Similarly, the estimate for the choice waiver
interacted with pre-NCLB choice percentage is wrong-signed and is not statistically significant at
even the 10% level. The contemporaneous estimate is larger in absolute value than in Table 3 as
well. In column (ii) of Table 5, we control for state-level regulation indices and again find results
that are similar to those in Table 3.24 These estimates indicate that our NCLB results are not
biased by secular trends and that, if anything, our baseline estimates are conservative.
We also examine the monthly time pattern of search frequency effects due to NCLBbased choice. Any impacts on search frequency should be most pronounced at the end of the
school year and during the summer, as this is when school choices are made for the following
year. This prediction stems from the fact that school improvement and AYP status is released
24

The one intra-district enrollment policy change comes in 2013, which is excluded from the analysis because of the
inclusion of a one-year lead. Thus, we cannot identify the immediate and post intra-district open enrollment
parameters in this regression.

25

each spring towards the end of the school year, and parents in Title I schools in improvement
status are notified by the school that they can switch schools in this period as well. In order to
examine the search patterns in response to NCLB-induced choice, we interact both the local
choice percentage and the waiver status with indicators for each month. The estimates on the
choice percentage are shown in Figure 2 (with January as the omitted month). These estimates
come from models with Search Unit, month and year fixed effects as well as controls for all
other choice environment variables in equation (3). There is a clear jump in search frequency in
May as well as in August. However, we note that the estimates are noisy and we cannot reject the
null hypothesis at the 10% level that all month estimates are the same. Furthermore, the effect of
NCLB choice is high in March, which is somewhat unexpected. Overall, the results in Figure 2
provide corroborating evidence that our estimates reflect the causal impact of changes in the
choice environment on search behavior rather than other confounding influences such as secular
search trends or changing demographics.25
In equations (1)-(3), we control for month and year fixed effects but not month-by-year
fixed effects. Due to the limited amount of state regulation variation and the fact that the NCLB
choice percentages all change in the same month, we do not have sufficient power to include
these fixed effects. Columns (iii)-(v) in Table 5 explore whether the lack of such fixed effects are
driving our estimates. We include, sequentially across columns, linear, quadratic and cubic
month-by-year trends. These are constructed by creating a variable that is a cumulative month
count from the first month in the sample. The estimates are on the whole similar to baseline. The
immediate effects of intra-district open enrollment and tuition vouchers become larger, while the
immediate effect on intra-district open enrollment becomes more negative. Furthermore, there

25

We also have examined whether our results are robust to using count models rather than linear models. Appendix
Table A-7 shows Poisson model estimates with block bootstrapped standard errors at the Search Unit level. The
results are consistent with those in Table 3. In Appendix Table A-4, we present estimates using log searches per
student. This dependent variable helps ensure our baseline results are not being driven by unobserved changes in the
size of the school-aged population, which would independently impact search frequency. The results are very similar
to those in Table 3, though on a different scale, and are somewhat more precisely estimated. These estimates show
that our results and conclusions are not being driven by the way in which we measure the dependent variable.

26

now is a small one-year positive effect of tuition credits of 1.4%. Including these flexible time
trends does not change the substantive results and conclusions from our baseline analysis.
Another identification concern relates to the NCLB choice estimates and the extent to
which they are driven by a negative information shock. When a Title I school fails to make AYP
for two consecutive years, parents in these schools are notified that the school is failing and that
their child can now attend another non-failing school in the area. Suppose that parents
subsequently use GreatSchools to search for more information about their current school - "How
bad is it?" Since our data only include the object of the search, and not the school currently
attended, this would appear as higher search frequency in an area with expanded choice.
As part of their accountability rules, many states publish district report cards that are
based on standardized test score results. These typically are in the form of grades A-F, but some
states also classify districts into discrete categories (such as “excellent” or “failing”) that can
easily be translated into A-F grades. To see if searches respond to “bad news” in addition to
expanded choice, we collected district report card data from the 10 states that publish such
information.26 By restricting ourselves to the states in which we could readily find this
information, we are making it more likely that this information was salient to parents. We
calculated the proportion of each Search Unit with each grade in each school year. Table 6
shows estimates of how district report card variation is related to search frequency. If low (D or
F) grades strongly predict search frequency, it suggests that parents also seek information in
response to “bad news” rather than simply exploring alternative schools. On the other hand, a
weak relationship between low accountability grades and searches would imply that searches are
driven primarily by choice rather than bad news.
We examine effects by report card grade (relative to A) and for high- and low-performing
districts (relative to C). In the first two columns, we first estimate a regression of NCLB Choice
Percentage on report card grades, including month, year and Search Unit fixed effects. NCLB
26

These states are California, Illinois, Indiana, Kentucky, Massachusetts, Ohio, Oregon, Texas and Washington.

27

Choice Percentage is only weakly related to district grades, which is sensible given that schools
often fail AYP due to the failure of relatively small subgroups. This means that examining the
relationship between accountability grades and search provides a relatively independent check of
how parents respond to negative news.
In columns (iii) and (iv), we see that there is a relationship between search prevalence
and district report card changes, but the proportion of districts with a grade of C is most strongly
correlated with search intensity. Most notably, obtaining a D or F does not lead to much
additional search relative to obtaining an A or B, and it leads to less search than obtaining a C
grade. The implication of these results is that receiving negative information about local schools
does not lead to additional online searches in a manner that would bias our estimates. Finally, in
columns (v)-(vii) of Table 6 we examine how controlling for these report card grades affects our
baseline estimates. Column (v) shows results for our baseline model estimated for the 10 states
for which we have report card data. The NCLB Choice Percentage estimate is somewhat smaller
than in Table 3, but it also is much less precisely estimated, and the 95% confidence interval
includes our baseline estimate. More importantly, when we add in controls for district report
cards, the estimates are unchanged. Together, these results support our estimation approach in
showing that online search frequency does not strongly react to receiving negative information
and that controlling for alternative information shocks does not affect or results. The estimates in
Table 6 give us additional confidence in our preferred interpretation of the results as reflecting
how school choice opportunities influence information accumulation among parents.
A final identification concern relates to the validity of the control states. The states that
do not alter their choice policies may be a poor counterfactual for those that do change their
policies. In Appendix Table A-5, we restrict our analysis only to the 11 states that change their
policies. The NCLB Choice estimates are much larger, but we urge caution in interpreting these
estimates due to the select nature of the states in this model. More importantly, the estimates for
the state policies are very similar to those in Table 3, if somewhat stronger. Thus, our state-level
28

policy results are not being driven by the inclusion of states that do not change their policies in
our sample period. These states do contribute to identifying the NCLB choice parameters,
however, which is why we include them in our baseline model.
4.4. Results for Specific Search Terms
In addition to overall search frequency, our data allow us to examine what types of
schools people are searching for on the Greatschools website. Using the search strings people
enter, we calculated the frequency in each Search Unit and month that individuals entered the
following four search terms: charter, private, high, and elementary.27 Estimates using these
search term counts as the dependent variable are informative about how each of the choice
environment factors we analyze influences the types of schools people search for. However,
these estimates also should be interpreted cautiously because some individuals may search for a
given type of school without entering any of these search terms.28 Because of the prevalence of
zeros (and the lack of large outliers), the dependent variables for this part of the analysis are the
raw search counts rather than the natural log. Means of each search term are shown in Table 1.
Table 7 presents the results from estimation of equation (3) using counts of each of the
five search terms as dependent variables. On the whole, these estimates are imprecise and there
are few statistically significant findings. However, the results are qualitatively similar to those
using total searches. In particular, district NCLB choice percentage is positively related to each
search term, and waivers are negatively correlated with each term in proportion to the pre-waiver
NCLB choice level. Tuition vouchers are positively correlated with searches of each term in the
short run but only with searches for charter and private after one year. Searches for “high” and
“elementary” increase in the long run due to inter-district open enrollment. The effects of other
search policies are smaller and less consistent across columns.
4.5. Charter School Results
27

There was an insufficient number of searches on “Middle” to estimate a model for this search term.
For example, they might enter “Boston” with the intent of examining charter schools in Boston, but our search
counts would not count this search as being related to charter schools (or to any other particular type of school).
28

29

Finally, in Table 8 we show estimates that demonstrate how the number of charter
schools in a Search Unit is related to search frequency. As discussed in Section 3, we lack a
source of exogenous variation in the number of charter schools, so it is possible that charter
school penetration is correlated with unobserved secular trends in search activity. This part of the
analysis therefore is more suggestive, but it still is interesting to examine how charter school
penetration correlates with online school quality search activity.
In column (i) of Table 8, we show that adding a charter school to an area is associated
with a 5.3% increase in search frequency. The sign and magnitude of this estimate is similar to
those for the other search policies for which we found positive effects and provide suggestive
evidence that charter school entry induces parents to obtain school quality information. In
column (ii), we control for all of the other choice measures. Not only is the coefficient on the
number of charter schools unaffected, the estimates on the other choice measures are similar to
baseline. Overall, these results indicate that parental information about local school quality is
endogenous to many aspects of the local choice environment, including the number of charter
schools.
5. Conclusion
This paper examines how observed searches for school quality information respond to
changes in the local school choice environment. We construct a unique dataset linking the
location being searched to the local school choice policies in a given area and month over a fouryear period from over 100 million unique searches on greatschools.org. The type of information
available on this website facilitates easy comparisons across local schools, and prior work has
shown that providing parents with this type of information, when combined with school choice,
leads parents to choose schools for their children that increase their measured academic
achievement (Hastings and Weinstein 2008).
We find evidence that changes in the local school choice policies and options have
sizable positive effects on the frequency of online searches about that locality. In particular,
30

expanding state-level intra- and inter-district open enrollment rules and providing private school
vouchers are positively associated with the number of searches about local schools in that state.
Furthermore, expansions in choice from increases in the number of schools in a given area that
are subject to choice-based sanctions under NCLB have a strong positive impact on online search
frequency. When the state becomes eligible for a waiver that exempts them from these sanctions,
however, search frequency declines. We also show evidence that charter school expansions in an
area are positively correlated with online school search behavior.
Taken together, our results point to parents responding to increasing school choice
options by collecting more information about local school quality. This is a novel finding and has
several important policy implications. First, it implies that for many families, the availability of
publicly-provided school quality information is not sufficient to get them to pay attention to it.
Parents must also have the incentive to seek and use this information. It is perhaps not surprising
that families who have few school choice options are less likely to access the available
information about other schools in the area. This finding can help explain why, even in the
information-rich post-NCLB world, some parents appear to have incomplete information about
schools. These results have implications for how the information components of school
accountability policies operate.
Second, our findings point to an additional channel through which school choice policies
affect parental behavior. In addition to increasing families’ choice sets, these policies can induce
parents to seek available information about school quality. To the extent that better information
improves the match between families and schools or leads to pressure among parents to increase
measured achievement, this effect can augment the impacts of school choice policies.
Third, our results suggest that online search tools such as greatschools.org can be
powerful mechanisms through which to provide families with the information they need to take
advantage of choice programs and to gain useful information about local schooling options more
broadly. That the information is being provided by an independent third party also might
31

increase the credibility of the information from parents’ perspectives, although more research is
needed to understand how parents interpret school quality information from different sources. It
might be possible for policymakers to use the existence of online school quality information
tools to increase the effectiveness of school choice policies insofar as they can help overcome
information deficiencies that exist in this market. We view such a possibility as a fruitful area for
future research.

32

Works Cited
Abdulkadiroğlu, Atila, Joshua D. Angrist, Susan M. Dynarski, Thomas J. Kane and Parag A.
Pathak. 2011. “Accountability and Flexibility in Public Schools: Evidence from Boston's
Charters And Pilots.” Quarterly Journal of Economics 126(2): 699-748.
Angrist, Joshua D., Parag A. Pathak, and Christopher R. Walters. 2013. “Explaining Charter
School Effectiveness.” American Economic Journal: Economic Policy 5(4): 1-27.
Armor, David J., and Brett M. Peiser. 1998. “Interdistrict Choice in Massachusetts,” in Learning
from School Choice, Paul E. Peterson and Bryan C. Hassel, eds. Washington, DC: Brookings
Institution Press.
Bayer, Patrick, Fernando Ferreira, and Robert McMillan. 2007. “A Unified Framework for
Measuring Preferences for Schools and Neighborhoods.” Journal of Political Economy
115(4): 588-638.
Black, Sandra. 1999. “Do Better Schools Matter? Parental Valuation of Elementary Education.”
Quarterly Journal of Economics 114(2): 577-599.
Black, Sandra E. and Stephen Machin. 2011. “Housing Valuations of School Performance” in
Eric A. Hanushek, Stephen Machin and Ludger Woessmann (Eds.) Handbook of the
Economics of Education, Volume 3. North-Holland: Amsterdam.
Bettinger, Eric. 2005. “The effect of Charter Schools on Charter Students and Public Schools.”
Economics of Education Review 24(2): 133-147.
Bifulco, Robert and Helen F. Ladd. 2006. “The Impacts of Charter Schools on Student
Achievement: Evidence from North Carolina.” Education Finance and Policy 1(1): 50-90.
Brasington, David M. 1999. “Which Measures of School Quality Does the Housing Market
Value?” Journal of Real Estate Research 118(3): 395-413.
Brasington, David and Donald R. Haurin. 2006. “Educational Outcomes and House Values: A
Test of the Value Added Approach.” Journal of Regional Science 46(2): 245–268.
Brasington, David M. and Donald R. Haurin. 2009. “Parents, Peers, or School Inputs: Which
Components of School Outcomes are Capitalized into House Value?” Regional Science and
Urban Economics 39(5): 523-529.
Burgess, Simon, Ellen Greaves, Anna Vignoles, and Deborah Wilson. 2009. “What Parents
Want: School Preferences and School Choice.” Centre for Market and Public Organisation
(CMPO) Working Paper No. 09/22.
Carnoy, Martin and Susanna Loeb. 2002. “Does External Accountability Affect Student
Outcomes? A Cross-State Analysis,” Educational Evaluation and Policy Analysis 24(4):
305-331.
Clapp, John M., Anupam Nanda, and Stephen L. Ross. 2008. “Which School Attributes Matter?
The Influence of School District Performance and Demographic Composition on Property
Values.” Journal of Urban Economics 63(2): 451-466.
Council of Chief State School Officers (CCSSO). 2013. School Choice in the States: A Policy
Landscape.
Cullen, Julie Berry, Brian A. Jacob and Steven Levitt. 2006. “The Effect of School Choice on
Participants: Evidence from Randomized Lotteries.” Econometrica 74(5): 1191-1230.
Deming, David J., Sarah Cohodes, Jennifer Jennings, and Christopher Jencks. 2013. “School
Accountability, Postsecondary Attainment and Earnings.” NBER Working Paper No. 19444.

33

Deming, David J., Justine S. Hastings, Thomas J. Kane and Douglas O. Staiger. 2014. “School
Choice, School Quality, and Postsecondary Attainment.” American Economic Review 104(3):
991-1013.
Dills, Angela K. 2004. “Do Parents Value Changes in Test Scores? High Stakes Testing in
Texas.” Contributions to Economic Analysis and Policy 3(1): Article 10.
Dobbie, Will and Roland G. Fryer, Jr. 2011. “Are High-Quality Schools Enough to Increase
Achievement Among the Poor? Evidence from the Harlem Children's Zone.” American
Economic Journal: Applied Economics 3(3): 158-187.
Downes, Thomas A. and Jeffrey E. Zabel. 2002. “The Impact of School Characteristics on House
Prices: Chicago 1987-1991.” Journal of Urban Economics 52(1): 1-25.
Figlio, David N. and Maurice E. Lucas. 2004. “What's in a Grade? School Report Cards and the
Housing Market.” American Economic Review 94(3): 591-604.
Fiva, Jon H. and Lars J. Kirkebøen. 2011. “Information Shocks and the Dynamics of the Housing
Market.” Scandinavian Journal of Economics 113(3): 525-552.
Friedman Foundation For Educational Choice. http://www.edchoice.org/School-Choice/SchoolChoice-Programs.
Gibbons, Stephen, Stephen Machin and Olmo Silva. 2013. “Valuing School Quality Using
Boundary Discontinuities.” Journal of Urban Economics 75(1): 15-28.
Grady, Sarah, Stacey Bielick and Susan Aud. 2010. “Trends in the Use of School Choice: 19932007.” National Center for Education Statistics, Institute of Education Sciences Report No.
NCES 2010-004.
Hanushek, Eric A., John F. Kain, Steven G. Rivkin, and Gregory F. Branch. 2007. “Charter
School Quality and Parental Decision Making With School Choice.” Journal of Public
Economics 91(5-6): 823-848.
Hanushek, Eric A. and Margaret E. Raymond. 2005. “Does School Accountability Lead to
Improved Student Performance?” Journal of Policy Analysis and Management 24(2): 297327.
Hastings, Justine S., Thomas J. Kane and Douglas O. Staiger. 2006. “Gender and Performance:
Evidence from School Assignment by Randomized Lottery.” American Economic Review
Papers and Proceedings 96(2): 232-236.
Hastings, Justine S., Thomas J. Kane and Douglas O. Staiger. 2010. “Heterogeneous Preferences
and the Efficacy of Public School Choice.” Mimeo.
Hastings, Justine S. and Jeffrey M. Weinstein. 2008. “Information, School Choice, and
Academic Achievement: Evidence from Two Experiments.” Quarterly Journal of Economics
123(4): 1373-1414.
Howell, William G., Patrick J. Wolf, David E. Campbell, and Paul E. Peterson. 2002. “School
Vouchers and Academic Performance: Results from Three Randomized Field Trials.”
Journal of Policy Analysis and Management 21(2): 191-217.
Imberman, Scott A. 2011. “Achievement and Behavior in Charter Schools: Drawing a More
Complete Picture.” Review of Economics and Statistics 93(2): 416-435.
Imberman, Scott A. and Michael F. Lovenheim. 2016. “Does the Market Value Value-Added?
Evidence from Housing Prices after a Public Release of School and Teacher Value-Added.”
Journal of Urban Economics 91: 104-121.
Kleitz, Bretten, Gregory R. Weiher, Kent Tedin, and Richard Matland. 2000. “Choice, Charter
Schools, and Household Preferences.” Social Science Quarterly 81(3): 846-854.
34

Krueger, Alan B. and Pei Zhu. 2004. “Another Look at the New York City School Voucher
Experiment.” American Behavioral Scientist 47(5): 658-698.
Mizala, Alejandra and Miguel Urquiola. 2013. “School Markets: The Impact of Information
Approximating Schools’ Effectiveness.” Journal of Development Economics 103: 313-335.
Nguyen-Hoang, Phuong and John Yinger. 2011. “The Capitalization of School Quality into
House Values: A Review.” Journal of Housing Economics 20(1): 30-48.
Rockoff, Jonah and Lesley J. Turner. 2010. “Short-Run Impacts of Accountability on School
Quality.” American Economic Journal: Economic Policy 2(4): 119-147.
Rouse, Cecilia Elena, Jane Hannaway, Dan Goldhaber and David Figlio. 2007. “Feeling the
Florida Heat? How Low-Performing Schools Respond to Voucher and Accountability
Pressure.” NBER Working Paper No. 13681.
Rouse, Cecilia Elena. 1998. “Private School Vouchers and Student Achievement: An Evaluation
of the Milwaukee Parental Choice Program.” Quarterly Journal of Economics 113(2): 553602.
Sass, Tim R. 2006. “Charter Schools and Student Achievement in Florida.” Education Finance
and Policy 1(1): 91-122.
Schneider, Mark, Melissa Marschall, Paul Teske and Christine Roche. 1998. “School Choice and
Culture Wars in the Classroom: What Different Parents Seek from Education.” Social
Science Quarterly 79(3): 489-501.
Schneider, Mark and Jack Buckley. 2002. “What Do Parents Want from Schools? Evidence from
the Internet.” Educational Evaluation and Policy Analysis 24(2): 133–144.
Tiebout, Charles M. 1956. “A Pure Theory of Local Expenditures.” Journal of Political
Economy 64(5): 416-424.
Vanourek, Greg, Bruno V. Manno, Chester E. Finn, and L. E. Bierlein Palmer. 1998. "Charter
Schools as Seen by Students, Teachers, and Parents." Learning from school choice: 187-212.
Yinger, John. 2014. “Hedonic Markets and Sorting Equilibria: Bid-function Envelopes for Public
Services and Neighborhood Amenities.” Journal of Urban Economics 86: 9-25.

35

Table 1. Descriptive Statistics of Analysis Variables
Variable Mean
Total Searches 234.9
“Charter” Searches
0.21
“Private” Searches
0.09
“High” Searches
3.69
“Elementary” Searches
0.83
State Intra-District Open Enrollment Laws
0.73
State Inter-District Open Enrollment Laws
0.86
State Tuition Voucher Laws
0.24
State Charitable Scholarship Tax Credit Laws
1.12
State Tuition Credit Laws
0.18
District NCLB Choice
0.21
Number of Charter Schools
5.36

SD
1060.4
2.48
1.15
31.27
8.93
0.58
0.49
0.64
1.92
0.56
0.21
21.32

Min
1
0
0
0
0
0
0
0
0
0
0
0

Max
41,011
94
55
1,542
450
2
2
2
5
2
0.9
406

Source: Authors’ tabulations of greatschools.org search data and state and local school choice policy variables as
described in the text. All tabulations include only the 39 states for which we have NCLB choice information.

Table 2. Correlations among Choice Variables
State Intra- State InterDistrict
District
Open
Open
Enroll.
Enroll.
Variable
Laws
Laws
State Intra-Dist Open Enroll. Laws
1
0.400
State Inter-Dist Open Enroll. Laws
1
State Tuition Voucher Laws
State Scholarship Credit Laws
State Tuition Credit Laws
District NCLB Choice

State
Tuition
Voucher
Laws
0.132
0.055
1

State
State
District
Scholarship Tuition
NCLB
Credit
Credit
Choice
Laws
Laws
-0.014
0.098
0.078
1

-0.036
0.002
0.479
0.291
1

-0.051
0.133
-0.040
-0.094
-0.122
1

Source: Authors’ tabulations of state and local school choice policy variables as described in the text. All correlations include only the
39 states for which we have NCLB choice information.

36

Table 3. OLS Estimates of the Relationship Between the Choice Environment and Log Total
Searches
Independent Variable
(i)
(ii)
(iii)
(iv)
0.718*
0.720*
0.723*
0.736**
District NCLB Choice Percentage
(0.383)
(0.382)
(0.379)
(0.363)
Pre-Waiver NCLB Choice
-0.400**
-0.398**
-0.412**
-0.438***
Percentage*NCLB Waiver
(0.155)
(0.157)
(0.157)
(0.146)
0.004
State School Choice Index
(0.013)
Intra-District Open Enrollment
-0.039
0.135
(0.101)
(0.136)
Index
Intra-District Open Enrollment
-0.010
Index* Months Post Change
(0.014)
Inter-District Open Enrollment
0.022
-0.150
Index
(0.095)
(0.114)
Inter-District Open Enrollment
0.020*
Index* Months Post Change
(0.013)
0.052
0.080
Tuition Voucher Index
(0.165)
(0.173)
Tuition Voucher Index*
0.008*
Months Post Change
(0.005)
-0.004
0.042
Charitable Scholarship Credit Index
(0.030)
(0.031)
Charitable Scholarship Credit
-0.005
Index* Months Post Change
(0.004)
-0.071
0.007
Tuition Credit Index
(0.080)
(0.082)
Tuition Credit Index*
-0.011***
Months Post Change
(0.004)
Intra-District Open Enrollment
Index* Months Pre Change
Inter-District Open Enrollment
Index* Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit
Index* Months Pre Change
Tuition Credit Index*
Months Pre Change

0.002
(0.004)
0.040**
(0.015)
-0.011
(0.010)
-0.034**
(0.014)
0.015
(0.011)

Source: Authors’ estimation of equations (1)-(3) using greatschools.org search data and local school choice policies
as described in the text. All results include only the 39 states for which we have NCLB choice information, and all
estimates include Search Unit, month and year fixed effects. N=50,177. The Search Unit is defined as the CBSA or
the county if the area is not in a CBSA. State School Choice Index is a sum of all state choice indices that are first
converted to standard deviation units. “Months pre” is the number of months prior to a law change that occurs
during our analysis period. “Months post” is the number of months after a law change that occurs during our
analysis period. Relative month measures are set to zero in states that do not experience a law change in our sample.
Standard errors clustered at the state level are in parentheses: * indicates significance at the 10% level, ** indicates
significance at the 5% level and *** indicates significance at the 1% level.

Table 4. OLS Estimates of the Relationship Between the Choice Environment and Log Total
Searches Using Binary State Choice Measures
Independent Variable
(i)
(ii)
(ii)
0.714*
0.621**
0.728**
District NCLB Choice Percentage
(0.378)
(0.307)
(0.356)
Pre-Waiver NCLB Choice Percentage*NCLB
-0.396**
-0.110
-0.448***
Waiver
(0.151)
(0.142)
(0.147)
-0.024
State School Choice Index
(0.043)
0.009
-0.002
Any Intra-District Open Enrollment
(0.113)
(0.118)
Any Intra-District Open Enrollment* Months
-0.023***
Post Change
(0.007)
0.017
-0.164
Any Inter-District Open Enrollment
(0.092)
(0.109)
Any Inter-District Open Enrollment* Months
0.021*
Post Change
(0.013)
-0.024
0.021
Any Tuition Voucher
(0.127)
(0.132)
Any Tuition Voucher*
0.014
Months Post Change
(0.010)
0.007
0.216***
Any Charitable Scholarship Credit
(0.111)
(0.078)
Any Charitable Scholarship Credit*
-0.024*
Months Post Change
(0.013)
-0.070
0.069
Any Tuition Credit
(0.151)
(0.084)
Any Tuition Credit*
-0.021**
Months Post Change
(0.008)
Any Intra-District Open Enrollment* Months
Pre Change
Any Inter-District Open Enrollment* Months
Pre Change
Any Tuition Voucher*
Months Pre Change
Any Charitable Scholarship Credit*
Months Pre Change
Any Tuition Credit*
Months Pre Change

-0.001
(0.008)
0.046***
(0.013)
-0.012
(0.010)
-0.041***
(0.013)
0.018*
(0.010)

Source: Authors’ estimation of equations (1)-(3) using greatschools.org search data and local school choice policies
as described in the text. All results include only the 39 states for which we have NCLB choice information. The
Search Unit is defined as the CBSA or the county if the area is not in a CBSA. N=50,177. The estimates include
Search Unit, month and year fixed effects. State School Choice Index is a sum of all state choice indicator variables.
“Months pre” and “months post” are the number of months relative to a law change that occurs during our analysis
period. Relative month measures are set to zero in states that do not experience a law change in our sample.
Standard errors clustered at the state level are in parentheses: * indicates significance at the 10% level, ** indicates
significance at the 5% level and *** indicates significance at the 1% level.

38

Table 5. OLS Estimates of the Relationship Between the Choice Environment and Log Total
Searches, Including Leads of NCLB Choice Measures and Month-Year Trends
Independent Variable
(i)
(ii)
(iii)
(iv)
(v)
0.802*
0.809**
0.735**
0.614*
0.610*
District NCLB Choice Percentage
(0.428)
(0.402)
(0.363)
(0.340)
(0.321)
Pre-Waiver NCLB Choice -0.638*** -0.691*** -0.438***
-0.307**
-0.418**
Percentage*NCLB Waiver
(0.181)
(0.160)
(0.136)
(0.143)
(0.190)
1-year Lead District NCLB Choice
-0.162
-0.099
Percentage
(0.799)
(0.770)
1-year Lead Pre-Waiver NCLB Choice
0.152
0.080
Percentage*NCLB Waiver
(0.282)
(0.236)
0.135
0.210*
0.314**
Intra-District Open Enrollment Index
(0.136)
(0.130)
(0.123)
Intra-District Open Enrollment Index*
-0.010
0.039***
0.067***
Months Post Change
(0.014)
(0.012)
(0.013)
-0.139
-0.150
-0.140
-0.212**
Inter-District Open Enrollment Index
(0.146)
(0.114)
(0.118)
(0.106)
Inter-District Open Enrollment Index*
0.039*
0.020
0.020
0.018
Months Post Change
(0.024)
(0.013)
(0.013)
(0.013)
0.629***
0.080
0.136
0.161
Tuition Voucher Index
(0.133)
(0.173)
(0.129)
(0.114)
Tuition Voucher Index*
0.003
0.008*
0.007
0.005
Months Post Change
(0.010)
(0.005)
(0.004)
(0.004)
0.034
0.042
0.018
-0.008
Charitable Scholarship Credit Index
(0.042)
(0.031)
(0.039)
(0.039)
Charitable Scholarship Credit Index*
-0.025
-0.005
0.0005
0.004
Months Post Change
(0.016)
(0.004)
(0.004)
(0.004)
0.007
0.019
0.046
-0.349***
Tuition Credit Index
(0.126)
(0.082)
(0.090)
(0.089)
Tuition Credit Index*
-0.013
-0.011**
-0.007**
-0.005
Months Post Change
(0.009)
(0.004)
(0.004)
(0.004)
Intra-District Open Enrollment Index*
Months Pre Change
Inter-District Open Enrollment Index*
Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit Index*
Months Pre Change
Tuition Credit Index*
Months Pre Change
Month-by-Year Time Trends
Observations

32,561

0.003
(0.004)
0.035*
(0.020)
-0.009
(0.011)
-0.027
(0.019)
0.004
(0.018)

0.002
(0.004)
0.040**
(0.015)
-0.011
(0.010)
-0.034**
(0.014)
0.015
(0.011)

-0.002
(0.004)
0.028
(0.018)
-0.018
(0.011)
-0.038**
(0.018)
0.014
(0.014)

-0.003
(0.005)
0.036*
(0.019)
-0.019*
(0.011)
-0.038**
(0.019)
0.011
(0.014)

32,561

Linear
50,177

Quadratic
50,177

Cubic
50,177

Source: Authors’ estimation of equations (1) and (3) using greatschools.org search data and local school choice
policies as described in the text. All results include only the 39 states for which we have NCLB choice information.

39

The Search Unit is defined as the CBSA or the county if the area is not in a CBSA. The estimates include Search
Unit, month and year fixed effects. “Months pre” is the number of months relative to a law change that occurs
during our analysis period. “Months post” is the number of months after a law change that occurs during our
analysis period. Relative month measures are set to zero in states that do not experience a law change in our
sample. The month-by-year time trends are constructed by creating a variable that is a cumulative count of months
beginning at the first month in the sample. We then control for linear, quadratic and cubic versions of this variable.
Standard errors clustered at the state level are in parentheses: * indicates significance at the 10% level, ** indicates
significance at the 5% level and *** indicates significance at the 1% level.

Table 6. The Relationship Between District Report Card Grades, NCLB Choice
Percentages, and Search Activity
Dependent Variable
Independent
Variable

NCLB Choice
Percentage
(i)
(ii)

Log (Total Searches)
(iii)
(iv)

Log (Total Searches)
(v)
(vi)
(vii)

Grade = B

-0.010
(0.009)

-0.006
(0.087)

0.056
(0.088)

Grade = C

-0.012*
(0.007)

0.168*
(0.086)

0.213**
(0.090)

Grade = D

0.015*
(0.008)

0.103
(0.104)

0.150
(0.107)

Grade = F

-0.004
(0.008)

0.017
(0.099)

0.127
(0.109)

Grade = A or B

0.012
(0.008)

-0.171*
(0.088)

-0.213**
(0.092)

Grade = D or F

0.017**
(0.006)

-0.119
(0.080)

-0.092
(0.081)

District NCLB
Choice Percentage

0.490
(0.538)

Pre-Waiver NCLB
Choice %* Waiver

0.516
(0.541)

0.517
(0.541)

-0.622*** -0.698*** -0.685***
(0.201)
(0.224)
(0.222)

Source: Authors’ estimation using greatschools.org search data, NCLB choice percentages and school district report card grades
as described in the text. All results include only the 10 states for which we have NCLB choice information and school district
report card information: CA, IL, IN, KY, MA, OH, OR, TX, WA, WI. N=13,313. The Search Unit is defined as the CBSA or
the county if the area is not in a CBSA. The estimates include Search Unit, month and year fixed effects. Standard errors
clustered at the Search Unit level are in parentheses: * indicates significance at the 10% level, ** indicates significance at the
5% level and *** indicates significance at the 1% level.

40

Table 7. OLS Estimates of the Relationship Between Choice and Specific Search Terms
Independent Variable
District NCLB Choice Percentage
Pre-Waiver NCLB Choice
Percentage*NCLB Waiver
Intra-District Open Enrollment Index
Intra-District Open Enrollment Index*
Months Post Change
Inter-District Open Enrollment Index
Inter-District Open Enrollment Index*
Months Post Change
Tuition Voucher Index
Tuition Voucher Index*
Months Post Change
Charitable Scholarship Credit Index
Charitable Scholarship Credit Index*
Months Post Change
Tuition Credit Index
Tuition Credit Index*
Months Post Change
Intra-District Open Enrollment Index*
Months Pre Change
Inter-District Open Enrollment Index*
Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit Index*
Months Pre Change
Tuition Credit Index*
Months Pre Change

Charter
0.324
(0.274)
-0.163*
(0.094)
0.037
(0.096)
-0.002
(0.005)
-0.013
(0.087)
-0.004
(0.004)
0.198**
(0.085)
-0.002
(0.002)
0.035
(0.039)
-0.001
(0.002)
-0.111
(0.079)
-0.002
(0.002)

Private
0.084
(0.081)
-0.102
(0.063)
0.025
(0.050)
-0.001
(0.006)
-0.004
(0.044)
0.004
(0.004)
0.079
(0.076)
0.004***
(0.001)
0.031**
(0.016)
-0.002**
(0.001)
-0.039
(0.036)
-0.004***
(0.001)

High
14.367
(11.351)
-5.081*
(2.642)
-1.914
(2.048)
-0.107
(0.128)
1.483
(1.637)
-0.117
(0.127)
0.406
(0.855)
-0.066
(0.047)
-0.075
(0.314)
0.030
(0.032)
0.742
(0.724)
-0.014
(0.013)

Elementary
3.070
(2.497)
-1.171*
(0.606)
-0.524
(0.541)
-0.019
(0.029)
0.409
(0.469)
-0.044
(0.028)
0.275
(0.232)
-0.025*
(0.013)
0.158
(0.135)
0.011
(0.008)
-0.201
(0.298)
0.003
(0.008)

-0.001
(0.002)
-0.012
(0.012)
-0.007
(0.006)
-0.004
(0.011)
-0.003
(0.008)

0.002
(0.001)
0.020**
(0.010)
-0.004
(0.005)
-0.017**
(0.008)
0.013**
(0.007)

-0.017
(0.050)
-0.264
(0.200)
-0.262
(0.163)
-0.152
(0.141)
-0.129
(0.101)

-0.015
(0.011)
-0.044
(0.050)
-0.100**
(0.039)
-0.118***
(0.036)
0.012
(0.020)

Source: Authors’ estimation of equation (3) using greatschools.org search data and local school choice policies as
described in the text. Dependent variables are counts of the number of times each search term is used. All results
include only the 39 states for which we have NCLB choice information. N=50,177. The Search Unit is defined as
the CBSA or the county if the area is not in a CBSA. The estimates include Search Unit, month and year fixed
effects. “Months pre” is the number of months relative to a law change that occurs during our analysis period.
“Months post” is the number of months after a law change that occurs during our analysis period. Relative month
measures are set to zero in states that do not experience a law change in our sample. Standard errors clustered at the
state level are in parentheses: * indicates significance at the 10% level, ** indicates significance at the 5% level
and *** indicates significance at the 1% level.

41

Table 8. OLS Estimates of the Relationship Between the Number of
Charter Schools and Log Number of Searches
Independent Variable
(i)
(ii)
0.053***
0.052***
Number of Charter Schools
(0.005)
(0.005)
0.618**
District NCLB Choice Percentage
(0.276)
Pre-Waiver NCLB Choice
-0.390***
Percentage*NCLB Waiver
(0.128)
0.193
Intra-District Open Enrollment Index
(0.152)
Intra-District Open Enrollment Index*
-0.020
Months Post Change
(0.028)
-0.136
Inter-District Open Enrollment Index
(0.101)
Inter-District Open Enrollment Index*
0.023*
Months Post Change
(0.013)
0.076
Tuition Voucher Index
(0.171)
Tuition Voucher Index*
0.007
Months Post Change
(0.005)
0.027
Charitable Scholarship Credit Index
(0.025)
Charitable Scholarship Credit Index*
-0.005
Months Post Change
(0.004)
0.033
Tuition Credit Index
(0.072)
Tuition Credit Index*
-0.010**
Months Post Change
(0.004)
Intra-District Open Enrollment Index*
Months Pre Change
Inter-District Open Enrollment Index*
Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit Index*
Months Pre Change
Tuition Credit Index*
Months Pre Change

-0.001
(0.004)
0.043***
(0.012)
-0.009
(0.008)
-0.032***
(0.011)
0.016*
(0.009)

Source: Authors’ estimation using greatschools.org search data and local school choice policies as described in the
text. All results include only the 39 states for which we have NCLB choice information. The Search Unit is defined
as the CBSA or the county if the area is not in a CBSA. N=49,733. The estimates include Search Unit, month and
year fixed effects. “Months pre” is the number of months relative to a law change that occurs during our analysis
period. “Months post” is the number of months after a law change that occurs during our analysis period. Relative
month measures are set to zero in states that do not experience a law change in our sample. Standard errors clustered
at the state level are in parentheses: * indicates significance at the 10% level, ** indicates significance at the 5%
level and *** indicates significance at the 1% level.

42

Figure 1. Total Searches by Month
900000
800000
700000
600000
500000
400000
300000
200000
100000
0
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45

Month (1=January 2010)
Source: Monthly search data from greatschools.org from January 2010 through October 2013.

Figure 2. Estimates of District NCLB Choice Percentage Interacted with Month Indicators
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
-0.1

1

2

3

4

5

6

7

8

9

10

11

12

-0.2
Source: Authors’ estimation of equation (3) but including interactions between month and District NCLB Choice
Percentage as well as month and NCLB Waiver status interacted with pre-NCLB Choice Percentage using
greatschools.org search data and local school choice policies as described in the text. The estimates include Search
Unit, month and year fixed effects as well. Each point in the figure shows the estimate from the interaction between
District NCLB Choice Percentage and month relative to January, which is the excluded month. The dotted lines
show the bounds of the 95% confidence interval, which is calculated from standard errors that are clustered at the
state level.

43

** Online Appendix – Not for Publication **

44

Table A-1. State School Choice Regulatory Changes

State
Intra-District Open
Enrollment:
Arkansas

Date of
Change

1/2013

Type of Regulation Change

Repeal voluntary and mandatory
intra-district choice

Inter-District Open
Enrollment:
Arkansas

1/2013

Louisiana

7/2013

New Jersey
Oregon
Virginia

10/2010
8/2010
4/2012

Repeal inter-district choice for
failing and low-income schools
Pass inter-district choice for lowincome schools
Pass voluntary inter-district choice
Pass voluntary inter-district choice
Pass voluntary inter-district choice

Tuition Vouchers:
Colorado
Colorado
Indiana
Indiana
Louisiana
Louisiana
North Carolina
Wisconsin
Wisconsin

6/2011
8/2011
5/2011
8/2011
5/2012
8/2012
1/2013
7/2013
8/2013

Voucher program announced
Voucher program enacted
Voucher program announced
Voucher program enacted
Voucher program announced
Voucher program enacted
Voucher program announced
Voucher program announced
Voucher program enacted

Charitable Scholarship
Credits:
Alabama

1/2013

Louisiana
New Hampshire
New Hampshire
Virginia
Virginia

5/2012
6/2012
1/2013
7/2012
1/2013

Announced and enacted fully
deductible tax credits
Announced and enacted tax credits
Announced tax credits
Enacted tax credits
Announced tax credits
Enacted tax credits

Tuition Credits:
Alabama

1/2013

Indiana

6/2011

Wisconsin

1/2013

Announced and enacted tuition
credits
Announced and enacted tuition
credits
Announced tuition credits
45

Table A-2. OLS Estimates of the Relationship Between the Choice Environment and Log
Total Searches – No Controls
Independent Variable
District NCLB Choice Percentage
Pre-Waiver NCLB Choice
Percentage*NCLB Waiver

(i)
-0.330
(0.855)
0.283
(0.756)

State School Choice Index

Intra-District Open Enrollment Index

(ii)
-0.435
(0.775)
0.398
(0.659)
0.066
(0.041)

(iii)
-0.629
(0.657)
0.478
(0.586)

(iv)
-0.460
(0.701)
-0.001
(0.597)

-0.167
(0.199)

-0.089
(0.189)
-0.010
(0.068)
0.285
(0.375)
0.038
(0.030)
0.085
(0.136)
0.014**
(0.005)
-0.039
(0.055)
0.004
(0.009)
-0.102
(0.134)
-0.016*
(0.009)

Intra-District Open Enrollment Index*
Months Post Change
0.442
(0.295)

Inter-District Open Enrollment Index
Inter-District Open Enrollment Index*
Months Post Change

0.158
(0.130)

Tuition Voucher Index
Tuition Voucher Index*
Months Post Change

-0.027
(0.050)

Charitable Scholarship Credit Index
Charitable Scholarship Credit Index*
Months Post Change

-0.167
(0.127)

Tuition Credit Index
Tuition Credit Index*
Months Post Change
Intra-District Open Enrollment Index*
Months Pre Change
Inter-District Open Enrollment Index*
Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit Index*
Months Pre Change
Tuition Credit Index*
Months Pre Change

0.029
(0.026)
0.022
(0.035)
0.017
(0.019)
0.014
(0.036)
0.026
(0.023)

Source: Authors’ estimation of equations (1)-(3) using greatschools.org search data and local school choice policies as
described in the text. All results include only the 39 states for which we have NCLB choice information. N=50,177. The
Search Unit is defined as the CBSA or the county if the area is not in a CBSA. Months pre is the number of months relative
to a law change that occurs during our analysis period. Months post is the number of months after a law change that occurs
during our analysis period. Relative month measures are set to zero in states that do not experience a law change in our
sample. Standard errors clustered at the state level are in parentheses: * indicates significance at the 10% level, ** indicates
significance at the 5% level and *** indicates significance at the 1% level.

46

Table A-3. OLS Estimates of the Relationship Between the Choice Environment and Log
Total Searches Using Enrollment-based Choice Indices
Independent Variable

(i)
0.716**
(0.374)
-0.408**
(0.149)
-0.038
(0.106)

Tuition Credit Index*
Months Post Change

(ii)
0.696**
(0.345)
-0.445***
(0.135)
0.052
(0.165)
-0.011
(0.017)
-0.059
(0.117)
0.021*
(0.013)
0.107***
(0.034)
0.021***
(0.003)
-0.052
(0.141)
0.017
(0.016)
-0.039
(0.068)
0.005
(0.009)

Intra-District Open Enrollment Index*
Months Pre Change
Inter-District Open Enrollment Index*
Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit Index*
Months Pre Change
Tuition Credit Index*
Months Pre Change

0.002
(0.005)
0.054***
(0.010)
-0.014
(0.009)
-0.048***
(0.015)
0.025***
(0.008)

District NCLB Choice Percentage
Pre-Waiver NCLB Choice
Percentage*NCLB Waiver
Intra-District Open Enrollment Index
Intra-District Open Enrollment Index*
Months Post Change

0.032
(0.099)

Inter-District Open Enrollment Index
Inter-District Open Enrollment Index *
Months Post Change

-0.048*
(0.025)

Tuition Voucher Index
Tuition Voucher Index *
Months Post Change

0.039
(0.102)

Charitable Scholarship Credit Index
Charitable Scholarship Credit Index*
Months Post Change

0.091**
(0.039)

Tuition Credit Index

Source: Authors’ estimation of equations (2) and (3) using greatschools.org search data and local school choice
policies as described in the text. All results include only the 39 states for which we have NCLB choice information.
The Search Unit is defined as the CBSA or the county if the area is not in a CBSA. N=50,177. The estimates include
Search Unit, month and year fixed effects. “Months pre” and “months post” are the number of months relative to a
law change that occurs during our analysis period. Relative month measures are set to zero in states that do not
experience a law change in our sample. Standard errors clustered at the state level are in parentheses: * indicates
significance at the 10% level, ** indicates significance at the 5% level and *** indicates significance at the 1%
level.

47

Table A-4. OLS Estimates of the Relationship Between the Choice Environment and Log Total
Searches per Student
Independent Variable
(i)
(ii)
(iii)
(iv)
0.051*
0.050*
0.052**
0.054**
District NCLB Choice Percentage
(0.026)
(0.026)
(0.026)
(0.025)
Pre-Waiver NCLB Choice
-0.037*** -0.039***
-0.043***
-0.042***
Percentage*NCLB Waiver
(0.011)
(0.011)
(0.012)
(0.010)
-0.002
State School Choice Index
(0.001)
Intra-District Open Enrollment
-0.018***
0.014
Index
(0.006)
(0.009)
Intra-District Open Enrollment
-0.001
Index* Months Post Change
(0.001)
Inter-District Open Enrollment
0.019***
-0.018**
Index
(0.006)
(0.007)
Inter-District Open Enrollment
0.002**
Index* Months Post Change
(0.001)
0.003
0.010
Tuition Voucher Index
(0.020)
(0.022)
Tuition Voucher Index*
0.001**
Months Post Change
(0.0004)
0.0002
0.002
Charitable Scholarship Credit Index
(0.002)
(0.003)
Charitable Scholarship Credit
-0.0006*
Index* Months Post Change
(0.0003)
0.003
0.003
Tuition Credit Index
(0.014)
(0.014)
Tuition Credit Index*
-0.001***
Months Post Change
(0.0004)
Intra-District Open Enrollment
Index* Months Pre Change
Inter-District Open Enrollment
Index* Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit
Index* Months Pre Change
Tuition Credit Index*
Months Pre Change

-0.0005
(0.0003)
0.004
(0.002)
-0.001
(0.001)
0.0003
(0.002)
0.002***
(0.001)

Source: Authors’ estimation of equations (1)-(3) using greatschools.org search data and local school choice policies
as described in the text. The dependent variable is log of per-student searches. All results include only the 39 states
for which we have NCLB choice information, and all estimates include Search Unit, month and year fixed effects.
The Search Unit is defined as the CBSA or the county if the area is not in a CBSA. State School Choice Index is a
sum of all state choice indices that are first converted to standard deviation units. “Months pre” is the number of
months prior to a law change that occurs during our analysis period. “Months post” is the number of months after a
law change that occurs during our analysis period. Relative month measures are set to zero in states that do not
experience a law change in our sample. Standard errors clustered at the state level are in parentheses: * indicates
significance at the 10% level, ** indicates significance at the 5% level and *** indicates significance at the 1%
level.

48

Table A-5. OLS Estimates of the Relationship Between the Choice Environment and Log Total
Searches, Using Only Observations in States that Change Choice Policies
Independent Variable
(i)
(ii)
(iii)
2.371
2.449
2.758*
District NCLB Choice Percentage
(1.657)
(1.636)
(1.515)
Pre-Waiver NCLB Choice
-0.195
-0.163
-0.156
Percentage*NCLB Waiver
(0.207)
(0.217)
(0.135)
0.005
State School Choice Index
(0.014)
Intra-District Open Enrollment
-0.009
0.267***
Index
(0.099)
(0.076)
Intra-District Open Enrollment
0.014
Index* Months Post Change
(0.018)
Inter-District Open Enrollment
0.040
-0.318***
Index
(0.081)
(0.080)
Inter-District Open Enrollment
0.041***
Index* Months Post Change
(0.013)
0.082
0.135
Tuition Voucher Index
(0.213)
(0.233)
Tuition Voucher Index*
0.018***
Months Post Change
(0.004)
-0.025
0.035*
Charitable Scholarship Credit Index
(0.035)
(0.018)
Charitable Scholarship Credit
-0.004
Index* Months Post Change
(0.004)
-0.028
0.055
Tuition Credit Index
(0.079)
(0.056)
Tuition Credit Index*
-0.010**
Months Post Change
(0.004)
Intra-District Open Enrollment
Index* Months Pre Change
Inter-District Open Enrollment
Index* Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit
Index* Months Pre Change
Tuition Credit Index*
Months Pre Change

0.004
(0.006)
0.073***
(0.007)
0.011
(0.007)
-0.028***
(0.007)
0.027****
(0.005)

Source: Authors’ estimation of equations (1)-(3) using greatschools.org search data and local school choice policies
as described in the text. All results include only the 11 states for which we have NCLB choice information and that
experience a law change in the sample period. All estimates include Search Unit, month and year fixed effects.
N=16,704. The Search Unit is defined as the CBSA or the county if the area is not in a CBSA. State School Choice
Index is a sum of all state choice indices that are first converted to standard deviation units. “Months pre” is the
number of months prior to a law change that occurs during our analysis period. “Months post” is the number of
months after a law change that occurs during our analysis period. Relative month measures are set to zero in states
that do not experience a law change in our sample. Standard errors clustered at the state level are in parentheses: *
indicates significance at the 10% level, ** indicates significance at the 5% level and *** indicates significance at the
1% level.

49

Table A-6. OLS Estimates of the Relationship Between the Choice Environment and Log Total
Searches, by Search Area Median Income and Poverty Rate
Below
Above
Below
Above
Independent Variable
Median
Median
Median
Median
Income
Income
Poverty
Poverty
0.298*
1.168**
0.734**
0.724*
District NCLB Choice Percentage
(0.174)
(0.585)
(0.363)
(0.383)
Pre-Waiver NCLB Choice
-0.168
-0.509***
-0.342**
-0.517***
Percentage*NCLB Waiver
(0.110)
(0.168)
(0.145)
(0.165)
Intra-District Open Enrollment
0.106
0.105
0.274***
0.084
Index
(0.099)
(0.162)
(0.117)
(0.160)
Intra-District Open Enrollment
0.004
-0.006
-0.026**
0.009
Index* Months Post Change
(0.008)
(0.021)
(0.010)
(0.016)
Inter-District Open Enrollment
-0.080
-0.140
-0.333***
-0.055
Index
(0.081)
(0.118)
(0.094)
(0.132)
Inter-District Open Enrollment
0.001
0.017*
0.021*
0.019
Index* Months Post Change
(0.009)
(0.010)
(0.013)
(0.013)
-0.153**
0.105
0.077
0.087
Tuition Voucher Index
(0.068)
(0.239)
(0.171)
(0.183)
Tuition Voucher Index*
0.001
0.004
0.008**
0.008
Months Post Change
(0.004)
(0.006)
(0.004)
(0.006)
0.072***
0.038
0.063*
0.025
Charitable Scholarship Credit Index
(0.025)
(0.039)
(0.040)
(0.030)
Charitable Scholarship Credit
0.00003
-0.007
-0.003
-0.007
Index* Months Post Change
(0.002)
(0.004)
(0.003)
(0.005)
-0.266***
0.075
-0.091
0.118
Tuition Credit Index
(0.087)
(0.124)
(0.092)
(0.082)
-0.014***
Tuition Credit Index*
0.002
-0.014***
-0.009***
(0.003)
(0.005)
Months Post Change
(0.004)
(0.005)
Intra-District Open Enrollment
Index* Months Pre Change
Inter-District Open Enrollment
Index* Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit
Index* Months Pre Change
Tuition Credit Index*
Months Pre Change

0.004
(0.004)
0.069**
(0.034)
0.021***
(0.006)
-0.060*
(0.033)
0.076**
(0.034)

-0.001
(0.005)
0.017
(0.015)
-0.011
(0.008)
-0.026*
(0.013)
-0.005
(0.006)

0.003
(0.004)
0.070***
(0.018)
-0.009
(0.009)
-0.036**
(0.015)
0.025*
(0.013)

0.0001
(0.005)
0.030*
(0.015)
-0.011
(0.010)
-0.032*
(0.016)
0.002
(0.009)

Source: Authors’ estimation of equation (3) using greatschools.org search data and local school choice policies as
described in the text. Models are estimated separately by median income per capita in the Search Unit, measured by
the 2012-2014 ACS. All estimates include Search Unit, month and year fixed effects. The Search Unit is defined as
the CBSA or the county if the area is not in a CBSA. State School Choice Index is a sum of all state choice indices
that are first converted to standard deviation units. “Months pre” is the number of months prior to a law change that
occurs during our analysis period. “Months post” is the number of months after a law change that occurs during our
analysis period. Relative month measures are set to zero in states that do not experience a law change in our sample.
Standard errors clustered at the state level are in parentheses: * indicates significance at the 10% level, ** indicates
significance at the 5% level and *** indicates significance at the 1% level.

50

Table A-7. Poisson Estimates of the Relationship Between the Choice Environment and
Search Frequency
Independent Variable

Tuition Credit Index*Months Post
Change

(iii)
0.372
(0.263)
-0.164**
(0.075)
0.146
(0.092)
-0.038***
(0.010)
-0.194**
(0.076)
0.006**
(0.003)
-0.038
(0.050)
-0.002
(0.003)
-0.003
(0.029)
-0.004***
(0.001)
0.033
(0.065)
-0.0003
(0.004)

Intra-District Open Enrollment
Index* Months Pre Change
Inter-District Open Enrollment
Index* Months Pre Change
Tuition Voucher Index*Months
Pre Change
Charitable Scholarship Credit
Index* Months Pre Change
Tuition Credit Index*Months Pre
Change

-0.002
(0.005)
0.071***
(0.015)
0.002
(0.005)
-0.012
(0.010)
-0.004
(0.010)

District NCLB Choice Percentage
Pre-Waiver NCLB Choice
Percentage*NCLB Waiver
Intra-District Open Enrollment
Index
Intra-District Open Enrollment
Index* Months Post Change
Inter-District Open Enrollment
Index
Inter-District Open Enrollment
Index* Months Post Change

(i)
0.373
(0.234)
-0.138*
(0.075)

Tuition Voucher Index
Tuition Voucher Index*Months
Post Change
Charitable Scholarship Credit
Index
Charitable Scholarship Credit
Index* Months Post Change
Tuition Credit Index

Source: Authors’ estimation of equations (1) and (3) using greatschools.org search data and local school choice
policies as described in the text. Estimates are from Poisson models that use the number of searches in a Search Unit
and month as the dependent variable. All results include only the 39 states for which we have NCLB choice
information. The Search Unit is defined as the CBSA or the county if the area is not in a CBSA. Months pre is the
number of months relative to a law change that occurs during our analysis period. Months post is the number of
months after a law change that occurs during our analysis period. Relative month measures are set to zero in states
that do not experience a law change in our sample. Standard errors that are calculated from 200 block bootstrap
replications at the state level are in parentheses: * indicates significance at the 10% level, ** indicates significance at
the 5% level and *** indicates significance at the 1% level.

51

Table A-8. OLS Estimates of the Relationship Between the Choice Environment and Log Total
Searches, All States
Independent Variable
Intra-District Open Enrollment
Index
Intra-District Open Enrollment
Index* Months Post Change
Inter-District Open Enrollment
Index
Inter-District Open Enrollment
Index* Months Post Change
Tuition Voucher Index
Tuition Voucher Index*
Months Post Change
Charitable Scholarship Credit Index
Charitable Scholarship Credit
Index* Months Post Change
Tuition Credit Index
Tuition Credit Index*
Months Post Change
Intra-District Open Enrollment
Index* Months Pre Change
Inter-District Open Enrollment
Index* Months Pre Change
Tuition Voucher Index*
Months Pre Change
Charitable Scholarship Credit
Index* Months Pre Change
Tuition Credit Index*
Months Pre Change
Number of Observations

39 States
(i)
0.202
(0.123)
-0.006
(0.013)
-0.212**
(0.102)
0.018
(0.012)
0.077
(0.168)
0.008*
(0.005)
0.031
(0.032)
-0.004
(0.004)
0.026
(0.086)
-0.012***
(0.004)

51 States
(ii)
0.047
(0.067)
-0.014
(0.011)
-0.091
(0.053)
0.003
(0.003)
0.096*
(0.056)
0.006*
(0.003)
0.036*
(0.020)
-0.003**
(0.001)
-0.027
(0.055)
-0.010***
(0.003)

-0.005
(0.005)
0.039**
(0.017)
-0.011
(0.010)
-0.033**
(0.015)
0.016
(0.012)

-0.007
(0.005)
0.034**
(0.012)
-0.010***
(0.014)
-0.028***
(0.010)
0.015
(0.011)

50,177

72,294

Source: Authors’ estimation of equations (1)-(3) using greatschools.org search data and local school choice policies
as described in the text. All estimates include Search Unit, month and year fixed effects. The Search Unit is defined
as the CBSA or the county if the area is not in a CBSA. State School Choice Index is a sum of all state choice
indices that are first converted to standard deviation units. “Months pre” is the number of months prior to a law
change that occurs during our analysis period. “Months post” is the number of months after a law change that occurs
during our analysis period. Relative month measures are set to zero in states that do not experience a law change in
our sample. Standard errors clustered at the state level are in parentheses: * indicates significance at the 10% level,
** indicates significance at the 5% level and *** indicates significance at the 1% level.

52

