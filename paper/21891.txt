NBER WORKING PAPER SERIES

PROCRASTINATION IN TEAMS
Joshua S. Gans
Peter Landry
Working Paper 21891
http://www.nber.org/papers/w21891
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2016

Thanks to seminar participants at the University of Toronto for helpful comments. Responsibility for
all errors remains our own. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w21891.ack
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2016 by Joshua S. Gans and Peter Landry. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

Procrastination in Teams
Joshua S. Gans and Peter Landry
NBER Working Paper No. 21891
January 2016
JEL No. C72,D03,M11
ABSTRACT
Naively present-biased agents are known to be severe procrastinators. In team settings, procrastination
can represent a form of free-riding that, in excess, can jeopardize a team's ability to meet a deadline. Here
we show how naivete and present bias, despite their reputations, can be desirable traits in a teammate,
enabling a team to optimize its performance while eliminating inefficient free-riding. These benefits
emerge only from a more flexible specification (in comparison to existing models) as to how naive
players reassess prior beliefs upon confronting present bias. By allowing the 'depth' and 'direction'
of such reassessments to vary, our model links present-biased discounting theories to the recently-revived
interest in modeling non-Bayesian reactions to null events, while offering a distinct approach reminiscent
of level-k reasoning. Key themes from our results include the value of behavioral diversity, the opposite
effects of 'introspection' and 'extrospection' on motivation, and that under- and over-thinking can both
undermine efficiency.
Joshua S. Gans
Rotman School of Management
University of Toronto
105 St. George Street
Toronto ON M5S 3E6
and NBER
joshua.gans@gmail.com
Peter Landry
University of Toronto, Dept of Management
Mississauga ON
Canada
Peter.Landry@rotman.utoronto.ca

1

Introduction

Just because a project is known to be worth the effort in the long-run does not
guarantee it will be completed in a timely fashion. According to standard economic
treatments, team projects are particularly prone to inefficiencies of this sort. Holmstrom (1982) showed it is largely impossible to use the value created by a team to
motivate its members due to moral hazard concerns.1 A literature on voluntary public goods contributions has demonstrated similar difficulties in overcoming free-riding
(Bagnoli and Lipman, 1989).2 In many cases, these incentive issues can be further
compounded by the possibility of coordination failure, as it can lead to inefficient
under-provision (or even over-provision) of effort on team projects (Wittenbaum et
al., 1998; Brandts and Cooper, 2006).
In a separate line of research, behavioral economic theories have shown that even
worthwhile individual projects can be derailed, as a consequence of present bias.
Present-biased agents discount future utility at t using the time-inconsistent quasihyperbolic discount function, βδ t , with “present bias factor” β < 1 (Laibson, 1997;
O’Donoghue, 1999, 2001). By reducing the effective weight of future payoffs in
decision-making (relative to a time-consistent evaluation), present bias can, in and of
itself, tempt an agent to put off investing effort on a worthy project. However, this
problem can be severely exacerbated by naive present bias — a situation in which the
agent is oblivious to their present bias until that present arrives. Compared to their
sophisticated counterparts (who correctly anticipate their own time-inconsistency),
naively present-biased agents can better justify putting off a task today based on a
false expectation that they will be motivated to do it tomorrow.3
Given the many obstacles to efficient team production already known to exist with
standard time-consistent agents, it would be natural to expect even worse outcomes
if present bias — especially with naivete — was brought into a team framework. To
look into this further, we develop a model of team collaboration with present-biased
agents who, building on familiar notions of naivete and sophistication from singleagent models, may be naive or sophisticated towards their partners’ present bias
1 For

a recent treatment, see Bonatti and Horner (2011).
note, this literature has shown that designing outcomes to ensure a particular agent is pivotal (that
is, has default control over the outcome) can generate incentives that mitigate inefficiency due to free-riding.
3 While Akerlof (1991) pointed to the role of naivete in a more general sense, the link between procrastination and naivete as it pertains to present bias was formally worked out by O’Donoghue and Rabin (1999).
O’Donoghue and Rabin (2001, 2008) later showed (respectively) that the vulnerability to severe procrastination extends to present-biased agents who exhibit a form of partial naivete and that (full) naivete can
lead to endless procrastination on longer-term projects.
2 Of

1

in addition to their own. To fully translate naive present bias into a team setting,
however, a trickier modeling question arises: how do such agents update their other
beliefs (including higher-order beliefs) when they inevitably discover their own present
bias?
To understand this technical challenge in our setting, first consider a familiar
situation in which two co-authors — Alice and Bob — are collaborating on a critical
and time-sensitive research project. At present, Alice and Bob are each deciding
whether or not to exert effort on a task that will bring the project closer to completion.
Since effort is costly, both co-authors have an incentive to minimize their contribution
to the project — provided it still gets done — creating a potential for free-riding. For
instance, if Bob chooses to put off doing a task, Alice will be forced to undertake
additional tasks to ensure the project is completed on time. Thus, there can be a
strategic advantage to procrastination in that it can allow an agent to economize on
their task share, but procrastination by both co-authors can prevent the team from
being able to meet its deadline.
Next, suppose Alice is fully naive in that, prior to facing her present decision, she
believed that both she and Bob would be time-consistent (and that this was common
knowledge). Now that the decision has arrived, however, Alice discovers that she
is in fact present-biased. While re-computing her optimal strategy in light of this
unexpected discovery, Alice may revisit her other prior assumptions. For instance,
she may ask herself, if I am present-biased, does this mean Bob is too? Alice may
also wonder, does Bob know that I am present-biased? If Alice concludes that the
answer to either (or both) of these questions is ‘yes,’ we say that she has reassessed
(i.e. reversed) her associated prior belief — and all of Alice’s infinite higher-order
prior beliefs are also subject to reassessment in this sense. To complicate matters
significantly, Alice cannot turn to Bayes’ Rule to resolve such questions. That is,
Alice was certain that she would not be present-biased, but Bayes’ Rule does not say
anything about how beliefs should be updated in response to ‘null’ events such as
this, to which the agent previously assigned zero-probability.
To address these issues, we formalize a tractable yet flexible “sequential reassessment” rule in which naive agents, upon confronting their own present bias, reassess
their prior beliefs about each players’ time-(in)consistency up to — but not beyond
— a given depth (i.e. order) between zero and infinity. Alice’s posterior, decisionrelevant beliefs can therefore be summarized by two numbers: the depth of her ‘inward’ reassessment regarding her own present bias and the depth of her ‘outward’

2

reassessment concerning Bob’s present bias. In turn, these numbers determine the
overall direction of Alice’s reassessment. That is, Alice is either considered more
‘introspective’ or ‘extrospective,’ on balance, depending on whether her inward or
outward reassessment is deeper.4
A main implication of our model is that, contrary to what one might expect,
introducing naively present-biased players into a team setting can allow a team to
optimize its performance while overcoming inefficient free-riding (and related coordination issues) that would otherwise exist. In establishing this and other results, the
model demonstrates the importance of its unique behavioral elements arising from
our novel sequential reassessment approach to confronting naive present bias, as the
depths and directions of such reassessments prove to be critical determinants of both
individual behavior and team efficiency. For example, we find that ‘extrospection’
(in the sense described above) will motivate a naively present-biased agent to overcome their infamous tendency to procrastinate, while ‘introspection’ has the opposite
effect. Moreover, a team with two naively present-biased agents will achieve full efficiency in our setting if and only if players are diverse in this regard. This prediction
speaks to a recurring theme in our model: that the ability of a team to work together
often depends on its precise composition. The result also offers a contribution to
the theoretical literature on the value of diversity, as it highlights a novel channel —
variation in the directions of naive agents’ reassessments — that can improve team
functionality in the absence of more familiar channels, such as diversity in skillsets or
technical knowledge.5
There have been a few models to date that have considered what happens when
(possibly naive) present-biased agents interact. However, these models make nonobvious (in our view) simplifying assumptions that sidestep thorny questions about
agents’ higher-order beliefs, and in doing so, preclude the forms of behavioral variation
that prove important in our model.6 In the language of our earlier example, these
4 Yes,

this is actually a word. See http://dictionary.reference.com/browse/extrospective.
composition of well-functioning teams has been at the heart of economics since Adam Smith’s
‘division of labor.’ Based on productive efficiency alone, there are gains from having a diverse set of skills
among team members. (See, for example, Becker and Murphy, 1992). Indeed, much of the research outside
of economics on diversity and team functionality has been based on the theoretical proposition that diversity
can provide a team with different information and insights, as well as the appropriate compositions of skills
for various tasks that need to be accomplished. (See for instance, the comprehensive review of that literature
by Mannix and Neale, 2005).
6 In an unpublished paper, Sarafidis (2006) examines the interaction of naive and sophisticated agents
and highlights when predictions are likely to differ from games with time-consistent agents. Akin (2009)
develops this further, exploring when such agents may generate inefficient outcomes in alternating-offer
bargaining games. Finally, Haan and Hauck (2014) highlight the need to consider present-biased agents’
assumptions about the time-consistency of agents they interact with. Although they focus on sophisticated
5 The

3

models effectively assume that Alice would reassess all of her prior beliefs, concluding
that both she and Bob are time-consistent (and that this is common knowledge) —
which is precisely the opposite of what she believed prior to confronting her present
bias.7 In our model, however, we take seriously the notion that naive agents may
revise their prior beliefs in other ways.
This paper proceeds as follows. In the next section, we introduce a simple, two
person, multiple task environment. Our goal here is to keep the underlying environment simple so as to place our analytical attention on the belief structure (on this
dimension, we aim for generality). Here we also describe our notion of perceptionperfect equilibrium in the underlying dynamic game that itself is a natural extension
of perception-perfect strategies considered by O’Donoghue and Rabin (1999, 2001).8
Section 3 characterizes the equilibrium strategies and outcomes that arise in teams
with fully naive agents who do not anticipate either their own or their partner’s
present bias. It is there that we introduce our key concept — sequential reassessment
— while showing how the team can achieve efficiency if its members vary in the direction of their reassessments. Section 4 then incorporates various forms of sophistication
into the framework. In particular, ‘self-sophisticated’ agents hold correct beliefs (including higher-order beliefs) about their own present bias and ‘other-sophisticated’
agents hold correct beliefs about their partner’s present bias. Sophistication can both
help and hurt the performance of a team depending on the precise nature of players’
sophistication as well as the composition of the team. While it is difficult to succinctly summarize these relationships, the key to assembling an efficient team is to
find agents who agree on their ‘differences’ at some level even if their exact beliefs
are incompatible — as was the case in Section 3.
As discussed at greater length in Section 5, our model provides a bridge between
established theories of present-biased discounting and the recently-revived decisiontheoretic interest in non-Bayesian updating in response to null events. Besides our
new application to present bias, sequential reassessment represents a distinct approach
agents, Brocas and Carrillo (2001) provide an earlier model of present bias in the context of both competitive
and cooperative projects, showing how competition can alleviate inefficiency stemming from a tendency to
procrastinate and also from a tendency to rush.
7 Technically, these papers generally achieve this by assuming that, when the present arrives, naive agents’
present biases are publicly observable or otherwise common knowledge. Why this would be so is not discussed.
Unlike conventional assumptions of common knowledge regarding players’ preference parameters, common
knowledge in this context entails a sudden reversal of beliefs, and hence learning, which requires an observable
signal of some sort (but it is not clear what this signal would look like or where it comes from). Nonetheless,
this has the effect of making it common knowledge that agents are present-biased and so there are no
questions regarding higher-order beliefs.
8 See also, Haan and Hauck (2014).

4

to this problem, which we compare and contrast to the treatments of Ortoleva (2012)
and Karni and Viero (2013). As formalized in our model, sequential reassessment
could also be cast as an extension of level-k reasoning models into the domains of
present bias and non-Bayesian updating in response to null events. Level-k models
posit that players’ beliefs (and strategies) are anchored to some naive prior held
by a “level-0” player such that a level-1 player best-responds to the strategy of a
level-0 player, a level-2 player best-responds to a level-1 player, and so on.9 Under
(finite) sequential reassessment, naively present-biased agents similarly believe they
are one step ahead of their partner and best-respond accordingly. Unlike standard
applications of level-k reasoning, however, we consider players’ ‘thought processes’ in
two opposing dimensions — ‘introspection’ and ‘extrospection,’ as we have labeled
them — while demonstrating the behavioral relevance of this distinction.
Although we believe naive present bias to be the most natural and well-grounded
motivation, sequential reassessment could in principle be applied by players who confront false preconceptions regarding any utility parameter. Building on this observation, in Section 6 we show how our framework can be collapsed to a strategicallyequivalent static game with the payoff structure of a two-player volunteer’s dilemma.
We then entertain one potential interpretation of “payoff naivete,” as it arises in
this context, that relates to biases in the maintenance of a positive self-image. By
viewing the model through this lens, we can relate our approach to established psychological concepts and also to some economic theories of overconfident (or otherwise
overoptimistic) players in team-like settings.

2

Model

We study a dynamic game of collaboration on a multi-task project. To focus on the
simplest nontrivial case of the general game we have in mind, we model a two-player
team that has two periods to complete a project that consists of three identical tasks.
In each period, t = 1, 2, players simultaneously choose whether or not to complete
a single task. Any such task requires an effort cost c > 0 and can be completed
by either player, although each player can only complete one task per period, while
9 See the models of Nagel (1995), Stahl and Wilson (1995), Costa-Gomes et al. (2001), Costa-Gomes and
Crawford (2006), and the closely-related ‘Cognitive Hierarchy’ model of Camerer et al. (2004). Real-life
players in normal form games do appear to exhibit a limited depth of reasoning in the manner suggested
by these models, as many empirical and experimental studies show that level-k reasoning often out-predicts
models based on standard equilibrium concepts (for a review, see Crawford et al., 2013).

5

each player receives a payoff equal to 1 if and when the project is completed.10 It is
important to note that it is always possible to complete a task — even in excess of
the number required for the project. Thus, if both players choose to exert effort in
both periods, there is an inefficient overprovision of effort as four tasks are completed
for a project that only requires three (certainly, there can be underprovision too, as
would be the case if the team collectively completes less than three tasks by the end
of the final period).
We assume that both players have time-inconsistent preferences whereby future
utility is discounted by a common present-bias factor β < 1.11 For simplicity, future utility is not discounted other than through this present bias.12 We want to
consider projects that are worth the effort to complete, even from the present-biased
perspective of a player who ultimately exerts effort in both periods. Therefore, we
β
assume c <
, which ensures that the player’s discounted payoff (β) exceeds the
1+β
discounted sum of the effort costs (c + βc) in this full-effort scenario.13
A distinction that is commonly made — and has proven to be behaviorally important — in single-agent models with present-biased discounting is whether the
individual is a “sophisticate” who correctly believes that they will be present-biased
in future periods, or a “naif” who is oblivious of their own future present bias until
that future “present” arrives. Translating these standard notions of naivete and sophistication into our multi-agent setting (where each player’s beliefs and higher-order
beliefs regarding both players’ present biases need to be specified) represents a whole
and messier-than-expected can of worms. In subsequent sections, we will do our best
to slowly and carefully peel this can open, and in doing so, we will characterize be10 By modeling a three-task project in this timeframe (and bearing in mind the implied labor capacity
constraint), we can consider inefficiencies due to free-riding and coordination failure while preserving the
notion that a team can actually create value. For a four-task project, there would be no incentive to
procrastinate. With two tasks, a team would serve no purpose since any one player would be able to
complete the task without the help of a teammate (and, in doing so, the threats to efficiency that exist in
team settings would be negated).
11 As we will see, solving our model with two present-biased players will require us to first characterize
the equilibria for the cases in which one or both players are time-consistent (i.e. β = 1). Therefore, even
with the assumption that both players are present-biased, we will be able to derive predictions involving
(hypothetical) time-consistent players along the way.
12 Since we are only considering a two-period model, the only relevant discount is the weight of β on utility
at t = 2, from the perspective at t = 1. In and of itself, this present bias would have the same effect if
it was conceived as a standard, exponential discount factor. While we could, in principle, consider naive
beliefs with respect to a standard discount factor, we do not adopt this interpretation because it is only
conventional to consider such naivete with respect to present-biased discounting.
c
13 Alternatively, we can express this condition as β >
, and interpret it as an assumption that the
1−c
present bias is mild enough to ensure that a time-inconsistent player prefers to have the project completed
even if it requires effort in both periods.

6

havior over a large range of time-inconsistent “types.” As will later become clear,
we will be able to formally express all of this diversity as variation in players’ beliefs
(importantly including higher-order beliefs) at the time choices are made, regarding
both player’s present biases. While we will put more structure on these beliefs later
(informed by established notions of naivete and sophistication), for now we formalize
them as follows.
2.1

General Formulation of Beliefs

For a given player, let µ = (µO ; µI ) denote their full set of beliefs regarding the
present biases (or lack thereof) of both players. In particular, µO = (µO (1), µO (2), . . .)
denotes outward beliefs pertaining to the other player’s present bias factor and µI =
(µI (1), µI (2), . . .) denotes inward beliefs pertaining to one’s own present bias factor,
where the argument n in µO (n) or in µI (n) connotes the degree of the associated
belief. Formally, these first-degree beliefs are defined as:
µO (1) = B

⇔

I believe my partner’s present-bias factor is B,

µI (1) = B

⇔

I believe my partner believes my present-bias factor is B,

(1)

where, for reasons that will soon be evident, we will restrict B ∈ {β, 1}. For each
z ∈ {O, I}, higher-degree beliefs are then defined recursively by:
µz (n + 1) = B

⇔

I believe my partner believes µz (n) = B, n = 1, 2, . . .

Thus, if µO (1) = β but µO (2) = 1, for example, the player whose beliefs are given
by µ believes that their partner is present-biased, but also believes that their partner
doesn’t know they knows this.14
Finally, we can also let µI (0) = β denote the player’s belief regarding their own
present bias where, unlike other beliefs defined above, it is necessarily correct because
a player must be aware (even if it is a brand new discovery) of their own present bias
at the time of their choice. That said, a player may believe their partner is timeconsistent (i.e. if µO (1) = 1). Thus, although we assume players are present-biased,
we will need to characterize the equilibrium strategies of hypothetical time-consistent
players for whom µI (0) = 1. Note, in either case, µI (0) will be interpreted as the
(actual or hypothetical) player’s true present-bias factor and is therefore excluded
14 Translating high-enough order beliefs into easy-to-grasp (and keep track of) language can be hard, so
we will keep our illustrative examples as simple as possible.

7

from the inward-belief vector, µI .
For the player with beliefs µ, let µ̃0 = (µ̃0O , µ̃0I ) denote their beliefs regarding
their partner’s beliefs, and let µ0 = (µ0O , µ0I ) denote their partner’s true beliefs. The
(original) player’s beliefs regarding their partner’s beliefs, µ̃0 , are uniquely determined
from µ using:
µ̃0O (n) = µI (n),

and µ̃0I (n) = µO (n + 1),

for all n = 1, 2, . . .

(2)

To see why µ̃0O (n) = µI (n) holds for the simplest case with n = 1, first recall if Alice is
the player whose beliefs are given by µ and Bob is her partner, then from equation (1)
we see that µI (1) = B means that Alice believes that Bob believes that her present
bias factor is B. Now µ̃0O (1) = B means that Alice believes µ0O (1) = B. Since µ0O (1)
means that Bob believes that Alice’s present bias factor is B, it follows that if Alice
believes this, i.e. if µ̃0O (1) = B, this means exactly the same thing as µI (1) = B. The
validity of the second expression in equation (2), µ̃0I (n) = µO (n + 1), can be verified
in a similar fashion. Lastly note, we can also define µ̃0I (0) = µO (1), which represents
(in this case) Alice’s belief regarding Bob’s present-bias factor.
To simplify our analysis while isolating the effect of µ on behavior, we rule out all
possible bases for heterogeneity in behavior besides those attributable to differences in
µ. Put differently, two players with the same beliefs µ and in the same (sub)game will
employ the same strategy.15 Moreover, since players’ present biases and associated
beliefs are irrelevant at t = 2 — recall, both the effort cost and potential payoff are
realized immediately — we presume all players have identical strategies at t = 2,
which will allow us to focus predominantly on how beliefs matter for behavior at
t = 1.16
2.2

Equilibrium Behavior

We assume players’ strategies are perception-perfect in that a player chooses the optimal action given their current preferences, their perceptions of what their partner’s
current action will be, and their perceptions of them and their partner’s future ac15 As seen in Section 3 and 4, we will allow players to differ with respect to their statuses as naive or
sophisticated (including forms of partial naivete/sophistication), but individual variation stemming from
these differences will be entirely captured by variation between µ and µ0 . That said, when expanding our
analysis to include hypothetical time-consistent players, whether or not a player is present-biased will surely
also be a permissible basis for differences in behavior.
16 The simplifications also allow us to abstract from potentially thorny questions related to learning that
are outside the scope of this paper. For instance, if a player’s beliefs at t = 1 are contradicted by their
partner’s chosen action, it is not obvious how or whether such beliefs at t = 2 might change.

8

tions.17 A player’s “perceptions” in this sense, while not necessarily correct, will just
be a straightforward extrapolation of what would happen given their beliefs µ (which
are also not necessarily correct).
In any subgame at t = 2 (where a subgame at t = 2 is uniquely defined by
the number of tasks completed in t = 1), this perception-perfect solution concept
effectively reduces to static Nash equilibrium since µ and µ0 only matter at t = 1
(recall, all possible costs and payoffs associated with actions at t = 2 are experienced
immediately and thus how players discount the future is of no consequence at this
stage of the game). We can therefore fully characterize the equilibrium strategies
at t = 2 in each possible subgame without worrying about players’ “types.” To
start, if three tasks remain at t = 2, effort is futile, so both players optimally shirk.
Since we are abstracting from variation in strategies besides those stemming from
differences in µ (which only matter at t = 1), players play the symmetric equilibrium
in the other potential subgames at t = 2. Consequently, if one task remains, both
players mix, exerting effort with probability 1 − c — this is the unique symmetric
equilibrium. If two tasks remain, however, there are multiple symmetric equilibria,
so we assume players follow the Pareto-dominant such equilibrium in which both
players exert effort, guaranteeing completion of the project.18 Of note, if the project
is still feasible in that either one or two tasks remain, then the per-person expected
continuation payoff at t = 2 is 1 − c.
As for the problem at t = 1, if a player believes their partner will exert effort with
probability p, the perceived expected values of exerting effort and of shirking are
−c + β(1 − c) and p · β(1 − c), respectively. Following the discussion above, if a player
perceives their partner as being the same type — i.e. if µ = µ̃0 and µI (0) = µ̃0I (0) = β
c
— then they will exert effort at t = 1 with probability 1 − β(1−c)
, while believing their
partner will do the same. Similarly, a hypothetical time-consistent player who believes
their partner is also time-consistent and has identical beliefs will (hypothetically) mix
c
at t = 1 with probability 1 − 1−c
.
Besides isolating the effect of µ on behavior (i.e. only permitting heterogeneity
in players’ strategies when there is heterogeneity in players types), our focus on the
unique, symmetric mixed-strategy equilibria in cases where players perceive their
partners as the same type is motivated by additional considerations. One such moti17 This

is essentially O’Donoghue and Rabin’s (1999, 2001) solution concept, extended to a multi-agent
setting.
18 This equilibrium selection rule can also be motivated by the fact that, for a player who believes their
partner is going to shirk, exerting effort at t = 1 is only a best-response if both players exert effort in the
subgame at t = 2 in which two tasks remain.

9

vation stems from a property of our game (to be discussed at greater length in Section
6) by which it can be collapsed to a strategically-equivalent static game featuring the
payoff structure of a two-player “volunteers dilemma.”19 In the volunteers dilemma,
players choose whether or not to make a costly sacrifice to provide a public good —
such as witnesses to a crime-in-progress choosing whether or not to alert the police. A
key aspect of this game is that only one volunteer is needed, so the Pareto-dominant
Nash equilibrium involves free-riding from all but one player. Observations from the
laboratory and the field, however, reveal a surprisingly high-incidence of outcomes in
which no one volunteers to thwart the crime, which suggests that players often fail to
select this efficient pure-strategy equilibrium, opting for a mixed-strategy equilibrium
instead.20
Apart from the tractability- and empirically-based considerations mentioned above,
our focus on the unique, symmetric mixed-strategy equilibria for homogeneous teams
can also be justified on the grounds that the alternative is trivial and uninteresting. In
particular, if we assume that players can reliably select the asymmetric, pure-strategy
equilibrium — perhaps through some costless communication device — in which the
project is always completed without any excess effort expenditure, then the team
functions perfectly and there is no ‘problem’ in need of a solution. Furthermore, in
our framework, teams would always select this equilibrium regardless of their composition. Thus, the alternate selection rule would prevent us from using the framework
to consider the challenges that free-riding and procrastination — and of present bias
more generally — can pose to team functionality, while precluding the potential for
remedies through forms of behavioral diversity.21
2.3

Motivation and Efficiency

The first of two key questions the model will be used to answer is: how does a player’s
beliefs, µ, influence their behavior? Since all players are, in effect, identical at t = 2,
19 Specifically,

the t = 2 subgame with one task remaining is isomorphic to a static, two-player volunteer’s
dilemma and, given the unique and symmetric mixed-strategy equilibria is selected in this subgame, the
payoff structure for the t = 1 subgame is likewise equivalent to that of a volunteer’s dilemma.
20 Darley and Latane (1968) provide early evidence of this well-known “bystander effect” leading to novolunteer outcomes, and show that the effect is actually exacerbated as the number of players increases. For
a review of such evidence and discussions of their theoretical implications, see Diekmann (1985, 1993) and
Franzen (1999).
21 The results of our model would be qualitatively robust to a generalization in which players select asymmetric pure-strategy equilibria and symmetric mixed-strategy equilibria with respective exogenous probabilities 1 − q and q for some q ∈ (0, 1). Since any two teams would generate the same outcome with probability
1 − q, the directions of our predictions would be preserved, while the expected magnitude of such effects
would be weighted by q.

10

we will focus on how, at t = 1, µ determines a player’s “motivation” in the following
sense:
Definition A player is motivated (at t = 1) if their strategy is to exert effort. A
player is unmotivated if their strategy is to shirk. A player is neither motivated nor
unmotivated if their strategy is to mix.
Until we put more structure on µ, we will not be able to say much about a player’s
motivation. With that said, the following lemma holds universally, and will help us
prove and provide intuition for later results. All proofs are in the appendix.
Lemma 1 A player is motivated if they believes their partner is unmotivated, and
unmotivated if they believes their partner is motivated.
The second key question the model will be used to answer is: under what circumstances is a team efficient? Put differently, what types of players should be paired
together to ensure the first-best outcome? Again, we can only say so much at present,
but the following lemma will be helpful in proving and understanding later results
characterizing a team’s efficiency:
Lemma 2 A team is efficient (in that it always achieves a first-best equilibrium) if
and only if one player is motivated and the other player is unmotivated.
Thus, an efficient team is necessarily “diverse” with respect to players’ motivational
dispositions, but what this actually means in terms of players’ beliefs as captured by
µ and µ0 or in terms of the nature of their naivete and/or sophistication has yet to
be determined. Note, in this first-best equilibrium, one out of two players completes
a task at t = 1, and then both players complete a task at t = 2 so that the project
is successfully completed without overprovision of effort. Since both players must
behave differently at t = 1 to achieve this outcome, we can immediately establish the
following important implication of Lemma 2:
Corollary 1 Any team comprised of players with “symmetric” beliefs in that µ = µ0
is inefficient.
Although we still have a long way to go in determining what it takes for a team to
be efficient, Corollary 1 provides a helpful start by telling us that we can rule out any
team in which both players are of the same type. That is, for a team to be efficient,
players’ must have asymmetric beliefs in that µ 6= µ0 .22
22 Note

here, that “symmetric” beliefs are not necessarily the same in the sense that both players agree

11

3
3.1

Teams with (Fully) Naive Players
Reassessing Naive Preconceptions

The first category of players we consider are those who are “fully naive” in that they
do not anticipate their own present bias nor do they anticipate their partner’s present
bias. To distinguish them from other types of time-inconsistent types considered later,
each of these fully-naive players will simply be referred to as a naif, where we will
proceed for now under the assumption that both players are naifs in this sense.
The language used in our motivating definition of “naivete” above reflects a very
standard concept from existing models of present-biased discounting, but it will need
to be further refined in the current framework in which a player’s type will ultimately
be defined by their beliefs, µ, on which they base their decision of whether or not to
exert effort. Thus, to help formally capture what such naivete actually means in the
current framework, we specify that a naif’s preconception before each period is that
neither they nor their partner are present-biased and that this is common knowledge.
Put differently, prior beliefs — including all higher-order beliefs — regarding them
and their partner’s present bias factors are all equal to 1. However, at the beginning of
a period, a naif unexpectedly learns of their own present bias, so that their updated,
choice-relevant belief regarding their own present bias factor is µI (0) = β < 1. At
this point, the naif may then be compelled to reassess their other preconceptions,
but Bayes’ rule gives no guidance on how or whether their beliefs change because
this discovery of their own naivete is an event to which they previously assigned
zero probability.23 At the lowest degree, for example, a naif may wonder, “does my
partner know that I have a present bias” or “does my partner also have a present
bias?” and their answers to these questions determine µI (1) and µO (1), respectively.
Thus, for this case of a naive player, we can regard µ as their beliefs regarding
both players’ present biases (or lack thereof) following a possible reassessment of
their preconceptions. Since a naif’s preconceptions are that both players are timeconsistent and that this was common knowledge, if a belief µz (n), z ∈ {O, I} has not
on everything, while “asymmetric” beliefs are not necessarily different in the sense that players disagree on
something. Instead, symmetry is used to describe the case in which a player’s beliefs are a mirror-image of
their partner’s. That is, if you and I are partners, our beliefs are symmetric if I would describe my beliefs
(including higher order beliefs) in exactly the same way as you would describe yours. For example, if I
believe that you believe that I am present biased, then you too would say “I believe that you believe that
I am present biased,” except from my perspective this actually means that you believe that I believe that
you are present biased.
23 While our extension to time-inconsistent preferences is novel, Ortoleva (2012) and Karni and Viero (2013)
axiomatically investigate non-Bayesian updating of this sort. See Section 5 for a more detailed discussion.

12

been reassessed, then µz (n) = 1. If, however, the belief has been reassessed, we take
this to mean that µz (n) = β.24,25
Assumption 1 If a belief is not reassessed, corresponding higher-order beliefs are
also not reassessed: µz (n) = 1 implies µz (n+k) = 1, for any n, k ≥ 1 and z ∈ {O, I}.
Put differently, a higher-order belief can only be reassessed if its corresponding
lower-order beliefs have been reassessed — a property we refer to as sequential reassessment. The idea here is that, if discovering one’s own present bias doesn’t
prompt a naif to reassess a given preconceived belief, it is unlikely the naif would
have revisited whether or not their partner believes they reassessed this preconception which wasn’t actually reassessed. Although we believe this to be a natural and
intuitively appealing restriction, Assumption 1 can also be relaxed significantly with
the main results intact (see Appendix A.16). Also see Section 5 for a discussion on
how sequential reassessment, as formalized here, can be motivated as an application
(and generalization) of level-k reasoning theories.
Let RO , RI ∈ {0, 1, . . .} denote the depths of outward and inward reassessments,
respectively. Formally, for z ∈ {O, I},




0,
Rz =
n ∈ {1, 2, . . .},


+∞,

if µz (n) = 1, for all n = 1, 2, . . .
if µz (m) = β if and only if m ≤ n
if µz (n) = β, for all n = 1, 2, . . .

(3)

0
Similar to our definitions of µ̃0 = (µ̃0O , µ̃0I ) and of µ0 = (µ0O , µ0I ), we also use R̃O
and

R̃I0 to denote the player’s beliefs regarding the depths of their partner’s outward and
0
inward reassessments, respectively, and RO
and RI0 to denote the true depths. We
0
and R̃I0
can also observe, from our definition of µ̃0 along with equation (3), that R̃O
are uniquely determined from RO and RI by:
0
= RI ,
R̃O

and R̃I0 = max{RO − 1, 0}.

24 The unexpected discovery of one’s own present bias β < 1 can be regarded as a paradigm shift where
the naif no longer implicitly assumes that everyone’s present bias factor is 1 (i.e. that everyone is timeconsistent), but is now confronted with the new knowledge that β is also a possible value for a present bias
factor, so that if µz (n) is reassessed, this means they have abandoned their corresponding preconception and
now assigns µz (n) = β.
25 This simplifying (and, in our view, intuitively reasonable) assumption can be relaxed significantly without
compromising the main results. In particular, Appendix A.16 demonstrates that the model’s predictions
hold as long as the highest-degree reassessments in each “direction” (i.e. inward and outward) are on [β, 1).
For example, µO = (β, β, 1, 1, . . .) has the same implications for behavior as µO = (µO (1), µO (2), 1, 1, . . .),
as long as β ≤ µO (2) < 1 (and where µO (1) could be any value).

13

We now introduce the following terminology to help us categorize naifs based on
the overall extent to which they reassess their preconceptions:
Definition Unlimited reassessment means RI = RO = +∞. Limited reassessment
means either RI < +∞ or RO < +∞ (or both). Zero reassessment, a special case of
limited reassessment, means RI = RO = 0.
Additionally, we can classify naifs for which reassessment is limited based on the
overall “direction” of their reassessments:
Definition A naif’s reassessment is strictly inward if RI > RO and strictly outward
if RO > RI . Accordingly, a naif’s reassessment is weakly inward if it is limited with
RI ≥ RO , and weakly outward if it is limited with RO ≥ RI . Colloquially, we may
think of a naif with inward reassessment as more ‘introspective,’ on balance, and a
naif with outward reassessment as more ‘extrospective.’
3.2

Results for Naifs

The first result of this section establishes necessary and sufficient conditions for a naif
to be motivated and to be unmotivated, based on the direction of their reassessments:
Proposition 1 A naif is motivated if and only if their reassessment is strictly outward, and unmotivated if and only if their reassessment is weakly inward.
This results highlights the polar effects of ‘introspection’ and ‘extrospection’ — taken
here to mean inward and outward reassessment – on individual motivation. Namely,
introspection in this sense can only serve to demotivate a naif, while extrospection
can generate the motivation necessary to overcome procrastination.
Since a team is efficient if and only if one player is motivated and the other is
unmotivated (Lemma 2), we can establish the following corollary to Proposition 1.
Corollary 2 A team with two naifs is efficient if and only if one player’s reassessment
is weakly inward and the other player’s reassessment is strictly outward.
Thus, in a team with two naifs, efficiency requires a new and perhaps unusual form
of diversity whereby players must differ with respect to the overall direction with
which they reassess their naive preconceptions. Put differently, the team maximizes
its performance if one player is introspective and the other is extrospective.
The next two corollaries take stock of the most extreme types of naifs — extreme
in terms of the depths of their reassessments. In doing so, we will see how there can
14

be both too little and too much collective reassessment of naive beliefs in a team with
two naifs.
Corollary 3 Nonzero reassessment is a necessary condition for a naif to be motivated. Therefore, in a team with two naifs, nonzero reassessment by at least one
player is a necessary condition for efficiency.
Corollary 4 Under unlimited reassessment, a naif is neither motivated nor unmotivated. Therefore, any team is inefficient if it includes a naif with unlimited reassessment.
Taken together, Corollaries 3 and 4 indicate that a team of naifs can only be
efficient if some preconceptions are reassessed while other preconceptions are not
reassessed. Put differently, collective ‘under-thinking’ in a team can prevent efficient
outcomes — but so can collective ‘over-thinking.’
3.3

Outcomes with (Hypothetical) Time-Consistent Teammates

Next we compare teams with two naifs to teams with one or more time-consistent
players (TCs) who are not present-biased and also assumed to hold correct beliefs
regarding both players’ present biases (or lack thereof).26 These comparisons are
straightforward because, in computing naifs’ perception-perfect equilibrium strategies, we first needed to characterize equilibrium behavior in hypothetical teams with
one or more TCs (as evident in the proof of Proposition 1). For example, a naif with
zero outward reassessment believes their partner is a TC and thus must ascertain how
a TC would behave in order to determine their perception-perfect best-response.
Corollary 5 A (hypothetical) team with one TC and one naif is efficient if and only
if the naif ’s reassessment is limited. With two TCs, the team is inefficient.
Hence, a team that lacks present bias is inherently inefficient, but this inefficiency
can be overcome by replacing one TC with a naif, as long as the naif’s reassessment
is not unlimited. This reliance on limited reassessment is noteworthy in part because
existing approaches to modeling naive present bias in multi-player games implicitly
26 Relaxing

this (standard) assumption may strengthen our main results. For example, suppose a team
includes a TC who believes, perhaps incorrectly, that their partner is also time-consistent (and that this
is common knowledge). Then the team must be inefficient because the TC will be neither motivated nor
unmotivated (as would also be the case with two TCs). Thus, if TCs were ‘unsophisticated,’ efficiency would
require two present-biased players, as opposed to the current formulation in which only one is needed (as
will be seen in Corollary 5).

15

assume that naive reassessments are, in effect, unlimited — an assumption that would
conceal a naif’s potential value as a teammate in our setting. Also note, the capacity
of the mixed team to attain the first-best outcome does not depend on the direction
of the naif’s (limited) reassessment, although the direction does determine (in the
manner predicted by Proposition 1) which player gets to economize on their task
share by procrastinating at t = 1 and which player is on the hook for exerting effort
in both periods.27

4

Teams with Sophisticated Players (Partial and Full)

In this section, we relax our previous restriction that players are fully naive by allowing for various forms of sophistication. As a starting point, we can consider a
standard, single-agent notion of sophistication as correctly anticipating one’s own
present bias prior to the present. However, for a variety of reasons, this notion will
have to be refined and expanded in the current framework. First, we will now want
to consider sophistication with respect to both one’s own and one’s partner’s present
bias. Second, we need to say something about higher-order beliefs to complete our
definitions. Thus, just as we would naturally conceive sophistication as it applies to
lowest-order beliefs, sophistication with respect to higher-order beliefs will mean that
such beliefs are correctly anticipated. Lastly, if a player’s prior beliefs are correct,
there is no reason to believe such beliefs will be reassessed. Therefore, in contrast to
our working conception of naivete, we do not need to separately consider a player’s
prior beliefs apart from their choice-relevant beliefs in defining sophistication. Consequently, sophistication will simply mean that the associated beliefs — as represented
in µ — at the time choices are made are correct.
Formally, we define two forms of sophistication (and parallel forms of naivete) as
follows:
Definition
(i-a) A player is self-sophisticated if all of their (choice-relevant) beliefs regarding their
own present bias are correct: µI (n) = µ̃0O (n) = µ0O (n), for all n = 1, 2, . . ..
(i-b) A player is other-sophisticated if all of their beliefs regarding their partner’s
27 For the case of a team with one TC and one fully-sophisticated present-biased player (we will elaborate on sophisticated players in the next section), our equilibrium selection rules do not pin down a unique
equilibrium — both efficient and inefficient equilibria are possible. For a team with two fully-sophisticated
time-inconsistent players for whom it is common knowledge that both players are present-biased the equilibrium is identical to the equilibrium for a team with two naifs who both have unlimited reassessment. Hence,
in addition to present bias, some naivete is needed in a team to guarantee efficiency.

16

present bias are correct: µO (n) = µ̃0I (n − 1) = µ0I (n − 1), for all n = 1, 2, . . . .
(ii-a) A player is self-naive if their preconception is that they are not present-biased
and that this is common knowledge.
(ii-b) A player is other-naive if their preconception is that their partner is not presentbiased and that this is common knowledge.
We can observe that the naifs we considered in Section 3 were both self-naive and
other-naive (i.e. “fully naive,” as we called them). Using our new terminology, we
can now define different types of players, with some level of sophistication, as follows:
Definition
(i) A self-sophisticate is a player who is self-sophisticated, but other-naive.
(ii) An other-sophisticate is a player who is other-sophisticated, but self-naive.
(iii) A full-sophisticate is a player who is self-sophisticated and other-sophisticated.
At this point, it might be worthwhile to highlight some asymmetries inherent in
both sets of definitions provided above. To start, in the first set of definitions (the
adjectives), we see that the two forms of sophistication (i-a and i-b) refer to properties
of a player’s choice-relevant beliefs, µ = (µO , µI ), while the two forms of naivete (ii-a
and ii-b) only refer to a player’s preconceptions while leaving open how their choicerelevant beliefs might look. This difference stems directly from the feature of our setup
mentioned above that preconceptions are only relevant with regards to naive beliefs.
Furthermore, in light of what actually causes reassessments of naive preconceptions,
this difference also gives rise to other asymmetries pertaining to how the various
types of players introduced in the second set of definitions (the nouns) arrive at their
decisions. In particular, an other-sophisticate may reassess their naive (in this case,
inward) preconceptions in the manner described in Section 3, yet a self-sophisticate
will never reassess their naive (outward) preconceptions.
To understand why other-sophisticates — but not self-sophisticates — may reassess
their naive preconceptions, recall from Section 3 that a specific event served as a
necessary trigger for such reassessments: namely, the unexpected discovery of one’s
own present bias. Thus, since an other-sophisticate is self-naive, this trigger will still
exist for such players. However, since a self-sophisticate correctly anticipates their
own present bias, they are never confronted with any new information to challenge
their other-naivete so that there will never be an impetus to reassess their naive
outward beliefs.
Therefore, like the naif considered in Section 3, only the other-sophisticate finds
17

herself unexpectedly questioning their preconceptions immediately prior to their effort
choice at t = 1, while the self-sophisticate’s subjective experience is quite different
in that, like the full-sophisticate, they carry on without ever questioning (or having
reason to question) what they previously thought to be true. As we will see, these
different “experiences,” so to speak, give rise to equilibrium behaviors that are not
simple reflections of one another, and in our formal results, it will therefore often
be practical to consider these two types of partial sophisticates separately (as we do
below):
Proposition 2 A self-sophisticate is unmotivated, regardless of their partner’s type.
Hence, a partially sophisticated player who is self-sophisticated but other-naive
always procrastinates in the sense that they never exerts effort to complete a task
before the final period. Furthermore, as will be fully apparent by the end of this
section, when we categorize types solely by their status as naive or sophisticated with
respect to both one’s own and one’s partner’s present biases, the self-sophisticate is
the only type of player for whom procrastination of this sort can always be expected.
Put differently, naifs, other-sophisticates, and full-sophisticates can all be motivated
in at least some circumstances — but self-sophisticates are never motivated.
We can understand the intuition for Proposition 2 by first noting that the selfsophisticate never reassesses their outward beliefs — i.e., µO = (1, 1, 1, . . .) — so
that their full set of beliefs will ultimately resemble that of a naif, as considered
in Section 3, for whom reassessed preconceptions are necessarily inward (although
possibly weakly). In turn, just as we saw in Proposition 1 for a naif with weakly
inward reassessments, this self-sophisticate is always unmotivated.
This next result considers the more complicated case of an other-sophisticate:
Proposition 3
(i) Under finite inward reassessment (RI < ∞), an other-sophisticate is motivated
if and only if one of the following is true: (a) their partner is self-sophisticated (i.e.
either a self-sophisticate or a full-sophisticate), or (b) their inward reassessment is
weakly shallower than their partner’s inward reassessment (RI ≤ RI0 ).
(ii) Under infinite inward reassessment, an other-sophisticate is never motivated.
To understand why an other-sophisticate is motivated with a self-sophisticated
partner (i-a), first note that in such cases both players have the same, correct beliefs
regarding the partner’s present bias, which implies that it truly is common knowledge that the partner is present biased: µO = µ̃0I = µ0I = (β, β, β, . . .). Therefore,
18

the other-sophisticate’s outward beliefs end up looking like those of an other-naive
player with infinite outward reassessment, so that with finite inward reassessment,
the other-sophisticate’s full set of beliefs resemble that of a strictly outward naif who
is always motivated according to Proposition 1. The other-sophisticate is similarly
motivated if their inward reassessment is weakly shallower than that of their partner
(i-b) because their partner’s inward reassessment determines the effective depth of
their own sophisticated outward beliefs from µO (n) = µ0I (n − 1), n = 1, 2, . . .. As
a result, the other-sophisticate’s beliefs would again be outward on balance, making
their motivated in the same vein as the strictly outward naif. In contrast, an othersophisticate is never motivated under infinite reassessment for the same reasons that
the naif in Proposition 1 was never motivated when RI = ∞. In particular, under infinite reassessment, an other-sophisticate believes it is common knowledge that both
players are present-biased and therefore mixes under the (possibly false) assumption
that their partner has identical beliefs and will therefore mix as well.
Proposition 4 A full-sophisticate is motivated if and only if their partner is unmotivated, and is unmotivated if and only if their partner is motivated.
Hence, a full-sophisticate’s motivational status is optimal in the sense that it will
be the opposite of their partner’s, so that their perception-perfect strategy is indeed
the true best-response. This prediction is not too surprising since all of the fullsophisticate’s beliefs are necessarily correct. However, as we will soon see, if the
full-sophisticate’s partner is neither motivated nor unmotivated (as would be the case
if their partner was also a full-sophisticate), the situation is less promising from an
efficiency perspective.
Proposition 5 A team comprised of two sophisticates with asymmetric beliefs (i.e.
µ 6= µ0 ) is efficient, unless one player is an other-sophisticate with infinite inward
reassessment and the other player is a self-sophisticate.
One key implication of Proposition 5 is that with (at least partially) sophisticated
players, pairing different types is almost enough to guarantee efficiency, since there is
only one special case in which efficiency is not guaranteed. The lesson here, it may
seem, is that similarity promotes inefficient outcomes while dissimilarity promotes
efficient outcomes. However, this generalization is problematic in light of our one
exception to the rule. That is, a team will be inefficient if it is comprised of the
two types of sophisticates who are (arguably) as dissimilar as possible. In particular,
19

one player in this inefficient team is self-naive, other-sophisticated, and has infinite
reassessment of their naive beliefs, while the other player is the opposite in each
regard: other-naive, self-sophisticated, and by way of being self-sophisticated (and
thus having no impetus to revisit their preconceptions), has zero reassessment of
their naive beliefs.
Another apparent lesson of Proposition 5 is that sophistication is good because,
along with asymmetric beliefs, sophisticated players almost always achieve the firstbest outcome. However, such a generalization would also have a major hole because
too much sophistication can be an obstacle to efficiency:
Proposition 6 A team with a full-sophisticate is inefficient if and only if the other
player is either a full-sophisticate as well or has reassessed beliefs that are identical
to those of a full-sophisticate.
Thus, pairing two full-sophisticates will never be efficient. Moreover, pairing a fullsophisticate with a naive (at least partially) player whose reassessed beliefs happen
to coincide exactly with what a full-sophisticate would have believed all along will
also be inefficient. With that said, pairing a full-sophisticate with anyone else —
equivalently, any potential partner for whom µ0 6= µ — does guarantee efficiency.
While the above result implicitly characterizes the efficiency of a team in which the
(in this case, full) sophisticate’s partner is either a naif or another type of sophisticate,
we have yet to consider the efficiency of teams that consist of one partial sophisticate
along with a naif. The next two results fill this gap:
Proposition 7 A team with one self-sophisticate and one naif is efficient if and only
if the naif ’s reassessment is strictly outward.
As we’ve learned so far, self-sophisticates are always unmotivated while naifs are
motivated only if their reassessments are strictly outward; thus, such strictly outward
reassessment by the naif is necessary and sufficient for efficiency in a team comprised
of one of each type.
Proposition 8 Consider a team with an other-sophisticate and a naif.
(i) If the naif ’s reassessment is weakly inward, the team is efficient if and only if the
other-sophisticate’s inward reassessment is weakly shallower than that of the naif.
(ii) If the naif ’s reassessment is strictly outward, the team is efficient if and only if
the other-sophisticate’s inward reassessment is strictly deeper than that of the naif.

20

This result is perhaps best understood if we interpret it while referring back to
Proposition 3, which characterized the individual strategies that an other-sophisticate
may employ. In particular, part (i-b) of Proposition 3 established that an othersophisticate is motivated if their inward reassessment is weakly shallower than their
partner’s. Part (i) of the current result then follows because a weakly inward naif is
unmotivated, so that the other-sophisticate must be motivated to ensure efficiency.
Part (ii) similarly follows because a strictly outward naif is motivated, so that the
other-sophisticate must be unmotivated for the team to be efficient.

5

Implications for Non-Bayesian Updating of Null Events

As mentioned earlier, our theory links established models of present-biased discounting to the recently-revived theoretical interest in non-Bayesian updating in response
to zero-probability events (Ortoleva, 2012; Karni and Viero, 2013).28 We feel it is
quite natural to bridge this gap since the standard model of fully-naive present bias
implicitly assumes that agents can assign zero-probability to events that may actually
occur, thus providing a well-grounded point of entry into the realm of non-Bayesian
updating.
Besides the new application to present bias, our model formalizes a novel “sequential reassessment” approach to Non-Bayesian updating in which an agent only
updates their prior beliefs about some parameter up to some threshold order (between
zero and infinity) so that higher-order beliefs above this threshold are not updated.
In addition to its tractability, we believe sequential reassessment is appealing because it captures a realistic aspect of human cognition in that lower-order beliefs are
more easily and naturally contemplated than higher-order beliefs.29 For example, it
is highly unlikely that you would stop to wonder whether or not I believe that you
believe that I am ambidextrous without wondering whether I am ambidextrous in
28 Also see Blume et al.’s (1991) and Myerson’s (1986) earlier extensions of subjective expected utility
theory to address updating in response to null events.
29 The tractability of our approach is greatly facilitated by our simplifying assumption that players are
absolutely certain (one way or another) regarding each of their beliefs. This assumption is carried over from
canonical, single-agent models of naive present bias — and also exists in models of partially naive present
bias, in which the agent anticipates a present bias but underestimate its severity (O’Donoghue and Rabin,
2001). Formally, partial naivete in this sense means the agent is ‘positive’ their future present bias will be
β̂ ∈ (β, 1). Sequential reassessment would also be amenable to the analysis of this type of player because
confronting the true present bias, β < β̂, still represents the realization of a zero-probability event. While
probabilistic beliefs regarding one’s present bias could be another reasonable approach to modeling partial
naivete, it would not provide a natural entry point for sequential reassessment in response to null events
(assuming the agent assigns a nonzero probability to the true present bias factor).

21

the first place. Moreover, by allowing unequal inward and outward reassessments,
sequential reassessment can speak to individual variation in ‘dispositions’ of social
cognition — some people may be more introspective and others more extrospective
— while allowing for variation in the depths of reassessments fits with the idea that
some of us may be more inclined to question our preconceived notions than others.
Sequential reassessment can also be regarded as a new application of level-k reasoning models to the domains of time-inconsistent preferences and of non-Bayesian
updating in response to null events.30 Level-k reasoning models are founded on the
premise that, in many cases, standard equilibrium concepts rely on implausible assumptions about humans’ reasoning capacities and that a more realistic characterization of how people actually think in strategic environments is needed. Formally, these
models assume that players’ beliefs (and strategies) are anchored to some naive prior
held by a “level-0” player such that a level-1 player best-responds to the strategy of
a level-0 player, a level-2 player best-responds to a level-1 player, and so on. Under
finite sequential reassessment, naifs similarly believe they are one step ahead of this
partner (in each direction) and best-respond accordingly. For example, suppose Alice
is a naif with RO = RI = 1 (i.e. Alice believes that Bob knows she is present-biased
and that Bob is present-biased too, but maintains all other preconceptions). Then
Alice best-responds under the belief that Bob has only engaged in one degree of out0
ward reassessment: R̃O
= 1 and R̃I0 = 0, falling one degree short of what she would
0
= 2 and RI0 = 1). More
perceive as the correct beliefs from Bob’s vantage point (RO
generally, sequential reassessment can be mapped to level-k reasoning, where a naif’s
level is given by k = max{2RI + 1, 2RO }, and where level-0 represents a hypothetical
time-consistent player who believes it is common knowledge that neither player is
present-biased.31 Indeed, real-life players in normal form games do appear to exhibit
a limited depth of reasoning, as many empirical and experimental studies show that
level-k reasoning often out-predicts models based on standard equilibrium concepts
(for a review, see Crawford et al., 2013).
30 See

Nagel (1995), Stahl and Wilson (1995), Costa-Gomes et al. (2001), Costa-Gomes and Crawford
(2006), and the closely-related ‘Cognitive Hierarchy’ model of Camerer et al. (2004).
31 In our setting, two players with different beliefs can be on the same level. For instance, suppose Alice
Y’s reassessment is as described above with RO = RI = 1 and Alice Z’s reassessment depths are RO = 0
and RI = 1. Then both Alices are level-3 players best-responding to what they perceive as level-2 opponents
(Bob Y and Bob Z) who themselves are under the false impression that they are best-responding to a level-1
opponent, who in turn is best-responding to the level-0 time-consistent type. The subtle distinction here is
0
that Alice Y believes that Bob Y is present-biased with reassessment depths RO
= 1 and RI0 = 0 while Alice
Z believes that Bob Z is not present-biased yet, oddly enough, has the same nonzero outward reassessment
0
RO
= 1 that Alice Y perceives in Bob Y.

22

As we alluded to above, sequential reassessment represents a distinct approach
for modeling non-Bayesian reactions to null events in relation to recently-proposed
axiomatic decision theories that address this topic. In Ortoleva’s (2012) “hypothesis
testing” model, the realization of a null state prompts the agent to discard their priors in favor of a different set of priors. Unlike sequential reassessment, this approach
relies on a pre-existing set of hypotheses (prior over priors) from which to draw. In
Karni and Viero’s (2013) “reverse Bayesianism” model, the discovery of a previouslyunconceived possibility (i.e., a consequence, act, or consequence-act link) leads the
agent to form posterior beliefs on those that were previously-conceived by proportionately reducing the associated priors while remaining agnostic to the magnitude of the
posterior for the newly-discovered possibility. This approach rules out a key property of sequential reassessment by which it allows for, and derives important results
from, the possibility that some priors are reassessed while others or not. If we were
to limit our types to those satisfying proportional reassessment of non-contradicted
priors, the naif in Section 3 would either engage in zero or unlimited reassessment,
thus precluding, for example, the strictly outward reassessment that was necessary to
motivate a naif and also to achieve efficiency in a team with two naifs (see Proposition
1 and Corollary 2).
We believe that updating in response to null events may follow a variety of approaches and that sequential reassessment may be more or less viable than the others
depending on the situation. With that said, we also believe that sequential reassessment is the most reasonable for the situation we consider. To start, the other approaches are ideally-suited to situations in which agents respond to noisy signals
about a ‘state’ (broadly speaking) by forming new beliefs regarding the likelihoods of
other, mutually-exclusive elements of the state space. Agents in our setting, however,
face a different problem: after learning the true value about a private parameter, they
are left to form beliefs regarding the private value of their partner’s parameter and
all higher-order (and naturally sequenced) beliefs thereof.
Besides these technical considerations, the hypothesis testing and reverse-Bayesianism
models are probably better suited for modeling more perceptive agents than those
considered here. Namely, these approaches implicitly require a capacity for learning
that naively present-biased agents are commonly understood to lack. A naif, as standardly conceived in single-agent models, unexpectedly confronts their present bias in
every period, but carries on treating their inevitable future present bias as a zeroprobability event. In the hypothesis testing and reverse-Bayesianism models, however,

23

agents will not form posterior beliefs that have already been contradicted. Related to
this, this naif holds (by definition) a false assumption, devoid of any doubt, regarding
a parameter that would in principle be known if it weren’t for a lack of sophistication. Sequential reassessment is uniquely in keeping with this self-assured concept of
naivete as it renders posterior beliefs that are not necessarily correct, yet nonetheless
held with certainty, while the hypothesis testing and reverse-Bayesianism models may
better describe probabilistic beliefs held by less oblivious agents regarding invariably
uncertain states.

6

Relation to a Static Volunteer’s Dilemma with Self-Image
Biases

Although we believe it to be the most natural and well-grounded motivation, our
analysis of naive present bias in a dynamic collaboration game could be regarded as
one of multiple candidate motivations for a less-specific approach in which players may
confront false preconceptions regarding some generic payoff parameter. Moreover, by
constructing a game in which we could effectively confine our analysis to the t = 1
decision, the framework can, in essence, be collapsed to a static game in which a
generic ‘payoff naivete’ can be analyzed devoid of dynamic considerations.32 To see
this, consider the ‘ex-ante’ game with the payoff structure given at left below, for
some φ̄ ∈ (0, 1). Here, player 1 is certain that this payoff structure is common
knowledge, but when called to select an action, suddenly learns that their payoff in
the bottom-left cell is higher than they initially expected, φ > φ̄, giving rise to the
payoff structure on the right:
a
b
a
b
(0, φ̄)
(0, φ0 )
a (0, 0)
a (0, 0)
−→
b (φ̄, 0) (−1, −1)
b (φ, 0) (−1, −1)
Ex-Ante

Action Selection

The parameter φ̄ in the top-right cell has also been replaced, in this case by φ0 ,
reflecting the possibility that learning about φ may compel player 1 to revisit their
32 The

collapsibility of our base model largely stems from our efforts to make it as simple as possible,
avoiding any extraneous generalizations that aren’t already in standard models of present bias. Accordingly,
this feature would not be preserved in many natural extensions of the base model, thus necessitating a
dynamic formulation with present bias. A few examples of extensions or modifications that might be worth
considering include: eliminating deadlines, modeling non-Bayesian learning between periods in response
to an inconceivable action by one’s partner (see Footnote 16), exploring other dynamic games (such as a
repeated Prisoner’s Dilemma), considering teams of different sizes, and simultaneously varying the deadline
length along with the total task requirements.

24

prior assumption regarding player 2’s corresponding parameter, now labeled as φ0 .
If we presume player 1 only entertains two possibilities, φ0 = φ and φ0 = φ̄, and
similarly restrict the space for all higher-order beliefs regarding φ and φ0 to {φ, φ̄},
c
c
then it is straightforward to show that, for φ̄ = 1−2c
and φ = β(1−c)−c
, their problem
is strategically-equivalent to the t = 1 subgame faced by the present-biased naif in
Section 3.
The static game described here can be interpreted as a two-player “volunteer’s
dilemma.” In particular, action a — the analog to exerting effort at t = 1 in our
dynamic game — represents a choice to volunteer to perform a costly task that
generates a public good (and only requires one volunteer to do so). A common
illustration of the volunteer’s dilemma is a situation with multiple witnesses to a
crime-in-progress. If at least one witness volunteers to alert the police, the crime will
be thwarted, but if no one volunteers, the criminal will succeed to the detriment of
the public interest.
In this story, the ‘action selection’ payoff matrix would represent a scenario in
which player 1 discovers a higher-than-anticipated payoff from not volunteering in
the event that player 2 volunteers. As it arises here, it may not be obvious how
to interpret ‘payoff naivete,’ but one possible interpretation relates to biases in the
maintenance of a positive self-image. To illustrate, suppose players derive utility
from a positive self-image — i.e. a view of oneself as a ‘socially responsible’ person
— that can be harmed by ‘socially irresponsible’ actions, which in this setting means
choosing b (not volunteering). A ‘naif’ here initially believes there is an intrinsic
cost from choosing b, but unexpectedly discovers a capacity to reconcile such socially
irresponsible behavior with a positive self-image in the event that it does no harm
(i.e., as long as their partner volunteers). Thus, “getting away” with not volunteering
would not entail the intrinsic self-image cost, making the associated (net) payoff higher
than anticipated: φ > φ̄.33 A revelation of this sort may be interpreted as a temporary
lowering of one’s personal ethical standards to permit a ‘one-time’ exemption, where
naivete may allow such dynamically inconsistent perceptions to persist.
The interpretation of the ‘naive volunteer’s dilemma’ outlined above can be understood in terms of established psychological concepts, some of which have appeared
in economic theory. The idea that prosocial behavior is incentivized by a preference
to maintain a positive self-image is at the heart of Brekke et al.’s (2003) “moral
33 We presume that the self-image cost is implicitly reflected in the ex-ante payoff matrix, with the net
utility associated with socially responsible behavior normalized to 0.

25

motivation” model, while the broader notion that a lower self-image carries a hedonic cost is inherent in some theories of overconfidence (Benabou and Tirole, 2002;
Koszegi, 2006). In turn, applications of Liberman and Trope’s (1998, 2003) temporal
construal theory to ethical behavior demonstrate a human tendency to judge one’s
own future (hypothetical) transgressions in terms of rigid ethical principles, while
situation-specific considerations can soften perceptions of present behavior (Eyal et
al., 2008; Tenbrunsel et al., 2010).34
If we re-interpret the formal predictions of our (originally-conceived) dynamic collaboration model through the lens of this ‘naive volunteer’s dilemma,’ it suggests
that a positively-biased self-image, broadly speaking, can enhance collective efficiency. In a somewhat similar vein, Gervais and Goldstein (2007) show that positive self-perception biases, taken here to mean overestimating one’s marginal return
to effort, can mitigate free-riding and coordination failure in firms, while Benabou
(2013) demonstrates that “wishful thinking” (i.e. ignoring bad news regarding a
project’s value) can also promote better outcomes and mitigate free-riding by boosting group morale. While these results present a similar flavor to our own, they rely
on a positively-biased self-image to inflate the perceived payoff of socially responsible
behavior. In contrast, our approach shows how a positively-biased self-image can,
perhaps paradoxically, promote socially responsible behavior (leading to socially efficient outcomes) even when the bias increases the perceived payoff associated with
socially irresponsible behavior.

7

Concluding Remarks

This paper presented a model of collaboration among present-biased players, each of
whom may be fully-naive, fully-sophisticated, or a hybrid thereof, i.e. self-sophisticated
regarding their own present bias yet other-naive regarding their partner’s (or vice
versa). Importantly, we allowed for variation in the “depths” and “directions” with
which naive preconceptions (including higher-order beliefs) are reassessed when players confront their own present bias. In doing so, we avoided ad-hoc assumptions on
34 Tenbrunsel et al. elaborate on this tendency, describing how transient influences can guide unethical
behaviors that were overlooked in past predictions of current behavior and will also be overlooked in future recollections of current behavior, where selective memory, post-hoc justifications, and shifting ethical
standards are subconsciously deployed to help sustain this so-called “ethical mirage.” Rotela and Richeson
(2013) document how selectively forgetting past wrongdoings can also serve to inflate one’s perceptions of
other in-group members, providing a potential basis for ‘other-naivete’ among players who share a common
identity.

26

how naive beliefs are updated in a realm where Bayes’ rule does not apply, while
also identifying new behavioral elements that, according to our model, turn out to be
crucial determinants of individual motivation and team efficiency.
To highlight one example, we showed that a team with two fully-naive players
will be efficient, as long as the team is diverse with respect to the directions of
players’ reassessments. One noteworthy aspect of this prediction is that it shows how
present-bias and naivete can enable efficient outcomes in a setting where a team with
two time-consistent players (and also a team with two fully-sophisticated presentbiased players) would be inefficient. Moreover, in achieving this efficient outcome,
the ‘extrospective’ naif with outward reassessment is motivated to exert effort at
the beginning of the project, while a time-consistent player would procrastinate with
some positive probability. Since present-bias — particularly naive present bias — is
known to make an agent prone to severe procrastination on individual projects, this
heightened motivation to complete a task early in a team setting reveals a different
‘side’ of the oft-maligned naively present-biased agent.
Overall, we offer a distinct approach to diversity and team functionality that embraces the incentive issues (and related coordination issues) highlighted in the economics literature along with the notion that a key instrument to ensure efficiency
within a team can be its composition. Our broad conclusion is that diversity among
agents in their ‘behavioral dispositions’ can often be efficiency enhancing. With that
said, our model also points to the potential value of moderation in this sense, as
maximizing diversity on multiple dimensions may backfire — as we saw when pairing
opposite types of partial sophisticates who also represent opposites in the depths with
which they reassess their naive preconceptions.

A
A.1

Appendix
Proof of Lemma 1

If a player believes their partner is unmotivated, the expected value of shirking is 0
and the expected value of effort is −c + β(1 − c) > 0. Therefore the player (who
believes their partner is unmotivated) is motivated. If a player believes their partner
is motivated, the expected value of shirking is β(1 − c) and the expected value of
effort is −c + β(1 − c) < β(1 − c). Therefore the player (who believes their partner is
motivated) is unmotivated. 

27

A.2

Proof of Lemma 2

If the team completes more than three tasks, there is inefficient overprovision of effort.
If the team completes less than three tasks, there is underprovision as the team fails
to complete the project. Therefore, the team must complete three tasks in any firstbest equilibrium. If the team completes zero tasks at t = 1 (i.e. both players shirk),
this three-task outcome is impossible. If the team completes two tasks at t = 1 (i.e.
both players exert effort), then both players mix at t = 2; therefore, in this case, the
inefficient two-task and four-task outcomes, as well as the efficient three-task outcome
all have a nonzero probability of occurring, so that the first-best is not assured. If
the team completes one task at t = 1 (i.e. one player shirks and the other exerts
effort), both players exert effort at t = 2, so that the three-task outcome is attained.
It is assured that the team will complete one task at t = 1 if and only if one player is
motivated and the other is unmotivated. Therefore, the team is efficient if and only
if one player is motivated and the other player is unmotivated. 
A.3

Proof of Corollary 1

Since behavior is uniquely determined by µ, if µ0 = µ, the players described by these
beliefs must be the same with respect to their status as motivated, unmotivated, or
neither. Therefore, from Lemma 2, such a team must be inefficient. 
A.4

Proof of Proposition 1

We first proceed by induction. In particular, we need to establish the following:
(i) Under zero reassessment, a naif is unmotivated
(ii) Take any n = 0, 1, . . .. If a naif with RO = m and RI = n is unmotivated for
any m = 0, 1, . . . , n, then a naif with RO = n + 1 and RI = m is motivated for
any m = 0, 1, . . . , n.
(iii) Take any n = 1, . . .. If a naif with RO = n and RI = m is motivated for any
m = 0, 1, . . . , n − 1, then a naif with RO = m0 and RI = n is unmotivated for
any m0 = 0, 1, . . . , n.
Proof of (i). Under zero reassessment, a naif believes their partner is a timeconsistent player who believes that his partner (i.e. the naif herself) is also timeconsistent and that this is all mutual information. A hypothetical time-consistent
28

player who believes he is paired with an identical player mixes, exerting effort with
c
(see Section 2.2). Therefore, the naif’s perceived expected values
probability 1 − 1−c

c
of exerting effort and of shirking are −c + β(1 − c) and 1 − 1−c
β(1 − c) = β(1 − 2c),
respectively. Since β(1 − 2c) > −c + β(1 − c), the naif is unmotivated under zero
reassessment.
0
Proof of (ii). For a naif with RO = n + 1 and RI = m, we have that R̃O
=m
and R̃I0 = n. Given m ≤ n, this naif thus believes their partner is unmotivated, by
assumption. From Lemma 1, the naif with RO = n + 1 and RI = m — and therefore
with strictly outward reassessment — is motivated.
0
Proof of (iii). For a naif with RO = m and RI = n, we have that R̃O
= n
0
and R̃I = m − 1, provided m ≥ 1. Given m ≤ n, this naif thus believes their
partner is motivated, by assumption. From Lemma 1, the naif with RO = m ≥ 1 and
RI = n−1 — and therefore with weakly inward reassessment — is unmotivated. Now
if m = 0, the naif with RO = m and RI = n believes their partner is a time-consistent
0
= n and R̃I0 = 0 (although a hypothetical time-consistent player’s
player where R̃O
beliefs would presumably not be based on reassessments triggered by unexpectedly
discovering one’s present bias, as they are for a naif, RO and RI can be defined from
µ in the exact same way). Now we know that a naif with RO = n and RI = 0
is motivated, by assumption. Therefore, if p is the probability that this naif with
RO = n and RI = 0 believes their partner will exert effort, −c + β(1 − c) > pβ(1 − c).
Adding (1 − β)(1 − c) to both sides, we get 1 − 2c > (pβ + (1 − β))(1 − c) ≥ p(1 − c).
Noting that, to the hypothetical time-consistent player with RO = n and RI = 0, the
perceived expected values of exerting effort and of shirking are 1 − 2c and p(1 − c),
respectively, this type of (hypothetical) player is motivated. Thus, from Lemma 1,
the naif who believes their partner is of this type is unmotivated.
Together, parts (i), (ii), and (iii) prove that a naif is motivated under strictly
outward reassessment and unmotivated under weakly inward reassessment. Now a
naif whose reassessment is neither strictly outward or weakly inward has unlimited
reassessment, and under unlimited reassessment, a naif believes their partner is of the
c
same type and thus mixes with probability 1 − β(1−c)
(see Section 2.2). Therefore, by
process of elimination, a strictly outward reassessment is not only sufficient, but also
necessary for a naif to be motivated, and a weakly inward reassessment is likewise
not only sufficient, but also necessary for a naif to be unmotivated. 

29

A.5

Proof of Corollary 2

From Proposition 1, we know that a team consists of one motivated player and one
unmotivated player if and only if one player’s reassessment is weakly inward, the
other player’s reassessment is strictly outward, and both players’ reassessments are
limited. From Lemma 2, we know that being comprised of such players is necessary
and sufficient condition for the team to be efficient. 
A.6

Proof of Corollary 3

From Proposition 1, we know that a naif is motivated if and only if RO > RI .
Therefore a naif must have nonzero reassessment with RO > 0 to be motivated.
Nonzero reassessment by at least one player is thus necessary for efficiency because,
from Lemma 2, we know that a team must have one motivated player to be efficient.


A.7

Proof of Corollary 4

The assertion that a naif is neither motivated nor unmotivated under unlimited reassessment is a direct implication of Proposition 1 (the mixing behavior of such players
is addressed in Proposition 1’s proof). From Lemma 2, we know that any player on
an efficient team must either be motivated or unmotivated. Therefore a team that
includes a naif with unlimited reassessment must be inefficient. 
A.8

Proof of Corollary 5

First note that Proposition 1 still applies for a naif with a time-consistent partner
because a naif’s status as motivated or unmotivated (or neither) does not depend on
who their partner actually is. Next, since a time-consistent player’s beliefs are correct,
Lemma 1 implies that the time-consistent player will be motivated (unmotivated) if
their fully-naive partner is in fact unmotivated (motivated). In turn, from Proposition
1 and Lemma 2, we get the desired result for the “mixed” team. As for the case of two
time-consistent teammates, this team must be inefficient in light of Lemma 2 because
these teammates must be the same with respect to their motivational statuses. 

30

A.9

Proof of Proposition 2

Since a self-sophisticate does not reassess their naive outward beliefs, we know that
µO (n) = 1 for all n = 1, 2, . . .. Therefore, for any µI , the self-sophisticate’s beliefs are
effectively weakly inward, and they are therefore unmotivated. 
A.10

Proof of Proposition 3

We first consider the case of finite inward reassessment. Now the other-sophisticate’s
partner must be one of the following: a full-sophisticate, a self-sophisticate, an othersophisticate, or a naif.
If the partner is self-sophisticated (i.e. a full-sophisticate or a self-sophisticate), we
must have that µO (n) = µ0I (n) = β for all n = 1, 2, . . .. Since the other-sophisticate’s
inward reassessment is finite, µI (n) = β if and only if n < k for some finite k ≥ 0 (and
µI (n) = 1 for all n ≥ k). Therefore, the other-sophisticate’s beliefs are effectively
strictly outward, and thus the other-sophisticate is motivated if their partner is selfsophisticated.
If the other-sophisticate’s partner is self-naive (i.e. an other-sophisticate or a naif),
then µO (n) = β if and only if n ≤ RI0 + 1. If the other-sophisticate’s inward beliefs
are weakly shallower than their partner’s, i.e. RI ≤ RI0 , then µI (n) = β if and
only if n ≤ RI with RI < RI0 + 1. Therefore, if RI ≤ RI0 , the other-sophisticate’s
beliefs are effectively strictly outward and thus the other-sophisticate is motivated.
If RI > RI0 , however, then µI (n) = β if and only if n ≤ RI with RI ≥ RI0 + 1. Thus,
if RI > RI0 , the other-sophisticate’s beliefs are effectively weakly inward and thus the
other-sophisticate is unmotivated.
Next we consider infinite inward reassessment by the other-sophisticate, i.e. µI (n) =
β for all n = 1, 2, . . .. If µO 6= µI , then the other-sophisticate’s beliefs must be effectively strictly inward, in which case they are unmotivated. If µO = µI , then µ = µ̃0 ,
i.e. they believe their partner is of the same type. Thus, the other-sophisticate in
this case is neither motivated nor unmotivated. 
A.11

Proof of Proposition 4

For a full-sophisticate, µ̃0 = µ0 . Thus, since any player’s motivation status is fully
determined by their beliefs, the full-sophisticate believes their partner is motivated if
and only if their partner truly is motivated (and similar if their partner is unmotivated). Therefore, from Lemma 1, we get our result. 
31

A.12

Proof of Proposition 5

First note that, if one player is an other-sophisticate with infinite inward reassessment
and the other player is a self-sophisticate, then we know from Proposition 3 that the
former player is not motivated and from Proposition 2 that the latter player is also
not motivated. Therefore, in light of Lemma 2, such a team is inefficient.
To show that alternate compositions are efficient, there are four potential cases to
consider:
(a) Both players are other-sophisticates with RI 6= RI0 . Since both players are
other-sophisticates, we know that µO (n) = β if and only if n ≤ RI0 + 1 and µ0O (n) = β
if and only if n ≤ RI + 1. Now take RI > RI0 , without loss of generality. In this
case, µI (n) = β if and only if n ≤ RI with RI ≥ RI0 + 1. Therefore, the beliefs given
by µ are effectively weakly inward, and thus this player is unmotivated. Meanwhile,
µ0I (n) = β if and only if n ≤ RI0 with RI0 < RI + 1. Thus, the beliefs given by µ0 are
effectively strictly outward, and thus the partner is motivated. Consequently, from
Lemma 2, this team is efficient.
(b) One player is an other-sophisticate and the other player is a full-sophisticate.
Expressing our notation from the other-sophisticate’s perspective (without loss of
generality), first note that µO (n) = µ0I (n) = β for all n = 1, 2, . . .. Next, since beliefs
are not symmetric, we must have that µI 6= µ0I = (β, β, β, . . .). Therefore, the othersophisticate’s inward reassessment is finite. Consequently, the outward-sophisticate
is motivated, from Proposition 3. In turn, the full-sophisticate must be unmotivated,
from Proposition 4. Finally, from Lemma 2, this team must be efficient.
(c) One player is a self-sophisticate and the other is a full-sophisticate. The selfsophisticate is unmotivated, from Proposition 2. In turn, the full-sophisticate must be
motivated, from Proposition 4. Finally, from Lemma 2, this team must be efficient.
Note that, since self-sophisticates do not reassess their naive outward beliefs, a
team with two self-sophisticates must have symmetric beliefs with µI (n) = µ0I (n) =
µO (n) = µ0O (n) = 1 for all n = 1, 2, . . .. Therefore the possibility of a team with
self-sophisticates did not need to be considered in the above proof. 
A.13

Proof of Proposition 6

If both players are full-sophisticates, it is common knowledge that both players are
present-biased. Therefore, µI = µ0I = µO = µ0O = (β, β, β, . . .). From Corollary 1,
such a team must be inefficient.

32

Now the full-sophisticate’s partner is a different type of sophisticate. From Proposition 5, this team will be efficient.
Next, suppose the full-sophisticate’s partner is a naif with limited reassessment.
From Proposition 1, the naif is unmotivated if their reassessment is weakly inward, and
motivated if their reassessment is strictly outward. Proposition 4, the full-sophisticate
is then motivated for the former type of naif and unmotivated for the latter, which
in turn implies that the team will be efficient in light of Lemma 2.
Lastly, suppose the full-sophisticate’s partner is a naif with unlimited reassessment.
Under unlimited reassessment, the naif’s beliefs are given by µ0I = µ0O = (β, β, β, . . .).
Thus, µ0I (n) = β = µO (n) for all n = 1, 2, . . ., i.e. the naif is (effectively) selfsophisticated. Moreover, µ0O (n) = β = µI (n − 1) for all n = 1, 2, . . ., i.e. the naif is
(effectively) other-sophisticated. Therefore, the naif is, in effect, a full-sophisticate
under unlimited reassessment (when paired with an actual full-sophisticate) because
all of their beliefs happen to be correct. Finally, since the naif is neither motivated nor
unmotivated under unlimited reassessment (Corollary 4), the team will be inefficient
(Lemma 2), as desired. 
A.14

Proof of Proposition 7

From Proposition 2, the self-sophisticate is unmotivated. From Proposition 1, the
naif is motivated if and only if their reassessment is strictly outward. Therefore, from
Lemma 2, the team is efficient if and only if the naif’s reassessment is strictly outward.


A.15

Proof of Proposition 8

First consider case (i). Since the naif’s reassessment is weakly inward, the naif is
unmotivated (Proposition 1). The other-sophisticate is motivated if and only if their
inward reassessment is weakly shallower than that of the naif (Proposition 3, part
(ii)), which in turn holds if and only if the team is efficient (Lemma 2).
Now consider case (ii). Since the naif’s reassessment is strictly outward, the naif is
motivated (Proposition 1). The other-sophisticate is unmotivated if and only if their
inward reassessment is strictly deeper than that of the naif (Proposition 3, part (ii)),
which in turn holds if and only if the team is efficient (Lemma 2). 

33

A.16

Robustness to Generalized Reassessments

Here we consider relaxing our assumptions on how naive beliefs are reassessed in two
ways. First, we no longer assume that reassessed beliefs must be β, and instead
allow a reassessed belief to assume any value on [β, 1). This may reflect some form
of partial reassessment of a particular belief in that it may be reassessed downward
from its prior belief (1), but not necessarily down to the level of the naif’s recentlydiscovered present bias factor (β) which prompted the reassessment. Second, we relax
our previous assumption that beliefs that are lower in order than the highest-order
reassessments in its associated direction are also reassessed. That is, we now allow
for the possibility that µz (k) = 1 and µz (k 0 ) < 1 with k 0 > k.
To establish the robustness of our results under these conditions, we first have
to adapt our previous notation to the new setting: To start, we define, for each
z ∈ {O, I}, a player’s reassessment depths as follows:
(
0,
if µz (n) = 1, for all n = 1, 2, . . .
Rz∗ =
max{n : µz (n) < 1},
otherwise.
We presume that this generalization pertains to finite reassessments for which Rz∗ <
∞, while maintaining our previous notion for cases of infinite reassessment along a
dimension (i.e. µz = (β, β, β, . . .)) to avoid having to work out arbitrarily complicated
yet uninstructive cases (such as µz (n) = 1 if and only if n is prime).
∗0
and RI∗ 0 denote the partner’s reSimilar to our previous definitions, we let RO
0
0
f∗ O and R
f∗ I denote the original player’s beliefs regarding R∗ 0
assessment depths and R
O
0
0
∗
∗
∗0
∗
∗
f
f
and RI . Now define f (x, y) ≡ {(R O , R I ) : RO = x, RI = y}. Thus, we can see that
∗
f∗ 0 ). Lastly, define k ∗ (µ) = min{k : f (k) (R∗ , R∗ ) = (0, 0)}. We
f∗ 0 , R
f (RO
, RI∗ ) = (R
O
I
O
I
∗
∗
already know that if k (µ) = 0 — i.e. under zero reassessment so that RO
= RI∗ = 0
— then the player is unmotivated. Now suppose a player with beliefs µA is unmotivated (motivated) and k ∗ (µA ) = n. Then, if k ∗ (µB ) = n + 1, a player with beliefs µB
must be motivated (unmotivated) because they believe their partner is unmotivated
(motivated). Therefore, a player with beliefs µ must be unmotivated if k ∗ (µ) is even
∗
and motivated if k ∗ (µ) is odd. Now k ∗ (µ) is even if and only if RI∗ ≥ RO
, and k ∗ (µ)
∗
is odd if and only if RO
> RI∗ . Hence, a naif who is weakly inward in the sense
∗
that RI∗ ≥ RO
remains unmotivated under our relaxed assumption on reassessments,
∗
while a naif who is strictly outward in the sense that RO
> RI∗ remains motivated,
which means that Proposition 1 is qualitatively robust to our generalizations. It is
34

straightforward to confirm that the corresponding corollaries follow in turn.

References
[1] Akerlof, George, “Procrastination and Obedience,” American Economic Review: Papers and Proceedings, 81 (1991), 1–19.
[2] Akin, Zafer, “Time Inconsistency and Learning In Bargaining Games,” International Journal of Game Theory, 36 (2007), 275–299.
[3] Bagnoli, Mark and Barton Lipman, “Provision of Public Goods: Fully Implementing the Core through Private Contributions,” Review of Economic Studies,
56 (1989), 583–601.
[4] Becker, Gary and Kevin Murphy, “The Division of Labor, Coordination Costs,
and Knowledge,” Quarterly Journal of Economics, 107 (1992), 1137–1160.
[5] Benabou, Roland, “Groupthink: Collective Delusions in Organizations and
Markets,” Review of Economic Studies, 80 (2013), 429–462.
[6] Benabou, Roland and Jean Tirole, “Self-Confidence and Personal Motivation,”
Quarterly Journal of Economics, 117 (2002), 871–915.
[7] Blume, Lawrence, Adam Brandenburger, and Eddie Dekel, “Lexicographic
Probabilities and Equilibrium Refinements,” Econometrica, 59 (1991), 81–98.
[8] Bonatti, Alessandro and Johannes Horner, “Collaborating,”American Economic Review, 101 (2011), 632-663.
[9] Brandts, Jordi, and David Cooper, “A Change Would Do You Good... An Experimental Study on How to Overcome Coordination Failure in Organizations,”
American Economic Review, 96 (2006), 669–693.
[10] Brekke, Kjell Arne, Snorre Kverndokk, and Karine Nyborg, “An Economic
Model of Moral Motivation,” Journal of Public Economics, 87 (2003), 1967–
1983.
[11] Brocas, Isabelle and Juan Carrillo, “Rush and Procrastination Under Hyperbolic Discounting and Interdependent Activities,” Journal of Risk and Uncertainty, 22 (2001), 141–164.

35

[12] Camerer, Colin, Teck-Hua Ho, and Juin-Kuan Chong, “A Cognitive Hierarchy
Model of Games,” Quarterly Journal of Economics, 119 (2004), 861–898.
[13] Costa-Gomes, Miguel and Vincent Crawford, “Cognition and Behavior in TwoPerson Guessing Games: An Experimental Study,” American Economic Review, 96 (2006), 1737–1768.
[14] Costa-Gomes, Miguel, Vincent Crawford, and Bruno Broseta, “Cognition and
Behavior in Normal-Form Games: An Experimental Study,” Econometrica, 69
(2001), 1193–1235.
[15] Crawford, Vincent, Miguel Costa-Gomes, and Nagore Iriberri, “Structural
Models of Nonequilibrium Strategic Thinking: Theory, Evidence, and Applications,” Journal of Economic Literature, 51 (2013), 5–62.
[16] Darley, John, and Bibb Latane, “Bystander Intervention in Emergencies: Diffusion of Responsibility.,” Journal of Personality and Social Psychology, 8 (1968),
377–383.
[17] Diekmann, Andreas, “Volunteer’s Dilemma,” Journal of Conflict Resolution,
29 (1985), 605–610.
[18] Diekmann, Andreas, “Cooperation in an Asymmetric Volunteer’s Dilemma
Game Theory and Experimental Evidence,” International Journal of Game
Theory, 22 (1993), 75–85.
[19] Eyal, Tal, Nira Liberman, and Taacov Trope, “Judging Near and Distant Virtue
and Vice,” Journal of Experimental Social Psychology, 44 (2008), 1204–1209.
[20] Franzen, Axel, “The Volunteers Dilemma: Theoretical Models and Empirical
Evidence,” in Foddy, Smithson, Schneider, and Hogg, eds. Resolving Social
Dilemmas: Dynamics, Structural, and Intergroup Aspects, Philadelphia, 135148 (1999).
[21] Gervais, Simon and Itay Goldstein, “The Positive Effects of Biased SelfPerceptions in Firms,” Review of Finance, 11 (2007), 453–496.
[22] Haan, Marco and Dominic Hauck, “Games with Possibly Naive Hyperbolic
Discounters,” working paper (2014).
[23] Holmstrom, Bengt, “Moral Hazard in Teams,” Bell Journal of Economics, 13
(1982), 324–340.
36

[24] Karni, Edi and Marie-Louise Vierø, “‘Reverse Bayesianism’: A Choice-Based
Theory of Growing Awareness,” American Economic Review, 103 (2013), 2790–
2810.
[25] Koszegi, Botond, “Ego Utility, Overconfidence, and Task Choice,” Journal of
the European Economic Association, 4 (2006), 673–707.
[26] Laibson, David, “Golden Eggs and Hyperbolic Discounting,” Quarterly Journal
of Economics, 112 (1997), 443–477.
[27] Liberman, Nira and Trope, Yaacov, “The Role of Feasibility and Desirability
Considerations in Near and Distant Future Decisions: A Test of Temporal
Construal Theory.,” Journal of Personality and Social Psychology, 75 (1998),
5–18.
[28] Liberman, Nira and Trope, Yaacov, “Temporal Construal,” Psychological Review, 110 (2003), 403–421.
[29] Mannix, Elizabeth and Margaret Neale, “What Differences Make a Difference?
The Promise and Reality of Diverse Teams in Organizations,” Psychological
Science in the Public Interest, 6 (2005), 31–55.
[30] Myerson, Roger, “Multistage Games with Communication,” Econometrica, 54
(1986), 323–358.
[31] Nagel, Rosemarie, “Unraveling in Guessing Games: An Experimental Study,”
American Economic Review, 85 (1995), 1313–1326.
[32] O’Donoghue, Ted and Matthew Rabin, “Doing It Now or Later,” American
Economic Review, 89 (1999), 103–124.
[33] O’Donoghue, Ted and Matthew Rabin, “Choice and Procrastination,” Quarterly Journal of Economics, 116 (2001), 121–160.
[34] O’Donoghue, Ted and Matthew Rabin, “Procrastination on Long-Term
Projects,” Journal of Economic Behavior and Organization, 66 (2008), 161–
175.
[35] Ortoleva, Pietro, “Modeling the Change of Paradigm: Non-Bayesian Reactions
to Unexpected News,” American Economic Review, 102 (2012), 2410–2436.

37

[36] Rotella, Katie and Jennifer Richeson, “Motivated to ‘Forget’ The Effects of
In-Group Wrongdoing on Memory and Collective Guilt,” Social Psychological
and Personality Science, 4 (2013), 730–737.
[37] Sarafidis, Yianis, “Games With Time Inconsistent Players,” working paper
(2006).
[38] Stahl, Dale and Paul Wilson, “On Players’ Models of Other Players: Theory
and Experimental Evidence,” Games and Economic Behavior, 10 (1995), 218–
254.
[39] Tenbrunsel, Ann, Kristina Diekmann, Kimberly Wade-Benzoni, and Max Bazerman, “The Ethical Mirage: A Temporal Explanation as to Why We Are
Not as Ethical as We Think We Are,” Research in Organizational Behavior, 30
(2010), 153–173.
[40] Wittenbaum, Gwen, Sandra Vaughan, and Garold Strasser, “Coordination in
Task-Performing Groups,” Theory and Research on Small Groups, (2002), 177–
204.

38

