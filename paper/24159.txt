NBER WORKING PAPER SERIES

KNOWLEDGE SPILLOVERS AND LEARNING IN THE WORKPLACE:
EVIDENCE FROM THE U.S. PATENT OFFICE
Michael D. Frakes
Melissa F. Wasserman
Working Paper 24159
http://www.nber.org/papers/w24159

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2017

We are grateful for the very helpful comments received from Rochelle Dreyfuss, Jacob Goldin,
Mark Lemley, Matt Notowidigdo, Arti Rai, Kyle Rozema, Dave Schwartz, Neel Sukhatme, Neil
Thompson, and seminar participants at the Annual intellectual Property Scholars Conference and
the Intellectual Property Statistics for Decision Makers Conference. We are also grateful to
Bhaven Sampat for providing patent citations data. The work was funded by University of
Illinois at Urbana Champaign Research Board, Award 12088 and the Cornell Institute for the
Social Sciences Small Grant Award. We are grateful to Matt Berry at the National Center for
Supercomputing Applications at the University of Illinois for collecting data from the Patent
Officeâ€™s PAIR database. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
Â© 2017 by Michael D. Frakes and Melissa F. Wasserman. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including Â© notice, is given to the source.

Knowledge Spillovers and Learning in the Workplace: Evidence from the U.S. Patent Office
Michael D. Frakes and Melissa F. Wasserman
NBER Working Paper No. 24159
December 2017
JEL No. J01,M50,O30
ABSTRACT
Using application-level data from the Patent Office from 2001 to 2012, merged with personnel
data on patent examiners, we explore the extent to which the key decision of examinersâ€”whether
to allow a patentâ€”is shaped by the granting styles of her surrounding peers. Taking a number of
methodological approaches to dealing with the common obstacles facing peer-effects
investigations, we document strong evidence of peer influence. For instance, in the face of a one
standard-deviation increase in the grant rate of her peer group, an examiner in her first two years
at the Patent Office will experience a 0.15 standard-deviation increase in her own grant rate.
Moreover, we document a number of markers suggesting that such influences arise, at least in
part, through knowledge spillovers among examiners, as distinct from peer-pressure mechanisms.
We even find evidence that some amount of these spillovers may reflect knowledge flows
regarding specific pieces of prior art that bear on the patentability of the applications in question,
as opposed to just knowledge flows regarding general examination styles. Finally, we find
evidence suggesting that the magnitude of these peer examiner influences are just as strong, or
stronger, than the influence of the examination styles of supervisors.

Michael D. Frakes
Duke University
School of Law
210 Science Drive
Box 90362
Durham, NC 27708
and NBER
Michael.frakes@law.duke.edu
Melissa F. Wasserman
University of Texas
College of Law
727 E Dean Keeton Street
Austin, TX 78705
mwasserman@law.utexas.edu

An online appendix is available at http://www.nber.org/data-appendix/w24159

I.

INTRODUCTION
The economics literature has become increasingly interested in understanding how the

behaviors of individual agents are shaped not just by the various economic incentives that they
face but also by their social interactions with others. One setting where peer influence is likely to
be of critical import to economic growth is the workplace. To what extent are worker decisions
impacted by the corresponding behaviors of their co-workers, even when we focus on non-teambased tasks? A still small, but growing number of studies have begun to tackle this question and
have started to demonstrate the critical role of social interactions within the workplace. However,
various uncertainties and open questions remain. For instance, how do the magnitudes of these
peer influences compare with other key determinants in the workplaceâ€”e.g., supervisor
influences? Moreover, are co-workers responding to each other due to pressures to conform to
social norms, or are knowledge spillovers causing co-workers to learn from one another? And,
what are the nature of any such spillovers? Do they reflect flows regarding specific, technical
knowledge or do they reflect something more general?
In this paper, we confront these questions and the empirical challenges accompanying them
while studying the behavior of patent examiners within the U.S. Patent Office. Although context
undoubtedly matters in all questions of this nature, the institutional setting surrounding the Patent
Office and the rich data on individual examiner behaviors that the Patent Office makes available
offers a number of unique and novel tools by which we may approach these challenging inquiries.
One of the key benefits of exploring workplace behavior in the patent examiner context
is the tractability offered by the relatively homogenous nature of examinersâ€™ jobs. At the core,
examiners are tasked with reviewing patent applications and determining whether a patent should
be granted covering the underlying invention, a decision that can readily be codified and a decision

2

that will be the focus of this study. While this benefit may be more easily obtainable in low-skilled
worker settings, it is arguably rare to find high-skilled settings amenable to codification and
measurement of this sort.

Further helpful is the fact that U.S. patent examination is a

predominantly isolated and individual task (supervisory oversight aside), making it easier to
separate peer-based knowledge flows from what is simply the product of joint team-based efforts.
An additional benefit of the Patent Office context is that we are able to identify and observe
each examinerâ€™s peer group. Examiners are organized into operational units within the Patent
Office called Art Units, each of which is managed by a Supervisory Patent Examiner (or SPE).
Each Art Unit consists of roughly eight to fifteen patent examiners who review applications in
similar technological areas. Examiners in Art Units generally work in close proximity to one
another in the Patent Officeâ€”e.g., same floor, same section of the hallway, etc. In our empirical
investigation, we treat examiners within the same Art Unit as the relevant peer group; however,
we acknowledge that examiners may indeed socially interact with others from outside of these
organizational units. To the extent that examiners from other Art Units likewise impact examiner
behavior, our results may be seen as a lower bound for the extent of examiner peer influence.
In order to estimate examiner peer effects, we collected data on individual patent
applications filed with, and disposed of by, the Patent Office over a 12-year period, with records
reflecting the nature of the disposition of those applications and, importantly, the name of the
associated examiner and the Art Unit to which they belong. To these data, we merged additional
information that we collected via the filing of various Freedom of Information Act Requests,
including information about each examinerâ€™s tenure at the Patent Office, the names of the SPEs
within the corresponding Art Units, and the dates when examiners begin telecommuting.

3

The identification of peer effects is a task that faces several well-known econometric
problems (Manski 1993). At the outset, we note that applications themselves are effectively
randomly assigned to examiners within Art-Units. 1 This key fact alone, however, does not cure
all sources of endogeneity. To overcome concerns that examiners of similar dispositions may be
allocated to similar peer groupsâ€”which might otherwise explain any correlated behaviorsâ€”our
specifications include examiner fixed effects. Of course, even if the composition of peer groups
is randomly determined, one might observe correlated behaviors within groups not as a result of
actual peer influences but due to unobservable factors that are common to the groupâ€”e.g., due to
changes in supervisory policies. We take several approaches in alleviating these concerns,
beginning with the inclusion of SPE fixed effects in some specifications. This analysis explores
how examinersâ€™ grant rates change as the granting tendencies of the peers within their Art Unit
change over time while accounting for turnover in supervisors over that time period. Secondarily,
we estimate specifications with a rich set of Art-Unit-by-year fixed effects (or, alternatively, ArtUnit-by-bi-year effects). These specifications calculate scores reflective of peersâ€™ grant rates at an
Art-Unit-by-month level and thereafter explore how a given applicationâ€™s likelihood of being
allowed changes within a given Art-Unit-by-year cell as the granting proclivities of the examiners
within that cell (other than the examiner associated with the given application) likewise change.
Finally, to confront the so-called â€œreflectionâ€ problemâ€”e.g., a concern as to whether group
behavior affects individual behavior or merely reflects or aggregates individual behaviorâ€”we take
an approach inspired by Cornelissen et al. (2017) and create peer scores at any point in time based

1

If applications were assigned within Art Units based on qualityâ€”e.g., all of the highest quality applications would go to a particular examinerâ€”
that might tend to produce a negative association between individual examiner behavior and peer behavior. Lemley and Sampat (2012) and Frakes
and Wasserman (2017) interviewed a number of examiners to confirm the assumption that sorting of this nature does not occur and that applications
are randomly assigned within Art Units. A recent paper, however, by Righi and Simcoe (2017) documents evidence of within-Art-Unit assignments
based on sub-technology specializations. However, Righi and Simcoeâ€™s analysis finds no evidence to suggest that applications are sorted across
examiners based on the importance or claim breadth of the applications.

4

on the long-term, lifetime grant rates of the examiners comprising that peer group, as opposed to
the peer grant rates at that precise time. 2 To what extent do the collective inherent grant rates of
the peers that an examiner faces at a point in time influence her own grant rate at that time? With
this construction, changes in the peer score over time capture temporal changes in the composition
of the peer group as opposed to temporal changes in the granting practices of a given, stable set of
peers. By abstracting away from any effect that contemporaneous co-worker behavior may have
on examiner behavior, this approach may likewise lead to lower-bound estimates of the degree to
which examiners influence each otherâ€™s practices.

Moreover, by de-emphasizing

contemporaneous effects through the use of peer scores based on time-invariant grant rates, this
approach to resolving the reflection problem also alleviates concerns that the peer-to-individual
grant rate associations we observe are driven by time-varying common unobservables.
While identifying true peer effects in the first place is a task that confronts various
econometric issues, identifying the mechanisms underlying any such effects faces challenges of
its own. If any peer influences do exist, do they derive from a story of peer pressure in which an
examinerâ€™s own views towards granting patents is shaped by some degree of shame in departing
from a known social norm or do they derive from a story in which examinerâ€™s learn how to conduct
examination reviews through their social interactions with peer examiners? To attempt to separate
these stories, we take advantage of the temporal breadth of our data and explore the dynamics of
any observed peer effects. If peer influences follow from a learning mechanism, we would expect
that examiners would be most influenced by their peers soon after the affected examiners start

2
In the alternative, we attempt to create even more pre-determined peer scores by calculating each examinerâ€™s overall grant rates in the years
preceding the year in which the subject application is being disposed of by the relevant examiner. The results are virtually identical across these
alternative constructions. We use lifetime rates as the primary specification as the purely pre-determined approach will tend to leave few
observations for examiners early in the sample period to characterize granting tendencies. We also consider other alternatives to determining
individual examiner effects in our construction of peer effects, including those that shrink individual examiner effects towards the mean using
signal-to-noise reliability factors (Kane and Staiger 2008).

5

their jobs with the Patent Office. Under a learning story, we would then predict that in the ensuing
years the practice styles learned during their initial years would persist and that future changes in
peer composition would have weaker influence. Moreover, under a learning story, we would
predict that new examiners are influenced to a greater degree by their more experienced peers
rather than by their similarly inexperienced co-workers.
Investigating dynamics of this nature will not only allow us to shed light on the mechanisms
underlying any peer influence, but may also further support the identification of peer effects as a
general matter. For instance, to the extent that the relationship between examiner grant rates and
peer grant scores is indeed the strongest in the case of new examiners, especially in the case of
new examiners surrounded by more experienced peers, it is also likely the case that (a) these
associations represent effects originating from the peers themselves rather than the other way
around (thereby further appeasing reflection problem concerns) and (b) the correlated behaviors
that we observe are not merely the result of shocks common to the entire Art Unit.
Ultimately, our results suggest a striking degree of peer influence within the Patent Office
that is likely to arise to some degreeâ€”though perhaps not exclusivelyâ€”through knowledge
spillovers among examiners, with findings consistent with each of the predictions of the learning
story. In the face of a one standard-deviation increase in the inherent grant rate of her peer group,
an examiner in her first two years at the Patent Office will increase her own grant rate by roughly
7.6 percentage points, representing a roughly 0.15 standard-deviation increase in her grant rate.
Moreover, subsequent changes over her career in the composition of her peer group are associated
with notably weaker influences on her grant rate relative to the peer effect during her early years
with the Patent Office. Further, results from lagged specifications suggests that peer influences
tend to persist over time, rather than being fleeting in nature. Collectively, these findings suggest

6

that examiners establish somewhat durable practice â€œstylesâ€ early in their career that generally
persist even in the face of subsequent changes in their workplace environment. Finally, we find
that these early-career effects are stronger when we construct peer scores based on the inherent
grant rate of the more experienced co-workers surrounding her.
To put these magnitudes in perspective, we compare the degree to which examiners appear
to learn from their co-workers to the degree to which they learn from the Supervisory Patent
Examiner (SPE) overseeing their Art Unit. For these purposes, we draw on information from each
SPEâ€™s tenure as an examinerâ€”to characterize that SPEâ€™s own views towards patent examinationâ€”
and estimate similar specifications that draw on within-Art-Unit changes over time in the granting
propensities of assigned SPEs. Through this exercise, we determine that peer influences on new
examiners are considerably stronger than supervisory influences.
We support these findings through a range of robustness and falsification checks. For
instance, we find that peer influences are weaker when constructing peer scores based on the set
of examiners that telecommute for at least 4 days a weekâ€”i.e., peers that are less present at the
office. Moreover, we find stronger signs of peer-based learning and influence in the case of
rejections based on obviousness grounds relative to the case of rejections based on lack-of-novelty
grounds. This is intuitive insofar as one might predict a stronger scope for learning in the
application of the obviousness standard given that it is arguably more nebulous and challenging to
apply in comparison with lack-of-novelty rejections. Finally, we move beyond viewing the job of
examiners as simply rejecting or allowing patent applications and consider a more nuanced
behavior of examiners: affirmatively working with applicants to narrow initially invalid claims to
the point where they become allowable. Consistent with the granting/rejecting results, we continue
to document strong peer influences in the case of these claim-narrowing behaviors.

7

Though the workplace peer effects literature has, to our knowledge, yet to dig deeper into
peer effects mechanisms than coarsely distinguishing between standard peer pressures and
knowledge spillovers, employers and policymakers may indeed wish to know the more precise
nature of any such mechanisms. For instance, is the information flow among patent examiners
one that respects general examination practice styles and strategies? Or, something more specific
and technical? For instance, are examiners learning of specific pieces of prior artâ€”e.g., particular
prior patentsâ€”from their peers that may bear on the patentability of the applications they are
presently reviewing?

In an additional empirical exercise, we attempt to uncover specific

knowledge flows of this sort taking advantage of another rich dimension to the data available in
the patent setting: micro-level patents citations data. We find that when reviewing applications,
examiners are significantly more likely to cite to a prior art reference that is among the set of â€œpetâ€
or favorite prior art references of their peer examiners when those peer examiners are not
telecommutingâ€”and are thus socially accessibleâ€”relative to when those peer examiners are
telecommuting. This finding lends support to a claim that at least some degree of the knowledge
flows among examiners capture a rich degree of specificity.
This analysis holds a number of potentially important policy implications given, in part,
the significant social welfare consequences of examinersâ€™ granting decisions. Should examiners
be overly permissive in their practices and routinely grant patents on inventions that are already
known or represent only a trivial advancement over current scientific understanding, they may
burden society with the deadweight losses associated with monopoly protection without reaping
the benefits of spurred innovation (Nordhaus 1969). In addition, invalidly issued patents can
inhibit follow-on discoveries in markets characterized by cumulative innovation (Scotchmer 1991,
Sampat and Williams 2014, Galasso and Schankerman 2014). Scholars and commentators have

8

argued that the Patent Office may indeed be issuing too many patents; others have emphasized the
equitable implications and deadweight losses associated with the substantial heterogeneity in grant
rates that have been observed across examiners (Frakes and Wasserman, 2017). To begin to
address any problems associated with elevated and/or inconsistent granting practices, it is critical
to first understand the determinants of such practices. This paper demonstrates the key role that
peer learning has to play in the process, a finding that may hold various implications for the ways
in which the Patent Office may seek to train and allocate new hires.
The rest of the paper proceeds as follows. In Section II, we provide a background on the
related literature and on the patent examination process. In Section III, we discuss our data and
methodology. In Section IV, we present our results. Finally, in Section V, we conclude.
II.

Background

II.A. Literature Review
This paper contributes to several literatures, beginning with the growing literature
exploring peer effects within the workplace. In a recent, path-breaking analysis, Cornelissen et al.
(2017) estimates peer effects within firm-occupation groups in an entire local labor market in
Germany, focusing on peer effects on wages as opposed to concrete behaviors of workers. The
breadth of the sectors included in their analysis allows them to separately test for peer influences
in low-skilled and high-skilled settings. They document weaker peer influences in the latter
setting, which leave the authors to suggest a potentially weak role for knowledge spillovers in the
workplace given that spillovers are more likely to be relevant in such high-skilled sectors.
To further separate knowledge spillover effects from peer-pressure effects, Cornelissen et
al. also estimate distributed lag specifications and document lagged peer effects among high skilled
sectors and near zero coefficients of the lagged peer score in the low-skilled sample. They suggest

9

that these findings support some role for knowledge spillovers in the skilled settings and a lack of
spillovers in the low-skilled settings. Though the authors do not fully spell out their interpretation
of this lagged coefficient, a near zero value for this coefficient would tend to suggest that a
temporary change in the peer score of interest would have only a contemporaneous effect and no
lingering effect (a zero lag would have a different interpretation in the face of a hypothesized
permanent change in the peer score). Presumably, if one thought that workers would learn from
their peers, then one might indeed expect a long-term effect of even a temporary shock. In other
words, if knowledge spillovers exist, a given peer shock may alter worker behavior now and in the
time ahead even in the face of a subsequent alteration of that peer group in future periods.
While these lagged findings do suggest some degree of learning in high skilled settings,
Cornelissen et al.â€™s analysis does not fully explore this learning story and does not identify the
extent to which peer influences help shape initial practice styles early in workersâ€™ careers that may
persist throughout their careers. Instead, their analysis effectively groups together new and
seasoned workers to test for more generic markers of learning, whether initial or ongoing learning.
By attenuating an estimation of early-career effects, this analysis may arguably be seen as
underselling the role of peers in determining worker behavior and the heterogeneous pathways that
workers set out upon. Moreover, should one indeed find stronger evidence of peer effects early in
a workerâ€™s career, such a finding would further support a learning interpretation and further cut
against the possibility of standard peer-pressure effects, including peer-pressure effects that
manifest with a delay and that might lead to lagged coefficients of the sort documented in
Cornelissen et al. (2017).
Jackson and Bruegmann (2009) come closer to documenting a story of this nature. Using
longitudinal data on student achievement and teacher characteristics, they find that teachers

10

experience greater test score gains among their students when they are surrounded by more
effective peer teachers. Moreover, in the associated web appendix, they find that new teachers are
even more sensitive to peer quality, supportive of a learning mechanism. They note, however, that
they are unable to disentangle a story in which new teachers truly learn from their peer teachers
(reflective of knowledge spillovers) from a story in which being surrounded by more effective
peers merely gives new teachers more time to engage in self-learning (a learning-by-doing
mechanism unrelated to knowledge spillovers). The idea behind this latter story is that teachers
do share some common tasks in overseeing the teaching of a particular grade; being surrounded
by better peers may reduce the amount of time a given teacher needs to spend on these common
tasks, opening up more time for individual learning. Importantly, this school teacher setting differs
from the patent examiner context in that new patent examiners do not share analogous common
tasks with her their peers, in which event the patent context may face fewer concerns over
separating a learning-from-co-worker story from a co-worker-induced self-learning story. 3
In addition to building on the above co-worker-related studies, our analysis contributes to
a larger literature on learning within the workplace. The management science and organizational
theory literatures, among others, have long recognized that early moments within careers at
particular organizations are especially critical in determining how workplace practice styles are
developed, often theorizing that initial hiring conditions may become â€œimprintedâ€ on employees. 4
Behind this imprinting theory is the contention that new hires are more malleable than experienced
workers within an organization and, in light of the uncertainty surrounding their new jobs, are

3

Other workplace peer effects studies include Guryan et al. 2009 (professional golfers), Gould and Winter 2009 (professional baseball players),
Mas and Moretti 2009 (supermarket workers), Waldinger (2012) (academic scientists), and Azoulay et al. (2010) (academic superstars), Our study
is also related to Hoâ€™s (2017) experimental work on peer review within government agencies. Guryan et al. (2009) likewise look for heterogeneous
workplace peer effects by the experience level of professional golfers and find more peer sensitivity at higher experience levels, perhaps inconsistent
with their expectations of greater sensitivity of new golfers.
4
For a recent survey paper regarding imprinting theories, see Marquis and Tilcsik (2013). Among many others, example analyses of imprinting
are found in Allen and Meyer 1990 and Baron et al. 1999. These studies are also related to a literature that explores the importance of initial
conditions in developing individual styles of behavior more broadly. See, for example, Malmendier & Nagel (2011).

11

more likely to be operating from a blank state (DiRenzo 1977; Ashforth and Saks 1996). 5 Once
imprinting has occurred and these styles have been established, they may persist even in the face
of subsequent environmental changes. 6
Finally, our paper builds upon a growing literature empirically analyzing patent examiner
behavior. Early studies in this still nascent literature demonstrated a substantial degree of
heterogeneity in patent office outcomes across patent examiners at the U.S. Patent Office
(Cockburn, Kortum, & Stern, 2003; Lichtman, 2004; Mann, 2014). Subsequent studies have begun
to unpack the origins of this heterogeneity. 7 In this vein, Lemley and Sampat (2012) estimate a
monotonically increasing relationship between years of examiner experience and examiner grant
rates. Frakes and Wasserman (2017) decompose the experience correlation found in Lemley and
Sampat (2012) into its various parts. Frakes and Wassermanâ€™s analysis suggests that much of that
positive correlation between experience and grant rates may be due not to experience itself but to
increases in examiner pay-grade levels, which are themselves associated with substantial
reductions in the amount of time given to examiners to review applications (which, in turn, may
crowd out time to find and articulate bases of rejections). Another key factor driving the
experience-grant-rate correlation is the examinerâ€™s hiring-year cohort, a factor identified in Frakes
and Wasserman (2017) but more fully explored in Frakes and Wasserman (2016). Examiners hired
prior to 2002â€”at a time in which the philosophy of the Patent Office was one characterized by a
very permissive granting styleâ€”tended to exhibit higher grant rates throughout their careers. In
particular, they would tend to maintain higher rates even in the face of a changing philosophy of

5

As stated by Dokko et al. 2009, during this the initial period of employment, it is believed that â€œcognitive models that . . . [individuals] hold can
be challenged and replaced with scripts and schema that are more congruent with the new environment.â€
6
In this light, our analysis and the imprinting literature in general is likewise related to a related literature about path dependence and historical
happenstance (see, for example, David 1985).
7
Other studies have not necessarily attempted to explain this heterogeneity, but have attempted to embrace it for identification purposes. That is,
a number of recent stories have taken advantage of heterogeneity in the granting tendencies of examiners, along with the random assignment of
applications to examiners, to estimate the effect of receiving a patent on various outcomes, including the effect of receiving patents on follow-on
innovation (Williams and Sampat 2014).

12

the Patent Office in the mid-2000s that called for a more restrictive stance. New examiners hired
in the mid-2000s, on the other hand, did reflect that changed philosophy. In other words, initial
career conditions appear to matter significantly in explaining patent examiner behavior. Missing
from Frakes and Wasserman (2016, 2017) is an appreciation of the role that co-workers may play
in those initial environments.
II.B. Background on Patent Examination Process
Every patent application filed with the Patent Office contains a specification describing the
invention, and a set of claims that defines the metes and bounds of the rights the applicant is
seeking. Incoming applications are first routed to an Art Unit, an organizational unit consisting of
eight to fifteen patent examiners who review applications in the same technological field. Upon
arrival, the Supervisory Patent Examiner (SPE) of that Art Unit randomly assigns the application
to a specific examiner (Lemley & Sampat, 2012).

That examiner will typically begin her

examination by conducting a prior art search, that is a search of previous patents, patent
applications, or other publications, that are material to the patentability of the claimed invention.
After completing this search, the examiner will assess the patentability of the invention in
light of the criteria outlined in the Patent Act. Two of these key criteria are the novelty and
nonobviousness requirements. Examiners may reject an application for lack of novelty if they
determine that the claimed invention is covered, in its entirety, by a single prior publication or
patent. An obviousness rejection is a little more complicated. Such a determination requires an
examiner to start with a prior art reference that covers only a portion of the invention and then
piece together additional references or rely upon what is known to one of ordinary skill in the art
in order to determine whether it would be â€œobviousâ€ to modify any one of the cited prior art
references to achieve the claimed invention.
13

It is critical to emphasize that there are two types of examiners working within each Art
Unit. Examiners at pay grades GS-13 and below on the General Schedule pay scale constitute the
first type and are known as known as â€œsecondaryâ€ or â€œassistantâ€ examiners. After completing a
special evaluation program, examiners may be promoted to become â€œprimaryâ€ examiners
(generally reaching GS-14 at this time). Primary examiners have full authority to sign off on all
aspects of their reviews without the need for supervisory review. Though primary examiners
continue to be assigned their own applications to review, they also help serve as quasi-supervisors
for assistant examiners. That is, while assistant examiners independently review, and complete
the bulk of the work associated with, the applications assigned to them, they must have their
reviews and decisions approved by a supervisorâ€”either by a primary examiner or by their SPE.
While SPEs do help sign off on the reviews of assistant examiners, they no longer review
applications of their own (unlike primary examiners). However, their supervisory functions go
beyond checking the work of assistant examiners, as SPEs are also tasked with overseeing the
training (initial and ongoing) of the examiners within their Art-Unit and with making sure that
their Art Units implement general Patent Office policies and directives.
Our analysis below endeavors to account for the different roles of assistant examiners,
primary examiners and SPEs. In particular, given the dual roles of primary examiners, we make
sure in our analysis below to separate GS-14 examiners from sub-GS-14 examiners when
constructing peer groups in order to identify true â€œpeerâ€ effects. In other words, we aim to
understand how the behavior of assistant patent examiners are influenced by their peer assistant
examiners. Nonetheless, we also take advantage of this institutional feature and estimate how the
granting behavior of assistant examiners are affected by the granting philosophies of the group of
primary examiners working within their Art Units. This exercise effectively allows us to compare

14

the magnitudes of pure peer effects with quasi-supervisor effects. We then take that comparison
one step further and compare each of these effects with pure supervisor effects. To capture these
latter effects, we use the granting practices of SPEs when they previously acted as examiners to
characterize the granting philosophies of SPEs and thereafter observe how granting behaviors of
examiners change in connection with within-Art-Unit changes in such philosophiesâ€”driven by
within-Art-Unit changes in SPEs over time.
III.

Data and Methodology
III.A Data
We collected data on individual patent applications from the Patent Officeâ€™s Patent

Application Information Retrieval (PAIR) database, covering roughly 1.4 million utility patent
applications that were filed on or after March, 2001 and that reached a final dispositionâ€”i.e.,
excluding ongoing applicationsâ€”by July 2012.

These data include, among other things,

information on whether or not the application was granted, the name of the examiner charged with
reviewing the application, the Art Unit to which the application was assigned, and information on
the bases of rejections associated with the applicationâ€”e.g., whether it was subject at any point to
an obviousness rejection or a lack-of-novelty rejection. 8
Through a series of Freedom of Information Act (FOIA) requests, we also collected a range
of information about examiners, including the year in which they joined the Patent Office (left
censored at 1992), and their GS-level over each year in our sample. Moreover, for those examiners
participating in the Patents Hoteling Program (PHP), which allows examiners to work from home
at least 4 days a week, we collected information on the precise day in which they started to

8
The rejection-criteria data was collected based on a textual analysis of office actions following the execution of optical character recognition
programs to office actions uploaded to the PAIR database. Further details on this data collection can be found in the Online Appendix to Frakes
and Wasserman (2017).

15

telecommute. 9 We then merged these examiner-specific fields with the application-level data
(using a fuzzy-name-matching application).
Through additional FOIA requests, we collected information about the identity of the
Supervisory Patent Examiner (SPEs) for the Art Unit associated with that application. For those
SPEs that were promoted to that position during our sample, we observed information about the
applications that those individuals reviewed while they were patent examiners prior to such
promotions, allowing us to calculate their pre-SPE grant rates, a metric that we use to proxy for
their general granting dispositions. For those SPEâ€™s promoted to that rank prior to the beginning
of our sample, we were unable to determine their examination style. Overall, we are able to assign
pre-SPE grant rates for the SPEs associated with given applications for roughly 38% of the
applications in our sample.
Table 1 provides summary statistics for the key variables in the analysis. Across all
applications and all examiners, applications are granted roughly 70 percent of time throughout our
sample. 10 Table 1 also presents the mean peer / supervisory grant rate across the three relevant
peer / supervisory groups in our analysis: (1) assistant examiners, (2) primary examiners and (3)
SPEs. As found in Frakes and Wasserman (2017), examinersâ€™ grant rates tend to increase as they
rise within the ranks in the Patent Office. With this in mind, the mean peer / supervisory grant
rates unsurprisingly increase as we move across these three groups, with the pure peer scoreâ€”the
grant rate of the assistant examinersâ€”coming in at roughly 65%.
III.B. Methodology

9
To be eligible for the PHP, patent examiners must have achieved a GS-12 level, have positive performance ratings, and have worked at the Agency
for at least two years. The PHP began in 2006. Over 86% of those eligible to participate in the Patent Officeâ€™s teleworking programs in fact elect
participation.
10
In calculating grant rates, it is important to clarify that Requests for Continued Examinations do not count as rejections of one application and
filings of a new applications; rather, they count as an intermediate step within the same application and thus do not contribute to an increase in the
grant-rate denominator. Continuation applications, however, are counted as new applications.

16

To begin to explore how patent examiners learn from their peer examiners, we estimate the
following specification, restricted to the applications completed during an examinerâ€™s first six
years at the Patent Office (this restriction being discussed further below and also lifted below):
ğºğºğºğºğºğºğºğºğºğºğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ = ğ›¼ğ›¼ + ğ›„ğ›„ğ¢ğ¢ + ğ››ğ››ğ¤ğ¤ + ğ›…ğ›…ğ’•ğ’• + [ğ›‰ğ›‰ğ’”ğ’” ] + ğ›½ğ›½1 (ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– )
+ ğ›½ğ›½2 (ğŸ™ğŸ™(ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = {3,4}))
+ ğ›½ğ›½3 (ğŸ™ğŸ™(ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = {5,6}))

+ ğ›½ğ›½4 (ğŸ™ğŸ™(ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = {3,4}) ğ‘‹ğ‘‹ (ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– ))

(1)

+ ğ›½ğ›½5 (ğŸ™ğŸ™(ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = {5,6}) ğ‘‹ğ‘‹ (ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– )) + ğ›ƒğ›ƒ6 ğ—ğ— ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘

+ ğœ€ğœ€ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘

where a indexes the individual application, i indexes the individual examiner, k indexes the Art
Unit to which the application is assigned, and t indexes the year in which the application is disposed
of by the examiner. GRANTaikt indicates whether or not the given application was allowed by the
examiner. ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ¸ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– captures the experience level in years of the examiner (based on the year of

application disposition matched with annual Patent Office rosters). Art-Unit and year effects are
captured by ğ››ğ››ğ¤ğ¤ and ğ›…ğ›…ğ’•ğ’• , respectively. Examiner fixed effects are captured by ğ›„ğ›„ğ¢ğ¢ , allowing us to

account, among other things, for endogenous allocations of examiners with particular
characteristics to certain peer groups. ğ—ğ— ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ includes other application characteristics including

whether the applicant is a large or small entity (as the Patent Office uses such terms for fee-setting
purposes), whether the application has foreign priority, the duration of the examination period (and
its square), and the GS-level level of the examiner at the time of disposition.11
ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– represents the peer score of interest for our analysis. To calculate this score, we

begin by determining the lifetime grant rate for all examiners in the sample (the percentage of

11
The entity size of the applicant is not included in the machine-ready PAIR data publicly disseminated by the Patent Office; however, we were
able to collect this information through our own Optical Character Recognition analysis of the bulk PAIR files.

17

applications that they allow over their tenure at the Patent Office). Given random assignment of
applications to examiners, this rate should be indicative of the examinerâ€™s general disposition
towards allowing patentsâ€”i.e., we should not be concerned about high grant rate examiners
systematically being assigned the highest quality applications (Sampat and Williams 2014). For
each application, we then calculate ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– by taking the average of the lifetime grant rates for

all examiners in the same Art-Unit-by-year cell as the application in question, leaving out the
contribution of the examiner reviewing the application at issue.

Rather than drawing on

contemporaneous changes in the granting practices of a stable set of peers, this approach identifies
the influences of peersâ€™ granting practices on an examinerâ€™s grant rates by drawing on changes in
the composition of the peer group over time within an Art Unit.
In certain specification checks, we include SPE fixed effects, ğ›‰ğ›‰ğ’”ğ’” , to account for changes in

supervisors within Art Units over time, which might otherwise represent shocks common to all
examiners within the affected Art Unit (which, in turn, might otherwise explain peer associations).
The SPE rosters that we obtained from the Patent Office allow us to assign SPEs to over 90% of
the observations in our sample. In yet another specification check meant to address concerns over
common unobservables, we calculate peer grant scores at the Art-Unit-year-month level and
impose a full set of Art-Unit-by-year fixed effects to allow for yearly changes in Art-Unit-specific
supervisory policies. We leave this latter specification as a robustness check in that it relies heavily
on within-year changes in peer composition. Considering that applications are actually completed
over a process of time that often spans greater than a year, such a fine-grained temporal analysis
requires relatively strong assumptions about the critical significance of the time of application

18

disposition itself. 12 With this in mind, we also take a more in-between approach and estimate
specifications with Art-Unit-by-bi-year fixed effects, allowing more time within Art-Unit-by-time
cells to observe fluctuations in peer composition.
As further robustness exercises, our analysis below takes several alternative approaches in
constructing the relevant peer score. For instance, rather than using overall lifetime grant rates to
characterize a peer examinerâ€™s granting proclivity, we consider a peer examinerâ€™s overall grant
rates up to year t-1 to characterize that her granting proclivity at year t. Moreover, instead of using
overall grant rates, we estimate specifications that use lifetime grant rates that are adjusted for
certain characteristics of examiners over that lifetime, mainly their experience levels, paygrade
levels, and the years and Art Units in which they practiced. We perform these adjustments by
regressing an examinerâ€™s grant rates on these various characteristics and a set of examiner fixed
effects and using the estimated fixed effects to characterize an examinerâ€™s lifetime granting
proclivities. In Figure 1, we depict a kernel plot of the distribution of estimated examiner fixed
effects across the various examiners in our sample, demonstrating the substantial degree of
examiner grant-rate heterogeneity underlying this empirical exercise.
In our primary specifications, we limit the above analysis to applications reviewed by
assistant examinersâ€”that is, by examiners at GS-levels 13 and belowâ€”while also making sure to
construct the peer score at time t based on the composition of other assistant examiners in their
Art-Unit at time t. This ensures that we are picking up pure peer effects since none of the
examiners in this group would be serving any supervisory function over the others. In the
alternative, we estimate specifications similar to that above but replace ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– with a similar
12

Recent research by Frakes and Wasserman (2016) arguably support this assumption to some degree, however, in demonstrating the often
insufficient and cursory nature of the decisions that examiners make in their early rounds of review, perhaps as a result of procrastination
behaviors.

19

measure meant to reflect: (1) the mean inherent grant rates of the primary patent examiners (GSlevel 14) practicing in the same Art Unit at year t and (2) the inherent grant rates of the Supervisory
Patent Examiners overseeing that Art Unit in year t. These latter specifications allow us to explore
quasi-supervisory and supervisory influences, respectively, with which we can compare to the
degree of peer influences.
Key to the above specification is its ability to explore how peer (and/or supervisory)
influences evolve with an examinerâ€™s tenure at the Patent Office. As such, the key coefficients of
interest in the above specification are those capturing how peer effects vary by the experience
group of the examiner reviewing the application in question, where we use two-year experience
bins and where we focus, at least in our primary specifications, on examiners within their first six
years at the Patent Office. 13 With the reference group being examiners in their first and second
year at the Patent Office, the estimated coefficient of ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– , ğ›½ğ›½1, indicates the degree to which

an examinerâ€™s grant rate is associated with her peer examinerâ€™s granting tendencies during her first

two years at the Patent Office, drawing on within-Art-Unit changes in peer composition over that
time to derive that estimate. ğ›½ğ›½4 , the coefficient of the interaction between the peer grant score and
the indicator for being in the third and fourth year at the Patent Office then captures the degree to
which subsequent changes in peer composition during this next stage of her career are associated
with the grant rate that she applies during that third and fourth year, where the magnitude of this
effect is interpreted with reference to first-and-second-year effect. We group experience bins into
two-year groups in order to allow for temporal variation within those groups in peer composition.
Given the critical nature of this dynamic analysis to our empirical exercise and to our aim
to look for markers of examiner learning, we attempt to construct this dynamic specification in the

13

The results are robust to alternative groupings of experience bins.

20

most balanced way possible. As such, we limit the analysis in our primary specifications to those
examiners that we can observe throughout our sample period at each of their first, second, third,
fourth, fifth and sixth years of work experience and limit our analysis to those applications that
they review over that time. Accordingly, in our primary specifications, we drop those examiners
that either stay at the Patent Office for a shorter period of time during our sample or that started at
the Patent Office prior to our sample beginning (which we can flag with the backdated rosters we
received from the Patent Office). Nonetheless, as robustness exercises, we also estimate the same
specification indicated above but in an unbalanced wayâ€”e.g., including examiners that start their
fourth year at the Patent Office at the beginning of our sample and use their observed behavior to
identify peer influences at the fourth year and beyond. In yet other specification checks, we
estimate unbalanced specifications that follow examiners over their entire careers.
In the results section below, we also highlight several additional modifications to the above
design, allowing us to more fully explore an examiner learning story. All empirical specifications
are clustered at the Art Unit level to account for auto-correlation within Art Units over time.
IV.

Results

IV.A. Peer effects
We present the results from our primary specification in Column 1 of Table 2. As reflected
by the estimated coefficient of the peer score variable, we find that a change from 0 to 100
percentage points in the mean inherent grant rate of an examinerâ€™s peer group is associated with a
roughly 43 percentage point increase in her own grant rate during her first and second year at the
Patent Office. Interpreted differently, these results suggest that a one standard deviation increase
in the peer grant rate is associated with a 7.6 percentage-pointâ€”or a roughly 0.15 standarddeviationâ€”increase in an examinerâ€™s own grant rate at the beginning of her career. During the
21

third and fourthâ€™s year of an examinerâ€™s tenure, we find that a subsequent one-standard deviation
change in the grant rate of her peers is association with a 3.1 percentage-point lower increase in
her own grant rate than it was during her first and second year. Furthermore, a one-standard
deviation increase in the peer grant score during her fifth and sixth years at the Patent Office is
similarly associated with about a 3.2 percentage-point lower increase in her grant rate relative to
the first and second year effect. In Column 2, we show that these results are nearly identical when
using an unbalanced sample of examiners over their first six years of their career.
In Table 3, we demonstrate that this pattern of resultsâ€”i.e., a strong early career effect that
soon weakensâ€”is robust (subject to some fluctuations in magnitudes) to a number of alternative
specifications, including those that (1) include SPE fixed effects (for those Art Units-year cells for
which we were able to collect data on the relevant SPE), (2) impose Art-Unit-by-year fixed effects
(while calculating peer grant scores at the month-year level) and Art-Unit-by-bi-year fixed effects,
(3) calculate peer scores (inherent peer granting tendencies) by using peer examiner grant rates in
all of the years prior to the year of the application in question, (4) calculate peer scores by using
risk-adjusted lifetime peer grant rates, adjusting for certain characteristics of the examiners
(mainly, experience levels and GS-levels), (5) calculate peer scores by using an empirical Bayesian
estimation approach that effectively modifies the above risk-adjusted approach to further adjust
predicted examiner grant rates to reflect their reliability by shrinking noisier estimates towards the
mean, 14 (6) likewise use an unbalanced sample of examiners but that also follow examiners over
their entire careers as opposed to just their first six years. In Figure II, we graphically depict the
results from this latter full-career specification.

14
This approach is inspired by various studies in the teacher value-added literature, for instance Kane and Staiger (2008) and Chetty et al. 2014).
Further details on this estimation strategy are provided in the Online Appendix.

22

This strongly declining influence of peer composition beyond an examinerâ€™s early career
moments is consistent with a model of examiner learning. As is well supported empirically by the
examiner-heterogeneity literature (Cockburn et al. 2002), the Patent Office extends considerable
discretion to examiners in conducting their reviews. But, how do examiners learn to operate within
these bounds of discretion? Under various models of learning, one would predict that examiners
would draw on certain sources of informationâ€”whether from self-experience or from
communication with others about their experiencesâ€”to develop a practice style within this range
of discretion. Moreover, under such models, they may be especially likely to do so early during
their careers when they are most impressionable. 15 Once developing that style, one would predict
that further stimuli in subsequent years would be less influential in further shaping granting
practices (Marquis and Tilcsik 2013). However, considering the nature of their jobsâ€”i.e., dealing
with evolving technologiesâ€”we would not necessarily predict that learning processes (and the
influence of peers on learning) would come to a complete halt later in an examinerâ€™s career; we
may simply predict a diminished role for learning. Not only do the dynamic pattern of results
present in Columns 1 and 2 of Table 2 and in Table 3 provide support for the claim that examiners
begin to develop their practice style soon after starting with the Patent Office, but they also support
the hypothesis that much of the source of information behind this learning comes from an
examinerâ€™s peers. The fact that peer influences do not completely diminish later in an examinerâ€™s
career may be consistent with the above supposition that examiners may continue to learn to some
degree throughout their careers. However, that residual peer effect may also be consistent with

15
Consider for instance models of imprinting which broadly suggest that individualsâ€”e.g., employeesâ€”may during particularly sensitive moments
begin to take on characteristics reflective of the environment during those moments and persist with those characteristics moving forward even in
the face of subsequent environmental changes. Marquis and Tilcsik (2013). When applying such models to individual employees, this literature
often focuses on early career moments as capturing these sensitive times during which the subjects are especially malleable. Other models might
lead to similar implications through predictions that employees are more likely to invest in building human capitalâ€”invest in learningâ€”when they
have longer time horizons in front of themâ€”i.e., when they have less experience (Jackson and Bruegmann 2009).

23

some role for standard peer pressure behaviors among examiners. We return to this ongoing
learning point below when discussing lagged effects and when discussing knowledge flows
regarding specific pieces of prior art.
Under a story of learning, in addition to predicting a diminishment in the influence of
stimuli later in an examinerâ€™s career, we would also predict a persistent effect of any stimuli that
they experience in the past. To explore the durability of initial influences more directly, we regress
the incidence of an application being granted on the peer grant score along with a 2-year lag of
that peer score, in addition to the various controls included in equation (1). 16 A positive coefficient
of the lagged term would either suggest a persistent effect of a past temporary shock or an effect
from a permanent shock in peer composition that grows over time. Either interpretation would
document persistence in peer effects that is arguably more consistent with a model in which
examiners learn from one another than with a model in which examiners simply wish to conform
in order to avoid social stigma (in the latter case, one would perhaps expect more fleeting responses
to temporary shocks in peer composition). We note at the outset of this exercise that we cannot
properly evaluate this question while looking at examiner decisions in their first and second year
at the Patent Officeâ€”after all, any relationship between an examinerâ€™s grant rate in the period of
time prior to her second work anniversary and the peer score for that Art Unit a full two years prior
would not be informative on any learning behavior of that particular examiner (since she was not
there at that prior time). However, refining our balanced sample a little further, we can ask how
examiner behavior between their third and sixth year at the Patent Office is shaped not only by
their contemporaneous peer scores but also by their lagged peer scores. We simplify this endeavor

16
We choose a 2-year lag time period as opposed to a 1-year lag (as used in Cornelissen et al. 2017), again considering that patent applications are
themselves processed over a period of time often spanning a year, in which we event, we hesitate to model temporal dynamics on too fine-grained
of a basis. That being, said the results from the 1-year lagged specifications are nearly identical to the 2-year lag specifications we choose as our
primary specification. Moreover, these results also generalize to a consideration of longer lagged periods.

24

by not interacting these contemporaneous and lagged effects by separate experience groups over
this range (a specification that would otherwise entail two dimensions of interactions). Moreover,
in light of this choice to test for lagged responses in generalâ€”without separately testing for lagged
responses for each experience interaction termâ€”we also estimate specifications that test for lagged
responses throughout an examinerâ€™s entire career (doing so in an unbalanced approach), as
opposed to limiting our focus solely to examiners between their third and sixth years.
We present the results from these lagged specifications in Columns 4-7 of Table 4. In the
balanced sample specification pooling examiners over their third-through-sixth years at the Patent
Office, we estimate a coefficient of the contemporaneous peer grant score of roughly 0.25 and a
coefficient of the lagged peer score of roughly 0.12, consistent with the expectations of a learning
mechanism behind the documented peer influences. The extent of this lagged effect is robust to
the estimation of an unbalanced sample that consider examiners in all years beyond their second
year and to the inclusion of SPE fixed effects, as demonstrated by Column 5 and 6 of Table 4. The
fact that we observe lagged effects on average even when tracking examiners throughout their
entire careers may also suggest that the residual role for peer influences we observe later in an
examinerâ€™s career (discussed above) may indeed be reflective of ongoing learning as opposed to
simple peer pressure.
These patterns of persistence complement prior research in Frakes and Wasserman (2016)
and Frakes and Wasserman (2017), which found that a key determinant of an examinerâ€™s grant rate
is the year in which she is hired, combined with the general philosophy of the Agencyâ€™s central
administrators at such times. Examiners starting in the mid-2000sâ€”at a time when the Agency
Director Jon Dudas espoused a more restrictive stance towards grantingâ€”consistently exhibited a
roughly 7-10 percentage point lower grant rate throughout their careers relative to examiners

25

starting prior to 2003â€”an era commonly perceive to be characterized by a more permissive
granting culture (perhaps evidenced by the Patent Office itself when stating in its 2001 Corporate
Plan that its primary mission was to help â€œcustomersâ€ get patents). The magnitude of these hiringyear cohort effects are of a comparable size to the findings in the present analysis, with the
difference in grant rates between examiners starting in the restrictive era versus the permissive era
being as large as the impact of a one-standard-deviation increase in the inherent grant rate of the
peers that surround new hires at the Patent Office. This suggests that peer effects may be as
influential in shaping examinersâ€™ granting practices as large high-level fluctuations in the stated
missions of Agency heads.
To further put the magnitude of our findings into perspective, we also compare our findings
to those set forth in Frakes and Wassermanâ€™s (2017) analysis of examiner time allocations, another
key determinant of patent examiner behavior identified in the literature to date. Conceptually, time
allocations are of critical import to observed granting practices given that examiners are legally
expected to allow applications if they are not able to find and articulate a basis of rejection in the
allotted time. Frakes and Wasserman (2017) find that as examiners ascend from GS-7 to GS-14â€”
a path that essentially cuts in half the amount of time examiners are given to review applicationsâ€”
they experience a roughly 10-19 percentage-point rise in their grant rates. As such, the effect of a
1-2 standard deviation fluctuation in the peer grant rate facing an examiner at the beginning of her
career is nearly as influential in shaping her granting practices as is a roughly 100% change in the
amount of time given to examiners to review applications.
IV.B. Supervisory Effects
Placing the magnitude of the above findings into even further context, we also estimate
similar specifications exploring the relationship between examiner grant rates and the inherent
26

grant rates of the GS-14 â€œprimaryâ€ examiners practicing in the affected examinerâ€™s Art Unit, a
particular group of peer examiners that also serve a quasi-supervisory role in helping to sign off
on the reviews of assistant examiners. As demonstrated by Column 3 and 4 of Table 2 (focusing
on balanced and unbalanced samples, respectively), we estimate a similar dynamic pattern in the
case of this peer/supervisor group as we do in the case of the pure peer group consisting of peer
assistant examinersâ€”that is, a strong relationship between an assistant examinerâ€™s grant rate and
the inherent grant rates of the group of primary examiners in her Art Unit at the time, though one
that is strongest when that assistant examiner is new to the Patent Office. The magnitude of this
relationship is roughly equal to the pure peer effects documented in Columns 1 and 2 of Table 2,
capturing how assistant examiners respond to their peer assistant examiners.
We extend this supervisory analysis to the consideration of SPE effects in Column 5 and 6
of Table 2. We continue to document an influence that dissipates with examiner experience. That
is, we do find that new examinersâ€™ granting practices may be shaped by the inherent grant rates of
the SPEs overseeing their Art Units (as captured by that SPEs granting history before they were
SPEs), and we find that changes in SPE compositions within Art Units later in an examinerâ€™s career
are associated with a weaker and weaker influence on an examinerâ€™s grant rates at those later
moments. In comparing the magnitude of these SPE effects with those of the assistant examiner
peer effects or the primary examiner peer effects, it is important to note that this SPE analysis is
performed on a subset of Art-Unit-by-year groups for which we have data on previous grant rates
of the relevant SPEs. To best form the comparison group for these SPE effects, in Column 6 of
Table 3, we replicate the pure peer effects analysis on this subset of Art-Unit-by-year cells. Doing
so, we find that the magnitude of the pure peer effects is nearly three times as large as the
magnitude of these supervisory effects.

27

All told, the evidence suggests that the composition and the granting backgrounds of an
examinerâ€™s peers appear to be just as or more influential on an examinerâ€™s early-career granting
decisions than the granting background of an examinerâ€™s supervisors.
IV.C. Other Specification Checks
We next consider several falsification exercises, beginning with the estimation of a 2-year
lead coefficient of the peer grant score in Columns 1-3 and 7 of Table 4. If changes in peer
composition would cause changes in assistant examiner grant rates, one would not expect to
observe this assistant examiner response prior to the point in time in which the peer composition
changed. 17 The results confirm that there are indeed no observed lead effects of concern.
We next consider a falsification exercise based on an evaluation of peer influences on the
use of lack-of-novelty rejections versus obviousness rejections. Both of these standards are similar
in ensuring that patents not be granted to inventions that are effectively already present in society.
However, obviousness determinations are commonly perceived as being more indeterminate and
subjective in nature than lack-of-novelty rejections. With this greater scope for discretion, one
would arguably expect to observe more markers of learning and peer influence in the case of
obviousness rejections. We test this in Columns 1 and 2 of Table 5, estimating specifications
similar to that estimated in Column 1 of Table 2 but where the dependent variable equals the
incidence of any obviousness (or lack of novelty) rejection during the course of the examination
process (even if the application is ultimately allowed in later stages of review) and where the peer
score represents the inherent obviousness rate (or inherent lack of novelty rate) of the peer

17
Again, we elect not to take too fine-grained of a temporal approach here and choose to track behavior over a two-year period considering that
the duration of examination reviews often span a period of time in excess of a year. Moreover, considering that peer grant scores are calculated
based on the time of disposition of applications and that applications indeed take some time to process, it may be possible to observe some amount
of anticipation effects (e.g., new examiners in an Art Unit exerting some influence on current examiners before those new examiners begin
completing their first reviews). However, one might not expect any such anticipation effects to be substantial and, in fact, we do not observe strong
anticipation effects anyway.

28

examiners. In the case of obviousness rejections, we find a pattern of early-career peer effects that
diminish with examiner experience, very similar to the grant-rate results. In the case of lack-ofnovelty rejections, we find little evidence of peer effects at any level of experience.
As an additional specification check, we further break down the pure peer scoreâ€”the mean
inherent grant rate of the peer assistant examinersâ€”into more specific peer scores based on the
experience of those peers. If the above findings are reflective of knowledge spillovers and
learning, one might predict that the channel of influence would be weaker in the case of new peer
examiners and stronger in the case of seasoned peer examiners. We explore these predictions in
Columns 3 and 4 of Table 5, estimating separate specifications where we calculate a peer score
based on peer assistant examiners who are in their first and second years at the Patent Office
(Column 3) and who are in their third year and beyond at the Patent Office (Column 4).

As

predicted, we estimate a weak relationship between a new examinerâ€™s grant rate and the inherent
granting practices of her similarly situated junior peers, with a point estimate of the coefficient of
this junior peer score being one-fourth of the size of the new hire peer-effect documented in Table
2 and one-fourth of the size of the senior peer effect estimated in Column 4 of Table 5.
Next, we consider another separation of the assistant examiner peer group based on the
peer examinersâ€™ participation in the Patent Officeâ€™s telecommuting program, whereby eligible
examiners may work from home for all but 1 or 2 days during a bi-week period. Naturally, one
may expect that the group of telecommuting examiners would have a weaker peer influence on
new examiners (who are themselves not eligible to work from home) relative to the group of nontelecommuting examiners. Non-telecommuting peers are actually in the office day-to-day with
new examiners and thus in a position to exert social influence in the first place. Knowledge
spillovers, after all, have been argued to be more likely to occur through high-frequency repeated

29

social contact (Von Hipple 1994). Of course, telecommuting examiners may still have some
influence, even if weaker, considering that they will typically spend some time in the Patent Office
over a bi-week period and considering that these examiners are among the most senior in the Art
Unit (i.e., a fact which bias against finding a differential).
We present the results of this final exercise in Columns 5 and 6 of Table 5. In the case of
the non-telecommuting peers, we estimate a strong peer effect on new hires that, as above,
diminishes with examiner experience. In the case of telecommuting peers, the point estimate for
the coefficient of the peer scoreâ€”capturing the effect of the telecommuting peers on new examiner
grant ratesâ€”is around Â½ of the magnitude of the corresponding effect for the non-telecommuting
examiners. These results lend further support to an interpretation of the above results as indeed
arising from social interactions with peers.
Finally, we reiterate that the above approach has characterized peer granting tendencies by
the mean inherent grant rate of surrounding peers. It is possible, however, that individuals may be
influenced by different aspects of the distribution of inherent grant rates across peersâ€”e.g., they
may be especially influenced by the highest grant-rate examiners around them. We consider
distributional effects of this nature in the Online Appendix, separately constructing peer scores
based on the examiners at the different percentiles of the peer grant-rate distribution within the
Art-Unit-by-year cell. Our results suggest that movements in peer composition at both the top and
bottom of the distribution of peer granting tendencies are associated with peer effects on individual
examiner behavior that are similar in magnitude and pattern to the mean effects estimated above.
That is, for instance, an increase in the peer grant rate at the 25th percentile of the within-Art-Unit
peer granting distribution is associated with a large (mean) increase in the grant rate of the affected
examiner during the first two years of her career, followed by a weakening of this peer influence

30

as her career proceeds. As such, the peer influences we document do not simply arise from the
highest grant-rate peers. However, we do find that the effect of changes in peer composition at
the higher percentiles are associated with larger effects on individual examiners relative to
corresponding changes in peer composition at the bottom of this distribution. For instance, we
find that the point estimate of the effect on new examinersâ€™ grant rates of an increase in the peer
score is 0.13 percentage-pointsâ€”or roughly 37%â€”larger in absolute terms in the case of
specifications that base peer scores on the 75th percentile of inherent peer grant rates relative to
those that base peer scores on the 25th percentile. In other words, examiners may indeed be less
influenced by the granting tendencies of their lower grant-rate peers.
Aside from these distributional considerations regarding which peers constitute the peer
score, the primary specification estimated above is also arguably limited in its parametric and
linear treatment of the peer grant score variable in estimating its influence on individual grant rates.
Accordingly, in the Online Appendix, we also take a more non-parametric approach, whereby,
instead of using the value of the inherent peer grant score as the key regressor of interest, we
include a series of dummy variables capturing the incidence of that peer score falling into the
various quartiles of the distribution of peer grant scores across Art Units. 18 To simplify this
exercise, we do not interact each of these dummies with the series of experience bins and instead
estimate an experience-invariant specification. Our results demonstrate the robustness of our
findings to this non-parametric alternative, with examiner grant rates rising monotonically across
each of the peer grant score quartiles. In particular, we find that grant rates rise by 2.3, 7.7 and 9.6
percentage points as we ascend into the second, third, and fourth quartiles of the distribution of
mean peer grant rates across the full sample. With a two-quartile jump being roughly on par with

18

For these purposes, we are still looking at the average peer to construct the peer score. But, we are then looking at the distribution of average
peer scores across the different Art Units.

31

a one-standard deviation change in the peer grant rate, and in light of the standard-deviation
interpretation of the primary results discussed above, the magnitude of these findings is consistent
with the more parametric approach taken in the baseline specifications.
IV.D. General versus Specific Knowledge Flows
To the extent the above findings reflect some degree of knowledge flow among examiners,
one might wonder the nature of such flows. Are examiners learning from other examiners general
styles and strategies towards examinationâ€”e.g., general search strategies or general views towards
the technological advancements necessary to surpass novelty and nonobviousness requirements?
Or, are examiners imparting more specific information to each other that be driving some part of
the above findings? For instance, are examiners learning about specific pieces of prior art from
their peers? To shed some light on these questionsâ€”in particular, to test for the presence of this
latter more specific channelâ€”we collect data from 2000-2010 on the patents that are cited by each
patent issued over that period, a dataset that allows us to explore citation patterns by a given patent
and citations patterns to a given patent, subject to the limitations of the given time period. 19
To explore whether examiners appear to be learning about specific patents from their peers,
we conduct a simple exercise. First, for each patent issued at time t, we determine whether the
examiner reviewing said application cited a patent among the set of â€œpetâ€ patents most frequently
cited throughout their careers by the other examiners also in the same Art Unit at time t, where we
define an examinerâ€™s set of â€œpetâ€ prior art by the 10 patents that they most frequently cite
throughout their career. 20 Motivating this approach is the observation by others in the literature
that examiners frequently turn to the same set of patents (Abrams and Sampat 2017) as pieces of

19
Given this construction, naturally, the pool of patents that are targets of citations span a longer period of time considering that patents issued
beyond 2000 will nonetheless cite older patents. We are grateful to Bhaven Sampat for providing us with these citation data.
20
The findings documented below are not sensitive to this precise cut-off.

32

prior art when conducting their reviews, a set of personalized information and preferences that
examiners may impart to their peers.
Of course, just observing that examiners cite, with some probability, patents that are among
the favorite pieces of prior art of those peers is not, in and of itself, telling regarding the
transmission of knowledge regarding the existence of those pieces of prior art. After all, peers
work within the same area of technology and thus there is likely to be some degree of correlation
in the set of patents that examiners within an Art Unit cite. Nonetheless, if examiners were indeed
learning about specific pieces of prior art from their peers, we might predict that they would be
more likely to learn from those peers around them regularly. That is, we might predict that the
above citation likelihood would be stronger when confining the relevant peer group to those
examiners in the same Art Unit at time t that are not telecommuting at such time relative to a
situation when we confine the peer group to those telecommuting at time t.
Telecommuting examiners tend to be more experienced and of higher GS levels than nontelecommuting examiners, creating a concern that examiners may differentially turn to pet patents
of their senior peers for reasons beyond just accessibility to those peers. Of course, this concern
would tend to bias against finding an accessibility effect. Nonetheless, to appease this concern,
we perform this comparison between the likelihood of citing to pet patents of oneâ€™s telecommuting
peers versus non-telecommuting peers while only looking at peer assistant examiners at either GSlevel 12 or 13. We also confine this comparison to only those Art Units and years where there are
at least one telecommuting examiner in the Art Unit-by-year cell.
With these restrictions, we find that examiners cite to the pet patents of their current nontelecommuting peers roughly 2.1 percent of the time, while only citing to the pet patents of their
telecommuting peers roughly 0.25 percent of the time. That is, examiners are roughly 8.2 times

33

more likely to cite to the favorite patents of their local, accessible peers than those peers working
from home. Of course, some difference here is to be expected given that at any point in time an
examiner may be surrounded by more non-telecommuting peers than telecommuting peers. In
fact, again when confining ourselves to Art-Unit-by-year cells in which there are at least one nontelecommuting examiner, there are nearly 6 time more non-telecommuting examiners than
telecommuting examiners. Nonetheless, the differential in citation likelihoods exceeds this
differential in peer examiner counts, suggesting that accessibility to peers may indeed impact the
likelihood that an examiner may cite to the favorite patents of those peers, which in turn may
suggest that peers do impart some degree of specific information to each other regarding pieces of
prior art that may be relevant to each otherâ€™s current applications.
One concern with this simple comparison of means of course is that Art Units may vary in
the degree to which their examiners telecommute and the degree to which they cite from their
peersâ€™ favorite patentsâ€”e.g., the above differential could just be a reflection of a situation in which
a certain Art Unit happens to have a low propensity of telecommuting examiners but a generally
high degree of citing to peersâ€™ favorite patents, though to the same degree across telecommuting
and non-telecommuting peers within that Art Unit. As such, in Table 6, we formalize this
comparison so as to better isolate the difference in citation likelihoods based on accessibility of
peers. For these purposes, we stack two separate samples of individual patents issued by assistant
examiners. The dependent variable across both such sub-samples indicates the incidence of the
examiner associated with the issued patent citing a patent that is among the set of pet patents for
the peer group at the relevant time. For the first sub-sample, this measure focuses on the incidence
of citing a pet patent of their telecommuting peers. For the second sub-sample (stacked on top of
the first), that dependent variable captures the likelihood of citing a pet patent of the non-

34

telecommuting peers. We also include a measure of the number of examiners associated with the
relevant Art Unit-by-year cell.

This measure for the first sub-sample reflects the number

telecommuting examiners in the Art-Unit-by-year cell; for the second sub-sample, it reflects the
number of non-telecommuting examiners. We take two approaches to parameterizing these
examiners counts: first, a semi-parametric approach in which we include the examiner count and
its square and, second, a more non-parametric approach in which we include a series of dummy
variables indicating the various quartiles of the examiner count distribution.
With this structure, we then regress the likelihood that the examiner cites one of her peersâ€™
favorite patents on an indicator variable for the non-telecommuting status of that peer group, while
including a control for the associated number of examiners (either telecommuting or nontelecommuting depending on the relevant sub-sample) and while including issued patent fixed
effects. This effectively allows us to compareâ€”within a given issued patentâ€”the likelihood that
that the associated examiner cited to one of her non-telecommuting peers relative to one of her
telecommuting peers while accounting for the stronger likelihood to do so based on the mix of
non-telecommuting and telecommuting peers in the Art Unit at the time of issuance. With these
layers of control, we find that examiners are roughly 0.3 to 0.4 percentage pointsâ€”or roughly 19
to 25%â€”more likely to cite to their non-telecommuting peersâ€™ favorite patents. 21
On a final note, we do not find a strong experience gradient in the degree to which
examiners cite their peersâ€™ pet prior art. This may reinforce the point addressed above that
examiners may engage in some degree of ongoing learning throughout their careers. This
continued learning is perhaps more likely to consist of specific, technical information of the sort

21
These findings are robust to alternative approaches that control instead for Art Unit and year fixed effects or Art-Unit-by-year fixed effects (in
lieu of patent-specific fixed effects).

35

explored in this sub-section, at least relative to the early career learning which may also involve a
greater degree of learning over general practice styles.
IV.E. Peer Effects in Claim Narrowing
Our analysis thus far has primarily viewed the job of patent examiners as either allowing
or rejecting patent claims. However, the iterative nature of the patent examination processâ€”
involving a back and forth between patent examiners and applicants over multiple rounds of
reviewâ€”creates the opportunity for a more nuanced dimension to the job of patent examiners:
claim narrowing. The exclusionary power of a patent depends not just on the presence of that
patent in the first place but also on the breadth of the claims underlying that patent. For instance,
a patent on â€œskisâ€ would tend to exclude a broader range of competition than a patent on
â€œcomposite downhill skis.â€ As such, not only may examiners develop a practice style regarding
their proclivities to allow or reject patent claims, but they may also develop a practice style
regarding how they work with applicants to narrow their claims to the point that they comply with
the legal patentability requirements (Kuhn and Thompson 2017).
Accordingly, in a final empirical exercise, we extend the above empirical framework to
explore the relationship between the degree to which a given patent was narrowed throughout the
examination process and the inherent narrowing proclivities of the associated peer group at the
relevant time and in the relevant Art Unit. For these purposes, we collected data from Jeffrey
Kuhn and Neil Thompson on the number of words added throughout the examination process to
the first claims in the patents issued during our sample. 22 Following, Kuhn and Thompson (2017),

22

The data received from Kuhn and Thompson, however, is subject to certain exclusions in that that they focused on patents issued subsequent to
January 1, 2005, while also excluding continuation applications and applications in the biotechnology area. Given the resulting implications for
our sample size, we elect with this exercise to estimate experience-interaction specifications that do not impose balance restrictionsâ€”that is, we
focus on examiners over the first six years of their careers without imposing requirements to follow each include examiner throughout the full
extent of those 6 years.

36

we use this word-added measure as a reflection of the degree of claim narrowing, considering that
longer claims generally impose a greater number of conditions that must be met before patent
infringement is found. In Panel A of Table 7, we present the results from this approach, whereas
in Panel B, we present results from specifications that form the claim-narrowing variable in
percentage termsâ€”i.e., normalizing words added by the number of words in the first claim of
issued patents. We also show results with and without the inclusion of SPE fixed effects.
Consistently across these specifications, we find little association between the degree of
claim narrowing for a given patent and the inherent claim narrowing tendencies of the relevant
peer examiners during the first 2 years of the affected examinerâ€™s career. However, as examiners
move into the later experience binsâ€”in their third year and beyondâ€”the degree to which they add
words to claims begins to be more strongly associated with the claim narrowing tendencies of their
peers. For instance, from Panel B, during the third and fourth years of an examinerâ€™s career, we
find an increase of roughly 0.15-0.17 in the number of words that an examiner adds to the first
claim of an issued patent as that examiner experiences a change in the composition of her peer
group that represents an increase of 1 word in the average inherent words-added of that peer group.
The magnitude of that peer effect does not appear to increase further as the examiner moves into
her fifth and sixth year at the Patent Office.
To summarize, we likewise find strong peer effects in claim narrowing practices of
examiners; however, these peer influences do not appear to emerge until an examiner has garnered
some degree of experience at the Patent Office. This delayed influence is not necessarily
inconsistent with the granting-focused learning story set forth above, where peer influences were
strongest early on in an examinerâ€™s career. Deciding to allow or reject patents is something that
examiners are necessarily asked to do from the very beginning of their careers at the Patent Office.

37

Accordingly, the learning process over granting stylesâ€”and the potential scope for peers to help
shape that learningâ€”is something that will naturally commence immediately upon the onset of an
examinerâ€™s career. The task of affirmatively working with applicants to narrow their claims before
allowing them is not necessarily a task that examiners must perform and thus is not a skill that they
will necessarily begin to develop from day one at the Patent Office. It may take examiners some
time to gather enough experience with reviewing applications and evaluating claims in any sense
before they are even in a position to start developing a deliberate claim-narrowing practice style
of this nature.
Consider the well-known idiomâ€”one must learn to walk before they can run. 23 The same
may simply be true for the sequence of learning facing patent examinersâ€”that is, an examiner
must learn to reject claims generally before learning to work with applicants to narrow claims to
the point of legal permissibility. For this reason, it may not be unreasonable to think that there
will be a delay in the onset of peer influences over claim-narrowing practices. If anything, in light
of this theorized sequencing of learning behavior, any such observed delay in peer influences in
the case of claim narrowing behavior may only reinforce an interpretation of the above documented
peer effects on grant rates as arising from a learning / knowledge spillover mechanism.
To support this interpretation of a delayed peer effect as arising from a delay in developing
this claim narrowing skill in the first place, we also estimate a simple regression of the number of
words added to an issued patent on a series of examiner experience bins in addition to various
controls, including examiner fixed effects, year fixed effects, Art Unit fixed effects, examiner GSlevel fixed effects, applicant entity size and application foreign priority status. In Figure A2 of the

23
That is, someone learning to walk may be influenced by the walking styles of those around them during those critical moments, but they may be
less influenced by the running styles of those around when they are simply learning to walk. At some point though, they reach a level of comfort
with walking that they can begin to start working on the more nuanced challenge of running, and perhaps it is at this point that they may begin to
be influenced by the running styles of their peers at those times.

38

Online Appendix, we plot the estimated coefficients of the experience group dummies. We find
that as examiners ascend from the first experience group (0-2 years) to the second experience
group, there is an increase of roughly 9 in the average number of words that are added throughout
the prosecution process of the patents they issue, representing a roughly 18% increase over the
mean. As such, consistent with the notion that examiners may delay in looking to their peers for
guidance on claim narrowing strategies because they may be holding off developing such skills in
the first place, we find that examiners indeed narrow claims to a much smaller degree at the
beginning of their career.
V.

Conclusion
Knowledge spillovers have been central to many models of economic growth and

technological change (Krugman 1991, Romer 1986, Lucas 1988). While much of the theoretical
and empirical discussions surrounding knowledge spillovers have focused on knowledge
transmission across firms or across geographical units (Audretsch and Feldman 2002), knowledge
transmissions within firms may also contribute significantly to these same macroeconomic
outcomes, in addition to the productivity outcomes of individual firms (Jackson and Bruegmann
2009). Our analysis has attempted to overcome some of the key empirical challenges involved
with testing for the presence and degree of spillovers within firms. In the process, we have found
strong evidence that a workerâ€™s practice style may be shaped early in her career and that one of the
key factors shaping her behavior is the corresponding practice styles of her peers during those
critical early moments of impressionability. Though our analysis focuses on just one employment
settingâ€”the U.S. Patent Officeâ€”its analysis demonstrates just how strong of a role that peers can
play in high skilled work settings, even when focusing on work tasks that are somewhat isolated
and non-team-based in nature.

39

Regardless of the generalizability of these findings beyond patent examiners, the findings
hold various implications for U.S. patent policy. Much attention has been paid to the levels and
variability of grant rates produced by examiners. Policies designed to remedy any harms resulting
from these patterns of behavior must start with an understanding of the sources of such behaviors.
The fact that examiners may learn so substantially from their peersâ€”perhaps more so than from
their supervisorsâ€”may be important for such purposes. Among other things, that knowledge may
help the Patent Office in how it allocates examiners to Art Unitsâ€”for example, the mix of junior
and senior examiners it wants to maintain within Art Units, or the placement of particularly
generous or harsh examiners. It may also bear on how the Agency wishes to structure and allocate
training efforts among the different classes of examiners within the Agency.
Our findings also hold implications for a particular personnel policy within the Patent
Officeâ€”i.e., its telecommuting program. To understand this connection, first consider one of the
key parallels between our analysis of within-firm knowledge spillovers and the literature on
spillovers across geographical units: the concept of proximity. A number of studies (for instance,
Jaffe, Trajtenberg and Henderson 1993, Audretsch and Feldman 1996) have demonstrated the
critical importance of geographical closeness in the transmission of knowledge and have generally
demonstrated the degree of regional clustering and concentration in innovative activity. The
findings from these geography-focused studies are arguably consistent with our findings of
stronger peer effects in the case of peers that do not telecommute and that are present day-to-day
in the Patent Officeâ€”i.e., more proximate peers. The significant effects from proximate workers
within firms may signal a strong role for peers to play in overall workplace efficiency. If peer
effects are properly overseen and directed (so as to produce positive and not negative spillovers),
the ability of new workers to learn from their peers can lead to potentially substantial productivity

40

gains. Such gains may be dampened to the extent that workers no longer interact in person. As
such, our analysis sheds light on some of the consequences that may befall the general movement
we have observed across a number of economic sectors to allow employees to work from home.
While telecommuting may reduce a number of transaction costs for firms and for employees, it
may impose transaction costs in the transmission of tacit knowledge (Von Hipple 1994). Whether
the former gains outweigh the latter losses is a subject for the future and ongoing research of the
consequences of telecommuting (Bloom et al., 2015, Frakes and Wasserman 2016, Mas and Pallais
2016).

REFERENCES
Allen, Natalie J., and John P. Meyer. 1990. â€œOrganizational Socialization Tactics: A Longitudinal
Analysis of Links to Newcomersâ€™ Commitment and Role Orientation,â€ Academy of
Management Journal 33: 847-858.
Ashforth, Blake K., and Alan M. Saks. 1996. â€œSocialization Tactics: Longitudinal Effects on
Newcomer Adjustment,â€ Academy of Management Journal 39(1): 149-178.
Audretsch, D. B. and M. P. Feldman. 1996. â€œR&D spillovers and the geography of innovation and
production,â€ American Economic Review 86(4): 253-273.
Audretsch, D.B. and M.P. Feldman. 2004.

â€œKnowledge spillovers and the geography of

innovation,â€ Chapter 61 in Handbook of Regional and Urban Economics: 2713-2739
Azoulay, Pierre, Joshua S. Graff Zivin, Jialan Wang. 2010. â€œSuperstar Extension,â€ Quarterly
Journal of Economics 125 (2): 549-589.
Baron, J. N., Burton, M. D., & Hannan, M. T. 1999. â€œEngineering bureaucracy: the genesis of
formal policies, positions, and structures in high-technology firms.â€ Journal of Law,
Economics, and Organization: 15(1): 1-41.
41

Bloom, Nicholas, James Liang, John Roberts, and Zhichun Jenny Ying. 2015. â€œDoes Working
from Home Work? Evidence from a Chinese Experiment,â€ Quarterly Journal of
Economics 130(1): 165-218.
Chetty, Raj, John N. Friedman, and Jonah R. Rockoff. 2014. â€œMeasuring the Impacts of Teachers
I: Evaluating Bias in Teacher Value-Added Estimates,â€ American Economic Review
104(5): 406-11.
Cockburn, I., S. Kortum, and S. Stern. 2003. â€œAre All Patent Examiners Equal? Examiners, Patent
Characteristics, and Litigation Outcomes,â€ in W. M. Cohen and S.A. Merril (Eds.), Patents
in Knowledge-Based Economy (Washington, DC: National Academies Press, 2003).
Cornelissen, Thomas, Christian Dustmann, and Uta SchÃ¶nberg. 2017. â€œPeer Effects in the
Workplace,â€ American Economic Review 107(2): 425-56.
David, Paul. A. 1985. "Clio and the Economics of QWERTY", American Economic Review 72:
332-7.
Dokko, Gina, Steffanie L. Wilk, and Nancy P. Rothbard. 2009. â€œUnpacking Prior Experience:
How Career History Affects Job Performance,â€ Organization Science 20: 51-68.
Frakes, Michael D. and Melissa F. Wasserman. 2016. â€œPatent Office Cohorts,â€ Duke Law Journal
65: 1601-1655.
Frakes, Michael, and Melissa Wasserman. 2016. â€œProcrastination in the Work Place: Evidence
from the U.S. Patent Office,â€ NBER Working Paper 22987.
Frakes, Michael, and Melissa Wasserman. 2017. â€œIs the Time Allocated to Review Patent
Applications Inducing Examiners to Grant Invalid Patents? Evidence from Microlevel
Application Data,â€ The Review of Economics and Statistics 99(3): 550-63.

42

Galasso, Alberto and Mark Schankerman. 2015. â€œPatents and Cumulative Innovation: Causal
Evidence from the Courts,â€ Quarterly Journal of Economics 130 (1): 317-369.
Gordon J. DiRenzo, 1977. â€œSocialization, Personality, and Social Systems,â€ Annual Review of
Sociology 3: 261-295.
Gould, Eric, and Eyal Winter. 2009. â€œInteractions between Workers and the Technology of
Production: Evidence from Professional Baseball,â€ Review of Economics and Statistics
91(1): 88-100.
Guryan, Jonathan, Kory Kroft, and Matthew J. Notowidigdo.

2009.

â€œPeer effects in the

workplace: evidence from random groupings in professional golf tournaments,â€ American
Economic Journal: Applied Economics 1 (4), 34â€“68.
Ho, Daniel. 2017. â€œDoes Peer Review Work? An Experiment of Experimentalism,â€ Stanford
Law Review 69(1): 1-119.
Jackson, C. Kirabo, and Elias Bruegmann. . 2009. â€œTeaching Students and Teaching Each Other:
The Importance of Peer Learning for Teachers,â€ American Economic Journal: Applied
Economics 1(4): 85-108.
Kane, Thomas J., and Douglas O. Staiger. 2008. â€œEstimating Teacher Impacts on Student
Achievement: An Experimental Evaluation,â€ NBER Working Paper No. 14607.
Krugman, Paul. 1991. Geography and Trade (MIT Press: Cambridge, MA).
Kuhn, Jeffrey, and Neil Thompson. 2017. â€œHow to Measure and Draw Causal Inferences with
Patent Scope,â€ International Journal of the Economics of Business, forthcoming.
Lemley, Mark A. and Bhaven Sampat. 2012. â€œExaminer Characteristics and Patent Office
Outcomes,â€ The Review of Economics and Statistics 94(3): 817â€“827.

43

Lichtman, Douglas. 2004. â€œRethinking Prosecution History Estoppel,â€ University of Chicago
Law Review: 151â€“82.
Lucas, Robert. 1988. â€œOn the mechanics of economic development,â€ Journal of Monetary
Economics 22: 3-39.
Malmendier, Ulrike, and Stefan Nagel, 2011. "Depression Babies: Do Macroeconomic
Experiences Affect Risk Taking?," The Quarterly Journal of Economics 126(1): 373-416
Mann, Ronald. 2014. â€œThe Idiosyncrasy of Patent Examiners: Effects of Experience and
Attrition,â€ Texas Law Review: 2149â€“76.
Manski, Charles F. 1993. â€œIdentification of Endogenous Social Effects: The Reflection Problem,â€
The Review of Economic Studies 60(3): 531-542.
Marquis, Christopher, and AndrÃ¡s Tilcsik. 2013. â€œImprinting: Toward A Multilevel Theory,â€
Working

Paper,

available

at

https://papers.ssrn.com/sol3/papers.cfm?abstract_id=

2198954.
Mas, Alexandre, and Enrico Moretti. 2009. â€œPeers at Work,â€ American Economic Review 99(1):
112-45.
Nordhaus, William, Invention, Growth, and Welfare (Cambridge, MA: MIT Press, 1969).
Righi, Cesare, and Timothy Simcoe, â€œPatent Examiner Specialization,â€ mimeo (2017).
Romer, Paul. 1986. â€œIncreasing returns and long-run growth,â€ Journal of Political Economy
94(5): 1002-37.
Sampat, Bhaven and Heidi L. Williams. 2014. .â€œHow do Patents Affect Follow-on Innovation?
Evidence from the Human Genome,â€ available athttp://economics.mit.edu/files/9778.
Scotchmer, Suzanne. 1991. â€œStanding on the Shoulder of Giants: Cumulative Research and the
Patent Law,â€ Journal of Economic Perspectives 5: 29â€“41.

44

Von Hipple, Eric. 1994. Sticky information and the locus of problem solving: implications for
innovation, Management Science 40: 429-439.
Waldinger, Fabian 2012. â€œPeer Effects in Science: Evidence from the Dismissal of Scientists in
Nazi Germany,â€ Review of Economic Studies 79(2): 838-61.

45

TABLE 1. SUMMARY STATISTICS

Panel A. Grant Rate Sample
Grant
Any Obviousness Rejection
Any Lack-of-Novelty Rejection
Examiner Experience: 1-2 Years
Examiner Experience: 3-4 Years
Examiner Experience: 5-6 Years
Examiner Experience: 6+ Years
Assistant Examiner
Assistant Examiner Peer Score (Grant Rate)
Primary Examiner Peer / Supervisor Score
(Grant Rate)
SPE Score (Grant Rate)

(1)

(2)

Mean

SD

0.695
0.855
0.662
0.102
0.155
0.158
0.585
0.447
0.651

0.461
0.352
0.473
0.302
0.362
0.365
0.493
0.497
0.178

0.772

0.303

0.782

0.192

Panel B. Claim Narrowing Sample
Number of Words Added to First Claim
47.854
62.490
throughout Prosecution of Issued Patents
Assistant Examiner Peer Score (Words
56.366
26.368
Added to First Claim)
Each observation in Panel A is a given application from the PAIR database that
reached a final disposition and that was published in the PAIR records between
March, 2001 and July, 2012. Each observation in Panel B is a given issued
patent from the Kuhn and Thompson (2017) database matched with the PAIR
records from Panel A.

46

TABLE 2. EFFECTS OF PEER AND SUPERVISOR GRANTING TENDENCIES ON ASSISTANT EXAMINER GRANT RATES, BY YEARS OF
ASSISTANT EXAMINER EXPERIENCE
(1)

(2)

(3)

Pure Peer Effects (Assistant
Examiner Effects)
Peer Score

0.426***
(0.075)

(4)

Quasi-Supervisory Effects
(Primary Examiner Effects)

0.401***
(0.057)

0.482***
(0.104)

0.341***
(0.056)

(5)

(6)

Supervisory Effects (SPE
Effects)
0.314***
(0.078)

0.196***
(0.061)

(Omitted: Peer Score X 0-2
Years Experience)
Peer Score X 2-4 Years
-0.173***
-0.161***
-0.219***
-0.210***
-0.135***
-0.088***
Experience
(0.031)
(0.022)
(0.041)
(0.029)
(0.049)
(0.029)
Peer Score X 4-6 Years
-0.182***
-0.191***
-0.298***
-0.312***
-0.190**
-0.169***
Experience
(0.049)
(0.037)
(0.068)
(0.049)
(0.077)
(0.051)
N
153906
415575
153584
413499
68063
183,268
Balanced Sample?
YES
NO
YES
NO
YES
NO
* significant at 10%; ** significant at 5%; *** significant at 1%. Standard errors are reported in parentheses and are clustered to
correct for autocorrelation within given Art Units. Coefficients of the experience group dummies are omitted for purposes of
brevity. Each observation is a given application from the PAIR database that reached a final disposition and that was published in
the PAIR records between March, 2001 and July, 2012. Each specifications tracks the granting decisions of assistant examiners
(GS-level 13 and below) over the first six years of their careers at the Patent Office. Columns 1, 3, and 5 focus on a balanced set
of examiners that we can observe practicing at the Patent Office over the entirety of their first six years at the Patent Office.
Columns 2, 4, and 6 present results from an unbalanced sample that imposes no such restrictions (only that we restrict the sample
to observations within the first six years of experience). All specifications include examiner fixed effects, Art Unit fixed effects,
year fixed effects and controls for various application-level characteristics

47

TABLE 3. EFFECTS OF PEER GRANTING TENDENCIES ON ASSISTANT EXAMINER GRANT RATES: VARIOUS ROBUSTNESS CHECKS
(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

Peer Score

0.334***
(0.088)

0.327***
(0.067)

0.443***
(0.062)

0.329***
(0.048)

0.486***
(0.074)

0.517***
(0.089)

0.906***
(0.213)

0.456***
(0.056)

(Omitted: Peer Score
X 0-2 Years
Experience)
Peer Score X 2-4
Years Experience
Peer Score X 4-6
Years Experience
Peer Score X 7+
Years Experience
N

-0.163***
(0.034)
-0.165***
(0.055)

-0.148***
(0.048)
-0.214***
(0.069)

-0.122***
(0.036)
-0.216***
(0.049)

-0.177***
(0.027)
-0.199***
(0.043)

-0.122***
(0.030)
-0.124***
(0.046)

-0.140***
(0.032)
-0.136***
(0.050)

-0.183***
(0.052)
-0.354***
(0.082)

-

-

-

-

-

-

-

145804

152745

152841

150504

153905

153905

68063

-0.190***
(0.020)
-0.236***
(0.032)
-0.251***
(0.048)
521275

Art Unit
and Year
Effects

Art-Unitby-Year
Fixed
Effects

Art-Unitby-Bi-Year
Fixed
Effects

Art Unit
and Year
Effects

Art Unit
and Year
Effects

Art Unit
and Year
Effects

Art Unit
and Year
Effects

Art Unit
and Year
Effects

YES

NO

NO

NO

NO

NO

NO

NO

Balanced or
Unbalanced?

Balanced

Balanced

Balanced

Balanced

Balanced

Balanced

Balanced

Unbalance
d

Construction of Peer
Grant Score at Year t

Lifetime
Grant
Rates

Lifetime
Grant
Rates

Lifetime
Grant
Rates

Grant Rate
for Years
Prior to t

Estimated
Examiner
Fixed
Effects

Empirical
Bayesian
Estimator

Lifetime
Grant
Rates

Lifetime
Grant
Rates

Limit to Art-UnitYear Cells With Data
on SPE Grant Rate?

NO

NO

NO

NO

NO

NO

YES

NO

Treatment of Art Unit
and Time Effects
SPE Dummies?

* significant at 10%; ** significant at 5%; *** significant at 1%. Standard errors are reported in parentheses and are clustered to correct for
autocorrelation within given Art Units. Coefficients of the experience group dummies are omitted for purposes of brevity. Each observation
is a given application from the PAIR database that reached a final disposition and that was published in the PAIR records between March,
2001 and July, 2012. Each specifications tracks the granting decisions of assistant examiners (GS-level 13 and below) over the first six years
of their careers at the Patent Office (except for Column 7 which tracks them over their whole careers). In addition to the indicated features
of the estimated specifications, all specifications include examiner fixed effects and controls for various application-level characteristics.

48

TABLE 4. DISTRIBUTED LEADS AND LAGS SPECIFICATIONS

2-Year Lead
Score
Contemporaneous
Peer Score
2-year Lagged
Peer Score
N
Balanced Sample
(Over first 6
Years of Career)?

(1)

(2)

(3)

(4)

(5)

(6)

0.057
(0.061)
0.302***
(0.082)

0.056
(0.041)
0.332***
(0.064)

0.009
(0.042)
0.151***
(0.069)

-

-

-

131575

409752

YES

NO

(7)

-

-

-

388813

0.253***
(0.079)
0.118*
(0.060)
116812

0.234***
(0.048)
0.141***
(0.043)
374417

0.112**
(0.052)
0.138***
(0.053)
360708

0.043
(0.044)
0.191***
(0.069)
0.139**
(0.068)
286041

NO

YES

NO

NO

NO

Limit to
Limit to
Limit to
Examiners
Examiners
Examiners
Other
Beyond their Beyond their Beyond their
NO
NO
NO
Restrictions?
Second
Second
Second
Years
Years
Years
SPE Effects?
NO
NO
YES
NO
NO
YES
YES
* significant at 10%; ** significant at 5%; *** significant at 1%. Standard errors are reported in parentheses and are clustered to correct
for autocorrelation within given Art Units. Each observation is a given application from the PAIR database that reached a final
disposition and that was published in the PAIR records between March, 2001 and July, 2012. Each specifications tracks the granting
decisions of assistant examiners (GS-level 13 and below) over the indicated years of their careers at the Patent Office. All specifications
include examiner fixed effects, Art Unit fixed effects, year fixed effects and controls for various application-level characteristics
Limit to
Examiners in
their 3rd-6th
Years

49

TABLE 5. EFFECTS OF PEER GRANTING TENDENCIES ON ASSISTANT EXAMINER GRANT RATES: VARIOUS FALSIFICATION EXERCISES

Peer Score
(Omitted: Peer Score
X 0-2 Years
Experience)
Peer Score X 2-4
Years Experience
Peer Score X 4-6
Years Experience
N

(1)

(2)

(3)

(4)

(5)

Incidence of
Any
Obviousness
Rejection

Incidence of
Any Lack-ofNovelty
Rejection
-0.035
(0.079)

Peer Group:
Assistant
Examiners
With Less
than 2 Years
of Experience
0.098**
(0.047)

Peer Group:
Assistant
Examiners
With 2 or
More Years of
Experience
0.400***
(0.072)

Peer Group:
NonTeleworking
Assistant
Examiners
(2006+)
0.462***
(0.075)

0.192***
(0.073)

-0.119***
(0.035)
-0.133***
(0.059)
136654

0.021
(0.050)
0.032
(0.080)
136701

-0.082***
(0.034)
-0.065*
(0.048)
135314

-0.185***
(0.031)
-0.201***
(0.049)
152659

-0.166***
(0.038)
-0.297***
(0.055)
131629

(6)
Peer Group:
Teleworking
Assistant
Examiners
(2006+)
0.244***
(0.082)

-0.116***
(0.057)
-0.232***
(0.069)
85473

* significant at 10%; ** significant at 5%; *** significant at 1%. Standard errors are reported in parentheses and are clustered to correct
for autocorrelation within given Art Units. Coefficients of the experience group dummies are omitted for purposes of brevity. Each
observation is a given application from the PAIR database that reached a final disposition and that was published in the PAIR records
between March, 2001 and July, 2012. Each specifications tracks the granting decisions of assistant examiners (GS-level 13 and below)
over the first six years of their careers at the Patent Office. Each specification focuses on a balanced set of examiners that we can
observe practicing at the Patent Office over the entirety of their first six years at the Patent Office. All specifications include examiner
fixed effects, Art Unit fixed effects, year fixed effects and controls for various application-level characteristics

50

TABLE 6: RELATIONSHIP BETWEEN LIKELIHOOD THAT ASSISTANT EXAMINER WILL CITE TO SET OF â€œPETâ€ / FAVORITE PATENTS OF
HER PEER GROUP AND AN INDICATOR VARIABLE FOR THE NON-TELECOMMUTING STATUS OF THAT PEER GROUP (RELATIVE TO THE
TELECOMMUTING STATUS OF THAT PEER GROUP)

Non-Tele-commuting Peer Group
N

(1)

(2)

0.003***

0.004***

(0.001)

(0.001)

326460

326460

0.19

0.25

Coefficient of Non-Tele-commuting Peer Group
as a Fraction of Mean of Dependent Variable
Sample of Issued Patents with Information on
Telecommuting Peer Group Stacked on Sample of

Sample

Issued Patents with Information on NonTelecommuting Peer Group
Relevant Examiner

Parameterization of Controls for Count of

Count and its Square

Telecommuting and Non-Telecommuting Examiners

YES

Issued Patent Fixed Effects?

Dummies for Different
Quartiles of Relevant
Examiner Count
YES

* significant at 10%; ** significant at 5%; *** significant at 1%. Standard errors are reported in parentheses and
are clustered to correct for autocorrelation within given Art Units. There are two observations for each issued
patent in our sample (based on applications from the PAIR database that reached a final disposition and that was
published in the PAIR records between March 2001 and July 2012). The dependent variable captures the
likelihood that the examiner associated with the given patent cited to the set of â€œpetâ€ / favorite patents frequently
cited by the peers in the relevant Art Unit-by-year cell, where the relevant peer group is the set of nontelecommuting examiners (at GS level 12 or 13) for the first observation within each issued patent and the set of
telecommuting examiners (at GS-level 12 or 13) for the second observation within each issued patent. We then
regress the likelihood that the examiner cited a â€œpetâ€ patent of the relevant peer group on an indicator for whether
the relevant peer group represents the non-telecommuting peers, along with a set of issued patent fixed effects.
Each regression controls for the number of examiner in the relevant Art Unit-by-year cell, where this measure
reflects the number of non-telecommuting examiners (at GS-level 12 or 13) for the first observation within each
issued patent and the number of telecommuting examiners (at GS_level 12 or 13) for the second observation
within each issued patent. Columns 1 and 2 reflect the indicated treatment of these examiner count controls. The
set of issued patents considered are confined to those issued by assistant examiners.

51

TABLE 7: EFFECT OF CHANGES IN INHERENT PEER NARROWING SCORES ON THE DEGREE OF INDIVIDUAL EXAMINER NARROWING
(1)

(2)

Panel A. Claim Narrowing Measure: Percentage Increase in Number of Words in First Claim throughout
Prosecution of Issued Patents
0.002
-0.188
Peer Score
(0.164)
(0.281)
(Omitted: Peer Score X 0-2 Years Experience)
0.215*
0.375**
Peer Score X 2-4 Years Experience
(0.124)
(0.176)
0.221**
0.422***
Peer Score X 4-6 Years Experience
(0.106)
(0.159)
Panel B. Claim Narrowing Measure: Number of Words Added to First Claim throughout Prosecution of Issued
Patents
0.093
0.001
Peer Score
(0.089)
(0.094)
(Omitted: Peer Score X 0-2 Years Experience)
0.149***
0.163***
Peer Score X 2-4 Years Experience
(0.040)
(0.043)
0.150***
0.173***
Peer Score X 4-6 Years Experience
(0.050)
(0.055)
142912
136916
N
SPE Effects?
NO
YES
* significant at 10%; ** significant at 5%; *** significant at 1%. Standard errors are reported in parentheses and are clustered
to correct for autocorrelation within given Art Units. Each observation is a given issued patent from the Kuhn and Thompson
(2017) dataset. Specifications are limited to applications reviewed by assistant examiners during the first six years of their
career, though, for sample size purpose, we do not impose strong balance conditions that we only track examiners who we can
observe over those full six years. All specifications include examiner fixed effects, Art Unit fixed effects, year fixed effects
and controls for various application-level characteristics.

52

FIGURE 1

0

1

Density

2

3

DISTRIBUTION OF ESTIMATED EXAMINER FIXED EFFECTS

-1

-.5
0
Estimated Examiner Fixed Effects

.5

Note: this figure presents a kernel density plot (Epanechnikov kernel with â€œoptionalâ€ bandwidth) of estimated examiner fixed
effects across all examiners in the sample. Examiner fixed effects are derived from the predicted values from a regression of the
incidence of the application being granted on a series of an examiner fixed effects, along with year effects, examiner GS levels,
examiner experience levels and various application-level characteristics (large entity status of applicant, foreign priority status of
applicant, and duration of examination and its square).

53

FIGURE 2

95% Confidence Interval of Estimated Effect
of 100% Increase in Inherent Peer Grant Score
on Assistant Examiner Grant Rate
0
.1
.2
.3
.4
.5

EFFECT OF INHERENT PEER GRANTING TENDENCIES ON ASSISTANT EXAMINER GRANT RATE, BY YEARS OF EXPERIENCE OF THE
AFFECTED ASSISTANT EXAMINER

<2 Years

5-6 Years
2-4 Years
Experience Group of Affected Assistant Examiner

Notes: this figure presents the results of the coefficients estimated in Column 7 of Table 3.

54

7+ Years

