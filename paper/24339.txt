NBER WORKING PAPER SERIES

CAN INNOVATORS BE CREATED? EXPERIMENTAL EVIDENCE FROM AN
INNOVATION CONTEST
Joshua S. Graff Zivin
Elizabeth Lyons
Working Paper 24339
http://www.nber.org/papers/w24339

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
February 2018

We thank participants at the May, 2016 Innovation Growth Lab Research Meeting and those at
the 5th AIEA-NBER conference. We gratefully acknowledge funding support from the Kauffman
Foundation and the National Science Foundation through its SciSIP Program (Award
SBE-1460344). This study is included in the AEA RCT Registry (AEARCTR-0001857). The
views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Joshua S. Graff Zivin and Elizabeth Lyons. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

Can Innovators be Created? Experimental Evidence from an Innovation Contest
Joshua S. Graff Zivin and Elizabeth Lyons
NBER Working Paper No. 24339
February 2018
JEL No. J24,M54,O32
ABSTRACT
Existing theories and empirical research on how innovation occurs largely assume that
innovativeness is an inherent characteristic of the individual and that people with this innate
ability select into jobs that require it. In this paper, we investigate whether people who do not
self-select into being innovators can be induced to innovate, and whether they innovate
differently than those who do self-select into innovating. To test these questions, we designed and
implemented an innovation contest for engineering and computer science students which allowed
us to differentiate between those who self-select into innovative activities and those who are
willing to undertake them only after receiving an additional incentive for doing so. We also
randomly offer encouragement to subsets of both the induced and self-selected contest
participants in order to examine the importance of confidence-building interventions on each
sample. We find that while induced participants have different observable characteristics than
those that were ‘innately’ drawn to the competition, on average, the success of induced
participants was statistically indistinguishable from their self-selected counterparts and
encouragement does not change this result. Heterogeneity in treatment effects suggests an
important role for the use of targeted interventions.

Joshua S. Graff Zivin
University of California, San Diego
9500 Gilman Drive, MC 0519
La Jolla, CA 92093-0519
and NBER
jgraffzivin@ucsd.edu
Elizabeth Lyons
School of Global Policy and Strategy
University of California, San Diego
9500 Gilman Drive, MC 0519
La Jolla, CA 92093-0519
lizlyons@ucsd.edu

1

Introduction

Innovation has long been viewed as important for productivity and income growth (Grossman and Helpman,
1994; Solow, 1957). Therefore, understanding the conditions under which productivity enhancing innovation
occurs is critical for understanding economic development more generally. Recent research has examined
incentive design for encouraging appropriate levels of experimentation (Azoulay et al., 2011; Ederer and
Manso, 2011; Holmstrom, 1989), how governments may be able to increase innovative activity through trade
and immigration policy (Grossman and Helpman, 1990; Oettl and Agrawal, 2008), and how intellectual
property policy can provide incentives to innovate and learn from others (Scotchmer, 1991). While these
studies provide important evidence on tools to increase innovative output, they all implicitly assume that
the population of innovators is fixed and, thus, that eﬀorts to increase innovation should be directed at these
existing innovators.1
In this paper, we use a randomized control trial (RCT) to explore the validity of this assumption. More
specifically, we examine whether successfully innovating requires an innate predisposition by testing whether
people who do not self-select into being innovators can be induced to innovate, and whether they innovate
diﬀerently than those who do self-select into innovating. In particular, our study allows us to address three
inter-related questions:

1. Is the desire to innovate innate or is it suﬃciently pliable that it can be induced?
2. Are induced innovators less able to innovate than those who naturally gravitate to innovative activities?
3. What is the impact of encouragement on the performance of innovators, and does this diﬀer between
innate and induced innovators?
Understanding whether innovators can be created, and how they fare relative to those who self-select
into innovative activities, has important implications for public and private policy. Should innovation policy
and strategy limit its attention to optimizing conditions for the workforce already engaged in that space or
might they be better served by designing institutions and incentives to lure more individuals into the fray?
If incumbents and induced entrants diﬀer in the quantity and quality of their innovative output, what is the
1 Research on entrepreneurs as innovators has begun to examine key characteristics of entrepreneurs and what leads them
to enter into self-employment. Both pre-founding work experience (e.g. Elfenbein et al., 2010), training (e.g. Lyons and Zhang,
2017), and genetics (Nicolaou et al., 2008) appear to impact the decision to become an entrepreneur. While the latter is
consistent with the notion that innovative ability is innate, the impacts of work experience are potentially consistent with our
contention that innovators can also be created. Given that would-be entrepreneurs chose their early work experience, more
evidence is needed to substantiate this claim. Moreover, entrepreneurs are only a subset of innovators and their characteristics
may not generalize to non-entrepreneur innovators. For example, in addition to innovation, entrepreneurs’ responsibilities
include labor management, securing financing, and marketing. Someone with a preference and the ability to innovate may not
have the desire to take on these additional responsibilities as well as the risks that innovation within an existing organization
does not involve.

2

optimal mix of eﬀorts to expand the knowledge frontier? Moreover, understanding whether innovative talent
is innate provides novel insights about the distribution of rents that arise from new inventions. If innovative
talent is entirely a quiddity, organizations will have to provide large amounts of compensation to attract
scarce innovators to the firm (e.g. Acemoglu, 1998). If, however, innovators can be created, compensation
to innovators will be disciplined by potential new entrants and the cost of creating them (e.g. Acemoglu
and Pischke, 1998). Moreover, if induced innovators are portable, firms may under-invest in creating them
(Becker, 1962).
More generally, examining the potential for growing the pool of innovators has important implications
for our understanding of the innovation process and possible avenues for increasing inventive output. In
particular, our study allows us to determine whether individuals who do not choose to innovate in the
absence of an intervention are being held back by accurate beliefs about their ability to perform, or by
psychological barriers that, if overcome, could meaningfully contribute to the innovation process.2
The RCT we implemented to interrogate these research questions was undertaken within an innovation
contest for undergraduate engineering and computer science students at UC San Diego (UCSD). Our design,
described in detail in Section 3, allows us to compare self-selected innovators to a population of potential
innovators with identical training, and to test whether the non-self-selected individuals can successfully
innovate. Moreover, it allows us to assess the diﬀerential eﬀects of confidence boosting messages across these
populations to determine whether this type of managerial intervention impacts innovative outcomes, and
whether the induced innovators’ performance benefits more from these eﬀorts. In addition, by observing
actual innovative output through the innovation contest, we are able to determine whether innate and
induced innovators have diﬀerent innovative skills.
As expected, those participants that were induced to participate were diﬀerent than those that volunteered based on observable characteristics. By design, the induced sample was more female, but induced
participants were also less likely to be drawn from majors that provide the most relevant skills for the competition and had lower cumulative GPAs. Yet, despite appearing to be less well equipped to compete, the
success of induced participants was statistically indistinguishable from those that were ‘innately’ drawn to
the competition. Thus, at least on average, it looks like innovators can be created.
The impacts of encouragement on competition outcomes were a bit more surprising. Encouragement
2 We

designed our sampling frame to allow us to test whether females are more likely to be impacted by interventions to
encourage entry into innovation. Given that females are under-represented in STEM jobs (Beede et al., 2011), they may be a
particular important target for firm and public policies that are aimed at expanding the pool of innovators. However, we did
not find robust diﬀerential treatment eﬀects for females and males (see Appendix Tables A1 and A2), and, therefore, do not
focus on this dimension of our study in this paper.

3

appears to have no eﬀect on any of our outcomes of interest.3 Moreover, it does not appear to have a
diﬀerential eﬀect for those induced, suggesting that confidence boosting is not essential for the reluctant
participants once they are induced to participate.
While induced participants do as well as those that initially volunteer and neither group appears to
benefit from encouragement on average, as predicted by the framework that motivates our experimental
design (see Section 2), these average eﬀects mask important heterogeneity in the impacts of each treatment
arm. In particular, the impacts of inducement are significantly less promising for lower ability students, as
proxied by cumulative GPA. At the same time, they are helped by encouragement. The impacts on high
ability students are much more surprising. Not only do they not benefit from this encouragement, but they
appear to be harmed by it.
Combined, our results demonstrate that innovators can be created through inducement subsidies, but
that targeting inducement is likely to be more cost eﬀective especially since targeting can be based on
information like GPA that is relatively easy to collect. Moreover, we demonstrate that encouragement may
also need to be targeted to focus on those who benefit from it while avoiding those it may harm.
The paper proceeds as follows; Section 2 motivates our experiment design, Section 3 describes our
research setting and experiment, and Section 4 describes our data and analysis, Section 5 presents our
findings, and Section 6 summarizes and concludes.

2

Motivating Framework

We begin with a simple and stylized framework to motivate our experimental treatment groups and experimental analysis. In particular, the framework allows for diﬀerent preferences and abilities for innovative
activities. The utility function used in the framework is consistent with our setting, but intended to be
general enough to be useful in other settings as well.

2.1

Framework set-up

There are n workers who each have an innovative type α. This α may aﬀect a worker’s cost of innovative activities, their expected likelihood of a successful innovative activity outcome, or both. For simplicity, assume
3 While encouragement does not aﬀect outcomes, survey evidence suggests that it does increase the perception that contestants
do not have enough time to complete their project amongst those that do not ultimately submit a final proposal. Since our
encouragement design included reminders about the competition deadline it may have made time scarcity more salient for those
that were falling behind on their project.

4

there are two possible α’s.4 Workers are presented with an opportunity to spend time on an innovative activity, referred to as an “innovation contest” that will pay them R if they succeed. Each worker succeeds with
some probability p(success|αi ). Each worker i has a cost c(αi ) of spending time on the contest. Therefore,
worker i’s expected utility from participating in the innovation contest is E(Ui |αi ) = p(success|αi )R − c(αi ).
Alternatively, workers can spend time on some outside option O. For simplicity, we assume the value of this
outside option is the same across workers.
Suppose that E(Ui |α1 ) ≥ E(Ui |α2 ) either because p(success|α1 ) ≥ p(success|α2 ), or c(α1 ) ≥ c(α2 ), or
both. In addition, suppose that E(Ui |α1 ) ≥ O ≥ E(Ui |α2 ) so that only workers with α1 participate in the
innovation contest. Going forward, we refer to these workers as “innate innovators”. This is consistent with
the idea that, all else equal, some people are more likely to select into innovative activities than others.

2.2

Subsidy Introduction

Suppose now that those who have not selected into the innovation contest are oﬀered some subsidy S to
participate in it. As a result, their expected utility from participating is now: E(Ui |α2 ) = p(success|α2 )R −
c(α2 )+S. Importantly, S does not aﬀect p(success|αi ). To avoid generating an income eﬀect from the subsidy
in which S is diﬀerentially aﬀecting p(success|α2 ), the subsidy is subsequently oﬀered to α1 type workers
as well, albeit after they have elected to participate in the study to avoid influencing their participation
decision.5 Suppose further than S is high enough that E(Ui |α2 ) ≥ O so that the non-innate workers now
also join the contest. Going forward, we refer to these workers as “induced innovators”.
If E(Ui |α1 ) ≥ E(Ui |α2 ) because p(success|α1 ) ≥ p(success|α2 ), and c(α1 ) is not less than c(α2 ), then
innate innovators are more likely to succeed in the innovation contest than induced innovators are. This
implies that innate innovators select into innovation because they have high innovative abilities.
Alternatively, if E(Ui |α1 ) ≥ E(Ui |α2 ) because c(α2 ) ≥ c(α1 ), and p(success|α1 ) is not greater than
p(success|α2 ), then innate innovators are no more likely to succeed in the innovation contest than induced
innovators are.6 This implies that innate innovators select into innovation because they have lower costs of
doing so, for instance, because they enjoy it more.78
4 In reality, there are a continuum of α types. This framework focuses on those at the margin of selecting into innovation.
Our experiment is not targeted at inducing workers who require a very large subsidy to participate in innovative activities and
we therefore do not consider how our treatments are likely to aﬀect them.
5 Note that if α type workers are better able to use S in their innovative activity because they have better abilities, than S
1
may diﬀerentially aﬀect worker types’ likelihood of success. Given the small size of S in the actual experiment, we do not think
it is likely to have a meaningful aﬀect on success likelihoods.
6 In this case, induced innovators may also have higher costs of innovation.
7 If we let the value of outside options vary across worker types, this result could come up because workers with α have
2
higher value outside options.
8 Although we are only allowing for one possible low α type in our model, in reality, it is possible that there are both low α

5

Therefore,
Proposition 1 If innate and induced innovators diﬀer in their probability of successfully innovating, then,
conditional on the cost of innovating being incurred, induced innovators should perform worse than innate
innovators.
Proposition 2 If innate and induced innovators diﬀer in their cost of innovation, then, conditional on the
cost of innovating being incurred, they should perform no diﬀerently on innovative activities.

2.3

Encouragement Intervention

Suppose now that managers can intervene in workers’ innovative activities in an eﬀort to increase p(success|αi ).
Specifically, they can undertake a confidence boosting intervention where confidence is defined as a worker’s
belief in their likelihood of success in innovation. Imagine this intervention increases p(success|αi ) if a
worker’s i is below some threshold. This may be the case if, for instance, lack of confidence causes poor performance due to anxiety-induced choking (Compte and Postlewaite, 2004) but that the intervention cannot
raise confidence above a certain level due to practical constraints.9 Managers cannot observe ex-ante which
worker’s are under-confident. If what diﬀerentiates α1 and α2 types is how confident in their abilities they
are, then this managerial intervention will raise p(α2 ) by more than p(α1 ). Therefore,
Proposition 3 If high and low type innovators diﬀer in self-confidence, then managerial interventions aimed
at increasing worker confidence in their abilities will increase innovative activity performance among low type
innovators (α2 s) more than it will among high type ones (α1 s).

3
3.1

Experimental Design
Research Setting & Population

To address our research questions, we implemented an RCT within an innovation contest for a subset of
students who are arguably most at risk of entering innovative careers. In particular, we introduced an
innovation contest open to all undergraduate engineering and computer science students at UCSD for which
participants were required to design and/or develop an application that helps people fall asleep faster based
types that have higher costs of innovating but similar abilities to those of innate innovators, and low α types that have lower
likelihoods of success than innate innovators. We test for this possibility empirically in section 5.
9 We do not believe that our confidence-boosting intervention has the potential to lead to over-confidence in workers which
could negatively impact performance (Barber and Odean, 2001). Our intervention will provide encouragement rather than
suggest to workers that they have exception skills.

6

on their personal preferences. This problem was defined through discussions with several executives and
entrepreneurs in technology industries, some of whom served as contest judges. It is both an important
problem that does not yet have an ideal solution, and one that we believed the undergraduate students
could make reasonable progress on within a three month window. Prior to the contest sign-up deadline,
students were told that the innovation contest would require them to submit an application that solves a
specified problem related to personalization, but were not told about the specific problem until after the
sign-up deadline.10
Students were invited to enroll in the contest through a series of newsletters and emails that were
supplemented with two information sessions between December, 2016 and January, 2017. The contest began
on February 8, 2017 and had a deadline of May 27, 2017. Contest winners were announced approximately two
weeks later during an awards ceremony and pitch event. The Engineering Department in which our target
participants are enrolled has been ranked in the top 10 globally (US News & World Report, 2016) and oﬀers
“...a broad and rigorous curriculum designed to provide students with the strong academic education and
technical training necessary for placement in the competitive high-tech job market as well as for advanced
studies in graduate school.” We selected this population because these students will have the technical
capabilities to produce impactful inventions in their lifetime, and because engineers are frequently the targets
of interventions to increase innovative activity (e.g. Bureau of Labor Statistics, 2013). In total, 190 students
signed up for the contest.
Submissions made by the contest deadline were evaluated by five technology industry participants who
helped us identify the contest problem and acted as judges for the contest output. They evaluated each
submission across four categories; functionality, user-friendliness, novelty, and potential commercial value
and provided a score of 1-5 on each category for a total score maximum of 20. The developers of the top
three applications were awarded prize money. First place received $5,000, second place received $2,000, and
third place received $1,000. Participants were instructed to submit any output they had at the time of the
deadline, including written plans, design mock-ups, minimum viable products, and beta apps. To maximize
design flexibility, submissions could be intended for any platform.

3.2

Treatments

In order to diﬀerentiate between innate and induced innovators, a random subset of eligible students who
did not sign up by the contest deadline were oﬀered a monetary incentive to participate in the contest,
10 This was to ensure that students who signed up early would not have a mechanical advantage over those who signed up
later.

7

specifically a $100 visa gift card. Taking up this oﬀer did not require students to do anything more than put
their name on the list of contest participants, and agree to receive emails about the contest. This incentive is
our inducement treatment, which is designed to ‘create’ innovators from a sample that did not self-identify
as such. In order to provide this incentive, the contest sign-up deadline was extended by one week. Students
who had already signed up to participate were informed about the sign-up deadline extension and monetary
incentive being oﬀered to some students to increase the participant pool. Moreover, they were also told they
would receive the same amount of money being oﬀered to the students who had not yet signed up.11 The
emails sent to both the students in our inducement treatment, and to the students who had self-selected into
the contest without inducement are provided in Appendix B. The innovation contest began the day after
the extended contest sign-up deadline, when the contest problem was revealed to students.12
To determine the diﬀerential eﬀect of a managerial intervention aimed at raising confidence on the selfselected and induced populations, a random subset of each group received a schedule of confidence boosting
emails throughout the contest period. In total, four emails were sent every two weeks with the exception
of the first three weeks during which all participants were receiving regular emails about the details of the
contest, and the final two weeks of the contest when all participants received a series of reminder emails.
The text included in the emails diﬀers from one email to the next, but they are all written to provide
versions of messages that have been shown to correlate with employee satisfaction and productivity in
organizational behavior research (e.g. Amabile and Pratt, 2016). For example, the emails sent to participants
in the encouragement treatment were designed to convey to participants that they are making a meaningful
contribution to their future careers and to the development of sleep technologies through their participation.
We also provided them links to resources for students working on their innovative capabilities at UCSD. The
complete texts of each email are included in Appendix B.
With this set up, we have four treatment groups (see Figure I). In total, 103 eligible students signed
up to participate before the initial sign-up deadline13 , and 87 eligible students who received the inducement
treatment signed up before the extended sign-up deadline. This is out of a total of 3,445 Engineering and
Computer Science Department undergraduate students of which 1,000 received the inducement treatment
email.14 Our sample sizes per treatment arm are as follows: 52 participants in the self-selected, no man11 Oﬀering the money to all participants reduces concerns about income eﬀects increasing the ability of participants to
successfully innovate. Those who sign up before the initial deadline were not expecting this payment so it will not bias our
measure of intent.
12 Given our intention to test heterogeneous treatment eﬀects across females and males, we oversampled females in our
inducement treatment email because only 24% of eligible students are female. As a result of this oversampling, 50% of the
students who received the inducement treatment were female.
13 This represents about 2% of the eligible population.
14 A take up of about 9% suggests that students who did sign up after the inducement treatment email did not do so just to

8

agerial intervention group; 51 in the self-selected with managerial intervention group; 44 in the induced, no
managerial intervention group; and 43 in the induced with managerial intervention group.
Figure I: Treatment Groups

4

No Managerial Intervention

Managerial Intervention

Self-Selected Innovators

n=52

n=51

Induced Innovators

n=44

n=43

Data & Analysis

All participants were asked to complete a basic survey when they signed up for the contest. The survey
asked participants for their degree majors, gender, year of study, GPA, and whether they have previously
participated in an innovation contest.
We collected outcome data based on whether or not participants submitted a project for consideration
by the judges, and the judges’ scoring of projects that were submitted. Each project was scored by three
judges. Our preferred measure of the quality of submissions is the average ranking judges gave each project.
Each judge scored 7 projects, so this measure ranges from 1-7 with 7 as the highest and 1 as the lowest.
We prefer this measure for two reasons. First, we are analyzing a competition in which the highest ranked
project wins. Second, our ranking measure captures the idiosyncratic scoring rubric for each judge without
the need for normalizations that can be hard to interpret. Including judge fixed eﬀects in our context is
impractical because projects were judged by three people and no three judges evaluated the same 7 projects
which leaves very few observations within each judge-triad. Our findings are robust to alternative measures,
including normalized average scores, as shown in Appendix Table A3.
We also ran a survey following the conclusion of the contest to ask participants about their experience
in the contest, including whether they spent any time on the contest problem and, if they did not submit
something for consideration, why they chose not to. There were four versions of the survey, one for each
treatment group combination, where each shared a common group of questions as well as some that were
specific to their treatment status. As detailed below, these survey results will be used to probe possible
mechanisms for our findings.
receive the $100 gift card.

9

4.1

Summary Statistics and Measurement

Mean participant characteristics based on pre-contest participant survey responses are provided in Panel A
of Table I. These statistics demonstrate that about one-third of participants are female, the majority are
enrolled in a computer science (CS) or electrical engineering (EE) major, participants are in their third
year of study on average, and a small minority have prior innovation contest experience. In addition, the
average cumulative GPAs of participants are quite high. CGPA is measured using response data from a
survey question in which we asked participants to indicate which category their cumulative GPA falls into
on a scale from 1-6 with 1 being less than 2.0, 2 being 2.0-2.49, 3 being 2.50-2.99, 4 being 3.0-3.49, 5 being
3.50-3.99, and 6 being 4.0. The sample mean suggests an average participant CGPA of about 3.5.
Contest performance summary statistics are presented in Panel B of Table I. About one-tenth of participants submitted a project for consideration by the judges. Conversations with organizations and individuals
who regularly run innovation contests and hackathons provide anecdotal evidence that this is a typical submission rate. In order to treat both the act of submitting and the quality of that submission as an endpoint
of interest, we generate an outcome variable using a combination of whether or not someone submitted, and
the project rank conditional on submitting. In particular, Average Ranking is equal to zero if a participant
did not submit a project and equal to their average ranking if they did. Consistent with the fact that many
participants did not submit a project for consideration by the judges, the mean of our outcome variable is
0.33. We verify that our findings are consistent with alternative measures that account for the large number
of zeros in this measure.15
Panel C of Table I presents summary statistics for three survey-based measures of contest engagement.
The first thing to note is that 78 of the contest participants completed the survey, representing about 41% of
the population of students who signed up to participate in the contest. As we discuss in section 5, those who
filled in the survey appear similar to those who did not on observable characteristics, but, not surprisingly,
were on average more engaged in the contest than those who did not complete the post-contest survey.
Among this selected population, close to 70% did spend some time on the contest problem but only 22%
of these participants ended up submitting a project for consideration by the judges. Among those who did
not spend any time on the contest or spent time but did not submit a project for consideration, about half
indicated that time constraints were their primary reason for not submitting a project, and another 40%
indicated that the diﬃculty associated with the contest problem was their primary reason for not submitting
15 In particular, we use the inverse hyperbolic sine transformation (Ramirez et al., 1994) to generate an alternative outcome
variable of interest. Analyses using this and other alternative outcome measures are presented in Appendix Table A3.

10

a project.16 We use this data to explore possible mechanisms for our main findings in section 5.5.
Table I: Summary Statistics
Mean

Std. Dev.

N

Female
Weighted Female
CS or ElecEng Major
Weighted CS or ElecEng Major
Year of Study
CGPA (1-6)
Prior Contest Experience

0.332
0.261
0.702
0.649
3.005
4.392
0.131

(0.472)
(0.386)
(0.459)
(0.429)
(1.261)
(0.901)
(0.338)

190
190
190
190
183
176
190

Panel B: Outcomes
Average Ranking (0 if not submission)
Submitted Project
Average Ranking Score Conditional on Submitting

0.332
0.090
3.715

(1.164)
(0.285)
(1.630)

190
190
17

Panel C: Survey Responses
Any Eﬀort Invested in Contest
Did not Submit due to Time Constraints
Did not Submit due to Challenge

0.679
0.470
0.409

(0.47)
(0.503)
(0.495)

78
66
66

Panel A: Participant Characteristics

Notes:Female and CS/Elec Eng Major weighted to account for over sampling in induced treatment.

4.2

Treatment Eﬀects Estimation

Since our study provides random assignment of treatments, our analysis will focus both on mean comparisons
across treatment groups and regression analyses. We begin by presenting the eﬀects of the inducement
treatment on selection into the contest, and then turn our attention to performance among those who
participate in the contest. Importantly, because we expect that the primary mechanism through which
inducement will aﬀect outcomes is through selection into participation, our preferred empirical specification
does not include controls for participant characteristics. Nonetheless, we also present results that include
controls for participant characteristic covariates to illustrate the role they are playing in our core findings.
We follow this by separately analyzing the impacts of the encouragement treatment on participant
performance. The encouragement treatment was randomly assigned to participants who had already selected
into the contest, so we do not expect that participant characteristics will vary by encouragement treatment
(comparisons are presented in section 5). As with inducement, we nonetheless run our regression analysis of
16 A small percentage of participants indicated their primary reason for not submitting a project for consideration was because
the contest problem was not suﬃciently interesting for them to spend time on.

11

the eﬀects of encouragement on outcomes with and without controls for these characteristics.
Since encouragement may diﬀerentially influence the induced and innate samples, we also analyze the
following equation:

Yi = α + β1 Inducementi + β2 Encouragementi + β3 (Inducementi ∗ Encouragementi ) + ϵi

(1)

where Yi is a measure of performance, T reatmenti is equal to one if participant i received the inducement
treatment, and Encouragementi is equal to one if participant i received the encouragement treatment.17
As our framework presented in section 2 demonstrates, we expect our treatments will have diﬀerent
impacts depending on student ability. Using cumulative GPA as our most comprehensive measure of ability,
we assess this directly by estimating the following equation:

Yi

=

αi + β1 (T reatmenti ) + β2 (HighCGP Ai ) + β3 (T reatmenti ∗ HighCGP Ai ) + ϵi

(2)

where Yi is a measure of performance or participation, T reatmenti is equal to one if participant i received
one of the two treatments, and HighCGP Ai is equal to one if participant i has above the sample median
cumulative GPA. We estimate these equations separately for the encouragement and inducement treatments.

5

Results

The presentation of our results follow the progression described in the previous section. We begin with
estimates of the overall impacts of the inducement and encouragement treatments as well as the interaction
between the two. This is followed by an analysis of heterogeneity in our treatment eﬀects by ability and an
exploration of the potential mechanisms that might underlie these findings.

5.1
5.1.1

Average Eﬀects of Receiving an Inducement to Innovate
Selection into Participation

Table II presents comparisons of mean participant characteristics by inducement treatment. As expected,
these comparisons demonstrate important diﬀerences between the population of participants who signed
up without receiving a subsidy for participating and those who only did so with a subsidy. By design,
17 We also verify that all of our estimates of treatment eﬀects on whether or not participants submit a project for consideration
are robust to using probit regressions.

12

the induced sample was more female. More importantly, induced participants were also less likely to be
drawn from majors that provide the most relevant skills for the competition, even when we account for the
over sampling of these majors in our inducement treatment assignment, and had lower cumulative GPAs.
Consistent with the predictions of our conceptual framework, inducement appears to lead lower ability
students to participate by increasing the pay-oﬀs to participation.18
Table II: Mean Participant Characteristic Comparisons by Inducement Treatment

Female
Weighted Female
CS or ElecEng Major
Weighted CS or ElecEng
Year of Study
CGPA (1-6)
Above Median CGPA
Prior Contest Experience
N

Not Induced

Induced

p-value

0.252
(0.043)
0.252
(0.043)
0.789
(0.040)
0.786
0.040
2.941
(0.120)
4.500
(0.091)
-.663
(0.049)
0.163
(0.036)
104

0.425
(0.054)
0.272
(0.034)
0.605
(0.053)
0.487
0.042
3.111
(0.146)
4.274
(0.101)
0.521
(0.060)
0.093
(0.032)
86

0.009***
0.726
0.006***
0.000***
0.365
0.096*
0.065*
0.154

Notes: Standard deviations are in parentheses. Female and CS/Elec Eng Major weighted to account for over sampling in induced
treatment. * significant at 10%; ** significant at 5%; *** significant at 1%

5.1.2

Impact on Outcomes

Despite the mean comparisons presented in Table II suggesting that the induced participants may be less
well equipped to compete, the success of these participants appears statistically indistinguishable from those
that were ‘innately’ drawn to the competition. In particular, mean outcomes across induced and innate
innovators presented in Table III demonstrate that induced participants have slightly lower mean submission
rates and scores than innate innovators, but that these diﬀerences are statistically insignificant and quite
small.
18 One possible concern with the inducement treatment is that those who signed up after the receiving it did so because
they did not see any of the contest announcements that were sent out prior to the inducement treatment. We think this is
unlikely for several reasons. First, the Engineering and Computer Science department, and the entrepreneurship center located
within the department sent out numerous emails to students about the contest over a two month period. Therefore, even if
the induced population did not read the emails announcing the contest, they would have chosen not to based on the subject
line that made clear there was a contest being announced which suggests they self-selected out of the contest based on their
preferences. Second, we asked participants in the inducement treatment why they had not signed up prior to receiving the
subsidy oﬀer in the post-contest survey, and while some stated they were not aware of the contest, many others stated that
they thought they didn’t have the time or ability to participate in it.

13

Table III: Mean Outcomes by Inducement Treatment
Not Induced

Induced

p-value

0.390
(0.126)
0.096
(0.029)
4.016
(0.497)
104

0.264
(0.108)
0.081
(0.030)
3.285
(0.653)
86

0.460

Average Ranking
Submitted Project
Average Ranking Conditional on Submitting
N

0.725
0.379

Notes: Standard deviations are in parentheses. Female and CS/Elec Eng Major weighted to account for over sampling in induced
treatment. * significant at 10%; ** significant at 5%; *** significant at 1%

We verify that the average eﬀect of the inducement treatment on outcomes is zero using regression
analysis and present these results in Table IV. Columns 1 and 2 present the estimated eﬀect of inducement
on whether or not a participant submits a project for consideration, columns 3 and 4 present the estimated
eﬀect of inducement on average project rankings, and columns 5 and 6 present the inducement treatment
eﬀect estimates on average project rankings conditional on making a submission to the contest. Columns 1,
3, and 5 do not include controls for participant characteristics, with those added in columns 2, 4, and 6. In
all specifications, the eﬀect of inducement on outcomes is insignificant.
Table IV: Eﬀect of Inducement Treatment on Outcomes
(1)
(2)
Submission

Inducement Treatment

Controls
Observations
R-squared
Mean dep var

(3)
(4)
Average Ranking

(5)
(6)
Average Ranking
Conditional on Submitting

-0.017
(0.0418)

-0.024
(0.0475)

-0.126
(0.170)

-0.190
(0.191)

-0.732
(0.806)

-0.527
(0.846)

No
190
0.001
0.090

Yes
172
0.025
0.090

No
190
0.003
0.510

Yes
172
0.046
0.510

No
17
0.052
2.824

Yes
17
0.404
2.824

Notes: Standard errors are in parentheses. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether
or not they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%

Thus, at least on average, it looks like eﬀective innovators can be ‘created’ through a simple inducement.
It is, however, noteworthy that the addition of controls for participant characteristics has a sizable eﬀect
on the point estimates for the average proposal scores conditional on submitting, suggesting a potentially
important role for heterogeneity that we will return to below.

14

5.2

Average Eﬀects of Receiving an Encouragement During the Contest

We are now ready to turn to the estimated eﬀects of the encouragement treatment on participant outcomes.
Table V presents mean comparisons between participants who did and did not receive the encouragement
treatment. As described earlier, the encouragement treatment was randomly assigned to all participants so
participants who received the encouragement treatment should look the same as those who did not. Panel A
on Table V largely confirms this with one minor exception. There is a small statistically significant diﬀerence
at the 10% level in whether or not a participant is in a computer science or electrical engineering major. To
ensure this diﬀerence is not impacting our findings, we confirm that all our results are robust to controlling
for it.
Panel B of Table V presents mean outcomes by encouragement treatment status. As in the case of
the inducement treatment, encouragement does not appear to have any significant impact on participant
outcomes in the contest.
Table V: Mean Comparisons by Encouragement Treatment
Not Encouraged

Encouraged

p-value

0.375
(0.050)
0.760
(0.044)
2.901
(0.137)
4.427
(0.100)
0.577
(0.050)
0.135
(0.035)

0.287
(0.047)
0.648
(0.049)
3.130
(0.125)
4.356
(0.092)
0.570
(0.052)
0.128
(0.035)

0.201

0.369
(0.118)
0.104
(0.031)
3.583
(0.415)
104

0.294
(0.121)
0.074
(0.027)
3.904
(0.792)
86

Panel A: Participant Characteristics
Female
CS or ElecEng Major
Year of Study
CGPA (1-6)
Above Median GPA
Prior Contest Experience

Panel B: Outcomes
Average Ranking
Submitted Project
Average Ranking Conditional on Submitting
N

0.093*
0.218
0.604
0.918
0.875

0.656
0.476
0.702

Notes: Standard deviations are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%

Table VI presents these results in a regression framework. The coeﬃcient estimates suggest that encouragement had no meaningful eﬀect on whether or not participants submitted a project or on our combined
average normalized score variable. The coeﬃcient estimate on submission scores conditional on submitting
15

(columns 5 and 6) are positive and quite large but as in the other columns, are statistically insignificant.
Together, these findings suggest that encouragement had no eﬀect on outcomes, the small sample size for
those that submitted a project make it diﬃcult to draw any definitive conclusions regarding that outcome.
Table VI: Eﬀect of Encouragement Treatment
(1)
(2)
Submission

(3)
(4)
Average Ranking

(5)
(6)
Average Ranking
Conditional on Submitting

Encouragement Treatment

-0.028
(0.042)

-0.020
(0.047)

-0.075
(0.169)

-0.014
(0.190)

0.322
(0.824)

0.425
(0.948)

Controls
Observations
R-squared
Mean dep var

No
190
0.002
0.0895

Yes
172
0.025
0.0895

No
190
0.001
0.510

Yes
172
0.040
0.510

No
17
0.010
2.824

Yes
17
0.393
2.824

Notes: Standard errors are in parentheses. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether
or not they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%

5.3

Interaction Eﬀects between Inducement and Encouragement

We next explore whether our encouragement treatment changes the eﬀect of inducement, for instance, by
boosting the confidence of participants who do not feel as capable of innovating as innate innovators. We
present the estimates from equation 1 described in section 4 in Table VII. As in Tables VI and IV, we run
the analysis with and without controls for participant characteristics.
The estimates demonstrate that across all specifications, the interaction between the inducement and
encouragement treatments is negative and, in some cases, quite large. However, it is important to note that
we cannot rule out that the coeﬃcients are zero or even positive. In the end, the treatment eﬀects and
interaction are explaining very little of the variation in participant performance, suggesting little role for the
interaction of our two treatments on participant outcomes.

5.4

Heterogeneous Treatment Eﬀects

We theorized in section 2 that the inducement treatment could vary by participant ability if inducement
leads both lower ability innovators and innovators with a higher cost of innovation but similar ability as
the self-selected population to participate. In particular, inducement should reduce performance among the
lower ability population, but not impact it among those that simply have a higher cost of participation.

16

Table VII: Joint Eﬀect of Inducement & Encouragement Treatment
(1)
(2)
Submission

Inducement Treatment

(3)
(4)
Average Ranking

(5)
(6)
Average Ranking
Conditional on Submitting

Encouragement Treatment*
Inducement Treatment

0.019
(0.059)
0.006
(0.057)
-0.073
(0.084)

0.016
(0.066)
0.018
(0.064)
-0.079
(0.093)

0.031
(0.238)
0.071
(0.230)
-0.318
(0.340)

-0.019
(0.267)
0.151
(0.259)
-0.344
(0.374)

-0.367
(1.099)
0.501
(1.099)
-0.902
(1.823)

-0.253
(1.180)
0.683
(1.308)
-0.729
(2.053)

Controls
Observations
R-squared
Mean dep var

No
190
0.007
0.0895

Yes
172
0.030
0.0895

No
190
0.009
0.510

Yes
172
0.051
0.510

No
17
0.072
2.824

Yes
17
0.424
2.824

Encouragement Treatment

Notes: Standard errors are in parentheses. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether
or not they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%

Moreover, encouragement may diﬀerentially impact high and low ability participants if, for instance, lower
ability participants are less confident than high ability participants are.
To simplify the presentation of our analysis of heterogeneous treatment eﬀects, we present mean comparison figures and regression estimates from equation 2 below. We begin by presenting heterogeneous eﬀects
of inducement, followed by those of encouragement.19

5.4.1

Eﬀects of Inducement by Participant GPA

Figure II presents the diﬀerence in mean contest performance between induced and non-induced contest participants for below and above median CGPA participants respectively. These means support our predictions
that when inducement leads lower ability individuals to participate in innovation, it leads to lower innovative
performance. In particular, inducement leads to a large and significant reduction in participant performance
among low GPA students, but an increase in performance among high GPA students. Interestingly, the
highest performers are innate low GPA students suggesting that they may have private information about
their innovative capabilities that are not reflected in their academic performance.
Table VIII presents estimates of the interaction between GPA and inducement, and provides support for
the mean comparisons. In particular, low GPA students suﬀer from inducement whereas high GPA students
benefit from it. These eﬀects seem to work both by aﬀecting submission rates and rankings conditional on
19 We did not design our study to have suﬃcient sample size to estimate heterogeneous eﬀects by all four treatment groups
and so we don’t report these eﬀects here. However, controlling for whether those in the inducement treatment are also in the
encouragement treatment and vice versa does not change our results.

17

Figure II: Change in Average Ranking due to Inducement by GPA

18

submissions.20 Appendix Table A4 demonstrates that the estimates presented in Table VIII are minimally
aﬀected by the inclusion of controls for participant characteristics, though we lose some significance.
Table VIII: Joint Eﬀect of Inducement Treatment by GPA

Inducement Treatment
Above Median CGPA
Above Median CGPA*
Inducement Treatment
Observations
R-squared
Mean dep var

(1)
Submission

(2)
Average Ranking

(3)
Average Ranking
Conditional on Submitting

-0.067
(0.064)
-0.059
(0.059)
0.084
(0.085)

-0.480*
(0.259)
-0.460*
(0.238)
0.581*
(0.344)

-2.068*
(1.085)
-2.101**
(0.939)
2.601
(1.473)

190
0.007
0.09

190
0.024
0.332

17
0.323
3.715

Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%

5.4.2

Eﬀects of Encouragement by Participant GPA

Figure III presents the diﬀerence in mean contest performance between encouraged and not encouraged
contest participants below and above median CGPA participants, respectively. As with inducement, these
comparisons demonstrate that the impacts of encouragement diﬀer by ability. Unsurprisingly, low GPA
students benefit from the additional support provided by encouragement. The impacts on high GPA students
are much less intuitive. Not only do they not benefit from this encouragement, but they appear to be harmed
by it.21
Table IX presents the estimated impact of the interaction between participant GPA and the encouragement treatment on our three primary outcomes of interest. This Table demonstrates that encouragement
negatively impacted both the likelihood of submitting a project and project quality conditional on submitting among high GPA students. The positive eﬀect of encouragement on low GPA student performance
appears to work largely by improving the quality of submitted projects. Appendix Table A5 demonstrates
that the estimates presented in Table VIII are minimally aﬀected by the inclusion of controls for participant
characteristics.
20 Given the relatively large standard errors on our estimates, we do not think interpreting the specific sizes of our estimates
is particularly valuable, and instead focus on interpreting their signs.
21 Interestingly, virtually all encouraged participants who completed the post-contest survey indicated positive experiences
with the encouragement emails suggesting those who were negatively impacted by the treatment did feel as though they had
been.

19

Figure III: Change in Average Ranking due to Encouragement by GPA

Table IX: Joint Eﬀect of Inducement Treatment by GPA

Encouragement Treatment
Above Median CGPA
Above Median CGPA*
Encouragement Treatment
Constant

Observations
R-squared
Mean dep var

(1)
Submission

(2)
Average Ranking

(3)
Average Ranking
Conditional on Submitting

0.052
(0.064)
0.052
(0.059)
-0.139*
(0.084)
0.073
(0.045)

0.397
(0.256)
0.246
(0.237)
-0.827**
(0.338)
0.228
(0.180)

1.890*
(0.905)
0.675
(0.855)
-4.510***
(1.344)
3.110***
(0.715)

190
0.018
0.09

190
0.037
0.332

17
0.529
3.715

Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%

20

5.5

Exploring Mechanisms

To better understand the mechanisms driving our estimated average eﬀects of the encouragement and inducement treatments, we ask all participants to complete a short survey following the announcement of
contest winners for the chance to win a $100 Visa gift card. The survey questions are reported in Appendix
B. Importantly, the sample of participants who completed the survey represents 41% of the total contest
participant population, and, as Table X shows, those who completed the survey were, on average, much
more likely to have submitted a project for consideration than those who did not complete it. Given this
selected sample, we view this part of our analysis as suggestive rather than conclusive evidence on some of
the underlying factors that may be driving our results.
Table X: Summary Statistics by Final Survey Completion

Panel A: Participant Characteristics
Female
CS or ElecEng Major
Year of Study
CGPA (1-6)
Prior Contest Experience
Inducement Treatment
Encouragement Treatment

Panel B: Outcomes
Submission
Average Ranking
Average Ranking Conditional on Submitting
N

No Response

Response

p-value

0.313
(0.043)
0.714
(0.042)
3.073
(0.122)
4.417
(0.083)
0.152
(0.034)
0.446
(0.0470
0.456
(0.047)

0.359
(0.055)
0.692
(0.053)
2.932
(0.144)
4.356
(0.115)
0.103
(0.035)
0.474
(0.058)
0.538
(0.058)

0.506

0.117
(0.070)
0.418
( 0.041)
3.249
(1.236)
114

0.639
(0.173)
0.642
(0.094)
3.858
(0.383)
76

0.745
0.458
0.657
0.326
0.706
0.262

0.002***
0.015**
0.530

Notes: Standard deviations are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%

In particular, we focus on three survey-based measures of contest engagement that we think are most
relevant for understanding how our treatments aﬀected participants’ perception and experience with the
contest. Specifically, we analyze whether encouragement or inducement correlates with whether or not
participants spent any time on the contest problem, and if they did not submit a project for consideration,

21

whether the treatments related to what prevented them from doing so. We break the latter measure of
engagement into two categories that were the most frequently cited explanations for not submitting a project;
not having enough time, and finding the contest problem too challenging to allow for satisfying solution
strategies.
Table XI presents the results of this analysis. Consistent with the finding that neither encouragement
nor inducement impacted participant outcomes on average, and with the mean comparisons presented in Tables III and V, the treatments do not appear to correlate significantly with whether or not participants invest
any eﬀort in the contest. Similarly, our treatments do not relate to the likelihood that participants failed
to submit a project to the contest because they felt the problem was too challenging for them. However, as
demonstrated by Column 3, we find that the encouragement treatment is associated with an approximately
thirty percentage point increase in the likelihood that participants report not submitting due to time constraints. In column 4, we add controls for participant characteristics to better capture selection, at least
on observables, and the estimate increases slightly. We view this finding as one consistent with the notion
that the encouragement emails increased the salience of the time required for developing a solution to the
contest problem and thus one that decreased submissions.22 In light of our results in Table IX, which showed
that the negative eﬀects of encouragement are concentrated on high GPA students, it seems plausible that
this time salience feature from encouragement is felt most acutely by high-achieving students whose scarce
time is more likely to be allocated to school work. Whether it also relates to the crowding out of intrinsic
motivation remains an open question.
Table XI: Eﬀects of Inducement and Encouragement on Survey Outcomes

Inducement Treatment
Encouragement Treatment

Controls
Observations
R-squared
Mean dep var

(1)
(2)
Any Eﬀort on Contest

(3)
(4)
No Submission due to Time

(5)
(6)
No Submission due to Challenge

-0.027
(0.107)
-0.091
(0.107)

-0.040
(0.122)
-0.081
(0.119)

-0.091
(0.121)
0.273**
(0.122)

-0.058
(0.152)
0.304**
(0.143)

0.055
(0.125)
-0.002
(0.125)

0.023
(0.154)
0.004
(0.145)

No
79
0.010
0.684

Yes
72
0.063
0.684

No
66
0.088
0.470

Yes
59
0.124
0.470

No
66
0.003
0.409

Yes
59
0.066
0.409

Notes: Standard errors are in parentheses. Columns 3-6 are restricted to the sample of participants who did not submit a project for
consideration in the contest. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether or not they
major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. * significant at
10%; ** significant at 5%; *** significant at 1%

22 All

estimates report in Table XI are robust to using probit regressions rather than linear probability models.

22

6

Discussion

This study provides novel and causal evidence on the scope for creating new innovators, with and without
encouragement. It also sheds light on the obstacles to inducing participation and the key characteristics
that distinguish those that self-identify as an innovator from those that need to be induced. Our findings
demonstrate that self-selected, or innate, innovators appear to have better academic performance and are
more likely to be enrolled in a major typically associated with the skills required to perform well in an
app contest relative to induced innovators. Despite these quality diﬀerences, we do not observe diﬀerences
in performance across the innate and induced samples, nor do we observe any eﬀect of encouragement on
participant performance. However, additional analysis of our data demonstrates that these average eﬀects
mask important heterogeneity in our sample. In fact, the impact of inducement is significantly less promising
for lower ability students, as proxied by cumulative GPA, but these students are precisely the ones that benefit
from the additional support provided by encouragement. The impacts on high ability students are much
more surprising. Not only do they not benefit from encouragement, but they appear to be harmed by it.
While our survey evidence suggests that this may due to the increased salience of the time commitment
required to complete the project, it is also consistent with the idea that encouragement is crowding out
intrinsic motivation in this more capable population (Benabou and Tirole, 2003).
Combined with the framework that motivated our study design, our results suggest that some people
select out of innovative activities based on their expected performance, while others select out based on the
costs of participating. They demonstrate that innovators can be created by subsidizing their initial entry
into innovative tasks, but that targeting inducement towards those who select out due to their expected cost
of participation rather than their expected performance is a more eﬀective strategy to promote innovation.
That targeted can be based on relatively easy information to obtain suggests that such a strategy may be
both practical and cost eﬀective. In particular, we find evidence that targeting can be based on information
that is relatively easy to collect. In addition, we demonstrate that encouragement may also need to be
targeted in order improve performance of workers who benefit from it, and importantly, to avoid harming
those who do not.
Several important caveats of our study are worth highlighting. First, our study sample is comprised
of undergraduate engineering students. While these students have the relevant technical capabilities to
innovate and will form the backbone of the innovation economy after graduation, their relative youth may
limit the generalizability of our findings to more experienced cohorts in the workplace. Second, the sample of
workers who submitted a project for consideration is quite low. Although we have anecdotal evidence that a
23

10% submission rate is standard for this type of competition and, therefore, that our findings have relevant
external validity, some of our null results may be in part due to lack of power. Third, while our encouragement
emails were motivated by evidence on motivating employees (e.g. Amabile and Pratt, 2016), there are many
ways to provide workers with encouragement aimed at enhancing performance. Therefore, while we think
our finding that managerial interventions designed to encourage workers can have negative impacts on
performance highlights a potentially important concern for managers of innovative firms, it remains possible
that alternative interventions could avoid this shortcoming. Lastly, our measures of contest success are
based on quantifiable performance metrics provided by expert evaluators. We do not have market-driven
measures of innovative success, which may better reflect the ambitions of firms. How well expert evaluations
of directed innovation translate into market success is an important area for future research.

7

References

Acemoglu, Daron, “Why do new technologies complement skills? Directed technical change and wage
inequality,” Quarterly Journal of economics, 1998, pp. 1055–1089.
and Jorn-Steﬀen Pischke, “The structure of wages and investment in general training,” Technical
Report, National Bureau of Economic Research 1998.
Amabile, Teresa M and Michael G Pratt, “The dynamic componential model of creativity and innovation in organizations: Making progress, making meaning,” Research in Organizational Behavior, 2016,
36, 157–183.
Azoulay, Pierre, Joshua Graﬀ Zivin, and Gustavo Manso, “Incentives and Creativity: Evidence from
the Howard Hughes Medical Investigator Program,” The RAND Journal of Economics, 2011, 42, 527–554.
Barber, Brad M and Terrance Odean, “Boys will be boys: Gender, overconfidence, and common stock
investment,” Quarterly Journal of Economics, 2001, pp. 261–292.
Becker, Gary S, “Investment in human capital: A theoretical analysis,” The Journal of Political Economy,
1962, pp. 9–49.
Beede, David N, Tiﬀany A Julian, David Langdon, George McKittrick, Beethika Khan, and
Mark E Doms, “Women in STEM: A gender gap to innovation,” Economics and Statistics Administration
Issue Brief, 2011, (04-11).
Benabou, Roland and Jean Tirole, “Intrinsic and extrinsic motivation,” The review of economic studies,
2003, 70 (3), 489–520.
Bureau of Labor Statistics, “Monthly Labor Review, 2013,” Technical Report 2013.
Compte, Olivier and Andrew Postlewaite, “Confidence-enhanced performance,” American Economic
Review, 2004, 94 (5), 1536–1557.
Ederer, Florian and Gustavo Manso, “Incentives for innovation: Bankruptcy, corporate governance,
and compensation systems,” Handbook of Law, Innovation, and Growth, 2011, pp. 90–111.
24

Elfenbein, Daniel W, Barton H Hamilton, and Todd R Zenger, “The small firm eﬀect and the
entrepreneurial spawning of scientists and engineers,” Management Science, 2010, 56 (4), 659–681.
Grossman, Gene and Elhanan Helpman, “Endogenous Innovation in the Theory of Growth,” Journal
of Economic Perspectives, 1994, 8 (1), 23–44.
Grossman, Gene M and Elhanan Helpman, “Trade, knowledge spillovers, and growth,” Technical
Report, National Bureau of Economic Research 1990.
Holmstrom, Bengt, “Agency costs and innovation,” Journal of Economic Behavior & Organization, 1989,
12 (3), 305–327.
Lyons, Elizabeth and Laurina Zhang, “Who Does (Not) Benefit from Entrepreneurship Programs?,”
Strategic Management Review, 2017, Forthcoming.
Nicolaou, Nicos, Scott Shane, Lynn Cherkas, Janice Hunkin, and Tim D Spector, “Is the
tendency to engage in entrepreneurship genetic?,” Management Science, 2008, 54 (1), 167–179.
Oettl, Alexander and Ajay Agrawal, “International labor mobility and knowledge flow externalities,”
Journal of International Business Studies, 2008, 39 (8), 1242–1260.
Ramirez, Octavio A, Charles B Moss, and William G Boggess, “Estimation and use of the inverse
hyperbolic sine transformation to model non-normal correlated random variables,” Journal of Applied
Statistics, 1994, 21 (4), 289–304.
Scotchmer, Suzanne, “Standing on the shoulders of giants: cumulative research and the patent law,” The
Journal of Economic Perspectives, 1991, 5 (1), 29–41.
Solow, Robert M, “Technical change and the aggregate production function,” The Review of Economics
and Statistics, 1957, pp. 312–320.
US News & World Report, “Best Global Universities for Computer Science,” Technical Report 2016.

25

Appendix A

Additional Tables
Table A1: Eﬀects of Inducement Gender
(1)
Submission

(2)
Average Ranking

(3)
Average Ranking
Conditional on Submitting

Inducement Treatment*
Female

-0.011
(0.052)
0.024
(0.065)
-0.023
(0.090)

-0.087
(0.212)
0.276
(0.265)
-0.203
(0.366)

-0.607
(1.002)
1.643
(1.103)
-0.783
(1.645)

Observations
R-squared
Mean dep var

190
0.002
0.0895

190
0.009
0.332

17
0.216
3.715

Inducement Treatment
Female

Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%

Table A2: Eﬀects of Encouragement by Gender
(1)
Submission

(2)
Average Ranking

(3)
Average Ranking
Conditional on Submitting

Encouragement Treatment*
Female

0.009
(0.051)
0.057
(0.060)
-0.111
(0.089)

0.046
(0.207)
0.289
(0.246)
-0.337
(0.363)

0.189
(0.909)
0.767
(0.949)
2.845
(1.878)

Observations
R-squared
Mean dep var

190
0.011
0.0895

190
0.009
0.332

17
0.309
3.715

Encouragement Treatment
Female

Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%

26

Table A3: Eﬀects of Encouragement & Inducement on Alternate Measures of Performance

Inducement
Treatment
Encouragement
Treatment

(1)
Average
Ranking (IHS)
-0.098
(0.128)
-0.028
(0.128)

(2)
Average
Normalized Score
-0.084
(0.134)
-0.031
(0.133)

(3)
Average Normalized Score
Conditional on Submitting
-0.327
(0.773)
0.473
(0.773)

(4)
Average Normalized
Score (IHS)
-0.059
(0.091)
-0.013
(0.091)

190
0.003
0.582

190
0.002
0.253

17
0.047
2.824

190
0.002
0.510

Observations
R-squared
Mean dep var

Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%

Table A4: Joint Eﬀect of Inducement Treatment by GPA, Controls

Inducement Treatment
Above Median CGPA
Above Median CGPA*
Inducement Treatment
Observations
R-squared
Mean dep var

(1)
Submission

(2)
Average Ranking

(3)
Average Ranking
Conditional on Submitting

-0.064
(0.069)
0.081
(0.094)
0.074
(0.093)

-0.487*
(0.277)
0.088
(0.378)
0.551
(0.373)

-1.978
(1.102)
-3.014*
(1.581)
2.314
(1.470)

172
0.040
0.09

172
0.065
0.332

17
0.627
3.715

Notes: Standard errors are in parentheses. All columns include controls for participant gender, cgpa, year of study, whether or not
they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%

27

Table A5: Joint Eﬀect of Encouragement Treatment by GPA, Controls
(1)
Submission

(2)
Average Ranking

(3)
Average Ranking
Conditional on Submitting

0.067
(0.068)
0.202**
(0.096)
-0.163*
(0.092)

0.477*
(0.273)
0.831**
(0.387)
-0.920**
(0.371)

2.490
(1.414)
1.619
(2.239)
-4.488**
(1.667)

172
0.054
0.09

172
0.081
0.332

17
0.726
3.715

Encouragement Treatment
Above Median CGPA
Above Median CGPA*Encouragement Treatment

Observations
R-squared
Mean dep var

Notes: Standard errors are in parentheses. All columns include controls for participant gender, cgpa, year of study, whether or not
they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%

Appendix B

Data Appendix

Inducement Treatment Emails
The email oﬀering a monetary incentive for contest participation sent to students in the inducement treatment
is copied below.

Hello,
The 2017 UC San Diego Student Innovation Contest is oﬀering students the opportunity to solve a real world
problem and win up to $5,000! Thanks to an award from the Kauﬀman Foundation, the contest organizers
are oﬀering a $100 pre-paid visa card for participating in the contest. A random sample of students have
been selected for this invitation-only opportunity and you are one of them.
The organizers have postponed the sign up deadline from February 1 until February 7 to allow students who
receive this invitation to take advantage of this opportunity. If you would like to participate in the contest,
please sign up by 6 pm on February 7 and you will automatically be awarded a $100 visa card. For more
information and to sign up for the contest, please visit: contest website.
This contest is open to all Jacobs School of Engineering undergraduate students.
Sincerely,
Contest organizer

28

The email explaining the monetary incentive and sign-up deadline extension to students in the self-selected
group is copied below.

Hello,
Thank you for signing up to participate in the 2017 UC San Diego Student Innovation Contest. Thanks to a
generous award from the Kauﬀman Foundation, the contest organizers are oﬀering students a $100 pre-paid
visa card just for participating in the contest! In addition, they have invited a randomly selected set of
students to sign up and also take advantage of this opportunity. To allow these students time to sign up,
the organizers have postponed the start of the contest until February 8.
As a result of these changes, you will be receiving a $100 visa card, and a description of the problem you are
to solve for the contest will be announced on February 8. The organizers apologize for any inconveniences
this delay may cause you. Details on how to collect your visa card will be sent to you within the next three
weeks.
Sincerely,
Contest organizer

29

Encouragement Treatment Emails

Encouragement Email #1

Dear UCSD Student Innovation Contest Participant,

We hope that youre enjoying the Quarter! We wanted to reach out to tell you how happy we are that you
are participating in the first ever UCSD Student Application Innovation Contest. We are confident that you
will enjoy the time you spend developing your submission, and that you will gain valuable experience and
knowledge through the process. By developing and refining your creativity, technical abilities, and project
management skills we strongly believe that this contest will prepare you for a rewarding and innovative
career. In addition, the solution you are developing for how an app can be used to help people fall asleep
has the potential to have meaningful social and commercial value.

We also want to remind you that UCSD has a number of resources available for students interested in
furthering their innovation capabilities, including the Institute for the Global Entrepreneur at the Jacobs
School of Engineering (http://jacobsschool.ucsd.edu/globalentrepreneur/).

We look forward to seeing your innovation!

Sincerely,
Contest Organizers

Encouragement Email #2

Dear UCSD Student Innovation Contest Participant,

You are now almost one third of the way through the first UCSD Student Innovation Contest! This also
means that you still have over ten weeks to work on your submission. We hope that you have begun to make
progress on your solution for helping people fall asleep faster, but if you havent had the chance to work on

30

it yet, there is plenty of time remaining to develop a solution in time for the deadline.

We look forward to seeing your innovation!

Sincerely,
Contest Organizers

Encouragement Email #3

Dear UCSD Student Innovation Contest Participant,

We hope youre enjoying Spring Break and getting some time to do things you enjoy! The contest judges
and organizers are very excited about the amount of creativity, eﬀort, and knowledge being put into
finding a solution to help people fall asleep faster and are looking forward to seeing your proposals and
applications. Just as a reminder, UCSD has some excellent resources for students considering careers
in entrepreneurship and innovation, including the Institute for the Global Entrepreneur at the Jacobs
School of Engineering (http://jacobsschool.ucsd.edu/globalentrepreneur/) and the Oﬃce of Research Affairs (http://innovation.ucsd.edu/entrepreneur/).

We look forward to seeing your innovation!

Sincerely,
Contest Organizers

Encouragement Email #4

Dear UCSD Student Innovation Contest Participant,

We hope your Spring Quarter has gotten oﬀ to a good start! We have just over 5 weeks left until the
contest deadline plenty of time for you to come up with and improve your solution to helping people
31

fall asleep faster with an application.

As a student in one of the 20 most innovative Computer Sci-

ence and Engineering departments in the US, we are thrilled to have you working on an application
that has the potential to have an impact on peoples well-being, and generate commercial success as well.
In addition to the sources available to students interested in careers in innovation and entrepreneurship
(http://jacobsschool.ucsd.edu/globalentrepreneur/, (http://innovation.ucsd.edu/entrepreneur/), the Kauﬀman Foundation, one of the contest sponsors, also has some great resources you can take advantage of
(http://www.kauﬀman.org).

We look forward to seeing your innovation!

Sincerely,
Contest Organizers

32

Copy of Post-Contest Survey

33

34

Notes: Question 1 was only included in the survey given to the induced population. Question 7 was only included in the survey given
to the encouraged population.

35

