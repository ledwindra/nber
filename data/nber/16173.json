{
    "id": 16173,
    "citation_title": "Active Labor Market Policy Evaluations: A Meta-Analysis",
    "citation_author": [
        "David Card",
        "Jochen Kluve",
        "Andrea Weber"
    ],
    "citation_publication_date": "2010-07-08",
    "issue_date": "2010-07-08",
    "revision_date": "None",
    "topics": [
        "\n",
        "Labor Economics",
        "\n",
        "Labor Supply and Demand",
        "\n"
    ],
    "program": [
        "\n",
        "Labor Studies",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nThis paper presents a meta-analysis of recent microeconometric evaluations of active labor market policies.  Our sample contains 199 separate \"program estimates\" - estimates of the impact of a particular program on a specific subgroup of participants - drawn from 97 studies conducted between 1995 and 2007.  For about one-half of the sample we have both a short-term program estimate (for a one-year post-program horizon) and a medium- or long-term estimate (for 2 or 3 year horizons).  We categorize the estimated post-program impacts as significantly positive, insignificant, or significantly negative.  By this criterion we find that job search assistance programs are more likely to yield positive impacts, whereas public sector employment programs are less likely.  Classroom and on-the-job training programs yield relatively positive impacts in the medium term, although in the short-term these programs often have insignificant or negative impacts.  We also find that the outcome variable used to measure program impact matters.  In particular, studies based on registered unemployment are more likely to yield positive program impacts than those based on other outcomes (like employment or earnings).  On the other hand, neither the publication status of a study nor the use of a randomized design is related to the sign or significance of the corresponding program estimate.  Finally, we use a subset of studies that focus on post-program employment to compare meta-analytic models for the \"effect size\" of a program estimate with models for the sign and significance of the estimated program effect.  We find that the two approaches lead to very similar conclusions about the determinants of program impact.\n\n",
    "acknowledgement": "\nWe thank the authors who responded to our survey for their co-operation and assistance.  We also thank four anonymous referees for helpful suggestions, and participants of an IZA/World Bank workshop, participants of LAMES 2009 Buenos Aires, and seminar participants at the University of Chile and the Inter-America Development Bank for comments on earlier versions of the paper.  Our research was funded by the Center for Labor Economics at UC Berkeley and by the German Science Foundation (DRG, SFB475). The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}