NBER WORKING PAPER SERIES

DAMPENING GENERAL EQUILIBRIUM:
FROM MICRO TO MACRO
George-Marios Angeletos
Chen Lian
Working Paper 23379
http://www.nber.org/papers/w23379

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2017, Revised June 2017

This paper subsumes an earlier draft that contained a similar message but used a different
framework. We are grateful to Guido Lorenzoni and Venky Venkateswaran for conference
discussions of our paper, and to Martin Beraja, Adam Guren, Glenn Ellison, Alessandro Pavan,
and Muhamet Yildiz for helpful discussions. We also thank seminar participants at MIT, Chicago
Booth, Duke, the Iowa State Conference on Global Games, the EFCE group at the 2016 NBER
Summer Institute, and the 2016 ESEM in Edinburgh. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2017 by George-Marios Angeletos and Chen Lian. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

Dampening General Equilibrium: From Micro to Macro
George-Marios Angeletos and Chen Lian
NBER Working Paper No. 23379
May 2017, Revised June 2017
JEL No. B41,D50,D80,E03,E13,E60
ABSTRACT
We argue that standard modeling practices often overstate the potency of general-equilibrium
(GE) mechanisms. We formalize the notion that GE adjustment is weak, or that it takes time, by
modifying an elementary Walrasian economy in two alternative manners. In one, we replace
Rational Expectations Equilibrium with solution concepts that mimic Tâtonnement or Cobweb
dynamics, Level-k Thinking, Reflective Equilibrium, and certain kinds of cognitive discounting.
In the other, we maintain rational expectations but remove common knowledge of aggregate
shocks and accommodate higher-order uncertainty. This permits us, not only to illustrate the
broader plausibility of the notion that the GE adjustment may be weak or slow, but also to
illustrate the sense in which our preferred approach—the one based on lack of common
knowledge—can be seen as a disciplined substitute to certain kinds of bounded rationality. We
finally discuss possible applications, including how our results may help reduce the gap between
the macroeconomic effects of interest and the micro or local effects estimated in a growing
empirical literature.

George-Marios Angeletos
Department of Economics, E52-530
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and NBER
angelet@mit.edu
Chen Lian
Department of Economics
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
lianchen@mit.edu

1

Introduction

General Equilibrium (GE) mechanisms are key to the interpretations we, economists, develop for various phenomena
and the related guidance we offer to policy makers. In some contexts, such mechanisms reinforce partial-equilibrium
(PE) effects, acting as “macroeconomic multipliers” that amplify exogenous shocks or increase policy effectiveness. In
other contexts, they offset PE effects, stabilizing aggregate outcomes or curtailing policy effectiveness.
One way or another, GE mechanisms limit the usefulness of PE intuitions. For instance, consider the popular notion
that a reduction in demand can trigger a recession. This notion may appear to be self-evident from a PE perspective,
yet it is absent in the neoclassical/RBC framework because of countervailing GE effects.
GE mechanisms also limit the usefulness of a growing empirical literature that seeks to quantify the causal effects
of aggregate shocks by exploiting the cross-sectional heterogeneity in the exposure to such shocks. For instance,
consider Mian and Suﬁ (2014), who offer compelling evidence that US regions that experienced steeper drops in
consumer credit during the recent recession also experienced larger employment losses. Although it is tempting to
use this evidence as a gauge of the macroeconomic impact of consumer deleveraging, there is a crucial limitation:
GE effects such as the adjustment of prices and income at the national level are absorbed by the time ﬁxed effect in
their regressions. As a result, there is a gap—of unknown magnitude and sign—between the “local” or “micro” effects
estimated in this type of work and the macroeconomic effects predicted by GE models.
In this paper, we re-evaluate the importance of GE mechanisms. We argue that standard modeling practices
overstate their potency by combining a strong solution concept and strong informational assumptions. We formalize
this point by comparing the predictions implied by this combination to those implied by certain variants of it. All but
one of them replace Rational Expectations Equilibrium (REE) with solution concepts that can be thought of as different
forms of “bounded rationality.” Our preferred alternative maintains REE but removes common knowledge of aggregate
shocks and accommodates higher-order uncertainty (i.e., uncertainty about the beliefs of others).
This multifaceted approach serves two goals: one applied and one methodological.
On the applied front, we offer different but complementary justiﬁcations for why GE adjustment may be “weaker”
or “slower” than previously considered. In settings in which GE effects amplify PE effects, the GE attenuation manifests
as under-reaction and inertia at the aggregate level. In settings in which, instead, GE effects offset PE effects, it manifests
as over-reaction and overshooting. In either case, because the underlying decision rules and the relevant PE effects
remain unchanged, the gap between the relevant micro and macro elasticities is reduced.1
On the methodological front, we connect three strands of the literature: the applied literature on incomplete
information and higher-order uncertainty;2 an older tradition that used Tâtonnement or Cobweb dynamics to capture
the off-equilibrium adjustment of prices in Walrasian economies; and a more recent literature in macroeconomics that
departs from the REE concept.3 We are thus able to demonstrate the capacity of different modeling approaches in
terms of attenuating or slowing GE adjustments; we also explain the sense in which lack of common knowledge can
be seen as a useful substitute to bounded rationality.4
Framework. We consider an elementary Walrasian economy, featuring decentralized and sequential trading. There
is a large number of “marketplaces,” which deﬁne the boundaries of market interactions: every agent can trade in a
single marketplace in each period, but may randomly move from one marketplace to another as time passes.
1 Throughout, the term “elasticity” refers to the response of an equilibrium outcome to an exogenous shock. In dynamic settings, the corresponding
concept is an impulse response function. Also, “micro” refers to the level of a market or a region, “macro” to the level of the economy.
2 See Morris and Shin (1998, 2002), Woodford (2003), Nimark (2008, 2017), Angeletos and La’O (2010, 2013), Angeletos and Lian (2016a,c,
2017) and the review in Angeletos and Lian (2016b).
3 See Garcıa-Schmidt and Woodford (2015), Gabaix (2016b), Farhi and Werning (2017), and Iovino and Sergeyev (2017).
4 The original development of our paper, which dates back to 2015, formalized the notion of GE attenuation on the basis of only two frictions:
the one that mimics Tâtonnement dynamics (see Section 5 in the present draft); and the one that allows for higher-order uncertainty (Section 6).
The additional variants that appear in Section 7 of the present draft help elaborate on the relations between the literatures cited in the previous two
footnotes, the present paper, and the speciﬁc applications we consider in Angeletos and Lian (2016a,c, 2017).

1

These are stark assumptions, which nevertheless capture two basic facts: that most trading is decentralized; and
that agents care, but are uncertain, about the behavior of agents they do not currently trade with.5 These assumptions
also help us draw a clear line between partial and general equilibrium: the former refers to the adjustment of a single
marketplace in isolation of the rest of the economy, the latter to the joint adjustment of all the marketplaces.
Starting from a status quo, we let an exogenous shock change the economy’s fundamentals (preferences, technologies, and endowments) and ask how its outcomes (quantities and prices) adjust to the shock. The answer to this
question depends on two sets of assumptions. The ﬁrst governs how the shock impacts the demand, the supply, and
the market-clearing outcomes in any given marketplace, taking as given the local perceptions of the behavior and the
prices in other marketplaces. The second speciﬁes how these perceptions themselves adjust to the shock.
In our analysis, we ﬁx the ﬁrst set of assumptions in line with standard modeling practice, but modify the second
set. In so doing, we are able to vary the potency of the GE effects of the shock, while holding constant its PE effects.
Frictionless Benchmark. In the vast majority of applied work,6 the relevant set of assumptions is (i) rational expectations and (ii) common knowledge of the state of the economy. This combination deﬁnes our frictionless benchmark.
Our benchmark predicts certain micro and macro elasticities, which serve as reference points in our subsequent
analysis. The macro elasticity measures the total effect of an aggregate shock on an aggregate outcome. The micro
elasticity measures the total effect of a local shock on the outcome of a single marketplace or, equivalently, the PE
effect of the aggregate shock. The gap between the two elasticities encapsulates the GE effect of the aggregate shock.
Our benchmark also has the following property: it replicates the outcomes of an Arrow-Debreu variant that allows
the agents to trade a complete set of date- and state-continent securities in a single centralized market that operates
once, at the beginning of time. Although not strictly needed for our purposes, this property is useful for three reasons.
First, it clariﬁes that our choice to let trading be sequential and decentralized does not introduce a friction by itself.
Second, it relates the conjectures that the agents form in our setting to the prices they observe in the Arrow-Debreu
variant. Finally, it sharpens the sense in which the GE adjustment is “perfect” and “instantaneous” in our benchmark.
All the considered modiﬁcations seek to relax this kind of perfection in the GE adjustment to the aggregate shock.
This is achieved by dropping either (i) rational expectations or (ii) the assumption that the shock is common knowledge.
Tâtonnement. In the ﬁrst modiﬁcation, we model the agent’s conjecture about the likely GE effects of the shock as
the product of an algorithm that mimics Tâtonnement dynamics. We choose this starting point because Tâtonnement
dynamics was traditionally meant to capture the process of adjustment from one equilibrium point to another. Unlike
the textbook version of this concept, however, there is no actual dynamics: we only model a cognitive process through
which each agent forms conjectures about market outcomes she does not directly observe. This process mimics a
Walrasian auctioneer who bases an initial conjecture on the pre-shock equilibrium point, computes the implied gap
between demand and supply, adjusts the relevant conjecture accordingly, and iterates. The number of iterations is
interpreted as the agent’s “depth of reasoning.”7
In our framework, this cognitive process is equivalent to iterating on a contraction mapping, whose ﬁxed point pins
down the REE prices. It follows that, in the limit as the depth of the process becomes inﬁnite, the post-shock price
conjectures coincide with their frictionless counterparts. But as long as the agents are “bounded rational” in the sense
that the aforementioned depth is ﬁnite, the assumed cognitive process generates a weaker adjustment in the relevant
conjectures than rational expectations do. It is therefore as if the GE spillovers have been reduced. Indeed, in the limit
that corresponds to zero cognitive depth, the macroeconomic effect of the shock is given by the PE effect alone: each
marketplace responds to the aggregate shock as if it were an idiosyncratic shock.
5 In

these respects, our modeling strategy borrows from the literatures on decentralized trading, the search-theoretic foundations of money, and
OTC markets (e.g., Kiyotaki and Wright, 1993; Lagos and Wright, 2005; Gale, 1986; Golosov, Lorenzoni, and Tsyvinski, 2014; Dufﬁe, Garleanu,
and Pedersen, 2005). Our goals and our contribution, however, are distinct.
6 This excludes the works cited in the sequel and, more generally, the literatures reviewed in Angeletos and Lian (2016b) and Woodford (2013).
7 This terminology evokes game-theoretic concepts such as Level-k Thinking. We study the connection in the sequel.

2

This result offers our ﬁrst formalization of the sought-after notion that GE adjustment is “imperfect” or “weak,”
relative to the frictionless benchmark. Because the PE adjustment that takes place at the marketplace level remains
the same as in that benchmark, the gap between the micro and macro elasticities of interest is reduced. The caveat is
that, by design, this comes at the cost of violating rational expectations.
Lack of Common Knowledge. In the second modiﬁcation, we bypass the aforementioned caveat by bringing back
the rational expectations hypothesis. We nevertheless attenuate the GE adjustment by removing common knowledge
of the underlying aggregate shock and of the reaction of the economy to it. In particular, we preclude the agents
from observing the reaction of marketplaces they do not themselves participate in, and we let them observe only a
noisy private signal of the underlying state of Nature. This may capture dispersed private information as in Lucas
(1972), Townsend (1983), Morris and Shin (2002), Morris and Shin (2002) and a large tradition in macroeconomics
and ﬁnance. But it can also be a representation of cognitive constraints as in Sims (2003), Woodford (2003, 2012),
Myatt and Wallace (2012), Pavan (2016) and Tirole (2015), or more generally of “states of mind” as in Harsanyi (1967).
While conceptually distinct, this setting is shown to have similar observable implications as the one described
before. In particular, for any depth of reasoning in the Tâtonnement setting, there is a level of the informational friction
in the new setting such that the irrational conjectures in the former are recast as the average rational expectations in
the latter, and the two economies generate the same observables at the aggregate level; and vice versa.
We conclude that lacking common knowledge of the aggregate shock helps rationalize a more ad hoc, and oldfashioned, way of thinking about equilibrium adjustments. But we also obtain the following distinct prediction: the
larger the GE effect in the frictionless benchmark, the larger the fraction of this effect that gets “erased” by any given
level of informational friction. In this regard, the offered remedy to the disconnect between the micro and the macro
elasticities of interest appears to work better the more severe the disconnect is to start with. Last but not least, we show
that the lack of common knowledge attenuates GE effects regardless of whether they reinforce or offset PE effects—a
prediction that, as discussed in the sequel, not shared by some of the considered alternatives.
The basic insight behind these ﬁndings is the following. Regardless of the information structure, rational expectations impose a ﬁxed-point relation between subjective beliefs and actual outcomes. But once agents lack common
knowledge of the innovations in the underlying fundamentals, this ﬁxed point is pinned down, not only by what the
agents know about these innovations, but also by what they think that others know, and so on. As one varies the
degree of such higher-order knowledge, one also varies the potency of the relevant GE effect.
The key lesson can be recast as follows. The rational expectations hypothesis alone does not nail down the relevant
GE effect; it only restricts its (absolute) magnitude within an interval. By imposing rational expectations together with
common knowledge of the shock, applied modeling practice often picks, perhaps inadvertently, the upper bound of
this interval. We instead show how one can span the entire interval. In this regard, we complement Bergemann and
Morris (2013), who study a class of beauty-contest games under arbitrary information structures; most importantly, we
explain the precise sense in which standard practice has “overstated” the importance of GE mechanisms.
Near-rationality, Level-k Thinking, and more. Not all forms of “bounded rationality” can capture the sought-after
notion of GE attenuation. For example, adapting the near-rationality concept of Akerlof and Yellen (1985a), or that of
the ϵ-equilibrium in games, to our context allows the GE effect to be either attenuated or ampliﬁed. With this basic
point in mind, we investigate whether GE attenuation is predicted by four other non-REE solution concepts. The ﬁrst
mimics Cobweb dynamics. The second mimics Level-k Thinking (Nagel, 1995, Stahl and Wilson, 1995, Farhi and
Werning, 2017). The third considers Reﬂective Equilibrium (Garcıa-Schmidt and Woodford, 2015). The fourth allows
for a form of “cognitive discounting” similar to that featured in Gabaix (2016a,b).
The variants based on Cobweb dynamics and Level-k Thinking are closely related to one another, in a manner that
resembles the aforementioned tight relation between the Tâtonnement and incomplete-information variants. Yet, they
are not always able to capture the sought-after notion of GE attenuation.
3

Consider, in particular, environments in which the GE effect offsets the PE effect, such as neoclassical settings in
which agents compete for ﬁxed resources; these environments are akin to games of strategic substitutability. In such
environments, Cobweb dynamics and Level-k Thinking allow the relevant price or quantity conjectures to overshoot
relative to the frictionless benchmark: every agent may expect the others to react more strongly to the shock than in
that benchmark. Whenever this is the case, the relevant GE effects are ampliﬁed instead of being attenuated.
This prediction appears problematic, not only because it is counterintuitive, but it also contradicts the “competition
neglect” phenomenon documented in the behavioral-economics literature (Camerer and Lovallo, 1999; Kahneman,
2011). This problem is avoided by our incomplete-information variant, as well as by “Reﬂective Equilibrium”, a
solution concept developed in Garcıa-Schmidt and Woodford (2015). This concept is grounded on Level-k Thinking.
But it also features a certain twist, which eliminates the aforementioned overshooting and guarantees that the relevant
conjectures behave similarly to those in our Tâtonnement and incomplete-information variants.
Finally, consider the kind of “cognitive discounting” found in Gabaix (2016a,b) or the related belief distortion
assumed in Greenwood and Hanson (2015). These approaches can accommodate GE attenuation, but are ﬂexible
enough to accommodate the exact opposite as well: it depends on whether the agents are assumed to err systematically
in the direction of believing that the other agents react less, or more, than what they actually do. For better or worse,
such ﬂexibility is not allowed by the alternative approach that maintains REE and adds higher-order uncertainty.
Dynamic Extension. The aforementioned results help formalize the notion that GE adjustment is “weak”, but allow
it to be as “instantaneous” as in the Arrow-Debreu paradigm. In an extension, we capture the complementary notion
that GE adjustment “takes time” by allowing the relevant conjectures to adjust slowly from the pre-shock frictionless
level to the post-shock one. In the variants that drop rational expectations, this requires the ad hoc assumption
that the “depth of reasoning” increases with the time lag since the shock has hit the economy. In the variant with
lack of common knowledge, instead, it obtains naturally from the property that beliefs converge to their frictionless
counterparts as agents observe past market outcomes.
Take-home Lessons. The combination of our results demonstrates that GE attenuation is a robust prediction of
either certain forms of bounded rationality or lack of common knowledge of the state of the economy. In this regard,
the two methodological approaches appear to be close substitutes to each other.
Nevertheless, some of the considered forms of bounded rationality leave open the door to the opposite prediction.
Furthermore, they all face certain conceptual and practical challenges. The most obvious one is the vulnerability to
Lucas’s critique. Another one is the aforementioned question of why the depth of reasoning may, or may not, increase
with time. For related reasons, these variants have difﬁculty in accommodating the notion that GE adjustment “takes
time” in stationary environments with recurring shocks: doing so would have required that the agents be swallow or
myopic thinkers vis-a-vis recent shocks and, at the same time, be deep thinkers vis-a-vis old shocks.
In our view, these observations tilt the balance in favor of the methodological approach that maintains rational
expectations, removes common knowledge of the state of the economy, and relates GE attenuation to higher-order
uncertainty. That said, since both informational and behavioral frictions seem empirically relevant, we ﬁnd it reassuring
for our purposes that the two kinds of friction can complement each other in the direction of attenuating GE effects.
Applications. Our framework is too abstract to permit a careful consideration of any particular application. We
consider this to be a strength, for it allows us to deliver the key insights in a ﬂexible manner and to connect to various
strands of the literature. We study a few applications in companion work, aiming to shed new light on the sources
of the business cycle (Angeletos and Lian, 2016c), monetary policy (Angeletos and Lian, 2016a), and ﬁscal policy
(Angeletos and Lian, 2017). The recent work of Iovino and Sergeyev (2017) on quantitative easing, and a few earlier
contributions such as Angeletos and La’O (2010), Venkateswaran (2014), and Schaal and Taschereau-Dumouchel
(2015), can be seen as additional applications of the broader ideas we articulate here. Finally, we brieﬂy discuss
potential applications outside macroeconomics, such as in industrial organization.
4

Layout. Section 2 positions our paper in the literature. Sections 3 and 4 introduce the framework and the frictionless
benchmark. Sections 5 and 6 explore the two leading variants, which build on Tâtonnement dynamics and on lack
of common knowledge. Section 7 studies additional variants. Section 8 develops the notion that GE adjustment takes
time. Section 9 discusses the key lessons and possible applications. Section 10 concludes.

2

Related Literature

Our paper builds heavily on Morris and Shin (1998, 2002, 2003), Woodford (2003), Bergemann and Morris (2013),
and the related macroeconomic literature on incomplete information; see Angeletos and Lian (2016b) for a survey
and additional references.8 We borrow from this literature the key insight that removing common knowledge of the
fundamentals impedes coordination and anchors higher-order beliefs. Our contribution includes the translation of
this insight in terms of GE attenuation and the building of a bridge between the aforementioned literature, the older
tradition on Tâtonnement and Cobweb dynamics, certain strands of the behavioral and experimental literatures, and
an emerging literature that removes rational expectations from the New-Keynesian framework (Garcıa-Schmidt and
Woodford, 2015; Gabaix, 2016b; Farhi and Werning, 2017). We also highlight that the GE attenuation implied by
higher-order uncertainty is robust to whether the environment features strategic complementarity or substitutability
(or, relatedly, whether GE effects amplify or offset PE effects), a prediction not shared by some of the considered
alternatives. Last but not least, we offer this attenuation as a potential remedy to the gap between the macro effects of
interest and the kind of local elasticities estimated in, inter alia, Mian and Suﬁ (2012, 2014), Nakamura and Steinsson
(2014) and Beraja, Hurst, and Ospina (2016).
By identifying predictions of the REE concept that are robust to the details of the information structure (which
is probably unknown to the analyst/econometrician), we complement Bergemann and Morris (2013). That paper
studies a class of games and focuses on the volatility and the dispersion of actions as the observables of interest. We
instead study a Walrasian economy and focus on certain elasticities (or IRFs), which are relevant either vis-a-vis the
aforementioned empirical literature or for policy counterfactuals. We also develop a framework that is better suited
for deﬁning, and studying, the notion of weak or slow GE adjustment.
By modeling the economy as a collection of segmented markets and by letting, in our preferred variant, agents form
rational expectations under dispersed information, we connect to Lucas (1972). Unlike that paper, however, we study
a setting in which there are general-equilibrium spillovers across the different “islands.” This means that the economy
is akin to a game, in which the behavior of each agent critically depends on her conjectures about the behavior of
others. These conjectures—and the associated higher-order beliefs—play a central role in our analysis, as they do in
the literature that has followed Morris and Shin (1998, 2002, 2003), whereas they are irrelevant in Lucas (1972).
By allowing current markets to clear under possibly arbitrary conjectures of future prices, our partial-equilibrium
analysis resembles the “temporary equilibrium” of Grandmont (1977); some subtle differences are explained in due
course. By allowing the aforementioned conjectures to depart from their REE counterparts, we then connect to Guesnerie (1992), Evans and Ramey (1992, 1995), Evans and Honkapohja (2001), and the literature discussed in Woodford
(2013). These works are concerned primarily with the question of whether the set of REE outcomes can be obtained as
the limit of certain eductive or learning procedures. Our paper bypasses this question—by working with a framework
in which the REE is the solution to a contraction mapping—and shifts the focus to a different theme.
By touching on the relation between micro and macro effects, our paper may appear to relate to the debate on
whether micro rigidity implies macro rigidity (Caplin and Spulber, 1987; Caballero and Engel, 1999; Golosov and
Lucas, 2007), or the debate on the elasticity of labor supply (Chetty et al., 2011, 2013; Keane and Rogerson, 2012).
8 Related is also the literature on rational inattention (Sims 2003; Mackowiak and Wiederholt 2009; Myatt and Wallace 2012; Pavan 2016), but
only insofar as rational inattention ends up introducing higher-order uncertainty (i.e., uncertainty about the beliefs and the behavior of others).

5

This is not the case, for neither of these debates is primarily concerned with GE effects. The former is about aggregation
of PE effects in settings with rich heterogeneity and non-linearity in these effects. The latter is about the calibration of
the key preference parameter that determines the PE response of labor supply to variation in wages.
The documented mechanism is also distinct—conceptually and empirically—from adjustment costs, habit, “stickiness”, “sparsity”, and any other friction that modiﬁes an agent’s decision rules, or a player’s best responses. Such
frictions ought to manifest in the response of individual choices to idiosyncratic shocks. By contrast, our mechanism
modiﬁes the macro-level responses while holding constant the underlying micro-level responses.9
Last but not least, the documented mechanism can manifest either as under-reaction or as over-reaction to aggregate
shocks: it depends on whether the GE effects amplify or offset the PE effects. Our work therefore provides a theory of
the attenuation of equilibrium interactions, not a theory of inertia or status-quo bias per se. By the same token, our
works builds a bridge from the macroeconomic literature on higher-order uncertainty to the behavioral literature on
“competition neglect” (Camerer and Lovallo, 1999; Kahneman, 2011; Greenwood and Hanson, 2015).

3

Framework

In this section, we introduce our baseline framework. We ﬁrst spell out the micro-foundations of the framework,
namely the market structure and the speciﬁcation of preferences, technologies, and endowments. We next derive the
associated demand and supply functions, which are the building blocks of our analysis. For reasons of tractability, we
thereafter work with the log-linearized demand and supply functions.

3.1

Marketplaces, Relocation, and Trading

Economic decisions take place over two periods, which we call “morning” and “afternoon”; these can be thought of
as proxies for “present” and “future” in setting with more than two periods, such as the one we consider in Section 8.
There is a double continuum of ﬁrms and households, each indexed by i ∈ [0, 1] × [0, 1], and three goods. One good
is storable and can be used for consumption and/or production in both periods. Possible examples include land and
capital, or leisure as in Lagos and Wright (2005). We let this good serve as the numeraire. The remaining two goods,
which we call the “morning good” and the “afternoon good”, are produced and consumed in the respective periods.
In each period, trade takes place in a continuum of segmented locations, which we call “marketplaces” and index
by m ∈ [0, 1]. Each marketplace operates two markets: one in the morning, where the morning good is traded with
the numeraire; and another in the afternoon, where the afternoon good is traded with the numeraire. In each period,
an agent can trade only in the marketplace she is currently in. As time passes, agents can move from one marketplace
to another: after the morning markets have closed but before the afternoon ones have opened, each agent receives an
idiosyncratic shock that determines whether she stays in her original marketplace or whether she gets relocated to a
different marketplace. The probability of an agent’s staying in her original marketplace in the “afternoon” is ρ ∈ [0, 1)
and that of relocating is 1 − ρ. Conditional on reallocation, all other marketplaces are equally likely.
These assumptions are illustrated in Figure 1. The marketplaces are represented by the boxes in the ﬁgure. In
the morning, an equal mass of agents is located to each of the marketplaces. After the morning market has cleared,
relocation takes places: while a fraction ρ ∈ [0, 1) of the agents from each marketplace stay put, the remaining fraction
is randomly relocated to all other marketplaces. In the afternoon, each marketplace is therefore populated by two types
of agents: a mass ρ of the agents that were originally located in that market; and a representative sample of the agents
that where originally spread in the rest of the economy. As mentioned in the Introduction, these stark assumptions
9 A variant of this point appears in Angeletos and Lian (2016a) in the following form: lack of common knowledge helps rationalizes a “discounted”
Euler condition at the aggregate level in spite of preserving the standard, undistorted, Euler condition at the individual level.

6

...

...

...

...

...

...

Figure 1: Marketplaces and Trading
help capture two realistic features: that agents participate in a limited number of markets at any given point of time;
and that agents nevertheless care about what’s going on in the rest of the economy because this affects their future
trading opportunities and thereby also their current incentives.
The “fundamental,” meaning an exogenous variable that affects preferences, technologies and endowments, differs
across agents. The initial distribution of agents is such that every marketplace receives equal masses of ﬁrms and
households, but these masses are not representative samples of the entire population. This is illustrated in the ﬁgure
by the fact that different boxes contain agents of different color. Note that, whether they relocate or not, agents maintain
their original “color” (their preferences, technologies, and endowments). It follows that the average fundamental in a
marketplace changes over time because, and only because, of the reshufﬂing in the composition of agents.
Without serious loss of generality, we ﬁnally assume that the original participants of any given marketplace share
the same preferences, technologies and endowments. (In the ﬁgure, each box starts with agents that have exactly the
same color, as opposed to having different shades of the same color.) This assumption lets us equate the idiosyncratic
fundamental of any given agent with the average fundamental of the marketplace in which that agent participates during
the morning. With this in mind, we henceforth let θm ∈ R denote the fundamental of the agents who participate in
marketplace m during the morning (Think of cross-sectional variation in θm as the different colors in the ﬁgure.)
Remark. Marketplaces do not have to coincide with geographic regions. Accordingly, the assumption that agents
move from one marketplace to another should not be interpreted as physical mobility. Instead, as in other works on
decentralized trading,10 this assumption is only meant to capture the fact that every agent typically trades with different
sets of other agents at different points of time. That said, when seeking to map the theory to the data, it seems plausible
to assume that agents who are closer to each other in terms of geographic distance are more likely to participate in the
same markets than agents that are further away from each other. We use this assumption in Appendix A—and only
there—so as to relate our theoretical contribution to the empirical literature we mentioned in the introduction.

3.2

1

Technologies, Preferences, and Endowments

We now specify the details of the technology that is available to each ﬁrm and of the preferences and the endowments
of each household. For our purposes, these details are relevant only insofar as they micro-found the demand and the
supply functions we work with in the rest of the paper.
Consider a ﬁrm i that trades in marketplace m during the morning and in marketplace m′ during the afternoon. Let

q denote its net supply of the morning good, qi∗ its net supply of afternoon good, and qin its net supply of the numeraire.
10 E.g.,

Kiyotaki and Wright (1993), Lagos and Wright (2005), Angeletos and La’O (2013), and Golosov, Lorenzoni, and Tsyvinski (2014).

7

Its technology is represented by a function Γ : R3 → R such that

qin = −Γ(qi , qi∗ ; θm ),

(1)

where Γ is strictly increasing and convex in (qi , qi∗ ), satisﬁes Γ(0, 0; θm ) = 0, and is differentiable in all its arguments. In
simple words, Γ(qi , qi∗ ; θm ) is the real cost of producing the pair (qi , qi∗ ). The realized proﬁt (in terms of the numeraire)
is thus given by

πi = pm qi + p∗m′ qi∗ + qin = pm qi + p∗m′ qi∗ − Γ(qi , qi∗ ; θm ),
where pm is the price of morning good in market m and p∗m′ is the price of afternoon goods in market m′ .
Consider next a household i that trades in marketplace m in the morning and marketplace m′ in the afternoon. We
let ci , c∗i , and cni denote her consumption of, respectively, the morning goods, the afternoon goods, and the numeraire.
We let her preferences depend on θm and represent them by following utility function:

ui = U (ci , c∗i ; θm ) + cni ,

(2)

where U is twice differentiable, strictly increasing, and strictly concave. We allow the endowment of the numeraire
also to depend on the local fundamental and, without loss of generality, set the endowments of the other two goods
to zero. The budget constraint of the household is thus given by

pm ci + p∗m′ c∗i + cni = yi ≡ e(θm ) + di ,

(3)

where e(θm ) denotes the endowment of the numeraire and di denotes the dividends the household receives from
owning shares on the ﬁrms. Because of the quasi-linearity in preferences, the distribution of dividends is irrelevant for
our purposes: any variation in income is absorbed by the consumption of the numeraire. With this in mind, we let
∫
di = [0,1]2 πj dj, which means that each household owns a fully diversiﬁed portfolio of all the ﬁrms in the economy.
Remark. We have allowed the preferences and the technology to be non-separable between the morning and the
afternoon goods in order to introduce an interdependence between the morning and the afternoon outcomes. One
example of such interdependence is the existence of capital goods. With separable preferences and technologies,
the desired interdependence between the morning and the afternoon outcomes can be preserved by dropping the
assumed quasi-linearity in the numeraire and by letting the agents trade bonds or money (i.e., to borrow and save) in
addition to trading the real goods. See Angeletos and Lian (2016a,c) for concrete examples.

3.3

Demand, Supply, and Market Clearing

Throughout, we impose the following minimal requirements on what the agents know and do.
Assumption 1. Every agent knows her own θm , the prices at which she trades, the structure described in the previous
two subsections, and the objects (U, Γ, e, ρ). Furthermore, every household [respectively, ﬁrm] is individually rational
in the sense that her chosen quantities maximize her utility [respectively, proﬁts] given the aforementioned knowledge,
the knowledge of the prices at which she trades, and her subjective belief of any unobserved variable.
Assumption 2. Subjective beliefs are the same within each marketplace (but can differ across marketplaces).
These assumptions are “minimal” in two complementary senses. First, they do not require that the agents know
¯ observe the prices in other marketplaces, or form rational expectations. Second, they sufﬁce for
the aggregate shock θ,
obtaining the demand and the supply schedules in each marketplace under arbitrary subjective beliefs of the outcomes
of other marketplaces.
8

To ease the analysis, we henceforth re-interpret all the variables as log-deviations from a symmetric steady state in
which all marketplaces have the same fundamentals, and we work with the log-linearized demand and supply system.
∗
With potential abuse of notation, we also let cm , qm , c∗m , qm
, etc., denote the average consumption and the average
∫
∫
output in a marketplace m. We next let c̄ ≡ c̄m dm, q̄ ≡ q̄m dm, etc., denote the economy-wide aggregates. We

ﬁnally let Êm [p∗m′ ] denote the subjective—potentially irrational—belief that the typical agent in marketplace m holds
about the price she is likely to face in the afternoon.11
Lemma 1. There exist linear functions D, S, D∗ , and S ∗ such that the following hold for every marketplace m: the
morning and afternoon demands are given by, respectively,

(
)
cm = D pm , Êm [p∗m′ ], θm

and

(
)
c∗m = ρD∗ (cm , p∗m , θm ) + (1 − ρ)D∗ c̄, p∗m , θ̄ ;

(4)

and the corresponding supplies are given by, respectively,

(
)
qm = S pm , Êm [p∗m′ ], θm

and

(
)
∗
qm
= ρS ∗ (qm , p∗m , θm ) + (1 − ρ)S ∗ q̄, p∗m , θ̄ .

(5)

This result characterizes the demand-and-supply structure of the economy. Let us explain where it comes from.
Thanks to the log-linearization, the morning demand of each household, and similarly the morning supply of each
ﬁrm, can be expressed as a linear function of the local morning price, the local fundamental, and the local subjective
belief of the afternoon prices. This explains the left-hand sides of conditions (4) and (5). To understand the right-hand
sides, note that the demand in any given afternoon market has two components: one reﬂecting the agents who were
in this market from the morning; and another reﬂecting the agents who were relocated from other markets. The former
have mass ρ and their demand is given by D∗ (cm , p∗m , θm ) ; the latter have mass 1 − ρ and their average demand is
(
)
∫
given D∗ (cm′ , p∗m , θm′ ) dm′ = D∗ c̄, p∗m , θ̄ . The same logic applies on the supply side.
We next impose market clearing.
∗
, for all m.
Assumption 3. Markets clear: cm = qm and c∗m = qm

How much can we tell about the behavior of the economy on the basis of Assumptions 1, 2, and 3 alone? Unfortunately, they are not enough to predict how the economy responds to the aggregate shock. The reason is that
these assumptions do not pin down the subjective beliefs that agents may hold in the morning about their trades in the
afternoon. Nevertheless, these assumptions permit us to express the market-clearing outcomes of each marketplace
as functions of the fundamentals and of these beliefs. We show this in the sequel.

3.4

The Mapping from Fundamentals and Subjective Beliefs to Observables

Consider the afternoon markets ﬁrst. Using Lemma 1 and the fact that cm = qm for all m (by market clearing of the
morning markets), the net afternoon demand in marketplace m can be expressed as follows:

(
)
∗
n∗m ≡ c∗m − qm
= ρN ∗ (qm , p∗m , θm ) + (1 − ρ)N ∗ q̄, p∗m , θ̄ ,

(6)

where N ∗ ≡ D∗ − S ∗ . To guarantee the existence of a unique p∗m that clears the afternoon market for every realization
of the fundamentals and the morning quantities, we assume that U and F are such that N ∗ (·, p∗ , ·) is decreasing in p∗ .
Finally, to characterize the market-clearing outcomes, we ﬁnd it convenient to introduce two auxiliary variables: the
11 Keep

in mind that, from the perspective of the individual agent, m′ is a random variable that is revealed in the afternoon.

9

average net afternoon demand, n̄∗ ≡

∫

nm dm, and the average afternoon price,
∗

∫

p̄ ≡

p∗m dm.

(
)
Aggregating condition (6) gives n̄∗ = N ∗ q̄, p̄∗ , θ̄ , which in turn means that n̄∗ = 0 if and only if p̄∗ = P ∗ (q̄, θ̄), where
P ∗ is deﬁned so that
N ∗ (q, P ∗ (q, θ), θ) = 0,

(7)

( )
for all (q, θ). Similarly, using (6), we have that, for every m, n∗m = 0 if and only if p∗m = ρP ∗ (qm , θm )+(1 − ρ) P ∗ q̄, θ̄ .We
therefore obtain the following characterization of the afternoon outcomes.
Lemma 2. There exist linear functions Q∗ and P ∗ such that, for all realizations of the fundamentals and the morning
quantities, the afternoon outcomes are given by

q̄ ∗ = Q∗ (q̄, θ̄),

p̄∗ = P ∗ (q̄, θ̄),

∗
qm
= ρQ∗ (qm , θm ) + (1 − ρ) q̄ ∗ ∀m,

and

p∗m = ρP ∗ (qm , θm ) + (1 − ρ) p̄∗ ∀m.

Consider next how the morning outcomes are determined. Using Lemma 1, the net demand in marketplace m can
be expressed as follows:

)
)
(
)
(
(
nm ≡ cm − qm = D pm , Êm [p∗m′ ], θm − S pm , Êm [p∗m′ ], θm = N pm , Êm [p∗m′ ], θm ,

(8)

where N ≡ D − S is the net (or excess) morning demand function. Similarly to N ∗ , we assume that U and F are such
that N (p, ·, ·) is decreasing in p: all the relevant excess morning demand curves are downward slopping. It follows
that, for every marketplace m and every possible value of the pair (Êm [p∗m′ ], θm ), there exists a unique pm such that it
clears the morning market. We denote this price and the corresponding market-clearing quantities by, respectively,

)
(
pm = P̃ Êm [p∗m′ ], θm

and

)
(
cm = qm = Q̃ Êm [p∗m′ ], θm ,

(9)

where P̃ and Q̃ are linear functions (which can be deduced by the demand and supply functions, D and S, or,
equivalently, by the utility and the cost functions, U and Γ).
Now note that, Êm [p∗m′ ], the subjective—potentially irrational—belief that the typical agent in marketplace m holds
about the price she is likely to face in the afternoon, has two components. Since this agent remains in marketplace

m in the afternoon with probability ρ and is relocated to a random other marketplace with the remaining probability,
we can express the aforementioned subjective probability as

Êm [p∗m′ ] = ρÊm [p∗m ] + (1 − ρ) Êm [p̄∗ ] .

(10)

To make further progress, we now add the following assumption:
Assumption 4. Agents know that Assumptions 1, 2, and 3 are true.
This assumption guarantees that the agents know that afternoon prices satisfy p∗m = ρP ∗ (qm , θm ) + (1 − ρ) p̄∗ in
any marketplace. It also guarantees that, by observing the morning price, the agents can perfectly infer the value of

qm in their own marketplace. From Lemma 2 and condition (10), we thus have the subjective beliefs in marketplace
m satisfy the following restriction:
(
)
Êm [p∗m′ ] = ρ2 P ∗ (qm , θm ) + 1 − ρ2 Êm [p̄∗ ] .

10

(11)

Let α̃ ≡

∂P ∗ ∂ Q̃
∂q ∂p∗ .

Provided that ρ2 α̃ ̸= 1, which we henceforth assume, we can combine conditions (9) and (11), solve

them for qm and pm , and therefore obtain the following characterization of the morning outcomes.
Lemma 3. There exist linear functions Q and P such that, for all m,

(
)
qm = Q Êm [p̄∗ ] , θm

and

(
)
pm = P Ê [p̄∗ ] , θm .

Furthermore, this fact, the fact stated in Lemma 2, and the functions (Q, P, Q∗ , P ∗ ) are known to every agent (but are
not necessarily common knowledge to them).
By expressing the market-clearing outcomes in the morning as functions of arbitrary subjective beliefs of the afternoon prices, we touch on the literature on “temporary equilibrium” (Grandmont, 1977). The twist is that, by
introducing segmented marketplaces and imposing Assumption 4, we have equated the “temporary equilibrium” of
the entire economy with the “partial equilibrium” of each marketplace in isolation.
To sum up, Lemmas 2 and 3 have shown how the morning outcomes can be expressed as functions of the fundamentals and of certain conjectures and how the afternoon outcomes can in turn be expressed as functions of the
fundamentals and the morning outcomes. To reach this point, we have only relied on Assumptions 1-4. These assumptions are noticeably weaker than those often made in applied research, because they do not impose common
knowledge of either the underlying shocks or the rationality and the decision rules of others. As a result, these assumptions leave free the conjectures that the typical agent in the morning can hold about the concurrent behavior of
agents in other marketplaces and, by the same token, about the prices she may herself face in the afternoon.
To form predictions about how the relevant economic outcomes—prices and quantities—respond to an exogenous
shock, we need to specify how the aforementioned conjectures are formed and adjust to the shock. We complete this
task in the next a few sections of the paper, under different assumptions about the solution concept and the information
that is available to the agents. We close the present section by specifying the shock under consideration.

3.5

The Exogenous Shock

Denote with θ̄ =

∫

θm dm the aggregate, or average, fundamental. Throughout, we let θ̄ be a single-dimensional

variable, θ̄ ∈ R, and focus on a once-and-for-all change in it, from some initial level, θ̄ = θ̄old , to some new level,

θ̄ = θ̄new ̸= θ̄old . We treat the initial level, θ̄old , as a ﬁxed parameter (and hence as a commonly known object) and
the change, ∆θ̄ ≡ θ̄new − θ̄old , as a random variable drawn from a Normal distribution with mean 0 and variance σθ2 .
We next specify the corresponding changes in the “local” fundamentals as follows:

∆θm = δm ∆θ̄ + ζm ,

(12)

where ∆θm is the change in the fundamental of any agent who is located in marketplace m in the morning, δm is a ﬁxed
∫
parameter that captures the exposure of m to the aggregate shock, with δm dm = 1, and ζm is a purely idiosyncratic
shock. The latter is independent of ∆θ̄, is drawn from a Normal distribution whose mean is zero and whose p.d.f. is
∫
∫
henceforth denoted by φ, and is such that ζm dm = ζφ(ζ)dζ = 0 for all realizations of uncertainty.
The question of interest is how the quantities and/or the prices respond to the shock. This can be split into two
parts. First, how does the shock shift demand and supply in each marketplace for given conjectures of the outcomes
in other marketplaces? Second, how does it shift the conjectures themselves? The answer to the ﬁrst part can readily
be obtained from Lemmas 2 and 3. The answer to the second part requires additional assumptions, namely a solution
concept and a speciﬁcation of the information that the agents have about markets they do not currently participate in.

11

4

The Frictionless Benchmark

Our benchmark is deﬁned by imposing the Rational Expectations Equilibrium (REE) concept along with the assumption
that, at any given period, the cross-sectional proﬁle of the fundamentals is common knowledge. More speciﬁcally,
we assume that all agents share the same information in the morning and this information contains the entire proﬁle
of (θm , pm )m∈[0,1] in the economy; all agents know this fact; all agents know that all agents know this fact; and so on.
Admittedly, this is a strong assumption; but it is the standard one.
Remark 1. The assumption that agents share the same information in the morning does not alone pin down their
subjective beliefs about the afternoon prices. In combination with the REE concept, however, it guarantees that all
agents share the same subjective beliefs and that these beliefs indeed coincide with the objective, rational, expectation
of the afternoon prices. In what follows, we prove this property and characterize the economy’s outcomes.
Remark 2. In our setting, the rational expectation of the afternoon prices happens to coincide with the actual
realizations of these prices, due to our simplifying assumption that there are no shocks to fundamentals between the
morning and the afternoon. This means that Rational Expectations Equilibrium (REE) coincides with Perfect Foresight
Equilibrium (PFE). However, as explained below, our characterization of the relevant expectations and of the associated
morning outcomes is robust to dropping the aforementioned assumption.

4.1

From Subjective Conjectures to Rational Expectations

Having imposed rational expectations, we can replace Êm [p̄∗ ] in Lemma 3 with E [p̄∗ ], where E denotes the rational expectation operator (conditional on the morning information). We thus have that the aggregate quantity in the
(
)
morning satisﬁes q̄ = Q E [p̄∗ ] , θ̄ . From Lemma 2, on the other hand, we have that the realized average price in the
afternoon is given by p̄∗ = P ∗ (q̄, θ̄). Combining these two fact imposes the following restriction between the realized
average price in the afternoon and the rational expectation of it in the morning:

(
)
p̄∗ = T E [p̄∗ ] , θ̄ ,

(13)

where T (p∗ , θ) ≡ P ∗ (Q (p∗ , θ) , θ) . Taking expectations on both sides and using the assumption that θ̄ is known in
the morning and the fact that E [E [p̄∗ ]] = E [p̄∗ ] , we infer that the rational expectation solves the following ﬁxed-point
relation:

(
)
E [p̄∗ ] = T E [p̄∗ ] , θ̄ .

(14)

Furthermore, the REE concept imposes that all the above facts are themselves commonly known to all agents. It
follows that both we, the outside observers, and the agents inside the model know that p̄∗ = E [p̄∗ ] and that E [p̄∗ ] is
itself pinned down by the ﬁxed points of the mapping T .
As noted earlier, the exact coincidence between p̄∗ and E[p̄∗ ] is due to the assumption that no innovation in the
aggregate fundamentals is possible between the morning and the afternoon.12 If we were to relax this assumption,
(
)
the morning quantities would still satisfy q̄ = Q E [p̄∗ ] , θ̄ , but now the afternoon prices would be given by p̄∗ =

P ∗ (q̄, θ̄) + ϵ, where ϵ is a term that captures the effect of the realized innovation. As a result, condition (13) would now
have to be replaced by p̄∗ = T (E [p̄∗ ] , θ) + ϵ. Nevertheless, because ϵ is unpredictable in the morning, condition (14)
would still hold. We conclude that, even when the realized p̄∗ varies around E[p̄∗ ] due to innovations in fundamentals,

T is the mapping whose ﬁxed points pin down the values of E[p̄∗ ] that are consistent with REE.
12 By an “innovation” we mean a change that is unpredictable in the morning. Predictable changes (sometimes referred to as “news shocks”) are
already nested, because we have not restricted how θ enters preferences and technology.

12

Note that the slope of T (p∗ , ·) with respect to p∗ is given by

α≡
where α̃ ≡

∂P ∗ ∂ Q̃
∂q ∂p∗ .

∂T
1 − ρ2
=
α̃,
∂p∗
1 − α̃ρ2

(15)

To guarantee that T is contraction mapping for every ρ, we make the following assumption.13

Assumption 5. α̃ ∈ (−1, 1).
Given this assumption, we can solve (14) for E [p̄∗ ] as a function of θ̄—and so can the agents inside the model. We
thus reach at the following result, which completes the equilibrium characterization of our benchmark.
Proposition 1. The equilibrium exists, is unique, and is such the following is true:
(i) The rational expectation of p̄∗ is given by

E[p̄∗ ] = P(θ̄)

(16)

where the function P is deﬁned by the ﬁxed point of T .
(ii) The equilibrium prices and quantities are given by Lemmas 2 and 3, replacing Êm [p̄∗ ], for every m, with P(θ̄).
Remark. In the preceding analysis, we have assumed that agents have common knowledge of (θm , pm )m∈[0,1] , the
entire cross-sectional proﬁle of the fundamentals and the prices. This assumption is consistent with those often made
in applied research, but is stronger than what is strictly needed in the present setting for the frictionless outcomes to
obtain: the same outcomes can be replicated under the weaker assumption that agents have common knowledge of
merely θ̄ and p̄. Note, however, that, in settings with richer matching/trading structures, common knowledge of the
average fundamental and/or the average price is generally not enough for replicating the frictionless outcomes.

4.2

Micro vs Macro, and PE vs GE

We are now ready to characterize how the morning outcomes respond to aggregate shocks. We focus on the morning
outcomes because we think of them as better proxies for the kind of outcomes that may be observable to an “econometrician” in the context of applications. This is because the “afternoon” in our model proxies the role of all the
relevant future market interactions, which may have not even be realized by the time the econometrician makes her
measurements. To simplify the exposition, we also focus on quantities; similar results apply for prices as well.
Combining the two parts of Proposition 1, we have that the realized quantities at the local and aggregate level are
given by, respectively,

qm = Q(P(θ̄), θm )

and

q̄ = Q(P(θ̄), θ̄).

(17)

Letting ∆ denote the change in a variable relative to its pre-shock value, we have the following result.
Proposition 2. There exist scalars ϵmicro and ϵM acro such that, for all realizations of the underlying aggregate and
idiosyncratic shocks, the corresponding changes in the equilibrium quantities are given by

(
)
∆qm = ∆q̄ + ϵmicro ∆θ̄m − ∆θ̄

and

∆q̄ = ϵM acro ∆θ̄.

The scalar ϵmicro measures the elasticity of local activity to a local shock or, equivalently, to the interaction of δm
with the aggregate shock. As explained in Appendix A, this object is therefore closely related to the kind of local
elasticities estimated in a growing empirical literature that exploits the cross-sectional heterogeneity in the exposure
to aggregate shocks (e.g. Mian and Suﬁ 2014). We henceforth refer to ϵmicro as the “micro elasticity”.
13 This assumption is, not only necessary and sufﬁcient for T to be a contraction mapping regardless of the value of ρ, but also sufﬁcient for the
property ρ2 α̃ ̸= 1, which was used in the construction of T in the ﬁrst place.

13

The scalar ϵM acro , on the other hand, measures the total effect of the aggregate shock on aggregate activity. We
henceforth refer to ϵM acro as the “macro elasticity”. This differs from ϵmicro because, and only because, of the GE
spillover across the different marketplaces. To see this, compare the following two scenarios. In the ﬁrst, we consider
an aggregate shock; let the agents understand that the shock hits all marketplaces at once and that, as result, p̄∗ will
adjust accordingly; and measure the resulting response in q̄. In the second, we consider the same aggregate shock but
ﬁx the subjective beliefs that the agents hold about the activity in other marketplace and about p̄∗ to their pre-shock
values. The ﬁrst scenario identiﬁes ϵM acro . The second scenario isolates the PE effect of the aggregate shock: it captures
the aggregate response that obtains when we hit all markets at once with the aggregate shock and nevertheless have
each market respond as if the shock was speciﬁc to that market or, equivalently, as if the agents expected p̄∗ to stay
constant. Clearly, this PE effect coincides with ϵmicro . It follows that the gap between ϵM acro and ϵmicro captures the
GE effect the aggregate shock, that is, the additional effect that obtains once we, and the agents inside the model, take
into account that p̄∗ itself adjusts in response to the aggregate shock so as to clear the afternoon markets.
We summarize these points in the following corollary.
Corollary( 1. The
macro elasticity can be decomposed to a PE and a GE component: ϵM acro = PE + GE, where
∫ ∂Q )
∂Q ∂P
micro
PE ≡
= PE. The gap
∂θ δm dm and GE ≡ ∂p∗ ∂θ . The PE effect is measured by the micro elasticity: ϵ
between the two elasticities therefore measures the GE effect of the shock.14
The gap identiﬁed above can be either negative or positive. Without loss of generality, let ϵmicro > 0. (This restriction merely ties a “positive” shock to an increase in the relevant quantity.) The case in which ϵM acro > ϵmicro captures
settings in which the GE effect works in the same direction as the PE effect, acting as an ampliﬁcation mechanism.
The alternative case, ϵM acro < ϵmicro , captures settings in which the GE effect works in the opposite direction than the
PE effect. We illustrate these two scenarios in the two panels of Figure 2, using the example of an aggregate demand
shock of the morning good. Blue (orange) lines represent the morning demand (supply) curves. In both panels, the PE
effect of the shock is represented by the movement from point X to point Y. Because we are considering a demand
shock, this entails a shift in the morning demand curve holding constant the morning supply curve. The GE effect, on
the other hand, is represented by the movement from point Y to point Z. This entails a shift in the morning supply
curve, as well as a further shift in the morning demand curve, because of the endogenous adjustment in p̄∗ . In the left
panel, this adjustment ampliﬁes the PE effect; in the right panel, it mitigates it.

pm

pm

Z

Z

Y

Y
X

X
GE effect

PE effect

GE effect

qm

PE effect

qm

Figure 2: PE and GE effects
14 A few clariﬁcations about terminology. First, the overall general-equilibrium response of q̄ to the aggregate shock is given by the entire ϵM acro ;
what we henceforth call GE effect is the component due to the adjustment of p∗ , that is, the effect that occurs beyond the PE effect. Second, what
we call PE effect in this paper is sometimes referred to as local GE effect in applied work. Finally, whereas we use the term “effect” to refer to the
marginal effect of a shock, in applied work the same term is often used to refer to the marginal effect times the size of the shock.

14

In what follows, we do not take a stand on which of these two cases applies: the GE effect may either amplify or
offset the PE effect. To make the analysis interesting, we only impose the following.
Assumption 6. The GE effect is non-zero:

∂Q ∂P
∂p∗ ∂θ

̸= 0.

We conclude this discussion with the following elementary observation. In the frictionless benchmark, the aggregate shock causes the economy to jump from point X to point Z , regardless of where Z is located relative to Y.
This underscores that the decomposition between PE and GE effect is irrelevant for the observables of the economy
at the aggregate level: all that matters is the total macroeconomic effect. By contrast, the modiﬁcations we study in
the rest of the paper Sections 5–7 will try to make sense of why this decomposition may be relevant and why the GE
adjustment may be “partial” in the sense that economy moves to a point in the middle of the segment between Y and

Z rather than all the way to Z .
Remark. In dynamic settings, the analogues of ϵmicro and ϵM acro are the impulse response functions of, respectively,
local and aggregate outcomes to, respectively, local and aggregate shocks. What we are interested in is the GE gap
between the two, not the technological or other factors that may drive the precise shape of these responses.

4.3

Connection to Arrow-Debreu and Additional Clariﬁcations

We now show that the outcomes of our frictionless benchmark coincide with those of an appropriate Arrow-Debreu
variant, which lets all markets operate at once and recasts the random matching as idiosyncratic technology and
preference shocks.15 This helps clarify some basic ideas and reﬁne the context of our contribution.
In the considered variant, there is neither sequential trading nor segmented marketplaces. Instead, there is a single
centralized market, which operates only once, but allows agents to trade over a sufﬁciently rich set of commodities.
This set includes a numeraire and multiple varieties of “morning” and “afternoon” goods. These varieties are indexed
by m, m′ ∈ [0, 1]. Finally, there are a double continuum of households and a double continuum of ﬁrms, each indexed
by i = (i1 , i2 ) ∈ [0, 1]2 .
Every household likes to consume a single variety of the morning good and a single variety of the afternoon good.
She knows a priori the variety of the morning good she likes, but faces idiosyncratic uncertainty about the likable
variety of the afternoon good. Fix an m and consider any household i who likes variety m of the morning good. The
probability that she likes variety m′ = m of the afternoon good is given by ρ ∈ [0, 1). With probability 1 − ρ, the variety
she likes is drawn from a uniform distribution over [0, 1]. Finally, her preferences (expected utility) are given by

)
]
[ (
Ui = ρ U ci , c∗i,m , θm + cni,m + (1 − ρ)

∫

]
[ (
)
U ci , c∗i,m′ , θm + cni,m′ dm′ ,

where c∗i,m′ and cni,m′ denote the consumption of the afternoon goods and the numeraire if she likes variety m′ in the
afternoon. As standard in the Arrow-Debreu paradigm, the household’s uncertainty is subsumed in her preferences:
it is as if the household faces no uncertainty, likes all the varieties of the afternoon good, and happens to have the
preferences deﬁned above. By the same token, because the Arrow-Debreu structure permits each agent to make
her purchase of each variety of the afternoon good contingent on the realization of her idiosyncratic uncertainty, her
budget can be expressed as follows:

pm ci + ρ

(

p∗m c∗i,m

+

cni,m

)

∫
+ (1 − ρ)

(

)
p∗m′ c∗i,m′ + cni,m′ dm′ = yi ,

where yi = ei (θ) + Π and where Π are the total proﬁts in the economy.
15 To

set up the present variant, we momentarily revert to the interpretation of the variables prior to log-linearization.

15

We make similar assumptions on the production side. Each ﬁrm can produce a single variety of the morning good
and a single variety of the afternoon good; knows a priori the morning variety; and faces idiosyncratic uncertainty about
the afternoon variety. Consider a ﬁrm i that produces variety m of the morning good. It produces variety m′ = m
of the afternoon good with probability ρ ∈ [0, 1); and with the remaining probability, the variety she can produce is
drawn from uniform distribution over [0, 1]. It follows that the ﬁrm’s expected proﬁt is given by

{
}
∗
∗
pm qi + ρ p∗m qi,m
− Γ(qi , qi,m
, θm ) + (1 − ρ)

∫

[ ∗ ∗
]
∗
′
pm′ qi,m′ − Γ(qi , qi,m
′ , θm′ ) dm ,

∗
′
where qi,m
′ is ﬁrm i’s production of the afternoon good if she can produce variety m in the afternoon.

It is straightforward to show that the variant described above gives rise to the same equilibrium prices and quantities
as our frictionless benchmark. The only difference is the following: what used to be forward-looking price conjectures
in that benchmark have been recast as actual prices in the present variant. By the same token, what was a dynamic
GE effect in the former has been recast as a static GE effect in the latter.

4.4

Remarks

Remark 1. In general, the distinction between PE and GE can be blurry. This is due to the intrinsic ambiguity of what
“partial equilibrium” means: this notion permits the analyst to hold constant some of the endogenous outcomes of a
model, but does not tell the analyst which outcomes to hold constant and which ones to let adjust. Our framework
seeks to offer some guidance on how one may approach this delicate choice in applications by tying the PE effect
with the equilibrium adjustment that takes place in markets that the agents currently participate in (equivalently, with
the response of prices and quantities that the agents can observe) and the GE effect with additional adjustment that
operates through more “remote” market interactions (“remote” could refer to distance in terms of geography, time,
or knowledge). Having said that, these ideas can be made sufﬁciently concrete only once one commits to a speciﬁc
application; see Section 9 for some examples.
Remark 2. If one takes the view that any given agent can engage in a single market interaction at any given instant
of time, then all GE effects are of a dynamic nature and are tied to expectations. This perspective explains our choice to
equate the GE effects that operate across marketplaces to a certain kind of expectations. But as we have just illustrated,
these expectations need not play an essential role under the frictionless benchmark: in that benchmark, it is as if all
interactions happen at once, in which case expectations are inactive and all GE effects are static.
Remark 3. Our frictionless benchmark is akin to assuming that all agents can get together in the same room and
can perfectly and instantaneously coordinate both their current and their future reaction to the underlying aggregate
shock. Here, this point was formalized by showing that our benchmark attains the same outcomes as an Arrow-Debreu
variant that leaves no room for either dynamics or expectations. Later on, we will further corroborate the same idea
by showing that our frictionless benchmark is akin to a static, complete-information, game in which players face no
uncertainty about one another’s actions. This limitation is endemic to the Arrow-Debreu framework.
Remark 4. The modeling practice in applied work in macroeconomics, ﬁnance, structural IO, and elsewhere
customarily departs from the Arrow-Debreu framework by allowing for monopoly power, ﬁnancial frictions, and the
like. Yet, by imposing the REE concept along with common knowledge of aggregate (economy- or industry-wide)
shocks, the vast majority of such work preserves the aforementioned kind of frictionless coordination in the adjustment
of beliefs, quantities, and prices to such shocks. By contrast, what we are after in this paper is precisely the introduction
of a certain friction in this kind of adjustment, a friction that can be interpreted as attenuating the relevant GE effects.
Remark 5. It is often appealing to abstract from the fact that most real-world trading is sequential and, instead,
represent the economy with a static model. In such models, one can still tie GE effects to expectations by letting each

16

household or ﬁrm have multiple selves, each of which engages in one market interaction and must forecast the choices
of other shelves. Think of this as a “big family” or a “team problem”: every member of the family/team makes a choice
that contributes towards a common goal, without necessarily having knowledge of the choices of other members.16
Remark 6. When an analyst uses a model to form predictions about the response of economic outcomes to
preference and technology shocks or to policy changes, she is of course aware that these predictions are sensitive to
the assumptions made. This sensitivity is not terribly bothering if the predictions are “unbiased” in the sense that a
perturbation of the underlying assumptions can change the predictions in either direction. As an example, consider the
predictions made by assuming a Cobb-Douglas utility and production function; these predictions are in the “middle” of
the set of the predictions that obtain with a relaxed, CES, speciﬁcation for preferences and technologies. Unfortunately,
this is not the case with the assumption of common knowledge: we will show that the predictions that are made on
the basis of this assumption are “biased” in the sense that they necessarily overstate the relevant GE effect relative to
the alternative of allowing for imperfect common knowledge.

5

Cognitive Tâtonnement

In the frictionless benchmark, the agents in each marketplace form rational expectations about the outcomes in other
marketplaces and, equivalently, about p̄∗ . Our ﬁrst variant allows the agents to make irrational conjectures about p̄∗ .
These conjectures, however, are not entirely arbitrary. Instead, they are the product of an algorithm that resembles
Tâtonnement dynamics. Relative to the traditional version of this concept, the twist here is that there are no actual
dynamics; instead, we are merely replacing rational expectations with another instantaneous cognitive process, which
happens to be deﬁned by the solution to a certain differential equation as opposed to the REE ﬁxed point.
Let us elaborate. The assumed algorithm consists of multiple rounds of making an initial conjecture about p̄∗ ,
calculating the implied imbalance in the market for afternoon goods, and subsequently updating the original conjecture
in the direction that helps reduce the imbalance. We index the rounds by t, treat t as a continuous variable, and
denote with T ∈ (0, ∞) the ﬁnal round, that is, the point at which the guess-and-update iterations stop and actual
behavior gets determined. Although it may be more natural to think of “rounds” as a discrete variable, letting t be a
continuous variable is consistent with existing treatments of Tâtonnement dynamics; see, e.g., Section 17.H in MasCollell, Whinston, and Green (1995). For our purposes, the advantage of treating t as a continuous variable is to let
the price conjecture p̂∗ be a continuous function of T.
Deﬁnition 1. Fix a T ∈ (0, ∞). The Tâtonnement solution is given by a conjecture p̂∗ and by realized outcomes
∗
(qm , pm , qm
, p∗m ) for every m such that the following hold:

(i) The aforementioned outcomes satisfy Lemmas 2 and 3, with Êm [p̄∗ ] = p̂∗ for all m.
(ii) p̂∗ is given by p̂∗ = P̂ ∗ (T ), where the function P̂ ∗ is obtained by solving the following ODE:

(
)
dP̂ ∗ (t)
= N P̂ ∗ (t), θ̄new
dt

∀t ≥ 0,

(18)

(
)
( (
)
)
with initial condition P̂ ∗ (0) = p̄∗old ≡ P(θ̄old ), where N p̂∗ , θ̄ = N ∗ Q p̂∗ , θ̄ , p̂∗ , θ̄ is the net aggregate demand for
afternoon goods if its average price is p̂∗ .17
Part (i) is equivalent to imposing Assumptions 1–4 along with the additional restriction that the subjective belief
of p̄∗ is the same across all marketplaces. Part (ii) then speciﬁes this belief as the product of the following iterative
procedure. An initial conjecture is formed at round t = 0 by letting p̂∗ (0) coincide with p̄∗old , the pre-shock equilibrium
16 See

17 The

Angeletos and Lian (2016c) for an application along these lines.
function P is the same as that obtained in condition 16.

17

price. Using this conjecture, the agent computes the implied aggregate demand and supply for afternoon goods and
subsequently adjusts her conjecture as follows: if the excess demand is positive, the conjecture is adjusted upwards;
if, instead, the excess demand is negative, the conjecture is adjusted downwards. The same updating procedure is
applied at all t ∈ (0, T ). At t = T, the updating terminates, generating the ﬁnal conjecture, p̂∗ = P̂ ∗ (T ), upon which
the actual behavior is based.
In Section 8, we develop a variant model that allows the relevant economic decisions to be repeated over many
periods. In that variant, every period other than the very ﬁrst one serves as the “afternoon” vis-a-vis the previous period.
By the same token, the outcomes in any given period depend on a price conjecture about the next period. This permits
us to map the passage of calendar time to an increase in the parameter T that shows up in the above deﬁnition and,
in this sense, give a real-time interpretation to the cognitive procedure. For the present purposes, however, we opt to
interpret a higher T as a higher “depth of reasoning”.18
In the rest of this section, we characterize the price conjecture and the outcomes that obtain when the REE concept
is replaced with the solution concept proposed in Deﬁnition 1. We then show how this attenuates the GE adjustment
relative to our frictionless benchmark, thus also helping reduce the gap between the micro and the macro elasticities.
Consider the price conjecture p̂∗ . Under Assumption 5, which means that T is contraction mapping,19 the assumption that N ∗ is decreasing in p∗ guarantees that N is also decreasing in p∗ . It follows that the solution to the ODE that
(
)
appears in Deﬁnition 1 is continuous in T and converges monotonically to the value of p∗ that solves N p∗ , θ̄new = 0.
And because this value coincides with the post-shock frictionless equilibrium price, the following is true.
Lemma 4. There exists a continuous and strictly increasing function w : [0, +∞) → [0, 1], with w(0) = 0 and
limT →∞ w(T ) = 1, such that, for any T and any ∆θ̄, the conjecture p̂∗ satisﬁes

p̂∗ = p̄∗old + w(T ) (p̄∗new − p̄∗old ) ,

(19)

where p̄∗old ≡ P(θ̄old ), p̄∗new ≡ P(θ̄new ), and θ̄new ≡ θ̄old + ∆θ̄.
Because w(T ) is bounded between 0 and 1, we have that the conjecture p̂∗ adjusts less to the underlying shock
than the rational expectation of p̄∗ does in the frictionless benchmark.20 It is in this sense that the GE adjustment is
attenuated. Furthermore, by varying T , we can let the conjecture p̂∗ span the entire interval between p̄∗old and p̄∗new ,
that is, we can span the entire adjustment that happens in p̄∗ in the REE benchmark. Furthermore, the higher T is, the
closer the conjecture is to the post-equilibrium price. Given the proposed interpretation of T as “depth of reasoning”,
we have that deeper reasoning maps to a smaller error relative to the REE benchmark.
The property that the Tâtonnement conjecture p̂∗ adjusts less to the underlying shock than the frictionless counterpart is not surprising. It is, however, instrumental to the broader theme of our paper. In Section 7, we discuss why this
property may not be shared by a few other plausible kinds of bounded rationality. In the next section, on the other
hand, we show how essentially the same property can be rationalized in a variant that preserves the REE concept but
removes common knowledge of the shock. Together with the results of Section 8, this facilitates the interpretation of
our preferred approach—lack of common knowledge—as a rationalization of the older idea that GE adjustment may
be “weak” in the short run.
It is also worth noting the following two points. First, the result depends on the excess demand for the afternoon
good being decreasing in its price. Without this property, the distance between the conjecture p̂∗ and its REE counterpart would actually increase without bound as T increases. In the literature, this issue is known as “Tâtonnement
18 This

hints at a connection to the concept of Level-k Thinking in games; we explore this connection is Section 7.
speaking, the weaker assumption α < 1 sufﬁces for all the results of this section.
20 Recall our earlier remark about the possibility of allowing for innovations in the fundamentals to occur between the morning and the afternoon.
In such an extension, P(θ̄) gives, not the realized p̄∗ , but rather its rational expectation in the morning. With this in mind, it is best to interpret p̄∗old
and p̄∗new as the frictionless values of the rational expectation of p̄∗ .
19 Strictly

18

stability” and is tied to the gross substitutability of goods.21 Second, the result depends on treating the rounds of
the Tâtonnement process as a continuous rather than a discrete variable in the following regard. Under the adopted
speciﬁcation, the following properties are true regardless of the precise slope of N : (i) by varying T in R+ , we can let

p̂∗ span the entire interval between p̄∗old and p̄∗new ; (ii) p̂∗ can never fall outside this interval; (iii) p̂∗ converges monotonically to p̄∗new as T → ∞. If instead we had let t be discrete, these properties would not necessarily hold: we would
have to restrict the slope of N and/or modify the speed of the Tâtonnement process.22
Consider now the observable outcomes that obtain on the basis of the conjecture characterized in Lemma 4. By
Lemma 3, we have that, for every m,

qm = Q (p̂∗ , θm ) .

(20)

That is, the morning quantities are determined in the same fashion as in our frictionless REE benchmark, except for
the fact that the rational expectation E [p̄∗ ] has been replaced with the Tâtonnement-based conjecture p̂∗ . By direct
(
)
∫
implication, the aggregate output of morning goods can be expressed as q̄ ≡ qm dm = Q p̂∗ , θ̄ ; and because of the
linearity of Q, the change in q̄ triggered by the aggregate shock can be expressed as

∆q̄

=

∂Q
∂Q
∆θ̄ + ∗ (p̂∗ − p̄∗old ) .
∂θ
∂p

(21)

Using the above property together with Lemma 4, we arrive at the following result.
Proposition 3 (Tâtonnement). For every T, there exists a scalar ϵT ât (T ) such that, for any realization ∆θ̄ of the aggregate
shock, the corresponding change in q̄ that obtains along the Tâtonnement(T ) solution is given by

∆q̄ = ϵT ât (T )∆θ̄.
Furthermore,

(
)
ϵT ât (T ) = ϵmicro + w(T ) ϵM acro − ϵmicro ,

(22)

where ϵmicro and ϵM acro are the same objects as in Section 4 and where w is the same function as the one in Lemma
4 (hence, w is continuous and strictly increasing in T, with w(0) = 0 and w(∞) ≡ limT →∞ w(T ) = 1).
In short, ϵT ât (T ) identiﬁes the macro elasticity of the Tâtonnement economy in which the depth of reasoning is

T . This elasticity is arbitrarily close to the underlying micro elasticity when T is low enough,23 but gets closer and
closer to the macro elasticity of the frictionless REE benchmark as T increases. This reﬂects the fact that, by design,
the Tâtonnement process helps arrest the GE adjustment that is present in that benchmark. Formally, using Lemma 4,
the GE effect of the modiﬁed economy can itself be expressed as

GET ât (T ) ≡
where GE ≡

∂Q ∂P
∂p∗ ∂θ

∂Q p̂∗ − p̄∗old
= w(T )GE,
∂p∗
∆θ̄

( M acro
)
=ϵ
− ϵmicro is the GE effect of the frictionless benchmark and where w(T ) is the afore-

mentioned function. Accordingly, the fact that w(T ) ∈ (0, 1) for all T > 0 formalizes the notion that GE adjustment
is “incomplete”, or that it is “weakened” by the considered relaxation of the solution concept; and the fact that w(T )
increases with T can be interpreted as the property that a larger GE adjustment requires “deeper reasoning.”
We illustrate these points with the help of Figure 2. In the frictionless benchmark, the effect of the aggregate shock
is represented by the shift from point X to point Z . Furthermore, this shift can be decomposed to a PE adjustment,
21 See,

e.g., Proposition 17.H.1 in Mas-Collell, Whinston, and Green (1995).
this we mean letting P̂ ∗ (t + 1) − P̂ ∗ (t) = b(t)N (P̂ ∗ (t), θ̄new ) for an appropriately chosen b : N → R+ .
23 The micro elasticity is the same in the two economies, for they both impose individual rationality and market clearing at the local level.
22 By

19

captured by the shift from X to Y, and a GE adjustment, captured by the shift from Y to Z. With the considered
modiﬁcation, the PE adjustment remains the same, but the GE adjustment is cut short: the economy moves to an
intermediate point along the segment between Y and Z. The smaller T is, the closer to Y the economy is.
Remark. By treating the Tâtonnement dynamics as a cognitive process that takes place within a ﬁxed moment
in time, we have formalized the notion that the GE adjustment is “incomplete” or “weak” while abstracting from
dynamics. In Section 8, we describe a multi-period extension in which additional rounds require more time. It is
then as if the economy moves slowly from point Y to point Z with the passage of time, helping accommodate the
complementary notion that GE adjustment “takes time.” Importantly, this mechanism is unlike the one associated
with adjustment costs in technologies or preferences: such features modify the underlying PE adjustment and manifest
as slow movement from point X to point Y . By contrast, the mechanism we document explains partial or slow GE
adjustment, even if the underlying PE adjustment is complete and instantaneous.

6

Removing Common Knowledge

The preceding analysis offered a simple, and logically coherent, formalization of the desired notion. This formalization, however, built on old-fashioned ideas about “off equilibrium” adjustment, which ﬁnd little place in modern
methodology. It also required a violation of rational expectations, raising delicate methodological issues, some of
which we touch on in Section 9.
We now show how the desired result can be obtained without the aforementioned caveats, by bringing back the
REE concept, removing common knowledge of the aggregate shock, and accommodating higher-order uncertainty
(i.e., uncertainty about the beliefs and the actions of others). In so doing, we not only provide a rationalization of the
GE attenuation documented in the previous section, but also help address the following elementary question:
Suppose that the analyst knows the structure of the economy.24 Suppose further that the analyst knows
the agents in the economy form rational expectations, but does not know what information, or beliefs, the
agents have about markets they do not currently participate in. What predictions can the analyst make
about the REE outcomes of the economy?
This question clariﬁes what we are after in this section. We are not interested in higher-order uncertainty per se.
Rather, we offer a reconsideration of what the REE concept “truly” predicts—where “truly” means without the use of
strong, albeit conventional, assumptions regarding what the agents know about the behavior of other agents.25
From this perspective, the key ﬁnding of this section is that (the absolute size of) the GE effect predicted by imposing
common knowledge of the shock is an upper bound of the GE effect that is predicted when this assumption is relaxed.
In short, imposing common knowledge is akin to “maximizing” the potency of the GE effect.

6.1

The Assumed Friction and its Possible Interpretations

The economy considered in this section shares the same primitives (preferences and technologies) as the frictionless
benchmark studied in Section 4. Unlike that benchmark, however, the present variant lets the agents have incomplete
(i.e., noisy and heterogeneous) information about the underlying aggregate shock.
Deﬁnition 2. The incomplete-information solution is given by the REE of the economy in which the following is true:
for each marketplace m, the information that the agents have in the morning about the underlying shock is summarized
24 By

this we mean that the analyst knows (U, Γ, e, ρ), the associated demand and supply functions, and the validity of Assumptions 1–5.
remark echoes related points from Angeletos and La’O (2013), Angeletos and Lian (2016b), and Bergemann and Morris (2013): accommodating higher-order uncertainty in macroeconomic models helps uncover the “true” or “robust” observable properties these models.
25 This

20

in a sufﬁcient statistic sm given by

sm = ∆θ̄ + vm ,
where vm is an idiosyncratic noise term, drawn from a Normal distribution with mean zero and variance σv2 , i.i.d.
across marketplaces, and independent of ∆θ̄.26
The assumed signal structure may appear to be restrictive. We explain why this appearance is deceptive in Appendix C. There, we build on the results of Bergemann and Morris (2013) and sketch how the analysis can be extended
to a more general speciﬁcation that allows each marketplace to observe a rich set of private and public signals about
either the underlying aggregate shock or the response of other marketplaces. The only nuisance is that, because some
the observed signals (e.g. public signals) may subject to aggregate noise, the predictions developed below must be
recast as averages across the realizations of such noise.27
Because information differs across marketplaces, the agents in one marketplace do not know what the agents in
other marketplaces know. That is, the agents face higher-order uncertainty about what others believe, about what
others believe that others believe, and so on.
Such higher-order uncertainty seems to be a natural feature of environments in which market interactions are
geographically segmented. But it can also be the symptom of cognitive constraints: in line with Tirole (2015) and
others, the private signal we have assumed above can be a representation of “cognitive states”, or of the coarse, and
idiosyncratic, understanding that the agents may have about what is going on in the economy.
This interpretation gives a behavioral twist to the present setting. It also builds a bridge to the bounded-rationality
variants considered in Section 7. There is, however, a crucial difference: in the present setting, there is no systematic
discrepancy between “reality” and the agents’ perceptions of it (i.e., between actual outcomes and beliefs). This is
because the cognitive friction is modeled as incomplete information rather than as a departure from REE.
The same point applies if we recast the aforementioned signal as the product of the kinds of “rational inattention”
considered in Sims (2003), Mackowiak and Wiederholt (2009), Myatt and Wallace (2012), and Pavan (2016). One
caveat is that these interpretations invite one to endogenize the signal structure. Such endogeneity would interfere
with the comparative statics conducted in Proposition 6, but would not affect any other result: the attenuation effect
we document in this section depends only on information being incomplete, not on it being exogenous.
Regardless of whether one interprets the assumed friction as the product of the geographic segmentation of the
market mechanism or of the cognitive limitations of the agents, the property that matters for our purposes is the resulting
anchoring of higher-order beliefs. To illustrate this property, let Ē h [.] denote that h-th order average-expectation
∫
∫
operator; this is deﬁned recursively by Ē 1 [·] ≡ Ē[·] ≡ Em [·]dm and Ē h [·] ≡ Em [Ē h−1 [·]]dm for all h ≥ 2, where

Em [·] is the rational expectation held in marketplace m during the morning. For every m, Em [∆θ̄] = λsm , where
λ=

1
∈ (0, 1].
1 + (σv2 /σθ2 )

(23)

By aggregating and iterating, we infer that, for all h ≥ 1, Ē h [∆θ̄] = λh ∆θ̄; equivalently,

Ē h [θ̄] = θ̄old + λh ∆θ̄.

(24)

It follows that, whenever λ < 1, higher-order beliefs are anchored in the sense that they move less than lower-order
beliefs for any given innovation in the fundamentals. Furthermore, this anchoring is stronger when λ is lower.
26 Keep in mind that ∆θ̄ is itself drawn from a Normal distribution with mean zero and variance σ 2 . Also, the signal s
m is meant to be a sufﬁcient
θ
statistic for all the information that marketplace m possess about θ̄ ; it therefore encompasses the information contained in the observation of θm .
27 In particular, the macro elasticity is now given by the slope of E[∆q̄|∆θ̄] with respect to ∆θ̄ , which is fully consistent with the deﬁnition of an
IRF in dynamic settings.

21

The distance of λ from 1 can thus be interpreted as a measure of the departure from common knowledge (with
the frictionless benchmark nested at λ = 1). By varying σv in [0, +∞), we can let λ span the interval (0, 1]. Finally,
following our earlier remark, Appendix C shows how the predicted response of the economy to ∆θ̄ under a richer
information structure can be mapped to the one characterized here for some λ ∈ (0, 1]. With these points in mind,
we henceforth treat λ as a ﬁxed parameter and proceed to characterize the REE outcomes as functions of λ.

6.2

Equilibrium Characterization

Let Em [p̄∗ ] denote the rational expectation that agents in marketplace m form about p̄∗ in the morning, based on the
local knowledge of si . By Lemma 3, we have that, for all m,

qm = Q (Em [p̄∗ ] , θm )

and

pm = P (Em [p̄∗ ] , θm ) .

(25)

That is, the morning outcomes are determined in the same fashion as in our frictionless benchmark, except that the
common rational expectation E[p̄∗ ] is replaced by the local rational expectation Em [p̄∗ ]. At ﬁrst glance, this may appear
to be an innocuous change. This is indeed the case insofar as one is concerned with the partial-equilibrium predictions
of the theory: as we move between the frictionless benchmark and the present variant, we vary the information upon
which the rational expectations of p̄∗ are formed, but do not vary how qm and pm respond either to these expectations
or to the local fundamentals. Yet, as we show next, the two economies make different general-equilibrium predictions
and, as a result, feature different gaps between the micro and the macro elasticities.
The aggregate quantity of the morning goods can now be expressed as follows:

∫
q̄ ≡
where Ē[p̄∗ ] ≡

∫

qm dm = Q(Ē[p̄∗ ], θ̄)

(26)

Em [p̄∗ ] dm is the average belief of p̄∗ in the cross-section of markets. To characterize how q̄ responds

to the change in the fundamentals, we therefore need to characterize how this average belief responds. And because
agents have rational expectations, this means that we need to characterize the ﬁxed-point relation between the average
belief Ē[p̄∗ ] and the actual p̄∗ . This is similar to our frictionless benchmark, except for the following difference: because
agents do not share the same information about aggregate economic conditions, this ﬁxed-point relation turns out to
be more “delicate” than before.
Let us elaborate. First, consider how demand and supply are determined in the afternoon markets. At this stage,
the quantities of the morning goods are predetermined. By Lemma 2, the afternoon prices satisfy

p̄∗ = P ∗ (q̄, θ̄),

(27)

where P ∗ is deﬁned as in condition (7). Replacing q̄ by (26), we get the following ﬁxed-point relation between the
realized value of p̄∗ and the average expectation of it in the morning:

)
(
p̄∗ = T Ē[p̄∗ ], θ̄ ,

(28)

where T is the same mapping as before. Taking expectations on both sides, we then obtain the following result.
Lemma 5. The following ﬁxed-point relation holds in equilibrium:

)
(
Ē[p̄∗ ] = T Ē 2 [p̄∗ ], Ē[θ̄] .

22

(29)

We can now see that, although the REE can still be understood as a ﬁxed point, the precise nature of this ﬁxed point
hinges on whether the underlying shock is common knowledge or not. Contrast the above condition to condition (14)
¯ p̄∗ , or any other variable coobtained in the frictionless benchmark. In that benchmark, the higher-order beliefs of θ,
incide with the corresponding ﬁrst-order beliefs, because all agents shared the same information. Condition (29) then
reduces to condition (29), which clariﬁes how the result above nests the result obtained in the frictionless benchmark.
But now note that, once we remove common knowledge of θ̄, higher-order beliefs can diverge from ﬁrst-order beliefs.
Furthermore, because realized prices depend on fundamentals and ﬁrst-order beliefs of prices, the latter depend on
ﬁrst-order beliefs of fundamentals and second-order beliefs of prices, which is what condition (29) states.
Iterating this condition forward, and using the fact that T is a contraction mapping, we obtain the following characterization of the equilibrium value of Ē [p̄∗ ].
Corollary 2. In equilibrium, the average rational expectation of p̄∗ is determined by the hierarchy of beliefs about the
underlying fundamentals:

Ē [p̄∗ ] = γ(1 − α)

∞
∑

[ ]
αh−1 Ē h θ̄ ,

(30)

h=1

where α ∈ (−1, +1) is deﬁned as in condition (15) and where γ ≡

∂P
∂θ

is the slope of Ē[p̄∗ ] with respect to θ̄ in the

frictionless benchmark.
Modeling the rational expectations of the endogenous future prices is therefore equivalent to modeling the hierarchy
of beliefs of the exogenous fundamentals. By assuming common knowledge of the latter, the standard practice forces
higher-order beliefs to collapse to ﬁrst-order beliefs. This may be convenient, but it is neither realistic nor innocuous:
it imposes a very tight structure on the stochastic nature and the observable implications of the REE solution. We next
show that relaxing this tight structure by allowing for lack of common knowledge of the underlying shock gives rise to
a similar GE attenuation effect as the Tâtonnement modiﬁcation studied in the previous section.
Remark 1. Lemma 5 and Corollary 2 are robust to the introduction of unpredictable innovations in the aggregate
fundamentals between the morning and the afternoon. In the presence of such shocks, condition (28) has to be
(
)
replaced with p̄∗ = T Ē[p̄∗ ], θ̄ + ε, where ε captures these shocks. But since these shocks are unpredictable in the
morning, conditions (29) and (30) remains valid. This echoes the related point we made in the frictionless benchmark.
Remark 2. Corollary 2 represents the rational expectations of p̄ as a function of both the ﬁrst- and the higherorder beliefs of the underlying payoff-relevant fundamentals. However, the presence of ﬁrst-order beliefs in this result
is largely an artifact of the assumption that the agents in each marketplace have perfect knowledge of their own
fundamentals. Suppose, instead, that, for all m, θm is imperfectly known in marketplace m; let ϑm ≡ Em [θm ] denote
the local ﬁrst-order belief of the local fundamental; and ﬁnally let ∂P ∗ /∂θ = 0, which means that p̄∗ is pinned down by
∫
∫
q̄ alone. Then, Corollary 2 continues to hold provided we replace θ̄ with ϑ̄ ≡ ϑm dm = Em [θm ]dm. But since the
ﬁrst-order beliefs of ϑ̄ are the second-order beliefs of the underlying payoff-relevant fundamentals, it is now only beliefs
of order two and higher that matter for the rational expectations of p̄. This underscores the central role of higher-order
beliefs in the effects we document in the sequel.
Remark 3. To understand the nature of the REE outcomes of our Walrasian economy, it has proved useful to
represent the rational expectations of p̄∗ as a function of the belief hierarchy of θ̄. To achieve this representation, we
iterated on the mapping T . This is akin to relating the Bayesian Nash Equilibrium of an incomplete-information game
to its rationalizable outcomes. Note, however, that neither the REE concept in Walrasian economies nor the BNE
concept in games require the agents to engage in higher-order reasoning: all that is required is a ﬁxed-point relation
between expectations and realized outcomes. From this perspective, what we do throughout this section is merely to
characterize this ﬁxed point for an appropriately rich set of information structures.
23

6.3

Lack of Common Knowledge as GE Attenuation

By combining Corollary 2 with our earlier characterization of the hierarchy of beliefs, we reach the following characterization of the post-shock rational expectation of p̄∗ .
Lemma 6. In the unique REE of the economy,

Ē [p̄∗ ] = p̄∗old + π(λ) (p̄∗new − p̄∗old )

(31)

where p̄∗old ≡ P(θ̄old ), p̄∗new ≡ P(θ̄new ), and the function π is continuous and strictly increasing in λ, with π(0) = 0
and π(1) = 1.
By varying λ, we can thus let the post-shock rational expectation in the modiﬁed economy take any value in
the range between the corresponding pre- and post-shock values in the frictionless benchmark. This formalizes the
following basic point, which we mentioned in the introduction: the rational expectations hypothesis alone predicts an
interval of possible price conjectures; and the standard practice of imposing common knowledge of the shock (λ = 1)
picks the upper bound of this interval.
Using Lemma 6 together with the fact that q̄ = Q(Ē[p̄∗ ], θ̄), we reach the following result, which formalizes the
sense in which the assumed friction bridges the gap between the relevant micro and macro elasticities.
Proposition 4 (Lack of Common Knowledge). For any λ, there exists a scalar ϵInc (λ) such that, for any realization ∆θ̄
of the aggregate shock, the corresponding change in q̄ is given by

∆q̄ = ϵInc (λ)∆θ̄
Furthermore,

(
)
ϵInc (λ) = ϵmicro + π(λ) ϵM acro − ϵmicro ,

(32)

where ϵmicro and ϵM acro are the same objects as those found in Proposition 2 and π is the same function as that found
in Lemma 6.
Recall that π is continuous and strictly increasing in λ, with π(0) = 0 and π(1) = 1. By varying λ between 0 and 1,
we can thus span all the values between ϵmicro and ϵM acro . For λ close to zero (meaning a sufﬁciently large departure
from common knowledge), the macro elasticity of the modiﬁed model is arbitrarily close to the micro elasticity of
the original model. But as λ increases (meaning a higher degree of common knowledge), the macro elasticity of the
modiﬁed model gets closer and closer to the macro elasticity of the original model. Importantly, all these properties
hold true no matter whether ϵM acro is higher or lower than ϵmicro . We conclude that varying the degree of common
knowledge is akin to varying the extent to which the GE effect is active, regardless of whether this effect ampliﬁes or
offsets the underlying PE effect.
The following is then an immediate corollary of Propositions 3 and 4.
Corollary 3. (i) For any Tâtonnement economy with depth T ∈ (0, ∞), there exists an incomplete-information economy with common-knowledge degree λ ∈ (0, 1) such that, for any realization of ∆θ̄, the average rational expectation

Ē [p̄∗ ] in the latter coincides with the conjecture p̂∗ in the former, and the two economies predict the same observable
change in q̄. (ii) The converse is also true.
This equivalence pegs the following question: is there a reason to prefer the one approach over the other? This
depends on how much one values rational expectations. We postpone a further discussion of this issue to Section 9.

24

Remark. The intuitions developed in this section rely on the fact that the REE can be understood as the limit
of iterating on the mapping T . To make sure that this limit exists, we required that T be a contraction mapping or,
equivalently, that α ∈ (−1, 1). As explained in the sequel, this means that the REE of our Walrasian economy is also the
unique dominance-solvable outcome of a certain game—a property that lends conﬁdence to the obtained predictions.
That said, the results presented above (Lemma 6, Proposition 3, and Corollary 4) extend to α ≤ −1 : in this case, the
REE is not dominance-solvable, yet it remains unique and continues to exhibit the propertied discussed above.

6.4

Two Additional Results

We conclude this section with two additional results. The ﬁrst tightens the game-theoretic interpretation of our results.
The second sheds additional light on the GE attenuation we have documented in this section.
Proposition 5. (i) There exists a linear function BR such that, for all realizations of uncertainty and all m, the equilibrium
value of qm satisﬁes

(
)
qm = BR θm , Em [θ̄], Em [q̄] .

(33)

(
)
(ii) If q̄ = BR θ̄, Ē[θ̄], Ē[q̄] and p̄∗ = P ∗ (q̄, θ̄), then p̄∗ = T (Ē[p̄∗ ], θ̄); and conversely, if p̄∗ = T (Ē[p̄∗ ], θ̄) and
(
)
q̄ = Q(Ē[p̄∗ ], θ̄), then q̄ = BR θ̄, Ē[θ̄], Ē[q̄] .
(iii) The slope of BR with respect to Em [q̄] equals α, the slope of T .
Part (i) states that the quantity qm produced in each market can be expressed as function of θm (which is locally
known), of the local expectation of θ̄, and of local expectation of q̄. Part (ii) states that looking for the ﬁxed point
of these best responses functions is equivalent to looking for the ﬁxed point of T , the function that pins down the
rational expectations of the relevant prices. Together, these results mean that we can recast the incomplete-information
solution of our dynamic Walrasian economy as the unique Bayesian-Nash Equilibrium of a ﬁctitious static game in
which the players are the markets, their actions are the local quantities, and their best response functions are given by
(33). Complementing this interpretation, part (iii) ties α, the slope of the function T whose ﬁxed point pins down the
rational expectations of the relevant price, to the degree of strategic complementarity (if α > 0) or substitutability (if

α < 0) in the aforementioned game.
This game is similar to the class of linear-quadratic beauty-contest games considered in Morris and Shin (2002),
Angeletos and Pavan (2007) and Bergemann and Morris (2013). A minor twist is that the best response depends
on both the beliefs and the actual realization of the underlying fundamentals.28 The restriction that α ∈ (−1, 1)
guarantees that this game admits a unique rationalizable outcome, which itself coincides with the unique REE outcome
of our Walrasian economy. Finally, the magnitude of the strategic complementarity/substitutability in this game can
be connected to the magnitude of the GE effect in our Walrasian economy.
This connection is tightest when p̄∗ depends on θ̄ only through q̄ (i.e., when ∂P ∗ /∂θ = 0). Under this restriction,
it is easy to show that

ϵM acro =

1 micro
ϵ
.
1−α

(34)

The macro and micro elasticities therefore share the same sign regardless of α, but their relative magnitude depends
on α. When α < 0, the ﬁctitious game features strategic substitutability, the GE effect offsets the PE effect, and our
attenuation effect translates to |ϵM acro | < |ϵInc | < |ϵmicro |. When instead α > 0, the ﬁctitious game features strategic
complementarity, the GE effect ampliﬁes the PE effect, and |ϵM acro | > |ϵInc | > |ϵmicro |.
Perhaps more intriguingly, we now show that, when the gap between ϵM acro and ϵmicro is larger, the fraction of this
gap that gets “erased” once one allows lack of common knowledge of the underlying aggregate shock is also larger.
28 To

put it differently, the payoff type of player m in the relevant game is given by the pair (θm , Em [θ̄]).

25

Proposition 6. Suppose ∂P ∗ /∂θ = 0 and ﬁx λ ∈ (0, 1). A higher |α| drives ϵInc /ϵM acro further away from 1. That
is, the same primitives that enhance the GE effect in the frictionless benchmark also strengthen the attenuation of this
effect in the considered variant.
This result follows, in effect, from Corollary 2: by raising the dependence of the equilibrium beliefs of p̄∗ on higherorder beliefs, a stronger GE effect makes these beliefs more anchored to p̄old , thus also raising the attenuation effect
we have formalized in this section.
Remark. The representation of our Walrasian economy as a game rests on our assumptions that markets are
segmented and that information is complete within each market (but not across markets). Without these assumptions,
prices would serve as signals of the simultaneous actions of other players, preventing the desired game-theoretic
representation: in games, players are allowed to observe signals of the past actions of others, but not of simultaneous
actions. That said, the essence would remain the same: even if markets are centralized, prices aggregate dispersed
private information, and agents face no cognitive constraints, common knowledge can still be hard to obtain. See
Allen, Morris, and Postlewaite (1993) for a thoughtful discussion.

7

Variants: Cobweb, Level-k, and Reﬂective Equilibrium

So far, we have shown that (i) dropping the assumption that the aggregate shock is common knowledge predicts a
reduction of the gap between micro and macro elasticities relative to the frictionless benchmark and (ii) this prediction
is shared by a speciﬁc relaxation of the REE concept, one that built on Tâtonnement. Clearly, this prediction need not
be shared by every relaxation of the REE concept.
For instance, consider the form of “near rationality” suggested by Akerlof and Yellen (1985a) or the closely related
concept of “ϵ-equilibrium” (also known as “near-Nash equilibrium”). In games, this concept requires that the action
of each player is “nearly rational” in the sense that it delivers a payoff that is within ϵ of the payoff delivered by the
best-response action, where ϵ > 0 is an exogenous scalar that can be thought of as the degree of bounded rationality.
Adapting this concept to our Walrasian setting boils down to letting the “nearly rational” demand and supply functions
vary around the “fully rational” ones deﬁned in Section 3. As a result, the aggregate change, ∆q̄, triggered by any
given shock can also vary around its frictionless counterpart. It follows the proposed relaxation of the REE concept
does not share the aforementioned prediction: the gap between the micro and macro elasticities can be larger in the
modiﬁed economy than in the frictionless benchmark.
This underscores that the approach we favor in this paper—namely, dropping common knowledge of aggregate
shocks while maintaining the REE concept—imposes a speciﬁc structure on the departure obtained from the frictionless
benchmark. This structure is precisely that the relevant GE effects have to be attenuated.
With this point in mind, we now explore whether this structure is shared by four other possible relaxations of the
REE concept, which build on the following concepts from the literature:
1. Cobweb dynamics, the familiar alternative to Tâtonnement dynamics;
2. Level-k Thinking, a solution concept often used in the experimental literature;
3. Reﬂective Equilibrium, a solution concept proposed in Garcıa-Schmidt and Woodford (2015); and
4. The kind of “cognitive discounting” featured in Gabaix (2016a,b).
In all these variants, we preserve the demand and supply system of the frictionless benchmark, as well as its partialequilibrium predictions. We nevertheless modify the general-equilibrium adjustment to aggregate shocks by letting
the agents act on the basis of certain kinds of irrational conjectures about how aggregate outcomes react to these
26

shocks. In this regard, the new variants are similar to the Tâtonnement variant studied in Section 5. The difference is
in the exact cognitive process that pins down the relevant price and/or quantity conjectures.
We ﬁrst show that the variants that are based on Cobweb dynamics and Level-k Thinking are tightly connected
with each other, but not necessarily with our earlier variants: in certain cases, the new variants predict that the relevant
price or quantity conjectures can overshoot relative to the frictionless benchmark, which in turn means that the GE
effects get ampliﬁed instead of being attenuated. We next show that, despite being a close cousin of Level-k Thinking,
the solution concept proposed by Garcıa-Schmidt and Woodford (2015) avoids the aforementioned “overshooting”
problem and ends up delivering similar predictions as our Tâtonnement and incomplete-information variants. We
ﬁnally discuss how Greenwood and Hanson (2015) and Gabaix (2016a,b) capture the desired effect by design.

7.1

Cobweb

A familiar alternative to the notion of Tâtonnement dynamics is that of Cobweb dynamics. Similarly to how we
treated the former in Section 5, here we recast the latter as an instantaneous cognitive process, whose outcome is a
price conjecture p̂∗ upon which the agents act and the morning markets clear.

( k−1 ∗
)
0 ∗
∗
k ∗
Deﬁne {T k }∞
(p , θ), θ for all (p∗ , θ) and all
k=0 recursively by letting T (p , θ) ≡ p and T (p , θ) ≡ T T

k ∈ {1, 2, ...}. The new solution concept can then be stated as follows.
Deﬁnition 3. Fix a k ∈ {0, 1, 2...}. The Cobweb(k ) solution is given by a conjecture p̂∗ and by realized outcomes
∗
(qm , pm , qm
, p∗m ) for every m such that the following hold:

(i) The aforementioned outcomes satisfy Lemmas 2 and 3, with Êm [p̄∗ ] = p̂∗ for all m.
(ii) The conjecture p̂∗ is given by

p̂∗ = T k (p̂∗0 , θ̄new ),

(35)

where p̂∗0 = p̄∗old ≡ P(θ̄old ).
The only difference form Deﬁnition 1 (our version of Tâtonnement) is the condition that pins down the conjecture

p̂ , namely condition (35) above. When k = 0, this condition gives p̂∗ = p̂∗0 = p̄∗old , meaning that agents behave under
∗

the conjecture that the average afternoon price will stay at its the pre-shock equilibrium level. Consider next k = 1.
Now any given agent realizes that, if other agents behave under the aforementioned conjecture, the aggregate quantity
(
)
in the morning will be q̄ = q̄0 ≡ Q(p̂∗0 , θ̄new ) and the afternoon markets will therefore clear with p̄∗ = P ∗ q̄0 , θ̄new =

T (p̂∗0 , θ̄new ). On the basis of this argument, the initial conjecture is updated from p̂ = p̂∗0 to p̂ = p̂∗1 ≡ T (p̂∗0 , θ̄new ). By
induction, the conjecture at an arbitrary round k is given by p̂∗ = p̂∗k ≡ T (p̂∗k−1 , θ̄new ) = T k (p̂∗0 , θ̄new ).
As evident in condition (5), considering a higher k maps to iterating more times on T . Because T is a contraction
mapping, we know that p̂∗k → p̄∗new as k → ∞. That is, the Cobweb process shares with the Tâtonnement process
that the price conjecture converges to the post-shock equilibrium price as the “depth of reasoning” increases without
bound. Unlike the Tâtonnement variant, however, this convergence need not be monotonic and the price conjecture
may fall outside the range between the pre- and the post-shock equilibrium price.
Lemma 7. There exists a sequence {gk }, with g0 = 0 and limk→∞ gk = 1, such that the following properties hold:
(i) For any k and any ∆θ̄, the conjecture p̂∗k satisﬁes

p̂∗k = p̄∗old + gk (p̄∗new − p̄∗old ) .
(ii) If α > 0, the sequence is strictly increasing and bounded between 0 and 1.
(iii) If instead α < 0, this sequence is non-monotone, with gk < 1 when k is even and gk > 1 when k is odd.

27

The price conjecture therefore falls inside the interval between p̄∗old and p̄∗new insofar as the economy features α > 0.
But if α < 0, the price conjecture can “overshoot” outside this interval. When this happens, the GE effect is ampliﬁed,
instead of being attenuated, relative to the frictionless benchmark. By the same token, the impact of the shock on q̄
can fall outside the interval deﬁned by the micro and macro elasticities of the frictionless benchmark.
Proposition 7 (Cobweb). For any k, there exists a scalar ϵCob (k) such that, for any realization ∆θ̄ of the aggregate
shock, the corresponding change in the value of q̄ that obtains in the Cobweb(k ) solution is given by

∆q̄ = ϵCob (k)∆θ̄
Furthermore,

(
)
ϵCob (k) = ϵmicro + gk ϵM acro − ϵmicro ,

(36)

where gk is the same as in Lemma 7, satisfying gk > 1 if α < 0 and k is odd and gk ∈ [0, 1) otherwise.
We conclude that Cobweb is similar to Tâtonnement and lack of common knowledge in economies in which GE
effect complements the PE effect (α > 0), but not in economies in which the GE effect offsets the PE effect (α < 0): in
the latter class of economies, Cobweb opens the door to ampliﬁcation of the GE effect.

7.2

Level-k Thinking

Level-k Thinking—also known as Limited-Depth Thinking—is a solution concept often used in the experimental literature, but also elsewhere.29 According to this concept, level-0 thinkers best-respond to the belief that other players’
strategies are ﬁxed at some “default” point; level-1 thinkers best-respond to the belief that other players are level-0
thinkers; and so on. We adapt this concept to our study of GE effects by building on Proposition 5, which permits us to represent the economy as a game in quantities, and by setting the default point for the average quan0
tity q̄ to its pre-shock( equilibrium level. In) particular, we deﬁne {BRk }∞
k=0 recursively by BR (θm , θ, q) ≡ q and
k
k−1
BR (θm , θ, q) ≡ BR θm , θ, BR
(θ, θ, q) for all (θm , θ, q) and all k ≥ 1, where BR is itself deﬁned as in Proposi-

tion 5, and state our solution concept as follows.
Deﬁnition 4. For any k ∈ {0, 1, 2...}, the level-k solution is given by a quantity conjecture q̂ and by realized outcomes
∗
, p∗m ) for every m such that the following hold:
(qm , pm , qm

(i) The aforementioned outcomes satisfy Lemmas 2 and 3, with Êm [p̄∗ ] = P ∗ (q̂, θ̄new ) ∀m.
(ii) The quantity conjecture q̂ is given by

q̂ = BRk (θ̄new , θ̄new , q̄old ),

(37)

where q̄old ≡ Q(p̄∗old , θ̄old ).
Let us explain this deﬁnition. When k = 0, every agent expects the aggregate quantity to remain at its pre-shock
equilibrium value; that is, q̂ = q̂0 ≡ q̄old . When k = 1, every agent expects the other agents to act as if k = 0 and therefore also expects the aggregate quantity to be given by the best response to q̄old ; that is, q̂ = q̂1 ≡ BR(θ̄new , θ̄new , q̂0 ).
By induction, for any k ≥ 1, the conjectured aggregate quantity is given by q̂ = q̂k ≡ BR(θ̄new , θ̄new , q̂k−1 ). This mirrors the deﬁnition of Level-k Thinking in games and explains part (ii).30 Part (i) then transforms the quantity conjecture
to a price conjecture and requires that demand and supply are based on this price conjecture: whenever an agent
29 See

Nagel (1995) and Stahl and Wilson (1994, 1995) for early contributions; Crawford, Costa-Gomes, and Iriberri (2013) for a survey; and
Garcıa-Schmidt and Woodford (2015), Farhi and Werning (2017) and Iovino and Sergeyev (2017) for recent applications in macroeconomics.
30 Note that, when every agent expects q̄ to equal q̂ , part (ii) of the deﬁnition together with Lemma 3 implies that the realized value of q̄ equals
BR(θ̄new , θ̄new , q̂). This in turn explains why the assumed conjectures satisfy the recursion q̂k ≡ BR(θ̄new , θ̄new , q̂k−1 ) for all k ≥ 1.

28

q̄

q̄
45o

o

45

q̄1
q̄∞
q̄3
q̄2
q̄1
q̄0

Y′

Y′′

Y′′

q̄3
q̄∞

Z

Z

q̄2

Y

q̄0
X

q̂0

Y

q̂∞

q̂

Y′
X

q̂0

q̂∞

q̂

Figure 3: Level-k Thinking
expects the aggregate morning quantity to be q̂, she also expects the average afternoon price to be P ∗ (q̂, θ̄new ), and
chooses her demand or supply accordingly.
Forming conjectures about the simultaneous behavior of the other agents is therefore equivalent to forming conjectures about the resulting future prices. This permits us to go back and forth between the game-theoretic and the
Walrasian representation of the economy under the level-k concept. Furthermore, because iterating on the bestresponse function BR is equivalent to iterating on the contraction mapping T , it is evident that there is tight relation
between the level-k and Cobweb solution concepts. This point is formalized in the following proposition.
Proposition 8. Suppose either that P ∗ (q̄, θ̄) is invariant to θ̄, or that we modify the Cobweb concept so that the initial
price conjecture is given by p̂0 = P ∗ (q̄old , θ̄new ) rather than p̂0 = p̄∗old ≡ P ∗ (q̄old , θ̄old ). Then, for any k ∈ {0, 1, 2...}, the
level-k solution and the Cobweb(k ) solution impose the same price conjectures and give rise to the same observables.
The two concepts are not tautologically the same: Level-k Thinking is deﬁned in the space of beliefs about the actions of other players, whereas Cobweb is deﬁned in the space of price conjectures. Furthermore, a minor discrepancy
between the two emerges when p̄∗old =
̸ P ∗ (q̄old , θ̄new ), because the two iterative procedures then start from different
initial guesses (or “default points”). This explains why the equivalence between the two has to be qualiﬁed by the ﬁrst
sentence in the above proposition. Notwithstanding these points, the essence of the two concepts is the same, and so
are their implications with regard to the response q̄ to the aggregate shock.
Corollary 4. Suppose ∂P ∗ /∂θ = 0. Similarly to Cobweb, Level-k Thinking attenuates the GE adjustment and reduces
the gap between micro and macro elasticities in economies in which the GE effect ampliﬁes the PE effect (α > 0), but
not in economies in which the GE effect offsets the PE effect (α < 0).
We illustrate this point in Figure 3. The left panel features strategic complementarity (α > 0), the right one features
strategic substitutability (α < 0). In either panel, the solid blue lines represent the best-response function BR before
and after the shock; q̄0 identiﬁes the pre-shock REE quantity; and q̄∞ identiﬁes the post-shock REE quantity. The PE
effect of the shock is captured by the vertical shift from point X to point Y. The frictionless GE effect is captured by
the shift from Y to Z. Note that the GE effect ampliﬁes the PE effect when α > 0 and offsets it when α < 0. Finally, the
dashed arrows represent the rounds of Level-k Thinking: level-0 is captured by the shift from X to Y (level-0 coincides
with PE); level-1 is captured by the shift from Y to Y ′ ; and so on. It is then evident that Level-k Thinking helps capture
the notion of incomplete GE adjustment when α > 0, but opens the door to GE ampliﬁcation when α < 0.31
31 Corollary 4 and the ﬁgure assume ∂P ∗ /∂θ = 0. If we relax this assumption, the aforementioned overshooting can obtain for the level-k
solution even when α > 0.

29

This prediction is at odds, not only with our priors regarding plausibility, but also with the experimental literature
on “competition neglect”. If we allow α ≤ −1, Level-k Thinking produces an additional prediction that we ﬁnd
unappealing, even though it may be hard to test empirically: the conjectured prices/quantities diverge away from their
REE counterparts as the depth of reasoning increases. In the next subsection, we explain how both of these problems
are cured by an amendment proposed by Garcıa-Schmidt and Woodford (2015). It is worth noting, however, that
none of these problems emerge with our preferred approach, namely the one that maintains rational expectations but
removes common knowledge of the shock.

7.3

Reﬂective Equilibrium

We now to turn attention to “reﬂective equilibrium”, a concept that is closely related to Level-k Thinking but bypasses
the aforementioned pathologies. This concept was originally developed by Garcıa-Schmidt and Woodford (2015) in
the context of the New-Keynesian model and was used to shed new light on the macroeconomic effects of monetary
policy. Putting aside the details of the considered application, the more general idea is to let the subjective conjecture
of a certain variable—inﬂation in their context—to adjust continuously with the difference between the conjecture
itself and the value of that variable that gets realized if all agents act on the basis of that conjecture. For our purposes,
we identify the relevant variable with the average afternoon price and adapt the solution concept of Garcıa-Schmidt
and Woodford (2015) as follows.
Deﬁnition 5. Fix a T ∈ (0, ∞). The level-T reﬂective equilibrium is given by a conjecture p̂∗ and by realized outcomes
∗
(qm , pm , qm
, p∗m ) for every m such that the following hold:

(i) The aforementioned outcomes satisfy Lemmas 2 and 3, with Êm [p̄∗ ] = p̂∗ for all m.
(ii) The conjecture p̂∗ is given by p̂∗ = P̂ ∗ (T ), where the function P̂ ∗ is obtained by solving the following ODE:

(
)
dP̂ ∗ (t)
= T P̂ ∗ (t), θ̄ − P̂ ∗ (t)
dt
with initial condition P̂ ∗ (0) = p̄∗old ≡ P(θ̄old ).
To interpret the above, note that, for every t, T

(

∀t ≥ 0,

(38)

)
P̂ ∗ (t), θ̄ gives the actual average price that clears the market

for afternoon goods when the quantity q̄ is determined under the (incorrect) conjecture that this price equals P̂ ∗ (t).
Condition (38) therefore requires that the conjecture is adjusted upwards if the “actual” price exceeds the conjectured
one, and downwards otherwise. The assumed concept is therefore similar to adaptive expectations, except that the
adjustments happen instantaneously and on the basis of hypothetical outcomes, as opposed to with the passage of
calendar time and on the basis of the observation of actual past outcomes.
The assumed concept also resembles Cobweb dynamics and Level-k Thinking in the follow regard: the conjectured outcome is adjusted in the direction of the realized outcome. But whereas Cobweb and Level-k require the
adjustment to be in discrete steps, with the conjecture in each round being replaced by the implied outcome in the
previous round, Reﬂective Equilibrium lets the adjustment happen at inﬁnitesimally small steps. This guarantees that
the conjecture never overshoot relative to the frictionless benchmark, thus bypassing the aforementioned “pathology”
of the Cobweb and level-k concepts: as we vary T, the price conjecture spans the entire interval between p̄∗old and

p̄∗new , in a continuous manner, and without ever overshooting outside of it, regardless of α. By the same token, the GE
effect is necessarily attenuated, and the following is true.
Proposition 9 (Reﬂectie Equilibrium). For any T ∈ (0, ∞), there exists a T ′ ∈ (0, ∞) and a λ ∈ (0, 1) such that the level-

T reﬂective equilibrium coincide with the Tâtonnement(T ′ ) solution, and both of them predict the same aggregate
outcomes as the incomplete-information variant with common-knowledge degree λ.
30

In the above, we have adapted the solution concept of Garcıa-Schmidt and Woodford (2015) in the space of price
conjectures. Clearly, the same results obtain if we recast it in the space of quantity conjectures. That is, if we let the
conjecture be q̂ = Q̂(T ), where the function Q̂ is obtained by solving the following ODE:

(
)
dQ̂(t)
= BR θ̄new , θ̄new , Q̂(t) − Q̂(t)
dt

∀t ≥ 0

(39)

with initial condition Q̂(0) = q̄old . Under this perspective, the cognitive process we have introduced here can be
thought of as a smooth version, not only of our variant that was based on Cobweb, but also of the one that was based
on Level-k Thinking. As already noted, it is this smoothness that avoids the overshooting problem of Level-k Thinking.
Remark 1. Garcıa-Schmidt and Woodford (2015) study a model that can admit multiple REE and investigate which,
and if any, of these equilibria coincides with the limit of their solution concept as T → ∞. This issue is not relevant
in our framework: thanks to the fact that T is a contraction mapping, not only is the REE unique, but it also coincides
with the aforementioned limit.
Remark 2. In Section 2.4 of their paper, Garcıa-Schmidt and Woodford (2015) discuss extensively how their
solution concept is a “smooth” version of Level-k Thinking, as well as how it relates to the earlier work of Evans and
Ramey (1992, 1995). In the Appendix, they also use an example to illustrate how the Level-k solution may oscillate
around the REE solution and may diverge away from it as k increases. Under the lenses of our framework, that example
maps to the case in which α < −1: in this case, the Level-k conjectures diverge to plus or minus inﬁnity as k → ∞,
whereas the reﬂective equilibrium converges to the REE solution as T → ∞. Our results in this section complement
Garcıa-Schmidt and Woodford (2015), not only by offering a sharper illustration of these particular points, but also by
connecting their contribution to the broader theme of our paper—GE attenuation—and by building a bridge between
their approach and the literature on higher-order uncertainty.

7.4

Cognitive Discounting

Gabaix (2016a,b) departs from the REE concept by assuming that the perceived law of motion of the aggregate state
of the economy is less responsive to the underlying aggregate shocks than the actual law of motion. To be concrete,
consider a dynamic model in which the aggregate state variable, de-trended around its steady state and denoted by xt ,
evolves according to the following law of motion: xt+1 = G (xt , ϵt+1 ) = Axt + Bϵt+1 , where A and B are matrices
and ϵt+1 is an exogenous innovation. Gabaix (2016a,b) imposes that the “behavioral agent” incorrectly perceives the
law of motion to be xt+1 = µG (xt , ϵt+1 ) , for some exogenous scalar µ ∈ (0, 1) that can be as the degree of “cognitive
discounting”.32 The same form of belief distortion was assumed by Greenwood and Hanson (2015) in a model meant
to capture a phenomenon that is known as “competition neglect” in behavioral economics.
We adapt this kind of bias in our own setting as follows. To simplify the exposition, normalize p̄∗old = 0. Next,
assume that the conjecture p̂∗ is given by the solution to the following ﬁxed-point problem:

p̂∗ = µT (p̂∗ , θnew ),

(40)

for some µ ∈ (0, 1). To interpret the above, note that T (p̂∗ , θnew ) gives the actual realization of the endogenous variable
of interest when the agents’ conjecture of this variable is set p̂∗ . Rational expectations impose that the conjecture and
the realization coincide: p̂∗ = T (p̂∗ , θnew ). The variant proposed above, instead, requires that the conjecture differs
from the realization by a discount factor equal to µ ∈ (0, 1). This mirrors the assumption made in Gabaix (2016a,b).
32 Gabaix (2016a) accommodates this kind of bias in a general framework; it also endogenizes the value of µ. Gabaix (2016b), on the other hand,
treats µ as exogenous and focuses on the implications of adding this bias to the New-Keynesian framework.

31

By solving the above ﬁxed point, one can show that p̂∗ satisﬁes the following restriction:

p̂∗ = p̄∗old + π(µ) (p̄∗new − p̄∗old ) ,

(41)

where π is the same function as the one deﬁned in Lemma 6. That is, the irrational conjecture generated by the Gabaixlike variant coincides with the average rational expectation in our earlier incomplete-information variant when λ = µ.
As a result, the two variants make the same predictions.
Proposition 10. For any Gabaix-like variant with discount µ ∈ (0, 1), there exists an incomplete-information economy
with parameter λ = µ such that, for any realization of ∆θ̄, the average rational expectation Ē [p̄∗ ] in the latter coincides
with the irrational conjecture p̂∗ in the former, and the two economies predict the same change in observable q̄. The
converse is also true.
This exact kind of equivalence need not extend to richer dynamic settings. The result nevertheless illustrates that
the kind of cognitive discounting assumed in Gabaix (2016a,b) and Greenwood and Hanson (2015) plays a similar
modeling role, and has similar observable implications, as the rational belief anchoring featured in our work and,
more generally, in the literature on incomplete information and higher-order beliefs.
From this perspective, the different methodological approaches can be seen as close substitutes to one another.
Note, however, the following subtlety. In the approach described above, nothing prevents the analyst from assuming
that µ > 1 instead of µ < 1 : a “behavioral” agent may incorrectly perceive either the endogenous state reacts less
or that it reacts more than what it actually does. This means that, although one can obtain the sought-after result
(attenuation of GE effects) by assuming the “right” kind of belief distortion, one can also obtain the opposite result
(ampliﬁcation of the GE effects) simply by assuming the opposite kind of belief distortion. This echoes our earlier
comment about Akerlof and Yellen (1985a,b) and ϵ-equilibrium.
Our preferred approach does not provide this degree freedom. Because the variation in higher-order beliefs is
necessarily bounded by the variation in ﬁrst-order beliefs, our approach predicts that the potency of the GE effects in
the absence of common knowledge is necessarily lower than in the frictionless benchmark.
Remark 1. By bunching Gabaix (2016a,b) and Greenwood and Hanson (2015) together, we seek, not only to
illustrate the formal connection between these works and ours, but also to relate the so-called “competition neglect”
phenomenon to our own preferred theory of GE attenuation. We revisit this point at the end of Section 9.
Remark 2. Gabaix (2016a,b) contains an additional friction, which we have abstracted from in the present analysis.
This additional friction is absent from Greenwood and Hanson (2015) and is, instead, the core element of Gabaix
(2014): relative to a fully rational agent, the “sparse” agent responds less to any variation in the variables that enter
her individual decision problem (prices, income, etc). This can be understood as a purely decision-theoretic friction,
which is distinct both conceptually and empirically from the one we have isolated in the present analysis.33
Remark 3. The heterogeneous-prior speciﬁcation considered in Angeletos and La’O (2009) and Angeletos, Collard,
and Dellas (2014) shares similar costs and beneﬁts as the alternative developed in Gabaix (2016a,b): both speciﬁcations afford a high degree of tractability at the cost of a delicate departure from rational expectations. Note, though,
that the approach taken in Angeletos and La’O (2009) and Angeletos, Collard, and Dellas (2014) allows the belief bias
to shrink with the passage of time, mimicking the kind of rational-expectation dynamics we study in the next section.
33 Gabaix

(2016a,b) sees the two frictions as two facets of the same cognitive constraint. We, instead, have separated them for pedagogical reasons:
one can accommodate inattention or any other adjustment friction in the decision rules (or the best responses) of an agent without dropping the
REE solution concept (or Nash Equilibrium), and vice versa. Also note one can shut down the one or the other friction in Gabaix (2016a,b) by
appropriately picking the relevant free parameters of his framework. For example, setting my = mr = 1 in Gabaix (2016b) recovers the standard
decision rules (shuts down inattention), whereas letting m̄ < 1 (respectively, m̄ > 1) allows for under-reaction (respectively, over-reaction) in the
perceived law of motion of the aggregate outcomes (or the behavior of others).

32

8

GE Adjustment Takes Time

In the preceding analysis, we formulated the idea of weak GE adjustment. We now formulate the complementary idea
of slow GE adjustment. To this goal, we introduce a variant framework, in which GE interactions happen repetitively,
that is, over multiple periods after the shock has hit the economy. Like our baseline framework, the new framework
is not meant to be either general or realistic. Rather, it is designed so as to facilitate (i) the adaptation of our earlier
insights to a dynamic context and (ii) some additional comparisons of the considered methodological approaches.

8.1

Set Up

There is a continuum of marketplaces, indexed by m ∈ [0, 1] , a double continuum of households, indexed by i =

(i1 , i2 ) ∈ [0, 1] × [0, 1] , and multiple periods, indexed by t ∈ {0, 1, 2, · · · , T }.34 To simplify the exposition, we
let T = ∞.35 At any given point of time, each marketplace is populated by a measure one of households and a
representative ﬁrm. Households may randomly move from one marketplace to another as time passes and are the key
decision-theoretic units in the model; ﬁrms are immobile and play an auxiliary role.
Households consume two goods in each period: leisure and a local ﬁnal good. The latter is produced by the local
ﬁrm in each marketplace, using the locally available labor and capital. Capital takes the form of multiple, imperfectlysubstitutable, varieties. Each household is capable of transforming the ﬁnal good into a single variety of capital, which
can be used into production next period. The efﬁciency of this transformation depends on a local fundamental, which
is speciﬁc to each marketplace but stays constant over time.36 We denote the fundamental of marketplace m by θm
and the corresponding aggregate by θ̄.
Marketplaces and matching. As in our baseline framework, the assumptions that markets are segmented but
households can randomly relocate from one marketplace to another help disentangle partial- and general-equilibrium
effects. To keep the analysis tractable, we now model the relocation of household as the product of random pairwise
matching across the marketplaces.
At t = 0, there is a given allocation of households across the marketplaces. This allocation is such that each
marketplace is populated by an equal measure of households. At the start of each period t ≥ 1, each marketplace

m is matched with another, randomly chosen, marketplace m′ . At this point, a fraction 1 − ρ of the population from
marketplace m relocates to marketplace m′ , and vice versa. Every household that relocates brings with her the capital
she had accumulated in her old home. Following this relocation, the match is dissolved and each marketplace operates
its own markets for the labor, the capital and the ﬁnal good.
We let M (i, t) denote the marketplace in which household i is located during period t. We let I (m, t) denote
the set of households who trade at marketplace m during period t. We ﬁnally adopt the convention that household

i = (i1 , i2 ) is located at marketplace m = i1 at t = 0; that is, M (i, 0) = i1 .
Firms. In each period t and each marketplace m, there is a competitive ﬁnal-good ﬁrm, which employs the capital
varieties and the labor of the households in I (m, t) . The produced quantity of the ﬁnal good is given by
1−ω
qm,t = κω
m,t ℓm,t ,

(42)

34 Note that t and T now refer to calendar time. This should not be confused with the notation used in Section 5, where t and T referred to the
number of iterations (or the depth) of Tâtonnement-like cognitive process.
35 We think of the time horizon as relatively short. Whether this means a few months or a few quarters is beyond the scope of this paper.
36 Note the subtle change relative to our baseline model: the fundamental is now ﬁxed to the marketplace rather than to the individual. This
change is made only for the purpose of simplifying the information structure, which now evolves endogenously over time.

33

where ℓm,t is the local supply of labor,

(∫

σ
) σ−1

σ−1
σ

κm,t ≡

ki,t−1 di

,

i∈I(m,t)

is a CES composite of the local capital varieties, ki,t−1 is the quantity of the capital variety owned and supplied by
household i (note that this is determined in the previous period), σ > 0 is the elasticity of substitution across varieties,
and ω ∈ (0, 1) is the capital share. Normalizing the price of the ﬁnal good to one, we can therefore express the proﬁts
of the ﬁnal-good ﬁrm in marketplace m and period t as

∫
qm,t − wm,t ℓm,t −

pm,i,t k i,t−1 di,
i∈I(m,t)

where wm,t denotes the local wage and pm,i,t denotes the local price of the capital variety supplied by household i.
Households. Consider household i. Her preferences are given by
T
∑

β t U (ci,t , ni,t ),

t=0

where β ∈ (0, 1) is her discount rate, ci,t denotes her consumption, ni,t denotes her labor supply, and U is the perperiod utility function, given by U (c, n) = c −

n1+η
1+η

for some η > 0. The period-t budget constraint is given by

ci,t + Γ (ki,t , θm ) = yi,t ≡ wm,t ni,t + pm,i,t ki,t−1 ,

with

m = M (i, t).

To interpret the above, recall ﬁrst that M (i, t) denotes the marketplace in which the household is located during period

t. Next, note that wm,t ni,t and pm,i,t ki,t−1 are, respectively, her labor and capital income. Finally, Γ (ki,t+1 , θm ) is the
1+ϕ

cost of transforming the ﬁnal good into the household’s capital variety. We let Γ (k, θ) = θ−ϕ k1+ϕ , for some ϕ > 0. A
“better” fundamental therefore means a lower cost of transforming the ﬁnal good into capital.
Log-linearization and shocks. As in our earlier analysis, we henceforth re-interpret all the variables as logdeviations from a symmetric steady state and we work with the log-linearized version of the model. We also consider
a once-and-for-all shock to θ̄ from some θ̄ = θ̄old to some θ̄ = θ̄new ̸= θ̄old . We treat the initial fundamental, θ̄old , as a
ﬁxed parameter and the change, ∆θ̄ ≡ θ̄new − θ̄old , as a random variable drawn from a Normal distribution centered
around 0. We denote the corresponding change in the local fundamentals by ∆θm . We ﬁnally use a bar over any
variable to indicate the economy-wide average of that variable.37
From elasticities to IRFs. In what follows, we investigate how the economy’s outcomes (investment, output, etc)
respond to the aforementioned shock, not only on impact (at t = 0) but also in all future periods (t ≥ 1). This exercise is
similar to the one conducted before, except that now the key theoretical object is an entire impulse response function
(IRF), describing the change in economic outcomes at each t ≥ 0, as opposed to a single elasticity scalar.

8.2

Preliminaries

We start the analysis by imposing Assumptions 1–4.38 These assumptions sufﬁce for obtaining the following result,
which represents the partial-equilibrium predictions of the model.
∫
∫
∫
is, q̄t ≡ qm,t dm, p̄t ≡ pm,t dm, k̄t−1 ≡ km,t−1 dm and so on. We also use the convention that k̄−1 = 0.
be precise, these assumptions are adapted to the multi-period framework of this section by allowing the agents to have arbitrary subjective
beliefs, not only of current and future outcomes in other marketplaces, but also of any unobserved past outcomes; and by imposing market clearing
to the markets for the consumption good, labor, and capital in all periods.
37 That

38 To

34

Lemma 8. (i) There exists a known linear vector function F such that, for every m and every t,

(qm,t , ℓm,t , wm,t , pm,t ) = F (κm,t ) .
(ii) There exists a known linear function K such that, for every m and every t,

(
)
km,t = K Êm,t [p̄t+1 ], θm ,
where Êm,t [.] denotes the period-t subjective expectation of the agents located in marketplace m during that period.
Part (i) gives the local output, employment, and prices in each period and each marketplace as functions of the local
capital stock. Part (ii) gives local investment as a function of the local subjective beliefs of a key general-equilibrium
object, the average price of capital next period. To pin down outcomes, what remains to do is to specify how these
subjective beliefs are formed and how they adjust to the underlying aggregate shock. We do so in the sequel, under
different assumptions about the solution concept and/or the level of common knowledge in the economy.

8.3

Frictionless Benchmark

Similarly as in Section 4, we deﬁne the frictionless benchmark by imposing the REE concept together with common
knowledge of θ̄ and of p̄t for all t.
In the Appendix, we show that there exists a linear function T such that, in any equilibrium and any t ≥ 1,

(
)
p̄t = T p̄t , θ̄ .
The slope of T is given by

α≡
where χ =

η(1−ω)
η+ω .

∂T
(1 − σχ) (1 − ρ2 )
=
,
∂p
σϕ + σχρ2 + (1 − ρ2 )

(43)

(44)

The mapping T and the scalar α have similar interpretations as the corresponding objects in our

baseline model, although they of course admit different functional forms.
It is easy to verify that α is necessarily less than +1; it can be either positive or negative;39 and is higher than −1 as
long as ϕ is high enough and/or σ is low enough.40 We henceforth assume that α > −1 holds so as to guarantee that

T deﬁnes a contraction mapping. We then have that p̄t = P(θ̄) for all t ≥ 1, where P is the ﬁxed point of T . Using
this into part (ii) of Lemma 8, we infer that, for all m and all t ≥ 0,

km,t = K(P(θ̄), θm )

and

k̄t = K(θ̄) ≡ K(P(θ̄), θ̄).

(45)

From part (i) of Lemma 8, we can then express the local outcomes (qm,t , ℓm,t , wm,t , pm,t ). The corresponding aggregates can then be expressed as linear functions of θ̄ alone.41
We are now ready to characterize the response of the economy to the aggregate shock. Without serious loss of
generality, we focus on investment as the observable quantity of interest. Think of this as the analogue of the “morning
quantity” in our baseline model. The responses of all other variables (output, employment, prices) can be inferred
from Lemma 8 and feature a similar disconnect between micro and macro effects. To allow for a non-zero GE effect,
we ﬁnally assume that α ̸= 0.
39 Given

that ρ ∈ (0, 1), we have that α ∈ (0, 1) if and only if σχ < 1, α = 0 if and only if σχ = 1, and α < 0 if and only if σχ > 1.
ϕ + χ(2ρ2 − 1) ≥ 0, α > −1 regardless of σ; and when ϕ + χ(2ρ2 − 1) < 0, α > −1 if and only if σ < σ̃, for some σ̃ > 1.
41 Note that local outcomes vary both in the cross section and over time due to the cross-section heterogeneity in θ
m and the random relocation
of agents. Aggregate outcomes, by contrast, are time invariant.
40 When

35

Proposition 11. There exist scalars ϵM acro and ϵmicro , with ϵM acro ̸= ϵmicro , such that

k̄t = k̄new ≡ k̄old + ϵM acro ∆θ̄ ∀t

(
)
km,t = k̄new + ϵmicro ∆θm − ∆θ̄ ∀m, t.

and

The ﬁrst equation characterizes the response of aggregate investment. On impact, k̄t jumps form k̄old ≡ K(θ̄old ) to

k̄new ≡ K(θ̄new ) and stays constant thereafter. In other words, the IRF of aggregate investment is ﬂat at a level equal
to ϵM acro . The scalar ϵM acro therefore has a similar meaning as the macro elasticity in our baseline framework, except
that it now indexes the entire dynamic response of the economy.42
The second equation shifts attention to the cross section and identiﬁes the scalar ϵmicro as the analogue of the micro
elasticity in our baseline framework: this scalar summarizes the IRF of local investment to local shocks or, equivalently,
the local exposure to the aggregate shock.
The two scalars differ from each other because of the GE effect associated with the mobility of capital across
marketplaces. Depending on parameters, this GE effect can cause ϵM acro to be either higher or lower than ϵmicro .
Intuitively, there are two opposite forces at work. On the one hand, investment choices tend to be strategic substitutes
because an increase in the aggregate capital stock raises wages and depresses the aggregate return to capital. On the
other hand, investment choices tend to be strategic complements because an increase in the aggregate capital stock
raises the demand for each individual variety (insofar as the different varieties are imperfect substitutes in production).
When the ﬁrst effect dominates, α < 0 and ϵM acro < ϵmicro ; otherwise, α > 0 and ϵM acro > ϵmicro .
Remark. In our setting, the frictionless benchmark lacks any interesting dynamic patterns in the responses either
of aggregate outcomes to aggregate shocks or of local outcomes to local shocks: the IRFs are ﬂat and boring. In
applications, interesting dynamic patterns can emerge from various forms of adjustment costs embedded in preferences
(e.g., desire to smooth consumption) or technology (e.g., adjustment costs to labor or capital). By abstracting from
such effects, we sharpen the comparison between the frictionless benchmark and the modiﬁcations studied in the
sequel: in these modiﬁcations, the aggregate IRFs are non-ﬂat because and only because of the kind of GE attenuation
we are interested in.43

8.4

Tâtonnement Dynamics

In the aforementioned benchmark, k̄t jumps for from k̄old to k̄new as soon as the aggregate shock hits the economy.
Behind this instantaneous adjustment in quantities, there is an instantaneous adjustment in the expected and the actual
price of capital: Et [p̄t+1 ] and p̄t+1 alike jump from p̄old ≡ P(θ̄old ) to p̄new ≡ P(θ̄new ). We now illustrate how this
adjustment can be slowed down by letting the relevant price conjectures adjust according to Tâtonnement dynamics.
The methodological strategy is similar to the one taken in Section 5, except that now the cognitive process takes
place in “real time”. In particular, the relevant conjecture here is that further updates of the initial conjecture of p̄t
occur only with the passage of the calendar time. The details are spelled out in Appendix D. Here, we describe the
basic ideas with the help of Figure 4.
We consider two different economies: the economy in the left panel features ϵM acro > ϵmicro > 0, meaning that the
GE effect reinforces the PE effect; the economy in the right panel features the opposite property. For each economy,
we draw the IRF of k̄t under two scenarios: the Tâtonnement variant under consideration (solid red line), and the
frictionless benchmark (dashed blue line). In that benchmark, k̄t jumps up by a quantity equal to ϵM acro and stays
at this higher level for ever after. In the Tâtonnement variant, instead, the initial jump in k̄t is approximately equal
to ϵmicro . Depending on which economy we consider, this initial response can represent either an under-reaction
or an over-reaction relative to the frictionless benchmark. In either case, however, it reﬂects the attenuation of the
42 Aggregate
43 One

employment and output exhibit the same dynamic response as k̄t , lagged by one period and scaled by a constant factor.
can accommodate such adjustment frictions in our setting by letting the cost of investment depend on the local capital stock.

36

k̄t
frictionless benchmark
Tâtonnement

ϵmicro

ϵM acro

ϵM acro

ϵmicro

k̄t

t

t

Figure 4: GE adjustment takes time. (Left panel: GE ampliﬁes PE. Right panel: GE offsets PE.)
underlying GE effect. This echoes the result of Section 5. What’s new here is that this attenuation decreases over time:
because the “Walrasian auctioneer” inside the mind of each agent updates the conjecture of p̄t as t increases, the
distance between the two IRFs decreases with t and eventually vanishes.

8.5

Dynamics with Incomplete Information

We ﬁnd the preceding variant to be useful for two reasons. First, it offers a direct, albeit old-fashioned, formalization
of the notion we are after, namely that GE adjustment takes time. Second, it illustrates more generally how this notion
can be captured by all the other variants that drop the REE concept: one must make the assumption that the “depth of
reasoning” increases with the passage of time. With Level-k Thinking, for example, one has to assume that k increases
with t; and with Gabaix’s variant, one has to assume that µ, the cognitive discount factor, increases with t. We now
show how our preferred approach helps capture the same notion without either a departure from rational expectations
or the need for any such additional assumption: the attenuation has to decrease with time, simply because rational
agents extract information from realized outcomes.44
Similarly to Section 6, we summarize the information that is available to marketplace m at the moment the shock
hits (t = 0) in a local signal sm given by

sm = ∆θ̄ + vm ,
where ∆θ̄ is the underlying shock and vm is an idiosyncratic noise term, drawn from N (0, σv2 ), i.i.d. across marketplaces, and independent of ∆θ̄. Unlike our earlier analysis, however, we must now take into account the fact that the
information structure changes endogenously over time, as agents relocate and trade.
In general, the task of characterizing the dynamics of beliefs in stationary settings with dispersed private information
and endogenous learning can be rather taunting. For example, Huo and Takayama (2015) prove that an exact ﬁnitestate-space solution is impossible for a large class of such settings. Here, the task is more manageable thanks to two
key assumptions: that there is a single, once-and-for-all aggregate shock; and that the endogenous learning boils down
to a bilateral exchange of the private information of any two marketplaces within any realized match.45
Let us explain. Fix a period t ≥ 1, a particular marketplace m, and a particular realization of the aforementioned
pairwise matching, and let m′ denote the match of marketplace m. At the moment its local markets for capital and
44 The results of this subsection rest on interpreting the friction as the product of the geographic dispersion of information rather than as a cognitive
friction. They also build heavily on earlier works that study the dynamics of learning in settings with strategic complementarity and dispersed
information, such as Woodford (2003), Nimark (2008, 2017) and Angeletos and La’O (2010). The added value here is to connect the sluggishness
of higher-order beliefs to the speed with which the GE effect settles in; to clarify that the same mechanism manifests as overshooting rather than
inertia in the case of strategic substitutability; and to draw the contrast to the aforementioned methodological alternatives.
45 In this regard, our setting features a similar “information percolation” as Dufﬁe and Manso (2007).

37

labor open, marketplace m is populated by two types of agents: those that we previously located in m (the “locals”)
and those that were previously located in m′ (the “foreigners”). By observing the local prices pm,t and/or wm,t , both
type of agents can infer the local capital stock, κm,t . Recall that the latter is given by a weighted average of the
investment made by the two type of agents, i.e., κm,t = ρkm,t−1 + (1 − ρ2 )km′ ,t−1 . Furthermore, each type knows its
own investment, i.e., the locals know km,t−1 and the foreigners know km′ ,t−1 . It follows that the observation of the local
prices perfectly reveals km,t−1 to the foreigners and km′ ,t−1 to the locals. Next, note that km,t−1 = K(θm , Em,t−1 [p̄t ])
and km′ ,t−1 = K(θm′ , Em′ ,t−1 [p̄t ]), where K is a commonly known function. Furthermore, the foreigners directly
observe θm as soon as they arrive in marketplace m. It follows that, by observing the local prices and learning km,t−1 ,
the foreigners also learn Em,t−1 [p̄t ]. To simplify the analysis, we assume the foreigners also tell the locals what θm′
was. It follows that, by learning km′ ,t−1 , the locals learn Em′ ,t−1 [p̄t ]. Furthermore, because there is no aggregate shock
¯ the equilibrium p̄t is a known, albeit time-varying, function of θ̄. It follows that the local
other than the one in the θ,
learn Em′ ,t−1 [θ̄] and the foreigners learn Em,t−1 [θ̄]. That is, it is as if the two types of agents exchange their (pre-trading)
posterior beliefs about θ̄.
We are thus able to show the following.
Lemma 9. There exists a deterministic sequence {λt }+∞
t=0 , with 0 < λt < λt+1 < 1 ∀t, such that the following is true:
(i) The belief hierarchy satisﬁes

Ēth [θ̄] = θ̄old + λht ∆θ̄ ∀t, h,
where Ēth [·] denotes that h-th order average expectation operator in period t.46
(ii) The equilibrium expectations of the price of capital are given by

Ēt [p̄t+1 ] = p̄old + π (λt ) (p̄new − p̄old ) ∀t,

(46)

where the function π is continuous and strictly increasing in λ, with π(0) = 0 and π(1) = 1.
(iii) λt → 1 as t → ∞.
The characterization of sequence {λt }Tt=0 can be found in the Appendix. For the present purposes, it sufﬁces to
note that the lack of common knowledge diminishes over time and eventually vanishes. That is, for any given h ≥ 1,
the average h-th order belief of the aggregate fundamental moves monotonically from a value closer to θ̄old to a value
closer to θ̄new as time passes. But the higher h is, the more anchored the h-th order belief is to θ̄old and the more time
it takes for it to cover any given distance between θ̄old and θ̄new . And because the period-t equilibrium expectation of
the price of capital can be expressed as a function of the contemporaneous belief hierarchy, we then obtain that this
expectation itself converges monotonically from p̄old to p̄new .
The following is then a direct implication.
Proposition 12. In the Tâtonnement variant described above, the dynamic response of aggregate investment to the
aggregate shock is given by

{
}
k̄t = k̄old + ϵmicro + π (λt ) (ϵM acro − ϵmicro ) ∆θ̄,

(47)

where π is the same function as the one appearing in Lemma 9.
This provides our preferred formalization of the notion that “GE adjustment takes times”: for t low enough, the
change in k̄t relative to the change in θ̄ is close to ϵmicro ; but as time passes, this change gets closer and closer to

ϵM acro .
If we were free to choose any increasing sequence {λt }+∞
t=0 in (0, 1), we could replicate exactly the dynamic
response obtained in the variant with Tâtonnement dynamics and, more generally, we could rationalize any speed.
46 This

is deﬁned recursively by Ēt1 [·] ≡

∫

Em,t [·]dm and Ēth [·] ≡

∫

Em,t [Ēth−1 [·]]dm for all h ≥ 2.

38

For better or worse, we are not entirely free to choose this sequence: it {λt }+∞
t=0 is dictated by the Bayesian learning that
obtains endogenously given the assumed trading structured. That said, the essence is that lack of common knowledge
rationalizes the patterns seen in Figure 4: because of the learning, the GE attenuation has to decrease with time.
What is more, the following variant of Proposition 6 applies.
Proposition 13. Fix the information structure and normalize ϵM acro = 1. For any t ≥ 0, k̄t is further away from k̄new ,
the larger |α|. Hence, when the GE effect is larger, it takes more time for it to settle in.
This is an intriguing prediction, not shared by our Tâtonnement variant, but naturally implied from the combination
of rational expectations with lack of common knowledge. In our setting, the information that every agent accumulates
as time passes is invariant to α. This means that we can vary the strength of the GE effect while holding constant the
sequence {λt }+∞
t=0 , which in turn gives the above result. In an extension that allows the agents to learn also from noisy
signals of the aggregate outcome k̄t , one can show that the informativeness of these signals decreases with |α|. This
reinforces the above message and offers an additional example of the predictive power of our preferred approach.

9

Lessons and Applications

In this section, we summarize the key lessons, compare the different methodological approaches under consideration,
and discuss a possible applications.

9.1

Main Lessons and Discussion

Our results can be summarized as follows. The variants that are based on lack of common knowledge or Tâtonnement
dynamics are able to capture the sought-after notion of GE attenuation regardless of whether the relevant GE effects
amplify or offset the corresponding PE effects. By contrast, the variants that are based on Level-k Thinking and Cobweb
dynamics have an inherent difﬁculty in capturing the sought-after notion of GE attenuation in settings in which the
GE effects offset the PE effects. That said, we also showed how the reﬂective-equilibrium concept of Garcıa-Schmidt
and Woodford (2015) helps reconcile the essence of Level-k Thinking, if not its exact form, with the notion of GE
attenuation. We ﬁnally discussed why the approach of Gabaix (2016b) can also accommodate this notion.
From a big-picture perspective, the various approaches therefore appear to be close substitutes to one another.
Accordingly, we would like to summarize the main take-home lesson of our paper as follows.
Take-Home Lesson. GE attenuation appears to be a robust implication of allowing either for plausible forms of bounded
rationality, or for a realistic friction in the ability of the agents to reach common knowledge of the state of the economy
and to coordinate their behavior.
That said, we also feel that, on the margin, there are good reasons to favor the approach that relaxes the commonknowledge requirements of standard models instead of dropping the rational expectations hypothesis.
First of all, any departure from the REE concept is, by its very nature, subject to Lucas’ critique. Of course, this does
not mean that one should be dogmatic about rational expectations. However, insofar as one assigns a positive value
to interpretations of the data and to policy prescription that do not rest on the presumption that agents make repeated,
and systematic, mistakes, the balance is titled in favor the approach that maintains the REE concept but relaxes the
common-knowledge assumptions of the theory.
Second, this approach is more “disciplined” in the sense that it does not allow the possibility to obtain the opposite
result. This contrasts with ϵ−equilibrium, the approach taken either in Gabaix (2016a,b) or in Angeletos and La’O
(2009), and Level-k Thinking in contexts where the GE effects offset PE effects.
39

Third, once our preferred approach is adapted to multi-period settings (as we did in the last section), it makes a sharp
prediction: the GE effects of any given aggregate shock are attenuated relative to their frictionless counterparts in the
short run, but get closer and closer to the latter as the time passes. The reason is that the level of common knowledge
about the underlying aggregate shock increases endogenously as the agents observe past market outcomes.
This prediction appears to be, not only a priori plausible, but also consistent with the evidence documented in
Coibion and Gorodnichenko (2012). Yet, this prediction is not necessarily shared by the alternative approaches.
Consider the particular setting studied in the last section. A key feature of that setting was that a shock occurs only
once, in the beginning of the calendar time. In such as setting, one can reconcile the idea that GE adjustment takes
time with some of the considered forms of bounded rationality, such as Level-k Thinking, by making the additional
assumption that agents become “deeper thinkers” as the calendar time increases. However, this begs the question of
what justiﬁes this assumption.
What is more, this assumption is not useful to stationary environments with recurring shocks. In such settings, one
would need the depth of thinking to increase, not with calendar time, but rather with the time lag since the shock has
occurred. But how could it be that agents are shallow thinkers vis-a-vis recent shocks and, at the same time, are deep
thinkers vis-a-vis shocks that occurred further in the past?
Fourth, note that the approaches that drop the REE concept require the selection of a “default point” that serves as
the anchor of the conjectures that the agents form about the actions of others or, equivalently, about all the endogenous
economic outcomes. In the variants studied in Section 7, this default point was assumed to coincide with p̄old or q̄old ,
the pre-shock frictionless outcomes.
This appears to mirror the speciﬁcation of the common prior in Section 6: in the incomplete-information variant,
the equilibrium beliefs of p̄ and q̄ were anchored to, respectively, p̄old and q̄old only because the common prior of the
underlying aggregate fundamental was centered around θ̄old . Does this mean that the two approaches have the same
degree of freedom in choosing the relevant belief anchor?
Not really. Once our preferred approach is adapted to stationary dynamic settings, there is no such freedom:
the objective probability distribution of the exogenous fundamentals together with Bayesian learning discipline what
the anchor is. By contrast, with the non-REE alternatives, the default point remains a free parameter, which can be
disciplined only with additional assumptions.47
Last but not least, it is not clear whether the REE concept is more demanding on the cognitive abilities of an agent
than any of the considered forms of bounded rationality. Indeed, what is easier? To solve for the REE ﬁxed point; to
compute the k -th order iteration of the mapping T for k ≥ 1; to solve the ODE associated with the reﬂective equilibrium; or to solve the modiﬁed ﬁxed point proposed by Gabaix (2016b)? In our view, the answer to this question is not
obvious. We therefore think that the common appeal of all these approaches is their ability to generate predictions
that seem conceptually plausible and empirically relevant, but are inconsistent with the frictionless benchmark.
In our eyes, these considerations tilt the balance in the direction of the methodological approach that maintains the
rational expectations solution concept but examines the robustness of its observable implications to lack of common
knowledge of the underlying fundamentals—which is the approach taken in Section 6 of the present paper, in the
complementary contribution of Bergemann and Morris (2013), and in much of the literature reviewed in Angeletos
and Lian (2016b). However, we do not wish to disparage any of the considered non-REE alternatives. To the contrary,
we believe that all these approaches complement one another in the direction of offering a more useful representation
of the real world than the one permitted by more conventional modeling practices.
Remark. In this paper, we deﬁned PE as the adjustment that takes place in each marketplace holding constant the
outcomes in other marketplaces. We also introduced a friction—whether in the form of removing common knowledge
47 Of course, the practitioners of these approaches are fully aware of this issue and apply careful judgement in choosing the default points in their
works. Our point here is only to highlight that our preferred approach bypasses the need for such judgements.

40

or in the form of relaxing the REE concept—in the conjectures that the agents in any given marketplace make about
the behavior of agents in other marketplaces. We did not, however, allow a similar friction to be present within
each marketplace. Although one can relax this assumption (at the expense of having to deal with the endogenous
aggregation of information through prices), the following principle seems reasonable. Agents have more precise
information about the markets they themselves currently participate in than about “remote” markets—where “remote”
could refer to distance in terms of geography, time, or knowledge. Our preferred approach then suggests that it is
precisely equilibrium effects operating through more remote connections that are likely to be attenuated more. This
point suggests an extension of our analysis to networks and a bridge to the works of Bergemann, Heumann, and Morris
(2017) and Golub and Morris (2017); we leave this open for future research.

9.2

Applications

We now discuss a few possible applications, some of which we explore in companion work. These applications cannot
be nested in the abstract framework of this paper: they feature micro-foundations that are appropriate for the particular
contexts of interest, richer market structures, more elaborate forms of forward-looking behavior, and speciﬁc kinds of
PE and GE effects. They nevertheless share the central theme of this paper, namely the attenuation of GE mechanisms.
To illustrate, consider Angeletos and Lian (2016a). In that paper, we show how relaxing the common-knowledge
requirements of an otherwise standard New-Keynesian model attenuates the GE effects of monetary policy and lessens
the “forward guidance puzzle.” In the next few paragraphs, we brieﬂy review the puzzle, the contribution of our
companion paper, and its relation to the present paper.
The aforementioned puzzle refers to the following issue. Suppose the economy is described by the New-Keynesian
model. Suppose further that the economy is in a slump and that the zero-lower-bound (ZLB) binds up to a future date

t = T − 1, for some T ≥ 2. Because of this constraint, the monetary authority is unable to stimulate aggregate demand
by reducing the current Federal funds rate. Yet, according to the model, the same goal can be achieved by a credible
promise to keep the interest rate below its “natural level” after the ZLB has ceased to bind, that is, at t ≥ T . For
plausible parameterizations of the model, the effectiveness of such a policy is quantitatively large. What is more, for
any parameterization, the effectiveness increases with T : the further into the future forward guidance has to operate,
the stronger its impact on current economic activity and inﬂation. Last but not least, a greater degree of price ﬂexibility
implies a greater degree of monetary non-neutrality, as measured by the elasticity of current activity to the interest rate
set after the ZLB has ceased to bind.
These predictions are considered, by many economists, as empirically implausible, which is why the issue is known
as a “puzzle”. For our purposes, the key is to observe that these predictions are driven by certain GE effects. The most
crucial among these GE effects is the feedback loop between aggregate spending and inﬂation. Reducing the nominal
interest rate at t = T causes inﬂation at t = T. Because the nominal interest rate is pegged at zero prior to T, the
increase in inﬂation translates to a low real interest rate between T − 1 and T. This stimulates aggregate spending at

T − 1, contributing to even higher inﬂation at T − 1, which in turn feeds to even higher spending at T − 2, and so
on. Clearly, the cumulative effect at t = 0 increases with T, which explains why the power of forward guidance also
increases with T . Finally, by permitting a greater inﬂation response, a greater degree of price ﬂexibility increases the
potency of this GE mechanism, thus also increasing the effectiveness of monetary policy.
In the standard New-Keynesian model, the aforementioned GE mechanism is captured by the interaction of the
representative household’s Euler condition with the New-Keynesian Philips Curve (NKPC). But there are two additional
GE mechanisms, buried underneath these equations. The one has to do with the feedback from future inﬂation to
current inﬂation: for given real marginal costs, the individual ﬁrm is more willing to raise its nominal price today if
she expects other ﬁrms to do the same in the future. The other has to do with the feedback from aggregate spending

41

to individual spending: when the individual consumer expects other consumers to spend more, she is encouraged to
spend more herself, because her own income increases with aggregate consumption.
The main result in Angeletos and Lian (2016a) is that removing common knowledge of the policy attenuates all the
aforementioned GE effects and, in so doing, limits the policy maker’s ability to stimulate the economy. This result can
be seen as an application of the present paper. Nevertheless, it is worth highlighting three subtleties.
First, the framework used in that paper does not feature the kind of market segmentation assumed in the present
paper: markets are centralized. The desired friction—lack of common knowledge—is then preserved by allowing for
enough sources of uncertainty so that the observed prices do not perfectly reveal the aggregate shock. This underscores
that, although the particular market structure assumed in the present paper permitted a particular speciﬁcation of the
“geography” of information, these particulars are not strictly needed for our insights to apply.
Second, the GE effects featured in that paper have a much richer dynamic structure than those featured in the
present paper. This is because the optimal consumption of an individual household in any given period depends
on the income and the interest rate she expects to face in all future periods—and similarly the optimal reset price
of a ﬁrm depends on the inﬂation and the real marginal costs she expects to face in all future periods. To make an
analogy, think of each future period in that paper as a different kind of “afternoon markets” in the present paper, with
price of each such market entering the demand and supply in the “morning market”. Despite this complexity, a sharp
characterization is possible thanks to the fact that all the relevant GE effects work in the same direction.
Last but not least, because of the aforementioned forward-looking aspects, a new, and context-speciﬁc, prediction
emerges: the documented attenuation is stronger the further into the future the policy operates (i.e., the larger T is).
This is because longer horizons maps to beliefs of higher order, which are themselves more anchored to the common
prior for any given level of informational friction.
Additional applications include Angeletos and Lian (2017) and Angeletos and Lian (2016c). In the former paper,
we explore how lack of common knowledge affects the validity of Ricardian Equivalence and the macroeconomic
effects of shocks to taxes and government spending in both the RBC and the New-Keynesian framework. In the
latter paper, we shift attention to the popular notion—if not the apparent fact—that a drop in consumer spending,
such as the one triggered by a “discount-factor shock” or by deleveraging, can trigger a recession. As noted in the
Introduction, this notion is grounded on solid PE intuitions, yet it ﬁnds no place in the RBC framework because of
countervailing GE effects. In our companion paper, we add an information friction that, not only helps attenuate these
GE effects along the lines suggested by the present paper, but also introduces a feedback mechanism that resembles
the Keynesian multiplier, despite the absence of nominal rigidity. As a result, the modiﬁed RBC model is able, not
only to accommodate the aforementioned notion/fact, but also to disentangle the degree of monetary non-neutrality
from the question of whether and how “demand forces” explain the observed business cycles.48
The earlier works of Angeletos and La’O (2010), Venkateswaran (2014), and Schaal and Taschereau-Dumouchel
(2015) can also be understood as applications of the broader theme of our paper. The ﬁrst paper effectively attenuates
the GE effects of TFP shocks in the RBC model and argues that this helps reconcile that model with the evidence in Gali
(1999). The second paper effectively attenuates the GE effects of TFP shocks in the DMP model and argues that this
helps lessen the “Shimer puzzle” (Shimer, 2005). The third paper effectively attenuates the GE interaction of the ﬁrms in
a variant of the RBC model with non-convex technologies. When TFP shocks are common knowledge, this interaction
is strong enough that multiple equilibria are possible; when instead there is sufﬁcient higher-order uncertainty about
the underlying TFP shocks, this interaction gets weakened enough that a unique equilibrium is selected.
Finally, although all the applications discussed above are conﬁned to macroeconomics, the insights we have developed are applicable in other ﬁelds as well. For instance, if one re-interprets our model as one applying to an industry
48 This does not mean that we favor models that feature monetary neutrality. We only wish to contrast with the New-Keynesian framework, which
prohibits the aforementioned kind of disentangling.

42

as opposed to a whole economy, one obtains a theory of the attenuation of the equilibrium effects of industry-wide demand and supply shocks, or of regulatory reforms. This may, inter alia, help shed light on the evidence in Greenwood
and Hanson (2015) and Doraszelski, Lewis, and Pakes (2017).
Consider ﬁrst Greenwood and Hanson (2015). This paper documents the cycles of the dry bulk shipping industry
and interprets these cycles as the outcomes of a model in which ﬁrms neglect a GE effect, namely, the endogenous
response of their competitors’ investment choices and of the future price to the exogenous, industry-wide, demand
shocks. This assumption borrows from the “competition neglect” discussed, informally, in Camerer and Lovallo (1999)
and Kahneman (2011). In the light of our results, this effect can be rationalized by allowing the ﬁrms to lack common
knowledge of the underlying industry-wide shocks. By the same token, the evidence in Greenwood and Hanson
(2015) may be consistent with an incomplete-information extension of Kalouptsidi (2014).
Consider next Doraszelski, Lewis, and Pakes (2017). This paper documents the empirical response of the UK
electricity industry to a market reform and interprets this response as the product of an off-equilibrium adjustment,
namely, of a form of learning about how to play the complete-information Nash equilibrium. In the light of our results,
the observed dynamics could also be reconciled with rational expectations once one allows for lack of common
knowledge. This conjecture appears to be consistent with Bonatti, Cisternas, and Toikka (2017).
To sum up, we hope that the examples discussed in this subsection indicate, not only the broad applicability of the
insights and of the perspective developed in this paper, but also the added value of exploring speciﬁc applications:
such applications can deliver concrete empirical predictions and useful policy lessons, which are not possible in the
present paper due to the assumed level of abstraction.
We close this section by making an additional observation, which may help further guide future empirical or quantitative work. The GE attenuation mechanism we have studied in this paper has distinct empirical implications from
adjustment costs, habit, liquidity constraints, sparsity, and any other friction that affect individual behavior (decision
rules). Such frictions ought to manifest in the response of individual outcomes to idiosyncratic shocks. Our mechanism,
by contrast, keeps these micro-level responses constant and modiﬁes only the macro-level responses by attenuating, or
slowing down, the relevant GE effects. Our mechanism may thus help explain, inter alia, why hump-shaped impulse
responses appear to be more pronounced in macroeconomic time series that in micro data.

10

Conclusion

General-equilibrium effects that operate at the economy-wide level are central to understanding the response of
macroeconomic outcomes to aggregate shocks, as well as to policy interventions. Such effects limit the usefulness of
partial-equilibrium intuitions. They also introduce a gap between the macroeconomic effects of interest and the kind
of micro or local elasticities that are estimated in a growing empirical literature.
In this paper, we sought to operationalize the notion that general-equilibrium effects may be less potent, or may
take more time to build force, than what is often presumed in applied research. To this goal, we built on existing
insights, but also blended them in a new—and hopefully insightful—manner.
We considered an elementary Walrasian economy, in which trading was sequential and decentralized. We ﬁxed
the microeconomic foundations in terms of the speciﬁcation of preferences, technologies, and market structures; in so
doing, we also ﬁxed the relevant demand and supply functions. We next characterized the response of this economy
to an aggregate shock under a benchmark speciﬁcation that, in line with the vast majority of applied work, imposed
rational expectations along with common knowledge of the aggregate shock. We then departed from that benchmark
in two distinct ways. In the one, we dropped the rational expectations solution concept in favor of certain kinds of
bounded rationality. In the other, we maintained the rational expectations solution concept but removed common
knowledge of the aggregate shocks.
43

We explored the similarities and the differences of the two approaches and brought multiple strands of literature
under the same umbrella. We concluded that, although all the considered variants can help accommodate the soughtafter notion of GE attenuation, the one that maintains rational expectations and removes common knowledge of the
aggregate shock appears to do so in a more natural and more structured manner (at least in our view). We also
emphasized that this variant does not require a literal interpretation of the informational friction; as in Sims (2003) and
Tirole (2015) and elsewhere, the assumed higher-order uncertainty can be a representation of the cognitive constraints
an agent faces when trying to forecast, or comprehend, the reaction of other agents to the underlying aggregate shock.
Our framework was deliberately simple and abstract. The intended goals were to simplify the analysis and to
deliver the key insights in a transparent and ﬂexible manner. The obvious cost is that the assumed level of abstraction
prevented any concrete application. We thus view the contribution of the present paper as a “proof of concept”
and explore a few applications in companion work (Angeletos and Lian, 2016a,c, 2017). In these applications, we
adopt the approach that maintains rational expectations but allows for incomplete information. As explained here,
the alternatives considered in Garcıa-Schmidt and Woodford (2015), Gabaix (2016b), and Farhi and Werning (2017)
are complementary, even though they do not share the exact same restrictions as our preferred approach.
All in all, we hope that our paper has shed new light on the sensitivity of the predictions of general-equilibrium
models to plausible relaxations of either the rational-expectations solution concept or the conventional but unrealistic
assumption that all agents share the same knowledge about the current state of the economy and the same beliefs about
its future prospects. Perhaps there is more to “simplistic” partial-equilibrium intuitions than the general-equilibrium
theorist is trained to see. Perhaps the macroeconomist should question how much her favorite structural interpretation
of the business cycle depends on general-equilibrium mechanisms that are sensitive in the respects we have highlighted
in this paper. And perhaps the policy maker should put more emphasis on policies that work through salient PE effects,
as opposed to multi-layer GE effects, if she wishes to steer the economy in the short run.49

49 The

last point is related to the rationale we provide in our companion work for “front loading” ﬁscal and monetary policy.

44

Appendix A. Connection to Empirical Work
Recently, there has been a boom of empirical research trying to gauge the macroeconomic effects of aggregate shocks
by exploiting the cross-sectional heterogeneity in the exposure of different geographical regions to these shocks. Important examples include Mian and Suﬁ (2012, 2014) and Beraja, Hurst, and Ospina (2016) in the context of the Great
Recession, and Nakamura and Steinsson (2014) in the context of ﬁscal multipliers. At the risk of overreaching, we
brieﬂy discuss how our analysis can be connected to this line of empirical work.
The type of empirical exercises conducted in these works can be represented in our baseline framework as follows.
Suppose that the data contain observations of ∆θ̄, the aggregate shock of interest, as well as ∆q̄, the corresponding
change in the outcome of interest.50 Suppose further that, apart from the shock of interest, there are other shocks that
are neither of interest to, nor observed by, the econometrician. It follows that
(48)

∆q̄ = ϵM acro ∆θ̄ + ε,
where ϵM acro is the macro elasticity of interest and ε is residual that captures the other shocks.

Clearly, an unbiased estimate of ϵM acro can be extracted from aggregate times series only if ε is uncorrelated with

∆θ̄ or if the econometrician has an instrument for ∆θ̄ that is itself uncorrelated with ε. In practice, these conditions are
rarely met. To overcome this limitation, the aforementioned works shift focus to the cross section and offer a credible
instrument for the differential exposure of different regions to the shock. There is, however, an important caveat: what
is actually estimated is a certain kind of micro elasticity, rather than the macro elasticity of interest.
To see this more clearly, suppose that a marketplace in the theory corresponds to a region in the data (say, a ZIP
code or a metropolitan area). The change in the regional outcome of interest can then be expressed as follows:

∆qm =

∂Q
∂Q ∂P
(δm ∆θ̄ + ζm ) + ∗
∆θ̄ + (ε + ξm ) ,
∂θ
∂p ∂θ

where ε and ξm capture, respectively, the aggregate and the idiosyncratic effects of the other, unobserved, shocks.
Using the facts that

∂Q
∂θ

= PE = ϵmicro and

∂Q ∂P
∂p∗ ∂θ

= GE = ϵM acro − ϵmicro , we can restate the above as

∆qm = ϵmicro δm ∆θ̄ + η + vm ,
where

η ≡ ε + (ϵM acro − ϵmicro )∆θ̄

and

vm ≡ ξm + ϵmicro ζm .

Since η is common to all regions, it is subsumed by the constant in a cross-sectional regression or, if we have longer
data, by the time ﬁxed effect in a panel regression. Having a credible instrument for the differential exposure to
the aggregate shock of interest means that, once the time ﬁxed effect has been partial out, the available instrument
covaries with δm ∆θ̄ but not with the residual vm . This permits the econometrician to obtain an unbiased estimate of

ϵmicro , which is valuable—but unless the gap between ϵM acro and ϵmicro happens to be small, this estimate gives little
information about ultimate object of interest, namely about the macroeconomic effect of ∆θ̄.
This epitomizes the conundrum faced by the aforementioned line of empirical work: allowing for a time ﬁxed effect
in the relevant regressions partials out, not only the concurrent shocks that contaminate the aggregate time series, but
also the GE effects of the shock of interest. In this paper, we provide a potential resolution to this conundrum: by
offering a rationale for why at least some of these GE effects may be impotent in the short run, we reduce the gap
between the object that is of interest and the one that is actually estimated in the aforementioned work.
50 For the purposes of the present discussion, one can think of the econometrician observing θ̄ and q̄ at multiple points of time, each of which
correspond to a different morning in an appropriate multi-period version of our framework. See Section 8 for such an extension.

45

Remark 1. The above discussion has assumed that a “marketplace” in our theory coincides with a “region” in the
data (that is, with the relevant level of observation in the available cross-sectional data). In the absence of such a
coincidence, the mapping between the theory and the data is more nuanced. However, provided that any two agents
who live in the same region are more likely to participate in the same markets than any two agents from different
regions, the essence of the conveyed message to survive.
Remark 2. The above discussion has also assumed that the micro elasticity is the same across all regions. In
empirical work, this assumption is often relaxed. Our point remains valid provided that one reinterprets ϵmicro as the
appropriate cross-sectional average of the regional elasticities.
Remark 3. The aforementioned empirical literature often emphasizes differential effects of the same shock on
different kinds of economic outcomes, such as employment in tradable versus non-tradable sectors in the case of Mian
and Suﬁ (2014). The points made above apply regardless: for each of the considered outcomes, the aforementioned
work estimates a local, or micro, elasticity.

Appendix B. Proofs
Proof of Lemma 1.

Consider a ﬁrm i that trades in markets m and m′ in, respectively, the morning and the afternoon.

Because the technology is convex, the following conditions are necessary and sufﬁcient for optimality:

[
Êm

]
∂Γ
∗
(qi , qi ; θm ) = pm ,
∂q

∂Γ
(qi , qi∗ ; θm ) = p∗m′ ,
∂q ∗

(49)

(50)

where Êm [·] denotes subjective—potentially irrational—belief of agents who trade in market m in the morning (By
Assumption 2, agents in the same market share the same belief in the morning.)
Now, consider the optimal behavior of a household i that trades in markets m and m′ in, respectively, the morning
and the afternoon. It is pinned down by the solution to the following ﬁrst-order conditions together with the budget
constraint (3):

[
Êm

]
∂U
(ci , c∗i ; θm ) = pm ,
∂c

∂U
(qi , qi∗ ; θm ) = p∗m′ .
∂c∗

(51)
(52)

As in the main text, we henceforth re-interpret all the variables as log-deviations from a symmetric steady state (in
which all marketplaces have the same fundamentals) and work with the log-linearized demand and supply system.
Solving and (log-linearizing) conditions (50) and (52), we can ﬁnd linear functions D∗ and S ∗ that characterize
individual supply and demand in the afternoon:

c∗i = D∗ (ci , p∗m′ , θm )

and

qi∗ = S ∗ (qi , p∗m′ , θm ) .

By individual rationality, we can then substitute the previous condition into conditions (49) and (51). We can ﬁnd
linear functions D and S that character supply and demand in the morning:

(
)
cm = ci = D pm , Êm [p∗m′ ], θm

and

(
)
qm = qi = S pm , Êm [p∗m′ ], θm ,

where we use the fact that consumers (ﬁrms) of any given marketplace m are identical in the morning.

46

Now let us consider the demand and supply in any afternoon market m. Note that the demand in afternoon market

m has two components: one reﬂecting the agents who were in this market from the morning; and another reﬂecting the
agents who were relocated from other markets. The former have mass ρ and their demand is given by D∗ (cm , p∗m , θm ) ;
(
)
∫
the latter have mass 1 − ρ and their average demand is given D∗ (cm′ , p∗m , θm′ ) dm′ = D∗ c̄, p∗m , θ̄ . As a result,

(
)
c∗m = ρD∗ (cm , p∗m , θm ) + (1 − ρ)D∗ c̄, p∗m , θ̄ .
The same logic applies on the supply side.
From the main text, we know the average market clearing price, p̄∗ , in the afternoon is given by

Proof of Lemma 2.

p̄∗ = P ∗ (q̄, θ̄). The aggregate quantity of afternoon goods is then given by
q̄ ∗ =

∫

(
)
{ρD∗ (qm , p∗m , θm ) + (1 − ρ)D∗ (q̄, p∗m , q̄)} dm = D∗ q̄, p̄∗ , θ̄ = Q∗ (q̄, θ̄),

(
)
where Q∗ (q̄, θ̄) ≡ D∗ q̄, P ∗ (q̄, θ̄), θ̄ for all (q̄, θ̄).
Now we consider the afternoon outcome for a particular market m. Let p∗m = ρP ∗ (qm , θm ) + (1 − ρ) p̄∗ . Because

N ∗ is linear, from condition (6) we have
(
)
n∗m = N ∗ ρqm + (1 − ρ) q̄ , ρP ∗ (qm , θm ) + (1 − ρ) p̄∗ , ρθm + (1 − ρ) θ̄ .
(
)
= ρN ∗ (qm , P ∗ (qm , θm ) , θm ) + (1 − ρ) N ∗ q̄, p̄∗ , θ̄
= 0,
which means that the aforementioned value for p∗m clears the afternoon market. Because N ∗ (·, p∗ , ·) is decreasing in

p∗ , the aforementioned value for p∗m is the unique market-clearing price. The corresponding quantity is then given by
(
)
∗
∗
qm
= ρD∗ (qm
, p∗m , θm ) + (1 − ρ) D∗ q̄, p∗m , θ̄
(
)
= ρD∗ (qm , P ∗ (qm , θm ) , θm ) + (1 − ρ) D∗ q̄, P ∗ (q̄, θ̄), θ̄
= ρQ∗ (qm , θm ) + (1 − ρ) Q∗ (q̄, p̄∗ ) ,
where Q∗ is deﬁned as before.
Proof of Lemma 3.

Using conditions (9), (11) and the linearity of Q̃, we have

)
(
) (
qm = ρ2 Q̃ (P ∗ (qm , θm ) , θm ) + 1 − ρ2 Q̃ Êm [p̄∗ ] , θm .
∗

Suppose ρ2 α̃ = ρ2 ∂P
∂q

∂ Q̃
∂p∗

̸= 1. The above then has a unique solution in qm , given by
(
)
qm = Q Êm [p̄∗ ] , θm ,

where Q is a linear function deﬁned implicitly so that, for all (p∗ , θ) ,

(
)
Q (p∗ , θ) = ρ2 Q̃ (P ∗ (Q (p∗ , θ) , θ) , θ) + 1 − ρ2 Q̃ (p∗ , θ) .

47

(53)

Similarly, using conditions (9), (11), and the linearity of P̃ , we have

(
)
(
)
pm = P̃ ρ2 P ∗ (qm , θm ) + 1 − ρ2 Êm [p̄∗ ] , θm
(
(
) (
)
)
= P̃ ρ2 P ∗ Q(Êm [p̄∗ ] , θm ), θm + 1 − ρ2 Êm [p̄∗ ] , θm
(
)
≡ P Êm [p̄∗ ] , θm .

(54)

By aggregation, we then have

(∫
q̄ = Q

∗

)

(∫
and

Êm [p̄ ] dm, θ̄

p̄ = P

∗

)

Êm [p̄ ] dm, θ̄ .

Finally, from Assumption 4, agents in the economy can do the above reasoning. As a result, Lemmas 2 (in particular
functions (Q, P, Q∗ , P ∗ )) and 3 are known to the agents.
Proof of Proposition 1.

Let us ﬁrst prove condition (15) in the main text. First, as T (p∗ , θ) ≡ P ∗ (Q (p∗ , θ) , θ) for all

(p∗ , θ), we have

∂T
∂P ∗ ∂Q
=
.
∗
∂p
∂q ∂p∗

(55)

From the deﬁnition of Q in condition (53), we have

∂Q
1 − ρ2 ∂ Q̃
=
.
∂p∗
1 − α̃ρ2 ∂p∗

(56)

Together with condition (55), we have

∂T
1 − ρ2 ∂P ∗ ∂ Q̃
1 − ρ2
=
=
α̃.
∗
2
∗
∂p
1 − α̃ρ ∂q ∂p
1 − α̃ρ2
This ﬁnishes the proof of condition (15) in the main text. Together with Assumption 5 and the fact ρ ∈ [0, 1), we have

−1 < α =

1 − ρ2
α̃ < 1.
1 − α̃ρ2

As a result, T is a contraction mapping. The unique solution of condition (14) can then be represented as

E[p̄∗ ] = P(θ̄),
where P(θ) is a linear function such that

P(θ) = T (P(θ), θ)

∀θ.

(57)

This ﬁnishes the proof of part (i) of the Proposition. Part (ii) can then be derived from Lemmas 2 and 3,.
Proof of Proposition 2.

Use condition (17) and consider the change relative to its pre-shock value, we have

( )
∆qm = Q(P ∆θ̄ , ∆θm ),

(58)

( )
∆q̄ = Q(P ∆θ̄ , ∆θ̄) ≡ ϵM acro ∆θ̄,

(59)

48

where

ϵM acro =

∂Q
∂Q ∂P
+ ∗
.
∂θ
∂p ∂θ

(60)

Subtracting condition (59) from condition (58), we have

(
)
∆qm = ∆q̄ + ϵmicro ∆θ̄m − ∆θ̄ ,
where

ϵmicro =
Proof of Corollary 1.
Proof of Lemma 4.
∗

∂N ∂Q
∂q ∂p∗

+

∗

∂N
∂p∗

∂Q
.
∂θ

(61)

The Proposition follows from conditions (60) and (61), and the fact that

∫

δm dm = 1.

Let us prove ﬁrst that N (p∗ , ·) is decreasing in p∗ . First, by deﬁnition of N , we have

∂N
∂p∗

=

. Then, by condition (56), we have
∂N
1 − ρ2 ∂N ∗ ∂ Q̃
∂N ∗
=
+
.
∗
2
∗
∂p
1 − α̃ρ ∂q ∂p
∂p∗

(62)

Moreover, by taking partial derivatives with respect to q in the deﬁnition of P ∗ , condition (7), we have

∂N ∗
∂N ∗ ∂P ∗
+
= 0.
∂q
∂p∗ ∂q
Together with condition (62), we have

∂N ∗
∂N
=
∂p∗
∂p∗

(
)
1 − ρ2
∂N ∗
1−
α̃
=
(1 − α) .
1 − α̃ρ2
∂p∗

From Assumption 5 and the fact that N ∗ (·, p∗ , ·) is decreasing in p∗ , we have

∂N
∂p∗

< 0. This proves that N (p∗ , ·) is

decreasing in p∗ .

(
)
(
)
(
)
Now we turn to the proof of Lemma 4. First note that N P̂ ∗ (t), θ̄new = N P̂ ∗ (t), θ̄new − N p̄∗new , θ̄new =
(
)
∂N
∗
∗
P̂
(t)
−
p̄
. Then, from condition (18), we have
∗
new
∂p
(
)
d P̂ ∗ (t) − p̄∗old
dt

=

)
)
∂N (( ∗
P̂ (t) − p̄∗old − (p̄∗new − p̄∗old )
∗
∂p

∀t ≥ 0.

Together with P̂ ∗ (0) = p̄∗old , we have

)
(
∂N
P̂ ∗ (t) − p̄∗old = (p̄∗new − p̄∗old ) 1 − e ∂p∗ t .
As a result,
∂N

w(T ) = 1 − e ∂p∗ T .

(63)

Therefore, w(T ) is continuous strictly increasing in T , w(0) = 0 and limT →∞ w(T ) = 1.
Proof of Proposition 3.
and ϵM acro − ϵmicro =

The Proposition follows directly from condition (21), Lemma 4, and the fact that ϵmicro =
∂Q ∂P
∂p∗ ∂θ .

49

∂Q
∂θ

Proof of Lemma 5.

The Lemma follows directly from taking average expectations of both sides of condition (28).

Proof of Corollary 2.

Iterating condition (28), we have

p̄∗ =

)h−1
∞ (
[ ]
∂T ∑ ∂T
Ē h−1 θ̄ ,
∗
∂θ
∂p

(64)

h=1

[ ]
where for notational simplicity we let Ē 0 θ̄ = θ̄. Taking derivatives with respect to θ̄ in the deﬁnition of P , condition
(57), and using condition (15), we have

∂T
∂P
= (1 − α)
= γ (1 − α) .
∂θ
∂θ

(65)

Substituting into condition (64), we have

p̄∗ = γ (1 − α)

∞
∑

[ ]
αh−1 Ē h−1 θ̄ .

h=1

Taking average expectation of both sides of the previous expression, Corollary 2 is then proved.
Proof of Lemma 6.

Substituting condition (24) into condition (30), we have

Ē [p̄∗ ] = γ θ̄old +

γ (1 − α) λ
∆θ̄ = p̄∗old + π(λ) (p̄∗new − p̄∗old ) ,
1 − αλ

where

π(λ) =

(1 − α) λ
.
1 − αλ

(66)

For −1 < α < 1, π is continuous and strictly increasing in λ, with π(0) = 0 and π(1) = 1.
Proof of Proposition 4.
Proof of Corollary 3.

The result follows directly from condition (26) and Lemma 6.
To prove part (i), note that for any T ∈ (0, ∞), there exists a unique λ ∈ (0, 1) such that

w (T ) = π(λ). This is because (i) w is continuous and strictly increasing in T, with w(0) = 0 and limT →∞ w(T ) = 1
and (ii) π is continuous and strictly increasing in λ, with π(0) = 0 and π(1) = 1. The Corollary then directly follows
from conditions (19), (22), (31) and (32).
To prove part (ii), similarly, note that for any λ ∈ (0, 1), there exists a unique T ∈ (0, ∞) such that π(λ) = w (T ).
The Corollary then directly follows from conditions (19), (22), (31) and (32).
Proof of Proposition 5.

Substituting condition (27) into condition (25), we have

(
)
qm = BR θm , Em [θ̄], Em [q̄] ,
where

BR (θm , θ, q) = Q (P ∗ (q, θ), θm ) ∀ (θm , θ, q) .
This proves part (i) of the Proposition.

50

Taking partial derivatives with respect to q in the above condition, together with condition (55), we have

∂BR
∂P ∗ ∂Q
∂T
=
= ∗ = α.
∂q
∂q ∂p∗
∂p
This proves part (iii) of the Proposition.

(
)
(
)
Now let us try to prove part (ii) of the Proposition. If q̄ = BR θ̄, Ē[θ̄], Ē[q̄] = Q P ∗ (Ē[q̄], Ē[θ̄]), θ̄ and p̄∗ =

P ∗ (q̄, θ̄), we have

[ ]
Ē[p̄∗ ] = P ∗ (Ē [q̄] , Ē θ̄ ),
(
)
p̄∗ = P ∗ (q̄, θ̄) = P ∗ (Q Ē[p̄∗ ], θ̄ , θ̄) = T (Ē[p̄∗ ], θ̄).

Conversely, if p̄∗ = T (Ē[p̄∗ ], θ̄) and q̄ = Q(Ē[p̄∗ ], θ̄), we have

( )
(
)
P ∗ q̄, θ̄ = P ∗ Q(Ē[p̄∗ ], θ̄), θ̄ = T (Ē[p̄∗ ], θ̄) = p̄∗ .
As a result,

(
)
P ∗ Ē[q̄], Ē[θ̄] = Ē[p̄∗ ].

Finally, from q̄ = Q(Ē[p̄∗ ], θ̄), we have

(
)
(
)
q̄ = Q P ∗ (Ē[q̄], Ē[θ̄]), θ̄ = BR θ̄, Ē[θ̄], Ē[q̄] .
This ﬁnishes the proof.
Proof of Proposition 6.

From conditions (32) and (34), we have

ϵM acro
1
=
,
micro
ϵ
1−α
ϵInc
ϵM acro

=

α micro
ϵmicro + π(λ) 1−α
ϵ
1
micro
1−α ϵ

=

α
1 + π(λ) 1−α
1
1−α

= (1 − α) +

(1 − α) αλ
1−α
=
.
1 − αλ
1 − αλ

The result is then immediate.
Proof of Lemma 7.

Because T 0 (p̄∗old , θ̄new ) = p̄∗old , we have g0 = 0. Now proceed by induction. Suppose for k ≥ 0,

we have p̂∗k = p̄∗old + gk (p̄∗new − p̄∗old ) . For k + 1, we have

p̂∗k+1 = T k+1 (p̄∗old , θ̄new )
= T (p̂∗k , θ̄new )
= p̄∗old +

)
∂T
∂T (
gk (p̄∗new − p̄∗old ) +
θ̄new − θ̄old
∗
∂p
∂θ

= p̄∗old + (αgk + (1 − α)) (p̄∗new − p̄∗old ) ,
where the last equation uses the fact that

p̄∗new − p̄∗old

=

∂T
)
(
)
∂P (
θ̄new − θ̄old ,
θ̄new − θ̄old = ∂θ
∂θ
1−α

51

(67)

according to condition (65). As a result, we have

p̂∗k+1 = p̄∗old + gk+1 (p̄∗new − p̄∗old ) ,
where

gk+1 = αgk + (1 − α) .

(68)

This proves part (i) in the Lemma 7.
To prove parts (ii) and (iii), from condition (68) and the fact that g0 = 0, we have, for all k ≥ 0,

(
gk = (1 − α)

1 − αk
1−α

)
= 1 − αk .

(69)

From this formula, it is easy to see that limk→∞ gk = 1. Moreover, if α > 0, the sequence is strictly increasing and
bounded between 0 and 1. Finally, if instead α < 0, this sequence is non-monotone, with gk < 1 whenever k is even
and gk > 1 whenever k is odd.
Proof of Proposition 7.

From part (i) of Deﬁnition 3, we have

qm = Q (p̂∗ , θm )

and

(
)
q̄ = P p̂∗ , θ̄ .

Then, this proposition follows directly from Lemma 7.
Proof of Proposition 8.

From part (ii) of the Deﬁnition 4, we have, for all k ≥ 0,

(
)
qm = Q Êm [p̄∗ ], θm

and

(
)
q̄ = P Êm [p̄∗ ], θ̄ ,

where Êm [p̄∗ ] = P ∗ (BRk (θ̄new , θ̄new , q̄old ), θ̄new ) = P ∗ (q̂k , θ̄new ). Note that, for k ≥ 1, we have

(
)
P ∗ (q̂k , θ̄new ) = P ∗ (BR θ̄new , θ̄new , q̂k−1 , θ̄new )
(
)
= P ∗ (Q P ∗ (q̂k−1 , θ̄new ), θ̄new , θ̄new )
= T (P ∗ (q̂k−1 , θ̄new ), θ̄new )
= ···
= T k (P ∗ (q̂0 , θ̄new ), θ̄new )
= T k (P ∗ (q̄old , θ̄new ), θ̄new ).

(70)

Now we consider two cases.
(i) If P ∗ (q̄, θ̄) is invariant to θ̄, we have P ∗ (q̄old , θ̄new ) = p̄∗old . As a result, Êm [p̄∗ ] = T k (p̄∗old , θ̄new ). This is exactly
the conjecture in condition (35) in the deﬁnition of Cobweb(k ) solution. The level-k solution and the Cobweb(k )
solution impose the same price conjectures and give rise to the same observables.
(ii) If we modify the Cobweb solution concept so that the initial price conjecture is given by p̂0 = P ∗ (q̄old , θ̄new ).
Then the RHS of the conjecture in condition (35) in the deﬁnition of Cobweb(k ) solution becomes exactly equal to

T k (P ∗ (q̄old , θ̄new ), θ̄new ) = P ∗ (q̂k , θ̄new ).

52

As a result, the level-k solution and the Cobweb(k ) solution impose the same price conjectures and give rise to the
same observables.
Proof of Corollary 4.

The result follows from Proposition 7 and case (i) in the proof of Proposition 8.

(
)
From Deﬁnition 5, condition (67) and the fact T p̄∗old , θ̄old = p̄∗old , we have, for all t ≥ 0,

Proof of Proposition 9.

(
)
d P̂ ∗ (t) − p̄∗old
dt

(

)(
) ∂T (
)
∂T
−
1
P̂ ∗ (t) − p̄∗old +
θ̄new − θ̄old
∗
∂p
∂θ
)
)
((
= − (1 − α) P̂ ∗ (t) − p̄∗old − (p̄∗new − p̄∗old ) .
=

Together with P̂ ∗ (0) = p̄∗old , we have

(
)
P̂ ∗ (t) − p̄∗old = (p̄∗new − p̄∗old ) 1 − e−(1−α)t .
As a result, we have, in the reﬂective equilibrium economy,

p̂∗ = p̄∗old + wref (T ) (p̄∗new − p̄∗old ) ,

(71)

(
)
in which wref (T ) = 1 − e−(1−α)T . Together with Lemma 4 and condition (63), we have, for any T ≥ 0, there exists
a T ′ such that the level-T reﬂective equilibrium conjecture p̂∗ coincides with the Tâtonnement(T ′ ) conjecture p̂∗ ,
and vice versa. Given part (i) of both Deﬁnition (5) and Deﬁnition (1), the level-T reﬂective equilibrium also shares
the same economic outcomes with the Tâtonnement(T ′ ) solution. The equivalence with the incomplete-information
variant then follows from Corollary 3.
Proof of Proposition 10.

T

(p̄∗old , θnew )

We ﬁrst prove condition (41). From condition (40) together with the fact that p̄∗old =

= 0, we have p̂∗ − p̄∗old = µT (p̂∗ − p̄∗old , ∆θ̄). Iterating, we have
∗

p̄ −

p̄∗old

= γ (1 − α)

∞
∑

αh−1 µh ∆θ̄ =

h=1

where γ =

∂P
∂θ

=

∂T
∂θ

1−α ,

γ (1 − α) µ
∆θ̄ = π (µ) (p̄∗new − p̄∗old ) ,
1 − αµ

as deﬁned in condition (65), and where π (µ) =

(1−α)µ
1−αµ

is the same function as the one deﬁned

in Lemma 6. This proves condition (41).
Then, from conditions (31) and (41), we know, for any Gabaix-like variant with discount µ ∈ (0, 1), there exists
an incomplete-information economy with parameter λ = µ such that, for any realization of ∆θ̄, the average rational
expectation Ē [p̄∗ ] in the latter coincides with the irrational conjecture p̂∗ in the former. Then, the two economies
predict the same observable change in q̄ from Lemma 3. The converse can be proved similarly.
Proof of Lemma 8.

Fix a period t and a marketplace m. Because of the linearity of preferences in consumption, we

can express the optimal (log-linearized) choices of any household i ∈ I(m, t) as follows:

ni,t = η1 wm,t

and

]
[
ki,t = θm + ϕ1 Êm,t pM (i,t+1),i,t+1 .

(72)

The ﬁrst part of this condition gives the optimal supply of labor; the second condition is the Euler condition and
characterizes optimal capital accumulation. As households in the same marketplace share the same belief, we have,

53

for all i ∈ I (m, t), ni,t = ℓm,t and

∫
ki,t = km,t ≡

(73)

ki,t di.
i∈I(m,t)

Turning to the local ﬁrm, we have

wm,t = qm,t − ℓm,t ,
where pm,t =

∫
i∈I(m,t)

pm,t = qm,t − κm,t

pm,i,t − pm,t =

and

1
σ

(κm,t − ki,t−1 ) ,

(74)

pm,i,t di is the (log-linearized) ideal price index for the capital composite in marketplace m.

The ﬁrst part of the above condition gives the ﬁrm’s demand for labor; the second part gives its demand for the capital
composite; the third part gives its demand for each particular capital variety.
By imposing market clearing in the labor market, and using the household’s supply of labor and the ﬁrm’s demand
for labor, we get

ℓm,t =

1
1+η qm,t

and

wm,t =

η
1+η qm,t .

(75)

By the production function, on the other hand, we have qm,t = ωκm,t + (1 − ω)ℓm,t . It follows that
(76)

qm,t = ψκm,t ,
where ψ ≡

(1+η)ω
η+ω

∈ (0, 1). By the ﬁrm’s demand for the capital composite, we then get
pm,t = −χκm,t ,

where χ ≡

η(1−ω)
η+ω

(77)

∈ (0, 1). Combing the above results, we infer that the local capital stock κm,t is a sufﬁcient statistic

for local quantities and local prices. By the same token, the aggregate investment in period t − 1 (which is the capital
stock in period t) is a sufﬁcient statistic for aggregate outcomes in period t.
∫
∫
Let q̄t ≡ qm,t dm and ℓ̄t ≡ ℓm,t dm denote the aggregate levels of, respectively, output and employment; let
∫
∫
w̄t ≡ wm,t dm and p̄t ≡ pm,t dm denote, respectively, the average wage and the average price of capital; and ﬁnally
∫
∫
let k̄t−1 ≡ km,t−1 dm = κm,t dm denote the aggregate investment in period t−1 (with the convention that k̄−1 = 0).
We know there exists a known linear vector function F such that, for every m and every t,
and

(qm,t , ℓm,t , wm,t , pm,t ) = F (κm,t )

(q̄t , ℓ̄t , w̄t , p̄t ) = F (k̄t−1 ).

Note that this characterization has relied only on Assumptions 1–3. This mirrors the characterization of the “afternoon outcomes” in our baseline model. We next use the above results together with Assumption 4 to characterize
the optimal investment choices. This mirrors the characterization of the “morning outcomes”.
Fix a period t and a marketplace m, consider any household i ∈ I(m, t), and let m′ = M (i, t + 1) denote the
location of that household in period t + 1. Thanks to Assumption 4, the household can reason that, regardless of what

m′ turns out to be, the price for her own capital will satisfy
pm′ ,i,t+1 = pm′ ,t+1 +

1
σ

(
(κm′ ,t+1 − ki,t ) = 1 −

1
χσ

)

pm′ ,t+1 − σ1 ki,t .

(78)

Next, because a household expects to stay in her current marketplace with probability ρ and to be randomly reallocated
with the remaining probability, her expectation of pm′ ,t+1 must satisfy

Êm,t [pm′ ,t+1 ] = ρÊm,t [pm,t+1 ] + (1 − ρ)Êm,t [p̄t+1 ].

54

(79)

Furthermore, because the household knows that pm,t+1 will satisfy pm,t+1 = −χκm,t+1 , and because the household
also knows that κm,t+1 will be given by mixture of the investment made by the current households in marketplace

m and of the investment made in a random other marketplace (which will become m’s match in period t + 1), the
following is true:

[
]
Êm,t [pm,t+1 ] = −χÊm,t ρkm,t + (1 − ρ) k̄t .

Finally, because the household can reason that all other households in her marketplace choose the same investment
as herself, and because p̄t+1 = −χk̄t , we can re-write that above as follows:

Êm,t [pm,t+1 ] = −χρki,t + (1 − ρ)Êm,t [p̄t+1 ].

(80)

Combining (79) and (80), we infer that

Êm,t [pm′ ,t+1 ] = −ρ2 χki,t + (1 − ρ2 )Êm,t [p̄t+1 ].

(81)

Plugging conditions (78) and (81) into condition (72), we have that, for every household i,

ki,t = θm +

1
ϕ

((

1−

1
χσ

)(

)
)
−ρ2 χki,t + (1 − ρ2 )Êm,t [p̄m+1 ] − σ1 ki,t ,

where m = M (i, t) and m′ = M (i, t + 1). Collecting terms and using the fact that ki,t = km,t , we get51

(

)

km,t = K Êm,t [p̄t+1 ], θm ≡

(

σ−

)

(1 − ρ2 )
σϕ
Êm,t [p̄t+1 ].
θ
+
m
σϕ + σχρ2 + 1 − ρ2
σϕ + σχρ2 + 1 − ρ2
1
χ

(82)

This gives investment as a function of the local fundamental and the local subjective beliefs of the next-period
average return to capital.
Proof of Proposition 11.

We ﬁrst prove conditions (43) and (44), whose derivation were omitted form the main text.

Under the REE concept together with common knowledge of θ̄ and of p̄t , we have that, for all i and all t,

Êm,t [p̄t+1 ] = Et [p̄t+1 ],
where Et denotes the rational expectation conditional on all the information that is commonly available in period t.
Using the above in Lemma 8 and aggregating, we get

(
)
k̄t = K Et [p̄t+1 ], θ̄ .
Because p̄t+1 = −χk̄t , we can rewrite the above as

(
)
p̄t+1 = T Et [p̄t+1 ], θ̄ ,
where T (·) ≡ −χK(·). Since both θ̄ and Et [p̄t+1 ] are commonly known in period t, so is p̄t+1 . We can thus restate
the above as
51 Note

(
)
p̄t+1 = T p̄t+1 , θ̄ ∀t ≥ 0.

that, the denominator, σϕ + (σχ − 1) ρ2 + 1 = σϕ + σχρ2 + 1 − ρ2 > 0.

55

From condition (82), the slope of T is then given by

α≡
where χ =

η(1−ω)
η+ω ,

∂T
(1 − σχ) (1 − ρ2 )
=
,
∂p
σϕ + σχρ2 + (1 − ρ2 )

as deﬁned above. Note then that, since ρ < 1 and σϕ + σχρ2 + (1 − ρ2 ) > 0, we have that α > 0

[resp., α < 0] if and only if σχ < 1 [resp., α > 0].
Now let

ϵmicro =

∂K
σϕ
=
>0
∂θ
σϕ + σχρ2 + 1 − ρ2

and

ϵM acro =

∂K
∂K ∂P
+
.
∂θ
∂P ∂θ

Proposition 11 then follows from condition (45) directly. Furthermore, it is straightforward to check the GE effect is
given by

GE =

∂K ∂P
α micro
=
ϵ
,
∂P ∂θ
1−α

which means that the GE effect ampliﬁes the PE effect (and ϵM acro > ϵmicro ) when α > 0, whereas the opposite is true
when α < 0.52
Proof of Lemma 9.

As discussed in the main text, starting t ≥ 1, it is as if agents each marketplace exchanges its

information with another randomly matched marketplace. As a result, in period t = 1, agents in any marketplace m
will have two independent signals about the aggregate shock ∆θ̄,

sm = ∆θ̄ + vm and sm′ = ∆θ̄ + vm′ ,
where m′ is the marketplace with which m is matched at period t, vm and vm′ are idiosyncratic noise terms, drawn
i.i.d. from N (0, σv2 ). Similarly, in period t = 2, agents in any marketplace m will have 4 signals about ∆θ̄. Two of
them are signals they already receive at t = 1. The other two are new, from the new marketplace with which m is
matched in period t = 2. By induction, it is as if, in period t ≥ 0, each marketplace m have a total of 2t signals of the
form sj = ∆θ̄ + vj , where vj is an idiosyncratic noise term, drawn from N (0, σv2 ). As we have a continuum of markets
but discrete time, the probability of a marketplace receives a “repetitive” signals through the matching place is always

0. We can henceforth view the 2t signals as i.i.d. As a result, we have
Ēt [∆θ̄] = λt ∆θ̄ and Ēt [θ̄] = θ̄old + λt ∆θ̄ ∀t ≥ 0,
where λt =

22t σv−2
22t σv−2 +σθ−2

(83)

and λt → 1 as t → ∞.

Iterating condition (83) by taking average expectations of both sides, we have

Ēth [∆θ̄] = λht ∆θ̄ and Ēth [θ̄] = θ̄old + λht ∆θ̄ ∀t ≥ 0 and h ≥ 1.
This proves parts (i) and (iii) of Lemma 9. To prove part (ii), note that, from Lemma 8, local investment is given by

km,t = K (Em,t [p̄t+1 ] , θm ) ,

(84)

where K is the same function as before and Em,t [·] is the rational expectation conditional on the information that is
available to marketplace m in period t. Together with condition (77), we get the following ﬁxed-point relation between
52 Note

that, as stated in the main text, the underlying parameters are restricted so that α ∈ (−1, 1).

56

the realized price p̄t+1 and the average expectation of it in period t,

(
)
p̄t+1 = T Ēt [p̄t+1 ] , θ̄ ,
where T is the same mapping as deﬁned in condition (43). Similarly to Corollary 2 in our baseline framework, we
can thus express the equilibrium expectations of the price of capital at any given period t as a linear combination of
the contemporaneous hierarchy of beliefs of the underlying fundamentals:

Ēt [p̄t+1 ] = γ(1 − α)

∞
∑

[ ]
αh−1 Ēth θ̄ ,

(85)

h=1

where γ ≡

∂P
∂θ

is the elasticity of the price with respect to θ̄ in the frictionless benchmark and where α ≡

∂T
∂p

is the

slope of the mapping T . Combining this result with Lemma 9, we have

Ēt [p̄t+1 ] = γ θ̄old +
where π(λ) =

(1−α)λ
1−αλ

γ (1 − α) λ
∆θ̄ = p̄old + π (λt ) (p̄new − p̄old ) ,
1 − αλ

is the same as the one in Lemma 6. As noted there, π is continuous and strictly increasing in λ,

with π(0) = 0 and π(1) = 1.
Proof of Proposition 12.

The result follows directly from aggregating condition (84) and Lemma 9.

Proof of Proposition 13.

From the proof of Proposition 11, ϵM acro =

1
micro
.
1−α ϵ

By normalizing ϵM acro = 1, we

have ϵmicro = P E = 1 − α and, similarly, GE = α. From Proposition 12, we have

k̄t = k̄old + {1 − α + π (λt ) α} ∆θ̄ = k̄new −
Let g (α, λ) ≡

α(1−λ)
1−αλ ,

α (1 − λt )
∆θ̄.
1 − αλt

for all α ∈ (−1, 1) and all λ ∈ (0, 1). Note that g (0, λ) = 0 and that |g (α, λ)| increases in |α| for

all λ ∈ (0, 1). As a result, for any t ≥ 0, k̄t is further away from k̄new when |α| is larger.
Proof of Proposition 14.

We ﬁrst prove condition (92). From condition (90), we have

(
)
∂N
P̂ (t) − p̄old = (p̄new − p̄old ) 1 − e ∂p t .
Therefore, for all t,we have that

p̂t+1 = p̄old + wt (p̄new − p̄old ),
with
∂N

wt ≡ 1 − e ∂p f (t) .
Because

∂N
∂p

< 0 and f is positively valued and strictly increasing, we have that wt ∈ (0, 1) for all t and that the

sequence {wt } is strictly increasing.
Now we turn to the proof of Proposition 14. By Lemma 8, the local and the aggregate level of investment is then
give by, respectively,
and

km,t = K (p̂t+1 , θm )

(
)
k̄t = K p̂t+1 , θ̄ ,

(86)

where K is the same function as before. Condition (93) then follows directly from condition (86), Lemma 8 and the
deﬁnition of ϵmicro and ϵM acro in the proof of Lemma 11.
57

Appendix C. A Richer Information Structure
In this appendix, we explain why the lessons of Section 6 extend to much richer information structures.
The representation of our economy as a beauty-contest game permits us to import the following result from Bergemann and Morris (2013): the outcomes generated by any symmetric Gaussian information structure can be replicated
by letting each player (here, each marketplace m) observe the following two signals about ∆θ̄:

sm = ∆θ̄ + vm

and

z = ∆θ̄ + η,

where vm is idiosyncratic noise, drawn from a Normal distribution with mean zero and variance σv2 , i.i.d. across
marketplaces, and independent of both ∆θ̄ and η , and where η is aggregate noise, drawn from a Normal distribution
with mean zero and variance ση2 , independent of ∆θ̄ and {vm }m∈[0,1] . While applied work has often adopted a literal
interpretation of the two signals assumed above as, respectively, private and public signals, the results of Bergemann
and Morris (2013) clarify that such a narrow interpretation is not needed. Instead, the signals assumed above offer a
convenient representation of a much larger class of information structures: by varying the parameters σv2 and ση2 of the
signals assumed above, the analyst can replicate the same joint distribution for (∆qm , ∆q̄, ∆θ̄) as the one implied by
any other set of symmetric Gaussian signals.53 By the same token, the noise η should be interpreted more generally
as a proxy for any correlated source of noise in the information, or beliefs, of the agents.
With these points in mind, we now revisit the results of Section 6 under the information structure assumed above.
First, note that the posterior for ∆θ̄ conditional only on the public signal z is given by

(
)
2
∆θ̄|z ∼ N µθ|z , σθ|z
,
−2
where µθ|z ≡ λz z, σθ|z
≡ σθ−2 + ση−2 , and λz ≡

is given

ση−2

σθ−2 +ση−2

. It follows that the local expectation of ∆θ̄ in marketplace m

Em [∆θ̄] = E[∆θ̄|z, sm ] = (1 − λs ) λz z + λs sm ,
where λs ≡

σv−2
.
−2
σθ|z
+σv−2

(87)

(88)

By aggregating and iterating, we infer that, for all h ≥ 1,

(
)
[(
)
]
(
)
Ē h [∆θ̄] = 1 − λhs λz z + λhs ∆θ̄ = 1 − λhs λz + λhs ∆θ̄ + 1 − λhs λz η.

(89)

Using the above result together with condition (30), we can express the average rational expectation of p̄∗ as follows:

Ē [p̄∗ ] = γ(1 − α)

∞
∑
h=1

(
(
)
(
)
)
[ ]
(1 − α) λs
1 − λs
αh−1 Ē h θ̄ = γ θ̄old +
(1 − λz ) + λz ∆θ̄ +
λz η .
1 − αλs
1 − αλs

From condition (30), we then get

[
(
)
]
(
)
(
)
(1 − α) λs
∂Q
1 − λs
∆q̄ = ϵmicro +
(1 − λz ) + λz ϵM acro − ϵmicro ∆θ̄ + ∗ γ
λz η.
1 − αλs
∂p
1 − αλs
Taking the expectation over the realizations of the noise η , we get
53 This

is true even if some of these signals are endogenous.

58

[
(
)
]
(
)
(1 − α) λs
Ē[∆q̄|∆θ̄] = ϵmicro +
(1 − λz ) + λz ϵM acro − ϵmicro ∆θ̄
1 − αλs
[
( )(
)]
micro
= ϵ
+ π λ̃ ϵM acro − ϵmicro ∆θ̄,
and therefore the elasticity of interest is given by

( )(
)
ϵInco = ϵmicro + π λ̃ ϵM acro − ϵmicro ,
where π is the same function as in Section 6 and where

λ̃ ≡

(1 − α) λs + λz (1 − λs )
∈ (0, 1].
(1 − α) + αλz (1 − λs )

Along with our earlier remark that the information structure assumed above is a convenient representation of any
symmetric Gaussian structure, this completes our argument that the GE effect obtained under any such information
structure can be mapped to the one in obtained in Section 6 for some λ ∈ (0, 1] (namely, for λ = λ̃).

Appendix D. Tâtonnement Dynamics
In this appendix we deﬁne and characterize the Tâtonnement variant that is brieﬂy discussed in Subsection 8.3. Let
( )
( )
N p̄, θ̄ ≡ − χ1 p̄ − K p̄, θ̄ measure the excess aggregate demand for capital that obtains in any given period if both
the average price of capital and the previous-period expectation of it are given by p.54 Next, let the function P̂ (·) be
the solution to the following ODE:

(
)
dP̂ (τ )
= N P̂ (τ ), θ̄new
dτ

∀τ ≥ 0

(90)

with initial condition P̂ (0) = p̄old . Note that P̂ (τ ) is deﬁned in the same fashion as in Deﬁnition 1 and identiﬁes the
price conjecture generated from the Tâtonnement-like cognitive process when its depth, or the number of rounds, is

τ. Finally, specify the period-t conjecture in our dynamic economy as follows:
Êm,t [p̄t+1 ] = p̂t+1 ≡ P̂ (f (t)),

(91)

where f : N → R+ is a function that maps the calendar time to Tâtonnement rounds. This function is assumed to
be strictly increasing—so that more rounds require more time or, conversely, time helps the agents become “deeper
thinkers”—but is otherwise a “free parameter” that controls the speed of adjustment in the relevant conjectures.
This construction yields a simple translation of the analysis in Section 5 to the present framework. In particular, it
is straightforward to check that there exists a strictly increasing sequence {wt }∞
t=0 , with wt ∈ (0, 1) for all t, such that
the period-t conjecture about the period-(t + 1) price of capital satisﬁes

p̂t+1 = p̄old + wt (p̄new − p̄old ).
54 To

(92)

1
understand the formula for N , take any t ≥ 1. From condition (77), the average demand for capital is given by κ̄t = − χ
p̄t . Next, suppose
that all agents expect, in period t − 1, that the period-t average price of capital will be p̄t . Then, from Lemma 8, we have that the average investment
in period t − 1, and therefore also the average supply of capital in period t, is given by k̄t−1 = K(p̄t , θ̄). It follows that the excess demand for
1
capital in period t equals − χ
p̄t − K(p̄t , θ̄), which explains the formula for N used above. For future reference, let us also note that the excess

demand is necessarily downward sloping:

∂N
∂p

1
= −χ
(1 − α) < 0.

59

This is similar to Lemma 4 in our baseline model, except that now the weight w increases with calendar time. Combing the above with Lemma 8, we then obtain the following characterization of the dynamic response of aggregate
investment.
Proposition 14. In the Tâtonnement variant described above, there exists a strictly increasing sequence {wt }∞
t=0 , with

wt ∈ (0, 1) for all t, such that
{
}
k̄t = k̄old + ϵmicro + wt (ϵM acro − ϵmicro ) ∆θ̄, ∀t.

(93)

As explained in the main text, this means that the GE effect is inactive in the short run but builds force as time
passes. The result is illustrated in Figure 4 in the main text, letting f (0) ≈ 0 and f (∞) ≈ 1.

60

References
Akerlof, George A and Janet L Yellen. (1985)a. “Can Small Deviations from Rationality Make Signiﬁcant Differences
to Economic Equilibria?” The American Economic Review 75 (4):708–720.
———. (1985)b. “A Near-rational Model of the Business Cycle, with Wage and Price inertia.” The Quarterly Journal
of Economics 100 (Supplement):823–838.
Allen, Franklin, Stephen Morris, and Andrew Postlewaite. (1993). “Finite Bubbles with Short Sale Constraints and
Asymmetric Information.” Journal of Economic Theory 61 (2):206–229.
Angeletos, George-Marios, Fabrice Collard, and Harris Dellas. (2014). “Quantifying Conﬁdence.” NBER Working
Paper No. 20807 .
Angeletos, George-Marios and Jennifer La’O. (2009). “Incomplete Information, Higher-order Beliefs and Price Inertia.”
Journal of Monetary Economics 56:S19–S37.
———. (2010). “Noisy Business Cycles.” In NBER Macroeconomics Annual 2009, Volume 24. University of Chicago
Press, 319–378.
———. (2013). “Sentiments.” Econometrica 81 (2):739–779.
Angeletos, George-Marios and Chen Lian. (2016)a. “Forward Guidance without Common Knowledge.” NBER Working
Paper No. 22785 .
———. (2016)b. “Incomplete Information in Macroeconomics: Accommodating Frictions in Coordination.” Handbook of Macroeconomics 2:1065–1240.
———. (2016)c. “A (Real) Theory of Keynesian Multipliers.” MIT mimeo .
———. (2017). “Fiscal Policy without Common Knowledge.” Work in progress .
Angeletos, George-Marios and Alessandro Pavan. (2007). “Efﬁcient Use of Information and Social Value of Information.” Econometrica 75 (4):1103–1142.
Beraja, Martin, Erik Hurst, and Juan Ospina. (2016). “The Aggregate Implications of Regional Business Cycles.” NBER
Working Paper No. 21956 .
Bergemann, Dirk, Tibor Heumann, and Stephen Morris. (2017). “Networks, Information and Volatility.” Yale University
and Princeton University mimeo .
Bergemann, Dirk and Stephen Morris. (2013). “Robust Predictions in Games with Incomplete Information.” Econometrica 81 (4):1251–1308.
Bonatti, Alessandro, Gonzalo Cisternas, and Juuso Toikka. (2017). “Dynamic Oligopoly with Incomplete Information.”
The Review of Economic Studies 84 (2):503–546.
Caballero, Ricardo J and Eduardo MRA Engel. (1999). “Explaining Investment Dynamics in US Manufacturing: a
Generalized (S, s) Approach.” Econometrica 67 (4):783–826.
Camerer, Colin and Dan Lovallo. (1999). “Overconﬁdence and Excess Entry: An experimental Approach.” The
American Economic Review 89 (1):306–318.

61

Caplin, Andrew S and Daniel F Spulber. (1987). “Menu Costs and the Neutrality of Money.” The Quarterly Journal of
Economics 102 (4):703–725.
Chetty, Raj, Adam Guren, Day Manoli, and Andrea Weber. (2011). “Are Micro and Macro Labor Supply Elasticities
Consistent? A Review of Evidence on the Intensive and Extensive Margins.” The American Economic Review
101 (3):471–475.
———. (2013). “Does Indivisible Labor Explain the Difference between Micro and Macro Elasticities? A Meta-analysis
of Extensive Margin Elasticities.” NBER Macroeconomics Annual 27 (1):1–56.
Coibion, Olivier and Yuriy Gorodnichenko. (2012). “What Can Survey Forecasts Tell Us about Information Rigidities?”
Journal of Political Economy 120 (1):116–159.
Crawford, Vincent P, Miguel A Costa-Gomes, and Nagore Iriberri. (2013). “Structural Models of Nonequilibrium
Strategic Thinking: Theory, Evidence, and Applications.” Journal of Economic Literature 51 (1):5–62.
Doraszelski, Ulrich, Greg Lewis, and Ariel Pakes. (2017). “Just Starting Out: Learning and Equilibrium in a New
Market.” Harvard University mimeo .
Dufﬁe, Darrell, Nicolae Garleanu, and Lasse Heje Pedersen. (2005). “Over-the-Counter Markets.” Econometrica
73 (6):1815–1847.
Dufﬁe, Darrell and Gustavo Manso. (2007). “Information Percolation in Large Markets.” American Economic Review
97 (2):203–209.
Evans, George W and Seppo Honkapohja. (2001). Learning and Expectations in Macroeconomics. Princeton University
Press.
Evans, George W and Garey Ramey. (1992). “Expectation Calculation and Macroeconomic Dynamics.” American
Economic Review 82 (1):207–24.
———. (1995). “Expectation Calculation, Hyperinﬂation and Currency Collapse.” The New Macroeconomics: Imperfect Markets and Policy Effectiveness :307–336.
Farhi, Emmanuel and Iván Werning. (2017). “Monetary Policy, Bounded Rationality, and Incomplete Markets.” NBER
Working Paper No. 23281 .
Gabaix, Xavier. (2014). “A Sparsity-Based Model of Bounded Rationality.” The Quarterly Journal of Economics
129 (4):1661–1710.
———. (2016)a. “Behavioral Macroeconomics Via Sparse Dynamic Programming.” NBER Working Paper No. 21848
.
———. (2016)b. “A Behavioral New Keynesian Model.” NBER Working Paper No. 22954 .
Gale, Douglas. (1986). “Bargaining and Competition Part I: Characterization.” Econometrica 54 (4):785–806.
Gali, Jordi. (1999). “Technology, Employment, and the Business Cycle: Do Technology Shocks Explain Aggregate
Fluctuations?” American Economic Review 89 (1):249–271.
Garcıa-Schmidt, Mariana and Michael Woodford. (2015). “Are Low Interest Rates Deﬂationary? A Paradox of PerfectForesight Analysis.” NBER Working Paper No. 21614 .

62

Golosov, Mikhail, Guido Lorenzoni, and Aleh Tsyvinski. (2014). “Decentralized Trading with Private Information.”
Econometrica 82 (3):1055–1091.
Golosov, Mikhail and Robert E Lucas. (2007). “Menu Costs and Phillips Curves.” Journal of Political Economy
115 (2):171–199.
Golub, Benjamin and Stephen Morris. (2017). “Expectations, Networks, and Conventions.” Harvard University mimeo
.
Grandmont, Jean-Michel. (1977). “Temporary General Equilibrium Theory.” Econometrica 45 (3):535–72.
Greenwood, Robin and Samuel G Hanson. (2015). “Waves in Ship Prices and Investment.” The Quarterly Journal of
Economics 130 (1):55–109.
Guesnerie, Roger. (1992). “An Exploration of the Eductive Justiﬁcations of the Rational-expectations Hypothesis.” The
American Economic Review :1254–1278.
Harsanyi, John C. (1967). “Games with Incomplete Information Played by Bayesian Players, Parts I, II, and III.” Management Science 14:159–182 (part I), 320–334 (part II), 486–502 (part III).
Huo, Zhen and Naoki Takayama. (2015). “Rational Expectations Models with Higher Order Beliefs.” Yale mimeo .
Iovino, Luigi and Dmitriy Sergeyev. (2017). “Quantitative Easing without Rational Expectations.” Work in progress .
Kahneman, Daniel. (2011). Thinking, Fast and Slow. Farrar, Straus and Giroux.
Kalouptsidi, Myrto. (2014). “Time to Build and Fluctuations in Bulk Shipping.” The American Economic Review
104 (2):564–608.
Keane, Michael and Richard Rogerson. (2012). “Micro and Macro Labor Supply Elasticities: A Reassessment of
Conventional Wisdom.” Journal of Economic Literature 50 (2):464–76.
Kiyotaki, Nobuhiro and Randall Wright. (1993). “A Search-Theoretic Approach to Monetary Economics.” The American Economic Review 83 (1):63–77.
Lagos, Ricardo and Randall Wright. (2005). “A Uniﬁed Framework for Monetary Theory and Policy Analysis.” Journal
of Political Economy 113 (3):463–484.
Lucas, Robert E. (1972). “Expectations and the Neutrality of Money.” Journal of Economic Theory 4 (2):103–124.
Mackowiak, Bartosz and Mirko Wiederholt. (2009). “Optimal Sticky Prices under Rational Inattention.” American
Economic Review 99 (3):769–803.
Mas-Collell, Andreu, Michael Whinston, and Jerry R Green. (1995). Microeconomic Theory. Oxford University Press.
Mian, Atif and Amir Suﬁ. (2012). “The Effects of Fiscal Stimulus: Evidence from the 2009 Cash for Clunkers Program.”
The Quarterly Journal of Economics :qjs024.
———. (2014). “What Explains the 2007–2009 Drop in Employment?” Econometrica 82 (6):2197–2223.
Morris, Stephen and Hyun Song Shin. (1998). “Unique Equilibrium in a Model of Self-fulﬁlling Currency Attacks.”
American Economic Review :587–597.
———. (2002). “Social Value of Public Information.” The American Economic Review 92 (5):1521–1534.
63

———. (2003). “Global Games: Theory and Applications.” In Advances in Economics and Econometrics (Proceedings
of the Eighth World Congress of the Econometric Society). Cambridge University Press.
Myatt, David P and Chris Wallace. (2012). “Endogenous Information Acquisition in Coordination Games.” The Review
of Economic Studies 79 (1):340–374.
Nagel, Rosemarie. (1995). “Unraveling in Guessing Games: An Experimental Study.” The American Economic Review
85 (5):1313–1326.
Nakamura, Emi and Jon Steinsson. (2014). “Fiscal Stimulus in a Monetary Union: Evidence from US regions.” The
American Economic Review 104 (3):753–792.
Nimark, Kristoffer. (2008). “Dynamic Pricing and Imperfect Common Knowledge.” Journal of Monetary Economics
55 (2):365–382.
———. (2017). “Dynamic Higher Order Expectations.” Cornell Univeristy mimeo .
Pavan, Alessandro. (2016). “Attention, Coordination, and Bounded Recall.” Northwestern University mimeo .
Schaal, Edouard and Mathieu Taschereau-Dumouchel. (2015). “Coordinating Business Cycles.” NYU mimeo .
Shimer, Robert. (2005). “The Cyclical Behavior of Equilibrium Unemployment and Vacancies.” American Economic
Review 95 (1):25–49.
Sims, Christopher A. (2003). “Implications of Rational Inattention.” Journal of Monetary Economics 50 (3):665–690.
Stahl, Dale O and Paul W Wilson. (1994). “Experimental Evidence on Players’ Models of Other Players.” Journal of
Economic Behavior & Organization 25 (3).
———. (1995). “On Players’ Models of Other Players: Theory and Experimental Evidence.” Games and Economic
Behavior 10 (1):218–254.
Tirole, Jean. (2015). “Cognitive Games and Cognitive Traps.” Toulouse School of Economicss mimeo .
Townsend, Robert M. (1983). “Forecasting the Forecasts of Others.” The Journal of Political Economy :546–588.
Venkateswaran, Venky. (2014). “Heterogeneous Information and Labor Market Fluctuations.” NYU mimeo .
Woodford, Michael. (2003). “Imperfect Common Knowledge and the Effects of Monetary Policy.” Knowledge, Information, and Expectations in Modern Macroeconomics: In Honor of Edmund S. Phelps .
———. (2012). “Inattentive Valuation and Reference-dependent Choice.” Columbia University mimeo .
———. (2013). “Macroeconomic Analysis Without the Rational Expectations Hypothesis.” Annual Review of Economics 5:303–346.

64

