NBER WORKING PAPER SERIES

ORDEAL MECHANISMS IN TARGETING:
THEORY AND EVIDENCE FROM A FIELD EXPERIMENT IN INDONESIA
Vivi Alatas
Abhijit Banerjee
Rema Hanna
Benjamin A. Olken
Ririn Purnamasari
Matthew Wai-Poi
Working Paper 19127
http://www.nber.org/papers/w19127
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2013
This project was a collaboration involving many people. We thank Jie Bai, Talitha Chairunissa, Donghee
Jo, Chaeruddin Kodir, He Yang, Ariel Zucker, and Gabriel Zucker for their excellent research assistance,
and Raj Chetty, Esther Duflo, Amy Finkelstein, and numerous seminar participants for helpful comments.
We thank Mitra Samya, the Indonesian Central Bureau of Statistics (BPS), the Indonesian National
Team for the Acceleration of Poverty Reduction (TNP2K, particularly Sudarno Sumarto and Bambang
Widianto), the Indonesian Social Affairs Department (DepSos), and SurveyMeter for their cooperation
implementing the project. Most of all, we thank Jurist Tan for her truly exceptional work leading the
field implementation. This project was financially supported by the World Bank, AusAID, and 3ie,
and analysis was supported by NIH under grant P01 HD061315. Additional Affiliations:. Banerjee,
Olken: BREAD, CEPR, and J-PAL Hanna: BREAD, CEPR, and J-PAL. All views expressed are those
of the authors, and do not necessarily reflect the views of the World Bank, TNP2K, Mitra Samya,
DepSos, the Indonesian Central Bureau of Statistics, or the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w19127.ack
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
¬© 2013 by Vivi Alatas, Abhijit Banerjee, Rema Hanna, Benjamin A. Olken, Ririn Purnamasari, and
Matthew Wai-Poi. All rights reserved. Short sections of text, not to exceed two paragraphs, may be
quoted without explicit permission provided that full credit, including ¬© notice, is given to the source.

Ordeal Mechanisms In Targeting: Theory And Evidence From A Field Experiment In Indonesia
Vivi Alatas, Abhijit Banerjee, Rema Hanna, Benjamin A. Olken, Ririn Purnamasari, and Matthew
Wai-Poi
NBER Working Paper No. 19127
June 2013
JEL No. I38,O12
ABSTRACT
Economic theory suggests that, when designing aid programs, ordeal mechanisms that impose differential
costs for rich and poor can induce self-selection and hence improve targeting (‚Äúself-targeting‚Äù). We
first re-examine this theory and show that ordeal mechanisms may actually have theoretically ambiguous
effects on targeting: for example, time spent applying imposes a higher monetary cost on the rich,
but may impose a higher utility cost on the poor. We then examine these issues empirically by conducting
a 400-village field experiment within Indonesia's Conditional Cash Transfer program. Targeting in
the program is usually conducted by automatically enrolling candidates who pass an asset test. We
compare whether instituting an ordeal mechanism, where villagers come to a central application site
to apply and take the asset test, improves targeting over the existing automatic enrollment system.
Within self-targeting villages, we find that the poor are more likely to apply, even conditional on whether
they would pass the asset test. On net, self-targeting villages have a much poorer group of beneficiaries
than status quo villages. However, marginally increasing the ordeal does not necessarily improve targeting:
while experimentally increasing the distance to the application site reduces the number of applicants,
it screens out both rich and poor in roughly equal proportions. Estimating the model structurally, we
show that only one would need to increase the ordeal dramatically (e.g. tripling wait times to 9 hours
or more) to induce detectable additional selection. In short, ordeal mechanisms can induce self-selection,
but marginally increasing the ordeal can impose additional costs on applicants without necessarily
improving targeting.
Vivi Alatas
World Bank
Jakarta Stock Exchange Building
Tower 2, 12th & 13th Floor
Jakarta, Indonesia
valatas@worldbank.org
Abhijit Banerjee
MIT
Department of Economics
50 Memorial Drive
Cambridge, MA 02142-1347
and NBER
banerjee@mit.edu
Rema Hanna
Kennedy School of Government
Harvard University
79 JFK Street
Cambridge, MA 02138
and NBER
Rema_Hanna@hks.harvard.edu
An online appendix is available at:
http://www.nber.org/data-appendix/w19127

Benjamin A. Olken
MIT
Department of Economics
50 Memorial Drive
Cambridge, MA 02142-1347
and NBER
bolken@mit.edu
Ririn Purnamasari
Jakarta Stock Exchange Building
Tower 2, 12th & 13th Floor
Jakarta, Indonesia
rpurnamasari@worldbank.org
Matthew Wai-Poi
World Bank
Jakarta Stock Exchange Building
Tower 2, 12th & 13th Floor
Jakarta, Indonesia
mwaipoi@worldbank.org

1. Introduction
In designing targeted aid programs, a perennial problem is how to separate the poor from the
rich. One strategy for doing so is to impose program requirements that are differentially costly
for the rich and the poor, in order to induce the poor to participate while dissuading the rich
from doing so (Nichols, Smolensky and Tideman, 1971; Nichols and Zeckhauser, 1982; Ravallion,
1991; Besley and Coate, 1992). These ‚Äúself-selection‚Äù or ‚Äúordeal‚Äù mechanisms are quite common:
welfare programs, from the Works Progress Administration (WPA) in the United States during
the Great Depression to the National Rural Employment Guarantee Act (NREGA) right-to-work
scheme in India today, often have manual labor requirements to receive aid; unemployment schemes
often require individuals to report to the unemployment office weekly during working hours, which
is challenging for the employed; subsidized food schemes often provide lower quality food so that
those who can afford tastier food choose not to purchase the subsidized products.
By imposing higher participation costs on the rich, these mechanisms may save governments
considerable screening costs and potentially result in better targeted programs. On the other hand,
imposing participation costs on the poor, however small, may also dissuade them from partaking.
For example, if the poor are very credit constrained or have higher discount rates than the rich,
a substantial fraction of them may choose not to apply, leading to a less pro-poor distribution of
beneficiaries. (See Currie 2006 for a review.)
In this paper, we explore the different margins through which self-selection may operate in the
context of Indonesia‚Äôs Conditional Cash Program (PKH), which provides beneficiaries with US$150
per year for 6 years. The program is aimed at about the poorest 5 percent of the population, with
eligibility traditionally determined based on a weighted sum of about 30 easy-to-observe assets (e.g.,
size of house, materials used to construct household roof, motorbike ownership). Working with the
Indonesian government, we experimentally varied the eligibility process for PKH across 400 villages.
In the treatment villages, households that were interested in the program were required to go to
a central registration site to take an asset test administered by the statistics office. This entailed
both travel (time and money costs) and waiting (more time costs). Within the treatment areas,
we randomly varied the application costs along two dimensions: the distance to the application
site and whether one or both spouses needed to be present to apply. In control areas, the status
quo procedure ‚Äì automatic enrollment ‚Äì was followed: the statistics office, working with local
government officials, drew up a list of potential beneficiaries; interviewed everyone at their homes;
and then automatically enrolled those who passed the asset test.1
We begin with a description of the experiment and the data. We then ask what we would expect
from such an experiment on purely a priori grounds. Specifically, we reexamine the classical theory
of self-selection into social programs developed by Nichols, Smolensky and Tideman (1971), Nichols
and Zeckhauser (1982), Besley and Coate (1992) and others. These papers assume indifference
1

These two approaches ‚Äì proxy-means tests (PMT) based on either a) automatic enrollment or b) self-selection into
being interviewed, followed by verification of assets based on the interview results ‚Äì are quite common. For example,
the initial Mexican Progresa program used an automatic enrollment PMT to determine beneficiaries in selected areas,
and the subsequent expansion of the program under the name Oportunidades used a self-selection PMT treatment
virtually identical to what we investigate in this study. See Coady and Parker (2009) and Martinelli and Parker
(2009).
2

curves that have the property that an ordeal is more costly in utility terms for the rich and that
this gap is increasing in the duration of the ordeal. As a result, there is a simple trade-off between
the deadweight loss of a longer ordeal and the better self-selection that it generates. We argue that
in a more realistic environment, these two properties may not necessarily hold. First, ordeals may
be more costly in utility terms for the poor than the rich: given that the poor tend to be savings
and credit constrained, the loss of earnings from applying may imply a greater utility cost because
their marginal utility of consumption is higher. Moreover, the same ordeal may even cost more in
monetary terms for the poor, as the rich may be better able to overcome an ordeal; for example, the
rich may quickly drive to a far-away registration site, while the poor may expend considerable time
walking to the site.2 Second, the gap may not necessarily increase in the duration of the ordeal.
Even if the total money cost is higher for the rich, the marginal cost of the ordeal may be lower.
For example, if the poor walk to a registration site to apply while the rich take a bus, the cost of
traveling a little further may be relatively smaller for the rich, given a fixed bus fare and faster
bus speed. Third, traditional selection models assume no idiosyncratic element in the decision to
apply, but we show that the effect on self-selection very much depends on the distribution of these
idiosyncratic shocks: if we assume that the underlying payoffs are such that the poorest people will
always apply even when there is a burdensome ordeal and the rich only do so when it is convenient
(i.e., when the utility shocks are very favorable), it may be that those who are not quite the poorest
may be most affected by ordeals, and this may have ambiguous effects on targeting.
Our empirical analysis proceeds in four stages. First, we begin by examining who chooses to selfselect into applying for the program in the 200 villages where self-targeting was implemented. To
do so, we utilize data on households‚Äô per capita consumption that we collected before the program
was announced or targeting began. We find that the probability of self-selecting to apply for the
program is monotonically decreasing in a household‚Äôs per capita consumption, i.e., that the poor are
always more likely to apply than the rich. Decomposing consumption into that which is potentially
observable to the government (i.e. the part that can be predicted based on observable assets)
and the unobservable residual, we show that those who apply are poorer on both observables and
unobservables than those who choose not to apply. This implies that self-selection can not only
potentially save resources (since many who would fail the asset test, i.e., have high observables, are
no longer tested), but that it also has the potential to improve targeting even over a universallyadministered asset test (since those that apply are poorer on unobservables than the population at
large). However, we also find evidence for the view that self-targeting may screen out some of the
poor: for example, only about 60 percent of the very poorest apply under self-targeting.
The question, though, for most governments is not necessarily how self-targeting would perform
relative to a counterfactual of no error, but rather how it would compare against the next best
alternative targeting strategy. The second step of our empirical analysis is to use the experiment
to compare self-targeting with the current status quo, in which the government conducted the asset
test for all potential beneficiaries (chosen through prior asset surveys and consultations with village
leadership) at their homes and automatically enrolled those that passed. Compared against this
real alternative, we find that per capita consumption was 21 percent lower for beneficiaries in the
2

While the car obviously costs money, most of that is sunk cost from the point of view of this intervention.
3

self-targeting villages than those under the status quo. This occurs along the entire distribution:
per capita consumption of the beneficiaries in self-targeting areas was first-order stochastically
dominated by the per capita consumption of those under the status quo. Moreover, exclusion error
was actually less of a problem in self-targeting than in the status quo: the very poorest households
were twice as likely to receive benefits in self-targeting than in control areas. Note that these findings
are not entirely driven by the fact that the government chose who to interview under the status
quo: supplementing the government‚Äôs asset test data in the automatic enrollment villages with
asset data that we independently collected for those not interviewed, we find that the beneficiaries
under self-targeting would still be, on average, poorer than those under a ‚Äúhypothetical‚Äù system
where everyone is interviewed for the asset test. Intuitively, this is possible because ‚Äì as we showed
above ‚Äì self-selection includes selection on unobservables. That is, conditional on passing the asset
test, those that self-select into applying have lower consumption than the average person in the
population.
The third step in our empirical analysis is to consider whether marginal increases in the severity
of the ordeal further increase targeting performance, which as we discussed above is theoretically
ambiguous. We examine the results from experimentally varying the distance to the registration
site (increasing travel costs) and the number of household members required to be present at the
application site (increasing opportunity costs of time for the family). Note that these experiments
were carefully designed to be within a set of policy instruments that could be potentially considered
by the government, under the requirement that the ordeals could not be so onerous that they either
discourage the severely credit-constrained poor from applying or that they would likely impose very
large application costs for the poor who might still be incorrectly screened out by the asset test.
Examining the experimental variation in the extent of the ordeal, we do not observe that increasing ordeals differentially improves targeting. We find that increasing the distance that the
applicant has to travel by an average of 1.7 kilometers reduces the overall number of applicants
about 17 percent, and thus inclusion error of the rich is reduced. However, there is no detectable
differential selection by income groups when we increase distance, and thus increasing distance also
screens out a similar fraction of poor households. Similarly, we do not observe significant differential
selection when we increase the opportunity cost of waiting by requiring both spouses to apply in
person rather than allowing either spouse to apply alone. In sum, these results show that while
ordeal mechanisms can induce self-selection by the poor, increasing the size of the ordeal can impose
additional costs on applicants without necessarily improving targeting.
The theoretical model outlines a number of reasons why marginal increases in the extent of
ordeals might not necessarily improve targeting. To understand which factors are in fact empirically
relevant, the final step of our empirical analysis uses Generalized Method of Moments to estimate
a CRRA utility version of our model with logit shocks. We use the average show up rates in the
far distance treatment for each income quintile as moments. Since we estimate the model using
only one experimental sub-treatment and cross-sectional differences in distances to fit the model,
not the experimental variation, we can check that the model‚Äôs predictions provide a reasonable
approximation of the experimental findings, which indeed they do.

4

We use the estimated version of the model to see which of the various mechanisms we outlined in
the theoretical section lie behind the fact that marginal increases in the extent of the ordeal do not
seem to differentially improve selection. Simulations from the estimated model suggest that, of the
theoretical mechanisms we outline, neither curvature of the utility function nor differential travel
technology is driving the results. In fact, we show that the data are best explained by a linear utility
function, rather than one with curvature, and we obtain virtually identical predictions when we
impose identical travel technologies on both the poor and the rich. We find that, with the estimated
distribution of idiosyncratic shocks, differential selection only occurs in our counterfactuals when
we triple the wait time at the registration site. This would mean that prospective applicants would
need to have waited in line 9 or more hours to be interviewed, which is beyond what appears to be
feasible as a policy.3 Instead, the model suggests that, to the extent that rich households forecast
that they have a very small likelihood of receiving benefits conditional on applying and therefore do
not bother to apply, even small ordeals can produce substantial selection, but marginally increasing
the intensity of the ordeal within the feasible range appears to imposes costs on applicants without
substantially improving targeting.
The remainder of the paper is organized as follows. Section 2 discusses the setting, experimental
design, and data. Section 3 introduces our model,which revisits the standard screening model in light
of curvature in the utility function, differential access ways of dealing with costs, and idiosyncratic
shocks. Section 4 examines the self-targeting data to ask who chooses to apply for the program.
Section 5 uses the experiment to compare self-targeting with the status quo PMT-based approach.
Section 6 examines the marginal effect of targeting when the ordeal is changed experimentally,
and compares this to what a structurally estimated version of our model would predict. Section 7
concludes.
2. Setting and Experimental Design
2.1. Setting: The PKH Program. This project explores self-targeting mechanisms within the
context of Program Keluarga Harapan (PKH), a conditional cash transfer project administered
by the Ministry of Social Affairs (DepSos) in Indonesia. The program targets households with
that have per capita consumption below 80 percent of the poverty line (approximately the poorest
5 percent of the population we study) and that meet the demographic requirements of having a
pregnant woman, a child between the ages of 0 to 5, or children below the age of 18 years old that
have not finished the nine years of compulsory education. Program beneficiaries receive direct cash
assistance ranging from Rp. 600,000 to Rp. 2.2 million (US$67-US$250) per year‚Äîor about 3.5 to
13 percent of the average yearly consumption by very poor households in our sample‚Äîdepending on
their family composition, school attendance, pre/postnatal check-ups, and completed vaccinations.4
3

Interestingly, in our pre-pilot we explicitly piloted treatments aimed at increasing the wait time, with wait times as
long as 8 or more hours. Even at wait times well below the level our simulations suggest would be necessary to induce
substantial targeting effects, villagers endogenously organized themselves to reduce wait times (e.g., by pre-assigning
scheduled times for people to come back to be interviewed). This suggests that actually implementing a policy that
requires waiting in line for more than 8 hours may be quite difficult to implement practically.
4
Note, however, that although PKH is formally a conditional cash transfer program, with transfers dependent upon
health takeup and school enrollment, these conditions are typically not enforced in practice.
5

The payments are disbursed quarterly for up to six years. Currently, around 1.12 million households
are enrolled in the program.5
Determining whether households fall below the consumption requirement (‚Äútargeting‚Äù) is difficult
because per capita consumption is not easily observed by the government. Instead, PKH uses
a proxy-means test (PMT) approach with automatic enrollment for all households that meet the
demographic requirements and pass a proxy-means test. Specifically, every three years, enumerators
from the Central Statistical Bureau (BPS) conduct a survey of households nationwide who are
potentially eligible for anti-poverty programs, including but not limited to PKH. They survey all
households that were included on previous surveys (regardless of whether they previously qualified or
not) and supplement this list with recommendations from local leaders and their own observations
of the kinds of houses that the households inhabit. After passing an initial pre-screening, each
household is asked a series of about 30 questions, including attributes of their home (e.g., wall
type, roof type), ownership of specific assets (e.g.,motorcycle, refrigerator), household composition,
and the education and occupation of the household head. These measures are combined with
location-based indicators, such as population density, distance to the district capital and access to
education. Using independent survey data, the government then estimates the relationship between
these variables and the household per capita consumption to generate a district-level formula for
predicting consumption levels based on the responses to the survey. Individuals with predicted
consumption levels below each district‚Äôs very poor line were eligible for the program.
2.2. Sample Selection. This project was carried out during the 2011 expansion of PKH to new
areas. We chose 6 districts (2 each in the provinces of Lampung, South Sumatra, and Central
Java) from the expansion areas to include a wide variety of cultural and economic environments.
Within these districts, we randomly selected a total of 400 villages, stratified such that the final
sample consisted of approximately 30 percent urban and 70 percent rural locations.6 Within each
village, we randomly selected one hamlet to be surveyed.7 These hamlets are best thought of as
neighborhoods that consist of about 150 households and that each have their own administrative
head, whom we refer to as the hamlet head.
2.3. Experimental Design. We randomly allocated each of the 400 villages to one of two targeting
methodologies: self-targeting or an automatic enrollment system, i.e. the status quo.8
2.3.1. Automatic Enrollment Treatment. In Indonesia, the automatic enrollment treatment is the
status quo, and the procedure discussed in Section 2.1 was followed. Due to cost considerations,
for this treatment, the automatic enrollment was only conducted in the one randomly selected
5

Program PKH Bidik 1,12 Juta Rumah Tangga Miskin. Kementrian Koordinator Bidang Kesejahteraan Rakyat. October 22, 2010. Retrieved from <http://www.menkokesra.go.id/content/program-pkh-bidik-112-juta-rumah-tanggamiskin-0>, last accessed October 3, 2011.
6
The sampling unit was a desa in rural areas and a kelurahan in urban areas. For ease of exposition, we henceforth
refer to both as villages.
7
Both desa and kelurahan are administratively divided by neighborhood into sub-villages known variously as dusun,
RW, or RT. For ease of exposition, we henceforth call them ‚Äúhamlets.‚Äù In rural areas, each hamlet ranges from about
30-330 households, while in urban areas, they each range from 70-410 households.
8
We also randomly assigned an additional 200 villages to a ‚Äúhybrid treatment‚Äù (see Alatas, Banerjee, Hanna, Olken,
Purnamasari and Wai-poi (2012)).
6

hamlet per village that we also surveyed in the baseline.9 For each hamlet in this treatment, the
government Bureau of Statistics (BPS) enumerators were given a pre-printed list of households
from the last targeting survey (PPLS, 2008). When they arrived at a village, the enumerators
showed the list to the village leadership and asked them to add any households to the list that they
thought were inappropriately excluded. The enumerators also had the option of adding households
to the list of interviewees if they observed that a household was likely to be quite poor. For
each potential interviewee, the enumerator conducted an initial five question pre-screening; those
households who passed the pre-screening were given the full PMT survey.10 Of the 6,406 households
on the potential interviewee list, 16 percent were eliminated based on the initial screen, and 5,383
households (or about 37.8 percent of each hamlet) were given the full PMT survey of 28 questions.
For each household that was interviewed, a computer-generated poverty score was generated using
the district-specific PMT formulas.11 A list of beneficiaries was generated by selecting all households
with a predicted score below the score cutoff for their district.
2.3.2. Self-Targeting Treatment. The enrollment criteria for both the demographic and consumption
criteria under the self-targeting mechanism was the same as in automatic enrollment, but households
were required to apply at a central registration station if they were interested in the program.
The fact that households needed to self-select means that some households who might have been
automatically enrolled would not receive benefits because they chose not to apply. Conversely, some
households who may have been forgotten or passed over when the government compiled the list of
households to be interviewed could apply and ultimately receive benefits.
The self-targeting treatment proceeded as follows: to publicize the application process, a community facilitator from a local NGO (Mitra Samya) visited each village to inform the village leaders
about the program, to brainstorm about the best indicators of local poverty with the leaders, and
to set a date for a series of hamlet-level meetings that were aimed at the poor.12 In these hamletlevel meetings, the facilitator described the PKH program and explained the registration process.
In particular, the facilitators stressed that the program was geared towards the very poor. For
example, they listed examples of questions that would be asked during the interview (e.g., type of
house, motorbike), informed households that there would be a verification stage post-interview, and
highlighted a set of local poverty criteria (the criteria that locals would typically use to characterize
very poor households). The goal was to ensure that the households understood their chances of
obtaining PKH conditional on showing up to be interviewed.
9

To select beneficiaries in the other hamlets, the government used the 2008 automatic enrollment survey.
The pre-screening consists of 5 questions: is the household‚Äôs average income per month in the past three months
more than Rp. 1,000,000 (USD$110); was the average transfer received per month in the past three months more
than Rp. 1,000,000 (USD$110); did they own a TV or refrigerator that cost more than Rp. 1,000,000 (USD$110); was
the value of their livestock productive building, and large agricultural tools owned more Rp. 1,500,000 (USD$167);
did they own a motor vehicle; and did they own jewelry worth more than Rp. 1,000,000 (USD$100). Households
that answered yes on either four or five of the questions were instantly disqualified and the survey ended.
11
The PMT formulas were determined using household survey data from SUSENAS (2010) and village survey data
from PODES (2008). On average, these regressions had an R-squared of 0.52. The questions chosen for the PMT
survey were those that the government were considering for the next nationwide targeting survey (the ‚ÄúPPLS 11‚Äù).
12
The local poverty indicators generated in the meeting were not used for targeting, but were instead used by
community members in the socialization process to help villagers understand how the PMT screening would operate.
10

7

Registration days for each area were scheduled in advance based on the number of predicted
applicants and their relative proportion within the hamlet.13 During the registration days, the BPS
enumerators were present at the registration station from 8AM to 5PM. Households were required
to come to the registration site if they wished to apply. Once they arrived, they were signed in and
given a number in the queue. When their number was called, BPS interviewed the household to
collect the same data that was conducted in the PMT interview.
Households who applied were subsequently categorized by eligibility based on the PMT regression
formula and the district-specific very poor line, using the same PMT formula and questions as in
the automatic enrollment treatment. Any household that was both classified as very poor based on
the assets they disclosed in their interview, and was also listed in the 2008 poverty census as very
poor (about 37 percent who passed the interview at the registration site) were selected as a PKH
recipient. All other households that classified as very poor based on their interview were subjected
to a verification process: Government surveyors went to their homes to collect data on the same set
of asset questions. The results of this home-based survey were used, with the same PMT regression
formula and poverty lines, to determine the final list of beneficiaries. About 68 percent of those
who got to the verification stage were ultimately considered eligible after the verification.14 Within
self-targeting treatment villages, we varied how the self-targeting was conducted in order to vary
the costs of registration. Specifically, we conducted two sub-treatments:
(1) Distance sub-treatment: We experimentally varied the distance to the registration site. The
idea was to vary the time and travel costs required to sign up, while ensuring that all locations could
still potentially be reached by walking, so as not to impose substantial financial transportation costs
on poor households.15 In the urban areas, we randomly allocated villages to have the registration
site at the sub-district office (far location) or the village office (near location). In rural areas, where
distances are greater than the urban areas, villages were randomly allocated to have the registration
site at the village office (far location) or in the sub-village (near location).16
(2) Both spouse sub-treatment: We experimentally varied whether one or two household members
were required to come to the registration site. In half of the self-targeting treatment villages,
households were told that any adult in the household could do so. Given that the program was
geared towards women, we expected that mostly women would apply. In the other half of the
villages, we required that both the husband and the wife jointly apply at the registration site. Note
13

Specifically, we estimated the predicted number of people who would show up to be interviewed using the pilot
data. We regressed the number of people who showed up on the number of households in the village and the number
of poor households. BPS staff were assigned based on these predicted show up rates, assuming a capacity to interview
34 households per day and a 25 percent buffer.
14
The fact that there was substantial under reporting of assets in the initial interview, and therefore that only 23 of
households passed the home-based asset verification, is consistent with the Mexican experience with targeting in
Progresa (Martinelli and Parker, 2009).
15
Thornton et al 2010 found that reducing distance to enrollment for health insurance increased enrollments substantially, but did not examine selection effects.
16
The distance sub-treatment was violated in four villages: in the first village, a longstanding ethnic tension caused a
large subset of the village to refuse to participate in interviews in a certain hamlet, so the interviewers held interviews
for a day in another hamlet; in the second village, a hamlet was a 4-5 hour walk away from the village office, so the
interviewers set aside a day to go to that hamlet; in the third village and fourth villages, the village leaders insisted
the the registration site be moved closer to the village. All analysis reports intent-to-treat effects where these four
villages are categorized based on the randomization result, not actual implementation.
8

that there was a fear of screening out poor households where the primary wage earner had migrated
for work. Thus, if the spouse was unable to attend due to a pre-specified reason (illness, out of
village for work), the household was required to bring a letter signed by the hamlet head providing
the reasons for the spouse‚Äôs unavailability, the rationale being that obtaining the letter in advance
would still be costly to households. On average, 29 percent of applicants in spouse sub-treatment
villages provided such a letter.
2.4. Randomization Design and Timing. We randomly assigned each of the 400 villages to the
treatments (see Table 1). In order to ensure experimental balance across geographic regions, we
stratified by 58 geographic strata, where each stratum consisted of all the villages from one or more
sub-districts and was entirely located in a single district. We then randomly and independently
allocated each self-targeting village to the sub-treatments, with each of these two sub-treatment
randomizations stratified by the previously defined strata and the main treatment.
From December 2010 to March 2011, an independent survey firm (Survey Meter) collected the
baseline data from one randomly selected hamlet in each village. After surveying was completed
in each sub-district, the government conducted the targeting treatments. The targeting treatments
thus occurred from January through April 2011.17 SurveyMeter conducted a first follow-up survey in
early August 201l, after the targeting was complete, but before the beneficiary lists were announced
to the villages. Fund distribution occurred starting in late August 2011.18 Finally, we conducted a
second endline survey in January 2012 to March 2012, after two fund distributions had occurred.
2.5. Data, Summary Statistics and Balance Test.
2.5.1. Data Collection. We collected three main sources of data:
Baseline Data: The baseline survey was completed in each sub-district before any targeting
occurred, and up to this point, there was no mention of the experiment in the villages. Within
each village, we randomly selected one hamlet, and within that hamlet, we randomly sampled nine
households from the set of those who met the demographic eligibility requirements for PKH, as well
as the sub-village head, for a total of 3,998 households across the 400 villages. The survey included
detailed questions on the household‚Äôs consumption level, demographics, and family networks in the
villages. We also collected data for all of the variables that enter the PMT formula, so that we can
calculate PMT scores for each surveyed household.
Targeting Data: We obtained all of the targeting data from the government, including who
was interviewed, all data from the interview (either at interview site or at home, or both), each
household‚Äôs predicted consumption score, and whether the household qualified to receive PKH. For
the self-targeting villages, we additionally asked the government to record data on each step of the
17

There was no mention of the targeting process until SurveyMeter had completed the baseline survey in the entire
sub-district. The mean time elapsed between the baseline survey and the commencement of targeting activities was
22 days.
18
Note that after the experiment selected beneficiaries, the Department of Social Affairs realized it had additional
funds available and decided to increase the number of people who received the program to also include households
that did not pass the selection process in our experimental treatments but had been classified as very poor under the
2008 poverty census. In calculating ‚Äúbeneficiaries‚Äù for purposes of experimental evaluation below, we do not include
these additional households.
9

process (e.g. where and when the registration meetings occurred, how the socialization was done in
each village, etc.).
Endline Surveys: We administered two endline surveys, both of which were conducted by SurveyMeter. The first endline survey occurred in August 2011, prior to announcements of the beneficiary lists. We surveyed up to three beneficiary households per village and revisited one household
from the baseline survey per village in 97 randomly chosen automatic enrollment villages and 193
self-targeting villages, for a total sample of 1,045 households.19 In this survey, we collected detailed
data on the households‚Äô consumption level, as well as respondents‚Äô experience and satisfaction with
the targeting process (e.g., whether they applied, how long they waited to be interviewed). In addition, for all beneficiary households, we collected additional data on demographics, family networks,
relationships with local leaders, and employment. We conducted the second endline from January
2012 to March 2012, after two rounds of PKH fund distribution. In this survey, we revisited all ten
of the baseline households, collecting consumption data, as well as data on satisfaction with PKH.
2.5.2. Summary Statistics and Experimental Validity. Table 2 shows the flow of surveyed households
through the experiment. Column 1 shows the total number of households in the baseline survey in
each of the two primary treatments. The next columns show the number of households who applied
to be interviewed for self targeting (754 out of 2,000, or 38 percent) or were interviewed as part
of the automatic enrollment treatment (706 out of 1,998, or 35 percent). Column 3 shows the the
number of baseline households who were ultimately chosen as beneficiaries (73 out of 2,000, or 3.65
percent, in self-targeting; 86 out of 1,998, or 4.3 percent, in automatic enrollment).
Appendix Table A.1 presents summary statistics and a check on the the experimental validity
using data from the baseline survey and a village census. Note that we chose all of the variables for
the table prior to analyzing the data. Column 1 presents the mean and standard deviations of each
variable in villages in the automatic enrollment treatment, while this information is provided for
the self-targeting villages in Column 2. Column 3 shows the difference (with associated standard
errors). Column 4 shows this difference after controlling for stratum fixed effects. Only 1 of the
20 differences presented is statistically significant (at the 10 percent level), confirming that the
treatment villages are balanced at the baseline. At the bottom of Columns 3 and 4, we provide the
p-value from a joint test of the treatment across all baseline characteristics that we consider. The
p-values of 0.99 and 0.67, respectively, confirm that the groups are balanced in the baseline.
3. Model
3.1. Model Set-up. In this section, we briefly re-examine self-selection into a welfare program
based on the expected benefits and costs of applying. We assume that households have a utility
function U (x), where x is current consumption. Households vary in their per period labor income,
denoted by y, but for a given household this is the same number in both periods. The application
cost is denoted by c (l, y), where l is the distance to the registration site. Conditional on applying,
households have a probability ¬µ(y) of passing the asset-based test and actually qualifying for the
19

Due to safety and travel concerns that were independent of the project, the survey company asked that that we did
not return to 10 villages in endline 1 and 13 villages in endline 2. These were spread among treatment and control
villages.
10

program (¬µ0 (y) ‚â§ 0).20 If the household qualifies for the program, it receives an additional income b
in the future period (for simplicity, we assume there is just one future period). Otherwise, it receives
no additional income. Finally, assume that the household starts with no assets and cannot borrow.
This is consistent with the evidence that many poor, and perhaps even not so poor, households in
developing countries tend to be credit constrained. This, combined with the assumption that the
household discounts future utilities (the discount factor is Œ¥ < 1), and the fact that in our model
future consumption is always weakly higher, rules out savings, and tells us that consumption in a
given period is just current income net of costs.
To complete the description of the model, assume that each person who applies receives a random
utility shock, Œµ, that encourages him to go to register, and F () is the distribution of .
Taken together, the household‚Äôs expected utility upon applying is:
U (y ‚àí c (l, y)) + ¬µ(y)Œ¥U (y + b) + (1 ‚àí ¬µ(y)) Œ¥U (y) + Œµ

(1)

If the household does not apply, expected utility is:
U (y) + Œ¥U (y)

(2)

The expected gain from applying is the difference, i.e.
U (y ‚àí c (l, y)) ‚àí U (y) + ¬µ(y)Œ¥ [U (y + b) ‚àí U (y)] + 

(3)

It will turn out to be convenient to define:
g(y, l) = U (y ‚àí c (l, y)) ‚àí U (y) + ¬µ(y)Œ¥ [U (y + b) ‚àí U (y)]

(4)

to denote the net gain without the shock. The household will apply if the expected utility from
doing so is larger than staying home, i.e., if ‚àíg (y, l) ‚â§ . The fraction of households that will apply
at a particular level of income y is given by F (‚àíg(y, l)). We are interested in how an increase in
distance, l, affects F (‚àíg(y, l)) at different levels of y.
3.2. Analysis. In this section, we start with the most basic model and add elements to the model
one-by-one in order to understand how each element affects the type of household that applies.
3.2.1. The Benchmark Case. Suppose that the utility function is linear (U (x) = x) and that the
time cost of applying is also linear in distance: œÑ l.21 For someone who earns a wage, w, this imposes
a monetary cost of œÑ lw. If we assume that wages are proportional to income, w = Œ±y, then the
monetary application cost can be written as œÑ lŒ±y. Assume also that there are no shocks ( ‚â° 0). In
this case, g (y) simplifies substantially, and a household applies if:
‚àí œÑ lŒ±y + Œ¥¬µ(y)b ‚â• 0.

(5)

20Note that in the model, households understand the ¬µ(y) function. Empirically, this seems plausible, as similar

PMT-based exercises had been done several times in the past in these villages, in 2005 and 2008.
21The linearity in time cost may be unrealistic since it includes both travel time and wait time, which are unlikely
to be linear in distance (though it may be increasing in distance since the further it is, the harder it is go home and
come back later if the wait time is particularly long). However, nothing really turns on the linearity assumption and
it simplifies the model.
11

Since the left hand side of this expression is decreasing in y, this expression defines a cutoff value
y ‚àó such that those who have incomes less than y ‚àó apply and those who have incomes greater than
‚àó
y ‚àó do not apply. Moreover, an inspection of equation (5) shows that ‚àÇy
‚àÇl < 0, that is, making the
ordeal more onerous increases the degree of selection and implies that the set of people who apply
will be poorer. This simple expression captures the basic intuition for using ordeal mechanisms for
selection captured by Nichols and Zeckhauser (1982).
3.2.2. Adding Shocks. Now, let‚Äôs consider what happens if we re-introduce the utility shock term.
In this case, a household applies iff:
œÑ lŒ±y ‚àí Œ¥¬µ(y)b ‚â§ Œµ.

(6)

Consider two levels of income, y1 and y2 > y1 , and assume that the cutoff value of  in both cases
is interior to the support of its distribution. The ratio of their show-up rates is:
1 ‚àí F (œÑ lŒ±y1 ‚àí Œ¥¬µ(y1 )b)
1 ‚àí F (œÑ lŒ±y2 ‚àí Œ¥¬µ(y2 )b)

(7)

This ratio is always greater than one because the rich are less likely to sign up because their costs
are higher and their probability of getting the benefit is lower. Note that this ratio is a measure of
how well targeted the application process is towards poorer individuals ‚Äì the higher the ratio, the
higher the fraction of the poor in the population of applicants. Making the ordeal tougher reduces
the number of poor applicants and imposes dead-cost on everyone who applies, which are both
undesirable. Therefore, the only reason to do so is that it improves the ratio of poor to rich, which
may reduce the costs of the program to the government.
Taking the derivative with respect to l, the distance to the registration site, tells us that targeting
efficiency measured by this ratio improves when l increases if and only if:
f (œÑ lŒ±y2 ‚àí Œ¥¬µ(y2 )b)
f (œÑ lŒ±y1 ‚àí Œ¥¬µ(y1 )b)
œÑ Œ±y2 ‚àí
œÑ Œ±y1 > 0.
(8)
1 ‚àí F (œÑ lŒ±y2 ‚àí Œ¥¬µ(y2 )b)
1 ‚àí F (œÑ lŒ±y1 ‚àí Œ¥¬µ(y1 )b)
This formula says that when costs, l, are marginally increased by a small amount, the share of
people who are lost is proportional to the density of people right on the margin ‚Äì given by the PDF
f (y) ‚Äì to the number of people who are inframarginal, given by the 1 ‚àí F (y) term.
This expression shows that a sufficient condition for targeting efficiency to be improving as l
increases is that the hazard rate,
f (œÑ lŒ±y ‚àí Œ¥¬µ(y)b)
1 ‚àí F (œÑ lŒ±y ‚àí Œ¥¬µ(y)b)

(9)

f (œÑ lŒ±y‚àíŒ¥¬µ(y)b)
is weakly increasing with y, since if this is true then clearly 1‚àíF
(œÑ lŒ±y‚àíŒ¥¬µ(y)b) œÑ Œ±y is increasing in y.
This property holds if F () represents a uniform, logistic, exponential or normal distribution, but
not in other relevant cases such as the Pareto distribution and other ‚Äúthick-tailed‚Äù distributions. The
Œ≤
log-logistic distribution function F () = cŒ≤+Œ≤ where c and Œ≤ are two known positive parameters
and  ‚â• 0, exhibits declining hazard rates as long as Œ≤ ‚â§ 1, but not otherwise.
To gain intuition into the model, we provide a simple illustration. In Figure 1, we examine the
simplest case of no shocks and linear utility. In Panel A, we draw the relationship between income
12

and gains for registration sites that are closer versus farther away. Note that the gain is decreasing
more steeply with income for higher distance; this is the standard single-crossing property common
to all screening models. As Figure B shows, moving from lower to higher distance reduces the
number of applicants, but only among the rich. Thus, targeting efficiency improves.
Figure 2 shows an example of how introducing shocks can overturn the benchmark intuition
developed in Section 3.2.1 above. We consider a simple case where income y ‚àà [0, 5], we set
œÑ Œ± = 0.2 and Œ¥¬µ (y) b = 0.5, choose the log-logistic parameters Œ≤ = c = 0.5, and consider distances
l ‚àà {2, 3}. As shown in Panel A, at any given consumption level, show-up rates are of course still
higher at lower distances, and for any distance level, show-up rates decline in income. What is
important however to note however is that in this example, the initial rate of decline in show up
rate with income (once the epsilons kick in) is quite high, but then slows as incomes become high.
f (y)
This is a consequence of the thick tails of the log-logistic distribution, which implies that 1‚àíF
(y) is
decreasing in y. This implies that increasing the distance from 2 to 3 actually hurts the ratio of of
poor to rich show-up rates, because it has a very large impact on the takeup at low income levels
f (y)
f (y)
(where 1‚àíF
(y) is large) but a much smaller impact at high income levels (where 1‚àíF (y) is small).
What this discussion illustrates is that single crossing in the classical screening sense is not
sufficient for increasing ordeals to increase targeting effectiveness. Instead, one also needs to consider
the density of people who are near the threshold and, hence, who will be affected by any marginal
change in ordeals.

3.2.3. Non-linearities in the Application Cost. Let us continue to assume linear utility, but now
model a non-linearity in the cost of applying, c (l, y). This non-linearity may be more realistic
because there are different transportation modes: one can either walk or take a bus. Buses are
faster, but they cost money. Given that l is the distance to the registration site, walkers face a
calorie cost Œ≥l and a time cost œÑ lw, where w is their wage rate and œÑ l is defined to include the
waiting time. Taking a bus requires a fixed bus fare, ŒΩ, plus a time cost, Œªlw, where Œª < œÑ . Once
again, Œªl includes waiting time. Assuming that the wage is proportional to income, w = Œ±y, the
decision rule is:
Ô£±
Ô£≤bus if ŒΩ + ŒªlŒ±y < Œ≥l + œÑ lŒ±y
D=
Ô£≥walk if ŒΩ + ŒªlŒ±y ‚â• Œ≥l + œÑ lŒ±y

(10)

Applying is optimal if and only if:
‚àí min{Œ≥l + œÑ lŒ±y, ŒΩ + ŒªlŒ±y} + Œ¥¬µ(y)b ‚â• lnŒµ

(11)

The expression on the left hand side is declining in y. Therefore, richer people always apply less.
To look at the effect of increasing l, consider two income levels y1 and y2 , such that at y1 , an
individual just prefers to walk if he applies, and at y2 , he just prefers to take a bus, so that y1 and
y2 are separated by some small distance œà. For those with income y1 , the cost of travel is Œ≥l +œÑ lŒ±y1 .
For those at y2 , it is ŒΩ + ŒªlŒ±y2 . The fall in utility due to an increase in distance of ‚àÜl will be greater
at y1 than y2 : (Œ≥ + œÑ Œ±y1 ) ‚àÜl > (ŒªŒ±y2 ) ‚àÜl. Therefore, an increase in distance can increase travel
costs more for the poor than for the rich.
13

To see this intuitively, consider the simple illustration in Figure 3. For both the rich and poor,
taking the bus is initially more expensive (i.e., no bus fare), but has a lower marginal cost. Due
to the higher marginal cost of their time, the rich switch to buses at lower distance than the poor
(l‚àó ). Between l‚àó and l‚àó‚àó (where the poor switch to the buses), one can clearly see from the figure
that the marginal travel cost when l is increased is actually larger for the poor than the rich. As
a result, even in the case where F (.) has increasing hazard rates, targeting efficiency may worsen.
Note from the figure that this cannot happen if both people walk or both take the bus (i.e., travel
costs are locally linear), or if the difference in incomes between them is large enough.
3.2.4. Curvature in the Utility Function. Finally, we introduce curvature into the utility function
by letting U (x) = lnx. To focus on one mechanism, assume that there is no utility shock ( ‚â° 0),
that the cost of travel is linear in distance (c(l, y) = Œ≥l + œÑ lŒ±y)), and that ¬µ(y) is a constant. In
this case, the net gain from applying is:

g(y, l) = ln (y ‚àí c (l, y)) + ¬µŒ¥ ln (y + b) + (1 ‚àí ¬µ) Œ¥ ln y ‚àí ln y ‚àí Œ¥ ln y
= ln

(y ‚àí c (l, y)) (y + b)¬µŒ¥ y (1‚àí¬µ)Œ¥
yy Œ¥

(12)
(13)

The household will apply when:
(y ‚àí c (l, y)) (y + b)¬µŒ¥
‚â•1
yy ¬µŒ¥
For convenience, we will work with the following function:22

(14)

(y ‚àí c (l, y)) (y + b)¬µŒ¥
.
(15)
yy ¬µŒ¥

There exists a y min such that y min ‚àí c l, y min = y min ‚àí Œ≥l ‚àí œÑ lŒ±y min = 0. Let‚Äôs start the
discussion at this value of y because any y below this does not make sense in our model. At just
above this level of y, y‚àíc(l,y)
is close to zero and as a result g must be less than one, so those with
y
income levels in this range will not apply. As y increases, G also increases, since it starts at zero
and thus can only go up). Taking the derivative of G with respect to y yields:
G(y, l) =






Œ≥l
b ¬µŒ¥ ¬µŒ¥b
Œ≥l
b ¬µŒ¥‚àí1
dG
‚àí 2 1 ‚àí œÑ lŒ± ‚àí
= 2 1+
1+
dy
y
y
y
y
y

¬µŒ¥‚àí1
 



1 + yb
b
Œ≥l
=
Œ≥l 1 +
‚àí ¬µŒ¥b 1 ‚àí œÑ lŒ± ‚àí
y2
y
y

(16)

(17)

In the neighborhood of y = y min , the expression in the square brackets is strictly positive.
However, the expression in the square bracket goes down when y goes up and converges to Œ≥l +
œÑ lŒ±¬µŒ¥b‚àí¬µŒ¥b. If this expression is positive, then G is monotone increasing in y, while if it is negative,
then it first goes up and then goes down.
22So g, defined above, is lnG.
14

Figure 4 represents the two possible configurations of G in this case. Panel A provides the case
where G first increases and then falls, while Panel B represents the case where G is monotonically
increasing. In each case, the values of y for which the G curve lies above the horizontal line at
G = 1, are those that apply. The dashed line in each figure demonstrates what happens when l
goes up. In both cases the G curve shifts down ‚Äì in Figure 4a this means that both the poorest
and richest people who were applying before the increase in l drop out, while in Figure 4b only
the poorest people drop out. In the first case, the effect on targeting depends on whether more of
the poor proportionally drop out than the rich, which in turn depends on how the population is
distributed near the two cutoffs. In the second case, the effect is unambiguously negative, with the
fraction of the rich among applicants increases when l goes up.
It is worth noting that so far in this discussion we suppressed the effect of y on ¬µ(y), which goes in
the direction of making the G function downward sloping. In particular, if there exists a y max such
that for y ‚â• y max , ¬µ(y) ‚âà 0, as seems reasonable, then above y max , G < 1 and no one will apply.
The more realistic case is therefore probably the case in Figure 4a, and the effect of an increase in
l on targeting will depend on the shape of the income distribution.
3.3. Summary. This exercise illustrates the complexities in designing ordeal mechanisms: once
we introduce a number of realistic features into the model, such as utility shocks that may have
thick-tailed distributions, alternative means of transportation, and diminishing marginal utility, the
intuitive argument that ordeals induce self-selection because the poor have a lower opportunity cost
of time is no longer automatically true. Increasing the costs of the ordeal can worsen self-selection
under relatively standard assumptions (log utility, as we saw above, for example is enough). Note
that we have not yet even introduced the more behavioral arguments for why the poor may not be
able to access the programs that are intended for them, such as self-control problems (e.g., Madrian
and Shea, 2001), stigma (e.g., Moffitt, 1983), as well as informational arguments, such as the fact
that the poor may not learn about the programs that are available to them (e.g., Daponte, Sanders
and Taylor, 1999).
Given the theoretical ambiguity, whether self-targeting improves targeting efficiency is ultimately
an empirical question. Therefore, we now turn to the data.
4. Who Self-Selects?
We begin by examining whether richer or poorer households were more likely to apply for the
PKH program in the 200 villages where the government implemented the self-targeting treatment.
Specifically, we plot a nonparametric Fan (1992) regression of the probability of applying against
baseline log per capita consumption (Figure 5). Note, again, that the consumption data was collected before any mention of targeting occurred.23 Bootstrapped standard error bands, clustered at
the village level, are shown in dashes.
23Consumption may, of course, not be a perfect measure of welfare. First, there may be measurement error in

consumption. Second, there may be alternative measures of welfare that may or may not more accurately represent
a household‚Äôs well-being (see Alatas, Banerjee, Hanna, Olken and Tobias (2012)). We use consumption because this
is often the metric that governments are trying to actually target on. Note that these measurement errors will not
affect our experimental results if the variation in consumption captures relative well-being; the measurement error
will simply introduce noise into our estimate.
15

Across all expenditure ranges, Figure 5 shows that the poor are more likely to apply than the
rich. This is evident as the probability of applying falls monotonically with per capita consumption.
At the very bottom of the expenditure distribution, a majority of households apply. For example,
61 percent of households at the 5th percentile of the consumption distribution do so. The share
applying falls rapidly as consumption increases: at the middle of the expenditure distribution, only
39 percent percent of households apply, and by the 75th percentile, only 21 percent do so. At the
95th percentile of per capita expenditure, only 10 percent of households apply.
From the perspective of the government, self-selection could affect targeting along two distinct
dimensions. First, there could be selection on characteristics that are observable to the government:
that is, households that have more assets, and are therefore less likely to pass the PMT, may be less
likely to show up. This type of selection could potentially save the government resources since it
would reduce the number of interviews that they would have to conduct for those who are likely to fail
the PMT anyway, but it would not necessarily change the poverty profile of beneficiaries compared
to automatic enrollment.24 Second, there could be selection on the unobservable component of
consumption: that is, conditional on a household‚Äôs PMT score, households with higher unobservable
consumption might also be less likely to attend. This could arise if there is self-selection based
on the opportunity cost of time (as in the model), or if households do not perfectly understand
the construction of the PMT score. If this type of selection on unobservables is occurring, then
introducing self-selection has the potential to lead to a poorer distribution of beneficiaries than
automatic enrollment.
To investigate this, we can decompose household consumption into the observable and unobservable components:
0
LN P CEi = Xi Œ≤ + i
(18)
where LN P CEi is the household‚Äôs log per capita consumption, Xi are the observable characteristics
that enter the PMT formula, Œ≤ are the PMT weights, and i is the residual, or the unobserved
component of consumption. We then examine the relationship between the probability of applying
0
and both the observable component, Xi Œ≤ and the unobservable component, i .
We first examine these relationships graphically, presenting non-parametric Fan regressions of
the probability of showing up as a function of the observable (Figure 6, Panel A) and unobservable
(Panel B) components of log per capita consumption. Bootstrapped standard 95 percent confidence
intervals (clustered at the village level) are shown in dashes, and the vertical line in the top panel
shows the average eligibility cutoff for receiving benefits. Strikingly, the probability of applying is
decreasing in both the observable and unobservable components of consumption.
We now formally examine these relationships in a regression framework. Table 3 provides the
results from estimating the following logit equation:
P rob (showup = 1) =

exp {Œ± + Œ≥P M Ti + Œ≥i }
1 + exp {Œ± + Œ≥P M Ti + Œ≥i }

(19)

24In reality, it is often too costly to interview everyone in the country, so most governments do some form of selection

to reduce the number of people interviewed. In our experimental results, we compare self-targeting to another
methodology that the government uses to cull the number of interviews (the current status quo for Indonesia). We
will then compare the efficiency of self-targeting to that of a hypothetical, full census PMT, to explore this dimension
further.
16

where P M Ti is the predicted portion of a household‚Äôs log per capita consumption (equal to Xi0 Œ≤
from equation (18)) and i is the residual portion of a household‚Äôs log per capita consumption from
equation (18). We use logit specifications since baseline showup rates will differ substantially once
we start to examine different samples, and therefore, in these settings the logit model is easier to
interpret. We show in Table A.2 that the results are qualitatively similar if we use linear probability
models instead. Finally, note that all standard errors are clustered by village.
Table 3 confirms the graphical analysis and shows that there is self-selection along both margins,
and that both of these forms of selection occur within both poor and richer households. Column
(1) provides the coefficient estimates for the full sample. Both the observable and unobservable
component of consumption significantly predict applying at the 1 percent level. The relative magnitudes suggest that the observed component of consumption has about 2.5 times the impact of
the unobserved component, but both are large: a doubling of the PMT score (i.e., predicted log
consumption based on assets) reduces the log-odds ratio of showing up by about 1.5; a doubling
of the unobserved component of consumption reduces the log-odds ratio of showing up by about
0.6. In Columns (2) and (3), we split the sample based on whether the household would have
been eligible to receive the program had they chosen to apply. What is notable is that selection on
unobservables occurs in both samples. Thus, even among the poorest 4 percent of households in
our sample, those who are poorer on unobservables are more likely to apply. This strong selection
on unobservables suggests that self-selection has the potential to result in a dramatically poorer
distribution of beneficiaries than other methods.
While both PMT scores and unobservables predict show up rates, the R-squared is of course
not 100 percent, so it is interesting to examine what other factors influence show up decisions. In
Appendix Table A.3, we add additional variables to equation (19). Panel A reports the results
for the entire sample; Panel B reports the result for the subset of people who would be eligible.
Several results are worth noting.25 First, household‚Äôs subjective perceptions of their own wealth
influence show up ‚Äì i.e. those who perceive themselves to be poorer on a subjective scale of 1 to
6 are substantially more likely to show up. Second, those households who have received previous
government programs (e.g., Raskin (rice for the poor), Askeskin (health insurance for the poor),
and BLT (direct cash assistance for the poor)) are also more likely to show up. Both of these
results suggest that households may be basing their show up decisions in part on their perceived
likelihood of receiving programs conditional on applying (i.e. their perceptions of ¬µ(y)), an issue we
will return to in Section 6.2 below. Third, more educated households are less likely to apply, not
more, suggesting that education is not a constraint on understanding program application rules in
this context.
5. Comparing Self-Selection and Automatic Enrollment
The self-targeting treatment generated considerable self-selection, and yet only about 60 percent
of the poorest group showed up, suggesting that there was significant exclusion error. However, it
is not clear that we should be comparing self-targeting to the theoretical ideal of no error because,
in reality, it is very costly for the government to collect consumption data for each and every
25Appendix Table A.3 is a logit specification, similar to Table 3; OLS results are shown in Appendix Table A.4.
17

household. Instead, the government‚Äôs choice is often to conduct self-targeting or to conduct an
alternative targeting methodology.26 Therefore, in Section 5.1, we compare self-targeting against
the real government procedure, which consists of an automatic enrollment for those who pass a
proxy-means test among those selected to be interviewed by the government and local communities.
Next, in Section 5.2, we additionally compare self-selection against a hypothetical exercise where we
use the data that we have collected independently to predict selection if the automatic enrollment,
based on the proxy-means test, was implemented universally.
5.1. Experimental Comparison of Self-Targeting with Status Quo Targeting. In this section, we test whether the types of individuals selected under self-targeting and automatic enrollment
(the current status quo procedure of the Indonesian government) differ. To do so, we compare the
distribution of beneficiaries in the 200 villages randomized to receive the self-targeting treatment
with the 200 villages randomized to receive the automatic enrollment treatment. Given the randomization, the distribution of beneficiaries and the probability of receiving benefits should be identical
in the two sets of villages absent the difference in targeting, so we can ascribe the differences that we
observe between the two sets of villages to the differences in targeting methodologies (see Appendix
Table A.1).
We begin with a graphical analysis in which we compare the distribution of beneficiaries under the
self-targeting and automatic enrollments treatments (Figure 7). In Panel A, we plot the cumulative
distribution function of log per capita consumption of the final PKH beneficiaries in both sets of
villages. The beneficiaries appear substantially poorer: the CDF of beneficiaries‚Äô consumption under
automatic enrollment first-order stochastically dominates that under selection. A KolmogorovSmirnov test of equality of distributions yields a p-value of 0.103.27
While the results in Panel A imply that the distribution of beneficiaries are poorer under selfselection, it does not tell the full story. In particular, it does not tell us whether this is due to
the inclusion of more poor households, the exclusion of rich households, or some combination of
both. To answer this question, we present non-parametric Fan regressions of the probability of
obtaining benefits as a function of log per capita consumption in Panel B of Figure 7. Bootstrapped
95 percent confidence intervals, clustered at the village level, are shown as dotted lines. The figure
shows that the probability of receiving aid is substantially higher for the very poorest households
in the self-targeting treatment. For those with log per capita consumption in the bottom 5 percent,
i.e. those with log per capita consumption below about 12.33, the probability of receiving benefits
is more than double that in self-targeting: 16 percent of those with log per capita consumption in
the bottom 5 percent receive benefits as compared with just 7 percent in the automatic enrollment
treatment. This difference is statistically significant at the 5 percent level. While exclusion error
is still very high ‚Äì even in self-targeting, only 16 percent of these very poor households received
benefits, meaning that 84 percent were excluded ‚Äì the rate of receiving benefits is 4 times higher
26Unlike asset data, which is verifiable in an in-person interview, consumption data is completely unverifiable since

it is all self-reported. Even if the government could afford to do a consumption survey for all households, it could
not use such data for targeting purposes since doing so would induce people to understate their true incomes.
27This p-value is based on randomization inference methods accounting for clustering at the village level. Alternatively, abstracting from the village-level clustering yields an exact p-value of 0.069.
18

than the overall rate of 4 percent of households in the sample who receive benefits, and double what
it is in the status quo automatic enrollment villages.
Conversely, households at higher consumption levels are substantially more likely to receive benefits in the automatic enrollment treatment. Households in the top 50 percent of the per capita
expenditure distribution ‚Äì none of whom should be receiving benefits ‚Äì are more than twice as likely
to receive benefits in automatic enrollment than in the self-targeting treatment: 2.5 percent of such
households receive benefits in automatic enrollment compared with 1 percent of such households
in self-targeting (statistically significant at the 5 percent level). One explanation is that there are
always errors in the PMT formula that allow some fraction of ineligible households to slip through
the proxy-means test. With self-targeting, however, most of these households do not apply, so
many fewer of them slip through. In sum, Figure B suggests that self-targeting both increased the
probability that very poor households received benefits and decreased the probability that richer
households did so, relative to the current status quo.
We now more formally quantify these effects using regression analysis, the results of which are presented in Table 4. In Column (1), we compare the difference in average log per capita consumption
of the beneficiary populations (LN P CEvi ) in the two treatments, by estimating by OLS:
LN P CEvi = Œ± + Œ≤SELFv + œëvi

(20)

where SELFv is a dummy for village v being in the self-targeting treatment and œëvi is the error
term. Standard errors are clustered by village. We estimate this model directly (Panel A) and with
stratum fixed effects (Panel B). Note that this is the regression equivalent of comparing the means
of the two distributions shown in Panel A of Figure 7. As suggested by the figures, the regression
analysis confirms that beneficiaries are substantially poorer under self-selection: Column (1) of
Panel A reports that per capita consumption of beneficiaries is is 21 percent lower in self-targeting
as compared to automatic enrollment (significant at the 1 percent level). Including stratum fixed
effects (Panel B), the difference becomes 11 percent, and the p-value increases to 0.14.28
To increase our precision of the difference in consumption levels of beneficiaries, as discussed
above, we did an interim midline survey after the targeting was complete, but before program
beneficiary status had been announced or benefits had begun, in which we oversampled beneficiaries
in both PMT and self-targeting villages. In Column (2), we compare log per capita consumption of
beneficiaries in the two treatments, including both the 159 beneficiaries from our baseline sample
and the additional 745 beneficiaries who we oversampled in the midline. Since the average level
of consumption may be different in these two survey rounds (for example due to seasonality), we
include a dummy variable for the survey round in which the data was collected. The results in
Column 2 are similar in magnitude but more precisely estimated: self-targeting selects beneficiaries
who are 18 to 19 percent poorer than those selected by the PMT treatment (statistically significant
at the 1 percent level).

28In general, one would expect stratum fixed effects to improve precision. However, in the regressions where we only

consider beneficiaries, we have so few observations (159 observations), and hence so few observations per stratum, that
including the fixed effects effectively drops many whole strata from the analysis, dramatically diminishing statistical
power.
19

In Column 3 of Table 4, we examine the probability of getting benefits (P rob (BEN EF ITvi = 1))
across the treatments for different groups. Specifically, we provide estimates from the following logit
model:
exp {Œ± + Œ≤SELFv + Œ≥LN P CEvi + Œ∑SELFv √ó LN P CEvi }
P rob (BEN EF ITvi = 1) =
(21)
1 + exp {Œ± + Œ≤SELFv + Œ≥LN P CEvi + Œ∑SELFv √ó LN P CEvi }
The coefficient of interest is the coefficient Œ∑ on SELFv √ó LN P CEvi , which captures the degree
to which there is differential targeting in the self-targeting treatment as compared with automatic
enrollment (the omitted category).29 The results confirm the overall story shown in Panel B of
Figure 7: the coefficient on Œ∑ is negative, large in magnitude, and statistically significant. This
implies that there is much stronger targeting by consumption in the self-targeting treatment than
in the automatic enrollment treatment. The magnitudes suggest that targeting is twice as strong
in self-targeting: the estimates in Panel A imply that doubling consumption decreases the log-odds
of receiving benefits by 0.70 in automatic enrollment, whereas it decreases the log-odds of receiving
benefits by 1.37 in self-targeting.
In Columns (4) - (6), we examine alternative dependent variables to quantify the types of inclusion
and exclusion error shown in Panel B of Figure 7. In Column (4) we define the overall error rate as a
dummy that is equal to 1 if either exclusion error (failing to give benefits to a very poor household)
or inclusion error (giving benefits to a non-very poor household) takes place. We find that the
log-odds ratio of making an error is about 0.2 lower under self-targeting (p-values of 0.08 without
stratum fixed effects and 0.11 with stratum fixed effects). Column (5) examines exclusion error,
defined as a dummy for a very poor households failing to receive benefits. The results in the table
suggest that the log-odds of such households being excluded (i.e., failing to get benefits) are between
0.55 and 0.71 lower in self-selection, though these results are not statistically significant (p-values
of 0.18 and 0.15, respectively). Likewise, inclusion error, defined as a non-very poor household who
does receive benefits, is lower in self-targeting, and statistically significant in the specification with
stratum fixed effects (Column (6); p-values 0.14 and 0.08, respectively).
On net, the non-parametric and parametric results combine to paint a clear picture: self-targeting
leads to a poorer distribution of beneficiaries, both because the poor are more likely to receive
benefits and because richer households are less likely to receive benefits.
5.2. Comparing Self-Targeting to a Hypothetical Universal Automatic Enrollment Treatment. In the automatic enrollment procedure, not all households were considered for enrollment.
Instead, as discussed in Section 2.3.1, households only received the full PMT interview if they passed
an initial set of screens. These pre-screening criteria were designed to save the government the cost
of having to conduct a complete long-form census of every household in the country every time it
wanted to select beneficiaries. On net, as shown in Table 2, about 34 percent of households in the
29We use logit models because the baseline benefit rate differs substantially by per capita expenditure, so proportional

models make more sense. Stratum fixed effects are also much more effective in proportional models given the
substantially different poverty levels across strata. Appendix Table (A.5) shows that the OLS version of the same
results are qualitatively similar, and if anything, show slightly higher levels of statistical significance. We cluster
the standard errors in models with no fixed effects, and all OLS specifications, by village. For the conditional logit
models where we include stratum fixed effects, for computational reasons we cluster fixed effects by stratum, which
is more conservative (one stratum contains multiple villages).
20

village received the full PMT interview, which is roughly comparable to the share of households
who self-select to be interviewed in the self-targeting treatment.
Comparing self-targeting against the current procedure is interesting because it provides information on the different methods that are realistically within a government‚Äôs choice set. However, it is
also interesting to ask how self-targeting performs relative to a PMT procedure that does not have
the pre-screening that occurs in the actual procedure. While this is less realistic (i.e., it is too costly
to actually be conducted by the government), it provides us with a greater understanding of the
margins through which self-selection occurs. Thus, in this section, we assume, hypothetically, that
the government had conducted the full PMT interview on everyone in the community. Recalling the
decomposition of who selects to apply in the self-targeting treatment in Section 4 into selection on
observables and selection on unobservables, we know a priori that self-targeting will perform worse
than universal automatic enrollment with respect to selection on observables, because by definition
universal automatic enrollment picks up 100 percent of households with PMT scores less than the
cutoff whereas self-targeting limits the beneficiaries to a subset of those who chose to apply. However, it is still possible that self-selection could still out-perform universal automatic enrollment on
net if the selection on unobservables is sufficiently large.
To simulate what would have happened in universal automatic enrollment, we use our baseline
data to construct PMT scores for those households who were not interviewed by the government
as part of the PMT process. That is, for those households who were not interviewed as part of
the real PMT treatment, we assume that they would have received benefits if their PMT score
(according to the asset data we collected in our baseline survey) was below the threshold required
to receive the program. We then repeat the same analysis in Figure 7 and Table 4, but instead
of comparing self-targeting to the actual automatic enrollment treatment, we compare it to the
constructed hypothetical universal automatic enrollment procedure.
The results are shown graphically in Figure 8 and in regression form in Table 5. Panel A of
Figure 8 shows that the distribution of beneficiaries still looks poorer in self-selection than in the
hypothetical universal automatic enrollment, though the difference between the two distributions
is no longer statistically significant (p-value from the Kolomogorov-Smirnov test of equality of
distributions, with randomization inference to cluster at village level, is 0.29). Panel B of Figure 8
reveals that automatic enrollment and self-targeting have similar patterns in terms of the probability
of being selected at the low end of the spectrum (though error bars cannot rule out some differences
between them), but that wealthier households are more likely to receive benefits under the automatic
enrollment than self-targeting. This is related to selection on unobservables shown in Figure 7b ‚Äì in
the automatic enrollment treatment, some high consumption people make it through the PMT screen
due to errors in the PMT, whereas those people do not self-select in the self-targeting treatment.
Looking at the regressions, Columns (1) and (2) of Table 5 confirm that, even under this hypothetical universal automatic enrollment treatment, the beneficiaries are poorer in self-targeting
than in automatic enrollment (though statistical significance depends on specification.)30) Although
noisy, exclusion error looks slightly higher in self-targeting (not surprising given that if data quality
30Note that we cannot replicate the analysis using the midline oversampling of beneficiary households here (e.g., the

analogue of Column 2 of Table 4, since we did not oversample those households who would have been beneficiaries
under the hypothetical universal PMT.
21

is the same, the hypothetical PMT should enroll a superset of those enrolled under self-targeting).31
Inclusion error is substantially lower in self-selection. As a result, the overall error rate in targeting
is substantially (and statistically significantly) lower in self-targeting than under this hypothetical
universal automatic enrollment.
5.3. Costs of Alternative Targeting Approaches. Self-targeting appears to perform better in
identifying the poor, but it also entails costs. There is the cost of the ordeal: households lose
valuable time traveling to the interview site and waiting in line to be interviewed, and often need
to spend money traveling as well. In addition, both self-targeting and PMT entail administrative
costs ‚Äì enumerators need to be paid to conduct interviews at self-targeting application sites for
self-targeting and to conduct field verification visits to assess PMT scores in both self-targeting and
PMT. One of the potential benefits of self-targeting is that it reduces the number of surveys that
need to be conducted compared to a universal PMT; but if those cost savings to the government
were offset by commensurate increases in the waiting and travel costs paid by households, one might
not be so sanguine about such a policy.
To help shed light on this issue, Table 6 presents data on costs for the 200 villages in our sample
in each treatment, along with the number of eligible households that do and do not receive benefits
(exclusion error), the number of ineligible households that do and do not receive benefits (inclusion
error), and, by way of comparison, the total annual dollars of benefits paid out to beneficiaries. We
separate costs paid by households into those paid by households who end up receiving the benefits
(for whom the net cost of applying or being interviewed was therefore positive) and for those paid
by households who do not end up receiving the benefits (for whom the net cost of applying or
being interviewed was negative). For PMT, where we surveyed only a single neighborhood, we
extrapolate to the entire village linearly; likewise, we extrapolate the costs for the hypothetical
universal PMT linearly from the actual PMT costs. Finally, note that there could be economies
of scale in implementing a national program. For PMT, where we indeed know the Indonesian
government‚Äôs costs from implementing the nationwide PMT, we report those ‚Äúat scale‚Äù costs as well
as those from our experiment; for self-targeting, which has yet to be done nationally, we do not
have an analogous estimate.
The results show that the costs on households imposed by self-targeting for 200 villages totaled
around USD$70,000. The bulk of these costs (87 percent) were borne by non-beneficiaries, both
because there were more of them and because, on average, they have a higher imputed wage rate.
Administrative costs added an additional $170,000, so the total costs of targeting were around
$240,000; this compares to around $1.2 million in benefits paid out in these villages per year.
Since eligible households generally receive the program for 6 years, the total targeting costs for
self-targeting are about 3 percent of the total benefits given out.
The PMT treatment, which interviewed a similar number of households, imposed only US$9,366
in costs on households (just the time they spent at home taking the asset survey), and if we use
the national-scale administrative costs, had a total cost of $120,378. But, as shown above, it had
31Of course, data quality may not be the same: in self-targeting, only a small number of households likely to be

selected are visited at home for the PMT interview, while in automatic enrollment, a much larger number are
interviewed. It is possible that in the smaller, more focused self-targeting interviews, data quality is higher.
22

substantially higher rates of both inclusion and exclusion error compared to self-targeting. The
hypothetical universal PMT, shown in Column (3), had almost identical exclusion error to selftargeting, though it had almost double the inclusion error. The total costs imposed on households
would be about $32,000 (about 45% of PMT), but the administrative costs, even using the nationalscale administrative costs, are about double that of self-targeting.
This analysis suggests that, if we treat administrative costs and costs borne by households equally,
self-targeting dominates the hypothetical universal PMT, in that it achieves better targeting at lower
total costs. Self-targeting and the status quo automatic enrollment PMT lie on very different parts
of the frontier: the status quo costs as much as 40 percent less than self-targeting (though this
difference could be muted if self-targeting enjoyed the same nationwide economies of scale as the
status quo), but has substantially higher rates of both inclusion and exclusion error. The main additional difference is that self-targeting places a higher fraction of the burden directly on households,
including many who do not ultimately receive benefits. Whether the benefits of increased targeting
outweigh the costs therefore depends on how one weighs costs borne by households compared with
administrative costs.

6. Marginal Effect of a Change in the Ordeal
Thus far, the findings suggest that self-targeting outperforms the status quo PMT procedure in
identifying the poor. We next explore the optimal way to design ordeal mechanisms. We showed in
Section 3 that the effect of marginally increasing the intensity of ordeals on separating the rich from
the poor is theoretically ambiguous. Therefore, we first experimentally test the effect of a change
in the ordeal on selection. Specifically, we examine the results from experimentally varying the
distance to the registration site and the number of households members required to be present at
the application site, as discussed in Section 2.3. Note that these experiments were carefully designed
to be within the set of policy instruments that potentially could be considered by the government
in their real conditional cash transfer program, under the requirements that the ordeals could not
be so onerous that they would either discourage the severely credit-constrained poor from applying
or that the program would unduly impose large application costs for the poor who might still be
incorrectly screened out by the asset test.
We then use the cross-sectional variation in our data to probe this question further: we fit a
CRRA utility model of the decision to apply with logit shocks for different income groups, using
a Generalized Method of Moments. The model helps us to understand which of the theoretical
channels outlined seem to be driving the results, and it allows us to predict whether one can
differentially improve the selection of the poor by increasing the ordeals.
6.1. Experimental Analysis. We begin our discussion by exploring the effect of increasing distance. In the self-targeting villages, we experimentally chose whether the sign-up location would be
situated very close or further away from the potential applicants‚Äô households. As Appendix Table
A.9a shows, moving from the far to close registration sites decreased the distance from 1.88 km
to 0.27 km; a reduction of 1.61 kilometers (or 1.69 kilometers controlling for strata fixed effects).
23

32

If the simplest version of the theory holds (See Section 3.2.1 under the assumption that the
utility shocks are uniformly distributed), we expect that there should be more applicants in the
close treatment and that they should be, on average, richer. Note, however, that under different
model assumptions, the effect may be negative.
Table 7 explores the impact of the close treatment on targeting outcomes by estimating the
following logit equation:
P rob (showup = 1) =

exp {Œ± + Œ≤CLOSEv + Œ≥LN P CEvi + Œ∑CLOSEv √ó LN P CEvi }
1 + exp {Œ± + Œ≤CLOSEv + Œ≥LN P CEvi + Œ∑CLOSEv √ó LN P CEvi }

(22)

where CLOSEv is a dummy for the close treatment in village v, LN P CEvi is household i‚Äôs log per
capita consumption, and CLOSEv √ó LN P CEvi is the interaction between them. Columns (1) - (3)
show results without stratum fixed effects, and Columns (4) - (6) show results with stratum fixed
effects.
Increasing distance reduces the number of applicants, but does not differentially affect who applies. We first show the results from estimating equation (22) including only the CLOSEv variable.
The results show that the close treatment increases the log-odds of applying by between 0.21 (Column 1, no stratum fixed effects, p-value 0.16) and 0.28 (Column (4), with stratum fixed effects,
p-value 0.101).33 Put another way, this means that moving from far to close increases the percentage
of households that apply by 15 percent (5.8 percentage points). When we test for differential selection by consumption (Column (5)), we are unable to distinguish the effect of the close treatment
by consumption levels from zero. Given that the theory implies that there may be non-linearities
in the effect on the type of individual who applies when we alter the ordeal, we next explore potential non-linearities in the effect. Specifically, Column (6) interacts the close treatment dummy
with dummies for quintiles of log per capita consumption, and once again, we find no evidence that
moving the targeting closer to the households differentially changes the distribution of who showed
up.
Similarly, as shown in Table 8, we also do not observe significantly fewer people applying when we
require both spouses to apply in person rather than allowing either spouse to apply alone.34 Given
this, it is not surprising that we find no effect either on the interaction of BOT H with per capita
consumption (Column (5)), or when we interact the treatment with quintile bins of consumption
(Column (6)). One potential reason why requiring both spouses did not decrease enrollments is that
this treatment included a provision through which households, in which one spouse was out of town
and could not attend the interview, could get a signed letter from a neighborhood leader to this
effect, allowing the interview to proceed with only one spouse. A total of 28 percent of interviewees
32Given differences in geography, the treatment effect of distance varied across rural and urban locations. In rural

areas, the sign-up station in the close treatment was located in each hamlet of the village (essentially 0 distance from
people‚Äôs houses), whereas in the far treatment it was in the village office (an average of 1.2 km from people‚Äôs houses)
(see Appendix Table A.9b). In urban areas, the sign-up station in the close treatment was located in the village office
(an average of 0.8 km from people‚Äôs houses), whereas in the far treatment it was in the subdistrict office (an average
of 3.1 km from people‚Äôs houses) (see Appendix Table A.9c).
33The OLS version of this coefficient, which is clustered at the village level rather than the stratum level, is statistically
significant at the 5% level (p-value 0.024). See Appendix Table A.7.
34In fact, the estimates suggest that requiring both spouses to attend actually increases overall applications somewhat,
perhaps because requiring both spouses means that the second spouse acts as a commitment device to show up, or
perhaps because it is more fun to go together.
24

came with such a letter, suggesting that this provision may have been used to allow those with high
opportunity costs to register anyway. This suggests that ordeals may in fact be hard to enforce in
practice ‚Äì loopholes such as this one, which the government put in place to be fair to those who, for
exogenous reasons, could not possibly comply with the ordeal, can be exploited to undo the intent
of the ordeal. This phenomenon seems similar to related problems observed in providing incentives
to nurses in India to show up at work ‚Äì a loophole that was required to exempt those who could
not attend because of a legitimate outside obligation from the incentive program was expanded so
much that it undid the entire impact of the incentive program (Banerjee, Duflo and Glennerster,
2008).
6.2. Using the Model to Distinguish Theories and Predict Alternative Policies. In this
section, we return to the model in Section 3, estimate the unknown parameters of the model using
the cross-sectional variation in the data, and use it to both understand the results thus far and
to explore the effect of further increasing the ordeals on selection. The calibrated version of the
model is useful for several reasons. First, it will help us understand whether the lack of differential
selection we observe from experimentally increasing applications costs is consistent with what a
calibrated version of the model would predict. Second, it allows us to test specifically for the different
theoretical mechanisms outlined in the model (e.g., curvature in the utility function, different modes
of transport for rich and poor). Finally, it allows us to consider counterfactual alternative policies
to see how large the costs would have to be in order to differentially affect selection of rich and poor.
To take the model to the data, we start with equation (3), and specify a functional form for the
1‚àíœÅ
utility function U and shock term . We assume that utility has a CRRA form (U (x) = x1‚àíœÅ ) with
unknown curvature parameter œÅ, and that the idiosyncratic utility shocks are drawn from a logistic
distribution with mean Œ±Œµ and standard deviation Œ≤Œµ . We focus on fitting these three parameters ‚Äì
œÅ, Œ±Œµ and Œ≤Œµ . 35
To estimate the model, we exploit the cross-sectional variation in registration costs and benefits.
We use data only from the far treatment group in fitting the model, so that we can explore what
happens experimentally in the close treatment group as an out-of-sample validation of the model.
We define registration costs as the per capita monetary cost, including foregone wages, of traveling
to the registration site, waiting in line, and returning home. That is, for household i, we specify:

c (yi , li ) = wagei ‚àó traveltimei + waittime + travelmoneyi ,
(23)
where traveltimei and travelmoneyi are the individuals‚Äô reports of the time and expenditure required to reach the application site, which we observe in the baseline survey for all households,
regardless of whether they show up or not. We compute waittime by taking average wait times by
treatment group and urban/rural designation calculated from the endline survey.36 We calculate
35We opt to not estimate a fourth parameter, Œ¥, because it turns out to have a lot of individual level heterogeneity

which makes it hard to separate from the utility shocks. Choosing a reasonable value for Œ¥ is further complicated by
the fact that PKH is supposed to last six years, but not everyone necessarily knows or believes that it will continue
for that long. The discount factor therefore reflects that uncertainty as well as the usual impatience. For this reason,
we take our baseline estimate of an annual discount factor to be 0.5, which is much lower than most conventional
estimates, but show in the Appendix Table A.10 that the results are similar with other choices of Œ¥.
36We do not have sufficient data to calculate separate wait times for each village.
25

the household hourly wage rate wagei by dividing monthly household expenditure by hours worked
by the household in a month.
Figure 9 plots a Fan regression of the total costs of applying c (yi , li ) against per capita consumption yi . The figure shows that the actual total sign up cost exhibits some mild concavity of the sort
we introduced as a possibility in Section 3.2.3.37
We calculate the level of benefit, bi , that the household would receive if enrolled in the program
based on the number of children and their respective education levels.38 We use a probit model to
predict ¬µ(yi ), the probability of getting the benefit conditional on applying.39 Since consumption
is likely measured with error, we assume that individuals make their decisions based on their true
income y ‚àó , whereas we observe y = y ‚àó eœâ , where œâ is a normally distributed error term. We use
the fact that, for a random subset of our sample, we observe per capita consumption measured 3
months apart in the two endline surveys to calibrate the standard deviation of œâ, which we estimate
to be 0.55, suggesting measurement error in consumption is non-trivial in our setting. We use the
cross-sectional variation within the far treatment in wagei , traveltimei , travelmoneyi , bi and ¬µ(yi )
to identify the model.
We estimate the model by Generalized Method of Moments, where the moments are the mean
values of the show up rates for the five quintiles of the consumption distribution in the far treatment. This gives us five moments to estimate three parameters, so we use a standard two-step
GMM procedure to compute optimal weights among the five moments. For each quintile in the far
treatment, we thus match the empirical show up rate by integrating over possible unobserved values
of the utility shock  and measurement error œâ term as follows:
¬®
P rob(showup = 1) =
1 {g(yi eœâ , li ) +  > 0} df dfœâ
1‚àíœÅ

where g (y, l) is defined in equation (4) and where U (x) = x1‚àíœÅ .
Table 9 shows the estimated parameter values. Specifically, the three estimated model parameters
are Œ±Œµ = ‚àí26, 126, Œ≤Œµ = 26, 805, and œÅ = 0.0000.40 The result that Œ±Œµ < 0 implies that the
idiosyncratic utility shocks on average favor not showing up. Since utility is estimated to be linear,
Œ± is interpretable in dollar terms, so the mean  term is equal to about USD$2.50. The fact that
œÅ = 0, which implies that the households are expected income maximizers with linear utility, is
somewhat surprising: perhaps it reflects the fact that on a monthly basis both the realized gains
and the actual costs are relatively small numbers (per capita monthly benefit is on average 5.22
percent of monthly per capita expenditure for the entire sample, while total cost per capita is 0.72
37A regression of c (y , l ) on y and y 2 show that the coefficient on the quadratic term is statistically significant at
i i
i
i

the 5 percent level. This is not driven by the outliers shown in the figure; we obtain a similar result even when we
drop the 17 observations with per capita consumption above Rp. 2,000,000 per month.
38The benefit is calculated as follows. Each beneficiary household receives a base benefit of Rp. 200,000 per year.
This level increases by Rp. 800,000 if they have a child age less than 3 or are currently expecting, by Rp. 400,000
if they have a child enrolled in primary school, and by Rp. 800,000 if they have a child in middle school. Since all
beneficiaries fall into at least one of these categories, the benefit level is therefore between Rp. 600,000 and Rp. 2.2
million per year, with a mean of about Rp. 1.3 million.
39We model the probability of receiving the benefit, conditional on applying, as a function of Log PCE. We include
urban/rural interacted with district fixed effects, since the PMT cutoff for inclusion varies slightly for each urban/rural
times district cell. The results are shown in Appendix Figure A.1.
40Note that the estimation was constrained such that œÅ ‚â• 0.
26

percent of monthly per capita expenditure for the entire sample). Given the estimated linearity of
the local utility function, it is not surprising that we get a clearly downward sloping show up curve
when we graphed show up rates against per capita consumption in Figure 5, as the potential effect
of the poor having much higher marginal utility costs of signing up, as discussed in Section 3.2.4,
do not appear to play a role empirically.
We then use these estimated parameters to predict the application rates under different assumptions for the cost function c (y, l) . For each possible c (y, l) , we simulate predicted application rates.
To summarize what the model predicts, we repeat the same logit regressions we performed in Table 7
on the simulated data. We also calculate the predicted show up rates for close and far sub-treatments
for those above and below the poverty line.41
The results from this exercise are shown in Table 10, and the predicted show up rates by quintile
are graphed in Figure 10. For comparison purposes, Column (1) of Table 10 and the top-left graph
of Figure 10 replicate the actual empirical results (e.g., Column (2) of Table 7). In addition to the
empirical results from the logit model, in Panel B, we calculate the show up rates for those above
and below the poverty line for both near and far treatments. In Panel C, we calculate the ratio of
the poor to rich show up rates (i.e., equation (7) from the model) for both treatments, as well as
the difference in this ratio between the near and far treatments (i.e., equation (8) from the model).
The ratio is positive but statistically insignificant, indicating no statistically detectable differential
targeting induced by moving from near to far in the experiment.42
In Column 2 of Table 10, we begin by estimating the effect on the simulated data of the change
in c (y, l) induced by the close treatment; that is, we use the actual costs c(yi , li ) for both close and
far households calculated using equation (23), and calculate each household‚Äôs predicted show up
rate using the model. Since we only used the far treatment to estimate the model, comparing these
simulated show up rates to actual show up rates serves as an out-of-sample check of the fit of model
using the experiment. We bootstrap the standard errors using sample sizes equivalent to our actual
data and with village-level clustering, so that the standard errors reported for the model-generated
data are equivalent to those from the actual data. The results in column 2 thus show what we
would have found had the data from our actual survey been generated by the model.43
41In order to run the logits using the predicted application rates, we create 3,000 copies of the data. The copies of

each individual are assigned to apply or not apply in proportion to that individual‚Äôs predicted probability of doing so.
To make the standard errors comparable to the main experiment, we apply a cluster bootstrap approach (clustered
on villages) to this distribution, holding the total number of observations equal to the number of observations in the
actual data.
42Note that the ratio is positive but insignificant, whereas the interaction term (the estimated coefficient
on[Close ‚àó LogP CE]) in Panel A is negative and insignificant. The reason they are of different signs is that the
logit model in Panel A is estimated using the linear LogP CE variable, whereas the ratios in Panel C are based on a
dummy variable for poor / non-poor. If we re-estimate the logit model using a dummy variable for rich, we obtain
results with the same sign. Note also that the results in this table are based on the actual populations in the near
and far sub-groups. Since this was randomized, these will be statistically similar, but there may be small sample
differences. Appendix Table A.12 replicates the analysis in this table adjusting for these small sample differences.
43Other recent papers that similarly use a well-identified randomized or natural experiment to provide a check of
model fit include Kaboski and Townsend (2011) and Duflo, Hanna and Ryan (2012). More generally, the idea of
hold out samples for validation has been used in several papers, staring with at least McFadden (1977); see Keane,
Todd and Wolpin (2011). A smaller number of papers use randomized control experiments to validate a structural
model. Wise (1985) estimates a model of housing demand on control group data, and validates the model using the
forecast of the effect of a housing subsidy. More recently, Todd and Wolpin (2006) used data from the PROGRESA
27

Comparing the actual empirical estimates in Column 1 with the estimates on the model-generated
data in Column 2, we find similar results of differential targeting between the treatments. In particular, even though the model seems to over-predict show up rates in the close treatment on average,
the small differential effect between rich and poor show up ratios moving from near to far in the
simulated data is not statistically distinguishable from what we actually observe in the experiment
(Panel C; p-value 0.602). Consistent with this, the coefficients on the close dummy interacted with
log per capita consumption (Œ∑ in equation (22)), which is another way of capturing the degree of
differential targeting between the close and far treatment, are also statistically indistinguishable
between the actual experimental data in Column (1) and the simulated data in Column (2) (pvalue 0.441). The fact that the model predictions are similar to the experimental findings provides
us with greater confidence in the simulation results for alternative cost structures in the following
columns.44 A comparison of model fit can be seen by comparing the actual show up rates by quintile
and treatment in the top-left of Figure 10 with the model‚Äôs predicted show up rates by quintile and
treatment in the top-middle of Figure 10.
6.2.1. Distinguishing Alternate Theories. Interestingly, even though there is strong evidence of selfselection (the poor are much more likely to show up than the rich, both on observables and unobservables), both the experiment and the model show no statistically significant marginal increase in
the targeting ratio from increasing the severity of the ordeal (i.e., moving from near treatment to
far). We can use the model to help understand why this is not occurring, and in particular, examine
the various mechanisms outlined in the model in Section 3.
Shocks. One possible explanation developed in the theory section is that, if the distribution of
shocks does not have the monotone hazard rate property, it is possible that targeting could get
worse as you increase distance, because the density of poor people induced to drop out by a higher
marginal change is higher than the density of richer people (see Section 3.2.2). However, the version
of the structural model we estimate and use in Column (2) uses logit shocks, which do have the the
monotone hazard rate property, yet still replicates the experimental findings. This suggests that
the distribution of shocks alone are not the problem.
However, the magnitude of the shocks may explain why the response is so low. Examining
equation (8), which showed the derivative of the show up ratio with respect to a change in distance
l, one can see that increasing the variance of the shocks, which would lower the PDF f at the
program, a conditional cash transfer program in Mexico. Using only the control villages, they estimated a structural
model of fertility, school participation and child labor. The model was validated by comparing the predicted effect
of PROGRESA to the experimental estimates of program effects. Lise, Seitz and Smith (2004) use data from the
Self Sufficiency Program in Canada to validate a search model of the labor market. As in Keane and Mott (1998),
we estimate the model using the treatment sample because the incentive schedule provides useful variation for model
identification, and we use the control sample for out-of-sample model validation. Other papers which combine
structural methods and experimental data (without using the control group for out of sample validation) include
Attanasio, Meghir and Santiago (2012) and Ferrall (2010).
44The one aspect of the model that does not match is that the predicted show up rates for those below the poverty
line are actually higher in the far treatment than in the near treatment (69 percent vs 67 percent). We have verified
that this is not due to the model, but rather due to small-sample differences in the expected benefits from obtaining
the program among the poor in these two samples. In particular, the poor in the far group have (statistically
insignificantly) more middle schoolers than the poor in the near group, which leads to higher show up rates. If we
simulate the impact of of moving from far to close on the exact same group of beneficiaries, we indeed would obtain
lower show up rates in far than in close in both rich and poor samples. See Appendix Table A.12.
28

margin for both rich and poor, would dampen the responsiveness to a marginal increase in ordeals.
To assess quantitatively whether this is important, in Column (3) we re-simulate the model where
we cut the standard deviation of the shocks  in half. Doing so increases the point estimate of the
impact of moving from close to far on the poor/rich show up ratio ‚Äì from 0.314 in the base-case
model to 0.470 ‚Äì but it would still not have been enough to be statistically detectable. In Column
(4) we shut off the shocks entirely, so that everyone for whom g(y, l) > 0 shows up. This increases
the estimated impact on the show up ratio to 0.584, but again, it would not have been enough to
be statistically detectable..
Curvature in the Utility Function. Another possible explanation given by the theory is that there
may be curvature in the utility function, so that even though the marginal monetary cost of higher
distance is greater for the rich, the monetary utility cost is greater for the poor (see Section 3.2.4).
However, when we estimated the structural model, the found that the model was best fit with linear
utility (i.e. œÅ = 0), suggesting that this is not an important part of the explanation in our setting.45
Different Technologies for Overcoming Ordeals. The third explanation suggested by the model
is that there are different transportation technologies used by the poor and the rich, so that the
marginal monetary cost of distance is smaller for the rich (see Section 3.2.3). Figure 9 showed that
this might be a possible explanation in the data, as the total costs of travel do appear to be concave
in per capita consumption. To investigate whether this explains the lack of differential selection in
response to an increase in distance, we use the model to generate simulated show up rates under the
counterfactual that the poor and the rich use the same travel technology. To do so, we model travel
costs (time and money) as a function of distance. Treating urban and rural populations separately,
we regress reported monetary costs and reported travel time to the close and far registration places
on quadratic functions of distance. We then use these predicted average travel costs ‚Äì which by
construction no longer allow richer households to use different transportation technologies ‚Äì for all
households, and re-calculate total registration costs c (y, l). We then re-estimate the logit regressions
and calculate the show up rates for the simulated data using these costs instead of the actual costs.
Column (5) reports the results, which appear similar to the experimental findings (p-value 0.449
in Panel A; p-value of 0.624 in Panel C). The fact that the results are virtually unchanged when
everyone is constrained to use similar transportation technologies suggests that the lack of differential
selection between close and far is not being driven by the fact that the rich and poor use different
transport technologies. The predicted show up rates using the same transport technology are show
in the top right of Figure 10, and confirm that technology is not the main issue.
Probability of Receiving Benefits. A final explanation is that most of the selection we observe in
Section 4 is being driven by the fact that households anticipate that ¬µ(y), the probability of receiving
benefits conditional on showing up, is downward sloping in income.46 To gauge the magnitude of
that effect, in Column (6), we simulate what would happen if, instead of using the actual empirical
45Appendix Figure A.2 shows the actual model fit, and alternatives where we impose higher values of œÅ. As is evident

from the Figure, imposing higher values of œÅ leads to a more convex relationship between show up rates and income
quintile than we observe in the data.
46Alternatively, it could be that there is a stigma from applying that is increasing with income y; i.e. the rich would
feel embarrassed from showing up and applying for an anti-poverty program, and the poor would not. Empirically,
this will look identical to a downward sloping ¬µ(y) function.
29

¬µ(y) function, we assume that all households assume that they will receive benefits with some
constant probability ¬µÃÑ equal to the population average probability of getting benefits. The results
are dramatic ‚Äì the coefficient on log per capita expenditure falls from around -1.4 (in Columns (1)
and (2)) to -0.3 (in Column (5)). This suggests that about 20 percent of the selection effect is driven
by the differential costs paid by rich and poor, and about 80 percent of the selection is caused by
the fact that the poor and rich have differential beliefs about their probability of receiving benefits
conditional on applying. Comparing the change in poor to rich show up ratios when we move from
the base model to the model with constant ¬µÃÑ, the share of the selection caused by ¬µ as opposed
to differential costs is even higher. This result is consistent with the overall empirical findings of
the paper: if most of the selection is coming because ¬µ(y) declines rapidly with income rather than
c(l, y) increasing rapidly with income, then even small costs can have very large selection effects,
since people with very low ¬µ(y) will not bother to sign up, but marginal increases in the costs of
the ordeal l impose deadweight costs without substantially improving selection.
6.2.2. Simulating Alternate Policies. The results thus far suggest that perhaps the problem is largely
one of magnitudes ‚Äì one might need a very large change in ordeals to impose meaningful additional
self-selection. The remaining columns consider counterfactual experiments where, for the far group,
we increase either the distance to the application site or the average wait time, to see just how much
of an ordeal one might need for the selection to become substantial. To simulate these counterfactual
costs with increased distance, we again regress travel time and monetary costs on quadratic functions
of distance from the application site, but now we do it separately for each rural/urban and income
quintile bin, to allow costs to be heterogeneous by income group. We then calculate the additional
costs of increased distance by adding either 3 km or 6 km to the actual distance, using the estimated
relationships to calculated marginal time and money costs from that additional distance, and then
adding that amount to the actual time and money costs reported for each individual. To simulate
counterfactual costs with increased waiting time, we simply increase the average waiting times by
3 or 6 times.
The results shown in Columns (7) and (8) of Table10, and graphed in the second row of Figure
10, demonstrate that adding additional distance is still not enough to induce substantial differential
selection ‚Äì even adding 6 km of distance, almost 4 times the mean mean value of 1.67 km ‚Äì is not
enough to induce substantial additional selection. The reason is that the marginal costs of increased
distance do not appear to be that high because the costs of distance are concave ‚Äì given that at
such far distances almost everyone (even the poor) takes some form of motorized transportation,
adding 6 km of distance raises the costs of applying by only about Rp. 6,700 on average (US$70
cents) (see Appendix Table A.11).
The results in Columns (9) and (10), and graphed in the third row of Figure 10, show that, by
contrast, dramatically increasing wait times in the far treatment could induce detectable differential
selection. For example, when we increase wait times by a factor of 6 for the far treatment, we
estimate a ratio of 2.8-1 for the poor-to-rich show up rates. This compares to a predicted ratio of
2.2-1 for the baseline model in Column (2). What is happening is that the non-poor are dissuaded
from showing up ‚Äì 33 percent of non-poor show up in the baseline model, compared to only 23
percent when the wait times are increased by a factor of 6, a decline of about 30 percent. By
30

contrast, the show up rates for the poor decrease by only about 10 percent when the wait times
are increased by a factor of 6. Intuitively, wait times are more effective than distance in generating
selection because wait times are a pure time cost, so the monetary costs are much more differential
by income, while poor and rich, after a certain distance, use motorized transportation technologies
so that the marginal cost of additional distance is relatively low for both income groups.
However, it is important to note that there are problems with long wait times in practice ‚Äì the
estimated wait times we needed to assume in Column (10) averaged over 17 hours ‚Äì almost two
full work days of waiting in line. The wait times in Column (9), where we increase them by a
factor of 3, are still about 9 hours. In a pilot for this study, when we experimented with long wait
times (although still much less than 17 hours), villagers spontaneously organized themselves and
assigned queuing numbers, so that people could wait at home and come back when it was their
turn to be interviewed, rather than having to spend hours waiting in line. This suggests that while
theoretically long wait times could be an effective screening device, actually making applicants wait
for more than a full day may be very difficult in practice.

7. Conclusion
Ordeal mechanisms are often used to induce self-selection in the targeting of social programs.
However, as we show in this paper, when we introduce real-world features into the model, such
as credit constraints, non-linear utility functions, and non-linearities in the transport costs, the
conventional wisdom that increasing ordeals improves targeting does not necessarily follow anymore.
The question of whether ordeals improve selection is therefore ultimately an empirical question.
Using data from a field experiment across 400 villages to examine targeting in Indonesia‚Äôs conditional cash program (PKH), we showed that, indeed, the poor are more likely to self-select into
applying than the non-poor. Interestingly, this selection occurred on two types of margins. First,
we observe selection on the component of consumption that is observable to governments. This
implies ordeals have the potential to save money, by not having to survey rich people who would
ultimately fail the asset test. Second, ordeal mechanisms also lead to selection on the unobservable
components of consumption, which means that targeting may become more pro-poor by screening
out the rich who may get incorrectly screened in by an asset test. On net, introducing self-selection
improved targeting as compared with the other targeting mechanisms that we considered, both the
current status quo and a universal automatic enrollment system.
However, while experimentally increasing the ordeals by increasing the distance to the application
site reduced the number of individuals who applied under the self-targeting regime, it did not
differentially improve targeting. Put another way, the increase in distance we experimentally induced
(a 1.6 kilometer increase in distance) imposed substantial enough costs on households to lower
application rates, but these costs did not differentially impact poor and rich households. Estimating
our model structurally, we showed that the additional time costs needed to induce differential
selection of the poor are high and out of the realistic policy realm from both an implementation
standpoint, and because they could induce substantial costs on the poor who may still be inaccuracy
screened out by the asset test.
31

In short, ordeals can be a power tool to improve targeting relative to automatic enrollment
systems, but making onerous ordeals even more costly may not be the best way to improve targeting
further. Moreover, while ordeals dominate the status quo, many of the poor still do not sign up.
Further research is necessary to understand how to improve or augment design of ordeals further.
For example, would increasing transparency in the rules, so that the poor know that they would
indeed qualify, also allow for easier cheating of the system by the rich? Or, given that we know that
the benefits are in the future, and we know that the poor may discount the future a lot or may have
procrastination issues that would prevent them from signing up, could small incentives to sign up
increase the applications of the poor, without having perverse effects on the rich? Understanding
these questions is an important direction for future research.

32

References
Alatas, V., A. Banerjee, R. Hanna, B.A. Olken and J. Tobias. 2012. ‚ÄúTargeting the Poor: Evidence
from a Field Experiment in Indonesia.‚Äù American Economic Review 104 (2):1206‚Äì1240.
Alatas, Vivi, Abhijit Banerjee, Rema Hanna, Benjamin A. Olken, Ririn Purnamasari and Matthew
Wai-poi. 2012. Elite Capture or Elite Benevolence? Local Elites and Targeted Welfare Programs
in Indonesia. Technical report MIT.
Attanasio, O.P., C. Meghir and A. Santiago. 2012. ‚ÄúEducation choices in Mexico: using a structural
model and a randomized experiment to evaluate Progresa.‚Äù The Review of Economic Studies
79(1):37‚Äì66.
Banerjee, A.V., E. Duflo and R. Glennerster. 2008. ‚ÄúPutting a Band-Aid on a corpse: Incentives for
nurses in the Indian public health care system.‚Äù Journal of the European Economic Association
6(2-3):487‚Äì500.
Besley, Timothy and Stephen Coate. 1992. ‚ÄúWorkfare versus Welfare: Incentive Arguments for Work
Requirements in Poverty-Alleviation Programs.‚Äù American Economic Review 82(1):249‚Äì61.
Coady, D. and S. Parker. 2009. Targeting social transfers to the poor in mexico. Working Paper
9/60 International Monetary Fund.
Currie, J. 2006. Public Policy and the Income Distribution. In Public Policy and the Income
Distribution, ed. David E. Quigley John M. Auerbach, Alan J. Card. Russel Sage Foundation.
Daponte, B.O., S. Sanders and L. Taylor. 1999. ‚ÄúWhy do low-income households not use food
stamps? Evidence from an experiment.‚Äù Journal of Human Resources pp. 612‚Äì628.
Duflo, E., R Hanna and Stephen P. Ryan. 2012. ‚ÄúIncentives Work: Getting Teachers to Come to
School.‚Äù American Economic Review 102 (4):1241‚Äì78.
Fan, Jianqing. 1992. ‚ÄúDesign-adaptive Nonparametric Regression.‚Äù Journal of the American Statistical Association 87(420):998‚Äì1004.
Kaboski, J.P. and R.M. Townsend. 2011. ‚ÄúA Structural Evaluation of a Large-Scale QuasiExperimental Microfinance Initiative.‚Äù Econometrica 79(5):1357‚Äì1406.
Keane, M.P., P.E. Todd and K.I. Wolpin. 2011. ‚ÄúThe structural estimation of behavioral models:
Discrete choice dynamic programming methods and applications.‚Äù Handbook of Labor Economics
4:331‚Äì461.
Lise, J., S. Seitz and J. Smith. 2004. Equilibrium policy experiments and the evaluation of social
programs. Technical report National Bureau of Economic Research.
Madrian, BC and DF Shea. 2001. ‚ÄúThe Power of Suggestion: Inertia in 401(k) Participation and
Savings Behavior.‚Äù Quarterly Journal of Economics 116(4):1149‚Äì1187.
Martinelli, Cesar and Susan W. Parker. 2009. ‚ÄúDeception and Misreporting in a Social Program.‚Äù
Journal of the European Economic Association 7(4):886‚Äì908.
Moffitt, R. 1983. ‚ÄúAn economic model of welfare stigma.‚Äù The American Economic Review
73(5):1023‚Äì1035.
Nichols, Albert L. and Richard J. Zeckhauser. 1982. ‚ÄúTargeting Transfers through Restrictions on
Recipients.‚Äù The American Economic Review 72(2):372‚Äì377.
Nichols, D., E. Smolensky and T.N. Tideman. 1971. ‚ÄúDiscrimination by waiting time in merit
goods.‚Äù The American Economic Review 61(3):312‚Äì323.
33

Ravallion, M. 1991. ‚ÄúReaching the Rural Poor Through Public Employment: Arguments, Evidence,
and Lessons from South Asia.‚Äù World Bank Research Observer 6(2):153‚Äì175.
Thornton, R.L., Hatt L.E. Field E.M. Mursaleena I. Diaz F.S. Gonzalez M.A. 2010. ‚ÄúSocial Security Health Insurance for the Informal Sector in Nicaragua: A Randomized Evaluation.‚Äù Health
Economics 19:181‚Äì206.
Todd, P.E. and K.I. Wolpin. 2006. ‚ÄúAssessing the impact of a school subsidy program in Mexico:
Using a social experiment to validate a dynamic behavioral model of child schooling and fertility.‚Äù
The American Economic Review 96(5):1384‚Äì1417.
Wise, D.A. 1985. ‚ÄúA behavioral model versus experimentation: The effects of housing subsidies on
rent.‚Äù Methods of Operations Research 50:441‚Äì89.

34

Table 1. Experimental Design

Both Spouse Subtreatment
Automatic Enrollment
Close Subtreatment
Self Targeting
Far Subtreatment
Total

50 (500)
50 (500)
100 (1,000)

Either Spouse Subtreatment
50 (500)
50 (500)
100 (1,000)

Total
200 (1,998)
100 (1,000)
100 (1,000)
200 (2,000)

Notes: This table provides the number of villages in each treatment cell. The number of households in each cell is also shown in parentheses.

Table 2. Descriptive Statistics for Households Surveyed in the Baseline

35

Automatic Enrollment
Self Targeting

Total number of
households
(1)
1998
2000

Number of
households
interviewed
(2)
706
754

Number of
beneficiaries
(3)
86
73

Notes: This table provides information on the flow of surveyed households through the experiment.

Percentage of
households
interviewed
(4)
35.34%
37.70%

Percentage of
interviewed
households that
received benefits
(5)
12.18%
9.68%

Percentage of
total households
that received
benefits
(6)
4.30%
3.65%

Table 3. Probability of Showing Up as a Function of the Observed and Unobserved Components of Baseline Log Percapita Consumption

Observable consumption (ùëãùëñ‚Ä≤ ùõΩ)

Unobservable consumption (ùúÄùëñ )
Stratum fixed effects
Observations
Mean of dependent variable

All
(1)

Showed up
Very poor
(2)

Not very poor
(3)

-2.217***
(0.201)
-0.907***
(0.136)

-0.811
(1.981)
-1.702*
(0.877)

-2.283***
(0.204)
-0.878***
(0.137)

No
2,000
0.377

No
72
0.653

No
1,928
0.367

Notes: Each column shows a logit regression of show up rates on PMT score and epsilon. Very poor is defined as being eligible for the program based on PMT score. Robust
standard errors, clustered at the village level, shown in parentheses *** p<0.01, ** p<0.05, * p<0.1
36

Table 4. Experimental Comparison of Targeting under Self Targeting and Automatic Enrollment Treatments
Log consumption
beneficiaries
(baseline)
(OLS)
(1)
Self targeting
Log consumption

-0.208***
(0.076)

Log consumption * Self targeting
Observations
Mean of dependent variable
37

Self targeting
Log consumption

159
12.78
-0.114
(0.077)

Log consumption * Self targeting
Observations
Mean of dependent variable

159
12.78

Log consumption
beneficiaries
(baseline + midline)
(OLS)
(2)

Receives
benefits
(LOGIT)
(3)

Panel A: No Stratum Fixed Effects
-0.193***
12.142**
(0.060)
(4.894)
-1.016***
(0.280)
-0.964**
(0.383)
904
13.61

3,996
0.0398

Panel B: With Stratum Fixed Effects
-0.175***
15.180***
(0.058)
(5.295)
-1.042***
(0.283)
-1.202***
(0.416)
904
13.61

3,489
0.0456

Error
(LOGIT)
(4)

Exclusion error
(LOGIT)
(5)

Inclusion error
(LOGIT)
(6)

-0.219*
(0.127)

-0.547
(0.403)

-0.313
(0.210)

3,998
0.0855

243
0.877

3,755
0.0344

-0.239
(0.148)

-0.709
(0.492)

-0.334*
(0.193)

3,918
0.0873

110
0.755

3,134
0.0412

Notes: Exclusion error is defined to be 1 if a household is very poor (as measured at baseline) and does not receive PKH and 0 otherwise. Inclusion error is defined to be 1 if a
not-very poor household does receive PKH and 0 otherwise. Error includes either exclusion or targeting error. In Panel A, robust standard errors, clustered at the village level,
are shown in parentheses. In Panel B, Columns (2) - (5), robust standard errors are clustered at the stratum level. *** p<0.01, ** p<0.05, * p<0.1

Table 5. Comparison of Targeting under Self-Selection and Hypothetical Universal Automatic Enrollment
Log consumption
(beneficiaries)
(OLS)
(1)
Self targeting
Log consumption

-0.133*
(0.069)

Log consumption * Self targeting
Observations
Mean of dependent variable

38

Self targeting
Log consumption

186
12.75

-0.040
(0.064)

Log consumption * Self targeting
Observations
Mean of dependent variable

186
12.75

Receives
benefits
(LOGIT)
(2)

Error
(LOGIT)
(3)

Panel A: No Stratum Fixed Effects
6.545
-0.271**
(4.710)
(0.129)
-1.428***
(0.261)
-0.552
(0.369)
3,996
0.0465

3,998
0.0878

Panel B: With Stratum Fixed Effects
9.055*
-0.293*
(4.981)
(0.156)
-1.488***
(0.271)
-0.749*
(0.393)
3,489
0.0533

3,918
0.0896

Exclusion error
(LOGIT)
(4)

Inclusion error
(LOGIT)
(5)

0.095
(0.350)

-0.541***
(0.207)

243
0.840

3,755
0.0391

0.128
(0.322)

-0.571***
(0.207)

126
0.714

3,134
0.0469

Notes: Exclusion error is defined to be 1 if a household is very poor (as measured at baseline) and does not receive PKH. Inclusion error is defined to be 1 if a not-very poor
household does receive PKH. Error includes either exclusion or targeting error. Households are defined as beneficiaries of the hypothetical PMT if either their PMT score
defined at baseline qualifies them for PKH or they in reality received the benefit. In Panel A, robust standard errors, clustered at the village level, are shown in parentheses.
In Panel B, Columns (2) - (5), robust standard errors are clustered at the stratum level. *** p<0.01, ** p<0.05, * p<0.1

Table 6. Summary of Targeting and Costs

# of eligible households that receive benefit
# of eligible households that do not receive benefit
# of ineligible households that receive benefit
# of ineligible households that do not receive benefit
Total annual benefits paid ($)
Total cost to households ($)
Total cost to beneficiary households ($)
Total cost to non-beneficiary households ($)
Total administrative costs in sample ($)
Total administrative costs, scaled ($)

SelfTargeting
(1)
2167
11917
6621
220051
1198099
108145
13400
94618
170800
.

PMT
(2)
1341
12743
8960
217711
1404528
9366
1174
8192
784083
120378

Hypothetical
Universal PMT
(3)
2347
11737
11140
215532
1838845
32403
1407
31002
2218978
340673

39

Notes: Estimates are totals for the 200 villages in our self-targeting sample. Column (1) is directly estimated using the self-targeting sample, and Columns (2) and (3) are
estimated using the PMT sample. Total population in Columns (2) and (3) are scaled to match Column (1). For number of eligible/ineligible households, total annual benefits
paid, and total cost to households, the percentage of eligible households in the village for Columns (2) and (3) are also scaled to Column (1). All monetary costs are reported
in U.S. dollars, using an exchange rate of 9,535 Rp. / USD$ 1.00 (October 2, 2012). Benefits per household are assumed to be Rp. 1.3 million annually. Costs to households
are calculated as the time cost of travel, waiting, and completing surveys (in PMT, just the cost of completing surveys) using the household average wage rate, as well as the
cost of transportation. Note that costs to households in self-targeting also include the time cost of attending an informational meeting on the treatment. Wage rates and
beneficiary/non-beneficiary breakdown of meeting attendees based on in-sample data; meeting attendance and length based on facilitators‚Äô meeting data. All households are
assumed to stay for the entire meeting. Total administrative costs in sample are calculated based on per-village and per-neighborhood costs actually incurred by the
experiment for Indonesian government surveyors in both self-targeting and PMT, as well as on actual costs by an external NGO that helped to spread information about
self-targeting; since PMT treatment was done in one neighborhood only, the actual costs are scaled up by the average number of neighborhoods in a village. Total at scale
administrative costs in PMT are based on the actual Indonesian government cost of executing the PMT nationwide, when they surveyed approximately 16 million households.
The costs of PMT are assumed to be linear in the number of households surveyed per village.

Table 7. Experimental Results: Probability of Showing up as a Function of Distance and Log Per Capita Consumption
No stratum fixed effects
(1)
(2)
(3)
Close subtreatment
Log consumption

0.205
(0.146)

Close subtreatment* Log consumption
Consumption quintile 2

1.345
(2.841)
-1.434***
(0.143)
-0.093
(0.217)

Consumption quintile 3
Consumption quintile 4
Consumption quintile 5
40

Close subtreatment * Consumption quintile 2
Close subtreatment * Consumption quintile 3
Close subtreatment * Consumption quintile 4
Close subtreatment * Consumption quintile 5
Stratum fixed effects
Observations
Mean of dependent variable

No
2,000
0.377

No
2,000
0.377

0.195
(0.238)

With stratum fixed effects
(4)
(5)
(6)
0.275
(0.168)

-0.317
(0.233)
-0.813***
(0.231)
-1.084***
(0.206)
-2.204***
(0.257)
-0.271
(0.323)
0.255
(0.299)
-0.385
(0.300)
0.174
(0.371)
No
2,000
0.377

Yes
1,960
0.385

0.485
(2.920)
-1.446***
(0.144)
-0.023
(0.218)

0.193
(0.310)

-0.326
(0.245)
-0.791***
(0.234)
-1.072***
(0.234)
-2.265***
(0.279)
-0.292
(0.368)
0.321
(0.325)
-0.261
(0.314)
0.277
(0.387)

Yes
1,960
0.385

Yes
1,960
0.385

Notes: Each column presents a logit regression of show up on the close sub-treatment. In Columns (1) - (3), robust standard errors are clustered at the village level. In
Columns (4) - (6), robust standard errors are clustered at the stratum level. *** p<0.01, ** p<0.05, * p<0.1

Table 8. Experimental Results: Probability of Showing up as a Function of Opportunity Cost Treatment
No stratum fixed effects
(1)
(2)
(3)
Both spouse subtreatment
Log consumption

0.196
(0.146)

Both spouse subtreatment * Log consumption
Consumption quintile 2

4.303
(2.840)
-1.324***
(0.145)
-0.318
(0.217)

Consumption quintile 3
Consumption quintile 4
Consumption quintile 5
41

Both spouse subtreatment * Consumption quintile 2
Both spouse subtreatment * Consumption quintile 3
Both spouse subtreatment * Consumption quintile 4
Both spouse subtreatment * Consumption quintile 5
Stratum fixed effects
Observations
Mean of dependent variable

No
2,000
0.377

No
2,000
0.377

0.461*
(0.237)

With Stratum fixed effects
(4)
(5)
(6)
0.185*
(0.099)

-0.292
(0.212)
-0.478**
(0.190)
-1.157***
(0.185)
-1.871***
(0.271)
-0.348
(0.322)
-0.416
(0.292)
-0.237
(0.305)
-0.514
(0.369)
No
2,000
0.377

Yes
1,960
0.385

3.334
(2.857)
-1.343***
(0.144)
-0.244
(0.217)

Yes
1,960
0.385

0.384
(0.243)

-0.327
(0.219)
-0.470**
(0.184)
-1.146***
(0.205)
-1.962***
(0.289)
-0.316
(0.380)
-0.305
(0.344)
-0.116
(0.328)
-0.356
(0.347)
Yes
1,960
0.385

Notes: Each column presents a logit regression of show up on the both spouse sub-treatment. In Columns (1) - (3), robust standard errors are clustered at the village level. In
Columns (4) - (6), robust standard errors are clustered at the stratum level. *** p<0.01, ** p<0.05, * p<0.1

Table 9. Estimated Parameter Values for the Model
ùõºùúÄ

ùõΩùúÄ

œÅ

-26126

26805

6.09E-15

(5445.492)

(8224.896)

(0.16011)

Notes: This table reports the mean and variance of the cost shock (Œµ) and the coefficient of relative risk aversion (œÅ). The parameters are estimated using two-step feasible
GMM. The moments are defined as the average show up rates within each consumption quintile. These five moments are fit only in the far treatment villages, assuming an
annual discount factor of 0.5. Bootstrapped standard errors are in parentheses.

T

42

Table 10. Modeled Effects of Time and Distance Costs on Show Up Rates
Show Up (Exp.)

Reported
Total Cost

Reported
Total cost,
SD[eps]/2
(3)

(1)

(2)

1.563
(2.813)
-1.419***
(0.145)
-0.109
(0.215)
1973

-1.654
(3.019)
-1.450***
(0.164)
0.134
(0.231)
5919000
0.441

Above poverty line, far
Above poverty line, close
Below poverty line, far
Below poverty line, close

34.123
39.116
54.237
57.895

33.165
37.465
69.910
67.194

27.376
31.807
71.484
68.116

Poor to rich ratio, far

1.589
(0.215)
1.480
(0.177)
0.109
(0.278)

2.108
(0.213)
1.793
(0.178)
0.314
(0.277)
0.602

2.611
(0.278)
2.142
(0.228)
0.470
(0.359)
0.428

Close
Log per capita expenditure
Close * Log per capita
expenditure
N
P-value‚Ä°

43

Poor to rich ratio, close
Difference of ratios
P-value

Reported
total cost,
SD[eps]=0
(4)

Predicted Show Up (Model)‚Ä†
Assuming No
Reported
Additional Distance
Differential
total cost,
Distance +
Distance +
Travel Cost
constant mu
3km
6km
(5)
(6)
(7)
(8)

Panel A: Logistic Regressions
-2.203
-2.378
-1.545
(3.395)
(3.540)
(2.919)
-1.955***
-2.208***
-1.442***
(0.183)
(0.200)
(0.164)
0.178
0.191
0.125
(0.261)
(0.273)
(0.223)
5919000
5919000
5913000
0.397
0.388
0.449
Panel B: Show-Up Rates
24.021
33.350
28.157
37.463
71.719
69.895
67.618
67.211
Panel C: Show-Up Rate Ratios
2.986
2.096
(0.335)
(0.206)
2.401
1.794
(0.255)
(0.185)
0.584
0.302
(0.428)
(0.276)
0.352
0.624

Inflated Wait Time
Wait
Wait
Time*3
Time*6
(9)
(10)

-1.690
(2.356)
-0.328**
(0.128)
0.138
(0.180)
5919000
0.379

-1.785
(3.038)
-1.465***
(0.168)
0.149
(0.232)
5913000
0.415

-1.614
(2.833)
-1.454***
(0.164)
0.139
(0.217)
5913000
0.417

-4.659
(2.974)
-1.700***
(0.171)
0.385
(0.228)
5919000
0.115

-7.307**
(3.245)
-1.927***
(0.194)
0.611**
(0.249)
5919000
0.029

32.070
35.164
37.367
36.866

31.875
37.465
68.882
67.194

31.211
37.465
67.969
67.194

28.104
37.465
67.456
67.194

23.036
37.465
64.047
67.194

1.165
(0.201)
1.048
(0.186)
0.117
(0.273)
0.985

2.161
(0.218)
1.793
(0.182)
0.368
(0.285)
0.517

2.178
(0.224)
1.793
(0.184)
0.384
(0.291)
0.495

2.400
(0.261)
1.793
(0.191)
0.607*
(0.330)
0.249

2.780
(0.348)
1.793
(0.185)
0.987**
(0.390)
0.067

Notes: In order to run logits on predicted show up rates, we create 3000 copies of the data. The copies of each individual are assigned to show up or not in proportion to his
predicted probability of showing up. Bootstrapped standard errors, clustered by village, are in parentheses. To compute the standard errors, for each bootstrap iteration we
sample 2,000 households, clustered at the village level, to make the sample equivalent to that in Column 1. We perform 1,000 bootstrap iterations. The p-value in Panel A is
the test of whether the coefficient on [Close ‚àó LogP CE] is equal to the equivalent coefficient in Column 1. The p-value in Panel C is the test of whether the difference in ratios
is equal to the difference in ratios in Column 1. *** p<0.01, ** p<0.05, * p<0.1 Significance levels not shown on first two rows of Panel C.

Figure 1. Illustration of Utility Gain with No Errors
applied
gain

1
0

far

close

close

far
y*

consumption

y**

y*

(a) Gain vs. Consumption for Close and
Far Sub-Treatments

income

y**

(b) Targeting Improves as Length of Ordeal Increases

1

0

.2

Application rate
.4
.6

Ratio of application rates
1.5
2

.8

1

2.5

Figure 2. Illustration of Utility Gain with Log-logistic Errors

1

1.5

2
y
distance = 2

2.5

3

1

distance = 3

1.5

2
y2
distance = 2

(a) Show Up Rates with Log-logistic Errors

2.5
distance = 3

(b) Ratio of Show Up Rates of Rich (y2 )
Compared to Poor (y1 = 1)

44

3

Figure 3. Non-Linearities in Travel Costs
cost
rich, walking
rich, bus

poor, walking
poor, bus

l'

intensity of ordeal

l''

Notes: Increasing ordeal within l‚Äô to l‚Äù, marginal cost for rich is lower than marginal cost for the poor.

Figure 4. Illustration of Utility Gain with Concave Utility
applies
gain
close

far

1
apply
don‚Äôt apply

close
far

consumption

consumption

(a) Gain vs. Consumption for Close and
Far Sub-Treatments

(b) Targeting can Worsen as Length of
Ordeal Increases

45

0

.2

Showed up
.4

.6

.8

Figure 5. Show Up Rates Versus Log Per Capita Consumption

11

12

13
14
Log per capita consumption

15

Notes: Figure provides a non-parametric fan regression of the probability of applying for PKH against baseline log per capita
consumption in the 200 self-targeting villages. Bootstrapped standard error bounds, clustered at the village level, are shown
in dashes.

46

0

.2

showup
.4

.6

.8

Figure 6. Show Up Rates Versus Observable and Unobservable Components of Log
Per Capita Consumption

12

13

14

15

PMTSCORE
0

0

.2

showup
.4

.6

.8

(a) Show Up as a Function of Observable Consumption (Xi Œ≤)

‚àí2

‚àí1

0
Epsilon

1

2

(b) Show Up as a Function of 47
Unobservable Consumption (Œµi )
Notes: Figures provide non-parametric fan regressions of the probability of applying for PKH against components of baseline
log per capita consumption in the 200 self-targeting villages. Bootstrapped standard error bounds, clustered at the village
level, are shown in dashes.

0

.2

.4

CDF

.6

.8

1

Figure 7. Experimental Comparison of Self Targeting and Automatic Enrollment
Treatments

11

12

13
14
Log per capita Consumption
Automatic Enrollment

15

Self‚àíTargeting

0

.1

Get benefit
.2

.3

.4

(a) CDF of Log Per Capita Consumption of Beneficiaries

11

12

13
Logconsumption

Automatic Enrollment

14

15
Self‚àíTargeting

48 of Log Per Capita Consumption
(b) Receiving Benefit as a Function
Notes: Panel A shows a CDF of log per capita consumption of beneficiaries. Kolmogorov-Smirnov test of equality yields a
p-value of 0.10. Panel B present a non-parametric Fan regression of benefit receipt on log per capita consumption .
Bootstrapped standard errors, clustered at the village level, are shown in dashes.

0

.2

.4

CDF

.6

.8

1

Figure 8. Comparison of Self-Selection and Hypothetical Universal Automatic Enrollment

11

12

13
14
Log per capita Consumption
Automatic Enrollment

15

Self‚àíTargeting

0

.1

Get benefit
.2

.3

.4

(a) CDF of Consumption of Beneficiaries

11

12

13
Logconsumption

Automatic Enrollment

14

15
Self‚àíTargeting

49 of Log Per Capita Consumption
(b) Getting Benefit as a Function
Notes: Panel A shows a CDF of log per capita consumption of beneficiaries. Kolmogorov-Smirnov test of equality yields a
p-value of 0.29. Panel B present a non-parametric Fan regression of benefit receipt on log per capita consumption.
Bootstrapped standard errors, clustered at the village level, are shown in dashes.

0

Total costs per capita
20000
40000

60000

Figure 9. Cost of Applying by Consumption

0

1000000

2000000
3000000
Per capita consumption

4000000

Notes: Figure shows a non-parametric Fan regression of total costs incurred in applying for PKH against per capita
consumption. Bootstrapped standard errors, clustered at the village level, are shown in dashes. Costs assume one individual
per household goes to sign-up location, even for households in opportunity cost sub-treatment.

50

Figure 10. Model Fit and Counterfactuals

Showup

Predicted Showup

1

2
3
4
5
Consumption Quintile

.2

.3

.4

.5

.6

No Differential Travel Costs

.1

.2

.3

.4

.5

.6

Actual Cost

.1

.1

.2

.3

.4

.5

.6

Measured Rates

1

2
3
4
5
Consumption Quintile

1

2
3
4
5
Consumption Quintile

Predicted Showup

1

2
3
4
5
Consumption Quintile

.5
.4
.3
.2
.1

.2

.3

.4

.5

.6

Travel Distance + 6km

.6

Travel Distance + 3km

.1

.1

.2

.3

.4

.5

.6

Actual Cost

1

2
3
4
5
Consumption Quintile

1

2
3
4
5
Consumption Quintile

Predicted Showup

1

2
3
4
5
Consumption Quintile

.4
.2
0

.2

.4

.6

Average Wait * 6

.6

Average Wait * 3

0

0

.2

.4

.6

Actual Cost

1

2
3
4
5
Consumption Quintile

Close

1

Far
51

2
3
4
5
Consumption Quintile

