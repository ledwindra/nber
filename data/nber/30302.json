{
    "id": 30302,
    "citation_title": "Long Story Short: Omitted Variable Bias in Causal Machine Learning",
    "citation_author": [
        "Victor Chernozhukov",
        "Carlos Cinelli",
        "Whitney Newey",
        "Amit Sharma",
        "Vasilis Syrgkanis"
    ],
    "citation_publication_date": "2022-08-01",
    "issue_date": "2022-07-28",
    "revision_date": "None",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Estimation Methods",
        "\n"
    ],
    "program": [
        "\n",
        "Labor Studies",
        "\n",
        "Public Economics",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nWe derive general, yet simple, sharp bounds on the size of the omitted variable bias for a broad class of causal parameters that can be identified as linear functionals of the conditional expectation function of the outcome. Such functionals encompass many of the traditional targets of investigation in causal inference studies, such as, for example, (weighted) average of potential outcomes, average treatment effects (including subgroup effects, such as the effect on the treated), (weighted) average derivatives, and policy effects from shifts in covariate distribution -- all for general, nonparametric causal models. Our construction relies on the Riesz-Frechet representation of the target functional. Specifically, we show how the bound on the bias depends only on the additional variation that the latent variables create both in the outcome and in the Riesz representer for the parameter of interest. Moreover, in many important cases (e.g, average treatment effects and avearage derivatives) the bound is shown to depend on easily interpretable quantities that measure the explanatory power of the omitted variables. Therefore, simple plausibility judgments on the maximum explanatory power of omitted variables (in explaining treatment and outcome variation) are sufficient to place overall bounds on the size of the bias. Furthermore, we use debiased machine learning to provide flexible and efficient statistical inference on learnable components of the bounds. Finally, empirical examples demonstrate the usefulness of the approach.\n\n",
    "acknowledgement": "\nThis is an extended version of an earlier paper prepared for the NeurIPS-21 Workshop \u201cCausal Inference & Machine Learning: Why now?\u201d We thank Elias Bareinboim, Ben Deaner, David Green, Judith Lock, Esfandiar Maasoumi, Steve Lehrer, Richard Nickl, Jack Porter, James Poterba, Eric Tchetgen Tchetgen, Ingrid Van Keilegom, and also participants of the Chambelain seminar, Canadian Economic Association and the Institute for Nonparametric Statistics meetings, and seminars at Harvard-MIT, Wisconsin, Emory, and BU Causal Seminar for very helpful comments. We are grateful to Jack Porter for suggesting the long story short title. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}