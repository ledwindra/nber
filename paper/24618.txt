                             NBER WORKING PAPER SERIES




                    ESTIMATING LATENT ASSET-PRICING FACTORS

                                        Martin Lettau
                                        Markus Pelger

                                     Working Paper 24618
                             http://www.nber.org/papers/w24618


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                            May 2018, Revised June 2018




We thank Svetlana Bryzgalova, John Cochrane, Jianqing Fan, Kay Giesecke, Bob Hodrick, Per
Mykland, Serena Ng, Viktor Todorov, Dacheng Xiu and seminar participants at Columbia,
Chicago, UC Berkeley, UC Irvine, ZÃ¼rich, Toronto, Boston University, Humboldt University,
Ulm, Bonn, Frankfurt and the conference participants at the NBER-NSF Time-Series Conference,
SoFiE, Western Mathematical Finance Conference and INFORMS for helpful comments. The
views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

Â© 2018 by Martin Lettau and Markus Pelger. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including Â© notice, is given to the source.
Estimating Latent Asset-Pricing Factors
Martin Lettau and Markus Pelger NBER
Working Paper No. 24618
May 2018, Revised June 2018
JEL No. C14,C38,C52,G12

                                          ABSTRACT

We develop an estimator for latent factors in a large-dimensional panel of financial data that can
explain expected excess returns. Statistical factor analysis based on Principal Component
Analysis (PCA) has problems identifying factors with a small variance that are important for
asset pricing. We generalize PCA with a penalty term accounting for the pricing error in expected
returns. Our estimator searches for factors that can explain both the expected return and
covariance structure. We derive the statistical properties of the new estimator and show that our
estimator can find asset-pricing factors, which cannot be detected with PCA, even if a large
amount of data is available. Applying the approach to portfolio data we find factors with Sharpe-
ratios more than twice as large as those based on conventional PCA and with significantly smaller
pricing errors.


Martin Lettau
Haas School of Business
University of California, Berkeley
545 Student Services Bldg. #1900
Berkeley, CA 94720-1900
and NBER
lettau@haas.berkeley.edu

Markus Pelger
312 Huang Engineering Center
Department of Management Science
& Engineering
Stanford University
Stanford, CA 94305
mpelger@stanford.edu
1. Introduction

      Approximate factor models have been a heavily researched topic in ï¬nance and macroeconomics in
the last years (see Bai and Ng (2008), Stock and Watson (2006) and Ludvigson and Ng (2010)). The most
popular technique to estimate latent factors is Principal Component Analysis (PCA) of a covariance or
correlation matrix. It estimates factors that can best explain the co-movement in the data. A situation
that is often encountered in practice is that the explanatory power of the factors is weak relative to
idiosyncratic noise. In this case conventional PCA performs poorly (see Onatski (2012)). In some cases
economic theory also imposes structure on the ï¬rst moments of the data. Including this additional
information in the estimation turns out to signiï¬cantly improve the estimation of latent factors, in
particular for those factors with a weak explanatory power in the variance.
      We suggest a new statistical method to ï¬nd the most important factors for explaining the varia-
tion and the mean in a large dimensional panel. Our key application are asset pricing factors. The
fundamental insight of asset pricing theory is that the cross-section of expected returns should be
explained by exposure to systematic risk factors.1 Hence, asset pricing factors should simultaneously
explain time-series covariation as well as the cross-section of mean returns. Finding the â€œrightâ€ risk
factors is not only the central question in asset pricing but also crucial for optimal portfolio and risk
management.2 Traditional PCA methods based on the covariance or correlation matrices identify fac-
tors that capture only common time-series variation but do not take the cross-sectional explanatory
power of factors into account.3 We generalize PCA by including a penalty term to account for the
pricing errors in the means. Hence, our estimator Risk-Premium PCA (RP-PCA) directly includes the
object of interest, which is explaining the cross-section of expected returns, in the estimation. It turns
out, that even if the goal is to explain the covariation and not the mean, the additional information
in the mean can improve the estimation signiï¬cantly.
      This paper develops the asymptotic inferential theory for our estimator under a general approx-
imate factor model and shows that it dominates conventional estimation based on PCA if there is
information in the mean. We distinguish between strong and weak factors in our model. Strong fac-
tors essentially aï¬€ect all underlying assets. The market-wide return is an example of a strong factor
in asset pricing applications. RP-PCA can estimate these factors more eï¬ƒciently than PCA as it ef-
ï¬ciently combines information in ï¬rst and second moments of the data. Weak factors aï¬€ect only
a subset of the underlying assets and are harder to detect. Many asset-pricing factors fall into this
category. RP-PCA can ï¬nd weak factors with high Sharpe-ratios, which cannot be detected with PCA,
even if an inï¬nite amount of data is available.
      We build upon the econometrics literature devoted to estimating factors from large dimensional
panel data sets. The general case of a static large dimensional factor model is treated in Bai (2003)

  1
     Arbitrage pricing theory (APT) formalized by Ross (1976) and Chamberlain and Rothschild (1983) states that in an
approximate factor model only systematic factors carry a risk-premium and explain the expected returns of diversiï¬ed
portfolios. Hence, factors that explain the covariance structure must also explain the expected returns in the cross-section.
   2
     Harvey et al. (2016) document that more than 300 published candidate factors have predictive power for the cross-
section of expected returns. As argued by Cochrane (2011) in his presidential address this leads to the crucial questions,
which risk factors are really important and which factors are subsumed by others.
   3
     PCA has been used to ï¬nd asset pricing factors among others by Connor and Korajczyk (1988), Connor and Korajczyk
(1993) and Kozak et al. (2017). Kelly et al. (2017) and Fan et al. (2016) apply PCA to projected portfolios.


                                                             1
and Bai and Ng (2002). Forni et al. (2000) introduce the dynamic principal component method. Fan
et al. (2013) study an approximate factor structure with sparsity. AÃ¯t-Sahalia and Xiu (2017) and Pelger
(2017) extend the large dimensional factor model to high-frequency data. All these methods assume
a strong factor structure that is estimated with some version of PCA without taking into account the
information in expected returns, which results in a loss of eï¬ƒciency. We generalize the framework of
Bai (2003) to include the pricing error penalty and show that it only eï¬€ects the asymptotic distribution
of the estimates but not consistency.
   Onatski (2012) studies principal component estimation of large factor models with weak factors.
He shows that if a factor does not explain a suï¬ƒcient amount of the variation in the data, it cannot be
detected with PCA. We provide a solution to this problem that renders weak factors with high Sharpe-
ratios detectable. Our statistical model extends the spiked covariance model from random matrix
theory used in Onatski (2012) and Benaych-Georges and Nadakuditi (2011) to include the pricing error
penalty. We show that including the information in the mean leads to larger systematic eigenvalues of
the factors, which reduces the bias in the factor estimation and makes weak factors detectable. The
derivation of our results is challenging as we cannot make the standard assumption that the mean
of the stochastic processes is zero. As many asset pricing factors can be characterized as weak, our
estimation approach becomes particularly relevant.
   Our work is part of the emerging econometrics literature that combines latent factor extraction
with a form of regularization. Bai and Ng (2017) develop the statistical theory for robust principal
components. Their estimator can be understood as performing iterative ridge instead of least squares
regressions, which shrinks the eigenvalues of the common components to zero. They combine their
shrinked estimates with a clean-up step that sets the small eigenvalues to zero. Their estimates have
less variation at the cost of a bias. Our approach also includes a penalty which in contrast is based on
economic information and does not create a bias-variance trade-oï¬€. The objective of ï¬nding factors
that can explain co-movements and the cross-section of expected returns simultaneously is based
on the fundamental insight of arbitrage pricing theory. We show theoretically and empirically that
including the additional information of arbitrage pricing theory in the estimation of factors leads to
factors that have better out-of-sample pricing performance. Our estimator depends on a tuning pa-
rameter that trades oï¬€ the information in the variance and the mean in the data. Our statistical theory
provides guidance on the optimal choice of the tuning parameter that we conï¬rm in simulations and
in the data.
   Our work is closely related to the paper by Fan and Zhong (2018) which allows estimating latent
factors based on an over-identifying set of moments. We combine the ï¬rst and second moments to
estimate factors while their approach allows the inclusion of additional moments. Their analysis is
based on a generalized method of moment approach under the assumption of a ï¬nite cross-section.
Our strong factor model formulation can be similarly related to a general method of moment problem.
We consider a large number of assets and include the additional perspective of a weak factor model
which we think is particularly relevant in the context of asset pricing factors.
   We apply our methodology to monthly returns of 370 decile sorted portfolios based on relevant
ï¬nancial anomalies for 55 years. We ï¬nd that ï¬ve factors can explain very well these expected returns
and strongly outperforms PCA-based factors. The maximum Sharpe-ratio of our ï¬ve factors is more

                                                   2
than twice as large as those based on PCA; a result that holds in- and out-of-sample. The pricing
errors out-of-sample are sizably smaller. Our method captures the pricing information better while
explaining the same amount of variation and co-movement in the data. Our companion paper Lettau
and Pelger (2018) provides a more in-depth empirical analysis of asset-pricing factors estimated with
our approach.
      The rest of the paper is organized as follows. In Section 2 we introduce the model and provide
an intuition for our estimators. Section 3 discusses the formal objective function that deï¬nes our
estimator. Section 4 provides the inferential theory for strong factors, while 5 presents the asymptotic
theory for weak factors. Section 6 provides Monte Carlo simulations demonstrating the ï¬nite-sample
performance of our estimator. In Section 7 we study the factor structure in a large equity data set.
Section 8 concludes. The appendix contains the proofs.


2. Factor Model

      We assume that excess returns follow a standard approximate factor model and the assumptions
of the arbitrage pricing theory are satisï¬ed. This means that returns have a systematic component
captured by ğ¾ factors and a nonsystematic, idiosyncratic component capturing asset-speciï¬c risk.
The approximate factor structure allows the non-systematic risk to be weakly dependent. We observe
the excess4 return of ğ‘ assets over ğ‘‡ time periods:

                                    ğ‘‹ğ‘¡,ğ‘– = ğ¹ğ‘¡ Î›âŠ¤
                                               ğ‘– + ğ‘’ğ‘¡,ğ‘–        ğ‘– = 1, ..., ğ‘ ğ‘¡ = 1, ..., ğ‘‡.

In matrix notation this reads as

                                                    ğ‘‹
                                                    âŸ = ğ¹
                                                        âŸ Î›
                                                          âŸ âŠ¤ + âŸ
                                                                ğ‘’ .
                                                  ğ‘‡Ã—ğ‘      ğ‘‡Ã—ğ¾ ğ¾Ã—ğ‘     ğ‘‡Ã—ğ‘


Our goal is to estimate the unknown latent factors ğ¹ and the loadings Î›. We will work in a large
dimensional panel, i.e. the number of cross-sectional observations ğ‘ and the number of time-series
observations ğ‘‡ are both large and we study the asymptotics for them jointly going to inï¬nity.
      Assume that the factors and residuals are uncorrelated. This implies that the covariance matrix
of the returns consists of a systematic and idiosyncratic part:

                                            Var(ğ‘‹) = Î›Var(ğ¹)Î›âŠ¤ + Var(ğ‘’).

Under standard assumptions the largest eigenvalues of Var(ğ‘‹) are driven by the factors. This moti-
vates Principal Component Analysis (PCA) as an estimator for the loadings and factors. Essentially all
estimators for latent factors only utilize the information contained in the second moment, but ignore
information that is contained in the ï¬rst moment.
      Arbitrage-Pricing Theory (APT) has a second implication: The expected excess return is explained
by the exposure to the risk factors multiplied by the risk-premium of the factors. If the factors are

  4
      Excess returns equal returns minus the risk-free rate.


                                                               3
excess returns APT implies

                                                    ğ¸[ğ‘‹ğ‘– ] = Î›ğ‘– ğ¸[ğ¹].

Here we assume a strong form of APT, where residual risk has a risk-premium of zero. In its more
general form APT requires only the risk-premium of the idiosyncratic part of well-diversiï¬ed portfo-
lios to go to zero. As most of our analysis will be based on portfolios, there is no loss of generality
by assuming the strong form.
    Factors constructed by PCA explain as much common time-series variation as possible. Conven-
                                                                              1
tional statistical factor analysis applies PCA to the sample covariance matrix ğ‘‹âŠ¤ ğ‘‹ âˆ’ ğ‘‹Ì„ğ‘‹Ì„âŠ¤ where       ğ‘‡
ğ‘‹Ì„ denotes the sample mean of excess returns. The eigenvectors of the largest eigenvalues are pro-
portional to the loadings Î›Ì‚ PCA . Factors are obtained from a regression on the estimated loadings. It
can be shown that conventional PCA factor estimates are based on the time-series variation objective
            5
function:

                                                            ğ‘    ğ‘‡
                                                  1                       âŠ¤ 2
                                          min              âˆ‘ âˆ‘ (ğ‘‹ğ‘¡ğ‘– âˆ’ ğ¹ğ‘¡ Î›ğ‘– )
                                           Î›,ğ¹    ğ‘ğ‘‡       ğ‘–=1 ğ‘¡=1


      We call our approach Risk-Premium-PCA (RP-PCA). It applies PCA to a covariance matrix with
overweighted mean

                                                      1
                                                          ğ‘‹âŠ¤ ğ‘‹ + ğ›¾ğ‘‹Ì„ğ‘‹Ì„âŠ¤
                                                      ğ‘‡

with the risk-premium weight ğ›¾. The eigenvectors of the largest eigenvalues are proportional to the
loadings Î›Ì‚ RP-PCA . We show that RP-PCA minimizes jointly the unexplained variation and pricing error:

                                          ğ‘   ğ‘‡                               ğ‘
                                     1                              âŠ¤    1                         2
                            min          âˆ‘ âˆ‘ (ğ‘‹ğ‘¡ğ‘– âˆ’ ğ¹ğ‘¡ Î›ğ‘– )2 +ğ›¾             âˆ‘ (ğ‘‹ğ‘–Ì„ âˆ’ ğ¹Î›      Ì„ âŠ¤ğ‘– ) ,
                            Î›,ğ¹    ğ‘ğ‘‡ ğ‘–=1 ğ‘¡=1                            ğ‘ ğ‘–=1
                                   âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸ âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸ
                                         unexplained variation                    pricing error


where ğ¹ Ì„ denotes the sample mean of the factors. Factors are estimated by a regression of the returns
                                                   âˆ’1
on the estimated loadings, i.e. ğ¹ Ì‚ = ğ‘‹Î›Ì‚ (Î›Ì‚ âŠ¤ Î›)
                                                 Ì‚    .
      We develop the statistical theory that provides guidance on the optimal choice of the key param-
eter ğ›¾. There are essentially two diï¬€erent factor model interpretations: a strong factor model and a
weak factor model. In a strong factor model the factors provide a strong signal and lead to exploding
eigenvalues in the covariance matrix. This is either because the strong factors aï¬€ect a very large
number of assets and/or because they have very large variances themselves. In a weak factor model
the factorsâ€™ signals are weak and the resulting eigenvalues are large compared to the idiosyncratic
spectrum, but they do not explode.6 In both cases it is always optimal to choose ğ›¾ â‰  âˆ’1, i.e. it is
better to use our estimator instead of PCA applied to the covariance matrix. In a strong factor model,

  5
    The variation objective function assumes that the data has been demeaned.
  6
    Arbitrage-Pricing Theory developed by Chamberlain and Rothschild (1983) assumes that only strong factors are non-
diversiï¬able and explain the cross-section of expected returns. As pointed out by Onatski (2012), a weak factors can be


                                                                 4
the estimates become more eï¬ƒcient. In a weak factor model it strengthens the signal of the weak
factors, which could otherwise not be detected. Depending on which framework is more appropriate,
the optimal choice of ğ›¾ varies. A weak factor model usually suggests much larger choices for the
optimal ğ›¾ than a strong factor model. However, in strong factor models our estimator is consistent
for any choice of ğ›¾ and choosing a too large ğ›¾ results in only minor eï¬ƒciency losses. On the other
hand a too small ğ›¾ can prevent weak factors from being detected at all. Thus in our empirical analysis
we opt for the choice of larger ğ›¾â€™s.
    The empirical spectrum of eigenvalues in equity data suggests a combination of strong and weak
factors. In all the equity data that we have tested the ï¬rst eigenvalue of the sample covariance matrix
is very large, typically around ten times the size of the rest of the spectrum. The second and third
eigenvalues usually stand out, but have only magnitudes around twice or three times of the average
of the residual spectrum, which would be more in line with a weak factor interpretation. The ï¬rst
statistical factor in our data sets is always very strongly correlated with an equally-weighted market
factor. Hence, if we are interested in learning more about factors besides the market, the weak factor
model might provide better guidance.


3. Objective Function

    This section explains the relationship between our estimator and the objective function that is min-
imized. We introduce the following notation:           1 is a vector ğ‘‡ Ã— 1 of 1â€™s and thus ğ¹âŠ¤ 1/ğ‘‡ is the sample
mean estimator of ğ¹. The projection matrix ğ‘€Î› = ğ¼ğ‘ âˆ’ Î›(Î›âŠ¤ Î›)âˆ’1 Î›âŠ¤ annihilates the ğ¾âˆ’dimensional
vector space spanned by Î›. ğ¼ğ‘ and ğ¼ğ‘‡ denote the ğ‘- respectively ğ‘‡-dimensional identity matrix.
   The objective function of conventional statistical factor analysis is to minimize the sum of squared
errors for the cross-section and time dimension, i.e. the estimator Î›Ì‚ and ğ¹ Ì‚ are chosen to minimize
the unexplained variance. This variation objective function is

                     ğ‘   ğ‘‡
                1                   âŠ¤ 2               1
         min         âˆ‘ âˆ‘ (ğ‘‹ğ‘¡ğ‘– âˆ’ ğ¹ğ‘¡ Î›ğ‘– ) = min             trace(ğ‘‹ğ‘€Î› )âŠ¤ (ğ‘‹ğ‘€Î› ))        s.t. ğ¹ = ğ‘‹(Î›âŠ¤ Î›)âˆ’1 Î›âŠ¤ .
          Î›,ğ¹   ğ‘ğ‘‡   ğ‘–=1 ğ‘¡=1                    Î›   ğ‘ğ‘‡

The second formulation makes use of the fact that in a large panel data set the factors can be esti-
mated by a regression of the assets on the loadings, ğ¹ = ğ‘‹(Î›âŠ¤ Î›)âˆ’1 Î›âŠ¤ , and hence the residuals equal
ğ‘‹ âˆ’ ğ¹Î›âŠ¤ = ğ‘‹ğ‘€Î› . This is equivalent to choosing Î›Ì‚ proportional to the eigenvectors of the ï¬rst ğ¾
                                1
largest eigenvalues of         ğ‘ğ‘‡
                                  ğ‘‹âŠ¤ ğ‘‹.7
                                  In most applications the data is ï¬rst demeaned, which means that
the estimator applies PCA to the estimated covariance matrix of ğ‘‹. Thus Î›Ì‚ is proportional to the
                                                   1          11âŠ¤
eigenvectors of the ï¬rst ğ¾ largest eigenvalues of ğ‘ğ‘‡ ğ‘‹âŠ¤ (ğ¼ğ‘‡ âˆ’ ğ‘‡ ) ğ‘‹.
    Arbitrage-pricing theory predicts that the factors should price the cross-section of expected excess


regarded as a ï¬nite sample approximation for strong factors, i.e. the eigenvalues of factors that are theoretically strong
grow so slowly with the sample size that the weak factor model provides a more appropriate description of the data.
   7
     Factor models are only identiï¬ed up to invertible transformations. Therefore there is no loss of generality to assume
that the loadings are orthonormal vectors and that the inner product of factors is a diagonal matrix.




                                                            5
returns. This yields a pricing objective function which minimizes the cross-sectional pricing error:

                    ğ‘                                       2                                              âŠ¤
                1              1              1                   1              1                1
                    âˆ‘(             ğ‘‹ğ‘–âŠ¤ 1 âˆ’        ğ¹ğ‘–âŠ¤ 1Î›âŠ¤
                                                        ğ‘– ) =         trace ((       1âŠ¤ ğ‘‹ğ‘€Î› ) ( 1âŠ¤ ğ‘‹ğ‘€Î› )       ).
                ğ‘   ğ‘–=1
                           ğ‘‡                  ğ‘‡                   ğ‘              ğ‘‡                ğ‘‡

   We propose to combine these two objective functions with the risk-premium weight ğ›¾. The idea
is to obtain statistical factors that explain the co-movement in the data and produce small pricing
errors:
                                                                                                                    âŠ¤
                     1                                                    1              1            1
             min           trace (((ğ‘‹ğ‘€Î› )âŠ¤ (ğ‘‹ğ‘€Î› )) + ğ›¾                        trace ((       1âŠ¤ ğ‘‹ğ‘€Î› ) ( 1âŠ¤ ğ‘‹ğ‘€Î› )        )
              Î›,ğ¹   ğ‘ğ‘‡                                                ğ‘ğ‘‡                 ğ‘‡            ğ‘‡
                     1                                     ğ›¾
           = min           trace (ğ‘€Î› ğ‘‹âŠ¤ (ğ¼ +                   11âŠ¤ ) ğ‘‹ğ‘€Î› )           s.t. ğ¹ = ğ‘‹(Î›âŠ¤ Î›)âˆ’1 Î›âŠ¤ .
               Î›    ğ‘ğ‘‡                                     ğ‘‡

Here we have made use of the linearity of the trace operator. The objective function is minimized
by the eigenvectors of the largest eigenvalues of
                                                                       1
                                                                      ğ‘ğ‘‡
                                                                         ğ‘‹âŠ¤    (ğ¼ğ‘‡ +
                                                                                       ğ›¾
                                                                                           11âŠ¤ ) ğ‘‹.
                                                                           Hence the factors and load-
                                                                                       ğ‘‡
ings can be obtained by applying PCA to this new matrix. The estimator for the loadings Î›Ì‚ are the
eigenvectors of the ï¬rst ğ¾ eigenvalues of ğ‘ğ‘‡ ğ‘‹âŠ¤ (ğ¼ğ‘‡ + ğ‘‡ 11âŠ¤ ) ğ‘‹ multiplied by âˆšğ‘. ğ¹ Ì‚ are ğ‘ ğ‘‹Î›.Ì‚ The
                                           1          ğ›¾                                      1


estimator for the common component ğ¶ = ğ¹Î› is simply ğ¶ Ì‚ = ğ¹Î›    Ì‚ Ì‚ âŠ¤ . The estimator simpliï¬es to PCA
of the covariance matrix for ğ›¾ = âˆ’1.
   In practice conventional PCA is often applied to the correlation instead of the covariance matrix.
This implies that the returns are demeaned and normalized by their standard-deviation before apply-
ing PCA to their inner product. Hence, factors are chosen that explain most of the correlation instead
of the variance. This approach is particularly appealing if the underlying panel data is measured in
diï¬€erent units. Usually estimation based on the correlation matrix is more robust than based on the
covariance matrix as it is less aï¬€ected by a few outliers with very large variances. From a statistical
perspective this is equivalent to applying a cross-sectional weighting matrix to the panel data. Af-
ter applying PCA to the inner product, the inverse of the weighting matrix has to be applied to the
estimated eigenvectors. The statistical rationale is that certain cross-sectional observations contain
more information about the systematic risk than others and hence should obtain a larger weight in
the statistical analysis. The standard deviation of each cross-sectional observation serves as a proxy
for how large the noise is and therefore down-weighs very noisy observations.
   Mathematically, a weighting matrix means that instead of minimizing equally weighted pricing
errors we apply a weighting function ğ‘„ to the cross-section resulting in the following weighted com-
bined objective function:

                                   1
                     min                trace(ğ‘„âŠ¤ (ğ‘‹ âˆ’ ğ¹Î›âŠ¤ )âŠ¤ (ğ‘‹ âˆ’ ğ¹Î›âŠ¤ )ğ‘„)
                         Î›,ğ¹       ğ‘ğ‘‡
                                                       1
                                                  +ğ›¾       trace (1âŠ¤ (ğ‘‹ âˆ’ ğ¹Î›âŠ¤ )ğ‘„ğ‘„âŠ¤ (ğ‘‹ âˆ’ ğ¹Î›âŠ¤ )âŠ¤ 1)
                                                       ğ‘

                                                                                ğ›¾
                                       = min trace (ğ‘€Î› ğ‘„âŠ¤ ğ‘‹âŠ¤ (ğ¼ +                   11âŠ¤ ) ğ‘‹ğ‘„ğ‘€Î› )
                                          Î›                                     ğ‘‡
                                                  s.t. ğ¹ = ğ‘‹(Î›âŠ¤ Î›)âˆ’1 Î›âŠ¤ .


                                                                      6
Therefore factors and loadings can be estimated by applying PCA to ğ‘„âŠ¤ ğ‘‹âŠ¤ (ğ¼ +
                                                                                                      ğ›¾
                                                                                                      ğ‘‡
                                                                                                          11âŠ¤ ) ğ‘‹ğ‘„.   In our
empirical application we only consider the weighting matrix ğ‘„ which is the inverse of a diagonal
matrix of standard deviations of each return. For ğ›¾ = âˆ’1 this corresponds to using a correlation
matrix instead of a covariance matrix for PCA.
      There are four diï¬€erent interpretations of RP-PCA:
      (1) Variation and pricing objective functions: Our estimator combines a variation and pricing error
criteria function. As such it only selects factors that are priced and hence have small cross-sectional
alphaâ€™s. But at the same time it protects against spurious factors that have vanishing loadings as it
requires the factors to explain a large amount of the variation in the data as well.8
      (2) Penalized PCA: RP-PCA is a generalization of PCA regularized by a pricing error penalty term.
Factors that minimize the variation criterion need to explain a large part of the variance in the data.
Factors that minimize the cross-sectional pricing criterion need to have a non-vanishing risk-premia.
Our joint criteria is essentially looking for the factors that explain the time-series but penalizes factors
with a low Sharpe-ratio. Hence the resulting factors usually have much higher Sharpe-ratios than those
based on conventional factor analysis.
      (3) Information interpretation: Conventional PCA of a covariance matrix only uses information
contained in the second moment but ignores all information in the ï¬rst moment. As using all available
information in general leads to more eï¬ƒcient estimates, there is an argument for including the ï¬rst
moment in the objective function. Our estimator can be seen as combining two moment conditions
eï¬ƒciently. This interpretation drives the results for the strong factor model in Section 4.
                                         1
  (4) Signal-strengthening: The matrix ğ‘‹âŠ¤ ğ‘‹ + ğ›¾ğ‘‹Ì„ğ‘‹Ì„âŠ¤ should converge to9
                                                  ğ‘‡


                                         Î› (Î£ğ¹ + (1 + ğ›¾)ğœ‡ğ¹ ğœ‡ğ¹âŠ¤ ) Î›âŠ¤ + Var(ğ‘’),

where Î£ğ¹ = Var(ğ¹) denotes the covariance matrix of ğ¹ and ğœ‡ğ¹ = ğ¸[ğ¹] the mean of the factors. After
normalizing the loadings, the strengths of the factors in the standard PCA of a covariance matrix
are equal to their variances. Larger factor variances will result in larger systematic eigenvalues and a
more precise estimation of the factors. In our RP-PCA the signal of weak factors with a small variance
can be â€œpushed upâ€ by their mean if ğ›¾ is chosen accordingly. In this sense our estimator strengthens
the signal of the systematic part. This interpretation is the basis for the weak factor model studied
in Section 5.


4. Strong Factor Model

      In a strong factor model RP-PCA provides a more eï¬ƒcient estimator of the loadings than PCA.
Both RP-PCA and PCA provide consistent estimator for the loadings and factors. In the strong factor

  8
     A natural question to ask is why do we not just use the cross-sectional objective function for estimating latent factors,
if we are mainly interested in pricing? First, the cross-sectional pricing objective function alone does not identify a set of
factors. For example it is a rank 1 matrix and it would not make sense to apply PCA to it. Second, there is the problem
of spurious factor detection (see e.g. Bryzgalova (2017)). Factors can perform well in a cross-sectional regression because
their loadings are close to zero. Thus â€œgoodâ€ asset pricing factors need to have small cross-sectional pricing errors and
explain the variation in the data.
   9
     In this large-dimensional context the limit will be more complicated and studied in the subsequent sections.


                                                              7
model, the systematic factors are so strong that they lead to exploding eigenvalues. This is captured
                                1 âŠ¤
by the assumption that          ğ‘
                                  Î› Î›   â†’ Î£Î› where Î£Î› is a full-rank matrix.10 This could be interpreted as
the strong factors aï¬€ecting an inï¬nite number of assets.
                                                                                                     1    1
   The estimator for the loadings Î›Ì‚ are the eigenvectors of the ï¬rst ğ¾ eigenvalues of               ğ‘
                                                                                                         ( ğ‘‡ ğ‘‹âŠ¤ ğ‘‹ + ğ›¾ğ‘‹Ì„ğ‘‹Ì„âŠ¤ )
multiplied by âˆšğ‘. Up to rescaling the estimators are identical to those in the weak factor model setup.
The estimator for the common component ğ¶ = ğ¹Î› is ğ¶ Ì‚ = ğ¹Î›    Ì‚ Ì‚ âŠ¤.
    Bai (2003) shows that under Assumption 1 the PCA estimator of the loadings has the same asymp-
totic distribution as an OLS regression of the true factors ğ¹ on ğ‘‹ (up to a rotation). Similarly, the
estimator for the factors behaves asymptotically like an OLS regression of the true loadings Î› on
ğ‘‹âŠ¤ (up to a rotation). Under slightly stronger assumptions we will show that the estimated loadings
under RP-PCA have the same asymptotic distribution up to rotation as an OLS regression of ğ‘Šğ¹ on
                      11âŠ¤
ğ‘Šğ‘‹ with ğ‘Š2 = (ğ¼ğ‘‡ + ğ›¾ ğ‘‡ ). Surprisingly, estimated factors under RP-PCA and PCA have the same
distribution.
    Assumption 1 is identical to Assumptions A-G in Bai (2003) plus the additional assumption in
                          1     ğ‘‡
E.4 that relates to      âˆšğ‘‡
                              âˆ‘ğ‘¡=1 ğ‘’ğ‘¡,ğ‘– . See Bai (2003) for a discussion of the assumptions. The correlation
structure in the residuals can be more general in the strong model than in the weak model. This comes
at the cost of larger values for the loading vectors. The residuals still need to satisfy a form of sparsity
assumption restricting the dependence. The strong factor model provides a distribution theory which
is based on a central limit theorem of the residuals. This is satisï¬ed for relevant processes, e.g. ARMA
models.


Assumption 1: Strong Factor Model
                                                                ğ‘
                                                1    ğ‘‡
  A: Factors: ğ¸[â€–ğ¹ğ‘¡ â€–4 ] â‰¤ ğ‘€ < âˆ and            ğ‘‡
                                                    âˆ‘ğ‘¡=1 ğ¹ğ‘¡ ğ¹ğ‘¡âŠ¤ â†’ Î£ğ¹ for some ğ¾ Ã— ğ¾ positive deï¬nite matrix Î£ğ¹
                          ğ‘
             1       ğ‘‡
      and    ğ‘‡
                 âˆ‘ğ‘¡=1 ğ¹ğ‘¡ â†’ ğœ‡ğ¹ .

   B: Factor loadings: â€–Î›ğ‘– â€– â‰¤ ğœ†Ì„ < âˆ, and â€–Î›âŠ¤ Î›/ğ‘ âˆ’ Î£ğœ† â€– â†’ 0 for some ğ¾ Ã— ğ¾ positive deï¬nite matrix
      Î£Î› .

  C: Time and cross-section dependence and heteroskedasticity: There exists a positive constant ğ‘€ < âˆ
      such that for all ğ‘ and ğ‘‡:

         1. ğ¸[ğ‘’ğ‘¡,ğ‘– ] = 0, ğ¸[|ğ‘’ğ‘¡,ğ‘– |8 ] â‰¤ ğ‘€.
                         ğ‘                                                                                    ğ‘‡
         2. ğ¸[ğ‘âˆ’1 âˆ‘ğ‘–=1 ğ‘’ğ‘ ,ğ‘– ğ‘’ğ‘¡,ğ‘– ] = ğ›¾(ğ‘ , ğ‘¡), |ğ›¾(ğ‘ , ğ‘ )| â‰¤ ğ‘€ for all ğ‘  and for every ğ‘¡ â‰¤ ğ‘‡ it holds âˆ‘ğ‘ =1 |ğ›¾(ğ‘ , ğ‘¡)| â‰¤
             ğ‘€

         3. ğ¸[ğ‘’ğ‘¡,ğ‘– ğ‘’ğ‘¡,ğ‘— ] = ğœğ‘–ğ‘—,ğ‘¡ with |ğœğ‘–ğ‘—,ğ‘¡ | â‰¤ |ğœğ‘–ğ‘— | for some ğœğ‘–ğ‘— and for all ğ‘¡ and for every ğ‘– â‰¤ ğ‘ it holds
                 ğ‘
             âˆ‘ğ‘–=1 |ğœğ‘–ğ‘— | â‰¤ ğ‘€.
                                                     ğ‘           ğ‘‡     ğ‘‡
         4. ğ¸[ğ‘’ğ‘¡,ğ‘– ğ‘’ğ‘ ,ğ‘— ] = ğœğ‘–ğ‘—,ğ‘¡ğ‘  and (ğ‘ğ‘‡)âˆ’1 âˆ‘ğ‘–=1 âˆ‘ğ‘—=1 âˆ‘ğ‘¡=1 âˆ‘ğ‘ =1 |ğœğ‘–ğ‘—,ğ‘ ğ‘¡ | â‰¤ ğ‘€.
                                              ğ‘
         5. For every (ğ‘¡, ğ‘ ), ğ¸ [|ğ‘âˆ’1/2 âˆ‘ğ‘–=1 (ğ‘’ğ‘ ,ğ‘– ğ‘’ğ‘¡,ğ‘– ) âˆ’ ğ¸[ğ‘’ğ‘ ,ğ‘¡ ğ‘’ğ‘¡,ğ‘– ]|4 ] â‰¤ ğ‘€.

  10
     In latent factor models only the product ğ¹Î› is identiï¬ed. Hence without loss of generality we will normalize Î£Î› to the
identity matrix ğ¼ğ¾ and assume that the factors are uncorrelated.


                                                            8
  D: Weak dependence between factors and idiosyncratic errors:
           1    ğ‘     1   ğ‘‡
     ğ¸ [ ğ‘ âˆ‘ğ‘–=1 â€– âˆšğ‘‡ âˆ‘ğ‘¡=1 ğ¹ğ‘¡ ğ‘’ğ‘¡,ğ‘– â€–2 ] â‰¤ ğ‘€.

  E: Moments and Central Limit Theorem: There exists an ğ‘€ < âˆ such that for all ğ‘ and ğ‘‡:
                                  1        ğ‘‡           ğ‘                                     2
          1. For each ğ‘¡, ğ¸ [â€– âˆšğ‘ğ‘‡ âˆ‘ğ‘ =1 âˆ‘ğ‘˜=1 ğ¹ğ‘  (ğ‘’ğ‘ ,ğ‘˜ ğ‘’ğ‘¡,ğ‘˜ âˆ’ ğ¸[ğ‘’ğ‘ ,ğ‘˜ ğ‘’ğ‘¡,ğ‘˜ )]â€– ] â‰¤ ğ‘€
                                                               1       ğ‘‡       ğ‘
          2. The ğ¾ Ã— ğ¾ matrix satisï¬es ğ¸ [â€– âˆšğ‘ğ‘‡ âˆ‘ğ‘¡=1 âˆ‘ğ‘–=1 ğ¹ğ‘¡ Î›âŠ¤       2
                                                              ğ‘– ğ‘’ğ‘¡,ğ‘– â€– ] â‰¤ ğ‘€

          3. For each ğ‘¡ as ğ‘ â†’ âˆ:

                                                                       ğ‘
                                                                   1                ğ‘‘
                                                                       âˆ‘ Î›ğ‘– ğ‘’ğ‘¡,ğ‘– â†’ ğ‘(0, Î“ğ‘¡ ),
                                                               âˆšğ‘      ğ‘–=1

                                       1       ğ‘           ğ‘
               where Î“ğ‘¡ = limğ‘â†’âˆ       ğ‘
                                           âˆ‘ğ‘–=1 âˆ‘ğ‘—=1 Î›ğ‘– Î›âŠ¤
                                                         ğ‘— ğ¸[ğ‘’ğ‘¡,ğ‘– ğ‘’ğ‘¡,ğ‘— ]

          4. For each ğ‘– as ğ‘‡ â†’ âˆ:

                                           1       ğ‘‡
                                           âˆ‘    ğ¹ğ‘¡ ğ‘’ğ‘¡,ğ‘– ğ·                                       Î©11,ğ‘–     Î©12,ğ‘–
                                      â› âˆšğ‘‡1 ğ‘¡=1
                                             ğ‘‡
                                                       â â†’ ğ‘(0, Î©ğ‘– )                     Î©ğ‘– = â›                 â
                                      â âˆšğ‘‡ âˆ‘ğ‘¡=1 ğ‘’ğ‘¡,ğ‘– â                                         âÎ©21,ğ‘–      Î©22,ğ‘– â 


                                           1    ğ‘‡    ğ‘‡       ğ¹ğ‘¡ ğ¹ğ‘ âŠ¤ ğ‘’ğ‘ ,ğ‘– ğ‘’ğ‘¡,ğ‘–            ğ¹ğ‘¡ ğ‘’ğ‘ ,ğ‘– ğ‘’ğ‘¡,ğ‘–
               where Î©ğ‘– = ğ‘ limğ‘‡â†’âˆ         ğ‘‡
                                               âˆ‘ğ‘ =1 âˆ‘ğ‘¡=1 ğ¸ â¡â› âŠ¤                                     ââ¤.
                                                           â£â ğ¹ğ‘  ğ‘’ğ‘ ,ğ‘– ğ‘’ğ‘¡,ğ‘–                ğ‘’ğ‘ ,ğ‘– ğ‘’ğ‘¡,ğ‘– â â¦

  F: The eigenvalues of the ğ¾ Ã— ğ¾ matrix Î£Î› Î£ğ¹ are distinct.


   Theorem 1 provides a complete inferential theory for the strong factor model.


Theorem 1: Asymptotic distribution in strong factor model
Assume Assumption 1 holds. Then:

  1. If min(ğ‘, ğ‘‡) â†’ âˆ, then for any ğ›¾ âˆˆ [âˆ’1, âˆ) the factors and loadings can be estimated consis-
     tently pointwise.

          âˆšğ‘‡
  2. If   ğ‘
               â†’ 0, then the asymptotic distribution of the loadings estimator is given by

                                               ğ·
                    âˆšğ‘‡ (ğ»âŠ¤ Î›Ì‚ ğ‘– âˆ’ Î›ğ‘– ) â†’ ğ‘(0, Î¦ğ‘– )

                                       âˆ’1                                                                                         âˆ’1
     Î¦ğ‘– = (Î£ğ¹ + (ğ›¾ + 1)ğœ‡ğ¹ ğœ‡ğ¹âŠ¤ )                (Î©11,ğ‘– + ğ›¾ğœ‡ğ¹ Î©21,ğ‘– + ğ›¾Î©12,ğ‘– ğœ‡ğ¹ + ğ›¾2 ğœ‡ğ¹ Î©22,ğ‘– ğœ‡ğ¹ ) (Î£ğ¹ + (ğ›¾ + 1)ğœ‡ğ¹ ğœ‡ğ¹âŠ¤ )
                           1                       1
                    ğ»=(        ğ¹âŠ¤ ğ‘Š2 ğ¹) (                   âˆ’1
                                                         Ì‚ ğ‘‰ğ‘‡ğ‘
                                                       Î›Î›)
                          ğ‘‡                     ğ‘

                                                                                              1                               11âŠ¤
     and ğ‘‰ğ‘‡ğ‘ is a diagonal matrix of the largest ğ¾ eigenvalues of                            ğ‘ğ‘‡
                                                                                                 ğ‘‹âŠ¤ ğ‘Š2 ğ‘‹   and ğ‘Š2 = (ğ¼ğ‘‡ + ğ›¾   ğ‘‡
                                                                                                                                    ).
     For ğ›¾ = âˆ’1 this simpliï¬es to the conventional case                            Î£âˆ’1       âˆ’1
                                                                                    ğ¹ Î©11,ğ‘– Î£ğ¹ .

          âˆšğ‘
  3. If    ğ‘‡
               â†’ 0, then the asymptotic distribution of the factors is not aï¬€ected by the choice of ğ›¾.

  4. For any choice of ğ›¾ âˆˆ [âˆ’1, âˆ) the common components can be estimated consistently if

                                                                           9
     min(ğ‘, ğ‘‡) â†’ âˆ. The asymptotic distribution of the common component depends on ğ›¾ if and only
     if ğ‘‡/ğ‘ does not go to zero. For ğ‘‡/ğ‘ â†’ 0

                                                                       ğ·
                                                    Ì‚ âˆ’ ğ¶ğ‘¡,ğ‘– ) â†’ ğ‘ (0, ğ¹ğ‘¡âŠ¤ Î¦ğ‘– ğ¹ğ‘¡ ) .
                                               âˆšğ‘‡ (ğ¶ğ‘¡,ğ‘–


                                                                                                   âˆ’1
   Note that Bai (2003) characterizes the distribution of âˆšğ‘‡ (Î›ğ‘– âˆ’ ğ»âŠ¤                                   Î›Ì‚ ğ‘– ), while we rotate the
estimated loadings âˆšğ‘‡ (ğ»âŠ¤ Î›Ì‚ ğ‘– âˆ’ Î›ğ‘– ). Our rotated estimators are directly comparable for diï¬€erent
choices of ğ›¾. The proof of the theorem is essentially identical to the arguments of Bai (2003). The key
argument is based on an asymptotic expansion. Under Assumption 1 we can show that the following
expansions hold
                                 1              âˆ’1    1                        âˆšğ‘‡
  1. âˆšğ‘‡ (ğ»âŠ¤ Î›Ì‚ ğ‘– âˆ’ Î›ğ‘– ) = ( ğ‘‡ ğ¹âŠ¤ ğ‘Š2 ğ¹)               âˆšğ‘‡
                                                        ğ¹âŠ¤ ğ‘Š2 ğ‘’ğ‘–   + ğ‘‚ğ‘ (      ğ‘
                                                                                  )   + ğ‘œğ‘ (1)

              âˆ’1                     1         âˆ’1     1                    âˆšğ‘
  2. âˆšğ‘ (ğ»âŠ¤        ğ¹ğ‘¡Ì‚ âˆ’ ğ¹ğ‘¡ ) = ( ğ‘ Î›âŠ¤ Î›)            âˆšğ‘
                                                        Î›âŠ¤ ğ‘’ğ‘¡âŠ¤   + ğ‘‚ğ‘ (     ğ‘‡
                                                                              )   + ğ‘œğ‘ (1)

                           âˆšğ›¿ âŠ¤           1             âˆ’1    1                âˆšğ›¿ âŠ¤      1         âˆ’1    1
          Ì‚ âˆ’ ğ¶ğ‘¡,ğ‘– ) =
  3. âˆšğ›¿ (ğ¶ğ‘¡,ğ‘–                ğ¹
                           âˆšğ‘‡ ğ‘¡
                                         ( ğ‘‡ ğ¹âŠ¤ ğ‘Š2 ğ¹)        âˆšğ‘‡
                                                                ğ¹âŠ¤ ğ‘Š2 ğ‘’ğ‘–   +     Î›
                                                                               âˆšğ‘ ğ‘–
                                                                                       ( ğ‘ Î›âŠ¤ Î›)        âˆšğ‘
                                                                                                           Î›âŠ¤ ğ‘’ğ‘¡âŠ¤   + ğ‘œğ‘ (1)
     with ğ›¿ = min(ğ‘, ğ‘‡).

We just need to replace the factors and asset space by their projected counterpart ğ‘Šğ¹ and ğ‘Šğ‘‹ in
Baiâ€™s (2003) proofs. Conventional PCA, i.e. ğ›¾ = âˆ’1 is a special case of our result, which typically
leads to ineï¬ƒcient estimation.


Lemma 1: If ğœ‡ğ¹ â‰  0, then it is not eï¬ƒcient to use the covariance matrix for estimating the loadings and
common components, i.e. the choice of ğ›¾ = âˆ’1 does not lead to the smallest asymptotic covariance
matrix for the loadings and common components.


   In order to get a better intuition we consider an example with i.i.d. residuals over time. This
simpliï¬ed model will be more comparable to the weak factor model in the next section.


Example 1: Simpliï¬ed Strong Factor Model
                            ğ‘
  1. Rate: Assume that      ğ‘‡
                                â†’ ğ‘ with 0 < ğ‘ < âˆ.

  2. Factors: The factors ğ¹ are uncorrelated among each other and are independent of ğ‘’ and Î› and
     have bounded ï¬rst two moments.


                                          ğ‘‡                                          ğœğ¹21               â‹¯   0
                                     1          ğ‘                      1          ğ‘â›                          â
                         ğœ‡ğ¹Ì‚ âˆ¶=          âˆ‘ ğ¹ğ‘¡ â†’ ğœ‡ğ¹            Î£Ì‚ğ¹ âˆ¶= ğ¹ğ‘¡ ğ¹ğ‘¡âŠ¤ â†’ Î£ğ¹ = âœ
                                                                                   âœ
                                                                                   âœâ‹®                   â‹±  â‹®âŸ âŸ
                                                                                                              âŸ.
                                     ğ‘‡   ğ‘¡=1                        ğ‘‡                                      2
                                                                                   â 0                  â‹¯ ğœğ¹ğ¾ â 

                             ğ‘
  3. Loadings: Î›âŠ¤ Î›/ğ‘ â†’ ğ¼ğ¾ and all loadings are bounded. The loadings are independent of the
     factors and residuals.


                                                                  10
                                                                                         ğ‘–.ğ‘–.ğ‘‘.
   4. Residuals: Residual matrix can be represented as ğ‘’ = ğœ–Î£ with ğœ–ğ‘¡,ğ‘– âˆ¼ ğ‘(0, 1). All elements and
      all row sums of Î£ are bounded.


Corollary 1: Simpliï¬ed Strong Factor Model:
The assumptions of example 1 hold. The factors and loadings can be estimated consistently. The
asymptotic distribution of the factors is not aï¬€ected by ğ›¾. The asymptotic distribution of the loadings
is given by

                                                                 ğ·
                                       âˆšğ‘‡ (ğ»âŠ¤ Î›Ì‚ ğ‘– âˆ’ Î›ğ‘– ) â†’ ğ‘(0, Î©ğ‘– ),

         2
where ğ¸[ğ‘’ğ‘¡,ğ‘– ] = ğœğ‘’2ğ‘– and

                                               âˆ’1                                                          âˆ’1
              Î©ğ‘– = ğœğ‘’2ğ‘– (Î£ğ¹ + (1 + ğ›¾)ğœ‡ğ¹ ğœ‡ğ¹âŠ¤ )       (Î£ğ¹ + (1 + ğ›¾)2 ğœ‡ğ¹ ğœ‡ğ¹âŠ¤ ) (Î£ğ¹ + (1 + ğ›¾)ğœ‡ğ¹ ğœ‡ğ¹âŠ¤ )               .

The optimal choice for the weight minimizing the asymptotic variance is ğ›¾ = 0. Choosing ğ›¾ = âˆ’1, i.e.
the covariance matrix for factor estimation, is not eï¬ƒcient.


   The estimator in the strong factor model can be formulated as a GMM problem. Up to a remainder
term that vanishes under appropriate rate conditions the loading estimator is given by

                                                                 âˆ’1
                                       ğ»âŠ¤ Î›Ì‚ ğ‘– = (ğ¹âŠ¤ ğ‘Š2 ğ¹)            ğ¹âŠ¤ ğ‘Š2 ğ‘‹ğ‘– .

This is equivalent to combining the OLS and the pricing moment conditions with a weight ğ›¾. More
speciï¬cally, we deï¬ne the following ğ¾ + 1 population and sample moments

                                                    âˆ’1/2                           1               âŠ¤                âˆ’1/2
                     ğ‘‹ğ‘¡,ğ‘– âˆ’ ğ¹ğ‘¡ Î›âŠ¤            âŠ¤
                                ğ‘– )ğ¹ğ‘¡ (ğ¸[ğ¹ğ‘¡ ğ¹ğ‘¡ ])                                      (ğ‘‹ğ‘– âˆ’ ğ¹Î›âŠ¤       âŠ¤
                                                                                               ğ‘– ) ğ¹ (ğ¹ ğ¹)
     ğº(Î›ğ‘– ) = ğ¸ â¡â›                                         ââ¤         Ì‚ ğ‘– ) = â› âˆšğ‘‡
                                                                     ğº(Î›                                                   â
                â£â           ğ¸[ğ‘‹ğ‘– âˆ’ ğ¹ğ‘¡ Î›ğ‘–âŠ¤ ]               â â¦                 â
                                                                                         1
                                                                                         ğ‘‡
                                                                                             (ğ‘‹ğ‘– âˆ’ ğ¹Î›âŠ¤
                                                                                                     ğ‘– )
                                                                                                           âŠ¤
                                                                                                               1           â 

The ï¬rst ğ¾ moments are identical to the OLS ï¬rst order condition of a regression of ğ‘‹ on ğ¹. The last
moment is the APT pricing moment equation. The GMM estimator

                                                      ğ¼               0
                                                   Ì‚ â›ğ¾
                                           argmin ğºâŠ¤                   â ğºÌ‚
                                                     â0               ğ›¾â 

has the solution ğ»âŠ¤ Î›Ì‚ ğ‘– .


5. Weak Factor Model

   If factors are weak rather than strong RP-PCA can detect factors that are not estimated by conven-
tional PCA. Weak factors aï¬€ect only a smaller fraction of the assets. After normalizing the loadings,
a weak factor can be interpreted as having a small variance. If the variance of a weak factor is below
a critical value, it cannot be detected by PCA. However, the signal of RP-PCA depends on the mean
and the variance of the factors. Thus, RP-PCA can detect weak factors with a high Sharpe-ratio even

                                                            11
if their variance is below the critical detection value. Weak factors can only be estimated with a bias
but the bias will generally be smaller for RP-PCA than for PCA.
                                                                                                                  1 âŠ¤
      In a weak factor model Î›âŠ¤ Î› is bounded in contrast to a strong factor model in which                        ğ‘
                                                                                                                    Î› Î›   is
bounded. The statistical model for analyzing weak factor models is based on spiked covariance mod-
els from random matrix theory. It is well-known that under the assumptions of random matrix the
eigenvalues of a sample covariance matrix separate into two areas: (1) the bulk spectrum with the
majority of the eigenvalues that are clustered together and (2) some spiked large eigenvalues sepa-
rated from the bulk. Under appropriate assumptions the bulk spectrum converges to the generalized
Marchenko-Pastur distribution. The largest eigenvalues are estimated with a bias which is charac-
terized by the Stieltjes transform of the generalized Marchenko-Pastur distribution. If the largest
population eigenvalues are below some critical threshold, a phase transition phenomena occurs. The
estimated eigenvalues will vanish in the bulk spectrum and the corresponding estimated eigenvectors
will be orthogonal to the population eigenvectors.11
                                                                                  1 âŠ¤
    The estimator of the loadings Î›Ì‚ are the ï¬rst ğ¾ eigenvectors of               ğ‘‡
                                                                                    ğ‘‹ ğ‘‹ + ğ›¾ğ‘‹Ì„ğ‘‹Ì„âŠ¤ .    Conventional PCA
                                                                         12
of the sample covariance matrix corresponds to ğ›¾ = âˆ’1.                        The estimators of the factors are the
regression of the returns on the loadings, i.e. ğ¹ Ì‚ = ğ‘‹Î›.Ì‚

5.1. Assumptions
      We impose the following assumptions on the approximate factor model:


Assumption 2: Weak Factor Model

  A: Rate: Assume that N/ğ‘‡ â†’ ğ‘ with 0 < ğ‘ < âˆ.

   B: Factors: The factors ğ¹ are uncorrelated among each other and are independent of ğ‘’ and Î› and
        have bounded ï¬rst two moments.


                                        ğ‘‡                                      ğœğ¹21         â‹¯     0
                                    1         ğ‘               1           ğ‘  â›                    â
                           ğœ‡ğ¹Ì‚ âˆ¶=       âˆ‘ ğ¹ğ‘¡ â†’ ğœ‡ğ¹       Î£Ì‚ğ¹ âˆ¶= ğ¹ğ‘¡ ğ¹ğ‘¡âŠ¤ â†’ Î£ğ¹ = âœ
                                                                             âœ
                                                                             âœâ‹®             â‹±  â‹®âŸ âŸ
                                                                                                  âŸ.
                                    ğ‘‡   ğ‘¡=1                   ğ‘‡                                2
                                                                             â 0            â‹¯ ğœğ¹ğ¾ â 

                           ğ‘
  C: Loadings: Î›âŠ¤ Î› â†’ ğ¼ğ¾ and the column vectors of the loadings Î› are orthogonally invariant (e.g.
        Î›ğ‘–,ğ‘˜ âˆ¼ ğ‘(0, 1/ğ‘) and independent of the factors and residuals.

  D: Residuals: The empirical eigenvalue distribution function of Î£ converges almost surely weakly to
        a non-random spectral distribution function with compact support. The supremum of the support
        is ğ‘ and the largest eigenvalues of Î£ converge to ğ‘.

 11
     Onatski (2012) studies weak factor models and shows the phase transition phenomena for weak factors estimated with
PCA. Our paper provides a solution to this factor detection problem. It is important to notice that essentially all models in
random matrix theory work with processes with mean zero. However, RP-PCA crucially depends on using non-zero means
of random variables. Hence, we need to develop new arguments to overcome this problem.
  12
     The properties of weak factor models based on covariances have already been studied in Onatski (2012), Paul (2007) and
Benaych-Georges and Nadakuditi (2011). We replicate those results applied to our setup. They will serve as a benchmark
for the more complex risk-premium estimator.


                                                            12
      Assumption 2.C can be interpreted as considering only well-diversiï¬ed portfolios as factors. It
essentially assumes that the portfolio weights of the factors are random with a variance of 1/ğ‘.
                                                                                                                              ğ‘–.ğ‘–.ğ‘‘.
The orthogonally invariance assumption on the loading vectors is satisï¬ed if for example Î›ğ‘–,ğ‘˜ âˆ¼
ğ‘(0, 1/ğ‘). This is certainly a stylized assumption, but it allows us to derive closed-form solutions
that are easily interpretable.13 Assumption 2.D is a standard assumption in random matrix theory.14
The assumption allows for non-trivial weak cross-sectional correlation in the residuals, but excludes
serial-correlation. It implies clustering of the largest eigenvalues of the population covariance matrix
of the residuals and rules out that a few linear combinations of idiosyncratic terms have an unusually
large variation which could not be separated from the factors. It can be weakened as in Onatski
(2012) when considering estimation based on the covariance matrix. However, when including the
risk-premium in the estimation it seems that the stronger assumption is required. Many relevant
cross-sectional correlation structures are captured by this assumption e.g. sparse correlation matrices
or an ARMA-type dependence.

5.2. Asymptotic Results
      In order to state the results for the weak factor model, we need to deï¬ne several well-known objects
from random matrix theory. We deï¬ne the average idiosyncratic noise as ğœğ‘’2 âˆ¶= trace(Î£)/ğ‘, which
is the average of the eigenvalues of Î£. If the residuals are i.i.d. distributed ğœğ‘’2 would simply be their
variance. Our estimator will depend strongly on the dependency structure of the residual covariance
matrix which can be captured by their eigenvalues. Denote by ğœ†1 â‰¥ ğœ†2 â‰¥ ... â‰¥ ğœ†ğ‘ the ordered
                  1 âŠ¤
eigenvalues of    ğ‘‡
                    ğ‘’ ğ‘’.   The Cauchy transform (also called Stieltjes transform) of the eigenvalues is the
almost-sure limit:

                                               ğ‘                                                           âˆ’1
                                          1              1                  1                   1
                  ğº(ğ‘§) = ğ‘.ğ‘ . lim             âˆ‘              = ğ‘.ğ‘ . lim         trace ((ğ‘§ğ¼ğ‘ âˆ’       ğ‘’âŠ¤ ğ‘’))         .
                                   ğ‘‡â†’âˆ    ğ‘   ğ‘–=1
                                                    ğ‘§ âˆ’ ğœ†ğ‘–            ğ‘‡â†’âˆ   ğ‘                   ğ‘‡

This function is well-deï¬ned for ğ‘§ outside the support of the eigenvalues. This Cauchy transform is
a well-understood object in random matrix theory. For simple cases analytical solutions exist and for
general Î£ it can easily be simulated or estimated from the data.
      A second important transformation of the residual eigenvalues is

                                   ğ‘                                                                  âˆ’2
                               ğ‘              ğœ†ğ‘–                      ğ‘                    1                   1
           ğµ(ğ‘§) = ğ‘.ğ‘ . lim         âˆ‘                     = ğ‘.ğ‘ . lim       trace (((ğ‘§ğ¼ğ‘ âˆ’       ğ‘’âŠ¤ ğ‘’))      (       ğ‘’âŠ¤ ğ‘’)) .
                        ğ‘‡â†’âˆ   ğ‘    ğ‘–=1
                                         (ğ‘§ âˆ’ ğœ†ğ‘–    )2         ğ‘‡â†’âˆ    ğ‘                    ğ‘‡                   ğ‘‡

The function ğµ(ğ‘§) is proportional to the derivative of ğº(ğ‘§). For special cases a closed-form solution
is available and for the general case it can be easily estimated.
      The crucial tool for understanding RP-PCA is the concept of a â€œsignal matrixâ€ ğ‘€. The signal matrix
essentially represents the largest true eigenvalues. For PCA estimation based on the sample covari-

 13
     Onatski (2012) does not impose orthogonally invariant loadings, but requires the loadings to be the eigenvectors of
1 âŠ¤
ğ‘‡
  ğ‘’ ğ‘’.  In order to make progress we need to impose some kind of assumption that allows us to diagonalize the residual
covariance matrix without changing the structure of the systematic part.
  14
     Similar assumptions have been imposed in Onatski (2010), Onatski (2012), Harding (2013) and Ahn and Horenstein
(2013).


                                                                13
ance matrix the signal matrix ğ‘€PCA equals:

                                                       ğœğ¹21 + ğ‘ğœğ‘’2        â‹¯        0
                                                  â›                                           â
                          ğ‘€PCA   = Î£ğ¹ + ğ‘ğœğ‘’2 ğ¼ğ¾ = âœ
                                                  âœ
                                                  âœ           â‹®           â‹±        â‹®          âŸ
                                                                                              âŸ
                                                                                              âŸ
                                                   â          0           â‹¯ ğœğ¹2ğ¾ + ğ‘ğœğ‘’2 â 

and the â€œsignalsâ€ are the ğ¾ largest eigenvalues ğœƒ1PCA , .., ğœƒğ¾
                                                             PCA
                                                                 of this matrix. The â€œsignal matrixâ€ for
RP-PCA ğ‘€RP-PCA is deï¬ned as

                                                                    1/2
                                       Î£ğ¹ + ğ‘ğœğ‘’2       Î£ğ¹ ğœ‡ğ¹ (1 + ğ›¾)
                                                                   Ìƒ
                          ğ‘€RP-PCA = â› âŠ¤ 1/2                              â.
                                    âğœ‡ğ¹ Î£ğ¹ (1 + ğ›¾)
                                                 Ìƒ (1 + ğ›¾)(ğœ‡ğ¹ ğœ‡ğ¹ + ğ‘ğœ22 )â 
                                                            âŠ¤



We deï¬ne ğ›¾Ìƒ = âˆšğ›¾ + 1 âˆ’ 1 and note that (1 + ğ›¾)          Ìƒ 2 = 1 + ğ›¾. The RP-PCA â€œsignalsâ€ are the ğ¾ largest
eigenvalues ğœƒ1RP-PCA , .., ğœƒğ¾
                            RP-PCA
                                   of ğ‘€RP-PCA . Intuitively, the signal of the factors is driven by Î£ğ¹ + (1 +
ğ›¾)ğœ‡ğœ‡âŠ¤ , which has the same eigenvalues as

                                                              1/2
                                            Î£ğ¹       Î£ğ¹ ğœ‡ğ¹ (1 + ğ›¾) Ìƒ
                                   â›                                   â.
                                       âŠ¤ 1/2                   âŠ¤
                                   â ğœ‡ğ¹ Î£ ğ¹  (1 + ğ›¾)
                                                   Ìƒ (1 + ğ›¾)(ğœ‡ğ¹  ğœ‡ğ¹  ) â 

                                                               ğ‘ğœğ‘’2      0
This is disturbed by the average noise which adds the matrix â›                  â. Note that the dis-
                                                             â 0    (1 + ğ›¾)ğ‘ğœğ‘’2 â 
turbance also depends on the parameter ğ›¾. We denote the corresponding orthonormal eigenvectors
of ğ‘€PCA by ğ‘ˆ:Ìƒ

                                                       ğœƒ1RP-PCA     â‹¯         0
                                                   â›                              â
                                 ğ‘ˆÌƒ âŠ¤ ğ‘€RP-PCA ğ‘ˆÌƒ = âœ
                                                   âœ
                                                   âœ     â‹®          â‹±         â‹®   âŸ
                                                                                  âŸ
                                                                                  âŸ.
                                                                       RP-PCA
                                                  â       0         â‹¯ ğœƒğ¾+1    â 

Unlike the conventional case of the covariance matrix with uncorrelated factors we cannot link the
eigenvalues of ğ‘€RP-PCA with speciï¬c factors. The rotation ğ‘ˆÌƒ tells us how much the ï¬rst eigenvalue
contributes to the ï¬rst ğ¾ factors, etc..


Theorem 2: Risk-Premium PCA under weak factor model
Assume Assumption 2 holds. We denote by ğœƒ1 , ..., ğœƒğ¾ the ï¬rst ğ¾ largest eigenvalues of the signal matrix
                                                                             1            11âŠ¤
ğ‘€ = ğ‘€PCA or ğ‘€ = ğ‘€RP-PCA . The ï¬rst ğ¾ largest eigenvalues ğœƒğ‘–Ì‚ ğ‘– = 1, ..., ğ¾ of ğ‘‹âŠ¤ (ğ¼ğ‘‡ + ğ›¾      ) ğ‘‹ satisfy
                                                                                              ğ‘‡   ğ‘‡


                                        1                                               1
                               ğ‘ â§ ğºâˆ’1 ( )              if ğœƒğ‘– > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ = limğ‘§â†“ğ‘
                           ğœƒğ‘–Ì‚ â†’ â¨      ğœƒğ‘–                                             ğº(ğ‘§)

                                 â© ğ‘                    otherwise.




                                                        14
      The correlation of the estimated with the true factors15 converges to

                                                              ğœŒ1        0    â‹¯    0
                                                            â›
                                                            âœ                      â
                                                            âœ0          ğœŒ2   â‹¯    0âŸ
                                                                                   âŸ
                                     Ì‚
                                     Corr(ğ¹, ğ¹)Ì‚ =    âŸÌƒ
                                                      ğ‘„     âœ
                                                            âœ                      âŸ
                                                                                   âŸ        âŸÌƒ
                                                                                            ğ‘…
                                                            âœ
                                                            âœ0          0    â‹±    â‹®âŸ
                                                                                   âŸ
                                                   ğ‘Ÿğ‘œğ‘¡ğ‘ğ‘¡ğ‘–ğ‘œğ‘›                              ğ‘Ÿğ‘œğ‘¡ğ‘ğ‘¡ğ‘–ğ‘œğ‘›
                                                            â0          â‹¯    0    ğœŒğ¾ â 

with

                                                        1
                                               ğ‘ â§         Ì‚             if ğœƒğ‘– > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡
                                           ğœŒğ‘–2 â†’ â¨ 1+ğœƒğ‘– ğµ(ğœƒğ‘– ))
                                                 â© 0                     otherwise



For ğœƒğ‘– > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ the correlation ğœŒğ‘– is strictly increasing in ğœƒğ‘– . If ğœ‡ğ¹ â‰  0, then for any ğ›¾ > âˆ’1 RP-PCA has
higher correlations ğœŒğ‘– than PCA and RP-PCA strictly dominates PCA in terms of detecting factors, i.e.
ğœŒğ‘– > 0.
      The rotation matrices satisfy ğ‘„Ìƒ âŠ¤ ğ‘„Ìƒ â‰¤ ğ¼ğ¾ and ğ‘…Ìƒ âŠ¤ ğ‘…Ìƒ â‰¤ ğ¼ğ¾ . Hence, the correlation ğ¶ğ‘œğ‘Ÿğ‘Ÿ(ğ¹
                                                                                           Ì‚ ğ‘– , ğ¹ğ‘–Ì‚ ) is not
necessarily an increasing function in ğœƒ. For ğ›¾ > âˆ’1 the rotation matrices equal:

                                                                              1/2 âˆ’1/2
                                           ğ‘„Ìƒ = (ğ¼ğ¾         Ìƒ
                                                        0) ğ‘ˆ1âˆ¶ğ¾         ğ‘…Ìƒ = ğ·ğ¾ Î£Ì‚ğ¹ Ì‚ ,

       Ìƒ
where ğ‘ˆ1âˆ¶ğ¾ are the ï¬rst ğ¾ columns of ğ‘ˆÌƒ and

                                            âŠ¤
                           ğœŒ     â‹¯     0                           ğœŒ1    â‹¯    0
                       â›â› 1           â                          â›            â   1 âˆ’ ğœŒ12           â‹¯    0     â
                       âœâœ                                                                                      âŸ
                   1/2 âœâœ  â‹®     â‹± â‹®âŸ âŸ        ğ¼ğ¾         0      âœ
                                                                 âœâ‹®      â‹± â‹®âŸ âŸ â›
                                                                                âœ â‹®                          â
                                                                                                             âŸ âŸ 1/2
          Î£Ì‚ğ¹ Ì‚ = ğ·ğ¾ âœ âœâœâœ            âŸ
                                      âŸ ğ‘ˆÌƒ âŠ¤ â›              â ğ‘ˆÌƒ âœ
                                                                 âœ            âŸ
                                                                              âŸ+âœ
                                                                                âœ                   â‹±   â‹® âŸ  âŸâŸ
                                                                                                               âŸğ·
                         âœ
                       âœâœ 0           âŸ
                                 â‹¯ ğœŒğ¾ âŸ      â0           0â  âœ   âœ0      â‹¯ ğœŒğ¾ âŸ
                                                                              âŸ                                âŸ ğ¾
                       âœ                                                                                   2 âŸ
                                                                                â 0                 â‹¯ 1 âˆ’ ğœŒğ¾ â 
                       ââ 0      â‹¯ 0â                             â0      â‹¯ 0â                                   â 
          ğ·ğ¾ = ğ‘‘ğ‘–ğ‘ğ‘” ((ğœƒ1Ì‚        â‹¯ ğœƒğ¾Ì‚ ))

For PCA (ğ›¾ = âˆ’1) the rotation matrices simplify to ğ‘„Ìƒ = ğ‘…Ìƒ = ğ¼ğ¾ .


      Theorem 2 states that the asymptotic behavior of the estimator can be completely explained by
the signals of the factors for a given distribution of the idiosyncratic shocks. The theorem also states
that weak factors can only be estimated with a bias. If a factor is too weak then it cannot be detected
at all. Weak factors can always be better detected using Risk-Premium-PCA instead of covariance PCA.
The phase transition phenomena that hides weak factors can be avoided by putting some weight on
the information captured by the risk-premium. Based on our asymptotic theory, we can choose the
optimal weight ğ›¾ depending on our objective, e.g. to make all weak factors detectable or achieving
the largest correlation for a speciï¬c factor. Typically the rotation matrices ğ‘ˆÌƒ and ğ‘‰Ìƒ are decreasing in
ğ›¾ while ğœŒğ‘– is strictly increasing in ğ›¾, yielding an optimal value for the largest correlation.


 15   Ì‚               1        11âŠ¤    âˆ’1/2
                                             1        11âŠ¤        1         11âŠ¤     âˆ’1/2
      Corr(ğ¹, ğ¹)Ì‚ = ( ğ‘‡ ğ¹âŠ¤ (ğ¼ âˆ’ ğ‘‡ ) ğ¹)     ( ğ‘‡ ğ¹âŠ¤ (ğ¼ âˆ’ ğ‘‡ ) ğ¹)Ì‚ ( ğ‘‡ ğ¹âŠ¤Ì‚ (ğ¼ âˆ’ ğ‘‡ ) ğ¹)Ì‚     .


                                                                  15
5.3. Examples
   In order to obtain a better intuition for the problem we consider two special cases. First, we
analyze the eï¬€ect of ğ›¾ in the case of only one factor. Second, we study PCA for the special case of
cross-sectionally uncorrelated residuals.


Example 2: One-factor model
Assume that there is only one factor, i.e. ğ¾ = 1. We introduce the following notation
                                    ğ‘â‹…ğœğ‘’2
   â€¢ Noise-to-signal ratio: Î“ğ‘’ =     ğœğ¹2
                           ğœ‡
   â€¢ Sharpe-ratio: ğ‘†ğ‘… = ğœğ¹ .
                             ğ¹

   â€¢ Î¦(ğœƒğ‘– ) âˆ¶= ğµ(ğœƒğ‘–Ì‚ (ğœƒğ‘– )).

The signal matrix ğ‘€ğ‘…ğ‘ƒâˆ’ğ‘ƒğ¶ğ´ simpliï¬es to

                                                1 + Î“ğ‘’    ğ‘†ğ‘…âˆš1 + ğ›¾
                               ğ‘€RP-PCA = ğœğ¹2 â›            2
                                                                        â
                                             âğ‘†ğ‘…âˆš1 + ğ›¾ (ğ‘†ğ‘… + Î“ğ‘’ )(1 + ğ›¾)â 

and has the largest eigenvalue:

                      1
                   ğœƒ = ğœğ¹2 (1 + Î“ğ‘’ + (ğ‘†ğ‘…2 + Î“ğ‘’ )(1 + ğ›¾)
                      2
                       + âˆš(1 + Î“ğ‘’ + (ğ‘†ğ‘…2 + Î“ğ‘’ )(1 + ğ›¾))2 âˆ’ 4(1 + ğ›¾)Î“ğ‘’ (1 + ğ‘†ğ‘…2 + Î“ğ‘’ ).


Corollary 2: One-factor model
Assume Assumption 2 holds and ğ¾ = 1. The correlation between the estimated and true factor has the
following limit:

                                                ğ‘                           1
                                 Ì‚
                                 Corr(ğ¹, ğ¹)Ì‚ 2 â†’                                              2
                                                                             ğœƒ
                                                                        (     2   âˆ’(1+Î“ğ‘’ ))
                                                        1 + ğœƒÎ¨(ğœƒ) â›                               + 1â
                                                                            ğœğ¹
                                                                  âœ          ğ‘†ğ‘…2 (1+ğ›¾)
                                                                                                     âŸ
                                                                  â                                  â 

and the estimated Sharpe-ratio converges to

                                                    ğœƒ
                                            ğ‘       ğœğ¹2
                                                          âˆ’ (1 + Î“ğ‘’ )
                                        Ì‚â†’
                                        ğ‘†ğ‘…                              Ì‚
                                                                        Corr(ğ¹,  Ì‚
                                                                                ğ¹).
                                                     ğ‘†ğ‘…(1 + ğ›¾)

For ğ›¾ â†’ âˆ these limits converge to

                                                    ğ‘          1
                                  Ì‚
                                  Corr(ğ¹, ğ¹)Ì‚ 2 â†’                     Î“ğ‘’2
                                                          1 + Î“ğ‘’ +   ğ‘†ğ‘…2
                                                    ğ‘              Î“ğ‘’                  1
                                            Ì‚ â†’ (ğ‘†ğ‘… +
                                            ğ‘†ğ‘…                          )                                .
                                                                   ğ‘†ğ‘…                              Î“ğ‘’2
                                                                             1 + Î“ğ‘’ +
                                                                            âˆš                     ğ‘†ğ‘…2




                                                              16
In the case of PCA, i.e. ğ›¾ = âˆ’1 the expression simpliï¬es to

                                                                ğ‘      1
                                             Ì‚
                                             Corr(ğ¹, ğ¹)Ì‚ 2 â†’
                                                                    1 + ğœƒÎ¨(ğœƒ)

with ğœƒPCA = ğœğ¹2 (1 + Î“ğ‘’ ).


    A smaller noise-to-signal ratio Î“ğ‘’ and a larger Sharpe-ratio combined with a large ğ›¾ lead to a more
precise estimation of the factors. In the simulation section we ï¬nd the optimal value of ğ›¾ to maximize
                                                                                                                              2
                                                                                                                 ğœƒ
                                                                                                            (     2   âˆ’(1+Î“ğ‘’ ))
                                                                                                                ğœğ¹
the correlation. Note that a larger value of ğ›¾ decreases ğœƒÎ¨(ğœƒ), while it increases                               ğ‘†ğ‘…2 (1+ğ›¾)
                                                                                                                                  , creating
a trade-oï¬€. In all our simulations ğ›¾ = âˆ’1 was never optimal.
    Now we study PCA for the special case of cross-sectionally uncorrelated residuals but many fac-
tors16


Example 3: PCA for model with independent residuals
Assume that ğ‘’ğ‘¡,ğ‘– i.i.d. ğ‘(0, ğœğ‘’2 ), i.e. Î£ = ğœğ‘’2 ğ¼ğ‘ . In this case the residual eigenvalues follow the well-
                                                                          ğ‘
known Marcenko-Pasteur Law. For simplicity assume that                    ğ‘‡
                                                                              â†’ ğ‘ with ğ‘ > 1. The results can be easily
extended to the case 0 < ğ‘ < 1.
    The maximum residual eigenvalue equals ğ‘ = ğœğ‘’2 (1 + âˆšğ‘)2 . The Cauchy transform takes the form

                                        ğ‘§ âˆ’ ğœğ‘’2 (1 âˆ’ ğ‘) âˆ’ âˆš(ğ‘§ âˆ’ ğœğ‘’2 (1 + ğ‘))2 âˆ’ 4ğ‘ğœğ‘’2
                             ğº(ğ‘§) =                                                               .
                                                                2ğ‘ğ‘§ğœğ‘’2

                                                                                1
Hence, the critical value for detecting factors is now ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ =                ğº(ğ‘+ )
                                                                                       = ğœğ‘’2 (ğ‘ + âˆšğ‘). The inverse of the
Cauchy transform and the B-function are given explicitly by

                                                ğœğ‘’2 (1âˆ’ğ‘)
                                1            1+
                         ğºâˆ’1 ( ) = ğ‘§ â›               ğ‘§
                                                   ğ‘ğœ2
                                                            â
                              ğ‘§      â 1        âˆ’ ğ‘§ğ‘’        â 
                                                      ğ‘§ âˆ’ ğœğ‘’2 (1 + ğ‘)                             1
                              ğµ(ğ‘§) =                                                         âˆ’          .
                                         2ğœğ‘’2 âˆšğ‘§2   âˆ’ 2(1 +     ğ‘)ğœğ‘’2 ğ‘§   + (ğ‘ âˆ’   1)2 ğœğ‘’4       2ğœğ‘’2


Corollary 3: PCA for model with independent residuals
Assumption 2 holds and ğ‘’ğ‘¡,ğ‘– i.i.d. ğ‘(0, ğœğ‘’2 ). The largest ğ¾ eigenvalues of the sample covariance matrix
have the following limiting values:
                                    2
                     ğ‘  â§
                        âª ğœğ¹2ğ‘– + ğœğ‘’2 (ğ‘ + 1 + ğœğ‘’2 )             if ğœğ¹2ğ‘– + ğ‘ğœğ‘’2 > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ â‡” ğœğ¹2 > âˆšğ‘ğœğ‘’2
                                 ğœğ¹ğ‘–
                 ğœ†Ì‚ ğ‘– â†’ â¨
                        âª ğœğ‘’2 (1 + âˆšğ‘)2                         otherwise.
                        â©

  16
     These results have already been shown in Onatski (2012), Paul (2007) and Benaych-Georges and Nadakuditi (2011). We
present them to provide intuition for the model.




                                                            17
The correlation between the estimated and true factors converges to

                                                      ğœŒ1            â‹¯     0
                                                  ğ‘ â›                      â
                                       Ì‚        Ì‚   âœ
                                       Corr(ğ¹, ğ¹) â†’ âœ                     â‹®âŸ
                                                                           âŸ
                                                    âœâ‹®              â‹±      âŸ
                                                    â0              â‹¯ ğœŒğ¾ â 

with

                                               ğ‘ğœğ‘’4
                                   â§
                                   âª
                                   âª         1âˆ’  4
                               ğ‘   âª
                                   âª
                                               ğœğ¹
                                                  ğ‘–
                                                                if ğœğ¹2ğ‘– + ğ‘ğœğ‘’2 > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡
                                       ğ‘ğœ2    ğœğ‘’4
                           ğœŒğ‘–2 â†’ â¨ 1+ ğœğ¹2ğ‘’   + 4 (ğ‘2 âˆ’ğ‘)
                                              ğœğ¹
                                 âª
                                 âª
                                 âª       ğ‘–      ğ‘–
                                 âª 0                            otherwise.
                                 â©


   Note that for ğœğ¹2ğ‘– going to inï¬nity, we are back in the strong factor model and the estimator be-
comes consistent.


6. Simulation

   Next, we illustrate the performance of RP-PCA and its ability to detect weak factors with high
Sharpe-ratios using a simulation exercise. We simulate factor models that try to replicate moments
of the data that we are going to study in section 7. The parameters of the factors and idiosyncratic
components are based on our empirical estimates. We analyze the performance of RP-PCA for diï¬€er-
ent values of ğ›¾, sample size and strength of the factors. Conventional PCA corresponds to ğ›¾ = âˆ’1.
In a factor model only the product ğ¹Î›âŠ¤ is well-identiï¬ed and the strength of the factors could be
either modeled through the moments of the factors or the values of the loadings. Throughout this
                                                      ğ‘
section we normalize the loadings to Î›âŠ¤ Î›/ğ‘ â†’ ğ¼ğ¾ and vary the moments of the factors. The factors
are uncorrelated with each others and have diï¬€erent means and variances. The variance of the fac-
tor can be interpreted as the proportion of assets aï¬€ected by this factor. With this normalization a
factor with a variance of ğœğ¹2 = 0.5 could be interpreted as aï¬€ecting 50% of the assets with an average
loading strength of 1. The theoretical results for the weak factor model are formulated under the
                     ğ‘
normalization Î›âŠ¤ Î› â†’ ğ¼ğ¾ . The PCA signal in the weak factor framework corresponds to ğœğ¹2 â‹… ğ‘ under
the normalization in the simulation.


   The strength of a factor has to be put into relationship with the noise level. Based on our theo-
                                             ğœğ¹2                1     ğ‘
retical results the signal to noise ratio    ğœğ‘’2
                                                   with ğœğ‘’2 =   ğ‘
                                                                          2
                                                                    âˆ‘ğ‘–=1 ğœğ‘’,ğ‘– determines the variance signal of a
factor. Our empirical results suggest a signal to noise ratio of around 5-7 for the ï¬rst factor which is
essentially a market factor. The remaining factors in the diï¬€erent data sets seem to have a variance
signal between 0.04 and 0.8. Based on this insight we will model a four-factor model with variances
Î£ğ¹ = ğ‘‘ğ‘–ğ‘ğ‘”(5, 0.3, 0.1, ğœğ¹2 ). The variance of the fourth factor takes the values ğœğ¹2 âˆˆ {0.03, 0.1}. The
ï¬rst factor is a dominant market factor, while the second is also a strong factor. The third factor
is weak, while the fourth factor varies from very weak to weak. We normalize the factors to be un-
correlated with each other. The Sharpe-ratios are deï¬ned as ğ‘†ğ‘…ğ¹ = (0.12, 0.1, 0.3, ğ‘ ğ‘Ÿ), where the



                                                           18
                           1. Factor                                                       2. Factor
150                                                                20
             True factor
             RP-PCA =0                                             15
100          RP-PCA =10
             RP-PCA =20
             PCA                                                   10
 50
                                                                    5

  0
                                                                    0


-50                                                                 -5
      0      50       100           150    200       250                 0     50        100          150    200       250
                             Time                                                              Time

                           3. Factor                                                       4. Factor
 25                                                                25

 20                                                                20

 15                                                                15

 10                                                                10

  5                                                                 5

  0                                                                 0

 -5                                                                 -5
      0      50       100           150    200       250                 0     50        100          150    200       250
                             Time                                                              Time



Figure 1: Sample paths of the cumulative returns of the ï¬rst four factors and the estimated factor processes. The fourth
factor has a variance ğœğ¹2 = 0.03 and Sharpe-ratio ğ‘ ğ‘Ÿ = 0.5. ğ‘ = 74 and ğ‘‡ = 250.


Sharpe-ratio of the fourth factor varies between the following values ğ‘ ğ‘Ÿ âˆˆ {0.2, 0.3, 0.5, 0.8}. These
parameter values are consistent with our data sets.
      The properties of the estimation approach depend on the average idiosyncratic variance and de-
pendency structure in the residuals. We normalize the average noise variance ğœğ‘’2 = 1, which implies
that the factor variances can be directly compared to the variance signals in the data.17 We use two
diï¬€erent set of residual correlation matrices.



      First, the correlation matrix of our simulated residuals is set to the empirical correlation that
we observe in the data. In more detail, we have estimated the residual correlation matrix based
on ğ‘ = 25 size and value double-sorted portfolios, ğ‘ = 74 extreme deciles sorted portfolios and
ğ‘ = 370 decile sorted portfolios as described in the empirical Section 7.18 In each case we have ï¬rst
regressed out the systematic factors and then estimated the residual covariance matrix with a hard

  17
     For the empirical data sets with ğ‘ = 370 assets the average noise variance is around ğœğ‘’2 = 2.5. Instead of normalizing
ğœğ‘’2 = 1 we could also multiply Î£ğ¹ by 2.5 and obtain the same factor model that is consistent with the data.
  18
     We use the same data set as Kozak, Nagel and Santosh (2017) to construct ğ‘ = 370 decile-sorted portfolios of monthly
returns from 07/1963 to 12/2017 (T=650). We use the lowest and highest decile portfolio for each anomaly to create a
data set of ğ‘ = 74 portfolios. The ğ‘ = 25 double-sorted portfolios are from Kenneth-French website for the same time
period.


                                                           19
        1. Factor Corr. (IS) for 2F =0.03          1. Factor Corr. (OOS) for 2F =0.03         1. Factor Corr. (IS) for 2F =0.1           1. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                                         0.6
       0.4                                         0.4                                      0.4                                         0.4
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20


        2. Factor Corr. (IS) for 2F =0.03          2. Factor Corr. (OOS) for 2F =0.03         2. Factor Corr. (IS) for 2F =0.1           2. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                                         0.6
       0.4                                         0.4                                      0.4                                         0.4
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20


        3. Factor Corr. (IS) for 2F =0.03          3. Factor Corr. (OOS) for 2F =0.03         3. Factor Corr. (IS) for 2F =0.1           3. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                                         0.6
       0.4                                         0.4                                      0.4                                         0.4
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20


        4. Factor Corr. (IS) for 2F =0.03          4. Factor Corr. (OOS) for 2F =0.03         4. Factor Corr. (IS) for 2F =0.1           4. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
                                                                                                                   SR=0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                    SR=0.5               0.6
       0.4                                         0.4                                      0.4                    SR=0.3               0.4
                                                                                                                   SR=0.2
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20




Figure 2: ğ‘ = 370, ğ‘‡ = 650: Correlation of estimated rotated factors in-sample and out-of-sample for diï¬€erent variances
and Sharpe-ratios of the fourth factor and for diï¬€erent RP-weights ğ›¾. We use the empirical residual correlation matrix.


thresholding approach setting small values to zero.19 . This provides a consistent estimator of the
residual population covariance matrix. We have regressed out the ï¬rst 3 PCA factors for the ï¬rst data
set and the ï¬rst 6 PCA factors for the last two data sets.20 The remaining correlation structure in the
residuals is sparse. In particular the estimated eigenvalues of the simulated residuals coincide with
the empirical estimates of the eigenvalues. Second, for ğ‘ = 370 assets we create a sparse residual
correlation matrix based on Î£ = ğ¶ğ¶âŠ¤ , where C is a matrix with where the ï¬rst 13 oï¬€-diagonal elements
take the value 0.7. The resulting covariance matrix is normalized to the corresponding correlation
matrix. The residuals are then generated as ğ‘’ğ‘¡ = ğœ–Î£ where ğœ–ğ‘¡ are i.i.d. draws from a multivariate
standard normal distribution.
         In the main part we consider only the cross-sectional dimension ğ‘ = 370 and time dimension
ğ‘‡ = 650, but in the appendix we also study the combinations {ğ‘ = 74, ğ‘‡ = 650} and {ğ‘ = 25, ğ‘‡ =
240} motivated by our empirical analysis. The loadings are i.i.d draws from a standard multivariate
normal distribution. The factors are i.i.d. draws from a multivariate normal distribution with means

   19
   See Bickel and Levina (2008) and Fan, Liao and Mincheva (2013))
   20
   Our results remain unchanged when we calculate residuals based on more PCA factors or using RP-PCA factors. The
additional results are available upon request.


                                                                                  20
           1. Factor SR (IS) for 2F =0.03         1. Factor SR (OOS) for 2F =0.03              1. Factor SR (IS) for 2F =0.1           1. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
                                                                                                                  SR=0.8
     0.6                                         0.6                                     0.6                                         0.6
                                                                                                                  SR=0.5
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                      SR=0.3             0.4
                                                                                                                  SR=0.2
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20


           2. Factor SR (IS) for 2F =0.03         2. Factor SR (OOS) for 2F =0.03              2. Factor SR (IS) for 2F =0.1           2. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
     0.6                                         0.6                                     0.6                                         0.6
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                                         0.4
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20


           3. Factor SR (IS) for 2F =0.03         3. Factor SR (OOS) for 2F =0.03              3. Factor SR (IS) for 2F =0.1           3. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
     0.6                                         0.6                                     0.6                                         0.6
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                                         0.4
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20


           4. Factor SR (IS) for 2F =0.03         4. Factor SR (OOS) for 2F =0.03              4. Factor SR (IS) for 2F =0.1           4. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
     0.6                                         0.6                                     0.6                                         0.6
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                                         0.4
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20




Figure 3: ğ‘ = 370, ğ‘‡ = 650: Sharpe ratios of estimated rotated factors in-sample and out-of-sample for diï¬€erent variances
and Sharpe-ratios of the fourth factor and for diï¬€erent RP-weights ğ›¾. We use the empirical residual correlation matrix.


and variances speciï¬ed as above. The idiosyncratic components are i.i.d. draws from a multivari-
ate normal distribution with mean zero and covariance matrix based on a consistent estimation of
the empirical residual correlation matrix respectively the parametric band-diagonal matrix. For each
setup we run 100 Monte-Carlo simulations. For the out-of-sample results we ï¬rst estimate the loading
vector in-sample and then obtain the out-of-sample factor estimates by projecting the out-of-sample
returns on the estimated loadings.
      Figure 1 provides some intuition for our estimator. It illustrates the sample path estimates for
diï¬€erent values of ğ›¾. If the fourth factor is weak with a high Sharpe-ratio, then conventional PCA or
RP-PCA with a too small value of ğ›¾ cannot detect it while RP-PCA with a suï¬ƒciently large ğ›¾ is able to
detect the factor.
      Figures 2 and 3 show correlations and Sharpe-ratios in the four-factor model for ğ‘ = 370 and
ğ‘‡ = 650 based on the empirical residual correlation structure. A.10 and A.11 show the results for
ğ‘ = 74.21 The risk-premium weight ğ›¾ has the largest eï¬€ect on estimating the fourth factor if it is
weak (ğœğ¹2 = 0.03) and has a high Sharpe ratio (ğ‘ ğ‘Ÿ â‰¥ 0.3). The second takeaway is that the estimates

 21
      All simulation results in the appendix are based on the empirical residual correlation matrix.


                                                                               21
of the strong factors is essentially not aï¬€ected by the properties of the weak factors and vice versa.
Hence, one could ï¬rst estimate the strong factors and project them out and then estimate the weak
factors from the projected data. Motivated by this ï¬nding we will study a one-factor model in more
detail.
        Figure 4 compares the prediction of our weak factor model theory with the Monte-Carlo simulation
for the empirical and the band-diagonal residual correlation matrix. We consider one factor with
Sharpe-ratio 0.8, but increasing variance. The prediction of our statistical model is conï¬rmed by the
Monte-Carlo simulation. It convincingly shows how weak factors can be better estimated with RP-
PCA with a large ğ›¾ when the Sharpe-ratio is high. In Figure 5 we plot the value of ğœŒğ‘–2 in the weak
factor model which determines the detection and correlation of the factors. We vary the signal ğœƒ
which among others depends on the choice of ğ›¾. We compare uncorrelated residuals with our weak
dependency structures. It is apparent that increasing the signal strength for detecting weak factors
becomes more relevant for correlated residuals.


                         Statistical Model                                                    Statistical Model
        1                                                                         1


                                                   PCA ( =-1)                                                           PCA ( =-1)
                                                                          Corr
Corr




       0.5                                         RP-PCA ( =0)                  0.5                                    RP-PCA ( =0)
                                                   RP-PCA ( =10)                                                        RP-PCA ( =10)
                                                   RP-PCA ( =50)                                                        RP-PCA ( =50)
        0                                                                         0
             0        0.05                   0.1                   0.15                0   0.05                   0.1                   0.15
                                 2                                                                    2
                                 F                                                                    F
                      Monte-Carlo Simulation                                               Monte-Carlo Simulation
        1                                                                         1
                                                                          Corr
Corr




       0.5                                                                       0.5



        0                                                                         0
             0        0.05                   0.1                   0.15                0   0.05                   0.1                   0.15
                                 2                                                                    2
                                 F                                                                    F




Figure 4: Correlations between estimated and true factor based on the weak factor model prediction and Monte-Carlo
simulations for diï¬€erent variances of the factor. Left plots: The residuals have cross-sectional correlation deï¬ned by the
band-diagonal matrix. Right plots: The residuals have the empirical residual correlation matrix. The Sharpe-ratio of the
factor is 0.8, i.e. the mean equals ğœ‡ğ¹ = 0.8 â‹… ğœğ¹ . We have ğ‘‡ = 650 and ğ‘ = 370, i.e. the normalized variance of the factors
in the weak factor model corresponds to ğœğ¹2 â‹… ğ‘.




                                                                     22
      1                                                                 1


    0.8                                                                0.8


    0.6                                                                0.6
2




                                                                   2
    0.4                                                                0.4


    0.2                                                                0.2
                                     dependent residuals                                             dependent residuals
                                     i.i.d residuals                                                 i.i.d residuals
      0                                                                 0
          0     10        20         30                 40   50              0   10       20         30        40          50
                            signal                                                          signal


                                                    1
Figure 5: Model-implied values of ğœŒğ‘–2 ( 1+ğœƒ ğµ(ğœƒ Ì‚ )) if ğœƒğ‘– > ğœğ‘ğ‘Ÿğ‘–ğ‘¡
                                                              2
                                                                   and 0 otherwise) for diï¬€erent signals ğœƒğ‘– . The average noise
                                                ğ‘–       ğ‘–
level is normalized in both cases to      ğœğ‘’2
                                         = 1. Left plots: The residuals have cross-sectional correlation deï¬ned by the
band-diagonal matrix. Right plots: The residuals have the empirical residual correlation matrix.


    Figures 6 and 7 provide more reï¬ned results for the one-factor model for ğ‘ = 370 and ğ‘‡ = 650
for the empirical and band-diagonal residual correlation matrix. We consider a factor variance ğœğ¹2 âˆˆ
{0.03, 0.05, 0.1, 0.3, 1.0} which ranges from weak to strong factors. Figures A.12 to A.16 show the
results for ğ‘ = 74 and ğ‘ = 25 and include estimates of the root-mean-squared pricing errors. The
risk-premium weight ğ›¾ has the largest eï¬€ect on correlations, Sharpe-ratios and pricing errors if the
factors are weak (ğœğ¹2 = 0.03 or 0.05) and have a high Sharpe ratio (ğ‘ ğ‘Ÿ â‰¥ 0.3). Note, that if there is not
much information in the mean, i.e. the Sharpe-ratio of the factor is low, a too high value ğ›¾ > 10 can
lead to an overestimation of the Sharpe-ratio in-sample. This makes sense as if too much weight is
given to an uninformative mean, the estimator will pick up some of the non-zero residuals. Note, that
the out-of-sample results provide reliable estimates that are not aï¬€ected by overï¬tting issues. Our
estimator has a larger eï¬€ect for smaller values of ğ‘ as this implies a weaker signal for the factors.




                                                                  23
                                      2                                                      2                                                      2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                            Statistical Model   F
                                                                                               =0.05                            Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1
        1                                                      1                                                      1                                                       1                                                       1

                                       SR=0.8
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                             SR=0.5                 0.5                                                    0.5                                                     0.5                                                     0.5
                                       SR=0.3
                                       SR=0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                   0        5      10      15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03                  Monte-Carlo Simulation        F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                   0        5      10      15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                   0        5      10      15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                      2                                                      2                                                      2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                            Statistical Model   F
                                                                                               =0.05                            Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1

       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                   0        5      10      15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03                  Monte-Carlo Simulation        F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1

       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                   0        5      10      15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1

       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                   0        5      10      15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20




Figure 6: ğ‘ = 370, ğ‘‡ = 650: Correlations and Sharpe-ratios as a function of the RP-weight ğ›¾ for diï¬€erent variances and
Sharpe-ratios. The residuals have cross-sectional correlation deï¬ned by the band-diagonal matrix.




                                                                                                                                        24
                                      2                                                     2                                                       2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                           Statistical Model   F
                                                                                              =0.05                             Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1
        1                                                      1                                                      1                                                       1                                                       1

                                       SR=0.8
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                             SR=0.5                 0.5                                                    0.5                                                     0.5                                                     0.5
                                       SR=0.3
                                       SR=0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03              Monte-Carlo Simulation            F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                      2                                                     2                                                       2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                           Statistical Model   F
                                                                                              =0.05                             Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1
       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03              Monte-Carlo Simulation            F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1
       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1
       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20




Figure 7: ğ‘ = 370, ğ‘‡ = 650: Correlations and Sharpe-ratios as a function of the RP-weight ğ›¾ for diï¬€erent variances and
Sharpe-ratios. The residuals have the empirical residual correlation matrix.



7. Empirical Application

             We apply our estimator to a large number of anomaly sorted portfolios. The same data is studied
in more detail in our companion paper Lettau and Pelger (2018). Based on the universe of U.S. ï¬rms in
CRSP, we consider 37 anomaly characteristics following standard deï¬nitions in Novy-Marx and Velikov
(2016), McLean and Pontiï¬€ (2016) and Kogan and Tian (2015). We use the same data set as Kozak,
Nagel and Santosh (2017)22 who have sorted the stock returns in yearly rebalanced decile portfolios.
This gives us a total cross-section of ğ‘ = 370 portfolios of monthly returns from 07/1963 to 12/2017
(T=650).23 The risk-free rate to obtain excess returns is from Kenneth Frenchâ€™s website. We estimate
statistical factors for diï¬€erent choices of ğ›¾ and evaluate the maximum Sharpe-ratio, average pricing
error and explained variation in- and out-of-sample.
             Table 1 reports the results for ğ¾ = 3 and ğ¾ = 5 factors for RP-PCA with ğ›¾ = 10 and PCA (ğ›¾ = âˆ’1).
ğ‘†ğ‘… denotes the maximum Sharpe-ratio that can be obtained by a linear combination of the factors, i.e.

       22
    We thank the authors for sharing the data.
       23
    Kozak, Nagel and Santosh (2017) create a data set based on 50 anomalies, but 13 of these anomalies are only available
for a signiï¬cantly shorter time horizon. We choose only those anomalies that are available for the whole time horizon of
ğ‘‡ = 650 observations.


                                                                                                                                        25
it combines the factors with the weights Î£âˆ’1
                                          ğ¹ ğœ‡ğ¹ . It measures how well the factors can approximate the
                                                                                               1   ğ‘
stochastic discount factor. The root-mean-squared pricing error (ğ‘…ğ‘€ğ‘†ğ›¼) equals âˆš ğ‘ âˆ‘ğ‘–=1 ğ›¼ğ‘–2 , where
the pricing error ğ›¼ğ‘– is the intercept of a time-series regression of the excess return of asset ğ‘– on the
factors. The idiosyncratic variation is the average variance of the residuals after regressing out the
factors. The in-sample analysis is based on the whole time horizon of ğ‘‡ = 650 months. The out-
of-sample analysis estimates the loadings with a rolling window of 20 years (ğ‘‡ = 240). With these
estimated loadings including information up to time ğ‘¡ we predict the systematic return and obtain
a pricing error out-of-sample at ğ‘¡ + 1. This corresponds to a cross-sectional pricing regression with
out-of-sample loadings. The mean and variance of the out-of-sample errors are used to calculate the
average pricing error and the idiosyncratic variation. We use the optimal portfolio weights for the
maximum Sharpe-ratio portfolio estimated in the rolling window period to create an out-of-sample
optimal return giving us the maximum Sharpe-ratio portfolio out-of-sample.



                                              In-sample                     Out-of-sample
                                       SR    RMS ğ›¼ Idio. Var.         SR     RMS ğ›¼ Idio. Var.
                RP-PCA 3 factors      0.23     0.17      12.75%      0.18     0.15      14.57%
                   PCA 3 factors      0.17     0.17      12.68%      0.14     0.15      14.66%

                RP-PCA 5 factors      0.53     0.14      10.76%      0.45     0.12      12.70%
                   PCA 5 factors      0.24     0.14      10.66%      0.17     0.14      12.56%

Table 1: Maximal Sharpe-ratios, root-mean-squared pricing errors and idiosyncratic variation for diï¬€erent number of
factors. RP-weight ğ›¾ = 10.


   RP-PCA and PCA diï¬€er the most in terms of the maximum Sharpe-ratio. For ğ¾ = 5 factors the
in- and out-of-sample Sharpe-ratio of RP-PCA is twice as large as for PCA. For ğ¾ = 3 factors there
is still a sizeable diï¬€erence in Sharpe-ratios, but it is less pronounced than for a larger number of
factors. A possible reason is that the 4th or 5th factor is weak with a high Sharpe-ratio and only
picked up by RP-PCA, while the ï¬rst four factors are stronger and hence can be detected by PCA.
Surprisingly, the pricing errors and the unexplained variation are very close for the two methods.
Only the out-of-sample pricing error of RP-PCA is smaller than for PCA. It seems that RP-PCA selects
high Sharpe-ratio factors with smaller out-of-sample pricing errors without sacriï¬cing explanatory
power for the variation.


   Figure 8 analyzes the eï¬€ect of ğ›¾ and the number of factors on the three criteria maximum Sharpe-
ratio, pricing error and variation. The Sharpe-ratio and pricing error change signiï¬cantly when includ-
ing the 5th factor. This 5th factor is also strongly aï¬€ected by the choice of ğ›¾ and seems to require
ğ›¾ > 5 to be detected by RP-PCA. Adding the 6th factor has only a very minor eï¬€ect on the three cri-
teria. That is why we opt for a 5-factor model. The ï¬gure illustrates that the amount of unexplained
variation is insensitive to the choice of ğ›¾. Hence, our factors capture more pricing information while
explaining the same amount of variation in the data.
   Table 2 shows that the variance signal for diï¬€erent factors suggests the existence of weak factors.
Here we extract the ï¬rst 6 factors with RP-PCA (ğ›¾ = 10) and PCA. In addition, we include the pop-

                                                        26
                                   SR (In-sample)                                                           SR (Out-of-sample)

             0.6                                                                         0.6


             0.4                                                                         0.4
SR




                                                                             SR
             0.2                                                                         0.2


              0                                                                           0
                   0          5          10           15           20                          0           5          10         15          20

                                  RMS   (In-sample)                                                       RMS     (Out-of-sample)
             0.4                                                                         0.4

             0.3                                                                         0.3

             0.2                                                                         0.2

             0.1                                                                         0.1

              0                                                                           0
                   0          5          10           15           20                          0           5          10         15          20

                        Idiosyncratic Variation (In-sample)                                        Idiosyncratic Variation (Out-of-sample)


             15                                                                          15
 Variation




                                                                             Variation
                                                           1 factor
             10                                            2 factors                     10
                                                           3 factors
                                                           4 factors
              5                                            5 factors                      5
                                                           6 factors
              0                                                                           0
                   0          5          10           15           20                          0           5          10         15          20




Figure 8: Deciles of 37 single-sorted portfolios from 07/1963 to 12/2016 (ğ‘ = 370 and ğ‘‡ = 650): Maximal Sharpe-ratios,
root-mean-squared pricing errors and unexplained idiosyncratic variation for diï¬€erent values of ğ›¾.


ular Fama-French 5 factors (marke, size, value, proï¬tability and investment) from Kenneth Frenchâ€™s
website. The variance signal is deï¬ned as the largest eigenvalues of Î›Î£ğ¹ Î›âŠ¤ . We normalize these
                                                           1      ğ‘
eigenvalue by the same constant ğœğ‘’2 =                      ğ‘
                                                                     2
                                                               âˆ‘ğ‘–=1 ğœğ‘’,ğ‘– based on the residuals from 6 PCA factors.24 This
makes the variance signals comparable to our simulation design. The 5th factor has a variance signal
around 0.05 which based on our simulation is well described by a weak factor model. The simu-
lations also predict that these weak factors can be better estimated by RP-PCA if they have a large
Sharpe-ratio. This is exactly what we observe in the data.
                                                                                               1     1
             The left plot in Figure 9 shows the eigenvalues of the matrix                     ğ‘
                                                                                                   ( ğ‘‡ ğ‘‹âŠ¤ ğ‘‹ + ğ›¾ğ‘‹Ì„ğ‘‹Ì„âŠ¤ ) normalized by the
average idiosyncratic variance. Our weak factor model predicts that the signal of this matrix should
be larger for RP-PCA compared to PCA. The eigenvalue curves conï¬rm that the signal for the weaker
factors clearly separates from the PCA signal. ğ›¾ = 10 seems to be suï¬ƒcient for strengthening the
signal. The right plot in Figure 9 normalizes the eigenvalues by the corresponding PCA eigenvalues.
In particular the signal for the 6th factor is strengthened.

   24
             The results do not change if we regress out more PCA or RP-PCA factors and are available upon request.


                                                                        27
                                                                  PCA         RP-PCA (ğ›¾ = 10)                                   FF5
                                                           ğœ12    8.05                   8.05                                   8.00
                                                           ğœ22    0.27                   0.27                                   0.21
                                                           ğœ32    0.21                   0.21                                   0.17
                                                           ğœ42    0.14                   0.14                                   0.03
                                                           ğœ52    0.05                   0.05                                   0.02
                                                           ğœ62    0.03                   0.04                                   0.00

Table 2: Deciles of 37 single-sorted portfolios: Variance signal for diï¬€erent factors: Largest eigenvalues of Î›Î£ğ¹ Î›âŠ¤ normal-
                                                  1   ğ‘
ized by the average idiosyncratic variance ğœğ‘’2 = ğ‘ âˆ‘ğ‘–=1 ğœğ‘’,ğ‘–
                                                           2
                                                             .




                                             Eigenvalues                                                                                   Eigenvalues

                                                                        =-1                                           1.5                                      =0
                         0.25
                                                                        =0                                                                                     =1
                                                                        =1                                                                                     =5
Normalized Eigenvalues




                                                                                             Normalized Eigenvalues
                                                                        =5                                            1.4                                      =10
                          0.2
                                                                        =10                                                                                    =20
                                                                        =20
                                                                                                                      1.3
                         0.15


                          0.1                                                                                         1.2


                         0.05                                                                                         1.1


                           0                                                                                           1
                                2   4    6      8    10      12     14         16                                           2      4   6      8    10    12   14     16
                                               Number                                                                                        Number



Figure 9: Deciles of 37 single-sorted portfolios from 07/1963 to 12/2016 (ğ‘ = 370 and ğ‘‡ = 650): Largest normalized
                           1   1
eigenvalues of the matrix ğ‘ ( ğ‘‡ ğ‘‹âŠ¤ ğ‘‹ + ğ›¾ğ‘‹Ì„ğ‘‹Ì„âŠ¤ ) for diï¬€erent RP-weights ğ›¾. Left plot: Eigenvalues are normalized by di-
                                                                                    1    ğ‘
vision through the average idiosyncratic variance ğœğ‘’2 = ğ‘ âˆ‘ğ‘–=1 ğœğ‘’,ğ‘–
                                                                  2
                                                                    estimated by the average of the non-systematic PCA
eigenvalues. Right plot: Eigenvalues are normalized by the corresponding PCA (ğ›¾ = âˆ’1) eigenvalues.




8. Conclusion

                          We develop a new estimator for latent asset pricing factors from large data sets. Our estimator
is essentially a regularized version of PCA that puts a penalty on the pricing error. We derive the
asymptotic distribution theory under weak and strong factor model assumptions and show that our
estimator RP-PCA strongly dominates conventional PCA. We can detect weak factors with high Sharpe-
ratios which are undetectable with PCA. Strong factors are estimated more eï¬ƒciently with RP-PCA
compared to PCA.




                                                                                        28
Appendix A. Simulation

Appendix A.1. Multi-Factor Model



        1. Factor Corr. (IS) for 2F =0.03          1. Factor Corr. (OOS) for 2F =0.03         1. Factor Corr. (IS) for 2F =0.1           1. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                                         0.6
       0.4                                         0.4                                      0.4                                         0.4
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20


        2. Factor Corr. (IS) for 2F =0.03          2. Factor Corr. (OOS) for 2F =0.03         2. Factor Corr. (IS) for 2F =0.1           2. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                                         0.6
       0.4                                         0.4                                      0.4                                         0.4
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20


        3. Factor Corr. (IS) for 2F =0.03          3. Factor Corr. (OOS) for 2F =0.03         3. Factor Corr. (IS) for 2F =0.1           3. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                                         0.6
       0.4                                         0.4                                      0.4                                         0.4
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20


        4. Factor Corr. (IS) for 2F =0.03          4. Factor Corr. (OOS) for 2F =0.03         4. Factor Corr. (IS) for 2F =0.1           4. Factor Corr. (OOS) for 2F =0.1

       0.8                                         0.8                                      0.8                                         0.8
                                                                                                                   SR=0.8
Corr




                                            Corr




                                                                                     Corr




                                                                                                                                 Corr
       0.6                                         0.6                                      0.6                    SR=0.5               0.6
       0.4                                         0.4                                      0.4                    SR=0.3               0.4
                                                                                                                   SR=0.2
       0.2                                         0.2                                      0.2                                         0.2
             0   5      10     15     20                 0   5     10     15    20                0   5      10     15      20                0   5      10    15     20




Figure A.10: ğ‘ = 74, ğ‘‡ = 650: Correlation of estimated rotated factors with true factors in-sample and out-of-sample for
diï¬€erent variances and Sharpe-ratios of the fourth factor and for diï¬€erent RP-weights ğ›¾.




                                                                                  29
           1. Factor SR (IS) for 2F =0.03         1. Factor SR (OOS) for 2F =0.03              1. Factor SR (IS) for 2F =0.1           1. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
                                                                                                                  SR=0.8
     0.6                                         0.6                                     0.6                                         0.6
                                                                                                                  SR=0.5
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                      SR=0.3             0.4
                                                                                                                  SR=0.2
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20


           2. Factor SR (IS) for 2F =0.03         2. Factor SR (OOS) for 2F =0.03              2. Factor SR (IS) for 2F =0.1           2. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
     0.6                                         0.6                                     0.6                                         0.6
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                                         0.4
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20


           3. Factor SR (IS) for 2F =0.03         3. Factor SR (OOS) for 2F =0.03              3. Factor SR (IS) for 2F =0.1           3. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
     0.6                                         0.6                                     0.6                                         0.6
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                                         0.4
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20


           4. Factor SR (IS) for 2F =0.03         4. Factor SR (OOS) for 2F =0.03              4. Factor SR (IS) for 2F =0.1           4. Factor SR (OOS) for 2F =0.1
     0.8                                         0.8                                     0.8                                         0.8
     0.6                                         0.6                                     0.6                                         0.6
SR




                                            SR




                                                                                    SR




                                                                                                                                SR
     0.4                                         0.4                                     0.4                                         0.4
     0.2                                         0.2                                     0.2                                         0.2
      0                                           0                                       0                                           0
            0      5     10     15     20              0   5     10    15     20               0      5     10     15      20              0   5     10     15    20




Figure A.11: ğ‘ = 74, ğ‘‡ = 650: Sharpe ratios of estimated rotated factors in-sample and out-of-sample for diï¬€erent
variances and Sharpe-ratios of the fourth factor and for diï¬€erent RP-weights ğ›¾.




                                                                               30
Appendix A.2. Single-Factor Model with ğ‘ = 74 and ğ‘‡ = 650


                                      2                                                     2                                                       2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                           Statistical Model   F
                                                                                              =0.05                             Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1
        1                                                      1                                                      1                                                       1                                                       1

                                       SR=0.8
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                             SR=0.5                 0.5                                                    0.5                                                     0.5                                                     0.5
                                       SR=0.3
                                       SR=0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03              Monte-Carlo Simulation            F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                      2                                                     2                                                       2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                           Statistical Model   F
                                                                                              =0.05                             Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1
       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03              Monte-Carlo Simulation            F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1
       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1
       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20




Figure A.12: ğ‘ = 74, ğ‘‡ = 650: Correlations and Sharpe-ratios as a function of the RP-weight ğ›¾ for diï¬€erent variances and
Sharpe-ratios.




                                                                                                                                        31
Appendix A.3. Single-Factor Model with ğ‘ = 25 and ğ‘‡ = 240


                                      2                                                     2                                                       2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                           Statistical Model   F
                                                                                              =0.05                             Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1
        1                                                      1                                                      1                                                       1                                                       1

                                       SR=0.8
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                             SR=0.5                 0.5                                                    0.5                                                     0.5                                                     0.5
                                       SR=0.3
                                       SR=0.2
        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03              Monte-Carlo Simulation            F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1
        1                                                      1                                                      1                                                       1                                                       1
Corr




                                                       Corr




                                                                                                              Corr




                                                                                                                                                                      Corr




                                                                                                                                                                                                                              Corr
       0.5                                                    0.5                                                    0.5                                                     0.5                                                     0.5


        0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                      2                                                     2                                                       2                                                       2                                                      2
                  Statistical Model   F
                                        =0.03                           Statistical Model   F
                                                                                              =0.05                             Statistical Model   F
                                                                                                                                                      =0.1                              Statistical Model   F
                                                                                                                                                                                                              =0.3                             Statistical Model   F
                                                                                                                                                                                                                                                                     =1

       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
         0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                           2                                                      2                                                      2                                                       2                                                        2
             Monte-Carlo Simulation        F
                                             =0.03              Monte-Carlo Simulation            F
                                                                                                    =0.05                  Monte-Carlo Simulation        F
                                                                                                                                                           =0.1                    Monte-Carlo Simulation        F
                                                                                                                                                                                                                   =0.3                    Monte-Carlo Simulation         F
                                                                                                                                                                                                                                                                            =1

       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
         0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20

                                             2                                                      2                                                        2                                                       2                                                       2
       Monte-Carlo Simulation OOS            F
                                               =0.03          Monte-Carlo Simulation OOS            F
                                                                                                      =0.05          Monte-Carlo Simulation OOS              F
                                                                                                                                                               =0.1          Monte-Carlo Simulation OOS              F
                                                                                                                                                                                                                       =0.3           Monte-Carlo Simulation OOS             F
                                                                                                                                                                                                                                                                               =1

       0.8                                                    0.8                                                    0.8                                                     0.8                                                     0.8
       0.6                                                    0.6                                                    0.6                                                     0.6                                                     0.6
SR




                                                       SR




                                                                                                              SR




                                                                                                                                                                      SR




                                                                                                                                                                                                                              SR
       0.4                                                    0.4                                                    0.4                                                     0.4                                                     0.4
       0.2                                                    0.2                                                    0.2                                                     0.2                                                     0.2
         0                                                      0                                                      0                                                       0                                                       0
              0        5      10      15        20                  0        5      10       15        20                   0       5      10       15        20                    0       5      10       15        20                   0       5      10       15        20




Figure A.13: ğ‘ = 25, ğ‘‡ = 240: Correlations and Sharpe-ratios as a function of the RP-weight ğ›¾ for diï¬€erent variances and
Sharpe-ratios.




                                                                                                                                        32
Appendix A.4. Pricing Errors for Single-Factor Model


                                 2                                               2                                                2                                               2                                               2
            Pricing Error (IS)   F
                                   =0.03                    Pricing Error (IS)   F
                                                                                   =0.05                     Pricing Error (IS)   F
                                                                                                                                    =0.1                     Pricing Error (IS)   F
                                                                                                                                                                                    =0.3                     Pricing Error (IS)   F
                                                                                                                                                                                                                                    =1
 0.14                                            0.14                                            0.14                                            0.14                                            0.14
                                  SR=0.8                                          SR=0.8                                          SR=0.8                                          SR=0.8                                          SR=0.8
 0.12                             SR=0.5
                                                 0.12                             SR=0.5
                                                                                                 0.12                             SR=0.5
                                                                                                                                                 0.12                             SR=0.5
                                                                                                                                                                                                 0.12                             SR=0.5
                                  SR=0.3                                          SR=0.3                                          SR=0.3                                          SR=0.3                                          SR=0.3
  0.1                                             0.1                                             0.1                                             0.1                                             0.1
                                  SR=0.2                                          SR=0.2                                          SR=0.2                                          SR=0.2                                          SR=0.2
 0.08                                            0.08                                            0.08                                            0.08                                            0.08

 0.06                                            0.06                                            0.06                                            0.06                                            0.06

 0.04                                            0.04                                            0.04                                            0.04                                            0.04

 0.02                                            0.02                                            0.02                                            0.02                                            0.02

   0                                               0                                               0                                               0                                               0

        0        5      10       15         20          0        5       10       15        20          0         5        10     15        20          0         5      10       15        20          0        5      10        15       20



                                  2                                               2                                                2                                               2                                               2
        Pricing Error (OOS)       F
                                    =0.03               Pricing Error (OOS)       F
                                                                                    =0.05                   Pricing Error (OOS)    F
                                                                                                                                     =0.1                   Pricing Error (OOS)    F
                                                                                                                                                                                     =0.3                   Pricing Error (OOS)    F
                                                                                                                                                                                                                                     =1
 0.14                                            0.14                                            0.14                                            0.14                                            0.14

 0.12                                            0.12                                            0.12                                            0.12                                            0.12

  0.1                                             0.1                                             0.1                                             0.1                                             0.1

 0.08                                            0.08                                            0.08                                            0.08                                            0.08

 0.06                                            0.06                                            0.06                                            0.06                                            0.06

 0.04                                            0.04                                            0.04                                            0.04                                            0.04

 0.02                                            0.02                                            0.02                                            0.02                                            0.02

   0                                               0                                               0                                               0                                               0

        0        5      10       15         20          0        5       10       15        20          0         5        10     15        20          0         5      10       15        20          0        5      10        15       20




Figure A.14: ğ‘ = 370, ğ‘‡ = 650: Root-mean-squared pricing errors as a function of the RP-weight ğ›¾ for diï¬€erent variances
and Sharpe-ratios.




                                 2                                               2                                                2                                               2                                               2
            Pricing Error (IS)   F
                                   =0.03                    Pricing Error (IS)   F
                                                                                   =0.05                     Pricing Error (IS)   F
                                                                                                                                    =0.1                     Pricing Error (IS)   F
                                                                                                                                                                                    =0.3                     Pricing Error (IS)   F
                                                                                                                                                                                                                                    =1

 0.15                             SR=0.8         0.15                             SR=0.8         0.15                             SR=0.8         0.15                             SR=0.8         0.15                             SR=0.8
                                  SR=0.5                                          SR=0.5                                          SR=0.5                                          SR=0.5                                          SR=0.5
                                  SR=0.3                                          SR=0.3                                          SR=0.3                                          SR=0.3                                          SR=0.3
                                  SR=0.2                                          SR=0.2                                          SR=0.2                                          SR=0.2                                          SR=0.2
  0.1                                             0.1                                             0.1                                             0.1                                             0.1



 0.05                                            0.05                                            0.05                                            0.05                                            0.05



   0                                               0                                               0                                               0                                               0

        0        5      10       15         20          0        5       10       15        20          0         5        10     15        20          0         5      10       15        20          0        5      10        15       20


                                  2                                               2                                                2                                               2                                               2
        Pricing Error (OOS)       F
                                    =0.03               Pricing Error (OOS)       F
                                                                                    =0.05                   Pricing Error (OOS)    F
                                                                                                                                     =0.1                   Pricing Error (OOS)    F
                                                                                                                                                                                     =0.3                   Pricing Error (OOS)    F
                                                                                                                                                                                                                                     =1

 0.15                                            0.15                                            0.15                                            0.15                                            0.15



  0.1                                             0.1                                             0.1                                             0.1                                             0.1



 0.05                                            0.05                                            0.05                                            0.05                                            0.05



   0                                               0                                               0                                               0                                               0

        0        5      10       15         20          0        5       10       15        20          0         5        10     15        20          0         5      10       15        20          0        5      10        15       20




Figure A.15: ğ‘ = 74, ğ‘‡ = 650: Root-mean-squared pricing errors as a function of the RP-weight ğ›¾ for diï¬€erent variances
and Sharpe-ratios.




                                                                                                                      33
             Pricing Error (IS) 2F =0.03                       Pricing Error (IS) 2F =0.05                      Pricing Error (IS) 2F =0.1                        Pricing Error (IS) 2F =0.3                      Pricing Error (IS) 2F =1
 0.25                                            0.25                                               0.25                                              0.25                                            0.25
                                  SR=0.8                                            SR=0.8                                          SR=0.8                                            SR=0.8                                         SR=0.8
                                  SR=0.5                                            SR=0.5                                          SR=0.5                                            SR=0.5                                         SR=0.5
  0.2                             SR=0.3            0.2                             SR=0.3           0.2                            SR=0.3             0.2                            SR=0.3           0.2                           SR=0.3
                                  SR=0.2                                            SR=0.2                                          SR=0.2                                            SR=0.2                                         SR=0.2
 0.15                                            0.15                                               0.15                                              0.15                                            0.15


  0.1                                               0.1                                              0.1                                               0.1                                             0.1


 0.05                                            0.05                                               0.05                                              0.05                                            0.05



        0       10    20    30     40      50             0       10    20    30     40       50           0        10   20    30    40      50              0      10    20     30    40       50           0     10    20     30    40      50



            Pricing Error (OOS) 2F =0.03                      Pricing Error (OOS) 2F =0.05                     Pricing Error (OOS) 2F =0.1                       Pricing Error (OOS) 2F =0.3                     Pricing Error (OOS) 2F =1
 0.25                                            0.25                                               0.25                                              0.25                                            0.25


  0.2                                               0.2                                              0.2                                               0.2                                             0.2


 0.15                                            0.15                                               0.15                                              0.15                                            0.15


  0.1                                               0.1                                              0.1                                               0.1                                             0.1


 0.05                                            0.05                                               0.05                                              0.05                                            0.05



        0       10    20    30     40      50             0       10    20    30     40       50           0        10   20    30    40      50              0      10    20     30    40       50           0     10    20     30    40      50




Figure A.16: ğ‘ = 25, ğ‘‡ = 240: Root-mean-squared pricing errors as a function of the RP-weight ğ›¾ for diï¬€erent variances
and Sharpe-ratios.


Appendix B. Proofs for the Weak Factor Model

        We only prove the statements for RP-PCA. The statements for the conventional PCA based on the
covariance matrix are a special case. Given an ğ‘ Ã— ğ‘ matrix ğ´ we denote the sorted eigenvalues by
ğœ†1 (ğ´) â‰¥ ... â‰¥ ğœ†ğ‘ (ğ´). Let ğœ™ğ´ (ğ‘§) be the empirical eigenvalue distribution, i.e. the probability measure
                                                1         ğ‘
deï¬ned as ğœ™ğ´ (ğ‘§) =                              ğ‘
                                                    âˆ‘ğ‘–=1 ğ›¿ğœ†ğ‘– (ğ´) where ğ›¿ğ‘¥ is the Dirac measure. In our case the probability measure
                                                                                                                                                                                               ğ‘
ğœ™ğ´ converges almost surely weakly for ğ‘‡ â†’ âˆ (and therefore also ğ‘ â†’ âˆ as                                                                                                                       ğ‘‡
                                                                                                                                                                                                     â†’ ğ‘ > 0 and ğ‘ and
ğ‘‡ are asymptotically proportional).
Proof of Theorem 2:
Instead of using
                                        1 âŠ¤
                                        ğ‘‡
                                          ğ‘‹ ğ‘Š2 ğ‘‹                  we study
                                                                                       1
                                                                                       ğ‘‡
                                                                                         ğ‘Šğ‘‹ğ‘‹âŠ¤ ğ‘Š                      with ğ‘Š = ğ¼ğ‘‡ +
                                                                                                                                                       ğ›¾Ìƒ
                                                                                                                                                       ğ‘‡
                                                                                                                                                             11âŠ¤ and ğ›¾Ìƒ = âˆšğ›¾ + 1 âˆ’ 1.                                    Deï¬ne the
orthonormal matrix ğ‘ˆ = (ğ‘ˆ1 , ğ‘ˆ2 ) consisting of the ğ‘‡ Ã— ğ¾ + 1 matrix ğ‘ˆ1 and the ğ‘‡ Ã— ğ‘‡ âˆ’ ğ¾ âˆ’ 1 matrix
ğ‘ˆ2 by


                                                                                                                1         (ğ¹âŠ¤ (ğ¼ğ‘‡ âˆ’
                                                                                                                                                  1
                                                                                                                                                      11âŠ¤ )ğ¹)âˆ’1/2                     0
                                                ğ‘ˆ1 = ((ğ¼ğ‘‡ âˆ’
                                                                               1
                                                                               ğ‘‡
                                                                                   11     âŠ¤
                                                                                              )
                                                                                                    ğ¹
                                                                                                   âˆšğ‘‡          âˆšğ‘‡
                                                                                                                  )â›                              ğ‘‡                                    â ğ‘ˆ,Ìƒ
                                                                                                                   â                              0                                   1â 

where the ğ¾ + 1 Ã— ğ¾ + 1 matrix ğ‘ˆÌƒ consists of the orthonormal eigenvectors of the â€œsignal matrixâ€
ğ‘€RP-PCA :

                                                                                           ğœƒ1           1/2                                                                    â‹¯            0
                                                               Î£ğ¹ + ğ‘ğœğ‘’2                 â›
                                                                                         âœ          Î£ğ¹ ğœ‡ğ¹ (1 + ğ›¾)
                                                                                                                Ìƒ                                                                      â
                                            ÌƒâŠ¤
                                           ğ‘ˆ â› âŠ¤ 1/2                              â ğ‘ˆÌƒ = âœ â‹®
                                                                                         âœ                                                                                     â‹±  â‹® âŸ  âŸ
                                                                                                                                                                                       âŸ
                                             âğœ‡ğ¹ Î£ğ¹ (1 + ğ›¾)
                                                          Ìƒ (1 + ğ›¾)(ğœ‡ğ¹âŠ¤ ğœ‡ + ğ‘ğœ22 )â 
                                                                                         â0                                                                                    â‹¯ ğœƒğ¾+1 .â 

ğ‘ˆ2 are orthonormal vectors orthogonal to ğ‘ˆ1 , i.e. ğ‘ˆ1âŠ¤ ğ‘ˆ2 = 0 and ğ‘ˆ2âŠ¤ ğ‘ˆ2 = ğ¼ğ‘‡âˆ’ğ¾âˆ’1 .




                                                                                                                         34
                                                   1 âŠ¤                                                             1
   We now analyze the spectrum of ğ‘† âˆ¶=             ğ‘‡
                                                     ğ‘ˆ ğ‘Šğ‘‹ğ‘‹âŠ¤ ğ‘Šğ‘ˆ,          which has the same eigenvalues as ğ‘‡ ğ‘‹âŠ¤ ğ‘Š2 ğ‘‹.

                                  1                                                 1 âŠ¤
             ğ‘†11        ğ‘†12           ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ + ğ‘’)(ğ¹Î›âŠ¤ + ğ‘’)âŠ¤ ğ‘Šğ‘ˆ1                   ğ‘ˆ ğ‘Š(ğ¹Î›âŠ¤ + ğ‘’)ğ‘’âŠ¤ ğ‘Šğ‘ˆ2
                                                                                    ğ‘‡ 1
         ğ‘†=â›                â = â›ğ‘‡        1 âŠ¤                                           1 âŠ¤
                                                                                                        â.
           âğ‘†21         ğ‘†22 â  â            ğ‘ˆ ğ‘Šğ‘’(Î›ğ¹âŠ¤
                                          ğ‘‡ 2
                                                              + ğ‘’)ğ‘Šğ‘ˆ1                    ğ‘ˆ ğ‘Šğ‘’ğ‘’âŠ¤ ğ‘Šğ‘ˆ2
                                                                                        ğ‘‡ 2             â 

An eigenvalue of ğ‘† that is not an eigenvalue of ğ‘†22 satisï¬es

                         0 = det(ğœ†ğ¼ğ‘‡ âˆ’ ğ‘†) = det(ğœ†ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’ ğ‘†22 )det(ğœ†ğ¼ğ¾+1 âˆ’ ğœ…ğ‘‡ (ğœ†))

with

                                      ğœ…ğ‘‡ (ğœ†) = ğ‘†11 + ğ‘†12 (ğœ†ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’ ğ‘†22 )âˆ’1 ğ‘†21 .

For suï¬ƒciently large ğ‘‡ it holds det(ğœ†ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’ ğ‘†22 ) â‰  0 for the ï¬rst ğ¾ + 1 eigenvalues. Therefore the
ï¬rst ğ¾ + 1 eigenvalues satisfy

                                               det(ğœ†ğ¼ğ¾+1 âˆ’ ğœ…ğ‘‡ (ğœ†)) = 0.

We want to study the limiting behavior of ğœ…ğ‘‡ (ğœ†) for ğ‘‡ â†’ âˆ.

                                                                                                        âˆ’1
                   1                                   1                            1
        ğœ…ğ‘‡ (ğœ†) =       (ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ + ğ‘’)) (ğ¼ğ‘ +               ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 (ğœ†ğ‘‡âˆ’ğ¾âˆ’1 âˆ’            ğ‘ˆ2âŠ¤ ğ‘Šğ‘’ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 )       ğ‘ˆ2âŠ¤ ğ‘’ğ‘Š)
                   ğ‘‡                                   ğ‘‡                            ğ‘‡
                                           âŠ¤
                   â‹… (ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ + ğ‘’))
                                                                              âˆ’1
                   ğœ†                                    1                                               âŠ¤
               =       (ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ + ğ‘’)) (ğœ†ğ‘ âˆ’               ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’)         (ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ + ğ‘’)) ,
                   ğ‘‡                                   ğ‘‡

where we have used the identify that for ğœ† â‰  0 which is not an eigenvalue of ğ´âŠ¤ ğ´ it holds ğ¼ğ‘‡ +ğ´(ğœ†ğ¼ğ‘ âˆ’
ğ´âŠ¤ ğ´)âˆ’1 ğ´âŠ¤ = ğœ†(ğœ†ğ¼ğ‘ âˆ’ ğ´ğ´âŠ¤ )âˆ’1 .
                                                                               ğ‘–.ğ‘–.ğ‘‘.
   Because of the orthonormality we have ğ‘ˆ2 ğ‘’ =âˆ¶ ğ‘’ Ìƒ with ğ‘’ğ‘¡Ìƒ âˆ¼ ğ‘(0, Î£). Note that ğ‘ˆ2 ğ‘Š = ğ‘ˆ2 by
construction. For any matrix ğ¶ independent of ğ‘ˆ1âŠ¤ ğ‘Šğ‘’ we have

                       ğ¸ [ğ‘ˆ1âŠ¤ ğ‘Šğ‘’ğ¶ğ‘’âŠ¤ ğ‘Šğ‘ˆ1 ] = trace(Î£) â‹… trace(ğ¶) â‹… ğ‘ˆ1âŠ¤ ğ‘Šğ‘ˆ1

                                                                              ğ¼ğ¾              0
                                               = trace(Î£) â‹… trace(ğ¶) â‹… ğ‘ˆÌƒ âŠ¤ â›                    â ğ‘ˆ.Ìƒ
                                                                            â0              1 + ğ›¾â 

By the law of large numbers and Lemma A.2 in Benaych-Georges and Nadakuditi (2011) it holds ï¬rst

                                                                         âˆ’1
                   ğœ†                               1                                           âŠ¤
                       (ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ )) (ğœ†ğ¼ğ‘ âˆ’            ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’)         (ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ ))
                   ğ‘‡                               ğ‘‡
                                                                                             âˆ’1
                        1                      1                     1
               =ğœ† (         ğ‘ˆ1âŠ¤ ğ‘Šğ¹ğ¹âŠ¤ ğ‘Šğ‘ˆ1 )         trace ((ğœ†ğ¼ğ‘ âˆ’         ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’)           ) + ğ‘œğ‘ (1),
                        ğ‘‡                      ğ‘                     ğ‘‡




                                                              35
second
                                                                            âˆ’1
                    ğœ†                          1                                             âŠ¤
                        (ğ‘ˆ1âŠ¤ ğ‘’)) (ğœ†ğ¼ğ‘ âˆ’            ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’)                (ğ‘ˆ1âŠ¤ ğ‘Šğ‘’)
                    ğ‘‡                      ğ‘‡
                                                                                                               âˆ’1
                                       trace(Î£) ğ‘ 1                                      1
                 =ğœ† (ğ‘ˆ1âŠ¤ ğ‘Šğ‘ˆ1 ) â‹…                                   trace ((ğœ†ğ¼ğ‘ âˆ’             ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’)         ) + ğ‘œğ‘ (1)
                                              ğ‘         ğ‘‡ğ‘                               ğ‘‡

and last but not least
                                                                                          âˆ’1
                         ğœ†                                      1                                         âŠ¤
                             (ğ‘ˆ1âŠ¤ ğ‘Š(ğ¹Î›âŠ¤ )) (ğœ†ğ¼ğ‘ âˆ’                      ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’)          (ğ‘ˆ1âŠ¤ ğ‘Šğ‘’)) = ğ‘œğ‘ (1).
                        ğ‘‡                                       ğ‘‡
             1
Note that   âˆšğ‘
               ğœ–âŠ¤   has orthogonally invariant column vectors by the properties of the normal distribution
and Lemma A.2 in Benaych-Georges and Nadakuditi (2011) applies. In summary the limit value of ğœ…ğ‘‡
is described by

                                                                   1/2
                                   Î£ğ¹       Î£ğ¹ ğœ‡ğ¹ (1 + ğ›¾)Ìƒ    ğ‘ â‹… trace(Î£) ğ¼ğ¾                                           0
              ğœ…ğ‘‡ (ğœ†) =ğœ†ğ‘ˆÌƒ âŠ¤ â›â› âŠ¤ 1/2          âŠ¤
                                                           â+             â›                                                 ââ ğ‘ˆÌƒ
                            ââğœ‡ğ¹ Î£ğ¹ (1 + ğ›¾)
                                          Ìƒ ğœ‡ğ¹ ğœ‡ğ¹ (1 + ğ›¾) â          ğ‘     â0                                          1 + ğ›¾ â â 
                                                                                  âˆ’1
                             1                         1
                         â‹…       trace ((ğœ†ğ‘ âˆ’              ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’)              ) + ğ‘œğ‘ (1).
                             ğ‘                         ğ‘‡

                                     ğ‘–.ğ‘–.ğ‘‘.
As ğ‘ˆ2 ğ‘Šğ‘’ = ğ‘ˆ2 ğ‘’ = ğ‘’ Ìƒ with ğ‘’ğ‘¡Ìƒ âˆ¼ ğ‘(0, Î£) for ğ‘¡ = 1, ..., ğ‘‡ âˆ’ ğ¾ âˆ’ 1 we have

                                                           ğ‘
                                              ğœ…ğ‘‡ (ğœ†) â†’ ğœ…(ğœ†) = ğœ†ğ‘ˆÌƒ âŠ¤ ğ‘€RP-PCA ğ‘ˆğº(ğœ†).
                                                                             Ìƒ


                                 ğœƒ1                 â‹¯          0
                               â›
                               âœ                                 â
Therefore ğœ† is eigenvalue of ğœ† âœ
                               âœâ‹®                   â‹±          â‹® âŸ
                                                                 âŸ
                                                                 âŸ ğº(ğœ†) which is equivalent to
                               â0                   â‹¯ ğœƒğ¾+1 â 

                                                   1                                                 1
                                    ğº(ğœ†) =                     respectively              ğœ† = ğºâˆ’1 (        ).
                                                   ğœƒğ‘–                                                ğœƒğ‘–

If a solution outside the support of the spectrum of ğ‘†22 exists, then it must satisfy the equation
         1
ğº(ğœ†) =   ğœƒğ‘–
              for some ğ‘– = 1, ..., ğ¾ + 1. Otherwise by Weilâ€™s inequality and the same arguments as in
                                                                   ğ‘                                                                   1
Benaych-Georges and Nadakuditi (2011) ğœ† â†’ ğ‘. For ğ‘§ > ğ‘ we have ğºâ€² (ğ‘§) < 0. Therefore if ğœƒğ‘– >                                          ğº(ğ‘)
                                                                                                 ğ‘
                                         1
then a solution exists. If ğœƒğ‘– <         ğº(ğ‘)
                                                  then no solution exists and ğœ† â†’ ğ‘.
    Recall that the estimators for the loadings and factors are deï¬ned as follows: Î›Ì‚ are the ï¬rst ğ¾
                 1
eigenvectors of ğ‘‹âŠ¤ ğ‘Š2 ğ‘‹ and ğ¹ Ì‚ = ğ‘‹Î›.Ì‚ For the proofs we will use an equivalent formulation. Denote
                    ğ‘‡
                                            1 âŠ¤                             âˆ’1/2
by ğ‘‰ the ï¬rst ğ¾ eigenvectors of             ğ‘‡
                                              ğ‘ˆ ğ‘Šğ‘‹ğ‘‹âŠ¤ ğ‘Šğ‘ˆ. Then Î›Ì‚ = ğ‘‹âŠ¤ ğ‘Šğ‘ˆğ‘‰ğ·ğ¾ ,                                       where ğ·ğ¾ is a diagonal
                                                        1
matrix with the ï¬rst ğ¾ largest           eigenvalues of ğ‘‡ ğ‘ˆâŠ¤ ğ‘‹âŠ¤ ğ‘Š2 ğ‘‹ğ‘ˆ, i.e.

                                                    1
                                                           ğ‘‰âŠ¤ ğ‘ˆâŠ¤ ğ‘Šğ‘‹ğ‘‹âŠ¤ ğ‘Šğ‘ˆğ‘‰ = ğ·ğ¾ .
                                                    ğ‘‡
                                                          1/2
The factors estimator takes the form ğ¹ Ì‚ = ğ‘‹Î›Ì‚ = âˆšğ‘‡ğ‘Šâˆ’1 ğ‘ˆğ‘‰ğ·ğ¾ .


                                                                           36
                                                       1 âŠ¤
      We analyze the ğ¾ + 1 eigenvectors of             ğ‘‡
                                                         ğ‘ˆ ğ‘Šğ‘‹ğ‘‹âŠ¤ ğ‘Šğ‘ˆ.                Assume ğ‘¢ğ‘– is an eigenvector of ğ‘† associated
with ğœ†ğ‘– :

                                         ğœ†ğ‘– ğ¼ğ¾+1 âˆ’ ğ‘†11              âˆ’ğ‘†12       ğ‘¢ğ‘–,1    0
                                     â›                                      ââ›      â=â› â
                                     â      âˆ’ğ‘†21            ğœ†ğ‘– ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’ ğ‘†22 â  âğ‘¢ğ‘–,2 â  â0â 

where ğ‘¢ğ‘–,1 and ğ‘¢ğ‘–,2 are the ï¬rst ğ¾ + 1 respectively last ğ‘‡ âˆ’ ğ¾ âˆ’ 1 components of the vector ğ‘¢ğ‘– . Hence

                                                                                   âˆ’1
                                                ğ‘¢2,ğ‘– = (ğœ†ğ‘– ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’ ğ‘†22 )               ğ‘†21 ğ‘¢ğ‘–,1
                                                  0 = (ğœ†ğ‘– ğ¼ğ¾+1 âˆ’ ğœ…ğ‘‡ (ğœ†ğ‘– )) ğ‘¢ğ‘–,1 .

Assume that ğœƒğ‘– > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ , i.e. ğœ†ğ‘– ğ¼ğ¾+1 âˆ’ ğœ…ğ‘‡ (ğœ†ğ‘– ) = 0 has a solution. Consequently

                                                     ğœƒ1            â‹¯        0
                                       â›
                                       âœ           â›
                                                âˆ’1 âœ
                                                                              ââ
                                       âœ
                                       âœğ¼ğ¾+1 âˆ’ ğœƒğ‘– âœâœâ‹®              â‹±        â‹® âŸ
                                                                              âŸ
                                                                              âŸâŸ
                                                                                âŸ ğ‘¢ = ğ‘œ (1).
                                                                                âŸ ğ‘–,1  ğ‘

                                       â           â0              â‹¯ ğœƒğ¾+1 â â 

As a consequence the vector ğ‘¢ğ‘–,1 has all elements equal to zero except at the ğ‘–th position:

                                             ğ‘¢âŠ¤
                                              ğ‘–,1 = (0 â‹¯ 0 â€–ğ‘¢ğ‘–,1 â€– 0 â‹¯ 0)


where â€–ğ‘¢ğ‘–,1 â€– denotes the length of the vector which is completely determined by the ğ‘–th element. The
vector ğ‘¢ğ‘–,2 satisï¬es

                                                           âˆ’2
           ğ‘¢âŠ¤           âŠ¤
            ğ‘–,2 ğ‘¢ğ‘–,2 = ğ‘¢ğ‘–,1 ğ‘†12 (ğœ†ğ‘– ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’ ğ‘†22 )              ğ‘†21 ğ‘¢ğ‘–,1
                              1                                                                 âˆ’2                         âŠ¤
                    = ğ‘¢âŠ¤
                       ğ‘–,1        ğ‘ˆ1âŠ¤ ğ‘Š (ğ¹Î›ğ‘‡ + ğ‘’) (ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 (ğœ†ğ‘– ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’ ğ‘†22 )                         ğ‘ˆ2âŠ¤ ğ‘Šğ‘’) (ğ¹Î›ğ‘‡ + ğ‘’) ğ‘Šğ‘ˆ1 .
                              ğ‘‡

By similar arguments as in the ï¬rst part of the proof showing the convergence of ğœ…ğ‘‡ (ğœ†) it follows that

                                       ğœƒ1   â‹¯      0
                                     â›
                                     âœ               â
                 ğ‘¢âŠ¤
                  ğ‘–,2 ğ‘¢ğ‘–,2   =ğ‘¢âŠ¤
                               ğ‘–,1   âœ
                                     âœâ‹®     â‹±      â‹® âŸ
                                                     âŸ
                                                     âŸ ğ‘¢ğ‘–,1
                                     â0     â‹¯ ğœƒğ¾+1 â 
                                                                                                     âˆ’2
                                                                            1
                               â‹… trace (ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 (ğœ†ğ‘– ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’                     ğ‘ˆ2âŠ¤ ğ‘Šğ‘’ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 )            ğ‘ˆ2âŠ¤ ğ‘Šğ‘’) + ğ‘œğ‘ (1).
                                                                            ğ‘‡

Recall that ğ‘ˆ2âŠ¤ ğ‘Šğ‘’ = ğ‘’ Ìƒ can be interpreted as ğ‘‡ âˆ’ ğ¾ âˆ’ 1 independent draws of a ğ‘(0, Î£). Denote
                                         1                       1
the eigenvalue distribution function of ğ‘’âŠ¤                            Ìƒ by ğœ™Ìƒ ğ‘‡ (ğ‘§). By assumption both
                                           Ìƒ ğ‘’ Ìƒ by ğœ™ğ‘‡ (ğ‘§) and of ğ‘’ğ‘’Ìƒ âŠ¤
                                                       ğ‘‡                                    ğ‘‡
                                                                            Ìƒ
converge to limit spectral distribution functions that are related through ğœ™(ğ‘§) âˆ’ ğ‘ğœ™(ğ‘§) = (1 âˆ’ ğ‘)ğ›¿0
where ğ›¿0 is the Dirac-measure with point-mass at zero.25 By the properties of the trace operator

                                                                                  âˆ’2
                                                       1                                                      ğ‘§
                trace (ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 (ğœ†ğ‘– ğ¼ğ‘‡âˆ’ğ¾âˆ’1 âˆ’                 ğ‘ˆ2âŠ¤ ğ‘Šğ‘’ğ‘’âŠ¤ ğ‘Šğ‘ˆ2 )              ğ‘ˆ2âŠ¤ ğ‘Šğ‘’) = âˆ«                    ğ‘‘ğœ™Ìƒ ğ‘‡ (ğ‘§)
                                                       ğ‘‡                                                  (ğœ†ğ‘– âˆ’ ğ‘§)2


 25
      See Chapter 2 in Yao, Zheng and Bai (2015).


                                                                       37
which converges almost surely to

                                  ğ‘§                          ğ‘§
                           âˆ«                 Ìƒ
                                           ğ‘‘ğœ™(ğ‘§) =âˆ«                ğ‘‘(ğ‘ğœ™(ğ‘§) + (1 âˆ’ ğ‘)ğ›¿0 )
                               (ğœ†ğ‘– âˆ’ ğ‘§)2                 (ğœ†ğ‘– âˆ’ ğ‘§)2
                                                               ğ‘§
                                                      = ğ‘âˆ«           ğ‘‘ğœ™(ğ‘§) = ğµ(ğœ†ğ‘– ).
                                                           (ğœ†ğ‘– âˆ’ ğ‘§)2

Consequently

                           1 = â€–ğ‘¢ğ‘–,1 â€–2 + â€–ğ‘¢ğ‘–,2 â€–2 = ğ‘¢âŠ¤
                                                      ğ‘–,1 ğ‘¢ğ‘–,1 (1 + ğœƒğ‘– ğµ(ğœ†ğ‘– )) + ğ‘œğ‘ (1)


and therefore

                                                                 ğ‘            1
                                                   â€–ğ‘¢ğ‘–,1 â€–2 â†’                         .
                                                                      1 + ğœƒğ‘– ğµ(ğœ†ğ‘– )

Assume that ğœƒğ‘– < ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ , i.e. ğœ†ğ‘– ğ¼ğ¾+1 âˆ’ ğœ…ğ‘‡ (ğœ†ğ‘– ) = 0 has no solution. It still holds

                                                            ğœƒ1       â‹¯        0
                                                          â›
                                                          âœ                    â
                                  ğ‘¢âŠ¤
                                   ğ‘–,2 ğ‘¢ğ‘–,2   =    ğ‘¢âŠ¤
                                                    ğ‘–,1   âœ
                                                          âœâ‹®         â‹±       â‹® âŸ
                                                                               âŸ
                                                                               âŸ ğ‘¢ğ‘–,1 lim ğµ(ğ‘§)
                                                                                      ğ‘§â†“ğ‘
                                                          â0         â‹¯ ğœƒğ¾+1 â 

                                                                                                   ğ‘
as ğœ†ğ‘– converges in probability to ğ‘. If limğ‘§â†“ğ‘ ğµ(ğ‘§) = âˆ’âˆ, then â€–ğ‘¢ğ‘–,1 â€– â†’ 0 and

                                                      ğ‘¢âŠ¤
                                                       ğ‘–,1 = (0 â‹¯ 0) .


All we need to show is that ğœƒğ‘– < ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ implies limğ‘§â†“ğ‘ ğµ(ğ‘§) = âˆ’âˆ. This follows for the largest eigen-
value ğœ†1 by the same argument as in the proof of theorem 2.3 in Benaych-Georges and Nadakuditi
(2011). If ğ¾ > 1 we need in addition eigenvalue repulsion to show the result for ğœ†ğ‘– for ğ‘– = 2, ..., ğ¾
(see Nadakuditi (2014), appendix 7). Assume that the distance between the largest eigenvalues of the
         1 âŠ¤
matrix   ğ‘‡
           ğ‘’ ğ‘’   decays with a certain rate

                                              ğ‘’âŠ¤ ğ‘’                   ğ‘’âŠ¤ ğ‘’                 log(ğ‘)
                                  |ğœ†ğ‘–+1 (            ) âˆ’ ğœ†ğ‘– (               )| â‰¤ ğ‘‚ğ‘ (              ).
                                               ğ‘‡                      ğ‘‡                    ğ‘2/3

This is satisï¬ed for normally distributed residuals as in our case (see Onatski (2012)). Hence,

                                                      ğ‘§
                               ğµ(ğœ†ğ‘– ) = ğ‘ âˆ«          ğ‘‘ğœ™Ìƒ ğ‘‡ (ğ‘§) + ğ‘œğ‘ (1)
                                           (ğœ†ğ‘– âˆ’ ğ‘§)2
                                            1                 1
                                      â‰¤ ğ‘‚ğ‘ ( ) â‹…                             + ğ‘œğ‘ (1)
                                            ğ‘     (ğœ†1 (ğ‘†22 ) âˆ’ ğœ†ğ¾+1 (ğ‘†22 ))2
                                                     ğ‘1/3
                                      â‰¤ ğ‘‚ğ‘ (                 ).
                                                   log(ğ‘)2

which satisï¬es the explosion condition.




                                                                     38
   We can now go back to the original problem: Deï¬ne

                                                          1
                                               â§                             if ğœƒğ‘– > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡
                                                   âˆš1+ğœƒğ‘– ğµ(ğºâˆ’1 (ğœƒğ‘– ))
                                   ğœŒğ‘– = â¨
                                        â© 0                                  otherwise.

The estimator for the factors can now be written as

                                                                  1/2
                                        ğ¹ Ì‚ = âˆšğ‘‡ğ‘Šâˆ’1 ğ‘ˆğ‘‰ğ·ğ¾

                                                     ğœŒ1                 0    â‹¯    0
                                                   â›
                                                   âœ                              â
                                                   âœ 0                  ğœŒ2   â‹¯  0âŸâŸ
                                                   âœ
                                                   âœ                              âŸ
                                                                                  âŸ 1/2
                                               âˆ’1
                                          = âˆšğ‘‡ğ‘Š ğ‘ˆ1 âœ
                                                   âœ 0                  0    â‹± â‹®âŸ âŸ ğ·ğ¾
                                                   âœ
                                                   âœ                              âŸ
                                                   âœ0                   â‹¯    0 ğœŒğ¾ âŸ
                                                                                  âŸ
                                                               â0       â‹¯       0â 

with

                          ğœƒ1Ì‚      â‹¯       0
                        â›               â                             â§ ğºâˆ’1 ( 1 )            if ğœƒğ‘– > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡
                   ğ·ğ¾ = âœ
                        âœ
                        âœâ‹®         â‹± â‹®âŸ âŸ
                                        âŸ                ,      ğœƒğ‘–Ì‚ = â¨      ğœƒğ‘–

                                                                      â© ğ‘                    otherwise.
                                      Ì‚
                        â0         â‹¯ ğœƒğ¾ â 

                       Ì‚
   The calculation for Corr(ğ¹, ğ¹)Ì‚ is straightforward. Note that the mean can be estimated by

                                                                       ğœŒ1    0    â‹¯   0
                                                                     â›
                                                                     âœ                 â
                                                                     âœ 0     ğœŒ2   â‹¯  0âŸâŸ
                                           1                         âœ
                                                                     âœ                 âŸ
                                                                                       âŸ 1/2
                              ğœ‡ğ¹Ì‚ Ì‚ =              (ğ‘‚ğ¾       1ğ¾ ) ğ‘ˆ âœ
                                                                   Ìƒ
                                                                     âœ 0     0    â‹± â‹®âŸ âŸ ğ·ğ¾ .
                                        1 + ğ›¾Ìƒ                       âœ                 âŸ
                                                                     âœ
                                                                     âœ0      â‹¯         âŸ
                                                                                  0 ğœŒğ¾ âŸ
                                                                     â0      â‹¯       0â 

Here we used that ğ‘Šâˆ’1 = ğ¼ğ‘‡ âˆ’
                                         ğ›¾Ìƒ
                                        1+ğ›¾Ìƒ
                                               11âŠ¤ and (1 + ğ›¾)Ìƒ 2 = 1 + ğ›¾.
Proof for i.i.d. residuals:
                                                                                                1 âŠ¤
For the special case where ğ‘’ğ‘¡,ğ‘– i.i.d. ğ‘(0, ğœğ‘’2 ), i.e. Î£ = ğœğ‘’2 ğ¼ğ‘ , the matrix                 ğ‘‡
                                                                                                  ğ‘’ ğ‘’   follows the Marcenko-
Pasteur law:

                                   1                                                                    1
                  ğ‘‘ğœ™(ğ‘§) =                       (ğ‘ âˆ’ ğ‘§)(ğ‘§ âˆ’ ğ‘)1{ğ‘§âˆˆ(ğ‘,ğ‘)} ğ‘‘ğ‘§ + max (0, 1 âˆ’                   ) ğ›¿0
                              2ğœ‹ğ‘ğœğ‘’2 ğ‘§ âˆš                                                                ğ‘

with

                                                       ğ‘ = ğœğ‘’2 (1 âˆ’ âˆšğ‘)2
                                                        ğ‘ = ğœğ‘’2 (1 + âˆšğ‘)2

ğ‘ and ğ‘ are the smallest respectively largest eigenvalue. For simplicity take ğ‘ > 1, but the results
can be easily extended to the case 0 < ğ‘ < 1. The object of interest is the Cauchy transform of the




                                                                  39
eigenvalue distribution function. Calculations as outlined in Bai and Silverstein (2010) lead to

                                      ğ‘§ âˆ’ ğœğ‘’2 (1 âˆ’ ğ‘) âˆ’ âˆš(ğ‘§ âˆ’ ğœğ‘’2 (1 + ğ‘))2 âˆ’ 4ğ‘ğœğ‘’2
                             ğº(ğ‘§) =                                                       .
                                                                2ğ‘ğ‘§ğœğ‘’2

Simple but tedious calculations show that

                                                            ğ‘§ğœğ‘’2 (1 âˆ’ ğ‘) + 1
                                             ğºâˆ’1 (ğ‘§) =                          .
                                                               ğ‘§ âˆ’ ğ‘ğœğ‘’2 ğ‘§2

Proof of Corollary 2: Plugging the eigenvalues and eigenvector formulas into Theorem 2 yields:

                                             ğ‘           ğœŒ1  1/2 Ì‚
                                 Ì‚
                                 Corr(ğ¹, ğ¹)Ì‚ â†’ (1 0) ğ‘ˆÌƒ â› â ğœƒ1Ì‚ Var( ğ¹)Ì‚ 1/2
                                                         0
                                                        â â 
                                                ğ‘
                                      Ì‚ ğ¹)Ì‚ â†’ ğœƒ1Ì‚ (ğ‘ˆ1,1
                                      Var(          Ìƒ 2 â€–ğ‘¢1,1 â€–2 + â€–ğ‘¢1,2 â€–2 )
                                                ğ‘       1
                                             ğœ‡Ì‚2 â†’             Ìƒ 2 ğœŒ1 ğœƒ1Ì‚ .
                                                              ğ‘ˆ1,2
                                                     1+ğ›¾

The proof for the limit for ğ›¾ â†’ âˆ is based on the insight that

                                                  lim ğµ(ğœƒ)ğœƒ2 â†’ ğ‘ğœğ‘’2 .
                                                  ğœƒâ†’âˆ



Lemma 2: Detection of weak factors
If ğ›¾ > âˆ’1 and ğœ‡ğ¹ â‰  0, then the ï¬rst ğ¾ eigenvalues of ğ‘€RP-PCA are strictly larger than the ï¬rst ğ¾
eigenvalues of ğ‘€PCA , i.e.

                                                ğœƒğ‘–RP-PCA > ğœğ¹2ğ‘– + ğ‘ğœğ‘’2 .

For ğœƒğ‘– > ğœƒğ‘ğ‘Ÿğ‘–ğ‘¡ it holds that

                                      ğœ•ğœƒğ‘–Ì‚              ğœ•ğœŒğ‘–
                                             >0               >0         ğ‘– = 1, ..., ğ¾.
                                      ğœ•ğœƒğ‘–               ğœ•ğœƒğ‘–

Thus, if ğ›¾ > âˆ’1 and ğœ‡ğ¹ â‰  0, then ğœŒğ‘–RP-PCA > ğœŒğ‘–PCA .


Proof of Lemma 2:
See result (12) on page 75 in LÃ¼tkepohl (1996) and straightforward calculations.




                                                              40
References

Ahn, S. C., Horenstein, A. R., 2013. Eigenvalue ratio test for the number of factors. Econometrica 81,
  1203â€“1227.
AÃ¯t-Sahalia, Y., Xiu, D., 2017. Principal component estimation of a large covariance matrix with high-
  frequency data. Journal of Econometrics 201, 384â€“399.
Bai, J., 2003. Inferential theory for factor models of large dimensions. Econometrica 71, 135â€“171.
Bai, J., Ng, S., 2002. Determining the number of factors in approximate factor models. Econometrica
  70, 191â€“221.
Bai, J., Ng, S., 2008. Large dimensional factor analysis. Foundations and Trends in Econometrics 3 (2),
  89â€“163.
Bai, J., Ng, S., 2017. Principal components and regularized estimation of factor models. Working Paper.
Benaych-Georges, F., Nadakuditi, R. R., 2011. The eigenvalues and eigenvectors of ï¬nite, low rank
  perturbations of large random matrices. Advances in Mathematics 227, 494â€“521.
Bryzgalova, S., 2017. Spurious factors in linear asset pricing models. Technical report, Stanford Uni-
  versity.
Chamberlain, G., Rothschild, M., 1983. Arbitrage, factor structure, and mean-variance analysis on
  large asset markets. Econometrica 51, 1281â€“1304.
Connor, G., Korajczyk, R., 1988. Risk and return in an equilibrium apt: Application to a new test
  methodology. Journal of Financial Economics 21, 255â€“289.
Connor, G., Korajczyk, R., 1993. A test for the number of factors in an approximate factor model.
  Journal of Finance 58, 1263â€“1291.
Fan, J., Liao, Y., Mincheva, M., 2013. Large covariance estimation by thresholding principal orthogonal
  complements. Journal of the Royal Statistical Society 75 (4), 603â€“680.
Fan, J., Liao, Y., Wang, W., 2016. Projected principal component analysis in factor models. The Annals
  of Statistics 44 (1), 219â€“254.
Fan, J., Zhong, Y., 2018. Optimal subspace estimation using overidentifying vectors via generalized
  method of moments. Working paper.
Forni, M., Hallin, M., Lippi, M., Reichlin, L., 2000. The generalized dynamic-factor model: Identiï¬cation
  and estimation. Review 82, 540â€“554.
Harding, M., 2013. Estimating the number of factors in large dimensional factor models. Working
  paper.
Kelly, B., Pruitt, S., Su, Y., 2017. Instrumented principal component analysis. Working Paper.
Kozak, S., Nagel, S., Santosh, S., 2017. Shrinking the cross section. Technical Report, Chicago Booth.
Lettau, M., Pelger, M., 2018. Factors that ï¬t the time series and cross-section of stock returns. Working
  paper.
Ludvigson, S., Ng, S., 2010. A factor analysis of bond risk premia. Handbook of the Economics of
  Finance.
LÃ¼tkepohl, H., 1996. Handbook of Matrices. John Wiley & Sons.
Onatski, A., 2010. Determining the number of factors from empirical distribution of eigenvalues.
  Review of Economic and Statistics 92, 1004â€“1016.


                                                   41
Onatski, A., 2012. Asymptotics of the principal components estimator of large factor models with
  weakly inï¬‚uential factors. Journal of Econometrics (168), 244â€“258.
Paul, D., 2007. Asymptotics of sample eigenstructure for a large dimensional spiked covariance model.
  Statistica Sinica 17 (4), 1617â€“1642.
Pelger, M., 2017. Large-dimensional factor modeling based on high-frequency observations large-
  dimensional factor modeling based on high-frequency observations. Working paper.
Ross, S. A., 1976. The arbitrage theory of capital asset pricing. Journal of Economic Theory 13, 341â€“
  360.
Stock, J., Watson, M., 2006. Macroeconomic Forecasting Using Many Predictors. Handbook of Economic
  Forecasting. North Holland.




                                                 42
