NBER WORKING PAPER SERIES

IDENTIFICATION AND ESTIMATION OF GAUSSIAN AFFINE TERM STRUCTURE
MODELS
James D. Hamilton
Jing Cynthia Wu
Working Paper 17772
http://www.nber.org/papers/w17772

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2012

We are grateful to Michael Bauer, Bryan Brown, Frank Diebold, Ron Gallant, Ken Singleton, anonymous
referees, and seminar participants at the University of Chicago, UCSD, Federal Reserve Board, Pennsylvania
State University, Society for Financial Econometrics, Midwest Macroeconomics Conference, Rice
University, University of Colorado, and the Federal Reserve Bank of San Francisco for comments
on earlier drafts of this paper. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2012 by James D. Hamilton and Jing Cynthia Wu. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.

Identification and Estimation of Gaussian Affine Term Structure Models
James D. Hamilton and Jing Cynthia Wu
NBER Working Paper No. 17772
January 2012
JEL No. C13,E43,G12
ABSTRACT
This paper develops new results for identification and estimation of Gaussian affine term structure
models. We establish that three popular canonical representations are unidentified, and demonstrate
how unidentified regions can complicate numerical optimization. A separate contribution of the paper
is the proposal of minimum-chi-square estimation as an alternative to MLE. We show that, although
it is asymptotically equivalent to MLE, it can be much easier to compute. In some cases, MCSE allows
researchers to recognize with certainty whether a given estimate represents a global maximum of the
likelihood function and makes feasible the computation of small-sample standard errors.

James D. Hamilton
Department of Economics, 0508
University of California, San Diego
9500 Gilman Drive
La Jolla, CA 92093-0508
and NBER
jhamilton@ucsd.edu
Jing Cynthia Wu
Booth School of Business
University of Chicago
5807 S Woodlawn Ave
Chicago, IL 60637-1610
Cynthia.Wu@chicagobooth.edu

1

Introduction.

The class of Gaussian affine term structure models1 developed by Vasicek (1977), Duffie and
Kan (1996), Dai and Singleton (2002), and Duffee (2002) has become the basic workhorse in
macroeconomics and finance for purposes of using a no-arbitrage framework for studying the
relations between yields on assets of different maturities. Its appeal comes from its simple
characterization of how risk gets priced by the market which, under the assumption of no
arbitrage, generates predictions for the price of any asset. The approach has been used to
measure the role of risk premia in interest rates (Duffee, 2002; Cochrane and Piazzesi, 2009),
study how macroeconomic developments and monetary policy affect the term structure of
interest rates (Ang and Piazzesi, 2003; Beechey and Wright, 2009; Bauer, 2011), characterize
the monetary policy rule (Ang, Dong, and Piazzesi, 2007; Rudebusch and Wu, 2008; Bekaert,
Cho, and Moreno, 2010), determine why long-term yields remained remarkably low in 2004
and 2005 (Kim and Wright, 2005; Rudebusch, Swanson, and Wu, 2006), infer market expectations of inflation from the spread between nominal and inflation-indexed Treasury yields
(Christensen, Lopez, and Rudebusch, 2010), evaluate the effectiveness of the extraordinary
central bank interventions during the financial crisis (Christensen, Lopez, and Rudebusch,
2009; Smith, 2010), and study the potential for monetary policy to affect interest rates when
the short rate is at the zero lower bound Hamilton and Wu (forthcominga).
But buried in the footnotes of this literature and in the practical experience of those
who have used these models are tremendous numerical challenges in estimating the necessary
1

By Gaussian affine term structure models we refer to specifications in which the discrete-time joint distribution of yields and factors is multivariate Normal with constant conditional variances. We do not in this
paper consider the broader class of non-Gaussian processes.

1

parameters from the data due to highly non-linear and badly behaved likelihood surfaces. For
example, Kim (2008) observed:
Flexibly specified no-arbitrage models tend to entail much estimation difficulty
due to a large number of parameters to be estimated and due to the nonlinear
relationship between the parameters and yields that necessitates a nonlinear optimization.
Ang and Piazzesi (2003) similarly reported:
difficulties associated with estimating a model with many factors using maximum likelihood when yields are highly persistent....We need to find good starting
values to achieve convergence in this highly non-linear system....[T]he likelihood
surface is very flat in λ0 which determines the mean of long yields....
This paper proposes a solution to these and other problems with affine term structure
models based on what we will refer to as their reduced-form representation. For a popular
class of Gaussian affine term structure models– namely, those for which the model is claimed
to price exactly a subset of N` linear combinations of observed yields, where N` is the number
of unobserved pricing factors– this reduced form is a restricted vector autoregression in the
observed set of yields and macroeconomic variables.2 We explore two implications of this fact
that seem to have been ignored in the large preceding literature on such models.
The first is that the parameters of these reduced-form representations contain all the
observable implications of any Gaussian affine term structure model for the sample of observed
2

For more general models where all yields are priced with measurement error, the reduced form is a
restricted state-space representation for the set of observed variables. The same tools developed here could
still be applied in that setting, though we leave exploration of such models for future research.

2

data, and can therefore be used as a basis for assessing identification.

If more than one

value for the parameter vector of interest is associated with the same reduced-form parameter
vector, then the model is unidentified at that point and there is no way to use the observed
data to distinguish between the alternative possibilities. Although as a general econometric
principle this idea dates back to Fisher (1966) and Rothenberg (1971), it has not previously
been applied to affine term structure models. In this paper, we use it to demonstrate that
the preferred representations proposed by Ang and Piazzesi (2003) and Pericoli and Taboga
(2008) are in fact unidentified, an observation that our paper is the first to point out. We
also use this approach to show that the representation proposed by Dai and Singleton (2000)
is unidentified.

Although this latter fact has previously been inferred by Collin-Dufresne,

Goldstein, and Jones (2008) and Aı̈t-Sahalia and Kimmel (2010) using other methods, we
regard the proof here based on the reduced form to be more transparent and direct.

We

further demonstrate that it is common for numerical search methods to end up in regions of
the parameter space that are locally unidentified, and show why this failure of identification
arises. These issues of identification are one factor that contributes to the numerical difficulties
for conventional methods noted above.
A second and completely separate contribution of the paper is the observation that it is
possible for the parameters of interest to be inferred directly from estimates of the reducedform parameters themselves. This is a very useful result because the latter are often simple
OLS coefficients. Although translating from reduced-form parameters into structural parameters involves a mix of analytical and numerical calculations, the numerical component is far
simpler than that associated with the usual approach of trying to find the maximum of the

3

likelihood surface directly as a function of the structural parameters. In the case of a justidentified structure, the numerical component of our proposed method has an additional big
advantage over the traditional approach, in that the researcher knows with certainty whether
the equations have been solved, and therefore knows with certainty whether one has found the
global maximum of the likelihood surface with respect to the structural parameters or simply
a local maximum.

In the conventional approach, one instead has to search over hundreds

of different starting values, and even then has no guarantee that the global maximum has
been found. In the case where the model imposes overidentifying restrictions on the reduced
form, one can still estimate structural parameters as functions of the unrestricted reducedform estimates by the method of minimum-chi-square estimation (MCSE). This minimizes
a quadratic form in the difference between the reduced-form parameters implied by a given
structural model and the reduced-form parameters as estimated without restrictions directly
from the data, with the weighting matrix given by the information matrix, in other words,
minimizing the value of the chi-square statistic for testing whether the restrictions are indeed
consistent with the observed reduced-form estimates.
Again while the general econometric method of minimum-chi-square estimation is well
known, our paper is the first to apply it to affine term structure models and demonstrate its
considerable advantages in this setting. Estimating parameters by minimizing the chi-square
statistic was to our knowledge first proposed by Fisher (1924) and Neyman and Pearson (1928).
Rothenberg (1973, pp. 24-25) extended the approach to more general parametric inference,
demonstrating that when (as in our proposed application) the reduced-form estimate is the
unrestricted MLE and the weighting matrix is the associated information matrix, the resulting

4

MCSE is asymptotically equivalent to full-information MLE. MCSE has also been used in
other settings by Chamberlain (1982) and Newey (1987).
More generally, MCSE could be viewed as a special case of minimum distance estimation
(MDE) discussed for example by Malinvaud (1970), in which one minimizes a quadratic form
in the difference between restricted and unrestricted statistics. We follow Rothenberg (1973)
in using the expression MCSE to refer to the special case of MDE in which the unrestricted
statistics are the unrestricted MLE and weights come from their asymptotic variance, in which
case MDE is asymptotically efficient. Another well-known example of MDE is the generalized
method of moments (GMM, Hansen (1982)), in which the unrestricted statistics are sample
moments.3 Bekaert, Cho, and Moreno (2010) used GMM to estimate parameters of an affine
term structure model. GMM in this form misses what we see as the two main advantages
of MCSE, namely, the OLS estimates are known analytically and MCSE, unlike GMM, is
asymptotically efficient.
Another popular example of MDE is the method of indirect inference proposed by Gallant
and Tauchen (1992), Smith (1993) and Gourieroux, Monfort, and Renault (1993). With indirect inference, the unrestricted parameter estimates are typically regarded as only approximate
or auxiliary characterizations of the data, and numerical simulation is typically required to
calculate the values for these auxiliary parameters that are implied by the structural model.
Duffee and Stanton (2008) suggested that for highly persistent data such as interest rates,
indirect inference or MLE may work substantially better than other moment-based estima3

In our application of MCSE, the unrestricted estimates (OLS coefficients and variances) are nonlinear
functions of sample moments. This connection between MCSE and GMM is explored further in Chamberlain
(1982, p. 18).

5

tors. One could view our application of MCSE as a special case of indirect inference in which
the unrestricted estimates are in fact sufficient statistics for the likelihood function and the
mapping from structural parameters to these coefficients is known analytically, precisely the
features from which our claimed benefits of MCSE derive.
In particular, we demonstrate in this paper that use of MCSE captures all the asymptotic
benefits of MLE while avoiding many of the numerical problems associated with MLE for
affine term structure models. Among other illustrations of the computational advantages, we
establish the feasibility of calculating small-sample standard errors and confidence intervals
for this class of models and demonstrate that the parameter estimates reported by Ang and
Piazzesi (2003) in fact correspond to a local maximum of the likelihood surface and are not
the global MLE.
There have been several other recent efforts to address many of these problems in affine
term structure models. Christensen, Diebold, and Rudebusch (2011) developed a no-arbitrage
representation of a dynamic Nelson-Siegel model of interest rates that gives a convenient representation of level, slope and curvature factors and offers significant improvements in empirical
tractability and predictive performance over earlier affine term structure specifications. Joslin,
Singleton, and Zhu (2011) proposed a canonical representation for affine term structure models that greatly improves convergence of maximum likelihood estimation.

Collin-Dufresne,

Goldstein, and Jones (2008) proposed a representation in terms of the derivatives of the term
structure at maturity zero, arguing for the benefits of using these observable magnitudes rather
than unobserved latent variables to represent the state vector of an ATSM. Each of these
papers proposes canonical representations that are identified, and the Christensen, Diebold,

6

and Rudebusch (2011) and Joslin, Singleton, and Zhu (2011) parameterizations lead to better
behaved likelihood functions than do the parameterizations explored in detail in our paper.
The chief difference between our proposed solution and those of these other researchers
is that they focus on how the ATSM should be represented, whereas we examine how the
parameters of the ATSM are to be estimated. Thus for example Christensen, Diebold, and
Rudebusch (2011) require the researcher to impose certain restrictions on the ATSM, whereas
Joslin, Singleton, and Zhu (2011) cannot incorporate most auxiliary restrictions on the P dynamics. It is far from clear how any of these three approaches could have been used to estimate
a model of the form investigated by Ang and Piazzesi (2003). By contrast, our MCSE algorithm can be used for any representation, including those proposed by Christensen, Diebold,
and Rudebusch (2011) and Joslin, Singleton, and Zhu (2011), and can simplify the numerical
burden regardless of the representation chosen. Indeed, some of the numerical advantages of
Joslin, Singleton, and Zhu (2011) come from the fact that a subset of their parameterization
is identical to a subset of our reduced-form representation, and their approach, like ours, takes
advantage of the fact that the full-information MLE for this subset can be obtained by OLS
for a popular class of models.

However, Joslin, Singleton, and Zhu (2011) estimated the

remaining parameters by conventional MLE rather than using the full set of reduced-form
estimates as in our approach. As Joslin, Singleton, and Zhu (2011) noted, their representation becomes unidentified in the presence of a unit root. When applied to highly persistent
data, we illustrate that their MLE algorithm can encounter similar problems to those of other
representations, which can be avoided with our approach to parameter estimation.
The rest of the paper is organized as follows. Section 2 describes the class of Gaussian affine

7

term structure models and three popular examples, and briefly uses one of the specifications
to illustrate the numerical difficulties that can be encountered with the traditional approach.
Section 3 investigates the mapping from structural to reduced-form parameters. We establish
that the canonical forms of all three examples are unidentified and explore how this contributes
to some of the problems for conventional numerical search algorithms. In Section 4 we use
the mapping to propose approaches to parameter estimation that are much better behaved.
Section 5 concludes.

2
2.1

Gaussian Affine Term Structure Models.
Basic framework

Consider an (M × 1) vector of variables Ft whose dynamics are characterized by a Gaussian
vector autoregression:
Ft+1 = c + ρFt + Σut+1

(1)

with ut ∼ i.i.d. N (0, IM ). This specification implies that Ft+1 |Ft , Ft−1 , ..., F1 ∼ N (µt , ΣΣ0 )
for
µt = c + ρFt .

(2)

Let rt denote the risk-free one-period interest rate. If the vector Ft includes all the variables
that could matter to investors, then the price of a pure discount asset at date t should be a
function Pt (Ft ) of the current state vector. Moreover, if investors were risk neutral, the price

8

they’d be willing to pay would satisfy

Pt (Ft ) = exp(−rt )Et [Pt+1 (Ft+1 )]
Z
= exp(−rt )
Pt+1 (Ft+1 )φ(Ft+1 ; µt , ΣΣ0 ) dFt+1

(3)

RM

for φ(y; µ, Ω) the M -dimensional N (µ, Ω) density evaluated at the point y:

φ(y; µ, Ω) =

1
(2π)M/2 |Ω|1/2



(y − µ)0 Ω−1 (y − µ)
.
exp −
2

(4)

More generally, with risk-averse investors we would replace (3) with

Pt (Ft ) = Et [Pt+1 (Ft+1 )Mt,t+1 ]
Z
=
Pt+1 (Ft+1 ) [Mt,t+1 φ(Ft+1 ; µt , ΣΣ0 )] dFt+1

(5)

RM

for Mt,t+1 the pricing kernel. In many macro models, the pricing kernel would be

Mt,t+1 =

βU 0 (Ct+1 )
U 0 (Ct )(1 + π t+1 )

for β the personal discount rate, U 0 (C) the marginal utility of consumption, and π t+1 the
inflation rate between t and t + 1.
Affine term structure models are derived from the particular kernel

Mt,t+1

h
i
0
0
= exp −rt − (1/2)λt λt − λt ut+1

9

(6)

for λt an (M × 1) vector that characterizes investor attitudes toward risk, with λt = 0 in the
case of risk neutrality. Elementary multiplication of (4) by (6) reveals that for this case

0
Mt,t+1 φ(Ft+1 ; µt , ΣΣ0 ) = exp(−rt )φ(Ft+1 ; µQ
t , ΣΣ )

(7)

µQ
t = µt − Σλt .

(8)

for

Substituting (7) into (5) and comparing with (3), we see that for this specification of the
pricing kernel, risk-averse investors value any asset the same as risk-neutral investors would if
the latter thought that the conditional mean of Ft+1 was µQ
t rather than µt . A positive value
for the first element of λt , for example, implies that an asset that delivers the quantity F1,t+1
dollars in period t + 1 would have a value at time t that is less than the value that would
be assigned by a risk-neutral investor, and the size of this difference is bigger when the (1, 1)
element of Σ is bigger.

An asset yielding Fi,t+1 dollars has a market value that is reduced

by Σi1 λ1t relative to a risk-neutral valuation, through the covariance between factors i and 1.
The term λ1t might then be described as the market price of factor 1 risk.
The affine term structure models further postulate that this market price of risk is itself
an affine function of Ft ,
λt = λ + ΛFt

(9)

for λ an (M × 1) vector and Λ an (M × M ) matrix. Substituting (9) and (2) into (8), we see

10

that
Q
Q
µQ
t = c + ρ Ft

for
cQ = c − Σλ

(10)

ρQ = ρ − ΣΛ.

(11)

In other words, risk-averse investors value assets the same way as a risk-neutral investor would
if that risk-neutral investor believed that the factors are characterized by a Q-measure VAR
given by
Ft+1 = cQ + ρQ Ft + ΣuQ
t+1

(12)

with uQ
t+1 a vector of independent standard Normal variables under the Q measure.
Suppose that the risk-free 1-period yield is also an affine function of the factors

0

rt = δ 0 + δ 1 Ft .

(13)

Then, as demonstrated for example in Appendix A of Ang and Piazzesi (2003), under the
above assumptions the yield on a risk-free n-period pure-discount bond can be calculated as

ytn = an + b0n Ft

11

(14)

where

bn

 i
1h
Q0
Q0 n−1
IM + ρ + · · · + ρ
δ1
=
n


an = δ 0 + b01 + 2b02 + · · · + (n − 1) b0n−1 cQ /n

(15)
(16)


− b01 ΣΣ0 b1 + 22 b02 ΣΣ0 b2 + · · · + (n − 1)2 b0n−1 ΣΣ0 bn−1 /2n.

If we knew Ft and the values of cQ and ρQ along with δ 0 , δ 1 , and Σ, we could use (14), (15),
and (16) to predict the yield for any maturity n.
There are thus three sets of parameters that go into an affine term structure model: (a)
the parameters c, ρ, and Σ that characterize the objective dynamics of the factors in equation
(1) (sometimes called the P parameters); (b) the parameters λ and Λ in equation (9) that
characterize the price of risk; and (c) the Q parameters cQ and ρQ (along with the same Σ
as appeared in the P parameter set) that figure in (12). If we knew any two of these sets of
parameters, we could calculate the third4 using (10) and (11). We will refer to a representation
in terms of (a) and (b) as a λ representation, and a representation in terms of (a) and (c) as
a Q representation.
Suppose we want to describe yields on a set of Nd different maturities. If Nd is greater
than N` , where N` is the number of unobserved pricing factors, then (14) would imply that
it should be possible to predict the value of one of the ynt as an exact linear function of
the others.

Although in practice we can predict one yield extremely accurately given the

others, the empirical fit is never exact. One common approach to estimation, employed for
4

We will discuss examples below in which Σ is singular for which the demonstration of this equivalence is
a bit more involved, with the truth of the assertion coming from the fact that for such cases certain elements
of λ and Λ are defined to be zero.

12

example by Ang and Piazzesi (2003) and Chen and Scott (1993), is to suppose that (14) holds
exactly for N` linear combinations of observed yields, and that the remaining Ne = Nd − N`
linear combinations differ from the predicted value by a small measurement error.

Let Yt1

denote the (N` × 1) vector consisting of those linear combinations of yields that are treated as
priced without error and Yt2 the remaining (Ne × 1) linear combinations. The measurement
specification is then







Yt1
(N` ×1)
Yt2
(Ne ×1)



 
 
=
 


A1
(N` ×1)
A2
(Ne ×1)



 
 
+
 


B1
(N` ×M )
B2
(Ne ×M )







 Ft + 




0

(N` ×Ne )

Σe
(Ne ×Ne )


 e
 ut
 (Ne ×1)

(17)

where Σe is typically taken to be diagonal. Here Ai and Bi are calculated by stacking (16) and
(15), respectively, for the appropriate n, while Σe determines the variance of the measurement
error with uet ∼ N (0, INe ). We will discuss many of the issues associated with identification
and estimation of affine term structure models in terms of three examples.

2.2

Example 1: Latent factor model.

In this specification, the factors Ft governing yields are treated as if observable only through
their implications for the yields themselves; examples in the continuous-time literature include
Dai and Singleton (2000), Duffee (2002), and Kim and Orphanides (2005). Typically in this
case, the number of factors N` and the number of yields observed without error are both taken
to be 3, with the 3 factors interpreted as the level, slope, and curvature of the term structure.
The 3 linear combinations Yt1 regarded as observed without error can be constructed from

13

the first 3 principal components of the set of yields. Alternatively, they could be constructed
directly from logical measures of level, slope, and curvature.
to choose 3 representative yields as the elements of Yt1 .

Yet another option is simply

Which linear combinations are

claimed to be priced without error can make a difference for certain testable implications of
the model, an issue that we explore in a separate paper (Hamilton and Wu, forthcomingb)
which addresses empirical testing of the overidentifying restrictions of affine term structure
models. For purposes of discussing identification and estimation, however, the choice of which
yields go into Yt1 is immaterial, and notation is kept simplest by following Ang and Piazzesi
(2003) and Pericoli and Taboga (2008) in just using 3 representative yields. In our numerical
example, these are taken to be the n = 1-, 12-, and 60-month maturities, with data on 36month yields included separately in Yt2 . Thus for this illustrative latent-factor specification,
equation (17) takes the form










1
 yt


 y 12
 t


 y 60
 t


yt36

0
  a1   b1
 
 
 
 
  a   b0
  12   12
+
=
 
 
  a   b0
  60   60
 
 
 
 
b036
a36







 0 







 0 

 e


 ut
 Ft + 



 0 










Σe

(18)

where an and bn are calculated from equations (16) and (15), respectively.
We will use for our illustration a Q representation for this system.

Dai and Singleton

(2000) proposed the normalization conditions Σ = IN` , δ 1 ≥ 0, c = 0 and ρ lower triangular.
Singleton (2006) used parallel constraints on the Q parameters (Σ = IN` , δ 1 ≥ 0, cQ = 0, ρQ
lower triangular). Our illustration will use Σ = IN` , δ 1 ≥ 0, c = 0 and ρQ lower triangular.
14

For the N` = 3, Ne = 1 case displayed in equation (18), there are then 23 unknown parameters:
3 in cQ , 6 in ρQ , 9 in ρ, 1 in δ 0 , 3 in δ 1 , and 1 in Σe , which we collect in the (23 × 1) vector θ.
The log likelihood is

L(θ; Y ) =

T
X

{− log [|det(J)|] + log φ(Ft ; c + ρFt−1 , IN` ) + log φ(uet ; 0, INe )}

(19)

t=1

for φ(.) the multivariate Normal density in equation (4) and det(J) the determinant of the
Jacobian, with



J =



B1
(N` ×N` )

(N` ×Ne )

0

B2
(Ne ×N` )

Σe
(Ne ×Ne )






Ft = B1−1 (Yt1 − A1 )
 2
uet = Σ−1
Yt − A2 − B2 B1−1 (Yt1 − A1 ) .
e
The Chen-Scott procedure is to maximize (19) with respect to θ by numerical search.
As a simple example to illustrate the difficulties with this traditional estimation and some
of the advantages of the procedure that we will be recommending to replace it, we simulated
a sample of 1000 observations using parameters specified in the first block of Table 1 below.
These parameters were chosen to match the actual observed behavior of the four yields used
here. On this sample we tried to choose θ so as to maximize (19) using the fminunc algorithm
in MATLAB.5 Since numerical search can be sensitive to different scaling of parameters, we
5

MATLAB numerical optimizers have been used by Cochrane and Piazzesi (2009), Aı̈t-Sahalia and Kimmel
(2010), and Joslin, Singleton, and Zhu (2011), among others. Duffee (2011) found that numerical search
problems can be reduced using alternative algorithms. Our purpose here is to illustrate the difficulties that
can arise in estimation. We will demonstrate that these identical MATLAB algorithms have no trouble with
the alternative formulation that we will propose below.

15

tried to scale parameters in a way consistent with a researcher’s prior expectation that risk
prices were small, multiplying cQ by 10 and δ 1 and Σe by 1000 so that a unit step for each
of these parameters would be similar to a unit step for the others.6

We used 100 different

starting values for this search, using a range of values for ρQ and starting the other parameters
at good guesses. Specifically, to obtain a given starting value we would generate the 3 diagonal
elements of ρQ from U [0.5, 1] distributions, set off-diagonal elements to zero, and set the initial
guess for ρ equal to this value for ρQ . We set the starting value for each element of δ 1 and Σe
to 1.e-4, δ 0 = 0.0046 (the average short rate), and cQ = 0.
In only 1 of these 100 experiments did the numerical search converge to the values that
we will establish below are indeed the true global MLE. These estimates, reported in the
second block of Table 1, in fact correspond very nicely to the true values from which this
sample was simulated. However, in 81 of the other experiments, the procedure satisfied the
convergence criterion (usually coming from a sufficiently tiny change between iterations) at a
large range of alternative points other than the global maximum. The third block of Table
1 displays one of these. All such points are characterized by an eigenvalue of ρ being equal
or very close to unity; we will explain why this happens in the following section.

For the

other 18 starting values, the search algorithm was unable to make any progress from the initial
starting values. Although very simple, this exercise helps convey some sense of the numerical
problems researchers have encountered fitting more complicated models such as we describe
in our next two examples.
6

To give the algorithm the best chance to converge, for each starting value we allowed the search to continue
for up to 10,000 function evaluations, then restarted the search at that terminal value to allow an additional
10,000 function evaluations, and so on, for 10 repetitions with each starting value.

16

2.3

Example 2: Macro finance model with single lag (MF1).

It is of considerable interest to include observable macroeconomic variables among the factors
that may affect interest rates, as for example in Ang and Piazzesi (2003), Ang, Dong, and
Piazzesi (2007), Rudebusch and Wu (2008), Ang, Piazzesi, and Wei (2006), and Hördahl,
Tristani, and Vestin (2006). Our next two illustrative examples come from this class. We
first consider the unrestricted first-order macro factor model studied by Pericoli and Taboga
(2008).

This model uses Nm = 2 observable macro factors, consisting of measures of the

inflation rate and the output gap, which are collected in an (Nm × 1) vector ftm . These two
observable macroeconomic factors are allowed to influence yield dynamics in addition to the
traditional N` = 3 latent7 factors ft` ,





Ft = 

(Nf ×1)

ftm
(Nm ×1)
ft`



,


(N` ×1)

for Nf = Nm + N` . The P dynamics (1), Q dynamics (12), and short-rate equation (13) can
for this example be written in partitioned form as

ftm

m
`
+ Σmm um
= cm + ρmm ft−1
+ ρm` ft−1
t

(20)

(Nm ×1)

ft`

m
`
`
= c` + ρ`m ft−1
+ ρ`` ft−1
+ Σ`m um
t + Σ`` ut

(N` ×1)
7

Pericoli and Taboga evaluated a number of alternative specifications including different choices for the
number of latent factors N` , number of lags on the macro variables, and dependence between the latent and
macro factors. They refer to the specification we discuss in the text as the M (3, 0, U ) specification, which is
the one that their tests suggest best fits the data.

17

ftm

Qm
Q `
Q
m
= cQ
m + ρmm ft−1 + ρm` ft−1 + Σmm ut

(21)

(Nm ×1)

ft`

Qm
Q `
Q m
+ Σ`` uQ`
= cQ
t
` + ρ`m ft−1 + ρ`` ft−1 + Σ`m ut

(N` ×1)

rt = δ 0 + δ 01m ftm + δ 01` ft` .

(22)

Pericoli and Taboga proposed the normalization conditions8 that Σmm is lower triangular,
Σ`m = 0, Σ`` = IN` , δ 1` ≥ 0, and cQ
` = 0.
Our empirical illustration of this approach will use t corresponding to quarterly data and
will take the 1-, 5-, and 10-year bonds to be priced without error (Yt1 = (yt4 , yt20 , yt40 )0 ) and the
2-, 3-, and 7-year bonds to be priced with error (Yt2 = (yt8 , yt12 , yt28 )0 ). Details of how the log
likelihood is calculated for this example are described in Appendix A.

2.4

Example 3: Macro finance model with 12 lags (MF12).

A first-order VAR is not sufficient to capture the observed dynamics of output and inflation.
For example, Ang and Piazzesi (2003) suggested that the best fit is obtained using a monthly
VAR(12) in the observable macro variables and a VAR(1) for the latent factors:9

m
m
m
ftm = ρ1 ft−1
+ ρ2 ft−2
+ · · · + ρ12 ft−12
+ Σmm um
t
`
+ Σ`` u`t .
ft` = c` + ρ`` ft−1

Pericoli and Taboga imposed f0` = 0 as an alternative to the traditional c` = 0 or cQ
` = 0, though we will
follow the rest of the literature here in using a more standard normalization.
9
Ang and Piazzesi refer to this as their Macro Model.
8

18

Our empirical example follows Ang and Piazzesi in proxying the 2 elements of ftm with the
first principal components of a set of output and and a set of inflation measures, respectively,
which factors have mean zero by construction. Ang and Piazzesi treated the macro dynamics
as independent of those for the unobserved latent factors, so that terms such as ρ`m and ρm`
in the preceding example are set to zero.
Ang and Piazzesi (2003) further proposed the following identifying restrictions: Σmm is
lower triangular, Σ`` = IN` , c` = 0, ρ`` is lower triangular, and the diagonal elements of ρ`` are
in descending order. Further restrictions and details of the model and its likelihood function
are provided in Appendix B. In the specification we replicate, Ang and Piazzesi postulated
that the short rate depends only on the current values of the macro factors:

0

0

rt = δ 0 + δ 1m ftm + δ 1` ft` .

They further noted that since ft` is independent of ftm under their assumptions, the values of
δ 0 and δ 1m in the short-rate equation can be obtained by OLS estimation of

0

rt = δ 0 + δ 1m ftm + vt .

(23)

To further reduce the dimensionality of the estimation, Ang and Piazzesi (2003) proposed
some further restrictions on this set-up that we will discuss in more detail in Section 4.4.

19

3

Identification.

The log likelihood function for each of the models discussed– and indeed, for any Gaussian
affine term structure model in which exactly N` linear combinations of yields are assumed to be
priced without error– takes the form of a restricted vector autoregression. The mapping from
the affine-pricing parameters to the VAR parameters allows us to evaluate the identifiability
of a given structure. If two different values for the structural parameters imply the identical
reduced-form parameters, there is no way to use observable data to choose between the two.
We now explore the implications of this fact for each of the three classes of models described
in the previous section.

3.1

Example 1: Latent factor model.

Premultiplying (1) by B1 (and recalling the normalization c = 0 and Σ = IN` ) results in

B1 Ft = B1 ρB1−1 B1 Ft−1 + B1 ut .

Adding A1 to both sides and substituting Yt1 = A1 + B1 Ft establishes

1
Yt1 = A∗1 + φ∗11 Yt−1
+ u∗1t

(24)

A∗1 = A1 − B1 ρB1−1 A1

(25)

φ∗11 = B1 ρB1−1 .

(26)

20

Likewise the second block of (17) implies



Yt2 = A∗2 + φ∗21 Yt1 + u∗2t

(27)

A∗2 = A2 − B2 B1−1 A1

(28)

φ∗21 = B2 B1−1
  

(29)





 u∗1t 
 0   Ω∗ 0 

 ∼ N   ,  1



  

u∗2t
0
0 Ω∗2
0

(30)

Ω∗1 = B1 B1

(31)

Ω∗2 = Σe Σ0e .

(32)

Equations (24) and (27) will be recognized as a restricted Gaussian VAR for Yt , in which
1
a single lag of Yt−1
appears in the equation for Yt1 and in which, after conditioning on the

contemporaneous value of Yt1 , no lagged terms appear in the equation for Yt2 . Note that when
we refer to the reduced-form for this system, we will incorporate those exclusion restrictions
along with the restriction that Ω∗2 is diagonal.
Table 2 summarizes the mapping between the VAR parameters and the affine term structure parameters implied by equations (24)-(32).10

The number of VAR parameters minus

the number of structural parameters is equal to (Ne − 1)(N` + 1). Thus the structure is
just-identified by a simple parameter count when Ne = 1 and overidentified when Ne > 1.
Notwithstanding, the structural parameters can nevertheless be unidentified despite the ap10

The value of δ 1 turns out not to appear in the product φ∗21 = B2 B1−1 .

21

parent conclusion from a simple parameter count.
Consider first what happens at a point where one of the eigenvalues of ρ is unity, that
is, when the P -measure factor dynamics exhibit a unit root.11

This means that one of

the eigenvalues of B1 ρB1−1 is also unity (B1 ρB1−1 x = x for some nonzero x) requiring that
(IN` − B1 ρB1−1 )x = 0, so the matrix IN` − B1 ρB1−1 is noninvertible. In this case, even if we
knew the true value of A∗1 , we could never find the value of A1 from equation (25). If Â1 is
proposed as a fit for a given sample, then Â1 + kx produces the identical fit for any k. Note
moreover from (16) that A1 and A2 are the only way to find out about cQ and δ 0 ; if we don’t
know the 4 values in A1 and A2 , we can never infer the 4 values of cQ and δ 0 . This failure of
local identification accounts for the numerous failed searches described in Section 2.2. When
the search steps in a region in which ρ has a near unit root, the likelihood surface becomes
extremely flat in one direction (and exactly flat at the unit root), causing the numerical search
to become bogged down. Because the true process is quite persistent, it is extremely common
for a numerical search to explore this region of the surface and become stuck.12
If instead we used the normalization cQ = 0 in place of the condition c = 0 just analyzed, a
similar phenomenon occurs in which a unit root in ρQ results in a failure of local identification
of δ 0 .
Even when all eigenvalues of ρ are less than unity, there is another respect in which the
latent factor model discussed here is unidentified.13 Let H denote any (N` × N` ) matrix such
11

Note we have followed Ang and Piazzesi (2003) and Joslin, Singleton, and Zhu (2011), among others, in
basing estimates on the likelihood function conditional on the first observation. By contrast, Chen and Scott
(1993) and Duffee (2002) included the unconditional likelihood of the first observation as a device for imposing
stationarity.
12
This point has also been made by Aı̈t-Sahalia and Kimmel (2010).
13
This has also been recognized by Ang and Piazzesi (2003), Collin-Dufresne, Goldstein, and Jones (2008)
and Aı̈t-Sahalia and Kimmel (2010).

22

0

that H 0 H = IN` . It is apparent from equations (24)-(32) that if we replace Bj by Bj H and
ρ by HρH 0 , there would be no change in the implied value for the sample likelihood. The
question then is whether the conditions imposed on the underlying model rule out such a
transformation. From equation (16), such a transformation requires replacing cQ with HcQ ,
and from (15) we need now to use Hδ 1 and HρQ H 0 . Since our specification imposed no
restrictions on ρ or cQ , the question is whether the proposed lower triangular structure for ρQ
and nonnegativity of δ 1 rules out such a transformation. The following proposition establishes
that it does not.
Proposition 1. Consider any (2 × 2) lower triangular matrix:




Q
 ρ11 0 
.

ρ =

Q
Q
ρ21 ρ22
Q

Then for almost all (2×1) positive vectors δ 1 , there exists a unique orthogonal matrix H other
than the identity matrix such that HρQ H 0 is also lower triangular and Hδ 1 > 0. Moreover,
HρQ H 0 takes one of the following forms:






ρQ
22
ρQ
21




ρQ
22

0 
0 

 or 
.



Q
Q
Q
ρ11
−ρ21 ρ11

For ρQ an (N` × N` ) lower triangular matrix, there are N` ! different lower triangular representations, characterized by alternative orderings of the principal diagonal elements.
There thus exist 6 different parameter configurations that would achieve the same maximum for the likelihood function for the latent example explored in Section 2.2. The experiment
23

did not uncover them because the other difficulties with maximization were sufficiently severe
that for the 100 different starting values used, only one of these 6 configurations was reached.
Dai and Singleton (2000) and Singleton (2006) originally proposed lower triangularity of ρ
or ρQ and nonnegativity of δ 1 as sufficient identifying conditions.

Our proposition estab-

Q
Q
lishes that one needs a further condition such as ρQ
11 ≥ ρ22 ≥ ρ33 to have a globally identified

structure.
Nevertheless, this multiplicity of global optima is a far less serious problem than the failure
of local identification arising from a unit root.

The reason is that any of the alternative

configurations obtained through these H transformations by construction has the identical
implications for bond pricing. By contrast, the inferences one would draw from Local 53 in
Table 1 are fundamentally flawed and introduce substantial practical difficulties for using this
class of models.
There is another identification issue, which has separately been recognized by Joslin, Singleton, and Zhu (2011) using a very different approach from ours: not all matrices ρQ can be
transformed into lower triangular form. For example, for N` = 2, if ρQ is written as lower
triangular, then ρQ
22 would have to be one of its eigenvalues. However, it is possible for an
unrestricted real-valued matrix ρQ to have complex eigenvalues, in which case there is no way
to transform it as Υ = HρQ H 0 for Υ a real-valued lower triangular matrix. We propose in the
following proposition an alternative normalization for the case N` = 2 that, unlike the usual
lower-triangular form, is completely unrestrictive.

24

Proposition 2. Consider ρQ any (2 × 2) real-valued matrix:


ρQ = 



ρQ
11

ρQ
12

Q
ρQ
21 ρ22


.


For almost all δ 1 ∈ R2+ , there exist exactly two transformations of the form Υ = HρQ H 0 such
that Υ is real, H 0 H = I2 , Hδ 1 > 0, and the two elements on the principal diagonal of Υ are
the same. Moreover, one of these transformations is simply the transpose of the other:








 a c 
.
Υ2 = 


b a

 a b 

Υ1 = 


c a

Hence one approach for the N` = 2 case would be to choose the 3 parameters a, b, and c
so as to maximize the likelihood with




 a b 

ρQ = 


c a

subject to the normalization b ≤ c. This has the advantage over the traditional lowertriangular formulation in that the latter imposes additional restrictions on the dynamics
(namely, lower-triangular ρQ rules out the possibility of complex roots) whereas the Υ formulation does not.
Unfortunately, it is less clear how to generalize this to larger dimensions. If ρQ has complex
eigenvalues, these always appear as complex conjugates. Thus if one knew for the case N` = 3

25

that ρQ contained complex eigenvalues, a natural normalization would be



Q
0
 ρ11 0


Q
Q
ρQ = 
 ρ21 a ρ23


Q
a
ρQ
31 ρ32

Q
with ρQ
23 ≤ ρ32









(33)

The value of a is then uniquely pinned down by the real part of the complex

eigenvalues. However, if the eigenvalues are all real, this is a more awkward form than the
usual




ρQ
11

0
0



Q
Q
ρQ = 
 ρ21 ρ22 0


Q
Q
ρQ
31 ρ32 ρ33









(34)

Q
Q
with ρQ
11 ≥ ρ22 ≥ ρ33 . The estimation approach that we propose below will instantly reveal

whether or not the lower triangular form (34) is imposing a restriction relative to the fullinformation maximum likelihood unrestricted values.

If (34) is determined not to impose

a restriction, one can feel confident in using the conventional parameterization, whereas if
it does turn out to be inconsistent with the estimated unrestricted dynamics, the researcher
should instead parameterize dynamics using (33).

26

3.2

Example 2: Macro finance model with single lag.

We next examine the MF1 specification of Pericoli and Taboga (2008). Calculations similar
to those for the latent factor model show the reduced form to be

ftm

=

(Nm ×1)

(Nm ×1)

Yt1

=

(N` ×1)

Yt2
(Ne ×1)

1
m
+ u∗mt
+ φ∗m1 Yt−1
A∗m + φ∗mm ft−1
1
m
+ ψ ∗1m ftm + u∗1t
+ φ∗11 Yt−1
A∗1 + φ∗1m ft−1
(N` ×1)

=

(N` ×N` )

(N` ×Nm )

(36)

(N` ×Nm )

A∗2 + φ∗2m ftm + φ∗21 Yt1 + u∗2t .
(Ne ×1)

(35)

(Nm ×N` )

(Nm ×Nm )

(37)

(Ne ×N` )

(Ne ×Nm )

Once again it is convenient to include the contemporaneous value of ftm in the equation for
Yt1 and include contemporaneous values of both ftm and Yt1 in the equation for Yt2 in order to
orthogonalize the reduced-form residuals u∗jt ; the benefits of this representation will be seen
in the next section. The mapping between structural and reduced-form parameters is given

27

by the following equations and summarized in Table 3 with Nf = Nm + N` :

−1
A∗m = cm − ρm` B1`
A1

(38)

−1
B1m
φ∗mm = ρmm − ρm` B1`

(39)

−1
φ∗m1 = ρm` B1`

(40)

−1
A1
A∗1 = A1 + B1` c` − B1` ρ`` B1`

(41)

−1
B1m
φ∗1m = B1` ρ`m − B1` ρ`` B1`

(42)

−1
φ∗11 = B1` ρ`` B1`

(43)

ψ ∗1m = B1m

(44)

−1
A∗2 = A2 − B2` B1`
A1

(45)

−1
φ∗2m = B2m − B2` B1`
B1m

(46)

−1
φ∗21 = B2` B1`




u∗mt




Var 
 u∗1t


u∗2t

(47)




Ω∗m







 =  0






0

0
Ω∗1
0





0  
 
 

0 
=
 
 
Ω∗2

Σmm Σ0mm

0

0

0

0
B1` B1`

0

0

0

Σe Σ0e









(48)

with Ω∗2 diagonal and B1 and B2 partitioned as described in Appendix A.
Once again inspection of the above equations reveals that the structure is unidentified.
One can see this immediately for the case N` = 3, Nm = 2, Ne = 3 simply by counting
parameters– there are 69 unknown structural parameters and only 66 reduced-form parameters
from which they are supposed to be inferred. The problem arises in particular from the fact
28

that, for the example we have been discussing, the observable implications of the 30 structural
parameters in ρQ and δ 1 are completely captured by the 27 values of ψ ∗1m , φ∗2m , φ∗21 , and Ω∗1 .
More fundamentally, the lack of identification would remain with this structure no matter
how large the value of Ne . One can see this by verifying that the following transformation
is perfectly allowed under the stated normalization but would not change the value of any
reduced-form parameter: B1` → B1` H 0 , c` → Hc` , ρm` → ρm` H 0 , ρ`` → Hρ`` H 0 , ρ`m → Hρ`m ,
and B2` → B2` H 0 , where H could be any (N` × N` ) orthogonal matrix.
There is also a separate identification problem arising from the fact that only maturities for which n is an even number are included in the observation set.

This means that

only even powers of ρQ appear in (15) and (16), which allows observationally equivalent sign
transformations through H as well.

3.3

Example 3: Macro finance model with 12 lags.

Last we consider the MF12 example, for which the reduced form is

ftm
(2×1)

Yt1
(3×1)

Yt2
(2×1)

m
= φ∗mm Ft−1
+ u∗mt

(49)

(2×24)
1
m
= A∗1 + φ∗1m Ft−1
+ φ∗11 Yt−1
+ ψ ∗1m ftm + u∗1t
(3×3)

(3×24)

= A∗2 + φ∗2m Ftm + φ∗21 Yt1 + u∗2t
(2×24)

(2×3)

29

(50)

(3×2)

(51)

φ∗mm




=

ρ1 ρ2 · · ·

ρ12

−1
A∗1 = A1 − B1` ρ`` B1`
A1
"
#

φ∗1m
(3×24)

φ∗11

=

(1)
B1m
(3×22)

0
(3×2)

"

−1
− B1` ρ`` B1`
(3×3)

#
(0)
B1m
(3×2)

(1)
B1m
(3×22)

−1
= B1` ρ`` B1`
(0)

ψ ∗1m = B1m
−1
A∗2 = A2 − B2` B1`
A1
−1
φ∗2m = B2m − B2` B1`
B1m
−1
φ∗21 = B2` B1`




u∗mt





Var 
 u∗1t


u∗2t

Ω∗m







 =  0






0


0
Ω∗1
0




0

0
0
0   Σmm Σmm
 
 
0

0 
0
B1` B1`
0
=
 
 
0
0
Σe Σ0e
Ω∗2









with Ω∗2 again diagonal and details on the partitioning of B1 and B2 in Appendix B. Table
4 summarizes the mapping between reduced-form and structural parameters. Note that the
only reduced-form parameters relevant for inference about the 6 elements of δ 0 and λ are the
5 values for A∗1 and A∗2 , establishing that these structural parameters are in fact unidentified.
One might have thought that perhaps δ 0 could be inferred separately from the OLS regression
(23), freeing up the parameters A∗1 and A∗2 for estimation solely of λ. However, this is not the
case, since the short-term interest rate is the same dependent variable in both regression (23)
and in the first OLS regression from which A∗1 is inferred. Another way to see this is to note
that at most what one can expect to uncover from the 5 values of A∗1 and A∗2 are the 5 values
of A1 and A2 . The first element of A1 is exactly equal to δ 0 , so even if δ 0 were known a priori,
30

the most that one could infer from A1 and A2 is 4 other parameters. Hence A1 and A2 would
not be sufficient to uncover the 5 unknowns in λ even if δ 0 were known with certainty.
Ang and Piazzesi’s (2003) Macro Model with its proposed identifying restrictions thus turns
out to be unidentified at all points of the parameter space. In their empirical analysis, Ang and
Piazzesi imposed an additional set of restrictions that were intended to improve estimation
efficiency, though as we have just seen some of these are necessary for identification.

We

discuss these further in Section 4.4 below.

4

Estimation.

The reduced-form parameters are trivially obtained via OLS. Hence a very attractive alternative to numerical maximization of the log likelihood function directly with respect to the
structural parameters θ is to let OLS do the work of maximizing the likelihood with respect
to the reduced-form parameters, and then translate these into their implications for θ. We
demonstrate in this section how this can be done.

4.1

Minimum-chi-square estimation.

Let π denote the vector consisting of reduced-form parameters (VAR coefficients and nonredundant elements of the variance matrices), L(π; Y ) denote the log likelihood for the entire
sample, and π̂ = arg max L(π; Y ) denote the full-information-maximum-likelihood estimate.

31

If R̂ is a consistent estimate of the information matrix,

R = −T

−1

∂ 2 L(π; Y )
E
∂π ∂π 0




then we could test the hypothesis that π = g(θ) for θ a known vector of parameters by
calculating the usual Wald statistic

T [π̂ − g(θ)]0 R̂ [π̂ − g(θ)]

(52)

which would have an asymptotic χ2 (q) distribution under the null hypothesis where q is the
dimension of π. Rothenberg (1973, p. 24) noted that one could also use (52) as a basis for
estimation by choosing as an estimate θ̂ the value that minimizes this chi-square statistic.
Following Rothenberg (1973, pp. 24-25), we can obtain asymptotic standard errors by
considering the linear approximation g(θ) ' γ +Γθ for Γ = ∂g(θ)/∂θ0 |θ=θ0 and γ = g(θ0 )−Γθ0
p

where π̂ → π 0 and we assume there exists a value of θ0 for which the true model satisfies
∗

g(θ0 ) = π 0 . Define the linearized minimum-chi-square estimator θ̂ as the solution to

min T [π̂ − γ − Γθ]0 R [π̂ − γ − Γθ] ,
θ

∗

∗

∗

that is, θ̂ satisfies Γ0 R(π̂ − γ − Γθ̂ ) = 0 or θ̂ = (Γ0 RΓ)−1 Γ0 R(π̂ − γ). Since
L

π 0 ) → N (0, R−1 ), it follows that

√

∗

√

T (π̂ −

L

T (θ̂ − θ0 ) → N (0, [Γ0 RΓ]−1 ) . Hence our proposal is to

approximate the variance of θ̂ with T −1 (Γ̂0 R̂Γ̂)−1 for Γ̂ = ∂g(θ)/∂θ0 |θ=θ̂ .
We show in Appendix E that this is in fact identical to the usual asymptotic variance

32

for the MLE as obtained from second derivatives of the log likelihood function directly with
respect to θ. In other words, the MCSE and MLE are asymptotically equivalent, and the
MCSE inherits all the asymptotic optimality properties of the MLE. If in a particular sample
the MCSE and MLE differ, there is no basis for claiming that one has better properties than
the other.
In the case of a just-identified model, the minimum value attainable for (52) is zero, in
which case one can without loss of generality simply minimize

[π̂ − g(θ)]0 [π̂ − g(θ)] .

(53)

Note that in this case, if the optimized value for this objective is zero, then θ̂ is numerically identical to the value that achieves the global maximum of the likelihood written as a
function of θ. Although θ̂M CSE in this case is identical to θ̂M LE , arriving at the estimate
by the minimum-chi-square algorithm has two big advantages over the traditional brute-force
maximization of the likelihood function. First, one knows instantly whether θ̂ corresponds
to a global maximum of the original likelihood surface simply by checking whether a zero
value is achieved for (53). By contrast, under the traditional approach, one has to try hundreds of starting values to be persuaded that a global maximum has been found, and even
then cannot be sure. A second advantage is that minimization of (52) or (53) is far simpler
computationally than brute-force maximization of the original likelihood function.
In addition, the greater computational ease makes calculation of small-sample confidence
intervals feasible. The models considered here imply a reduced form that can be written in

33

companion form as
Yt = k + ΦYt−1 + ΣY ut
for Yt the (N × 1) vector of observed variables (yields, macro variables, and possible lags
of macro variables) and ut ∼ N (0, IN ), where the parameters k, Φ, and ΣY are known
functions of π. We can then obtain bootstrap confidence intervals for θ as follows.

For

(j)

artificial sample j, we will generate a sequence {ut }Tt=1 of N (0, IN ) variables for T the
(j)

original sample size, and then recursively generate Yt
(j)

t = 1, 2, ..., T, starting from Y0

(j)

(j)

= k(π̂) + Φ(π̂)Yt−1 + ΣY (π̂)ut

for

= Y0 , the initial value from the original sample, and using

the identical parameter values k, Φ, and ΣY (as implied by the original π̂) for each sample
j. On sample j we find the FIML estimate π̂ (j) on that artificial sample and then calculate
h
i0
h
i
(j)
θ̂ = arg minT π̂ (j) − g(θ) R̂(j) π̂ (j) − g(θ) . We generate a sequence j = 1, 2, ..., J of such
θ

samples, from which we could calculate 95% small-sample confidence intervals for each element
of θ. The small-sample standard errors for parameter i reported in the following section were
q
P
(j)
calculated from J −1 Jj=1 (θ̂i,M CSE − θ̂i )2 where θ̂i is the MCSE estimate for the original
(j)

sample (whose original FIML π̂ was used to generate each artificial sample j) and θ̂i,M CSE is
the minimum-chi-square estimate for artificial sample j.
We now illustrate these methods and their advantages in detail using the examples of affine
term structure models discussed above.

4.2

Example 1: Latent factor model.

In the case of Ne = 1, the latent factor model is just-identified, making application of
minimum-chi-square estimation particularly attractive.
34

The reduced-form parameter vec-

tor here is

π=

!0
0 0
0 0




∗
0
∗
0
, [diag(Ω2 )]
, [vech(Ω1 )] , vec
vec
A∗2 φ∗21
A∗1 φ∗11

where vec(X) stacks the columns of the matrix X into a vector. If X is square, vech(X) does
the same using only the elements on or below the principal diagonal, and diag(X) constructs a
vector from the diagonal elements of X. Because u∗1t and u∗2t are independent, full-informationmaximum-likelihood (FIML) estimation of π is obtained by treating the Y1 and Y2 blocks
separately.

Since each equation of (24) has the same explanatory variables, FIML for the

1
, with Ω̂∗1 the
ith row of [A∗1 , φ∗11 ] is obtained by OLS regression of Yit1 on a constant and Yt−1

matrix of average outer products of those OLS residuals:

Ω̂∗1 = T −1

T
X

∗

∗

1
1
(Yt1 − Â∗1 − φ̂11 Yt−1
)(Yt1 − Â∗1 − φ̂11 Yt−1
)0 .

t=1

FIML estimates of the remaining elements of π are likewise obtained from OLS regressions
of Yit2 on a constant and Yt1 .
The specific mapping in Table 2 suggests that we can use the following multi-step algorithm
to minimize (53) for the latent factor model with N` = 3 and Ne = 1.
Step 1. The estimate of Σe is obtained analytically from the square root of Ω̂∗2 .
Step 2. The estimates of the 9 unknowns in ρQ and δ 1 are found by numerically solving
the 9 equations in (29) and (31)

∗

[B2 (ρ̂Q , δ̂ 1 )][B1 (ρ̂Q , δ̂ 1 )]0 = φ̂21 Ω̂∗1
35

[B1 (ρ̂Q , δ̂ 1 )][B1 (ρ̂Q , δ̂ 1 )]0 = Ω̂∗1 .
i0
h
∗
Specifically, we do this by letting14 π̂ 2 = ( vec(φ̂21 Ω̂∗1 ) , [vech(Ω̂∗1 )]0 )0 and g2 (ρQ , δ 1 ) = ([vec(B2 B10 )]0 ,
0

[vech(B1 B1 )]0 )0 and finding ρ̂Q and δ̂ 1 by numerical minimization of [π̂ 2 − g2 (ρQ , δ 1 )]0 [π̂ 2 −
g2 (ρQ , δ 1 )].
Step 3. The estimate of ρ can then be obtained analytically from (26):

∗

ρ̂ = B̂1−1 φ̂11 B̂1

(54)

where B̂1 is known from Step 2.
Step 4. Numerically solve the 4 unknowns in δ 0 and cQ from the 4 equations in Â∗1 and
Â∗2 using (25) and (28):



I3 −

B̂1 ρ̂B̂1−1



A1 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) = Â∗1

A2 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) − B̂2 B̂1−1 A1 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) = Â∗2 .
Although Steps 2 and 4 involve numerical minimization, these are computationally far simpler problems than that associated with traditional brute-force maximization of the likelihood
function with respect to the full vector θ.

To illustrate this, we repeated the experiment

described in Section 2.2 with the same 100 starting values. Whereas we saw in Section 2.2
14

To assist with scaling for numerical robustness, we multiplied each equation in step 2 by 1200 × 1.e+7 and
those in step 4 below by 1.e+8. If we were minimizing (52) directly one would automatically achieve optimal
scaling by using R̂ in place of a constant k times the identity matrix as here. However, our formulation takes
advantage of the fact that the elements of π̂ can be rearranged in order to avoid inversion of B1 inside the
numerical optimization, in which case R̂ is no longer the optimal weighting matrix. The minimization was
implemented using the fsolve command in MATLAB. We also multiplied δ 1 by 1000 to improve numerical
robustness.

36

that only one of these efforts found the global maximum under the traditional approach, with
our method all 100 converge to the global MLE in one of the 6 configurations that are observationally equivalent for the original normalization. One of the reasons for the greater robustness
is that the critical stumbling block for the traditional method– numerical search over ρ– is
completely avoided since in our approach (54) is solved analytically. Another is that cQ and
uncertainties about its scale are completely eliminated from the core problem of estimation of
ρQ and δ 1 .
Joslin, Singleton, and Zhu (2011) have recently proposed a promising alternative parameterization of the pure latent affine models that shares some of the advantages of our approach.
They parameterize the system such that A∗1 and φ∗11 in (24) are taken to be the direct objects of interest, and as in our approach, estimate these directly with OLS. But whereas our
approach also uses the OLS estimates of A∗2 and φ∗21 in (27) to uncover the remaining affinepricing parameters, their approach finds these by maximizing the joint likelihood function of
Y1 and Y2 . Although they report that the second step involves no numerical difficulties, our
experience is that while it offers a significant improvement over the traditional method, it is
still susceptible to some of the same problems.

For example, we repeated the experiment

described above with the same data set and same starting values for δ 0 and the 3 unknown
diagonal elements in ρQ that appear in their parameterization as we used in the simulations
described above, starting the search for Ω∗1 from the OLS estimates as they recommend. We
found that the algorithm found the global maximum in 54 out of the 100 trials15 , but got
stuck in regions with diagonal elements of ρQ equal to unity in the others, in a similar failure
To assist the numerical search, we multiplied Ω∗1 by 1000. Without this scaling, the searches only succeeded
in finding the global maximum in 14 of the 100 trials.
15

37

of local identification that we documented above can plague the traditional approach.
We applied our method directly to the Ang and Piazzesi interest rate data described in
more detail in Section 4.4 below. Table 5 reports the resulting minimum-chi-square estimates
(identical in this case to the full-information-maximum-likelihood estimates). The table also
reports asymptotic standard errors in parentheses and small-sample standard errors in square
brackets. The latter were calculated by applying our method to each of 1000 separate data
sets, each generated from the vector autoregression estimated from the original data set. Note
that the fact that we can verify with certainty that the global maximum has been found on
each of these 1000 simulated data sets is part of what makes calculation of small-sample
standard errors feasible and attractive. Finding the FIML estimate on 1000 data sets takes
about 90 seconds on a PC. For this example, we find that the asymptotic standard errors
provide an excellent approximation to the true small-sample values.
Although our original inference was conducted in terms of a Q representation, we report
the implied λ representation values in the right-hand columns of Table 5, since that is the
form in which parameter estimates are often reported for these models.

Our suggestion is

that the approach we illustrate here, of beginning with a completely unrestricted model to
see which parameters appear to be most significant, has many advantages over the traditional
approach16 in which sundry restrictions are imposed at a very early stage, partly in order to
assist with identification and estimation.
16

See for example Duffee (2002) and Duarte (2004).

38

4.3

Example 2: Macro finance model with single lag.

We also applied this procedure to estimate parameters for our MF1 example using a slightly
different quarterly data set from Pericoli and Taboga. We used constant-maturity Treasury
yields as of the first day of the quarter, dividing the numbers as usually reported by 400 in
order to convert to units of quarterly yield on which formulas such as (14) are based.

We

estimated inflation from the 12-month percentage change in the CPI and the output gap by
applying the Hodrick-Prescott filter with λ = 1600 to 100 times the natural log of real GDP.
Data run from 1960:Q1 to 2007:Q1 and were obtained from the FRED database of the Federal
Reserve Bank of St. Louis.
If we impose 3 further restrictions on ρQ
`` relative to the original formulation, the MF1
model presented above would be just-identified in terms of parameter count, for which we
would logically again simply try to invert the reduced-form parameter estimates to obtain
the FIML estimates of the structural parameters. Once again orthogonality of the residuals
across the three blocks of (35) through (37) means FIML estimation can be done on each block
separately, and within each block implemented by OLS equation by equation. Our estimation
procedure on this system is then as follows.
Step 1. The ftm and Yt2 variance parameters are obtained analytically from (48), that is,
Σ̂mm from the Cholesky factorization of Ω̂∗m and Σ̂e from the square root of Ω̂∗2 .
Step 2. Using (44), (46), (48), and (47), choose the values of ρQ and δ 1 so as to solve the

39

following equations numerically17 :

∗

B1m (ρQ , δ 1 ) = ψ̂ 1m

∗

∗

∗

B2m (ρQ , δ 1 ) = φ̂2m + φ̂21 ψ̂ 1m
vech

n
 

0 o
B1` (ρQ , δ 1 ) B1` (ρQ , δ 1 )
= vech Ω̂∗1


0
∗
B2` (ρQ , δ 1 ) B1` (ρQ , δ 1 ) = φ̂21 Ω̂∗1 .

We initially tried to solve this system for ρQ
`` of the lower-triangular form (34), but found no
solution exists, indicating that the FIML estimate of ρQ
`` has complex roots. We accordingly
reparameterized ρQ
`` in the form (33), for which an exact solution was readily obtained.
Step 3. From these estimates one then analytically can calculate ρ̂m` , ρ̂mm , ρ̂`` , and ρ̂`m
∗

∗

∗

∗

from φ̂m1 , φ̂mm , φ̂11 , and φ̂1m , respectively.
Step 4. Since cm and c` are unrestricted, the values of δ 0 and cQ can be inferred solely
from A∗2 by numerical solution of (45):

−1
A2 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) − B̂2` B̂1`
Â1 (δ 0 , cQ , ρ̂Q , δ̂ 1 ) = Â∗2 .

Step 5. We then can calculate the remaining parameters analytically using (38) and (41):

−1
ĉm = Â∗m + ρ̂m` B̂1`
Â1
17

To improve accuracy of the numerical algorithm, we multiplied the last two equations by 400 and then
the whole set of equations by 1.e+7. The parameter δ 1 was also scaled by 100.

40



−1
−1
ĉ` = B̂1`
Â∗1 − Â1 + B̂1` ρ̂`` B̂1`
Â1 .
Table 6 reports the FIML estimates obtained by the above algorithm along with asymptotic
standard errors. These estimates would cause one to be cautious about the proposed model–
standard errors are quite large, and 3 eigenvalues of the estimated ρQ matrix are outside the
unit circle. We found small-sample standard errors much more difficult to calculate for this
example, in part because the value of ρQ associated with a given π̂ (j) can have anywhere from
zero to four complex eigenvalues, with eigenvalues of the ρQ
`` submatrix sometimes greater than
2 in modulus. Our interpretation is that further restrictions on the interaction between the
macro and latent factors could be helpful for this class of models.

4.4

Example 3. Macro finance model with 12 lags.

Here our data set follows Ang and Piazzesi (2003) as closely as possible, using zero-coupon
bond yields with maturities of 1, 3, 12, 36 and 60 months from CRSP monthly treasury file,
each divided by 1200 to quote as monthly fractional rates. We obtained two groups of monthly
US macroeconomic key indicators, seasonally adjusted if applicable, from Datastream. The
first group consists of various inflation measures which are based on the CPI, the PPI of finished
goods, and the CRB Spot Index for commodity prices. The second group contains variables
that capture real activity: the Index of Help Wanted Advertising, Unemployment Rates, the
growth rate of Total Civilian Employment and the growth rate of Industrial Production. All
growth rates and inflation rates are measured as the difference in logs of the monthly index
value between dates t and t−12. We first normalized each series separately to have zero mean

41

and unit variance, then extracted the first principal component of each group, designated the
“inflation” and “real activity” indices, respectively, with each index having zero mean and unit
variance by construction. The sample period for yields is from December 1952 to December
2000, and that for the macro indices is from January 1952 to December 2000. We assume
that 1-, 12- and 60-month yields are priced exactly, and 3- and 36-month yields are priced
with error (Ne = 2). We use the Ang and Piazzesi (2003) Macro Model with their additional
proposed zero restrictions to illustrate minimum-chi-square estimation for an overidentified
model.
The reduced-form equations (49)-(51) form 3 independent blocks. If we interpret Ytm =
ftm , we can write the structure of block i for i = 1, 2, m as

Yti =
(qi ×1)

Π0i xit + u∗it

(qi ×ki )(ki ×1)

(qi ×1)

u∗it ∼ N (0, Ω∗i ).
The information matrix for the full system of reduced-form parameters is




 R̂m 0 0


R̂ = 
 0 R̂1 0


0
0 R̂2

42









where as in Magnus and Neudecker (1988, p. 321)



Ω̂∗−1
i


R̂i = 


⊗T

−1

PT

t=1

0

xit xit

0
0









Dqi
(1/2)Dqi Ω̂∗−1
⊗ Ω̂∗−1
i
i

0

for DN the N 2 × N (N + 1)/2 duplication matrix satisfying DN vech(Ω) = vec(Ω).
The structural parameters Σe appear only in the last half of the third block, no other
parameters appear in this block, and these 2 structural parameters are just-identified by
the 2 diagonal elements of Ω∗2 . Thus the minimum-chi-square estimates of Σe are obtained
immediately from the square roots of diagonal elements of Ω̂∗2 .

The structural parameters

ρ1 , ..., ρ12 appear directly in the first block and, through ρQ , in the second and third blocks
as well, so FIML or minimum-chi-square estimation would exploit this. However, to reduce
dimensionality, we follow Ang and Piazzesi in replacing ρ2 , ..., ρ12 where they appear in ρQ with
the OLS estimates ρ̂2 , ..., ρ̂12 . In order to try to replicate their setting as closely as possible,
we also follow their procedure of imposing δ̂ 1m on the basis of OLS estimation of (23). Hence
the minimum-chi-square analog to their problem is to minimize an expression of the form of
(52) with
π̂ =

h

i0 h
 i0 h
 i0 0
∗
vec Π̂1
, vech Ω̂1
, vec Π̂2


(55)





R̂ = 





Ω̂∗−1
1

⊗T

−1

PT

t=1

0

x1t x1t

0
0



0


0

⊗ Ω̂∗−1
D3
(1/2)D3 Ω̂∗−1
1
1

0

0
m0
10
x1t = (1, Ft−1
, Yt−1
, ftm0 )0

43

0
Ω̂∗−1
⊗ T −1
2

PT

t=1

0

x2t x2t









x2t = (1, Ftm0 , Yt10 )0
0

Π̂i =

T
X

!
0

Yti xit

=T

−1

!−1
0

xit xit

for i = 1, 2

t=1

t=1

Ω̂∗1

T
X

T 
X

Yt1


0
0
1
− Π̂1 x1t Yt − Π̂1 x1t
0

t=1





 [û2t (1)]2 · · ·
T 
X

..
..
∗
−1

Ω̂2 = T
.
.

t=1 

0
···

0
..
.
[û2t (Ne )]2









0

with û2t (j) the jth element of Yt2 − Π̂2 x2t .
Ang and Piazzesi also imposed a further set of restrictions on parameters, setting parameters with large standard errors as estimated in their first stage to zero. Their understanding
was that the purpose of these restrictions was to improve efficiency, though we saw in Section
3.3 that some of these restrictions are in fact necessary in order to achieve identification. Our
purpose here is to illustrate the minimum-chi-square method on an overidentified structure,
and we therefore attempt to estimate their final proposed structure using our method. The
additional parameters that Ang and Piazzesi fixed at zero include the (2,1) and (3,1) elements
of ρ`` (which recall was already lower triangular), the (1,2), (2,2), (3,2) and (1,3) elements of
Λ`` , both elements in λm , and the 2nd and 3rd elements of λ` . Our goal is then to minimize
(52) with respect to the 17 remaining unknown parameters, 1 in λ` , 4 in Λmm , 5 in Λ`` , 4 in
ρ`` , and 3 in δ 1` .18
18

We made one other slight change in parameterization that may be helpful. Since Λ`` always enters
either the minimum-chi-squared calculations or the original maximum likelihood estimation in the form of
high powers of the matrix ρQ
`` = ρ`` − Λ`` , the algorithms will be better behaved numerically if the unknown
elements of ρQ
rather
than
those
of Λ`` are taken to be the object of interest. Specifically, for this example
``

44

The results of this estimation for 100 different starting values are reported in Table 7.
Our procedure uncovered three local minima to the objective function. The parameters we
report as Local1 correspond to the values reported in Table 6 of Ang and Piazzesi.

The

small differences between our estimates and theirs are due to some slight differences between
the data sets and the fact that, in an overidentified structure, the minimum-chi-square and
maximum-likelihood estimates are not numerically identical. Our procedure establishes that
the estimates reported by Ang and Piazzesi in fact represent only a local maximum of the
likelihood– both the estimates we report as Local2 and Global achieve substantially higher
values for the log likelihood function relative to Local1. Moreover, the differences between
estimates in terms of the pricing of risk are substantial.

In the original reported Ang and

Piazzesi estimates, an increase in inflation lowers the price of inflation risk and raises the price
of output risk, whereas the values implied by Global reverse these signs. This is consistent
with their finding that the prices of observable macro risk behave very differently between
their Macro Model and Macro Lag Model specifications– we find they also differ substantially
across alternative local maxima of the log likelihood function even within their single Macro
Model specification. Note that the large prices of risk for these higher local maxima can make
them easy to miss with conventional estimation and conventional starting values of zero price
of risk.
Another benefit of the minimum-chi-square estimation is that the value for the objective
we implemented this subject to the proposed restrictions by parameterizing




θ1 0 0
θ5 0 0
 θ6 θ2 θ7  ,
ρ`` =  0 θ2 0 
ρQ
`` =
0 θ3 θ4
θ8 θ3 θ9
and then translated back in terms of the implied values for Λ`` for purposes of reporting values in Table 7.

45

function itself gives us an immediate test of the various overidentifying restrictions. There
are 152 parameters in the reduced form vector π in (55). The 17 estimated elements of θ then
leave 135 degrees of freedom. The 1% critical value for a χ2 (135) variable is 176. Thus the
observed minimum value for our objective function (462.15) provides overwhelming evidence
that the restrictions imposed by the model are inconsistent with the observed data.

5

Conclusion.

There are considerable benefits from describing affine term structure models in terms of their
implications for the reduced-form representation of the data, which for a popular class of
models is simply a restricted Gaussian vector autoregression.

In this paper we used this

representation to develop an approach to characterizing identification that has not previously
been used for affine term structure models. We demonstrated that three popular canonical
representations are in fact not identified, and showed how convergence to an unidentified
region of the parameter space can complicate numerical search.

A second and separate

contribution of the paper was to propose inferring structural parameters from the unrestricted
OLS estimates by the method of minimum-chi-square estimation, which is an approach to
parameter estimation that again has not previously been used for affine term structure models.
We demonstrated that among other benefits, this method is asymptotically equivalent to
maximum likelihood estimation and can in some cases make it feasible to calculate smallsample standard errors, to know instantly whether estimates represent a global or only a local
optimum, and to recognize whether a given structure is unreasonably restricting the class of

46

possible models.
By missing these insights, previous researchers have instead often imposed arbitrary restrictions in order to obtain estimates and in other cases failed to find the true global maximum
of the likelihood function.

By showing how to recognize an unidentified structure, greatly

reducing the computational burden of estimation, and providing an immediate specification
test of any proposed restrictions, we hope that our methods will help to make these models a
more effective tool for research in macroeconomics and finance.

47

References
Aı̈t-Sahalia, Yacine, and Robert L. Kimmel, 2010, Estimating Affine Multifactor Term Structure Models Using Closed-Form Likelihood Expansions. Journal of Financial Economics,
98.
Ang, Andrew, Sen Dong, and Monika Piazzesi, 2007, No-Arbitrage Taylor Rules. National
Bureau of Economic Research, Working paper no. 13448.
Ang, Andrew, and Monika Piazzesi, 2003, A No-Arbitrage Vector Autoregression of Term
Structure Dynamics with Macroeconomic and Latent Variables. Journal of Monetary Economics, 50, 745–787.
Ang, Andrew, Monika Piazzesi, and Min Wei, 2006, What Does the Yield Curve Tell Us About
GDP Growth. Journal of Econometrics, 131, 359–403.
Bauer, Michael D., 2011, Term Premia and the News. Federal Reserve Bank of San Francisco,
Working paper.
Beechey, Meredith J., and Jonathan H. Wright, 2009, The High-Frequency Impact of News
On Long-Term Yields and Forward Rates: Is It Real? Journal of Monetary Economics, 56,
535–544.
Bekaert, Geert, Seonghoon Cho, and Antonio Moreno, 2010, New Keynesian Macroeconomics
and the Term Structure. Journal of Money, Credit, and Banking, 42, 33–62.
Chamberlain, Gary, 1982, Multivariate Models for Panel Data. Journal of Econometrics, 18,
5–46.
48

Chen, Ren-Raw, and Louis Scott, 1993, Maximum Likelihood Estimation for a Multifactor
Equilibrium Model of the Term Structure of Interest Rates. The Journal of Fixed Income,
3, 14–31.
Christensen, Jens H. E., Francis X. Diebold, and Glenn D. Rudebusch, 2011, The Affine
Arbitrage-Free Class of Nelson-Siegel Term Structure Models. Journal of Econometrics,
164, 4 – 20.
Christensen, Jens H. E., Jose A. Lopez, and Glenn D. Rudebusch, 2009, Do Central Bank Liquidity Facilities Affect Interbank Lending Rates? Working paper 2009-13, Federal Reserve
Bank of San Francisco.
Christensen, Jens H. E., Jose A. Lopez, and Glenn D. Rudebusch, 2010, Inflation Expectations
and Risk Premiums in an Arbitrage-Free Model of Nominal and Real Bond Yields. Journal
of Money, Credit, and Banking, 42, 143 – 178.
Cochrane, John H., and Monika Piazzesi, 2009, Decomposing the Yield Curve. AFA 2010
Atlanta Meetings Paper.
Collin-Dufresne, Pierre, Robert S. Goldstein, and Christopher S. Jones, 2008, Identification
of Maximal Affine Term Structure Models. Journal of Finance, 63, 743–795.
Dai, Qiang, and Kenneth J. Singleton, 2000, Specification Analysis of Affine Term Structure
Models. The Journal of Finance, 55, 1943–1978.
Dai, Qiang, and Kenneth J. Singleton, 2002, Expectation Puzzles, Time-Varying Risk Premia,
and Affine Models of the Term Structure. Journal of Financial Economics, 63, 415–441.
49

Duarte, Jefferson, 2004, Evaluating an Alternative Risk Preference in Affine Term Structure
Models. Review of Financial Studies, 17, 379–404.
Duffee, Gregory R., 2002, Term Premia and Interest Rate Forecasts in Affine Models. The
Journal of Finance, 57, 405–443.
Duffee, Gregory R., 2011, Forecasting with the Term Structure: The Role of No-Arbitrage
Restrictions. Working Paper, Johns Hopkins University.
Duffee, Gregory R., and Richard H. Stanton, 2008, Evidence on Simulation Inference for Near
Unit-Root Processes with Implications for Term Structure Estimation. Journal of Financial
Econometrics, 6, 108 – 142.
Duffie, Darrell, and Rui Kan, 1996, A Yield-Factor Model of Interest Rates. Mathematical
Finance, 6, 379–406.
Fisher, Franklin M., 1966, The Identification Problem in Econometrics. New York: McGrawHill.
Fisher, R.A., 1924, The Conditions Under Which χ2 Measures the Discrepancey Between
Observation and Hypothesis. Journal of the Royal Statistical Society, 87, 442 – 450.
Gallant, A. Ronald, and George E. Tauchen, 1992, A Nonparametric Approach to Nonlinear
Time Series Analysis: Estimation and Simulation. In New Directions in Time Series Analysis
Part II, edited by David Brillinger, Peter Caines, John Geweke, Emanuel Parzen, Murray
Rosenblatt, and Murad S. Taqqu, Springer-Verlag.

50

Gourieroux, Christian, Alain Monfort, and Eric Renault, 1993, Indirect Inference. Journal of
Applied Econometrics, 8S, S85 – S118.
Hamilton, James D., and Jing Cynthia Wu, forthcominga, The Effectiveness of Alternative
Monetary Policy Tools in a Zero Lower Bound Environment. Journal of Money, Credit &
Banking.
Hamilton, James D., and Jing Cynthia Wu, forthcomingb, Testable Implications of Affine
Term Structure Models. Journal of Econometrics.
Hansen, Lars P., 1982, Large Sample Properties of Generalized Method of Moments Estimators. Econometrica, 50, 1029 – 1054.
Hördahl, Peter, Oreste Tristani, and David Vestin, 2006, A Joint Econometric Model of
Macroeconomic and Term-Structure Dynamics. Journal of Econometrics, 131, 405 – 444.
Joslin, Scott, Kenneth J. Singleton, and Haoxiang Zhu, 2011, A New Perspective On Gaussian
Dynamic Term Structure Models. Review of Financial Studies, 24, 926–970.
Kim, Don H., 2008, Challenges in Macro-Finance Modeling. BIS Working Paper No. 240,
FEDS Working Paper No. 2008-06.
Kim, Don H., and Athanasios Orphanides, 2005, Term Structure Estimation with Survey
Data On Interest Rate Forecasts. Federal Reserve Board, Finance and Economics Discussion
Series 2005-48.
Kim, Don H., and Jonathan H. Wright, 2005, An Arbitrage-Free Three-Factor Term Structure

51

Model and the Recent Behavior of Long-Term Yields and Distant-Horizon Forward Rates.
Federal Reserve Board, Finance and Economics Discussion Series 2005-33.
Magnus, Jan R., and Heinz Neudecker, 1988, Matrix Differential Calculus with Applications
in Statistics and Econometrics. John Wiley & Sons, Ltd.
Malinvaud, Edmond, 1970, Statistical Methods of Econometrics, Third Revised Edition. New
York: North-Holland.
Newey, Whitney K., 1987, Efficient Estimation of Limited Dependent Variable Models with
Endogenous Explanatory Variables. Journal of Econometrics, 36, 231–250.
Neyman, J., and E. S. Pearson, 1928, On the Use and Interpretation of Certain Test Criteria
for Purposes of Statistical Inference: Part II. Biometrika, 20A, 263 – 294.
Pericoli, Marcello, and Marco Taboga, 2008, Canonical Term-Structure Models with Observable Factors and the Dynamics of Bond Risk Premia. Journal of Money, Credit and Banking,
40, 1471–1488.
Rothenberg, Thomas J., 1971, Identification in Parametric Models. Econometrica, 39, 577–
591.
Rothenberg, Thomas J., 1973, Efficient Estimation with A Priori Information. Yale University
Press.
Rudebusch, Glenn D., Eric T. Swanson, and Tao Wu, 2006, The Bond Yield ‘Conundrum’
From a Macro-Finance Perspective. Monetary and Economic Studies (Special Edition), 83–
128.
52

Rudebusch, Glenn D., and Tao Wu, 2008, A Macro-Finance Model of the Term Structure,
Monetary Policy and the Economy. The Economic Journal, 118, 906–926.
Singleton, Kenneth J., 2006, Empirical Dynamic Asset Pricing. Princeton University Press.
Smith, Jr., Anthony A., 1993, Estimating Nonlinear Time-Series Models Using Simulated
Vector Autoregressions. Journal of Applied Econometrics, 8S, S63 – S84.
Smith, Josephine M., 2010, The Term Structure of Money Market Spreads During the Financial Crisis. Ph.D. thesis, Stanford University.
Vasicek, Oldrich, 1977, An Equilibrium Characterization of the Term Structure. Journal of
Financial Economics, 5, 177–188.

53

Appendix A. Log likelihood function for the MF1 specification.
The coefficients relating Yt1 and Yt2 to macro and latent factors can be partitioned as
 0 
b4

  b020 
 0 
B1m B1`



 (3×2) (3×3)  =  b40
0
 b 
B2m B2`
8
 0 
(3×2) (3×3)
 b 
12
0

b28
for bn given by (15). The conditional density for the tth observation is then
1
m
`
, ft−1
, uet−1 )
f (ftm , ft` , uet |ft−1
| det(J)|

m
f (ftm , Yt |ft−1
, Yt−1 ) =

where
m
`
`
m
`
m
f (ftm , ft` , uet |ft−1
, ft−1
, uet−1 ) = f (ftm |ft−1
, ft−1
)f (ft` , |ft−1
, ft−1
)f (uet )
0

`
m
m
`
f (ftm |ft−1
, ft−1
) = φ(ftm ; cm + ρmm ft−1
+ ρm` ft−1
, Σmm Σmm )
`
m
m
`
f (ft` |ft−1
, ft−1
) = φ(ft` ; c` + ρ`m ft−1
+ ρ`` ft−1
, IN` )

f (uet ) = φ(uet ; 0, INe )
−1
ft` = B1`
(Yt1 − A1 − B1m ftm )
2
m
`
uet = Σ−1
e (Yt − A2 − B2m ft − B2` ft )


B1` 0
J=
.
B2` Σe

For the Q representation and our N` = 3, Nm = 2, Ne = 3 example, there are 25 unknown
elements in ρ, 25 in ρQ , 5 in c, 2 in cQ , 5 in δ 1 , 1 in δ 0 , 3 in Σmm , and 3 in Σe . The traditional
approach is to arrive at estimates of these 69 parameters by numerical maximization of
L(θ; Y ) =

T
X

m
log f (ftm , Yt |ft−1
, Yt−1 )

t=1

as calculated using the above formulas.

54

Appendix B. Log likelihood for the MF12 specification.
The P dynamics can again be represented as a special case
 of (1) by using the companion
m0
`0 0
m
m0
m0
0
0
0 0
form Ft = (Ft , ft ) , Ft = (ft , ..., ft−11 ) , c = 024×1 , c` , and


ρ1

ρ2 ρ3 · · ·

 (2×2)
 I2
0

 0
I2

 ..
..
ρ= .
.

 0
0

 0
0

0
0

ρ11 ρ12

0















0
0
..
.

···
···
...

0
0
..
.

0
0
..
.

0
0
..
.

0
0
0

···
···
···

0
I2
0

0
0
0

0
0
ρ``
(3×3)



0

0



0 ··· 0
.. . . ..
. .
.
0 ··· 0
0 ··· 0

0
..
.





.




Σmm 0 · · ·
(2×2)





Σ=




0
..
.
0
0

0
Σ``
(3×3)

Ang and Piazzesi assumed that the risk associated with lagged macro factors is not priced
and imposed the restriction
in a λ representation that the values in (9) are characterized by
0
λ = λ0m , 0022×1 , λ0` and


0

0



0 ··· 0
.. . . ..
. .
.
0 ··· 0
0 ··· 0

0
..
.





.




Λmm 0 · · ·
(2×2)





Λ =

(27×27)



0
..
.
0
0

0
Λ``
(3×3)


0
Q0
0
From (10) and (11) it follows that the parameters in (12) are given by cQ = cQ0
,
0
,
c
m
22×1 `
and
 Q

ρ1 ρ2 ρ3 · · · ρ11 ρ12
0
 (2×2)



0 0 ··· 0
0
0 
 I2


 0
I2 0 · · · 0
0
0 
 .
.. .. . .
..
..
.. 
.
ρQ = 
.
.
.
.
.
.
. 

.
 0
0 0 ··· 0
0
0 


 0

0
0
·
·
·
I
0
0


2


0
0 0 ··· 0
0
ρQ
``
(3×3)

55

Ang and Piazzesi used N` = 3 and Ne = 2, assuming that the 1-, 12-, and 60-month yields
were priced without error, while the 3- and 36-month yields were priced with error, so that
the B matrices can be written in partitioned form as
 0 
b1
 (0)

(1)
 b012 
B1m B1m B1`

0
 (3×2) (3×22) (3×3)  

b
 (0)
=
(1)
60
 0 
B2m B2m B2`
 b 
3
(2×2) (2×22) (2×3)
0
b36
(1)

where for example B1m are the coefficients relating the observed yields to 11 lags of the 2
macro factors.
The conditional density for this case is then
m
, Yt−1 ) =
f (ftm , Yt |Ft−1

1
m
`
, ft−1
, uet−1 )
f (ftm , ft` , uet |Ft−1
| det(J)|

m
`
m
`
f (ftm , ft` , uet |Ft−1
, ft−1
, uet−1 ) = f (ftm |Ft−1
)f (ft` |ft−1
)f (uet )
0

m
m
m
m
f (ftm |Ft−1
) = φ(ftm ; ρ1 ft−1
+ ρ2 ft−2
+ · · · + ρ12 ft−12
, Σmm Σmm )
`
`
f (ft` |ft−1
) = φ(ft` ; ρ`` ft−1
, IN` )

f (uet ) = φ(uet ; 0, INe )
i


h
(1)
(0)
−1
ft` = B1`
Yt1 − A1 − B1m
B1m Ftm

h
i

(0)
(1)
2
m
`
uet = Σ−1
Y
−
A
−
F
−
B
f
B2m B2m
2
2` t
e
t
t


B1` 0
J=
.
B2` Σe

Appendix C. Proof of Proposition 1.
Write


H=

u x
v y


.

Since columns of H have unit length, without loss of generality we can write (u, v) = (cos θ, sin θ)
for some θ ∈ [−π, π]. The second column of H is also a point on the unit circle, for which
orthogonality with the first column also requires it to be located on the line ux + vy = 0, with
the two solutions x = −v, y = u and x = v, y = −u. Thus the set of orthogonal (2 × 2)
matrices can be represented as either rotations


cos θ − sin θ
(C.1)
H1 (θ) =
sin θ cos θ

56

or reflections


H2 (θ) =

cos θ sin θ
sin θ − cos θ


.

(C.2)

The condition that the (1, 2) element of H1 (θ)ρH1 (θ)0 be zero requires
Q
Q
2
(ρQ
11 − ρ22 ) sin θ cos θ − ρ21 sin θ = 0.

One way this could happen is if sin θ = 0. But this would imply either H1 (−π/2) = −I2 ,
violating the sign requirement Hδ 1 ≥ 0, or else the identity transformationH1 (π/2) = I2 .
Hence the condition of interest is
Q
Q
(ρQ
11 − ρ22 ) cos θ − ρ21 sin θ = 0.

(C.3)

If θ1 satisfies condition (C.3), then one can show
0

Q

ρQ
0
22
Q
ρ21 ρQ
11



H1 (θ1 )ρ H1 (θ1 ) =


.

Alternatively for H2 (θ) we have the requirement
Q
Q
2
(ρQ
11 − ρ22 ) sin θ cos θ + ρ21 sin θ = 0

for which the solution sin θ = 0 would violate H2 (θ)δ 1 ≥ 0, leaving the sole condition
Q
Q
(ρQ
11 − ρ22 ) cos θ + ρ21 sin θ = 0.

(C.4)

For any θ2 satisfying (C.4),
Q

0

H2 (θ2 )ρ H2 (θ2 ) =



ρQ
0
22
Q
−ρ21 ρQ
11


.

Now consider the nonnegativity condition. Since cot θ is monotonic on (0, π) and repeats
the pattern on (−π, 0), there are two values θ ∈ [−π, π] satisfying (C.3). We denote the first
by θ1 ∈ [0, π], in which case the second is given by θ1 − π. The two solutions to (C.4) can
then be written as −θ1 and −θ1 + π. We are then looking at 4 possible transformations:


 
  ∗ 
cos θ1 − sin θ1
δ 11
δ 11 cos θ1 − δ 12 sin θ1
δ 11
H1 (θ1 )δ 1 =
=
≡
sin θ1 cos θ1
δ 12
δ 11 sin θ1 + δ 12 cos θ1
δ ∗12


 

− cos θ1 sin θ1
δ 11
−δ ∗11
H1 (θ1 − π)δ 1 =
=
− sin θ1 − cos θ1
δ 12
−δ ∗12


  ∗ 
cos θ1 − sin θ1
δ 11
δ 11
H2 (−θ1 )δ 1 =
=
− sin θ1 − cos θ1
δ 12
−δ ∗12


 

− cos θ1 sin θ1
δ 11
−δ ∗11
.
H2 (−θ1 + π) =
=
sin θ1 cos θ1
δ 12
δ ∗12
57

Apart from the knife-edge condition δ ∗11 = 0 or δ ∗12 = 0 (which would require a particular
relation between the elements of the original ρQ and δ 1 ), one and only one of the above four
vectors would have both elements positive, and this matrix produces HρQ H 0 of one of the two
specified forms.
For N` > 2, one can construct a family of such orthogonal matrices, for example using a
matrix like


cos θ 0 − sin θ

1
0
H(θ) =  0
sin θ 0 cos θ
Q
Q
Q
for θ satisfying ρQ
31 sin θ = (ρ11 − ρ33 ) cos θ, which swaps the (1,1) and (3,3) elements of ρ .
Exactly one of the 4 possible matrices performing this swap will preserve positive Hδ 1 . There
are N` choices for the value one can put into the (1,1) element as a result of such swaps, N` − 1
remaining choices for ρQ
22 , or a total of N` ! permutations.

Appendix D. Proof of Proposition 2.
Consider first rotations H1 (θ) as specified in (C.1). The (1,1) element of Υ = H1 (θ)ρQ [H1 (θ)]0
is seen to be
Q
Q
Q
2
2
h1 (θ) = ρQ
(D.1)
11 cos θ − (ρ21 + ρ12 ) cos θ sin θ + ρ22 sin θ.
Q
We claim first that there exists a θ ∈ [0, π/2] such that h1 (θ) equals (ρQ
11 + ρ22 )/2. To see
this, note that at θ = 0, the value of h1 (θ) is ρQ
11 , whereas at θ = π/2, it is instead equal to
Q
ρ22 . Since h1 (θ) is continuous in θ, there exists a value θ1 such that h1 (θ1 ) is exactly halfway
Q
between ρQ
11 and ρ22 .
Notice next that the eigenvalues of Υ = HρQ H 0 are identical to those of ρQ , and hence the
trace of Υ (which is the sum of the eigenvalues) is the same as the trace of ρQ :
Q
Υ11 + Υ22 = ρQ
11 + ρ22 .
Q
Q
Q
Q
0
Thus since Υ11 = (ρQ
11 + ρ22 )/2, then also Υ22 = (ρ11 + ρ22 )/2. Hence H1 (θ 1 )ρ [H1 (θ 1 )] is of
the desired form with elements along the principal diagonal equal to each other. As in the
proof of Proposition 1, H1 (θ1 − π) is the other rotation that works.
Alternatively, H could be a reflection matrix H2 (θ) as in (C.2), for which the (1,1) element
of H2 (θ)ρQ [H2 (θ)]0 is found to be:
Q
Q
Q
2
2
ρQ
11 cos θ + (ρ21 + ρ12 ) cos θ sin θ + ρ22 sin θ

(D.2)

Q
This turns out to equal (ρQ
11 + ρ22 )/2 at θ 2 = −θ 1 and θ 2 = −θ 1 + π. As in the proof of
Proposition 1, in the absence of knfe-edge conditions on δ 1 , exactly one of the transformations
H1 (θ1 ), H1 (θ1 − π), H2 (−θ1 ), H2 (−θ1 + π) preserves positivity of Hδ 1 , establishing existence.
For uniqueness, suppose we have found a transformation HρQ H 0 = Υ of the desired form.
Then any alternative transformation H ∗ ρQ H ∗0 can equivalently be written as H̃ΥH̃ 0 for H̃H =
H ∗ . Hence the result will be established if we can show that the only transformations H̃ΥH̃ 0
that keep the diagonal elements equal to each other and also satisfy H̃δ 1 ≥ 0 are the identity
and transposition. Since a = Υ11 = Υ22 and since the transformation preserves eigenvalues,

58

we know that if the (1,1) and (2,2) elements of H̃ΥH̃ 0 are equal to each other, each must again
be the value a. Thus if H̃ = H1 (θ) for some θ, we require as in (D.1) that
a cos2 θ − (Υ21 + Υ12 ) cos θ sin θ + a sin2 θ = a
which can only be true if
(Υ21 + Υ12 ) cos θ sin θ = 0.

(D.3)

This requires either cos θ = 0, sin θ = 0, or Υ21 = −Υ12 . For cos θ = 0, H1 (θ)δ 1 would
violate the nonnegativity condition, while sin θ = 0 corresponds to H1 (θ) = ±I2 . Finally, if
Υ21 = −Υ12 , one can verify that H1 (θ)Υ[H2 (θ)]0 = Υ for all θ. Alternatively, for reflections
applied to a matrix Υ for which a = Υ11 = Υ22 , we see as in (D.2) that a cos2 θ + (Υ21 +
Υ12 ) cos θ sin θ + a sin2 θ = a, which again can only hold for θ satisfying (D.3). In this case,
sin θ = 0 is ruled out by the constraint H2 (θ)δ 1 ≥ 0, but for cos θ = 0 we have




0 1
0 −1
H2 (π/2) =
and H2 (−π/2) =
.
1 0
−1 0
Both of these give HΥH 0 = Υ0 but only H2 (π/2)δ 1 > 0. Finally, when Υ21 = −Υ12 , then
H2 (θ)Υ[H2 (θ)]0 = Υ0 for any θ. Thus the only transformation H̃ΥH̃ 0 that preserves equality
of diagonal elements is transposition, as claimed.

Appendix E. Asymptotic standard errors of MLE.
Here we demonstrate that under the usual regularity conditions,
#
"
∂ 2 L(π(θ); Y )
= −T Γ0 RΓ
E
∂θ∂θ0
θ=θ0
for

"

#
∂π(θ)
Γ=
∂θ0 θ=θ0
"
#
2
∂
L(π;
Y
)
R = −T −1 E
.
∂π∂π 0 π=π0

Note


∂L(π(θ); Y ) h
=
∂θ0

∂L(π)
∂π 1

···

∂L(π)
∂π q

i

∂π 1
∂θ1

 ..
 .

∂π q
∂θ1

59

···
..
.

∂π 1
∂θN

···

∂π q
∂θN

..
.






2

∂ L(π(θ); Y )
=
∂θi ∂θ0

h

∂π 1
∂θi

···

∂π q
∂θi

∂ 2 L(π)
∂π 1 ∂π 1

..
.

i



∂ 2 L(π)
∂π q ∂π 1


+

h

∂L(π)
∂π 1

···

∂L(π)
∂π q

i




···
..
.

∂ 2 L(π)
∂π 1 ∂π q

···

∂ 2 L(π)
∂π q ∂π q

∂ 2 π1
∂θ1 ∂θi

..
.

∂ 2 πq
∂θ1 ∂θi

..
.



∂π 1
∂θ1

 .
  ..


∂π q
∂θ1

···
..
.

∂ 2 π1
∂θN ∂θi

···

∂ 2 πq
∂θN ∂θi

..
.

···
..
.

∂π 1
∂θN

···

∂π q
∂θN

..
.



 (E.1)



.

Evaluate (E.1) at θ = θ0 , take expectations with respect to the distribution of Y, and use the
fact that Γ is not a function of Y :
 2

∂ 2 L(π)
∂ L(π)
·
·
·
"
#
∂π 1 ∂π q
π=π 0 
 ∂π1 ∂π1 π=π0
∂ 2 L(π(θ); Y )
0 0


.
.
.
.
.
.
E
= ei Γ E 
(E.2)
Γ
.
.
.
0
 2

∂θi ∂θ
θ=θ0
∂ L(π)
∂ 2 L(π)
· · · ∂πq ∂πq
∂π q ∂π 1
π=π
π=π 0
 20

∂ π1
∂ 2 π1
· · · ∂θN ∂θi
θ=θ0 
io  ∂θ1 ∂θi θ=θ0
n h


∂L(π)
∂L(π)
..
..
..
·
·
·
+ E

.
.
.
∂π 1
∂π q
π=π 0
π=π 0
 2 .

2
∂ πq
∂ πq
·
·
·
∂θ1 ∂θi
∂θN ∂θi
θ=θ0

θ=θ0


But the usual regularity conditions imply E ∂L(π)/∂π j |π=π0 = 0, so the second term in
(E.2) vanishes. Stacking the row vectors represented by the first term into a matrix produces
 2

∂ L(π)
∂ 2 L(π)
·
·
·
#
"
∂π 1 ∂π q
π=π 0 
 ∂π1 ∂π1 π=π0
∂ 2 L(π(θ); Y )


.
.
.
0
..
..
..
=ΓE
E
Γ
0
 2

∂θ∂θ
θ=θ0
2
∂ L(π)
∂ L(π)
·
·
·
∂π q ∂π 1
∂π q ∂π q
π=π 0

as claimed.

60

π=π 0

cQ
ρQ

ρ

δ0
δ1
Σe
eig(ρ)
LLF

True values
Global maximum
Local 53
0.0407 0.0135 0.5477 0.0416 0.0085 0.5316 -0.5562 0.0204
0.9991
0
0 0.9985
0
0 0.9986
0
0.0101 0.9317
0 0.0116 0.9328
0 0.0113 0.9316
0.0289 0.2548 0.7062 0.0219 0.2500 0.7202 0.0203 0.2438
0.9812 0.0069 0.0607 0.9696 0.0141 0.0671 0.9794 0.0063
-0.0010 0.8615 0.1049 -0.0027 0.8533 0.1175 -0.0028 0.8380
0.0164 0.1856 0.6867 0.0085 0.1985 0.6993 0.0333 0.1923
0.0046
0.0046
0.1344
1.729E-4 1.803E-4 4.441E-4 1.71E-4 1.71E-4 4.45E-4 1.72E-4 1.59E-4
9.149E-5
9.105E-5
9.110E-5
0.9879 0.9341 0.6074 0.9734 0.9448 0.6040
1.000 0.9306
28110.4
28096.5

0.0527
0
0
0.7352
0.0840
0.1267
0.7202
4.54E-4
0.6070

Table 1: Parameter values used for simulation and estimates associated with (1) the global
maximum and (2) a representative point of local convergence.

VAR
parameter
Ω∗2
φ∗21
Ω∗1
φ∗11
A∗2
A∗1

No. of
Σe
Ne
elements
Ne
X
N` Ne
N` (N` + 1)/2
N`2
Ne
N`

ρQ
δ1
N` (N` + 1)/2 N`
X
X
X
X
X

X
X
X
X

ρ
N`2

cQ
N`

δ0
1

X
X

X
X

X
X

Table 2: Mapping between structural and reduced-form parameters for the latent factor model.

VAR
parameter
Ω∗2
Ω∗m
ψ ∗1m
φ∗2m
φ∗21
Ω∗1
φ∗m1
φ∗mm
φ∗11
φ∗1m
A∗2
A∗m
A∗1

No. of
Σe
Σmm
Ne Nm (Nm + 1)/2
elements
Ne
X
X
Nm (Nm + 1)/2
N` Nm
Ne Nm
Ne N`
N` (N` + 1)/2
Nm N`
2
Nm
N`2
N` Nm
Ne
X
Nm
X
N`
X

ρQ δ 1 ρm` ρmm ρ`` ρ`m δ 0 cQ cm c`
2
Nf2 Nf Nm N` Nm
N`2 N` Nm 1 Nm Nm N`

X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X

X
X

X
X
X

X
X

X
X X
X X X
X X
X

Table 3: Mapping between structural and reduced-form parameters for the MF1 model.

VAR
parameter
Ω∗2
Ω∗m
φ∗mm
ψ ∗1m
φ∗21
Ω∗1
φ∗11
φ∗2m
φ∗1m
A∗2
A∗1

No. of
elements
2
3
48
6
6
6
9
48
72
2
3

Σe
2
X

Σmm
3

ρ1,...,12
48

Λmm
4

δ 1m
2

X
X

X

X

ρ``
6

Λ``
9

δ 1`
3

δ0
1

λ
5

X
X
X
X
X
X
X

X
X
X
X
X
X
X

X
X
X
X
X
X
X

X
X

X
X

X

X
X

X
X
X
X

X
X
X
X

X
X
X
X

Table 4: Mapping between structural and reduced-form parameters for the MF12 model.

cQ

ρQ

ρ

δ0

δ1

Σe

Estimated Q representation parameters Implied λ
0.0407
λ −0.0407
0.0135
0.5477
[0.0063]
[0.0399]
[0.1194]
[0.0063]
(0.0062)
(0.0378)
(0.1073)
0.9991
0
0
Λ −0.0178
[0.0005]
[0.0109]
(0.0004)
−0.0111
0.0101
0.9317
0
[0.0033]
[0.0050]
[0.0102]
(0.0032)
(0.0046)
0.0289
0.2548
−0.0125
0.7062
[0.0193]
[0.0206]
[0.0507]
[0.0090]
(0.0185)
(0.0172)
(0.0439)
0.9812
0.0069
0.0607
[0.0110]
[0.0231]
[0.0303]
(0.0067)
(0.0226)
(0.0294)
−0.0010
0.8615
0.1049
[0.0343]
[0.0331]
[0.0113]
(0.0309)
(0.0318)
(0.0094)
0.0164
0.1856
0.6867
[0.0187]
[0.0289]
[0.0353]
(0.0174)
(0.0277)
(0.0350)
0.0046
[0.0011]
(0.0011)
1.729E-4 1.803E-4
4.441E-4
[2.31E-5] [3.80E-5]
[1.75E-5]
(2.28E-5) (3.74E-5)
(1.62E-5)
9.149E-5
[2.81E-6]
(2.70E-6)

representation parameters
−0.0135
−0.5477
[0.0399]
[0.1194]
0.0069
[0.0231]

0.0607
[0.0303]

−0.0701
[0.0323]

0.1049
[0.0331]

−0.0693
[0.0354]

−0.0195
[0.0449]

Table 5: FIML estimates with small-sample standard errors (in square brackets) and asymptotic standard errors (in parentheses) for latent factor model fit to Ang and Piazzesi (2003)
data set.

cQ

0.0306 −0.0458
(0.5291)

c

−0.1028
(0.4951)

ρ

Q

0

0.2414 −0.9632 −1.5301

2.4063

(0.4672)

(4.4009)

(7.2480)

(1.4128)

0.0436 −0.2138 −0.3565

0.2933

(0.2895)

(0.2801)

(1.0688)

−0.3933

1.2411

0.2376 −0.0197 −0.0574

(0.3857)

(0.3706)

(0.2437)

0.2036 −0.2046

0.8579

(0.3691)

(0.1435)

(0.2083)

(0.3852)

(0.1332)
(0.1470)

0

(0.3900)
(0.5579)

0

0.1035 −0.0054

0.8826 −0.1926

(0.2373)

(0.0672)

(0.5723)

(0.1464)

0.1001 −0.1415

0.0223

0.0303

0.8826

(0.6387)

(0.1215)

(0.0810)

(0.0672)

0.9461

0.2203 −0.0428 −0.0210

0.0639

(0.0325)

(0.0508)

(0.1531)

0.0002

0.8735 −0.0435 −0.0233 −0.0517

(0.0310)

(0.0487)

0.0932

0.1683

0.8203 −0.0844

(0.3903)

(0.1686)

(0.6723)

−0.0827
(0.1190)

δ0

0

0.7725

−0.1035

ρ

0

(1.1382)

(0.6661)

(0.2005)
(0.1618)

(0.0456)
(0.0538)
(0.2453)

(0.1555)

0.1378
(1.0303)

0.0852 −0.1110

0.8715

0.0978

(0.1295)

(0.1127)

(0.2066)

(0.3430)

0.1220

0.0449

0.0756

0.0555

0.4728

(0.2649)

(0.5693)

(1.0167)

(0.1468)

(0.7418)

−0.0082
(0.0062)

δ1

6.86E-4

1.02E-3

2.03E-3

1.92E-4

7.67E-4

(2.88E-4)

(3.03E-4)

(2.35E-3)

(1.33E-3)

(6.31E-3)

Σe

2.02E-4

1.87E-4

1.09E-4

(1.29E-5)

(1.19E-5)

(6.97E-6)

Σmm

0.6996

0

(0.0448)

0.1174

0.6617

(0.0604)

(0.0424)

Table 6: FIML estimates and asymptotic standard errors for the MF1 model.

ρ``

δ 1`
λ`
Λmm
Λ``

χ2
LLF
Frequency

Global
Local1
Local2
0.9921
0
0 0.9918
0
0 0.9920
0
0
0 0.9462
0
0 0.9412
0
0 0.9437
0
0 -0.0034 0.9021
0 -0.0095 0.7712
0 -0.0032 0.9401
1.11E-04 4.27E-04 1.98E-04 1.09E-04 4.30E-04 1.92E-04 1.22E-04 4.26E-04 1.92E-04
-0.0409
0
0 -0.0441
0
0 -0.0388
0
0
2.8783 0.4303
-0.3430 0.1474
1.5633 0.1341
-6.1474 -0.8744
1.7675 -0.0607
16.0624 7.4290
-0.0048
0
0 -0.0045
0
0 -0.0056
0
0
-0.0445
0 0.2910 -0.0474
0 0.2881 -0.0423
0 0.3000
-0.0322
0 0.3687 -0.0331
0 0.2110 -0.0299
0 0.4120
462.15
530.69
503.10
20703
20668
20679
14
84
2

Table 7: Three local minima for the chi-square objective function for the restricted MF12
specification.

