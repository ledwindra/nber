NBER WORKING PAPER SERIES

PUTTING TASKS TO THE TEST:
HUMAN CAPITAL, JOB TASKS AND WAGES
David H. Autor
Michael J. Handel
Working Paper 15116
http://www.nber.org/papers/w15116

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2009

We thank the Princeton Data Improvement Initiative for conducting the survey underlying this analysis.
We are grateful to Alan Krueger for encouragement and invaluable suggestions and to Aaditya Muthukumaran
for research assistance. Autor acknowledges generous support from the National Science Foundation
(CAREER SES-0239538). The views expressed herein are those of the author(s) and do not necessarily
reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2009 by David H. Autor and Michael J. Handel. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.

Putting Tasks to the Test: Human Capital, Job Tasks and Wages
David H. Autor and Michael J. Handel
NBER Working Paper No. 15116
June 2009
JEL No. J15,J16,J24,J31
ABSTRACT
Employing original, representative survey data, we document that cognitive, interpersonal and physical
job task demands can be measured with high validity using standard interview techniques. Job tasks
vary substantially within and between occupations, are significantly related to workers' characteristics,
and are robustly predictive of wage differentials both between occupations and among workers in
the same occupation. We offer a conceptual framework that makes explicit the causal links between
human capital endowments, occupational assignment, job tasks, and wages. This framework motivates
a Roy (1951) model of the allocation of workers to occupations. Tests of the model’s implication that
'returns to tasks' must negatively covary among occupations are strongly supported.

David H. Autor
Department of Economics
MIT, E52-371
50 Memorial Drive
Cambridge, MA 02142-1347
and NBER
dautor@mit.edu
Michael J. Handel
Department of Sociology
539 Holmes Hall
Northeastern University
Boston, MA 02115
m.handel@neu.edu

Introduction
Contemporary analysis of the economic value of skill in the labor market is rooted in
Becker’s (1964) human capital model. A central insight of the Becker framework is that skill can
be treated as a durable investment good that is acquired (i.e., purchased) in part by attending
school or engaging in on the job training. Building from this logic, empirical analysis of the
market price of skill, starting with Mincer (1974), uses investment measures, such as years of
schooling and experience, as proxies for skill. The human capital model has been highly
successful in explaining both the level of the return to education and its evolution over time. A
key result of this work is that despite unprecedented increases in the supply of educated workers
over the course of a century, secularly rising demand for skill has kept the wage returns to
schooling investments high and, for the most part, rising for at least as long as representative data
are available (Goldin and Katz, 2008).
Although the human capital framework illuminates both the determination of skill prices and
the incentives for skill investment, it is silent on what factors determine the skills that are
demanded. Concretely, empirical analysis of the return to education is not directly informative
about what skills workers use on the job, why these skills are required, and how these skill
requirements have changed over time. To answer these foundational questions requires a
conceptual framework that links the tasks and activities that workers perform on the job to the
skills needed to carry out these activities.
A recent literature attempts to supply this conceptual apparatus by using a “task framework”
to analyze job skill requirements (Autor, Levy and Murnane, 2003). The simple idea of this
approach is to classify jobs according to their core task requirements—that is, the main activities
that workers must accomplish in their work—and then consider the set of formal and informal
1

skills required to carry out these tasks. The task approach potentially offers a microfoundation
for linking the aggregate demand for skill in the labor market—a primitive in the human capital
model—to the specific skill demands of given job activities.
The task approach has found application in several recent strands of work. Autor, Levy and
Murnane (‘ALM,’ 2003) study the link between evolving technology, changes in job task
requirements, and shifts in the demand for workers of different levels of education. Their
primary hypothesis is that workplace computerization leads to the automation of a large set of
‘middle education’ (i.e., high school or some college) routine cognitive and manual tasks, such
as bookkeeping, clerical work and repetitive production tasks. Job tasks in these occupations are
readily automated because they follow precise, well-understood procedure—or ‘routines’—that
lend themselves to codification in computer software. A key implication of the ALM hypothesis
is that the well-documented hollowing out (or ‘polarization’) of the occupational distribution of
employment in numerous advanced countries is in part attributable to computerization.1
Recent work in the immigration literature also employs the task approach. Papers by Cortes
(2008) and Peri and Sparber (forthcoming) compare the job task assignments of equally educated
native and immigrant workers. An intuitive but nonetheless important finding of both studies is
that for given levels of education and experience, U.S. natives are much more likely than
immigrants to be employed in language and communications intensive occupations whereas
immigrants are more likely to be employed in occupations demanding physical labor. This
1

Goos and Manning use the term ‘polarization’ in a 2003 working paper. Acemoglu (1999), Goos and Manning
(2003, 2007), Autor, Katz and Kearney (2006, 2008), Autor and Dorn (2008), Spitz-Oener (2006), Smith (2008),
Dustmann, Ludsteck and Schönberg (2009), and Goos, Manning, and Salomons (2009) present evidence that
employment polarization has occurred during the last two decades in the UK, US, and in 14 of 16 Western European
countries for which consistent data are available for 1993 through 2006. Black and Spitz-Oener (forthcoming)
consider implications of this phenomenon for demand for female labor. Bartel, Ichniowski and Shaw (2007) present
plant-level evidence on the impact of computerization on work organization and productivity in the valve
manufacturing industry.

2

finding in part helps to explain why similarly educated immigrants and natives do not appear to
compete more directly in the labor market.2
Several recent studies consider the effect of international offshoring on U.S. employment. In
these studies, the unit of analysis is job tasks rather than jobs per se. Antràs, Garicano and RossiHansberg (2006) and Grossman and Rossi-Hansberg (2008) develop theoretical models of
international offshoring built upon the notion that routine job tasks are more suitable for
offshoring than non-routine job tasks. Empirical papers by Blinder (2007) and Jensen and
Kletzer (forthcoming) analyze the task content of U.S. jobs to assess their potential for
international offshoring.3
While these examples highlight the potential of job tasks as an organizing framework, the
task approach faces two significant challenges. The first is conceptual. Research using the task
approach has not to date made explicit the economic mapping between tasks—which are
characteristics of jobs—and human capital, which is a characteristic of workers. This disjuncture
between tasks and human capital is particularly relevant to the analysis of the wage ‘returns’ to
job tasks, as we discuss below.
The second challenge is measurement. The primary research data sets used for studying
employment and earnings provide rough measures of workers’ human capital, such as education,
potential experience, gender, race and place of birth, but essentially no information on their job
tasks. To overcome this limitation, researchers typically impute task requirements to person-level
observations using data from the U.S. Department of Labor’s Dictionary of Occupational Titles
(DOT) and its successor, the Occupational Information Network (O*Net). Both data sets offer
2

In related work, Black and Spitz-Oener (forthcoming) point to differences between males and females in job task
specialization as a factor contributing to the closing of the gender gap in the U.S. and Germany.
3

Distinct from the focus of the polarization literature on routine tasks, these papers analyze the degree to which jobs
require face-to-face interactions—which are tasks that are inherently difficult to offshore.

3

representative measures of job requirements in detailed occupation, but their limitations for task
measurement are substantial.4 Most significantly, both DOT and O*Net provide information on
job characteristics only at the level of occupations, not workers. This makes analysis of withinoccupation heterogeneity in task demands and its relationship to earnings infeasible.5 We present
evidence below both that job tasks differ among workers within an occupation and that this
variation is an important determinant of earnings.
The current paper provides an exploratory effort to confront both of the limitations above: a
lack of conceptual structure for analyzing the wage ‘returns’ to tasks, and a lack of data for
analyzing the person-level relationship between tasks, education and wages. The first offers a
simple conceptual framework for interpreting the relationship between job tasks and wages. We
argue that the familiar logic of the Mincerian wage regression, used to estimate the ‘return to
education,’ does not carry over to estimating the ‘returns to tasks.’ Distinct from durable
investments such as education, job tasks are not fixed worker attributes; workers can modify
their task inputs at will. Our conceptual framework assumes that workers choose tasks according
to comparative advantage and reallocate their labor input among tasks when the market value of
tasks changes. These assumptions motivate the use of a Roy (1951) self-selection framework to
analyze the relationship between tasks and wages. We show that a simple, multi-dimensional
Roy model implies testable restrictions on the relationship between ‘task returns’ within and
between occupations. Notably, these implications are quite distinct from the Mincerian model.

4

While an earlier generation of scholars criticized the DOT for its subjective, non-representative and outmoded
measurement of job characteristics (cf. Miller et al., 1980), the Department of Labor’s substantial investments in the
O*Net have improved this instrument relative to its predecessor.
5

Another key limitation is that job content measures in these databases are updated infrequently (the DOT is no
longer updated), with time lags that differ among occupations. This makes it difficult to use these tools to track
changes in task content within jobs.

4

The second goal of our paper is to rigorously explore the value-added of task measurement at
the person level for analyzing job content and wage determination. For this analysis, we
collected new data on the job activities of a representative sample of U.S. workers across a
variety of task domains, including cognitive, interpersonal, and physical activities. These data, a
subcomponent of the Princeton Data Improvement Initiative (PDII) survey, allow us to assess the
extent to which job tasks vary within (as well as between) occupations, and to test whether
within-occupation variation in job tasks is systematically related to workers’ human capital and
demographic characteristics, such as race and gender.
Analysis of person-level task measures reveals sizable, systematic and statistically significant
differences in the job tasks performed by minorities and non-minorities possessing observably
similar education and experience levels and working in the same occupations. While such race
differences in job tasks are plausible and indeed expected, they are nevertheless inaccessible to
statistical analysis using either standard human capital variables or occupation-level indicators,
or both.
We further assess the value-added of self-reported job tasks as predictors of labor market
outcomes relative to occupation-level measures available from sources like the O*Net. To
operationalize this comparison, we merge O*Net measures at the level of detailed 6-digit
Standard Occupational Classification (SOC) occupations onto individual PDII records and also
assign occupation-level PDII task means to individual PDII records. Combining parallel
measures from O*Net and the PDII, we estimate a set of wage regressions that test whether (1)
occupation-level PDII measures have predictive power for earnings conditional on O*Net
occupation-level measures; and (2) whether person-level PDII measures have predictive power
for earnings conditional on PDII and O*Net occupation-level measures. In both cases, we find
5

that they do. Controlling for worker demographics and a full set of occupation dummies,
measures of the tasks that workers actually perform on the job significantly improve the power
of cross-sectional earnings models.6 Moreover, the within-occupation relationship between job
tasks and wages is statistically indistinguishable from the between-occupation relationship,
suggesting that tasks are a potentially valuable tool for characterizing individual jobs in addition
to broader occupations, as is the conventional practice.
In the final section of the paper, we offer an initial empirical test of the Roy model’s
implications using the PDII data. This test yields qualified support for the model. Though the
primary purpose of our model is to build intuition for how job tasks ‘should’ be related to worker
earnings in equilibrium, we believe that the general approach and initial empirical evidence
provide a useful foundation for more comprehensive analyses.
I.

How should job tasks be rewarded in the labor market? A conceptual framework
The Mincer (1974) earnings model provides the conceptual underpinnings for empirical

analysis of the market returns to human capital investments. In the Mincer model, human capital
is proxied by education and potential experience, and the coefficient on years of schooling
obtained from a log earnings regression is interpreted as the compensating differential for
income forgone while in school. If human capital is unidimensional and markets are competitive,
the law of one price applies: the economy wide price of human capital should be invariant across
jobs. These assumptions motivate a hedonic model of earnings such as the following,
(1)

,

6

Black and Spitz-Oener (forthcoming) analyze the relationship between job tasks and wages in West Germany.
Distinct from our approach, their task measures are constructed at the occupation- rather than person-level.

6

where

is the log hourly wage of worker ,

years of completed schooling, and

is a vector of person-level covariates,

is potential experience. In this model,

is

is an estimate of

the market return to a year of schooling. If the primary cost of schooling is foregone earnings and
capital markets function efficiently, the Mincer model further predicts that the equilibrium rate of
return to a year of education should approximately equal the market interest rate.
Does this hedonic reasoning also carry over to the interpretation of the market returns to job
tasks—that is, should we expect the coefficient on job tasks in a wage regression to capture the
equilibrium, economy-wide price of these tasks? Our answer to this question is no. Job tasks
differ from education in two key respects. First, tasks are not durable investment goods like
education that must earn a well-defined market rate of return. The tasks that a worker performs
on the job are an application of that worker’s skill endowment to a given set of activities, and
workers can modify these task inputs as job requirements change. This ongoing self-selection of
workers into job tasks implies that there will not generally be a one-to-one mapping between a
worker’s stock of human capital and the job tasks she performs. Of course, tasks and human
capital cannot be treated as independent. In the model below, we assume that workers’ task
efficiencies are determined by their human capital stocks.
The second key distinction between job tasks and years of schooling is that tasks are a highdimensional bundle of activities, the elements of which must be performed jointly to produce
output. For example, flight attendants engage in both interpersonal and physical tasks,
construction workers perform both analytical and physical tasks, and managers perform both
analytical and interpersonal tasks. In each case, these core job tasks cannot be unbundled; each
worker occupying the job must perform them.

7

These two observations—ongoing self-selection of workers into tasks and bundling of task
demands within jobs—motivate a Roy (1951) model of the allocation of workers to job tasks.
We conceive of a job, or, more broadly, an occupation, as an indivisible bundle of task demands,
all of which are performed simultaneously by each worker in the occupation. We assume that
workers are income maximizing. They self-select into the occupations that offer the highest wage
(or, more generally, highest utility) to the bundle of tasks they are able to produce given their
skill endowments. The empirical implications of this model differ significantly from the
Mincerian compensating differentials framework, as we show below.
A. Model
We write workers’ skill endowments as a vector of task efficiencies (equivalently, abilities),
where the skill endowment of worker

is written as

. Each element of

strictly positive number measuring the efficiency of worker
perform

units of task

at task

in a given time interval. We think of

. Thus, worker

is a

can

as representing a worker’s

stock of human capital, and her efficiency in each task may be a result of human capital
investments. We make no further assumption on the distribution of
its elements except that

has continuous support on

Occupations produce output using the vector of

or the correlation among

.7
tasks, where the productive value of tasks

differs among occupation. This assumption differs from the Mincerian framework for human
capital, in which the marginal productivity of education is equated across sectors. It is logical for
job tasks, however, due to occupation-level indivisibilities.
7

The assumptions that all elements of are positive and have continuous support assures that the self-selection of
workers into occupations is well determined. Absent this assumption, two occupations that offered different rewards
to a specific task but identical rewards to all other tasks could be equally attractive to a given worker (i.e., if that
worker’s endowment had
).

8

Let the output of worker
(2)

in occupation

equal:

,

where

and

is a worker-specific error term. Note that

is not constrained to be

positive; a worker who is poorly matched to an occupation could have a negative marginal
product in that occupation (e.g., an untrained airline pilot). We normalize the output price for
each occupation at unity. This normalization is not restrictive since a logarithmic change in the
market price of an occupation’s output is equivalent to a multiplicative change in the
exponentiated terms of (2).8 Thus, we can summarize the production structure of occupation
with the vector

.

Assuming that workers are paid their marginal product, the log wage of worker
occupation

in

is:

(3)

.

Taking this production structure as given, each worker chooses the occupation

that maximizes

her output and hence earnings:
(4)

.
This economy is characterized by self-selection of workers into occupations based on

comparative advantage. In equilibrium, the marginal worker in occupation

8

We could equivalently write equation (2) as

that reflects market demand and other factors,

, where
and

is indifferent

is a productivity shifter

.

9

between that occupation and the next best alternative.9 Infra-marginal workers, however, strictly
prefer the occupation they have selected relative to any alternative.
What are the ‘returns to tasks’ in this model? Differentiating equation (3) indicates that task
returns in this model are occupation-specific:
(5)

.

The equilibrium of the model ensures that workers are employed in the occupation that has the
highest reward to their bundle of tasks. But this does not imply that workers necessarily receive
the maximum market reward to each element in their task bundle, or that each element is equally
valuable in all occupations.
B. Empirical implications
As is well understood, identifying the market locus of the ‘return to skills’ in the presence of
self-selection is not empirically straightforward (cf. Heckman and Honoré, 1990). Given the nonrandom assignment of workers to occupations, a regression of log wages on workers’ job tasks
will not generally recover the average returns to those tasks. Concretely, workers with high
efficiencies in given tasks will sort towards occupations that have high rewards for those tasks.
The average ‘return to tasks’ observed in the data will therefore not correspond to the average
return over all occupations (e.g., if workers were randomly assigned to occupations).
Estimating task returns using observational data is particularly challenging when the rewards
to clusters of tasks are correlated. Consider, for example, a hypothetical case where the marginal
productivity of physically demanding tasks is strictly positive in all occupations (

) but

9

This assumes that occupations are sufficiently ‘close together’ that there is a marginal worker in each occupation.
With a finite set of occupations, it is conceivable that all workers would strictly prefer the occupation they are in.
This would not affect our substantive conclusions.

10

the productivity of physical tasks is highest in occupations that have comparatively low returns
to other major task categories (e.g., analytical tasks), so
intensity of worker

. Let

and

denote the

physical and analytical task input on the job respectively. An OLS

regression of log wages on individual task input of the following form,
(6)

,

may potentially recover a ‘return’ to physically demanding tasks that is negative (i.e.,

).

This spurious inference would arise because the cross-occupation correlation between the returns
to physical and analytical tasks is negative, even though the within-occupation return to physical
tasks is uniformly positive.10
Without further strong assumptions on the distribution of task endowments, it would be
difficult to identify the structural parameters that underlie this model. Fortunately, the model
implies testable restrictions on the relationship between tasks and wages that do not rely on these
parameters.
Proposition 1: Let be the set of all occupations that have non-zero employment in equilibrium.
For each occupation
, it must be the case that
is not vector dominated by some another
occupation

where

.

This proposition says that for occupation
cannot be an alternative occupation

to attract workers (and thus belong to

that has both a higher intercept and a higher return to all

tasks. If such an occupation existed, all workers in occupation
employment in occupation

), there

and hence

would strictly prefer

.

10

This bias will be present if there is non-zero cross-occupation correlation between the returns to physical and
analytical tasks. The sign and magnitude of the bias will depend on both the sign and magnitude of the covariance
term and the magnitude of cross-occupation variances in task returns. Proposition 2 below demonstrates that there
must be a negative cross-occupation correlation in task returns among occupations that have positive employment in
equilibrium.

11

Proposition 2: For all occupations
positive across all task pairs
for some

, the covariance among task returns cannot be uniformly

. That is, either

for some

, or

, or both.

To see why this proposition holds, consider a case where all occupations use only one task
, so each occupation

can be described by the double

, it must be the case that
must be a worker
be some value of

. For each occupation
for some value of

who prefers occupation

to

such that

. Given that
, so some worker

. That is, there

, however, there must also
prefers

to . Jointly,

these restrictions imply that:
(7)

.

That is,

: the returns to tasks must negatively covary within the set of occupations

that have positive employment. Were this not so, some subset of workers could be made strictly
better off by changing occupations. This reasoning extends directly to the case of multiple tasks:
the covariances among task returns, and between task returns and the intercept, cannot be
uniformly positive.11 We test this proposition below.
II.

Data Sources
The primary data source for our analysis is a module of the Princeton Data Improvement

Initiative survey (PDII) that collects data on the tasks that workers regularly perform on their
jobs. The items in this module cover cognitive, interpersonal, and physical dimensions of job
demands, corresponding to the Data, People, and Things classification used in the Dictionary of
Occupational Titles (DOT).

11

It does not need be negative for all elements, however.

12

Four items elicit information on cognitive job demands: (1) the length of longest document
typically read as part of the job (ranging from one page or less to more than 25 pages); (2)
frequency of mathematics tasks involving high-school or higher mathematics (algebra, geometry,
trigonometry, probability/statistics, or calculus); (3) frequency of problem solving tasks requiring
at least 30 minutes to find a good solution; and (4) proportion of work day managing or
supervising other workers.
Three items on face-to-face interactions with people other than co-workers or supervisors
elicit information on interpersonal job demands: (1) interactions with customers or clients; (2)
interactions with suppliers or contractors; and (3) interactions with students or trainees.12
Two items elicit information on physical and routine job tasks: (1) proportion of the work
day spent performing physical tasks such as standing, operating machinery or vehicles, or
making or fixing things by hand; and (2) proportion of the work day spent performing short,
repetitive tasks.
For many analyses, we use principal components analysis to combine the PDII items into
three standardized scales, which we designate Data, People, Things, respectively.
The PDII also includes information on individuals’ human capital, demographic background,
occupation, industry, and wages. We use this information to examine the correlations between
standard demographic measures and job tasks across individuals, and to analyze the value of
using task measures to predict wages in addition to standard human capital and demographic
background variables. For all analyses we use a consistent sample of cases with full information
on tasks, demographics, human capital, and wages, and with at least five cases per three-digit
occupation (n=928). The restriction that occupations contribute at least five cases is needed for
12

These questions are from the PDII module that measures the suitability of jobs for international offshoring
(Blinder and Krueger, 2008).

13

the analyses comparing the relative strengths of individual- and occupation-level measures of job
tasks in wage determination.13
Many of the task questions contained in the PDII are adapted from the survey of Skills,
Technology, and Management Practices (STAMP) written and fielded by Handel (2007,
2008a,b; see also Hilton 2008). Handel (2008a) provides an extensive discussion of the
conceptual basis, validity, and reliability of the STAMP measures, which generalizes to the
closely related PDII measures. Handel (2008b) presents preliminary results from the STAMP
survey, which can be compared to results presented below.
An alternative source of information on job content is the U.S. Department of Labor's
Occupational Information Network (O*Net), which contains occupation-level measures and
replaces the Dictionary of Occupational Titles as an official career counseling tool. The O*Net
database, many years in the making, is only beginning to be used by academic researchers.
Nevertheless, O*Net offers a useful point of comparison to the PDII measures. If parallel
measures from the PDII and O*Net are highly correlated, this offers evidence of what
psychologists call convergent validity. Comparing results across wage regressions provides
evidence on the relative strengths of two different approaches to measuring task input (Handel
2008a) and the value-added of person-level relative to occupation-level job content measures.
We construct scales from a large number of O*Net items that appear likely to capture

13

Our precise sample restrictions in sequence are as follows (based on an initial PDII sample of 2,500): Currently
working (238 observations dropped); ages 18 through 64 (211 observations dropped); non-missing task measures
(35 observations dropped); non-missing education (6 observations dropped); non-missing wage data (486
observations dropped); non-missing, non-military and non-farm occupation (36 observations dropped); at least 5
valid observations in each occupation (573 observations dropped).

14

comparable or closely related dimensions of task input to those in the PDII and match these
measures to the PDII data at the six digit occupation level.14
Other approaches to providing job task measures alongside human capital variables at the
person level include the German IAB/BIBB dataset and the British Skills Survey, which are
repeated cross-sections of workers over one or two decades (Spitz-Oener, 2006; Dustman,
Ludsteck and Schonberg, forthcoming; Felstead et al., 2007). If the PDII analyses prove
illuminating, they may suggest the utility of a similar time series for the United States.
III. Job Tasks: Levels and Differences among Education and Occupation Groups
A. PDII measures
The PDII measures, summarized in Table 1, provide a snapshot of the skill levels and task
content of U.S. jobs. Only about one-quarter (23 percent) of wage and salary workers use any
kind of higher-level math on at least a weekly basis, while about one-third (35 percent) read
documents longer than 6 pages on a regular basis as part of their jobs. Along with similar results
from the STAMP survey, these are the first figures on the actual levels of math and reading that
individuals use on their jobs. A far larger percentage report engaging in extended problem
solving either daily (40 percent) or weekly (29 percent). Approximately 31 percent manage or
supervise others at least half the time on their jobs.
More than half (52 percent) of wage and salary workers have a lot of contact with customers
or clients as part of their jobs. Not surprisingly, far fewer people have a lot of contact with
students or trainees (23 percent) and suppliers (11 percent) as part of their jobs.

14

See the Appendix for a detailed description of the O*Net measures we use.

15

Slightly more than half (51 percent) of workers report spending more than half their time on
short, repetitive tasks and almost two-thirds (63 percent) report spending at least half their time
doing physical tasks, such as standing, handling objects, or operating equipment.
Because these characteristics describe important dimensions of both jobs and the persons
selected into them, one expects the measures to be associated with both demographic and job
characteristics. Subsequent columns of Table 1 summarize PDII responses by gender, race
(White, Black, Hispanic), and education (less than high school, high school only, some college,
college degree or greater).15 Appendix Table 1 provides a similar breakdown by major
occupational group. There are striking differences across gender, race and education categories
in all task activities. For example, females are substantially more likely than males to spend at
least half of their time on repetitive tasks (58 versus 44 percent), and Blacks and Hispanics are
substantially more likely than Whites to spend at least half of their time on physical job tasks
(these percentages are 60, 73, and 77 for Whites, Blacks and Hispanics respectively).
To facilitate comparisons among PDII variables, and for later comparison with O*Net
measures, we converted the response scales of individual PDII items to a common metric (0-10)
with two exceptions: length of longest document typically read on the job is converted to number
of pages; and the interpersonal items measuring frequency of face-to-face contact are converted
into dichotomous measures.
The upper panel of Table 2 presents means and standard deviations for the converted PDII
sample for the full sample overall and by education group. The final column of the table provides
the contrast in the mean of each task between the most educated and least educated group,
normalized by the standard deviation of the task measure. Among the individual PDII items, the
15

1.5 percent of the sample is in a fourth race group, Asian. Because of the very small number of respondents (12),
we do not separately tabulate this group.

16

range in means across education groups is particularly sizable for physical tasks (1.3 standard
deviations) and problem solving, reading, and routine tasks (1.1 standard deviations). Somewhat
surprisingly, neither managerial/supervisory activity nor advanced math tasks are strongly
associated with educational level in the PDII. None of the interpersonal measures is associated
with education, but this is somewhat less surprising for reasons noted below.
The lower panel of Table 2 summarizes three composite variables constructed from the PDII
that correspond to the canonical Data, People and Things scales introduced by the DOT. The first
principal component of the variables measuring interactions with Customers, Suppliers and
Trainees is used as a scale of a job’s involvement with People (explained variance=0.44). Unlike
the other domains, the individual variables measure qualitative differences rather than levels or
magnitudes of skill demands. This may account for their relatively low association with
education and weak performance in the analyses below.16
The first principal component of the Routine and Physical variables is used as a scale for a
job’s level of involvement with Things (explained variance=0.69). These characteristics define
jobs with high levels of routine, generally manual demands, and engagement with physical
objects. The PDI variables measuring Management, Problem Solving, Math and Reading,
identify jobs that demand relatively high levels of cognitive skills. Their first principal
component is used as an overall scale of a job’s involvement with Data (explained
variance=42%). Notably, the ranges in task means between education groups are especially large
for the scales dealing with Things (1.5 s.d.) and Data (1.3 s.d). This is not so for the People
measure, though this is not surprising for the reasons noted.

16

For a discussion of the difficulties involved in measuring interpersonal skill demands, see Handel 2008a.

17

Table 3 shows the breakdowns by one-digit occupation. In this case, the largest and smallest
means differ by approximately 1.5 standard deviations for physical tasks and customer service
interactions, by 1.4 standard deviations for routine tasks, 1.3 standard deviations for
managerial/supervisory tasks, 1.1 standard deviations for math and problem solving, and 0.8
standard deviations for reading and training tasks. The ranges for Data, People and Things are
1.5, 1.2 and 1.8 standard deviations, respectively. Broad occupation does a better job than
personal education in identifying individuals who perform most of the interpersonal tasks.
Table 4 presents correlations of the items and scales with one another and with education and
three-digit occupation. Education has moderate correlations with the physical tasks (-0.39),
routine tasks (-0.39), and problem solving (0.31) items, and moderate to strong correlations with
the Data (0.39) and Things (-0.47) scales. The correlations with detailed occupation were
calculated by regressing item and scale values on the 91 unique three-digit occupation dummies
present in the data, and taking the square root of R-squared to calculate the multiple correlation
coefficient. These correlations are much larger than those involving personal education, ranging
from 0.51 to 0.75. This is not surprising given the greater fineness of the occupational categories
and the fact that the items were designed to measure the characteristics of jobs more directly than
the qualities of the people holding them.
Taken together, the PDII task measures show sensible patterns of variation across education
and occupational groups, with some exceptions, and provide concrete information on what
people do on their jobs and the share of the workforce performing each task at various
intensities.
B. Comparing Job Task Measures between the PDII and O*Net

18

Table 5 presents correlations between composites of O*Net items and the corresponding
PDII items, measured both at the individual level (column 1) and averaged by detailed
occupation to match the level of O*Net's aggregation (column 2). In selecting O*Net scales for
comparison, we attempted to use only those O*Net variables that have a close relationship to the
underlying construct. With 234 question items arrayed across seven questionnaires, the O*Net
offers an abundance of candidate measures. We selected on average four O*Net measures for
each PDII measure, with a minimum of two O*Net variables used for each comparison and a
maximum of eight. Details of these variables are given in the Appendix.
The correlations between PDII person-level responses and O*Net occupation-level mean
responses given in the first column of Table 5 are moderately strong for managing, problem
solving, and reading (>0.38), and even stronger for physical job demands and the Data and
Things scales (0.56 - 0.63). The math and People scale correlations are rather modest (<0.30), as
are measures of contacts with suppliers and students/trainees.
Taking advantage of the detail of the O*Net questionnaire, we created two subscales for the
routine measures that are intended to capture multiple dimensions of routine tasks, following the
taxonomy of Autor, Levy and Murnane (2003). One scale measures routine physical (‘manual’)
activities such as tasks involving repetitive motion. The second measures routine cognitive tasks,
such as checking entries in a ledger.17 Notably, the PDII measure of routine activity correlates
positively with the O*Net routine manual scale (0.36) and negatively with the O*Net routine
cognitive scale (-0.22). Scrutiny of Appendix Table 1, summarizing PDII responses by
17

The O*Net questions used to represent routine manual tasks are: repetitive physical tasks; keeping a pace set by
machinery or equipment; and time spent making repetitive motions. The routine cognitive questions are:
documenting/recording information; processing information; importance of continuous, repetitious physical
activities (like key entry) or mental activities (like checking entries in a ledger); and clerical knowledge.

19

occupation, provides some insight into this pattern. The major occupation for which workers are
most likely to report spending almost all of their time on routine activities is Transportation (63
percent). By contrast, Clerical workers are lower on self-reported routine activities (47 percent)
than workers in service occupations (48 percent).
The clear contrast between the routine cognitive and routine manual scales is apparent in
Appendix Table 2, which tabulates standardized means of PDII and O*NET measure by
occupation. The major occupations with the highest level of routine cognitive tasks are clerical
occupations, management, and professional specialty occupations. Two of three of these
occupations score well below average for routine manual tasks, with clerical occupations scoring
close to average. By contrast, the major occupations with the highest levels of routine manual
tasks are production, transportation, and construction/repair occupations. All three are well
below the mean for routine cognitive tasks.
These results suggest two inferences. First, the routine cognitive and routine manual task
groups in O*Net almost certainly comprise two distinct factors; treating them as a single
repetitiveness dimension (as done by the PDII survey) sacrifices important detail and, in the
process, places far greater weight on the manual than cognitive dimension of routine activity.
Second, the response pattern to the PDII routine activity question suggests that this item may not
be well worded.18 While the PDII question was intended to capture workers’ involvement in
tasks that are repetitive in the sense of being mechanistic, procedural and readily subject to
automation, it is apparent that many respondents understood the question to include activities
that are repetitive in the sense of being mundane or potentially tedious—such as driving a
18

The precise wording of Q25b is, “How much of your workday (involves/involved) carrying out short, repetitive
tasks? (Almost all the time, more than half the time, less than half the time, almost none of the time.)”

20

vehicle or serving customers. These tasks are not mechanistic or readily automatable in the sense
intended by the question. But they are likely viewed as repetitive by workers who perform them
on an ongoing basis. This probable flaw in the construction of the PDII question should be kept
in mind when interpreting subsequent regression results.19
The second column of Table 5 gives occupation-level correlations between the O*Net
composite measures and the corresponding occupation-level means of the PDII variables for the
91 occupations represented in the data set. By construction, these correlations must be as large or
larger than the person-level correlations in the first column since the O*Net measures only vary
at the occupation level and thus cannot be correlated with within-occupation variation in
responses to the PDII measures. The magnitudes of the occupation-level correlations are in fact
quite high. Six are in the range 0.62-0.82, compared to none in first column.
This pattern raises an important question: what is the appropriate level of measurement for
job tasks? Though O*Net measures are based upon person-level surveys of incumbent workers
or, for some scales, designated subject matter experts, the O*Net data are only released to
researchers as occupation-level measures, typically means. A potential virtue of the PDII survey
instrument is that it measures tasks at both the individual and (via aggregation) occupation level.
The value-added of using person–level task measures, alongside or instead of occupational
averages, is however unknown. One objective of the PDII survey effort is to study this question.
Industrial psychologists typically view occupational titles as coherent, well-defined job
categories rather than merely as pragmatic classification tools, and hence tend to treat all withinoccupation variation as measurement error (Harvey 1991; Peterson, et al. 1999). While we
concur that some portion of within-occupation variation in survey measures of job task content
19

In ongoing work, we are exploring task ‘automatability’ in detail by classifying respondents’ self-reports of
primary work activities in the PDII survey according to the automatability of these tasks.

21

will reflect measurement error, it appears unlikely that there is no meaningful variation in job
tasks within occupations. Casual empiricism suggests that it is commonplace for workers with
the same occupational title in a given firm to differ in their skills, responsibilities, work
activities, and pay.20
A contribution of the PDII instrument is that it allows us to assess both the extent to which
task self-reports vary within-occupations and the degree to which this variation captures
substantive differences among workers rather than simply measurement error. To shed light on
these issues, Section V of the paper analyzes the relationship between individual earnings and
job tasks measured at both the individual and occupation level, in the latter case using both PDII
and O*Net measures.
IV. Explaining Differences in Job Tasks: The Roles of Human Capital, Occupation, and
Demographic Characteristics
Although almost all analyses of job tasks treat tasks as an occupation level construct, a virtue
of the PDII’s individual-level task measures is that they permit investigation of the variance of
job tasks within occupations and the degree to which this variation is systematically related to
worker as well as job attributes. This section analyzes the extent to which the tasks workers
perform on the job can be explained by their individual human capital, demographic attributes,
and the technical requirements of the job itself, proxied by detailed occupation dummies.

20

This view is clearly untenable for the large, residual “not elsewhere classified” occupations, which are quite likely
heterogeneous and not really detailed occupations in their own right at all. Moreover, since the specificity and
boundaries of occupational classifications differ among survey instruments and are subject to regular revision, it is
not possible in practice that measured occupational categories correspond to distinct and unique job categories in the
economy.

22

We focus on the three task composites: Data tasks, representing cognitive demands; People
tasks, representing customer service and managerial tasks; and Things, representing manual
demands and engagement with physical objects. We fit OLS models of the form:
(8)

,

where the vector
language),

includes human capital measures (education, potential experience, primary

is a vector of demographic characteristics (race, ethnicity and sex), and

is a

vector of 91 occupation dummies corresponding to the full set of occupations contributing 5 or
more observations to our sample. 21 The reference group for this regression is white male high
school graduates who, implicitly, are employed in the ‘average’ occupation in the sample.
Table 6a presents regressions results for the Data scale, which is standardized with mean zero
and variance one. Models (1) through (3) enter each set of independent variables separately and
models (4) through (7) enter them in varying combinations. Human capital variables—education,
potential experience, and Spanish language—explain approximately 19 percent of overall
variation in on-the-job use of Data tasks (column 1), whereas demographic characteristics—race,
ethnicity and sex—explain only about 2 percent of variation in this measure (column 2).
Nevertheless, female workers and those with limited English proficiency perform less
cognitively demanding work on average, with Data task demands about one-fifth of a standarddeviation below that of white males.
Column 3 shows that detailed occupation dummies explain a substantial proportion (48%) of
total variation in use of Data tasks. Even within occupations, however, human capital measures
are significant determinants of workers’ use of Data tasks. Holding occupation constant, workers

21

The Spanish language dummy variable is equal to one for individuals who required the Spanish-language version
of the PDII questionnaire.

23

with post-college education perform more cognitively demanding tasks, though the effect is
greatly diminished, while Spanish language workers perform less cognitively demanding tasks.
When all three sets of variables—human capital, demographic, and occupation—are entered
simultaneously, post-college education and Spanish language remain significant determinants of
Data tasks. Female-male and Black-white gaps in Data tasks are eliminated.
In sum, the models suggest that a substantial proportion of cognitive task content is ‘hard
wired’ into occupations. Individual human capital remains relevant, however, for workers with a
graduate education and limited English proficiency even after accounting for occupation effects.
Notably, human capital differences do not explain the substantial female-male gap in the use of
cognitive tasks, but this difference is entirely accounted for by occupation. Thus, race and sex
exert an independent effect on occupational assignment that does not run through human capital
as measured in our data.22
As was the case with cognitive tasks, estimates for interpersonal tasks in Table 6b show that
occupation explains a large proportion of the total variation in interpersonal job demands (33%),
while human capital explains a relatively small proportion (6%), with this latter fact mostly
reflecting the strong negative effects of limited English language proficiency. What differs
between cognitive and interpersonal tasks, however, is that the effects of education and race on
interpersonal tasks operate largely within rather than between occupations. Better educated
workers, limited English proficient workers, and Asian workers perform significantly fewer
interpersonal tasks than white high school males, and this pattern is equally pronounced whether
or not we condition on occupation.
22

Bertrand, Goldin and Katz find that among U.S. workers obtaining an MBA from a top U.S. business school
between 1990 and 2006, substantial gender gaps in career advancement develop and accumulate within a few years
of graduation, reflecting differences in training prior to MBA completion, differences in career interruptions, and
differences in weekly hours (Bertrand, Goldin and Katz 2009).

24

Women are more specialized in interpersonal tasks than males, consistent with expectations.
Notably, this pattern is entirely explained by differences in occupational specialization rather
than differences in specialization within occupations. Somewhat unexpectedly, blacks are more
likely to perform interpersonal tasks on their jobs than non-Hispanic whites, and this effect
remains robust across all models.
Table 6c shows that both human capital and occupation account for a substantial proportion
of the variation in the Things scale, explaining 28 and 54 percent of variance respectively.
Demographic characteristics explain a much smaller proportion of variance, and these
relationships are not robust to inclusion of either human capital or occupation variables. There is
a strong negative relationship between education and physical task demands, and a strong
positive relationship between limited English proficiency and physical task demands. Though the
magnitude of these relationships is diminished by inclusion of occupation dummies—indicating
that these human capital variables affect physical task demands in part through occupational
choice—both attributes remain robust predictors of physical task demands within occupation.
In net, these results are notable for revealing the structuring power of occupations as
determinants of job content. Indeed, occupation is the dominant measurable predictor of job
tasks in our data. Alongside this fact, measures of human capital—in particular, education and
English language proficiency—are in all cases significant predictors of within- as well as
between-occupation variation in job tasks. Human capital therefore plays a dual role in
determining workers’ job tasks, both allocating workers to occupations and influencing their job
tasks within occupations (though it is apparent that the occupation channel is quantitatively
larger). Race and sex are also strong predictors of workers’ job tasks across all categories. But
the relationship between race, sex and job tasks runs largely through occupational assignment;
25

we find few systematic race or sex differences in cognitive or physical job task demands among
workers within the same occupation.
V.

Job Tasks and Wages: Descriptive Regressions

A. Predicting wages using the PDII measures
To what extent does within-occupation variation in job tasks capture substantive differences
in job content rather than simply noise? In the absence of canonical, observational measures of
job tasks, we test whether self-reported variation in job tasks, net of occupation, human capital
and sex/gender, is a robust predictor of wages. If so, this would provide prima facie evidence that
self-reported task variation is likely to be informative about job content even within
occupations.23
We explore the predictive relationship between tasks and wages in Table 7 by regressing
workers’ log hourly wages in the PDII on the Data, People, and Things scales, as well as human
capital, demographic background, and detailed occupation variables. As a benchmark, column
(1) presents a standard cross-sectional Mincerian wage regression of hourly wages on human
capital and demographic measures. All variables in this regression have the expected signs and
magnitudes, and the R-squared of this model is equal to 0.38, comparable to standard crosssectional models estimated using the Current Population Survey.
Column (2) replaces the human capital and demographic controls from the Mincerian
regression with the three tasks scales. The task measures predict substantial wage differentials. A
one standard deviation increase in the cognitive task scale is associated with a 22 percent wage
premium, while a one standard deviation increase in physical tasks is associated with a 24
23

An alternative interpretation would be that some omitted worker characteristic affects both wages and selfreported jobs tasks but does not affect actual job tasks per se (or does not affect wages through tasks). We cannot
dismiss this possibility out of hand, though we doubt it is the primary explanation for the findings below.

26

percent wage penalty. Interpersonal task demands as measured in the PDII are associated with a
slight wage penalty of 6 percent. By themselves, the three task scales account for 33 percent of
the variation in log wages, which is only slightly less than the full set of human capital and
demographic measures. When 91 detailed occupation dummies are used in place of the task
measures (column 3), they account for 57 percent of wage variation.
To what extent do these three sets of variables—human capital and demographics, job tasks,
and occupation—capture distinct sources of wage variance? Columns (4) and (6) show that the
task measures remain significant predictors conditional on either human capital and demographic
measures or on a full set of occupation dummies. Similarly, columns (4) and (5) indicate that the
human capital measures are also robust to inclusion of either task measures or occupation
variables. Finally, column (7) demonstrates that when all three clusters of variables are entered
simultaneously, each is a significant predictor of wages. Notably, comparing the Wald tests for
the joint significance of each group of variables (bottom row of Table 7), we find that the Fstatistic for the task measures is substantially larger than for the other two groups of variables.
While statistical significance is not synonymous with economic significance, the economic
magnitude of the relationship between tasks and wages—even net of other variables—is sizable.
Within occupations, a one standard deviation increase in cognitive tasks predicts an 8 log point
wage premium. A one standard deviation increase in physical tasks predicts a 14 log point wage
penalty. When human capital and gender controls are also included (column 7), these effects are
diminished slightly but remain large and significant.
One aspect of these results merits particular emphasis. The regressions in Tables 6a through
6c indicate that even within occupations, there are systematic differences in job tasks among
workers who differ according to human capital, race and gender. This pattern directly implies
27

that job tasks must also be predictive of wages, since tasks are correlated with education,
demographics and occupation, and these variables are in turn predictors of wages. What is not
known from the prior results, however, is whether the residual variation in job tasks remaining
after netting out occupation, education, race and sex is also predictive of wages. Column (7) of
Table 7 reveals that it is. Thus, we read this evidence as plainly supporting the hypothesis that
self-reported job tasks capture substantive differences in job activities among workers both
within and between occupations.
B. Do PDII Task Measures Add Value to O*Net Task Measures?

One further means to assess the value-added of the individual-level PDII measures is to
compare their predictive power with the corresponding O*Net measures. Table 8 performs this
comparison. The first column repeats the simple regression of wages on the Data, People, and
Things scales used in the prior table. In this case, we cluster standard errors at the occupation
rather than person level since we will also be using occupation-level means of PDI and O*Net
variables as predictors.
In column (2), we replace the individual-level scales with PDII occupational means,
following the O*Net approach.24 These occupation-level scales are also highly significant
predictors of earnings. When both person- and occupation-level task measures are entered
simultaneously (column 3), both sets of variables remain highly significant, and this remains true
when human capital and demographic controls are added to the model.25 Notably, the person-

24

To avoid confounding the predictive power of occupational averages with the direct correlation between a
worker’s own tasks and wages, the O*Net occupational mean assigned to each observation is a ‘leave-out’ mean,
equal to the grand mean of the task measure for all workers in the occupation except for the current worker. Thus,
the leave-out mean of each task measure differs very slightly for each worker in the sample.
25

Demographic variables are included in Table 8 in all columns that include human capital measures, but we do not
tabulate them to conserve space.

28

level and occupation-level relationships between job tasks and wages are similar in magnitude to
one another, a hypothesis that we formally test and accept in the third to final row of the table.
Thus, the within-occupation relationship between tasks and wages is indistinguishable from the
between-occupation relationship.26 Given that measurement error in tasks is greater at the person
than the occupation level, this pattern argues strongly that the person-level tasks measures are
quite informative.
In the remaining columns of Table 8, we introduce the O*Net measures and compare their
performance with the PDII scales. Column (5) shows that the standardized O*Net Data scale has
a stronger effect on wages (0.38) than the parallel PDII Data scale calculated at the occupational
level (0.23). But when both O*NET and PDII occupation-level scales are included in column (7),
the PDII effect is larger and more precisely estimated. Notably, neither the O*Net People nor
Things scales has a significant effect on wages. Moreover, the PDII Data variables measured at
both the individual and occupational levels remain largely robust as a group to the inclusion of
all additional predictors, while all O*Net measures become insignificant in columns (7) through
(9) when PDII occupation-level measures are included.27
This exercise demonstrates that the PDII task measures compare favorably with O*Net
occupation-level measures as a predictor of worker-level outcomes, despite the fact that the
O*Net measures are derived from much larger samples. Mean PDII scores could potentially be
usefully merged onto other data sets that lack detailed information about the task content of jobs,
such as the Current Population Survey. But the results in Tables 7 and 8 underscore that this
26

The table reports tests of the joint hypothesis that the coefficient of each of the three person-level task measures is
equal to the corresponding occupation-level measure. We further test these restrictions for each task measure
separately, and readily accept the hypothesis in all cases. The closest any test comes to rejecting the null is in
column (3), where equality of the person- and occupation-level Things measure is accepted at the 9 percent level.
27

We again accept the hypothesis of the joint equality of the PDII person and occupation level measures in column
(9).

29

procedure would discard meaningful variation in job tasks that occurs within rather than between
occupations. Indeed, the main takeaway of these wage models is that, relative to standard,
occupation-level measures of job tasks, person-level task measures appear to add substantial
value in explaining worker outcomes
VI. Job Tasks and Wages: Testing the Model’s Predictions
In this final section, we provide an exploratory test of the primary implication of the
conceptual model, which is that the returns to the task categories must negatively covary within
occupations.28 To implement this test, we first estimate separately by occupation the following
OLS regression of workers’ hourly wages on their task inputs:
(9)

.

The explanatory variables in this model are the three PDII composite task measures used in
earlier tables. As discussed above, for an occupation to be included in this exercise, it must
contribute at least five wage observations to the PDII data set, yielding a sample of 91
occupations and 928 observations.29
Using the parameters obtained from estimating equation (9), we perform bivariate
regressions of the elements of

on one another, in all cases weighting by the

sum of worker weights within an occupation:
(10)

28

To simplify terminology but with no loss of generality, we also refer to an occupation’s wage regression intercept
as a ‘task return.’
29

There are four parameters to be estimated, and hence at least five observations are required to estimate the
parameters plus standard errors. It is for this reason that our entire analysis is limited to occupations with five-plus
observations.

30

The conceptual framework predicts that the point estimates for

will generally be negative.

Panel A of Table 9 presents estimates of equation (10). In three of six cases, the bivariate
relationships are negative, and two of these estimates are highly negative. By contrast, none of
the three positive relationships is significant at the 5 percent level. Though we did not have
strong priors on the relationships among task returns, the pattern of results accords with
conventional notions about occupational specialization. Occupations that most reward physical
tasks have comparatively low returns to analytical tasks and vice versa, and occupations that
most reward analytical tasks have comparatively low returns to interpersonal tasks and vice
versa.
There are of course numerous limitations to this procedure. One such limitation is that there
is substantial imprecision in estimates of task returns due to the fact that the occupation-level
regressions from which these estimates are drawn have a very small number of data points in
most cases.30 To address this concern, we re-estimated equation (10) using median regressions,
which are substantially more robust to outliers than OLS regressions. These median regression
models, found in panel B of Table 9, strongly reinforce the OLS results. Four of six point
estimates obtained from the median regressions are negative, and as before, two are negative and
significant. Precision is substantially higher for these models, however, with t-ratios of 3.9 and
7.2, respectively, for the physical-analytical and analytical-interpersonal regressions. By contrast,
the two positive point estimates are very far from significance. These median regressions
demonstrate that the OLS results are not driven by outliers—in fact, just the opposite.
Though these patterns are supportive of the model, substantial uncertainties remain. A first is
that the estimation procedure applied to equation (9) implicitly assumes that there is no self30

The mean number of observations per occupation is 10.2 and the median is 8.

31

selection into occupations based upon unobserved characteristics, specifically

in equation (2).

If in fact, the fixed, unobserved, person-level component of productivity is correlated with
occupational choice, this would bias estimates of the intercept terms,

, in the occupation-

level regressions.
A second limitation is that our procedure implicitly assumes that the three task measures used
for the estimation comprise exhaustive measures of the tasks rewarded within occupations. If this
strong assumption is not met, and, furthermore, the omitted tasks are correlated with the included
task measures, we will again obtain biased estimates of

, where the direction of

the bias is not ex ante ascertainable.
Finally, the imprecision inherent in the estimation prevents us from applying even stronger
tests of the conceptual apparatus. Taken literally, the model implies that each worker is
employed in the occupation that provides the highest wage given her task endowment. We
should accordingly be able to compare the calculated counterfactual wage (based upon
) that each worker would have received in all possible occupations to confirm
that no worker could be made better off by switching occupations. Given, as above, the
imprecision in estimates of

, and moreover, the likelihood that our estimation

procedure captures only a subset of relevant tasks, this test would be trivially rejected.31
VII. Conclusions

31

An additional strict implication of the model that is not supported by the estimates is that returns to each task
should be positive in all occupations. Though we would of course expect some point estimates to be negative simply
due to sampling variability, we suspect that the issue is somewhat deeper. Of greatest concern is that the estimated
returns to physical tasks are negative in the majority of occupations. This suggests, plausibly, that there is
unobserved negative selection of low-skilled workers into occupations that are intensive in physical tasks. Other
interpretations are possible, however, including compensating differentials, incomplete measurement of tasks, and
non-competitive wage setting between occupations.

32

This paper makes three contributions to the expanding theoretical and empirical literature
that employs job tasks as a building block for conceptualizing and quantifying job skill demands.
Drawing on original, representative survey data containing detailed measures of workers’ job
tasks, along with standard demographic and wage measures, we document that job tasks vary
substantially within (as well as between) occupations and we establish that variation in job tasks
among workers in the same occupations is systematically related to their race, gender and
English-language proficiency. The most pronounced and systematic differences in job task
activity are found for Spanish language speakers, who perform substantially fewer analytic and
interpersonal tasks and substantially more repetitive physical and cognitive tasks than equally
educated workers in the same occupations. We also find that black workers perform a
disproportionate number of interpersonal tasks. Notably, females perform substantially fewer
analytic tasks and substantially more interpersonal and routine tasks than equally educated
males, a pattern that is driven by differences in occupational category. In fact, we find no
significant differences in average task input between males and females once we condition on a
full set of occupation effects.
The second contribution of the paper is to explore the degree to which person-level variation
in job tasks is a robust predictor of wages. While it would be hypothetically possible that the
systematic differences in self-reported job tasks that we find between demographic groups
primarily reflect cultural differences in response patterns rather than realized differences in job
tasks, the wage analysis suggests that this is not the case. Both between and within occupational,
demographic and education groups, the tasks that workers perform on the job are significant
predictors of their hourly wages. Notably, this predictive power is maintained when occupationlevel job task measures from O*Net and the PDII survey are also included in regression models.
33

Thus, job task measures effectively distinguish normally unobserved attributes of workers and
jobs that vary within occupational, demographic and education groups.
The third contribution of the paper is to offer a conceptual framework that makes explicit the
causal links between workers’ human capital endowments, their occupation, the tasks that they
perform on the job, and the wages they earn. The simple observation that motivates our approach
is that, while workers can hold multiple jobs, they can supply tasks to only one job at a time. The
indivisible bundling of tasks within jobs means that the productivity of particular task inputs will
not necessarily be equated across jobs—and so the ‘law of one price’ will not generally apply to
the market rewards to job tasks.
We propose instead a high-dimensional Roy model in which the allocation of workers to
tasks is driven by individuals self-selecting into occupations to maximize their incomes given
their skill endowments. While this framework is primarily intended to build intuition rather than
guide empirical analysis, our exploratory empirical analysis provides some initial support for the
conceptual model. In particular, we find that estimated ‘returns to tasks’ negatively covary
within occupations, which is a necessary condition for self-selection to occur; absent this
negative covariance, a single occupation might conceivably offer the highest return to all tasks,
and thus attract the entire labor force. We believe that further refinement and rigorous testing of
this conceptual and empirical approach is a promising avenue for future study.

34

References
Acemoglu, Daron. 1999. “Changes in Unemployment and Wage Inequality: An Alternative
Theory and Some Evidence.” American Economic Review, 89 (December), 1259-1278.
Autor, David H., Lawrence F. Katz, and Melissa S. Kearney. 2008. “Trends in U.S. Wage
Inequality: Revising the Revisionists.” Review of Economics and Statistics. 90(2), May, 300323.
Autor, David H., Lawrence F. Katz, and Melissa S. Kearney. 2006. “The Polarization of the U.S.
Labor Market.” American Economic Review, 96:2 (May), 189-194.
Autor, David H., Frank Levy, and Richard J. Murnane. 2003. “The Skill Content of Recent
Technological Change: An Empirical Investigation.” Quarterly Journal of Economics,
118(3), November, 1279-1333.
Bartel, Ann, Casey Ichniowski and Kathryn L. Shaw. 2007. “How Does Information Technology
Affect Productivity? Plant-Level Comparisons of Product Innovation, Process Improvement,
and Worker Skills.” Quarterly Journal of Economics, 122(4), November.
Black, Sandra E. and Alexandra Spitz-Oener. Forthcoming. “Explaining Women's Success:
Technological Change and the Skill Content of Women's Work.” Review of Economics and
Statistics.
Bertrand, Marianne, Claudia Goldin, and Lawrence F. Katz. 2009. “Dynamics of the Gender Gap
for Young Professionals in the Corporate and Financial Sectors.” NBER Working Paper No.
14861, January.
Blinder, Alan. 2007. “How Many U.S. Jobs Might be Offshorable?” Princeton University Center
for Economic Policy Studies Working Paper No. 142, March.
Blinder, Alan and Alan B. Krueger. 2008. “Measuring Offshorability: A Survey Approach.”
Princeton University Working Paper, October.
Cortes, Patricia. 2008. “The Effect of Low-skilled Immigration on U.S. Prices: Evidence from
CPI Data,” Journal of Political Economy, 116(3), 381-422.
Dustmann, Christian, Johannes Ludsteck and Uta Schönberg. 2009. “Revisiting the German
Wage Structure.” Quarterly Journal of Economics, 114(2), May, 843-882.
Goos, Maarten and Alan Manning. 2003. “Lousy and Lovely Jobs: The Rising Polarisation of
Work in Britain.”CEPR Working Paper No. 0604, December.
Felstead, Alan, Duncan Gallie, Francis Green and Ying Zhou. 2007. “Skills at Work, 1986 to
2006.” University of Oxford, ESRC Centre on Skills, Knowledge and Organisational
Performance.

35

Goos, Maarten and Alan Manning. 2007. “Lousy and Lovely Jobs: The Rising Polarization of
Work in Britain.” Review of Economics and Statistics 89 (February), 118-33.
Handel, Michael J. 2007. “A New Survey of Workplace Skills, Technology, and Management
Practices (STAMP): Background and Descriptive Statistics.” Paper presented at “Workshop
on Research Evidence Related to Future Skill Demands,” The National Academies,
Washington, DC.
Handel, Michael J. 2008a. “Measuring Job Content: Skills, Technology, and Management
Practices.” Institute for Research on Poverty Discussion Paper No. 1357-08. Madison, WI:
University of Wisconsin.
Handel, Michael J. 2008b. “What Do People Do at Work? A Profile of U.S. Jobs from the
Survey of Workplace Skills, Technology, and Management Practices (STAMP).” Paper
presented at the Labor Seminar, Wharton School of Management, University of
Pennsylvania.
Harvey, Robert J. 1991. “Job Analysis.” in Handbook of Industrial and Organizational
Psychology, Marvin D. Dunnette and Leaetta M. Hough, eds. Palo Alto, CA: Consulting
Psychologists Press.
Heckman, James J. and Bo E. Honoré. 1990. “The Empirical Content of the Roy Model.”
Econometrica, 58(5), September, 1121-1149.
Hilton, Margaret. 2008. Research on Future Skill Demands: A Workshop Summary.
Washington, DC.: National Research Council of the National Academies.
Jensen, Bradford J. and Lori G. Kletzer. 2006. “Tradable Services: Understanding the Scope and
Impact of Services Outsourcing.” in Brookings Trade Forum 2005, “Offshoring WhiteCollar Work — The Issues and the Implications,” Lael Brainard and Susan M. Collins,
editors, pp. 75-134.
Jensen, Bradford J. and Lori G. Kletzer. Forthcoming. “Measuring Tradable Services and the
Task Content of Offshorable Services Jobs,” in Labor in the New Economy, Katharine
Abraham, Mike Harper and James Spletzer, eds., University of Chicago Press.
Kleiner, Morris M. and Alan B. Krueger. 2008. “The Prevalence and Effects of Occupational
Licensing.” NBER Working Paper No. 14308, September.
Manning, Alan. 2004. “We Can Work it Out: the Impact of Technological Change on the
Demand for Low-Skill Workers.” Scottish Journal of Political Economy, 51(5), November,
581-608.
Mincer, Jacob. 1974. Schooling, Experience, and Earnings. New York: NBER Press.

36

Miller, Anne R., Donald J. Treiman, Pamela S. Cain, and Patricia A. Roose (editors).
1980.Work, Jobs and Occupations: A Critical Review of the Dictionary of Occupational
Titles, Washington, DC: National Academy Press.
Peri, Giovanni and Chad Sparber. Forthcoming. “Task Specialization, Immigration and Wages”
American Economic Journal: Applied Economics.
Peterson, Norman G., Michael D. Mumford, Walter C. Borman, P. Richard Jeanneret, and Edwin
A. Fleishman. An Occupational Information System for the 21st Century: The Development of
O*NET. Washington, DC: American Psychological Association.
Roy, A.D. 1951. “Some Thoughts on the Distribution of Earnings.” Oxford Economic Papers,
3(2), 135-146.

Smith, Christopher L. 2008. “Implications of Adult Labor Market Polarization for Youth
Employment Opportunities.” MIT working paper, July 2008.
Spitz-Oener, Alexandra. 2006. “Technical Change, Job Tasks and Rising Educational Demands:
Looking Outside the Wage Structure.” Journal of Labor Economics 24 (April), 235-70.
Weiss, Matthias. 2008. “Skill-biased Technical Change: Is There Hope for the Unskilled?”
Economics Letters, 100, 439-441.

37

Appendix
We constructed multi‐item, additive scales from the O*Net database that are parallel to individual
items in the PDII in order to evaluate the convergent validity of the PDII items and to assess the
relative merits of job‐level measures, like the PDII, and occupation‐level measures, like O*Net.
Scale names are in bold and the O*Net items are listed below them.
Reading
Reading comprehension (Skills questionnaire, no. 1)
Written letters and memos (Work Context questionnaire, no. 5)
Mathematics
Mathematics (Skills questionnaire, no. 5)
Mathematics (Knowledge questionnaire, no. 14)
Managing others
Management of personnel resources (Skills questionnaire, no. 35)
Coordinating the work and activities of others (Work Activities questionnaire, no. 33)
Developing and building teams (Work Activities questionnaire, no. 34)
Guiding, directing, and motivating subordinates (Work Activities questionnaire, no. 36)
Administration and management (Knowledge questionnaire, no. 1)
Problem solving
Complex problem solving (Skills questionnaire, no. 17)
Critical thinking (Skills questionnaire, no. 7)
Judgment and decision making (Skills questionnaire, no. 31)
Making decisions and solving problems (Work Activities questionnaire, no. 10)
Thinking creatively (Work Activities questionnaire, no. 11)
Physical tasks
Handling and moving objects (Work Activities questionnaire, no. 17)
Performing general physical activities (Work Activities questionnaire, no. 16)
Time spent bending or twisting body (Work Context questionnaire, no. 41)
Time spent climbing ladders, scaffolds, poles, etc. (Work Context questionnaire, no. 36)
Time spent keeping or regaining balance (Work context questionnaire, no. 39)
Time spent kneeling, crouching, stooping, or crawling (Work context questionnaire, no. 38)
Time spent standing (Work context questionnaire, no. 35)
Time spent using hands to handle, control, or feel objects, tools, or controls (Work context questionnaire,
no. 40)
Time spent walking or running (Work context questionnaire, no. 37)
Repetitive cognitive tasks
Documenting/recording information (Work Activities questionnaire, no. 24)
Processing information (Work Activities questionnaire, no. 8)
Importance of continuous, repetitious physical activities (like key entry) or mental activities (like
checking entries in a ledger) (Work Context questionnaire, no. 51)
Clerical (Knowledge questionnaire, no. 2)
38

Repetitive physical tasks
Keeping a pace set by machinery or equipment (Work Context questionnaire, no. 55)
Time spent making repetitive motions (Work Context questionnaire, no. 42)
Customer interaction
Assisting and caring for others (Work Activities questionnaire, no. 29)
Communicating with people outside the organization (Work Activities questionnaire, no. 27)
Performing for or working directly with the public (Work Activities questionnaire, no. 32)
Interactions that require you to deal with external customers (as in retail sales) or the public in general (as
in police work) (Work Context questionnaire, no. 8)
Customer and personal service (Knowledge questionnaire, no. 5)
Supplier/contractor interactions
Management of material resources (Skills questionnaire, no. 34)
Communicating with people outside the organization (Work Activities questionnaire, no. 27)
Student/trainee interactions
Instructing (Skills questionnaire, no. 15)
Coaching and developing others (Work Activities questionnaire, no. 37)
Training and teaching others (Work Activities questionnaire, no. 35)
Education and training (Knowledge questionnaire, no. 23)

39

Table 1. PDII Task Measures by Major Demographic Group: Employed Workers ages 18-64
FeWhite
Black
His< HS
HS
Some
Grad
Coll
All
Male
Male non-Hisp non-Hisp panic Grad
Time on physical tasks
Almost all
49.3
51.4
47.1
44.1
61.0
67.9
83.2
63.8
48.1
Half or more
14.0
15.5
12.5
15.4
12.3
8.8
1.4
16.2
16.8
Less than half
36.7
33.1
40.4
40.6
26.8
23.2
15.5
20.0
35.1

Coll +
25.7
12.8
61.5

Time on repetitive tasks
Almost all
34.0
Half or more
16.7
Less than half
49.3

28.0
15.6
56.5

40.2
17.9
42.0

31.1
16.6
52.3

35.1
12.4
52.5

47.3
20.2
32.5

48.9
16.7
34.4

51.6
14.6
33.8

29.5
26.6
43.9

14.9
10.8
74.3

Time on managing/supervising
Almost all
21.5
Half or more
9.4
Less than half
69.1

23.7
11.0
65.4

19.3
7.8
72.9

21.5
9.9
68.7

28.5
4.8
66.8

18.6
10.9
70.6

29.5
4.8
65.7

14.1
4.3
81.5

22.5
10.3
67.2

26.3
15.3
58.4

Solve problems of 30+ minutes
Daily
39.8
Weekly
28.5
Less than weekly
31.7

41.4
29.9
28.7

38.2
27.0
34.8

42.7
29.4
27.9

37.8
16.9
45.3

26.5
32.8
40.7

21.0
11.0
68.1

25.6
33.9
40.5

43.9
27.5
28.7

56.7
28.5
14.8

Use high-school+ math
Daily
Weekly
Less than weekly

16.4
9.5
74.1

14.7
5.8
79.5

14.7
8.0
77.3

11.2
7.0
81.7

23.3
7.2
69.5

13.2
2.5
84.3

13.8
7.2
79.0

15.3
8.9
75.8

18.3
8.6
73.1

Longest document typically read at job
6 - 25 + pages
35.2
35.8
2-5 pages
29.7
29.2
1 or fewer
35.1
35.1

34.6
30.3
35.2

38.6
30.3
31.1

33.9
24.8
41.3

18.1
31.5
50.4

25.9
10.2
63.9

20.3
25.0
54.8

31.2
38.8
30.0

56.8
32.6
10.6

Have a lot of face to face contact with... (excluding coworkers)
None
12.9
12.5
13.3
11.6
15.7
Customers/clients
51.8
47.1
56.5
52.5
65.3
Suppliers/contractors 10.5
14.5
6.4
10.7
13.3
Students/trainees
22.5
17.4
27.7
22.0
27.1
Patients
11.8
6.2
17.5
11.9
17.8

17.4
41.6
8.9
21.2
7.4

11.4
43.8
6.7
19.0
8.0

17.7
54.0
14.3
21.8
7.5

10.4
54.9
10.3
17.0
17.7

10.5
49.0
7.8
28.6
12.3

14.6

8.7

33.4

26.1

31.7

15.6
7.7
76.8

Sample share
100.0
50.8
49.2
73.7
n = 928. See text for details of sample construction.

10.1

Table 2. Means and Standard Deviations of PDII Task Variables,
Overall and by Education Group

All

<HS

HS

Some College PostCollege Grad College

Stand'zed
Post-Coll
< HS gap

A. PDII Survey Measures
0. Sample share (%)

100.0

8.7

33.4

26.1

21.1

10.6

1. Manage (0-10)

3.4
(4.0)

3.7
(4.4)

2.5
(3.5)

3.5
(4.1)

3.9
(4.1)

5.0
(4.1)

0.3

2. Problem solve (0-10)

7.1
(3.1)

5.3
(3.3)

6.2
(3.2)

7.3
(3.0)

8.0
(2.6)

8.7
(2.2)

1.1

3. Math (0-10)

2.7
(3.8)

1.8
(3.6)

2.3
(3.7)

2.8
(3.9)

3.2
(4.0)

3.6
(3.9)

0.5

9.3
(13.2)

6.1
(11.2)

6.3
(11.7)

8.1
(11.8)

11.6
(13.3)

20.1
(16.1)

1.1

5. Routine (0-10)

5.5
(3.8)

6.8
(3.5)

6.9
(3.5)

5.7
(3.5)

3.9
(3.6)

2.6
(3.0)

-1.1

6. Physical (0-10)

6.2
(4.2)

8.7
(3.0)

7.7
(3.5)

6.4
(4.0)

4.1
(4.3)

3.2
(4.1)

-1.3

7. Customer (% yes)

52
(50)

44
(50)

54
(50)

55
(50)

52
(50)

42
(50)

0.0

8. Suppliers (% yes)

11
(31)

7
(25)

14
(35)

10
(30)

10
(30)

3
(16)

-0.1

9. Train (% yes)

22
(42)

19
(40)

22
(41)

17
(38)

28
(45)

31
(46)

0.3

4. Read (0 - 40 pages)

B. Composites of PDII Measures
1. Data

0.00
(1.0)

-0.50
(0.9)

-0.37
(0.9)

0.05
(1.0)

0.34
(0.9)

0.78
(0.8)

1.3

2. People

0.00
(1.0)

-0.18
(1.1)

0.07
(1.1)

-0.03
(1.0)

0.06
(1.0)

-0.13
(0.8)

0.1

3. Things

0.00
0.56
0.44
0.06
-0.56
-0.89
-1.5
(1.0)
(0.8)
(0.8)
(0.9)
(0.9)
(0.9)
n = 928. Each cell gives mean and standard deviation of the respective standardized or
composite PDII measure. The final column gives the gap in the mean measure between workers
with post-college education minus workers with less than high school education, divided by the
standard deviation of the measure.

Table 3. Means and Standard Deviations of PDII Task Variables by Major Occupation
Manager

Prof
Spec

Tech/
Sales

Constr/
Clerical Repair

Production

TransPort

Standzed
Min - Max
Service
Gap

A. PDII Survey Measures
0. Sample share (%)

12.8

19.8

13.5

16.1

5.6

4.2

8.6

19.4

1. Manage (0-10)

6.9
(3.8)

3.6
(3.8)

4.1
(3.8)

2.2
(3.7)

2.9
(3.5)

3.8
(4.0)

1.6
(3.4)

2.4
(3.7)

1.3

2. Problem solve (0-10)

8.8
(2.2)

8.3
(2.4)

6.5
(3.2)

6.9
(3.0)

8.4
(2.1)

7.5
(2.7)

5.4
(3.0)

5.5
(3.4)

1.1

3. Math (0-10)

4.0
(4.1)

3.4
(3.9)

2.1
(3.8)

2.0
(3.6)

5.1
(4.1)

4.0
(4.2)

3.5
(4.3)

0.8
(2.0)

1.1

14.1
(15.0)

15.5
(15.2)

6.3
(10.5)

6.7
(11.1)

11.2
(14.4)

6.5
(11.9)

5.3
(11.9)

6.0
(10.0)

0.8

5. Routine (0-10)

2.6
(2.9)

3.4
(3.3)

6.4
(3.5)

6.9
(3.3)

4.9
(3.4)

6.4
(3.3)

8.0
(3.0)

6.6
(3.8)

1.4

6. Physical (0-10)

2.9
(4.1)

4.1
(4.2)

7.2
(3.4)

4.5
(4.3)

9.3
(1.7)

8.2
(2.9)

9.3
(1.6)

8.7
(2.9)

1.5

7. Customer (% yes)

39
(49)

52
(50)

91
(29)

33
(47)

36
(49)

13
(34)

53
(50)

60
(49)

1.5

8. Suppliers (% yes)

18
(39)

1
(12)

12
(33)

8
(27)

23
(43)

7
(26)

31
(47)

4
(19)

1.0

9. Train (% yes)

14
(34)

36
(48)

31
(46)

15
(35)

24
(43)

8
(27)

3
(17)

26
(44)

0.8

4. Read (0 - 40 pages)

B. Composites of PDII Measures
1. Data

0.8
(0.8)

0.5
(0.8)

-0.2
(0.9)

-0.3
(0.9)

0.4
(0.8)

0.1
(1.0)

-0.5
(1.0)

-0.6
(0.8)

1.5

2. People

-0.1
(1.0)

0.0
(0.8)

0.6
(0.9)

-0.3
(1.0)

0.0
(1.1)

-0.7
(0.9)

0.1
(1.1)

0.0
(0.9)

1.2

3. Things

-0.9
(0.9)

-0.6
(0.9)

0.3
(0.9)

0.0
(0.8)

0.3
(0.6)

0.4
(0.8)

0.8
(0.6)

0.5
(0.8)

1.8

n = 928

Table 4. Correlations among PDII task variables
A. PDII Survey Measures

1. Manage
2. Problem solve
3. Math
4. Read
5. Routine
6. Physical
7. Customer
8. Suppliers
9. Training
10. Education
11. Occupation

1
2
3
4
5
6
1.00
0.24 1.00
0.19 0.29 1.00
0.16 0.21 0.17 1.00
-0.10 -0.23 -0.08 -0.21 1.00
-0.12 -0.27 -0.02 -0.23 0.38 1.00
0.10 -0.03 -0.05 0.03 0.06 0.17
0.06 0.11 0.13 -0.02 0.07 0.08
0.16 0.03 0.00 0.05 -0.03 0.08
0.18 0.31 0.11 0.29 -0.38 -0.39
0.65 0.58 0.54 0.55 0.63 0.75

7

8

1.00
0.20 1.00
0.22 0.07
0.01 -0.06
0.64 0.51

9

10

1.00
0.09
0.59

1.00
0.74

B. Composites of PDII Survey Measures
1
2
3
4
1. Data
1.00
2. People
0.12 1.00
3. Things
-0.34 0.13 1.00
4. Education
0.39 0.02 -0.47 1.00
5. Occupation
0.689 0.575 0.733 0.74
n=928. Statistics in bottom row of each panel are multiple correlation coefficients from regressions on
three-digit occupation dummies

Table 5. Correlations among Parallel
PDII and O*NET Variables
PDII task measurement level

Individual

1.
2.
3.
4.
5.

6.
7.
8.
9.

Manage
Problem solve
Math
Read
Routine tasks
a. manual
b. cognitive
Physical
Customer
Suppliers
Train

11. Data
12. People
13. Things

Occupation
Mean

A. Individual Variables
0.48
0.45
0.25
0.38
0.36
-0.22
0.63
0.34
-0.01
0.25
B. Composite Scales
0.56
0.11
0.57

0.75
0.78
0.47
0.63
0.58
-0.34
0.84
0.53
-0.01
0.43

0.82
0.19
0.78

N
928
91
The correlations for routineness show association of the
single PDII routine task measure with O*NET's routine
manual (line 5a) and routine cognitive (line 5b) items. The
PDII's physical task item correlates more strongly with both
the O*NET routine manual measure (0.45) and routine
cognitive measure (-0.52). The O*NET math measure also
correlates more strongly with the PDII problem solving
(0.39) and reading (0.34) measures than the PDII math
item.

Table 6a. Regressions of Standardized PDII Task Variables on
Demographics, Human Capital Measures and Occupation Dummies.
Dependent Variable: Data (Analytic) Tasks
(1)

(2)

(3)

(4)

(5)

(6)

(7)

Less than High
School

0.03
(0.12)

0.02 0.17
(0.12) (0.12)

0.16
(0.12)

Some College

0.35
(0.08)

0.37 0.08
(0.08) (0.07)

0.05
(0.07)

College

0.62
(0.08)

0.64 0.05
(0.08) (0.09)

0.05
(0.09)

Post-College

1.03
(0.11)

1.04 0.29
(0.11) (0.12)

0.30
(0.12)

Experience

0.04
(0.01)

0.04 0.01
(0.01) (0.01)

0.01
(0.01)

Experience /100

-0.09
(0.02)

-0.09 -0.04
(0.02) (0.02)

-0.04
(0.02)

Spanish language

-0.66
(0.16)

-0.68 -0.48
(0.17) (0.15)

-0.66
(0.16)

2

Female

-0.22
(0.07)

-0.24
(0.06)

-0.03 0.02
(0.07) (0.07)

Black

-0.10
(0.11)

-0.04
(0.10)

0.12 0.07
(0.09) (0.09)

Hispanic

-0.26
(0.09)

0.08
(0.10)

0.17 0.28
(0.08) (0.09)

Asian

0.02
(0.24)

-0.13
(0.22)

-0.17 -0.28
(0.20) (0.20)

91 occ dummies

No

No

Yes

No

Yes

Yes

Yes

R-Squared

0.19

0.02

0.47

0.20

0.50

0.48

0.50

F(Education vars)
p-value

29.7
0.00

30.5
0.00

2.1
0.08

2.1
0.08

F(Gender + race)
5.1
4.3
1.6
3.0
p-value
0.00
0.00
0.17 0.02
n = 928. Standard errors are in parentheses. All models include a
constant and are weighted by sampling weights.

Table 6b. Regressions of Standardized PDII Task Variables on
Demographics, Human Capital Measures and Occupation Dummies.
Dependent Variable: People (Interpersonal) Tasks
(1)

(2)

(3)

(4)

(5)

(6)

(7)

Less than High
School

0.00
(0.13)

0.00 -0.01
(0.13) (0.13)

0.00
(0.13)

Some College

-0.11
(0.08)

-0.13 -0.01
(0.08) (0.08)

-0.04
(0.08)

College

-0.04
(0.09)

-0.03 -0.07
(0.09) (0.10)

-0.06
(0.10)

Post-College

-0.19
(0.12)

-0.16 -0.33
(0.12) (0.13)

-0.28
(0.13)

Experience

-0.01
(0.01)

-0.01 -0.02
(0.01) (0.01)

-0.02
(0.01)

Experience /100

-0.01
(0.02)

0.00 0.02
(0.02) (0.02)

0.03
(0.02)

Spanish language

-0.86
(0.17)

-0.88 -0.87
(0.18) (0.16)

-0.93
(0.17)

2

Female

0.10
(0.07)

0.14
(0.06)

-0.07 0.01
(0.08) (0.08)

Black

0.25
(0.11)

0.21
(0.10)

0.37 0.32
(0.10) (0.10)

Hispanic

-0.16
(0.09)

0.01
(0.10)

-0.07 0.11
(0.09) (0.10)

Asian

-0.34
(0.24)

-0.47
(0.23)

-0.60 -0.71
(0.22) (0.22)

91 occ dummies

No

No

Yes

No

Yes

Yes

Yes

R-Squared

0.06

0.02

0.33

0.07

0.38

0.35

0.40

F(Education vars)
p-value

1.0
0.42

1.0
0.43

1.8
0.13

F(Gender + race)
3.6
3.0
5.6
p-value
0.01
0.01
0.00
n = 928. Standard errors are in parentheses. All models include a
constant and are weighted by sampling weights.

1.2
0.29
5.6
0.00

Table 6c. Regressions of Standardized PDII Task Variables on
Demographics, Human Capital Measures and Occupation Dummies.
Dependent Variable: Things (Physical or Repetitive Cognitive) Tasks
(1)

(2)

(3)

(4)

(5)

(6)

(7)

Less than High
School

0.00
(0.11)

-0.02 0.02
(0.11) (0.11)

0.00
(0.11)

Some College

-0.32
(0.07)

-0.34 0.01
(0.07) (0.07)

0.02
(0.07)

College

-0.94
(0.08)

-0.94 -0.30
(0.08) (0.09)

-0.30
(0.09)

Post-College

-1.23
(0.10)

-1.23 -0.43
(0.10) (0.11)

-0.43
(0.11)

Experience

-0.03
(0.01)

-0.03 -0.02
(0.01) (0.01)

-0.02
(0.01)

Experience /100

0.05
(0.02)

0.04 0.03
(0.02) (0.02)

0.04
(0.02)

Spanish language

0.51
(0.15)

0.42 0.40
(0.16) (0.14)

0.41
(0.15)

2

Female

0.08
(0.06)

0.12
(0.06)

0.10 0.12
(0.07) (0.07)

Black

0.20
(0.10)

0.04
(0.09)

0.07 0.05
(0.09) (0.09)

Hispanic

0.48
(0.09)

0.12
(0.09)

0.13 -0.01
(0.08) (0.08)

Asian

0.10
(0.24)

0.22
(0.21)

0.32 0.33
(0.18) (0.18)

91 occ dummies

No

No

Yes

No

Yes

Yes

Yes

R-Squared

0.28

0.03

0.54

0.29

0.56

0.54

0.57

F(Education vars)
p-value

59.6
0.00

58.4
0.00

6.3
0.00

F(Gender + race)
8.1
2.0
2.3
p-value
0.00
0.10
0.05
n = 928. Standard errors are in parentheses. All models include a
constant and are weighted by sampling weights.

6.2
0.00
1.8
0.13

Table 7. OLS Regressions of Log Hourly Wages on Task Scales,
Demographic Variables, and Occupation Dummies
(1)

(2)

(3)

(4)

(5)

(6)

(7)

Data

0.22
(0.02)

0.14
(0.02)

0.08
0.07
(0.02) (0.02)

People

-0.06
(0.02)

-0.05
(0.02)

-0.04 -0.03
(0.02) (0.02)

Things

-0.24
(0.02)

-0.13
(0.02)

-0.14 -0.10
(0.02) (0.02)

Less than High
School

0.13
(0.07)

0.13
0.17
(0.07) (0.07)

0.16
(0.07)

Some College

0.21
(0.05)

0.11
0.07
(0.04) (0.04)

0.07
(0.04)

College

0.54
(0.05)

0.33
0.21
(0.05) (0.05)

0.18
(0.05)

Post-College

0.82
(0.06)

0.51
0.38
(0.07) (0.07)

0.31
(0.07)

Experience

0.04
(0.01)

0.03
0.02
(0.00) (0.00)

0.01
(0.00)

Experience2 /100

-0.06
(0.01)

-0.04 -0.03
(0.01) (0.01)

-0.02
(0.01)

Spanish language

-0.58
(0.10)

-0.48 -0.40
(0.09) (0.09)

-0.34
(0.09)

Female

-0.28
(0.03)

-0.23 -0.10
(0.03) (0.04)

-0.09
(0.04)

Black

-0.16
(0.06)

-0.14 -0.16
(0.05) (0.05)

-0.15
(0.05)

Hispanic

-0.07
(0.06)

-0.06 -0.04
(0.05) (0.05)

-0.06
(0.05)

Asian

0.08
(0.13)

0.10
0.09
(0.12) (0.11)

0.12
(0.11)

91 occ dummies

No

No

R-squared

0.38

0.33

F(Educ + demo vars)
p-value

40.1
0.00

F(Task measures)
p-value

149.9
0.00

Yes
0.57

No

Yes

0.46

0.61

16.7
0.00

7.2
0.00

44.2
0.00

Yes
0.60

Yes
0.63
5.5
0.00

19.6
0.00

11.6
0.00

F(Occ dummies)
12.4
5.6
6.3
4.3
p-value
0.00
0.00
0.00
0.00
n = 928. Standard errors are in parentheses. All models include a constant
and are weighted by sampling weights.

Table 8. OLS Wage Regressions of Log Hourly Wages on Occupation-Level Task Measures from
O*Net and Occupation- and Person-Level Task Measures from PDII
(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

PDII Data (person level)

0.22
(0.03)

0.12
(0.03)

0.09
(0.03)

0.14
(0.03)

0.11
(0.03)

0.09
(0.03)

PDII People (person level)

-0.06
(0.03)

-0.03
(0.03)

-0.03
(0.02)

-0.06
(0.03)

-0.04
(0.03)

-0.03
(0.02)

PDII Things (person level)

-0.24
(0.03)

-0.15
(0.02)

-0.09
(0.02)

-0.17
(0.03)

-0.15
(0.02)

-0.08
(0.02)

PDII Data (occ mean)

0.23
(0.05)

0.16
(0.05)

0.10
(0.04)

0.17
(0.06)

0.12
(0.05)

0.08
(0.05)

PDII People (occ mean)

-0.02
(0.03)

0.00
(0.03)

-0.02
(0.02)

-0.05
(0.04)

-0.02
(0.04)

-0.04
(0.03)

PDII Things (occ mean)

-0.15
(0.04)

-0.06
(0.04)

-0.04
(0.04)

-0.12
(0.07)

-0.05
(0.08)

-0.02
(0.06)

ONet Data (occ mean)

0.38
(0.09)

0.18
(0.09)

0.10
(0.11)

0.05
(0.11)

-0.01
(0.10)

ONet People (occ mean)

0.02
(0.09)

0.06
(0.07)

0.08
(0.08)

0.08
(0.08)

0.07
(0.07)

ONet Things (occ level)

0.04
(0.06)

0.07
(0.06)

0.07
(0.06)

0.07
(0.07)

0.01
(0.05)

Less than High School

0.15
(0.10)

0.14
(0.10)

Some College

0.06
(0.05)

0.05
(0.05)

College

0.26
(0.07)

0.24
(0.06)

Post-College

0.43
(0.09)

0.40
(0.09)

Experience

0.02
(0.01)

0.02
(0.01)

Experience2 /100

-0.04
(0.01)

-0.04
(0.01)

Spanish language

-0.50
(0.18)

-0.49
(0.18)

R-Squared

0.33

F(PDII person level)
p-value
F(PDII occ means)
p-value
F(Equality of PDII personand occ-level coefs)
F(Onet occ means)
p-value
F(Education vars)
p-value

57.0
0.00

0.33

0.38

0.47

38.8
0.00

16.8
0.00
8.1
0.00
1.6
0.20

8.6
0.00
5.0
0.00
0.4
0.77

0.30

0.34

16.8
0.00
4.5
0.01

23.9
0.00
7.5
0.00

0.37

5.6
0.00

1.5
0.23

0.39

0.48

16.7
0.00
2.0
0.12
0.8
0.50
1.0
0.38

7.9
0.00
1.7
0.18
0.4
0.77
0.7
0.58
6.7
0.00

Table 8 notes. N = 928. Standard errors in parentheses are clustered on occupation (91 categories).
All models include a constant and are weighted by sampling weights. Columns 4 and 9 additionally
include dummies for female, Black, Asian and Hispanic.

Table 9. Bivariate Relationships among Regression Coefficients obtained from
Occupation-Level Wage Regression Models: OLS Estimates

(1)
b(things)

(2)
b(data)

Dependent Variable
(3)
(4)
b(people) Intercept

(5)
Intercept

(6)
Intercept

A. OLS Estimates
b(data)

-0.24
(0.09)

b(people)

0.22
(0.14)
-0.34
(0.11)

b(things)
Constant
R-Squared

0.24
(0.15)
0.07
(0.11)

-0.03
(0.17)

-0.17
(0.04)

0.08
(0.05)

-0.01
(0.05)

2.88
(0.06)

2.90
(0.06)

2.89
(0.07)

0.08

0.10

0.00

0.03

0.03

0.00

B. Median Regression Estimates
b(data)
b(people)
b(things)

-0.21
(0.05)

0.09
(0.10)
-0.46
(0.06)

0.09
(0.12)
-0.03
(0.08)

-0.13
(0.16)

Constant

-0.16
0.07
-0.08
2.86
2.88
2.88
(0.03)
(0.04)
(0.04)
(0.07)
(0.07)
(0.09)
n = 91. Each column in each panel corresponds to a separate regression (OLS or
Median) of the indicated coefficient on the tabulated coefficients plus an intercept.
Standard errors are given in parentheses. Models are weighted by the sum of PDII
sampling weights in each occupation.
Coefficients used as regressions variables above are obtained from person-level
regressions of log hourly wages on standardized PDII task input measures (data,
people and things) and an intercept, where regressions are performed separately
within each PDII occcupation that contains at least 5 observations (91 occupations
total). Regressions are weighted by sum of PDII sampling weights in each occupation.
Means and SD's of the variables used in these models are: b(data) 0.09 (0.46); bpepl 0.02 (0.41); b(things) -0.19 (0.38); intercept 2.90 (0.60).

Appendix Table 1. PDII Task Measures by Occupation: Employed Workers ages 18-64

Manager

Prof.
Spec

Tech
/Sales

Clerical

Constr/
Repair

Production

Transport

Service
Occs

Time on physical tasks
Almost all
Half or more
Less than half

20.1
7.8
72.1

24.5
17.6
57.9

51.0
26.4
22.5

31.3
10.7
58.1

83.8
12.0
4.1

63.9
25.9
10.3

81.2
15.7
3.2

80.3
5.8
13.9

Time on repetitive tasks
Almost all
Half or more
Less than half

5.4
11.9
82.7

12.7
12.3
75.0

41.7
19.6
38.7

46.8
20.8
32.5

22.3
18.7
59.0

37.8
24.3
38.0

63.2
19.8
17.0

48.1
15.4
36.5

Time on managing/supervising
Almost all
53.5
Half or more
14.2
Less than half
32.3

18.1
13.6
68.3

23.5
9.3
67.2

14.7
4.6
80.7

12.3
12.2
75.5

20.7
17.8
61.5

11.8
3.6
84.6

15.2
6.0
78.8

Solve problems of 30+ minutes
Daily
71.4
Weekly
18.5
Less than weekly
10.2

56.9
28.8
14.3

30.6
31.7
37.7

32.7
34.3
33.0

54.9
28.0
17.1

36.9
41.6
21.5

9.0
42.6
48.4

23.9
18.8
57.4

Use high-school+ math
Daily
Weekly
Less than weekly

19.8
5.8
74.5

14.5
5.9
79.6

13.9
4.4
81.8

25.0
26.1
48.9

21.3
16.9
61.9

25.1
3.0
71.9

1.7
2.1
96.2

Longest document typically read at job
6 - 25 + pages
58.7
59.2
2-5 pages
29.1
33.1
1 or fewer
12.2
7.8

20.2
39.9
39.9

25.1
30.3
44.6

45.1
25.5
29.5

15.0
42.6
42.4

13.5
15.7
70.8

25.2
23.7
51.1

Have a lot of face to face contact with... (excluding coworkers)
None
5.5
13.8
0.0
31.9
Customers/clients
39.2
51.9
91.9
33.1
Suppliers/contractor
18.3
1.5
12.3
7.6
Students/trainees
13.6
36.1
31.4
14.6
Patients
3.6
20.7
7.6
11.1

5.0
36.2
23.4
24.0
0.0

29.7
13.3
7.3
7.6
6.9

13.5
52.6
31.1
2.8
2.1

8.6
60.1
3.8
26.3
20.2

5.6

4.2

8.6

19.4

21.0
17.2
61.9

Sample share
12.8
19.8
13.5
n = 928. See text for details of sample construction.

16.1

Appendix Table 2. Comparison of Standardized PDII and O*Net Task Variables by Major
Occupation
Manager

Prof
Spec

Tech/
Sales

Constr/
Clerical Repair

Production

TransPort

Service

A. Individual Variables
1. Managing

1.36
1.72

0.30
0.42

0.09
-0.48

-0.35
-0.18

-0.22
-0.30

0.07
-0.02

-0.73
-0.90

-0.57
-0.65

2. Problem solving

1.08
1.02

0.74
0.74

-0.65
-0.87

0.12
-0.21

0.70
0.15

0.15
0.01

-0.97
-0.81

-1.04
-0.80

3. Math

0.81
0.90

0.50
0.32

-0.46
0.05

-0.20
0.39

1.15
0.51

0.48
0.32

0.11
-0.90

-0.97
-1.24

4. Reading

0.74
0.75

0.83
0.59

-0.58
-0.71

-0.30
0.50

0.25
-0.41

-0.47
-0.72

-0.91
-1.12

-0.62
-0.71

-1.13
-0.91
0.64

-0.84
-0.79
0.60

0.58
0.23
-0.54

0.62
0.06
1.04

-0.21
0.35
-0.71

0.47
1.26
-0.31

0.92
1.13
-0.56

0.57
0.29
-1.17

6. Physical

-1.05
-0.77

-0.41
-0.29

0.50
0.18

-0.71
-0.86

0.96
1.62

0.69
0.45

0.87
0.60

0.77
0.98

7. Customer interactions

-0.36
0.87

0.38
0.96

1.29
0.43

-0.63
-0.07

-0.46
-1.19

-1.22
-1.68

-0.18
-0.88

0.26
-0.43

8. Supplier interactions

0.46
1.70

-0.62
0.31

0.17
-0.74

-0.28
0.04

0.85
-0.23

-0.20
-0.63

1.11
-0.95

-0.46
-0.66

9. Trainee interactions

-0.49
0.87

0.59
1.10

0.52
-0.40

-0.32
-0.25

0.03
-0.25

-0.60
0.00

-0.73
-1.06

0.31
-0.69

5. Routine tasks
PDII measure
O*Net routine manual
O*Net routine cognitive

B. Composites
1. Data

1.31
1.28

0.78
0.61

-0.52
-0.62

-0.23
0.12

0.58
-0.04

0.05
-0.13

-0.86
-1.07

-1.04
-0.96

2. People

-0.28
1.36

0.28
0.91

1.14
-0.30

-0.67
-0.11

0.07
-0.62

-1.14
-0.87

-0.01
-1.13

0.13
-0.70

3. Things

-1.23
-0.93

-0.69
-0.60

0.61
0.23

-0.12
-0.45

0.48
1.11

0.67
0.95

1.01
0.96

0.77
0.71

n = 928

