NBER WORKING PAPER SERIES

COMPASSION OR CASH:
EVALUATING SURVEY RESPONSE INCENTIVES AND VALUING PUBLIC GOODS
V. Kerry Smith
Sharon L. Harlan
Michael McLaen
Jacob Fishman
Carlos Valcarcel
Marcia Nation
Working Paper 21288
http://www.nber.org/papers/w21288

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2015

This material is based upon work supported by the National Science Foundation under grant number
BCS-1026865, Central Arizona-Phoenix Long-Term Ecological Research (CAP LTER). Thanks are
due to Shauna Mortensen for assistance in preparing this manuscript. The views expressed herein are
those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w21288.ack
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2015 by V. Kerry Smith, Sharon L. Harlan, Michael McLaen, Jacob Fishman, Carlos Valcarcel,
and Marcia Nation. All rights reserved. Short sections of text, not to exceed two paragraphs, may be
quoted without explicit permission provided that full credit, including © notice, is given to the source.

Compassion or Cash: Evaluating Survey Response Incentives and Valuing Public Goods
V. Kerry Smith, Sharon L. Harlan, Michael McLaen, Jacob Fishman, Carlos Valcarcel, and
Marcia Nation
NBER Working Paper No. 21288
June 2015
JEL No. C81,H44
ABSTRACT
This paper reports the results of an experiment evaluating the effects of incentives on individuals' willingness
to participate in a survey. By pairing the assessment with a natural field experiment, the analysis considers
private versus public goods as incentives, and estimates respondents' willingness to support the oldest
food bank in the U.S.
V. Kerry Smith
Department of Economics
W.P. Carey School of Business
P.O. Box 879801
Arizona State University
Tempe, AZ 85287-9801
and NBER
kerry.smith@asu.edu
Sharon L. Harlan
School of Human Evolution and
Social Change
Arizona State University
Tempe, AZ 85287-2402
Sharon.Harlan@asu.edu
Michael McLaen
PracticeMax
9382 E. Bahia Drive, Suite B202
Scottsdale AZ 85260
mikemclaen@cox.net

A data appendix is available at:
http://www.nber.org/data-appendix/w21288

Jacob Fishman
Department of Economics
Arizona State University
Tempe, Arizona 85287
fishman.jk@gmail.com
Carlos Valcarcel
Department of Economics
Center for Environmental Economics
and Sustainability Policy
Arizona State University
Tempe, AZ 85287-9801
Carlos.Valcarcel@asu.edu
Marcia Nation
Julie Ann Wrigley Global Institute
of Sustainability
Arizona State University
Tempe, AZ 85287-5402
Marcia.Nation@asu.edu

Compassion or Cash:
Evaluating Survey Response Incentives and Valuing Public Goods

V. Kerry Smith, Sharon L. Harlan, Michael McLean, Jacob Fishman,
Carlos Valcarcel, and Marcia Nation

I. Introduction
This paper reports a unique assessment of the effects of incentives on individuals’
willingness to participate in a social survey.1 We consider monetary incentives, contributions to a
charity, and the option to choose either the cash or a contribution of the same amount. Both the
monetary offer and the treatment offering the ability to select cash or a contribution were
significantly more likely to increase participation when compared with the treatment offering to
donate the same amount to charity. Respondents who received the option allowing a choice of
cash or a contribution, and who participated, were less likely to donate as the size of the
monetary incentive increased.
Our findings are relevant to three different sets of research: (1) we are the first, to our
knowledge, to evaluate the effectiveness of a private good (cash) versus a public good (charity)
in obtaining survey responses; (2) our findings are also relevant to the literature on charitable
giving. By using a strategy relatively free of social pressure, respondents can give to a charity
without being influenced by peer effects.2 Neutralizing such peer effects is important because
about 75 percent of giving has been estimated to be due to social pressure (DellaVigna, List and
1

See Mercer et al. [2015] for a recent meta analysis of the evidence on the role of incentives for survey responses.
Respondents are given the option to take the survey online, by phone, or in person. The majority (64%) who
completed the survey during this experiment took it online.
2

1

Malmendier [2012]). As a result, past research does not offer the ability to estimate the private
demand for charity in a way that is free of this social pressure.3 And (3) our choice based
treatment—cash versus a contribution—extends the logic of field experiments, combining them
with surveys, and provides a new strategy for measuring the value of public goods.
Our choice option is a natural field experiment where subjects decide to give to the
charity.4 The charity is fixed. They must complete the survey to be able to “pay for” the services
of the charity. They make their contribution by surrendering the monetary incentive. The
subjects are a subset of the random sample of residents of the Phoenix metropolitan area. The
potential respondents were randomly assigned to the different treatments associated with the
experiment. The final sample was determined by the respondents’ participation decisions within
the fixed time interval at the outset of the field time of a survey associated with the Central
Arizona Project Long Term Ecological Research Site (LTER).5
Section II outlines the design of our experiment, conducted during the first phase of the
2011 Phoenix Area Social Survey. Section III summarizes our results. Section IV we consider
their implications for each of the research areas we highlighted. The last section summarizes the
findings.
II. Experimental Design

3

More specifically, this literature focuses on mechanisms to increase monetary gifts (Landry et al. [2006], List and
Lucking-Reiley [2002]), the reasons for giving to charity (Croson and Shang [2009], DellaVigna, List, and
Malmendier [2012], List [2011]) and the effects of changes in the price of charitable giving (Clotfelter [1990] and
Karlan and List [2007]).
4

Harrison and List [2004] identified six factors to be considered in determining whether an experiment can be
considered as taking place “in the field”. Their factors include: the nature of the subject pool; the information
subjects bring to the task; the nature of the community; the nature of the task or trading rules applied; the nature of
the financial stakes; and the nature of the environment. (P. 1012)
5
The primary objective of the survey required that adjustments be made in efforts to recruit respondents. As a result,
the experiment had to stop when these changes were made.

2

The Phoenix Area Social Survey (PASS) is one of the activities of the NSF sponsored
Central Arizona Project (CAP) LTER at Arizona State University (ASU). A pilot study for the
first implementation of this survey was conducted in 2001-2002 and full administration of the
social survey was completed in 2006. Our analysis was undertaken as part of the replication of
the survey in 2011. It used the neighborhood definitions established in 2006 and added five new
neighborhoods. The 2006 definition for the neighborhoods was based on two criteria: the
network of monitoring sites for local ecosystems in the Phoenix metropolitan area and the
identification of local communities based on demographic criteria including income, ethnicity,
and retirement status. The 204 ecological monitoring sites maintained as part of the CAP LTER
are used to study vegetation, soil, and other ecological variables on 30 x 30 meter sample plots
distributed over all types of land uses in the study area (see Grimm and Redman [2004]). The
sampling frame for neighborhoods was determined by examining aerial photographs of the areas
surrounding 101 monitoring sites within residential neighborhoods (other sites were located in
undeveloped desert or farmland). 94 sites (101 in residential areas less the 7 eliminated sites)6
were aligned with Census Block groups to identify the socio-economic characteristics of the
sampling units. Eight categories were specified in defining these groups of neighborhoods: low
income urban core;7 low income suburban; middle to high income urban core; middle income
suburban; low to middle income fringe areas;8 high income suburban; high income fringe; and
retirement communities. Five neighborhoods were selected from each category to reflect
variability in the demographic composition and the mix of home owners and renters. This

6

Seven sites of the sixteen visited were eliminated because the residents were not close to the plot used for
monitoring.
7
Urban core neighborhoods are within 5 miles of downtown Phoenix or within 1.5 miles of the other 7 large city
downtowns. The exact distances somewhat based on historical development patterns.
8
Urban fringe areas are defined as having a moderate amount of undeveloped land within a mile of the
neighborhood as of 2005.

3

process yielded a total of 40 neighborhoods in 2006. In 2011, five new neighborhoods from a set
that were important sites for CAP LTER research (one monitoring and four others) were added
to the sample following the same basic structure for identifying neighborhood characteristics.
The survey used a multi modal format and was administered by the ASU Institute for
Social Science Research from May 26, 2011 to January 6, 2012. 2,127 potential respondents
were selected as part of the sample design. Household selection had two dimensions in the 2011
survey. All addresses for the 2006 survey respondents were included in the sample. These were
supplemented with other residential addresses in the sampled neighborhoods. These addresses
were randomly sampled from an enumerated list of tax assessor parcels. The survey was
announced to the sample with several initial mailers.9 First, a postcard in English and Spanish
was sent to the selected addresses notifying the potential respondents of the project and the
specific, randomly assigned incentive for them to participate. Second, a letter in English and
Spanish was sent explaining how to complete the survey along with the same assigned incentive.
The letter included a brochure describing the project in both languages, a one dollar bill, and a
magnet with a graphic design for the project. When the data collection was ended, 806
completed surveys were obtained with a response rate of 43.4% computed using the standard
definition of the American Association for Public Opinion Research [2011].
The incentives varied in two dimensions based on: the amount of incentive and the way it
was offered. Three different monetary values ($10, $20, and $30) were used in each of three
different structures: (a) as a monetary incentive to be mailed to respondents after they completed
the survey; (b) as a donation of one of the three amounts to the First Food Bank Alliance (also

9

The Appendix A provides a brief summary of the details as well as copies of the materials sent to announce the
survey.

4

known locally as St. Mary’s Food Bank)10 when the survey was completed; and (c) as either a
check for one of the three monetary values or a donation of that amount to the food bank upon
completion. The respondents in this treatment could select their preferred option. They could not
modify the amount to be donated, it was all or nothing.
The objective of the survey was to collect information about the knowledge and
environmental attitudes of the Phoenix area population with as high a response rate as possible.
As a result, the experimental period was limited to May through the end of August of 2011. After
that, the focus was changed to increased monetary incentives to encourage a high level of
participation. Our analysis is limited to the respondents who agreed and completed the survey or
who declined or terminated interviews during the experimental period. 557 interviews were
completed and 187 were refused or terminated during the experimental period. Table 1
summarizes the distribution by experimental treatment and final interview status. The original
assignment of treatments by neighborhood was intended to be random. The random assignment
of treatments was made to the 2,127 identified as potential respondents. As indicated in the next
to last row of Table 1, the final disposition does not appear consistent with a random assignment.
Disproportionate assignments were made to the $20 or $30 cash offers and to the $30 choice
treatment. The distribution relevant for the experimental period is the next row up where the $20
and $30 cash treatments are larger than any of the others. These distributions were assigned
randomly for each of the 45 neighborhoods, rather than to the composite sample without regard
to neighborhood. The cash treatment with the $30 incentive continues to be the largest group
with the $20 cash also large. The remainder appear balanced considering the overall sample.

10

There is no religious affiliation associated with the food bank and in order to prevent attitudes toward Catholicism
from influencing responses, we did not refer to the food bank as “St. Mary’s” in our communication with
respondents.

5

The specific treatment each respondent received is random. This unequal distribution
influences the precision of our estimates and the ability to recover measures of responses for all
treatments in all 45 neighborhoods but not the randomization at the individual respondent level.
Thus it should not bias our comparisons evaluating the effects of the treatments.
We evaluated the decisions to take the survey in several different ways. First, relying on
the random assignment to each housing unit (and respondent) we estimate ordinary least squares
(OLS) models with participation decision as a binary dependent variable and the features
defining each treatment as independent variables.11 These include the amount of the monetary
offer and dummy variables for cash, charity, or the choice formats. The second model includes
fixed effects for the neighborhoods along with the design related variables as determinants of
each person’s decision about whether to participate. The last approach is non-parametric. In this
case, each of the nine possible treatments is interacted with dummy variables identifying each of
the 45 neighborhoods. We use OLS, with the dummy variable for the participation decision, as
the dependent variable and these interaction terms to measure the response rates for each
combination where there is sufficient sample to recover an estimate. These estimated coefficients
are then used as dependent variables in second stage models. In this case the framework relies on
what can be detected using these estimates for average response rates across the
treatment/neighborhood combinations for analyzing the experimental data cells. The second and
third approaches provide different strategies to assess whether our conclusions would be affected
by the disproportionate assignment of treatments to some neighborhoods.
Finally, for those respondents who received the treatment allowing a choice of cash or the
charity, we also evaluate what they decided as the monetary incentive changed. This analysis
11

While early research considering binary response, dependent variable models favored probit or logit, Angrist and
Pischke [2009] and Wooldridge [2010, Chapter 15] conclude that the linear probability (OLS) model generally
provides reliable estimates of the directions and magnitudes of the average effects of independent variables.

6

offers the ability to estimate their willingness to support the food bank. These estimates are free
of the social pressure often associated with other efforts to evaluate the motives for charitable
giving.12
III. Results
Table 2 provides the estimates for our linear probability models evaluating the factors
that influenced the decision to participate in the survey. The first column is a model that includes
the amount of the monetary incentive and dummy variables for each of the ways it was offered.
We exclude the intercept to allow estimation of the separate effects for the cash, donation, and
choice treatments. The size of the incentive is not a significant determinant of participation and
this result holds regardless of the model specification considered, including non parametric
estimates.
Our finding contrasts with the overall conclusion of the Mercer et al. [2015] metaanalysis. These authors found the best overall summary of their evaluation of financial incentives
was that the past analyses were consistent with the size of the offer having a significant,
nonlinear effect on response rates. Their analysis does have some important differences with our
research. It involves survey-wide response rates so the meta-regression captures differences
across different surveys. By contrast, our analysis involves the same survey instrument and
evaluates differences across potential respondents at the individual level. The modes considered
in Mercer et al.’s summary were mail, telephone, and in person interviews but were constant for
each survey. The modes in our survey were the outcome of the respondents’ decisions as part of

12

As noted at the outset, the survey could be taken online, by telephone, or with a scheduled personal interview. A
multinomial-logit model considers the demographic factors influencing the choice of online, telephone, or in person
response rates indicated that whites were significantly more likely to use online or telephone, and education was a
significant positive factor in the selection of the online mode.

7

the decision to take the survey. Finally, our analysis did not have a treatment with no incentive.
As a result, it was not possible to consider the response patterns compared to this situation.
All of the coefficients for the dummy variables for the mode effects are statistically
significant. Model 1’s results confirm that providing cash yields significantly higher participation
than when the same amount is offered as a donation. The same is true for the treatment offering a
choice of cash or the contribution when compared to a donation. These test results are reported in
the two rows below the number of observations for each model. Finally, a test for differences in
the coefficients for the cash treatment and a choice to donate or keep the cash fails to reject the
null hypothesis of equality.
The second column includes fixed effects for each neighborhood serving as a sampling
unit in the model along with the dummy variables for the form used in offering incentives. None
of the conclusions summarized based on model (1) are altered. The last two columns in the table
ask a related question, namely, does the comparison of cash versus the choice treatment change
if we account for each respondent’s decision to donate or keep the incentive? To address this
question, it is important to acknowledge the decision of whether or not to keep the cash is likely
correlated with the decision to participate. As a result, the models in columns 3 and 4 are based
on instrumental variable (IV) estimates using the randomly assigned monetary incentive as the
instrument for the choice to donate. As the models in the first two columns indicate, the
monetary incentive was not a significant determinant in potential respondent’s decision to
participate. However, it was a significant determinant (as we discuss in more detail below) in
their decisions to donate the money they received for completing the survey. 13

13

A simple regression indicates a significant negative relationship with a F =10.89 (p-value = 0.001) for the joint
null hypothesis of no association.

8

Using the IV estimator based on the predicted donation choice from a model with the size
of the monetary incentive offered, we find the test results for the effects of cash incentives versus
donation do not change. Cash and choice are not significantly different in their incentive effects.
Moreover, these conclusions are also not affected if fixed effects for the neighborhoods are
included in the models. One contrasting finding with these estimates arises with the difference
between coefficients associated with choice and donation. These coefficients would not be
judged as significantly different. However, the magnitudes of the estimated parameters are
comparable to what we found in OLS models omitting the endogenous decision to donate effect.
Thus, this change seems likely to be due to the larger standard errors for the IV estimates.
Our last comparison of the effects of different types of incentives is given in Table 3.
Here we report the results for the two step non-parametric test of the effects of the types of
incentives. The analysis is now more comparable to Mercer et al. in that we are comparing the
estimated average response rates for cells defined by the neighborhood and treatment received.
With our small sample and disproportionate assignments, this strategy is a more demanding
approach for testing these hypotheses. As the sample size at the bottom of Table 3 suggests, we
are not able to estimate response rates for all of the possible combinations of neighborhood and
treatment alternatives. The sample includes 271 versus 405 (9 x 45) of the possible alternatives.
All of the estimates use the estimated standard errors from the OLS first stage estimates of the
coefficients for the dummy variables for each neighborhood/treatment alternative to construct
feasible generalized least squares (FGLS) estimates for assessing the incentive effects. Model 1
considers the monetary incentive alone. Model 2 includes the dummy variables for the format in
which the incentive was offered. The findings are consistent with the analysis at the individual
level. We report the estimated difference between the response rates and the p-value for tests of

9

equality. Cash incentives and a choice of cash or donation lead to significantly greater
participation than offering to donate, regardless of whether the model takes account of the
monetary incentives.
Table 4 reports the influence of the size of the monetary incentive on the decision to
donate. The sample is restricted to the individuals who agreed to participate and received the
choice treatment. Several aspects of these results are notable. First, the likelihood of donating
declines as the size of the monetary incentive increases. Model 1 is based on the choices of these
respondents receiving the choice treatment.14 Model 2 restricts the sample to those who received
the choice treatment and completed the survey online. It reflects the choice of individuals who
experienced the most limited social pressure to donate. The results are comparable.
It is possible to use these models to estimate the average respondents’ economic value for
the public good services provided by the food bank. This last element stems from the ability to
adapt the participation incentive so it provides a natural field experiment. To develop this
estimate, consider a simple model for each survey participant’s decision to donate to the food
bank. Equation (1) specifies a linear, indirect utility function for the utility realized if a
respondent donates his financial incentive to the food bank

and (2) if he does not

(1)
(2)
This formulation is similar to the logic Hanemann [1984] originally outlined to derive the
welfare properties of discrete choice models. We assume the marginal utility of income
14

,

We also considered a sub-sample of the respondents receiving this treatment who agreed to provide their
household income. The choice to donate model was:
Donate = +.398 - .012 Dollar Incentive + .0018 income
(2.99) (-2.26)
(2.28)
Income = household income in thousands of dollars, Number of observations = 99, R 2 = .11
As other literature has suggested, the likelihood of donating the monetary incentive to charity increases with the
income level of the respondent.

10

designated by

, remains constant across the two decisions.

represents the monetary

incentive. Since the model describes the choice for an individual who has agreed to participate, it
recognizes that taking the survey implies the time commitment, represented here by . With this
treatment, a decision to donate the incentive implies the respondent’s “out of pocket” cost is the
time for the survey. By contrast, a decision to keep the incentive offsets the time cost of doing
the survey. The

and

terms capture the difference in well-being a person experiences with

the decision to donate versus not donate to the food bank.
It is not possible to unpack whether different respondents interpret the “amount” of
public good services provided by the food bank in relation to the warm glow they might
experience from giving to any cause. More specifically, if we re-formulate the two state-specific
preference functions to include the total amount given to charity by others, say , and allow for
the possibility of a warm glow effect, then it is possible to illustrate why testing this hypothesis is
unfeasible. When the individual contributes ,

would then be given as equation (3):

(3)
and

would be equation (4):
(4)
where

Using these expressions for

and
and

and assumptions about the form of

we see more information on respondents’ beliefs about
would be needed to test warm glow.

In principle, such analyses could be undertaken in future research. This pairing of field
experiments and response incentive offers a strategy for addressing some of the limitations that
List [2011] identified as being associated with the existing research on the demand for charitable
services. For example, a revised incentive structure could distinguish these effects using the

11

results from Eckel et al.’s [2005] laboratory experiments with undergraduates. More specifically,
these authors found that explaining exogenous contributions to a charity as the result of a tax on
subjects’ endowment resulted in a crowding out of their subsequent contributions and thus
reduced or eliminated warm glow effects. Using this logic it would be possible to explain to a
subset of the potential survey respondents that a portion of the incentive they would have earned
was already earmarked as a “tax” for the food bank and ask if they wished to contribute the
balance of their proposed financial incentive. Finally, to derive our measure for the economic
value of donating, assume

and

represent unobserved heterogeneity associated with the

two states. A person donates if

, and we can use the estimated parameters for our

choice model to recover a measure for the maximum donation,

, participants in the survey

would make on this “giving occasion”. Equation (5) solves for

consistent with

given
.
(5)
The time commitment is the same regardless of whether the individual donates or not and thus
drops from the relationship.
Our estimates for the maximum contribution can be interpreted using Kotchen’s [2015]
analysis.15 He demonstrates that the maximum take it or leave it donation can exceed the amount
a person would contribute if he had discretion in selecting the amount. Our experiment recovers
a partial measure for the concept he envisioned as the take it or leave it value of donating. In our
case, the value is for contributions to the food bank on a given occasion. These estimates are
computed for two samples, one with all respondents receiving the choice treatment and for the
15

While Kotchen’s analysis focuses on the donation vehicle as part of a contingent valuation survey, his model is
directly relevant to the choice implied by our field experiment.

12

subset who answered using the online survey model and might be expected to experience the
lowest amount of social pressure. Both estimates are significantly different from zero. They are
$38 and $39 respectively. As we discuss in the next section, there are other elements to include
in the full monetary measure of the take it or leave it donation value. These additional
components would include the opportunity cost of the time to take the survey. Our design
precluded recovering a measure for this added value because the sample used to estimate

had

to agree to take the survey in order for our analysis to observe their donation decisions.
IV. Discussion
Perhaps the most interesting component of this analysis arises from embedding a natural
field experiment within our assessment of response incentives. By allowing respondents to
decide whether to keep or donate the financial incentive, it is possible to estimate a part of the
economic value of the public good services provided by First Food Bank Alliance. A take it or
leave it opportunity to contribute a fixed amount implements a variant of the logic envisioned in
Kotchen’s [2015] analysis of the donation vehicle for contingent valuation surveys. In our case,
the choice is a “real one” that fits the structure of his model. Using the model to evaluate the
economic value of the food bank’s services would require an expansion in his framework that
addresses how people consider opportunities to donate within a setting that links what might be
described as planned overall giving in a well-defined time horizon with the choices made in each
specific opportunity to donate. To our knowledge this issue has not been addressed in the
literature on charitable giving. List [2011] discusses annual giving, he describes who makes
these donations, and how they are distributed among different charitable groups. The time
horizons discussed are annual and the potential distribution over a lifetime, not in terms of each
specific opportunity to give.
13

There are several ways of conceptualizing this task. We consider two possibilities.
Unfortunately both require more information than we collected in this initial experiment. It is
nonetheless worth sketching the logic of each because it would be possible to use the basic
framework treating survey incentives as a source for natural field experiments to investigate the
interrelationship between the mix, timing, and total amount given to charity over a household’s
budgeting cycle. The first possible interpretation of the timing of charitable contributions would
be to treat them as akin to repeated “use” or consumption, where the frequency of purchases is
endogenous. Liu, Rettenmaier and Saving [2011] consider a simple static model that
distinguishes a fixed cost of consumption from the unit price of the commodity or service
experiencing repeated consumption. In their analysis this fixed component or “setup cost” could
be a travel cost for a recreation trip and the price could be the unit cost of the activity such as ski
lift costs or lodging.16
The analogy to the setup cost with charitable contributions would be the time and costs
associated with investigating the reliability of a charitable organization. This assessment could
involve evaluating the share of contributions used for administration and management,
performance in meeting stated objectives, and so forth. Costs arise in obtaining reliable
information to address these issues. The Liu et al framework suggests that as the setup costs
increase, the frequency of giving to otherwise completely equivalent charities is likely to decline
and the intensity of giving to just one of them increases. The implications for total giving in the
time period used to characterize overall consumption expenditures (across all of the equivalent
charities in their analysis) would be an empirical issue. Food banks are widely recognized as
having among the lowest administrative costs and having reliable and predictable outcomes. This

16

These types of examples have a long history in economic modeling of recreation demand. See Phaneuf and Smith
[2005] for a review.

14

is certainly true of the First Food Bank Alliance. As a result, this logic does not provide
predictions for the frequency of giving or the total amount in a given budgeting period. As a
result their model provides a framework for specifying hypotheses for testing and a clear
motivation for further empirical research
Using a parallel to second literature associated with consumer responses to sales and
holding inventories of storable goods (see Hendel and Nevo [2004]) leads to a similar general
conclusion. This literature would require more assumptions about how people conceptualize the
time distribution of giving. Resources available for meals and warm clothing, for example, may
be more important in the winter than in the fall and spring. Needs in the summer would likely be
different and depend on the location of the food bank. To use this literature to gauge intertemporal substitution of giving would require more assumptions about how people envision what
different distributions for a given amount of contributions to charity over time will accomplish.
We might be able to learn about inter-temporal substitution by using events that motivate
individuals to alter a planned pattern of giving such as natural disasters. These events may well
trigger the substitution of an immediate opportunity for other longer term or more permanent
needs. Field experiments require advance planning, navigating internal review board
requirements and often significant resources. As a result, it is difficult to take advantage of
strategic opportunities caused by natural events. By using field experiments as part of survey
incentives it should be possible to design a research question associated with disasters to both
consider an important question—inter-temporal displacements of donations and “do good” by
helping those in need as a result of the disaster providing the immediate need for help.
As we noted with our specific application, additional information would be needed to
pursue the hypotheses implied by either of these models. It is also not impossible to implement

15

fully a variant of Kotchen’s model. We do not know what the respondents were already giving to
the food bank. Moreover, the range of incentives offered to them limit what we can say about
donations when people were provided a wider range of incentive values. Nonetheless, our results
do demonstrate that this strategy offers a viable basis for estimating people’s willingness to pay
for increases in the amounts of these types of public goods. We can go a bit further in
considering the maximum contribution on a gift occasion by including an estimate of the
opportunity cost of time and use the two sets of results to gauge the implied value of the food
bank’s services. Smith and Mansfield’s [1998] estimates of the value of time, based on the
compensation offered to North Carolina households in 1995-96 for their time spent in a
telephone interview, provide the closest parallel to the current situation. Based on these results,
we estimate that the average respondent gave up 30 minutes that would be worth between $12
and $24 (in 2011 dollars).17 This decision was made regardless of whether they kept or donated
the money. By keeping the incentive, they would cover the opportunity costs of time on average.
One might argue that those who donated the incentive would also have been willing to contribute
an additional $12 to $24 if they did not have to take the survey.18
A further question one might ask when evaluating the economic value of charity to a food
bank concerns the public services that respondents believe they are receiving when they donate.
While the analytical models for charitable contributions assume perfect substitution between
individual gifts in defining the amount of the public good and generally represent them as the

17

The Smith-Mansfield estimates were based on an offer to complete a second telephone survey. Depending on the
specific statistical model selected from this study, the estimate for the per hour opportunity cost of time ranged from
$19.65 to $32.74 in 1995 dollars. Using the consumer price index to convert from 1995 to 2011 dollars implies these
should be scaled by 1.476. The PASS survey took ½ hour, adjusting for the time and rounding the resulting
estimates yields these results.
18
Of course, this logic accepts the fungibility of time and money implicit by the use of the Smith-Mansfield
estimates to value these respondents’ time. Other research has suggested that the opportunity cost of time in
different uses will be different and the people would not necessarily make this type of exchange in all contexts. See
Palmquist, Phaneuf, and Smith [2010] for related discussion.

16

sum of the cash contributions (see Andreoni [1989], List [2011]), the charities tend to describe
the effects of contributions by translating into outcomes.19 The First Food Bank Alliance, for
example, routinely translates dollar contributions into meals (at a fixed ratio) such as “$30 to
provide 210 meals”. This logic is consistent with the strategy used for framing contingent
valuation surveys since the Exxon Valdez survey (Carson et al. [1992]). That is, these surveys
described the object of choice offered to survey respondents as a plan to avoid specific injuries,
rather than a specific improvement in the environment. Survey respondents in these cases make
choices about the plan. In principle, the natural field experiment could be designed to include
details of how survey incentives would be used to “produce” different types of public or impure
public goods.
V. Summary and Implications
To our knowledge this study is the first effort to compare public goods with private goods
(cash) as response incentives for a household survey. We found that our public good—a
contribution to a food bank—was not as effective as either a cash incentive or a format that
allows each respondent to decide to keep or donate the cash20. Our findings on the effects of the
amount of the incentive contrast with the existing literature, that found “. . . a strong, nonlinear
effect of incentives across all three models of data collection included in the analysis.” (Mercer
et al. [2005], p. 124). While the results reported here focused on models specified to be linear in
the incentive, we also considered non-parametric, nonlinear (log transformed), and interaction
variables for the amount of the incentive with the form of the incentive (i.e. cash, donation or
choice). None of these alternatives changed our overall conclusions.
19

We are grateful to Kelly Bishop for suggesting consideration of this strategy.
St. Mary’s Food Bank Alliance was established in 1967 and is recognized as the first food bank in the world and
one of the largest in the U.S. See www.firstfoodbank.org/learn-more/our-history.
20

17

Our approach does contrast with past assessments of response rates that tend to involve
comparisons across surveys which used a single mode for their responses. Our respondents could
choose the mode for their response – from online, telephone, or in person interviews. Incentives,
whether cash or donation, were paid after the survey was completed.21 While past research on
survey incentives found that prepaid incentives were more effective than promises with delayed
payment, Mercer et al. note the effects are not uniform for all models. Our research argues that
the use of incentives to enhance participation in surveys provides an opportunity for conducting
field experiments. It is possible to reduce the front-end negotiation for access to different groups
for experiments and broaden the types of subject pools studied. Of course, for this linkage to be
cost effective the front-end field experiments cannot compromise the objectives of the surveys
that offer the mechanisms for undertaking the experiments.

21

A total of $2,570 was contributed to the food bank as part of this research.

18

Table 1: Survey Outcomes by Experimental Design and Sample

Incentive Option That Respondent Was Originally Offered
Final Outcome
Asian Language
Bad Mail
Field Complete
No Mail Receptacle
Non-Contact
Non Resident
Online Complete
Partial Interview
Refusal
Telephone Complete
Terminate
Undeliverable
Vacant
Distribution for Possible
Sample During the
Experimental Period
Distribution for Full Sample
Distribution for Analysis of
the Experiment

Cash Cash Cash Donate Donate Donate Choice Choice Choice
10
20
30
10
20
30
10
20
30

Total

0
6
0
1
0
0
45
0
17
8
1
0
15

0
32
12
0
1
1
70
0
21
16
0
0
57

0
36
26
0
84
0
131
1
48
21
0
0
61

0
8
3
0
0
0
28
0
16
1
0
1
22

1
7
2
0
0
0
26
0
25
4
0
0
14

0
9
1
0
0
0
25
0
18
1
0
0
15

0
14
3
0
0
0
35
0
11
5
1
0
13

0
14
0
1
0
0
38
0
19
9
0
1
17

0
9
1
0
6
0
41
0
10
5
0
1
13

1
135
48
2
91
1
439
1
185
70
2
3
227

93
179

210
327

408
435

79
166

79
164

69
157

82
160

99
166

86
373

1,205
2,127

71

119

226

48

57

45

55

66

57

744

19

Table 2: OLS and IV Estimates for Experimental Treatments a
Model 1
0.00038
(0.19)
0.782
(14.84)
0.599
(11.22)
0.762
(14.64)


No

Model 2
0.00149
(0.74)
0.820
(5.60)
0.680
(4.53)
0.813
(5.52)


Yes

Model 3


0.791
(37.24)
0.607
(17.15)
0.797
(5.23)
-0.117
(-0.19)
No

Model 4


0.744
4.45
0.592
3.47
0.841
3.88
-0.471
(-0.70)
Yes

R2
No. of observations

0.756
744

0.788
744


744


744

Test: Cash = Donate
p-value

16.06
0.0001

9.73
0.002

19.93
0.000

11.16
0.001

Test: Choice = Donate
p-value

10.19
0.002

7.43
0.007

1.49
0.223

2.09
0.148

Test: Cash = Choice
p-value

0.27
0.603

0.03
0.862

0.00
0.966

0.37
0.545

Dollar Incentive
Money / Cash
Donation
Choice
Give to Charity
Fixed Effects

a

The numbers in parentheses below the estimated coefficients are the t-ratios for the null
hypothesis of no association. In the case of models 3 and 4, these are asymptotic Z-statistics
for the IV estimates.

20

Table 3: Second State FGLS Estimates for Treatment Affects a

0.8006
(19.39)

Model 2
-0.0003
(-0.15)
0.8209
(17.65)
0.7392
(15.44)
0.8408
(18.31)



Model 3


0.8144
(45.06)
0.7339
(22.50)
0.8354
(29.45)



0.925

0.927

0.927

271

271

271

Test: Cash = Donate
p-value

0.082
0.033

0.080
0.032

Test: Choice = Donate
p-value

0.102
0.020

0.101
0.020

-0.020
0.561

-0.021
0.533

Dollar Incentive

Model 1
0.0002
(0.11)

Money / Cash
Donation
Choice
Intercept
R2
No. of observations

Test: Cash = Choice
p-value
a

The numbers in parentheses are asymptotic Z statistics for the null
hypothesis of no association.

21

Table 4: OLS Estimates for Choice to Donate Incentive to Charity a
Model 1

Model 2

-0.01292

-0.01558

(-3.19)

(-3.02)

0.49588

0.61799

(5.24)

(5.06)

178

114

R2

0.058

0.077

WTP for Food Bank

38.37

39.67

(6.88)

(6.30)

Dollar Incentive

Intercept

No. of observations

a

The numbers in parentheses for parameter estimate are t statistics for the
hypothesis of no association. Those below the WTP estimate are asymptotic
Z statistics for hypothesis WTP = 0.

22

References
American Association for Public Opinion Research. 2011. Standard Definitions: Final
Dispositions of Case Codes and Outcome Rates for Surveys. 7th edition. AAPOR.
Andreoni, James. 1989. “Giving with Impure Altruism: Applications to Charity and Ricardian
Equivalence.” Journal of Political Economy, 97(6): 1447-1458.
Angrist, Joshua D. and Jorn-Steffen Pischke. 2009. Mostly Harmless Econometrics: An
Empiricist’s Companion, (Princeton, N.J.: Princeton University Press).
Carson, Richard T., R.C. Mitchell, W.M. Hanemann, R.J. Kopp, S. Presser, and P.A. Ruud.
1992. “A contingent valuation study of lost passive use values resulting from the Exxon
Valdez oil spill.” Report to the Attorney General of the State of Alaska.
Croson, Rachel and Jen Shang. 2009. “A Field Experiment in Charitable Contribution: The
Impact of Social Information on the Voluntary Provision of Public Goods.” Economic
Journal, 119(540): 1422-1439.
Clotfelter, Charles T. 1990. “The Impact of Tax Reform on Charitable Giving: A 1989
Perspective.” Do Taxes Matter? The Impact of the Tax Reform Act of 1986, ed. J.
Slemrod, (Cambridge, MA: MIT Press).
DellaVigna, Stefano, John List, and Ulrike Malmendier. 2012. “Testing for Altruism and Social
Pressure in Charitable Giving.” The Quarterly Journal of Economics, 127(1): 1-56.
Eckel, Catherine C., Philip J. Grossman, and Rachel M. Johnston. 2005."An experimental test of
the crowding out hypothesis." Journal of Public Economics, 89(8): 1543-1560.
Grimm, Nancy B. and Charles L. Redman. 2004. “Approaches to the Study of Urban
Ecosystems: The Case Study of Central Arizona – Phoenix.” Urban Ecosystems, 7:199213.

23

Hanemann, W. Michael. 1984. “Welfare Evaluations in Contingent Valuation Experiments with
Discrete Responses” American Journal of Agricultural Economics, 66(3): 332-341.
Harrison, Glenn W. and John A. List. 2004. “Field Experiments.” Journal of Economic
Literature, 42(4): 1009-1055.
Hendel, Igal and Aviv Nevo. 2004. “Inter-temporal Substitution and Storable Products.” Journal
of the European Economic Association, 2(2-3): 536-547.
Karlan, Dean and John List. 2007. “Does Price Matter in Charitable Giving? Evidence from a
Large-Scale Natural Field Experiment.” American Economic Review, 97(5): 1174-1193.
Kotchen, Matthew J., 2015. “Reconsidering Donations for Nonmarket Valuation.”
Environmental and Resource Economics, forthcoming.
Landry, Craig, Andreas Lange, John List, Michael Price, and Nicholas Rupp. 2006. “Toward an
Understanding of the Economics of Charity: Evidence from a Field Experiment.” The
Quarterly Journal of Economics, 121(2): 747-782.
List, John A. 2011. “The Market for Charitable Giving.” The Journal of Economic Perspectives,
25(2): 157-180.
List, John A., and David Lucking-Reiley. 2002. “The Effects of Seed Money and Refunds on
Charitable Giving: Experimental Evidence from a University Capital Campaign.” Journal
of Political Economy, 110(1): 215-233.
Liu, Liqun, Andrew J. Rettenmaier, and Thomas R. Saving. 2011. “How Much and How Often:
A Model of Repeated Consumption with Endogenous Consumption Frequency.”
Economics Letters, 110(3): 186-188.

24

Mercer, Andrew, Andrew Caporaso, David Cantor and Reanne Townsend. 2015. “How Much
Gets You How Much? Monetary Incentives and Response Rates in Household Surveys.”
Public Opinion Quarterly, 79(1):105-129.
Palmquist, Raymond B., Daniel J. Phaneuf, and V. Kerry Smith. 2010. “Short Run Constraints
and the Increasing Marginal Value of Time in Recreations.” Environmental and Resource
Economics, 46(1):19-41.
Phaneuf, Daniel J. and V. Kerry Smith. 2005. “Recreation Demand Models” in Karl-Göran
Mäler and Jeffrey R. Vincent, editors. Handbook of Environmental Economics, Vol. 2:
Valuing Environmental Changes, (Amsterdam: North Holland) pp. 672-761.
Smith, V. Kerry. 1997. “Pricing What is Priceless: A Status Report on Non-Market Valuation of
Environmental Resources.” The International Yearbook of Environmental and Resource
Economics 1997/1998, H. Folmer and T. Tietenberg, Eds., (Cheltenham, UK: Edward
Elgar), 156-204.
Smith, V. Kerry, and Carol Mansfield. 1998. “Buying time: Real and Hypothetical Offers.”
Journal of Environmental Economics and Management, 36(3): 209-224.
Wooldridge, Jeffrey M., 2010. Econometric Analysis of Cross Section and Panel Data, second
edition, (Cambridge, MA: The MIT Press).

25

