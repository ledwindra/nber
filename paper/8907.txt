NBER WORKING PAPER SERIES

PHYSICIAN INCOME PREDICTION ERRORS:
SOURCES AND IMPLICATIONS FOR BEHAVIOR

Sean Nicholson
Nicholas S. Souleles

Working Paper 8907
http://www.nber.org/papers/w8907

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2002
The University of Pennsylvania Research Foundation, Jefferson Medical College, and the Rodney L. White
Center for Financial Research generously provided funding for the follow-up surveys. We are very grateful
to Joseph S. Gonnella, Jon Veloski, Mary Robeson and other members of the Center for Research in Medical
Education and Health Care at Jefferson Medical College for providing access to and assistance with the
Jefferson Longitudinal Study. Patricia Danzon, Mark Pauly, Rob Lemke, Dan Polsky, and members of the
macro lunch and the applied economics workshop at The Wharton School provided helpful suggestions, as
did members of workshops at Stanford University, the University of Chicago, and the University of
California-Berkeley, and participants at the Michigan/HRS/BLS Conference on Survey Research on
Household Expectations and Preferences. Our research assistants provided valuable contributions: Josh Beer,
Matt Cinque, Hanli Mangun, and Peter Margetis. The views expressed herein are those of the authors and
not necessarily those of the National Bureau of Economic Research.

© 2002 by Sean Nicholson and Nicholas S. Souleles. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.

Physician Income Prediction Errors: Sources and Implications for Behavior
Sean Nicholson and Nicholas S. Souleles
NBER Working Paper No. 8907
April 2002
JEL No. J24, J3, J44, I11, D84

ABSTRACT
Although income expectations play a central role in many economic decisions, little is known
about the sources of income prediction errors and how agents respond to income shocks. This paper uses
a unique panel data set to examine the accuracy of physicians’ income expectations, the sources of
income prediction errors, and the effect of income prediction errors on physician behavior. The data set
contains direct survey measures of income expectations for medical students who graduated between
1970 and 1998, their corresponding income realizations, and a rich summary of the shocks hitting their
medical practices. We find that income prediction errors were positive on average over the sample period,
but varied significantly over time and cross-sectionally. We trace these results to persistent specialtyspecific shocks, such as the growth of health maintenance organizations (HMOs) and other changes
across health care markets. Physicians who experienced negative income shocks were more likely to
respond by increasing their hours worked, allocating fewer of their work hours to teaching/research and
more to patient care, and were more likely to switch specialties.

Sean Nicholson
Health Care Systems Department
The Wharton School
3641 Locust Walk
Philadelphia, PA 19104
nicholss@wharton.upenn.edu
Tel: 215-898-9403
Fax: 215-573-2157

Nicholas S. Souleles
Finance Department
The Wharton School
3641 Locust Walk
Philadelphia, PA 19104
and NBER

1
I. Introduction
Income expectations are an important determinant of many economic decisions, including
schooling and occupational choice. However, little is known about the accuracy of income expectations,
the sources of income prediction errors, and how people respond to income shocks (Manski, 1993). Since
income expectations are rarely directly observed, the most common approach in empirical applications is
to assume that expectations are rational and infer income expectations from panel data on realized
income. (See Dominitz and Manski (1997) for a review of this literature, and Willis and Rosen (1979) for
an example of this approach.) However, Manski (1993) has shown that misspecifying how income
expectations are formed can lead to incorrect inferences about peoples’ behavior given their expectations,
for instance the responsiveness of school enrollment to the expected return to schooling.
There are only a few existing studies that assess the accuracy of income expectations, usually by
comparing survey measures of income expectations with subsequent income realizations. Das and van
Soest (1999) examine data from the Dutch Socio-Economic Panel, which asked people to predict whether
in the next year their household income would decrease, remain unchanged, or increase. They find that
between 1984 and 1989 their sample substantially underestimated their income growth; income
expectations were too pessimistic on average. Using a U.S. sample, Dominitz (1998) compares one-yearahead income predictions in 1993, elicited in the form of subjective probabilities, with peoples’ actual
1

income in 1994. He finds income expectations were too optimistic, by contrast.

There are a number of limitations to the existing literature. First, one should not necessarily

1

Most other studies of the accuracy of household expectations have used aggregated data on inflation
expectations (e.g., Maddala, Fishe, and Lahiri, 1981; Gramlich, 1983; Batchelor, 1986). However, when agents’
information sets differ, aggregation can lead to spurious rejections of rationality. Some papers have indirectly
modeled occupational choice without observing peoples’ subjective income expectations. Zarkin (1985) examines
whether prospective teachers incorporate forecastable demand conditions into their decision to enter the occupation.
He finds that future student enrollment rationally affects the occupational decisions of secondary school teachers, but
not of elementary school teachers. Siow (1984) assumes that prospective lawyers expect future cohorts of students
to arbitrage away any rents that would otherwise occur from a wage shock. He finds evidence consistent with his
model.

2
expect prediction errors to average out to zero over a relatively short sample period (Souleles, 2001;
Keane and Runkle, 1998). As a result, expectations that are rational ex ante might not appear rational ex
post. For instance, the respondents in the two studies above might by chance have received positive and
negative income shocks, respectively, over their short sample periods. Analyses of the accuracy of
income expectations therefore require long sample periods. Souleles (2001) examines 18 years of
monthly data from the Michigan Survey of Consumer Attitudes and Behavior. This survey records
household expectations and subsequent realizations for a number of variables, including household
income and financial security, inflation, and aggregate economic activity. Souleles finds that even over a
long sample period, expectations of most of these variables appear to be biased and inefficient, at least ex
post. He traces these results in part to aggregate shocks, like the business cycle and changes in monetary
policy regime, as well as group-level shocks (e.g., shocks that disproportionately hit low education
workers).
A second limitation of the literature is that the answers to the expectations questions are usually
constrained to be discrete (e.g., Will income increase, decrease, or stay the same?), which complicates the
analysis. Third, the expectations are usually limited to a one-year horizon, whereas life-cycle decisions
like occupational choice depend on longer-horizon expectations. A final limitation is that most studies
that reject the rationality of expectations do not explain why they reject, or whether the shocks that caused
the prediction errors significantly altered people’s subsequent behavior.
In this paper we examine the accuracy of physicians’ income expectations, the sources of income
prediction errors, and the effect of income prediction errors on physician behavior. We test, for example,
whether the income prediction errors of specialists are significantly related to the advent of managed care,
and whether physicians change their hours worked if their income turns out to be different than expected.
We use a unique panel data set that allows us to overcome many of the limitations of previous studies of
income expectations. The Jefferson Longitudinal Database contains information on all medical students

3
who graduated from Jefferson Medical College, a large medical school in Philadelphia, since 1970. The
data set contains direct survey measures of medical students’ subjective income expectations, the
students’ actual practice income at various points during their medical career, and a rich set of
demographic and ability measures. In the fourth year of medical school, Jefferson students have been
asked to predict the following: the specialty in which they will practice, their income 5, 10, and 20 years
after completing residency training (i.e., their income with 5, 10, and 20 years of post-residency
experience), peak career income, and characteristics of their medical practice. In 1998 we devised a
follow-up survey asking the same Jefferson physicians to report their current income, their income
realizations in the same years for which they had previously stated their expected income, and the actual
characteristics of their practice. The physicians were also asked to identify market and practice changes
that occurred throughout their career, and to distinguish changes that were anticipated and unanticipated
as of the time they formed their expectations. These unique questions allow us to reconstruct the
physicians’ information sets and identify shocks that might explain their prediction errors.
The Jefferson Survey is particularly well suited to analyze income expectations because it solicits
open-ended (continuous) income expectations over a person’s lifecycle. By 1998, the Jefferson graduates
had been practicing medicine for up to 25 years, a period that might be long enough to allow negative and
positive shocks to average out to zero if expectations are unbiased. Moreover, the sample period includes
almost 30 cohorts of physicians. By contrast, if we tracked only a few cohorts of medical students, say
those who graduated before 1975, then a large permanent shock to the physician services market in the
late 1970s might lead one to reject the rationality of expectations based on incomes realized in the 1980s
and 1990s. Medical students who graduate in the 1980s and 1990s, however, should have incorporated
this shock into their own income expectations.
In a previous paper, Nicholson and Souleles (2001), we analyzed the original Jefferson income
expectations data to try to identify the information that students use when forming income expectations,

4
and to examine whether subjective income expectations can help explain students’ specialty choices. We
found that medical students condition their expectations in part on the contemporaneous income of
physicians practicing in the specialty they plan to enter, but not on a one-for-one basis. This suggests that
expectations are not strictly myopic.2 In fact, we found evidence that expectations are partly forwardlooking: after students entering a given specialty reported relatively high income expectations, physicians
in that specialty subsequently tended to experience higher income growth relative to other specialties, as
measured by aggregated physician income data from the American Medical Association (AMA). We also
found that the subjective income expectations were more useful in predicting specialty choice than
contemporaneous physician income. These results suggest that the subjective expectations variables are
quite informative. However, without the actual physician-specific realizations of income and other data
solicited in the 1998 follow-up survey, we were not able to assess formally the accuracy of the
expectations, explore the sources of prediction errors, nor examine the welfare implications of prediction
errors.
This paper examines a number of aspects of physician income expectations and realizations.
First, we compare a physician’s actual income to the income he expected when he was a fourth-year
medical student to gauge the accuracy of income expectations, including their unbiasedness and
efficiency. Second, and more importantly, we analyze the sources of any systematic prediction errors. In
particular, can the results be explained by ex post shocks to realized income? The richness of the data
allows us to analyze many salient possible shocks. For example, are income prediction errors more
negative for female physicians? Do medical students under or over estimate the returns to ability? More
generally, we examine how prediction errors vary cross-sectionally and over time. This allows us to
characterize the shocks that have hit physicians in different specialties at different points between 1970
and 1998. For instance, to what extent did changes in the structure of health insurance in a physician’s
2

If income is serially correlated across cohorts, rational expectations of income should be partly correlated

5
market, such as the emergence of health maintenance organizations (HMOs), lead to income prediction
errors? Third, we examine whether shocks that cause income prediction errors significantly altered
physicians’ subsequent behavior. How much flexibility do physicians have to respond to shocks, and
along what margins do they respond? For instance, do they adjust their hours worked? In light of the
central role of income risk in many economic decisions, such an analysis of income shocks should be of
independent and general interest.
We find that medical students made systematic income prediction errors, even over the long, 28year sample period. We trace the errors in large part to persistent specialty-specific shocks.
Unanticipated market and practice changes, such as changes in demand for physician services and in
payments from health insurers, help explain much of the cross-sectional variation in prediction errors
across physicians. For example, specialist physicians (e.g., surgeons and obstetricians) practicing in
markets with relatively high HMO enrollment earned substantially less than they expected relative to
physicians in these same specialties practicing in markets with average levels of HMO enrollment. More
generally, the results call into question the common assumption that aggregate shocks affect people
uniformly. Empirical implementations of rational expectations (or forward-looking) models therefore
need to account for richer systematic heterogeneity in prediction errors. We also find that income
prediction errors help explain subsequent physician behavior. Physicians who experienced negative
income shocks were more likely to respond by increasing their hours worked, allocating fewer of their
work hours to teaching/research and more to patient care, and were more likely to switch specialties.
These results imply that market and practice shocks have substantial welfare effects.
The rest of this paper is organized as follows. We describe the data in more detail in Section II.
In Section III we present the empirical method for assessing the accuracy of income expectations,
identifying the sources of income prediction errors, and examining the effect of prediction errors on

with contemporaneous income.

6
changes that physicians make to their medical practice. We present results in Section IV and offer
concluding comments in Section V.

II. Data
The Jefferson Longitudinal Database contains unique information about physicians’ expectations
regarding their medical practice. In 1970 Jefferson Medical College began surveying its medical students
in their fourth year of medical school. Students are asked to predict the specialty in which they will
practice and their income from medical practice. Between 1970 and 1979, students were asked to state
the income, after medical expenses and before taxes, they expected to receive 5, 10, and 20 years after
completing residency training, and the peak income they expected to receive during their career.3
Students were asked, “…(to) assume that dollars maintain their present value …” when stating their
expected income. Students who graduated after 1979 have been asked to predict only their peak income,
not income after 5, 10, and 20 years of experience. The Jefferson Longitudinal Study contains
information on all 5,995 alumni who graduated between 1970 and 1998, most of whom are now
practicing physicians. In the first column of Table 1 we report means of key variables for the entire
sample.
The Jefferson database includes demographic information and rich measures of student ability
and performance in school. Medical students must pass three national exams before they can receive a
license to practice medicine in the United States. Part 1 of the National Board of Medical Examiners
(NBME) test is administered after the second year of medical school and covers the classroom material
taught during the first two years (e.g., anatomy, physiology, pharmacology).4 Jefferson students who

3

Most medical students complete between three and five years of residency training, depending on the
specialty, before practicing medicine. We consider a physician to begin “practicing medicine” when he completes
residency training.
4
The second part of the NBME exam is administered in the fourth year of medical school and the third part
is administered in the first year of a student’s residency program. We focus on the Part 1 score as a measure of
student ability and performance because this exam occurred before students stated their income expectations.

7
graduated between 1996 and 1998 received an average score of 209.1 on Part 1 of the NBME, referred to
hereafter as the board score. The average board score for all students who graduated from a U.S. medical
school during this same time period was 210.8, so Jefferson students appear to be generally representative
of U.S. medical students.5
In 1998 we mailed surveys to all the individuals who graduated from Jefferson Medical College
between 1970 and 1979, the period during which students predicted their income with 5, 10, and 20 years
of post-residency experience, as well as their peak career income. In 1998 these alumni had been
practicing medicine between 13 and 25 years. They were asked to report current characteristics of their
practice such as their specialty, the average number of hours they work per week, and their patients’
sources of health insurance. The Jefferson alumni also reported their medical practice income (after
expenses but before taxes) for the previous year (1997), as well as their practice income 5, 10, and 20
years after they completed residency training, without making any adjustments for inflation.6 These
income realizations correspond in time to the income expectations the physicians provided when they
were fourth-year medical students. An impressive 93 percent of the physicians who completed the 1998
follow-up survey reported their practice income for each year requested.
The follow-up survey allows us to calculate income prediction errors -- the difference between
actual and expected income -- for each respondent in their 5th, 10th, and, for older physicians, their 20th
year of practicing medicine. Since the income prediction errors, like other variables solicited from
surveys, will inevitably be measured with some error, we also asked physicians the following question:
“Overall, how did your actual practice income in your 10th year [or 20th year for older physicians]
compare with the income that you expected when you were a fourth-year medical student (after taking

5

The standard deviation of the board score among students who graduated from U.S. medical schools
between 1996 and 1998 is 18.
6
The question for 1997 income was worded as follows: “Please estimate your income from medical
practice in 1997 to the nearest $10,000, after professional expenses but before taxes. Please include all income from
fees, salaries, risk pools, retainers, bonuses and other forms of compensation.”

8
inflation into consideration)?” The physician could report that his actual income was higher, lower, or
about the same as previously expected. This “subjective assessment” variable allows us to instrument for
a respondent’s income prediction error when it is used as an independent variable in analyzing the impact
of the errors on subsequent behavior. We undertake additional checks for measurement error below.
The 1998 follow-up survey tried to identify the reasons why a physician’s realized income might
be higher or lower than had been expected. Physicians who have been practicing medicine for 20 years or
more were asked to identify changes in the health care market (e.g., a decrease in the payments received
from health insurance companies, or an increase in demand for their services) and changes they made to
their practice (e.g., an increase in hours worked) that occurred during their first 20 years of practicing and
had a significant effect on their income in the 20th year. Physicians who had been practicing for fewer
than 20 years were asked a similar question regarding their experience during the first 10 years of
practicing medicine. The physicians were then asked to indicate which of these market and practice
changes had been expected when they were fourth-year medical students. This information allows us to
reconstruct a student’s information set at the time he stated his expected income. Household data sets
rarely contain such rich data regarding information sets.
In the 1998 follow-up survey we also asked physicians to identify any substantial changes they
made to their practice (e.g., changes in hours worked, or in the number of uninsured patients treated)
since their 20th or 10th year of practicing medicine, depending on whether the respondent had been
practicing for more than or fewer than 20 years. This information allows us to examine whether and how
physicians altered their behavior in response to shocks they faced over their careers, as measured by the
income prediction errors. We also asked the Jefferson alumni to forecast their retirement age and
whether, with hindsight, they would have selected the same specialty in medical school, selected a
different specialty, or would have left the medical profession altogether.
In 1999 we mailed a similar follow-up survey to all students who graduated from Jefferson

9
Medical College between 1980 and 1998. After 1979 Jefferson asked its students to predict only their
peak income. Therefore, the 1999 follow-up survey splits physicians into two groups according to their
response to the following question: “Do you think that your income from medical practice has already
peaked, or has not yet peaked.” Physicians who believed their income had already reached its maximum
value, after taking inflation into consideration, were asked to report the year in which their real income
from medical practice peaked as well as the actual peak amount. For these physicians we can calculate an
income prediction error by comparing the actual peak income to the peak income expected as of the
fourth year of medical school, with both variables adjusted for inflation.
Respondents who believed in 1999 that their income had yet to reach its peak were asked to
report their current expectations for peak income. This allows us to calculate the difference between a
respondent’s current expectation for peak income and his expectation for peak income when he was a
fourth-year medical student. Like the prediction errors, this difference reflects the arrival of new
information. All respondents of the 1999 follow-up survey were also asked to report their income from
medical practice for the most recently completed year (1998), as well as their practice income for 1992.
We structured the rest of the follow-up survey for the 1980-1998 graduates in the same way as
the survey for the 1970-1979 graduates. Members of the former group were asked to document changes
in the health care market and their practice between the year they graduated from medical school and
either the year in which their income peaked, or 1999 if they believed their income had yet to reach its
peak. They were asked to identify changes they made to their practice since their income peaked, or
changes they expect to make in the future if they believe their income has not yet peaked. The students
also provided subjective assessments of whether their actual peak income was higher, lower, or about the
same as expected (or whether their current expectation for peak income was higher, lower, or about the
same as their original expectation for peak income).
Forty-four percent of the Jefferson Medical College alumni (2,631 individuals) completed the

10
follow-up surveys. This is an unusually good response rate for a mail survey, especially in light of the
sensitive nature of the income and other survey questions. Even so, since we know a great deal about the
non-respondents from the survey and other information collected during medical school, we can check for
evidence of selection bias in completing the follow-up survey. Means for the main variables collected
during medical school are reported in column 2 of Table 1 for those individuals who completed the
follow-up survey. In general, the characteristics of the respondents to the follow-up survey are quite
similar to the entire population of students who graduated between 1970 and 1998 (column 1). Relative
to the non-respondents, the respondents are slightly younger, are more likely to be male and white, have
slightly higher board scores (ability), and were slightly more likely to become a family practitioner and
less likely to become a radiologist.7 However, these differences are all small in magnitude, and the
analysis below will control for these characteristics as well as the physicians’ own characterization of the
shocks to their practices. Hence, any remaining unobserved heterogeneity is unlikely to systematically
explain our results, especially the cross-sectional results that we highlight. Further, there is no
statistically significant difference in expected income between respondents and non-respondents, which
suggests that respondents do not substantially differ in unobserved ability either. Overall, there is little
evidence of systematic selection in the follow-up sample.
Table 2 reports means and standard deviations for the sample of 2,350 individuals who returned
the follow-up survey and had completed their residency training at the time of the survey. This and
subsequent tables exclude from the analysis the 281 respondents who were still residents and so not yet
practicing. As reported in the middle of Table 2, about one-third (0.366) of the practicing respondents
believe their actual income with 10 years of experience, 20 years of experience, or their peak income was
higher than they expected when they were a fourth-year medical student, and a similar percentage believe
it was lower than expected. Hence, there is substantial variation in the physicians’ subjective assessments
7

Of the variables listed in Table 1, only the means for these six variables are significantly different for

11
of the signs of their income prediction errors. About 20 percent of the respondents would have chosen a
different specialty in medical school or left the medical profession entirely given what they have learned
since graduation.
Turning to the bottom of Table 2, a fairly large proportion of physicians have experienced
changes in their market or have made changes to their practice that had a significant effect on their
income (or their expected peak income). Few of these physicians anticipated these changes when they
were in medical school. The second column at the bottom of the table reports the proportion of those
experiencing a change that expected the change when they were in medical school. For example, 51
percent of the physicians report that demand for their services increased between the time they graduated
from medical school and their 10th or 20th year of practicing, or the year in which their income peaked.
However, only 35 percent of the physicians who experienced a demand increase anticipated this change
when they were a fourth-year medical student. For most physicians, therefore, the increase in demand
can be characterized as a shock – an unforeseen event that could affect income but not expected income.
Similarly, most of the 57 percent of physicians whose payments from insurance companies decreased
were surprised by this change. On the other hand, less than 10 percent of physicians report they
significantly decreased their hours worked, but about one-third of them expected to do so.
In the last two decades managed care health plans, such as health maintenance organizations
(HMOs) and preferred provider organizations (PPOs), have replaced fee-for-service plans as the dominant
form of health insurance in the United States. We want to measure the extent to which this
transformation of the health insurance market represented a shock to physicians’ incomes. In 1976, less
than three percent of the U.S. population was enrolled in an HMO.8 Relative to a traditional fee-forservice health plan, HMOs generally cover more health services (e.g., pharmaceuticals and preventive
care), require patients to pay relatively less when they receive medical care, and charge a lower premium.
respondents and non-respondents at the five-percent level.

12
HMOs are able to offer a more comprehensive product for a lower price by restricting enrollees’ choice
of physicians and hospitals, negotiating lower fees with physicians and hospitals included in the network,
and more aggressively managing the care that patients receive, for example by requiring patients to
receive permission from their primary care physician before seeing a specialist. HMO enrollment has
grown rapidly over the past two decades as individuals and businesses have sought to limit the growth
rate of health spending. By 1999, about 30 percent of the population was enrolled in an HMO, and even
more were enrolled in less restrictive managed care health plans such as PPOs.
Studies have shown that HMOs reduce their enrollees’ use of hospital services and negotiate
lower payments to hospitals for these services (Miller and Luft, 1994; Cutler, McClellan, and Newhouse,
2000). The evidence is mixed regarding whether HMOs increase or decrease their enrollees’ use of
physician office visits (Miller and Luft, 1994). Despite the widespread impression that HMOs have
reduced physicians’ incomes, there has been little empirical evidence confirming this effect.9 Many of the
students in our sample graduated when HMOs were uncommon. Suppose the Jefferson students did not
expect HMOs, and managed care plans generally, to be as prevalent as they are. Then the physicians who
located in areas that subsequently experienced considerable growth of HMO enrollment might earn much
less than expected, ceteris paribus, especially in non-primary care specialties.
We use data from Interstudy, a research organization that studies managed care health plans, to
determine the percentage of the population in each physician’s state that was enrolled in an HMO in each
year. We know the state in which a respondent lived in 1998 or 1999, but do not know their residence in
prior years. We assume, therefore, that a physician has practiced medicine in their current state

8

Based on data from Interstudy.
Simon et al. (1996) find that between 1985 and 1993 primary care physicians practicing in states with
relatively high managed care enrollment experienced relatively large income increases, whereas the opposite was
true for hospital-based physicians (radiologists, anesthesiologists, and pathologists). This result is consistent with
the widely held view that primary care physicians will fare better than non-primary care physicians in a market
dominated by managed care health plans.
9

13
continuously since completing residency training.10

III. Empirical Method
We begin by formally testing whether medical students’ income expectations are unbiased and
efficient. Income expectations are unbiased if the mean prediction error is zero. We compute the income
prediction error of physician i in the jth year after completing residency training as the difference between
realized income (Yi,j) and expected income (EYi,j,t=0). We test for unbiasedness by regressing this error on
a constant:

(1) Yi, j − EYi, j, t =0 = α0 + u1.
We convert expected and realized income to 1996 dollars using the urban consumer price index (CPI),
and we correct the standard errors to allow for correlation in the error terms between physicians who
received income in the same year, which allows for common shocks. The income expectations were
reported when the respondent was a fourth-year medical student (t=0), and actual income was reported
retrospectively in the 1998 or 1999 follow-up survey. The mean prediction error (α0) could be non-zero
because of systematic shocks in the physician services market. In this case unbiasedness might be
rejected ex post even if students make ex ante optimal forecasts given the information that was available
to them. However, because our sample period is quite long, extending almost 30 years during which
there should have been both positive and negative income shocks, the shocks should be more likely to
average out than in previous studies of income expectations. In any case, our data will allow us to
characterize the sources of systematic income prediction errors.
Income expectations are efficient if people use all of the information available to them to forecast
their income. Time series analyses of efficiency often test for serial correlation in prediction errors.

10

Since some physicians move during their careers, our HMO enrollment variable will be measured with
some error, which will tend to attenuate our estimates of its effects. Polsky et al. (2000) find that between 1.5 and
2.0 percent of physicians relocated their practice to another metropolitan area per year between 1988 and 1992.

14
However, our micro data set contains few income prediction errors per physician (two or three errors for
physicians who graduated before 1980, and only one error for the physicians who graduated after 1980).
Therefore to test efficiency this paper instead focuses on cross-sectional variation, and looks for
systematic demographic components in the prediction errors. Specifically, we add to the specification
variables Xi in physician i's information set at the time of forecast (t=0), including personal
characteristics:

(2) Yi, j - EYi, j, t =0 = β0 + β1 Xi + u 2 .
If any of the β1 coefficients are non-zero, the efficiency hypothesis is rejected.
We further examine the sources of income prediction errors by adding variables Zi,j that might
have affected physician i’s income in year j, but were not necessarily in his information set in year zero:

(3) Yi, j - EYi, j,t =0 = γ1 T + γ 2 Xi + γ 3 Zi, j + u 3 .

We include a full set of year dummies (T) to identify the timing of aggregate shocks to the market for
physician services. Indicator variables for a physician’s specialty are included in Z to see whether
unexpected shocks had a different effect across specialties. Z also contains the percentage of the
population in physician i’s state that is enrolled in an HMO in year j. This measure of HMO penetration
is sometimes interacted with the set of specialty indicators because HMOs might exert a different effect
on different specialties. A common assumption is that by requiring patients to begin their treatment with
a primary care physician (i.e., family practitioner, pediatrician, or a general internist) who then decides
whether a specialist referral is necessary, HMOs would favor primary care relative to non-primary care

15
physicians.
We also include in Z the self-reported changes in a physician’s market, such as a decrease in the
payments received from health insurance companies, and changes physicians made to their practices, such
as decreasing the fraction of uninsured patients treated. If medical students anticipated these market and
practice changes when they formed their income expectations, they should not be highly correlated with
the income prediction errors. For each type of market or practice change, therefore, we include an
indicator if the physician reported that the change occurred and was anticipated when the respondent was
a fourth-year medical student, and a separate indicator if the change occurred but was not anticipated.
Unexpected changes should be correlated more strongly with the income prediction errors than are
expected changes.
The prediction errors are the difference between realized and expected income. It is sometimes
informative to examine separately the determinants of realized income and of expected income. Since
Nicholson and Souleles (2001) already analyzed the income expectations, we focus here on the income
realizations. We regress realized income in year j on a set of indicators for the year in which income was
received (T), personal characteristics (X), and characteristics of a physician’s market and practice (Z):

(4 ) Y i, j = δ 1 T + δ 2 Xi + δ 3 Zi, j + u 4 .

Z includes the measure of HMO penetration and practice characteristics, such as the average number of
hours worked per week and the proportion of patients who are uninsured.
Finally, we examine whether physicians alter their behavior after shocks cause their actual
income to be different than expected, or after shocks cause physicians to revise their income predictions.
Let Pt represent a characteristic of physician i’s practice in year t, such as the number of hours worked per
week, the proportion of patients who are poor, or the amount of time allocated to research and teaching.

16
Physicians were surveyed at time j + k (1998 or 1999) and asked to report changes they have made to
their practice since year j, where j is either their 10th or 20th year of practicing medicine. The probability
that a physician changes a characteristic of his practice between year j and j + k is assumed to be a
function of his income prediction error in year j, Yi,j - EYi,j,t=0, controlling for his actual income in year j
and personal characteristics (X):

(5) (P i, j+ k − P i, j ) = θ 0 +θ 1(Yi, j - EYi, j,t =0 ) + θ 2 Y ij + θ 3 Xi + u 5 .
To maximize sample size, for physicians whose income has not yet peaked, the dependent variable is a
change the physician expects to make in the future and the revision in expected peak income (EYpeak,t=1999
– EYpeak,t=0) is used instead of the prediction error.11 A non-zero coefficient for θ1 indicates that
physicians alter their behavior in response to unanticipated income shocks.

IV. Results
a. Income Prediction Errors
Table 3 reports the average prediction error, separately for 5, 10, and 20 years of experience, and
for physicians’ peak income if they believe their income has already peaked. The income prediction
errors for 5, 10, and 20 years of experience (columns 1-3) are from the students who graduated between
1970 and 1979, whereas the peak income prediction errors (column 4) are from the students who
graduated between 1980 and 1998. For comparability we express all dollar values in 1996 dollars. We
regress a person’s income prediction error for each experience level on a constant term as described in
equation (1). The null hypothesis of unbiasedness is that the coefficient on the constant term (α0) is zero.

11

Recall that for physicians who believe their income has not yet peaked, the follow-up survey asked them
to identify changes they expect to make in the future, and to re-forecast their peak income. About 35 percent of the
observations used in the results for equation (5) employ these revisions to peak income. The conclusions are
qualitatively the same, however, without these observations. The analyses of prediction errors using equations (1) to
(3) do not use the revisions to expected peak income.

17
α0 is positive and significantly different from zero for all four experience levels. Income was on
average significantly greater than expected, especially early in physicians’ careers: α0 is $107,600 with 5
years of experience but considerably smaller ($20,400) with 20 years of experience. The result for peak
income in the final column is generally consistent with the previous columns: the physicians reporting
peak income had fewer than 16 years of experience at the time of the follow-up survey. Therefore, it
appears that average income prediction errors generally decline with the forecast horizon.
The bottom panel of Table 3 presents the distribution of income prediction errors by years of
experience. The median physician earned $68,300 more than he or she expected after five years of
practicing medicine, $48,900 more than expected after 10 years, and $5,900 more than expected after 20
years of experience. The median income prediction error for physicians whose income has already
peaked is $51,800. There is substantial heterogeneity in the income prediction errors. Although the mean
prediction error is positive for all experience levels, a considerable number of physicians earned less than
they expected after 10 and 20 years of experience. The difference between the 75th and 25th percentile of
errors is about $120,000 for 5 and 10 years of experience, and almost $150,000 for 20 years of
experience. Thus, although the average prediction errors decline with the forecast horizon, the crosssectional variance of the errors increases with horizon.
It is possible, of course, that measurement error affects these results. The larger errors at lower
levels of experience could be due to recall bias that worsens with the horizon. For example, for some
physicians the 5th year of experience occurred as many as 21 years before the follow-up survey. Suppose
that a physician who is asked to recall his income at a relatively distant point in the past reports an
amount that is biased toward his current income, which is generally larger than the income he is recalling.
Such a bias could generate prediction errors that decrease with the forecast horizon. We test this
hypothesis by pooling the 5, 10, and 20-year prediction errors and regressing them on a constant, separate
indicators for 5 years and 10 years of experience, and a variable measuring the number of years elapsed

18
between the year of income receipt and the follow-up survey. While the indicators for 5 and 10 years of
experience remain significantly positive, with a larger coefficient for 5 years, the number of years elapsed
is insignificant.12 Thus, the large prediction errors are associated with being in the 5th year and 10th year
of experience per se, even if the 5th year and 10th year took place relatively recently. The prediction errors
are not associated with the time elapsed, counter to the hypothesis of systematic recall bias.13
Further, the results are similar if we analyze the revision in expected peak income for physicians
who believe their income has not yet peaked (EYpeak,t=1999 - EYpeak,t=0). Here the current expectation for
peak income from the follow-up survey is not subject to recall bias. The corresponding mean revision
(α0) is 45.6 (standard error of 5.93), which implies that these physicians on average received good news,
and revised up their expectations for peak income. Furthermore, recall bias is unlikely to explain the
systematic cross-sectional components of the prediction errors that we emphasize below. For instance,
there is no reason to suppose that recall bias differentially affects female versus male physicians, or
physicians in states with high HMO enrollment versus those in states with low HMO enrollment.
There are a number of other possible explanations for the result that the average prediction errors
decrease with the forecast horizon. First, it could be that shocks to the health care market
disproportionately benefited younger physicians. To explain the results, however, successive cohorts of
young physicians must have received positive shocks repeatedly over the sample period. As noted below,
the average forecast error is positive for every cohort in the sample.14 Second, it could be that students are

12

The coefficient on the number of years elapsed is also insignificant if we also include in the regression
prediction errors for physicians whose income has already peaked.
13
A related form of recall bias might involve money illusion. Suppose physicians underestimated the
amount of inflation that occurred between the year of income receipt and the follow-up survey, for example in the
late 1970s. They might then report too large a figure for nominal income for the early part of their careers. We test
this hypothesis by regressing the pooled 5, 10, and 20-year prediction errors on a constant, indicators for 5 years and
10 years of experience, and the change in the CPI between the year of income receipt and the follow-up survey. The
coefficient on the change in the CPI is insignificant.
14
Souleles (2001) notes that such a result is not unlikely when the relevant “regime” is long lasting. For
instance, he finds that low education workers continued to receive disproportionately negative shocks over the
1980's and 1990's, perhaps due to ongoing and unexpected skill-biased technical change. As a result he concludes
that it is very difficult to distinguish ex ante bias from ex post shocks. Similarly, here the shocks due to different

19
generally better at forecasting over long rather than short horizons. Since income shocks can be
persistent, however, this seems unlikely. Note that the same students are forecasting over the different
horizons, so one cannot conclude that students are uniformly pessimistic. Third, students might be
relatively pessimistic regarding the beginnings of their careers. Anecdotes suggest that many medical
students are not fully aware of how steeply income rises early in physicians’ careers, perhaps because
students unduly extrapolate their low incomes during the lengthy period of medical training. Students
might receive more accurate information regarding the income of very experienced physicians, perhaps
because the clinical faculty who have a great deal of contact with third- and fourth-year medical students
have considerable experience. We further analyze this explanation below.
To test for efficiency, we regress the income prediction errors on variables that were in students’
information sets when they stated their expected income, using equation (2). Results are reported in the
first column of Table 4. The prediction errors for 5, 10, and 20 years of experience, and for peak income
are pooled together, with experience and experience squared included as controls.15 Standard errors are
adjusted to allow for correlation within an individual across different experience levels.
The estimated coefficients for experience are jointly significant. The prediction errors with 5
years and 10 years of experience are $87,000 and $76,000 larger, respectively, than the prediction errors
for 20 years of experience, consistently with Table 3, even controlling for demographic characteristics.
The coefficient for female physicians is significantly negative. Nicholson and Souleles (2001)
showed that females expected to earn less than men, controlling for a similar set of covariates. Evidently
their incomes turned out ex post to be even lower than expected, to a substantial degree. The difference
between realized and expected income was $56,700 lower, on average, for women relative to men. Hence
the gender gap does in fact represent a large, negative shock to women. One explanation for this result
health care regimes can also be prolonged.
15
The results include the prediction errors for peak income for physicians whose incomes have peaked, but
not the revisions to expectations of peak income for physicians whose incomes have not yet peaked. Consistently
with Table 3, more than 80 percent of the observations are prediction errors for 5, 10, and 20 years of experience

20
that we will examine later is that women, particularly those with young children, work fewer hours than
men, and women might underestimate the impact of childrearing on their income when forming income
expectations. White physicians earned $35,000 more than they expected relative to non-white physicians,
whereas the coefficient on ability (the board score) is not significantly different from zero.
The three physician-specific characteristics (female, white, board score) are jointly significant.
While these results represent a formal rejection of efficiency, one cannot conclude that students
systematically differed in the ex ante quality of their income forecasts. Different types of students might
have received different shocks ex post, even on average over the long sample period. Furthermore, these
demographic characteristics and experience explain relatively little of the variation in income prediction
errors between physicians; the R2 in the first column of Table 4 is only 0.04.
The remaining columns of Table 4 use equation (3) to further explore the sources of income
prediction errors. The second column includes as independent variables only experience and a full set of
dummies for the year in which a physician received his income. The time dummies control for aggregate
shocks that (uniformly) affected all physicians. The year indicator variables are jointly significant. Thus,
the average prediction errors vary significantly over time. As will be discussed below, the largest income
prediction errors occurred in the late 1980s, although on average the students earned more than they
expected in every year. Nonetheless, aggregate shocks explain relatively little of the variation in income
prediction errors; the R2 in the second column is only 0.04.
The third column of Table 4 focuses instead on additional cross-sectional heterogeneity in
prediction errors. In light of the large differences in income between specialties, we replace the year
dummies with specialty indicator variables. Although the Jefferson alumni have generally earned more
than they expected, there are substantial differences by specialty. Students who entered internal medicine
sub-specialties (e.g., cardiology or gastroenterology), radiology, anesthesiology, and surgery earned over

(from the older cohorts of physicians graduating before 1980).

21
$100,000 per year more than they expected, relative to students who entered family practice (the omitted
specialty), on average. Under the assumption that the ex ante quality of students’ forecasts do not vary
across specialties, this suggests that different specialties received different income shocks ex post. That
is, there are specialty-specific shocks that the aggregate time dummies cannot soak up. The R2 of 0.16
indicates that specialty-specific shocks alone explain a considerable amount of the variation across
physicians in income prediction errors, more than year dummies and personal characteristics.
An alternative interpretation of the difference in errors across specialties is that medical students
are not particularly knowledgeable about physician income, and the quality of their knowledge varies
across specialties. However, this assessment is not consistent with the analysis by Nicholson and
Souleles (2001). They find that students do in part foresee future relative trends in specialty income and
incorporate these changes into their own expectations, although not on a dollar for dollar basis. That is,
while their expectations are sensitive to future income trends, some of these trends are unexpected.
Further, if the average specialty errors simply reflected differential knowledge across specialties,
one might expect the relative errors to be rather constant over time. However the relative errors change
over time. This again suggests that different specialties received different shocks over time. To illustrate
this result, we group the specialties into two categories: non-primary care physicians (surgeons,
radiologists, internal medicine sub-specialists, obstetricians, pathologists, psychiatrists, and
anesthesiologists) and primary care physicians (family practitioners, internists, and pediatricians). We
then interact the year indicators (as in the second column of Table 4) with an indicator that equals one for
the non-primary care physicians. The interaction terms are jointly significant and their inclusion
increases the R2 from 0.04 in column 2 to 0.09 (not reported).
In Figure 1 we plot the mean income prediction error over time, separately for primary and nonprimary care physicians. To increase precision, the time dummies refer to two-year increments.16 For

16

The underlying specification omits the constant term.

22
primary care physicians the mean income prediction error is always positive, and significantly different
from zero at the five-percent level for every time period. Relative to primary care physicians, nonprimary care physicians’ income was much larger than expected, especially so in the late 1980s.17
The gap between the lines in Figure 1 characterizes the relative shock to non-primary care versus
primary care physicians. Even if recall bias or other measurement issues affect the overall sample
average prediction error, they are unlikely to explain the fluctuations in this gap. The fluctuations in
relative errors are indicative of time-varying, specialty-specific shocks. The relative positive shock to
non-primary care income in the 1980s might be due in part to new medical technologies (e.g., MRI,
arthroscopic surgery, laparascopic surgery, and angioplasty) that increased the demand for specialist
services.18 The relative negative shock to non-primary care physicians that occurred in the early 1990s
could be due to the influence of managed care health plans on the physician services market and the 1992
revision to the Medicare fee schedule that favored primary care physicians. We will further examine
these shocks below.
These results have important methodological implications for rational expectations (or forwardlooking) models. Empirical implementations of such models usually rely on time dummies to soak up all
systematic components of prediction errors, assuming that aggregate shocks hit all people uniformly.19
However, our results suggest that time-varying, group-specific shocks, which are not captured by time
dummies, are also important. Empirical models need to account for such systematic heterogeneity in
prediction errors.
The final column of Table 4 includes year indicators, specialty indicators, and personal
17

The non-primary care - year interactions are always positive, and significant at at least the 10-percent
level for every 2-year bin in the sample period.
18
Because of entry barriers in the non-primary care specialties, these technology shocks were not fully
offset by more residents switching into non-primary care. Many medical students who tried to obtain residency
positions in orthopedic surgery, surgery, radiology, and obstetrics in the 1980s were unsuccessful (Nicholson, 2001).
19
In many empirical specifications the prediction errors are relegated to the residual term and assumed to be
classical. However, if the prediction errors are systematic (e.g., they are correlated with basic demographic
characteristics), they are likely to be correlated with some of the regressors of interest, resulting in biased estimates.

23
characteristics. These variables collectively explain 19 percent of the variation in income prediction
errors. This R2 is large considering that classical income prediction errors should be white noise.
Evidently prediction errors are not as classical as usually assumed. Controlling for specialty and year,
women still earned less than they expected relative to men, as did non-whites.

b. Income Realizations
Nicholson and Souleles (2001) already analyzed one component of the income prediction errors,
the income expectations. Here we analyze the other component -- the income realizations elicited in the
follow-up surveys. Although there are up to four separate income observations for each respondent,
information on the characteristics of their practice is available only for the time of the follow-up survey,
either in 1998 or 1999.20

We therefore perform two separate regressions, both following equation (4).

First, we pool the multiple income observations for each respondent and regress them on personal
characteristics, including experience, market characteristics (e.g., HMO penetration over time), and
specialty indicators. In this specification the standard errors are adjusted to allow for correlation in the
error terms between the multiple observations for an individual. HMO penetration is interacted with the
specialty indicators to allow the effects of HMOs to vary across specialties. Second, we regress a
physician’s income in 1997 or 1998 on personal characteristics, specialty indicators, as well as
contemporaneous practice characteristics (in 1998 or 1999).
The results of the first regression with multiple income observations over physicians’ careers are
reported in the first column of Table 5. Controlling for specialty and ability, as measured by the board

See Souleles (2001) for a discussion.
20
Recall that the first follow-up survey (in 1998) was sent to students who graduated from medical school
between 1970 and 1979. Among this group, physicians who had been practicing medicine for fewer than 20 years
were asked their income with 5 years of experience, 10 years of experience, and for 1997 (the most current complete
year at the time of the survey). Physicians who had been practicing medicine for 20 or more years were also asked
their income with 20 years of experience. The second follow-up survey (in 1999) was sent to students who
graduated between 1980 and 1998. These physicians were asked to report their income in 1998 (the most current
complete year), 1992, and their peak income if they believed their income had already peaked.

24
score, women earned $59,600 less, on average, than men. The estimated coefficients for experience and
experience squared, which are jointly significant, imply that annual practice income increased by $43,000
(in real dollars) in the first five years of a physician’s career, increased by $24,000 between the fifth and
10th year of experience, and decreased by $9,000 between the 10th and 20th years of experience. That is,
the experience-income profile is quite steep at low levels of experience and peaks before 20 years of
experience. As suggested above, medical students might not be fully aware of the initial steepness of the
experience-income profile.
The uninteracted variable for HMO penetration, corresponding to family practice, is insignificant.
The HMO-specialty interactions, however, are statistically significant for several non-primary care
specialties.21 Relative to family practice, specialists in fields like internal medicine sub-specialties,
surgery, ob/gyn, and anesthesiology in states with high levels of HMO activity earn significantly less than
comparable physicians practicing in those specialties in states where HMOs are less prominent. These
effects are also economically significant. For example, a cardiologist in a state where 20.9 percent of the
population is enrolled in an HMO (the mean value for the physicians in the sample) is predicted to earn
$33,400 less per year than an otherwise similar cardiologist practicing in a state where only 11.2 percent
of the population is enrolled in an HMO (one standard deviation lower than the mean).
HMO enrollment has grown rapidly in the United States, especially between 1992 and 1998 when
enrollment grew at an average rate of 12.4 percent per year. The growth of HMOs could constitute the
negative shock experienced by non-primary care physicians relative to primary care physicians in the
1990s that is illustrated in Figure 1. After 1993 the relative income prediction errors for non-primary care
physicians relative to primary care physicians began to decline.
The second regression specification in Table 5, reported in the third and fourth columns, includes
the contemporaneous practice characteristics. Even when one controls for practice characteristics,

21

The HMO penetration variable and the HMO-specialty interactions are jointly significant in Table 5.

25
including average hours worked per week, women were earning substantially less than men in 1997/1998.
The coefficient estimate on the board score is not statistically significant. Part of the explanation is that
some students with relatively high board scores take academic positions, which pay less within each
specialty. Also, students with high board scores are more likely to enter high-paying specialties
(Arcidiacono and Nicholson, 2001), so some of the returns to ability will be captured by the specialty
indicator coefficients. There are large income differences by specialty. Internal medicine sub-specialists,
for example, earned an average of $303,000 per year more than family practitioners. (For brevity, the
coefficients on the specialty indicators are not reported in Table 5).
Most of the practice characteristic coefficients are statistically and economically significant.
Physicians who work long hours, have a relatively small proportion of poor patients, are in a group
practice, and are not employed by the government have greater income relative to other physicians. For
example, a physician who works 65 hours per week and has a practice where 10 percent of the patients
are poor (Medicaid insurance or uninsured) has a predicted income that is $21,000 higher than a
comparable physician who works a total of 55 hours per week and has a practice where 20 percent of the
patients are poor.

c. Shocks to Physician Practices and Markets
To test the extent to which medical students anticipated the impact of HMOs when they formed
their income expectations, we add the HMO penetration variable and HMO-specialty interaction variables
as explanatory variables to the analysis of prediction errors. As in the fourth column of Table 4, income
prediction errors across physicians’ careers are pooled, and personal characteristics, specialty indicators,
and year indicators are included. The results are reported in Table 6. Income prediction errors in internal
medicine, internal medicine sub-specialties, surgery, ob/gyn, anesthesiology, and radiology were more
than $70,000 larger, on average, than in family practice. However, for four of these specialties (internal

26
medicine, surgery, ob/gyn, anesthesiology) as well as psychiatry, the coefficient for the HMO-specialty
interaction is negative and significant.22 A surgeon in a market with the mean amount of HMO activity
(20.9 percent of the population enrolled in an HMO) earned an estimated $111,500 more than he expected
with 10 years of experience, whereas an otherwise equivalent surgeon in a market where HMOs are more
prevalent (31.6 percent of the population enrolled in an HMO, or one standard deviation higher than the
mean) earned only $62,000 more than he expected. Thus differences in HMO activity across markets
explain a fairly substantial amount of the variation in income prediction errors for surgeons and other
non-primary care physicians. That is, the growth of HMOs represented a large and unexpected shock to
specialist physicians.
Of course HMOs represent only one of many possible shocks that could explain why the mean
income prediction error is positive and why there is considerable variation in prediction errors across
physicians. The Jefferson follow-up survey contains a unique catalogue of possible shocks. We asked
respondents to identify specific market and practice changes that occurred since they formed their income
expectations at the end of medical school (t=0), and to indicate which changes were unanticipated and
therefore not a part of the respondent’s information set at the time of the forecasts. The income prediction
errors should be more strongly correlated with unanticipated changes than with anticipated changes.
Unanticipated market and practice changes can also be viewed as revisions to a respondent’s information
set, and could cause a respondent to revise his expected income. In the follow-up survey we also asked
physicians whose income had not yet peaked to re-forecast their peak income. Therefore, we also test
whether unanticipated market and practice changes are associated with changes in a physician’s
expectations regarding peak income.
To maximize the sample size, Table 7 pools the variables for the income prediction error in year j
(Yj – EYj,t=0) and the change in expected peak income between medical school and year j (EYpeak,t=1999 –

22

The HMO variable and the HMO-specialty interaction terms are jointly significant.

27
EYpeak,t=0). The independent variables include information that was available to the respondents in their
fourth year of medical school (female, white, and board score, as in Table 4). We also include separate
indicator variables for anticipated and unanticipated changes that occurred between the time of the
income forecast and its realization, or between the first and second prediction for peak income (i.e.,
between t=0 and t=j). Year j for the income prediction errors is either the 10th year of practicing
medicine, the 20th year of practicing medicine, or the year in which a respondent’s income peaked. For
physicians whose income has not yet peaked, year j is 1999. For brevity, the coefficient estimates for
changes that occurred and were unanticipated are reported in the third column. We include year indicator
variables to control for aggregate shocks, but not specialty indicators. If the incidence of market changes
varied between specialties, the specialty indicators would capture some of the cross-sectional impact of
the market changes on income prediction errors.
Ten of the 16 unanticipated market and practice changes are statistically significant at the 5 or 10
percent level, and some have had an economically significant effect on physicians’ income prediction
errors (or revisions to expected peak income). Starting in the middle of Table 7, physicians who indicated
when they were a fourth-year medical student that they were planning to enter a relatively low-paying
specialty (family practice, pediatrics, and psychiatry) but now report to be practicing in a relatively highincome specialty (internal medicine sub-specialty, surgery, ob/gyn, anesthesiology, and radiology) earned
$146,000 more than they expected (or revised their expected peak income upwards by $146,000), on
average, relative to physicians who are practicing in their expected specialty. Conversely, physicians who
have switched from a high- to a low-paying specialty had income prediction errors that were $109,000
lower than otherwise similar physicians. Hence changes in specialty are associated with large income
prediction errors.
Physicians practicing in a market where the demand for their services increased or the payments
from health insurers increased each earned about $29,000 more than expected, relative to all other

28
physicians. Physicians who accepted more uninsured and poor patients than they expected earned
$30,000 less than expected; physicians who took a salaried position (e.g., with an HMO) earned $27,000
less than expected; and physicians who accepted more capitated contracts (providing fixed payment
regardless of the amount of services rendered to a patient) than expected earned $20,000 less than they
expected.
Two of the coefficients on the unexpected change variables have a surprising sign. Physicians
that experienced unexpected decreases in their payments from health insurance companies have relatively
large prediction errors and physicians who accepted fewer poor patients have relatively small prediction
errors. One explanation for these results is that there could have been both positive and negative shocks
in the interval between the time of forecast and income receipt, but physicians might be reporting only the
more recent shock. For example, suppose a large increase in health insurance payments was followed by
a small reduction in reimbursement. The physician might report on the follow-up survey that
reimbursement levels decreased. Similarly, in response to a negative income shock a physician may have
accepted fewer poor patients. Nonetheless, the bulk of the unanticipated shocks have the expected effect.
Only two of the 14 coefficients on the market and practice changes that were anticipated by
medical students when they formed their income predictions are significant. Physicians who experienced
an anticipated increase in the demand for their services earned an average of $30,700 more than they
expected, relative to other physicians; and physicians who took a salaried position, and expected to do so,
earned $42,600 less than expected. Note, however, that the follow-up survey only asked physicians to
indicate if a market or practice change that occurred was expected, not whether that change had a larger
or smaller impact on their income than expected. One explanation for these two coefficients is that the
change in general was qualitatively expected, but its magnitude or quantitative impact on income was
partly unanticipated. Overall, these results vividly illustrate the pervasiveness and economic significance

29
of shocks to physicians’ practices.23

d. Impact of Income Shocks on Behavior
Our analysis so far has focused on the sources of income prediction errors. To further document
the economic significance of prediction errors, and the usefulness of the underlying expectations
variables, we now examine whether the errors affect subsequent behavior.24 The 1998 follow-up survey
asked physicians to identify changes they have made to their practices since their 20th or 10th year of
practicing medicine, depending on whether the respondent had been practicing for more than or fewer
than 20 years, respectively. Since Jefferson graduates after 1979 reported only their expected peak
income, the 1999 follow-up survey asked physicians to identify changes they made to their practice either
since their income peaked or changes they expect to make in the future if they believe their income has
not yet peaked. These questions allow us to examine whether and how physicians altered their behavior
in response to shocks they faced over their careers, as measured by the income prediction errors and
revisions in expected peak income, again pooled.
We examine three possible changes a physician could make to his practice: a change in the
number of hours worked per week, a change in the percent of time devoted to teaching and research (nonpatient activities), and a change in the number of Medicaid and uninsured patients treated. For each
potential change, respondents could indicate an increase (coded as 1), a decrease (coded as –1), or no
change (coded as 0). Following equation (5), we relate the practice changes since year j (Pi,t+k – Pi,j) to
personal characteristics, including the physician’s age at the time of the follow-up survey, his income in
year j (Yj), and his income prediction error in year j, Yj – EYj,t=0 (or the change in expected peak income :

23

The results are qualitatively similar if we exclude the revisions to expected peak income and examine
only income prediction errors in Table 7.
24
Recall that Nicholson and Souleles (2001) found that the expectations variables were significant in
forecasting the students’ specialty choices.

30
EYpeak,t=1999 – EYpeak,t=0).25 The subscript j refers to the year when the physician has 10 years of
experience, 20 years of experience, or the year in which his income peaked.
Physicians were also asked to predict their retirement age and whether, with hindsight, they
would have chosen the same specialty in medical school, selected a different specialty, or would have left
the medical profession altogether. The retirement age is continuous but top-coded at 75 years of age.26
Respondents who indicate they would have chosen a different specialty or left medicine altogether are
coded as one; those who would remain in their specialty are coded as zero.
The income prediction errors and revisions in predicted income are likely to be measured with
error, which would tend to bias the coefficient on the prediction error toward zero. In the reported results
we therefore estimate equation (5) using two-stage least squares. We instrument for the constructed
income prediction errors (Yj-EYj,t=0) using a physician’s subjective assessment in 1998 or 1999 regarding
whether his income with 10 or 20 years of experience, his peak income, or his current expectations for
peak income is higher, lower, or about the same as he expected when he was a fourth-year medical
student. We create two indicator variables for people who believe their actual income (or current
expected peak income) is higher than initially expected, or lower than initially expected. Physicians’
subjective assessments of their income prediction errors perform quite well as instruments for the
constructed prediction errors. The first-stage coefficient on the indicator for actual income (or current
expected peak income) being higher than initially expected is $26,600 (standard error of $7,100), and the
coefficient on the indicator for income being lower than initially expected is -$16,200 (standard error of
$7,000), and the two coefficients are jointly very significant. These strong first-stage results reinforce our
confidence in the quality of the expectations data.
Table 8 reports the results. The instrumented prediction error is negative and significant in three

25

Age and experience are highly correlated because most students are close to 22 years of age when they
matriculate.
26
The expected retirement age is the only one of these five variables that is not measured as a change
because we do not observe the age at which a respondent expected to retire when he was a medical student.

31
of the five regressions. Physicians who earned less than they expected in year j were more likely to
respond by increasing their hours worked after year j (column 1), increasing the percentage of their time
devoted to treating patients as opposed to alternatives like research and teaching (column 2), and
reporting that with hindsight they would have chosen a different specialty or left the medical profession
altogether (column 5). These responses to unanticipated shocks are intuitive. Physicians who
experienced positive shocks consumed more leisure, spent more time on lower-paying but perhaps more
enjoyable activities such as teaching and research, and had greater confidence that their career choice was
optimal.27

V. Conclusions
Income expectations play a central role in many economic decisions. However, because
economists cannot usually directly observe income expectations, they have received little study. In this
paper we use a unique panel data set recording physician income expectations and realizations to examine
the accuracy of income expectations, the sources of income prediction errors, and the effect of these
errors on subsequent physician behavior. We find that medical students made systematic income
prediction errors, even over a long (28-year) sample period. Unlike most previous studies, the data set is
rich enough to identify the sources of the prediction errors. We trace a large part of the errors to timevarying specialty-specific shocks. These shocks, as well as other systematic demographic components of
the errors, call into question the common assumption that aggregate shocks affect people uniformly.
More generally, empirical implementations of forward-looking models need to better account for

27

In unreported regressions we have also estimated equation (5) non-linearly, using the constructed income
prediction errors (Yj-EYj,t=0) without instrumenting for the errors as in Table 8. We estimate the practice change
specifications (columns 1-3 of Table 8) using an ordered probit since the dependent variables are trichotomous and
ordered; we estimate the specification for retirement age by ordinary least squares and the specification for selecting
a different specialty or leaving medicine with a probit equation. In two of the five regressions the coefficient on the
prediction error (or change in predicted peak income) is significant. Physicians who earned less than they expected
in year j report a relatively low expected retirement age and are more likely to report that with hindsight they would
have chosen a different specialty or left the medical profession altogether.

32
systematic heterogeneity in shocks and prediction errors.
The data set includes a thorough description of the shocks to physicians’ practices and markets.
We find that market changes that were unanticipated by a medical student when he formed his income
expectations, such as an unexpected increase in demand for physician services, help explain much of the
variation in income prediction errors across physicians. For example, specialist, non-primary care
physicians practicing in markets with relatively high HMO enrollment earned substantially less than they
expected, compared to specialists in markets with low HMO enrollment. We also find that income
prediction errors substantially alter subsequent physician behavior. Physicians who experienced negative
income shocks were more likely to respond by increasing their hours worked, allocating fewer of their
work hours to teaching/research and more to patient care, and were more likely to switch specialties.
These results imply that heterogeneous income shocks can have substantial welfare effects.

33
References
Arcidiacono, Peter, and Sean Nicholson, 2001, “The Mirage of Peer Effects: Evidence From U.S. Medical
Schools, ,” mimeo.
Batchelor, Roy A., 1986, “Quantitative v. Qualitative Measures of Inflation Expectations,” Oxford
Bulletin of Economics and Statistics, 48: 99-120.
Betts, Julian R., 1996, “What Do Students Know About Wages?” Journal of Human Resources, 31(1):
27-56.
Cutler, David M., Mark McClellan, and Joseph P. Newhouse, 2000, “How Does Managed Care Do It?”
RAND Journal of Economics 31(3): 526-548.
Das, Marcel, and Arthur van Soest, 1999, “ A Panel Data Model for Subjective Information on Household
Income Growth,” Journal of Economic Behavior & Organization 40: 409-26.
Dominitz, Jeff, 1998, “Earnings Expectations, Revisions, and Realizations,” The Review of Economics
and Statistics 80(3): 374-388.
Dominitz Jeff, and Charles F. Manski, 1997, “Using Expectations Data to Study Subjective Income
Expectations,” Journal of the American Statistical Association 92(439): 855-867.
Dominitz, Jeff, and Charles F. Manski, 1996, “Eliciting Student Expectations of the Returns to
Schooling,” Journal of Human Resources, 31(1): 1-26.
Gramlich, Edward, 1983, “Models of Inflation Expectations Formation,” Journal of Money, Credit, and
Banking, 15: 155-173.
Keane, Michael P. and David E. Runkle, 1998, “Are Financial Analysts’ Forecasts of Corporate Profits
Rational,” Journal of Political Economy 106(4): 768-805.
Maddala, G.S., Raymond Fishe, and Kajal Lahiri, 1981, “A Time Series Analysis of Popular Expectations
Data,” in Zellner, A., ed., 1983, Applied Time Series Analysis of Economic Data, U.S. Department of
Commerce: 278-290.
Manski, Charles F., 1993, “Adolescent Econometricians: How do Youth Infer the Returns to Schooling?,”
in Studies of Supply and Demand in Higher Education, eds. C. Clotfelter and M. Rothschild, Chicago:
University of Chicago Press: 43-57.
Miller, Robert H., and Harold S. Luft, 1994, “Managed Care Plan Performance Since 1980,” Journal of
the American Medical Association 271(19): 1512-1519.
Nicholson, Sean, and Nicholas S. Souleles, 2001, “Physician Income Expectations and Specialty Choice,”
NBER working paper 8536.
Nicholson, Sean, 2001, “Barriers to Entering Medical Specialties, mimeo.

34
Polsky, Daniel, Phillip R. Kletke, Gregory D. Wozniak, and Jose J. Escarce, 2000, “HMO Penetration and
the Geographic Mobility of Practicing Physicians,” Journal of Health Economics 19(5): 793-809.
Simon, Carol J., William D. White, Patricia Born, and David Dranove, 1998, “Managed Care and the
Physician Marketplace,” in Managed Care & Changing Health Care Markets, Michael A. Morrisey, ed.
Washington, D.C.: American Enterprise Institute Press.
Siow, Aloysius, 1984, “Occupational Choice Under Uncertainty,” Econometrica 52: 631-645.
Sloan, Frank A., 1970, “Lifetime Earnings and Physicians’ Choice of Specialty,” Industrial and Labor
Relations Review 24: 47-56.
Souleles, Nicholas S., 2001, “Consumer Sentiment: Its Rationality and Usefulness in Forecasting
Expenditure– Evidence from the Michigan Micro Data,” Journal of Money, Credit, and Banking,
forthcoming (NBER working paper 8410).
Willis, Robert J. and Sherwin Rosen, 1979, “Education and Self-Selection,” Journal of Political Economy
87(5): S7-S36.
Zarkin, Gary A., 1985, “Occupational Choice: An Application to the Market for Public School Teachers,”
Quarterly Journal of Economics 100(2): 409-446.

35
Table 1
Sample Means and Standard Deviations From Fourth-year Medical Student Surveys

Age at graduation
Female
White
Part 1 NBME board exam score
Expected income, in 1996 dollars ($000)
- 5 years of experience: EY5,t=0
- 10 years of experience: EY10,t=0
- 20 years of experience: EY20,t=0
- peak income: EYpeak,t=0
Expected specialty
- internal medicine
- family practice
- pediatrics
- surgery
- ob/gyn
- psychiatry
- anesthesiology
- radiology
- other

All Jefferson
Students
(n=5,995)
Mean

Completed Follow-up Survey (n=2,631)
Mean
Std. Deviation

26.8
0.236
0.875
204.2

26.6
0.231
0.900
205.1

2.83
0.422
0.299
17.1

97.6
148.9
184.2
183.1

95.0
148.8
184.1
185.4

46.2
81.5
85.7
113.1

0.232
0.144
0.061
0.223
0.054
0.031
0.027
0.036
0.192

0.225
0.163
0.068
0.233
0.056
0.032
0.023
0.029
0.170

0.418
0.370
0.252
0.423
0.230
0.177
0.151
0.168
0.376

Notes: Jefferson medical students were asked during their fourth year (t=0) to predict their income EYj,
t=0 from medical practice with j= 5, 10, and 20 years of experience after completing residency training, as
well as the peak income in their careers. (Students who graduated after 1979 were asked to predict only
their peak income, not their income 5, 10, and 20 years after completing residency training. Sample
means for the latter variables reflect the responses from students who graduated before 1980 only.)
Column 1 includes all students who graduated from Jefferson Medical College between 1970 and 1998.
Column 2 and column 3 include the subset of students who responded to the 1998 or 1999 follow-up
surveys that recorded the corresponding income realizations.

36
Table 2
Sample Means and Standard Deviations from the 1998 and 1999 Follow-Up Surveys

Practice/market characteristics (t=1998/99)
- solo practice
- hours worked per week
- teach 10+ hours/week
Percent of state residents enrolled in an HMO
Actual income from medical practice (1996 $000):
- 5 years of experience: Y5
- 10 years of experience: Y10
- 20 years of experience: Y20
- current (1997 or 1998) income
- peak income, if income has peaked: Ypeak
Expected peak income, if income has
has not yet peaked: EYpeak, t=1998/9
Expected retirement age
Respondents’ subjective assessment of Y10, Y20,
or Ypeak relative to EY10,t=0, EY20,t=0, or EYpeak,t=0:
- actual income higher than expected
- actual income about same as expected
- actual income lower than expected
W/ hindsight, respondent would have chosen a
different specialty in medical school or left
medicine altogether
Market/practice changes that occurred during
first 10 or 20 years of practicing medicine:
- demand for MD services increased
- demand for their services decreased
- payments from insurance companies increased
- payments from insurance companies decreased
- increase in utilization management by insurers
- MD accepted more uninsured/Medicaid patients
- MD accepted fewer uninsured/Medicaid patients
- MD accepted more capitated contracts
- MD switched specialties
- MD switched to a different practice
- MD took a salaried position
- MD increased work hours
- MD decreased work hours
- MD allocated more time to seeing patients
- MD allocated more time to non-patient activities

Mean

Std. Deviation

0.118
56.1
0.220
20.9

0.323
14.6
0.414
10.7

200.8
238.5
220.2
194.4
259.0
238.3

152.1
177.0
135.6
125.6
183.1
173.4

61.9

7.76

0.366
0.296
0.338

0.482
0.456
0.473

0.196

0.397

Change
occurred
0.511
0.096
0.143
0.572
0.300
0.154
0.075
0.326
0.043
0.206
0.111
0.344
0.089
0.168
0.099

Respondent expected the
change, conditional
on its occurrence
0.346
0.149
0.335
0.231
0.137
0.212
0.120
0.202
0.073
0.187
0.121
0.255
0.323
0.157
0.154

Notes: N=2,350. The follow-up surveys in 1998 and 1999 elicited income realizations Yj at j years of experience
corresponding to the income expectations asked during medical school (t=0), in current dollars, including peak
career income if their income has already peaked. (If income has yet to peak, students were asked to re-forecast

37
their peak career income, EYpeak, t=1998/9.) Students were also asked to subjectively assess whether their income
turned out higher or lower than they expected when they were a fourth-year medical student. This question refers to
income at the 20th year of experience for physicians with at least 20 years of experience; otherwise it refers to
income at the 10th year of experience. Students also catalogued the changes to their practices and markets that
occurred during the first 10 years of practice (20 years for the older physicians), and whether they had expected
these changes as of the 4th year of medical school. The sample includes only graduates who were practicing
medicine at the time of the survey (excluding residents).

38
Table 3: Income Prediction Errors With 5, 10, and 20 Years of Experience, and for Peak Income
Panel A: Average Income Prediction Errors (1996 $000)
Graduated 1970-1979
Dependent variable:
mean (α0)
S.E.
Observations

Graduated 1980-1998

Y5 - EY5,t=0

Y10 - EY10,t=0

Y20 - EY20,t=0

Ypeak – EYpeak,t=0

107.6**

92.5**

20.4**

78.7**

(6.04)

(7.64)

(11.8)

753

246

380

(7.12)
762

Panel B: Distribution of Income Prediction Errors (1996 $000)
Percentile

Y5 - EY5,t=0

Y10 - EY10,t=0

Y20 - EY20,t=0

Ypeak – EYpeak,t=0

10th

-16.2

-50.9

-137.4

-42.4

25th

20.9

-4.7

-77.4

-0.2

Median

68.3

48.9

5.9

51.8

75th

145.6

137.0

74.1

133.4

90th

259.2

294.1

202.3

254.6

Notes: Income prediction errors are constructed as the difference between actual income Yj with j years of experience (from the follow-up survey) and the
corresponding expected income EYj,t=0 for year j, as forecasted in the fourth year of medical school (t=0). Expected and realized incomes are converted to 1996
dollars using the consumer price index. Since 1980, the medical school survey asks students to predict only their peak income; before 1980, it also asked for
predictions with j=5, 10, and 20 years of experience. Panel A estimates the average forecast error using equation (1), by regressing the errors on a constant α0.
The standard errors are adjusted to allow for correlation between physicians according to the year in which income was received. ** = significantly different
from zero at the five-percent level.

39
Table 4
Determinants of Income Prediction Errors

Female
White
Board score
Experience
Experience squared
Indicators for year
income received

(1)
Personal
Characteristics
-56.7**
(9.74)
34.5*
(18.9)
-0.0718
(0.249)
3.26
(2.09)
-0.363**
(0.089)

(2)
Year
Controls

Not included

Jointly sig.

Not included

0.214
(2.56)
-0.277**
(0.103)

Specialty indicators (family practice omitted)
- internal medicine

(3)
Specialty
Controls

(4)
Specialty, Year, &
Personal Characteristics
-45.3**
(10.2)
39.4**
(17.2)
-0.252
(0.235)
5.20**
2.63
(2.09)
(2.55)
-0.420**
-0.309**
(0.088)
(0.101)

Constant

84.8
(52.2)

70.9**
(19.0)

45.9**
(8.95)
205**
(27.0)
20.2**
(8.93)
118**
(14.2)
97.5**
(16.5)
-9.96
(12.7)
149**
(27.0)
141**
(16.6)
26.1**
(13.3)
59.5**
(17.2)
12.3
(11.3)

Observations
R2

2,117
0.04

2,117
0.04

2,117
0.16

- internal medicine sub-specialties
- pediatrics
- surgery
- ob/gyn
- psychiatry
- anesthesiology
- radiology
- pathology
- other

Jointly significant

40.8**
(9.25)
198**
(25.9)
19.1**
(9.39)
108**
(14.4)
95.3**
(16.9)
-22.9*
(13.5)
148**
(27.4)
134**
(15.8)
18.0
(14.0)
54.9**
(17.6)
40.2
(51.5)
2,117
0.19

Notes: This table tests for systematic components in the income prediction errors, following equations (2) and (3).
The dependent variable is the difference between realized and expected income, Yj – EYj,t=0 in year j. Observations

40
are pooled for j= 5, 10, and 20 years of experience and for peak career income. Family practice is the omitted
specialty in columns (3) and (4). Standard errors are corrected to allow the error terms to be correlated for an
individual throughout his career. ** = significantly different from zero at the 5-percent level; * = significantly
different from zero at the 10-percent level.

41
Table 5
Determinants of Physicians’ Income
Pooled Observations

Female
White
Board score
Experience
Experience squared
Percentage of population
enrolled in HMO

Coefficient

S.E.

Coefficient

S.E

-59.6**
10.6
-0.252
10.4**
-0.378**
0.176

5.46
8.52
0.156
1.19
0.058
0.442

-32.8**
-0.107
-0.080
9.46**
-0.273**

5.16
8.49
0.182
1.45
0.066

1.63**
-0.440**
75.5
-0.477
-13.4
-48.5**

0.220
0.110
76.0
0.363
9.63
7.12

22.0

38.9

HMO * specialty indicators (family practice omitted)
- internal medicine
-0.994**
- internal medicine sub-specialists
-3.12**
- pediatrics
0.276
- surgery
-1.79**
- ob/gyn
-1.75**
- psych
-0.663
- anesthesiology
-3.13**
- radiology
-0.048
- pathology
0.023
- other
-0.629

0.418
1.21
0.488
0.687
0.747
0.498
0.994
0.811
0.726
0.744

Practice characteristics (1998 or 1999)
- hours worked/week
- poor patients as % of total
- > 9 hours/week on teaching/research
- board score * teach > 9 hours
- solo practice
- employed by government
Constant
Observations
R2

1997 or 1998 Income

159**

35.4
4,837
0.27

1,806
0.30

Notes: The dependent variable is ex post income received in year j, Yij, following equation (4). In the first
specification, j is the year in which a physician had 5, 10, and 20 years of experience, and the year in which a
physician’s income peaked, pooled together. The standard errors are corrected to allow the errors to be correlated for
a physician throughout his career. The second specification uses income only from 1997 and 1998, the year before
the follow-up survey, and includes contemporaneous practice characteristics as of the follow-up survey. Indicator
variables for a respondent’s specialty and the year in which he received their income are included in the both
specifications. ** = significantly different from zero at the 5-percent level; * = significantly different from zero at
the 10-percent level.

42
Table 6: Effect of HMOs on Income Prediction Errors
Coefficient

S.E.

Female
White
Board score
Experience
Experience squared

-47.3**
40.7**
-0.219
2.33
-0.300**

10.2
18.1
0.236
2.60
0.102

Specialty indicators (family practice omitted)
- internal medicine
- internal medicine sub-specialist
- pediatrics
- surgery
- ob/gyn
- psychiatry
- anesthesiology
- radiology
- pathology
- other

71.9**
220**
20.3
177**
142**
31.0
201**
120**
35.4
85.8**

15.4
42.9
16.9
23.9
28.6
25.4
44.6
25.4
22.9
31.0

0.574

0.805

Percentage of state population
enrolled in an HMO

HMO * specialty interactions (family practice omitted)
- internal medicine
-2.02**
- internal medicine sub-specialist
-1.51
- pediatrics
0.145
- surgery
-4.63**
- ob/gyn
-3.08*
- psychiatry
-3.60*
- anesthesiology
-3.49**
- radiology
0.985
- pathology
-1.05
- other
-2.10**

0.722
2.06
0.809
1.09
1.58
1.81
1.54
1.27
1.02
1.11

Constant

55.5

Observations
R2

30.0
2,101
0.20

Notes: This table tests for systematic components in the income prediction errors, following equations (2) and (3),
focusing on the effect of the growth in health maintenance organization (HMO) enrollment. The dependent variable
is the difference between realized and expected income, Yj – EYj,t=0 in year j. Observations are pooled for j= 5, 10,
and 20 years of experience and for peak career income. Family practice is the omitted specialty. Indicator variables
are included for the year in which income was received. Standard errors are corrected to allow the errors to be
correlated for a physician throughout his career. ** = significantly different from zero at the 5-percent level; * =
significantly different from zero at the 10-percent level.

43
Table 7
Impact of Market and Practice Changes on Income Prediction Errors
Anticipated at t=0

Unanticipated at t=0

Market and practice changes:

Coefficient

S.E.

Coefficient

S.E.

Demand for MD’s services increased
Demand for MD’s services decreased
Payments from insurance companies increased
Payments from insurance companies decreased
Increase in utilization mgmt by insurers
MD accepted more uninsured/Medicaid pts
MD accepted fewer uninsured/Medicaid pts
MD accepted more capitated contracts
MD switched to higher-paying specialty
MD switched to lower-paying specialty
MD switched to a different practice
MD took a salaried position
MD increased work hours
MD decreased work hours
MD allocated more time to seeing pts
MD allocated more time to non-pt activities

30.7**
13.2
21.3
15.6
3.23
-39.9
-67.9
-5.00

11.0
25.3
21.0
16.5
23.1
28.1
68.4
17.3

-0.218
-42.6**
10.3
14.3
50.0
-16.7

19.9
17.8
15.1
20.1
33.7
18.1

29.0**
2.77
28.7**
29.0**
-5.83
-29.9**
-43.0**
-19.9**
146**
-109**
6.11
-27.3**
16.3*
4.03
1.29
-19.4

9.39
19.8
14.4
9.76
9.70
10.9
17.9
9.68
40.3
26.9
10.3
9.25
8.84
20.3
9.84
12.1

Female

-25.9**

9.64

White

12.3

16.1

Board score

-0.288

0.242

Experience

-4.10

3.08

Experience squared

0.055

0.103

Constant

144**

51.6

Observations
R2

1,660
0.08

Notes: This table analyzes the effect on income prediction errors of various changes in physician markets and
practices, following equation (3). The dependent variable is the income prediction error in year j: Yj - EYj,t=0.
Observations are pooled for j = 10 years of experience, 20 years of experience, or the year in which a person’s
income reached its peak. (For physicians whose income has not yet peaked, the dependent variable is the change
between 1999 and the 4th year of medical school (t=0) in the person’s expectation for peak income: EYpeak,t=1999 EYpeak,t=0). Each market and practice change is interacted with an indicator for whether the change was anticipated
as of t=0. The anticipated and unanticipated changes are both included as independent variables in a single
regression; the unanticipated changes are listed in the third column for clarity. Indicator variables are included for
the year in which a physician received his income. ** = significantly different from zero at the 5-percent level;
* = significantly different from zero at the 10-percent level.

44
Table 8
Effect of Income Prediction Errors on Behavior
Change in %
of time devoted
to patients

Change in #
of Medicaid/
poor patients

Dependent variable:
Income prediction error
(Yj - EYj,t=0)

-0.0044**
(0.0013)

-0.0014*
(0.0007)

-0.0001
(0.0007)

0.0054
(0.0097)

-0.0022**
(0.0008)

Income, Yt=j

0.0039**
(0.0011)

0.0013**
(0.0007)

0.0001
(0.0006)

-0.0097
(0.0085)

0.0013**
(0.0006)

Female

0.0304
(0.0734)

0.0160
(0.0438)

0.0322
(0.0375)

-2.15**
(0.578)

0.0830*
(0.0467)

White

-0.0351
(0.0955)
-0.0093
(0.0057)
-0.221
(0.252)

0.0705
(0.0570)
-0.0098**
(0.0034)
0.0865
(0.150)

-0.0212
(0.0488)
-0.0032
(0.0029)
0.132
(0.129)

0.505
(0.752)
0.353**
(0.0447)
45.6**
(1.95)

0.0292
(0.0564)
0.0030
(0.0042)
-0.0942
(0.224)

1,491

1,491

1,491

Age
Constant
Observations

1,491

Expected
retirement age

w/ hindsight, MD would
have chosen a different
specialty in med school

Change in
hrs. worked

781

Notes: This table analyzes the effect of income prediction errors (shocks) in year t=j on physician behavior, following equation (5). All models are estimated
with two stage least squares. The physician’s subjective assessment of whether his income in year t=j was different than expected at t=0 (see Table 2) is used as
an instrument for the constructed prediction errors: Yj - EYj,t=0. Observations are pooled for j = 10 years of experience, 20 years of experience, or the year in
which a person’s income reached its peak. (For physicians whose income has not yet peaked, the dependent variable is the change between 1999 and the 4th year
of medical school (t=0) in the person’s expectation for peak income: EYpeak,t=1999 - EYpeak,t=0.) The dependent variables in columns 1-3, which indicate whether
a physician made a change to his practice since the year t=j, can take on one of three values: 1 for an increase, 0 for no change, and –1 for a decrease. The
expected retirement age is a continuous variable top-coded at 75. In column 5, the binary dependent variable is 1 if the person indicated in 1998/1999 that with
hindsight he would have selected a different specialty in medical school or left the medical profession altogether. Indicator variables are included for the year in
which a physician received his income or revised his predicted peak income. The income and income prediction error variables are measured in thousands of
dollars.

45

Figure 1
Differences in Income Prediction Errors Between Primary and Non-primary Care Physicians

200
180
160
Income
Prediction
Error
(1996 $000)

Non-primary care MDs

140
120
100
80
60
Primary care MDs

40
20
0
79/80

81/82

83/84

85/86

87/88

89/90

91/92

93/94

95/96

97/98

Year in Which Income Was Received (2-year bins)
Notes: This figure displays the year effects (in two-year bins) from a regression of the income prediction errors Yj - EYj,t=0 on indicator variables
for the year in which income was received, and interactions of the year dummies and an indicator for non-primary care specialties
(e.g., surgery, internal medicine subspecialties, ob/gyn, radiology, anesthesiology, psychiatry, pathology). Experience and experience squared
are included in the regression. Two-year periods with fewer than 30 income observations are not displayed in this figure.

