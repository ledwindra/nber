NBER WORKING PAPER SERIES

SCIENTIFIC TEAMS AND INSTITUTION COLLABORATIONS:
EVIDENCE FROM U.S. UNIVERSITIES, 1981-1999
James D. Adams
Grant C. Black
J. Roger Clemmons
Paula E. Stephan
Working Paper 10640
http://www.nber.org/papers/w10640
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
July 2004

The views expressed herein are those of the author(s) and not necessarily those of the National Bureau of
Economic Research.
©2004 by James D. Adams, Grant C. Black, J. Roger Clemmons, and Paula E. Stephan. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

Scientific Teams and Institutional Collaborations: Evidence from U.S. Universities, 1981-1999
James D. Adams, Grant C. Black, J. Roger Clemmons, and Paula E. Stephan
NBER Working Paper No. 10640
July 2004
JEL No. L3, O3
ABSTRACT
This paper explores recent trends in the size of scientific teams and in institutional collaborations.
The data derive from 2.4 million scientific papers written in 110 leading U.S. research universities
over the period 1981-1999. We measure team size by the number of authors on a scientific paper.
Using this measure we find that team size increases by 50 percent over the 19-year period. We
supplement team size with measures of domestic and foreign institutional collaborations, which
capture the geographic dispersion of team workers. The time series evidence suggests that the trend
towards larger and more dispersed teams accelerates at the start of the 1990s. This acceleration
suggests a sudden decline in the cost of collaboration, perhaps due to improvements in
telecommunications. Using a panel of top university departments we find that private universities
and departments whose scientists have earned prestigious awards participate in larger teams, as do
departments that have larger amounts of federal funding. Placement of former graduate students is
a key determinant of institutional collaborations, especially collaborations with firms and foreign
scientific institutions. Finally, the evidence indicates that scientific influence increases with team
size and institutional collaborations. Since increasing team size implies an increase in the division
of labor, these results suggest that scientific productivity increases with the scientific division of
labor.
James D. Adams
Department of Economics
3504 Russell Sage Laboratory
Rensselaer Polytechnic Institute
110 8th Street
Troy, NY 12180-3590
and NBER
adamsj@rpi.edu
Grant C. Black
School of Business and Economics
Indiana University at South Bend
1700 Mishawaka Avenue
South Bend, IN 46634-7111

J. Roger Clemmons
Institute for Child Health Policy
University of Florida
PO Box 100147
Gainesville, FL 32610-0147
jrc@ichp.edu
Paula E. Stephan
Department of Economics
And Andrew Young School of Policy Studies
Atlanta, GA 30303-3083
pstephan@gsu.edu

I.

Introduction

Over the past century teams of scientific specialists have largely replaced the independent scientist,
much as corporate R&D laboratories have largely replaced the independent inventor. This trend towards
larger teams is strongly evident in nearly all data on scientific research, including our own1. Advancing
instrumentation and the sheer quantity of what there is to know have pushed it, while improving
communications have pulled it, to its present state of development. Pencil-and-paper research is the lone
exception to the rule, but this forms a dwindling share of science and may at last succumb to the same
forces that have elsewhere led to large-scale research.
The study of scientific teams is important, first, because it brings to light changes in the research
production function that otherwise would remain hidden. In particular, scientific collaboration might
increase the effectiveness of research, just as specialization increases general productive efficiency2. The
evidence on efficiency is suggestive but not definitive. Collaborative research is more highly cited
(Presser, 1980; Sauer, 1988), suggesting that collaboration does raise quality. But more able researchers
also attract more coworkers (Zuckerman and Merton, 1973) so that separating efficiency from talent in a
cross-section is not easy. Still, the size of scientific teams has increased steadily with time, so that growth
in capital, knowledge, and communications could be responsible for the rising propensity to collaborate
even as talent has remained about the same.
A second reason why collaboration is important lies in its role as a channel of knowledge flows
between scientists. And since collaborators are increasingly found in different institutions and countries,
the entire subject is relevant to the tendency for knowledge to flow more readily and over greater distances
than ever before.
In this paper we present findings on the size of scientific teams, institutional collaborations, and the
geographic dispersion of team workers, using a large database that covers most of U.S. academic science
1

See Zuckerman and Merton (1973), De Solla Price (1986), and Hicks and Katz (1996), for trends in the
size of scientific teams since 1900. Weiner (1994), writing about mid-century, strongly disapproves of the
notion that corporate R&D laboratories might supplant individual researchers and inventors. And yet
Mowery and Rosenberg (1998, Ch. 2) describes exactly this process of replacement.
2
The form of the research production function is central to the properties of growth models, as a
comparison between Romer (1990) and Jones (1995) reveals. Thus the findings of this paper could prove
indirectly relevant to growth theory.

during the years 1981-1999. Our analysis begins with the description of trends in scientific teams and
collaborations at the level of individual scientific papers, which are observations at the piece-work level.
Afterwards, in the context of a panel of universities and fields observed over time, we examine the
determinants of team size and institutional collaboration, as well as their consequences for research output.
The descriptive findings include the following. The data confirm that team size has increased by about
50 percent during the last two decades of the 20th century. We also find that the trend towards larger teams
accelerated, rising from a 2.19 percent annual rate of growth in the 1980s to a 2.57 percent rate during the
1990s. This is an acceleration of 17 percent (2.57/2.19 – 1) between the 1980s and the 1990s. We also
study geographic dispersion directly, using a mileage indicator for the top 110 U.S. universities that form
the core of our data. The annual rate of growth in mileage rises from 3.53 percent in the 1980s to 4.45
percent in the 1990s, an acceleration of 29 percent.
During the same period of time the rate of domestic collaboration more than doubled between U.S.
universities, and between U.S. universities and U.S. firms. Foreign collaborations, while not as common,
increased five-fold. Of all regions, collaboration with Asia increased most rapidly, followed by Europe,
with other regions trailing by a considerable margin. These differences reflect differences in the growth of
scientific research by region of the world. Also, foreign collaboration accelerated between the 1980s and
1990s. The foreign share in institutional collaborations rose annually by 5.11 percent during the 1980s, but
by 7.41 percent during the 1990s. Thus, growth accelerates by 45 percent (7.41/5.11 – 1).
In additional work we address factors that promote or deter teams and collaborations. This analysis is
carried out using a panel of 12 main sciences in the top 110 U.S. universities. Hence, the observations are
at the level of university-fields over time. Our results include the following: a larger stock of federally
funded R&D, private control of a university, and the number of prestigious awards increase team size.
Collaboration with other U.S. universities is an increasing function of the stock of R&D, private control,
and the number of recent PhDs placed in other top 110 schools. Collaboration with foreign institutions of
science is found to increase with the stock of R&D, private control, the number of prestigious awards, and
with the number of recent PhDs placed in leading research countries. Here the results are more fragile, and
there is evidence that the stock of R&D and private control trade places with the number of prestigious
awards. In addition we examine collaboration with U.S. firms, finding again that R&D and private control

2

to an extent increase joint scientific research with firms. But in this case, prestigious awards decrease
collaboration with firms, probably because the emphasis of universities earning such awards is on basic
rather than applied research. As with foreign collaboration, placement of recent PhDs with industries
proves to be very powerful in determining collaboration between universities and firms. The greater
importance of PhD placements in the case of foreign and corporate collaborations than in university
collaborations is consistent with the greater scarcity of substitutes for former PhDs in foreign and corporate
environments.
The empirical work concludes with a study of the role of team size and collaboration in the
determination of research output as measured by papers and citations. The papers and citations are
“fractionated,” in that they consist of estimated proportions that a university and field contribute to both.
We find that papers and especially citations increase with team size, but that the role of shares of
institutional affiliations in the production of papers is less clear. Universities that collaborate more with
foreign institutions, and especially other top 110 schools, produce fewer papers, holding team size constant.
On the other hand collaboration with foreign institutions and other top 110 schools is linked to an increase
in total citations, so that a trade off of fewer papers in return for larger overall scientific influence appears
to be taking place.
The rest of this paper consists of six sections. Section II reviews the literature and models the
determinants of scientific teams and institutional collaborations. Section III describes the database and
calculations that we have undertaken using it. Section IV presents time series evidence on scientific teams.
Section V compares trends in collaborative behavior across scientific disciplines. Section VI provides
regression evidence on the determinants of team size and institutional collaboration using a panel of
university-fields. Section VII concludes.

II.

Analytical Framework

The economics literature on teams is both theoretical and empirical. One line of theoretical work
examines the problem of free-riding and proposes incentive schemes that punish shirking (Holmstrom,
1982; Kandel and Lazear, 1992). Other research examines the relationship between specialization, team
size, and the extent of the market (Becker, 1985; Becker and Murphy, 1992), while still more research

3

(Rosen, 1982) looks at the role of managerial talent in determining the size of firm and its work force using
an efficient supervision model.
Recent empirical research on teams in steel mills by Ichniowski, Shaw and Pennushi (1997) finds that
innovative management practices that promote cooperation in teams and offer pay incentives increase
productivity in steel mini-mills over traditional management practices that tend to limit worker
responsibility. Other empirical research examines institutional collaborations in science and technology
(Arora and Gambardella, 1990; Mowery, 1992; Powell, 1996; Stephan and Levin, 2000; Zucker, Darby,
and Armstrong, 2001; Adams, Chiang and Starkey, 2001; Adams, 2002; Adams, Chiang, and Jensen, 2003;
Adams, 2003, forthcoming; and Adams and Marcu, 2004). These papers tend to find that institutional
collaboration is related to the complementarity of skills, often abetted by policy and by the increasing
complexity of scientific problems.
The present paper concerns small teams of co-workers in scientific research. However, owing to the
location of team members in different scientific institutions, the paper is concerned as well with
institutional collaborations. In our analysis we abstract from free-riding and supervision because the
system of reward for priority in discovery severely punishes shirking by team members and rewards good
work with publication, reputation, and income. Our analysis is inextricably connected, though, with
specialization, the division of labor, and the location of team members, because these factors play large
roles in the empirical analysis and influence the efficiency of scientific research.
In the following exposition we assume that scientific research yields satisfaction to investigators, but
we suppose that this gain in utility is insufficient for investigators to self-finance their research. We base
this assumption on the rarity of scientific research in societies that lack government or private support for
science. But if self-finance is ruled out, then it follows that the quantity of research is subject to a research
budget constraint that is externally imposed, though the budget is of course responsive to grant-raising
efforts3. In conformity with the empirical work below, and with the perception that skill, specialization,
and the division of labor are inter-related and essential elements in the formation of scientific teams, we
assume that the decision variables are the skill of team workers s , the size of the team n , and distance, or

3

In the analysis we assume that the research budget R is at a maximum with respect to grant-raising
efforts.
4

geographic dispersion D 4. Geographic dispersion exceeds zero if and only if the team involves
institutional collaboration so that D is an indicator of such collaboration.
Research output Q is produced according to a Cobb-Douglas production function of skill and team
size. Therefore,
(1)

Q = As α n β ,

The exponents obey the inequalities 0 < α < 1, 0 < β < 1, α + β < 1 so that production is subject to
decreasing returns to scale. The parameter A represents total factor productivity. It could represent the
university environment and the ability or eminence of faculties that are matched to these environments in
advance of the formation of scientific teams. A also undergoes independent increases as knowledge
expands, because knowledge is a factor of production that is fixed with respect to individual researchers. In
turn A tends to increase skill and team size. Thus, “complexity” of projects can be viewed as an indicator
for knowledge and other sources of total factor productivity of the knowledge production function that give
larger teams an increasing advantage. It has been suggested to us that sociological “norms” of scientific
fields have changed in favor of larger teams. However, another interpretation is that larger and higherskilled teams are more efficient as knowledge increases, so that norms are simply a reflection of efficiency
rather than an independent causal factor that increases the division of scientific labor. And besides all the
above, the increasing emphasis by funding agencies on team awards involving large grants and multiple
scientific institutions is consistent with the advantages of larger teams as driven by A in this framework.
On the cost side we assume that the research budget R must cover wage costs of all team
members, as well as a fixed cost F that depends on dispersion of team workers, representing coordination
costs. Of course, geographic dispersion entails benefits as well as costs. In part the gain derives from the
additional funding that can be secured, as the evidence presented below on international and firm-university
collaboration suggests. This is the productive role of dispersion in the present analysis. The research
budget constraint is:

We abstract from the idea that skill and distance could be inter-related as in s = s (D ), s′ > 0, s′′ < 0 . This
constraint would be relevant if abilities were noticeably scarce within a given distance. The analysis in the
paper could easily be extended to deal with this complicating factor.
4

5

(2)

R (D ) = w(s ) n + F (D )

The amount of funding is a concave function of distance, so that
(3)

R′ > 0, R′′ < 0 ,

Thus the returns to dispersion are diminishing. Below we allow for both a shift in funding and also of the
sensitivity of funding to distance or dispersion, which are plausible elements that could alter institutional
collaborations. For example, funding could increase as a result of prior awards. In addition an increase in
the urban density of universities would tend to increase the sensitivity of funding to distance. In (2) the
wage rate w is an increasing and convex function of skill, as in the phenomenon of “superstars” (Rosen,
1981). This yields the following properties of the wage function:
(4)

w′ > 0, w′′ > 0 .

We suppose that the fixed cost F , which represents coordination costs, is an increasing function of
distance D owing to the difficulty of meeting and communicating which this imposes. Therefore, the
properties of the fixed cost function are
(5)

F ′ > 0, F ′′ > 0 .

Thus, coordination costs are an increasing function of distance. As in the case of funding R , changes in
the fixed costs of scientific teams are plausible and realistic features of cross-sectional and time series data.
Fixed costs and their sensitivity to geographic dispersion tend to decline over time with improvements in
telecommunications. F tends to decrease with prior investments in team workers, especially graduate
students, which make working at a distance less costly. This is likely to be a potent factor in both crosssectional data, where universities with larger, more highly ranked graduate programs are more prone to
engage in institutional collaborations; and in time series data, due to the growth of graduate programs over
time.
The problem is one of maximizing output (1) subject to the research budget constraint (2) and their
properties as expressed in (3)-(5), where the control variables are skill s , team size n , and distance D .
The Lagrangian function for this problem is
(6)

L = Asα n β + λ [R(D ) − w(s ) n − F (D )]

First order conditions for (6) are

6

∂L α Q
=
− λw′n = 0
∂s
s
∂L β Q
=
− λw = 0
∂n
n
∂L
= λ (R ′ − F ′ ) ≤ 0
∂D
∂L
= R − wn − F = 0
∂λ

(7)

Optimal amounts of skill and team size are assumed to exceed zero, so that the first two expressions are
equalities. The third expression of (7) is for the moment left as an inequality, to suggest that if funding is
sufficiently unresponsive to dispersion, then D equals zero and institutional collaboration does not occur.
However, consider the case where D > 0 , so that variations in all three of the controls are allowed. The
second order conditions that ensure a maximum for this problem are that the determinants of the bordered
Hessian of the Lagrangian alternate in sign:

(8)

Lss

Lsn

L sλ

Lsn
L sλ

Lnn
Lnλ

Lnλ > 0,
0

Lss

Lsn

0

L sλ

Lsn
0
L sλ

Lnn
0
Lnλ

0

Lnλ
<0
0
0

LDD
0

For exceptionally clear statements of these conditions see Chiang (1974, Section 12.3) or Dixit (1990,
Chapter 7). Using this information and the method of comparative statics we can show that skill s and team
size n tend to increase with productivity A . To see this form the displacement system of (7),
⎡ds ⎤ ⎡−
⎢dn ⎥ ⎢
[H ] ⎢⎢ ⎥⎥ = ⎢⎢−
dD
⎢ ⎥ ⎢
⎣dλ ⎦ ⎢⎣

(9)

1 Q dA ⎤
A s
⎥
1 Q dA
⎥
A n

⎥,
⎥
⎥⎦

0
0

⎡ Lss
⎢L
where: [H ] = ⎢ sn
⎢ 0
⎢
⎣ Lsλ

Lsn
Lnn
0
Lnλ

0
0
LDD
0

Lsλ ⎤
Lnλ ⎥⎥
.
0 ⎥
⎥
0 ⎦

Solving (9) for changes in the control variables and pre-multiplying by the transposed shift vector yields

(10)

⎡−
⎡ ds ⎤
⎢
⎢ dn ⎥
⎢−
− 1A Qs dA − 1A Qn dA 0 0 ⎢ ⎥ = − 1A Qs dA − 1A Qn dA 0 0 [H ]−1 ⎢
⎢dD ⎥
⎢
⎢ ⎥
⎢⎣
⎣ dλ ⎦

[

]

Since by (8) [H ] and [H ]

−1

a combination of

[

]

1 Q dA ⎤
A s
⎥
1 Q dA
⎥
A n

0
0

⎥<0
⎥
⎥⎦

are negative definite, the expression on the right of (10) is strictly negative and

s and n increases as A increases. Likewise we can show that an increase in sensitivity

7

of funding to distance D , or a decrease in sensitivity of fixed costs F causes an increase in D and in
institutional collaborations. Finally, an exogenous increase in funding R , perhaps due to past awards, will
tend to increase team size and skill. These implications tend to fit rather well the results that we report in
section VI below.

III. Database of Scientific Papers
The data set consists of 2.4 million scientific papers that were published during 1981-1999 and have at
least one author from a set of leading U.S. universities. These “top 110” universities account for most of
U.S. academic research. The Institute for Scientific Information (ISI) in Philadelphia is the source of the
data. All papers belong to a standard set of communications consisting of articles, reviews, notes, and
proceedings. The specific source is ISI’s Current Contents data base5.
The papers are assigned to fields according to a classification of the journal in which they appear.
This classification system consists of 88 academic fields. In order to link the paper data to the 12 main
sciences in the National Science Foundation (NSF) CASPAR database, we assign each of the 88 fields to
one of the 12 main fields6. The Appendix lists the 110 universities, ranked by their R&D funding in 1998.
Table 1 shows the 12 main NSF sciences and their components made up of the 88 ISI sub-fields.
As noted in the introduction, we use the data both at the paper level and at the level of universityfields. At the paper level we compile time trends and cross-sectional patterns by field and year. The data
record date of publication, scientific fields of journals in which the papers appear, institutional affiliation of
authors, address information on city, state, and country; and author names as well as number of authors7.
It is important for the reader to see that the address information is completely separate from author
information, so that a name cannot be assigned to a location at this time. The address information is
nevertheless useful in its own right. Besides the top 110 universities the addresses identify U.S. and

5

The journal set consists of approximately 5500 journals that were active in 1999, as well as about 1600
inactive journals that were cited in currently active periodicals.
6
The 12 fields are: agriculture, astronomy, biology, chemistry, computer science, earth sciences,
economics and business, engineering, mathematics and statistics, medicine, physics, and psychology.
7
There is no limit at this time on the number of authors in the ISI data. The maximum number in our
sample is 210, while the mean number in the paper-level data is 2.36. Notice that the number of authors
underestimates the number of team members when it excludes contributors, such as research assistants. It is
an overestimate when it includes honorific authors. In short, the number of authors measures the size of
scientific teams with error. This error is unavoidable since we lack any other measure of team size.
8

foreign institutions consisting of other universities and colleges; governments and government research
institutes; medical centers; corporations; and all other institutions8. We use the addresses to construct
fractions of scientific papers written in one or more of the top 1109.
We also construct numbers and shares of institutional addresses contributed by different types of
institutions as rough estimates of the location of team workers. Within the U.S. the institutional types
consist of (a) U.S. Government, (b) Other U.S. Universities, (c) U.S. Corporations, (d) U.S. Medical
Centers, and (e) All Other U.S. Institutions. Outside the U.S. the institutional types consist of (a) Foreign
Governments, (b) Foreign Universities, and (c) All Other Foreign Institutions, including by country. As we
have seen, this information allows us to assign fractions of papers to different institutional classes as well
as to provide indicators of the proportional contribution by each class.
Table 2 reports the distribution of scientific papers by the 12 main science fields. The table includes
the years 1981, 1990, and 1999 and all years, showing which fields gain share and which lose. Among the
life sciences, which dominate the data, biology gains while agriculture loses. Among the physical sciences
astronomy and physics gain share. Perhaps not surprisingly, among the mathematical sciences, computer
science gains share and mathematics and statistics lose share. Engineering increases its share. And finally,
the social and behavioral sciences perceptibly lose share.
We use paper-level statistics for the descriptive work in sections IV and V, because this retains the
means and standard deviations of the original data. In section VI we carry out regression analysis of the
determinants of team size, domestic and foreign collaboration, and research “output”. For this purpose we
construct a panel at the level of universities, fields and years. The reason is that the panel allows us to
combine the ISI papers and citations data with information on university-field level R&D and
characteristics of doctoral programs. The NSF CASPAR database of universities, a compendium of NSF
surveys, is the source of the data on university R&D. The National Research Council 1993 Survey of
Doctoral Programs (NRC, 1995) includes characteristics of graduate programs, especially counts of Nobel
8

About 5% of the addresses could not be assigned.
The fractions are ½, ½ in the case of two institutions, 1/3, 1/3, 1/3 for three institutions, and so on. The
cumulative distribution of the number of top 110 institutions per paper is as follows, with number of
institutions in parentheses: 79.6% (1 institution), 96.8% (2 institutions or less), 98.3% (3 institutions or
less), and 99.5% (4 institutions or less). Of course, these are extremely crude indicators of contributions
because they do not include time and effort by team members, nor do they differentiate among types of
effort. In short, the institutional address fractions do not measure labor input, even though we use them to
attribute output to scientific institutions.
9

9

prizes and other prestigious awards, as well as rankings of quality of PhD programs in 1993. Finally,
microdata from the NSF Survey of Earned Doctorates (SED) provide us with estimates of the migration of
PhD students to the academic and industrial sectors of the U.S. economy, as well as to other countries10.
We impose one other constraint on the panel which does not apply to the paper-level data. We consider
only leading departments out of the top 110. All other schools form a remainder cell within each field.
More precisely, we include the top 25 universities in astronomy plus a remainder, the top 50 universities in
agriculture, chemistry, computer science, economics and business, earth sciences, mathematics and
statistics, physics, and psychology, plus one remainder each. And finally we include the top 75 universities
in biology, medicine, and engineering plus remainders for each of these three fields. Summing across
fields, and accounting for the fact that only 48 schools of agriculture formally exist, the panel data consist
of 660 university-fields in any given year. Our purpose in breaking out fewer individual schools in smaller
fields, and more in larger fields, is to avoid large numbers of empty cells for universities in which fields
(and doctoral programs) are small or non-existent11. The result is a panel of 12,540 observations, before
bad or missing data are excluded, that approximates teams and institutional collaborations of 660
university-fields in 12 main sciences over the 19-year period. This panel includes an array of variables that
are likely to drive teams, collaborations, and research output. We describe the major variables in the panel
data and sources of these variables in section VI, where we consider determinants of team size and
collaboration.

IV. Time Trends in Scientific Collaborations
Figures 1-10 display time series of scientific research, team size, and institutional collaboration. All
the graphs refer to the years 1981 to 1999. Figure 1 shows trends in the output of U.S. scientific papers.
The upper line is the sum of all papers having at least one author from a top 110 U.S. university. The
middle line consists of U.S. equivalent papers. By this we mean the fraction of U.S. affiliations in all

10

The migration data used in this paper represents flows of new PhDs with definite plans at the time of
graduation, so that the destinations that we used are projected as within a few months of graduation. The
data are undercounts since one-third of new PhDs do not have definite plans. Moreover, the data represent
even a greater undercount to industry, since many new PhDs go to industry only after completing their
postdoctoral training.
11
The size of the remainder of the top 110 equals an average “department” along the individual top 25, 50,
or 75 schools in a field, showing that we miss rather little by our aggregation procedure. This finding
reflects the positive skew of academic programs. For more on this issue see Adams and Griliches (1998).
10

institutional affiliations on each paper, which is then summed over all papers. The lower line consists of
top 110 paper equivalents. This is the fraction of top 110 affiliations in all affiliations summed over papers.
U.S. and top 110 equivalent papers grow more slowly than total papers. Top 110 equivalents decline by
2.5% as of 1999 compared with the 1995 peak. The increasing spread between papers and their U.S.
equivalents reflects the rising contribution of foreign institutions. This could be seen as beneficial: foreign
institutions produce more of the research and transfer more of their knowledge to the U.S. Or it could be
viewed with pessimism: just remaining in the same place after 1995 seems to have required an increase in
the foreign contribution.
Figure 2 graphs domestic collaboration with other top 110 schools (left scale) and with the top 200
U.S. R&D firms (right scale)12. While the per paper number of schools and firms grow at roughly the same
rate, growth in collaboration with firms is less rapid in the 1980s and more rapid in the 1990s. This
acceleration in university-firm joint research could represent increasing placement of graduate students
with firms rather than schools, it could be a statement about the success of federal programs designed to
promote joint research, or it could signify a slowdown in industrial support for basic research that leads to
increasing reliance on university collaborators. This last point is consistent with the decline in scientific
papers published in industry since 1991. See National Science Foundation, Science and Engineering
Indicators 2004, Volume II, table 5-36.
Comparative trends in foreign and total collaborations are the subject of figure 3. Trends in foreign
universities and institutions per paper follow the left scale. The right scale indicates the total of all
institutions. Collaborations with foreign universities and institutions grow more rapidly than institutional
collaboration as a whole, which is consistent with figure 113.
Figure 4 reveals that growth rates in team size (authors per paper) and institutional collaborations are
about the same. Given that foreign collaborations are growing more rapidly than all collaborations,
domestic collaborations must be growing more slowly than team size. Thus, scientific teams are becoming
more internationalized over time.
12

We define the number of other top 110 schools as the number of top 110 schools minus one, which
represents the “home” institution. In this way we account for conditioning of the data on membership in the
top 110 universities.
13
Correcting the total for conditioning on a top 110 university, the total institutions series increases from
0.8 to 2.0, or 2.5 times. Foreign schools per paper increase from 0.07 to 0.32, or more than 4.5 times, while
all foreign affiliations increase from 0.1 to 0.46, which is again more than 4.5 times.
11

The next two figures examine trends in foreign collaboration by region of the world from 1981 to
199914. Figure 5 reports counts of foreign addresses per paper. The dominant region for collaboration is
Europe, reflecting the size of the scientific sector in Europe. The countries of South and East Asia come in
second by the end of the period, followed by the rest of the Americas. The rest of the world, composed of
Africa, the Middle East, and Oceania, runs a distant fourth.

Figure 6 brings out more clearly the

differences in growth by region. The figure normalizes each of the series in figure 5 by its 1981 value.
Growth is more rapid in Asia and Europe and slower in the Americas and the rest of the world. This reflects
differences in the growth of scientific resources by region.
Figures 7 and 8 consider interactions between team size and the foreign share. Figure 7 displays time
paths of the foreign share classified by intervals of team size. The foreign share is greater in larger teams.
International cost-sharing of large-scale projects could lie behind this relationship, for example in the
Human Genome project, in large-scale space missions, and so on. Figure 8 brings out comparative growth
more clearly by again normalizing each of the series in figure 7 by its 1981 value. The graph shows that
smaller teams are becoming more internationalized at a faster rate. Since larger teams are more
internationalized in 1981, this implies convergence in the foreign share by team size.
Figures 9 and 10 reveal comparative trends in the foreign share by science field. Figure 9 reports time
series of the foreign share in which fields are grouped by their initial 1981 share. The three most
international fields are astronomy, mathematics and statistics; and physics. The three fields that are least
international are agriculture, biology, and medicine. The foreign shares of remaining fields (chemistry,
computer science, earth sciences, economics, engineering, and psychology) fall in the middle. Figure 10
brings out comparative growth more clearly by normalizing each of the series in figure 9 by the 1981 value.
The figure shows that the life sciences are becoming internationalized at the most rapid rate. Since these
fields are the least internationalized at the start, this result again suggests a mild form of convergence in the
foreign shares.

14

In this figure Europe consists of Western and Eastern Europe as well as the European Soviet Socialist
Republics of the former Soviet Union. Asian countries include Japan, India, China, and other countries of
East and South Asia, such as Malaysia, Indonesia, South Korea, Singapore, and Taiwan. Other countries in
the Americas include Canada, Central America, the Caribbean, and South America. Africa, the Middle
East, and Oceania includes Israel (Middle East) and Australia and New Zealand (Oceania), and thus
contains the developed countries in each region.
12

V.

Findings on Collaborative Behavior By Field of Science
We turn now to descriptive findings by field of science and time. We display these in a series of

tables given the number of fields which each chart involves. Table 3 reports team size in 1981, 1990, and
1999, as well as growth in team size across the decades of the 1980s and 1990s. In 10 of 12 fields, growth
occurs more rapidly in the 1990s. This pattern dominates the grand average in the bottom row.
Acceleration in the growth of team size is the rule in these data.
Table 4 uses a direct measure of distance to explore the geographic dispersion of team members.
Owing to data limitations the analysis is restricted to the top 110 U.S. universities. We assume that the
highest ranked university-field on each paper is the “head” institution and calculate mileages to other top
110 institutions on that paper based on latitude and longitude coordinates15. If only one top 110 institution
participates in a paper then the mileage is zero. Therefore, changes in the mileage statistics depend on
changes in the tendency to work with other top 110 schools. The average mileage on a paper is a direct
measure of geographic dispersion within the system of top 110 schools.
The table reports mean distances in 1981, 1990, and 1999 and it compares growth rates across
decades. Growth in geographic dispersion is quite clear but acceleration in growth is less obvious. Six of
12 fields show evidence of acceleration (agriculture, chemistry, earth sciences, engineering, physics, and
psychology), the growth of one (biology) is constant, and the remaining five (astronomy, computer science,
economics and business, mathematics and statistics, and medicine) reveal mild deceleration. And yet the
overall pattern is one of growth acceleration. Table 3 reveals an expanding geographic scope of
collaboration within the top 110: mean distances double from 78 miles to 159 miles over the period. And
despite some mixed results, overall growth accelerates across the two decades. On average the rate of
growth in mileage increases from 3.5% in the 1980s to 4.5% in the 1990s.
Table 5 considers domestic institutional collaboration by field. The table is specifically concerned
with collaborations with other top 110 schools and with top 200 R&D firms. The table reports levels of
collaboration of both kinds in 1981 and 1999 and reports growth over the full period. The table reveals
changes in collaboration within academia as well as between academia and industry. Growth in

15

The calculation assumes that the earth is a sphere and calculates distance using the geodesic or shortest
distance between two points on that sphere. For more, see Adams and Jaffe (1996) and Adams (2002).
13

collaboration within the university sector is general, although it is most rapid in agriculture, biology,
chemistry, and psychology. The situation is quite different in the “between” dimension. There
heterogeneity is the norm: it is the life sciences (agriculture, biology, and medicine) and psychology whose
collaboration with firms expands most rapidly. Industry-university collaboration in more established
industrial-scientific fields (chemistry, computer science, engineering, and physics) grows more slowly. Of
course, the level of collaboration is far higher in these fields than in the life and behavioral sciences.
Astronomy and economics are the only fields where university-firm collaboration declines. All these
patterns are of course driven by changes in the population of industrial scientists in the different disciplines.
Table 5 allows us to compare growth rates in domestic collaboration across sectors and fields. Let
us define a relative increase in the “outward” dimension of a field as an excess in growth of collaboration
with industry over growth in collaboration with universities. Likewise, let us define a relative increase in
the “inward” dimension as taking place when the growth rate with industry is less than the growth rate with
universities. Based on this criterion agriculture, biology, computer science, medicine, and psychology are
becoming more outward disciplines. By the same token astronomy, chemistry, earth science, economics
and business, engineering, mathematics and statistics, and physics are becoming more inward.
Table 6 concludes the descriptive findings by examining trends in foreign collaboration across the
sciences. The table computes the foreign share in institutional addresses on individual papers in 1981,
1990, and 1999. It also examines growth in the share across the decades of the 1980s and 1990s. For
comparison we include mean foreign and total institutional affiliations in brackets. Almost without
exception growth in the foreign share is more rapid than growth of either of the domestic indicators shown
in table 4. Moreover, growth accelerates in every field. Average growth is 5.11% in the 1980s but 7.41%
in the 1990s, so that the acceleration is 0.45 (7.41/5.11 - 1).

VI. Regression Findings
We turn now to the problem of explaining team size, the various dimensions of institutional
collaboration by sector and country, and research “output”. For this purpose, as we have seen, we have
constructed a panel of universities, fields and years, in order to match relevant data from the National
Science Foundation and the National Research Council that are reported at this level, as we have already
explained in section III of this paper. Table 7 contains descriptive statistics from the panel data. The

14

statistics show that the average university field-year observation has a team size of 4.26 authors per paper,
of which 2.65 are estimated to belong to a university-field16. The average university-field article involves
0.41 other top 110 universities. On average foreign institutions contribute a 5.2 percent share of all
institutional affiliations, while U.S. firms contribute 2.0 percent. The average number of papers is 149, for
which 709 citations are received from other top 110 universities during the first five years including the
year in which the paper is published.
The average stock of deflated R&D is about 58 million dollars of 1992. This is the eight-year stock
depreciated at a 15% rate and lagged one year. Thus the R&D stock in 1981 is the sum of deflated and
depreciated R&D over the years 1973-1980 and likewise for all other years17. The average stock of R&D
per lagged paper, a measure of resources per unit of “output”, is about a half million dollars of 1992.
Private universities account for 35 percent of the sample, while on average there are 0.23 prestigious
awards per university-field.
The local university R&D ratio captures the geographic concentration of research in the vicinity of a
university-field, which could be a measure of the ease of institutional collaboration. It is defined as the
ratio of other universities’ R&D within 25 miles to the same R&D within 200 miles. Thus, it denotes the
low cost of nearby collaborators. The ratio of equipment expenditure to R&D over the previous three years
could signify capital-labor substitution, as well as replacement of institutional collaborations.
Ten percent of graduate students go to a school that ranks in the top 20 percent of the top 110
universities. Eighteen percent go to U.S. firms, and five percent go to 12 countries that are highly active in
scientific research. These variables are pools of graduate students that could drive shares of other top 110
schools, U.S. firms, and foreign institutions in the research of a given university-field. In the empirical
work we lag the different graduate student shares by two years in order to take publication lags into
account.

16

The average number of authors is greater in the panel data consisting of university-fields than in the
original paper level data, because the university-field observations weight large teams more heavily than do
individual papers.
17
The choice of an eight-year (and thus incomplete) R&D stock is dictated by the 1973 start date for flows
of R&D in the CASPAR data base, as this interacts with the 1981 start date of the ISI data. The eight-year
stock is thus the longest history that we have. We should say that the CASPAR R&D data, while they
represent a major achievement in data collection on universities, also contain substantial respondent errors.
We have tried to flag these errors and to remove all suspicious observations on R&D from our analysis.
15

Table 8 reports regressions that explain the measure of team size, the logarithm of authors per paper.
Since authors per paper are university-field means, the data are continuous and the estimation method is
OLS. All the regressions remove bad or missing data on the R&D stocks. All include dummy variables for
year and field, in which 1981 and chemistry are the omitted categories. The dummies absorb trend and
field effects, which are highly significant and similar to those depicted in the preceding figures.
Equation 8.1 is a baseline regression that includes the logarithm of the stock of federally funded R&D
in thousands of 1992 dollars and the private university indicator. We find that the stock of federally funded
R&D per paper to an extent increases team size18. This suggests that larger projects entail greater
specialization. Private universities form significantly larger teams. There are several possible explanations
for this result. Private universities may obtain more R&D funding from private foundations and wealthy
donors, which we are not able to measure. Another possible reason for the finding is that better pay, startup packages, and working conditions in top private institutions attract more talented faculty (Ehrenberg,
2003; Ehrenberg, Rizzo, and Jakubson, forthcoming). This talent advantage, which is related to salary and
perhaps governance advantages of top private institutions, could pull together a larger pool of coworkers
(Zuckerman and Merton, 1973).
Equation 8.2 repeats 8.1 but restricts team size to less than 10 workers. The idea behind this restriction
is that university-field R&D is increasingly mismatched with team size as size increases, because an
escalating share of funding is external and is not captured by university-field R&D. Thus, the error in the
R&D stock rises with team size. Consistent with this idea, the coefficient on R&D stock increases slightly
and is more significant in 8.2 than 8.1.
Equations 8.3 and 8.4 add a battery of variables to 8.1 and 8.2. As a whole these variables reduce the
regression coefficient of the stock of R&D per paper. The battery includes the number of prestigious
awards. Since awards data are missing for agriculture and medicine, 8.3 and 8.4 exclude these two fields.
Awards increase team size, consistent with the notion that funding and talent attract coworkers. The local
R&D ratio, which tries to capture local concentration of potential team members, has a small positive effect
on team size, which is not always significant, perhaps because team workers in the same school substitute
for team workers elsewhere. The equipment intensity of R&D spending in the most recent three years
18

We divide federally funded R&D by papers lagged two years, in order to avoid division error bias with
the logarithm of authors per paper on the left hand side of the regression.
16

could signify capital- labor substitution. Consistent with this, its coefficient is negative, but again it is not
always significant. Finally, the indicator of top 20 percent in field slightly decreases team size, possibly
indicating the availability of graduate student assistance within an institution.
Table 9 consists of Grouped Logit equations. The dependent variable is the logarithm of the relative
share of other top 110 schools in the research of a given university-field. This is the share divided by one
minus the share19. While the relative share seems to be a useful way to get at substitution of research by
other top 110 schools for internal research, it does have one limitation. Observations for which the relative
share equals zero cannot be included in the estimation procedure, because these zero values rule out any
finite value for the regression function. The same point applies to tables 10 and 11, which also use
Grouped Logit.
All equations in table 9 include year and field dummies, which are highly significant. In equations 9.1
and 9.3 the logarithm of the stock of federally funded R&D per paper significantly increases the share of
other top 110 schools. Private universities collaborate to a larger extent with other top 110 schools, as do
schools where the faculty have earned a larger number of awards. Again we attribute the greater reach of
institutions with more research dollars and more awards to greater resources and talent.
Equations 9.2 and 9.4 include an array of new variables. The fraction of former PhD students placed in
the top 40 percent of schools in a field is a significant factor in collaboration. Again top 20 percent status
in a field deters collaborations with other top 110 schools, perhaps because of the availability of graduate
assistance within a university-field.
Table 10 is similar to table 9, except that here the dependent variable is the relative share of foreign
institutions in the research of a university-field. For this reason the PhD placement indicator is the fraction
of PhDs who have located to top research countries. The role of the university-field R&D stock per paper
is not as strong in table 10 as it was before in table 9, perhaps because the availability of foreign R&D in
part drives the collaboration. And yet additional R&D and private control do increase the foreign share in
10.1 and 10.2.
The foreign placement indicator contributes strongly to foreign collaboration. It is of some interest to
note that the share of equipment expenditures in the recent past significantly discourages foreign
19

Grouped Logit writes the regression function as log[s / (1 − s )] = X ′β + u .

17

collaboration. This result suggests the role of the funding motive (see section II) for foreign and other
collaborations, especially in equipment-intensive fields such as astronomy and experimental physics, which
are well represented in these data (see figures 9 and 10 and table 6). Foreign collaborations could amortize
fixed costs of expensive equipment across countries in such fields.
Table 11 repeats the exercise of tables 9 and 10, this time using the logarithm of the relative U.S.
corporate share in the research of a university-field as the dependent variable. While the stock of R&D per
paper has rather weak effects on the corporate share, private control of a university increases U.S. corporate
collaboration at a high level of statistical significance. In contrast university-fields that have earned many
prestigious awards collaborate less with firms. What these results suggest to us is that corporate R&D
support is much sought after by private universities. This is true, except in the case of departments with a
strong basic science focus that tend to win prestigious awards and extensive federal support. Notice that
because firms are the primary supporters of research collaborations with universities, it is their R&D that is
the likely driver of collaboration, not the university-field’s R&D.
Also in table 11, the fraction of former PhDs placed in industry strongly drives collaboration with
firms, as one would expect. Recent equipment-intensity also appears to substitute for firm collaborations,
again suggesting the role of outside research partners in underwriting equipment expense.
Tables 8-11 hold constant science field, R&D stock, private control, PhD placements, equipment
intensity of R&D, as well as other variables. For this reason time effects from the regression tables should
lie closer to “pure” effects of technological change on collaboration than trends in the raw data. To show
what these effects look like, figure 11 graphs the regression coefficients from the time dummies in
equations 8.1, 9.1, 10.1, and 11.1, which we previously suppressed in the interest of brevity. A comparison
of the various line graphs confirms what we have already seen—that the foreign share increases more
rapidly than the other indicators, and so on. However, there is an interesting jump in the time series of
relative shares contributed by foreign institutions, U.S. universities, and U.S. firms, which occurs between
1990 and 1991. This jump likely applies to papers written in the late 1980s. Our guess is that the jump
measures the increasing availability of information technology, which enables team workers to collaborate
more cheaply and effectively at a distance. This seems especially reasonable given that there is no clear

18

jump in team size at this time, so that external coworkers are replacing internal coworkers. We concede
that this point is somewhat speculative and that more work is needed to prove the claim.
The empirical work concludes with Table 12, which is concerned with the explanation of research
“output” measured by the sum of fractions of papers and citations to those papers by a university-field20.
The estimation method is Ordinary Least Squares. As before, year and field dummies are included
throughout the table. Equations 12.1 to 12.3 use the logarithm of the fractional number of papers as the
dependent variable, while 12.4 to 12.6 use the logarithm of fractional five-year citations. By “fractional” of
course, we mean the sum of the internal paper and citation fractions within a university-field
In equation 12.1 and the others the coefficient of the logarithm of the lagged stock of R&D is as
expected, positive and highly significant. However, it is also significantly less than 1.0, consistent with the
findings of Adams and Griliches (1998) that suggest diminishing returns to the stock of R&D at the
university-field level. The logarithm of all authors per paper decreases the output of papers in 12.1.
However, this anomalous result merely picks up movement of authorship outside the university-field. The
negative sign is spurious: larger teams involve more institutional collaboration, a smaller number of inside
authors, and thus a smaller number of internal, fractional papers. To see this more clearly notice that when
the fractional number of authors inside a university-field is used instead, as in 12.2, the coefficient on the
logarithm of authors reverses and becomes positive and highly significant. This is precisely the pattern of
sign that one would expect of indicators of the division of labor such as team size.
Equation 12.3 adds shares of other U.S. universities foreign institutions, and U.S. firms to 12.1.
Shares of outside institutions reduce the fractional number of papers, in part because, as already noted,
authorship moves away from the university-field. Another possibility, which is raised by the citation
results, is that a quantity-quality tradeoff exists in the data. An increase in the foreign share may genuinely
imply that fewer but better papers are written within a university-field.
If equations 12.1 to 12.3 seem to suggest that collaboration reduces the number of papers for
reasons that are mostly spurious, then 12.4 to 12.6 indicate that institutional collaboration increases citation
and thus total scientific impact. However, the counterpart to the spurious negative effect of all team

20

Recall that if a university-field contributes half a paper, the fraction assigned is ½; if it contributes a
third, then the fraction is 1/3, and so forth. See fn. 7. For present purposes this fractionation of papers and
citations avoids multiple counting of the papers and citations across universities.
19

members on papers in 12.1, is the much smaller output elasticity of all authors in 12.4 compared with that
of “inside” authors in 12.5. In 12.6 we see that that institutional collaboration also increases fractional
citations. Overall, the evidence of table 12 suggests that the scientific division of labor increases research
“output” as measured by total influence of a university-field21.

VII. Discussion and Conclusion
This paper has presented evidence on patterns of research collaboration in U.S. universities over the
last two decades of the 20th century. The evidence on the size of scientific teams, as measured by authors
per paper, suggests that specialization and the division of labor have increased markedly over this period,
especially during the 1990s. Our findings on collaboration between institutions suggest a similar pattern of
developments, but with some new twists. Collaboration with foreign universities increases more rapidly
over time than team size, while domestic collaboration increases less rapidly. We take this as evidence that
the location of team members is shifting and is becoming more geographically dispersed. However, we
lack complete information on the causal factors directing this dispersion. It seems plausible to say that
domestic collaboration has for a long time been more feasible than international collaboration, and that
only recently have modern communications technologies made international science viable for researchers
on projects of normal size. This interpretation receives support from figures 7 and 8 where it is the smaller
teams that are becoming internationalized at a faster rate. But in addition, an increasing emphasis on large
databases, as in biology and medicine, and on massive instrumentation, as in astronomy and physics, may
have also played important roles in these trends towards greater internationalization.
The growth of collaboration as observed in this article could be viewed as consistent with the
increasing efficiency of the research enterprise. Collaboration at a distance permits a combination of
complementary capabilities that leads to the execution of more and hopefully better research. In this way it
is likely welfare-improving. However, a more somber interpretation is that lagging public funding of
scientific research compels universities to engage in institutional collaborations, especially with firms and
foreign institutions, as a substitute means of support.

21

This is not a perfect test. Some citations could involve hidden self-citations to previous collaborations by
the same research team. We cannot address this upward bias with the data that we have, because we cannot
link names and addresses of researchers, including across papers.
20

References
Adams, James D., “Comparative Localization of Academic and Industrial Spillovers,” Journal of
Economic Geography 2 (July 2002): 253-278.
______________, “Learning, Internal Research, and Spillovers: Evidence from a Sample of R&D
Laboratories,” 2003: forthcoming in The Economics of Innovation and New Technology.
______________, and Adam B. Jaffe, “Bounding the Effect of R&D: An Analysis using Matched
Establishment-Firm Data,” Rand Journal of Economics 27 (Winter 1996): 700-721.
______________, and Zvi Griliches, “Research Productivity in a System of Universities,” Annales
D’Economie et de Statistique 49/50 (1998): 127-162.
______________, Eric P. Chiang, and Katara Starkey, “Industry-University Cooperative Research
Centers,” Journal of Technology Transfer 26 (January 2001): 73-86.
______________, Eric P. Chiang, and Jeffrey L. Jensen, “The Influence of Federal Laboratory R&D on
Industrial Research,” The Review of Economics and Statistics 85 (November 2003): 1003-1020.
______________, and Mircea Marcu, “R&D Sourcing, Joint Ventures, and Innovation: A Multiple
Indicators Approach,” Cambridge, Massachusetts: NBER Working Paper 10474, May, 2004.
Arora, Ashish, and Alfonso Gambardella, “Complementarity and External Linkages: the Strategies of
The Large Firms in Biotechnology,” Journal of Industrial Economics 38 (June 1990): 361-379.
Becker, Gary S., “Human Capital, Effort, and the Sexual Division of Labor,” Journal of Labor
Economics 3 (January 1985), Part 2: Trends in Women’s Work, Education, and Family Building:
S33-S58.
_____________, and Kevin M. Murphy, “The Division of Labor, Coordination Costs, and Knowledge,”
Quarterly Journal of Economics 107 (November 1992): 1137-1160.
Chiang, Alpha C., Fundamental Methods of Mathematical Economics, 2nd edition, New York: McGrawHill, 1974.
Dixit, Avinash K., Optimization in Economic Theory, 2nd edition, Oxford, UK: Oxford University Press,
1990.

21

Ehrenberg, Ronald G., “Studying Ourselves: The Academic Labor Market,” Journal of Labor Economics
21 (April 2003): 267-288.
_________________, Michael J. Rizzo, and George H. Jakubson, “Who Bears the Growing Cost of
Science at the University,” in Science and the University, Ronald G. Ehrenberg and Paula E.
Stephan, editors, Madison, Wisconsin: University of Wisconsin Press, forthcoming.
Hicks, Diana, and J.S. Katz, “Science Policy for a Highly Collaborative Science System,” Science and
Public Policy 23 (February 1996): 39-44.
Holmstrom, Bengt, “Moral Hazard in Teams,” Bell Journal of Economics 13 (1982): 324-340.
Ichniowsky, Casey, Kathryn Shaw, and Giovanna Prennushi, “The Effects of Human Resource
Management Practices on Productivity: A Study of Steel Finishing Lines,” The American
Economic Review 87 (June 1997): 291-313.
Jones, Charles I., “R&D-Based Models of Economic Growth,” Journal of Political Economy 103 (August
1995): 759-784.
Kandel, Eugene, and Edward P. Lazear, “Peer Pressure and Partnerships,” Journal of Political Economy
100 (August 1992): 801-817.
Mowery, David C., “International Collaborative Ventures and the Commercialization of New
Technologies,” in Nathan Rosenberg, Ralph Landau, and David C. Mowery, editors, Technology
and the Wealth of Nations, Stanford, California, Stanford University Press, 1992.
_______________, and Nathan Rosenberg, Paths of Innovation: Technological Change in 20th Century
America, Cambridge, UK: Cambridge University Press, 1998.
National Research Council, Research-Doctorate Programs in the United States: Continuity and
Change, Washington, DC: National Academy Press, 1995.
National Science Foundation, Science and Engineering Indicators 2004, Arlington, Virginia: National
Science Board, 2004.
Powell, Walter W., “Inter-Organizational Collaboration In the Biotechnology Industry,” Journal of
Institutional and Theoretical Economics 152 (1996): 197-215.
Price, Derek J. de Solla, Big Science, Little Science, and Beyond, Revised Edition, New York: Columbia
University Press, 1986.

22

Presser, Stanley, “Collaboration and the Quality of Research,” Social Studies of Science 10 (1980):
95-101.
Romer, Paul M., “Endogenous Technological Change,” Journal of Political Economy 98 (October 1990),
Part 2: S71-102.
Rosen, Sherwin, “The Economics of Superstars,” The American Economic Review 71 (December 1981):
845-858.
____________, “Authority, Control, and the Distribution of Earnings,” Bell Journal of Economics 13
(Autumn 1982): 311-323.
Sauer, Raymond D., “Estimates of the Returns to Quality and Coauthorship in Economic Academia,”
Journal of Political Economy 96 (August 1988): 855-866.
Stephan, Paula E., and Sharon G. Levin, “The Importance of Implicit Contracts in Collaborative Scientific
Research,” in Philip Mirowski and Esther-Mirjam Sent, editors, The Economics of Science,
University of Chicago Press, 2000.
Wiener, Norbert, Invention: The Care and Feeding of Ideas, Boston, MIT Press, 1994.
Zucker, Lynne G., Michael R. Darby, and Jeff S. Armstrong, “Commercializing Knowledge: University
Science, Knowledge Capture, and Firm Performance,” Cambridge, Massachusetts: NBER
Working Paper 8499, October 2001.
Zuckerman, Harriett, and Robert K. Merton, “Age, Aging, and Age Structure in Science,” in Robert K.
Merton, The Sociology of Science: Theoretical and Empirical Investigations, Norman W.
Storer, editor, Chicago: University of Chicago Press, 1973.

23

Appendix
The 110 Top Universities
Appendix Table A-1
The Top 110 U.S. Universities in the Institute for Scientific Information (ISI) Database
Ranked By 1998 Federal R&D

University Name (Rank)

Johns Hopkins University (1)

1998 Federal
R&D
Expenditures
752.983*

University Name (Rank)

1998 Federal
R&D
Expenditures

Emory University (36)

118.045
115.312

Stanford University (2)

342.426

University of Iowa (37)

University of Washington – Seattle (3)

336.748

University of California-Davis (38)

114.912

University of Michigan, All Campuses (4)

311.450

Georgia Institute of Technology, All Campuses (39)

113.643

Massachusetts Institute of Technology (5)

310.741

Baylor College of Medicine (40)

110.610

University of California-San Diego (6)

262.303

University of Florida (41)

106.510

Harvard University (7)

251.876

Vanderbilt University (42)

106.325

University of Pennsylvania (8)

247.914

Boston University (43)

104.428

University of Wisconsin-Madison (9)

240.513

University of Miami (44)

101.492

University of California-Los Angeles (10)

233.702

New York University (45)

101.426

Columbia University, All Campuses (11)

229.723

University of Utah (46)

100.722

University of Colorado, All Campuses (12)

228.342

University of Massachusetts, All Campuses (47)

100.122

University of California-San Francisco (13)

219.912

University of Texas Southwestern Med Center Dallas (48)

97.200

University of Alabama, All Campuses (14)

205.511

Indiana University, All Campuses (49)

95.840

Yale University (15)

205.046

Carnegie Mellon University (50)

95.046

University of Minnesota, All Campuses (16)

204.741

University of Virginia, All Campuses (51)

93.328

Cornell University, All Campuses (17)

204.187

Purdue University, All Campuses (52)

92.844

University of Southern California (18)

190.547

SUNY at Stony Brook, All Campuses (53)

91.531

Washington University (19)

187.173

University of Cincinnati, All Campuses (54)

90.307

Pennsylvania State University, All Campuses (20)

186.274

University of Hawaii at Manoa (55)

86.886

California Institute of Technology (21)

177.748

Georgetown University (56)

84.801

Duke University (22)

172.532

University of New Mexico, All Campuses (57)

84.365

University of North Carolina at Chapel Hill (23)

171.505

Virginia Polytechnic Institute and State University (58)

82.734

University of California-Berkeley (24)

171.135

Oregon State University (59)

82.416

University of Illinois at Urbana-Champaign (25)

168.871

Michigan State University (60)

81.146

University of Pittsburgh, All Campuses (26)

168.511

Colorado State University (61)

80.451

University of Texas at Austin (27)

165.082

Yeshiva University (62)

80.000

University of Arizona (28)

161.999

North Carolina State University at Raleigh (63)

79.533

Texas A&M University, All Campuses (29)

144.938

University of Maryland at Baltimore (64)

78.037

Case Western Reserve University (30)

132.274

SUNY at Buffalo, All Campuses (65)

76.037
73.797

University of Rochester (31)

130.773

University of Illinois at Chicago (66)

University of Maryland at College Park (32)

129.198

Oregon Health Sciences University (67)

71.054

Northwestern University (33)

127.911

University of Texas Health Science Center Houston (68)

70.446

University of Chicago (34)

125.982

Rutgers the State University of NJ, All Campuses (69)

69.829

Ohio State University, All Campuses (35)

124.177

University of Tennessee, All Campuses (70)

69.793

24

Appendix Table A-1
The Top 110 U.S. Universities in the Institute for Scientific Information (ISI) Database
Ranked By 1998 Federal R&D

University Name (Rank)

1998 Federal
R&D
Expenditures

University Name (Rank)

1998 Federal
R&D
Expenditures

Princeton University (71)

69.005

Louisiana State University, All Campuses (91)

67.090

University of California-Santa Barbara (72)

68.408

University of California-Irvine (92)

65.902

Woods Hole Oceanographic Institution (73)

64.765

Washington State University (93)

44.510
44.412

University of Missouri, All Campuses (74)

63.556

Brown University (94)

Tufts University (75)

61.167

Rockefeller University (95)

43.845

University of Kentucky, All Campuses (76)

60.760

Arizona State University Main (96)

41.359

University of Nebraska, All Campuses (77)

58.482

Rice University (97)

34.772

Wayne State University (78)

57.646

University of Delaware (98)

33.688

Wake Forest University (79)

56.705

CUNY, All Campuses (99)

32.412

New Mexico State University, All Campuses (80)

56.587

University of AK Fairbanks, All Campuses (100)

31.505

University of Texas Health Science Center San Antonio (81)

55.004

University of Vermont (101)

31.460

Utah State University (82)

54.903

University of California-Santa Cruz (102)

29.849

University of Georgia (83)

54.712

Syracuse University, All Campuses (103)

29.200

University of Connecticut, All Campuses (84)

53.189

Brandeis University (104)

28.098

Tulane University (85)

52.924

University of Oregon (105)

27.041

Iowa State University (86)

51.196

University of New Hampshire (106)

25.913

University of Kansas, All Campuses (87)

50.567

West Virginia University (107)

24.985

Florida State University (88)

50.451

University of California-Riverside (108)

22.988

Virginia Commonwealth University (89)

48.167

Loyola University of Chicago (109)

17.685

Dartmouth College (90)

45.053

Lehigh University (110)

13.019

Notes. Federal R&D is taken from the CASPAR database of the National Science Foundation. * The data
for Johns Hopkins University includes R&D expense for the Applied Physics Laboratory.

25

Figure 1--Total Papers, Top 110 Equivalents, and US Equivalents of the Top 11 U.S.
Universities, 1981-1999
160000
150000
140000

Papers

130000
Top 110 Equivalent Papers

120000

US Equivalent Papers
Total Papers

110000
100000
90000
80000
1981

1984

1987

1990

1993

1996

1999

Year

Figure 2--Top 110 U.S. Universities and Top 200 U.S. R&D Firms
Per Paper, 1981-1999
0.035

0.8

0.03

0.7
0.025
0.6
0.02
0.5
0.015

0.4

0.3

0.01
1981

1984

1987

1990

1993

1996

Year

26

1999

Top 200 R&D Firms per Paper

Other Top 110 Universities per Paper

0.9

Top 110 Universities per Paper
Top 200 R&D Firms per Paper

0.5

3.1

0.45

2.9

0.4

2.7

0.35
2.5
0.3
2.3
0.25
2.1

All Institutions

Foreign Schools and Institutions

Figure 3--Foreign Schools, Foreign Instiutions, and All Institutions
Per Paper, 1981-1999

Foreign Schools per Paper
Foreign Institutions per Paper
Total Institutions per paper

0.2
1.9

0.15

1.7

0.1
0.05

1.5
1981

1984

1987

1990

1993

1996

1999

Year

Figure 4--Mean Authors and Institutions per Paper, 1981-1999
4.5

Authors, All Institutions

4

3.5

3
Authors per Paper
Total Insititutions per Paper
2.5

2

1.5

1
1981

1984

1987

1990

1993

Year

27

1996

1999

Figure 5--Foreign Address Counts per Paper,
By Region of the World, 1981-1999
0.3

Regions per Paper

0.25

0.2
Africa, Middle East and Oceania
Asia

0.15

Rest of the Americas
Europe

0.1

0.05

0
1981

1984

1987

1990

1993

1996

1999

Year

Figure 6--Norm alized Foreign Address Counts per Paper,
By Region of the World, 1981-1999 (1981=1.0)

8

7

Addresses per Paper

6

5
Africa, Middle East and Oceania
Asia

4

Rest of the Americas
Europe

3

2

1

0
1981

1984

1987

1990

1993

Year

28

1996

1999

Figure 7--Foreign Address Share per Paper,
By Team Size, 1981-1999
0.4
0.35

Foreign Share

0.3
0.25

Foreign Share, 2-4 Authors
Foreign Share, 5-8 Authors

0.2

Foreign Share, 9-12 Authors
Foreign Share, 13+ Authors

0.15
0.1
0.05
0
1981

1984

1987

1990

1993

1996

1999

Year

Figure 8--Normalized Foreign Address Share per Paper,
By Team Size, 1981-1999 (1981=1.0)
3

2.5

Foreign Share

2
Foreign Share, 2-4 Authors
Foreign Share, 5-8 Authors

1.5

Foreign Share, 9-12 Authors
Foreign Share, 13+ Authors

1

0.5

0
1981

1984

1987

1990

1993

Year

29

1996

1999

Figure 9--Foreign Address Share per Paper,
By Degree of Internationalization, 1981-1999
0.21
0.19
0.17

Foreign Share

0.15
0.13

Foreign Share in Least International Fields

0.11

Foreign Share in More International Fields
Foreign Share in Most International Fields

0.09
0.07
0.05
0.03
0.01
1981

1984

1987

1990

1993

1996

1999

Year

Figure 10--Normalized Foreign Address Share per Paper,
By Degree of Internationalization, 1981-1999 (1981=1.0)
4
3.5

Foreign Share

3
2.5
Foreign Share in Least International Fields
2

Foreign Share in More International Fields
Foreign Share in Most International Fields

1.5
1
0.5
0
1981

1984

1987

1990

1993

1996

Year

30

1999

Figure 11--Trends in Team Size and Institutional Collaborations,
Time Effects from Regression Analysis, 1983-1999 (1983=0.0)
1.2

1

Time Effects

0.8
Team Size

0.6

U.S. University Share
Foreign Share

0.4

U.S. Corporate Share

0.2

0

-0.2

1983

1987

1991

1995

Year

31

1999

Table 1
Composition of 12 Main Science Fields,
Papers and Citations of the Top 110 U.S. Universities

Main Science Field

Sub-Field Composition of Main Science Field

Agriculture

General agriculture and agronomy; aquatic sciences; animal sciences; plant sciences; agricultural
chemistry; entomology and pest control; food science and nutrition; veterinary medicine and animal
health

Astronomy

Astronomy and astrophysics

Biology

General biological sciences; biochemistry and biophysics; cell and developmental biology; ecology
and environment; molecular biology and genetics; biotechnology and applied microbiology;
microbiology; experimental biology; immunology; neurosciences and behavior; pharmacology and
toxicology; physiology; oncogenesis and cancer research

Chemistry

General chemistry; analytical chemistry; inorganic and nuclear chemistry; organic chemistry and
polymer science; physical chemistry and chemical physics; spectroscopy, instrumentation, and
analytical science

Computer Science

Computer science and engineering; information technology and communications systems

Earth Sciences

Atmospheric sciences; geology and other earth sciences; geological, petroleum, and mining
engineering; oceanography

Economics and Business

Economics; accounting; decision and information sciences; finance, insurance, and real estate;
management; marketing

Engineering

Aeronautical engineering; biomedical engineering; chemical engineering; civil engineering;
electrical and electronics engineering; engineering mathematics; environmental engineering and
energy; industrial engineering; materials science; mechanical engineering; metallurgy; nuclear
engineering

Mathematics and Statistics

Mathematics; biostatistics and statistics

Medicine

General and internal medicine; anesthesia and intensive care; cardiovascular and hematology
research; cardiovascular and respiratory systems; clinical immunology and infectious disease;
clinical psychology and psychiatry; dentistry and oral surgery; dermatology; endocrinology,
metabolism, and nutrition; environmental medicine and public health; gastroenterology and
hepatology; health care sciences and services; hematology; medical research, diagnosis, and
treatment; medical research, general topics; medical research, organs and systems; neurology;
oncology; ophthalmology; orthopedics, rehabilitation, and sports medicine; otolaryngology;
pediatrics; radiology, nuclear medicine, and imaging; reproductive medicine; research, laboratory
medicine, and medical technology; rheumatology; surgery; urology and nephrology

Physics

General physics; applied physics, condensed matter, and materials science; optics and acoustics

Psychology

Psychology and psychiatry

Source: Institute for Scientific Information

32

Table 2
Distribution of Papers by Field, of the Top 110 U.S. Universities
1981, 1990, 1999, and All Years

Number of Papers
Field of Science
1981

1990

1999

All Years

Agriculture

8,697
(9.0%)

10,714
(8.5%)

9,341
(6.1%)

189,004
(7.8%)

Astronomy

1,688
(1.7%)

1,581
(1.3%)

2,913
(1.9%)

35,508
(1.5%)

Biology

24,928
(25.7%)

32,495
(25.7%)

41,742
(27.4%)

634,737
(26.3%)

Chemistry

7,951
(8.2%)

10,432
(8.3%)

12,205
(8.0%)

194,798
(8.1%)

Computer Science

872
(0.9%)

1,611
(1.3%)

2,045
(1.3%)

28,037
(1.2%)

Earth Sciences

2,802
(2.9%)

3,818
(3.0%)

4,956
(3.3%)

72,920
(3.0%)

Economics

1,758
(1.8%)

2,600
(2.1%)

2,363
(1.6%)

43,540
(1.8%)

Engineering

5,334
(5.5%)

9,204
(7.3%)

11,689
(7.7%)

170,147
(7.1%)

Mathematics

3,086
(3.2%)

3,127
(2.5%)

3,623
(2.4%)

60,710
(2.5%)

Medicine

26,791
(27.6%)

33,154
(26.3%)

41,199
(27.0%)

648,704
(26.9%)

Physics

7,289
(7.5%)

11,521
(9.1%)

13,840
(9.1%)

215,942
(9.0%)

Psychology

5,770
(6.0%)

6,017
(4.8%)

6,538
(4.3%)

115,482
(4.8%)

Total

96,966

126,274

152,454

2,409,529

Source: Institute for Scientific Information and authors’ calculations.

33

Table 3
Team Size and Its Rate of Growth, by Field, of the Top 110 U.S. Universities
1981, 1990, and 1999

Mean Authors Per Paper
Field of Science

Agriculture
Astronomy
Biology
Chemistry
Computer Science
Earth Sciences
Economics
Engineering
Mathematics
Medicine
Physics
Psychology
Total

1981

% Annual
Growth Rate,
1981-1990

1990

% Annual
Growth Rate,
1990-1999

1999

2.407

1.55

2.768

2.00

3.314

2.654

2.36

3.283

4.57

4.952

2.810

2.11

3.398

2.55

4.274

2.816

1.04

3.093

1.68

3.597

1.861

1.47

2.124

2.42

2.640

2.288

2.30

2.814

2.78

3.615

1.572

1.04

1.727

1.29

1.939

2.289

1.14

2.537

1.80

2.984

1.531

0.97

1.671

1.47

1.907

3.259

1.79

3.828

1.99

4.580

3.091

5.46

5.053

4.03

7.264

2.209

1.66

2.565

2.24

3.138

2.766

2.19

3.368

2.57

4.244

Source: Institute for Scientific Information and authors’ calculations.

34

Table 4
Distance Between Team Workers in the Top 110 U.S. Universities,
By Field, 1981, 1990, and 1999

Mean Distance in Miles
Field of Science

Agriculture
Astronomy
Biology
Chemistry
Computer Science
Earth Sciences
Economics
Engineering
Mathematics
Medicine
Physics
Psychology
Total

1981

% Annual
Growth Rate,
1981-1990

1990

% Annual
Growth Rate,
1990-1999

1999

50.9

2.63

64.5

7.15

122.8

264.6

2.76

339.2

1.82

399.5

76.8

4.45

114.6

4.46

171.2

50.8

0.58

53.5

4.65

81.3

138.2

0.45

143.9

0.12

145.4

145.7

2.29

179.1

5.95

306.0

124.8

4.28

183.5

0.81

197.3

61.2

1.76

71.7

2.94

93.4

128.3

1.68

149.2

1.50

170.8

62.2

5.34

100.6

4.84

155.5

92.6

2.51

116.1

3.40

157.7

88.8

4.18

129.4

4.55

194.8

77.7

3.53

106.8

4.45

159.4

Source: Institute for Scientific Information and authors’ calculations.

35

Table 5
Indicators of U.S. Institutional Collaboration,
By Field, Paper of the Top 110 Universities, 1981 and 1999

Other Top 110 Universities Per Paper*

Top 200 Firms Per Paper

Field of Science

Agriculture
Astronomy
Biology
Chemistry
Computer Science
Earth Sciences
Economics
Engineering
Mathematics
Medicine
Physics
Psychology
Total

1981

%Annual Growth
Rate, 1981-1999

1999

1981

%Annual Growth
Rate, 1981-1999

1999

0.224

5.44

0.630

0.003

8.11

0.014

0.387

2.72

0.649

0.016

-0.34

0.015

0.403

5.45

1.135

0.007

6.03

0.022

0.195

7.50

0.811

0.023

2.78

0.039

0.197

2.55

0.320

0.078

4.25

0.175

0.250

3.71

0.506

0.021

0.24

0.022

0.177

3.47

0.342

0.009

-3.09

0.005

0.175

4.73

0.430

0.046

2.91

0.080

0.166

3.11

0.300

0.012

2.69

0.020

0.500

3.67

1.005

0.005

8.26

0.024

0.280

3.98

0.596

0.048

0.11

0.049

0.214

5.34

0.590

0.002

6.59

0.007

0.345

4.70

0.843

0.014

4.18

0.031

Source: Institute for Scientific Information and authors’ calculations. *This is the number of top 110
universities per paper minus one. This measure maintains symmetry with top 200 firms per paper, which is
the number of “other” institutions as well, in this case, top R&D firms.

36

Table 6
Measures of Foreign Affiliation, by Field
Papers of the Top 110 Universities, 1981, 1990, and 1999
Mean Share of Foreign Affiliations
[Mean Foreign Affiliations, Mean Total Affiliations]
Field of Science
Foreign
Institutional
Affiliations in
1981

% Annual
Growth In
Foreign Share,
1981-1990

Foreign
Institutional
Affiliations in
1990

% Annual
Growth In
Foreign Share,
1990-1999

Foreign
Institutional
Affiliations in
1999

0.028
[0.067,1.482]

4.77

0.043
[0.113,1.638]

9.81

Agriculture

0.104
[0.340,2.397]

0.086
[0.247,1.963]

5.49

0.141
[0.509,2.479]

6.14

Astronomy

0.245
[1.144,3.436]

0.034
[0.092,1.732]

6.31

0.060
[0.189,2.046]

6.73

Biology

0.110
[0.455,3.085]

0.046
[0.111,1.456]

3.14

0.061
[0.161,1.573]

6.35

Chemistry

0.108
[0.363,2.441]

0.043
[0.102,1.479]

3.70

0.060
[0.151,1.680]

7.03

Computer Science

0.113
[0.317,2.057]

0.052
[0.141,1.627]

5.33

0.084
[0.267,1.950]

7.23

Earth Sciences

0.161
[0.559,2.626]

0.041
[0.092,1.432]

3.06

0.054
[0.130,1.634]

6.16

Economics

0.094
[0.255,1.926]

0.040
[0.095,1.506]

3.13

0.053
[0.131,1.574]

7.60

Engineering

0.105
[0.302,2.111]

0.071
[0.161,1.438]

4.45

0.106
[0.248,1.588]

5.12

Mathematics

0.168
[0.422,1.901]

0.021
[0.067,2.035]

6.29

0.037
[0.132,2.265]

8.14

Medicine

0.077
[0.345,3.140]

0.070
[0.205,1.721]

3.74

0.098
[0.456,2.169]

7.70

Physics

0.196
[1.194,3.187]

0.016
[0.042,1.559]

6.22

0.028
[0.075,1.775]

8.28

Psychology

0.059
[0.188,2.329]

0.036
[0.097,1.731]

5.11

0.057
[0.186,1.971]

7.41

0.111
[0.466,2.840]

Total

Source: Institute for Scientific Information and authors’ calculations.

37

Table 7
Means and Standard Deviations of Principal Regression Variables
Top 110 U.S. University Data
Mean
(S.D.)

Variable

Indicators of Teamwork and Research “Output”
Number of Authors in a University-Field per Paper

2.65
(0.96)
4.26
(6.43)
0.41
(0.57)
0.07
(0.05)
0.02
(0.02)
149.28
(158.28)
708.75
(1575.74)

Number of Authors per Paper
Other Top 110 U.S. Universities per Paper
Foreign Share per Paper
U.S. Corporate Share Per Paper
Number of Papers by a University-Field
Number of Citations Received by a University-Field,
This Year and the Next Four Years
Characteristics of University-Fields
Stock of Federally Funded R&D in a University and Field
(in Thousands of 1992 Dollars)
Stock of Federally Funded R&D in a University and Field
Per Paper (in Thousands of 1992 Dollars)
Private University
Number of Awards a
Local University R&D Ratio b
Equipment Expenditure/R&D,
Previous Three Years
Share of Graduate Students Placed in Top 20 Percent
Schools, lagged two Years
Share of Graduate Students Placed in U.S. Firms, lagged
Two Years
Share of Graduate Students Placed in 12 Top Research
Countries, lagged two years c

58,277.65
(81,955.07)
485.71
(746.57)
0.35
(0.48)
0.23
(0.62)
0.08
(0.16)
0.07
(0.05)
0.10
(0.14)
0.18
(0.20)
0.05
(0.10)

Notes: Sources for the data are the Institute for Scientific Information, National Science Foundation,
National Research Council, and authors’ calculations. a Awards include the Fields Medal, MacArthur
Awards, the National Medal of Science, the National Medal of Technology, Fellow of the National
Academy of Science, and the Nobel Prize. See the text for a further discussion. b The Local University
R&D Ratio equals R&D in the same field but in other universities within 25 miles, divided by R&D in the
same field but in other universities within 200 miles. c Research countries are Australia, Canada, France,
Germany, Japan, the United Kingdom, Italy, the Netherlands, Israel, New Zealand, Sweden, and
Switzerland.

38

Table 8
Determinants of Team Size
Dependent Variable: Log (Authors/Paper)
(T-Statistics in Parentheses)

Variable or Statistic

Eq. 8.1

Eq. 8.2

Eq. 8.3

Eq. 8.4

1983-1999

1983-1999

1983-1999

1983-1999

None

None

All 12 Main
Fields
Yes,
Significant
Yes,
Significant

Less than 10
Workers
All 12 Main
Fields
Yes,
Significant
Yes,
Significant

10 Fields a

Less than 10
Workers
10 Fields a

Yes,
Significant
Yes,
Significant

Yes,
Significant
Yes,
Significant

0.012
(3.0)**
0.044
(7.5)**

0.014
(6.4)**
0.035
(10.6)**

Equipment Expenditure/R&D,
Previous Three Years
Top 20 Percent In Field
(1=yes, 0=No)
Root MSE

0.267

0.147

0.007
(1.5)
0.049
(6.3)**
0.021
(3.1)**
0.020
(1.0)
-0.166
(-2.5)**
-0.029
(-3.0)**
0.295

0.007
(2.6)**
0.031
(7.3)**
0.019
(5.4)**
0.026
(2.3)*
-0.010
(-0.3)
0.001
(0.3)
0.155

Adjusted R 2

0.76

0.81

0.76

0.78

Number of Observations

9,638

9,228

7,371

6,979

Time Period
Restrictions on Team Size
Fields Included
Year Dummies Included
Field Dummies Included

Log (Stock of Federally Funded R & D,
Divided by papers lagged two years)
Private University
(1=yes, 0=No)
Number of Awards a
Local University R&D Ratio

Notes: Estimation Method is OLS. Sources for the data are the Institute for Scientific Information, the
National Science Foundation, the National Research Council, and authors’ calculations. The dependent
variable is the logarithm of the mean number of authors per paper in a university, field, and year. a
Agriculture and Medicine lack data on prizes and awards b Awards include the Fields Medal, MacArthur
Awards, the National Medal of Science, the National Medal of Technology, Fellow of the National
Academy of Science, and the Nobel Prize. See the text for a further discussion. c The Local University
R&D Ratio equals R&D in the same field but in other universities within 25 miles, divided by R&D in the
same field but in other universities within 200 miles. **Parameter is significantly different from zero at the
1% level for a one-tailed test. * Parameter is significantly different from zero at the 5% level for a onetailed test.

39

Table 9
Determinants of Relative Contribution of U.S. Universities
Dependent Variable: Log (Other Top 110 Share/(1-Other Top 110 Share))
(T-Statistics in Parentheses)

Variable or Statistic

Eq. 9.1

Eq. 9.2

Eq. 9.3

Eq. 9.4

Time Period

1983-1999

1983-1999

1983-1999

1983-1999

Fields Included

All 12 Main
Fields
Yes,
Significant
Yes,
Significant

All 12 Main
Fields
Yes,
Significant
Yes,
Significant

10 Fields a

10 Fields a

Yes,
Significant
Yes,
Significant

Yes,
Significant
Yes,
Significant

0.056
(11.8)**
0.076
(13.1)**

0.067
(12.7)**
0.057
(8.9)**

0.068
(12.8)**
0.101
(15.1)**
0.021
(4.9)**

Equipment Expenditure/R&D,
Previous Three Years
Top 20 Percent in Field
(1 if yes, 0 if no)
Root MSE

0.268

0.053
(2.6)**
0.218
(12.0)**
0.074
(1.0)
-0.034
(-5.1)**
0.267

0.270

0.067
(12.2)**
0.078
(10.5)**
0.019
(4.3)**
0.103
(4.5)**
0.204
(10.4)**
0.005
(0.1)
-0.022
(-2.8)**
0.266

Adjusted R 2

0.57

0.57

0.60

0.61

Number of Observations

9,613

8,621

7,726

7,182

Year Dummies Included
Field Dummies Included

Log (Stock of Federal Funded R & D,
per Paper Lagged Two Years)
Private University
(1=yes, 0=No)
Number of Awards b
Fraction of PhDs Placed In Top 40 Percent
Departments, Lagged Two Years
Local University R&D Ratio c

Notes: Estimation method is Grouped Logit. Sources for the data are the Institute for Scientific
Information, National Science Foundation, National Research Council, and authors’ calculations.
a
Data on prizes and awards are missing for agriculture and medicine. b Awards include the Fields Medal,
MacArthur Awards, the National Medal of Science, the National Medal of Technology, Fellow of the
National Academy of Science, and the Nobel Prize. See the text for further discussion. c The Local
University R&D Ratio equals R&D in the same field but in other universities within 25 miles, divided by
R&D in the same field but in other universities within 200 miles. **Parameter is significantly different
from zero at the 1% level for a one-tailed test. * Parameter is significantly different from zero at the 5%
level for a one-tailed test.

40

Table 10
Determinants of the Relative Foreign Contribution
Dependent Variable: Log (Foreign Share /(1- Foreign Share))
(t-Statistics in Parentheses)

Variable or Statistic

Eq. 10.1

Eq. 10.2

Eq. 10.3

Eq. 10.4

Time Period

1983-1999

1983-1999

1983-1999

1983-1999

Fields Included

All 12 Main
Fields
Yes,
Significant
Yes,
Significant

All 12 Main
Fields
Yes,
Significant
Yes,
Significant

10 Fields a

10 Fields a

Yes,
Significant
Yes,
Significant

Yes,
Significant
Yes,
Significant

0.026
(4.7)**
0.035
(5.2)**

0.014
(2.4)*
0.030
(4.2)**

0.008
(1.2)
0.007
(0.8)
0.021
(4.2)**

Fraction of PhDs Placed In the Top 12 c
Research Countries, Lagged Two Years
Equipment Expenditure/R&D,
Previous Three Years
Top 20 Percent in Field
(1 if yes, 0 if no)
Root MSE

0.312

0.278
(7.1)**
-0.510
(-6.7)**
0.035
(5.0)**
0.309

0.312

0.005
(0.7)
0.008
(1.0)
0.018
(3.2)**
0.194
(4.4)**
-0.378
(-5.0)**
0.009
(1.0)
0.310

Adjusted R 2

0.72

0.73

0.67

0.67

Number of Observations

9,509

9,169

7,629

7,461

Year Dummies Included
Field Dummies Included

Log (Stock of Federally Funded R & D
divided by papers lagged 2 years)
Private University
(1=yes, 0=No)
Number of Awards b

Notes: Estimation method is Grouped Logit. Sources for the data are the Institute for Scientific
Information, National Science Foundation, National Research Council, and authors’ calculations.
a
Agriculture and Medicine lack data on prizes and awards b Awards include the Fields Medal, MacArthur
Awards, the National Medal of Science, the National Medal of Technology, Fellow of the National
Academy of Science, and the Nobel Prize. See the text for a further discussion. c The top 12 research
countries are Australia, Canada, France, Germany, Israel, Italy, Japan, the Netherlands, New Zealand,
Sweden, Switzerland, and the United Kingdom. See the text for further details. **Parameter is
significantly different from zero at the 1% level for a one-tailed test. * Parameter is significantly different
from zero at the 5% level for a one-tailed test.

41

Table 11
Determinants of the Relative U.S. Corporate Contribution
Dependent Variable: Log (U.S. Corporate Share/(1-U.S. Corporate Share))
(t-Statistics in Parentheses)

Variable or Statistic

Eq. 11.1

Eq. 11.2

Eq. 11.3

Eq. 11.4

Time Period

1983-1999

1983-1999

1983-1999

1983-1999

Fields Included

All 12 Main
Fields
Yes,
Significant
Yes,
Significant

All 12 Main
Fields
Yes,
Significant
Yes,
Significant

10 Fields a

10 Fields a

Yes,
Significant
Yes,
Significant

Yes,
Significant
Yes,
Significant

0.024
(2.7)**
0.070
(6.3)**

0.026
(2.8)**
0.067
(5.9)**

0.003
(0.3)
0.144
(11.3)**
-0.060
(-6.8)**

Fraction of PhDs Placed In U.S.
Industry, Lagged Two Years
Equipment Expenditure/R&D,
Previous Three Years
Top 20 Percent in Field
(1 if yes, 0 if no)
Root MSE

0.461

0.532
(14.3)**
-0.263
(-2.4)*
-0.005
(-0.4)
0.453

0.460

0.010
(1.0)
0.136
(10.2)**
-0.063
(-6.6)**
0.482
(11.5)**
-0.316
(-2.7)**
0.010
(0.8)
0.452

Adjusted R 2

0.69

0.70

0.63

0.64

Number of Observations

8,378

8,103

6,597

6,472

Year Dummies Included
Field Dummies Included

Log (Stock of Federally Funded R & D
divided by papers lagged 2 years)
Private University
(1=yes, 0=No)
Number of Awards b

Notes: Estimation method is Grouped Logit. Sources for the data are the Institute for Scientific
Information, National Science Foundation, National Research Council, and authors’ calculations.
a
Agriculture and Medicine lack data on prizes and awards b Awards include the Fields Medal, MacArthur
Awards, the National Medal of Science, the National Medal of Technology, Fellow of the National
Academy of Science, and the Nobel Prize. See the text for a further discussion. **Parameter is
significantly different from zero at the 1% level for a one-tailed test. * Parameter is significantly different
from zero at the 5% level for a one-tailed test.

42

Table 12
Determinants of Research “Output”
Dependent Variables: Log (Papers), Log (Citations over Five Years)
(t-Statistics in Parentheses)

Log (Papers)

Variable or Statistic

Log (Citations over Five Years)

Eq. 12.1

Eq. 12.2

Eq. 12.3

Eq. 12.4

Eq. 12.5

Eq. 12.6

Time Period

1981-1999

1981-1999

1981-1999

1981-1995

1981-1995

1981-1995

Fields Included

All 12
Main Fields
Yes,
Significant
Yes,
Significant

All 12
Main Fields
Yes,
Significant
Yes,
Significant

All 12
Main Fields
Yes,
Significant
Yes,
Significant

All 12
Main Fields
Yes,
Significant
Yes,
Significant

All 12
Main Fields
Yes,
Significant
Yes,
Significant

All 12
Main Fields
Yes,
Significant
Yes,
Significant

0.457
(89.0)**
-0.085
(-4.8)**

0.450
(87.1)**

0.0.443
(89.3)**
0.019
(1.1)

0.553
(69.6)**
0.312
(10.2)**

0.546
(68.0)**

0.557
(69.6)**
0.264
(8.4)**

Year Dummies Included
Field Dummies Included

Log (Stock of Federally Funded R &D)
Log (Authors per Paper)
Log (University-Field Authors per Paper)

0.286
(9.0)**

Top 110 U.S. University Share per Paper

0.548
(10.8)**

Root MSE

0.497

0.495

-5.973
(-30.1)**
-1.059
(-7.6)**
-.378
(-1.4)
0.453

Adjusted R 2

0.80

0.81

0.80

0.82

0.82

0.82

10,772

10,772

10,772

8,504

8,504

8,504

Foreign Share per Paper
U.S. Corporate Share Per Paper

Number of Observations

0.688

0.687

1.276
(4.0)**
1.237
(5.2)**
0.094
(0.2)
0.686

Notes: Estimation method is OLS. Sources for the data are the Institute for Scientific Information,
National Science Foundation, National Research Council, and authors’ calculations.
b
Awards include the Fields Medal, MacArthur Awards, the National Medal of Science, the National Medal
of Technology, Fellow of the National Academy of Science, and the Nobel Prize. See the text for a further
discussion. **Parameter is significantly different from zero at the 1% level for a one-tailed test. *
Parameter is significantly different from zero at the 5% level for a one-tailed test.

43

