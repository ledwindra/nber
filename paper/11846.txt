NBER WORKING PAPER SERIES

IMPROVING THE PERFORMANCE
OF THE EDUCATION SECTOR:
THE VALUABLE, CHALLENGING, AND LIMITED ROLE
OF RANDOM ASSIGNMENT EVALUATIONS
Richard J. Murnane
Richard R. Nelson
Working Paper 11846
http://www.nber.org/papers/w11846
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2005

We would like to thank Greg Baker for his research assistance, and Patricia Graham and Catherine Snow for
helpful comments on an earlier draft. Richard Murnane’s work on this project was supported by a grant from
the Spencer Foundation. Richard Nelson’s work was partially supported by the Sloan Foundation. The views
expressed herein are those of the author(s) and do not necessarily reflect the views of the National Bureau
of Economic Research.
©2005 by Richard J. Murnane and Richard R. Nelson. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.

Improving the Performance of the Education Sector: The Valuable, Challenging, and Limited
Role of Random Assignment Evaluations
Richard J. Murnane and Richard R. Nelson
NBER Working Paper No. 11846
December 2005
JEL No. I21
ABSTRACT
In an attempt to improve the quality of educational research, the U.S. Department of Education’’s
Institute of Education Sciences has provided funding for 65 randomized controlled trials of
educational interventions. We argue that this research methodology is more effective in providing
guidance to extremely troubled schools about how to make some progress than guidance to schools
trying to move from making some progress to becoming high performance organizations. We also
argue that the conventional view of medical research

discoveries made in specialized laboratories

that are then tested using randomized control trials -- is an inaccurate description of the sources of
advances in medical practice. Moreover, this conventional view of the sources of advances in
medical practice leads to incorrect inferences about how to improve educational research. We
illustrate this argument using evidence from the history of medical research on the treatment of cystic
fibrosis.
Richard J. Murnane
Graduate School of Education
Harvard University
6 Appian Way - Gutman 409
Cambridge, MA 02138
and NBER
richard_murnane@harvard.edu
Richard R. Nelson
Columbia University
rrn2@columbia.edu

INTRODUCTION
In a number of the world’s wealthiest countries, including the United States,
France, and Germany, the effectiveness of public education is a matter of great concern.
International achievement comparisons show that students in these countries do not score
nearly as well on math and science tests as students in other countries, particularly in East
Asia. Evidence that the skills of a country’s labor force are an increasingly important
determinant of the rate of economic growth makes this pattern troubling (Hanushek and
Kimko, 2000). Particularly disturbing in the U.S. is the relatively poor academic
performance of African-American and Latino children, who constitute a growing portion
of the nation’s population.
The challenge of raising academic performance is made especially difficulty by
uncertainty about the most effective strategies for improving education. This issue is
especially acute in the United States, where test scores have been remarkably stable over
the last 40 years despite a more than 200 percent increase in real per pupil expenditure on
public education.1 In this paper we focus particularly on attempts to improve public
education in the United States. However, we believe that the themes are relevant to other
countries.
Concerns about the performance of public education in the United States are not
new; in fact, complaints about performance go back almost to the nineteenth century birth
of public education in this country. What is relatively new, however, are the policy
responses of state governments and more recently the federal government. Historically

1

Expressed in 2001-2 constant dollars, expenditures per pupil were $3,066 in the 1961-62 school year and
$9,553 in the 2001-02 school year. (See Table 166 on page 204 of Snyder et al., 2004.)

2

public education was primarily a local activity in the United States, with state and federal
governments providing modest financial support and some regulation, but leaving most
governance, curriculum, and resource issues to local governments. Beginning in the late
1980s, this situation has changed dramatically. Almost all states have introduced
standards-based reform systems that include specification of the skills and knowledge
that students should master at each grade level, tests to assess student mastery of the
standards, and sanctions for students or for educators when performance is judged low.
Passage in 2001 of the federal No child Left Behind (NCLB) legislation brought the
federal government more centrally into the picture, and significantly added to the
pressure on local schools to improve student performance on state-mandated tests by
specifying a definition of the “adequate yearly progress” schools are expected to make.
The stipulation that adequate progress must be made not only for the student body as a
whole, but for all racial and ethnic groups, represents an attempt to keep the focus on
groups that historically have not fared well in American schools.
While the long-run consequences of standards-based education – or test based
accountability, as the reforms are often called – are yet to be determined, their
introduction has had two striking consequences. First, they have temporarily pushed into
the background questions about what constitutes a good education. At least for
educational leaders responsible for urban schools, the operational definition of a good
education has become one that results in consistent improvement in test scores for all
children.2

2

Of course, there are many who question whether higher scores on high stakes tests mean better prepared
students (e.g. Koretz, 2005), but to date their influence on policy debates has been modest.

3

Second, test-based accountability has increased educators’ search for strategies to
increase test scores. The list of candidates includes more resources, new curricula, more
teacher training, better incentives for teachers and students, and changes in governance
structure. Every one of these options has its advocates. Yet the evidence on the
consequences of adopting any of these options is murky at best. Thus, school and school
district leaders face increasing pressure to improve performance, but little reliable
guidance on how to do so.
It is in this context that the federal government has developed renewed interest in
improving the quality of educational research. The logic is straight-forward. Formal
research and development (R&D) has played an important role in improving performance
in many sectors, including agriculture and medicine. Much written-about success stories
include hybrid corn and the Salk and Sabin polio vaccines. Shouldn’t high quality
research play an equally important role in improving the performance of the education
sector? Educational research, like research in agriculture and public health, has a
significant component of public funding. This brings the federal government directly into
the business of deciding how research should be done.
A role for the federal government in sponsoring educational research and
development dates back to the creation of the U.S. Office of Education in 1867.
However, over the next 90 years, the role was extremely modest (Warren, 1974). It
increased somewhat with the creation of the National Science Foundation in 1950.
However, in that same year a major education bill that had passed the Senate and was
supported by President Truman died in a House committee because of fear that federal
funding would result in federal control of local schools. It took the 1957 launching of

4

Sputnik by the Soviet Union to overcome these obstacles to a significant federal role. In
1958 the Congress passed the National Defense Education Act that provided significant
funds for educational innovations. Over the next 20 years NSF and the U.S. Office of
Education funded a variety of curriculum development and teacher training initiatives
(Dow, 1991). However, the emphasis was much more on developing and disseminating
new curricula than on research evaluating their impacts on student learning.
The need for a systematic educational research program was a primary reason
for the creation of the National Institute of Education. Seen an analogous to the National
Institutes of Health, NIE was announced with great fanfare and the promise of dramatic
increases in funding. Yet before a decade was past, NIE was dead. Factors contributing
to its demise included weak political support for educational research, political errors by
its early leaders,3 the creation of the Department of Education which demoted the agency
from equivalence with the US Office of Education, and, finally, the election in 1980 of a
president who wanted the federal government to be less involved in education. All of
these factors contributed to the sense that NIE had failed to live up to expectations, a
judgment typically made without consideration of what realistic expectations might have
been.
Over the next 25 years, the federal government has continued to provide some
support for educational research and development, albeit with a much lower profile.
Most of the U.S. Department of Education’s modest budget for R&D has gone to
educational research centers and labs, typically connected to schools of education. The
centers, which are awarded in periodic competitions, investigate particular themes seen as
3

For example, an early director chose to attend a meeting in Paris rather than the Senate appropriations
committee hearing on NIE’s budget.

5

important to American education. These include improvements in math, science,
reading, and math instruction, strategies for improving high schools, methods for
increasing adult literacy and learning, research on evaluation, standards, and testing, and
policy areas including the role of the states in promoting educational reform. The
regional labs provide technical assistance to states and school districts.
While advocates for the labs and centers have touted their contributions, to most
legislators they have seemed extremely modest, especially when compared to hybrid corn
and the polio vaccines. One oft-proposed explanation is that educational research has
been insufficiently “scientific.” Of course, this raises the question of what scientific
research in education would look like.
In the fall of 2000 the U.S. Department of Education asked the National Research
Council to form a committee to address this question. The Committee’s 157 page report,
released in 2002, was a carefully worded document, proposing six principles for defining
scientifically based research, and arguing that choice of research methods needs to be
tailored to the question under investigation (Shavelson and Towne, 2002).
While the NRC Committee was deliberating, the Congress passed the No Child
Left Behind Act of 2001. The definition of scientifically based research in NCLB was
more narrow than that described in the yet-to-be-released NRC report. While the
definition is lengthy, the part that the U.S. Department of Education seemed to embrace
was the emphasis on the value of randomized experiments.
On November 5, 2002, President Bush signed into law the Education Sciences
Reform Act, which authorized the creation of a new organization to sponsor educational
research, the Institute of Education Sciences. In its first 28 months of operation, IES

6

provided funding for 65 random assignment evaluations, including studies of reading
comprehension programs, violence prevention programs, after-school programs, teacher
preparation, teacher induction, and teacher professional development programs, school
choice programs, and educational technology initiatives.4 The explicit goal of these
studies is to provide better evidence to state and local educational policymakers about
“what works.”
To facilitate access to such information, the U.S. Department of Education has
provided significant funding for the “What Works Clearinghouse,” an organization with
the following purpose:
On an ongoing basis, the What Works Clearinghouse (WWC) collects, screens,
and identifies studies of the effectiveness of educational interventions (programs,
products, practices, and policies). We review the studies that have the strongest
design, and report on the strengths and weaknesses of those studies against the
WWC Evidence Standards so that you know what the best scientific evidence
has to say. 5

To gain a sense of the challenge involved in providing education practitioners
with sound advice on what works, it is instructive to review the accomplishments of the
What Works Clearinghouse to date. According to its website, as of September 2005,
after three years of work, the What Works Clearinghouse has completed the review of
research in one study area, middle school math curricula. It examined 77 studies
conducted since 1983. Only 10 met its standards of evidence, and only four of those

4

The figure of 65 random assignment evaluations was provided by Dr. Lynn Okagaki, Deputy Director for
Science, IES, in an email message on March 29, 2005. The information on the types of studies funded by
IES was taken from the following U.S. Department of Education website:
http://www.ed.gov/rschstat/eval/resources/studyplans.html (accessed March 24, 2005).
5
DoE’s $18.5 million dollar grant to the What Works Clearinghouse was awarded in August 2002, a few
months prior to the passage of ESRA, the legislation that authorized the creation of the Institute for
Education Sciences.

7

were random assignment evaluations. It concluded that two of the curricula interventions
achieved positive statistically significant benefits compared to alternatives. 6
We note that there are two somewhat different roles that can be played by
educational research and by randomized experiments as a research methodology. First,
research can be directed toward the creation, development, and evaluation of practices
that are significantly different from those broadly used. The purpose here is to advance
the frontiers of educational practice. Second, research can be aimed at assessing the
effectiveness of different educational practices already in use in some settings, with the
aim of defining, and then disseminating, best practice. In the language of introductory
economics, the first objective is to expand the production possibility frontier. The second
is to help educational organizations move closer to the current frontier.
We think it fair to say that during the NIE years the most common view was that
educational research was mainly aimed at the first objective, advancing the frontier of
what is possible to accomplish, as research had indeed done in the fields of agriculture
and medicine. The more recent orientation represents greater emphasis on the second
objective, the identification and dissemination of best practices.
Of course, the distinction between these two objectives for educational research is
not clear-cut. In many cases educational research is concerned with exploring new ways
of applying ideas that have been around for some time and that some teachers have used
in one way or another in their practice. Teaching mathematics through a curriculum that
prompts children to develop an understanding of the properties of number systems is one

6

The information summarized in this paragraph was taken from the following website:
http://www.whatworks.ed.gov/ and from the report, math_topic_report.pdf, accessed at that website on
Sept. 5, 2005.

8

example. Today’s new math curricula have deep roots in the “new math” of the 1960s
(Sarason, 1971).
Another respect in which the distinction between the two objectives of education
research is not clear-cut is that many new educational tools, especially technology-based
tools, were developed in other sectors and are being adapted to education. Examples
include the use of computer-based technology to improve in-service training for teachers
and the analysis of student assessment results. Some of these initiatives may eventually
have a significant impact on educational practice and performance. However, we note
that these technology-based initiatives are not stand-alone new technologies akin to the
polio vaccines. Instead, they are tools that may help groups of teachers to work together
more effectively in improving their practice.
We will explore these differences in greater depth later. Here, we simply want to
state that well designed random assignment evaluations can play a useful role in both in
testing the efficacy of new educational tools and practices and in identifying and
spreading the best of current practices. However, we will argue that it is important to
understand the limits of what greater use of random assignment evaluations can do in
education, or in medicine or agriculture for that matter.
In agriculture, in medicine, and in education, random assignment testing can be a
useful tool for evaluating well specified, well controlled practices. However, in all of
these fields, and certainly in education, there often is much more to effective practice
than simply a set of well specified routines. Evidence that particular instructional
approaches have been effective in some settings with some students experiencing
particular learning problems can be useful to skilled practitioners. However, conducting

9

random assignment evaluations in a manner that provides such nuanced results is
challenging. So is the work of teachers who must identify students with particular
problems and learn by trial and error whether a particular instructional technique will
help a particular student. Teachers’ ability to do this will depend not only on their own
skill, but on the characteristics of the school in which they work, including its priorities,
support for teamwork, and the quality of diagnostic tests routinely used to assess
students’ skills.
While we doubt that any analyst familiar with schools would dispute the argument
that the same tightly-defined practices will not work equally well in all schools, some
would argue that that the challenge is simply to identify the critical interaction effects
between the characteristics of the clients and the setting, on the one hand, and the most
effective practices, on the other hand. We would argue, however, that it is not possible,
ex ante, to identify which practices will be most effective with particular students in
particular settings. Figuring this out is a key part of the work in high performing schools.
Unpacking this argument is the topic of the rest of this paper.

THE ROUTINE, NON-ROUTINE, AND ORGANIZATIONAL ASPECTS OF
EDUCATIONAL PRACTICE
Practice in any area of human activity involves a mix of routines that are
relatively standardized, describable, replicable, imitable, and aspects that do not have
these characteristics. This is so in medical practice as well as in education, as we will
document later in this paper. But in our view, the non-routine aspects of educational
practice are especially important to high performance. Practice in any area of activity

10

involves a mix of actions that are largely at the discretion of individuals, actions that
involve tightly coordinated teamwork, and actions that are more loosely coordinated
under the broad organizational influences that shape how individuals interact. In
education there is typically both a considerable amount of autonomy for individual
teachers, and considerable potential for organizational influences to shape how individual
teachers act and cooperate.
We believe that random assignment testing and the What Works Clearinghouse
are likely to be much more useful for schools that are struggling to achieve a modest level
of performance than for schools that have met this objective and now seek to become
high performing organizations. In making this point, we find it useful to consider two
kinds of schools. No school exactly fits either of these models, but we believe that a great
many schools are close to one or the other.
The first kind of school is struggling. Teachers are not particularly well trained,
and there is significant turnover of both teachers and students. If the high rates of
turnover are taken as given, the key to progress is to identify and implement a set of
relatively routinized practices that work reasonably well on average, even under these
adverse conditions.
The program in such schools generally will involve both a core standard set of
practices, and a set of standardized remedial programs that are invoked for students who
are doing especially poorly. Candidates for the latter include enrollment in supplementary
classes using scripted strategies designed to improve phonemic awareness, use of
computer programs aimed at improving mastery of specific skills, or mandatory summer
school with a specific curriculum. Applying these special treatments to different kinds of

11

problem cases can be recognized as an extension of the basic idea that the key to
organizational improvement is to choose the best standardized “treatments,” and train all
staff to implement these faithfully.
This approach to organizational improvement dates back to the tradition of
scientific management associated with Frederick W. Taylor. When introduced to a
school system that previously has no coherent strategy for improving student
performance, this approach can result in significant achievement gains. Schools that
work largely under this model clearly can benefit greatly from a program of randomized
testing of readily usable educational practices that seeks to identify what works in similar
contexts.
A problem with this mode of educational practice, however, is that what it can
achieve is inherently limited. Children differ significantly and some will have difficulty
learning irrespective of the choices of the core curriculum and instructional techniques,
and the standard remediation programs used to help students that are experiencing
academic difficulties. Educational practice that sticks closely to well established routines
is inherently limited in what it can achieve.
An alternative school model embraces from the outset the reality that some
children will not make steady academic progress irrespective of the district’s choices of
its basic curricula and instructional techniques, and its choices of standardized remedial
programs. Adherents of this model of organizational improvement see the critical
challenge as identifying rapidly those children not making adequate progress under the
standard program, diagnosing their learning difficulties, developing individualized
improvement strategies, and monitoring progress closely. They may also see as part of

12

their work identifying and challenging students who seem to be unusually gifted. More
generally, adherents of this model see their primary challenge as developing an
organization that is effective at providing consistent, high quality instruction, monitoring
continuously the learning of every child, and figuring out a way to help each child who is
experiencing learning problems.
We note that not all schools can operate according to this second mode. To do so
requires a well educated and relatively stable core of teachers, and resources with which
they can work. Many schools and school districts do not meet these conditions. Schools
that are able to operate this way clearly can do better than schools that are forced to
operate largely through routines. These fortunate schools also can learn lessons from
resources like the What Works Clearinghouse since their districts must choose curricula.
Evidence that students in similar districts using particular curricula have done especially
well on particular tests is relevant to their curriculum adoption decisions. Also,
information on instructional techniques that have worked with children experiencing
particular learning difficulties can help skilled teachers as they search for ways to help
particular children.
However, adherents to this second approach to improving schools are particularly
interested in policies that can most effectively improve the skills of teachers and increase
their coordination of instruction, and recognize that this is a more complicated endeavor
than training teachers to follow a scripted curriculum. The results of random assignment
evaluations are likely to be of very limited value in guiding this work.
This is evident from evaluations of a number of initiatives aimed at building the
skills of teachers and changing the ways people in schools interact. The introduction of a

13

new math curriculum in Pittsburgh provides one example. Among the principles
underlying Everyday Math, a K-grade 5 math curriculum developed with NSF support, is
that students should construct algorithms for conducting numerical calculations rather
than memorizing rules. Instead of didactically explaining to students rules to follow,
teachers should model solution strategies and then pose problems and encourage students
to devise and practice problem-solving approaches. Students should work in groups to
develop problem-solving strategies so that they become accustomed to explaining their
reasoning. For most Pittsburgh elementary school teachers, Everyday Math was a quite
significant departure from the way they had learned math and from the methods they
were taught to teach math.
The district invested heavily in teacher training aimed at improving elementary
school teachers understanding of mathematics and their skills in teaching the new
curriculum. The evaluation report indicated that the average performance of students on
mathematics exams aligned with the curriculum did improve between 1996 and 1998.
However, there was significant variation in performance across schools. Students in
schools in which Everyday math was implemented well did much better on the fourthgrade math exam than did students in schools in which the quality of implementation was
poor. A careful reading of the report reveals another important statistic – out of 53
Pittsburgh elementary schools, 8 implemented the new curriculum well, 3 implemented it
poorly, and the quality of implementation in the other 45 elementary schools lay between
these extremes. This was after several years of quite intensive and quite expensive
professional development (Briars and Resnick, 2000). So the lesson for educational
leaders seems to be the awkward combination: Everyday Math is an extremely effective

14

curriculum when it is implemented well, but even with significant investment, it is
difficult to implement well.
The random assignment evaluations of James Comer’s School Development
Program by Thomas Cook and his colleagues provides another example (Cook et al.,
1999; and Cook et al., 2000). The essence of the Comer approach to improving schools
is that adults, teachers, and parents must form new relationships with each other, and
through this process engage students in new ways. The principles underlying the Comer
model make sense. However, they are difficult to implement. Many schools that try to
change the way adults interact with each other fail to do so. As a result, the evaluations
have shown that implementation of the Comer model tends to be weak. Those schools
that do implement the model well experience performance improvements. But given the
difficulty in implementing the principles, the lessons for educational leaders again are not
clear.

RANDOM ASSIGNMENT TESTING OF INCENTIVE SYSTEMS AND BROAD
GOVERNING STRUCTURES
Many economists believe that the key to improving the performance of the
education system is to design, implement, and evaluate reward systems that create strong
incentives for teachers and school administrators to improve students’ skills (Hanushek,
1994 and 2004). We share the view that it is important to experiment with alternative
incentive systems and to rigorously evaluate the results with randomized controlled trials.
We see as especially interesting the incentives a number of districts introduced to attract
skilled teachers to schools serving concentrations of poor children.

15

At the same time, our interpretation of the quite limited available evidence is that
creating strong financial incentives to improve student achievement in the face of limited
knowledge about how to do this is problematic. We base this judgment on evidence
about the consequences of pay-for-performance for educators and greater competition for
public schools.
Pay for performance for individual teachers, -- or merit pay as it is commonly
known – has a long history in American education. Literally thousands of school districts
have tried merit pay at one time or another over the last century.

However, almost all

dropped it within five years. Since there has never been a well designed evaluation of
any merit pay program, it is not clear what the consequences for students and teachers of
any specific plan were. However, a common view is that the demise of the plans
stemmed, at least in part, from the recognition that teachers need to work together to
create an effective school and that merit pay for individual teachers generates an
environment that inhibits cooperation (Murnane and Cohen, 1986).
In recent years a number of school districts and states have introduced schoolbased pay-for-performance plans that provide financial rewards to the faculties of schools
whose students perform well on mandatory tests. The plans vary and to date little is
known about their consequences. However, an evaluation of the North Carolina plan
showed that the criteria for a financial reward were much more difficult to meet in
schools serving large percentages of disadvantaged children (Ladd and Walsh, 2002). As
a result teachers tried to avoid working in these schools. One lesson is the difficulty of
getting the incentives right. A second is the pressing need for knowledge about how to
improve schools serving concentrations of disadvantaged students. The reason is that

16

strong incentives in the face of a lack of knowledge about how to bring about desired
outcomes are likely to elicit dysfunctional responses.
Another approach to improving incentives is to introduce voucher plans that
provide financial support to parents that choose to send their children to non-public
schools. The logic is that greater competition will induce public schools to improve their
performance. In the last decade there have been several random assignment evaluations
of small scale voucher programs aimed at providing greater school options for students
from low income families. While advocates and opponents of vouchers emphasize
different aspects of the evaluation results, most would agree that the results were mixed.7
The main lesson we take away, again, is that strong incentives alone will not result in
markedly improved performance in the face of quite limited knowledge about how to
create effective education for disadvantaged students.
So while we agree that it is important to learn more about the consequences of
alternative incentive regimes, this is not a substitute for research aimed at increasing
knowledge of how to improve production processes in schools. This is especially true
since the clients of schools are children. Even if improved incentives would lead over
time to a winnowing out of ineffective schools, the cost of failures in terms of children’s
futures is enormous.

SIMILARITIES AND DIFFERENCES BETWEEN MEDICINE AND EDUCATION:
TREATING CYSTIC FIBROSIS
7

For example, Rouse (1998) reported that students participating in the Milwaukee voucher experiment did
a little better than the control group in math, but not in reading. Howell et al. report that black children
attending private schools as a result of their participation in the New York City Scholarship program scored

17

In this section we consider the treatment of cystic fibrosis as a way of illuminating
both the similarities and differences between the roles of research in medicine and
education. We draw principally on two sources. One is an article by John Littlewood
(2002) that describes the series of advances in understanding and treatment of cystic
fibrosis over the past sixty years that have greatly increased the expected lifespan and the
quality of life of those that have the disease. The other is an article by Atul Gawande
(2004), which describes the very significant differences in the effectiveness of treatment
of cystic fibrosis at the present time among centers that specialize in the treatment of the
disease, with reflections on the factors that lie behind those differences.
Medical scientists and physicians now know that cystic fibrosis is a genetic
disease. Since 1989 they even know the location on the genome where the problem can
arise. They know that the source of the disease is a mutation that reduces the ability of
cells to manage chloride. The result is that various bodily secretions are thickened, which
makes the body less able to absorb food, and which gradually clogs the lungs. These
infirmities decrease the ability of the body to resist various infections.
Sixty years ago these facts were not known. In fact, only in 1938 was cystic
fibrosis described as a definite clinical entity. While some medical scientists strongly
believed that the disease was inherited in some way, others were not so sure. A prominent
belief was that the disease was related to vitamin A deficiency. It was widely understood
that those with the disease could not absorb food normally, and also were vulnerable to a
variety of infections. The disease was understood as a children’s disease because, until
recently, most people that inherited it died before the age of ten.

better on math and reading exams than did children in the black children in the control group, but this was
not the case for Hispanic children.

18

Since the end of World War II there have been significant advances in treatment,
which increased somewhat the life expectancy of children with the disease. Most of the
advances have been of two sorts. One involved discovery of nutrients that those with the
disease seemed to be able to absorb. The other was the discovery of antibiotics that kept
many of the infections from being fatal. There apparently was growing understanding
that the root problem was inability of the body to deal with chlorides. However,
Littlewood’s discussion of the various advances in treatment does not indicate that this
understanding had much to do with the discovery of better treatments. That discovery
process seems to have been largely experimental.
As new treatments were discovered or invented and tried, a process that up until
the 1950s seems largely to have been the result of the work of individual medical
scientists and doctors, news of how they seemed to be working was spread through the
professional community. Testing seems to have been done largely by individual
physicians, physician groups, or clinics. Until the 1970s, there does not seem to have
been much care taken to design careful statistical analysis, much less conduct random
assignment evaluations. But certain of the new treatments had positive effects that were
quickly visable to the physicians using them, and the word of these spread. Others turned
out not to be effective. In some cases this became apparent relatively quickly. In other
cases, it took some time for initial enthusiasm to wane. Littlewood gives the example of
“mist tent therapy.”
The 1950s and 1960s saw the emergence of important new institutions dedicated
to collaborative research on the causes and treatment of cystic fibrosis. These included
the Cystic Fibrosis Foundation and a collection of clinics that specialized in treatment of

19

the disease. There is little doubt that the new institutions improved the flow of
information. The foundation also promoted evaluations of alternative treatments,
including, during the 1970s, the first double blind nutritional intervention study.
However, the role of systematic evaluation research seems to have been modest relative
to the role played by the judgment of physicians based on their experiences with their
own patients. And the new treatments described by Littlewood seem generally to have
been of the form that skilled physicians could adopt them reasonably effectively, in some
cases after training.
Littlewood judges that by the 1980s understanding of the disease had become
significantly stronger. These advances in understanding led to increasingly reliable
diagnostic techniques. But it is not clear that it had much of an effect on treatments,
where the old experimental process seems to have continued to be the rule, with some
significant improvements being found in nutrition, means of warding off infection, and
physiotherapy.
Littlewood proposes that in the 1990s the new understanding of the genetic basis
of cystic fibrosis had begun to influence strongly the search for better treatment. While he
predicts that gene therapies will become available within ten to fifteen years, as of the
time he wrote his article (2002) nothing much seems to have come from this route
(although a phase 1 clinical trial involving gene therapy using compacted DNA has
recently been completed).8
We would like to highlight several important features of this story which bear on
the current debate regarding how to improve educational practice. A flow of new

8

Information taken from the following website on September 5, 2005:
http://www.cff.org/research/clinical_trials/ongoing_trials/gene_therapies/

20

treatments was coming out of research done primarily by physicians working with their
own patients. Particularly as diagnostic tests of lung function improved, the evidence
that these new treatments were effective was relatively obvious to the physicians treating
the patients. Communication among the professional community was a vital aspect of the
process of improvement. The system of professional publications, conventions, and
personal communications, many supported by the Cystic Fibrosis Foundation, provided
an equivalent to the What Works Clearinghouse.
Thus far the story we have told of progress in treating cystic fibrosis sounds a lot
like the story in the minds of those who are advocating more scientific research, more
systematic evaluation of alternative treatments, and a better way of communicating what
works and what doesn’t in education. One difference is that the rate of introduction of
promising new ways of treating clients has been more rapid in treating cystic fibrosis than
in educating students. But the broad belief that careful evaluation and reliable and timely
dissemination of information bearing on efficacy certainly is supported by the cystic
fibrosis case.
There is another aspect of the cystic fibrosis case, however, that is strongly
reminiscent of our proposition that there is much about good practice in a field that is
very difficult to describe in terms of a set of routines to follow or in terms of a well
defined program that can be evaluated by random assignment testing.
The 2004 article by Atul Gawande on the differences in the efficacy of treatment
of cystic fibrosis in different specialized centers focuses on just this. His basic theme is
that there are very great differences across the hundred or so treatment centers in the
United States in the average length of life of the patients they treat. Moreover, the same

21

centers are the best performing year after year. Little of this variation can be explained
by differences in the client mixes or in the package of treatments different centers use –
they all use the standard treatments that the most current research has found to be the
most effective. Nor can the center to center variation be explained by differences in the
credentials of staff.
This phenomenon of large site to site performance differences is not unique to
treatment for cystic fibrosis. It is a common pattern in medicine and in many other areas
of social services, including counseling of welfare recipients and foster children, and
education. Just as with cystic fibrosis treatment centers, little of the site to site
performance variation in these centers can be explained by differences in the packages of
standardized treatment techniques or credentials of staff. So what is the explanation?
According to Gawande, the best centers for treating cystic fibrosis are especially
effective at monitoring key indicators of patients’ health, especially lung function,
identifying rapidly patients whose lung function declines, training all staff to diagnose the
source of the problem – often stemming from changes in patients’ personal behaviors --,
working with the patient to develop a tailored improvement strategy, and monitoring
progress closely.
Gawande’s explanation is consistent with several points Littlewood makes. First,
more than 1,000 mutations of the gene causing cystic fibrosis have been identified and
patients with different mutations experience different symptoms and need different
treatments. Second, the environment in which patients live affects the treatments they
need. Third, patients’ health depends critically on their behaviors including what they eat
and the diligence with which they carry out daily treatment regimens. Since patients

22

often notice the effects on their health only after an extended period of neglecting their
daily treatments, there is a tendency to skip these treatments. However, doing so results
in loss of lung function that is very difficult to reverse. Consequently, part of the work in
the best treatment centers is to convince patients to carry out their treatments faithfully, to
monitor indicators of health closely, and to attempt to intervene quickly when even a
small decline in lung function is detected.
An implication of Gawande’s explanation is that research aimed at explaining
performance variation across centers needs to focus on why some organizations are more
effective learning organizations than others are. This includes paying attention to
improving patient monitoring systems, building the capacity of staff to identify and
diagnose problem cases, creating incentives for staff to do this critical work, and
developing mechanisms to learn from failures.

MAKING THE RIGHT INFERENCES FROM MEDICAL RESEARCH
As we have noted, much of the policy discussion about the role research could
and should play in the advance of educational practice takes modern medicine as a
model. However, the view of how progress occurs in these fields and the roles research
plays tends to be somewhat oversimplified. We hope that a more accurate understanding
of how advances in medical practice actually occur can help orient the discussion of how
educational research can contribute to expanding the frontier of best practice in
education. In the next section, we attempt to provide perspective by arguing that while
educational research will not approach the power of research in advancing practice in
medicine, we believe it may have at least as much scope and power as research on

23

business practice. We think the similarities and differences there are important to reflect
upon.
Much of the discussion comparing educational research with research in the field
of medicine assumes several things about medical research, explicitly or implicitly, that
are not quite accurate. The first is that research exploring ways to improve practice has
been sharply oriented by strong scientific understanding. The second is that significant
improvements in practice almost always are the result of prior advances in scientific
understanding. The third is that virtually all advances in the efficacy of medical practice
take place through the same series of steps: advances in scientific understanding lead to
more effective research to find better practice, which when achieved is handed down to
the medical practice community.
The history of advances in the treatment of cystic fibrosis, which we presented
earlier, should cast doubt on all of these assumptions. Much of the research that in fact
achieved better practice was guided only very loosely by sophisticated scientific
understanding. Rather, it was exploratory and experimental, guided by broad
understanding of the disease and the needs of patients, with deep scientific understanding
largely in the background. While in many cases the significant advances that were
achieved involved the use of new materials (for example, antibiotics) and equipment
(imaging devices) that had been developed upstream from the fibrosis research endeavor,
and usually for different purposes, it does not appear that advances in deep understanding
of fibrosis have played a particularly major role in enabling advances in practice,
although this may be changing. And there has been and continues to be a considerable
two-way interaction between biomedical scientists doing research concerned with cystic

24

fibrosis and physicians treating patients and conceiving as well as testing new
procedures.
The way advances have occurred in the treatment of cystic fibrosis is not atypical.
The same kind of a story can be told in many disease areas. Among the various medical
technologies, the development of new pharmaceuticals stands out in terms of the extent to
which the bulk of the work leading to advances is done in laboratories. The advance of
surgical practice, on the other hand, proceeds as much in practice as it does in a
laboratory setting (Gelijns, 1992). And even regarding pharmaceuticals, a lot is learned in
practice about side effects, effective doses, the kinds of diseases and patients for which
they are effective. Learning about the efficacy and safety of pharmaceuticals does not
stop with the FDA mandated clinical trials.
We think it also useful to understand that randomized control trials, while an
important part of the processes of evaluation of practices in modern medicine, is only one
part. The cystic fibrosis case shows the important role that physician evaluation plays in
the process, as well as communication among physicians and physician groups. On the
other hand, the new pharmaceuticals that the physicians worked with in their efforts to
deal better with this particular disease had demonstrated safety and efficacy in carefully
controlled clinical trials, if usually on diseases other than cystic fibrosis, before they were
admitted to the set of tools available to physicians. And we have noted the occasional
undertaking of double blind studies to assess the efficacy of treatments that were in
experimental use. The use of randomized trials to test the efficacy of evolving practice in
treatment of cystic fibrosis probably has been less extensive than it has been in the cases
of other human ailments where the population at risk is much greater, for example heart

25

disease, and various forms of cancer. However, even in these areas, it important to
understand the use of random assignment testing as an important part of the system of
evaluation of practices, but far from the whole story. We think the same understanding
ought to prevail regarding the use of RA in education.

EVALUATIONS OF INNOVATIONS IN BUSINESS PRACTICES?
Business practice is an interesting contrast with medical practice. It is extremely
difficult to do effective off-line experimentation that provides much guidance regarding
how a new business practice will work on-line. It is, of course, possible to test the
technical performance of new hardware systems, like a new computer, or an intracompany telephone system. But it is a rule, not an exception, for a company to have
considerable difficulty in integrating the new hardware system into its organization so
that it enhances productivity rather than diminishes it. The newspapers are full these days
with stories of new software systems carefully designed off-line that just don’t work in
practice.
One of the authors of this paper has studied two well known innovations in
business practice: the multi-divisional form of organizing decision making and authority
in multi-product line business (often called the M form) and Quality Circles . In neither
case was much off-line research done prior to the first attempts of business to implement
these new ways of doing things. In the case of the M form, the basic idea certainly has
proved useful, but it has taken a lot of learning and adjustment on the part of companies
who adopted the broad idea to get the system running satisfactorily. And Quality Circles

26

turned out to be largely a fad, whose time now has largely passed (Chandler, 1990; and
Cole and Scott eds., 2000).
While we do not see research on business organizations as a model educational
research should emulate, we do see some useful themes in the work W. Edward Deming
pioneered. The first is the importance of developing and maintaining a variety of finegrained measures of performance, recognizing that no one measure tells the complete
story. This is especially important in education today, given the pressure many schools
face to improve students’ performances on state-mandated tests. Some teachers, as well
as some researchers, question whether improved scores on the high-stakes tests mean that
students have acquired skills that will be important in their lives. Developing a variety of
indicators of success is critical to judging whether the incentives provided by high stakes
testing are constructive.
A second theme is the importance of developing a systematic strategy for
monitoring a variety of dimensions of performance and for analyzing the sources of
lagging performance. This is an important part of the work of the most successful cystic
fibrosis centers. A third theme is that most research that will be valuable to schools
striving to be high performance organizations must be done in close collaboration with
the schools themselves, rather than in off-site R&D centers.

SERP: A NEW MODEL FOR EDUCATION RESEARCH
Partly in response to the failure of the National Institute of Education and its
successor organizations to develop a research program that was both productive and seen
as such by the Congress, the National Research Council established a committee in 1996

27

to consider new designs for educational R&D. In its 1999 report, the committee called
for a large-scale program of research development and evaluation, with most of the work
embedded in school settings (Donovan et al., 2003).
In 2001 the NRC established a second committee with the mandate to outline just
what the new research program should look like. The 2003 report of this committee, The
Strategic Education Research Partnership, called for a new kind of partnership among
research, practitioners, and policy makers. The characteristics of the proposed SERP
program included focusing the research agenda on problems of practice, setting the
research in schools, bringing to bear a variety of sources of knowledge and expertise,
rigorous attention to replication and the systematic building of knowledge, the
development of mechanisms to disseminate knowledge effectively, and the importance of
coordinating work across sites and projects (Donovan et al., 2003). The first SERP field
site is in the Boston Public Schools and focuses on improving literacy instruction in
middle schools.
The SERP design is attractive for several reasons. It specifically embraces the
idea that skilled practitioners are sources of new ideas for improving teaching and
learning. It acknowledges that many innovations appear effective in particular sites at
particular times, but it is difficult to transfer the successes to new sites. By paying close
attention to interactions among innovations and particular characteristics of the original
setting, SERP research projects strive to distill what is needed for successful transfer. By
incorporating partnerships among researchers, practitioners, and policy makers in all
projects, the designers of SERP hope to keep work focused on critical problems of

28

schools, expose practitioners to new insights from scholarly disciplines, and develop
support for dissemination of effective practices.
Given the ambitious nature of the SERP agenda, it will take considerable time to
learn whether it is successful in improving education and in developing and sustaining
the political support required for continued funding. However, a necessary condition for
success is educating policy makers and potential funding organizations to recognize that
that success is much more likely to come in the form of many small ideas for improving
practice than from a blockbuster innovation akin to the Salk vaccine. It will be important
to develop a fine-grained, multi-dimensional set of indicators of instructional quality and
student performance that can be used to document important, but perhaps subtle
improvements in teaching and learning.

THE ROLE OF RANDOMIZED EXPERIMENTS: IMPORTANT, CHALLENGING,
LIMITED
Randomized experiments are likely to be an especially powerful strategy for
increasing knowledge of the consequences of particular educational interventions when
the following conditions hold:9
1. The treatment is well defined. If this is not the case, it is difficult to make
inferences from the evaluation results.
2. The treatment is relatively easy to implement. Poor implementation is a
common explanation for findings of “no effects.”

9

This paragraph draws heavily from Thomas Cook (2002) and from Cook’s paper in this issue.

29

3. The effects of the treatment are evident in a relatively brief period of time.
Selective attrition that undermines the validity of the random assignment
design becomes more severe over time.
4. The effects of the treatment do not vary among a great many subgroups of the
intended population. The greater the number of interaction effects, the larger
must be the experiment to identify these effects.
5. Feedback effects are modest. The presence of significant feedback effects
means that the consequences of “going to scale” with the intervention might
be very different from the consequences of the random assignment evaluation.
There is no shortage of educational interventions that satisfy the criteria above.
Indeed, considerable sums of money currently pay for a wide variety of programs that
could be evaluated with randomized experiments. They include nutrition programs,
after-school programs, and targeted intervention programs designed to address specific
problems for specific well defined groups of students. For this reason we applaud the
resolution of IES to support randomized evaluations of such programs. We believe that
the results, presumably publicized through the What Works Clearinghouse website, can
play an important role in helping schools that are floundering badly to make some
progress.
However, it is particularly challenging to develop random assignment evaluations
that can provide educators with information useful in moving schools from “making
some progress” to becoming high performance organizations that are effective in helping
all students to master demanding state-specified learning standards. The reason is that no
set of prescribed routines will enable all children to learn. There are many reasons

30

individual students have difficulty acquiring specific skills. So part of the challenge is
identifying the difficulties individual lagging students are experiencing and developing a
tailored remediation strategy. As explained above, the results of random assignment
evaluations showing that particular instructional techniques are effective in helping some
students with particular learning difficulties in particular types of settings would be useful
to skilled teachers searching for solutions to particular students’ learning problems.
However, it would take very large scale, carefully designed experiments to provide such
fine-grained results. For that reason we expect that random assignment evaluations will
be of only limited value in helping schools to become high performing organizations.
Also, convincing students of the need to do their part, even when they see no
immediate reason to do so, is as much a part of the work in high performing schools as it
is for physicians in higher performing treatment centers for cystic fibrosis. Creating an
organization that is skilled at doing this work effectively is much more complex than
applying a well defined treatment. It seems unlikely that random assignment evaluations
can be very useful in identifying the conditions necessary for doing this work well. To
go further, some analysts (e.g., Richard Elmore, 2004) make the compelling argument
that adopting a significant number of modular instructional initiatives eventually poses an
obstacle to continued school improvement. The reason is that such “programitis” hinders
development of a coherent and consistent program of instruction and a school-wide
coordinated strategy for monitoring the progress of individual students.
The emphasis on a coherent instructional program and coordinated monitoring
and intervention strategies does not mean that there is no room for new initiatives. For
example, many schools are engaged in promising efforts to examine student assessment

31

results regularly and systematically. The idea is that this work can help school faculty to
pinpoint aspects of their instruction that is not working well for significant numbers of
students.10 While promising, this initiative does not lend itself to random assignment
evaluation for two reasons. First, it is not a modular activity that can make a difference
by itself. It can help schools to improve only if it is part of a coherent school
improvement strategy. Second, the work is not a well defined activity involving
faithfully carrying out a set of prescribed routines. Instead, school faculties need to
figure out a way of doing the work that builds on the skills and resources they have and
that keeps the activity focused on improvement rather than on the limitations of particular
teachers’ instruction. While researchers have offered general guidelines for approaching
this work, they are far from well developed routines.
In conclusion, we want to call attention to a provision of the No Child Left
Behind legislation that will cause problems down the road unless educational research
becomes more effective. This provision is that all schools continue to improve their
performance over time. We believe that the second model of school improvement
described above (developing a coherent instructional program and coordinated
monitoring and intervention strategies) has greater potential for continual improvement
than the first model. However, even schools with the stable faculties needed to embrace
the second model will experience diminishing returns to improvement efforts unless there
are advances in the state of the art. While we do not think that the rate of advance in best
practice in education will ever be close to the rate of advance achieved in some areas of
medicine, including the treatment of cystic fibrosis, we do think that suitably oriented

10

See, for example, Boudett, City, and Murnane (2005).

32

educational research can help to advance the state of the art. Random assignment
evaluations can and should play an important role in educational research, including the
SERP program. However, the role, while important, should be limited. Random
assignment evaluations will be no more effective in closing the gap between the best
performing schools and schools making “some progress” than they have been in closing
the gap between the best performing cystic fibrosis centers and the competent, but less
successful centers.

33

References

Boudett, K.P., E.A. City, and R.J. Murnane, eds, (2005). Data Wise: a step-by-step guide
to using assessment results to improve teaching and learning (Cambridge: Harvard
Education Press).
Briars, D. and L. Resnick (2000). Standards, Assessments—What Else? The Essential
Elements of Standards-Based School Improvement. CSE Technical Report 528 (UCLA,
National Center for Research on Evaluation, Standards, and Student Testing/University
of Pittsburgh, Learning Research and Development Center).

Chandler, A. (1990). Scale and Scope: The Dynamics of Industrial Capitalism.
Cambridge: Harvard Univ. Press).
Cole, R. and W.R. Scott, eds. (2000). The Quality Movement and Organization theory.
Thousand Oaks, Ca.: Sage).
Cook, T. D. (2002). Randomized Experiments In Educational Policy Research: A Critical
Examination Of The Reasons The Educational Evaluation Community Has Offered For
Not Doing Them. Educational Evaluation and Policy Analysis, 24( 3), 175- 199.

Cook, T.D., F. Habib, M. Phillips, R.A. Settersten, S.C. Shagle and S.M. Degirmencioglu
(1999). Comer's School Development Program in Prince George's County: A theorybased evaluation. American Educational Research Journal 36(3): 543-597.

Cook, T.D., H.D. Hunt, and R.F. Murphy (2000). Comer's School Development Program
in Chicago: A theory-based evaluation. American Educational Research Journal 37(2):
535-597.
Donovan, M.S., A.K. Wigdor, and C.E. Snow, eds. (2003). Strategic Education Research
Partnership. Committee on a Strategic Education Research Partnership. (Washington,
DC: The national Academies Press).
Dow, P.B. (1991). Schoolhouse Politics: Lessons from the Sputnik Era (Cambridge, MA.:
Harvard University Press).

Elmore, R.F. (2004). School Reform from the Inside Out: Policy, Practice, and
Performance (Cambridge: Harvard Education Press).
Gawande. A. (2004). The Bell Curve. The New Yorker (Dec. 6,).

34

Gelijns, A. C. (1992). Technology and Health Care in an Era of Limits (Washington,
D.C.: National Academies Press).
Hanushek, E.A. (1994). Making Schools Work: Improving Performance and Controlling
Costs (Washington, D.C.: Brookings).
Hanushek, E.A. (2004). What If There are No Best Practices,” Scottish Journal of
Political Economy 51(May, 2004)2: 156-172.
Hanushek, E.A. and D.D. Kimko (2000). Schooling, Labor Force Quality, and the
Growth of Nations. American Economic Review 90(5): 1184-1208.
Koretz, D. (2005). Alignment, High Stakes, and the Inflation of Test Scores," in (eds., J.
Herman and E. Haertel) Uses and Misuses of Data in Accountability Testing (National
Society for the Study of Education Yearbook).
Ladd, H. F. and R.P. Walsh (2002). Implementing value-added measures of school
effectiveness: getting the incentives right, Economics of Education Review, 21(1): 1-17.
Littlewood, J. (2002. The history of the development of cystic fibrosis care. Available
at: http://www.cysticfibrosismedicine.com (accessed November 23, 2005).
Murnane, R.J. and D.K. Cohen (1986). Merit Pay and the Evaluation Problem: Why
Most Merit Pay Plans Fail and a Few Survive. Harvard Educational Review 56(February
1986)1: pp. 1-17
208.0(5), December 2000, pp. 1184-1208. “
Rouse, C.E. (1998). Private School Vouchers and Student Achievement: An Evaluation
of the Milwaukee Parental Choice Program. Quarterly Journal of Economics 113
(2):553-602.
Sarason, S. (1971). The Culture of the School and the Problem of Change (Boston: Allyn
and Bacon).
Shavelson, R.J. and L. Towne, eds. (2002) Scientific Research in Education (Washington,
National Academy Press)
Snyder,T.D.,Tan,A.G.,and Hoffman,C.M.(2004). Digest of Education Statistics
2003,(NCES 2005 –025).U.S. Department of Education, National Center for Education
Statistics.Washington, DC: Government Printing Office.
Warren, D.R. (2004). To Enforce Education: A History of the Founding Years of the
United States Office of Education (Detroit: Wayne State University Press).

