NBER WORKING PAPER SERIES

DISHONESTY AND SELECTION INTO PUBLIC SERVICE
Rema Hanna
Shing-Yi Wang
Working Paper 19649
http://www.nber.org/papers/w19649

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2013

We thank Gabriel Scheffler, Paula Pedro, Madhumitha Hebbar, Sugat Bajracharya and Priyanka Kanth
for their excellent coordination of the field activities, and extend a special thank you to Manaswini
Rao, who provided invaluable insights into the field logistics. We thank Jonathan Holmes for superb
research assistance. This paper has benefited from comments from or conversations with Santosh Anagol,
Guillaume Frechette, Thomas Fujiwara, Ann Harrison, Sendhil Mullainathan, Sandip Sukhtankar,
Asim Khwadja, Rohini Pande, and Debraj Ray. All errors are our own. This study was funded in part
by Harvard Dean’s Grant and the Russell Sage Foundation. The views expressed herein are those of
the authors and do not necessarily reflect the views of the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w19649.ack
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2013 by Rema Hanna and Shing-Yi Wang. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

Dishonesty and Selection into Public Service
Rema Hanna and Shing-Yi Wang
NBER Working Paper No. 19649
November 2013
JEL No. H1,J2,O1
ABSTRACT
In this paper, we demonstrate that university students who cheat on a simple task in a laboratory setting
are more likely to state a preference for entering public service. Importantly, we also show that cheating
on this task is predictive of corrupt behavior by real government workers, implying that this measure
captures a meaningful propensity towards corruption. Students who demonstrate lower levels of prosocial
preferences in the laboratory games are also more likely to prefer to enter the government, while outcomes
on explicit, two-player games to measure cheating and attitudinal measures of corruption do not systematically
predict job preferences. We find that a screening process that chooses the highest ability applicants
would not alter the average propensity for corruption among the applicant pool. Our findings imply
that differential selection into government may contribute, in part, to corruption. They also emphasize
that screening characteristics other than ability may be useful in reducing corruption, but caution that
more explicit measures may offer little predictive power.

Rema Hanna
Kennedy School of Government
Harvard University
79 JFK Street
Cambridge, MA 02138
and BREAD
and also NBER
Rema_Hanna@hks.harvard.edu
Shing-Yi Wang
The Wharton School
University of Pennsylvania
3620 Locust Walk
Philadelphia, PA 19104
and NBER
was@wharton.upenn.edu

I. INTRODUCTION
Corruption is a pervasive problem in many developing countries, leading to a large theoretical literature in
development economics geared towards understanding when and why it exists. Two explanations are
often raised to explain the variation in observed corruption, both within and across countries. First,
Shleifer and Vishny (1993), Banerjee (1997), Di Tella and Schargrodsky (2004), and Olken and Pande
(2012), among others, have argued that the variation in the benefits and costs of corrupt behaviors may
drive differences across countries, across agencies within a country, or even across the types of tasks for
which public servants are responsible.

A second explanation posits that individuals have different

preferences and beliefs that make corrupt behavior more or less morally costly conditional on the given
incentive structure (Besley, 2005). This latter explanation is particularly relevant in explaining variation
in corruption across individuals that occupy the same position and face the same incentive structures.
A growing empirical literature focuses on the first explanation, documenting how monitoring and
financial incentives affect the public service delivery (see, among others, Olken, 2007; Duflo, Hanna and
Ryan, 2012; Niehaus and Sukhtankar, forthcoming).1

However, much less is known about the second

explanation, about the type of individuals who prefer to enter civil service. For example, Dal Bó, Finan
and Rossi (2013) show that higher wages attract higher quality candidates as measured by IQ and
personality, with no adverse effect on measures of self-reported pro-social preferences. In contrast,
Alatas et al. (2009) play a three-person sequential move game with 60 groups of students and find that
students’ job preferences for public service do not determine their propensity to bribe in the game.
We aim to contribute to the literature on selection into government by asking two key questions:
First, is there evidence that individuals who want to apply for government jobs have a higher propensity
for corruption? To do so, we test whether students who cheat on a simple laboratory task are more likely
to want to enter public service. Importantly, we validate this measure by showing that civil servants who
cheat on task are also more likely to exhibit real corrupt behavior.
1

There is also a related literature that studies how increases in monitoring and information affects elected officials
(e.g. Ferraz and Finan, 2008; Banerjee, Kumar, Pande and Su, 2011) and explores similar questions in the selection
of politicians (e.g. Besley 2005; Besley, Pande and Rao, 2005; Caselli and Morelli, 2004).

2

Second, we ask whether screening applicants for ability will inadvertently choose most corrupt
individuals among the pool of applicants. Motivating our empirical exercise is a simple framework that
examines the decision to apply for a government position given the returns to different characteristics in
the public and private sector.

India—like many countries—employs ability-based civil service

examinations to screen potential candidates. Assuming there are higher wage returns to ability in the
private sector and more opportunity for corruption in the public sector, high-ability individuals who apply
for public service jobs will have higher levels of non-wage benefits (such as corrupt payments or utility
from public service) in the government. Thus, if the government screens primarily on ability, they may
inadvertently select individuals who possess these other characteristics. This effect can disappear if the
degree to which ability reduces the cost of exam preparation outweighs the differences in the wage returns
to ability in the private and public sectors.
We examine these ideas empirically using data from laboratory experiments and surveys with
both university students and government bureaucrats. We conducted a series of laboratory experiments
with 669 students in their final year of college in India. One of the main empirical challenges to
answering these types of questions is devising a meaningful measure of an individual’s propensity for
corruption. While the literature offers several clever ways to measure corruption (see Banerjee, Hanna
and Mullainathan, 2012, for a review), these methods cannot be applied to questions about selection as it
is only possible to collect these measures for those already in government. Thus, it is important to find
meaningful proxies for corrupt behavior once in public service.
We adapt a method from Fischbacher and Follmi-Heusi (2013) to our setting. Fischbacher and
Follmi-Heusi (2013) asked each subject to roll a die once and report the number on the die to receive a
payment that was increasing in the number reported; they then used the deviations from the uniform
distribution to make statements on the cheating propensity of a group. To capture an individual’s
propensity to cheat, we asked each participant to roll a standard die 42 times. While we do not know with
certainty if an individual lied, we can observe how far each individual’s distribution of reports is from the
uniform distribution. Note that this measure is also appealing in that it does not prime the subject on
3

corruption or dishonesty explicitly and allows them to feel comfortable in knowing that no one can say
with certainty that they are cheating.
One important contribution of this paper is that we also administered the dice task to Indian civil
servants for whom we had good measures of actual corruption. Specifically, we conducted the dice task
with 165 government nurses who were part of an experiment conducted by Dhaliwal and Hanna (2013),
in which they collected detailed measures of absenteeism through the use of random checks over a two
year period. Thus, we can test whether the dice task outcome predicts fraudulent absenteeism.
Dishonestly as measured by the dice task is rampant. About 34 percent of the students reported
points that were above the 99th percentile of the theoretical distribution. The government nurses appeared
to cheat less, with only about 9 percent above the 99th percentile. The level of cheating is lower than the
baseline in Fischbacher and Föllmi‐Heusi (2013): they found 62 percent of rolls resulted in the highest
two numbers, while we find that 45 percent of rolls did so for the students and 34 percent for the nurses.
The dice task outcome predicts corrupt behavior by government nurses: nurses who were above
the sample median of dice points were 7.1 percent more likely to be fraudulently absent than those below
it. Students who cheated on the dice game were then 6.3 percent more likely to want a government job.
We find no additional predictive value of the dice task for high-ability students than low ability students
in terms of job preferences, which implies that screening on ability would neither exacerbate or mitigate
the selection problem among government workers in this context.
In addition to the dice task, we explored a series of other experimental and survey measures to
understand what predicts both corruption and job preferences. We find that students who exhibit lower
levels of pro-social behavior (using a measure from Camerer, 2003) more likely to prefer a government
job, even conditional on an individual’s outcome on the dice task.

However, the outcome of the

experimental message game (Gneezy, 2005) does not predict student employment preferences, consistent
with other papers that find that little to no relationship between job preferences and outcomes from games

4

that are very explicit in framing interactions as corrupt (for example, Alatas et al., 2009).2 Similarly,
while some non-explicit personal measures (neuroticism and locus of control) predict student employment
preferences in theoretically sensible ways, we did not find consistent results when looking at the same
attitudinal questions regarding job success and bribery that we asked to both the nurses and students. The
fact that these fairly explicit, attitudinal statements do not predict either corruption by the government
nurses or their dice task score suggests that these measures may be more likely to be gamed and less
likely to be useful for accurately screening employees.
Overall, we find that dishonest individuals—as measured by the dice task—prefer to enter
government service. The fact that the dice task also predicts corrupt behaviors by government workers
once one is entrenched within the bureaucracy implies that dishonesty is a meaningful margin of
selection. These relationships do not appear to be dependent upon ability. These findings are important
because they highlight that the variation in the levels of observed corruption may, in part, be driven by
who selects into government service. While we do not find that choosing the highest ability applicants
would also screen in those who are more corrupt, a policy implication of this work is that the recruitment
process might be improved by increasing the emphasis on characteristics other than ability, as long as the
measures are not too explicit to be gamed.
The remainder of the paper is organized as follows. Section II presents background information
and the conceptual framework that motivates our empirical design.

Section III describes our data

collection process and laboratory tests, while Section IV provides sample statistics and basic correlations
across variables. In Section V, we explore the relationship between the individual characteristics, job
preferences, and corrupt behaviors. Section VI concludes.

II. BACKGROUND AND FRAMEWORK
A. Background

2

See Abbink, Irlenbusch and Renner (2002), Abbink and Schmidt (2006), Barr and Serra (2009) and Cameron et al
(2009) for additional examples of explicit laboratory games of corruption.

5

The setting for this study is India, which employs examinations to screen candidates for government
positions. Civil service exams are common in many countries (e.g. Brazil, China, Tanzania, Mongolia),
as they are seen as a fair and meritocratic process to choose the highest ability individuals (Bagchi 2007).
In India, the Constitution (Article 320) prescribes the Union Public Service Commission (UPSC)
to fill civil services posts with a “written examination with or without a viva voce examination or
interview to supplement them.” According to their 2009-2010 annual report, the UPSC received 15
million applications and conducted 14 examinations for national civil service posts. State-level civil
service jobs are filled by each state’s public service commission, which employ exams for both general
and specialized positions, e.g. engineering, geology and medical services.3 The written exams test
aptitude and knowledge and are often followed by an interview. However, the written component is more
strongly weighted in the applicant’s final score than the interview: in the general UPSC exam, the
interview is worth 13 percent of the total score, while it is only worth 9 percent in the general state exam
of Karnataka, the setting of our project.

B. Conceptual Framework
In this section, we present a simple framework to explore the link between one’s propensity for
corruption, pro-social preferences, and ability with the decision to enter the civil service. This framework
is useful in terms of framing the margins through which selection may occur and because it motivated our
data collection efforts.
Individuals can enter the government or the private sector. Wages in the private sector, f(Ai),
increase with ability, Ai, i.e. f'(Ai)>0 and f(Ai) ≥ 0 for all Ai; utility is assumed to only be a function of
wages.4 To enter the government, individuals take a civil service exam. In contrast to the private sector,
government wages, ki, are independent of ability. This assumption seems reasonable for India and other

3

Each type of exam stipulates a set of qualifications that include a specific level of education; in some cases, a
degree in a specialized field of study and a certain grade threshold is also required.
4
We present a simple one-period model, but the predictions are the same if we consider individuals making a career
choice based on the present discounted value of the future stream of benefits.

6

developing countries, where government wages and promotion are often rigidly determined by tenure and
do not vary with job performance (Bagchi, 2007; Ilaiah, 1995). Utility from a government job, k+g(Pi,
Ci), depends on more than just the stated wage: individuals also gain utility from public service, Pi, and
those with a higher propensity toward cheating (denoted by Ci) can augment their wages through
corruption: ∂g/∂P>0 and ∂g/∂C>0 and g(Pi,Ci) ≥ 0 for all Pi and Ci.5
Assuming no costs to taking the civil service exam, individuals will do so if and only if:
k+g(Pi,Ci)>f(Ai).
Under this set of assumptions, high ability individuals will only find government jobs attractive enough to
apply for if the utility return from working in a pro-social position and from engaging in corruption is
higher than the utility return from their ability in the private market. Thus, the model predicts that within
the pool of high-ability applicants for government jobs, we would expect relatively higher levels of prosocial behavior, propensity for corruption, or both. If this prediction holds true, an additional testable
prediction follows: if the screening mechanism for government jobs primarily chooses applicants based
on ability (e.g. the ability tests that comprise a majority of civil service exams), one may inadvertently
hire individuals with both higher pro-social behaviors, higher propensity for corruption, or both, with the
relative mix of characteristics dependent upon the relative utility returns of each characteristic.
Thus far, we have assumed that ability only matters in determining the wage returns in the private
sector.

However, many developing countries use civil services exams to screen for high-ability

candidates and taking these exams is costly: individuals in India spend substantial amounts of time, even
years studying, and considerable amounts of money to pay for preparation assistance.6 Assume that highability individuals need to exert less effort to pass the exam: the cost of taking the exam, e(Ai), depends
on ability such that e'(Ai)<0 and e(Ai) ≥ 0. Individuals will take the exam if and only if:
k+g(Pi,Ci)-e(Ai)>f(Ai).

5

For simplicity of notation, we assume that there are no returns to cheating behavior in the private sector. However,
the implications of the model hold as long as the non-wage utility gains that are associated with corrupt behavior are
greater in the government sector than in the private sector.
6
For example, see Mohanty (2013).

7

Under these assumptions, the earlier prediction that among those that will apply for a government job,
higher Ai corresponds with higher levels of Pi or Ci now holds only if f'(Ai)>-e'(Ai), i.e. if the wage
returns to ability are greater than the degree to which ability helps in the exam process. If f'(Ai)=-e'(Ai),
then among those who prefer a government job, there will be no correlation between ability and these
other characteristics, pro-social preference and propensity for corruption. Finally, if f'(Ai)<-e'(Ai), we
would expect that high-ability candidates would have relatively lower Pi and Ci.
This relationship has significant policy implications: it implies that the propensity for corruption
of those who want to enter public service will be determined in part by the relative returns of ability in the
private sector versus taking the civil service exams. Moreover, depending on this relationship, hiring
exams that only screen on ability—within the given candidate pool—may ultimately exacerbate or
mitigate this propensity for corruption. The impact on corruption among civil servants depends on the
sign and the degree of correlation between ability and propensity for corruption.

III. EXPERIMENTAL PROCEDURES AND DATA COLLECTION
We conducted a series of surveys and lab experiments with both college students and government nurses
in Karnataka, India, to measure the propensity for corruption, pro-social preferences, and ability.

A. Student Sample
As we want to examine individual behaviors prior to entering the civil service, our sample is drawn from
university students. We recruited seniors from seven large, mid-tier universities in the city of Bangalore
in Karnataka, India. We obtained permission from each university to recruit subjects from classrooms and
from recruitment booths on campus. We chose to recruit from classes comprised of seniors in majors
where both government and private sector jobs were viable options.7 We informed students that the

7

We avoided majors in which job preferences were already strongly defined. To identify target majors, we
conducted polling in classrooms prior to the recruitment stage to ask students whether they preferred government or
private sector jobs. In the end, about 80 percent of the survey respondents were in the Commerce Stream, while the
remaining were in Science. We did not survey Arts students, as few entered government service.

8

sessions would explore the “cognitive skills, aspirations, background, and personality characteristics of
graduating students,” that the sessions would take about one hour and that they would be paid INR 20
(about USD 0.45) upon arrival to the session and up to an additional INR 392 (USD 8.71) depending on
the session tasks; the average payment was INR 216 (USD 4.80).8
In August and September 2012, 669 students participated in 28 sessions (Appendix Table 1).9
The sessions were located in rooms at the university or in restaurants and other event spaces close by, and
at any given time, there were up to four separate rooms in use for each session. We provided the subjects
with cardboard folders to ensure privacy as they filled out the survey forms. Since friends often attended
the sessions together, we tried to separate them into different survey rooms within the sessions.
The survey questions covered demographics, work experience and post-graduation plans,
preferences and expectations. We asked questions covering several psychology measures including locus
of control (Rotter 1966) and the Big-Five personality measures (John, Donahue and Kentle, 1991; John,
Naumann and Soto, 2008). We included some commonly used survey questions to assess attitudes about
cheating and corruption, such as what percent of individuals in the classroom would cheat during an exam
and whether they thought that most businesses paid bribes. We also inquired about actual corrupt
behavior, such as hiring an illegal agent who facilitates bribes to obtain a government service. Finally, we
collected extensive contact information for the students, their relatives, and their friends in order to be
able to track them in several years in the future to ascertain their ultimate job outcomes.10
The crux of the surveys was a series of laboratory experiments designed to measure honesty, prosocial behaviors, and ability. Each experimental measure is outlined below:

8

We designed the financial incentives to be in a range that would appeal to students to participate, but not too large
that it would be coercive. For comparison, the price of a ticket to a high end movie theater is about INR 400.
9
These schools comprise about 3,215 students (Appendix Table 1). We designed the sessions to be close to the
university and to not conflict with class times. In total, 1,081 students signed up to attend a session, which implies
that 61 percent of those who signed up attended one. As Appendix Table 2 shows, the sessions ranged from 6 to 39
students; the final sessions tended to have lower attendance due to university protests and a city-wide transit strike.
10
To apply for the civil service exams, applicants must be between the ages of 21 to 30 (the age requirement is
relaxed somewhat for those in minority categories); the average age of entrants to the national civil service is about
27 (for example, see http://www.indianexpress.com/news/engineers-and-doctors-still-rule-civil-servicesexam/1003432/).

9

The Dice Task: To obtain an individual measure of dishonesty, we asked each participant to privately roll
a six-sided die 42 times and to record the outcome of the die after each roll. For each value of 1 reported,
we paid the participants INR 0.5; the payment increased by INR 0.5 for each higher value on the die, up
to INR 3 for each reported roll of 6. Thus, the minimum possible payment is INR 21 and it occurs if the
participant reports rolling all 1’s, while the maximum payment (for all 6’s) is INR 126. Appendix Figure
1 provides the task directions.
We ensured privacy: in addition to the cardboard folders, we instructed the survey team to either
exit or be on the opposite side of the room during this task. Thus, participants could be assured that it
would impossible for us to know for certain if they lied. However, we can determine how far the
distribution of each individual’s outcomes is from the uniform distribution.11

Thus, even though we

cannot say with certainty who cheated, this provides a measure that is strongly correlated with doing so.
This task is adapted from Fischbacher and Follmi-Heusi (2013). One key difference is that they
asked participants to roll the dice only once. This allows them to make statements about the group of
individuals in each session they conduct, but not about each individual in the group. Their methodology is
well suited to the laboratory context, where one can induce variation in treatments at the group level and
the outcomes in lab behavior can be observed at the aggregate level. The innovation in our approach is
important in that it allows us to examine the empirical relationship between an individual’s revealed
levels of dishonesty with real world outcomes and choices.

The Message Game: Another experimental approach to examining lying behavior is to implement a
cheap talk sender-receiver game where individuals with private information have the choice of whether to
send an honest or dishonest message to another player. We implement a game that was developed by
Gneezy (2005) and that has also been used, for example, by Sutter (2009) and Hurkens and Kartik (2009).

11

To detect non-random shifts in the value of the dice rolls per individual, we conducted power calculations using
the effect sizes observed in Fischbacher and Föllmi‐Heusi (2013), which ranged from 0.7 to 0.15. Using a
conservative effect size of 0.7, along with a power level of 0.8 and an alpha equal to 0.05, the one-sided on-sample
required sample size was 37. We rounded up to 42 as it was evenly divisible by 6.

10

We present the sender in the game with two possible pay-offs associated with a binary choice made by the
receiver (see Appendix Figure 2). The sender then has a choice of two messages to send:
Message A: “Option A will earn you more money than option B.”
Message B: “Option B will earn you more money than option A.”
The sender is told that the receiver will not see the actual pay-offs associated with each choice, but will
only see their message. The sender can choose either to send an honest message that indicates the choice
that will give the receiver more money and the sender less, or a dishonest message that indicates the
opposite. We implement three rounds with variation in the pay-offs as shown in Appendix Table 3. We
stressed that neither party will ever know who they were paired with, although they did know that it was
someone from within their session and that our enumerators saw their choices.
We are interested in whether the sender chooses to lie during the game. Every participant plays
the role of the sender first. This is a slight departure from previous studies where half of the participants
are senders and the rest are receivers. Our method ensures that we have outcome data for all subjects,
thereby increasing our ability to correlate the key outcome with individual preferences. Later in the
session, each participant also plays the role of the receiver, mainly to ensure that the payoffs are realistic.

The Pro-Social Preferences Game: We used a standard dictator game to measure willingness to give to
others (see Camerer, 2003, for an overview). We instructed participants that they can divide INR 50
between themselves and a charity of their choice from among seven well-known, respected charities
(UNICEF, Child Rights and You, Being Human, Help Age INDIA, CARE India, Red Cross and Save the
Children).12 For each rupee that they donated rather than kept for themselves, the amount given to the
charity was doubled. The appropriate charitable donations were made.

12

In the classic version of this type of dictator game, player 1 chooses how much of an endowment to keep for
themselves or to share with other participants in the session, and the outcome is determined only by player 1’s
actions. The subsequent adaptation to giving the money to a charity rather than other individuals is also fairly
common in the literature (e.g. Eckel and Grossman, 1996; Carpenter, Connolly and Myers, 2008).

11

Ability Measures: We employed two incentivized ability tests.

First, we administered a digit span

memory test in which participants listened to a series of digits and, after ten seconds, were asked to write
down the number. We conducted five rounds, where the first round contained 5 digits and each
subsequent round increased the number of digits by 2. The students were paid INR 2 for each correct
round.

Second, we adapted a test of cognitive ability from Ariely, Gneezy, Loewenstein and Mazar

(2009). We gave participants a set of matrices, with 12 numbers displayed in each matrix (Appendix
Figure 3). They were asked to identify the two numbers in each matrix that add to 10. Participants were
given 12 matrices to solve within 3 minutes, and received INR 2 for each correct answer.

B. Nurse Sample
A question that always arises is whether behavior in the lab predicts actual behavior.

To address this

question, we examined whether the dice predicts corrupt behavior. We administered the dice task to
government nurses within the context of a broader experiment that is described in detail in Dhaliwal and
Hanna (2013), where we had real measures of corruption. The experiment spanned 333 primary health
centers (PHC) across five districts in Karnataka and focused on understanding whether increased
attendance monitoring of health care workers through the use of a biometric device improved access to
medical services.
We focus on absenteeism: as Banerjee, Hanna, and Mullainathan (2012) point out, bureaucratic
absenteeism is an attractive form of corruption to study because one can measure, by cross-checking,
whether the bureaucrat is fraudulently collecting a paycheck for a day not worked. Dhaliwal and Hanna
(2013) conducted this cross-checking: they implemented 9 rounds (two baseline, 7 post-intervention) of
independent random checks of the PHC staff between July 2010 and November 2012.13 The random
checks proceeded as follows: the enumerator conducts a surprise visit to the PHC and records the staff
13

PHCs within the same sub-district were generally surveyed at the same time; we randomly assigned the time of
day that PHCs were checked so that no PHC was always checked at the same time of day. Note that although they
were infrequent checks, there was a concern that the monitoring associated with the random checks could affect
attendance as well; therefore, 50 percent of sample was randomly selected to be visited in every other follow-up
survey round. Dhaliwal and Hanna (2013) show that the monitoring frequency does not impact the absence rate.

12

attendance at the moment of arrival; if the PHC was closed on arrival, everyone is considered absent.
Individuals who were transferred or resigned were subsequently dropped from the sample from then on.
Between November 2012 and January 2012, a series of surveys with the health center staff were
conducted to assess their beliefs on the biometric devices. For the staff nurses, we obtained permission
from the government to add the dice task and the memory test to this survey. The sample consisted of
nurses in the 185 PHCs where the position was not vacant. Unlike the random checks, we made
appointments to ensure that the nurses would be present and conducted revisits when possible if the nurse
was absent. We interviewed staff nurses at 165 PHCs; Appendix Table 4, Column 1, shows that there is
no significant difference between the attendance rates of nurses at PHCs that we were able to interview
and those that we were unable to do so.14
We aimed to design the nurses’ tasks to be comparable to those of the students, but there were
several differences. Most importantly, we could not pay government workers in cash. Instead, we
obtained permission from the government to pay them in candy (Appendix Figure 4). One piece of candy
is worth about Rs 1, and therefore, we offered double the amount for the nurses for the tasks than for the
students, but in candy rather than dollars. In addition, the memory test differed from the student test in
three ways. First, while the students’ test started with a 5 digit sequence, piloting with non-sample nurses
informed us that this was already quite difficult. Therefore, we started with a 3 digit sequence for the
nurses. Second, we gave the students five rounds of number sequences, but increased it to nine rounds for
the nurses in order to increase the measured variation in ability. Third, because the students were
surveyed as a group, they were asked all five rounds; for the nurses, the test ended as soon as they
incorrectly remembered a sequence.

14

Some larger PHCs had multiple staff nurses; however, for budgetary reasons, we only interviewed one nurse per
PHC. We tried to interview the nurses who were typically staffed during the day to correspond to the time when
Dhaliwal and Hanna (2013) conducted the random checks. In many cases, the doctor gave us permission as to which
nurse we could talk to at his or her PHC. In Appendix Table 4, Column 2, we regress the attendance rate on an
indicator variable for being surveyed, PHC fixed effects, and the survey controls. We find no difference in the
attendance rates between those nurses that were interviewed with the other nurses within their PHC.

13

Since we surveyed nurses at work, we had to be cognizant of both time and logistical factors.
Thus, we could not administer all of the experimental tasks that we gave to the students. For example, the
message game requires two players, is more complicated to explain than the dice task and takes longer to
play; thus, we deemed it infeasible to conduct in this setting. Piloting informed us that the nurses found
the matrices test too difficult and thus we did not administer it.
Finally, the survey also included questions on the nurses’ basic demographic characteristics and
on their beliefs on statements such as “It is possible to operate a business in India without bribing” and
“Promotions should be based primarily on job performance rather than seniority.”

IV. EXPERIMENTAL OUTCOMES AND CORRELATIONS ACROSS MEASURES
In this section, we present summary statistics from the laboratory tasks. Relatively few of these types of
tests have been conducted in developing countries and, therefore, it is also interesting to compare the
findings from our setting to those from more developed nations. In addition, as our simple conceptual
framework implies, the characteristics of the selected individuals depends on the correlations between the
characteristic defined in the screening criterion (i.e. ability) and these other characteristics. Thus, we also
explore the correlations between the various measures.

A. Laboratory Test Outcomes
Tables 1A and 1B provide descriptive statistics for the experimental measures, as well as key outcome
variables.15 In Figures 1 and 2, we graph the distribution of the experimental outcomes.
In the dice game, which measured one’s propensity for corruption, the students reported a mean
of 168 points in the dice task (Table 1A). As shown in Panel A of Figure 1, cheating was rampant among
the students: the median points reported by students was 164, which corresponds to the 95 percentile of

15

In Appendix Table 5, we provide descriptive statistics on the demographic characteristics of both the students and
nurses. Forty percent of the students are male, about half come from a minority category, and 81 percent are
commerce majors (Panel A). Ninety-five percent of the nurses are female, they had been in the government for on
average 8.5 years, and they had been at their current PHC for on average 4.6 years (Panel B).

14

the probability density function of the theoretical distribution (given by the red line in figure); in fact,
34.2 percent of students reported points that were at or above the 99th percentile of the theoretical
distribution (given by the dotted line).16

The nurses also cheated, but to a much lesser extent than the

students: their median number of points was 152, and 9.4 percent of them reported points above the 99th
percentile of the theoretical distribution (Figure 1, Panel B).17
As many (e.g. Levitt and List, 2007) have pointed out, the differences in design features that need
to be made when testing students in a laboratory setting versus testing individuals in real-world settings
may result in different outcomes. These features may, in part, explain why the nurses cheated less than
the students in the dice task. First, the incentives were in candy rather than money since we could not
give the government workers cash. If the nurses valued the candy less than the students valued the cash,
their incentive to cheat would have been weaker. Second, while we held the student sessions at the
university or in event spaces nearby, we interviewed the nurses at work.18 Although we ensured privacy,
the location may have led the nurses to feel less comfortable cheating than the students. However, the
nurses did feel comfortable answering non-experimental questions relating to bribes (Table 1B).
The high level of cheating that we observe in this task is also observed in a study of Swiss
students by Fischbacher and Föllmi-Heusi (2013). In their baseline experiment, they find that students
reported that 35 percent of rolls resulted in the highest number on the die and 62 percent in the highest
two.19 In comparison, as Appendix Figure 5 shows, almost 45 percent of rolls resulted in the highest two
numbers for students and 34 percent for nurses in India.
In the pro-social preferences game, students chose to keep a greater percentage of the funds rather
than donate to charity. On average, students chose to keep Rs 29.3, or 59 percent of their endowment
16

The theoretical median is 147 points and the theoretical 99th percentile is 173 points.
This finding has also been observed in other contexts. For example, playing a three-person, sequential-move
game, Alatas, et al (2009) find that public servants have a lower tolerance for corruption than students in Indonesia.
18
Armantier and Boly (2008) conduct a lab experiment on corruption with students in Canada and one with
individuals recruited for the same task in Burkina Faso who did not know it was an experiment. In the control
setting, the students were more likely to cheat, but the rate was similar when both were offered a large enough bribe.
This may differ from our setting in that the individuals were recruited to work on a one-time task, whereas the
government nurses may be more concerned about being labeled a cheater in their long-term workplace.
19
The theoretical distribution is 16.7 percent for the highest roll and 33.4 for the highest two.
17

15

(Table 1A); because their donation to the charities would be doubled, the students’ choice of giving up Rs
20.7 implies that the charity received about Rs 41.4. Only 13 percent of the students kept less than onefifth of the endowment (Figure 2, Panel A).
In existing literature, the average donation rate has varied across different contexts and by the
game set-up: for example, studying 69 medical and nursing students in Tanzania, Kolstad and Lindkvist
(2013) found on average donation of 1153 TSH (or about 12 percent of their endowment). Eckel and
Grossman (1996) finds that the donation rate in the United States increases from 38 percent to 73 percent
when the transfer goes to a legitimate charity rather than to an anonymous individual in the room. Benz
and Meier (2008) show that almost 80 percent of students donate when the funds are designated to the
university social funds and about 65 percent donate to a general charity. Note that Benz and Meier (2008)
and Cárdenas, Chong and Ñopo (2013) show that this type of measure is highly correlated with real
charitable behavior, suggesting that it provides a meaningful proxy for pro-social preferences.
In the message game, there was considerable variation in the number of lies (Figure 2, Panel B).
On average, the senders lied 1.71 times out of 3, with about 19 percent never lying and 30 percent lying
all three times.20 These numbers are similar to previous studies: studying 450 students in Israel, Gneezy
(2005) finds between 17 to 52 percent of senders lie, with the variation determined by the financial gains
associated with lying. Hurkens and Kartik (2009) find that between 38 to 47 percent of their sample in
Spain lies, and 35 to 59 percent of the sample lie in a study in Germany by Sutter (2009).
In terms of the ability measures, students scored, on average, 1.68 out of 5 on the memory test
and 2.25 out of 12 in the matrices test, while the nurses scored 2.66 out of 9 on the memory test (see
Appendix Figure 6 for the distributions). These measures predict a real-world proxy for ability: students
who are above median ability on the average of both tests have a significantly higher college GPA
(Appendix Table 6, Column 1). Moreover, the matrices and memory tests are highly correlated with one
another (Columns 2 and 3).

20

Following the choice of messages to send, we ask the students whether they expect the receivers to believe them.
The vast majority, 82.2 percent, expect to be believed. Gneezy (2005) observes a similar percentage.

16

B. Correlations Between the Dice Task, Ability and Other Characteristics
In Table 2, we explore what factors are correlated with the dice task and ability. One of the contributions
of this paper is to apply the dice task to obtain an individual measure of dishonesty, and therefore, these
correlations provide an understanding of what this measure captures.
The first two columns of Table 2 show the results for the students, while the second two show
them for the nurses. In Columns 1 and 3, the dependent variable is dice points and the regressions are
estimated by OLS; in Columns 2 and 4, it is an indicator for above-median ability and the coefficients
presented are the probit marginal effects evaluated at the sample mean. The student regressions include
enumerator fixed effects and are clustered by session, while the nurse regressions include survey and
experimental fixed effects and are clustered by nurse.
We do not observe a relationship between dice points and ability for either the student or nurse
samples (Columns 1 – 4). As shown in Column 1, students who keep a larger share of the funds in the
pro-social game tend to be more likely to cheat in the dice task (higher score), while always lying in the
message game is also somewhat correlated with cheating on the dice task (p-value = 0.15). However,
neither of these measures appears to be strongly related to ability (Column 2).
We also explore the relationships between personality measures, survey questions designed to
measure dishonesty, and demographic characteristics with both the dice task outcome and ability. Starting
with the students, we examined three personality measures: conscientiousness captures self-discipline and
achievement orientation, agreeableness is a tendency for compassion and cooperation, and neuroticism
refers to emotional instability.21 Agreeableness and neuroticism have a negative and significant
relationship with dice points. This is consistent with the findings in the psychology literature (Berry et al,
2007; Salgado, 2002; Ragatz and Fremouw, 2010) suggesting that agreeableness and neuroticism are
negatively correlated with deviant behavior (e.g. drug and alcohol use, white collar crime, theft),
21

In Appendix Table 7, we replicate Table 2, but we exclude individuals who did not answer all questions that are
used to define the personality measures. While this results in a smaller sample size (and thus less statistical
precision), the sign of the predictions remains the same.

17

absenteeism and unsafe behavior (e.g. accidents, injuries). Neither survey measure designed to get at the
propensity for corrupt behaviors (e.g. agent use or perception of cheating) are correlated with dice points,
perhaps implying that those who cheat in the dice task also lie when asked about corrupt behaviors.
Turning to the nurses, longer tenure in government is associated with a higher dice score and
lower ability. However, those that have been at their current PHC longer tend to have lower dice points,
even conditional on their total years of government service; this is consistent with the hypothesis that
corrupt individual are more successful at moving to achieve better postings (Wade, 1982), or that those
who are more honest are more likely to be retained at a given hospital. Finally, we explore the survey
measures of corruption: we posed four statements relating to corruption and asked whether participants
agreed or disagreed with the statements.22 We took the z-score of each measure and averaged them to
create an index. We observe no correlation between the index and either dice points or ability.

V. PREDICTIONS FOR PREFERENCES AND CORRUPTION OUTCOMES
A. Do Lab Measures of Dishonesty Predict Selection into Government and Real Corruption Outcomes?
We begin by testing whether there is a relationship between honesty, as measured by the dice task, and
the real world outcomes: student preferences for government jobs and nurse absenteeism. Table 3A
displays the marginal effects from the probit relationship between the individuals’ total points in the dice
task and the main outcomes of interest.23 In Columns 1 and 2, the sample refers to the students and the
outcome is an indicator variable for whether they expressed a preference for a government job. For these
regressions, we include indicators for gender and caste, a cubic in age, enumerator fixed effects and
cluster by session.24 In Columns 3 and 4, the sample refers to the nurses and the dependent variable is an
indicator for whether the nurse was present during the random check; we include the survey and
22

The statements are “Success is determined more by ‘who you know’ than by ‘what you know’,” “most businesses
use bribes to get government contracts,” “Promotions should be based primarily on job performance rather than
seniority” and “it is possible to operate a business in India without bribing.”
23
Appendix Tables 8A and 8B report the estimates using OLS. The conclusions are identical.
24
Appendix Table 9, Panel A, shows that the conclusions are the same for the students if we omit the caste, gender
and age controls and the enumerator fixed effects, while the remaining panel shows similar results when we separate
ability into its component variables.

18

experimental parameters (treatment status, treatment status interacted with post, survey found, time of
day, month and district fixed effects), gender, a cubic in age and in tenure and cluster by nurse.25
Students who scored higher on the dice task (i.e. are more dishonest in this task) prefer
government jobs. A one standard deviation increase in dice points reported corresponds to a 4.2 percent
increase in the probability of preferring a government job (Column 1). This is significant at the 1 percent
level. In Column 2, we also examine a binary variable of whether the total points were above the sample
median, which corresponds to the 95 percentile of the theoretical distribution. Those with total points
above the median are 6.3 percent more likely to want a government job than those below the median
(significant at the 10 percent level). Overall, the results underscore the idea that corruption may be
exacerbated by the types of individuals who want to enter into public service.
Next, we test whether one’s performance on the dice task predicts corrupt practices of civil
servants. The government nurses who reported points above the sample median were 7.5 percent more
likely to be fraudulently absent from work than those who scored below (Column 4).

As shown in

Column 3, dice points are negatively correlated with attendance. A standard deviation increase in the
score on the dice task decreases attendance by 3 percent and this relationship is significant at the 10
percent level.

As a placebo check, we also estimated the model where the government doctor’s

attendance is the outcome measure (Appendix Table 11). A nurse’s score on the dice task is uncorrelated
with his or her corresponding doctor’s attendance rate, with a p-value of 0.91 for dice points and a p-value
of 0.875 for the indicator variable for above-median points. Thus, it appears that dishonesty as measured
by the dice game predicts the real-world corrupt behaviors of civil servants. This form of corruption has a
real cost, as Dhaliwal and Hanna (2013) show, where experimentally increasing nurse attendance has a
real and positive impact on the birth weights of babies.
As we discussed in Section III, there may be cases where within the pool of high-ability
applicants for government jobs, we might expect greater propensity for corruption. Therefore, in Table

25

When we omit the demographic characteristics, the survey design and experimental fixed effects for the nurses,
the coefficient on the dice indicator variable is no longer significant at conventional levels (Appendix Table 10).

19

3B, we first test whether dishonesty is still predictive of job choice conditional on ability (Panel A) and
then test whether we observe higher levels of cheating among high-ability individuals who prefer a
government job (Panel B). In addition to job choice, we also test whether the dice measure differentially
predicts fraudulent absenteeism of government workers by ability. To measure ability, we construct a
variable that equals one if the individual scores above median on the memory test for the nurses and
above median on the average of the memory and the matrices tests for the students.
We do not observe a significant relationship between ability, dishonesty, and the real-world
outcomes. The coefficients on the dice outcomes are virtually unchanged when controlling for ability for
both samples, and the ability measures themselves are not significantly correlated with either job
preferences or absenteeism (Panel A). In the student sample, the coefficients on the interaction are not
significantly different from zero (Panel B), which implies that the relative wage returns to ability in the
private sector may be offset by the way relative returns to ability in the public sector. The nurse sample
tells a consistent story: while nurses that are more dishonest in the dice task are also more likely to be
absent from work, this relationship does not vary based their ability (Columns 3 and 4 of Panel B).
We next explore whether the outcomes from the pro-social preferences game and the message
game are correlated with whether students prefer civil service jobs in Table 4A.26 As our framework
discusses, there is the potential for either the utility from engaging in pro-social behavior or the returns to
corruption to matter in determining job preferences. It is thus an empirical question as to which
characteristic dominates among those interested in public service. The estimates are marginal effects
from the probit estimation, include facilitator fixed effects, and are clustered at the session level.27 As
Column 1 in Panel A shows, a one standard deviation increase in the amount that individuals keep for
themselves, rather than donate to charity, corresponds with a 4 percent increase in the likelihood of
26

In Appendix Table 12, we also explore the relationship between the experimental measures and the expected
wages of the students for their first job. Those who report high points on the dice task have a higher reported
expected wage (Column 1), even conditional on their pro-social preferences and lying three times in the message
game (Column 4). The amount kept in the pro-social preferences game and lying in the message game do not
significantly predict one’s stated expected wage (Columns 2 and 3).
27
Appendix Tables 13A and B show that the results of Table 4A and B are unchanged when using OLS. Appendix
Table 14 provides the estimates from Table 4A with varying sets of controls, which do not change the conclusions.

20

preferring a government job (significant at 5 percent level). Thus, the students with higher demonstrated
levels of pro-social preferences prefer private sector jobs over government ones.
In contrast, lying consistently during the message game appears uncorrelated with job preferences
(Column 2). One possible reason for the difference from the dice task findings is that the two measures
reflect different consequences: the students are stealing from the experimenters in the dice task but
explicitly stealing from other students in the message game. A second possibility is that the outcomes are
more public in the message game, with enumerators will observing whether a student lied. In contrast,
there is no way to identify with certainty if someone lied in the dice task. A third possibility is that the
students did not fully understand how to play the message game, given that it is more complex than the
dice task. However, this seems unlikely: we observe students engaging in behavior that increases their
payments in the message game, and 80 percent of the students lie at least once.
In Column 3, we include all three experimental measures in one regression; the measures are
jointly significant (p-value of 0.001). The dice measure and the pro-social preferences remain significant
and the magnitudes of the coefficients do not change much. Lying behavior in the message game remains
insignificant. Thus, the results suggest that students who exhibit more dishonesty on the dice task prefer
government jobs but that people with greater social preferences do not want a government job. While the
model suggested that either returns to corruption or utility from social preferences may drive selection
into government, the data indicate that the gains from corruption, but not from social preferences, affect
the pool of students that apply for government jobs in India.
In Table 4B, we again explore the interactions of these measures of pro-social behavior and
honesty with ability for the students. We find that the effects of these measures do not appear to be
dependent on ability either individually (Columns 1 and 2 of Panel B) or when considered jointly (the pvalue for the three interactions in Panel B, Column 3 is 0.905).
Overall, the analysis in this section suggests that those who display a tendency for dishonesty in
the tasks and a lower level of pro-social behavior are more likely to want to enter government service.

21

Furthermore, screening based on ability neither exacerbates nor mitigates the problem of negative
selection into government.

B. Are Survey Measures Predictive of Real-World Preferences and Behaviors?
Increasingly, governments are incorporating personality and ethics questions into the screening
mechanism for bureaucratic positions, under the belief that screening on ability is not enough to ensure an
honest and capable civil service. For example, the Singaporean Civil Service exams often have a
personality profiling exam, which captures factors such as whether one is an introvert or extrovert, a
negotiator or a dictator, etc. (PSC Annual Report 2011). In 2011, the Indian UPSC added an ethics
portion to its main civil service exams.28 Thus, in Table 5, we explore how these types of personality and
survey measures relate to students’ job preferences and nurse absenteeism and how they fare against the
experimental measures discussed above. 29 For the respective regressions, we include the same controls
and cluster the standard errors as described in Table 3.
Starting with the student sample (Columns 1 – 4), we explore three of the Big-Five personality
measures.30 These measures, conscientiousness, agreeableness and neuroticism, have been found in some
analyses to be correlated with counterproductive behavior in the workplace, including absenteeism and
turnover (see Berry et al., 2007; Salgado, 2002). As shown in Columns 1 and 4, only the neuroticism
index is predictive of job preferences, with neurotic types of individuals less likely to prefer government
jobs. If we posit that corrupt types prefer government jobs, this is consistent with the previous evidence
that neurotic individuals engage in less deviant and counterproductive workplace behaviors. In addition,
we also asked a set of questions developed by psychologists to measure the extent to which individuals
believe that they have control over the events in their lives—the “locus of control.” The higher the score,
28

http://timesofindia.indiatimes.com/india/UPSC-releases-sample-paper-on-ethics-for-civil-servicesexams/articleshow/21808969.cms
29
As above, the interactions of these measures with ability are insignificant, and so we omit them for conciseness.
Appendix Table 15 provides the results with no controls, while Appendix Table 16 provides them with restricted
definitions.
30
The results for the other two, openness to experience and extraversion, are omitted here due to space constraints
and less evidence in the literature of their correlation with counter-productive behavior.

22

the more likely an individual believes that his or her outcomes are determined by forces outside of their
control. Having a higher external locus of control is highly correlated with a preference for a public
sector position (Column 1). This is consistent with prior studies that have suggested that an external
locus of control is positively correlated with unethical behavior in a laboratory game involving making
kickbacks to other players (Hegarty and Sims, 1978).
Next, we explore two types of survey questions regarding corruption and cheating. First, we ask
whether the respondent has previously used an agent—an illegal helper who facilitates bribes -- to receive
a public service. As this is a very direct question about illegal behavior, some may not want to answer
honestly. Thus, we also asked less direct questions: the percentage of their classmates who would cheat
on an exam with the professor in the room, as well as if the professor left the room due to an emergency;
the variable “Classroom Cheating” is an average of both responses. These types of questions presume
that individuals who are more likely to cheat would also assume that people cheat in general. Students
that report having used an illegal agent are 6.1 percent more likely to prefer a government job but this is
not statistically different from zero at the standard levels.. The coefficient on the share of classmates who
would cheat on an exam is negative and significant at the 10 percent level (Column 2). Note that the sign
is the opposite of the results of what one would expect, suggesting that the presumption that individuals’
beliefs regarding cheating are positively correlated with behavior is false or the students were not
answering honestly.
In Column 3, we examine four attitudinal questions about job success and bribery. Students who
believed that networks are necessary for success were 5.6 percent more likely to prefer public service
positions. However, students who believed bribes are necessary to operate a business in India were 4.5
percent less likely to prefer government work. Thus, it seems that reporting that corruption is pervasive or
necessary in standard attitudinal questions about corruption do not consistently predict preferences.
Finally, in Column 5, we explore whether the same attitudinal questions regarding corruption that
we asked the students also predict fraudulent nurse absenteeism. Nurses that believe that most businesses

23

pay bribes are more likely to attend work, but the other attitudinal questions are not significantly related
their attendance.
In sum, we find that some personality measures (neuroticism and locus of control) have
consistent results with the dice task in predicting job preferences, but that the other standard measures we
explore have no detectable predictive power within our sample.

The explicit, non-experimental

elicitations of preferences for corruption have little predictive power for detecting real-world fraudulent
behavior.

VI. CONCLUSION
In this paper, we offer evidence that the college students who cheat on a simple task are more likely to
prefer to enter government service after graduation. This relationship does not appear to vary by ability,
suggesting that screening on ability does not change the level of honesty of those chosen for government
service among the pool of applicants.
Importantly, we show that cheating on this task is also predictive of fraudulent behaviors by real
government officials, which implies that the measure captures a meaningful propensity towards
corruption. Given that the existing methods of measuring corruption only apply for those who are already
entrenched in the bureaucracy, our validation of a measure of cheating against real-world corruption
outcomes offers an important tool for future research on selection and corruption.
These findings are important because they demonstrate that the variation in the levels of observed
corruption may, in part, be driven by who selects into government service. In addition, they offer two key
policy insights.

First, the recruitment and screening process for bureaucrats may be improved by

increasing the emphasis on characteristics other than ability. It is important to note that individuals may
not want to reveal their characteristics, especially their propensity for dishonesty, so the method of
measurement matters. The simple, experimental measure we employed predicted the corrupt behaviors of
the government employees, but the game in which corruption was explicitly framed and the fairly
standard attitudinal questions had little predictive value. Second, while recent empirical papers have
24

shown that reducing the returns to corrupt behavior decreases the probability that bureaucrats engage in
corruption, our work suggests that these interventions may have had even broader effects by changing the
composition of who might apply.

Works Cited
Abbink, Klaus, Bernd Irlenbusch, and Elke Renner, "An Experimental Bribery Game," Journal of Law,
Economics, and Organization, 18 (2002), 428-454.
Abbink, Klaus, and Heike Hennig-Schmidt. "Neutral Versus Loaded Instructions in a Bribery
Experiment," Experimental Economics 9 (2006), 103-121.
Alatas, Vivi, Lisa Cameron, Ananish Chaudhuri, Nisvan Erkal, and Lata Gangadharan, "Subject Pool
Effects in a Corruption Experiment: A Comparison of Indonesian Public Servants and Indonesian
Students," Experimental Economics, 12 (2009), 113-132.
Ariely, Dan, Uri Gneezy, George Loewenstein, and Nina Mazar. "Large Stakes and Big Mistakes." The
Review of Economic Studies, 76 (2009), 451-469.
Armantier, Olivier, and Amadou Boly, "Can Corruption be Studied in the Lab? Comparing a Field and a
Lab Experiment." Comparing a Field and a Lab Experiment (September 1, 2008). CIRANO-Scientific
Publications 2008s-26 (2009).
Bagchi, Sanjoy, The Changing Face of Bureaucracy: Fifty Years of the Indian Administrative Service,
New Delhi: Rupa & Company, 2007.
Banerjee, Abhijit, “A Theory of Mis-Governance,” Quarterly Journal of Economics, 112 (1997), 12891332.
Banerjee, Abhijit, Rema Hanna, and Sendhil Mullainathan, “Corruption.” Handbook of Organizational
Economics, Princeton University Press, 2012.
Banerjee, Abhijit, Selvan Kumar, Rohini Pande, and Felix Su, “Do Informed Voters Make Better
Choices? Experimental Evidence from Urban India, Mimeo, 2011.
Barr, Abigail, and Danila Serra, "The Effects of Externalities and Framing on Bribery in a Petty
Corruption Experiment," Experimental Economics, 12 (2009), 488-503.
Benz, Matthias, and Stephan Meier, "Do People Behave in Experiments as in the Field?—Evidence from
Donations," Experimental Economics, 11 (2008), 268-281.
Berry, Christopher M., Deniz S. Ones, and Paul R. Sackett. "Interpersonal Deviance, Organizational
Deviance, and their Common Correlates: a Review and Meta-Analysis." Journal of Applied Psychology,
92 (2007), 410-424.
25

Besley, Timothy, "Political Selection," The Journal of Economic Perspectives, 19 (2005), 43-60.
Besley, Timothy, Rohini Pande, and Vijayendra Rao, “Just Rewards? Local Politics and Public Resource
Allocation in South India,” World Bank Economic Review, 26 (2012), 191-216.
Camerer, Colin, Behavioral Game Theory: Experiments in Strategic Interaction. Princeton: Princeton
University Press, 2003.
Cameron, Lisa, Ananish Chaudhuri, Nisvan Erkal, and Lata Gangadharan, "Propensities to Engage In and
Punish Corrupt Behavior: Experimental Evidence from Australia, India, Indonesia and Singapore,"
Journal of Public Economics, 93 7 (2009), 843-851.
Cárdenas, Juan Camilo, Alberto Chong, and Hugo Ñopo, "Stated Social Behavior and Revealed Actions:
Evidence from Six Latin American Countries," Journal of Development Economics, 104 (2013), 16-33.
Carpenter, Jeffrey, Cristina Connolly, and Caitlin Knowles Myer, "Altruistic Behavior in a Representative
Dictator Experiment." Experimental Economics, 11 (2008), 282-298.
Caselli, Francesco, and Massimo Morelli, "Bad Politicians." Journal of Public Economics, 88 (2004),
759-782.
Dal Bó, Ernesto, Frederico Finan, and Martín Rossi, “Strengthening State Capabilities: The Role of
Financial Incentives in the Call to Public Service,” Quarterly Journal of Economics, 128 (2013), 11691218.
Dhaliwal, Iqbal and Rema Hanna, “Deal with the Devil: The Successes and Pitfalls of Bureaucratic
Reform,” MIMEO, 2013.
Di Tella, Rafael, and Ernesto Schargrodsky, "Do Police Reduce Crime? Estimates Using the Allocation of
Police Forces after a Terrorist Attack," American Economic Review, (2004), 115-133.
Duflo, Esther, Rema Hanna, and Stephen P. Ryan, "Incentives Work: Getting Teachers to Come to
School," The American Economic Review, 102 (2012), 1241-1278.
Eckel, Catherine, and Philip Grossman, "Altruism in Anonymous Dictator Games," Games and Economic
Behavior, 16 (1996), 181-191.
Ferraz, Claudio and Fred Finan, “Exposing Corrupt Politicians: The Effect of Brazil’s Publicly Released
Audits on Electoral Outcomes,” Quarterly Journal of Economics, 123(2008), 703-745.
Fischbacher, Urs, and Franziska Föllmi‐Heusi, "Lies in Disguise—an Experimental Study on Cheating,"
Journal of the European Economic Association, 11 (2013), 525-547.
Gneezy, Uri, "Deception: The Role of Consequences," The American Economic Review, 95 (2005), 384394.
Hegarty, W. Harvey, and Henry P. Sims, "Some Determinants of Unethical Decision Behavior: An
Experiment," Journal of Applied Psychology, 63 (1978), 451.
Hurkens, Sjaak, and Navin Kartik, "Would I Lie to You? On Social Preferences and Lying Aversion,"
Experimental Economics, 12 (2009), 180-192.
26

Ilaiah, Kancha, "Beware of Bureaucratic Doras'," Economic and Political Weekly, 30 (1995), 22-24.
John, Oliver P., Eileen M. Donahue, and Robert L. Kentle, "The Big Five Inventory—Versions 4a and
54." Berkeley: University of California, Berkeley, Institute of Personality and Social Research (1991).
John, Oliver P., Laura P. Naumann, and Christopher J. Soto, "Paradigm Shift to the Integrative Big Five
Trait Taxonomy: History, Measurement, and Conceptual Issues, Handbook of Personality: Theory and
Research, 3 (2008), 114-158.
Kolstad, Julie Riise, and Ida Lindkvist, "Pro-Social Preferences and Self-Selection into the Public Health
Sector: Evidence from an Economic Experiment," Health Policy and Planning, 28 (2013), 320-327.
Levitt, Steven D., and John A. List, "What do Laboratory Experiments Measuring Social Preferences
Reveal About the Real World?" The Journal of Economic Perspectives, 21 (2007), 153-174.
Mohanty, Subhashish. “Centres Increase Civil Service Coaching Fees,” The Telegraph, November 28,
2013. http://www.telegraphindia.com/1111129/jsp/odisha/story_14810267.jsp
Niehaus, Paul, and Sandip Sukhtankar, "Corruption Dynamics: The Golden Goose Effect," American
Economic Journal: Economic Policy, forthcoming.
Olken, Benjamin, “Monitoring Corruption: Evidence from a Field Experiment in Indonesia,” Journal of
Political Economy, 115 (2007), 200-249.
Olken, Benjamin A. and Rohini Pande, “Corruption in Developing Countries,” Annual Review of
Economics, 4 (2012), 479-509.
Ragatz, Laurie, and William Fremouw, "A Critical Examination of Research on the Psychological
Profiles of White-Collar Criminals," Journal of Forensic Psychology Practice, 10 (2010), 373-402.
Rotter, Julian B, "Generalized Expectancies for Internal Versus External Control of Reinforcement,"
Psychological Monographs: General and Applied, 80 (1966), 1-28.
Salgado, Jesus F, "The Big Five Personality Dimensions and Counterproductive Behaviors," International
Journal of Selection and Assessment, 10 (2002), 117-125.
Singapore Public Service Commission, Annual Report, 2011.
Shleifer Andrei and Robert W. Vishny, “Corruption,” Quarterly Journal of Economic, 108 (1993), 599617.
Sutter, Matthias, "Deception through Telling the Truth?! Experimental Evidence from Individuals and
Teams," The Economic Journal, 119 (2009), 47-60.
Wade, Robert,"The System of Administrative and Political Corruption: Canal Irrigation in South India,"
The Journal of Development Studies, 18 (1982), 287-328.

27

Figure 1: Total Points in Dice Task
(a) Student Sample

(b) Nurse Sample

These figures provide the distribution of outcomes across from the dice task
for the student (Panel A) and nurse (Panel B) samples. The thick lines
represent the within sample median, while the dashed lines represent the
99th percentile of the probability density function of total score from rolling
an unbiased die 42 times without cheating.

Figure 2: Distribution of Outcomes from Experimental Measures,
Student Sample
(a) INR Kept in Pro-Social Preferences Game

(b) Number of Times Lied in Message Game

These figures provide the distribution of outcomes from the Pro-Social Preferences Game (Panel A) and the Message Game (Panel B) from the student
sample.

Table 1A: Descriptive Statistics, Student Sample
Mean

SD

N

167.59
29.31
0.30

21.04
13.01
0.46

661
662
662

2.25
1.68

2.22
0.89

660
661

Panel C: Personality Measures and Survey Measures of Corruption
Conscientiousnes Index
3.59
Agreeableness Index
3.71
Neuroticism Index
2.86
Used an Agent
0.28
Classroom Cheating With Prof in Room
0.34
Classroom Cheating With Prof Out of Room
0.62
Promotions Should be Based on Seniority (% Agree)
0.08
Success Requires Contacts (% Agree)
0.62
Bribes are Common (% Agree)
0.85
Bribes are Necessary (% Agree)
0.53

0.56
0.53
0.63
0.45
0.26
0.29
0.27
0.49
0.36
0.50

659
660
660
637
658
658
660
657
658
655

Panel D: Real World Outcome
Wants Government Job

0.50

660

Panel A: Experimental Measures
Points in Dice Task
INR Kept in Pro-Social Preferences Game
Always Lied in Message Game
Panel B: Ability Measures
Correct Answers in Matrices Test
Correct Answers in Memory Test

0.43

This table provides sample statistics from the student sample. In Panel C, the big 5 personality indexes are
calculated using the method described in (John et al, 2008) and (John et al., 1991) with the exception that if
one of the questions were not answered, we still averaged over the other questions (subsequent regressions include a dummy variable for when this was done).In Panel C, the second-to-last and third-to-last last variables
provide the percent of students who agree or strongly agree to two questions (“Success is determined more by
‘who you know’ than by ‘what you know’ ” and “most businesses use bribes to get government contracts”),
while the last and fourth-to-last variables provide the percent of students who disagree or strongly disagree to
two questions (“Promotions should be based primarily on job performance rather than seniority” and “it is
possible to operate a business in India without bribing”

Table 1B: Descriptive Statistics, Nurse Sample
Mean

SD

N

Panel A: Experimental Measures
Points in Dice Task

151.84

13.46

165

Panel B: Ability Measures
Number Correct in Memory Test

2.66

1.26

165

Panel C: Attendance Measures
Presence

0.49

0.50

720

Panel D: Non-Experimental Measures of Corruption
Promotions Should be Based on Seniority (% Agree)
Success Requires Contacts (% Agree)
Bribes are Common (% Agree)
Bribes are Necessary (% Agree)

0.14
0.97
0.42
0.54

0.35
0.18
0.49
0.50

152
150
144
148

This table provides sample statistics from the nurse sample. In Panel A, the dice task replicates the task given
to the students, but is paid in chocolate rather than money. In Panel C, the attendance measures comes from
periodic random checks by independent enumerators as reported in Dhaliwal and Hanna (2013). We exclude
nurses who are permanently transferred or resigned or who are working temporarily at another facility. In
Panel D, the second and third variables provide the percent of students who agree or strongly agree to two
questions (“Success is determined more by ‘who you know’ than by ‘what you know’ ” and “most businesses
use bribes to get government contracts”), while the first and fourth variables provide the percent of students
who disagree or strongly disagree to two questions (“Promotions should be based primarily on job performance
rather than seniority” and “it is possible to operate a business in India without bribing”).

Table 2: What Predicts Dishonesty in the Dice Task and Ability?
Student Sample
(1)
Dice
Points
High Ability

Conscientiousness Index
Agreeableness Index
Neuroticism Index
External Locus of Control
Classroom Cheating
Male
Parent is a Government Employee

0.239∗∗∗
(0.072)
2.498
(1.723)
2.163
(1.548)
−2.566∗
(1.394)
−3.102∗∗
(1.131)
0.081
(0.642)
−1.084
(3.273)
5.815∗∗
(2.672)
−0.811
(1.580)

0.000
(0.001)
0.001
(0.002)
−0.034
(0.040)
0.049
(0.042)
0.072∗
(0.039)
0.018
(0.033)
−0.005
(0.017)
0.042
(0.100)
0.107∗∗
(0.053)
0.030
(0.058)

Years at PHC
Years of Government Service
Corruption Beliefs Index
Joint F-Test Statistic
Joint Chi-Squared Test Statistic
P-Value
Dependent Variable Mean
Observations

4.970
0.000
167.3
627

(3)
Dice
Points

(4)
High
Ability

−0.296
(2.451)

0.153
(2.370)

Dice Points
INR Kept in Pro-Social Preferences
Game
Always Lied in Message Game

(2)
High
Ability

Nurse Sample

0.000
(0.003)

−7.078
(4.828)

0.111
(0.222)

−1.094∗∗
(0.420)
0.823∗
(0.464)
−1.212
(2.753)

−0.032∗∗
(0.016)
0.004
(0.017)
−0.111
(0.097)

2.031
24.882
0.009
0.431
627

0.079
151.9
133

5.573
0.350
0.526
133

This table explores correlations between dice points and ability with individual characteristics. For the students, high ability is computed by taking the average of the z-scores from the memory and matrices test,
and assigning everyone who is above the median as high; for the nurses, it is defined based on the memory
test. In Columns 1 and 3, the coefficients are from OLS regressions; in Columns 2 and 4, the coefficients are
marginal effects evaluated at the means from a probit regression. In the student sample (Columns 1 and 2),
the regressions include enumerator fixed effects, indicators for caste and a cubic in age and are clustered at
the session level. The big 5 personality indexes are calculated using the method described in (John et al,
2008) and (John et al., 1991), except that we averaged over questions which were actually answered when
there were missing values. Students who cheat is the average of the percentage of students the respondent
thinks will cheat if the professor is in the room, and the percentage of students the respondent thinks will
cheat if the professor is not in the room. In the nurse session, we control for a cubic in age, survey factors
(survey round, month of the year, time of day, district) and experimental treatments (treatment and the interaction of treatment with a dummy indicating that the survey was conducted post-treatment); we cluster
these regressions the PHC level. The corruption beliefs index is the average of the z-scores for the four questions reported in Panel D of Table 1B, where zscores are normalized such that a positive score indicates a
higher perception of corruption.∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

Table 3A: Does Dishonesty in the Dice Task Predict Job Preferences
and Worker Attendance?
Student Sample

Nurse Sample

Wants Government Job

Attendance

(1)
Dice Points
High Dice Score

(2)

0.002∗∗∗
(0.001)

(3)

(4)

−0.002∗
(0.001)
0.063∗
(0.037)

−0.075∗∗
(0.038)

Columns 1 and 2 explore the relationship between the students’ outcome on the
dice task and their preferences to enter government service; 43 percent of students
indicate a preference for a government job. The coefficients are marginal effects
evaluated at coefficient means from a probit regression, controlling for enumerator
fixed effects, gender, caste and a cubic in age. Standard errors clustered at the
session level are in parentheses. A high dice score is a score above the respective
median scores for students and nurses. The sample size is 660 in Columns 1 and 2.
Columns 3 and 4 provide the relationship between the outcome on the dice task and
attendance for the nurse sample. The dependent variable is binary variable equal
to one if a nurse was present during a given survey round; mean attendance is 48.7
percent across the 720 observations. We control for gender, a cubic in age and in
tenure, survey factors (survey round, month of the year, time of day, district) and
experimental treatments (treatment and the interaction of treatment with a dummy
indicating that the survey was conducted post-treatment). See Dhaliwal and Hanna
(2013) for a more detailed description of the data. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

Table 3B: Does the Relationship Between Dishonesty and Outcomes Vary by Ability?
Student Sample

Nurse Sample

Wants Government Job

Attendance

(1)

(2)

(3)

(4)

Panel A: Control for Ability
Dice Points

0.002∗∗∗
(0.001)

High Dice Score
High Ability

0.009
(0.052)

−0.002∗
(0.001)
0.062∗
(0.037)
0.013
(0.052)

−0.040
(0.043)

−0.075∗
(0.038)
−0.039
(0.043)

Panel B: Control for Ability Interaction
Dice Points

0.002∗∗
(0.001)

High Dice Score
High Ability
High Ability x Dice Points
High Ability x High Dice Score

0.106
(0.337)
−0.001
(0.002)

−0.002
(0.002)
0.095∗∗
(0.046)
0.052
(0.080)

−0.077
(0.111)

−0.097
(0.393)
0.000
(0.003)

−0.076
(0.061)
−0.040
(0.061)

0.002
(0.083)

This table explores the relationship between dishonesty in the dice task, ability and the outcomes.
For the students, “high ability” is computed by taking the average of the z-scores from the memory
and matrices test, and assigning everyone who is above the median as high; for the nurses, it is defined based on the memory test. The sample and regression set-up is similar to Table 3A. In Panel A,
we additionally include the high ability indicator variable. In Panel B, we then additionally include
the interaction of the dice outcomes with the high ability indicator variable. ∗ p < .10, ∗∗ p < .05,
∗∗∗ p < .01

Table 4A: The Relationship Between Pro-Social Preferences and Dishonesty
and Wanting a Government Job, Student Sample
(1)
INR Kept in Pro-Social Preferences Game
Always Lied in Message Game
Points in Dice Task
Joint Wald Test Statistic
P-Value

(2)

(3)

0.010
(0.041)

0.003∗
(0.002)
0.000
(0.041)
0.002∗∗
(0.001)

∗∗

0.003
(0.001)

18.820
0.001

This table explores the relationship between the experimental measures of dishonesty and prosocial behaviors with a preference for government service within the student sample. In all regressions, the outcome variable is an indicator for a preference for a government job, the coefficients
are marginal effects evaluated at the mean from a probit regression, the regression equation includes enumerator fixed effects, indicators for gender and caste, and a cubic in age, and the standard errors are clustered by session. The sample size is 660. In Column 1, the variable of interest
is the amount kept in the pro-social preferences game, while it lying all three times in the message
game in Column 2. In Column 3, we include all three experimental measures in a single regression; we report the Wald test statistic and associated p-value of the null hypothesis that the three
displayed coefficients are equal to zero. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

Table 4B: The Relationship Between Pro-Social Preferences, Dishonesty, and Ability
and Wanting a Government Job - Student Sample
(1)
Panel A: Control for Ability
INR Kept in Pro-Social Preferences Game

(2)

0.003∗∗
(0.002)

Always Lied in Message Game

0.007
(0.040)

Points in Dice Task
High Ability
Panel B: Control for Ability Interaction
INR Kept in Pro-Social Preferences Game

0.007
(0.052)

0.012
(0.053)

0.003
(0.002)

Always Lied in Message Game

0.023
(0.046)

Points in Dice Task
High Ability
High Ability x INR Kept
High Ability x Always Lied
High Ability x Dice Points
Joint Wald Test Statistic
P-Value (Interactions Only)

−0.025
(0.117)
0.001
(0.003)

0.023
(0.054)

−0.038
(0.067)

(3)
0.003∗
(0.002)
−0.003
(0.040)
0.002∗∗
(0.001)
0.005
(0.052)
0.002
(0.002)
0.011
(0.046)
0.002∗
(0.001)
0.059
(0.336)
0.001
(0.004)
−0.032
(0.066)
−0.001
(0.002)
0.560
0.905

This table explores the relationship between dishonesty, pro-social preferences, ability and the
students employment preferences. High ability is computed by taking the average of the z-scores
from the memory and matrices test, and assigning everyone who is above the median as high.
The sample and regression set-up is similar to Table 4A. In Panel A, we additionally include the
high ability indicator variable and report the Wald statistic and associated p-value of the null hypothesis that the three displayed coefficients are equal to zero. In Panel B, we then additionally
include the interaction of the dice outcomes with the high ability indicator variable and report
the joint test of the null hypothesis that the interactions of ability with dishonesty and pro-social
preferences are equal to zero). ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

Table 5: Do Personality Measures and Corruption Beliefs Predict
Job Preferences and Worker Attendance?

(1)

Student Sample

Nurse Sample

Wants Government Job

Attendance

(2)

(3)

(4)

Conscientiousness Index

−0.043
(0.041)

−0.072
(0.044)

Agreeableness Index

−0.027
(0.047)

−0.026
(0.047)

Neuroticism Index

−0.059∗∗
(0.026)

−0.068∗∗
(0.028)

External Locus of Control

0.034∗∗
(0.014)

Student Has Used Agent
Classroom Cheating

(5)

0.040∗∗∗
(0.015)
0.061
(0.038)

0.051
(0.038)

−0.145∗
(0.079)

−0.143∗
(0.081)
−0.010
(0.021)

Promotions Based on Seniority

−0.009
(0.020)

−0.019
(0.023)

Success Requires Contacts

0.056∗∗
(0.022)

0.045∗∗
(0.022)

−0.020
(0.022)

Bribes are Common

0.002
(0.027)

0.018
(0.026)

−0.022
(0.022)

Bribes are Necessary

−0.045∗∗
(0.021)

−0.048∗∗
(0.020)

0.014
(0.024)

11.916
0.018
0.428
629

60.627
0.000
0.421
599

2.285
0.683
0.490
610

Joint Wald Test Statistic
P-Value
Dependent Variable Mean
Observations

21.663
0.000
0.427
633

4.944
0.084
0.422
609

Columns 1 -4 explore the relationship between the students personality measures and corruption beliefs and their preferences to enter government service. The coefficients are marginal effects evaluated at coefficient means from a probit
regression, controlling for enumerator fixed effects, indicators for gender and caste and a cubic in age. Standard errors
clustered at the session level are in parentheses. See Table 1A for more details on the measures. Column 5 provides the
relationship between corruption beliefs and attendance for the nurse sample. The dependent variable is binary variable
equal to one if a nurse was present during a given survey round. We control for a cubic in age, gender, survey factors
(survey round, month of the year, time of day, district) and experimental treatments (treatment and the interaction of
treatment with a dummy indicating that the survey was conducted post-treatment). See Dhaliwal and Hanna (2013)
for a more detailed description of the data, and the notes for Table 1B for the full description of how the beliefs were
measured. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Figure 1: Dice Task Instructions (Student Sample)

THIRD TASK
D5.0 Here, we will ask you to throw a die. Report the number outcome on the top of the dice after it
lands. For example, the outcome is “4” if the top of the die looks like:
We will ask you to do this 42 times, and write the outcome
each time. You will receive .5 INR for each point rolled.
Roll

1

2

3

4

Payout

INR 0.5

INR 1.0

INR 1.5

INR 2.0

5
INR
2.5


6
INR 3.0

You would receive 2.0 INR for this round
You can earn between INR 21 and 126. Write down the numbers that you rolled in the table.
Roll
Number
1

Outcome
(from 1-6)

Roll
Number
16

Outcome
(from 1-6)

Roll
Number
31

2

17

32

3

18

33

4

19

34

5

20

35

6

21

36

7

22

37

8

23

38

9

24

39

10

25

40

11

26

41

12

27

42

13

28

14

29

15

30

Total (A)

Total (B)

Total Payment (A+B+C)x0.5 =

Total (C)

Outcome
(from 1-6)

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Figure 2: Message Game Instructions (Student Sample)

PART F
F0.1

FOURTH TASK
Here, you will be sending a message to another participant. You are not playing against any
of your friends. You will never know who the other participant is and the other participant
will never know who you are. There are two payment options, which YOU CAN see but the
other participant CAN NOT SEE. Different people get different payment options.

Example
Step 1: Look at the payment options below. Under Option A you earn 10 INR and the other
participant earns 25 INR. Under Option B you earn 15 INR and the other participant earns
10 INR. Only you can see this; the other participant cannot see this.
Option A: Rs 10 to you and Rs 25 to the other participant
Option B: Rs 15 to you and Rs 10 to the other participant
Step 2: You pick a message to send to the other participant about the payment options.
Message 1: "Option A will earn you more money than option B."
Message 2: "Option B will earn you more money than option A."
Step 3: The other participant only sees the message you send. Based on your message, they
will then pick an option, either Option A or Option B.
Step 4: You and the other participant will receive money based on which option the other
participant picks.

Remember, you will not pick an option. You will only pick a message to send to the other
player. Now suppose Participant 1 sends the message 2 “Option A will earn you more money
than option B” to Participant 2 and participant 2 picks up option A. In this scenario
Participant 1 will earn 10 INR and Participant 2 will earn 25 INR.

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Figure 3: Matrices Game Instructions (Student Sample)

PART C
SECOND TASK
In the next task we will see a set of matrices with 12 numbers each. You will be
asked to find the two numbers in each of the matrices that add up to 10. You
will be given 3 minutes, and you will be paid 2 INR for each you solve. Please
circle only two numbers in each matrix.
Here is an example:

9.38

6.74

8.17

5.15

6.61

3.06

9.17

0.91

4.88

3.58

4.87

6.42

Here 3.58 and 6.42 are the numbers that add up to 10

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Figure 4: Dice Task Instructions (Nurse Sample)
Enumerator Instructions: Please request the staff nurse to throw a die and report the number outcome on the top of the die
after it lands.

Here, we will ask you to throw a die. Report the number outcome on the top of the dice after it lands. For
example, the outcome is “4” if the top of the die looks like:
We will ask you to do this 42 times, and write the outcome
each time. You will receive 1 Candy for each point rolled
Roll
Number of
candies

1

2

3

4

5

6

Thus, you can earn candies between 42 and 256 depending on the numbers you roll.
Please write down the numbers that you rolled in the table provided.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

Roll
Number
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30

Total (A)

Total (B)

Roll Number

Outcome
(from 1-6)

Outcome
(from 1-6)

Roll
Number
31
32
33
34
35
36
37
38
39
40
41
42

Total (C)

Outcome
(from 1-6)

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Figure 5: Distribution of Rolls in Dice Task
(a) Student Sample

(b) Nurse Sample

This figure provides the distribution of numbers rolled in the dice task for
the student (Panel A) and nurse (Panel B) samples.

(c) Matrices Test, Student Sample

(b) Memory Test, Nurse Sample

This figure provides the distribution of outcomes of the ability measures. Panels A and B graphs the distribution of the number of correct answers
in the memory game for the student and nurse samples, respectively. Note that the memory test given to the nurses was a simplified version of the
student test, which may account for their higher average scores. Panel C provides the results of the matrices test for the student sample.

(a) Memory Test, Student Sample

Appendix Figure 6: Distribution of Experimental Ability Measures

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 1: Student Recruitment
Number of Schools
Number of Sessions
Total Number of Seniors in Surveyed Schools
Number Who Signed Up For Survey
Number Who Came to Take Survey

7
28
3215
1081
669

This table provides descriptive statistics on student recruitment
and sessions.

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 2: Dishonest Behavior Observed, by Session - Student Sample

1101
1102
1103
1104
1105
1201
1202
1203
1204
1205
1206
1301
1302
1303
1304
1401
1501
1502
1503
1504
1505
1601
1602
1603
1604
1605
1701
1703

(1)

(2)

Total
Students

Was
Caught
Cheating

15
26
28
28
21
28
24
28
28
28
29
19
27
39
15
30
30
32
32
32
32
6
10
12
18
14
10
25

3
5
6
4
5
1
3
2
4
3
2
2
0
3
3
6
3
2
0
2
4
0
0
0
3
0
2
1

(3)
Asked if
Could Lie
(Message
Game)
1
0
0
2
0
0
0
0
0
0
0
0
0
0
0
7
3
0
0
0
0
0
0
0
0
0
0
0

(4)
Asked to
Leave
Early
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0

This table provides descriptive statistics on student sessions, where each row
represents a separate session.

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 3: Payoffs Used in the Message Game
Payoff To
Round

Option

Treatment 1
1
A
B

Sending
Player

Receiving
Player

10
15

15
10

2

A
B

15
10

10
20

3

A
B

10
15

22
2

Treatment 2
1
A
B

15
10

10
20

2

A
B

10
15

22
2

3

A
B

10
15

15
10

This table provides the payoffs used in the message game.

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 4: Test for Selection of Nurses into Endline Survey
Nurse Sample
Attendance
(1)
PHC Surveyed

0.002
(0.046)

Nurse Surveyed in Endline
PHC Fixed Effects
Dependent Variable Mean
Observations

(2)

No

0.026
(0.033)
Yes

0.426
1978

0.414
1779

In this table, we explore whether the surveyed nurses systematically differed from those that were not surveyed in terms of their
presence. In Column 1, we test whether nurses that work at the
surveyed PHC had different attendance rates than the 16 PHCs
that we were unable to survey at. In Column 2, the sample is
restricted to the PHCs where we surveyed, and we test whether
the nurse that was surveyed different systematically in terms of
attendance rates from the other nurses that work at that PHC.
The coefficients are marginal effects evaluated at the coefficient
means from a probit regression. We include the survey design
and treatment controls described in Table 3A. Standard errors
clustered at the PHC are provided in parentheses. ∗ p < .10, ∗∗
p < .05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 5: Demographic Characteristics
Mean

SD

N

Panel A: Student Sample
Male
Age (Years)
Parent is a Government Employee
Relative is a Government Employee
Caste: Scheduled Tribes
Caste: Scheduled Castes
Caste: Other Backward Castes
Caste: General
Commerce Major
Science Major
Grade Point Average

0.40
19.65
0.24
0.68
0.03
0.11
0.37
0.50
0.81
0.19
69.36

0.49
0.80
0.43
0.47
0.16
0.31
0.48
0.50
0.39
0.39
10.39

661
638
659
633
640
640
640
640
661
661
616

Panel B: Nurse Sample
Male
Age (Years)
Tenure in Government (Years)
Tenure in PHC (Years)

0.05
34.20
8.61
4.75

0.23
8.78
7.77
4.07

165
165
157
164

This table provides descriptive statistics on the demographic characteristics of subjects in the student (Panel A) and nurse (Panel B) samples.

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 6: The Relationship Between Different Measures of Ability
Student Sample

High Ability

Grade Point
Average

High Score
in Memory Test

Number Correct
in Memory Test

(1)

(2)

(3)

∗∗∗

2.849
(0.937)

0.078∗
(0.045)

High Score in Matrices Test

0.086∗∗∗
(0.025)

Number Correct in Matrices Test
Observations

597

637

637

This table tests the relationship between the different ability measures in the student sample. In Column
1, we regress the students self-reported GPA on a dummy for high ability, which is constructed by taking
the the average of the z-scores from their memory and matrices tests and generating a dummy variable if
the students score is greater than the median. In Columns 2 and 3, we explore the relationship between
the students score on the memory and matrices tests. Coefficients are from OLS regressions with indicators for gender and caste, a cubic in age and surveyor fixed effects. Standard errors clustered at the
session level are in parenthesis. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 7: What Predicts Dishonesty in Dice Task?
Student Sample With Restricted Definitions
Student Sample
(1)
Dice
Points
High Ability

0.927
(3.350)

Dice Points
INR Kept in Pro-Social Preferences
Game
Always Lied in Message Game
Conscientiousness Index
Agreeableness Index
Neuroticism Index
External Locus of Control
Student Has Used an Agent
Classroom Cheating
Male
Parent is a Government Employee
Joint F-Test Statistic
Joint Chi-Squared Test Statistic
P-Value
Dependent Variable Mean
Observations

(2)
High
Ability

0.187∗
(0.096)
3.258
(2.477)
2.645
(2.618)
−2.818
(2.104)
−1.217
(1.396)
−0.393
(0.750)
−2.585
(2.476)
0.463
(3.555)
7.769∗∗
(2.986)
−2.945
(2.398)

0.001
(0.002)
0.005∗
(0.003)
−0.013
(0.059)
0.059
(0.062)
0.101∗
(0.058)
−0.002
(0.043)
0.022
(0.023)
−0.212∗∗∗
(0.067)
0.037
(0.125)
0.109
(0.076)
0.095
(0.073)

3.224
0.006
338

55.964
0.000
0.433
337

This table replicates Table 2, expect that we restrict the sample to individuals
with no missing values for the big 5 personality measures. ∗ p < .10, ∗∗ p <
.05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 8A: Does Dishonesty in the Dice Task Predict Job Preferences
and Worker Attendance? OLS

Dice Points
High Dice Score

Student Sample

Nurse Sample

Wants Government Job
(1)
(2)

Attendance
(3)
(4)

0.002∗∗∗
(0.001)

−0.001
(0.001)
0.062∗
(0.034)

−0.052
(0.037)

This table replicates Table 3A, but estimates all regressions using OLS rather than
probit. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 8B: Is the Relationship Between Dishonesty and Outcomes
Dependent on Ability? OLS
Student Sample

Nurse Sample

Wants Government Job
(1)
(2)

Attendance
(3)
(4)

Panel A: Control for Ability
Dice Points

0.002∗∗∗
(0.001)

High Dice Score
High Ability

0.007
(0.051)

−0.002
(0.001)
0.060∗
(0.035)
0.010
(0.051)

−0.014
(0.042)

−0.052
(0.037)
−0.014
(0.042)

Panel B: Control for Ability Interaction
Dice Points

0.002∗∗
(0.001)

High Dice Score
High Ability
High Ability x Dice Points
High Ability x High Dice Score

0.072
(0.329)
−0.000
(0.002)

−0.002
(0.002)
0.090∗∗
(0.045)
0.046
(0.079)

−0.069
(0.110)

−0.035
(0.374)
0.000
(0.002)

−0.051
(0.059)
−0.014
(0.059)

−0.001
(0.079)

This table replicates Table 3B, but estimates all regressions using OLS rather than probit.
p < .05, ∗∗∗ p < .01

∗∗

∗

p < .10,

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 9: Does Dishonesty in the Dice Task Predict
Student Job Preferences?
With Varying Levels of Controls
Wants Government Job
(1)
(2)
Panel A: No Controls
Dice Points

0.002∗∗∗
(0.001)
0.065∗
(0.033)

High Dice Score

Panel B: Separate Controls for Memory and Matrices Tests
Dice Points

0.002∗∗∗
(0.001)

High Dice Score
High Memory Score
High Matrices Score

−0.033
(0.040)
0.030
(0.050)

0.058
(0.037)
−0.034
(0.040)
0.036
(0.050)

This table replicates Table 3A, Columns 1 and 2, with varying control
variables. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 10: Does Dishonesty in the Dice Task Predict Nurse Attendance?
With No Controls
Nurse Sample
Attendance
(1)
(2)
Panel A: No Controls
Dice Points
High Dice Score

−0.000
(0.001)
−0.046
(0.041)

This table replicates Table 3B, Columns 3 and 4,
with varying control variables. ∗ p < .10, ∗∗ p < .05,
∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 11: Placebo Test with Doctors
Doctor Attendance
(1)
Dice Points of Nurses
High Dice Score for Nurses

(2)

0.001
(0.001)
0.019
(0.035)

This table replicates Table 3A, Columns 3 and 4. However, instead of exploring the relationship between a nurses dice score and
her attendance, we explore the relationship between the nurses
dice score and the doctors attendance as a placebo check. ∗
p < .10, ∗∗ p < .05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 12: Do Pro-Social Preferences and Dishonesty Predict
the Students’ Expected Future Wage?
Expected Log Wage
(1)
Points in Dice Task
INR Kept in Pro-Social Preferences Game
Always Lied in Message Game
Joint F-Test Statistic
P-Value

(2)

(3)

(4)

0.011
(0.059)

0.004∗∗∗
(0.001)
−0.000
(0.001)
0.001
(0.058)

∗∗∗

0.004
(0.001)

0.001
(0.001)

3.398
0.032

This table replicates explore the relationship between the experimental measures of pro-social behavior and dishonesty, with expected wage for the student sample. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 13A: The Relationship Between Pro-Social Preferences
and Dishonesty and Wanting a Government Job
Student Sample - OLS
(1)
INR Kept in Pro-Social Preferences Game
Always Lied in Message Game
Points in Dice Task
Joint Wald Test Statistic
P-Value

(2)

(3)

0.010
(0.041)

0.003∗
(0.002)
0.000
(0.041)
0.002∗∗
(0.001)

∗∗

0.003
(0.001)

5.895
0.003

This table replicates Table 4A, but estimates all regressions using OLS rather than probit.
.10, ∗∗ p < .05, ∗∗∗ p < .01

∗

p<

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 13B: The Relationship Between Pro-Social Preferences, Dishonesty,
and Ability and Wanting a Government Job, Student Sample - OLS
(1)
Panel A: Control for Ability
INR Kept in Pro-Social Preferences Game

(2)

0.003∗∗
(0.001)

Always Lied in Message Game

0.007
(0.040)

Points in Dice Task
High Ability
Panel B: Control for Ability Interaction
INR Kept in Pro-Social Preferences Game

0.005
(0.051)

0.010
(0.052)

0.003
(0.002)

Always Lied in Message Game

0.023
(0.047)

Points in Dice Task
High Ability
High Ability x INR Kept
High Ability x Always Lied
High Ability x Dice Points

−0.029
(0.112)
0.001
(0.003)

0.021
(0.053)

−0.038
(0.067)

(3)
0.003∗
(0.002)
−0.003
(0.040)
0.002∗∗
(0.001)
0.003
(0.051)
0.002
(0.002)
0.012
(0.046)
0.002∗
(0.001)
0.028
(0.321)
0.001
(0.003)
−0.034
(0.066)
−0.000
(0.002)

Joint Wald Test Statistic (Interactions Only)
P-Value
This table replicates Table 4B, but estimates all regressions using OLS rather than probit.
p < .05, ∗∗∗ p < .01

∗∗

0.187
0.905
∗

p < .10,

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 14: The Relationship Between Pro-Social Preferences
and Dishonesty and Wanting a Government Job, Student Sample - With No Controls
(1)
INR Kept in Pro-Social Preferences Game

(2)

(3)

0.007
(0.040)

0.003∗
(0.002)
−0.003
(0.040)

∗∗

0.003
(0.002)

Always Lied in Message Game
Points in Dice Task

0.002∗∗
(0.001)

Joint Wald Test Statistic
P-Value

15.940
0.001

This table replicates Table 4A with no control variables.

∗

p < .10,

∗∗

p < .05,

∗∗∗

p < .01

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 15: Do Personality Measures and Corruption Beliefs Predict
Job Preferences and Worker Attendance? With No Controls

(1)

Student Sample

Nurse Sample

Wants Government Job

Attendance

(2)

(3)

(4)

Conscientiousness Index

−0.040
(0.040)

−0.066
(0.044)

Agreeableness Index

−0.040
(0.047)

−0.036
(0.046)

Neuroticism Index

−0.061∗∗
(0.026)

−0.069∗∗∗
(0.026)

External Locus of Control

0.038∗∗∗
(0.013)

0.045∗∗∗
(0.014)
0.068∗∗
(0.034)

Student Has Used Agent

0.057∗
(0.034)

−0.136∗
(0.073)

Classroom Cheating

−0.127∗
(0.075)
−0.005
(0.022)

Promotions Based on Seniority

0.057∗∗∗
(0.021)

Success Requires Contacts

−0.002
(0.020)

−0.008
(0.023)

0.012
(0.024)

−0.026
(0.022)
0.009
(0.024)

−0.003
(0.025)

Bribes are Necessary

−0.052∗∗∗
(0.019)

−0.055∗∗∗
(0.018)

15.020
0.005
0.432
651

70.765
0.000
0.426
620

29.181
0.000
0.430
656

6.848
0.033
0.426
631

This table replicates Table 5 but does not include any controls.

0.022
(0.022)

0.044∗∗
(0.021)

Bribes are Common

Joint Wald Test Statistic
P-Value
Dependent Variable Mean
Observations

(5)

3.802
0.433
0.490
610

APPENDIX FIGURES AND TABLES: NOT FOR PUBLICATION

Appendix Table 16: Do Personality Measures and Corruption Beliefs Predict
Job Preferences and Worker Attendance?
Student Sample With Restricted Definitions
Student Sample
Wants Government Job
(1)

(3)

(4)

0.007
(0.045)

0.003
(0.049)

Agreeableness Index

−0.102∗
(0.057)

−0.129∗∗
(0.061)

Neuroticism Index

−0.087∗∗∗
(0.031)

−0.098∗∗
(0.039)

0.029
(0.019)

0.037∗
(0.022)

Conscientiousness Index

(2)

−0.034
(0.040)

0.032∗∗∗
(0.012)

External Locus of Control
Student Has Used Agent

0.075
(0.059)
−0.115
(0.109)

Classroom Cheating
Promotions Based on Seniority

0.013
(0.030)

Success Requires Contacts

0.023
(0.029)

Bribes are Common

−0.005
(0.028)

Bribes are Necessary

0.007
(0.024)

Joint Wald Test Statistic
P-Value
Dependent Variable Mean
Observations

0.424
469

0.425
628

14.305
0.006
0.421
354

38.690
0.000
0.419
334

This table replicates Table 5, expect that we restrict the sample to individuals who answered all
questions on the locus of control and big 5 personality measures. ∗ p < .10, ∗∗ p < .05, ∗∗∗ p < .01

