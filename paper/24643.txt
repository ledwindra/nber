NBER WORKING PAPER SERIES

PRACTICAL POLICY EVALUATION
Narayana R. Kocherlakota
Working Paper 24643
http://www.nber.org/papers/w24643

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2018

This is a revised version of a paper that was presented at the April 2018 Carnegie-RochesterNYU Conference on Public Policy honoring the contributions of Charles Plosser to economics; I
thank my discussant Harold Cole and the other participants in the conference for their comments.
I also thank the participants at the 2018 Texas Monetary Conference, and in particular my
discussant Stefano Eusepi, for their comments. The views expressed herein are those of the
author and do not necessarily reflect the views of the National Bureau of Economic Research.
The author has disclosed a financial relationship of potential relevance for this research. Further
information is available online at http://www.nber.org/papers/w24643.ack
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Narayana R. Kocherlakota. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.

Practical Policy Evaluation
Narayana R. Kocherlakota
NBER Working Paper No. 24643
May 2018
JEL No. E58,E60,E61
ABSTRACT
In the wake of the Lucas Critique, the study of appropriate macroeconomic policy has largely
focused on the comparison of different regimes/rules. In practice, few policymakers are faced
with making those kinds of choices. In this paper, I examine the problem of a policymaker
making but one in a long sequence of similar decisions (like to raise or cut interest rates by a
quarter percentage point). I model the policymaker as playing a dynamic game against a forwardlooking private sector. My main result is that, under relatively weak conditions, the policymaker's
optimal within-equilibrium response to the current state can be found by applying statistical
regression methods to past macroeconomic data. Theory is only useful as a source of information
about credible functional form restrictions on these regressions. Based on this result, I argue that
macroeconomic policy evaluation intended to be of practical value should rely considerably less
on putatively structural macroeconomic models and considerably more on regression-based
approaches.

Narayana R. Kocherlakota
Department of Economics
University of Rochester
202 Harkness Hall
P.O. Box 270156
Rochester, NY 14627
and NBER
nkocherl@ur.rochester.edu

1

Introduction

There is an enormous academic literature about macroeconomic policy evaluation under the
assumption that private agents are forward-looking. Most of this literature is about the
following kinds of questions:
• What is the optimal specification of date- and state-contingent monetary/fiscal policies?
• What is the optimal specification of a monetary-fiscal policy rule that maps endogenous
and exogenous variables into policy choices?
• Out of the many possible equilibria in an infinite horizon dynamic policy game, which
one is optimal?
Here, the word “optimal” typically refers to “ex-ante” or “steady-state” welfare. The research
addressing these kinds of questions is careful to respond to the Lucas Critique (1976) by using
dynamic stochastic general equilibrium (DSGE) models that are intended to be invariant to
di↵erent choices among possible policy regimes.
These broad questions are indeed important ones for those policymakers who have been
asked to consider a once-and-for-all change in an overarching policy regime. But these situations are rare ones. In practice, policymakers are usually faced with a much more limited
problem: what should they do today, given that their current action is only one of a long
temporal chain of such choices? Thus, at fixed time intervals, central banks choose the level
of short-term interest rates or long-term asset purchases. In the US, the Federal Reserve
decides on an annual basis whether large banks should be allowed to pay out dividends.
Democratically elected governments periodically formulate budget plans.
In this paper, I ask the following question: how should a policymaker, who is making but
one in a long sequence of choices over time, use the available data to arrive at a decision? I
address the question by embedding the policymaker within a standard dynamic policy game
in which he or she makes choices at a point in time, taking into account the response of a

2

forward-looking private sector to those choices. I then analyze within an equilibrium how the
policymaker can make use of available data to estimate his/her best response to the state.
My main result is that, under relatively weak conditions, the policymaker should choose
the action that maximizes the estimated reduced-form regression function of his/her payo↵s
on past choices. By using (game) theory, I show that the policymaker doesn’t need to use
(macroeconomic) theory.
My argument proceeds in two steps based on two assumptions. First, I assume that,
conditional on the information available to the private sector, there is sufficient variation
in the policymaker’s private information about his/her objective (or about the economy)
to induce the policymaker to make all possible policy choices. This full support restriction
ensures that, within an equilibrium, no policy change leads the private sector to update its
beliefs about the policymaker’s future strategy. The immutability of the private sector beliefs
implies that, contrary to the concerns expressed by Lucas (1976), the policymaker can treat
his/her payo↵ as a fixed exogenous function of current policy choices (and the current state).
The second step of the argument concerns the econometrics of estimating this fixed exogenous payo↵ function using past data. I assume that the policymaker’s objective varies due to
non-economic factors that, conditional on his/her available information, only a↵ect economic
outcomes through the policy choice itself. This conditional independence restriction serves to
create a sequence of quasi-experiments that, combined with the earlier full support restriction
about the policymaker’s objective, allows the policymaker to use a nonlinear regression to
identify the impact of any policy choice on his/her payo↵s. The conditional independence
restriction parallels the assumptions made about taste shifters in dynamic discrete choice
econometric models (Aguirregabiria and Mira (2010, p. 40)). However, it is (considerably)
weaker than the unconditional independence assumption typically made about policy error
terms in macroeconometric models (Smets and Wouters (2007, p. 591)).
This two-step argument justifies an approach to policymaking based on nonparametric
regressions when there is an abundance of data about past policy choices and their con-

3

sequences. In the paper, I discuss how theory can be a useful supplementary source of
information to the policymaker when data is scarce (or, relatedly, when the conditional independence restriction is only occasionally satisfied). But the kind of theory needed is quite
di↵erent from the elaborate “structural” models that are typically used by academic macroeconomists. The role of theory is provide functional form restrictions (such as linearity) on
the payo↵ response function of interest. There is no sense in which the needed theory or
model needs to be structural.1
Following the seminal work of Barro and Gordon (1983), there has been a large literature
on dynamic games in macroeconomics. This literature has two distinct goals. Positively, it
seeks to understand properties of the data as properties of equilibria of the dynamic game.
Normatively, it uses the equilibria of the dynamic game as a way to characterize the range
of what can be accomplished in the absence of commitment.
My aim is di↵erent: I use dynamic game theory as a tool to help policymakers and
advisors to figure out how to make choices within the context of a given equilibrium. The
basic intuition of my main result is simple: To solve his/her decision problem, a player
within a game only needs to know how other players will respond to his/her choices. The
decision-maker doesn’t need to know any details about why those other players will respond
the way that they do. The point of this paper is that the government can glean the limited
information that it needs about the private sector’s response function using a simple (possibly
nonlinear) regression. In the language of public economics, the regression function is a
“sufficient statistic” for the policymaker’s decision problem.2
There has been much criticism of modern macroeconomic models in the wake of the finan1
Even the limited role for theory envisioned in this paragraph may exaggerate its importance in reality.
For example, when the global financial crisis hit in 2007, it had few if any immediate predecessors in the
data. But Bernanke (2015) suggests that, in crafting its response to the crisis, the Federal Reserve did not
turn to economic theory. Instead, it relied mainly on the conclusions of Bagehot (1873), which are grounded
in a limited number of observations about the relative efficacy of di↵erent Bank of England interventions in
the prior century. Bernanke’s (2015) justification for the appeal of Bagehot’s prescriptions to the Fed is also
primarily empirical (see, for example, Chapter 3) rather than theoretical. At least in this instance, even a
rather limited set of observations was seen as more useful than a wide body of theory.
2
See Chetty (2009). I thank Mike Waugh for pointing out this key connection to me.

4

cial crisis, in terms of their treatment of financial markets, their treatment of labor markets,
their treatment of heterogeneity, and their treatment of expectations. All of these criticisms
are largely orthogonal to my argument. In the wake of the Lucas Critique, macroeconomists
have designed their models so as to allow policymakers and their advisors to analyze the
impact of regime changes. I o↵er no assessment of the models’ value in that regard. My
main message is that economic theory teaches us that most practical policy questions can
be addressed with only limited reference to these models (or others). Macroeconomists both within and without policy institutions - who want to contribute to the making of policy
should be doing much more research on how best to develop the statistical methods necessary
to answer these “practical policy” questions, instead of continuing to focus almost exclusively
on developing models suitable for addressing “regime change” questions.
My discussion echoes echoes Sims’ (1982) views on the limitations of the relevance of
the Lucas Critique for actual policymaking. Indeed, I view one contribution of my paper
as formalizing some of his core ideas.3 Since Sims wrote, there has been a revolution in
applied microeconomics in the use of atheoretical statistical methods to obtain answers to
important policy questions. This paper argues that a similar change could be of value in
applied macroeconomics.
My discussion is also related to the analysis of “modest” policy interventions in Leeper and
Zha (2003). In contrast to my general game-theoretic approach, they focus on a particular
model of monetary policy and treat policy as being determined by a non-strategic automaton.
Despite this di↵erence in approaches, the thrust of their conclusions is similar to mine.
My main result (that a policymaker can simply use a statistical approach to estimate
his/her best response in the context of a policy game) has antecedents in the monetary
policy learning literature.4 For example, Cho, Sargent, and Williams (CSW) (2002) consider
a central bank in a dynamic monetary policy game that assesses its inflation-unemployment
3

I discuss the connection of my results to the structural vector autoregression literature initiated by Sims
(1980) in Section 6.
4
I thank Jim Bullard and Stefano Eusepi for pointing out these connections to me.

5

trade-o↵ by periodically running a regression on an infinite history of past data. They
note that when the policymaker weights all past observations equally in these regressions,
the unique self-confirming equilibrium is the same as the unique Nash equilibrium when all
features of the game are common knowledge (see page 9 of CSW). This conclusion is an
example of the more general result that I obtain.5
Plosser (2014) argues that the Federal Reserve would be well-served if it were to precommit to an interest rate rule of the kind described by Taylor (1993).6 This paper doesn’t
address this argument. Instead, I simply take it as a feature of the institutional environment
that the central bank has (transitory) discretion at any date.7 The question then is how,
given that discretion, the central bank can best use the available data to achieve its objective.

2

Di↵erences From the Lucas Critique

In this section, I describe the two main di↵erences between the analysis of Lucas (1976) and
mine. The first di↵erence has to do with the di↵ering nature of the policy questions. The
second di↵erence has to do with my use of more modern game theory than was available to
Lucas to model private agent beliefs about public sector behavior.

2.1

Di↵ering Policy Questions

To illustrate how the policy questions in this paper di↵er from those considered by Lucas, it is
useful to consider a version of the permanent income hypothesis that is essentially equivalent
5

To be clear, CSW mainly focus on a version of their model in which the policymaker (suboptimally)
discounts past data. It is this discounting that gives rise to the transitory self-confirming “escapes” from the
Nash equilibrium that are central to their paper.
In CSW’s model, the central bank doesn’t have shocks to its tastes. Instead, the central bank faces a random
error that separates its policy choice and the implementation of that choice. It is these implementation errors
that serve to generate the infinite sequence of “quasi-experiments” that the central bank needs to estimate
the slope of the Phillips curve.
6
See Kocherlakota (2016) for a di↵erent perspective from Plosser’s.
7
Plosser (2013) seems to do the same when discussing the challenges associated with forward guidance.

6

to that in Lucas (1976). I define permanent income by:

ypt = (1

)

1
X

s

Et yt+s ,

s=0

where yt represents after-tax income at date t and the information available at date t embedded in the conditional expectation consists of {yt s }1
s=0 . Consumption at date t is given
by:
ct = kypt + ut
where ut can be viewed as a mean zero, constant variance shock that is i.i.d. over time.
The consumer’s pre-tax income is constant at 2a. At each date t, the government chooses
a lump-sum tax ⌧t so as to maximize the objective function:
(2wt + ⌧t )2

2vt )2

(yt

where the objective shifter wt is a random walk, so that (wt

wt 1 ) is mean zero, constant

variance, and i.i.d. over time and the objective shifter vt is mean zero, constant variance,
and i.i.d. over time.
The solution to the government’s problem is to set ⌧t equal to a vt wt . After-tax income
is then given by:
yt = a + vt + w t

(1)

In this model, as Lucas (1976, p. 26) argues, we can derive a reduced form relating consumption to current and past after-tax incomes:

ct = k(1

)yt + k (1

)

1
X

j

yt

j

+ ut

(2)

j=0

where

is determined by the relative variances of the transitory income shock vt and the

permanent tax shock wt .

7

With one key di↵erence, to which I’ll turn in a moment, the above description follows
Lucas’ (1976) exposition of the permanent income hypothesis. Lucas then turns to a consideration of a wide variety of di↵erent tax policies, like a permanent increase in the level of
taxes or a permanent increase in their volatility. He shows that the impact of such policy
changes cannot be accurately predicted via the reduced form relationship (2).
The key di↵erence lies in how I motivated the government’s choices that give rise to (2).
Lucas posits that the government randomizes taxes in order to generate the law of motion
(1). But he does not explain why the government is randomizing taxes in this fashion. In
contrast, I posit a particular (random) objective for the government. The variation in taxes
that leads to (2) is a consequence of the government’s making its choices according to this
objective.
My formalization of the policy problem imposes a great deal of discipline on the government. The government is required to makes its tax choices periodically. It makes those
choices according to an exogenous objective that it cannot alter. The only policy question
is: how can the government choose ⌧t at each date so as to maximize its objective? None of
the Lucas tax proposals are possible.
I admit that, in my desire to follow Lucas’ lead, I’ve assumed away any dependence of the
government’s objective on the private sector’s response to the policy choice. These responses
do play a key role in my more general analysis. Later, I’ll return to a modified version of the
consumption tax problem that includes this e↵ect.

2.2

Rules and Strategies

Lucas (1980b) argues that: “our ability as economists to predict the responses of agents
rests, in situations where expectations about the future matter, on our understanding of the
stochastic environment agents believe themselves to be operating in. In practice, this limits
the class of policies the consequences of which we can hope to assess in advance to policies
generated by fixed, well understood, relatively permanent rules (or functions relating policy
8

actions taken to the state of the economy).” (emphasis mine). Similar considerations led him
to state in the second part of the Critique that “the only scientific quantitative evaluations
available to us are comparisons of the consequences of alternative policy rules” (emphasis
his). These views have been highly influential in circumscribing the scope of macroeconomic
policy evaluation among academics over the past forty plus years.
In this paper, I diverge considerably from Lucas’ perspective. I don’t require my hypothetical policymaker to commit in advance to a policy rule of the kind that Lucas describes.
Rather, the policymaker is allowed to choose freely at each date. Lucas’ words seem to suggest that there is no systematic way to analyze such a situation. But dynamic game theory
- developed largely in the 1980s after Lucas wrote - provides exactly that kind of systematic
approach. We shall see that in a (time-independent recursive) equilibrium the policymaker
finds it optimal to follow a stable strategy (as a function of the state of the economy). This
strategy is known to the agents in the economy and they make their choices, based on that
knowledge. Within the equilibrium, the policymaker is seen as following a “rule” by the private sector. But that “rule” emerges endogenously from periodic policymaker optimization,
not from exogenously imposed restrictions on policymaker behavior.
How can the policymaker ever contemplate deviations from this strategy that is seen as a
rule by private agents? I allow for shocks to the policymaker’s objective that are unobservable
to the private sector. The private sector can attribute any possible policymaker choice as
being due to a (possibly extreme) realization of this shock. Hence, they never have any
reason to change their (concentrated) beliefs about the policymaker’s strategy.

3

A Dynamic Game and Its Equilibrium

In this section, I set forth a baseline dynamic model of periodic policy choice when the
private sector is forward-looking, and describe a natural notion of recursive equilibrium for
this game. Within this equilibrium, the private sector’s strategy is a fixed invariant function

9

of the current state and the government’s current action. As a result, the government’s
within-equilibrium decision problem depends only on the current state.

3.1

Timing of Play

In this subsection, I describe the timing of play in a given period in a dynamic game between two players: the government and the private sector.8 The description is abstract, in
an attempt to capture many policy choices. However, I frequently connect the high-level
description back to the specific problem of a central bank choosing the short-term interest
rate.
In what follows, I refer to “sets” and to “densities” over those sets. I intend for the former
term to include both discrete sets and compact intervals in Euclidean spaces. I intend for the
latter term to include, correspondingly, both vectors of probability weights and probability
density functions.
Stage 1: Common knowledge of persistent factors.
At the beginning of the period, a state variable x 2 X is common knowledge between the
government and the private sector.
The state variable x captures all relevant information from prior periods that helps predict
the course of the economy in the current period, conditional on the choices of the government.9
The information x could be about endogenous variables (such as asset prices or lagged data
on output in the context of monetary policy) or about exogenous variables. The dimension
of X is potentially large (so it could include microeconomic information like (approximate)
distributions of net worth across households, firms, and/or financial institutions.). Similarly,
this formulation is consistent with the possibility that the evolution of x is influenced by
8

I treat the private sector as a group of agents that are required to co-ordinate their actions. The analysis
can readily be extended to a model in which the private sector is a group of atomless agents who freely choose
to co-ordinate on the same choice (as in Chari and Kehoe (1990)).
9
The state variable x necessarily includes all payo↵-relevant state variables. But it may also include
payo↵-irrelevant state variables that inform the players’ strategies, like past communication or promised
utility.

10

latent state variables, as long as the two players do not have private information about those
latent variables.
Stage 2: Government learns its preferences.
The government privately observes a payo↵ shifter ✓ drawn from the set ⇥ according to the
density p✓ (.|x). This density has full support for all x.
The government privately learns the realization of a shock ✓ that influences its payo↵
function. In the monetary policy context, we could view ✓ as a gauge for how dovish or
hawkish the central bank is. However, ✓ could also measure the central bank’s desire for interest rate smoothing that is independent of their macroeconomic objectives (see the example
in Section 5.2).
Stage 3: Government chooses an action.
The government publicly chooses g from the set G.
In this stage, the government chooses a policy action. In the context of monetary policy,
the action would be the choice of a short-term interest rate target, in combination with some
form of communication (like a policy statement or press release).
Stage 4: Private sector chooses an action.
The private sector publicly chooses an action a from the set A.
The private sector responds to the government’s policy action. The set A could be very
high-dimensional. As we’ll see, the private sector’s action choice also shapes the evolution of
the state variable x.
I treat the private sector as a single agent. But this is without loss of generality in terms of
my main results - I could readily incorporate arbitrary degrees of observable or unobservable
heterogeneity into the description of the private sector. As we will see, from the point of
view of the policymaker, the private sector is simply a multi-armed bandit.

11

Stage 5: The economic outcome is determined.
The economic outcome y is publicly drawn from the set Y according to the density py (.|x, g, a).
The (within-period) economic outcome y is determined. It is potentially a↵ected by the
current state and the actions of the government and private sector.
Conditional on the public state variable x, the taste shifter ✓ is only allowed to a↵ect
py indirectly through the government’s choice of g. This conditional (on x) independence
restriction10 is key in what follows: it means that the variation in g due to ✓ can be seen as
a form of randomized experiment.11
Stage 6: Period payo↵s are realized.
The government realizes its within-period payo↵ w(✓, g, y). The private sector realizes its
within-period payo↵ u(x, a, y).
The private sector payo↵ is a function of its action and the economic outcome. The
government payo↵ is a function of the economic outcome, its choice, and its taste shifter.
The exclusion of the state variable x from the policymaker’s payo↵ function is only for
simplicity and has no material e↵ect on the analysis.
It is often argued that governments need economic models to know what they should
maximize. The government’s payo↵ here should be understood as being determined by
statutory requirements and political factors, not by economic reasoning. Thus, the Federal
Reserve seeks to stabilize inflation and unemployment at their long-run levels because of
Congressional mandates.
10

It may be worth emphasizing that this conditional independence restriction is weaker than the more
standard unconditional independence assumption made about policy errors in macroeconomics. For example,
it allows the taste shifter ✓ to exhibit arbitrary dependence on past economic outcomes through the public
state variable x.
11
As in Imbens and Wooldridge (IW) (2007), there are actually two distinct restrictions being imposed on
the taste shifter ✓. The first is that, conditional on x, the random variable ✓ is stochastically independent
of all other disturbances that influence the economic outcome y. This is what IW call a random assignment
restriction. The second is that changes in the taste shifter ✓ have no direct e↵ect on the economic outcome
y. This is what IW call an exclusion restriction. In the settings of interest to IW, they view the exclusion
restriction as much more substantive. In the context under study in this paper, I see the random assignment
restriction as likely to be the one with more content.

12

Stage 7: Next period’s state is realized.
Next period’s state x0 is publicly drawn from the set X, according to the density px0 (.|x, a, y).
This density has full support over X for all (x, a, y).
The state evolves in response to the private sector choices and outcomes. The exclusion
of g as an influence on px0 is only for simplicity and doesn’t a↵ect the results.

3.2

Building an Equilibrium

Given the above within-period timing, I now turn to the construction of an equilibrium.12
3.2.1

Private Sector Strategy

I start with the private sector. It is forward-looking, in the sense that its overall payo↵ in a
given period is given by the expectation of:
u(.) + U 0 , 0 <

<1

where the within-period payo↵ u was defined above and U 0 is the discounted sum of future
within-period payo↵s. Recall that the private sector’s action choice a↵ects the future state
x0 of the economy. This ability to influence the future, combined with the forward-looking
nature of its objective, means that the private sector’s action in a given state depends on
its beliefs about how future governments will respond to the evolution of the state. In
equilibrium, the government uses a stable (pure) strategy that maps the public state x and
its private information ✓ into an element of G. Consistent with this equilibrium restriction,
the private sector believes that the government uses a strategy ˆ of the form ˆ : X ⇥ ⇥ ! G.
12

The equilibrium concept is Bayesian-Nash. (Perfection has no additional bite because all information
sets of the two players have positive probability.) I focus further on equilibria that are pure strategy, timeindependent, and that depend on the past only through the state variable x. This formulation of equilibrium is
a natural analog of the “recursive equilibrium” concept used extensively by macroeconomists (see Ljungqvist
and Sargent (2018) for many applications). It is distinct from (Bayesian-)Markov equilibrium because the
state x may include payo↵-irrelevant variables.

13

Given those beliefs, and given its observations of the state x and a government action
choice g, the private sector’s problem in any period is given by:

maxa

ˆ

{u(x, a, y) +

Y

ˆ

V (x0 ; ˆ )px0 (x0 |x, a, y)dx0 }py (y|x, g, a)dy

X

Here, V (x0 ; ˆ ) represents the private sector’s continuation value, given that it observes the
public state x0 and believes that the government has a time-invariant strategy ˆ . Within
a period, the government chooses its action before the private sector does. As a result,
the private sector beliefs about the government’s strategy only matter because the private
sector is forward-looking, which means that ˆ a↵ects the private sector’s problem through
the continuation value function.
The solution to this maximization problem depends on the private sector’s information
(x, g) and on the private sector’s beliefs ˆ about the government’s strategy. Hence, the
solution can be denoted ↵⇤ (x, g; b).

The value function V satisfies a natural recursive relationship. First, we define ū(x; ˆ ) to

be the expectation of the private sector’s within-period payo↵:
u(x, ↵⇤ (x, ˆ (x, ✓); ˆ ), y)

over the randomness generated by (✓, y). (Note this expectation is based on the private
sector’s belief that, in the future, it will use the strategy ↵⇤ .) We calculate that expectation
by using the product of the conditional densities:
py (y|x, (x, ✓), ↵⇤ (x, ˆ (x, ✓); ˆ ))
p✓ (✓|x)

14

Then, the value function V (x; ˆ ) is equal to the expectation of:
ū(x; ˆ ) + V (x0 ; ˆ ).

over the randomness generated by x0 , conditional on x. We calculate the expectation using
the product of the conditional densities:
px0 (x0 |x, ↵⇤ (x, ˆ (x, ✓); ˆ ), y)
py (y|x, ˆ (x, ✓), ↵⇤ (x, ˆ (x, ✓); ˆ ))
p✓ (.|x)

3.2.2

Full Support

The private sector’s beliefs about the government’s strategy are concentrated on the single
function ˆ . This is how Nash equilibrium and its refinements work: every player’s strategy is
common knowledge. It follows that the private sector will never change its beliefs about the
government’s strategy as long as the government’s (public) actions have positive probability
given the information known to the private sector. That kind of consistency is ensured if the
private sector’s belief ˆ has full support in the sense that:

8x 2 X and 8g 2 G, 9✓ 2 ⇥ s.t. ˆ (x, ✓) = g
In words, the strategy ˆ has full support if the private sector can always rationalize any
observed action choice g as being due to a particular realization of the government’s private
information about its payo↵s.13
The full support requirement is important because it serves to limit the history dependence
13

In the next section, I introduce the possibility that the government has information about the economy
that is not known to the private sector. In this context, the full support restriction is weaker: it only requires
that the private sector can always rationalize any choice by the government as being due to some realization
of the government’s private information about its payo↵s or the economy.

15

of equilibrium strategies. Suppose ˆ didn’t satisfy the full support requirement. Then, in
any period, the private sector might see a history of government choices that is inconsistent
with the government’s having always used the strategy ˆ . In any such history (and in
any continuation of any such history), the private sector’s beliefs about future government
choices may di↵er from ˆ . The private sector’s strategy could then depend on the full history
of government choices, not just on the current choice.
3.2.3

The Government’s Strategy

I turn next to the government. For now, I’ll assume that the government is myopic in each
period; I’ll discuss the (minor) consequences of relaxing that assumption later.
Because the private sector makes its choices after the government in each period, the
government must form beliefs about the private sector’s strategy (that is, how it will respond
to various choices of the government). I assume the government believes that the private
sector’s strategy is ↵
ˆ , where:
↵
ˆ :X ⇥G!A
Thus, the government’s problem in any period, given its observations of (x, ✓), is to choose
g to solve:
maxg2G

ˆ

w(✓, g, y)py (y|x, g, ↵
ˆ (x, g))dy

Y

The resulting strategy can be written as a function

⇤

(x, ✓; ↵
ˆ ) of the government’s information

(x, ✓), given the government’s beliefs ↵
ˆ about the private sector’s strategy.
Above, I stressed that the private sector’s beliefs are concentrated on a strategy for the
government that has full support. In what follows, I simply assume that this full support
restriction is satisfied in equilibrium. But it is straightforward to ground it on primitives.
The key is that the government cares - at least somewhat - about its choice g for reasons
other than achieving a particular economic outcome. For example, suppose G = {g 1 , g 2 } and
the government’s di↵erential within-period payo↵ between the two elements of G is given by

16

w+ (x, y) + ✓, where ✓ is normally distributed with mean zero and positive variance
regardless of the private sector’s strategy and regardless of how small

2

. Then,

is, there is a positive

probability that the government finds it optimal to choose g1 and a positive probability that
the government finds it optimal to choose g2 . This is exactly what is meant by full support.14
3.2.4

Equilibrium

An equilibrium is a government strategy
•

⇤

⇤

and a private sector strategy ↵⇤ such that:

(x, ✓; ↵⇤ ) solves the government’s problem for all (x, ✓), given that the government

believes that the private sector uses strategy ↵⇤ .
• ↵⇤ (x, g;

⇤

) solves the private sector’s problem for all (x, g), given that the private sector

believes that the government uses strategy
function V (.;
•

⇤

and the private sector’s continuation value

) is defined as above.

has full support (so that, for any x in X and any g in G, there exists ✓ in ⇥ such

that

3.3

⇤

⇤

⇤

(x, ✓) = g).

Discussion

The above describes a dynamic game between the government and the private sector, in
which both make periodic choices. Within the equilibrium to the game, the government and
the private sector follow time-invariant strategies (that map their payo↵-relevant information
into actions). These strategies are commonly known.15
Within this equilibrium, given its observations (x, ✓), the government contemplates choosing among all possible g in G. In his Critique, Lucas expresses concern that deviations from
past behavior on the part of the government will lead to confusion in the private sector about
14

Similar assumptions about primitives could be used to ensure that any self-confirming equilibrium outcome (in the sense of Fudenberg and Levine (1993)) is a Nash equilibrium outcome.
15
I make no attempt to endogenize the learning of this equilibrium on the part of the private sector.
Nachbar (1997) suggests that doing so might well be problematic.

17

the government’s future strategy. But within an equilibrium to the above game, this potential
confusion simply can’t happen: it is common knowledge between the players how the private
sector updates its beliefs in response to any government action choice. This statement is true
even if the government’s strategy doesn’t have full support. With full support, the relevant
updating is considerably simplified: no matter what the government does, the private sector
never changes its beliefs about the government’s future strategy.
All persistent factors in the economy are embedded in the publicly observable state variable x. Later, I’ll discuss the consequences of relaxing that assumption, so that, conditional
on the public state, the government’s (privately known) payo↵ shifter ✓ is persistent. As we
shall see, that persistence makes the private sector’s beliefs about ✓ into a key state variable
in the problems of both the private sector and the government.

4

Econometrics of the Government’s Problem

Within the above equilibrium, the government enters period t. It observes (xt , ✓t ). Recall
that, in equilibrium, the government’s problem is to solve:

maxg2G ⇧G (g; xt , ✓t , ↵
ˆ)

where:
⇧G (g; xt , ✓t , ↵
ˆ) =

ˆ

w(✓t , y, g)py (y|xt , g, ↵
ˆ (xt , g))dy

Y

Here, ↵
ˆ represents the private sector’s response to government choices and py is the (exogenous) density of the economic outcome, conditional on government/private sector choices.
Within an equilibrium, the government knows that ⇧G is a fixed function of (g, xt , ✓t ). In
this section, I turn to the econometrics of using past data to figure out ⇧G . Accordingly, I
now suppose that the government in period t doesn’t know py or ↵
ˆ . Rather, it has an infinite

18

data set:
(xt s , yt

1
s 1 , gt s 1 )s=0

of current and past realizations of the public state x, past realizations of the economic outcome
y, and the government’s past actions. (In an appendix, I consider some of the important and
interesting complications associated with having a finite sample.) The data set doesn’t (need
to) include the past realizations of the government’s payo↵ shifter ✓. However, I do suppose
that the government knows ✓t - that is, its current within-period payo↵ as a function of its
choice and the economic outcome (g, y).
In this section, I address the question of how the government can use these data to solve
its problem. I demonstrate the main result in the paper: the decision problem can be solved
by the government’s:
• using observations in which x is close to xt
• running a nonlinear regression of its past payo↵s (evaluated using the current realization
of ✓t ) on its past choices of g
• and then choosing the value of g that maximizes this regression function.
Thus, the government can solve its problem through purely statistical methods without any
knowledge of structural elements like py or u.

4.1

Conditionally Random Government Choices

The government’s objective is the expectation of its payo↵, given (xt , ✓t ), for each possible
choice of g. The goal is to use past data to estimate this conditional expectation. In order
to do so, I assume that, as is true within a recursive equilibrium, the private sector’s past
strategy ↵⇤ is the same as the private sector’s current strategy ↵
ˆ.
This estimation poses a potential endogeneity problem. The government’s various past
choices of g are associated with the variables (x, ✓) di↵ering from the current observation
19

(xt , ✓t ). These di↵erent realizations of (x, ✓) are, in turn, associated with di↵erent conditional
densities for y. The government needs to distinguish the possible e↵ects of (x, ✓) on y from
the e↵ects of g itself.
However, in the description of stage 5 of the game, we imposed the restriction that the
density of the economic outcome y, conditional on the state xt , only depends on the payo↵
shifter ✓t through the government’s choice of g. This conditional independence restriction
implies we can rewrite the government’s period t objective for any g as:

⇧G (g; xt , ✓t , ↵
ˆ ) = E(w(✓t ,

⇤

(x, ✓), y)|x = xt ,

where the expectation is over the realizations of (✓, y) and

⇤

(x, ✓) = g; ↵
ˆ)

⇤

is the past strategy of the

government.16 This converts the government’s policy projection problem (what should be
projected to happen if it chooses g?) into a conditional expectation (what should be expected
to happen in the event that its strategy implies a choice of g?). In the remainder of this
section, I show how this result implies that the government can use regression methods to
find the solution to its problem, even though it doesn’t know py or ↵
ˆ.
4.1.1

Finite Sets

In this subsection, I assume that the sets (X, G) are both finite.17
Let Sg = {sn }1
n=1 be a subset of the natural numbers such that:
(xt

sn , g t sn )

= (xt , g).

The “for any g” part of this statement relies on the government’s past strategy ⇤ having full support.
This restriction is satisfied within an equilibrium and is verifiable using the infinite sample.
17
In the case that G has two elements, this subsection becomes a special case of the vast treatment e↵ects
literature. The policy decision g = 1 can be viewed as the economy being assigned to “treatment” while
the policy decision g = 0 can be viewed as an assignment to “no treatment”. The conditional independence assumption on ✓ is then that the decision to “treat”, conditional on x, is independent of all other
factors that a↵ect the economic outcome. As is well-known, under this assumption, the expected impact of
treatment relative to non-treatment is equal to the di↵erence in the average outcomes between treated and
non-treatment.
16

20

The set Sg is the subset of past data in which the realization of x was the same as in the
current period and the government’s action choice was g. The full support assumptions made
about px0 (in stage 7) of the dynamic game, combined with the full support assumption about
the government’s past strategy
The sequence {yt

1
sn }n=1

⇤

, ensure that Sg has an infinite number of observations.

is a countably infinite sequence of i.i.d. draws from the density:

py (y|xt , g, ↵
ˆ (xt , g))

Consider the sample average:

w̄g = limN !1

1
X

w(✓t , g, yt

sn )/N

n=1

This infinite-sample average of i.i.d. draws is equal to the expectation of the government’s
within-period payo↵, conditional on xt and the government’s choice being g. Hence, we can
conclude that:

w̄g = E(w(✓t ,

⇤

(xt , ✓), y)|x = xt ,

⇤

(xt , ✓) = g; ↵
ˆ)

= ⇧G (g; xt , ✓t , ↵
ˆ)

The government can then choose g by looking for the value of g that delivers the highest w̄g .
To summarize: to evaluate a particular option g, the government:
1. discards all past observations except those with the same x as it observes today and
with the same g as it is considering. These past observations likely are based on a
di↵erent ✓ than the current ✓t . But that di↵erent ✓ doesn’t a↵ect the empirical density
of the y’s.
2. transforms the economic outcome y for each observation in the retained data into a
payo↵ w, using the current realization of ✓ and the g under consideration.

21

3. average the resulting w’s.
The government then picks the option g that delivers the highest average in step 3.
4.1.2

Interval Case

I now turn to the case in which the sets (X, G) are compact intervals in Euclidean spaces.
Given the current state xt , let ⇤(✏) be a neighborhood of size ✏ around (xt ). Let S✏ (xt ) =
{sn }1
n=1 be the subset of the natural numbers such that (xt

sn )

2 ⇤(✏). As argued above,

S✏ (xt ) has an infinite number of observations. To simplify the argument, I assume that ✏ is
sufficiently small that we can view the density of (✓, y), conditional on x, as being the same
for all x in ⇤(✏).
Consider the data set:
(Wn , gt

1
sn )n=1

where:

Wn ⌘ w(✓t , gt

s n , yt s n )

Note that the payo↵ Wn is defined using the current realization of ✓. Given the assumption
that (✓t

s n , yt s n )

is independent of (xt

sn )

in ⇤(✏), it follows that {Wn , gt

1
sn }n=1

is a sequence

of i.i.d. vectors. We can use this data set to estimate a nonlinear regression of W on g:

W = h(g; xt ) + u

where u is mean-independent of g. Note that, given xt , the regression function h is identified
because of the full support restriction on the government’s strategy.
The regression function h(g; xt ) measures the expectation of the government’s payo↵,

22

⇤

conditional on x equalling xt and the government’s choice
⇤

h(g; xt ) = E(w(✓t ,

(xt , ✓), y)|x = xt ,

⇤

(xt , ✓t ) equalling g. Hence:

(xt , ✓) = g; ↵
ˆ)

= ⇧G (g; xt , ✓t , ↵
ˆ)

It follows that the government can solve its problem by choosing the value of g that optimizes
the regression function h(g; xt ).
4.1.3

Linear-Quadratic Case

In this subsection, I illustrate the value of functional form restrictions via a linear-quadratic
example. It serves as the basis of the two specific economic cases that I analyze later.
Suppose it is known that the public state {xt }1
t=1 follows an exogenous stochastic process.
As well, it is known that the economic outcome y is an affine function of (x, g, a) and a
disturbance term:
y=

0

+

xx

+

gg

+

aa

+"

where " has mean zero and constant variance. The government’s payo↵ is given by:

(g

✓)2

(y

ȳ)2

where ✓ is a non-degenerate shock with mean bx that is conditionally (on x) independent of
". Finally, the government believes that the endogenous private sector strategy is linear:

↵
ˆ (x, g; ˆ ) = ↵0 + ↵x x + ↵g g

This belief is correct if the private sector’s objective is quadratic in (x, a, y) and it believes
that the government’s strategy is using a strategy that is linear in (x, ✓).
Given the linear strategy of the private sector, the economic outcome is affine in the

23

current state x and the government’s choice g:

y=

0
0

+

0
xx

+

0
gg

+"

Suppose that, in the past, the government’s strategy has put positive weight on ✓. Then, x
and g are imperfectly correlated. The government can consistently estimate

0

by regressing y

on (x, g). It can then choose g so as to maximize its objective, taking this estimated response
as given:
maxg

(g

✓)2

(

0
0

+

0
xx

+

0
gg

ȳ)2

Note the solution to this maximization problem does in fact put nonzero weights on both
(x, ✓). So, assuming that the government has always behaved optimally in the past, the
government can identify the e↵ect of g on y by regressing y on (g, x).
4.1.4

Summary

In the context of the dynamic policy game described in the prior section, I contemplated a
government with an infinite amount of data about its past choices (g), past states (x) and
past economic outcomes (y). I showed that the government can solve for its best response to
the private sector’s strategy using a purely statistical two-step procedure. First, it regresses
past economic outcomes (transformed through its current payo↵ function w(✓t , .)) on its past
choices. Second, it finds the choice of g that maximizes this estimated regression function.
The procedure works (in the sense of solving the government’s decision problem in any
period) in the context of the equilibrium defined in the prior section. But it’s more generally
applicable: the government can use this procedure to find its best response as long as:
• the private sector’s current strategy is the same as its past strategy
• and the government’s past strategy has full support conditional on publicly observable
information

24

The key requirement is that, in the past data, the government’s action varies over its action
set G because of a taste shifter that, conditional on the publicly observable state xt , only
a↵ects the economic outcome through the government’s policy choice. This conditional independence restriction allows the government to use the estimated regression function as a
way to do conditional policy projections.

4.2

A Potential Role for Theory

In the prior subsections, I described how the government can estimate its objective function
⇧G using a nonparametric regression. These nonparametric methods essentially threw out
all past data in which the realization of x di↵ered (too much) from the current observation
xt . I now turn to how the restrictions implied by theory or other auxiliary information can
potentially allow the government to use past data when the state x di↵ers markedly from its
current value. These kinds of restrictions will turn out to be helpful when the government’s
data is more limited or when the conditional independence restriction is only satisfied for
some values of x. However, there is no need for the relevant theory to be “structural”, in the
sense that its fundamental parameters are invariant to policy regime changes.
To recall (yet again), the government’s objective function takes the form:

⇧G (g; xt , ✓t , ↵
ˆ) =

ˆ

w(✓t , y, g)py (y|xt , g, ↵
ˆ (xt , g; ˆ ))dy

Y

when its information set is (xt , ✓t ). Here, ↵
ˆ is the private sector’s strategy determined by its
optimization problem. In many situations, theory (combined with other data/information)
could be used to restrict the form of the private sector’s objective. There may also be
theoretical or data-based restrictions on the conditional density py that describes the response
of the economic outcome to the actions of the government and public sector. Collectively,
these various restrictions serve to connect the government’s objective function at di↵erent
realizations of (x, ✓).

25

At an abstract level, we can capture these connections by requiring ⇧G to be indexed by
2 B, so that, given ✓t , there exists a function ⌥ : B ⇥ X ⇥ G ! R

a low-dimensional vector
such that:

⌥( , x̄, g) =

ˆ

w(✓t , y, g)py (y|x̄, g, ↵
ˆ (x̄, g; ˆ ))dy

Y

for all (x̄, g). As above, the conditional independence restriction implies that:

⌥( , x̄, g) = E(w(✓t ,

⇤

(x, ✓), y)|x = x̄,

⇤

(x, ✓) = g; ↵
ˆ)

for all (x̄, g), so that ⌥( , .) is the nonlinear regression function of w on g, given that x = x̄.
There are many ways to estimate

given the large data set available to the government.

Here’s one that is based on method of moments. Form the data set (Wn , gt

1
n , xt n )n=1 ,

where:
Wn = w(✓t , gt

n , yt n )

The government can then look for the value of ˆ in B that satisfies moment conditions of
the kind:
N

1

N
X
n=1

for various

[Wn

⌥( ˆ, xt

n , gt n )]1{(xt

n ,gt n )2

}

=0

that are (Borel) subsets of (X ⇥G). With that estimate in hand, the government

can solve its problem by finding the value of g that maximizes ⌥( ˆ, g, xt ) (that is, by setting
x = xt ).
In this fashion, theory can play a role in helping the government solve its problem. To
be clear, that role is certainly not a star turn. The government is not looking to build an
elaborate theoretical edifice that can be described as structural in some sense. In particular,
the government is completely uninterested in the economic mechanisms behind the past data
on (g, x). Rather, it is using theory as a source of plausible functional form restrictions.
These kinds of auxiliary restrictions can also make it possible for the government to proceed when the conditional independence restriction only holds in some states. In particular,

26

suppose that:
py (.|x, ✓, g, a)
is independent of ✓ when x is in E, but may depend on ✓ if x is not in E. In this case, the
variation in ✓ is only generating a policy “experiment” for those x in E. The key question is
whether it is possible to identify
is, is there a unique

⇤

using only the data from these “experiment” states - that

in B such that:

⌥( , x̄, g) =

ˆ

w(✓t , y, g)py (y|x̄, g, ↵
ˆ (x̄, g; ˆ ))dy

Y

for all (x̄, g) such that x̄ is in E. If so, the government can discard the past observations in
which the economic state xt
estimate

⇤

n

is not in E, and then use the remaining data, as above, to

. It can then find the optimal policy choice by maximizing ⌥(

⇤

, xt , g),. even if

xt is not in E. The government is using the additional restrictions provided by theory (or
other) information to substitute for the lack of experimental variation in g.

4.3

Additional Government Information

The above analysis assumed that the government’s information about the economy was limited to what is publicly observable (x). Suppose instead that the government also privately
observes a factor ⇠ such that the conditional density py depends in some fashion on ⇠:

py (y|x, ⇠, g, a)

and that ⇠ is (imperfectly) correlated with ✓. This interaction between the government’s taste
shifter and the conditional density of y would eliminate the (conditional on x) “experimental”
nature of the government’s past policy choices.
In this case, we need to expand the definition of the state to include ⇠. In particular,
suppose that, conditional on (x, ⇠), ✓ a↵ects y only through g and that, conditional on (x, ⇠),

27

the government’s strategy

⇤

(x, ., ⇠) has full support over G. Then, the government can, as

above, solve its problem by using data in which (x, ⇠) is close to (xt , ⇠t ) and regressing its past
payo↵s on its past choices.18 The conditioning in the conditional independence restriction is
with respect to the government’s information set.

4.4

Why Not “Structural”?

The government can identify its best response using a simple regression approach. Why
doesn’t it need or want to use a more structural approach?
As section 1.2.1 describes, the private sector’s strategy depends on its beliefs about the
government’s strategy. In much of academic macroeconomics, it is presumed that the government can influence those private sector beliefs through credible announcements or overt
commitments. Most academic analyses of policy hinge then on how the private sector’s
strategy would change if its beliefs about the government’s strategy were to change. But
gauging that strategic response requires the government to know many details about the
private sector, like its within-period payo↵ function, its discount factor, and the nature of
state-to-state transitions. More broadly, the government needs to know elements of the private sector’s problem that are structural, in the sense that they are invariant to its beliefs
about the government’s strategy.
In contrast, I consider the government’s decision problem within an equilibrium (as defined
in the prior section). In this decision problem, the government has no ability to influence
the beliefs or strategy of the private sector. Instead, the government’s problem is to choose
its best action taking those beliefs/strategy as given. As long as those beliefs/strategy don’t
change over time, this problem can be e↵ectively addressed using purely statistical methods.
18

In this case, the government’s choice of g typically conveys information to the private sector about ⇠. This
information about y influences the private sector’s decision problem. However, in equilibrium, the private
sector finds it optimal to follow a strategy that is a time-invariant function of (x, g).

28

4.5

Why the Rules Approach is Flawed

It is common to recommend that the government should use the past data in a di↵erent
fashion: estimate its past strategy/rule and then play according to that rule. But there are
two problems with this approach.
First, what does it mean to “estimate” the past rule? Presumably, it means using a
(possibly nonlinear) regression to decompose the government’s past policy choices:

gt

n

= ⇡(xt

n)

+ ✏t

n

into a systematic part (due to the publicly observable information x) and a non-systematic
part ✏, which is mean-independent of x. The recommendation would then be to play according
to the rule ⇡(xt ) today. But this recommendation ignores the government’s taste shifter ✓
and the government’s private information ⇠ about the economy. There is a reason why the
error term ✏ exists in the past data, and the government needs to take account of that when
making its current decision.
Second, and perhaps more importantly, there is no reason why the current government
should assume that its past behavior was in fact optimal. The rules-based approach locks
the government into repeating any past mistakes. The statistical approach described above
instead allows the government to improve on any past errors.

5

Examples

In this section, I provide two linear-quadratic examples of the more general analysis in the
prior section. The first is a simple permanent income hypothesis example of the kind discussed
in Section 2. The second is a New Keynesian monetary example. The main conclusion in
both examples is that the government can use a reduced-form regression to solve its withinequilibrium decision problem without knowing the “structural” or “deep” parameters.

29

I don’t require the private sector’s beliefs ˆ about the government’s strategy to be the
same as the government’s actual strategy

in either example. I could add this (equilibrium)

restriction without a↵ecting the argument. What matters is that the private sector believes
that the government’s strategy has full support. This aspect of the private sector’s beliefs
ensures that they are independent of the government’s choices.

5.1

Consumption Tax Example

I posit that pre-tax income (relative to its mean) follows:

et = et

1

+ ⌘t

where {⌘t }1
t=1 is i.i.d.. Current consumption (relative to its mean) is given by:
ct = aytp + byt

where yt is after-tax income and:
ytp = (1

)Et

1
X

s

yt+s

s=0

is permanent after-tax income. The government’s objective is

c2t

(⌧t

ut )2 , where ut is

i.i.d. over time.
The private sector assumes that the government will use a strategy of the form:

⌧t = Âet + B̂ut

in the future. Given those beliefs, the private sector’s consumption in period t is given by a

30

linear function19 :
c t = AP S e t + B P S ⌧ t
The key to the government’s problem is that this function is invariant to its choice of ⌧t . This
is because the private sector ascribes di↵erent ⌧t ’s, conditional on et , to the government’s
having seen di↵erent realizations of ut .
The government regresses past ct on past (et , ⌧t ) to uncover the coefficients (AP S , BP S )
in the private sector’s linear strategy. It then optimizes:
(BP S ⌧t + AP S et )2

(⌧t

ut ) 2

with respect to ⌧t . This gives rise to a linear function20 :

⌧t = Aet + But

where B 6= 0. Thus, as surmised by the private sector, the government uses a linear strategy
that puts non-zero weight on both (et , ut ).
Note that, in solving its decision problem, the government only needs to know the reducedform coefficients (AP S , BP S ). It doesn’t need to know how the private sector’s strategy depends on its beliefs Â.
19
20

Specifically, AP S = a(1
Â) + b and BP S = (a(1
) + b).
More specifically, A = AP S BP S /(1 + BP2 S ) and B = 1/(BP2 S + 1).

31

5.2

Monetary Policy Example

In this example, I consider a simple log-linearized New Keynesian model in which:

yt = Et yt+1

(RtCB

rtnat

Et ⇡t+1 )

⇡t = yt + µt
nat
Et rt+1
= (1

⇢nat )r̄ + ⇢nat rtnat

Et µt+1 = ⇢µ µt
Here, the variable rtnat is the natural real rate of interest and µt is the firms’ mark-up shock;
they’re exogenous variables that are commonly known to evolve according to first-order
autoregressive processes. (However, the coefficients of these processes are not known to the
government.) The variables (yt , ⇡t ) represent log-linearized output gaps and inflation; they’re
endogenous choices of the private sector in period t. The variable RtCB is the nominal interest
rate to be chosen by the central bank in period t. (I’ve left out the forward-looking part of the
New Keynesian Phillips curve. This can be rationalized through the inflexible firms’ setting
their prices equal to last period’s price level, as opposed to their own prices.)
I assume that the central bank wants to maximize:
yt2

⇡t2

(RtCB

r̄

✏t ) 2

Here, besides eliminating output gaps and non-zero inflation, the central bank wants to keep
nominal interest rates stable around a target level that is subject to mean zero shocks in the
form of ✏t . These shocks are i.i.d. over time and have support equal to the real line.
I first solve for the representative household’s strategy, as a linear function of the state
variable (µt , rtnat ) and the central bank’s choice RtCB . To that end, re-write the representative

32

household’s Euler equation in terms of y as:
RtCB + rtnat + ⇢µ µt + (1 + )Et yt+1

yt =

Suppose that the household believes that the central bank’s period (t + 1) strategy is linear:
CB
nat
CB
CB
Rt+1
= Â0 + ÂCB
1 rt+1 + Â2 µt+1 + Â3 ✏t+1

where ÂCB
> 0. Given these beliefs, there is a time-invariant linear output strategy:
3

H nat
H CB
yt = AH
+ AH
0 + A1 rt
2 µt + A3 Rt

that satisfies the Euler equation.21
Next, I assume that the central bank has an infinite data set of current and past observations of the exogenous variables (rtnats , µt s )1
s=0 and past observations of the endogenous variables (yt s , RtCBs )1
s=1 . Given these data, the central bank regresses yt

s

on contem-

poraneous (rtnats , µt s , RtCBs ). This regression identifies the household’s strategic parameters
H
H
H
(AH
0 , A1 , A2 , A3 ) as long as the central bank’s past strategy puts non-zero weight on ✏t s ,

so that there is variation in RtCBs that is independent of the variation in the state variables
(rtnats , µt s ). The central bank can identify  by regressing ⇡t
21

s

on yt

s

and µt s .

H
H
H
In particular, the parameters (AH
0 , A1 , A2 , A3 ) satisfy:
H nat
H CB
AH
+ AH
0 + A1 r t
2 µ t + A3 R t

=

H
RtCB + rtnat + ⇢µ µt + (1 + )[AH
0 + A1 ((1

=

H
CB
⇢nat )r̄ + ⇢nat rtnat ) + AH
2 ⇢µ µt + A3 Et Rt+1 ]

H
RtCB + rtnat + ⇢µ µt + (1 + )[AH
0 + A1 ((1
CB
+(1 + )AH
+ ÂCB
3 (Â0
1 ((1

⇢nat )r̄ + ⇢nat rtnat ) + AH
2 ⇢µ µ t ]
⇢nat )r̄ + ⇢nat rtnat ) + ÂCB
2 ⇢µ µ t )

This equation implies, via the method of undetermined coefficients, that:
H
H
AH
0 = (1 + )[A0 + A1 (1

AH
1
AH
2
AH
3

=

+ (1 +

= ⇢µ + (1

CB
CB
⇢nat )r̄ + AH
+ AH
3 Â0
3 Â1 (1

H CB
)[AH
1 ⇢nat + A3 Â1 ⇢nat ]
H CB
+ )[AH
2 ⇢µ + A3 Â2 ⇢µ ]

=

33

⇢nat )r̄]

Given that information from its past data, the central bank can find its optimal RtCB in
the current period by solving the maximization problem:

max

(RtCB

r̄

✏t ) 2

⇡t2

yt2

subject to the constraints that:
H nat
H CB
yt = AH
+ AH
0 + A1 rt
2 µ t + A3 R t

⇡t = yt + µt

. It is readily shown that the solution to this optimization problem takes the form::
nat
CB
RtCB = ACB
+ ACB
+ ACB
0
1 rt
2 µt + A3 ✏t

where ACB
is non-zero. Hence, the central bank does find it optimal to use a strategy with
3
full support.22
As in the prior example, the government can solve its problems using only the reducedH
H
H
form coefficients (AH
0 , A1 , A2 , A3 ). It doesn’t need to know those coefficients relate to the
CB
CB
CB
private sector’s beliefs (ÂCB
0 , Â1 , Â2 , Â3 ) or other more structural aspects of the envi-

ronment.

6

Discussion

In this section, I discuss some extensions and relate the above discussion to prior literature.
22

Note that the central bank’s strategy can be written in a Taylor Rule-like representation:
RtCB = r̄



1

AH
3 ⇡t

1

AH
3 yt + ✏ t

However, this representation is misleading in a couple of related ways. First, the central bank is choosing
its policy instrument before the private sector variables (⇡t , yt ) are determined. Second, because (⇡t , yt ) are
determined after RtCB , the error term in this representation is necessarily correlated with the private sector
variables.

34

6.1

Relationship to Structural Vector Autoregressions

The statistical approach that I discuss above is reminiscent of what has been done in the
structural vector autoregression (SVAR) literature initiated by Sims (1980). But I see at
least three important di↵erences between that literature23 and my own discussion.
First, I provide a game-theoretic justification for why a government faced with a periodic
policy choice can use a purely statistical approach to estimate its best response at each date.
I have not seen that done for the SVAR approach.
Second, the SVAR literature typically is based on the perspective of an economist who
does not know the information set of the government. Thus, from the SVAR perspective,
the relevant notion of a shock in this model is the unanticipated component of government
policy:
✏t ⌘ g t

E(gt |xt )

given the information xt available to the public sector. But, as discussed in Section 4.2, the
government might have more information (⇠) about the evolution of the economy than what is
in x. This kind of information would, from the SVAR perspective, make ✏ a “non-structural”
innovation.
In contrast, in this paper the relevant perspective is that of the policymaker and his/her
advisers. It seems plausible that they will know their own information (that is, what’s
included in the public shock xt and any private shock ⇠t ) about the economy, and so be able
to tell what past policy variation can be ascribed to that information. To be clear, I don’t
mean to suggest that the conditional independence restriction imposed on ✓ in this paper is
non-substantive - but it does seem considerably more plausible than the typical identification
restrictions in the SVAR literature. (This policymaker-oriented attack on the identification
problem is similar to the narrative approach to identification used by Romer and Romer
(1989).)
Finally, the SVAR literature is overly ambitious in terms of its goals relative to what
23

See Stock and Watson (2016) for an extensive recent summary.

35

is needed here. The SVAR literature typically attempts to identify the response of a large
number of economic variables to an identified policy shock. Here, because I am focused on
the policymaker’s problem, there is only one variable of interest: the policymaker’s payo↵.
As we saw when we discussed the role of theory in Section 4.1.3, the policymaker has no
interest in the statistical or economic details of how past data on its past choices or the
economic state were generated. This wedding between estimation and decision-making plays
an even larger role in the appendix where I discuss finite sample issues.

6.2

Reputation: Hidden Persistence in Government Tastes

In the description of the game, the density of the policy shifter ✓t depends only on the
publicly observable variable xt . This doesn’t mean that ✓ lacks temporal dependence. But
it does mean that any temporal dependence in ✓t is encoded in the publicly observable xt .
As a result, at the beginning of each period, all agents - public and private - agree on the
likelihoods of di↵erent realizations of ✓.
Suppose alternatively that, conditional on the public state x, the taste shifter ✓ has
persistence in the form of a Markov structure. The government’s knowledge of ✓t then
provides it with superior knowledge about the future evolution of the policy taster shifter.
The private sector’s choice of its action at would depend on its possibly imperfect beliefs
about ✓t (updated after it observes the government’s choice of gt ). Thus, the translation of
any government policy choice into the density of y now depends on the private sector’s beliefs
about ✓t .
We can only treat this case if the government, at the time of making its choice, knows the
private sector’s beliefs about ✓t . Without this knowledge, the government’s strategy could
depend on the full history of its actions, because that full history is shaping the private
sector’s beliefs about the current value of ✓t . We could no longer view the government’s
strategy as being recursive in any simply described state.
So, to extend the results to allow for hidden persistence, we need to augment the public
36

state variable xt with a public measure of the private sector’s beliefs about ✓t . Once we do so,
the main result (that the government can identify its optimal choice using a simple regression
of its payo↵ on g, conditional on x) can be extended to this case. In the monetary policy
context, I view asset prices and/or surveys about future monetary policy as containing the
relevant kind of information.24

6.3

Private Sector Private Information

In the above discussion. the private sector’s equilibrium strategy ↵⇤ is a deterministic function of its information xt and gt . It is easy to extend the baseline model to relax this (possibly
overly strong) implication. Suppose that, at the same time as the government learns its payo↵ type, the private sector privately observes a factor ' drawn from a conditional density
p' (.|x). Suppose too that this factor influences the private sector’s within-period payo↵ function and/or the conditional density of the economic outcome y. Then, the private sector’s
equilibrium strategy ↵⇤ is a function of (x, g, ').
The government can still solve its policy problem using the same regression-based approach as long as this additional factor ' satisfies two restrictions. First, it is important
that, conditional on the government’s information (x, ⇠), ✓ (the government’s taste shifter)
and ' are independent. Otherwise, the realization of ✓ a↵ects the density of the economic
outcome y through its interaction with ', and the past realizations of g can no longer be
viewed as a conditional experiment. Second, it is important that ' only depends on the
past through x. Otherwise, the private sector and the government will enter the period with
di↵erent beliefs about the evolution of the economy.
24

The discussion in this subsection likely seems somewhat arcane. But it is highly pertinent to actual
policymaking. The whole issue of whether “expectations are anchored” is tightly connected to what agents
believe the objective of the policymaker (✓t ) is.

37

6.4

Non-Myopic Government

Throughout, I have imposed the restriction that the government only cares about its withinperiod payo↵. Suppose that its objective in period t is instead:

wt +

g Et wt+1

+

2
g Et wt+2

+ ... +

T
g Et wt+T

where Et represents the government’s conditional expectation25 as of date t. How would the
above analysis change?
The answer is: not much. The current period t government can’t control what the
future governments will do. Rather, it makes its choices taking those future governments’
Markov strategy

⇤

as given. From the point of view of the current government, the future

governments are really no di↵erent from the private sector.26
All that changes is the government’s measure of its payo↵. Suppose as before the government has a data set:
{yt

1
n , gt n , xt n }n=1

where (X, G) are compact intervals in Euclidean spaces. Suppose in addition that the government has data on both current and past realizations of its taste shifter {✓t

1
n }n=0 .

In light

of its multi-period payo↵, the government now defines:

Wn0

= w(✓t , gt

n , yt n )

+

T
X

s
g w(✓t n+s , gt n+s , yt n+s )

s=1

to be its (realized) payo↵ in period (t
that the observations of {xt

1
n(T +1) }n=1

n), where n > T. Without loss of generality, assume
are all sufficiently close to xt that we can treat:

0
(Wn(T
+1) , gt
25

1
n(T +1) )n=1

In contrast, Feldman, et. al. (2016) argue that a non-myopic government should use market-based
expectations rather than statistical expectations.
26
Note that this analysis of a non-myopic government continues to presume that, conditional on xt , ✓t is
independent of past ✓’s.

38

as a sequence of i.i.d. random vectors. (We can always discard data so that this is true.)
The government can now run a nonlinear regression of W 0 on g using this data set. Under
the same conditional independence restriction on ✓t that we made earlier (it doesn’t a↵ect
the economic outcome yt or future state xt+1 except through g), this regression function is
again equivalent to the government’s current projection of its expected (multi-period) payo↵,
conditional on having chosen g.

7

The Right Questions to Ask

There may be no more important sentence in the intellectual history of macroeconomics than
this one penned by Robert Lucas (1980a): “Our task ... is to write a FORTRAN program
that will accept specific economic policy rules as ’input’ and will generate as ’output’ statistics
describing the operating characteristics of time series we care about, which are predicted to
result from these policies.” This research vision - radical at the time Lucas wrote - became
foundational for the discipline in the 1980s and has remained so ever since. There is a sense
that it has led to much progress. Thanks to advances in both technique and technology, the
computer programs that Lucas foresaw are based on increasingly complex economic models of
household and firm interactions. Thanks to the same advances in technique and technology,
these complex models can now be parameterized with reference to amazingly rich micro-data.
The problem is that this research agenda is by construction largely irrelevant to the
formation of most - not all, but most - actual economic policy. The agenda is based on the
idea that policy evaluation is about the assessment of rules that specify how policy is to
be formulated in all dates and states. The consideration of such sweeping counterfactuals is
indeed a highly exciting intellectual activity. It should not be surprising that it has generated
an enormous body of fascinating papers. But this literature about policy regimes is not of
much practical interest: policymakers rarely have the power to engage in this kind of quasiconstitutional design. The typical policymaker is instead charged at a single point in time

39

with making but one episodic decision in a long sequence of such decisions.
How should such a policymaker use the available data to make the best possible decision?
In this paper, I analyze this problem using the tools of dynamic game theory. I show that
the policymaker can solve his/her problem by first regressing policymaker payo↵s on past
choices (and information), and then making the policy choice that maximizes that (possibly
nonlinear) regression function. The regression function thus serves as a sufficient statistic
for decisions: the policymaker has no need to know why the economy responds the way that
it does to policy actions. As a result, the role of theory is limited to providing information
about credible functional form restrictions on the regression function of interest.
Formally, my argument relies on the full support and conditional independence restrictions
described in the body of the paper.27 But it would be a logical and substantive mistake to view
the validity of these two sufficient restrictions as strictly necessary for the purely statistical
approach recommended in this paper to be of use. Rather, I view the theory in this paper
as emphasizing that policymakers should be focused on figuring out how the policymaker’s
payo↵ depends on his/her actions. It points to the kinds of questions that policymakers (and
their advisors) should be asking:
• Why have policy decisions varied in the past, given the available information about the
economy?
• Conditional on that available information, can this source of variation be plausibly
viewed as having had little impact on the economy except through the policy choice
itself?
• How will the policy choices under consideration a↵ect the private sector’s beliefs about
the strategies of future policymakers?
27

Like other kinds of exclusion restrictions, the latter requirement is non-testable. Cooley and Leroy
(1984) criticize atheoretical macroeconometrics because of these non-testable restrictions. Despite their
(reasonable) concerns, in the interim, these kinds of restrictions have become critical in much of applied
microeconomics. Also, and as I noted earlier, much of theoretical macroeconomics employs even stronger
independence restrictions.

40

• What kinds of variables should be seen as part of the economic state (x) that is predetermined at the time policy is made?
• What kinds of theoretically plausible a priori parametric restrictions can be imposed
on the form of the regression function of interest?
These kinds of questions lie at the heart of much modern applied microeconomics. They
should become more central to macroeconomic policy evaluation that is intended to be of
practical value.

41

References
[1] Aguirregabiria, V., and Mira, P., “Dynamic Discrete Choice Structural Models: A Survey,” Journal of Econometrics 156, 2010, 38-67.
[2] Bagehot, W., Lombard Street: A Description of the Money Market, 1873.
[3] Barro, R., and Gordon, D., “A Positive Theory of Monetary Policy in a Natural Rate
Model,” Journal of Political Economy 91, 1983, 589-610.
[4] Bernanke, B., The Courage to Act: A Memoir of a Crisis and its Aftermath, New York,
NY: W. W. Norton and Company, Inc., 2015.
[5] Breiman, L., “Statistical Modeling: The Two Cultures,” Statistical Science 16, 2001,
199-231.
[6] Chari, V. V., and Kehoe, P., “Sustainable Plans,” Journal of Political Economy 98,
1990, 783-802.
[7] Chetty, R., “Sufficient Statistics for Welfare Analysis: A Bridge Between Structural and
Reduced-Form Methods,” Harvard University working paper, 2009.
[8] Cho, I., Sargent, T., and Williams, N., “Escaping Nash Inflation,” Review of Economic
Studies 69, 2002, 1-40.
[9] Cooley, T., and LeRoy, S., “Atheoretical Macroeconometrics: A Critique,” Journal of
Monetary Economics 16, 1985, 283-308.
[10] Ferguson, T., Mathematical Statistics: A Decision-Theoretic Approach, New York: Academic Press, 1967.
[11] Feldman, R., Heinecke, K., Kocherlakota, N., Schulhofer-Wohl, S., and Tallarini, T.,
“Market-Based Expectations as a Tool for Policymakers,” University of Rochester working paper, 2016.
42

[12] Fudenberg, D., and Levine, D., “Self-Confirming Equilibrium,” Econometrica 61, 523545.
[13] Imbens, G., and Wooldridge, J., “Instrumental Variables with Treatment E↵ect Heterogeneity: Local Average Treatment E↵ects,” NBER Lecture 5, Summer 2007.
[14] Kocherlakota, N., “Rules versus Discretion: A Reconsideration,” Brookings Papers on
Economic Activity 2016(2), 1-48.
[15] Leeper, E., and Zha, T., “Modest Policy Interventions,” Journal of Monetary Economics
50, 1973, 1673-1700.
[16] Ljungqvist, L. and Sargent, T., Recursive Macroeconomic Theory, Third Edition, Cambridge, MA: MIT Press, 2018.
[17] Lucas, R. E., Jr., “Econometric Policy Evaluation: A Critique,” Carnegie-Rochester
Conference Series on Public Policy 1, 1976, 19-46.
[18] Lucas, R. E., Jr., “Methods and Problems in Business Cycle Theory,” Journal of Money,
Credit, and Banking 12, 1980a, 696-715.
[19] Lucas, R. E., Jr., “Rules, Discretion, and the Role of the Economic Advisor,” in Rational
Expectations and Economic Policy, ed. S. Fischer, Chicago: The University of Chicago
Press, 1980, 199-210.
[20] Mullainathan, S., and Spiess, J., “Machine Learning: An Applied Econometric Approach,” Journal of Economic Perspectives 31, 2017, 87-106.
[21] Nachbar, J., “Prediction, Optimization, and Learning in Repeated Games,” Econometrica 65, 1997, 275-309.
[22] Plosser, C., “Forward Guidance,” speech given at Stanford Institute of Economic Policy
Research, Stanford University, 2013.

43

[23] Plosser, C., “Monetary Policy Rules: Theory and Practice,” speech given at “Frameworks for Central Banking in the Next Century Policy Conference,” Hoover Institution,
Stanford University, 2014.
[24] Romer, C., and Romer, D., “Does Monetary Policy Matter? A New Test in the Spirit
of Friedman and Schwartz,” NBER Macroeconomics Annual 4, 1989, 121-170.
[25] Sims, C., “Macroeconomics and Reality,” 1980, Econometrica 48, 1980, 1-48.
[26] Sims, C., “Policy Analysis with Econometric Models,” Brookings Papers on Economic
Activity 1982(1), 107-151.
[27] Smets, F., and Wouters, R., “Shocks and Frictions in US Business Cycles: A Bayesian
DSGE Approach,” American Economic Review 97, 2007, 586-606.
[28] Stock, J., and Watson, M., “Dynamic Factor Models, Factor-Augmented Vector Autoregressions, and Structural Vector Autoregressions in Macroeconomics,” Handbook of
Macroeconomics, vol 2., ed. J. Taylor and H. Uhlig, New York: Elsevier, 2016, 415-525.
[29] Taylor, J., “Discretion Versus Policy Rules in Practice,” Carnegie-Rochester Series on
Public Policy 39, 1993, 195–214.

44

Appendix on Finite Samples
In this Appendix, I return to the baseline setup described in Sections 3 and 4. There, I
assumed that the government has an infinitely long data set of past observations on its
choices and the outcomes of those choices. I now turn to the more realistic situation in which
the government in a given period t only has a finite data set. I sketch two possible approaches
to dealing with finite samples: Bayesian and classical. As will become clear, my discussion is
mainly intended to be suggestive of possible routes for further research, as opposed to being
definitive.28
One unresolved issue is that there is a basic internal inconsistency in my treatment of
the finite sample case. I consider the problem of a government at date t that only has a
finite data set. As will become clear, that government’s optimal choice necessarily depends
on this entire sample and its strategy is no longer recursive in a state variable like x. But I
nonetheless continue to assume that the government at date t treats the strategies used by
the private sector and past governments as functions of the past only through x.

Bayesian
Suppose that, in period t, the government has a finite data set {xt

N
n , gt n , , yt n }n=1

of past

observations on the economic state, on its own choice, and on the economic outcome. It also
has current data xt on the economic state and on its taste shifter ✓t .
Define Wn = w(✓t , gt

n , yt n )

to be the government’s payo↵ in period (t

n) (evaluated

using today’s realized tastes). As noted above, suppose that the government’s and the private
sector’s past strategies are time invariant functions of the current state. Then, conditional on
the sequence {xt

N
n , gt n }n=1 ,

{Wn }N
n=1 is a realization of N independent random variables,

where the density of Wn is determined by the pair (xt
28

n , gt n ).

(This means that the density

I use a traditional probabilistic approach to thinking about the government’s problem when it has a finite
sample. However, it could be interesting to instead explore the pluses and minuses of a more algorithmic
approach (that is, machine learning) as described in Breiman (2001) and as discussed in Mullainathan and
Speiss (2017).

45

of Wn and Wm is necessarily the same in any two dates in which (xt

n , gt n )

= (xt

m , gt m ).)

At this stage, I assume that using economic theory or other auxiliary sources of information29 , the government knows that the density of W, conditional on (x, g), can be written:

h(W, g, x, )

for some

in a finite dimensional parameter space B. The government’s information also

gives it a prior belief about

representable by a density p over B.

Given the government’s information about , it can write the (conditional) likelihood of
the data string W N ⌘ (Wn )N
n=1 as:
L(W N ; ) =

N
Y

h(Wn , gt

n , xt n ,

)

n=1

It can then update the prior p using this conditional likelihood to obtain a posterior belief
over B, given the data string W N :

p0 ( ) / p( )

N
Y

h(Wn , gt

n , xt n ,

)

n=1

With this posterior in hand, and given its current observations of (✓t , xt ), the government
can find its optimal choice of g by solving the problem:

maxg✏G

ˆ

0

p( )

B

ˆ

R

W h(W, g, xt , )dW d

Here, the government is evaluating each g by calculating its implied within-period expected
payo↵, for each possible specification of

, and then integrating with respect to its (data-

based) posterior p0 .
Earlier, we saw how, with an infinite dataset, the government could use its past experience
29

By using a conditional approach, I ignore any potential information about
about (g, x).

46

contained in the observations

as its sole source of information about the consequences of di↵erent policy choices. But with a
finite sample, the government may have few or no past observations with potentially desirable
combinations of (x, g). The Bayesian approach provides an automatic way to substitute
theory or any other sources of information embedded in the prior to compensate for these
data limitations. Note that, with an infinite number of observations, the posterior density
p0 ( ) would be concentrated on a single value.

Classical
I begin with a classical approach that is standard in the sense that it is typically used in
practical applications. I then describe an alternative approach that is grounded in statistical
decision theory.
The standard approach is to plug in the maximum likelihood estimate of the unknown
parameters. Define the conditional likelihood L(W N ; ) as above. We can then define the
maximum likelihood estimate ˆ(W N ) as that value of

max

2B L(W

N

that solves:

; ).

Given this estimate, the government can find its optimal policy by solving the problem:

maxg2G

ˆ

R

W h(W, xt , g, ˆ(W N ))dW

However, there is a problem with this (standard) approach. If we look at the government’s
maximand in the above objective, we can see that its maximand depends on the sample W N
via ˆ. From an ex-ante (pre-sample) perspective, this variability influences the government’s
payo↵. This e↵ect is ignored by the standard approach. (Of course, if N = 1, this variability
disappears: ˆ(W N ) is the same for all samples.)
We can take this sample variability into account by using basic statistical decision theory.30
30

Ferguson (1967) is a classic reference.

47

Consider any decision rule d that maps datasets W N into the government’s action set G.
(Again, as above, I treat the past realizations of (gt

N
n , xt n )n=1

as given.) Then, if the true

parameter is , the government gets an ex-ante (pre-sample) payo↵ of:

G(

; d) =

ˆ ˆ

W h(W, xt , d(W N ), )L(W N ; )dW dW N

RN R

The government can then evaluate the ex-ante performance of di↵erent decision rules by
comparing their payo↵ functions

G.

For example, suppose there is a decision rule d⇤ such

that its associated payo↵ function is larger than any other decision rule for all

G(

; d⇤ )

G(

:

; d)

Then it would clearly be appropriate for the government to use that d⇤ . Unfortunately,
it seems highly unlikely in most settings that the government could find such a d⇤ . More
generally, the government would have to choose a decision rule by trading o↵ performance
at some (true) values of

against performance at other values of . The Bayesian approach

accomplishes that trade-o↵ via the prior belief on .

48

