NBER WORKING PAPER SERIES

NETWORK SECURITY AND CONTAGION
Daron Acemoglu
Azarakhsh Malekian
Asuman Ozdaglar
Working Paper 19174
http://www.nber.org/papers/w19174
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2013

We thank various numerous seminar and conference participants for useful suggestions. We gratefully
acknowledge financial support from the Toulouse Network with Information Technology and Army
Research Office. The views expressed herein are those of the authors and do not necessarily reflect
the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
Â© 2013 by Daron Acemoglu, Azarakhsh Malekian, and Asuman Ozdaglar. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including Â© notice, is given to the source.

Network Security and Contagion
Daron Acemoglu, Azarakhsh Malekian, and Asuman Ozdaglar
NBER Working Paper No. 19174
June 2013
JEL No. D6,D62
ABSTRACT
We develop a theoretical model of security investments in a network of interconnected agents. Network
connections introduce the possibility of cascading failures due to an exogenous or endogenous attack
depending on the profile of security investments by the agents. The general presumption in the literature,
based on intuitive arguments or analysis of symmetric networks, is that because security investments
create positive externalities on other agents, there will be underinvestment in security. We show that
this reasoning is incomplete because of a first-order economic force: security investments are also
strategic substitutes. In a general (non-symmetric) network, this implies that underinvestment by some
agents will encourage overinvestment by others. We demonstrate by means of examples that there
can be overinvestment by some agents and also that aggregate probabilities of infection can be lower
in equilibrium compared to the social optimum. We then provide sufficient conditions for underinvestment.
This requires both sufficiently convex cost functions (convexity alone is not enough) and networks
that are either symmetric or locally tree-like. We also characterize the impact of network structure
on equilibrium and optimal investments. Finally, we show that when the attack location is endogenized
(by assuming that the attacker chooses a probability distribution over the location of the attack in order
to maximize damage), there is an additional incentive for overinvestment: greater investment by an
agent shifts the attack to other parts of the network.
Daron Acemoglu
Department of Economics
MIT, E52-380B
50 Memorial Drive
Cambridge, MA 02142-1347
and CIFAR
and also NBER
daron@mit.edu

Asuman Ozdaglar
Department of Electrical Engineering
and Computer Science
Massachusetts Institute of Technology
77 Massachusetts Ave, E40-130
Cambridge, MA 02139
asuman@mit.edu

Azarakhsh Malekian
MIT Laboratory for Information and Decision System
77 Massachusetts Avenue, Room 32-D608
Cambridge, MA 02139
malekian@MIT.EDU

1

Introduction

Computer, communication, transport and economic networks all depend on some degree of security for their operation. For example, a virus that infects a set of connected computers or a
malfunction in a router, domain or switch may influence the functioning of the entire network and
in the worst case scenario, will spread from one part to the rest of the network. Almost all networks
are protected with security investments. For example, individual computers use virus scans and
refrain from visiting websites that appear suspicious. Domains use firewalls and other security
devices to prevent exposure to viruses and malware. Consequently, it has long been recognized,
in Anderson and Mooreâ€™s (2006, p. 610) words, that â€œsecurity failure is caused at least as often by
bad incentives as by bad designâ€.
An emerging literature at the boundary of economics and computer science investigates how
these incentives are determined and how they shape security investments and resilience of networks. A clear positive externality exists in security investments. An agent that fails to protect itself
adequately not only increases the probability of its own infection but also increases the likelihood
that infection will spread to other agents. Based on this intuition, the literature has so far presumed
that there will be underinvestment in security (e.g., Anderson and Moore, 2006, Bachrach, Draief
and Goyal, 2012, Goyal and Vigier, 2011, Larson , 2011). These intuitions, however, are based on
analyses of â€œsymmetric networksâ€. In symmetric networks, there is either no network structure
and all agents (or individuals or nodes) interact with all others or, loosely speaking, all agents occupy the same position in the network as all others. Such symmetric networks are neither realistic
nor conducive to an understanding of the role of the structure of the network on equilibrium (and
optimal) security investments. The lack of realism is obvious: there is considerable heterogeneity across agents in all of the aforementioned networks; domains and routers differ in terms of
their size and importance, and computer users are typically connected to very different numbers
of users and occupy different positions in the overall network. The importance of analyzing the
impact of network structure is also equally salient and has long been recognized as central for the
study of network security as the following quote, again from Anderson and Moore (2006, p. 613),
illustrates: â€œNetwork topology can strongly influence conflict dynamics... Different topologies
have different robustness properties with respect to various attacks.â€
The next example shows that the presumed underinvestment in network security need not
hold in non-symmetric networks, and in fact, infection might be much more widespread in the
socially optimal allocation than in a decentralized equilibrium.
Example 1.1. Consider the network given in Fig. 1. The underlying network S is a star with 5
nodes, each representing an agent. Each agent can protect herself against infection by investing in
security q, defined as the probability that she is â€œimmuneâ€ to infection. Suppose that her utility
is given by the probability that she is uninfected minus her cost of security investment, assumed
to be given by c(q) =

q2
5 (2.9

âˆ’ 1.33q). Suppose also that the initial infection (attack) hits one of

the agents uniformly at random. If this node is susceptible, it will get infected. Each infected
1

1

2

3

4

5

Figure 1: The equilibrium security profile is qe = [0.2, 1, 1, 1, 1] and the social optimum is qs =
[1, 0.2, 0.2, 0.2, 0.2]
agent can infect all its susceptible neighbors. One can verify that qe = (0.2, 1, 1, 1, 1) is a purestrategy Nash equilibrium security profile. However, the social optimum security profile is qs =
(1, 0.2, 0.2, 0.2, 0.2). The expected (number of) infections in equilibrium is I(S, qe ) = 0.16, but
expected infections in the social optimum I(S, qs ) = 0.64.
The key to this example and to the economic richness of security decisions in a non-symmetric
network is a simple observation: security decisions of different agents not only create positive externalities but are typically also strategic substitutes, meaning that greater investment by an agent
reduces the desired investment of others, as can be readily seen in Example 1. This strategic substitutes property makes the analysis of non-symmetric networks particularly important.
This paper studies equilibrium and socially optimal security investments in a general random
network subject to attack. Each agent i is connected to a subset of other agents and chooses a
security investment qi . An infection is probabilistically transmitted across connected agents. Conditional on transmission to agent i, the probability of infection of this agent is 1 âˆ’ qi (meaning
that with probability qi , this agent is immune to infection). This formulation is both tractable and
makes the positive externality from network investments transparent . We distinguish two types
of attacks: (1) random attacks, which are likely to hit each agent uniformly at random (and in particular independent of their security investments); (2) strategic attacks, where the location of the attack
is determined by an adversary wishing to maximize expected infection (see also Bachrach, Draief
and Goyal, 2012, Goyal and Vigier, 2011).
We first provide a decomposition of individual payoffs into an own effect and an externality,
a tractable decomposition that underpins the rest of our analysis and appears not to have been
noticed so far in the literature. This decomposition enables us to write the payoff of an agent as
a function of network effects of others and as a linear function of her own security investment,
minus its own cost of investment. These network effects have a simple recursive structure and can
be computed by considering the network with one agent removed at a time.
Second, using these decompositions we establish the existence of a pure-strategy Nash equilibrium in the random attacks model. Example 1 above already shows that such equilibria may
2

feature overinvestment by some nodes and lower than optimal level of infection over the entire
network, in contrast to what has generally been presumed on the basis of the positive externality
underlying these interactions.
Third, we show that symmetric equilibria of symmetric networks always involve underinvestment as presumed by the existing literature. Intuitively, in a symmetric equilibrium the positive
externality dominates the strategic substitutes effect and thus each agent underinvests (it is easy
to see why this has to be so; if not, then all agents would overinvest, which would be inconsistent
with positive externalities). Nevertheless, we also show that symmetric networks do not preclude
non-symmetric equilibria, which may still involve overinvestment as in our Example 1 above. The
intuition for this is also simple: once the equilibrium is non-symmetric (even if the underlying network is symmetric), the underinvestment of one agent will trigger overinvestment by some others,
which can dominate the underinvestment effect.
Fourth, we introduce a special class of networks, where the network structure is represented
by a tree and cost of investments are sufficiently convex (as defined below), and show that such
networks always lead to underinvestment in security (though a tree structure is not sufficient for
this result by itself as we also illustrate by examples). The intuition for this result can be obtained
as follows: sufficiently convex cost functions ensure that when the overall probability of infection
reaching agent i increases, this agent does not increase his security investment so much as to reduce
its overall probability of infection. This combined with the tree network puts an upper bound on
how much an agent will change its investment because some other agents underinvest, enabling
us to show that, in equilibrium, all agents underinvest.
Fifth, we show that this result generalizes to random networks with local tree structures (meaning that there exists pÌ‚ such that any subcomponent of a certain size of the network does not contain a cycle with probability at least pÌ‚). The intuition for this result follows from the previous one,
which enables us to bound the network effect of each agent on the rest of the network for each
subcomponent of the original network.
Sixth, we strengthen this result for symmetric networks such as Erdos-Renyi graphs and we
also provide additional ranking results for symmetric networks comparing equilibrium infection
rates across different network structures. These results rely on observing that for this class of
symmetric networks not only a symmetric equilibrium exists but is also the only equilibrium.
Seventh, we show that there is an additional reason for overinvestment in the case of strategic attacks, echoing an intuition going back to de Meza and Gould (1992): preventive activities
can create negative instead of positive externalities when they shift attacks to other nodes. We
illustrate this first using a tree network with sufficiently convex cost functions, thus establishing
that even in this case overinvestment can easily result. Finally, for a symmetric random graphs
and some additional conditions on cost functions, we show that the equilibrium always involves
overinvestment.
There is now a large literature on spreads of infections and epidemics over networks including, among others, Molloy and Reed (1998, 2000), Newman et al. (2001), and Chung and Lu
3

(2002). Early works considering control of infections and epidemics include Sanders (1971) and
Sethi (1974). Brito et al. (1991), Geoffard and Philipson (1997), Goldman and Lightwood (2002)
and Toxvaerd (2009) analyzed certain aspects of precautionary or vaccination behavior in related
settings.
More closely related to our paper are Bachrach, Draief and Goyal (2012) and Larson (2011), both
analyzing endogenous formation of networks (connections) together with security decisions in
the presence of infections. In Larsonâ€™s model, for example, network connections generate benefits
for agents but also spread infection. In Larsonâ€™s model each agent chooses both their expected
connectivity and a security level. Both of these papers focus on symmetric networks (e.g., ErdosRenyi random graphs), and thus do not obtain any of our main results. Blume et al. (2011) also
study network formation in the presence of negative contagion, but focus on providing bounds on
the inefficiency of equilibrium.1
Also closely related are works related to â€œstrategic attacks,â€ where precautionary behavior
shifts attacks from one agent to another. As mentioned above, an early paper showing this possibility is de Meza and Gould (1992). Related issues are studied in Baccara and Bar-Isaac (2008),
Bachrach, Draief and Goyal (2012), Goyal and Vigier (2011), Kovenock and Roberson (2010), and
Hoyer and Jaegher (2010), but once again without focusing on the effects of network structure.
Our results contribute to the literature in two distinct ways. First, we generalize existing models of both random and strategic attacks to (potentially asymmetric) random networks and show
how new economic forces arise in the setting that were absent in symmetric equilibria. Second, we
provide new and powerful characterization results. We show that the oft-presumed underinvestment in security investments is not generally true and overinvestment arises in a range of settings,
with both random and strategic attacks, for well-defined economic reasons. Our characterization
results then enable us to determine a range of cases where underinvestment or overinvestment
incentives dominate.

Basic Notation and Terminology
Throughout the paper unless otherwise stated, a vector is viewed as a column vector. We denote
by xi , the ith component of a vector x. For a vector x, xâˆ’T denotes the subvector that corresponds
to the indices not in set T .
An undirected graph with node set V and edge set E is represented by G = (V, E). We let
|V | = n and |E| = m. We sometimes use the notation V (G) and E(G) to denote the node set and
the edge set of graph G. A graph without edges is called an â€œempty graphâ€. The subgraph of a
graph G is a graph H with V (H) âŠ† V (G) and E(H) âŠ† E(G). The subgraph of G = (V, E) induced
by V 0 âŠ‚ V , denoted by G[V 0 ], is defined as G[V 0 ] = (V 0 , {(u, v)|(u, v) âˆˆ E, u, v âˆˆ V 0 }). Also, for a
given VÌ„ âŠ‚ V , we will sometimes use the notation Gâˆ’VÌ„ as G[V âˆ’ VÌ„ ].
1
Classic references on network formation include Jackson and Wolinsky (1996) and Bala and Goyal (2000)]. See also
Jackson (2008) and Vega-Redondo (2007) for excellent book-length treatments of issues of contagion in networks and
network formation.

4

A random graph A is drawn from a probability space (â„¦, F[V ], P), where â„¦ is the set of all
undirected graphs with node set V , F is the family of all subsets of â„¦, and for every AÌƒ âˆˆ â„¦, P(AÌƒ)
is the probability of AÌƒ. For a given i âˆˆ V , Aâˆ’i is drawn from the probability space (â„¦âˆ’i , Fâˆ’i , Pâˆ’i )
where â„¦âˆ’i is the set of all undirected graphs with node set Vâˆ’i , Fâˆ’i is the family of all subsets of
P
â„¦âˆ’i , and for a given AÌƒ0 âˆˆ â„¦âˆ’i , Pâˆ’i (AÌƒ0 ) = {AÌƒâˆˆâ„¦|AÌƒâˆ’i =AÌƒ0 } P(AÌƒ). Similarly, given a random network
A, the induced network over the node set V 0 âŠ‚ V is denoted by A[V 0 ] and is drawn from the
probability space (â„¦0 , F0 , P0 ), where â„¦0 is the set of all graphs with node set V 0 , F0 is the family of
P
all subsets of â„¦0 , and for a given AÌƒ0 âˆˆ â„¦0 , P0 (AÌƒ0 ) = {AÌƒâˆˆâ„¦|AÌƒ[V 0 ]=AÌƒ0 } P(AÌƒ).

The rest of the paper is organized as follows. Section 2 presents our basic model, focusing on
the case in which attacks are random (undirected with respect to security investments). It shows
why, because of the strategic substitutes aspect of investments, the common conjecture that there
will necessarily be underinvestment in security does not always hold. Section 4 establishes that
when costs functions are â€œsufficiently convexâ€ and networks are trees, the equilibrium is unique
and always involves underinvestment relative to the social optimum. Section 5 extends these results to random networks that are â€œlocally tree-like,â€ meaning that they feature low probability
of a cycle within the component of the network attached to any particular agent. Section 6 establishes a similar uniqueness and underinvestment results for symmetric random networks and
for island networks (which consist of several symmetric islands sparsely connected to each other).
This section also provides a ranking of the extent of contagion across different symmetric networks. Section 7 considers strategic attacks (directed with respect to to the security investment
profile of agents), and shows an additional reason for overinvestment. Section 8 concludes, while
the Appendix contains all the proofs and some additional examples.

2

Model

We study the spread of infection among a set V = {1, . . . , n} of agents over a network. Agent
interactions are represented by a random network A drawn from a probability space (â„¦, F, P),
where â„¦ is the set of undirected networks with node set V .2 We use Ar to denote a realization of
random network A and refer to it as the interaction network. We often use the terminology Ar is
generated from A, denoted by Ar âˆ¼ A, to highlight the dependence on the random network A.3
An attacker exposes one of the agents to an infection (virus), which then spreads dynamically
to the other agents. Attackerâ€™s decision of which agent to target is represented by the probability
vector Î¦ = (Ï1 , . . . , Ïn ), where Ïi denotes the probability of attacking agent i. We use the notation
s to denote the selected target agent, also referred to as the seed agent. The infection is transmitted
2

We will use the terms agent, node and individual interchangeably throughout the paper. Similarly, we will use the
terms network and graph interchangeably.
3
A deterministic network G = (V, E) is a special case of this model in which P(G) = 1 and for all G0 6= G, P(G0 ) = 0.

5

on the edges of the interaction network.4
Before the interaction network Ar and the location of the attack is realized, each agent i invests
in a security level qi âˆˆ [0, 1] to decrease the chance of getting infected. We use q = [qj ]jâˆˆV and
qâˆ’i = [qj ]jâˆˆV, j6=i to denote the security profiles (short for security investment profiles) of all agents
and all agents other than i respectively. Here, qi can be interpreted as the probability that agent i is
immune to the infection. Conversely, 1 âˆ’ qi is the probability that the agent is susceptible, meaning
that if the infection reaches her, she gets infected with probability 1 âˆ’ qi (independent of all other
events).5
Given network A, security profile q and attack decision Î¦, we denote the probability of node i
getting infected by Pi (A, q, Î¦). The utility function of agent i, denoted by ui is given by

ui (A, q, Î¦) = vi 1 âˆ’ Pi (A, q, Î¦) âˆ’ ci (qi ),
where vi is the value agent i derives from being uninfected and ci (qi ) is the cost agent i incurs
for investing in security level qi . We assume vi = 1 in the rest of the paper. However, all the
results hold even without this assumption. We adopt the following standard assumption on the
investment cost function.
Assumption 1 (Investment Cost). For each i, the function ci : [0, 1] â†’ R+ is continuously differentiable, strictly increasing, strictly convex, and satisfies the boundary conditions c(0) = 0, c0 (0) = 0, and
limqâ†’1 c0 (q) = âˆž.6
We define (utilitarian) social welfare as the sum of the utilities of the agents in the network:
W (A, q, Î¦) =

X

ui (A, q, Î¦).

iâˆˆV

Given network A and security profile q, we define the transmission network as the subgraph of
the interaction network Ar induced over the set of susceptible agents Vs âŠ‚ V and denote it by At .
The infection is transmitted through the transmission network.7 In particular, given transmission
network At and seed agent s, the set of infected agents consists of the set of agents that belong to
the same connected component with agent s in At .
4

For example, when the network A is generated according to an ErdoÌˆs-ReÌnyi graph with parameter p âˆˆ (0, 1) (i.e.,
there exists an edge between any pair of agents independently with probability p), this implies that an infected agent
transmits the infection to each of the other agents independently with probability p.
5
If we think of the spread of the infection dynamically over the network, this implies that if the agent is not infected
the first time the infection reaches her, she will not be infected in any of the subsequent instances.
6
The boundary conditions are imposed to simplify the exposition, and all of our results hold without them.
7
Formally, given Ar = (V, E) and a set of susceptible agents Vs âŠ‚ V , the transmission network At is given by
At â‰¡ Ar [Vs ] = (Vs , {(i, j) âˆˆ E | i, j âˆˆ Vs }). We often use the terminology At is generated from (A, q), denoted by
At âˆ¼ (A, q), to highlight the dependence on the random network A and the security profile q. The probability of
transmission network At can be written as
X
Y
Y
X
P(Ar )
(1 âˆ’ qi )
qi .
P (At ) =
P (At | Ar , Vs ) =
{Ar ,Vs | At =Ar [Vs ]}

{Ar ,Vs | At =Ar [Vs ]}

6

iâˆˆVs

iâˆˆV
/ s

We study two different attack models: a random attack model in which the attacker targets each
agent with attack decision Î¦, which is determined exogenously and independent of the security
investments of the agents, and a strategic attack model in which the location of the attack is determined by an adversary who observes the security profiles of all agents and chooses one agent to
attack with the goal of maximizing expected infections. The random attack model represents the
scenario where the attack is an exogenous random event and one of the agents is selected at random according to Î¦. The strategic attack model on the other hand represents a strategic adversary
wishing to maximize the damage to the network.8

3

Random Attack Model

In this section, we focus on the random attack model, where the attackerâ€™s decision is an exogenously given probability vector Î¦ = (Ï1 , . . . , Ïn ). We first present key properties of equilibria and
social optimum for this model, which will also apply (in a slightly modified form) to our analysis
of the strategic attack model. Our first result provides a characterization for the infection probability of an agent in terms of his security level qi and a network effect caused by the other agents. We
then show that the network effect admits a simple decomposition that highlights the contribution
of the agents on infection one at a time. These characterizations enable us to express individual
utility and social welfare in a form that makes the dependence on the security levels explicit. We
use these expressions to show the existence of a pure-strategy Nash equilibrium for the resulting
game, to characterize the best response and welfare maximizing strategies of agents, and to study
the monotonicity behavior of best response strategies in response to changes in security profiles
of other agents. In the last subsection, we focus on symmetric networks (defined formally below)
and show that while such networks have a unique symmetric equilibrium that features underinvestment, they may also have asymmetric equilibria in which some agents over invest compared
to the social optimum.

3.1

Key Properties

Our first proposition provides a tractable decomposition of individual utility functions into an
own effect and network effects of other individuals.
Proposition 3.1 (Network Effect). Given network A, security profile q, and attack decision Î¦, the infection probability of agent i satisfies
Pi (A, q, Î¦) = (1 âˆ’ qi )PÌƒi (A, qâˆ’i , Î¦),
where PÌƒi (A, qâˆ’i , Î¦) is the probability of the infection reaching agent i.
8
A hybrid model, where the attacker can target agents according to the characteristics but not their security investments, gives results very similar to the random attack model. We do not discuss this hybrid case to economize on
space.

7

As with all the other results in the paper, unless stated otherwise, the proof of this proposition
is provided in the Appendix.
This result is intuitive in view of the fact that agent i is susceptible to infection with probability
1âˆ’qi . If she is immune, then she will not get infected in any case. If she is susceptible, she will only
get infected if the infection reaches her. In what follows, we refer to PÌƒi (A, qâˆ’i , Î¦) as the network
effect of A on i.
The network effect on an agent admits a simple decomposition and can be computed recursively by considering the network with one agent removed at a time.9
Proposition 3.2 (Decomposition). Given network A, security profile qâˆ’j , and attack decision Î¦, the
probability of infection reaching agent j, PÌƒj (A, qâˆ’j , Î¦), satisfies the following: For all i âˆˆ V, i 6= j,
PÌƒj (A, qâˆ’j , Î¦) = PÌƒj (Aâˆ’i , qâˆ’{i,j} , Î¦) + (1 âˆ’ qi )Qj,i (A, qâˆ’{i,j} , Î¦),
where Qj,i (A, qâˆ’{i,j} , Î¦) is the probability that the infection reaches agent j only through a path that contains agent i conditional on i being susceptible.
We refer to (1 âˆ’ qi )Qj,i (A, qâˆ’{i,j} , Î¦) as the externality of i on j.
This decomposition follows from considering the following mutually exclusive events under
which infection reaches agent j: (A) there exists a path from the seed agent s to j in the transmission network that does not include i, or (B) all possible paths from s to j in the transmission network goes through i. The probability of first event is equal to the probability of infection reaching
agent j in the network Aâˆ’i and is independent of qi (and qj ).10 The probability of the second event
can be written as the probability of infection reaching j through a path that contains i conditional
on i being susceptible (which does not depend on qi ) times the probability of i being susceptible,
which is (1 âˆ’ qi ). Figure 2 illustrates different transmission networks over which infection reaches
agent j: Fig. 2(a) shows instances in which event (A) occurs, and Fig. 2(b) shows an instance in
which event (B) occurs.

3.2

Existence

Using Proposition 3.1, we can write the utility function of agent i as the following:


ui (A, q, Î¦) = 1 âˆ’ (1 âˆ’ qi )PÌƒi (A, qâˆ’i , Î¦) âˆ’ ci (qi ).
9
In a graph G = (V, E), a path between nodes u and v corresponds to u = v0 , e1 , v1 , e2 , . . . , ek , vk = v where
ei = (viâˆ’1 , vi ) âˆˆ E, for all 1 â‰¤ i â‰¤ k with no repeated edges and nodes.
10
This probability does not depend on Î¦i , nevertheless we keep the dependence on the entire vector Î¦ to simplify the
notation.

8

ð‘—

ð‘—

ð‘Ž

ð‘–

ð‘—

ð‘Ž

ð‘–

ð‘ 

ð‘ 

ð‘Ž

(b)

(a)

ð‘–

ð‘ 

Figure 2: Transmission networks over which the infection reaches agent j. Figure (a) shows transmission
networks in which there exists a path from s to j that does not include i (event (A) occurs). Figure (b) shows
the transmission network in which all possible paths from s to j goes through i (event (B) occurs).
Similarly, fixing any i âˆˆ V , from Propositions 3.1 and 3.2, social welfare takes the following form:
W (A, q) =

X

uj (A, q, Î¦)

jâˆˆV




= 1 âˆ’ (1 âˆ’ qi )PÌƒi (A, qâˆ’i , Î¦) âˆ’ ci (qi )


X 
+
1 âˆ’ (1 âˆ’ qj ) PÌƒj (Aâˆ’{i} , qâˆ’{i,j} , Î¦) + (1 âˆ’ qi )Qj,i (A, qâˆ’{i,j} , Î¦)
âˆ’ cj (qj ).
jâˆˆV j6=i

(3.1)
A security profile qe is a (pure-strategy) Nash equilibrium if for all i âˆˆ V and all qi âˆˆ [0, 1],
ui (A, qe , Î¦) â‰¥ ui (A, (qi , qeâˆ’i ), Î¦).
Similarly, a security profile qs is a social optimum if for all q âˆˆ [0, 1]n ,
W (A, qs , Î¦) â‰¥ W (A, q, Î¦),
i.e., qs is a global maximum of the social welfare function.
Theorem 3.1 (Equilibrium Existence). In the random attack model, for any network A, there exists a
pure-strategy Nash equilibrium.
The existence of a pure-strategy Nash equilibrium follows from the linearity of the utility function ui (A, q, Î¦) in qi , its continuity in q, and the fact that the strategy spaces are compact, and we
omit a formal proof.
It is useful for what follows to define the best response strategy of an agent i, Bi (qâˆ’i ), as the
security level qi that maximizes her utility given the security profile qâˆ’i of other agents. Clearly:
c0i (Bi (qâˆ’i )) = PÌƒi (A, qâˆ’i , Î¦).

9

(3.2)

Similarly, the welfare maximizing strategy of agent i, Si (qâˆ’i ), is the security level qi that maximizes social welfare given the security profile qâˆ’i of other agents, given by
c0i (Si (qâˆ’i )) = PÌƒi (A, qâˆ’i , Î¦) +

X

(1 âˆ’ qj )Qj,i (A, qâˆ’{i,j} , Î¦).

(3.3)

j6=i

A comparison of these two expressions immediately establishes that
Bi (qâˆ’i ) â‰¤ Si (qâˆ’i ).

(3.4)

Given the profile of security investments of other agents, agent i always invests less in best response strategy than in the welfare maximizing strategy. However, as Example 1 in the Introduction shows, this does not imply underinvestment by all agents.
The network effect satisfies intuitive monotonicity properties given in the following proposition.
Proposition 3.3. Given network A and two security profiles q and qÌ‚, the following properties hold for each
agent i âˆˆ V :
(a) If qâˆ’i â‰¥ qÌ‚âˆ’i , then PÌƒi (A, qâˆ’i , Î¦) â‰¤ PÌƒi (A, qÌ‚âˆ’i , Î¦).
(b) For any VÌ‚ âŠ‚ V , PÌƒi (Aâˆ’VÌ‚ , qâˆ’(VÌ‚ âˆª{i}) , Î¦) â‰¤ PÌƒi (A, qâˆ’i , Î¦).
(c) If PÌƒi (A, qâˆ’i , Î¦) â‰¥ PÌƒi (A, qÌ‚âˆ’i , Î¦), then Bi (qâˆ’i ) â‰¥ Bi (qÌ‚âˆ’i ).
Part (a) of this proposition states the intuitive fact that probability of the infection reaching
agent i is smaller when other agents select a higher security profile. Part (b) establishes that the
probability of the infection reaching agent i is smaller in a subgraph (which is expected since
there are more paths along which infection can reach agent i in the original graph). Finally, part
(c), which will play an important role in some of our later proofs, shows that the best response
strategy of agent i is higher when the network effect of A on i is higher.

3.3

Symmetric Networks

We next focus on symmetric networks (with symmetric agents in terms of their cost function ci ,
which is denoted by c in this subsection).
Definition 1 (Symmetric Network). A random network A is symmetric if for any permutation Ï€ : V â†’
V , A0 = Ï€(A) has the same distribution as A.
The preferential attachment networks, Erdos-Renyi random graphs and random graphs with
arbitrary degree distributions are examples of symmetric networks.11
11

Note that the interaction network need not be symmetric; rather, agent locations within the network are identical in
expectation.

10

ð‘Ž

ð‘Ž

ð‘Ž

1
9

4
15

4
9

8
9

ð‘

8
9

(ð‘Ž)

ð‘

4
15

4
15

ð‘

ð‘

(ð‘)

4
9

ð‘

4
9

ð‘

(ð‘)

Figure 3: A 3-cycle network. Figure (a) shows the asymmetric equilibrium security profile, Figure (b) shows
the symmetric equilibrium security profile, and Figure (c) shows the symmetric social optimum security
profile.
Our next result shows that in symmetric networks, a unique symmetric equilibrium security
profile exists and that investment levels and thus the symmetric equilibrium are always lower than
the (unique) symmetric social optimum.
Theorem 3.2. Suppose Assumption 1 holds. For a symmetric network, there exists a unique symmetric
equilibrium (with investment q e ) and a unique symmetric social optimum (with investment q s ). Moreover
we have q e â‰¤ q s .
The key result in Theorem 3.2 is the underinvestment in security in the symmetric equilibrium relative to the social optimum. This result, which confirms those in the existing literature,
has a straightforward intuition, which can be seen from Eq.(3.4): given the security profile of all
other agents, an individual always has weaker incentives to invest in security in the best response
strategy than in the welfare maximizing strategy. In a symmetric equilibrium this implies that
everybody will have weaker incentives to invest in security, leading to underinvestment.
This intuition does not extend to asymmetric equilibria of symmetric networks as the next
example shows.
49
Example 3.1. Consider the 3-cycle network illustrated in Fig. 3. We assume that c(q) = q 2 ( 24
âˆ’ 54 q).

One can verify that the security level at the unique symmetric equilibrium is q e =
has an asymmetric equilibrium given by
which is symmetric with security level

4

qÌ‚e

qs

=

=

( 19 , 89 , 89 ).

4
15 .

This example

Moreover, it has a unique social optimum,

4
9.

Tree Networks with Sufficiently Convex Cost Functions

In this and the subsequent two sections, we focus on tree networks and cost functions that satisfy
a stronger requirement than convexity, which we refer to as sufficiently convexity. A graph is a tree
if it is connected and acyclic. A graph is acyclic if it has no cycle and is connected if between each
pair of nodes, a path exists.

11

We will show that the combination of these two assumptions ensures that expected infections
at the social optimum is less than or equal to that in the equilibrium. The role of each of these
assumptions will be clarified later in this section.
We first define our new assumption on the investment cost functions.
Assumption 2 (Sufficiently Convex Cost Function). For each i, the cost function ci : [0, 1] â†’ R+ is
sufficiently convex if c0i (q)(1 âˆ’ q) is strictly increasing over [0, 1].
This assumption is equivalent to the function cÌƒ(x) = c(1 âˆ’ x) having an elasticity of marginal
cost greater than or equal to 1. An example of a sufficiently convex cost function is c(q) = âˆ’q âˆ’
log(1 âˆ’ q).
To understand the implications of sufficiently convex cost functions, recall the first-order condition satisfied by the best response strategy Bi (qâˆ’i ) of agent i given in Eq. (3.2). In view of Proposition 3.1, the infection probability of agent i, when he selects his best response strategy given the
security profile qâˆ’i , can be expressed as
Pi (A, (Bi (qâˆ’i ), qâˆ’i ), Î¦) = (1 âˆ’ Bi (qâˆ’i ))c0i (Bi (qâˆ’i )).
The key implication of Assumption 2 is that, when qâˆ’i decreases, even if agent i in response increases his investment, his probability of infection will still increase. Put differently, sufficiently
convex cost functions ensure that direct effects (change in othersâ€™ investments) dominate indirect
effects (the response to this change). The next lemma states this result more formally.
Lemma 4.1. Suppose Assumptions 1 and 2 hold. Let qâˆ’i and qÌ‚âˆ’i be such that PÌƒi (A, qâˆ’i , Î¦) â‰¥ PÌƒi (A, qÌ‚âˆ’i , Î¦).
Then Pi (A, (Bi (qâˆ’i ), qâˆ’i ), Î¦) â‰¥ Pi (A, (Bi (qÌ‚âˆ’i ), qÌ‚âˆ’i ), Î¦).
This lemma clarifies the role of the sufficiently convex cost assumption in establishing results
on â€œunderinvestment in equilibriumâ€ for general networks: even though underinvestment by others triggers overinvestment by agent i, sufficiently convex cost functions ensure that iâ€™s overall
infection probability increases when this is the case and thus bounding how much iâ€™s investment
can increase.
Nevertheless, Lemma 4.1 does not immediately imply that expected infections are necessarily
higher in the equilibrium than in the social optimum. This can be proven for tree networks, which
also guarantees uniqueness of equilibrium.
Theorem 4.1. Suppose Assumptions 1 and 2 hold. For any tree network, there exists a unique pure-strategy
Nash equilibrium security profile.
Here we provide the intuition for the proof of this result, which illustrates the central roles of
both sufficiently convex cost functions and the tree structure. If there exist multiple equilibria qe
and qÌ‚e , we can find an edge (x, y) such that qxe > qÌ‚xe , qye < qÌ‚ye , and for all nodes v in the subtree

12

rooted at y (i.e., nodes that reaches x through y) qve < qÌ‚ve . By sufficiently convex cost assumption,
this implies
Px (A, qe , Î¦) > Px (A, qÌ‚e , Î¦) but Py (A, qe , Î¦) < Py (A, qÌ‚e , Î¦).

(4.1)

The idea is then to exploit the tree network structure and establish a contradiction. In particular,
because qve < qÌ‚ve for all v in the subtree rooted at y, the probability of infection for agent y coming
from this subtree is greater under the profile qe than qÌ‚e . In addition, if the probability of infection
for y from its upstream neighbors was also higher under the profile qe than qÌ‚e , then this would
contradict (4.1). Moreover, if the probability of infection for y from its upstream neighbors was
lower under qe than qÌ‚e , then this would contradict the ranking of the investments of x and y in
the two candidate equilibria, again yielding a contradiction. Intuitively, in a tree network with
sufficiently convex cost functions, greater investment in one part of the network always translates
into higher probability of infection for neighboring agents, and this precludes the possibility of
two different equilibrium profiles.
More importantly, tree networks and sufficiently convex cost functions also ensure an unambiguous ranking between expected infections in equilibrium and social optimum as shown in the
next theorem.
Theorem 4.2. Suppose Assumptions 1 and 2 hold. Let I(A, q, Î¦) denote expected infections in network
A with security profile q and attack decision Î¦. Given tree network A, we have I(A, qe , Î¦) â‰¥ I(A, qs , Î¦)
where qe and qs are the equilibrium and the socially optimal security profiles.
This theorem also holds for any random network where the realizations correspond to a set
of potentially disconnected trees, e.g., we start with a tree, and each edge remains active with
probability p âˆˆ (0, 1].
The economic intuition of this theorem is related to the reason why such a result is not true in
general networks and without sufficiently convex cost functions. We have seen that underinvestment by an agent triggers overinvestment by others (because investments in security are strategic
substitutes), and this response can have a greater impact on expected infections than underinvestment by the first agent. Sufficiently convex cost functions limit the extent of the indirect response
of an agent, and the tree network by ruling out cycles ensures that we can use this bound to rank
expected infections in equilibrium and social optimum.
The technical intuition of the proof of Theorem 4.2 is also instructive, as illustrates why tree
networks and sufficiently convex cost functions are important for the result. For this reason, while
a formal proof is provided in the Appendix, we discuss the main idea here.
Consider the set V1 = {i âˆˆ V | qis â‰¤ qie }, i.e., V1 is the set of agents that overinvest in the
equilibrium relative to the social optimum (if V1 is empty, it means that all agents underinvest in
the equilibrium and the result follows straightforwardly). For any VÌ„ âŠ‚ V , let CI (i, Aâˆ’VÌ„ ) denote

13

the contribution of agent i to infection in subgraph Aâˆ’VÌ„ for a given security profile q, i.e.,
ï£¶

ï£«
X

ï£¬
CI (i, Aâˆ’VÌ„ , Î¦) = (1 âˆ’ qi ) ï£­PÌƒi (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i} , Î¦) +

ï£·
(1 âˆ’ qj )Qji (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i,j} , Î¦)ï£¸ . (4.2)

jâˆˆV âˆ’VÌ„ âˆª{i}

The key to the proof of Theorem 4.2 is the following lemma which establishes that for tree networks, the contribution of agents to infection in a subgraph is upper bounded by their contribution
to infection in the original graph.
Lemma 4.2. Given tree network A and node set VÌ„ âŠ‚ V ,
X

X

CI (i, Aâˆ’VÌ„ ) â‰¤

iâˆˆV âˆ’VÌ„

CI (i, A).

iâˆˆV âˆ’VÌ„

The intuition follows from the fact that for tree networks, if an agent k is removed, then the
network effect of agent i on agent j either remains constant (if the path between the two did not
include k) or decreases to zero. (if the path did include k.) This is not necessarily true for graphs
with cycles as Example A.1 in the Appendix shows.
Using Lemma 4.2, an upper bound for expected infections in the social optimum is the following:
I(A, qs , Î¦) â‰¤ I(Aâˆ’V1 , qsâˆ’V1 , Î¦) +

X

c0i (qis )(1 âˆ’ qis ).

iâˆˆV1

Here we used Eq. (3.3) to write CI (i, A) as c0i (qis )(1âˆ’qis ) (and see also Lemma A.1 in the Appendix).
Moreover, expected infections in the equilibrium can be lower bounded as follows:
I(A, qe , Î¦) â‰¥

X

c0i (qie )(1 âˆ’ qie ) + I(Aâˆ’V1 , qeâˆ’V1 , Î¦âˆ’V1 ).

iâˆˆV1

This lower bound is obtained by applying Eq. (3.2) for the agents in V1 and using Proposition
3.3(b) to provide a lower bound on expected infections among agents outside set V1 .
These two bounds, combined with the following observations, yield the desired result.
(1) I(Aâˆ’V1 , qeâˆ’V1 , Î¦âˆ’V1 ) â‰¥ I(Aâˆ’V1 , qsâˆ’V1 , Î¦âˆ’V1 ) since qis â‰¥ qie for all i âˆˆ V âˆ’ V1 ;
(2)

0 e
iâˆˆV1 ci (qi )(1
convex and qis

P

âˆ’ qie ) â‰¥

0 s
iâˆˆV1 ci (qi )(1

P

âˆ’ qis ) since investment cost functions are sufficiently

< qie for all i âˆˆ V1 .

Example A.2 in the Appendix shows that Assumption 2 cannot be dispensed with for the results of Theorems 4.1 and 4.2, i.e., for tree networks, if the investment cost function is not sufficiently convex, the equilibrium need not be unique and expected infections in equilibrium may be
strictly lower than that at the social optimum.

14

5

Large Networks and Local Tree Structures

The previous section established that expected infections are greater in equilibrium than in the social optimum provided that investment cost functions are sufficiently convex and the network is a
tree. The latter assumption is particularly restrictive as communication networks do not generally
resemble trees (typically involve cycles, which are ruled out with the tree assumption). In this
section, we show that the same efficiency comparison holds for large networks provided that they
have a â€œlocal tree structureâ€.

5.1

Local Tree Structures

We start by defining the local tree concept formally.
Definition 2 (h-Local Tree Structure). A random network has h-local tree structure if the connected
component attached to each agent of the network is acyclic with probability at least h.
In other words, a local tree structure only requires a high probability that the components
attached to an agent is acyclic (thus it allows some probability of cycles and also cycles in other
parts of the network).
Our main result provides a relation between expected infections in equilibrium and in the social
optimum for a network with a local tree structure.
Theorem 5.1. Suppose Assumptions 1 and 2 hold. Given a network with 1 âˆ’ -local tree structure, we have
I(A, p, qe , Î¦) + n â‰¥ I(A, p, qs , Î¦) where qe and qs are the equilibrium and the socially optimal security
profiles.
The economic intuition of this result is closely related to Theorem 4.2, and again exploits sufficiently convex cost functions and the structure of the network, which now, with high probability,
rules out cycles in the spread of an infection within the component of the network attached to each
agent.The proof also illustrates the relationship between this result and Theorem 4.2. In particular,
the proof considers expected infections in cyclic and acyclic components of each interaction network separately. Expected infections in cyclic components is bounded above by expected number
of agents belonging to cyclic components and as a result is at most n. We then use a similar argument as in the proof of Theorem 4.2 to show that expected infections in the social optimum in
acyclic components of the interaction network is less than or equal to expected infections in the
equilibrium.

5.2

Large Networks and Local Tree Structures

One question posed by Theorem 5.1 is whether the remainder term, n, is truly small in the sense
that n(n) â†’ 0 as n â†’ âˆž (where we emphasize that this is not trivial because  is a function of n as
our notation (n) here underscores). We next show that for a random network model in which we
15

first generate the interaction network and then activate the edges independently with probability
p > 0, the answer is affirmative. In particular, under the right conditions on p, the network in
question has a 1 âˆ’ (n)-local tree structure and n(n) â†’ 0 as n â†’ âˆž.
In this random network model, we first generate the interaction network and then activate
edges independently with activation probability p. We use Aa to denote a realization of random
network A under the activation probability p and refer to it as the activated network. We will use
the terminology Aa is generated from (A, p), denoted by Aa âˆ¼ (A, p) to represent the dependence
on random graph A and the activation probability p. We next provide conditions on (A, p) under
which limnâ†’âˆž (n) as well as limnâ†’âˆž n(n) is 0.
Let the eigenvalue Î»(G) represent the second largest in absolute value of the adjacency matrix
of the degenerate network G. For a given d < n, let Gd denote the set of dâˆ’ regular graphs G
with Î»(G) = o(d). Combining Lemma A.5 and Theorem A.1 (see Appendix A.6), we obtain the
following theorem.
Theorem 5.2. Given random network A generated from (â„¦, F, P), where â„¦ = {G = (V, E)|E âŠ‚ EÌ‚, (V, EÌ‚) âˆˆ
Gd },
âˆš
â€¢ If d = â„¦( n) and p < d1 , the generated random network from (A, p) is a 1 âˆ’ (n)-local tree network
with limnâ†’âˆž (n) = 0.
â€¢ If p <

1
,
n log2 (n)

the generated random network from (A, p) is a 1 âˆ’ (n)-local tree network with

limnâ†’âˆž (n)n = 0.
Intuitively, for p small, all components of the random graph of size n are smaller than log n
with high probability. Then the result follows by bounding the probability of a cycle within each
component.

6

Symmetric and Island Networks

The previous two sections establish a comparison between expected infections in equilibrium and
social optimum for two classes of special networks (trees and large graphs with locally tree structure) under sufficiently convex cost functions. In this section, we establish a similar comparison
for symmetric random networks and for â€œislandsâ€ networks, which consist symmetric â€œislandsâ€
sparsely connected to each other. An important step in our results is to prove the uniqueness of
equilibrium, which rules out the possibility of highly asymmetric equilibria with counterintuitive
implications as in example in the Introduction. We end this section by providing a ranking of different random symmetric networks in terms of expected equilibrium infections, thus quantifying
which sorts of networks are likely to lead to greater contagion of infection.

16

6.1

Uniqueness of Equilibrium

Our next result establishes the existence of a unique symmetric pure-strategy Nash equilibrium
in symmetric networks (and no other equilibria) when the investment cost function is sufficiently
convex. An immediate corollary of this result that follows from Theorem 3.2 is then the comparison
of expected infections in equilibrium and social optimum.
Theorem 6.1. Suppose Assumptions 1 and 2 hold. Given symmetric random network A, there exists a
unique pure-strategy Nash equilibrium and a unique socially optimal security profile.
Corollary 6.1. Suppose Assumptions 1 and 2 hold. Given symmetric random network A, we have I(A, qe , Î¦) â‰¥
I(A, qs , Î¦) where qe and qs are the equilibrium and the socially optimal security profiles.
Recall from Section 3.3 that there is underinvestment in the symmetric equilibrium of symmetric networks (compared to the social optimum). The problem, however, was that there can also be
asymmetric equilibria in such symmetric networks which feature overinvestment. By establishing
uniqueness, Theorem 6.1 rules out such asymmetric equilibria and thus guarantees equilibrium
underinvestment.

6.2

Islands Network

In this subsection, we consider â€œislandsâ€ networks, which can be considered as a generalization
of symmetric networks in the sense that it combines a number of symmetric networks (islands).
Similar types of networks are also considered Golub and Jackson (2012).
Definition 3 (Islands networks). An islands network consists of a set of agents denoted by V , a set of
islands denoted by H = {H1 , H2 , . . . , Hn }, and a set of edges (or bridges) between the islands (i.e., between
randomly selected agents from the islands) denoted by T . Each agent v âˆˆ V resides on one island Hj âˆˆ H.
We assume that each Hi is a symmetric random network and the edges of T form a tree network when we
view each island as a supernode.
In the rest of this section, we use Hi to denote both the symmetric random network and the realized interaction network corresponding to island i. We abuse the notation and denote an islands
network by A = (V, H, T ). Our next result establishes uniqueness of equilibrium (again under
Assumptions 1 and 2).
Theorem 6.2. Suppose Assumptions 1 and 2 hold. For any islands network, there exists a unique purestrategy Nash equilibrium security profile.
Our main result for this subsection establishes that under Assumptions 1 and 2 in islands networks, expected infections is greater in equilibrium than the social optimum.
Theorem 6.3. Suppose Assumptions 1 and 2 hold. Given islands network A = (V, H, T ), we have
I(A, qe , Î¦) â‰¥ I(A, qs , Î¦) where qe and qs are the equilibrium and the socially optimal security profiles.
17

The proof and the intuition of this result follow those of Theorem 4.2, and are again based on
bounding the contribution of a subset of agents to the expected infections, but now focusing on
the contribution of an island (see in particular, Lemma A.6 in the Appendix).

6.3

Ranking Symmetric Networks

Our results so far have not been informative about the extent of contagion and expected infections
in a network (except for comparing between equilibrium and social optimum). In this subsection,
we provide a ranking across symmetric networks in terms of their expected equilibrium infections.
With this objective in mind, we represent the network structure in symmetric networks using
the following equivalent characterization: a symmetric random network can be generated from
a distribution over a set of fixed graphs G (referred to as base graphs) and a uniform allocation of
each agent to one of the nodes of the base graph. To simplify the exposition, we will focus on a
degenerate distribution over the base graphs (we assume there is only one base graph) though our
results extend to the more general case. We use G to denote the base graph and GÌ‚ to denote the
corresponding symmetric random network.
Our next result shows that as the base graph gets denser, expected equilibrium infections increases. We say that a graph G is denser than G0 , if G has additional links relative to G0 and denote
it by G0 âŠ‚ G. Since the equilibrium security profile in symmetric random graphs is always symmetric, without loss of generality we represent the equilibrium security profile with the symmetric
equilibrium security level in the rest of this section.
Theorem 6.4. Suppose Assumptions 1 and 2 hold. Given two base graphs G1 and G2 , if G1 âŠ‚ G2 then
I(GÌ‚1 , q1e , Î¦) â‰¤ I(GÌ‚2 , q2e , Î¦) where q1e and q2e represent the equilibrium security levels for GÌ‚1 and GÌ‚2 .
The economic idea here is simple. A denser network generates more interlinkages and thus
more pathways for an infection to spread. Recognizing this, agents will typically increase their
security investments in a denser network (relative to a less dense network), but under sufficiently
convex cost functions, this response will never dominate the increase in infection probabilities due
to the greater density of linkages.
The density of connections does not enable us to compare many important networks, including
trees. We next define a partial order on trees that allows us to compare equilibrium behavior. We
start by defining the distance vector for a tree network.
Definition 4 (Distance Vector). For a given tree network T , dT = (d1 , . . . , dn ) is the distance vector of
T , where di is the number of (distinct) pair of nodes that are at distance i âˆ’ 1 from each other.
For example, the distance vector for a star base graph Sn with n nodes is dSn = (0, 2(n âˆ’
1), (n âˆ’ 1)(n âˆ’ 2), 0, . . . , 0). For two tree networks T1 and T2 , we define a partial order in terms of
the distance vector as follows:

18

Definition 5 (Domination, â‰º). For two tree base structures T and T 0 , let dT = (d1 , . . . , dn ) and dT 0 =
(d0 , . . . , d0n ) represent their distance vector. Tree T dominates T 0 , denoted by T 0 â‰º T , if for all 1 â‰¤ i â‰¤ n,
P1i
Pi
0
j=1 dj â‰¤
j=1 dj .
Proposition 6.1. Suppose Assumptions 1 and 2 hold. For two symmetric networks with tree base graphs
T1 and T2 , if T2 â‰º T1 then I(TÌ‚1 , q1e , Î¦) â‰¥ I(TÌ‚2 , q2e , Î¦) where q1e and q2e denote the equilibrium security
levels in TÌ‚1 and TÌ‚2 .
One can show that for symmetric networks with tree base graphs, a star network dominates all
the other trees and the path network will be dominated by all trees. Note that this relation does
not provide a complete order over tree networks.
Our final result in this subsection provides a comparison of expected infections for any two
symmetric networks. For a given base graph G, let %G ( nk ) denote the normalized expected size
of the connected component attached to a random agent v in the induced subgraph of G over Vk
where Vk is the set of k randomly selected agents from G.
Theorem 6.5. Suppose Assumptions 1 and 2 hold. For two symmetric networks GÌ‚1 and GÌ‚2 with base
graphs G1 and G2 , I(GÌ‚1 , q1e , Î¦) â‰¥ I(GÌ‚2 , q2e , Î¦) if for q
all x âˆˆ [0, 1], %G1 (x) â‰¥ %G2 (x), and only if there is

no  > 0 and an interval I âŠ‚ [0, 1] of length at least
k
n

2 ln(2+2/)
n

such that %G1 ( nk ) < %G2 ( nk ) âˆ’  for all

âˆˆ I.
This result follows from the following characterization which enables us to express the number

of infected agents as a Bernstein polynomial of q with coefficients %G ( ni ).
Proposition 6.2. Given a base graph G with n nodes and a symmetric security profile q, expected equilibrium infections are given by
I(G, q, Î¦) =

n
X

i nâˆ’i

n(1 âˆ’ q) q

i=1

7

  
i
n
%G
.
n
i

Strategic Attack Model

We have so far focused on the random attack model where the attack decision Î¦ is determined
randomly and independently from the security investments of the agents. In many applications,
however, the attack is not a random event, but the act of a strategic adversary, intended on causing
maximum damage. This, in particular, implies that an attack may not be independent of security
investments. In this section, we focus on this latter case. The main insight is that strategic attack
generates another reason for overinvestment in security relative to the social optimum, this time
even with sufficiently convex cost functions.12
12

One could also consider a hybrid model where the attack can be targeted across agents according to their characteristics (e.g., their cost functions or their position in the network) but not according to their security investments â€”for
example, the attack decision takes place before or at the same time as the investment decisions. From the viewpoint
of overinvestment, this hybrid model would be similar to the random attack model, because agents cannot discourage
attacks by further increasing their investments.

19

More specifically, we consider a strategic attacker which, after observing the security profile of
agents, selects an attack decision Î¦ = (Ï1 , . . . , Ïn ) (where Ïi is the probability of attacking agent
i) to maximize his utility given by expected infections minus the cost of the attack decision. We
P
assume that the cost of an attack decision Î¦ is given by ni=1 Î¶(Ïi ) where Î¶ is a convex function
and twice continuously differentiable. A key assumption in our model is that the attacker observes
the security level of all the agents. We therefore analyze the Stackelberg equilibrium of the resulting
two stage game: the agents select their security levels anticipating the decision of the attacker and
the attacker optimizes his attack strategy given the security choices. Given the best response attack
strategy of the attacker, we refer to the Nash equilibrium among the agents as the Nash equilibrium
of the security game.
We introduce a convex cost function for the attacker both for substantive and technical reasons.
Substantively, targeting attacks according to the investment vector would require very precise
knowledge about each agentâ€™s investments. A convex cost function enables us to capture the idea
that the closer the attacker would like to come to precisely targeting one agent over all others,
the greater the cost it has to incur. Technically, pure-strategy equilibria may generally fail to exist
for reasons similar to the non-existence of pure-strategy equilibria and Bertrand competition with
capacity constraints, as the next example illustrates.
Example 7.1. Consider the network A with 2 singleton agents. We show that attacking a single agent
without cost may lead to nonexistence of a pure-strategy Nash equilibrium. For any security profile q,
the attacker selects the agent with minimum security level to attack. We next consider all possible candidates for the Nash equilibrium and present a profitable unilateral deviation for each candidate, establishing
nonexistence of a Nash equilibrium:
(a) q1 < q2 : In this case, agent 2 has incentive to decrease q2 , decreasing the cost without changing his
infection probability.
(b) q1 = q2 < 1: In this case agent 2 has incentive to slightly increase q2 . This reduces the probability of
him being attacked from

7.1

1
2

to 0 while slightly increasing his cost.

Equilibrium in the Strategic Attack Model

In this section, we study the equilibrium in the strategic attack model with convex cost. In the rest
of this section, we will use the following notations. We use 1n to denote the vector of dimension
n with each entry equal to n1 . Also we define the vector of all 0 except the ith entity which is 1 by
ei . The utility function of the attacker, given network A, security profile q, and an attack decision
Î¦ = (Ï1 , . . . , Ïn ), ua (A, q, Î¦) is defined as follows:
ua (A, q, Î¦) =

n
X
i=1

Ïi

I(A, q, ei )
âˆ’ Î¶(Ïi ).
n

20

In this model, since the security choices of agents impact the location of the attack, the network
effect on an agent is no longer independent of his security level, i.e., Proposition 3.1 does not hold
for this model. This implies that security investments will no longer satisfy the characterization
we used so far, cf. Eq. (3.2).
Nevertheless, expected infections when agent i is targeted (in the strategic attack model) are
closely linked to the infection probability of agent i under random attack model we have analyzed
so far (where, recall that, each agent is attacked with equal probability independent of their security investments). This property enables us to use the decomposition in Proposition 3.1 to write
the utility function of the attacker in closed form.
Lemma 7.1. Given random network A and security profile q, expected infections when agent i is attacked is equal to the network size times infection probability of agent i under the random attack model,
i.e., I(A, q, ei ) = nPi (A, q, 1n ) = n(1 âˆ’ qi )PÌƒi (A, qâˆ’i , 1n ).
Intuitively, the infection probability of agent i under the random attack model is the probability
of having a path between i and a randomly selected agent. Conveniently, expected infections when
i is attacked is given by the sum (over all j) of the probability of having a path between i and j,
and thus the two are closely linked as shown in the lemma.
Given attack decision Î¦ = (Ï1 , . . . , Ïn ) and attack cost function Î¶, let Î¨(Î¦) =
Î¥(Î¦) = max1â‰¤iâ‰¤n

|Î¶ 000 (Ï

Pn

1
i=1 Î¶ 00 (Ïi )

and

i )|
Î¶ 00 (Ïi ) .

Theorem 7.2. In the strategic attack model with convex cost, assume that c002 (Î¦)Î¥(1 âˆ’ q) + 2Î¨(Î¦) for any
attack decision Î¦. Then there exists a pure-strategy Nash equilibrium.
The condition in this theorem ensures that the utility of each agent with respect to their own
security level is concave. In the next section, we focus on symmetric random graphs. We show
that under some conditions over the attacker cost function, agents overinvest in the equilibrium
compared to the socially optimal solution.

7.2

Strategic Attacks over Symmetric Graphs

In this subsection, we consider the strategic attack model over symmetric networks. As explained
in subsection 3.3, in the random attack model the security investment of one agent creates a positive externality on other agents. Our results so far have shown that, under some assumptions,
this force ensures that expected equilibrium infections are greater than (or equal to) expected infections in the social optimum â€” even though, without these assumptions, overinvestment is also
possible in the random attack model. In the strategic attack model, however, security investments
also create negative externalities on others because they divert the attacker to other agents. The
next example shows the possibility of overinvestment with strategic attacks.
Example 7.2. Consider the line network discussed in Fig. 4 with investment cost function c0 (q) =
q
2(1âˆ’q)

for both agents, and attacker cost function Î¶(Ï) =
21

Ï2
24 .

It can be verified that the unique

Figure 4: Agents overinvest in the equilibrium relative to social optimum. For investment cost function
2
q
and the attack cost function Î¶(Ï) = Ï20 , the security investments in the equilibrium is
c0 (q) = 2(1âˆ’q)
qe = (0.66, 0.66) and the security investment in the social optimum is qs = (0.63, 0.63).

ð‘Ž

ð‘

(pure-strategy) Nash equilibrium is qe = (0.66, 0.66) while the socially optimal security profile is
qs = (0.63, 0.63).
The rest of this subsection provides sufficient conditions for overinvestment or underinvestment. The next assumption ensures that the cost function of the attacker is not â€œtoo convexâ€ because otherwise strategic attacks would be essentially like random attacks (deviating from uniform
probabilities of attack would be too costly).
Assumption 3 (Boundedly Convex Cost Function). The function Î¶ : [0, 1] â†’ R+ is boundedly
convex with Î±, Î² > 0 if
â€¢ Î¶ is twice continuously differentiable, strictly increasing and strictly convex on (0, 1],
â€¢ Î¶(0) = 0, Î¶ 0 (0) = 0,
â€¢ âˆ’Î± â‰¤ Î¶ 000 (x) < âˆ’Î² where 0 â‰¤ x â‰¤ 1.
Theorem
7.3. Suppose Assumption 3 holds with Î±, Î² > 0. Given symmetric random network A with
q
Î±
n â‰¥ Î² + 1, a pure-strategy Nash equilibrium always exists.
The proof of this theorem is straightforward and involves showing that the utility of each agent
is concave under Assumption 3.
Our main results in this section is presented next and provides sufficient conditions for overinvestment and underinvestment.
Theorem 7.4. Suppose Assumption 3 holds. Given symmetric random network A agents will overinvest
in the symmetric equilibrium relative to the symmetric socially optimal solution if
â€¢ Î¶ 00 ( n1 ) â‰¤

0âˆ’1 ( 1 )(1âˆ’c0âˆ’1 ( 1 ))
nâˆ’1 c
n
n
2
n 1+(nâˆ’1)(1âˆ’c0âˆ’1 ( 1 ))

when c0âˆ’1 (n) â‰¤ 1 âˆ’

âˆš1 ,
n+1

â€¢ Î¶ 00 ( n1 ) â‰¤

nâˆ’1 c0âˆ’1 (n)(1âˆ’c0âˆ’1 (n))
,
n2 1+(nâˆ’1)(1âˆ’c0âˆ’1 (n))

when c0âˆ’1 ( n1 ) â‰¥ 1 âˆ’

âˆš1 ,
n+1

n

0âˆ’1

0âˆ’1

c0âˆ’1 ( 1 )(1âˆ’c0âˆ’1 ( 1 ))

c
(n)(1âˆ’c
(n)) nâˆ’1
1
n
n
â€¢ Î¶ 00 ( n1 ) â‰¤ min( nâˆ’1
,
). when c0âˆ’1 ( n1 ) â‰¤ 1âˆ’ âˆšn+1
â‰¤ c0âˆ’1 (n).
n2 1+(nâˆ’1)(1âˆ’c0âˆ’1 (n)) n2 1+(nâˆ’1)(1âˆ’c0âˆ’1 ( 1 ))
n

22

Also if Î¶ 00 ( n1 ) â‰¥ 1 then agents always underinvest in the symmetric equilibrium relative to the symmetric
socially optimal solution.
The various conditions in this theorem are intuitive. They link under/overinvestment to the
convexity of the attackerâ€™s cost function. Overinvestment requires this cost function not to be â€œtoo
convexâ€ since, otherwise, the attacker would choose probabilities very close to those in the random
attack model (uniform across all agents), thus muting negative externalities. When either of these
three conditions in the first part of the theorem is satisfied, negative externalities are non-trivially
present because when an agent increases its security investment, it anticipates that this will trigger
a large decline in its own probability of being the target of the attack. This creates an â€œarms raceâ€
between agents and leads to overinvestment. In contrast, when the attackerâ€™s cost function is
sufficiently convex, there will be little response of attack probabilities to security investments, in
which case the same forces as in the random attack model dominate and ensure underinvestment
(recall that under conditions of Theorem 7.4, there is underinvestment with random attacks).

8

Conclusion

This paper has developed a model of investment in security in a network of interconnected agents.
Our baseline model is one of random attacks. Network connections introduce the possibility of
cascading failures depending on the profile of security investments by the agents. The existing
literature has identified a central positive externality in this environment: security investments
reduce the likelihood of an infection spreading to other agents, and because each agent ignores
this effect, the existing literature has presumed that there will be underinvestment in security.
We first show that this reasoning is incomplete because of another first-order economic force:
security investments are also strategic substitutes. In a general (non-symmetric) network, this implies that underinvestment by some agents will encourage overinvestment by others. We demonstrate by means of examples that not only can there be overinvestment by some agents but also
aggregate probabilities of infection can be lower in equilibrium compared to the social optimum.
The bulk of the paper provides a detailed characterization of investment decisions over general networks and sufficient conditions for underinvestment. Our results here rely on a new and
tractable decomposition of the probability of infection of an individual into an own and an externality effect. Using this result, we show that there will be equilibrium underinvestment when (1)
networks are locally tree-like, symmetric or comprised of sparsely connected islands of symmetric networks; (2) cost functions are sufficiently convex, which guarantee that when an agent faces
a higher likelihood of being infected because of othersâ€™ choices, his or her investment does not
increase so much as to reduce her overall probability of infection.
We also characterize the impact of network structure on equilibrium and optimal investments.
Finally, we also extend our analysis to an environment with strategic attacks, where the attacker
chooses a probability distribution over the location of the attack in order to maximize damage. We
23

first relate probabilities of infection under strategic attacks to those under random attacks, and
then provide sufficient conditions for over and underinvestment in this case. The intuition for
overinvestment in this case is simple: greater investment by an agent shifts the attack to other
parts of the network.
We view our paper as a first step towards a systematic analysis of contagion over networks
in the presence of precautionary behavior and security investments. Obvious next steps include
more dynamic models and models in which contagion takes different forms reflecting different
economic forces (e.g., resulting from the bankruptcy of a financial institution indebted to others as
in Acemoglu, Ozdaglar and Tahbaz-Salehi, 2013).

References
[1] D. ACEMOGLU, A. OZDAGLAR, and A. TAHBAZ-SALEHI, â€œSystemic risk and stability in
financial networks,â€ NBER working paper, National Bureau of Economic Research, 2013.
[2] R. ANDERSON and T. MOORE, â€œThe economics of information security,â€ Science, vol. 314,
no. 5799, pp. 610â€“613, 2006.
[3] M. BACCARA and H. BAR-ISAAC, â€œHow to organize crime,â€ Review of Economic Studies,
vol. 75, no. 4, pp. 1039â€“1067, 2008.
[4] Y. BACHRACH, M. DRAIEF, and S. GOYAL, â€œCompetig for security,â€ working paper, 2012.
[5] V. BALA and S. GOYAL, â€œA noncooperative model of network formation,â€ Econometrica,
vol. 68, no. 5, pp. 1181â€“1230, 2000.
[6] L. BLUME, D. EASLEY, J. KLEINBERG, R. KLEINBERG, and E. TARDOS, â€œNetwork formation in the presence of contagious risk,â€ in 12th ACM conference on Electronic commerce, pp. 1â€“
10, 2011.
[7] D. L. BRITO, E. SHESHINSKI, and M. D. INTRILIGATOR, â€œExternalities and compulsary
vaccinations,â€ Journal of Public Economics, vol. 45, no. 1, pp. 69 â€“ 90, 1991.
[8] F. CHUNG and L. LU, â€œConnected components in random graphs with given expected degree
sequences,â€ ANNALS OF COMBINATORICS, vol. 6, no. 2, pp. 125â€“145, 2002.
[9] D. DE MEZA and J. R. GOULD, â€œThe social efficiency of private decisions to enforce property
rights,â€ Journal of Political Economy, vol. 100, no. 3, pp. 561â€“80, 1992.
[10] P. GEOFFARD and T. PHILLIPSON, â€œDisease eradication: Private versus public vaccination,â€
American Economic Review, vol. 87, no. 1, pp. 222â€“30, 1997.
[11] S. M. GOLDMAN and J. LIGHTWOOD, â€œCost optimization in the SIS model of infectious
disease with treatment,â€ working paper, University of California at Berkeley, 1995.
24

[12] B. GOLUB and M. JACKSON, â€œHow homophily affects the speed of learning and bestresponse dynamics,â€ The Quarterly Journal of Economics, vol. 127, no. 3, 2012.
[13] S. GOYAL and A. VIGIER, â€œRobust networks,â€ Mimeo, Cambridge University, 2011.
[14] S. GOYAL and A. VIGIER, â€œSocial interaction, vaccination, and epidemics,â€ working paper,
2013.
[15] B. HOYER and K. D. JAEGHER, â€œStrategic network disruption and defense,â€ working paper,
Utrecht School of Economics, 2010.
[16] M. O. JACKSON, Social and Economic Networks. Princeton University Press, 2008.
[17] M. JACKSON and A. WOLINSKY, â€œA strategic model of social and economic networks,â€
Journal of Economic Theory, vol. 71, no. 1, pp. 44 â€“ 74, 1996.
[18] D. KOVENOCK and B. ROBERSON, â€œThe optimal defense of networks of targets,â€ working
paper, 2010.
[19] N. LARSON, â€œNetwork security,â€ MPRA paper, University Library of Munich, Germany,
2011.
[20] M. MOLLOY and B. REED, â€œThe size of the giant component of a random graph with a given
degree sequence,â€ Combinatorics, Probability and Computing, vol. 7, pp. 295â€“305, 1998.
[21] M. MOLLOY and B. REED, â€œA critical point for random graphs with a given degree sequence,â€ Random Structures and Algorithms, no. 6, pp. 161â€“180, 2000.
[22] M. E. J. NEWMAN, S. H. STROGATZ, and D. J. WATTS, â€œRandom graphs with arbitrary
degree distributions and their applications,â€ Physical Review E, vol. 64, p. 026118, 2001.
[23] J. L. SANDERS, â€œQuantitative guidelines for communicable disease control programs,â€ Biometrics, vol. 27, no. 4, pp. 883â€“893, 1971.
[24] S. P. SETHI, â€œQuantitative guidelines for communicable disease control program: A complete
synthesis,â€ Biometrics, vol. 30, no. 4, pp. 681â€“691, 1974.
[25] F. TOXVAERD, â€œFoundations of strategic epidemiology: Recurrent infection and treatment,â€
working paper, 2009.
[26] VEGA-REDONDO, Complex Social Networks. Cambridge University Press, 2007.

25

A

Appendix

A.1

Background Material

Theorem A.1 (Frieze, Krivelevich, Martin 2003). Let G be a dâˆ’ regular graph with Î» = o(d). Let Gp
with p =

Î±
d

be obtained from G by including each edge with probability p. If Î± < 1, with high probability

the maximum component size of Gp is O(log(n)).
Theorem A.2 (Bernstein Polynomials). The n + 1 Bernstein basis polynomials of degree n are defined as

bÎ½,n (x) = nÎ½ xÎ½ (1 âˆ’ x)nâˆ’Î½ , Î½ = 0, . . . , n.
Let f be a continuous function on the interval [0, 1]. Consider the Bernstein polynomial
 
n
X
Î½
Bn (f )(x) =
f
bÎ½,n (x).
n
Î½=0

Then we have,
lim Bn (f )(x) = f (x)

nâ†’âˆž

uniformly on the interval [0, 1].
Theorem A.3 (Hoeffdingâ€™s Inequality). Let Z1 , . . . , Zn be independent, identically distributed random
variables, such that 0 â‰¤ Zi â‰¤ 1. Then,
ï£«

ï£¶
n
X
1
2
Zi âˆ’ E[Z] > ï£¸ â‰¤ 2eâˆ’2n .
Pr ï£­
n
i=1

A.2

Proofs of Section 3: Random Attack Model

Proof of Proposition 3.1 (Network Effect). Agent i gets infected only if i is susceptible. Let (Xi )
denote the event that agent i is susceptible. The infection probability of i can be stated as,
Pi (A, q, Î¦) = Pi (A, q, Î¦|(Xi ))(1 âˆ’ qi ).

(A.1)

We next show that Pi (A, q, Î¦|(Xi )) does not depend on qi . By definition, in a given transmission
At

network At , i gets infected if s is connected to i in At . Let i âˆ’â†’ j denote the event that i is connected
to j in At . Using this definition, the infection probability of i conditional on (Xi ) can be written as
Pi (A, q, Î¦|(Xi )) =

X

P(A,q) (At |(Xi ))
At

{At |sâˆˆAt âˆ©iâˆ’â†’s}

=

X

X
At

{At |sâˆˆAt âˆ©iâˆ’â†’s}

{Ar ,V

s âŠ†V

26

|At =Ar [V

P(Ar )
s ]}

Y
jâˆˆVs j6=i

(1 âˆ’ qj )

Y
j6âˆˆVs

qj ,

where the second equality follows from the definition of the probability of the transmission network and the fact that conditional on (Xi ), i âˆˆ Vs with probability 1. This shows that Pi (A, q, Î¦|(Xi ))
is independent of qi . Substituting Pi (A, q, Î¦|(Xi )) with PÌƒi (A, qâˆ’i , Î¦) in Eq. (A.1) we obtain
Pi (A, q, Î¦) = (1 âˆ’ qi )PÌƒi (A, qâˆ’i , Î¦).

Proof of Proposition 3.2 (Decomposition). As in the previous proof, let (Xi ) denote the event that
At

agent i is susceptible and i âˆ’â†’ j denote the event that i is connected to j in At . In the given
network A, denote the seed node by s. In the transmission network At âˆ¼ (A, q), for two agents j
and i with i 6= j, one of the following mutually exclusive events will happen:
(A) s is connected to j in Atâˆ’i .
(B) s is not connected to j in At âˆ’i , but is connected to j in At .
(C) s is not connected to j in At .
Agent j gets infected if event (A) or (B) happens. We next express infection probability of agent j
A

as the sum of probabilities of events (A) and (B). Let i âˆ’
â†’ j denote the event that i is connected to
j in A. Also, let Aj denote the collection of transmission networks in which j is connected to s, i.e.,
At

Aj = {At âˆ¼ (A, q)|j âˆ’â†’ s}. The infection probability of agent j can be written as
Pj (A, q, Î¦) =

X
At âˆˆAj

X

P(A,q) (At ) =

X

P(A,q) (At ) +

{At |Atâˆ’i âˆˆAjâˆ’i }

{At |Atâˆ’i 6âˆˆAjâˆ’i

T

P(A,q) (At ),

(A.2)

At âˆˆAj }

where the first term is the probability of event (A) and the second term is the probability of event
(B).
We first show that the first term in Eq. (A.2) can be written as
X

P(A,q) (At ) = Pj (Aâˆ’i , qâˆ’i , Î¦).

(A.3)

{At |Atâˆ’i âˆˆAjâˆ’i }

By definition
X

Pj (Aâˆ’i , qâˆ’i , Î¦) =

P(Aâˆ’i ,qâˆ’i ) (AÌ„t ).

(A.4)

{AÌ„t |AÌ„t âˆˆAjâˆ’i }

The probability of the transmission network AÌ„t generated from (Aâˆ’i , qâˆ’i ) can be written as the
marginal probability of the transmission network At that satisfies Atâˆ’i = AÌ„t , i.e.,
X

P(Aâˆ’i ,qâˆ’i ) (AÌ„t ) =

{At |Atâˆ’i =AÌ„t }

27

P(A,q) (At ).

Combining the preceding relation with Eq. (A.4), we obtain
X

Pj (Aâˆ’i , qâˆ’i , Î¦) =

X

X

P(A,q) (At ) =

t

{AÌ„t |AÌ„t âˆˆAjâˆ’i } {At |Aâˆ’i =AÌ„t }

P(A,q) (At ),

{At |Atâˆ’i âˆˆAjâˆ’i }

which shows the desired result.
We next rewrite the second term in Eq. (A.2), i.e., probability of event (B) by conditioning it on
the event that i and j are susceptible:
X
{At |Atâˆ’i 6âˆˆAjâˆ’i

T

X

P(A,q) (At ) = (1 âˆ’ qi )(1 âˆ’ qj )

{At |Atâˆ’i 6âˆˆAjâˆ’i

At âˆˆAj }

T

P(A,q) (At |(Xi ) âˆ© (Xj )). (A.5)
At âˆˆAj }

Let Qj,i () be the function that represents the probability of event (B) conditional on the event
P
(Xi ) âˆ© (Xj ). Clearly, {At |At 6âˆˆAj âˆ©At âˆˆAj } P(A,q) (At |(Xi ) âˆ© (Xj )) only depends on qâˆ’{i,j} and A
âˆ’i

âˆ’i

and is independent of qi and qj . Hence, Qj,i () is a function of A, qâˆ’{i,j} , and Î¦. Hence, it can be
expressed as Qj,i (A, qâˆ’{i,j} , Î¦). Combining the preceding relation with Eqs. (A.2),(A.3), and (A.5)
and using Proposition 3.1, we obtain
Pj (A, q, Î¦) = Pj (Aâˆ’i , qâˆ’i , Î¦) + (1 âˆ’ qi )(1 âˆ’ qj )Qj,i (A, qâˆ’{i,j} , Î¦)


= (1 âˆ’ qj ) PÌƒj (Aâˆ’i , qâˆ’i , Î¦) + (1 âˆ’ qi )Qj,i (A, qâˆ’{i,j} , Î¦) .
By applying Proposition 3.1 to the preceding equation, we obtain
PÌƒj (A, qâˆ’j , Î¦) =

Pj (A, q, Î¦)
= PÌƒj (Aâˆ’i , qâˆ’{i,j} , Î¦) + (1 âˆ’ qi )Qj,i (A, qâˆ’{i,j} , Î¦).
1 âˆ’ qj

which shows the desired result.
Proof of Proposition 3.3. (a) Network Effect Monotonicity in Security Profile We first show that
given network A and two security profiles qâˆ’i and qÌ‚âˆ’i with qâˆ’i â‰¥ qÌ‚âˆ’i , we have PÌƒi (A, qâˆ’i , Î¦) â‰¤
PÌƒi (A, qÌ‚âˆ’i , Î¦).
Let VÌ‚ denote the set of agents with strictly higher security levels in the security profile q
compared to qÌ‚, i.e., VÌ‚ = {v âˆˆ Vâˆ’i | qv > qÌ‚v }. We prove the claim by induction on |VÌ‚ |. The
base case is immediate: If |VÌ‚ | = 0, then qv = qÌ‚v for all v âˆˆ Vâˆ’i . Hence, PÌƒi (A, qâˆ’i , Î¦) =
PÌƒi (A, qÌ‚âˆ’i , Î¦).
We next assume that for an integer m > 0, if |VÌ‚ | = m, the claim holds, i.e., PÌƒi (A, qâˆ’i , Î¦) â‰¤
PÌƒi (A, qÌ‚âˆ’i , Î¦) (Induction Hypothesis). We will next prove that the claim still holds if |VÌ‚ | =
m + 1. Consider an arbitrary agent 1 âˆˆ VÌ‚ . Define a new security profile qÌƒ such that qÌƒv = qv
for all v 6= 1, and qÌƒ1 = qÌ‚1 . Note that qâˆ’i and qÌƒâˆ’i only differ in the security level of agent 1.
We first show that PÌƒi (A, qâˆ’i , Î¦) â‰¤ PÌƒi (A, qÌƒâˆ’i , Î¦). Using Proposition 3.2 (with the identifica-

28

tion j = i and i = 1), we can rewrite PÌƒi (A, qâˆ’i , Î¦) as
PÌƒi (A, qâˆ’i , Î¦) = PÌƒi (Aâˆ’1 , qâˆ’{1,i} , Î¦) + Qi,1 (A, qâˆ’{i,1} , Î¦)(1 âˆ’ q1 )
â‰¤ PÌƒi (Aâˆ’1 , qâˆ’{1,i} , Î¦) + Qi,1 (A, qâˆ’{i,1} , Î¦)(1 âˆ’ qÌƒ1 )
= PÌƒi (Aâˆ’1 , qÌƒâˆ’{1,i} , Î¦) + Qi,1 (A, qÌƒâˆ’{i,1} , Î¦)(1 âˆ’ qÌƒ1 ) = PÌƒi (A, qÌƒâˆ’i , Î¦).

(A.6)

The inequality follows from qÌƒ1 = qÌ‚1 < q1 and the last equality follows from qÌƒj = qj for all
j 6= 1.
We next compare PÌƒi (A, qÌƒâˆ’i , Î¦) with PÌƒi (A, qÌ‚âˆ’i , Î¦). First note that qÌƒ â‰¥ qÌ‚. Moreover, we have
|{j âˆˆ Vâˆ’i | qÌƒj > qÌ‚j }| = m. By induction hypothesis, it implies that

PÌƒi (A, qÌƒâˆ’i , Î¦) â‰¤ PÌƒi (A, qÌ‚âˆ’i , Î¦).

(A.7)

Combining Eqs. (A.6) and (A.7), we obtain PÌƒi (A, qâˆ’i , Î¦) â‰¤ PÌƒi (A, qÌ‚âˆ’i , Î¦).
(b) Network Effect Monotonicity in Network Density We show that given VÌ‚ âŠ‚ V and agent i âˆˆ
V âˆ’ VÌ‚ , PÌƒi (Aâˆ’VÌ‚ , qâˆ’VÌ‚ âˆª{i} , Î¦) â‰¤ PÌƒi (A, qâˆ’i , Î¦). Using Proposition 3.1, we have
Pi (Aâˆ’VÌ‚ , qâˆ’VÌ‚ , Î¦) = (1 âˆ’ qi )PÌƒi (Aâˆ’VÌ‚ , qâˆ’(VÌ‚ âˆª{i}) , Î¦).
By definition, PÌƒi (Aâˆ’VÌ‚ , qâˆ’(VÌ‚ âˆª{i}) , Î¦) is the probability of infection reaching agent i in Aâˆ’VÌ‚ .
Consider a transmission network AÌ„t generated from (Aâˆ’VÌ‚ , qâˆ’VÌ‚ ) in which infection can reach
agent i. The probability of the transmission network AÌ„t can be written as the marginal probability of the transmission networks At generated from (A, q) that satisfies Atâˆ’VÌ‚ = AÌ„t . Furthermore, in any transmission network At that satisfies Atâˆ’VÌ‚ = AÌ„t , infection can reach agent
i. Hence, the probability of infection reaching agent i in a transmission network generated
from (A, q) is at least PÌƒi (Aâˆ’VÌ‚ , qâˆ’(VÌ‚ âˆª{i}) , Î¦). In other words,
PÌƒi (Aâˆ’VÌ‚ , qâˆ’VÌ‚ âˆª{i} , Î¦) â‰¤ PÌƒi (A, qâˆ’i , Î¦).
(c) Best Response Monotonicity in Network Effect Given network A and security profiles qâˆ’i
and qÌ‚âˆ’i , if PÌƒi (A, qâˆ’i , Î¦) â‰¥ PÌƒi (A, qÌ‚âˆ’i , Î¦), then Bi (qâˆ’i ) â‰¥ Bi (qÌ‚âˆ’i ). Using Eq. 3.2, it implies
that
c0i (Bi (qâˆ’i )) = PÌƒi (A, qâˆ’i , Î¦) â‰¥ PÌƒi (A, qÌ‚âˆ’i , Î¦) = c0i (Bi (qÌ‚âˆ’i )).
Combining the preceding inequality with Assumption 1, it follows that Bi (qâˆ’i ) â‰¥ Bi (qÌ‚âˆ’i )
which shows the desired result.

29

Proof of Eq. (3.4). Let Bi (qâˆ’i ) and Si (qâˆ’i ) denote the best response strategy and welfare maximizing strategy of agent i. We show that Bi (qâˆ’i ) â‰¤ Si (qâˆ’i ). Using Eq. 3.2, we have
c0i (Bi (qâˆ’i )) = PÌƒi (A, qâˆ’i , Î¦).
Moreover, it follows from Eq. 3.3 that
c0i (Si (qâˆ’i )) = PÌƒi (A, qâˆ’i , Î¦) +

X

Qj,i (A, qâˆ’{i,j} , Î¦)(1 âˆ’ qj ).

j6=i

By definition, Qj,i (A, qâˆ’{i,j} , Î¦)(1 âˆ’ qj ) is a probability. Therefore,
PÌƒi (A, qâˆ’i , Î¦) +

X

Qj,i (A, qâˆ’{i,j} , Î¦)(1 âˆ’ qj ) â‰¥ PÌƒi (A, qâˆ’i , Î¦),

j6=i

implying that c0i (Si (qâˆ’i )) â‰¥ c0i (Bi (qâˆ’i )). The claim follows by the assumption that ci () is strictly
convex (cf. Assumption 1), and therefore c0i () is a strictly increasing function.

A.3

Proofs of Subsection 3.3: Symmetric Networks

Proof of Theorem 3.2.
Existence of the symmetric pure-strategy Nash equilibrium We show that there exists a q e âˆˆ [0, 1]
such that u(A, q, Î¦) achieves its maximum at q = qen . Due to symmetry, we have
âˆ‚
âˆ‚
u(A, q, Î¦)|q=qn =
u(A, q, Î¦)|q=qn âˆ€ i, j âˆˆ V.
âˆ‚qi
âˆ‚qj

(A.8)

Let
f (x) =

âˆ‚
u(A, q, Î¦)|q=xn .
âˆ‚qj

We next show that, f (x) is a decreasing function in x.
The continuity and differentiability of u(A, qn , Î¦) follows from Propositions 3.1, 3.2 and Assumption 1. By definition,
u(A, qn , Î¦) = 1 âˆ’ (1 âˆ’ q)PÌƒ (A, qnâˆ’1 , Î¦) âˆ’ c(q).
Hence,
f (q) = PÌƒ (A, qnâˆ’1 , Î¦) âˆ’ c0 (q).
Using Proposition 3.3(a), we have PÌƒ (A, qnâˆ’1 , Î¦) is a decreasing function in q. Also by As30

sumption 1, c0 (q) is continuous and strictly increasing, which shows that f (q) is strictly decreasing in q. We next show that, there exists a unique q e âˆˆ (0, 1) such that f (q e ) = 0. Using
Assumption 1 and the inequality 0 â‰¤ PÌƒ (A, qnâˆ’1 , Î¦) â‰¤ 1 , it is guaranteed that f (0) â‰¥ 0 and
f (1) < 0. Therefore, there exists a unique q e such that f (q e ) = 0. As a result, using Eq. (A.8),
qen is the unique symmetric equilibrium.
Underinvestment in the symmetric equilibrium We next show that in the symmetric equilibrium,
q e â‰¤ q s . For the sake of contradiction, assume q e > q s . We next show that under this assumption, we have c0 (q s ) â‰¥ c0 (q e ). Using Eqs. (3.2), (3.3), and the fact that PÌƒ (A, qnâˆ’1 , Î¦) is
decreasing in q, the following relations hold.
c0 (q s ) = PÌƒ (A, qsnâˆ’1 , Î¦) âˆ’ (1 âˆ’ q s )

âˆ‚
PÌƒ (A, qsnâˆ’1 , Î¦)
âˆ‚q s

â‰¥ PÌƒ (A, qsnâˆ’1 , Î¦)
â‰¥ PÌƒ (A, qenâˆ’1 , Î¦)
= c0 (q e ),
where the second inequality follows from Proposition 3.3(a). Nevertheless, Assumption 1
implies that c0 (q e ) > c0 (q s ) assuming q e > q s . This contradicts the preceding inequality,
completing the proof.

A.4

Proofs of Section 4: Sufficiently Convex Cost Functions

Proof of Lemma 4.1. Since qâˆ’i and qÌ‚âˆ’i satisfy PÌƒi (A, qâˆ’i , Î¦) â‰¥ PÌƒi (A, qÌ‚âˆ’i , Î¦), it follows from Proposition 3.3 (c) that Bi (qâˆ’i ) â‰¥ Bi (qÌ‚âˆ’i ). Using Proposition 3.1 and the characterization of the best
response strategy of an agent given in Eq. (3.2), we obtain
Pi (A, (Bi (qâˆ’i ), qâˆ’i ), Î¦) = PÌƒi (A, qâˆ’i , Î¦)(1 âˆ’ Bi (qâˆ’i )) = c0i (Bi (qâˆ’i ))(1 âˆ’ Bi (qâˆ’i )).
Similarly, we have
Pi (A, (Bi (qÌ‚âˆ’i ), qÌ‚âˆ’i ), Î¦) = c0i (Bi (qÌ‚âˆ’i ))(1 âˆ’ Bi (qÌ‚âˆ’i )).
Since ci is sufficiently convex (cf. Assumption 2) and Bi (qâˆ’i ) â‰¥ Bi (qÌ‚âˆ’i ), we have
c0i (Bi (qâˆ’i ))(1 âˆ’ Bi (qâˆ’i )) â‰¥ c0i (Bi (qÌ‚âˆ’i ))(1 âˆ’ Bi (qÌ‚âˆ’i )),
which using the preceding relations implies
Pi (A, (Bi (qâˆ’i ), qâˆ’i ), Î¦) â‰¥ Pi (A, (Bi (qÌ‚âˆ’i ), qÌ‚âˆ’i ), Î¦).

31

Figure 5: Tree uniqueness

Proof of Theorem 4.1. Assume to arrive at a contradiction that we have two different equilibrium
security profiles qe and qÌ‚e . Using qe and qÌ‚e , we can partition the nodes into three sets V1 , V2 and
V3 as follows:
qie > qÌ‚ie for all i âˆˆ V1 ,
qie = qÌ‚ie for all i âˆˆ V2 ,
qie < qÌ‚ie for all i âˆˆ V3 .
We first show that the sets V1 and V3 are non-empty. Assume the contrary and suppose V3 is
empty. This implies that qe â‰¥ qÌ‚e . Moreover, since qe 6= qÌ‚e , there exists an agent i âˆˆ V1 with
e â‰¥ qÌ‚ e , Proposition 3.3(a) implies that PÌƒ (A, qe , Î¦) â‰¤ PÌƒ (A, qÌ‚e , Î¦). Using
qie > qÌ‚ie . Since qâˆ’i
i
i
âˆ’i
âˆ’i
âˆ’i

Proposition 3.3(c), it follows that qie = Bi (qeâˆ’i ) â‰¤ Bi (qÌ‚eâˆ’i ) = qÌ‚ie , yielding a contradiction. A similar
argument can be used to show that the set V1 is nonempty.
For the rest of the proof, we use the notation L(i) to denote the set Vj , j = 1, 2, 3, that node i
belongs to, i.e., L(i) = Vj if and only if i âˆˆ Vj . Furthermore, we define the tree order with respect to
a node r as the partial order on the nodes of a tree with u < v if and only if the unique path from r
to v passes through u. For a tree order (with respect to an arbitrary node r), it follows immediately
that there exists an edge (x, y) âˆˆ E such that (a) L(x) 6= L(y), x < y, and (b) For all v 0 âˆˆ V such
that y < v 0 , we have L(y) = L(v 0 ). Let Y = {v âˆˆ V | v > y}.13
13

Since both V1 and V3 are non-empty, there always exists an edge (x, y) with L(x) 6= L(y) and x < y: among these
edges, pick the one with the largest distance from r.

32

Assume without loss of generality that x âˆˆ V1 and y âˆˆ V3 , i.e.,14
qxe > qÌ‚xe ,

qye < qÌ‚ye ,

qve < qÌ‚ve

for all v âˆˆ Y.

Hence, agent x invests more in security in qe than in qÌ‚e , and agent y and agents in set Y invest
in more security in qÌ‚e than in qe . This is illustrated in Fig. 5. Using the sufficiently convex cost
assumption (cf. Assumption 2) and Lemma 4.1, we have
Px (A, qe , Î¦) > Px (A, qÌ‚e , Î¦),

(A.9)

Py (A, qe , Î¦) < Py (A, qÌ‚e , Î¦).

(A.10)

In view of the tree network structure, we can decompose infection probability of agents x and
y using the network effect on x when y is removed from the network and the network effect on y
when x is removed from the network. More specifically, let PÌ‚x and PÌ‚y denote infection probabilities
of agents x and y when agents y and x are removed from the network respectively, i.e.,
PÌ‚x (q) = PÌƒx (Aâˆ’y , qâˆ’{x,y} , Î¦)(1 âˆ’ qx ),
PÌ‚y (q) = PÌƒy (Aâˆ’x , qâˆ’{x,y} , Î¦)(1 âˆ’ qy ).
Using PÌ‚x and PÌ‚y , we can write down infection probabilities of agents x and y as follows:
Px (A, qe , Î¦) = PË†x (qe ) + (1 âˆ’ qxe )PË†y (qe ),

(A.11)

Py (A, qe , Î¦) = PË†y (qe ) + (1 âˆ’ qye )PË†x (qe ).

(A.12)

Substituting PË†x (qÌ‚e ) and PË†y (qÌ‚e ) for PË†x (qe ) and PË†y (qe ) in the above equations, we obtain similar
relations for Px (A, qÌ‚e , Î¦) and Py (A, qÌ‚e , Î¦).
Since all agents in Y belong to set V3 , it follows from Proposition 3.3(a) that
PË†y (qe ) â‰¥ PË†y (qÌ‚e ).

(A.13)

There are two cases to consider:
(a) PË†x (qe ) â‰¥ PË†x (qÌ‚e ): In this case, using Eqs. (A.12) and (A.13), we obtain Py (A, qe , Î¦) â‰¥
Py (A, qÌ‚e , Î¦), contradicting Eq. (A.10).
14

The argument that follows will also hold if we assume one of these agents belong to V2 .

33

(b) PË†x (qe ) < PË†x (qÌ‚e ): Using Eq. (A.13) and the fact that qxe > qÌ‚xe , we obtain


PË†y (qe ) âˆ’ PË†y (qÌ‚e ) â‰¥ PË†y (qe ) âˆ’ PË†y (qÌ‚e ) (1 âˆ’ qÌ‚xe )
â‰¥ PË†y (qe )(1 âˆ’ qxe ) âˆ’ PË†y (qÌ‚e )(1 âˆ’ qÌ‚ex ).

(A.14)

Furthermore, since PË†x (qe ) < PË†x (qÌ‚e ) and qye < qÌ‚ye , we obtain


PË†x (qe )(1 âˆ’ qye ) âˆ’ PË†x (qÌ‚e )(1 âˆ’ qÌ‚ye ) â‰¥ PË†x (qe ) âˆ’ PË†x (qÌ‚e ) (1 âˆ’ qÌ‚ye )
â‰¥ PË†x (qe ) âˆ’ PË†x (qÌ‚e ).

(A.15)

Combining Eqs. (A.14) and (A.15), we have
(PË†y (qe ) + PË†x (qe )(1 âˆ’ qye )) âˆ’ (PË†y (qÌ‚e ) + PË†x (qÌ‚e )(1 âˆ’ qÌ‚ye ))
â‰¥ (PË†x (qe ) + PË†y (qe )(1 âˆ’ qxe )) âˆ’ (PË†x (qÌ‚e ) + PË†y (qÌ‚e )(1 âˆ’ qÌ‚xe )).
Using the expressions in Eqs. (A.11) and (A.12), this implies
Py (A, qe , Î¦) âˆ’ Py (A, qÌ‚e , Î¦) â‰¥ Px (A, qe , Î¦) âˆ’ Px (A, qÌ‚e , Î¦) â‰¥ 0,
where the last inequality follows from Eq. (A.9) and yields a contradiction.

Proof of Lemma 4.2. We first show the following stronger statement: Given tree network A and
set VÌ„ âŠ‚ V , for any i, j âˆˆ V âˆ’ VÌ„ , we have
Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦) â‰¤ Qj,i (A, qâˆ’{j,i} , Î¦).

(A.16)

Given tree network A, one of the following mutually exclusive events happens:
(A) The unique path between s (seed node) and j in the tree network includes i.
(B) The unique path between s and j in the tree network does not include i.
If event (B) happens, the probability that infection reaches j stays unchanged after i is removed
from the tree in both A and Aâˆ’VÌ„ which implies
Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦|(B)) = Qj,i (A, qâˆ’{j,i} , Î¦|(B)) = 0.

(A.17)

Suppose next that event (A) happens.
We denote the unique path between s and j by s, v1 , v2 , . . . , vk = i, . . . , vm = j. Node j gets infected
in A if and only if for all 1 â‰¤ i â‰¤ m, vi is susceptible. However, in Aâˆ’VÌ„ , j gets infected if and only

34

if for all 1 â‰¤ i â‰¤ m, vi is susceptible and vi 6âˆˆ VÌ„ . Hence,
Pj (A, q, Î¦|(A)) â‰¥ Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(A)).
Furthermore, we have
Pj (A, q, Î¦|(A)) = (1 âˆ’ qj )(1 âˆ’ qi )Qj,i (A, qâˆ’{j,i} , Î¦|(A)),
Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(A)) = (1 âˆ’ qj )(1 âˆ’ qi )Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦|(A)).
Combining the preceding relations with Eq. (A.17), we obtain
Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦) = Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦|(A))P ((A))
1
=
Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(A))P ((A))
(1 âˆ’ qi )(1 âˆ’ qj )
1
Pj (A, q, Î¦|(A))P ((A))
â‰¤
(1 âˆ’ qi )(1 âˆ’ qj )
= Qj,i (A, qâˆ’{j,i} , Î¦|(A))P ((A))
= Qj,i (A, qâˆ’{j,i} , Î¦),
completing the proof of Eq. (A.16). Combining this result with Eq. (4.2) and Proposition 3.3(b), we
obtain
CI (i, A) = (1 âˆ’ qi )(PÌƒi (A, qâˆ’i , Î¦) +

X

(1 âˆ’ qj )Qji (A, qâˆ’{i,j} , Î¦))

jâˆˆVâˆ’i

â‰¥ (1 âˆ’ qi )(PÌƒi (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i} , Î¦) +

X

(1 âˆ’ qj )Qji (A, qâˆ’{i,j} , Î¦))

jâˆˆVâˆ’i

â‰¥ (1 âˆ’ qi )(PÌƒi (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i} , Î¦) +

X

(1 âˆ’ qj )Qji (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i,j} , Î¦))

jâˆˆVâˆ’VÌ„ âˆª{i}

= CI (i, Aâˆ’VÌ„ ),
which shows the desired result.
Proof of Theorem 4.2. If qs > qe then by using Propositions 3.1 and 3.3(a), we have Pi (A, qs , Î¦) <
Pi (A, qe , Î¦) for all i âˆˆ V implying that I(A, qs , Î¦) â‰¤ I(A, qe , Î¦). Otherwise, let V1 = {i âˆˆ V | qis â‰¤
qie }, i.e., V1 is the set of agents that overinvest compared to the social optimum. We first provide
a recursive characterization of expected infections in a given network A, using the decomposition
result presented in Proposition 3.2.
Lemma A.1. Given network A and security profile q, the expected total number of infected people satisfies

35

the following: for all VÌ„ âŠ‚ V and i âˆˆ V âˆ’ VÌ„ ,
I(Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦) = CI (i, Aâˆ’VÌ„ ) + I(Aâˆ’VÌ„ âˆª{i} , qâˆ’VÌ„ âˆª{i} , Î¦),
where CI (i, Aâˆ’VÌ„ ) is the contribution of agent i to infection in network Aâˆ’VÌ„ .
Proof of Lemma A.1. The expected infections in a network Aâˆ’VÌ„ for a security profile qâˆ’VÌ„ , can be
stated as
X

I(Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦) =

Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦).

jâˆˆV âˆ’VÌ„

Using Proposition 3.2, we have

X

I(Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦) =

Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦)

jâˆˆV âˆ’VÌ„

X

= Pi (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦) +

Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦)

jâˆˆV âˆ’VÌ„ âˆª{i}

X

= Pi (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦) +

(1 âˆ’ qj )(PÌƒj (Aâˆ’VÌ„ âˆª{i} , qâˆ’VÌ„ âˆª{i} , Î¦)

jâˆˆV âˆ’VÌ„ âˆª{i}

+ (1 âˆ’ qi )Qji (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i,j} , Î¦))
X
= Pi (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦) +
Pj (Aâˆ’VÌ„ âˆª{i} , qâˆ’VÌ„ âˆª{i} , Î¦)
jâˆˆV âˆ’VÌ„ âˆª{i}

+

X

(1 âˆ’ qi )(1 âˆ’ qj )Qji (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i,j} , Î¦)

jâˆˆV âˆ’VÌ„ âˆª{i}

= CI (i, Aâˆ’VÌ„ ) + I(Aâˆ’VÌ„ âˆª{i} , qâˆ’VÌ„ âˆª{i} , Î¦),
showing the desired result.

We next present the proof of Theorem 4.2 using Lemma A.1. We first show that given tree
network A, for all VÌ‚ âŠ‚ V ,
I(A, q, Î¦) â‰¤ I(Aâˆ’VÌ‚ , qâˆ’VÌ‚ , Î¦) +

X

CI (v, A).

(A.18)

vâˆˆVÌ‚

The proof is by induction on |VÌ‚ |. If |VÌ‚ | = 1, then by applying Lemma A.1 and setting VÌ„ = âˆ…, we
obtain Eq. (A.18).
Suppose next that Eq. (A.18) holds for all VÌ‚ with |VÌ‚ | = m for an integer m > 1. We will show
that it also holds for VÌ‚ with |VÌ‚ | = m + 1. Consider an agent i âˆˆ VÌ‚ and let VÌ‚âˆ’i = VÌ‚ âˆ’ {i}. Since

36

|VÌ‚âˆ’i | = m, using induction hypothesis we have
X

I(A, q, Î¦) â‰¤ I(Aâˆ’VÌ‚âˆ’i , qsâˆ’VÌ‚ , Î¦) +

CI (v, A).

âˆ’i

(A.19)

vâˆˆVÌ‚âˆ’i

Moreover, using Lemma A.1 and setting VÌ„ = VÌ‚âˆ’i , we obtain
I(Aâˆ’VÌ‚âˆ’i , qVÌ‚âˆ’i , Î¦) = CI (i, Aâˆ’VÌ‚âˆ’i ) + I(Aâˆ’VÌ‚ , qâˆ’VÌ‚ , Î¦).

(A.20)

Using Lemma 4.2, we have
CI (i, Aâˆ’VÌ‚âˆ’i ) â‰¤ CI (i, A).

(A.21)

Putting Eqs. (A.19), (A.20), and (A.21) together shows that Eq. (A.18) holds for the VÌ‚ with |VÌ‚ | =
m + 1 completing the proof of Eq. (A.18).
Using Eq. (A.18) with VÌ‚ = V1 and setting q = qs , we obtain
I(A, qs , Î¦) â‰¤ I(Aâˆ’V1 , qsâˆ’V1 , Î¦) +

X

CI (i, A).

iâˆˆV1

Since qs is the socially optimal security profile, by Eq. (3.3) we have
X

CI (i, A) =

iâˆˆV1

X

c0i (qis )(1 âˆ’ qis ).

iâˆˆV1

Combining the preceding relations, we obtain
I(A, qs , Î¦) â‰¤ I(Aâˆ’V1 , qsâˆ’V1 , Î¦) +

X

c0i (qis )(1 âˆ’ qis ).

(A.22)

iâˆˆV1

Moreover, for the equilibrium security profile qe , using Eq. (3.2) and Proposition 3.3(b), we
obtain
I(A, qe , Î¦) =

X

=

c0v (qve )(1 âˆ’ qve ) +

â‰¥

X

Pv (A, qe , Î¦)

vâˆˆV âˆ’V1

vâˆˆV1

X

Pv (A, qe , Î¦)

vâˆˆV âˆ’V1

vâˆˆV1

X

X

Pv (A, qe , Î¦) +

c0v (qve )(1

âˆ’

qve )

+ I(Aâˆ’V1 , qeâˆ’V1 , Î¦).

(A.23)

vâˆˆV1

Using the sufficiently convex cost assumption and the fact that qie > qis for all i âˆˆ V1 , it follows

37

that
X

c0i (qis )(1 âˆ’ qis ) <

iâˆˆV1

X

c0i (qie )(1 âˆ’ qie ).

(A.24)

iâˆˆV1

Moreover, since qie â‰¤ qis for all i âˆˆ V âˆ’ V1 , Proposition 3.3(b) implies
I(Aâˆ’V1 , qsâˆ’V1 , Î¦) â‰¤ I(Aâˆ’V1 , qeâˆ’V1 , Î¦).

(A.25)

Combining Eqs. (A.22), (A.23), (A.24), and (A.25) we obtain
I(A, qs , Î¦) â‰¤ I(Aâˆ’V1 , qsâˆ’V1 , Î¦) +

X

c0i (qis )(1 âˆ’ qis )

iâˆˆV1

â‰¤ I(Aâˆ’V1 , qeâˆ’V1 , Î¦) +

X

c0i (qie )(1 âˆ’ qie )

iâˆˆV1
e

â‰¤ I(A, q , Î¦),
completing the proof of Theorem 4.2.

A.5

Proofs of Section 5

Before providing the proof of Theorem 5.1, we first extend the decomposition property (i.e., Proposition 3.2) and Lemma A.1 for acyclic components of a network. We then use the same line of
argument as Theorem 4.2, to prove Theorem 5.1.
We use the following notation in the rest of this section. Given random network A, for each
agent v, let (DvA ) be the event that the attached connected component to v in Ar âˆ¼ A is acyclic and
(OvA ) be the event that the attached connected component to v in Ar has a cycle. Let P ((DvA )) and
P ((OvA )) be the probability of these events.
Using Proposition 3.2, one can easily show that
Lemma A.2. Given network A and two nodes i and j in A, we have,
PÌƒj (A, qâˆ’j , Î¦|(DjA )) = PÌƒj (Aâˆ’i , qâˆ’{i,j} , Î¦|(DjA )) + (1 âˆ’ qi )Qj,i (A, qâˆ’{i,j} , Î¦|(DjA )),

(A.26)

where Qj,i (A, qâˆ’{i,j} , Î¦|(DjA )) is the probability that infection reaches agent j only through a path that
contains agent i conditional on i being susceptible and event (DjA ) happens.
We next extend Lemma A.1.

38

Lemma A.3. Given network A and security profile q, we have: For all VÌ„ âŠ‚ V and i âˆˆ V âˆ’ VÌ„ ,
X

Pv (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(DvA ))P ((DvA ))

vâˆˆV âˆ’VÌ„

X

= CI (i, Aâˆ’VÌ„ |(DiA ))P ((DiA )) +

Pv (Aâˆ’VÌ„ âˆª{i} , qâˆ’VÌ„ âˆª{i} , Î¦|(DvA ))P ((DvA )),

vâˆˆV âˆ’VÌ„ âˆª{i}

(A.27)
where,
CI (i, Aâˆ’VÌ„ |(DiA ))
X

= (1 âˆ’ qi )(PÌƒi (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i} , Î¦|(DiA )) +

(1 âˆ’ qj )Qji (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{i,j} , Î¦|(DiA ))).

jâˆˆV âˆ’VÌ„ âˆª{i}

Proof. Given network Aâˆ’VÌ„ and security profile qâˆ’VÌ„ , by using Lemma A.2, we have
X

Pv (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(DvA ))P ((DvA ))

vâˆˆV âˆ’VÌ„

=

X

Pj (Aâˆ’(VÌ„ âˆª{i}) , qâˆ’(VÌ„ âˆª{i}) , Î¦|(DjA ))P ((DjA )) + Pi (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(DiA ))P ((DiA ))

jâˆˆV âˆ’(VÌ„ âˆª{i})

X

+ (1 âˆ’ qi )

(1 âˆ’ qj )Qj,i (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i,j}) , Î¦|(DjA ))P ((DjA ))

jâˆˆV âˆ’(VÌ„ âˆª{i})

= (1 âˆ’ qi )PÌƒi (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(DiA ))P ((DiA ))
X
(1 âˆ’ qj )Qj,i (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i,j}) , Î¦|(DjA ))P ((DjA ))
+ (1 âˆ’ qi )
jâˆˆV âˆ’(VÌ„ âˆª{i})

+

X

Pj (Aâˆ’(VÌ„ âˆª{i}) , qâˆ’(VÌ„ âˆª{i}) , Î¦|(DjA ))P ((DjA )).

(A.28)

jâˆˆV âˆ’(VÌ„ âˆª{i})

Using Lemma A.3, we obtain
CI (i, Aâˆ’VÌ„ |(DiA ))
X

=(1 âˆ’ qi )(PÌƒi (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i}) , Î¦|(DiA )) +

(1 âˆ’ qj )Qji (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i,j}) , Î¦|(DiA ))).

jâˆˆV âˆ’(VÌ„ âˆª{i})

We next show that
X

(1 âˆ’ qj )Qji (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i,j}) , Î¦|(DiA ))P ((DiA ))

jâˆˆV âˆ’(VÌ„ âˆª{i})

=

X

(1 âˆ’ qj )Qji (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i,j}) , Î¦|(DjA ))P ((DjA )).

(A.29)

jâˆˆV âˆ’(VÌ„ âˆª{i})
Ar

In the interaction network Ar âˆ¼ A, either i âˆ’
6 âˆ’â†’ j, in which case infection can not reach i through
39

Ar

j, or i âˆ’âˆ’â†’ j, which implies that i and j belong to the same connected component. In this case, the
event (DiA ) happens if and only if the event (DjA ) happens. Hence,
Qji (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i,j}) , Î¦|(DjA ))P ((DjA )) = Qji (Aâˆ’VÌ„ , qâˆ’(VÌ„ âˆª{i,j}) , Î¦|(DiA ))P ((DiA )).

(A.30)

Combining Eqs. (A.28), (A.29), and (A.30) we obtain Eq. (A.27), completing the proof.
Finally, we extend Lemma 4.2 for acyclic components.
Lemma A.4. Given network A and security profile q, CI (i, A|(DiA )) â‰¥ CI (i, Aâˆ’VÌ„ |(DiA )).
Proof of Lemma A.4. We show a stronger statement. We show that for any i, j âˆˆ V âˆ’ VÌ„ ,
Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦|(DiA )) â‰¤ Qj,i (A, qâˆ’{j,i} , Î¦|(DiA )).
Let the random variable s denote the seed node. Conditional on the event (DiA ), one of the
following mutually exclusive event happens:
(A) The only path between s and j includes i.
(B) The path(s) between s and j do not include i.
Let P ((A)) and P ((B)) be the probability of each event conditional on the event (DiA ). Note that
P ((A)) + P ((B)) = 1. Therefore,
Qj,i (A, qâˆ’{j,i} , Î¦|(DiA )) = Qj,i (A, qâˆ’{j,i} , Î¦|(A))P ((A)) + Qj,i (A, qâˆ’{j,i} , Î¦|(B))P ((B)).

(A.31)

If event (B) happens, the probability that infection reaches j through i in both A and Aâˆ’VÌ„ is 0. In
other words,
Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦|(B)) = Qj,i (A, qâˆ’{j,i} , Î¦|(B)) = 0

(A.32)

We next analyze CI () when event (A) happens. Under this event, we have
Pj (A, q, Î¦|(A)) = (1 âˆ’ qj )(1 âˆ’ qi )Qj,i (A, qâˆ’{j,i} , Î¦|(A))
Similarly,
Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(A)) = (1 âˆ’ qj )(1 âˆ’ qi )Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦|(A)).
Conditional on (A), the path between s and j is unique and includes i. We denote this path by
s, v1 , v2 , . . . , vk = i, . . . , vm = j without loss of generality. Under this event, j gets infected in A if
and only if for all 1 â‰¤ i â‰¤ m, vi is susceptible. However, in Aâˆ’VÌ„ , j gets infected if and only if for
all 1 â‰¤ i â‰¤ m, vi is susceptible and vi 6âˆˆ VÌ„ . Hence,
Pj (A, q, Î¦|(A)) â‰¥ Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(A)).
40

(A.33)

Combining Eqs. (A.31), (A.32), and (A.33), we obtain
1
Pj (Aâˆ’VÌ„ , qâˆ’VÌ„ , Î¦|(A))P ((A))
(1 âˆ’ qi )(1 âˆ’ qj )
1
â‰¤
Pj (A, q, Î¦|(A))P ((A))
(1 âˆ’ qi )(1 âˆ’ qj )

Qj,i (Aâˆ’VÌ„ , qâˆ’VÌ„ âˆª{j,i} , Î¦|(DiA )) =

= Qj,i (A, qâˆ’{j,i} , Î¦|(DiA )),
completing the proof.
Using Lemmas A.2, A.3, and A.4, we next present the proof of the main result of this section.
Proof of Theorem 5.1. The proof of this theorem uses the same line of argument as Theorem 4.2. In
this proof, we analyze expected infections in acyclic components and cyclic components separately.
Let qe be the equilibrium security profile and qs be the socially optimal security profile. If qs > qe ,
then I(A, qs , Î¦) â‰¤ I(A, qe , Î¦).
Otherwise, similar to the previous section, partition the nodes into three sets V1 , V2 and V3 such
that:
ï£±
ï£´
ï£´
ï£´
q s â‰¤ qie
ï£´
ï£² i
qie = qis
ï£´
ï£´
ï£´
ï£´
ï£³qis â‰¥ qie

for all i âˆˆ V1 ,
for all i âˆˆ V2 ,
for all i âˆˆ V3 .

The proof follows a number of steps:
â€¢ We first show that in the equilibrium, expected infections satisfies 15
I(A, qe , Î¦) â‰¥

X

c0 (qie )(1 âˆ’ qie ) +

X

Pi (Aâˆ’V1 , qeâˆ’V1 , Î¦).

iâˆˆV âˆ’V1

iâˆˆV1

â€¢ We then show that in the social optimum, the expected infections is at most
I(A, qs , Î¦) â‰¤

X

c0 (qis )(1 âˆ’ qis ) +

X

Pi (Aâˆ’V1 , qsâˆ’V1 , Î¦) + n.

(A.34)

iâˆˆV âˆ’V1

iâˆˆV1

â€¢ Putting these two steps together, we then conclude that I(A, qs , Î¦) â‰¤ I(A, qe , Î¦) + n.
We first analyze expected infections in the equilibrium. Using a similar argument as Theo15

The attack decision in Pi (Aâˆ’V1 , qeâˆ’V1 , Î¦) is Î¦âˆ’V1 where Î¦ is the attack decision of A.

41

rem 4.2, we have
I(A, qe , Î¦) =

X

Pi (A, qe , Î¦)

iâˆˆV

X

â‰¥

c0 (qie )(1 âˆ’ qie ) +

X

Pi (Aâˆ’V1 , qeâˆ’V1 , Î¦).

(A.35)

iâˆˆV âˆ’V1

vâˆˆV1

We next present an upper bound for expected infections in the social optimum. By law of total
probability, we obtain
I(A, qs , Î¦) =

X

Pi (A, qs , Î¦|(DiA ))P ((DiA )) + Pi (A, qs , Î¦|(OiA ))P ((OiA )).

(A.36)

iâˆˆV

We prove Eq. (A.34) in two steps:
1. We first show that in a (1 âˆ’ )-local tree network A, we have
X

Pv (A, q, Î¦|(OvA ))P ((OvA )) â‰¤ n.

vâˆˆV

2. We then show that, given random network A, if qs is the socially optimal security profile,
then the following inequality holds:
X

Pv (A, qs , Î¦|(DvA ))P ((DvA )) â‰¤

vâˆˆV

X

c0 (qis )(1 âˆ’ qis ) +

X

Pi (Aâˆ’V1 , qsâˆ’V1 , Î¦|(DvA ))P ((DvA )).

iâˆˆV âˆ’V1

iâˆˆV1

We start by proving the first step and providing an upperbound for expected infections in cyclic
components. For each agent v, by definition of local tree, the probability that v belongs to a cyclic
component is at most . Therefore, the probability that v belongs to a cyclic component and gets
infected is also at most . Summing over all agents v, we have
X

Pv (A, q, Î¦|(OvA ))P ((OvA )) â‰¤ nP ((OvA )) = n.

(A.37)

vâˆˆV

We next analyze expected infections in acyclic components in the social optimum. We show that
for any security profile q and for any VÌ‚ âŠ‚ V ,
X

Pv (A, q, Î¦|(DvA ))P ((DvA ))

vâˆˆV

â‰¤

X

Pv (Aâˆ’VÌ‚ , qâˆ’VÌ‚ , Î¦|(DvA ))P ((DvA )) +

vâˆˆV âˆ’VÌ‚

X

CI (v, A|(DvA ))P ((DvA )). (A.38)

vâˆˆVÌ‚

The proof of Eq. (A.38) follows the same line of the argument used for Eq. (A.18) in Lemma A.1.
The proof is by induction on |VÌ‚ |. If |VÌ‚ | = 1, then by setting VÌ„ = âˆ… and applying Lemma A.3, we
obtain Eq. (A.38). We next assume that for any VÌ‚ , if |VÌ‚ | â‰¤ m, then Eq. (A.38) holds (Induction
42

hypothesis). We then prove that if |VÌ‚ | = m + 1, the statement holds still. Consider an agent i âˆˆ VÌ‚
and define VÌ‚âˆ’i = VÌ‚ âˆ’ {i}. With a similar argument presented for Eq. (A.18) in Lemma A.1, we
obtain
X

Pv (A, q, Î¦|(DvA ))P ((DvA ))

vâˆˆV

â‰¤

X
vâˆˆV

=

X

X

Pv (Aâˆ’VÌ‚âˆ’i , qâˆ’VÌ‚âˆ’i , Î¦|(DvA ))P ((DvA )) +

CI (v 0 , A|(DvA0 ))P ((DvA0 ))

v 0 âˆˆVÌ‚âˆ’i

Pv (Aâˆ’VÌ‚ , qâˆ’VÌ‚ , Î¦|(DvA ))P ((DvA )) + CI (i, Aâˆ’VÌ‚ |(DiA ))P ((DiA ))

vâˆˆV

+

X

CI (v 0 , A|(DvA0 ))P ((DvA0 ))

v 0 âˆˆVÌ‚âˆ’i

â‰¤

X

X

Pv (Aâˆ’VÌ‚ , qâˆ’VÌ‚ , Î¦|(DvA ))P ((DvA )) +

vâˆˆV

CI (v, A|(DvA ))P ((DvA )).

vâˆˆVÌ‚

The first inequality follows from the induction hypothesis. The first equation is implied by Lemma A.2
and the second inequality follows from Lemma A.4. Furthermore, using Lemmas 4.1, A.4, Eq. (3.3),
and assuming that c(q) is sufficiently convex, for the socially optimal security profile we have
CI (v, A|(DvA ))P ((DvA )) â‰¤ CI (v, A) = c0 (qvs )(1 âˆ’ qvs ).

(A.39)

Combining Eqs. (A.35), (A.38), and (A.39), we obtain
X

Pv (A, qs , Î¦|(DvA ))P ((DvA ))

(A.40)

vâˆˆV

â‰¤

X

Pv (Aâˆ’V1 , qsâˆ’V1 , Î¦|(DvA ))P ((DvA )) +

vâˆˆV âˆ’V1

â‰¤

X

â‰¤

CI (v, A|(DvA ))P ((DvA ))

vâˆˆV1

Pv (Aâˆ’V1 , qsâˆ’V1 , Î¦|(DvA ))P ((DvA ))

vâˆˆV âˆ’V1

X

X

+

X

c0 (qvs )(1 âˆ’ qvs )

vâˆˆV1

Pv (Aâˆ’V1 , qeâˆ’V1 , Î¦)

+

vâˆˆV âˆ’V1

X

0

c

(qve )(1

âˆ’ qve )

vâˆˆV1

â‰¤ I(A, qe , Î¦).

(A.41)

The third inequality holds because
1. For all v âˆˆ V1 , qvs < qve . Hence, by Lemma 4.1 we have
c0 (qvs )(1 âˆ’ qvs ) < c0 (qve )(1 âˆ’ qve ).
2. For all v âˆˆ V âˆ’ V1 , qvs â‰¥ qve . Hence, by Proposition 3.3(a), for all v âˆˆ V âˆ’ V1 ,
Pv (Aâˆ’V1 , qsâˆ’V1 , Î¦|(DvA ))P ((DvA )) â‰¤ Pv (Aâˆ’V1 , qsâˆ’V1 , Î¦) â‰¤ Pv (Aâˆ’V1 , qeâˆ’V1 , Î¦).
43

By combining the preceding steps we obtain the third inequality. The last inequality was proven
in Eq. (A.35).
Finally combining Eqs. (A.36), (A.37), and (A.40), we obtain
I(A, qs , Î¦) â‰¤ I(A, qe , Î¦) + n,
completing the proof.

A.6

Proofs of Subsection 5.2

In the rest of this section, we denote the component attached to v in the activated network Aa by
Aa

Aav , i.e., Aav = Aa [VÌ„ ] such that VÌ„ = {j âˆˆ V |j âˆ’âˆ’â†’ v}. By Definition 2, the random network generated from (A, p) has h-local tree structure if the attached component to each agent is acyclic with
(A,p)

probability at least h. Let (Dv

) be the event that the component attached to v in the activated
(A,p)

network from (A, p) is acyclic. Hence, a lower bound on P ((Dv

)) is also a lower bound on the

h parameter of the local tree structure. Given interaction network Ar âˆ¼ A and an agent v âˆˆ V , we
(A,p)

obtain a lower bound on P ((Dv

)) via the following steps:

1. We first introduce an algorithm that specifies the activation order of the edges in multiple
stages to obtain the activated network Aav .
2. We then present a recursive computation of the lower bound of having an acyclic component
attached to v after the kth stage of the algorithm.
(A,p)

3. We finally bound the maximum number of stages of the algorithm and consequently P ((Dv
for a class of random networks (A, p).

In order to generate Aav , one can first focus on Ar , and starting from a particular node v, activate
edges independently with probability p. For the sake of analysis, we use the following order on
activating the edges.

Algorithm A.1 (Activation(Ar , p, v)).
â€¢ Initialize C1v = {v}. Initialize k = 1.
â€¢ Initialize CÌ„ v = âˆ…. E1a = âˆ….
â€¢ While V âˆ’ Ckv âˆ’ CÌ„ v 6= âˆ… do
â€“ For an agent vk0v âˆ’ CÌ„ v , activate the edges between v 0 and Ckv in Ar . Denote the set of active edges
by Ev0 .

44

))

v
âˆ— If at least one of these edges between v 0 and Ckv are active, then, Ck+1
= Ckv âˆª{v 0 }, k = k+1,
a
CÌ„ v = âˆ…, Eka = Ekâˆ’1
âˆª Ev0 .

âˆ— Otherwise, CÌ„ v = CÌ„ v âˆª {v 0 }.

This algorithm (starting from v) considers one node at a time and activates all edges between
that node and all â€œactivated nodesâ€ (i.e., endpoints of all activated edges). The set Ckv contains
activated nodes and the set Eka contains the set of activated edges at the end of stage k.16 The set
CÌ„ v is used at each stage k, to discover nodes which are one hop away from the set Ckv .
(Ar ,k)

v
a
Let Ar,k
v = (Ck , Ek ) and let (Dv

) denote the event that Ar,k
v is acyclic. Also, let kÌ‚ be the

number of stages of Algorithm Activation(Ar , p, v).
Lemma A.5. Given interaction network Ar and activation probability p, the following holds. For all 2 â‰¤
k â‰¤ kÌ‚,
P ((Dv(A

r ,k)

r,k

)) = (1 âˆ’ p)|E[Av

]|âˆ’k+1

â‰¥ (1 âˆ’ p)

(kâˆ’1)(kâˆ’2)
2

(A.42)

.
(Ar ,1)

Proof. We first show the equality. The proof is by induction. In stages 1 and 2, P ((Dv

)) = 1

and hence the induction basis holds. We then assume that for all k < m â‰¤ kÌ‚, Eq. (A.42) holds. We
next show that this equation holds for k = m. Let v 0 be the agent that is added to C v at stage m.
The attached component to v is acyclic at the end of stage m if the following holds:
(Ar ,mâˆ’1)

â€¢ The component attached to v is acyclic at the end of stage m âˆ’ 1, i.e., event (Dv

)

happens, and
v âˆ’ Cv
â€¢ For v 0 = Cm
mâˆ’1 , we have |Ev 0 | = 1.
(Ar ,mâˆ’1)

By induction hypothesis, we have P ((Dv

the second event happens with probability (1 âˆ’ p)
the fact that the number of edges between

v0

r,mâˆ’1

)) = (1 âˆ’ p)|E[Av

and

]|âˆ’(mâˆ’1)+1 .

r,mâˆ’1
|E[Ar,m
]|âˆ’1
v ]|âˆ’|E[Av

v
Cmâˆ’1

We next show that

. This equation follows from

r,mâˆ’1
is exactly equal to |E[Ar,m
]|.
v ]| âˆ’ |E[Av

Conditional on one of the edges being active, the probability of all the other edges being inacr,m

tive is equal to (1 âˆ’ p)|E[Av

]|âˆ’|E[Ar,mâˆ’1
]|âˆ’1 .
v

Combining the preceding relation with the induction

hypothesis, we obtain
P ((Dv(A

r ,m)

)) = P ((Dv(A

r ,mâˆ’1)

r,mâˆ’1

= (1 âˆ’ p)|E[Av

r,m

= (1 âˆ’ p)|E[Av

r,m

))(1 âˆ’ p)|E[Av
]|âˆ’(mâˆ’1)+1

]|âˆ’m+1

]|âˆ’|E[Ar,mâˆ’1
]|âˆ’1
v
r,m

(1 âˆ’ p)|E[Av

]|âˆ’|E[Ar,mâˆ’1
]|âˆ’1
v

,

completing the proof of the equality. The inequality in Eq. (A.42) is implied by the fact that in stage
v | = m. Hence, the induced subgraph over C v has at most
m, |Cm
m
16

m(mâˆ’1)
2

At each stage k, one node is added to Ckv implying that the algorithm will terminate.

45

edges. In other words,

|E[Ar,m
v ]| â‰¤

m(mâˆ’1)
.
2

Combining the preceding relation with the fact that 1 âˆ’ p â‰¤ 1, we obtain
r,m

(1 âˆ’ p)|E[Av

]|âˆ’m+1

â‰¥ (1 âˆ’ p)

m(mâˆ’1)
2

,

completing the proof.
Using the previous result, it follows that
P ((Dv(A,p) )) â‰¥ (1 âˆ’ p)

(kÌ‚âˆ’1)(kÌ‚âˆ’2)
2

.
(A,p)

Hence, by obtaining an upperbound on kÌ‚, we can get a lower bound on P ((Dv

)). We obtain the

upperbound on kÌ‚ using Theorem A.1 given in subsection A.1. Combining these two results, we
(A,p)

provide conditions on (A, p) under which, P ((Dv

)) â‰¥ 1 âˆ’ (n) with limnâ†’âˆž (n) â†’ 0.

Let Î»(G) represent the second largest eigenvalue in absolute value of the adjacency matrix of
the degenerate network G. For a given d < n, let Gd denote the set of dâˆ’ regular graphs G with
Î»(G) = o(d). Consider a random network A generated from (â„¦, F, P), where â„¦ = {G = (V, E)|E âŠ‚
EÌ‚, (V, EÌ‚) âˆˆ Gd }.
Combining Lemma A.5 and Theorem A.1, we present the proof of the main theorem of this
section.
âˆš
Proof of Theorem 5.2. We first show that if d âˆˆ â„¦( n) and p < d1 , the generated random network
from (A, p) is a 1 âˆ’ (n)-local tree network with limnâ†’âˆž (n) = 0. We show that:
â€¢ If p <

1
d,

by Theorem A.1 for all v âˆˆ V , C v is of size at most O(log(n)), with probability

1 âˆ’ 1 (n), where limnâ†’âˆž 1 (n) = 0.
â€¢ If C v is of size O(log(n)), by Lemma A.5, the attached component to v in the transmission
network is acyclic with probability at least 1 âˆ’ (n) where limnâ†’âˆž (n) = 0.
âˆš
Combining the above steps implies the desired result. Theorem A.1 implies that if d âˆˆ â„¦( n) and
p <

1
d,

the maximum component size of the transmission network is O(log(n)) with probability

1 âˆ’ 1 (n). In other words, with probability 1 âˆ’ 1 (n) for all v âˆˆ V , C v is of size O(log(n)). Let (A)
be the event that the maximum component size of the transmission network is O(log(n)).
Moreover, by using Lemma A.5 we have
P ((Dv(A,p) )) â‰¥

X

(1 âˆ’ p)

a
(|V [Aa
v ]|âˆ’1)(|V [Av ]|âˆ’2)
2

P(A,p) (Aa )

Aa âˆ¼(A,p)

â‰¥

X

(1 âˆ’ p)

{Aa âˆ¼(A,p)| |V [Aa
v ]|=O(log(n))}

46

a
(|V [Aa
v ]|âˆ’1)(|V [Av ]|âˆ’2)
2

P(A,p) (Aa ).

(A.43)

âˆš
Assuming d = â„¦( n), p <

1
d

and |V [Aav ]| = O(log(n)), we obtain
(1 âˆ’ p)

a
(|V [Aa
v ]|âˆ’1)(|V [Av ]|âˆ’2)
2

â‰¥ 1 âˆ’ (n),

(A.44)

where limnâ†’âˆž (n) = 0. Combining Eqs. (A.43) and (A.44), we have
lim P ((Dv(A(n),p) ))

nâ†’âˆž

X

â‰¥ lim

nâ†’âˆž

(1 âˆ’ p)

a
(|V [Aa
v (n)]|âˆ’1)(|V [Av (n)]|âˆ’2)
2

P(A(n),p) (Aa (n))

{Aa (n)âˆ¼(A(n),p)| |V [Aa
v (n)]|=O(log(n))}

â‰¥ lim (1 âˆ’ 1 (n))(1 âˆ’ (n)) = 1,
nâ†’âˆž

completing the proof of the first part of the theorem. Using a similar argument, we can show that
if p <

1
,
n log2 (n)

the generated random network from (A, p) is a 1 âˆ’ (n)-local tree network with

limnâ†’âˆž (n)n = 0.

A.7

Proofs of Section 6

Proof of Theorem 6.1. As we have shown in Theorem 3.2, for any symmetric network A there exists a unique symmetric equilibrium. We show that under Assumption 2, for any symmetric random network, this is in fact the only equilibrium security profile.
Assume the contrary. This implies that the symmetric random network A has an asymmetric
equilibrium security profile. Let q e be the security level in the symmetric equilibrium, qen denote
the symmetric equilibrium security profile and qÌ‚e be an asymmetric equilibrium security profile.
We then show that there exist two agents i, j âˆˆ V such that qÌ‚ie > q e and qÌ‚je < q e .
Assume to arrive at a contradiction that for all i âˆˆ V , qÌ‚ie â‰¥ q e . Using Proposition 3.3(a), this implies that for all i âˆˆ V , Pi (A, qÌ‚e , Î¦) â‰¤ Pi (A, qen , Î¦). Moreover, since qÌ‚e 6= qe , this implies that qÌ‚ie >
q e for some agent i. Under Assumption 2, by Lemma 4.1, we obtain Pi (A, qÌ‚e , Î¦) > Pi (A, qen , Î¦),
yielding a contradiction. Similarly, one can extend the argument and reach a contradiction if for
all i âˆˆ V , qÌ‚ie â‰¤ q e . Hence, there exist two agents i, j âˆˆ V such that qÌ‚ie > q e and qÌ‚je < q e .
We next show that
Pi (A, qÌ‚e , Î¦) â‰¤ Pj (A, qÌ‚e , Î¦),

(A.45)

using Proposition 3.2 and symmetry. Consider two agents i, j âˆˆ V such that qÌ‚ie > q e and qÌ‚je < q e .
By Proposition 3.2
Pi (A, qÌ‚e , Î¦) = (1 âˆ’ qÌ‚ie )PÌƒi (Aâˆ’i , qÌ‚e{âˆ’i,âˆ’j} , Î¦) + (1 âˆ’ qÌ‚ie )(1 âˆ’ qÌ‚je )Qi,j (A, qÌ‚eâˆ’{i,j} , Î¦),
Pj (A, qÌ‚e , Î¦) = (1 âˆ’ qÌ‚je )PÌƒj (Aâˆ’i , qÌ‚e{âˆ’i,âˆ’j} , Î¦) + (1 âˆ’ qÌ‚je )(1 âˆ’ qÌ‚ie )Qj,i (A, qÌ‚eâˆ’{i,j} , Î¦).

47

(A.46)

Also since A is symmetric, it follows that
PÌƒi (Aâˆ’j , qÌ‚e{âˆ’i,âˆ’j} , Î¦) = PÌƒj (Aâˆ’i , qÌ‚e{âˆ’i,âˆ’j} , Î¦),
Qi,j (A, qÌ‚eâˆ’{i,j} , Î¦) = Qj,i (A, qÌ‚eâˆ’{i,j} , Î¦).

(A.47)

Combining Eqs. (A.46), (A.47) and the fact that qÌ‚ie > q e > qÌ‚je , we obtain Eq. (A.45).
Finally, assuming qÌ‚e and qen are both equilibrium security profiles, qÌ‚ie > qÌ‚je and assuming c(q)
is sufficiently convex, using Eq. (3.2) we obtain
Pi (A, qÌ‚e , Î¦) = c0 (qÌ‚ie )(1 âˆ’ qÌ‚ie ) > c0 (qÌ‚je )(1 âˆ’ qÌ‚je ) = Pj (A, qÌ‚e , Î¦),
which contradicts Eq. (A.45) and shows the uniqueness of the equilibrium. With a similar line of
argument, one can show that under Assumption 2 for any symmetric random network, the socially
optimal security profile is unique and symmetric.

A.8

Proofs of Subsection 6.2

Proof of Theorem 6.2. The proof follows the proof of Theorem 3.2 and Theorem 4.1 closely. We
prove the following steps:
1. We show that in any equilibrium security profile, all agents residing on the same island select
the same security level.
2. Given that the individuals on the same island use the same security level in the equilibrium,
we show that the equilibrium security profile for the whole network is unique.
The proof of step(1) is the same as the proof of Theorem 3.2 despite the fact that the whole network
is not a symmetric random network. However, given that the individuals residing on the same
island are connected symmetrically to other islands, in expectation the location of the individuals
on the same island are symmetric with respect to each other. We next show the proof of step(2).
Given that all agents residing on the same island play symmetrically in the equilibrium security
profile, without loss of generality the equilibrium security profile for all agents on the same island
can be expressed via a scalar. In the rest of the proof, the equilibrium security profile qe denote the
equilibrium security profile of the islands and qie denote the equilibrium security level of island i.
We next show that the equilibrium security profile qe is unique. Assume to arrive at a contradiction
that we have two different equilibrium security profiles qe and qÌ‚e . Similar to Theorem 4.1 we
partition the islands into three sets H1 , H2 and H3 as follows:
qie > qÌ‚ie for all Hi âˆˆ H1 ,
qie = qÌ‚ie for all Hi âˆˆ H2 ,
qie < qÌ‚ie for all Hi âˆˆ H3 .
48

Following the same line of argument as Theorem 4.1, we show that for any tree order of the
bridges without loss of generality, we can assume that there exists a bridge (Hx , Hy ) âˆˆ T such that
Hx âˆˆ H1 , Hy âˆˆ H3 , and for all Hv âˆˆ Y where Y = {Hv âˆˆ H | Hv > Hy }, we have Hv âˆˆ H3 .
We will abuse the notation and denote the infection probability of an agent residing on island
Hi , by PHi (). We next show that we can decompose the infection probability reaching to the
agents of island Hx and island Hy using the network effect on Hx when island Hy is removed from
the network and the network effect on Hy when island Hx is removed from the network. More
specifically, let PÌ‚x and PÌ‚y denote infection probabilities reaching to the agents of island Hx and Hy
when island Hy and Hx are removed from the network respectively, i.e.,
PÌ‚x (q) = PÌƒHx (Aâˆ’Hy , qâˆ’y , Î¦)(1 âˆ’ qx ),
PÌ‚y (q) = PÌƒHy (Aâˆ’Hx , qâˆ’x , Î¦)(1 âˆ’ qy ).
and let PÌ„x (and PÌ„y ) denote infection probability that reaches to the agents in island Hx if the underlying network is Hx and the seed node is on island Hx , i.e., for all i âˆˆ Hx and for all j âˆˆ Hy ,
PÌ„x (q) = Pi (Hx , qx , 1Ì‚),
PÌ„y (q) = Pj (Hy , qy , 1Ì‚).

Using PÌ‚x , PÌ‚y , PÌ„x , and PÌ„y we can write down infection probabilities of agents x and y as follows:
Px (A, qe , Î¦) = PË†x (qe ) + PÌ„x (qxe )PË†y (qe ),

(A.48)

Py (A, qe , Î¦) = PË†y (qe ) + PÌ„y (qye )PË†x (qe ).

(A.49)

The rest of the proof follows the same line of argument as Theorem 4.1.
Define CIH (Hi , A) as the contribution of island Hi to infection in network A, i.e.,
CIH (Hi , A) = I(A, q, Î¦) âˆ’ I(Aâˆ’Hi , q, Î¦).

(A.50)

We show that for any islands connection network, the contribution of islands to infection in a
subgraph is upper bounded by their contribution to infection in the original network.
Lemma A.6. Given an islands connection network A = (V, H, T ), for any HÌ„ âŠ‚ H and Hi 6âˆˆ HÌ„,
CIH (Hi , Aâˆ’HÌ„ ) â‰¤ CIH (Hi , A).

49

Proof of Lemma A.6. Expanding Eq. (A.50), we have
CIH (Hi , A) = I(A, q, Î¦) âˆ’ I(Aâˆ’Hi , q, Î¦)
= |V (Hi )|PHi (A, q, Î¦) +

X

|V (Hj )|(PHj (A, q, Î¦) âˆ’ PHj (Aâˆ’Hi , q, Î¦)).

Hj âˆˆHâˆ’{Hi }

Similarly, we can define CIH (Hi , Aâˆ’HÌ„ ). We next show the following:
(a) For any island Hi âˆˆ H âˆ’ HÌ„, PHi (A, q, Î¦) â‰¥ PHi (Aâˆ’HÌ„ , q, Î¦).
(b) For any island Hj âˆˆ H âˆ’ HÌ„ âˆ’ Hi , PHj (A, q, Î¦) âˆ’ PHj (Aâˆ’Hi , q, Î¦) â‰¥ PHj (Aâˆ’HÌ„ , q, Î¦) âˆ’
PHj (Aâˆ’({Hi }âˆªHÌ„) , q, Î¦).
Combining steps (a) and (b) implies that CIH (Hi , Aâˆ’HÌ„ ) â‰¤ CIH (Hi , A), proving Lemma A.6.
Since Aâˆ’HÌ„ âŠ‚ A, by Proposition 3.3(c) it follows that for any Hi âˆˆ H âˆ’ HÌ„, PHi (A, q, Î¦) â‰¥
PHi (Aâˆ’HÌ„ , q, Î¦), establishing step (a). We next present the proof of step (b).
Let the random variable Hs denote the island that the seed node resides on. In the islands
connection network, one of the following mutually exclusive events happens:
(A) The unique path over bridges between island Hs and Hj in the tree T includes Hi .
(B) The unique path of bridges between Hs and Hj in the tree T does not include Hi .
If event (B) happens, the probability that infection reaches Hj stays unchanged after Hi is
removed from the network in both A and Aâˆ’HÌ„ , which implies
PHj (A, q, Î¦|(B)) âˆ’ PHj (Aâˆ’Hi , q, Î¦|(B)) = PHj (Aâˆ’HÌ„ , q, Î¦|(B)) âˆ’ PHj (Aâˆ’({Hi }âˆªHÌ„) , q, Î¦|(B)) = 0.
(A.51)
Suppose next that event (A) happens. The unique path between Hs and Hj then includes Hi and
can be represented as Hs , H1 , . . . , Hk = Hi , . . . , Hm = Hj . An agent in island Hj gets infected in A
if and only if for all 1 â‰¤ r â‰¤ m, the agents corresponding to the endpoints of the bridges between
(Hr , Hr+1 ) are being infected. However, in Aâˆ’HÌ„ , Hj gets infected if and only if for all 1 â‰¤ r â‰¤ m,
the agents corresponding to the endpoints of the bridge between (Hr , Hr+1 ) are being infected and
Hr 6âˆˆ HÌ„. Hence,
PHj (A, q, Î¦|(A)) âˆ’ PHj (Aâˆ’Hi , q, Î¦|(A)) â‰¥ PHj (Aâˆ’HÌ„ , q, Î¦|(A)) âˆ’ PHj (Aâˆ’({Hi }âˆªHÌ„) , q, Î¦|(A)).

50

Combining the preceding relations with Eq. (A.51), we obtain
PHj (A, q, Î¦) âˆ’ PHj (Aâˆ’Hi , q, Î¦)
= (PHj (A, q, Î¦|(A)) âˆ’ PHj (Aâˆ’Hi , q, Î¦|(A)))P ((A))
+ (PHj (A, q, Î¦|(B)) âˆ’ PHj (Aâˆ’Hi , q, Î¦|(B))P ((B))
â‰¥ (PHj (Aâˆ’HÌ„ , q, Î¦|(A)) âˆ’ PHj (Aâˆ’(HÌ„âˆª{Hi }) , q, Î¦|(A)))P ((A))
+ (PHj (Aâˆ’HÌ„ , q, Î¦|(B)) âˆ’ PHj (Aâˆ’(HÌ„âˆª{Hi }) , q, Î¦|(B)))P ((B))
= PHj (Aâˆ’HÌ„ , q, Î¦) âˆ’ PHj (Aâˆ’({Hi }âˆªHÌ„) , q, Î¦),
completing the proof of step (b). The result then follows from the definition of CIH .
Proof of Theorem 6.3. By Theorem 6.2, in the equilibrium and the social optimum, all agents on the
same island play symmetrically. Hence without loss of generality, we can denote the equilibrium
and the socially optimal security profiles of all agents residing on an island via a scalar. Similar to
Theorem 6.2, let qe and qs denote the equilibrium and the socially optimal security profiles of the
islands. If qs > qe then by Propositions 3.3(a) and 3.1, we have Pv (A, qs , Î¦) < Pv (A, qe , Î¦) for all
v âˆˆ V implying that I(A, qs , Î¦) â‰¤ I(A, qe , Î¦). Otherwise, let H1 = {Hi âˆˆ H | qis â‰¤ qie }, i.e., H1
is the set of islands that overinvest compared to the social optimum. The rest of the proof follows
from the following steps:
1. We first present an upper bound for expected infections of the social optimum. We show
P
that, I(A, qs , Î¦) â‰¤ I(Aâˆ’H1 , qsâˆ’H1 , Î¦) + Hi âˆˆH1 |V (Hi )|c0i (qis )(1 âˆ’ qis ). To obtain this result, we
show that
â€¢ For any HÌ‚ âŠ‚ H, I(A, q, Î¦) â‰¤ I(Aâˆ’HÌ‚ , qâˆ’HÌ‚ , Î¦) +

H
Hi âˆˆHÌ‚ CI (Hi , A).

P

â€¢ Furthermore, CIH (Hi , A) â‰¤ |Hi |c0 (qis )(1 âˆ’ qis ).
Combining the preceding relations, implies the desired inequality.
2. We then compare this upper bound with the expected infections in the equilibrium that was
expressed in Eq. (A.23), i.e.,
I(A, qe , Î¦) â‰¥

X

|Hi |c0 (qie )(1 âˆ’ qie ) + I(Aâˆ’H1 , qeâˆ’H1 , Î¦).

Hi âˆˆH1

We start by proving step (1). We show that for any HÌ‚ âŠ‚ H,
I(A, q, Î¦) â‰¤ I(Aâˆ’HÌ‚ , qâˆ’HÌ‚ , Î¦) +

X

CIH (Hi , A).

(A.52)

Hi âˆˆHÌ‚

The proof is by induction on |HÌ‚|. If |HÌ‚| = 0, then CIH (HÌ‚, A) = 0. Hence, Eq. (A.52) trivially holds
(the induction basis). We next assume that if |HÌ‚| = m, then Eq. (A.52) holds (induction hypothesis)
51

and we then prove that it would hold if |HÌ‚| = m + 1 as well. Consider an island Hi âˆˆ HÌ‚ and let
HÌ‚âˆ’i = HÌ‚ âˆ’ {Hi }. Since |HÌ‚âˆ’i | = m, by induction hypothesis we have
I(A, q, Î¦) â‰¤ I(Aâˆ’HÌ‚âˆ’i , qsâˆ’HÌ‚ , Î¦) +

X

âˆ’i

CIH (Hj , A).

(A.53)

Hj âˆˆHÌ‚âˆ’i

Furthermore, by Eq. (A.50) we have
I(Aâˆ’HÌ‚âˆ’i , qsâˆ’HÌ‚ , Î¦) = I(Aâˆ’HÌ‚ , qsâˆ’HÌ‚ , Î¦) + CIH (Hi , Aâˆ’HÌ‚âˆ’i ) â‰¤ I(Aâˆ’HÌ‚ , qsâˆ’HÌ‚ , Î¦) + CIH (Hi , A), (A.54)
âˆ’i

where the inequality follows from Lemma A.6. Combining Eqs. (A.53) and A.54, we obtain
I(A, q, Î¦) â‰¤ I(Aâˆ’HÌ‚âˆ’i , qsâˆ’HÌ‚ , Î¦) +

X

CIH (Hj , A) â‰¤ I(Aâˆ’HÌ‚ , qsâˆ’HÌ‚ , Î¦) +

âˆ’i

X

CIH (Hj , A),

Hj âˆˆHÌ‚

Hj âˆˆHÌ‚âˆ’i

completing the proof of Eq. (A.52).
We next show that in an islands connection network, when agents select the socially optimal security profile, we have
CIH (Hi , A) â‰¤ |V (Hi )|c0 (qis )(1 âˆ’ qis ).

(A.55)

Using Eq. (A.50), CIH (Hi , A) can be written as follows:
CIH (Hi , A) = I(A, qs , Î¦) âˆ’ I(Aâˆ’Hi , qs , Î¦)
X
= |V (Hi )|PHi (A, qs , Î¦) +

Pd (A, qs , Î¦) âˆ’ Pd (Aâˆ’Hi , qs , Î¦).

(A.56)

dâˆˆV âˆ’V (Hi )

We next show that in an islands connection network A = (V, H, T ), given an island Hi âˆˆ H,
and two agent v, d âˆˆ V such that v âˆˆ V (Hi ) and d âˆˆ V (Hj ), we have
(1 âˆ’ qi )Qd,v (A, qs , Î¦) â‰¥

1
(PÌƒd (A, qs , Î¦) âˆ’ PÌƒd (Aâˆ’Hi , qs , Î¦)).
|V (Hi )|

(A.57)

Let Hs denote the island that the seed node resides on. Since A is an island connection network
one of the following mutually exclusive events happens:
(A) The unique path of bridges between Hs and Hj in T includes Hi .
(B) The unique path of bridges between Hs and Hj in T does not include Hi .
If event (B) happens, then the probability of infection reaching to d stays unchanged after Hi is
removed which implies
(1 âˆ’ qis )Qd,v (A, qs , Î¦|(B)) = PÌƒd (A, qs , Î¦|(B)) âˆ’ PÌƒd (Aâˆ’Hi , qs , Î¦|(B)) = 0.
52

Suppose next that event (A) happens. In this scenario, PÌƒd (Aâˆ’Hi , qs , Î¦)|(A)) = 0. Let S, H1 , . . . , Hk =
Hi , . . . , Ht = Hj denote the unique path over the bridges in T , between islands Hs and Hj . Let
(Am ) denote the event in which agent m is the randomly selected agent from Hi that is connected
to Hk+1 . By law of total probability and assuming that the security profiles as well as the islands
are symmetric, we have: For any m âˆˆ V (Hi ),
X

PÌƒd (A, qs , Î¦|(A)) =

PÌƒd (A, qs , Î¦|(Am ))P ((Am )) = PÌƒd (A, qs , Î¦|(Am )).

(A.58)

mâˆˆV (Hi )

Also if event (Am ) happens, the only way to reach from Hs to Hj is through agent m. That implies
(1 âˆ’ qis )Qd,v (A, qs , Î¦|(A)) â‰¥ PÌƒd (A, qs , Î¦|(Am ))P ((Am )) =

1
PÌƒd (A, qs , Î¦|(Am )).
|V (Hi )|

(A.59)

Combining Eqs. (A.59) and (A.58), we obtain
(1 âˆ’ qis )Qd,v (A, qs , Î¦) = (1 âˆ’ qi )Qd,v (A, qs , Î¦|(A))P ((A)) + (1 âˆ’ qi )Qd,v (A, qs , Î¦|(B))P ((B))
= (1 âˆ’ qis )Qd,v (A, qs , Î¦|(A))P ((A))
1
â‰¥
PÌƒd (A, qs , Î¦|(Am ))P ((A))
|V (Hi )|
1
(PÌƒd (A, qs , Î¦) âˆ’ PÌƒd (Aâˆ’Hi , qs , Î¦)).
=
|V (Hi )|
Combining the preceding relation with Eqs. (A.50) and (3.3), in the socially optimal solution for
each agent m âˆˆ V (Hi ), the following relations hold:
|V (Hi )|c0 (qis )(1 âˆ’ qis ) = |V (Hi )|Pi (A, qs , Î¦) + |V (Hi )|

X

(1 âˆ’ qis )(1 âˆ’ qds )Qd,v (A, qs , Î¦)

dâˆˆV

X

s

â‰¥ |V (Hi )|Pi (A, q , Î¦) +

(Pd (A, qs , Î¦) âˆ’ Pd (Aâˆ’Hi , qs , Î¦))

dâˆˆV âˆ’V (Hi )

=

CIH (Hi , A),

completing the proof of Eq. (A.55). Combining Eqs. (A.54) and (A.55), we obtain
I(A, qs , Î¦) â‰¤ I(Aâˆ’H1 , qâˆ’H1 , Î¦) +

X

CIH (Hi , A)

Hi âˆˆH1

â‰¤ I(Aâˆ’H1 , qsâˆ’H1 , Î¦) +

X
Hi âˆˆH1

53

|V (Hi )|c0i (qis )(1 âˆ’ qis ),

completing the proof of step (1). Finally, by combining steps (1) and (2), we obtain
I(A, qs , Î¦) â‰¤ I(Aâˆ’H1 , qsâˆ’H1 , Î¦) +

X

|V (Hi )|c0i (qis )(1 âˆ’ qis )

Hi âˆˆH1

â‰¤ I(Aâˆ’H1 , qeâˆ’H1 , Î¦) +

X

|Hi |c0 (qie )(1 âˆ’ qie )

Hi âˆˆH1

â‰¤ I(A, qe , Î¦),
where the second inequality follows from Proposition 3.3(a) and Lemma 4.1, and the third inequality from Eq. (A.23), completing the proof of the Theorem.

A.9

Proofs of Subsection 6.3

Lemma A.4. Suppose Assumptions 1 and 2 hold. Given two symmetric networks GÌ‚1 and GÌ‚2 , I(GÌ‚1 , q1e , Î¦) â‰¥
I(GÌ‚2 , q2e , Î¦) if and only if I(GÌ‚1 , q, Î¦) â‰¥ I(GÌ‚2 , q, Î¦) for all q âˆˆ [0, 1].
Proof of Theorem A.4. Consider two symmetric random networks GÌ‚1 and GÌ‚2 . We first show that
if for all q âˆˆ [0, 1],
I(GÌ‚1 , q, Î¦) â‰¥ I(GÌ‚2 , q, Î¦),

(A.60)

then q1e â‰¥ q2e where q1e and q2e are the symmetric equilibrium security levels of GÌ‚1 and GÌ‚2 . Assume
to arrive at a contradiction that q1e < q2e . Hence, we have
c0 (q1e ) = PÌƒi (GÌ‚1 , q1e , Î¦) â‰¥ PÌƒi (GÌ‚2 , q1e , Î¦) â‰¥ PÌƒi (GÌ‚2 , q2e , Î¦) = c0 (q2e ).

(A.61)

First equation is implied by Eq. (3.2). First inequality is obtained by the assumption in the statement, and the second inequality is the combination of Proposition 3.3(a) and the fact that q1e < q2e .
Moreover, since by Assumption 1, the function c is strictly convex, we have c0 (q1e ) < c0 (q2e ) which
is in contrast with Eq. (A.61) and shows that q1e â‰¥ q2e .
Combined with Lemma 4.1, this implies Pi (GÌ‚1 , q1e , Î¦) â‰¥ Pi (GÌ‚2 , q2e , Î¦) which completes the
proof of the first part.
We next show that if the condition in Eq. (A.60) does not hold, then we can find two sufficiently
convex cost functions c and cÌ‚ such that
I(GÌ‚1 , q1e , Î¦) > I(GÌ‚2 , q2e , Î¦), and I(GÌ‚1 , qÌ‚1e , Î¦) < I(GÌ‚2 , qÌ‚2e , Î¦),

(A.62)

where q1e and q2e are the symmetric equilibrium security levels of GÌ‚1 and GÌ‚2 for cost function c, and
qÌ‚1e and qÌ‚2e are the symmetric equilibrium security levels of GÌ‚1 and GÌ‚2 for cost function cÌ‚, establishing that a ranking of equilibrium in terms of expected infections is not possible. Let qÌ„, qÌƒ âˆˆ [0, 1] be

54

such that
I(GÌ‚1 , qÌ„, Î¦) > I(GÌ‚2 , qÌ„, Î¦), and I(GÌ‚1 , qÌƒ, Î¦) < I(GÌ‚2 , qÌƒ, Î¦).

(A.63)

We first present two sufficiently convex cost functions c(q) and cÌ‚(q) such that q1e = qÌ„ and qÌ‚1e = qÌƒ.
We then show that q2e < q1e and qÌ‚2e > qÌ‚1e . Combining these inequalities with Lemma 4.1 gives the
desired result. Let c(q) and cÌ‚(q) be such that
c0 (q) =

where aÌ„ =

I(GÌ‚1 ,qÌ„,Î¦)
qÌ„n

I(GÌ‚1 ,qÌƒ,Î¦)
.
qÌƒn
e
e
q1 = qÌ„ and qÌ‚1

aÌ„q
aÌƒq
and cÌ‚0 (q) =
,
(1 âˆ’ q)
(1 âˆ’ q)

and aÌƒ =

One can verify that

= qÌƒ. We next show that q2e < q1e and qÌ‚2e > qÌ‚1e . We first show

that q2e < q1e . Assume to arrive at a contradiction that q2e â‰¥ q1e . Substituting q1e with qÌ„ and combining
with the preceding equation we have
c0 (q2e ) â‰¥ c0 (q1e ) = c0 (qÌ„) =

I(GÌ‚1 , qÌ„, Î¦)
I(GÌ‚2 , qÌ„, Î¦)
I(GÌ‚2 , q2e , Î¦)
>
â‰¥
.
n(1 âˆ’ qÌ„)
n(1 âˆ’ qÌ„)
n(1 âˆ’ qÌ‚2e )

First inequality follows from the fact that c0 (q) is convex and q2e â‰¥ q1e . Second equality follows from
Eq. (3.2), second inequality from Eq. (A.63), and the third inequality from Proposition 3.3(a). Using
Eq. (3.2), we obtain c0 (q2e ) =

I(GÌ‚2 ,q2e ,Î¦)
n(1âˆ’qÌ‚2e )

which is a contradiction and shows the desired result. Using

a similar line of argument, one can show that qÌ‚2e > qÌ‚1e .
Using q2e < q1e and qÌ‚2e > qÌ‚1e together with Lemma 4.1, we obtain Eq. (A.62), completing the
proof.
Proof of Theorem 6.4. We first show the following:
Lemma A.7. Given two symmetric random networks GÌ‚1 and GÌ‚2 generated from two base graphs G1 and
G2 , if G1 âŠ‚ G2 , then Pi (GÌ‚1 , q, Î¦) â‰¤ Pi (GÌ‚2 , q, Î¦) for all i âˆˆ V and for all q âˆˆ [0, 1].
The proof of this lemma follows the same line of argument as Proposition 3.3(c) closely. The
preceding lemma together with Theorem A.4 establishes our desired result.
Proof of Proposition 6.1. The infection probability of an agent in a symmetric random tree T with
distance vector d and the symmetric security level q is defined as follows:
Pi (T, q, Î¦) =

n
1 X
di (1 âˆ’ q)i .
n2
i=1

We first show that for two symmetric random trees (T, d) and (T 0 , d0 ) and a given vector z =

55

(z1 , . . . , zn ) such that z1 â‰¥ z2 â‰¥ . . . â‰¥ zn â‰¥ 0, if T 0 â‰º T , then we have
j
X

(di âˆ’ d0i )zi â‰¥ zj

i=1

j
X

(di âˆ’ d0i ) for all 1 â‰¤ j â‰¤ n.

(A.64)

i=1

To prove this, we use induction on j. For j = 1 (i.e., the induction basis) the statement trivially
holds. We assume that the statement holds for j â‰¤ m < n. We then prove that the statement holds
for j = m + 1.
Expanding the left hand side and substituting j with m + 1 we obtain
j
X
i=1

(di âˆ’ d0i )zi =

m+1
X

(di âˆ’ d0i )zi =

i=1

m
X

(di âˆ’ d0i )zi + zm+1 (dm+1 âˆ’ d0m+1 )

i=1

â‰¥ zm

m
X

(di âˆ’ d0i ) + zm+1 (dm+1 âˆ’ d0m+1 )

i=1
m
X
â‰¥ zm+1 (
di âˆ’ d0i ) + zm+1 (dm+1 âˆ’ d0m+1 )
i=1
m+1
X

= zm+1 (

di âˆ’ d0i )

i=1

where the first inequality follows from the induction hypothesis and the second inequality is due
to the fact that d  d0 and zm+1 < zm .
Using this result, we next show that if T 0 â‰º T then I(TÌ‚ , q, Î¦) â‰¥ I(TÌ‚ 0 , q, Î¦). By the definition of
the distance function we have
I(TÌ‚ , q, Î¦) âˆ’ I(TÌ‚ 0 , q, Î¦) =

n
n
X
1
n X
0
i
n
(d
âˆ’
d
)(1
âˆ’
q)
â‰¥
(1
âˆ’
q)
(di âˆ’ d0i ) â‰¥ 0.
i
i
n2
n
i=1

i=1

The preceding inequality follows from Eq. (A.64) when z is replaced by qÌ„ where qÌ„ = ((1 âˆ’ q), (1 âˆ’
q)2 , . . . , (1 âˆ’ q)n ). Note that qÌ„i â‰¥ qÌ„j â‰¥ 0 for all i â‰¤ j, hence Eq. (A.64) holds. Finally by applying
Theorem A.4, we obtain I(TÌ‚ , q e , Î¦) â‰¥ I(TÌ‚ 0 , qÌ‚ e , Î¦) where q e and qÌ‚ e denote the equilibrium security
levels of TÌ‚ and TÌ‚ 0 respectively.
Proof of Proposition 6.2. Let (Î±i ) be the event in which exactly i agents are susceptible. The expected infections can be stated as
I(GÌ‚, q, Î¦) =

n
X

I(GÌ‚, q, Î¦|(Î±i ))P ((Î±i )),

(A.65)

i=1

where P ((Î±i )) denotes the probability that event (Î±i ) happens.
We first show that I(GÌ‚, q, Î¦|(Î±i )) = n%G ( ni ). Let V i denote the set of subsets of agents of size i,

56

i.e., V i = {V 0 âŠ‚ V ||V 0 | = i}. We have
X

I(GÌ‚, q, Î¦|(Î±i )) =

I(GÌ‚[VÌ„ ], q, Î¦)P (VÌ„ |(Î±i )) =

1 X

I(GÌ‚[VÌ„ ], q, Î¦).
n
i

VÌ„ âˆˆV i

(A.66)

VÌ„ âˆˆV i

Here, the second equality follows from the fact that for all VÌ„ âˆˆ V i , P (VÌ„ ) which is the probability
of having all agents in VÌ„ susceptible and all agents in V âˆ’ VÌ„ immune, is the same and is equal to
1
.
(ni)
Now, note that for a given base graph G, %G ( ni ) denotes the normalized expected size of the

(1 âˆ’ q)i q nâˆ’i . Hence, for all VÌ„ âˆˆ V i , P (VÌ„ |(Î±i )) =

connected component attached to a randomly selected seed node v from G, in the induced subgraph of G over i randomly selected agents from G. In other words, %G ( ni ) denotes expected
infection rate in GÌ‚ when i randomly selected agents are susceptible and the rest of the agents are
immune, which implies the following:
 
1 X
i
n n
i

I(GÌ‚[VÌ„ ], q, Î¦) = n
%G ( ) = n%G ( ).
n
n
n
i
i
i
i
VÌ„ âˆˆV

n
i

The result follows by combining this with the fact that P ((Î±i )) =



(1 âˆ’ q)i q nâˆ’i .

Proof of Theorem 6.5. The proof consists of two parts. Given two base structures G1 [n] and G2 [n],
we first show that if for all r âˆˆ [0, 1] %G1 (r) â‰¥ %G2 (r), then I(GÌ‚1 , q1e , Î¦) â‰¥ I(GÌ‚2 , q2e , Î¦) for any
sufficiently convex cost function. As in the rest of the paper, let q1e and q2e denote the equilibrium
security levels of GÌ‚1 and GÌ‚2 . By Proposition 6.2 and assuming that %G1 (r) â‰¥ %G2 (r) for all r âˆˆ [0, 1],
we have,
 
 
n
n
X
X
n
i
n
i
i nâˆ’i
I(GÌ‚1 , q, Î¦) =
n
(1 âˆ’ q) q %G1 ( ) â‰¥
n
(1 âˆ’ q)i q nâˆ’i %G2 ( ) = I(GÌ‚2 , q, Î¦). (A.67)
i
n
i
n
i=1

i=1

Combining Eq. (A.67) with Theorem A.4 shows the desired result. To prove the only if part, we
will first show the following:
Theorem A.5. For any n and  > 0 there exists Î´(n) such that for all G1 and G2 if there exists an interval
I âŠ‚ [0, 1] of length at least Î´ for which %G1 ( nk ) â‰¥ %G2 ( nk ) +  for all

k
n

âˆˆ I, then there exists q such that

I(GÌ‚1 , q, Î¦) > I(GÌ‚2 , q, Î¦). Furthermore, limnâ†’âˆž Î´(n) = 0.
Proof. Let q = (max(I) + min(I))/2. Consider a Binomial random variable X with parameters n

57

and q. Let XÌ‚ =

X
n.

1
(I(GÌ‚1 , q, Î¦) âˆ’ I(GÌ‚2 , q, Î¦)) = E[%G1 (XÌ‚) âˆ’ %G2 (XÌ‚)]
n
= E[%G1 (XÌ‚) âˆ’ %G2 (XÌ‚)|XÌ‚ âˆˆ I]P r[XÌ‚ âˆˆ I] + E[%G1 (XÌ‚) âˆ’ %G2 (XÌ‚)|XÌ‚ 6âˆˆ I]P r[XÌ‚ 6âˆˆ I]
â‰¥ E[|XÌ‚ âˆˆ I](1 âˆ’ 2eâˆ’nÎ´
=  âˆ’ (1 + )2eâˆ’nÎ´

2 /2

2 /2

) + E[âˆ’1|XÌ‚ 6âˆˆ I]2eâˆ’nÎ´

2 /2

.

The first equation follows from the definition of %G1 and the linearity of expectation, and the
second equation follows from the law of total probability. By applying Theorem A.3, we obtain
P r[XÌ‚ 6âˆˆ I] â‰¤ 2eâˆ’nÎ´

2 /2

. Combining with the fact that %G1 (XÌ‚) âˆ’ %G2 (XÌ‚) â‰¥ âˆ’1, we obtain the first

inequality.
q
By choosing any Î´ > 2 ln(2+2/)
we can ensure that I(GÌ‚1 , q) âˆ’ I(GÌ‚2 , q) > 0 which proves the
n
q
claim. Note that limnâ†’0 2 ln(2+2/)
= 0.
n
Combining the preceding theorem with Theorem A.4 shows the desired result.

A.10

Proofs of Section 7

Proof of Theorem 7.1. Let (Xi ) denote the event that agent i is susceptible. In the random attack
model, the probability of a susceptible agent i getting infected can be stated as follows:
Pi (A, q, Î¦) = Pi (A, q, Î¦|(Xi ))(1 âˆ’ qi ).

(A.68)

Put differently, the probability of a susceptible agent i getting infected is equal to the probability of
having a path between agent i and a randomly selected seed node s in the transmission network
At âˆ¼ (A, q), i.e.,
Pi (A, q, 1n |Xi ) =

1X
n
sâˆˆV

X

P(A,q) (At |(Xi )).
At

{At |(sâˆˆAt )âˆ©iâˆ’â†’s}

Moreover, to compute the expected infections after attacking agent i, we can restate it as the sum
over all agents j, the probability of agent i being connected to agent j. Using this interpretation it is
clear that I(A, q, ei ) = nPi (A, q, 1Ì‚n ). Using Proposition 3.2, we have I(A, q, ei ) = PÌƒi (A, qâˆ’i , 1Ì‚n )(1âˆ’
qi )n.
Proof of Theorem 7.2. To show the existence of the Nash equilibrium of the security game, we
show that the utility of each agent with respect to his security level is always concave if
c00 (q) â‰¥ Î¨2 (Î¦)Î¥(Î¦)(1 âˆ’ q) + 2Î¨(Î¦).

58

(A.69)

Given network A and security profile q, let Î¦ = (Ï1 , . . . , Ïn ) denote the attack decision selected
by the strategic attacker. The utility of an agent j can be written as follows:

uj (A, q, Î¦) = 1 âˆ’ Pj (A, q, Î¦) âˆ’ c(qj )
ï£«
ï£¶
n
X
= ï£­1 âˆ’ (1 âˆ’ qj )
PÌƒj (A, qâˆ’j , ei )Ïi ï£¸ âˆ’ c(qj ).

(A.70)

i=1

For ease of notation, let Î±i = PÌƒj (A, qâˆ’j , ei ). We show that if the inequality (A.69) holds, then
âˆ‚ 2 uj (A,q)
âˆ‚qj 2

â‰¤ 0, proving that the utility of agent j is concave with respect to his security level. Using

Eq. (A.70), we have
âˆ‚ 2 uj (A, q, Î¦)
âˆ‚ âˆ‚uj (A, q, Î¦)
=
2
âˆ‚qj
âˆ‚qj
âˆ‚qj
n
n
X
âˆ‚ X
âˆ‚Ïi
=
(
Î±i Ïi âˆ’ (1 âˆ’ qj )
Î±i
âˆ’ c0 (qj ))
âˆ‚qj
âˆ‚qj
i=1

=2

n
X
i=1

Î±i

i=1

âˆ‚Ïi
âˆ’ (1 âˆ’ qj )
âˆ‚qj

n
X
i=1

Î±i

âˆ‚ 2 Ïi
âˆ’ c00 (qj ).
âˆ‚qj 2

(A.71)

To show the concavity of the utility function we also need to analyze the attackerâ€™s response to
a given security profile q. The attackerâ€™s value after attacking agent i is equal to the expected
infections after the attack. Using Theorem 7.1, expected infections is a linear function of qj and is
obtained from the following equation:
I(A, q, ei ) = n(1 âˆ’ qi )PÌƒi (Aâˆ’{j} , qâˆ’{i,j} , 1Ì‚n ) + n(1 âˆ’ qj )(1 âˆ’ qi )Qi,j (A, qâˆ’{i,j} , 1Ì‚n ).
For ease of notation, let Î³i (A, q) = (1âˆ’qi )PÌƒi (Aâˆ’j , qâˆ’i,j , 1Ì‚n ) and Î²i (A, q) = (1âˆ’qi )Qi,j (A, qâˆ’{i,j} , 1Ì‚n ).
Given network A and security profile q, the optimal attack decision Î¦ = (Ï1 , . . . , Ïn ) is obtained
from the following program:
Maximize
subject to

n
X
i=1
n
X

Ïi (Î²i (A, q)(1 âˆ’ qj ) + Î³i (A, q)) âˆ’ Î¶(Ïi )
(Î»)

Ïi = 1

i=1

Ïi â‰¥ 0

forall i âˆˆ [n]

Define
L(Î¦, Î», Âµ) =

n
X

ï£«
ï£¶
n
n
X
X
Ïi (Î²i (A, q)(1 âˆ’ qj ) + Î³i (A, q)) âˆ’ Î¶(Ïi ) + Î» ï£­
Ïi âˆ’ 1 ï£¸ +
Âµ i Ïi ,

i=1

i=1

59

i=1

(Âµi )

where Î» âˆˆ R and Âµi âˆˆ R+ .
By the first order necessary conditions for the optimality of the solution of a nonlinear program,
we have
âˆ‚
âˆ‚
L = Î²i (A, q)(1 âˆ’ qj ) + Î³i (A, q) âˆ’
Î¶(Ïi ) + Î» + Âµi = 0
âˆ‚Ïi
âˆ‚Ïi
Âµ i Ïi = 0

(for all i âˆˆ [n]).

Furthermore, assuming that Î¶() is a convex increasing function with Î¶(0) = 0, we have
Ïi =
Given that

P

i Ïi


âˆ‚ âˆ’1
Î¶
max(0, Î²i (A, q)(1 âˆ’ qj ) + Î³i (A, q) + Î») .
âˆ‚Ïi

= 1, we have,

âˆ‚ âˆ’1
i âˆ‚Ïi Î¶

P

(A.72)


max(0, Î²i (A, q)(1 âˆ’ qj ) + Î³i (A, q) + Î») = 1.

17

To

evaluate Eq. (A.71), we need to analyze the second derivative of Ïi with respect to qj . Having
Pn
i=1 Ïi = 1 implies that,
n
X
âˆ‚Ïi
i=1

âˆ‚qj

(A.73)

= 0.

Combining with Eq. (A.72), we obtain
n
X
âˆ‚Ïi
i=1

âˆ‚qj

=
=

âˆ’Î²i (A, q) âˆ’

âˆ‚Î»
âˆ‚qj

(A.74)

Î¶ 00 (Ïi )
n
X
âˆ’Î²i (A, q)

Î¶ 00 (Ïi )

i=1

âˆ’Î¨

âˆ‚Î»
âˆ‚qj

(A.75)
(A.76)

= 0.
Hence, we have
âˆ‚Î»
=
âˆ‚qj

Pn

i=1

âˆ’Î²i (A,q)
Î¶ 00 (Ïi )

Î¨

.

(A.77)

The second order derivative of Ïi and Î» with respect to qj is obtained by the following equations.
2

âˆ‚ Î»
âˆ’ âˆ‚q
2
âˆ‚Ïi 2 Î¶ 000 (Ïi )
âˆ‚ 2 Ïi
j
=
âˆ’
(
)
.
Î¶ 00 (Ïi )
âˆ‚qj Î¶ 00 (Ïi )
âˆ‚qj 2
17

Since

âˆ’1
âˆ‚
Î¶ ()
âˆ‚Ïi

(A.78)

is also an increasing function, we can compute Î» for each choice of q by doing a binary search.

60

âˆ‚2Î»
=âˆ’
âˆ‚qj 2

âˆ‚Ïi 2 Î¶ 000 (Ïi )
i=1 ( âˆ‚qj ) Î¶ 00 (Ïi )

Pn

Î¨

(A.79)

.

Replacing Eqs. (A.78) and (A.79) in Eq. (A.71), we obtain:
âˆ‚ 2 uj (A, q, Î¦)
=
âˆ‚qj 2
ï£«
n
X
i=1

ï£«

ï£¶

âˆ‚2Î»
âˆ‚qj 2

ï£¶

ï£¬ âˆ‚Ïi ï£¬
ï£·
âˆ‚Ïi 2 Î¶ 000 (Ïi ) ï£·
ï£· âˆ’ c00 (qj )
+
)
+
(
(1
âˆ’
q
)
Î±i ï£¬
2
ï£­
ï£¸
j
ï£­ âˆ‚qi
ï£¸
Î¶ 00 (Ïi )
âˆ‚qj Î¶ 00 (Ïj )

We next show that if Eq. (A.69) holds, the utility of each agent is concave with respect to his
security level. We consider two cases:
(a) Î¶ 000 () < 0.
(b) Or Î¶ 000 () â‰¥ 0.
In case (a), combining Eq. (A.79) and the fact that Î¶ 000 () < 0 and Î¶ 00 () â‰¥ 0, implies that
Furthermore, since 0 â‰¤ Î²i â‰¤ 1, it is implied that âˆ’1 â‰¤

âˆ‚Î»
âˆ‚qj

âˆ‚ 2 uj (A, q, Î¦)
=
âˆ‚qj 2
n
X
i=1

â‰¤

ï£¬ âˆ‚Ïi
Î±i ï£¬
ï£­2 âˆ‚qi +

n
X
i=1

=

ï£«

n
X
i=1

â‰¤ âˆ’2

âˆ‚2Î»
ï£¬ âˆ‚qj 2
ï£­ 00
Î¶ (Ïi )

ï£«
ï£¬ âˆ‚Ïi
Î±i ï£­2
+
âˆ‚qi
ï£«
ï£¬ âˆ’Î²i âˆ’
Î±i ï£­2
Î¨

ï£¶
+(

âˆ‚2Î»
âˆ‚qj 2
(1
Î¶ 00 (Ïi )
âˆ‚Î»
âˆ‚qj

+

ï£¶
ï£·
âˆ’ qj )ï£¸ âˆ’ c00 (qj )
ï£¶
ï£·
âˆ’ qj )ï£¸ âˆ’ c00 (qj )

n
n
âˆ‚Î» X Î±i
âˆ‚ 2 Î» X Î±i
+
(1
âˆ’
q
)
âˆ’ c00 (qj )
j
âˆ‚qj
Î¶ 00 (Ïi )
Î¶ 00 (Ïi )
âˆ‚qj 2
i=1

â‰¤ âˆ’2

ï£¶

ï£·
âˆ‚Ïi 2 Î¶ 000 (Ïi ) ï£·
00
) 00
ï£¸ (1 âˆ’ qj )ï£·
ï£¸ âˆ’ c (qj )
âˆ‚qj Î¶ (Ïj )

âˆ‚2Î»
âˆ‚qj 2
(1
Î¶ 00 (Ïi )

n
X
i=1

i=1

n
Î±i
âˆ‚ 2 Î» X Î±i
+
(1
âˆ’
q
)
âˆ’ c00 (qj )
j
Î¶ 00 (Ïi )
Î¶ 00 (Ïi )
âˆ‚qj 2

â‰¤ 2Î¨ + (1 âˆ’ qj )

i=1

n
X
âˆ’Î¶ 000 (Ïi )

Î¶ 00 (Ïi )3
i=1

âˆ’ c00 (qj )

â‰¤ 2Î¨ + Î¨2 Î¥(1 âˆ’ qj ) âˆ’ c00 (qj ).
61

> 0.

â‰¤ 0. Replacing these inequalities in

Eq. (A.71), we obtain,

ï£«

âˆ‚2Î»
âˆ‚qj 2

Hence, if Eq. (A.69) holds, the utility of each agent is concave in his security level.
With a similar argument, one can show that if Eq. (A.69) holds, then in case (b) the utility of
each agent with respect to his security level is concave, completing the proof.
Proof of Theorem 7.3. We first investigate the symmetric equilibrium security profile. Consider a
security profile in which the security level of all agents except agent i is equal to q e and the security
level of agent i is q 0 . In the rest of this section, qi denotes a vector of size i with all entries equal to
q. Assuming that the attack cost function is convex, for a symmetric random network, the attack
decision of the strategic attacker can be stated as,
Î¦ = (Ï1 , . . . , Ïn ) where Ïi = Ï, for all j 6= i Ïj =

1âˆ’Ï
.
nâˆ’1

Let PÌ‚ (n) = PÌƒ (A, qe , 1n ) and PÌ‚ (n âˆ’ 1) = EvâˆˆV [PÌƒ (Aâˆ’v , qeâˆ’v , 1Ì‚n )].
The optimal value of Ï is obtained from the following program:
maximize

(A.80)

Ï(1 âˆ’ q 0 )PÌ‚ (n) + (1 âˆ’ Ï)(1 âˆ’ q e )(PÌ‚ (n âˆ’ 1) + (1 âˆ’ q 0 )
subject to

1âˆ’Ï
PÌ‚ (n) âˆ’ PÌ‚ (n âˆ’ 1)
) âˆ’ Î¶(Ï) âˆ’ (n âˆ’ 1)Î¶(
)
e
1âˆ’q
nâˆ’1

Ïâ‰¥0

(A.81)

We first show that the utility of agent i with respect to q 0 is always concave if Assumption 3
holds. Using Proposition 3.1, we can rewrite the utility of agent i as follows:
n
1
(1 âˆ’ PÌ‚ (n)) +
(nPÌ‚ (n) âˆ’ 1)) âˆ’ c(q 0 ).
nâˆ’1
nâˆ’1

(A.82)

!
2Ï
âˆ‚2
n
âˆ‚Ï
âˆ‚
ui (A, (q 0 , qenâˆ’1 ), 1Ì‚n ) = âˆ’c00 (q 0 ) +
(PÌ‚ (n) âˆ’ 1) âˆ’2 0 + 0 2 (1 âˆ’ q 0 ) .
nâˆ’1
âˆ‚q
âˆ‚q 0 2
âˆ‚q

(A.83)

ui (A, (q 0 , qenâˆ’1 ), Î¦) = 1 âˆ’ (1 âˆ’ q 0 )(Ï
Hence, we have

We next show that if Assumption 3 holds,

âˆ‚Ï
âˆ‚q 0

< 0 and

âˆ‚2Ï
âˆ‚q 0 2

> 0. Showing these two inequalities, in

combination with the fact that PÌƒ (A, q, Î¦) â‰¤ 1 will guarantee that the utility of agent i is concave.
Applying the optimality condition of Ï on Eq. (A.81), we obtain
PÌ‚ (n âˆ’ 1)(q e âˆ’ q 0 ) = Î¶ 0 (Ï) âˆ’ Î¶ 0 (

62

1âˆ’Ï
).
nâˆ’1

(A.84)

Using Eq. (A.84), we can restate

âˆ‚Ï
âˆ‚q 0

and

âˆ‚2Ï
âˆ‚q 0 2

as follows:

âˆ‚Ï
âˆ’PÌ‚ (n âˆ’ 1)
=
1âˆ’Ï ,
1
00
âˆ‚q 0
Î¶ (Ï) + nâˆ’1
Î¶ 00 ( nâˆ’1
)


âˆ‚Ï 2
1
000 ( 1âˆ’Ï )
000 (Ï) +
(
Î¶
)
âˆ’Î¶
2
0
âˆ‚q
nâˆ’1
âˆ‚ Ï
(nâˆ’1)2
.
1âˆ’Ï
2 =
1
0
00
00
âˆ‚q
Î¶ (Ï) + nâˆ’1 Î¶ ( nâˆ’1 )

(A.85)

(A.86)

âˆ‚Ï
Assuming that Î¶() is convex, using Eq. (A.85) it immediately follows that âˆ‚q
0 < 0. Furthermore,
q
âˆ‚2Ï
assuming that n â‰¥ Î±Î² + 1, using Eq. (A.85) and if Assumption 3 holds, we obtain âˆ‚q
0 2 > 0. Com-

bining these two inequalities with Eq. (A.83), it implies that given a symmetric random network,
âˆ‚
u(A, (q 0 , q e ), Î¦) < 0. Furthermore, using Eq. (A.84), one can show
âˆ‚ 2 q0
(q 0 , qe ), therefore u(A, (q 0 , qe ), Î¦) is continuous in (q 0 , qe ), completing the

if Assumption 3 holds then
that Ï is continuous in
proof.

Proof of Theorem 7.4. As was shown in Theorem 7.3 if Assumption 3 holds, for symmetric large
networks the utility of each agent is always concave. We first study the symmetric socially optimal
solution. Let us denote the symmetric socially optimal security level by q s . In the symmetric
socially optimal solution we have:
c0 (q s ) = PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) âˆ’ (1 âˆ’ q s )

âˆ‚
PÌƒ (A, qsnâˆ’1 , 1Ì‚n ).
âˆ‚q s

We next consider the symmetric equilibrium. Since all agents play the same strategy we have
Ï=

1
n.

Let us call the symmetric equilibrium security level, q e . Using Eq. (A.82), we can rewrite

the first order condition in the equilibrium as follows:
c0 (q e ) = PÌƒ (A, qenâˆ’1 , 1Ì‚n ) âˆ’ (1 âˆ’ q e )(

n
âˆ‚Ï
(1 âˆ’ PÌƒ (A, qenâˆ’1 , 1Ì‚n )) 0 |q0 =qe ).
nâˆ’1
âˆ‚q

Applying Eq. (A.85) to the preceding equation, we obtain
c0 (q e ) = PÌƒ (A, qenâˆ’1 , 1Ì‚n ) + (1 âˆ’ q e )((1 âˆ’ PÌƒ (A, qenâˆ’1 , 1Ì‚n ))

EvâˆˆV [PÌƒ (Aâˆ’v , qenâˆ’2 , 1Ì‚n )]
).
Î¶ 00 ( n1 )

Knowing that the utility of each agent with respect to his security level is concave, to show that
q e â‰¥ q s it is enough to show that:
PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) + (1 âˆ’ q s )((1 âˆ’ PÌƒ (A, qsnâˆ’1 , 1Ì‚n ))
â‰¥ PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) âˆ’ (1 âˆ’ q s )

63

EvâˆˆV [PÌƒ (Aâˆ’v , qsnâˆ’2 , 1Ì‚n )]
)
Î¶ 00 ( n1 )

âˆ‚
PÌƒ (A, qsnâˆ’1 , 1Ì‚n ).
âˆ‚q s

We first show that âˆ’ âˆ‚qâˆ‚ s PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) â‰¤
metric security profile

qsn .

nPÌƒ (A,qsnâˆ’1 ,1Ì‚n )
1âˆ’q s

in the symmetric settings for the sym-

For a given symmetric security profile qn we can rewrite PÌƒ (A, qnâˆ’1 , 1Ì‚n )

as follows:
PÌƒ (A, qnâˆ’1 , 1Ì‚n ) =
âˆ‚
PÌƒ (A, qnâˆ’1 , 1Ì‚n ) =
âˆ‚q

nâˆ’1
X
i=0
nâˆ’1
X

bi q i (1 âˆ’ q)nâˆ’iâˆ’1 ,

ibi q

(1 âˆ’ q)

nâˆ’iâˆ’1

âˆ’

i=1
nâˆ’2
X

nâˆ’2
X

(n âˆ’ i âˆ’ 1)bi q i (1 âˆ’ q)nâˆ’iâˆ’2

i=0

(n âˆ’ i âˆ’ 1)bi q i (1 âˆ’ q)nâˆ’iâˆ’2

â‰¥âˆ’

i=0
nâˆ’2
X

â‰¥ âˆ’n

â‰¥

iâˆ’1

bi q i (1 âˆ’ q)nâˆ’iâˆ’2

i=0
nâˆ’2
X

âˆ’n
1âˆ’q

bi q i (1 âˆ’ q)nâˆ’iâˆ’1

i=0

âˆ’n
â‰¥
PÌƒ (A, qnâˆ’1 , 1Ì‚n ).
1âˆ’q
Now the condition that should be satisfied will be reduced to,
((1 âˆ’ PÌƒ (A, qsnâˆ’1 , 1Ì‚n ))

EvâˆˆV [PÌƒ (Aâˆ’v , qsnâˆ’2 , 1Ì‚n )]
nPÌƒ (A, qsnâˆ’1 , 1Ì‚n )
)
â‰¥
.
1 âˆ’ qs
Î¶ 00 ( n1 )

Put differently, it is sufficient to show that
EvâˆˆV [PÌƒ (Aâˆ’v , qsnâˆ’2 , 1Ì‚n )]
1
nÎ¶ 00 ( ) â‰¤ (1 âˆ’ q s )((1 âˆ’ PÌƒ (A, qsnâˆ’1 , 1Ì‚n ))
.
n
PÌƒ (A, qsnâˆ’1 , 1Ì‚n )
We next find a lower bound for the right hand side of the preceding relation, which we will denote
it by R. By definition, we have
1
1 nâˆ’1
â‰¤ PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) â‰¤ +
(1 âˆ’ q s ),
n
n
n
1
1 nâˆ’2
â‰¤ EvâˆˆV [PÌƒ (Aâˆ’v , qsnâˆ’2 , 1Ì‚n )] â‰¤ +
(1 âˆ’ q s ).
n
n
n
Using the preceding inequalities, it is easy to show that
1
1
(1 âˆ’ q s )( 1 nâˆ’1
âˆ’ 1)
s
n
n + n (1 âˆ’ q )
nâˆ’1
q s (1 âˆ’ q s )
=
.
n 1 + (n âˆ’ 1)(1 âˆ’ q s )

Râ‰¥

64

One can easily show that the above function is increasing between between q s âˆˆ [0, 1 âˆ’
and decreasing between q s âˆˆ (1 âˆ’

âˆš 1 , 1].
n+1

solution we have

âˆš1 ]
n+1

Furthermore, assuming that q s is the socially optimal

1
c0âˆ’1 ( ) â‰¤ q s â‰¤ c0âˆ’1 (n).
n

We then consider the following cases:
â€¢ c0âˆ’1 (n) â‰¤ 1 âˆ’

âˆš1 ,
n+1

â€¢ c0âˆ’1 ( n1 ) â‰¥ 1 âˆ’

âˆš1 ,
n+1

â€¢ c0âˆ’1 ( n1 ) â‰¤ 1 âˆ’

âˆš1
n+1

â‰¤ c0âˆ’1 (n).

We will only analyze the first case. Other cases can be analyzed similarly. In the first case, R will
be minimized when q s = c0âˆ’1 ( n1 ). Hence, the sufficient condition for having overinvestment is,
n âˆ’ 1 c0âˆ’1 ( n1 )(1 âˆ’ c0âˆ’1 ( n1 ))
1
.
Î¶ ( )â‰¤
n
n2 1 + (n âˆ’ 1)(1 âˆ’ c0âˆ’1 ( n1 ))
00

Second scenario, will be reduced to:
1
n âˆ’ 1 c0âˆ’1 (n)(1 âˆ’ c0âˆ’1 (n))
Î¶ 00 ( ) â‰¤
.
n
n2 1 + (n âˆ’ 1)(1 âˆ’ c0âˆ’1 (n))
And the third scenario will be reduced to
1
n âˆ’ 1 c0âˆ’1 (n)(1 âˆ’ c0âˆ’1 (n))
n âˆ’ 1 c0âˆ’1 ( n1 )(1 âˆ’ c0âˆ’1 ( n1 ))
Î¶ 00 ( ) â‰¤ min( 2
,
).
n
n 1 + (n âˆ’ 1)(1 âˆ’ c0âˆ’1 (n)) n2 1 + (n âˆ’ 1)(1 âˆ’ c0âˆ’1 ( n1 ))
Next, we show that when Î¶ 00 ( n1 ) â‰¥

1
n

then underinvestment always happen. We first show that

in the symmetric socially optimal solution, we have
PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) âˆ’ (1 âˆ’ q s )

âˆ‚
PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) â‰¥ 2PÌƒ (A, qsnâˆ’1 , 1Ì‚n ).
âˆ‚q s

Let s denote the seed node. Using Eq. (3.3) for an agent i in the symmetric socially optimal security

65

profile, we have
X
âˆ‚
s
PÌƒ
(A,
q
,
1Ì‚
)
=
Qj,i (A, qsâˆ’nâˆ’2 , Î¦)(1 âˆ’ q s )
n
nâˆ’1
âˆ‚q s
j6=i
X
X
â‰¥
Qj,i (A, qsâˆ’nâˆ’2 , Î¦|s = i)(1 âˆ’ q s )P (s = i) +
Qj,i (A, qsâˆ’nâˆ’2 , Î¦|s 6= i)(1 âˆ’ q s )P (s 6= i)

âˆ’ (1 âˆ’ q s )

j6=i

â‰¥

X

j6=i

Qj,i (A, qsâˆ’nâˆ’2 , Î¦|s

s

= i)(1 âˆ’ q )P (s = i)

j6=i

= I(A, qs , ei )

1
n(1 âˆ’ q s )

= PÌƒ (A, qsnâˆ’1 , 1Ì‚n ),
where the last inequality follows from Theorem 7.1. Since under Assumption 3, the utility of each
agent with respect to his security level is concave, to guarantee that q e â‰¤ q s , it suffice to show that
PÌƒ (A, qsnâˆ’1 , 1Ì‚n ) + (1 âˆ’ q s )((1 âˆ’ PÌƒ (A, qsnâˆ’1 , 1Ì‚n ))

EvâˆˆV [PÌƒ (Aâˆ’v , qsnâˆ’2 , 1Ì‚n )]
)
Î¶ 00 ( n1 )

â‰¤ 2PÌƒ (A, qsnâˆ’1 , 1Ì‚n ).
Assuming Î¶ 00 ( n1 ) â‰¥ 1, the preceding relation always hold.

A.11

Examples

Example A.1. Consider the network A in Fig. 6. Let n = 100, qa = qa1 = qa2 = 0.5, and qb =
qb1 = . . . = qbnâˆ’2 = 0.25. Suppose also Î¦i = 0.01 for all i = 1, . . . , 100. We show that CI (a1 , A) <
CI (a1 , Aâˆ’a2 ). By definition, we have
X

CI (a1 , A) = Pa1 (A, q, Î¦) +

(1 âˆ’ qj )(1 âˆ’ qa1 )Qj,a1 (A, qâˆ’{a1 ,j} , Î¦)

jâˆˆV âˆ’{a1 }

ï£«

ï£¶

= (1 âˆ’ qa ) ï£­PÌƒa1 (A, qâˆ’{a1 } , Î¦) +

X

(1 âˆ’ qj )Qj,a1 (A, qâˆ’{a1 ,j} , Î¦)ï£¸ .

jâˆˆV âˆ’{a1 }

The network effect on a1 can be written as
PÌƒa1 (A, qâˆ’{a1 } , Î¦) =

1
(1 + (n âˆ’ 2)(1 âˆ’ qb ) + (1 âˆ’ qa )(1 âˆ’ qbnâˆ’2 )).
n

The second term on the right hand side of this equation corresponds to the event that the seed
agent is in {b1 , . . . , bn } and is susceptible and the third term to the event that the seed agent is
a2 , is susceptible and at least one agent in set {b1 , . . . , bn } is susceptible. Also for each j âˆˆ B =

66

ð‘Ž1

ð‘1

ð‘Ž2

ð‘2

ð‘ð‘›âˆ’3 ð‘ð‘›âˆ’2

Figure 6: For the security profile q where qa = qa1 = qa2 = 0.5 and qb = qb1 = . . . = qbnâˆ’2 = 0.25,
CI (a1 , A) < CI (a1 , Aâˆ’a2 ).
{b1 , . . . , bnâˆ’2 }, we have
Qj,a1 (A, qâˆ’{a1 ,j} , Î¦) =

1
(1 + (n âˆ’ 3)qa (1 âˆ’ qb )).
n

The first term on the right hand side of the above equation corresponds to the event that the seed
agent is a1 and the second term to the event that the seed agent is in B âˆ’ {j} and a2 is not susceptible. Similarly, we have
Qa2 ,a1 (A, qâˆ’{a1 ,a2 } , Î¦) =

1
(1 âˆ’ qbnâˆ’2 ).
n

The right hand side of the above equation is the probability of the event that the seed agent is a1
and at least one of the agents in B is susceptible. Putting these equations together, we obtain
CI (a1 , A) =

1 âˆ’ qa
(1 + 2(n âˆ’ 2)(1 âˆ’ qb ) + 2(1 âˆ’ qa )(1 âˆ’ qbnâˆ’2 ) + (n âˆ’ 2)(n âˆ’ 3)qa (1 âˆ’ qb )2 ) â‰ˆ 14.112.
n

Using similar approach, we obtain
CI (a1 , Aâˆ’a2 ) =

1 âˆ’ qa
(1 + 2(n âˆ’ 2)(1 âˆ’ qb ) + (n âˆ’ 3)(n âˆ’ 2)(1 âˆ’ qb )2 ) â‰ˆ 27.47.
n

Comparing the preceding equations, we observe that CI (a1 , A) < CI (a1 , Aâˆ’a2 ).
Example A.2. Consider the 5-node star network given in Fig. 1. Let c(q) = 0.2q 2 (2.9 âˆ’ 1.33q),
and Î¦i =

1
5,

for i = 1, . . . , 5. Note that c(q) is not sufficiently convex. One can verify that qe =

(0.2, 1, 1, 1, 1) is a pure-strategy Nash equilibrium security profile and qs = (1, 0.2, 0.2, 0.2, 0.2) is a
socially optimal security profile. The expected infections in the equilibrium is I(A, qe , Î¦) = 0.16.
However, expected infections in the social optimum is I(A, qs , Î¦) = 0.64.

67

