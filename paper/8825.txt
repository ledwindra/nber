NBER WORKING PAPER SERIES

IS THE THREAT OF REEMPLOYMENT SERVICES MORE EFFECTIVE THAN THE
SERVICES THEMSELVES? EXPERIMENTAL EVIDENCE FROM THE UI SYSTEM

Dan A. Black
Jeffrey A. Smith
Mark C. Berger
Brett J. Noel

Working Paper 8825
http://www.nber.org/papers/w8825

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
March 2002
We thank the U.S. Department of Labor for financial support through a contract between the Kentucky Department of
Employment Services and the Center for Business and Economic Research at the University of Kentucky. Smith also
thanks the Social Science and Humanities Research Council of Canada for financial support. We thank Bill Burris,
Donna Long, and Ted Pilcher of the Kentucky Department of Employment Services for their assistance, and Steve Allen,
Susan Black, Amitabh Chandra, and Roy Sigafus for research assistance. Seminar participants at Boston University,
Colorado, Cornell, the Econometric Society meetings, Houston, Indiana, the Institute for Fiscal Studies, Louisiana State,
Maryland, MIT, Missouri, Ohio State, the Society of Labor Economists meetings, the Stockholm School of Economics,
SUNY-Buffalo, Syracuse, the Tinbergen Institute, UBC, the University of Toronto, the Upjohn Institute and the
University of Western Ontario provided useful comments. We especially thank Jaap Abbring, Joshua Angrist,
Christopher Taber and Bruce Meyer for their suggestions, along with two anonymous referees. The views expressed
herein are those of the authors and not necessarily those of the National Bureau of Economic Research.

© 2002 by Dan A. Black, Jeffrey A. Smith, Mark C. Berger and Brett J. Noel. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

Is the Threat of Reemployment Services More Effective than the Services Themselves?
Experimental Evidence from the UI System
Dan A. Black, Jeffrey A. Smith, Mark C. Berger and Brett J. Noel
NBER Working Paper No. 8825
March 2002
JEL No. H0, J6, C9

ABSTRACT
This paper examines the effect of the Worker Profiling and Reemployment Services (WPRS)
system. This program “profiles” UI claimants to determine their probability of benefit exhaustion (or
expected spell duration) and then provides mandatory employment and training services to claimants with
high predicted probabilities (or long expected spells). Using a unique experimental design, we estimate
that the WPRS program reduces mean weeks of UI benefit receipt by about 2.2 weeks, reduces mean UI
benefits received by about $143, and increases subsequent earnings by over $1,050. Much (but not all)
of the effect results from a sharp increase in early exits from UI in the experimental treatment group
compared to the experimental control group. These exits coincide with claimants finding out about their
mandatory program obligations rather than with actual receipt of employment and training services. While
the program targets those with the highest expected durations of UI benefit receipt, we find no evidence
that these claimants benefit disproportionately from the program. In addition, we find strong evidence
against the “common effect” assumption, as the estimated treatment effect differs dramatically across
quantiles of the untreated outcome distribution. Overall, the profiling program appears to successfully
reduce the moral hazard associated with the UI program without increasing the take-up rate.

Dan A. Black
Center for Policy Research
426 Eggers Hall
Syracuse University
Syracuse, NY 13244-1020
danblack@maxwell.syr.edu

Jeffrey A. Smith
Department of Economics
University of Maryland
3105 Tydings Hall
College Park, MD 20742
and NBER
smith@econ.umd.edu

Mark C. Berger
Department of Economics
Gatton College of Business and Economics
University of Kentucky
Lexington, KY 40506-0034
mberger@pop.uky.edu

Brett J. Noel
American Express - TRS
10030 North 25th Avenue
Building 10400
Phoenix, AZ 85021
Brett.J.Noel@aexp.com

1 Introduction
It is well known that the UI system provides incentives for workers to lengthen their spells of
unemployment by providing a subsidy to their job search and leisure. This paper examines the
behavioral effects of a new program that “profiles” Unemployment Insurance (UI) claimants
based on the predicted length of their unemployment spell or the probability that they will
exhaust their UI benefits. Established in 1993 and formally called the “Worker Profiling and
Reemployment Services” (WPRS) system, the program forces claimants with long predicted UI
spells or high predicted probabilities of benefit exhaustion to receive employment and training
services early in their spell in order to continue receiving benefits. 1
We consider the effects of the profiling program on claimant behavior using data from
Kentucky. Our data embody a unique experimental design. The randomization in our
experiment occurs only to satisfy capacity constraints and only at the margin. UI claimants are
assigned “profiling scores” that take on integer values from 1 to 20, with higher scores indicating
claimants with longer expected durations. The requirement to receive reemployment services is
allocated by profiling score up to capacity. Within the marginal profiling score – the one at
which the capacity constraint is reached – random assignment allocates the mandatory services
requirement. Thus, if there are 10 claimants with a profiling score of 11 but only seven
remaining slots, seven claimants are randomly assigned to the treatment group and three are
assigned to the control group.
Campbell (1969) terms this experimental design a “tie-breaking experiment.” Apparently,
Thistlethwaite and Campbell (1960) first advocated it as a means of evaluating the impact of

1

See U.S. Department of Labor (1999) for a more detailed description of the program and of how it varies across
states. See Blackmore and Welsh (1983) for a description of a related debate regarding statistical models for
sentencing in the criminology literature.

2
receiving a college scholarship. 2 To our knowledge, our experiment is the first to use this
design. In general, the “tie-breaking experiment” does not directly identify many commonly
estimated parameters, such as the impact of treatment on the treated. Instead, further
assumptions are required, which we discuss in Section 4.
A large empirical literature provides evidence consistent with the view that UI reduces
the incentive to find a job quickly. For example, Meyer (1990) documents spikes in the empirical
hazard function as workers approach the exhaustion of their UI benefits, and Card and Levine
(2000) and Noel (1998) document that increasing the length of time that claimants may receive
benefits causes the empirical hazard function to fall substantially. 3 Looking at search behavior
directly, Barron and Mellow (1979) find that those workers receiving UI searched 1.6 fewer
hours per week than unemployed workers not receiving payments. St. Louis, Burgess, and
Kingston (1986) offer compelling evidence that claimants systematically violate the search
requirements that UI imposes.
Several policies have modified the system by reducing the incentives for excess benefit
receipt while at the same time not punishing workers for whom a longer search is optimal. The
reemployment bonus experiments surveyed in Meyer (1995) tested one such policy. In these
studies, claimants who find a job quickly and keep it receive a cash payment. 4 These
experiments indicate that the unemployment spells of UI claimants can be shortened without loss
of post-program earnings. 5 Though reemployment bonuses reduce the length of UI spells, they
prove expensive because many claimants receive bonuses who would have exited quickly

2

We thank Joshua Angrist for bringing these citations to our attention. Campbell (1969) notes the relationship
between the “tie-breaking experiment” and the regression discontinuity design. See Heckman, LaLonde and Smith
(1999) and Angrist and Krueger (1999) for discussions of the regression discontinuity design.
3
See also Ehrenberg and Oaxaca (1976), Moffitt (1985), Katz and Meyer (1990) and many others.
4
In the Illinois experiment, for a subset of the treatment group it was the employer rather than the employee who
received the bonus. This form of the bonus had a much lower utilization rate and was omitted from subsequent
experiments.

3
without them. Moreover, Meyer argues convincingly that permanent adoption of reemployment
bonuses would substantially increase the UI take-up rate as eligible persons who expect short
spells and who do not at present file for benefits would do so in order to collect the bonus. This
response would further increase the cost of the program without increasing its benefits. 6
While the UI bonus schemes represent a “carrot” designed to lure claimants back into
employment, other experiments used “sticks,” such as greater enforcement of UI job search
requirements, to push claimants who could find work back into employment by raising the costs
of staying on UI. Ashenfelter, Ashmore and Deschênes (1999) present experimental evidence on
work search enforcement programs in four states that suggests at most a small deterrent effect.
Meyer (1995) reviews other experiments that examined programs that combined stricter
enforcement with job search assistance. These programs had stronger effects and passed
standard cost-benefit tests. Such “stick” policies have the potential to shorten UI spells without
causing the increases in the take-up rate generated by reemployment bonuses.
The profiling program we examine in this paper combines aspects of both types of UI
reforms. For some claimants, the services they must receive may represent a “stick” that raises
the cost of staying on UI and thereby induces early exit. In essence, the services operate as a
leisure tax for these claimants. 7 For others, the services may represent a “carrot” that augments
their human capital and job search skills.
We have four major findings. First, using our unique experimental data, we evaluate the
WPRS system for persons at the profiling score margin. We estimate that for this group, the
program reduces mean weeks of UI benefit receipt by about 2.2 weeks, reduces mean UI benefits

5

See Anderson (1992), Decker (1994), Decker and O'Leary (1995) and Woodbury and Spiegelman (1987) for
analyses of the individual bonus experiments.
6
O'Leary, Decker and Wandner (1998) propose using profiling to allocate eligibility for reemployment bonuses to
get around the problem of increases in the take-up rate and of subsidizing current claimants who would have short
spells even without the bonuses.

4
received by about $143, and increases subsequent earnings by about $1,000. Given its very low
cost, the program easily passes standard cost-benefit tests. Our findings suggest that programs
that combine carrots and sticks early on in a benefit spell may be more cost-effective than other
programs types, such as bonuses and tighter eligibility monitoring, examined in recent years.
Second, the dynamics of the treatment effect provide important evidence about how the
program works. The experimental treatment group has significantly higher earnings in the first
two quarters after filing their UI claims than the control group, while there are no significant
differences in the third through sixth quarters. This suggests that the earnings gains result
primarily from earlier return to work in the treatment group. Moreover, examination of the exit
hazard from UI suggests that much of the impact results from persons in the treatment group
leaving UI upon receiving notice of the requirement that they receive reemployment services,
rather than during or after the receipt of those services. Thus, the program induces some jobready claimants to exit quickly, thereby reducing the extent of moral hazard in the UI program.
Third, using the framework in Heckman, Smith, and Clements (1997) we estimate the
distribution of impacts from the WPRS treatment. We find strong evidence against the
“common effect” assumption in our data, as the estimated impact of treatment varies widely
across quantiles of the outcome distributions. The pattern of impacts suggests that the treatment
has its largest effect on persons whose spells without treatment would be of moderate duration.
Fourth, we evaluate the use of profiling scores based on expected UI claim duration as a
means of allocating the treatment. If this is an efficient method of treatment allocation, we
would expect to find that the impact of treatment increases in the profiling score. Instead, we
find little evidence of any systematic relationship between the estimated impact of treatment and
the profiling score. This suggests that such profiling does not increase the efficiency of

7

See, among others, Besley and Coate (1992), Coate, Johnson and Zeckhauser (1994) and Black and Smith (2001)

5
treatment allocation and indicates the potential value of further research on econometric
methods of treatment allocation before extending profiling to other programs. 8
The paper proceeds as follows: In the next section, we describe the Kentucky WPRS
system and the design of the experiment. Section 3 presents a theoretical framework for our
investigation. Section 4 discusses the parameters of interest in evaluating the WPRS program and
indicates what assumptions are required to obtain estimates of these parameters using our data.
The fifth section analyzes the experimental data and the final section concludes.

2 How the WPRS System Works
States are afforded a great deal of leeway in the design and implementation of their WPRS
systems. In Kentucky, the Department of Employment Services contracted with the Center for
Business and Economic Research (CBER) of the University of Kentucky to develop an
econometric model of expected UI spell duration.
CBER estimated the profiling model using five years of UI claimant data and variables
obtained from various administrative and public use data sets. The profiling model contains
local economic and labor market conditions along with worker characteristics. 9 U.S. Department
of Justice regulations prevent states from using sex, age, race, ethnicity, and veteran status in
their profiling models. While the econometric profiling model provides a continuous measure of
the expected number of weeks of benefit receipt, CBER provides the Department of Employment
Services with a discrete profile score ranging from 1 to 20. Claimants predicted by the profiling
model to exhaust between 95 and 100 percent of their unemployment benefits receive a score of

for discussions of leisure taxes and related issues such as work requirements in transfer programs.
8
See Berger, Black, and Smith (2000) for a more detailed discussion of this issue.
9
See Berger, Black, Chandra, and Allen (1997) for a more detailed description of the model. The profiling model
has moderate success in predicting claimants who will exhaust their UI benefits. Berger, et al. report that selection
based on the profiling model results in a treated group whose members receive 78.3 percent of their possible benefits
while random assignment would result in a treated group whose members receive only 66.6 percent of their possible
benefits. “Perfect” assignment based on realized spell lengths would yield a treatment group whose members
receive about 93 percent of their potential benefits.

6
20, claimants predicted to exhaust between 90 and 95 percent of their unemployment benefits
receive a 19, and so on. The WPRS system was implemented in October of 1994; we make use
of UI spells starting between that date and June 30, 1996.
The Kentucky WPRS system begins with claimants providing information about their
employment history and characteristics while filing their claims. For claimants found to be
eligible for profiling, the Kentucky DES provides CBER with data from the claimants' intake
forms. 10 CBER then provides local Department of Employment Services' offices with the
profiling scores of claimants in their area. Finally, those claimants selected to receive
reemployment services are contacted through the mail to inform them of their rights and
responsibilities under the program. A copy of the letter sent by the Department of Employment
Services appears in Exhibit 1.
Because of capacity constraints, local offices at some times during the year are not able to
serve the entire population of claimants, making it necessary to ration entry into the program.
CBER allocates program slots at each local office, serving those claimants with the highest
profiling scores. In the marginal score group, where there are enough slots to serve some but not
all claimants with a given score, CBER randomly assigns persons to either an experimental
treatment group required to participate in reemployment services as a condition of continued UI
receipt or an experimental control group exempt from this requirement. We call these sets of
claimants “profiling tie groups,” or PTGs – groups of claimants in a given office filing claims in
a given week who have the marginal profiling score for that office in that week. This design
differs from typical experimental evaluations of employment and training programs wherein all
program applicants are randomly assigned.

10

Individuals who have a definite recall-to-work date or who are hired through a union hall are exempt from
profiling.

7
Unfortunately for the experiment but fortunately for the claimants, the Kentucky
economy was extremely strong from October 1994 to June 1996, the period for which we
currently have data. As a result, local offices were often able to treat the entire claimant
population. Indeed, of the 57,779 claimants in this period, 48,002 were selected for treatment, or
slightly over 83 percent. Of the 2,748 potential PTGs, there are only 286 actual PTGs, ranging in
size from 2 to 54. The mean size of a PTG is 6.9, with a median of 4, a 25th percentile of 3, and
a 75th percentile of 8. Profiling scores within the PTGs range from 6 to 19 with the median and
the mode at 16. 11 Combining all of the PTGs yields a treatment group of 1,236 claimants and a
control group of 745 claimants. Thus, the experimental design uses only about 2.6 percent of the
treated population and 7.6 percent of the untreated population. Table 1 compares the
demographic characteristics of the treatment and control groups as well as the population of
treated claimants.
Figure 1 provides a time line for the typical claimant, although there is considerable
heterogeneity among claimants in the timing of these events. Unemployment insurance checks
are usually sent fortnightly in Kentucky. The first check is received in week two of the spell.
The letter in Exhibit 1 is typically received after the first check but before the second – that is, in
week three or four. Claimants need to contact the UI office in week three or four to verify their
continuing eligibility in order to receive the second check. Thus, if the letters, and the
mandatory reemployment services they imply, are to have a deterrent effect, we would expect to
observe it between weeks two and four. Within ten working days following notification of the
program, claimants selected for treatment report to a local office for an orientation where they
learn about the program and complete a questionnaire. Using this information, Employment
11

Most of the variation in the marginal profiling score among the PTGs consists of variation across local offices. A
regression of the marginal profiling score on a vector of local office indicators using PTGs as the unit of observation

8
Services staff assess the claimants and then refer them to specific services, such as assisted job
search, employment counseling, job search workshops, and retraining programs.
Among those claimants who attended the orientation, 76.7 percent were referred to less
expensive job search and job preparation activities. These less expensive services are also less
intensive, typically consuming from four to six hours of claimant time. In contrast, only 13.8
percent were referred to (relatively) more expensive education and training programs. 12 The
average number of services received following orientation was 1.02. Conditional on completing
at least one service, the average number of additional services received was 2.10. Of those
referred to services, only 61.3 percent completed at least one. Another 5.7 percent started at least
one service but returned to employment before completing any. Overall, 31.8 percent of those
referred received no services because they had returned to employment, chose not to claim
benefits, or were exempted because their previous employer provided similar services. 13

3 Theoretical Framework
To get a better feel for the potential impact of the program, in this section we outline a simple
model of an unemployed worker's job search in the presence of unemployment insurance. We
begin by considering the value of being unemployed in the absence of the WPRS system. In the
U.S. unemployment insurance system, benefits are paid for a limited duration, usually 26 weeks.
As a result, the value of being unemployed decreases over time up to the point of benefit
exhaustion. After benefit exhaustion the value of being unemployed remains a constant,
reflecting the assumed stationarity of the distribution of wage offers. A worker will maximize
his or her discounted, expected utility by setting the reservation wage so that the value of

explains 64 percent of the variation in profiling scores. There are, however, at least two different offices for each
profiling score among the PTGs.
12
Individuals could be referred to more than one service and some persons were referred to miscellaneous other
services. See Noel (1998) for a detailed description of the available services.

9
employment at the reservation wage just equals the value of being unemployed, as in standard
search models. Therefore, the declining value of being unemployed implies that the worker's
reservation wage declines until the worker exhausts his or her benefits.
There are at least two ways in which the WPRS system may influence workers’
valuations of unemployment. First, if the reemployment services are effective they will improve
the distribution of wage offers during and after receipt of the services. This has the further effect
of increasing the value of being unemployed prior to the start of services, as claimants anticipate
receiving them. There are a couple of reasons to believe, however, that any impact of
reemployment services on wage offers will be small. Past experience with government training
programs suggests that they are often ineffective (Heckman, LaLonde and Smith, 1999). In
addition, most of the services provided to the unemployed under WPRS are of modest duration
and cost relatively little to provide. Assuming reasonable rates of return on investment, their
modest cost suggests at best a modest effect.
Second, because the reemployment services take time, receiving services reduces the
quantity of leisure that unemployed workers may consume. This “leisure tax” lowers the value of
remaining unemployed both before and during the period of service receipt. 14 Time spent in
reemployment services also reduces the time available for job search, which further reduces the
value of being unemployed before and during the services.
The net effect of the profiling system on the value of unemployment, and hence on the
probability of leaving UI in each week, depends on the signs and magnitudes of these two
effects. If the services are effective, then the two factors work in opposite directions prior to and

13

The fraction exempted due to receiving similar services from their previous employer is not precisely known, but
program staff indicate that it is small. The remaining 1.2 percent were either referred in error or have incomplete
data on service completion.
14
If the requirements of the WPRS system are sufficiently onerous, they may lead eligible unemployed persons to
avoid UI entirely. Interestingly, even in the absence of the profiling system, empirical studies find UI take-up rates

10
during the services. Once done with services, only the wage offer effect persists and the
employment hazard is increased. If the services are ineffective, then the net effect prior to and
during receipt of services is to lower the value of unemployment and speed exit from UI, but the
program has no effect after receipt of services. If the program works for some claimants but not
for others, then we might observe a mixture of effects, including a situation where the hazard rate
out of UI increases prior to service receipt due to claimants for whom the services represent a
cost, and after service receipt due to claimants for whom they represent a benefit.
While we have couched this argument in terms of the workers' reservation wages,
workers may care about other dimensions of their employment. To the extent that the WPRS
program causes workers to accept less attractive job matches, it will lead to greater job turnover
and more frequent subsequent spells of unemployment. Unfortunately, this effect is difficult to
detect in the data when the treatment has the effect of inducing earlier return to work, because an
earlier return to work increases the time at risk of subsequent unemployment even in the absence
of any effect operating through match quality.

4 Parameters of Interest, Identification and Estimation
In this section, we discuss different parameters of interest and outline how we can use our
experimental data to identify them. For simplicity, suppose that the experimental data are
generated from the linear model
yi = X iγ + Ti βi + εi ,

(1)

where yi is the dependent variable for the ith individual, X i is a vector of covariates, Ti is the
treatment indicator, εi is white noise, γ is a vector of unknown parameters, and βi is the personspecific impact of the treatment.

of substantially less than one. See Blank and Card (1991) and Anderson and Meyer (1997) for estimates and
extended discussion of the measurement issues involved.

11
Because many members of the experimental treatment group do not receive
employment and training services, it is important to distinguish the impact of actually receiving
reemployment services from the impact of being assigned to treatment per se. We use
“treatment” to mean receiving the letter in Exhibit 1 and being subject to the requirement to
receive services in order to continue receiving UI, rather than actual receipt of employment and
training services. It is this treatment whose impact is captured by βi .

4.1 Parameters of Interest
We now define three parameters of interest. The most common parameter in the evaluation
literature is the mean impact of treatment on the treated ( TT ). In our notation, it is
TT = E( βi |Ti = 1) .
The TT parameter indicates the mean effect of treatment as it is currently allocated and provides
the key input for a cost-benefit analysis of the profiling treatment as presently allocated.
Another parameter of interest is the mean impact of treatment on a randomly selected
claimant. This parameter is called the average treatment effect ( ATE ), and is given by
ATE = E ( βi ) ,
where the expectation is taken over the population of claimants. 15 The ATE parameter provides
the key input for a cost-benefit analysis of a program in which the treatment is given to all
claimants, regardless of profiling score.
The third parameter of interest consists of what Imbens and Angrist (1994) call a local
average treatment effect (LATE). It is local in the sense that it represents the mean impact of
treatment on the treated for persons in the profiling groups, and thus on the margin of being
treated. The implicit instrument is a particular change in the program budget, one that would

12
leave all the treated persons in the PTGs untreated. Define PTG-specific mean impacts by
βj = E( βi |PTG = j ) , where PTG = 0 for persons not in a PTG and PTG = j ∈{ 1,..., 286 }
where j indexes the 286 PTGs for persons in a PTG. In this notation, the LATE parameter is
given by
LATE = E( βi |Ti = 1,PTG > 0 ) = Ei ( βj |Ti = 1,PTG > 0 ) .
The LATE parameter is a weighted average of the βi where the weights are proportional to the
number of treated persons in each PTG. 16

4.2 Identification
We now consider how our experimental data can be used to identify the parameters defined in
the preceding section. To begin, we assume that the standard set of assumptions regarding
experimental data hold, including the assumption that the impact on one person does not depend
on which other, or how many other, persons receive the treatment. 17
Under these assumptions the experimental data from the PTGs identify the βj . Within
each PTG, random assignment assures that cov(T,
i εi ) = 0 in equation (1). As LATE is a
weighted average of the βj , it too is identified by our experimental data. Identification of the

15

The imposition of the profiling treatment on the population of claimants could affect the composition of that
population, by encouraging or discouraging some eligible persons from taking up their UI benefits, or even by
affecting who becomes unemployed.
16
We could define other LATEs corresponding to different weighted averages of the PTG-specific impacts. For
example, we could consider the mean impact on all persons in a PTG, given by
E( βi |PTG > 0 ) = Ei ( βj |PTG > 0 ) ,
or the average impact among PTGs, given by
E j ( βj |PTG > 0 ) .
These parameters correspond to different policy experiments than the LATE defined in the text. In a world of
heterogeneous impacts, these different parameters will differ in value. See Black, McKinnish and Smith (2001) for
further discussion.
17
This condition is called the stable unit treatment value assumption (SUTVA) in the statistics literature. The
remaining standard assumptions are no randomization bias, no treatment group dropout and no control group
substitution into the same or similar treatments. These assumptions are discussed in detail in Heckman and Smith
(1995) and Heckman, LaLonde and Smith (1999).

13
LATE parameter requires no additional assumptions about the person-specific impacts βi .
They can vary across persons as a function of X i or in ways unrelated to X i .
Because the impact of treatment may differ between persons in the PTGs and persons not
in the PTGs, the experimental data from the PTGs do not directly identify the average treatment
effect or the impact of treatment on the treated without some additional structure. The simplest
assumption to make is the “common effect” assumption, whereby the impact of treatment is the
same for all persons, so that βi = β for all i . The same conclusions follow for the slightly more
general case where βi = β +νi but νi , the person-specific component of the impact, is either not
known or known but not acted upon. 18 In the common effect case, all three parameters are the
same, so that
ATE = TT = LATE .
Given that the experimental data identify the LATE parameter, under the common effect
assumption they also identify the average treatment effect and the effect of treatment on the
treated.
The common effect assumption, though frequently used (often implicitly) in the applied
literature, is quite strong. A second assumption relaxes the common effect assumption to allow
variation in impacts across persons, but only as a function of observed covariates. In notation, it
assumes that βi = β( X i ) .19 In this case, the experimental data from the PTGs can be used to
identify the β( X i ) function. To obtain estimates of the ATE or TT parameters requires only
applying the estimated β( X i ) function to the distribution of the X i among all claimants or
among treated claimants, respectively. Thus, for example, we would estimate TT as

18

In fact, even this condition is stronger than is strictly necessary. What is required is that the idiosyncratic
component of the impact is uncorrelated with whether or not the claimant is in a PTG.

14
TT = ∫ β( Xi ) f ( Xi |Ti = 1)dX i .

(2)

We apply this method to estimate the TT parameter in Section 5.6 below.
This method works so long as the support of X i in the PTGs includes the support of X i
in the broader population for which an estimate is being constructed. The problem of a sufficient
support for X i within the population of persons in a PTG is not of merely theoretical interest.
Suppose that the impact of the program is a function of the profiling score, Pi , so that
βi = β( Pi ) . In this case, if we wished to estimate the average treatment effect for all UI
claimants, the support condition would prevent us from doing so, because the population of
treated claimants includes values of Pi from 1 to 20 while the population of claimants in PTGs
includes only values of Pi from 6 to 19.
This discussion of identification reveals an important aspect of our tie-breaking
experimental design. The tie-breaking design may be acceptable in contexts where traditional
random assignment designs are not, because it requires less random assignment and does not
randomly assign those most in need. These political benefits come at the cost of the additional
assumptions required in the tie-breaking design to identify the TT and ATE parameters, which
are the usual objects of evaluation interest. 20

4.3 Estimation
To produce our experimental impact estimates, we estimate versions of
yi = µj + β* Ti + υi ,

(3)

19

As in the common effect case, in this case it can also be assumed that there is additional variation in the personspecific impact, so long as it either not known or not acted upon.
20
Identification in the general case wherein βi = β( Xi ) + νi and νi is known and acted upon is beyond the scope of
this paper. See Heckman, Smith and Clements (1997) and Heckman and Smith (1998) for extended discussions of
this case.

15
where yi is the outcome for the ith individual, Ti is a binary indicator for whether or not the
ith individual received treatment, µj is a vector of PTG fixed effects to control for differences
in expected earnings in the absence of treatment across PTGs, and υi is a random disturbance
term. β* and µj are parameters to be estimated, and the µj correspond to the X i in equation
(1).
Conditioning on the PTG fixed effects has two important consequences for the estimates.
First, because the proportion of claimants in the treatment group varies across PTGs, failure to
control for PTGs would result in biased estimates of the impact parameters if expected earnings
in the absence of treatment differ across PTGs. Second, because each PTG consists of
individuals with a specific profiling score at a particular location on a particular week, including
the µj implicitly conditions on the profiling score, location, and time period. Conditioning on
these factors substantially reduces the residual variation in these data and thereby increases the
precision of our estimated treatment effects. 21
In a common effect world, unweighted estimation of equation (3) provides efficient
estimates of the all three parameters of interest defined in Section 4.1. Similarly, estimation of a
version of equation (3) with interaction terms provides consistent estimates of the β( X i )
function when the βi = β( X i ) assumption holds.
When the common effect assumption does not hold and there are different impacts across
PTGs, unweighted estimation of equation (3) does not provide a consistent estimate of any of the
three parameters of interest. Instead, the β* from unweighted estimation of equation (3) consists
of a weighted average of the βj that is difficult to interpret in a meaningful way. For our

21

Adding additional X i in an attempt to soak up more of the residual variance has little effect on the coefficient
estimates (as expected given random assignment) and little effect on the estimated standard errors.

16
purposes, two features of the implicit weights on the βj are interesting. First, for a given
random assignment ratio within a PTG, increases in the number of claimants in the PTG
increases the implicit weight on that PTG in the estimate β* . Second, for a given size of PTG
the weight is larger the closer the random assignment ratio is to 0.5. 22
To estimate the LATE parameter when the common effect assumption does not hold
requires estimating a weighted version of equation (3). To estimate the mean impact of
treatment on the treated persons in a PTG, we weight the data so that

P r (T i ) =

1

2

within each

PTG. Exact formulae for the weights are given in Black, McKinnish and Smith (2001).

5 Empirical Analyses
5.1 Aggregate Estimates
We focus on three outcomes of interest: the number of weeks that a claimant receives benefits,
the amount of benefits that the claimant receives, and the claimant's earnings in the quarters
following initiation of the UI claim. All data elements are taken from administrative records of
the Kentucky Department of Employment Services.
The measure of earnings after the unemployment event is less than ideal for three
reasons. 23 First, because UI records are only for the Commonwealth of Kentucky, no earnings
are recorded for claimants who crossed state lines to begin employment. This is likely to be
particularly problematic in the urban areas of Kentucky. Of the seven Metropolitan Statistical
Areas in Kentucky, only Lexington is not located on the border of an adjoining state. While this
does not interject any bias into the experiment per se, it is important to keep in mind that we are
measuring the earnings of claimants in Kentucky, not their total earnings.

22

The derivation of the weights on the βj implicit in the unweighted estimation of equation (3) is beyond the scope

of this paper; see Black, McKinnish and Smith (2001) for the derivation.
23
See Hotz and Scholz (2000) for a general discussion of the advantages and disadvantages of administrative data
and Kornfeld and Bloom (1999) for a comparison of UI data and survey data in an evaluation context.

17
Second, earnings are not observed for claimants who work in a non-covered sector.
Third, UI records do not include any “informal” activities. To the extent that claimants work “off
the books,” the UI records understate total earnings. If the treatment increases participation in the
formal labor market and reduces participation in the informal labor market, then our measure of
earnings will tend to overstate the earnings impact of treatment. These problems are standard in
all analyses that use earnings variables constructed from state-level UI records.
Table 2 presents the basic impact estimates from the experiment, obtained by estimating
equation (3) above. In column (1) we report the results for the unweighted data. In a common
effect world, these constitute consistent estimates of all three parameters of interest introduced in
Section 4.2. We find that the treatment group collects payments for about 2.2 fewer weeks than
the control group. The treatment group receives about $143 less in benefits than the control
group, but this difference is statistically significant only at the ten percent level. Finally, the
treatment group earned, on average, $1,054 more than the control group in the year following
initiation of the UI claim. Thus, in terms of mean impacts, the WPRS treatment does what it is
intended to do. It shortens the duration of UI claims, reduces total benefits paid, and raises
earnings. 24
The reductions in weeks paid and amount of benefits paid, however, give conflicting
estimates of the magnitude of the treatment effect. The mean weekly benefit payment is
approximately $168, which suggests that a 2.2 week reduction in weeks paid should reduce the
amount paid by about $370. In contrast, a savings of $143 suggests a reduction of only 0.85 in
weeks paid. This latter estimate is similar to estimates from other programs in the existing
literature; see Meyer (1995). We examine this apparent discrepancy in detail in the Appendix.

24

We wondered if the impact of treatment might diminish over calendar time as later cohorts of claimants learned
about the relatively modest time commitment that the program usually requires. We found, however, no systematic
pattern over time.

18
In short, we find evidence of more repeat UI spells in the treatment group. Our evidence
suggests that for some of these repeat spells, the benefits paid variable was updated in the
administrative records to reflect the second spell but the weeks paid variable was not. This
finding suggests an upward bias in our impact on weeks paid. As a whole, the evidence
presented in the Appendix suggests that the weeks paid impact estimates in Table 2 may have a
modest upward bias.
Column (2) presents estimates obtained using the alternative weighting scheme described
in Section 4.3. Under the common effect assumption, these estimates, along with those in
column (1), represent alternative consistent estimates of all three parameters of interest. In this
context, comparing the two sets of estimates gives a sense of the sensitivity of the substantive
findings to alternative weighting schemes. Under the assumption that the effects of treatment
vary among individuals, however, the estimates in column (2) represent consistent estimates of
the LATE parameter defined in Section 4.2, while the estimates in column (1) do not correspond
to any of our parameters. In this case, the differences across columns result from estimating
different parameters, rather than from estimating the same parameter in different ways.
Turning now to the estimates themselves, the two estimates for the weeks paid measure
are virtually identical at about two weeks. For the amount paid measure, however, the LATE
estimate is lower at -$81.94. In contrast, the LATE earnings impact estimate of $1,600 exceeds
the corresponding unweighted estimate. Although the point estimates differ, the 95 percent
confidence interval of the unweighted estimates contain all of the corresponding LATE
estimates in column (2). Thus, while it is conceptually important to distinguish between these
estimates, in this application (though perhaps not in others) it does not make a statistically
significant difference.

19
In what follows, we present only unweighted estimates. We do so for three reasons.
First, they are the simplest to construct and discuss. Second, in a common effects world the
unweighted estimates are the most efficient. Third, and most importantly, in all cases the same
substantive conclusions result from using the unweighted estimates and the weighting scheme
corresponding to the LATE parameter. A complete set of tables constructed using the LATE
weighting scheme is available from the authors upon request.
5.2 Putting the Aggregate Estimates in Perspective
To put these estimated impacts into perspective, consider the estimates from the UI bonus
experiments that Woodbury and Spiegelman (1987) present. They estimate that a $500 bonus to
UI claimants who found a job within 11 weeks resulted in a reduction in the duration of UI spells
of about 1.1 weeks. The earnings of those offered a bonus were comparable to the earnings of
those not offered a bonus. Thus, relative to the Illinois bonus experiment, the Kentucky WPRS
appears to have had a substantial impact on claimants. This may reflect the fact that claimants
have until week 11 to find alternative employment under the Illinois bonus, but to avoid
reemployment services under WPRS claimants must find a job within the first few weeks of their
unemployment spell. The WPRS program has the further advantage that it is unlikely to increase
the UI take-up rate.
The WPRS impacts reported here also tend to be larger than those from experimental
evaluations of job search assistance programs for UI claimants summarized in Meyer (1995). 25
Most of these programs (see his Tables 5A and 5B) have estimated impacts equal to or less than
one week of benefit receipt. Decker, Freeman, and Klepinger (2000) analyze the recent Job
Search Assistance (JSA) experiment, which used profiling to assign workers to job search
assistance in Washington, DC, and Florida. They find that structured job search assistance in

20
Washington lowered the number of weeks receiving benefits by 1.13 weeks and reduced
payments by $182, while the impacts in Florida were -0.41 weeks and $39, respectively. The
larger impacts we find here are consistent with the somewhat more intensive employment and
training services being offered, which presumably raise the cost of continued UI receipt for those
who do not value them and raise the benefits of service receipt for those who do.
It is interesting to consider the costs and benefits of the profiling program from the point
of view of the UI system. Our estimates from column (1) of Table 2 indicate that treated
claimants receive $143 less in benefits than untreated claimants. We can compare these average
benefits with the average costs per treated claimant in the Kentucky UI system. To construct the
average costs per treated claimant, we use data on the average hours spent per week on profiling
in each of the 28 local offices and the state UI office, the average compensation per hour for
employees of the Kentucky Department for Employment Services, the annual cost of the contract
with CBER at the University of Kentucky to maintain the profiling model and data system, and
the number of treated claimants in the first 86 weeks of profiling. 26 These costs sum to $11.93 per
treated claimant. Even if one adds approximately $0.5 million in start-up costs and initial model
development and spreads them over the treated claimants from the first 86 weeks of profiling, the
costs are still only $22.35 per recipient. Thus, the profiling system appears to save the UI
program a substantial amount of money. 27

5.3 What if there Was No Random Assignment?
In the spirit of LaLonde (1986), Heckman and Hotz (1989), Heckman, Ichimura, Smith, and
Todd (1998) and others we consider whether a simple nonexperimental estimator can replicate

25

See Corson, Long, and Nicholson (1985), Anderson, Corson, and Decker (1991) and Johnson and Klepinger
(1994) for analyses of the individual job search experiments.
26
These data were provided by Ted Pilcher of the Kentucky DES.
27
The costs shown here do include short-term training provided by UI staff but do not include the cost of long-term
training referrals to outside providers. A full cost-benefit analysis would include these additional costs. A cost-

21
our experimental estimates. Using data on all claimants –both treated and untreated –during
our experiment, we estimate equation (3) including a treatment dummy along with variables for
each claimant's race, sex, age, tenure at last job, experience, education, month and year of filing a
claim and the region of residence within Kentucky. We estimate the model with and without
dummy variables for each profiling score. This econometric model assumes a common effect
world and that any selection into treatment depends linearly on the observable characteristics
included in the model. Black and Smith (2001) discuss this point in detail and explore the ability
of various nonexperimental estimators to replicate the experimental estimates in Table 2.
For the weeks paid measure, the regression estimates with and without the profiling score
dummies show reductions of 2.4 and 2.0 weeks, respectively. These estimates closely resemble
those in Table 2. For the amount of benefits received, we estimate a $66 reduction in benefits
paid when using the profiling score dummies, and a $240 increase without them. Finally, for
annual earnings, we obtain an impact estimate of about $350 without the profiling score controls,
but only $82 with them.
Dickinson, Kreutzer, and Decker (1997) evaluate the WPRS using nonexperimental
methods for three states: Delaware, Kentucky, and New Jersey. Like ours, their estimators
depend on the assumption of linear selection on observables. For Kentucky, they find that the
program reduced weeks of benefit receipt by 0.72, reduced benefits paid by $96 and had no
impact on earnings. Overall, both our estimates and those from Dickinson, Kreutzer and Decker
(1997) suggest that simple nonexperimental estimators do not do a very good job of replicating
the experimental impact estimates, which is consistent with the usual findings in the literature.

benefit analysis from the standpoint of society (rather than of the UI system) would also include the increased
earnings of the treated claimants and some measure of the value of their foregone leisure.

22
5.4 The Effect of Treatment Over Time
Figure 2 displays hazard rates for leaving UI for the experimental treatment and control groups. 28
It documents a large impact of treatment after receipt of the letter notifying claimants of their
obligation to receive reemployment services. About 13 percent of the treatment group exits after
the first two weeks but only about four percent of the control group exits. Subsequently, the
hazard rate of the treatment group is almost always higher than that of the control group,
although the difference is statistically significant only a couple of times. We may use the hazard
function estimates to calculate the survivor function. The maximum difference between the
treatment and control group survivor functions is 0.11, which is achieved in week 12. The
difference after just two weeks is 0.083 or about 75 percent of the maximum difference.
That the exit hazard in the treatment group continues to lie above that for the control
group for most of the eligibility period is consistent with a positive impact of employment and
training services on those who receive them. The latter explanation is consistent with the
evidence of modest but detectable impacts in the AFDC work/welfare experiments documented
in Gueron and Pauly (1991). Alternatively, it is possible that persons with low hazard rates in the
treatment group exit UI in the first few weeks at a higher rate than similar persons in the control
group.
In Figures 3 and 4, we graph mean earnings and employment by quarter after the start of
the UI spell for the treatment and control groups. The earnings estimates illustrate the impact of
early exit from unemployment in the treatment group. In the first quarter, treatment group
members average $525 more in earnings than control group members, indicating that about half
of the earnings gain occurs in the first quarter. In the second quarter the earnings impact is about

28

Parameter estimates are presented in Appendix Table B1 of Black, Smith, Berger, and Noel (1999). Most benefits
are paid bi-weekly. Technically, these data are not true hazards because we do not observe whether the weeks of
benefit receipt are consecutive. Rather, they represent counts of the number of weeks within the benefit year that a

23
$344. By the third quarter, the difference, while positive, is no longer statistically significant,
and for subsequent quarters there is virtually no difference in mean earnings. The impact of
treatment on employment – where employment is defined as positive earnings during a quarter –
indicates a substantial increase in the probability of employment in the first quarter, a modest
increase in the second quarter and little effect after that. Only the first quarter effect is
statistically significant. 29
Experimental evaluations of mandatory job search assistance in other contexts report
similar results. Corson and Decker’s (1989) analysis of the New Jersey search experiments and
Johnson and Klepinger’s (1994) analysis of the Washington search experiment both find
evidence of early return to work. Decker, Freeman, and Klepinger’s (2000) analysis of JSA
experiments in Washington, DC, and Florida also find sharp increases in the hazard rate in the
second and third weeks of the JSA program. Dolton and O’Neill’s (1996) experimental
examination of the Restart component of Britain's UI system parallels our findings on a different
dimension. After receiving benefits for six consecutive months, the Restart program requires
recipients to participate in an interview with a case worker. Dolton and O’Neill (1996) document
a sharp spike in the hazard rate of the treatment group relative to the control group when
claimants receive notice of the interview. Johnson and Klepinger (1991, Table 4) find a similar
spike in the UI exit hazard in response to a letter notifying the recipient of an eligibility review
interview in the Washington Alternative Work Search Experiment.
Our results are consistent with the idea that the WPRS system lowers the worker’s
reservation wage and increases search intensity early in the unemployment spell. A faster return
to employment implies worse matches on average in the treatment group. This in turn implies

claimant receives payments. Over 80 percent of claimants in PTGs, of treated claimants, and of all claimants had
either no interruption or one of two weeks or less.

24
that we should observe treatment group members having more interrupted spells of
unemployment as more of their matches fail to result in stable employment. To test this
prediction, we estimated a linear probability model based on equation (3) with an indicator for
the presence of an interrupted spell as the dependent variable. The results indicate that the
treatment group had a 0.06 higher probability of having an interrupted spell than the control
group (with a p-value of 0.003), which corresponds to about a 36% increase in the number of
interrupted spells. 30 At the same time, the absence of significant earnings impacts in quarters
three through six after the start of the claim indicates that there is no long term diminution in
match quality due to the treatment.
In sum, we have strong evidence that the earnings gains we document result from more
early exits from UI in the experimental treatment group. Most of these exits take place prior to
possible receipt of reemployment services. Instead, they coincide with receipt of the letter
indicating the claimant's obligation to receive services. Earnings are significantly higher in the
first and second quarters after claimants' file their claims, and we find no evidence that claimants
ever suffer substantially reduced earnings through the first six quarters after their claims. This
evidence suggests that the WPRS treatment is an effective tool for reducing the extent of moral
hazard in the UI program.

29

We also consider whether a claimant returned to a previous employer. We find that the treatment group is more
likely to have earnings at the same firm in the quarter before and the quarter after their UI spell compared to control
group, but the difference is not statistically significant.
30
If the WPRS program lowers claimants' reservation wages early in their unemployment spells, then treatment
group members who exited early should have lower earnings than control group members who exit early. To test
this, we interacted the treatment indicator with an indicator for whether or not the claimant exited early -- that is,
within four weeks of the start of the UI claim. We find strong evidence of lower earnings among treatment group
members exiting early compared to control group members who do so. See Black, Smith, Berger, and Noel (1999)
for these estimates.

25
5.5 Are the Treatment Effects “Common Effects?”
Recent work by Heckman, Smith, and Clements (1997) and others emphasizes variation in the
impact of treatment across persons as an important aspect of the evaluation problem. In this
section, we examine variation in the impacts of the WPRS treatment in two ways.
First, we consider variation in impacts as a function of observable characteristics. We
interacted the treatment indicator in equation (3) with a variety of individual characteristics.
Though the point estimates sometimes differed across subgroups, the differences were
statistically significant only in the case of age, where older claimants, surprisingly, had a larger
impact of treatment. 31 In addition to looking at variation as a function of individual
characteristics, we also tested for variation in impacts among the 286 PTGs. The p-values from
F-tests of the null of equal impacts across PTGs (i.e., that βj = β for all j ) are 0.842 for weeks
of benefits paid, 0.706 for amount of benefits paid and 0.823 for annual earnings. Thus, we fail
to reject the null in all three cases. Unfortunately, given the large number of PTGs the sample
size for the each PTG is quite small and the statistical power of our test is limited.
Second, we consider person-specific impacts based on a generalization of the common
effect model. This generalization preserves the property that the ranks of persons in the treated
and untreated distributions are the same, which arises in the common effect model from the fact
that in the population the treatment group outcome distribution is just the control group outcome
distribution shifted by a constant. At the same time, it relaxes the assumption that the size of the
impact is the same for each person. Under this generalization, impact estimates are constructed
by taking differences across quantiles of the treated and untreated outcome distributions. The
difference between the analysis here and that in Heckman, Smith and Clements (1997) is that we
remove the PTG fixed effects from the outcomes prior to differencing across quantiles.

26
Formally, we construct
ˆj
y%1ij = y1ij − µ

(4)

ˆj
y% 0 ij = y0 ij − µ

(5)

where y%1ij ( y% 0ij ) is the outcome for the ith member of the treatment (control) group in the jth
PTG with the PTG fixed-effect removed, y1ij ( y0ij ) is the unadjusted outcome for the ith
member of the treatment (control) group in the jth PTG, and µ̂j is the estimated fixed effect for
the jth PTG. We calculate impacts by running quantile regressions of y% on an intercept and a
treatment indicator. The impact estimate for a given quantile of the y% 0ij distribution is just the
coefficient on the treatment indicator from the corresponding quantile regression. Under the null
hypothesis of a common effect, these impact estimates should not vary over quantiles. Figure 5
plots the estimates. 32
In their analysis of the JTPA program, Heckman, Smith, and Clements (1997) find
reasonably strong support for the common effect model; in their data the estimated impact is
relatively constant across much of the control group outcome distribution. In contrast, we find a
great deal of heterogeneity in the impact of treatment. For weeks of benefits paid the impact
estimates range from 1.1 to 3.7 weeks, for the amount paid the impacts range from about -$400
to $130, and for earnings they range from about $280 to over $1300. Indeed, there are
statistically significant positive and negative estimates of the impact of treatment on the amount
of benefits paid. Thus, this analysis finds little evidence for the common effects model. The
estimated impacts depend strongly on the untreated outcome for all of the variables we examine.

31

These estimates are available on request from the authors. The estimates for age appear in Table 4 of Black,
Smith, Berger and Noel (1999).
32
In Appendix Table B3 of Black, Smith, Berger, and Noel (1999) we report the estimates. Like Heckman, Smith
and Clements (1997), we use quantiles of the outcome distributions, rather than simply matching individuals across
distributions, because the treatment and control groups are of unequal size.

27
The estimated impacts also tell an interesting story. For all three outcome variables, the
impacts are not monotonic in y% 0ij . For the weeks of benefits paid and amount of benefits paid
variables, Figure 5 shows that the impacts of the program are concentrated in the middle of the
control group outcome distribution. The treatment appears to have very little impact on persons
who would otherwise exhaust or come close to exhausting their benefits, but a very large impact
on persons who would otherwise be between the 25th and 75th percentiles in terms of either
outcome. For those expected to have short spells and receive few benefits, there appears to be a
modest impact on weeks of benefits paid but little or no impact on amount of benefits paid.
These findings represent further evidence that allocating the treatment on the basis of the
expected duration of UI benefit receipt may not represent an optimal strategy.
5.6 Estimates of TT When βi = β( X i )
In Section 4.2, we discussed how to construct estimates of the mean impact for populations
broader than that for which we actually have experimental data in the cases where the treatment
effect is a function of covariates, or βi = β( X i ) . Table 3 presents estimates of the mean impact
of treatment on the treated ( TT ) constructed by re-weighting the conditional (on X i )
experimental impact estimates using the distribution of each X i in the treated sample. 33
Table 3 presents impact estimates based on re-weighting. Not surprisingly, our estimates
of the impact depend on the particular X variable used to do the re-weighting. For example, the
mean impact estimates for earnings range from a high of $1,362 to a low of $828. In general,
however, the impact estimates tell the same substantive story as our estimates in Table 2. In no
case do the reweighted estimates based fall outside of the 95 percent confidence bounds of the
estimates in column (1) of Table 2. This is consistent with the fact that we did not find many

28
statistically significant differences in impacts among subgroups. This evidence provides some
support for thinking that our impact estimates provide a guide to the effect of the profiling
treatment for populations broader than just the PTG members in our experimental data.

5.7 Evaluating Profiling as an Allocation Mechanism
In addition to evaluating the impact of the profiling treatment on those assigned to it, we also
briefly consider a different evaluation question: How well does the profiling mechanism allocate
the treatment? 34 If the goal of profiling is to increase the efficiency of treatment allocation then,
assuming that the costs of the treatment do not vary across persons, it should allocate the
treatment to those for whom it has the largest impact. To address this question, we assume that
the individual impacts depend on the profiling score, so that βi = β( Pi ) . If the profiling
mechanism enhances the efficiency of treatment allocation, then the impact of treatment should
increase with the profiling score, as those with higher scores are much more likely to get treated.
Table 4 presents estimates of β( Pi ) for our three outcome variables. To perform this
analysis, we divide claimants into four groups based on their profiling scores: 6-13 (about 26
percent of the treatment group), 14 or 15 (about 20 percent of the treatment group), 16 (about 21
percent of the treatment group) and 17 to 19 (about 33 percent of the treatment group). The
results suggest that the impact varies nonlinearly with the profiling score, but we can reject the
null of equal impacts across profiling score subgroups only for earnings.
The assumption underlying the WPRS is that those with the longest expected UI spells
benefit the most from the profiling treatment. The estimates in Table 4 provide little justification
for this assumption, as there does not appear to be a monotonic relationship between the profiling
score and the impact of treatment. Thus, like the evidence on person-specific impacts in Figure

33

For some variables, the support condition discussed in Section 4.2 comes into play. As a result, we perform the reweighting using the conditional density in the treated population over the region of common support.
34
See Berger, Black and Smith (2000) for an extended discussion of these issues.

29
5, the evidence in Table 4 calls into question the wisdom of using expected UI spell duration
(rather than, say, predicted impacts) as a means of allocating treatment.

6 Conclusion
In this paper, we use unique experimental data to examine the impact of the Worker Profiling
and Reemployment Services (WPRS) initiative. Our experimental data are for persons in
marginal profiling groups – that is, persons whose expected UI spells are just long enough to put
them in the group required to receive reemployment services in return for continued receipt of
benefits. This design, called a tie-breaking experiment by Thistlethwaite and Campbell (1960),
allows the introduction of random assignment without major program disruption and without
denying services to those most in need. In so doing, it may reduce both line worker resistance to
random assignment and the negative publicity sometimes associated with random assignment
experiments in the social services.
For this group, we find that random assignment to the WPRS treatment results in a 2.2
week reduction in benefit receipt relative to the control group. This represents a reduction in
mean benefits payments of slightly over $143 per recipient. In addition, the experimental
treatment group had significantly higher earnings in the year after the start of their UI claim. This
earnings difference arises almost entirely from higher earnings in the first two quarters after the
start of the claim. This suggests that earnings gains are due primarily to the earlier return to work
of some treatment group members rather than due to higher wages conditional on employment.
We find no evidence that the earnings of the treatment group are lower through the first six
quarters after the unemployment spell, suggesting that the program does not have a strong
adverse impact on job-match quality.
The reduction in the length of recipiency in the treatment group is largely accomplished
by early exits from UI. Many of these early exits coincide in time with the letters sent out to

30
treatment group members to notify them of their obligations under the program. These
findings suggest that the gains from the program result in large part from removing claimants
from the UI rolls who were job ready and had little trouble locating employment. Hence, the
WPRS treatment appears to be successful at reducing the moral hazard associated with the UI
program. Moreover, from the perspective of the UI system, and likely from that of society as
well, it produces a wide excess of benefits over costs.
We find strong evidence against the “common effect” assumption. For the WPRS
program, the estimated treatment effect appears to differ dramatically across quantiles of the
untreated outcome distribution. In particular, for both the weeks of benefits paid and the amount
of benefits paid outcomes, the impact of the program is concentrated in the middle of the
untreated outcome distribution. That is, the program reduces weeks paid and benefits paid for
persons who would otherwise have had moderate values of those variables. It has little effect on
persons who would otherwise exit very early and receive few benefits and on those who would
otherwise exhaust or come close to exhausting their benefits.
Finally, the underlying assumption of the WPRS program is that those with the longest
expected UI spell durations would benefit the most from the requirement that they participate in
reemployment services in order to continue receiving their UI benefits. It is also assumed that
treating these claimants will result in the largest budgetary savings for state UI systems. Our
results provide little justification for either assumption as we do not find a monotonic
relationship between the profiling score and the impact of treatment. If the goal of profiling is to
allocate the treatment to those claimants with the largest expected impact from it, or to save the
state UI system the most money, then our findings call into question the wisdom of using the
expected benefit duration as a means allocating treatment. They also suggest the value of further
thought and study before extending profiling to other programs.

31

7 Appendix
We noted in Section 5.1 that the estimated impacts on weeks of benefits paid and on the amount
of benefits paid presented in Table 2 seem inconsistent. The impact on weeks of benefits paid in
Table 2 is constructed using the weeks paid variable recorded in the UI administrative data. In
this appendix, we compare unweighted impact estimates obtained using the weeks paid variable
with alternative estimates based on a measure of weeks paid constructed indirectly from other
elements of the administrative data. We construct this alternative measure, which we call
“imputed weeks of benefits paid” by dividing the total benefits paid variable by the weekly
benefit level variable. Because the weekly benefit amount may change over a spell, this measure
may contain some error, but it provides a useful check on the weeks paid variable.
The weeks paid variable and the imputed weeks paid variable are highly correlated
(0.884), but the correlation is higher for the control group (0.947) than for the treatment group
(0.849). On closer examination, we found that most of the disagreements occurred for treatment
group members with four or fewer weeks paid (using the weeks paid variable), where a
disagreement occurs when imputed weeks paid exceed the weeks paid variable by at least 1.5
weeks. In Table A1, we provide a breakdown of whether or not the weeks paid and imputed
weeks paid variables disagree by whether or not the claimant exited early. Among those who did
not exit early, we find only three disagreements, two in the treatment group and one in the
control group. Among those who exit early, the two measures of weeks paid differ for only 2 of
the 105 claimants in the control group but for 116 of the 290 claimants in the treatment group.
Using the information in the administrative data, we can calculate the elapsed calendar
time from the first week each claimant received benefits to the last week. If the elapsed calendar
time exceeds the imputed weeks paid by two weeks or more, we assume that there was an
interruption in the spell. That is, we assume the claimant had a spell of UI receipt, followed by a

32
spell of non-receipt (presumably due to employment) followed by a second spell of UI receipt
within the benefit year. For the sample of all early exits, the median difference between elapsed
calendar time and imputed weeks paid is 17 weeks. Among the early exits, 66 claimants – 2 in
the control group and 64 in the treatment group – appear to have an interrupted spell. In these
cases, we believe that the weeks of benefits paid variable was not updated to reflect the second
spell of UI receipt while the amount of benefits paid variable was. This is consistent with the
fact that the latter, but not the former, plays an important role in the UI administrative system.
This interpretation helps to account for the apparent inconsistency in the estimates in Table 2. It
also leads to a somewhat different interpretation of the spike in the hazard at week 2 in Figure 1,
as it suggests that many of those who leave early in response to the “threat” of reemployment
services end up returning to UI after a spell of employment.
Of course, our measure of interrupted spells depends on correct reporting of the first and
last weeks paid variables. For 16 recipients, we have doubts about the accuracy of these data
elements. Although they have no interruptions according to our measure, each has either a value
of weeks paid in excess of 13 weeks combined with positive earnings in the first quarter or
imputed earnings (calculated by dividing quarterly earnings by 13 minus the value of the
imputed weeks paid variable) in the first quarter in excess of $2,000 a week. We believe that
these observations probably have interrupted spells combined with coding errors in the first or
last week paid variables. For the remaining 35 observations where the weeks paid and imputed
weeks paid variables disagree we find no evidence of an interrupted spell and have no
explanation for the disagreement.
The impact of treatment on earnings provides an indirect means of assessing the impact
of treatment on the number of weeks of employment and thereby on the number of weeks of
benefits paid. With an estimate of weekly earnings, we can use the estimated earnings impacts to

33
estimate the impact of treatment on the number of weeks of employment. To estimate mean
weekly earnings, we use earnings in the quarter before the start of the UI spell, which is the
quarter with the highest earnings. To be conservative, we exclude observations with less than
$2,500 in quarterly earnings and estimate weekly earnings by dividing mean quarterly earnings
by 12 rather than 13 weeks, which represents an implicit unemployment rate during the quarter
of about 7.7 percent. Even with these restrictions, the mean weekly earnings of claimants is only
$523 ($6,277/12). This suggests that, if the impact of treatment is independent of earnings (a
strong assumption), then the WPRS treatment increases weeks of employment by about 2.02
weeks. This estimate almost certainly understates the true effect because we have very likely
overestimated the weekly earnings of claimants. Nevertheless, this estimate is surprisingly
similar to the estimates for weeks of benefits paid in Table 2.
In addition to measurement problems, the seeming inconsistency in the estimated impacts
in Table 2 could be due to a correlation between the impact of treatment and the benefit level. If
the treatment has a stronger effect, in terms of reductions in weeks of benefits paid, on persons
with low benefit levels, this would account for the seeming inconsistency. We examined this
relationship and found that it exhibited a U-shaped pattern. Thus, while impacts and benefits do
not appear to be independent, neither does this relationship account for the seeming
inconsistency.
Taking all of the evidence into account suggests that there may be some upward bias in
the estimates of the impact of the WPRS treatment on weeks of benefits paid reported in Table 2.
Thus, this evidence constitutes an important reminder that administrative data are not a panacea
and must be used with care. While they avoid some problems associated with survey data, such
as non-response, administrative data often have unique problems of their own.

34

References
Anderson, Patricia. 1992. “Time-Varying Effects of Recall Expectation, a Reemployment Bonus,
and Job Counseling on Unemployment Durations.” Journal of Labor Economics. 10(1):
99-115.
Anderson, Patricia, Walter Corson, and Paul Decker. 1991. “The New Jersey Unemployment
Insurance Reemployment Demonstration Project: Follow-up Report.” Unemployment
Insurance Occasional Paper 91-1. U.S. Department of Labor, Employment and Training
Administration, Unemployment Services.
Anderson, Patricia and Bruce Meyer. 1997. “Unemployment Insurance Takeup Rates and the
After-Tax Value of Benefits.” Quarterly Journal of Economics. 112(3): 913-937.
Angrist, Joshua D. and Alan B. Krueger. 1999. “Empirical Strategies in Labor Economics” in
Handbook of Labor Economics, Volume 3A, eds. Orley Ashenfelter and David Card.
Amsterdam: North-Holland. 1277-1366.
Ashenfelter, Orley, David Ashmore, and Olivier Deschênes. 1999. “Do Unemployment
Insurance Recipients Actively Seek Work? Randomized Trials of Four US States.”
National Bureau of Economic Research Working Paper #6982.
Barron, John M. and Wesley Mellow. 1979. “Search Effort in the Labor Market.” Journal of
Human Resources. 14(3): 427-41.
Berger, Mark C., Dan A. Black, Amitabh Chandra and Steven N. Allen. 1997. “Kentucky's
Statistical Model of Worker Profiling for Unemployment Insurance.” Kentucky Journal
of Economics and Business. 16: 1-18.
Berger, Mark C., Dan A. Black and Jeffrey A. Smith. 2000. “Evaluating Profiling as a Means of
Allocating Government Services.” in Econometric Evaluation of Labour Market Policies,
eds. Michael Lechner and Friedhelm Pfeiffer. Heidelberg: Physica-Verlag. 59-84.
Besley, Timothy and Stephen Coate. 1992. “Workfare Versus Welfare: Incentive Arguments for
Work Requirements in Poverty-Alleviation Programs.” American Economic Review.
81(2): 249-261
Black, Dan A., Terra McKinnish and Jeffrey A. Smith. 2001. “Weight a Moment: Identification
in Natural Experiments” Unpublished manuscript, Syracuse University.
Black, Dan A. and Jeffrey A. Smith. 2001. “Employment Subsidies and Leisure Taxes in the
Design of Transfer Programs.” Unpublished manuscript, University of Maryland.
Black, Dan A., Jeffrey A. Smith, Mark C. Berger, and Brett J. Noel, 1999. “Is the Threat of
Training More Effective than Training Itself? Experimental Evidence from the UI
System” University of Western Ontario Research Report #9913.

35
Black, Dan A. and Jeffrey A. Smith. 2001. “A Comparison of Econometric and Experimental
Evaluation Using Cross-Section, Panel Data, and Matching Models.” Unpublished
manuscript, University of Maryland.
Blakemore, John and Jane Welsh. 1983. “Selective Incapacitation: Sentencing According to
Risk.” Crime & Delinquency. 29(4): 504-528.
Blank, Rebecca and David Card. 1991. “Recent Trends in Insured and Uninsured
Unemployment: Is There an Explanation?” Quarterly Journal of Economics. 106(4):
1157-90.
Campbell, Donald T. “Reforms as Experiments.” 1969. American Psychologist. 24: 409-29.
Card, David and Phillip B. Levine. 2000. “Extended Benefits and the Duration of UI Spells:
Evidence from the New Jersey Extended Benefit Program.” Journal of Public Economics
78:1-2, 107-38.
Coate, Stephen, Stephen Johnson and Richard Zeckhauser. 1994. “Pecuniary Redistribution
through In-Kind Programs.” Journal of Public Economics. 55(1): 19-40.
Corson, Walter, and Paul T. Decker. 1989. “The Impact of Reemployment Services on
Unemployment Insurance Benefits: Findings from the New Jersey Unemployment
Insurance Reemployment Demonstration.” Unpublished manuscript, Mathematica Policy
Research.
Corson, Walter, David Long, and Walter Nicholson. 1985. “Evaluation of the Charleston
Claimant Placement and Work Test Demonstration.” Unemployment Insurance
Occasional Paper 85-2. US Department of Labor, Employment and Training
Administration, Unemployment Services.
Decker, Paul T. 1994. “The Impact of Reemployment Bonuses on Insured Unemployment in the
New Jersey and Illinois Reemployment Bonus Experiments.” Journal of Human
Resources. 29(3): 718-741.
Decker, Paul T. and Christopher J. O'Leary. 1995. “Evaluating Pooled Evidence from the
Reemployment Bonus Experiments.” Journal of Human Resources. 30(3): 534-550.
Decker, Paul T., Lance Freeman, and Daniel H. Klepinger, 2000. “Assisting Unemployment
Insurance Claimants: The One-Year Impacts of the Job Search Assistance
Demonstration” Unpublished Manuscript, Mathematica Policy Research.
Dickinson, Katherine P., Suzanne D. Kreutzer, and Paul T. Decker, 1997. “Evaluation of Worker
Profiling and Reemployment Services Systems.” Unpublished manuscript, Social Policy
Research Associates.
Dolton, Peter and Donal O'Neill. 1996. “Unemployment Duration and the Restart Effect: Some
Experimental Evidence.” Economic Journal. 106(435): 387-400.

36
Ehrenberg, Ronald and Ronald Oaxaca. 1976. “Unemployment Insurance, Duration of
Unemployment and Subsequent Wage Gain.” American Economic Review. 66(5): 754766.
Gueron, Judith and Edward Pauly. 1991. From Welfare to Work. New York, NY: Russell Sage
Foundation.
Heckman, James and V. Joseph Hotz. 1989. “Choosing Among Alternative Nonexperimental
Methods for Estimating the Impact of Social Programs: The Case of Manpower
Training.” Journal of the American Statistical Association. 84(408): 862-874.
Heckman, James J., Hidehiko Ichimura, Jeffrey A. Smith, and Petra Todd. 1998. “Characterizing
Selection Bias Using Experimental Data.” Econometrica. 66(5): 1017-1098.
Heckman, James J., Robert J. LaLonde and Jeffrey A. Smith. 1999. “The Economics and
Econometrics of Active Labor Market Programs.” in Handbook of Labor Economics,
Volume 3A, eds. Orley Ashenfelter and David Card. Amsterdam: North-Holland. 18652097.
Heckman, James J., Jeffrey A. Smith, and Nancy Clements. 1997. “Making the Most Out Of
Programme Evaluations and Social Experiments: Accounting for Heterogeneity in
Programme Impacts.” Review of Economic Studies. 64(4): 487-36
Heckman, James J., and Jeffrey A. Smith. 1995. “Assessing the Case for Social Experiments.”
Journal of Economic Perspectives. 9(2): 85-110.
Heckman, James J., and Jeffrey A. Smith. 1998. “Evaluating the Welfare State,” in Econometrics
and Economic Theory in the 20th Century: The Ragnar Frisch Centennial, ed. Steiner
Strom. Cambridge, UK: Cambridge University Press for Econometric Society
Monograph Series. 241-318.
Hotz, V. Joseph and Karl Scholz. 2000. “Measuring Employment and Income Outcomes for
Low-Income Populations with Administrative and Survey Data.” Unpublished
manuscript, UCLA.
Imbens, Guido and Joshua Angrist. 1994. “Identification and Estimation of Local Average
Treatment Effects.” Econometrica. 62(2): 467-76.
Johnson, Terry R. and Daniel H. Klepinger. 1991. “Evaluation of the Impacts of the Washington
Alternative Work Search Experiment.” Unemployment Insurance Occasional Paper 91-4.
U.S. Department of Labor, Employment and Training Administration, Unemployment
Services.
Johnson, Terry R. and Daniel H. Klepinger. 1994. “Experimental Evidence on Unemployment
Insurance Work-Search Policies.” Journal of Human Resources. 29: 695-717.

37
Katz, Lawrence and Bruce Meyer. 1990. “The Impact of the Potential Duration of
Unemployment Benefits on the Duration of Unemployment.” Journal of Public
Economics. 41(1): 45-72.
Kornfeld, Robert and Howard Bloom. 1999. “Measuring Program Impacts on Earnings and
Employment: Do Unemployment Insurance Wage Reports from Employers Agree with
Surveys of Individuals?” Journal of Labor Economics. 17(1): 168-197.
LaLonde, Robert, 1986. “Evaluating the Econometric Evaluation of Training Programs with
Experimental Data.” American Economic Review. 76(4): 604-20.
Meyer, Bruce D. 1990. “Unemployment Insurance and Unemployment Spells.” Econometrica.
58(4): 757-782.
Meyer, Bruce D. 1995. “Lessons from the US Unemployment Insurance Experiments.” Journal
of Economic Literature. 33(1): 91-131.
Moffitt, Robert. 1985. “Unemployment Insurance and the Distribution of Unemployment
Spells.” Journal of Econometrics. 28: 85-101.
Noel, Brett J. 1998. Two Essays on Unemployment Insurance. Unpublished dissertation,
University of Kentucky.
O'Leary, Christopher J., Paul Decker and Stephen A. Wandner. 1998. “Reemployment Bonuses
and Profiling.” W.E. Upjohn Institute Staff Working Paper #98-51.
St. Louis, Robert D., Paul L. Burgess, and Jerry L. Kingston. 1986. “Reported vs. Actual Job
Search by Unemployment Insurance Claimants.” Journal of Human Resources. 21(1):
92-117.
Thistlethwaite, D. L. and D. T. Campbell. 1960. “Regression Discontinuity Analysis: An
Alternative to ex post facto Experiment.” Journal of Educational Psychology. 51: 309-17.
U.S. Department of Labor. 1999. “Evaluation of Worker Profiling and Reemployment Services
Policy Workgroup: Final Report and Recommendations.” Employment and Training
Administration.
Woodbury, Stephen and Robert Spiegelman. 1987. “Bonuses to Workers and Employers to
Reduce Unemployment: Randomized Trials in Illinois.” American Economic Review.
77(4): 513-530.

38

Table 1: Demographic Characteristics of Treatment and Control Groups:
Kentucky WPRS Experiment, October 1994 to June 1996
Control Group

Treatment
Group

P-values for
tests of
differences
in means

Treated
Population

Age

37.0
(10.9)

37.1
(11.1)

0.717

37.4
(11.2)

Years of schooling

12.3
(2.10)

12.6
(2.14)

0.221

12.4
(2.06)

White male

0.564

0.518

0.095

0.517

White female

0.352

0.372

0.060

0.398

Nonwhite male

0.040

0.055

0.433

0.042

Nonwhite female

0.044

0.055

0.691

0.043

Earnings in year before
claim

$19,759
(13,678)

$19,047
(13,636)

0.666

$19,168
(14,588)

Weekly benefit amount

$168.35
(68.90)

$167.36
(64.70)

0.747

$173.11
(64.77)

745

1,236

---

48,002

N

Source: Authors’ calculations from the Kentucky WPRS Experiment. Standard deviations are given in parentheses.
Means are unweighted. Tests for differences in means are for the treatment and control groups and are based on a
linear regression that also conditions on the 286 PTGs. The treated population consists of all claimants assigned to
the profiling treatment, not just those in the PTGs. All claimants are eligible for 26 weeks of UI benefits.

39

Table 2: Impact of Treatment on Duration of Benefits and Earnings: Kentucky
WPRS Experiment, October 1994 to June 1996
Outcome Measures

Impact of Treatment
Unweighted

Number of weeks receiving
UI benefits

-2.241
(0.509)
[0.000]

Treatment on the Treated in
the PTGs (LATE)
-2.045
(0.411)
[0.000]

UI benefits received

-143.18
(100.3)
[0.077]

-81.44
(81.6)
[0.159]

Earnings in the year after
the start of the UI claim

1,054.32
(588.0)
[0.037]

1,599.99
(475.2)
[0.001]

Earnings in 1 st quarter

525.58
(192.8)
[0.003]

684.31
(144.4)
[0.000]

Earnings in 2nd quarter

344.05
(161.4)
[0.017]

463.51
(128.9)
[0.000]

Earnings in 3rd quarter

220.67
(181.5)
[0.112]

397.73
(145.7)
[0.003]

Earnings in 4th quarter

-35.99
(176.1)
[0.582]

54.44
(142.1)
[0.351]

1,981

1,981

N

Source: Authors’ calculations from the Kentucky WPRS Experiment. Each of the regressions controls for the
Profiling Tie Group (PTG) of the recipients. There are 745 claimants in the control group, 1,236 claimants in the
treatment group and 286 PTGs. Standard errors are in parentheses and p-values from one-tailed tests are in brackets.

40

Table 3: Estimates of the Impact of Treatment on the Treated Based on the
Assumption that βi = β( X i ) :
Kentucky WPRS Experiment, October 1994 to June 1996
Weights

Unweighted
Profiling score weights*
Local office weights*
Time weights*

Age category weights

Education category weights

Sex weights

Race category weights

N

Number of weeks
receiving UI
benefits

UI benefits
received

Earnings in year
after claim

-2.241
(.509)
[0.000]
-2.239
(0.547)
[0.000]
-2.424
(0.560)
[0.000]
-2.327
(0.506)
[0.000]

-$143.18
(100.3)
[0.077]
-$86.67
(109.55)
[0.215]
-$128.91
(110.44)
[0.122]
-$150.48
(99.46)
[0.065]

$1,054.32
(588.0)
[0.037]
$1,362.19
(656.87)
[0.019]
$1,250.81
(644.75)
[0.027]
$1,139.57
(591.82)
[0.027]

-2.316
(0.502)
[0.000]
-2.276
(0.500)
[0.000]
-2.284
(0.509)
[0.000]
-1.979
(0.508)
[0.000]

-$154.11
(100.12)
[0.062]
-$151.20
(98.52)
[0.063]
-$154.95
(100.66)
[0.062]
-$140.81
(101.71)
[0.083]

$828.21
(586.82)
[0.079]
$1,070.49
(563.82)
[0.029]
$1,036.86
(596.27)
[0.041]
$989.40
(597.99)
[0.049]

1981

1981

1981

Source: Authors’ calculations from the Kentucky WPRS Experiment. Each of the regressions controls for the
Profiling Ties Group (PTG) of the recipients. Standard errors are given in parentheses and p-values from one-tailed
tests are given in brackets. An asterisk denotes that the support of the experimental sample is smaller than the
support in the treated sample. In these cases, we integrate using equation (2) only over the region of common
support. The categories are as follows: for profiling score, each individual score from 6 to 19; for time, each
calendar week; for education, less than high school, high school graduate, more than high school; for age, under 35,
35 to 49 and 50 and above; for race, white and nonwhite.

41

Table 4: Estimates of the Impact of Treatment on the Treated Under the
Assumption that the Impact is a Function of the Profiling Score ( b i = b ( Pi ) ):
Kentucky WPRS Experiment, October 1994 to June 1996

Profiling score between
6 and 13
Profiling score between
14 and 15
Profiling score of 16

Profiling score between
17 and 19

P-value for test of equal impacts
across approximate profiling score
quartiles

Weeks paid

Amount paid

Annual earnings

-2.238
(0.913)
[0.007]
-1.891
(1.050)
[0.036]
-3.057
(1.102)
[0.003]
-1.861
(1.039)
[0.037]

-$270.08
(179.74)
[0.067]
-$14.42
(206.77)
[0.472]
-$465.73
(216.94)
[0.016]
$182.09
(204.60)
[0.813]

$939.51
(1052.05)
[0.186]
-$1,257.14
(1,210.25)
[0.851]
$4,175.83
(1,269.76)
[0.001]
$689.71
(1,197.55)
[0.283]

0.851

0.132

0.021

Source: Authors’ calculations from the Kentucky WPRS Experiment. Each of the regressions controls for the
Profiling Tie Group (PTG) of the recipients. There are 745 claimants in the control group, 1,236 claimants in the
treatment group and 286 PTGs. The approximate quartiles for the profiling scores are scores 6 to 13 (515 members),
scores 14 and 15 (390 members), score 16 (424 members), and scores 17 to 19 (652 members).

42

Table A1: A Comparison of Weeks Paid and Imputed Weeks Paid: Kentucky
WPRS Experiment, October 1994 to June 1996

Weeks of benefits paid is greater than 4 weeks
Weeks paid and imputed weeks paid agree
Weeks paid and imputed weeks paid disagree
N

Control
Group

Treatment
Group

639
(99.84%)
1
(0.16%)
640
(100.0%)

943
(99.79%)
2
(0.21%)
945
(100.0%)

103
(98.10%)

174
(60.21%)

2
(1.90%)
0

64
(22.15%)
16
(5.54%)

0

35
(12.11%)

105
(100.0%)

290
(100.0%)

Weeks of benefits paid is less than 5 weeks
Weeks paid and imputed weeks paid agree

Weeks paid and imputed weeks paid disagree
Interrupted spell of benefit recipiency
Apparent interruption of benefit recipiency,
imputed earnings in excess of $2,000 per week
No apparent interruption of benefit recipiency

N

Source: Authors’ calculations from the Kentucky WPRS Experiment.

43

Week

0

Claim filed

1

2

3

4

5

Services end
Letter
received
First check
Orientation
and other
received
services
received;
second
check
received

Figure 1: Timeline for Typical UI Claimant in Kentucky WPRS Program

45
0.140
0.120

Hazard Rate

0.100
0.080
0.060
0.040
0.020
0.000
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Week

Control Group

Treatment Group

Figure 2: Hazard Functions of the Treatment and Control Groups,
Kentucky WPRS Experiment, October 1994 to June 1996
Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the fivepercent level. The parameter estimates used to construct the graph appear in Table B1 of Black, Smith, Berger, and
Noel (1999).

45
6000.000

5000.000

Earnings

4000.000

3000.000

2000.000

1000.000

0.000
-4

-3

-2

-1

1

2

3

4

5

6

Quarter
Control Group

Treatment Group

Figure 3: Earnings of the Treatment and Control Groups,
Kentucky WPRS Experiment, October 1994 to June 1996
Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the fivepercent level. The parameter estimates used to construct the graph appear in Table B2 of Black, Smith, Berger, and
Noel (1999).

46
1.000
0.900

Fraction Employed

0.800
0.700
0.600
0.500
0.400
0.300
0.200
0.100
0.000
-4

-3

-2

-1

1

2

3

4

5

6

Quarter
Control Group

Treatment Group

Figure 4: Employment of the Treatment and Control Groups,
Kentucky WPRS Experiment, October 1994 to June 1996
Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the fivepercent level. The parameter estimates used to construct the graph appear in Table B2 of Black, Smith, Berger, and
Noel (1999).

1600

47

Impact on Earnings

1400
-1

-2

-3

1200
1000
800
600
400
200

-4

0
0

20

40

60

80

100

0

20

40

Percentile

60

80

Percentile

300
200
Impact on Amount Paid

Impact on Weeks Paid

0

100
0
-100
-200
-300
-400
-500
0

20

40

60

80

100

Percentile

Figure 5: Impact of Treatment on Weeks Paid, Benefits Paid, and Earnings at Quantiles of the Untreated
Outcome Distribution, Kentucky WPRS Experiment, October 1994 to June 1996
Notes: Authors’ calculation from Kentucky WPRS Experiment. Triangles denote significant differences at the five-percent level. The parameter estimates used
to construct the graph appear in Table B3 of Black, Smith, Berger and Noel (1999).

100

CABINET FOR HUMAN RESOURCES
COMMONWEALTH OF KENTUCKY
FRANKFORT 40621

DEPARTMENT FOR EMPLOYMENT SERVICES
DATE:
SS #:
LO #:

Dear Claimant:
You have been identified as a dislocated worker and selected under the UI Claimant Profiling
Program to receive job search assistance services. You are obligated under the law to
participate. Failure to report or participate in reemployment services without justifiable cause
may result in denial of your unemployment insurance benefits
This program is designed to provide job search assistance services to those UI claimants
identified as being most likely to need assistance in finding new employment. We will assess
your needs and work with you to decide which services may increase your chances of finding
a good job. Services may include counseling, job search workshops, testing, job referral and
placement, or if needed, referral to more intensive services, such as training.
If you are presently enrolled in training, have recently received job search services, or are
engaged in any job search services that you believe may exempt you from participation in this
program, bring all documents or relevant information concerning your participation with you
when you report to the local office.
You are REQUIRED BY LAW, KRS 341 .350(2)(b), to attend the Orientation Session at the
place, date and time specified below:
PLACE:

DATE:
TIME:
You may be determined ineligible to receive unemployment insurance benefits for failure to
report to your local office as instructed or failure to participate in required services.

If you are UNABLE TO ATTEND,

Your participation in orientation may be postponed if you have a compelling reason to prevent
you from attending on the date and time stated above, BUT it must be for circumstances
beyond your control. Any postponement will be reported to UI for review of your availability.
BRING THIS LETTER WITH YOU WHEN YOU COME IN.
UI-P-100
(Rev. 09/94)

JOB SERVICE

Exhibit 1

