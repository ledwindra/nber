NBER WORKING PAPER SERIES

CHILDREN’S SCHOOLING AND PARENTS’ INVESTMENT IN CHILDREN:
EVIDENCE FROM THE HEAD START IMPACT STUDY
Alexander M. Gelber
Adam Isen
Working Paper 17704
http://www.nber.org/papers/w17704

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2011

We thank Jay Bhattacharya, Hanley Chiang, David Cutler, David Deming, Mark Duggan, Olivia Mitchell,
Michael Puma, Dan Sacks, Todd Sinai, Danny Yagan, and seminar participants at Wharton for suggestions.
Gelber acknowledges financial support from the Center for Human Resources, the Risk and Decision
Processes Center, and the Zicklin Center for Business Ethics, all at Wharton. Isen acknowledges financial
support from the Institute of Education Sciences, U.S. Department of Education, through Grant #R305B090015
of the U.S. Department of Education. All errors are our own. The views expressed herein are those
of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2011 by Alexander M. Gelber and Adam Isen. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.

Children’s Schooling and Parents’ Investment in Children: Evidence from the Head Start Impact
Study
Alexander M. Gelber and Adam Isen
NBER Working Paper No. 17704
December 2011
JEL No. H31,H52,I21,I28,J13
ABSTRACT
Parents may have important effects on their children, but little work in economics explores whether
children's schooling opportunities crowd out or encourage parents' investment in children. We analyze
data from the Head Start Impact Study, which granted randomly-chosen preschool-aged children the
opportunity to attend Head Start. We find that Head Start causes a substantial increase in parents'
involvement with their children—such as time spent reading to children, math activities, or days spent
with children by fathers who do not live with their children—both during and after the period when
their children are potentially enrolled in Head Start. We discuss a variety of mechanisms that are consistent
with our findings, including a simple model we present in which Head Start impacts parent involvement
in part because parents perceive their involvement to be complementary with child schooling in the
production of child qualities.

Alexander M. Gelber
The Wharton School
University of Pennsylvania
1403 Steinberg-Dietrich Hall
3620 Locust Walk
Philadelphia, PA 19104
and NBER
agelber@nber.org
Adam Isen
University of Pennsylvania
Steinberg-Dietrich Hall #1400
3620 Locust Walk
Philadelphia, PA 19104-6372
isen@wharton.upenn.edu

An online appendix is available at:
http://www.nber.org/data-appendix/w17704

Parent inputs may have important effects on child outcomes (e.g. Gary Becker and
Nigel Tomes 1976; Becker 1981; Becker and Tomes 1986; Petra Todd and Kenneth Wolpin
2003; Bruce Sacerdote 2007).2 In analyzing the return to schooling, it is possible to
distinguish the direct impact that schooling programs have on children from the indirect
impact that is mediated through the effect that schooling has on parent investment in
children. If parents have large impacts on their children, these indirect effects may be
important. A priori, we do not know the sign of these indirect effects: schooling inputs could
crowd out or encourage parent inputs. Furthermore, the degree to which government inputs
cause parent inputs to increase or decrease helps to determine the efficiency of government
expenditure on schooling: many believe that government-provided schooling may supplant
parents’ role to some extent. As Becker and Tomes (1986) write in their theoretical analysis
of crowdout of parent investment by public expenditure: “Compensatory responses of parents
apparently greatly weaken the effects of…some Head Start programs.”3 Moreover, if
investment in children is costly to parents, then estimating the impact of schooling programs
on parents’ investment is relevant to a full welfare analysis of the programs. These questions
are important for understanding the effect of schooling programs on children and the
mechanisms through which these effects operate, but there is little empirical work in
economics on how schooling programs impact parents’ investment in children.4
The Head Start Impact Study (HSIS) represents a promising setting for investigating
these issues in the context of Head Start (HS). HS is a government program that provides

2

Indeed, parenting is often thought to play an important role in explaining differences in child outcomes across
racial and socioeconomic status groups (e.g. Jeanne Brooks-Gunn, Greg Duncan, and Pamela Klebanov 1996),
as well as by gender (Marianne Bertrand and Jessica Pan 2011). Randomized control trials of efforts to involve
parents in children’s lives have often found positive impacts on children, including on children’s cognitive
scores (Chad Nye, Herb Turner, and Jamie Schwartz 2006).
3
Becker and Tomes also write that "Government programs may have effects [on parent behavior] by changing
rates of return on parent investments in children…However, we have emphasized the redistribution effects of
many programs—including Head Start programs…because the redistribution effects are clear, while effects
[due to changing the marginal rate of return] are not clear, even in direction…." By “redistribution effects,”
Becker and Tomes are referring to the compensatory responses of parents that could cause a decrease in parent
investment in response to an increase in child schooling. See also Becker and Tomes (1976).
4
In the education field, concern about the importance of parents has spawned a literature on how to increase
parent involvement (e.g. Joyce Epstein 2011). Perry Preschool, the Abecedarian Project, and the Chicago
Child-Parent Center Program all sought to involve parents and appear to have achieved large gains for lowincome youth (e.g. Flavio Cunha and James Heckman 2010 or Frances Campbell and Craig Ramey 1994). On
the empirical relationship between parent inputs and child endowments, see Anna Aizer and Flavio Cunha
(2011), Christina Paxson and Norbert Schady (2007), Sandra Black, Paul Devereux, and Kjell Salvanes
(forthcoming), or Mark Rosenzweig and Junsen Zhang (2009).

2

preschool to low-income children. Like many schooling programs, one specific goal of HS is
to increase parent involvement with their children. First-time applicants to HS for the fall of
2002 were randomly selected by HSIS for access to HS.5 HSIS followed the children and
their parents for several subsequent years, collecting information on a variety of child and
parent outcomes both during and after the period when children were potentially enrolled in
HS (U.S. Department of Health and Human Services 2010, henceforth HHS 2010). A wide
range of measures of parent involvement in children’s lives are available, including parents’
responses to questions on time spent with children and various parent-child activities, as well
as teachers’ and HSIS interviewers’ reports of parent involvement. By “parent involvement”
we mean activities that parents undertake that require time or effort and directly involve their
children.
We find that in response to children’s HS access, parents are substantially and
statistically significantly more involved with their children along a wide variety of
dimensions, particularly along those dimensions that appear to be investments in child human
capital. For example, parents read to their children more often, and for a longer amount of
time at each sitting, when their children have access to HS than when they do not. Even after
children are no longer attending HS, their parents appear to invest more in them. For
example, fathers not living in the home with their children spend more days visiting their
children when their children had been in HS, even after these children are no longer enrolled
in HS. When we use access to HS as an instrument for HS enrollment, we find that the point
estimates of the mean increase in parent investment in children is 15% of a standard
deviation while children are potentially enrolled in Head Start and 6% of a standard deviation
after they are potentially enrolled. We show that these results are robust to a wide variety of
alternative empirical choices. Teachers and interviewers also report greater parent
involvement in the HS group than in the control group, suggesting that the increase in
measured parent involvement is not simply due to self-reporting by parents. These findings

5

HSIS randomly assigned a sample of 3- and 4-year-old HS applicants either to the “HS group” or to the
control group. The HS group was allowed to enroll in HS at the HS center to which they applied, while the
control group was not granted access to HS at that center (but may have received similar services through other
available programs chosen by their parents—in occasional cases through other HS centers). Even though a
minority of the control group still managed to attend other HS centers, we often refer to those in the treatment
group as those who had “HS access” or “HS eligibility.” A “program” is a contractor with the government that
runs one or more “centers.” A “center” refers to a specific location containing a number of HS classrooms.

3

on parent involvement during and after the experiment constitute the core of the paper. Our
results show that HS is successful in its goal of increasing parent involvement with children.
Intriguingly, we find that across HS programs, those programs that raised children’s
cognitive test scores more also tended to raise parents’ involvement with their children more.
We discuss a variety of mechanisms that are consistent with our findings, including a simple
model we present in which Head Start impacts parent involvement in part because parents
perceive their involvement to be complementary with child schooling in the production of
child qualities.
While there is little attention to the relationship between parent and schooling inputs
in the economics literature, our analysis builds on many important studies that have
empirically examined aspects of HS and its impact on children.6 HHS (2010) investigates
data from the HSIS, focusing primarily on the impact of HS on children’s cognitive and noncognitive test scores. As we describe later, HHS (2010) also investigates certain measures of
parent involvement with their children but finds very limited evidence that parent
involvement was impacted. HSIS collected a rich set of data that are not analyzed in HHS
(2010) but that we analyze in this study; these data show a strong impact of Head Start on a
wide variety of parent involvement outcomes. Relative to HHS (2010), we investigate the
impact of HS on an order of magnitude more parent outcomes; we use several new methods
to analyze the data, including new econometric approaches; we explore the mechanisms
through which the effect on parent involvement may operate; and we place our results in a
possible theoretical context.7
HHS (2010) follows previous work by Janet Currie and Duncan Thomas (1995), who
find that HS improves children’s cognitive scores while they are enrolled in HS but that these
gains fade over time for blacks. Eliana Garces, Thomas, and Currie (2002) find evidence of
long-run impacts of HS on school attainment, earnings, and criminal behavior. Jens Ludwig
6

Jishnu Das, Stefan Dercon, James Habyarimana, Pramila Krishnan, Karthik Muralidharan, and Venkatesh
Sundararaman (2011) examine the relationship between schooling and parent expenditures in the context of
India. Andrew Houtenville and Karen Conway (2008) estimate a production function that includes both
schooling and parent inputs. Fuhua Zhai, Jane Waldfogel, and Jeanne Brooks-Gunn (2011) use nonexperimental variation to examine the effect of HS on the maltreatment of children by parents. Randomized
evaluations of the Even Start family literacy program have found little evidence that it impacted parent
involvement with children (e.g. St. Pierre et al. 1995). HHS (2010) provides an extensive review of literature on
the impact of HS on children.
7
Appendix B describes in detail the differences and small number of similarities between our paper and HHS
(2010).

4

and Douglas Miller (2007) find that HS has persistent positive impacts on children’s future
schooling and mortality. David Deming (2009) also finds long-run effects of HS on
children’s skills.8 It is difficult to reconcile the combination of fade-out of test score gains
with long-run impacts of HS, though similar results have been found in other contexts (e.g.
James J. Heckman, Lena Malofeeva, Rodrigo Pinto, and Peter Savelyev 2010; Raj Chetty et
al. 2011; Susan Dynarski, Joshua Hyman, and Diane Whitmore Schanzenbach 2011);
persistent parent investment could be one mechanism through which the long-run impacts are
mediated.
The paper proceeds as follows. Section I describes the Head Start Impact Study.
Section II lays out the basic empirical approach of the paper. Section III presents our basic
results and various robustness checks. Section IV discusses the results and suggests several
mechanisms that may underlie them. Section V concludes.
I. HS and the Head Start Impact Study
Head Start is a program of the U.S. Department of Health and Human Services that
provides education, health, nutrition, and parent involvement services to low-income children
and their families. In 2009, HS provided services to 904,153 children, 54% of whom were
four years old or older, and 46% of whom were three years old or younger. Services were
provided by 1,591 programs operating 49,200 classrooms. The average per-child
expenditure was $7,600. Eligibility is largely income-based—families typically must earn
less than 130% of the federal poverty level in order to be eligible—though each local
program includes other eligibility criteria, such as child disability status.
During the spring and summer of 2002, eligible first-time 3- and 4-year-old
applicants to HS for the Fall of 2002 were randomly selected by HSIS for access to HS. We
refer to HHS (2010) for a much more detailed description of the experiment, but we briefly
describe several of its main features here. The study selected children from 84 nationally
representative HS programs, corresponding to 353 HS centers. HSIS collected information
on a variety of child and parent outcomes for several subsequent years in both groups. The
“HS group” was allowed to enroll in HS, while the “control group” was not granted access to
HS (but may have received similar services through other available programs chosen by their
8

Others such as Katherine Magnuson, Christopher Ruhm, and Jane Waldfogel (2004) have studied the effect of
prekindergarten on school performance. HHS (2002) studies Early Head Start for infants and toddlers. Chloe
Gibbs, Ludwig, and Miller (2011) also discuss the long-run impact of Head Start on children.

5

parents—in occasional cases through other HS centers).9 The treatment group contains at
least some non-missing observations on 2,479 children, and the control group contains at
least some non-missing observations on 1,582 children.10
HSIS collected information on these children and on a wide variety of measures of
their parents’ activities in the Fall of 2002 (subsequent to their enrollment in HS) and in the
Spring of 2003, 2004, 2005, and 2006. HSIS interviewed parents—almost always
mothers—in an in-home interview. The questions asked of parents in the HSIS in-home
interview, listed in Appendix Table 1 (available as an Electronic Appendix), vary somewhat
across survey years but also contain many questions that overlap across years. The children
were grouped in two cohorts, the “3-year-old cohort” (2,449 children) and the “4-year-old
cohort” (1,993 children). The 3-year-old HS cohort could first attend HS in the Fall of 2002,
but both treatment and control group members from this cohort were allowed to enroll in HS
in the Fall of 2003.11 In the 3-year-old cohort, the fraction of the treatment group that
enrolled in HS was 88% in the Fall of 2002 and 63% in the Fall of 2003. The fraction of the
control group that enrolled in HS was 19% in the Fall of 2002 and 49% in the Fall of 2003.
Subsequent to the end of the 2003-4 school year, children in the 3-year-old cohort could no
longer be enrolled in HS. The 4-year-old HS cohort could first attend HS in the Fall of 2002.
Subsequent to the 2002-3 school year, the 4-year-old cohort could no longer be enrolled in
HS. In the 4-year-old cohort, the fraction of the treatment group that enrolled in HS was 83%
in the Fall of 2002, and the fraction of the control group that enrolled in HS was 16% in the
Fall of 2002.12
Table 1 displays summary statistics for the main demographic variables in the
experiment. The means of these variables are balanced between the treatment and control
groups: in no case is the mean in the treatment group statistically significantly different from
the mean in the control group at the 10% level.13 The experiment’s randomization therefore
9

We often refer to the HS group as the “treatment group.”
Data are missing for part of the sample; we discuss this issue in greater detail below.
11
The study follows each cohort through the first grade, so the 4-year-old cohort is followed through Spring
2005, while the 3-year-old cohort is followed through Spring 2006.
12
9% of the treatment group and 23% of the control group is in non-Head Start center-based care (such as a
child care center, preschool, or pre-kindergarten program), while those not in any center-based care are typically
in daycare homes or cared for by their parents or other relatives.
13
This holds true whether comparing the raw means of the treatment and control group or comparing the means
when the observations are weighted by their sample weights. HHS (2010) only examines balance after
weighting by parent weights that adjust for non-response and other factors.
10

6

appears valid. Nearly half of the sample of children is male. Just over a third is Hispanic;
just under a third is black; and slightly under a third is white or another race. Just under 70%
speak English at home, and just over 30% speak Spanish. Almost 70% have a mother who
was born in the U.S. Children are 3.92 years old on average, mothers are 28.9 years old on
average, and fathers are 29.11 years old on average. Appendix Table 1 shows the means and
standard deviations of the full set of dependent variables on parent involvement used in the
paper. While a full discussion of these 87 variables is beyond the scope of the paper, it is
worth noting that these summary statistics show that parents on average report being quite
involved with their children’s lives along a wide variety of dimensions. For example, the
summary statistics show that in the “During” (“After”) period, parents spent a mean of 91.81
(108.53) minutes per week reading to their children; fathers living outside the home spent a
mean of 6.10 (5.02) days per month with their children; 19% (23%) of parents visited an art
gallery or museum with their children; and 45% of parents track the learning and
development of their children using stars or stickers to chart their progress in the “During”
period.14
II. Basic Empirical Approach
In our main specification, we use an instrumental variables (IV) procedure:
(1)

HeadStartip = α0 + α1Tip + Xipα + vip

(2)

Yip = β0 + β1HeadStartip + Xipβ + uip

(1) is the first stage equation, and (2) is the second stage. In (1), HeadStartip is a dummy that
equals 1 if the child is enrolled in HS and 0 otherwise; Tip is a dummy variable measuring
whether individual i in program p is part of the treatment or control group in the experiment;
α0 is a constant; α1 is the first stage coefficient on treatment; and α is a vector of coefficients
on the control variables. The two-stage least squares estimate of β1 identifies a local average
treatment effect: the causal impact of Head Start among the subset of individuals who would
enroll in Head Start on winning the lottery and would not enroll in Head Start without
winning the lottery (i.e. the compliers). The first stage of this IV procedure yields a
14

We define the “During” period as the period while children are still potentially eligible for HS (Fall 2002 and
Spring 2003), and we define the “After” period as the period after children are potentially eligible for HS
(Spring 2004-2006). We exclude data from the 3-year-old cohort observed in Spring 2004 from both the During
and After periods because some of the 3-year-olds were still enrolled in HS during this period, as described
above. When we include these data alternatively in the “During” period or the “After” period, we obtain similar
results to those shown (slightly smaller than those shown in the former case, and slightly larger than those
shown in the latter case).

7

coefficient of 0.68 on the dummy representing HS access. The first-stage F-statistic is
typically near 500. In (2), Yip is an outcome variable for individual i in HS program p. These
outcomes could represent a measure of parent involvement with their children (such as
reading or math activities with children), a dummy variable for the mother’s labor force
participation, or other relevant outcomes. In some cases, we also run the following reduced
form regression:
Yip = β0 + β1Tip + Xipβ + uip,

(3)

in which we regress the outcome directly on the treatment dummy. Xip is a vector of controls
for demographic variables; β0 is a constant; β1 is the coefficient of interest on the treatment
dummy; β is a vector of coefficients on X; and ε is an error. Except where otherwise noted,
we cluster the standard errors at the level of the HS program.
In the regressions in the main tables in the paper, we typically use two-stage least
squares to estimate (1) and (2). In Appendix Table 2, we report the reduced form regression
for each outcome, in which we regress the outcome directly on the treatment dummy, using
the technique appropriate to the form that the dependent variable takes (ordinary least
squares (OLS) for continuous outcomes, probit for binary outcomes, or ordered probit for
multiple ordered outcomes). In order to form the IV estimates in Appendix Table 2, the
simplest approach is simply to compute the Wald estimate by dividing the estimated effect of
treatment by 0.68 (i.e. multiplying by 1.47); as we show, the results of the reduced form and
first stage are extremely similar with and without covariates. The results of the two-stage
least squares regressions with covariates are always nearly identical to this Wald estimate
reported in Appendix Table 2. Since the first stage is so strong, it is unsurprising that the
significance levels on the coefficients are always the same when we run the reduced form as
when we run the IV.
Missing data represents a potential challenge in this setting. In 17.48% of the sample,
data are always missing on the dependent variable due to non-response by an individual.15
HHS (2010) weights the data so that it is nationally representative of the HS student
population. Our basic results, reported in the main tables, use their final sample weights. We
15

22.10% of all observations are missing in the control group, and 14.24% are missing in the treatment group.
Note, however, that the fact that the treatment is uncorrelated with demographics for non-missing observations
(as shown in Table 1) is suggestive of the possibility that treatment is uncorrelated with unobservables for nonmissing observations.

8

additionally address the presence of missing data in three ways. First, we perform a slightly
different imputation procedure. We match non-missing individuals to their nearest missing
neighbor using a propensity score calculated using all of the demographics in Table 1
collected in the initial HS application and their interactions, plus dummies for HS Centers.
We then replace missing data with data on the nearest non-missing neighbor. These results,
which we show in Table 4, are almost always similar to the results we obtain from using the
sample weights developed by HHS (2010); in those cases in which they diverge, the
alternative results almost always show slightly larger effects of treatment on parent
involvement than the results based on the weights in HHS (2010). Second, in Table 4 and
Appendix Table 2, we calculate the bounds on the treatment effect proposed by David S. Lee
(2009), which bound the effect of treatment when data are missing in an experimental design.
In many cases, the Lee lower bounds on the treatment effects we estimate also indicate
positive effects of treatment on parent involvement. Third, we show regressions in Table 4
that do not use weights.
III. Effect of HS Enrollment on Parent Inputs
a. Effect of HS Access on Parent Inputs
Appendix Table 2 shows the effect of treatment on each dependent variable relating
to parent involvement with children.16 The regression results in Appendix Table 2A show a
strong positive and significant impact of treatment on most measures of parent involvement
with children while the experiment was in progress, in Fall 2002 and Spring 2003. Broadly
speaking, categories of activities that are typically positively affected include reading/writing-/vocabulary-related activities (such as “practice writing the alphabet”), math-related
activities (such as “play math-related games”), tracking the learning and development of the
child (such as “by keeping notes about (his/her) behavior or progress”), undertaking cultural
activities with the child (such as “visited an art gallery, museum, or historical site”), setting
rules for children (such as “rules or routines about how many hours of TV allowed to

16

We put these results in the appendix for convenience, not because we wish to suggest that they are much less
important to the paper than the results we show below in Table 2 and elsewhere. Indeed, we consider the results
in Table 2 to be convenient elaborations on the results in Appendix Table 2. Since the number of dependent
variables in question is very large, it is less unwieldy to present these results in an appendix than in the main
text. In Table 3 of the main text, we discuss selected outcomes of interest from Appendix Table 2.

9

watch”), and qualitative features of parenting practices (such as “I encourage my child to be
curious, to explore, and to question things”).17
Appendix Table 2B shows the results of regression (1) when the dependent variables
are instead measured after the experiment occurred, in Spring 2004 and Spring 2005 for the
4-year-old-cohort, and in Spring 2005 and Spring 2006 for the 3-year-old cohort. The set of
dependent variables is different than those measured in the During period, because certain
variables were measured only during the period of the experiment (such as certain math
activities or activities relating to tracking the learning and development of the child), and
other variables (such as days the mother spent volunteering in the child’s school) are
measured only after the experiment occurred. The results show that most parent inputs are
estimated to have increased in response to the treatment.18 However, the point estimates are
usually smaller than the estimates in the During period (for those variables that are observed
in both periods), and fewer estimates are statistically significantly different from zero.
Several categories of variables are often positively and statistically significantly impacted by
treatment in the After period: math activities, father inputs, rules set by parents, and
qualitative features of parenting practices.
b. Aggregating the results
It is additionally of interest to assess whether treatment “usually” had a positive
impact on parent involvement with children. We do so in three ways, described in greater
detail below. Each of these approaches is of interest, but each one also has limitations. By
providing a compilation of evidence that all supports the same conclusion, we attempt to
address concerns that might arise about any of these approaches considered on its own. All
of these analyses point to the same conclusion: that parent involvement with children
generally increased in response to treatment.
First, we assess how many of the estimated impacts of treatment on parent
involvement are positive and significant. Of the 65 effects estimated in the During period, 24
are positive and significant at the 1% level, 8 are positive and significant at the 5% level, 12
17

HHS (2010) finds that HS eligibility increases a “cultural enrichment” scale, specifically for the 3-year-old
cohort in Spring 2003 (significant at the 5% level after correcting for multiple comparisons), and that parents
were more likely to read to children (specifically for the 3-year-old cohort in Spring 2003, significant at 10%
after correcting for multiple comparisons). It finds insignificant impacts on several other outcomes.
18
When we limit the set of dependent variables in Fall 2002 and Spring 2003 only to those that are only
observed in Spring 2004, Spring 2005, and Spring 2006 (or vice versa), the results show positive and extremely
similar and significant impacts of treatment.

10

are positive and significant at the 10% level, and 20 are positive and insignificant. One is
negative and insignificant (p>.40),19 and none is negative and significant. Of the 62 effects
estimated in the After period, 8 are positive and significant at the 1% level, 6 at the 5% level,
5 at the 10% level, and 34 are positive and insignificant. 9 are negative and insignificant, and
none is negative and significant.20
Second, in order to make the outcome variables comparable with each other, we
follow the method of Jeffrey Kling, Jeffrey Liebman, and Lawrence Katz (2007).21 We
normalize each of the dependent variables by subtracting its mean and dividing by its
standard deviation in the control group. We calculate the coefficient estimates reported in
Table 2 by averaging the coefficient estimates across the regressions for all parent
involvement outcomes:
(4)

Σj(1/J)(βj/σj)

where j indexes outcomes, J is the total number of outcomes, βj represents the coefficient on
treatment for the j-th outcome, and σj represents the standard deviation of the j-th outcome in
the control group. Following Kling, Liebman, and Katz, we calculate the standard error by
running an IV regression pooling all of the data from all of the different outcomes.22 In
particular, we pool the normalized data across all outcome variables and then regress these
pooled outcomes on a dummy variable for treatment.23 We refer to this procedure as
“normalized IV.” The normalized analysis is useful because it allows us to form an
aggregate measure of the magnitude of the effect of treatment on parent outcomes.
Nonetheless, this analysis has limitations: it implicitly weights each outcome equally and
uses a functional form that is not appropriate for ordered categorical outcomes.

19

“Has your family received any child support payments from (his/her) father?”
We exclude the parent medical involvement outcomes in Appendix Table 2 (such as taking the child to a
vision screening) from this aggregation and the two other aggregation methods we discuss below, since medical
outcomes are arguably less closely related to parent involvement. We include medical outcomes in a robustness
check. Note that 3 of 4 medical outcomes are significantly positively affected by treatment in the During
period, and 1 of 4 is marginally significantly positively affected in the After period.
21
Some of the variables are binary; others are represented as multiple ordered outcomes; and still others can
take on any positive value.
22
We obtain similarly significant results when we do not first normalize the dependent variable for continuous
outcomes in this way.
23
We pool all outcomes, leading to a large sample size, and cluster the standard errors at the program level.
When we instead take the mean of normalized parent inputs for each individual and run a regression of mean
normalized parent inputs on the treatment dummy (with as many observations as individuals), the results are
very similar, with very similar significance levels.
20

11

Row A of Table 2 shows these results, which demonstrate a strong positive and
significant mean effect of treatment on the outcomes. The point estimates suggest that
pooling across all measures of parent outcomes, treatment raises parent involvement with
their children by an average of 15% of a standard deviation in the During period and 6% in
the After period, both of which are significant at the 1% level.24 These results are essentially
unchanged by adding controls in Columns 2 and 5. In Figure 1, for each individual, we
calculate the mean of the normalized parent involvement measures and plot the distribution
of this variable in the treatment group (upper line) and control group (lower line). This
figure shows that Head Start appears to have had the biggest impact on parent involvement in
the lowest quantiles, and that it had a bigger impact in the During period than the After
period.25
The other rows of Table 2 show this analysis aggregated by category of parent
involvement (created using the variables in each category listed in Appendix Table 2). In the
During period, reading activities, math activities, tracking the learning and development of
the child, and parent use of rules or routines are each significantly positively affected at the
1% level. Qualitative features of parenting effort and other (often cultural) activities are each
significantly positively affected at the 5% level. It is notable that some of the impacts that
are quantitatively largest are found for those categories of involvement that seem most likely
to impact child human capital directly (e.g. reading activities, math activities, and tracking
the child’s development). In the After period, math activities and rules or routines are each
significantly positively impacted at the 1% level, and teacher and interviewer reports of
parent involvement and qualitative features of parenting effort at the 5% level.26

24

We obtain results with similar significance levels throughout the pooled analysis in the paper when we
remove certain dependent variables from the analysis that arguably may not reflect greater parent involvement
with their children, including when we remove all of the variables relating to rules set by parents, or when we
remove all of the variables relating to “qualitative parent practices” such as “I encourage my child to be curious,
to explore, and to question things.”
25
The Kolmogorov-Smirnov test shows that the treatment and control distributions are significantly different in
the During period (p<.001) and in the After period (p<.05).
26
Note that since some questions were asked in the After period that were not asked in the During period and
vice versa, each category of involvement sometimes refers to a different set of questions in each period. For
example, there are no uniform teacher reports of parent involvement in the During period (since many children,
especially in the control group, did not have teachers before kindergarten), whereas they reported three
measures of parent behavior in the After period; the interviewer-reported variable “A variety of learning
materials are available” was asked in both periods. Please see Appendix Tables 1 and 2 for a list of all of the
variables included in each category and period.

12

Third, we examine whether across all regressions, the estimated impact of treatment
on the outcomes is jointly significant and different from zero, by performing a generalized
Hausman test for joint significance of the coefficients across all of the reduced form
regressions considered in Appendix Table 2, which include probit regressions (for the binary
dependent variables), ordered probit regressions (for the 3-, 4-, 5-, and 6-category outcomes),
and ordinary least squares regressions (for the continuous outcomes). These results in Table
2 again show that across all specifications, the coefficients are jointly significant at the 1%
level, in both the During and After periods. One limitation of this analysis is that the
generalized Hausman test examines joint significance with respect to the null that all of the
coefficients are equal to zero. If a coefficient is negative, this would (at an intuitive level)
“contribute” to the joint significance level of the coefficients. However, as noted above, the
estimated coefficient is negative in only one case in the During period (and is insignificant in
this case). Despite this limitation, we show the generalized Hausman test because it allows
us to cumulate results while running the specifications that are most appropriate to ordered or
binary dependent variables.27
When we examine the dynamics of the effect on parent involvement, we find no
evidence that the impact of HS enrollment on parent involvement fades over the course of the
period after children are potentially enrolled in HS. When we estimate the IV treatment
effect using data only on children in 2004, 2005, or 2006, we estimate coefficients (standard
errors) on the HS enrollment dummy of .06 (.03), .05 (.02), and .06 (.03), respectively, all
significantly different from zero at the 5% level. The time trend over 2004-6 interacted with
treatment is insignificantly different from zero (p>0.40). When we estimate the IV treatment
effect in the After period using data only on children currently in kindergarten or in first
27

Factor analysis represents a different approach to aggregating the dependent variables, which we explore in
Appendix Table 3. One benefit of factor analysis is that it recovers a number of latent parent input variables,
rather than implicitly weighting each outcome equally. We ran a factor analysis by first pooling all of the
dependent variables together and extracting their common variability, and then using the Kaiser criterion to
keep factors whose eigenvalues are greater than 1. We then regressed each of the factors on HS attendance and
instrument for HS attendance with treatment status. The results show a strong positive and significant impact of
treatment on most of the factors considered individually in the During period: the estimated impact of treatment
is positive and significant at the 1% level for two of the factors; positive and significant at the 5% level for one
of the factors; and positive and insignificant for two of the factors. In the After period, the outcomes are
grouped into nine factors. The estimated impact of treatment is positive and significant at the 5% level for three
of the factors; positive and significant at the 10% level for two of the factors; positive and insignificant for three
of the factors; and negative and insignificant (p>.40) for one of the factors. In both the During and After
periods, when we pooled the factors together, we found larger and more significant mean effects of HS on the
factors than the effects we found in the other analyses.

13

grade, we estimate coefficients (standard errors) on HS enrollment of .05 (.02) and .06 (.02),
respectively, both significantly different from zero at the 5% level. The time trend interacted
with treatment is again insignificantly different from zero for these groups (p>0.40).28
c. Particular outcomes
In Table 3, we examine particular outcomes of interest. We do so not because we
believe that these are always more important than other outcomes listed in Appendix Table 2,
but rather in order to highlight some outcomes of particular interest, and to give show more
specific examples in the main text of the sorts of outcomes that respond to treatment. As
noted above, parents tend to increase their reading-related activities with their children.
Column 1 shows that the number of times parents read to children increases significantly in
response to HS enrollment in the During period, and Column 2 shows that the amount of
time a parent reads to a child per sitting increases significantly, as well. By multiplying
together the number of times a parent read to a child by the amount of time spent reading per
sitting, we can form a measure of the amount of time a parent spent reading to their child.29
More broadly, we could consider this to be an imperfect proxy for parent-child teaching time.
We find a positive, large, and highly significant effect of treatment on the estimated amount
of time spent reading with children in the During period: the increase in amount of time spent
reading in response to treatment is 18.71 minutes (20.4% of the mean of this variable), with a
standard error of 4.79 minutes.
Days spent with the father, asked among children whose fathers do not live in the
home, represents a second measure of the time parents spend with children. Interestingly, in
Column 4 of Table 3, days spent by the father with the child increases a striking amount after
the experiment is over, with a point estimate of the effect of treatment of .94 days (18.7% of
the mean, with a standard error of .45 days); in the During period, days spent by the father
with the child increases insignificantly, with a point estimate of the effect of treatment of .62
days (10.2% of the mean, with a standard error of .58 days).

28

When we estimate the impact of HS enrollment on parent involvement just in Fall 2002, the coefficient
(standard error) on HS enrollment is .12 (.02), and in Spring 2003, it is .19 (.03), both significantly different
from zero at the 1% level, and significantly different from each other at the 5% level. It therefore appears that
parents increase their involvement over the course of the During period.
29
How many times per week a parent read to a child is “topcoded” at “every day.” In the results reported here,
we assume that “every day” indicates that a parent read to a child exactly 7 times in the past week. The results
are not sensitive to alternative assumptions.

14

In Column 5, we show an example of the finding that parent involvement in
children’s math activities rises in response to Head Start enrollment (in this case “practicing
math concepts using dance or acting out stories”). Column 6 shows an example of the
finding that culturally enriching activities parents undertake with their children tend to rise in
response to Head Start enrollment (in this case “taking a child to an art gallery, museum, or
historical site”). Column 7 shows an example of the finding that parents track child
development more in response to Head Start enrollment (in this case “by keeping notes about
the child’s behavior or progress”). Throughout these regressions, it is typical that the
estimated positive effects on parent involvement are larger and more significant in the
During period than in the After period.
Most of the results are based on parents’ self-reports of their activities, but it is
possible that they incorrectly self-report greater levels of involvement in response to HS
access. For example, parents could have felt more pressure to report investing in their
children or perceive greater involvement purely as a result of HS access. If not only parents
but teachers and interviewers report greater parent involvement, we can have more
confidence that parents are correct in reporting greater involvement. Column 8 of Table 2
shows that in the During and After periods considered separately, the interviewer’s response
to the question “A variety of learning materials are available” responds positively but
insignificantly to treatment. However, when we pool results from the During and After
periods, this coefficient increases to .072 (with a standard error of .032, implying that the
coefficient is significantly different from zero at the 5% level). We also find some evidence
that reports of parent involvement by children’s kindergarten and first-grade teachers
increased as a result of HS access, contained in the section of Appendix Table 2 entitled
“Teacher and Interviewer-Reported Parent Involvement.” Two of the estimates are
insignificant, but a third estimate, of the effect of treatment on a dummy measuring parents’
responses to the question “Have parents met with teacher and special needs team for special
needs children,” is large, positive, and significant at the 5% level.
d. Other econometric approaches
In Appendix Table 2, we report each regression separately for many outcome
variables and calculate standard errors separately for each of these regressions. One concern
about this approach is that we consider multiple outcome variables but do not correct the

15

standard errors for multiple comparisons. While we have aggregated results across
regressions in a number of ways that are not subject to this criticism, we additionally address
this issue by applying the Holm-Bonferroni procedure to our estimates. In Appendix Table
2, for each estimate, we report the p-value associated with the Holm adjustment in Column 4,
which we view as a conservative—if anything overly conservative—approach to estimating
the standard errors. Even after performing the Holm adjustment, 13 of the outcomes in the
During period are estimated to have been significantly increased by the treatment at the 1%
level, 3 at the 5% level, and 6 at the 10% level.
As noted above, data are always missing for 17.48% of the sample due to nonresponse. In addition to the alternative imputation procedure for missing data discussed
above, we address missing data by calculating for each variable the lower bound on the
treatment effect implied by the Lee (2009) trimming procedure and report it in Column 5 of
Appendix Table 2. These lower bounds are positive for 22 out of 63 outcome variables in the
During period, indicating that the effect of treatment on these measures of parent
involvement is positive even in the Lee (2009) “worst case” scenario.30
Table 4 shows various robustness checks. Column 1 shows the results of reduced
form OLS regressions (3) for the pooled analysis analogous to Column 1 of Table 2. Column
1 of Table 4 verifies the claim that the results of the IV regressions in Table 2 are extremely
similar to the analogous results in Table 4 multiplied by 1/0.68=1.47 (where 0.68 is the firststage coefficient in the IV regressions). Moreover, the significance levels in the OLS
regressions are very similar to the significance levels in the IV regressions. Column 2 shows
that “jackknife weights,” which account for the uncertainty in the sampling of programs
included in the analysis in order to make the sample ostensibly nationally representative,
yield results extremely similar to the basic results. Column 3 shows the Lee lower bound on
30

Note that only 20 out of 63 of the outcomes in the Appendix are listed as having a positive Lee lower bound,
but that in fact 22 are positive because we round two numbers to zero. In counting these 22 outcomes, we
exclude medical variables since we exclude these from the main analysis (but note that the coefficients on HS
have a positive Lee lower bound for all of these medical variables, so that they would increase the total number
of positives to 26 if included in the analysis). These Lee bound results suggest that missing data in fact is an
important issue in interpreting the results, but they further suggest that the main result—that there is strong
evidence that many parent inputs rise when children are eligible for HS—ultimately survives a correction for
missing data. The top portion of the distribution trimmed from the sample varies across outcomes, and
therefore examining the bounds on each individual outcome separately understates the degree to which we can
bound the results across all outcomes. Consistent with this, when we pool all outcomes together and run the
trimming procedure, the Lee lower bound is statistically significantly greater than zero in the During period (see
Table 4 Column 3).

16

the reduced form estimates in the main specification in Table 2 Row A. The lower bound on
the treatment effect in the During period is 0.04 and is significantly different from zero at the
5% level (though the lower bound on the treatment effect in the After period is -0.01 and is
insignificantly different from zero).31
In Column 4 of Table 4, we show the results when we run the main specification from
Table 2 but instrument for whether a child enrolled in any center-based care, which includes
HS enrollment as well as preschool, pre-kindergarten programs, or other child care centers.
Doing so decreases the coefficient on the treatment dummy in the first stage regression (1)
but does not affect the coefficient on the treatment dummy in the reduced form (3), and thus
the estimated coefficient on HS enrollment increases slightly relative to the baseline
specification. In Column 5, we include four medical outcomes in the analysis, such as
whether the parent took the child to a routine doctor’s appointment, which have been
otherwise excluded from the analysis. Column 6 shows the results from the main
specification without weights, as most other field experiments do. Column 7 shows the
results from the main specification when we use our alternative weighting procedure to
address missing data, as we describe more fully above and in Appendix A. The results are
again extremely similar to the basic results.
We analyzed whether the impacts of HS on parent involvement were different across
demographic groups and found no evidence of significantly different impacts across any of
the different subsamples of children that we examined: whether or not the father was at
home; male or female children; Fall 2002 income level of the parents; number of siblings;32
or the 3- or 4-year-old cohorts. The separate analysis of the 3- and 4-year-old cohorts is
important because in the 3-year-old cohort, children in the treatment group on average spent
0.83 years more in HS than children in the control group, whereas the 4-year-old cohort,
children in the treatment group on average spent 0.67 years more in HS than children in the
control group. Thus, it is unsurprising that we find relatively similar impacts of treatment on
these cohorts. When we examine each of the outcomes in Appendix Table 1 separately, we
find only one out of 65 outcomes for which the effect of treatment is significantly different at
the 5% level in the 3-year-old and 4-year-old cohorts in the During period and none of 62
31

The Lee lower bound in the After period is positive when we include medical variables in the analysis.
Becker and Tomes (1976) raise the possibility that parents could respond to an education program for a given
child by spending more time or money on other children in the family.
32

17

outcomes that is significantly different at the 5% level in the two cohorts in the After
period.33 These considerations all suggest that pooling data from the 3-year-old and 4-yearold cohorts is appropriate.
In order to address this issue further, in Column 8 of Table 4 we additionally run a
regression in which we regress parent inputs on a variable measuring the total amount of time
over which a child was exposed to HS, and we instrument for this variable using the
treatment dummy interacted with dummies for the 3- and 4-year-old cohorts. This
specification implicitly recognizes that the treatment occurs on average for a slightly
different total period of time for children in these different cohorts. The results are
essentially identical to the basic results.
e. Other outcomes
Appendix Table 4 shows the estimated impact of HS on other relevant outcomes. It
shows that HS had a positive and significant effect on child cognitive and non-cognitive
scores in the During period (p<.01 and p<.10, respectively), which is in the same vein as the
results in HHS (2010). HS had a small and insignificant impact on cognitive and noncognitive scores in the After period, though the point estimates are still positive. HS had an
insignificant impact on the probability that the father is in the home and the probability that a
child is special needs in both the During and After periods, which are relevant in interpreting
the results relating to father involvement and special needs children.
IV. Discussion
This section states and explores several exclusive hypotheses that could account for
the impact of Head Start on parent involvement.34 First, specific features of Head Start
programs, such as the extent to which Head Start centers encourage parents to volunteer in
the centers, could in turn encourage parents to be more involved with their children. Second
(third), parents could perceive their involvement with their children as complementary to
observed (unobserved) changes in child characteristics, such as cognitive or non-cognitive
33

When we normalize all outcomes and examine all outcomes pooled (as in Column 1 of Table 2) and for all
years of the data pooled together, we find that treatment had a 0.012 larger impact in the 4-year-old cohort than
in the 3-year-old cohort, with a standard error of 0.025, implying an insignificant difference between the groups.
When we run these regressions in the During period, we find that treatment had a 0.016 larger impact in the 3year-old cohort than in the 4-year-old cohort, with a standard error of 0.036. When we run these regressions in
the After period, we find that treatment had a 0.018 larger impact in the 4-year-old cohort than in the 3-year-old
cohort, with a standard error of 0.030.
34
These hypotheses are not mutually exclusive.

18

scores, that result from Head Start enrollment. Fourth, parents could spend more time with
their children because they are more pleasant to be with.35 Fifth, peer effects among parents
could lead parents to change their behavior: those parents whose children are in Head Start
could be exposed to high-involvement parents and therefore raise their involvement. Sixth, it
is possible that parents perceive their children to have “won a lottery” and therefore invest
more in them simply for this reason, for example because they would perceive their child to
“be a winner” if they won any lottery. Seventh, Head Start could lead to changes in parent
time with children through impacts on parents’ time budget constraints (for example because
the effectively free childcare given by Head Start influences parents’ effective wage).
a. Cross-Program Correlation of Effects on Cognitive Scores and Parent Inputs
We demonstrate the intriguing finding that the parents of children randomly assigned
to treatment in programs that boosted cognitive scores the most in Spring 2003 were more
likely to show greater involvement with their children as a result of treatment. A positive
correlation would be consistent with the claim that parents increase their involvement with
their children due to the impact that HS has on their children’s cognitive scores (consistent
with Explanation 2 above). It is also possible that children’s cognitive scores proxy for
unobserved changes in children’s characteristics (Explanation 3). However, this correlation
would not be immediately predicted by Explanation 5 (peer effects among parents) or
Explanation 6 (the “winning the lottery effect”), since there is no immediate reason why peer
effects or the “winning the lottery effect” should be larger in programs that raise child
cognitive scores the most. It also would not be immediately predicted by Explanation 1
(specific features of Head Start programs), but it would be consistent with Explanation 1
under the arguably reasonable presumption that those Head Start programs that are most
effective in one dimension (raising cognitive scores) may also be most effective in another
dimension (raising parent involvement). Finally, a positive cross-program correlation would
be consistent with the possibility that parent involvement is responsible for the increase in
child cognitive scores, rather than the reverse.

35

We distinguish Explanation 4 from Explanations 2 and 3 because in Explanations 2 and 3, parents perceive
HS as complementary with parent investment in producing child characteristics, whereas Explanation 4 posits
that parents directly derive more utility from parent-child teaching time due to changes in child characteristics.
See the framework in Appendix E.

19

As a first step in estimating this correlation across Head Start programs, we estimate
the effect of treatment in each Head Start program on both cognitive scores and parent
involvement and then correlate these effects across programs.36 In particular, we run the
following regressions:
(5)

Cognitiveip = α p(Tip*δ p) + δ p + εip

(6)

Involvementip = β p(Tip*δ p) + δ p + εip

In (5), Cognitiveip represents a normalized cognitive score of individual i in program p; δ p
represents a vector of fixed effects for each HS program that equal 1 when individual i is in
program p and 0 otherwise; Tip is the treatment dummy measured for individual i in program
p; and α p is a vector of coefficients on the vector of interactions of the treatment dummy and
the program fixed effects. In (6), the notation is the same and Involvementip represents the
normalized involvement measures of parents of child i in program p. Figure 2 shows that the
correlation across programs of the α p and β p is positive and easily visible (with a correlation
of 0.42, which is significantly different from zero at the 1% level).37
Nonetheless, the estimated cross-program correlation between αp and βp in (5) and (6)
may be biased, among other reasons because parent involvement and cognitive scores are
positively correlated in a cross section of students (even absent the effects of HS). With
finite program size and a positive cross-sectional correlation between cognitive scores and
parent involvement, we would estimate an upward-biased cross-program correlation between
impacts of HS on parent involvement and impacts of HS on cognitive scores, absent a
jackknife procedure.38 To address this issue, we implement a jackknife by omitting each
individual i’s scores when calculating program quality. Appendix Table 5 shows that there is
a strong positive and statistically significant estimated association between cognitive scores
36

In both the treatment and control groups, we consider a child to be in a given program if they applied to a
center in that program.
37
We run reduced-form regressions in (5) and (6), but the results of the IV regression (i.e. instrumenting for
Head Start enrollment interacted with program fixed effects using Head Start eligibility interacted with program
fixed effects) show an even higher correlation of program effects on cognitive scores and program effects on
parent inputs (0.73, significant at 1%). When we calculate this correlation at the level of the HS center, rather
than the HS program, we find a correlation of 0.35 (significantly different from zero at the 1% level). The
results in Appendix Table 5 are also similar when the variation is at the level of the HS center (rather than
program).
38
Note, however, that programs on average have 42 students in the treatment and control groups, so the
potential scope for bias is small. Moreover, error in measuring program impacts is likely to bias this estimated
correlation in Figure 1 downward; following the method in Chetty et al. (2011), we calculate that this
downward bias should be 30.2%.

20

and parent inputs in the During period.39 By contrast, Appendix Table 5 shows that 58
detailed HS center characteristics reported by center directors—which arguably comprise a
list of the main plausible mechanisms by which HS (or other centers) may be directly
promoting increased parent involvement (such as the utilization of parent teacher
conferences, having parents volunteer in the center, or home visits by center staff)—together
have little correlation with the impact of HS on parent inputs.40 This constitutes suggestive
evidence that makes Explanation 1 appear less likely (though still possible).41 Appendix
Table 5 also shows that the effect of programs on non-cognitive scores has a weaker
relationship with the effect on parent involvement in the During period.42 Appendix C
describes the jackknife procedure in detail and contains a further discussion of Appendix
Table 5.
b. Changes in parents’ child care responsibilities and illustrative conceptual framework
To examine the role the changes in parents’ child care responsibilities may play in
accounting for changes in parent investment in children (Explanation 7), consider how these
39

The cross-program correlation of the effect of HS on parent involvement and cognitive scores is also notable
because it again suggests that parents are not simply self-reporting higher levels of involvement in the treatment
group. If the only reason that we see a correlation between treatment and parent involvement is that parents are
self-reporting greater involvement with their children in response, even though they do not actually increase
their involvement, then we would expect to see no correlation across programs of the effect on parent
involvement with the effect on cognitive score.
40
Center directors at both HS centers and at other childcare centers reported these 58 center characteristics.
Appendix C describes how we construct these measures of HS and non-HS center characteristics. These reports
by directors appear to contain useful information since they are highly correlated (p<0.001) with reports by
parents of their involvement in the centers.
41
Another piece of evidence is consistent with the spirit of these results, which document an association of
parent involvement with cognitive scores but not with Head Start center characteristics. When we instrument for
own cognitive scores using the cognitive scores of peers in Column 4 of Appendix Table 5, the coefficient on
the HS dummy is greatly affected—decreasing from 0.16 when we implement the specification in Appendix
Table 5 without including cognitive scores as a regressor, to 0.08 when we do include cognitive scores
(p<.01)—but when we control for HS center characteristics in Column 5, the coefficient on the HS dummy
stays at 0.08 (p>0.40). Similarly, when we run the regression from Table 2 Row A and control for cognitive
scores, the coefficient on the HS dummy is greatly affected (going down by 56%, p<.01 for the test of equal
coefficients to Table 2 Column 1), but when we instead control for HS center characteristics, the coefficient on
the HS dummy is insignificantly affected (p>0.40) and the point estimate changes negligibly. In addition, when
we run the regression from Table 2 Row A and control for non-cognitive scores, the coefficient on the HS
dummy is little affected (p>0.40), again suggesting that changes non-cognitive scores have little association
with changes in parent inputs. However, it is worth stressing the important caveats that unobserved features of
Head Start programs could cause the positive cross-program correlation of impacts on parent involvement and
cognitive scores that we observe; that cognitive and non-cognitive scores are endogenous outcomes that are
affected by treatment along with parent involvement; and that center characteristics are not exogenously
assigned across centers.
42
If non-cognitive characteristics proxy for how enjoyable parent-child teaching time is, this constitutes
suggestive (though far from definitive) evidence that parents are not investing more in children primarily due to
observable ways that HS makes children more pleasant to spend time with (Explanation 4).

21

results relate to the changes in child and parent time allocation associated with Head Start
enrollment. Appendix Table 6 Panel B shows that HS enrollment raises children’s weekly
hours in childcare including HS (other than childcare by parents) by 11.71 hours per week,
and the effect is significantly different from zero at the 1% level.43 Assuming that children
must either be with their parents or in non-parent childcare—a reasonable approximation for
3- and 4-year-olds—this implies that total time with parents must have decreased during the
experiment.44 This is due to the child time budget constraint: children who are enrolled in
HS mechanically have less time to spend with their parents, since a large fraction of their day
is now spent in HS rather than with their parents.
In order to provide an illustrative conceptual framework to organize ideas about
children’s and parents’ time allocation as it relates to the results we obtain in the During
period, in Appendix E we sketch a framework in which parent-child time has multiple
dimensions. In this framework, children’s time is divided into 4 categories: time spent in HS,
time spent in non-HS non-parent childcare, time spent with parents in which parents teach or
otherwise invest in them, and non-teaching time with parents. If time in non-parent childcare
rises, then total parent time must fall. Parents’ time is devoted to teaching or otherwise
investing in children, spending non-teaching time with children, or non-child time. The first
goal of this framework is to illustrate a very simple point: parent-child teaching time can
increase even if total parent-child time decreases in response to child enrollment in HS.
In the framework, designed specifically to capture Explanation 2 (or 3) above, parents
derive utility both directly from their own time allocation and from their children’s
characteristics, which are in turn a function of Head Start hours, non-Head Start non-parent
childcare, parent teaching time, and parent non-teaching time. A key point illustrated by the
framework is that if parent teaching time is perceived as sufficiently complementary with

43

A similar finding is documented in HHS (2010). Appendices C and D discuss further results that we develop
on children’s time allocation from Appendix Table 6. As we discuss further in these appendices, Appendix
Table 6 also shows that there is little evidence that parents’ probability of labor force participation responded to
child Head Start enrollment, which constitutes suggestive evidence that this factor does not drive changes in
parent investment in children.
44
It is possible that preschool-aged children also spend time with friends. However, this factor seems
extremely unlikely to reverse the conclusion that Head Start caused a decrease in overall parent time with
children. In order to reverse this conclusion, it would have to be the case that children spent at least 11.71 fewer
hours with friends as a result of Head Start, which seems extremely unlikely. Nonetheless, in the framework in
Appendix E, we accommodate the possibility that children could in principle be spending some time not with
parents or in other childcare.

22

Head Start inputs in producing valued child characteristics, then teaching time can increase in
response to an increase in child Head Start hours.45 Appendix E contains a more detailed
discussion of the framework and its relationship to our empirical results. In this framework
and elsewhere in the paper, we interpret the measures of parent involvement from the
empirical work as “investment” in children; by “investment,” strictly speaking we mean
simply that parent “investment” activities have both a direct impact on parents’ utility and an
indirect effect through child characteristics (whose value to parents and children may in part
be realized later in life, for example through child earnings outcomes). We focus on
Explanation 2 since it is arguably the most directly consistent with the data, and since it is
helpful to clarify a formal framework that underlies the complementarity postulated in this
explanation. However, it is worth emphasizing that the data certainly do not rule out other
explanations discussed above.
c. Parent involvement in the After period
We noted above that the cross-program correlation of impacts on parent investment
and child cognitive scores is consistent inter alia with the possibility that child cognitive
scores impact parent investment, or with the possibility that parent investment impacts child
cognitive scores. In light of the fact that the effect of HS on several parent inputs persists
even after the experiment ends, it is perhaps surprising that the cognitive and non-cognitive
gains from HS fade over time. This combination of findings suggests either that these parent
inputs do not raise cognitive and non-cognitive measures, or that the effect on these scores is
not large enough to be detected as statistically significant in our sample.46
Assuming that changes in child characteristics impact parent involvement, rather than
the reverse, it is possible that increased parent involvement may persist in the HS group in
the After period because it responds to unmeasured cognitive or non-cognitive characteristics
of children that change due to HS.47 Alternatively, parents could increase their involvement

45

A second key point illustrated by the framework is that the welfare impact of Head Start depends in part on
the direct impact of parents’ effort on their utility, as discussed below.
46
It is also possible that the effect of these parent inputs is not apparent in these measures of cognitive and noncognitive ability but would appear in other measures.
47
It could also be that parent involvement persists because parents falsely expect the measured test score gains
from the During period to persist and thus continue their increased involvement in the After period.

23

in the During period (for example in reaction to increases in child cognitive scores) and form
habits of greater involvement that persist into the After period.48
V. Conclusion
We investigate the effect of HS enrollment on parents’ involvement with their
children. We find that when children enroll in HS, their parents are more involved with them
along a wide variety of dimensions, both during and after the period when children are
enrolled in the program. This finding is robust across a variety of analyses. We also find
evidence that this impact on parent involvement does not fade over the course of the period
after children are potentially enrolled in HS. Several hypotheses could account for the
impact of Head Start on parent involvement; our data point toward parents’ reaction to the
impact of Head Start on child characteristics, or unobserved features of Head Start programs
that directly induce parent involvement, as potential explanations for the increase in parent
involvement, but several other explanations are possible.
Our findings are notable for a number of reasons. First, the results suggest that a
welfare analysis of Head Start or other schooling programs must include an estimate of their
effect on parents’ effort, since effort is typically modeled as costly at the margin.49 Second,
studies of the effect of schooling inputs on children have typically estimated the overall
effect of schooling programs on child outcomes, without disaggregating these effects into
direct effects of the programs on child outcomes and indirect effects of the programs that
operate through their effect on parent investment. If these parent inputs positively affect
children’s outcomes, our results suggest that in previous studies that have measured the
overall effect of HS on child outcomes, the direct effect on child outcomes is smaller than the
estimates of the overall effect on child outcomes.50
Third, our findings are interesting in part because one of the goals of HS is to increase
parent involvement with their children. Our results show that HS succeeds in that goal.

48

In this light, it is interesting to note that as described in Section IV.c, parent involvement drops off sharply
from the During to the After period, whereas parent involvement is persistently at a similar level throughout the
After period: the estimated coefficient is 0.12, 0.19, 0.06, 0.05, and 0.06 in Fall 2002, Spring 2003, Spring
2004, Spring 2005, and Spring 2006, respectively. This time pattern appears inconsistent with a model in which
parents form a habit of involvement with their children and (as we might expect) these habits slowly fade.
49
Of course, the potential positive impacts of parent effort on children must be considered in any welfare
analysis along with effort costs to parents. See the discussion of social welfare in the framework in Appendix E.
50
Relatedly, the results suggest that in a fully specified model of the production of child human capital, parent
inputs may be affected by government policy or other factors that affect child schooling.

24

Interestingly, however, we find little evidence in support of the hypothesis that this effect
operates through the measures that HS takes to involve parents, such as parent-teacher
meetings. If the effect of HS on parents is mediated through the impact that HS has on
children’s cognitive ability—which appears consistent with the data—this suggests in turn
that if schooling in other contexts has positive impacts on child test scores, it will also have
positive impacts on parent investment.51
Despite the fact that test score gains fade out after HS ends, there is evidence that HS
does have impacts on long-run child outcomes (Garces, Thomas, and Currie 2002; Deming
2009; Ludwig and Miller 2007). The re-emergence of schooling impacts on children in later
life, despite no measurable medium-run impact on test scores, has also been noted in other
contexts (e.g. Heckman, Malofeeva, Pinto, and Savelyev 2010; Chetty et al. 2011; Dynarski,
Hyman, and Schanzenbach 2011). It is possible that persistent increases in parent investment
constitute a channel through which the long-run impact on child outcomes is mediated.
This paper has a number of limitations and suggests several directions for future
study. First, we typically do not directly observe time spent by parents on parent-child
activities. These outcomes could be explored in a dataset in which measures of parent time
with children is collected. Second, many educational institutions seek to increase parent
involvement with their children, as parent involvement is often seen as a crucial factor in the
success of educational programs. It would be of interest to see whether schooling has a
similar impact on parents’ involvement with their children in settings outside of HS. Third,
we do not observe some important elements of parents’ investment in children, including
expenditures on many goods for children. A dataset with information on expenditures would
be very helpful in completing this picture. Finally, it is difficult to know which, if any, of the
parent involvement outcomes we investigated have positive impacts on their children. If we
knew how different parent inputs affected child outcomes, we could use this paper’s
estimates of the impact of HS on each separate parent outcome to predict how changes in
these inputs induced by Head Start should impact child outcomes.52 The effect of parent
involvement on children’s outcomes remains an important outstanding question.
51

The estimated impacts are also similar across demographic groups. This is also suggestive that the findings
may generalize in some other contexts.
52
Some work has investigated how different parent inputs affect child outcomes in other contexts (e.g. Paxson
and Schady 2007 on Ecuador), but this work has not examined the Head Start population.

25

References
Aizer, Anna, and Flavio Cunha. 2011. “Child Endowments, Parent Investments and the
Development of Human Capital.” Brown University Working Paper.
Becker, Gary. 1981. A Treatise on the Family. Cambridge, MA: Harvard University Press.
Becker, Gary, and Nigel Tomes. 1976. “Child Endowments and the Quantity and Quality
of Children.” Journal of Political Economy 84(4): S143-S162.
Becker, Gary, and Nigel Tomes. 1986. “Human Capital and the Rise and Fall of Families.”
Journal of Labor Economics 4(3): S1-S39.
Bertrand, Marianne, and Jessica Pan. “The Trouble with Boys: Social Influences and the
Gender Gap in Disruptive Behavior.” NBER Working Paper 17541.
Black, Sandra, Devereaux, Paul and Kjell Salvanes. 2007. “Small Family, Smart Family?
Family Size and the IQ Scores of Young Men.” Forthcoming, Journal of Human
Resources.
Brooks-Gunn, Jeanne, Greg Duncan, and Pamela Klebanov. 1996. “Ethnic Differences
in Children’s Intelligence Test Scores: The Role of Economic Deprivation, Home
Environment and Maternal Characteristics,” Child Development 67: 396–408.
Campbell, Frances, and Craig Ramey. 1994. “Effects of Early Intervention on Intellectual
and Academic Achievement: A Follow-Up Study of Children from Low-Income
Families.” Child Development 65(2): 684-698.
Chetty, Raj, John Friedman, Nathaniel Hilger, Emmanuel Saez, Diane Schanzenbach,
and Danny Yagan. Forthcoming. “How Does Your Kindergarten Classroom Affect
Your Earnings? Evidence from Project STAR.” Quarterly Journal of Economics.
Cunha, Flavio, and James J. Heckman. 2010. “Investing in our Young People.” NBER
Working Paper 16201.
Currie, Janet, and Duncan Thomas. 1995. “Does Head Start Make a Difference?”
American Economic Review 85(3): 341.
Dynarski, Susan, Joshua Hyman, and Diane Whitmore Schanzenbach. 2011
“Experimental Evidence on the Effect of Childhood Investments on Postsecondary
Attainment and Degree Completion.” NBER Working Paper 17533.
Das, Jishnu, Stefan Dercon, James Habyarimana, Pramila Krishnan, Karthik
Muralidharan, and Venkatesh Sundararaman. 2007. “School Inputs, Household
Substitution, and Test Scores.” University of San Diego Working Paper.
Deming, David. 2009. “Early Childhood Intervention and Life-Cycle Skill Development:
Evidence from Head Start.” American Economic Journal: Applied Economics 1(3):
111-134.
Epstein, Joyce. 2011. School, Family, and Community Partnerships: Preparing Educators
and Improving Schools, 2nd edition. Boulder, CO: Westview Press.
Garces, Eliana, Duncan Thomas, and Janet Currie. 2002. “Longer-Term Effects of Head
Start.” American Economic Review 92(4): 999–1012.
Gelbach, Jonah B. 2002. “Public schooling for young children and maternal labor supply.”
American Economic Review 92: 307–322.
Gibbs, Chloe, Jens Ludwig, and Douglas Miller. 2011. “Does Head Start do any Lasting
Good?” NBER Working Paper 17452.
Heckman, James J., Lena Malofeeva, Rodrigo Pinto and Peter Savelyev. 2008. “The
Effect of the Perry Preschool Program on Cognitive and Noncognitive Skills: Beyond
Treatment Effects.” Unpublished manuscript, University of Chicago.

26

Houtenville, Andrew, and Karen Conway. 2008. “Parental Effort, School Resources, and
Student Achievement.” Journal of Human Resources 43: 437-453.
Kling, Jeffrey, Jeffrey Liebman, and Lawrence Katz. 2007. “Experimental Analysis of
Neighborhood Effects.” Econometrica 75(1): 83–119.
Lee, David S. 2009. “Training, Wages, and Sample Selection: Estimating Sharp Bounds on
Treatment Effects.” Review of Economic Studies 76: 1071–1102.
Ludwig, Jens, and Douglas Miller. 2007. “Does Head Start Improve Children's Life
Chances? Evidence from a Regression Discontinuity Design.” The Quarterly Journal
of Economics 122(1): 159-208.
Magnuson, Katherine, Christopher Ruhm, and Jane Waldfogel. “Does Prekindergarten
Improve School Preparation and Performance?” NBER Working Paper 10452.
Nye, Chad, Herb Turner, and Jamie Schwartz. 2006. “Approaches to parent involvement
for improving the academic performance of elementary school age children.”
Campbell Systematic Reviews 4. doi: 10.4073/csr.2006.4.
Paxson, Christina, and Norbert Schady. 2007. “Cognitive Development among Young
Children in Ecuador: The Roles of Wealth, Health, and Parenting,” Journal of Human
Resources 42(1): 49-84.
Rosenzweig, Mark and Junsen Zhang. 2009. “Do Population Control Policies Induce More
Human Capital Investment? Twins, Birth Weight and China's "One-Child" Policy.”
Review of Economic Studies 76(3): 1149-1174.
Sacerdote, Bruce. 2007. “How Large are the Effects from Changes in Family Environment?
A Study of Korean American Adoptees.” Quarterly Journal of Economics 122(1):
119-157.
St. Pierre, Robert, G., Janet Swartz, Beth Gamse, Stephen Murray, Dennis Deck, and
Phil Nickel. 1995. National evaluation of the Even Start family literacy program:
Final report. Cambridge, MA: Abt Associates, Inc.
Todd, Petra, and Kenneth I. Wolpin. 2003. “On the Specification and Estimation of the
Production Function for Cognitive Achievement.” Economic Journal 113: F3-F33.
U.S. Department of Health and Human Services, Administration for Children and
Families. 2002. “Final Report on the Early Head Start Evaluation.”
U.S. Department of Health and Human Services, Administration for Children and
Families. 2010. “Head Start Impact Study, Final Report.”
Zhai, Fuhai, Jane Waldfogel, and Jeanne Brooks-Gunn. “Estimating the effects of Head
Start on parenting and child maltreatment.” Child and Youth Services Review
doi:10.1016/j.childyouth.2011.03.008.

27

Figure 1a and 1b. Distribution of parent involvement in the treatment and control groups in
the During period (1a) and After period (1b)

2
0
-2
-4

Parental Involvement

4

Control and Treatment Distributions of Parental Involvement

0

.2

.4

.6

.8

1

Percentile
Control Distribution

Estimated Distribution Un de r Treatment

2
0
-2
-4

Parental Involvement

4

Control and Treatment Distributions of Parental Involvement

0

.2
Control Distribution

.4

Percentile

.6

.8

1

Estimated Distribution Un de r Treatment

Notes: Figure 1a (Figure 1b) shows the distribution of parent involvement in the treatment and control
groups in the During (After) period. The darker (blue) line (lower in each figure) shows the
percentiles of the distribution in the control group, and the lighter (red) line (higher in each figure)
shows the percentiles of the distribution in the treatment group. The Kolmogorov-Smirnov test
shows that the treatment and control distributions are significantly different in the During period
(p<.001) and the After period (p<.05). The index of parent involvement is calculated by first
normalizing the parent involvement measures by subtracting the mean of each of the measures of
parent involvement listed in Appendix Table 2, dividing by the standard deviation in the control
group, and then averaging the normalized measures for each child. The figure shows that in the
During period, the impact of treatment on parent involvement appears to have been largest at the
lowest quantiles of parent involvement. The difference between the treatment and control
distributions is much smaller in the After period than in the During period, but the differences
between the treatment and control distributions also appear to be largest in the lower quantiles of the
distribution in the After period. The size of the first stage does not vary appreciably across the
distribution. Data are from the sample of survey responders (N=2,285 in the treatment group;
N=1,410 in the control group). All observations are weighted by the final parent weights.

28

.15
.1
.05
0
-.05

Impact on parent involvement

.2

Figure 2. Correlation across HS programs of effect of treatment on child cognitive scores (xaxis) and effect of treatment on parent involvement (y-axis)

-.2

0

.2
.4
Impact on cognitive scores

.6

Notes: Figure 2 shows that there is a positive correlation across HS programs of the
programs’ estimated impact on children’s cognitive scores (depicted on the x-axis) and the
programs’ estimated impact on parent involvement (depicted on the y-axis). The estimated
correlation of these effects across programs is 0.42, which is significantly different from zero
at the 1% level. “Cognitive scores” refers to the 11 measures of cognitive scores of the child
listed in Appendix A. We pool the measures of cognitive scores and run regression (5) in
which we regress cognitive scores on treatment interacted with program dummies, plus the
main effects of the program dummies. We pool the measures of parent inputs and run
regression (6) in which we regress parent inputs on treatment interacted with program
dummies, plus the main effects of the program dummies. We bin impacts on cognitive
scores into 10 equal-sized bins (of 10 percentiles each) and plot the mean of the outcome
variable within each bin.

29

Table 1. Experiment Balance on Demographics. Weighted and unweighted means of
demographic variables in the treatment and control groups, and p-values of t-tests for
differences in means.
Unweighted
Weighted
TreatTreatVariables
N
ment
Control
p-value
ment
Control p-value
Gender
Male
3,695
0.493
0.505
0.49
0.489
0.501
0.61
Female
3,695
0.507
0.495
0.49
0.511
0.499
0.61
Race
White
3,695
0.317
0.333
0.32
0.325
0.333
0.73
Hispanic
3,695
0.379
0.379
0.99
0.362
0.376
0.51
Black
3,695
0.305
0.289
0.30
0.313
0.291
0.29
Language
English
3,695
0.697
0.701
0.80
0.715
0.695
0.32
Spanish
3,695
0.303
0.299
0.80
0.285
0.305
0.32
Urban status
Urban
3,695
0.840
0.837
0.81
0.820
0.810
0.57
Non-Urban
3,695
0.160
0.163
0.81
0.180
0.190
0.57
Immigrant status
Mother
born in US
3,570
0.687
0.680
0.66
0.689
0.676
0.56
Mother not
born in US
3,570
0.313
0.320
0.66
0.311
0.324
0.56
Child age
3,570
3.92
3.92
0.94
3.92
3.92
0.92
Mother age
3,516
28.81
28.66
0.50
28.97
28.70
0.29
Father age
3,156
29.11
29.02
0.68
29.31
29.10
0.45
Other kids
3,560
1.64
1.67
0.88
1.64
1.65
0.85
Notes: The table shows that there are no significant differences in demographics across
the treatment and control groups. Gender, race, language spoken, and urban status refer
to the characteristics of the child. “White” includes “other” (non-hispanic, non-black)
races, which are aggregated together in the HSIS data. “Other kids” refers to the number
of children in the household other than the child under study. In the “weighted” columns
all observations for parents are weighted by the appropriate Fall 2002 final weights. In the
“unweighted” column, no weights are used. 2,285 children are included in the treatment
group means, and 1,410 children are included in control group means. All variables are
measured in the Fall of 2002.

30

Table 2. Effect of HS on parent involvement. The table shows coefficients and standard
errors on the treatment dummy from IV regressions of parent involvement on HS
enrollment. The instrument for whether a child was enrolled in HS is the treatment
dummy indicating that the child had access to HS. Dependent variable: measures of
parent involvement.

A) All outcomes
B) Reading and
writing activities
C) Math activities
D) Other parentchild activities
E) Qualitative
parenting measures
F) Rules and
routines
G) Tracking child
learning
H) Father
involvement
I) Parent-school
involvement
J) Teacher and
interviewer reports
Covariates
General. Hausman

(1)
0.15
(.02)***
0.20
(0.03)***
0.20
(0.04)***
0.07
(0.03)***
0.08
(0.03)**
0.13
(0.03)***
0.22
(0.04)***
0.00
(0.07)
-0.11
(0.07)
0.00***

During
(2)
0.15
(0.02)***
0.19
(0.03)***
0.19
(0.04)***
0.06
(0.03)***
0.07
(0.03)**
0.12
(0.03)***
0.23
(0.04)***
0.00
(0.07)
-0.11
(0.07)
X
0.00***

(3)
264,999
76,509
43,837
54,242
24,915
43,592
18,459
3,445
-3,097

(4)
0.06
(0.02)***
0.04
(0.03)
0.10
(0.03)***
0.07
(0.03)**
0.08
(0.03)**
0.10
(0.03)***
-0.05
(0.07)
0.01
(0.03)
0.09
(0.04)**
0.00***

After
(5)
0.06
(0.02)***
0.04
(0.03)
0.10
(0.04)***
0.07
(0.03)**
0.07
(0.03)**
0.09
(0.03)***
-0.06
(0.06)
0.01
(0.03)
0.09
(0.04)**
X
0.00***

(6)
320,439
70,652
31,879
52,981
49,298
35,258
-6,693
62,356
25,577

Notes: The table shows the results of regressions in which measures of parent involvement
listed in Appendix Table 2 are related to HS enrollment or access. Following Kling, Liebman,
and Katz (2007), we normalize the outcome variables by subtracting their mean and dividing by
their standard deviation in the control group. We then form the coefficient estimate by running
IV regression (2) of each outcome on HS enrollment, in which HS enrollment is instrumented
using HS access, and averaging the coefficient estimates across regressions. We form the
standard error by pooling the outcome variables and running IV regression (2). In Row A we
report the results in which all outcome variables are pooled; in rows B-J we report the results on
distinct categories of variables (defined in Appendix Table 2). The generalized Hausman test
examines the hypothesis that across all of the reduced form regressions (3), the coefficients on
treatment are jointly different from zero. “Covariates” in Columns 2 and 5 include dummies for
child gender, race, language at home, and whether the child resides in an urban area, which are
added as independent variables to regressions (1) and (2). Columns 3 and 6 show the number of
observations in each category; the N’s in each separate category do not add up to the total for
“all outcomes” because we do not include interviewer reports in “all outcomes.” Columns 1-3
show information for the During period, and Columns 4-6 show information for the After
period. Standard errors are clustered at the level of the program. All observations are weighted
by the final parent weights. The number of unique individuals represented in the regressions is
3,916. The first-stage F-statistics when we pool all outcomes without (with) covariates is 537.34
(543.48) in the During period and 490.43 (495.22) in the After period; all of the other first-stage Fstatistics are over 375. *** denotes significance at the 1% level; ** at the 5% level; and * at the
10% level.

31

Table 3. Effect of HS on particular parent involvement outcomes. The table shows coefficients and
standard errors on the treatment dummy from probit, ordered probit, or IV regressions of parent
involvement on HS enrollment. Dependent variable: measures of parent involvement (listed in column
headings)
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
Number
How long
Minutes
Days with Practiced
Visited
Track
Learning
of Times
read
reading
father
math
art gallery
child’s
materials
Read
learning
available
Panel A: During
HS enrollment
R-squared
Log-likelihood
N
Panel B: After
HS enrollment

0.21
(0.09)***
--1956648
7257

2.78
(0.82)***
0.00
-7211

18.71
(4.79)***
0.00
-7232

0.01
(0.06)
--2003609
7075

1.46
(0.81)*
0.00
-7035

7.04
(4.78)
0.00
-7051

0.91
(0.85)
--249374
1729

0.26
(0.09)***
--1161974
3678

0.12
(0.07)*
--744096
7257

0.37
(0.09)***
--548854
3693

0.10
(0.07)
--5679
3097

1.38
0.15
0.03
-0.09
(0.69)***
(0.07)*
(0.06)
(0.06)
-----R-squared
-0.00
-1092651 -857878
-10212
Log-likelihood
3539
-5908
3336
7072
N
Notes: The table shows the results of regressions in which measures of parent involvement are
related to HS enrollment or access. The dependent variable in question is listed in each column
heading. The regression is a probit in Columns 5 and 6; an ordered probit in Columns 1, 4, and 8;
and two-stage least squares in Columns 2, 3, and 7. In Columns 1, 4, 5, 6, and 8, we form the Wald
estimate by dividing the coefficient estimate by the first stage (0.68). The table shows coefficient
estimates and standard errors; since the regressions are estimated using different methods, these coefficient
estimates must be interpreted accordingly. Panel A shows results for the During period, while children
are potentially enrolled in HS, and Panel B shows results for the period after which children are
potentially enrolled. The standard deviation of the dependent variable in the During (After) period is
15.97 (16.13), 103.0 (101.3), and 9.53 (8.41) in Columns 2, 3, and 4 respectively. Standard errors are
clustered at the level of the program. All observations are weighted by the final parent weights. In
Column 1, the dependent variable is the number of times a parent read to the child per week (ordered
in categories). In Column 2, the dependent variable is how long in minutes the parent read to the
child at each sitting. In Column 3, the dependent variable is how many minutes per week the parent
reads to the child, constructed by multiplying the dependent variables from Columns 1 and 2. The
sample size is slightly bigger for the constructed variable in Column 3 than in Column 2 because
those occasional individuals who report that they do not read to their child (as recorded in Column 1)
do not answer the question about how many minutes per sitting they read to their child (in Column
2), but we infer in constructing the dependent variable in Column 3 that they read to their child 0
minutes per week. In Column 4, the dependent variable is “In the past month, on about how many days
has [CHILD] seen (his/her) father.” In Column 5, the dependent variable is “Use dance or act out stories
to practice math ideas such as numbers or size.” In Column 6, the dependent variable is “Visited an art
gallery, museum, or historical site.” In Column 7, the dependent variable is “Track how child learns and
grows by keeping notes about (his/her) behavior or progress”; this variable is not available in the After
period. In Column 8, the dependent variable is “A variety of learning materials are available,” which is
reported by the HSIS interviewer. The results are extremely similar when controlling for the covariates
included in Columns 2 and 5 of Table 2. *** denotes significance at the 1% level; ** at the 5%
level; and * at the 10% level.

32

Table 4. Alternative specifications. The table shows coefficients and standard errors on
the treatment dummy from IV (reduced form) regressions of parent involvement on HS
enrollment (access). In the IV regressions, the instrument for whether a child was
enrolled in HS is the treatment dummy indicating that the child had access to HS.
Dependent variable: pooled measures of parent involvement
Reduced form
(1) Final
(2)
(3) Lee
parent
Jackknife
lower
weights
weights
bound
Panel A: During
Coefficient
on HS
F-statistic in
first stage
N
Panel B: After
Coefficient
on HS
F-statistic in
first stage
N

(4)
Center
Access

Normalized IV
(5) Inc.
(6) No
(7)
medical
weights
Alternative
variables
Imputation

(8)
IV for time
in HS

0.10
(0.02)***
--

0.10
(0.02)***
--

0.04
(0.02)**
--

0.19
(0.03)***
276.89

0.16
(0.03)***
541.19

0.14
(0.02)***
949.75

0.14
(0.02)***
528.07

0.15
(0.02)***
537.34

264,999

264,999

264,999

264,999

284,394

264,999

429,528

264,999

0.04
(0.02)***
--

0.04
(0.02)**
--

-0.01
(0.02)
--

0.08
(0.03)***
249.92

0.06
(0.02)***
493.76

0.03
(0.02)**
933.98

0.07
(0.02)***
564.29

0.05
(0.02)***
256.67

320,439

320,439

320,439

320,439

348,210

320,439

663,504

320,439

Notes: In Columns 1-3, we run the reduced form regression (3), in which we pool measures of
parent involvement and regress them on the dummy measuring HS access. In Column 1 (as well
as Columns 3-8), we use the final parent weight in weighting the observations. Column 1 shows
that the IV regressions have very similar significance levels to the OLS regressions, and that the
coefficient estimates in the IV regressions are approximately 1.47 multiplied by the coefficient
estimates in the OLS regressions. In Column 2, we use the jackknife variance weights that are
meant to account for sampling error in forming a nationally representative sample, as discussed in
Appendix A. In Column 3, we show the Lee (2009) lower bounds on the treatment effect from
the pooled reduced form regression (3), with standard errors calculated as suggested in Lee
(2009). These bounds are for the intent-to-treat, so we do not show an IV version of the bounds
regressions. In Column 4, we show the results when we instrument for whether the child was in
any center-based program using the HS dummy. In Column 5, we include medical outcomes in
the analysis, such as whether the parent took the child to a doctor’s appointment. In Column 6, we
use no weights. In Column 7, we show the results when we run the two-stage least squares
regressions (1) and (2) and impute missing data by matching missing and non-missing
observations using a propensity score, as described in Appendix A. The sample size is
substantially larger than the other columns because we sometimes match observations to multiple
nearest neighbors (in those cases in which multiple neighbors are equally near). In Column 8, we
instrument for the amount of time an individual is enrolled in HS using the treatment dummy
interacted with dummies for the 3-year-old and 4-year-old cohorts, as described in the text. Panel
A shows results for the During period, and Panel B shows results for the After period. All of
the results are extremely similar when we use the controls in Table 2. Standard errors are
clustered at the level of the program, except in Column 2 in which we use the jackknife
procedure. *** denotes significance at the 1% level; ** at the 5% level; * at the 10% level.

33

Appendix A: Description of Variables and Sample Selection
This appendix describes how we construct the variables and sample in the analysis in the paper.
Our sample size is slightly smaller than that in HHS (2010) because the data provided to us
exclude Puerto Rico, whereas HHS (2010) includes Puerto Rico.
The regression sample sizes are sometimes slightly different from table to table. This is because
when using independent variables from different samples, there are different amounts of missing
data. As a rule, for each table we drop each observation that is either missing the dependent
variable or missing all of the independent variables. When only some of the independent
variables are missing, we “dummy out” the missing observations by setting missing variables
equal to the mean of the variables for the non-missing observations and controlling for a dummy
that equals 1 when that variable is missing and 0 otherwise. The results are robust to dropping all
observations when at least one independent variable is missing.
Final weights are calculated for parent interview questions and child cognitive and non-cognitive
measures in each year, in order to make the sample nationally representative of the Head Start
population. We use the appropriate weights for each variable. When the regressions include
observations on both parent involvement and cognitive scores, we use the weights that are
appropriate to the left-hand-side variable in question. The correlation among the weights is near
1, and the results are robust to using any set of weights.
Parent age, number of other children in the household, and immigration status are not
observed for all individuals and therefore have smaller sample sizes. As a result, we do not
include these as control variables in the regressions reported, although the results are very
similar if the missing values are dummied out.
Consistent with most previous literature on experiments, we use the final weight for variance
estimation. As shown in Table 4, using the jackknife variance weights gives similar results but
generally gives standard errors that are approximately 20% larger. This implies that the estimated
significance levels generally do not change, but in rare cases they drop. Results from Appendix
Table 2 using the jackknife weights are available from the authors upon request. The weights
that we use for variance estimation are appropriate for estimating the variance of the estimates on
the sample of HS Centers examined in the experiment. The jackknife weights are ostensibly used
to make the sample nationally representative, but the experiment was only run on over-subscribed
HS centers, which may differ systematically from other HS centers even after applying the
calculated weights.
We typically cluster our standard errors at the HS program level, which is the most aggregated
available partition of our sample. In Figure 2, we also run a bootstrap to calculate the standard
error on the correlation between the fixed effects-treatment interaction on parent involvement and
cognitive scores, running 100 replications and sampling at the program level.
For the cognitive and non-cognitive variables, we use all of the measures analyzed in HHS at the
end of the experiment. Eleven cognitive measures from Spring 2003 are reported: 1) Preschool
Comprehensive Test of Phonological and Print Processing: Elision, which measures the phonetics
of words, syllables, and phonemes; 2) Peabody Picture Vocabulary Test III (Test de Vocabulario
en Imágenes Peabody for Spanish speakers), which measures vocabulary knowledge and
receptive language; 3) Counting Bears, which measures ability to identify one-to-one
correspondence; 4) Color Names, which measures color identification; 5) McCarthy Draw-ADesign, which measures perceptual motor skills; 6) Letter Naming, which measures the ability to

34

recognize letters of the alphabet; 7) Woodcock-Johnson III Applied Problems, which measures
the ability to analyze and solve math problems; 8) Woodcock-Johnson III Oral Comprehension,
which measures oral comprehension using syntactic and semantic clues; 9) Woodcock-Johnson
III Spelling, which measures early writing and spelling; 10) Woodcock-Johnson III Letter-Word
Identification (Woodcock-Muñoz Letter-Word Identification for Spanish speakers), which
measures letter and word identification skills; and 11) emergent literacy scale which measures
literacy. The last of these measures is reported by parents; all of the results in the paper are
extremely similar when we exclude this measure from the analysis. Nine indeces measuring noncognitive skills are analyzed in the report, pertaining to the following domains: 1) aggressive
behavior; 2) hyperactive behavior; 3) closeness; 4) conflict; 5) positive relationships; 6) social
competencies; 7) social skills and positive approaches to learning; 8) problem behavior; and 9)
withdrawn behavior. All of these variables are reported by parents. The directions of all the
variables are made consistent, so that the measures of “positive” behavior (such as “positive
relationships”) are increasing while negative behavior (such as “conflict”) are decreasing. For
both cognitive and non-cognitive measures, in order to make the variables comparable across
measures, we standardize each variable by subtracting the mean and dividing by the standard
deviation of the variable in the control group. Finally, in Table 5, we take the average of all the
normalized cognitive scores as our measure of cognitive scores, in order to reduce the sample size
by an order of magnitude and keep it in the hundreds of thousands; the results are nearly identical
if we stack each measure instead.
In order to address the fact that some observations of the dependent variable are missing, we
undertake an alternative procedure to impute missing data in Column 7 of Table 4. We exploit
the fact that the data include demographic information on all children, including those missing in
every year. Specifically, we have information on child gender, race, language at home, and
whether the child resides in an urban area for both missing and non-missing children. For
each time period, we run a probit to calculate the propensity of being in the sample.
Specifically, we run a probit in which the dependent variable is a dummy for being missing
and independent variables are all of the demographics above and their interactions along
with dummies for the HS centers to which the parents applied, weighting each observation
by the child base weight (which is available for all children and adjusts for the probability of
being sampled but does not adjust for non-response). We then replace missing data with data
on the nearest non-missing neighbor as given by the propensity score, weighting the imputed data
by the missing individual’s base weight.
In the text, we mention the results of a factor analysis of the variables, which are displayed in
Appendix Table 3. A factor analysis can only be run on observations that are missing no data for
any variable. While there is a large overlap across samples, different questions are asked in
different years. To address this issue, we run the following separate factor analyses in the During
period: one on the Fall 2002 data, one on the Spring 2003 data (excluding the questions asked of
households missing a father), and one on the question asked of the single mother households.
Using the Kaiser criterion, the process yielded two factors in Fall 2002, two factors in the Spring
2003 main sample, and no factors for the single parent household variables as the procedure did
not find enough commonality between these variables. In the After period, different questions
were asked by grade level, leading to a consistent set of questions for the kindergarten sample
(the 4-year-olds in Spring 2004 and the 3-year-olds in Spring 2005) and the first grade sample
(the 4-year-olds in Spring 2005 and the 3-year-olds in Spring 2006). Again, we ran a separate
factor analysis on the questions asked of single mother households and the teacher-reported
variables (since project staff were unable to interview every kindergarten and first grade teacher,
leading to about 25% otherwise non-missing children missing data for teacher reports; we use the
teacher interview weights for these variables). The procedure yielded five factors in the main

35

kindergarten sample, four factors in the main first grade sample, and no factors in the other
samples that have substantially fewer variables. Given these issues relating to missing data, the
sample sizes tend to be smaller than in the other analyses, and they also vary across periods and
samples. The results are robust to alternative means of addressing these issues—either imputing
each missing variable or adding indicators for all missing variables and including them in the
factor analysis.
In Appendix Table 5, we employ 58 measures of the degree to which HS centers encouraged
parents to be involved with their children or otherwise interacted with parents. We use these
measures to instrument for parent-reported measures of parent-center involvement. These
measures are collected for children who attend any center-based child care, for both children in
the treatment and control groups, including both HS and other forms of child care such as non-HS
preschool or day care. For those children who did not attend any center-based care—typically
children who are cared for at home—we set the values of the variables measuring center
directors’ reports of center encouragement to zero because parents of those not in a center
mechanically received no encouragement from a center; the results are similar when setting these
values to missing rather than zero, or when using a propensity score (estimated using all available
demographics) to match missing and non-missing observations and replace missing with matched
non-missing observations.
The characteristics of the center a child attends are potentially correlated with unobserved
determinants of parent involvement, for example because parents who invest more in their
children could systematically choose to send their children to better centers (particularly in the
control group). Thus, in order to form the cleanest possible measure of the degree to which the
center encourages parent involvement, we exclude own observations in forming the measure of
center encouragement and only include the compliers. In other words, for individual i in
experimental group g in program p, we calculate measure m of center-based encouragement as
follows:
n

(7) Encouragementipgm

gp
1
=
∑ Encouragementgp
ngp − 1 j =1, j ≠i

Here m indexes all 58 measures of center encouragement; experimental group g∈{0,1} indexes
whether individual i is in the treatment or control group; and ngp represents the number of
compliers in experimental group g in program p.53 (The results are similar regardless of whether
we measure encouragement based on the average of the observations of others in the program and
experimental group or based on the encouragement measure of the actual center that each child
attended.) We only use data on those individuals that comply with their treatment status in each
individual’s program experimental group in order to form these measures of center
encouragement (excluding own observations as described above); the results are extremely
similar when using data on all individuals in order to form the measures of center encouragement.
We obtain similar results when we aggregate to the level of the center and experimental group,
rather than the program and experimental group (but do so on the level of the program because
the Appendix Table 5 regressions effectively rely on variation at the level of the program).
Children’s parents can decide whether to participate in the opportunities offered by the centers,
such as volunteering in the center or seeking or accepting help from the center in providing
53

For compliers in the treatment group, this measure of encouragement is the same for all children in a
given center.

36

medical care for their child. Thus, the eight parent-reported variables relating to involvement in
their center are potentially endogenous to parent involvement but still contain information on the
degree to which the center encouraged parent involvement. The parent-reported measures of
involvement in the center therefore serve as natural endogenous variables. We measure these
variables at the level of the individual child. These measures are instrumented using the director
reported measures, in order to address the possibility of error in measuring the degree to which a
center encouraged parent involvement.
Appendix B: Description of Similarities and Differences from HHS (2010)
Overall, we view our results as complementary to HHS (2010). There are just a few similarities
between our paper and HSIS. In the main tables and figures of our paper, there is no overlap.
Overall, HHS (2010) finds only scant evidence that HS affected parent involvement. Only one of
61 measures of parent involvement that HHS (2010) examines is found to have been significantly
affected by treatment at the 5% level after performing a correction for multiple comparisons.54
(Each of the 9 outcomes HHS (2010) examines was observed in multiple time periods, making 61
total.) In Appendix Table 2, 5 outcomes that we use are also examined in HHS (2010), but 84
other parent involvement outcomes that we use are not analyzed at all in HHS (2010). Among
these 5 outcomes (dentist visits, one measure of reading with children, cultural activities, school
contact, and parent participation in school), we examine the reading and dentist variables
differently than HHS (2010). HHS (2010) codes the reading variable as binary, but we keep in its
original multiple-category form. We exclude observations of the dentist variable for which the
parent reported that HS helped them get the care for their child (in Table 4 where this variable is
used), while HHS (2010) did not, and we wholly exclude the dentist outcome when aggregating
results in the main tables. (The purpose of HHS (2010) is to investigate how attending HS
influences the receipt of dental care, and thus it make sense that HHS (2010) included these
observations. By contrast, we are interested in abstracting from the effect that HS-specific
measures had on parent involvement, in order to understand the mechanisms that underlie the
effect of HS on parent involvement. Our results are extremely similar whether or not we exclude
these variables.)
There are also four other “parent” measures that HSIS include in their report that we do not
include in our analysis (spanking, use of timeout, a 10-item safety precaution scale, and
“parenting style”). Among other reasons, we do not include these because they are difficult to
interpret as parent involvement. Spanking and the use of timeout are difficult to interpret as
measures of parent involvement because they may be a reaction to the children’s behavior, and
also because parents may spank and send their children to timeout less because they are
mechanically around their children for fewer hours in the day. The 10-item safety precaution
scale includes questions, for example, about whether the parents have a working smoke detector
in the home, a choice that does not necessarily relate directly to investment in children. Parenting
style, such as the degree of authoritativeness, is classified via Baumrind’s typology of parenting
styles, but none of these parenting styles necessarily indicates greater or lesser investment with
children. Again, the examination of these measures are fully consistent with the goal of the HSIS
analysis, which is about understanding the broad impacts of HS; nonetheless, for our purposes,
they are often difficult to characterize as parent involvement.

54

HHS (2010) corrects for multiple comparisons within each of several time periods and within each of the
two cohorts, so that the typical correction they perform is across approximately 7 outcomes.

37

HHS (2010) finds that none of the measures is significantly affected after the experiment, which
is at odds with our finding of a positive and statistically significant impact on parent involvement
in the After period. HHS (2010) always examines each cohort-time period separately and does
not include data from Fall 2002.
Appendix C: Description of Jackknife Procedure and results in Appendix Table 5
Let g∈{0,1} be an indicator for the experimental group in question, which equals 1 if an
observation is in the treatment group and 0 if an observation is in the control group. Similarly to
Chetty et al. (2011), we calculate the quality of each individual i’s program p in the During
period (CQualip) as the difference between the average scores of the ngp-1 other students from i’s
program p and experimental group g and the average scores of the m-gp students assigned to i’s
program p in the opposing experimental group -g:55

(8) CQualip =

1
1
Cog jp !
$
ngp ! 1 j"g , j#i
m! gp

$ Cog

kp

k"! g

This serves as a measure of the program’s quality because high-quality programs will tend to
have larger differences in mean cognitive scores between the treatment group and the control
group (excluding own score).56 To form the measure of cognitive scores in (8), we normalize each
child’s cognitive measures to have mean 0 and standard deviation 1 and take the mean.
In Column 1 of Appendix Table 5, we then regress normalized parent inputs for individual i on i’s
cognitive scores, pooling data on all measures of parent inputs. In particular, the “reduced form”
regression we run in Columns 1-3 of the table is:

(

)

(9) Involvement ip = ! o + ! 1 Tip *CQualip + ! 2Tip + ! 3CQualip + " p + # ip
where α1 represents the coefficient of interest on the interaction between treatment and the
measure of program quality (Tip*CQualip); Tip represents the treatment dummy; and δp represents
program fixed effects. Intuitively, these regressions estimate the association between parent
inputs and an increase in cognitive scores (after conditioning on the main effect of treatment, the
main effect of program quality, and program fixed effects). Column 1 of Appendix Table 5 shows
that program quality is highly correlated with parent involvement: the coefficient on program
quality in the During (After) period is 0.25 (0.13), with a standard error of 0.09 (0.07)
(significantly different from zero at the 1% (10%) level).57
55

The “opposing experimental group” of the treatment group is the control group, and the “opposing
experimental group” of the control group is the treatment group.
56
We calculate this measure for both individuals in the treatment and control groups; within a program, the
measure of quality will therefore tend to be positive in one experimental group and negative in the other.
57
Note that when we perform our regressions in the After period, we form our measure of program quality
using cognitive or non-cognitive scores from the During period, whereas our dependent variable is formed
using parent involvement measures from the After period. Thus, it is important to note that in these
regressions, we are effectively correlating program impacts on cognitive or non-cognitive scores in the
During period with program impacts on parent involvement in the After period. We do so because
cognitive and non-cognitive scores are insignificantly affected by treatment in the After period (as shown in
Appendix Table 4), so there is effectively no useful variation in cognitive or non-cognitive scores across
programs in the After period. When we instead construct a measure of program quality using cognitive or
non-cognitive scores in the After period, we find that these are insignificantly associated with impacts on
parent involvement. It remains of interest to investigate whether impacts on cognitive or non-cognitive

38

We analogously calculate a measure of the program’s quality NCQualip based on children’s noncognitive scores NCog:

(10) NCQualip =

1
1
NCog jp !
$
ngp ! 1 j"g , j#i
m! gp

$ NCog

kp

k"! g

In Column 2 of Appendix Table 5, we use this measure of program quality based on normalized
non-cognitive scores of peers in the program and use NCQual in regression (9) instead of CQual.
This shows that peers’ non-cognitive scores have no significant association with parent inputs in
the During period (and a marginally significant association in the After period). When we add
both measures of program quality to the regression in Column 3, the cognitive score-based
measure of program quality picks up most of the variation in both the During and After periods.
In the During period, the coefficient on the cognitive score-based measure of program quality is
significantly different from zero at the 5% level, whereas the point estimate of the coefficient on
the non-cognitive score-based measure of program quality is small and insignificantly different
from zero.
As an alternative, we follow the spirit of Chetty et al. (2011) by instrumenting for cognitive (noncognitive) scores with the interaction of program quality and treatment status. In particular, the
first stage regression for cognitive scores is:

(

)

(

)

(11) Cog ip = ! o + !1 Tip *CQualip + ! 2 Tip * NCQualip + !3CQualip + ! 4 NCQualip + !5Tip + " p + uip
where β1 and β2 represent the coefficients on the interactions between treatment and the measures
of program quality (Tip*CQualip and Tip*NCQualip, respectively), which serve as excluded
instruments. We run an analogous first-stage regressions in which non-cognitive scores and Head
Start attendance serve as the dependent variables. The second stage is:

(12) Involvement ip = ! o + ! 1CHAT + ! 2 NCHAT + ! 3CQualip + ! 4 NCQualip + ! 5 HSip + " p + vip
Here CHAT represents the fitted values from the first stage regression (10), NCHAT represents
the fitted values from the analogous first stage regression for non-cognitive scores, HS represents
the fitted values from the first stage regression of the Head Start enrollment dummy on the Head
Start access dummy, and γ1 and γ2 represent the coefficients of interest.58 In the During period,
the regression in Column 4 confirms the finding that effects on cognitive scores are highly
correlated across programs with effects on parent involvement, whereas non-cognitive scores
have no significant association with parent involvement.59 In the After period, cognitive and non-

scores in the During period are correlated with impacts on parent involvement in the After period, for
example because parents in the After period could observe the impact on child cognitive scores in the
During period and expect them to continue to the After period.
58
This regression could estimate biased effects of cognitive scores on parent involvement if the effects of
treatment on cognitive scores are correlated across programs with unobserved determinants of parent
involvement. We emphasize that our primary goal in Appendix Table 5 is rather to estimate the association
between program effects on cognitive scores and on parent inputs.
59
When we put cognitive or non-cognitive scores in the IV regression separately (as in the reduced form
regressions in Columns 1 and 2), we again estimate that cognitive scores have a highly significant positive
association with parent involvement and that non-cognitive scores have an insignificant positive association
with parent involvement.

39

cognitive score impacts are both insignificantly associated with parent involvement, though the
point estimates are both positive.60
In Columns 5 and 6, we investigate how these results are affected by controlling for other
factors that could mediate the relationship between Head Start enrollment and parent inputs.
As noted in the text, it is possible that certain programs could be particularly effective both in
raising cognitive scores and in raising parent inputs. However, we find that the degree to which
programs encourage parent involvement has little association with the estimated effects.
In Column 5, we show that the coefficient on cognitive scores is little changed from Column
4 by controlling for center directors’ detailed reports of measures that their centers sponsor that
involve parents. Center directors in both the treatment and control groups filled out an exhaustive
survey about ways in which their center encouraged parents to be involved in school-related
activities or otherwise may have interacted with parents. (For those in the control group, these
variables measure the degree to which their childcare center encouraged these activities).61 These
58 variables, listed in Appendix Table 1, include detailed questions about the degree to which
parents volunteer in the center, detailed aspects of the services provided to the community by the
center (such as through parent education meetings), and other ways parents might be included in
the preschool experience (such as informing parents of their children’s progress in school or
home visits by center staff). These arguably collectively constitute the main ways that HS may
potentially involve parents. Note that moreover, we do not take a stand a priori on which of these
measures, if any, influences parent involvement; rather, the regressions will reveal which if any
of these measures is correlated with parent involvement.
These reports by center directors of the actions their centers take to involve parents may measure
with error the degree to which the center encourages parent involvement. In order to address this
concern, we instrument for one measure of the degree to which centers encouraged parent
involvement using another measure, in the hope that these two measures may have uncorrelated
measurement errors.62 Parents also reported eight measures of ways in which they are involved
with their children’s center-based program (which again may include Head Start, other
preschools, or other childcare centers) or ways in which the program involves the family, and

60

As in Chetty et al. (forthcoming), interpreting these results is potentially confounded by the presence of
peer effects. With peer effects, a high ability student may raise his peers’ scores; since cognitive ability and
parent involvement are correlated in a cross-section of students, this could lead in a finite sample to a
positive correlation across programs in the estimated effect of treatment on peers’ cognitive scores and
peers’ parent involvement. While we cannot entirely purge our estimator of the influence of peer effects,
peer effects are likely to account for at most a tiny fraction of the correlation documented in Appendix
Table 5 (much as Chetty et al. argue in their context). This is because the results are estimated with
variation at the level of the program, which on average enrolls a total of over 400 students, representing
children spread across multiple locations and multiple classrooms within a location. A treated student in
our sample shares a classroom (that has an estimated mean class size of 18.5 students) with a mean of 1.37
out of the 36.16 other treated children from each program in our sample. In a linear-in-means model of peer
effects, this implies that the scope for potential peer effects within the treatment group is very small and
highly unlikely to explain even a minor part of the strong correlation documented in Figure 2 and Appendix
Table 5.
61
A “center” may include a childcare center, preschool or pre- kindergarten program. The construction of
these variables is discussed in Appendix A.
62
When we control for the 58 center director reports and omit parent reports from the regression equation,
rather than using the 58 center director reports as instruments for parent reports—that is, we run the
reduced form regression—we estimate qualitatively similar results to those shown in Columns 5 and 6.

40

these parent reports are in fact highly correlated with the director reports (with first-stage Fstatistics typically in the hundreds).63
Consistent with the argument that the measures HS centers took to involve parents have little
association with the impacts on parent involvement, Appendix Table 5 shows that the average
coefficient on the eight normalized parent-reported center measures is small and insignificantly
different from zero. Moreover, the next row of Appendix Table 5 shows that the F-statistic on
parent reports of measures that HS centers took to involve them indicates that they are jointly
insignificantly different from zero in the During and After periods in both Columns 5 and 6. In
comparison with the estimated coefficients on cognitive (or non-cognitive) scores, the average
point estimate of the coefficients on center measures is very small. The estimated association
between cognitive scores and parent involvement is also insignificantly different in Columns 4
and 5 in both the During and After periods (p>0.40).
We also may be interested in the extent to which changes in measures of parent labor force
participation are associated with the changes in investment in children. To shed some suggestive
light on this question, we additionally control for (endogenous) measures of mothers’ and fathers’
labor force participation in the During (After) period. The presumption that these should matter
little to the results—given the weak effects of HS enrollment on parent labor force participation
later estimated in Appendix Table 6—is confirmed. The coefficients on cognitive and noncognitive scores are little changed by controlling for parents’ labor force participation from
Column 5 to Column 6 (p>0.40).
These results document an association between program effects on parent involvement and
program effects on cognitive scores (or, to a lesser extent, non-cognitive scores). Unsurprisingly,
these program effects are also estimated to be positively correlated when the dependent variable
is formed by pooling normalized cognitive score measures, and the independent variable is
constructed by forming a measure of program quality based on the extent to which it raises parent
involvement.64 We implement this in Column 7 of Appendix Table 5. Specifically, we form a
measure of program quality based on the difference in normalized mean parent involvement in
the During period in the treatment and control groups, which we call PQualip:

(13) PQualip =

1
1
Parent jp !
$
ngp ! 1 j"g , j#i
m! gp

$ Parent

kp

k"! g

We then pool cognitive scores and regress these on the parent involvement-based measure of
program quality formed above:

(

)

(14) Cog ip = !o + !1 Tip * PQualip + !2Tip + !3 PQualip + " p + # ip
63

These measures are the following: how often the parents attended parent teacher/child-care provider
conferences, how often the parents attended parent education meetings or workshops, how often the
parents volunteered in the childcare setting, how often the parents attended or helped out with
activities such as fieldtrips, fundraising, policy council, or other planning activities, how often
parents participated in other activities at the child’s setting, whether the center staff visited the home,
whether the center helped the parents acquire dental care for their child, and whether the center
helped the parents acquire a health screening for their child.
64
As noted in the text, the cross-program correlation of effects on parent involvement and effects on
cognitive scores could arise inter alia from effects of cognitive scores on parent involvement, or vice versa.

41

Column 7 of Appendix Table 5 reports the coefficient ϕ1 from this regression, showing that
program effects on parent quality and cognitive scores are again highly positively and
significantly correlated in both the During and After periods. Implementing the IV version of this
regression (analogous to the specification in Columns 4-6) again shows similar results. When
non-cognitive scores are made the dependent variable, and parent involvement-based measure of
quality is the independent variable of interest (as in Column 7), the results again show a weaker
and insignificant correlation between the two.
Collectively, these results are suggestive of the conclusion that parent inputs are strongly
associated across HS programs with gains in cognitive scores, somewhat associated across HS
programs with gains in non-cognitive scores, but little (and insignificantly) associated with
observable measures that centers take to involve parents, and little (and insignificantly) associated
with changes in parent time allocation. (Note that parent inputs are little associated with
observable measures that centers take to involve parents even though these center directorreported characteristics do successfully predict parent-reported parent involvement in center
activities, indicating that the measures reported by center directors do provide useful
information.) As we note in the text, in keeping with the spirit of results, which document an
association of parent involvement with cognitive scores but not with Head Start center
characteristics, when we instrument for own cognitive scores using the cognitive scores of peers
in Column 4 of Appendix Table 5, the coefficient on the HS dummy is greatly affected—
decreasing from 0.16 when we implement the specification in Appendix Table 5 without
including cognitive scores as a regressor, to 0.08 when we do include cognitive scores (p<.01)—
but when we control for HS center characteristics in Column 5, the coefficient on the HS dummy
stays at 0.08 (p>0.40). Similarly, when we run the regression from Table 2 Row A and control for
cognitive scores, the coefficient on the HS dummy is greatly affected (going down by 56%, p<.01
for the test of equal coefficients to Table 2 Row A), but when we control for HS center
characteristics, the coefficient on the HS dummy is insignificantly affected (p>0.40) and the point
estimate changes little. Unsurprisingly, controlling for changes in parents’ time allocation in the
Table 2 Row A also matters negligibly to the coefficient on the HS dummy (p>0.40).
Nonetheless, due to the caveats noted above—omitted variable bias may impact how to interpret
the coefficient estimate on the program quality measures, and it is possible that parent inputs
could be partly responsible for the increase in cognitive and non-cognitive measures, rather than
the reverse—we stress that the results in this section constitute suggestive, rather than definitive,
evidence.
Appendix D: Description of Appendix Table 6 Results not Discussed in Main Text
Appendix Table 6 Panel A shows the estimated effect of HS on parents’ choices. Row A shows
that childcare expenses fall significantly in response to Head Start enrollment. Rows B through E
show that both during and after the experiment, mothers’ and fathers’ probability of working is
affected insignificantly by treatment at the 5% level.65 (Though note that the confidence intervals
are wide enough that we cannot rule out substantial changes in work.)

65

The finding of no significant effect of HS on mothers’ labor supply is perhaps surprising in light of the
finding of Jonah Gelbach (2002), who found strong effects of child schooling opportunities on mothers’
labor supply. The discrepancy in the results suggests either that HS represents a substantially different
context or study population than that in previous studies or that such effects exist but the sample size is not
large enough for us to detect effects. The effect on fathers’ probability of working in the During period is
insignificant at the 10% level under our alternative imputation procedure in Column 4 of Table 2.

42

Further insight on children’s time allocation is gained by investigating the impact of HS on other
measures of children’s time in Appendix Table 6 Panel B. There is a positive and significant (at
1%) effect of HS on non-parent childcare (Row F). By contrast, there is a strong negative and
significant (at the 1% level) effect of HS on weekly hours at a center-based daycare other than HS
(Row G), on weekly hours at a day care run from a home (Row H), and on weekly childcare
hours with non-parent relatives (Row I).66
Appendix E: Conceptual Framework
This appendix presents a toy conceptual framework. The goal of this appendix is to sketch an
extremely stripped-down framework that is consistent with the empirical findings, specifically
that parent inputs rise when children are enrolled in Head Start, that this effect is correlated with
the effect of Head Start on child cognitive scores, and that total parent-child time may have
decreased. The aim is simply to fix ideas about a small number of key determinants of parents’
decisions, in order to illustrate that the findings may be consistent with a simple framework,
rather than to present a fully-fledged model of parent investment and child schooling. This model
is taken as representing parents’ choices in the During period, while children are potentially
enrolled in Head Start.67
Parents maximize their utility U, which is defined over parent-child teaching time P1, parent-child
non-teaching time P2, non-child parent time N, and child quality V:

(15) max U = U(P1 , P2 , N,V )
P1 ,P2

We assume that Ui>0 and Uii<0 for all i (and that U is twice continuously differentiable in all of
its arguments). The subscript i on U denotes the partial derivative of U with respect to the i-th
argument. Parent-child teaching time P1 represents the time parents spend engaging in activities
that are likely to have a particularly large positive effect on their children’s human capital. Other
parent-child time P2 represents other activities that parents may do with their children, such as
watching TV while their children are in the room, that are less likely to raise their children’s
human capital. We include two possible types of parent-child time in order to accommodate the
possibility that total parent-child time falls even while parent-child investment time rises, which
is indicated by the empirical results. (Appendix Table 6 Panel B shows that HS access raises
children’s weekly number of hours in childcare including HS (other than childcare by parents) by
11.71 hours per week, and the effect is significantly different from zero at the 1% level.
Assuming that children must either be with their parents or in non-parent child care—a
reasonable approximation for 3- and 4-year-olds that we discuss further when we present the time
budget constraints below—this implies that total time with parents must have decreased.)
Non-child parent time N encompasses all other activities that parents may engage in, including
market work, leisure, and housework not involving children. We collapse all other parent
activities into a single aggregate under the rationale that distinguishing, for example, between
work and non-work activities is not central to the mechanisms we intend to illustrate in this

66

Weekly hours at a center-based daycare other than HS and weekly hours at a daycare run from a home
are mutually exclusive categories and differ because receiving home-based daycare rules out the possibility
that this daycare is run at a center.
67
A framework with multiple periods—i.e. both During and After periods—would complicate the
presentation while not providing additional insight about the interaction of Head Start and parents’ and
children’s budget constraints, which are the focus of the model presented.

43

appendix.68 Child characteristics V may include children’s human capital, long-run earnings
outcomes, or other child characteristics that parents value and that motivate parents to invest in
their children. Child quality V is in turn a function of their time in Head Start H, their time in nonHead Start non-parent child care D, parent teaching time P1, and parent-child non-teaching time
P2: V=V(H,D,P1,P2). We may assume that V is twice continuously differentiable in all of its
arguments, and it is also reasonable to assume that V1>0 and V3>0. D may encompass day care,
non-Head Start schooling, or other child care settings. H is an exogenous parameter that depends
on Head Start enrollment (and depends in expectation on Head Start access).
Note that V depends directly on Head Start time H, even though we could alternatively assume
with no substantive impact on the results that V depends inter alia on the interaction of P1 with
prior child cognitive characteristics, which in turn depends on Head Start enrollment. In other
words, we could alternatively write V=V(Q(H),D,P1,P2), where Q(H) represents child cognitive
characteristics Q, which may depend on the influence of Head Start H. This shows parents
reacting to the cognitive impacts of Head Start, rather than directly to Head Start, which may be
rhetorically closer to the mechanism postulated in the text. Above we instead let V depend
directly on Head Start time H for notational convenience.
As discussed in the text, we sometimes refer to P1 as an “investment,” but strictly speaking we
mean simply that P1 has both a direct impact on utility and an indirect effect through child
characteristics (whose value to parents may in part be realized later in life, for example through
child earnings outcomes, much as an investment would). All of the key points discussed below—
the fact that parent-child teaching time can rise in response to Head Start even as total parentchild time falls, and that the effect of Head Start on parent-child teaching time can be
strengthened as the complementarity of teaching time and Head Start rises—are also consistent
with a model in which U1<0 (and U11>0), so that the direct effect of parent-child teaching time
on utility is negative (at the margin) and parents teach their children only because it produces
valued child characteristics V.
The above assumption on V implies that we can re-write (15) above as:

(16)

max U = U(P1 , P2 , N,V (H , D, P1 , P2 ))
P1 ,P2

Parents therefore value P1 and P2 both directly in the utility function, and indirectly insofar as
these inputs change child characteristics V.
Importantly, this expression shows that parent effort costs must be included in any calculation of
the welfare effect of Head Start (due to the direct dependence of U on P1). If social welfare were
the sum of parent and child utility (e.g. W=U+UC(P1,P2,H,D), where W is social welfare and UC
is child welfare), then the dependence of both U and UC on (inter alia) P1 must be taken into
account in a social welfare calculation.
Parents maximize (16) subject to the parents’ and children’s time budget constraints, (17) and
(18) respectively:

(17)

P1 + P2 + N = T

68

We do so while recognizing that childcare availability is likely to change parents’ effective wage by
decreasing hourly childcare expenditures; our framework represents a convenient simplification that
abstracts from this issue.

44

(18)

P1 + P2 + H + D = T

The parent’s time budget constraint says that the parent’s time endowment T is devoted to parentchild teaching time, parent-child non-teaching time, or other activities. The child’s time budget
constraint says that the child’s time endowment T is devoted to parent-child teaching time,
parent-child non-teaching time, time in Head Start, or time in non-parent non-Head Start child
care. (It is possible that preschool-aged children also spend time with friends or by themselves,
without any form of supervision from parents, school, or other child-care providers. The model
can encompass these possibilities by subsuming them in D.69) The implication of the child time
budget constraint is that children who are enrolled in HS mechanically have less potential time to
spend with their parents, since a large fraction of their day is now spent in HS rather than with
their parents.
Solving this model yields the following expressions for the effect of H on P1 and P2:

(19)

! P1 CE " BF
=
! H BD " AE

(20)

! P2 CD " AF
=
! H AE " BD

where A, B, C, D, E, and F are defined as follows:

A = U11 + U 33 − 2U13 + [2U14 − 2U 34 + U 44 (V3 − V2 )](V3 − V2 ) + U 4 (V22 + V33 − 2V23 )

B = U12 + U 33 − U13 − U 23 + (U14 − U 34 )(V4 − V2 ) + [U 24 − U 34 + U 44 (V4 − V2 )](V3 − V2 )
+U 4 (V22 + V34 − V23 − V24 )
C = [U14 − U 34 + U 44 (V3 − V2 )](V1 − V2 ) + U 4 (V13 + V22 − V12 − V23 )

D = U12 + U 33 − U13 − U 23 + (U 24 − U 34 )(V3 − V2 ) + [U14 − U 34 + U 44 (V3 − V2 )](V4 − V2 )
+ U 4 (V22 + V34 − V23 − V24 )
E = U 22 + U 33 ! 2U 23 + [2U 24 ! 2U 34 + U 44 (V4 ! V2 )](V4 ! V2 ) + U 4 (V22 + V44 ! 2V24 )
F = [U 24 − U 34 + U 44 (V4 − V2 )](V1 − V2 ) + U 4 (V14 + V22 − V12 − V24 )
This solution illustrates a number of points. First, it is possible that ∂P1/∂H can be positive (if
(CE-BF)/(BD-AE)>0, which is not ruled out by the weak assumptions on utility): parent-child
teaching time can increase in response to Head Start enrollment. Second, this is possible even if
∂P2/∂H is negative (indeed, note that the denominator of the expression for ∂P2/∂H is the negative
of the denominator of the expression for ∂P1/∂H). Third, it is moreover possible that total parent
time can fall with H (i.e. ∂(P1+P2)/∂H<0) even if ∂P1/∂H>0. As an example, suppose that BDAE>0. Then C>BF/E and C>AF/D imply ∂P1/∂H>0 and ∂P2/∂H<0.70 Moreover, if CEBF<CD-AE (which is guaranteed, for example, if G1>G2 and F2>F1), then ∂P1/∂H<-∂P2/∂H
(implying ∂(P1+P2)/∂H<0), even though ∂P1/∂H>0. Again, given the weak conditions on utility
above, all of these scenarios are possible. Fourth, increased complementarity between Head Start
69

If child time alone or with friends rises enough in response to Head Start enrollment, it could imply that
the empirical results are consistent with the possibility that P1+P2 rises when in response to Head Start
enrollment. As discussed in the text, we consider this to be a remote possibility. Nonetheless, we note that
the framework in this section is also consistent with the possibility that ∂(P1+P2)/∂H>0.
70
If BD-AE<0, then C<BF/E and C<AF/D guarantee ∂P1/∂H>0 and ∂P2/∂H<0.

45

H and parent investment P1 in producing valued child characteristics V can increase the effect of
Head Start on parent investment ∂P1/∂H. As the complementarity V13 of H and P1 rises, this
raises C; if V13 is large enough in the scenario outlined above, this can cause C>BF/E and
C>AF/D. While V13>0 is not a necessary condition for ∂P1/∂H>0 and ∂(P1+P2)/∂H<0, it may
push the results in this direction and is consistent with the empirical results presented.
Note that this captures Explanations 2 (or 3) in the text, but that Explanation 4 is different
because it posits that parents directly derive more utility from spending more time with children
who have been enrolled in Head Start (as opposed to deriving utility from parent involvement
through the impact of Head Start on child characteristics V). In other words, Explanation 4 might
postulate instead that parent utility is as follows:

(21)

max U = U(P1 , P2 , N,V (H ))
P1 ,P2

and that U14>0 and V’(H)>0. Here child characteristics V depend on Head Start enrollment H, and
parents enjoy spending time more with children when their characteristics change due to Head
Start (U14>0). Note that under this alternative utility function, the effect of Head Start on parentchild teaching time P1 still would relevant to a calculation of the welfare impact of Head Start due
to the direct dependence of U on P1.
	  

	  

46

Appendix Table 2A. Effect of treatment on parent involvement during the experiment
(1) Dependent Variable

(2)
Scale

(3)
Reduced
form

(4)
IV

(5)
Holm
adjustment (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./
loglikelihood

0.12
(0.05)**
0.22
(0.05)***
0.13
(0.05)***
0.10
(0.06)*
0.04
(0.05)
0.14
(0.04)***
1.89
(0.56)***
12.73
(3.26)***
0.17
(0.05)***
0.20
(0.05)***
0.14
(0.06)**
0.25
(0.05)***
0.19
(0.05)***

0.18
(0.07)**
0.32
(0.07)***
0.19
(0.07)***
0.15
(0.09)*
0.06
(0.07)
0.21
(0.09)***
2.78
(0.82)***
18.71
(4.79)***
0.25
(0.07)***
0.29
(0.07)***
0.21
(0.09)**
0.37
(0.07)***
0.28
(0.07)***

0.582

-0.07

3571

-811371

0.00

0.06

3564

-807193

0.25

-0.21

3550

-671933

1

-0.03

3575

-669388

1

-0.14

3573

-790609

0.05

0.00

7257

-1956648

0.06

-0.21

7211

0.00

--

-14.25

7232

0.00

0.08

0.06

3692

-1315266

0.00

0.10

3678

-1321145

0.70

0.03

3684

-1353535

0.00

0.12

3684

-1388395

0.01

0.08

3689

-1329234

1-6

0.06
(0.05)

0.09
(0.07)

1

-0.11

3679

-1320080

1-6

0.06
(0.05)

0.09
(0.07)

1

-0.06

3681

-1384593

Learning-related activities with child
Practiced writing the alphabet
0-2
Practiced writing/spelling
name
Practiced rhyming words

0-2

Help with letters, words, or
numbers
Told Stories

0-2

How many times read to child
in past week
For about how long at a sitting

1-4

Time spent reading to child in
past week (constructed)
Work on learning the names
of the letters
Discuss new words

0-2

0-2

Continuous
Continuous
1-6
1-6

Have [CHILD] tell you a story

1-6

Practice the sounds that letters
make or phonics
Listen to you read stories
where [CHILD] sees the print
such as Big Books
Listen to you read stories
where (he/she) doesn’t see the
print.
Retell or make up stories.

1-6
1-6

47

Appendix Table 2A (continued). Effect of treatment on parent involvement during the
experiment
(1) Dependent Variable

(2)
Scale

(3)
Reduced
form

(4)
IV

(5)
Holm
adjustment (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./
loglikelihood

0.16
(0.06)***
0.29
(0.05)***

0.24
(0.09)***
0.43
(0.07)***

0.22

0.04

3672

-1367371

0.00

0.20

3677

-1326090

0.28
(0.06)***

0.41
(0.09)***

0.00

0.12

3690

-1315399

0.09
(0.05)*
0.09
(0.05)*

0.13
(0.07)*
0.13
(0.07)*

1

-0.02

3686

-1375116

1

-0.00

3696

0.00

0.08
(0.05)*
0.01
(0.05)
0.22
(0.05)***
0.10
(0.06)*
0.19
(0.05)***
0.17
(0.05)***

0.12
(0.07)*
0.01
(0.07)
0.32
(0.07)***
0.15
(0.09)*
0.28
(0.07)***
0.25
(0.07)***

1

-0.06

3568

-775208

0.34

-0.14

3571

-757538

0.00

0.02

3575

-798032

1

-0.03

3575

-669388

0.05

0.08

3683

-1358694

0.08

-0.04

3685

-1200744

1-6

0.18
(0.06)***

0.26
(0.09)***

0.08

-0.01

3678

-1161974

1-6

0.18
(0.06)***

0.26
(0.09)***

0.08

-0.02

3674

-1087797

Learning-related activities with child
1-6
Show [CHILD] how to read a
book or magazine
1-6
Have [CHILD] practice
writing or spelling (his/her)
name.
1-6
Learn about rhyming words
and word families such as cat,
mat, sat.
1-6
Practice or teach directional
words such as over, up, or in.
ContinNumber of materials you use
uous
to work on above reading and
language activities
0-2
Counted things that you can
see
Talk about the calendar
0-2
Talk about how big something
is
Help with letters, words, or
numbers
Talk about the calendar or
days of the week.
Work with rulers, measuring
cups, spoons, or other
measuring instruments.
Use dance or act out stories to
practice math ideas such as
numbers or size.
Use music to understand math
ideas.

0-2
0-2
1-6
1-6

48

Appendix Table 2A (continued). Effect of treatment on parent involvement during the
experiment
(1) Dependent Variable

(2)
Scale

Learning-related activities with child
Work with shape blocks.
1-6
Count out loud.
Number of materials parents
use to work on above math
activities
Other activities with child
Played sports or exercised
together
Played with toys or indoor
games together
Involved in chores

1-6
Continuous

0-2
0-2
0-2

Took on errands

0-2

Arts & Crafts

0-2

Arts & Crafts

1-6

Number of materials parents
use to work on arts & crafts
Gone to a play, concert, or
other live show
Talked with [CHILD] about
family history or ethnic
heritage
Visited an art gallery,
museum, or historical site
Attended an event sponsored
by a community, ethnic, or
religious group

Continuous
Binary
Binary

Binary
Binary

(3)
Reduced
form

(4)
IV

(5)
Holm
adjustment (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./
loglikelihood

0.13
(0.06)**
0.08
(0.06)
0.16
(0.04)***

0.19
(0.09)**
0.12
(0.09)
0.24
(0.06)***

0.82

-0.01

3682

-1365147

1

-0.00

3688

-1109052

0.02

0.07

3696

0.01

0.05
(0.05)
0.00
(0.06)
0.04
(0.05)
0.02
(0.05)
0.06
(0.05)
0.09
(0.05)*
0.12
(0.06)*
0.07
(0.06)
0.09
(0.05)*

0.07
(0.07)
0.00
(0.09)
0.06
(0.07)
0.03
(0.07)
0.09
(0.07)
0.13
(0.07)*
0.18
(0.09)*
0.10
(0.09)
0.13
(0.07)*

1

-0.14

3565

-813850

0.99

-0.11

3553

-504379

1

-0.08

3573

-661471

1

-0.09

3573

-561994

1

-0.15

3559

-802032

1

-0.03

3682

-1358100

1

-0.02

3696

0.00

1

-0.33

7257

-740270

1

-0.04

7262

-1070025

0.08
(0.05)*
0.06
(0.05)

0.12
(0.07)*
0.09
(0.07)

1

-0.30

7257

-744096

1

-0.06

7265

-1060156

49

Appendix Table 2A (continued). Effect of treatment on parent involvement during the
experiment
(1) Dependent Variable

(2)
Scale

Qualitative features of parenting practices
1-5
“I encourage my child to be
curious, to explore, and to
question things”
1-5
“Make sure my child knows I
appreciate what (he/she) tries
to accomplish.”
1-5
“I encourage my child to be
independent of me.”
1-5
“Once I decide how to deal
with misbehavior of child, I
follow through”
1-5
“My child and I have warm
intimate moments together”
1-5
“There are times I don't have
the energy to make my child
behave as (he/she) should”
1-5
“Teach child that misbehavior
or breaking the rules will
always be punished”
Medical
Binary
Has [CHILD] been seen by a
dentist since September
(exclude if HS helped)
Binary
Do you have a place where
you usually take [CHILD] for
routine medical care
Binary
Has a professional tested
[CHILD's] hearing (exclude if
HS helped)
Binary
Has a professional tested
[CHILD's] vision (exclude if
HS helped)

(3)
Reduced
form

(4)
IV

(5)
Holm
adjustment (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./
loglikelihood

0.04
(0.06)

0.06
(0.09)

1

-0.08

3563

-763701

0.02
(0.05)

0.03
(0.07)

1

-0.08

3561

-474905

0.02
(0.04)
0.06
(0.04)

0.03
(0.06)
0.09
(0.06)

1

-0.12

3554

-837400

1

-0.08

3551

-949379

0.11
(0.06)**
0.06
(0.05)

0.16
(0.09)**
0.09
(0.07)

1

0.00

3564

-644430

1

-0.11

3562

-1097162

0.11
(0.05)**

0.16
(0.07)**

1

-0.02

3560

-905578

0.39
(0.05)***

0.57
(0.07)***

0.00

0.35

6524

-904456

0.05
(0.10)

0.07
(0.15)

1

0.01

7255

-204014

0.27
(0.06)***

0.40
(0.09)***

0.00

0.20

2806

-421031

0.29
(0.06)***

0.43
(0.09)***

0.00

0.21

2810

-421489

50

Appendix Table 2A (continued). Effect of treatment on parent involvement during the
experiment
(1) Dependent Variable

Father inputs
In the past month, on about
how many days has [CHILD]
seen (his/her) father
Has your family received any
child support payments from
(his/her) father
Track how child learns and grows
By keeping notes about
(his/her) behavior or progress
By collecting samples of
[CHILD]’s work

(2)
Scale

(3)
Reduced
form

(4)
IV

(5)
Holm
adjustment (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./
loglikelihood

Continuous

0.62
(0.58)

0.91
(0.85)

1

-2.98

1729

-249374

Binary

-0.08
(0.08)

-0.12
(0.12)

1

-0.41

1716

0.00

Binary

0.25
(0.06)***
0.45
(0.09)***
0.21
(0.07)***
0.12
(0.07)*
0.13
(0.07)*

0.37
(0.09)***
0.66
(0.13)***
0.31
(0.10)***
0.18
(0.10)*
0.19
(0.10)*

0.01

0.14

3693

-548854

0.00

0.41

3692

-299859

0.17

0.16

3691

-283965

1

-0.02

3691

-531240

1

-0.26

3692

-329681

Binary

0.06
(0.06)

0.09
(0.09)

1

-0.01

3690

-467397

Binary

0.11
(0.06)**

0.16
(0.09)**

1

-0.01

3685

-547512

Binary

0.32
(0.06)***
0.11
(0.06)**
0.14
(0.04)***

0.47
(0.09)***
0.16
(0.09)**
0.21
(0.06)***

0.00

0.25

7269

-615219

1

0.05

7209

-572218

0.08

0.04

7205

-984131

0.07
(0.04)*

0.10
(0.06)*

1

-0.03

7265

-987202

Binary
Binary

By collecting photos
By charting (his/her) behavior
or skills with stars or stickers
By other means
Rules or routines in the home
Do you have a daily routine
that you usually follow with
your child
Do you regularly use an
organized educational
approach for activities
Rules or routines about
bedtime
Rule or routines about TV
programs allowed to watch
Rules or routines about how
many hours of TV allowed to
watch
Rules or routines about what
kinds of food child eats

Binary
Binary

Binary
Binary

Binary

51

Appendix Table 2A (continued). Effect of treatment on parent involvement during the
experiment
(1) Dependent Variable

(2)
Scale

(3)
Reduced
form

Rules or Routines (continued)
Binary
0.10
Rules or routines about what
(0.04)**
chores child does
Teacher- and Interviewer-Reported Parent Involvement
A variety of learning materials
1-7
0.07
(0.05)
are available

(4)
IV

(5)
Holm
adjustment (pvalue)

(6)
Lee lower
bound

(7)
N

(8)
R-sq./
loglikelihood

0.15
(0.06)**

0.51

0.01

7269

-947540

0.10
(0.07)

1

-0.15

3097

-5679

52

Appendix Table 2B. Effect of treatment on parent involvement after the experiment
(1) Dependent Variable

(2)
Scale

(3)
Reduced
form

(4)
IV

(5)
Holm (pvalue)

(6)
Lee lower
bound

(7)
N

(8)
R-sq./loglikelihood

0.01
(0.04)
0.99
(0.55)*
4.79
(3.25)

0.01
(0.06)
1.46
(0.81)*
7.04
(4.78)

1

-0.10

7075

-2003609

1

-2.55

7035

0.00

--

-18.64

7051

0.00

-0.01
(0.05)
0.02
(0.05)
0.07
(0.06)
-0.02
(0.04)
0.04
(0.05)

-0.01
(0.07)
0.03
(0.07)
0.10
(0.09)
-0.03
(0.06)
0.06
(0.07)

1

-0.10

3533

-1205496

1

-0.08

3531

-1180900

1

-0.04

3534

-1312998

1

-0.12

3543

-1221099

1

-0.07

3543

-1245700

1-6

0.05
(0.04)

0.07
(0.06)

1

-0.12

3532

-1313433

1-6

0.05
(0.05)
0.04
(0.05)
0.03
(0.05)

0.07
(0.07)
0.06
(0.07)
0.04
(0.07)

1

-0.07

3535

-1375566

1

-0.07

3526

-1348833

1

-0.04

3532

-1015296

1-6

0.05
(0.04)

0.07
(0.06)

1

-0.06

3539

-1313032

1-6

0.02
(0.05)
0.05
(0.03)*
0.05
(0.05)
0.11
(0.05)**

0.03
(0.07)
0.07
(0.04)*
0.07
(0.07)
0.16
(0.07)

1

-0.09

3537

-1343285

1

-0.01

3555

0.00

1

-0.03

3548

-1231035

1

-0.08

3548

-1310808

0.10
(0.05)*

0.15
(0.07)*

1

-0.10

3539

-1092651

Learning-related activities with the child
1-4
How many time read to child
in past week
For about how long at a sitting
Continuous
ContinHow many minutes in the past
uous
week did you read to your
child (constructed)
1-6
Work on learning the names
of the letters
Discuss new words
1-6
Have [CHILD] tell you a story

1-6

Practice the sounds that letters
make or phonics
Listen to you read stories
where [CHILD] sees the print
such as Big Books
Listen to you read stories
where (he/she) doesn’t see the
print.
Retell or make up stories.

1-6

Show [CHILD] how to read a
book or magazine
Have [CHILD] practice
writing or spelling (his/her)
name.
Learn about rhyming words
and word families such as cat,
mat, sat.
Practice or teach directional
words such as over, up, or in.
Number of materials you use
to work on reading activities
Talk about the calendar or
days of the week.
Work with rulers, measuring
cups, spoons, or other
measuring instruments.
Use dance or act out stories to
practice math ideas such as
numbers or size.

1-6

1-6

1-6

Continuous
1-6
1-6

1-6

53

Appendix Table 2B (cont’d). Effect of treatment on parent involvement after experiment
(1) Dependent Variable

(2)
Scale

(3)
Reduced
form

Learning-related activities with the child (continued)
1-6
0.14
Use music to understand math
(0.05)***
ideas.
Play math-related games
1-6
0.09
(0.05)**
1-6
0.07
Count things such as small
(0.03)**
toys or chips, to learn math
Work with shape blocks.
1-6
0.08
(0.04)*
Count out loud.
1-6
0.01
(0.06)
Contin-0.02
Number of materials parents
(0.04)
uous
use to work on above math
activities
1-4
0.04
Practice reading, writing, or
(0.05)
working with numbers
Read books to child
1-4
0.03
(0.06)
Tell stories
1-4
0.04
(0.06)
Sing songs
1-4
0.03
(0.05)
Other activities with the child
Arts & Crafts
1-6
0.11
(0.05)**
Binary
0.08
Gone to a play, concert, or
(0.05)
other live show
Binary
0.04
Talked with [CHILD] about
(0.04)
family history or ethnic
heritage
Binary
0.02
Visited an art gallery,
(0.04)
museum, or historical site
Attended an event sponsored
Binary
0.05
(0.05)
by a community, ethnic, or
religious group
Talk about nature or do
1-4
0.05
(0.04)
science projects with
[CHILD]
Play games or do puzzles with
1-4
0.05
(0.05)
[CHILD]
Build something or play with
1-4
0.08
(0.05)
construction toys with
[CHILD]

(4)
IV

(5)
Holm (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
Rsq./loglik
eli-hood

0.21
(0.07)***
0.13
(0.07)**
0.10
(0.04)**
0.12
(0.06)*
0.01
(0.09)
-0.03
0.06

0.557

-0.09

3527

-1085386

1

-0.04

3532

-1349387

1

-0.03

3545

-1179669

1

-0.06

3540

-1345583

1

-0.07

3545

-952843

1

-0.09

3555

0.00

0.06
(0.07)
0.04
(0.09)
0.06
(0.09)
0.04
(0.07)

1

-0.05

3528

-845417

1

-0.08

3522

-988111

1

-0.13

3528

-979109

1

-0.11

3524

-1043347

0.16
(0.07)**
0.12
(0.07)
0.06
(0.06)

1

0.00

3547

-1373199

1

-0.16

7078

-839174

1

-0.05

7077

-1066449

0.03
(0.06)
0.07
(0.07)

1

-0.23

7072

-857878

1

-0.04

7079

-1071292

0.07
(0.06)

1

-0.19

3524

-962962

0.07
(0.07)
0.12
(0.07)

1

-0.11

3519

-1028164

1

-0.15

3522

-990260

54

Appendix Table 2B (continued). Effect of treatment on parent involvement after the
experiment
(1) Dependent Variable

(2)
Scale

Other activities with the child (continued)
Help [CHILD] do arts and
1-4
crafts
1-4
Play a sport or exercise
together?
Involve [CHILD] in
1-4
household chores, like
cooking, cleaning, or caring
for pets
Qualitative features of parenting practices
1-5
“I encourage my child to be
curious, to explore, and to
question things”
1-5
“Make sure my child knows I
appreciate what (he/she) tries
to accomplish.”
1-5
“I encourage my child to be
independent of me.”
1-5
“Once I decide how to deal
with misbehavior of child, I
follow through”
1-5
“My child and I have warm
intimate moments together”
1-5
“There are times I don't have
the energy to make my child
behave as (he/she) should”
1-5
“Teach child that misbehavior
or breaking the rules will
always be punished”
Medical
Binary
Has [CHILD] been seen by a
dentist since September
Binary
Do you have a place where
you usually take [CHILD] for
routine medical care
Binary
Has a professional tested
[CHILD's] hearing
Binary
Has a professional tested
[CHILD's] vision

(3)
Reduced
form

(4)
IV

(5)
Holm (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./log
likelihood

0.04
(0.04)
0.00
(0.06)
0.10
(0.05)*

0.06
(0.06)
0.00
(0.09)
0.15
(0.07)*

1

-0.17

3516

-990707

1

-0.15

3521

-1078834

1

0.01

3526

-888777

0.13
(0.04)***

0.19
(0.06)***

0.07

0.05

7047

-1608804

0.09
(0.05)**

0.13
(0.07)**

1

0.03

7048

-1118307

0.05
(0.04)
0.08
(0.04)**

0.07
(0.06)
0.12
(0.06)**

1

-0.03

7012

-1778338

1

-0.02

7040

-1970608

0.02
(0.05)
0.02
(0.04)

0.03
(0.07)
0.03
(0.06)

1

-0.08

7056

-2227240

1

-0.06

7045

-1471852

0.09
(0.03)**

0.13
(0.04)**

0.872

0.00

7050

-1883477

0.07
(0.04)*
0.08
(0.07)

0.10
(0.06)*
0.12
(0.10)

1

-0.01

7064

-963867

1

0.04

7075

-204697

0.04
(0.04)
0.04
(0.04)

0.06
(0.06)
0.06
(0.06)

1

-0.02

6821

-857457

1

-0.01

6811

-842408

55

Appendix Table 2B (continued). Effect of treatment on parent involvement after the
experiment
(1) Dependent Variable

Father inputs
In the past month, on about
how many days has [CHILD]
seen (his/her) father
Has your family received any
child support payments from
(his/her) father
Rules or routines in the home
Rules or routines about
bedtime
Rule or routines about TV
programs allowed to watch
Rules or routines about how
many hours of TV allowed to
watch
Rules or routines about what
kinds of food child eats
Rules or routines about what
chores child does
Parent Involvement in School
How often work with
[CHILD] on things he/she
learned in school
Mother attended general
school meeting
Mother gone to parent teacher
conference
Mother attended a class event,
such as a play or sport event
Mother volunteer at the school
Father attended general school
meeting
Father gone to parent teacher
conference
Father attended a class event,
such as a play or sport event
Father volunteer at the school

(2)
Scale

(3)
Reduced
form

(4)
IV

(5)
Holm
adjustment (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./
loglikelihood

Continuous

0.94
(0.47)**

1.38
(0.69)**

1

-1.83

3336

0.00

Binary

-0.05
(0.07)

-0.07
(0.10)

1

-0.28

3357

-515918

Binary

0.05
(0.08)
0.21
(0.05)***
0.13
(0.04)***

0.07
(0.12)
0.31
(0.07)***
0.19
(0.06)***

1

0.00

7065

-328548

0.00

0.17

7034

-521752

0.07

0.06

7036

-889820

0.06
(0.05)
0.06
(0.05)

0.09
(0.07)
0.09
(0.07)

1

-0.02

7062

-1028372

1

0.00

7061

-789969

1-6

0.02
(0.05)

0.03
(0.07)

1
1

-0.07

7054

-1806621

1-6

-0.03
(0.05)
0.05
(0.05)
-0.05
(0.04)
0.10
(0.05)**
-0.03
(0.05)
-0.02
(0.05)
-0.03
(0.05)
0.06
(0.07)

0.04
(0.07)
0.07
(0.07)
-0.07
(0.06)
0.15
(0.07)**
-0.04
(0.07)
-0.03
(0.07)
-0.04
(0.07)
0.09
(0.10)

1

-0.09

6983

-724537

1

-0.01

6979

-686689

1

-0.14

6972

-1007060

1

-0.06

6962

-1023060

1

-0.19

6856

-998523

1

-0.19

6860

-972092

1

-0.21

6851

-947169

-0.76

6839

-461697

Binary
Binary

Binary
Binary

1-6
1-6

1-6
1-6
1-6
1-6

1
	  

56

Appendix Table 2B (continued). Effect of treatment on parent involvement after the
experiment
(1) Dependent Variable

(2)
Scale

(3)
Reduced
form

(4)
IV

(5)
Holm (pvalue)

(6)
Lee
lower
bound

(7)
N

(8)
R-sq./
loglikelihood

Teacher- and Interviewer-Reported Parent Involvement
Parent attend open house
Binary
-0.05
-0.07
1
-0.09
5360
(0.07)
(0.10)
Have parents volunteered
Binary
0.00
0.00
0.959
-0.12
5353
(0.05)
(0.07)
Have parents met with teacher
Binary
0.32
0.47
1
0.12
609
(0.15)** (0.22)**
and special needs team for
special needs children
A variety of learning materials
1-7
0.06
0.09
-0.04
5908
1
(0.04)
are available
(0.06)
Notes: Appendix Table 2 shows the coefficients and standard errors on the treatment dummy
from OLS, probit, ordered probit, and two-stage least squares regressions of parent inputs on the
treatment dummy. Column 1 shows the dependent variable in question. Column 2 shows the
scale that the dependent variable takes. “Continuous” refers to dependent variables that can take
on any value; otherwise, the range that the dependent variable can take is shown. A scale of “XY” means that the dependent variable can take on any integer value between the integers X and
Y, inclusive. Column 3 shows the estimated coefficients and standard errors on the treatment
dummy from the reduced form regression (3) without control variables. For continuous variables,
we run OLS; for binary variables, we run probits; and for variables with multiple ordered
outcomes, we run ordered probits. The probit and ordered probit results report coefficients on the
treatment dummy (not marginal effects). Column 4 shows the estimated coefficients and standard
errors on the treatment dummy from the IV estimates. For the continuous variables, we run twostage least squares as in regressions (1) and (2) without control variables. For the categorical
outcomes, we take the coefficient estimates from the probit and ordered probit regressions in
Column 3 and calculate the Wald estimate by multiplying the estimated coefficients by
1.47=1/0.68, where 0.68 is the first-stage coefficient from the regression of the HS enrollment
dummy on the HS access dummy (with no controls). Column 5 shows the estimated p-value
associated with the coefficient estimate after performing the Holm adjustment to account for
multiple comparisons. We do not perform a Holm adjustment for the variable measuring time
spent reading because we construct this variable using the variables included in the basic data; the
results are very similar after performing this adjustment, as well (and the coefficient on treatment
remains significantly different from 0 at the 5% level). Column 6 shows the lower bound on the
estimated reduced form treatment effect in Column 3, after performing the trimming procedure of
Lee (2009) to address missing data. Column 7 shows the number of observations in the
regressions. Column 8 reports the R-squared for OLS regressions and the log-likelihood for
probit and ordered probit regressions. Standard errors are clustered at the level of the program.
All observations are weighted by the final parent weights, except the teacher-reported variables,
which are weighted by teacher interview weights. *** denotes significance at the 1% level; ** at
the 5% level; * at the 10% level.

57

-639928
-980784
-114614

-10212

Appendix Table 3. Factor Analysis
(1) Dependent
(2) Treatment
(3) Holm
(4) Lee lower
(5) N
(6) R-squared
variable
Effect
adjustment (pbound
value)
Panel A: Fall 2002
Factor 1
0.28
0.00
0.00
3441
0.01
(0.06)***
Factor 2
0.02
0.51
-0.15
3441
0.00
(0.04)
Panel B: Spring 2003
Factor 1
0.36
0.00
0.11
3367
0.02
(0.07)***
Factor 2
0.12
0.06
-0.03
3367
0.00
(0.05)**
Factor 3
0.10
0.21
-0.08
3367
0.00
(0.06)
Panel C: Spring 2004-5
Factor 1
0.15
0.17
-0.03
3087
0.00
(0.06)**
Factor 2
0.00
0.88
-0.16
3087
0.00
(0.06)
Factor 3
0.11
0.19
-0.04
3087
0.00
(0.05)**
Factor 4
0.07
0.66
-0.09
3087
0.00
(0.06)
Factor 5
0.08
0.46
-0.03
3087
0.00
(0.05)*
Panel D: Spring 2005-6
Factor 1
0.10
0.62
-0.02
3212
0.00
(0.07)
Factor 2
-0.07
0.69
-0.14
3212
0.00
(0.07)
Factor 3
0.13
0.33
0.00
3212
0.00
(0.06)**
Factor 4
0.09
0.35
-0.01
3212
0.00
(0.04)*
Notes: Appendix Table 3 shows the results of a factor analysis of the depenent variable. To
perform this analysis, we first pool all of the dependent variables together and extract the
principal components, and then we use the Kaiser criterion to keep factors whose eigenvalues are
greater than 1. We do so separately for each of the periods during which the dependent variables
are observed. This yields two factors in Fall 2002; four factors in Spring 2003; six factors in
Spring 2004-5; and five factors in Spring 2005-6. We then regress each of the factors on the
Head Start dummy, instrumenting for Head Start enrollment with HS access. Column 2 shows the
coefficients and standard errors on the treatment dummy from this regression. Standard errors are
clustered at the level of the program. All observations are weighted by the final parent weights.
Column 3 shows the p-values after performing the Holm adjustment. Column 4 shows the lower
bound on the estimated treatment effect after performing the trimming procedure of Lee (2009) to
address missing data. Column 5 shows the number of observations in the regressions. Column 6
reports the R-squared. *** denotes significance at the 1% level; ** at the 5% level; * at the 10%
level.

58

Appendix Table 4. Effect of HS on other outcomes. The table shows coefficients and
standard errors on the treatment dummy from IV regressions of parent involvement on
HS enrollment. Dependent variables are listed in column headings
(1)
(2)
(3)
(4)
Cog.
NonFather
Special
scores
cog.
lives in
needs
scores
home
child
Panel A: During
HS
0.22
0.09
-.04
-enrollment
(.06)*** (0.05)*
(.03)
N
40,043
Panel B: After
HS
0.02
enrollment
(.05)
N

64,506

32,002

7273

--

0.01
(.03)

-0.02
(.03)

0.007
(0.016)

137,280

7,090

5,364

Notes: The table shows the results of regressions in which additional outcomes of
interest are related to HS enrollment through the two-stage least squares regressions
(1) and (2). The dependent variable in question is listed in each column heading.
Panel A shows results for the During period, and Panel B shows results for the After
period. Standard errors are clustered at the level of the program. All observations
are weighted by the final parent weights. In Column 1, the dependent variable is
child cognitive scores. In Column 2, the dependent variable is child non-cognitive
scores. Cognitive and non-cognitive scores have been normalized to have mean zero
and standard deviation 1 (as described in the Appendix) and stacked in these
regressions. In Column 3, the dependent variable is a dummy that equals 1 if the
father lives in the home and 0 otherwise. In Column 4, the dependent variable is “In the
past month, on about how many days has [CHILD] seen (his/her) father.” The results are
extremely similar when controlling for the covariates included in Columns 2 and 5 of
Table 2. *** denotes significance at the 1% level; ** at the 5% level; and * at the
10% level.

59

Appendix Table 5. Correlation of program effects on cognitive scores and parent involvement. Table
shows coefficients and standard errors from OLS (regression (9)) or two-stage least squares regressions
(regressions (10) and (11)). The dependent variable in Columns 1-6 is formed by pooling measures of
parent involvement and is formed in Column 7 by pooling cognitive score measures

Panel A: During
Coeff. on Program
Quality (Cog.)
Coefficient on
Parent Inputs
Coeff. on Prog.
Quality (Non-cog.)
IV for parentreported measures
Control for labor
force participation
Avg. effect of center
measures
F-statistic on reports
(p-value)

(1) RF

(2) RF

(3) RF

(4) 2SLS

(5) 2SLS

(6) 2SLS

(7) RF

0.25
(0.09)***
--

--

0.21
(0.10)**
--

0.16
(0.04)***
--

0.16
(0.04)***
--

--

--

0.23
(0.09)**
--

--

0.13
(0.09)

0.06
(0.09)

0.07
(0.10)

0.05
(0.05)
X

0.04
(0.05)
X

0.38
(0.12)***
--

X
--

--

--

--

--

--

--

--

0.01
(0.01)
0.91
(0.51)

0.01
(0.01)
0.93
(0.50)

---

Panel B: After
Coeff. on Prog.
0.14
-0.11
0.08
0.09
0.11
-Quality (Cog.)
(0.07)*
(0.07)
(0.05)
(0.02)***
(0.02)***
Coefficient on
------0.22
Parent Inputs
(0.09)**
Coeff. on Prog.
-0.13*
0.09
0.12
0.12
0.11
-Quality (Non-cog.)
(0.07)
(0.07)
(0.08)
(0.03)***
(0.03)***
IV for parentX
X
reported measures
Control for labor
X
force participation
Avg. effect of center
----0.001
0.005
-measures
(0.011)
(0.012)
F-statistic on reports
----1.06
1.07
-(p-value)
(0.36)
(0.39)
Notes: In Column 1, we run reduced-form regression (9) from Appendix C. In Column 2, we run this
regression except that the measure of program quality is formed using child non-cognitive scores.
Column 3 adds both cognitive and non-cognitive scores. Column 4 shows the results from two-stage
least squares regressions (10) and (11). Column 5 additionally instruments for the eight measures of
HS center-encouraged parent involvement reported by parents (listed in Appendix C), using the 58
measures of center parent-related activity reported by center directors. Column 6 additionally
controls for measures of parents’ labor force participation. In Columns 4-6, the first stage F-statistics
corresponding to the endogenous variables are typically over 100. In Column 7, we effectively run the
regression in reverse: the dependent variable is formed by pooling cognitive score measures, and the
independent variable of interest is a measure of program quality formed using measures of parent
involvement. “RF” denotes reduced form. “Cognitive scores” refers to the mean for each child of all 11
normalized cognitive score measures, listed in Appendix A. All of these results are nearly identical when
we control for the covariates included in some specifications in Table 2. Standard errors are clustered
at the level of the program. All observations are weighted by the final parent weights. N=257,704 in
Columns 1-6 and 39,268 in Column 7 in the During period; N=300,063 in Columns 1-6 and 36,949 in
Column 7 in the After period. 3,688 unique individuals are included in the regressions in the During
period, and 3,456 unique individuals are included in the regressions in the After period. The sample
size is slightly smaller than in Tables 2 and 4 because cognitive scores are sometimes missing for fellow
program designees. *** denotes significance at the 1% level; ** at the 5% level; * at the 10% level.

60

Appendix Table 6. Effect of treatment on time allocation of parents and children. The table shows the
coefficients and standard errors on the treatment dummy from IV regressions of the dependent variable in
question on the instrumented Head Start enrollment dummy. The column heading shows the dependent
variable in question.
(1) Dependent var.
(2) Coeff. on HS
(3) Mean of
(4) N
Enrollment Dummy
dependent variable
Panel A: Parent variables
(A) Monthly
-28.31
37.45
3,696
childcare expenses ($)
(8.27)***
(B) Mother LFP
-0.04
0.52
3,445
during
(0.03)
(C) Father LFP
0.05
0.89
1,743
during
(0.03)*
(D) Mother LFP after
-0.01
0.57
6,471
(0.03)
(E) Father LFP after
0.02
0.94
3,192
(0.02)
Panel B: Child variables
(F) Hrs. of non-parent
11.71
22.10
3,696
care (inc. HS)
(1.12)***
(G) Hrs. of ctr-based
-6.08
4.71
3,696
daycare (non-HS)
(0.86)***
(H) Hrs. at a day care
-2.81
1.71
3,696
home
(0.56)***
(I) Hrs. with non-2.87
2.59
3,696
parent relatives
(0.67)***
Notes: The dependent variable in each row is listed in Column 1. Column 2 shows coefficients and
standard errors on the treatment dummy from a regression of the outcome variable in question on the
treatment dummy. In Rows B through E, we run probits of the outcome on the Head Start access dummy,
and we form the reported Wald estimate of the effect by dividing this reduced form estimate of the effect of
HS access on the outcome by the first stage coefficient on the treatment dummy. In Rows B through E, we
report marginal effects on the dependent variable (rather than coefficients). In other rows, we show two
stage least squares estimates. The measures of children’s time in Rows F-I are all in weekly terms. The
sample sizes differ across dependent variables in part because the After period contains more observations
than the During period (since the questions were usually asked in more time periods in the After period),
and in part because the amount of missing data differs across variables. Standard errors are clustered at the
level of the program. All observations for parents are weighted by the final parent weights, and
observations for children are weighted by the final child weights. *** denotes significance at the 1% level;
** at the 5% level; * at the 10% level.

61

