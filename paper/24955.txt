NBER WORKING PAPER SERIES

UNDERSTANDING DOCTOR DECISION MAKING:
THE CASE OF DEPRESSION
Janet M. Currie
W. Bentley MacLeod
Working Paper 24955
http://www.nber.org/papers/w24955

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2018, Revised January 2020

This paper was originally prepared for the Fisher-Schultz lecture of the Econometric Society
delivered in Lisbon on August 23, 2017. We are grateful for the helpful comments received at
that time, as well as from audiences at Yale, Stanford, University of Mannheim, University of
Pittsburgh, Rochester University, University of Virginia, Dartmouth, Tel Aviv University,
University College London, Universidad Carlos III Madrid, New York University, Pompeu
Fabra, CEMFI, CEPRA/NBER, and the International Association of Applied Economists. The
authors thank Hendrik Jürges, Aviv Nevo and three anonymous referees for helpful comments
and Allen Campbell for working with us to help us access the IQVIA data. Xuan Li, Sara
Shahanaghi, Haowen (Alice) Wu, Emily Cuddy and Utkarsh Kumar provided outstanding
research assistance. We thank the NIA for support under P30-AG024928-14. Princeton
University participates in the BCBS Alliance for Health Research. The Blue Cross Blue Shield
Association (BCBSA) established the BCBS Alliance for Health Research to engage leading U.S.
healthcare researchers in collaborative efforts to use a limited data set drawn from BCBS
companies to explore critical health care issues in order to improve the health of Americans. The
BCBS Alliance for Health Research provides researchers with use of a secure data portal to
access a limited data set from BCBS Axis®, the largest collection of commercial insurance
claims, medical professional and cost of care information. BCBSA is an association of
independent BCBS companies. The authors are solely responsible for the content of the paper.
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Janet M. Currie and W. Bentley MacLeod. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.

Understanding Doctor Decision Making: The Case of Depression
Janet M. Currie and W. Bentley MacLeod
NBER Working Paper No. 24955
August 2018, Revised January 2020
JEL No. I1,I12,J24
ABSTRACT
Treatment for depression is complex, requiring decisions that may involve tradeoffs between
exploiting treatments with the highest expected value or experimenting with treatments with
higher possible payoffs. Using patient claims data, we show that among skilled doctors, using a
broader portfolio of drugs predicts better patient outcomes, except in cases where doctor’s
decisions violate loose professional guidelines. We introduce a behavioral model of decision
making guided by our empirical observations. The model’s novel feature is that the tradeoff
between exploitation and experimentation depends on the doctor’s diagnostic skill. The model
predicts that higher diagnostic skill leads to greater diversity in drug choice and better matching
of drugs to patients even among doctors with the same initial beliefs regarding drug effectiveness.
Consistent with the finding that guideline violations predict poorer patient outcomes, simulations
of the model suggest that increasing the number of possible drug choices can lower performance.

Janet M. Currie
Department of Economics
Center for Health and Wellbeing
185A Julis Romo Rabinowitz Building
Princeton University
Princeton, NJ 08544
and NBER
jcurrie@princeton.edu
W. Bentley MacLeod
Department of Economics
Columbia University
420 West 118th Street, MC 3308
New York, NY 10027
and NBER
bentley.macleod@columbia.edu

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF
DEPRESSION TREATMENT
JANET M CURRIE AND W BENTLEY MACLEOD
Forthcoming in Econometrica

Abstract. Treatment for depression is complex, requiring decisions that may involve tradeoffs between exploiting treatments with the highest expected value or experimenting with
treatments with higher possible payoffs. Using patient claims data, we show that among
skilled doctors, using a broader portfolio of drugs predicts better patient outcomes, except in cases where doctor’s decisions violate loose professional guidelines. We introduce
a behavioral model of decision making guided by our empirical observations. The model’s
novel feature is that the tradeoff between exploitation and experimentation depends on the
doctor’s diagnostic skill. The model predicts that higher diagnostic skill leads to greater diversity in drug choice and better matching of drugs to patients even among doctors with the
same initial beliefs regarding drug effectiveness. Consistent with the finding that guideline
violations predict poorer patient outcomes, simulations of the model suggest that increasing
the number of possible drug choices can lower performance.

1. Introduction
Understanding doctor decision making is central to improving health and reducing health
care costs. This paper examines variations in doctor decision making in the context of the
prescribing of anti-depressant medications in the U.S. Anti-depressants are one of the largest
and fastest growing classes of drug treatments. In the U.S., 13% of the adult population had
Key words and phrases. health economics, decision making, learning, human capital.
This paper was originally prepared for the Fisher-Schultz lecture of the Econometric Society delivered in
Lisbon on August 23, 2017. We are grateful for the helpful comments received at that time, as well as
from audiences at Yale, Stanford, University of Mannheim, University of Pittsburgh, Rochester University,
University of Virginia, Dartmouth, Tel Aviv University, University College London, Universidad Carlos III
Madrid, New York University, Pompeu Fabra, CEMFI, CEPRA/NBER, and the International Association
of Applied Economists. The authors thank Hendrik Jürges, Aviv Nevo and three anonymous referees for
helpful comments and Allen Campbell for working with us to help us access the IQVIA data. Xuan Li,
Sara Shahanaghi, Haowen (Alice) Wu, Emily Cuddy and Utkarsh Kumar provided outstanding research
assistance. We thank the NIA for support under P30-AG024928-14. Princeton University participates in
the BCBS Alliance for Health Research. The Blue Cross Blue Shield Association (BCBSA) established the
BCBS Alliance for Health Research to engage leading U.S. healthcare researchers in collaborative efforts to
use a limited data set drawn from BCBS companies to explore critical health care issues in order to improve
the health of Americans. The BCBS Alliance for Health Research provides researchers with use of a secure
data portal to access a limited data set from BCBS Axis®, the largest collection of commercial insurance
claims, medical professional and cost of care information. BCBSA is an association of independent BCBS
companies. The authors are solely responsible for the content of the paper.
1

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

2

taken an anti-depressant in the past 30 days in 2011/12, up from 6.8% in1999/2000 (Kantor
et al. (2015)). Other countries have seen a similar increase in anti-depressant use over time.
For example, the EU average utilization rate rose from just under 3% to almost 6% between
2000 and 2010.1 Depression has been blamed for rising suicide rates in the U.S., with suicide
ranking as the 10th leading cause of death in 2016.2
Depression is an especially interesting context for studying doctor decision making. First,
there are 33 separate anti-depressant drug molecules available over our study period. Since
every patient responds differently to each drug, and there is no one drug that dominates all
others for all patients, finding the best option necessarily requires experimentation. However,
experimentation is costly in the sense of subjecting patients to sub-optimal drug choices, so
expanding the drug choice set does not necessarily improve patient welfare within a fixed
treatment window. Hence, guidelines that limit choice may be welfare-improving. Second,
as Frank and McGuire (2000) observe, the assessment of patient condition is often more
difficult in the case of mental illness than for many physical illnesses, suggesting that doctor
diagnostic skill plays an important role. We show that there is a link between doctor skill and
the payoff to experimentation, which implies that the best choice of treatment for a patient
at a point in time depends in part on the doctor’s skill level. Third, prices (and “detailing”,
i.e. marketing of drugs directly to doctors) are relatively unimportant in decision making
about anti-depressants today since most anti-depressants are available as generics and many
patients face the same cost (a small co-pay) for many drug choices. Anti-depressants belong
to the large and interesting category of markets that clear largely without the aid of price
signals (Roth (2018)). Hence, the usual economic approach of seeking to set prices “correctly”
is unlikely to improve doctor decision making in this setting.
The goal of this paper is to better understand doctor practice style and to ask how decision
making is related to patient outcomes. A closely related question is whether patient outcomes
can be improved by limiting physician decision-making through the imposition of guidelines.
We begin with an exploratory analysis of the relationship between doctor practice style,
guidelines, and patient outcomes using novel data formed by merging information on all antidepressant prescriptions for each doctor to national administrative claims data for hundreds
of thousands of patients treated with anti-depressants. One advantage of using claims data
(and a contribution of our paper) is that we can examine emergency room (ER) visits and
hospitalizations as patient outcomes, rather than relying on suicides as the outcome measure
as in previous studies (Berndt et al. (2015), Ludwig et al. (2009)). Suicides are thankfully
relatively rare, making it difficult to compare doctors in terms of this patient outcome.
We characterize practice style for anti-depressant prescribing in terms of how dispersed it
is (i.e. how many different drugs doctors use), and in terms of whether the doctor violates
(See Trends in Anti-Depressant Consumption)
(See Suicide Statistics).

1
2

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

3

national and international guidelines for prescribing. Doctors vary widely on these two
measures. Our main empirical findings are as follows: 1) Among patients seeing skilled
doctors, more dispersed prescribing is associated with better patient outcomes; 2) Among
patients seeing less skilled physicians, more dispersed prescribing is not associated with better
patient outcomes; and 3) Violating guidelines about drug transitions is associated with worse
outcomes in all patients. These results demonstrate that there is significant variation in these
two measures of doctor practice style, and that they are related to patient outcomes.
We then develop an economic model of decision making in order to link dispersion in
prescribing to physician behavior and performance. Thompson (1933) recognized that drug
choice can be viewed as a statistical decision problem involving estimation of the means and
variances of treatments and updating them over time. Since the doctor can only observe
one treatment at a time, the problem takes the form of a multi-armed bandit in which the
patient is like a “slot machine,” and the drug choice each period corresponds to the question
of which arm of the machine to pull (Robbins (1952)). The practitioner does not know the
best drug for a particular patient in advance, and learns by trial and error. At any point in
time there is a trade-off between choosing the treatment with the highest expected value, and
experimenting to learn more about treatments that may be better for a particular individual.
There is an extensive literature on optimal decision rules for a multi-armed bandit. However finding the solution is computationally challenging (Kendrick et al. (2014)). Doctors
face time constraints and must make a drug choice for a particular patient within a few
minutes. Hence they are not likely be solving a complex dynamic programing problem.
In computer science, a rapidly developing area of research builds on the adaptive learning
model of Lai and Robbins (1985) to develop practical solution methods that achieve solutions
which are close to optimal (see Bubeck and Cesa-Bianchi (2012); Sutton and Barto (2018)).
In these models, drug choice depends on both the expected value of a choice and on beliefs
about the variance in outcomes for that choice. For example, if there are two drugs A and
B, and A has a higher expected value but the variance of B is believed to be higher, then a
doctor may choose drug B because there is more to learn regarding its effectiveness. When
the doctor chooses B this reduces her uncertainty about B, and depending on the outcome
she will either stick to B or go back to A. We adopt this general approach to model learning,
and assume that doctors update their beliefs using Bayes rule.
The novel insight from our model is that the trade-off between experimentation and choosing the drug with the highest expected value depends on the physician’s diagnostic skill.
Intuitively, if a physician is not able to correctly assess a patient’s condition, then there is
little to be learned from experimenting and the patient is likely to be better off without it.
In contrast, if a physician is highly skilled in the sense of being able to correctly assess a

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

4

patient’s condition, i.e. has excellent diagnostic skill, then the potential gains from experimentation are larger. It follows that there will not necessarily be a single correct treatment
even for identical patients since the best treatment will also depend on the doctor’s characteristics. Other things being equal, a skilled diagnostician should be more experimental
than a less skilled diagnostician. Physicians who are more skilled will use a wider variety
of drugs for their patients, and physicians with better diagnostic skills stand to learn more
from experimentation and so should be more experimental.
Finding the optimal treatment entails experimentation, and hence may involve some
choices that turn out to have been suboptimal ex post. Experimentation may make it more
likely that the physician finds the optimal treatment, but it may also make it more likely
that the physician violates prescribing guidelines, with potentially negative consequences for
patients. Hence, guidelines that rule out some choices may improve patient welfare over
a fixed treatment window. Simulations of our model demonstrate exactly this point, consistently indicating that restrictions on physician’s choice sets (guidelines) can be welfare
improving over a finite treatment horizon.
Our empirical findings (1 and 2) are consistent with the result that experimentation is
more beneficial when physicians have more skill. The third empirical finding suggests that
there is a limit to the benefits of experimentation: Violating guidelines is associated with
worse patient outcomes even in patients seeing skilled physicians.
The agenda of the paper is as follows: Section 2 provides some background and further
discussion of the literature. Section 3 discusses the data, while the empirical results are
discussed in section 4. Section 5 introduces the model details, and how one can connect
doctor diagnostic skill and learning with observed performance. We conclude with Section
6.
2. Background: Previous Work on doctor Decision Making and Practice
Style
While differences between patients are obviously an important driver of heterogeneity in
treatment, there is increasing evidence that variation in doctor decision making is important.
For example, Cutler et al. (2019) document large differences in doctor beliefs about appropriate treatment. Similarly, previous studies have found little evidence that patient demand
drives the large differences in C-section rates across U.S. providers (McCourt et al. (2007)).
Finkelstein et al. (2015) suggest that at least half of the observed variation in procedure use
among the elderly is due to supply-side factors.
Doctor peer effects are one potential source of area-level variation in treatment choices.
Models of peer effects such as Chandra and Staiger (2007) imply that the practice styles of
doctor peers should converge over time, though the evidence on that front is mixed perhaps

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

5

because of the difficulty of defining peers (see Molitor (2016), Donohue et al. (2018), Epstein
and Nicholson (2009), Dranove et al. (2011) and Chan (2015)). The mixed results suggest
that proximity alone is not enough to drive spillovers in practice style, and that variation in
practice style is likely to depend upon sub-specialty and detailed features of the environment
in which doctors work.
Fear of litigation is another frequently cited reason for variations in doctor decision making.
The idea that doctor decisions are shaped primarily by fear of litigation remains popular, even
though it has been repeatedly de-bunked. For example, Baicker and Chandra (2005) find
no evidence that treatment responds to changes in legal liability, except for some screening
procedures.
Our focus is on the prescribing behavior of physicians. Starting with Stern and Trajtenberg
(1998), several previous studies use concentration in a doctor’s prescribing as a measure
of practice style. Frank and Zeckhauser (2007) cite survey data showing that the most
prescribed medication for a specific condition was responsible for about 60% of a doctors’
prescriptions for that condition. Patient demographics had little explanatory power. Berndt
et al. (2015) use data on prescriptions of anti-psychotics. They show that most doctors have
a favorite drug and that on average 66% of their prescriptions are for this drug.
Other studies treat prescription choice as an application of consumer demand theory.
Crawford and Shum (2005) study the market for ulcer drugs and estimate a structural
model of drug choice. In their model all of the differences in treatment are driven by patient
needs or preferences. As Crawford and Shum (2005) (page 1147) state: “. . . all doctors in
our model have the same probability of prescribing a given drug to a patient with a given
diagnosis in a given time period.” Dickstein (2015) uses a similar methodology to model how
drug choices are affected by differences in patient co-payments across insurance plans. Over
his time period (2003-2005), branded drugs were a larger share of the anti-depressant market
and the insurer’s price paid varied from $8.00-$110.00 per month. However, co-pays only
varied from about $10.00 to $20.00 per month, and drugs with a wide range of prices had
similar co-pays, suggesting that price differences could only be a partial explanation of drug
choice. Neither study allows differences in doctor practice style per se to explain the choice
of prescription drugs.
Since we have doctor identifiers we are able to document variation in physician practice
style, and connect it to patient outcomes. Differences in prescribing practices have led to
calls for stronger practice guidelines, especially in psychiatry. Meehl (1954), Grove et al.
(2000) and Kahneman and Klein (2009) argue that algorithms could do as least as well
as a psychiatrist in the treatment of mental illness, and the development of algorithms for
treatment is an active area of ongoing research (see Adli et al. (2017)). On the other hand,
Frank and Zeckhauser (2007) express concern that guidelines could prevent doctors from

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

6

providing care that is sufficiently individualized, while Cosgrove et al. (2018) worry that
guidelines may be influenced by pharmaceutical companies. More generally, management
practices have been shown to be strongly related to outcomes in health care settings, and
the question of how best to structure guidelines for doctors is an important one (see Bloom
et al. (2015) and Tsai et al. (2015)).
The challenge is to provide ways to measure practice style that can be linked to patient
outcomes in order to assess doctor performance. Currie and MacLeod (2017) and Currie
et al. (2016) develop a framework for studying individual doctor decision making in contexts
where doctors make zero/one choices and there is little scope for learning about individual
needs over time. In addition to showing variation in skill, they find that there is a great
deal of variation across physicians in both responsiveness to a patient’s condition and in the
aggressiveness of treatment choices; moreover, these characteristics of doctors are fairly stable
over time. More recently, Chan et al. (2019) document a similar finding for radiologists, who
vary greatly in their ability to correctly diagnose pneumonia.
This paper extends this work to a more complex case where learning is important. In our
model a doctor’s practice style can be characterized in terms of their diagnostic skill (which
corresponds to how responsive doctors are to a patient’s condition) and their reservation
probabilities (which provide a summary measure of a doctor’s taste for experimentation and
risk preferences). This paper builds on our previous work by showing how diagnostic skill
helps doctors to learn about the effectiveness of treatment when there are many potential
treatments and the best choice can only be determined by trial and error. 3 Moreover, even
given a trial, it may not be obvious whether a particular drug is working or not. Randomized
controlled trials of drug treatments for depression can yield very noisy results: In most cases
the placebo effect of giving a drug accounts for about 80% of the total measured effect.
Like us, Frank and Zeckhauser (2007) observe that the treatment of depression can be
viewed as a bandit problem in which one learns about the best course of action by carrying
out trial and error learning with different anti-depression drugs. Rothschild (1974) shows
that in a market setting, trial and error learning leads to a stable equilibrium with significant
price heterogeneity. This heterogeneity arises because at some point it is no longer profitable
to explore further choices, so that individuals with different consumption histories can settle
on different choices. Aghion et al. (1991) study the optimal search strategy with learning and
highlight the trade-off between exploitation (continuing with the same choice), or exploration
(trying a new choice). They find that in a setting without discounting, parties will eventually

A unique feature of treating depression is that observable patient physical characteristics, such as sex or
medical condition, have very little predictive power. People with particular genotypes may have adverse
drug responses, but genetic tests are not currently recommended as part of standard practice (Zeier et al.
(2018)).
3

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

7

learn the true demand functions facing firms. Bergemann and Välimäki (1996) extend these
results to the case of endogenous investment into learning.
Cohen et al. (2007) suggest that humans solve this type of problem using an index rule for each drug choice the physician assigns a valuation that is a combination of the expected
treatment effect and the potential information to be gained by prescribing the drug. In
contrast to dynamic programming which works backwards from the potential last period of
treatment to the present, forward-looking algorithms compute the valuation using currently
available information. Sutton and Barto (2018) provide a review of the literature on such
rules beginning with Gittins (1979) and Lai and Robbins (1985).4 One of the most successful
algorithms is based on computing the “upper confidence bound” for a given arm (Bubeck and
Cesa-Bianchi (2012); Srinivas et al. (2012); Srivastava et al. (2015)). These “UCB algorithms”
are used to model human decision making in a variety of contexts, including laboratory
experiments with bandit choice (Reverdy et al. (2014)), decision making in complex games
(Wu et al. (2018)), and advertising (Schwartz et al. (2017)).
The model we introduce in section 5 uses the idea of an upper confidence bound from
this literature to introduce the concept of a “reservation probability,” p, that defines an
valuation qd for choice d. We are inspired by Simon (1955)’s idea of satisficing, the basis
of contemporary labor market models of search. In these models workers search until they
receive a wage offer that exceeds their reservation wage. In our model, the probability that
the effect of drug d is larger than qd is p. A doctor’s practice style can be summarized by
this reservation probability: The doctor will try new drugs until the probability that a new
drug is better than the current drug falls below the reservation probability. We show below
that this simple rule provides a good approximation to an optimal strategy.
An implication of the model is that optimizing agents operating in the same environment
exhibit a great deal of variation in their choices. In our case the doctor is solving a matching
problem which involves trying to find the best treatment for each patient given unobserved
patient characteristics. It is important that different patients should be given different
treatments. Hence, better doctors will have more dispersed drug choices. To make this idea
more precise we introduce a model of drug choice that incorporates diagnostic skill. We
then discuss the implications of variations in diagnostic skill and reservation probabilities for
patient outcomes and for the within-doctor dispersion of drug choices.
3. Data
In order to examine the relationship between doctor skill, practice style, and patient
outcomes, we use a new national sample of claims data from Blue Cross Blue Shield Alliance
for Health Research (BCBS), a collaborative effort involving most of the regional BCBS plans.
See also Erev and Roth (2014)’s discussion of the earlier literature using reinforcement learning in economics.

4

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

8

The administrative claims data come from a limited data set made available through a secure
data portal and are drawn from Blue Cross Blue Shield (BCBS) Axis®, the largest source
of commercial insurance claims data in the U.S.5 We first selected a 10% sample of all of the
member numbers (for members aged between 18 and 64 as of January 2013) in the system
between January 2013 to September 2016. BCBS data had about 99 million members aged
between 18 and 64 who had any claims over our sample period. Of the 9.9 million members
we selected, about 4.5 million ever had a pharmacy claim, and of these, 723,818 members
were ever prescribed antidepressants over the sample period. These members constitute our
initial BCBS data sample. For each of these members, we generate a panel of data with a
record for each month and year that they appeared in the claims data. In each time period
we know whether they are taking any anti-depressant drug, what drug it was, who prescribed
it, claims for drugs, outpatient visits, emergency room (ER) visits, and inpatient visits, and
total health care costs generated by summing all claims across inpatient, outpatient, and
pharmacy data bases. We focus on ER visits as an outcome because in the US, patients
with mental health crises are uniformly advised to proceed to the nearest ER for assessment.
ER visits (and subsequent hospitalizations) for mental health indications are much more
numerous than suicides and have a substantial impact on health care costs.6
A problem with using the BCBS data to examine practice style is that most doctors also
see patients with other types of insurance. Hence, measures of practice style constructed
using only the BCBS data could omit many of a doctor’s other patients. We remedy this
problem by measuring dispersion in prescribing using a second data base from IQVIA which
comes from their Xponent data base.7IQVIA (formerly known as IMSQuintiles) is a public
company specializing in pharmaceutical market intelligence. As of 2014, IQVIA directly
surveyed 86% of retail pharmacies, with the remaining prescriptions imputed to add to
industry totals using a patented projection method. The data includes information about
each provider from the American Medical Association. We are able to find a match in the
IQVIA data for 74.0 percent of the doctors in our BCBS data sample. We also match in
doctor characteristics such as specialty from the National Plan and Provider Enumeration
System (NPPES). We follow Berndt et al. (2015) and limit our analysis to doctors who wrote

5Accessing

insurance claims data often requires extended negotiations with individual insurance carriers, or
with government entities. Further information about the BCBS Health of American Initiative, including
information about their Axis® data base and contact information is available at: BCBS Health of America.
6Our own calculations using hospital records from six states that participate in the Health Care Utilization
Project (Arizona, Florida, Kentucky, Maryland, New Jersey, and New York) suggest that in 2014 there were
379.9 ER visits annually per 1,000 individuals. Of these, 50.9, or 13.4% listed a mental health diagnosis on the
hospital record. This included 5.1% who listed mood disorders and 4.9% who listed anxiety. Anti-depressants
are frequently prescribed for both of these conditions.
7The IQVIA data is available for purchase to qualified researchers. For further information, contact
Allen.Campbell@iqvia.com.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

9

12 or more prescriptions for anti-depressants in the IQVIA data in at least one year of the
sample, and who were not missing doctor characteristics.
Following Theil (1967) and Shorrocks (1980) we use the Shannon entropy score as our
main measure of dispersion in doctor prescribing. Results were qualitatively similar if we
used a Herfindahl index or the share of a doctor’s anti-depressant prescriptions that was for
their favorite drug.
P
To define entropy, let p ∈ ∆n = {p ∈ [0, 1]n | i pi = 1} be a probability vector. Let n (p)
denote the number of entries in the vector.
Definition 1. Given a vector p ∈ ∆n , then the scaled entropy score is given by Φ (p) =
P
φ (p) /log (n) ∈ [0, 1], where φ (p) = nk=1 pk log(1/pk ) is the Shannon entropy index, k is
the number of drugs that are ever available over the sample period, and pk is the share of
patients who are taking drug k at time t.
The scaled measure has values between zero and 1, and a unique maximum with pk
= 1/k. There are k minima, each corresponding to pk = 1. Let njt be the number of
patients that a doctor treats in period t, and let ndjt be the number of prescriptions of
n
drug d ∈ D = {d1 , . . . , dm }, where m is the number of drugs, in period t. Let pdjt = ndjt
,
jt
be the fraction of patients of doctor j who are prescribed drug d in period t. This mdimensional vector pjt ∈ [0, 1]m is a measure of the doctor’s practice style at time t. It
can be summarized using the normalized entropy score defined above. We allow a doctor’s
entropy score to vary over time, calculating a separate entropy score for each doctor for each
calendar year of data.8 We match 2013 BCBS data to 2012 doctor entropy data, and so on.
Due to data limitations, both 2015 and 2016 BCBS data are merged to entropy measures for
2014; however, within doctor entropy changes only slowly over time. Once the IQVIA data
are matched to the BCBS data, we use the mean entropy score for each doctor over the entire
treatment interval with that patient. This decision eliminates small changes in entropy scores
that would otherwise occur whenever the patient’s treatment interval happens to span more
than one calendar year of data. It means that within-patient changes in entropy are due solely
to changes in the prescribing doctor. Since there are 33 different anti-depressant molecules
in use over our sample period, the entropy score is computed using m=33. However, the top
eleven molecules accounted for the vast majority of the prescriptions in 2014 (see Appendix
Table 1), and when we focus on transitions from one drug to another we use these eleven
molecules plus “all others” and drug combinations (which we dub “cocktails.”)

8Since

the entropy score is a non-linear function of treatment choice, one might worry about biased estimates
for doctors with few patients. Simulations of the entropy index showed that the small sample bias is
sufficiently small that we can ignore it.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

10

Table (1) provides information about the breakdown of anti-depressant prescriptions and
entropy scores across types of providers in the IQVIA data. The vast majority of antidepressant scripts are written not by psychiatrists but by general practitioners and other
doctors who have little specific training in the use of anti-depressants. The model discussed
below predicts that providers with less expertise should do less experimentation. Table (1)
shows that in keeping with this prediction, psychiatrists have the highest entropy scores,
followed by GPs, with other doctors having substantially lower entropy scores. Entropy
scores increase with doctor cohort, except among the oldest doctors where they show a
decline which is consistent with prime age doctors being the most skilled. A limitation
of the version of the IQVIA data that we were able to obtain is that there is no patient
identifier. Therefore, we cannot examine experimentation within-patient in these data, and
the overall entropy scores in the second panel of Table (1) represent a mix of within patient
and across patient prescribing.
Table 1. Volume and Dispersion of Physician Prescribing in 2013, by Specialty
All
Other
GPs
Psychiatrists
prescriptions
physicians
# Prescriptions (millions)
231.6
120.7
51.1
15.9
# Prescribers
767,985
267,898
49,523
214,928
Prescriptions/Provider
301.6
450.5
1032.5
73.8
Average Entropy Scores by Medical School Graduation Year
<1975
0.619
0.619
0.656
0.500
1976-1985
0.623
0.631
0.657
0.499
1986-1995
0.618
0.630
0.649
0.479
1996+
0.608
0.625
0.631
0.445
Average Share of Drugs to Physician's "Favorite" Drug
<1975
0.257
0.256
0.223
0.364
1976-1985
0.253
0.245
0.218
0.366
1986-1995
0.254
0.242
0.220
0.387
1996+
0.258
0.242
0.229
0.415
Notes: Entropy calculations include only providers with >=12 scripts in the year and
are based on m=33 separate drug molecules. Data on prescriptions from IQVIA includes
physician identifiers and is merged to American Medical Association files that provide the
doctor’s medical school graduation year and specialty.

In order to give some intution about how variations in entropy scores correspond to other
Page 1
measures, in the bottom panel of the table, we show that among GPs, roughly a quarter of
prescriptions are for the favorite drug, compared to about 22% among psychiatrists, and 36
to 42% among other specialties, depending on the cohort.
A second measure of practice style is the extent to which a doctor follows practice guidelines. We consider guidelines provided by the American Psychiatric Association (Gelenberg
et al. (2010)), the UK National Institute for Health and Care Excellence (NICE), and the
Canadian government. The NICE guidelines suggest that clinicians should start with an

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

11

SSRI, and if that does not work then they should consider a drug in a different class (NICE,
2017). The Canadian guidelines point out that even within drug classes, some drugs are
more efficacious. They suggest that if the first drug does not work clinicians should switch
to a more effective drug. They provide rankings based on comparisons of the effectiveness
of different drugs as first line treatments in clinical trials (Kennedy et al. (2016)).
The American Psychiatric Association’s (APA) guidelines for treatment of major depressive disorder advise that if one drug is not effective, the patient should switch to another
but they do not specify what that drug should be. They do however note that “the following medications are optimal for most patients: SSRIs, SNRIs, Mirtazapine, and Bupropion”
(page 31, Gelenberg et al. (2010)). This list excludes two drugs that together accounted for
17.58% of the market in 2014 (see Appendix Table 1). Since most drug combinations have
not been evaluated in clinical trials, the possible drug interactions or side effects are largely
unknown. Hence, all guidelines also urge caution in the use of “drug cocktails.”
Diffusion in prescribing and the violation of guidelines are related since following a guideline means ruling out potential choices. Figure 1 illustrates this relationship by showing the
actual distribution of entropy scores compared to the counter-factual distribution that would
exist if all doctors adhered to the APA guidelines. In the counter-factual, prescriptions for
medications that violate guidelines are distributed over the remaining options in proportion
to actual prescription patterns. Figure 1 shows that if the APA guidelines were followed, the
right tail of the entropy distribution would be compressed, and the whole distribution would
shift to the left. Hence, the APA guidance, while loose, would still be binding on practice
styles if it were followed.
Table (2) provides an overview of the BCBS data. The table divides patients into those who
ever saw a psychiatrist as an outpatient, and those who did not. We do not divide patients
into whether they are currently seeing a psychiatrist or not, because the same patient is
more likely to start seeing a psychiatrist if their condition deteriorates. Table (2) shows that
most patients in our sample never see a psychiatrist over the 12 to 13 months that we follow
them. Patients who ever see a psychiatrist during the window in which we observe them will
be seeing more skilled providers on average. On average, patients experience 1.3 changes
in entropy scores, which coincide with changes in the doctor treating them. When we look
at drug transitions, we have a slightly smaller sample because we lose the first observation
when we lag.
The second panel of Table (2) provides information on how often patients changed medications in a way that violated one of the prescription guidelines. The informal APA guideline
is most likely to be violated. Relatively large numbers of patients receive a cocktail of
drugs, especially from psychiatrists. To get some understanding of the magnitudes, consider
that a patient who is in the data for 11 months, is observed to have 10 month-to-month

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

12

transitions, where “transitions” also include staying on the same medication from month to
month. Hence, if 4.5 percent of all transitions violate the guideline, the average patient has
0.45 violations over the period that we see them.

Figure 1.

Actual and Counterfactual Distribution of Physician Entropy Scores. This figure

shows the distribution of actual entropy scores in 2013 (shaded bars) and the distribution that
would have existed if doctors had followed the APA guidelines for prescribing (white bars). We
assume prescriptions that are in violation of guidelines would have been distributed in the same
way as a doctor’s remaining prescriptions had they followed the guidelines.

The third and fourth panels of Table (2) present data on the costs of care and outcomes.
These include total monthly costs and costs broken into pharmacy, professional (e.g. doctor
visits), and facility (e.g. hospital) claims. All of these costs are right skewed: The modal
patient is not very expensive, while the 90th percentile (or in the case of facilities costs,
the 99th percentile) patient incurs considerable monthly costs. These figures represent the
actual amount paid to the various providers. Patients who saw a psychiatrist at some point
have higher costs in every category suggesting that they are sicker on average. We will
include patient fixed effects to control for differences in the patient’s average severity level.
Comparing models with and without patient fixed effects also provides information about
which patients switch to higher skilled physicians, as discussed further below. While costs
are important, our primary outcomes are indicators for whether the patient used the ER
or was hospitalized with a mental health indication. Overall, approximately one percent of
patients had an ER visit or hospitalization with a mental health indication each month.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

13

Although these data are rich, they have some major limitations. The most significant
limitation in the IQVIA data is the lack of a patient identifier. Arguably, high diffusion in
drug choices within a patient represents a different sort of experimentation than diffusion
across patients. High diffusion across patients could even be interpreted as an additional
measure of skill since it could mean that a doctor is sorting patients into different categories
before prescribing to them. Two limitations of the BCBS data are that we do not follow
most patients very long, and that we only see a subset of each doctor’s patients (those who
have BCBS coverage). A third limitation of the BCBS data is that many people who are
treated with anti-depressant drugs lack any indication about why they are being treated. For
example, if a patient is prescribed anti-depressants in the course of their annual physical, or
in a followup visit to an obstetrician, the only indication on the claim may be for a general
visit. Hence, it is possible that some people in our sample are being treated “off-label” for
another condition such as anxiety. Thus, the most accurate description of our sample is that
it includes people who are treated with anti-depressants at some point in our sample period.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

14

Table 2. Summary of BCBS Patient Data by Outpatient Provider
Patient Type:

All Patients

Ever Saw
Psychistrist

Never Saw
Psychiatrist

450,802
5,409,124
11.999

82,810
1,117,032
13.489

367,992
4,292,092
11.664

4.491

8.917

3.335

218.27
2,025.83
48.38

86.87
1,242.10
20.16

794.23
19.75
699.94

447.98
0.00
451.30

0.00
198.42

0.00
88.72

9,767.20

7,232.10

0.0237

0.0323

0.0214

0.0097

0.0170

0.0077

# members
# member-months

# months/member
# months antidepressants/member
8.303
9.499
8.034
# changes in entropy/member
1.331
1.621
1.265
# member-month with drug transitions
4,716,167
976,768
3,739,399
Percent monthly drug transitions from t-2 to t-1 that violate each guideline (as % of row 8)
UK
0.102
0.117
0.098
Canada
2.406
2.177
2.466
US
4.623
3.334
3.601
Cocktail

Average Monthly Costs (in Jan. 2013 dollars)
total monthly cost: 50th p'tile
109.17
90th p'tile
1,412.10
pharmacy cost: 50th p'tile
23.95
90th p'tile
519.57
professionals cost: 50th p'tile
0.00
90th p'tile
facility cost: 50th p'tile

504.15

0.00
90th p'tile
108.51
99th p'tile
7,828.53
Share with Emergency Room or Hospitalization each Month
1 if any ER/hospitalization
1 if any ER/hosp. for mental health

Notes: Authors’ calculations from the BCBS data. The treatment period is defined as up to 1
month before the first observed month with an anti-depressant script up till 3 months after the
last observed month with an anti-depressant script. ER/Hosp. visits are considered to have been
for mental health if that is one of the indications listed. Transitions can be from the same drug
to the same drug or from a drug to no drug, for
example.
Page
1

4. Empirical findings
In order to examine the relationship between dispersion in a doctor’s prescribing and
patient outcomes, we estimate models of the form:
(1)

Yijt = a0 + b1 φjt−1 + b2 xi + b3 countyi + b4 yt + eijt ,

or alternatively:
(2)

Yijt = ai + b1 φjt−1 + b2 yt + eijt ,

where Y is one of the outcomes discussed above, x are the observable fixed patient characteristics (age category and gender), county indicates county fixed effects, and y indicates year
fixed effects. The second specification, which includes patient fixed effects, subsumes the
observable patient characteristics and county fixed effects (since most patients do not move
in the short interval that we observe them). By including a patient fixed effect, we control

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

15

for important unobserved characteristics of the patient including their mean overall severity,
history prior to appearing in the claims data, taste for medication, and so on. We estimate
the model separately for patients who ever saw a psychiatrist as an outpatient and for those
who did not, in order to allow for the effects of entropy to be different for patients who see
providers with different average skill levels. The doctor’s entropy score is measured at t-1
for an outcome measured at time t, so that the measure of practice style always precedes
the outcome.
In order to examine the relationship between violations of treatment guidelines and outcomes, we estimate models of the following form:
(3)

Yijt = a0 + b1 V ijt−1 + b2 xi + b3 countyi + b4 yt + eijt ,

or alternatively:
(4)

Yijt = ai + b1 V ijt−1 + b2 yt + eijt ,

where V is a vector of four indicators each equal to one if a drug transition between t-2 and
t-1 violated one of the three guidelines discussed above, or if it involved the prescription of a
drug cocktail. Hence, we look at the outcome one period after a change in the drug regime,
that is, at period t. These regression models will show how diffusion in prescribing and the
violation of guidelines are related to patient outcomes. Although all of these patients are
being treated in the U.S., we can consider the hypothetical effects of violating guidelines from
Canada and the U.K. and thus gain a rough idea of the efficacy of the different guidelines.
Including patient fixed effects offers a powerful way to control for patient heterogeneity
in order to isolate the effects of doctor practice style. There may however, still be timevarying, unobserved characteristics of patients that are important. In particular, patients
who are getting worse may transition to more skilled doctors (e.g. from general practitioners
to psychiatrists). If higher entropy scores are associated with greater skill but sicker patients
match with more skilled doctors, then the estimated effects of diffusion in prescribing will be
biased towards zero so that our estimates will tend to understate any true positive effects of
entropy. All standard errors are clustered on the doctor’s ID in order to allow for correlations
in treatment within doctors, both for the same patient over time and between patients seeing
the same doctor.
Regressions of patient outcomes on provider entropy scores are shown in Table 3 for the
full sample, as well as for the two subsamples defined by whether the patient ever saw
a psychiatrist. Odd-numbered columns control for county fixed effects, broad patient age
categories and gender. Even-numbered columns control for patient fixed effects. The first row
of the first two columns suggests that patient heterogeneity is important: In the regressions
without patient fixed effects, it appears that provider entropy increases costs, whereas once

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

16

patient fixed effects are included in the model, entropy is shown to have a significantly
negative relationship with costs. What this tells us is that the sicker patients tend to match
with the highest entropy providers, leading to a positive bias in the relationship between costs
and entropy in OLS. When that selection is controlled for by looking within patients, we see
that more diffuse prescribing (higher entropy) is associated with better patient outcomes.
Since the dependent variable is log costs, the coefficient of -0.085 in column 2 can be
interpreted as an elasticity: A one unit change in entropy would lead to a 8.5% decrease
in total costs. Entropy varies from around 0.4 to 0.8 as shown in Figure 1, with most
mass between 0.5 and 0.75. Hence an entropy measure 0.25 higher is correlated with a
2.1% decrease in costs. The columns with fixed effects show that an increase in entropy is
associated with a large decrease in non-drug costs (a 0.25 increase in entropy is estimated
to reduce these costs by 4.0%). A small part of this reduction comes from reductions in the
probability of ER visits and hospitalizations. An increase of 0.25 in entropy is associated
with a 0.001 point decline in the probability of such visits on a baseline of 2.4%.
These overall patterns mask differences in the estimates by patient group. Patients who
saw a psychiatrist at some point see more skilled practitioners on average. The patient
fixed effects models show the differential effects of entropy net of differences in the patients’
average conditions. Panel B shows that among patients who ever saw a psychiatrist, more
diffuse prescribing is associated with a reduction in ER visits and hospitalizations, both
overall and specifically for mental health. The corresponding fixed effects models indicate
that an increase of 0.25 in the provider entropy score is associated with a reduction of 10.2%
in the probability of any ER visit or hospitalization. The probability of a visit specifically
for a mental health diagnosis falls by 14.7%. Comparing the OLS and fixed effects estimates
of the effect of entropy on the probability of an ER/Hospital visit with a mental health
indication, we see that the sign changes from positive to negative. This change indicates
that patients who are more likely to go to the ER or be hospitalized are also more likely to
switch to a higher entropy provider (recall that psychiatrists have more diffuse prescribing
on average). Hence, OLS estimates of the effect of entropy are biased. When this bias is
mitigated by including patient fixed effects, we find that among patients seeing more skilled
doctors, switching to a higher entropy doctor is associated with better patient outcomes, our
empirical finding #1.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

17

Table 3. Patient Outcomes at t and Provider Entropy at t-1
(1)

(2)

(3)

(4)

ln(nonln(nonln(total
ln(total
drug
drug
Outcome:
cost)
cost)
costs)
costs)
Patient FE
no
yes
no
yes
Panel A: All patient observations
Entropy (t-1)
0.309
-0.085
-0.106
-0.160
(0.034)
(0.039)
(0.035)
(0.038)
Constant
3.806
5.003
2.510
3.159
(0.033)
(0.025)
(0.035)
(0.025)
Mean Dep. Variable
3.976
3.976
2.512
2.511
Adj. R2
0.044
0.433
0.027
0.303
# Obs. (millions)
5.409
5.409
5.409
5.409
# Members
450,802
450,802
450,802
450,802
Panel B: Patients who ever saw a psychiatrist as an outpatient
Entropy (t-1)
0.040
0.044
-0.214
-0.013
(0.066)
(0.073)
(0.083)
(0.073)
Constant
4.379
5.500
3.004
3.661
(0.078)
(0.049)
(0.090)
(0.049)
Mean Dep. Variable
4.557
4.557
3.024
3.024
Adj. R2
0.059
0.424
0.051
0.353
# Obs. (millions)
1.117
1.117
1.117
1.117
# Members
82,801
82,801
82,801
82,801
Panel C: Patients who never saw a psychiatrist as an outpatient
Entropy (t-1)
-0.153
-0.180
-0.564
-0.222
(0.034)
(0.045)
(0.035)
(0.045)
Constant
3.986
4.907
2.685
3.036
(0.035)
(0.028)
(0.037)
(0.029)
Mean Dep. Variable
3.825
3.825
2.378
2.378
Adj. R2
0.048
0.374
0.028
0.282
# Obs. (millions)
4.292
4.292
4.292
4.292
# Members
367,992
367,992
367,992
367,992

(5)

(6)

(7)

(6)

ER or
Hospital
no

ER or
Hospital
yes

ER/Hosp
for
Mental
Health
no

ER/Hosp
for
Mental
Health
yes

-0.004
(0.001)
0.024
(0.001)
0.024
0.004
5.409
450,802

-0.005
(0.002)
0.030
(0.001)
0.024
0.092
5.409
450,802

0.008
(0.001)
0.004
(0.001)
0.010
0.002
5.409
450,802

-0.001
(0.001)
0.011
(0.001)
0.010
0.073
5.409
450,802

-0.013
(0.003)
0.035
(0.003)
0.032
0.012
1.117
82,801

-0.013
(0.004)
0.046
(0.003)
0.032
0.110
1.117
82,801

0.005
(0.002)
0.014
(0.002)
0.017
0.008
1.117
82,801

-0.010
(0.003)
0.024
(0.002)
0.017
0.098
1.117
82,801

-0.008
(0.001)
0.026
(0.001)
0.021
0.004
4.292
367,992

0.000
(0.002)
0.024
(0.001)
0.021
0.086
4.292
367,992

0.003
(0.001)
0.005
(0.001)
0.008
0.002
4.292
367,992

0.003
(0.001)
0.006
(0.001)
0.008
0.060
4.292
367,992

Notes: Each column of each panel shows coefficients from a single regression model.
These regressions show the relationship between the physician’s entropy score at t-1 and
patient outcomes at time t. All models include year and month fixed effects. Regressions
in odd numbered columns include county fixed effects, patient age, and gender. These
controls are dropped when patient fixed effects are added. Standard errors are clustered
on provider ID.

The group of patients who never saw a psychiatrist as an outpatient are seeing less skilled
providers on average, mainly GPs. The patient fixed effects models show that in this group,
switching to a higher entropy doctor appears to lower costs, but this is not driven by a
significant reduction in ER visits or hospitalizations, suggesting that these high-entropy
GPs are just lower cost providers on average. Moreover, although there is no change in
the propensity to use the ER or hospital, there is a 9.7% increase in the probability of an
ER/hospital visit with a mental health indication. It is possible that this increase reflects
a higher likelihood of reporting a mental health problem for a given ER/hospital visit.
The overall take away is that in patients seeing this group of relatively less skilled doctors,
switching to a higher entropy provider does not improve patient outcomes, our empirical
finding #2.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

18

Our story that psychiatrists have both more diffuse prescribing and greater skill in treating
mental health patients is consistent with both sets of results. An alternative story is one
in which a patient switches doctors following a crisis, but then regresses back towards their
mean level of illness. However, if this were the case, then we might expect to see a similar
pattern in the two groups of patients. That is, it might be reasonable to assume that patients
who experience a crisis are more likely to switch to a doctor willing to prescribe a broader
portfolio of drugs even if they do not switch to a psychiatrist, and that regression to the
mean would operate similarly in both groups of patients. To explain our results, it would
have to be the case that regression to the mean was important in one group (those ever
seeing psychiatrists) but not in the other.
Table (4) shows the estimated relationship between patient outcomes in month t, and
having had a drug transition from month t-2 to t-1 that violated treatment guidelines.
Transitions that violated the UK guidelines are associated with higher costs and an increase
in ER visits or hospitalizations in OLS, but not in patient fixed effects models. This change
in significance indicates that patients are more likely to make such transitions when they
are sicker. Transitions that violate the Canadian or U.S. treatment guidelines are associated
with uniformly worse patient outcomes including higher costs, and more ER visits and hospitalizations with mental health indications. Panel A, which shows estimates for all patients,
indicates that the coefficient estimates are reduced when patient fixed effects are included
in the model, showing that doctors are more likely to violate guidelines or to prescribe drug
cocktails for sicker patients. But they remain statistically significant: Even within patient,
drug transitions that violate guidelines are associated with increases in ER visits and hospitalizations with mental health indications. The fixed effects estimates suggest that violations
of the U.S. guidelines are associated with a 28.2% increase in total costs, an increase in the
probability of any ER visit or hospitalization of 13.0%, and an increase in the probability of
an ER visit or hospitalization with a mental health indication of 20.0%.
Prescribing drug cocktails is also associated with increases in ER visits and hospitalizations, as well as with a 51.4% increase in total costs. Some of the higher cost is mechanical
in the sense that taking more drugs will usually involve higher costs than taking less drugs.
But column (4) shows that total non-drug costs also rise by 36.3% which may reflect the 20%
higher probability of having an ER visit or hospitalization with a mental health indication.
The next two panels of Table (4) examine the relationship between violations of the different treatment guidelines and outcomes in the two subsamples of patients defined by whether
or not they ever saw a psychiatrist as an outpatient. The relationships are quite similar
across the two groups indicating that violations of treatment guidelines are associated with
bad outcomes whether they are prescribed by more or less skilled practitioners, which is

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

19

our empirical result #3. For instance, although the point estimates on ER visits and hospitalizations are higher in the patients who ever saw a psychiatrist as an outpatient, this is
because the baseline risk of this outcome is higher in this group. In the patient fixed effects
models, a violation of U.S. guidelines is associated with an increase in the probability of
any ER visit or hospitalization of 15.6%, and with a 17.6% increase in the probability of an
ER visit or hospitalization for a mental health condition. Hence, patients who experience a
drug transition that violates treatment guidelines have a significantly higher probability of
a subsequent ER visit or hospitalization, and much of this increase is accounted for by visits
with mental health indications.
In summary, the estimates in Table (3) indicate that seeing a doctor with more diffuse
prescribing is associated with better patient outcomes among patients who see more skilled
practitioners, but not among patients who see less skilled practitioners. Table (4) suggests,
however, that there may be a limit on the extent to which experimentation is beneficial even
among skilled practitioners, and that therefore there may be a useful role for guidelines that
restrict some prescribing practices.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

Table 4. Outcomes at t when Drug Transition from (t-2) to (t-1) Violated
Prescribing Guidelines
(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

ln(total
cost)
yes

ln(nondrug
costs)
no

ln(nondrug
costs)
yes

ER/Hosp ER/Hosp
for
for
ER or
ER or
Mental Mental
Hospital Hospital Health
Health
no
yes
no
yes

0.214
(0.034)
0.282
(0.007)

0.703
(0.045)
0.519
(0.009)

0.216
(0.041)
0.291
(0.008)

0.012
(0.003)
0.010
(0.0005

0.003
(0.003)
0.003
(0.0005)

0.006
(0.002)
0.004
(0.0003)

-0.001
(0.002)
0.002
(0.0003)

0.388
0.488
0.423
0.416
(0.009)
(0.008)
(0.010)
(0.009)
Cocktail
1.009
0.514
0.800
0.363
(0.011)
(0.009)
(0.013)
(0.010)
Mean Dep. Variable
4.010
4.010
2.514
2.514
Adj. R2
0.054
0.389
0.034
0.308
# Obs. (millions)
4.716
4.716
4.716
4.716
# Members
450,802 450,802 450,802 450,802
Panel B: Patients who ever saw a psychiatrist as an outpatient
Violation UK Guidelines
0.444
0.249
0.726
0.315
(0.071)
(0.066)
(0.090)
(0.078)
Violation US Guidelines
0.256
0.241
0.378
0.271
(0.016)
(0.013)
(0.018)
(0.015)

0.007
(0.001)
0.017
(0.001
0.023
0.005
4.716
450,802

0.004
(0.001)
0.005
(0.001)
0.023
0.093
4.716
450,802

0.003
(0.0003)
0.011
(0.0003)
0.010
0.003
4.716
450,802

0.002
(0.0003)
0.002
(0.0004)
0.010
0.074
4.716
450,802

0.012
(0.007)
0.011
(0.001)

-0.001
(0.006)
0.005
(0.001)

0.010
(0.005)
0.005
(0.001)

-0.001
(0.005)
0.003
(0.001)

Violation Can. Guidelines

0.498
0.513
0.486
0.416
(0.020)
(0.017)
(0.023)
(0.020)
Cocktail
0.774
0.581
0.638
0.444
(0.017)
(0.014)
(0.022)
(0.015)
Mean Dep. Variable
4.573
4.573
3.017
3.017
Adj. R2
0.070
0.391
0.059
0.362
# Obs.
976768
976768 976768
976768
# Members
82,810
82,810
82,810
82,810
Panel C: Patients who never saw a psychiatrist as an outpatient
Violation UK Guidelines
0.551
0.200
0.647
0.183
(0.042)
(0.039)
(0.051)
(0.047)
Violation US Guidelines
0.387
0.298
0.504
0.299
(0.009)
(0.008)
(0.010)
(0.009)

0.008
(0.001)
0.016
(0.001)
0.032
0.012
976768
82,810

0.002
(0.001)
0.005
(0.001)
0.032
0.111
976768
82,810

0.005
(0.001)
0.012
(0.001)
0.017
0.009
976768
82,810

0.002
(0.001)
0.002
(0.001)
0.017
0.101
976768
82,810

0.011
(0.003)
0.009
(0.001)

0.004
(0.003)
0.003
(0.001)

0.005
(0.002)
0.003
(0.0003)

0.000
(0.002)
0.001
(0.0003)

Violation Can. Guidelines

0.007
(0.001)
0.014
(0.001)
0.021
0.005
3.739
367,992

0.005
(0.001)
0.004
(0.001)
0.021
0.086
3.739
367,992

0.003
(0.0003)
0.007
(0.0004)
0.008
0.002
3.739
367,992

0.002
(0.0004)
0.002
(0.0004)
0.008
0.060
3.739
367,992

ln(total
Outcome: cost)
Patient FE
no
Panel A: All patient observations
Violation UK Guidelines
0.564
(0.037)
Violation US Guidelines
0.403
(0.008)
Violation Can. Guidelines

Cocktail
Mean Dep. Variable
Adj. R2
# Obs. (millions)
# Members

0.372
(0.010)
0.877
(0.014)
3.863
0.055
3.739
367,992

0.483
(0.009)
0.468
(0.012)
3.863
0.380
3.739
367,992

0.416
(0.011)
0.640
(0.016)
2.383
0.033
3.739
367,992

0.418
(0.010)
0.307
(0.013)
2.383
0.286
3.739
367,992

Notes: Each column of each panel represents a single regression model. These regressions
show the relationship between a transition (between t-2 and t-1) that violated one of the
guidelines, and the patient’s outcomes at time t. All models include year and month
fixed effects. Regressions in odd numbered columns include county fixed effects, patient
age, and gender. These controls are dropped when patient fixed effects are added.
Standard errors are clustered on provider ID.

20

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

21

5. Understanding Variation in doctor Practice Style
The empirical evidence shows that diffusion in prescribing and the violation of guidelines
are two dimensions of doctor practice style that show a great deal of variation in the data.
Patients are better off with doctors who do not violate treatment guidelines and with psychiatrists who use a greater variety of drugs in treatment. In this section we explore the
implications of optimal and boundedly rational decision making for practice style. In the
first sub-section we illustrate the main ideas for a two-drug, two-period example in which we
can explicitly compute the Bayesian optimal choice. We introduce the notion of a reservation
probability using ideas from the machine learning literature for solving multi-armed bandit
problems. We show that with two choices the optimal decision can be implemented with a
reservation probability rule. The optimal reservation probability increases with the doctor’s
skill and decreases with the discount rate.
Currie and MacLeod (2020) extend this idea to the multi-drug choice problem and show
that in the multi-drug case the reservation probability rule converges to the optimal long
run treatment at the same rate as the optimal choice rule. Moreover, higher skilled doctors
converge towards the optimum faster and exhibit both more experimentation and more
diffuse prescribing in the short run.
However, the short run properties of the rule depend on small sample statistics, and
are difficult to understand analytically. The most efficient way try to understand how the
algorithm behaves in the short run is through simulation. Hence, in the second subsection
below we use data from randomized controlled trials to calibrate the model for the multi-drug
case. We show that doctors with low skill have better outcomes when they have a relatively
low reservation probability, while higher skilled doctors achieve better outcomes with higher
reservation probabilities. In the long run, experimentation can lead to better outcomes, but
since experimentation can involve exposing patients to sub-optimal treatments, it also leads
to short-term costs. Finally, we observe that restricting choice via guidelines can enhance
the performance of all doctors when patients are being seen over shorter treatment intervals.
To keep the analysis as clear as possible, we suppose that there is no risk aversion and that
doctors and patients have the same preferences over outcomes. Since we use a normal-linear
framework the analysis can be extended to deal with risk aversion, and such an extension
does not affect the qualitative features of choice.
5.1. A Two-Drug, Two-Period Example of Drug Choice. Suppose that doctors follow a procedure that is consistent with optimal choice, but that observed behavior may vary
depending on doctor characteristics, especially skill. Our approach to thinking about the
problem follows from Simon (1955). Simon shows that a reservation wage provides a parsimonious description of search behavior over time. One may not observe worker discount

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

22

rates or search costs, but knowing the reservation wage enables us to predict a worker’s decision to accept a job at wage w or continue to search for better wage. Our context is similar:
Since the outcome from drug treatment is uncertain, a single observation is not sufficient to
determine the best choice of drug. The doctor must use repeated trials of different drugs in
order to find the best choice. At each decision point, there is a trade-off between sticking
to a treatment or experimenting with other treatments that may have higher benefit. In
the multi-armed bandit problem this trade-off is framed as the choice between exploitation
- continuing with the same arm - or exploration - trying a new arm.
The essential building block of our model is a simple index rule for assigning a valuation to
each choice. Suppose that the doctor is deciding between two drugs, d ∈ {A, B}, where the
doctor’s beliefs regarding the effect of these drugs are characterized by a Normal distribution:
2
2
ed ∼ N (µtd , σtd
), where µtd is the ex ante mean effect of the drug d in period t and σtd
is
the doctor’s belief regarding the variance of the effect for a patient in this period.
Now suppose that doctor j’s taste for experimentation at date t can be summarized by
a reservation probability pjt ∈ [0.5, 1]. The index rule we use to assign a value to drug
d ∈ {A, B} is:
(5)

qjtd = µtd + F −1 (pjt ) σtd ,

where F () is the cumulative distribution function for the standard Normal distribution.
Since F −1 (pjt ) is increasing in pjt then a higher reservation probability leads to a higher
2
weight on the variance. Since etd ∼ N (µtd , σtd
), then in period t for d ∈ {A, B}:


qjtd − µtd
(6)
P r [etd ≤ qjtd ] = F
= pjt .
σtd
Observe that when the reservation probability is 50% then F −1 (0.5) = 0. In that case
P r [etd ≤ qjtd = µtd ] = 0.5. In other words in this case the valuation is simply the estimated
effect of treatment, and hence the short run optimal choice is a special case of a reservation
probability rule with ρjt = 0.5.
Suppose the mean effect of drug A is greater than drug B, but the variance of B is higher
than the variance of A. When the reservation probability is 50% the doctor behaves like a
short-term optimizer and selects the arm with the highest expected effect. Hence drug A
would be chosen. Since the variance of treatment B is higher than that of treatment A,
from (5) it follows that for some some probability p̄AB > 0.5 we have for all pjt > p̄AB that
qjtB > qjtA .
These possibilities are illustrated in Figure (2). When the reservation probability is 0.5
0.5
the valuation is equal to the mean of the treatment effect, qjtd
= µjtd , d ∈ {A, B}, and
0.5
0.5
qjtA > qjtB . A “behavioral” interpretation of this rule is that if the probability that drug
B is better than drug A is less than 50%, then the doctor sticks with drug A. When the

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

23

0.95
0.95
reservation probability is 95%, then qjtB
> qjtA
, and the doctor will try drug B as long as
there is a 5% or better chance that it will have a better effect than drug A. We can show that
this rule corresponds to an optimal choice for the two-period decision once we incorporate
physician learning.
Suppose patient i’s underlying condition does not change over time, and is summarized by
an unobserved value: γi0 ∈ < in period t = 0 , where γi0 < 0 indicates a severe depression that
should be treated. A patient taking drug d has (unobserved) condition γid = γi0 + eid ∈ <,
where eid is the treatment effect of the drug.
The doctor meets the patient twice. In period 1 the doctor observes a signal of the patient’s
condition, yij1 . The doctor then prescribes a drug d1 ∈ {A, B}. The patient takes the drug
and realizes condition γi1d1 = γi0 + ei1d1 at the end of period 1. At the beginning of period 2
the doctor meets again with the patient, observes her condition, yij2 , and prescribes a drug
d2 ∈ {A, B}. The patient’s condition in period 2 is given by: γi2d2 = γi0 + ei2d2 .

1.00

0.95

0.50

0.00

-5.0

-2.5

0.0

2.5

5.0

Figure 2. Effect of Reservation Probability on Drug Choice

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

24

We assume that the doctor’s only goal is to improve the patient’s condition. The doctor’s
payoff is given by:
Uj (d1 , d2 ) = E {(1 − ζj ) γi1d1 + ζj γi2d2 }
=E {γi0 } + E {(1 − ζj ) ei1d1 + ζj ei2d2 } ,
where ζj ∈ (0, 1) is the relative weight placed on payoffs in periods 2 and 1, and dt is the
drug prescribed in period t ∈ {1, 2}. When ζj approaches zero then the doctor only cares
about outcomes in the first period. When ζ approaches 1 then the doctor is concerned only
with the long run well being of the patient, and may use the first period to learn more about
which drug is most effective for the patient.
The initial condition γ0 of the patient is a fixed effect that is not affected by the doctor’s
choice in this model. Hence without loss of generality we can set:
(7)

Uj (d1 , d2 ) = E {(1 − ζj ) ei1d1 + ζj ei2d2 } .

Thus the doctor’s goal is to find the drug that has the largest positive treatment effect.
5.1.1. Beliefs. Doctor choice can be modeled as a Bayesian decision problem. The Bayesian
approach requires the explicit modeling of beliefs for all parameters that are relevant for a
decision:
(1) Patient Condition. The doctor is assumed to have ex ante beliefs regarding the
condition of each new patient. Let prior beliefs regarding patient condition be given
by:


1
2
(8)
γi ∼ N µj0 , σj0 =
.
ρj0
The ex ante precision of this belief is given by ρj0 > 0, the inverse of the variance
of the distribution. We use precision and variance interchangeably, depending upon
which is more convenient: ρvaluation = σ2 1
.
valuation
(2) Drug Efficacy. The ex ante belief about the treatment effect of drug d ∈ {A, B} for
patient i by doctor j is given by:


1
(9)
eid ∼ N µj0d ,
,
ρj0d
where µj0d > 0 is the mean effect, and ρj0d is the precision of the doctor’s beliefs
regarding the benefit of drug d before meeting the patient. After treatment with d
the patient has condition γid = γi0 + eid , where eid is the true, unobserved, realized
effect of drug d. The true effect is revealed over the course of treatment.
(3) Diagnostic skill. The new ingredient we introduce is the ability of the doctor to
observe a patient’s underlying condition. For each patient i, there is a true effect

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

25

of drug d given by eid . The true effect is not observed by the doctor, but inferred
through observation of the patient. At the beginning of period 1 the patient arrives
and the doctor observes patient condition, yij1 :
(10)

yij1 = γi + ij1 ,


where the error term satisfies ij1 ∼ N 0, 2ξ1j (the factor 2 is included to simplify the
subsequent expressions in this two drug case). Here we follow Currie and MacLeod
(2017), and view the precision ρj as a measure of a doctor’s diagnostic skill - the
extent to which they are able to assess a patient’s true underlying condition. A
higher ξj corresponds to a more skilled doctor. Similarly, at the beginning of period
2, the patient again visits the doctor, who receives further information:
yij2 = γi + eid1 + ij2 ,
where ij2 has the same distribution as ij1 .

5.1.2. Decisions. Given these beliefs and the doctor’s skill level, the doctor then makes
choices to maximize her payoff (7). In this simple two-period model it is assumed µj0d > 0,
and hence it is always optimal to prescribe a drug. Assume that ex ante drug A is preferred
to drug B (µj1A ≥ µj1B > 0), and hence in the absence of new information the doctor (and
patient) prefer drug A over drug B, and prefer B over no treatment.
At the beginning of period 1 the doctor’s information is given by I1 = {yij1 } ∈ I1 , the
diagnosis at the end of the first meeting. Since the outcome of the interview provides no
information about any of the drug treatments, there is no updating of beliefs regarding drug
effects. Hence, beliefs in period 1 regarding the effects of the drugs remain unchanged, and
for d ∈ {A, B} then µij1d = µj0d and ρij1d = ρj0d .
At the beginning of period 2 the doctor’s information includes the previous observation,
the drug chosen, and a new observation of the patient’s condition, I2 = {yij1 , d1 , yij2 } ∈ I2 .
Given this information, the doctor’s decisions can be summarized by the function ~δj =
{δj1 , δj2 }, where the choice each period maps information to a drug choice, δj1 : I1 → {A, B}
and δj2 : I2 → {A, B} . The Bayesian optimal decision problem is solved by backwards
induction. One first solves for the optimal choice in period 2 for any possible information
set, and then solves for the optimal choice in period 1 given its impact on period 2 payoffs.
Since ζj > 0, the goal of the doctor in period two is to choose a drug that maximizes
patient well being in period 2:
∗
δj2
(I2 ) = argmaxd2 ∈{A,B} E {eid2 |I2 } .

Consider first the case in which the doctor chooses d1 = A, and let I2A = {yij1 , d1 = A, yij2 }.
We assume that the effects of the drugs are uncorrelated, and hence observing the effect of

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

26

drug A has no effect on the doctor’s beliefs about drug B and:

E eiB |I2A = µij2B = µij1B = µj0B > 0.
The doctor uses the outcome from the first period of treatment to update her assessment
of the success of treatment with drug A. The doctor cannot directly observe true patient
condition γi0 , but can see whether the patient’s condition improves between periods 2 and
period 1, yij2 − yij1 = eiA + ij2 − ij1 ,where the precision/quality of the signal (yij2 − yij1 )
is ξj = 1 +1 1 .
2ξj

2ξj

From this result it follows using the optimal updating rule for Normally distributed random
variables that:

ρj1A µj1A + ξj (yj2 − yj1 )
µj2A = E eiA |I2A =
(11)
= µj1A + ∆ij2A ,
ρj1A + ξj

ξ
2
, is the new information regarding the
where ∆ij2A = ρj1Aj+ξj (yj2 − yj1 − µj1A ) ∼ N 0, σ̂j2A
effect of drug A. Ex ante this information has mean zero and variance:
2


ξj
1
2
2
.
(12)
σ̂j2A =
σj1A
+ 2σj2 = ρ2
j1A
ρj1A + ξj
+ ρjiA
ξj
See DeGroot (1972) for an explicit derivation of the one-dimensional case used here.
Notice that the variance of the new information regarding the effect of drug A satisfies
2
σ̂j2A ∈ [0, 1]. The variance is increasing with diagnostic skill and decreasing with the precision
of the doctor’s beliefs regarding the effectiveness of drug A . When the doctor has no
diagnostic skill, ξj = 0, and observing the outcome from period 1 provides no information
2
= 0. The variance of beliefs regarding the effect of the drug also remains unchanged,
so σ̂j1A
ρj2A = ρj1A . In contrast, a skilled doctor (ξj > 0) learns about the effect of a drug by
observing the patient and updates her beliefs regarding the precision of her estimate of eid :
ρj2A = ρj1A + ξj =

1


var eiA |I2A

=

1
2
σij2A

.

Period 2 is the last period of treatment, and hence the doctor prescribes the drug that she
believes will provide the largest expected effect. She continues with drug A if and only if:


E eiA |I2A > E eiB |I2A ,
(13)

µj1A + ∆ij2A = µj2A ≥ µj2B = µj1B .

This result determines the optimal choice at period 2 given that drug A was prescribed
in period 1. In order to decide whether or not to try drug A, the doctor has to consider the
expected benefit of prescribing drug A in period 1 on the improvement in period 2 decision
making. Letting d∗2 denote the optimal choice in period 2, the expected benefit computed in

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

27

period 1 is:

E eid∗2 |yij1 , d1 = A = E {max {µj1A + ∆ij2A , µj1B }}
= µj1A + E {max {∆ij1A , µj1B − µj1A }}


µj1B − µj1A
= µj1A + σ̂j2A V
,
σ̂j2A
where σ̂j2A is given by (12) and V (x) = E {max {x, γ}} = L (x) + x, where γ ∼ N (0, 1) is
the standard Normal distribution. The function L (x) is the unit-normal linear loss function,
which satisfies:
L (x) = E {max {x, γ}} − x = (1 − F (x)) (φ (x) − x) > 0,
where F (x) is the cumulative Normal distribution function and φ (x) = E {γ|γ ≥ x} is the
expected value of a lower truncated Normal distribution.9 This function is a measure of the
value of information from learning the value of γ ∼ N (0, 1), while having x as the alternative
choice.


µjB −µjA
The term Vj1A ≡ σ̂j2A V
represents the option value from choosing drug A in
σ̂j2A
period 1. In period 2 one can continue with drug A and get µj1A , or change to drug B. The
payoff from choosing drug A in period 1 given optimal decision making in period 2 is:
(14)

U (d1 = A, d∗2A ) = (1 − ζj ) µj1A + ζj (µj1A + Vj1A ) = µj1A + ζj Vj1A .

There is a similar expression for drug B where d∗2B represents the optimal choice in period
2 given that drug B was chosen in period 1:
(15)

U (d1 = B, d∗2B ) = (1 − ζj ) µj1B + ζj (µj1B + Vj1B ) = µj1B + ζj Vj1B .

Putting this together we have:
Proposition 2. A rational Bayesian doctor chooses drug A over drug B in period 1 if and
only if:
(16)

µj1A + ζj Vj1A ≥ µj1B + ζj Vj1B ,

an inequality that is satisfied to the first order if and only if:
(17)

µj1A + τj σ̂j2A ≥ µj1B + τj σ̂j2B ,

where τj =

9Raiffa

L(x).

ζi
L (0)
(1−ζj )

ζi
' 0.4 (1−ζ
.
j)

and Schlaifer (2000) provide an extensive discussion of the value of information and the function

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

28

Thus, to the first order, the optimal choice in period 1 is consistent with a reservation
probability that is given by:


ζi
∗
pj = F (τj ) = F
L (0) ∈ [0.5, 1] .
(1 − ζj )
This rule has two interesting features. First, when the doctor cares only about maximizing
the patient’s current condition (ζj = 0), then the reservation probability is 50% and choice is
determined by the static optimal choice rule - she chooses the drug with the highest expected
value. When the doctor cares only about the long run, then ζj → 1 and p∗j → 1, and the
2
choice is completely determined by the variance of the new information, σ̂j2D
: The physician
chooses the highest variance treatment in order to acquire the most information. Given that
preferences are not observed, the reservation probability rule is equivalent to the optimal
rule for some value of p∗j .
The option value from choosing drug d, Vj1d , is a non-linear function of the mean effects
for both drugs. This implies that the Gittins (1979) rule, in which the characteristics of
the arms are additively separable, is not optimal for finite horizon problems. See Gittins
et al. (2011) for an extensive discussion of the issue. Given that in practice choice is over
a finite horizon, using a Gittins type index rule to model optimal choice is necessarily an
approximation.
In this model, there is a clear link between diagnostic skill and experimentation. In
particular, doctor diagnostic skill increases the value of information from experimentation.
Expression (12) implies that increasing the doctor’s diagnostic skill, ξj , increases the return
to experimentation:
∂ σ̂j2d
> 0, d ∈ {A, B} .
∂ξj
2
If ξj = 0, then σ̂j2d
= 0 for d ∈ {A, B}, and the doctor will choose drug A for both periods
because it has the highest ex ante value (since we have assumed µj0A > µj0B ). Increasing
doctor skill, ξj , increases the return from experimentation, and hence the set of situations
where the doctor will choose B over A, even though A is known to be the treatment with
the highest expected value ex ante. Thus, this example illustrates that a better doctor who
is following an optimal decision rule might choose a drug with a lower expected efficacy ex
ante.
5.2. Simulating Practice Style. Although the BCBS data are very rich, they will not
allow us to fully explore the implications of our model for patient welfare. In particular, we
typically do not follow patients in the data very long and so we cannot take account of what
may be lengthy patient histories to directly measure time paths of drug switching. While we
follow doctors for longer than patients, we cannot see how they might be grouping patients
into types, so we also cannot implement the model by examining how doctors sequentially

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

29

treat similar patients. In practice many treatment intervals are relatively short, suggesting
that it would be useful to understand finite sample features of our models. In the finite
sample case it is difficult to obtain meaningful closed form solutions. Hence, the short-run
properties of the model are best assessed with simulations.
Given a reservation probability rule, the value of choosing a particular drug depends on
the characteristics of that drug, as shown in (5). Thus, the two-drug case discussed above
extends naturally to several drugs. Each period the doctor updates her beliefs about the
effectiveness of a drug based on the patient’s current condition using Bayes rule, and then
she chooses the drug with the highest value given the reservation probability. This simple
rule does a very good job of approximating the optimal solution (see Currie and MacLeod
(2020) for details).10
The simulation illustrates the nonlinear way that doctor skill and reservation probabilities
can affect provider behavior and patient utility over short time periods. We examine how
both dispersion in prescribing and patient outcomes are affected by guidelines. An advantage
of simulations is that we can fix the distribution of patients to be exactly the same for each
doctor. Even though patients are ex ante identical, the simulations illustrate that whether
a patient prefers a doctor to experiment or not will depend on the diagnostic skill of the
doctor. This implies that there cannot be a unique optimal treatment protocol that applies
to all patients.
The simulations consider a 2x3 experiment with 6 doctor types. The doctor is either an
expected utility maximizer with reservation probability of 50%, or an experimental type
with a reservation probability of 95%. We also allow doctors to belong to low, medium, and
high-skill groups in terms of diagnostic skill. Let ξj ∈ {10.0, 1.0, 0.1} , measure the accuracy
with which the doctor assesses the patient’s condition. Here ξj = 10 denotes high skill (H),
and ξj = 0.1 denotes low skill (L). Suppose that treatment occurs monthly over a period of
36 months.
In our simulations we assume that doctor priors are given by data about the mean and
variance of the effects of drugs from clinical trials. This implies that all doctors are equally
well informed and hold similar beliefs, which is not likely to be true in practice but is a useful
counter-factual to consider. Clinical trials for anti-depressants randomly assign depressed
patients to treatment and control groups. The control group gets a placebo drug while the
treatment group get the drug under investigation. The level of depression before and after
the experiment is often measured using the Hamilton 17 score (See Hamilton (1960)) in which
a score of h > 7 means that the person is depressed. We normalize this scale so that positive
values indicate that the person is not depressed, and negative values indicate depression: The
10Chapter

14 of Kay (1993) gives a derivation of the n-dimensional linear learning rule for Normally distributed random variables. If the effects of the drugs are correlated then the general learning rule updates
the beliefs for both drugs, which in turn improves the speed of convergence to the optimal choice.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

30

scale is given by log (7) − log (hi ), where hi is the patient’s Hamilton 17 score. Meta-analysis
of drug trials appear regularly in the medical literature so that in principal, all professionals
have access to current results. See for example Linde et al. (2015) and Cipriani et al. (2016).
The clinical trials data we use are described further in the Appendix.
The assumptions we make about drug efficacy in order to model doctor beliefs are briefly
summarized in Table 5. The table details the efficacy of each of the top 11 anti-depressant
drugs (ranked by market share in 2014) in terms of their effects on the improvement in the
Hamilton 17 score. The placebo effect is quite large. In the case of Sertraline (the generic
for Zoloft), which is the most popular drug, the placebo effect is 80% of the total effect of
treatment. The fact that the placebo effect is on average responsible for more than 50% of
a drug’s effect is one factor that can help explain why it is hard to find the most effective
treatment. To address this large placebo effect, we renormalize the effect of treatment by
subtracting the placebo effect. We also allow the effect of “no drug” to be correlated with each
drug within patient. In other words, “no drug” is assumed to correspond to the placebo effect
of seeking treatment, which mechanically creates correlation among all the drug treatments.
Table 5. Effect of Anti-Depression Drugs on Hamilton 17 Score for Depression Severity From Clinical Trials (mean score before treatment is 25.2)
Active Ingredient
Sertraline
Citalopram
Fluoxetine
Escitalopram
Paroxetine
Trazodone
Duloxetine
Bupropion
Amitriptyline
Venlafaxine
Mirtazapine
Placebo

Brand Name(S)
Zoloft
Celexa
Prozac
Lexapro
Paxil
Oleptro
Cymbalta
Wellbutrin
Elavil
Effexor
Remeron
-

Class of
Drug
SSRI
SSRI
SSRI
SSRI
SSRI
SARI
SNRI
NDRI
Tricyclic
SNRI
Tetracyclic

Market Depression Standard
Share 2014, Reduction Deviation
14.63
-9.90
7.78
12.83
-10.30
7.08
10.57
-9.40
6.13
9.68
-10.40
5.97
5.32
-9.80
6.14
9.35
-15.70
9.00
6.84
-10.70
7.00
10.34
-12.00
8.70
5.18
-14.00
8.70
7.09
-12.10
8.71
2.82
-14.00
7.70
-8.00
6.67

Notes: Many anti-depressant drug trials use the Hamilton 17 score for assessing the
severity of depression because it is a continuous measure. The mean depression reduction
and the standard deviations presented here are culled from meta-analyses of drug effects
as described further in an unpublished appendix that is included in the NBER working
paper version of this paper. The market shares are computed by the authors using the
IQVIA data set.

Page 1

The simulations consider a doctor who has a constant load of 300 patients, all drawn from
the same k-dimensional normal distribution of people with “true” drug effects taken from
the clinical trials. Each patient will have a different optimal drug, but at first all patients
will appear to be identical to the doctor. When doing the simulation, we reseed the random
number generator for each of the 6 doctor types. This means that each doctor is facing

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

31

exactly the same population of patients and exactly the same signals from the patients.
Hence, any observed differences in outcomes are due only to differences in the doctor’s
characteristics. We do 10 runs and take the average over the runs, and then plot doctor
utility (which depends on the number of deviations from optimal treatment) and dispersion
in doctor prescribing, characterized using the entropy score (we also tried 100 runs, but the
results were very similar). Since beliefs are fixed by the clinical data, the simulations explore
the effects of doctor diagnostic skill and the doctor’s taste for experimentation, as captured
by the reservation probability.
We consider one additional factor, which is whether there are treatment guidelines. As
discussed above, following guidelines constrains the doctor’s treatment choices. In the long
run, eliminating treatment options should make patients strictly worse off. However, we saw
that empirically, doctors who violate guidelines have worse patient outcomes (empirical finding #3). In the short run, search is costly to patients since it may involve being subjected to
sub-optimal treatments, so it is possible that eliminating choices that have a low probability
of being optimal could make patients better off. Poly-pharmacy is a particularly interesting
example. Even if the best treatment for a patient involves using several drugs, having to
search over all possible drug combinations would increase search costs and the length of time
it takes to find the optimal treatment. Since there is little information from drug trials about
the efficacy of drug combinations, we focused on two-drug combinations and assumed that
their efficacy was given by a weighted sum of the efficacy of each drug, where the weight
given to each drug was 0.6. This choice of weights means that in our simulations, the optimal treatment is actually more likely to be a two-drug combination than a single drug. The
variance of each two-drug combination is assumed to be equal to the sum of the variances
of each drug times the square of 0.6, plus a small amount of idiosyncratic noise. The simulations were done with Julia and the diagrams with ggplot. The code and data that we are
allowed to share is available on dataverse (Currie-Macleod at Dataverse). Table (6) outlines
the steps, with references to the corresponding derivations for the two period problem. The
simulation is based on a multi-period, multi-drug extension of the two period model whose
theoretical properties are discussed in more detail in Currie and MacLeod (2020).
Figure (3) illustrates the evolution of dispersion in a doctor’s prescribing from time 0 to
36 months as a function of doctor characteristics and whether or not the doctor follows a
guideline. Dispersion tends to rise among doctors of all skill levels, though it is constrained
by following guidelines as one would expect. However, the effect of following guidelines is
much smaller for doctors with a high reservation probability, who place a high value on
experimentation. Doctors with a low reservation probability end up with significantly lower
dispersion if they follow guidelines.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

32

In Figure (4) we plot the doctor’s utility as a fraction of the maximum possible payoff.
Since in our model doctor utility depends only on patient outcomes, higher doctor utility is
synonymous with better patient outcomes. In this simulation, low skilled doctors have very
flat payoff functions, though they are slowly increasing over time. In contrast, high skilled
doctors have payoffs that rise rapidly over the first year of treatment, and then rise more
slowly over time. Having a higher reservation probability (i.e. being more experimental)
is associated with higher payoffs, especially among high skilled doctors. Perhaps the most
remarkable result from this section is that following guidelines is associated with better shortrun patient outcomes, even though guidelines constrain treatment choice. This is consistent
with our empirical finding #3, that violating guidelines is associated with worse outcomes.
The effect of guidelines is greatest for low skilled doctors with high reservation probabilities
and for high skilled doctors with low reservation probabilities. One interpretation is that
guidelines constrain low skilled doctors who are inclined to experiment on their patients;
Guidelines also make it less likely that a high skilled doctor who is inclined to stop searching
early will get stuck on a very suboptimal treatment.
Table 6. Simulation Steps
1.1. Read in parameters values for drug effects.
1.2. For runs R = 1,..., 100 do the following code:
2.1 Set new seed(R) = next prime number after seed(R-1).
2.2 For each of the six doctor types j in J do the following:
3.1. Seed random number generator with seed(R)
(each doctor sees exactly same set of 300 patients)
3.2. For each patient i in I draw an unobserved vector of
treatment effects (9) and then:
4.1. Initialize doctor beliefs (8)
4.2. Each month t = 1, ..., 36 do:
5.1. Draw an observation yijt using (10)
5.2. Update beliefs regarding treatment effect
of drugs (11-12)
5.3. Compute value for each treatment given
beliefs and reservation probability (14-15)
5.4. Compute optimal choice (2)
depending upon guideline case.
5.5. Save results.
3.3. For each month-doctor type compute mean patient utility and
prescription diversity for the 300 patients and save results.
1.3. Average patient utility and prescription diversity over
the runs by month-doctor type.
1.4 Plot the results.

The qualitative patterns we simulate for high skilled doctors match what we observe in
the group of patients who ever see psychiatrists. In patients seeing high skilled doctors,
higher entropy is associated with better patient outcomes (empirical finding #1), suggesting

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

33

that doctors with more dispersed prescribing patterns are better able to match drugs to
patients. However, as discussed above, in the patients who see only less-skilled doctors,
higher dispersion in prescribing is not empirically associated with better patient outcomes
(empirical finding #2). Our simulations suggest that it is difficult to generate this result in
our model in which all doctors have similar well-informed priors about drug efficacy and use
information efficiently. In real life, a doctor may prescribe badly either because of a lack of
diagnostic skill, or because of faulty priors.
Low Skill

Medium Skill

High Skill

Low Res Probs

0.4

0.2

0.0
0.6
High Res Probs

Physician Prescription Dispersion

0.6

0.4

0.2

0.0
0

10

20

30

0

10

20

30

0

10

20

30

Month
Does doctor violate practice guidelines against poly−pharmacy?

No

Yes

Figure 3. Simulation Results on the Effects of Doctor Skill and Reservation
Probabilities on Diffusion in Prescribing, With and Without Guidelines
Given prescribing data that followed a doctor over a relatively long time period, included
a patient identifier, allowed one to track patients who move between doctors, and had information about patient outcomes, one might be able to explore different models of physician
belief formation. This might be achieved by estimating a structural model that examines
the empirical relationship between doctors’ beliefs, reservation probabilities, and skill levels.
The reservation probability could be measured using the number of times a doctor changed
drugs within a patient, normalized by the length of time the patient was seen. Data on first
prescriptions (ideally to patients who had not been taking any drug for some period of time)
could be used to identify doctors with different priors. For example, a doctor who routinely
prescribed one drugs to new, medication-naive patients could be assumed to have different
priors than one who routinely prescribed a different drug. Empirically, all of the information
that can be obtained from the data about possible differences in priors can be summarized
by differences in actual drug choices conditional on the number of drugs prescribed, so one

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

34

could control for differences in priors by identifying them with doctor types based on these
choices.
Low Skill

Medium Skill

High Skill

80.0%
Low Res Probs

60.0%

20.0%
0.0%
80.0%
60.0%

High Res Probs

Patient Health

40.0%

40.0%
20.0%
0.0%
0

10

20

30

0

10

20

30

0

10

20

30

Month
Does doctor violate practice guideline against poly−pharmacy?

No

Yes

Figure 4. Simulation of the Effects of Doctor Skill and Reservation Probabilities on Utility, With and Without Guidelines
Given an indicator about priors, the reservation probabilities, and information about patient outcomes, and assuming that higher skilled doctors will have better outcomes on average
as well as outcomes that improve with the length of treatment, the model could allow us to
back out a distribution of diagnostic skill. It would then be possible to examine the empirical
relationship between skill and reservation probabilities, conditional on priors. Given rapidly
evolving access to claims data, and improvements in the quality of such data, it may be
possible to estimate a model along these lines in the near future.
6. Conclusions
Using unique data formed by combining information about how doctors prescribe antidepressants combined with individual claims data from a large health insurer, we characterize
doctor practice style by measuring dispersion in prescribing and whether the doctor violates
prescribing guidelines. In turn, differences in these measures of practice style are significantly
associated with patient outcomes including total costs, non-drug costs, and emergency room
visits, and hospitalizations.
The relationships between practice style and outcomes are quite different among patients
who ever saw psychiatrists, and the larger group of patients who were treated only by
non-specialists. Among patients seeing skilled doctors, seeing a doctor with more diffuse

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

35

prescribing is associated with a reduction in the probability of a subsequent ER visit or hospitalization with a mental health indication. In patients seeing unskilled doctors, switching
to a doctor with more diffuse prescribing is not associated with improvements in patient
outcomes.
We also look at the effects of transitions from one drug to another. Patients whose doctors
violate prescribing guidelines pertaining to these transitions have worse outcomes. Estimates
from models with patient fixed effects suggest that violations of U.S. guidelines are associated
with a 28.2% increase in total costs, a 13.0% increase in the probability of any ER visit or
hospitalization, and a 20.0% increase in the probability of an ER visit or hospitalization with
a mental health indication. These findings indicate that while some flexibility in treatment
options is likely optimal for skilled providers, guidelines are useful to rule out bad practice.
Having shown that practice style is strongly related to patient outcomes, we turn to
interpreting the estimates using a model of doctor decision making. We think of the sequence
of drug choices as a classic multi-armed bandit problem. Such problems involves a trade-off
between experimenting to learn more about what works best for a particular patient, and
systematically choosing the alternative with the highest expected payoff. In our model, the
trade-off between experimentation and choosing the drug with the highest expected value
depends on the physician’s diagnostic skill. If a physician is highly skilled in the sense of
being able to correctly assess a patient’s condition, i.e. has excellent diagnostic skill, then
the potential gains from experimentation are large.
One insight of the model is that there will not necessarily be a single correct treatment even
for identical patients since the best treatment will also depend on the doctor’s characteristics.
Other things being equal, a skilled diagnostician should be more experimental than a less
skilled diagnostician. Physicians who are more skilled will use a wider variety of drugs
for their patients, and physicians with better diagnostic skills stand to learn more from
experimentation and so will be more experimental. This insight is likely to be applicable in
other markets with expert decision makers. For example, other things being equal, a skilled
surgeon should perform more surgeries on marginal patients than a less skilled surgeon, and
a more skillful lawyer should take more cases to trial.
Since finding the optimal treatment entails experimentation, it is likely that some choices
will turn out to have been suboptimal ex post. Experimentation may make it more likely
that the physician finds the optimal treatment, but it may also make it more likely that
the physician violates prescribing guidelines. Using simulations based on data from clinical
drug trials and doctors with different assumed levels of skill, we show that in the short run,
guidelines that rule out some choices can improve patient welfare. Our empirical findings are
consistent with the model’s insight that experimentation is more beneficial when physicians

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

36

have more skill, and that restrictions on physician’s choice sets are associated with better
patient outcomes over the treatment intervals in our data.
Our results have number of potential implications for health policy. Much of the literature
about variations in observed practice style begins with the assumption that conditional on
price and patient characteristics there is a well defined optimal choice of treatment.11 From
this perspective, the goal of health policy is mainly to get the price “right” so that the optimal
choice will be made. Our results show that in the presence of match-specific treatment and
learning there cannot be a single “optimal” choice. Rather, the optimal practice style varies
with doctor skill and with the uncertain information that the doctor collects while treating
the patient. In short-run treatment settings, patients may be better off when guidelines take
some treatments off the table, even when those treatments are optimal for some patients. The
cost of searching over a wide set of treatments may outweigh the benefit of finding a somewhat
better treatment. Overall, our results suggest that optimal policy regarding guidelines does
not involve a stark choice between following rules or allowing unlimited doctor discretion
but should allow doctors to practice medicine within well defined boundaries.
References
Adli, M., K. Wiethoff, T. C. Baghai, R. Fisher, F. Seemüller, G. Laakmann, P. Brieger,
J. Cordes, J. Malevani, G. Laux, I. Hauth, H.-J. Möller, K.-T. Kronmüller, M. N. Smolka,
P. Schlattmann, M. Berger, R. Ricken, T. J. Stamm, A. Heinz, and M. Bauer (2017).
How effective is algorithm-guided treatment for depressed inpatients? results from the
randomized controlled multicenter german algorithm project 3 trial. International Journal
of Neuropsychopharmacology 20 (9), 721–730. 5
Aghion, P., P. Bolton, C. Harris, and B. Jullian (1991, June). Optimal learning by experimentation. Review of Economics Studies 58 (4), 621–654. 6
Baicker, K. and A. Chandra (2005). The effect of malpractice liability on the delivery of
health care. In D. M. Cutler and A. M. Garber (Eds.), Frontiers of Health Policy Research,
Volume 8. Berkeley, CA: The Berkeley Electronic Press. 5
Bergemann, D. and J. Välimäki (1996). Learning and strategic pricing. Econometrica,
1125–1149. 7
Berndt, E. R., R. S. Gibbons, A. Kolotilin, and A. L. Taub (2015). The heterogeneity of
concentrated prescribing behavior: Theory and evidence from antipsychotics. Journal of
Health Economics 40, 26 – 39. 2, 5, 8
Bloom, N., C. Propper, S. Seiler, and J. Van Reenen (2015). The impact of competition
on management quality: Evidence from public hospitals. The Review of Economic Studies 82 (2), 457–489. 6
For example Skinner (2012)’s nice review of the literature on regional variation is organized around the
factors that lead doctors to choose one treatment versus another.
11

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

37

Bubeck, S. and N. Cesa-Bianchi (2012). Regret analysis of stochastic and nonstochastic
multi-armed bandit problems. Foundations and Trends® in Machine Learning 5 (1), 1–
122. 3, 7
Chan, D. C. (2015, April 19). Tacit learning and influence behind practice variation: Evidence from physicians in training. mimeo. 5
Chan, David C, J., M. Gentzkow, and C. Yu (2019, November). Selection with variation
in diagnostic skill: Evidence from radiologists. Working Paper 26467, National Bureau of
Economic Research. 6
Chandra, A. and D. O. Staiger (2007). Productivity spillovers in health care: Evidence from
the treatment of heart attacks. Journal of Political Economy 115 (1), pp.103–140. 4
Cipriani, A., X. Zhou, C. Del Giovane, S. E. Hetrick, B. Qin, C. Whittington, D. Coghill,
Y. Zhang, P. Hazell, S. Leucht, P. Cuijpers, J. Pu, D. Cohen, A. V. Ravindran, Y. Liu,
K. D. Michael, L. Yang, L. Liu, and P. Xie (2016). Comparative efficacy and tolerability
of antidepressants for major depressive disorder in children and adolescents: a network
meta-analysis. The Lancet. June 8. 30
Cohen, J. D., S. M. McClure, and A. J. Yu (2007). Should i stay or should i go? how the
human brain manages the trade-off between exploitation and exploration. Philosophical
Transactions of the Royal Society B-Biological Sciences 362 (1481), 933–942. 7
Cosgrove, L., A. Shaughnessy, and T. Shaneyfelt (2018). When is a guideline not a guideline?
the devil is in the details. BMJ Evidence-based Medicine 23 (1), 33–36. cited By 2. 6
Crawford, G. S. and M. Shum (2005). Uncertainty and learning in pharmaceutical demand.
Econometrica 73 (4), 1137–1173. 5
Currie, J., W. B. MacLeod, and J. V. Parys (2016, May). Physician practice style and patient
health outcomes: The case of heart attacks. Journal of Health Economics 47, 64–80. 6
Currie, J. M. and W. B. MacLeod (2017, January). Diagnosis and unnecessary procedure
use: Evidence from c-section. Journal of Labor Economics 35 (1), 1–42. 6, 25
Currie, J. M. and W. B. MacLeod (2020, January). Learning, reservation probabilities and
boundedly rational choice in bandit problems. 21, 29, 31
Cutler, D., J. Skinner, A. D. Stern, and D. Wennberg (2019). Physician beliefs and patient
preferences: A new look at regional variation in health care spending. American Economic
Journal: Economic Policy 11 (1), 192–221. 4
DeGroot, M. H. (1972). Optimal Statistical Decisions. New York, NY: McGraw-Hill Book
C. 26
Detke, M. J., Y. Lu, D. J. Goldstein, J. R. Hayes, and M. A. Demitrack (2002). Duloxetine, 60
mg once daily, for major depressive disorder: a randomized double-blind placebo-controlled
trial. The Journal of Clinical Psychiatry 63 (4), 308–315. 44

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

38

Dickstein, M. J. (2015, April). Physician vs. patient incentives in prescription drug choice.
Stanford University. 5
Donohue, J. M., H. Guclu, W. F. Gellad, C.-C. H. Chang, H. A. Huskamp, N. K. Choudhry,
R. Zhang, W.-H. Lo-Ciganic, S. P. Junker, T. Anderson, and S. Richards-Shubik (2018,
OCT 1). Influence of peer networks on physician adoption of new drugs. PLOS
ONE 13 (10). 5
Dranove, D., S. Ramanarayanan, and A. Sfekas (2011). Does the market punish aggressive experts? Evidence from cesarean sections. B E Journal of Economic Analysis &
Policy 11 (2). 5
Epstein, A. J. and S. Nicholson (2009). The formation and evolution of physician treatment
styles: An application to cesarean sections. Journal of Health Economics 28, 1126–1140.
5
Erev, I. and A. E. Roth (2014). Maximization, learning, and economic behavior. Proceedings
of the National Academy of Sciences of the United States of America 111, 10818–10825. 7
Finkelstein, A., M. Gentzkow, and H. Williams (2015). Sources of geographic variation
in health care: Evidence from patient migration. The Quarterly Journal of Economics 131 (4), 1681–1726. 4
Frank, R. G. and T. G. McGuire (2000). Economics and mental health. In M. V. Pauly,
T. G. McGuire, and P. P. Barros (Eds.), Handbook of Health Economics, Volume 1, Part
B, Chapter 16, pp. 893 – 954. Elsevier. 2
Frank, R. G. and R. J. Zeckhauser (2007). Custom-made versus ready-to-wear treatments:
Behavioral propensities in physicians’ choices. Journal of Health Economics 26 (6), 1101
– 1127. 5, 6
Gelenberg, A. J., M. P. Freeman, J. C. Markowitz, J. F. Rosenbaum, M. E. Thase, M. H.
Trivedi, and R. S. V. Rhoads (2010). Practice Guideline for the Treatment of Patients
with Major Depressive Disorder (Third ed.). American Psychiatric Association. 10, 11
Gittins, J., K. Glazebrook, and R. Weber (2011, February). Multi-Armed Bandit Allocation
Indices (2nd ed.). John Wiley & Sons. 28
Gittins, J. C. (1979). Bandit processes and dynamic allocation indexes. Journal of the Royal
Statistical Society Series B-Methodological 41 (2), 148–177. 7, 28
Goldstein, D. J., C. Mallinckrodt, Y. Lu, and M. A. Demitrack (2002). Duloxetine in the
treatment of major depressive disorder: a double-blind clinical trial. The Journal of
Clinical Psychiatry 63 (3), 225–231. 44
Grove, W., D. H. Zald, B. S. Lebow, B. E. Snitz, and C. Nelson (2000). Clinical versus
mechanical prediction: A meta-analysis. Psychological Assessment 12, 19–30. 5
Hamilton, M. (1960). A rating scale for depression. Journal of Neurology, Neurosurgery and
Psychiatry 23 (1), 56. 29

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

39

Hieronymus, F., J. F. Emilsson, S. Nilsson, and E. Eriksson (2015, March). Consistent
superiority of selective serotonin reuptake inhibitors over placebo in reducing depressed
mood in patients with major depression. Molecular Psychiatry 21 (4), 523–530. 43, 44
Kahneman, D. and G. Klein (2009). Conditions for intuitive expertise: A failure to disagree.
American Psychologist 64 (6), 515–526. 5
Kantor, E. D., C. D. Rehm, J. S. Haas, A. T. Chan, and E. L. Giovannucci (2015, NOV
3). Trends in prescription drug use among adults in the United States from 1999-2012.
JAMA - Journal of the American Medical Association 314 (17), 1818–1831. 2
Kasper, S. (1995). Clinical efficacy of mirtazapine: a review of meta-analyses of pooled data.
International Clinical Psychopharmacology 10, 25–35. 43, 44
Kay, S. M. (1993). Fundamentations of Statistical Signal Processing. Saddle-Hill, NJ: Prentice Hall PTR. 29
Kendrick, D. A., H. M. Amman, and M. P. Tucci (2014). Chapter 1 - learning about learning
in dynamic economic models. In K. Schmedders and K. L. Judd (Eds.), Handbook of
Computational Economics Vol. 3, Volume 3 of Handbook of Computational Economics,
pp. 1 – 35. Elsevier. 3
Kennedy, S. H., R. W. Lam, R. S. McIntyre, S. V. Tourjman, V. Bhat, P. Blier, M. Hasnain,
F. Jollant, A. J. Levitt, G. M. MacQueen, S. J. McInerney, D. McIntosh, R. V. Milev, D. J.
Müller, S. V. Parikh, N. L. Pearson, A. V. Ravindran, R. Uher, and the CANMAT Depression Work Group (2016, August). Canadian network for mood and anxiety treatments
(canmat) 2016 clinical guidelines for the management of adults with major depressive disorder: Section 3. pharmacological treatments. Canadian Journal of Psychiatry. Revue
Canadienne de Psychiatrie 61 (9), 540–560. 11
Kirsch, I., B. J. Deacon, T. B. Huedo-Medina, A. Scoboria, T. J. Moore, and B. T. Johnson
(2008). Initial severity and antidepressant benefits: A meta-analysis of data submitted to
the food and drug administration. PLoS Medicine 5 (2), 45. 44
Lai, T. L. and H. Robbins (1985). Asymptotically efficient adaptive allocation rules. Advances
in applied mathematics 6 (1), 4–22. 3, 7
Linde, K., L. Kriston, G. Rücker, S. Jamil, I. Schumann, K. Meissner, K. Sigterman, and
A. Schneider (2015). Efficacy and acceptability of pharmacological treatments for depressive disorders in primary care: Systematic review and network meta-analysis. The Annals
of Family Medicine 13 (1), 69–79. 30
Llorca, P.-M., J.-M. Azorin, N. Despiegel, and P. Verpillat (2005). Efficacy of escitalopram
in patients with severe depression: a pooled analysis. International journal of clinical
practice 59 (3), 268–275. 43
Ludwig, J., D. E. Marcotte, and K. Norberg (2009). Anti-depressants and suicide. Journal
of Health Economics 28 (3), 659–676. 2

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

40

Maneeton, N., B. Maneeton, K. Eurviriyanukul, and M. Srisurapanont (2013). Efficacy,
tolerability, and acceptability of bupropion for major depressive disorder: a meta-analysis
of randomized–controlled trials comparison with venlafaxine. Drug Design, Development
and Therapy 7, 1053. 44
McCourt, C., J. Weaver, H. Statham, S. Beake, J. Gamble, and D. K. Creedy (2007). Elective
cesarean section and decision making: A critical review of the literature. Birth 34 (1), 65–
79. 4
Meehl, P. E. (1954). Clinical vs. Statistical Prediction: A Theoretical Analysis and a Review
of the Evidence. University of Minnesota Press. 5
Molitor, D. (2016, August). The evolution of physician practice styles: Evidence from
cardiologist migration. Working Paper 22478, National Bureau of Economic Research. 5
Raiffa, H. and R. Schlaifer (2000). Applied Statistical Decision Theory. Wiley. 27, 42
Reverdy, P. B., V. Srivastava, and N. E. Leonard (2014). Modeling human decision making
in generalized gaussian multiarmed bandits. Proceedings of the IEEE 102 (4), 544–571. 7
Robbins, H. (1952). Some aspects of the sequential design of experiments. Bulletin of the
American Mathematical Society 58 (5), 527–535. 3
Roth, A. E. (2018, July). Marketplaces, markets, and market design. American Economic
Review 108 (7), 1609–58. 2
Rothschild, M. (1974). A two-armed bandit theory of market pricing. Journal of Economic
Theory 9 (2), 185 – 202. 6
Schwartz, E. M., E. T. Bradlow, and P. S. Fader (2017). Customer acquisition via display
advertising using multi-armed bandit experiments. Marketing Science 36 (4), 500–522. 7
Shorrocks, A. F. (1980). The class of additively decomposable inequality measures. Econometrica 48 (3), 613–625. 9
Simon, H. A. (1955). A behavioral model of rational choice. Quarterly Journal of Economics 69, 99–118. 7, 21
Skinner, J. (2012). Causes and consequences of regional variations in health care. In M. V.
Pauly, T. G. McGuire, and P. P. Barros (Eds.), Handbook of Health Economics, Volume 2,
Chapter 2, pp. 45–49. Elsevier B. V. 36
Srinivas, N., A. Krause, S. M. Kakade, and M. W. Seeger (2012, May). Information-theoretic
regret bounds for gaussian process optimization in the bandit setting. IEEE Transactions
on Information Theory 58 (5), 3250–3265. 7
Srivastava, V., P. Reverdy, and N. E. Leonard (2015). Correlated multiarmed bandit problem:
Bayesian algorithms and regret analysis. arXiv preprint arXiv:1507.01160 . 7
Stern, S. and M. Trajtenberg (1998, December). Empirical implications of physician authority in pharmaceutical decisionmaking. Working Paper 6851, National Bureau of Economic
Research. 5

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

41

Sutton, R. S. and A. G. Barto (2018). Reinforcement Learning, 2nd Edition. MIT Press. 3,
7
Theil, H. (1967). Information Theory and Economics. North-Holland. 9
Thompson, W. R. (1933). On the likelihood that one unknown probability exceeds another
in view of the evidence of two samples. Biometrika 25 (3/4), 285–294. 3
Tsai, T. C., A. K. Jha, A. A. Gawande, R. S. Huckman, N. Bloom, and R. Sadun (2015, 08).
Hospital board and management practices are strongly related to hospital performance on
clinical quality metrics. Health affairs 34 (8), 1304–1311N. 6
Van Moffaert, M., J. De Wilde, A. Vereecken, M. Dierick, J. Evrard, J. Wilmotte, and
J. Mendlewicz (1995). Mirtazapine is more effective than trazodone: a double-blind controlled study in hospitalized patients with major depression. International Clinical Psychopharmacology. 43
Wu, C. M., E. Schulz, M. Speekenbrink, J. D. Nelson, and B. Meder (2018). Generalization
guides human exploration in vast decision spaces. Nature Human Behaviour 2 (12), 915–
924. 7
Zeier, Z., L. L. Carpenter, N. H. Kalin, C. I. Rodriguez, W. M. McDonald, A. S. Widge,
and C. B. Nemeroff (2018). Clinical implementation of pharmacogenetic decision support
tools for antidepressant drug prescribing. American Journal of Psychiatry 175 (9), 873–
886. PMID: 29690793. 6

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

42

Appendix A. On Line Appendix
Proof of Proposition(2).
Proposition. A Bayesian rational doctor chooses drug A over drug B in period 1 if and
only if:
(18)

µj1A + ζj Vj1A ≥ µj1B + ζj Vj1B ,

an equality that is satisfied to the first order if and only if:
(19)

µj1A + τj σ̂j2A ≥ µj1B + τj σ̂j2B ,

where

ζj
ζj
L (0) ' 0.4
.
1 − ζi
1 − ζi

τj =

Proof. The first inequality follows immediately from the definition of the payoffs. For the
second inequality take a Taylor series expansion of V (x) around x = 0.
−∞

Z

tf (t) dt + (1 − F (x)) x.

V (x) =
x

V 0 (x) = xf (x) − f (x) x + (1 − F (x)) ,
= (1 − F (x)) .
Hence:

x
V (x) ' L (0) + .
2

Thus we have:


µj1B − µj1A
U (d1 =
' µj1A + ζj σ̂j2A L (0) +
2σ̂j2A
µj1B − µj1A
= µj1A + ζj σ̂j2A L (0) + ζj
.
2
We have a similar expression for drug B:
µj1A − µj1B
U (d1 = B, d∗2B ) = µj1B + ζj σ̂j2B L (0) + ζj
2
Re-arranging the mean terms we get that to the first order U (d1 = A, d∗2A ) ≥ U (d1 = B, d∗2B )
if and only if:
ζj
ζj
µj1A +
L (0) σ̂j2A ≥ µj1B +
L (0) σ̂j2B ,
(1 − ζj )
(1 − ζj )
from which we get (19). The numerical approximation to L (0) ' 0.4 is to be found in the
appendix to Raiffa and Schlaifer (2000).

A, d∗2A )





A.1. Drug Effects and Dropouts: How Data for Table 5 is Constructed. This
document will go drug-by-drug and show how the data used to model doctor tastes in the

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

43

simulations were constructed. All cited papers are listed in the bibliography at the end.
Each drug is listed by its pharmaceutical name, with its primary trade name included in
parentheses. All effect means and standard deviations use the Hamilton-17 (HAMD-17)
scale as their metric of improvement. Market shares were computed by the authors using
the 2014 IQVIA data.

(1) Sertraline (Zoloft): All effect data were drawn from Hieronymus et al. (2015)
table 2, which includes multiple sertraline studies. First, the average was taken over
all sertraline studies to get average means and standard deviations of the HDRS-17
score both at baseline and endpoint. Mean effects were computed as the difference
between average baseline score and average endpoint score. To compute standard
deviations, we take advantage of the assumption that baseline scores and drug effects
are independent. Under this assumption,
2
2
2
σendpoint
= σbaseline
+ σef
f ect

Solving for σef f ect , we have:
σef f ect =

q

2
2
σendpoint
− σbaseline

(2) Citalopram HBR (Celexa): All effect data were drawn from Hieronymus et al.
(2015) table 2, which includes multiple citalopram studies. Means and standard
deviations were computed using an identical procedure as used for sertraline.
(3) Fluoxetine HCL (Prozac): All effect data were drawn from Hieronymus et al.
(2015) table 2, which includes multiple fluoxetine studies. Means and standard deviations were computed using an identical procedure as used for sertraline.
(4) Escitalopram Oxal (Lexapro): All effect data were drawn from Llorca et al.
(2005), table 3. The mean effect was taken to be the difference in Hamilton-17 score
between baseline and LOCF (Last Observation Carried Forward). Like for sertraline,
we take advantage of the assumed independence between the baseline score and effect,
and compute the standard deviation of the effect as:
q
2
2
− σbaseline
σef f ect = σLOCF
(5) Trazodone HCL (Oleptro): The mean effect was drawn from Kasper (1995) table
3, line 3 (Belgium). The effect is expressed as the mean change in HAMD-17 score
for a single study. No data was found on the standard deviation of the effect for
trazodone. However, Van Moffaert et al. (1995) claim that the standard deviation
of mirtazapine’s effect is about 20% lower than that for trazodone. Thus, we let
traz
mirt
mirt
σef
f ect = σef f ect , where σef f ect is defined below.

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

44

(6) Duloxetine HCL (Cymbalta): The mean effect was drawn fom Detke et al. (2002),
table 2. The effect is expressed as the mean change in HAMD-17 for a single study.
The standard deviation of the effect was drawn from page 227 of Goldstein et al.
(2002) which doesn’t provide the standard deviation derived from their data but
rather an “assumed” standard deviation of 7. We can hope that this standard deviation was informed by their data, but are not sure of this.
(7) Wellbutrin XL: No papers were found measuring the direct effect and standard
deviation for bupropion. However, Maneeton et al. (2013)claims that these would be
approximately the same as those for venlafaxine. For this reason, the effect and standard deviation of the effect of bupropion was made identical to that for venlafaxine
(see below).
(8) Amitriptyline HCL (Elavil): All effect data was drawn from Kasper (1995) page
30 (within the text). These data came from a single study of both amitriptyline
and mirtazapine. You will notice they provide data for both “mean change from
baseline” and “reductions at the endpoint”. The data pulled are those corresponding
to reductions at the endpoint.
(9) Venlafaxine (Effexor): All effect data was drawn from table 1 of Kirsch et al.
(2008), which includes several different of venlafaxine. In order to obtain a single
figure for the mean and standard deviation of change, the average was taken over
the relevant studies presented in the table. Note that the d denotes the standard
deviation.
(10) Mirtazapine (Remeron): All effect data was drawn from Kasper (1995), page 27
(within the text). These data came from an analysis of pooled data of mirtazapine
trials.
(11) Paroxetine (Paxil): All effect data were drawn from Hieronymus et al. (2015) table
2, which includes multiple paroxetine studies. Means and standard deviations were
computed using the same procedure as for sertraline. Note that these paroxetine
studies include a variety of different dosages.
(12) Placebo: Most of the studies we have come across provide data on the effect of
placebos on patients with major depressive disorder. We have defined our “placebo”
effects and standard deviations by taking the average over the data provided in
Hieronymus et al., which provides data on 18 different placebo-controlled trials. To
compute the mean and standard deviation of the effect, we employ the same procedure
used for sertraline, for example (please see above).

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

Table 7. Market shares of all antidepressant prescriptions, 2006 and 2014
(Branded products in italics under the equivalent generic product)

Note: Authors’ calculations from the IQVIA data. Different drug
classes correspond to different hypothesized methods of action. Only
the most commonly prescribed drugs in each class are listed. In most
cases there is a generic and a branded drug. E.g. Zoloft is the brand
name and the equivalent generic is Sertraline. We give the molecule
the generic name. The table shows that 11 drugs account for most of
the market though 33 drugs were sold. “Wellbutrin” includes the
branded drugs Wellbutrin, Budeprion, Forfivo, and Aplenzin; “Paxil”
includes both Paxil and Pexeva.
A.2. Market Shares of Drugs.

45

UNDERSTANDING DOCTOR DECISION MAKING: THE CASE OF DEPRESSION TREATMENT

Princeton University and NBER
E-mail address: jcurrie@princeton.edu
Columbia University and NBER
E-mail address: bentley.macleod@columbia.edu

46

