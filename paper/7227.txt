NBER WORKING PAPER SERIES

THE IMPACT OF U.S. NEWS &
WORLD REPORT COLLEGE RANKINGS
ON ADMISSIONS OUTCOMES AND
PRICING POLICIES AT
SELECTIVE PRIVATE INSTITUTIONS
James Monks
Ronald G. Ehrenberg
Working Paper 7227
http://www.nber.org/papers/w7227

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
July 1999

The Cornell Higher Education Research Institute is supported by the Andrew W. Mellon foundation and other
donors. All opinions expressed are those of the authors and not those of the National Bureau of Economic
Research, the Consortium on Financing Higher Education, Cornell University, or the Andrew W. Mellon
Foundation.
© 1999 by James Monks and Ronald G. Ehrenberg. All rights reserved. Short sections of text, not to exceed

two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given
to the source.

The Impact of U.S News & World Report College
Rankings On Admission Outcomes and Pricing
Decisions at Selective Private Institutions
James Monks and Ronald G. Ehrenberg
NBER Working Paper No. 7227
July 1999
JEL No. I2
ABSTRACT
Despite the widespread popularity of the U.S. News & World Report College rankings there has
been no empirical analysis of the impact of these rankings on applications, admissions, and enrollment
decisions, as well as on institutions’ pricing policies. Our analyses indicate that a less favorable rank leads
an institution to accept a greater percentage of its applicants, a smaller percentage of its admitted applicants
matriculate, and the resulting entering class is of lower quality, as measured by its average SAT scores.
While tuition levels are not responsive to less favorable rankings, institutions offer less visible price discounts
in the form of slightly lower levels of expected self-help (loans and employment opportunities) and
significantly more generous levels of grant aid. These decreases in net tuition are an attempt to attract
additional students from their declining applicant pool.

James Monks
Consortium on Financing Higher Education
238 Main Street (Suite 307)
Cambridge, MA 02142
Jmonks@mit.edu

Ronald G. Ehrenberg
Cornell Higher Education Research Institute
256 Ives Hall
Ithaca, NY 14853-3901
and NBER
Rge2@cornell.edu

I. Introduction
Each fall the U.S. News & World Report (henceforth USNWR) publishes an issue that
ranks the colleges and universities throughout the country. Many higher education
administrators abhor this form of detailed numerical ordering of the institutions. Stanford
University has gone so far as to have the data underlying their ranking audited by outside
consultants, and the Association of American Universities is investigating the possibility of
constructing its own ranking scheme in response to the popularity of the USNWR ranking
(imitation being the highest form of flattery). At the same time, many institutions use their
standing in the rankings as a selling point in their admissions brochures. Ehrenberg
(forthcoming, chapter 4) outlines actions taken by Cornell University to improve its relative
position in the rankings, that had no effect on the institution’s underlying academic quality. He
also illustrates how minor changes in the methodology used by USNWR can result in substantial
changes in the rank ordering of the top-ranked national universities.
The widespread popularity of the rankings among students and families, as evidenced by
the sales of the USNWR issue that contains the rankings and of their expanded special college
ranking supplementary publication, as well as the increasing angst and attention that these
rankings cause higher education administrators, warrant an analysis of the impact of these
rankings on the higher education admissions processes. Machung (1998) chronicles the efforts
sometimes taken by institutions to ensure or improve their position in the rankings. She also
points out that a recent study by the Art and Science Group, a market research firm, found that
two-thirds of parents of high-achieving, college-bound seniors felt the USNWR rankings to be
“very helpful” in evaluating a college’s quality. Hansmann (1998) also provides anecdotal

evidence that Yale’s achieving the top position in the USNWR ranking of law schools resulted in
a precipitous increase in the yield at the Yale Law School, the following year.
Despite these convincing examples and casual observations concerning the influence of the
USNWR rankings of colleges and programs, there has been no thorough empirical investigation
into the impact of these rankings on potential students’ or academic institutions’ behavior. Our
paper fills this void by examining the effects of changes in USNWR rankings on the admissions
outcomes and pricing policies of a set of institutions that are at the very top of the undergraduate
rankings. In particular, we investigate the impact of changes in highly ranked national
universities’ and liberal arts colleges’ USNWR rankings on the fraction of their applicants that
they admit (their admit rates), the fraction of their accepted applicants that enroll (their yield
rates) and the average SAT scores of their resulting freshman classes. We also examine the
impact of changes in these institutions’ rankings on the tuition levels they charge, the self-help
levels they include in their financial aid packages, their aid-adjusted tuition levels (the average
price actually paid by students on need-based financial aid), and their net tuition levels (the
average price actually paid by all students).

II. Data
We focus on the set of national universities and liberal arts colleges that are ranked at the
top of the rankings because these institutions and their rankings receive a disproportionate share
of public attention. 1 The institutions in our sample include 16 of the top 25 national universities,
1

Our set of institutions is drawn from the Consortium on Financing Higher Education and
includes: Amherst, Barnard, Brown, Bryn Mawr, Carleton, Columbia, Cornell, Dartmouth,
Duke, Georgetown, Harvard, Johns Hopkins, MIT, Mount Holyoke, Northwestern, Oberlin,
Pomona, Princeton, Smith, Stanford, Swarthmore, Trinity (CT), University of Chicago,
University of Pennsylvania, University of Rochester, Washington University, Wellesley,
Wesleyan, Williams, and Yale.
2

one university ranked between 26th and 50th and 13 of the top 25 national liberal arts colleges in
the USNWR 1998 rankings. We restrict our attention to these institutions because we were able
to obtain detailed information for them on the typical expected self-help and the financial aidadjusted tuition levels for incoming freshmen. The availability of freshmen aid-adjusted prices
permits us to more fully capture the impact of annual changes in the institutions’ rankings on
their pricing decisions than we could have done if we were forced to rely only on posted tuition
levels.
The institutions in our sample are all members in the Consortium on Financing Higher
Education (COFHE), which was established in 1974, before the beginning of the USNWR
rankings in 1983. 2 Because all of the institutions in our sample are privately controlled, no
inferences about the impact of changes in rank on admissions outcomes and pricing policies in
public higher education institutions should be drawn from the results that follow.
We limit our sample years to the admissions outcomes and pricing policies for the
entering classes of the 1988/89 to 1998/99 academic years, and to the prior year’s fall USNWR
rankings (the fall of 1987 to the fall of 1997). The first year of our sample is the first year that
USNWR reported rankings for at least the top 25 liberal arts colleges and the top 25 national
universities. Prior to 1987, USNWR reported only the top 10 or so ranked institutions in each
category. The fall 1997 ranking is the final ranking used because it is hypothesized to influence
the admissions’ outcomes and pricing behavior for the 1998/99 academic year, the last year for
which we had admissions and pricing information, at the time we wrote the paper. The resulting
sample consists of 30 institutions across 11 years, for a panel of 330 observations. For some

2

Oberlin is the exception. Oberlin joined COFHE in 1988. All other institutions in our sample
joined COFHE before USNWR began ranking colleges and universities
3

institution-years, the level of self-help or net tuition was not reported and those observations
were dropped from the statistical analyses that used these variables.
USNWR determines an institution’s rank among national universities and liberal arts
colleges by taking a weighted average of the institution’s scores on 7 broad categories of
academic input and outcome measures. In its 1997 rankings, the categories and their weights
were academic reputation (25 percent), retention rate (20 percent), faculty resources (20 percent),
student selectivity (15 percent), financial resources (10 percent), alumni giving (5 percent), and
graduation rate performance (5 percent). These 7 categories were further divided and 16
different variables were used to capture their dimensions. These 16 variables were: academic
reputation, as measured by a survey of college presidents; the fraction of freshman applicants
that were admitted (the admit rate): the fraction of accepted applicants that enrolled (the yield
rate); the percentage of incoming freshman in the top 10 percent of their high school class; the
average SAT or ACT scores or entering freshmen; average faculty compensation; the percentage
of faculty with a Ph.D. or the highest degree possible in the field; the percentage of faculty who
were full-time; the student/faculty ratio; the percentage of classes with 1 to 19 students; the
percentage of classes with 50 or more students; the 6 year graduation rate; the freshman
retention rate; average education expenditures per student; the alumni giving rate; and the
institution’s graduation rate performance relative to its predicted graduation rate measure.
Periodically, USNWR alters the methodology it uses to determine the rankings. So
changes in an institution’s rank do not necessarily indicate true changes in the underlying
“quality” of the institution. In fact, some institutions have changed their positions in the ordering
by as much as 18 places in a single year. For example, Bryn Mawr dropped from 5th position in
1989, to 23rd position in 1990. The hypotheses we are testing here is thus whether a change in an

4

institution’s USNWR ranking, which is not necessarily equal to a change in the “true” academic
quality of the institution, influences its admissions outcomes and its pricing behavior.
III. Empirical Results
Our methodological approach is to statistically relate the admissions outcomes and
pricing variables described above for an institution in an academic year to its lagged (previous
year’s) USNWR ranking. Some institutions in our sample did not receive a specific numerical
rank in some years because USNWR only reported the numerical ranks of the top 25 institutions
in each category from 1987 to 1994. After 1994 they listed the top 50 national universities and
top 40 national liberal arts colleges. For those institution-years for which an institution dropped
out of the top 25 and its numerical rank was not reported, we assigned the institution a rank of
25. We also included in the model a dichotomous variable that was set equal to one for these
institution-years and zero otherwise. It is straightforward to show that the coefficient on this
variable indicates whether an institution that fell below a rank of 25 in those years experienced
admissions or pricing outcomes that were significantly different from those of the 25th ranked
institution.
We include average endowment per student at an institution among the explanatory
variables in order to control for differences across institutions and over time in the ability to fund
operations from revenue sources other than tuition. Institutional dichotomous variables are also
included to capture time-invariant institution specific reputation and policy effects. Finally, year
dichotomous variables are included to control for changes in the potential applicant pool and
pricing environment that are consistent across this set of institutions.
Table 1 presents the results of our analyses of the impact of USNWR rank on admissions
outcomes. In the first column, the admit rate (the number of students admitted/the number of

5

applicants) is specified to be linearly related to the institution’s lagged USNWR rank, the
dichotomous variable for the institution’s lagged rank being greater than 25 and not specifically
reported, average endowment per student, and institution and year effects. An increase in rank of
one (an increase in rank reflects a less favorable position in the ordering; for example, moving
from being ranked 2nd to 3rd) is associated with a positive and statistically significant increase in
the institution’s admit rate of 0.399. In other words, a change in rank, from say 4th to 5th ,
coincides with an increase in an institution’s admit rate of almost one half of a percentage point.
An institution whose rank is increasing must admit a greater percentage of its shrinking applicant
pool in order to fill its incoming class, thus becoming less selective in its admissions.
Conversely, an institution whose rank improves (becomes lower) can accept a smaller percentage
of its applicants and increase its selectivity.
As column 2 indicates, an increase in rank not only decreases the selectivity of an
institution, but lowers its yield (number of matriculants/number of admitted students), as well. A
less favorable rank results in a smaller percentage of an institution’s admitted applicants
accepting positions in the entering class. This provides an additional reason why institutions that
are losing ground in the rankings must admit a larger percentage of their applicants, while
institutions that improving in the rankings can accept a smaller percentage of their applicants.
While the impact on yield is statistically significant, the magnitude of the effect of a change in
rank on yield is rather small. It takes an improvement in rank of 6 places to increase an
institution’s yield by 1 percentage point. 3
An increase in average endowment per student also increases an institution’s yield. In
particular, a $10,000 increase in endowment per student increases an institution’s yield by 0.56
3

We also estimated models in which the admit rate and yield rate were specified as log-odds
ratios. The results were very similar and are not presented here.
6

percentage points. As will be discussed in the following section, an increase in endowment leads
to pricing policies that lower the financial aid adjusted cost of attendance, thus increasing yield.
The net effect of an increase in rank on admit rates and yields is a decline in the average
SAT score of the institution’s incoming freshmen class. 4 The largest reductions in SAT scores
are felt at the top of the rankings, with the impact declining further down the ordering of
institutions. Thus the increased selectivity and yield that accompany an improvement in rank
leads to a modest increase in the quality of the institution’s incoming freshmen class, as
measured by its average SAT scores. 5
Table 2 presents our estimates of the impact of changes in an institution’s USNWR rank
on its pricing policies and on the tuition revenue it actually nets per student. All outcome
variables in this table are specified in logarithmic form, so that the estimated coefficients for
each explanatory variable represent the approximate percentage changes in the outcome
associated with a one-unit change in the explanatory variable.
The first column presents estimates of the impact of rank and endowment per student on
tuition. An increase in rank has no statistically significant impact on tuition. Similarly, an
increase in endowment has no significant impact on tuition. “Sticker prices” appear not to be
influenced by changes in the overall rank and wealth of an institution, conditional on institution
and year-specific effects. This may be because gross tuition levels act, in part, as a signal of
academic quality (Breneman (1994), p. 32), so that an institution does not want to reveal its
declining position by lowering its published price.

4

The pre-1996/97 average composite SAT scores have been recentered to correct for the
“recentering” of SAT scores that took place in that year.
5
We experimented with including the square of rank in each of the regressions reported in
tables 1 and 2. However, it proved to be statistically significant and improved the fit of the model
only for the SAT score equation.
7

As column 2 indicates, however, an increase in rank is associated with a decrease in the
typical expected freshmen self-help contribution from students. Institutions that experience a
declining position (increasing rank) in the USNWR ordering appear to lower their self-help levels
in an attempt to attract additional students, although this result is only significantly different
from zero at the 10 percent level.
Consistent with the impact of rank on self-help, an increase in rank significantly lowers
average financial-aid-adjusted tuition. An increase in rank (less favorable ranking) of 10 places
leads to a reduction in aid adjusted tuition of approximately 4 percent. Because an increase in
rank was shown in column 1 not to significantly reduce tuition levels, this reduction in aidadjusted tuition implies that a less favorable ranking prompts institutions to provide more
generous financial aid. 6 Likewise, an improvement in rank raises aid-adjusted tuition, as higher
ranked institutions do not have to offer deep discounts to attract matriculants.
An increase in endowment per student also is associated with lower aid-adjusted tuition.
This implies that institutions pass on at least some of their increases in wealth to their students in
the form of more generous financial aid packages. A $100,000 increase in endowment per
student reduces aid-adjusted tuition by approximately 4 percent.
Finally, an increase in rank leads to a decrease in net tuition (average aid-adjusted tuition
across all students, both aided and non-aided). The decrease in net tuition is smaller than the
decrease in aid-adjusted tuition. This result is consistent with the statistically insignificant effect
of rank on tuition and the significant decrease in aid-adjusted tuition found in columns 1 and 3,
respectively.
6

Aid-adjusted tuition is defined as tuition minus average grant aid per student, for those students
on aid. It does not include self-help and merit aid. Although merit aid is becoming increasingly
popular, it still constituted only 2.5 percent of all grant aid awarded in 1998/99 at the COFHE

8

Conclusion
Our analyses suggest that an increase in a selective private institution’s USNWR rank (a
less favorable ranking) leads the institution to accept a greater percentage of its applicants (an
increase its admit rate), that a smaller percentage of its admitted pool of applicants matriculates
(a decrease in its yield), and that its resulting entering class is of lower quality, as measured by
average SAT scores. In addition, we find that institutions’ tuition levels are not responsive to
less favorable rankings. This may be because lower tuition relative to one’s competitors may be
perceived of as an additional signal of lower quality. As a result, institutions that have declined
in the ratings offer less visible price discounts in the form of lower levels of expected self-help
and more generous levels of grant aid, in an attempt to attract additional students from their
declining applicant pool.
Cornell University, the home institution of one of us, provides a case study and test of the
predictive power of our results. Cornell jumped in rank from 14th in the fall of 1997 (the last
year used in our study) to 6th in the fall of 1998. Our estimates imply that this 8 place
improvement in rank should have led to approximately a 3 percentage point reduction in the
institution’s admit rate, a one percentage point increase in its yield, and approximately an 8 point
increase in its entering freshmen’s average SAT scores. While data on these outcomes for the
freshmen class entering in the fall of 1999 have not yet been publicly released by Cornell, a
senior administrator confirmed for us that the reduction in the university’s admit rate and the
increases in its yield and average freshmen SAT scores were at least as large as our predictions.
Moreover, completed freshman applications to the university rose by over 10 percentage points.

institutions, and was granted to less than 2 percent of the total COFHE enrollment. Its exclusion
from the aid-adjusted tuition levels should not significantly influence the results.
9

A change in rank does have a significant influence on admissions outcomes and
institutional pricing decisions for liberal arts colleges and national universities that are at the very
top of the USNWR ranking lists. These in turn, through the methodology that USNWR uses, will
have an impact on the institutions’ future rank. 7 The growing popularity and influence of these
rankings may also lead the institutions to try to influence them. Institutions may attempt to
improve their position in the rankings by lobbying USNWR to change the methodology in a way
that might favor an institution or group of institutions, by “correcting” their data in a way that
leads to an improvement in their ranking, or by devoting resources to activities related to
improving their rank that do not directly enhance educational quality. An example of the latter
might be to increase the size of their development offices in order to increase their alumni giving
rates, even if the marginal return to the university in terms of dollars raised from doing so
doesn’t exceed the cost of the additional staff.
The factor that receives the largest weight in the USNWR rankings is the survey of higher
education administrators. Hence an improvement (or decline) in an institution’s rank may lead to
future movements in its rank in the same direction because administrators are increasingly aware
of how other institutions fare in the rankings. The heightened awareness, and perhaps even
animosity, among higher education administrators concerning their institutions’ relative positions
in the USNWR rankings appears to be warranted, as changes in rank have a significant influence
on the applications and enrollment decisions of students and the pricing behavior of the
institutions.
7

This mechanical relationship may lead to an endogeneity problem in our analyses, if current
rank is correlated with future rank, which in turn is determined in part by current admission
outcomes. Our inability to specify adequate exogenous variables for an institution’s rank prevent
us from conducting formal statistical tests of whether rank should be treated as endogenous in
our models. However, our use of lagged rank and of institutions specific effects is intended to
minimize this problem.
10

References

Breneman, David W. (1994). Liberal Arts Colleges: Thriving, Surviving, or Endangered?
Brookings Institution, Washington, D.C.
Ehrenberg, Ronald G. (forthcoming). Adam Smith Goes to College…..and learns why they can’t
hold down their costs”.. Harvard University Press, Cambridge, MA
Hansmann, Henry (1998). “Higher Education as an Associative Good.” Yale Law School
mimeo.
Machung, Anne. (1998). “Playing the Rankings Game.” Change. July/August 1998, pp. 12-16.
U.S. News and World Report, various issues 1983 to 1998.
</ref_section>

11

Table 1 US News and World Report Rankings and Admissions Outcomes
Academic Years 1988/89-1998/99
Dependent Variable
Admit
Rate

Yield

Average SAT

Constant

19.543***
(4.121)

44.083***
(1.988)

1402.628***
(11.848)

Lagged US News Rank

0.399***
(0.098)

-0.171***
(0.047)

-2.777***
(0.773)

Lagged US News Rank Squared

-------

-------

0.086***
(0.025)

Dummy of Lagged Rank > 25

0.473
(1.527)

1.073
(0.737)

-3.009
(4.357)

Average Endowment/student
(thousands 98/99 $)

-0.013
(0.015)

0.056***
(0.007)

0.045
(0.041)

Institutional Dummy Variables

Yes

Yes

Yes

Year Dummy Variables

Yes

Yes

Yes

Adjusted R-square

0.93

0.97

0.96

30
330

30
330

30
330

Number of Institutions
Number of Institution-Years

Notes:
(* ,**, ***) statistically significantly different from zero at 10% (5%, 1%) level.
Average endowment is 3 year moving average of lagged endowment levels.

12

Table 2 US News and World Report Ranking and Pricing
Academic Years 1988/89-1998/99
Dependent Variable (in log form)

Tuition

SelfHelp

Aid Adjusted
Tuition

Net Tuition

Constant

10.102***
(0.012)

8.577***
(0.080)

9.461***
(0.069)

9.915***
(0.036)

Lagged US News Rank:

-0.0001
(0.0003)

-0.004*
(0.002)

-0.004**
(0.002)

-0.003***
(0.001)

Dummy of Lagged Rank > 25

0.0020
(0.0044)

-0.031
(0.028)

-0.013
(0.026)

-0.022*
(0.013)

Average Endowment/student
(thousands 98/99 $)

-0.00001
(0.00004)

0.0000
(0.0003)

-0.0004*
(0.0002)

-0.0001
(0.0001)

Institutional Dummy Variables

Yes

Yes

Yes

Yes

Year Dummy Variables

Yes

Yes

Yes

Yes

Adjusted R-square

0.98

0.78

0.61

0.85

Number of Institutions
Number of Institution-Years

30
330

30
325

30
330

30
326

Notes:
(*,**, ***) statistically significantly different from zero at 10% (5%, 1%) level.
Average endowment is 3 year moving average of lagged endowment levels.

13

