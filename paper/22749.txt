NBER WORKING PAPER SERIES

THE COMPETITIVE EFFECTS OF ONLINE EDUCATION
David J. Deming
Michael Lovenheim
Richard W. Patterson
Working Paper 22749
http://www.nber.org/papers/w22749

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
October 2016

The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2016 by David J. Deming, Michael Lovenheim, and Richard W. Patterson. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

The Competitive Effects of Online Education
David J. Deming, Michael Lovenheim, and Richard W. Patterson
NBER Working Paper No. 22749
October 2016
JEL No. I22,I23
ABSTRACT
We study the impact of online degree programs on the market for U.S. higher education. Online
degree programs increase the competitiveness of local education markets by providing additional
options in areas that previously only had a small number of brick-and-mortar schools. We show
that local postsecondary institutions in less competitive markets experienced relative enrollment
declines following a regulatory change in 2006 that increased the market entry and enrollment of
online institutions. Impacts on enrollment were concentrated among private non-selective
institutions, which are likely to be the closest competitors to online degree programs. We also
find increases in per-student instructional spending among public institutions. Our results suggest
that by increasing competitive pressure on local schools, online education can be an important
driver of innovation and productivity in U.S. higher education.
David J. Deming
Harvard Graduate School of Education
Gutman 411
Appian Way
Cambridge, MA 02138
and NBER
david_deming@gse.harvard.edu
Michael Lovenheim
Department of Policy Analysis and Management
Cornell University
102 Martha Van Rensselaer Hall
Ithaca, NY 14853
and NBER
mfl55@cornell.edu

Richard W. Patterson
B117 Lincoln Hall
United States Military Academy
West Point, NY
richard.patterson@usma.edu

Online education is an increasingly important component of the U.S. higher education
landscape. In 2014, one in three college students in degree-granting U.S. institutions took at least
one course online (Allen and Seaman, 2015). Millions of students from all over the world also
have enrolled in Massive Open Online Courses (MOOCs) offered in partnership with major
research universities such as Harvard, MIT and Stanford (Ho et al. 2014, McPherson and Bacow
2015, Waldrop 2014). By 2012, more than 6 percent of all U.S. bachelor’s degrees were awarded
online (Deming et al. 2016). The rapid rise of online course offerings and degrees has led to
predictions that competition from MOOCs and other online course offerings will lead to
“disruptive innovation” in higher education (e.g. Christensen and Eyring 2011, Cowen and
Tabarrok 2014). While there is a growing body of research examining student outcomes among
those enrolling in online degree programs or courses (Deming et al. 2016, Bettinger et al. 2014),
no prior work has estimated the impact of this change in higher education markets on brick and
mortar schools.
The exuberance over MOOCs and other high-profile online offerings obscures the fact that
most of the growth in online higher education has been among the least selective institutions,
especially for-profit colleges (Deming, Goldin and Katz 2012). In 2013, selective institutions
accounted for only about 2 percent of enrollment in fully online programs, compared to 33
percent for the for-profit sector (Deming et al. 2015).1 Online for-profits spend very little per
student, and are viewed less favorably by employers than non-selective brick and mortar schools
of all types (Deming et al. 2016).
For public institutions, the allure of online education lies in its potential to cut costs in a time
of declining state support and tightening budgets (Bowen et al. 2014). Yet cost savings from
larger classes and less student-faculty contact may cause instructional quality to suffer, and high
quality online courses are – at least at the time of writing – equally or even more expensive to
develop and staff than in-person courses (McPherson and Bacow 2015).2

1

We define selective institutions as those that received a rating of Most Competitive, Highly Competitive or Very
Competitive according to the 2009 Barron’s Profile of American Colleges.
2
Several recent studies conducted in a wide variety of institutions find that online course-taking reduces student
learning and lowers persistence through college (Figlio, Rush and Yin 2013, Xu and Jaggars 2013, Hart, Friedman
and Hill 2014, Streich 2014, Bettinger et al. 2016). Bowen et al. (2014) compare student performance in a fully
online statistics course to a hybrid version across six different public research universities and find no difference in
learning.

1

In this paper, we ask whether online degree programs can improve educational productivity
by exerting competitive pressure on traditional brick-and-mortar institutions. How might
competition from online providers affect the market for higher education? In a well-functioning
marketplace, the new availability of a cost-saving technology should increase efficiency, because
colleges compete with each other to provide the highest quality education at the lowest price.
The market for selective colleges is increasingly geographically integrated, and these colleges
compete fiercely on the quality margin (Hoxby 1997, Hoxby 2009, Clotfelter 1999). In contrast,
the vast majority of students in non-selective colleges attend school close to their home and in
their home state. In 2013, 39.3 percent of students at selective colleges were from out-of-state,
compared to just 13.8 percent of students in less selective four-year schools and only 5.6 percent
in community colleges.
In principle, local education markets can still be competitive. However, there are a few
reasons to suspect that many are not. First, public colleges and universities are heavily subsidized
by state and local governments and face political pressure to keep tuition low. Prices at public
institutions are often set below marginal cost, which drives out private competitors who are not
receiving such subsidies. Second, for political and historical reasons, public institutions are often
located in communities that are not populous enough to support private competitors.
As a result of the uneven geographic dispersion of postsecondary schools and the high
probability that students enrolling in nonselective schools attend close to home, non-selective
public institutions in less dense areas either are local monopoly providers of education or have
considerable market power. Online education has the potential to disrupt these local monopolies
by introducing competition from alternative providers that do not require students to leave home
to attend. The impact of competition from online providers will depend on the degree of
monopoly power held by incumbents, as well as on the extent to which students are willing to
substitute between online and in-person programs.
We analyze the impact of increases in prevalence and market share of online institutions on
student outcomes and institutional behavior at traditional brick-and-mortar schools. Studying the
impact of competitive pressure from online institutions on local education markets is inherently
difficult, for two reasons. First, competitive pressure is challenging to measure directly,
especially since there is sparse data on online degree programs offered by traditional brick and
mortar schools. Second, it is difficult to isolate the impact of competition from online institutions
2

from other changes affecting the market for higher education, because online degree programs by
their nature are available everywhere at the same time.
We address these challenges by exploiting a 2006 change in the Federal regulation of online
education called the 50 percent rule. As we discuss later, this regulatory change allowed
institutions to specialize in the provision of online degrees and dramatically lowered barriers to
entry into online education. Deming et al. (2015) show that the median price of an online degree
dropped by 34 percent between 2006 and 2013, suggesting that online degree providers were
competing with each other for students. While the regulatory change was national, we argue that
it should affect local education markets differently depending on their level of competitiveness
prior to 2006.
We measure competitiveness using the Herfindahl index, a standard measure of market
concentration. High values of the Herfindahl index indicate that postsecondary enrollment is
concentrated in a small number of institutions that are likely to enjoy monopoly power. We
compare changes before and after 2006 in enrollment, prices and other outcomes in markets with
more or less market concentration, using a generalized differences-in-differences framework. We
define education “markets” as the Metropolitan Statistical Areas (MSA) or county if a county is
not in an MSA. Finally, we calculate a Herfindahl index as of the year 2000, which predates the
spread of online education.
Our results generally align with theoretical predictions of how schools should react to
increased competition. We find that the impact of online competition on enrollment, prices and
educational resources is greater in markets where enrollment was more highly concentrated prior
to 2006. A one standard deviation increase in the Herfindahl index is associated with a post-2006
enrollment decline of about 2 percent and an increase in per-student instructional expenditures of
about 1.8 percent. The impacts on enrollment are largest among not-for-profit and for-profit
private institutions.
We also find that online competition shifts resources towards instructional expenditures.
Overall, a 1 standard deviation increase in the Herfindahl index post-2006 increases per-student
instructional expenditures by 1.8%. This effect is largest in the public sector and among 4-year
schools. In the private and two-year sectors, there is no increase in per-student instructional
spending, but these institutions do experience a decline in revenues per student. These declines
likely are driven by enrollment decreases from increased online competition. Thus, two-year and
3

private colleges experience a relative shift towards instructional expenditures, which are held
constant in the face of declining overall resources.
We examine the effect of online competition on tuition prices as well. Our tuition analysis is
restricted to private schools because public school tuition is heavily subsidized and is unlikely to
reflect market forces. Somewhat contrary to expectations, we find that online competition
increases average tuition, particularly in the private four-year sector and that it is associated with
increased tuition dispersion, especially in the private two-year sector. One possible explanation is
that tuition increases are a response to revenue losses associated with enrollment reductions from
online competition. Additionally, most online institutions are for-profits that charge high prices
and serve students who are heavily subsidized by Federal Title IV financial aid. If students do
not face the full cost of their education when making enrollment decisions, quality competition
may be more salient than price competition.
A second approach we take to identifying the competitive effects of online education
programs is to use the differential spread of Internet availability across states (Goolsbee,
Lovenheim and Slemrod 2010). Since online enrollment requires access to the Internet,
competitive pressures from online schools should be larger in areas with more Internet access. A
drawback of this approach is that we only have comprehensive Internet penetration data at the
state level, which necessitates defining education markets in a more aggregated manner.3 Thus,
this is not our preferred approach but provides supporting evidence of our market concentration
results using a very different source of variation.
Similar to the market concentration analysis, we employ a difference-in-difference estimator
that examines how postsecondary outcomes change as a function of Internet penetration rates
after 2006 when online schools became more prevalent. Thus, we estimate whether there was a
change in the relationship between state Internet access and brick-and-mortar postsecondary
outcomes in 2006. Our findings are broadly consistent with those from the market power
analysis: Internet penetration growth post-2006 is associated with decreased log enrollment and
higher per-student instructional expenditures.

3

Dettling, Goodman and Smith (2016) examine the effect of high speed Internet on college application behavior
using FCC data on the number of county-level broadband Internet service providers. These data are only available
through 2008 but allow sub-state variation. We have analyzed our models using these data, but with only 2 years of
post-2006 observations the estimates are imprecise. Furthermore, we show below that most of our results are driven
by the 2009-2013 period, which is missed by these data.

4

Overall, our results suggest that there may be important general equilibrium effects of online
degree programs on the market for higher education. Hoxby (1997) studies how declining
transportation costs and increased sharing of information and standardized testing led to
geographic integration of the market for higher education over the last several decades. As she
shows, those changes were most consequential for elite colleges, who increasingly compete in a
national market for students. This paper fits into the broader literature on the industrial
organization of higher education by studying the impact of a technological change – online
education – on less-selective, mostly open access postsecondary institutions. Like Hoxby (1997),
our results suggest that the geographic integration of higher education markets may lead to
efficiency gains as institutions compete with each other for students. To our knowledge, this is
the first analysis to show such effects of competition for schools that do not practice selective
admissions.

I. A Brief History of Online Education in the U.S.
Long before the Internet, distance education took the form of correspondence courses that
delivered lessons by mail, radio and television. U.S. colleges and universities such as University
of Maryland University College (UMUC) and the University of Wisconsin-Extension have been
offering correspondence courses in some form for nearly a hundred years.
Fully online degrees were developed in the mid-1990s, when dial-up Internet started to
become available for commercial use. Early examples of such programs include CALcampus
and Western Governors University. The first postsecondary institution to open an online campus
was the University of Phoenix, which enrolled more than 1,200 students in the 1994-1995
academic year, according to data from the U.S. Department of Education Integrated
Postsecondary Education Data System (IPEDS).
The for-profit sector moved relatively slowly into online education. By 2000, only a handful
of for-profits had online degree programs at all. One reason was technological – in 2000 only 37
percent of Americans had Internet connections at home, and only 3 percent had high-speed
broadband access (Pew Charitable Trusts 2016). By 2005, more than 60 percent of Americans
had Internet access, and broadband access grew eleven-fold to 33 percent.
Regulatory restrictions also played an important role in the growth of online degree
programs. The Higher Education Act (HEA) of 1992 required that schools distributing Federal
5

Title IV aid have no more than 50 percent of total student course time spent in distance education
(the 50 percent rule). The rule was interpreted broadly to include mail-in correspondence courses
as well as online degree programs.
The 50 percent rule did not prevent schools from offering online degrees, but it did limit
market entry by effectively requiring all institutions to enroll one student in-person for every
student enrolled online. Specialized online schools could not exist under the 50 percent rule. The
1998 HEA created the Distance Education Demonstration Program (DEDP), a pilot program that
allowed waivers of the 50 percent rule for selected institutions. Notable participants included
University of Phoenix, Capella University, and Western Governors University. Online
enrollment grew rapidly among DEDP participants between 1998 and 2005, and in February of
2006 the Higher Education Reconciliation Act (HERA) eliminated the 50 percent rule.
These regulatory changes had a large impact on enrollments in online programs. IPEDS only
began tracking online enrollment directly in 2013, but the data are collected at the campus
branch level. This makes it possible to measure enrollment at individual branches of “chain”
institutions with multiple campuses, such as the University of Phoenix. We estimate online
enrollment using the method outlined in Deming, Goldin and Katz (2012), which classifies a
school campus as online if it has the word “online” in its name or if no more than 33 percent of
the school’s students are from one U.S. state. This is a conservative measure of online enrollment
because many schools offer online degree programs through their in-person branches (see
Deming, Goldin and Katz (2012) for more details). Figure 1 plots estimated yearly enrollment in
online degree programs using this method and shows the significant rise in these types of
programs in the early-mid 2000s.
Figure 1 further divides online enrollment into two categories: 1) campuses with a significant
but not complete online presence; and 2) campuses or entire institutions which are online only.4
Between 2000 and 2006, online institutions grew from essentially zero to about 1.75 percent of

4

The first category includes central branches of “chain” for profit institutions where online students from across the
country are likely to be assigned. For example, in 2009 DeVry University operated 26 campus branches across the
U.S. The Illinois branch had an enrollment of 24,624, which was more than 3 times larger than the next largest
branch and about 40 percent of total enrollment in DeVry. While some of these students were enrolled in the inperson Illinois branch, most were enrolled online. In contrast, University of Phoenix has a separate online campus
that enrolled more than 300,000 students – about 77 percent of total University of Phoenix enrollment - in 2009.
Other schools, such as Ashford University and Capella University, have only a single campus branch at which
nearly everyone is enrolled online.

6

all U.S. postsecondary enrollments. This growth was modestly larger for specialized online
campuses.
In the four years following the end of the 50 percent rule, online schools grew from 1.75 to
4.5 percent of all U.S. enrollment. Online-only campuses and institutions accounted for about 2.1
percentage points of this increase, or about 75 percent of the growth in online enrollment over
the 2006-2010 period. Moreover, the number of institutions satisfying our definition of “online”
grew from 13 in 2004 to 24 in 2006 to 39 in 2010. These trends suggest that the market for
online education grew rapidly and became significantly more competitive after 2006.

II. How Might Online Degrees Affect Higher Education Markets?
Online institutions affect local education markets by increasing competitive pressure.
Students who previously had only a limited set of choices (or perhaps no choice at all) now can
choose to enroll in online institutions instead. This increase in the number of options available to
students means that local colleges and universities no longer have monopoly power and must
compete for students. Thus, the impact of online institutions should be proportional both to the
amount of prior market power of local institutions and to the substitutability between local
nonselective schools and online degree programs.
We focus on the impact of increased competitive pressure from online schools on enrollment
and resource allocation among traditional postsecondary institutions. While no prior work has
examined this question, it relates closely to existing research on the competitive effects of K-12
school choice. A sizable body of research examines how school choice policies affect resource
levels and distribution in traditional public schools (Hoxby 2000; Hoxby 2003; Jackson 2012;
Cook 2016). While these papers find that elementary and secondary schools respond to
competitive pressures by changing educational inputs, the direction and magnitude of effects
tends to vary.
Competition in the postsecondary market has many similarities to competition in the
elementary and secondary markets, although it is distinguished along three important
dimensions. First, postsecondary schools charge tuition. Thus, unlike with K-12 school choice,
there is a price mechanism that can act to clear the market. Of course, most colleges and
universities receive substantial state subsidies, and financial aid weakens the relationship
between posted tuition and what students actually pay, but the fact that postsecondary schools,
7

and in particular private schools, can compete over prices differentiates this setting from choice
in K-12 markets.
Second, institutions of higher education have broader purposes than K-12 schools. An
elementary or secondary school’s main objective is to increase student learning in a small set of
academic subjects. Colleges and universities also aim to increase student learning, but over a
wider variety of subjects. Moreover, they aim to produce knowledge in the form of research.
Higher education markets therefore are more horizontally differentiated than their K-12
counterparts. Colleges with different objectives and different student bodies are unlikely to
compete with each other. This is a key reason why we focus on nonselective schools, which offer
a relatively homogenous product in a standard fee-for-service model (Hoxby 2014).
Third, non-attendance is usually not an option in the K-12 setting. In contrast, since people
are not required to attend college, market entry of online degree programs might increase total
postsecondary enrollment. This could happen through a direct effect of increasing access to
college but also indirectly: if competition raises the quality of education offerings, more students
might be pulled into higher education.
This market design gives rise to several predictions, which we test empirically below. Our
first prediction is that the impact of competition from online degree programs on enrollment will
be greater in markets where enrollment is more concentrated in a small number of institutions.
This is because in the absence of outside competitors, local institutions with monopoly power
will generally be providing a lower quality education for the price.
Our second prediction is that online degree programs should increase price competition and
reduce economic rents for schools with monopoly power. Given that prices at public institutions
are only weakly market driven at best, we might expect price competition to be most important
for private institutions. If institutions compete primarily over price, then the introduction of a
common (online) option should lead to a decline in the variance of tuition prices across local
education markets. Again, this effect should be larger for private institutions.
Finally, we might also expect competitive pressure to lead to changes in institutional resource
allocation, such as increased spending on instruction and/or student support services. The
predicted effects for tuition and resources are linked: schools can compete on both prices and
quality, but they might not do so equally. If competition is mainly over quality, the level and
variance of tuition prices actually could increase. This might occur in an environment where
8

tuition is subsidized by financial aid, making the actual prices faced by prospective students less
salient. Thus, how postsecondary schools will respond to heightened competition is determined
in part by the factors over which they compete.

III. Data
III.A. Main Analysis Data
Our main source of institutional data for this study is IPEDS, which contains institution-level
information on enrollment, posted tuition prices, revenues, expenditures and educational
resources for all U.S. postsecondary institutions that distribute Federal Title IV financial aid (Pell
grants and Stafford loans). We collected IPEDS data at the institution-year level for years 19902013.5 Our analysis is mostly restricted to years 2000-2013, which provides several years in
which online degree programs prevalence was low and also insulates us from biases related to
many changes in how IPEDS measures core variables of interest in the 1990s. Using 2000 as our
base year allows us to obtain market concentrations that are not affected by online degree
programs, but that are recent enough to accurately reflect market power in later years.
It is important to distinguish selective from nonselective institutions in our context because
selective schools are much more geographically integrated, which means they have considerably
less market power (Hoxby 2009, 2014). In 2000, 44.3 percent of first-time freshmen in selective
four-year institutions were from out-of-state, compared to only 15.2 percent in less selective
four-year publics and 7.5 percent in community colleges. Additionally, most online programs are
open enrollment – very few practice selective admissions.6 As a result, schools that have
selective admissions policies are unlikely to be in direct competition with online degree
programs. We therefore focus on less- and non-selective institutions that serve highly local
markets, which we define as any institution that has a rating of Most Competitive, Highly
Competitive or Very Competitive according to the 2009 Barron’s Profile of American Colleges.
The main variables of interest in this study are enrollment, in-state tuition charges, perstudent revenues, expenditures per student and instructional expenditures per student. The
IPEDS revenue and expenditure data contain outliers that are likely to reflect measurement error

5

We refer to school years by the calendar year of the spring term. For example, we refer to school year 2012-2013
as 2013.
6
In our data, only one online-only institution reports practicing selective admissions – Grand Canyon University.

9

and that can cause undue influence on mean estimates. We therefore winsorize these variables by
cutting the top and bottom 1% of revenues, expenditures and instructional expenditures per
student.7Table 1 shows means and standard deviations of the outcome variables we employ in
this study, both overall and by institution type. The means generally conform to expectations,
with four-year and private institutions having higher per-student revenues and expenditures than
their public and two-year counterparts. Furthermore, public institutions are much larger and
charge lower tuition than private colleges and universities. Because we focus on nonselective
institutions, our sample is comprised of 8,782 schools, about 1/3 of which are public and a little
over half of which are four-year.

III.B. Measuring Market Concentration
There is little reason to expect that the distribution of public institutions across metropolitan
areas reflects a competitive equilibrium. While private colleges may enter markets endogenously
in response to potential profit opportunities, the location of public institutions largely reflects
historical and political factors. There has been almost no new entry of public colleges or
universities in the U.S. over the last 25 years. Many public institutions are located in non-urban
areas that would not otherwise support a market for higher education – for example, in 2013, 18
percent of non-selective public enrollment was in non-urban areas, compared to only 8 percent
for private non-selective institutions.
The uneven distribution of colleges and universities across areas in the US drives
heterogeneity in the competitive effects of online postsecondary programs. To measure local
market power, we first define a postsecondary market as the MSA in which a school is located. If
a school is not located in an MSA, we define the market as the county. This definition thus
acknowledges that students have more options in cities and can easily move across counties
within the city to enroll. In less urban areas, the local schooling option is typically the
community college or the non-selective four-year school located in one’s county.
Our measure of market concentration is the Herfindahl index of enrollment shares. The
Herfindahl index is a measure of the extent to which enrollment is spread out evenly among
many postsecondary schools or whether it is concentrated in one or only a couple schools. It is

7

Winsorizing the data in this way has little impact on the log estimates but does affect the level estimates as
expected. Results using the full sample are available from the authors upon request.

10

preferable to raw counts of the number of different types of schools because it takes into account
the size of enrollment at each local school; a small school affects local competition less than a
larger school. Formally, the Herfindahl index is the sum of squared enrollment shares across
schools within a market:
=∑
where

,

is the enrollment share in institution i in market j and Nj is the total number of

postsecondary institutions in market j;

∈ [0,1], with values closer to 1 indicating less

competition (more concentrated enrollment).
We calculate Herfindahl indices using 2000 enrollment data for all non-selective schools in a
market as well as separately by level (two-year, four-year) and control (public, private). Thus, Hj
is a fixed characteristic of the market that does not change over time. Table 1 provides means of
Herfindahl indices and other analysis variables of interest. The mean Herfindahl index value is
about 0.31. However, the standard deviation is also about 0.31, suggesting that there is
significant variation in college concentration across markets. 8 Private schools on average have
less market power, with a mean Herfindahl index of 0.29. Table 1 also shows that for a small
number of local markets, sector-specific Herfindahl indices cannot be calculated because there is
no school of that type in the market in 2000.
Table 1 includes tabulations separately for public and private institutions as well as for twoyear and four-year schools. Public institutions and community colleges tend to be located in
markets in which there is more market power.9 Across school types, there is in general much less
competition from public institutions than from private institutions. This probably reflects
endogenous decisions by private institutions to enter markets based on the supply of potential
students. We examine below whether there are heterogeneous effects of online competition
across the different types of sector-specific market concentration.

8

The US Department of Justice considers a market to be highly concentrated when the Herfindahl index is higher
than 0.26, which illustrates the high level of market power in the nonselective higher education market. Appendix
Figure 1 contains Herfindahl index distributions and highlights the large amount of variation across areas in the
amount of market concentration: many areas have a Herfindahl index below 0.1, while a substantial number have an
index above 0.25.
9
Appendix Figure 1 shows the distribution of the nonselective Herfindahl index for public and private institutions.
While the modes of the distributions are similar, there is a much larger mass of public institutions with considerable
market power.

11

Figures 2 and 3 show the geographic distribution of nonselective market shares by MSA and
by county, respectively. In the cases where the counties in Figure 3 overlap with an MSA in
Figure 2, the MSA is the relevant market. The different shading in each Figure 2 corresponds to
quartiles of the Herfindahl index. For counties, over 40% have a Herfindahl index of 1. We
therefore split counties into terciles of the distribution with an index value less than 1 and then a
category with only single-school counties. As expected, there is much higher market
concentration when markets are defined as counties rather than MSAs. The main conclusion
from these figures is that there is considerable variation in local market power across space and
that there is little geographic clustering of market power. Thus, our market power measures are
not simply picking up unobserved aspects of higher education markets that are correlated with
geographic region or state.
Figures 2 and 3 also demonstrate that many areas of the country are characterized by a high
degree of nonselective market power. Among MSAs, the top quartile has a Herfindahl index
above 0.68 and among counties it is 0.94. In contrast, the bottom quartile of the distribution has
little market power, especially among MSAs. Thus, there is much geographic variation in the
scope for online postsecondary options to have competitive effects on local higher education
markets.

III.C. Measuring Internet Penetration Rates
Internet penetration rates are calculated at the state-year level using the Current Population
Survey (CPS). Beginning in 1989, the CPS has included questions in various forms about
Internet access and usage. These questions were asking in 1989, 1993, 1997, 1998, 2000, 2001,
2003, 2007, 2009, 2010 and 2012. We follow the approach developed in Goolsbee, Lovenheim
and Slemrod (2010) to construct a state-year panel of Internet access rates that accounts for the
fact that the wording of the question changes over time. In 1989 and 1993, a respondent is
defined as having Internet access if he reports that he has e-mail or a computer with a modem. In
the 1997-2003 surveys we code a respondent as having Internet access if she responds that she
has access to the Internet at home, school or work. Post-2003, the CPS directly asks if
respondents have Internet access. Between survey years, state-level Internet penetration rates are
linearly interpolated.

12

Figure 4 contains trends in Internet penetration rates between 1989 and 2012 for the highestand lowest-Internet penetration state in each year. The maximum and minimum state changes
over time, so the figure also shows which state provides each observation. Internet access is
generally trending upward strongly over this period, but it is doing so unevenly across states.
Thus, there is significant cross-state variation in the time pattern of Internet access. Below, we
explore whether this time pattern is related to postsecondary outcomes among nonselective
institutions in a state, and in particular whether changes in Internet penetration rates have
differential impacts after 2006 when the supply of online enrollment options increased.

IV. Empirical Strategy
We first examine how postsecondary outcomes change after 2006 as a function of 2000
market concentrations in a difference-in-difference setting. In particular, we estimate the
following regressions at the institution-year level:
=

(1)

+

(

where indexes institutions, s indexes state,
year.

)+

∗

+

+

+

indexes market (county or MSA) and indexes

is the nonselective market Herfindahl index in 2000. We control for time-varying

characteristics of institutions and markets (such as the local unemployment rate), institution fixed
effects ( ) and state-by-year fixed effects (

). Note that the main effect of

is absorbed by

the institution fixed effects, since institutions do not move across markets. Standard errors are
clustered at the market level throughout.
The coefficient of interest in this equation is

, which shows how the relationship between

market power (as measured by the Herfindahl index) and postsecondary outcomes changes in
2006 when online programs became more prevalent. Similar to any difference-in-difference
design, this approach embeds two main assumptions: 1) schools in markets with different levels
of market power would have exhibited similar trends absent the rise of online programs and 2)
there are no shocks or policies that occur after 2006 that differentially affect markets with
different values of

.

We provide evidence on the validity of the first assumption by estimating event studies of the
following form:
(2)

=

+ ∑

∗ ( = )+
13

+

+

+

.

This model estimates a separate coefficient on Hm in every year, and the coefficients

−

provide evidence on whether there are differential pre-2006 trends as a function of 2000
market share. Note that our model does not necessarily predict a sharp break in 2006, since
online schools were growing in prevalence prior to 2006. However, the 2006 regulatory change
sped up the rate of entry of online programs. We therefore expect a shift in how 2000 market
shares relate to postsecondary outcomes after 2006, although the exact timing is unclear.
Furthermore, they are likely to be some “pre-treatment” trends that reflect the rise of online
programs prior to 2006.
The second assumption is much more difficult to test. We control for market-year level
observable characteristics to account for any compositional changes across areas that may be
correlated with 2000 market shares. Because we cannot perfectly test the assumptions underlying
our preferred approach, we implement a second empirical strategy that uses differences in
Internet penetration rate changes across states. While this approach relies on assumptions about
the exogeneity of Internet penetration rate changes, these assumptions differ substantially from
those needed to justify our preferred approach. To the extent that the estimates from both
methods are similar, this alternate approach provides support for our results.
We estimate difference-in-difference models that examine how the relationship between
Internet penetration rates in state I and year t (Ist) changes in 2006:
(3)

=

+

(

∗

)+

+

+

+

+

.

Note that Ist varies over time within state. The identifying variation in this model thus comes both
from changes in the relationship between Internet penetration rates and postsecondary outcomes
in 2006 and from changes in Internet penetration rates with states. The main assumption
underlying this model is that the only reason the relationship between Ist and outcomes changes
in 2006 is because of the growth of online education. We also need to assume that there are no
shocks or other policies that occur in 2006 which are correlated with Ist. Because Ist and Hm are
not highly correlated – the correlation coefficient between the Herfindahl index and the growth
in Internet penetration between 2000 and 2012 is -0.05 – it is highly unlikely that any
unobserved shock that would bias the first approach would also bias the second approach in the
same direction.
V. Results

14

V.A. Enrollment
Table 2 shows estimates from equation (1) of the impact of post-2006 online competition on
enrollment. Panel A present results in levels, and Panel B shows the natural log of enrollment.
Because of the large variance in enrollment, we prefer the log estimates. However, we present
both for completeness. Column 1 presents pooled results for all non-selective colleges. Columns
2 and 3 present results for public and private enrollment (including both not-for-profit and forprofit institutions), while Columns 4 and 5 split by four-year and two-year colleges respectively.
We find consistent evidence across specifications that less competitive markets experienced
relative declines in enrollment after the expansion of online degree programs. A one standard
deviation increase in market concentration (0.31, as measured by the H-index) leads to a decline
in post-2006 enrollment of about 2 percent. We find larger impacts for private institutions; a one
standard deviation increase in market concentration reduces post-2006 enrollment by 2.5 percent.
Public schools in Panel A show evidence of a sizable and statistically significant decline in
enrollment, but the results in Panel B indicate these results are not robust to measuring
enrollment in logs. This is likely because of the existence of some very large public schools,
which have an undue influence on the estimates in Panel A. We thus conclude that enrollment in
public schools does not respond to competitive pressures overall. The last two columns show that
effects are similar in percentage terms for 4-year and 2-year schools; a one standard deviation
increase in the Herfindahl index leads to an enrollment reduction of about 2% after 2006.
Figure 5 presents estimates of equation (2) graphically, following the less restrictive
specification in equation (2). Note that we have excluded 2005 in these results, which essentially
normalizes all estimates to be relative to this pre-treatment year. All event study estimates that
follow use this convention. When we allow the impacts of market concentration to vary by year,
we find a borderline significant decline of about 4 percent in log enrollment for private
institutions in 2007, exactly one year after the end of the 50/50 rule. The coefficients remain
negative in nearly every year from 2007 to 2013. In contrast, we find no statistically significant
impact on log enrollment at public institutions for any year after 2006, which is consistent with
the evidence in Panel B of Table 2.

V.B. Tuition

15

In Section II, we predicted that competition from online degree programs would cause price
convergence across local education markets. Figure 6 presents some initial evidence on this
question by plotting the enrollment-weighted coefficient of variation (the standard deviation
divided by the mean) for tuition in public and private non-selective schools between 1990 and
2013. Figure 6 shows that variation in tuition at private non-selective institutions held steady
throughout the 1990s, but started to decline in the early 2000s. In contrast, there is little change
in the variance of tuition at public institutions over this period.
While time series evidence is suggestive, in Table 3 we present estimates of equation (1) with
tuition as the outcome to more closely link any tuition changes with underlying market shares.
Because public tuition is not primarily determined by market competition, we focus on private
institutions. Column 1 presents results for all private schools, while Columns 2 and 3 focus on
private four-year and two-year institutions, respectively.
Surprisingly, we find little evidence that competition from online institutions lowers tuition
in more concentrated markets. The coefficients in Column 1 are positive but are not statistically
significant at even the 10% level. They suggest a small positive effect on average tuition of about
0.5 percent for a one standard deviation increase in the H-Index. There is a negative but not
significant effect for private 2-year schools in column (3) that is very small in absolute value,
while the results in Column 2 actually imply increases in private four-year tuition in more
concentrated markets. Figure 7 shows event study estimates for nonselective private schools.
These results show that private tuition increases as a function of 2000 market share after 2006,
with all of the increases coming after 2009. Furthermore, there is little evidence of pre-2006
differential trends in tuition that would lead to a bias in our estimates.
What could explain the positive effect on private sector tuition? One explanation is that the
enrollment declines in Table 2 force private colleges to charge more to cover their fixed costs. In
other words, private schools might be forced to raise tuition in order to make up for the loss in
resources associated with declining enrollment. Another explanation is that price competition is
not particularly strong in higher education markets where enrollment is heavily subsidized by
Federal Pell grant and Stafford loan dollars, and thus price is not very salient to consumers. This
suggests that schools will compete over other features, such as resources. While these
explanations are not mutually exclusive, we lack the ability to distinguish them in the data.

16

Panel C shows the impact of online competition on market-level variation in tuition prices.
The dependent variable is the absolute difference between the institution’s posted tuition and the
national average tuition divided by the national average tuition. Thus, the estimates yield the
effect of increased competition on the coefficient of variation (the standard deviation divided by
the mean). Interestingly, the estimates indicate an increase in price dispersion post-2006 as a
function of 2000 market share. These estimates are driven by private 2-year schools, where a 1
standard deviation increase in the H-index leads to a 1.4 percentage point increase in the
coefficient of variation. Again, this evidence suggests schools likely are not competing over
posted prices, which is sensible given the sizable subsidies offered to students through the
financial aid system .10 Indeed, if prices are difficult for students to observe, higher competition
could cause an increase in posted prices that are driven by university expansions in educational
resources.

IV.C. Spending

Table 4 presents estimates of equation (1) where the outcomes are expenditures (Panel A),
instructional expenditures (Panel B) and revenues (Panel C) per student. Given the enrollment
declines shown in Table 2, there can be a mechanical positive effect on per-student expenditures
if expenditures react slowly to enrollment changes or if expenditures are nonlinear in enrollment.
However, we view it as unlikely that all of the resource changes we document are due to
enrollment effects.
As in Table 2, we show results for all non-selective schools as well as separately for public
and private institutions and for 2-year and four-year institutions. Because there is a lot of
variation in expenditures, these estimates are necessarily noisier than those discussed above. But,
we find evidence that expenditures per student increase more after 2006 in more concentrated
markets. The impacts are largest for instructional expenditures - a 1 standard deviation increase
in market share leads to an increase in instructional expenditures per student of about 1.8
percent. As shown in Table 1, there is significant variance associated with these outcomes, so we
favor the log model; we focus on these although we present both for interested readers.

10

It is possible these schools are competing over net price with institutional aid. However, nonselective schools in
general and 2-year schools in particular tend to offer little institutional aid.

17

The impact on instructional expenditures is largest for 4-year schools (3.1 percent for a 1
standard deviation increase in the H-index) and for public schools (1.9 percent for a 1 standard
deviation increase in the H-index). We find no statistically significant impact of market
concentration on instructional spending in 2-year schools or private schools.
Figure 8 shows event studies for instructional expenditures per student. The estimates are
imprecise, but there is some evidence of an increase in per-student instructional spending after
2006, most of which occurs after 2009. However, the pre-trend for this outcome actually begins
around 2004. One possible explanation is that schools increased instructional spending in
anticipation of increased competition from online schools.
The results for overall spending per student are consistent with those for instructional
spending but are less precise. The one exception is that we see a reduction in overall spending
due to increased competition among all nonselective schools, which is driven by the private
sector. Panel C shows that the expenditure declines in the private sector we document are driven
in large part by changes in per-student revenues. Both private and 2-year schools experience
significant declines in revenues due to heightened competitive pressures.
Private schools are heavily reliant on tuition funding. Table 2 shows these institutions
experience sizable declines in enrollment when there is increased competition. We also find – in
Table 3 – that they increase tuition in response to online competition. However, Table 4 shows
that these tuition increases do not fully offset the impact of declining enrollment on per-student
revenues.
Comparing the revenue changes to the expenditure changes, one possible explanation is that
while private and two-year schools are shifting resources toward instruction, they nonetheless
face increasingly-binding financial constraints that reduce the total amount of resources available
to them. The result is that these institutions are able to hold instructional expenditures per student
relatively constant in the face of declining total resources. Despite the fact that revenues decline,
there is a relative shift to instructional expenditures in the private and two-year sectors.
In contrast, there is no impact on per-student revenue in public schools and four-year schools.
This could be because state appropriations counteract reductions in tuition revenue from
enrollment declines in the four-year sector (we do not see a consistent enrollment effect in the
public sector). It also is the case that four-year schools tend to be less reliant on tuition revenues,
which reduces their exposure to revenue losses when enrollment declines. Instructional
18

expenditures per student rise considerably, which suggests that public schools may respond to
threat from online competitors by increasing the breadth of course offerings, lowering class
sizes, or increasing instructional expenses. Unfortunately, the IPEDS data do not allow us to
examine more specific categories of instructional spending.

IV.D. Heterogeneity in Market Power Across Sectors

Throughout the analysis, we have characterized competition using nonselective enrollment
concentrations. This aggregation may miss important heterogeneity in market power across
sectors. As Table 1 shows, private schools tend to have less market power than public schools. If
schools in these sectors compete within but not across sectors, our aggregation of all enrollments
will miss important aspects of how competition operates. In Table 5, we present results from a
model similar to equation (1) but where we control separately for the private H-index and the
public H-index interacted with a post-2006 indicator. We also separately control for the
interaction of post-2006 and indicators for whether the market is missing each H-index. This
occurs when the market does not have a school of the given type in it in 2000.
Panel A shows log enrollment estimates; the results load completely on the private sector Hindex. The enrollment effect on all nonselective schools is similar to the effect in Table 2, at 1.8
percent for a one standard deviation change in the private Herfindahl index (0.29). Reassuringly,
market concentration of private institutions has a larger impact on private college enrollment.
While private enrollment responds to heightened competition in both the public and private
sector, the effects are in opposing directions: A one standard deviation increase in the public
institution H-index leads to an increase in private college enrollment of about 1.7 percent,
whereas a one standard deviation increase in private institution H-index leads to a 3.8 percent
decline in enrollment. In contrast, we find no evidence that increased public or private market
concentration affects enrollment at public institutions after 2006.
In the last two panels of the table, we provide expenditure and instructional expenditure
estimates overall and separately for the public and private sectors. In general, we find that
expenditure and instructional expenditure at both public and private institutions are more
responsive to competition among public schools, although the estimates are somewhat imprecise.
Specifically, we find that per-student expenditure and instructional expenditure at private
19

institutions decline with public-school market concentration after 2006, while public per-student
instructional expenditure increases with public-school market concentration. Private college
market concentration does not affect public or private institutional expenditures.

V. Results from Internet Penetration Variation
Finally, in Table 6 we present results from a complementary identification strategy that
exploits state-by-year variation in Internet penetration, following equation (3). This identification
strategy has considerably less power than our preferred approach, so we only show estimates for
all nonselective schools. Despite the reduced statistical power, these results present supporting
evidence that is important given the potentially strong assumptions underlying casual
identification in equation (1).
The results in Table 6 are qualitatively similar to those shown above. A 10 percentage point
increase in the Internet penetration rate post-2006 leads to a 0.7% reduction in nonselective
enrollment and an increase of $1,587 per student in instructional expenditures. We also find
positive coefficients on overall expenditures and revenues per student. Only the instructional
expenditures effect is significant at even the 10% level. While imprecise, the fact that these
results are broadly consistent with our baseline estimates suggests our conclusions are not being
overly affected by biases driven by differential trends or shocks correlated with 2000 market
shares and with the timing of federal guidelines supporting online postsecondary options.

VI. Conclusion
In this paper we study the impact of increased competition from online degree programs on
traditional postsecondary institutions. Following a regulatory change that increased the market
entry and enrollment of online institutions after 2006, local schools in less competitive markets
experienced relative declines in enrollment. The impacts on enrollment were concentrated among
less selective private institutions that are likely to be online schools’ closest competitors. We also
find that institutions responded to competitive pressure by increasing instructional spending, a
broad proxy for quality. These impacts are driven by public institutions, suggesting that they also
felt pressure to improve quality in response to online competition. In contrast, we find no

20

evidence that increased competition lowered prices for in-person degree programs, perhaps
because Federal Title IV subsidies weaken price competition in higher education.
Our results show the importance of thinking broadly about the impact of online degree
programs on U.S. higher education. Several recent studies have found that online courses and
degree programs lead to less learning, lower degree completion rates and worse labor market
outcomes. However, our findings suggest that online education can be an important driver of
innovation and productivity in U.S. higher education even if (at least at the time of writing)
online institutions are producing a lower quality product. Our results provide preliminary
evidence that the threat of “disruption” from online education may cause traditionally sluggish
and unresponsive institutions to improve quality or risk losing students. Another direct benefit –
unexamined in this paper – is the impact of online schools on access to higher education for
students who do not live near a traditional campus or who must enroll during irregular hours.
While we are still in early days, online degrees are likely to be a disruptive force in the market
for U.S. higher education, and so they remain an important topic for future work.

21

References
Allen, I. Elaine, and Jeff Seaman. 2015. "Grade level: Tracking online education in the United
States." Babson Park, MA: Babson Survey Research Group. Accessed March 10, 2015.
Bowen, William G., Matthew M. Chingos, Kelly A. Lack and Thomas I. Nygren. 2014.
“Interactive Learning Online at Public Universities: Evidence from a Six-Campus Randomized
Trial.” Journal of Policy Analysis and Management 33(1): 94-111.
Bettinger, Eric, Lindsay Fox, Susanna Loeb, and Eric Taylor. 2014. “Changing Distributions:
How Online College Classes Alter Student and Professor Performance.” Mimeo.
Christensen, Clayton M., and Henry J. Eyring. 2011. The Innovative University: Changing the
DNA of Higher Education from the Inside Out. John Wiley & Sons.
Cook, Jason. 2016. “The Effect of Charter Competition on Unionized District Revenues and
Resource Allocation.” Mimeo.
Cowen, Tyler and Alex Tabarrok. 2014. “The Industrial Organization of Online Education.”
American Economic Review 104(5): 519-522.
Clotfelter, Charles T. 1999. “The Familiar but Curious Economics of Higher Education:
Introduction to a Symposium,” Journal of Economic Perspectives 13: 3-12.
Deming, David J., Noam Yuchtman, Amira Abdulafi, Claudia Goldin, and Lawrence F. Katz.
2016. “The Value of Postsecondary Credentials in the Labor Market: An Experimental Study.”
American Economic Review 106(3): 778-806.
Deming, David J., Claudia Goldin, Lawrence F. Katz, and Noam Yuchtman. 2015. “Can Online
Learning Bend the Higher Education Cost Curve?” American Economic Review 105(5): 496-501.
Deming, David J., Claudia Goldin and Lawrence F. Katz. 2012. “The For-Profit Postsecondary
School Sector: Nimble Critters or Agile Predators?” Journal of Economic Perspectives 26(1):
139-163.
Dettling, Lisa J., Sarena Goodman and Jonathan Smith. 2016. Every Little Bit Counts: The
Impact of High-Speed Internet on the Transition to College.” Mimeo.
Figlio, David, Mark Rush and Lu Yin. 2013. “"Is it Live or is it Internet? Experimental Estimates
of the Effects of Online Instruction on Student Learning." Journal of Labor Economics 31(4):
763-784.
Goolsbee, Austan, Michael F. Lovenheim and Joel Slemrod. 2010. “Playing With Fire:
Cigarettes, Taxes and Competition from the Internet.” American Economic Journal: Economic
Policy 2(1): 131-154.
22

Hart, Cassandra, Elizabeth Friedmann, and Michael Hill. 2014. “Online Course-taking and
Student Outcomes in California Community Colleges." Association for Public Policy Analysis &
Management.
Ho, Andrew Dean, Justin Reich, Sergiy O. Nesterko, Daniel Thomas Seaton, Tommy Mullaney,
Jim Waldo, and Isaac Chuang. 2014. “HarvardX and MITx: The First Year of Open Online
Courses, Fall 2012-Summer 2013.” Mimeo.
Hoxby, Caroline M. 1997. “How the Changing Market Structure of US Higher Education
Explains College Tuition” NBER working paper No. w6323.
Hoxby, Caroline M. 2000. “Does Competition among Public Schools Benefit Students and
Taxpayers?” American Economic Review 90(5): 1209-1238.
Hoxby, Caroline M. 2003. “School Choice and School Productivity. Could School Choice be a
Tide that Lifts all Boats?” In The Economics of School Choice, Caroline M. Hoxby (Ed).
University of Chicago Press: Chicago, IL.
Hoxby, Caroline M. 2009. “The Changing Selectivity of American Colleges.” Journal of
Economic Perspectives 23(4): 95-118.
Hoxby, Caroline M. 2014. “The Economics of Online Postsecondary Education: MOOCs,
Nonselective Education, and Highly Selective Education.” NBER Working Paper No. 19816.
Jackson, C. Kirabo. 2012. “School Competition and Teacher Labor Markets: Evidence from
Charter School Entry in North Carolina.” Journal of Public Economics 96(5-6): 431-448.
McPherson, Michael S. and Lawrence S. Bacow. 2015. “Online Higher Education: Beyond the
Hype Cycle.” Journal of Economic Perspectives 29(4): 135-153.
Pew Charitable Trusts. 2016. “Broadband vs. Dial-up Adoption Over Time.” Available Online:
http://www.pewinternet.org/data-trend/internet-use/connection-type/, last accessed 5/15/2016.
Streich, Francie E. 2014. “Online Education in Community Colleges: Access, School Success,
and Labor-Market Outcomes.” Mimeo.
Waldrop, M. Mitchell. 2014. “Massive Open Online Courses, aka MOOCs, Transform Higher
Education and Science.” Nature Magazine: 1-5
Xu, Di and Shanna Smith Jaggars. 2013. “The Impact of Online Learning on Students’ Course
Outcomes: Evidence from a Large Community and Technical College System.” Economics of
Education Review 37(December): 46-57.

23

0

.01

.02

.03

Figure 1. Increasing Specialization of Online Degree Programs: Share of Total U.S.
Enrollment in Online Degree Programs, by year

2000

2003

2006

2009

Schools with significant online presence
Institution is online only, or an identifiable online campus

Source: IPEDS

24

2012

Figure 2. Herfindahl Indices of Non-selective School Market Share by City

(.6867284,1]
(.4403316,.6867284]
(.264122,.4403316]
[.0230999,.264122]
No data

Source: Authors’ calculations from 2000 IPEDS. Non-selective schools are those with an admissions profile below
“Very Competitive” in the 2009 Barron’s Profile of American Colleges.

Figure 3. Herfindahl Indices of Non-selective School Market Share by County

(.999,1]
(.742,.999]
(.406,.742]
[0,.406]
No data

Source: Authors’ calculations from 2000 IPEDS. Non-selective schools are those with an admissions profile below
“Very Competitive” in the 2009 Barron’s Profile of American Colleges.

25

Figure 4. Internet Penetration Rates
1

Internet Penetration Rate

0.9
0.8

AK

0.7

UT

AK

NH
AK

KY

AK

0.6

OR

MS

AK

WV

MS

0.5
0.4
0.2
0.1

MS

MD

0.3

MS

MS

CO

MS

DC
MS

MS

0 WV
1989 1993 1997 1998 2000 2001 2003 2007 2009 2010 2012
Year

Source: 1989, 1993, 1997, 1998, 2000, 2001, 2003, 2007, 2009, 2010 CPS data as described in the text. The state
listed next to each data point shows the state with the highest (diamond) and lowest (square) Internet penetration rate
in that year.

26

Figure 5. The Effect of Online Competition on Traditional School Enrollment – Event
Study Estimates by School Type

-.15

-.1

Log Enrollment
-.05
0

.05

Non-Selective Market Concentration and Changes in Public School Logged Enrollment

2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013
year
Coefficient

95% confidence interval

-.15

-.1

Log Enrollment
-.05
0
.05

Non-Selective Market Concentration and Changes in Private School Logged Enrollment

2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013
year
Coefficient

95% confidence interval

Source: Authors’ estimation of equation (2) using 2000-2013 IPEDS data as described in the text. Each point is an
estimate of , and the bars extending from each point show the 95% confidence interval calculated from standard
errors that are clustered at the market (MSA/county) level.
is set to zero, so all estimates are relative to that
year. Regressions control for market-year unemployment rate, total population, poverty rate, proportion black,
proportion Hispanic, proportion that are veterans, and proportion male. Estimates also include state-by-year fixed
effects and institution fixed effects. Herfindahl (H-) indices are for non-selective schools, which are those with an
admissions profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges.

27

Figure 6. Cross-market Coefficient of Variation in In-state Posted Tuition

Coefficient of Variaiton

0.6
0.5
0.4
0.3
0.2
0.1
Public

Private

0
1990 1992 1994 1996 1998 2000 2002 2004 2006 2008 2010 2012 2014

Year
Source: 1990-2013 IPEDS. The coefficient of variation is the cross-market (MSA/county) standard deviation
divided by the year-specific mean. Tuition is only for non-selective schools, which are those with an admissions
profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges.

28

Figure 7. The Effect of Online Competition on Traditional Private School Tuition – Event
Study Estimates

Tuition
-2000-1500-1000 -500 0 500 1000

Non-Selective Market Concentration and Changes in Private School Tuition

2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013
year
Coefficient

95% confidence interval

Source: Authors’ estimation of equation (2) using 2000-2013 IPEDS data as described in the text. Each point is an
estimate of , and the bars extending from each point show the 95% confidence interval calculated from standard
errors that are clustered at the market (MSA/county) level.
is set to zero, so all estimates are relative to that
year. The regression controls for market-year unemployment rate, total population, poverty rate, proportion black,
proportion Hispanic, proportion that are veterans, and proportion male. All estimates also include state-by-year fixed
effects and institution fixed effects. Herfindahl (H-) indices are for non-selective schools, which are those with an
admissions profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges.

29

Figure 8. The Effect of Online Competition on Traditional School Resources – Event Study
Estimates

-.15

Log Instructional Spending
-.1
-.05
0
.05

Non-Selective Market Concentration and Changes in Instructional Spending

2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013
year
Coefficient

95% confidence interval

Source: Authors’ estimation of equation (2) using 2000-2013 IPEDS data as described in the text. Each point is an
estimate of , and the bars extending from each point show the 95% confidence interval calculated from standard
errors that are clustered at the market (MSA/county) level.
is set to zero, so all estimates are relative to that
year. The regression controls for market-year unemployment rate, total population, poverty rate, proportion black,
proportion Hispanic, proportion that are veterans, and proportion male. All estimates also include state-by-year fixed
effects and institution fixed effects. Herfindahl (H-) indices are for non-selective schools, which are those with an
admissions profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges.

30

Table 1. Descriptive Statistics of Analysis Variables
Variable
Non-selective Herfindahl
Index
Public Herfindahl Index
Private Herfindahl Index
No Public Herfindahl
Index
No Private Herfindahl
Index
Total Enrollment
Log Total Enrollment
In-State Tuition
Log In-State Tuition
Revenues per Student
Expenditures per Student
Instructional Expenditures
per Student
Number of Institutions
Number of Observations

Full
Sample
0.312
(0.309)
0.404
(0.322)
0.290
(0.294)
0.013
(0.115)
0.024
(0.154)
2,337
(5,669)
6.218
(1.847)
11,064
(7,658)
9.018
(0.866)
18,058
(19,167)
16,359
(16,469)
6,062
(5,933)
8,782
88,249

Public
Private
Four-Year Two-Year
Institutions Institutions Institutions Institutions
0.453
0.249
0.284
0.327
(0.363)
(0.257)
(0.292)
(0.316)
0.539
0.342
0.370
0.423
(0.355)
(0.286)
(0.308)
(0.329)
0.376
0.261
0.285
0.293
(0.332)
(0.274)
(0.298)
(0.292)
0.019
0.023
0.008
(0.137)
(0.151)
(0.087)
0.078
0.014
0.030
(0.268)
(0.119)
(0.170)
5,769
816
3,292
1,799
(7,465)
(3,763)
(7,170)
(4,528)
7.719
5.553
6.994
5.782
(1.728)
(1.470)
(1.583)
(1.842)
4,161
14,384
13,959
9,694
(2,848)
(7,001)
(8,318)
(6,915)
8.094
9.463
9.342
8.865
(0.742)
(0.487)
(0.680)
(0.902)
15,227
19,332
23,126
15,057
(20,347)
(18,470)
(21,834)
(16,686)
13,302
17,737
21,132
13,516
(17,204)
(15,936)
(18,531)
(14,373)
5,512
6,310
7,112
5,437
(6,146)
(5,818)
(6,326)
(5,593)
2,176
27,090

6,606
61,159

3,077
28,679

5,705
50,788

Source: 2000-2013 IPEDS data as described in the text. All Herfindahl indices are for non-selective schools, which
are those with an admissions profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges.
Each cell shows the mean for each variable with the standard deviation directly following in parentheses.

31

Table 2. The Effect of Online Competition on Traditional School Enrollment
Panel A: Total Enrollment
All NonIndependent Variable
Selective Public
Non-selective H-Index * -356.0*** -730.4***
(113.0)
(121.7)
Post-2006

Private
-489.3***
(179.3)

4-Year
-467.0*
(258.2)

2-Year
-185.6***
(45.2)

Observations
R2

61,094
0.036

31,747
0.075

56,422
0.103

88,169
0.048

27,075
0.276

Panel B: Log Total Enrollment
All NonIndependent Variable
Selective Public
Non-selective H-Index * -0.064*** -0.002
Post-2006
(0.017)
(0.019)

Private
-0.080***
(0.031)

4-Year 2-Year
-0.062** -0.059***
(0.027) (0.020)

Observations
R2

61,094
0.130

31,747
0.144

88,169
0.130

27,075
0.232

56,422
0.137

Source: Authors’ calculations as described in the text using 2000-2013 IPEDS data. Each column in each panel
comes from a separate regression that controls for market-year unemployment rate, total population, poverty rate,
proportion black, proportion Hispanic, proportion that are veterans, and proportion male. All estimates also include
state-by-year fixed effects and institution fixed effects. Herfindahl (H-) indices are for non-selective schools, which
are those with an admissions profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges.
Standard errors clustered at the market (MSA/county) level are in parentheses: *** indicates statistical significance
at the 1% level, ** indicates significance at the 5% level, and * indicates significance at the 10% level.

32

Table 3. The Effect of Online Competition on In-State Posted Tuition among Private
Institutions
Panel A: Tuition Levels
All
Private
Independent Variable
Private
4-Year
Non-selective H-Index * 267.9
860.7***
Post-2006
(182.7)
(278.6)

Private
2-Year
-264.6
(242.3)

School-year observations
Unique schools
R2

34,964
1,971
0.320

53,744
5,977
0.254

18,780
4,345
0.254

Panel B: Log Tuition
All
Private
Independent Variable
Private
4-Year
Non-selective H-Index * 0.0169
0.0354***
Post-2006
(0.0118) (0.0136)

Private
2-Year
-0.006
(0.0181)

School-year observations
Unique schools
R2

34,956
4,342
0.329

53,731
5,971
0.318

18,775
1,968
0.360

Panel C: Tuition Coefficient of Variation
All
Private
Independent Variable
Private
4-Year
***
Non-selective H-Index * 0.036
0.0069
Post-2006
(0.010)
(0.012)

Private
2-Year
0.046***
(0.015)

School-year observations
Unique schools
R2

34,964
1,971
0.185

53,744
5,977
0.034

18,780
4,345
0.098

Source: Authors’ calculations as described in the text using 2000-2013 IPEDS data. Each column in each panel
comes from a separate regression that controls for market-year unemployment rate, total population, poverty rate,
proportion black, proportion Hispanic, proportion that are veterans, and proportion male. All estimates include stateby-year fixed effects and institution fixed effects. The coefficient of variation is the absolute deviation from the
national year-specific mean divided by the national year-specific mean. Herfindahl (H-) indices are for non-selective
schools, which are those with an admissions profile below “Very Competitive” in the 2009 Barron’s Profile of
American Colleges. Standard errors clustered at the market (MSA/county) level are in parentheses: *** indicates
statistical significance at the 1% level, ** indicates significance at the 5% level, and * indicates significance at the
10% level.

33

Table 4. The Effect of Online Competition on Traditional School Resources
Panel A: Total Expenditures per Student
Dep. Var. Independent
All NonForm
Variable
Selective Public
Private
4-Year
Level
Non-selective H-328.9
1,620
-564.0
1,094*
(659.8)
Index * Post-2006
(576.3)
(1,036)
(766.5)
Log

Non-selective HIndex * Post-2006

-0.041**
(0.017)

-0.010
(0.024)

-0.045
(0.027)

0.015
(0.019)

2-Year
-383.1
(794.4)
-0.056**
(0.024)

Panel B: Instructional Expenditures per Student
Dep. Var. Independent
All NonForm
Variable
Selective Public
Private
4-Year
**
Level
Non-selective H-155.6
740.7
-151.7
456.8**
Index * Post-2006
(210.0)
(197.5)
(364.6)
(269.0)

2-Year
-284.2
(304.0)

0.059***
(0.022)

0.101***
(0.022)

0.037
(0.032)

Panel C: Total Revenues per Student
All NonSelective Public
Private
4-Year
-1,185*
1,953
-1,982**
-117.3
(703.3)
(1,298)
(884.1)
(928.6)

2-Year
-941.9
(999.3)

Log

Non-selective HIndex * Post-2006

Dep. Var. Independent
Form
Variable
Level
Non-selective HIndex * Post-2006
Log

Non-selective HIndex * Post-2006

-0.055***
(0.016)

0.060*
(0.033)

-0.015
(0.024)

-0.008
(0.031)

-0.074***
(0.027)

-0.015
(0.022)

-0.064***
(0.022)

Source: Authors’ calculations as described in the text using 2000-2013 IPEDS data. Each cell comes from a separate
regression that controls for market-year unemployment rate, total population, poverty rate, proportion black,
proportion Hispanic, proportion that are veterans, and proportion male. All estimates also include state-by-year fixed
effects and institution fixed effects. Herfindahl (H-) indices are for non-selective schools, which are those with an
admissions profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges. Total expenditure
per student, instructional expenditures per student, and total revenues per student are top and bottom coded (or
winsorized) at the 99th and 1st percentiles to address measurement issues generated by extreme outliers. Standard
errors clustered at the market (MSA/county) level are in parentheses: *** indicates statistical significance at the 1%
level, ** indicates significance at the 5% level, and * indicates significance at the 10% level.

34

Table 5. The Effect of Online Competition on Traditional Schools – Using Sector-Specific
Market Share Measures
Panel A: Log Enrollment
All NonIndependent Variable
Selective
Public
Public H-Index
-0.00206
0.0103
(0.0162)
(0.0199)
Private H-Index
-0.0608***
-0.0205
(0.0168)
(0.0184)

Private
0.0587**
(0.0271)
-0.1297***
(0.0279)

Panel B: Log Expenditures per Student
All NonIndependent Variable
Selective
Public
Public H-Index
-0.0494***
-0.0214
(0.0171)
(0.0260)
Private H-Index
0.0093
0.0288
(0.0178)
(0.0223)

Private
-0.0514***
(0.250)
-0.0026
(0.0261)

Panel C: Log Instructional Expenditures per Student
All NonIndependent Variable
Selective
Public
Private
*
Public H-Index
0.0290
0.0600
-0.0531*
(0.0217)
(0.0358) (0.0279)
Private H-Index
0.0043
0.0039
0.0228
(0.0219)
(0.0278) (0.0294)
Source: Authors’ calculations as described in the text using 2000-2013 IPEDS data. Each column in each panel
comes from a separate regression that controls for market-year unemployment rate, total population, poverty rate,
proportion black, proportion Hispanic, proportion that are veterans, and proportion male. All estimates also include
state-by-year fixed effects and institution fixed effects. Herfindahl (H-) indices are for non-selective schools, which
are those with an admissions profile below “Very Competitive” in the 2009 Barron’s Profile of American Colleges.
Standard errors clustered at the market (MSA/county) level are in parentheses: *** indicates statistical significance
at the 1% level, ** indicates significance at the 5% level, and * indicates significance at the 10% level.

35

Table 6. The Effect of Online Competition on Traditional Schools- Internet Growth
Independent
Variable
Internet Rate
Internet Rate* Post2006

Instructional
Log
Expenditures Expenditures Revenues
Enrollment Enrollment per Student
per Student
per Student
*
-2368
0.056
8,477
3,578
3,442
(1,276)
(0.173)
(7,033)
(2,236)
(8,986)
64.91
-0.074
-1,675
-447.3
-3,681
(543.7)
(0.151)
(3,421)
(1,231)
(4,396)

Source: Authors’ calculations as described in the text using 2000-2013 IPEDS data. Each column comes from a
separate regression that controls for state-year unemployment rate, total population, poverty rate, proportion black,
proportion Hispanic, proportion that are veterans, and proportion male. All estimates include institution and year
fixed effects. The estimation sample includes all non-selective schools, which are those with an admissions profile
below “Very Competitive” in the 2009 Barron’s Profile of American Colleges. Total expenditure per student,
instructional expenditures per student, and total revenues per student are top and bottom coded or Winsorized at the
99th and 1st percentiles to address measurement issues generated by extreme outliers. Standard errors clustered at the
state level are in parentheses: *** indicates statistical significance at the 1% level, ** indicates significance at the
5% level, and * indicates significance at the 10% level.

36

Appendix Figure 1. Distribution of Herfindahl Indices

0

1

D e n sit y
2

3

4

All Nonselective Institutions

0

.2

.4
.6
Herfindahl Index

.8

1

kernel = epanechnikov, bandwidth = 0.0249

Private Institutions

0

0

.5

1

D e n sit y
2

D e n sit y
1
1.5

3

2

4

2.5

Public Institutions

0

.2

.4
.6
Public Herfindahl Index

.8

0

1

.2

.4
.6
Private Herfindahl Index

kerne l = epa nechniko v, bandwidth = 0.0207

kerne l = epanechniko v, bandwidth = 0 .030 0

37

.8

1

