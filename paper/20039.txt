NBER WORKING PAPER SERIES

ALGORITHMS AND THE CHANGING FRONTIER
Hezekiah Agwara
Philip Auerswald
Brian Higginbotham
Working Paper 20039
http://www.nber.org/papers/w20039
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2014

We thank Adam Jaffe, Ben Jones, Tim Simcoe, and participants in the NBER “The Changing Frontier:
Rethinking Science and Innovation Policy” pre-conference and conference for their comments. We
also thank Lewis Branscomb, Stuart Kauffman, José Lobo, and Karl Shell for their contribution to
developing ideas central this chapter via jointly authored work, and W. Brian Arthur for helpful
conversations, insights and inspiration. The views expressed herein are those of the authors and do
not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2014 by Hezekiah Agwara, Philip Auerswald, and Brian Higginbotham. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.

Algorithms and the Changing Frontier
Hezekiah Agwara, Philip Auerswald, and Brian Higginbotham
NBER Working Paper No. 20039
April 2014
JEL No. D30,F60,L15,O31,O32,O33
ABSTRACT
We first summarize the dominant interpretations of the “frontier” in the United States and predecessor
colonies over the past 400 years: agricultural (1610s-1880s), industrial (1890s-1930s), scientific (1940s1980s), and algorithmic (1990s-present). We describe the difference between the algorithmic frontier
and the scientific frontier. We then propose that the recent phenomenon referred to as “globalization”
is actually better understood as the progression of the algorithmic frontier, as enabled by standards
that in turn have facilitated the interoperability of firm-level production algorithms. We conclude by
describing implications of the advance of the algorithmic frontier for scientific discovery and technological
innovation.
Hezekiah Agwara
George Mason University
hezekiah.agwara@gmail.com
Philip Auerswald
George Mason University
3351 Fairfax Dr., MS 3B1
Arlington, Virginia 22201
philip.auerswald@gmail.com

Brian Higginbotham
George Mason University
BHigginbotham@uschamber.com

Everywhere, economic activity is turning outward by embracing shared business and
technology standards that let businesses plug into truly global systems of production.
— Sam Palmisano, former CEO of IBM (2006, p. 130)
I. Introduction
“What is the frontier?” Frederick Jackson Turner asked in his seminal work, The Frontier in
American History (1893). “In the census reports it is treated as the margin of that settlement
which has a density of two or more to the square mile.” When Turner wrote of the closing of the
American frontier, he was referring to the end of an interval that lasted over three hundred years,
as the first European settlements in the North American continent grew and expanded westward.
The frontier was viewed as a place, bounded on one side by the easternmost fields cleared for
agriculture and on the other by the westernmost wilderness. In between, Turner argued, was a
marginal space in which necessity was, even more than elsewhere, the mother of invention.
By the time Franklin Delano Roosevelt wrote to Vannevar Bush in November 1944 to request
the report celebrated in this research volume, the frontier itself had changed. “New frontiers of
the mind are before us,” Roosevelt wrote, “and if they are pioneered with the same vision,
boldness, and drive with which we have waged this war we can create a fuller and more fruitful
employment and a fuller and more fruitful life.” Much as Thomas Jefferson had charged
Meriwether Lewis and William Clark to survey the previously unexplored domains of the West
in 1803, so Roosevelt tasked Bush to survey previously unexplored domains of human inquiry.
The desired endpoint of the undertaking was the same in both cases: to improve lives and
increase prosperity.
The title of the report Bush produced, Science the Endless Frontier, expressed succinctly how
societal progress was defined by the middle of the twentieth century. Released in July 1945, a
month after the Allied victory in Europe and a year before George Doriot created the world’s
first publicly owned venture capital firm, Bush’s report was about how best to maintain in
peacetime a rate of scientific progress that had been unprecedented when driven by the
necessities of war.

2

The frontier of scientific knowledge has advanced at least as dramatically in the nearly seventy
years since 1945 as the frontier of the American West advanced in the seventy years after 1803.
In both cases, the advancement was part of “the changing frontier” that has been a central feature
of American economic history, which in turn is the title of this volume. The real change related
to the evolution of the frontier itself.
It is significant that America’s first World’s Fair opened in Philadelphia exactly seventy years
after Lewis and Clark returned to St. Louis at the end of their two-year expedition. The
International Exhibition of Arts, Manufacturers, and Products of the Soil and Mine, as it was
officially called, was a sort of museum in reverse in which inventions that signaled the creation
of major new industries were first exhibited to the general public. These included Alexander
Graham Bell’s telephone (communications technology), the Remington typewriter (office
services), the Wallace-Farmer Electric Dynamo (electric power), and Heinz Ketchup (food
processing). Indeed, there is considerable poetic significance in the fact that Frederick Jackson
Turner first presented his renowned paper on “The Significance of the Frontier in American
History” before the American Historical Society at a subsequent World’s Fair—the 1893
World’s Columbian Exposition in Chicago.
What of today? Where is the changing frontier of societal advance situated in 2013, both in the
United States and globally? Is that frontier expanding or closing? These are the questions we
seek to answer in this chapter.
To be clear, we recognize from the outset the parallel relevance of multiple notions of the
“frontier.” From the standpoint of a single firm or of a nation, we can think of the frontier as the
boundary of economic production given existing technology and techniques—the “production
possibilities frontier” (PPF) whose origins trace back to the early 19th century and the work of
David Ricardo. We can also define the frontier in a global sense in terms of the boundaries of
scientific advance, much in the way that Vannevar Bush employed the term. Or, as Cesar
Hildalgo, Ricardo Hausmann, and co-authors have recently explored,1 we can define the
economic frontier for any region or country in terms of the country’s existing (and constantly
evolving) production capabilities.

1

Hidalgo, Hausmann and Dasgupta (2009) and Haussman et al. (2011).

3

In this chapter we are arguing that these three concepts of the frontier—the frontier of industry,
the frontier of science, and the frontier of what we’ll call algorithms—actually define an
advancing frontier of their own. That advancing “frontier of frontiers” is global.
The way we think about the frontier obviously affects how we seek to measure it. Total factor
productivity serves to measure the advance of aggregate production possibilities. Patents can
(with well known limitations) measure the advance of the scientific frontier. Measures of the
advance of the algorithmic frontier are less well developed. We propose some potential proxies
in this chapter.
We develop our argument in three stages. In section II we introduce the idea of “the algorithmic
frontier” through a summary of the progression of the idea of the frontier in American history.
In particular we summarize different dominant interpretations of the frontier over the past four
hundred years of U.S. history: agricultural (1610s-1880s), industrial (1890s-1930s), scientific
(1940s-1980s), and algorithmic (1990s-present). We then go back and motivate the idea of the
algorithmic frontier a second time, from the standpoint of the evolution of economic theory. We
argue (as suggested above) that the progression of historical frontiers (or, more precisely, of the
frontier of frontiers) finds its direct parallel in the progression of economic theory.
In section III of the paper we set the stage for proposing potential measures of the advance of the
algorithmic frontier by discussing the relationship of “production recipes” (a term with historical
resonance in economics that we use interchangeably with “production algorithms”), standards,
and inter-operability (both within and between firms). This section of the paper provides a bridge
to sections IV and V, in which we argue that the last thirty years of the centuries-old process
referred to as “globalization” has been, more than ever before, defined by the adoption of
standards and associated improvement in the inter-operability of production algorithms. This is
where our argument connects directly with Hildalgo and Hausmann (2009) and Hausmann et al.
(2011), as well as with considerable prior literature that emphasizes the algorithmic substructure
of the global exchange economy.
Finally, in section VI, we tie the chapter back to the core theme of this volume by discussing
how the advance of the algorithmic frontier has affected the process of scientific discovery and
technological innovation. Section VII concludes.

4

II. Changing Frontiers in the United States
Historical Context
The first American frontier requires little description. The map in Figure 1 illustrates the
movement of the frontier westward from 1803 through the nineteenth century. The social
complexity of the process of westward movement—a subject of active scholarly inquiry in the
century since Turner presented his paper—yields to remarkable simplicity when looked at from a
cartographic perspective. Inexorably, the frontier moved westward until European settlements
covered a continent. The economy of the United States during this lengthy interval was defined
by two industries: agriculture and the extraction of natural resources. Accordingly, we refer to
this first, most famous frontier in American history as the agricultural frontier.
[Insert Figure 1 Here]
The second American frontier was not the scientific one that formed the subject of the Bush
report but its industrial precursor. The World’s Fair was to the era of the industrial frontier what
the earliest precursors of the rodeo were to the era of the agricultural frontier: places where
successful experimentation could be recognized and rewarded. The inventive wave that had been
building since the 1870s continued to gain force. In the 1900s alone the Wright brothers flew the
first plane at Kitty Hawk, Henry Ford sold his first Model A, Samuel Insull merged
Commonwealth Electric with Chicago Edison to create Commonwealth Edison—the world’s
first large-scale electric utility—and major breakthroughs were made in the development of the
radio.
The frontier for the United States in the first third of its history was thus about realizing
economies of scale afforded by the combination of new technologies and new modes of social
organizations. The era from the 1890s to the 1930s (in particular from roughly 1910 to the start
of World War II) was the one in which the basic infrastructure of the modern United States was
developed. The high-level industrial classifications that experienced the greatest growth during
this interval include utilities, electric equipment and supplies, rubber and plastic products,
petroleum and coal products, and printing and publishing.2 The inventions listed above were
among the sparks that ignited the industrial engine of the early twentieth century.
2

Data from the Historical Statistics of the United States and the Census of Manufacturers.

5

Bibliometric analysis provides a particularly vivid lens through which to view the changing
industrial frontier. Figure 2 presents data on word frequencies created using Google Ngram,
which is based on a digital database of more than 5.2 million books published worldwide
between 1500 and 2008 and comprises more than 500 billion words. Around that database
Google created an interface they call the Ngram Viewer, which enables users to plot the
frequency with which words and phrases appear in this dataset over time.3 The Ngram tool can
be used to get a sense of the intensity of interest in particular technologies over time—put simply,
the relative frequency with which particular words appear in published works of any type, for
every year since 1500. Figure 2 presents a sample plot using the words “carriage, automobile,
airplane, and rocket.” The pattern shown for each of these words is consistent with the “hype
cycle” hypothesized by Gartner Consulting, illustrated in Figure 3. In the Gartner model, societal
interest (which we conjecture is correlated with word frequencies in the Ngram database) in a
technology grows rapidly after its first introduction. Interest soon reaches a peak, after which an
era of disillusionment sets in. Interest falls off, usually just as the foundation for widespread
societal adoption is setting in. By the time a technology is ubiquitous, its everyday usage is
roughly constant; economic stability is reflected by this bibliometric stability.4
[Insert Figures 2 and 3 Here]
Although the plot in Figure 2 is a simple representation of word frequency over time, it has some
interesting characteristics. First, from 1900 to 1940, use of the word “carriage” decreases at just
about the same rate that use of the word “automobile” increases; this is consistent with our
intuition about the introduction of a more powerful substitute technology. Second, consistent
with the Gartner hypothesis, the peak of relative intensity of usage comes well before
technological maturity and market ubiquity. Finally, for these two words at least, the “hype cycle”
seems to become increasingly compressed over time. This is consistent with considerable data
that documents the increasing rates of adoption of new technologies and shorter product life
cycles over time.

3

See http://books.google.com/ngrams.

4

For more on the Gartner hype cycle see

http://www.gartner.com/technology/research/methodologies/hype-cycle.jsp.

6

The inventions that defined the industrial frontier from 1890 through the 1930s represented
major advances not just for the United States but for humanity on a global scale. However, these
inventions were the outcome not of scientific research but of systematic tinkering. In the middle
of the twentieth century the nature of invention began to change; invention became more
scientific, with scientific research playing an increasing role in motivating major advances.5
Again, simple word-frequency plots help illustrate. Figure 4, also created with Google’s Ngram
tool, illustrates the intensity of usage of the words “research” and “technology” from 1800 to
2000. Rarely used before 1900, “research” begins to gain currency only in the 1920s, rises
steadily, and then levels off starting in the 1980s. Technology follows a similar trend, but the
period of rapid rise begins in the 1960s.
[Insert Figure 4 Here]
Figure 5 illustrates the system of science-based innovation that came into being following World
War II. Advances in fundamental knowledge—the basic science column on the left-hand side—
undergird the system of science-based innovation in a modern economy. Of course, advances in
basic science will have no impact on economic growth or human well-being if they do not
translate first into technologies, and ultimately into goods and services. The core technologies
5

Joseph Schumpeter wrote of the innovation as early as 1928 that within the emerging “trustified”

capitalism “innovation is no longer . . . embodied typically in new firms, but goes on, within the big units
now existing . . . Progress becomes ‘automatised,’ increasingly impersonal and decreasingly a matter of
leadership and individual initiative.” By 1959, John Jewkes, David Sawers, and Richard Stillerman wrote:
In the twentieth century . . . the individual inventor is becoming rare; men with the power of
originating are largely absorbed into research institutions of one kind or another, where they must
have expensive equipment for their work. Useful invention is to an ever-increasing degree issuing
from the research laboratories of large firms which alone can afford to operate on an appropriate
scale . . . Invention has become more automatic, less the result of intuition or genius and more a
matter of deliberate design.
This world of systematic innovation—if not based on science, per se, then on research more generally
understood—represents the frontier that Vannevar Bush described, and sought to advance, in Science the
Endless Frontier.

7

represented in the second column are the direct translation of science into a capability for
innovation. Core technologies may be developed within the university, in an entrepreneurial
startup, or, most commonly, in the existing corporation. Core technologies typically are
combined to create new goods and services. Industry production networks organized around
existing goods and services are represented in the third column from the left. Industry production
networks, or industry “clusters” when localized, are defined in terms of goods and services, not
in terms of technologies. On the far right-hand side are the product markets themselves, where
consumers and workers are situated. Innovations that renew or re-create existing industries not
infrequently originate with workers near a production process, or with consumers of a product or
service, rather than in a lab or university.
[Insert Figure 5 Here]
As Bush foresaw, this system has yielded significant dividends for American society.
Tremendous scientific advances were made at Bell Telephone Laboratories, DuPont, General
Electric, RCA Laboratories, the IBM T. J. Watson Research Center, the Xerox Palo Alto
Research Center, together defining a Golden Age of corporate research and development (R&D)
in the United States (Auerswald & Branscomb, 2005). It was the work that took place in these
laboratories—arguably at least as much as that in universities, which was more distant from
market applications—that defined the scientific frontier that drove the advance of the U.S.
economy in the post-World War II era (Trajtenberg et al., 1992).
Coming fifty years after the publication of Turner’s classic work on the closing of the western
frontier, the title of the Bush report was significantly expansive: Science the Endless Frontier
pointed to a dimension of human attainment that would not be subject to limitation, as the prior
era had been. In the case of the westward expansion, an insurmountable obstacle ultimately was
reached: the Pacific Ocean. To Bush and those of his generation, no such obstacle was
foreseeable when it came to the scientific frontier. An end to science-based innovation was
essentially inconceivable. Yet by the 1970s, fewer private firms—regardless of their size—found
it to be in their interest to invest in the sort of basic research that the Bush report had championed.
One-by-one, the great corporate laboratories either closed or sharply narrowed their focus.
Macroeconomic data also suggests that a significant structural shift took place in the economic
frontier in the 1970s. Using a methodology developed by the Bureau of Economic Analysis

8

(BEA), Lee and Schmidt (2010) calculate the changes to GDP that result from treating R&D as
an investment rather than as an expense (Table 1). They find that recategorizing R&D in this
manner adds 0.13 percent to GDP growth rates from 1959 to 1973. However, from 1973 to 1994,
the impact vanishes. This coincides with the much-discussed productivity slowdown, as well as
the “conglomerate” discount experienced by the largest and most diversified U.S. corporations
starting in the late 1960s.
[Insert Table 1 Here]
In the BEA analysis, the re-categorization of R&D as investment once again begins to change the
calculation of GDP growth rates appreciably from 1995 to 2007. As Jorgenson and Stiroh (2000)
have documented, the primary vehicle by which R&D was contributing to GDP growth in the
late 1990s and 2000s was via innovations in information and communications technology (ICT).
The new frontier was, and is, algorithmic rather than research-based.
This is not to say that the system of science-based innovation described in Figure 5 has vanished.
Far from it: it is larger and more robust than ever. As in prior eras, the infrastructure developed
during the advance of one frontier remains fundamental to society as the next develops.
Agricultural output increased for decades after the agricultural frontier was overtaken by the
industrial frontier. Manufacturing output increased for decades after the industrial frontier was
overtaken by the scientific frontier. Similarly, the output of science-based innovation has
continued to increase even as that frontier has been overtaken by the algorithmic frontier.
Theoretical Context
We can readily describe the difference between agricultural, industrial, scientific, and
algorithmic frontiers using standard production theory. Each of the first three frontiers has an
associated domain within economics. The economics of the agricultural frontier were
Malthusian; the economics of the industrial frontier were those of classical growth theory; and
the economics of science based-innovation are those of the particular variant of growth theory
advanced in Romer (1986, 1990). In this section, we argue that the algorithmic frontier may
require different economics as anticipated long ago by Simon (1967), Winter (1968), and Arrow
(1971) and partially articulated more recently by Aghion and Howitt, (1992), Kremer (1993),

9

Romer (1996), Weitzman (1998), Hildalgo and Hausmann (2009), Hausmann et al. (2011),
Bloom & Van Reenen, (2010), and Arthur (2009, 2011) among others.
In a Malthusian world, land is the fundamental fixed factor, whereas populations are variable.
Accordingly, rents accrue to land, and an interval of growth (though ephemeral) can be realized
only through geographical expansion. Long-term growth is infeasible.
In an industrial model, capital replaces land. Investment can increase the capital-to-labor ratio.
This increases the marginal product of labor, and thus the wage rate. Both the rate of population
growth and the rate of technical change are exogenous. Growth is a matter of reaching the steady
state level of per-capita consumption, which in turn is limited by the rate of technological
advance. This, writ large, is the familiar world of the neoclassical growth model.
In the science-based model, technical change is the result of active investment. Knowledge is
non-rival and non-excludable, so the outcomes of R&D investments spill over to the economy as
a whole.6 Achieving economic equilibrium in the presence of aggregate increasing returns to
knowledge is feasible so long as the research technology exhibits locally decreasing returns.
Long-term growth rates can be increased by subsidizing research or the accumulation of human
capital. This, writ large, is the familiar growth model set forth in Romer (1986, 1990).
How does the algorithmic model differ from the science-based model? Where the science-based
model (like the Bush report) is built on the assumption that the transmission of economic
knowledge is (or at least can be) costless and error free, the algorithmic model takes the costly
process by which ideas are created, stored, shared, combined, and, of course, connected to
economic exchange as the central problem of economic life.
The algorithmic model recognizes the possibility of a global best practice, or optimum, but does
not assume that all firms, or all countries, will operate at this point. Even within the United States

6

This notion is associated with the work of Romer (1986, 1990), though it is present many other places.

“Non-rival” means that one person’s use of an idea does not keep another person from using the idea;
“non-excludable” means that it is impossible to keep a person from using an idea once it is “out in the
open”; and “knowledge spillovers” refers to the costless transmission of ideas that are non-rival and nonexcludable. Romer (1996) also employs the term “recipes” to refer to production algorithms, following
both Simon (1967) and Winter (1968).

10

not all firms within an industry operate at the production possibilities frontier. While some firms
maintain an advantaged position through nonmarket competition, there is a deeper trend at work
in this new frontier.
The algorithmic model recognizes that research and development is an important element inside
the black box of productivity, but that research and new knowledge creation are necessary but
insufficient conditions to allow firms to operate at the boundary of the production possibilities
frontier. This reflects the fact that there is diversity in the productivity levels of knowledge
creation, which forms the basis of comparative advantage. This diversity in knowledge—itself
the outcome of path-dependent processes—leads to diverse levels of productivity in product
innovation.7
New knowledge creation through research and development plays a crucial role in economic
growth, but the diversity in productivity levels within or between countries is also a function of
the diversity of productivity levels in process innovation. The algorithmic model internalizes the
insight that management quality varies and that management heterogeneity is central to
understanding observed differentials between regions and nations.8 When firm-level managers
oversee the evolution of a production algorithm, they may emphasize different components of a
management strategy. As an example, Bloom and Van Reenen (2010) find that American firms
are better at providing incentives but are worse at monitoring than are managers in Sweden.
Process innovation has always mattered but because of increasing organizational complexity
from dispersed production networks, production algorithms and the organization of information
are now defining the frontier of economic progress as never before.
In this light, consider the notion, central to the science-based model, that ideas are both “nonrival” and “non-excludable,” and economically relevant innovations are characteristically subject
to “knowledge spillovers.” In the algorithmic model, the ideas that actually propel growth and
development are overwhelmingly uncodified, context dependent, and transferable only at

7

Hildalgo, Haussman, and Dasgupta (2009); Hidalgo et al. (2011).

8

Goldfarb and Yang (2009).

11

significant cost—which is to say that tacit knowledge dominates, information asymmetries are
the norm, and transactions costs are significant.9
While knowledge spillovers of the type that are central to the science-based model clearly exist,
they are unlikely to be of significant relevance in the practical work of creating the new business
entities that drive twenty-first-century global value chains.10 The reason for this is that most
productive knowledge is firm specific and producers far from dominant production clusters must
learn to produce through a process of trial and error. Market-driven innovation involves the
search for ideas that are rivalrous and excludable (at least temporarily), out of which ventures
with proprietary value can be created. The impediments to innovation that matter most are not a
lack of appropriability of returns but the everyday battles involved in communicating ideas,
building trust, and making deals across geographically disparate regions and diverse economic
units.11 To the extent that the public benefits not captured by the investing firm (resulting from
knowledge spillovers or other mechanisms) are temporally far off or uncertain, it is unlikely that
they will be of greater importance to innovation-related decision-making than will be the
immediate, first-order challenges of organizing and financing the firm’s operations.12
In the next section we develop this idea further. We first define “production recipes,” a term that
has historical resonance in economics that we will use interchangeably with “production
algorithms.” We then consider how the adoption of standards enables the interoperability of
firm-scale production recipes. We argue that improvements in inter-operability have been
essential to the functioning of complex supply chains, and in this manner have been central to the
story of unprecedented growth experienced globally in the past decade.

9

Important early work by Mansfield (1961, 1963) on the subject of technological change related to

imitation by one firm of the production methods of another. This work advanced the studies by Griliches
(1957) on technological adoption. Where Griliches had used published data to study the adoption of
essentially modular agricultural technologies, Mansfield (1961) used questionnaires and interviews to
study the adoption of new production techniques by large firms in four industries.
10

We emphasize that the focus here is not on web pages and pirated music videos. These digitized

products—even including patents—are not the same thing as production algorithms or recipes.
11

Auerswald (2008).

12

Bloom & Van Reenen (2010).

12

III. Production recipes, Standards, and Interoperability
Production Recipes
Schumpeter (1912) famously wrote “Technologically as well as economically considered,
production ‘creates’ nothing in the physical sense. In both cases it can only influence or control
things and processes, or “forces.”… [T]o produce means to combine the things and forces within
our reach. Every method of production signifies some definite combination … The carrying out
of new combinations we call ‘enterprise’; the individuals whose function it is to carry them out
we call ‘entrepreneurs.’” The “new combinations” that entrepreneurs create are combinations of
interdependent activities that jointly constitute the organization. These are “routines” in the
language of Nelson and Winter (1982),“organizational capabilities” in the language of Chandler
(1990, 1992), and “production recipes” in the language of Winter (1968) and Auerswald et al.
(2000).
In this paper, we employ “production recipes” as our term of choice to describe combinations of
interdependent activities that jointly constitute an organization. In this language, we can readily
think of mangers as “cooks” who oversee the execution of existing, well-known, recipes while
entrepreneurs are more like “chefs,” improvising new recipes—which is to say, creating new
combinations.13
The use of the term “recipe” serves as a reminder that the sort of routinized processes of
production we seek to describe with this term are as old as human society itself. Among the
oldest Sumerian tablets are ones that describe actual recipes (e.g. for the production of beer) as
well as numerical algorithms.14 Indeed, we will employ the term “recipe” interchangeably with
“production algorithm.”
The idea of a recipe was clearly expressed by Winter (1968, p. 9): “‘Knowing how to bake a
cake’ is clearly not the same thing as ‘knowing how to bring together all of the ingredients for a
cake.’ Knowing how to bake a cake is knowing how to execute the sequence of operations that
are specified, more or less closely, in a cake recipe.” In the algorithmic model, this distinction

13

We thank Irwin Feller for sharing this analogy. See also Auerswald (2012).

14

Knuth (1972) and Auerswald (2012).

13

takes on first-order importance: knowing how to bake a cake is different from knowing how to
bring together all of the ingredients for a cake.
Figure 6, drawn from Auerswald et al. (2000), illustrates this point.15 A neoclassical production
plan is a particular input-output relationship. In its simplest rendition, it is a point (x, y) where x
≥ 0 is the quantity of the input and where y ≥ 0 is the quantity of the output. Figure 6 shows the
production possibilities of the firm, the shaded area T, and three specific possible production
plans labeled A, B, and C. The production function in this figure exhibits constant returns to
scale, such that the best a firm can do is
y=θx
where θ is a positive scalar that can be thought of as the organizational capital of the most
productively efficient firm. The production function is comprised of the set of input-output pairs
that lie on the boundary of the production possibilities set.
[Insert Figure 6 Here]
All of this is just a restatement of standard theory. Now, however, assume further that the
approach utilized by the firm to convert inputs to outputs is encoded as a program. This program
runs inside the “black box” of the standard production function to convert inputs to outputs.
For the sake of illustration, let us say that a given production process is comprised of three
operations, each of which can be conducted in one of just two ways. We can exhaustively
enumerate all possible production recipes as the set of eight binary strings {000, 001, 010, 100,
011, 101, 110, 111}. Each of these recipes will be associated with its own scalar measure of
effectiveness. Let us refer to the level of effectiveness as the “organizational capital” associated
with the recipe. For example, recipe 010 might be associated with organizational capital θ, and
recipe 101 might be associated with organizational capital θ'. Let us arbitrarily say that recipe
010 is the best of the bunch, so its associated level of organizational capital is greater than the
organizational capital associated with any of the other recipes.

15

The description of Figure 6 that follows in the next three pages is drawn from Auerswald (2009) and

Auerswald and Branscomb (2005).

14

Referring back to Figure 6, input-output pair A, which lies on the boundary line as defined by y
= θx, clearly “dominates” input-output pair B; the firm using recipe 010 produces more output
with less input than the firm using recipe 101. For all firms to operate on the production
possibilities frontier requires (1) that all firms have knowledge of the elements of the set of
potentially usable recipes; (2) that all firms are aware of the effectiveness of each recipe in actual
production. Under such conditions, all firms in this example would use production recipe 010.
Figure 6 also allows us to clearly see the difference between economic distance and
technological distance. From an economic standpoint, input-output pair A is close to input-output
pair B but distant from input-output pair C. However, from the standpoint of technology, pairs A
and C are the same, as they are produced with the same recipe (010); input-output pair B is
maximally different from both A and C, in that the recipe used to produce B differs in every
operation from that used to produce pairs A and C. Taking one operation at a time, 0 ≠ 1; 1 ≠ 0;
0 ≠ 1. Since there are three operations in all and the two recipes differ in every operation, the
technological distance between the two recipes is 3.
The complexity of a production recipe can be represented either in terms of both the number of
“operations” or distinct units involved in the production process or (critically) the extent of the
interdependence between those units.16 The greater the complexity of technology as defined in
terms of interdependence, the lower the correlation between the effectiveness of the original
production recipes (i.e., the leader’s method) and that of the same recipe altered slightly (i.e., an
imperfect imitation).17
In the Romer (1986, 1990) science-based model, technological distance does not exist; newly
discovered recipes add to aggregate knowledge as soon as they are put into practice. In the
16

Coase (1937, p. 390) argued that, in the presence of technological interdependencies, firms will expand

to realize economies of scope. When firms do expand in such a manner to internalize the externalities,
they create what Auerswald et al. (2000) term “intra-firm externalities.” Indeed, if one particular unit of a
firm is not linked to any other via such intra-firm externalities, then we reasonably wonder why that unit
is part of the firm to begin with (rather than, for example, acting as an outside contractor). In this sense, a
transactions cost theory of the firm predicts that, in industries where technological interdependencies
abound, managers will typically be charged with solving complex coordination problems.
17

See Auerswald (2009) and related prior work; also Rivkin (2000).

15

algorithmic model, search for better recipes is constrained both by technological distance and by
the complexity of the production process. Newly discovered recipes that are not easily imitated
are the essence of economic differentiation and the basis for above-normal profits.
The Historical Importance of Standards
According to the International Organization for Standards (ISO 2004), standards are a
“document, established by consensus and approved by a recognized body, that provides, for
common and repeated use, rules, guidelines or characteristics for activities or their results, aimed
at the achievement of the optimum degree of order in a given context.” The term “optimum order”
is significant. The standardization of interfaces allows for a system-wide optimization of the
balance between order and flexibility in the supply chain.18 Standards are one form of codified
knowledge that have been critical in sharing technical knowledge and expanding the reach of the
market.19
The first emperor of China, Qin Shi Huangdi (221 to 206 BC), standardized both writing and
weights and measures, with the aim of increasing trade within the newly unified country. From
the invention of bills of exchange in the Middle Ages, to the development of universal time in
the late 19th century and container shipping in the mid-20th, innovations in standards have
lowered the cost and enhanced the value of exchanges across distances. In the process, they have
created new capabilities and opportunities on a global scale.
In our most recent period of globalization, the role of standards grew in importance as trade
resumed in the post-WWII era. High transactions costs initially impeded trade, despite the
emphasis on open markets and the resumption of (mostly) free trade through the Bretton Woods
institutions. Some of the impediments stemmed from difficulties at the transition points of the
global economy rather than tariff levels per se. One of the dominant forces driving the
algorithmic frontier has been an unceasing quest to harmonize standards globally.

18

Auerswald (2012).

19

It is evident, of course, that standards can also restrict trade. For a thorough discussion see e.g. World

Trade Organization, 2005 World Trade Report: Exploring the links between trade, standards and the
WTO, Geneva: World Trade Organization, 2005.

16

The growth of supply chains and the role of standardization in facilitating efficient chains thus
have been critical to the functioning of global markets. Standardization of containerized
shipping20 and pallets,21 two seemingly innocuous and generally unheralded developments,
combined to transform global trading patterns. Entrepreneurs Malcolm Mclean in shipping and
Norman Cahners in pallets, performing an essential operations research task, were responsible
for these two transformations.22 As a result of these standards, global shipping costs fell from
over $5.86 per ton in the 1950s to about $0.16 today.23
The European adoption of the global system for mobile communications (GSM) standards is
another example of the benefit of standards harmonization. While Europe achieved rapid
advances in mobile technology, in the U.S. the FCC decided not to adopt an official cellular
standard but to allow competition to select the optimal technology.24 As a result, the market
became segmented in the U.S., with different companies each lobbying for their proprietary
standards. Adoption of cellular technology was slower in the U.S. as a result.25
More generally, the diffusion of mobile phones based on the two dominant standards (GSM and
CDMA) is one of the most astounding cases of the expansion of the algorithmic frontier. In 2000
there were fewer than 740 million mobile phone subscriptions, or roughly 16 per 100
inhabitants;26 by 2012 there were more than 6.3 billion subscriptions (101 per 100 inhabitants).
The rapid diffusion was facilitated by the adoption of technical standards that enable

20

Levinson (2008).

21

Vanderbilt (2012); Raballand and Aldaz-Carroll (2007),

22

Levinson (2008); Vanderbilt (2012)

23

Murphy & Yates (2009), p. 50. One result of the decline in transportation costs has been the rise of just-

in-time manufacturing practices that have been the drivers of modern growth for firms like Honda, Toyota,
and Walmart (Levinson 2008).
24

Guasch et al. (2007).

25

Over time this has been important, but because mobile standards are updated almost every ten years, the

lock-in effect from settling on a potentially inferior standard is reduced; the U.S. appears to have become
slightly more innovative recently (Dodd, 2012).
26

Data from ITU (2013). Retrieved from

http://www.itu.int/en/ITU-D/Statistics/Documents/statistics/2013/Mobile_cellular_2000-2012.xls.

17

communications to occur over a common network. Once the technology was standardized, it was
comparatively easy for firms like Vodafone to move into untested markets.
Instead of building extensive landline networks, developing countries built mobile towers and
“leap-frogged” the older technology. The fastest growing mobile markets between 2002 and
2008 were in Africa, India, and China.27 This is even true when we look at hostile, conflictridden environments such as Afghanistan and Pakistan.28 In Afghanistan, the number of
subscriptions rose from under 30,000 in 2000 to more than 18 million in 2012. The case of
Pakistan is even more remarkable: in 2000 the number of mobile subscriptions was 360,000; it
rose to more than 120 million by 2012.
The standards underlying GSM and CDMA encompass one layer in what engineers refer to as
the internet protocol stack. The five layers of the TCP/IP protocol stack are: applications,
transport, Internet, link (or routing), and physical.29 The modular design of the protocol stack
allows engineers to design standards for one stack independent of the others. Thus, at the
application level, for instance, the W3C can focus on web design and applications standards like
HTML and CSS. This allows for an efficient division of labor in standard creation and allows
firms within standard setting organizations to develop expertise at a given layer.30
In many areas of government regulation, but particularly in environmental regulation where
standards are binding, firms operating in multiple jurisdictions may face different regulations. In
order to comply, firms will often choose to adhere to the most stringent, an effect colloquially
referred to as “so goes California.” The phenomenon applies to many areas beyond
environmental standards and regulations.
For the past thirty years, as global ties have deepened, firms have found that dealing with the
financial and accounting rules in different jurisdictions can be a regulatory hurdle that

27
28
29

Kalba, (2008); Sauter & Watson (2008), p. 20)
Auerswald (2012).
The Internet Engineering Task Force (IETF) defines the standard in RFC 1122, Host Requirements, and

defines four layers. Authors frequently refer to the Link and Physical layers separately, although in RFC
1122 they are considered one layer.
30

Simcoe (2013)

18

advantages large firms with extensive financial and accounting departments. Two global efforts
have gradually pushed the international financial system towards a harmonized set of standards.
In the U.S., FASB (the Financial Accounting Standards Board), at the direction of the SEC, has
led the transition from US GAAP accounting standards to the International Financial Reporting
Standards (IFRS). The IFRS began as a system to harmonize financial accounting standards
within the European Union, but as with California’s environmental regulations, the value of
global harmonization was quickly appreciated. Progress has been slow but the efforts are
ongoing and the US is gradually transitioning to the globally recognized standards.
In addition to accounting standards, the Bank for International Settlements has coordinated
efforts to harmonize capital standards in the banking industry. There are currently three sets of
accords, Basel I, Basel 2, and Basel 3. The US and other industrialized countries are in the
implementation phase of Basel 3, while developing countries are typically at earlier stages. Most
low-income countries are making progress at implementing Basel II, especially when large
global financial institutions are present.31
Of comparable significance to these global standards have been within-firm standards that define
and hold together global supply chains. From the sourcing of raw materials to the marketing of
final goods, procurement contracts between buyers and suppliers depend on clear communication
of expectations and specifications, all facilitated by standards.
Types of Standards
Our theoretical understanding of standards is limited and the categories that are most commonly
identified are somewhat arbitrary because standards can blur formal boundaries. Kindleberger
provided one early attempt at understanding the economic role of standards. He identified two
primary purposes: “to reduce transactions costs and to achieve economies of scale through
product interchangeability” (1983, p. 395). David (1987) observed that standards could perform
both functions and that it might be preferable to classify standards based on the economic
problem they solve (e.g. compatibility standards). One common characteristic intrinsic to all
standards is that they codify technological knowledge.32
31

Gottschalk and Griffith-Jones (2010)

32

Blind and Jungmittag (2007).

19

Standards are classified based on their function and also on whether they are formal or informal.
Informal or de facto standards are norms or requirements that may be voluntarily adopted and
that frequently arise as a result of path dependence. Formal, or de jure, standards have the force
of law behind them, either as laws, regulations, or contracts.33 These are flexible categories and
there may be some movement between types over time.
Whether standards have the force of law or simply gain network effects and de facto status, they
are typically classified in one of four categories: reference, compatibility, interchangeability, and
quality standards, with some room for overlap34 (Blind 2004; David and Greenstein 1990;
Guasch et al 2007.)
Reference standards (information or measurement standards) tie the value of one object to a
reference base (NIST/SEMATECH 2012.) A weight measurement serves as a metaphor or simile.
For example, a standardized pound in a scale is used to measure a comparable weight of another
object, such as a bag of oranges (Busch 2011, 10). Standardized weights and measures are a
typical example of these standards (NIST/SEMATECH 2012.) Reference standards can also
serve as coordination mechanisms. Landes (1983) describes the historical importance of
establishing the measurement of time. Today dates and time have been codified by ISO 8601 –
data elements and interchange formats.
Compatibility (interface) standards enable different components of a system to work together
because they are based on common characteristics. The extensive network of railroads is a clear
example because commercial and passenger rail both work on the same tracks.35
Compatibility standards are among the most ubiquitous. According to Farrell and Simcoe (2013),
compatibility standards account for more than 40% of the total stock of American National
33

Rycroft and Kash (1999).

34

There are other classification systems. For example, ISO (2012) defines three categories. “Standards

can be broadly sub-divided into three categories, namely product, process and management system
standards. The first refers to characteristics related to quality and safety for example. Process standards
refer to the conditions under which products and services are to be produced, packaged or refined.
Management system standards assist organizations to manage their operations. They are often used to
help create a framework that then allows the organization to consistently achieve the requirements that are
set out in product and process standards.”
35

Blind (2004); David and Greenstein (1990); Guasch et al. (2007).

20

Standards. Because the infrastructure encompassing ICT is inherently modular, compatibility
standards dominate in this field. Biddle et al (2010) estimate that a modern laptop utilizes at least
251, and perhaps more than 500, unique compatibility standards.
The next two standards, interchangeability and quality, can be thought of as subsets of
compatibility standards. Interchangeability (variety reducing) standards refer to parts that are
interchangeable and for the most part identical. The industrial revolution and the rise of assembly
line processes at the beginning of the 20th century required that tools in engineering be
standardized.36 As a result, standardized components from one manufacturer can be expected to
work just as well as another. This is not limited to engineering but extends to many practical
products, such as paper products.37
Quality (and safety) standards certify to consumers that a product or service was produced in a
specific manner with a consistent minimum allowable quality. The best known standards are the
ISO quality management standards, which are discussed in Section V. Health and safety
standards for toys, food, drugs and electrical appliances fall into this category as well.38
The Creation and Maintenance of Standards
The creation and maintenance of standards is a social activity at least as much as it is technical.
While basic research, invention, and technological innovation can create ever-expanding menus
of technological options, the process of standardization involves inducing a potentially large set
of stakeholders to agree on a single choice. Solving such coordination problems is difficult and
costly. Furthermore, those most knowledgeable about the relative strengths and weaknesses of
various standards options are also often those with the most at stake in deciding which standards
are selected.
The role of standards grew in importance following the American Civil War and the rise of
science based industry during the Second Industrial Revolution. The first standards institutions
arose during this time. Figure 7, also created with Google Ngram, shows the concomitant rise in

36

Brady (1961).

37

Guasch et al. (2007); Blind (2004).

38

Guasch et al. (2007).

21

the use of the words “industry” and “standards.”39 The gradual development of standards
institutions followed three stages in which: (1) standards were localized within the firm or other
administrative unit (2) standards were agreed at the national level by one industry, and (3)
standardization was carried out at an international scale.
[Insert Figure 7 Here]
In practice, because of the benefits of sponsoring a standard, international standard-setting is an
almost unavoidably contentious and difficult process. It usually occurs in one (or a combination
of) four ways.40
First, standards may arise through the decentralized choice of market participants. Second, firms
may find it easier to negotiate, typically through a formal Standard Setting Organization (SSO)
or independent industry consortia. Third, a dominant market leader may set a standard, which
smaller firms may follow. Finally, a standard may be set ex post through converters or multihoming.41
It is important to note that the convergence of international standards and global supply chain
footprints has offered opportunities to both small and large players. Within these opportunities
lie leverage points for systemic change. Increased efficiencies in the operation of global supply
chains have enabled Walmart to grow over the past 50 years to become the world’s largest
private employer.42 Yet the same shared global infrastructure famously has allowed the flatscreen TV manufacturer Vizio to develop the best logistics partnerships in its industry—from

39

One important trend to notice is that standards have continued to grow in importance even though

industry trails off starting in the 1980s.
40

This section draws on Farrell and Simcoe (2013).

41

Converters allow different platforms to work together. Mutli-homing refers to the process of making a

product, such as a video game, available on two different platforms, like the Sony PlayStation or
Microsoft Xbox.
42

If WalMart was a country it would be China’s eighth-biggest trading partner, ahead of all but the largest

economies. See http://www.edf.org/page.cfm?tagID=2101.

22

manufacturers in China to distribution through Costco—despite employing a minimal core
staff.43
Standards and Interoperability
Global enterprise requires interoperability. This interoperability is being developed in a
cumulative manner, piece by piece, and new standards are required at every stage.44
Standards have become increasingly important in the era of the algorithmic frontier because they
enable the interoperability of firm-level recipes. The existence of standards turns a firm-level
recipe into a subroutine of a larger program comprising many different recipes. That larger
program enumerates the full instructions for the operation of a supply chain. As Paul Agnew, an
early proponent of international standards, pointed out, compatibility standards resolve the
difficulties that arise “at the transition points—points at which the product passes from
department to department within a company, or is sold by one company to another or to an
individual” (Agnew, quoted in Murphy & Yates, 2009, p. 7). Without standards, the
interdependencies between the firm-level recipes comprising a supply chain would grow at a
greater rate than the length of the chain, and the operation of the supply chain would be
unmanageable.
Note that standardization to enable the interoperability of recipes as subroutines is different from
the standardization of firm-level recipes themselves. In the food service industry, standardized
recipes and production processes have famously been the success of franchise-based firms like
McDonalds and KFC. Such firms have contributed to advancing the algorithmic frontier, but the
particularly strict form of encoding that the franchise model represents is not the focus of this
chapter.
Along similar lines, we can argue that the domain of analysis relating to “General Purpose
Technologies” (GPTs) is really about the nesting of production recipes. Following from
Schumpeter’s observation that “[t]o produce means to combine the things and forces within our
reach,” we can readily observe that technologies themselves are frequently combined into other
43

See http://hbswk.hbs.edu/pdf/item/6424.pdf. The apparel manufacturer Li & Fung is among companies

that have pursued a similar strategy (Hagel and Brown 2005).
44

Baldwin and Clark (2000).

23

technologies, as sub-components. Such technologies-acting-as-subcomponents themselves
encode production recipes.45 The recombination of technologies is thus, implicitly, the
recombination of subroutines within a recipe. GPTs are technologies that operate at lower—more
fundamental—levels of such an algorithmic hierarchy (a.k.a. supply chain).46
In the next section we continue this line of argument by proposing that the recent phenomenon
referred to as “globalization” is actually better understood as the progression of the algorithmic
frontier, enabled by standards that in turn facilitate interoperability—both among and within
supply chains.
IV. Globalization Is Really Standardization
The recent wave of global integration termed “globalization” tends to be described in terms of
the international integration of commodity, capital, and labor markets (Bordo et al. 2003). If this
is what we mean by the term, however, then it is clear that our current period is not the first
example of globalization. There have been two major periods of globalization (Baldwin &
Martin 1999) since the mid-nineteenth century. The first began in the mid-nineteenth century and
ended with the onset of World War I. After an interlude between the wars that included the Great
Depression, the second era of globalization began during the reconstruction after World War II.
Growth in trade accelerated following the end of WWII, but in the past century we have seen

45

The automated teller machine (ATM) or the rice cooker are two examples of physical technologies

(hardware) encoding specific subroutines of a production recipe—in the first case, as executed by a teller
sitting at a window in a physical bank, and in the second case as executed by a cook in a kitchen. In the
case of ATMs, the process has iterated forward again in the past 3-4 years as significant elements of the
functioning of the ATMs (software/hardware) have been encoded as “apps” on mobile phones, making
them subroutines of the functioning of another technology (the phone).
46

With regard to General Purpose Technologies the seminal reference is Bresnahan and Trajtenberg

(1995). Doyne Farmer and James McNerney have sought recently to formalize the idea that a supply
chain constitutes an instance of a production ecology, and further that the hierarchies of nested
subroutines that, in the aggregate, comprise the production algorithm for the supply chain are equivalent
to “trophic levels” in such an ecology. The lower the trophic level of a given technology (which is to say,
of the subroutine the technology encodes) the more “general purpose” the technology.

24

trade flows of comparable magnitude to our current experience.47 This type of global integration
has actually been occurring for at least one thousand years, although the flow of information has
not always been from the West to the East (Sen, 2002).48
What makes the current era unique and different from prior eras of globalization? Alternatively,
what has been the driver of the shift from the scientific frontier to the algorithmic? The primary
difference between the algorithmic frontier and the earlier era of the scientific frontier is the rise
of distributed networks of production and innovation (Auerswald & Branscomb, 2008). In this
view, globalization is really a process of interdependence and interconnectedness (Acs & Preston
1997). The real driver expanding the algorithmic frontier is the increasing reach of collaborative
networks of all kinds—particularly production, but also research.49 As Branstetter, Li, and
Veloso write in this volume, “The important role of multi-national corporations in the
international invention explosions in China and India may help to explain why they are occurring
at an early stage of economic development.” The production networks themselves are the direct
result of standardization. For that reason, we argue that globalization is really standardization.
Shared standards and business practices have been a precondition to this process of economic
integration. In contrast with the traditional multinational assembly of subsidiaries, the global
enterprise is a flexible assembly of firms around the world, with skills and capacity that can be
drawn upon for the most efficient combination of business processes. The rapid globalization and
economic integration witnessed in recent years has, in this manner, created the need for
standardization of management systems, which are essentially the interface layer between
production subroutines. As then-CEO of IBM Palmisano wrote in 2006:
[S]tarting in the early 1970s, the revolution in information technology (it) improved the
quality and cut the cost of global communications and business operations by several
47

Foreign direct investment as a share of GDP, starting with the third wave of democracy in 1974,

accelerated from 5.2% between 1950 and 1973 to 25.3% from 1974 to 2007 (WTO, 2008, p. 15).
48

Sen (2002) cites as examples the transfer of knowledge of mathematics (decimal system) from India to

the West, and of paper, gunpowder, and the printing press from China to Western Europe, among other
technologies.
49

The resulting diversity of production levels is thus a result of the degree of incumbency and

competition in an industry (Auerswald, 2012).

25

orders of magnitude. Most important, it standardized technologies and business
operations all over the world, interlinking and facilitating work both within and among
companies. This combination of shared technologies and shared business standards, all
built on top of a global IT and communications infrastructure, changed the sorts of
globalization that companies found possible.50
With diverse productivity levels among firms, companies in “ascending markets” within the
developing world have faced significant signaling challenges in the global marketplace. In
addition, they must manage information and compliance costs and adopt a common language of
exchange. The result has been a remarkable increase in certain standards, or norms, issued by
international organizations. We discuss this trend in the next section.
V. Using Quality Management Standards to Map the Movement of the Algorithmic
Frontier
Despite the importance of standards, empirical research on standardization has made only limited
progress since the late 1990s.51 The adoption of technical standards has proved difficult to

50

Palmisano (2006, p. 130). The transformation of IBM, which embodied the large-scale research-based

firm of the scientific era, epitomizes the structural evolution that has taken place on a global scale. Once
the epitome of the industrial giant with an international reach driven by science-based innovation—at its
peak in the 1960s-1970s, IBM was investing half of its net income on developing new products and spent
more money on computing research than the federal government (Acs, 2013, p. 72)—IBM is today best
“understood as global rather than multinational” (Palmisano 2006, p. 127). The change involves sourcing
production from a variety of firms in different countries, and marketing the resulting products globally as
well. Palmisano describes the integration of China and India into the global economy as the “most visible
signs of this change.” Between 2002 and 2003, he writes, foreign firms built sixty thousand
manufacturing plants in China, many of them targeting global markets. Similar ties with firms in India are
expanding the base from which global products and services are created.
51

Among the few firm-level studies of the decision to seek certification from global standards bodies are

Chen et al. (2008) and Guasch et al. (2007).

26

measure. Data limitations and the potential for simultaneity to create endogeneity bias have
plagued the empirical study of the effects of adopting ISO standards.52
Standards are well-known to be associated with both costs and benefits from a social welfare
standpoint. On the side of social costs, standards may serve as impediments to technical
advancement or function as a non-tariff barriers to trade.53 On the social benefit side, the
literature suggests at least three potential categories of positive impact. First, the existence of
internationally recognized process standards may lower barriers of entry into production and
distribution networks on a global scale, thereby enabling trade and making it more inclusive.
Second, achieving functional compatibility and interoperability according to global norms may
facilitates the adoption of platform technologies. Third, the process of obtaining and maintaining
standards-certification may serve as an important learning tool and lead to increased productivity
through standardized routines; such learning expands the set of capabilities present in the
economy, expanding the set of pathways for growth in the manner described by Hidalgo and
Hausmann (2009) and Hausmann et al. (2011).
One source of data to help map the movement of the algorithmic frontier on process
certifications is the International Organization for Standardization. Formed by the United States
along with the other leading powers in 1947—just two years after Vannevar Bush published
Science the Endless Frontier—the International Organization for Standardization (abbreviated as
“ISO” for reasons explained in footnote)54 was designed to complement the functions of existing
national standards bodies55 by providing a wider forum for the agreement, adoption, and
dissemination of standards.
52

Clougherty and Grajek (2012).

53

World Trade Organization (2005).

54

According to the ISO, “because ‘International Organization for Standardization’ would have different

acronyms in different languages (‘IOS’ in English, ‘OIN’ in French for Organisation internationale de
normalisation), its founders decided to give it an all-purpose shortened name. They chose ‘ISO,’ derived
from the Greek isos, meaning ‘equal.’ Whatever the country, whatever the language, the short form of the
organization’s name is always ISO.” From http://www.iso.org/iso/about/discover-iso_isos-name.htm.
55

Notably, the American National Standards Institute in the United States and the British Standards

Institute in the United Kingdom.

27

Today the two most common ISO management standards are the ISO 9000 and 14000 series,
which have been supplemented in recent years by standards for information security
management, food security, and, most recently, social responsibility (ISO 26000), among
others.56
ISO 9000 addresses “quality management,” which covers what an organization does to fulfill
quality and regulatory requirements, enhance customer satisfaction, and achieve continual
performance improvement.57 ISO 9000 consists of internationally accepted principles and
requirements for managing an enterprise so as to earn the confidence of customers and markets.58
Among the ISO standards the ISO 9000 series of quality management standards are the most
general standards, and thus particularly interesting from our standpoint as they most plausibly
relate to the management of integration with other subroutines within a global supply chain.
The adoption of ISO 9000 series of standards has occurred on a massive, global scale. The ISO
9000 series quality-management standards are diffused across more than 170 countries, but
certification remains concentrated. Table 2 presents the top ten countries by certified firms,
which account for more than two-thirds of the total certifications in 2011. There are two notable
trends in these data. First, the new frontier in quality processes, or process design algorithms, has
expanded globally through distributed networks of production. The fast growing BRICs
constitute more than a third of total certifications, and three countries are in the top ten: Brazil
(#9), China (#1), and India (#7). Russia (#14) and South Africa (#39), which is increasingly

56

Appendix I provides a summary description of the ISO quality-management standards.

57

The immediate predecessor to ISO 9000 was BS 5750, a quality-management standard in Great Britain.

Since its inception, ISO 9000 quality-management standards have transitioned beyond manufacturing and
have become widespread across industries, including the service sector, as can be seen in Table 3. Despite
the widespread adoption of these standards across industries, the existing literature has been concerned
with the trade effects from the adoption of these standards in agriculture (Swann, 2009).
58

Furusten (2002)

28

identified with these emerging markets, also rank quite highly. South Korea, the most rapidly
growing country in the world during past half century,59 rounds out the top ten.
The change in the composition of the top ten countries between 1993, the first year for which
data is available, and 2011 is striking. In 1993 the top ten countries were, in order, the United
Kingdom, Australia, the United States, France, Germany, the Netherlands, South Africa, Ireland,
Italy, and Denmark; South Africa was the only non-developed country included and one of only
a few outside Western Europe. The wide acceptance and adoption of the ISO series has expanded
the algorithmic frontier and enhanced the capabilities and opportunities for firms in the
developing world.
[Insert Tables 2 and 3 here]
The distributed nature of production networks is clear from these data. More than one-quarter of
firms with foreign ownership (the majority-owned foreign affiliates of parent companies) are
ISO certified.60 However, the ISO story is not limited to the case of the parent companies of
multinationals in developed countries imposing quality standards on their foreign subsidiaries.
Interestingly, the top-certified developing countries, or ascending markets, did not dominate
firms by country in 2011. Instead, industrialized firms in Japan, Western Europe, and the United
States (#11) also found benefits from adopting management standards, such as the ISO 9000
series. Firms seeking ISO certification in the developed world include those at the technological
frontier, such as General Electric (in energy, health care, and related services) and Netgear (ICT),
which proudly proclaim their ISO certifications on their websites. Even in cases where product
quality is undisputed, managers find the process of codifying the production process to be a

59

We omit Equatorial Guinea, which experienced the greatest rate of growth in per capita income of any

country in the world in the fifty years after 1960, but without any appreciable advance in economic
development measured along other dimensions.
60

Authors’ calculations from World Bank Enterprise Survey (enterprisesurveys.org); majority-owned

foreign affiliates are defined as businesses in which an investor of another country holds at least 10%
voting ownership (BEA, 2013).

29

useful activity.61 This survey evidence may imply that management standards are an important
link in global supply chains but that they are not simply a procurement standard.
Figure 8 graphs the adoption rates of a broader range of ISO quality-management standards. The
data follow a similar pattern, with initial adoption in Western Europe followed by gradual
adoption outside the region. This process appears to have accelerated following the successful
implementation of the ISO 9000 set of standards.
[Insert Figure 8 here]
While the potential benefits of adopting ISO standards have been studied extensively, the
literature has produced few clear results. Pathways of benefits vary among studies as well. ISO
adoption is alternately conjectured to function as a signal of competitiveness; to be associated
with productivity enhancements and firm learning; or to lead to enhanced compatibility via a
common-language effect.
If there is a consensus in the literature on ISO adoption, it is that the benefit of certification to the
certified firm is at least as much in the widening of market opportunities as it is in the
achievement of process-quality improvements.62 A model developed by Terlaak and King (2006)
suggests that certification with a management-quality standard may reduce information
asymmetries in supply chains and bestow a competitive advantage on certified firms. The pursuit
of certification may also, on its own, communicate desirable but otherwise unobserved
organizational attributes.63

61

Corbett & Luca (2002).

Terlaak and King (2006), however, argue that there must be other tangible financial incentives to justify
the outlay of substantial organizational resources to obtain certification, so that the decoupling of the
certification effect and the quality effect is not sustainable in a longer-run equilibrium.
62

Breka (1994); Litsikas (1997); Rao et al. (1997).

63

Terlaak and King (2006) find that tangible financial incentives justify the outlay of substantial

organizational resources to obtain ISO certification The authors examined the effects of ISO 9000
certification on the competitive advantage of U.S. manufacturing firms. Using a panel of firms, they
found that firms grew faster after ISO certification, ceteris paribus. Importantly, firms’ growth effect was
greater in situations where buyers faced greater difficulties in acquiring information about suppliers.

30

While the ISO certification process nominally requires companies to undergo restructuring of
their organization and operational processes, a question remains as to whether certification
results in actual improvements in firm-level capabilities. Some past studies suggest that
achieving ISO certification induces organizations to adopt practices that improve operational
performance.64 Corbett and Luca (2002) and others have found the process of obtaining ISO
certification increases functional compatibility and interoperability according to global norms,
thus easing adoption of platform technologies. To be sure, if ISO certification conveys no
information at all about quality or capabilities (in expectation), then buyers in the supply chain
should tend to ignore it and suppliers should, as a consequence, ultimately cease to seek it. In this
sense, we would conjecture that a full decoupling of the certification effect and the quality effect
(including revealed quality) is not sustainable in a longer-run equilibrium.
Whether financial benefits clearly accompany certification is another unresolved empirical
question. In addition to prior empirical and theoretical work, some evidence is available from
survey data. Corbett and Luca (2002) surveyed business executives in 15 countries in the Winter
of 2001, receiving just under 3,000 responses. The responses indicated that ISO 9000
certification was considered “important” to the firms continued success, the most favorable
survey choice.65 In a study of the impact of ISO quality management standards in Asia, survey
data from UNIDO revealed that 36.1% of respondents cited “internal improvement” as their
primary reason for choosing to implement a quality management system (UNIDO 2012). This
was the most common reason cited, followed by “customer pressure” (26.1%) and “corporate or
top management objective” (18.5%). With regard to the link to certification and performance, the
purchasers surveyed in this report responded that ISO 9000 certified firms performed “better” or
“much better” than non-certified suppliers. The World Bank Enterprise Surveys data show a

64

Litsikas (1997); Rao et al. (1997).

65

The authors report that “the average score for ISO 9000 certification across all industries was 3.95

(where 3 corresponds to ‘somewhat important’ and 4 to ‘important’).” (Corbett and Luca, 2002: p. 10)
The responses for ISO 14000 certification were not as robust and varied between “somewhat important”
to “important” for the firms continued success. Demand for ISO 14000 certification typically originated
in a firms marketing department rather than a quality control office or from top management, as was the
case with ISO 9000.

31

strong positive correlation between ISO certification and exporting activity. 66 Eighty-eight
percent of the time (significant at .01 level), regions with higher proportions of firms with
standards certification also recorded greater exporting activity.67 Further, as shown by Prakash
and Potoski (2007), the certification intensity of trading partners has a strong influence on
adoption patterns.
Regardless of the direction of the specific causality running between trade and ISO certification,
there is ample reason to believe that process standards such as ISO and technical standards such
as GSM and TCP/IP (discussed above) have, together, had a dramatic impact on the global
economy during its past thirty years of unprecedented growth.
The promise of the next standards to drive change on a global scale lies outside the bounds of
reasonable conjecture. But while the nature of standards in the next—and most substantial—
phase of the centuries-old process of global economic inclusion is uncertain, the continued
centrality of standards is not. A core challenge of global development in the 21st century is thus
the creation and maintenance of standards that accelerate, rather than impede, innovation at the
same time they expand, rather than contract, economic inclusion on a global scale.
In the next section we consider a dimension of the advance of the algorithmic frontier of
particular significance not only to the past development of the global economy but also to its
future: the impact of the advance of the algorithmic frontier on the discovery of new ideas.
VI. Algorithms and the Process of Discovery
So far in this chapter we have


considered the development of the economy of the United States as the frontier has
shifted from agricultural, to industrial, to scientific, and finally to algorithmic;



proposed a theoretical unit of analysis in the study of the algorithmic economy, which we
term the “production recipe”; and

66

Prakash & Potoski (2007).

67

Authors’ pairwise correlation analysis of data from the World Bank Enterprise Surveys, available at

http://www.enterprisesurveys.org.

32



noted the importance of standards in enabling the interoperability of production recipes,
with particular attention to how such interoperability has facilitated international trade
and accelerated global growth.

What we have not yet done is consider sources of novelty in the algorithmic economy, and how
they may be different from those that have driven economic advance in the past. That is the goal
of this last section in the chapter.
Following directly from the previous section we certainly can observe that, just as improvements
in information and communications technologies associated with the advance of the algorithmic
frontier have enabled the decentralization of processes to produce things, so have they led to a
decentralization of processes to produce ideas. From the 1940s to the 1980s, when economic
advance was bounded by the scientific frontier, a handful of corporate research labs—Bell
Telephone Laboratories (“Bell Labs”), RCA Laboratories, the IBM T.J. Watson Research Center,
and the Xerox Palo Alto Research Center (PARC), being the leaders—produced an astoundingly
disproportionate share of the world’s scientific discoveries and technological advances.68
The “golden age” of the large-scale corporate research laboratory supported by monopoly rents
came to an end in the 1980s, due to a combination of factors including deregulation, the
emergence of the conglomerate discount, and changes in the technology of discovery. In its place
has emerged a less concentrated system of “divided technical leadership” (Ozcan and Greenstein
2013) involving a global network of smaller-scale corporate laboratories, government
laboratories, academic institutions, and start-up ventures. The primary role of large corporations
in this system is not to generate new innovations themselves, but rather to produce and market
such innovations at mass scale.69

68

For example, William Shockley and colleagues at Bell Labs developed the silicon transistor, and then

went on to understand the underlying science of their innovation, a process that earned them the Nobel
Prize in Physics in 1956. For more on Bell Labs see Gertner (2012); regarding the “golden age” of
corporate research labs, see Auerswald and Branscomb (2005).
69

Auerswald and Branscomb (2005).

33

The decentralization of the production of ideas enabled by the advance of the algorithmic frontier
is one dimension of change in the process of discovery. A second—and more fundamental—one
relates to methodologies of discovery themselves.
Among biologists the notion that life is fundamentally algorithmic earned a central place in
theory decades ago. Most of the great discoveries in biological sciences in the 20th century—the
discovery of the double-helix, most notably among them—were inspired by the work of pioneers
of information theory notably including Norbert Weiner and Claude Shannon. As Sydney
Brenner, the 2002 Nobel Laureate in medicine, said in 1971: “I feel that this new molecular
biology has to go in this direction—to explore the high-level logical computers, the programs,
the algorithms of development…” The result of biologists’ shift to focusing on “the algorithms
of development” has been a revolution in the life sciences that continues to unfold today, with
dramatic effects.
Advances in understanding about the nature of biological systems have translated directly into
advances in actual technologies of discovery in the life sciences. Techniques such as
combinatorial chemistry and high-throughput screening are today encoded in “lab-on-a-chip”
technologies,70 turning Schumpeter’s vision of the search for economically valuable “new
combinations” into algorithmically-driven pieces of hardware capable of doing the work of
dozens, if not hundreds, of post-docs using the methods of two decades ago.
In contrast, the advance of discovery in economics was, from the 1950s to the 1980s, firmly
rooted in the logical positivist project of deriving theories from axiomatic foundations, then
subjecting them to empirical test using econometric methods. The development and increasing
influence within economics of lab experiments, field experiments, and even applications of
neuro-science in the 1990s to the present has greatly increased the methodological diversity of
the discipline.
Until recently, however, the social sciences (economics in particular) have remained separated
from the life sciences and the physical sciences by orders-of-magnitude differences in both the
availability and the reliability of data. The relatively poor quality of data available to social
scientists and the perceived impracticability of conducting controlled economic experiments at
70

A pioneer in this work is Caliper Technologies, founded by Larry Bock and Michael Knapp in 1995.

34

large scale has necessitated the development by economists of methods of causal inference far
more elaborate than those employed in other sciences. However—as is well-known and widely
discussed as the advent of “Big Data”—data on people’s behavior in social contexts is increasing
in quantity and improving in quality at an astounding rate. As a consequence, there is ample
reason to believe that continued advances in the algorithmic frontier over the next two decades
will transform the process of discovery in economics and other social sciences just as they have
been doing for the past two decades in the life sciences.
VII. Conclusion
Vannevar Bush is best known as the author of Science the Endless Frontier, which provides the
inspiration for this volume; for his work during World War II as director of the U.S. Office of
Scientific Research and Development; and for his part in the development of analogue computers.
However, one of Bush’s most powerful and enduring contributions may have been that which he
made via a July 1945, Life magazine article titled, “As We May Think,” which was published
just weeks before VJ Day. As he looked ahead to the frontier of societal advance in the postwar
era, his emphasis was not on the products of publicly funded science but on the capacities of
privately produced tools: “The world has arrived at an age of cheap complex devices of great
reliability; and something is bound to come of it.” In that essay, he envisions how existing lowcost technologies might be further advanced and networked into a system for the storage and
retrieval of ideas, which he called the “memex”: “Wholly new forms of encyclopedias will
appear, ready made with a mesh of associative trails running through them, ready to be dropped
into the memex and there amplified.” The existence of this tool would allow for a continuation of
the forward progress of human inquiry: “[Man] has built a civilization so complex that he needs
to mechanize his records more fully if he is to push his experiment to its logical conclusion and
not merely become bogged down part way there by overtaxing his limited memory.”
Among those who read this essay in Life magazine was a 25-year-old aerospace engineer named
Douglas Engelbart. Engelbart was so taken by the vision set forth in “As We May Think” that he
redirected his career to making that vision a reality. In 1968, at the fall Joint Computer
Conference (a semiannual meeting of the then-major computing societies held in San Francisco),
Engelbart delivered to over a thousand participants a presentation that set forth for the first time

35

the core elements of the user architecture that would define the information revolution in decades
to come: the computer mouse, text editing, hypertext, windowing, and video conferencing.
This story of serendipitous inspiration and invention illustrates the fundamental link between the
science-based frontier and the algorithmic frontier, as well as the differences between the two.
Although Vannevar Bush conceived and led the most ambitious and large-scale R&D programs
ever undertaken at that time (notably including the Manhattan Project), he was able to look ahead
to an era where the greatest progress in science-based discovery would be enabled by lowering
the cost of storing and sharing ideas horizontally among scientists. Douglas Engelbart further
democratized that vision, prototyping an architecture of interaction through standardized
interfaces that we have come to know simply as information and communications technology.
This anecdote also suggests that the legacy of Vannevar Bush is arguably not about the
importance of science-based research per se, any more than it is about the creation of the
National Science Foundation and the decades of discovery it has enabled. Rather, it is about the
importance of understanding that, at any point in time, the frontier of social attainment is
changing. When Bush led the committee that produced Science the Endless Frontier in 1945, the
changing frontier consisted of the transition of an economy based on industrial growth through
economies of scale to one based on improved goods and services through science-based
innovation. Today, as we have sought to describe above, the frontier is changing again.
Just as the advent of science-based innovation motivated an earlier generation of economists to
create new theoretical frameworks and analytic techniques to understand the rate and direction of
technical change, so the advance of the algorithmic frontier is challenging the current generation
of economists to respond in a like manner. The existence of this volume and the work it contains
provide some evidence of the will that exists to meet that challenge.

36

APPENDIX 1: ISO Management Standards
(Source: ISO 2011)

ISO 9001:2008
ISO 9001:2008 gives the requirements for quality management systems. Certification to the
standard is used in global supply chains to provide assurance about suppliers’ ability to satisfy
quality requirements and to enhance customer satisfaction in supplier-customer relationships.
Up to the end of December 2011, at least 1,111,698 certificates had been issued in 180 countries
and economies, two more than in the previous year. The 2011 total represents a decrease of 1%
(-6,812) over 2010.
The top three countries for the total number of certificates issued were China, Italy, and Japan,
while the top three for growth in the number of certificates in 2011 were Italy, China, and
Romania.
ISO 14001:2004
ISO 14001:2004, which gives the requirements for environmental management systems, retains
its global relevance for organizations wishing to operate in an environmentally sustainable
manner.
Up to the end of December 2011, at least 267,457 ISO 14001:2004 certificates had been issued, a
growth of 6% (+15,909), in 158 countries, two more than in the previous year.
The top three countries for the total number of certificates were China, Japan, and Italy, while
the top three for growth in the number of certificates in 2011 were China, Italy, and France.
ISO/TS 16949:2009
ISO/TS 16949:2009 gives the requirements for the application of ISO 9001:2008 by suppliers in
the automotive sector. Up to the end of December 2011, at least 47,512 ISO/TS 16949:2009
certificates, a growth of 8% (+3,566), had been issued in 86 countries and economies, two more
than in the previous year.
The top three countries for the total number of certificates were China, the Republic of Korea,
and the U.S., while the top three for growth in the number of certificates in 2011 were China,
India, and the Republic of Korea.

37

ISO 13485:2003
ISO 13485:2003 gives quality-management requirements for the medical device sector for
regulatory purposes. Up to the end of December 2011, at least 20,034 ISO 13485:2003
certificates, growth of 6% (+1,200) had been issued in 95 countries and economies, two more
than in the previous year.
The top three countries for the total number of certificates were the U.S., Germany, and the
United Kingdom, while the top three for growth in the number of certificates in 2011 were the
U.S., Israel, and Japan.
ISO/IEC 27001:2005
ISO/IEC 27001:2005 gives the requirements for information security-management systems. At
the end of December 2011, at least 17,509 ISO/IEC 27001:2005 certificates, a growth of 12%
(1,883) had been issued in one hundred countries and economies, eight less than in the previous
year.
The top three countries for the total number of certificates were Japan, India, and the United
Kingdom, while the top three for growth in the number of certificates in 2011 were Japan,
Romania, and China.
ISO 22000:2005
ISO 22000:2005 gives the requirements for food-safety management systems. Up to the end of
December 2011, at least 19,980 ISO 22000:2005 certificates, a growth of 8% (1,400) had been
issued in 140 countries and economies, two more than in the previous year.
The top three countries for the total number of certificates were China, Greece, and Romania,
while the top three for growth in the number of certificates in 2011 were China, Italy, and
Romania.
ISO 50001:2011
ISO 50001:2011 gives the requirements for energy management systems. It was published in
mid-June 2011. Up to the end of December 2011, at least 461 ISO 50001:2011 certificates had

38

been issued in 32 countries and economies. The top three countries for the total number of
certificates were Spain, Romania, and Sweden.

39

References
Acs, Z.J. (2013). Why philanthropy matters: How the wealthy give, and what it means for our
economic well-being. Princeton, NJ: Princeton University Press.
Acs, Z.J., & Preston, L. (1997). Small and medium-sized enterprises, technology, and
globalization: Introduction to a special issue on small and medium-sized enterprises in the
global economy. Small Business Economics, 9(1), 1-6.
Aghion, P. and P. Howitt (1992). A model of growth through creative destruction, Econometrica,
60(2), 323–351.
Akerlof, G. A. (1970). The Market for “Lemons”: Quality Uncertainty and the Market
Mechanism. The Quarterly Journal of Economics, 84(3), 488–500.
Arrow, K. J. (1962). The economic implications of learning by doing. The review of economic
studies, 29(3), 155–173.
Arthur, W. B. (2009). The nature of technology: What it is and how it evolves. New York: Free
Press.
Arthur, W. B. (2011). The second economy. McKinsey Quarterly (4).
Auerswald, P. (2008). Entrepreneurship in the theory of the firm. Small Business Economics, 30,
111-126.
Auerswald, P. (2010). Entry and Schumpeterian profits: How technological complexity affects
industry evolution. Journal of Evolutionary Economics, 20, 553-582.
Auerswald, P. (2012). The coming prosperity: How entrepreneurs are transforming the global
economy. New York: Oxford University Press.
Auerswald, P., & Branscomb, L.M. (2005). Edwin Mansfield, technological complexity, and the
‘golden age’ of U.S. corporate R&D. Journal of Technology Transfer, 30(1/2), 139-157.
Auerswald, P., & Branscomb, L.M. (2008). Research and innovation in a networked world.
Technology in Society, 30(3-4), 339-347.
Auerswald, P., Kauffman, S., Lobo, J., & Shell, K. (2000). The production recipes approach to
modeling technological innovation: An application to learning by doing. Journal of Economic
Dynamics and Control, 24, 389-450.
Baldwin C. and Clark, K. (2000). Design rules: Volume 1. Cambridge, MA: MIT Press.

40

Baldwin, R.E., & Martin, P. (1999). Two waves of globalisation: superficial similarities,
fundamental differences (working paper no. 6904). Cambridge, MA: National Bureau of
Economic Research. Retrieved from http://www.nber.org/papers/w6904
Biddle, B., White, A., & Woods, S. (2010). How many standards in a laptop? (And Other
Empirical Questions) (SSRN Scholarly Paper No. ID 1619440). Rochester, NY: Social
Science Research Network. Retrieved from http://papers.ssrn.com/abstract=1619440
Blind, K. (2004). The Economics Of Standards: Theory, Evidence, Policy. Edward Elgar
Publishing.
Blind, K., & Jungmittag, A. (2008). The impact of patents and standards on macroeconomic
growth: a panel approach covering four countries and 12 sectors. Journal of Productivity
Analysis, 29(1), 51–60.
Bloom, N., & Van Reenen, J. (2010). Why do management practices differ across firms and
countries? [Monograph]. Retrieved July 14, 2013, from http://cep.lse.ac.uk/
Bordo, M.D., Taylor, A.M., & Williamson, J.G. (2003). Introduction. In M. D. Bordo, A. M.
Taylor, & J.G. Williamson Eds.), Globalization in historical perspective (pp. 1-10). Chicago:
University of Chicago Press.
Brady, R. A. (2011). Organization, Automation, And Society: The Scientific Revolution In
Industry. Literary Licensing, LLC.
Breka, J. (1994, May). Study finds gains with ISO 9000 registration increase over time. Quality
Progress, pp. 18-20.
Bresnahan, T.F., Trajtenberg, M. (1995). ‘General purpose technologies: ‘Engines of
growth’?‘ Journal of Econometrics, 65:1, 83-108.
Bureau of Economic Analysis. (2013, April 18). Summary estimates for multinational
companies: employment, sales, and capital expenditures for 2011. Retrieved from
http://www.bea.gov/newsreleases/international/mnc/2013/_pdf/mnc2011.pdf
Busch, Lawrence. (2011). Standards: Recipes for Reality. The MIT Press.
Bush, V. (1945a). As we may think. The Atlantic. Retrieved from
http://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/
Bush, V. (1945b). Science the endless frontier. Washington, DC: U.S. Government Printing
Office.
41

Chandler, A. D. (1990). Scale and Scope: The Dynamics of Industrial Capitalism. Belknap/
Harvard University Press.
Chandler, A. D.(1992). Organizational capabilities and the economic history of the industrial
enterprise, Journal of Economic Perspectives, 6(3), 79—100.
Chen, M.X., Wilson, J., & Otsuki, T. (2008). Standards and export decisions: Firm-level
evidence from developing countries. The Journal of International Trade & Economic
Development, 17, 501-523.
Clougherty, J.A., & Grajek, M. (2012). International standards and international trade:
Empirical evidence from ISO 9000 diffusion (working paper no. w18132). Cambridge, MA:
National Bureau of Economic Research.
Coase, R.H. (1937). The nature of the firm. Economica, 4, 386-405.
Corbett, C.J., & Luca, A. (2002.) Global survey on ISO 9000 and ISO 14000: Summary of
findings (working paper). Retrieved from
http://personal.anderson.ucla.edu/charles.corbett/papers/iso_survey_report_us.pdf
Corbett, C.J., Montes-Sancho, M.J., & Kirsch, D.A. (2005). The financial impact of ISO 9000
certification in the United States: An empirical analysis. Management Science, 51, 1046-1059.
David, P. A. (1987). Some New Standards for the Economics of Standardization in the
Information Age. In P. S. Dasgupta & P. Stoneman (Eds.), Economic Policy and
Technological Performance (pp. 206–239). Centre for Economic Policy Research.
David, P. A., & Greenstein, S. (1990). The Economics Of Compatibility Standards: An
Introduction To Recent Research 1. Economics of Innovation and New Technology, 1(1-2), 3–
41.
Dodd, A.Z. (2012). The essential guide to telecommunications. Upper Saddle River, NJ: Prentice
Hall.
Farrell, J. and Simcoe, T. (2013). Four Paths to Compatibility. In Peitz, M., Waldfogel, J., &
Oxford handbooks. (2012). The Oxford handbook of the digital economy. New York: Oxford
University Press.
Furusten, S. (2002). The knowledge base of standards. In N. Brunsson & B. Jacobsson (Eds.), A
world of standards. New York: Oxford University Press.

42

Gertner, J. (2012). The idea factory: Bell Labs and the great age of American innovation.
London [etc.]: Penguin Books.
Goldfarb, A., & Yang, B. (2009). Are all Managers created equal? Journal of Marketing
Research (JMR), 46(5), 612–622.
Gottschalk, R., & Griffith-Jones, S. (2010). Basel II implementation in low-income countries  :
challenges and effects on SME development. In The Basel capital accords in developing
countries  : challenges for development finance. - Basingstoke, Hampshire [u.a.]  : Palgrave
Macmillan.
Griliches, Z. (1957). Hybrid corn: An exploration in the economics of technological change.
Econometrica, 25, 501-522.
Guasch, J.L., Racine, J.-L., Sanchez, I., & Diop, M. (2007). Quality systems and standards for a
competitive edge. Washington, DC: World Bank Publications.
Hagel III, J. and J. S. Brown (2005). The only sustainable edge: Why business strategy depends
on productive friction and dynamic specialization. Boston: Harvard Business School Press.
Hausmann, R., Hidalgo, C.A., Bustos, S., Coscia, M., Chung, S., Jimenez, J. et al. (2011). The
atlas of economic complexity: Mapping paths to prosperity. Retrieved from
http://atlas.media.mit.edu/book/
Hidalgo, C. A., Hausmann, R., & Dasgupta, P. S. (2009). The building blocks of economic
complexity. Proceedings of the National Academy of Sciences of the United States of America,
106(26), 10570–10575.
International Organization for Standardization. (2013). The ISO survey of management system
standard certifications, 2011. Retrieved from
http://www.iso.org/iso/iso_survey2011_executive-summary.pdf
International Organization for Standardization. (2004). ISO/TMB policy and principles
statement: Global relevance of ISO technical work and publications. Retrieved from
http://www.iso.org/iso/global_relevance.pdf
Jewkes, J., David, S., & Richard, S. (1969). The sources of invention. New York: W.W. Norton.
Jorgenson, D. W., & Stiroh, K. J. (2000). Raising the speed limit: U.S. economic growth in the
information age. Brookings Papers on Economic Activity, 31(1), 125-236.

43

Kalba, K. (2008). The adoption of mobile phones in emerging markets: Global diffusion and the
rural challenge. International Journal of Communication, 2, 631-661.
Kindleberger, C. P. (1983). Standards as Public, Collective and Private Goods. Kyklos, 36(3),
377.
Knuth, D. (1972). Ancient Babylonian algorithms. Communications of the ACM, 15:7, 671-677
(July).
Kremer, M. (1993). Population Growth and Technological Change: One Million B.C. to 1990.
The Quarterly Journal of Economics, 108(3), 681–716. doi:10.2307/2118405
Landes, D. (1983). Revolution in time clocks and the making of the modern world. Belknap Press.
Lee, J., & Schmidt, A.G. (2010, December). Research and development satellite account update,
estimates for 1959-2007. Survey of Current Business, pp. 16-56.
Levinson, M. (2008). The box: How the shipping container made the world smaller and the
world economy bigger. Princeton, NJ: Princeton University Press.
Litsikas, M. (1997). Companies choose ISO certification for internal benefits. Quality 36, 20 - 26.
Mansfield, E. (1961). Technical change and the rate of imitation. Econometrica, 29, 41-766.
Mansfield, E. (1963). The Speed of Response of Firms to New Techniques. The Quarterly
Journal of Economics, 77(2), 290–311.
Markoff, J. (2013, July 3). Computer visionary who invented the mouse. New York Times.
Retrieved from http://www.nytimes.com/2013/07/04/technology/douglas-c-engelbartinventor-of-the-computer-mouse-dies-at-88.html
Murphy, C., & Yates, J. (2009). The International Organization for Standardization (ISO):
Global governance through voluntary consensus. London; New York: Routledge.
Nelson, R. R., & Winter, S. G. (1982). An evolutionary theory of economic change. Harvard
University Press.
NIST/SEMATECH. 2012. “e-Handbook of Statistical Methods.”
http://www.itl.nist.gov/div898/handbook/index.htm (Accessed August 24, 2012).
Ozcan, Y., & Greenstein, S. (2013). The (de)Concentration of Sources of Inventive Ideas:
Evidence from ICT Equipment. NBER Working Paper.
Palmisano, S.J. (2006, May/June). The globally integrated enterprise. Foreign Affairs.
44

Prakash, A., & Potoski, M. (2007). Investing up: FDI and the cross-country diffusion of ISO
14001 management systems1. International Studies Quarterly, 51, 723-744.
Raballand, G., & Aldaz-Carroll, E. (2007). How do differing standards increase trade costs? The
case of pallets. The World Economy, 30, 685-702.
Rao, S., Ragu, T.S., & Solis, L.E. (1997). Does ISO 9000 have an effect on quality management
practices? An international empirical study. Total Quality Management, 8, 335-346.
Rivkin J. (2000). Imitation of complex strategies. Management Science, 46, 824-844.
Romer, P.M. (1986). Increasing returns and long-run growth. Journal of Political Economy, 94,
1002-1037.
Romer, P.M. (1990). Endogenous technological change. Journal of Political Economy, 98(5),
S71-102.
Romer, P. M. (1996). Why, Indeed, in America? Theory, History, and the Origins of Modern
Economic Growth. The American Economic Review, 86(2), 202–206.
Rycroft, R.W., & Kash, D.E. (1999). The complexity challenge: Technological Innovation for the
21st century. New York: Thomson Learning.
Sauter, R., & Watson, J. (2008). Technology leapfrogging: A review of the evidence (a report for
DFID).
Schumpeter, Joseph A. (1912). Theorie der witschaftlichen Entwicklung. Leipzig: Duncker &
Humblot. Revised English translation (1934) by Redvers Opie, The theory of economic
development. Oxford: Oxford University Press.
Schumpeter, J. (1928). The instability of capitalism. The Economic Journal, 38, 361-386.
Schumpeter, J.A. (2008). Capitalism, socialism, and democracy (3rd ed). New York: Harper
Perennial Modern Classics. Original work published 1942
Sen, A. (2002). How to judge globalism. The American Prospect, 13(1), 2-7.
Simcoe, T.S., Graham, S.J.H., & Feldman, M.P. (2009). Competing on standards?
Entrepreneurship, intellectual property, and platform technologies. Journal of Economics &
Management Strategy, 18, 775-816.
Simcoe, T.S. (forthcoming). Modularity and the Evolution of the Internet. In Greenstein, S.,
Goldfarb, A., & Tucker, C. Economics of Digitization. NBER.

45

Simon, H.A. (1967). Programs as factors of production. California Management Review, 10(2),
15-22.
Shepherd, W.R. (1923). Historical atlas. New York: Henry Holt.
Swann, G.M.P. (2009). International standards and trade: A review of the empirical literature.
Paper presented at the conference, Barriers to Trade: Promoting Good Practice in Support of
Open Markets. Retrieved from http://www.oecd.org/trade/non-tariffmeasures/43685142.pdf
Teece, D. J. (1986). Profiting from technological innovation: Implications for integration,
collaboration, licensing and public policy. Research Policy, 15(6), 285–305.
Terlaak, A., & King, A.A. (2006). The effect of certification with the ISO 9000 quality
management standard: A signaling approach, Journal of Economic Behavior & Organization,
60, 579-602.
Trajtenberg, M., Henderson, R., & Jaffe, A. (1992). Ivory tower versus corporate lab: An
empirical study of basic research and appropriability (working paper no. 4146). Cambridge,
MA: National Bureau of Economic Research. Retrieved from
http://www.nber.org/papers/w4146
Turner, F.J. (1893). The significance of the frontier in American history. Report of the American
Historical Association, 199-227.
UNIDO. (2012). Study into the value of ISO 9001. Retrieved September 25, 2012, from
http://www.iaf.nu/articles/Study_into_the_value_of_ISO_9001_/279
Vanderbilt, T. (2012, August 14). The single most important object in the global economy. Slate.
Retrieved from
http://www.slate.com/articles/business/transport/2012/08/pallets_the_single_most_important_
object_in_the_global_economy_.2.html
Weitzman, M.L. (1970). Soviet postwar economic growth and capital-labor substitution. The
American Economic Review, 60, 676-692.
Weitzman, M. L. (1998). Recombinant growth, Quarterly Journal of Economics, 113(2), 331–
360.
Winter, S.G. (1968). Toward a neo-Schumpeterian theory of the firm. Santa Monica, CA: Rand
Corporation.

46

World Trade Organization. (2005). World Trade Report 2005: Trade Standards and the WTO.
Geneva, Switzerland.
World Trade Organization. (2008). World trade report 2008: Trade in a globalizing world.
Geneva, Switzerland: Author.

47

Tables and Figures
Table 1: R&D and GDP
U.S. average annual real GDP growth rates, unadjusted and R&D adjusted: 1959–2007
(Percent)
Period
Unadjusted real GDPa
R&D-adjusted real GDPb
Difference
1959–2007
3.32
3.39
0.07
1959–73
4.20
4.33
0.13
1974–94
3.02
3.03
0.01
1995–2001
3.76
3.93
0.17
2002–07
2.75
2.87
0.12
Source: Lee & Schmidt (2010); Bureau of Economic Analysis; National Science Foundation Science and
Engineering Indicators, 2012

Table 2: Top 10 Countries for ISO 9001 Certificates, 2011
Rank
1
2
3
4
5
6
7
8
9
10

Country
China
Italy
Japan
Spain
Germany
United Kingdom
India
France
Brazil
Korea, Republic of
Sum
All Others
Total

Number of certificates
328,213
171,947
56,912
53,057
49,450
43,564
29,574
29,215
28,325
27,284
817,631 (73.5%)
294,067 (26.5%)
1,111,698

Source: ISO Survey 2011

Table 3: Top Five Industrial Sectors for ISO 9001 Certificates 2011
1
2
3
4
5

Sector
Services
Basic metal and fabricated metal products
Construction
Electrical and optical equipment
Machinery and equipment

Number of certificates
203,970
101,848
83,864
79,237
58,427

Source: ISO Survey 2011

48

49

Figure 1: Map of Movement of the Western Frontier. I (top left) 1803-1810; II (top right)
1810-1835; III (bottom left) 1835-1855; IV (bottom right) Since 1855.

Source: Shepherd (1923, p. 202)

50

  
  
  2: Ngram,
  
  
  
Figure
“Carriage,
Automobile,
Airplane, and Rocket”
  

  

  

  

  

carriage

  

  

automobile

  

airplane

  

     

rocket

0.004%
0.0032%
0.0024%
0.0016%
0.0008%
0.00%

     
  
  
  
  

  
  
  
  

1740

1760

1780

1800

1820

1840

1860

1880

1900

1920

1940

  
  
  
  
  

  
  
  
  

  
  
  
  

  
  

  

     

  
  
  
  

  
  
  
  

  

  
     

  
     

  
  
  
  

  
  
  
  

  
  

     
     

51

  
  

  
  
  
  

  
  

  
     

  

  

1960

1980

2000

Figure 3: Gartner “Hype Cycle”

Note: For more on hype cycles, see http://www.gartner.com/technology/research/methodologies/hype-cycle.jsp

52

  
  

  
  

  
  

  

  
  

  

  

  

  

  

  

Figure 4: Ngram, “Research, Technology”
research

     

technology

0.025%
0.02%
0.015%
0.01%
0.005%
0.00%

     
     
     

1740

1760

1780

1800

1820

1840

1860

1880

1900

1920

1940

  
     
     

     
     

  
  

  

     

     
     

  

  
     

  
     

     
     

  
  

     
     

53

  
  

  
  

  
     

  

  

1960

1980

2000

Figure 5: Post-WWII System of Science-Based Innovation

54

Figure 6: Production Possibilities Frontier

Source: Auerswald et al., 2000

55

Figure 7: Ngram, “Industry, Standards”

56

Figure 8: Adoption Path of ISO Quality Management Standards
300,000

1,200,000

250,000

1,000,000

200,000

800,000

150,000

600,000

100,000

400,000

50,000

200,000

0

1993

1995

1997

1999

2001

2003

2005

2007

ISO 14001

ISO 22000

ISO/IEC 27001

ISO 13485

ISO/TC 16949

ISO 9001 (right axis)

57

2009

2011
ISO 50001

0

