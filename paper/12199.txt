NBER WORKING PAPER SERIES

DO HIGH SCHOOL EXIT EXAMS INFLUENCE EDUCATIONAL
ATTAINMENT OR LABOR MARKET PERFORMANCE?
Thomas S. Dee
Brian A. Jacob
Working Paper 12199
http://www.nber.org/papers/w12199
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2006

We would like to thank Adam Gamoran and the participants at the “Will Standards-Based Reform in
Education Help Close the Poverty Gap?” conference at the University of Wisconsin’s Institute for Research
on Poverty for helpful suggestions. We would like to thank Wei Ha and J.D. LaRock for excellent research
assistance. All remaining errors are our own. Jacob can be contacted at: John F. Kennedy School of
Government, Harvard University, 79 JFK Street, Cambridge, MA 02138; email: brian_jacob@harvard.edu.
Dee can be reached at Department of Economics, Swarthmore College, Swarthmore, PA 19081; email:
dee@swarthmore.edu. The views expressed herein are those of the author(s) and do not necessarily reflect
the views of the National Bureau of Economic Research.
©2006 by Thomas S. Dee and Brian A. Jacob. All rights reserved. Short sections of text, not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given
to the source.

Do High School Exit Exams Influence Educational Attainment or Labor Market Performance?
Thomas S. Dee and Brian A. Jacob
NBER Working Paper No. 12199
April 2006
JEL No. I2, J3
ABSTRACT
State requirements that high school graduates pass exit exams were the leading edge of the
movement towards standards-based reform and continue to be adopted and refined by states today.
In this study, we present new empirical evidence on how exit exams influenced educational
attainment and labor market experiences using data from the 2000 Census and the National Center
for Education Statistics' Common Core of Data (CCD). Our results suggest that the effects of these
reforms have been heterogeneous. For example, our analysis of the Census data suggests that exit
exams significantly reduced the probability of completing high school, particularly for black
students. Similarly, our analysis of grade-level dropout data from the CCD indicates that Minnesota's
recent exit exam increased the dropout rate in urban and high-poverty school districts as well as in
those with a relatively large concentration of minority students. This increased risk of dropping out
was concentrated among 12th grade students. However, we also found that Minnesota's exit exam
lowered the dropout rate in low-poverty and suburban school districts, particularly among students
in the 10th and 11th grades. These results suggest that exit exams have the capacity to improve
student and school performance but also appear to have exacerbated the inequality in educational
attainment.
Thomas S. Dee
Department of Economics
Swarthmore College
Swarthmore, PA 19081
and NBER
dee@swarthmore.edu
Brian A. Jacob
John F. Kennedy School of Government
Harvard University
79 JFK Street
Cambridge, MA 02138
and NBER
brian_jacob@harvard.edu

1. Introduction
The Federal government has recently taken a central role in promulgating standards-based
education reform through the No Child Left Behind (NCLB) Act of 2001. In particular, NCLB
has introduced explicit requirements for student testing as well as consequences for schools that
fail to make “adequate yearly progress” towards specific achievement goals. The
implementation of this landmark legislation continues to unfold at the state level as the 2013-14
deadline for raising all students to academic proficiency approaches (Olson 2005). A question of
particular interest about these ongoing standards-based reforms is whether they will be able to
close the achievement gaps that contribute to the persistence of poverty and economic inequality.
However, many states have long-standing experiences with standards-based reform. In
particular, the so-called “first wave” of education reform began approximately 30 years ago as
several states began to introduce standardized tests that students were required to pass in order to
graduate. In addition to these “exit exams,” a second, distinguishing feature of the first-wave
reforms was the introduction of state-level requirements that students pass an explicit number of
core academic courses in order to graduate. The adoption of state-level “course graduation
requirements” accelerated in the 1980s after they were a featured recommendation in the
influential report, “A Nation at Risk” (National Commission on Excellence in Education 1983).
Nearly all states now have explicit requirements for how many core academic courses that
high school graduates must complete. And, currently, twenty states require high school
graduates to pass an exit exam. Seven other states plan to introduce such requirements within the
next seven years (Sullivan et al. 2005). Furthermore, in several of the states with long-standing
graduation requirements, the required exit exam has evolved from “minimum competency tests”
that require relatively modest skills to more rigorous tests linked to state academic standards.

2

However, these pervasive reforms have been the subject of little rigorous empirical
scrutiny. The literature that is available provides contradictory evidence on the fundamental
consequences of these state initiatives. In this study, we present new empirical evidence on how
these state reforms - exit exams, in particular – influenced educational attainment and early labor
market experiences. This study makes three broad contributions to the extant literature. One
involves the analysis of more recent data sets (i.e., data from the 2000 Census and the NCES’
Common Core of Data) and state policy changes. A second contribution is the use of research
designs that are robust to potential confounding factors and that allow us to synthesize our
findings with the prior literature. Third, we directly examine how the effects of these policies
may have varied by race, gender, and ethnicity and assess what these findings suggest about the
effects of first-wave reforms on children in poverty.
This study is organized as follows. Section 2 provides background on the first-wave
reforms and discusses the prior literature. Section 3 presents new evaluation results based on
data from the 2000 Census. Section 4 presents complementary evidence based on dropout data
from the Common Core of Data (CCD). Section 5 concludes with a discussion of what these
results suggest about the effects of ongoing standards-based reforms.

2. “First Wave” Education Reforms

2.1 Conceptual Framework
In the 1970s, there was a growing perception that the quality of public schools was in
decline and that the high school diploma, in particular, was no longer a meaningful credential
that vouched for a student’s skills and motivation (e.g., Popham 1981). These concerns were

3

often voiced most prominently by local business leaders concerned with the quality of the
entering workforce. Nearly every state responded to these concerns by instituting testing
programs designed to assess students’ basic skills (Pipho 1978). The intent of most of these new
testing programs was to identify low-performing students and provide them with sources of
remediation. However, a number of states also began to require that students pass a performance
threshold in order to graduate.1 These exit exams (EE), particularly in their earliest incarnations,
typically required that students demonstrate math and reading skills at only an 8th or 9th grade
level. Furthermore, students often began taking these exams as early as 8th or 9th grade and were
typically given multiple re-testing opportunities so that they could graduate. Nonetheless, the
failure rates on these exams often proved politically unacceptable and states would sometimes
lower their cut scores or adjust their exemptions in response (e.g., Catterall 1989).
In addition to these test-based standards, states also began introducing a particular type of
“process” standard over this period: requirements that high school graduates complete explicit
numbers of courses, particularly in core academic areas. These reforms accelerated after “A
Nation at Risk” decried “cafeteria-style” curricula and recommended that the adoption of a “New
Basics” curriculum that included 4 years of English and 3 years of social studies, science, and
mathematics. Only a few states adopted the “New Basics” requirements but virtually every state
introduced or increased its course graduation requirements (CGR) over the last three decades.
The public discourse that accompanied the adoption of these policies focused on
encouraging the academic effort of students and reinvigorating the high school diploma as a
meaningful education credential. However, these reforms could conceivably influence student
outcomes in several distinct and sometimes contradictory ways. For example, the most obvious

1

States typically delayed the enactment of these exit exams in order to provide students with adequate notice, to
allow for the development of the tests and curricular changes, and in response to court challenges (Table A1).
4

potential consequence of exit exams is to elicit increased academic effort from students. The
potential education benefits of exit exams could also extend beyond the marginal student from
whom they might encourage additional effort. In particular, Bishop (1999) discusses how the
higher and external standards implied by exit exams might limit the "nerd harassment" and peer
pressure that encourages high-ability students to shirk educational effort.
However, the introduction of exit exams could also have unintended, pejorative
consequences for the effort and achievement of particular students. For example, the existence
of a testing requirement could retard the academic engagement of very low-performing students
who see little chance of passing the exam. A related concern, based on the phenomenon known
as “stereotype threat” (Steele 1997, 1998), suggests that exit exams could exacerbate minority
achievement gaps. Stereotype threat occurs when a student perceives that they will be viewed
through the lens of a negative stereotype (e.g., a minority student taking a standardized test).
Experimental evidence indicates that stereotype threat can occur in testing environments and that
it can lower academic engagement and achievement. It has also been suggested (e.g., Philips and
Chin 2001) that standards like exit exams could reduce performance among high-achieving
students by prominently signaling relatively low public expectations. In fact, the authors of “A
Nation at Risk” voiced this concern, suggesting that minimum competency tests would become
maximum standards and lower the expectations for high-ability students.
Another conjectured benefit of exit exams is that their high-stakes consequences will
promote student achievement by improving the performance of schools and teachers. For
example, the “effective schools” literature has identified several characteristics associated with
successful schools. These critical traits include clearly defined objectives, a common mission,
continuous monitoring of student performance, and appropriate remediation for under-achieving

5

students (Purkey & Smith, 1983; Purkey & Smith, 1985; Stringfield & Teddlie, 1988). This
literature suggests that the introduction of exit exams could make schools more effective through
establishing clear objectives and providing student-specific assessments. Exit exams may also
encourage (and facilitate) the targeting of remediation efforts to the neediest students and in a
manner that reduces minority achievement gaps.
On the other hand, exit exams could also harm school and teacher performance. For
example, high-stakes exit exams could lead to the use of more narrow teaching styles and
curricula (i.e., “teaching to the test”) that are less effective at fostering intellectual engagement
and higher-order critical skills (Murnane and Levy 2001, Airasian 1987, Koretz and Barron
1998, Jacob 2005). Indeed, there is strong evidence that high-stakes educational accountability
policies lead to strategic placement of low-achieving students into special education or bilingual
programs to avoid testing (Jacob 2005, Figlio and Getzler 2002, Cullen and Reback 2006). Of
course, provisions of NCLB that require nearly all students to take the exams is intended to
mitigate this concern. However, there is even evidence that accountability may lead teachers and
administrators to manipulate student exam scores in order to falsely improve student
performance (Jacob and Levitt 2003).
As noted above, one of the key motivations for the first-wave education reforms was to
ensure that a high school diploma was a signal that a student had mastered important skills. This
suggests that the other potentially important consequences of exit exams involve their effects on
employer perceptions. More specifically, exit exams may have changed the signaling value of a
high school diploma by changing the composition of workers at different education levels.
Proponents generally argue that stricter graduation requirements will increase the benefit of a
high school diploma because employers will know that high school graduates have mastered

6

certain skills. What is less often realized, however, is that the introduction of stricter graduation
requirements may also enhance the “signal” conveyed by not completing high school. Consider
the simplest case in which case the new standards have no incentive effects, and merely reduce
the fraction of those able to obtain a diploma. In this case, the average ability level of the
graduate group will increase because the lowest-achieving students who received diplomas under
the old standard no longer receive diplomas under the new-standard. However, the average
ability level among dropouts will also increase because the students who were pushed into the
dropout group under the new standard are higher-achieving than those who were already in the
dropout group under the old standard. The “sorting” induced by the new requirements will
therefore improve the labor market outcomes for both dropouts and graduates (Betts and Costrell
2001).

2.2 Prior Literature
The prior discussion indicates that the likely effects of the first-wave standards on student
outcomes should be viewed as an open, empirical question. However, despite the prominence of
standards-based reforms, these long-standing state-level experiments have actually been the
subject of relatively little empirical scrutiny. The evidence that does exist is generally mixed and
unsatisfactory. This is largely due to two issues: the lack of consistent and reliable data on
outcomes such as achievement or educational attainment, and the difficulty of differentiating
between effects due to the exit exams and effects due to other related policies or conditions in the
state at the time. In this subsection, we review several recent studies, highlighting the two
difficulties described above.2

2

For a survey of earlier research, see Jacob (2001).

7

Several studies conducted a cross-sectional analysis of educational attainment and labor
market performance using nationally representative data sets such as High School and Beyond
(HS&B) and the National Educational Longitudinal Survey (NELS88). In a cross-sectional
analysis of NELS88, Jacob (2001) finds that exit exams only increase dropout probabilities for
low-ability students. Bishop and Mane (2001) find similar results with the NELS88 – namely,
course graduation requirements reduced the probability of graduating high school and state exit
exams increased dropout rates for students with below-average grades, but increased GEDs and
time in high school on average. Lillard and DeCicca (2001) present evidence that course
graduation requirements, but not state exit exams, increase dropout rates. This analysis is based
both on state-year panel data and individual-level data from HS&B and NELS88, although the
exit-exam effect is based exclusively on cross-sectional comparisons and does not separately
examine lower-achieving students. Using a later wave of data from NELS88, Warren and
Edwards (2005) find that high school examination requirements are not associated with increased
chances of leaving school without a diploma or GED, even among low-SES and low-achieving
students.
A significant limitation of these studies is that they have a limited ability to control for
state-specific factors that may be correlated with student outcomes as well as the adoption of EEs
or CGRs. For example, one might be concerned that states adopt stricter graduation
requirements in response to a decline in student performance, in which case cross-sectional
estimates of EE or CGR would likely be biased toward finding negative policy effects. While
the papers cited above attempt to control for state-specific factors such as employment rates, per
pupil expenditures and other things that might influence student outcomes, one might still be
concerned about the type of trend described above, or some other unobservable state factor.

8

Moreover, analyses based on NELS88 cannot provide information on cohorts other than those
expected to graduate in 1992.
Dee (2003) uses data from the 1990 Census Public-Use Microdata Sample (PUMS) to
address several of these concerns. The PUMS is a five percent sample from the Census that
includes a variety of information on individuals including age, race, gender, state-of-birth,
highest grade completed, employment and earnings. Using age and state-of-birth (which serves
as a proxy for the state in which the one attended secondary school), Dee determines whether
individuals would have been subject to CGRs or EEs as adolescents. He then employs a
difference-in-difference strategy that involves comparing the outcomes of individuals within the
same state who experienced different policies due to their age and the timing of when the
policies were introduced. By controlling for fixed effects for state-of-birth, he is able to control
for any time-invariant state characteristics that might be correlated with policy adoption and
student outcomes. Dee (2003) finds that EEs reduced the probability of completing high school,
but only for black males. However, he also found that exit exams created passive labor market
rewards for black males in the form of increased employment in their twenties, an outcome
consistent with the hypothesis that these testing regimes changed the signals associated with
dropping out and graduating.3
Finally, several recent studies have utilized state-level data on enrollment and completion
rates to examine this issue. The studies find mixed results. Amrein and Berliner (2002) find that

3

Dee (2003) considers part-time as well as full-time employment, and (in some specifications) includes controls for
whether the respondent was enrolled in school (presumably college) at the time of the interview. At the time of the
interview, all respondents would have been at least 20 years of age. Moreover, he finds that exit exams have no
impact on the likelihood that Black males enroll in college. Together, these facts suggest that the employment
effects are not driven by the fact that high school dropouts are more likely to be employed than enrolled students.
While these results are consistent with a scenario in which the implementation of an EE changes the composition of
dropouts and graduates, the findings are also consistent with a scenario in which the implementation of the exam
changed the actual skills acquired by students (dropouts as well as graduates). However, Dee (2003) also found that
exit exams were associated with reductions in core academic course taking.
9

EEs increase dropout rates; Carnoy and Loeb (2002), Green and Winters (2004), Warren and
Jenkins (2005), and Marchant and Paulson (2005) find no effect on completion rates. As
outlined in Warren et al. (2005) and Warren (2005), this recent work has several serious
methodological shortcomings: information about EEs is often inaccurate; the state-level
completion rate measures have important flaws; and many of these studies fail to account for
unobserved heterogeneity across states.
A recent study by Warren et al. (2005) addresses these measurement and specification
issues. More specifically, the authors utilize state-level panel data on high school completion
rates from 1975 to 2002, and examine three dependent variables: (1) a status dropout measure
that treats high school diplomas and GED certificates as equivalent. This measure is derived
from CPS data on 16-19 year olds not enrolled in school & without a diploma or GED; (2) a high
school completion measure that uses data from the Common Core of Data (CCD). This measure
is defined as the ratio of the number of high school completers (which is available for each state
and year over many years) to the number of ninth graders enrolled three academic years earlier,
after adjusting for interstate migration; and (3) the percent of 16-19 year olds in a state who take
the GED. They find that exit exams are associated with lower completion rates and higher rates
of GED test-taking, and that these relationships are stronger in states with more difficult exams,
higher poverty levels, and more racial-ethnic minorities.
The authors note that CPS-based state-level high school dropout rates have substantial
limitations, but choose to report results on this measure for comparison with prior research.
Warren et al.’s (2005) preferred measure is their estimated high school completion rate. An
analysis by Warren (2005) suggests that this measure is not biased by interstate migration, grade
retention or changes in the size of incoming high school cohorts. However, they note that this

10

measure is modestly biased by international migration and student retention in the 8th grade.
From the perspective of evaluating the effects of exit exams, this study has two more substantive
shortcomings. One is that the aggregate state-year completion rates make it more difficult to
examine the important question of how the effects of exit exams may have varied by race,
gender, and ethnicity. Second, this study does not address the issue of whether exit exams have
had their conjectured effects on subsequent labor market outcomes.
A recent study by Martorell (2004) applies a novel research design to the dropout
question. The author examines the impact of the exit exam in Texas utilizing a regression
discontinuity design in which he compares students who barely pass and barely fail the test. He
finds two particularly interesting results. First, he finds no evidence of a discouragement effect.
That is, students who barely fail the exam in 10th or 11th grade are no more likely to drop out than
students who barely pass the exam in these grades. Second, the exam does ultimately reduce the
likelihood of graduation. Students who barely fail the final exam have significantly lower
chances of holding either a diploma or a GED, and are less likely to attend post-secondary
schooling, than those who barely pass. The author estimates that roughly one percent of Texas
students do not graduate because they cannot pass the test, which implies a relative effect of
roughly 5 percent (relative to the mean dropout rate).4
The most recent studies of high school exit exams provide mixed evidence on the basic
question of whether they increased the likelihood of dropping out of high school. This study
contributes to this literature in several distinct ways: (1) We use the most recently available data,
which allows us to assess whether the more recent (and generally more rigorous) exit exams
uniquely influenced educational attainment; (2) Unlike several of the prior studies, we also
4

The relative effect is calculated by dividing the absolute effect (1 percentage point) by the average dropout rate (20
percent), which yields 1/20 = 0.05 or 5 percent.
11

focus on the important question of whether these reforms had unique effects by race, gender or
ethnicity; (3) Our study examines the effects of exit exams on subsequent labor market
outcomes, not just educational attainment.

3. Evidence from the 2000 Census
In this section, we present new evidence on the impact of EEs and CGRs using data from
the 2000 Census Public Use Microdata Sample (2000 PUMS). The PUMS data offers several
other advantages relative to the CPS and CCD data used in the analyses described above. First,
the large number of respondents in the PUMS allows one to precisely identify very small policy
effect, and a better ability to detect race-specific responses to educational policies. Second, the
background information on race and gender allows one to examine the impact of educational
policies across important demographic subpopulations. Third, the self-reported data on
educational attainment avoids some of the problems associated with the high school completion
measures used by Warren et al. (2005) and others. Also, because PUMS respondents report
attainment as of 1999, for most birth cohorts the data will allow an individual who takes longer
than four years to finish high school to be counted as completing. Finally, the PUMS provides
information on other interesting and important outcomes such as college attendance, employment
and earnings.
On the other hand, the PUMS has several important limitations. First, because of
interstate mobility, state-of-birth is an imperfect proxy for the state in which a child attended
secondary school. This measurement error will tend to attenuate the effects of the state-level
education policy variables such as EE and CGR. Second, respondents may systematically
misreport educational attainment or employment. If this misreporting is (conditionally) random

12

with respect to relevant characteristics, it will simply increase the residual variation in our
models, and thus decrease the precision of our estimates. On the other hand, if an individual’s
tendency to misreport his or her educational attainment is correlated with the existence of an EE
or CGR, the misreporting may introduce bias into our estimates. A third and related problem is
that the PUMS questionnaire does not distinguish between conventional high school graduates
and GED completers. In light of the possibility that EEs encourage students to drop out but also
complete a GED (e.g., Warren et al. 2005), this Census coding convention implies that our
results will understate the true policy-induced reductions in the likelihood of graduating from
high school.

3.1 Data
The 2000 PUMS consists of approximately 14 million respondents (5 percent of the
population) who completed the long form questionnaire to the decennial Census (U.S. Bureau of
the Census 2003). The PUMS includes a host of information on respondents, including age,
race, gender, state-of-birth, current state-of-residence, educational attainment and labor market
performance. One particularly useful feature of the PUMS is that, because it contains individuals
from multiple birth cohorts within each state, one can exploit within-state variation in EE and
CGR instead of the cross-state variation to estimate the effects of these policies.
Our extract from the PUMS data consists of the 2,925,005 white (non-Hispanic),
Hispanic and Black respondents who were aged 18 between 1980 and 1998 and born in one of
forty-nine states (Ruggles et al. 1997).5 Two of the outcome variables defined for each

5

Respondents born in Nebraska were omitted since that state does not use Carnegie units in defining its graduation
standards. The inclusion of Nebraska does not change the results for EEs. We identified the year in which each
respondent was 18 by their age on enumeration day (April 1, 2000). Respondents from the District of Columbia, or
those born abroad were also excluded.
13

respondent identify educational attainment, a binary indicator for high school graduation and
another for college entrance.6 We limited the sample to those who were at least 18 by 1998
because of the biases that could be generated by state-specific trends in the "incomplete spells"
of high school completion and college entrance among cohorts that were younger at the time of
the Census interview (Angrist and Evans 1999). The other dependent variables reflect the labor
market experiences of each PUMS respondent. One is a binary indicator for employment
participation, which is defined for all respondents.7 The other is the natural log of average
weekly wages, which is only defined for 2,429,250 respondents. This wage variable is the ratio
of pre-tax wage and salary income reported for the previous calendar year and the corresponding
number of weeks worked.
Using the respondents’ birth year and state-of-birth, we determine whether each
individual was subject to an EE or CGR. Specifically, we assign each respondent the EE and
CGR policies that applied to the high school graduating class in his or her state of birth when the
respondent was 18 years old. For example, a 27-year-old respondent born in Virginia would
have been 18 years old in 1991, and thus assigned the policies in place for the graduating class of
1991 in Virginia. Table A1 presents data on EE by state and year. Here year refers to a
graduating class rather than a calendar year. For example, when we say that Virginia had an EE
in 2000, we mean that the high school graduating class of 2000 in Virginia was subject to the
exam.

6

College entrants are those whose highest reported educational attainment was "Some college, no degree" or higher.
It should be noted that this sample, of course, includes students who attended private schools. However, their
inclusion is arguably appropriate since it is possible that students may switch schools to avoid the consequences of
stricter standards.
7
Those who report that they are not in the labor force are defined as unemployed to avoid omitting discouraged
workers. However, the exclusion of these respondents does not substantively alter the subsequent results.
14

Following Warren et al. (2005), we distinguish between more and less difficult exit
exams based on the difficulty of the material included in the exam. Specifically, if any
component of a state EE assessed material that was first presented during the high school years
(i.e., in ninth grader or later), the EE is referred to as a more difficult exam. Information on the
grade level of the material assessed in an EE was gathered from a variety of sources, including
official reports published by state departments of education as well as newspaper accounts of the
EE.8 Note that this definition has several shortcomings. Because districts may introduce
material at different grade levels, it is difficult to determine whether this measure is comparable
across states. In addition, states can alter the difficulty of an exam by adjusting the required
passing score, so that it is possible that an exam containing “less difficult” material may actually
be more difficult to pass relative to an exam covering more difficult material.
The second dummy identifies whether the state had a high, academically focused CGR in
effect for that graduating class. A “high” CGR is defined here as a required high school
curriculum that includes at least 3 Carnegie units in English, 2 in social studies, 1 in science and
1 in mathematics.9 A “very high” CGR is defined here as a curriculum that requires the
following: 4 Carnegie units in English, 3 in social studies, 2 in math and 2 in science.
Table 1 presents summary statistics for our sample. Roughly 87 percent of respondents
graduated high school and 57 percent attended at least some college. About 14 percent of the

8

It is worth noting that our investigation revealed several potential mistakes in the classification adopted by Warren
et al. 2005. For example, Warren et al. (2005) indicate that the Florida exam became “more difficult” in 1993
whereas our research indicates that this did not occur until the introduction of the FCAT in 1996. Similarly, Warren
et al. indicates that Louisiana’s exit exam was “more difficult” since its inception in 1991 while our research
indicates that it did not reach this level of difficulty until the introduction of a new exam in 2003.
9
Some studies represent state CGR policies by the total number of Carnegie units required. However, this measure
may more accurately reflect the focus of reform efforts (e.g., A Nation at Risk), which was to course taking in core
academic areas.
15

sample is Black and 3 percent is Hispanic.10 Over 75 percent of respondents were employed at
the time of the survey. Approximately 32 percent of state-year observations have an EE, but
only 5 percent have a more difficult EE. Rigorous CGR are more common, with 75 percent of
state-years requiring at least 3 units of English, 2 units of social studies and 1 unit of math and
science and 25 percent requiring 4, 3, 2 and 2 or more.

3.2 Empirical Strategy
The basic specification used for regression models based on these data is:
(1)

Yist = β X ist + γ Z st + us + α t + ε ist

where Yist is the dependent variable for respondent i in state-of-birth s and birth cohort t, and the
matrix X includes observed, individual-level traits. In most models, the individual covariates
simply include binary indicators for race and gender. In the models for labor market outcomes,
we also estimate models that control for measures of educational attainment (i.e., separate
dummy variables for high school graduates, those with some college and those with bachelor
degrees) and a dummy variable for whether the respondent attended school within the last year.11
We discuss the estimates from the reduced form as well as the more complete models in the next
section. The terms us and α t represent fixed effects specific to each state of birth and year of
birth. The term ε is a mean-zero random error. We report Huber-White heteroscedasticconsistent standard errors, which allow for arbitrary correlation of errors within each state-of-

10

The proportion of Hispanics is lower than the national average since we exclude all respondents who were
foreign-born.
11
The school attendance variable is meant to control for the fact that those respondents still in school over the last
year would have had limited labor market experiences. This specification is similar to those used by Bishop and
Mane (2001).
16

birth (Bertrand et al. 2004). For specifications with dichotomous outcome variables, we estimate
Probit models; for other specifications, we estimate OLS models.
The matrix Z includes determinants that were specific to the birth cohorts within each
state. These determinants include the two independent variables of interest: dummy variables
that reflect the state EE and CGR policies in place for each birth cohort at age 18. These and
other state-year controls were matched to the respondents by their state-of-birth and year-ofbirth. As noted earlier, the measurement error introduced by relying on state-of-birth will lead to
attenuation bias in these state-level variables, suggesting that the reported estimates can be
interpreted as lower bounds on the true effects.12
As suggested earlier, the identification strategy embedded in this model makes a
potentially important contribution to our understanding of the consequences of EE and CGR
because it removes the possible biases due to unobserved time-invariant state-level determinants
of educational attainment and labor market performance. The inclusion of state fixed effects
means that we are effectively comparing the differences among cohorts in the "treatment" states
before and after the introduction of new standards to the contemporaneous cross-cohort changes
in the "control" states.
We present some evidence on the empirical relevance of relying on within-state versus
cross-state comparisons by comparing the results of models that do and do not include the state
fixed effects. As a further, ad-hoc check on the validity of this specification, in some models we
include an additional predictor variable – namely, the number of state executions that took place
in a respondent’s state-of-birth when the respondent was 18 years of age as a predictor (e.g., Dee
2003). Insofar as one believes that state executions should not have had a large and statistically

12

We found that the results were similar in models that matched respondents to the state-year variables by their state
of residence five years prior to the Census.
17

significant effect on educational attainment, for example, the finding of such effects would
suggest the presence of specification error. One virtue of using state executions for this type of
“falsification exercise” is that there was considerable variation over this period both within states
and across states in the number of state executions.
In the preferred specifications, which include state fixed effects, the possible sources of
omitted variable biases are the unobserved determinants of Y that are also related to the timing of
new standards within states. The matrix Z addresses this concern by including other regression
controls that vary by state and year. For example, new state standards were sometimes part of
omnibus education bills that included other policy changes such as increased spending. To
control for the possible effects of school spending, some models include, as an independent statelevel variable, real expenditures on K-12 public schools per student in average daily attendance
when the respondents were 16 to 17 years old. For example, respondents who were 18 in 1980
were matched to the school expenditures in their state during the 1978-1979 school year.
Another state-year control in most models is the state unemployment rate when the respondent
was 17 years old. This variable is expected to have a positive effect on educational attainment
since it reduces the opportunity costs associated with remaining in school (Duncan 1965).
Card and Lemieux (2001) present evidence that the natural variation in the size of
particular birth cohort’s population can also influence educational attainment. At the college
level, this could occur if temporary increases in cohort size are not fully matched by an increased
supply of enrollment space at local colleges and universities. At the secondary level, increased
cohort size may reduce the benefits of remaining in school by lowering school quality.13
Therefore, we also include a measure of cohort size based on the natural log of the U.S. Census
Bureau's estimate of 18 year-olds in the respondent's state of birth at age 18. We also include a
13

Card and Lemieux (2001) find that cohort size is associated with significant increases in pupil-teacher ratios.

18

measure of the real costs of postsecondary tuition based on the in-state rate at "lower-level" state
colleges and universities when the respondent was 17 years old (Card and Lemieux 2001, Kane
1994).14 As a control for within-state changes in socioeconomic priors, we also matched each
respondent to the poverty rate in their state when they were 17 years old. Finally, we include one
additional measure of related educational accountability policies in the state at the time the
respondent was 18 years of age: a binary variable indicating whether the state issued report cards
for individual schools.

3.3 Results
Table 2 shows the marginal effects evaluated at the mean derived from Probit models
predicting the likelihood of graduating high school. Column 1 presents what might be described
as the baseline specification, which includes individual demographics (i.e., indicators for Black
and female) along with state and year fixed effects. There is no significant relationship between
the likelihood of dropping out and the existence of either an EE or CGR. In column 2, we see
that adding controls for time-varying state variables (in column 2) does not change the results.
The standard errors on the EE and CGR variables imply that our analysis has the power to detect
effects of roughly +/- 0.4 percentage points, which translates into roughly 3 percent if one uses
average dropout rate of 12.7 percent as a baseline.
The specification shown in column 3 includes separate indicators for more and less
difficult EEs and CGRs, but does not find effects that are significant at conventional levels. It is
also possible that the impact of EE or CGR evolve over time, as students, parents and teachers
become more familiar with the new requirements. In results not shown here, we test for an

14

Complete data on community college tuition was not available for several states. For these states (NH, SD, CA,
and SC), we used state college tuition.
19

interaction between the existence of a less difficult EE and the number of years it has been
required, but do not find any significant results.15
Column 4 serves as a specification check. In this specification, we include the number of
state-year executions in the model as a predictor. Since we do not think that the number of
executions could have any causal impact on the contemporaneous high school completion rate, if
this variable is a significant predictor, then we might be concerned that we have omitted an
important time-varying state characteristic that influences educational outcomes and might bias
our estimates. Indeed, we find that the number of state executions is a positively associated with
the high school graduation rate, which raises concern about our previous specification.
In an effort to more completely account for time-varying state characteristics that might
confound our analysis, in column 5 we include a series of division-specific time trends.
Specifically, we interact a cubic term in the year since 1979 with indicators for each of the nine
different census divisions, for a total of 27 additional covariates. These covariates control for
any factors that may have been changing over time in different parts of the country, including
such things such as economic conditions we do not pick up with the unemployment rate, social
norms or public policies that pertain to educational attainment, or other factors. In column 5, we
see that once we control for these time trends, the coefficient on state executions drops
dramatically and is no longer significant.
Turning to the estimates of the education policy variables in column 5, we see that both
more and less difficult exams are negatively associated with the likelihood that a student
completes high school. Specifically, the easier EEs are associated with a 0.5 percentage point
reduction in the likelihood of completion, which translates into a 4 percent increase in the
15

The more difficult EEs have not been in place long enough to obtain reliable estimates on the time trend for these
exams.
20

probability of dropping out. More difficult exit exams are associated with a 0.7 percentage point
or 5.5 percent increase in the probability of dropping out. In contrast, neither the moderately nor
the very rigorous CGRs appear to be associated with changes in high school completion.
Table 3 shows the results for high school completion separately by race and gender. The
specification includes division-specific time trends, and thus is comparable to column 5 in Table
2, with the exception that the models are estimated separately by race and gender which allows
all of the coefficients to vary across groups (i.e., a completely unrestricted model). As discussed
above, one would expect more rigorous graduation requirements to have a larger negative impact
on lower-achieving students, which we proxy for with race and ethnicity. Consistent with this
hypothesis, we find that EEs reduce the likelihood of high school completion for Black students
by twice as much as they do for white students. More and less difficult EEs are associated with a
.013 and .018 percentage point reduction in the likelihood of high school completion among
Black males, which translates into relative dropout effects of roughly 5.2 and 7.3 percent.
Among Black females, easier exit exams do not appear to have significant effects, but more
difficult exams are associated with a .021 percentage point (11 percent) reduction in the
likelihood of completing high school. Interestingly, exit exams do not appear to affect high
school completion rates for white females, though they sharply reduce the completion rates
among white males. Overall, the existence of CGRs is not associated with changes in high
school completion rates, although they do seem to reduce the probability of high school
completion for one subgroup – namely, white females.
The results for Hispanics are somewhat more puzzling. Our point estimates suggest that
EEs increase the likelihood of high school completion among Hispanics. While the estimates
are not significant at conventional levels, the point estimates are large in magnitude and thus may

21

warrant further exploration in subsequent research. We tested the extent to which the somewhat
anomalous Hispanic results are due to particular states. It appears that the positive effect of exit
exams for Hispanic boys is due largely to New York State. The results for Hispanic girls do not
appear to be due to any single state. One possible explanation for the difference in estimated
effects among Black and Hispanic students is that Hispanic students may have been eligible for
language-related exemptions and testing accommodations (e.g., Sullivan et al. 2005, Chapter 6),
although this seems less likely given the fact that our sample is limited to native born Hispanics.
It is also possible that schools with predominantly Hispanic populations were more effective in
responding to the policies.
As discussed above, the expected effect of EE and CGR on college attendance is unclear.
On the one hand, if some of the students prevented from graduating high school because of the
requirements would have attended college, we would expect the policies to reduce attendance.
On the other hand, if the requirements lead other students to be better prepared for college (or to
believe that they are better prepared for college), then one would expect the policies to increase
postsecondary enrollment. In practice, it seems likely that one would expect to find a negative
relationship at the very bottom of the ability distribution, but perhaps find a somewhat positive
relationship at somewhat higher points on the ability distribution. In general, however, it seems
unlikely that we would expect to find any effect among moderately or high ability students, for
whom the requirements were probably not a binding constraint.
The results for postsecondary enrollment shown in Table 4 suggest that EEs do not have
a significant influence on college attendance. One notable exception is for Hispanic females
who faced a more difficult EE. These students were considerably more likely to enroll in college
than their counterparts who did not face a difficult EE.

22

The evidence presented thus far is largely consistent with the concerns sometimes raised
by critics of standards-based reforms – namely, higher requirements may reduce educational
attainment among disadvantaged groups. Moreover, the findings shown in Tables 2-4 are
consistent with our earlier work (Jacob 2001, Dee 2003). As noted earlier, however, a full
evaluation of these policies should consider the impact of more rigorous graduation standards on
labor market performance. An examination of the labor market effects is also interesting insofar
as business leaders frequently express concern with the quality of their work force, and were
often instrumental in the adoption of the EEs and CGRs. Indeed, higher standards may benefit
students by inducing greater effort in high school, which is later rewarded in the labor market.
They may also influence the relative returns of a high school degree by changing the signal
associated with the diploma, although, as discussed above, it is not clear whether this will
improve the earnings of high school graduates relative to dropouts since student sorting alone
would suggest higher standards would raise the ability level of both graduates and dropouts.
Table 5 presents results for reduced-form models predicting employment. The covariates
are identical to those in the earlier models. Models that control for educational attainment and
whether the respondent is currently in school yield comparable results. Overall, the results seem
to suggest that neither EEs nor CGRs had any substantial impact on employment. There is some
evidence that EEs may be associated with slight reductions in employment for Blacks and
increases for white females, although these results are quite small in magnitude and only
marginally significant.. Once again, there is a somewhat puzzling improvement for native-born
Hispanic females. Employment rates increase substantially for these students when they face
EEs and CGRs. Table 6 presents results for earnings. Note that only respondents who reported
earnings greater than zero are included in these specifications. While the estimates are quite

23

noisy, a few tentative patterns emerge. The introduction of CGRs is not significantly related to
earnings. However, exit exams (particularly the more difficult ones) tended to reduce the
subsequent earnings of white and Hispanic students while increasing those of Black students.
The wage gains of Black students are somewhat surprising in light of their reduced educational
attainment and the evidence of wage losses among non-Black students. This heterogeneous
pattern of results cannot be easily reconciled as a signaling phenomenon and instead suggests
that there were unique incentive effects of exit exams by race and ethnicity, at least at the center
of the wage distribution.
To summarize, our results indicate that exit exams led to statistically significant
reductions in high school completion, which were concentrated among Black students and white
males. In terms of labor market outcomes, our results indicate that exit exams may have
increased the subsequent earnings of Black students while reducing those of white students.
Finally, our results highlight a surprising and puzzling positive effect of stricter graduation
requirements, particularly exit exams, on the outcomes of native-born Hispanic females. For
example, our estimates indicate that exit exams improved the college matriculation and
employment of native-born, Hispanic females.

4. Evidence from the Common Core of Data (CCD)
The evaluation results based on the 2000 Census indicate that exit exams, particularly the
most difficult ones, reduced the probability of completing high school among white males and
black students. However, there are a number of reasons to be concerned that these estimates may
understate the true effects of exit exams on the probability of completing high school. For
example, the use of state-of-birth to match PUMS respondents to their state exit-exam

24

requirement could introduce measurement error. To the extent this measurement error promotes
attenuation bias, the true effect of exit exams on educational attainment would be understated.
A second issue that would also lead our results to understate the true effect of exit exams
on the probability of completing high school is that the PUMS survey did not distinguish high
school completers from GED completers.16 A third issue is that, because the PUMS data provide
“status” data on educational attainment (i.e., the total share meeting a definition at a given point
in time), they do not identify precisely when exit exams may have increased the probability of
dropping out. In other words, this evidence does not identify whether most students dropped out
after failing their initial attempts (i.e., early in high school) or persisted with re-tests through 12th
grade. The design of improved remediation for the dropout risk ostensibly created by exit exams
could benefit from evidence of such grade-by-grade risks. A fourth and more general concern is
that the empirical evidence based on an alternative identification strategy would provide useful
evidence on the robustness of the Census results.
This section addresses several of these concerns by presenting different evidence on
whether (and when) exit exams increased the probability of dropping out of high school. This
analysis is based on unique, district-level dropout data that the National Center for Education
Statistics (NCES) began collecting in the early 1990s through the Common Core of Data
(CCD).17 Generally, the NCES has only reported these data from states that used dropout
definitions that conformed to their standard, which is described below.18 Fortunately, over the
last 15 years, the number of states that have chosen to conform to their definition has increased.

16

There is evidence that exit exams increased rates of GED completion (e.g., Warren, Jenkins and Kulick 2005).
Prior analyses based on NCES data have relied on state-level reports of the number of high school diplomas
granted and measures of the relevant enrollment base, often with attempted adjustments for the effects of grade
retention and migration (e.g., Greene and Winters 2004, Warren, Jenkins and Kulick 2004).
18
In more recent years, the CCD also reports dropout data from states that use a similar definition of a dropout
except for their calendar conventions.
17

25

However, because of the limited overlap between states that have consistently reported these
dropout data and states that introduced exit exams over this period, we focus on the experiences
within one particular state, Minnesota.

4.1 Graduation requirements in Minnesota
In the early 1990s, the Minnesota Legislature and the State Board of Education expressed
their intention to develop “results-oriented” high school graduation requirements for the state’s
public school students. As in many other states, the motivation for these requirements came from
business and community leaders concerned that students did not have the basic skills necessary
for productive employment and responsible citizenship. The subsequent graduation rules
required that students pass “Basic Skills Tests” (BST) in math, reading, and writing in order to
graduate. Passing scores on the math and reading tests were first required of the graduating class
of 2000 (i.e., 9th graders during the 1996-97 school year). The requirement that public high
school graduates achieve a passing score on the writing test was delayed until the graduating
class of 2001.19
Another prominent component of Minnesota’s new high school graduation requirements
was that students demonstrate higher-order understanding through complex and highly
controversial, performance-based assessments known as the “Profile of Learning.” These
standards became effective somewhat later (i.e., beginning with students entering 9th grade
during the 1998-1999 school year). While there is some evidence that the unpopular “Profile”
influenced classroom practice, its implementation was highly uneven (Avery, Beach, and Coler
2003). After several years of legislative wrangling, the state effectively transferred control over

19

Beginning with the class of 2001, the cut score required to pass the BST also increased from 70 percent of
questions answered correctly to 75 (Shah 2001).
26

these standards to local school districts.20 Then, shortly after our study period (i.e., in 2003), the
“Profile” was abolished entirely. Unsurprisingly, we found that the Profile had no distinct effects
on dropout rates separate from those of the BST requirement. Nonetheless, a caveat about our
reduced-form results is appropriate because the timing of these policy changes overlapped
considerably.21
For all the reasons discussed earlier, whether Minnesota’s BST requirement actually
increased or decreased dropout rates is clearly an open, empirical question. When Minnesota’s
80,000 8th graders first took the BST in the spring of 1996, the pass rates seemed surprisingly
low to many observers; only 63 percent passed the reading test and 76 percent passed the math
test (Minneapolis Star-Tribune 1996). And these initial passing rates were substantially lower
among minority and low-income students (Smith and Duchesne 1996).22
However, the ultimate effect of the BST requirement on dropout rates could be attenuated
by a number of factors. For example, relative to other states with exit exams, Minnesota provided
an unusually high number of re-test opportunities (i.e., eleven). Like most other exit-exam states
(Gayler et al. 2004, Table 10), the state also required school districts to develop individualized
remediation plans for each student who failed a BST in 8th or 9th grade. The state also provided
flexibility and testing accommodations for students with disabilities and those who were English
language learners (ELL). For example, students with an IEP could have their BST cut scores
lowered by their local IEP team. And ELL students who had been enrolled for fewer than three

20

See Avery, Beach, and Coler (2003) for details.
However, it should be noted that the grade-specific heterogeneity in our BST results is clearly consistent with
exit-exam effects but less plausibly related to the Profile.
22
Interestingly, the gaps in pass rates among white and minority students are larger in Minnesota than in other states
(Gayler et al. 2004, page 37).
21

27

years in a school where the primary instructional language was not English were exempted from
the graduation requirements.23
The BST in math and reading were administered in grades 8 through 12 while the writing
test was first taken in grade 10. The first cohort required to pass the BST in math and reading
took these exams for the first time as 8th graders in the spring of 1996. The cohort required to
pass the BST in writing took this test for the first time as 10th graders in the spring of 1999. The
implementation of the BST requirements attracted relatively little public notice, especially
relative to the more controversial “Profile of Learning” standards. One exception occurred in
2000 when scoring errors led to some students being mistakenly told they failed the test,
including about 50 seniors who were denied diplomas (Bakst 2000). There were also two
incidents of teachers being accused of stealing copies of the high-stakes exams (Associated
Press, 2001). Interestingly, during the summer of 2005, which is after our study period, the
Minnesota legislature enacted legislation to replace the BST with tests geared to higher level
grade content and aligned to state content standards (Sullivan et al. 2005, Table 3).

4.2. Common Core of Data (CCD)
The National Center for Education Statistics (NCES) collaborates annually with state
education agencies to organize a variety of data on all public schools and school districts (e.g.,
staffing, enrollments, and finances) into the Common Core of Data (CCD). The data items
collected by the CCD are based on consistent definitions that have been developed by the NCES
and state representatives over several decades. Beginning in the early 1990s, the CCD included

23

The state also translated the Math BST into Hmong, Somali, Spanish, and Vietnamese (Sullivan et al. 2005, page
172).
28

district and grade-level data on dropouts from a growing number of states (including Minnesota)
whose reporting practices conformed to the NCES definitions.
The CCD uses an “event” dropout definition. More specifically, a student is designated as
a dropout for a particular school year if he was enrolled at some time during the school year and
met several explicit criteria as of October 1 in the next school year. These criteria are that the
student in question was not enrolled, had not graduated or completed an approved educational
program (e.g., GED), had not transferred and was not absent due to death or a school-recognized
illness or suspension. The CCD reports dropout rates which are based on these dropout data and
specific to each district and grade. These rates were constructed by dividing the number of
NCES-defined event dropouts for each district and grade by its corresponding enrollment base
for that school year.24
The grade-specific dropout rates in the CCD are not perfect measures. Most notably, it
would be preferable to separate GED completers from conventional graduates. Furthermore, a
problem with any event measure is that it will not reflect subsequent re-enrollment by a student
who drops out except through a change in the enrollment base. However, as noted earlier, these
data also have several unique benefits. For example, relative to the PUMS data, individuals
attending public schools can be matched without measurement error to their high school
graduation requirements. Furthermore, because these dropout rates accommodate both grade
retention and student mobility, they are not subject to the concerns that have been the focus of
studies using state-year high school completion rates based on adjusted enrollment data (e.g.,
Warren 2005).25

24

States do not report this enrollment base directly. Instead, the NCES constructs these variables from gradespecific enrollments from schools within the district.
25
The NCES gives states autonomy in verifying a student’s transfer status (e.g., transcript requests or withdrawal
notices with signed parental assurances about re-enrollment) but discourages reliance on unsubstantiated reports.
29

Another unique feature of these grade specific dropout rates is that they facilitate a
somewhat unusual empirical strategy for identifying the effects of Minnesota’s high school
graduation requirements on educational attainment. That strategy, which is described below,
relies on the fact that within each district and year, we observe the dropout rates in grades, some
of which are constrained by Minnesota’s exit-exam policies and some of which are not. The unit
of observation for this analysis is the dropout rate for each unique district-grade-year observation
over the nine school years from 1994-95 to 2001-2002. We applied several edits to the pooled
CCD files to create a data set suitable for this analysis. For example, we deleted school districts
that were regional service agencies or state or Federal agencies providing services to specialneeds populations as well as districts without students. We also deleted districts that did not
serve students in a grade from 9th through 12th.
We also deleted a small number of observations where the dropout rate was either
negative or greater than 100. However, the results presented here are similar when these
observations are included with imputed dropout rates of 0 or 100 percent. We also applied an
imputation to correct a coding convention used for the Minnesota data for the 1994-95 and the
1996-97 school years. Specifically, in most years, roughly a quarter of the district-by-grade
observations for Minnesota had no dropouts. However, for the 1994-1995 and 1996-1997 school
years, only one grade-district observation had a dropout rate of zero. Instead districts in these
years with positive enrollments had missing or not applicable for dropout rates that should have
been zero. We have imputed zero to these observations but checked that the results are similar
without this imputation and when data from these two school years are omitted.
As noted earlier, an issue of particular interest is whether exit exams have unique effects
among high-poverty students or those who are racial or ethnic minorities. To address these

30

issues, we matched the Minnesota school districts to 1995 data on the percent of children in
poverty within the district and to 1993-94 data aggregated from the school-level CCD files on
the racial and ethnic composition of the district’s students. The grade-level dropout data in the
CCD are actually defined by race, ethnicity and gender over this period. However, we use
district-level data on minority composition because the relevant enrollment bases for the CCD’s
race and ethnicity-specific dropout data were not collected. Specifically, the school-level CCD
only started collecting grade-specific enrollments by race, ethnicity and gender in the 1998-99
school year. Our final, analytical sample omits the observations that could not be matched to
these poverty and demographic data. An examination of these observations indicated that they
largely consisted of administrative school districts that had been incorrectly flagged in the CCD
and school districts, largely charter schools, which had been created during the sample period.26
The final data set consists of an unbalanced panel of 10,502 grade-level dropout rates for the
approximately 350 districts observed in each of nine academic years.

4.3 Specifications
Our approach to evaluating the effects of Minnesota’s BST requirement on dropout rates
exploits the variation generated by the fact that the exit exam was first required of the graduating
class of 2000. State exit exams were often first tied to a specific graduating class while the cohort
was in 8th or 9th grade in order to avoid the perceived unfairness and possible court challenges
associated with subjecting those already in high school to a requirement they could not have
anticipated. This sort of phased introduction creates potentially useful variation in policy
exposure both across grades and within grades over time. For example, the first high school
cohort subject to the new exit exam requirements was in 9th grade during the 1996-97 school
26

Our results are quite similar in specifications that include these observations.

31

year. However, the cohorts in grades 10 through 12 during that year did not have to pass the BST
but did share the determinants of dropout rates common to their district and year. In the
subsequent school year, the grades constrained by the BST requirement expanded to include both
9th and 10th graders, and, by the 1999-2000 school year, the students in all four grades. The
shaded areas in Table 8 identify the grade-year observations subject to the BST requirement
during the school years for which we have CCD dropout data.
The variation in BST exposure ( X gdt ) across grades and within grades over time implies
that the effect of this policy ( β ) on dropout rates ( y gdt ) can be identified conditional on fixed
effects unique to each grade ( µ g ), district ( α d ) and year ( λt ):
(2)

y gdt = βX gdt + µ g + α d + λt + ε gdt .

Furthermore, because the policy change of interest varies by grade and year in all observed
districts, equation (2) can be extended to condition on fixed effects unique to each district-grade
combination ( µ gd ) and to each district-year combination ( α dt ):
(3)

y gdt = βX gdt + µ gd + α dt + ε gdt .

The standard errors reported for these specifications are clustered at the grade-district level.
Clustering at this cross-sectional level leads to the more conservative (i.e., larger) standard errors
and is consistent with concerns about the possible influence of serial correlation (Bertrand et al.
2004).27

27

Specifically, we found that these standard errors were larger than those that were uncorrected and those calculated
using the conventional White procedure. We also found basically similar results in WLS specifications when the
enrollment base was the weight. However, the WLS estimates did indicate that the 12th grade dropout rate is larger
than that based on OLS. We suspect that this reflects the heterogeneous effects of Minnesota’s exit exam by district
traits (e.g., in larger urban districts), an issue we examine directly in our analysis.
32

The conditional means in Table 7 illustrate how the dropout rates in Minnesota’s public
high schools varied across grades and over time while the BST requirement was implemented.
Casual “difference in differences” comparisons based on these means can illustrate the basic
logic of this identification strategy. For example, the dropout rate for 10th graders fell by 0.13
percentage points (i.e., 5 percent) in the 1997-98 school year, which was when 10th graders were
first subject to the BST requirement. Over that same time period, but in the higher grades not
subject to the requirement (grades 11 and 12), the dropout rates increased by at least 0.18
percentage points. These simple comparisons suggest that the BST requirement reduced the 10th
grade dropout rate in Minnesota.
OLS estimates based on equations (2) and (3) generalize such basic comparisons.
28

However, they also provide a framework for identifying whether the effects of BST

requirements varied by grade. For example, as noted earlier, if these exit exams had a strong
discouragement effect, we might expect to find that they led to particularly large increases in the
9th and 10th grade dropout rates. Alternatively, these exit exams could increase the dropout rate
more substantially among 12th graders if students remain in school and persist in attempting to
pass the BST despite earlier failures. We examine this issue by evaluating the reduced-form
effects associated with interactions between a BST dummy variable and grade-specific dummy
variables.
The basic panel-data research design outlined here (i.e., exploiting the policy variation
within grades over time) has not, to our knowledge, been utilized elsewhere. Therefore, this

28

We report OLS estimates based on a linear probability model. Because a large share of observations have no
dropouts, procedures like a grouped logit are not feasible. However, after making a small imputation to observations
with no dropouts (see Greene 2003, page 689), we did find that a grouped logit specification generated results
similar to those reported here. Another problem with a grouped logit in this context is that, because the dropout rates
tend to be low and the number of students aggregated in each observation fairly large, this specification generates
suspiciously small standard errors (Greene 2003, page 689).
33

approach may provide a useful complement to more conventional panel-data evaluations like that
presented in Section 3. However, like any empirical evaluation, this approach also turns on
implicit, maintained assumptions that may not, in fact, be valid.
In particular, this approach implicitly assumes that the common shocks to dropout rates in
a particular year have a similar effect across all four grades. However, violations of this
assumption could reasonably occur and perhaps bias these results. For example, suppose that,
during the economic expansion of the late 1990s, the dropout rates of 12th graders (who were
generally not subject to exit exams) grew relative to the contemporaneous dropout rates for the
earlier grades (which often were subject to exit exams). This pattern would occur if 12th graders
were particularly likely to leave high school as Minnesota’s unemployment rate fell during the
late 1990s. Similarly, the later increases in Minnesota’s unemployment rate (i.e., during 1999,
2000, and 2001) could have led to particularly large reductions in the dropout rate of 12th
graders, just as 12th graders were also being required to pass the BST. Under this particular
scenario, our reduced-form estimates would have a negative bias because of unrelated year
effects unique to a particular grade.
While it is not possibly to address these important concerns definitively, we can examine
their empirical relevance through selective adjustments to the groups of grades included in our
evaluations. For example, the assumption that there are common grade-year shocks is more
likely to be valid when comparing only near grades (e.g., just 11th and 12th grades). We present
evidence on how these sample restrictions influence our results. As an additional approach, we
also examined specifications that allowed us to condition on grade-year fixed effects by using
contemporaneous dropout data from the neighboring states (i.e., North Dakota and Iowa), which
were well represented in the CCD dropout data over this period and did not introduce exit

34

exams.29 The point estimates from these specifications were basically similar to those described
below (i.e., negative effects in earlier grades and a positive effect in the 12th grade). However,
these point estimates were also more imprecise and their values were somewhat sensitive to
which of the two control states was included. More disturbingly, we found that the dropout rates
in Minnesota had pre-reform trends that differed significantly from Iowa and North Dakota,
which suggests that the identifying assumptions for these specifications were not valid.

4.4 Results
Table 8 presents the basic evaluation results based on the full sample of district-gradeyear observations. The initial specifications (i.e., columns 1 and 2) condition only on grade, year,
and district fixed effects. However, the subsequent models (i.e., columns 3 through 8) introduce
district-grade and district-year fixed effects. These results indicate that, overall, the introduction
of the BST requirement was associated with small and statistically insignificant reductions in the
dropout rates. However, these estimates consistently indicate that the assumption of a common
BST effect across grades obscures heterogeneous effects across grades. More specifically, these
estimates indicate that the introduction of an exit exam reduced the dropout rate in both grades
10 and 11 by approximately 0.3 percentage points (i.e., 9 to 16 percent) but increased the
dropout rate in the 12th grade by a similar amount (i.e., approximately 8 percent). These findings
suggest that Minnesota’s exit-exam policy improved student and school performance in the
earlier high-school grades and did not discourage students from remaining in school. However,
these results also indicate that the existence of the BST requirement constrained students who
could not pass the exam after repeated attempts. A recent study based on longitudinal data from

29

This approach would be analogous to a “difference-in-difference-in-differences” strategy (e.g., Gruber 1994).

35

Texas (Martorell 2005) similarly found that exit exams increased the dropout rate through their
effect on students sitting for their “last chance” exam.
Interestingly, the results in Table 8 are quite similar across specifications that condition
on the fixed-effects interactions. And these interactions have considerable explanatory power,
increasing the R2 by approximately 50 percent. However, the results reported in Table 9 explore
the robustness of these findings further by examining specifications based only on the dropout
rates from more similar (i.e., closer) grades. The corresponding reductions in sample size implied
by this check reduce the precision of the estimates. However, the estimates themselves are
generally quite similar across these different samples. These results suggest that year effects
unique to particular grades are not a source of confounding biases in these evaluations.
The remaining results, which are based on the data from all four grades, examine how the
grade-specific effects of the BST requirement varied by a variety of observable district traits.
The results in the first panel of Table 10 are based on dividing the observed school districts into
quartiles based on their pre-reform position in the distribution of the percent of students who
were black or Hispanic. It should be noted that, there are relatively few minority students in
Minnesota (i.e., roughly 5 percent of students were black and 2 percent Hispanic), even in the
districts in the top quartile of this distribution. Therefore, these estimates should be understood as
identifying the effect for the average student in these districts rather than the effect for a minority
student per se.30 Nonetheless, the results in Table 10 suggest that the dropout effects of the BST
requirement differed noticeably across these districts. For example, in the districts with higher
concentrations of minorities, the BST led to particularly large increases in the 12th grade dropout

30

Because the PUMS analysis suggested that the effects of exit exams differed for black and Hispanic students, we
also considered more disaggregated measures of minority students. However, the results based on these data were
quite similar. Among other things, this could reflect that the Hispanics observed in the CCD files include both native
and foreign-born students.
36

rate (e.g., 0.69 to 0.92 percentage points). However, these results also indicate that the BST led
to relatively large reductions in the grade 10 and 11 dropout rates.31 Interestingly, the BST
requirement had small and statistically insignificant effects in the districts with the lowest
concentration of minority students.
The results in the next panel are based on dividing districts into quartiles based on their
1995 position in the state distribution of the percent of children in poverty. The results based on
the high-poverty districts tend to be statistically imprecise. However, the point estimate for the
12th grade dropout effect is approximately twice as large as that based on the full sample.
Interestingly, these results indicate that the reductions in 10th and 11th grade dropout rates were
concentrated in the lower-poverty districts. In fact, in the lowest-poverty districts, the BST
requirement was also associated with reductions in the 12th grade dropout rate.
The next specification attempts to refine these comparisons by focusing on the
observations from districts in the top halves of the state distributions of percent minority students
and percent of children in poverty. These results suggest that the BST led to increased dropout
rates across all four grades with a particularly large and statistically significant effect on the 12th
grade dropout rate. The final set of results in Table 10 examines the unique effects associated
with a district’s urbanicity. Interestingly, the BST requirement led to a particularly large increase
in the 12th grade dropout rate in urban districts (i.e., over 3 percentage points) and, to a lesser
extent, in rural districts. In contrast, the beneficial effects of the BST requirements (i.e.,
reductions in 10th and 11th grade dropout rates) were largely concentrated in suburban school
districts.

31

The distinct effects of exit exams in high-minority districts were similar in models that excluded the Minneapolis
and St. Paul districts.
37

In sum, the evidence from Minnesota’s experience with exit exams is consistent with
several of the claims made by both proponents and critics of these policies. For example, these
results indicate that the BST requirement was actually associated with reductions in the dropout
rates for earlier high school grades. This result is consistent with the hypothesis that Minnesota’s
exit exam improved student effort and/or school performance.
Mapping these results into an implied change in the high school graduation rate is not
straightforward, in part because these data are based on “event” dropouts who may later reenroll. However, assuming that event dropouts do not return to school and using the pre-reform
dropout rates as a base, the full-sample results (i.e., reductions in the dropout rate in grades 9-11
and an increase in grade 12) imply that the overall high school graduation rate increased by
approximately one half of a percentage point (i.e., a increase of approximately 0.5 percent given
an implied graduate rate of 89.2 percent).
However, critics of exit exams would not be surprised to find that these improvements
were concentrated in lower-poverty and suburban districts. In contrast, the increased dropout
rates were found in urban districts and those with higher shares of minority students and children
in poverty. In fact, calculations based on these point estimates indicate that the implied changes
in the high school graduation rates for these districts were consistently negative. For example, in
urban districts during the 1993-1995 period, the implied high school graduation rate was 75.1
percent. The results in Table 10 imply that this rate fell to 72.7 percent as a result of the BST
requirement, a decrease of approximately 3.2 percent.

38

5. Conclusions

The notion that high school graduates should meet high academic standards has a
universal appeal. The increasing importance of cognitive skills for economic success in recent
years adds a sense of urgency to standards-based reforms in high school. However, some doubt
whether binding standards can effectively improve student or school performance. There are
also concerns about whether standards-based reforms may exacerbate economic inequality by
harming the students most at risk of academic failure. This study attempts this broader debate by
presenting new evidence on the educational and economic consequences of the earliest,
standards-based reform: mandatory exit exams for high school students.
Our results, based on data from the 2000 Census, indicate that exit exams led to
particularly large increases in the dropout rates of black students. Similarly, our analysis of
Minnesota’s recent exit exam, based on the NCES’ Common Core of Data (CCD), indicates that
this graduation requirement increased the dropout rates in school districts with relatively large
concentrations of minority students as well as in urban and high-poverty school districts.
Furthermore, Minnesota’s exit exam also reduced the dropout rates in suburban and low-poverty
school districts. Taken at face value, these findings imply that these standards-based reforms
have exacerbated both poverty and inequality.
However, a number of factors suggest that the implications for poverty reduction of our
state-level experiences with exit exams are not quite so straightforward. For example, our
analysis of data from the 2000 Census provided some evidence that exit exams improved longerterm outcomes (e.g., college matriculation, labor-market outcomes) for Hispanic females and
blacks. These changes could reflect both the signaling and the incentive effects of exit exams.
The possible incentive effects of standards-based reform were also suggested by our evidence

39

that exit exams reduced the early high-school dropout rates in some of Minnesota’s school
districts.
These ambiguities suggest a number of possibly fruitful directions for further research.
For example, as states continue to both introduce exit exams and simultaneously develop richer,
longitudinal data on student achievement, it should become possible to identify how the
incentive effects of exit exams may have changed the distribution of cognitive achievement.
Second, the evidence that exit exams reduced the dropout rates in some districts (e.g., lowpoverty districts) suggests it would be useful to learn more about the mediating factors that may
have facilitated these improvements. Third, it would be useful to develop further evidence on
whether exit exams generally encourage students to drop out during 12th grade and to identify the
implications of this pattern for both targeted remediation and reform.

40

References
Airasian, Peter W. “State Mandated Testing and Educational Reform,” American Journal of
Education, 1987, 95, 3, 393-412.
Angrist, Joshua D. and William N. Evans. "Schooling and Labor Market Consequences of the
1970 State Abortion Reforms," in Research in Labor Economics, Solomon W. Polachek, editor,
Stamford, Conn.: JAI Press, 1999, pages 75-113.
Associated Press State and Local Wire. “Cass Lake-Bena teacher accused of stealing copy of
state test,” April 2, 2001.
Avery, P. G., Beach, R., & Coler, J. (2003, February 16). The impact of Minnesota's "Profile of
Learning" on teaching and learning in English and social studies classrooms, Education Policy
Analysis Archives, 11(7). Retrieved December 23, 2005 from http://epaa.asu.edu/epaa/v11n7/.
Bakst, Brian. “Diplomas denied to fewer seniors because of test error than estimated,”
Associated Press State and Local Wire, August 15, 2000.
Bertrand, M., E. Duflo, and S. Mullainathan. “How Much Should We Trust Differences-indifferences Estimates?” Quarterly Journal of Economics 119(1), 2004: 249-276
Bishop, John H. "Nerd Harassment, Incentives, School Priorities and Learning," in Earning and
Learning: How Schools Matter, Susan E. Mayer, editor, Paul E. Peterson, editor. Brookings
Institution Press, 1999.
Bishop, John H. and Ferran Mane. "The impacts of minimum competency exam graduation
requirements on high school graduation, college attendance and early labor market success,"
Labour Economics 8 (2001), 203-222.
Card, David and Thomas Lemieux. "Dropout and Enrollment Trends in the Postwar Period:
What Went Wrong in the 1970s?" in An Economic Analysis of Risky Behavior Among Youths,
J. Gruber, editor, University of Chicago Press, 2001.
Catterall, James S. "Standards and School Dropouts: A National Study of Tests Required for
High School Graduation," American Journal of Education (November, 1989):1-34.
Cullen, Julie and Randall Reback "Tinkering Towards Accolades: School Gaming under a
Performance Accountability System", working paper, 2006.
Dee, Thomas S. “The 'First Wave' of Accountability,” in No Child Left Behind? The Politics and
Practice of Accountability, Paul Petersen and Martin West, editors, Brookings Institution Press,
2003.
Duncan, B. “Dropouts and the unemployed,” Journal of Political Economy, LXXIII (1965): 121134.

41

David N. Figlio & Lawrence S. Getzler, 2002. "Accountability , Ability and Disability: Gaming
the System," NBER Working Paper 9307, National Bureau of Economic Research, Inc.
Gayler, Keith, Naomi Chudowsky, Nancy Kober, Madlene Hamilton, Margery Yeager. “State
High School Exit Exams: A Maturing Reform,” Center on Education Policy, Washington, DC,
August 2004.
Greene, Jay P. and Marcus A. Winters. “Pushed out or pulled up? Exit exams and dropout rates
in public high schools,” Manhattan Institute, New York, New York, 2004.
Greene, William H. Econometric Analysis, 5th Edition. Prentice Hall: Upper Saddle River, New
Jersey, 2005.
Gruber, Jonathan., 1994. “The Incidence of Mandated Maternity Benefits,” American Economic
Review 84(3):622-641.
Jacob, Brian A. "Accountability, Incentives and Behavior: Evidence from School Reform in
Chicago" Journal of Public Economics 89(5-6), 2005
Jacob, Brian A. and Steven Levitt. "Rotten Apples: An Investigation of the Prevalence and
Predictors of Teacher Cheating" Quarterly Journal of Economics 118(3), 2003
Jacob, Brian A. "Getting Tough? The Impact of High School Graduation Exams," Educational
Evaluation and Policy Analysis 23(2), 2001: 99-122.
Kane, Thomas. "College entry by blacks since 1970: The role of college costs, family
background, and the returns to education," Journal of Political Economy 102, 1994, 878-911.
Koretz, Daniel M. and Sheila M. Barron. “The Validity of Gains in Scores on the Kentrucky
Instructional Results Information System (KIRIS),” RAND, 1998.
Lillard, Dean R. and Philip P. DeCicca. "Higher standards, more dropouts? Evidence within and
across time," Economics of Education Review 20 (2001) 459-473.
Martorell, Francisco (2004). “Do High School Graduation Exams Matter? A Regression
Discontinuity Approach.” Working paper, University of California, Berkeley.
Murnane, Richard J. and Frank Levy. "Will Standards-Based Reforms Improve the Education of
Students of Color?" National Tax Journal LIV(2), June 2001: 401-415.
National Commission on Excellence in Education. A Nation at Risk: The Imperative for
Educational Reform, April 1983.
Olson, Lynn. "Room to Maneuver," Education Week 25(15), December 15, 2005, S1-S5.

42

Phillips, Meredith and Tiffani Chin. "Comment," in Brookings Papers on Education Policy 2001,
edited by D. Ravitch, Brookings Institution Press, 2001.
Pipho, Chris. "Minimum Competency Testing in 1978: A Look at State Standards," Phi Delta
Kappan 59 (9), 585-8, May 1978.
Popham, W. James. "The Case for Minimum Competency Testing," Phi Delta Kappan 63(2),
October 1981, 89-91.
Ruggles, Steven, Matthew Sobek et. al. Integrated Public Use Microdata Series: Version 2.0.
Minneapolis: Historical Census Projects, University of Minnesota, http://www.ipums.umn.edu,
1997.
Shah, Allie. “More 12th graders fail skills tests; New writing test, stricter scoring affect results,”
Minneapolis Star Tribune, June 1, 2001, page 1A.
Smith, Maureen M. and Duchesne Paul Drew. “Skills-test failure rate high for minority, poor
students,” Minneapolis Star Tribune, May 25 1996, page 1A.
Sullivan, Patricia, Margery Yeager, Naomi Chudowsky, Nancy Kober, Eileen O’Brien, and
Keith Gayler. “State High School Exit Exams: States Try Harder but Gaps Persist,” Center on
Education Policy, Washington, DC, August 2005.
Steele, C.M. "A threat in the air - How stereotypes shape intellectual identity and performance,"
American Psychologist 52: (6) 613-629 June 1997
Steele, C.M. "Stereotyping and its threats are real," American Psychologist 53: (6) 680-681 June
1998
Warren, John Robert & Melanie R. Edwards. 2005. “High School Exit Examinations and High
School Completion: Evidence from the Early 1990s.” Educational Evaluation and Policy
Analysis 27:53-74.
Warren, John Robert. 2005. "State-Level High School Completion Rates: Concepts, Measures,
and Trends." Education Policy Analysis Archives 13:1-35.
Warren, John Robert and Krista N. Jenkins "High Stakes Graduation Tests and High School
Dropout in Texas and Florida, 1979–2001," Sociology of Education, 78, 2005: 122-143.
Warren, John Robert, Krista N. Jenkins, Rachael B. Kulick "High School Exit Examinations and
State-Level Completion and GED Rates, 1975-2002,” working paper, December 2005.

43

Table 1: Descriptive Statistics for the PUMS Analysis
Full Sample
Source (definition)

Min

Max

Less Difficult
Exit Exam
Mean
SD

More Difficult
Exit Exam
Mean
SD

Mean

SD

0.873

0.333

0.859

0.348

0.826

0.379

0.573

0.495

0.568

0.495

0.508

0.500

0.755

0.430

0.740

0.439

0.676

0.468

615
6.080

1178
0.802

617
6.082

1205
0.795

380
5.624

807
0.745

Dependent Variables
High school graduate
Attended college
Employed
Average weekly earnings
Ln(average weekly earnings)
Main Independent Variables

2000 PUMS (completed high school –
may or may not have obtained further
0
1
education)
2000 PUMS (enrolled in college – may
or may not have obtained further
0
1
education)
2000 PUMS (those not in the labor
force are included as unemployed)
0
1
2000 PUMS (total annual salary income
divided by number of weeks worked)
0.077 325000
2000 PUMS
-2.565 12.692

Various sources (in effect for the high
school graduating class in the
respondent’s state-of-birth in the year
that the respondent was 17 years old;
covers material at below 9th grade level)
Less difficult exit exam (EE)
Various sources (covers material at 9th
grade level or higher
More difficult EE
Moderately rigorous course
Various sources (at least 3 English, 2
graduation requirements (CGR) social studies, 1 math, 1 science)
Various sources (at least 4 English, 3
Very rigorous CGR
social studies, 2 math, 2 science)
Individual Covariates
2000 PUMS
Female
2000 PUMS
Black
2000 PUMS
Hispanic

44

0

1

0.317

0.465

1.000

0.000

0.000

0.000

0

1

0.053

0.224

0.000

0.000

1.000

0.000

0

1

0.746

0.436

0.444

0.497

0.516

0.500

0

1

0.234

0.423

0.456

0.498

0.484

0.500

0
0
0

1
1
1

0.506
0.135
0.033

0.500
0.342
0.178

0.509
0.212
0.027

0.500
0.409
0.161

0.501
0.168
0.068

0.500
0.374
0.252

Enrolled in school
High school graduate
Some College
BA
State Level Time-Varying
Covariates

2000 PUMS
2000 PUMS (completed high school,
but did not obtain any further education)
2000 PUMS (completed high school
and enrolled in college and/or obtained
an AA degree)
2000 PUMS (obtained a BA degree or
higher)

0

1

0.152

0.359

0.152

0.359

0.327

0.469

0

1

0.300

0.458

0.291

0.454

0.318

0.466

0

1

0.354

0.478

0.337

0.473

0.415

0.493

0

1

0.219

0.414

0.231

0.422

0.093

0.290

0.180

0.068

0.021

0.150

0.036

0.148

0.030

13.050 11.647

0.832

0.064

0.015

0.058

0.009

0.272

0.139

0.036

11.754

0.702

12.148

0.401

2698

727

362

802

352

813

336

27.400 17.965

2.496

17.082

1.727

16.133

1.182

50647

27242

8757

28305

8020

34309

5320

1
37

0.015
0.845

0.121
3.219

0.019
0.859

0.137
0.348

0.035
0.826

0.184
0.379

Statistical Abstract of the U.S. (in
respondent’s state-of-birth when the
Poverty rate
0.024
respondent was 17 years old)
Statistical Abstract of the U.S. (in
respondent’s state-of-birth when the
Unemployment rate
8.814
respondent was 17 years old)
Ln(number of 18 year olds in Census (in respondent’s state-of-birth
the state)
when the respondent was 18 years old) 0.029
State of Washington Higher Education
Coordinating Board (in respondent’s
Average in-state tuition at
state-of-birth when the respondent was
17 years old)
0.000
lowest level state college
Digest of Educational Statistics (in
respondent’s state-of-birth when the
K-12 student:teacher ratio
1.900
respondent was 17 years old)
Digest of Educational Statistics (in
Average K-12 teacher salary
respondent’s state-of-birth when the
11448
($2000)
respondent was 17 years old)
Various sources (policy in respondent’s
State issued school report cards state-of-birth when the respondent was
for K-12
12 years old)
0
Various sources
Number of executions
0

45

Table 2: Probit estimates of the effect of high school graduation requirements on high school completion
Independent Variables
(1)
(2)
(3)
(4)
(5)
-.001
-.002
Any exit exam
(.003)
(.002)
-.002
-.002
-.005**
Less difficult exit exam
(.002)
(.002)
(.001)
-.005
-.006*
-.007**
More difficult exit exam
(.003)
(.003)
(.003)
-.001
-.002
Any course graduation requirements
(.003)
(.002)
Moderately difficult course graduation
-.002
-.002
-.002
requirements
(.002)
(.002)
(.002)
Very difficult course graduation
.001
.001
.000
requirements
(.002)
(.002)
(.002)
Number of years following
introduction of exit exams
Number of state executions when
.0003**
0.0001
individual was 18
(.0001)
(0.0002)
Mean of the dependent variable
.873
.873
.873
.873
.873
State-year controls
N
Y
Y
Y
Y
Division-specific cubic time trends
N
N
N
N
Y
Number of observations
2925005
2925005
2925005
2925005
2925005
Notes: The unit of observation is the individual. The data comes from the 2000 PUMS. The sample includes individuals age 20-38 on census
day. Residents from Nebraska and the District of Columbia are excluded. Only individuals indicating race as white, Black or Hispanic are
included. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation
requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science.
Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in
science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth. State-year controls include the unemployment rate, the natural log of the number of 18 year olds, the poverty rate, the average teacher salary
and the average student:teacher ratio, and an indicator for whether the state issued report cards for K-12 schools. The marginal effect evaluated at
the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for clustering of errors within state-of-birth.
*=significant at the 10 percent level. **= significant at the 5 percent level.

46

Table 3: Probit estimates of the effect of high school graduation requirements on high school completion by race and gender
White
Black
Hispanic
White
Black
Hispanic
male
male
male
female
female
female
Independent Variables
(1)
(2)
(3)
(4)
(5)
(6)
(7)
-.005**
-.005**
-.013**
.032
-.0002
-.006
.0003
Less difficult exit exam
(.001)
(.002)
(.005)
(.021)
(.0017)
(.004)
(.0188)
-.006**
-.006*
-.018**
.023
-.002
-.021**
.032
More difficult exit exam
(.003)
(.003)
(.008)
(.032)
(.003)
(.008)
(.019)
Moderately difficult course
-.002
.0003
-.003
.007
-.003*
-.003
.005
graduation requirements
(.002)
(.0020)
(.005)
(.016)
(.002)
(.005)
(.014)
Very difficult course graduation
-.0002
.005**
-.007
.008
-.004*
-.001
.008
requirements
(.0025)
(.003)
(.006)
(.016)
(.002)
(.006)
(.018)
Mean of the dependent variable
.873
.878
.752
.701
.908
.817
.755
Number of observations
2925005
1212102
184909
47044
1221388
210997
48543
Notes: The unit of observation is the individual. The data comes from the 2000 PUMS. The sample includes individuals age 20-38 on census
day. Residents from Nebraska and the District of Columbia are excluded. Only individuals indicating race as white, Black or Hispanic are
included. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation
requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science.
Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in
science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend, and the following state-year controls: the unemployment rate, the natural log of the number of 18 year
olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for
K-12 schools. The marginal effect evaluated at the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for
clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level.
All

47

Table 4: Probit estimates of the effect of high school graduation requirements on college enrollment by race and gender
Dependent variable = College Enrollment
White
Black
Hispanic
White
Black
Hispanic
All
male
male
male
female
female
female
Independent Variables
(1)
(2)
(3)
(4)
(5)
(6)
(7)
Less difficult exit
-.001
-.004
.005
.026
.001
.006
.018
exam
(.003)
(.004)
(.005)
(.026)
(.003)
(.004)
(.017)
More difficult exit
-.004
-.003
.010
.047
-.007
-.005
.083**
exam
(.006)
(.007)
(.009)
(.033)
(.007)
(.006)
(.027)
Moderately difficult
-.005
-.0001
-.008
.007
-.006
-.005
-.005
course graduation
(.004)
(.0042)
(.008)
(.017)
(.004)
(.007)
(.015)
requirements
Very difficult course
.001
.008
-.006
.004
-.004
.001
.009
graduation
(.005)
(.005)
(.010)
(.019)
(.005)
(.010)
(.020)
requirements
Mean of the dependent
0.573
.561
.387
.372
.638
.504
.449
variable
Number of
2925005
1212102
184909
47051
1221388
211007
48546
observations
Notes: The unit of observation is the individual. The data comes from the 2000 PUMS. The sample includes individuals age 20-38 on census
day. Residents from Nebraska and the District of Columbia are excluded. Only individuals indicating race as white, Black or Hispanic are
included. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation
requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science.
Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in
science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend and the following state-year controls: the unemployment rate, the natural log of the number of 18 year
olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for
K-12 schools. The marginal effect evaluated at the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for
clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level.

48

Table 5: Probit estimates of the effect of high school graduation requirements on employment by race and gender
Dependent variable = Employed
White
Black
Hispanic
White
Black
Hispanic
All
male
male
male
female
female
female
Independent Variables
(1)
(2)
(3)
(4)
(5)
(6)
(7)
.0005
-.001
-.009*
-.019
.009*
-.001
.006
Less difficult exit exam
(.0024)
(.003)
(.005)
(.020)
(.005)
(.005)
(.010)
.003
-.002
.004
-.028
.009*
-.009
.031*
More difficult exit exam
(.004)
(.004)
(.009)
(.030)
(.005)
(.007)
(.018)
Moderately difficult course
-.0002
.0005
-.001
-.023
.003
-.010
.043**
graduation requirements
(.0017)
(.0025)
(.006)
(.017)
(.004)
(.006)
(.012)
Very difficult course graduation
-.002
.002
-.0002
-.006
-.004
-.008
.050**
requirements
(.002)
(.003)
(.0063)
(.020)
(.004)
(.007)
(.017)
Mean of the dependent variable
.755
.840
.600
.713
.721
.643
.627
Number of observations
2925005
1212102
184909
47053
1221388
211007
48453
Notes: The unit of observation is the individual. The data comes from the 2000 PUMS. The sample includes individuals age 20-38 on census
day. Residents from Nebraska and the District of Columbia are excluded. Only individuals indicating race as white, Black or Hispanic are
included. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation
requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science.
Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in
science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend, and the following state-year controls: the unemployment rate, the natural log of the number of 18 year
olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for
K-12 schools. The marginal effect evaluated at the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for
clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level.

49

Table 6: OLS estimates of the effect of high school graduation requirements on earnings by race and gender
Dependent variable = Ln(Average weekly wages)
White
Black
Hispanic
White
Black
Hispanic
All
male
male
male
female
female
female
Independent Variables
(1)
(2)
(3)
(4)
(5)
(6)
(7)
-.005
-.014*
.012
-.040
-.009
.005
-.004
Less difficult exit exam
(.005)
(.008)
(.008)
(.034)
(.006)
(.007)
(.021)
-.012
-.027*
.022*
-.071*
-.022**
.028*
-.005
More difficult exit exam
(.009)
(.016)
(.011)
(.039)
(.011)
(.015)
(.038)
Moderately difficult course
-.001
-.006
-.002
-.011
.004
.007
.001
graduation requirements
(.005)
(.007)
(.009)
(.023)
(.006)
(.008)
(.028)
Very difficult course graduation
.003
.003
-.012
.011
.004
-.004
.021
requirements
(.007)
(.009)
(.010)
(.041)
(.007)
(.009)
(.032)
Mean of the dependent variable
6.080
6.289
6.023
6.057
5.910
5.847
5.804
Number of observations
2429250
1073357
139183
39109
974508
166250
36843
R-squared
0.1945
0.2063
0.1185
0.1361
0.1188
0.1063
0.0992
Notes: The unit of observation is the individual. The data comes from the 2000 PUMS. The sample includes individuals age 20-38 on census
day. Residents from Nebraska and the District of Columbia are excluded. Only individuals indicating race as white, Black or Hispanic are
included. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation
requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science.
Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in
science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend, and the following state-year controls: the unemployment rate, the natural log of the number of 18 year
olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for
K-12 schools. Standard errors shown in parentheses are adjusted to account for clustering of errors within state-of-birth. *=significant at the 10
percent level. **= significant at the 5 percent level.

50

Table 7 - Mean dropout rates by grade and year, Minnesota school districts, 1993-94 to 2001-02 school years
Grade
9
10
11
12

1993-94

1994-95

1995-96

1996-97

1997-98

1998-99

1999-00

2000-01

2001-02

1.15
2.41
3.37
3.44

1.14
2.71
3.26
4.07

1.27
2.70
3.78
4.21

1.29
2.71
3.73
3.89

1.16
2.58
3.92
4.48

0.90
2.29
3.00
3.68

0.91
1.95
3.18
3.94

0.80
1.94
2.67
3.97

0.73
1.75
2.99
4.06

The unit of observation is the grade (9-12) within a school district in a given school year (n = 10,502). The sources of these data are the annual
Common Core of Data (CCD) universe surveys. The shaded areas identify grade-year combinations, which were required to pass Minnesota’s
Basic Skills Tests (BST).

51

Table 8 – Estimated effects of Minnesota’s Basic Skills Test on dropout rates
Independent variable

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

-

-.164
(.129)
-

-

-.088
(.135)
-

-

-.115
(.134)
-

-

BST x GRADE 9

-.136
(.134)
-

BST x GRADE 10

-

BST x GRADE 11

-

BST x GRADE 12

-

BST

R2
District effects
Year effects
Grade effects
District-grade effects
District-year effects

-.140
(.155)
-.419**
(.172)
-.356*
(.202)
.332*
(.177)

-

-.197
(.158)
-.432**
(.156)
-.372**
(.165)
.306**
(.152)

-

-.119
(.157)
-.358**
(.172)
-.284
(.211)
.361*
(.187)

-

-.179
(.165)
-.364**
(.151)
-.299*
(.175)
.331**
(.166)

.5252

.5262

.6827

.6836

.6305

.6314

.7824

.7833

yes
yes
yes
no
no

yes
yes
yes
no
no

no
yes
no
yes
no

no
yes
no
yes
no

no
no
yes
no
yes

no
no
yes
no
yes

no
no
no
yes
yes

no
no
no
yes
yes

The unit of observation is the grade (9-12) within a school district in a given school year (n=10502). The sources of these data are the annual
Common Core of Data (CCD) universe surveys from 1993-94 to 2001-2002. Standard errors, adjusted for clustering at the grade-district level, are
reported in parentheses. *=significant at the 10 percent level. **= significant at the 5 percent level.

52

Table 9 – Estimated effects of Minnesota’s exit exam on dropout rates by sample traits
Grades in sample
Full sample (Grades 9, 10, 11, and 12)
Grades 11 and 12
Grades 10, 11, and 12
Grades 10 and 11
Grades 9, 10, and 11
Grades 9 and 10

Estimated effect of BST by grade
Grade 9
Grade 10 Grade 11 Grade 12

Sample size

-.179
(.165)

-.364**
(.151)

-.299*
(.175)

.331**
(.166)

10,502

-

-.301*
(.176)
-.345
(.220)
-.408**
(.182)
-.411**
(.179)

.344
(.213)
.383*
(.198)
-

5276

-

-.241
(.211)
-.247
(.181)
-.259
(.222)
-.318
(.215)
-

-

7870

-

5226

-.215
(.201)
-.190
(.204)

7907
5275

The unit of observation is the grade (9-12) within a school district in a given school year (n = 11,740).
The sources of these data are the annual Common Core of Data (CCD) universe surveys. All models
condition on district-year and district-grade fixed effects. Standard errors, adjusted for clustering at the
grade-district level, are reported in parentheses. *=significant at the 10 percent level. **= significant at
the 5 percent level.

53

Table 10 – Estimated effects of Minnesota’s exit exam on dropout rates by district traits
Districts in sample

Estimated effect of BST by grade
Grade 9
Grade 10 Grade 11 Grade 12

Sample
size

-.179
(.165)

-.364**
(.151)

-.299*
(.175)

.331**
(.166)

10,502

-.054
(.291)
-.250
(.283)
-.499
(.354)
.103
(.383)

-.618**
(.266)
-.272
(.273)
-.542*
(.321)
-.015
(.334)

-.194
(.262)
-.171
(.306)
-.700*
(.412)
-.114
(.392)

.924**
(.277)
.689**
(.296)
-.329
(.338)
.066
(.390)

2623

Percent of children in poverty: Bottom quartile

.044
(.408)
.207
(.280)
-.472*
(.251)
-.489
(.357)

-.182
(.357)
.163
(.251)
-.750**
(.242)
-.677**
(.326)

.115
(.413)
.100
(.277)
-.195
(.238)
-1.192**
(.417)

.699
(.434)
.625**
(.272)
.496*
(.298)
-.478*
(.289)

Above median in percent of students minority
& percent of children in poverty

.216
(.332)

.179
(.303)

.405
(.339)

1.285**
(.313)

2132

.445
(.577)
-.413
(.294)
-.129
(.211)

-.365
(.757)
-.840**
(.272)
-.205
(.189)

-.314
(.928)
-.669**
(.263)
-.177
(.230)

3.13**
(1.07)
-.131
(.239)
.357*
(.212)

316

Full sample
Percent of students minority: Top quartile
Percent of students minority: 3rd quartile
Percent of students minority: 2nd quartile
Percent of students minority: Bottom quartile
Percent of children in poverty: Top quartile
Percent of children in poverty: 3rd quartile
Percent of children in poverty: 2nd quartile

Urban
Suburban
Rural

2627
2624
2628
2596
2626
2640
2640

2351
7835

The unit of observation is the grade (9-12) within a school district in a given school year (n = 10502). The
sources of these data are the annual Common Core of Data (CCD) universe surveys. All models condition
on district-year and district-grade fixed effects. Standard errors, adjusted for clustering at the gradedistrict level, are reported in parentheses. *=significant at the 10 percent level. **= significant at the 5
percent level.

54

Table A1: High School Exit Exams
1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005
State
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
Alabama
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
Arkansas
0
0
1
1
1
1
1
1
1
1
1
1
1
1
0
0
0
0
0
0
0
0
0
0
0
0
0
Delaware
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
Florida
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
2
Georgia
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
0
0
0
0
0
Hawaii
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
2
2
2
2
2
2
Indiana
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
2
2
2
Louisiana
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
Maryland
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
2
2
2
Mass.
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
Minnesota
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
Mississippi
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
Nevada
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
2
New Jersey
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
New Mexico
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
2
2
2
2
2
2
New York
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
North Carolina 0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
2
2
2
2
2
2
2
2
2
2
2
2
Ohio
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
South Carolina 0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
2
2
Tennessee
0
0
0
0
0
0
0
0
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
2
2
2
2
Texas
0
0
1
1
1
1
1
1
1
1
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
2
2
Virginia
Notes: Data is drawn from a variety of sources, including a comprehensive Lexis-Nexis search of news articles from the relevant states from
roughly 1978-forward, and from a variety of academic articles. The coding is as follows:
• 0 = state did not have a high school exit exam for the graduating class in that year
• 1 = state had a high school exit exam for the graduating class in that year that tested material below the 9th-grade level
• 2 = state had a high school exit exam for the graduating class in that year that tested material on the 9th-grade level or above

55

