NBER WORKING PAPER SERIES

SUPERMODULARITY AND TIPPING
Geoffrey Heal
Howard Kunreuther
Working Paper 12281
http://www.nber.org/papers/w12281
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2006

Heal is at Columbia Business School and Columbia School of International Affairs, gmh1@columbia.edu.
Kunreuther is at the Wharton School of the University of Pennsylvania, kunreuther@wharton.upenn.edu. We
are especially grateful to Larry Samuelson for assistance with this paper, and also grateful to Doug Bernheim,
Vince Crawford and two referees for constructive comments. The views expressed herein are those of the
author(s) and do not necessarily reflect the views of the National Bureau of Economic Research.
©2006 by Geoffrey Heal and Howard Kunreuther. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is
given to the source.

Supermodularity and Tipping
Geoffrey Heal and Howard Kunreuther
NBER Working Paper No. 12281
May 2006
JEL No. C72, D80, H23
ABSTRACT
We model tipping as a game-theoretic phenomenon and investigate the connection between
supermodular games, tipping of equilibria and cascading, and apply the results to issues that arise
in the context of homeland security and computer security. We show that tipping and cascading can
occur in supermodular games and that "increasing differences"is a sufficient condition for tipping.
Supermodularity and tipping of equilibria are closely related. We relate our results to Schelling’s
early work on tipping.
Howard Kunreuther
Operations and Information Management
The Wharton School
University of Pennsylvania
Philadelphia, PA 19104-6366
and NBER
kunreuther@wharton.upenn.edu

1

Introduction

This paper brings together two very diﬀerent literatures, one on tipping and cascading, and one on supermodularity and strategic complementarity. The idea of tipping
was made widely known in economics by Thomas Schelling’s pathbreaking work in
1978 [13], although it goes back further as his book indicates.1 The idea is that a small
change in the state of a system can cause a large jump in its equilibrium.2 In one of
the best-known of Schelling’s examples the state variable was the racial composition
of a neighborhood, and at the tipping point a small increase in the proportion of
non-whites led to a new equilibrium with a sharply lower fraction of whites. Malcolm
Gladwell’s recent best-seller [5] popularized the idea of tipping and intimated its applicability to a vast range of phenomena. Cascading is a refined form of tipping (see
Avinash Dixit [3]) in which the movement from one equilibrium to another occurs
through a classic domino eﬀect. A change of strategy by agent one leads agent two to
follow suit, and the changes by one and two together lead agent three to follow and
so on. There is a step-by-step movement to a new equilibrium, initiated by a change
on the part of one agent.
It is remarkable that though tipping and cascading are so widely referenced in the
social sciences, they have not previously been modelled in a game-theoretic framework
or linked to a broader context (with the exception of Dixit’s paper [3]). We argue
1

See also Schelling 1971 [12]. William Easterly 2004 [4] gives a more detailed history of this
concept.
2
Intuitively it seems that there should be a connection with catastrophe theory, although this
point does not seem to have been explored in the literature.

1

in this paper that tipping and cascading are natural outcomes in a wide variety of
problems that exhibit supermodularity.
The literature on supermodularity also goes back to the 1970s, dating to the work
of Donald Topkis [14] [15], although it at the literature on tipping have evolved quite
separately. The idea of supermodularity was developed further by Xavier Vives [16]
and Paul Milgrom and John Roberts [11]: since then it has been used widely in
the literatures on game theory and comparative statics. Jeremy Bulow et al. [1]
introduced the related idea of strategic complementarity. Supermodularity allows
us to identify a class of games for which rather general comparative static results
are available, and builds on the idea of increasing diﬀerences, which means that the
return to a move by one agent can be increased by actions by other agents.
Our work has evolved from research on strategic interdependence in the context
of national security. Originally motivated by a desire to understand the impact of
interdependence in airline security after 9/11/01, it has evolved to a more general
model of how interdependence aﬀects the incentive to invest in protective measures
for any kind of network, including electronic networks such as computer networks.
(For the national security applications see our papers [6] [9], and for computer network applications see Michael Kearns [8].) One of our early findings was that many
networks exhibit a tipping phenomenon with respect to investments in security: for
certain values of state variables few agents invest and security is low. A small change
can lead to everyone investing with a massive increase in security, a finding that might

2

have important policy implications. In trying to understand why tipping occurs we
inevitably are drawn to supermodularity, as this is a template of a particular type of
interdependence that is well-understood.
Our central result is that supermodularity and tipping/cascading are related. In
particular, the “increasing diﬀerences" property that is linked to supermodularity is
a key to tipping and cascading, and indeed is a suﬃcient condition for tipping. A
necessary and suﬃcient condition for the equilibria of a symmetric game to exhibit
the tipping phenomenon is that the game show “suﬃcient increasing diﬀerences.” In
the case of symmetric games we give a highly intuitive definition of what it is to show
suﬃcient increasing diﬀerences and then use this to describe a simple and intuitive
algorithm for constructing the smallest possible tipping set, i.e. the smallest set such
that when all its members change strategy then all agents outside the set follow suit.
We show similar results for cascading. A key part of the proof is providing a definition
of tipping in terms of the properties of Nash equilibria, rather than as the equilibria
of dynamic processes as in the generally-used examples.
Intuitively it is clear that there is a connection between strategic complementarity
and tipping, and hence between supermodularity and tipping. The essence of strategic
complementarity is that one agent making a particular move makes that same move
more attractive to other agents. It then follows that this may lead to tipping. However
there does not seem to be a formal analysis of this relationship, which is what we are
oﬀering here. After developing the theoretical relationship between supermodularity

3

and tipping, we illustrate our results with the airline security problem that motivated
our original research. More specifically we show how the main theorem can be used
to identify airlines that play a critical role in the adoption of higher standards of
security in a decentralized system. (A numerical application with real airline data
can be found in [6].)

2

Tipping and supermodularity

Consider a game with N players i ∈ {1, 2, ..., N } , each choosing a strategy si in the
discrete strategy space {0, 1} and having a utility function ui : {0, 1}N → R. We have
a natural order on the hypercube {0, 1}N given by the standard vector ordering on
RN , and with this ordering denoted ≥ it forms a complete lattice.3
We assume that each agent’s payoﬀ function ui shows increasing diﬀerences in the
choices of strategies by other agents. Formally this means that if 0i or 1i denotes a
0 or 1 in the ith position of the vector S of all strategy choices and S−i denotes the
0

vector of choices of all agents other than i, and for S−i ≥ S−i , then for any i
³
´
³
´
0
0
0
ui 1i , S−i −ui 0i , S−i ≥ ui (1i , S−i )−ui (0i , S−i ) with strict inequality if S−i > S−i
(1)

This implies that the payoﬀ to agent i from changing from 0 to 1 increases if
another agent changes from 0 to 1. This property is implied by supermodularity of
3

We use A > B to show that A exceeds B in at least one component and is no less in all and
A ≥ B to show that it is at least as great in all components.

4

the functions ui in the sense
³ 0´
³ 0
´
³ 0
´
¡ ¢
ui S + ui S ” ≤ ui S ∨ S ” + ui S ∧ S ”
0

0

where S ∨S ” and S ∧S ” denote respectively the least upper bound and greatest lower
0

bounds of the vectors S and S ” respectively (for details see Milgrom and Roberts
[11]).
We shall assume that the game has (at least) two Nash equilibria, {0, 0, .., 0} and
{1, 1, .., 1}. We also assume that these equilibria are Pareto ranked with the latter
dominating, as this is the case in the applications that motivate this paper. We shall
refer to these on occasions as the eﬃcient and ineﬃcient equilibria. However it is
important that none of the propositions to be established below depend in any way
on the equilibria being Pareto ranked: they depend only in the increasing diﬀerences
assumption (1).4 A policy-maker will naturally be interested in ruling out the inefficient equilibrium and ensuring an eﬃcient outcome, as in a coordination problem
(Vincent Crawford [2], Walter Heller et al. [7]). We study conditions under which it
is possible to do this by changing the strategies of a subset of the players. This is the
tipping problem: a “tipping set” of agents can by changing their strategies shift the
equilibrium from one extreme to the other.
4

Milgrom and Roberts in Theorem 5 and corollaries establish that a supermodular game has
largest and smallest serially undominated strategy profiles and that these are Nash equilibria. The
zero and one profiles are undominated, but we have not assumed supermodularity, just increasing
diﬀerences.

5

Let T be an arbitrary subset of players. We are going to investigate whether agents
in the set T can “tip” the system, i.e. can by changing strategy shift the equilibrium
from {0, 0, ...0} to {1, 1, ...1} . To do this we define the T − game as the game above
with the additional constraint that for all players in T the only permissible strategy
choice is si = 1. If the T − game has as its only equilibrium {1, 1, ...., 1} then we say
that T is a tipping set or T − set. The key point here is that when agents in T choose
strategy 1, this is also the best response for all agents not in T .
A set is a minimal T − set if it is a T − set and no subset is. It is a smallest
T − set if it is a T − set and no other T − set has fewer members. Clearly if T is a
T − set then getting the members of T to adopt strategy 1 will rule out the ineﬃcient
equilibrium: members of the set T can tip the equilibrium, can force the system to
the eﬃcient outcome. If T is a small subset of N then this can be an important policy
tool.
Below we characterize these various types of T − sets and show that in certain
cases the smallest T − set can be formed by a simple algorithm, in which we rank
agents by a very natural characteristic and then pick the first K ≤ N in this ranking.
Intuitively the characteristic is a measure of the changes in others agents’ payoﬀs
that result when an agent changes her strategy from 0 to 1. It is a measure of the
externalities that an agent generates, and a measure of the degree of supermodularity.
The significance of this result is that by ensuring that agents in a T − set choose
strategy 1 the authorities can rule out the ineﬃcient equilibrium: alternatively if the

6

system is at the ineﬃcient equilibrium then it can be“tipped” to the eﬃcient one by
changes of strategy on the part of this subset of players. Such changes may be induced
outside the formal structure of the game, for example by side payments or other
financial incentives, or alternatively by regulation. As the subset in a smallest T −set
may be very small, this may be an attractive policy from a regulator’s perspective.
It also provides a possible resolution of the coordination problem for supermodular
games, one not previously noted.
Key to our analysis is the eﬀect on agent j 0 s payoﬀ of changing strategy from
0 to 1, and how this eﬀect changes when another agent, say i, also changes from 0
to 1. By the increasing diﬀerences property (1), we know that the change by i will
increase the eﬀect on j 0 s payoﬀ of the change by j. Let s−i−j , 1i , 0j denote the vector
of strategies where all agents k other than i, j are choosing sk ∈ s−i−j and i, j are
choosing 1 and 0 respectively. Define

∆j (i = 0, s−i−j ) = uj (s−i−j , 0i , 1j ) − uj (s−i−j , 0i , 0j )
and

∆j (i = 1, s−i−j ) = uj (s−i−j , 1i , 1j ) − uj (s−i−j , 1i , 0j )
These are the returns to agent j from changing from 0 to 1 when agent i chooses
either 0 (in the first line) or 1 (in the second line) and everyone else chooses s−i−j .

7

The diﬀerence between these returns is

∆ij (s−i−j ) = ∆j (i = 1, s−i−j ) − ∆j (i = 0, s−i−j ) ≥ 0

(2)

∆ij (s−i−j ) = [uj (s−i−j , 1i , 1j ) − uj (s−i−j , 1i , 0j )] −

(3)

That is,

[uj (s−i−j , 0i , 1j ) − uj (s−i−j , 0i , 0j )]

This is the increase in the return to j 0 s change of strategy as a result of i0 s change
of strategy, and from the condition of increasing diﬀerences (1) we know that this
is positive. It is a measure of the positive externalities generated by a change of
i0 s strategy, such externalities being guaranteed by increasing diﬀerences. As more
agents i change their strategy from 0 to 1 there will be a greater increase in utility
for the other agents j in the system.
We are interested in the conditions under which an ineﬃcient equilibrium can be
tipped to an eﬃcient one, and so focus on equations (2) and (3) when all agents other
than i and j are choosing strategy 0 :

∆ij (0) =

£ ¡ N−2
¢
¡
¢¤
uj 0
, 1i , 1j − uj 0N−2 , 1i , 0j −
¤
¢
£ ¡ N−2
, 0i , 1j − uj , (0N−2 , 0i , 0j )
uj 0
8

(4)

where 0N−2 indicates that there are N − 2 zeros in the positions other than i and j.
Proposition 1 Under the assumption 1 of increasing diﬀerences there exists a tipping set that tips the equilibrium with all 0s to that with all 1s.
Proof. Consider the following sequence of inequalities, which link the equilibrium
with all zeros to that with all ones in a series of steps in each of which an additional
agent changes strategy from zero to one, and which hold by the increasing diﬀerences
(1) property.

¡
¢
¡
¢
¡
¢
¡
¢
ui 0N−1 , 1i − ui 0N−1 , 0i < ui 0N−2 , 11 , 1i − ui 0N −2 , 11 , 0i <

(5)

¡
¢
¡
¢
ui 0N−3 , 11 , 12 , 1i − ui 0N−3 , 11 , 12 , 0i < ...... <
ui (11 , 12 , ..., 1N−1 , 1i ) − ui (11 , 12 , ..., 1N−1 , 0i )

If we take the first inequality

¡
¢
¡
¢
¡
¢
¡
¢
ui 0N−1 , 1i − ui 0N−1 , 0i < ui 0N−2 , 11 , 1i − ui 0N−2 , 11 , 0i
we see that the payoﬀ to agent i from a strategy change is raised when agent 1 also
picks strategy 1. The second inequality

¡
¢
¡
¢
¡
¢
¡
¢
ui 0N−2 , 11 , 1i − ui 0N −2 , 11 , 0i < ui 0N−3 , 11 , 12 , 1i − ui 0N−3 , 11 , 12 , 0i
shows that the payoﬀ to i from the change from 0 to 1 is increased again when agent
9

2 changes from 0 to 1. The inequalities repeat this process changing one additional
agent’s strategy each time. The inequalities here hold by the increasing diﬀerence
property (1).
Note that the first diﬀerence is negative

¡
¢
¡
¢
ui 0N−1 , 1i − ui 0N−1 , 0i < 0
as the vector of all zeros is a Nash equilibrium so 0 is a best response for i: note also
that to the contrary the last diﬀerence

ui (11 , 12 , ..., 1N−1 , 1i ) − ui (11 , 12 , ..., 1N−1 , 0i ) > 0

is positive as the vector of all ones is also a Nash equilibrium and now 1 is a
best response.

As the sequence of diﬀerences starts negative and ends positive

¡
¢
it must change sign: let the first positive diﬀerence be ui 0N −t−1 , 11 , .., 1t , 1i −

¡
¢
ui 0N −t−1 , 11 , .., 1t , 0i . Then clearly the first t agents form a T − set. Once they
have chosen 1 as a strategy, this is the best response of all other agents. This proves
that a T − set exists.
In principle we can find the smallest T − set by reviewing this set of inequalities
for every possible ordering of agents and finding the ordering for which the change
of sign occurs after the smallest number of inequalities. However for a large number
of agents this approach could prove extremely time-consuming as the number of

10

orderings increases exponentially with the number of agents. We can oﬀer more
eﬃcient ways of finding the smallest T − set in a special case.
In order to provide a simple characterization of a T − set we focus on the special
case in which the diﬀerence ∆ij (0) in equation (4) is independent of the index j,
i.e. the eﬀects of i0 s change of strategy are symmetric over other agents. In addition
we assume that ∆ij (s−i−j ) is independent of s−i−j and so does not depend on the
strategies chosen by others. These two conditions of symmetry and independence
taken together we call assumption A1.

∆ij (0) = ∆ik (0) = ∆i (0) = ∆i

(A1)

For each agent i, ∆i is the alteration in the payoﬀ that all other agents get from
switching strategy from 0 to 1 as a result of agent i changing from 0 to 1, a uniform
externality that i by changing strategy imposes on others when they change strategy.
Given this, agents can be ranked unambiguously by the values of their ∆i functions, and we assume without loss of generality that they are numbered so that
∆1 ≥ ∆2 ≥ ....... ≥ ∆N . An agent’s ability to tip the ineﬃcient equilibrium is measured by its ∆, and we show below that the smallest T − set consists of agents with
the greatest ∆s.
Let

© t N−t−1 ª
0 ,1
, 1k denote the following vector: the k − th coordinate is 1, t

coordinates are zero, all others (of which there are N − t − 1) are 1, and the first
N − t − 1 coordinates are 1 if k > N − t and the first N − t are 1 otherwise.
11

From (2) and (3) and (A1) we can write
X
¡ N−K−1 K ¢
¡ N−K−1 K ¢
¡ N−1 ¢
¡ N−1 ¢ i=K−1
uj 0
, 1 , 1j −uj 0
, 1 , 0 = uj 0
, 1 −uj 0
,0 +
∆i (6)
i=1

¡
¢
¡
¢
Hence finding a t such that ui 0N−t , 11 , .., 1t , 1i −ui 0N −t , 11 , .., 1t , 0i > 0 is the same
¢
¢ P
¡
¡
Pi=t−1
as finding a t such that uj 0N−1 , 1 − uj 0N−1 , 0 + i=t−1
∆i >
i=1 ∆i > 0 or
i=1

¢
¢
¡
¡
uj 0N−1 , 0 − uj 0N−1 , 1 . From this we can readily prove:

Proposition 2 Given A1, if a smallest T − set exists then for some integer F it
consists of the first F agents when agents are ranked by the value of ∆i .
Proof. If F < N is a T − set then for all j > F we must have
¡
¢
¡
¢
uj 0N−F −1 , 1F , 1j − uj 0N−F , 1F ≥ 0
By (6) above this is equivalent to
i=F
−1
X
i=1

¢
¢
¡
¡
∆i ≥ uj 0N −1 , 0 − uj 0N−1 , 1 ∀j > F

(7)

To construct the smallest T − set we need to find the smallest number F for which
(7) holds. Clearly we get this by ranking agents by the size of ∆i and choosing first
those with the largest value of ∆i , i.e. those that create the largest externalities or
that exhibit increasing diﬀerences to the greatest degree.
Proposition 2 shows that the agents that are most capable of changing the game’s
12

equilibrium are those that generate the largest externalities to others, and that the
ability to change the equilibrium depends on the game being suﬃciently supermodular
or on the degree of increasing diﬀerences being great enough. The terms ∆i are
measures of the degree of increasing diﬀerence, and assumption A1 places a structure
on these so that they are symmetric across agents. This structure is necessary for the
simplicity of our arguments but not for the basic intuition that increasing diﬀerences
contribute to tipping, as Proposition 1 shows. Within the structure defined by A1
we can say that increasing diﬀerences being suﬃciently large in the sense of (7) is
necessary and suﬃcient for tipping of the ineﬃcient equilibrium. A numerical example
of tipping at the ineﬃcient equilibrium of a super modular game is given in [6].
It is possible to establish results like Proposition 2, but more complex ones, with
weaker assumptions than A1. Suppose for example that we drop the independence
assumption, namely that ∆ij (s−i−j ) is independent of s−i−j . In this case in stating
and deriving a proposition analogous to Proposition 2 we need to reorder the agents
by the size of ∆i after each selection of a member of the tipping set, as the change
of strategy from 0 to 1 by one agent can alter the ranking of the agents still choosing
0 by their ∆i s. In forming the tipping set at each stage we add the remaining agent
whose ∆i is greatest given the strategies now in place by all other agents, and this
gives a more general but less parsimonious version of Proposition 2. If we drop the
symmetry condition we are back with the general case of Proposition 1.

13

3

Cascading

A cascade is a sequence of events in which a change of strategy by one agent leads
another to change, the changes of the two together lead a third to change, and so
on. It is a version of the classic domino eﬀect. Avinash Dixit models this well and
we follow his framework [3]. In our context a cascade will begin from an equilibrium
where all agents choose si = 0. A cascade of length k is a situation where:
• if 1 were to change from 0 to 1 but all others were to remain at 0 then 20 s best
response would be 1
• if 1 and 2 were to choose 1 and all others 0, then 30 s best response would be 1.
• if 1, 2 and 3 were to choose 1 and all others 0, then 40 s best response would be
1
• and so on up to agent k. The strategy tuple in which agents 1 through k choose
1 and all others choose 0 is a Nash equilibrium.

If we think of the game as one in which moves are made sequentially by players in
ascending order, we will see that if the first mover chooses 1 (perhaps as a result of
factors outside the game as we have defined it, such as policy inducements) then the
second mover chooses 1 and so on up to and including the k −th mover and thereafter
all will choose 0 and the outcome will be an equilibrium. If the only equilibria involve
either all zeros or all ones then the outcome of such a cascade will be the equilibrium

14

with all 1s, and this will be attained from the equilibrium of zeros by persuading
agent number one to change strategy.
Formally we have a cascade of length k at the Nash equilibrium {0, 0, ..., 0} if
agents can be numbered so that agent 20 s best response to {1, s2 , 0, ...0} is s2 = 1,
agent 30 s best response to {1, 1, s3 , 0, ...0} is s3 = 1, and for all agents j for j ≤ k the
best response to {1, 1, .., sj , 0, ..0} is sj = 1, and in addition {1, 1, .., sk = 1, 0, ..0} is a
Nash equilibrium. Using the framework and assumptions of the previous section we
can set out suﬃcient conditions for a cascade of length k.
We can give a formal characterization of the conditions for a cascade of length k
as follows:

Proposition 3 A cascade of length k occurs if

∆j−1

⎛ j−2
⎛ j−2
⎞
⎞
z }| {
z }| {
≥ uj ⎝1, .., 1, 0, .., 0⎠ − uj ⎝1, .., 1, 0, 1, 0..0⎠

for all j ≤ k.
Proof. For a change by agent 1 to change agent 20 s strategy we need that

u2 (1, 1, 0..0) − u2 (1, 0..0) = u2 (0, 1, 0..0) − u2 (0, ..0) + ∆1 > 0

or
∆1 > u2 (0, ..0) − u2 (0, 1, 0..0)
15

Similarly for a change by agent 2 to change 30s strategy

u3 (1, 1, 1, 0..0) − u3 (1, 1, 0..0) = u3 (1, 0, 1, 0..0) − u3 (1, 0, ..0) + ∆2 > 0

or
∆2 > u3 (1, 0, ..0) − u3 (1, 0, 1, 0..0)
The proposition follows by repeating this argument.
Cascading, like tipping, depends on a game exhibiting “enough increasing diﬀerence.” A numerical example of cascading from the ineﬃcient to the eﬃcient equilibrium of a supermodular game is given in [6].

4

Schelling’s work

Schelling [13] provides a number of examples of the role of a critical mass in inducing
tipping: in these examples individuals make a decision about being part of process or
group based on what they see others doing. A key example is given by individuals’
decisions about whether to reside in a neighborhood, which they do if there are enough
others like themselves who are already there. Schelling’s most famous example, of
racial segregation in residential districts, was essentially dynamic, with a sequence
of changes evolving over time. However it is possible to capture much of what was
interesting in and essential to that model with a static formulation identical to that
used above.
16

Consider a population of P people of a certain type living in a neighborhood.
Each has two possible strategies - stay S or move M. The payoﬀ to each depends
on how many others of the group do the same: the payoﬀ to staying is the number
of others who stay, #(S), and the payoﬀ to moving is likewise the number of others
who do this, #(M). Clearly all staying or all moving are both Nash equilibria, and
if #(M) > #(S) then the best response of all who have not moved is to move, so
that we have the possibility of tipping. This game displays increasing diﬀerences, as
the payoﬀ to changing from S to M increases with the number of people who have
already changed.

5

Airline security

We now illustrate our results on tipping and supermodularity in a case that we and
others have studied extensively, that of airline security (see Howard Kunreuther and
Geoﬀrey Heal [9], Heal and Kunreuther [6] and Michael Kearns [8]). Each airline is
concerned with how large an investment it should incur to reduce the likelihood of
a dangerous bag or passenger being on board one of its airplanes. Each knows that
even if it invests in security screening there is still a chance that a dangerous bag
or passenger could transfer to it from another airline with lax inspection procedures.
There is nothing it can do to stop this process short of inspecting all passengers and
bags transferred from other airlines, a time consuming and costly process followed
only by El Al.. The Pan Am 103 crash illustrates this case well: the bag that caused
17

the accident was loaded at Gozo Airport in Malta, with lax security, transferred to
a Pan Am feeder in Frankfurt and then to Pan Am 103 in Heathrow, set to explode
at over 28,000 feet. There was nothing that Pan Am could have done to prevent this
disaster short of inspecting all bags transferred to its planes from other airlines.

5.0.1

The Model

Kunreuther and Heal (2003) [9] have developed a game theoretic model to show that
each airline will have less incentive to invest in security if it knows that other airlines
have not invested. In the context of the above model, can one specify conditions for
tipping an equilibrium from one where none invest to an equilibrium where all invest
in security?
There are n ≥ 2 separate airlines. During the course of a given time period each
airline makes a certain number of trips, each of which is identical. Consider a given
plane trip initiated by airline i, and assume that the airline has made no investments
in security systems. Let pij be the probability that on any trip a bag containing a
bomb is loaded onto airline i and is then transferred to airline j, exploding on j. If
i = j, then pii represents the probability that an airline loads a bag with a bomb
X
X
and this explodes on its own plane. Let pi =
pij and pei =
pij . Thus pi is the
j

j6=i

probability of airline i loading a bomb that explodes on its own plane and pei is the
probability that it loads a bomb that explodes on another airline - a measure of the

risk that it poses to others. We expect that pi < 1 so that there is some chance that

18

the airline does not load a bag with a bomb that explodes. Each airline can either
invest in a security system (strategy = S) at a cost per trip of ci > 0 or not invest N.
Security systems are assumed to be completely eﬀective so that they eliminate the
chance of a bomb coming through the airline’s own facility. In the event that a bomb
explodes on a plane, the loss is L > 0. The initial income of an airline is Y > ci ∀i.
In the case of just airlines A1 and A2 that exchange passengers and baggage
maximizing expected profits, this framework gives rise to the following payoﬀ matrix
showing the outcomes for the four possible combinations of N and S. If both airlines
invest in security systems then their payoﬀs per trip are just their initial incomes net
of the investment costs. If A1 invests and A2 does not, then A1 has a payoﬀ of income
Y minus investment cost c1 minus the expected loss from a bomb transferred from
A2 that explodes on A1 (i.e., p21 L), while A2 has a payoﬀ of income Y minus the
expected loss from a bomb loaded and exploding on its plane, p22 L. If neither invests
then A1 has a payoﬀ of income Y minus the expected loss from a bomb loaded and
exploding on its own plane p11 L minus the expected loss from a bomb transferred
from A2 that explodes on A1 (i.e., p21 L) conditioned on there being no explosion from
a bomb loaded by A1 itself (1 − p11 ). A2 ’s payoﬀ is determined in a similar fashion.

A1 /A2

S

N

S

Y − c1 , Y − c2

Y − c1 −p21 L, Y − p22 L

N

Y − p11 L, Y − c2 −p12 L Y − p11 L− (1 − p11 ) p21 L, Y − p22 L− (1 − p22 ) p12 L
19

Choosing to invest in security measures is a dominant strategy for 1 if and only if

c1 < p11 L and c1 < p11 [1 − p21 ] L

(8)

The condition that c1 < p11 L is clearly what we would expect from a single airline
operating on its own. The tighter condition that c1 < p11 [1 − p21 ] L reflects the risk
imposed by a firm without security on its competitor: this is the risk that dangerous
baggage will be transferred from an unsecured airline.
Following the model developed in section 2, we need to identify the change in the
return to airline 1 when it invests in security as a result of investment by airline 2.
From the payoﬀ matrix it is easy to see that this is

∆21 = p11 p21 L

By similar reasoning we can show that for the cases of three and four airlines when all
are not investing and airline 2 changes from not investing to investing the expressions
for the change in 1’s payoﬀ are respectively

∆21 = p11 p21 L (1 − p31 ) , ∆21 = p11 p21 L (1 − p31 ) (1 − p41 )

For the general case of N agents the change in the return to j investing as a result

20

of i investing when no other agents are investing is

∆ij = pjj pij L

Y

k6=i,j

(1 − pik )

(9)

If agents other than i, j are investing, say agents in {S}, then they are excluded from
the product:
∆ij = pjj pij L

Y

k6=i,j,j ∈{S}
/

(1 − pik )

However, we are interested in tipping an equilibrium at which no agents are investing,
so we are interested in the case in which S is empty and the first version of the
formula applies. The expression (9) has a natural intuitive interpretation. The term
Y
pij L
(1 − pik ) is the expected cost to agent j of a security failure at agent i,
k6=i,j

conditional on there not being a security failure at another agent k 6= i, j. The higher
this expected cost the greater the increase in j’s expected gains from investing if i
invests in protection as well. Multiplying this expected gain by pjj normalizes this
value given the chance of a loss because of a security failure at j and determines the
increase in expected profit to j from i investing in security. Consider the extreme

case where pjj = 0. For the two agent case if p11 = 0 then, as is clear from the payoﬀ
matrix and expression (8) , there is no return to agent 1 to investing in security on its
own. It would then never be optimal for agent 1 to invest in security whether or not
agent 2 invested. More generally the smaller the value of pjj , the less reason agent j
will have to invest in security on its own and hence the less likely that this agent will

21

be a candidate for being tipped into investing should other agents such as i invest in
security ( 9).
With this characterization of the ∆s we are in a position to apply the results of
the previous sections to understand the tipping and cascading possibilities for the
airline security problem. Assume, following Assumption A1, that ∆ij is independent
of j so that ∆ij = ∆i , pjj = p and pij = qi . In this case 9 becomes:

∆ij = ∆i = pqi L

Y

k6=i,j

(1 − pk )

(10)

If there are two Nash equilibria with either everyone or no one investing in protection, then by Proposition 1 the smallest T − set consists of the first K agents when
agents are ranked by the value ∆i . Agents will have higher values of ∆i if they have
high values of qi .

5.1

Applications to Other IDS Problems

As shown in Kunreuther and Heal [9] there are a wide range of problems that exhibit
features of supermodularity where tipping could occur. One area that naturally falls
into this class is computer security. Here the central issue is the incentive each
agent has to invest in protecting itself against a possible virus, when it knows that it
may be infected from other agents. The following example adapted from Kearns [8]
illustrates this problem. Imagine the user population of a large organization in which
each individual has a desktop computer with its own local software and memory, but
22

in which parties also maintain important data files or documents on a shared disk
drive accessible to the entire organization.
From the perspective of the organization, the primary security concern is that
an intrusion (whether by a piece of malicious software or a human hacker) might
erase the contents of this shared hard drive. Each user’s desktop computer and its
contents–including E-mail, downloaded programs or files, and so on–is a potential
point of entry for such intrusion. Each user must implicitly decide about many aspects
of their individual security practices: how often they change their password (and how
secure those passwords are against dictionary and other common attacks), whether
they enable encryption in their web and e-mail communications, their care in not
downloading suspicious files and programs, their anti-virus software maintenance, and
many other features, each of which takes time and hence is costly. The vulnerability of
the shared hard drive is determined by the collective behavior along these dimensions.
Hence if an agent invests in rigorous security precautions, her investments can be
compromised by a failure to do likewise on the part of just one other. As it may be
the case that some other agents do not store valuable data on the shared drive, their
incentives to adopt best-practice security measures may be small. So we again have
an interdependent security problem, with supermodularity of the associated game
and the possibility of tipping from an equilibrium where none take security seriously
to one where all do.
A related problem is one where each division in a decentralized firm needs to

23

determine whether it wants to incur the costs of investing in risk-reducing measures
knowing that other divisions in the same firm may not follow suit.(see [10] for more
details). By not investing in protection there is some probability pi that division i will
have a large loss that could cause its division to fail and qi ≤ pi is the probability that
the loss would be so large that the entire firm would become insolvent. Two recent
examples are Nick Leeson operating in the Singapore futures market division causing
the collapse of Baring’s Bank and Arthur Andersen being brought into bankruptcy by
the actions of its Houston branch. The losses L in this case are the costs that managers
and other employees of the division will incur if their division goes bankrupt. These
include the search costs for new employment and other negative features associated
with losing ones job including loss of reputation. The ranking of agents in forming
a T − set is similar to that in proposition 2 so that one would want to find ways
to encourage those divisions in the firm who create the largest expected negative
externalities to be the first ones to invest in protection and thus induce other divisions
to follow suit.

References
[1] Bulow Jeremy I., John D. Geanakoplos and Paul D. Klemperer 1985. “Multimarket Oligopoly: Strategic Substitutes and Complements". Journal of Political
Economy, vol. 93, no 313, 488-511.

24

[2] Crawford, Vincent and Hans Haller, Hans 1990. “Learning How to Cooperate:
Optimal Play in Repeated Coordination Games” Econometrica Vol 58: Issue 3
(May 1990) 571 - 595.
[3] Dixit

Avinash

K

2002.

“Clubs

with

entrapment."

Available

at

www.princeton.edu/~dixitak/home. Published in American Economic Review Vol.. 93 No. 5 pp. 1824-1829.
[4] Easterly, William 2004

"Empirics of Strategic Interdependence"

February

(mimeo)
[5] Gladwell Malcolm 2000. The Tipping Point Little Brown and Co.
[6] Heal Geoﬀrey and Kunreuther Howard.(2005). “IDS Models of Airline Security”
Journal of Conflict Resolution 41:201-17.
[7] Heller, Walter 1986 “Coordination Failure in Complete Markets with Applications to Eﬀective Demand”. In Equilibrium Analysis: Essays in Honor of Kenneth J. Arrow Vol II, ed. W.P.Heller, R.M. Starr and D.A. Starrett, Cambridge
University Press., 1986.
[8] Kearns, Michael 2005. "Economics, Computer Science, and Policy". Issues in
Science and Technology, Winter pages 37-47.

25

[9] Kunreuther Howard and Geoﬀrey Heal 2003. “Interdependent Security.” Journal of Risk and Uncertainty, Special Issue on Terrorist Risks, Vol. 26 No. 2/3
(March/May): 231-249.
[10] Kunreuther Howard and Geoﬀrey Heal 2005 “Interdependencies within an Organization” in B. Hutter and M. Powers (ed.) Organizational Encounters with
Risk (Cambridge University Press)
[11] Milgrom Paul and John Roberts. 1990. “Rationalizability, Learning and Equilibrium in Games with Strategic Complementarities" Econometrica 58: 1255-77.
[12] Schelling, Thomas 1971. "Dynamic Models of Segregation" Journal of Mathematical Sociology 1:143-86.
[13] Schelling, Thomas 1978. Micromotives and Macrobehavior. New York: Norton
[14] Topkis, Donald 1978 "Minimizing a Submodular Function on a Lattice" Operations Research 26: 305-21.
[15] Topkis, Donald 1979 "Equilibrium Points in Nonzero-Sum n-Person Submodular
Games" Siam Journal of Control and Optimization 17:773-87.
[16] Vives, Xavier. Journal of Economic Literature Vol.. XLIII (June 2005)

26

