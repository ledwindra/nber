{
    "id": 22880,
    "citation_title": "Labor Market Outcomes and Postsecondary Accountability: Are Imperfect Metrics Better than None?",
    "citation_author": [
        "Veronica Minaya",
        "Judith Scott-Clayton"
    ],
    "citation_publication_date": "2016-12-05",
    "issue_date": "2016-12-01",
    "revision_date": "None",
    "topics": [
        "\n",
        "Public Economics",
        "\n",
        "National Fiscal Issues",
        "\n",
        "Health, Education, and Welfare",
        "\n",
        "Education",
        "\n"
    ],
    "program": [
        "\n",
        "Economics of Education",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nPolicymakers at the state and federal level are increasingly pushing to hold institutions accountable for the labor market outcomes of their students. There is no consensus, however, on how such measures should be constructed, or how the choice of measure may affect the resulting institutional ratings. Using state administrative data that links postsecondary transcripts and in-state quarterly earnings and unemployment records over more than a decade, we construct a variety of possible institution-level labor market outcome metrics. We then explore how sensitive institutional ratings are to the choice of labor market metric, length of follow-up, and inclusion of adjustments for student characteristics. We also examine how labor market metrics compare to the academic-outcome-based metrics that are more commonly incorporated into state accountability systems. We conclude that labor market data provides information that is quite distinct from students\u2019 academic outcomes. Institutional ratings based on labor market outcomes, however, are quite sensitive to the specific metric. The choice of metric and length of follow up appear to matter much more than compositional adjustments. Our findings suggest a cautious approach: while a mix of feasible labor market metrics may be better than none, reliance on a single metric, especially if measured very early, may undermine policymakers\u2019 ongoing efforts to accurately quantify institutional performance.\n\n",
    "acknowledgement": "\nAuthors are listed in alphabetical order; both contributed equally to this project. The authors gratefully acknowledge Josh Hawley and Lisa Neilson at the Ohio Education Research Center, who helped facilitate our application for the restricted data utilized herein, and Caroline Hoxby, Kevin Stange, Jeff Smith, Robert Kelchen, and NBER conference participants for valuable suggestions. Funding to obtain and clean the data used herein was provided by the Institute of Education Sciences, U.S. Department of Education, through Grant R305C110011 to Teachers College, Columbia University. The opinions expressed are those of the authors and do not represent views of the Institute, the U.S. Department of Education, the Ohio Education Research Center, or the National Bureau of Economic Research.\n\n\n"
}