NBER WORKING PAPER SERIES

BUILDING THE STOCK OF
COLLEGE-EDUCATED LABOR
Susan Dynarski
Working Paper 11604
http://www.nber.org/papers/w11604
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2005

Comments welcome: susan_dynarski @ harvard.edu. I am grateful to the Russell Sage Foundation and the
University of California at Los Angeles for funding. Betsy Kent, J.D. LaRock, Isabel Millan-Valdes and Juan
Saavedra provided excellent research assistance. Joe Doyle, Amy Finkelstein, Brian Jacob, Jeff Liebman,
Erzo Luttmer, Ben Olken, Cecilia Rouse, Sarah Turner and seminar participants at the Centre for the
Economics of Education, Dartmouth, Harvard, MIT, the National Bureau of Economic Research, the
University of California at Davis and the University of Michigan were generous with their helpful comments.
Any errors are my own. The views expressed herein are those of the author(s) and do not necessarily reflect
the views of the National Bureau of Economic Research.
©2005 by Susan Dynarski. All rights reserved. Short sections of text, not to exceed two paragraphs, may
be quoted without explicit permission provided that full credit, including © notice, is given to the source.

Building the Stock of College-Educated Labor
Susan Dynarski
NBER Working Paper No. 11604
September 2005
JEL No. I21, I22, I28
ABSTRACT
Half of college students drop out before completing a degree. These low rates of college completion
among young people should be viewed in the context of slow future growth in the educated labor
force, as the well-educated baby boomers retire and new workers are drawn from populations with
historically low education levels. This paper establishes a causal link between college costs and the
share of workers with a college education. I exploit the introduction of two large tuition subsidy
programs, finding that they increase the share of the population that completes a college degree by
three percentage points. The effects are strongest among women, with white women increasing
degree receipt by 3.2 percentage points and the share of nonwhite women attempting or completing
any years of college increasing by six and seven percentage points, respectively. A cost-benefit
analysis indicates that tuition reduction can be a socially efficient method for increasing college
completion. However, even with the offer of free tuition, a large share of students continue to drop
out, suggesting that the direct costs of school are not the only impediment to college completion.
Susan Dynarski
Harvard University
Kennedy School of Government
79 JFK Street
Cambridge , MA 02138
and NBER
susan_dynarski@harvard.edu

I. Introduction
College attendance has risen substantially over the past forty years. In 1968, 36 percent of 23year-olds had gone to college. By 2000, that figure had grown to 55 percent. Over the same period, the
share of young people with a college degree has risen relatively slowly. In 1968, the share of 23-yearolds with a bachelor’s degree was 14 percent, while in 2000 it was 19 percent.1 As these figures make
clear, many young people enter college but drop out before completing a degree. In the 2000 Census, just
57 percent of those age 22 to 34 with any college experience had completed an associate’s or bachelor’s
degree. Thirteen percent of those who had attempted college had not completed even a year.2
These low rates of college completion among young people should be viewed in the context of
slowed growth in the educated labor force, as the well-educated baby boomers retire and new workers are
drawn from populations with historically low education levels (Ellwood, 2001). This sluggish growth in
the stock of educated labor in the United States can be contrasted with much faster growth rates in other
nations. In 1991, only two countries (Canada and Finland) exceeded the United States in their shares of
young people with a college degree, and only by a couple of percentage points. By 2002, the picture had
changed dramatically. Thirteen countries have equaled or exceeded the benchmark achieved by the
United States in 1991 and four nations are now ahead of us, with Japan and Korea outstripping us by
more than ten percentage points (Organization for Economic Cooperation and Development, 2004).

1

These figures, tabulated from the October Current Population Surveys of 1968-2000, are from Turner
(2003). The figures for 23-year-olds imply that the college dropout rate has risen sharply. Turner points
out that among 30-year-olds the dropout rate is, by contrast, quite flat. She concludes that while the
dropout rate is not rising the time it takes to complete college is lengthening. A consequence is that each
college entrant now spends fewer years working as a college graduate. That is, the lifetime supply of
college-educated labor provided by each college entrant is dropping over time.

2

Author’s tabulations from the Public Use Microdata One-Percent Sample of the 2000 Census.
1

Any major growth in the college-educated workforce will require an increase in college
completion, since very large gains in college entry are now behind us.3 There are several channels through
which policy might affect the completion margin. Sociologists have focused, in particular, on weak
connections between college dropouts, their peers and their teachers (Tinto, 1994). Another lever is
improved academic preparation in high school. This paper focuses on a third channel: college costs. A
small literature has shown that decreasing college costs substantially increases the college entry rate of
young people. By contrast, we know little about how costs affect college completion.4
Theory does not unambiguously predict the impact of schooling costs on persistence through
college, even once we know the impact of college costs on college entry. In Manski’s framework (1989),
students learn about their academic skills when they enter college and, should they find them lacking,
drop out. Marginal decreases to college costs may induce students with low expectations of success to
undertake this experiment. An alternative (but not incompatible) story is that the marginal college student
may be credit-constrained. Relaxing credit constraints may then induce into college individuals with
better academic skills than the typical college student.
Determining how schooling costs affect human capital investment is not straightforward, since
the costs faced by a potential student may well be correlated with unobserved determinants of her
educational attainment. This paper exploits the introduction of large scholarship programs in two
Southern states to identify the effect of college costs on college completion. During the 1990s, a dozen
states introduced large-scale merit aid programs. Arkansas started the trend in 1991, with Georgia

3

Seventy percent of young high school graduates have some college experience in Census 2000. Among
high income families the rate is ninety percent (Ellwood and Kane, 2000). This is not meant to imply that
there is no room for improvement at margins other than college completion. A substantial share of
nonwhites and Hispanics have not attempted college, but this is largely driven by their low rate of high
school graduation.

4

For analysis of the causal impact of college costs on attendance see Kane (1994), Dynarski (2000, 2003,
2004) and Seftor and Turner (2002). Dynarski (2002) reviews this literature. Bettinger (2004) and
Dynarski (2003) present suggestive evidence that financial aid has a causal impact on completed
schooling. Angrist (1993) and Bound and Turner (2002) show that veterans' educational benefits increase
completed schooling.
2

following suit in 1993. These programs waive tuition and fees for students who achieve a minimum GPA
in high school (typically 3.0), and maintain a minimum GPA in college (typically 2.5 to 3.0). These are
not scholarships for a tiny academic elite: nearly 60 percent of those graduating high school in Georgia
qualify for its merit scholarship.
In previous work, I have shown that these programs have had a positive impact on college
attendance (Dynarski, 2000 and 2004). In those papers, data limitations prevented the estimation of the
effect of merit aid on college completion. These data limitations have been relaxed by the release of the
2000 decennial census micro-data. As of 2000, several cohorts who were exposed to the Arkansas and
Georgia programs were in their early twenties, the traditional age of college graduation. I use a treatmentcomparison research design to evaluate the effect of these programs on college completion rates. Crosscohort differences in college completion within the states provide the identifying variation in the analysis.
The identifying assumption is that any cross-cohort change in college completion in the treatment states,
relative to the control states, is due to the scholarship programs.
To preview the results, I find a large and significant impact of college costs on degree receipt.
The scholarship programs appear to increase the share of young people with a college degree by three
percentage points. This is a substantial effect, especially given that in the treatment states just 27 percent
of the pre-program cohorts have a college degree. The effects are strongest among women, with white,
non-Hispanic women showing increases of 3.2 percentage points. The share of nonwhite and Hispanic
women attempting or completing any years of college increased by six and seven percentage points,
respectively.
The identifying assumption, while ultimately untestable, is subjected to a series of plausibility
checks. A key threat to the internal validity of the estimates is any pre-program trend in college
completion in the treatment states relative to the comparison states (Meyer, 1995). A plausible scenario is
that Arkansas and Georgia began to build their human capital years before introducing the scholarship
programs, through increased investment in children’s education or by attracting skilled adults from other
states. In this scenario, these pre-existing trends could even cause the scholarship programs, with well3

educated parents in the treatment states demanding scholarships so as to reduce tuition costs for their
college-bound children. Both pre-existing trends and reverse causality would produce a spurious, positive
correlation between the scholarship programs and educational attainment.
I address this critical set of concerns with several methods. First, throughout the analysis I assign
program eligibility based on state of birth rather than state of residence. Recent migration into the
treatment states by well-educated young workers and their families cannot, therefore, explain the results.5
Second, a visual inspection of the data shows a distinct break from trend in the schooling of the affected
cohorts. Third, I include in the regressions parametric and non-parametric controls for trends in education
at the level of the state of birth and state of residence.6 Fourth, I show that the program effects occur only
at educational margins plausibly affected by eligibility for the merit scholarships. Together, this set of
results provides strong support for the identifying assumption of the paper.
My reduced-form estimation strategy cannot separately identify the effect of aid on entry and
persistence conditional on entry. I can, however, place fairly narrow bounds on the persistence effect. The
scholarship programs appear to increase by five to eleven percent the probability of persistence to degree
of those who would have entered college even in the absence of the programs.
A cost-benefit analysis indicates that tuition reduction can be an effective and socially efficient
method for increasing college completion. However, this approach alone will not keep the bulk of
dropouts from leaving college. The programs studied in this paper drove to zero the direct costs of
schooling for many entering college students, yet even with this offer of free tuition a large share of
students continued to drop out of college. This suggests that the direct costs of college are not the only (or

5

In fact, assigning eligibility based on residence yields small and insignificant results. This point is
discussed later in the paper.

6

By bringing in data from the 1990 census, I also can control for the interaction of age effects with state
of birth, which in the cross-sectional analysis using the 2000 census is the source of identification of the
program effect. The point estimates are robust to this very strong test.
4

even the central) impediment to degree completion, and policymakers and researchers will need to
explore more avenues in order to increase the stock of college educated labor.7
One promising avenue is improved preparation in primary and secondary school. At least two
studies provide firm evidence that early interventions can have an impact on postsecondary attainment.
Results in Krueger and Whitmore (2001) indicate that students randomly assigned to small classes in
early elementary school are more likely than students in a control group to take college entry exams (a
strong predictor of college entry). The Abcederian study, a randomized-controlled trial, has shown a
positive impact of intensive, early childhood interventions on post-secondary schooling (FPG Child
Development Institute, 2005). Another possible policy lever is improved institutional support for college
students, in the form of more counseling, better coordination of course schedules and easier credit
transfers between two-year and four-year colleges. While these interventions have been fielded, analyzed
and discussed extensively (e.g., Tinto, 1994), there is no credible evidence of their causal impact on
college completion.
The paper is organized as follows. Section II provides a literature review and background on the
state subsidy programs that will be the subject of the analysis. Section III lays out the identification
strategy and describes the data. Section IV provides results and robustness checks. Section V explores
heterogeneity in the program’s impact. Section VI discusses the results and Section VII concludes.

II. Background
This section discusses the relevant economic literature and provides background on the programs
that will be the subject of the empirical analysis.

7

This conclusion accords with Stinebrickner and Stinebrickner (2003), who show that the dropout rate
approaches fifty percent at Berea College, even though that school pays all costs (tuition, fees, books,
room and board) for all its students. Note that their evidence and mine do not rule out liquidity constraints
as an explanation for low college completion rates, since the direct cost of college is a fraction of its total
cost. Further, a conclusion that current tuition prices are not the main impediment to college completion
does not imply that substantially raising the price of college would not increase the dropout rate, since
there are likely non-linearities in the response to price.
5

College Costs and College Completion
Financial aid plausibly affects several margins of behavior: college attendance, college entry, and
degree completion.8 Dozens of studies have examined the relationship between college costs and these
outcomes.9 Almost all are plagued by identification problems, with the analyses failing to control for
correlation between college costs and unobserved determinants of schooling outcomes.
A handful of well-identified studies, however, has established a strong casual link between
schooling costs and college attendance. Dynarski (2003) finds that the elimination of the Social Security
student benefit program, which paid the college costs of the children of deceased parents, substantially
reduced the college attendance of the affected population. Studies which examine the Pell Grant, currently
the largest source of federal grant aid, produce somewhat mixed results: Hansen (1983) and Kane (1995)
found no effect of the introduction of the Pell on the college attendance rate of low-income recent high
school graduates, but recent work by Seftor and Turner (2002) has found a positive effect on the
attendance of slightly older youth. Most relevant to the current paper, Dynarski (2000, 2004) and Kane
(2003) find that large-scale state merit scholarship programs substantially increase the share of young
people attending college.
The evidence on the effect of aid on college persistence and completion is comparatively thin.
Angrist (1993) and Bound and Turner (2002) show that veterans’ educational benefits increase completed
schooling. Dynarski (2003) finds that the elimination of the Social Security student benefit program
reduced the schooling of the affected population of two-thirds of a year, but this result is imprecisely
estimated. Bettinger (2004) uses regression-discontinuity methodology to examine the effect of the Pell
Grant on persistence rate of college entrants and finds a positive effect, but notes that his results are quite

8

College attendance is a state variable, indicating that at a given point in time a person is enrolled in
college. Entry and completion are stock variables, indicating that a person has ever attended college or
has completed college, respectively.

9

Leslie and Brinkman (1988) review these studies.
6

sensitive to specification. The contribution of the present paper is to provide estimates of the effect of
college costs on persistence and degree completion that are precisely estimated and robust to specification
and functional form.

State Merit Aid Programs
Since the early Nineties, more than a dozen states have established broad-based merit aid
scholarships. While states have long awarded college scholarships based on academic performance in
high school, these programs have traditionally subsidized only the highest-performing students. For
example, New York gives a scholarship to each high school’s top scorer on the state Regents exam. The
academically-elite students who receive these scholarships are unlikely to alter their decisions to complete
a degree based on whether they receive the scholarship. By contrast, the new merit scholarships are open
to students with solid but not exemplary academic records. A dozen state merit aid programs have
eligibility criteria that are sufficiently lenient that at least thirty percent of high school seniors have grades
and test scores that qualify them for an award. Many of these students may be on the margin of
completing a college degree, and so these programs are a fruitful source of variation for examining this
particular outcome.
Of the thirteen states with broad-based merit aid programs, nine are in the South (see Appendix
Table). In 1993, just two states, Arkansas and Georgia, had programs in place. By 2003, thirteen states
had introduced large merit aid programs. Most of this growth has occurred quite recently, with six
programs starting up since 1999. Many of the merit programs are too new to detect effects on college
completion in currently available data. The oldest programs, established in Arkansas in 1991 and in
Georgia in 1993, provide the identifying variation in the paper.10

10

Despite the differences between the two programs that I detail below, I find that their effects on college
completion are virtually identical.
7

The Arkansas program was proposed in January 1991 by then-Governor Bill Clinton. The
program was quickly approved by the legislature and was in place in time for the high school class of
1991 to be offered scholarships for their fall enrollment. Eligibility for the Arkansas scholarship requires
a 19 or above on the ACT, a score exceeded by 60 percent of test-takers nationwide and below the
Arkansas state average of 20.4. Eligibility also requires a cumulative high school GPA of 2.5 in a set of
core classes, a standard met by up to 60 percent of high school students nationwide.11 Continued receipt
of the scholarship requires a GPA of 2.5 in college and progress at the rate of at least 24 semester hours a
year.12 The scholarship is available for a maximum of four years of undergraduate study.
At its inception the Arkansas program paid tuition and required fees up to $1,000 at public and
private colleges in Arkansas; this was raised to $1,500 in 1994 and $2,500 in 1997. Starting in 1994,
students received a bonus of $500 if their previous year’s college grades were 3.0 or above. In light of
prevailing tuition prices in Arkansas, these are generous subsidies. In 1994, tuition and required fees were
$2,200 at University of Arkansas at Fayetteville (the state’s flagship institution) and $1,110 at Arkansas
State University at Beebe.
When the program was introduced, Arkansas limited eligibility for the scholarships to those with
family incomes below $35,000 (for a family with two children); this was raised to $40,000 in 1993 and to
$75,000 in 1999. These caps should be viewed in the context of Arkansas, where incomes are among the
lowest in the nation. Median household income was $27,000 and $32,000 in 1989 and 1999,
respectively.13

11

Author’s calculations from the 1997 National Longitudinal Survey of Youth. This is the share of
students with a senior year GPA of at least 2.5, and so is likely an upper bound on the share of students
who achieve this GPA for their entire high school career.

12

Typically, a bachelor’s degree requires 120 semester hours.

13

After the last increase in the income cap, enrollment in the program soared. A state revenue shortfall
then led program administrators to suspend the program, which was funded by general revenues. This
period falls outside the main analysis of the paper, which focuses on age cohorts entering college in 1996
and earlier.
8

Georgia’s HOPE (Helping Outstanding Pupils Educationally) program was proposed in early
1993 by then-Governor Zell Miller. This program, too, moved quickly from proposal to legislation, with
the high school class of 1993 eligible for the first scholarships. The program is funded by a lottery, also
established in 1993. The scholarship requires a 3.0 GPA in high school.14 Renewal of the scholarship
requires a 3.0 GPA in college, with GPAs calculated when students accumulate 30, 60, 90 and 120 credit
hours. Unlike the Arkansas program, there is no time limit on scholarship receipt, but funded credit hours
are limited to 150.15 While Arkansas’ scholarship is dollar-denominated, the Georgia scholarship covers
full tuition and fees at any Georgia public college or university. For Georgia private colleges and
universities, the scholarship pays a lump sum that was gradually raised from $1,000 in 1993 to $3,000 in
1995.
Participation in HOPE during its first year was limited to those with family incomes below
$66,000. This income cap was raised to $100,000 in 1994 and eliminated in 1995. Until 2001, HOPE
scholarships were offset by other sources of aid. Low-income students faced higher transaction costs and
lower average HOPE scholarships than did upper-income students, since they were required to apply for
federal financial aid and their state scholarships were offset by any grants they received.16

14

As of 2000, only high school courses in a core curriculum (math, science, English, etc.) can be counted
toward the qualifying GPA.

15

Cornwell, Lee and Mustard (2004) argue that HOPE has led students to slow their progress through
college, opting for lighter courseloads in order to more easily meet the GPA requirement. Students bear
most of the cost of such a strategy, since it substantially increases the opportunity cost of a college degree.
If HOPE does slow progress through college, I will underestimate its effect on college completion, since
in my data the eligible cohorts are relatively young. In principle, I can estimate the effect of HOPE on
time-to-degree by calculating age-specific program effects. In practice, these age-specific effects cannot
be disentangled from year-specific effects induced by the aging of the program and multiple changes in
the program rules.

16

Georgia education officials, concerned that students would forgo applying for federal aid once the
HOPE Scholarship was available, mandated that applicants from families with incomes lower than
$50,000 complete the four-page Free Application for Federal Student Aid (FAFSA), which requests
detailed income, expense, asset and tax information.
9

Note that the structure of the public university scholarship in Georgia provides incentives for
schools to raise their prices in order to capture more scholarship funds. Countervailing pressure against
price increases is provided by the legislature and students ineligible for the scholarships. The paper’s
estimates capture the reduced-form effect of the merit scholarships, which includes any drop in
educational attainment among those ineligible for the scholarship but exposed to the price increases.
Given the generosity of the scholarships and the small increases in price documented in the literature, any
such offsetting effect is likely quite small.17
III. Empirical Methodology
The empirical strategy is straightforward. I use a treatment-comparison research design. States
that never introduce merit programs, or introduce them after the period under analysis, constitute the
comparison group. I test the sensitivity of the results to the choice of comparison states. Relative changes
in educational attainment in the states that introduce merit aid identify the effect of merit aid.
The key variable of interest is a dummy variable, merit, that indicates whether an individual
would have been exposed to a merit aid program upon high school graduation. Treatment status is
determined by year and state of high school graduation. Those who graduated from high school in 1991
and after in the state of Arkansas were exposed to that state’s scholarship program. Those who graduated
before 1991 were not eligible; the program was not grandfathered. Similarly, those who graduated in
1993 and after in Georgia were exposed to that state’s scholarship program.
The census provides neither state nor year of high school graduation. I use age at the time of the
census survey to assign the year of high school graduation, which I assume to occur at age 18. For
example, an individual who was 27 in April 2000 (when census data are collected) was 18 in April 1991,
and so is assigned to be a high school senior in 1991. This is an imperfect proxy, since in the spring of

17

Dynarski (2000) shows that public tuition and fees rose slightly faster in Georgia than in the rest of the
US after HOPE once introduced, after lagging US tuition growth in the pre-program period. In a more
detailed analysis, Long (2004) also concludes that the HOPE program has placed upward pressure on
prices.
10

their senior year many high school students are 19.18 I also test using Current Population Survey data on
the age distribution of high school seniors to probabilistically assign the year of high school graduation
and, thereby, treatment status. This increases the point estimates by about ten percent.
I use state of birth to assign state of high school attendance. For this purpose, state of birth is
preferred over state of residence because the latter may be endogenously determined by the treatment:
individuals may migrate to college and then settle in the state in which they go to school. However, a
drawback of using state of birth as a proxy for state of high school attendance is that about twenty percent
of high-school-age youth live outside their state of birth. This classification error will tend to bias the
estimates downward. In one specification, I use high-school-age respondents in the Census to estimate
transition probabilities between state of birth and state of residence. I apply this matrix to the analytical
sample in order to probabilistically assign the state of high school graduation and, thereby, treatment
status. This increases the point estimates by about twenty-five percent.

Sample Definition
My main analytical sample consists of 22- to 34-year-olds in the 2000 census. The lower cutoff is
chosen because it is a traditional age of college-leaving, and so is a reasonable age at which to begin
measuring degree completion. The upper cutoff is more arbitrary, and is chosen to provide roughly equal
numbers of age cohorts graduating high school in the years preceding and following the introduction of
the programs. These age cohorts correspond to the high school classes of 1984 through 1996, assuming
students graduate at age 18.
I limit the sample to those who currently live in, and were born in, the United States.19
Observations for which age, state of birth or completed education is imputed are dropped from the

18

Information on quarter of birth would allow a more accurate assignment, but this variable is unavailable
in the 2000 Census.
11

analysis. Analyses that include the imputed values produce substantively similar results. I do not use the
census sample weights in the analysis. Use of the weights does not substantively alter the results.

Variable Definitions
As of 1990, the Census does not collect data on years of schooling at the college level, instead
capturing information about degree completion. The relevant survey question is reproduced in the
Appendix Table 1. I will focus on whether an individual has earned any college degree, including a twoyear associate’s degree.20 Additional results will show the impact of the merit aid programs at every level
of education by estimating treatment effects for all sixteen categories of the education variable.
Measures of race and ethnicity are included in some specifications. Mutually-exclusive indicator
variables define individuals as Hispanics of any race, Black non-Hispanics, white non-Hispanics, and
other non-Hispanics. Table 2 contains the means of the key variables, listed separately by the individual’s
state of birth - Arkansas, Georgia, the rest of the South, and the rest of the United States.21

Specification
In the most parsimonious specification, I regress educational attainment against the treatment
dummy and a set of state of birth and age effects. I estimate the following equation using Ordinary Least
Squares:
(1) yiab = β meritab + δ a + δ b + ε iab

19

Mississippi’s program, introduced in 1996, is old enough to affect AA completion in 2000 but too
young to affect BA completion. To simplify the analysis I have removed Mississippi from the sample; its
inclusion does not alter the results substantially.

20

This corresponds to values 12 and above of the census education variable.

21

The Southern census region consists of the South Atlantic states (Delaware, Florida, Georgia,
Maryland, North Carolina, South Carolina, Virginia and West Virginia, plus the District of Columbia);
the East South Central states (Alabama, Kentucky, Mississippi and Tennessee); and the West South
Central states (Arkansas, Louisiana, Oklahoma and Texas).
12

Here, yiab is a measure of the completed education of person i of age a born in state b. δ b and δ a denote
state of birth and age fixed effects, respectively, and ε iab is an idiosyncratic error term. The identifying
assumption of this equation is that any relative increase across age cohorts in the schooling of those born
in merit aid states is attributable to the merit program itself. If the identifying assumption is correct, β is
the increase in education associated with exposure to a merit aid program.
I will generally perform this regression in cell means measured at the level of state of birth and
age cohort:
(2) yab = β meritab + δ a + δ b + ε ab
This approach produces estimates mathematically identical to those obtained in Equation (1), yet requires
little computational power. Further, as discussed later in the paper, performing the regression in grouped
means allows for a very simple calculation of consistent standard errors (See Bertrand, Duflo and
Mullainathan, 2004).

IV. Results and Robustness Checks
I begin with a visual inspection of the cell means that provide the identifying variation in the
paper. Figure 1A separately plots the probability of degree completion in Arkansas and the rest of the
United States, excluding Georgia. Since this is a single cross-section, the graph reflects both time and age
variation in education, with age effects dominating among the youngest cohorts. Education rises steadily
among those in their twenties. In the US, the share holding a college degree rises from 17.5 percent
among 22-year-olds to 37.7 percent among 29-year-olds.22 College completion is considerably lower in
Arkansas than in the US; among pre-program cohorts, the gap averages thirteen percentage points.
The shape of the US age-education profile provides the counterfactual for Arkansas. Among the
pre-program age cohorts, Arkansas roughly tracks the US. The series is noisy but essentially flat for these

22

Using multiple cross-sections, Turner (2004) documents that degree completion continues through the
twenties and into the early thirties.
13

cohorts, though the Arkansas series is (unsurprisingly) noisier than that of the US. With the first postprogram cohort there is a marked convergence in the two series, however. The gap between Arkansas and
the US narrows by more than seven percentage points between the two cohorts that straddle the
introduction of the scholarship. After this sharp convergence, Arkansas cohorts again roughly track their
US counterparts. During the post-program era, the gap between the US and Arkansas averages nine
percentage points. We see a similar dynamic at work in Georgia, shown in Figure 1B. The gap between
Georgia and the US is roughly nine percentage points among the pre-program cohorts. Starting with the
first post-program cohort, we see a convergence between the two series, with the gap closing to about five
percentage points.
In both of these figures, the sharp divergence from trend in the first program year supports the
identifying assumption of the paper. In the regression analysis, I will explicitly test for this break from
trend by controlling for linear and quadratic trends in age at the state level.

Baseline Results and Statistical Inference
Table 3 presents the results of estimating Equation (1). The coefficient of 0.0298 in Column (1) suggests
that the merit programs increased the share of the population earning a college degree by 2.98 percentage
points. To give a sense of the magnitude of this estimate, note that the pre-program level of degree
completion was about 24 percent in Georgia and Arkansas.
The heteroskedasticity-adjusted standard error is 0.82 percentage points. As discussed by
Bertrand, Duflo and Mullainathan (2004), standard errors in this context can be misleading for two
reasons: the treatment varies not across individuals but across age cohorts within states and there is likely
serial correlation in the error term across cohorts within states. The most straightforward solution is to
collapse the data into state-age means and re-run the estimating equation, adjusting the standard errors for
correlation within state of birth. Monte Carlo simulations in Bertrand, Duflo and Mullainathan (2004)
show that this approach produces hypothesis tests of the correct power. These results of this method are in
Column (2) of Table 3. The regression is weighted by the size of the population within each cell; the
14

slope coefficient is therefore identical to that obtained from the regression run in the micro data.23 The
standard error drops by more than half, to 0.40 percentage points.
An alternative approach to inference in this context, again suggested by Bertrand, Duflo and
Mullainathan (2004), is to eliminate the time series variation in the data, which also eliminates the serial
correlation. If Arkansas and Georgia had introduced their programs in the same year, this would involve
grouping the means by state of birth and pre/post-program, then running the regression in these means.
The equivalent in the current context is to regress the outcome against state and year effects in the micro
data, form residuals, and for the treatment states only do a before/after comparison of the means of these
residuals, again weighted by the cell size. With this approach, the point estimate is 2.82 percentage points
and the standard error drops yet further, to 0.30 percentage points.
These estimates of the standard errors are summarized in Table 4, along with several additional
approaches for estimating the standard errors in the microdata. With even the largest estimates of the
standard error I do not fail to reject the null. Looking across the table, we see that accounting for serial
correlation within states has a substantial impact on precision. The 95-percent confidence interval for the
program effect is four percentage points wide when unadjusted for serial correlation within states and one
to two percentage points wide when adjusted. Adjusting for serial correlation decreases standard errors in
this context because the error terms are weakly and negatively auto-correlated within each state of birth.
By contrast, the CPS wage data used in Bertrand et al. exhibit large and positive autocorrelation; thus,
adjusting for serial correlation in their context increases standard errors.24 In the remainder of the analysis,
I will estimate regressions in grouped means, with the standard errors then adjusted for autocorrelation
within states.

23

If the regression is unweighted and, therefore, each state-age cohort given equal weight, the point
estimate is 3.2 percentage points.

24

I regress the outcome variable on state-of-birth and age fixed effects and form residuals, thereby
isolating the variation that identifies the program effect. The first-, second- and third-order autocorrelation coefficients for these residuals are 0.05, -0.02 and -0.03, respectively. The analogous
autocorrelations in Bertrand et al. are 0.51, 0.41 and 0.33.
15

State-Specific Labor Market Shocks
In the classic human capital model (Becker, 1994), educational attainment is a function not only of direct
costs but also of opportunity costs and returns to schooling. If the drop in direct costs that is the subject of
this analysis is correlated with shifts these other determinants of human capital, then the estimates
obtained so far may be biased. A tight labor market will increase the opportunity costs of college, which
in theory will tend to reduce the share of young people completing a degree.25 The same booming labor
market may also boost tax revenues and thereby render a state more willing to fund a merit aid program.
This would induce a negative correlation between the merit programs and college completion. Economic
conditions may also induce a positive correlation between merit programs and college completion: high
returns to college might induce parents to pressure politicians to fund scholarships, and will also tend to
keep people in school.
To test whether labor market conditions are biasing the estimates, I add a set of control variables
to the basic specification. First, I control for the state unemployment rate, measured in the respondent’s
state of birth in the year in which he was 18 years old. This variable is intended to capture both
opportunity costs for the young person and the financial situation of his family. Second, I control for the
college wage premium among prime-wage workers, again measured in the respondent’s state of birth in
the year in which he was 18 years old.26 This is intended to capture the young person’s perceived returns
at the time he is making the decision to enroll in college. Third, I control for the size of the state-of-birthby-age cohort. This last variable may affect educational attainment through capacity constraints in
education (Bound and Turner, 2004). I allow the effect of all of these variables to vary with age, which

25

A booming labor market may also boost the income of parents of college-age children, which in the
presence of liquidity constraints will tend to increase the share of young people completing a degree.

26

I use 35- to 54-year-olds in the1984-96 March CPS to estimate these college premia. The premium is
defined as the difference between the mean log wages of year-round, full-time workers with exactly a
high school degree and a BA or above.
16

flexibly captures any changes over time in the effect of labor market conditions on schooling decisions.
Results are in Column (2) of Table 5.27 The unconditional estimate is reproduced in Column (1). After
controlling for these measures of labor market conditions the estimate drops imperceptibly, from 2.98 to
2.82, with little loss in precision. If the racial and ethnic composition of the program states is changing
over time relative to that of the comparison states, this would tend to bias the results, since race and
ethnicity are correlated with education. In the third column of the table, I therefore add additional controls
for race and ethnicity, as well these variables interacted with a sex dummy. Again, all of these variables
are interacted with age in order to allow their effect to vary flexibly over time. The estimated program
effect (Column (3)) is quite stable, at 2.63 percentage points, with a standard error of 0.53.

Robustness to Definition of Comparison States
Labor market conditions and population characteristics may be shifting in unobserved ways in the
South relative to the rest of the country. Over the past few decades, relative income and education have
been rising in the South, suggesting that the rise in education estimated in the previous sections simply
reflects a broader convergence of the South with the rest of the country. If this is the case, then the US is
a poor counterfactual for Arkansas and Georgia, with the rest of the South forming a more appropriate
comparison group. I limit the sample to those with a Southern state of birth and re-estimate Equation (2).
The result is in Column (2) of Table 6. The estimate is quite stable at 2.78 percentage points, though the
standard error doubles to 0.79 percentage points.

27

Mechanically, I control for these covariates as follows. I regress the merit dummy and outcome variable
against the covariates and form residuals. I collapse these residuals into cell means at the level of state of
birth and age and re-estimate Equation (2) with these cell means as the unit of observation. This will
produce the same point estimates as running Equation (1) in the microdata with covariates, with the
advantage of producing unbiased standard errors.
17

In the next column, I define the sample as any state that had introduced a merit program by 2003;
this includes the non-Southern states of Michigan, Nevada and New Mexico. In this approach, the states
that ever introduce a merit program form their own comparison group and the program effect is identified
from the staggered timing of the programs’ introductions. The resulting estimate is 2.64, with a standard
error of 0.48 percentage points. In the last column, I again limit the sample to states that ever introduce a
merit scholarship but drop the non-Southern merit states from this analysis. The estimate is still positive
and significant but drops to 2.29 percentage points, with a standard error of 0.60 percentage points.

Falsification Exercise
State of birth and state of residence are highly correlated. To make clear that the identification of
the program effect is driven by state of birth, rather than current state of residence, Table 7 shows the
results of re-estimating the equations with state of residence determining treatment status. That is, current
state of residence, rather than state of birth, is assumed to be the state in which a person graduated from
high school. These estimates are very small and statistically indistinguishable from zero: 0.39 and zero
percentage points when the entire US and the South, respectively, are used as the comparison groups.
This result shows that the states with scholarship programs are not simply states to which the
well-educated are migrating. This strongly supports the identification strategy of the paper. In fact, since
the estimates of the paper indicate that the merit programs are inducing more young people to complete
college, the null results of Table 7 necessarily imply that either highly educated workers are migrating out
of merit states or relatively uneducated workers are migrating into the merit states. The scenario of an
inflow of uneducated workers is consistent with Moretti (2004). He shows that a college-educated
workforce generates positive wage externalities for both skilled and unskilled workers; through this
channel, a state with a growing share of college-educated workers could be a magnet for unskilled labor.
Whether those induced to complete college remain in the state in which they are educated is
important from the state’s perspective: it is quite different to educate a college graduate and have her
leave than to have her stay and produce positive externalities. I do not explore migration in the present
18

paper, but instead focus on the efficacy of higher education policy in getting more people to complete
college, wherever those workers may take their human capital after graduation.

Underlying Trends in Educational Attainment
I have so far controlled for observable differences between the treatment and comparison states.
Any unobserved differences between the treatment and comparison states that are fixed over time will be
absorbed by the state-of-birth fixed effects and will not bias the estimates. But any changes in the
populations and economies of Arkansas and Georgia that do not also occur in the comparison states are a
threat to the internal validity of the estimates. Since the industrial composition of the South has been
shifting substantially over the last several decades, and there has been a steady migration of the US
population southward, the assumption of fixed differences between the treatment and comparison states
may well be invalid.
I informally evaluated this threat to validity with Figures 1A and 1B, which indicate a sharp break
for the affected cohorts. A more formal approach is to control parametrically for state-specific trends in
college completion. A typical method is to include linear time trends in the regression and identify the
program effect with deviations from those trends. Figures 1A and 1B make clear, however, that the
counterfactual trend is not linear, but rather quadratic. I test both the linear and quadratic functional
forms, as well as a non-parametric approach. As discussed below, all of these strategies return similar
results, with quite consistent point estimates but, in some cases, substantial loss of precision.
I first add to the baseline regression a linear term in age, interacted with the state of birth
dummies:28

(3)

yab = β meritab + λb ageab + δ a + δ b + ε ab

28

Conducting this exercise with means of the residuals, rather than unconditional means, does not alter
the results.
19

This specification allows each state to be on its own linear age trend in degree completion, with the
program effect identified by deviations from these trends. Results are in Column (2) of Table 8. For the
US sample, the point estimate drops from 2.98 to 2.21 percentage points and the standard error more than
triples, to 1.36. A similar pattern holds for the Southern census region, where the estimate drops from
2.78 to 2.45 percentage points and the standard error rises to 1.83. I next add the square of age, again
interacted with state of birth:

(4)

2
yab = β meritab + λb ageab + ηb ageab
+ δ a + δ b + ε ab

As shown in Column (3), the estimate based on the US sample is essentially unchanged, while the
Southern sample estimate rises to 3.44 percentage points. The standard errors rise yet higher and the
estimates are not statistically significant.
The approaches just discussed impose a functional form on the underlying trends. Including a
separate set of age effects for each geographic area, by contrast, allows the age-education profiles to take
whatever forms the data suggest. In Column (4), I add to the regression the interactions of age with the
nine census divisions of birth.29 Using either the US or Southern samples, the resulting estimate is 2.35
percentage points, with a standard error of about 1.5 percentage points, representing a small change in the
point estimate but a large loss in precision.
While in a single cross-section I cannot control for the interaction of state of birth with age
effects and still identify the program effect, I can control for the interaction of state of residence with age.
With this approach, those who reside in their state of birth identify the state-specific age-education
profiles, while those who live outside of their state of birth identify the program effect. Results are in
Column (5). The estimates rise slightly and are statistically significant: 4.16 percentage points for the US
and 3.18 for the Southern sample.

29

Arkansas and Georgia are in separate divisions, so separate counterfactual age profiles are estimated for
each of these treatment states.
20

Note, however, that interstate migrants may have an unusual response to the merit programs.
Interstate mobility is highly correlated with education and income, so those who live outside their state of
birth may come from relatively advantaged backgrounds; while this does not bias the estimate it may limit
its generalizability. Ideally we could control for the interaction of state of birth with age, thereby
identifying an effect averaged over those who do and do not live within their state of birth. With data
from two points in time, we can include such controls while still identifying the program effect. I
therefore bring the 1990 census into the analysis, and add to the baseline specification state-of-birth-byage effect interactions, as well as all second-order interactions of census year, state of birth and age
effects:

(5)

yabt = β meritabt + δ a + δ b + δ t + δ ab + δ bt + δ at + ε ab

Equation (5) controls for state-specific changes between 1990 and 2000 in the rate of degree-holding
(through the interactions of census year and state of birth), as well as any changes over time in the shape
of the age-education profile that are common across the states (through the interaction of census year and
age). Finally, the specification controls for any state-of-birth-specific idiosyncrasies in the shape of the
age-education profile that are persistent over time (through the interaction of state of birth with age
effects). The program effect is identified by the triple interaction of state of birth, age dummies and
census year. Put differently, it is identified by changes between 1990 and 2000 in state-of-birth-specific
age-education profiles. Results are in Table 9. For both the US and South the estimates rise slightly, to
3.50 for the US sample and 3.32 for the South. Unsurprisingly, since this specification pushes the data
quite hard, the standard errors rise substantially, to about two percentage points.30 The stability of the
coefficients, however, is strongly supportive of the identification strategy of the paper.

30

These standard errors are clustered at state of birth and census year, which is the unit of observation at
which we would be concerned about autocorrelation.
21

Accounting for Classification Error in Treatment Status
The analysis has so far used state of birth and age to assign eligibility for a merit aid program,
with each individual imputed to be eligible with probability one or probability zero. There are two sources
of error in this method of assignment to treatment status. First, in the 2000 census, 24 percent of high
school students lived outside their state of birth. Assuming this rate has not changed substantially over
time, my assignment of eligibility for merit aid is incorrect for about 24 percent of the analytical sample.
Second, many students are younger or older than 18 in the spring of their senior year, typically ranging in
age from 17 to 19. For those high school seniors who were younger or older than 18 at the time a merit
program was introduced in their state, the paper has incorrectly imputed eligibility. In this section of the
paper I attempt to correct for both of these sources of error in the assignment of treatment status.
I first address misclassification due to interstate migration. By using state of birth as a proxy for
state of high school attendance, I have so far ignored the information provided by current state of
residence. I therefore predict state of high school attendance with state of birth and use this predicted
value to assign treatment status. That is, I allow treatment status to be a probabilistic (rather than
deterministic) function of state of birth. To implement this strategy, I use high-school-age youth (15 to 17
years old) in the 2000 census to estimate a matrix of transition probabilities between state of birth and
state of high school attendance. In principle, this matrix could have 51 X 51 cells. However, since
attendance in only two states (Arkansas and Georgia) produces a treatment, it is more efficient to estimate
a matrix with dimension 51 X 2, corresponding to 51 states of birth and high school attendance in Georgia
or Arkansas.31 I apply this matrix to the older sample (22- to 34-year-olds) to yield predicted state of high
school attendance. The resulting predicted probabilities are used to define the treatment variable, which

31

Specifically, I run OLS regressions of the following form, where i indexes individuals, b indexes state
of birth and I is an indicator variable:

I ( state of residence = AR)ib = δ b + ε ib

I ( state of residence = GA)ib = µb + vib
22

now ranges from zero to one. I then re-run Equation (2).32 Results are in Table 10. The estimate rises from
2.98 to 3.74 percentage points.
This is quite close to the error-corrected estimate that would be appropriate if migration to and
from the merit states were random. Aigner (1973) and Freeman (1984) show that the relationship between
the true coefficient and that estimate in the presence of classification error is:
(6)

β* =

βˆ
1− δ

where βˆ is the coefficient estimated in the presence of measurement error and δ is the degree of
classification error.33 Nationwide, 24 percent of high school seniors live outside their state of birth, so the
baseline estimate of 2.98 corresponds to a error-corrected estimate of 3.92 (=2.98 /0.76).
I next account for measurement error in the year of high school graduation. I do so by allowing
treatment status to be a probabilistic function of age, using the 1989-91 School Enrollment Supplements
of the October CPS to estimate age-specific probabilities of being a high school senior for those age 16
through 24.34 I use these probabilities to impute for the analytical sample the probability of being a senior
in each of the years from 1984 through 2000. The resulting predicted probabilities are used to define the

32

The treatment variable is now defined as the sum of the interactions of two predicted probabilities with
age dummies, e.g., for person of age a born in state b:

meritab = Prb (high school in AR) × I (a <=18 in 1991) + Prb (high school in GA) × I (a <=18 in 1993)
33

This result may seem obvious, since classical measurement error is known to produce attenuation in
regression coefficients. However, measurement error in binary variables is non-classical: if a zero is
observed, the measurement error can only be non-negative and if a one is observed the measurement error
can only be non-positive. This violates the standard assumption that the measurement error is
uncorrelated with the truth.
34

The questions needed to determine whether a person is enrolled for a high school senior are available
for these ages only. I constrain the sum of these probabilities to equal one, so that the estimate is corrected
only for the timing of when an age cohort was a high school senior. Allowing the probabilities to sum
than less than one would inflate the estimates by the inverse of the share of a birth cohort that attains the
senior year of high school.
23

treatment variable, which now ranges from zero to one, and the key estimating equation is re-run.35 The
resulting estimate is in Table 10, Row (3): 3.33 percentage points, with a standard error of 0.57
percentage points. Finally, in Row (4) I allow treatment status to be a probabilistic function of both state
of birth and age. This yields an estimated program effect of 4.21 percentage points, with a standard error
of 0.57.
For simplicity of interpretation and exposition, in the remainder of the paper I will estimate
coefficients that are not adjusted for classification error. It should be kept in mind, however, that the
error-corrected estimates are twelve to forty percent higher than the uncorrected estimates.

V. Heterogeneity in Program Effects

The robustness checks of the previous section establish a strong case for causal interpretation of
the paper’s estimates. Estimates that control for observable characteristics and for underlying trends in
unobservable determinants of degree completion return quite similar results. So, too, do estimates that use
as the comparison group the entire US, the South alone, and states that ever introduce a merit aid
program. In every case, the estimates indicate that the merit aid programs increased the share of the
young, working age population receiving a college degree by three to four percentage points. Correcting
for mis-classification in treatment status increases the point estimate to 3.3 to 4.2. Having laid out the case
for causality in the estimated effects, in this section I identify the margins of behavior and populations
that respond most strongly to the scholarship programs.
I start by examining how margins other than college degree completion react to the programs.
This exercise is of interest for two reasons. First, it is a check on the identification strategy, in that it

35

The treatment dummy is now defined as the sum of the interactions of two predicted probabilities with
state of birth, e.g., for person of age a born in state b:
meritab =I b (born in Arkansas) × Pra (HS senior in 1991+) + I b (born in Georgia) × Pra (HS senior in 1993+)
24

allows us to confirm that there is no significant change in education at levels unaffected by the policy.
Second, it allows us to hypothesize about the marginal student whose behavior is affected by the program.
I pinpoint changes in the full distribution of schooling using the methodology of the preceding
section. I create a set of indicator variables, each indicating that an individual’s level of education is
greater than or equal to schooling category j and create means of these variables for each state-of-birth by
age cohort:
(7)

yabj = E (educ ≥ j ) ab

I then estimate program effects ( β j ) for each of these j outcomes.
(8)

yabj = β j meritab + δ aj + δ bj + ε abj

These coefficients, along with their point-wise 95 percent confidence intervals, are plotted in Figure 2.
For reference, Table 11 lists the coefficients and their standard errors. Each point represents the estimated
program effect on the probability of being equal to or above that level of education. The point above AA,
for example, is 2.98. This estimate, seen throughout in the paper, is the impact of the program on the
probability of receiving an AA or above.
For all pre-college outcomes, the estimates are close to zero. Ex ante, we might have expected an
effect of the programs upon high school graduation, since they both reward academic performance in high
school and increase the option value of graduating. 36 However, the results suggest that those whose
behavior is affected by these incentives (those close to having a B average in high school) are not at the
margin of dropping out of high school and therefore are unresponsive to this incentive.

36

High school grades have risen in Georgia since its scholarship was introduced, which is consistent with
either increased effort in high school or grade inflation. Henry and Rubenstein (2002) document a steady
correlation between SAT scores and high school grades among entering Georgia college freshmen. They
argue that this unchanging relationship is evidence against grade inflation.
25

The first positive and large estimate appears at the college entry margin, with a statistically
insignificant estimate of 1.59 percentage points.37 There is a yet larger (and significant) impact on
persistence through college, with the share completing at least some years of college rising by 1.94
percentage points. Relative to baseline, this is a large effect: in the 2000 census, 9 percent of this age
group had entered college without completing a single year. As discussed in detail in the previous section,
there is a statistically significant effect of 2.98 percentage points upon degree completion.
There is also a statistically significant impact upon completing any education beyond the BA
(1.37 percentage points). This could indicate a weakness in the identification strategy, since the
scholarships only directly subsidize undergraduate study. There are several plausible explanations for a
program effect beyond the BA. First, courses taken at the baccalaureate level often count toward a
graduate degree, so completing a BA moves one closer to an MA. For example, accounting and nursing
students at Georgia Southern University concurrently earn bachelor’s and master’s degrees, with HOPE
paying for 150 credit hours of the combined course-load; the BA requires just 120 credit hours.38 More
generally, a simple model of human capital accumulation suggests that post-baccalaureate schooling
decisions will be a function of past schooling costs, implying that a college graduate who paid less for her

37

In previous work with the Current Population Surveys, I have estimated a five to seven percentage
point impact of the merit programs on the contemporaneous college attendance rate of 18- to 19-year-olds
(Dynarski, 2000 and 2004). This result is not directly comparable to any of the present estimates, since
the attendance rate conflates two outcomes: entry and persistence conditional upon entry. Further, note
that the contemporaneous CPS attendance questions may capture short college spells forgotten by those
answering retrospective Census questions. Card and Lemieux (2001) note divergence between education
of cohorts as measured by Census and the CPS.

38

State legislators, arguing that HOPE was not intended to pay for graduate school, have voted to limit to
127 the credit hours paid by the program (Salzer, 2005). A second HOPE provision, introduced in 1996,
encourages graduate study: the state forgives graduate student loans of those who teach in Georgia
elementary and secondary schools.
26

bachelor’s degree will be more willing to borrow for a master’s degree.39 Finally, in the presence of
liquidity constraints, a scholarship can lead students to work less and thereby complete their education
more quickly. In my data, I cannot rule out that the treated cohorts are simply completing their planned
degrees at a quicker pace. If this is the case, the programs’ effects on completed education will fade as the
treated cohorts age.40 However, even if the program effect completely dissipates as cohorts age, there will
still be a positive welfare impact of the scholarships, since education completed earlier in life yields more
years of private and social returns.
I now turn to exploring heterogeneity across populations in the programs’ effects. Treatment
heterogeneity could be driven by a variety of factors that vary systematically across the population, such
as preparation in high school, labor market opportunities, returns to schooling, parental education and
liquidity constraints. I capture the reduced-form impact of all of these channels. I split the sample into
four mutually-exclusive groups: non-Hispanic white/Asian men, non-Hispanic white/Asian women,
Hispanic and nonwhite men, and Hispanic and nonwhite women, running Equation (2) separately for each
of these groups. The resulting coefficients, along with their point-wise 95 percent confidence intervals,
are plotted in Figures 3A through 3D.
I find substantial heterogeneity in the effect of the scholarships, with the most striking effects for
women. Hispanic and nonwhite women are most responsive to the scholarships (Figure 3A), with their
college entry rate rising by 5.99 percentage points and their probability of completing at least some
college rising by 7.44 percentage points. They also exhibit large increases in their probability of receiving

39

See Dynarski (2000) for the development of this model, which shows that future human capital
investment will depend on the cost of past investment if the price of debt rises with its level. There is
evidence that students and families face rising interest rates when borrowing for college. The cheapest
source of funds for most families is federally subsidized student loans, with housing equity the next
alternative. If housing equity has been exhausted, families can turn to unsubsidized federal loans. As a
last resort, families can turn to more expensive sources of funds, such as unsecured personal loans,
retirement savings and credit cards.
40

In theory, I can test for fadeout of the program effect; in practice, it is difficult to discern such patterns
from random noise and year-specific changes in program generosity.
27

any college degree (3.46 percentage points). White, non-Hispanic women (Figure 3B) respond quite
strongly, as well, with their increases concentrated at completing any college degree (3.2 percentage
points) and completing a BA (2.3 percentage points). This group also exhibits somewhat smaller effects at
college entry (1.2 percentage points) and the completion at least a year of college (1.5 percentage points).
All of these estimates are highly significant.
Program effects are relatively muted among white, non-Hispanic men (Figure 3C), but this
group’s probability of receiving a BA rises by respectable 1.93 percentage points. The results for
Hispanic and nonwhite men are mixed and noisy (Figure 3D). There are precisely-estimated increases in
the probability of completing any college degree and at least a BA (1.60 and 2.79 percentage points,
respectively), but there is also a large and insignificant drop in the probability that this group will
complete high school. This could indicate that instructional resources are being shifted away from
students on the margin of dropping out of high school, among which nonwhite and Hispanic men are
disproportionately represented, but this estimate is so imprecise that I hesitate to draw firm conclusions.
I summarize the effects on degree completion in Table 12. For the entire sample, the effect is
concentrated on the BA margin: 2.52 percentage points, as compared to 0.46 for the AA margin. A
similar relationship holds for white, non-Hispanic women, for whom the BA outcome is more sensitive
than the AA (2.29 as compared to 0.87). Among nonwhite and Hispanic women, however, the AA margin
dominates: the estimated effect is 2.63 percentage points for the AA as compared to 0.82 for BA or
above. Among men, the estimated AA effect is negative, significantly so for nonwhites and Hispanics,
indicating that the subsidies are shifting this group from AA receipt toward BA completion.

VI. Discussion

Together, these tables and figures provide strong evidence that the merit aid programs increased
the completed schooling of eligible youth. Merit aid is estimated to increase the college entry rate by 1.6
percentage points, the share who complete any years of college by 1.94 percentage points, and the share
who complete any college degree by 2.98 percentage points, and the share who complete a BA or above
28

by 2.52 percentage points. All but the first of these estimates are highly significant. All of these margins
are ones that are plausibly affected by the merit aid programs, which decrease the cost of both entering
and persisting through college.
The program effects are much stronger for women than for men; the behavioral gap among
nonwhites is especially striking. The results accord with previous evidence on the relative elasticity of
male and female college attendance (Card and Lemieux, 2001). As the return to college has risen over
time, women have made far greater gains than men in college completion rates. Between the late 1980s
add the late 1990s, young women shot past their male peers in their college completion rate, with the
share of recent high school graduates with a BA rising from 21 to 31 percent for women and from 24 to
26 percent for men. The female advantage in college-going is particularly pronounced among
nonwhites.41 Nonwhite and Hispanic men are more likely than others to drop out of high school, be
incarcerated, or join the military, all of which will blunt the effect of any scholarship on this group’s
schooling decisions. Differential performance in high school explains gender differences in the effect of a
merit scholarship, in particular. Among members of the high school class of 1992 that went to college, 49
percent of women had a high school GPA of at least 3.0, while just 36 percent of their male peers
performed as well. If these achievement patterns held in Arkansas and Georgia, fewer male than female
high school graduates would have been eligible for the merit scholarships.

How Does Merit Aid Affect Persistence in College?
I cannot separately identify the effect of merit aid on college entry and persistence conditional on
entry, because I cannot identify the marginal entrant. Instead, the paper has measured the reduced-form
impact of merit aid on completed schooling, which is the product of effects upon entry and persistence.
We can place informative bounds on the size of the persistence effect, however. One bound is formed by

41

These statistics are for the high school classes of 1982 and 1992 and are drawn from High School and
Beyond and NELS88, respectively. See National Center for Education Statistics (2005). For discussion of
the gender gap in college see Jacob (2002).
29

assuming that none of those induced into college by the scholarships completes a degree. The other bound
is formed by assuming that all of those induced into college by the scholarships complete a degree. I
calculate these bounds below, using as inputs the estimated effects from Table 12 and the following data
for pre-program cohorts in the treatment states: 51.5 percent entered college and 26.7 percent completed a
degree, leading to a baseline persistence rate of 51.8 percent (=26.7/51.5).
Scenario A: No student induced into college by the scholarship program completes a degree.
In this case, all of the 2.98 percentage point increase in degree completion must be explained by
increased persistence among those who would have entered college even in the absence of the
scholarship. The merit programs are then estimated to have increased the degree completion rate
to 29.7 percent (=26.7+2.98). The persistence rate is therefore calculated to rise by 5.2 percentage
points to 57.0 percent (=29.7/51.5), or by about ten percent (=5.2/51.8).
Scenario B: Every student induced into college by the scholarship program completes a degree.
The programs are estimated to increase college entry by 1.6 percentage points. Thus, in this
scenario, 1.38 percentage points (=2.98-1.6) of the increase in degree completion must be
attributable to increased persistence of those who would have gone to college in the absence of
the program. The program is estimated to increase their completion rate to 28.08 (=26.7+1.38)
percent, which in turn implies an increase of 2.7 percentage point in persistence (from 51.8
percent to 54.5 percent [=28.08/51.5]), or about five percent (=2.7/51.8).
The scholarship programs are therefore estimated to increase persistence to degree, conditional on college
entry, by 2.7 to 5.2 percentage points.42 Given a baseline persistence rate of 51.8 percent, this is
equivalent to a proportional increase of five to ten percent (or, equivalently, corresponds to a decrease in
the college dropout rate of six to twelve percent).
Note that the paper’s estimates reflect any incentive effect of the scholarships on academic effort
in high school and college. They are therefore not directly comparable to estimates yielded from variation

42

If we assume that marginal entrants persist at the same rate as pre-program college students, the implied
increase in the persistence rate for infra-marginal college entrants is 4.3 percentage points.
30

in price driven by, for example, Pell Grant eligibility.43 It is not clear whether the academic requirements
of the programs will tend to lead to larger or smaller college completion effects than a non-merit subsidy.
The merit programs’ academic requirements may push students to work harder in college, and thereby
make them more likely to succeed. This may make these programs particularly effective at increasing
degree receipt. Conversely, though, they may deny subsidies to many students who are on the margin of
completing a college degree, but whose grades are too low to maintain the scholarship. The programs
require a 2.75 to 3.0 GPA in college, well above the GPA required to graduate. This may make the
programs less effective in encouraging degree completion than one that is targeted at a lower point in the
distribution of academic achievement.

Cost-Benefit Analysis
While the scholarships increase college entry and degree completion, it is still the case that most
of the scholarship funds go to people who would have entered or completed college anyway. Do the
private and social returns to the human capital created by the merit scholarships justify the outlay? In this
section, I discuss the possible benefits of the programs, delineate their costs, and calculate the social
welfare consequences of the merit scholarships under a variety of scenarios.
A rich literature explores the private and social benefits of education. There is now extensive
evidence concerning the causal impact of a high school education on a variety of outcomes. High school
increases wages, extends life, increases civic participation, reduces crime and improves outcomes for the

43

Bettinger (2004) uses a regression-discontinuity strategy to identify the effect of Pell Grant eligibility
on persistence, finding that a $1,000 increase in Pell Grant eligibility increases persistence between the
first and second years of college by two to four percentage points. Extrapolating Bettinger’s results to the
current context requires assuming that the effect of a scholarship is linear in its face value and that the
effect of a subsidy on the hazard of dropping out is constant across years of college. With these
assumptions, Bettinger’s estimate predicts that the merit aid program would increase the share completing
a BA by seven to fourteen percentage points, compared to the paper’s estimates of three to four
percentage points.
31

children of those constrained to stay in school.44 We have comparatively little information about the
corresponding returns to a college education.45 Plausibly, the private and social returns to college are
different from those of high school, so many of the existing estimates cannot be safely extrapolated.
While evidence indicates a high school education keeps people out of prison, college graduation is
unlikely to yield similar benefits. For the purposes of the current calculation, I take a conservative
approach and ignore all non-financial returns and externalities. This provides a lower bound on the social
benefits of the programs.
The benefits are the sum of the marginal returns associated with attaining a given level of
schooling, weighted by the program’s causal impact on the probability that this level of schooling is
attained:

∑β α
j

j

j

Here, β j is the effect of program on probability of attaining education level of j.46 α j is the lifetime
return to attaining schooling level j rather than schooling level j-1. These returns are calculated by
summing and discounting) the age-specific difference in the annual mean earnings of those with
schooling level j and j-1:47

y −y
j

αj =

65

∑

a

a = j +6

r

j −1
a

a −1

44

See Angrist and Krueger (1991) on wages; Lleras-Muney (2005) on health; Lochner and Moretti (2004)
on crime; Dee (2004) and Milligan, Moretti and Oreopoulos (2004) on civic participation; and
Oreopoulos, Page and Stevens (2003) on improved outcomes for children of high school graduates.

45

Currie and Moretti (2003) and Moretti (2004) examine the impact of receiving a college education on
children’s health and others’ wages, respectively. Card (1995) estimates private wage returns using
distance to college as an instrument for a college education.

46

Effects are essentially zero for levels of education lower than college entry, so they are ignored.

47

While it appears that the program increased the population share with a master’s degree, I do not
include this as a program benefit in these calculations. Mechanically, I achieve this by excluding those
with education above a BA from the calculations of mean earnings.
32

To anchor the analysis, I assume that the marginal student earns the returns to education observed in the
cross section. These cross-sectional “returns” do not have a causal interpretation, since they include wage
differences driven by unobserved worker heterogeneity, but do provide a useful point of reference. Note
that these differences in annual earnings incorporate differences driven by both hourly wages and labor
supply. Both margins are plausibly affected by education.
The costs consist of the scholarships, the excess burden induced by raising funds for the
scholarships, and the forgone earnings of those who stay in school longer because of the scholarships. I
first describe costs for those whose schooling attainment is not affected by the scholarship – that is, the
inframarginals. Opportunity costs of this group do not enter the social welfare calculation, as they would
have attended college in the absence of the program. I assume that the annual scholarship is $2,500. In
expectation, about 30 percent of a given age cohort will use this scholarship for at least one year of
college.48 Forty percent of those who use the scholarship as freshmen get the scholarship for a second
year; other students drop out or get grades too low to qualify. Three-quarters of those who receive the
scholarship the second year get it a third year, and two-thirds of those who get it the third year receive it
the fourth year. Just twenty percent of those who enter with a merit scholarship will both stay in school
and earn a GPA above 3.0 long enough to earn a BA.49 I use these hazards to calculate expected
scholarship costs for the inframarginals.
For the marginals, the expected scholarship cost is a weighted sum of the estimated impact of the
program on attaining a given level of schooling and the marginal scholarship cost associated with moving
the student to that level of schooling:

48

About 60 percent of the Census sample has gone to college. About half of recent high school graduates
entering college in 2001 had a GPA of 3.0 in high school (author’s calculations from Beginning
Postsecondary Students Survey), so about 30 percent (=0.6*0.5) of a given age cohort is expected to take
up the scholarship for at least a year.
49

I have calculated these hazards using data on high school grades, college grades and persistence in the
2001 Beginning Postsecondary Students Survey. Administrative data from Georgia on the share
scholarship recipients who receive HOPE for multiple years yield hazards very similar to those predicted
by the BPS data.
33

∑β S
j

j

j

For example, the education category about the AA (a two-year degree) is the BA. The marginal
scholarship cost for moving someone from an AA to a BA is then $2,500, for two years. The scholarship
costs are inflated in order to account for the deadweight loss induced by the taxes needed to raise the
revenue for the program. Gruber and Saez (2002) conclude that the elasticity of taxable income is 0.4;
given an average tax rate of 33 percent this corresponds to an marginal deadweight loss of taxation of
0.245.50 I use a real discount rate of four percent, which is appropriate given that I am not allowing for
any real wage growth.
Given this set of assumptions, the present-discounted, per-person cost of offering the program to
an age cohort is about $1,700. Adding in the excess burden increases this cost to about $2,100.51 Eighty
percent of the scholarship funds flows to those whose schooling attainment is unaffected by the
program.52 All of the relevant opportunity costs are borne by the marginals. Across the entire cohort, they
average $2,000. All of the benefits are also produced by the marginals. Assuming that they face crosssectional returns to education, the expected lifetime returns (again, averaged over the entire cohort) are

50

The Georgia scholarship is funded by a lottery, which as a revenue source will have a lower excess
burden than the income tax since players gain utility from playing and have some chance of winning. The
Arkansas program is funded from general revenues.

51

Note that these are not per-student costs but per-person costs, averaged across the entire age cohort.
Many members of the cohort receive nothing, while relatively few receive the scholarship for four years.
52

The scholarship is a transfer that can affect utility through a variety of channels, including increased
consumption. By ignoring any benefits that accrue through channels other than increased education, I
provide a lower bound on program benefits. The program’s internal rate of return would rise considerably
if these dollars were treated as a transfer rather than a cost.
34

$8,100. Benefits exceed costs by a factor of two. The internal rate of return implied by these figures is
7.9 percent, which easily exceeds any reasonable efficiency threshold.53
A key assumption in this calculation is that marginals face the same rates of return as we observe
in the cross section. In this setting, theory does not unambiguously predict whether the marginal person
will have a return to schooling higher or lower these population values. If the scholarship loosens
liquidity constraints then her return may be higher, while if it simply reduces the price of college then her
return may be lower. Card (2001) notes that instrumental-variable estimates of the return to schooling are
typically higher than OLS estimates, which would suggest that the internal rate of return of 7.9 percent is
not overly optimistic. However, even if those whose schooling is increased by the scholarships earn
returns that are a third lower than those observed in the cross-section, the internal rate of return is 5.5
percent, while if they earn returns that are a third higher it is 9.7 percent. Note that all of these figures
represent lower bounds on the internal rate of return, as I have underestimated the benefits by ignoring
positive externalities to education and treating as a cost (rather than a transfer) the eighty percent of
scholarship dollars that go to students whose educational attainment is unaffected by the program.

VII. Conclusion

While the college attendance rate has risen sharply over time, the share of the population that has
completed college has stayed relatively flat. Given that a very high proportion of high school graduates
currently attempt college, large increases in the stock of college-educated labor will have to operate

53

The above calculations may underestimate the program costs, in that the tuition and fees paid by the
scholarship do not represent the full public cost of educating a college student. Winston (1999) estimates
that roughly thirty percent of the average cost of educating a college student is covered by tuition and
fees, with the remainder covered by endowment income and government subsidies. This average figure
surely overstates the subsidy costs for marginal college graduates, for two reasons. First, the subsidy is
highest at selective institutions, which marginal students are not likely to attend. Second, marginal cost is
almost certainly below average cost for the moderate enrollment gains induced by the scholarship
programs. But even if we add the average subsidy (and its associated deadweight loss) to the costs of the
program, the internal rate of return is 6.8 percent.
35

through the intensive rather than the extensive margin, by adding more years to the schooling of those
who enter college rather than drawing more into postsecondary education. This paper has provided strong
evidence that subsidies to the direct costs of college are an effective tool for increasing college
completion and persistence.
The results are robust to the inclusion of covariates, including measures of labor market demand
in state of birth when the college entry decision was being made. Nor does the inclusion of flexiblyspecified state-specific trends in education alter the conclusions. I find a large and significant impact of
these subsidies on both degree receipt and college entry. The results suggest that merit programs increase
college degree attainment by three to four percentage points. This is a substantial effect, given that the
baseline share of the affected population with a college degree was just 27 percent. The effects on
schooling are strongest among women, with white, non-Hispanic women increasing degree receipt by 3.8
percentage points and the share of Hispanic and nonwhite women attempting or completing any years of
college increasing by six and seven percentage points, respectively.
While my reduced-form estimation strategy cannot separately identify the effect of aid on entry
and persistence, I estimate fairly narrow bounds on the persistence effect. The merit aid programs appear
to increase by five to eleven percent the probability of persistence to degree of those who would have
gone to college in the absence of a merit aid program – that is, of inframarginal college entrants. A simple
cost-benefit analysis concludes that the private benefits of the scholarship programs substantially
outweigh their costs, with a an internal rate of return to of five to ten percent.
These results indicate that tuition policy can play a welfare-enhancing role in increasing the stock
of college-educated labor. But it should be emphasized that, for the bulk of college students, a scholarship
with very low transaction costs is not sufficient to get them to complete a degree. Even with the offer of
free tuition, a large share of students continue to drop out of college, suggesting that the direct costs of
school are not the only impediment to college completion. The results indicate that more than tuition
reduction will necessary in order to substantially increase the stock of college educated labor. Candidate

36

mechanisms are better preparation in elementary and secondary school, more intensive institutional
supports in college, and funding that extends beyond direct costs to opportunity costs.

37

References

Angrist, Joshua (1993). “The Effect of Veterans Benefits on Education and Earnings.” Industrial and
Labor Relations Review 46:4, 637-52.
Angrist, Joshua and Krueger, Alan (1991). “Does Compulsory School Attendance Affect Schooling and
Earnings?” Quarterly Journal of Economics 106:4, pp. 979-1014.
Becker, Gary (1994). Human Capital. Chicago: University of Chicago Press.
Bertrand, Marianne, Esther Duflo and Sendhil Mullainathan (2004). “How Much Should We Trust
Differences-in-Differences Estimates?” Quarterly Journal of Economics 119:1, pp. 249-275.
Bettinger, Eric (2004). “How Financial Aid Affects Persistence,” in Caroline Hoxby, ed., College
Choices: The Economics of Where to Go, When to Go, and How To Pay for It. Chicago:
University of Chicago Press.
Bound, John and Sarah Turner (2002). “Going to War and Going to College: Did World War II and the
G.I. Bill Increase Educational Attainment for Returning Veterans?” Journal of Labor Economics.
20 (4): 784-815.
Bound, John and Sarah Turner (2004). “Cohort Crowding: How Resources Affect Collegiate
Attainment.” University of Michigan Population Studies Center, Research Report No. 04-557.
Card, David (1995). “Using Geographic Variation in College Proximity to Estimate the Return to
Schooling,” in Aspects of Labour Market Behaviour: Essays in Honour of John Vanderkamp, ed.
by Louis N. Christofides, E. Kenneth Grant, and Robert Swidinsky. Toronto: University of
Toronto Press, pp. 201-222.
Card, David (2001). “Estimating the Return to Schooling: Progress on Some Persistent Econometric
Problems.” Econometrica 69:5, pp. 1127-1160.
Card, David and Alan B. Krueger (1992). “Does School Quality Matter? Returns to Education and the
Characteristics of Public Schools in the United States.” Journal of Political Economy 100:1, 1-40.
Card, David and Thomas Lemieux (2001). “Dropout and Enrollment Trends in the Postwar Period: What
Went Wrong in the 1970s?” in Jonathan Gruber, ed., Risky Behavior among Youths: An
Economic Analysis. Chicago: University of Chicago Press.
Cornwell, Christopher and David Mustard (2005). “Merit-Based Scholarships and Car Sales.”
Unpublished manuscript, University of Georgia.
Cornwell, Christopher, David Mustard and Deepa Sridhar (2004). “The Enrollment Effects of MeritBased Financial Aid: Evidence from Georgia’s HOPE Scholarship.” Unpublished manuscript,
University of Georgia.
Cornwell, Christopher, Kyung Hee Lee and David Mustard (2004). “Student Responses to Merit
Scholarship Retention Rules.” Unpublished manuscript, University of Georgia.

38

Currie, Janet and Enrico Moretti (2003). “Mother’s Education and the Intergenerational Transmission of
Human Capital: Evidence from College Openings.” Quarterly Journal of Economics 118:4, pp.
1495-1532.
Dee, Thomas (2004). “Are There Civic Returns to Education?” Journal of Public Economics 88:9, pp.
1697-1720.
Dynarski, Susan (2000). “Hope for Whom? Financial Aid for the Middle Class and Its Impact on College
Attendance.” National Tax Journal 53:3, 629-661.
Dynarski, Susan (2002). “The Behavioral and Distributional Implications of Aid for College.” American
Economic Review 92:2, 279-285.
Dynarski, Susan (2003). “Does Aid Matter? Measuring the Effect of Student Aid on College Attendance
and Completion.” American Economic Review 93:1, 279-288.
Dynarski, Susan (2004). “The New Merit Aid,” in Caroline Hoxby, ed., College Choices: The Economics
of Where to Go, When to Go, and How To Pay for It. Chicago: University of Chicago Press.
Ellwood, David (2001). “The Sputtering Labor Force of the 21st Century: Can Social Policy Help?” in
Alan Krueger and Robert Solow, eds., The Roaring Nineties: Can Full Employment Be
Sustained? New York: Russell Sage.
Ellwood, David and Thomas Kane (2000). “Who is Getting a College Education? Family Background and
the Growing Gaps in Enrollment,” in Sheldon Danziger and Jane Waldfogel, eds., Securing the
Future. New York: Russell Sage.
FPG Child Development Institute, University of North Carolina (2005). “Early Learning, Later Success:
The Abecedarian Study, Early Childhood Educational Intervention for Poor Children: Executive
Summary.” http://www.fpg.unc.edu/~abc/summary.cfm Accessed July 14, 2005.
Gruber, Jonathan and Emmanuel Saez (2001). “The Elasticity of Taxable Income: Evidence and
Implications.” Journal of Public Economics 84:1, pp. 1-32.
Henry, Gary and Ross Rubenstein (2002). “Paying for Grades: Impact of Merit-based Financial Aid on
Educational Quality.” Journal of Policy Analysis and Management 21:1, pp. 93-109.
Healy, Patrick (1997). “HOPE Scholarships Transform the University of Georgia.” The Chronicle of
Higher Education, November 7, p. A32.
Jacob, Brian (2002). “Where the Boys Aren’t: Non-cognitive Skills, Returns to School and the Gender
Gap in Higher Education.” Economics of Education Review 21, pp. 589-98.
Kane, Thomas J. (1994). “College Entry by Blacks since 1970: The Role of College Costs, Family
Background, and the Returns to Education.” Journal of Political Economy 102:5, 878-911.
Kane, Thomas J. (2003). “A Quasi-Experimental Estimate of the Impact of Financial Aid on CollegeGoing.” National Bureau of Economic Research Working Paper 9703,
Krueger, Alan and Diane Whitmore (2001). “The Effect of Attending a Small Class in the Early Grades
on College-test Taking and Middle School Test Results: Evidence from Project Star.” Economic
Journal 111 (January), pp. 1-28.

39

Leslie, Larry and Paul Brinkman. 1988. The Economic Value of Higher Education. New York:
Macmillan.
Lleras-Muney, Adriana (2005) “The Relationship between Education and Adult Mortality in the United
States,” Review of Economic Studies 72:1.
Lochner, Lance and Enrico Moretti (2004), “The Effect of Education on Crime: Evidence from Prison
Inmates, Arrests, and Self-Reports,” American Economic Review, 94:1 (March), pp. 155-189.
Long, Bridget (2004). “How do Financial Aid Policies affect Colleges? The Institutional Impact of the
Georgia HOPE Scholarship.” Journal of Human Resources 39:3.
Meyer, Bruce (1995). “Natural and Quasi-Natural Experiments in Economics.” Journal of Business and
Economic Statistics 12, 151–162.
Milligan, Kevin, Enrico Moretti, and Philip Oreopoulos (2004). “Does Education Improve Citizenship?
Evidence from the U.S. and the U.K.” Journal of Public Economics 88:9-10.
Moretti, Enrico (2004). “Estimating the Social Return to Higher Education: Evidence from Longitudinal
and Repeated Cross-Sectional Data.” Journal of Econometrics 121:1-2 pp. 175-212.
National Center for Education Statistics, US Department of Education (2005). “Gender Differences in
Participation and Completion of Undergraduate Education and How They Have Changed Over
Time.” Washington, DC: Government Printing Office.
Oreopoulos, Philip, Marianne Page and Ann Stevens (2003). “Does Human Capital Transfer from Parent
to Child? The Intergenerational Effects of Compulsory Schooling.” Unpublished manuscript,
University of Toronto.
Organization for Economic Cooperation and Development (2004). Education at Glance: OECD
Indicators 2004. Paris: OECD.
Salzer, Patrick (2005). “House Votes to Limit HOPE to 127 Credits.” The Atlanta Journal Constitution,
February 22.
Seftor, Neil and Turner, Sarah (2002). “Back to School: Federal Student Aid Policy and Adult College
Enrollment.” Journal of Human Resources 37:2, 336-352.
Stinebrickner, Ralph and and Todd Stinebricker (2003). “Understanding Educational Outcomes of
Students from Low-Income Families.” Journal of Human Resources 38:3, 591-617.
Tinto, Vincent (1994). Leaving College: Rethinking the Causes and Cures of Student Attrition. Chicago:
University of Chicago Press.
Turner, Sarah E. (2004) “Going to College and Finishing College: Explaining Different Educational
Outcomes,” in Caroline Hoxby, ed., College Choices: The Economics of Where to Go, When to
Go, and How To Pay for It. Chicago: University of Chicago Press.
Winston, Gordon (1999). “Subsidies, Hierarchy and Peers: The Awkward Economics of Higher
Education.” Journal of Economic Perspectives 13:1, pp. 13-36.

40

Table 1
College Experience vs. College Completion
Age 25-34
2000 Census, 1% Sample
% with Any
College
Experience

% with College
Degree
(AA or BA)

% with College
Degree
(BA)

Share of College
Entrants Not
Completing a
Degree

Black or Hispanic

60.8%

26.8%

18.8%

56%

White Non-Hispanic

71.4%

44.8%

35.4%

37%

Table 2
Sample Means, by State of Birth
22- to 34-year olds
Census 2000, 1% Sample

Arkansas

Georgia

Rest of South

Rest of US

Any College Experience

0.495

0.517

0.551

0.606

Any College Degree

0.223

0.260

0.282

0.337

Associate's Degree Only

0.058

0.060

0.068

0.083

Bachelor's Degree or Above

0.165

0.200

0.214

0.254

Nonhispanic White or Asian

0.786

0.682

0.707

0.783

Unemployment Rate in State of Birth, at Age 18

0.072

0.056

0.066

0.064

N

3,467

9,225

97,321

332,347

Notes: Means are unweighted. Observations with imputed values of education, age or state of birth are dropped. Unemployment rate
is that of young people, from Bureau of Labor Statistics. Mississippi, which introduced a merit program in the middle of the period
under analysis, is dropped from the sample.

Table 3
OLS Estimates of Effect of
Merit Aid Programs on College Degree Attainment
22- to 34-year-olds, 2000 Census

US
(1)
Micro Data

(2)
Cell Means,
Weighted by N ab

(3)
Cell Means,
Unweighted

Merit Aid Program

0.0298
(0.0082)

0.0298
(0.0040)

0.0324
(0.0040)

Age Fixed Effects

Y

Y

Y

State of Birth Fixed Effects

Y

Y

Y

345,039

650

650

0.33

0.33

0.33

N
Mean of Y

Notes:
Micro regression: Heteroskedasticity-adjusted standard error in parentheses.
Cell-mean regressions: standard errors adjusted for correlation within state of birth. Regression in Column
(2) weighted by number of observations within the age-state of birth cell.

Table 4
Robustness of Statistical Inference

(1)
(2)
(3)
(4)

I. Micro Data
Alternative approaches to computing standard error
no adjustment for autocorrelation
arbitrary variance-covariance in error term, by state of birth
arbitrary variance-covariance in error term, by state of birth & age

0.0298
(0.0082)
(0.0038)
(0.0096)

(6)
(7)

II. Unconditional Cell Means
Alternative approaches to computing standard error
no adjustment
arbitrary variance-covariance in error term, by state of birth

(0.0104)
(0.0040)

(8)
(9)

III. Eliminate Time Series Variation
before/after comparison of treatment state residuals

0.0282
(0.0030)

(5)

0.0298

Notes: All methods of estimating the standard errors account for heteroskedasticity.
I. Micro Data : Specification consists of degree regressed on merit dummy, state of birth fixed effects
and age fixed effects.
II. Unconditional Cell Means : Same as micro regression but data aggregated to state-of-birth by age
cells and regression weighted by cell size.
III. Eliminate Time Series Variation: In microdata, outcome and treatment dummy regressed on state
of birth and age fixed effects. Residuals aggregated to state-of-birth-by-age cells and these means (for
treatment states only) regressed against treatment dummy.

Table 5
Control for Labor Market Characteristics & Demographics

Merit Eligibility

Cohort Size, Unemployment Rate & College Premium
Sex, Race, Ethnicity

(1)

(2)

(3)

0.0298
(0.0040)

0.0282
(0.0042)

0.0263
(0.0053)

Y

Y
Y

Notes: All covariates are interacted with age dummies. State-age mean residuals from regressions that
include the listed covariates are the unit of observation. Regressions are weighted by cell size and
standard errors are adjusted for correlation at the state level. Cohort size is measured in the 2000 census
for age cohort within each state of birth. Return to college is for state of birth in year individual was 18
and is calculated from the 1984-96 March CPS among 35-54-year-olds; see text for details.

Table 6
Sensitivity of Results to Choice of Comparison States

Southern States
that Ever
Introduce Merit
Aid

US

Southern States

States that Ever
Introduce Merit
Aid

(1)

(2)

(3)

(4)

Merit Aid Program

0.0298
(0.0040)

0.0278
(0.0079)

0.0264
(0.0048)

0.0229
(0.0060)

Age Fixed Effects

Y

Y

Y

Y

State of Birth Fixed Effects

Y

Y

Y

Y

N

650

208

156

117

Mean of Y

0.33

0.28

0.28

0.27

Notes:
Micro regressions: standard errors adjusted for correlation within state of birth in parentheses; within state of birth and age in brackets.
Cell-mean regressions: weighted by cell size with standard errors adjusted for correlation within state of birth.

Table 7
Falsification Exercise
Assignment of Treatment Status Based of State of Residence

US

South

(1)

(2)

(3)

(4)

State of
Birth

State of
Residence

State of
Birth

State of
Residence

Merit Aid Program

0.0298
(0.0040)

0.0039
(0.0149)

0.0278
(0.0079)

0.0000
(0.0176)

Age Fixed Effects

Y

Y

Y

Y

State of Birth Fixed Effects

Y

State of Residence Fixed Effects
N

Y
Y

650

650

Y
208

208

Note: Regressions are at the level of cell means (age by state of birth in Columns (1) and (3) and age by state
of residence in Columns (2) and (4)). Regressions weighted by cell size. Standard errors adjusted for
correlation within state of birth (1 and 3) or state of residence (2 and 4).

Table 8
Robustness Check:
Linear, Quadratic and Non-Parametric Controls for Underlying Trends

State of Birth X Age Trends

Baseline

Census Division
X Age Effects

State of Residence
X Age Effects

Linear

Quadratic

Nonparametric

Nonparametric

(1)

(2)

(3)

(4)

(5)

United States

0.0298
(0.0040)

0.0221
(0.0136)

0.0216
(0.0209)

0.0235
(0.0145)

0.0416
(0.0120)

South

0.0278
(0.0079)

0.0245
(0.0183)

0.0344
(0.0235)

0.0235
(0.0149)

0.0318
(0.0140)

Notes: Dependent variable is state-age mean of degree. Regressions are weighted by cell size and standard errors are adjusted for correlation at the state level.
All regressions include state-of-birth and age fixed effects. Specification in Column (2) includes a separate linear trend in age for each state of birth.
Specification in Column (3) includes a separate quadratic trend in age for each state of birth. Column (4) includes a full set of age-effect X division interactions.
Column (5) includes a full set of age-effect X state-of-residence interactions.

Table 9
Robustness Check:
Non-Parametric Controls for Age, by State of Birth
US

Program Effect

South

(1)

(2)

(3)

(4)

Baseline

Control for
State-of-Birth X
Age

Baseline

Control for
State-of-Birth X
Age

2000

1990 & 2000

2000

1990 & 2000

0.0298
(0.0040)

0.0350
(0.0205)

0.0278
(0.0079)

0.0332
(0.0218)

Age Dummies X State of Birth

Y

Y

Age Dummies X Census Year

Y

Y

Census Year X State of Birth

Y

Y

N

650

1,300

208

416

Notes: Standard errors adjusted for heteroskedasticity and correlation within state of birth and census year All regressions are weighted by
cell size and include state-of-birth and age fixed effects.

Table 10
Correct for Measurement Error in Treatment Status
US Sample, 22-34-year-olds

(1)

Baseline

0.0298
(0.0040)

(2)

Predict State in Which High School Senior

0.0374
(0.0054)

(3)

Predict Year in Which High School Senior

0.0333
(0.0057)

(4)

Predict State and Year in Which High School Senior

0.0421
(0.0057)

Notes:
Row (1): Treatment status is a deterministic function of age and state of birth.
Individuals are assumed to attend high school in state of birth and be a high school senior at age 18.
Row (2): Treatment status is a deterministic function of age and a probabilistic function of state of birth.
High-school age (15- to 17-year-old) individuals in the 2000 census are used to estimate a transition matrix between
state of birth and state of residence. Matrix is used to estimate the probability of residence in a merit-aid state during
high school for the analytical sample.
Row (3): Treatment status is a probabilistic function of age and a deterministic function of state of birth.
1989-1991 School Enrollment Supplements of the October CPS are used to estimate age-specific probabilities of being
a high school senior among 16- to 24-year-olds. Separate probabilities are estimated by sex-race. These probabilities
are used to estimate the probability of being a senior in each of the years from 1984 through 2000 for the analytical
sample. The sum of these probabilities is constrained to equal one.
Row (4): Treatment status is a probabilistic function of age and a probabilistic function of state of birth.
Methods of both Row (2) and Row (3) are used to predict treatment status.

Table 11
Program Effect by Level of Education
22- to 34-year-olds, US born

Effect on probability that education is
greater than or equal to…
No schooling
Nursery to 4
5-6
7-8
9
10
11
12, no diploma
12, diploma
< 1 year college
some college, no degree
AA
BA
MA
Prof Degree
PhD

coefficient

se

-0.0014
-0.0010
-0.0014
0.0015
-0.0017
-0.0056
-0.0064
-0.0059
0.0159
0.0194
0.0298
0.0252
0.0137
0.0046
0.0012

(0.0003)
(0.0003)
(0.0006)
(0.0007)
(0.0048)
(0.0050)
(0.0087)
(0.0056)
(0.0100)
(0.0042)
(0.0040)
(0.0044)
(0.0047)
(0.0020)
(0.0003)

Table 12
Heterogeneity in Treatment Effects By Race, Ethnicity and Sex
US Sample
(1)

(2)

(3)

Any College
Degree

BA
or above

AA Only

Full Sample

0.0298
(0.0040)

0.0252
(0.0044)

0.0046
(0.0025)

White Non-Hispanic Women

0.0316
(0.0048)

0.0229
(0.0050)

0.0087
(0.0020)

Nonwhite and Hispanic Women

0.0346
(0.0214)

0.0082
(0.0138)

0.0263
(0.0082)

White Non-Hispanic Men

0.0158
(0.0092)

0.0193
(0.0050)

-0.0035
(0.0093)

Nonwhite and Hispanic Men

0.0160
(0.0034)

0.0279
(0.0047)

-0.0120
(0.0028)

Notes: Each coefficient represents a separate regression. Dependent variable is state-age
mean of degree for specified group. Regressions are weighted by cell size and standard
errors are adjusted for correlation at the state level. All regressions include state-of-birth
and age fixed effects.

Figure 1A: Proportion Holding a College Degree,
by Age Cohort, Census 2000
Arkansas vs. Rest of US
Line indicates last pre-program year
40%

30%

20%

Rest of US
AR

10%

Year in Which Age 18 (Age in Census 2000)

1996 (22)

1995 (23)

1994 (24)

1993 (25)

1992 (26)

1991 (27)

1990 (28)

1989 (29)

1988 (30)

1987 (31)

1986 (32)

1985 (33)

1984 (34)

0%

Figure 1B: Proportion Holding a College Degree,
by Age Cohort, 2000 Census
Georgia vs. Rest of US
Line indicates last pre-program year
40%

30%

20%

Rest of US
GA

10%

Year in Which Age 18 (Age in Census 2000)

1996 (22)

1995 (23)

1994 (24)

1993 (25)

1992 (26)

1991 (27)

1990 (28)

1989 (29)

1988 (30)

1987 (31)

1986 (32)

1985 (33)

1984 (34)

0%

Figure 2
Effect of Merit Aid of Full Distribution of Education
Plotted is effect on Pr(Educ>=X)

0.10
0.08
0.06
0.04
0.02

-0.06
-0.08
-0.10

PhD

Prof Degree

MA

BA

AA

some college, no
degree

< 1 year college

11

10

9

7-8

5-6

12, diploma

-0.04

12, no diploma

-0.02

Nursery to 4

0.00

Figure 3A
Effect of Merit Aid of Full Distribution of Education
Plotted is effect on Pr(Educ>=X)
Non-Hispanic White Women

0.10
0.08
0.06
0.04
0.02

-0.06
-0.08
-0.10

PhD

Prof Degree

MA

BA

AA

some college, no
degree

< 1 year college

11

10

9

7-8

5-6

12, diploma

-0.04

12, no diploma

-0.02

Nursery to 4

0.00

Figure 3B
Effect of Merit Aid of Full Distribution of Education
Plotted is effect on Pr(Educ>=X)
Hispanic and Nonwhite Women

0.10
0.08
0.06
0.04
0.02

-0.06
-0.08
-0.10

PhD

Prof Degree

MA

BA

AA

some college, no
degree

< 1 year college

11

10

9

7-8

5-6

12, diploma

-0.04

12, no diploma

-0.02

Nursery to 4

0.00

Figure 3C
Effect of Merit Aid of Full Distribution of Education
Plotted is effect on Pr(Educ>=X)
Non-Hispanic White Men

0.10
0.08
0.06
0.04
0.02

-0.06
-0.08
-0.10

PhD

Prof Degree

MA

BA

AA

some college, no
degree

< 1 year college

11

10

9

7-8

5-6

12, diploma

-0.04

12, no diploma

-0.02

Nursery to 4

0.00

Figure 3D
Effect of Merit Aid of Full Distribution of Education
Plotted is effect on Pr(Educ>=X)
Hispanic and Nonwhite Men

0.10
0.08
0.06
0.04
0.02

-0.06
-0.08
-0.10

PhD

Prof Degree

MA

BA

AA

some college, no
degree

< 1 year college

11

10

9

7-8

5-6

12, diploma

-0.04

12, no diploma

-0.02

Nursery to 4

0.00

Appendix Table 1
State Merit Aid Programs

State

Start

Arkansas

1991

Florida
Georgia
Kentucky
Louisiana
Maryland

1997
1993
1999
1998
2002

Award
In-State Only

Eligibility
initial: 2.5 GPA in HS core & 19 ACT

public: up to $2,500*

renew: 2.75 college GPA

private: same

initial: 3.0-3.5 HS GPA & 970-1270 SAT/20-28 public: 75-100% tuition/fees*
renew: 2.75-3.0 college GPA

private: 75-100% avg public tuition/fees*

initial: 3.0 HS GPA

public: tuition/fees

renew: 3.0 college GPA

private: $3,000

initial: 2.5 HS GPA

public: $500-3,000*

renew: 2.5-3.0 college GPA

private: same

initial: 2.5-3.5 HS GPA & ACT > state mean

public: tuition/fees + $400-800*

renew: 2.3 college GPA

private: avg public tuition/fees*

initial: 3.0 HS GPA in core

2-yr school - $1,000

renew: 3.0 college GPA
Michigan
Mississippi
Nevada
New Mexico
S. Carolina
Tennessee**
W. Virginia

2000
1996
2000
1997
1998
2003
2002

4-yr school - $3,000
th

initial: level 2 of MEAP or 75 pctile of
renew: NA

in-state: $2,500 once

initial: 2.5 GPA & 15 ACT

fresh/soph: $500

renew: 2.5 college GPA

jr/sr: $1,000

initial: 3.0 GPA & pass Nevada HS exam

public 4 yr: tuition/fees (max $2,500)

renew: 2.0 college GPA

public 2-yr: tuition/fees (max $1,900)

st

out-of-state: $1,000 once

initial: 2.5 GPA 1 semester of college
renew: 2.5 college GPA

public: tuition/fees

initial: 3.0 GPA & 1100 SAT/24 ACT

2-yr school - $1,000

renew: 3.0 college GPA

4-yr school - $2,000

initial:

3.0 college GPA or 890 SAT/19 ACT

2-yr school - $1,500 or tuition and fees

renew:

2.75 - 3.0 college GPA

4-yr school - $3,000 or tuition and fees

private: none

initial: 3.0 HS GPA in core & 1000 SAT/21

public: tuition/fees

renew: 2.75-3.0 college GPA

private: avg public tuition/fees

*award varies with test score or GPA
** Award valid at all institutions in the Southern Association of Schools and Colleges

Appendix Table 2
Census 2000 Educational Attainment Question

What is the highest degree or level of school this person has COMPLETED? Mark ONE box. If currently
enrolled, mark the previous grade or highest degree received.

01

No schooling completed

02

Nursery school to 4th grade

03

5th grade or 6th grade

04

7th grade or 8th grade

05

9th grade

06

10th grade

07

11th grade

08

12th grade, NO DIPLOMA

09

HIGH SCHOOL GRADUATE — high school DIPLOMA or the equivalent (for example: GED)

10

Some college credit, but less than 1 year

11

1 or more years of college, no degree

12

Associate degree (for example: AA, AS)

13

Bachelor’s degree (for example: BA, AB, BS)

14

Master’s degree (for example: MA, MS, MEng, MEd, MSW, MBA)

15

Professional degree (for example: MD, DDS, DVM, LLB, JD)

16

Doctorate degree (for example: PhD, EdD)

