blUR WORKING PAPER SERIES

UNIT ROOTS IN REAL CNP: DO WE KNOW. AND DO WE CARE?

Lawrence 3. Christiano
Martin Eichenbaum

Working Paper No. 3130

NATIONAL RIJREM) OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
October 1989

We are grateful to Christopher Sims for criticisms and suggestions which led to
substantial improvements on an earlier draft of this paper. We also thank R.
Anton Braun, John Campbell, John Cochrane. Pierre Perron, Danny Quah, James
Stock, Mark Watson, and Ken West for their comments. We are indebted to Kathy
Rolfe for exceptional editorial assistance. This research was supported in
part by a grant from the National Science Foundation. This paper is part of
NBER's research program in Economic Fluctuations. The views expressed herein
are those of the authors and not those of the Federal Reserve Rank of
Minneapolis. the Federal Reserve Bank of Chicago, the Federal Reserve Bank
System, or the National Bureau of Economic Research.

NBER Working Paper #3130
October 1989

UNIT ROOTS IN REAL CNP: DO WE KNOW, AND DO WE CARE?

ABSTRACT

No, and maybe not.

Lawrence J. Christiano
Research Department
Federal Reserve Bank of
Minneapolis
Minneapolis, MM 55480

Martin Eichenbaum
Department of Economics
Northwestern University
Evanston, IL 60208

Macroeconomists have traditionally viewed movements in aggregate output as repre-

senting temporary fluctuations about a deterministic trend. According to this view,

Innovations to real gross national product (GM?) should have no impact on long—run
forecasts of aggregate output. Increasingly, however, this view of aggregate fluctuations has been challenged. Following the important work of Nelson and Plosser (1982),

numerous economists have argued that real GNP is best characterized as a stochastic

process that does not revert to a deterministic trend path.

Under these circum-

stances, innovations to real GM? should affect output forecasts into the indefinite
In pursuing this interpretation of the data, various researchers have tried

future.

to

measure the long-run response of real GM? to a shock. Estimates of this response

are often referred

to as

the persistence of shocks to real GM?.

Not surprisingly, the literature on persistence has
recent

become

intertwined with

controversies over the empirical plausibility of two Important classes of sta-

tistical univariate time series models: trend stationary and difference stationary
models.

Ultimately, proponents of the view that shocks to real GM? are persistent

must build their case on the empirical plausibility of the hypothesis that real GM? is

difference rather than trend stationary or, in other words, that real

GNP has a unit

root.
To us, the possibility of providing a !•oompelling case that real GM? is either
trend or difference stationary seems extremely small, certainly on the basis of postwar data.
processes
140w

This is because there is only one difference between these two types of

and that

difference

is completely suimitarized by tbe answer to the question,

much should an innovation to real GM? affect the optimal forecast of real GM? into

the infinite future? If the answer is zero, then real GM? is trend stationary. If
the answer is not zero, then real GM? is difference stationary. The competing hypoth-

eses have no other testable differences. Once we pose the question in this way, it
seems clear that economists ought to be extremely skeptical of any argument that pur-

ports to support one view or the other. Simply put, it's hard to believe that a mere
10 years of data contain any evidence on the only experiment that is relevant.

-2Notwithstanding

these obvious difficulties, over the past decade there haS been

an explosion of empirical research on whether macroeconomic time series are best
viewed as trend or difference stationary. Even more surprising are the strong conclu-

sions that seem to mark this literature.

For example, Schwert (1987, p. 99) writes

that "following Nelson and Plosser, many authors have found that many aggregate output
series .

. ., aggregate

price level sel'ies . .

., and

other aggregate nominal series

nontain a unit root." Slanchard and Quah (1988, p. 1) simply begin their analy-

sis by stating that "in response to an innovation in GNP of 1%, one should revise

one's forecast by more than i over long horizons.

This fact is documented by

Campbell and Mankiw (i987a), building on earlier work by Nelson and Plosser (1982)."

And Campbell and Mankiw (i987b, p. iii) write that "much disagreement remains over
exactly how persistent are shocks to output. Nonetheless, among investigators using
postwar quarterly data, there is almost unanimity that there is a substantial permanent effect."

The first part of thia paper argues that the new consensus about the presence and

size of the unit root in real UN? is not supported by an analysts of postwar U.S. GNP
data.

The data simply do not discriminate between the trend stationary and the

difference stationary views of U.S. real GNP. Given the nature of the difference
between

these two types of stochastic processes, any argument in favor of one or the

other necessarily relies on strong identifying restrictions. Unfortunately, inference
turns

out to be extremely sensitive to exactly which identifying restrictions are

made. Moreover, the relevant sets of identifying restrictions are not the sort which
economic

theory has anything to say about.

The paper argues this point in two ways. Initially, we investigate the problem
using the parametric approach proposed by Campbell and Mankiw (i98Ta). The basic
strategy

is to estimate the long—run response of real GNP to an innovation using a

particular parametric, autoregressive moving average (ARMA) representation of the
growth rate of real UN!'.

For the postwar U.S. data, the relative plausibility of the

-3trend and the difference stationary hypotheses depends critically on the precise order
of the ARIIA representation chosen. Campbell and Kankiw (1987a) emphasize an ARIIA(2,2)

representation of postwar U.S. real GNP.

Indeed, if one conditions on that precise

representation of the data, then real CNP is plausibly argued to be difference stationary. Unfortunately, very small perturbations in the order of the ARIIA representa-

tion turn out to have a very large impact on this inference.

For example, if one

conditions on an ARMA(3,3) representation of the data, then real CNP appears to be
trend atationary. Neither the data nor econowic theory can convincingly discriminate
between these competing representations of real GNP.

Since inference is very sensitive to particular parametric assumptions, we also
examine the problem using the nonparametric methods developed by Cochrane (1988a}. We

show that, when applied to postwar data, these methods are completely uninformative
about the relative plausibility of the trend and the difference stationary hypotheses.

How much should one's forecast of real CNP over long horizons be revised in

response to a 1 percent innovation? Taken together, our results lead us to answer, We
don't know.

Indeed, we argue that this is the right answer even If by long horizons

we mean periods as short as five years.

Taking any other position simply seems

unwarranted by the available evidence.

The second part of this paper investigates the consequences of not knowing. Here

we ask the question, Do we care if real GNP has a unit root? Our answer is, Maybe
not. Some authors have argued that we should care because the degree of persistence -

in

real ON? can be used to infer what the principal impulses driving business cycles

are (for example, Long and Plosser, 1983; Dc Long and Summers, 1988). This line of

reasoning presumes that If real OH? is highly persistent, then the shocks must be
principally to technology, whereas if there is little persistence, then the shocks
must be principally to aggregate demand, such as innovations to monetary and fiscal
policy. Campbell and Mankiw (1981's), Cochrane (1988a}, and West (1988b) argue persua-

sively against this view by pointing out that in a variety of plausible models these
presumptions are wrong.

—4—
A more plausible reason for earing revolves around the possibility that the
implications of dynamic economic models depend sensitively on the presence or absence

of a unit root in the forcing variables to agents' environments. Our results suggest

that the degree of sensitivity is minimal.

What economic agents care about is the

relative importance of temporary versus permanent shocks to their environments—-and
this is, at best, only loosely related to the unit root issue.

We reach this conclusion by considering two exsmples which have been used to
argue for the importance of unit recta. These are Deaton's (1g86) and iansen's 19B9)

analyses of the permanent income hypothesis CPIH) and real business cycle lilaC)
models. Both authors argue that the dynamic properties of their respective models are

extremety sensitive to the presence or absence of unit roots in income.

Indeed,

Deaton and Nansen argue that the degree of sensitivity is large enough to affect
inference about the overall plausibility of the models.

Taken at face value, these examples do create a presumption that we should care
about the unit root issue.

However, this presumption turns out to depend on a key

maintained assumption of both analyses, nsaely, that the forcing variables of concern

to agents are driven by a single shock.

This assumption implies a sharp dichotomy

between trend and difference stationary specifications which is not tied in any logical way to the unit root issue. With only one shock to agents' environments, a trend

stationary specification implies that all shocks have purely temporary effects,
whereas difference stationary specifications necessarily incorporate the opposite
extreme; all shocks have purely permanent effects.

But without this assumption,

difference stationarity does not imply the absence of temporary shocks to agents'
environments.

To see why, suppose we actually knew that a particular random variable was
difference stationary.

Indeed, assume that we actually knew the univariate, differ-

ence stationary, Wold representation of the random variable. For each such representation, the variable can be decomposed into permanent and temporary components in an

—5—
infinite number of ways (Quah, 1988). While each decomposition implies precisely the

same univariate time series representation, each decomposition embodies different
assumptions about the relative importance of permanent and temporary shocks to the
variable. Simply knowing the univariate time series representation of a random van—
abie provides no information about which of the infinite decompositions agents may be
observing and responding to. At the same time,. which decomposition is chosen is critical since agents' actions differ depending on whether they are responding to a perma-

nent or a temporary shook.

Cbnseque7ntly•, the properties of dynamic models will in

general depend sensitively on the relative importance of permanent and temporary
shocks. Agreeing on the presense of a unit root in the law of motion for some variable, or even the variable's univanlate time series representation, imposes almost no

restrictions on one's view of this issue since there always exists a decomposition
which makes the permanent cornonent arbitrarily small.

Allowing for the presence of a temporary component in the difference stationary

representation of the forcing variables to agents' environments breaks the sharp
dichotomy implicit in the analyses of Deaton and Hansen. Quah (1989) shows this quite

dramatically in his discussion of Deaton's results. When agents see only the univariate, difference stationary representation for labor income, consumption is predicted to be about 1.8 times as volatile as income; when the trend stationary specifi-

cation is adopted, consumption is predicted to be 0.2 times as volatile as income.
Despite

these sharp differences, Quah is able to dispisy a temporary/permanent decom-

position of Deston's difference stationary model of labor income which has the following property:

If agents observe both components separately, then the predicted rela-

tive volatility of consumption coincides with the predictions of the trend stationary

model of labor income. This is true despite the fact that the anivaniate time series

representation implied by Quah's components model is precisely the same as that

implied

by Deston's difference stationary model.

In the second part of this paper, we illustrate Quah's results in the context of
ABC models. In particular, we show that the implications of an unobserved components,

—6—
difference stationary version of Hansen a RSC model closely resemble those of a trend
stationary specification.

Our tentative conclusion is that once we admit the possi-

bility that agents are responding to both temporary and permanent shocks, the unit
root question loses much of its importance.

Our paper is organized as follows.

First we discuss the concepts of trend and

difference statlonarity and two statistical procedures which have been used to distin-

guish between them empirically. In the next two sections, we argue that, using postwar data, one cannot determine the long—run effect of an innovation to real ON? based

on two leading statistical procedures, the ARMA method of Campbell and Kankiw
(1987a,b) and the nonparametric method of Coohrsne (1988a). Then we address the issue

of whether unit roots matter from an economic perspective.

En the last section, we

make some concluding remarks.

A SELECTIVE OVERVIEW OF THE LITERATURE
Recent research aimed at analyzing the persistence of shocks to real ON? has been

conducted almost exclusively within the confines of atheoretical time series models.
Much of the debate has centered on efforts to support or refute the trsditionsl view
that fluctuations in real GM? reflect temporary deviations from a deterministic trend

path. At issue is the relative plausibility of two important classes of statistical
univariate time series models: trend stationary and difference stationary models. We
begin by reviewing these models.

Consider the time series variable

which we assume is measured in loga-

rithms. According to the trend stationary model,
deterministic trend. If the growth rate of

is a stationary stochastic process, the

deterministic trend component must be linear.
representation for

yt +

reflects these assumptions:

a(L)e.

is covariance stationary about a

The following univariste time series

—.7—
Here a(L)

1

+

aL

+

a2L2

+

constant, t denotes tinie, and

. -. is

a polynomial in the lag operator L, y

is the zero sean,

serially

scalar

u000rreiated time t inno-

is covariance sta-

Since

We denote the variance of t by a2.

vation to

is a

tionary, Yal and 2 are both finite. For convenience, we assume that fla1 is finite.

According to the difference stationary model, the first difference of t is a
covariance stationary process which we write as

Ay

+

(2)

-

b(L)ut.

Here A denotes the first-difference operator, b(L)

1 • b11. + b2L2 +

nomial in the lag operator L, z is a scalar constant, ZIb1 (
mean, serially uncorrelsted innovation to

addition, we impose the requirement that b(1)

, and

... is

a poly-

is the zero

We denote the variance of Ut by a. In
:g

0.

Without this requirement,

there is no difference beteen trend stationary and difference stationary processes.
This follows from the fact that any trend stationary process, (1), can be represented
in the form of (2). To see this, simply first—difference both sides of (1) to obtain

syt

'r +

ML)s

where A(L) = (1—L)a(L).

This process satisfies all of the conditions imposed by the

difference stationary model ezcept for one. The sum of coefficients on current and
lagged Et's in (3) is given by A(l). Under our assumptions, Mi)
lates the condition that the sum 0±'

0. But this vio-

the moving average coefficients in (2) is not

equsl to zero. Evidently, the condition that b(1) s 0 is all that distinguishes trend
and difference stationary processes.

Two widespread interpretations of b(1) revolve around its role in determining the
degree of persistence in

of the optimal forecast of

One measure of persistence centers on the response to Ut

into the infinite future.

Let E denote the time t

expectations operator conditioned on the information set (UtiUt_
Nelson (1981) show that

}.

Beveridge and

-a —

his

[Etyt k -

Et

b{1)u.

It follows that b{1) completely characterizes the revision in the long-run outlook for

Y induoed by a time t unit innovation to

0, so that an innovation at time t ought to affect our forecast of y into the

b(1) *

infinite future.

However, if

is trend stationary——say, as given by (3)—-then

0. Consequently, an innovation to

A(I)

if y is difference stationary, then

into the infinite future.

should have no impact on our foreoast of

This simply reflects the fact that eventually a trend

stationary process always returns to its deterministic trend path.

The
run

other common measure of

fcrecast of

a difference stationary process is always changing. According to (4),

the time t revision

natural

persistence revolves around the fact that the long-

to the

long-run

forecast of

is

the random

b(1)ut. A

measure of the amount of variation in this variable is its variance,

[b(1)12o2. If

is trend stationary, then fluctuations in Ut

induce

movements in y; that is, the long-run outlook is deterministic.
variance

variable

of the

only transitory

Consequently, the

revision to the long-run forecast of a trend stationary random vari-

able, [A{1)]2a2, is zero.

Under the first interpretation of b(1), the issue of trend versus difference
stationarity reduces to the question, How much should an innovation to the stochastic

process y at time t affect our forecast of

into the infinite future? Under the

second interpretation of b(1), the issue of trend versus difference stationarity
reduces

future?

to the question,

How variable is the optimal forecast of

in the infinite

Posed in these terms, neither question is answerable on the basis of any

finite data set. There simply are no observations on the experiment. The relevant
issues then become, What identifying restrictions have been made in the literature to
answer questions about persistence?

And how sensitive are the answers to different

identifying assumptions?

To review the literature from this perspective, we adopt the following generic
representation for Aye:

—9—
syt

where

a

+ C(L)n

is the white noise innovation to

a trend stationary representation.

with

variance 2. -When CM) = 0, (5) is
The

Otherwise, it is difference stationary.

literature on the persistence of U.S. real GH? can be roughly divided into two cate-

gories. One category focuses simply on the question of whether or not CM)
is, whether real GM? ts trend or difference stationary.
here, with one adopting CM)

0.

0, that

Two strategies are -taken

0 as the null hypothesis and the other adopting C(1) *

For example, Campbell and P4ankiw (1987a) use the first strategy; Melson and

Ploaser (1982), the second. This type of analysis only addresses the narrowly defined
-

question Are output fluctuations temporary or permanent?

The other category of research aims to quantify the persistenoe of

by focusing

on the two measures discussed above. Watson (1986), Campbell and Mankiw (1981a,b),
Clark (1987), and Campbell and Deaton (1988) estimate CM) using postwar U.S. real CUP
data.

Campbell and Mankiw (1987a,b) and Campbell and Deaton (1988) also measure

[C(1)]2o2 using an estimator proposed by Cochrane (1988a), who implements his procedure on per capita real CM? data covering the pre- and postwar period.

How can these authors make inferences about etther C(1) or (C(1)12a2 using a
finite amount of data? As Ccchrane (1988a) emphasizes, inferences about the persistence of

are made possible only by imposing tdentifying restrictions on CCL) and

it. The point of these restrictions is to allow the econometrician to make inferences

about the long-run dynamics of. ye-—say, as measured by C(1)—-from its short—run
dynamics. The different types

of

identifying assumptions in the Literature fall into

two categories which are closely linked, to different strategies for actually estimat-

ing objects like C(1). One strategy amounts to fitting parsimoniously parameterized
ARMA models for Ay and then drawing inferences about persistence from the resulting
parameter estimates. The other strategy is less parametric, in nature.

Consider first the more parametric strategy. Here, two differentapproaches for
achieving parsimony have been pursued.

Authors like Campbell and Maniciw (1987a)

- 10

-

achieve parsimony by limiting the orders of the autoregressive and moving average
components of the ARMA representation of the data.

In particular CCL) is assumed to

be of the form

where OIL) and :(L) are polynomials in the lag operator of order q and p,

respec-

tively. This implies an ARNA(p,qJ representation for Aye. No additional, restrictions

are imposed on the model.
[that is, Cli)

To test the null hypothesis that

is trend stationary

0], Campbell and Mankiw obtain both an unconstrained estimate of CII)

and en estimate of C(L} subject to the constraint that Cli)

0.

Given some metric

for Judging the empirical plausibility of the constraint, they omiculate Cli)
o(l)f(1) using the preferred
A

modei.

second strategy for achieving parsimony is to work within the confines of an

unobserved

components model. Here the idea is to model
=

as the sum of permanent and

are difference and trend stationary stochastic processes, respectively. An important advantage of this approach
is that parsimonious representations for at and ct will imply ANNA representations for
temporary components:

+ Ct, where

and

with high autoregressive and moving average components.
(1986) asswipes that

representation.

For example, Watson

is a pure random walk and c has a second-order autoregressive

In addition, he assumes that s and

are orthogonal processes.

Under these assumptions, his aodel generates an ARHA(2,2) representation for
is completely described by four parameters:

that

the variances of the innovations to

and c, and the autoregressive parameters of o.

We think of unobserved components models of ay as simply devices for achieving
parameter parsimony in ARNA models. From this perspective, the particular decomposition adopted need not be structural in any interesting economic sense.

Indeed, this

approach for achieving parsimony may be quite useful for forecasting purposes even if

the restrictions are false.

However, as a devioe for obtaining the true cyclical

— 11 —

component of the data, this approaoh is more problematic.
exists an uncountable number of decompositions fcr
tion that

and

This is because there

even if we impose the assump-

are orthogonal processes (Quah, 1988). Each decomposition implies

precisely the same univariate time series representation for y Obviously, strong
restrictions are required to identify z and c. Unfortunately, the economic motivations behind the decompositions used in the unobserved components literature are often

left unspecified and are at best problematic when viewed from the perspective of economic theory.

For example, the Beveridge and Nelson (1981) decomposition aasumes that the inno-

vations to 2t and ct are perfectly correlated. This is clearly incompatible with real
business cycle models in which there is more than one shock (such as in Christiano and

Eichenbaum, 1988b; Braun, ig8g; or NcOratten, 1989).
assumption that

At the other extreme, the

and c :'e orthogonal processes is also incompatible with these

models. BBC models often do lead to unobserved components representations for

(as

in King, Plosser, Stock, and Watson, 1987). However, nothing inherent in the models
underlying these representations implies that t ought to be difference stationary (as

opposed to trend stationary) or, if so, that Z

ought to be a random walk. Finally,

and most importantly, when agents' environments have more than one shock, 2

and ci

will be imperfectly correlated. But these are precisely the circumstances under which
unobserved components models are not. identified (Watson, 1986).

The set of restrictions imposed on C(L) by a particular unobserved components

model clearly influences inference about C(1). One way to see thts is to compare
Campbell and Mankiw's (1987s) results with those of Watson (1986).

Working with an

unconstrained ARMA(2,2) model for aye, Campbell and Mankiw estimate C(1) to be 1.52.

But Watson's unobserved components, constrained ARIIA(2,2) model generates a quite
different estimate: 0.57. Aside from a minor discrepancy in sample period, the only
difference between the two procedures is the constraints imposed by the unobserved
components model. The point of this comparison is not to evaluate the relative plau-

— 12

aibility

—

of these two parametric procedures for estimating Cli).

instead, we only

want to emphasize—-as Watson (1986) does--that inference about Cli) can be very sensi—
tive to different identifying assumptions about C(L).

In contrast to the parametric approaches discussed above, Coehrsne (lYSCa) proposes the following statistic to measure persistence:

k var(y —

'1+2

2

in

kDy
Here Dy var(y —

y_1)t

k-i k —

o = oovyt,ayt..1)/a , and k

2, 3

tsee Cochrane,

1988a, for a proof of the equality in (7).1 For a given value of k, Campbell and
Haniciw (1987a) estimate v by replacing the population moments in (7) with their
sample analogs.

(For an alternative estimator, see Oochrane, i988a.} We denote the

sample estimator of vic by vic.

To motivate the usefulness of

as a measure of persistence, we use the fact

that

V =limVk

2

Soy (1)/os.
y

Here SAy111 is the spectral density of

for w e [0,2a1. If

55(z)

evaluated at frequency zero. Let z z

has the law of motion given by (5), then

C(z)C(z)a2.

Consequently,

(CM)]2O/Oy
Combining (8) and (10), we see that the issue of whether a time series is trend stationary [that is, CM) = 01 or difference stationary :C(i)

01 is equivalent to ask-

ing whether the value of its spectral density at frequency zero (z = 1) is zero or
nonzero, respectively.

- 13

-

To implement this estimator, one must choose

a

value of k.

Consequently, the

crucial identifying assumption underlying this measure of persistence is the assump—
ticn that whatever value of k is chosen1 the higher autocorrelations are of negligible
importance.

Cochrane (1988a) argues that for real GNP a good value for k is in the

region of 20—30 years.

The key point is that, unlike parametric ARMA approaches,

Cochrane's procedure does not exploit information about the short-run dynamics of
to measure long-run dynamics.

--

UNIT ROOTS IN REAL GM?: DO WE KNOW?
Parametric Measures of Persistence
In this section, we analyze the persistence of U.S. real GNP using the parametric

methods discussed above. We begin by estimating a variety of parsimoniously parame—
terized ARMA models for the first difference of the log of quarterly real ONE using
data from 19148:1 to i985:i.
maximum

likelihood

procedure.

To estimate the models, we used Analey's (1979) exact
As Campbell and Mankiw (198Ta) do, we restrict our-

selves to ARMA(p,q) models with p r 0, 1, 2, 3 and q r 0, 1, 2, 3, but do not consider

the case in which both p and q equal zero.

In addition to estimating the uncon-

strained ARMA models, we estimated the models (those for which q a 1) subject to the
constraint of trend stationarity [o{1)

C(1)

03.

Our estimation results are in Table 1. There we report twice the difference of
the log likelihood values associated with the unconstrained and constrained versions
of each ARMA model. The corresponding number in parentheses is the probability value

of the associated likelihood ratio statistic implied by the chi—square distribution
with one degree of' freedom.
benchmark only.

These probability values are included as a convenient

Standard justifications for interpreting the likelihood ratio sta-

tistic as a realization from an asymptotic chi-square distribution rule out unit mov-

ing average roots under the null hypothesis.
Schwert, 197T.)

(See Kohn, 1979, and Plosser and

Each estimated AlMA model generates an estimate of CM), which we

denote by 0(1). The sample estimator of C(1} is simply e(1)/(1i. Since 0(1)

0 by

— ill —

construction

for the constrained models, Table 1 reports the value of 0(1) correapond—

ing to only the unconstrained models.

We Want to emphasize four key features of our results

1. Generally, imposing the constraint 0(1)

0 causes a greater deterioration in

the likelihood function of the more parsimoniously parameterized models. For
example, the drop is very dramatic in the p

ratio statistic exceeds 150.

p
ial.

1

0 models, where the likelihood

The smallest drop occurs in the models with

and q r 3, where the deterioration in the likelihood function is trivIndeed, using conventional sampling theory, we cannot reject the null

hypothesis that 0(1) r 0 at the 30 percent significance level.

2. An important exception to the general pattern that more parsimony implies a
smaller likelihood ratio statistic is the ARMA(2,2) model.

In the class of

models with p a 2, this is the only model in which, using conventional sampling theory, we can reject the null hypothesis that 0(1)

0 at the 5 percent

significance level.

3. With the exception of the AfiIIA(3,3) model, all of the estimated values of
0(1) are substantially greater than 1.

At the same

time, for most of the

models, the likelihood ratio statistic suggests a great deal of uncertainty
about the true value of 0(1).

11.

In the ARMA(3,3) model, the only specification for which the global maximum

of the likelihood function occurs at 0(1) = 0, one of the autoregressive
roots equals 0.9119, so that there is near parameter redundancy.

An alternative way to represent our results is to display the graph of the maxi-

mized value of the likelihood surface of the different ARIIA aodels as a function of
0(1).

This representation makes even clearer the first three features discussed

above. For a fixed value of 0(1) equal to k, the parameters of the ARMA model must

satisfy

the restriction eM) -

k(1)

-

0. To generate the desired likelihood surface,

we computed the maximized value of the likelihood function for all the ARMA(p,q)
aodels with

p

a 1, q a 0, subJect to this restriction. In so doing, we chose values

of k belonging to the grid defined by the boundaries zero and 2 and fixed grid size
0.01.

The resulting likelihood surfaces for the ARHA(0,4), AMIA(l,q), ARMA(2,q), and
ARMA(3,q) sodels are displayed in Figures la-id, respectively.

and highest curves in each figure correspond to q

The lowest, middle,

1, 2, and 3, respectively.

According to these figures, all of the likelihood surfaces have a local maximum at a

large value of C(1).

Moreover, all of the surfaces corresponding to models with a

nontrivial aoving average component flatten out as C(1) goes to zero. This is a mani-

festation of the well—known fact that the slope of the exact likelihood function is
zero on the unit circle.'

To see our first result, compare the global maximum of the likelihood function

with its value at C(1) = 0.

Generally, the diatance between these two values is

smaller for the more profligately parsmeterized models. For example, whenever p a 1
and q r 3, the global maximum of the likelihood function is very close to its alterna-

tive values. Consistent with our second result, the ARHA(2,2) model stands out as an
exception to this pattern.
whtch the global maximum

CM)

is

More typical are the ARMA(1,1) and ARMA(2,3) models, in
extremely close to the value of the likelihood function at

0. Finally, consistent with findings in Plosser and Schwert (1977), the graphs

in Figures la-id indicate that oonventional estimates of the standard error of C(i)
are likely to overstate the precision with which C(1) is estimated. This Is because
conventional methods for computing standard errors are based on the local curvature of

the likelihood function at C(1). For most of our models, there is substantial curva-

ture around CM) but little difference between the value of the likelihood function

at CM) and CM) r 0.

Interestingly, conventional methods for computing standard

errors do not give misleading results for the ARMA(1,3) and ARIIA(3,3) models. In both

— 16

—

cases, the likelihood function is basically constant over the whole range of values
for CEll which we considered.

Overall, the results in Table 1 and Figures la—id show that inference about 0(1)

is extremely sensitive to the choice of ARMA model, that is, the choice of p and

q.

Some of the MIMI models support the difference stationary perspective since they indi-

cate that C(1) is large and precisely estimated. Models in this category include the
ARMA(l,1), ARMA(2,2), and ARMA(O,q) spectfications,q

1, 2, 3. But other iRMA

models are consistent with the trend stationary perspective because they indicate that

either Cli)

0 or little can be said about its value.

include ihe ARMA(2,l}, ARMA(3,1), and ARMA(p,3) models, p

Models in this category
1, 2, 3. The key question

is, Which perspective is best able to account for these apparently conflicting
results?

To answer this question, we adopt the following approach. First, we ask whether

an empirically plausible trend stationary data-generating mechanism exists that can
explain those results in Table 1 which appear to support the difference stationary
perspective.

Then we ask the analog question for difference stationary data—

generating mechanisms -

This

general strategy for selecting between competing explanations of apparently

contradiotory statistical results was described and implemented in Christiano and
Ljungqvist (1988)! To apply this strategy, each explanation must be formalized as
pne

or more fully specified data—generating mechanisms.

To repreaant the trend sta-

tionary

perspective, we chose two models.

model.

In addition, we considered an 1241(1,3) model in order to ensure that any

The first is our estimated ARMA(3,3)

results based on the ABMA(3,3) model are not sensitive to the fact that it has a rela-

tively large number of parameters. Although our estimated 1211(1,3) model implies a
large value for dl), the likelihood function hardly deteriorates when we impose the
constraint that C(l) 0 (Figure ld). Indeed, when Campbell arid Mankiw (1987a) estimate the 1241(1,3) model using a slightly different data set and a slightly different

— 17

estimation

—

method, the global maximum actually occurs at C(1)

Consequently, we

chose as our second trend stationary mechanism the Caispbell-Mankiw ARMA(1,3) model."

To represent the difference stationary perspective, we chose our estimated
ARIIA(2,2) model. The choice of only one model reflects our need to economize on computational costs.

This particular model was chosen because we think it has the best

chance of accounting for the evidence in Table 1 that Cli) r 0 or is imprecisely esti-

mated. In addition, focusing on the ARMA(2,2) model hss the important advantage of
making our results directly comparable to those of Campbell and ?nkiw (1987a).
We analyze the relative plausibility of the trend and difference stationary per-

spectives using two questions: Can the ARNA(3,3) and the trend stationary ARNA(1,3)

specifications account for the high likelihood ratio statistic and the high value
of Cli) obtained using the ARNA(2,2} model? And can the ARMA(2,2) model account for
the low likelihood ratio statistics and the value of C(i) obtained using the ARMA(i,3)
and the ARHA(3,3) models?

Evaluating the Trend Stationary Perspective

To assess the plausibility of the trend stationary perspective, we conducted the

following Monte Carlo experiments. We generated 2,000 data sets, each 151 observations long, using our estimated ARMA(3,3) model and the Campbell-t4anklw ARMA(1,3)
model.5 For each realization of 151 observations, we estimated both cdnstrained and
unconstrained AR}IA(2,2) addels and then computed a likelihâod ratio statistic to test

the null hypothesis that Cli)

0.

The frequency distributions of these likelihood

ratio statistics, as well as the distribution of the chi—square statistic with one
degree of freedom, are displayed in Figure 2a.

In Table 1, we reported that the ARMA(2,2) model produced a likelihood ratio
statistic of 4.356 when we tested the null hypothesis that C(i) r

0.

Our Monte Carlo

evidence reveals that if the true data-generating mechanism was our ARMA(3,3) model,
then a likelihood ratio statistic greater than or equal to 4.356 would actually oocur
74

percent of the time,

If the true data—generating mechanism was Campbell and

— 18 —

Mankiw's (1987a) ARMA(1,3) model, then this would occur 35 percent of the time. Obviously, these numbers are much larger than the frequency of 14 percent predicted by the
conventional ohi—square distribution,

Indeed, Figure 2a reveals that the likelihood

ratio statistic of 14.356 is close to the central tendency of that statistic for
ARIIA(1,3) and ARMA(3,3) models. Evidently, both of these trend stationary models can

easily account for the high likelihood ratio statistic associated with testing the
null hypothesis of trend stationarity obtained with the ARMA(2,2) model.

By—products of the preceding Monte Carlo studies are simulated frequency distributions for the values of C(1) obtained using the ARI4A(2,2) model in data generated by

the ARMM3,3) and ARMA(1,3) models.

These frequency distributions are plotted in

Figure 2b. The main characteristics of the two distributions are very similar. Both
are bimodal. The larger mode is centered about a value of CM) substsntially greater

than 1, while the smaller mode is centered about zero. The unconditional means of
C(1)

are 1.143 and

models,

1.23 when the data are generated by the ARMâ(3,3) and ARMA(1,3)

respectively. The corresponding

standard errors are 0.39 and 0.57. Comparing

these values with the value of C(1) produced by the ARXA(2,2) model (1.53), we con-

clude that both the aRMA(3,3) and the ARXA(1,3) models can easily account for the
estimate of C(1) Obtained with the ARMA(2,2) model.

Campbell and Mankiw report that, with the ARMA(2,2) model, CCI)

standard error of 0.16.

1.52, with a

While our reported standard errors are larger, this may

partly reflect the tendency of standard errors based on the local curvature of the
likelihood function to overstate the precision with which C(1) is estimated. We conjecture that standard errors based on local curvature of the likelihood function will

on average correspond to the standard deviation of C(1) conditional on being in the
larger mode of the bimodal frequency distribution. Some support for this conjeoture
is provided by the fact that the standard errors of C( 1) conditional on being in the

larger mode of Figure 2b are 0.20 and 0.23 when data are generated by the ARIIA(3,3)
and ARMA(1,3) models, respectively.
and 1.146.J

[The corresponding mean values of CM) are 1.51

— 19 —

Specification
that

Error and Near Parameter Redundancy. So far, we have established

the ARMA(2,2) results can easily be accounted for by both of our trend stationary

models. At first glance1 this may seem surprising, for at least two reasons: first,
in both data—generating mechanisms, CU) = 0 by oonstructlon yet the estimated value
of 0(1) is typically quite large. Second, it Ia well known that, when a moving average root is near the unit circle, maximum likelihood parameter estimates have positive

mass on the unit circle (Sargan and Bhargava, 1983).

This is referred to as the

pileup pjnomencn. Our data-generating mechanisms have an exact unit moving average
root.

As Campbell and Manklw (1987a) emphasize, the pileup phenomenon suggests that,

other things equal, conventional sampling theory substantially understates the evidence against the null hypotheais that C(1)

0.

In sharp contrast, our Monte Carlo

experiments reveal that the conventional probability value of k percent associated

with the likelihood ratio test of Cli)

0 substantially overstates the evidence

against the null hypothesis of trend statlonarity.

Now we show that two key factors aocount for the results in Figures 2a and 2b:
(1) the specification error arising from the fact that the ARMA(2,2) model is misspecified from the perspective of either the ARMA(1,3) or the ARMA(3,3) model and (2)
the

near parameter redundancy problem which arises from the fact that both trend sta—

tionary models have an autoregressive root near the unit circle. We begin by provid-

ing the underlying intuition using large-sample arguments.

Then we present the

results of a suitably chosen Monte Cario experiment.
Our large-sample

argument is based, in part, on the probability limit (plim) of

the ARMA(2,2) model when we assume that the true data—generating process corresponds
to the estimated AR)4A(3,3) model.

This plim was calculated by first simulating a

realization of 20,000 observations from the estimated ARMA(3,3) model and then estimating an ARI4A(,2) model on the synthetic data set. The resulting ARMA(2,2) iriodel is

given by

(1 — O.62'lgL. +

O.'461L2)Ay

=

(1 — 0.31431. +

0.5934L2)nt.

(11)

— 20 -

The model sujimiarized by (11) implies that C(1) = 1.53, a value very different from
zero, the true value of 0(1) in the data-generating process. Evidently, the impaot of
specification error is to substantially bias the estimate of CM) away from zero.

A striking feature of the previous result is that the plim of CM) actually
oorresponda (up to three decimal places) to the value of C(1) obtained from the
ARI4A(2,2) model estimated with the actual U.S. data (Table 1).

To understand this

result, recall the near redundancy of the parameters describing the ARMA(3,3) model.

As reported in Table ,
(0.299

the

autoregressive and moving average roots of that model are

0.5651, 0.9119) and (0.133

0.7147i, 1), respectively. $tnce O.9l9 is close

to 1, the ARMA(2,2) model defined by stripping away both these roots has roughly the
same covariance structure as the estimated ARHA(3,3) model.

EquatIon (11) reveals

that this is indeed what the probability limit of the misspecified ARIIA(2,2) model
amounts to. This is because the autoregressive and moving average roots in (11.) are
(0.312 t

0.603i)

arid (0.157

0.75Zli},

respectively.

These are very close to the

corresponding roots of the ARIIA(2,2) model estimated using the postwar (3.5. data:
(0.293 s 0.614i) and (0.139

0.776i).

Since C(1) is determined entirely by these two

roots, the two ARMA(2,2) models generate essentially identical values.

The previous reasoning takes as given that a masimum likelihood estimator of the

misspecified ARZIA(2,2) model wants to ignore the maximal autoregressive and moving
average roots of the ARMA(3,3) model, even though this has the effect of converting
the model into one with a large value of C(1). Why should this be so? With a large
amount of data, maximum likelihood selects a theoretical spectral density that matches

as closely as possible the true spectral density of the data. When the model to be
estimated is correctly specified, the estimated spectral density will, in population,
coincide with the true spectral density matrix. However, since the ARMA(2,2) model is

misspecified, the estimated spectral density cannot match the true spectral density
matrix at all frequencies.

From this perspective, the relevant question is, Which

frequencies will bear the brunt of the specification error?

— 21 —

An

implication of results in Christiano and Lichenbaum (1987) and Cochrane

(1988a) is that maximum likelihood seeks to minimize the average percentage error of

the diacrepanoy between the theoretical spectral density matrix of the miaspecified

model and the true spectral density matrix. Let S1y(e) denote the spectral density

of the true model at frequency w
model ia C(e1;s,e)C(e1w;4,e)c2.

[O,2s].

The spectral density of the estimated

Here we have modified our notation slightly in

order to explicitly reflect the dependence of C on the autoregressive parameters, •;
the moving average parameters, 0; and the innovation variance, 2, In population, the
maximum likelihood estimator of * and 0 mInimizes6

(12)

f1 S1y(e_IW)/EC(e_iW;$,e)C(eiW;$,e)! da.

Notice, first, that when the true' data-generating process

C(1)

r

0.

is trend stationary,

This implies that S3 0 at frequency zero (equation (9)1.

By continu-

ity, S, will be amall in a neighborhood around frequency zero. Consequently, other
things equal, the method of maximum likelihood will sacrifice accuracy in a neighborhood of frequency zero in order to achieve a better fit over intervals of higher
frequencies.

This suggests the possibility that the impact of specification error

will fall heavily on the object of interest, C(1). Second, notice that errors over
any small band of frequencies do not contribute in an important way to the criterion
function which maximum likelihood is-minimizing.

To understand the combined impact of these considerations, examine Figure 3a,

which displays the spectra of ay implied by the estimated ARNA(3,3) model and ihe
ARMA(2,2) model of equation (11).
worth noting:

(1) There are two

Two features of the first spectral density are

regions in which the level of the spectral density

undergoes substantial change—-the area around frequency zero and the area around the

seasonal frequency, 1.5.

The first region is smaller than the second because of
the very steep slope of the spectrum near zero. This reflects the near parameter

redundancy of the

(2)

ARMA(3,3) model.

-

- 22
Figure

-

3a shows that the misspecified ARMA(2,2) model described by (11) succeeds

in closely mimicking the high—frequency properties of the ARMA(3,3) spectrum. Indeed,

the two spectra are virtually identical for values of o

exoeeding 1, that is, time

periods less than 6.3 quarters. The brunt of speoifioation error is heavily borne by
the low frequencies.

To better understand the nature of the trade—of fs involved in fitting the mis—
specified AR1IA(2,2) model, consider the following experiment. Suppose that we forced

the ARMM2,2) to match the low-frequency behavior of the AR14A(3,3) model. What would

the cost be? To answer this question, we computed the pith of the ARMA(2,2} model
subject to the constraint that Cli) r

o.7 The

resulting spectrum is shown in Figure

3b. where that of the ARJIA(3,3) is repeated, from Figure 35.
constrained

can be seen, the

ARI1A2,2) model succeeds in capturing the behavior of the ARMA(3,3) model

in the neighborhood of a

0.

However, to aooomplish this, it must set one of the

autoregressive roots close to 1. This root and
negligible effect on
out

As

the

the

unit moving average root have a

spectrum at higher frequencies because they oanoel each other

at those frequencies. Consequently, the ARHA(2,2) model has only two parameters

left to matob the relatively complicated seasonal and high—frequency dynamics of the
ARMA(3,3) model.

The best that the constrained ARMA(2,2) model oan do is to ignore

the seasonal dip and draw a smoothed version of the ARFIA(3,3) spectrum at the higher
frequencies. The misspeoified ARMA(2,2) model simply does not have enough flexibility

to capture the dynamics of the ARMA(3,3) speotrum at both the sero and the seasonal
frequencies.

Our analysis indioates that when forced to choose which dynamics to

mimic, the unoonstrained ARIIA(2,2) simply gives up on the long-run dynamics.

Specification error will not always result in a biased estimate of Cli).

The

fact that the ARNA(2,2) model generates a large value of Cli) depends oritioally on
the near parameter redundancy in the ARMA{3,3) model. A simple way to see this is to
repeat our previous experiment but assume a trend stationary ARMA(3,3) model in which
the problem of near

parameter redundanoy is less severe.

Figure 3c displays the spec—

- 23

-

trum of the ARXAC3,3) model obtained by replacing the largest autoregressive root,
0.9kg,

in our

estimated ARMA(3,3)

model with 0.500. Comparing FigutZes 3a and 3c, we

see that the primary effect of reducing the maximal autoregressive root is to expand
the band about frequency zero in which the level of the spectrum undergoes substantial
change.

the

This suggests that maximum likelihood

will give greater weight to matching

low—frequency dynamics of the modified ARMAC3,3) model.

indeed, the pith of the

ARIIAC2,2) model fit to data generated by the modified Afi}lA(3,3) model turns out to
imply a value of CCI) precisely ejial to zero.

Figure 3c also displays the spectrum

of this ARMA(2,2) model. Notice that-the spectrum exactly coincides with that of the

modified ARNAC3,3) model at ,
closely.
behavior.

z0

and matches its low-frequency behavior quite

At the same time, it does quite poorly with respect to the high-frequency

As before, the misspecified ARNA(2,2) model does not have enough flexi-

bility to capture the dynamics of the ARMA(3,3) spectrum at both the zero and the
seasonal frequencies.

But now, when forced to choose which dynamics to mimic, the

ARMA(2,2) model chooses to mimic the long-run dynamics. By reducing the severity of
the

near parameter redundancy problem, we have increased the cost of ignoring the

long-run dynamics.

The previous

large-sample considerations suggest that without near parameter

redundancy, the trend stationary perspective could not have accounted for the large
value of CM) aasociated with the ARMA(2,2) model. To show that this is indeed true,

we repeated the Monte Carlo study of Figure 2a using the modified ARMAC3,3) model
which has a maximal autoregressive root of 0.5. When we did this, we found that only
3 percent of the simulated likelihood ratio statistics exceed the value reported in

Table 1, #.356. This stands in sharp contrast to Figure 2a, where 7k percent of the

simulated likelihood ratio statistics exceed that value.

Taken together, these

results establish that both specification error and the near parameter redundancy
problea allow the trend stationary models to account for the high and apparently precise estimate of CM) obtained using the ARMA(2,2) model.8

— 24 —

To summarize, from the trend stationary perspective, the high value of CM) associated with the ARMA(2,2} model reflects the choice of maximum

area around the seasonal dip in the spectrum of the data.

likelihood

to model the

This dip may reflect the

effects of the procedure used by the U.S. Department of Commerce to seasonally adjust

the data (Granger and Newbold, 1977, p. 66). This, in turn, raises the possibility
that measures of persistence generated from low-order ARM models could be very sensi-

tive to different seasonal adjustment procedures.

Jaeger and Kunst (1989) obtain

precisely this result. Our analysis provides a possible explanation for their result.
Reconciling Our Results With Campbell and Mankiw's. Our results contrast sharply

with ihose of Campbell and Mankiw (1987a). Using Monte Carlo methods, they reach the
conclusion that trend stationary models cannot account for the results obtained with
the ARMA(2,2) model.

The reason for the difference is that Campbell and Mankiw's

(1987a) Monte Carlo study assumes that the ARMA(2,2) model is correctly specified. In
particular,

their data-generating mechanism is the model estimated by Blanohard

(1981), according to which

is a second-order autoregression about a linear trend,

with autoregressive roots equal to 0.5 and 0.84. This implies an ARMA(2,1)

tation

for 't with

represen-

a moving average root of 1.

Taking as given the estimated Blanchard model, Campbell and Mankiw generated 20

data

sets, each 151 observations long. Then, using the ARMA(2,2) model, they computed

a likelihood ratio test of the null hypothesis that C(1) r

0

for each data set. Their

calculations lead to the dramatic result that the likelihood ratio statistic does not

exceed 4.356 in any of the 20 artificial data sets.9 Obviously, under their maintained assumptiona, the likelihood ratio test is not biased toward rejecting the null
hypothesis that C(1)

0.

less often than it should.

Indeed, the test rejects the null hypothesis considerably

Based on this evidence, Campbell and Mankiw infer that

Blanohard's model cannot account for the ARMA(2,2) results.

Campbell and Mankiw (1987a, p. 871) summarize their findings this way: "We conclude from our literature review and our small Monte Carlo study that while there are

- 25

-

some statistical difficulties with our estimator, there is no reason to think that

these bias us toward rejecting stationarity." This conclusion seems warranted if the
ARtIA(2,2) model is correctly specified. However, bothour results and theirs point to

other empirically plausible trend stationary models relative to which the ARMA(2,2)
model is misspecified.

According to these models, there ia reason to think that tests

based on the ARJ4A(2,2) aodel are severely biased toward rejecting stationarity.

Evaluating the Unit Root Perspective

-

Now we consider whether the ARMA(2,2) model can account for the key features of

Campbell and Mankiw's estimated ARMA(1,3) model as well as our estimated ARMA(3,3}
model. The salient characteristic of both of these models is that, according to the
likelihood ratio statistic, there is very little evidence againat the hypothesis that
C{1) r

0.

Suppose, in fact, that the true data—generating mechanism is given by our

estimated ARNA(2,2) model. mat should we expect if we estimate an ARNA(1,3} or an
ARMA(3,3) model?

Campbell and Mankiw (1987a) conjecture that the high likelihood

value associated with the test that CI?)

0 reflects the pileup phenomenon.

To investigate that conjecture, we performed the following Monte Carlo esperi—

ment. Using our estimated ARNA{2,2) model, we generated 2,000 data sets, each 151
observations long.

For each data set; we estimated constrained and unconstrained

versions of the ARNA(1,3) and ARMA{3,3) models, thus generating 2,000 likelihood ratio

statistics for testing the null hypothesis that Cli)

0.

Consistent with Campbell

and Mankiw's conjecture, we found that, for the ARMA(i,3) and ARMA(3,3) models, 37 and

47 percent, respectively, of the likelihood ratio statistics are identically zero.
Figure J4 displays the frequency distributions of the estimated values of Cli) corresponding to the ARMA(i,3) and ARNA(3,3) models.
pile up at zero.

In both cases, the estimated C()'s

This, in turn, corresponds to a pileup of likelihood ratio sta-

tistics at zero.

Among the estimated C(1)'s that exceed zero, the vast majority are greater than
1.

This suggests that the typical likelihood surfaoe in the Monte Carlo study

- 26

-

resembles the surfaces depicted in Figures lb—Id in two respects. First, there is a
local maximum in the region of large values of C(1). Second, the likelihood surface
is increasing as C(1) declines toward zero.

These results are consistent with the

notion that, across synthetic data sets, the likelihood surface tilts back and forth,
with the global maximum shifting between extreme values at C(1) = 0 and CC) ) 1.

Overall, the empirical values of CCI) implied by the ARNA(1,3) and RMA(3,3)
models are clearly consistent with the bimodal distribution for the simulated C(l)'s

when the data-generating mechanism is the ARKA(2,2) model.

We conclude that the

ARMA(2,2) model can account for the salent characteristics of the estimated ARMA(1,3)
and ARIIA(3,3) models.

Sunmn_!y
We

have argued that the parametric methods of Campbell and Nankiw (1g87a) do not

provide a basis for taking a strong position on whether shocks to real GNP are best
characterized as having temporary or permanent effects. Perhaps the best way to conclude thls section is to consider Figure 5, which displays the impulse response func-

tions of real CNP implied by a subset of the ARMA models that we estimated. Included
are the impulse response functions implied by the Blanchard ARMA(2,1) model estimated
using his data up to 1980 (old Blanchard), the updated version of that model estimated

using our larger data set (new Blanchard), as well as our estimated ARIIA(2,2) and
ARNA(3,3) models.' Notice that all of the impulse response functions have very similar

shapes for the first 5—10 quarters. Only after this is the impulse response func-

tion of the difference stationary ARMA(2,2) model radically different in shape from

that of the trend stationary models.

To sharply differentiate among these models

would require reasonably precise information about the higher-order autocorrelations. Needless to say, these are not estimated very precisely with postwar U.S. real
ON? data.

Campbell and tiankiw concluded that a 1 percent innovation in real ONE' ought to

induce a revision in the long—run forecast cf real ONE' of more than 1

percent.

- 27

-

Suppose by the long run we mean anything more than four years.

Figure 5 indicates

that this conclusion is supported only by the ARMA(2,2) model.

None of the trend

stationary models support it, and-one of these models, the 58NA(3,3), is at least as
plausible as the ARMA(2,).

Figure 5 also reveals that all of the ARI4A models we investigated have impulse

response functions above the old Blanohard model.

Suppose we accept Blanohard's

(1981, p. 150) assertion that this model summarizes macroeconomists' views in 1980
about the nature of the dynamics in real GNP. On this premise, it seems fair to oon-

elude that macroeconomists must now revise upward their point estimate of the half—

life of an innovation in real ON?. This is true regardless of whether they take a
trend or a difference stationary perspective.

Less obvious is the idea that the

Increased point estimate has any econOmic significance. We know of no interesting
case in which the differences in persistence among the three trend stationary models
in Figure 5 are important.'' Later we will discuss whether there are interesting economic issues at stake in adopting a unit root perspective.

ppparametric 1easures of Persistenoe
Above we argued that one cannot distinguish between the competing null hypotheses

that postwar (1.3. real ON? is trend stationary or difference stationary using the
parametric methods of Campbell and Hankiw U987a). A natural response to this problem
Is to examine the persistence of real ONP using the nonparametric methods of Cochrane
(1988a).

Table 2 reports Cochrane's variance ratio statistic k for the values of Ii used

by Campbell and Mankiw (1987a). The numbers in parentheses are asymptotic standard

errors computed using the formula of Priestly (1982, p. 1463)

s.e. (Vk)

To make our results comparable with those above, we also
report nonparainetric estimates of C(1), obtained from k, using a transformation dis-

cussed in Campbell and Mankiw (1987a). Let R2
as

1 -

o/oy.

Then (8) can be written

-

-28..
CM)

(13)

[v/(l—H2)]2.

Here R2 is the traction of the variance in iy
values of aye.

Let

that is

predictable using all lagged

denote the first—order autocorrelation of iy. Campbell and

Mankiw's (1987a) nonparametric estimator of CM), C(l)L(, is defined by

(1't)

[Vk/M;2)I1f2
where

is the sample estimate of the first-order autocorrelation of iy.

In practice, to óalculate Cochrane's variance ratio statistic, we must choose a
value of Li.

measure

As we stressed earlier, the key identifying assumption underlying this

of persistence is the assumption that, whatever value of k is choaen, the

higher autocorrelations are of negligible importance. This suggests that Li should not
be chosen too small. To see this, notice that V1

1 +

As long as Ayt is posi-

tively autooorrelated, V1 will exceed 1 even if the process is tiend stationary. But
T -

when Li

i,

0 by construction.

relative to the sample size, T.
variety of values of Li.

Clearly, k should not be chosen too large

Table 2 reports the values of

and C(l)Li for a

Comparing Tables I and 2, we see that, roughly, the non-

parametric estimates of CM) are lower than the parametric estimates of CM). But the
reported standard errors, calculated using the Priestly formula, are all quite large
relative to the point estimates.

According to Table 2, distinguishing between the classes of trend stationary and
difference stationary models using Cochrane's nonparametric measure of persistence is

difficult. Unfortunately, we cannot formally teat the null hypothesis of trend ststionarity

of

since, under

that null hypothesis, Priestly's formula for the standard error

equals zero for all k. We can, however, ask whether the representative models

discussed in the last section are consistent with the computed Vks.

To investigate this question, we
ment.

performed the following Monte Carlo experi-

We considered three data-generating mechanisms:

the Campbell and Hankiw

ARKA(1,3) aodel and our estimated ARMA(2,2) and ARMA(3,3} models. For each of these,

- 29

—

we generated 2,000 data sets, each wIth 151 observations. We then calculated

,

IC

2,...,

75 using each of the data sets.

for

The results of our experiment are

reported in Table 2. To understand these numbers, consider a particular column, say,

the one labeled AflS3). Any given row in that column ccrresponds to a particular
value of k.

The corresponding entry in the row is the fraction of times (out of

2,000) that the k-lag variance ratio statistic calculated from the simulated ARMA(1,3}

data exceeds the corresponding empirical value of

reported in column (3).

The

numbers in the columns labeled ARNA{2.2) and ARMA(3,3) are constructed in an analogous

way. Notice that the probability values in columns (#)-(6) lie between 0.18 and 0.73,
so that the empirical vICis
ARMA models,

in

column (3) can be accounted for by each of our three

W.e conclude that, even from this limited perspective, the k,5 do not

let us discriminate between trend and difference statlpnary representations of the
data.

Examining the same empirical variance ratio statistics, Campbell and Mankiw
(1987a, p. 875) conclude that "the nonparametric estimates thus confirm our finding
that postwar quarterly real 01W appears to be more persistent than a random walk.'t
The reason Campbell and Mankiw give for reaching this conclusion Is that
real GM? data are consistently . .

larger

for the

than one would expect to find for a random

walk in a sample of this size" (pp. 87k.-T5).

This can be seen in Figure 6, which

plots the mean values of the vkts implied by the random walk model, together with
the k,5 calculated using the data. What Campbell and Mankiw's reasoning ignores is
that a large class of trend stationary models, including those which they consider,
imply mean values for the vk,s which closely mimic their empirical counterparts. This

also can be seen in Figure 6, which displays the mean values of

implied by our

estimated ARMA(3,3) model.

A different way to state our objection to Campbell and Mankiw's argument is that
it implicitly assumes that the direction and magnitude of the bias in

is relatively

insensitive to the underlying data—generating mechanism. Unfortunately, this assump-

- 30

tion

is not true.

-

Suppose that the underlying data-generating process is a random

walk. Campbell and Flankiw (1987a), among others, stress that, in this case, the vari-

ance ratio statistic is severely downward biased.

In contrast, suppose the true

generating mechanism is our estimated AIIMA(3,3) process, so that V
Figure 6, the

are consistently much larger than zero, even for a

0.

According to

75.

We infer

that, st least for this data—generating mechanism, the variance ratio statistic is
very substantially upward biased.

We conclude that, given the sample size of cur data set on real GNF, the variance

ratio statistic gives us almost no reliable information. Our nonparsmeiric estimates
of V and 0(1) are no doubt consistent with the view that postwar U.S. real Gd? is more

persistent than a random walk. But they are at least as consistent with the view that

postwar U.S. real GNP is less persistent than a random walk, Which view is true? We
can't tell.

UNIT ROOTS IN REAL ON?: 00 WE CARE?
Suppose we knew the answer to the question, Flow much should one revise a long-run

forecast of aggregate output in response to an innovation in U.S. real ON?? Would we
care? At one level, the answer is obvious: unit roots per se cannot be very ircpor—
tant. The existence of a unit root means only that CC) s 0; that does not preclude a
value of Ccl) arbitrarily, close to zero. We do not know of any model in which agents'

decision rules are discontinuous in 0(1).

Therefore, it seems likely that for any

trend stationary speoifioation of the forcing variables in agents' environments, some
difference stationary specifioation will imply arbitrarily similar dynamic behavior.

In practice, however, this is not the perspective of conoern to economists.
Typioally, the analyst's problem is not one of seleoting between different specifica-

tions with arbitrarily similar values for CC). usually, the decision to model a time

series as difference or trend stationary leads the analyst to adopt specifications
with very different implications for 0(1).

For example, in Deaton's (1956) analysis

of the PIll, the difference and trend stationary specifications for measured labor

— 31 —

income

imply values of Cli) near 1.5 and

zero, respectively. Similarly, in Hansen's
(1989) analysis of ROC models, the

difference and trend stationary

technology shooLca Imply values of CO)

caaes, the dynamic properties of the

specifications for

eua1 to I and zero, respectively.
endogenous variables behave

In both

very differently

depending on which specification is chosen.

Here we argue that the draniatio
results Obtained by Deaton and Efansen

reflect model sensitivity to unit

roots per se or even the value of

do not

univariate mea-

sures of persistence like Cli). Rather,
they reflect the assumption that the

variables of concern to agents are driven

by a single shock.

forcing

Under these circum...

stances, the assumption of difference

stationarity implies that all of the shocks to
agents' environaentg have purely permanent
effects.

Onoe the unit root issue Is

decoupled from the temporary/pr,nen
issue, the unit root issue loses much of its

quantitative signifioa•

Unit Roots and the Permanent Income

Hypothes

Because of its simplicity, the RIM is

why unit roots seem to matter and why
for illustrative purposes only.

a convenient vehicle for illustrating both

they may not matter after all. We use the FIX

Unobserved component models of labor

remedy the empirical shortcomings of the FIX

income will not

(West, 1988a). More generally, this

type

of modification to the basic model

cannot account for the fact that the
orthogonality

conditions implied by the PIM are violated

by the data (Flavin, 1981; Campbell and

Deaton, 1988 Campbell and Manklw, 1989;
and Christisno, Elchenbunj, and
1989),

According to the RIM, the level of
income.

Marshall,

consumption depends on both asset and labor

However, given a constant real interest

rate, the only thing that induces
households to set date t

consumption, c, to a value different from

current or expected future labor

adjust oonsumption by the annuity value

about y5 for s

0, 1

ct_i is news about

income, y. When such news arrives, households
of the resulting revision to expectations

This annuity value, computed using the constant inter—

— 32 -

est rate r, is the change in consumption that can
in an expected value sense. Formally, the

io(itr

act

feasibly be maintained indefinitely

P18 posits that
(15)

-

optimization problem with a soluFlail (1978) describCs a partial equilibriuul consumer

tion which implies (15), while Christiano

(1987), Hansen (1987), Sargent (1987), and

Christiano, Eiohnbaum, sind Marshall (1989)

discuss general equilibrium environments

which rationalize relation (15).

We now consider the case that has been made

for

the view that unit roots

that its univariate time series represenmatter. Suppbse that agents only see 4 and

tation is a4
To

see

Here t is the innovation in 4: that

C(L)et.

how sensitive 5o is to CR), suppose that

regression about a trend with autoregressive

L.). When

1,

4

is

Ct

4 — Et_

a first-order auto—

parameter , so that CR) s

(1—1)1(1-

1]. Nctice that C(1) drops dis-

simply a random walk C(L)

continuously to zero for values of

4 is

is.

less than 1. With this general specification

of

C(L), equatiOn (15) implies that
1

=

____

(16)

Ct

One way of seasuring the sensitivity of the

model's implications tc different

specifications of $ is to examine the relative volatility of consumption, V0. Deaton

(1986) and others define V5 as the ratio

of the standard deviation of changes in

consumption, [Z(act)211"2r to the standard deviation of the univariate innovation

in 4,
$ r

1.

. For

simplicity, suppose r

However, V0 0.5 when $

tility of a change in

0.01. Then, according to (16), V10

1 when

0.99. Obviously, the impact on consumption vola-

is very large for values of

sensitivity reflects the faot that households place
income in the distant future. &nd this is precisely
neighborhood of 1 have large effects.LZ

in a neighborhood of 1. This
substantial weight on expected
where small differences in

in a

— 33 -

At first

glance,

then, this example seems to provide powerful

view that economists should care about unit roots.

misleading, To demonstrate why, we use

motivation for the

However, we think the example is

an argument in Quah (1989) which draws

implications of the well-known fact that

there exists an infinite number of

out the

orthogonal

decompositions of difference stationary

processes into persistent and transient components.

Let Yi and

denote the time t values of two

trend stationary stochastic

orthogonal difference and

processes, respectively, which constitute such a decom-

position, so that

+ y.

4=

(17)

Assume that the time series

representations of

and

are given by

(18)

(19)

where c is the white noise innovation to y for i r
0, 7. Also, ot and
are
orthogonal at all leads and lags.
Consistent with its definition as the trend stationary component of 4, the
sum of the coefficients in the moving
average representa
tion for 50 is zero.
For illustrative purposes, consider the random walk case,
orthogonal decompositions of this process is

One class of

given by

C1(L) r 1 • VL
(20)
1

(21)

a2

2
it

2

a s

2
Ot

a

—22
(1+$) a
t

(22)

2
q,Ee

it

(23)

— 314

for

all 0 a V

—

is a valid decomposition of y, we need

1. To prove that (20)—(23)

only verify that E(Ay) =

e

and E(AyAy_5) 0 for s A 1.

Under the assumption that households observe Yft
to

(15) implies thst Act evolves according
1

Act =

and yotePsfltY relation

+r cj)zot.
r

(2U)

1

equals the annuity value of the innovation

to

Thus, the time t change in consumption
plus the annuity value of the innovation
the permanent component of labor income,
g0bstituting (20)—(23) into (214) we obtain

to the temporary component, ot•

(i +

V/U+r))et

(25)

E.

+

is given by

Therefore, the relative volatility of consumption

-

iii'-(_itiJ-

Ac

this

2 1/2

2

expression is minimized for

(26)

-

1+j

1, in whioh case VA

0995. The assumption

decomposition of y results in only a
that agents react to this particular orthogonal

relative to ths case in which agents only

trivial reduction in consumption volatility

that reduce V to the empirioally
observe y. Specifications of C0(L) and C1(L)
plausible value of 0.5 are described below
ition for understanding how Quah's examples

and by Quah (1939). However, all ihe intuwork is contained in our example.

There are at least two ways to underatand why
zero. First, note from (20)—(23) that, as

is less than

when

exceeds

$ increases, the varianoe of innovations

to

the variance of the innovations to the temthe permanent component falls relative to
an increasing proportion of news is about
porary component, so that, loosely speaking,

This is important for determining the relathe stationary oomponent of labor Income.
of oonsuniptiOn to an innovation in

tive volatility of consumption because the response

the temporary component of y is muoh smaller
innovation in the permanent component.

than the corresponding response to an

— 35

Second,

-

consider the response of y to a one standard

that is, o/(j+,)

The dynamic response of 4y

silk-i), i /17 i) for s

the

to such an Ispulse is given by

C, T, respectively, and zero for s > 1.

response of y is oiC+i) for s r C and o for a >
the value of ,

deviation increase in

C.

The corresponding

Notice that, irrespective of

long-run response of y to a one standard

deviation impulse in the

permanent component is CM)o, which equals

° in our examplej3 while the eventual
impact of a typical permanent shock is invariant
to i, the path by which one gets
there is not.

With * r 0 (the no—comp,,e case), the

response of y is equal to
a for ails a 0, so that the long-run impact
is realized insnediately.

in contrast, with 4k > 0, the long-run impact cn

realized until one period later. Since r 1'
dardized innovation to

is not

0, the present value of a permanent stan-

is decreasing in 4. Therefore, the response of consumption

to such an innovation is also decreasing in
invariant to 9 when r

on labor income of a typical innovation

9. Consistent with this intuition,

V5 is

0.

To pursue this line of reasoning,

we consider the following class of decomposi-

tions for y:

127)

for d r 1, 2, 3.

In addition, we set p

the decomposition__c, a, and

0.98 and a

is a random walk with Innovation variance a2.

requirement that the long-run impact of an
equal a .
e

7. The remaining elements of

C0(L)——are determined by the requirement that
The scalar

°€1 is determined by the

innovation in it of magnitude c must

This condition requires that c equal (1—p)

.

Since IoJ < 1, a

is a

decreasing function of d. This in turn
suggests that 1J ought to be decreasing in
d.

The remaining elements of the unobserved

components model are obtained using the

methods described by Quah (1989). These are given by

dri; C0(L)

1i(1—pL)
(28)

a2 r
r

(29)

- 36

-

(30)

dr2

(1_aL)/(1-eL)2

c0(L)
a

p

22
p /a

(31)

£0

where a satisfies a2 - ya

+ 1,

2t1#(1_p)21P1, and

d 1, and i

(32)

dr3L C0(L)

(1_aL)(1_a2L)/(PL)3
(33)

a2 = p3a2/(a1a2)
14

where

1 for i

al
I

Figure

1, 2.

in L, a C1(L)/(1L)

7 plots the first 500 coefficients in the polynomial

for d = 1, 2, 3.

Each curve represents the impul: response of y

to a one standard

Consistent with our previous example, the long-run
deviation innovation in Elt•
to d- This can be seen in Figure 7 by noting
response of a typical shock is invariant

to 1, the long—run impact of a
thai all of the impulse response functions converge
standardized innovation in the no_component

version of the model (d

0). at the same

standard deviation shock to cit is not invaritime, the value to households of a one

ant to d.

This is because f0rward—looking agents care

about the intermediate-term

a decreasing function of d, the annuity

impact of permanent shocks. Since those are

is decreasing in d.

value of a standardized innovation in

This annuity value

equals 1, 0.2,0.115, and 0.31 in the d 0, 1, 2, and 3 decompositions, respectively.
necessarily falls as d increases. This is
These arguments do not imply that
because consumption also adjusts in response

tc t.

Not surprisingly, as d increases

and permanent shocks become less important, temporary
The annuity value of a standardized innovation

shooks become mere ispcrtant.

in c is 0, 0.330, 0.1122, and 0.1178 in

However, the inoreasing contrithe d =

0,

1, 2, and 3 decompositions, respectively.

bution of temporary shooks to '1ic is smaller
shocks.

We derive the relative volatility of consumption, 11Ac'

values by squaring them and taking the square

find that

than the reduced impact of permanent
from these annuity

root of the resulting sum. Doing an, we

equals 1, 0.88, 0.62, and 0.57 in the d =

0,

1, 2, and 3 deccnpOsi-

— 37 —

tions.

Interestingly, when d r

3

V5 is very close to the empirically plausible

value of 0.5.
To suemiarize our findings, consider three of the

1,

no—components model; the

czodels presented above: the •

1, 000aponents model with d

3; and the •

components model. The implications of the first model for the
are very different from those of the other two models. At the
tions of those other models for consumption dynamics

0.99,

no-

behavior of consumption

same time, the ispitha-

are very similar. The key fea-

ture that distinguishes the first model from the others

is the absence cf temporary

shocks.

This suggests that what is important for the dynamics of

value of + per se. Rather, it is the relative importance

consumption is not the

of temporary and permanent

shoots. A tight link between o and
the dynamics of consumption exists only under the
strong assumption that agents do not see and respond to different
income.

Without this assumption, the assertion that the

faced by agents contain a unit root——or that CV)a has
have important implications for the dynamics of

exogenous driving variables

a particular value-—does not

consumption.

A key feature of the two-component model of labor income

tion sets are larger than the econometrician's.

force the intuition about the driving force

components of labor

Is thst agents' informa-

We can build on this fact to rein-

underlying our results. IS

extreme example where economic agents actually know the entire

labor income. The eoonometrician does not. From the

future path of their

perspective of agents, the inno-

vat ion variance of labor income equals zero, so that the

change in consumption always

equals zero. This would be true even if there were a large innovation

unit root in the univariate labor income process.

Consider the

variance and a

The esamples we have discussed

above can be viewed as less extreme illustrations of this

point.

Unit Roots and the Real Business Cycle Model

Now we use the results above to analyze a second

example which, according to

Hansen (1989), suggests that model dynamics appear to be sensitive tounit roots. The

- 33

-

consumption e,
model he considers is one in which a representative agent chooses
ln(T-n)}
subject to the
capital kt+i, and hours worked n to maximize Y0(ln(o) ÷ s
resource constraint c •

kt+i

—

fl_o)kt

t• Here y, time t gross output, is pro-

(znt}(T_9

duced according to the Cobb-Douglas production function,
-

lu'iuIs

The

variable at is a technology shook that satisfies

Alog(z) = x ÷ C(L)et
where C(L) = (1—L)/(1—sL).
-

to
Hansen's results indicate that the volatility of hours worked, nt, relative

productivity, y/n,- is very sensitive to values of t near
behind this result can be described as follows.

1.

The basic intuition

Given our production function, the

inar-inal productivity of labor is proportional to average productivity, y/n.
things equal, both are an increasing function of at.

1, a positive innovation in at -is associated with a

Wi-ten

is positive and less than

smaller upward revision in the

Under these circumstances, the returns from working at time t are

outlook for

effect on n.

unusually high, thus triggering a strong intertemporal substitution
When

= , the outlook

Etzt÷t 5

a

Other

for future at moves one—for-one with innovations in z, since

for all i, t >

0.

Not surprisingly, here agents have less incentive to

intertemporally substitute labor over time.

-

in hours
In analyzing this example, we consider two measures of the volatility
worked, 0n

One

measure is the standard deviation of ilog(n), while the other is the
been applied

standard deviation of log(n), after the Kodriok and Prescott filter haa
(Prescott, 1936). similarly, we have two seasures of the volatility

of productivity,

cy/n. One is the standard deviation of ilog(y/n); the other, the standard deviation
of lcg(y/n), after the Hodrick_Premcott filter has teen applied.
All model

paraieter values——aside from those pertaining to ilog(a)——coincide

with those used in Chnistiano and Eiohenbaum N983b).'5 The method used
mate the solution to the model is also described there- An important

to approxi-

feature of the

- 39

solution

is that

-

it implies a linear bivariate time series representation for

log(n)

and log(y/n). in addition, both iog(n) and log(y/n) depend partly on the present
discounted value of expected future values of log(z).

This allows us to use the

intuition developed earlier.

Table 3 reports results based on the first-difference filter.'7
columns (1) and (2), we see that

On/Oy/n rises more than LW percent when t dropa from

1 to 0.99. Clearly, this is due primarily to an increase in the

volatility of nt. As

• drops below 1, fluctuations in z go from being 100 percent permanent tc
percent

Comparing

being 100

temporary. As indicated above, employment responds more to temporary than to

permanent shocks because agents lntertsmporally substitute hours worked toward
periods
in which the returns to working are relatively high.

The

sharp difference between these models reflects the maintained assumption that

there is only one source of shocks to agents' envtroicents. The analysis above sug-

gests that if we abandon this assumption and sdopt the d
of

3 components

representation

z given by (32)—(33), then the volatility of employment should rise toward the

value implied by the trend stationary model ( r 0.99). This is because a substantial
component
these

of

the shocks to the agents' erwironslents will then be transitory.

And

are the types of shocks that induce large changes in labor supply.

The results of this experiment are reported in column (3)

of Table 3. Notice
that the relstive volatility of hours is now roughly equal to the value which emerges
from the •
0.99 model. Also, the other moments of the unobserved components model

match the corresponding moments of the • 0.99 model reasonably well. Table U
reports results for the same three model economies but for which the Hodriok—Prescott

filter

has been used to induce stationarity.

The same general pattern observed In

Table 3 emerges in Table II.

These calculations roughly confirm the findings in our analysis of the
However, there are at least two respects in which a more complete analysis is

Pill.

required

before firm conclusions can be reached. First, we have only studied a small subset of

- 140

the

-

second-moment properties of the model. The •

components models may

differ

= 0.99

and the difference stationary

substantially in other dimensions.

Second, we wonder

whether a components representation of z can mimic a trend stationary REC model with
substantially lower values of s.

CONCLUSION

In this paper, we have argued that maoroeconomists should not take strong posi-

tions on whether postwar U.S. real GNP is trend or difference stationary.

As we

emphasized in the Introduction, there are strong a priori reasons for being suspicious

of claims in favor of difference or trend stationary representations of real GNP. A
simple way to.aee this. is to consider parametric ARMA representations of the firstdifferenced data.

Blough (988)

trend stationary ARI4A

and Cochrane (1988b) have pointed out that every

model has a difference stationary ANNA model local to it, and

virs versa. Distinguishing between these on the basis of a finite data set is surely
an Impossible task. .

This

a priori line of reasoning can be used to dismiss Campbell

and Flaniciw's (lg8Ta) rejection of the hypothesis of trend stationtrity in favor of the

difference stationary ARNA(2,2) model.

To do so, one need only consider a trend

stationary ARMA(3,3) model with autoregressive and moving average roots identical to

those of their ARMA(2,2) model plus an autoregressive root of
average root of 1. For

>

0

-

and a moving

but sufficiently small, it must be true that there is no

detectable difference between the competing models.

A similar line of a priori reasoning oould be used to dismiss almost any argument

in favor of a given difference stationary model of real CNP. One

need

only seleot a

treod stationary model that is arbItrarily close to it.

But suppose this were the

only way to salvage the trend stationary perspective.

At best, this would be a

Pyrrhic victory for that perspective since, for all practical purposes, the selected

trend stationary model would coincide with the given difference stationary model.
This is because the two models' impulse response functions would be virtually identical at all but infinite horizons. An analogous set of observations applies to argu-

- Ui

—

ments in favor of a given trend stationary model of real ON?.

In this paper, we go

beyond the a priori line of reasonIng by showing that one cannot distinguish between
difference and trend stationary models with impulse response functions which are sub-

stantially different at horizons even as short as three years. On this issue, the a
priori line of reasoning summarized above ia moot.

It is useful to contrast our results with those in the literature on the
properties of stationarity tests.

power

A variety of authors have concluded that existing

tests of whether time series are difference stationary or trend stationary have extremely poor power properties (for example, Oejong, Nankervis, Savin, and Whiteman,
1988).

Power issues are of interest in the context of tests of the unit root null

hypothesim because this hypothesis is typically not rejected for postwar U.S. real ON?

data. However, power issues are obvfously of less interest when the null hypothesis
is rejected. This is precisely the relevant case in the context of testing the trend
stationary null hypothesis. The major result In the literature is the strong rejection of trend stationarity for postwar U.S. real ON? (Campbell and Nankiw, ?987a).

The principal focus of the first part of our paper is on this rejection.

From

thia perspective, the issue of interest is the size of Campbell and Nankiw's (i9UTa)
test, that is, the probability of rejecting the null hypothesis if the data-generating

mechanism is in fact trend stationary.

The size characteristics of their test are

excellent if the analyst specifies the correct ARMA representation of the data. However, we show that their tests give extremely misleading results if that ARMA repre-

sentation is misspecified in seemingly innocuous ways. This result complements those
of Oejong, Nankervis, Savin, and Whiteman (1988), who show that specification error in

the form of unmodeled residual correlation can lead to excessive rejection of the
trend stationary null hypothesis.

Viewed as a whole, the results here are consistent with the view that one cannot

discriminate, on the basis of postwar data, between the null hypotheses of trend and
difference stationarity for U.S. real ON?. At the same time, economic theory offers

— 142

no guidance on this question.

—

As Sims (lgBB) has emphasized, in linear models, the

trend behavior of endogenous variables is almost always determined by the analysts
assumptions about the trend behavior of the unobservable forcing vartables in agents'
environments.

Ii

does

not emerge from some principle of eoonomic theory. True, one

can construct endogenous growth models in which the prediction of difference sta—
tionarity emerges from the production of human capital.

(See, for example, King,

Plosser, and Rebelo, 1988; King and Rebelo, 1936: and Christiano and Eichenbaujn,
1988a.)

Unfortunately, though, these implications depend very sensitively on par-

ticular functional form assumptions about which economic theory has little to say.

Should we despair at not knowing? We think not. Our results suggest that the
implications of a broad class of dynamic models are reasonably robust to whether the

forcing variables in agents' environments are modeled as trend or difference stationary.

Existing examples which purport to document extreme sensitivity actually

demonstrate sensitivity to the extreme assumptions that all shocks are either temporary or permanent.

We think nacroeeonomists should care very much about the rela-

tive importance of permanent and temporary shocks to agents' environments.

But con-

ventional aiheoretioal measures of persistence convey little information about this
question.

And structural inferences based on such measures cught to be viewed with

extreme skepticism. Convincing inference requires the use of economic theory in conjunction with the data.

- 43

-

NOTES

'To see this, suppose that the model being estimated is an ARMA(p,2)
p >

0.

Denote the moving average roots by X1

and t2.

with

For simplicity, assume these

are real. Let t denote the parameters of the pth..order autoregressive

is well own that the exact likelihood function obtained after

component.

It

concentrating out the

innovation varxanoe, L(,x1,x2), has the property that
L(Q,411x2)

Therefore, L3(,x,1)

0, where 13 denotes the partial derivative of L with respuct

to its third argument. We can express L as a function of 0(1)

a k by substituting out
terms of k; L[$,11,1_k$(1)/(1_51)J. Then the partial derivative of I. with
respect to k is
which equals aero for k a 0. Let
1(k)
L{ox111_k$(1}/(1_xpj, after maximizing out
for A2

in

and X. A simple envelopeargu_

ment establishes that the derivative of f with respect to K is also zero.

2Essentially, the Christiano-Ljungqvist method is a model selection strategy.
Alternative strategies are the sequential likelihood ratio tests and Akaike (1974) or
Schwartz (1978) criteria.
These model selection procedures may be quite useful for

choosing among forecasting models when there is a clear gain to parameter

parsimony.

However, they may not be appropriate for our purposes.

The Christiano_LJungqvist
procedure is closely related to methods for testing nonnested models, the
encompassing
principle discussed by Mizcn and Richard (1986), as well as the selection criterion
used by Sargent (1916) and Christiano and £ichenbaus (1987).

3in their analysis, Campbell and Mankiw (1987a)

include data from 1947 and esti-

mate their models using a Kalman—filtering algorith.m.

"The log likelihood value associated with these parameter values is only 0.0 15
below the global maximum.

5All shooks were drawn from a normal distribution

with mean zero and standard

deviation 0.0100847.

6This formula oan be obtained as follows. Eirmt replace the Gaussian likelihood

function by its frequency domain approximation [for example,

equation (145) in
Christiano and Eichenbaum, 1987]. Then replace the periodogram in that formula by the
spectral density of the true model. The formula in the text is obtained by concen-

trating out the innovation variance from the latter and by driving the number of
observations to infinity.
Christiano and Fiohenbaum (1987) use the unconcentrated,
multivariate version of this formula to analyze the large-sample consequences of maxi-

mum likelihood estimation of a misspeoified model. The formula in the text is also an
implication of equation (AM) in Coohrane (1988a). Both our derivation and Cochrane's

assume that C(1) a 0. The following computational experiment makes us somewhat

con-

—a

fident

-

0. We computed the plim of the mis—

that the formula also holds when C(i)

specified ARMA(2,2) model in two ways. One corresponds to the method described in the

text. The other is a discrete analog of the formula in the text which employs 1,000
equispaced points around the unit circle.

Both methods yield virtually identical

results.

7This model is (1 — 1.5075L +

=

0.5296L2)Ayt

(1

—

A930L

+

0.1930L2)nt.

8We repeated all the experiments discussed in this secticn with the Campbell—
Maniciw aRMA(1,3) model as the data-generating process. With respect to the asymptotic

arguments, our results were virtually identical.

The results of redoing the last

Monte Carlo discussed in the text were similar, though less dramatic. The effect of
reducing the autoregressive parameter from 0.95 to 0.5 is to reduce the percentage of
likelihood ratio statistics exceeding 14.356 from 38 to 22.

91n fact, 14 of the 20 likelihood ratio statistics are exactly equal to zero,
while the largest only equals 1.77.

'°We obtained the following point estimates for the ARMA(2,1) model with

CM) =

1.35Thy — 1
(0.074)

—

0.393Ay

(0.075)

+

t

—

gumbers in parentheàes are standard errors obtained by taking minus the inverse of the
second derivative of the log likelihood function.

''Once parameter uncertainty is taken into account, these differences may not
even be statistically significant. For example, consider the old and new Slanchard
models. Point estimates and associated standard errors fcr the latter are reported in

note 10. They show that the lag 1 and 2 coefficients in the old Blanchard model are
0.22 and 0.36 standard errors, respectively, away from the corresponding coefficients
in

the new Blanchard

model.

For example, in (15), with a quarterly interest rate of 1 percent, changes in

12

anticipated income even 40 years in the future reoeive a nonnegligible weight of

1.oi60 = 0.2.

See Chrlstianc (1987) for an extended discussion cf the view that

unit roots may matter in the context of the PIH.

'3Th1s is a general property of temporary/permanent decompositions, not Just
orthogonal decompositions. For a proof, see Cochrane (1988a, p. 9014).

.
2
3, ai also satisfies (as) — xiai + 1 = 0 for i ' 1, 2. Here
3(1-p)2/p and
a1 and x2 are the solutions to c2 — (c1-s-'4)x . (c0-s.2o1+4) r 0, where ci
where i =
0.97
—
÷
0.0067i
0.0067i,
0.97
and a2
c/3. When p z 0.98, a1 =
l't

For the case d

(1)1/2

- 1j5 15

We

thank Ken West for this argument.

'51n particular, the parametric values are those reported in the "Divisible
Labor" column of their Table 1.
''The second-moment properties reported in Tables 3 and 14 were obtained by appiy-

ing the appropriate inverse Fourier transform to the spectral density of the filtered
bivariate system. (For example, see Sargent, 1987, chap. 11, sec. 6.)

REFERENCES
(19711)
A New Look at Statistical Model Identification. IEEE Transactions
on Automatic Control, AC—19: 716-23.

Akailte, H.

Ansley, C. F.
(1979)
An Algorithm for the Exact Likelihood of a Mixed Autoregressive-Moving Average Process. Biometrika, 66: 59-66.
Beveridge, S., and Nelson, C. F.
(1981) A New Approach to Decomposition of Eoonomio
Time Series into Permanent and Transitory Components with Particular Attention to
Measurement of the "Business Cycle." Journal of Monetary Economics, 7:
151.Ttl.

Blanchard, 0. J.
What is Left of the Multiplier Accelerator?
(1981)
Economic Review (Papers and Proceedings), 71: 15O-5q.

American

Blanchard, 0. J., and Quah, D.
(1988) The Dynamic Effects of Aggregate Demand and
Supply Disturbances. Manuscript, Massachusetts Institute of Technology.

Blough, S. R.

(1988)

On the Impossibility of Testing for Unit Roots and

Cointegraticn in Finite Samples.
University.

Working Paper in Economics 21 1, Johns Hopkins

Braun, R. A.

Taxes and the Postwar U.S. Business Cycle.
(1989)
University of Virginia.

Manuscript,

Campbell, J. 1., and Deaton, A. (1988) Why is Consumption Sc Smooth? Manuscript.
Princeton University.

Campbell, J. Y., and Mankiw, N. C.

(1987a)
Are Output Fluctuations Transitory?
Quarterly Journal of Economics, 102: 857-80.

(1987b)
Permanent and Transitory Components in Macroeconomic Fluctuations. American Economic Review (Papers and Proceedings) 77: 111-17.

__________

(1989) Permanent Income, Current Inccme, and Consumption. Manuscript,
Princeton University.

__________

(1987) Is Consumption Insufficiently Sensitive to Innovations in
[noome? American Economic Review (Papers and Proceedings) 77: 33T-l1.

Christlano, L. .J.

Christiano, L. J., and Eichenbaum, M.
(1987)
Temporal Aggregation and Structural
Inference in Macroeconomics. Bubbles and Other Essays, eds. K. Brunner and A. H.
Neltzer. Carnegie—Rochester Ccnference Series on Public Pclicy, 26:
63—130.
Amsterdam: North—Holland.

(!986a) Human Capital, Endogenous Growth and Aggregate Fluctuations.
Manuscript, Federal Reserve Bank of Minneapolis.

___________

(19B8b)
Is Theory Really Ahead of Measurement? Current Real Business
Cycle Theories and Aggregate Labor Market Fluctuations.
Working Paper 2700,

__________

National Bureau of Economic Research.

- 46

-

Christisno,

The Peraanent income
(1989)
L. J.; Eichenbauin, M.; and Marshall, D.
Hypothesis Revisited. Manuscript, Federal Reserve Bank of Minneapolis.

J.,

and Ljungqvist, L.
(1988) Money Does Granger-Cause Output in the
Christiano, L.
Bivariate Money-Output Relation. Journal of Monetary Economics, 22: 217-35.

Clark, F. K.
(1987) The Cyclical Component of U.S. Economic Activity. Quarterly
Journal of Economics, 102: 797-814.
Cochrane, J. H.
(1968a)
Economy, 96: 893-920.

How Big Is the Random Walk in GNP? Journal of Political

_________ (1988b)

A Critique of the Application of Unit Roots Tests. Manuscript,
University of Chicago.

Deaton, A. S.

(1986)

Life Cycle Models of Consumption: Is the Evidence Consistent

with the Theory?
Advances in Econometrics.
Fifth World Congress of the
Econometric Society, Cd. T. F. Bewley, 2: 121-46. Cambridge, Mass.: Cambridge
University Press.

DeJong, 0. N.; Nankervis, J. C.; Savin, N. E.; and Whiteman, C. H.
Integration Versus Trend-Stationarity in Macroeconomic Time Series.
University of Iowa.

(1988)
Manuscript,

Dc Long, J. B., and Suamers, L. H. (1988) On the EAistence and Interpretation of a

"Unit Root" in U.S. GNP.

Working Paper 2716, National Bureau of Economic

Research.

Flavin, H. A.
(1981) The Adjustment of Conmumption to Changing Expectations About
Future Income. Journal of Politicel Econcy, 69:
974—1009.

Granger,

C. W. J., and Newbold, P.
York: Academic Press.

(1977)

Forecasting Economic Time Series.

New

Hall, B. E.

Stochastic Implications of the Life Cycle-Permanent Income
(1978)
Hypothesis: Theory and Evidence. Journal of Political Economy, 86: 971—87.

Hansen, G. D. (1989) Technical Progress and Aggregate Fluctuations. Department of
Economics Working Paper 546, University of California, Los Angeles.

Hansen, L. P.
(1987) Calculating Asset Prices in Three Example Economies. Advances
in Econometrics.
Fifth World Congress of the Econosetric Society, ed. T. F.
Bewley, 2: 207-43. Cambridge, Mass.: Cambridge University Press.

Jaeger, A., and Kunst, B. K. (1989) Seasonal Adjustment and Measuring Persistence in
Output. Manuscript, Institute for Advanced Studies, Vienna, Austria.

Production, Grcwth and
King, B. G.; Plosmer, C. I.; and Rebelo, S. 7.
(1988)
Business Cycles: II. New Directions. Journal of Monetary Econcmics 21: 309—
41.

Stochastic Trends and
(1987)
King, B. G.; Plosser, C.; Stock, J.; and Watson, H.
Economic Fluctuations. Working Paper 222g. National Bureau of Economic Research.

King, B. G., and Rebelo, S. T.

(1986)
Manuscript, University of Rochester.

Business Cycles with Endogenous Growth.

Kohn, B.
(1979)
Asymptotic Estimation and Hypothesis Testing Results for Vector
Linear Tiae Series Models. Econcmetrica, i7: 1005-1030.

Long, J. B., Jr., and Plosser, C. I.

(1983)

Real Business Cycles.

Journal of

Political Economy, 91: 39-69.

The Macroeconomic Effects of Tax Policy in an Equilibrium
McOratten, K.
(1989)
Model. Manuscript, Duke University.

- 47
Mizon, C. E., and

Richard, J.

F.

—

(1986)

Application to Testing Non—nested Hypotheses.

The Encompassing
Econometrics,

Princtple

5l:

and

657-78.

Its

Nelson, C. R., and Piosser, C. I.
(1982) Trends and Random Walks in Macroeconomic
Time Series:
Some Evidence and Impiications.
Journal of Monetary Economics,
10: 139—62.

Piosser, C. I., and Schwert, C. W.
(1977)
Estimation of a Non—Invertible Moving
Average Process: The Case of Overdifferencing. Journal of Econometrics, 6:
199—

224.

Prescott, K. C.
(1986) Theory Ahead of Business Cycle Measurement.
Federal Reserve
Bank of Minneapolis Quarterly Review, 10:
9—22.
Also in Real Business Cyc4
Real Exchange Rates and Aotuai Policies. Carnegie-Rochester Conference Series on
Public Policy, eds. K. Brunner and A. H. Meitter, 25: 11—444.
Amsterdam: North—
Holland.
Priestly, K. 5.

Quart, o.

(1982) pgçral Analysis and Time Series. London: Academic Press.

(1988)

The Relative Importance of Permanent and Transitory Components:
Identification and Some Theoretical Bounds.
Working Paper 498, Massachusetts
Institute of Technology.

____________
tlon for

(1989)

"Excess

Permanent

Smoothness"

of Technology.

and Transitory Movements in Labor Income:

An Explana-

in Consumption. Manuscript, Massachusetts Institute

Sargan, J. 0., and Bhargava, A. (1983) Maximum Likelihood Estimation of Regression
Models with First Order Moving Average Errors When the Root Lies on the Unit
Circle. Econometrioa, 51: 799—820.

Sargent, T. (1976) Econometric Evogeneity and Alternative Estimators of Portfolio
Balance Schedules for Hyperinflations: A Note. Journal of Monetary Economics,
2: 511—21.
__________ (1987) Macroeconomic Theory. 2d S. New York: Academic Press.
Schwarz, 0. (1978) Estimating the Dimension of a Model. Annals of Statistics, 6:
1461—64.

Sahwert, 0. N.
Macroeconomic

C

1987)

Effects of Model Specification on Tests for Unit Roots in
of Monetary Economics, 20: 73—103.

Data. Journal

Sims, C. A. (1988) Bayesian Skepticism on
nomic Dynamics and Control, 12: 1463—714.

Unit Root Econometrics. Journal of

Watson, M. N.
(1986) Univariate Detrending Methods with Stochastic Trends. Journal
of Monetary Economics, 18: 49-75.

West, K. 0. (198k) The Insensitivity of Consumption to News About Income. Journal
of Monetary Economics, 21: 17—33.
On the Interpretation of Near Random—Walk Behavior in ClIP.
___________
(1988b)
American Economic Review, 78 202—209.

Table 1

Results Based on Parametric Models of Persistence

Roots

Likelihood
Ratio Statistic**
(p-value)

Model
p,q*

..

--

.568.719

0,1

.

C(1)

Autoregressive

0,2

275.825

0,3

170.775
(.00)

-.275

1.275

(.00)

Moving
Average

.

1,577

.

-. 153±.498i

(.00)
•

•

--

1,0

-.392,
.025±.608i

1.838

1.602

.376

——

.168

1,1

23.684
(.00)

1.746

.52k

1,2

11.27k
(.00079)

1.772

.260

1.816

-.089

1,3
.
,.

2,0

.

!.

.110
(,74)

.

——

2,1

.8h0
(.36)

2,2

I.356

2,3

.990
(.32)

-.034±.491i

.

,0i2±.6221,
-.451
——

1.830

.554,—.542

1.798

.508,-.542

1.530

.293±.614i

.139±.776i

1.605

.168±.668i

.108±.8k8i,
—.206

1.604

.432t.297i,

—.365

(.04)

3,0.

.

-.518
3,1

.569
(.45)

1.365

3,2

3.020

1.657

.000
(1.00)

.249,

.1o8±,867i

.149 t.720i

(.08)

3,3

;631±.3koi,
-.417

.000

.299±.565i,
.949

.133±.7471,
1.000

autoregressive and moving average order, respectively, of ARMA
fit to Ay.

*p,q

ttwioe the difference between log likelihood values obtained when
(The p—value is obtained using the
C(1) = 0 is and is not imposed.
chi—square distribution with 1 degree of freedom.)

Table 2
Nonparametric Estimates of Persistence

Model

k

C(1)'

vk

ARIIA(3,3)

ARMA(l,3)

ARMA(2,2)

(1)

(2)

(3)

(4)

(5)

(6)

10

1.41

1.71
(5,49)

.29

.34

.46

20

1.24

1,32
(3407)

.37

.41

.63

30

1.14

1.12
(2.14)

.34

.37

.65

40

1.00

.86
(1.43)

.38

.40

.68

50

.86

.64
(.95)

.44

.44

.73

60

.88

.67

.31

.32

.62

.18

.20

.48

•

(.91)
75

.70

.90

(.85)

Notes:
Columns (2) and

(3):

C(l)k is defined in equation (14);

in (7).

(4)—(6):
Frequency, in artificial data generated by the
indicated ARLIA model, that the simulated
exceeds the corresponding

Columns

empirical value reported in column (3).

The ARMA(3,3) and ARMA(2,2)

models are those we estimated and reported in Table 1. The ARI4A(1,3)

model is the trend stationary model reported in Campbell and Mankiw
(1987a).

Table 3
Results Based on First-Difference Filter

Components
Model
Mo-Components Model

.
$
:

,=1
I

(1)

°n

cov(n,n1)
eov(y/n,y/n1)

cov(n,y/n1)
cov(y/n,n1)

(2)

.98

p

(3)

.97

.96

.0065

.0086

.0085

.0096

a,

.99

.68

°n'y/n
.

$

.0089

.0089

—.026

-.026

-.026

.060

.073

.08k

-.072

-.07k

-.072

.023

.031

.032

Table 4
Results Based on Hodrick—Prescott Filter

Components
Model
No-Components Model

$1

$1

$=.99

p.98

(1)

(2)

(3)

a/a,

.67

.9k

.9k

a

.008k

.011

.011

.013

.012

.012

.71

.71

.71

cov(y/ny/n1)

.74

.75

.75

cov(n,y/n1)

.59

.57

.57

.75

.75

.75

.

cov(n,n1)

cov(y/n,n_1)

0

5.4

0.0

0.0

I

cc'

fl/J2z.z——1.4

1.6

_._..._... .—___._._

1.2

1.0

2

541

532

0.2

5415

534

—--

542

530

230.5
0

540

0.4

q=3
-

0.0

q=2

-,

ARMA(2)

0.2

-

5.4

0.0

q2

Figure lb ARMA3q)

545.5

543
542/2

526

ic

530—--—-0
5.2

5-JO_s

545

540.5

541

541.5

542

530

ñgure lb ARMAI1,qI

FlQu!e
542.5

540

542

Vt C(1)

cc' i

Maximized Log Likelihood Function
br Various ARMA Models

Figures la—id

--

0.0

q—i

0.5

1

-

Ccli

I

qe3

ccl'

L

-

-

..

----

-.
.

1

2

1/2

—

1.1

.4

/

-j/

-

1-6

IS

-

1.0

.5

2

2

Figures 2a—2b

Accounting for the ARMA(2,2) Results
From the Trend Stationary Perspective
Figure 2a Frequency Distribution of the Likelihood Ratio Statistic
for Testing C(1) = 0
0.1

0,09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.01

Figure 2b Frequency Distribution of C(1)

1]

0.08
U-

0

0.5

1.5

clii

2

2.5

I

N.

S

-

-

5.5

-

AFIMA(2,2)

Constrained

/ N

,Modat

-

25-

0.5

I

9

-

I

-

2

FregusseylAaaiassl

1.5

Estimated
ARMA(3.3)Modet

-

0,5

-I -- -:

:1

5.5

I ARMA(22)
I Model

u.s

t
2

Erepsency IRanians)

t.5

ARMA(3,3) Mode!

a

5

//

-

-

Its

1••

/
/

—

t

-

sneesi

-

25

:i

Unconstrained
AtRMAI2,21 Model

1,5
2
FsesrsaricyRaniansI

- Mod,Eed Model
ARMA43)
-

Data Gene,ate,r by Mouthed 5$tMA)33

Fgure 3c Unconst'-anreu Results

I-

I5

2.5

Note, The curves pa the ligures above depict the spectral density of various models
Each spectraldensity has been scaled so that the Innovationvariance is unity

-

—--•-

h

-

NUnconstrained

—

Figure 3a Unconsireined Resuts
Data Gerreraled by Eslinraled AAMA(.3} Model

..sL

25

Figure 3b ConstrainedFlesulls
Data GanaratsitSy EstimatedtaiW4O.3) Mndei

A Large-Sample View

Why the Trend Stationary Perspective Can Accountfor the ARMA(2,2) Results

Figures 3a--3c

-J 5,

11.4

Os

lb

Old
Blanchard

0

0.0

LO

.6

/

.

.

11(1

Model

(0

glanchard-

New

—,

111110

57
lOea0000J

ye

Eslirnaled
ARMAç&a)Mortal

Esbrrraled

'I

us

______:__..

Cll}Basedoe

ResponseFunclions
hnpd.dby Vsflou.ARMA Models

Figure
Impedes

g
20.15

0.11°

0.214-

70

00

00

lOb

.;,---- ..

I
0.7

0.1

02

0.7-

0.4

;e.s

tO

50

---

'Empwoal40

:0

-

/

20

.

7°

/
/

.-

110

d-2

d-t/

150

/
/
/

-

01,0

00111)

lime Oaannial

1100

756

50

el Estimated
AR
31

Meanc

DynamicResponseat Psnssnsnt Conrpaaant
toe One Stardard DevIationShook
a,CrIUltl -U lord — 1.2.3

Figure 7

0

11,4

4.2

o.e

11

1.4

s.0

lIt

Nonpnnretrlc M.ssurss
otPutslslsnce

FreQuencyDirIrrbsoliricot Gfl)
Using Dale GenereleolbyEsirnoalod 0nM4122t Model

b.n_

bay

Figure

F'gorel
Accoontirig tar the ARMA(1,) aid AJWA43.31 Results
Front lb. OlileruncuStationeryPeropsolive

400

4201

70

5101

50

