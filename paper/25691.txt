NBER WORKING PAPER SERIES

THE CAUSAL INTERPRETATION OF TWO-STAGE LEAST SQUARES WITH
MULTIPLE INSTRUMENTAL VARIABLES
Magne Mogstad
Alexander Torgovitsky
Christopher R. Walters
Working Paper 25691
http://www.nber.org/papers/w25691

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
March 2019, Revised July 2020

We thank Stéphane Bonhomme, Vishal Kamat, Azeem Shaikh, and Ed Vytlacil for helpful comments,
and Christine Blandhol, John Bonney, and Conroy Lau for outstanding research assistance. The views
expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau
of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w25691.ack
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2019 by Magne Mogstad, Alexander Torgovitsky, and Christopher R. Walters. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.

The Causal Interpretation of Two-Stage Least Squares with Multiple Instrumental Variables
Magne Mogstad, Alexander Torgovitsky, and Christopher R. Walters
NBER Working Paper No. 25691
March 2019, Revised July 2020
JEL No. C01,C1,C26
ABSTRACT
Empirical researchers often combine multiple instrumental variables (IVs) for a single treatment using
two-stage least squares (2SLS). When treatment effects are heterogeneous, a common justification
for including multiple IVs is that the 2SLS estimand can be given a causal interpretation as a positively-weighted
average of local average treatment effects (LATEs). This justification requires the well-known monotonicity
condition. However, we show that with more than one instrument, this condition can only be satisfied
if choice behavior is effectively homogenous. Based on this finding, we consider the use of multiple
IVs under a weaker, partial monotonicity condition. We characterize empirically verifiable sufficient
and necessary conditions for the 2SLS estimand to be a positively-weighted average of LATEs under
partial monotonicity. We apply these results to an empirical analysis of the returns to college with
multiple instruments. We show that the standard monotonicity condition is at odds with the data. Nevertheless,
our empirical checks show that the 2SLS estimate retains a causal interpretation as a positively-weighted
average of the effects of college attendance among complier groups.

Magne Mogstad
Department of Economics
University of Chicago
1126 East 59th Street
Chicago, IL 60637
and NBER
magne.mogstad@gmail.com
Alexander Torgovitsky
University of Chicago
1126 E. 59th Street
Chicago, IL, 60637
atorgovitsky@gmail.com

Christopher R. Walters
Department of Economics
University of California, Berkeley
530 Evans Hall #3880
Berkeley, CA 94720-3880
and NBER
crwalters@econ.berkeley.edu

1

Introduction

Instrumental variables (IVs) are widely used to estimate causal relationships. In practice, researchers often combine multiple IVs using two-stage least squares (2SLS). In
Section 2, we report a survey of empirical papers using IV that were published in leading
journals since 2000. More than half of these papers report results from a specification
with multiple IVs for a single treatment, typically combined using 2SLS.
The textbook motivation for combining multiple IVs is statistical efficiency. However, this requires an assumption of constant treatment effects. In contrast, allowing
for heterogeneous treatment effects is a key motivation in the modern program evaluation literature, and one which is supported by a large body of empirical work.1 In an
influential paper, Imbens and Angrist (1994, “IA” hereafter) provided an alternative
justification for using 2SLS with multiple IVs, one which allows for heterogeneous treatment effects. They showed that the 2SLS estimand can be interpreted as a positivelyweighted average of local average treatment effects (LATEs) for subpopulations whose
treatment status is affected by the instruments. This result holds for any number of
instruments, as long as IA’s “monotonicity” condition is satisfied.2
The fact that widespread empirical practice rests on the monotonicity condition
raises a number of questions. What requirements does this condition place on choice
behavior when there are multiple IVs? Can we expect these requirements to be satisfied? If not, is it still possible to retain a causal interpretation of the 2SLS estimand
while allowing for unobserved heterogeneity in both treatment effects and choice behavior? The contribution of our paper is to answer these questions and, by doing so,
offer theoretical and empirical guidance for researchers who wish to use 2SLS with
multiple IVs.
In Section 3, we begin our theoretical analysis by showing that the monotonicity
condition cannot be satisfied with more than one instrument without restricting choice
behavior to be effectively homogenous.3 For example, if the treatment is college at1

Heckman (2001) compiled a list of empirical evidence on heterogeneous treatment effects prior to
2001. More recent papers that find evidence of unobserved heterogeneity in treatment effects include Bitler,
Gelbach, and Hoynes (2006), Doyle Jr. (2007), Moffitt (2008), Carneiro and Lee (2009), Firpo, Fortin,
and Lemieux (2009), Carneiro, Heckman, and Vytlacil (2011), Maestas, Mullen, and Strand (2013), Bitler,
Hoynes, and Domina (2014), Walters (2014), Felfe and Lalive (2014), French and Song (2014), Havnes and
Mogstad (2015), Kirkeboen, Leuven, and Mogstad (2016), Kline and Walters (2016), Carneiro, Lokshin, and
Umapathi (2016), Cornelissen, Dustmann, Raute, and Schönberg (forthcoming), Nybom (2017), and Brinch,
Mogstad, and Wiswall (2017).
2
In discussing the use of multiple IVs instead of a single binary instrument, Angrist and Pischke (2009, p.
173) write that “The econometric tool remains 2SLS and the interpretation remains fundamentally similar
to the basic LATE result, with a few bells and whistles.”
3
Our analysis here builds upon points made by Heckman and Vytlacil (2005, Section 6) and Heckman,

1

tendance and the instruments are tuition and proximity, the monotonicity condition
requires all individuals to respond more to tuition than to proximity, or vice versa.
This is a concerning implication; it shows that appealing to IA monotonicity to justify
combining multiple IVs comes at the cost of assuming homogeneity in choice behavior.
Motivated by this observation, we then consider a weaker, partial version of the
monotonicity condition. The partial monotonicity condition is that the IA monotonicity condition is satisfied for each instrument separately, holding all of the other
instruments fixed. We show that partial monotonicity is satisfied if each instrument
makes every individual weakly more likely to choose treatment. For example, a sufficient condition for partial monotonicity is that all individuals are at least as likely to
attend college if they live closer to a college or face lower tuitions. However, unlike
the IA monotonicity condition, partial monotonicity does not restrict heterogeneity in
the relative impacts of different instruments; it allows for some individuals to respond
more to tuition than to proximity, and for others to respond more to proximity than
to tuition.
In Section 4, we show that even though partial monotonicity permits heterogeneous
choice behavior, it can still be sufficient to give the 2SLS estimand a causal interpretation as a positively-weighted average of LATEs. Moreover, we characterize sufficient
and necessary conditions for this interpretation, and show that the conditions can be
checked empirically. In a simple case with two binary instruments this amounts to
verifying that the unconditional correlations between the treatment and each instrument have the expected sign. More generally, our results provide a set of tests that
researchers can report alongside 2SLS estimates formed from multiple IVs. These tests
are implemented in our companion Stata module, mivcausal.4
In Section 5, we apply our results to estimating the returns to college attendance,
using the same data as Carneiro et al. (2011). We focus on two instruments used
by those authors: local labor market conditions and distance to college. We show
that these instruments generate different estimated marginal treatment effect (MTE)
schedules, a finding which is inconsistent with IA monotonicity. Nevertheless, our
empirical checks show that under partial monotonicity the 2SLS estimand retains an
interpretation as a positively-weighted average of the causal effects of college attendance
among complier groups. This finding illustrates how assumptions weaker than IA
monotonicity can be sufficient for the modest empirical goal of using 2SLS to recover
a weighted average of LATEs.
Urzua, and Vytlacil (2006, Section III.D).
4
The module is available for download from the Boston College Statistical Software Components (SSC)
archive.

2

2

Survey on the Use of Multiple Instruments

Empirical researchers often combine multiple IVs using 2SLS. To document this practice, we searched the Web of Science Database for articles published between January
2000 and October 2018 containing the words “instrument” or “instrumental variable”
in the abstract, title, or topic words. We restricted the search to the following five
journals: Journal of Political Economy, American Economic Review, Quarterly Journal of Economics, Review of Economic Studies, and Econometrica. In total, 266 articles
matched our search criteria.
We restrict our attention to the 122 of these papers that use at least one IV in an
empirical application. The other 144 papers not included were either methodological
papers without an empirical application, or were papers that used the word “instrument” in a different context, such as to describe a policy or financial instrument.
Column (1) of Table 1 tabulates the papers used in our survey by the journal in which
they were published. The other columns of Table 1 categorize these papers based on
the number of IVs used, the number of IVs compared to the number of endogenous
variables, and the choice of IV estimator.
Column (2) includes papers containing at least one specification in the main body
of the paper that included more than one IV. The number of IVs is defined as the
number of variables excluded from the outcome equation. If a paper has multiple IVs,
but each reported specification used no more than one instrument, then we do not
count it in column (2). The bottom row of column (2) reveals that more than half of
the papers in our sample used more than one instrument.
In column (3) of Table 1, we count the subset of papers from column (2) that have
at least one specification in the main body of the paper with more IVs than endogenous
variables. This is typically referred to as an “over-identified” specification in a constanteffects model. Comparing column (3) to column (2), we see that most papers that used
more than one IV had a specification with fewer endogenous variables than IVs. Nearly
all of these specifications have just a single endogenous variable, consistent with the
framework that we will use in our analysis.
A few of the papers in column (3) used more IVs than endogenous variables in a way
that was either nonstandard or unclear to us. In column (4), we remove these papers
and focus on only those that combined multiple IVs using 2SLS or optimally-weighted
generalized method of moments (GMM). This leaves 43% of papers across the five
journals. This confirms our claim that combining more instruments than endogenous
variables through 2SLS (or occasionally GMM) is widespread empirical practice. This
practice is the focus of this paper.

3

Table 1: IV papers by journal and type

(1)
All papers

(2)

(3)

Papers that use
Papers with more
multiple IVs
IVs than endogenous
variables

(4)
Papers with more
IVs than endogenous
variables using
2SLS/GMM

American
Economic Review

100%
44

39%
17

36%
16

34%
15

Quarterly Journal
of Economics

100%
28

54%
15

46%
13

43%
12

Journal of Political
Economy

100%
23

65%
15

48%
11

43%
10

Econometrica

100%
15

67%
10

60%
9

53%
8

Review of
Economic Studies

100%
12

67%
8

67%
8

58%
7

All

100%
122

53%
65

47%
57

43%
52

In Table 2, we categorize the papers in column (4) of Table 1 into three types by
the relationship between their multiple IVs. Case A is when at least two of the IVs are
economically distinct quantities. For example, Carneiro et al. (2011) instrument for
college attendance with measures of local labor market conditions, distance to college,
and local tuition in public four-year colleges. As shown in column (2), the vast majority
of papers fall into case A. Given its empirical importance, our analysis will be centered
around this case.
The other two cases are less common. Case B are papers in which all IVs in the
multiple IV specification are formed via interactions between pre-determined covariates
and a single exogenous instrument. For example, Angrist and Krueger (1991) use a full
set of indicators interacted between state and quarter of birth as instruments for years
of schooling. As we see in column (3), case B accounts for only 13% of the papers,
making it the least common of the three types of papers with multiple IVs. Case C is
when the multiple IV specification uses functions of a single exogenous variable. For
example, using distance and its square as instruments for college attendance would fall
into this case. As shown in column (4), Case C is also relatively rare, accounting for
only 19% of the papers.

4

Table 2: Multiple IV papers by journal and relationship between their IVs

(1)

(2)

Papers with more
Case A
IVs than endogenous
variables using
2SLS/GMM

(3)

(4)

Case B

Case C

American Economic Review

100%
15

60%
9

13%
2

27%
4

Quarterly Journal of Economics

100%
12

75%
9

8%
1

17%
2

Journal of Political Economy

100%
10

70%
7

0%
0

30%
3

Econometrica

100%
8

63%
5

38%
3

0%
0

Review of Economic Studies

100%
7

71%
5

14%
1

14%
1

All

100%
52

67%
35

13%
7

19%
10

This table classifies the papers from column (4) of Table 1 into three cases of multiple instruments.
Case A are studies that use multiple economically distinct instruments. Case B are studies that
use covariate interactions with a single instrument. Case C are studies that use multiple functions
of a single instrument. These cases are mutually exclusive and exhaustive; some proportions do not
sum to 100% due to rounding.

3

Monotonicity Conditions with Multiple IVs

This section contains our results on the interpretation of the IA and partial monotonicity conditions when there are multiple IVs. We first develop an equivalent characterization of the IA condition, which facilitates a graphical interpretation of its content.
Among other things, the graphical interpretation reveals that the IA condition has
nothing to do with “monotonicity” in the usual sense of the phrase. Then, we argue
that IA monotonicity severely restricts choice heterogeneity. This motivates interest
in the weaker, partial monotonicity assumption. Throughout the paper, we consider
the binary treatment case, since allowing for multiple treatments already complicates
the IA monotonicity condition even with a single instrument (Angrist and Imbens,
1995; Heckman et al., 2006). For our theoretical analysis, we condition on covariates

5

nonparametrically and keep this conditioning implicit in the notation.

3.1

Definition of the IA Monotonicity Condition

Consider a population of individuals i ∈ I. Denote individual i’s potential treatment
status if some instrument vector Zi were set to z by Di (z) ∈ {0, 1}, where z takes

values in some subset Z of RL . We assume that the support of Zi is contained in Z,
possibly as a proper subset. When L > 1, we view each component of the vector Zi as

comprising an economically distinct quantity. That is, if L = 2 then Zi,1 and Zi,2 will
denote the two distinct instruments, each of which can take two or more values.
Imbens and Angrist (1994, “IA”) introduced the following assumption on the potential treatment states, which they described as “monotonicity.”
Assumption IAM. (IA Monotonicity) For all z, z 0 ∈ Z either Di (z) ≥ Di (z 0 ) for

all i ∈ I, or Di (z) ≤ Di (z 0 ) for all i ∈ I.

Heckman and Vytlacil (2005, pp. 715-716) observed that Assumption IAM requires
uniformity across individuals, not monotonicity in the instrument. The results ahead
provide further justification of their observation. Nevertheless, to conform with the
existing literature, we still refer to Assumption IAM as “IA monotonicity.” For clarity,
we refer to the usual definition of monotonicity as “actual monotonicity.”
Assumption AM. (Actual Monotonicity) If z 0 ≥ z in the vector sense (componentwise), then Di (z 0 ) ≥ Di (z) for all i ∈ I.

We show ahead that IA monotonicity (Assumption IAM) neither implies nor is implied
by actual monotonicity (Assumption AM).

3.2

A Graphical Characterization of IA Monotonicity

Assumption IAM is a comparison across all individuals for any two values of Zi . To
interpret this condition when Zi is a vector, it is useful to rephrase it as a comparison
across all values of Zi for any two individuals. The equivalent condition is that for any
two individuals j and k, either j must take treatment under all instrument values that
k does, or the opposite. This is the content of the following proposition.5
Proposition 1. For any i ∈ I, define Zi ≡ {z ∈ Z : Di (z) = 1} as the set of all
instrument values for which individual i would take treatment. Assumption IAM holds
if and only if for all j, k ∈ I, either Zj ⊆ Zk , or Zk ⊆ Zj .
5

Proofs for all propositions are contained in Appendix A.

6

Figure 1: Assumption IAM neither implies nor is implied by monotonicity of Di (z) in z
z2

z2

Zk
Zk
zj

Zj

z 00

z0
Zj

z

zk
z1

z1

(a) Sets Zj and Zk are not nested,
so Proposition 1 implies that Assumption
IAM does not hold. For example, compare
zj and zk : Dj (zj ) = 1 > 0 = Dk (zj ), while
Dk (zk ) = 1 > 0 = Dj (zk ). Yet, Di (z) is
monotone in z for both i = j, k.

(b) If I = {j, k}, then Proposition 1 shows
that Assumption IAM would hold. However, neither Dj (z) nor Dk (z) are monotone in z. For example, z ≤ z 0 , and z 0 ≤
z 00 , but Di (z) = Di (z 00 ) = 0 < Di (z 0 ) = 1
for i = j, k.

Proposition 1 shows that Assumption IAM can be interpreted as a “nesting condition”
among the sets of instrument values that induce different agents to take treatment.6
This means that with two instruments one can gain intuition about the content of
Assumption IAM by drawing sets in R2 .
For example, in Figure 1a, we have drawn two sets Zj and Zk that are not nested.

Proposition 1 says that Assumption IAM fails, which can be verified by comparing the

choices individuals j and k would make at the points marked zj and zk . Yet, for both
individuals j and k, the instrument has a monotonic effect in the sense that Di (z) is
increasing in z. That is, if z 0 ≥ z as a vector (component-wise), then Di (z 0 ) ≥ Di (z).

This shows that Assumption AM does not imply Assumption IAM.

Figure 1b depicts the opposite case, in which Zk ⊆ Zj . If I only consists of

individuals like j and k, then Proposition 1 implies that Assumption IAM is satisfied.
However, the instrument does not have a monotonic effect on treatment choice. For
example, moving from z to z 0 ≥ z moves both individuals’ choices from 0 to 1, but
moving from z 0 to z 00 ≥ z 0 moves their choices back to 0. This shows that Assumption

IAM does not imply monotonicity in the usual sense of Assumption AM.
6

This nesting condition is different than the “equivalent monotonicity condition” used by Vytlacil (2002,
p. 335), although it shares a superficial resemblance. Vytlacil (2002, p. 336) used the sets Zi for his proof
of the existence of an equivalent threshold-crossing model.

7

z2 (proximity)

z2 (proximity)

Figure 2: Assumption IAM requires homogenous choice behavior

(0, 1)

(0, 0)

zk

(1, 1)

(1, 0)

∂Vk (z ? )

{z : Vk (z) = 0}

∂Vj (z ? )
z?
zj

{z : Vj (z) = 0}

{z : Vk (z) = 0}
{z : Vj (z) = 0}

z1 (subsidy)

z1 (subsidy)

(a) Each instrument takes two binary values. Individual j has Zj = {(1, 0), (1, 1)}
and individual k has Zk = {(0, 1), (1, 1)}.
Points (1, 0) and (0, 1) violate the nesting
condition in Proposition 1.

(b)
An illustration of Proposition 2.
When (3) fails to hold for two individuals j, k ∈ I, one can find points zj and
zk which violate the nesting condition in
Proposition 1 by taking small steps in the
directions of the dotted arrows.

3.3

Implications for Heterogeneity in Choice Behavior

In this section, we examine the restrictions that Assumption IAM places on choice
behavior. To do this, we use a random utility model. Assume that individual i’s
indirect utility from choosing d when the instrument is z is given by Vi (d, z). The
individual chooses Di (z) = 1 if and only if Vi (1, z) ≥ Vi (0, z):

1, if Vi (z) ≥ 0
Di (z) = arg max Vi (d, z) ≡
,
0, if V (z) < 0
d∈{0,1}
i

(1)

where Vi (z) ≡ Vi (1, z) − Vi (0, z) and ties are resolved in favor of treatment.

For concreteness, consider the familiar setting of the returns to schooling in which

Di (z) represents a binary decision to attend college. Suppose that z = (z1 , z2 ), where
z1 is a tuition subsidy, and z2 is proximity to a college (e.g. Kane and Rouse, 1993;
Card, 1995). Larger values of either instrument encourage college attendance, so that
Di (z) is a monotonic function of z and Assumption AM is satisfied. As observed in
the previous section, this neither implies nor is implied by Assumption IAM. In Figure
2, we draw two possible indifference curves along which individuals j and k would be
on the margin between attending and not attending college.

8

Suppose that z only takes the values {(0, 0), (0, 1), (1, 0), (1, 1)} shown in Figure 2a.

Then individual j would attend college if and only if they received a tuition subsidy,

regardless of whether they lived in close proximity. Individual k would attend college if
and only if they lived in close proximity, regardless of whether they received a tuition
subsidy. That is, (1, 0) is in Zj but not Zk , and (0, 1) is in Zk but not Zj , so that

Assumption IAM fails. Thus, Assumption IAM does not permit individuals to differ in
their responses to different incentives to attend college: all individuals must find either
a tuition subsidy or distance to be more compelling. This suggests a strong form of
preference homogeneity.
We can sharpen this statement when the instrument is continuous and the net
indirect utility function is differentiable. This is shown in the next proposition, which
is illustrated in Figure 2b.
Proposition 2. Suppose that Di (z) is determined by (1). Let z ? be a point in the
interior of Z, and let I(z ? ) ≡ {i ∈ I : Vi (z ? ) = 0} denote the set of individuals

who are indifferent between treatment and non-treatment when faced with z ? . Suppose
further that Vi (z) is a continuously differentiable function of z in a neighborhood of z ?
for all i ∈ I. Then Assumption IAM implies that
∂1 Vj (z ? )∂2 Vk (z ? ) = ∂1 Vk (z ? )∂2 Vj (z ? )
for all j, k ∈ I(z ? ), where ∂` Vi (z) ≡

∂
∂z` Vi (z)

(2)

for ` = 1, 2.

Proposition 2 says that if Assumption IAM holds, then any two individuals who are
indifferent between treatment and non-treatment at z ? must have the same marginal
rate of substitution between the two components of the instrument. That is, assuming
that the second component has an impact at z ? (so that ∂2 Vi (z ? ) 6= 0), Assumption
IAM implies

∂1 Vj (z ? )
∂1 Vk (z ? )
=
∂2 Vj (z ? )
∂2 Vk (z ? )

(3)

for all individuals j and k who are indifferent at z ? . This is a strong statement about
preference homogeneity.
For example, suppose that individual i’s net utility from attending college is given
by the random coefficients specification
Vi (z) = Bi,0 + Bi,1 z1 + z2

so that

Di (z) = 1[Bi,0 + Bi,1 z1 + z2 ≥ 0],

(4)

where Bi,1 ≥ 0 controls variation in the taste for subsidies relative to proximity. Propo-

9

sition 2 shows that Assumption IAM does not hold if Bi,1 varies with i.7 Thus, the
college attendance decision of every individual is either affected more by tuition subsidies (if b1 ≡ Bi,1 ≥ 1), or by proximity (if b1 < 1), and all individuals trade off these
incentives at the same rate. Assumption IAM does not permit heterogeneity in these
behavioral responses.

3.4

Partial Monotonicity

Assumption IAM creates unattractive implications for choice behavior because it requires cross-instrument comparisons, such as the comparison between (0, 1) and (1, 0)
in Figure 2a. We can eliminate these comparisons by considering a condition that compares only values of a single component of the instrument, holding all other components
fixed. To state such a condition, we divide vectors z ∈ Z into their `th component,

z` , and all other (L − 1) components, z−` . We write z = (z` , z−` ) to emphasize the

separation of the `th component.

Consider the following assumption:8
Assumption PM. (Partial Monotonicity) Take any ` = 1, . . . , L, and let (z` , z−` )
and (z`0 , z−` ) be two points in Z. Then either Di (z` , z−` ) ≥ Di (z`0 , z−` ) for all i ∈ I, or
Di (z` , z−` ) ≤ Di (z`0 , z−` ) for all i ∈ I.

Assumption IAM clearly implies Assumption PM. When L = 1, Assumption PM is
equivalent to Assumption IAM; when L > 1, it is strictly weaker. To see this, recall
Figure 2a, where we determined that Assumption IAM fails. Holding z2 = 0 fixed,
both individuals j and k are weakly induced to treatment by switching z1 from 0 to
1. The same is true when the roles of z1 and z2 are swapped. If I consisted of only

individuals like j and k, then Assumption PM would be satisfied.

Figure 2 suggests that a simple sufficient condition for Assumption PM is monotonicity in the usual sense of Assumption AM. This is the content of the following
proposition.
Proposition 3. Assumption AM implies Assumption PM.
Unlike Assumption IAM, Assumption AM can be easily satisfied in random utility
models with heterogeneous preferences. For example, if Vi (z) follows the random coefficients specification (4), then it will be satisfied if Bi,1 is positive for all i. This is
7

Heckman et al. (2006, p. 399) note that Assumption IAM can fail in random coefficient specifications
like (4). Our analysis shows that it must fail when the instruments are continuous.
8
Mountjoy (2019) uses a similar assumption in a setting with multiple unordered treatments.

10

easy to interpret and justify: all individuals are more likely to attend college if tuition is lower, even if they differ in their preferences for tuition relative to proximity.
More generally, Proposition 3 shows that Assumption PM is satisfied whenever Vi (z)
is weakly increasing in z.9
Our running example of the returns to college was chosen because it is familiar,
not because it favors either Assumption IAM or PM. In Appendix B, we review three
empirical papers from our survey in Section 2. These papers are on diverse topics, but
each one combines multiple economically distinct IVs using 2SLS, and so falls into column (2) (“Case A”) of Table 2. For each paper, we discuss the substantive assumptions
represented by both Assumptions IAM and PM. Our conclusion from that exercise is
consistent with our theoretical results: Assumption IAM is an extremely strong condition with multiple instruments, whereas Assumption PM—while not innocuous—is
much less controversial.
It is important to observe that Assumption AM is sufficient but not necessary for
Assumption PM. For example, consider the influential study by Angrist and Evans
(1998), who used the sex composition of a family’s first two children to instrument
for family size. Let Di indicate whether the family had exactly two or more than two
children. Let Zi,1 and Zi,2 indicate the sexes of their first two children. Angrist and
Evans (1998) present empirical evidence that families for which these two sexes are the
same (Zi = (0, 0) or Zi = (1, 1)) are more likely to have a third child. Suppose that
this is due to a uniform preference ordering in the population, so that for all i ∈ I
Di (0, 0) ≥ Di (0, 1),

Di (0, 0) ≥ Di (1, 0),

and Di (1, 1) ≥ Di (0, 1),

Di (1, 1) ≥ Di (1, 0).

(5)

This is consistent with Assumption PM, but it violates Assumption AM.
Another way to see the difference between Assumptions AM and PM is to consider
the interacted random coefficient specification
Vi (z) = Bi,0 + Bi,1 z1 + z2 + Bi,2 z1 z2 ,

(6)

where we suppose for simplicity that Z = {0, 1}2 . If all individuals i ∈ I have Bi,1 ≥ 0,

Bi,2 ≤ −1, but Bi,1 ≤ −Bi,2 , then Assumption AM fails while Assumption PM is
satisfied. The reason is due to the strong negative interaction effect (submodularity)
9

More generally still, Theorem 4 of Milgrom and Shannon (1994) implies that Assumption PM will be
satisfied if Vi (d, z) has the single-crossing property in (d; z). The single-crossing property is ordinal, and is
strictly weaker than monotonicity in the usual sense.

11

between z1 and z2 on indirect net utility, which is controlled here by Bi,2 . This implies
that Di (z1 , z2 ) is increasing as a function of z1 when z2 = 0, but decreasing when z2 = 1,
and similarly when the roles of z1 and z2 are reversed. This violates Assumption AM,
even though Assumption PM is satisfied.10

4

Interpreting 2SLS Under Partial Monotonicity

Imbens and Angrist (1994, Theorem 2) showed that under standard instrument exogeneity and relevance conditions, Assumption IAM ensures that the 2SLS estimand
can be written as a weighted average of causal effects for complier subpopulations. The
weights are convex in that they are non-negative and sum to one. Their result holds
regardless of the number of instruments, as long as the first stage for the 2SLS estimand is fully saturated. However, it crucially depends on Assumption IAM, which we
have shown requires a strong form of preference homogeneity with two or more distinct
instruments. In this section, we show that the Imbens and Angrist (1994) result can
be partially salvaged under Assumption PM.

4.1

Potential Outcomes and Exogeneity Condition

To define the 2SLS estimand, we need to introduce an outcome variable, Yi . We write
potential outcomes for Yi as Yi (1) and Yi (0) to correspond to setting Di to treatment
(Di = 1) and non-treatment states (Di = 0). The notation incorporates the usual
exclusion restriction that Zi has no direct causal effect on Yi . The observed outcome
is Yi = Di Yi (1) + (1 − Di )Yi (0) = Yi (Di ). The observed treatment state is related to
the potential treatment states analyzed in the previous section as
Di =

X

1[Zi = z]Di (z) = Di (Zi ).

z∈Z

Throughout the paper, we maintain the following exogeneity condition:
Assumption E. (Exogeneity) (Yi (0), Yi (1), {Di (z)}z∈Z ) ⊥
⊥ Zi .
Assumption E is common in nonparametric IV models, and identical to Condition
1 of Imbens and Angrist (1994). For simplicity, we state the condition in terms of
full independence, although our analysis of the 2SLS estimand only involves mean
outcomes, so only requires a weaker form of Assumption E.11
10

To see that the above configuration satisfies Assumption PM, note that Bi,1 ≥ 0 implies that Di (0, 0) ≤
Di (1, 0), Bi,1 ≤ −Bi,2 implies that Di (0, 1) ≥ Di (1, 1), Di (0, 0) ≤ Di (0, 1) by virtue of the normalized
coefficient on z2 , and Bi,2 ≤ −1 implies that Di (1, 0) ≥ Di (1, 1).
11
The weaker form still requires that {Di (z)}z∈Z ⊥
⊥ Zi , but relaxes full joint independence to the restriction

12

Table 3: Groups under Assumption PM with (7)

Gi (group g)
Always-taker (at)
Eager complier (ec)
Reluctant complier (rc)
Never-taker (nt)
Z1 complier (1c)
Z2 complier (2c)

z1
z2
Di (0, 0) Di (0, 1)
1
0
0
0
0
0

z3
z4
Di (1, 0) Di (1, 1)

1
1
0
0
0
1

1
1
0
0
1
0

1
1
1
0
1
1

Cg

∅
{2}
{4}
∅
{3}
{2, 4}

Dg

∅
∅
∅
∅
∅
{3}

The sets Cg and Dg are integers k for which group type g acts as a complier or defier when considering the contrast z k−1 to z k . This notation is explained in more detail in Section 4.4.

4.2

Two Binary Instruments

We first consider the case in which Zi = (Zi,1 , Zi,2 ) consists of two binary instruments
Zi,1 ∈ {0, 1} and Zi,2 ∈ {0, 1}, with support Z = {0, 1}2 . We also assume that the
direction of Assumption PM is known a priori to be

Di (0, 0) ≤ Di (0, 1) ≤ Di (1, 1),
and Di (0, 0) ≤ Di (1, 0) ≤ Di (1, 1).

(7)

This particular ordering is not required, but it helps with the notation and exposition
to not have to consider multiple different orderings simultaneously; our more general
results in Section 4.4 relax this condition.12 The following proposition establishes that
under these conditions the population I can be partitioned into six mutually exclusive
and exhaustive groups.

Proposition 4. If Z = {0, 1}2 and Assumption PM is satisfied with the order shown
in (7), then each i ∈ I belongs to exactly one of the six groups in Table 3.

The terminology in Table 3 modifies that of Angrist, Imbens, and Rubin (1996).
Always- and never- takers exhibit the same behavior regardless of either instrument.
Z1 compliers take treatment if and only if Zi,1 is switched on, while Z2 compliers take
treatment if and only if Zi,2 is switched on. Eager compliers participate in treatment
if either instrument is on, and reluctant compliers only participate if both instruments
that E[Yi (d)|{Di (z)}z∈Z , Zi = z 0 ] not depend on z 0 for both d = 0 and d = 1.
12
Also, note that the direction of the comparisons are still identified under Assumption PM, just as they
are under Assumption IAM, since Assumption E implies that P[Di (z) = 1] = P[Di |Zi = z].

13

Figure 3: Correspondence between random coefficients and behavioral types
Bi,1
2

1

0
−2

−1

0

Always-takers
Z1 compliers
Reluctant compliers

Bi,0

Eager compliers
Z2 compliers
Never-takers

These regions show how random coefficient realizations relate to behavioral types if treatment were
determined by the binary choice model (4) with Bi,1 ≥ 0. For example, a Z2 complier has Di (0, 0) =
0, Di (1, 0) = 0, Di (0, 1) = 1, and Di (1, 1) = 1. The first three choices imply that Bi,0 < 0,
Bi,0 + Bi,1 < 0, and Bi,0 + 1 > 0, with the fourth choice implied by the third. The region of such
(Bi,0 , Bi,1 ) realizations is shown in cross-hatches.
are on. For any of the six groups, an increase in either instrument weakly increases
treatment, which implies that Assumption AM also holds in this case. Assumption IAM
will be violated if the population includes both Z1 and Z2 compliers, since in this case
a change in Zi from (0, 1) to (1, 0) would induce Z1 compliers to enter treatment and
Z2 compliers to exit treatment. Figure 3 shows how realizations of random coefficients
would map into these six group types if potential treatment states were generated by
(4).
As in Imbens and Angrist (1994, Theorem 2), we consider the 2SLS estimand with
a saturated first stage, and a second stage with Di and a constant. That is, the 2SLS
estimand is formed by using 1 (a constant), Zi,1 , Zi,2 , and Zi,1 Zi,2 as instruments for
1 and Di . Since the first stage is saturated, this 2SLS procedure generates the same
coefficient estimate on Di as the IV estimator that uses the propensity score p(Zi ) ≡
P[Di = 1|Zi ] as the sole instrument for Di . Let β2sls = Cov(Yi , p(Zi ))/ Cov(Di , p(Zi ))

denote this coefficient. Let Gi ∈ {at, nt, 1c, 2c, ec, rc} denote individual i’s group among
the six shown in Table 3, and define πg ≡ P[Gi = g] and ∆g ≡ E[Yi (1) − Yi (0)|Gi = g]

14

to be the population shares and average treatment effects for each group. The following
proposition establishes the relationship between these quantities and β2sls .
Proposition 5. Suppose Zi has support Z ≡ {0, 1}2 and that Assumption PM is

satisfied with the ordering in (7). Suppose in addition that Assumption E is satisfied,
and that β2sls exists. Then
β2sls =

X

ωg ∆ g ,

g∈{1c,2c,ec,rc}

where the ωg are weights that sum to 1. Both ωec and ωrc are always non-negative. If
π1c ≥ π2c , then ω1c is also non-negative, while the sign of ω2c is given by


sgn(ω2c ) = 1[π2c > 0] × sgn P[Di = 1|Zi,2 = 1] − P[Di = 1|Zi,2 = 0] .
If π2c ≥ π1c , then ω2c is non-negative, and the sign of ω1c is given by


sgn(ω1c ) = 1[π1c > 0] × sgn P[Di = 1|Zi,1 = 1] − P[Di = 1|Zi,1 = 0] .
Proposition 5 shows that the 2SLS estimand is a linear combination of average
treatment effects for the four groups that change treatment status in response to one
or both of the instruments. The groups are non-overlapping, and the weights on the
groups (ωg ) sum to unity.13 This implies that β2sls = ∆ ≡ ∆g in the unlikely situation
that there are constant treatment effects across behavioral groups. In general, however,
the 2SLS estimand might not be a positively-weighted average of treatment effects for
the four groups, because some of the weights might be negative. The weights for
reluctant compliers and eager compliers are always non-negative. If π1c ≥ π2c , the

weight given to the Z1 compliers is also non-negative, but the weight given to the Z2
compliers can be either positive or negative.

The intuition is that a shift of Zi from (0, 1) to (1, 0) induces Z1 compliers to enter
treatment and Z2 compliers to exit treatment. If π1c ≥ π2c , then the net effect of
this shift is still more participation in treatment. However, the Z2 compliers act as

“defiers,” and therefore receive negative weight for this binary contrast. Whether the
overall weight given to the Z2 compliers is positive or negative depends on whether
this negative weight is outweighed by the positive weight given to the Z2 compliers
in the two other instrument contrasts for which they enter treatment: Zi = (0, 0) to
Zi = (0, 1), and Zi = (1, 0) to Zi = (1, 1). If instead π2c ≥ π1c , then the roles of the
Z1 and Z2 compliers are reversed.

13

Formulas for ωg are given in the proof.

15

4.3 When is the 2SLS Estimand a Positively-Weighted Average of
Compliers?
Proposition 5 shows that one can check whether the 2SLS estimand is a positivelyweighted average of causal effects by examining observable relationships between treatment and instruments. Specifically, if both Z1 and Z2 compliers are present in the
population and π1c ≥ π2c , then ω2c will be negative if and only if the coefficient on

Zi,2 in a regression of Di on Zi,2 (and a constant) is negative. Likewise, if π2c ≥ π1c ,

then ω1c will be negative if and only if the coefficient on Zi,1 in a regression of Di on
Zi,1 (and a constant) is negative. One can either check both cases, or check only the
relevant case, which is identified by the sign of p(1, 0) − p(0, 1) = π1c − π2c .

It is important to note that except for πat and πnt , the group shares are not them-

selves separately identified. This is because there are five linearly independent group
shares (after accounting for the fact that they sum to unity), but only four values of
the propensity score. As mentioned, the sign of p(1, 0) − p(0, 1) indicates whether Z1 or
Z2 compliers are more common. However, it is not possible to determine whether the

less common group is entirely absent. If it were the case that π1c = 0 or π2c = 0, then
Assumption IAM would hold and the 2SLS estimand would necessarily be a positivelyweighted average of the remaining three complier groups.
Finding negative weights based on the formulas in Proposition 5 represents a situation in which the unconditional relationship between an instrument and the treatment
has a different sign than the ceteris paribus impact of the instrument. This may be
rare in practice, since researchers often have prior beliefs regarding the impacts of the
instruments (e.g. if each instrument is an encouragement to take treatment), and a
researcher may be unlikely to use an instrument if the raw correlation with the treatment contradicts the expected sign. A necessary condition for such a contradiction is
that the instruments are negatively correlated.
Proposition 6. Suppose Zi consists of two binary instruments that satisfy Assumption
PM with the ordering in (7), that Assumption E is satisfied, and that β2sls exists. If
Cov(Zi,1 , Zi,2 ) ≥ 0, then both ω1c and ω2c are non-negative.
An important special case of Proposition 6 is when the instruments are independent,
so that Cov(Zi1 , Zi,2 ) = 0 and the 2SLS weights are guaranteed to be positive. The
leading scenario in which the instruments would be negatively correlated is when Zi,j =
1 tends to imply Zi,k = 0 for j 6= k. For example, Zi,1 and Zi,2 may indicate two
different arms in an experiment corresponding to different types of encouragement

to take the treatment. In this setting, Cov(Zi,1 , Zi,2 ) < 0 and negative weights are
possible.

16

In Appendix C, we use the full sufficient and necessary characterization in Proposition 5 to develop formal statistical tests about the signs of the weights. We consider
four tests of the null hypothesis that the weights are positive. In a small simulation
study, we find that the test based on the procedure of Romano, Shaikh, and Wolf (2014)
performs the best, with size only slightly below its nominal level. We also consider a
test of the null hypothesis that at least one weight is negative. All five tests can be
implemented using the mivcausal Stata package.

4.4

Multivalued Instruments

Suppose that Zi consists of two or more distinct, discrete instruments, and that its
support has K elements total. Label these elements as supp(Zi ) ≡ {z 1 , . . . , z K } in

increasing order of the propensity score, so that p(z k ) ≥ p(z k−1 ) for all k ≥ 2. In the
case considered in Section 4.2, K = 4 and the instrument values would be ordered as

z 1 = (0, 0), z 2 = (0, 1), z 3 = (1, 0), and z 4 = (1, 1) if p(1, 0) ≥ p(0, 1), with the roles of

z 2 and z 3 switched in the opposite case.

Let G represent the set of all realizations of {Di (z)}z∈Z that are consistent with

Assumption PM and the observed values of p(z). In Section 4.2, where there were two
binary instruments with the ordering (7), G was composed of the six groups in Table 3.
Table 4 displays another example consistent with the ordering (5) in which there are

seven groups. As before, let Gi denote individual i’s group membership, let πg denote
the proportion of the population in each group g, and let ∆g denote group g’s average
treatment effect.
For each g ∈ G, define the set:
Cg = {k ∈ {2, . . . , K} : Di (z k ) = 1 and Di (z k−1 ) = 0 for all i with Gi = g}.
This is the set of instrument values k at which individuals in group g are compliers in
the sense that they would not take treatment if Zi = z k−1 , but would take treatment
if Zi = z k . Similarly, define
Dg = {k ∈ {2, . . . , K} : Di (z k ) = 0 and Di (z k−1 ) = 1 for all i with Gi = g}
as the set of instrument values at which individuals in group g act as defiers. For
example, in Section 4.2, we had C1c = {3}, D1c = ∅, C2c = {2, 4}, and D2c = {3}. We

also had Cec = {1}, Crc = {4}, Cat = Cnt = ∅, and Dg = ∅ for each g ∈ {at, nt, ec, rc};
recall Table 3. Table 4 reports the sets Cg and Dg , for an alternative case consistent
with (5).

17

Table 4: Groups under Assumption PM with (5)

z1
Gi (group g) Di (1, 0)
Always-taker (at)
Group 2
Group 3
Group 4
Group 5
Group 6
Never-taker (nt)

z2
z3
Di (0, 1) Di (1, 1)

1
0
1
0
0
0
0

1
1
0
0
0
0
0

z4
Di (0, 0)

1
1
1
1
0
1
0

1
1
1
1
1
0
0

Cg

∅
{2}
{3}
{3}
{4}
{3}
∅

Dg

∅
∅
{2}
∅
∅
{4}
∅

As before, consider the same 2SLS specification used by Imbens and Angrist (1994,
Theorem 2) with a saturated first stage, and a second stage that contains Di and a
constant. Let β2sls denote the 2SLS estimand corresponding to the coefficient on Di .
The following proposition provides an interpretation of the 2SLS estimand.
Proposition 7. Suppose Zi takes K values {z 1 , . . . , z K } labeled so that the propensity

score is increasing and suppose that the support of Zi is rectangular, that is supp(Zi ) =
supp(Zi,1 )×· · ·×supp(Zi,L ). If Assumptions PM and E are satisfied, and if β2sls exists,

then

β2sls =

X

ωg ∆ g ,

g∈G:Cg 6=∅

where ωg are weights such that
sgn(ωg ) = 1[πg > 0] × sgn

P

K
X
k=2

g∈G:Cg 6=∅ ωg

= 1, and

!

(1[k ∈ Cg ] − 1[k ∈ Dg ]) Cov Di , 1[p(Zi ) ≥ p(z )]
.


k

Proposition 7 shows that under Assumption PM, the 2SLS estimator produces a
weighted average of treatment effects for groups that comply with some instrument
change. The weights on each group could be positive or negative, but this can be
checked empirically. To do this, one must generate the sets Cg and Dg by applying
Assumption PM to the set of K instrument values and the observed ordering of the

propensity score, as we did in the examples in Tables 3 and 4. The sign of the weight
for group g is then determined by the overall sum of Cov(Di , 1[p(Zi ) ≥ p(z k )]) for

instrument values k at which they comply less the sum of these terms at values k for
which they defy.

18

The additional rectangular support condition in Proposition 7 is necessary to ensure
that the contrasts picked up in β2sls are restricted by Assumption PM. For example, if
in the special case in Section 4.2 the support of Zi were only {(0, 1), (1, 0)}, then either

the Z1 compliers or Z2 compliers would always have negative weight. This is intuitive
since Assumption PM does not place any direct restrictions on behavior in the contrast
between (0, 1) and (1, 0).

4.5

Using Each Instrument Separately

A natural alternative to combining two or more instruments through 2SLS is to use each
instrument separately. This may be unattractive due to a loss of statistical precision.
However, it is justified under Assumption PM with the important caveat that all of the
other instruments generally must be conditioned on as control variables in both the first
and the second stage of the 2SLS estimator.14 This is necessary because Assumption
E is stronger than the exogeneity condition in the traditional constant effects linear
IV model. Whereas the traditional condition only requires Zi to be exogenous with
respect to the outcome process, Assumption E also requires Zi to be independent of
{Di (z)}z∈Z , and thus exogenous with respect to potential treatments as well.

To see why conditioning is necessary, consider again the case with two binary in-

struments. In the heterogeneous effects framework, using the first instrument by itself
requires considering marginal potential treatment states with respect to Zi,1 . These
are related to the joint potential treatment states by
Di,1 (z1 ) ≡ (1 − Zi,2 )Di (z1 , 0) + Zi,2 Di (z1 , 1).

(8)

To apply the Imbens and Angrist (1994) LATE interpretation using only Zi,1 as the
instrument would require that Zi,1 is independent of (Di,1 (0), Di,1 (1)). We can see from
(8) that this is unlikely to hold outside of the case where Zi,1 and Zi,2 are themselves
independent. However, Assumption E does imply that Zi,1 and (Di,1 (0), Di,1 (1)) will be
independent conditional on Zi,2 . Similarly, Assumption PM implies that Assumption
IAM holds for the marginal potential treatments conditional on Zi,2 . See Mogstad,
Torgovitsky, and Walters (2020) for a complete development of these ideas.
In Table 5, we report on the ways that researchers use multiple instruments separately using the same sample of papers from Section 2. Of the 65 papers in column (2)
of Table 1 that used multiple IVs for the same treatment variable, we found 20 that fit
a separate 2SLS model using a single IV for at least one specification reported in the
main body of the paper. Column (2) of Table 5 restricts these papers to those that do
14

This has been noted elsewhere, e.g. Carneiro et al. (2011, footnote 6).

19

Table 5: Multiple IV papers that use IVs separately

(1)

(2)

Papers that ever Papers that do
use IVs separately not control for
omitted IVs

(3)
Papers that always
use IVs separately
and never control
for omitted IVs

American Economic Review

7

6

2

Quarterly Journal of Economics

5

5

4

Journal of Political Economy

6

5

2

Econometrica

1

1

0

Review of Economic Studies

1

1

1

All

20

18

9

This table includes the subset of the papers from column (2), Table 1 that fit a separate 2SLS model
using a single IV in at least one specification in the main body of the paper.
not condition on the other omitted IVs when fitting such a model, while column (3)
further restricts column (2) to papers that never used all IVs together in any specification. As shown in column (2), 90% of the papers that use multiple IVs separately
do not control for the omitted instruments. Unless the multiple IVs are independent,
these papers are reporting an estimated quantity that likely does not have a causal
interpretation.

5

Estimating the Returns to College

We illustrate the results of the previous sections by estimating the returns to college
attendance.

5.1

Sample and Instruments

Carneiro, Heckman, and Vytlacil (2011, “CHV”) used multiple IVs to estimate the
returns to college in a sample of white men from the National Longitudinal Survey
of Youth 1979 Cohort. We use their sample and focus on the two instruments that
are the strongest predictors of college attendance: average log earnings in a youth’s
county of residence at age 17, and the presence of a four-year college in a youth’s

20

Table 6: Summary statistics

Average log wage, 1989-1993

Mean
(1)
2.378

Standard
deviation
(2)
0.499

Attended college

0.495

0.500

Corrected AFQT score

0.449

0.952

Mother's years of schooling

12.102

2.335

Number of siblings

2.927

1.909

Urban residence at age 14

0.744

0.436

1959.759

2.340

Permanent local log earnings

10.283

0.188

Local log earnings in 1991

10.293

0.165

Low local earnings at age 17

0.250

0.433

Nearby four-year college at age 14

0.525

0.500

Year of birth

Sample size

1747

Notes: This table reports means and standard deviations of key variables
for white men in the National Longitudinal Survey of Youth 1979
sample. Column (1) displays mean characteristics, and column (2) shows
standard deviations. AFQT score is corrected for differences in years of
schooling at the time individuals took the test. Permanent local log
earnings equals average log earnings from 1973 to 2000 for an
individual's county of residence at age 17. Low local earnings at age 17 is
an indicator equal to one if the residual from a regression of average log
earnings for an individual's county at age 17 on the other covariates falls
below the 25th percentile in the sample.

county of residence at age 14.15 For these two instruments, Assumption PM holds if
all individuals view college as more attractive when local labor market opportunities
are weaker and when a college is nearby. This seems plausible, since higher opportunity
costs and longer distances are likely undesirable for everyone. In contrast, Assumption
IAM requires all individuals to place the same relative weight on these economically
distinct types of incentives.

15

These two instruments were also used in several earlier studies of the returns to education e.g. Card
(1995) Cameron and Heckman (1998) Kling (2001), and Cameron and Taber (2004).

21

Table 7: OLS and 2SLS estimates of the returns to college
2SLS
OLS

Second stage excluding:

Controls
(2)
0.042
(0.006)

No interaction
(3)

Interaction
(4)

Low local earnings at 17

0.103
(0.033)

0.104
(0.022)

0.124
(0.033)

Nearby four-year college at 14

0.000
(0.027)

0.061
(0.023)

0.069
(0.025)

Low local earnings*Nearby college

-0.067
(0.046)

Corrected AFQT score

0.096
(0.014)

0.232
(0.011)

0.232
(0.011)

-0.049
(0.062)

0.157
(0.094)

0.008
(0.047)

Mother's years of schooling

0.013
(0.005)

0.030
(0.004)

0.030
(0.004)

-0.006
(0.010)

0.021
(0.014)

0.001
(0.008)

Number of siblings

-0.005
(0.005)

-0.018
(0.005)

-0.018
(0.005)

0.006
(0.008)

-0.010
(0.009)

0.002
(0.007)

Urban residence at 14

0.020
(0.024)

0.031
(0.024)

0.032
(0.024)

-0.001
(0.029)

0.027
(0.028)

0.002
(0.027)

Permanent local log earnings

0.073
(0.073)

-0.081
(0.067)

-0.083
(0.067)

0.127
(0.088)

0.056
(0.068)

0.060
(0.070)

Local log earnings in 1991

0.727
(0.078)

0.224
(0.069)

0.228
(0.069)

0.581
(0.104)
21.970

0.780
(0.115)
7.182

0.641
(0.090)
15.451
0.080

1747

1747

1747

1747

1747

1747

College attendance (return per year)

No controls
(1)
0.085
(0.006)

First stage

22
1747

Nearby college
(6)
-0.024
(0.100)

Both
(7)
0.137
(0.049)

0.092
(0.051)
-0.054
(0.033)

-0.036
(0.045)

First stage F -statistic for excluded instruments
P -value: overidentification test
Sample size

Local earnings
(5)
0.198
(0.065)

Notes: This table reports ordinary least squares (OLS) and two-stage least squares (2SLS) estimates of the effects of college attendance on log wages for white men in the NLSY
1979. Columns (1) and (2) show coefficients from OLS regressions of log hourly wages on college attendance. Columns (3)-(7) display coefficients from two-stage least squares
models instrumenting college attendance with low earnings in an individual's county at 17 and the presence of a four-year public college in an individual's county at 14. Columns
(3) and (4) show first stage specifications with and without the interaction of the two instruments. Column (5) displays the estimated second stage using the low local earnings
variable as the excluded instrument, column (6) shows the second stage using the nearby college variable as the excluded instrument, and column (7) displays the second stage
excluding both instruments. The second stage estimates are based on the additively separable first stage in column (3). Columns (2)-(7) also control for cohort indicators. Returns to
college are expressed annually by dividing the college coefficient by 4. Robust standard errors in parentheses.

Table 6 reports descriptive statistics for key variables in the CHV sample. The
outcome variable Yi is the log of individual i’s average hourly wage from 1989 to 1993,
and the treatment Di equals one for individuals that attended college. Throughout our
analysis we control for a vector Xi of covariates that includes AFQT scores, mother’s
years of education, number of siblings, urban residence at age 14, year of birth indicators, permanent local earnings (defined as average log earnings in the age 17 county
of residence from 1973 to 2000), and average log earnings in the county of residence
in 1991.16 The latter two variables account for general differences in earnings across
counties, so that conditional on Xi the local earnings instrument can be interpreted as
capturing idiosyncratic fluctuations in local labor market opportunities at the time of
the college enrollment decision.
The bottom rows of Table 6 display descriptive statistics for the two instruments.
To parallel the discussion of Section 4.2 we create a binary version of the local earnings
instrument, labeled Zi,1 , which equals one if the residual from a regression of local
earnings on Xi is in the bottom quartile of the sample.17 By construction, this definition
means that 25% of youths experienced low local earnings at age 17. Fifty-three percent
of individuals lived near a four-year college at age 14, which we label with a binary
indicator, Zi,2 .

5.2

2SLS Estimates

We begin by reporting ordinary least squares (OLS) and 2SLS estimates of the returns
to college. Following CHV, we divide all college coefficients by four to express returns
on an annual basis. Column (1) of Table 7 displays the coefficient from a bivariate
OLS regression of log wages on college attendance, which gives an annual return of
9%. Column 2 shows that controlling for the covariates and instruments reduces the
college premium to 4% per year.
An extensive literature argues that OLS estimates of the returns to schooling may
be biased by unobserved differences in ability (e.g., Card 2001). Motivated by this
16

We follow CHV and use a version of AFQT that corrects for differences in years of schooling at the time
of the test. CHV also include labor market experience as an additional control variable in the second stage
of their estimation procedure. Because experience may partially mediate the effects of college enrollment
we instead control for age (captured by the year of birth indicators) and interpret the effects of college
attendance inclusive of any impacts on experience.
17
In results not reported here, we found that other thresholds for discretizing the local earnings instrument
yielded similar results but were less predictive of college attendance.

23

concern, columns 3-7 of Table 7 report 2SLS estimates of the system:
Di = ψ + Π1 Zi,1 + Π2 Zi,2 + Xi0 δ + ηi ,
Yi = α + βDi + Xi0 γ + i .

(9)
(10)

We compare 2SLS estimates from models excluding the instruments from the second
stage one at a time, adding the other to the set of controls Xi in equation (10) as in
Section 4.5, as well as a model that excludes both instruments from the second stage
simultaneously.
The first stage estimates show that both instruments boost college attendance.
Column (3) of Table 7 reports OLS estimates of equation (9), and column (4) shows
estimates from a saturated specification that adds an interaction between the two
instruments. The interaction term is small and statistically insignificant, and its value
implies that the partial effect of each instrument is always positive, indicating that the
ordering of the propensity score is consistent with (7) from our discussion of two binary
instruments in Section 4.2. In view of the insignificant interaction term, we maintain
the more parsimonious additively separable model from column (3) going forward.
This specification shows that youths experiencing low local earnings at age 17 are
10 percentage points more likely to attend college conditional on the controls, and this
estimate is highly statistically significant. In the framework of Section 4.2, this implies
that 10% of the population complies with Zi,1 , including eager compliers, reluctant
compliers, and Z1 compliers. Youths that live near a four-year college at age 14 are
6 percentage points more likely to attend college, an estimate that is also statistically
significant. The larger first stage for the local earnings instrument implies that the
share of Z1 compliers exceeds the share of Z2 compliers (π1c > π2c ). However, the
levels of these shares are not identified, so we have no empirical basis for assuming
that π2c = 0.
Columns (5) and (6) of Table 7 reveal that the two instruments generate very
different estimates of the returns to college. Treating the low local earnings variable as
the excluded instrument yields a positive and significant 2SLS estimate of 19.8% per
year, while excluding the nearby college variable produces an insignificant estimated
return of negative 2.4%. These two estimates are outside the typical range of such
estimates (usually around 10%; see Card 1999), but both estimates are also statistically
imprecise.
As can be seen in column (7), excluding both instruments from the second stage
yields a more reasonable and precisely estimated return of 13.7% per year. At the
same time, the standard rationale for this procedure relies on the strong restrictions on

24

choice behavior underlying Assumption IAM. Moreover, the overidentification test for
the combined model is rejected at marginal significance levels (p = 0.08), suggesting
heterogeneity in returns across subpopulations affected by each instrument. This raises
the possibility that violations of Assumption IAM could contaminate the combined
2SLS estimates.

5.3

Assessing IA Monotonicity

We explore violations of Assumption IAM by comparing estimates of marginal treatment effects (MTEs) for the two instruments (Heckman and Vytlacil, 1999, 2005, 2007).
The MTEs are based on the model
Di (z) = 1[p(z, Xi ) ≥ Ui ],

(11)

(Yi (1), Yi (0), Ui ) ⊥
⊥ Zi |Xi ,

(12)

where Ui is distributed uniformly, conditional on Xi and Zi . Vytlacil (2002) showed
that the model defined by (11) and (12) is equivalent to the framework of Imbens
and Angrist (1994). In particular, the separable threshold-crossing representation of
potential treatment choices in equation (11) is equivalent to Assumption IAM, with
the homogeneous ordering of preferences over the instruments represented by the onedimensional unobservable Ui .
Heckman and Vytlacil (2005) define the MTE as the average treatment effect at a
percentile of the unobserved cost Ui and value of the covariates Xi , that is,
MTE(u, x) ≡ E [Yi (1) − Yi (0)|Ui = u, Xi = x] .
They show that if there is continuous variation in the probability of treatment, then
the MTEs are identified by derivatives of the average outcomes with respect to the
propensity score: MTE(u, x) = ∂ E [Yi |p(Zi , Xi ) = u, Xi = x] /∂u. A core implication

of Assumption IAM (or the equivalent (11)) is that the MTE schedule is invariant to
which instrument is used to calculate these derivatives. In contrast, Assumption PM
allows for the possibility that each instrument is associated with a different unobserved
cost of treatment and its own MTE function (Mogstad et al., 2020). Comparing MTEs
generated by different instruments therefore provides a test of Assumption IAM.18

18

This observation is based on Mogstad et al. (2020), who develop MTE methods for multiple IVs that
enable testing Assumption IAM and aggregating information across instruments under Assumption PM.

25

.2

.4
.6
College utility cost percentile
Local earnings

Nearby college

A. Marginal treatment effects for each instrument

.8

-.4

Marginal treatment effect
-.2
0
.2
-.4

26

Difference in marginal treatment effects
-.2
0
.2
.4

.6

.4

Figure 4: Marginal treatment effects of college attendance based on local earnings and nearby college instruments

.2

.4
.6
College utility cost percentile

.8

B. Difference in marginal treatment effects

Notes: This figure plots estimates of marginal treatment effects (MTEs) of a year of college attendance on log wages using low average log earnings in an individual's county at age 17 (local earnings) and the presence of a
college in an individual's county at age 14 (nearby college) as instruments. Panel A plots separate MTE estimates based on each instrument, and panel B plots the difference in estimated MTEs with 90 percent confidence
intervals based on 1,000 bootstrap replications. MTE estimates are estimated derivatives of the conditional mean log wage with respect to the propensity score evaluated at the mean of the controls. The predicted probability
of college attendance comes from a logit regression of college attendance on the two instruments and controls. The conditional mean of log wages is estimated based on local regressions of log wages on a quadratic function
of the estimated propensity score and controls. Local regressions are evaluated at increments of 0.04 from 0.2 to 0.8 using a triangle kernel and bandwidth of 0.32. The controls in both steps include quadratic functions of
AFQT, mother's education, number of siblings, permanent local earnings, and local earnings in 1991, along with urban status and cohort indicators. AFQT and mother's education are interacted with the instruments in the
logit model and with the linear propensity score term in the outcome regressions. The MTE estimates using a given instrument include the other instrument and its interactions with the linear propensity score term, AFQT,
and mother's education as additional controls.

Since MTEs are not nonparametrically identified when the instruments are discrete, we use parametric models for p(Zi , Xi ) and E [Yi |p(Zi , Xi ), Xi ] to estimate MTE

curves separately for each instrument. This amounts to extrapolating from the LATEs
identified by each instrument to compare treatment effects at a common value of the
propensity score, which must be the same if Assumption IAM holds.19 We estimate
MTEs by first fitting a logit model for p(Zi , Xi ), then running local regressions of Yi
on Xi and a quadratic function of the estimated propensity score, weighted with a
triangle kernel function maximized at the target value of u. We allow for covariate
heterogeneity by interacting the linear propensity score term with elements of Xi . The
MTE estimates are derivatives of the fitted conditional mean function evaluated at the
sample average of the covariates. Paralleling the 2SLS models in columns (4) and (5) of
Table 7, we exclude each instrument separately while including the other as a control
variable, thereby producing separate MTE estimates based on the separate variation in
each instrument. We focus on MTEs for values of u from 0.2 to 0.8 because estimates
at extreme values of u were very imprecise. Inference is conducted based on 1,000
bootstrap replications of the entire procedure.
The results reveal that the two instruments generate different MTE schedules.
Panel A of Figure 4 shows that the local earnings instrument yields a relatively flat
MTE curve, suggesting limited variation in treatment effects as a function of unobserved responsiveness to labor market opportunity costs. In contrast, the MTE curve
for the nearby college instrument is sharply downward sloping, implying substantial
treatment effect heterogeneity along the distance dimension. As a result, MTEs based
on the nearby college instrument tend to be larger at low values of u and smaller at high
values of u compared to those based on the local earnings instrument. The bootstrap
confidence intervals displayed in Panel B show that the differences in MTE schedules
are statistically significant at low and high values of u, and a joint test rejects equality
of the two sets of MTEs at conventional levels (p = 0.046). Subject to the modeling
restrictions required to estimate MTEs with discrete instruments, these results indicate
that Assumption IAM does not hold jointly for the local earnings and nearby college
instruments.

5.4

Implications for Combined 2SLS Estimates

Our results so far suggest that Assumption IAM may be violated for the combination
of instruments considered here. At the same time, estimates based on the individual
19

See Brinch et al. (2017), Mogstad, Santos, and Torgovitsky (2018), Mogstad and Torgovitsky (2018),
and Kline and Walters (2019) for related discussion of extrapolation based on discrete instruments.

27

Table 8: Testing for positive 2SLS weights

Low local earnings at 17

Dependent variable:
College attendance
Nearby college
(1)
(2)
0.119
0.102
(0.024)
(0.024)

Nearby college at 14

0.071
(0.023)

P -value: Positive weights
P -value: Negative weights

1.000
1.000
0.001

Notes: This table displays regressions of the variable listed in each
column on the variable listed in each row in the NLSY sample. All
models control for covariates. Robust standard errors are in parentheses.
The first p -value comes from a test of the null hypothesis that the 2SLS
weights are all positive, and the second comes from a test of the null
hypothesis that at least one weight is negative.

instruments are imprecise, so it may still be useful to combine these instruments via
2SLS. How do violations of Assumption IAM affect the interpretation of the combined
2SLS results in Table 7?
We answer this question by applying Propositions 5 and 6 to the CHV sample.
Table 8 reports coefficients from regressions of Di on each instrument separately along
with the coefficient from a regression of Zi,2 on Zi,1 . These models also control for
Xi . Column (1) demonstrates that controlling for the covariates (but not the other
instrument), the correlation between each instrument and the treatment is positive and
statistically significant. The formulas in Proposition 5 then imply that the weights for
each complier group must be positive under Assumption AM even if both Z1 and Z2
compliers are present. Similarly, column (2) shows that the partial correlation between
the two instruments is also positive. By Proposition 6, this implies that the 2SLS
weights are positive even if Assumption IAM is violated. The joint distribution of the
two instruments therefore turns out to be sufficient to yield positive weights in this
case.
The final rows of Table 8 use these results in formal statistical tests for positive
and negative 2SLS weights. We consider tests of both the null hypothesis that the
weights are all positive, and the complimentary hypothesis that at least one weight is
negative.20 As expected given the strong positive correlations in Table 8, the null hy20

The tests, which were implemented using our companion Stata package mivcausal, are described in
more detail in Appendix C. The p–value reported for the null of positive weights is from the test based on
Romano et al. (2014).

28

pothesis of negative weights is rejected at conventional levels (p = 0.001), while a test
of the null of positive weights does not reject and generates a high p-value of 1.0. These
findings show that in the CHV application, the combined 2SLS estimand retains an
interpretation as a positively-weighted average of treatment effects when Assumption
IAM is replaced by the weaker Assumption AM. This has been emphasized elsewhere
as an attractive property of estimands in settings with treatment effect heterogeneity
(e.g. Angrist and Pischke, 2009). Our results demonstrate that if estimating a positive
weighted average of treatment effects is the researcher’s goal, then they may justified in combining instruments via 2SLS without relying on the onerous homogeneity
restrictions implied by IA monotonicity.

6

Conclusion

The IA monotonicity condition is a cornerstone of modern IV analysis. It is appealed
to often, but rarely justified explicitly. As we have shown, it will not hold when there
are multiple IVs without severe restrictions on choice heterogeneity. This creates a
dilemma for using IV methods to aggregate findings into a larger body of knowledge:
Each instrument is associated with a different set of complier groups, but combining
multiple IVs together using IA monotonicity requires assuming that these groups are
effectively identical in terms of their choice behavior.
In this paper, we have clarified the implications of IA monotonicity and considered
combining instruments under a weaker condition called partial monotonicity. Partial
monotonicity is not a strong assumption about choice behavior. It is satisfied under the
usual mathematical interpretation of monotonicity that each instrument encourages
all individuals either towards or away from treatment. We have shown that it still
preserves the interpretation of the 2SLS estimand as a positively-weighted average of
causal effects for complier groups, except in rare cases. These rare cases can and should
be checked for when reporting 2SLS estimates with multiple IVs. The conditions for
positive weights turn out to hold in our application to estimating the returns to college
attendance, even while the IA monotonicity condition seems to be clearly violated.
While our results provide theoretical and empirical guidance for researchers who
wish to use 2SLS to combine multiple IVs, it is important to recognize that positivelyweighted averages of LATEs do not necessarily answer interesting scientific or policy
counterfactuals. This point motivates our companion paper (Mogstad et al., 2020), in
which we develop a framework for aggregating multiple IVs to conduct inference about
specific target parameters that do answer well-posed counterfactual questions. The
framework generalizes the approach of Mogstad et al. (2018) to replace IA monotonic-

29

ity with partial monotonicity. The key idea is that even under partial monotonicity,
each instrument still carries identifying content about unobserved quantities that are
instrument-invariant, such as the average treatment effect. Harmonizing this content
across instruments allows for information to flow between instruments and to aggregate into greater whole. This provides a way to combine exogenous variation from
multiple sources for policy evaluation, while still maintaining plausible conditions on
choice behavior.

30

A

Proofs

Proof of Proposition 1. (⇒) Suppose that the nesting statement is not true. Then
there exist j, k ∈ I such that Zj 6⊆ Zk and Zk 6⊆ Zj . Since the empty set ∅ is a subset

of every set (including itself), this implies that both Zj and Zk are not empty. Thus,

there exists a zj ∈ Zj such that zj ∈
/ Zk , and there exists a zk ∈ Zk such that zk ∈
/ Zj .
By the definition of these sets, this means that

Dj (zj ) = 1 > 0 = Dj (zk )
and Dk (zj ) = 0 < 1 = Dk (zk ).

(13)

Thus, Di (zj ) ≥ Di (zk ) for some i = j, but Di (zj ) < Di (zk ) for some other i = k. This
violates Assumption IAM. By contraposition, it follows that Assumption IAM implies
the nesting statement.
(⇐) Conversely, if Assumption IAM is not true, then there exist j, k ∈ I and

zj , zk ∈ Z such that (13) holds. By definition, (13) implies that zj ∈ Zj , but zj ∈
/ Zk ,

and that zk ∈ Zk , but zk ∈
/ Zj . That is, Zk 6⊆ Zj , and Zj 6⊆ Zk . It follows that the
nesting statement also implies Assumption IAM.

Q.E.D.

Proof of Proposition 2. Suppose to the contrary that there exist j, k ∈ I(z ? ) for
which (2) does not hold. Then the matrix
"
?

∂Vjk (z ) ≡

∂1 Vj (z ? ) ∂2 Vj (z ? )

#

∂1 Vk (z ? ) ∂2 Vk (z ? )

"
≡

∂Vj (z ? )

#

∂Vk (z ? )

is invertible. Thus, the span of the rows of ∂Vjk (z ? ) is R2 , so there exists a unit
vector v ? ∈ R2 such that ∂Vj (z ? )v ? > 0, while ∂Vk (z ? )v ? < 0. Taking a Taylor series
expansion at z ? + v ? for sufficiently small  > 0, we have that

Vj (z ? + v ? ) ≈ Vj (z ? ) +  [∂Vj (z ? )v ? ] > 0,

while

Vk (z ? + v ? ) ≈ Vk (z ? ) +  [∂Vk (z ? )v ? ] < 0

since Vj (z ? ) = Vk (z ? ) = 0. On the other hand, an  step in the direction −v ? yields
Vj (z ? − v ? ) < 0

while Vk (z ? − v ? ) > 0.

31

Using the random utility model, (1), we have that
Dj (z ? + v ? ) = 1 > Dj (z ? − v ? ) = 0

and Dk (z ? + v ? ) = 0 < Dk (z ? − v ? ) = 1,
which shows that Assumption IAM is violated. This establishes the result through
contraposition.

Q.E.D.

Proof of Proposition 3. Take any (z` , z−` ) and (z`0 , z−` ) in Z. Since z` , z`0 ∈ R,

either z` ≥ z`0 or z`0 ≥ z` . Suppose that the first case holds. Then (z` , z−` ) ≥ (z`0 , z−` ),

so Di (z` , z−` ) ≥ Di (z`0 , z−` ) for all i, as required by Assumption PM.

Q.E.D.

Proof of Proposition 4. That an individual i cannot belong to more than one of
the six groups can be verified by inspection. To see that i must belong to at least one
of these groups, note that under (7), either
Di (0, 0) ≤ Di (0, 1) ≤ Di (1, 0) ≤ Di (1, 1)

(14)

or Di (0, 0) ≤ Di (1, 0) ≤ Di (0, 1) ≤ Di (1, 1).

(15)

If i satisfies (14) then by Table 3, their group is Gi ∈ {at, nt, 1c, ec, rc}; that is, some-

thing other than a Z2 complier. If i satisfies (15), then their group is something other
than a Z1 complier. In either case, they must belong to one of the six groups listed in
Table 3.

Q.E.D.

Proof of Proposition 5. Label the instrument pairs as z 1 = (0, 0), z 2 = (0, 1), z 3 =
(1, 0), and z 4 = (1, 1), and denote their associated probabilities as q k ≡ P[Zi = z k ]
for k = 1, 2, 3, 4. We will prove the result for the case with π1c ≥ π2c , so that the
propensity score p(z k ) ≡ P[Di = 1|Zi = z k ] is increasing in k, due to Assumption PM
and (7). A symmetric proof applies to the case with π2c ≥ π1c .

Theorem 2 in Imbens and Angrist (1994) shows that the 2SLS estimand is given

by a convex weighted average of three Wald (1940) estimands, which we write as
β2sls = λ2 w2 + λ3 w3 + λ4 w4 ,
where the Wald estimands are given by
wk ≡

E[Yi |Zi = z k ] − E[Yi |Zi = z k−1 ]
,
p(z k ) − p(z k−1 )

32

(16)

and the weights are defined by
 P4

`
`
p(z k ) − p(z k−1 )
`=k q p(z ) − E[p(Zi )]
h
i.
λk ≡ P
P4
4
j ) − p(z j−1 ))
` (p(z ` ) − E[p(Z )])
(p(z
q
i
j=2
`=j
Theorem 1 of Imbens and Angrist (1994) shows that each Wald estimand, wk , gives the
average treatment effect for individuals who change treatment status in response to a
change in the instrument from z k−1 to z k . Using the group definitions in Proposition 4,
this implies that w2 represents the average treatment effect for both the Z2 compliers
and eager compliers. Similarly, w4 reflects the average treatment effect for the Z2
compliers and the reluctant compliers. So,





π2c
πec
w2 =
∆2c +
∆ec ,
π2c + πec
π2c + πec




π2c
πrc
and w4 =
∆2c +
∆rc .
π2c + πrc
π2c + πrc
However, w3 is different, since a shift from z 2 ≡ (0, 1) to z 3 ≡ (1, 0) creates twoway flows. In particular, such a shift induces Z1 compliers to take treatment, but Z2

compliers to exit treatment. Using a minor modification of the argument in Imbens
and Angrist (1994), it follows that
E [(Yi (1) − Yi (0))(Di (1, 0) − Di (0, 1)]
p(z 3 ) − p(z 2 )




π1c
π2c
=
∆1c −
∆2c
p(z 3 ) − p(z 2 )
p(z 3 ) − p(z 2 )




π1c
π2c
=
∆1c −
∆2c ,
π1c − π2c
π1c − π2c

w3 =

where the last equality used p(z 3 ) − p(z 2 ) = (π1c + πec ) − (π2c + πec ) = π1c − π2c .
Substituting the expressions for the Wald estimands into (16), we have
X

β2sls =

ωg ∆g ,

g∈{1c,2c,ec,rc}

where
λ2 πec
,
πec + π2c
λ4 πrc
ωrc ≡
,
πrc + π2c

ωec ≡

λ3 π1c
,
π1c − π2c

 
 

λ2 π2c
λ3 π2c
λ4 π2c
≡
−
+
.
πec + π2c
π1c − π2c
πrc + π2c

ω1c ≡
and ω2c

33

It is straightforward to verify that ωec , ω1c , and ωrc are each non-negative, and that
X

ωg = λ2 + λ3 + λ4 = 1.

g∈{1c,2c,ec,rc}

For ω2c , note first that
πec + π2c = p(z 2 ) − p(z 1 ),
and that, similarly,
π1c − π2c = p(z 3 ) − p(z 2 )

and πrc − π2c = p(z 4 ) − p(z 3 ).

Substituting this observation and the definition of λk into the expression for ω2c and
simplifying, we have
ω2c



q 2 p(z 2 ) − E[p(Zi )] + q 4 p(z 4 ) − E[p(Zi )]
i.
h
= π2c × P
P4
4
` (p(z ` ) − E[p(Z )])
j ) − p(z j−1 ))
q
(p(z
i
`=j
j=2

The denominator of this expression is always positive and π2c is always non-negative.
For the numerator, notice that since Zi,2 = 1 if and only if Zi ∈ {z 2 , z 4 },


q 2 p(z 2 ) − E[p(Zi )] + q 4 p(z 4 ) − E[p(Zi )]
= E [Zi,2 (p(Zi ) − E[p(Zi )])]

= E [Zi,2 (Di − E[Di ])] ≡ Cov(Di , Zi,2 ),
where the second equality follows by iterating expectations. Thus, the sign of ω2c is
the same as that of Cov(Di , Zi,2 ), which is in turn the same as the sign of E[Di |Zi,2 =
1] − E[Di |Zi,2 = 0], since

Cov(Di , Zi,2 ) = (E[Di |Zi,2 = 1] − E[Di |Zi,2 = 0]) P[Zi,2 = 1] P[Zi,2 = 0].
Q.E.D.
Proof of Proposition 6. Since Zi,1 and Zi,2 are binary,
P[Di = 1|Zi,2 = 1] − P[Di = 1|Zi,2 = 0]
=

p(1, 1) P[Zi,1 = 1|Zi,2 = 1] + p(0, 1) P[Zi,1 = 0|Zi,2 = 1]

− p(1, 0) P[Zi,1 = 1|Zi,2 = 0] − p(0, 0) P[Zi,1 = 0|Zi,2 = 0].

34

Assumption PM with (7) together with E imply that
p(1, 1) ≡ P[Di = 1|Zi,1 = 1, Zi,2 = 1] = P[Di (1, 1) = 1] ≥ P[Di (0, 1) = 1] = p(0, 1),
and similarly that p(1, 0) ≥ p(0, 0) and p(0, 1) ≥ p(0, 0). If Cov(Zi,1 , Zi,2 ) ≥ 0, then
also P[Zi,1 = 1|Zi,2 = 1] ≥ P[Zi,1 = 1] ≥ P[Zi,1 = 1|Zi,2 = 0]. Thus,
Pr[Di = 1|Zi,2 = 1] − Pr[Di = 1|Zi,2 = 0]
≥

p(1, 1) P[Zi,1 = 1] + p(0, 1) (1 − P[Zi,1 = 1])

− p(1, 0) P[Zi,1 = 1] − p(0, 0)(1 − P[Zi,1 = 1])

= [p(1, 1) − p(1, 0)] P[Zi,1 = 1] + [p(0, 1) − p(0, 0)] (1 − Pr[Zi,2 = 1]) ≥ 0.
By Proposition 5, this implies that ω2c ≥ 0. A symmetric argument shows that P[Di =
1|Zi,1 = 1] − P[Di = 1|Zi,1 = 0] ≥ 0, so that ω1c ≥ 0 as well.

Q.E.D.

Proof of Proposition 7. By Theorem 2 in Imbens and Angrist (1994),
β2sls =

K
X

λ k wk ,

(17)

k=2

where the Wald estimands are
wk ≡

E[Yi |Zi = z k ] − E[Yi |Zi = z k−1 ]
,
p(z k ) − p(z k−1 )

and the weights are

 PK `
`
p(z k ) − p(z k−1 )
`=k q p(z ) − E[p(Zi )]
i.
h
λk ≡ P
PK `
K
` ) − E[p(Z )])
j ) − p(z j−1 ))
q
(p(z
(p(z
i
j=2
`=j

(18)

By Assumption E,
wk =
=

E[Yi (Di (z k )) − Yi (Di (z k−1 ))]
p(z k ) − p(z k−1 )
P
k
k−1 ))|G = g]π
i
g
g∈G E[Yi (Di (z )) − Yi (Di (z
P

=

p(z k ) − p(z k−1 )
P
g:k∈Cg ∆g πg −
g:k∈Dk ∆g πg
p(z k ) − p(z k−1 )

,

(19)

since Yi (Di (z k )) − Yi (Di (z k−1 )) = 0 except when k ∈ CGi or k ∈ DGi . Substituting

35

(19) into (17),
β2sls =
=

K
X
k=2
K
X

P

g:k∈Cg

λk

∆g π g −

p(z k ) −
P

g∈G

λk

=

!



p(z k ) − p(z k−1 )

πg

g∈G

∆g πg

g:k∈Dg
k−1
p(z
)

(1[k ∈ Cg ] − 1[k ∈ Dg ]) ∆g πg

k=2

X

P

K
X
k=2

(1[k ∈ Cg ] − 1[k ∈ Dg ])



λk
k
p(z ) − p(z k−1 )

!
∆g ≡

X

ωg ∆g . (20)

g∈G

Substituting the definition of λk from (18) and simplifying,
ωg = π g
= πg

K
X
k=2
K
X
k=2

(1[k ∈ Cg ] − 1[k ∈ Dg ])
(1[k ∈ Cg ] − 1[k ∈ Dg ])



PK

(

[



Cov(Di ,1[p(Zi )≥p(z k )])
Var(p(Zi ))



)

`
`
`=k q p(z )−E[p(Zi )]
PK
PK `
j
j−1
)) `=j q p(z ` )−E[p(Zi )]
j=2 (p(z )−p(z

(

)]


,

(21)

where in the numerator we used


h
i
Cov Di , 1[p(Zi ) ≥ p(z k )] = E 1[p(Zi ) ≥ p(z k )] (Di − E[Di ])
h
i
k
= E 1[p(Zi ) ≥ p(z )] (p(Zi ) − E[p(Zi )])
=

K
X
`=k



q ` p(z ` ) − E[p(Zi )] ,

and in the denominator we used
Var(p(Zi )) = E [Di (p(Zi ) − E[p(Zi )])]
=

K
X
`=1

=

K
X
`=1

=

K
X
j=2



p(z ` ) p(z ` ) − E[p(Zi )] q `


K


X


1[j ≤ `] p(z j ) − p(z j−1 )  p(z ` ) − E[p(Zi )] q `
j=2




K 

X

 p(z j ) − p(z j−1 )
p(z ` ) − E[p(Zi )] q `  ,
`=j

where the third equality follows from a telescoping sum identity,21 together with the
21

In particular, that a` = a1 +

PK

j=2

1[j ≤ `](aj − aj−1 ) for any scalars {a` }K
`=1 .

36

fact that

PK

`=1


p(z ` ) − E[p(Zi )] q ` = 0. Examining the expression for the weights in

(21), we have that

sgn(ωg ) = 1[πg > 0] × sgn

K
X
k=2

!

.
(1[k ∈ Cg ] − 1[k ∈ Dg ]) Cov Di , 1[p(Zi ) ≥ p(z k )]


It remains to show that ωg = 0 when Cg = ∅, so that only groups that comply with

at least one instrument contrast receive weight in the 2SLS estimand. To see that this
is so, suppose to the contrary that there is a group g with πg > 0 for which Cg = ∅,
while ωg 6= 0. Given the structure of ωg , such a group must have Dg 6= ∅. That is, this
group must defy at some instrument contrast, even though they do not comply at any
other instrument contrasts. We will prove that such a “pure defier” group cannot exist
under Assumption PM by establishing a contradiction.
Let j0 ∈ Dg be the instrument contrast at which the “pure defier” group g defies.

By definition, Di (z j0 ) = 0, while Di (z j0 −1 ) = 1. Since Cg = ∅, it follows that for any i
with Gi = g,

Di (z j ) = 1[j < j0 ].

(22)

In particular, Di (z 1 ) = 1, while Di (z K ) = 0.
To proceed, it will be helpful to use the following terminology. We call two vectors z j
and z k pm-comparable if they differ in only one component. That is, z j and z k are pmcomparable if there exists an `0 ∈ {1, . . . , L} such that z`j = z`k for all ` 6= `0 . If and z j

and z k are pm-comparable, then Assumption PM requires that either Di (z j ) ≤ Di (z k )
for all i ∈ I or that Di (z j ) ≥ Di (z k ) for all i ∈ I. Moreover, as we show in Lemma

1, if j ≤ k, then there cannot exist a group g ? with πg? > 0 for which individuals i in
group g ? have Di (z j ) > Di (z k ). We will now use this result to show that the existence
of the “pure defier” group g defined above creates a contradiction.
Let z j1 be the vector whose first component is the same as that of the largest
propensity-score instrument value, z K , while all other components are the same as the
smallest, z 1 . That is,
1
z j1 ≡ (z1K , z−1
).

Then z j1 and z 1 are pm-comparable, and z j1 ∈ supp(Zi ), which we have assumed is

rectangular. Since Di (z 1 ) = 1 for any i with Gi = g and p(z 1 ) is the smallest propensity
score value, it follows from Lemma 1 that Di (z j1 ) = 1 for these individuals as well.
Thus by (22), it must be that j1 < j0 .

37

Now let z j2 be the same as z j1 except with its second component replaced by z2K .
That is,
j1
) ≡ (z1K , z2K , z31 , . . . , zL1 ).
z j2 ≡ (z2K , z−2

Then z j2 is pm-comparable to z j1 , and z j2 ∈ supp(Zi ). If it were the case that j2 ≥ j0 ,

then p(z j2 ) ≥ p(z j0 ) ≥ p(z j1 ), so that Lemma 1 would imply that Di (z j2 ) = 1 for

individuals with Gi = g. At the same time, (22) would imply that Di (z j2 ) = 0 for

these individuals, yielding a contradiction. Thus, it must be that j2 < j0 .
Continuing in this way, we find a sequence of vectors z j1 , z j2 , z j3 , . . . , z jL that each
differ from z K in one component less than its predecessor, and such that j` < j0 for
each `. This process ends once we reach jL , at which point z jL = z K is the instrument
value corresponding to the largest propensity score value. However, this implies a
contradiction, because jL < j0 while at the same time jL = K ≥ j0 . We conclude that
a “pure defier” group cannot exist under Assumption PM, and therefore that the sum
in (20) only needs to be indexed over g ∈ G for which Cg 6= ∅.

Q.E.D.

Lemma 1. Suppose that Assumption E holds. Let G denote the set of all realizations

of {Di (z)}z∈Z that are consistent with Assumption PM. Suppose that z and z 0 are pm-

comparable and that p(z) ≤ p(z 0 ). Then there does not exist a group g ? ∈ G such that
πg? > 0 and Di (z) > Di (z 0 ) for all i with Gi = g ? .

Proof of Lemma 1. Since z and z 0 are pm-comparable, Assumption PM requires
that Di (z) ≤ Di (z 0 ) for all i ∈ I, or Di (z) ≥ Di (z 0 ) for all i ∈ I. If such a group g ?
did exist, then the latter case would need to hold. However, this would imply that
p(z) ≡ P[Di = 1|Zi = z]
= P[Di (z) = 1]

= P[Di (z) = 1|Gi = g ? ]πg? + P[Di (z) = 1|Gi 6= g ? ](1 − πg? )

> P[Di (z 0 ) = 1|Gi = g ? ]πg? + P[Di (z 0 ) = 1|Gi 6= g ? ](1 − πg? )
= P[Di = 1|Zi = z 0 ] ≡ p(z 0 ),

which contradicts the assumption that p(z) ≤ p(z 0 ).

B

Q.E.D.

Additional Examples of Assumptions IAM and PM

In this appendix, we consider three example papers from our survey, each of which
combines multiple economically distinct IVs using 2SLS. In each example, we discuss

38

the content of both Assumptions IAM and PM. We conclude in each that Assumption
IAM is unlikely to hold, whereas the weaker Assumption PM is more plausible.

B.1

Thornton (2008)

The author evaluates an experiment in rural Malawi in which individuals who were
screened for HIV were then randomly assigned incentives to receive their results. Two
incentives were used: a cash-redeemable voucher and the distance to the nearest results center. Thornton uses these randomly assigned incentives as instruments for the
decision to obtain the results, with the goal of estimating the causal effect of learning
HIV status on the demand for condoms.
Assumption IAM would require an individual’s decision to obtain their HIV test
results to either be influenced more by the voucher, or by the distance to the results
center. It is not difficult to imagine two individuals who similarly value learning their
HIV status , but who differ in their preferences over distance versus a monetary incentive. For example, a low-wage worker with a lower opportunity cost of time might be
more affected by a voucher than by the distance to the center. On the other hand, a
high-wage worker with a higher opportunity cost might value the reduced travel time
to a closer center more than a voucher.
While Assumption IAM monotonicity is hard to justify, Assumption PM is likely
to hold. Keeping distance fixed, a voucher incentive should increase the likelihood that
any individual obtains his or her results. Keeping the voucher incentive fixed, being
randomly assigned a closer results facility should decrease the opportunity cost and
thus also increase the likelihood of obtaining the test results.

B.2

Currie and Moretti (2003)

The authors examine the impact of a mother’s educational attainment on her infant’s
health. As instruments for mother’s education, the authors use the number of two- and
four-year colleges present in the mother’s county of residence when she was 17 years
old. The argument is that the availability of college may have induced some women to
obtain more education.
Assumption IAM would require all mothers to be influenced more by the presence
of a two-year college or by the presence of a four-year college when deciding how much
education to obtain. This is unlikely. For example, two-year colleges may provide a
cheaper option, while four-year colleges may provide a better education. There is likely
to be substantial heterogeneity in preferences over the cost and quality of education.
However, Assumption PM is a more reasonable assumption. A mother’s educa-

39

tional attainment should increase as her opportunities for education increase. If this is
true, then the ceteris paribus impact of the presence of a four-year college on attained
education would be positive regardless of whether there is also a two-year college, and
vice-versa. This is all that is required for Assumption PM to be satisfied.

B.3

Dippel (2014)

The author considers the long-term effects on economic growth of forcibly integrating
Native American communities in the United States. As instruments for integration,
the author uses the value of gold and silver mining activity in these communities. The
rationale behind these instruments is that when land was found to be more valuable,
the federal government would free up larger portions of the land by forming fewer,
more concentrated reservations.
Assumption IAM would require the likelihood of forced integration across all tribes
and reservations to either be affected more by the value of silver activity or by the value
of gold activity. This would not hold if the officials responsible for forced integration
had different beliefs about the value of each metal. This could occur if these beliefs vary
by the location of the reservation or by the official responsible, among other reasons.
In contrast, Assumption PM follows the logic of the author’s argument: holding the
value of one metal fixed, increasing the value of the other increases the likelihood of
forced integration.

C
C.1

Tests about the Signs of the 2SLS Weights
Estimation

Suppose that we exclude a priori the possibility that π1c = 0 or π2c = 0. Then
Proposition 5 implies that the signs of the 2SLS weights in the case with two binary
instruments are determined by the signs of
θj (x) ≡ P[Di = 1|Zi,j = 1, Xi = x] − P[Di = 1|Zi,j = 0, Xi = x]

for j = 1, 2,

where we have conditioned on covariates, Xi , since they are included in our application
in Section 5. To develop our tests, we assume that the conditional probability of
treatment given Zi,j and Xi is additively separable in Zi,j . This implies that θj (x) ≡ θj

does not depend on x, and that θj is identified as the population regression coefficient

on Zi,j in a regression of Di on Zi,j and Xi .22
22

It is straightforward to extend the following to test joint hypotheses about θj (x) across different pre–
specified x values. It is also possible to test joint hypotheses about θj (Xi ) as a random variable using tools

40

We estimate θ ≡ (θ1 , θ2 ) with two ordinary least squares estimators, θ̂ ≡ (θ̂1 , θ̂2 ),

based on a sample of size n. We assume that these estimators are jointly asymptotically
√
normal and denote the limiting variance–covariance matrix of n(θ̂ − θ) by Σ. Let Σ̂

be a consistent estimator of Σ. Let σ12 and σ22 be the diagonal components of Σ, let
σ12 be the off–diagonal component, and denote the corresponding components of Σ̂ by
σ̂12 , σ̂22 , and σ̂12 , respectively.

C.2

Testing the Null Hypothesis of Positive Weights

We first consider tests of the null hypothesis that the weights are positive (nonnegative), that is of
H0+ : θ1 ≥ 0

and θ2 ≥ 0,

against the complementary alternative.
The first and simplest approach is to treat θ1 ≥ 0 and θ2 ≥ 0 as separate hypotheses

and then apply a Bonferroni correction. Letting p̂1 and p̂2 denote the p–values from
the corresponding one–sided t–tests, the Bonferroni–corrected p–value is then
p̂0 ≡ min{2p̂1 , 2p̂2 , 1}.
This test will typically be conservative.
The second approach is to consider the test statistic
T̂ ≡ min

j=1,2

√

nθ̂j
,
σ̂j

(23)

that is, the minimum of the individual t–statistics, and reject H0+ if this quantity is
too small. If H0+ is true, then the distribution of T̂ has the following lower bound
asymptotically:
"
#


√
√
h
i
n(θ̂j − θj )
nθj
P T̂ ≤ t = P min
+
≤ t ≤ P min Wj ≤ t ,
j=1,2
j=1,2
σ̂j
σ̂j

(24)

where W ≡ (W1 , W2 ) is a bivariate normal distribution with mean zero, unit variances,
and correlation σ1,2 σ1−1 σ2−1 . Thus, the test that rejects H0+ when T̂ is smaller than the

from the literature on conditional moment inequalities (e.g. Andrews and Shi, 2013; Chernozhukov, Lee,
and Rosen, 2013; Armstrong, 2015; Chetverikov, 2018). We focus on the separable case as it enables the
construction of simple tests which can be implemented easily in statistical software, and which require no
additional choices or tuning parameters on the part of the researcher.

41

α quantile of the distribution of minj=1,2 Wj has size no greater than α. In the Monte
Carlo simulation in Section C.4, we refer to this test as the “Mintest.” Implementing
it requires simulating the distribution of minj=1,2 Wj using its estimated correlation,
σ̂12 σ1−1 σ̂2−1 .
The third approach uses the quasi–likelihood ratio statistic

0


Q̂ = min n θ̂ − t Σ̂−1 θ̂ − t ,
t≥0

and rejects if Q̂ is too large. Let t̂? denote the minimizer of this problem and let
k̂ ? ∈ {0, 1, 2} denote the number of components of t̂? that are zero, that is, where the

non-negativity constraint is binding. Cox and Shi (2019) show that the test that rejects
when Q̂ is larger than the 1 − α quantile of a chi–squared distribution with k̂ ? degrees
of freedom controls size at level α. We call this the Cox–Shi test in Section C.4.

The fourth test is from Romano et al. (2014, “RSW”), and also uses the test statistic
T̂ from (23). Their approach improves on the Mintest described above by estimating
√
a 1 − β joint confidence interval for minj=1,2 n(θ̂j − θj ) and using this to improve

the coarse bound used in (24) to obtain a critical value. Both this first step and their

resulting critical value requires bootstrapping the linear regression estimators, θ̂1 and
θ̂2 . For a level α test, RSW recommend setting β = α/10, which means that the
number of bootstraps used in the first step confidence interval needs to be rather large
to get an accurate approximation of the 1 − β quantile. This can make the RSW test
somewhat computationally demanding compared to the other three tests.

C.3

Testing the Null Hypothesis of Negative Weights

We also consider the opposite null hypothesis that one or more 2SLS weight is negative,
that is, of
H0− : θ1 ≤ 0

or

θ2 ≤ 0,

against the complementary alternative. We use an intersection–union test (IUT) based
on the theory in Berger (1982). In the current context, the IUT argument is simple:
reject H0− at level α if both θ1 ≤ 0 and θ2 ≤ 0 are rejected at level α using one-

sided t–tests. This controls size because the probability that both θ1 ≤ 0 and θ2 ≤ 0

are rejected under the null is by construction smaller than the probability that either
θ1 ≤ 0 or θ2 ≤ 0 are rejected. Perhaps more surprisingly, Berger (1982, Theorem 2)
provides conditions under which the IUT test is size–correct, which is confirmed in
our simulations. See Berger and Hsu (1996, Section 3) and Casella and Berger (2002,

42

Section 8.3) for more detail.

C.4

A Monte Carlo Simulation

The Monte Carlo simulation has the following data generating process. The group
shares are set at πat = 2/12, πec = 1/12, πrc = 1/12, πnt = 2/12, π1c = 5/12, and
π2c = 1/12. First, Zi,2 ∈ {0, 1} is drawn with probability 1/2. Then, Zi,1 is drawn
conditional on Zi,2 with probability

P[Zi,1 = 1|Zi,2 = z2 ] = Φ(ν0 (1 − z2 ) + ν1 z2 ),
where Φ is the standard normal distribution function, and ν0 , ν1 are design parameters.
The parameter ν0 is set such that H0+ is true if and only if ν1 ≥ 0, H0− is true if and
only if ν1 ≤ 0, and both null hypotheses are true when ν1 = 0.

Figure C.1 shows QQ–plots of the p–values from our various tests against the uni-

form distribution for three values of ν1 .23 The middle row with ν1 = 0 shows that
all tests control size when both H0+ and H0− are true, with the IUT and RSW tests
being closest to size–correct. When ν1 = −.25, so that H0− is true, the three simpler-toimplement tests (Bonferroni, Mintest, Cox–Shi) all have roughly the same power, while

the RSW test is substantially more powerful. Power for the IUT test when ν1 = .25
is difficult to gauge, since there is no point of comparison, but one would expect that
it is quite good given its performance at the boundary of the null hypothesis (ν1 = 0).
Figure C.2 reports power curves for a 5% level test which confirm the superior power
of the RSW test.

23

All simulations are based on 2,000 replications. We used 2,000 bootstrap draws for the RSW test.

43

Figure C.1: Size and power for five tests
n = 200

n = 2000

0.75
ν1 = −0.25

0.50

0.25

0.00

Test

0.15

Bonferroni
ν1 = 0

Rejection probability

0.20

0.10

Cox-Shi
IUT
Mintest
RSW

0.05

0.00

0.75
ν1 = 0.25

0.50

0.25

0.00
0.05

0.10

0.15

0.20

0.05

0.10

0.15

0.20

Nominal level
The dotted line is the 45 degree line. The top row (ν1 = −.25) is where H0− is true, the bottom row
is where H0+ is true, and both hypothesis are true in the middle row.

44

Figure C.2: Power curves for five tests

0.8

H0−

H0+

Rejection probability

0.6

Test
Bonferroni
Cox-Shi
0.4

IUT
Mintest
RSW

0.2

0.0
-0.4

-0.2

0.0

0.2

0.4

ν1
The dotted horizontal line indicates the nominal level of .05. The dotted vertical line indicates the
boundary between where H0+ and H0− are true. The sample size is n = 1000.

45

References
Andrews, D. W. K. and X. Shi (2013): “Inference Based on Conditional Moment Inequalities,” Econometrica, 81, 609–666. 41
Angrist, J. D. and W. N. Evans (1998): “Children and Their Parents’ Labor Supply:
Evidence from Exogenous Variation in Family Size,” American Economic Review, 88, 450–
477. 11
Angrist, J. D. and G. W. Imbens (1995): “Two-Stage Least Squares Estimation of Average Causal Effects in Models with Variable Treatment Intensity,” Journal of the American
Statistical Association, 90, 431–442. 5
Angrist, J. D., G. W. Imbens, and D. B. Rubin (1996): “Identification of Causal Effects
Using Instrumental Variables,” Journal of the American Statistical Association, 91, 444–455.
13
Angrist, J. D. and A. B. Krueger (1991): “Does Compulsory School Attendance Affect
Schooling and Earnings?” The Quarterly Journal of Economics, 106, 979–1014. 4
Angrist, J. D. and J.-S. Pischke (2009): Mostly Harmless Econometrics, Princeton University Press. 1, 29
Armstrong, T. B. (2015): “Asymptotically Exact Inference in Conditional Moment Inequality Models,” Journal of Econometrics, 186, 51–65. 41
Berger, R. L. (1982): “Multiparameter Hypothesis Testing and Acceptance Sampling,” Technometrics, 24, 295–300. 42
Berger, R. L. and J. C. Hsu (1996): “Bioequivalence Trials, Intersection-Union Tests and
Equivalence Confidence Sets,” Statistical Science, 11, 283–319. 42
Bitler, M., H. Hoynes, and T. Domina (2014): “Experimental Evidence on Distributional
Effects of Head Start,” Tech. rep. 1
Bitler, M. P., J. B. Gelbach, and H. W. Hoynes (2006): “What Mean Impacts Miss:
Distributional Effects of Welfare Reform Experiments,” The American Economic Review,
96, 988–1012. 1
Brinch, C. N., M. Mogstad, and M. Wiswall (2017): “Beyond LATE with a Discrete
Instrument,” Journal of Political Economy, 125, 985–1039. 1, 27
Cameron, S. V. and J. J. Heckman (1998): “Life Cycle Schooling and Dynamic Selection Bias: Models and Evidence for Five Cohorts of American Males,” Journal of Political
Economy, 106, 262–333. 21
Cameron, S. V. and C. Taber (2004): “Estimation of Educational Borrowing Constraints
Using Returns to Schooling,” Journal of Political Economy, 112, 132–182. 21
Card, D. (1995): “Using Geographic Variation in College Proximity to Estimate the Return to
Schooling,” in Aspects of Labour Market Behavior: Essays in Honour of John Vanderkamp,
ed. by L. N. Christofides, E. K. Grant, and R. Swidinsky, University of Toronto Press,
201–222. 8, 21

46

——— (1999): “The causal effect of education on earnings,” in Handbook of Labor Economics,
ed. by O. Ashenfelter and D. Card, Elsevier Science, vol. 3, 1801–1863. 24
——— (2001): “Estimating the Return to Schooling: Progress on Some Persistent Econometric
Problems,” Econometrica, 69, 1127–1160. 23
Carneiro, P., J. J. Heckman, and E. J. Vytlacil (2011): “Estimating Marginal Returns
to Education,” American Economic Review, 101, 2754–81. 1, 2, 4, 19, 20
Carneiro, P. and S. Lee (2009): “Estimating distributions of potential outcomes using
local instrumental variables with an application to changes in college enrollment and wage
inequality,” Journal of Econometrics, 149, 191–208. 1
Carneiro, P., M. Lokshin, and N. Umapathi (2016): “Average and Marginal Returns to
Upper Secondary Schooling in Indonesia,” Journal of Applied Econometrics, 32, 16–36. 1
Casella, G. and R. L. Berger (2002): Statistical Inference, Pacific Grove, Calif. [u.a.]:
Duxbury/Thomson Learning. 42
Chernozhukov, V., S. Lee, and A. M. Rosen (2013): “Intersection Bounds: Estimation
and Inference,” Econometrica, 81, 667–737. 41
Chetverikov, D. (2018): “ADAPTIVE TESTS OF CONDITIONAL MOMENT INEQUALITIES,” Econometric Theory, 34, 186–227. 41
Cornelissen, T., C. Dustmann, A. Raute, and U. Schönberg (forthcoming): “Who
benefits from universal childcare? Estimating marginal returns to early childcare attendance,” Journal of Political Economy. 1
Cox, G. and X. Shi (2019): “A Simple Uniformly Valid Test for Inequalities,”
arXiv:1907.06317 [econ, math, stat]. 42
Currie, J. and E. Moretti (2003): “Mother’s Education and the Intergenerational Transmission of Human Capital: Evidence from College Openings*,” The Quarterly Journal of
Economics, 118, 1495–1532. 39
Dippel, C. (2014): “Forced Coexistence and Economic Development: Evidence From Native
American Reservations: Forced Coexistence and Economic Development,” Econometrica,
82, 2131–2165. 40
Doyle Jr., J. J. (2007): “Child Protection and Child Outcomes: Measuring the Effects of
Foster Care,” The American Economic Review, 97, 1583–1610. 1
Felfe, C. and R. Lalive (2014): “Does Early Child Care Help or Hurt Children’s Development?” Tech. Rep. 8484. 1
Firpo, S., N. M. Fortin, and T. Lemieux (2009): “Unconditional Quantile Regressions,”
Econometrica, 77, 953–973. 1
French, E. and J. Song (2014): “The Effect of Disability Insurance Receipt on Labor
Supply,” American Economic Journal: Economic Policy, 6, 291–337. 1
Havnes, T. and M. Mogstad (2015): “Is universal child care leveling the playing field?”
Journal of Public Economics, 127, 100–114. 1

47

Heckman, J. J. (2001): “Micro Data, Heterogeneity, and the Evaluation of Public Policy:
Nobel Lecture,” The Journal of Political Economy, 109, 673–748. 1
Heckman, J. J., S. Urzua, and E. Vytlacil (2006): “Understanding Instrumental Variables in Models with Essential Heterogeneity,” Review of Economics and Statistics, 88, 389–
432. 1, 5, 10
Heckman, J. J. and E. Vytlacil (2005): “Structural Equations, Treatment Effects, and
Econometric Policy Evaluation,” Econometrica, 73, 669–738. 1, 6, 25
Heckman, J. J. and E. J. Vytlacil (1999): “Local Instrumental Variables and Latent Variable Models for Identifying and Bounding Treatment Effects,” Proceedings of the National
Academy of Sciences of the United States of America, 96, 4730–4734. 25
——— (2007): “Chapter 71 Econometric Evaluation of Social Programs, Part II: Using the
Marginal Treatment Effect to Organize Alternative Econometric Estimators to Evaluate Social Programs, and to Forecast their Effects in New Environments,” in Handbook of Econometrics, ed. by J. J. Heckman and E. E. Leamer, Elsevier, vol. Volume 6, Part 2, 4875–5143.
25
Imbens, G. W. and J. D. Angrist (1994): “Identification and Estimation of Local Average
Treatment Effects,” Econometrica, 62, 467–475. 1, 6, 12, 14, 18, 19, 25, 32, 33, 35
Kane, T. J. and C. E. Rouse (1993): “Labor Market Returns to Two- and Four-Year
Colleges: Is a Credit a Credit and Do Degrees Matter?” Working Paper 4268, National
Bureau of Economic Research. 8
Kirkeboen, L. J., E. Leuven, and M. Mogstad (2016): “Field of Study, Earnings, and
Self-Selection,” The Quarterly Journal of Economics, 131, 1057–1111. 1
Kline, P. and C. Walters (2019): “On Heckits, LATE, and Numerical Equivalence,” Econometrica, 87, 677–696. 27
Kline, P. and C. R. Walters (2016): “Evaluating Public Programs with Close Substitutes:
The Case of Head Start*,” The Quarterly Journal of Economics, 131, 1795–1848. 1
Kling, J. R. (2001): “Interpreting Instrumental Variables Estimates of the Returns to Schooling,” Journal of Business and Economic Statistics, 19, 358–364. 21
Maestas, N., K. J. Mullen, and A. Strand (2013): “Does Disability Insurance Receipt
Discourage Work? Using Examiner Assignment to Estimate Causal Effects of SSDI Receipt,”
The American Economic Review, 103, 1797–1829. 1
Milgrom, P. and C. Shannon (1994): “Monotone comparative statics,” Econometrica, 157–
180. 11
Moffitt, r. (2008): “Estimating Marginal Treatment Effects in Heterogeneous Populations,”
Annales d’Economie et de Statistique, 239–261. 1
Mogstad, M., A. Santos, and A. Torgovitsky (2018): “Using Instrumental Variables
for Inference About Policy Relevant Treatment Parameters,” Econometrica, 86, 1589–1619.
27, 29
Mogstad, M. and A. Torgovitsky (2018): “Identification and Extrapolation of Causal
Effects with Instrumental Variables,” Annual Review of Economics, 10. 27

48

Mogstad, M., A. Torgovitsky, and C. Walters (2020): “Policy Evaluation with Multiple
Instrumental Variables,” Working paper. 19, 25, 29
Mountjoy, J. (2019): “Community Colleges and Upward Mobility,” Working paper. 10
Nybom, M. (2017): “The Distribution of Lifetime Earnings Returns to College,” Journal of
Labor Economics, 000–000. 1
Romano, J. P., A. M. Shaikh, and M. Wolf (2014): “A Practical Two-Step Method for
Testing Moment Inequalities,” Econometrica, 82, 1979–2002. 17, 28, 42
Thornton, R. L. (2008): “The Demand for, and Impact of, Learning HIV Status,” American
Economic Review, 98, 1829–63. 39
Vytlacil, E. (2002): “Independence, Monotonicity, and Latent Index Models: An Equivalence Result,” Econometrica, 70, 331–341. 7, 25
Wald, A. (1940): “The Fitting of Straight Lines if Both Variables are Subject to Error,” The
Annals of Mathematical Statistics, 11, 284–300. 32
Walters, C. (2014): “The Demand for Effective Charter Schools,” Tech. rep. 1

49

