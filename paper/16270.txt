NBER WORKING PAPER SERIES

A SEMIPARAMETRIC APPROACH FOR ANALYZING NONIGNORABLE MISSING
DATA
Hui Xie
Yi Qian
Leming Qu
Working Paper 16270
http://www.nber.org/papers/w16270

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2010

The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
¬© 2010 by Hui Xie, Yi Qian, and Leming Qu. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including ¬© notice,
is given to the source.

A Semiparametric Approach for Analyzing Nonignorable Missing Data
Hui Xie, Yi Qian, and Leming Qu
NBER Working Paper No. 16270
August 2010
JEL No. C01,J16
ABSTRACT
In missing data analysis, there is often a need to assess the sensitivity of key inferences to departures
from untestable assumptions regarding the missing data process. Such sensitivity analysis often requires
specifying a missing data model which commonly assumes parametric functional forms for the predictors
of missingness. In this paper, we relax the parametric assumption and investigate the use of a generalized
additive missing data model. We also consider the possibility of a non-linear relationship between
missingness and the potentially missing outcome, whereas the existing literature commonly assumes
a more restricted linear relationship. To avoid the computational complexity, we adopt an index approach
for local sensitivity. We derive explicit formulas for the resulting semiparametric sensitivity index.
The computation of the index is simple and completely avoids the need to repeatedly fit the semiparametric
nonignorable model. Only estimates from the standard software analysis are required with a moderate
amount of additional computation. Thus, the semiparametric index provides a fast and robust method
to adjust the standard estimates for nonignorable missingness. An extensive simulation study is conducted
to evaluate the effects of misspecifying the missing data model and to compare the performance of
the proposed approach with the commonly used parametric approaches. The simulation study shows
that the proposed method helps reduce bias that might arise from the misspecification of the functional
forms of predictors in the missing data model. We illustrate the method in a Wage Offer dataset.

Hui Xie
Department of Biostatistics
School of Public Health
University of Illinois at Chicago
huixie@uic.edu
Yi Qian
Department of Marketing
Kellogg School of Management
Northwestern University
2001 Sheridan Road
Evanston, IL 60208
and NBER
yiqian@kellogg.northwestern.edu

Leming Qu
Department of Statistics
Boise State University
lqu@boisestate.edu

A Semiparametric Approach for Analyzing
Nonignorable Missing Data
Hui Xie‚àó , Yi Qian,‚Ä† and Leming Qu‚Ä°
July 1, 2010

Summary
In missing data analysis, there is often a need to assess the sensitivity of key inferences to departures
from untestable assumptions regarding the missing data process. Such sensitivity analysis often
requires specifying a missing data model which commonly assumes parametric functional forms for
the predictors of missingness. In this paper, we relax the parametric assumption and investigate
the use of a generalized additive missing data model. We also consider the possibility of a nonlinear relationship between missingness and the potentially missing outcome, whereas the existing
literature commonly assumes a more restricted linear relationship. To avoid the computational
complexity, we adopt an index approach for local sensitivity. We derive explicit formulas for the
resulting semiparametric sensitivity index. The computation of the index is simple and completely
avoids the need to repeatedly fit the semiparametric nonignorable model. Only estimates from the
standard software analysis are required with a moderate amount of additional computation. Thus,
the semiparametric index provides a fast and robust method to adjust the standard estimates for
nonignorable missingness. An extensive simulation study is conducted to evaluate the effects of
misspecifying the missing data model and to compare the performance of the proposed approach
‚àó

Department of Epidemiology and Biostatistics, University of Illinois, Chicago, IL 60612.
Email: huixie@uic.edu.
‚Ä†
Northwestern University. 2001 Sheridan Rd, Evanston, IL 60208.
‚Ä°
Boise State University. 1910 University Dr., Boise ID 83725.
1

with the commonly used parametric approaches. The simulation study shows that the proposed
method helps reduce bias that might arise from the misspecification of the functional forms of
predictors in the missing data model. We illustrate the method in a Wage Offer dataset.

Key words:

Generalized Additive Model; MNAR; Semiparametric Joint Selection Model;

Nonignorability; Sensitivity Analysis.

1.

Introduction

Missing data arise frequently in studies across different disciplines, including public health,
medicine, economics, and social sciences. Missingness can be due to nonresponse in household surveys, attrition in longitudinal studies, or patient noncompliance in experimental
studies and clinical trials. In missing data analysis, ignorability has been a standard assumption regarding the missing data mechanism (Rubin 1976). Under ignorability, a valid
likelihood/Bayesian inference can ignore modeling the missing data mechanism. In the likelihood/Bayesian inference, ignorability holds under the assumptions of missing at random
(MAR) and parameter distinctness (Rubin 1976, Heitjan and Rubin 1991).
Although ignorability is a convenient and useful assumption, it is usually an approximation to reality when missingness is not by design. There are important situations where this
assumption can be questionable. In the analysis of potentially nonignorable missing data,
the selection model is a popular class of models, where one augments the model for the complete data with a missing data model. In practice, a parametric binary regression model has
been commonly employed for modeling the missing data process. In situations where there
are continuous missingness predictors, misspecifying the functional forms of these predictors
by the parametric model can lead to severe bias in the inference of the primary parameters
of interest. In this paper, we propose a data-driven procedure to adaptively choose the
functional forms of the continuous predictors. Specifically, we propose using the generalized
2

additive model (GAM) to relax the linearity assumptions in the missing data model.
One can perform a direct estimation of such a semiparametric joint selection model
(Chen and Ibrahim 2006). The direct estimation can yield valid inferences when the model
is correctly specified, although its computation is very heavy and requires specialized programming. More importantly, such a joint selection model is often weakly or non-identified
(Little 1995, Troxel 1998, Troxel et al. 1998, Chen and Ibrahim 2006), and the results can be
highly sensitive to untestable model assumptions (Kenward 1998). To tackle this problem,
the use of a nonignorable selection model has been proposed as a tool for assessing sensitivity
of inference to nonignorable missingness (Little 1995, Vach and Blettner 1995, Copas and Li
1997, Scharfstein et al. 1999, Copas and Eguchi 2001). A global sensitivity analysis usually
involves repeatedly fitting the nonignorable model for a range of magnitudes of nonignorability, which can be computationally burdensome. To avoid the computation burden, we
utilize an index approach to local sensitivity (Troxel et al. 2004) that uses a Taylor series
expansion to approximate the estimates in the neighborhood of the MAR model. The index
method has been applied in various settings (Xie and Heitjan (2004, 2009), Ma et al. 2005,
Xie (2008, 2009), Qian and Xie 2010, Zhang and Heitjan (2006, 2007)).
The local sensitivity method proposed in the literature utilizes the linear logistic regression for modeling the missing data process. In this article we relax the linearity assumption
and investigate the usage of a generalized additive model for a more robust and flexible modeling of the missing data mechanism. Furthermore, the proposed method is computationally
less complex than the alternative global sensitivity method. Specifically, our approach avoids
fitting any complicated semiparametric joint selection model. Only estimates from a MAR
analysis of the outcome model and a MAR GAM for the missing data process are required
to evaluate sensitivity. Both estimates can be obtained using standard software packages
such as SAS or S-Plus/R. For instance, the MAR GAM for the missing data process can be
3

fitted using PROC GAM in SAS or the S-Plus/R function gam. In summary, the proposed
approach renders sensitivity analysis for nonignorable missingness (1) simple to perform
by avoiding excessive additional computation and (2) robust to model misspecification by
automatically adjusting for potentially complex missing data mechanisms.
The rest of the paper is organized as follows. In Section 2 we describe the semiparametric joint selection model. In Section 3 we review the ISNI (index of local sensitivity
to nonignorability) methodology. In Section 4, we investigate the use of GAM to model
the missing data process. We also consider the possibility of a nonlinear relationship between missingness and the potentially missing outcome, and present specific formulas of
the sensitivity index in the Appendix when the relationship follows a quadratic form. In
Section 5, we conduct simulation studies to compare the performance of the parametric
and semiparametric approaches for modeling the missing data process with respect to their
ability to reduce bias of the MAR estimates. In Section 6, we apply the methodology to
an application on estimating wage offer function. We conclude with a discussion in Section 7.

2.

Selection Model for Nonignorable Missingness

Consider that we have data (Yi , Xi , Zi , Gi ) from the unit i, i = 1, ¬∑ ¬∑ ¬∑ , n. The underlying
ideal outcome, Yi , arises independently from a distribution with a probability density function
fŒ∏ (Yi |Xi ), where Xi contains a set of fully observed covariates. We are interested in drawing
inferences on Œ∏ or a subset of it. Here for the purpose of this presentation, we restrict
our attention to the case where Yi is a univariate. For various reasons, Yi is subject to
missingness. Let Gi be 1 if yi is observed and 0 if yi is missing. We assume the following
missing data model fŒ≥ (gi |yi , zi ), where Gi |Yi , Zi ‚àº Bernoulli(PŒ≥ (Gi = 1|Yi , Zi )) and
PŒ≥ (Gi = 1|Yi = yi , Zi = zi ) = h(Œ∑Œ≥0 (zi ) + Œ∑Œ≥1 (yi )),

4

(1)

h is the inverse of a monotonic link function; Zi is a set of fully observed predictors for missingness; Œ∑Œ≥0 (¬∑) and Œ∑Œ≥1 (¬∑) are smooth functions, and their functional forms are unspecified
now; Let Œ≥ = (Œ≥0 , Œ≥1 ) where Œ≥0 is a vector of parameters that associates the probability of
missingness with observed data, and Œ≥1 associates the probability of missingness with potentially unobserved data. In the model, Œ∑Œ≥1 (y) represents the form of nonignorable missingness:
when Œ∑Œ≥1 (y) is constant in y, the missing data mechanism is MAR; when Œ∑Œ≥1 (y) depends on
y, it becomes missing not at random (MNAR).
Let (Y, X, Z, G) be the stacked data over all the units. We rewrite Y as (Yobs , Ymis ),
where Yobs refers to the observed components of Y and Ymis refers to the missing components
of Y . The covariates X and Z are considered as fixed, and the conditioning on them in
fŒ∏ (yi |xi ) and fŒ≥ (gi |yi , zi ) will be suppressed for notational simplicity. The data to be modeled
are thus (Yobs , G). The correct log-likelihood of the model parameters is
Z
LC (Œ∏, Œ≥; yobs , g) ‚àù ln fŒ∏,Œ≥ (yobs , g) = ln fŒ≥ (g|yobs , ymis ) fŒ∏ (yobs , ymis ) dymis . (2)
Under the MAR condition, fŒ≥ (g|yobs , ymis ) = fŒ≥ (g|yobs ) and can be moved out of the
integral. With the parameter distinctness, this results in a simpler log-likelihood for Œ∏
Z
LI (Œ∏; yobs ) ‚àù ln fŒ∏ (yobs ) = ln
fŒ∏ (yobs , ymis ) dymis .

(3)

In practice, the simpler log-likelihood LI is often used because it avoids modeling the missingdata mechanism. However, in the general case of nonignorable missingness, LI is not proportional to LC and thus the inference based on LI is potentially biased.

3.

ISNI Methodology

As indicated above, for a dataset with missingness, the correct log-likelihood is LC (Œ∏, Œ≥; yobs , g).
We define:
(Œ∏ÃÇ(Œ≥1 ), Œ≥ÃÇ0 (Œ≥1 )) = arg maxŒ∏‚àà‚Ñ¶Œ∏ ,Œ≥0 ‚àà‚Ñ¶Œ≥0 LC (Œ∏, Œ≥0 , Œ≥1 ; yobs , g) for a fixed Œ≥1 .
5

One can then vary Œ≥1 in a plausible range and investigate how the other parameter estimates
in the model are affected. In the existing literature, such sensitivity analysis commonly
assumes a linear binary regression model for missing data process, that is, a restriction
that Œ∑Œ≥0 (zi ) = Œ≥0T zi and Œ∑Œ≥1 (yi ) = Œ≥1 yi . In this selection model, the likelihood LC (Œ∏; Œ≥1 ) is
proportional to the likelihood LI (Œ∏) for all Œ∏ ‚àà ‚Ñ¶Œ∏ when Œ≥1 = 0. Œ∏ÃÇ(0) is then the MLE of Œ∏
in the ignorable model. The difference between Œ∏ÃÇ(0) and Œ∏ÃÇ(Œ≥1 ) is a sensible measure of the
sensitivity of the MLE when Œ≥1 is perturbed around the ignorable model. The idea of a local
sensitivity analysis is to approximate Œ∏ÃÇ(Œ≥1 ) by a Taylor series expansion as follows:
Œ∏ÃÇ(Œ≥1 ) ‚âà Œ∏ÃÇ(0) +
where

‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1

Œ≥1 =0

‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1

√ó Œ≥1 ,

(4)

Œ≥1 =0

measures the changing rate of Œ∏ÃÇ as a function of Œ≥1 , and this quantity is

referred to as the index of local sensitivity to nonignorability (ISNI) (Troxel et al. 2004). In
this approximation, Œ∏ÃÇ(0) is obtained by maximizing the simpler log-likelihood LI . As shown
in Troxel et al. (2004), a simple formula for
ISNI =

‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1

‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1

Œ≥1 =0

is

2
= ‚àí‚àá2 L‚àí1
Œ∏,Œ∏ ‚àá LŒ∏,Œ≥1 ,

(5)

Œ≥1 =0

with
‚àá2 LŒ∏,Œ∏ =

‚àÇ 2 LC
‚àÇŒ∏‚àÇŒ∏T

‚àá2 LŒ∏,Œ≥1 =

;
Œ∏ÃÇ(0),Œ≥ÃÇ0 (0),Œ≥1 =0

‚àÇ 2 LC
‚àÇŒ∏‚àÇŒ≥1

.
Œ∏ÃÇ(0),Œ≥ÃÇ0 (0),Œ≥1 =0

The first term ‚àá2 LŒ∏,Œ∏ is the observed Hessian matrix of the ignorable model that is usually
readily available. The second term evaluates the orthogonality of Œ∏ and Œ≥1 . One limitation
of ISNI, as a local sensitivity method, is that the above local approximation might not be
sufficiently accurate for extreme nonignorability (i.e. |Œ≥1 | is large). Thus, ISNI is most useful
for moderate nonignorability (e.g. a rich set of observed predictors for missingness has been
conditioned on so that the remaining nonignorability is not extreme).

6

4.

Extending ISNI using a Generalized Additive Model

When some components of Z are continuous, a linear predictor, as considered above, may
not be adequate, and the misspecification of the functional forms for Z may lead to severe
bias in the estimation of Œ∏, the parameters of primary interest. It is thus desirable to use
extended models that describe a wider range of selection mechanisms. In this section, we
investigate the use of GAM for a robust and flexible modeling of the missingness probability.
That is, rather than prespecifying Œ∑Œ≥0 (Zi ) as a linear form, we let Œ∑Œ≥0 (Zi ) follow a GAM
(Hastie and Tibshirani 1990):
Œ∑Œ≥0 (Zi ) = Œ≥00 + Œ∑01 (Zi1 ) + Œ∑02 (Zi2 ) + ... + Œ∑0m (Zim ),
where Zi is composed of m missingness predictors, (Z1 , ..., Zm ), and Œ∑0j is an arbitrary smooth
and mean zero function for the jth covariate Zj , j = 1, ..., m. Because of the additivity in
the nonparametric component, the model is termed as generalized additive model.
Another important modeling decision is to specify Œ∑Œ≥1 (yi ). Note that yi is missing whenever Gi = 0, and thus an attempt to estimate Œ∑Œ≥1 (yi ) would inevitably require imposing
untestable assumptions or using external data. Because of the lack of information from the
data at hand for identification, a feasible approach is to perform sensitivity analysis with
respect to Œ∑Œ≥1 (yi ). In the existing literature, it is common to assume a linear form for Œ∑Œ≥1 (yi ),
i.e., Œ∑Œ≥1 (yi ) = Œ≥1 yi . One benefit of this parametrization is the ease of interpreting the sensitivity analysis result. Although the linearity assumption is reasonable in many practical
applications, it is by no means universally applicable. Thus, we will base our development
P
q
on a more general functional form of Œ∑Œ≥1 (yi ) as Q
q=1 Œ≥1q yi , where Q is a user-specified order.
One can consider using the following penalized log-likelihood of the resulting semi-

7

parametric nonignorable selection model for sensitivity analysis:
LPC (Œ∏, Œ≥00 , Œ∑01 , ¬∑ ¬∑ ¬∑ , Œ∑0m , Œ≥1 ; yobs , g) =
Z

Z
m
1X
2
‚Ä≤‚Ä≤
Œªj Œ∑0j
(u) du,
ln
fŒ≥ (g|Œ≥00 , Œ∑01 , ¬∑ ¬∑ ¬∑ , Œ∑0m , Œ≥1 , yobs , ymis )fŒ∏ (yobs , ymis )dymis ‚àí
2 j=1
where Œªj ‚â• 0 is a smoothing parameter whose value can be adjusted to avoid overfitting.
The sensitivity of inference with respect to nonignorable missingness can then be assessed
by calculating (Œ∏ÃÇ(Œ≥1 ), Œ≥ÀÜ0 (Œ≥1 )) for a plausible range of values for Œ≥1 . For any given value of
Œ≥1 , we must obtain (Œ∏ÃÇ(Œ≥1 ), Œ≥ÀÜ0 (Œ≥1 )) by maximizing LPC over (Œ∏, Œ≥0 ). An algorithm such as
the EM algorithm can be used to maximize the above likelihood and obtain (Œ∏ÃÇ(Œ≥1 ), Œ≥ÀÜ0 (Œ≥1 )).
The optimization can be heavy (e.g. taking a long time to converge) and it also requires
specialized programming. Moreover, this optimization needs to be repeatedly performed for
a range of Œ≥1 values, which further compounds the computational burden.
In contrast, the ISNI method substantially reduces the computational workload. As
the parameters Œ≥0 = (Œ≥00 , Œ∑01 , ¬∑ ¬∑ ¬∑ , Œ∑0m ) in the missing data model are orthogonal to the
parameter Œ∏ in the complete data model when Œ≥1 = 0 ( i.e., missingness is MAR), one can
show that for a vector Œ≥1 = (Œ≥11 , ¬∑ ¬∑ ¬∑ , Œ≥1Q ), we have
‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1T

2
= ‚àí‚àá2 L‚àí1
Œ∏,Œ∏ ‚àá LŒ∏,Œ≥1 ,
Œ≥1 =0

with
‚àá2 LŒ∏,Œ∏ =
‚àá2 LŒ∏,Œ≥1 =

‚àÇ 2 LPC
‚àÇŒ∏‚àÇŒ∏T
‚àÇ 2 LPC
‚àÇŒ∏‚àÇŒ≥1T

where hi = h(Œ≥ÃÇ00 +

Pm

j=1

=
Œ∏ÃÇ(0),Œ≥ÃÇ0 (0),Œ≥1 =0

‚àÇ ln fŒ∏ (Yobs )
‚àÇŒ∏‚àÇŒ∏T

= ‚àí hi
Œ∏ÃÇ(0),Œ≥ÃÇ0 (0),Œ≥1 =0

Œ∏ÃÇ(0)

‚àÇEŒ∏ (YiQ )
‚àÇEŒ∏ (Yi )
,¬∑¬∑¬∑ ,
‚àÇŒ∏
‚àÇŒ∏

!

,

(6)

Œ∏ÃÇ(0),Œ≥ÃÇ0 (0),Œ≥1 =0

Œ∑ÃÇ0j (Zij )) is the predicted probability of being observed under the

MAR model, and h(¬∑) is the inverse of the logit link. The above calculation requires only
8

the MAR estimates, which are obtained by optimizing the following log-likelihood:
LPI (Œ∏, Œ≥00 , Œ∑01 , ¬∑ ¬∑ ¬∑ , Œ∑0m , Œ≥1 = 0; yobs , g) =

m

1X
Œªj
ln fŒ∏ (yobs ) + ln fŒ≥0 ,Œ≥1 =0 (g|yobs ) ‚àí
2 j=1

Z

2

‚Ä≤‚Ä≤
Œ∑0j
(u) du.

In particular, the calculation of the extended ISNI requires the estimation of Œ∑0 (Z) under
the MAR model, i.e., Œ≥1 = 0. The fit maximizes the following penalized log-likelihood:
Z
m
1X
2
‚Ä≤‚Ä≤
P ELL(Œ≥00 , Œ∑01 , ¬∑ ¬∑ ¬∑ , Œ∑0m ; g) = ln fŒ≥0 ,Œ≥1 =0 (g|yobs ) ‚àí
Œªj Œ∑0j
(u) du.
2 j=1
The conventional algorithm for the estimation of a GAM is the local scoring procedure
(Hastie and Tibshirani 1990), which maximizes the above PELL. Equation (6) shows that
a missing observation is given more weight in the calculation of the ISNI if its predicted
probability of nonmissingness, hi , is large ( i.e., unexpected missing). The quantity hi is
related to the missing data mechanism and plays an important role in assessing the sensitivity.
Using a generalized additive model to describe the missing-data mechanism is useful here
because we need accurate and robust estimates of these probabilities of being observed.
P
q
For ease of interpretation, one can reparameterize Œ∑Œ≥1 (y) = Œ≥11 Q
q=1 rq y , where rq =

Œ≥1q /Œ≥11 , and then define
ISNIr =

‚àÇ Œ∏ÃÇ(Œ≥11 , r)
‚àÇŒ≥11

=
Œ≥11 =0

‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1T

Œ≥1 =0

‚àÇŒ≥1
‚àÇŒ≥11

=
Œ≥1 =Œ≥11 ¬∑r

‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1T

r,

(7)

Œ≥1 =0

where r = (r1 , ¬∑ ¬∑ ¬∑ , rQ )T . Given a user-specified r, one can approximate the potential change
of Œ∏ÃÇ(Œ≥1 ) when Œ≥11 is perturbed from 0 to a given value as follows:
Œ∏ÃÇ(Œ≥1 ) ‚àí Œ∏ÃÇ(0) ‚âà

‚àÇ Œ∏ÃÇ(Œ≥1 )
‚àÇŒ≥1T

Œ≥1 = ISNIr ‚àó Œ≥11 .

(8)

Œ≥1 =0

Using the extended ISNI method, it is convenient for a data analyst to entertain plausible
choices of Q and r to explore the sensitivity with respect to the functional forms of Œ∑Œ≥1 (y).
9

In the Appendix, we derive explicit ISNIr formulas for Q = 2 ( i.e., a quadratic function)
when the outcome is modeled by a generalized linear model.

5.

A Comparison Using Simulated Data

In this section, we conduct simulation studies to compare the performance of the parametric
and semiparametric approaches for modeling the missing data process. Specifically, we simulate data from both linear and nonlinear missing data models, and then investigate if the
ISNI based on a GAM missing data model provides a more faithful and robust adjustment
of an MAR estimate than those based on various linear logistic missing data models. We
follow the steps below to perform the simulation studies.
Step 1: Generate the hypothetical complete data, (Yi , Xi ), independently from the following
bivariate normal distribution:


Yi
Xi



‚àº BV N



0
0


 
1 œÅ
,
;
œÅ 1

where i = 1, ¬∑ ¬∑ ¬∑ , n and the sample size n = 500. The parameter œÅ takes the value of -0.5, 0,
or 0.5. We are interested in the conditional distribution of Yi |Xi , which is N (Œ≤0 + Œ≤1 xi , œÉ 2 ),
where Œ≤1 = œÅ is the parameter of interest.
Step 2: Generate the missingness pattern. Yi is subject to missingness with the probability
of nonmissingness given by the following missing data model:
logit(PŒ≥ (Gi = 1|Yi = yi , Xi = xi )) = Œ∑Œ≥0 (xi ) + Œ≥1 yi ,
According to the exact form of Œ∑Œ≥0 (x), we have the following configurations:
‚Ä¢ Case 1.
‚Ä¢ 1. Linear Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 1 + x + Œ≥1 y.
10

(9)

‚Ä¢ 2. Quadratic Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 1 + x + x2 + Œ≥1 y.
‚Ä¢ 3. Cubic Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 1 + x + x2 + x3 + Œ≥1 y.
‚Ä¢ 4. Sine Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 2 sin(2x) + Œ≥1 y.
‚Ä¢ Case 2.
‚Ä¢ 1. Linear Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 1 + x + Œ≥1 y.
‚Ä¢ 2. Quadratic Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 1 ‚àí (x ‚àí 1)2 + Œ≥1 y.
‚Ä¢ 3. Cubic Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 1 ‚àí (x ‚àí 1)2 + (x ‚àí 1)3 + Œ≥1 y.
‚Ä¢ 4. Sine Function. logit(PŒ≥ (G = 1|X = x, Y = y)) = 2 sin(2(x ‚àí 1.5)) + Œ≥1 y.
We vary Œ≥1 to be (‚àí1, ‚àí0.5, ‚àí0.1, 0.1, 0.5, 1). The proportion of missingness in Y ranges
from 15% to 65% in the genrated datasets.
Step 3: With each generated dataset, we compute the MAR estimate, Œ≤ÃÇ1 (0), by applying
the least-square fitting of the regression model, using only the cases with observed yi . Based
on Equation (4), we calculate three ISNI-adjusted estimates as follows:
Œ≤ÃÇ1L (Œ≥1 ) = Œ≤ÃÇ1 (0) + ISNIL √ó Œ≥1 ,

Œ≤ÃÇ1P (Œ≥1 ) = Œ≤ÃÇ1 (0) + ISNIP √ó Œ≥1

Œ≤ÃÇ1G (Œ≥1 ) = Œ≤ÃÇ1 (0) + ISNIG √ó Œ≥1 .

(10)

The three ISNIs, ISNIL , ISNIP , and ISNIG , are listed in order of increasing generality to
model the missing data process. The most constrained one is ISNIL , whose calculation assumes a priori that Œ∑01 (xi ) in Equation (9) is linear in xi as Œ∑01 (xi ) = Œ≥00 + Œ≥01 xi . A more
general one, ISNIP , increases modeling flexibility by manually adding higher-order polynomial terms for xi (i.e., quadratic term, cubic term, ¬∑ ¬∑ ¬∑ ). This process stops when adding the
next higher-order term of xi into the missing data model does not significantly improve the

11

model fit at the 0.05 level, where the improvement in model fitness is measured by the difference in model deviance. This analysis strategy represents a common parametric approach
to seek more acceptable models for the missing data mechanism. The most general one,
ISNIG , uses the GAM method to estimate the missing data model. It uses a nonparametric scatterplot smoother, such as a smoothing spline method, for the estimation of Œ∑Œ≥01 (xi )
and lets data tell the functional form of xi . As compared with ISNIP , ISNIG enjoys two
advantages. GAM is more general as it applies to arbitrary smooth functions whereas the
parametric additive model applies to a priori specified parametric family (e.g. a polynomial
family). Another important benefit with ISNIG is the automation of the procedure which
avoids manually increasing the model complexity
For our simulation model, the formula for ISNI is derived to be
‚àíœÉÃÇ 2 (

where œÉÃÇ 2 =

P

X

i:gi =1

P 1(g =1)

i:gi =1 (yi ‚àíŒ≤ÃÇ0 (0)‚àíŒ≤ÃÇ1 (0)xi )
i

i

2

x
ei x
eTi )‚àí1

X

i:gi =0

hi x
ei ,

is the MAR estimate of the residual variance, and Œ≤ÃÇ0 (0)

and Œ≤ÃÇ1 (0) are the MAR estimates of the Œ≤0 and Œ≤1 , respectively; x
ei = [1, xi ]T is the vector

of predictors for the unit i; hi is the predicted probability of Gi = 1 under the MAR model.
P
For ISNIL , hi = h(Œ≥ÃÇ00 (0) + Œ≥ÃÇ01 (0)xi ). For ISNIP , hi = h(Œ≥ÃÇ00 (0) + Jj=1 Œ≥ÃÇ0j (0)xJi ), where J
is the selected order of the polynomial function of xi . For ISNIG , hi = h(Œ≥ÃÇ00 (0) + Œ∑ÃÇŒ≥01 (xi )),

where Œ∑ÃÇŒ≥01 (xi ) is adaptively estimated by a smoothing spline under the MAR assumption.
The gam function in S-Plus with a default degree of freedom of 4 is used for smoothing.
In practical applications, one can calculate the ISNI-adjusted estimates in Equation (10)
for a plausible range of Œ≥1 values, and investigate the sensitivity of the MAR estimates to
nonignorable missingness. In the simulation studies, we plug in the true value of Œ≥1 . The
performance of these ISNI-adjusted estimates can then be evaluated in terms of their ability
to reduce bias of the MAR estimates, for various scenarios of missing data mechanisms.
12

Step 4: Repeat Step 1 to Step 3 for 300 times for the same values of œÅ and Œ≥1 . Using the
resulting sample of estimates, we compute the mean squared error (MSE), bias, and standard
deviation (SD) for each of the four estimators of Œ≤1 : Œ≤ÃÇ1 (0), Œ≤ÃÇ1L (Œ≥1 ), Œ≤ÃÇ1P (Œ≥1 ), Œ≤ÃÇ1G (Œ≥1 ). We then
repeat Step 4 for other configurations of œÅ and Œ≥1 .
Figure 1 plots the bias when Œ≤1 = œÅ = 0. The results on SDs and MSEs can be found
in Online Supplement Tables 1,2 and Figures 1 and 2. As shown there, the SDs for the
adjusted estimates are almost the same as the SDs of the MAR estimates and as a result,
the differences in the MSE among these estimates are mainly determined by the differences
in the size of the bias. Therefore, in Figure 1, we plot only the bias for the purpose of
comparison. The plots for other values of œÅ lead to qualitatively similar conclusions and
are reported as the online Supplement Figures 3 to 6. As shown in the figures, the MAR
estimate Œ≤ÃÇ1 (0) is biased. A general pattern is that the larger the size of Œ≥1 , the larger the size
of the bias in Œ≤ÃÇ1 (0). This can be readily seen from the V-shaped bias function of Œ≤ÃÇ1 (0) (as a
function of Œ≥1 ) in Figure 1. When Œ∑Œ≥01 (x) is a linear function, all three adjusted estimates,
Œ≤ÃÇ1L (Œ≥1 ), Œ≤ÃÇ1P (Œ≥1 ), and Œ≤ÃÇ1G (Œ≥1 ), are capable of removing the bias of the MAR estimate Œ≤ÃÇ1 (0)
under both cases 1 and 2. This can be seen in Figure 1, as the bias functions of the three
adjusted estimates are all flat at a close-to-zero value over Œ≥1 values for the linear functions.
This indicates that ISNI is an accurate sensitivity index and can effectively reduce the bias
of the MAR estimate when the missing data mechanism is correctly specified.
Though all three adjusted estimates remove the bias of the MAR estimator when Œ∑Œ≥01 (x)
is linear in x, the effectiveness in doing this can be very different for the other forms of
Œ∑Œ≥01 (x). We study the simulation results in the following three key aspects. (1) If Œ∑Œ≥01 (x)
is actually quadratic or cubic, Œ≤ÃÇ1L (Œ≥1 ) has a significant amount of bias under case 2. This
can be seen from the V-shaped bias function of Œ≤ÃÇ1L (Œ≥1 ) for Quadratic and Cubic in Figure
1 (b). In comparison, both Œ≤ÃÇ1P (Œ≥1 ) and Œ≤ÃÇ1G (Œ≥1 ) perform much better in removing the bias,
13

[hp]

0.5

1.0

‚àí0.5

0.0

0.5

0.20

0.20
‚Ä¢‚Ä¢

‚Ä¢

0.15
0.05

0.10

abs(bias)

0.10
0.05

1.0

‚Ä¢
‚àí1.0

‚Ä¢

‚àí0.5

‚Ä¢

0.0

‚Ä¢‚Ä¢

‚Ä¢
‚Ä¢
‚Ä¢‚Ä¢
0.5

1.0

‚Ä¢

‚Ä¢‚Ä¢
‚Ä¢

‚àí1.0

‚àí0.5

‚Ä¢

0.0

0.5

1.0

‚Ä¢‚Ä¢

0.0
r1

‚Ä¢
0.5

‚Ä¢

1.0

0.20
0.15

0.15

0.20
‚Ä¢
‚Ä¢

‚Ä¢

‚Ä¢

0.10

‚Ä¢

abs(bias)

‚Ä¢

0.05

‚Ä¢

0.10

abs(bias)

‚Ä¢

‚Ä¢

‚Ä¢

‚Ä¢

‚Ä¢

‚àí1.0

‚àí0.5

0.0

‚Ä¢
‚Ä¢

‚Ä¢
‚Ä¢

‚Ä¢‚Ä¢

‚Ä¢

‚Ä¢‚Ä¢

‚àí1.0

‚àí0.5

0.0

‚Ä¢

‚Ä¢
‚Ä¢
0.5

1.0

r1

‚Ä¢
‚Ä¢

‚Ä¢

‚Ä¢

‚Ä¢
‚Ä¢‚Ä¢

‚Ä¢
‚Ä¢

0.5

1.0

‚Ä¢

‚Ä¢
‚Ä¢

‚Ä¢‚Ä¢

‚Ä¢
‚Ä¢

‚àí1.0

‚àí0.5

0.0

0.5

r1

Figure 1. (a) Upper Panel: Plot of bias of four estimates for case 1 and Œ≤1 = œÅ = 0.
(b): Lower panel: Plot of bias of four estimates for case 2 and Œ≤1 = œÅ = 0.
The thick solid line: the MAR estimate Œ≤ÃÇ1 (0).
The dotted line: the adjusted estimate using linear predictor, Œ≤ÃÇ1L (Œ≥1 ).
The dashed line: the adjusted estimate using polynomial predictor, Œ≤ÃÇ1P (Œ≥1 ).
The thin solid line: the adjusted estimate using smoothing spline predictor, Œ≤ÃÇ1G (Œ≥1 ).

14

‚Ä¢

‚Ä¢

‚Ä¢

‚Ä¢‚Ä¢

0.0

0.05
‚Ä¢

‚Ä¢

0.0

‚Ä¢‚Ä¢

‚Ä¢

‚Ä¢

0.05

0.20

‚Ä¢

‚Ä¢

‚Ä¢

0.10

0.10

abs(bias)

0.15

Sine

0.20

Cubic

‚Ä¢

‚Ä¢‚Ä¢

‚Ä¢‚Ä¢

Quadratic

‚Ä¢

‚Ä¢

‚Ä¢
‚Ä¢

‚Ä¢‚Ä¢

Linear

0.0

0.0

‚Ä¢‚Ä¢

‚Ä¢‚Ä¢

‚Ä¢

‚Ä¢

r1

0.05

‚àí0.5

‚Ä¢‚Ä¢

‚Ä¢
‚Ä¢

‚Ä¢‚Ä¢

‚Ä¢

r1

‚Ä¢

‚àí1.0

0.15
‚àí1.0

‚Ä¢
‚Ä¢

‚Ä¢

r1

‚Ä¢

‚Ä¢

‚Ä¢‚Ä¢

‚Ä¢

r1

‚Ä¢

‚Ä¢

‚Ä¢

‚Ä¢

0.0

0.0

Sine

‚Ä¢

0.0

‚àí0.5

0.0

‚Ä¢

‚Ä¢

0.15

‚àí1.0

abs(bias)

0.10
0.05

0.05

‚Ä¢

‚Ä¢

‚Ä¢

‚Ä¢
‚Ä¢

‚Ä¢‚Ä¢

‚Ä¢

abs(bias)

0.15

‚Ä¢

‚Ä¢

abs(bias)

0.15
0.10

abs(bias)

‚Ä¢

‚Ä¢

0.0

Cubic

0.20

Quadratic

0.20

Linear

‚Ä¢‚Ä¢

‚Ä¢

r1

‚Ä¢
‚Ä¢
1.0

as shown by their flat bias functions at a close-to-zero value in these figures. This shows
that the misspecification of the missing data model can lead to large bias for the adjusted
parameter estimates in the complete data model, and it can be important to choose a proper
missing data model. (2) Interestingly, in case 1, the bias of Œ≤ÃÇ1L (Œ≥1 ) is almost the same as
those of Œ≤ÃÇ1P (Œ≥1 ) and Œ≤ÃÇ1G (Œ≥1 ), even for the quadratic and cubic form of Œ∑01 (xi ). This shows
that Œ≤ÃÇ1L (Œ≥1 ) has a certain degree of robustness with respect to the misspecification of the
missing data model. (3) When Œ∑01 (xi ) follows a sine form, both Œ≤ÃÇ1L (Œ≥1 ) and Œ≤ÃÇ1P (Œ≥1 ) have
sizable biases, and Œ≤ÃÇ1G (Œ≥1 ) performs best. This shows that ISNIG is most general, and it
can be important to use a data-driven approach, such as a GAM, to model the continuous
predictors in the missing data model.
These findings from the simulation studies suggest that the adjusted estimator based
on ISNIL , which assumes a linear logistic regression, has a certain degree of robustness to
misspecification of missing data mechanism. There can be, however, situations where ISNIL
is seriously affected by the misspecification of functional forms in the missing data model.
In this case, both ISNIP and ISNIG are useful to protect one from having a misleading assessment of the potential change of the estimates. In particular, ISNIG performs better due
to its modeling generality and more robust and automated process to discover the complex
missing data process. Due to the availability of standard software for fitting a GAM, the
success of ISNIG in reducing the bias of the MAR estimates depends less on the experience
of the data analyst to detect model misspecification, as compared with ISNIP .

6.

An Application

Mroz (1987) used a wage offer dataset to demonstrate the sensitivity of empirical econometric analysis to various economic and statistical assumptions. Many of these assumptions,
though useful, are often untestable and thus it is insufficient to base conclusions solely on
15

a single analysis. A more prudent approach is to compare the analysis with those obtained
under alternative assumptions. If the conclusions are reasonably robust, one can have more
confidence about the conclusions drawn. To demonstrate our method, we will mainly focus
on the potential misspecification of functional forms in the missing data mechanism.
The interest of the empirical application is to estimate the wage offer outcome as a
function of education level and experience, after controlling for other observed characteristics
of an woman. That is, one is interested in estimating the following linear regression model:
lwagei = (Intecept, educ, exper, expersq, age, nwif einc, kidslt6, kidsge6)ti Œ≤ + «´i , (11)
where i = 1, ¬∑ ¬∑ ¬∑ , 753, lwage is the logarithm of the wife‚Äôs wage; educ is the wife‚Äôs years
of schooling; exper is the wife‚Äôs labor market experience and expersq is the square term of
exper; age is the wife‚Äôs age; nwif einc is the non-wife family income; kidslt6 is the number of
children less than 6 years and kidsge6 is the number of children between 6 and 18 inclusive.
Not every married woman in the sample had her wage outcome observed. Among the
753 married women in the sample, 325 married women did not participate in the labor force
and as a result their wage outcomes, if employed, were missing. It is possible that the
participation of a married woman in the labor force depends on her potential wage outcome,
even after conditioning on the other observed variables. In order to account for this potential
nonignorability, we assume the following model for self-selection to employment:
logit(P (Gi = 1)) = Œ≥00 + Œ∑1 (educi ) + Œ∑2 (experi ) + Œ∑3 (agei ) + Œ∑4 (nwif einci ) +
kidslt6i Œ≥05 + kidsge6i Œ≥06 + lwagei Œ≥1 ,
where Gi is the indicator variable for participation in the labor force. As a comparison, we
will also consider the following linear logistic labor participation model:
logit(P (Gi = 1)) = (intercept, educ, exper, age, nwif einc, kidslt6, kidsge6)Ti Œ≥0 + lwagei Œ≥1 .
16

Table 1 presents the MAR analysis, which shows that education level and experience have
statistically significant positive effects on the wage offer after the adjustment by the other
variables. Table 1 also presents the ISNI values, which evaluate the effect of nonignorable
missingness of wage outcome on the model estimates. When Y is continuous, the ISNI
value depends on the scale of Y . Thus, to better gauge the sensitivity, we use a sensitivity
S.E.
|, where S.E. is the standard error of a parameter
transformation statistic, c = | ISNI
/œÉ
estimate under the MAR model and œÉ is the standard deviation of Y . The c value implies

that for ISNI to be equal to one S.E., |Œ≥1 | needs to be at least c/œÉ, which under the logit link
corresponds to a magnitude of nonignorability such that a change of œÉ/c in Y is associated
with a change of e1 = 2.7 in the odds of being observed. Thus, the c statistic represents the
critical magnitude of nonignorability, above which the bias due to nonignorable missingness
is larger than the sampling error and therefore causes concern. The smaller the c statistic
is, the larger the sensitivity to nonignorability is. Following Troxel et al. (2004), we suggest
using c = 1 as a cutoff value for important sensitivity as this implies that the bias will be in
the same size as the sampling error for a moderate nonignorability where a change of one‚àíœÉ
in Y is associated with a change of 2.7 in the odds of being observed.
The c statistics summarized in Table 1 show that the MAR estimates of both educ and
exper are sensitive to nonignorable missingness in the outcome. Both MAR estimates have
c statistics less than 1 and this is so when the missing data model is either logistic or GAM.
Thus, the conclusions regarding the sensitivity of these two important estimates are robust
to the choice of missing data model. The conclusions regarding expersq and nwif einc,
however, depend on the choice of the missing data model. With the linear logistic model,
we find that the MAR estimates for expersq and nwif einc have c statistics of less than 1,
indicating that both MAR estimates are sensitive to nonignorable selection for labor force
participation. With the GAM model, these MAR estimates have c statistics of larger than
17

[hp]

Table 1
ISNIs for Parameter Estimates in the Wage Offer Dataset.

Predictor

MAR
Est.

S.E.

Intercept
educ
exper
expersq
nwifeinc
kidslt6
kidsge6
age

-0.36
0.10
0.04
-0.00075
0.0057
-0.056
-0.018
-0.0035

0.32
0.015
0.013
0.00039
0.0033
0.088
0.028
0.005

Linear Logistic
ISNI
c
MAR Est.
+ISNI/œÉ
-0.26
0.019
0.024
-0.00050
-0.0035
-0.12
0.007
-0.006

0.87
0.57
0.40
0.60
0.67
0.53
2.76
0.67

-0.72
0.126
0.073
-0.0015
0.00079
-0.221
-0.0077
-0.011

GAM + Linear Œ∑Œ≥1 (y)
ISNI
c
MAR Est.
+ISNI/œÉ
-0.19
0.018
0.016
-0.00022
-0.0017
-0.12
0.004
-0.007

1.20
0.61
0.57
1.29
1.43
0.53
4.92
0.57

-0.62
0.124
0.064
-0.0010
0.0034
-0.220
-0.012
-0.013

1, indicating that these two MAR estimates are not sensitive to nonignorability.
Using ISNI, we can also calculate the adjusted estimates when Œ≥1 , the parameter for
nonignorable selection, is perturbed from zero. A positive value of Œ≥1 is plausible because it
is highly unlikely that one will decline a job offer when the offered wage is high. Here we
consider Œ≥1 = 1/œÉ, which corresponds to a magnitude of nonignorability where a change of
one standard deviation in lwage corresponds to the odds ratio of labor force participation
being 2.7. In the wage offer dataset, the MAR estimate of œÉ is 0.72. Therefore, as the offered
wage changes by a fold of e0.72 = 2.1, the odds of labor force participation change by 2.7. This
seems to be a moderate nonignorability. The resulting adjusted estimates for this moderate
nonignorability are reported under the column ‚ÄúMAR Est. + ISNI/œÉ‚Äù in Table 1. With
this Œ≥1 value, we see that the adjusted estimates for educ and exper become larger than the
corresponding MAR estimates, which implies that the MAR estimates likely underestimate

18

2
‚àí2

‚àí2

‚àí1

0

1

s(exper)

0
‚àí1

s(educ)

1

3

4

2

[htp]

6

8

10

12

14

16

0

10

20

30

40

exper

0
s(age)

‚àí4

‚àí2

‚àí1

‚àí1
‚àí2
‚àí3

s(nwifeinc)

0

1

1

educ

0

20

40

60

80

100

30

nwifeinc

35

40

45

50

55

60

age

Figure 2. Plots of smooth terms in a generalized additive model for labor force participation
in the Wage Offer data. The dashed lines are 95% pointwise confidence intervals.

the true effects of education and experience. It is also important to note that the adjusted
estimate (-.0015) for expersq under the linear logistic model is almost 50% larger than that
(-.0010) under the GAM for missing data process. This can lead to a potentially significant
difference in estimating the effect of working experience on the wage outcome.
To explore the possible reasons of the discrepancy in ISNI values between the linear
logistic and the GAM labor participation model, we plot in Figure 2 the smooth fitted
functions of the four continuous predictors for labor force participation, obtained from the
GAM model. The figure shows that the relationship between experience and labor force
participation is nonlinear. A chi-square test shows that this nonlinear trend is statistically
significant (p-value= 0.01). It is plausible that this nonlinear relationship between experience
19

and labor force participation drives the difference in the ISNI values.
The above ISNI analysis assumes that a logit transformation of the probability of missingness depends on lwage in a linear form. In the section S.1 of the online Supplement, we
conduct additional analyses where the missingness depends on lwage in a quadratic form.
The analysis shows somewhat smaller assessment of sensitivity for some parameter estimates.

7.

Discussion

It has been recognized that measuring the sensitivity of the inference to alternative missing
data assumptions is an important component of data analysis. Such analysis often requires
positing a missing data model. There typically exists little information to test the assumptions in the missing data model. Thus, it is desirable to utilize a model that covers a wide
range of selection mechanisms. In this article, we propose using a semiparametric approach
to adaptively choose the functional form of the continuous predictors for missingness.
We have investigated the consequences of misspecifying a nonignorable missing data
model using the simulation study and real data analysis. Specifically, we investigate the
performance of ISNI, a recently proposed local sensitivity index of nonignorability, under
the misspecification of missing data model. We found that ISNI has some robustness to
misspecifying the functional form of the predictors for missingness. There exist, however,
important situations where the consequence of misspecification in the missing data mechanism can be significant. In these cases, using more flexible missing data models can help
protect the analysis from such misspecification. We recommend the semiparametric sensitivity index that uses a GAM approach for modeling missing data process, due to its modeling
generality and the automated feature of the procedure. The semiparametric index enables
us to model a larger class of missing data mechanisms than the usual linear logistic model
or parametric nonlinear additive model does. The automation of the procedure is also an
20

important benefit, especially when many continuous predictors for missingness exist, and
how they affect missingness is not well understood. In these situations, it is cumbersome,
if not infeasible, to manually choose proper higher-order terms and/or transformation for
each continuous predictor. The more automated fitting of the missing data mechanism that
uses a GAM substantially reduces the time and efforts invested in such a modeling exercise.
This is particularly helpful in light of the fact that modeling the missing data mechanism
is usually not of primary interest for a study, but has to be properly dealt with in order to
draw correct conclusions about the main interest of the study.
The sample sizes in our analyses are reasonably large and are commonly seen in practice.
When data are sparse, GAM, as a non-parametric method, might not perform well. In
this scenario, one may consider using recently-developed sparse additive model techniques
(Ravikumar et al. 2009), that combines the idea from sparse modeling and additive nonparametric regression.
The proposed semiparametric index is substantially easier to compute than the alternative
global sensitivity method because there is no need to fit any nonignorable model. Thus, it
can be ideal for quickly and robustly measuring the sensitivity of a standard analysis to
nonignorable missingness. If the sensitivity is small, then the standard analysis is considered
trustworthy. Otherwise, one might need to collect more data to better understand the
missing data mechanism (Hirano et al. 2001, Qian 2007). The semiparametric index can be
useful to robustly identify the situations where one may need to take the route.
In this article, we have also extended ISNI to situations where missingness depends
on the missing outcome through a polynomial function. We have derived explicit ISNI
formulas when the nonignorable missingness follows a quadratic form and illustrated its use
in the wage offer dataset. This extension makes the index applicable to a broader range
of applications where investigators suspect that the nonignorable missingness might be of a
21

22
complex relationship and would like to investigate the sensitivity under such a belief.
The proposed method can be generalized to multivariate outcomes with nonignorable
missingness. Qian and Xie (2010) develop local sensitivity methods for various types of longitudinal data with both dropout and intermittent missingness, resulting in a general pattern
of missingness. In their application, the predictors for the missingness are all categorical variables. In other longitudinal applications where the missingness predictors contain continuous
variables, a linear logistic missing data model may lead to erroneous conclusions. In this
case, the proposed semiparametric index method can be extended to provide a more robust
method to measure the impact of nonignorable missingness in longitudinal data analysis.
Acknowledgements
We thank the Editor, the Associate Editor and the anonymous referees for many constructive
comments that led to substantial improvements in the manuscript.

Appendix: ISNI for GLM when Œ∑Œ≥1 (y) is of a quadratic form.
In this Appendix, we derive explicit ISNI formulas when Œ∑Œ≥1 (y) is a quadratic function, i.e.,
Œ∑Œ≥1 (y) = Œ≥11 y + Œ≥12 y 2 . Specifically, we develop these formulas when the outcome Yi follows
a generalized linear model (GLM), which assumes that Yi is independent with density
fŒ∏ (yi ) = exp




yi Œªi (Œ≤) ‚àí b(Œªi (Œ≤))
+ c(yi , œÑ ) ,
a(œÑ )

where Œªi is the canonical parameter; functions b(¬∑) and c(¬∑, ¬∑) determine a particular distribution in the exponential family; a(œÑ ) = œÑ /w, where œÑ is the dispersion parameter and w is a
known weight. Note that the quadratic function of Œ∑Œ≥1 (y) does not apply to binary outcomes.
Thus, we derive the ISNI formulas for other common cases of GLM. In the derivation below,

we reparameterize Œ∑Œ≥1 (y) = Œ≥11 (y + r2 y 2 ), where r2 = Œ≥12 /Œ≥11 . The ISNI formula for Œ∑Œ≥1 (y)
being a linear function can be obtained by setting r2 = 0.
Normal Distribution
For a normal linear model, Yi ‚àº N (xTi Œ≤, œÑ ), where œÑ = œÉ 2 . Then E(Y 2 )=E 2 (Y ) + œÑ , and
according to Equation (7), for a given value of r2 , the index for the regression parameter is:
ISNIr = ‚àíœÑÃÇ (

X

xi xTi )‚àí1

i:gi =1

X

(1 + 2r2 ¬µÃÇi )xi hi .

i:gi =0

where ¬µÃÇi = xTi Œ≤ÃÇ, and Œ≤ÃÇ and œÑÃÇ are the MAR estimates of Œ≤ and œÑ , respectively.
Poisson Distribution
For Poisson outcome, we have E(Y 2 )=E 2 (Y ) + E(Y ). Assuming the canonical log link:
ln E(Yi ) = ln ¬µi = xTi Œ≤, and the dispersion parameter œÑ = 1, then according to Equation
(7), for a given value of r2 , the index for the regression parameter is:
ISNIr = ‚àí(

X

i:gi =1

exp(xTi Œ≤ÃÇ)xi xTi )‚àí1

X

(1 + r2 + 2r2 ¬µÃÇi ) exp(xTi Œ≤ÃÇ)xi hi .

i:gi =0

where ¬µÃÇi = exp(xTi Œ≤ÃÇ), and Œ≤ÃÇ is the MAR estimate of Œ≤.
Gamma Distribution
Let the dispersion parameter œÑ = ŒΩ ‚àí1 , and œÑ also denotes the constant coefficient of
variation. For Gamma distribution, we have E(Y 2 ) =

ŒΩ+1
E(Y )2 .
ŒΩ

Assuming the canonical

T
reciprocal link: (E(yi ))‚àí1 = ¬µ‚àí1
i = xi Œ≤, then according to Equation (7), for a given value

of r2 , the index for the regression parameter is:
ISNIr =

ŒΩ + 1 T ‚àí2
1 X T ‚àí2 T ‚àí1 X
(1 + 2r2 ¬µÃÇi
(
(xi Œ≤ÃÇ) xi xi )
)(xi Œ≤ÃÇ) xi hi .
ŒΩÃÇ i:g =1
ŒΩ
i:g =0
i

i

where ¬µÃÇi = 1/xTi Œ≤ÃÇ, and Œ≤ÃÇ and ŒΩÃÇ are the MAR estimates of Œ≤ and ŒΩ, respectively.
23

24
Inverse Gaussian Distribution
For inverse Gaussian distribution, E(Y 2 ) = E(Y )2 + œÑ E(Y )3 , where a(œÑ ) = 1/œÑ . Assuming
T
the canonical link, E(Yi )‚àí2 = ¬µ‚àí2
i = xi Œ≤, then according to Equation (7), for a given value

of r2 , the index for the regression parameter is:
ISNIr = 2œÑÃÇ (

X

i:gi =1

(xTi Œ≤ÃÇ)‚àí3/2 xi xTi )‚àí1

X

(1 + 2r2 ¬µÃÇi + 3r2 œÑÃÇ ¬µÃÇ2i )(xTi Œ≤ÃÇ)‚àí3/2 xi hi .

i:gi =0

where ¬µÃÇi = (xTi Œ≤ÃÇ)‚àí2 , and Œ≤ÃÇ and œÑÃÇ are the MAR estimates of Œ≤ and œÑ , respectively.
References
Chen, Q., and Ibrahim, J.G.(2006), ‚ÄúSemiparametric Models for Missing Covariate and
Response Data in Regression Models,‚Äù Biometrics, 62:177‚Äì184.
Copas, J.B., and Li, H.G.(1997), ‚ÄúInference for non-random samples,‚Äù Journal of the Royal
Statistical Society B, 59:55‚Äì95.
Copas, J.B., and Eguchi, S.(2001), ‚ÄúLocal sensitivity approximations for selectivity bias,‚Äù
Journal of the Royal Statistical Society B, 63: 871‚Äì895.
Hastie, T. J., and Tibshirani, R.J.(1990), Generalized additive models, London: Chapman &
Hall.
Heitjan, D. F., and Rubin, D.B (1991), ‚ÄúIgnorability and coarse data,‚Äù Annals of Statistics,
19: 2244‚Äì2253.
Hirano, K., Ridder, G.W., and Rubin, D. B. (2001), ‚ÄúCombining Panels with Attrition and
Refreshment Samples,‚Äù Econometrica, 69, 1645‚Äì1659.
Kenward, M.G. (1998), ‚ÄúSelection models for repeated measurements with non-random
dropout: An illustration of sensitivity,‚Äù Statistics in Medicine, 17: 2723‚Äì2732.
Little, R.J.A.(1995), ‚ÄúModeling the drop-out mechanism in longitudinal studies,‚Äù Journal of
the American Statistical Association, 90: 1112‚Äì1121.
Ma, G., Troxel, A. B., and Heitjan, D. F. (2005), ‚ÄúAn Index of Local Sensitivity to
Nonignorable Dropout in Longitudinal Modeling,‚Äù Statistics in Medicine, 24,
2129‚Äì2150.
Mroz, T.A. (1987), ‚ÄúThe Sensitivity of an Empirical Model of Married Women‚Äôs Hours of
Work to Economic and Statistical Assumptions,‚Äù Econometrica, 55, 765‚Äì799.
Qian, Y. (2007), ‚ÄúDo National Patent Laws Stimulate Domestic Innovation in a Global
Patenting Environment? A Cross-Country Analysis of Pharmaceutical Patent
Protection, 1978-2002,‚Äù The Review of Economics and Statistics, 89(3), 436‚Äì453

Qian, Y., and Xie, H. (2010), ‚ÄúMeasuring the Impact of Nonignorability in Panel Data with
Non-monotone Nonresponse,‚Äù Journal of Applied Econometrics, in press.
Ravikuma, P., Lafferty, J., Liu, H. and Wasserman, L. (2009), ‚ÄúSparse Additive Models,‚Äù
Journal of the Royal Statistical Society: Series B, 71: 1009-1030.
Rubin, D.B. (1976), ‚ÄúInference and missing data,‚Äù Biometrika, 63: 581-592.
Scharfstein, D., Rotnizky, A., and Robins, J.M. (1999) ‚ÄúAdjusting for nonignorable dropout
using semi-parametric models,‚Äù Journal of the American Statistical Association, 94,
1096-1146.
Troxel, A.B. (1998), ‚ÄúA comparative analysis of quality of life data from a Southwest
Oncology Group randomized trial of advanced colorectal cancer,‚Äù Statistics in
Medicine, 17: 767‚Äì779.
Troxel, A. B., Harrington, D. P., and Lipsitz, S. R. (1998), ‚ÄúAnalysis of Longitudinal
Measurements with Non-ignorable Non-monotone Missing Values,‚Äù Applied
Statistics, 47, 425‚Äì438.
Troxel, A. B., Ma, G., and Heitjan, D. F. (2004), ‚ÄúAn Index of Local Sensitivity to
Nonignorability,‚Äù Statistica Sinica, 14: 1221‚Äì1237.
Vach, W., and Blettner, M. (1995) ‚ÄúLogistic regression with incompletely observed
categorical covariates - investigating the sensitivity against violation of the missing at
random assumption,‚Äù Statistics in Medicine, 14: 1315‚Äì1329.
Verbeke, G., Molenberghs, G., Thijs, H., Lesaffre, E., and Kenward, M.G. (2001) ‚ÄúSensitivity
analysis for nonrandom dropout: a local influence approach,‚Äù Biometrics, 57: 7‚Äì14.
Xie, H., and Heitjan, D. F. (2004), ‚ÄúSensitivity Analysis of Causal Inference in a Clinical
Trial Subject to Crossover,‚Äù Clinical Trials, 1: 21‚Äì30.
Xie, H. (2008), ‚ÄúA Local Sensitivity Analysis Approach to Longitudinal Non-Gaussian Data
with Non-ignorable Dropout,‚Äù Statistics in Medicine, 27: 3155‚Äì3177.
Xie, H. (2009), ‚ÄúBayesian Inference from Incomplete Longitudinal Data: A Simple Method
to Quantify Sensitivity to Nonignorable Dropout,‚Äù Statistics in Medicine,
28:2725‚Äì2747.
Xie, H., and Heitjan, D. F. (2009), ‚ÄúLocal sensitivity to nonignorability: Dependence on the
assumed dropout mechanism,‚Äù Statistics in Biopharmaceutical Research, 1(3):
243-257.
Zhang, J., and Heitjan, D.F. (2006), ‚ÄúA Simple Local Sensitivity Analysis Tool for
Nonignorable Coarsening: Application to Dependent Censoring,‚Äù Biometrics,
62:1260‚Äì1268.
Zhang, J., and Heitjan, D. F. (2007), ‚ÄúImpact of nonignorable coarsening on Bayesian
inference,‚Äù Biostatistics, 8: 722‚Äì743.

25

