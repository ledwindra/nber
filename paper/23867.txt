NBER WORKING PAPER SERIES

A THEORY OF EXPERIMENTERS
Abhijit Banerjee
Sylvain Chassang
Sergio Montero
Erik Snowberg
Working Paper 23867
http://www.nber.org/papers/w23867

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2017

We are grateful to Angus Deaton, Pascaline Dupas, Jeff Ely, Guido Imbens, Charles Manski,
Pablo Montagnes, Marco Ottaviani, Bruno Strulovici, Alexey Tetenov, Duncan Thomas, Chris
Udry, as well as audience members at Bocconi, the Cowles Econometric Conference (2016), the
ESSET Meeting at Gerzensee (2017), Emory, INSEAD, MIT, the NBER Development
Economics Summer Meeting (2016), the North-American Econometric Society Meeting (2016),
the SISL Conference at Caltech (2017), UBC, and the UCL/Cemmap workshop on Econometrics
for Public Policy (2016), for several helpful discussions. Chassang and Snowberg gratefully
acknowledge the support of NSF grant SES-1156154. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
Â© 2017 by Abhijit Banerjee, Sylvain Chassang, Sergio Montero, and Erik Snowberg. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including Â© notice, is given to the source.

A Theory of Experimenters
Abhijit Banerjee, Sylvain Chassang, Sergio Montero, and Erik Snowberg
NBER Working Paper No. 23867
September 2017
JEL No. C90,D81
ABSTRACT
This paper proposes a decision-theoretic framework for experiment design. We model
experimenters as ambiguity-averse decision-makers, who make trade-offs between subjective
expected performance and robustness. This framework accounts for experimenters' preference for
randomization, and clarifies the circumstances in which randomization is optimal: when the
available sample size is large enough or robustness is an important concern. We illustrate the
practical value of such a framework by studying the issue of rerandomization. Rerandomization
creates a trade-off between subjective performance and robustness. However, robustness loss
grows very slowly with the number of times one randomizes. This argues for rerandomizing in
most environments.
Abhijit Banerjee
Department of Economics, E52-540
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and NBER
banerjee@mit.edu
Sylvain Chassang
Department of Economics
New York University
19 West 4th Street
New York, NY 10012
and NBER
sylvain.chassang@gmail.com

Sergio Montero
Department of Political Science
Harkness Hall 320
University of Rochester
Rochester, NY 14627
smontero@rochester.edu
Erik Snowberg
Division of Humanities and Social Sciences
MC 228-77
California Institute of Technology
Pasadena, CA 91125
and NBER
snowberg@caltech.edu

1

Introduction

The proliferation of experiments in academia, business, and public policy has been accompanied by spirited debates about best practices for experiment design and the statistical
analysis of experimental results. Topics of debate include pre-registration of experiment designs, pre-analysis plans, the pros and cons of rerandomization, clustering, stratification, and
statistical significance testing (Bruhn and McKenzie, 2009; Deaton, 2010; Duflo et al., 2008;
Humphreys et al., 2013; Imbens, 2010; Olken, 2015; Athey and Imbens, 2016; Benjamin et
al., 2017). At the heart of these debates are differingâ€”usually implicitâ€”models of knowledge
generation and how people interpret experimental evidence. This paper seeks to provide a
decision-theoretic framework that may be able to guide, and help resolve, these debates. We
show that our framework is consistent with important elements of observed experimental
practice. We then use our framework to shed light on one of the less contentious open questions of experimental design, rerandomization. Finally, we discuss how our framework might
be used to address other questions about experiment design.
Unfortunately, models of experimentation and information acquisition fail to explain why
researchers (almost always) run randomized controlled trials (RCTs; see Kasy, 2016).1 This
is due to modeling decision-makers as subjective expected utility maximizers (Savage, 1954).
As RCTs are mixed strategies over experimental assignments, they can never be strictly
optimal for such a decision-maker.
To overcome this limitation, we model a Bayesian experimenter facing an adversarial
audience. This is equivalent to assuming an ambiguity-averse decision-maker with standard
maxmin preferences (Gilboa and Schmeidler, 1989). In our formulation, the decision-maker
maximizes a mixture of her own subjective expected utility term and the welfare of an
adversarial audience with non-common priors. Examples of such audiences abound: the
1

For seminal contributions to the literature on experimentation and information acquisition Rothschild
(1974); Grossman and Stiglitz (1980); Aghion et al. (1991); Bergemann and VaÌˆlimaÌˆki (1996); Persico (2000);
Bergemann and VaÌˆlimaÌˆki (2002, 2006).

1

Food and Drug Administration for drug trials, seminar audiences and journal referees for
research papers, and governments or NGOs for development proposals.2
The paper reports two main sets of results. The first set of results shows that RCTs can be
optimal for a decision-maker facing an adversarial audience, and clarifies the circumstances
in which this is the case. If the decision-maker places non-zero weight on satisfying her
adversarial audience, then, for sufficiently large sample sizes, it is always strictly optimal for
the decision-maker to use a RCT. Indeed, as the sample size N grows large, RCTs permit
âˆš
robust prior-free inference, and achieve assignment losses of order 1/ N . On the other hand,
deterministic experiments are generically strictly optimal when the sample size is small and
the decision-maker puts sufficiently high weight on her subjective expected utility.
This set of results accords with the observed heterogeneity of experimental practice. Randomized experiments tend to be used by decision-makers who put a high value on convincing
an adversarial audience (scientists, pharmaceutical companies), or when the decision-maker
can afford large samples (A/B testing in online marketing). Whenever data points are expensive and the decision-maker puts little weight on satisfying an adversarial audience, optimal
experiments are deterministic as such a design optimizes the informational value of each
acquired data point (new product launches in select markets, preliminary medical research
on diseases that would otherwise result in quick and certain death).
The second set of results applies our framework to the question of whether experimenters
should rerandomize to improve covariate balance between treatment and control groups.
Rerandomization draws multiple treatment assignments, then chooses the one that maximizes balance. For example, a medical researcher may want to ensure that treatment and
control groups are similar in terms of gender, age, race, and baseline health variables such
as blood pressure and weight (Morgan and Rubin, 2012). Despite the ease of using rerandomization to improve balance, researchers are concerned that it may adversely affect the
2

The audience could also be another side of the decision-maker herself, as ambiguity aversion is a natural
way to model self-doubt.

2

reliability of findings (Bruhn and McKenzie, 2009).
The trade-offs at the heart of rerandomization are succinctly captured in our framework.
Successive rerandomizations improve balance, as captured by the subjective expected utility component of preferences. However, rerandomization reduces robustness, as captured
by the adversarial component of preferences. In the extreme case where the allocation is
rerandomized until perfect balance is achieved, the allocation is effectively deterministic
and the adversarial term is always bounded away from first-best. In contrast, robustness
losses are vanishing in sample size N when the number of rerandomizations grows linearly
or sublinearly in N .
Our framework builds on a long line of work in statistics, starting with Wald (1950).
Variants of Waldâ€™s framework have more recently been used in economics and econometrics
to study questions of identification and model uncertainty (Manski, 2004, 2009; Kitagawa and
Tetenov, 2015; Marinacci, 2015). However, prior work has not sought to provide a positive
and normative model of experimenters.3 The prior literature falls into two broad groups:
one focuses on ambiguity aversion, the other on regret minimization. While our main results
are stated in an ambiguity-aversion framework, in Section 5 we show they extend to a regretminimization framework. This is important as Tetenov (2012) shows that asymmetric regret
minimization is sufficient for explaining the standard practice of null-hypothesis statistical
testing (NHST) using t-statistics. Our basic insights therefore apply directly to classical
statistical inference as well as to our more conventional decision-theoretic model.
The paper is structured as follows. Section 2 introduces our framework. Section 3 delineates the forces that determine whether running a randomized or deterministic experiment
is optimal. Section 4 studies the trade-offs involved in rerandomization. Section 5 shows
that our results extend to reference-dependent preferences, better suited to explain the use
of t-statistics in decision-making. Section 6 discusses other applications for our framework,
3

This paper is also related to the dormant literature in multi-Bayesian statistical decision theory (Weerahandi and Zidek, 1981, 1983). In these models, Bayesians with conflicting preferences adopt random decision
rules, rather than randomized experiments.

3

including subgroup analysis. Appendix A explores the use of reference-dependent preferences
as a foundation for t-statistics. Proofs are contained in Appendix B. Appendix C presents
simulations.

2

A Framework for Studying Experiment Design

Decisions and payoffs. A decision-maker chooses whether or not to implement a policy
that provides a treatment Ï„ âˆˆ {0, 1} to a unit mass of individuals. For simplicity, we assume
that the final policy choice a âˆˆ {0, 1} is all-or-nothing and sets Ï„ = a for all individuals.4
Potential outcomes for an individual with treatment status Ï„ are random variables Y Ï„ âˆˆ
{0, 1}; Y = 1 is referred to as a success. Each individual has observable covariates x âˆˆ X âŠ‚
Rm that affect the distribution of outcomes Y . X is finite, and the distribution q âˆˆ âˆ†(X) of
covariates in the population is known and has full support. The probability of success given
covariate x is denoted by pÏ„x â‰¡ prob(Y Ï„ = 1|x), and, conditional on x, outcomes are i.i.d.
The state of the world is described by the finite-dimensional vector p = (p0x , p1x )xâˆˆX âˆˆ
[0, 1]2X â‰¡ P of success probabilities pÏ„x conditional on treatment status Ï„ âˆˆ {0, 1} and
covariates x. Note that state-space P is compact, convex, and finite-dimensional. Given a
state p and a policy decision a âˆˆ {0, 1}, the decision-makerâ€™s payoff u(p, a) is
u(p, a) â‰¡ Ep Y a =

X

q(x)pax .

xâˆˆX

Although covariates x are observable, our framework implicitly allows for unobservable
R
characteristics. Denoting unobserved characteristics by z, we would have pÏ„x = pÏ„x,z dF (z|x).
Large shifts in correlations between x and z are captured by allowing the mapping x 7â†’ px
to be discontinuous in x.
4

See Section 6 for a discussion of sub-group analysis and targeting.

4

Experiments and strategies. To maximize her odds of making the correct policy choice,
the decision-maker can run an experiment on N participants. For simplicity, we assume that
N is even and exogenously given. Formally, an experiment is a tuple e = (xi , Ï„i )iâˆˆ{1,...,N } âˆˆ
(X Ã— {0, 1})N â‰¡ E. Experiment e generates outcome data y = (yi )iâˆˆ{1,...,N } âˆˆ {0, 1}N â‰¡ Y,
with yi s independent realizations of YiÏ„i given (xi , Ï„i ). Throughout, we assume that N < 2|X|,
even as we increase N . A natural special case is unique individuals: |X| = N and q(X) =

1
.
|X|

This corresponds to settings where subjects are fixed, and the decision-maker must choose
a treatment assignment.
The decision-makerâ€™s strategy consists of both an experimental design E âˆˆ âˆ†(E), which
is a mixed strategy over experimental assignments, and an allocation rule Î± : E Ã— Y â†’
âˆ†({0, 1}), which maps experimental data (e, y) to policy decisions a âˆˆ {0, 1}. We denote by
A the set of such mappings.
Preferences. We consider an ambiguity-averse decision-maker with standard maxmin
preferences (Gilboa and Schmeidler, 1989). We reinterpret these preferences in a way that
is convenient for comparative static exercises. Under this interpretation, the decision-maker
has her own prior h0 and faces an adversarial audience of Bayesian stakeholders with noncommon priors.5 She chooses a strategy (E, Î±) to solve

U (E, Î±) â‰¡ Î»Eh0 ,E [u(p, Î±(e, y))] + (1 âˆ’ Î») min Eh,E [u(p, Î±(e, y))],
hâˆˆH

(DP)

where H is a convex set of priors h âˆˆ âˆ†(P ) over states p âˆˆ P , and represents the set of
priors belonging to members of the audience. The decision-maker places weight Î» on her
own subjective utility, and weight 1 âˆ’ Î» on the utility of her audience.6 When Î» = 1, these
5

If the audience entertained a common prior h, then the decision problem would boil down to subjective
expected utility maximization for the mixed prior Î»h0 + (1 âˆ’ Î»)h.
6
Whenever h0 âˆˆ H, increasing 1 âˆ’ Î» also corresponds to increasing the set of priors that the decisionmaker entertains as plausible. If audience members have veto power and enjoy a common outside option,
then 1âˆ’Î»
Î» is the Lagrange multiplier placed on the audienceâ€™s individual rationality constraint.

5

preferences coincide with standard subjective expected utility maximization. We sometimes
refer to this case as Bayesian.
Equivalent experiments. As successes are independent conditional on covariates, experiments that differ only by a permutation of participants with identical covariates are
equivalent from a decision-making perspective.
Definition 1 (equivalent experiments). Two experiments e = (xi , Ï„i )iâˆˆ{1,...,N } and e0 =
(x0i , Ï„i0 )iâˆˆ{1,...,N } are equivalent, denoted by e âˆ¼ e0 , if there exists a permutation Ïƒ : {1, . . . , N } â†’
0
) for all i. The equivalence
{1, . . . , N } of the participantsâ€™ labels such that (xi , Ï„i ) = (x0Ïƒ(i) , Ï„Ïƒ(i)

class of an experiment e is denoted by [e].7 We denote by [E] the partition of possible experiments in equivalence classes. We say that two experimental designs E and E 0 are equivalent,
denoted by E âˆ¼ E 0 , if they induce the same distribution over [E].
Lemma 1. Whenever E âˆ¼ E 0 , max U (E, Î±) = max U (E 0 , Î±).
Î±âˆˆA

Î±âˆˆA

All proofs can be found in Appendix B.
Standard RCTs. As many of our results deal with randomized controlled trials (RCTs),
it is useful to define these explicitly. A standard RCT that assigns a share Ï€ âˆˆ (0, 1) of
participants to treatment Ï„ = 1, corresponds to a strategy (Erct , Î±rct ):
â€¢ Erct samples N exchangeable participants labelled by i âˆˆ {1, Â· Â· Â· , N }, with covariates
(xi )iâˆˆ{1,Â·Â·Â· ,N } drawn according to the distribution of observable covariates q;
â€¢ Erct assigns treatment Ï„i = 1iâ‰¤Ï€N ;
 PN
PN
â€¢ Î±rct (e, y) â‰¡ 1yÌ‚1 â‰¥yÌ‚0 , where yÌ‚ Ï„ â‰¡
i=1 yi 1Ï„i =Ï„
i=1 1Ï„i =Ï„ is the mean outcome for
participants with treatment status Ï„ .
7

It is convenient to include distributions E with support in [e] in the equivalence class of e.

6

2.1

Assumption about the Audience

We impose the following limited extrapolation condition on X, N , and H: Denote by
P
pa â‰¡ xâˆˆX q(x)pax the expected probability of success given policy a âˆˆ {0, 1}. Given an
experiment e = (Ï„i , xi )iâˆˆ{1,Â·Â·Â· ,N } , denote by pe â‰¡ (pÏ„xii )iâˆˆ{1,Â·Â·Â· ,N } the subset of success rates for
participants in the experiment. Vector pe is an upper bound to the information generated
by experiment e in the sense of Blackwell (1953).
Assumption 1 (limited extrapolation). There exists Î¾ > 0 such that, for all e âˆˆ E, there
exists a prior h âˆˆ arg minhâˆˆH Eh (maxaâˆˆ{0,1} pa ) such that, for almost every pe ,

min Eh



a

0



max p âˆ’ p pe , Eh

aâˆˆ{0,1}



a

1

max p âˆ’ p pe

aâˆˆ{0,1}


> Î¾.

This imposes two important constraints on the members of the adversarial audience.
First, the information from any experiment is insufficient to fully convince every single
audience member (represented by some prior h âˆˆ H) of the correct policy a âˆˆ {0, 1}.
Second, audience members cannot be arbitrarily pessimistic; they cannot be certain that
p1 = p0 = 0.
Note that the requirement that N < 2|X| ensures that Assumption 1 can be satisfied.
We show in Section 5 that Assumption 1 is dispensable when the decision-maker exhibits
regret aversion.

3
3.1

Optimal Design and Randomization
Bayesian Experimentation

When Î» = 1, the decision-maker is a standard subjective expected utility maximizer. In this
case, it is known that deterministic experiments are weakly optimal. In fact, we show that

7

for generically every priorâ€”that is, for an open and dense set of priors under an appropriate
distanceâ€”deterministic experiments are strictly optimal when Î» is close to 1.8
Proposition 2 (near-Bayesians do not randomize). If Î» = 1, then for every prior h0 , there
exists a deterministic experiment eâˆ— solving (DP).
For generically every prior h0 , there exist Î» âˆˆ (0, 1) and a unique equivalence class of
experiments [eâˆ— ] such that for all Î» > Î», a (potentially mixed) experiment E âˆˆ âˆ†(E) solves
(DP) if and only if support E âŠ‚ [eâˆ— ].
In recent work, Kasy (2016) uses a similar result to argue that RCTs may be suboptimal.
However, his key point is that deterministic assignments are much more likely to achieve
covariate balance between treatment and control groups. Instead, we suggest that Proposition 2 shows the limits of subjective expected utility maximization as a positive model
of experimenters. We argue that the decision problem defined by (DP) is more successful
at explaining the range of information acquisition strategies observed in practice. Later, in
Section 4, we study rerandomization as a non-deterministic alternative to improving balance.

3.2

Adversarial Experimentation

We now examine the case where the experimenter cares about her audienceâ€™s preferences.
Proposition 3. Take weight Î» âˆˆ (0, 1) as given. There exists N such that for all N â‰¥ N ,
any optimal experiment is randomized. More precisely, the following hold:
(i) For any N , any optimal experiment E âˆ— satisfies
 r
ln 2
max min Eh,E âˆ— [u(p, Î±(e, y))] â‰¥ min Eh max u(p, a) âˆ’
.
Î±âˆˆA hâˆˆH
hâˆˆH
aâˆˆ{0,1}
N


8

We use the uniform norm on distributions: d(h, h0 ) â‰¡ sup

AâŠ‚P
A meas.

|h(A) âˆ’ h0 (A)|.

8

(ii) For any N , all deterministic experiments e âˆˆ E are bounded away from
first-best:

âˆ€e âˆˆ E,

max min Eh,e [u(p, Î±(e, y))] < min Eh
Î±âˆˆA hâˆˆH

hâˆˆH


max u(p, a) âˆ’ Î¾,

aâˆˆ{0,1}

where Î¾ is defined in Assumption 1.
Point (i) shows that the efficiency loss of the optimal experiment compared to the firstâˆš
best decision is bounded above by a term of order 1/ N . Point (ii) shows that the loss
from a deterministic experiment is bounded below by Î¾, where Î¾ is bounded away from zero,
and independent of N . Thus, as N grows, the optimal experiment cannot be deterministic;
therefore, it must be randomized.
The rationale for randomization can be understood by observing that the decision-maker
is playing a zero-sum game against nature. The decision-maker first chooses an experimental
design and a decision rule. Nature then picks the prior which maximizes the chance of the
experimenter choosing the wrong policy, given the decision-makerâ€™s experiment design. If
there is a known pattern in the choice of experimental assignments, nature can exploit it
to lower the decision-makerâ€™s payoff. Randomization eliminates patterns that nature can
exploit. This is related to the fact that ambiguity-averse agents may have preferences for
randomization even if they exhibit risk-aversion over known lotteries (Saito, 2015).9

3.3

RCTs as a Rule of Thumb

A corollary of the proof of Proposition 3 is that the standard RCT (Erct , Î±rct ) (defined in
Section 2) provides a near optimal solution to decision problem (DP).
9

A key modeling choice here is that nature cannot observe the outcome of the decision-makerâ€™s randomization before picking a prior. Kasy (2016) assumes that nature observes the outcome of the experimenterâ€™s
randomization and then picks a prior, which renders randomization useless. We believe our assumption is
more consistent with research practice: Referees typically complain about research design, not about why
a particular observation ended up in the treatment or control group. The exception is when there is an
extreme imbalance between treatment and control on a covariate the referee considers important.

9

Corollary 1. Experimentation policy (Erct , Î±rct ) is such that for all priors h âˆˆ âˆ†([0, 1]X ),

Eh,Erct [u(p, Î±rct (e, y))] â‰¥ Eh

 s
ln 2
,
max u(p, a) âˆ’
aâˆˆ{0,1}
2Ï€N

where Ï€ â‰¡ min{Ï€, 1 âˆ’ Ï€}.
As this result holds for every prior h, standard RCTs allow approximately optimal
decision-making for both Bayesian and ambiguity-averse decision-makers. Thus, an RCT
can be interpreted as a rule-of-thumb that avoids the complexity of specifying the space of
priors in decision problem (DP) and deriving an optimal solution.
Note that Corollary 1 holds even though there may be arbitrarily many covariates, some
of which have a significant impact on treatment effects, and exact balance cannot be ensured.
As outcomes are bounded, it is not possible for rareâ€”and therefore hard to balanceâ€”
covariate realizations to have a substantial impact on payoffs. Balance in expectation is
sufficient to guarantee approximately optimal decision-making.

3.4

Positive Implications

Figure 1 maps out some positive implications of Propositions 2 and 3 for experiment design.
When sample points are scarce, or when the decision-maker does not put much weight
on satisfying her audience (Î» close to 1), the optimal experiment will be deterministic,
driven by prior h0 . That is, the experimenter will focus on assigning treatment and control
observations to the participants from whom she expects to learn the most. This is the case,
for example, when a firm is implementing a costly new process at a few production sites:
The firm will focus on the places where it can learn the most. This may, for example,
involve assigning treatment to sites where success is the least likely (Banerjee et al., 2017).
Similarly, early stage medical research often does not feature randomizationâ€”especially when
treating conditions known to result in severe disability or death.10 In this case, there is no
10

For recent examples, see Harmon (2016) and Yuhas (2016).

10

Figure 1: When to randomize? Theory matches broad patterns.
1âˆ’Î»
Î»
Drug Approval

Development Economics

Early Stage
Medcal Research

Randomize

Product Design

Do Not
Randomize

Online Marketing

Political Speech

N
adversarial audience. Scientists are trying to learn whether a particular research direction is
worth exploring.
When the decision-maker must instead satisfy a sufficiently adversarial audience, or she
has a sufficiently large sample, she will randomize. The former is the case in scientific
research. The latter is the case for firms doing A/B testing online. Although the firm only
needs to convince itself of the effectiveness of a particular ad or UI design, observations
are so plentiful that randomization is used to effectively address internal concerns about
robustness. This is also the case for later stage medical research seeking regulatory approval:
government regulators and investors form the adversarial audience for pharmaceutical and
medical device companies.

4

Rerandomization as a Refined Rule-of-Thumb

Having established that our framework makes reasonable positive predictions about experimental practice, we now use it to shed light on an open question of experimental design:
11

rerandomization. As noted in Section 3.3, a standard RCT is only a near-optimal solution
to (DP). In particular, it may sometimes result in an unbalanced sample that permits little
real opportunity for learning.
This could be avoided by computing an optimal solution to (DP). For appropriate problems, the solution is a distribution over possible assignments that puts greater weight on
balanced assignments, and may put zero weight on excessively unbalanced assignments.
This distribution maintains sufficient randomization to ensure robust decision-making. Unfortunately, it is implausible that one could carefully and reliably elicit full preferences from
experimenters and their audience at the onset of an experiment. Computing an optimal solution to (DP) is a tricky exercise, and a well designed rule-of-thumb may be more valuable.
In practice, experimenters resolve this difficulty through rerandomization: they repeatedly randomize until they obtain an assignment that satisfies their balance objectives. As
Bruhn and McKenzie (2009) highlight, this practice is widespread, poorly theorized andâ€”
in principleâ€”a substantial deviation from one-shot randomization. Our framework can be
used to clarify the trade-offs involved in rerandomization. We argue that, used in moderation, rerandomization is a valuable rule-of-thumb that provides a flexible way to improve
balanceâ€”and/or reflect ancillary design objectivesâ€”without sacrificing significant decisionmaking robustness. Compared to other common approaches to ensuring balance, it has the
added benefit of carefully controlling losses in robustness.

4.1

K-rerandomized Experiments

The objective of the decision-maker, as described by (DP), can be rewritten as

max Î»EE [B(e)] + (1 âˆ’ Î»)R(E).

Eâˆˆâˆ†(E)

Decision problem (DP) sets B(e) â‰¡ Eh0 [u(p, Î±(e, y))|e], capturing â€œbalanceâ€, and R(E) â‰¡
minhâˆˆH Eh,E [u(p, Î±(e, y))], capturing robustness. We re-write (DP) in this form to emphasize
12

that our results hold for any objective function B(e) the experimenter, or other stakeholders,
might have.
With this mapping, we define a K-rerandomized experiment EK as follows:
1. Independently draw a set of K assignments {e1 , Â· Â· Â· , eK } with each ek = (xi , Ï„i,k ) such
that a fraction Ï€ âˆˆ (0, 1) of participants receives treatment Ï„ = 1.
2. Select the assignment eâˆ—K âˆˆ argmaxeâˆˆ{e1 ,Â·Â·Â· ,eK } B(e) that maximizes balance, breaking
ties with a uniform draw.
3. Run experiment eâˆ—K , generating outcomes yK .
Ï„
is the mean outcome
4. Policy is chosen according to Î±rct (eâˆ—K , yK ) â‰¡ 1yÌ‚K1 â‰¥yÌ‚K0 , where yÌ‚K

for participants with treatment status Ï„ .
Rerandomization protocols may also use a stopping time to endogenously pick the number of randomizations (Morgan and Rubin, 2012). Provided the stopping time has an upper
bound K, all our results apply for this bound. However, our results show open-ended stopping times may lead to significant robustness losses.

4.2

The Trade-off of Rerandomization

For any balance function, the gains from rerandomization are immediately apparent.
Remark 1. B(eâˆ—K ) first-order stochastically dominates B(eâˆ—Kâˆ’1 ).
The value of balance is formally and intuitively clear. In the context of statistical inference, Morgan and Rubin (2012) study the value of rerandomization when B(e) = âˆ’M (e),
in which M (e) is the Mahalanobis distance between the treatment and control samples.
They show that rerandomization leads to significantly more precise estimates of treatment
effects when outcomes come from a linear Gaussian model.11 Bungi et al. (2016) show, more
11

The Mahalanobis distanceâ€”defined as M (e) â‰¡ (xÌ‚1 âˆ’ xÌ‚0 )0 [cov(xÌ‚1 âˆ’ xÌ‚0 )]âˆ’1 (xÌ‚1 âˆ’ xÌ‚0 )â€”is commonly used in
multivariate matching (Rubin, 1980; Cochrane and Rubin, 1973; Rubin, 1979). Outcomes follow a Gaussian
linear model when they are defined by YiÏ„i = hxi , Î²i + Î´Ï„i + ÏƒÎµi , with Îµi âˆ¼ N (0, 1).

13

generally, that balance from symmetric stratification procedures also substantially increases
precision.
The Cost of Rerandomization. Although rerandomization provides clear benefits in
terms of improved balance, there are common, but vague, concerns about its potential costs.
As Bruhn and McKenzie (2009) document, this leads many researchers to use rerandomization but not report it. Our framework clarifies the issue by showing that rerandomization can
reduce robustness, but that this cost is relevant only when the number of rerandomizations
is very large:
Proposition 4. There exists Ï > 0 such that for all N , if K â‰¥ 2N , then

max min Eh,EK [u(p, Î±(e, y))] < min Eh
Î±

hâˆˆH

hâˆˆH


max u(p, a) âˆ’ ÏÎ¾.

aâˆˆ{0,1}

Intuitively, when K is sufficiently large, the allocation becomes essentially deterministic.
Proposition 3 implies that this precludes first-best robustness.12 However, the number of
rerandomizations K needed to cause fixed losses in robustness is exponential in the sample
size.
A moderate number of rerandomizations has little impact on robustness:
Proposition 5. Given K â‰¥ 2, consider a rerandomized experiment EK assigning treatment
to a proportion Ï€ âˆˆ (0, 1) of participants. Then for all h âˆˆ H,
 s
ln K
Eh,EK [u(p, Î±RCT (e, y))] â‰¥ Eh max u(p, a) âˆ’
,
aâˆˆ{0,1}
Ï€N


where Ï€ â‰¡ min{Ï€, 1 âˆ’ Ï€}.
12

The process by which a realized experiment e is reached is irrelevant for a Bayesian: h0 (p | e, y, e âˆ¼ Î´e ) =
h0 (p | e, y, e âˆ¼ Erct ) = h0 (p | e, y, e âˆ¼ EK ), in which Î´e denotes the deterministic experiment e.

14

As the additional loss from rerandomization is of order

âˆš

ln K, which is less than 5 for

K â‰¤ 1010 , K linear in N does not change the order of magnitude of robustness losses. This
suggests the following guideline:
Suggested Guideline. Set K â‰¤ N .13
Remark 1 and Propositions 4 and 5 clarify the pros and cons of rerandomization, but
do not provide a hard and fast rule. Our suggested guideline defines a range of acceptable
behavior that limits potential robustness-losses from rerandomization. Within this range,
different decision-makers may choose differently. A Bayesian decision-maker using the linear
Gaussian model studied by Morgan and Rubin (2012) should choose the largest possible
number of rerandomizations. An ambiguity-averse decision-maker entertaining a symmetric
set of possible priors may prefer to randomize only once (see Appendix C.1 for a stylized
numerical example).

4.3

Other Approaches for Increasing Balance

Rerandomization can be seen as an algorithm to bias the distribution of experimental assignments towards high-balance ones. It is simpler than many matching algorithms, especially
when one wants to establish balance on multiple continuous covariates. Moreover, as our
results hold for any balance function B(e), they are also true if this function is specified after
seeing the K possible rerandomizations. As we highlight in Section 6, this degree of freedom
may be very useful in practice as a way to respond to the preferences of stakeholders and
implementation partners.
It is instructive to relate rerandomization to an experiment design that ensures balance
in a more direct way: by randomizing conditional on strata. Formally, the experimenter
first defines a set of acceptable assignments Eâ€  âŠ‚ E. Then, an assignment is drawn from
13

The probability that the rerandomized assignment will be in the top 5% most balanced is 1âˆ’0.95K > 99%
when K = 100. Thus, experimenters may wish to limit the number of rerandomizations to 100, even if N is
much larger (Banerjee et al., 2017).

15

Eâ€  with uniform probability. This procedure involves two difficulties. First, if Eâ€  is defined implicitlyâ€”for example, the set of all assignments whose balance is above a certain
thresholdâ€”computing it may be quite difficult. Second, this procedure obfuscates potential
robustness costs. Indeed, if the set of acceptable assignments Eâ€  turns out to be small,
the intuition underlying Proposition 4 suggests that robustness will be bounded away from
first-best.14
Our framework can be used to explicitly evaluate the potential robustness costs of such
approaches. Note that the procedure described above sets B(e) â‰¡ 1eâˆˆEâ€  . Define EEâ€  as the
randomized experiment that picks an assignment e âˆˆ Eâ€  with uniform probability. Finally,
let pEâ€  > 0 denote the probability that a uniformly chosen assignment e âˆˆ E belongs to
Eâ€  . Note that computing pâ€  may be difficult, especially for complex or opaque matching
algorithms. In that case, Monte Carlo simulations may provide an approximate value for
pEâ€  .
Corollary 2. For all h âˆˆ H,

Eh,EEâ€  [u(p, Î±RCT (e, y))] â‰¥ Eh


max u(p, a) âˆ’ min

aâˆˆ{0,1}

1
Kâ€  âˆˆN 1 âˆ’ (1 âˆ’ pâ€  )Kâ€ 

s

ln Kâ€ 
Ï€N

This implies that a stratification or matching procedure will come at a limited cost of
robustness if an acceptable assignment can be reached with high probability within a small
number of rerandomizations.

5

Extension to Reference Dependent Preferences

14

This may occur when an experimenter uses a matching algorithm to achieve balance across several
continuous covariates. Note that stratification and matching can considerably improve the precision of
estimates (Athey and Imbens, 2016; Bungi et al., 2016). However, it is important to assess whether a proposed
design limits the set of possible assignments so severely that it causes significant losses in robustness.

16

It has been shown that decision problem (DP) does not rationalize the use of null-hypothesis
statistical testing (NHST) using t-statistics. For this, we need reference-dependent preferences with the status quo as the reference point (Tetenov, 2012).15 As most researchers use
NHST, it is important to extend our main results to such reference-dependent preferences.
Interestingly, this extension also allows us to dispense with the limited extrapolation
assumption. One of the key features of this assumption is to ensure that learning is still
possible even for the worst-case prior for any experimental design. Without this constraint,
the worst prior would always put unit mass on the probability of success being zero, regardless of the policy choice. However, when considering regret minimization, nature favors
environments in which the decision-maker can make an incorrect decisionâ€”otherwise there
is no possibility of regret. As a result, under regret aversion, there is always a value for
information even at the unconstrained worst-case prior.
Let âˆ†a â‰¡ pa âˆ’ p1âˆ’a denote true expected outcome differences between action a âˆˆ {0, 1}
and the alternative. We consider a decision-maker who seeks to solve
max Î»Eh0 [wÎ± (âˆ†Î± )] + (1 âˆ’ Î») min Eh [wÎ± (âˆ†Î± )].
E,Î±

hâˆˆH

(DP0 )

in which, for all a âˆˆ {0, 1},
wa (âˆ†a ) = âˆ†a + Îºa Ã— âˆ†a 1âˆ†a <0 ,

with Îºa > 0.

In words, the decision-maker cares about improvements rather than absolute levels, and is
Îºa > 0 implies she is particularly averse to making wrong choices. Note that H in (DP0 ) is
now the set of all priors over P . For simplicity, we assume N = |X|, so that each subject is
unique.16
15

See Appendix A as well as Tetenov (2012) for micro-foundations of the standard approach to NHST.
Our results extend to the case when N < 2|X|, as before. Moreover, our analysis applies more generally
to functions wa that are strictly increasing and concave in âˆ†a . We restrict wa to the form above to clarify
the relationship with the prior literature.
16

17

We show in Appendix A that this class of preferences rationalizes the use of t-statistics
whenever Îº1 > Îº0 , that is, when a preference for success is not symmetric with respect to
the policy choice a. In addition it coincides with pure regret-averse preferences when Îº0 and
Îº1 grow large.17
The conditions under which deterministic and randomized experiments are optimal are
qualitatively unchanged:
Proposition 6. Consider a decision-maker solving Problem (DP0 ):
(i) For generically every prior h0 , there exists Î» âˆˆ (0, 1) such that, for all Î» > Î»,
it is optimal to use a deterministic experiment.
(ii) For every h0 and every Î» âˆˆ (0, 1), as N becomes arbitrarily large, deterministic experiments remain bounded away from efficiency, and randomized experiments are strictly optimal.
Additionally, the near-optimality of K-randomized trials continues to hold:
Proposition 7. There exists M > 0 such that for every prior h âˆˆ H,


Eh wa (âˆ†a ) e âˆ¼ EK , a âˆ¼ Î±RCT â‰¥ Eh

6



s

ln K
.
max wa (âˆ†a ) âˆ’ M
aâˆˆ{0,1}
Ï€N

Discussion

The ambition of this paper is to propose a decision-theoretic framework that takes seriously
the concerns of experimenters, and can help clarify current experimental practices as well as
resolve open debates. In this final section, we discuss further implications of our framework,
and preview other possible applications.
17

Regret-averse preferences have received extensive attention from statisticians and econometricians (Wald,
1950; Manski, 2004, 2009; Kitagawa and Tetenov, 2015). However, failure of transitivity can reduce their
appeal (see, for example, Marinacci, 2015).

18

Why randomize? Our analysis clarifies the circumstances in which randomization is optimal: when robustness matters and the sample size is large. When robustness considerations
are motivated by an adversarial audience with non-common priors, randomization can be
interpreted as a way to let parties with diverging priors agree on a process. Indeed, stakeholders with divergent priors need not be satisfied by any given deterministic experiment:
there may always exist a prior under which the experimentâ€™s design is flawed. In contrast,
running a randomized experiment guarantees each stakeholder that, in expectation, the final
decision will be optimal from her perspective. However, there is a tension here: when the
assignment is revealed, some stakeholders may wish to change it ex post.
Whether robustness is motivated by an external audience, or internal doubts, our analysis
highlights the importance of actually randomizing. An experimenter that adopts a protocol
that is only â€œnearlyâ€ random, such as assignment based on time of day of an experimental
session (see Green and Tusicisny, 2012, for a critique), or the first letter of an experimental
subjectâ€™s name (as was the case in the deworming study of Miguel and Kremer, 2004; see
Deaton, 2010 for a critique), can always find a skeptical prior in her audience. Randomization
provides a defense against the most skeptical priors; near-randomization does not.
Rerandomization as an additional degree of freedom. Our framework also clarifies
the trade-offs of rerandomization: it improves subjective balance, but comes at the expense of
robustness. However, the loss in robustness from rerandomization grows slowly in the number
of times we rerandomize. As a result, applied in moderation, rerandomization provides a
useful degree of freedom for experimenters who have subjective preferences over balance.
While pre-specifying the objective function used in rerandomization has the added benefit
of permitting randomization inference tests (Fisher, 1935; Morgan and Rubin, 2012; Young,
2016,; see Appendix C.2.3 for examples), we emphasize that it is not a requirement for our
results to hold. Indeed, Proposition 5 remains true if the balance function B(e) is specified
after experimental assignments {e1 , Â· Â· Â· , eK } are drawn.
19

This suggests a novel use of rerandomization: as a way to let stakeholders, such as implementation partners, express preferences over assignments. The experimenter may draw K
treatment assignments in advance and let her implementation partners pick their preferred
assignment. This process could be used with any stakeholder, including regulators, funders,
or the communities from which experimental participants are drawn. These stakeholders
often have equity concerns and distributional preferences. They may further care about
targeting treatment to those they believe will benefit the most, or may simply dislike randomization and wish to exert some control over assignment. The ability to at least partially
accommodate the preferences of stakeholders by letting them pick their preferred assignment
among K options may help build good will and ensure cooperation.18
Extending the framework: Subgroup analysis. While we believe that our framework
is well suited to extensions designed to answer other important questions about experimental
practice. We illustrate this by providing an outline of how our framework may be extended
to address another important methodological question: sub-group analysis.
Consider a partition of the population into subgroups G âˆˆ G where G is a partition of
X. Treatment and policy Î± may now be targeted by subgroup. Assignment Î± becomes
a mapping from experimental outcomes (e, y) to a distribution over targeted assignments
a = (aG )GâˆˆG âˆˆ {0, 1}G . The decision-makerâ€™s problem is now:
max Î»Eh0 ,E,Î± [u(p, a)] + (1 âˆ’ Î») min Eh,E,Î± [u(p, a)]
E,Î±

where u(p, a) =

P

GâˆˆG

P

xâˆˆG

hâˆˆH

(DP00 )

q(x)paxG .

This framework can provide guidelines on how finely to target treatment as a function
of the data and sample size. An ambiguity-averse decision-maker would not want to tailor
assignments based on within-group treatment effects when the number of groups G âˆˆ G is
18

Constraints from implementation partners led Miguel and Kremer (2004) to assign treatment alphabetically, eliciting concerns from Deaton (2010).

20

of order N . If treatment effects are constant across groups, targeting leads to inefficient
treatment choices for a non-vanishing share of the population. A Bayesian decision-maker
putting sufficient weight on treatment effects being constant or correlated across groups
would come to the same conclusion. On the other hand, if the number of groups is small
compared to N , and the decision-makerâ€™s subjective prior entertains the possibility that the
optimal treatment is different across groups, then the solution to (DP00 ) will target by group
(and approach first-best efficiency).

More generally, we believe that related decision-theoretic frameworks are needed to address the trickier aspects of experiment design. For example, if a random, uninformed
statement is included in a pre-analysis plan, should this affect inference? It seems logical
that the answer would be no, but this calls into question the entire exercise. Or, why should
formulating an additional hypothesis affect our confidence in the analysis of others? Yet,
this is the impact of corrections for multiple hypotheses testing. These questions, as well as
others, await a rigorous treatment with solid decision-theoretic foundations.

21

References
Aghion, Philippe, Patrick Bolton, Christopher Harris, and Bruno Jullien, â€œOptimal Learning by Experimentation,â€ The Review of Economic Studies, 1991, 58 (4), 621â€“
654.
Athey, Susan and Guido Imbens, â€œThe Econometrics of Randomized Experiments,â€
arXiv preprint arXiv:1607.00698, 2016.
Banerjee, Abhijit, Sylvain Chassang, and Erik Snowberg, â€œDecision Theoretic Approaches to Experiment Design and External Validity,â€ in Esther Duflo and Abhijit Banerjee, eds., Handbook of Field Experiments, Elsevier, 2017, pp. 141â€“174.
Benjamin, Daniel, James Berger, Magnus Johannesson, Brian Nosek, EricJan Wagenmakers, Richard Berk, Kenneth Bollen, Bjorn Brembs, Lawrence
Brown, and Colin Camerer, et al., â€œRedefine Statistical Significance,â€ Nature Human
Behaviour, 2017, forthcoming.
Bergemann, Dirk and Juuso VaÌˆlimaÌˆki, â€œLearning and Strategic Pricing,â€ Econometrica,
September 1996, 64 (5), 1125â€“1149.
and , â€œInformation Acquisition and Efficient Mechanism Design,â€ Econometrica, 2002,
70 (3), 1007â€“1033.
and

, â€œBandit Problems,â€ 2006. Cowles Foundation discussion paper.

Blackwell, David, â€œEquivalent Comparisons of Experiments,â€ The Annals of Mathematical
Statistics, 1953, 24 (2), 265â€“272.
Bruhn, Miriam and David McKenzie, â€œIn Pursuit of Balance: Randomization in
Practice in Development Field Experiments,â€ American Economic Journal: Applied Economics, 2009, 1 (4), 200â€“232.
Bungi, Federico A., Ivan A. Canay, and Azeem M. Shaikh, â€œInference under
Covariate-Adaptive Randomization,â€ 2016. mimeo. Duke University.
Cochrane, William G. and Donald B. Rubin, â€œControlling Bias in Observational Studies,â€ SankhyaÌ„: The Indian Journal of Statistics, Series A, 1973, 35 (4), 417â€“446.
Deaton, Angus, â€œInstruments, Randomization, and Learning about Development,â€ Journal of Economic Literature, June 2010, 48 (2), 424â€“455.
Duflo, Esther, Rachel Glennerster, and Michael Kremer, â€œUsing Randomization in
Development Economics Research: A Tool Kit,â€ in T. Paul Schultz and John Strauss, eds.,
Handbook of Development Economics, Vol. 4, Amsterdam: Elsevier, 2008, pp. 3895â€“3962.

Referencesâ€“1

Fisher, Ronald Aylmer, The Design of Experiments, Edinburgh and London: Oliver &
Boyd, 1935.
Gilboa, Itzhak and David Schmeidler, â€œMaxmin Expected Utility with a Non-Unique
Prior,â€ Journal of Mathematical Economics, 1989, 18 (2), 141â€“153.
Green, Donald P and Andrej Tusicisny, â€œStatistical Analysis of Results from Laboratory Studies in Experimental Economics: A Critique of Current Practice,â€ 2012. Columbia
University, mimeo.
Grossman, Sanford J and Joseph E Stiglitz, â€œOn the Impossibility of Informationally
Efficient Markets,â€ The American Economic Review, June 1980, 70 (3), 393â€“408.
Harmon,
Amy,
â€œAfter Long Fight,
Drug Gives Sudden Reprieve,â€
The New York Times,
Februrary 22,
2016.
Published online at:
http://www.nytimes.com/2010/02/23/health/research/23trial.html.
Humphreys, Macartan, Raul Sanchez de la Sierra, and Peter Van der Windt,
â€œFishing, Commitment, and Communication: A Proposal for Comprehensive Nonbinding
Research Registration,â€ Political Analysis, 2013, 21 (1), 1â€“20.
Imbens, Guido W, â€œBetter LATE than Nothing: Some Comments on Deaton (2009) and
Heckman and Urzua (2009),â€ Journal of Economic Literature, June 2010, 48 (2), 399â€“423.
Kasy, Maximilian, â€œWhy Experimenters Might not Always Want to Randomize, and what
they Could Do Instead,â€ Political Analysis, 2016, 24 (3), 324â€“338.
Kitagawa, Toru and Aleksey Tetenov, â€œWho should be Treated? Empirical Welfare
Maximization Methods for Treatment Choice,â€ 2015. Collegio Carlo Alberto, mimeo.
Luenberger, David G., Optimization by Vector Space Methods, New York: John Wiley &
Sons, 1969.
Manski, Charles F., â€œStatistical Treatment Rules for Heterogeneous Populations,â€ Econometrica, 2004, 72 (4), 1221â€“1246.
, â€œThe 2009 Lawrence R. Klein Lecture: Diversified Treatment under Ambiguity,â€ International Economic Review, 2009, 50 (4), 1013â€“1041.
Marinacci, Massimo, â€œModel Uncertainty,â€ Journal of the European Economic Association, 2015, 13 (6), 1022â€“1100.
McDiarmid, Colin, â€œOn the Method of Bounded Differences,â€ Surveys in Combinatorics,
1989, 141 (1), 148â€“188.
Miguel, Edward and Michael Kremer, â€œWorms: Identifying Impacts on Education and
Health in the Presence of Treatment Externalities,â€ Econometrica, January 2004, 72 (1),
159â€“217.
Referencesâ€“2

Morgan, Kari Lock and Donald B. Rubin, â€œRerandomization to Improve Covariate
Balance in Experiments,â€ The Annals of Statistics, 2012, 40 (2), 1263â€“1282.
Olken, Benjamin A., â€œPromises and Perils of Pre-Analysis Plans,â€ The Journal of Economic Perspectives, 2015, 29 (3), 61â€“80.
Persico, Nicola, â€œInformation Acquisition in Auctions,â€ Econometrica, 2000, 68 (1), 135â€“
148.
Rothschild, Michael, â€œA Two-Armed Bandit Theory of Market Pricing,â€ Journal of Economic Theory, 1974, 9 (2), 185â€“202.
Rubin, Donald B., â€œUsing Multivariate Matched Sampling and Regression Adjustment to
Control Bias in Observational Studies,â€ Journal of the American Statistical Association,
1979, 74 (366a), 318â€“328.
, â€œBias Reduction using Mahalanobis-metric Matching,â€ Biometrics, 1980, 36 (2), 293â€“298.
Saito, Kota, â€œPreferences for Flexibility and Randomization under Uncertainty,â€ The
American Economic Review, 2015, 105 (3), 1246â€“1271.
Savage, Leonard J., The Foundations of Statistics, Courier Corporation, 1954.
Tetenov, Aleksey, â€œStatistical Treatment Choice Based on Asymmetric Minimax Regret
Criteria,â€ Journal of Econometrics, 2012, 166 (1), 157â€“165.
Wald, Abraham, Statistical Decision Functions, New York: Wiley, 1950.
Weerahandi, Samaradasa and James V. Zidek, â€œMulti-Bayesian Statistical Decision
Theory,â€ Journal of the Royal Statistical Society. Series A (General), 1981, 144 (1), 85â€“93.
and , â€œElements of multi-Bayesian decision theory,â€ The Annals of Statistics, 1983, 11
(4), 1032â€“1046.
Young, Alwyn, â€œChannelling Fisher: Randomization Tests and the Statistical Insignificance of Seemingly Significant Experimental Results,â€ 2016. mimeo., London School of
Economics.
Yuhas, Alan, â€œCancer Researchers Claim â€™Extraordinary Resultsâ€™ using Tcell Therapy,â€ The Guardian, February 15, 2016.
Published online at:
https://www.theguardian.com/science/2016/feb/15/cancer-extraordinary-results-tcell-therapy-research-clinical-trials.

Referencesâ€“3

Online Appendixâ€”Not Intended for Publication
A

Rationalizing t-statistics

A primary goal of this paper is to provide a suitable positive model of experimental practice
that can be used to examine and guide innovations. However, decision problem (DP) is
incompatible with hypothesis testing using t-statistics, a mainstay of experimental practice.
The raw treatment effectâ€”that is, the difference in average outcomes âˆ†1 â‰¡ p1 âˆ’ p0 â€”is
sufficient for near-optimal decision-making.
This appendix describes a class of experimenter preferences that rationalize the use of
t-statistics. Hypothesis testing favors implementation of the status quo (or null) treatment
a = 0. We first clarify that standard preferences (including risk-aversion) do not rationalize
t-statistics. We then turn to reference-dependent preferences.
Ambiguity aversion does not play a role in this argument. We consider a decision2

maker with independent Gaussian posteriors N (pÌ‚a , ÏƒNa ) over the mean outcome pa of action
a âˆˆ {0, 1}.1 A risk-neutral Bayesian decision-maker solving maxaâˆˆ{0,1} E[pa ] will simply take
action a = 1 if and only if pÌ‚1 âˆ’ pÌ‚0 > 0. However, the t-statistic for a given treatment effect
is given by

tâ‰¡

âˆš
pÌ‚1 âˆ’ pÌ‚0
.
Np 2
Ïƒ0 + Ïƒ12

(1)

Thus, decision rules that choose a = 1 if and only if t > t > 0 are suboptimal. To see this,
note that there always exists Ïƒ0 large enough to cause the decision-maker to stick with a = 0
regardless of the estimated treatment effect.
1

Parameters pÌ‚a and

2
Ïƒa
N

could be derived from a standard Gaussian learning model.

Online Appendixâ€“1

Risk-aversion over policy outcomes. A natural supposition is that risk aversion may
drive the reliance on hypothesis testing using t-statistics. However, this is not the case. To
show this, we assume (w.l.o.g.) that Ïƒ0 < Ïƒ1 , and consider a decision-maker who wants to
solve maxaâˆˆ{0,1} E [Î“(pa )] where Î“ is thrice continuously differentiable and concave. For N
large, the second order development of E [Î“(pa )] is
1 00
Ïƒ2
Î“(pÌ‚1 ) âˆ’ Î“(pÌ‚0 )
.
E [Î“(pa )] = Î“(pÌ‚a ) âˆ’ Î“ (pÌ‚a ) a implying sufficient statistic Î¸ = 2N 00 1 2
2
N
Î“ (pÌ‚ )Ïƒ1 âˆ’ Î“00 (pÌ‚0 )Ïƒ02
As Ïƒ0 < Ïƒ1 , the decision-maker will choose policy a = 1 whenever Î¸ > Î³, where Î³ =

0

1 Î“
.
2 Î“00

In

the special case where Î“ is quadratic, Î¸ reduces to
pÌ‚1 âˆ’ pÌ‚0
.
Î¸=N 2
Ïƒ1 âˆ’ Ïƒ02
This differs significantly from a t-statistic: mean treatment effect pÌ‚1 âˆ’ pÌ‚0 is scaled by the
difference of variances, rather than the sum of standard deviations. Indeed, risk-aversion
means that the decision-maker values certainty (a small variance in outcomes) as well as
a higher mean outcome. Varianceâ€”rather than standard deviationâ€”plays a role as Î“ is
smooth, and can be approximated by a 2nd order polynomial.
Reference-dependent preferences. The preceding discussion suggests that hypothesis
testing can only be motivated by reference-dependent preferences that treat a = 0 and a = 1
asymmetrically (see Tetenov, 2012). Let âˆ†a â‰¡ pa âˆ’ p1âˆ’a . Consider a decision-maker who
seeks to solve
max E[wa (âˆ†a )],

aâˆˆ{0,1}

(2)

where
âˆ€a âˆˆ {0, 1},

wa (âˆ†a ) = âˆ†a + Îºa Ã— âˆ†a 1âˆ†a <0
Online Appendixâ€“2

with Îº1 > Îº0 â‰¥ 0.
Lemma A.1. Consider a reference-dependent agent solving (2). The optimal-decision rule
takes the form t > tâˆ— , with tâˆ— > 0.
Proof. Let t â‰¡ âˆšp

1 âˆ’p1

Ïƒ02 +Ïƒ12

1

0



. As p âˆ’ p âˆ¼ N pÌ‚1 âˆ’ pÌ‚0 ,

p

Ïƒ02

+

Ïƒ12



, it follows that t âˆ¼ N (t, 1). As

both w0 and w1 are positively homogeneous of degree 1, the decision-maker chooses a = 1 if
and only if:

 q
 
 q


1
0
2
2
2
2
E w1 (âˆ† ) âˆ’ w0 (âˆ† ) > 0 â‡â‡’ Et w1 t Ïƒ0 + Ïƒ1 âˆ’ w0 âˆ’t Ïƒ0 + Ïƒ1 t > 0

 

â‡â‡’ Et w1 t âˆ’ w0 âˆ’t |t > 0
â‡â‡’ t > tâˆ—


for some value of t. Note that w1 t âˆ’ w0 âˆ’t = (2 + Îº0 )t + (Îº1 âˆ’ Îº0 )t1t<0 . As Îº1 > Îº0 it






follows that w1 t âˆ’w0 âˆ’t is concave in t. This implies that Et w1 t âˆ’ w0 âˆ’t |t = 0 < 0,
so that tâˆ— > 0.

B

Proofs

Proof of Lemma: By the Minimax Theorem (Luenberger, 1969), the decision-makerâ€™s
indirect utility from running experiment E can be written as
V (E) â‰¡ max U (E, Î±) = max min0 Eh,E [u(p, Î±(e, y))]
Î±âˆˆA

Î±âˆˆA hâˆˆH

= min0 max Eh,E [u(p, Î±(e, y))].
hâˆˆH Î±âˆˆA

Online Appendixâ€“3

Given h, the decision-makerâ€™s payoff from running experiment E can be written as
"
max Eh,E [u(p, Î±(e, y))] = max
Î±âˆˆA

Î±âˆˆA

=

X
eâˆˆE

=

X
eâˆˆE

X
eâˆˆE

E(e)

E(e)Epâˆ¼h
X
yâˆˆY

#
X

prob(y|p, e)u(p, Î±(e, y))

yâˆˆY

max Epâˆ¼h [prob(y|p, e)u(p, a)]

aâˆˆ{0,1}

E(e)v(h, e),

maxaâˆˆ{0,1} Epâˆ¼h [prob(y|p, e)u(p, a)]. As v(h, e0 ) = v(h, e) â‰¡ v(h, [e])
P
for all e0 âˆˆ [e], it follows that V (E) = minhâˆˆH 0 [e]âˆˆ[E] E([e])v(h, [e]). Thus, if E and E 0 induce

where v(h, e) â‰¡

P

yâˆˆY

the same distribution over [E], V (E) = V (E 0 ).



Proof of Proposition 2: We begin by showing that deterministic experiments are always
weakly optimal for a Bayesian decision-maker. The decision-makerâ€™s indirect utility from
running experiment E can be written as
max Eh0 ,E [u(p, Î±(e, y))] =
Î±âˆˆA

X
eâˆˆE

E(e)v(h0 , e),

where v(h0 , e) is the indirect utility from decision-making given realized experiment e:
P
âˆ—
v(h0 , e) â‰¡
yâˆˆY prob(y|e) maxaâˆˆ{0,1} Epâˆ¼h0 [u(p, a)|e, y]. Any deterministic experiment e
solving maxeâˆˆE v(h0 , e) is optimal. More strongly, E solves (DP) if and only if support E âŠ‚
argmax v(h0 , e).
eâˆˆE

To show that deterministic experiments are generically strictly optimal, we begin by
showing that argmax[e]âˆˆ[E] v(h0 , [e]) is generically a singleton for Î» = 1. We first show that
the set of priors h0 such that there is a uniquely optimal equivalence class of experiments is
open. Suppose that [e0 ] is uniquely optimal under h0 . As E is finite, there exists Î· > 0 such
that v(h0 , [e]) < v(h0 , [e0 ])âˆ’Î· for all [e] 6= [e0 ]. As v(h, e) is continuous in h, this implies that
Online Appendixâ€“4

there exists a neighborhood H0 of h0 such that, for all h âˆˆ H0 , v(h, [e]) < v(h, [e0 ]) âˆ’ Î·/2.
Hence, [e0 ] is the uniquely optimal design for all priors h âˆˆ H0 .
We now prove that the set of priors h0 such that there is a uniquely optimal equivalence
class of experiments is dense. The proof is by induction on the number of equivalence classes
[e0 ] in argmax[e]âˆˆ[E] v(h0 , [e]). We show that if there exist n such equivalence classes, then in
any neighborhood of h0 there exists a prior h such that there are at most n âˆ’ 1 equivalence
classes in argmax[e]âˆˆ[E] v(h, [e]).
Indeed, assume that [e0 ] 6= [e1 ] both belong to argmax[e]âˆˆ[E] v(h0 , [e]). For Î¸ > 0, consider
the polynomial MÎ¸ (p) in p âˆˆ P defined by
MÎ¸ (p) = v ((1 âˆ’ Î¸)h0 + Î¸p, [e0 ]) âˆ’ v ((1 âˆ’ Î¸)h0 + Î¸p, [e1 ]) ,
where (1 âˆ’ Î¸)h0 + Î¸p denotes the mixture probability measure that places mass 1 âˆ’ Î¸ on h,
and mass Î¸ on the Dirac mass at p. As [E] is finite, for all Î¸ > 0 small enough, it must be
that
argmax v((1 âˆ’ Î¸)h0 + Î¸p, [e]) âŠ‚ argmax v(h0 , [e]).
[e]âˆˆ[E]

[e]âˆˆ[E]

Consider such a Î¸ > 0. The fact that [e0 ] 6= [e1 ] implies that MÎ¸ (p) is not identically equal
to 0. Hence, there exists p such that v ((1 âˆ’ Î¸)h0 + Î¸p, [e0 ]) 6= v ((1 âˆ’ Î¸)h0 + Î¸p, [e1 ]). This
implies that the inductive step holds at prior hÌƒ = (1 âˆ’ Î¸)h0 + Î¸p. Using the fact that
[E] is finite and v(h, [e]) is continuous in h, this implies that the inductive step holds at a
prior that admits a density against the Lebesgue measure. Thus, when Î» = 1, deterministic
experiments are generically strictly optimal.
We now consider the case of Î» < 1. Given Î», h, and [e], as the decision-makerâ€™s utility

Online Appendixâ€“5

takes values in [0, 1], letting Î±0 âˆˆ argmaxÎ±âˆˆA Eh0 ,e [u(p, Î±(e, y))] we have
v(Î»h0 + (1 âˆ’ Î»)h, [e]) â‰¤ Î»v(h0 , [e]) + (1 âˆ’ Î»)v(h, [e]) â‰¤ v(h0 , [e]) + (1 âˆ’ Î»)

and

v(Î»h0 + (1 âˆ’ Î»)h, [e]) â‰¥ Î»v(h0 , [e]) + (1 âˆ’ Î»)Eh,e [u(p, Î±0 (e, y))] â‰¥ v(h0 , [e]) âˆ’ (1 âˆ’ Î»).
As there are finitely many experiments, if [e0 ] is the unique maximizer of v(h0 , [e]), there
exists Î· > 0 such that, for all [e] 6= [e0 ], v(h0 , [e0 ]) > v(h0 , [e]) + Î·. Together, this implies
that there exists Î» âˆˆ (0, 1) such that, for all Î» > Î», objective (DP) is maximized at E if and
only if support E âŠ‚ [e0 ].



Proof of Proposition 3: To establish point (i) and Corollary 1, we use the standard RCT
(Erct , Î±rct ). Losses L(p) from first best, given state of the world p, are defined as


L(p) â‰¡ max pa âˆ’ Ep,Erct prob(1y1 âˆ’y0 >0 ) .
aâˆˆ{0,1}

By symmetry, it suffices to treat the case where p1 âˆ’ p0 > 0. In this case, we have L(p) =
(p1 âˆ’ p0 )probp,Erct (y 1 âˆ’ y 0 â‰¤ 0). The probability of choosing the suboptimal policy can be
bounded using McDiarmidâ€™s inequality.2 By applying McDiarmidâ€™s inequality to f (y) â‰¡
PN
PÏ€N 1
1
1
0
y
âˆ’
i
i=Ï€N +1
i=1 yi , we obtain
(1âˆ’Ï€)N
Ï€N

probp,Erct (y 1 âˆ’ y 0 â‰¤ 0) = probp,Erct y 0 âˆ’ y 1 âˆ’ (p0 âˆ’ p1 ) â‰¥ (p1 âˆ’ p0 )
!
2(p1 âˆ’ p0 )2
â‰¤ exp âˆ’ 1
1
+ Ï€N
(1âˆ’Ï€)N

= exp âˆ’2Ï€(1 âˆ’ Ï€)N (p1 âˆ’ p0 )2

â‰¤ exp âˆ’Ï€N (p1 âˆ’ p0 )2 ,
2

McDiarmid (1989): Let X1 , . . . , Xn be independent random variables, with Xk taking values in a set Ak
for each k. Suppose that the (measurable) function f : Ã—k Ak â†’ R satisfies |f (x) âˆ’ f (x0 )| â‰¤ ck whenever x
and x0 differPonly in the kth coordinate. Then, for any t > 0, prob (f (X1 , . . . , Xn ) âˆ’ E[f (X1 , . . . , Xn )] â‰¥ t) â‰¤
exp âˆ’2t2 / k c2k .

Online Appendixâ€“6

where the last inequality follows from 2Ï€(1 âˆ’ Ï€) â‰¥ Ï€ â‰¡ min{Ï€, 1 âˆ’ Ï€}. For any a > 0, the
mapping x 7â†’ x exp(âˆ’ax2 ) is ln-concave and maximized at x = (2a)âˆ’1/2 . This implies that
s


max pa âˆ’ Ep,Erct p1y1 âˆ’y0 >0 â‰¤

aâˆˆ{0,1}

exp(âˆ’1)
â‰¤
2Ï€N

s

ln 2
.
2Ï€N

(3)

An analogous argument delivers (3) also for the case where p1 âˆ’ p0 â‰¤ 0. Hence, given any
h âˆˆ H,

s

ln 2
max u(p, a) âˆ’ Eh,Erct [u(p, Î±rct (e, y))] â‰¤
.
aâˆˆ{0,1}
2Ï€N


Eh

Setting Ï€ = 1/2 yields point (i) and the tightest bound.
To establish point (ii), fix a deterministic experiment e âˆˆ E. From the Limited Extrapolation Assumption, there exists h âˆˆ H such that for almost every pe ,
 



a
0
a
1
min Eh max p âˆ’ p pe , Eh max p âˆ’ p pe
> Î¾. Hence,
aâˆˆ{0,1}
aâˆˆ{0,1}


max Eh,e [u(p, Î±(e, y))] â‰¤ Eh,e max Eh,e [u(p, a)|pe ]
Î±
aâˆˆ{0,1}


â‰¤ Eh,e max u(p, a) âˆ’ Î¾.
aâˆˆ{0,1}



Proof of Proposition 4: Consider an experiment eâ€  âˆˆ argmaxeâˆˆsupport EK B(e). As the
total number of subsets of {1, Â· Â· Â· , N } is equal to 2N , the number of experiments that assign
treatment to Ï€N participants out of N is necessarily less than or equal to 2N . Hence the
K
probability that the kth rerandomized trial selects eâ€  is at least Ï â‰¡ 1 âˆ’ 1 âˆ’ 2âˆ’N . For
K â‰¥ 2N ,
Ï â‰¥ 1 âˆ’ exp 2N ln 1 âˆ’ 2âˆ’N



âˆ¼ 1 âˆ’ exp(âˆ’1) > 0.

Online Appendixâ€“7

Hence, there exists Ï > 0 such that, for all N , rerandomized experiment EK selects deterministic experiment eâ€  with probability at least Ï.
The proof of Proposition 3 implies that there exists hâ€  âˆˆ H such that


âˆ€e âˆˆ E, max Ehâ€  ,e [u(p, Î±(e, y))] â‰¤ min Eh max u(p, a) ,
Î±âˆˆA
hâˆˆH
aâˆˆ{0,1}


â€ 
and max Ehâ€  ,eâ€  [u(p, Î±(e , y))] â‰¤ min Eh max u(p, a) âˆ’ Î¾.
Î±âˆˆA
hâˆˆH
aâˆˆ{0,1}


Hence, max min Eh,EK [u(p, Î±(e, y))] â‰¤ min Eh max u(p, a) âˆ’ ÏÎ¾.
Î±âˆˆA hâˆˆH

hâˆˆH

aâˆˆ{0,1}



Proof of Proposition 5: Denote by (y 0,k , y 1,k ) the sample average of outcomes by treatment
group for experiment ek , and by (y âˆ—0 , y âˆ—1 ) the sample average of outcomes by treatment group
for the experimental design eâˆ—K selected by rerandomized experiment EK .
Losses L(p) from first best given state of the world p are defined as L(p) â‰¡ maxaâˆˆ{0,1} pa âˆ’


Ep,EK prob(1yâˆ—1 âˆ’yâˆ—0 >0)â€˜ . By symmetry, it suffices to treat the case where p1 âˆ’ p0 > 0. In this
case, we have
L(p) = (p1 âˆ’ p0 )probp,EK (y âˆ—1 âˆ’ y âˆ—0 â‰¤ 0)


1
0
â‰¤ (p âˆ’ p )probp,EK
min y 1,k âˆ’ y 0,k â‰¤ 0
kâˆˆ{1,...,K}
( K
)
X
â‰¤ (p1 âˆ’ p0 ) min 1,
probp,EK (y 1,k âˆ’ y 0,k â‰¤ 0) .
k=1

As in the proof of Proposition 3, by applying McDiarmidâ€™s inequality to fk (y) â‰¡ y 0,k âˆ’ y 1,k ,
we obtain probp,EK (y 1,k âˆ’ y 0,k â‰¤ 0) â‰¤ exp (âˆ’Ï€N (p1 âˆ’ p0 )2 ), where Ï€ â‰¡ min{Ï€, 1 âˆ’ Ï€}.

Online Appendixâ€“8

We have that K exp(âˆ’Ï€N (p1 âˆ’ p0 )2 ) â‰¤ 1 â‡â‡’ p1 âˆ’ p0 â‰¥
ï£±
ï£´
ï£² p1 âˆ’ p0

L(p) â‰¤

q

ln K
,
Ï€N

which implies that

if p1 âˆ’ p0 <

ï£´
ï£³ K(p1 âˆ’ p0 ) exp(âˆ’Ï€N (p1 âˆ’ p0 )2 ) if p1 âˆ’ p0 â‰¥

q

ln K
,
Ï€N

q

ln K
.
Ï€N

(4)

q
1
The mapping x 7â†’ x exp(âˆ’Ï€N x2 ) is ln-concave and maximized at x = 2Ï€N
. As K â‰¥ 2,
q
q
1
we have lnÏ€NK > 2Ï€N
, which implies that both terms on the right-hand side of (4) are
q
q
maximized at p1 âˆ’ p0 = lnÏ€NK . This implies that indeed L(p) â‰¤ lnÏ€NK . Identical reasoning
applies in the case where p1 âˆ’ p0 < 0.



Proof of Corollary 2: Consider a balance function minimized by assignments e âˆˆ Eâ€  . Let
LK denote the loss in efficiency from a K-rerandomized trial, and LEâ€  the loss in efficiency
from experiment EEâ€  . The likelihood that the assignment e drawn from EK belongs to Eâ€  is

1 âˆ’ (1 âˆ’ pEâ€  )K . As LK â‰¥ 1 âˆ’ (1 âˆ’ pEâ€  )K LEâ€  , it follows from Proposition 5 that
LEâ€ 

1
â‰¤
1 âˆ’ (1 âˆ’ pEâ€  )K

s

ln K
.
Ï€N


Proof of Proposition 6: Point (i) follows from a reasoning similar to that of Proposition
2. For Î» = 1, given an experiment E, the decision-makerâ€™s indirect utility is
max Eh0 [wÎ± (âˆ†Î± )] =
Î±,E

where w(h0 , e) â‰¡

P

yâˆˆY

X
eâˆˆE

E(e)w(h0 , e),

prob(y|e) maxaâˆˆ{0,1} Epâˆ¼h0 [wa (âˆ†a )|e, y] . Hence, an experiment E is

optimal if and only if support E âŠ‚ arg maxe w(h0 , e).

Online Appendixâ€“9

To conclude the proof of point (i), it is sufficient to show that arg max[e]âˆˆ[E] w(h0 , [e]) is a
singleton. A reasoning identical to that of Proposition 2, with w(h0 , [e]) in place of v(h0 , [e]),
shows that this is the case for generically every prior h0 . The existence of an appropriate
threshold Î» < 1 follows from the fact that w(h0 , [e]) is Lipshitz continuous in h0 , and there
are finitely many possible experimental assignments.
We now turn to point (ii). We know from Proposition 7 that there exist randomized
âˆš
experiments leading to optimal decisions up to a penalty of order O(1/ N ). This implies
âˆš
that the decision-maker can guarantee herself a payoff greater than âˆ’O(1/ N ). Consider a
deterministic experiment e. For d âˆˆ R, let the state p(d) such that
p0x =

1
2

+ d, p1x =

p0x = 12 ,

p1x =

1
2
1
2

if Ï„x = 1;
âˆ’d

if Ï„x = 0.

Consider the prior he that puts probability 0.5 on p(d = Î½) and 0.5 on p(d = âˆ’Î½) for
Î½ âˆˆ (0, 1/2). By construction the information generated by the experiment is independent of
whether d = Î½ or d = âˆ’Î½. In addition, âˆ†1 = p1 âˆ’ p0 = âˆ’d. Hence, regardless of the action a
taken by the decision-maker, there is probability 0.5 that âˆ†a = âˆ’Î½ and probability 0.5 that
âˆ†a = +Î½. As wa is locally strictly concave around 0, it follows that expected payoffs from
running a deterministic experiments are bounded away below 0.
This implies that for N large enough, randomized experiments are strictly optimal.



Proof of Proposition 7: The proof is closely related to that of Proposition 5. Consider
first the case where âˆ†p > 0. Then the efficiency loss compared to first-best is equal to

L = Eh [w1 (âˆ†1 ) âˆ’ wÎ±RCT (âˆ†1 )|âˆ†1 > 0].

Online Appendixâ€“10

As functions wa are Lipschitz continuous and wa (0) = 0, there exists M > 0 such that

L â‰¤ M Eh [(1 âˆ’ Î±RCT )âˆ†1 |âˆ†1 > 0].
In turn, if âˆ†p < 0, there exists M such that the efficiency loss satisfies L â‰¤ M Eh [âˆ’Î±RCT âˆ†1 |âˆ†1 <
0].
The proof of Proposition 5 implies that Eh [(1âˆ’Î±RCT )âˆ†1 |âˆ†1 > 0] and Eh [âˆ’Î±RCT âˆ†1 |âˆ†1 <
q
K
0] are bounded above by log
. This proves Proposition 7.

Ï€N

C

Simulations

C.1

Optimal Experimentation

A simple example helps clarify the use of rerandomization as a way to pick a trade-off between
subjectively optimal experiments and the robustness of RCTs. We consider an environment
where N = |X| = 2, X = {0, 1}, and the experimenter is given a sample of participants with
(x1 , x2 ) = (1, 0).
We parameterize the set H of admissible priors over the set P of states of the world as
follows. First, for the expected probability of success given policy a âˆˆ {0, 1}, pa = qpa1 + (1 âˆ’
q)(1 âˆ’ pa0 ), we consider priors such that, with equal probability, the pair (p0 , p1 ) describes

either a â€œhigh probability of successâ€ world with minaâˆˆ{0,1} pa , maxaâˆˆ{0,1} pa = (1/2, 3/4)

or a â€œlow probability of successâ€ world with minaâˆˆ{0,1} pa , maxaâˆˆ{0,1} pa = (1/4, 1/2).
Next, given pa , to further constrain the support of priors in H, we construct a grid over
the set of values of the conditional success probabilities pa0 and pa1 consistent with pa . Note
that as pa0 = (pa âˆ’ qpa1 )/(1 âˆ’ q), pa0 â‰¥ 0 implies that pa1 â‰¤ ha â‰¡ min{1, pa /q}, while pa0 â‰¤ 1
implies that pa1 â‰¥ la â‰¡ max{0, (q âˆ’ 1 + pa )/q}. Letting ma â‰¡ la /2 + ha /2, we restrict priors in
Online Appendixâ€“11

H to assign positive probability only to values of pa1 defining an equally-spaced, 10-segment
grid from la /2 + ma /2 to ma /2 + ha /2.
With only two participants, we consider experiments with Ï„1 = 1 âˆ’ Ï„2 , and we solve numerically for the optimal probability with which participant 1 should be treated to maximize
the adversarial component of the experimenterâ€™s payoff as defined in (DP) with policy chosen
according to Î±rct . Figure C.1 shows how the optimal experiments vary with the value of
q âˆˆ [0, 1], the share of agents with x = 1 in the population. Relative to a standard RCT with
probability Ï€ = 1/2 of treating each participant, the experimenter only experiences gains
from running an optimal experiment for intermediate values of q. In this range, rerandomization offers a compromise between optimality and the robustness of the RCT. However, if q
is close to zero or one, the advantage of rerandomization over the standard RCT disappears.

Figure C.1: Range of optimal experiments as a function of the environment.

C.2

The Trade-Offs of Rerandomization

We provide two numerical explorations of our results. We begin by considering a wellbehaved case in which treatment effects are continuous with respect to a small number of
Online Appendixâ€“12

underlying characteristics, so that there is limited tension between balance and robustness.
We then turn to a much more discontinuous setting designed to oppose the desire to balance
and robust policy making. The message from both simulations is clear: rerandomization
increases balance with very little to no increase in mistaken decisions.
C.2.1

Smooth Priors

We consider the following environment. Covariates x are drawn i.i.d. according to

Q5

k=1

U [0, 1],

a five-dimensional uniform distribution. These are mapped to outcomes according to a fivedimensional unknown parameter Âµ:

prob(Yi = 1|x) =

exp(Âµ Â· x)
.
1 + exp(Âµ Â· x)

Parameter Âµ is drawn according to a five-dimensional truncated normal: Âµ âˆ¼

Q5

k=1

N (0, 1)|[âˆ’2,2] .

We denote by Ï„ âˆ— and Î± the Bayes optimal assignment of treatment and policy choice under
this model.
We report balanceâ€”captured by the negative of the L2 norm between mean characteristics across treatment and controlâ€”as well as several efficiency losses of interest (see Figure
C.2):
â€¢ Bayes Loss given Bayes Optimal Assignment


EÂµ,x,Ï„ âˆ— max u(p, a) âˆ’ u(p, Î±) ;
aâˆˆ{0,1}

â€¢ Loss under worst prior given Bayes optimal assignment


max Ex,Ï„ âˆ— max u(p, a) âˆ’ u(p, Î±) ;
Âµ

aâˆˆ{0,1}

(5)

(6)

Online Appendixâ€“13

10%

0

8%

âˆ’0.1

6%

âˆ’0.2

Balance

Loss Compared to Firstâˆ’best (Error Rate)

Figure C.2: Rerandomization substantially increase balance with no cost to robustness.

4%

2%

âˆ’0.3

âˆ’0.4

0

âˆ’0.5
10

100
N (Log Scale)

1,000

Randomization
Randomization (Worst Prior)

10

100
N (Log Scale)

Rerandomization
Rerandomization (Worst Prior)
Rerandomization (Worst Prior, Evil RA)

â€¢ Loss under worst prior, and worst assignment Ï„


max Ex max E max u(p, a) âˆ’ u(p, Î±) .
Âµ

Ï„

1,000

(7)

aâˆˆ{0,1}

The ex-ante Bayes expected loss (5) is essentially identical under randomization and
rerandomization. Loss measure (6) chooses the prior that maximizes the error rate given
the experimental strategy E of the experimenter. While this is substantially higher than the
Bayes expected loss â€” as expected â€” it is not substantially different between randomization
and rerandomization. Finally, loss measure (7) stacks the deck against the experimenter, and
assumes that the experimenter has an â€œevil RAâ€ who chooses the experimental assignment
Ï„ from eK that maximizes the expected loss. This has no application in the case of randomization, but in the case of rerandomization it substantially increases error rates. However,
it is important to note even under this highly unrealistic scenarioâ€”the evil RA must know
the data-generating processâ€”the error rate is about one-tenth of 1% for N â‰¥ 300.
In the simulations above, we vary K, the number of rerandomizations according to our

Online Appendixâ€“14

0.004

âˆ’0.05

0.003

âˆ’0.1

0.002

Balance

0

âˆ’0.15

Worst Prior Error Rate

Figure C.3: Rerandomizaton increases balance with no robustness cost with fixed N .

0.001
0

20
40
60
80
Number of Rerandomizations (K)
Balance

100

Worst Prior Error Rate

rule of thumb, K = min{N, 100}. This suggests that the simulation may be masking some
decision-making cost of rerandomization by increasing N simultaneously. Figure C.3 shows
this is not the case by plotting worst-prior loss and balance with K, holding N fixed at 100.
Balance improves substantially, especially for the first 20 rerandomizations, but the error
rate is essentially flat.
C.2.2

The Case of Non-Smooth Priors

We now consider an environment designed to create a tension between balance and robustness. Also, we pick assignment Ï„ using balance objective B(e) = âˆ’||x1 âˆ’ x0 ||2 . Policy is
chosen according to Î±(e, y) â‰¡ argmaxaâˆˆ{0,1} y a âˆ’ y 1âˆ’a .
The environment involves a single covariate x âˆˆ X = {1, 2, . . . , 10,000}. Even covariates
are twice as likely as odd covariates, and the treatment effect is small and negative for even
covariates, and large and positive for odd covariates. Specifically, for n âˆˆ {1, 2, . . . , 5,000},
q(2n âˆ’ 1) =

2
4
p0
1
q(2n)
=
, p12nâˆ’1 = 4p02nâˆ’1 = , and p12n = 2n = ,
2
3|X|
5
2
4

Online Appendixâ€“15

Figure C.4: Rerandomization substantially increase balance with no cost to robustness.
0

40%

âˆ’500
Balance

Error Rate

60%

20%

âˆ’1,000

0

âˆ’1,500
10

100

1,000

10,000

10

N (Log Scale)

1,000

10,000

N (Log Scale)

Randomization

Thus, on aggregate, u(p, 1) =

100

13
30

>

2
5

Rerandomization

= u(p, 0), so treatment is beneficial, and Î± = 1 is

the â€œcorrectâ€ decision. This setup is meant to make attempts to balance the sample likely
to cause inferential mistakesâ€”balancing will tend to pair odd observations with the more
numerous even observations, which are not an appropriate comparison group.3
Figure C.4 examines the error rates and balance of randomization and rerandomization.
As can be seen in the first panel, all three give roughly the same error rate. This is because
the chosen balance function, B(e), in these simulations is very unlikely to select a more
biased sample allocation. While in any specific application the interaction of the model
parameters and the balance function may produce different results, it appears quite difficult
to find a balance function that 1) might actually be used and 2) is particularly pernicious.
On the other hand, once again, rerandomization substantially improves the balance of
the samples. This is particularly true for small and moderate sample sizes, up to the order
of 1,000, although even with 10,000 participants there is an improvement in balance, even
3

Indeed, using pairwise matching to assign treatment and control status increases inferential errors, but
does so equally for randomization and rerandomization

Online Appendixâ€“16

though we only re-draw the experimental allocation 100 times.
C.2.3

(Re-)Randomization Inference

As noted in the text, if B(e) is pre-specified, randomization inference can be used to calculate
standard errors (Fisher, 1935; Young, 2016). Here, we illustrate this process using the
simulations, and balance functions, from the prior subsections.
In particular, randomization inference uses the following procedure:
1. Randomize assignment (Ï„i )iâˆˆ{1,...,N }
2. Generate data (yiÏ„i )iâˆˆ{1,...,N }
3. Calculate treatment effect âˆ†yÌ‚ â‰¡ yÌ‚ 1 âˆ’ yÌ‚ 0
4. Re-draw experimental assignment using the same randomization procedure (Ï„ij )iâˆˆ{1,...,N }
j

j

5. Calculate treatment effect as if Ï„ j had been implemented âˆ†j yÌ‚ â‰¡ yÌ‚ Ï„i =1 âˆ’ yÌ‚ Ï„i =0
6. Return to Step 4, repeat until j = J (usually 10,000).
The simulated distribution of âˆ†j yÌ‚ is the distribution of treatment effects that would be
observed if p1x = p0x , âˆ€x âˆˆ X. This can be used to calculate p-values, or infer standard errors.
Clearly, knowing B(e), and the number of rerandomizations, K, is critical to properly
implementing Step 4. If this is the case, we say that the experimenter can conduct rerandomization inference.
In Figure C.5, we compare rerandomization inference and the standard errors that would
come from a regression of outcomes on treatment status. Finally, we also include naÄ±Ìˆve
randomization inference, where the experimenter does not know B(e), and consequently
draws a single randomization to calculate each âˆ†j yÌ‚.

Online Appendixâ€“17

Figure C.5: Comparing rerandomization inference with other inference strategies.

0.4

4

Standard Errors

Density of Estimates

Smooth Simulation
3
2
1

0.3
0.2
0.1
0

0
âˆ’0.4

âˆ’0.2

0

0.2

10

0.4

Estimate

100
N (Log Scale)

1,000

100
N (Log Scale)

1,000

0.4

4

Standard Errors

Density of Estimates

Nonâˆ’Smooth Simulation
3
2
1

0.3
0.2
0.1
0

0
âˆ’0.4

âˆ’0.2

0

0.2

0.4

10

Estimate

Reâˆ’Randomization Inference
Randomization Inference
Standard Error from Regression

The right-hand-side panels of the figure show the distribution of âˆ†j yÌ‚ under each technique. The distribution shown for the regression comes from a simulated normal with standard deviation equal to the standard error from the regression coefficient. The left-hand-side
panels show how standard errors from each source change as the sample grows larger. Note
that we set K = min{N, 100} for both the experimental simulation and rerandomization
inference.
The results under all schemes are substantially the same. This may be due, in part, to
the fact that outcomes are bounded in our simulations. However, it is certainly the case, as

Online Appendixâ€“18

our theoretical results show, that rerandomization has a very small impact on the robustness
of decision-making.

Online Appendixâ€“19

