NBER WORKING PAPER SERIES

CROWDFUNDING SCIENTIFIC RESEARCH
Henry Sauermann
Chiara Franzoni
Kourosh Shafi
Working Paper 24402
http://www.nber.org/papers/w24402

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
March 2018

We thank Experiment.com co-founder Cindy Wu for help with data collection and for extremely
helpful insights on the platform and its projects. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Henry Sauermann, Chiara Franzoni, and Kourosh Shafi. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

Crowdfunding Scientific Research
Henry Sauermann, Chiara Franzoni, and Kourosh Shafi
NBER Working Paper No. 24402
March 2018
JEL No. I23,O31,O32
ABSTRACT
Crowdfunding may provide much-needed financial resources, yet there is little systematic
evidence on the potential of crowdfunding for scientific research. We first briefly review prior
research on crowdfunding and give an overview of dedicated platforms for crowdfunding
research. We then analyze data from over 700 campaigns on the largest dedicated platform,
Experiment.com. Our descriptive analysis provides insights regarding the creators seeking
funding, the projects they are seeking funding for, and the campaigns themselves. We then
examine how these characteristics relate to fundraising success. The findings highlight important
differences between crowdfunding and traditional funding mechanisms for research, including
high use by students and other junior investigators but also relatively small project size. Junior
investigators are more likely to succeed than senior scientists, and women have higher success
rates than men. Conventional signals of quality - including scientists' prior publications - have no
relationship with funding success, suggesting that the crowd applies different decision criteria
than traditional funding agencies. Our results highlight significant opportunities for crowdfunding
in the context of science while also pointing towards unique challenges. We relate our findings to
research on the economics of science and on crowdfunding, and we discuss connections with
other emerging mechanisms to involve the public in scientific research.

Henry Sauermann
European School of Management and Technology
Berlin
Schlossplatz 1
10178 Berlin
Germany
and NBER
henry.sauermann@esmt.org
Chiara Franzoni
Department of Management, Economics
and Industrial Engineering
Politecnico di Milano
20133 Milan
Italy
chiara.franzoni@polimi.it

Kourosh Shafi
University of Florida
Bryan Hall 133
Gainesville, FL 32611
kourosh.shafi@warrington.ufl.edu

Introduction
Crowdfunding – an open call for money from the general public – has become a major source of
funding for entrepreneurial, artistic, and social projects [1-4]. More recently, scientists and policy
makers have suggested that crowdfunding could also be valuable to support scientific research
[5-7] and some universities actively encourage their researchers to start crowdfunding campaigns
[8]. The public discussion as well as related work on crowdsourcing and Citizen Science suggest
several potential benefits [9-11]. One hope is that funding from the crowd can expand the total
amount of resources available for science, or at least partly compensate for tighter budgets of
traditional funding agencies [6]. In light of the increasing difficulties especially junior scientists
face in getting funding through traditional channels [12], some observers highlight that the crowd
may be more willing to fund researchers who do not yet have an established track record [7].
Finally, “broadcasting” proposals to a large number of potential funders may allow researchers to
identify those supporters who share an interest in the same topics, even if these topics are not
mainstream or priorities for traditional funding agencies [10, 13].
Despite these hopes, however, the potential of crowdfunding for scientific research is not
clear. Many crowdfunding campaigns in other domains fail, suggesting that raising money from
the crowd can be quite challenging [2, 14]. Moreover, research projects have characteristics that
would be expected to make it challenging to raise funding from the crowd. Among others,
scientific research is often risky, while members of the crowd may have a preference for projects
that are likely to succeed [15]. Similarly, there is an asymmetry in the knowledge of highly
trained scientists and potential “citizen” funders, such that the latter may find it difficult to assess
the quality and merit of research proposals [15, 16]. Research projects also cannot typically offer
the tangible outputs that are often “pre-sold” on general-purpose platforms such as Kickstarter,
and scientific research projects may generally be perceived to have less direct use value than
other types of projects [15, 17]. On the other hand, crowdfunding platforms that specialize in
scientific research projects may attract backers with different kinds of motivations and decision
criteria than general-purpose platforms. Moreover, they may be able to offer tools that are
tailored to the needs of scientists and their funders and may help increase the odds of fundraising
success.
To assess the potential of crowdfunding for scientific research, we report initial evidence
from Experiment.com, the currently largest dedicated platform for crowdfunding research. We
1

first provide descriptive information on the creators seeking funding, the projects they are
seeking funding for, and features of the crowdfunding campaigns. We then investigate how these
various characteristics are related to campaign success. We compare the results to prior research
on the predictors of fundraising success in crowdfunding but also to research on traditional
scientific funding mechanisms such as government grants. Finally, we examine whether and how
predictors of crowdfunding success differ from the factors that predict attention from a more
professional audience – journalists covering scientific research.
Our analysis provides new evidence on the state of crowdfunding in scientific research and
should be of interest to scholars in the economics of science as well as to scientists who consider
starting their own crowdfunding campaigns. By providing empirical evidence from the specific
context of science, this study also contributes to the broader literature on crowdfunding, which
tends to focus on general-purpose platforms.

Prior research
Although prominent success stories such as the Pebble Watch or the Oculus Virtual Reality
Headset have demonstrated the potential of crowdfunding, many campaigns fail to reach their
funding targets [2, 14]. As such, a growing literature in fields as diverse as economics,
management, and the sciences has started to examine crowdfunding from a descriptive
perspective, and to explore potential drivers of fundraising success [18]. Most of these
contributions, however, have looked at crowdfunding for startups, technology development, or
projects in the arts or cultural industries. In contrast, there is little evidence on the potential of
crowdfunding as a tool to raise resources for scientific research [17, 19].
Although a unified framework for studying crowdfunding has not emerged yet [20], most of
the prior literature examines how crowdfunding success relates to factors in the following three
broad domains.
First, many studies have examined how fundraising success is related to certain
characteristics of the individuals who are seeking to raise funding (i.e., the “creators” of a
campaign). In particular, several studies have explored gender differences in funding success,
finding that female creators, or teams that have at least one female creator, are more likely to
achieve success compared to male creators [21-23]. Other studies have considered creators’
broader social networks, highlighting the role of the social interconnectedness of the creator in
2

explaining funding outcomes [2, 23-25]. Related work has considered the geographic location of
creators, finding that crowdfunding provides a wider reach than traditional funding mechanisms
such as venture capital, although geographic distance still seems to matter [26, 27].
Second, several papers have studied how fundraising success is related to characteristics of
the project, i.e., what funding is raised for. The existing evidence suggests that projects aimed at
non-profit goals are more likely to be funded than projects with for-profit goals [28, 29].
Moreover, there is robust evidence that projects with smaller budgets are more likely to achieve
their targets [2, 23, 24]. Recent work studying technology-related projects on Kickstarter has
found that projects attempting radical innovations were less likely to be funded than projects
proposing incremental innovations, perhaps reflecting that backers doubt the feasibility of radical
proposals or that radical proposals appear less useful in addressing currently perceived needs
[15].
Third, much attention has been directed at features of the campaign itself, e.g., what
information is presented, how it is presented, and how creators interact with the crowd. Research
has found that the amount of information provided about a project is positively correlated to
funding success [23, 25], particularly when the information makes the project more
understandable and relatable to the crowd [30]. Information given in a visual form, including
videos, is particularly useful [2, 23, 31]. Relatedly, project updates during the campaign can
further increase the likelihood of success [32]. Endorsements by a third party, such as business
angels or venture capitalists, correlate positively with fundraising success, perhaps because they
serve as a signal of quality and reduce the information asymmetry between the creator and the
crowd [33, 34]. Finally, a study in the context of scientific research suggests that campaigns were
more successful when scientists started nurturing an audience for their projects before the
crowdfunding campaign, taking advantages of their social networks [19].
We build on this existing work to provide insights into crowdfunding campaigns in an
understudied context – scientific research. In considering specific factors within each of the three
domains, we can thus also draw on prior research in the economics of science, including work on
predictors of fundraising success in the traditional (grant-based) system. With respect to creator
characteristics, for example, we distinguish junior versus senior researcher status as well as
academic versus industry affiliations [35, 36]. Similarly, we classify projects based on their
research objectives, develop a proxy for the riskiness of the research, and examine what kinds of
3

research expenses creators plan to cover with the funding raised [37-39]. For campaign
characteristics, we consider a range of factors such as “lab notes”, as well as the listing of prior
publications, which are often taken as signals of quality by traditional funding agencies [35].

Crowdfunding platforms for scientific research projects
Our data come from the platform Experiment.com, which is dedicated to crowdfunding for
scientific research. This US-based platform was established in May 2012 under the name
Microryza and was later renamed. The platform allows investigators to create a profile and post a
campaign webpage to raise the desired funds. The campaign stays open for a limited amount of
time, typically 30-45 days. Experiment.com uses an “all-or-nothing” mechanism, i.e., donors are
charged and the pledged funds are transferred to the campaign creators only if the predetermined funding goal is reached. In this sense, campaigns resemble the all-or-nothing nature
of competitive grant proposals made to traditional funding agencies.
There are several other platforms for crowdfunding scientific research, following a similar
model as Experiment.com. Table 1 provides examples of other relevant platforms, with basic
information such as founding date and number of projects hosted. The table shows that some of
these platforms are independent, while others are run by universities or funding agencies
primarily for their own purposes. While some have been operating for several years, others have
failed. Experiment.com is, to the best of our knowledge, the largest dedicated platform for the
crowdfunding of scientific research projects.
For the purpose of our study, it is important to distinguish dedicated crowdfunding platforms
such as Experiment.com from two related, but different types of platforms that may also be used
by researchers. First, there are charity fundraising platforms such as Benefunder and
Thecommongood. Such platforms differ from Experiment.com in that funds are typically raised
for an organization or general cause rather than specific research projects, fundraising remains
open for an extended time, there is no explicit fundraising goal, and there is no all-or-nothing
funding mechanism. Thus, these platforms are similar to traditional charity institutions, except
that they use the online channel for fundraising.
Second, there are general-purpose “rewards-based” platforms such as Kickstarter or
Indiegogo. These platforms are project-based and follow an all-or-nothing model, but are
primarily for business or artistic projects and rarely host campaigns that focus on scientific
4

research. They usually require creators to give rewards to the backers and have other specific
provisions that make the fundraising for scientific research projects difficult. For example,
Kickstarter explicitly excludes projects aimed at the treatment or prevention of illnesses [40], and
Indiegogo stopped accepting non-profit projects in February 2018 [41].

Data and Measures
We obtained from Experiment.com leadership the links to all crowdfunding campaigns that
were started since the platform launch in May 2012 and for which success or failure status was
known in August 2015. We scraped the webpage content of these campaigns to obtain measures
for a wide range of project characteristics as well as funding outcomes. In addition, we handcoded additional variables based on project descriptions on the campaign webpages and profile
pages of campaign creators. Experiment.com terms of use do not prohibit data collection for
scientific purposes and the leadership’s cooperation in providing data access also indicates
permission.
We dropped from the analysis 16 campaigns with incomplete webpages. Our final sample
includes 728 campaigns. Of these campaigns, 68% were started by a single creator. The
remaining campaigns were posted by teams ranging from 2 to 7 individuals, for a total of 1,153
creators in our sample.
In the following, we describe our variables and measures. Table 2 shows summary statistics
at the level of individual creators; Table 3 shows summary statistics at the level of campaigns.
Creator characteristics
Affiliation. Campaigns typically provide information on the background of the creators. If
the campaign did not provide this information, we searched the internet. We hand-coded the
organizational affiliations of the creators using the following categories: Educational institution
(including universities, colleges, and high schools); company/firm (including startups as well as
established firms); and other organization (including non-profits or government research
institutes). Some creators acted without organizational affiliation, sometimes explicitly stating
that they were “independent”; these are coded as “no affiliation/independent”.
Position. We coded creators’ position using the following categories: Student below
PhD/MD level; PhD/MD student; Postdoctoral researcher; Assistant Professor; Associate/Full
Professor; Employee/Affiliate (if not one of the above categories); individual (no affiliation); and
5

other. If campaigns listed teams of individuals with clear organizational positions (e.g., a team of
undergraduate students participating in an iGEM contest), we coded them accordingly. The
“other” category of positions includes cases where the creators are teams of unknown
composition or organizations (e.g., a foundation).
Gender. We coded creators’ gender primarily based on first names using the API of
genderize.io. The algorithm returns the gender and a probability that a specific name-gender
attribution (male or female) was correct; in case it cannot decide, the algorithm returns none. In a
second step, we double-checked the accuracy of the codes and completed missing data with
additional help from the profile pictures of creators or Googling their name. Gender is set to
“N.A./unknown” if the primary organizer is a team or an organization.
Region. Many campaigns include a tag indicating the primary affiliation of the creators
(e.g., name of a university or company). If such an affiliation was not provided, we coded the
location of the researchers based on the project description or researcher profiles. Only 5% of
campaigns have more than one location and we thus focus on the primary one. Note that the
coding reflects the location of the researchers, which may differ from the location where research
is performed (e.g., a campaign by Duke University researchers to study the Brazilian rainforest
would be coded as located at Duke). We code the following broader regions: Non-US (11%),
US-Northeast (IL, IN, OH, PA, NJ, RI, CT, MA, NH, VT, ME, NY, MI, WI), US-South (FL,
MS, AL, GA, SC, NC, TN, KY, WV, VA, DC, MD, DE), US-West/Midwest (TX, LA, AR, OK,
NM, AZ, NV, UT, CO, KS, MO, IA, NE, WY, ID, MT, SD, MN, ND), and US-Pacific (CA, OR,
WA, AK, HI). Although it would be desirable to analyze data at the level of individual states,
many states have too few cases for reliable inference.
Creator count. This is the count of creators listed on the campaign webpage.
Project characteristics
Field. Creators indicated up to 5 field classifications on the campaign website. We coded a
series of 20 dummy variables taking the value of one if a particular field was selected (see Table
3). We collapsed small fields (fields with less than 5% of cases) into the field “Other”.
Project objective. We coded the substantive project objective by manually classifying
projects into the following categories: Project whose main objective is conducting scientific
research; projects that focus on development (e.g. the development of devices, tools, software,
and methods); and projects with other objectives (e.g., the restoration of objects or the protection
6

of animals and ecosystems). We classified projects as research if they focused on identifying
general mechanisms or empirical regularities. In many cases, creators of research projects also
stated their goal to publish results in a scientific journal.
Funding target. Once the campaign is closed, Experiment.com does not show the funding
target but shows the amount raised and the percentage of the target that has been raised. We
recover the target by dividing the amount raised by the percentage raised. This variable is
missing for 21 campaigns that raised zero percent of their target. For descriptive analyses, we
report figures in U.S. Dollars. Given the skewed distribution of funding targets, regression
analyses use logarithmized values of the variable.
Pilot project. We coded a dummy variable as one if the project description stated that the
project was a pilot study or that it involved data collection or testing for a larger follow-on
project. For example, one campaign stated, “It is almost impossible to achieve funding without
substantial preliminary data. This fundraiser will help fund this initial experiment and provide
data for future grant proposals.” [42]
Budget. Campaigns include a budget that shows the intended use of funds. Experiment.com
does not provide pre-defined budget categories and we hand-coded expenses into the following
categories: Salaries for organizers (individuals listed as creators on the campaign); salaries for
non-organizers (e.g., students, research assistants); equipment, materials, supplies, software, and
analysis services; travel (including conferences and field trips); other direct costs (e.g.,
compensation for patients, publications, open access fees); indirect costs (overhead); other
(including budget without details). We then compute for each project the share of costs in each
category.
Risk score. To obtain a proxy for project risk, we analyze the content of the project
description. We use the word list developed by Loughran and McDonald [43], which is based on
the union of uncertainty, weak modal, and negative words. Examples of uncertain words include
believe, pending, approximate, uncertain, and uncertainty. Examples of negative words include
failure, decline, and difficult. Examples of weak modal words include could, might, nearly,
maybe, and possibly. We calculate a score based on the Term Frequency-Inverse Document
Frequency (TF-IDF) weighting scheme, which gives more weight to words that are relatively
rare in the entire corpus of documents [44]. The formula also includes normalization to account
for the fact that campaigns differ in the length of their project descriptions. The word list used to
7

construct our measure has been used in several studies [e.g., 45, 46] and although it was not
developed specifically for scientific risk, we suggest that projects with higher scores on this
measure are likely to be perceived as more uncertain and risky by potential backers who consider
whether to provide resources. For a robustness check, we also construct a simpler measure by
just computing the frequency with which the words from the above list appear in a project
description.
Campaign characteristics
Endorsements 01. Experiment.com offers creators the option to show endorsements by
well-known scientists or other individuals. We coded a dummy variable equal to one if the
campaign lists at least one endorsement.
Prior papers 01. Dummy variable equal to one if the campaign lists at least one prior
scientific publication by at least one of the creators. Listing prior publications may allow
researchers to signal their accomplishment and scientific credibility.
Video 01. Dummy variable equal to one if the campaign includes a video that introduces the
creators and/or the project.
Lab notes pre closing 01. Experiment.com allows creators to provide background
information and campaign updates in the form of “lab notes”. We created a dummy variable
equal to one if creators posted at least one lab note prior to the closing of the campaign. This
variable may reflect that creators are willing to engage more actively with potential funders.
Rewards 01. Campaigns may offer rewards to donors for making a pledge. Examples of
rewards include photographs of animals, lab visits, or T-shirts. We coded a dummy variable
equal to one if a campaign offered any rewards. Although some campaigns make access to lab
notes contingent on a donation, contingent lab note access is not counted as a reward in our
coding.
Platform age. Campaigns run at different points in the platform’s life cycle, which may
affect their likelihood of success. To capture the age of the platform at the time that a particular
campaign is run, we compute the time difference between the closing of the focal campaign and
the closing of the first campaign on the platform (May 18, 2012), measured in weeks.
Outcomes
Funded 01. Dummy variable equal to one if the campaign raised at least 100% of its target.
8

Amount raised. Amount raised by the campaign (in U.S. Dollars), regardless of whether the
target was reached. In rare cases, this figure includes funds raised outside the platform, e.g., at in
person events. Given the skewed distribution of this measure, regression analyses use
logarithmized values.
Press coverage 01. Some campaigns have a section that lists coverage of the campaign by
science journalists. We coded a dummy variable equal to one if the campaign lists at least one
press item. Assuming that science journalists typically have scientific training or relevant
experience [47], we interpret this measure as reflecting success in attracting attention from a
more professional audience. We also include this variable in regressions of financial funding
outcomes because press coverage listed on the campaign website may serve as a quality signal
for potential backers. Excluding this variable from the latter regressions does not change our
results.

Results
Selected descriptive insights
Creator characteristics. We first examine key characteristics of the creators starting
crowdfunding campaigns. Panel A in Fig. 1 shows the affiliation of the creators. Over 80% are
affiliated with educational institutions (e.g., universities and colleges), 4.58% are affiliated with
firms, and 8.45% with other organizations such as foundations, museums, non-profits, or
research institutes. Roughly 5% of creators are un-affiliated, sometimes explicitly calling
themselves “independent researcher”. The preponderance of campaigns involves creators from
just one type of affiliation. In particular, of all the campaigns with at least one creator from an
educational institution, only 1.7% also have a creator affiliated with a firm, and only 6.3% also
have a creator affiliated with an “other” organization (e.g., nonprofit, research institute).
We further distinguish creators affiliated with educational institutions by their position (Fig.
1, Panel B). We find that a large share of these creators are students, including over 30%
undergraduate or master’s students and 25% PhD or MD students. Roughly 7% are postdocs,
11.6% assistant professors, and 17% associate or full professors.
With respect to gender, 56.6% of all primary campaign creators are male and 39.7% female.
In the remaining cases, gender could not be determined or did not apply because an organization,
not a person, was listed as the creator.
9

As noted earlier, 68% of campaigns were started by a single creator while 32% were started
by teams ranging from 2 to 7 creators. Table 2 shows creators’ characteristics separately for all
creators (column 1), and for only one creator per campaign, taking the first-listed creator in case
of teams (column 2). For team-based projects, we further show creators’ characteristics
separately for the investigator listed first in the team (column 3), and for all other team members
who were not listed first (column 4). First and non-first listed individuals in teams are quite
similar in terms of affiliation, reflecting the low rate of cross-affiliation collaborations. However,
first listed creators in teams are somewhat more senior (in particular, less likely to be student
below PhD/MD level) and less likely to be female.
The vast majority of creators on the platform Experiment.com are located in the U.S. (89%)
and 11% are located in other countries. The US-based creators were distributed across all
regions, including northeastern states (31%), southern states (15%), states bordering the Pacific
(22%), and states in the west/midwest (17%). We compared the geographic distribution of
funded US-based campaigns to the distribution of awards by NIH and NSF over a comparable
time period (2012-2015). Fig. S1 shows that Experiment.com has a somewhat larger share of
successful projects in the Pacific region and a smaller share in the northeast compared to
NSF/NIH, likely because Experiment.com was started on the West Coast. However,
Experiment.com funding volume is much more concentrated in the northeast region, which is
largely due to an extremely successful outlier project located in Massachusetts (see below).
While the specific patterns are unlikely to generalize, two observations may be more general.
First, at least in the first years of their operation, crowdfunding platforms may be more localized
than traditional funding sources, serving primarily their home regions [see 26]. Second, while
government grants tend to be of similar sizes [48], amounts raised in crowdfunding can vary
quite dramatically. As such, the regional distribution of amounts raised may differ quite
substantially from the regional distribution of the number of successful campaigns.
Project characteristics. After providing insights on campaign creators, we examine more
closely what kinds of projects these creators propose. First, the most frequently listed field
classifications are (in descending order of frequency): Biology, Ecology, Medicine, Engineering,
Education, Psychology, and Social Sciences (Tab. 3).
In terms of their substantive objectives, roughly 78% of projects aim at the scientific
investigation of a topic (e.g. the impact of climate change on oak trees, the use of computer
10

games to develop team skills in autistic children, the testing of a drug against kidney cancer), and
12% aim at the development of devices, tools, software, or methods. The remaining 10% have
other types of objectives, such as the restoration of objects (e.g. dinosaur skeletons) or the
protection of animals and ecosystems.
As a proxy for project size, we examine the amount of funding creators seek to raise.
Funding targets ranged from $100 to over $100,000. One extreme project had a target of $1
million to find a cure for the rare Batten disease [49]. The average project target was $6,425, the
median $3,500. Thus, while some campaigns reach the scale of traditional funding requests, most
seek to raise small amounts. One possible explanation is that crowdfunding is used for pilot
studies that are intended to lead to larger follow-on projects. Our coding shows that 16% of
projects were pilot studies.
Campaigns also include a budget, allowing us to explore for what kinds of expenses creators
seek to raise funds. The average campaign requested the majority of funds for materials,
equipment and services (59%), followed by travel (16%) and salaries for personnel other than the
creators (e.g. research assistants) (11%). Compensation or salary for creators constituted only 3%
of the average budget.
Predictors of fundraising success
Experiment.com campaigns typically last 30-45 days and work with an all-or-nothing
policy, i.e., creators receive pledged funds only if the campaign achieves the pre-defined target at
the closure date. The success rate in our sample was 48%, higher than the success rate of projects
on the general-purpose platform Kickstarter (36%) [40] and considerably higher than the success
rates at NSF (23% in competitive grants in 2014) and NIH (16% for new research applications in
2015) [50, 51]. Conditional upon funding success, projects raised a total of $4.37 million,
distributed in a range from $110 to an extreme of $2.6 million for the Batten disease project,
with an average of $12,617 and median of $3,103. We now turn to the question how funding
success is related to characteristics of the creators, the projects, and the campaigns.
Empirical approach. We examine predictors of fundraising success using regression
models that routinely control for factors such as scientific field or age of the platform (Tab. 4).
For the 32% of campaigns that were posted by a team of creators, our main analysis focuses on
the characteristics of the first listed creator. The rationale is that in the sciences, first listed
authors are typically those who “own” the project and make the largest substantive contributions
11

[52]. Campaign descriptions also typically provide more information about first authors than
non-first authors, providing support for the notion that these individuals are driving the project.
Robustness checks using team averages of individual characteristics (e.g., the share of female
team members) rather than the characteristics of the primary creator show very similar results
(reported in Tab. S1).
We use two different variables to capture fundraising outcomes: The first is the dummy
variable indicating whether a campaign achieved its target (Table 4, Models 1-3). These models
are estimated using logit regressions, and we report odds ratios for ease of interpretation (odds
ratios greater than one indicate a positive relationship, odds ratios smaller than one indicate a
negative relationship). The second dependent variable is the continuous measure of pledges
received regardless of whether the funding target was achieved (Models 4-6). These regressions
are estimated using OLS. All regressions use heteroscedasticity-robust standard errors.
For each of the two outcome variables, we estimate three models. The first model includes
all control variables as well as characteristics of the primary campaign creator but does not
include project or campaign characteristics. The second additionally includes characteristics of
the project. The third additionally includes characteristics of the campaign. This stepwise
approach allows us to first examine differences in success rates for different types of individuals,
and to then examine the extent to which these differences may be explained by differences in the
types of projects they seek funding for or differences in the way campaigns are implemented.
And of course, the degree to which project and campaign characteristics predict funding success
is of interest in its own right.
Funding success and creator characteristics. Model 1 in Table 4 shows that that junior
scientists (students and postdocs) as well as independent researchers are more likely to reach
their funding targets than associate and full professors. These differences remain significant even
accounting for the fact that their targets tend to be lower and thus easier to achieve (Model 2; a
regression with funding target as the dependent variable is shown in Model 7). There is no
significant difference between junior and senior scientists in the amount of pledges received
(Table 4, Model 4), although the former raise more money conditional upon a particular funding
target (Model 5). Thus, while there are concerns that junior investigators are at a disadvantage
when applying to traditional funding agencies [12], the crowd appears favorable towards junior
scientists. While we can only speculate, this result may reflect that backers consider perceived
12

need in addition to scientific merit, or that backers derive utility from supporting the education
and professional development of junior scientists.
We find no systematic differences in funding success between creators affiliated with
educational institutions versus any other type of organizations. Since measures of positions are
correlated with affiliation types, we also re-estimate regressions with these variables separately;
the substantive results are unchanged (Tab. S2, Models 1-6).
Consistent with prior research [53], we find significant gender differences in crowdfunding
success: Women have higher odds of reaching their funding goal than men (Table 4, Model 1)
and also raise significantly more money (Model 4). While higher success rates of women on
Kickstarter have been partly attributed to the fact that women have a tendency to propose smaller
projects [53], we find no such evidence in science: Funding targets of campaigns created by men
and women show no significant difference (Model 7) and the gender dummy changes little when
project and campaign characteristics are included (Models 2, 3, 5, and 6). Women’s significantly
higher success rates in crowdfunding contrast with similar or slightly lower odds of success than
men when competing for grants from government agencies such as NIH or NSF [54, 55]. Future
research is needed to explore potential drivers of the observed gender differences in
crowdfunding success, and better data on the project backers (including their gender) would be
particularly valuable [21].
Funding success and project characteristics. We now turn more explicitly to the
characteristics of the project for which funding is sought (Table 4, Models 2 and 5). We find no
significant differences in funding success between projects pursuing research versus
development objectives, or between pilot and non-pilot projects. Projects with larger funding
targets are less likely to get funded, consistent with prior evidence [2]. At the same time,
campaigns with higher targets receive a larger volume of pledges, highlighting the challenge of
setting funding targets that are achievable but also result in meaningful resources when achieved.
To investigate whether fundraising success is correlated with the riskiness of the project, we
include the text-based measure of risk. This measure has no relationship with funding success or
the amount of money raised (Table 4, Models 2 and 5). Robustness checks using an alternative
simpler risk measure (see variables and measures above) give the same result (Table S2, Models
7-8). Although our analysis cannot address the question whether the crowd funds more or less
risky projects than traditional funding agencies [56], it suggests that backers on dedicated
13

platforms for funding scientific research pay little attention to risk when deciding which
particular research projects to support.
Funding success and campaign characteristics. The data show several relationships
between funding success and features of the campaign itself (Tab. 4, Models 3 and 6). First, a
potential challenge in crowdfunding research is that backers – especially those without a
background in science – may find it difficult to assess the scientific merit of projects or creators.
Campaigns can address this challenge by using various quality signals [1]. For example,
Experiment.com offers campaign creators the option to include endorsements by well-known
scientists or other individuals. We find that campaigns with endorsements (15% of all
campaigns) have significantly higher odds of success and raise more funds than campaigns
without endorsement. Another potential quality signal is the listing of prior publications that are
(co-)authored by the creators. Surprisingly, while 25% of campaigns list prior publications, these
campaigns are not more likely to be funded and do not raise more money. This result is
particularly interesting given the important role that prior publications play in traditional grant
applications [35].
Second, Experiment.com allows creators to provide background information and campaign
updates in the form of “lab notes”. Campaigns that posted lab notes prior to closure (67% of all
campaigns) have significantly higher odds of success and raise more money than projects
without lab notes. Campaigns featuring a video presentation (57%) are also more likely to
succeed, consistent with other crowdfunding contexts [2]. These results reinforce the notion that
effort in designing campaigns as well as reaching out and interacting with the crowd can be an
important predictor of funding success [19, 57].
Finally, prior studies argue that research projects find it difficult to offer the kinds of
tangible rewards that are often central to crowdfunding campaigns on platforms such as
Kickstarter [17]. Consistent with this concern, most projects in our sample do not offer any
rewards. However, 11% of projects offer – sometimes quite creative – rewards such as visits to
the research lab, acknowledgement on future publications, photographs of animals observed, or
the naming of a shark. Projects offering a reward have a higher likelihood of achieving their
target and also raise significantly more funds. This observation suggests that backers of scientific
research may not only contribute for the sake of supporting science or to help individual
researchers but may also respond to explicit incentives and rewards.
14

Comparing crowd versus expert audiences
Our finding that junior scientists tend to be more successful and that prior publications
appear to matter little suggests that the crowd may apply quite different criteria than a traditional
scientific audience when deciding which projects to support. To further explore this possibility,
we examine which campaigns receive press coverage from science writers (Tab. 4, Models 810). Our conjecture is that science writers are more likely than the general public to have
advanced scientific training [47] and subscribe more strongly to traditional criteria when
evaluating the importance and promise of research. As expected, we find intriguing differences
between the factors that predict funding success versus attention from the press. First, junior
scientists are more likely to be funded than senior scientists, but they are less likely to receive
press coverage. Second, lab notes and rewards are associated with significantly higher funding
success but they are not correlated with press attention. Third, listing creators’ prior publications
– a potential quality signal – does not increase the chances to be funded, but it does have a
positive relationship with press coverage. Science writers’ preferences are not necessarily
representative of those of scientists generally or of decision makers at traditional funding
agencies. However, our results provide some tentative evidence that the crowd judges projects
differently from evaluators who have a more professional scientific background. Similar
evidence has been found in recent work comparing crowd and expert evaluations in the context
of the arts [58].
Before we conclude, we note that all regressions should be interpreted as correlational in
nature. Thus, significant coefficients on independent variables do not necessarily imply a causal
effect of these variables on funding outcomes or on press attention. Causal interpretation is
difficult because independent variables may proxy for otherwise unobserved factors, such as
differences in the nature of research or unobserved outreach activities by creators. On the other
hand, concerns about reverse causality can largely be excluded since most of our independent
variables are fixed before funding outcomes are observed. In light of remaining endogeneity
concerns, the statistically and economically significant relationships observed in our data suggest
fruitful avenues for future research examining why exactly certain characteristics of creators,
projects, and campaigns are associated with higher fundraising success.

15

Discussion
Crowdfunding for scientific research is still in its early stages, but the considerable number
of funded projects suggests that it can provide important financial support. Moreover,
crowdfunding seems to differ in important ways from traditional funding mechanisms such as
grants from government agencies [12, 35, 39, 54, 55, 59]: Success rates are comparatively high,
junior scientists tend to be more successful than senior scientists, and female investigators are
more likely to be funded than male investigators. Furthermore, we find no evidence that riskier
projects have a lower likelihood of being funded and creators’ prior publications appear to matter
little for funding success. Fundraising is also faster than in the traditional grant-based system. At
the same time, the amounts raised with crowdfunding tend to be much smaller and funds are
used primarily for materials and travel rather than salaries or tuition.
Our results support the view that crowdfunding of scientific research broadens access to
resources for groups that have been excluded or disadvantaged in traditional funding systems,
similar to what has been shown in crowdfunding of business initiatives [27]. However, the
amount of resources raised – at the level of individual projects but also the platform as a whole –
is presently too small for crowdfunding to serve as a substitute for traditional funding
mechanisms. As such, crowdfunding for research may best be seen as a complement to such
traditional sources. In particular, crowdfunding appears to be particularly useful for students or
(aspiring) researchers who do not have the track record required by most traditional funding
agencies, and it may be suitable for smaller pilot studies without preliminary evidence. In these
areas, even a relatively small grant can enable a project to proceed and may also make a longterm difference by allowing researchers to increase their chances of subsequent funding in the
traditional system [see 27].
Despite these benefits, there are also potential concerns. First, the crowd may fund projects
that are in legal (or political) grey zones. For example, some creators in our sample noted that
traditional funding sources would not support projects on gun culture [see 60], on the impact of
the legalization of marijuana, or on the development of molecules that can lead to mutations in
humans. Second, although Experiment.com encourages academics to obtain study approval from
their Institutional Review Boards, it is not clear whether all creators who work with human
subjects – especially those outside academia – understand and follow guidelines for ethical and
responsible research [6]. A final concern is that crowdfunding sidesteps traditional peer review
16

and the crowd may support projects with low scientific merit [61]. Of course, backers may
deliberately ignore some of the selection criteria used by traditional funding agencies (such as
prior publications) and may also support campaigns for reasons other than scientific merit, e.g.,
to help a passionate student or enable a “fun” project. Nevertheless, platforms should require that
projects provide enough information to allow potential backers to make informed decisions.
To raise meaningful amounts of funding, campaign creators need to reach beyond family
and friends to engage broader audiences [57, 62]. Yet, reaching a broad audience requires
significant effort, e.g., to develop videos, write engaging lab notes, or respond to backers’
comments and suggestions (see Fig. S2 for an example). Some creators may come to realize that
the relatively small amount of money that can be raised is not worth these costs in terms of time
and effort [63]. Indeed, our finding that crowdfunding is used especially by junior scientists may
reflect that these scientists have lower opportunity costs of time than senior researchers, while
also having less access to traditional funding sources. Junior scientists may also feel more
comfortable using social media, an important component of many crowdfunding campaigns [19,
57]. More generally, the rise of crowdfunding is likely to increase the value of skills in
communicating research and interacting with “citizen” audiences [56]. In addition to dedicated
programs such as the recently launched Lab for Open Innovation in Science [64], educators and
PhD advisors should consider how they can help students develop such skills as part of the
regular research training.
Although our analysis focused on financial resources, crowdfunding may also provide
several non-financial benefits. Creators can receive feedback on their research, achieve greater
visibility of their work, and may enjoy interactions with broader audiences [57]. Moreover,
backers may continue to support projects in other ways, e.g., by offering access to infrastructure
and research sites (see Fig. S2). The public can benefit from crowdfunding by gaining direct
insights into the research process (e.g., via lab notes), participating in the allocation of resources
for research, and by feeling empowered to contribute to the progress of science [56, 57]. Future
research is needed to quantify these non-financial benefits and to develop tools that increase
scientists’ ability to achieve the financial as well as non-financial objectives of their
crowdfunding campaigns.
This discussion of non-financial benefits of crowdfunding highlights potential ties to another
recent development - namely “crowd science” or “citizen science” projects, where scientists ask
17

the public not for financial resources but for inputs in the form of time and knowledge [9, 65].
We suggest that future research could benefit from considering similarities (and differences)
between these mechanisms for involving the public in different aspects of the scientific research
process. Some of the tools and best practices developed in the context of citizen science [66, 67]
may prove useful in crowdfunding efforts, while findings from crowdfunding research may help
citizen science projects to understand the dynamics of project participation and to increase
participant engagement [2, 9]. Among others, future research could explore whether individuals
who are willing to support a project with money are also more likely to support projects with
time or other contributions. Similarly, some crowdfunding campaigns seek funding to support
citizen science projects, and it would be important to know whether researchers can benefit from
asking for financial and non-financial contributions at the same time, or whether platforms can
increase their effectiveness by co-hosting crowdfunding and citizen science projects.
Even though our focus is on understanding crowdfunding as a mechanism to raise resources
for scientific research, our findings also contribute to the broader crowdfunding literature. First,
some of our results corroborate prior findings in a new empirical context, suggesting broader
generalizability of those prior findings. Among others, we confirm that women are not at a
disadvantage but tend to be more successful than men in raising crowdfunding [21-23]. Using a
rich set of measures on projects and campaigns, we also find that this advantage holds even when
we account for campaign targets or characteristics of the campaign. Our finding that campaigns
with endorsements are more successful than campaigns without endorsements is consistent with
prior evidence from Kickstarter [33]. Finally, we confirm that active engagement with the crowd
(e.g., in the form of lab notes) can increase fundraising success [32, 57] and that visual
information such as videos is particularly beneficial [2, 23, 31].
Perhaps more importantly, we add to the crowdfunding literature by exploring aspects that
have received less attention in prior work. Unlike prior studies, for example, we can observe
creators’ substantive experience (proxied by position such as student versus professor) and show
that experience has a negative relationship with funding success. This relationship is surprising,
at least if we believe that more experienced scientists are better able to identify important
research questions and are better able to execute a given project [35, 68]. This counterintuitive
result suggests that funders may support projects not only for their stated project objective but
also for other reasons such as the perceived need of the creator. Of course, it may also be that
18

less experienced scientists have more creative project ideas [69] or that they are better able to
relate to and communicate with non-expert audiences. Either way, future research should
examine how creators’ experience is related to funding success in other contexts, including
settings where backers have a clear personal interest in project success (i.e., in rewards-based
campaigns that pre-sell products).
Relatedly, we find that projects pursuing research versus development objectives are
similarly likely to succeed. This result seems at odds with recent work showing that funding
success on Kickstarter is higher for incremental than for radical innovations [15]. Although the
research vs. development and radical vs. incremental distinctions are conceptually different, an
intriguing conjecture for the different findings is that Kickstarter and Experiment.com have
different types of “dominant crowds”: While backers on Kickstarter may be more concerned
with the likelihood of success and the usefulness of project outcomes for their own needs,
backers on Experiment.com may not expect to benefit personally from project results and may
thus be willing to support also projects that are riskier or that promise general insights rather than
tangible outcomes. More generally, our findings highlight the need for future research that
examines the predictors of funding success across a range of different platforms and that
explores the role of contingency factors such as the type of crowdfunding (e.g., rewards-based
vs. donations) as well as the goals and motives of the typical backers.
The results presented in this paper suggest a number of additional questions for future
research. First, we observed that several characteristics of creators, projects, and campaigns are
significant predictors of funding success, but we cannot establish the causal nature of these
relationships. Experimental studies that assign key characteristics randomly or exploit suitable
natural experiments could provide causal evidence and identify tools creators can use to improve
the performance of their campaigns. Second, our data include no information about the backers,
which is a challenge with crowdfunding research generally [20]. It would be interesting to know
whether backers tend to come from particular parts of the general population (e.g., with respect
to education, science background, or age), and which creators are more successful in reaching
beyond their friends and family. Third, future research is needed on why backers support
scientific research projects, how their motivations differ from those of traditional funding
agencies, and how backer motivations shape their interactions with creators. Finally, while we
provided insights into campaigns’ ability to raise funding, we do not observe whether funded
19

projects achieve their scientific objectives. Future research is needed to measure the scientific
output resulting from crowd-funded projects, explore which projects are more likely to be
successful, and whether interacting with the crowd can allow researchers to improve the quality
and impact of their scientific work.

20

References
1.

Agrawal AK, Catalini C, Goldfarb A. Some simple economics of crowdfunding. In: Lerner
J, Stern S, editors. Innovation Policy and the Economy. 14: National Bureau of Economic
Research; 2014. p. 63-97.

2.

Mollick E. The dynamics of crowdfunding: An exploratory study. Journal of Business
Venturing. 2014;29(1):1-16.

3.

Bruton G, Khavul S, Siegel D, Wright M. New financial alternatives in seeding
entrepreneurship: Microfinance, crowdfunding, and peer-to-peer innovations.
Entrepreneurship Theory and Practice. 2015;39(1):9-26. doi: 10.1111/etap.12143.

4.

Fleming L, Sorenson O. Financing by and for the Masses. California Management Review.
2016;58(2):5-19.

5.

Lin T. Scientists turn to crowds on the web to finance their projects. New York Times. 2011
July 11, 2011.

6.

Cha A. Crowdfunding propels scientific research. Washington Post. 2015 Jan. 18, 2015.

7.

Siva N. Crowdfunding for medical research picks up pace. The Lancet.
2014;384(9948):1085-6. doi: 10.1016/s0140-6736(14)61661-5.

8.

Kessler S. Georgia Tech launches its own crowdfunding site for scientific research.
Fastcompany. 2013 Sept. 4, 2013.

9.

Sauermann H, Franzoni C. Crowd science user contribution patterns and their implications.
Proceedings of the National Academy of Sciences. 2015;112(3):679-84.

10. Jeppesen LB, Lakhani K. Marginality and problem-solving effectiveness in broadcast
search. Organization Science. 2010;21(5):1016-33.
11. Nielsen M. Reinventing Discovery: The New Era of Networked Science: Princeton
University Press; 2011.
12. Alberts B, Kirschner MW, Tilghman S, Varmus H. Rescuing US biomedical research from
its systemic flaws. Proceedings of the National Academy of Sciences. 2014;111(16):5773-7.
13. Franzoni C, Sauermann H. Crowd Science: The organization of scientific research in open
collaborative projects. Research Policy. 2014;43(1):1-20.
14. Colombo MG, Franzoni C, Rossi-Lamastra C. Cash from the crowd. Science.
2015;348:1201-2.
21

15. Chan CSR, Parhankangas A. Crowdfunding Innovative Ideas: How Incremental and Radical
Innovativeness Influence Funding Outcomes. Entrepreneurship Theory and Practice.
2017;41(2):237-63. doi: 10.1111/etap.12268.
16. Sturgis P, Allum N. Science in society: re-evaluating the deficit model of public attitudes.
Public understanding of science. 2004;13(1):55-74.
17. Wheat RE, Wang Y, Byrnes JE, Ranganathan J. Raising money for scientific research
through crowdfunding. Trends in Ecology & Evolution. 2013;28(2):71-2.
18. Butticè V, Franzoni C, Rossi-Lamastra C, Rovelli P. The road to crowdfunding success: A
review of extant literature. In: Afuah A, Tucci CL, Viscusi G, editors. Creating and
Capturing Value Through Crowdsourcing: Oxford University Press; 2017.
19. Byrnes JE, Ranganathan J, Walker BL, Faulkes Z. To crowdfund research, scientists must
build an audience for their work. PLoS ONE. 2014;9(12):e110329.
20. McKenny AF, Allison TH, Ketchen DJ, Short JC, Ireland RD. How Should Crowdfunding
Research Evolve? A Survey of the Entrepreneurship Theory and Practice Editorial Board.
Entrepreneurship Theory and Practice. 2017;41(2):291-304.
21. Greenberg J, Mollick E. Activist choice homophily and the crowdfunding of female
founders. Administrative Science Quarterly. 2017;62(3):341–74.
22. Frydrych D, Bock AJ, Kinder T, Koeck B. Exploring entrepreneurial legitimacy in rewardbased crowdfunding. Venture Capital. 2014;16(3):247-69.
23. Colombo MG, Franzoni C, Rossi-Lamastra C. Internal social capital and the attraction of
early contributions in crowdfunding. Entrepreneurship Theory and Practice. 2015;39(1):75100.
24. Zheng H, Li D, Wu J, Xu Y. The role of multidimensional social capital in crowdfunding: A
comparative study in China and US. Information & Management. 2014;51(4):488-96.
25. Butticè V, Colombo MG, Wright M. Serial crowdfunding, social capital, and project
success. Entrepreneurship Theory and Practice. 2017;41(2):183-207.
26. Agrawal A, Catalini C, Goldfarb A. Crowdfunding: Geography, social networks, and the
timing of investment decisions. Journal of Economics & Management Strategy.
2015;24(2):253-74.
27. Sorenson O, Assenova V, Li G-C, Boada J, Fleming L. Expand innovation finance via
crowdfunding. Science. 2016;354(6319):1526-8.
22

28. Skirnevskiy V, Bendig D, Brettel M. The influence of internal social capital on serial
creators’ success in crowdfunding. Entrepreneurship Theory and Practice. 2017;41(2):20936.
29. Pitschner S, Pitschner-Finn S. Non-profit differentials in crowd-based financing: Evidence
from 50,000 campaigns. Economics Letters. 2014;123(3):391-4.
30. Parhankangas A, Renko M. Linguistic style and crowdfunding success among social and
commercial entrepreneurs. Journal of Business Venturing. 2017;32(2):215-36.
31. Dushnitsky G, Marom D. Crowd monogamy. London Business School Review.
2013;24(4):24-6.
32. Block J, Hornuf L, Moritz A. Which updates during an equity crowdfunding campaign
increase crowd participation? Small Business Economics. 2018;50(1):3-27.
33. Courtney C, Dutta S, Li Y. Resolving information asymmetry: Signaling, endorsement, and
crowdfunding success. Entrepreneurship Theory and Practice. 2017;41(2):265-90.
34. Mohammadi A, Shafi K. Gender differences in the contribution patterns of equitycrowdfunding investors. Small Business Economics. 2018;50(2):275-87.
35. Stephan P. How Economics Shapes Science: Harvard University Press; 2012.
36. Sauermann H, Stephan P. Conflicting logics? A multidimensional view of industrial and
academic science. Organization Science. 2013;24(3):889-909.
37. Stokes D. Pasteur's Quadrant: Basic Science and Technological Innovation. Washington,
DC: Brookings Institution Press; 1997.
38. Wang J, Veugelers R, Stephan P. Bias against novelty in science: A cautionary tale for users
of bibliometric indicators. NBER Working Paper #221802016.
39. Azoulay P, Graff Zivin JS, Manso G. Incentives and creativity: evidence from the academic
life sciences. The RAND Journal of Economics. 2011;42(3):527-54. doi: 10.1111/j.17562171.2011.00140.x.
40. Kickstarter. [Feb. 2018]. Available from: https://www.kickstarter.com/help/stats.
41. Indiegogo. Available from: https://support.indiegogo.com/hc/en-us/articles/115002403448How-do-I-raise-funds-for-a-nonprofit-.
42. Bishop G, Hanson B. Using nanoparticles to activate immune cells to fight tumors.
https://experimentcom/projects/using-nanoparticles-to-activate-immune-cells-to-fighttumors?s=discover2014.
23

43. Loughran T, McDonald B. IPO first-day returns, offer price revisions, volatility, and form S1 language. Journal of Financial Economics. 2013;109(2):307-26.
44. Manning CD, Schütze H. Foundations of statistical natural language processing: MIT Press;
1999.
45. Garcia D. Sentiment during recessions. The Journal of Finance. 2013;68(3):1267-300.
46. Liu B, McConnell JJ. The role of the media in corporate governance: Do the media
influence managers' capital allocation decisions? Journal of Financial Economics.
2013;110(1):1-17.
47. Austin J. Science writing and editing 2011 [Feb. 2018]. Available from:
http://www.sciencemag.org/careers/2011/10/science-writing-and-editing.
48. Miklos A, Anderson V. Distribution of NIGMS R01 Award Sizes 2016. Available from:
https://loop.nigms.nih.gov/2016/05/distribution-of-nigms-r01-award-sizes/.
49. Finding a cure for Batten disease. Available from: https://experiment.com/projects/findinga-cure-for-batten-disease.
50. National Science Foundation. Report to the National Science Board on the National Science
Foundation's Merit Review Process. 2015 Contract No.: NSB-2015-14
51. National Institutes of Health. Research Portfolio Online Reporting Tools 2016. Available
from: https://report.nih.gov/success_rates/.
52. Sauermann H, Haeussler C. Authorship and contribution disclosures. Science Advances.
2017;3(11). doi: 10.1126/sciadv.1700404.
53. Marom D, Robb AM, Sade O. Gender dynamics in crowdfunding: Evidence on
entrepreneurs, investors, deals, and taste-based discrimination. SSRN Working Paper2016.
54. Ley TJ, Hamilton BH. The gender gap in NIH grant applications. Science.
2008;322(5907):1472-4.
55. Ceci SJ, Williams WM. Understanding current causes of women's underrepresentation in
science. Proceedings of the National Academy of Sciences. 2011;108(8):3157-62.
56. Hui JS, Gerber EM, editors. Crowdfunding science: Sharing research with an extended
audience. Proceedings of the 18th ACM Conference on Computer Supported Cooperative
Work & Social Computing; 2015: ACM.
57. Li F-W, Pryer KM. Crowdfunding the Azolla fern genome project: a grassroots approach.
GigaScience. 2014;3(1):16-9.
24

58. Mollick E, Nanda R. Wisdom or madness? Comparing crowds with expert evaluation in
funding the arts. Management Science. 2016;62(6):1533-53. doi:
doi:10.1287/mnsc.2015.2207.
59. Laudel G. How do National Career Systems Promote or Hinder the Emergence of New
Research Lines? Minerva. 2017;55(3):341-69.
60. Wadman M. Firearms research: The gun fighter. Nature. 2013;496(7446):412-5.
61. Cha AE. Crowdfunding propels scientific research. The Washington Post. 2015.
62. Kuppuswamy V, Bayus B. Crowdfunding creative ideas: The dynamics of project backers in
Kickstarter. SSRN Working Paper2015.
63. Marshall J. Kickstart your research. Proceedings of the National Academy of Sciences.
2013;110(13):4857-9.
64. Ludwig Boltzmann Gesellschaft. Lab for Open Innovation in Science (LOIS).
65. Bonney R, Shirk JL, Phillips TB, Wiggins A, Ballard HL, Miller-Rushing AJ, et al. Next
steps for Citizen Science. Science. 2014;343(6178):1436-7.
66. Bonney R, Cooper CB, Dickinson J, Kelling S, Phillips T, Rosenberg KV, et al. Citizen
science: a developing tool for expanding science knowledge and scientific literacy.
BioScience. 2009;59(11):977-84.
67. Prestopnik NR, Crowston K, editors. Citizen science system assemblages: understanding the
technologies that support crowdsourced science. Proceedings of the 2012 iConference;
2012: ACM.
68. Merton RK. The Sociology of Science: Theoretical and Empirical Investigations. Chicago:
University of Chicago Press; 1973. xxxi, 605 p. p.
69. Jones BF, Weinberg BA. Age dynamics in scientific creativity. Proceedings of the National
Academy of Sciences. 2011;108(47):18910-4.

25

Panel A

Panel B
Student below PhD/MD

Educational

30.32

81.87

PhD/MD student

Company/ firm

25.30

Postdoc

4.58

7.09

Assistant professor

Other organization

8.45

11.56

Associate/full professor

17.01

Employee (other)
No affiliation

7.31

5.11

Other position

0

20

40
60
percent

80

1.42

0

10

20
percent

30

Fig. 1: Affiliation of all project creators (Panel A, N=1,136) and position of creators who are
affiliated with an educational institution (Panel B, N=917). Excludes cases with missing data.

26

Tab. 1: Examples of dedicated platforms for crowdfunding scientific research
Name

URL

Opened

Status as of January 2018

https://www.Experiment.com
http://www.petridish.org
http://www.davincicrowd.com

2012
2012
2012

Active. 1820 projects hosted.
Closed. 32 projects hosted.
Active. 92 projects hosted.

Consano

http://www.consano.org

2013

Active. 67 projects hosted.

Donorscure

http://www.donorscure.org

2013

Active. 16 projects hosted.

Wallacea/Crowdscience
Futsci
Science Starter

http://crowd.science
http://futsci.com
http://www.sciencestarter.de

2014
2015
2015

Active. 36 projects hosted.
Active. 12 projects hosted.
Active. 122 projects hosted.

http://myprojects.cancerresearchuk.org
http://starter.gatech.edu

2008
2013

Closed.
Closed.

http://spark.ucla.edu
http://crowdfund.vt.edu

2014
2017

Active. 15 projects hosted.
Active. 29 projects hosted.

Independent platforms
Experiment
Petridish
Davincicrowd

Institution-specific platforms
Cancer Research UK
Georgia Institute of Technology
UCLA
Virginia Tech

27

Tab. 2: Summary statistics at the creator level
Variable
Affiliation

Position

Gender

Educational institution
Firm
Other organization
None/independent
Affiliation unknown
Below PhD/MD
PhD/MD
Postdoc
Assistant professor
Associate/Full professor
Employee
Individual/no affiliation
Other position
Position unknown
Male
Female
Gender N/A or unknown

All creators
N=1,153
0.81
0.05
0.08
0.05
0.01
0.24
0.20
0.06
0.09
0.14
0.17
0.05
0.02
0.03
0.57
0.40
0.04

First listed
N=728
0.80
0.05
0.08
0.06
0.00
0.21
0.23
0.05
0.10
0.14
0.18
0.06
0.02
0.01
0.59
0.37
0.05

In team: first
N=231
0.83
0.04
0.10
0.03
0.00
0.17
0.21
0.08
0.11
0.20
0.17
0.03
0.03
0.01
0.56
0.39
0.04

In team: not first
N=425
0.81
0.03
0.08
0.04
0.04
0.29
0.15
0.07
0.07
0.13
0.15
0.04
0.02
0.07
0.53
0.45
0.02

28

Tab. 3: Summary statistics at the campaign level (including average creator characteristics)
avg_affil_~c
avg_affil_~m
avg_affil_~r
avg_affil_~e
avg_pos_be~w
avg_pos_phd
avg_pos_po~c
avg_pos_as~t
avg_pos_as~c
avg_pos_empl
avg_pos_in~l
avg_pos_ot~r
avg_ge~_male
avg_ge~emale
avg_gender~r
_Iregion1_1
_Iregion1_2
_Iregion1_3
_Iregion1_4
_Iregion1_5
_Iregion1_9
researcher~t
field_Biol~y
field_Ecol~y
field_Medi~e
field_Chem~y
field_Engi~g
field_Educ~n
field_Psyc~y
field_Soci~e
field_Other
_Igoal_cat_1
_Igoal_cat_2
_Igoal_cat_9
b_total
bshare_org~y
bshare_non~y
bshare_equ~t
bshare_tra~l
bshare_dir~t
bshare_ind~t
bshare_other
target
pilot
risk_score
risk_~180130
endorseme~01
priorown
video
notes_pre01
reward
platformage
funded01
raisedamount
raisedperc~t
avgpledge
press01

Variable
Share educational
Share firm
Share other organization
Share none/independent
Position
Share below PhD/MD
Share PhD/MD
Share Postdoc
Share assistant professor
Share associate/full professor
Share employee
Share individual/no affiliation
Share other position
Gender
Share male
Share female
Share n/a or unknown
Region
US south
US northeast
US pacific
US west/midwest
Non-US
Unknown
Other creator characteristics Creator count
Field
Biology
Ecology
Medicine
Chemistry
Engineering
Education
Psychology
Social Science
Other field
Objective
Research
Development
Other goal
Budget
Total budget
Share creator salary
Share other salary
Share equipment
Share travel
Share other direct
Share indirect cost
Share other
Other project characteristics Funding target
Pilot project
Risk score
Risk score simple
Campaign characteristics
Endorsement 01
Prior papers 01
Video 01
Lab notes pre closing 01
Rewards 01
Platform age
Outcomes
Funded 01
Amount raised
Raised percent
Average pledge
Press coverage 01
Affiliation

Mean
0.80
0.05
0.09
0.06
0.23
0.22
0.05
0.10
0.12
0.18
0.06
0.03
0.58
0.38
0.04
0.15
0.32
0.22
0.17
0.11
0.03
1.58
0.51
0.32
0.25
0.05
0.13
0.12
0.11
0.08
0.24
0.78
0.12
0.10
7,763
0.03
0.11
0.59
0.16
0.10
0.00
0.01
6,425
0.16
15.77
13.45
0.15
0.25
0.57
0.67
0.11
109.42
0.48
6,333
62.70
101.20
0.34

SD

1.10

38,108

0.01
37,956
8.81
10.04

34.07
98,001
71.56
188.54

Min
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
50
0
0
0
0
0
0
0
100
0
0
0
0
0
0
0
0
0
0
0
0
5
0

Max
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
7
1
1
1
1
1
1
1
1
1
1
1
1
1,000,000
1
1
1
1
1
0.3
1
1,000,411
1
60.44
70
1
1
1
1
1
179.14
1
2,641,086
1,000
3,110
1

29

Tab. 4: Main regressions
1
logit
Position: Below PhD/MD
Position: PhD/MD
Position: Postdoc
Position: Assistant professor
Position: Associate/Full professor
Position: Employee
Position: Individual/no affiliation
Position: Other position
Affiliation: Educational institution
Affiliation: Firm
Affiliation: Other organization
Gender: Female
Gender: N/A or unknown

4.212**
[1.359]
2.392**
[0.739]
3.644**
[1.519]
1.241
[0.456]
omitted
1.370
[0.615]
2.954*
[1.273]
2.684
[1.777]
omitted
0.956
[0.512]
1.782
[0.789]
1.505*
[0.277]
0.644
[0.312]

(Ln) target
Objective: Research
Objective: Development
Objective: Other
Pilot project
Risk score

Funded 01
2
logit
3.007**
[1.026]
1.861+
[0.609]
3.255**
[1.387]
1.046
[0.394]
omitted
0.966
[0.451]
2.210+
[0.966]
2.880
[1.925]
omitted
1.397
[0.805]
2.065
[0.937]
1.538*
[0.288]
0.712
[0.345]
0.674**
[0.067]
omitted
0.818
[0.254]
1.236
[0.417]
0.957
[0.253]
0.989
[0.009]

Press coverage 01
Endorsement 01
Prior papers 01
Video 01
Lab notes pre closing 01
Reward 01
Creator count
Region: US northeast
Region: US south
Region: US pacific
Region: US west/midwest
Region: Non-US
Region: Unknown
Field: Biology
Field: Medicine
Field: Ecology
Field: Chemistry
Field: Engineering
Field: Education
Field: Psychology
Field: Social sciences
Field: Other
Platform age
Platform age squared
Constant
Observations
df
R-squared

1.190*
omitted
0.958
1.854*
1.203
0.591+
0.591
1.624*
1.470
2.459**
1.852
0.785
1.640+
0.645
5.778**
2.213**
0.957**
1.000**
0.521
[0.421]
703
28

1.225*
omitted
0.992
2.018**
1.159
0.601+
0.594
1.649*
1.640+
2.601**
1.771
0.839
1.626
0.624
5.230**
2.041**
0.956**
1.000**
18.064*
[22.446]
703
33

(Ln) amount raised
5
OLS

3
logit

4
OLS

3.223**
[1.226]
1.516
[0.534]
1.972
[0.881]
0.799
[0.329]
omitted
0.864
[0.413]
1.850
[0.989]
3.535+
[2.439]
omitted
1.549
[0.913]
1.868
[0.893]
1.539*
[0.306]
0.692
[0.348]
0.518**
[0.060]
omitted
0.895
[0.288]
1.260
[0.456]
0.899
[0.256]
0.994
[0.010]
1.382
[0.318]
2.401**
[0.653]
1.260
[0.298]
1.500*
[0.308]
3.713**
[0.820]
2.202*
[0.770]
1.157
omitted
1.035
1.960*
1.094
0.595
0.664
1.362
1.691+
1.592+
1.137
0.679
1.207
0.523+
5.142**
1.676+
0.946**
1.000**
103.487**
[157.565]
703
39

-0.137
[0.237]
0.019
[0.228]
0.422
[0.267]
-0.182
[0.263]
omitted
-0.531+
[0.320]
-0.147
[0.303]
0.639
[0.668]
omitted
0.599
[0.383]
0.801*
[0.330]
0.395**
[0.131]
0.024
[0.415]

0.187**
omitted
0.056
0.476**
-0.205
-0.594**
-0.586
0.296+
0.407*
0.662**
0.169
0.012
0.378*
-0.351
0.524+
0.362*
-0.029**
0.000**
7.024**
[0.574]
703
28
0.163

0.570*
[0.222]
0.549**
[0.206]
0.744**
[0.260]
0.175
[0.248]
omitted
0.169
[0.305]
0.554+
[0.295]
0.666
[0.571]
omitted
-0.006
[0.372]
0.390
[0.311]
0.406**
[0.116]
-0.200
[0.353]
0.779**
[0.063]
omitted
-0.189
[0.193]
0.011
[0.224]
0.002
[0.164]
-0.009
[0.006]

0.153*
omitted
0.005
0.329*
-0.068
-0.633**
-0.505
0.402**
0.319+
0.628**
0.421
0.086
0.417*
-0.223
0.825**
0.629**
-0.023**
0.000**
0.028
[0.726]
703
33
0.325

6
OLS
0.522*
[0.211]
0.367+
[0.192]
0.355
[0.253]
-0.010
[0.231]
omitted
0.156
[0.274]
0.381
[0.300]
0.707
[0.541]
omitted
0.024
[0.332]
0.205
[0.283]
0.359**
[0.107]
-0.165
[0.317]
0.647**
[0.061]
omitted
-0.138
[0.182]
0.029
[0.219]
-0.062
[0.155]
-0.003
[0.006]
0.088
[0.127]
0.446**
[0.131]
0.121
[0.132]
0.303*
[0.122]
1.020**
[0.131]
0.472**
[0.160]
0.103+
omitted
0.057
0.232
-0.116
-0.629**
-0.404
0.231+
0.309+
0.229
0.155
-0.020
0.173
-0.291+
0.661**
0.421**
-0.021**
0.000**
0.533
[0.702]
703
39
0.430

(Ln) target
7
OLS

8
logit

-0.825**
[0.119]
-0.677**
[0.116]
-0.529**
[0.166]
-0.442**
[0.137]
omitted
-0.850**
[0.183]
-0.797**
[0.188]
0.017
[0.384]
omitted
0.771**
[0.217]
0.494*
[0.203]
-0.022
[0.073]
0.268
[0.194]

0.343**
[0.107]
0.428**
[0.125]
0.723
[0.306]
0.540+
[0.197]
omitted
0.544
[0.245]
0.420+
[0.193]
1.238
[1.005]
omitted
0.919
[0.514]
1.275
[0.597]
1.023
[0.194]
1.699
[0.879]

omitted
-0.116
[0.132]
-0.156
[0.138]
0.132
[0.101]
0.000
[0.004]
0.137+
[0.076]
0.167
[0.102]
0.036
[0.085]
0.329**
[0.073]
0.182*
[0.077]
-0.009
[0.103]
0.030
omitted
0.082
0.146
-0.145
0.059
-0.020
-0.154
0.097
-0.092
-0.344+
-0.013
-0.083
-0.156
-0.435**
-0.356**
-0.004
0.000
8.751**
[0.357]
703
38
0.253

1.137
omitted
0.882
0.786
0.917
0.843
0.462
0.832
1.138
2.309**
1.499
1.829+
1.475
1.020
0.882
0.603+
1.147**
0.999**
0.000**
[0.000]
703
28

Press coverage 01
9
logit

10
logit

0.478*
[0.159]
0.550*
[0.168]
0.865
[0.374]
0.655
[0.250]
omitted
0.732
[0.334]
0.566
[0.269]
1.363
[1.120]
omitted
0.880
[0.496]
1.062
[0.514]
1.061
[0.201]
1.449
[0.790]
1.518**
[0.158]
omitted
0.830
[0.264]
1.246
[0.413]
0.640+
[0.165]
0.986
[0.010]

0.604
[0.218]
0.485*
[0.160]
0.537
[0.248]
0.522
[0.212]
omitted
0.618
[0.283]
0.501
[0.276]
1.014
[0.817]
omitted
0.995
[0.572]
1.245
[0.604]
1.084
[0.222]
1.789
[0.969]
1.333**
[0.148]
omitted
1.049
[0.346]
1.464
[0.527]
0.586*
[0.153]
0.987
[0.011]

1.127
omitted
0.871
0.724
1.012
0.879
0.517
0.854
1.174
2.301**
1.756
1.975*
1.458
1.067
0.995
0.658
1.176**
0.999**
0.000**
[0.000]
703
33

2.149**
[0.569]
4.910**
[1.133]
1.951**
[0.421]
1.106
[0.245]
1.491
[0.430]
1.180+
omitted
0.755
0.647
0.839
0.785
0.383
0.655
1.179
1.891*
1.199
1.799+
1.269
0.871
0.761
0.478*
1.190**
0.999**
0.000**
[0.000]
703
38

Note: +=sig. at 10%, *=sig. at 5%, **=sig. at 1%. Robust standard errors. Odds ratios reported for logits.
30

Crowdfunding Scientific Research: Supporting Materials

NSF

.73

.35
.17

.36 .41

.31
.18

.16

.061

.24 .21

.19 .18

.21 .21

.044

0

.2 .4 .6 .8

1

Crowd

south

northeast

pacific westmidwest

south

northeast

pacific westmidwest

.42 .44
.22

.21

.2

.2

.15 .16

0

.2 .4 .6 .8

1

NIH

south

northeast

pacific westmidwest

Share of total funding amount
Share of total funded projects

Fig. S1: Region’s share of total funding and total number of funded projects, by funding source.
NSF and NIH data pooled for years 2012-2015, Sources: dellweb.bfa.nsf.gov and
report.nih.gov/award/index.cfm.

31

Fig. S2: Excerpt of discussion from the Open Insulin Project
(https://Experiment.com/projects/open-insulin/discussion)

32

Tab. S1: Regressions using team averages of creator characteristics
1
logit
Share below PhD/MD
Share PhD
Share postdoc
Share assistant professor
Share employee
Share individual/no affiliation
Share firm
Share affiliation other
Share female
Share gender N/A or unknown

4.084**
[1.409]
1.787+
[0.612]
2.528+
[1.203]
1.071
[0.437]
0.839
[0.391]
3.026*
[1.346]
1.275
[0.707]
2.084
[0.959]
1.749**
[0.355]
0.522
[0.268]

(Ln) target
Objective: Research
Objective: Development
Objective: Other
Pilot project
Risk score

Funded 01
2
logit
2.685**
[0.965]
1.298
[0.460]
2.054
[0.995]
0.843
[0.349]
0.582
[0.290]
2.130+
[0.952]
1.745
[1.056]
2.273+
[1.111]
1.767**
[0.366]
0.609
[0.321]
0.688**
[0.070]
omitted
0.836
[0.260]
1.250
[0.423]
0.956
[0.253]
0.989
[0.009]

Press coverage 01
Endorsement 01
Prior papers 01
Video 01
Lab notes pre closing 01
Reward 01
Creator count
Region: US northeast
Region: US south
Region: US pacific
Region: US west/midwest
Region: Non-US
Region: Unknown
Field: Biology
Field: Medicine
Field: Ecology
Field: Chemistry
Field: Engineering
Field: Education
Field: Psychology
Field: Social sciences
Field: Other
Platform age
Platform age squared
Constant
Observations
df
R-squared

1.107
omitted
1.043
1.855*
1.226
0.591+
0.597
1.596*
1.477
2.481**
1.655
0.803
1.700+
0.700
5.602**
2.024**
0.955**
1.000**
0.703
[0.584]
703
27

1.144
omitted
1.063
1.966**
1.176
0.597+
0.584
1.635*
1.652+
2.644**
1.592
0.857
1.669
0.676
5.192**
1.906*
0.954**
1.000**
22.655*
[28.824]
703
32

3
logit

4
OLS

2.953**
[1.204]
1.052
[0.415]
1.090
[0.566]
0.574
[0.263]
0.523
[0.278]
1.857
[0.993]
1.968
[1.295]
2.357
[1.256]
1.746*
[0.383]
0.561
[0.322]
0.530**
[0.062]
omitted
0.944
[0.308]
1.254
[0.452]
0.911
[0.261]
0.995
[0.010]
1.308
[0.306]
2.493**
[0.694]
1.290
[0.306]
1.546*
[0.318]
3.798**
[0.840]
2.376*
[0.826]
1.075
omitted
1.098
1.878*
1.097
0.581
0.601
1.328
1.677+
1.575+
0.982
0.661
1.180
0.567+
5.120**
1.545
0.944**
1.000**
129.700**
[199.919]
703
38

-0.247
[0.268]
-0.122
[0.269]
0.113
[0.331]
-0.263
[0.300]
-0.639
[0.397]
-0.091
[0.326]
0.565
[0.436]
0.671+
[0.407]
0.496**
[0.145]
0.146
[0.487]

0.183**
omitted
0.074
0.446**
-0.210
-0.602**
-0.629
0.304+
0.435*
0.675**
0.142
0.020
0.372+
-0.325
0.496+
0.350+
-0.031**
0.000**
7.215**
[0.610]
703
27
0.156

(Ln) amount raised
5
OLS
0.611*
[0.247]
0.518*
[0.240]
0.542
[0.335]
0.210
[0.275]
0.062
[0.336]
0.666*
[0.312]
0.029
[0.394]
0.353
[0.334]
0.510**
[0.128]
-0.149
[0.370]
0.801**
[0.064]
omitted
-0.173
[0.191]
0.012
[0.222]
-0.009
[0.166]
-0.008
[0.006]

0.128*
omitted
0.043
0.327*
-0.051
-0.629**
-0.486
0.385**
0.334+
0.629**
0.368
0.069
0.425*
-0.178
0.797**
0.586**
-0.024**
0.000**
-0.114
[0.747]
703
32
0.325

6
OLS

7
logit

0.585*
[0.238]
0.354
[0.226]
0.069
[0.309]
-0.036
[0.263]
0.104
[0.311]
0.508
[0.315]
0.054
[0.361]
0.220
[0.310]
0.443**
[0.118]
-0.109
[0.356]
0.666**
[0.062]
omitted
-0.117
[0.181]
0.021
[0.216]
-0.064
[0.157]
-0.003
[0.006]
0.087
[0.127]
0.440**
[0.133]
0.158
[0.133]
0.316**
[0.121]
1.023**
[0.131]
0.499**
[0.160]
0.083
omitted
0.089
0.221
-0.104
-0.628**
-0.416
0.220
0.316+
0.217
0.098
-0.050
0.171
-0.249
0.636**
0.387*
-0.022**
0.000**
0.376
[0.727]
703
38
0.433

0.287**
[0.096]
0.331**
[0.111]
0.563
[0.280]
0.466+
[0.191]
0.311*
[0.145]
0.417+
[0.192]
1.465
[0.855]
1.336
[0.646]
1.000
[0.213]
2.254
[1.265]

1.176*
omitted
0.862
0.761
0.932
0.840
0.470
0.852
1.150
2.382**
1.514
1.736+
1.544
0.985
0.931
0.617+
1.147**
0.999**
0.000**
[0.000]
703
27

Press coverage 01
8
logit

9
logit

0.413*
[0.148]
0.437*
[0.154]
0.696
[0.354]
0.591
[0.250]
0.415+
[0.195]
0.564
[0.270]
1.445
[0.839]
1.159
[0.575]
1.046
[0.225]
1.857
[1.084]
1.501**
[0.159]
omitted
0.816
[0.255]
1.250
[0.411]
0.639+
[0.166]
0.986
[0.010]

0.631
[0.252]
0.500+
[0.195]
0.462
[0.263]
0.516
[0.236]
0.452
[0.219]
0.603
[0.328]
1.389
[0.832]
1.354
[0.676]
1.016
[0.232]
2.190
[1.260]
1.341**
[0.149]
omitted
1.053
[0.341]
1.491
[0.533]
0.597+
[0.158]
0.986
[0.011]

1.156+
omitted
0.857
0.711
1.038
0.875
0.541
0.870
1.183
2.359**
1.733
1.878+
1.536
1.044
1.038
0.664
1.176**
0.999**
0.000**
[0.000]
703
32

2.165**
[0.572]
4.876**
[1.141]
1.925**
[0.414]
1.131
[0.252]
1.460
[0.425]
1.206*
omitted
0.752
0.638+
0.855
0.768
0.394
0.678
1.205
1.905*
1.206
1.722
1.302
0.872
0.781
0.494*
1.193**
0.999**
0.000**
[0.000]
703
37

(Ln) target
10
OLS
-1.002**
[0.137]
-0.791**
[0.137]
-0.679**
[0.185]
-0.596**
[0.154]
-0.799**
[0.216]
-0.874**
[0.197]
0.636**
[0.231]
0.363
[0.235]
-0.042
[0.080]
0.357
[0.255]

omitted
-0.090
[0.125]
-0.153
[0.138]
0.147
[0.101]
-0.001
[0.004]
0.143+
[0.075]
0.168
[0.105]
-0.013
[0.083]
0.322**
[0.073]
0.201**
[0.076]
-0.024
[0.106]
0.050
omitted
0.058
0.105
-0.169+
0.039
-0.102
-0.121
0.099
-0.086
-0.306+
0.001
-0.114
-0.169
-0.425*
-0.308**
-0.005
0.000
8.909**
[0.365]
703
37
0.255

Note: +=sig. at 10%, *=sig. at 5%, **=sig. at 1%. Robust standard errors. Odds ratios reported for logits.
33

Tab. S2: Regressions using position and affiliation separately and using simple risk score

Position: Below PhD/MD
Position: PhD/MD
Position: Postdoc
Position: Assistant professor
Position: Associate/Full professor
Position: Employee
Position: Individual/no affiliation
Position: Other position

Funded 01
1
logit

(Ln) amt raised
2
OLS

Press 01
3
logit

4.221**
[1.370]
2.396**
[0.744]
3.720**
[1.552]
1.246
[0.460]
omitted
1.746+
[0.561]
2.958*
[1.281]
3.386+
[2.218]

-0.132
[0.237]
0.030
[0.227]
0.459+
[0.266]
-0.172
[0.262]
omitted
-0.006
[0.233]
-0.140
[0.302]
0.973
[0.727]

0.342**
[0.107]
0.425**
[0.124]
0.727
[0.308]
0.540+
[0.197]
omitted
0.591+
[0.183]
0.418+
[0.192]
1.368
[1.095]

Affiliation: Educational institution
Affiliation: Firm
Affiliation: Other organization
Affiliation: No affiliation
Gender: Female
Gender: N/A or unknown

1.526*
[0.280]
0.645
[0.309]

0.427**
[0.130]
0.041
[0.423]

1.030
[0.194]
1.695
[0.875]

Funded 01
4
logit

omitted
0.654
[0.261]
1.246
[0.385]
1.380
[0.502]
1.593**
[0.283]
1.034
[0.478]

(Ln) amt raised
5
OLS

omitted
0.123
[0.294]
0.441+
[0.247]
-0.065
[0.252]
0.408**
[0.129]
0.196
[0.425]

Press 01
6
logit

omitted
0.898
[0.375]
1.418
[0.447]
0.811
[0.334]
0.924
[0.170]
1.563
[0.730]

(Ln) target
Objective: Research
Objective: Development
Objective: Other
Pilot project

Funded 01
7
logit

(Ln) amt raised
8
OLS

Press 01
9
logit

3.237**
[1.232]
1.503
[0.528]
1.986
[0.881]
0.782
[0.321]
omitted
0.855
[0.409]
1.834
[0.976]
3.665+
[2.514]
omitted
1.525
[0.899]
1.862
[0.894]

0.525*
[0.211]
0.363+
[0.192]
0.358
[0.253]
-0.019
[0.230]
omitted
0.155
[0.273]
0.378
[0.300]
0.714
[0.536]
omitted
0.015
[0.331]
0.200
[0.283]

0.601
[0.216]
0.475*
[0.156]
0.534
[0.246]
0.511
[0.209]
omitted
0.605
[0.276]
0.489
[0.271]
1.002
[0.804]
omitted
1.000
[0.572]
1.251
[0.605]

1.538*
[0.306]
0.686
[0.347]
0.519**
[0.061]
omitted
0.893
[0.287]
1.257
[0.458]
0.895
[0.255]

0.357**
[0.106]
-0.164
[0.318]
0.647**
[0.061]
omitted
-0.141
[0.183]
0.026
[0.220]
-0.062
[0.155]

1.071
[0.219]
1.805
[0.971]
1.326*
[0.147]
omitted
1.029
[0.337]
1.440
[0.519]
0.587*
[0.153]

1.004
[0.010]
1.387
[0.319]
2.385**
[0.649]
1.251
[0.295]
1.498*
[0.308]
3.795**
[0.846]
2.202*
[0.770]
1.156
omitted
1.038
1.990*
1.083
0.595
0.684
1.338
1.678+
1.555
1.126
0.659
1.214
0.515+
5.189**
1.661+
0.943**
1.000**
102.636**
[158.165]
703
39

0.000
[0.006]
0.090
[0.127]
0.447**
[0.131]
0.118
[0.132]
0.303*
[0.122]
1.027**
[0.131]
0.475**
[0.161]
0.102+
omitted
0.059
0.239+
-0.119
-0.627**
-0.391
0.222
0.307+
0.221
0.149
-0.033
0.173
-0.297+
0.661**
0.418**
-0.022**
0.000**
0.517
[0.703]
703
39
0.429

0.995
[0.010]

Risk score
Risk score simple
Press coverage 01
Endorsement 01
Prior papers 01
Video 01
Lab notes pre closing 01
Reward 01
Creator count
Region: US northeast
Region: US south
Region: US pacific
Region: US west/midwest
Region: Non-US
Region: Unknown
Field: Biology
Field: Medicine
Field: Ecology
Field: Chemistry
Field: Engineering
Field: Education
Field: Psychology
Field: Social sciences
Field: Other
Platform age
Platform age squared
Constant
Observations
df
R-squared

1.201*
omitted
0.957
1.851*
1.188
0.608+
0.590
1.615*
1.449
2.493**
1.895
0.776
1.663+
0.637
5.829**
2.223**
0.956**
1.000**
0.524
[0.422]
703
26

0.188**
omitted
0.055
0.480**
-0.235
-0.564**
-0.580
0.309+
0.450*
0.675**
0.228
0.036
0.356+
-0.356
0.523+
0.394*
-0.031**
0.000**
7.044**
[0.579]
703
26
0.155

1.139+
omitted
0.883
0.785
0.912
0.852
0.454
0.832
1.132
2.331**
1.519
1.819+
1.490
1.019
0.887
0.607+
1.145**
0.999**
0.000**
[0.000]
703
26

1.126
omitted
0.956
1.759*
1.143
0.608+
0.530
1.608*
1.207
2.548**
1.552
0.836
1.432
0.633
5.590**
2.051**
0.956**
1.000**
1.374
[1.112]
703
22

0.197**
omitted
0.031
0.433*
-0.225
-0.626**
-0.688+
0.311+
0.455*
0.688**
0.214
-0.001
0.332+
-0.331
0.542*
0.392*
-0.030**
0.000**
6.993**
[0.548]
703
22
0.149

1.203*
omitted
0.860
0.778
0.953
0.811
0.458
0.856
1.346
2.220**
1.715
1.748+
1.522
1.032
0.849
0.659
1.148**
0.999**
0.000**
[0.000]
703
22

2.175**
[0.577]
4.890**
[1.126]
1.950**
[0.420]
1.114
[0.249]
1.508
[0.435]
1.180+
omitted
0.760
0.662
0.839
0.789
0.375
0.641+
1.181
1.874*
1.187
1.746+
1.272
0.850
0.767
0.479*
1.187**
0.999**
0.000**
[0.000]
703
38

Note: +=sig. at 10%, *=sig. at 5%, **=sig. at 1%. Robust standard errors. Odds ratios reported for logits.
34

