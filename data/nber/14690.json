{
    "id": 14690,
    "citation_title": "Instruments of development: Randomization in the tropics, and the search for the elusive keys to economic development",
    "citation_author": [
        "Angus S. Deaton"
    ],
    "citation_publication_date": "2009-01-29",
    "issue_date": "2009-01-29",
    "revision_date": "2011-12-05",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Estimation Methods",
        "\n",
        "Experimental Design",
        "\n",
        "Development and Growth",
        "\n",
        "Development",
        "\n"
    ],
    "program": [
        "\n",
        "Economics of Aging",
        "\n",
        "Economic Fluctuations and Growth",
        "\n",
        "Economics of Health",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nThere is currently much debate about the effectiveness of foreign aid and about what kind of projects can engender economic development. There is skepticism about the ability of econometric analysis to resolve these issues, or of development agencies to learn from their own experience. In response, there is movement in development economics towards the use of randomized controlled trials (RCTs) to accumulate credible knowledge of what works, without over-reliance on questionable theory or statistical methods. When RCTs are not possible, this movement advocates quasi-randomization through instrumental variable (IV) techniques or natural experiments. I argue that many of these applications are unlikely to recover quantities that are useful for policy or understanding: two key issues are the misunderstanding of exogeneity, and the handling of heterogeneity. I illustrate from the literature on aid and growth. Actual randomization faces similar problems as quasi-randomization, notwithstanding rhetoric to the contrary. I argue that experiments have no special ability to produce more credible knowledge than other methods, and that actual experiments are frequently subject to practical problems that undermine any claims to statistical or epistemic superiority. I illustrate using prominent experiments in development. As with IV methods, RCT-based evaluation of projects is unlikely to lead to scientific progress in the understanding of economic development. I welcome recent trends in development experimentation away from the evaluation of projects and towards the evaluation of theoretical mechanisms.\n\n",
    "acknowledgement": "\nThe Keynes Lecture, British Academy, October 9th, 2008. I am grateful to Abhijit Banerjee, Tim Besley, Anne Case, Hank Farber, Bill Easterly, Bo Honor\u00e9, Michael Kremer, David Lee, Chris Paxson, Sam Schulhofer-Wohl, Burt Singer, Jesse Rothstein, and John Worrall for helpful discussions in the preparation of this paper. For comments on a draft, I would like to thank Tim Besley, Richard Blundell, David Card, Winston Lin, John List, Costas Meghir, David McKenzie, Burt Singer, Alessandro Tarozzi, Gerard van den Berg, Eric Verhoogen and especially Esther Duflo. I also like to acknowledge a particular intellectual debt to Nancy Cartwright, who has discussed these issues patiently with me for several years, whose own work on causality has greatly influenced me, and who pointed me towards other important work; to Jim Heckman, who has long thought deeply about the issues in this lecture, and many of whose views are recounted here; and to David Freedman, whose recent death has deprived the world of one of its greatest statisticians, and who consistently and effectively fought against the (mis)use of technique as a substitute for substance and thought. None of which removes the need for the usual disclaimer, that the views expressed here are entirely my own. I acknowledge financial support from NIA through grant P01 AG05842-14 to the National Bureau of Economic Research. The views expressed herein are those of the author(s) and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}