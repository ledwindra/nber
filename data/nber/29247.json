{
    "id": 29247,
    "citation_title": "Harms of AI",
    "citation_author": [
        "Daron Acemoglu"
    ],
    "citation_publication_date": "2021-09-13",
    "issue_date": "2021-09-09",
    "revision_date": "2024-03-23",
    "topics": [
        "\n",
        "Labor Economics",
        "\n",
        "Labor Supply and Demand",
        "\n",
        "Labor Compensation",
        "\n",
        "Industrial Organization",
        "\n",
        "Market Structure and Firm Performance",
        "\n",
        "Antitrust",
        "\n",
        "Development and Growth",
        "\n",
        "Innovation and R&D",
        "\n",
        "Other",
        "\n",
        "Economic Systems",
        "\n"
    ],
    "program": [
        "\n",
        "Economic Fluctuations and Growth",
        "\n",
        "Industrial Organization",
        "\n",
        "Labor Studies",
        "\n",
        "Productivity, Innovation, and Entrepreneurship",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nThis essay discusses several potential economic, political and social costs of the current path of AI technologies. I argue that if AI continues to be deployed along its current trajectory and remains unregulated, it may produce various social, economic and political harms. These include: damaging competition, consumer privacy and consumer choice; excessively automating work, fueling inequality, inefficiently pushing down wages, and failing to improve worker productivity; and damaging political discourse, democracy's most fundamental lifeblood. Although there is no conclusive evidence suggesting that these costs are imminent or substantial, it may be useful to understand them before they are fully realized and become harder or even impossible to reverse, precisely because of AI's promising and wide-reaching potential. I also suggest that these costs are not inherent to the nature of AI technologies, but are related to how they are being used and developed at the moment - to empower corporations and governments against workers and citizens. As a result, efforts to limit and reverse these costs may need to rely on regulation and policies to redirect AI research. Attempts to contain them just by promoting competition may be insufficient.\n\n",
    "acknowledgement": "\nPrepared for The Oxford Handbook of AI Governance. I am grateful to many co-authors who have contributed to my thinking on these topics and on whose work I have heavily relied in this essay. They include: David Autor, Jonathon Hazell, Simon Johnson, Jon Kleinberg, Anton Korniek, Azarakhsh Malekian, Ali Makhdoumi, Andrea Manera, Sendhil Mullainathan, Andrew Newman, Asu Ozdaglar, Pascual Restrepo and James Siderius. I am grateful to David Autor, Lauren Fahey, Vincent Rollet, James Siderius and Glen Weyl for comments. I gratefully acknowledge financial support from Google, the Hewlett Foundation, the NSF, the Sloan Foundation, the Smith Richardson Foundation, and the Schmidt Sciences Foundation. The views expressed herein are those of the author and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}