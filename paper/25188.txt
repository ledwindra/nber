NBER WORKING PAPER SERIES

THE RISE OF CLOUD COMPUTING:
MINDING YOUR P’S, Q’S AND K’S
David Byrne
Carol Corrado
Daniel E. Sichel
Working Paper 25188
http://www.nber.org/papers/w25188

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
October 2018

We thank Victoria Angelova, Prianka Bhatia, and Liang Zhang for extraordinary research
assistance. We extend a special acknowledgment to Liang Zhang for her excellent Wellesley
College thesis that developed semi-annual price indexes for Amazon Web Services’ basic
compute product. All views expressed in this paper are those of the authors alone and should not
be attributed to organizations with which they are affiliated, nor to the National Bureau of
Economic Research. Sichel is grateful to the Bureau of Economic Analysis and the National
Telecommunications and Information Administration for grant support of $25,600 for work
related to this paper.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by David Byrne, Carol Corrado, and Daniel E. Sichel. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that
full credit, including © notice, is given to the source.

The Rise of Cloud Computing: Minding Your P’s, Q’s and K’s
David Byrne, Carol Corrado, and Daniel E. Sichel
NBER Working Paper No. 25188
October 2018
JEL No. E01,E22,E31,L16,O3,O4
ABSTRACT
Cloud computing—computing done on an off-site network of resources accessed through the
Internet—is revolutionizing how computing services are used. However, because cloud is so new
and it largely is an intermediate input to other industries, it is difficult to track in the U.S.
statistical system. Moreover, there is a paucity of systematic information on the prices of cloud
services. To begin filling this gap, this paper does three things. First, we define the different
segments of cloud computing and document its explosive expansion. Second, we develop new
hedonic prices indexes for cloud services based on quarterly data for compute, database, and
storage services offered by Amazon Web Services (AWS) from 2009 to 2016. These indexes fall
rapidly over the sample period, with quickening (and double digit) rates of decline for all three
products starting at the beginning of 2014. Finally, we highlight the puzzle of why investment in
IT equipment in the NIPAs has been so weak while capital expenditures have exploded for IT
equipment associated with cloud infrastructure. We suggest that cloud service providers are
undertaking large amounts of own-account investment in IT equipment and that some of this
investment may not be captured in GDP.
David Byrne
Federal Reserve Board
20th & Constitution Ave., NW
Washington, DC 20551
david.m.byrne@frb.gov
Carol Corrado
The Conference Board
845 Third Avenue
New York, NY 10022-6679
Carol.Corrado@conference-board.org

Daniel E. Sichel
Department of Economics
Wellesley College
106 Central Street
Wellesley, MA 02481
and NBER
dsichel@wellesley.edu

1. Introduction
A transformation is underway that is revolutionizing the way computing services are
provided to businesses, households, and the government. This new way of accessing
computing services—typically referred to as “the cloud” or “cloud computing”—
represents the latest transition to a new computing platform—one in which computing is
done on a network of off-site computing resources accessed through the Internet.1 As
this paper shows, the changes are extraordinary and likely will have important
consequences for the structure of the economy, productivity growth, and economic
measurement. Yet, because the advent of these services is relatively recent, and because
they largely are intermediate business inputs rather than final demand, their imprint on
the economy is difficult to identify in official statistics.
Byrne and Corrado (2017a) assessed the macroeconomic impact of the shift to
cloud computing and concluded that the productivity-enhancing impacts of the shift to
cloud computing were not yet particularly evident in macroeconomic data—even after
taking major steps to improve the measurement of ICT asset prices (Byrne and Corrado,
2017b) whose prices should be indicative of cloud services prices.2 This paper builds on
their work by developing measures to quantify the service prices and quantities and the
capital investment relevant for understanding the U.S. cloud services industry —the Ps,
Qs, and K’s of the title.

1

The notion of technological change in computing as a platform shift was introduced by Bresnahan and
Greenstein (1999), who analyzed the disruptive effects of the introduction of PC/client-server platform on
the computer industry.
2
Other first order macroeconomic impacts of the shift to cloud computing include (1) a weakening in the
demand for IT equipment for a given volume of ICT services, (2) a lowering of the cost of supplying a
given volume of ICT services (e.g., power consumption costs), and (3) an increase in the productivity of
software development.

1

Our basic finding is that prices for cloud services have fallen rapidly and that the
use of the cloud has grown tremendously as has investment in the related infrastructure of
IT equipment and software. For our analysis of prices, we assembled a unique data set
with quarterly data on prices and characteristics for cloud services offered by the largest
provider, Amazon Web Services (AWS), since the first quarter of 2009 when AWS
began posting prices on the Internet. The data cover AWS’ basic compute, database, and
storage products.3
For AWS, the price for their compute product fell at an average rate of about 7
percent during 2000-2016. Price declines were slower before 2014 and more rapid
starting in the beginning of 2014. Interestingly, 2014 is the year when Microsoft and
Google began posting prices for their cloud offerings on the Internet. We suspect that
AWS’ large price declines were a response to that change in the competitive
environment. For AWS’ database product, prices fell at an average rate of more than 11
percent during 2009-16. Here too, prices fell relatively modestly until the beginning of
2014, after which they fell at an average rate of more that 22 percent through the end of
2016. AWS’ storage product followed a similar pattern, with prices falling at an average
annual rate of about 17 percent during 2009-2016 and even faster declines starting in
2014.
We also use a variety of metrics to highlight the extremely rapid growth of the
cloud and of capital expenditures by large providers of cloud services. The extremely
rapid growth of these capital expenditures raises a puzzle. Why has investment in IT
equipment in the NIPAs been so weak if large and important firms are rapidly expanding

3

We also collected data for Microsoft’s and Google’s basic compute, storage, and database services. We
intend to develop price indexes for those in future work.

2

their capital expenditures for this equipment? In part, this tension could reflect, as noted
in Byrne and Corrado (2017a), higher utilization of this equipment at cloud providers
than at individual businesses that had deployed this equipment previously. That higher
utilization would imply less demand for IT equipment for a given demand for computing
services. But, there is another possibility: cloud providers appear to be designing and
assembling IT equipment on an own-account basis. We believe that this own-account
investment should be included in the figures for business investment in IT, and we
present some back-of-the-envelope numbers suggesting that this own-account investment
is large. Our calculation suggests that, if this own-account investment were included in
business IT investment, then the growth rate of nominal investment in IT equipment
during 2007-2015 would have averaged a little more than 2 percentage points higher, and
real GDP average annual growth would have been a touch higher as well.4
The paper is organized as follows. Section 2 defines cloud computing and
provides nomenclature for describing different cloud service products. This section also
discusses the key technologies underlying cloud infrastructure. Section 3 describes our
new price indexes for cloud computing services, including the data, methodology, and
results. Section 4 uses several different metrics to demonstrate the exceptionally rapid
growth of cloud computing and the associated infrastructure. We also highlight the
puzzle described above concerning IT capital investment. Section 5 concludes.

4

The level of nominal GDP in 2015 would have been $117 billion higher if our estimate of own-account
investment in IT equipment were included.

3

2. What is cloud computing?
Because cloud computing is so new and has not been studied extensively by
economists, we begin with some basic definitions and nomenclature. In particular, we
start with the definition developed by the National Institute of Standards (NIST) and
generally affirmed in the literature (e.g., Kushida, Murray, and Zysman 2011), then
discuss the range of cloud services available, and finally turn to a brief review of key
technologies underlying the development of cloud computing.
2.1 The NIST Definition of Cloud computing
A definition of cloud computing was created by the National Institute of
Standards and Technology (NIST) in November 2009 and, after consultations with many
industry and government experts and stakeholders, published in final form in September
2011 (Mell and Grance, 2011). Their definition remains relevant and makes more
concrete and complete the brief definition given above. After noting that cloud
computing is an evolving paradigm, NIST states:
Cloud computing is a model for enabling ubiquitous, convenient, on-demand
network access to a shared pool of configurable computing resources that can be
rapidly provisioned and released with minimal management effort of service
provider interaction.
NIST describes the following types of clouds:
•

Private cloud (a cloud infrastructure provisioned for a single organization or
specific community of organizations; it may exist on or off premises)5

•

Public cloud (a cloud infrastructure provisioned for open use by the public; it
exists on the premises of the cloud provider)

•

Hybrid cloud (a combination of the above bound together by standardized or
proprietary technology that enables data and application portability).

5

The NIST “community cloud” deployment model is grouped with the “private cloud” model for ease of
exposition.

4

Finally, NIST provides a concise description of the infrastructure that underlies the cloud
as:
the collection of hardware and software that enables the five essential
characteristics of cloud computing. The cloud infrastructure can be viewed
as containing both a physical layer and an abstraction layer. The physical
layer consists of the hardware resources that are necessary to support the
cloud services being provided, and typically includes server, storage and
network components. The abstraction layer consists of the software
deployed across the physical layer, which manifests the essential cloud
characteristics. Conceptually the abstraction layer sits above the physical
layer. [Italics our own, Mell and Grance (2011, page 2.)]
2.3 Cloud products
The NIST cloud computing definition also includes a description of service models, or
service offerings. In measurement nomenclature, these services correspond to “product
types” or product classes. These product classes include:
•

Infrastructure as a service (IaaS)

•

Platform as a service (PaaS)

•

Software as a service (SaaS)

with each described more fully in the box. As discussed below and in the box, we would
add “Serverless” or Function as a Service (FaaS) to NIST’s list.

5

Definition of Cloud Service Products
IaaS (infrastructure as a service)—provides computer processing, storage, networks, and other
fundamental computing resources, where the consumer can deploy and run arbitrary software,
including operating systems as well as applications. The consumer neither manages nor
controls the underlying cloud infrastructure but has control over operating systems, storage,
and deployed applications, and possibly some control of select networking components.
PaaS (platform as a service)—provides ability to deploy consumer-created applications
created using programming languages, libraries, services, and tools. The consumer neither
manages nor controls the underlying cloud infrastructure including network, servers,
operating systems, or storage but has control over the deployed applications.
Serverless also known as FaaS or Function as a Service—provides the capability of deploying
functions (code) on a cloud infrastructure. The consumer (who would be a software
developer) no longer manages nor controls the underlying cloud infrastructure including
network, servers, operating systems, storage, or the computing program. An Application
Program Interface (API) gateway controls all aspects of execution.
SaaS (software as a service)—provides the capability of running providers’ applications on a
cloud infrastructure. The applications are accessible from various client devices through
either a thin-client interface (e.g., web browser) or a program interface. The consumer neither
manages nor controls the underlying cloud infrastructure including network, servers,
operating systems, storage, or even individual application capabilities, apart from limited
user-specific application configuration settings.

____________________
Sources: Authors’ update of NIST service models. See also Cohen (2017) and Avram (2016)

This collection of product types often is referred to as the cloud “stack,” and the earlier
point about a layer of abstraction lying across the physical layer becomes important for
understanding the relationship among these products. As one moves up the stack from
IaaS to PaaS and so on, the level of abstraction increases, in the sense that the final user
can abstract from (or ignore) more and more of the underlying infrastructure. As
highlighted by the italicized sentences in the box, for IaaS, the user still needs to think
about operating systems, storage, and other computing resources. For PaaS, the final user

6

needs to think only about the deployed application and can abstract from (or largely
ignore) other aspects of the infrastructure.
Since the NIST definition was published, the industry has introduced a new layer
of abstraction, called “serverless” or Function as a Service. At this level of abstraction,
the final user only needs to think about functions or code that are to be performed and the
cloud services provider manages all other aspects of the infrastructure. Serverless can be
regarded as sitting above PaaS in the NIST stack (as in the box), although it may also be
regarded as a refined PaaS service.
As a final point about nomenclature for cloud service products, we connect this
discussion to the state of computing pre-cloud by noting the role of traditional data
centers. By using a data center, the final user could abstract from the physical hosting
environment, a lower level of abstraction than in any of the cloud services described in
the box. The growth of cloud computing thus has its roots, at least in part, in the
competitive advantage the cloud offers customers in terms of cost, flexibility, and
scalability. At the same time, the growth and popularity of the technology also reflects
how the layers of abstraction in its products (especially the distinction between PaaS and
SaaS) serve distinct classes of customers. With abundant computing resources, value in
the stack moves up toward applications and platform, and the lower infrastructure layers
become commoditized (Kushida, Murray and Zysman, 2015).
Recent developments in the cloud that facilitate the work of software developers
could be particularly significant and could, in time, have important macroeconomic
consequences. As cloud vendors adapt technologies that enable them to develop products
“higher up the stack” and offer services with greater abstractions, the work of software

7

development is simplified. Thus, although all classes of customers benefit from the move
to greater abstraction in the technologies deployed, the benefits enjoyed by software
product developers are especially significant (Cohen 2017). As a specific example, the
movement to serverless services with Amazon’s 2014 release of the Lambda computing
platform has enabled developers to focus only on code and its rapid deployment. This
has lowered costs of new software product development among providers of software
products for final sale (via SaaS or regular licensing) as well as for applications
developed for use within a developer’s own firm (or custom-developed for use within a
given firm).6
Thus far, we have barely discussed Software as a Service (SaaS). In the usual
nomenclature SaaS products sit on the top of the stack. However, we believe that SaaS is
best understood as a category of software product services (albeit complex) rather than
cloud services per se. SaaS products are usually supplied with transactional metering—
that is, not as a collection of elastically provisioned services per the NIST definition.
Thus, SaaS products may thus be equally regarded as software products sold via an online subscription business model—a business model whose use has grown in the digital
economy.7 8 Accordingly, the prices and quantities we study as cloud computing in the
remainder of this paper exclude SaaS products.

6

Managed services featured at Amazon’s 2017 developers conference, for example, included tools for
business to leverage sophisticated deep-learning models and data without having to deal with complex
infrastructure issues (Murray 2017).
7
For further discussion of the role of business models in services provision, see OECD (2014), chapter 4,
“The Digital Economy, New Business Models and Key Features.”
8
As reported by Rackspace, a respected IaaS provider, “In recent years there has been a move by
traditional software vendors to market solutions as Cloud Computing which are generally accepted to not
fall within the definition of true Cloud Computing.” Rackspace goes on to describe SaaS as “software
delivered over the web,” which is precisely our point. Technically, some SaaS products satisfy the NIST
definition of cloud, e.g., the Salesforce Customer Relationship Management (CRM) product, but many

8

2.3 Cloud technologies
The cloud platform relies on a suite of technologies—mainly virtualization, grid
computing, and micro-services architectures—but also everything that makes high-speed
broadband possible. Arguably, IT history is at the point where the tagline Sun
Microsystems coined in the early 1990s, “The Network is the Computer,” is finally right.9
The network is no longer a mere bridge between autonomous nodes on independent
missions and prone to choke points (as in provision of transport). The continuous
increase in network capacity, along with a near disappearance of limitations that could
choke traffic in an earlier era (hardline security policies, storage performance issues, lastmile WAN hindrances), are the foundation of this latest platform shift in computing.
Behind a virtual machine host on a network of today, computing resources—
storage, memory, networking, and CPUs—are physically distributed and managed via
processing queues. Long before enterprises began moving onto the cloud, mainframes
and servers were virtualized, and an essential element of computing focused on the
function of processing queues. With cloud computing, some resource queue end-points
are moved offsite, and more than ever, computing resource acquisition and allocation
becomes the central task of cloud providers. One can be far more technical about the
transformation of computing as it has undergone virtualization and moved to a cloud
platform, but it is hard to be more prosaic than the old Sun tagline.
Cloud vendors have made increasing use of virtualization and grid computing to
elastically supply information-processing services since the advent of the millennium,

others, including other CRM products, do not. See https://support.rackspace.com/whitepaper/understanding-the-cloud-computing-stack-saas-paas-iaas/ (accessed February 25, 2017).
9
The Sun Microsystems tagline is attributed to John Gage (Reiss, 1996). The discussion in this paragraph
draws from Hubbard (2014).

9

with the growth in capacity especially rapid since 2006 when Amazon Web Services
opened its doors. The virtualization technology that is the primary enabler of cloud
computing has been in commercial use since the 1970s via IBM mainframes. Modern
IBM mainframes (circa the System/390 introduced in 1990 and renamed zSeries in 2000)
are exceptionally adept at handling large, diverse and varying workloads and remain in
use today, though they have lost much force in the large datacenter market with the rise
in cloud computing (Byrne and Corrado, 2017b). Grid computing is applying the
resources of many computers in a network to a single problem at the same time; the
technology was first used in 1989 to link supercomputers and thereafter grew and
evolved along with the Internet (De Roure et al., 2003).
“Containers” are another new cloud technology. Containers—a scalable form of
virtualization technology—allow users to run and deploy applications without launching
a new virtual machine for each application, increasing the speed of software application
development, deployment, and scalability. In terms of enterprise applications outside of
Silicon Valley, it is still early in the application of containers. Indeed, the technology
generally was not widely understood outside cloud vendors until the release of open
source LINUX formats (Docker 1.0) in March 2013. Docker transformed container
technology to a product for enterprise use. The consultancy IDC estimated that in 2014
only 1 percent of enterprise applications are running on containers that can readily be
scaled, but reportedly growth in Docker adoption has been very rapid since then.10

10

See “8 Surprising Facts about real Docker Adoption”, originally published October 2015 and last updated
June 2016 at https://www.datadoghq.com/docker-adoption/ [accessed February 25, 2017]. See also Elliot
and Perry (2018).

10

One final point of history connects this discussion to the earlier use of commercial
time-sharing services. These services were an important part of the computing
environment in its earliest days. There was a period of frantic growth (1955-1965), after
which the industry flourished for another 20 years due to a competitive advantage that
“arose from the nonlinear relationship between total operating costs and performance—
the larger the time-sharing system, the lower the per-user cost” (Campbell-Kelly and
Garcia-Swartz, 2008, page 27). Commercial time-sharing services underwent a complete
industrial boom-to-bust cycle, i.e., like typewriters and punched card machines, after the
advent of the PC.11

3. Prices of Cloud Computing Services
Outside of sporadic media reports and research by some private consultants relatively
little is known about the prices of cloud computing services. This paper develops new
price indexes for three basic products provided by one of the leading providers of cloud
services.
Data
We collected prices on a quarterly basis from Amazon Web Services (AWS), the
earliest and largest provider. We collected prices from when AWS began posting prices
on the internet, with the earliest prices from 2009. To collect historical prices, we used
the Internet Archive (also known as the Wayback Machine) to pull posted prices from
web pages as they appeared in prior periods. We collected prices for a compute product

11

According to Campbell-Kelly and Garcia-Swartz (2008), the market for time-sharing existed because it
was the only means at that time of providing a personal computing experience at a reasonable cost. They
also present econometric evidence showing that the growth of time-sharing services in its hey-day slowed
down the growth of mainframe computer shipments; see their online appendix.

11

(renting virtual machines), a selection of database products that offer SQL as well as
other database software, and a range of disk storage products.
Of course, the services for which we gathered prices are just a subset of the wide
array of services available, and they are at the lower end of the “stack” of cloud products
described above. In particular, we place the compute and storage products in the IaaS
category, and we place the database products in PaaS. That said, these compute,
database, and storage services are key foundational elements on which many of the
services that are higher in the stack are based. Accordingly, we believe that the compute,
database, and storage products considered in this paper provide a very useful and broadly
representative sample of available cloud services.
AWS has been the market leader and has posted prices on the Internet since 2009.
Microsoft began posting prices in early 2014 and Google began posting prices in late
2014. We believe that AWS is broadly representative of the market, though future work
on prices of other providers is needed to confirm that.
We note one important limitation of our data. We obtained data on prices and
product characteristics but not on quantities because cloud service providers do not make
product-level sales information readily available. We also were unable to obtain private
data on quantities.
Amazon Web Services (AWS)
AWS offers an amazing array of products. One common feature across all
products is that customers choose among regions; that is, where the servers are located on
which they are running applications and storing data. Currently, AWS offers four regions
in the U.S., including Virginia, California, Oregon, and Ohio. (Amazon also offers many

12

regions outside the United States.) For this paper we collected prices for Virginia,
California, and Oregon. (The Ohio region was only introduced in October 2016.) For an
AWS customer, choosing a region that is geographically closer reduces latency, and some
customers will store data in multiple regions for redundancy. Prices differ across regions,
with prices in California generally higher than those in Virginia or Oregon. In general,
the differences in prices across regions are in levels, while changes in prices tend to be
very similar across regions.
Compute Product (EC2 – Elastic Compute Cloud). Using this product amounts to
renting a virtual machine (PC or server) from AWS, and this product is priced in terms of
dollars per hour. In cloud computing nomenclature, the use of a virtual machine is
known as an “instance,” and AWS offers instances in a wide range of configurations.
During the span of our data from 2009 to 2016, AWS offered 55 different configurations
of virtual machines. Each configuration has specified characteristics in terms of the
power of the processor, the amount of RAM, and the amount of disk space allocated. In
addition, customers can choose between Linux and Windows operating systems. For
every available configuration, we collected prices as well as characteristics, and we have
a total of 4,079 observations for EC2 prices. The characteristics are important, and we
will use them to construct hedonic price indexes.
AWS offers several different pricing schemes for instances. For EC2, we
collected data for only “on-demand” instances, which can be purchased at any time with
no commitment. AWS also offers “reserved” instances, for which a customer pays in
advance for a set volume of instances whether or not the instances are used. Prices of
reserved instances are lower than those of on-demand instances. In addition, AWS runs a

13

spot market for instances. Customers can bid for instances at a price of the customers’
choosing. The customer will receive the instances if they are available, but will not
receive them if some other customer offered to pay a higher price for available instances.
Prices of spot instances also tend be below those of on-demand instances. Finally, AWS
offers quantity discounts to heavier users.
Tracking prices for all of these different types of instances was beyond the scope
of this paper. For the purpose of constructing price indexes, a key question is whether the
price trends for on-demand instances differ in systematic ways from those of other types
of instances. Our sense is that prices within these different pricing schemes tend to move
together, but that remains an open question. That said, we suspect that individual
customers experience price declines that are more rapid for a time than are the trends we
estimate. In particular, as customers gain experience with AWS and migrate more
applications to the cloud, we suspect that they increasingly shift toward reserved
instances and avail themselves of quantity discounts. This shift toward lower-priced
instances generates faster price declines during the shift than we estimate from tracking
prices of on-demand instances. Of course, once a customer has finished the shift toward
lower-priced instance types, the trend in prices experienced by that customer likely would
be in line with the price trends that we estimate.
Our raw data for EC2 prices are plotted in figure 1. This figure plots AWS’
posted prices for each instance type for the full time it is in the market, with a different
colored line capturing each different instance type. In the figure, we show separate plots
for each region and operating system pair with each column of graphs covering a region
and each row covering an operating system. The graphs, plotted with a log scale, indicate

14

that prices tend to follow downward step functions, with longish periods of no price
change. It also is evident that AWS revamped its offering of instance types around the
beginning of 2014, dropping most extant instance types and introducing new ones. Of
course the graphs reflect no controls for characteristics or quality of the instances, and as
shown below, it turns out that this revamping was associated with a large drop in qualityadjusted prices.
Database Product (RDS – Relational Database Service). Using this product
amounts to renting database software along with a virtual machine (called an instance
class) to run the software. It is priced in terms of dollars per hour. AWS offers several
different database engines, including MySQL, SQL, SQL Standard, SQL Express, SQL
Web, SQL Enterprise, PostgreSQL, Oracle, Aurora, and MariaDB. Some of these are
open source while others are proprietary and require a license. For those requiring a
license, AWS offers instances for which customers use their own license as well as
instances for which AWS provides the license (for a higher price). AWS also offers
several different instance classes with differences in the CPU power of the virtual
machine, the amount of RAM, network performance, and whether the instance class is
optimized for input-output to storage. For every available configuration, we collected
prices as well as characteristics for on-demand instances. (AWS also offers reserved
instances for its database product.) In total, we have 5,340 observations on RDS prices.
Our raw data for a selection of RDS prices are plotted in figure 2. This figure
plots AWS’ posted prices for each RDS instance type for the MySQL database software
for the Virginia, California, and Oregon regions. Because of the multiplicity of types of
database software, it is not feasible to plot all our data in a single figure. That said, the

15

data in this figure are broadly representative of those for other regions and database
software. The graphs are plotted with a log scale and show the same overall pattern as
the EC2 price plots. Prices tend to follow downward step functions, with longish periods
of no price change. As with EC2, AWS revamped its offerings around the beginning of
2014, dropping most extant instance types and introducing new ones.
Storage Product (S3 – Simple Storage Solution). Using this product amounts to
renting hard disk space. It is priced in terms of $ per terabyte (TB) per month.12 The
pricing scheme for S3 builds in volume discounts directly with pricing tiers. For
example, customers pay one price for the first TB used, a lower price for the next 49 TB
used, a still lower price for the next 50 TB used, and so on.13 AWS also offers three
different types of storage: “standard” allows immediate access to stored data;
“infrequent” access is for longer-term storage and data can be retrieved only with a delay;
and “glacier” storage has an even longer delay for retrieval. As with other AWS
products, customers can choose among regions. We collected prices for all pricing tiers,
all three types of storage, and the Virginia, California, and Oregon regions. In total, we
have 445 observations on S3 prices.
Our raw data for S3 prices are plotted in figure 3. This figure plots AWS’ posted
prices for each price tier for the full time it is in the market for each region and type of
storage pair. (Each different price tier is represented by a different colored line.) In the
figure, each column is for a region, and each row is for a different type of storage
(standard, infrequent, and glacier).

12

A Terabyte of data is 1,014 Gigabytes. The prefix “tera” is from the Greek work for monster.
The pricing tiers have changed over time. For example, early on prices dropped after the first TB of data,
while now pricing does not drop until after the first 50 TB of data. This change reflects the on-going
decline in the price of storage.
13

16

Results
The new quality-adjusted price indexes presented here for EC2 (compute) and
RDS (database) control for quality change are based on adjacent-quarter regressions. For
S3 (storage), quality does not change appreciably because the product is just a TB of
storage so we rely on matched-model indexes.
To explain our rationale for using adjacent-quarter regressions, we first describe a
dummy-variable hedonic specification:14
ln !!,! = ! +

! !! !!,!,!

+ !! !!,! + !!,!

(1)

where Pi,t is the price of a product in period t, Xk,i,t is the value of characteristic k for that
product in period t (measured in logs or levels, as appropriate), Di,t is a time dummy
variable (fixed effect) that equals 1 if the price i is observed in period t and zero
otherwise, and εi,t is an error term.
A potential shortcoming of equation 1, highlighted by Pakes (2003) and Erickson
and Pakes (2011), is that the coefficients on the characteristic are constrained to remain
constant over the full sample period. Byrne, Oliner, and Sichel’s (forthcoming) study on
microprocessors used adjacent-year regression; here, we follow their setup but use
adjacent-quarter regressions.
To make things precise, we describe our adjacent-quarter procedure for EC2; the
procedure for RDS is parallel. For EC2, we estimate the following regression for each
two-quarter overlapping period:
ln !!,! = ! +

! !! !!,!,!

+ !!!! + !!,!

(2)

14

The language used here to describe adjacent-quarter regressions draws heavily from Byrne, Oliner, and
Sichel (forthcoming).

17

where Pi,t is the price of EC2 instance of type i in quarter t and !!,!,! is kth characteristic
of instance i in quarter t. The dummy variable D2t equals 1 if the price observation is for
the second quarter of the two-quarter overlapping period and 0 otherwise.
To construct a price index from these sequences of regressions, we spliced
together the percent changes implied by the estimated coefficients on the D2t variables.
All of the reported results are bias-adjusted to account for the transformation from log
prices to a non-log price index.15
Because we do not have quantity data, the adjacent-quarter regressions are
unweighted so that each observation receives an equal weight in the regression. This
approach is an unfortunate limitation of not having quantity data.
EC2. For the adjacent-quarter regressions for EC2, the following characteristics
entered as natural logs: ECU (AWS’ designation of the power of the processor), Mem
(the amount of memory in GB), and Storage (the amount of disk storage in GB).16 The
regressions also include the following fixed effects: storSSD (=1 if the disk storage is
solid state), pltfrm (=1 if the processor is 64 bit, =0 if the processor is 32 bit), System (=1
if the system is Linux, =0 for Windows), inO (=1 if the price is for the Oregon region),
and inC (=1 if the price is for the California region).
Results of these regressions are summarized in Table 1. Because of the number
of adjacent-quarter regressions, the table summarizes the regression results, showing the

15

Because the exponential function is nonlinear, the translation from the natural log of prices to price levels
requires an adjustment in order to be unbiased. We apply the standard adjustment based on the estimated
variance of the coefficient δ, as described in van Dalen and Bode (2004).
16
In later periods, AWS began charging separately for disk storage for some instances. For these
observations, Storage is set equal to zero.

18

minimum, maximum and median values of coefficient estimates across the regressions.17
In addition, of the 31 adjacent-quarter regressions, the table shows the fraction of the
estimates for each coefficient that are significant at the 5 and 10 percent significance
levels.
The coefficient on the dummy variable capturing quality-adjusted price change,
D2, has a median value of zero, reflecting that prices are not changing in most quarters.
The coefficient for the variable for processor power, ECU generally is positive and highly
significant, as prices are higher for instances providing more processor power. The same
pattern holds for the memory variable, Mem. The variable for disk storage is almost
always significant though its sign often is negative. Among the fixed effects, solid-state
disk storage, StorSSD, has relatively little effect on prices, while instances running with
Linux, the System variable, are priced at a hefty discount to instances running with
Windows (for which AWS would be paying a license fee). The coefficient on the fixed
effect distinguishing between 32 and 64 bit processors (pltfrm) is quite variable across
regressions and significant in about a third of the regressions. Prices in the Oregon
region, captured by the inO variable, are little different from those in Virginia, while
prices in the California region, the inC variable typically are more than 10 percent higher
than prices in Virginia.
Table 2 reports the price indexes generated by these regressions, as well as the
number of observations and adjusted-R2 for each adjacent-quarter regression.18 The
17

As is evident in the table (as well as in our adjacent-quarter estimates for other cloud services), some
parameters exhibit considerable variation across the adjacent-quarter regressions. Running adjacent-year
regressions likely would damp this variation. We chose not to consider adjacent-year regressions for two
reasons. First, because prices of these services change infrequently and by large amounts and because new
products are introduced infrequently, we wanted to be able to isolate these periods of change. Second, our
quarterly frequency coincides with that in the National Accounts.
18
The price trends for EC2 are similar to those reported by Zhang (2016).

19

adjusted-R2s are quite high, indicating that the right-hand-side variables are capturing
most of the sources of variation in prices. The price index is shown in the first column
and percent changes at quarterly rates are reported in the second column. These figures
highlight that prices do not change in most quarters. Price declines are large in some
quarters, with the biggest drop in the first quarter of 2014, when AWS revamped its
offerings of EC2 instances. Although not evident in the plots of posted prices in figure 1,
the newly offered instances provided much higher quality at prices that were, on their
face, roughly comparable to the posted prices of the old offerings of instances.
Accordingly, the hedonic regressions identify a very large quality-adjusted price decline
in that period.
All told, quality-adjusted prices for EC2 instances fall at an average annual rate of
about 7 percent over the full sample. Interestingly, prices fell at an annual average rate of
about 5 percent from the beginning of 2009 to the end of 2013. Then, in early 2014, just
as Microsoft had entered the market to sufficient degree that they were posting their
cloud prices on the Internet (and shortly before Google started doing the same), AWS
began cutting prices more rapidly. That started with the big price drop in early 2014, and
over the period from the start of 2014 to the end of 2016, EC2 prices fell at an average
annual rate of 10.5 percent.
RDS. For the adjacent-quarter regressions for RDS, the following characteristics
entered as natural logs: Vcpu (AWS’ designation of the power of the processor) and
Memory (the amount of memory in GB). The regressions also include the variable
IOPerformance which is a qualitative variable indicating whether the network
performance is low, moderate, high, or very high. In addition, the regressions include the

20

following fixed effects: Provisioned IOPS optimized (=1 if instance is optimized for
input to and output from storage), inO (=1 if the price is for the Oregon region), inC (=1
if the price is for the California region), a set of fixed effects for each type of database
software offered (the omitted category is SQL standard).
Results of these regressions are summarized in Table 3. As for the EC2 results,
the table summarizes the regression results, showing the minimum, maximum and
median values of coefficient estimates across the regressions. In addition, of the 25
adjacent-quarter regressions, the table shows the fraction of the estimates for each
coefficient that are significant at the 5 and 10 percent significance levels.
The coefficient on the dummy variable capturing quality-adjusted price change,
D2, has a median value of zero, reflecting that prices are not changing in most quarters.
The coefficient for the variable for processor power, Vcpu generally is positive and
relatively significant, as prices are higher for instances providing more processor power.
The same pattern holds for the memory variable, Memory. The variable for
IOPerformance also is always positive and almost always significant. Among the fixed
effects, the variable Provisioned IOPS optimized (indicating optimization of storage
input/output) is always positive and significant. Just as for EC2, prices in the Oregon
region, captured by the inO variable, are little different from those in Virginia, while
prices in the California region, the inC variable typically are more than 10 percent higher
than prices in Virginia. Among the fixed effects for different database software, most are
priced at significant discounts relative to SQL standard. Oracle is the big exception; if
AWS provides the license, Oracle is priced significantly above SQL standard.

21

Table 4 reports the price indexes generated by these regressions. The adjustedR2s are quite high, indicating again that the right-hand-side variables are capturing most
of the sources of variation in prices. The price index is shown in the first column and
percent changes at quarterly rates are reported in the second column. As for EC2, these
figures highlight that prices do not change in most quarters. Price declines are large in
some quarters, with the biggest drop at the beginning of 2014, when AWS revamped its
offerings.
All told, quality-adjusted prices for RDS instances fall at an average annual rate
of more than 11 percent over the full sample. Over sub-periods, the pattern is that same
as that for EC2 prices. Prices fell at an annual average rate of about 3 percent from the
beginning of 2009 to the end of 2013. Then, in early 2014, just as Microsoft had entered
the market to sufficient degree that they were posting their cloud prices on the Internet,
AWS began cutting prices more rapidly. That started with the big price drop in early
2014, and over the period from the start of 2014 to the end of 2016, RDS prices fell at an
average annual rate of more than 22 percent.
S3. As noted, quality does not change appreciably over time for S3, the AWS
storage product. Accordingly, we construct matched-model indexes by tracking price
changes over time for each price tier. Table 5 reports the resulting price indexes for each
price tier. As for EC2 and RDS, these figures indicate that prices do not change in most
quarters. Price declines are large in some quarters, with the biggest drop at the beginning
of 2014, as AWS appeared to be responding to a competitive threat from Microsoft (and
Google later in the year).

22

The bottom three lines of the table provide summary figures that are an
unweighted average of price change across all of the price tiers. All told, prices for S3
storage fall at an average annual rate of more than 17 percent over the full sample. Over
sub-periods, the pattern is that same as that for EC2 prices. Prices fell at an annual
average rate of about 12 percent from the beginning of 2009 to the end of 2013. Then, in
early 2014, just as Microsoft had entered the market to sufficient degree that they were
posting their cloud prices on the Internet, AWS began cutting prices more rapidly. That
started with the big price drop in early 2014, and over the period from the start of 2014 to
the end of 2016, S3 prices fell at an average annual rate of about 25 percent.

4. How Big is the Cloud?
Official revenue data for the cloud services industry and its main products
according to nomenclature used in this paper are not available. Nonetheless, a natural
starting point is BEA’s data on the closest intermediate use category in the input-output
account, 514 (Data Processing, Internet Publishing, and other Information Services).
This category includes data for NAICS industry 518200 (Data processing, hosting, and
related services), which subsumes much of the relevant core cloud services activity but
includes other information services as well.19 These data suggest the intensity of business
use of purchased cloud services has been rising steadily (figure 4a). Because this
category of spending is very coarse, it does not highlight the dynamism and explosive
growth of cloud services, however. For example, the latest Census revenue data for data
19

The structure of NAPCS (North American Product Classification System), introduced in 2017, usefully
distinguishes between web site hosting, data storage services, and so forth, but does not distinguish
between services provided by traditional data centers and cloud vendors. See the industry description at
https://www.census.gov/eos/www/naics/index.html and the NAPCS structure at
https://www.census.gov/eos/www/napcs/ (accessed March 5, 2017).

23

processing, hosting, and related services (NAICSs 518200) grew 8 and 10 percent in
2015 and 2016, respectively. While these rates of change are rapid relative to the overall
economy, according to Amazon’s company reports, AWS revenues grew 70 and 55
percent, respectively, in these calendar years.20
Using a broader definition of the cloud, Cisco Systems estimates that since
emerging in the mid-2000s the cloud model has rapidly dominated the data center market.
Cloud data centers currently account for 90 percent of data center traffic and have
accounted for essentially all growth since 2010 (figure 5). Indeed, traffic at cloud data
centers rose at a 62 percent average annual rate between 2010 and 2016. This concept of
cloud data centers, however, also does not correspond directly to the purchased services
discussed in the previous paragraph for at least three reasons. First, it includes traffic
related to the massive core centers used for “free services”, e.g., Google’s centers for its
gmail service. Second, Cisco’s measure of cloud activity includes traffic at dedicated
centers designed but not owned by IT services companies (e.g., IBM Cloud Services).
Payments for these services likely are included in the NAICS 541512 (Computer and
network design services) industry. Revenues in this industry have grown especially
rapidly relative to GDP (figure 4b).
Third, the Cisco measures reflect the rise of the “edge” cloud, which has a
restraining effect on both traffic and underlying business IT costs. A host of new
technologies—including the Internet of Things (IoT), augmented and virtual reality,
autonomous cars, drones and smart cities—has led to an explosion in the volume of data
that, given current bandwidth, can not feasibly be transmitted to and from the cloud for
processing in real time. Accordingly, this development has led business and governments
20

Data referred to in this paragraph accessed September 10, 2018.

24

to locate the processing and storage of its massive data collections locally or near the
perimeter (that is, near the “edge”) of internet providers networks. Without going into
details (but see AT&T, 2017), edge computing streamlines the flow of data, transmitting
only higher-value data (for example., data from multiple IoT sources) to a shared central
cloud center for further processing and analytic use.
Concurrently, capital expenditures at hyperscale cloud service providers have
surged in recent years, rising at an annual rate of 21 percent during 2010 to 2015.
Moreover, these expenditures now have reached roughly $50 billion per year, similar in
magnitude to capital expenditures at telecom service providers (figure 6).21
Figure 7 shows the importance and rapid growth of the cloud from a different
perspective: the share of the world’s most powerful computers operated by IT service
firms leapt from under 10 percent in 2006 to more than 40 percent in 2009 and has
persisted at that level since.22
And, tying back to the discussion of virtualization, IT consultancies commented
in 2008 that server virtualization had become the “killer app” for the business datacenter.
Subsequently, IDC estimated that the number of virtual machines (VM) per server in the
United States—an indicator of the application workload of an enterprise server—
advanced nearly 12 percent per year from 2007 to 2013 (Byrne and Corrado, 2017a).

21

Cisco classifies a data center operator as hyperscale if they have revenue of $1B in Iaas/Paas, $2B in
SaaS, $4B from internet/search/social networking, or $8B from e-commerce/payment processing. Figure 6
includes the companies meeting this definition that provide cloud services.
22
The IT services category is necessarily broader than cloud services because the descriptions of individual
supercomputing sites vary in specificity. That being said, some sites are identified as Microsoft Azure and
AWS.

25

Where has all this Investment Gone?
How well does this financial data align with official measures? Mapping
company reports to official industry statistics is challenging. Companies providing cloud
services provide a host of other IT services as well. Consequently, their establishments
undoubtedly are classified to a variety of industries, most notably the industries in
NAICS subsectors 511 (Publishing Industries, except Internet (includes Software)), 513
(Broadcasting and Telecommunications), and 519 (Other Information Services).
In light of this wave of investment by cloud service providers, the continuing shift
away from IT equipment in business fixed investment in equipment and intangibles may
be seen as puzzling. Figure 8 plots NIPA nominal IT investment and the capital
expenditures figure for cloud service providers from figure 6. As shown, these two series
tracked fairly closely from the mid 1990s through about 2009 as IT investment tailed off
as a share of GDP. But, after 2009, these series diverged sharply as capital expenditures
surged while the series for NIPA IT investment remained sluggish. One possible
explanation is the higher utilization that follows as firms outsource IT functions to the
cloud. Such an increase in utilization could translate into weaker investment in the short
run. Indeed, IDC Inc. reports that the nominal value of sales of servers to U.S. firms fell
at an annual average rate of 11 percent from 2004 to 2016 and the decline accelerated
since 2008.
That being said, we also consider another possibility: that cloud services firms
have been building their own IT equipment, at least in part.23 If so, then a portion of the
capital expenditures reported above may be for components that have gone into IT
23

A parallel presentation of own-account investment by cloud service providers appears in Byrne, Corrado,
and Sichel (2017).

26

equipment built on an own-account basis rather than for already assembled IT equipment.
Google, for example, is reported to have built both computing and network equipment
from purchased components.24 Consistent with this possibility, the “use tables”
published by the U.S. Bureau of Economic Analysis indicate that the output of the
Computer and Electronics Manufacturing sector (NAICS 334) used by IT services sectors
is substantial—$58.6 billion in 2015.25 At the same time, the “make tables” indicate that
these electronic intermediates are not made into final electronics sold by the IT services
sector. This suggests that these components are used for own-account production of IT
equipment used within the firms.
If this story is correct, this own-account investment should be (but we believe
likely is not) counted in the NIPAs as business investment in IT equipment, albeit ownaccount investment. How much might this own-account investment add up to? For the
sake of argument, we assume that the omitted investment value of the own-account
production of final electronics is equal to the value of the electronic intermediates used.26
With this valuation, the story for business investment in IT equipment changes markedly.
As seen in figure 9, nominal IT equipment and software investment including our
estimate of own-account would be $58 billion higher in 2015 than in the official
estimates, amounting to 0.32 percent of GDP. For nominal investment in IT equipment,
adding this own-account investment would boost the average annual growth rate during
2007-2015 by roughly 2 percentage points compared with official estimates. For nominal
24

See “Like Google and Facebook, Twitter designs its own servers,” Wired Magazine, July 9, 2015.
(https://www.wired.com/2015/07/like-google-facebook-twitter-designs-computer-servers/)
25
We treat BEA categories 511, 512, 514 and 5415 as IT services. This group includes industry 518210
mentioned above (in category 514) as well as software publishing, telecom services, and computer design
services.
26
We believe this assumption is conservative; although the details of data center server inputs are not
available, Gartner, Inc. reports that the market value of personal computers is roughly four times the value
of electronic inputs.

27

GDP growth, including this own-account investment would add three basis points per
year to the growth rate during this period.

5. Conclusion
We find that cloud computing has exploded. By available measures, the quantity
of cloud activity has grown extremely rapidly as has associated capital investment. At
the same time, prices of basic cloud services have fallen rapidly since 2009, based on a
unique dataset we assembled. However, because cloud is so new and so much of it is
intermediate input, it is challenging to track in the statistical system, and the available
data do not distinguish between cloud-based and traditional services, whether services are
purchased or produced internally, or generated at the “edge.” We highlight one area
where real GDP may be understated by a noticeable amount as a result of changes in the
economy related to the rise of cloud computing.

28

References
AT&T Edge Cloud (2017). AT&T Labs and AT&T Foundry, white paper. Available at
https://about.att.com/content/dam/innovationdocs/Edge_Compute_White_Paper%20FIN
AL2.pdf
Avram, Abel (2016), “FaaS, PaaS, and the Benefits of the Serverless Architecture,”
InfoQ, posted on June 25, 2016 and available at:
https://www.infoq.com/news/2016/06/faas-serverless-architecture
Bresnahan, Timothy F. and Shane Greenstein (1999). “Technological Competition and the
Structure of the Computer Industry.” Journal of Industrial Economics 47 (1), pp. 1-40.
Byrne, David M. and Carol A. Corrado (2017a). “ICT Prices and ICT Services: What do
they tell us about Productivity and Technology?” International Productivity Monitor 33
(Fall 2017), 150-181.
Byrne, David M. and Carol A. Corrado (2017b). “Accounting for Innovation in
Consumer Digital Services: Implications for Economic Growth and Consumer Welfare,”
presentation at the 5th IMF Statistical Forum, “Measuring the Digital Economy”, IMF
Headquarters, Washington, D.C., November 16, 2015. Paper available here:
http://www.imf.org/~/media/Files/Conferences/2017-stats-forum/carrado.ashx?la=en
Byrne, David M., Carol A. Corrado and Daniel E. Sichel (2017). “Own-Account IT
Equipment Investment”. FEDS Notes (October 4, 2017), Federal Reserve Board,
Washington, D.C. Available here.
Byrne, David M., Stephen D. Oliner, and Daniel E. Sichel, “How Fast Are Semiconductor
Prices Falling?” Review of income and Wealth, forthcoming, also available as NBER
working paper #21074, April 2015.
Campbell-Kelly, Martin and Daniel D. Garcia-Swartz (2008). “Economic Perspectives on
the History of the Computer Time-Sharing Industry, 1965-1985.” IEEE Annals of the
History of Computing, pp. 16-36.
Cohen, Robert B. (2017) “Understanding the Next Production Revolution and its
Relationship to Software Innovations.” Mimeo, Economic Strategy Institute (January 22).

29

De Roure, David, Mark A. Baker, Nicholas R. Jennings, and Nigel R. Shadbolt (2003).
“The Evolution of the Grid.” In F. Berman, G. C. Fox, and T. Hey (Eds.), Grid
Computing: Making the Global Infrastructure a Reality, Wiley Series in
Communications Networking and Distributed Systems, Chapter 3, pp. 65–100.
Chichester, England: John Wiley & Sons, Ltd.
Elliot, Stephen and Randy Perry (2018). “Adopting Multicloud – A Fact-based
Blueprint for Reducing Enterprise Business Risks”. International Data Corporation
White Paper
(June).
Erickson, Tim and Ariel Pakes (2011). “An Experimental Component Index for the CPI:
From Annual Computer Data to Monthly Data on Other Goods,” American Economic
Review 101 (August), 1707-1738.
Gort, M and S. Klepper (1982), ‘‘Time Paths in the Diffusion of Product Innovations,’’
Economic Journal, 92, pp. 630-653.
Hubbard, Patrick (2014). “The Network in the Computer, Again” Network Computing
(May 6), available at
http://www.networkcomputing.com/cloud-infrastructure/network-computeragain/1827958867
Kushida, Kenji E., Jonathan Murray, and John Zysman (2011). “Diffusing the Cloud:
Cloud Computing and Implications for Public Policy.” Journal of Industry, Competition
and Trade, 11(3), 209-237.
Kushida, Kenji E., Jonathan Murray, and John Zysman (2015). “Cloud Computing:
From Scarcity to Abundance.” Journal of Industry, Competition and Trade, 15(1),
5-19.
Mell, Peter and Timothy Grance (2011). The NIST Definition of Cloud Computing.
NIST Special Publication 800-145. Doi:
http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf
Murray, Jonathan (2017). “The Third Wave”. Medium (December 19), available at
https://medium.com/@adamalthus/the-third-wave-b4ec5380079a
OECD (2014). Addressing the Tax Challenges of the Digital Economy. OECD/G20
Base Erosion and Profit Shifting Project. Paris: OECD Publishing.
Pakes, Ariel (2003). “A Reconsideration of Hedonic Price Indexes with an Application
to PC’s,” American Economic Review, 93(5), 1578–96.
Reiss, Spencer (1996) “Power to the People”, Wired Magazine (December 1), available
at https://www.wired.com/1996/12/esgage/

30

van Dalen, Jan and Ben Bode, “Estimation Bias in Quality-Adjusted Hedonic Price
Indexes,” mimeo, Rotterdam School of Management, 2004.
http://www.ipeer.ca/papers/vanDalenBodeOct.1,2004,SSHRC%20Paper17.pdf
Zhang, Liang, “Price Trends for Computing Services,” Senior Thesis, Wellesley College,
May 2016.

31

Table 1
Amazon EC2 Adjacent-Quarter Regressions, 2009:Q2-2016:Q4
(summary of coefficient estimates across all adjacent-quarter regressions)
Minimum

Maximum

Median

Fraction
significant at
5%

D2

-.329

.031

.0

2/31

2/31

ECU

-.114

.604

.212

28/31

29/31

Mem

-.739

.85

.630

31/31

31/31

Storage

-.66

.199

-.067

30/31

31/31

StorSSD

-.049

.017

.0

0/31

10/31

System

-.444

0

-.341

29/31

29/31

pltfrm

-.477

2.103

.0

10/31

10/31

inO

-.025

.038

.0

0/31

0/31

inC

.0

.146

.127

23/31

24/31

-5.939

-.926

-4.616

31/31

31/31

Constant

Fraction
significant at
10%

Note: D2 is the dummy variable for the second quarter of the adjacent-quarter regression. ECU, Mem, and
Storage are in natural logs. ECU measures processor power, Mem is the amount of RAM, and Storage is
the amount of disk storage. Other variables enter as fixed effects. StorSSD =1 if solid state storage, System
=1 if operating system is Linux, pltfrm =1 if the processor is 64 bit, inO = 1 if the region is Oregon, and inC
= 1 if the region is California. The omitted categories are the Windows operating system in the Virginia
region with magnetic hard drive disk storage and a 32-bit processor.

Table 2
Amazon EC2 (Compute Product) Price Index
Price Index
2009: 1
2009: 2
2009: 3
2009: 4
2010: 1
2010: 2
2010: 3
2010: 4
2011: 1
2011: 2
2011: 3
2011: 4
2012: 1
2012: 2
2012: 3
2012: 4
2013: 1
2013: 2
2013: 3
2013: 4
2014: 1
2014: 2
2014: 3
2014: 4
2015: 1
2015: 2
2015: 3
2015: 4
2016: 1
2016: 2
2016: 3
2016: 4

100.00
100.00
100.00
95.29
95.29
95.29
91.27
91.77
91.77
91.77
91.77
84.92
87.71
88.68
88.68
88.68
82.37
77.98
77.98
77.95
56.15
56.15
56.15
56.15
56.15
56.15
56.15
56.15
48.84
48.84
48.72
48.72

Percent Change
(qtrly rate)

Number of
observations

Adjusted R2

.0
.0
-4.7
.0
.0
-4.2
.5
.0
.0
.0
-7.5
3.3
1.1
.0
.0
-7.1
-5.3
.0
.0
-28.0
.0
.0
.0
.0
.0
.0
.0
-13.0
.0
-.2
.0

20
20
38
56
60
69
75
76
76
76
98
126
132
132
132
156
182
184
242
370
440
440
440
440
440
440
440
518
596
596
298

0.996
0.996
0.91
0.927
0.926
0.955
0.968
0.969
0.969
0.969
0.967
0.961
0.96
0.963
0.963
0.953
0.949
0.974
0.974
0.944
0.956
0.956
0.956
0.956
0.956
0.956
0.956
0.938
0.936
0.936
0.936

Memo: Avg at
annual rate
2009:1-2016:4
-6.9
(annual rate)
2009:1-2013:4
-5.1
(
2014:1-2016:4
-10.5
(
Note: Based on adjacent-quarter hedonic regression as described in the text. All estimates are bias adjusted
to account for the translation from log price to a price index. The last two columns show the number of
observations and adjusted R2s from each of the adjacent-quarter regressions.

33

Table 3
Amazon RDS Adjacent-Quarter Regressions, 2010:Q3-2016:Q4
(summary of coefficient estimates across all adjacent-quarter regressions)
Minimu
m

Maximum

Median

Fraction
significant at
5%

Fraction
significant
at 10%

D2

-0.53

0.01

0.00

5/25

5/25

Vcpu

-0.15

0.22

.03

16/25

16/25

Memory

0.57

.74

.69

25/25

25/25

IOPerformance
Provisioned
IOPS optimized

0.04

0.35

0.25

24/25

24/25

0.07

0.22

0.13

25/25

25/25

inC

0.09

0.12

0.11

25/25

25/25

inO

-0.01

0.01

0.00

0/25

0/25

Aurora

-1.31

0.00

0.00

5/25

5/25

MySQL
Oracle (own
license)
Oracle (AWS
provided license)

-1.44

0.00

-1.00

18/25

18/25

-1.43

0.00

-1.00

17/25

17/25

0.00

0.76

0.37

21/25

21/25

PostgreSQL
SQL (own
license)

-1.38

0.00

0.00

12/25

12/25

-1.02

0.00

-0.67

18/25

18/25

SQL express

-1.37

0.00

-0.96

18/25

18/25

SQL web

-0.66

0.00

-0.60

18/25

18/25

MariaDB

-1.44

0.00

0.00

4/25

4/25

Constant

-3.10

-1.99

-2.87

25/25

25/25

Note: No observations for 2015:Q4 were available in the web archive.

34

Table 4
Amazon RDS (Database Product) Price Index, 2010:Q2-2016:Q4
Price Index
2010: 2
2010: 3
2010: 4
2011: 1
2011: 2
2011: 3
2011: 4
2012: 1
2012: 2
2012: 3
2012: 4
2013: 1
2013: 2
2013: 3
2013: 4
2014: 1
2014: 2
2014: 3
2014: 4
2015: 1
2015: 2
2015: 3
2015: 4
2016: 1
2016: 2
2016: 3
2016: 4
Memo: Avg ch,
annual rate
2010:2-2016:4
2010:2-2013:4
(
2014:1-2016:4

100.00
100.00
93.73
93.73
93.73
93.73
93.73
93.73
93.73
93.73
93.73
87.25
87.19
87.19
87.19
82.29
48.30
48.30
48.30
48.30
48.30
48.55
48.55
38.38
38.20
38.20
38.20

Percent Change
(qtrly rate)

Number of
observations

Adjusted R2

0.0%
-6.3%
0.0%
0.0%
0.0%
0.0%
0.0%
0.0%
0.0%
0.0%
-6.9%
-0.1%
0.0%
0.0%
-5.6%
-41.3%
0.0%
0.0%
0.0%
0.0%
0.5%
0.0%
-20.9%
-0.5%
0.0%
0.0%

22
24
24
44
64
64
64
133
202
202
242
282
282
308
420
601
696
696
696
696
712

0.999
0.997
1
0.999
0.999
0.999
0.999
0.971
0.967
0.967
0.971
0.976
0.976
0.978
0.977
0.975
0.981
0.981
0.981
0.981
0.981

1183
1218
702
606

0.983
0.985
0.984
0.983

-11.6
-3.3
-22.6

Note: Based on adjacent-quarter hedonic regression as described in the text. All estimates are bias
adjusted to account for the translation from log price to a price index. The last two columns show the
number of observations and adjusted R2s from the adjacent-quarter regressions. No observations are
available for 2015:Q4; we assumed no price change in that quarter.

35

Table 5
Amazon S3 (Storage Product) Price Indexes, Standard Storage, Virginia
(percent change, quarterly rate)
2009: 2
2009: 3
2009: 4
2010: 1
2010: 2
2010: 3
2010: 4
2011: 1
2011: 2
2011: 3
2011: 4
2012: 1
2012: 2
2012: 3
2012: 4
2013: 1
2013: 2
2013: 3
2013: 4
2014: 1
2014: 2
2014: 3
2014: 4
2015: 1
2015: 2
2015: 3
2015: 4
2016: 1
2016: 2
2016: 3
2016: 4
Memo: Avg ch, AR
2009:1-2016:4
(annual rate)
2009:1-2013:4
2014:1-2016:4
(
2009:1-2016:4
2009:1-2013:4
2014:1-2016:4

s≤ 1
.0
.0
.0
.0
.0
.0
-6.7
.0
.0
.0
.0
-10.7
.0
.0
.0
-24.0
.0
.0
-10.5
-64.7
.0
.0
.0
.0
.0
.0
.0
-23.3
.0
.0
.0

1<s≤50
.0
.0
.0
.0
.0
.0
.0
.0
-16.7
.0
.0
-12.0
.0
.0
.0
-27.3
.0
.0
-6.2
-6 .7
.0
.0
.0
.0
.0
.0
.0
-22.0
.0
.0
.0

50<s≤100
.0
.0
.0
.0
.0
.0
-21.4
.0
.0
.0
.0
-13.6
.0
.0
.0
-26.3
.0
.0
-14.3
-51.7
.0
.0
.0
.0
.0
.0
.0
-24.1
.0
.0
.0

-18.1
-10.9
-29.3

-18.7
-13.1
-27.6

-19.5
-15.9
-25.3

Average across all price tiers
Average across all price tiers
Average across all price tiers

Terabyte (TB) Range
100<s≤500
500<s≤1K
.0
.0
.0
.0
.0
.0
.0
.0
.0
-15.4
-9.5
.0
.0
.0
.0
.0
.0
.0
.0
-13.6
-5.3
.0
.0
.0
.0
.0
.0
-26.3
-27.8
.0
.0
.0
.0
-14.3
-15.4
-51.7
-48.2
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
-24.1
-26.3
.0
.0
.0
.0
.0
.0
-18.8
-14.7
-25.3

-18.9
-14.5
-24.8

1K<x≤5K

≥5K

.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
-25.0
.0
.0
-15.0
-45.1
.0
.0
.0
.0
.0
.0
.0
-25.0
.0
.0
.0

.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
.0
-21.8
-36.0
.0
.0
.0
.0
.0
.0
.0
-23.6
.0
.0
.0

-15.7
-10.0
-23.4

-11.6
-5.5
-19.9

-17.3
-12.1
-25.1

Note: Based on matched-model indexes for each price tier. AWS offered different sets of price tiers in different
periods so not all tiers have entries for every period.

36

0

0

Figure 1
Amazon EC2 Posted Prices by Instance, for Each Region and for Linux and Windows
EC2 On-demand price, VA, Linux, by Instance type

EC2 On-demand price, CA, Linux, by Instance type

EC2 On-demand price, OR, Linux, by Instance type

6

6

6

2

2

2

.8
.6

.8
.6

.8
.6

.4
.2

Price, $/hr

18
14
10

Price, $/hr

18
14
10

Price, $/hr

18
14
10

.4
.2

0

2009.1

.4
.2

0

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

EC2 On-demand price, VA, Windows, by Instance type

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

EC2 On-demand price, CA, Windows, by Instance type

6

6

2

0
2

2

.8
.6

.8
.6

.8
.6

.2

2009.1

Price, $/hr

6

Price, $/hr

18
14
10

Price, $/hr

18
14
10

.4

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

2012.1

2013.1

2014.1

2015.1

2016.1

.4
.2

.2

2010.1

2011.1

EC2 On-demand price, OR, Windows, by Instance type

18
14
10

.4

2010.1

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

Figure 2
Amazon RDS Posted Prices by Instance, for MySQL in the Virginia, California, and Oregon Regions

RDS My SQL, On-demand price, Virginia, by Instance type
12

Price, $/hr

4
1.5
1
.5

2009.1

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2015.1

2016.1

2015.1

2016.1

RDS My SQL, On-demand price, California, by Instance type
12

Price, $/hr

4
1.5
1
.5

2009.1

2010.1

2011.1

2012.1

2013.1

2014.1

RDS My SQL, On-demand price, Oregon, by Instance type
12

Price, $/hr

4
1.5
1
.5
0

2009.1

2010.1

2011.1

2012.1

2013.1

2014.1

38
0

0

Figure 3
Amazon S3 Posted Prices by Price Tier, for Each Region and Storage Type
S3 standard storage price, VA, by price tier

S3 standard storage price, CA, by Instance type

18
14
10
6

18
14
10
6

.8
.6
.4

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

S3 infrequent storage price, VA, by Instance type

2

2
Price, $/hr

18
14
10
6

.2

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

S3 infrequent storage price, CA, by Instance type

18
14
10
6

.8
.6
.4

2010.1

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2009.1

S3 glacier storage price, CA, by Instance type

6

6

6

2

2
0
.8
.6
.4

.8
.6
.4

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2016.1

.2

2009.1

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

2
Price, $/hr

Price, $/hr

2010.1

2015.1

S3 glacier storage price, OR, by Instance type
18
14
10

2009.1

2014.1

.2

18
14
10

.2
0

2013.1

.8
.6
.4

18
14
10

.8
.6
.4

2012.1

2

.8
.6
.4

S3 glacier storage price, VA, by Instance type

2011.1

S3 infrequent storage price, OR, by Instance type

.2

2009.1

2010.1

18
14
10
6

Price, $/hr

2010.1

.8
.6
.4
.2

.2

2009.1

Price, $/hr

Price, $/hr

.8
.6
.4
.2

Price, $/hr

2

2
Price, $/hr

Price, $/hr

2

S3 standard storage price, OR, Linux, by Instance type
18
14
10
6

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

.2
0

2009.1

2010.1

2011.1

2012.1

2013.1

2014.1

2015.1

2016.1

39

Figure 4a. Intermediate uses of information services, 1987 to 2015
Percent of
GDP
1.0
.8
.6
.4
.2
.0
1987

1992

1997

Government

2002

2007

2012

Private

Note: Data processing, hosting, and other information services products, wherever
produced (BEA IO product code 514, covering 2002 NAICS 5182, 51913)

Figure 4b. Intermediate uses of computer and network design services, 1987 to
2015

Percent of
GDP
1.0
.8
.6
.4
.2
.0
1987

1992

1997

Government

2002

2007

2012

Private

41

42

Figure 6. U.S. Company Capital Expenditure:
Selected IT Service Providers

120

100

80

Cloud Service Providers

60

40

20

Telecommunications Service Providers

0
1997

1999

2001

2003

2005

2007

2009

2011

2013

2015

Source. Authors' tabulation of company financial filings.
Note. Included cloud service providers meet Cisco definition of hyperscale. Included telecommunications service providers
are AT&T, Verizon, Sprint, T-Mobile US, Century Link and related companies. See endnote v for detail.

43

Figure 7. Industrial Supercomputer Capacity by Sector
100%

80%

60%

Manufacturing, other

Share

Finance
Energy

40%

Media, Gaming
Comm. Services
IT services

20%

0%

Jun-05 Jun-06 Jun-07 Jun-08 Jun-09 Jun-10 Jun-11 Jun-12 Jun-13 Jun-14 Jun-15 Jun-16
Source. top500.com, authors' calculations.

44

0.90
0.80

2.30
IT Service Provider Cap. Ex. (left)
IT Equipment Investment (right)

0.70

2.10
1.90
1.70

0.60

Share of GDP (percent)

Company Capital Expenditure
Scaled by GDP (percent)

Figure 8. Capital Expenditure, Selected U.S. IT Service Providers
and NIPA Nominal IT Equipment Investment

1.50
0.50

1.30

0.40

1.10

0.30

0.90
1997 1999 2001 2003 2005 2007 2009 2011 2013 2015

Source. Bureau of Economic Analysis. Authors' tabulation of company financial reports.
Note. IT equipment investment includes communications equipment, computers and peripherals.
Included cloud service providers meet Cisco definition of hyperscale. Included telecommunications
service providers include AT&T, Verizon, Sprint, T-Mobile US, Century Link and related companies.
See endnote v for detail.

45

Figure 9. IT Equipment & Software Investment
700
600

$ Billion

500
400
300
200
100
0
1997

2002

2007
Official

2012

w/ Own-account

Source. U.S. Bureau of Economic Analysis, authors' calculations.

46

