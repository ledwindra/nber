NBER WORKING PAPER SERIES

MAKING SUMMER MATTER:
THE IMPACT OF YOUTH EMPLOYMENT ON ACADEMIC PERFORMANCE
Amy Ellen Schwartz
Jacob Leos-Urbel
Joel McMurry
Matthew Wiswall
Working Paper 21470
http://www.nber.org/papers/w21470

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2015, Revised May 2020

This research is generously supported by the Smith Richardson Foundation Grant #2013-9178. The
authors would like to thank the NYC Department of Youth and Community Development, the NYC
Department of Education and Siddhartha Aneja, Meryle Weinstein and Michele Leardo for their assistance
and Megan Silander for contributions to an earlier draft of this paper. The authors would also like
to thank participants at the Association for Education Finance and Policy Annual Conference, and
the Association for Public Policy and Management Fall Research Conference, and seminar participants
at the Evans School, the University of Oregon, American University and Kingâ€™s College London. The
views expressed herein are those of the authors and do not necessarily reflect the views of the National
Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
Â© 2015 by Amy Ellen Schwartz, Jacob Leos-Urbel, Joel McMurry, and Matthew Wiswall. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including Â© notice, is given to the source.

Making Summer Matter: The Impact of Youth Employment on Academic Performance
Amy Ellen Schwartz, Jacob Leos-Urbel, Joel McMurry, and Matthew Wiswall
NBER Working Paper No. 21470
August 2015, Revised May 2020
JEL No. I2,J24,J38
ABSTRACT
This paper examines New York Cityâ€™s Summer Youth Employment Program (SYEP). SYEP provides
jobs to youth ages 14-24, and due to high demand for summer jobs, allocates slots through a random
lottery system. We match student-level data from the SYEP program with educational records from
the NYC Department of Education and use the random lottery to estimate the effects of SYEP participation
on a number of academic outcomes, including test taking and performance. We find that SYEP participation
has positive impacts on student academic outcomes, and these effects are particularly large for students
who participate in SYEP multiple times.

Amy Ellen Schwartz
Maxwell School of Citizenship
and Public Affairs
Center for Policy Research
Syracuse University
426 Eggers Hall
Syracuse, NY 13244
amyschwartz@syr.edu
Jacob Leos-Urbel
Tipping Point Community
220 Montgomery St, Ste 850
San Francisco, CA 94104
jacob.leos.urbel@gmail.com

Joel McMurry
Department of Economics
University of Wisconsin-Madison
1180 Observatory Drive
Madison, WI 53706
mcmurry2@wisc.edu
Matthew Wiswall
Department of Economics
University of Wisconsin-Madison
1180 Observatory Drive
Madison, WI 53706
and NBER
matt.wiswall@gmail.com

1) Introduction
Unemployment rates for youth jumped to historical highs after the recession of
2008 and have been slow to recover. An important component of this jobs crisis is the
lack of available summer jobs for high school studentsâ€”especially low-income youth. 1
This dearth of employment opportunities for youth may hamper their development, with
lasting negative consequences. Prior research suggests that adolescent employment
improves net worth and financial well-being as an adult (Painter, 2010; Ruhm, 1995). An
emerging body of research indicates that summer employment programs also lead to
decreases in violence and crime (Sum et al, 2013; Heller, 2013, 2014; Gelber et al 2014). 2
Work experience may also benefit youth, and high school students specifically, by
fostering various non-cognitive skills, such as positive work habits, time management,
perseverance, and self-confidence (Lillydahl, 1990; Mortimer, 2003; Duckworth et al,
2007). 3
Building on previous work (Leos-Urbel, 2014), this paper studies the impact of
summer youth employment on studentsâ€™ academic achievement. We utilize a large data
set including nearly 200,000 applicants to New York Cityâ€™s Summer Youth Employment
Program (SYEP) from 2005-2008. We match the SYEP program data for each student to

1

Summer jobs for low-income youth represented a major component of The American Recovery
and Reinvestment Act (ARRA), which provided $1.2 billion for youth employment opportunities
and funded 345,000 jobs during the summer of 2009 (Bellotti et al. 2010). However, these funds
are no longer available, and many other publicly funded jobs have also experienced reductions in
the number of youth they are able to employ.
2
This is consistent with evidence that unstructured time with peers is associated with greater
delinquent behavior (Anderson & Hughes, 2009).
3
Heckman (2000); Cunha, Heckman, and Schennach (2010) argue that non-cognitive skills and
motivation are critical for future skill development, and that these skills can be improved at later
ages.

3

academic records from the New York City Department of Education (NYCDOE).
Importantly, since the number of applicants substantially exceeds the number that can be
served, positions are allocated through a random lottery, offering an unusual opportunity
to derive robust estimates of the impact of the program. We use data on New York
Stateâ€™s â€œRegentsâ€ exams designed to assess performance in a variety of high school
subjects including Mathematics, Sciences, English, and History. Further, we examine the
way in which the impact of SYEP varies with repeated program participation over
multiple summers and explore heterogeneity across key student subgroups.
Our estimates indicate that SYEP improves academic outcomes for the New
York City (NYC) public school students who participate: SYEP increases the number of
exams students attempt, the number of exams students pass, and the average score
students achieve. The Two Stage Least Squares (2SLS) estimates using the lottery as an
instrument for attendance indicate that participating in SYEP increases the number of
Regents exams passed (with a score of at least 65) by a statistically significant (at the 1
percent level) 0.023 exams. To give some context to this effect size, we find that this
estimated effect of SYEP is equivalent to the estimated effect on test passing rates of a
0.14 standard deviation increase in the 8th grade reading score and 20 percent of the
difference in the pass rates for free lunch and non-free lunch eligible students (where free
lunch eligible is a common measure of poverty).
Further, we find that the improvements in test taking and passing increase with
the number of years a student participates in SYEP â€“ impacts are larger for second time
participants and largest for those participating for the third time. While we cannot claim
that these participation effects reflect entirely a causal dosage effect, because the decision

4

to apply is an endogenous one, these effects are suggestive that allowing the program to
enroll students voluntarily for multiple summers can have even larger effects on their
academic performance than a single exposure to the program. Our findings suggest
substantial heterogeneity in program effects, and thus an important avenue for policy
makers to target the program to those who might benefit from it the most.
Relevant Prior Research
Much of the previous research examining the impact of high school student
employment on academic outcomes has been limited to work during the school year,
focusing on the potential tradeoffs between the developmental and financial benefits of
working and the possible crowding out of time devoted to academics (Rothstein, 2007;
Sabia, 2009; Kalenkoski & Pabilonia, 2009). This research largely suggests that working
a moderate number of hours (i.e., fewer than 20 hours per week) during the school year
has either a small positive effect or no effect on outcomes such as school attendance, time
spent on homework, and GPA, and that working more than a moderate number of hours
(i.e., more than 20 hours per week) has negative effects on these outcomes (Lillydahl,
1990; Monahan, Lee, & Steinberg, 2011; Rothstein, 2007; Stern & Briggs, 2001). Most
previous research, however, has explicitly excluded work experiences during the summer
when there is considerably less risk of detracting attention from school responsibilities
(Painter, 2010; McNeal, 1997).
Walker and Vilella-Velezâ€™s (1992) evaluation of the Summer Training and
Education Program (STEP) is one study that directly examines summer employment.
They find that STEP improved reading and mathematics test scores for academically-

5

behind 14- and 15-year-olds from poor urban families who participated in the program.
STEP consisted of half-day summer jobs combined with half-days of academic
coursework (specially designed remedial reading and mathematics curricula). In addition
to higher test scores, participating students had better grade point averages, showed more
knowledge about responsible sexual and social behavior, and had higher attendance rates
than students from a control group. SYEP is similar to STEP, with employment
combined with some classroom instruction, although SYEPâ€™s classroom instruction is
considerably less (about 10 percent of program hours, as described more fully below).
In the first research to study SYEP using the randomized admission lottery, LeosUrbel (2014) estimates the impact of SYEP on student attendance for the 2007 cohort of
students. He finds a significant increase in school attendance in the school year following
SYEP participation, with larger effects among students likely to be at greater risk of low
attendanceâ€”students 16 years and older with low attendance rates in the previous year.
We expand on these findings by considering a broader range of academic outcomes
including test taking and performance on a wide range of exam subjects. Further, and key
to this analysis, we use data on four SYEP cohorts, constituting nearly 200,000 SYEP
applicants, allowing us to study effects of repeated program exposure on individuals who
participate multiple years. In more recent work on NYCâ€™s SYEP program using tax
records and analyzing different outcomes, Gelber et al (2014) find that SYEP
participation causes a decrease in incarceration rates and mortality but a modest decrease
in average earnings for the three years after participation and no effect on college
participation. Modestino (2019) studies a Boston SYEP and finds that program

6

participation reduces criminal activity and improves conflict resolution skills. These
findings suggest that our estimates of positive effects on academic outcomes in high
school may not affect the college participation margin but may affect other later life
outcomes.
The plan for the remainder of the paper is as follows. The next section describes
the institutional background and some key details of the administration of NYCâ€™s SYEP
program. The following section describes the matched SYEP and NYC Department of
Education data. Next we discuss the econometric framework and the estimation results.
We conclude by discussing the size of the effects relative to the cost of the program and
important policy lessons suggested by the empirical analysis.

2) Institutional Background
New York Cityâ€™s Summer Youth Employment Program (SYEP) is designed to
introduce and prepare youth for future careers, foster skills important for success in the
labor market, and provide supplemental income to families. SYEP participants work in a
variety of entry-level jobs at community-based organizations (CBOs), government
agencies and private sector businesses; most common worksites include summer camps
and day care, followed by social or community service agencies and retail. Participants
are paid for up to 25 hours per week for up to six (or, in some years, seven) weeks at
minimum wage, currently $8.75 per hour. In addition to work experience, 10 percent of
participant hours are dedicated to education and training on topics related to time
management, financial literacy, workplace readiness and etiquette, and career planning

7

and finding employment.
The NYC Department of Youth and Community Development (DYCD)
administers the program and contracts with a variety of CBOs to conduct intake and
enrollment, as well as provide training and supervise job placement. All NYC residents
ages 14-24 are eligible to apply to SYEP. 4 To apply to the program, youth submit an
application directly online or through a paper application and select a CBO service
provider. Both types of applications are entered into the central SYEP data system. The
system cross-checks across all service provider applications for duplication by matching
the Social Security number and name of the applicant to ensure that each youth submits
only one application for the program. Each complete application is randomly assigned an
identification number. After the application deadline, DYCD assigns each service
provider the number of SYEP slots that they are contracted to serve. DYCD then runs a
lottery using the data system for each provider. The computerized system, using a
random selection algorithm, selects applicants using the identification numbers for each
provider according to the number of slots they have been allocated. The system sees each
application as an ID number belonging to a provider and does not use any applicant
information to determine their selection into the program, with the exception of those
who have self-identified as having a disability. We exclude these students from the
analysis.

4
SYEP also includes a few separate programs targeted at special populations, including one that
serves only youth with disabilities through a separate lottery competition, a special program
targeting vulnerable youth in foster care, court-involved or who are runaway/homeless youth that
was added in 2009, and a school-year program funded through the Workforce Investment Act that
does not use a lottery and guarantees admission. The results presented here focus on the larger
general SYEP program and lottery only.

8

SYEP is funded through a combination of federal (including Workforce
Investment Act, Community Services Block Grant and American Recovery and
Reinvestment Act funds), state (state TANF and general funds), city (through a city tax
levy) and private funds, and changes in the availability of program funding have dictated
fluctuations in the number of participants served over time. Specifically, the increase in
city and state funding after 2005 allowed DYCD to increase the number of participants
from 38,467 in 2005 to 42,956 participants by 2008. Expansion has not met demand,
however, as the number of applications has almost doubled. SYEP received 53,005
applications in 2005; this number grew to 80,129 in 2008.

3) Data and Sample
Student-level data for this study come from two primary sources: SYEP files
from the DYCD and New York City Department of Education (NYCDOE)
administrative data files. We matched students from each of these files for the 2005-2008
program years, encompassing 196,620 SYEP applications. Data from DYCD include an
indicator of SYEP lottery result, the CBO provider the student applied to, and, for those
students who participated, the type of SYEP work placement, the specific worksite, and
number of hours worked. Variables from NYCDOE files include student demographics,
school attendance, and information about standardized test-taking and performance.
Data Matching

9

Importantly, because the SYEP program is open to all NYC youth, including
non-students and students not enrolled in NYC public schools (students enrolled in
private religious and private non-religious schools), a 100 percent match rate between the
DYCD and NYCDOE files is impossible. 5 Since DYCD and NYCDOE files do not
contain a common identifying number (e.g. Social Security number), data were matched
on participant first and last names and date of birth. Matching was conducted by an
independent NYCDOE-approved consultant in order to maintain student anonymity. The
match rate was between 77 and 81 percent depending on the year. Unmatched
participants then include students enrolled in private or parochial schools or enrolled in
schools outside of NYC, as well as non-students. The match rate for NYCDOE students,
if we were able to identify them directly from the SYEP data, is likely considerably
higher, though we cannot directly test this. Therefore, determining the success rate for the
match is complicated by this fact, and we instead conduct a number of tests of the
relationship between probability of being matched and random lottery results. We find
that student files matched to NYCDOE data have a similar proportion of lottery winners
as the unmatched files (for which we only have DYCD data), indicating that winning the
lottery is not related to matching of files. We conduct additional tests on the match rate as
described below.
NYCDOE Data

5

Prior to matching the SYEP file to NYCDOE student ID numbers, we removed observations for
youth who had indicated on their SYEP application that they had left high school before finishing,
graduated from high school or completed a GED, or attended college, all of whom would not be
expected to match with NYCDOE student records.

10

The NYCDOE data include student-level demographic information, as well as an
academic record for each year in the NYC public schools. Student demographics include
gender, race\ethnicity, English proficiency, participation in special education and ESL
services, free and reduced price lunch eligibility, grade level, and age.
Each student record includes information on test-taking and performance on New
York State standardized tests in a variety of subjects, including English, various
mathematics exams (Math A, Math B, and Integrated Algebra and Geometry, which
replaced Math A and B in later years), Global History, Earth Science, Biology, Physics
and Chemistry. These tests, known as the â€œRegents Examinations,â€ are a series of tests
aligned with New York Stateâ€™s Learning Standards, and designed and administered by
the New York State (NYS) Department of Education, under the authority of the Board of
Regents of the University of The State of New York and prepared by teacher examination
committees and testing specialists. Examination scores range from 0â€“100%. Although the
specific requirements change over time and students have some flexibility in choosing
which exam to take, starting with students who entered 9th grade in 2001, earning a NYS
high school diploma (â€œRegentsâ€™ Diplomaâ€) requires passing a set of these exams
including mathematics, English, Global History and Geography, US History and
Government, and at least one science (e.g. Biology, Chemistry, Physics, Earth Science).
More specifically, in order to graduate with a high school diploma, students must score
65 or higher on any one math examâ€”usually Math A, 6 English, Global History and
Geography and US History and Government, and one science exam. To earn an

6

Math A was last administered in January, 2009 and replaced by Integrated Algebra beginning in
June 2008 and Geometry beginning in June 2009.

11

Advanced Regents Diploma, students must pass an additional mathematics exam, Math
B, 7 and one additional science (at least one life science and one physical science).
Additionally, students entering 9th grade in 2007 and prior had the option of graduating
with a â€œLocal Diploma,â€ which required passing any one of five Regents exams with a
score of at least 55. This option was gradually phased-out, 8 and the Local Diploma was
not available for students entering 9th grade in 2008 and later. Regents exams in all
subjects are offered in June each year, and a limited number of Regents are offered in
January and August. There are no mandated grades in which students are eligible or
required to take a specific exam, but they typically take the exam at the end of the related
course. Because the graduation requirements reward passing but do not penalize failing, it
is in a studentâ€™s best interest to take these exams as early as possible. The majority of
students elect to take the exams in June at the end of the school year.
Our analyses focus on the impact of SYEP participation on academic outcomes,
including test-taking and test-performance. To assess student performance, we examine
three test-related outcomes in turn: test taking, passing at various levels, and the level of
the actual test score. We construct an indicator variable for whether the student took the
Regents exam in a particular subject and variables measuring performance as z-scores for
each exam. 9 We also include indicator variables for whether the student passed the exam

7

Math B was last administered in June 2010, replaced by Algebra 2 and Trigonometry in June
2009.
8
Students entering grade 9 in 2005 were required to score 65 or above on two of the five required
Regents exams and score 55 or above on the remaining three; 2006 9th graders were required to
score 65 or above on three of the five required exams, and 2007 9th graders were required to score
65 or above on four of the five required exams.
9
Z-scores are standardized to have a mean of zero and a standard deviation of one across all
students taking that Regents exam in that particular year.

12

at three cut points: 55 (the score required for a Local Diploma available to a subset of
students in our sample); 65 (required for a Regents diploma), and 75 (required on English
and Math A for admission to CUNY four-year colleges). From these exam-specific
indicators, we create seven measures to capture general performance on Regents exams:
whether attempted any Regents exams in the school year following SYEP application and
the total number of Regents exams attempted, the total number of exams passed with a
score of 55 or above, the total number of exams passed with a score of 65 or above, the
total number of exams passed with a score of 75 or above, and the average (mean) score
on all exams taken that year.
Sample: SYEP Applicants
Our sample includes all SYEP applicants who were matched to the NYC public
school records and were enrolled public school students, representing 134,366 applicants
to the program from 2005-2008. 10 Table 1 includes the number of SYEP applicants in
each year as well as the number selected (â€œWinnersâ€), and not selected (â€œLosersâ€), by the
lottery. Note that the number of applicants increased in each year, and that the percentage
of applicants selected to participate decreased. Importantly, as discussed below, some
students applied to SYEP more than one time during this time frame, and these 134,366
applications consist of 96,214 unique individuals.
Table 2 provides descriptive statistics on the population of SYEP applicants from

10
We exclude duplicate observations for students who submit multiple SYEP applications within a
year, and a subgroup who applied to vulnerable youth programs, WIA programs or programs that
guaranteed summer jobs and did not use a lottery. We also exclude students who were are
currently in grade 7 or lower and those who are in grade 12. We exclude students currently in
grade 7, students currently in grade 12, and students in ungraded special education.

13

NYC public schools. The modal grade during which a student first applied to SYEP was
9th grade (about 41 percent of the applicants), with 22 percent applying in 8th grade, and
24 percent applying in 10th grade for the first time. Compared to non-applicants, SYEP
applicants are more likely to be female. Reflecting the substantially more disadvantaged
background of the applicants, SYEP applicants are more likely to be receiving free or
reduced price lunch. In addition, the applicants are much more likely to be black.
Table 3 provides descriptive statistics for the outcomes of interest related to
student Regents exam attempts and performance. 72 percent of the sample attempted at
least one Regents exam, with an average of 1.76 exams attempted each year. Roughly
half of the sample passed at least one Regents exam, with students passing an average of
1.13 exams (at score of 65 or higher) per year. The average z-score of -0.14 indicates that
this sample performed 0.14 standard deviations below the city average. Note that these
numbers do vary across cohort years.
Finally, Table 4 provides the â€œtake-upâ€ rate of SYEP placement offers.
Depending on the year, between 73-84 percent of participants offered an SYEP
placement (i.e. they won the SYEP lottery for the CBO they applied to) actually
participated in the program and worked at their summer job. 11
Testing Lottery Randomization
In order to evaluate the possibility that admission to the program is not random,

11

Around 2007, DYCD made a push to advertise SYEP and increase the number of applicants.
The number of applicants in our sample increased by about 40%, from 29,718 in 2006 to 40,233 in
2007. One possible explanation is that the large increase in applicants pulled from a wider pool of
applicants, some of whom were less inclined to accept the SYEP offer.

14

we estimated the effect of winning the lottery on each pre-existing student characteristic
(8th grade test scores, gender, race, free lunch status). If winning the lottery is random, it
should be uncorrelated with any characteristic of the student at the time of application.
Recall that each year, each CBO conducted its own separate lottery and therefore we
need to test the joint hypothesis that all CBO lottery outcomes are unrelated to student
characteristics. Conducting a single test where we treat all separate CBO lotteries as a
single lottery likely biases the test. We test the randomization for each program year
separately and conduct cross-equation tests. 12 Specifically, for each program year, and for
each observed characteristic, we regress each characteristic on a full set of indicators for
CBOs and indicators for winning the lottery interacted with CBO. Table 5 provides the
results from a joint cross-equation, cross-model F-test that all treatment-by-CBO
interaction coefficients are equal to zero. The results indicate that we cannot reject the
hypothesis that the lottery was random at conventional significance levels.
We also conducted a second test of lottery randomization by testing whether winning the
lottery predicts pre-SYEP academic outcomes. Because this falsification test uses the
same outcomes as in our main analysis, we discuss the results of this test below, after the
presentation of the main results. In short, on the basis of this falsification test, we cannot
reject the hypothesis that the lottery was in fact random.

12

Conducting the tests in this way is for convenience. We could also estimate a single regression
in which we include CBO x year and CBO x year x win variables.

15

4) Empirical Strategy
This paper investigates the impact of SYEP on student academic success in the
school year following SYEP participation, exploiting the random assignment of program
participants. By comparing academic outcomes of students offered SYEP placements (the
treatment group) to outcomes of students not offered placements (control group), we
derive intent-to-treat (ITT) estimates of the impact of SYEP. Since we also have data on
whether the student actually participated in an SYEP program and the extent of this
involvement, we can also estimate treatment effects of program participation among
those who apply. Our key outcomes are student-level measures of attempting, passing,
and performance (test scores) on the New York State standardized high school exams,
including exams in Mathematics, English, History, and Science. Importantly, because
SYEP participation is allocated via lottery, we are able to obtain causal estimates. If each
SYEP lottery is random and there is no differential attrition, within any individual lottery
a simple comparison of sample means on the outcome of interest between those offered
an opportunity to participate in SYEP (treatment group) and those not (control group)
provides unbiased estimates of the intent-to-treat effect, where the treatment is
participating in SYEP. In our analyses, the comparison group is the set of students who
applied to SYEP in a particular summer, but who were not offered a placement. These
students should be otherwise similar to the students in the treated group across all
dimensions and, most importantly, similar in the distribution of unobserved
characteristics, such as motivation and other non-cognitive attributes. As discussed above,
we conduct several tests of the randomization of the lottery, including a standard test

16

based on comparing observed characteristics of the lottery winners and losers, and a
second test, a falsification test, using whether a lottery win predicts prior year outcomes.
We cannot reject the hypothesis that the lottery is random.
Intent-to-Treat (OLS)
We begin with an analysis using an indicator for winning the lottery as the variable of
interest to estimate an intent-to-treat effect. To construct the estimating equations it is
important to recall that there is not just one SYEP lottery each year, but that each
Community Based Organization (CBO) has a separate lottery. As described above, each
CBO is associated with a potentially different set of jobs and programs.
Let Yitgbc be the outcome of interest for student ğ‘–ğ‘–, year ğ‘¡ğ‘¡, grade level ğ‘”ğ‘”, who applied to

CBO ğ‘ğ‘, and from an initial application cohort ğ‘ğ‘. The initial application cohort ğ‘ğ‘ is

defined as the grade times year of initial application. 13 Note that given some students
apply to SYEP more than once and repeat grades, cohort is not collinear with grade and
year.
Each of our outcomes is specified as
â€²
ğ›¼ğ›¼ + ğ›¿ğ›¿ğ‘ğ‘ğ‘ğ‘ + ğ›¾ğ›¾ğ‘ğ‘ + ğœ‡ğœ‡ğ‘”ğ‘” + ğœğœğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– (1)
ğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = ğ›½ğ›½ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– + ğ‘‹ğ‘‹ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–

where ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘›ğ‘›ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– takes a value of 1 if student ğ‘–ğ‘– won CBO ğ‘ğ‘â€™s lottery in period ğ‘¡ğ‘¡ and was

made an offer to participate in SYEP and 0 if he/she was not. Note the timing: the lottery

13

There are 24 unique first time application cohorts, e.g. first-time applicants who were in 9th
grade in year 2005 is one cohort, 10th grade in year 2005 is another, and so on. By including these,
we control for any cohort specific factors that may shape the first time applicant pool and/or their
outcomes.

17

in calendar year ğ‘¡ğ‘¡ associated with the ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘›ğ‘›ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– variable is for the summer before the

academic year over which the outcome ğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– occurs. 14 ğ‘‹ğ‘‹ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is a vector of student

characteristics which may influence student performance, such as gender, race/ethnicity,
free and reduced price lunch eligibility, limited English proficiency, special education
status, and ESL status. ğ‘‹ğ‘‹ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is potentially grade-varying as students change their free

lunch eligibility, ESL and other statuses as they progress through the school system. 15 ğ›¿ğ›¿ğ‘ğ‘ğ‘ğ‘

are fixed effects for each CBO interacted by calendar year. These fixed effects index each
individual lottery and program offered by each CBO, allowing us to control for potential
differences in the selection rates and applicant pools across CBOs and years. ğ›¾ğ›¾ğ¶ğ¶ are

cohort fixed effects, based on a studentâ€™s first year of applying to SYEP and grade in the
school year prior to applying to SYEP. These fixed effects absorb any mean differences
in cohort â€œqualityâ€ across the various application cohorts. ğœ‡ğœ‡ğ‘”ğ‘” are grade specific fixed

effects which absorb any grade level differences in academic outcomes as students
progress through school. ğœğœğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is the remaining residual error. 16

In this model, ğ›½ğ›½ is the primary parameter of interest and captures the effect of

14
For the test score outcomes, which are mainly recorded in June at the end of the academic year,
the spacing between SYEP participation, in the summer before, and these outcomes is 9-11
months.
15
The student characteristics vector is indexed with calendar time t and grade g because some
characteristics change over time when students repeat a grade. For example, if a student repeats a
grade they could come back the next year English proficient, when they were not the year
previous. Out of the 134,366 students in the analysis sample, 18,959 students repeat a grade.
16
Note that although covariates are not necessary to derive unbiased impact estimates when
treatment is randomly assigned, including additional covariates can improve the small sample
properties if the reduction in residual error variance outweighs the increase in imprecision due to
the estimation of additional parameters. Given our very large sample sizes, it would seem clear
that the reduction in residual error variance is the far more important factor. See Bloom (2006) for
some discussion of this issue.

18

being randomly offered (via lottery) a placement in SYEP. We estimate ğ›½ğ›½ using OLS.
Below we consider various forms of heterogeneity in the impacts of SYEP, where the

effects of SYEP vary by characteristics of the student, by the type of summer work and
program, and by the number of times applied to and participated in SYEP.
Treatment on the Treated (2SLS)
Because our data include not only lottery results (whether the student wins the
lottery and is offered an SYEP placement), but also whether the lottery winners in fact
participated in SYEP, we can estimate a second set of models using SYEP participation
as the treatment variable and the lottery win variable as an instrument:
â€²
ğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = ğ›½ğ›½Ë˜ ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– + ğ‘‹ğ‘‹ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–
ğ›¼ğ›¼Ë˜ + ğ›¿ğ›¿Ë˜ğ‘ğ‘ğ‘ğ‘ + ğ›¾ğ›¾Ë˜ğ‘ğ‘ + ğœ‡ğœ‡Ë˜ğ‘”ğ‘” + ğœğœË˜ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– (2)

â€²
ğœ”ğœ” + ğœ‰ğœ‰ğ‘ğ‘ğ‘ğ‘ + ğœƒğœƒğ‘ğ‘ + ğœ†ğœ†ğ‘”ğ‘” + ğœ–ğœ–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– (3)
ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = ğœ‘ğœ‘ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– + ğ‘‹ğ‘‹ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–

where ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘ƒğ‘ƒğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is an indicator variable equal to 1 if student ğ‘–ğ‘–, in year ğ‘¡ğ‘¡, grade ğ‘”ğ‘”, cohort
ğ‘ğ‘ participated in SYEP through CBO ğ‘ğ‘, and 0 otherwise. ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– , as defined above, is the
indicator of winning the lottery and being offered admission into SYEP. Equations (2)

and (3) form a Two Stage Least Squares (2SLS) system, with equation (3) the first stage
for the second stage given in equation (2). If the lottery is random, then winning the
lottery serves as a valid instrument for participating in SYEP.
Given that about 73-84 percent of participants actually participated in the SYEP
program if they won the lottery, the 2SLS estimate of SYEP participation ğ›½ğ›½Ë˜ should be
about a third larger than the intent-to-treat effect estimate ğ›½ğ›½ in equation (1). Because

some individuals may not participate in SYEP even if they are offered admission (win the
lottery), ğ›½ğ›½Ë˜ identifies the average effect of the SYEP program on the treated (the

19

treatment-on-the-treated, TOT), rather than the average effect in the population of
applicants. ğ›½ğ›½ from the intent-to-treat analysis, on the other hand, identifies the average

effect of being offered an SYEP placement. Both treatment parameters are average

effects over the same complier population but differ in their relative magnitudes. We
return to the issue of interpreting the magnitude of the estimates below.

5) Results
In this section we present our baseline results. We first present a test of the
randomization of the lottery. We then proceed to examine the effects of SYEP using OLS
(ITT) estimates with the lottery randomization variable directly and using the lottery as
an instrument in an instrumental variables 2SLS (TOT) analysis. The next section
examines heterogeneity in the effects of SYEP participation.
OLS (Intent-to-Treat) Results
Table 6 presents results for models in which we estimate the impact of winning
the SYEP lottery on Regents exam outcomes in the following school year. Because the
variable of interest we use is the randomized lottery result, the OLS estimator is unbiased
and consistent for the intent-to-treat effect. All models also include demographic controls
including free and reduced-price lunch eligibility, race/ethnicity, gender, special
education status and Limited English Proficiency, as well as CBO, grade, and cohort

20

fixed effects, as described above. 17
We use seven key measures of academic success related to test-taking and testperformance (passing and z-scores). Our initial models examine performance across all
Regents exams in the school year following SYEP application. These outcomes all
capture important measures of educational progress, effort, and ultimately success. In
addition to being a necessary pre-condition for graduation, attempting the Regents exams
may also be a signal of academic interest, engagement, and effort. If participation in
SYEP encourages students to increase their school effort, they may elect to take more
Regents exams than the minimum required for graduation, potentially improving their
chances at graduating from high school and improving their preparation for postsecondary study. Further, to the degree that participation in SYEP encourages academic
effort, there may be an improvement in student performance on these exams â€“ both in
terms of passing and the actual score â€“ if students are more attentive in class or spend
more time studying and preparing for exams. 18
Column 1 of Table 6 indicates that winning the SYEP lottery has a small positive

17

Results are similar if one drops the student level covariates from the regressions, as would be
expected given the lottery is random (See Appendix). The initial application cohort c is defined as
the grade x year of initial application. Given some students apply to SYEP more than once and
repeat grades, cohort is not collinear with grade and year.
18
In interpreting these results, note that the effects of SYEP on test taking performance comes
through two channels. First, SYEP induces more students to take tests. Second, SYEP can
improve performance on tests for two groups of students: infra-marginal students who would have
taken the test anyway, even in the absence of SYEP; and for marginal students who are induced to
attempt the test by SYEP. If this marginal group of test takers is of sufficiently low ability relative
to the infra-marginal students who would always take the tests, then the SYEP effect of inducing
lower ability students to attempt more tests could result in a 0 or negative average effect of SYEP
on test performance.

21

and significantly different from zero (at the 10 percent level) effect on whether students
attempt at least one Regents exam. Winning the SYEP lottery increases the probability of
attempting any Regents exam in the following year by 0.4 percentage points. To get a
sense of the magnitude of this effect, Table 3 indicates that in years following SYEP
application, the average probability a student attempted any Regents exam was 72
percent. Column 2 indicates a small statistically significant positive effect of winning the
SYEP lottery on the number of exams attempted - an increase of 0.021 exams from a
baseline of 1.76 exams attempted on average (Table 3).
In addition to a positive effect of increasing the Regents exam attempts, we also
find that SYEP improved test performance. Columns 3 and 5 indicates that SYEP lottery
winners experienced a small significant increase in passing any Regents exam (at the 65
score or higher), as well as in the number of exams passed. Column 4 finds a small
significant increase in the number of exams with a score of 55 or higher, and Column 6
indicates a small but not significant effect on the number of exams with a score of 75 or
higher, which constitute a high level of achievement. Finally, Column 8 indicates a small
increase in the mean standardized scores on these exams by about 0.008 standard
deviations, which is significantly different from 0 at the 10 percent level (p-value 0.08).
Note that the sample size for this outcome is among those students who took tests. Taken
together, these results suggest that SYEP has a small positive effect on taking and passing
Regents exams. 19

19

We also perform an F-test against the null hypothesis that all treatment effects for outcomes 1-6
are jointly zero. Table A11 (column 1) shows that we can reject the null hypothesis of no effect.
We consider only outcomes 1-6 as the seventh outcome, average z-score, is undefined for those
who took no exams and thus the sample for this last group differs from that for outcomes 1-6.

22

2SLS (Treatment on the Treated) Results
The results in Table 6 are OLS estimates for the intent-to-treat effect. Given that
about 73-84 percent of students who are offered an SYEP placement (won the lottery)
take-up the program and actually participate, the effects of program participation are
higher than the OLS results above indicate. We next turn to instrumental variable
estimates using winning the lottery as an instrument for SYEP participation, as described
above. Table 7 displays the 2SLS estimates of the TOT impact on test taking and
performance. These results indicate that the average effects of participating in SYEP are
small and positive, and these effects are approximately 1.2-1.4 times greater than the
OLS (ITT) estimates reported in Table 6.

6) Effect Heterogeneity
The models estimated above assume a constant effect of SYEP on academic
outcomes. We next explore heterogeneity in the effects of SYEP participation in two
dimensions: (i) by student observable characteristics such as gender, race, free lunch
status, and prior academic achievement, and (ii) by the number of times previously
participated in SYEP.
Heterogeneity by Student Characteristics
We estimate heterogeneity by student characteristics by generalizing the 2SLS
estimator in Equations (2) and (3) by allowing an interaction between SYEP participation
and student characteristics in X (gender, race, English ability, free lunch, age, and 8th

23

grade test scores), using as instruments lottery results interacted with those same
variables. The main equation we estimate is then
â€²
ğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = ğ›½ğ›½Ë˜ ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– + ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– Ã— ğ‘‹ğ‘‹â€²ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– ğ›¤ğ›¤Ë˜ + ğ‘‹ğ‘‹ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–
ğ›¼ğ›¼Ë˜ + ğ›¿ğ›¿Ë˜ğ‘ğ‘ğ‘ğ‘ + ğ›¾ğ›¾Ë˜ğ‘ğ‘ + ğœ‡ğœ‡Ë˜ğ‘”ğ‘” + ğœğœË˜ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– (4)

Where ğ›¤ğ›¤Ë˜ is a vector of treatment-by-covariate interaction coefficients. For each

outcome Y, we then predict the SYEP expected benefit (EB) for each student based on
their covariates. For a student with covariates ğ‘‹ğ‘‹ = ğ‘¥ğ‘¥, their SYEP expected benefit is

ğ¸ğ¸ğ¸ğ¸ = ğ¸ğ¸(ğ‘Œğ‘Œ|ğ‘‹ğ‘‹ = ğ‘¥ğ‘¥, ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘† = 1) âˆ’ ğ¸ğ¸(ğ‘Œğ‘Œ|ğ‘‹ğ‘‹ = ğ‘¥ğ‘¥, ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘†ğ‘† = 0) = ğ›½ğ›½^Ë˜ + ğ‘¥ğ‘¥ â€² ğ›¤ğ›¤^Ë˜ (5)

Table 8 presents the estimated distribution of SYEP effects. In the top panel, we
present the results for students who applied to SYEP. The top row reports the LATE, the
2SLS estimate from Table 7. The next row reports the average expected benefit,
averaging over the joint distribution of X variables in the sample of SYEP appliers. The
difference between the LATE and average EB estimates reflects the implicit weighting of
the 2SLS estimator over the distribution of covariates, which reflects the distribution of
compliers to the instruments, and may not be the sample proportion.
The next several rows of Table 8 report the percentiles of the distribution of
SYEP expected benefits, and the large differences in EB provide evidence of relevant
effect heterogeneity. We estimate that for 23-41 percent of appliers, SYEP participation
would negatively affect their academic outcomes (depending on the outcome), reflecting
a potential tradeoff of SYEP employment with academic participation and performance.
We also estimate that the EB of SYEP participation for some students could be several

24

times higher than the 2SLS/LATE estimates.
The bottom of Table 8 reports the EB distribution for the sample of non-SYEP
appliers. Although this sample did not participate in SYEP, we can predict effects for this
group using their observed covariates. The distribution of benefits for the non-appliers is
similar to that for appliers, suggesting that non-appliers are not selectively lower EB
individuals, at least based on observable characteristics.
Heterogeneity by Past Participation
An important feature of the SYEP program is that students are allowed to
participate in multiple years, and access to the program through the lottery process does
not depend on past participation: each lottery outcome is unrelated to lotteries in the
previous and subsequent years. Thus, there are a group of students who participate in t
and apply again in t+1, and among this group of previous participants, a randomlyassigned group will be offered a placement in t+1. We can exploit this feature of the
lottery randomization to estimate the effect of an additional year of SYEP participation,
conditional on previous participation, for specific sub-groups of repeat appliers.
Table 9 provides information regarding patterns in applications and selection by
the SYEP lottery over the four-year study period. While 68 percent of the sample applied
in only one year, 32 percent applied more than once, with 24 percent applying twice, 6
percent applying three times, and less than 1 percent applying four times. Among these
applicants, 39 percent never won the SYEP lottery, 48 percent won once, 11 percent
twice, and about 1.6 percent three times.
In general, the estimated impact of SYEP may vary for those who had applied

25

(and participated) in previous years for two main reasons. First, for those who apply, win
the lottery, and participate in multiple years, there may be a dosage effect, in which
participating in SYEP for more than one summer has a different effect than participating
once. Second, although the SYEP lottery does not take into account whether a student
had applied or participated before, the decision to apply for multiple years itself is not
random, and it may be that the types of students who choose to apply for multiple years
have different benefits from the program, even in the first year of participation. Given
this selection by application behavior, for which we have no lottery randomization or
other suitable instrument, our estimates reflect the local treatment effects for the subgroups who choose to apply for SYEP multiple times. Of course, our estimates of SYEP
effects, even for the first lottery, are necessarily local to the population who applies at all
to SYEP, and they may not extrapolate to the non-applicant group. This is a common
feature of many social programs: while lottery-based exogenous variation provides
credible identification of particular causal effects, these effects are always local to the
endogenous applicant group.
To estimate the effect of the second and third year of SYEP on those groups who
previously participated once and twice, respectively, we re-estimate our baseline intentto-treat model (1) but limit the sample based on application and participation history. We
divide the sample into three groups by application status and SYEP participation: Group
1 (first-time applicants), Group 2 (one-time past participators and second-time
applicants), and Group 3 (two-time past participators and third-time applicants). To be
clear, Groups 2 and 3 are students that had previously applied for SYEP, won the lottery,
and participated in SYEP (once in the case of Group 2 and twice in the case of Group 3).

26

To simplify the notation, we ignore the other control variables and drop the lottery/CBO,
grade, and cohort effects in the equation specifications below, but we include all of these
variables in the models we estimate. For each group of applicants ğ‘˜ğ‘˜, the outcome for
student ğ‘–ğ‘– in period ğ‘¡ğ‘¡ is

ğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– = ğ›½ğ›½ğ‘˜ğ‘˜ ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– + ğœğœğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– (6)

where ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘›ğ‘›ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is the dummy variable for winning the lottery in summer ğ‘¡ğ‘¡, and ğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is the

outcome in the academic year following that summer (e.g. if ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘›ğ‘›ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is for Summer 2006,

then ğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– is for the following academic year, Fall 2006-Spring 2007). The coefficient on

the ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘›ğ‘›ğ‘–ğ‘–ğ‘–ğ‘–ğ‘–ğ‘– variable, ğ›½ğ›½ğ‘˜ğ‘˜ , provides the effect of being offered additional SYEP placements

for the ğ‘˜ğ‘˜ ğ‘¡ğ‘¡â„ group of students.

Table 10 presents estimates for the 3 groups. Panel A indicates no significant

effect of winning the lottery for all first-time applicants, with one exceptionâ€”a small
significant increase in the number of exams passed with a score of 55 and 65 or higher. In
contrast, Panel B indicates substantial effects of winning the SYEP lottery for the group
who has already participated once. That is, while by and large there is no significant
effect of winning the lottery when averaging over all first-time appliers, the effect of
participating for the second time is statistically and economically significant for those
who participate and apply again. Panel C shows even larger effects of winning for the
third time for the final group of third-time applicants who have participated twice.
However, as this group is far smaller than groups 1 and 2, these estimates are noisier. 20
Table A11 presents results from a test of the joint restriction that treatment effects for all

20

Note that the models we are estimating are not panel models per se: each model includes only
one student observation. Therefore the error structure is not clustered at the student level.

27

outcomes are zero. 21 For only the full sample and Group 2 can we reject the null
hypothesis of no effect of SYEP.
Interpreting these ğ›½ğ›½ğ‘˜ğ‘˜ estimates for each sub-group requires some care. Although

estimating model (6) does indeed recover the causal effect of winning the ğ‘˜ğ‘˜ ğ‘¡ğ‘¡â„ lottery, this
effect is, as discussed above, local to Group ğ‘˜ğ‘˜ which has endogenously formed via

winning and participating in each previous lottery 1 through ğ‘˜ğ‘˜ âˆ’ 1. ğ›½ğ›½ğ‘˜ğ‘˜ may represent a

true dosage effect, where the effect of winning additional lotteries has a larger or smaller
magnitude than previous lotteries. However, it also might be that Group ğ‘˜ğ‘˜ has selected

into applying for the ğ‘˜ğ‘˜ ğ‘¡ğ‘¡â„ time based on the causal effects they enjoy. Said another way,

the SYEP data do not include a randomized multiple treatment arm experiment, in which
some groups are randomly offered 0,1,2,3 years of participation in SYEP. Instead,
students endogenously apply to multiple lotteries, and only for those students who apply
to multiple lotteries do we observe multiple SYEP doses. The Appendix provides more
detail and shows more formally that the dosage effect is not identified using this type of
data.
However, using the rich set of covariates available to us in the NYCDOE data,
we can characterize how Groups 1, 2, and 3 differ along observables. Table 11 shows
results comparing Group 1 versus 2 and Group 2 versus 3. 22 Groups 1 and 2 differ

21
As students who do not attempt any exams have no defined average score, the sample in
outcomes 1-6 differs (is a strict superset) of the sample for outcome 7, the average score.
Therefore we restrict the F-test in Table A11 to outcomes 1-6.
22
An alternative approach is to test the restriction that mean covariates are the same among all
three groups. However, due to the sequential way in which each group is formed, it is more natural
to directly test Group 2 against Group 1 and Group 3 against Group 2.

28

substantially in their observable student composition. Relative to first-time applicants
(Group 1), second-time applicants who have participated once (Group 2) are more likely
to be black, less likely to have limited English proficiency or English as a second
language, older, and have lower 8th grade reading scores. Relative to Group 2, Group 3
students are more likely to be black, are older, and have lower 8th grade reading scores.
As model (6) specifies a homogenous treatment effect within each group, the different
composition of students across groups might explain some of the differences seen in
Table 10.
To more directly identify how selection-on-observables between Groups 1, 2, and
3 determines the group-specific treatment effect ğ›½ğ›½ğ‘˜ğ‘˜ , we use our estimates of heterogenous

treatment effects by observable characteristics to calculate, for each outcome, the average
expected benefit (EB) in each group. Table 12 shows that for most outcomes, Groups 2
and 3 are made up of students with higher predicted treatment effects than Group 1. This
suggests that selection-on-observables in the decision to apply and participate drives
some of the differences in causal effects across groups. Therefore, although we cannot
identify exactly how much of the different effect estimates are dosage versus selection,
we have suggestive evidence that there is clear selection based on observables.

7) Robustness Checks
Match Rates
As described above, the SYEP program is open to non-students and students not
enrolled in NYC public schools (enrolled in private religious and non-religious schools),

29

and therefore the match rate between the SYEP program data and the NYCDOE data is
about 77-81 percent depending on the year.
We test for whether winning the lottery and being offered a SYEP placement
directly affected the match rate by using the full sample of all NYC public school
students (matched SYEP applicants and unmatched students). We consider only the
sample of first-time applicants to SYEP because, as estimated above, winning the lottery
is correlated with second and third applications. Our test consists of regressing a dummy
variable for the student being matched on an indicator for winning the lottery and grade
and lottery fixed effects. The estimated coefficient on the indicator for whether the
student won a SYEP lottery is not statistically significant at conventional levels (p-value
= 0.28) and the estimated coefficient is small in magnitude at 0.003 (see Appendix). This
result indicates that the match rate of SYEP and NYCDOE data is unrelated to the
student winning the lottery.
Attrition
We also tested whether winning the SYEP lottery affected whether students
remain in the NYC public schools and therefore continue to appear in our matched
NYCDOE-SYEP data. We define â€œattritionâ€ as a student who was in the NYCDOE
records in the year prior to applying to SYEP, not appearing in the NYCDOE data in the
year following the SYEP lottery. Appendix Table A reports results from a test of whether
winning the SYEP lottery is related to student attrition in the NYCDOE records by
replacing the outcome variable in our main estimating equation (1) with an indicator for
attrition. Our estimates indicate that winning the lottery is unrelated to attrition at
conventional significance levels across all grade levels.

30

Falsification Test
If the SYEP lottery is truly random, then winning the lottery should be
uncorrelated with past student outcomes. Using our main specification (1), we replace the
future outcomes for the academic year following the summer of SYEP lottery offer with
past outcomes for the academic year prior to SYEP application. Table 13 reports results
from this falsification test. Across the outcomes we examine, we find that winning the
lottery does not have a statistically significant effect on past outcomes, and coefficient
estimates small in magnitude. These results provide additional evidence in favor of the
validity of our research design.

8) Discussion
Our estimates suggest that participation in SYEP has, on average, a positive,
albeit small, effect on taking and passing the standardized tests administered by New
York State to measure progress in high school subjects. The results offer evidence that
SYEP improves educational outcomes that have proven stubbornly resistant to
interventions. As an example, New York Cityâ€™s Conditional Cash Transfer program
offered high school students $600 incentive for each Regents exam passedâ€“up to fiveâ€“but
yielded no significant effect (Riccio et al., 2013). 23

23

Interestingly, larger effects were found for students who were deemed proficient in English
Language Arts and Mathematics at the time they enrolled in high school, suggesting this is a
subgroup worthy of future investigation in the SYEP analysis.

31

Policy Implications of Effect Heterogeneity
Program evaluation can be thought of as answering three questions: is a
particular program effective, do the benefits of the program justify its costs, and what are
the mechanisms through which its benefits are realized? For a given program which is
unique in its institutional details, it is reasonable to think that the first two questions are
of primary importance, and the results above show that answering these questions by
estimating homogenous effects alone understates the effectiveness of SYEP for some
groups. That is, the estimated average causal effects across all students mask considerable
heterogeneity across both student covariates and multiple years of participation. These
findings of larger effects of SYEP for some groups warrant further discussion.
First, it bears repeating that when examining heterogeneous treatment effects by
observable characteristics, we do not set out to â€œfindâ€ some group that enjoyed a larger
benefit than the average effects suggest. Such an exercise is in principle valid, but care
must be taken to avoid spurious conclusions generated by multiple hypothesis testing.
Instead, we simply ask the question of whether we can detect a non-degenerate
distribution of treatment effects, exploiting the rich data on student characteristics and
relatively large sample size available to us to estimate causal effects for demographic
cells of non-trivial dimension. Indeed, we do find considerable variation in treatment
effects that suggests there are students for whom SYEP is very effective. Put another
way, modest average effects imply neither a small homogenous benefit of the program
nor even a small effect for the marginal student. Efforts to better target this and other

32

similar programs may be fruitful. 24
We find a considerable difference in the impact of participating in SYEP the first
time and participating the second (or third) time for select groups of students.
Disentangling these effects reveals, in fact, little effect of a single year of participation,
but larger, positive effects for the second and third year of participation.
It may be that students experience a dosage effect by which they realize larger
benefits with additional years of participation, for a variety of possible reasons.
Alternatively, these larger effects for those who have participated in the past may be due
to self-selection, which we might think of as a particularly inexpensive form of program
targeting. Although the SYEP lottery is random in any given year, the decision to apply
in subsequent years is not. Thus, students who do not have access to alternate activities or
means of finding employment might be more likely to apply for an additional year of
SYEP participation. Or, more motivated students may apply year after year, and may
benefit more from SYEP. Additionally, the decision to apply to SYEP for a second or
third year may be due to a positive experience after the first year of SYEP.
Given these two channels, a finding of positive or stronger effects for multiple
participators could be because there are increasing returns to participants for each year
students participate, or simply because the estimates reflect the self-selection of students

24

A recent study (Davis & Heller 2019) carries out a similar analysis evaluating a Chicago SYEP.
These authors use a machine learning model to identify subgroups who benefit from participation,
and they find evidence of subgroups for whom the treatment effect is much larger than the ITT.
Their method allows them to characterize the subgroups that benefit, which we explicitly do not
attempt. Although the program and outcomes studied in that paper differ from those examined
here, we interpret the findings as additional evidence of substantial heterogeneity in the treatment
effects of summer programs.

33

who are most likely to benefit from SYEP in any year. For policy makers, it may not
necessarily be crucial to distinguish the two types of effects, at least for some types of
policy questions. A finding of a large causal effect on multiple participators, regardless of
the mechanism, may indicate that SYEPâ€™s decision to allow repeat participators is simply
beneficial.
Effect Sizes
How large are the effect sizes we estimate? One simple way to measure the effect
sizes is to compare them to differences in the same outcomes by salient socioeconomic
differences â€“ the disparity in outcomes between white and black students and the
disparity between poor (free lunch eligible) and not-poor students. As an example, our
intent-to-treat estimate that SYEP improves the likelihood of passing any exam at the 65
threshold by 0.7% is roughly 38% the size of the black-white gap of 1.9% and 14% of the
poverty gap of 5.3%. The average effects on the treated group (TOT) are even larger. If
allocated only to the disadvantaged group, SYEP would close the race gap in pass rates
by almost 49% and the poverty gap by almost 19% with similar effects on the number of
exams taken.
What Does SYEP Cost to Provide?
We can obtain a rough estimate of the direct cost of the program as the sum of
the wages paid to participants, administrative costs and the costs for additional program
features, such as education components. Drawing on features and experiences from
SYEP and other social programs, we estimate each of these factors: SYEP participants

34

are paid New York State minimum wage, set at $8.75 per hour. Program participants
generally work twenty five hours per week for six weeks, or 150 hours. Thus, payments
to SYEP participants may be as high as $1312.50. Estimates of administrative overhead
costs vary, although 15 percent is commonly used by local governments. (This is, for
example, the overhead rate that the California Department of Education allows for public
after-school programs.) Finally, the cost of the supplementary education and training will
likely vary by provider or CBO, but previous work has estimated the per participant cost
of an educational program at $650 (Schwartz & Leos-Urbel, 2014).
Taken together, we estimate a cost of slightly more than $2,150 per participant â€“
less than 15% of annual per pupil education spending in NYC. To be clear, this is an
estimate of the budgetary cost â€“ that is, the direct outlays paid by the government or
funder of the program, the majority of which is essentially a transfer to (predominately
low-income) youth participants. Although a comprehensive cost-benefit analysis is
outside the scope of this paper, much of the program costs may be offset by the value of
work provided to organizations that youth work for and the communities they work in, as
well as by the value of the associated improvement in participantsâ€™ educational outcomes
(see, for example, Chetty et al. 2014).

9) Conclusions
We use the randomized lottery design of the SYEP to estimate that participation
in SYEP has a small positive effect on a variety of test taking and passing outcomes for
New York City high school students. The effects of SYEP on test taking are considerably

35

larger for students who had participated in SYEP in prior years, compared to those
applying for the first time. This suggests that there may be dosage effects associated with
SYEP participation and/or those students most likely to benefit from the program selfselect by applying to SYEP for multiple years. Regardless, this analysis indicates that
allowing participation in summer jobs programming for multiple years pays dividends for
some high school students well beyond the paycheck itself. Indeed, the benefits of this
relatively low-cost intervention are likely to substantially exceed the costs, suggesting
SYEP may be an important addition to the toolkit for policy makers seeking to improve
academic outcomes for high school students. Additional work exploring the persistence
of the effects beyond high school, the spillover effects for peers and communities and, in
a different vein, the heterogeneity in impacts across job placements and features, is
clearly warranted to provide guidance to policymakers adopting summer youth
employment programs across the country.

36

References
Anderson. A. L. and Hughes, L. A. (2009). Exposure to situations conducive to
delinquent behavior: The effects of time use, income, and transportation. Journal of
Research in Crime and Delinquency, 46(1), 5-34.
Bellotti, J., Rosenberg, L., Sattar, S., Esposito, A., & Ziegler, J. (2010). Reinvesting in
Americaâ€™s youth: Lessons from the 2009 Recovery Act Summer Youth Employment
Initiative. Princeton, NJ: Mathematica Policy Research, Inc.
Bloom, H. (2006). The core analytics of randomized experiments for social research.
MDRC Working Papers on Research Methodology.
Chetty, Raj, John N. Friedman, and Jonah E. Rockoff. (2014) "Measuring the Impacts of
Teachers II: Teacher Value-Added and Student Outcomes in Adulthood." American
Economic Review, 104(9): 2633-79.
Davis, J., & Heller, S. (2019). Rethinking the Benefits of Youth Employment Programs;
The Heterogeneous Effects of Summer Jobs. The Review of Economics and Statistics
(forthcoming), doi:10.1162/rest_a_00850.
Dee T., Dobbie W., Jacob B., & Rockoff J.(2019). The Causes and Consequences of Test
Score Manipulation: Evidence from the New York Regents Examinations. American
Economic Journal: Applied Economics, 11(3), 382-423.
Duckworth, A. L., Peterson, C., Matthews, M. D., & Kelly, D. R. (2007). Grit:
Perseverance and passion for long-term goals. Journal of Personality and Social
Psychology, 92(6), 1087.
Kalenkoski, C., & Pabilonia, S. (2009). Does working while in high school reduce U.S.
study time? Social Indicators Research, 93: 117-121.
Kemple J., Segeritz M., & Stephenson N. (2013). Building On-Track Indicators for High
School Graduation and College Readiness: Evidence from New York City. Journal of
Education for Students Placed at Risk, 18(1), 7-28.
Gelber, A., Isen, A., and Kessler, J. (2014). â€œThe Effects of Youth Employment:
Evidence from New York City Summer Youth Employment Program Lotteries,â€ NBER
working paper, December.
Heckman, J. (2000). Policies to foster human capital. Research in Economics, 54(1), 356.
Heller, S. (2013). Short-term results of the One Summer Plus Evaluation. Chicago:
University of Chicago Crime Lab.

37

Heller, S. (2014). The Effects of Summer Jobs on Disadvantaged Youth. Unpublished
manuscript, University of Pennsylvania, Philadelphia, PA.
Lillydahl, J. (1990). Academic achievement and part-time employment of high school
students. The Journal of Economic Education, 21(3), 307-316.
Leos-Urbel, J. (2014) What is a summer job worth? The impact of summer youth
employment on academic outcomes. Journal of Policy Analysis and Management, 33(4),
891-911.
McNeal, R. (1997). Are students being pulled out of high school? The effect of
adolescent employment on dropping out. Sociology of Education, 70(3), 206-220.
Modestino, A. (2019). How Do Summer Youth Employment Programs Improve Criminal
Justice Outcomes, and for Whom? Journal of Policy Analysis and Management, 38(3),
600-628.
Monahan, K., Lee, J., & Steinberg, L. (2011). Revisiting the impact of part-time work on
adolescent adjustment: distinguishing between selection and socialization using
propensity score matching. Child Development, 82(1), 96-112.
Mortimer, J. (2003). Working and Growing up in America. Cambridge: Harvard
University Press.
Painter, M. (2010). Get a job and keep it! High school employment and adult wealth
accumulation. Research in Social Stratification and Mobility, 28(2).
Rothstein, D. (2007) High school employment and youths' academic achievement. The
Journal of Human Resources, 42(1).
Riccio, J. , Dechausay, N., Miller C., NuÃ±ez, S., Verma N., Yang, E. (2013). Conditional
cash transfers in New York City; The continuing story of the Opportunity NYCâˆ’Family
Rewards Demonstration. MDRC. New York, NY.
Ruhm, C. (1995). Is High School Employment Consumption or Investment? Journal of
Labor Economics, 15(4), 735-776.

Sabia, J. (2009). School-year employment and academic performance of young
adolescents. Economics of Education Review, 28(2).
Schwartz, A. E., Stiefel, L., & Wiswall, M. 2013. Do Small Schools Improve
Performance in Large, Urban Districts? Causal Evidence from New York City Journal of
Urban Economics, 77: 27-40

38

Schwartz, A. E. and Leos-Urbel, J. (2014). "Expanding Summer Employment
Opportunities for Low-Income Youth." In M. S. Kearney and B. H. Harris (Eds.) The
Hamilton Project: Policies to Address Poverty in America. (pp.55-66). Washington, D.C.:
Brookings Institution Press.
Stern, D., & Briggs, D. (2001). Does paid employment help or hinder performance in
secondary school? Insights from U.S. high school students. Journal of Education and
Work, 14(3), 355-372.
Sum, A., Trubskyy, M. & McHugh, W. (2013). The summer employment experiences and
the personal/social behaviors of youth violence prevention employment program
participants and those of a comparison group. Boston, MA: Center for Labor Market
Studies Northeastern University.
Walker, G., and Vilella-Velez, F. (1992). Anatomy of a demonstration: The Summer
Training and Education Program (STEP) from pilot through replication and
postprogram impacts. Philadelphia, PA: Public/Private Venture.

39

Making Summer Matter:
The Impact of Youth Employment on Academic
Performance
Data Appendix
This study analyzes the treatment effect of participation in New York Cityâ€™s Summer Youth Employment
Program (SYEP) on academic outcomes for New York City public high school students. Estimating this
effect requires sampling from the joint distribution of student outcomes and characteristics, and program
application, selection, and participation. The former are obtained from the New York City Department of
Education (NYCDOE) administrative data files, and the latter come from the NYC Department of Youth
and Community Development (DYCD). Because these datasets are large and complex, and this study has
evolved through several drafts, the final results presented here differ slightly (but not qualitatively) from
those in previous versions. In particular, the construction of academic outcomes changed slightly between
drafts. This Data Appendix describes how this change altered our main estimates.

Regents Examinations
The academic outcomes examined in this study consist of the number of Regents Examinations attempted
and passed (at several score cut-offs) as well as the average within-exam standardized score. Clearly, these
outcomes will differ depending on the set of exams used in their calculation. Inclusion of more exams will
inflate the number of exams attempted and passed, although this has ambiguous effects on the treatment
effect of SYEP. Below are displayed, for each exam, the number of SYEP applicants who attempted that
exam in the year following SYEP application.
Regents Exam Attempts: Appliers (2006-2009)

2006
2007
2008
2009

Engl

Bio

Chem

Earth Sci

Physics

Math A

Math B

Geo

Algebra

Lang

Global Hist

US Hist

5, 759
7, 189
11, 553
13, 879

4, 241
5, 138
7, 636
9, 926

2, 148
2, 755
3, 652
3, 965

2, 641
3, 176
4, 459
5, 565

720
988
1, 418
1, 635

6, 335
7, 021
9, 698
4, 176

1, 668
2, 142
3, 625
4, 047

0
0
0
5, 235

0
0
0
10, 066

1, 670
2, 375
3, 365
3, 936

5, 649
7, 109
12, 195
14, 194

5, 164
6, 468
10, 140
11, 682

Notes: Sample includes all applications for students expected to be in high school following SYEP. Applications are
omitted if the student submits multiple applications or is in ungraded special education following SYEP. Applications
to vulnerable youth programs, programs based out of the city, or programs with a greater than 99 percent or less than
0 percent selection rate are omitted. Math A and B were phased out in favor of geometry and algebra in 2009.

A coding error in the previous draft of this paper erroneously excluded many US History scores from years
2006-2008. Therefore, the final results of this study differ from those previously reported. Below we compare
the Two Stage Least Squares (2SLS) estimates computed with and without US History. The latter set
replicates closely previously reported results. The former (including US History) are preferred as they use
more information on academic outcomes relevant to high school graduation. The reader will note that
qualitatively, the conclusions are the same. SYEP participation had a significantly positive effect on the
number of exams attempted, the probability of passing any exam with a score of at least 65, and the number
passed at score cut-offs 55 and 65.

1

Treatment-on-the-Treated Estimates
Dependent variable:
Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

(1)

(2)

(3)

(4)

(5)

(6)

(7)

0.005âˆ—
(0.003)

0.026âˆ—âˆ—âˆ—
(0.010)

0.009âˆ—âˆ—âˆ—
(0.003)

0.033âˆ—âˆ—âˆ—
(0.009)

0.023âˆ—âˆ—âˆ—
(0.008)

0.010
(0.006)

0.010âˆ—
(0.006)

Panel A: Table 7
Worked

Panel B: US History Omitted from Outcomes
Worked

0.004
(0.003)

0.019âˆ—âˆ—
(0.009)

0.007âˆ—âˆ—
(0.003)

0.023âˆ—âˆ—âˆ—
(0.008)

0.016âˆ—âˆ—
(0.007)

0.006
(0.005)

0.010âˆ—
(0.006)

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

Y
Y
Y
134,366
0.169

Y
Y
Y
134,366
0.282

Y
Y
Y
134,366
0.235

Y
Y
Y
134,366
0.291

Y
Y
Y
134,366
0.321

Y
Y
Y
134,366
0.340

Y
Y
Y
96,200
0.395

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Heteroskedastic robust standard errors clustered at the student-level. Students
in 12th grade, below 8th grade, and in ungraded special education are excluded. Cohort is an indicator for the year of
first application to SYEP interacted with the grade of the student when first applied. There are 24 unique cohorts in
the sample. Limited English Proficiency (LEP) is determined by score on the Language Assessment Battery exam.
Zread and Zmath are 8th grade state test scores, standardized by grade and year of administration. Grade is current
grade level in school which includes 8-11th grade and an additional category for alternative specialized programs (for
example GED programs).

2

Making Summer Matter:
The Impact of Youth Employment on Academic
Performance
Appendices and Figures
Appendix A.1
Consider a standard potential outcomes model in which there are three possible â€œdosagesâ€ of SYEP participation: p = 0, 1, 2 for 0, 1, or 2 times participating, respectively.1 Potential outcomes for each state p are given
by

Yp = Î´p + Up

(1)

where by normalization E(Up ) = 0 for all p. The average effect of participating in SYEP once (relative to
never participating) is given by Î´1 âˆ’ Î´0 , and the average effect of participating twice (versus once) is given
by Î´2 âˆ’ Î´1 . We define a â€œDosage Effectâ€ as DE21 = (Y2 âˆ’ Y1 ) âˆ’ (Y1 âˆ’ Y0 ) and therefore the average dosage
effect is ADE21 = (Î´2 âˆ’ Î´1 ) âˆ’ (Î´1 âˆ’ Î´0 ). We are interested in testing the whether ADE21 = 0. Rejecting this
restriction with a positive (negative) ADE21 would be evidence of supermodularity (submodularity) in SYEP
participation: students who participate twice enjoy a larger (smaller) effect of the second participation.
Next, consider attempting to identify ADE21 using the data generated by SYEP. For simplicity, we assume
full compliance (winning the lottery implies participation). Let Wp = 1 denote winning the pth lottery and 0
otherwise, and let Ap = 1 denote applying to the pth lottery with 0 otherwise. We can identify at least two
local effects with the following estimands:

Î²1 = E(Y |W1 = 1, A1 = 1) âˆ’ E(Y |W1 = 0, A1 = 1)
Î²2 = E(Y |W2 = 1, W1 = 1, A2 = 1, A1 = 1) âˆ’ E(Y |W2 = 0, W1 = 1, A2 = 1, A1 = 1)

(2)
(3)

As seen below, Î²1 and Î²2 correspond to the average treatment effects of the first and second lottery for
Groups 1 and 2, respectively, defined in the main text (see Equation 6). Group 1 of first time appliers who
have never participated and Group 2 who apply twice after having won and participated once.
Decomposing Î²2 , we have

Î²2 = E(Y2 |W2 = 1, W1 = 1, A2 = 1, A1 = 1) âˆ’ E(Y1 |W2 = 0, W1 = 1, A2 = 1, A1 = 1)
= Î´2 + E(U2 |W2 = 1, W1 = 1, A2 = 1, A1 = 1) âˆ’ {Î´1 + E(U1 |W2 = 0, W1 = 1, A2 = 1, A1 = 1)}
= (Î´2 âˆ’ Î´1 ) + E(U2 âˆ’ U1 |W1 = 1, A2 = 1, A1 = 1)

(4)
(5)
(6)

where the last equality is given by lottery randomization, which implies that E(Up |Wp = 1, Â·) = E(Up |Wp =
0, Â·) for all p (and conditioning variables prior to p). Therefore, Î²2 does indeed identify the average treatment
effect of winning the second lottery for Group 2. (Î´2 âˆ’ Î´1 ) is the average effect of participating twice relative
1 Although we do consider three-time applicants in the main analyses, here we restrict our attention to participating at most
twice. The point at hand is made no clearer by considering higher "dosages."

1

to once, and E(U2 âˆ’ U1 |W1 = 1, A2 = 1, A1 = 1) is the selection effect for Group 2, who apply twice after
having won and participated once.
In general, the application decision is likely endogenous, and so

E(U2 âˆ’ U1 |W1 = 1, A2 = 1, A1 = 1) 6= E(U2 âˆ’ U1 ) = 0

(7)

Therefore, comparing the outcomes of the second lottery winners and losers in Group 2 does not identify the
average effect of participating twice over once. Further, we see from decomposing Î²1 that

Î²1 = (Î´1 âˆ’ Î´0 ) + E(U1 âˆ’ U0 |A1 = 1)

(8)

The difference in these two estimands identifies

Î²2 âˆ’ Î²1 = (Î´2 âˆ’ Î´1 ) âˆ’ (Î´1 âˆ’ Î´0 ) + E(U2 âˆ’ U1 |W1 = 1, A2 = 1, A1 = 1) âˆ’ E(U1 âˆ’ U0 |A1 = 1)

(9)

And it is clear that assuming that the selection terms are equal in magnitude is extremely stringent and
unlikely to obtain. We conclude that the average dosage effect is not identified.

2

Tables and Figures
Table 1: Sample by Lottery Outcome, 2005-2008
Year
2005
2006
2007
2008
Total

Winners

Losers

Total

15, 544
17, 165
19, 296
19, 963
71, 968

9, 126
11, 609
19, 353
22, 310
62, 398

24, 670
28, 774
38, 649
42, 273
134, 366

Notes: Sample includes all applications for students expected to be in high school following SYEP.
Applications are omitted if the student submits
multiple applications or in ungraded special education following SYEP. Applications to vulnerable
youth programs, programs based out of the city,
or programs with a greater than 99 percent or less
than 0 percent selection rate are omitted.

3

Table 2a: Comparison of Applicants and Non-Applicants
First Time Applicants

Non-Applicants

Difference

0.56
0.05
0.50
0.32
0.12
0.72
0.10
0.04
0.01
0.09
âˆ’0.03
âˆ’0.02

0.48
0.15
0.30
0.40
0.15
0.64
0.09
0.10
0.05
0.08
âˆ’0.01
âˆ’0.02

0.08
âˆ’0.10
0.21
âˆ’0.07
âˆ’0.04
0.08
0.02
âˆ’0.06
âˆ’0.04
0.01
âˆ’0.02
âˆ’0.004

Female
White
Black
Hispanic
Asian
Free Lunch
Red Lunch
LEP
ESL Not LEP
Graded Spec Ed
Z Reading 8th Grade
Z Math 8th Grade

P-Value
0
0
0
0
0
0
0
0
0
0
0
0.32

Notes: First time applicants are defined as the first application made by a student after 2005
for students who did not apply in 2005. 2005 is excluded since we cannot see applications made
before 2005 and thus we cannot distinguish first-time applicants from repeat applicants in
2005. Non-applicants are defined as students in grades 8-11 and alternative special education
who never apply between 2005 and 2008. Limited English Proficiency (LEP) is determined by
score on the Language Assessment Battery exam. Z Reading and Z Math scores are 8th grade
state test scores, standardized by grade and year of administration.

Table 2b: Grade of First Application
Grade
8
9
10
11
Alt Specialized Program
Total Apply
Total Never Apply

Fraction

Count

0.219
0.407
0.243
0.124
0.007

15, 068
28, 050
16, 763
8, 517
505
68, 903
451, 464

Notes: First time applicants are defined as the
first application made by a student after 2005
for students who did not apply in 2005. 2005 is
excluded since we cannot see applications made
before 2005 and thus we cannot distinguish firsttime applicants from repeat applicants in 2005.
Non-applicants are defined as students in grades
8-11 and alternative special education who never
apply between 2005 and 2008.

4

Table 3: Regents Exam Outcomes in School Year Following SYEP (SYEP Applicants 2005-2008)
Statistic
Attempt Any Exam
Number Attempted
Pass Any Exam (65+)
Number of Exams Passed (55+)
Number of Exams Passed (65+)
Number of Exams Passed (75+)
Avg. Z-Score

N

Mean

St. Dev.

Min

Max

134,366
134,366
134,366
134,366
134,366
134,366
96,200

0.72
1.76
0.55
1.43
1.13
0.58
âˆ’0.14

0.45
1.52
0.50
1.39
1.28
0.98
0.82

0
0
0
0
0
0
âˆ’7.19

1
8
1
8
8
6
2.32

Notes: Sample includes all applications for students expected to be in high school following
SYEP. Applications are omitted if the student submits multiple applications or in ungraded
special education following SYEP. Applications to vulnerable youth programs, programs
based out of the city, or programs with a greater than 99 percent or less than 0 percent
selection rate are omitted.

5

Table 4: SYEP Take-Up Rates (2005-2008)

2005
2006
2007
2008
Total

Fraction of Lottery Winners that Worked

Number of Winners

82.1
83.5
73.4
74.4
77.9

15, 544
17, 165
19, 296
19, 963
71, 968

Notes: Sample includes all applications for students expected to be in
high school following SYEP. Applications are omitted if the student
submits multiple applications or in ungraded special education following
SYEP. Applications to vulnerable youth programs, programs based out
of the city, or programs with a greater than 99 percent or less than 0
percent selection rate are omitted.

6

Table 5: Lottery Randomization Results

F
Prob >F

2005

2006

2007

2008

0.99
0.56

1.01
0.44

0.99
0.57

1.04
0.19

Notes: We test lottery randomization by regressing each
student characteristic on a full set of lottery fixed effects
and lottery fixed effects interacted with lottery outcome. We
test the restriction that all lottery-by-outcome coefficients
are zero. Recall that each year, each CBO conducted its
own separate lottery, and therefore we need to test the joint
hypothesis that all CBO lottery outcomes are unrelated to
student characteristics. Conducting a single test in which we
treat all separate lotteries as a single lottery likely biases the
test.

7

Table 6: Intent-to-Treat Estimates
Dependent variable:
Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

(1)

(2)

(3)

(4)

(5)

(6)

(7)

âˆ—

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

Select

0.004
(0.002)

0.021
(0.008)

0.007
(0.003)

0.026
(0.007)

0.018
(0.006)

0.007
(0.005)

0.008âˆ—
(0.004)

Female

0.019âˆ—âˆ—âˆ—
(0.002)

0.091âˆ—âˆ—âˆ—
(0.007)

0.017âˆ—âˆ—âˆ—
(0.003)

0.078âˆ—âˆ—âˆ—
(0.007)

0.045âˆ—âˆ—âˆ—
(0.006)

0.023âˆ—âˆ—âˆ—
(0.005)

0.001
(0.005)

Black

0.011
(0.007)

âˆ’0.007
(0.020)

âˆ’0.019âˆ—âˆ—âˆ—
(0.007)

âˆ’0.067âˆ—âˆ—âˆ—
(0.019)

âˆ’0.123âˆ—âˆ—âˆ—
(0.018)

âˆ’0.204âˆ—âˆ—âˆ—
(0.016)

âˆ’0.149âˆ—âˆ—âˆ—
(0.013)

Asian

0.022âˆ—âˆ—âˆ—
(0.008)

0.150âˆ—âˆ—âˆ—
(0.023)

0.017âˆ—âˆ—
(0.008)

0.154âˆ—âˆ—âˆ—
(0.023)

0.171âˆ—âˆ—âˆ—
(0.022)

0.192âˆ—âˆ—âˆ—
(0.020)

0.059âˆ—âˆ—âˆ—
(0.015)

Hispanic

âˆ’0.004
(0.007)

âˆ’0.015
(0.021)

âˆ’0.011
(0.007)

âˆ’0.035âˆ—
(0.020)

âˆ’0.080âˆ—âˆ—âˆ—
(0.018)

âˆ’0.147âˆ—âˆ—âˆ—
(0.016)

âˆ’0.091âˆ—âˆ—âˆ—
(0.013)

Free Lunch

âˆ’0.036âˆ—âˆ—âˆ—
(0.004)

âˆ’0.079âˆ—âˆ—âˆ—
(0.012)

âˆ’0.053âˆ—âˆ—âˆ—
(0.004)

âˆ’0.105âˆ—âˆ—âˆ—
(0.012)

âˆ’0.115âˆ—âˆ—âˆ—
(0.011)

âˆ’0.078âˆ—âˆ—âˆ—
(0.009)

âˆ’0.074âˆ—âˆ—âˆ—
(0.007)

Red Lunch

0.010âˆ—âˆ—
(0.005)

0.063âˆ—âˆ—âˆ—
(0.016)

âˆ’0.002
(0.006)

0.036âˆ—âˆ—
(0.015)

0.018
(0.014)

0.005
(0.012)

âˆ’0.024âˆ—âˆ—
(0.009)

LEP

0.186âˆ—âˆ—âˆ—
(0.008)

0.681âˆ—âˆ—âˆ—
(0.029)

0.128âˆ—âˆ—âˆ—
(0.010)

0.378âˆ—âˆ—âˆ—
(0.026)

0.223âˆ—âˆ—âˆ—
(0.024)

0.081âˆ—âˆ—âˆ—
(0.017)

âˆ’0.058âˆ—âˆ—âˆ—
(0.018)

ESL Not LEP

0.019âˆ—
(0.011)

0.085âˆ—âˆ—
(0.034)

0.010
(0.011)

0.074âˆ—âˆ—
(0.031)

0.064âˆ—âˆ—
(0.027)

0.076âˆ—âˆ—âˆ—
(0.019)

âˆ’0.003
(0.022)

Spec Ed

âˆ’0.010âˆ—âˆ—
(0.005)

âˆ’0.094âˆ—âˆ—âˆ—
(0.013)

âˆ’0.133âˆ—âˆ—âˆ—
(0.005)

âˆ’0.307âˆ—âˆ—âˆ—
(0.011)

âˆ’0.283âˆ—âˆ—âˆ—
(0.010)

âˆ’0.112âˆ—âˆ—âˆ—
(0.006)

âˆ’0.349âˆ—âˆ—âˆ—
(0.010)

Age

âˆ’0.117âˆ—âˆ—âˆ—
(0.002)

âˆ’0.360âˆ—âˆ—âˆ—
(0.006)

âˆ’0.121âˆ—âˆ—âˆ—
(0.002)

âˆ’0.325âˆ—âˆ—âˆ—
(0.005)

âˆ’0.286âˆ—âˆ—âˆ—
(0.004)

âˆ’0.132âˆ—âˆ—âˆ—
(0.003)

âˆ’0.102âˆ—âˆ—âˆ—
(0.004)

Zread

0.001
(0.002)

âˆ’0.002
(0.006)

0.051âˆ—âˆ—âˆ—
(0.002)

0.092âˆ—âˆ—âˆ—
(0.005)

0.171âˆ—âˆ—âˆ—
(0.005)

0.221âˆ—âˆ—âˆ—
(0.004)

0.245âˆ—âˆ—âˆ—
(0.004)

Zmath

0.045âˆ—âˆ—âˆ—
(0.002)

0.156âˆ—âˆ—âˆ—
(0.006)

0.101âˆ—âˆ—âˆ—
(0.002)

0.258âˆ—âˆ—âˆ—
(0.005)

0.298âˆ—âˆ—âˆ—
(0.005)

0.266âˆ—âˆ—âˆ—
(0.004)

0.294âˆ—âˆ—âˆ—
(0.004)

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

Y
Y
Y
134,366
0.169

Y
Y
Y
134,366
0.281

Y
Y
Y
134,366
0.235

Y
Y
Y
134,366
0.290

Y
Y
Y
134,366
0.321

Y
Y
Y
134,366
0.340

Y
Y
Y
96,200
0.395

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Heteroskedastic robust standard errors clustered at the student-level. Students
in 12th grade, below 8th grade, and in ungraded special education are excluded. Cohort is an indicator for the year of
first application to SYEP interacted with the grade of the student when first applied. There are 24 unique cohorts in
the sample. Limited English Proficiency (LEP) is determined by score on the Language Assessment Battery exam.
Zread and Zmath are 8th grade state test scores, standardized by grade and year of administration. Grade is current
grade level in school which includes 8-11th grade and an additional category for alternative specialized programs (for
example GED programs).

8

Table 7: Treatment-on-the-Treated Estimates
Dependent variable:
Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

(1)

(2)

(3)

(4)

(5)

(6)

(7)

âˆ—

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

Worked

0.005
(0.003)

0.026
(0.010)

0.009
(0.003)

0.033
(0.009)

0.023
(0.008)

0.010
(0.006)

0.010âˆ—
(0.006)

Female

0.019âˆ—âˆ—âˆ—
(0.002)

0.091âˆ—âˆ—âˆ—
(0.007)

0.017âˆ—âˆ—âˆ—
(0.003)

0.078âˆ—âˆ—âˆ—
(0.007)

0.045âˆ—âˆ—âˆ—
(0.006)

0.023âˆ—âˆ—âˆ—
(0.005)

0.001
(0.005)

Black

0.011
(0.007)

âˆ’0.008
(0.020)

âˆ’0.019âˆ—âˆ—âˆ—
(0.007)

âˆ’0.069âˆ—âˆ—âˆ—
(0.019)

âˆ’0.124âˆ—âˆ—âˆ—
(0.018)

âˆ’0.205âˆ—âˆ—âˆ—
(0.016)

âˆ’0.150âˆ—âˆ—âˆ—
(0.013)

Asian

0.022âˆ—âˆ—âˆ—
(0.008)

0.150âˆ—âˆ—âˆ—
(0.023)

0.017âˆ—âˆ—
(0.008)

0.155âˆ—âˆ—âˆ—
(0.023)

0.171âˆ—âˆ—âˆ—
(0.022)

0.192âˆ—âˆ—âˆ—
(0.020)

0.059âˆ—âˆ—âˆ—
(0.015)

Hispanic

âˆ’0.004
(0.007)

âˆ’0.016
(0.021)

âˆ’0.011
(0.007)

âˆ’0.035âˆ—
(0.020)

âˆ’0.081âˆ—âˆ—âˆ—
(0.018)

âˆ’0.147âˆ—âˆ—âˆ—
(0.016)

âˆ’0.091âˆ—âˆ—âˆ—
(0.013)

Free Lunch

âˆ’0.036âˆ—âˆ—âˆ—
(0.004)

âˆ’0.079âˆ—âˆ—âˆ—
(0.012)

âˆ’0.053âˆ—âˆ—âˆ—
(0.004)

âˆ’0.105âˆ—âˆ—âˆ—
(0.012)

âˆ’0.115âˆ—âˆ—âˆ—
(0.011)

âˆ’0.078âˆ—âˆ—âˆ—
(0.009)

âˆ’0.074âˆ—âˆ—âˆ—
(0.007)

Red Lunch

0.010âˆ—âˆ—
(0.005)

0.063âˆ—âˆ—âˆ—
(0.016)

âˆ’0.002
(0.006)

0.036âˆ—âˆ—
(0.015)

0.017
(0.014)

0.005
(0.012)

âˆ’0.024âˆ—âˆ—
(0.009)

LEP

0.186âˆ—âˆ—âˆ—
(0.008)

0.682âˆ—âˆ—âˆ—
(0.029)

0.128âˆ—âˆ—âˆ—
(0.010)

0.379âˆ—âˆ—âˆ—
(0.026)

0.223âˆ—âˆ—âˆ—
(0.024)

0.081âˆ—âˆ—âˆ—
(0.017)

âˆ’0.058âˆ—âˆ—âˆ—
(0.018)

ESL Not LEP

0.019âˆ—
(0.011)

0.086âˆ—âˆ—
(0.034)

0.010
(0.011)

0.075âˆ—âˆ—
(0.031)

0.064âˆ—âˆ—
(0.027)

0.077âˆ—âˆ—âˆ—
(0.019)

âˆ’0.003
(0.022)

Spec Ed

âˆ’0.010âˆ—âˆ—
(0.005)

âˆ’0.094âˆ—âˆ—âˆ—
(0.013)

âˆ’0.133âˆ—âˆ—âˆ—
(0.005)

âˆ’0.308âˆ—âˆ—âˆ—
(0.011)

âˆ’0.283âˆ—âˆ—âˆ—
(0.010)

âˆ’0.112âˆ—âˆ—âˆ—
(0.006)

âˆ’0.349âˆ—âˆ—âˆ—
(0.010)

Age

âˆ’0.117âˆ—âˆ—âˆ—
(0.002)

âˆ’0.360âˆ—âˆ—âˆ—
(0.006)

âˆ’0.121âˆ—âˆ—âˆ—
(0.002)

âˆ’0.324âˆ—âˆ—âˆ—
(0.005)

âˆ’0.285âˆ—âˆ—âˆ—
(0.004)

âˆ’0.131âˆ—âˆ—âˆ—
(0.003)

âˆ’0.102âˆ—âˆ—âˆ—
(0.004)

Zread

0.001
(0.002)

âˆ’0.002
(0.006)

0.051âˆ—âˆ—âˆ—
(0.002)

0.092âˆ—âˆ—âˆ—
(0.005)

0.171âˆ—âˆ—âˆ—
(0.005)

0.221âˆ—âˆ—âˆ—
(0.004)

0.245âˆ—âˆ—âˆ—
(0.004)

Zmath

0.045âˆ—âˆ—âˆ—
(0.002)

0.156âˆ—âˆ—âˆ—
(0.006)

0.101âˆ—âˆ—âˆ—
(0.002)

0.258âˆ—âˆ—âˆ—
(0.005)

0.298âˆ—âˆ—âˆ—
(0.005)

0.266âˆ—âˆ—âˆ—
(0.004)

0.294âˆ—âˆ—âˆ—
(0.004)

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

Y
Y
Y
134366
0.06

Y
Y
Y
134366
0.064

Y
Y
Y
134366
0.133

Y
Y
Y
134366
0.117

Y
Y
Y
134366
0.169

Y
Y
Y
134366
0.213

Y
Y
Y
96200
0.325

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Heteroskedastic robust standard errors clustered at the student-level. Students
in 12th grade, below 8th grade, and in ungraded special education are excluded. Cohort is an indicator for the year of
first application to SYEP interacted with the grade of the student when first applied. There are 24 unique cohorts in
the sample. Limited English Proficiency (LEP) is determined by score on the Language Assessment Battery exam.
Zread and Zmath are 8th grade state test scores, standardized by grade and year of administration. Grade is current
grade level in school which includes 8-11th grade and an additional category for alternative specialized programs (for
example GED programs).

9

Table 8a: LATE and Expected Benefit (Appliers Only)

LATE
Avg. EB
P01 EB
P10 EB
P50 EB
P90 EB
P99 EB
P50 EB - P10 EB
P90 EB - P50 EB

Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

0.005âˆ—âˆ—
(0.002)
0.004
(0.003)
âˆ’0.029âˆ—âˆ—
(0.009)
âˆ’0.013âˆ—âˆ—âˆ—
(0.004)
0.003
(0.003)
0.023âˆ—âˆ—âˆ—
(0.004)
0.046âˆ—âˆ—âˆ—
(0.007)
0.016âˆ—âˆ—âˆ—
(0.003)
0.02âˆ—âˆ—âˆ—
(0.003)

0.026âˆ—âˆ—âˆ—
(0.007)
0.018âˆ—âˆ—
(0.008)
âˆ’0.107âˆ—âˆ—âˆ—
(0.021)
âˆ’0.051âˆ—âˆ—âˆ—
(0.012)
0.016âˆ—
(0.008)
0.088âˆ—âˆ—âˆ—
(0.011)
0.175âˆ—âˆ—âˆ—
(0.021)
0.066âˆ—âˆ—âˆ—
(0.008)
0.072âˆ—âˆ—âˆ—
(0.009)

0.009âˆ—âˆ—âˆ—
(0.002)
0.011âˆ—âˆ—âˆ—
(0.003)
âˆ’0.021
(0.012)
âˆ’0.007
(0.004)
0.009âˆ—âˆ—âˆ—
(0.003)
0.031âˆ—âˆ—âˆ—
(0.005)
0.05âˆ—âˆ—âˆ—
(0.008)
0.016âˆ—âˆ—âˆ—
(0.003)
0.022âˆ—âˆ—âˆ—
(0.004)

0.033âˆ—âˆ—âˆ—
(0.007)
0.025âˆ—âˆ—âˆ—
(0.008)
âˆ’0.066
(0.028)
âˆ’0.029âˆ—âˆ—
(0.012)
0.023âˆ—âˆ—âˆ—
(0.008)
0.079âˆ—âˆ—âˆ—
(0.011)
0.136âˆ—âˆ—âˆ—
(0.031)
0.051âˆ—âˆ—âˆ—
(0.008)
0.056âˆ—âˆ—âˆ—
(0.009)

0.023âˆ—âˆ—âˆ—
(0.006)
0.018âˆ—âˆ—
(0.007)
âˆ’0.069
(0.03)
âˆ’0.029âˆ—âˆ—
(0.011)
0.017âˆ—âˆ—
(0.007)
0.065âˆ—âˆ—âˆ—
(0.01)
0.108âˆ—âˆ—âˆ—
(0.022)
0.046âˆ—âˆ—âˆ—
(0.008)
0.048âˆ—âˆ—âˆ—
(0.008)

0.01âˆ—âˆ—
(0.005)
0.007
(0.006)
âˆ’0.055âˆ—âˆ—
(0.018)
âˆ’0.025âˆ—âˆ—
(0.008)
0.007
(0.006)
0.039âˆ—âˆ—âˆ—
(0.008)
0.07âˆ—âˆ—âˆ—
(0.015)
0.032âˆ—âˆ—âˆ—
(0.006)
0.032âˆ—âˆ—âˆ—
(0.006)

0.01âˆ—âˆ—
(0.004)
0.014âˆ—âˆ—
(0.006)
âˆ’0.073âˆ—âˆ—
(0.027)
âˆ’0.02âˆ—âˆ—
(0.008)
0.013âˆ—âˆ—
(0.006)
0.044âˆ—âˆ—âˆ—
(0.01)
0.092âˆ—âˆ—âˆ—
(0.023)
0.033âˆ—âˆ—âˆ—
(0.008)
0.031âˆ—âˆ—
(0.009)

Notes:
*p<0.1; **p<0.05; ***p<0.01. For each outcome, expected benefit (EB) is the predicted treatment effect
of SYEP given student covariates and the 2SLS estimates of heterogeneous treatment effects by student covariates.
Bootstrap standard errors are calculated with 1000 bootstrap iterations, block clustered at the student level. Bootstrap p-values for LATE, mean, and quantiles computed for a two-sided test, and bootstrap p-values for difference in
select quantiles computed for a one-sided test. Standard errors of LATE estimates differ from those in Table 7 as they
are bootstrapped instead of asymptotic estimates.
Table 8b: LATE and Expected Benefit (Non-Appliers Only)
Any Attempt
Avg. EB
P01 EB
P10 EB
P50 EB
P90 EB
P99 EB
P50 EB - P10 EB
P90 EB - P50 EB

âˆ—

0.006
(0.004)
âˆ’0.033âˆ—
(0.012)
âˆ’0.012âˆ—
(0.005)
0.005
(0.003)
0.025âˆ—âˆ—âˆ—
(0.005)
0.051âˆ—âˆ—âˆ—
(0.009)
0.017âˆ—âˆ—âˆ—
(0.003)
0.02âˆ—âˆ—âˆ—
(0.004)

N. Attempts

Any Pass 65

âˆ—âˆ—

âˆ—âˆ—âˆ—

0.027
(0.011)
âˆ’0.119âˆ—âˆ—
(0.03)
âˆ’0.045âˆ—âˆ—
(0.015)
0.026âˆ—âˆ—
(0.01)
0.098âˆ—âˆ—âˆ—
(0.017)
0.196âˆ—âˆ—âˆ—
(0.029)
0.071âˆ—âˆ—âˆ—
(0.011)
0.073âˆ—âˆ—âˆ—
(0.012)

0.012
(0.004)
âˆ’0.026
(0.014)
âˆ’0.009
(0.006)
0.01âˆ—âˆ—âˆ—
(0.004)
0.035âˆ—âˆ—âˆ—
(0.007)
0.057âˆ—âˆ—âˆ—
(0.01)
0.019âˆ—âˆ—
(0.005)
0.025âˆ—âˆ—âˆ—
(0.005)

N. Pass 55
âˆ—âˆ—

0.026
(0.01)
âˆ’0.09âˆ—
(0.038)
âˆ’0.034âˆ—
(0.017)
0.024âˆ—âˆ—âˆ—
(0.009)
0.09âˆ—âˆ—âˆ—
(0.014)
0.155âˆ—âˆ—
(0.045)
0.058âˆ—âˆ—âˆ—
(0.012)
0.066âˆ—âˆ—âˆ—
(0.011)

N. Pass 65

N. Pass 75

ZScore

0.015
(0.01)
âˆ’0.1âˆ—âˆ—
(0.038)
âˆ’0.039âˆ—
(0.017)
0.017âˆ—âˆ—
(0.008)
0.069âˆ—âˆ—âˆ—
(0.012)
0.113âˆ—âˆ—
(0.03)
0.056âˆ—âˆ—âˆ—
(0.013)
0.052âˆ—âˆ—âˆ—
(0.009)

0.007
(0.008)
âˆ’0.066âˆ—
(0.025)
âˆ’0.03âˆ—
(0.014)
0.009
(0.007)
0.043âˆ—âˆ—âˆ—
(0.009)
0.075âˆ—âˆ—âˆ—
(0.016)
0.039âˆ—âˆ—
(0.011)
0.035âˆ—âˆ—âˆ—
(0.006)

0.009
(0.007)
âˆ’0.109âˆ—âˆ—âˆ—
(0.033)
âˆ’0.035âˆ—âˆ—
(0.012)
0.013âˆ—âˆ—
(0.006)
0.045âˆ—âˆ—âˆ—
(0.011)
0.103âˆ—âˆ—
(0.031)
0.048âˆ—âˆ—âˆ—
(0.012)
0.033âˆ—âˆ—
(0.009)

Notes:
*p<0.1; **p<0.05; ***p<0.01. For each outcome, expected benefit (EB) is the predicted treatment effect
of SYEP given student covariates and the 2SLS estimates of heterogeneous treatment effects by student covariates.
Bootstrap standard errors are calculated with 1000 bootstrap iterations, block clustered at the student level. Bootstrap
p-values for LATE, mean, and quantiles computed for a two-sided test, and bootstrap p-values for difference in select
quantiles computed for a one-sided test.

10

Table 9: Number of Applications and Selections
N Apps
1
2
3
4
Total

Percent

N Students

68.46
24.19
6.58
0.77
100

65, 868
23, 277
6, 332
737
96, 214

N Wins
0
1
2
3
4
Total

Percent

N Students

39.27
48.45
10.59
1.59
0.10
100

37, 786
46, 616
10, 185
1, 526
101
96, 214

Notes: Sample includes all applications for students expected to be in
high school following SYEP. Applications are omitted if the student
submits multiple applications or in ungraded special education following
SYEP. Applications to vulnerable youth programs, programs based out
of the city, or programs with a greater than 99 percent or less than 0
percent selection rate are omitted.

11

Table 10: Hetereogenous Effects by Past Participation
Dependent variable:
Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

(1)

(2)

(3)

(4)

(5)

(6)

(7)

Panel A: First-Time Applicants (Group 1)
Select

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

âˆ’0.0004
(0.003)

0.016
(0.010)

0.004
(0.004)

0.021âˆ—âˆ—
(0.010)

0.016âˆ—
(0.009)

0.005
(0.007)

0.006
(0.006)

Y
Y
Y
66,973
0.169

Y
Y
Y
66,973
0.299

Y
Y
Y
66,973
0.244

Y
Y
Y
66,973
0.308

Y
Y
Y
66,973
0.333

Y
Y
Y
66,973
0.355

Y
Y
Y
49,143
0.416

Panel B: Second-Time Applicants, One-Time Past Participators (Group 2)
Select

0.016âˆ—âˆ—
(0.006)

0.034
(0.021)

0.015âˆ—âˆ—
(0.007)

0.033âˆ—
(0.019)

0.009
(0.017)

0.016
(0.013)

0.004
(0.012)

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

Y
Y
Y
17,836
0.193

Y
Y
Y
17,836
0.286

Y
Y
Y
17,836
0.250

Y
Y
Y
17,836
0.298

Y
Y
Y
17,836
0.336

Y
Y
Y
17,836
0.352

Y
Y
Y
13,195
0.387

Panel C: Third-Time Applicants, Two-Time Past Participators (Group 3)
Select

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

0.003
(0.017)

0.063
(0.051)

0.012
(0.017)

0.088âˆ—âˆ—
(0.044)

0.067âˆ—
(0.038)

0.015
(0.026)

0.019
(0.030)

Y
Y
Y
3,129
0.207

Y
Y
Y
3,129
0.333

Y
Y
Y
3,129
0.230

Y
Y
Y
3,129
0.309

Y
Y
Y
3,129
0.324

Y
Y
Y
3,129
0.324

Y
Y
Y
2,061
0.354

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Sample limited to outcomes in 2007-2009. Heteroskedastic robust standard
errors clustered at the student-level. Students in 12th grade, below 8th grade, and in ungraded special education are
excluded. Cohort is an indicator for the year of first application to SYEP interacted with the grade of the student
when first applied. There are 24 unique cohorts in the sample. Limited English Proficiency (LEP) is determined by
score on the Language Assessment Battery exam. Zread and Zmath are 8th grade state test scores, standardized by
grade and year of administration. Grade is current grade level in school which includes 8-11th grade and an additional
category for alternative specialized programs (for example GED programs).

12

Table 11: Balance Test - Hetereogenous Effects Groups
Group 2 Less Group 1
Female
White
Black
Asian
Hispanic
Free Lunch
Reduced Lunch
LEP
ESL Not LEP
Spec Ed
Age
Zread
Zmath

P-Value

âˆ’0.003
âˆ’0.01
0.06
âˆ’0.02
âˆ’0.03
âˆ’0.01
0.01
âˆ’0.02
âˆ’0.01
0.02
0.65
âˆ’0.04
âˆ’0.01

Group 3 Less Group 2
âˆ’0.01
0.001
0.03
âˆ’0.01
âˆ’0.02
âˆ’0.01
âˆ’0.01
âˆ’0.003
âˆ’0.005
0.01
0.64
âˆ’0.04
âˆ’0.01

0.45
0
0
0
0
0.01
0.001
0
0
0
0
0.0000
0.52

P-Value
0.42
0.87
0.002
0.12
0.01
0.57
0.46
0.17
0.01
0.27
0
0.02
0.59

Notes: Displayed point estimates are differences in average covariate value between Groups 2
and 1 and Groups 3 and 2, respectively. Group 1 consists of all first-time applicants in years
2006-2008. Group 2 is all students who applied for the second time in 2006-2008 and had
applied, won, and participated in the prior year. Group 3 is all students who applied for the
third time in 2006-2008 and had applied, won, and participated in each of the two years prior.

Table 12: Average Expected Benefit
Group
1
2
3

Any Attempt
0.0056
0.0059
0.0059

N. Attempts
0.0262
0.0304
0.0335

Any Pass 65
0.0099
0.0094
0.0081

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

0.0314
0.0374
0.0416

0.0221
0.0268
0.0289

0.0095
0.0112
0.0112

0.0111
0.0111
0.0091

Notes: For each outcome, expected benefit (EB) is the predicted treatment effect of SYEP given student covariates
and the 2SLS estimates of heterogeneous treatment effects by student covariates. Group 1 consists of all first-time
applicants in years 2006-2008. Group 2 is all students who applied for the second time in 2006-2008 and had applied,
won, and participated in the prior year. Group 3 is all students who applied for the third time in 2006-2008 and had
applied, won, and participated in each of the two years prior.

13

Table 13: Lottery Randomization Results by Covariate

Female
White
Asian
Black
Hispanic
Free Lunch
Reduced Lunch
LEP
ESL Not LEP
Spec Ed
Grade 8
Grade 9
Grade 10
Grade 11
Alt Grade
Age
Zread
Zmath

Win Coef

SE

P-Value

-0.004
0
-0.003
0.002
0
-0.004
0.002
0.001
0.001
0.003
-0.001
0.002
0.002
-0.001
-0.001
-0.006
-0.003
-0.005

0.003
0.001
0.001
0.002
0.002
0.003
0.002
0.001
0.001
0.002
0.002
0.003
0.003
0.002
0.001
0.008
0.005
0.004

0.19
0.82
0.02
0.36
0.87
0.12
0.3
0.51
0.41
0.05
0.56
0.56
0.53
0.53
0.07
0.37
0.45
0.27

Notes: Point estimates and hetereoskedastic robust standard
errors (clustered at student level) for separate regressions of each
student covariate on full set of indicators for winning each lottery
(2005-2008).

Table 14: Falsification Test (Outcomes Year Prior to Lottery)
Dependent variable:
Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

(1)

(2)

(3)

(4)

(5)

(6)

(7)

Select

0.003
(0.002)

0.003
(0.004)

0.002
(0.002)

0.003
(0.004)

âˆ’0.001
(0.004)

âˆ’0.003
(0.004)

âˆ’0.008
(0.008)

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

Y
Y
Y
138,162
0.477

Y
Y
Y
138,162
0.546

Y
Y
Y
138,162
0.391

Y
Y
Y
138,162
0.513

Y
Y
Y
138,162
0.440

Y
Y
Y
138,162
0.279

Y
Y
Y
50,906
0.157

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Sample differs from main analyses due to lagged outcome. Heteroskedastic robust
standard errors clustered at the student-level. Students in 12th grade, below 8th grade, and in ungraded special
education are excluded. Cohort is an indicator for the year of first application to SYEP interacted with the grade of
the student when first applied. There are 24 unique cohorts in the sample. Limited English Proficiency (LEP) is
determined by score on the Language Assessment Battery exam. Zread and Zmath are 8th grade state test scores,
standardized by grade and year of administration. Grade is current grade level in school which includes 8-11th grade
and an additional category for alternative specialized programs (for example GED programs).

14

Appendix
Table A1: Likelihood of Winning SYEP Lottery by Matching to DOE Data

2005
2006
2007
2008

Matched

Not Matched

Total

63.7
60.8
50.5
48.5

64.0
61.2
51.1
48.0

63.7
60.9
50.7
48.4

Notes: Applications to vulnerable youth programs, programs based out of the city, or programs with a greater
than 99 percent or less than 0 percent selection rate are
omitted.

15

Table A2: Probability of Being Matched to DOE Data (2006-2008)
Dependent variable:
Matched
Select

0.003
(0.003)

CBO x Year FE?
Grade FE?
Observations
R2

Y
Y
120,817
0.037

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Heteroskedastic robust standard errors clustered at the lotterylevel. Grade is last grade before application which includes 7-12th grade and an additional category
for alternative programs. Sample includes all unmatched applications to SYEP in years 2006-2008
and all first-time applicants in those years. 2005 is excluded since we cannot see applications made
before 2005 and thus we cannot distinguish first-time applicants from repeat applicants in 2005.

16

Table A3: Attrition in Year Following Application
Grade
8
9
10
11
Alt. Program
Total

Frac Attrite Winners

Frac Attrite Losers

Frac Attrite All

N Applications

2.8
4.1
2.5
4.1
31.7
3.8

2.9
4.5
2.8
4.0
30.8
4.0

2.8
4.3
2.6
4.1
31.2
3.9

20, 855
50, 613
42, 227
23, 327
1, 137
139, 966

Notes: Attrition is defined as not appearing in NYCDOE administrative data in the year following
the SYEP lottery. Main Analyses condition on non-attrition, so number of analyzed applications
is mechanically smaller than total presented here. Sample includes all applications for students
expected to be in high school following SYEP. Applications are omitted if the student submits
multiple applications or in ungraded special education following SYEP. Applications to vulnerable
youth programs, programs based out of the city, or programs with a greater than 99 percent or less
than 0 percent selection rate are omitted.

17

Table A4: Impact of Winning Lottery on Attrition (2006-2009)
Dependent variable:
8th Grade

9th Grade

10th Grade

11th Grade

Alt Program

All Grades

(1)

(2)

(3)

(4)

(5)

(6)

Select

0.0003
(0.002)

âˆ’0.001
(0.002)

0.001
(0.002)

0.0003
(0.003)

0.026
(0.033)

0.001
(0.001)

CBO x Year FE?
Cohort FE?
Grade FE?
Observations
R2

Y
Y
N
20,855
0.037

Y
Y
N
50,613
0.021

Y
Y
N
42,227
0.032

Y
Y
N
23,327
0.040

Y
Y
N
1,137
0.207

Y
Y
Y
139,966
0.047

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Outcome variable is attrition in years 2006-2009. Attrition
is defined as not appearing in DOE administrative data in the year following the SYEP lottery.
Main analyses condition on non-attrition, so number of analyzed applications is mechanically smaller
than total presented here. Sample includes all applications for students expected to be in high
school following SYEP. Applications are omitted if the student submits multiple applications or is in
ungraded special education following SYEP. Applications to vulnerable youth programs, programs
based out of the city, or programs with a greater than 99 percent or less than 0 percent selection
rate are omitted.

18

Table A5: Fraction of NYC DOE Students Attempting at Least One Regents Exam 2006-2009
Grade

Fraction

8
9
10
11
12
Alt. Program

12.8
50.4
76.9
84.3
53.3
17.7

Notes: NYC DOE students include all students with non-missing grades who appear in
administrative data.

19

Table A6: Comparing ITT Effect Size

Panel A: ITT Estimates
Select
Black
Free Lunch
Zread

Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

0.004
0.011
-0.036
0.001

0.021
-0.007
-0.079
-0.002

0.007
-0.019
-0.053
0.051

0.026
-0.067
-0.105
0.092

0.018
-0.123
-0.115
0.171

0.007
-0.204
-0.078
0.221

0.008
-0.149
-0.074
0.245

Panel B: SYEP Effect / Covariate Coefficient
Perc Black
Perc Free Lunch
Perc Zread

Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

0.369
0.111
4.772

3.004
0.261
10.901

0.383
0.137
0.144

0.380
0.243
0.278

0.148
0.158
0.107

0.037
0.096
0.034

0.052
0.105
0.032

Notes: For each outcome, the percent of covariate effect (Panel B) is defined as the ITT effect of SYEP divided by the
absolute value of the coefficient on a given covariate in the estimated ITT model.

20

Table A7: Comparing TOT Effect Size

Panel A: TOT Estimates
Worked
Black
Free Lunch
Zread

Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

0.005
0.011
-0.036
0.001

0.026
-0.008
-0.079
-0.002

0.009
-0.019
-0.053
0.051

0.033
-0.069
-0.105
0.092

0.023
-0.124
-0.115
0.171

0.010
-0.205
-0.078
0.221

0.010
-0.150
-0.074
0.245

Panel B: SYEP Effect / Covariate Coefficient
Perc Black
Perc Free Lunch
Perc Zread

Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

0.485
0.143
6.095

3.345
0.336
14.351

0.484
0.177
0.185

0.480
0.313
0.358

0.189
0.204
0.137

0.047
0.124
0.044

0.066
0.132
0.040

Notes: For each outcome, the percent of covariate effect (Panel B) is defined as the treatment effect of SYEP divided
by the absolute value of the coefficient on a given covariate in the estimated two-stage-least-squares model.

21

Table A8a: Heterogeneous Treatment-on-the-Treated Estimates
Dependent variable:
Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

(1)

(2)

(3)

(4)

(5)

(6)

(7)

Worked

âˆ’0.024
(0.055)

âˆ’0.121
(0.151)

0.042
(0.055)

âˆ’0.111
(0.138)

âˆ’0.083
(0.122)

âˆ’0.103
(0.093)

0.081
(0.105)

Worked x Female

0.005
(0.006)

0.038âˆ—âˆ—
(0.019)

0.005
(0.006)

0.034âˆ—âˆ—
(0.017)

0.023
(0.015)

0.011
(0.011)

âˆ’0.004
(0.011)

Worked x Black

âˆ’0.012
(0.017)

âˆ’0.017
(0.051)

âˆ’0.019
(0.018)

0.007
(0.049)

0.015
(0.046)

0.015
(0.040)

âˆ’0.008
(0.030)

Worked x Asian

âˆ’0.002
(0.018)

âˆ’0.024
(0.056)

âˆ’0.015
(0.019)

âˆ’0.003
(0.055)

0.015
(0.052)

0.028
(0.048)

âˆ’0.026
(0.033)

Worked x Hispanic

âˆ’0.001
(0.017)

0.002
(0.053)

âˆ’0.008
(0.018)

0.036
(0.050)

0.049
(0.047)

0.043
(0.041)

0.016
(0.031)

Worked x Free Lunch

0.007
(0.010)

âˆ’0.027
(0.032)

âˆ’0.003
(0.011)

âˆ’0.042
(0.030)

âˆ’0.030
(0.027)

0.026
(0.022)

âˆ’0.010
(0.018)

Worked x Red Lunch

0.010
(0.013)

âˆ’0.036
(0.041)

âˆ’0.008
(0.014)

âˆ’0.062
(0.039)

âˆ’0.041
(0.036)

0.048
(0.030)

âˆ’0.017
(0.023)

Worked x LEP

âˆ’0.007
(0.022)

âˆ’0.006
(0.084)

âˆ’0.021
(0.028)

âˆ’0.034
(0.076)

âˆ’0.060
(0.068)

âˆ’0.035
(0.049)

âˆ’0.065
(0.048)

Worked x ESL Not LEP

âˆ’0.013
(0.030)

0.030
(0.098)

âˆ’0.003
(0.030)

0.106
(0.086)

0.055
(0.075)

âˆ’0.051
(0.054)

0.069
(0.062)

Worked x Spec Ed

0.016
(0.011)

0.046
(0.033)

0.033âˆ—âˆ—âˆ—
(0.011)

0.063âˆ—âˆ—
(0.028)

0.054âˆ—âˆ—
(0.023)

0.012
(0.015)

0.048âˆ—âˆ—
(0.024)

Worked x Age

0.002
(0.003)

0.009
(0.008)

âˆ’0.001
(0.003)

0.009
(0.008)

0.006
(0.007)

0.003
(0.005)

âˆ’0.003
(0.006)

Worked x Zread

0.019âˆ—âˆ—âˆ—
(0.005)

0.049âˆ—âˆ—âˆ—
(0.015)

0.010âˆ—âˆ—
(0.005)

0.024âˆ—
(0.013)

0.024âˆ—
(0.012)

0.025âˆ—âˆ—
(0.010)

âˆ’0.004
(0.009)

Worked x Zmath

âˆ’0.006
(0.005)

0.017
(0.015)

0.001
(0.005)

0.011
(0.013)

0.003
(0.012)

âˆ’0.014
(0.010)

âˆ’0.003
(0.009)

Year FE?
Grade FE?
Observations
R2

Y
Y
134366
0.06

Y
Y
134366
0.064

Y
Y
134366
0.133

Y
Y
134366
0.117

Y
Y
134366
0.169

Y
Y
134366
0.214

Y
Y
96200
0.325

Note: âˆ— p<0.1; âˆ—âˆ— p<0.05; âˆ—âˆ—âˆ— p<0.01. Heteroskedastic robust standard errors clustered at the student-level. Students
in 12th grade, below 8th grade, and in ungraded special education are excluded. Cohort is an indicator for the year of
first application to SYEP interacted with the grade of the student when first applied. There are 24 unique cohorts in
the sample. Limited English Proficiency (LEP) is determined by score on the Language Assessment Battery exam.
Zread and Zmath are 8th grade state test scores, standardized by grade and year of administration. Grade is current
grade level in school which includes 8-11th grade and an additional category for alternative specialized programs (for
example GED programs).

22

Table A8b: Joint Test of Treatment Interactions
Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

1.6
0.1

2.5
0.001

1.4
0.1

1.6
0.1

1.4
0.1

1.2
0.3

1.3
0.2

F-Stat
P-Value

Notes: F-statistics and p-values from test of joint restriction that all treatment by covariate coefficients
are zero.

Table A9: Expected Benefit Moments: Apply Less Non-Apply

Avg. EB
P01 EB
P10 EB
P50 EB
P90 EB
P99 EB

Any Attempt

N. Attempts

Any Pass 65

N. Pass 55

N. Pass 65

N. Pass 75

ZScore

âˆ’0.522
(0.324)
âˆ’0.119
(0.488)
0.108
(0.611)
âˆ’0.845
(0.245)
âˆ’0.111
(0.435)
âˆ’0.114
(0.157)

âˆ’0.497
(0.198)
âˆ’0.114
(0.339)
0.112
(0.409)
âˆ’0.644
(0.126)
âˆ’0.118
(0.364)
âˆ’0.12
(0.12)

âˆ’0.089
(0.693)
âˆ’0.237
(0.278)
âˆ’0.354
(0.528)
âˆ’0.117
(0.619)
âˆ’0.136
(0.27)
âˆ’0.137
(0.117)

âˆ’0.061
(0.812)
âˆ’0.376
(0.162)
âˆ’0.195
(0.548)
âˆ’0.061
(0.817)
âˆ’0.134
(0.174)
âˆ’0.147
(0.237)

0.135
(0.692)
âˆ’0.436âˆ—
(0.057)
âˆ’0.377
(0.294)
0.016
(0.955)
âˆ’0.065
(0.499)
âˆ’0.052
(0.488)

âˆ’0.056
(0.931)
âˆ’0.202
(0.35)
âˆ’0.204
(0.563)
âˆ’0.249
(0.664)
âˆ’0.097
(0.424)
âˆ’0.07
(0.438)

0.35
(0.208)
âˆ’0.498âˆ—âˆ—âˆ—
(0.002)
âˆ’0.778âˆ—
(0.081)
0.019
(0.961)
âˆ’0.034
(0.762)
âˆ’0.118
(0.431)

Notes:
*p<0.1; **p<0.05; ***p<0.01. Estimate presented is moment computed on appliers less that
computed on non-appliers, expressed as a percentage of applier moment. Bootstrap p-values in parentheses
computed against the null hypothesis of no difference between moment for appliers and non-appliers. For
each outcome, expected benefit (EB) is the predicted treatment effect of SYEP given student covariates and
the 2SLS estimates of heterogeneous treatment effects by student covariates. Bootstrap standard errors are
calculated with 1000 bootstrap iterations, block clustered at the student level. Bootstrap p-values for LATE,
mean, and quantiles computed for a two-sided test, and bootstrap p-values for difference in select quantiles
computed for a one-sided test.

23

Table A10a: 90th-10th EB Quantile Differential in Mean Covariates (Appliers)

Age
Asian
Black
ESL Not LEP
Female
Free Lunch
Hispanic
LEP
Red Lunch
Spec Ed
Zmath
Zread

Any Attempt

N. Attempts

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

0.189
(0)
0.199âˆ—âˆ—âˆ—
(0)
âˆ’0.614âˆ—âˆ—âˆ—
(0)
âˆ’0.041âˆ—âˆ—âˆ—
(0)
0.454âˆ—âˆ—âˆ—
(0)
âˆ’0.009
(0.144)
0.319âˆ—âˆ—âˆ—
(0)
âˆ’0.029âˆ—âˆ—âˆ—
(0)
0.128âˆ—âˆ—âˆ—
(0)
0.12âˆ—âˆ—âˆ—
(0)
0.91âˆ—âˆ—âˆ—
(0)
2.497âˆ—âˆ—âˆ—
(0)

0.364
(0)
0.193âˆ—âˆ—âˆ—
(0)
âˆ’0.406âˆ—âˆ—âˆ—
(0)
0.016âˆ—âˆ—âˆ—
(0)
0.634âˆ—âˆ—âˆ—
(0)
âˆ’0.265âˆ—âˆ—âˆ—
(0)
0.118âˆ—âˆ—âˆ—
(0)
âˆ’0.046âˆ—âˆ—âˆ—
(0)
0.003
(0.452)
âˆ’0.004
(0.222)
2.075âˆ—âˆ—âˆ—
(0)
2.611âˆ—âˆ—âˆ—
(0)

Any Pass 65
âˆ—âˆ—âˆ—

âˆ’0.645
(0)
0.034âˆ—âˆ—âˆ—
(0)
âˆ’0.486âˆ—âˆ—âˆ—
(0)
âˆ’0.007âˆ—âˆ—âˆ—
(0)
0.278âˆ—âˆ—âˆ—
(0)
âˆ’0.016âˆ—âˆ—âˆ—
(0.01)
0.276âˆ—âˆ—âˆ—
(0)
âˆ’0.253âˆ—âˆ—âˆ—
(0)
âˆ’0.122âˆ—âˆ—âˆ—
(0)
0.561âˆ—âˆ—âˆ—
(0)
1.052âˆ—âˆ—âˆ—
(0)
1.776âˆ—âˆ—âˆ—
(0)

N. Pass 55
âˆ—âˆ—âˆ—

0.685
(0)
âˆ’0.004
(0.346)
âˆ’0.43âˆ—âˆ—âˆ—
(0)
0.135âˆ—âˆ—âˆ—
(0)
0.7âˆ—âˆ—âˆ—
(0)
âˆ’0.193âˆ—âˆ—âˆ—
(0)
0.419âˆ—âˆ—âˆ—
(0)
âˆ’0.155âˆ—âˆ—âˆ—
(0)
âˆ’0.187âˆ—âˆ—âˆ—
(0)
0.257âˆ—âˆ—âˆ—
(0)
1.358âˆ—âˆ—âˆ—
(0)
1.801âˆ—âˆ—âˆ—
(0)

N. Pass 65
âˆ—âˆ—âˆ—

0.276
(0)
âˆ’0.007âˆ—
(0.074)
âˆ’0.463âˆ—âˆ—âˆ—
(0)
0.083âˆ—âˆ—âˆ—
(0)
0.563âˆ—âˆ—âˆ—
(0)
âˆ’0.175âˆ—âˆ—âˆ—
(0)
0.501âˆ—âˆ—âˆ—
(0)
âˆ’0.245âˆ—âˆ—âˆ—
(0)
âˆ’0.134âˆ—âˆ—âˆ—
(0)
0.27âˆ—âˆ—âˆ—
(0)
1.203âˆ—âˆ—âˆ—
(0)
1.947âˆ—âˆ—âˆ—
(0)

N. Pass 75
âˆ—âˆ—âˆ—

0.337
(0)
0.035âˆ—âˆ—âˆ—
(0)
âˆ’0.534âˆ—âˆ—âˆ—
(0)
âˆ’0.091âˆ—âˆ—âˆ—
(0)
0.433âˆ—âˆ—âˆ—
(0)
0.012âˆ—
(0.091)
0.588âˆ—âˆ—âˆ—
(0)
âˆ’0.085âˆ—âˆ—âˆ—
(0)
0.389âˆ—âˆ—âˆ—
(0)
0.044âˆ—âˆ—âˆ—
(0)
0.049âˆ—âˆ—âˆ—
(0)
1.626âˆ—âˆ—âˆ—
(0)

ZScore
âˆ’0.525âˆ—âˆ—âˆ—
(0)
âˆ’0.384âˆ—âˆ—âˆ—
(0)
0.04âˆ—âˆ—âˆ—
(0)
0.127âˆ—âˆ—âˆ—
(0)
âˆ’0.205âˆ—âˆ—âˆ—
(0)
0.02âˆ—âˆ—âˆ—
(0)
0.324âˆ—âˆ—âˆ—
(0)
âˆ’0.27âˆ—âˆ—âˆ—
(0)
âˆ’0.109âˆ—âˆ—âˆ—
(0)
0.781âˆ—âˆ—âˆ—
(0)
âˆ’1.525âˆ—âˆ—âˆ—
(0)
âˆ’1.686âˆ—âˆ—âˆ—
(0)

Notes:
*p<0.1; **p<0.05; ***p<0.01. Displayed are differences in mean covariates between between top
and bottom deciles of expected benefit: E[X | EB quantile=90, outcome=Y]-E[X | EB quantile=10, outcome=Y].
(P-values for t-test of equality of means displayed. Appliers only.)

24

Table A10b: 90th-10th EB Quantile Differential in Mean Covariates (Non-Appliers)

Age
Asian
Black
ESL Not LEP
Female
Free Lunch
Hispanic
LEP
Red Lunch
Spec Ed
Zmath
Zread

Any Attempt

N. Attempts

âˆ—âˆ—âˆ—

âˆ—âˆ—âˆ—

0.152
(0)
0.129âˆ—âˆ—âˆ—
(0)
âˆ’0.521âˆ—âˆ—âˆ—
(0)
âˆ’0.099âˆ—âˆ—âˆ—
(0)
0.417âˆ—âˆ—âˆ—
(0)
âˆ’0.121âˆ—âˆ—âˆ—
(0)
0.111âˆ—âˆ—âˆ—
(0)
âˆ’0.092âˆ—âˆ—âˆ—
(0)
0.123âˆ—âˆ—âˆ—
(0)
0.093âˆ—âˆ—âˆ—
(0)
0.926âˆ—âˆ—âˆ—
(0)
2.798âˆ—âˆ—âˆ—
(0)

0.661
(0)
0.089âˆ—âˆ—âˆ—
(0)
âˆ’0.38âˆ—âˆ—âˆ—
(0)
0.046âˆ—âˆ—âˆ—
(0)
0.582âˆ—âˆ—âˆ—
(0)
âˆ’0.444âˆ—âˆ—âˆ—
(0)
âˆ’0.024âˆ—âˆ—âˆ—
(0)
âˆ’0.124âˆ—âˆ—âˆ—
(0)
âˆ’0.009âˆ—âˆ—âˆ—
(0)
0.006âˆ—âˆ—âˆ—
(0)
2.16âˆ—âˆ—âˆ—
(0)
2.856âˆ—âˆ—âˆ—
(0)

Any Pass 65
âˆ—âˆ—âˆ—

âˆ’1.318
(0)
âˆ’0.142âˆ—âˆ—âˆ—
(0)
âˆ’0.331âˆ—âˆ—âˆ—
(0)
âˆ’0.026âˆ—âˆ—âˆ—
(0)
0.267âˆ—âˆ—âˆ—
(0)
âˆ’0.298âˆ—âˆ—âˆ—
(0)
âˆ’0.033âˆ—âˆ—âˆ—
(0)
âˆ’0.604âˆ—âˆ—âˆ—
(0)
âˆ’0.069âˆ—âˆ—âˆ—
(0)
0.393âˆ—âˆ—âˆ—
(0)
1.448âˆ—âˆ—âˆ—
(0)
2.464âˆ—âˆ—âˆ—
(0)

N. Pass 55
âˆ—âˆ—âˆ—

1.38
(0)
âˆ’0.141âˆ—âˆ—âˆ—
(0)
âˆ’0.242âˆ—âˆ—âˆ—
(0)
0.378âˆ—âˆ—âˆ—
(0)
0.565âˆ—âˆ—âˆ—
(0)
âˆ’0.231âˆ—âˆ—âˆ—
(0)
0.346âˆ—âˆ—âˆ—
(0)
âˆ’0.437âˆ—âˆ—âˆ—
(0)
âˆ’0.164âˆ—âˆ—âˆ—
(0)
0.174âˆ—âˆ—âˆ—
(0)
1.372âˆ—âˆ—âˆ—
(0)
2.13âˆ—âˆ—âˆ—
(0)

N. Pass 65
âˆ—âˆ—âˆ—

0.524
(0)
âˆ’0.144âˆ—âˆ—âˆ—
(0)
âˆ’0.173âˆ—âˆ—âˆ—
(0)
0.208âˆ—âˆ—âˆ—
(0)
0.488âˆ—âˆ—âˆ—
(0)
âˆ’0.272âˆ—âˆ—âˆ—
(0)
0.382âˆ—âˆ—âˆ—
(0)
âˆ’0.615âˆ—âˆ—âˆ—
(0)
âˆ’0.095âˆ—âˆ—âˆ—
(0)
0.214âˆ—âˆ—âˆ—
(0)
1.178âˆ—âˆ—âˆ—
(0)
2.364âˆ—âˆ—âˆ—
(0)

N. Pass 75
âˆ—âˆ—âˆ—

1.014
(0)
âˆ’0.03âˆ—âˆ—âˆ—
(0)
âˆ’0.233âˆ—âˆ—âˆ—
(0)
âˆ’0.208âˆ—âˆ—âˆ—
(0)
0.405âˆ—âˆ—âˆ—
(0)
0.031âˆ—âˆ—âˆ—
(0)
0.578âˆ—âˆ—âˆ—
(0)
âˆ’0.173âˆ—âˆ—âˆ—
(0)
0.373âˆ—âˆ—âˆ—
(0)
0.039âˆ—âˆ—âˆ—
(0)
âˆ’0.247âˆ—âˆ—âˆ—
(0)
1.606âˆ—âˆ—âˆ—
(0)

ZScore
âˆ’0.954âˆ—âˆ—âˆ—
(0)
âˆ’0.4âˆ—âˆ—âˆ—
(0)
0.01âˆ—âˆ—âˆ—
(0)
0.373âˆ—âˆ—âˆ—
(0)
âˆ’0.11âˆ—âˆ—âˆ—
(0)
âˆ’0.05âˆ—âˆ—âˆ—
(0)
0.326âˆ—âˆ—âˆ—
(0)
âˆ’0.64âˆ—âˆ—âˆ—
(0)
âˆ’0.049âˆ—âˆ—âˆ—
(0)
0.545âˆ—âˆ—âˆ—
(0)
âˆ’0.314âˆ—âˆ—âˆ—
(0)
âˆ’0.485âˆ—âˆ—âˆ—
(0)

Notes:
*p<0.1; **p<0.05; ***p<0.01. Displayed are differences in mean covariates between between top
and bottom deciles of expected benefit: E[X | EB quantile=90, outcome=Y]-E[X | EB quantile=10, outcome=Y].
(P-values for t-test of equality of means displayed. Non-appliers only.)

25

Table A11: Joint Test of Zero Treatment Effect on Outcomes 1-6
Full Sample
F-Stat
P-Value

2.73
0.01

Group 1
1.32
0.24

Group 2
2.51
0.02

Group 3
1.10
0.36

Notes: For each group, statistics generated from F-test of joint restriction that treatment
effect is zero for all outcomes other than average Z-score. Average Z-score is omitted
as students who attempt no exams have no defined average score. Group 1 consists
of all first-time applicants in years 2006-2008. Group 2 is all students who applied for
the second time in 2006-2008 and had applied, won, and participated in the prior year.
Group 3 is all students who applied for the third time in 2006-2008 and had applied,
won, and participated in each of the two years prior. Full Sample is identical to that
analyzed in Tables 6-7.

26

