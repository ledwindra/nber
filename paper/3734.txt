NBER WORKING PAPERS SERIES

DYNAMIC (S,s) ECONOMIES

Ricardo J. Caballero
Eduardo M.R.A. Engel

Working Paper No. 3734

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 1991

This paper is part of NEER's research program in Economic
Fluctuations. Any opinions expressed are those of the authors
and not those of the National Bureau of Economic Research.

NBER Working Paper #3734
June 1991

DYNAMIC (S,s) ECONOMIES

ABSTRACT

In

this paper we provide a framework to study the aggregate
dynamic behavior of an economy where individual units follow (S.

s) policies. We characterize structural and stochastic
heterogeneities that ensure convergence of the economy's
aggregate to that of its frictionless counterpart, determine the
speed at which convergence takes place, and describe the
transitional dynamics of this economy. In particular, we
consider a dynamic economy where agents differ in their initial
positions within their bands and face both stochastic and
structural heterogeneity; where the former refers to the presence
of (unit specific) idiosyncratic shocks, and the latter to
differences in the widths of units' (S,s) bands and their
response to aggregate shocks. We study the evolution of the
economy's aggregate and the evolution of the difference between
this aggregate and that of an economy without macroeconomic
friction, where the latter pertains to a situation where
individual units adjust with no delay to all shocks. We also

examine the sensitivity of this difference to conmion shocks. For
example, in the retail inventory problem the aggregate deviation
and sensitivity to common shocks correspond to the aggregate
inventory level and its sensitivity to aggregate demand shocks,
respectively.

Ricardo J. Caballero
Department of Economics
Columbia University
New York, NY 10027
and
NEER

Eduardo.M.R.A. Engel
Department of Economics
M.I.T.
Cambridge, MA 02139

1 INTRODUCTION
In recent years there has been a surge in the application of formal microecononhic
models of discontinuous and lumpy adjustment —originally developed in the early 50's

for retail inventories— to a variety of topics in economics, such as cash balances, labor
demand, investment, entry and exit, prices, durable goods and technology upgrade. Yet the
possibility of explaining aggregate economic phenomena based on these models has remained

largely unexplored, primarily because of the technical difficulties involved. Since aggregate
data do not look as discontinuous and lumpy as their microeconomic counterparts, in order

to apply these models to macroeconomic data aggregation has to be modeled explicitly.
This is hard to do when shocks are not purely idiosyncratic but also have a common (or,
equivalently, aggregate) component. The few results existent in the literature have provided

important insights, but have been limited either to numerical simulations (Blinder 1981)

or to steady state analysis (Caplin 1985, Caplin and Spulber 1987).2 This paper's main
contribution is to provide a framework within which the out—of—steady—state aggregate
dynamics of an economy with lumpy adjustment at the microeconomic level can be studied
analytically.

We simplify the mathematics substantially by only considering a particular, but widely

used, adjustment policy: the one sided (S,s) rule. In the last section we argue that many
of this paper's insights either carry over directly to more general forms of adjustment rules

or provide the natural foundation for their study.
One of the appealing characteristics of (S, i) rules is their simplicity: an individual agent
allows his state variable (e.g. inventories) to fall freely until it reaches a certain critical level

s; at this point abrupt action takes place and the state variable is reset to an upper value S
from where the cycle starts again. Examples where the optiinality of fixed (S,s) rules has
been established go back to the problem of inventories management (Scarf, 1959); a more
recent example is price setting in the presence of menu—costs (Sheshinski and Weiss, 1983;

Caplin and Sheshinski, 1987). Moreover, the fixed (S,s) model has also been extensively
used in the Operations Research and Economics literatures as an approximation for more
complex optimal rules (e.g. Arrow, harris and Marschal, 1951; Karlin and Fabens, 1959;
I

Blinder, 1981; Ehrhardt, Schultz and Wagner, 1981; Blanchard and Fischer, 1989, p.405).
Whenever microeconomic units adjust discretely and by large amounts, the issue of heterogeneity acquires high priority. The similarity between the economy's aggregate patti and
the discontinuous and lumpy path of microeconomic units grows with the degree of synchro-

nization of units' actions. In the limit, when all units are identical and act simultaneously

(the symmetric equilibria assumption), the aggregate path is indistinguishable from that
of an individual unit. On the other hand, if units' actions exhibit little synchronization,

the aggregate may depart substantially from the behavior of any single (representative)
unit. The framework developed in this paper addresses precisely the process of endogenous

synchronization and staggering of individual units, and studies the aggregate implications
of such phenomena.
We consider a dynamic economy where agents differ in their initial positions within their

bands and face both stochastic and struclural heterogeneity; where the former refers to the

presence of (unit specific) idiosyncratic shocks, and the latter to differences in the widths
of units' (5, s) bands and their response to aggregate shocks. We study the evolution of the
economy's aggregate and the evolution of the difference between this aggregate and that of
an economy without microeconomic friction, where the latter pertains to a situation where

individual units adjust with no delay to all shocks. We also examine the sensitivity of this

difference to common shocks. For example, in the retail inventory problem the aggregate
deviation and sensitivity to common shocks correspond to the aggregate inventory level and

its sensitivity to aggregate demand shocks, respectively.

In Section 2 we determine conditions under which the inicroeconomic effect of lumpy

adjustment rules has no aggregate impact. Section 3 begins the study of the economy's
aggregate (out—of--steady--state) dynamics by discussing the summary variables we use to

describe the economy over time. In Section 4 we consider the effect of stochastic heterogeneity on the economy's dynamic aggregate behavior when no structural differences

are present. We show that the economy's aggregate converges to that of its counterpart
without friction when idiosyncratic shocks spread out without bound over time, and that
the speed of convergence increases with the rate at which dispersion occurs; we also show
that common shocks play no role in aiding convergence. Structural heterogeneity is incor-

porated into the analysis in Section 5; we show that it can lead to convergence by itself,
that the speed ofconvergence grows with the degree of structural heterogeneity, and that
common shocks aid convergence when structural differences are present. Section 6 shows
2

that, paradoxically, the interaction between both krms of heterogeneity may actually slow
down convergence. Section 7 presents final remarks. An extensive appendix follows.

2 BASIC MODEL AND STEADY STATE
We consider an economy composed of a large number of units, and approximate this

large number by a continuum, indexed by i E [0, 1]. We let z) denote the difference
between x(i), the actual value of unit I'S state variable at time i when an (S, s) policy is
followed, and x(t), the value of the same variable if there was no friction. For example,
consider the retail inventory problem, where firms decide on their optimal inventory holding

in the presence of uncertain demand and fixed replenishment costs. In this case z'(t) and

are accumulated sales and accumulated inventory orders, and z1() is the level of
inventories.

We express every frictionless (optimal) variable, x(t), as the sum of an idiosyncratic

component, v(t), and the unit's response to an aggregate shock a(t) fx(t)di:

x(t) = Oa() + v,(t),

(1)

where 9 is unit i's sensitivity to the common shock.3 For example, in the retail inventory
problem da(t) denotes aggregate demand shocks and 6 the sensitivity of sector i's demand

to these shocks. We normalize the sensitivity parameters so that f 9 di = 1; this implies

that by construction f v,(i) di = 0 for all t.
We assume that, for each unit i, z(t) decreases monotonically and continuously until
it reaches the unit specific trigger barrier, sj; at this point finite control is exerted on x to
bring zj back to the unit specific target barrier S1.4
ASSUMPTION 1 . SationariLy, symmeirij, monotonicity and continuity.

1. The variable zj(t) is controlled according to a stationary, fixed band, one sided, unit
specific (5, a) policy.

2. The (S,s) rules are symmetric: S1 =
3. The variable z1(t) decreases monotonically during time periods where no control is

exerted.6

4. The sample paths of v(t) are continuous and those of a(t) are continuous, increasing

3

and unbounded.

This framework can accommodate many well known problems, apart from the retail
inventory problem mentioned above. A few of them are:

• The Pricing Problem, where firms pay a menu—cost when they adjust their nominal

prices. In this case x(t) is the frictionless optimal price and x() the actual price
charged.

• The Cash—Balance Problem, where consumers decide on the optimal level of cash

holdings when adjusting their cash—balances is costly. In this case, x(t) and z,()
are accumulated expenditures and accumulated withdrawals, and z-(t) is the current
cash balance.

• The Technology Update Problem, where firms decide on whether to scrap their current

machines and update them or not. In this case, x(i) and x1(i) are desired and actual
state of technology, and z1(t) is the gap between them.

• The Durable Goods Problem, where consumers decide when to buy a durable good

and adjusting the stock they have is costly. In this case, z(t) and x(i) are desired
and actual levels of the stock of durable goods, and z1(i) is the gap between them. In
this problem, the sensitivity parameters could correspond to the marginal propensities
to consume.

• The Capital Stock Adjustment Problem, where firms decide when to adjust their
capital stock when there are non—convex costs of adjustment. In this case, x(i) and
are desired and actual levels of the stock of capital, and z1(t) is the gap between
themY

The main goal of this paper is to examine the behavior of the variable we call "the

aggregate," defined as the integral of the z,()'s over all i's and denoted by X(i). Using
the definition of the z)'s, and letting Z() fJ z,() di, leads to the following expression
for X(i):

X(t) = a(s) + Z(t).

(2)

When there isno microeconomic friction, all the z's are identically zero, thus X() =

X(i) = a(s).

As we are interested the effects of microeconomic (S,s) policies on the
4

departure of X(t) from X(t),

we

focus on the mean of the cross—section distribution of

individual departures, Z(t).8 The entire analysis carried out in this paper —in particular the
computation of the latter mean— is conditional on the actual path of the aggregate shock

a(t). It turns out that the results we derive do not depend on any particular features of
this path, as long as a(t) is continuous, increasing and tends to infinity (see Assumption 1).
We therefore do not need to specify the stochastic mechanism underlying common shocks.
The fact that we consider the dynamic path of the actual cross—section distribution —and

not that of the joint distribution of all units— in spite of the presence of aggregate shocks,

is one of the building blocks of the methodology we develop in this paper. Its usefulness
is best appreciated when we consider convergence issues in Sections 4 and 5. We therefore

postpone discussing its importance until the final section.

Instead of working directly with z(t), it is notationally convenient to describe the
problem in terms of the fraction unit i has covered of its (S,s) band at time t, c,(t). We
therefore define:

c(i)—,

(3)

S — 8 denotes unit i's bandwith. The variable 4(t) takes values in [0, 1); it
starts its cycle when cQ) = 0 (i.e. when z1(t) = S) and ends it when c,(t) reaches one (i.e.
when zj(t) reaches s,). Substituting z1(t) — x'(t) for z,(t) in (3) yields:
where A,

=

(!

—

x5(t) — z(1)
A1

Substituting x(t) by (1), adding and subtracting cj(0), and noting that (x1(t) — x1(0))/A,

is always an integer, yields:

(4)

4(t) = (c(o) + 01a(t)+ vi(i)) (mod 1),

where z (mod 1) denotes the difference between the real number x and its integer part and
we set a(0) and v1(O) equal to zero without loss of generality.
We let Ct, Vj, 0 and A denote random variables with a joint probability distribution

identical to that of the joint cross—section distribution of the c1(i)'s, the v,(t)'s, the O,'s and
the A1's.9 Thus, we have that:
(5)

=(

+ e(t)-1- V) (mod 1).
5

An expression for the aggregate deviation, Z(t), can be obtained directly in terms of the
variables we defined above. All that is needed to determine Z(t) is the value of the current
aggregate shock, a(t), and the cross—section distribution of the random vector (co,vj,A,O).
PRoPosITIoN 1

Suppose assumption 1 holds. Then Z(i) = g(a(t),i) and X(t) = a(t) +

g(a(t),t), where

g(a,t)

E(A)—E[A{(co+ °)(mod1)}]

Paoop: Follows directly from equations (3), (4) and (5). •
The intermittent and lumpy microeconoinic behavior is irrelevant at the aggregate level

when —for any realization of the stochastic mechanism underlying aggregate and idiosyn-

cratic shocks— Z(t) remains constant over time. Without loss of generality we suppose
that the constant aggregate deviation is equal to zero in what follows.
DEFINITION 1

The aggregate deviation of an economy satisfying Assumption 1 is at its
steady state at time I = 0 if g(a,t) = 0 for all a a(0) 0 and all I 0, with g(a,t)
defined in Proposition 1.

Whether the economy's aggregate deviation is at its steady state or not depends on
the stochastic mechanism underlying the model. There are various sets of conditions under

which the aggregate deviation remains equal to zero as time passes. In this paper we
consider conditions that can be expressed only in terms of the cross—section distributions

defined above. In the following proposition —which is an extension of Proposition 1 in

Caballero and Engel (1989b)— we show that when units' initial positions within their
cycle are distributed uniformly on [0, 1) and independent from the remaining sources of
heterogeneity, the economy's aggregate deviation is at its steady state.

PRoposiTioN 2 (Caballero and Engel, 1989b) Given Assumption I, the economy's aggregate deviation is at its steady state at time I = 0 if c0 is uniform on [0,1) and independent

from A, 0 and vg for all 1> 0. Furthermore, cg is uniform on [0,1) for all t > 0.
This result shows that when units' positions within their cycle are independent from the
sources of structural and stochastic heterogeneity, there exists a cross—section (or empirical)

distribution of the c's that is invariant under continuous, monotone, aggregate shocks.
6

This distribution is uniform. It follows —from equation (3)— that there also exists a
cross—section distribution of the z's that is invariant under the same class of shocks. This

distribution is determined by the probability distribution of A; it is uniform only when
bandwidths do not vary across units.
Proposition 2 presents an economy with strong forms of microeconomic rigidity that has

an aggregate behavior indistinguishable from that of an economy without friction. This is a
generalization of the insightful result in Caplin and Spulber (1987). They consider the case
where all units have the same bandwidth, no idiosyncratic shocks are present, and common

shocks have the same impact on all units' z7(t)'s. None of these conditions are required for

Proposition 2 to hold. In addition, the scenario described in Proposition 2 has a realistic

feature that is absent in an economy without structural or stochastic heterogeneity: the
relative positions of units within their cycle changes over time. The order in which units
adjust their state variable does not repeat itself from one cycle to another.
Proposition 2 assumes that the initial cross—section distribution of the 4's is independent

from the joint distribution of idiosyncratic shocks, bandwidths and sensitivity parameters.

If this is not the case, the cross-section distribution of the 4's generally does not remain
uniform on [0,1) and the aggregate deviation, Z(t), does not remain constant. This happens, for example, when units with smaller bandwidths —or larger sensitivity parameters—

are initially concentrated at the beginning of their cyde, as is further illustrated in Section
5.

3

DESCRIPTION OF NON—STEADY—STATE DYNAMICS

There are many reasons why Assumption 1 may be momentarily violated and the (5, s)

economy's aggregate deviation be forced away from the steady state described in Proposi-

tion 2. For example, in the case of the pricing problem, a finite (discrete) change in a(i),
like an oil shock or a large monetary shock, bunches a fraction of units at the beginning of

their cycle. Alternatively, a widening of units' bands —due, for example, to an increase in
the rate of core inflation in an economy where bands are set optimally— leaves a fraction
of the new state space initially with no units. In the time period following any one of these

"structural changes," the aggregate deviation ypicaUy does not remain constant and the
economy therefore is not at its steady state anymore.
In the following three sections we study the dynamic behavior of the economy outside of

its steady state. We consider idiosyncratic shocks and structural heterogeneity as possible
7

sources of convergence; the latter meaning differences in bandwidths and sensitivity parameters. For expository simplicity, we study the effects of these factors separately before
considering their interaction.

Proposition 1 characterizes the dynamic path of the difference of the aggregates from
economies with and without frictions. For example, it can he used to determine the evolution of the average level of inventories after an oil shock. Yet we may not only be interested

in the level of aggregate inventories at a given point in time, but also in the potential im-

pact of a small aggregate demand shock on this aggregate. This impact on Z(t) is equal
to the (partial) derivative of the function g —defined in Proposition 1— with respect. to a,

evaluated at (a(i), t). We denote this derivative by J(t)

Og/i9a.

The relation between J(t) and the cross—section distribution of firms' positions within

their cycle is best understood if we look at the effect of a small common shock, 1a, on the

aggregate deviation, Z(t), when sensitivity parameters do not vary across units (0

1).

We begin with the units that are forced to start a new cyde. The common shock forces
a unit with bandwidth A to adjust only if it has covered a fraction larger or equal than
1—

(Aa/A) of its cycle before the shock. The fraction of units with bandwidth A that

reach their trigger point is proportional to Aa f(IA,A)(1)/A + O((ia)2),1° where fx(A)
denotes the density of the random variable X. Other things equal, this fraction is smaller
the larger the common bandwidth. This effect is exactly offset by the fact that Z(t) grows

more when a unit with a larger bandwidth restarts its cyde. Thus, the contribution to the
• aggregate deviation of those units that a.djust and have bandwidth equal to A is proportional

to 4a.f(C4A=A)(1 )fA(A); the total increase in Z(i) due to units reaching their trigger point

is then equal to a.ff(C11A)(1)fA(A)dA =

a.f4(r). Next we consider those units that

do not start a new cycle alter the aggregate shock. Every unit that does not adjust decreases

its contribution to Z(i) by ia; their total contribution is equal to La (minus a term of
order (ia)2 that accounts for the fact that not all units belong to the group that does not

start a new cycle). We have therefore shown that g/a is equal to f(1) — 1 + O(ta).
Letting a approach zero we conclude that J(t) = f1(1j — 1.
It is apparent from the previous paragraph and Proposition 1 that both J(t) and Z(t)
may be equal to zero even when the economy's aggregate deviation is "far away" from its

steady state. On the one hand, J() is equal to zero every time f(1) is equal to one;1' on
the other hand, Proposition 1 implies that Z(t) = 0 every time fA E(c A = A)fA(A) dA = 0.

Therefore Z(t) = 0 whenever the weighted average of the "sectoral" aggregates is equal to

8

zero; where the latter are defined as the aggregates conditional on a common bandwidth.
Since these sectoral aggregates may evolve in rather arbitrary ways, there is no reason why

their average should remain equal to zero in the future.
It is tempting to argue, based on Proposition 2, that the economy's aggregate deviation

is at its steady state every time the cr061—section distribution of units within their cycle,

c, is uniform on [0,1). This intuition is supported by the fact that Z(t) = E{A( — c)}
is equal to zero when c is uniform on [0,1) and independent form A. Yet this argument is

not correct, since c is generally not independent from A. For example, consider the case
where a fraction of units is bunched at the beginning of their cycle after the economy is

perturbed away from its steady state. Other things equal, units with larger bandwidths
move a smaller fraction of their cyde in a given period of time, so that the correlation
between A and c is negative in the time period following the perturbation. We conclude
that although Z(t), J(t) and the shape of the cross—section distribution of units positions
within their cycle are interesting summary variables of the economy's aggregate deviation

at any particular instant in time, neither of them has the property of capturing how much

the economy's aggregate behavior differs from that of its counterpart without frictions.
Next we consider two indices that do have this property:

E SUP(a>a(t),a>f} g(a,s)
and

J(t) E
The definition of these indices is now illustrated by describing how one of them, Z(t), is
evaluated at a given instant in time, to. Suppose that accumulated common shocks at time

to are equal to o• Consider all possible future paths of the aggregate shock, {a(s), s

that satisfy Assumption 1 and have a(io) = ao, and calculate the maximum (absolute)
aggregate deviation for every one of them. The index Z(t) then is equal to the largest
among these maxima. The aggregate deviation and its sensitivity to small aggregate shocks

have (absolute) values that are bounded from above by Z(i) and J) for any future
trajectory of the common shock that satisfies Assumption j•12
Once

the economy's aggregate deviation departs from the steady state, it typically
never exactly retuTas there. There usually is no instant in time at which the economy's
aggregate deviation has actually reached its steady state again (in the sense of Definition 1).

9

This implies that there always exists the possibility that the aggregate deviation's sensitivity

to common shocks, J(t), be relatively large at some instants in time, even if Z(i) converges

to zero. The aggregate effect of microeconomic frictions is not being washed away in this

case. This justifies requiring that J"(i) also tends to zero for microeconomic frictions
to become irrelevant at the macroeconomic level. Motivated by the discussion above we
define "convergence of the economy

aggregate to that of its cotAnterpart with no friction"

as follows:

DEFINITIoN 2 The aggregate of an economy that satisfies Assumption 1 convergc8 to that

of its frictionless counterpart if Z(t) and J(*) tend to zero as t tends to infinity.13

In sum, we describe the dynamic behavior of an (S,s) economy using four summary
variables. We look at the economy's aggregate deviation from the frictionless counterpart,

at the sensitivity of this index to common shocks, and at the suprema of these indices over
all possible realizations of the underlying stochastic mechanism.

4

CONVERGENCE AND IDIOSYNCRATIC SHOCKS

4.1

CONVERGENCE

In this section we isolate stochastic heterogeneity as the only source of convergence

by assuming that all uiijts have the same bandwidth )j
parameters (e E 1).

)) and

the same sensitivity

There are many ways in which the economy's aggregate may converge to that of its
frictionless counterpart. For example, convergence takes place if idiosyncratic shocks are
correlated with Co in such a way that they exactly ll in the gaps between the density of c
and a density uniform on [0,1) in finite time and, after this happens, become independent
of units' positions within their cyde so that ct remains uniform on [0,1) (see Proposition 2).
This way of achieving convergence is rather far—fetched; there exist other scenarios where
convergence takes place that are even more arbitrary. In this section we consider conditions
that ensure convergence when there is no systematic relation between CO and the realizations

of the idiosyncratic shocks.
ASSUMPTION 2

Independence. The random variables c0 and Vt are independent for all
t > 0, or, equivalently, dv is independent from c, for all a

10

Under the independence assumption, convergence is not achieved by filling in the gaps in

finite time, but by making initial conditions irrelevant as time passes. This happens when
the cross—section distribution of idiosyncratic shocks, V, folded back into the unit interval,

converges to a distribution uniform on [0,1) and thereby "washes away" the initial cross—

section distribution of units' positions within their cycle. An example is useful at this
point. Suppose that the process generating any unit's idiosyncratic shocks, (v1(t), t 0), is
Gaussian with variance ti2(t) growing as time passes. Since these processes are independent
across units, the cross—section distribution of idiosyncratic shocks, vt, also is normal and has

the same variance. This follows from the Glivenko—Cantelli Theorem, see e.g. Billlngsley

(1986). Figure la illustrates how the cross—section density of idiosyncratic shocks flattens
out; the corresponding evolution of the density of Cg is illustrated in Figure lb —where we
have abstracted from the value of the common shock a(t)— for the case where Co is a spike

at 0.5. Since the expected value of c approaches one half, Z(t) tends to zero, and since the
cross—section density of Cj is approaching one, J(t) = f(P)—1 tends to zero. Furthermore,

since bandwidths and sensitivity parameters are the same across units, aggregate shocks do
not act as a unit separating mechanism, all they do is move units around their cycle. Figure
lc illustrates this by showing how the density of ct varies for different values of the common

shock at a fixed instant in time (t=1.0). It follows that Z(t) and J(t) both tend to zero.
Thus Figure 1 suggests that all summary variables converge to zero when the cross—section

density of idiosyncratic shocks flattens out as time passes. This assumes that densities are
unirnodal, or at least that they do not oscillate too much. The following assumption makes
these intuitive conditions on the density of the vg's precise.
ASSUMPTION 3 Flattening out of densities. The total variation of the density of Vt tends

to zero as t tends to infinity.'4
Assumption 3 holds when the density of Vt IS uthmodal and its largest value tends to
zero as i tends to infinity. Two situations where this happens are when the Vt'S are normal

and their variance tends to infinity, and when the Vt'S are absolutely continuous and have
independent increments or, more generally, are an integrated process. "l'he proposition that
follows provides general conditions under which convergence occurs.
PROPOSITION 3

Suppose idiosyncratic shocks and differences in units' initial positions

within their cycle are the only sourtes of heterogeneity and Assumptions 1- 3 hold. Then the
11

economy's aggregate converges to that of its counterpart without friction and Cg converges
to a distribution uniform on [0,1).

PROOF: See the appendix. I
The assumptions of Proposition 3 are on the cross—section distribution of idiosyncratic

shocks, not on the processes generating individual units' shocks. Since we have a continuum of units, the Glivenko'—Cantelli Theorem (see Billingsley, 1986) provides a link between

assumptions on the v(i)'s and assumptions on vj. For example, if idiosyncratic shocks are
i.i.d. across units, then the cross—section distribution of idiosyncratic shocks is equal to the

probability distribution generating individual shocks. Another example is when the v,(t)'s
are of the form 7w,(t), with the w,(t)'s ii.d. across units and y a fixed, unit specific parameter (that could depend on Oj and A,). In this case Vg has the same probability distribution

as the product of the independent random variables F and Wt,where F corresponds to the
cross—section distribution 7,'S, and tv to the common distribution of w,(t)'s.

4.2 SPEED OF CONVERGENCE
Figure 1 suggests that convergence is faster when the variance of idiosyncratic shocks,

relative to the common bandwidth, is larger. It also shows that the speed at which the
economy's aggregate behavior approaches that of an economy with no friction —as mea-

sured by Z(t) and J(t)— does not depend on the sample path of the common shock a(t).
We illustrate these issues with an example.

Suppose the economy's aggregate deviation is at its steady state, when an increase in
the variance of shocks leads all units to increase their bandwidths by 50%, and that the new
idiosyncratic shocks follow a Brownian motion with instantaneous standard deviation equal

to 5%. From the symmetry assumption it follows that Co is uniform on [1/4,3/4). Figure
2a shows the resulting paths of the aggregate deviation Z(t) for two economies which only
differ in the realizations of the common shock, a(t). The explicit dependence of g(a(t), t) on

t (via v) is reflected in the dampening of the oscillations of the sample paths of Z(t). The
dependence of g on a(t) determines the speed at which the actual sample paths oscillate; the

number of oscillations grows with the speed at which common shocks accumulate. Figure

2b illustrates the corresponding paths of J(i).
The convergence mechanism we consider in this section ensures that the cross—section

distribution of units' positions within their cycle converges to a distribution U uniform
12

on [0, 1). It is therefore not surprising that the summary variables Z() and J(t) are
closely related to particular notions of distance between c and U. Since the corresponding

relation for J) can be derived intuitively, we only consider this case. From our discussion

in Section 3, we have that J(t) is equal to f,(1) —

1.

The index J() is obtained by

maximizing Og/8a over all values of a a(t) and all values of s 1. Modifying the value of
a for a. fixed instant in time s rotates the density of c1 without affecting its shape; for this

see Figure ic and imagine joining both ends of the z-axis to form a circular diagram, as in

Caplin and Spulber (1987). It follows that sup I(a,s)I is equal to supa f,(a) — i. The
latter expression is the sup—distance between the densities of c and U, which we denote by

R(C., U). It is equal to the largest relative error made when approximating the distribution

of c by a distribution uniform on [0, i).' We therefore have that J(t) = 6Pa> R(c, U).
Figure lb indicates that it is quite likely that lt(c., U) decreases monotonically over time.
This is indeed true when the Vt'S have independent increments, as is shown in Proposition A4

in the Appendix. It then follows that J'(t) = R.(cg, U), that is, that the largest (percentage)

error made when approximating the probability of an event under c by the corresponding

probability under U is equal to the largest sensitivity of the aggregate deviation to small
common shocks over all possible future sample paths of a(t).

Figures 2c and 2d show the trajectories of Z) and J(t) that correspond to Figures

2a and 2b. These do not depend on the particular paths of a(t). It follows from the
formulas we derive for the summary statistics in the appendix that the speed of convergence

increases with the relative importance of idiosyncratic shocks compared with the common

bandwidth. For example, if in the experiment of Figure 2 x1() and z(i) are the logarithms
of economically meaningful variables and time is measured in years, then it takes about 18

years before J(t) is below 5 percent when c/A is equal to 0.1; if a/A is equal to 0.5 it takes
only about 9 months.16
In Proposition Al in the Appendix, we provide general expressions for the indices used

to construct these figures. They are all expressed in terms of the Fourier coefficients of Vj,

and show that, loosely speaking, the smaller the Fourier coefficients, the faster all indices
converge to zero. This can be understood in terms of the example given in Figure 1 above,

since Fourier coefficients measure how fast vt spreads out.17 Moreover, in the particular
case where idiosyncratic shocks have independent increments, all the indices converge to

zero at the same rate as Ikit, where k denotes the first non-trivial Fourier coefficient of
v1/A that differs from zero.38 Hence speed of convergence is faster, the smaller the first
13

non-trivial Fourier coefficient of v1/A. For example, when idiosyncratic shocks follow a

Brownian motion with instantaneous variance a2, we have that Ik = exp(—2r2c2/X2).
Since the variance of the random variable that is folded back into the unit interval (see
equation (4)) is (o-/A)2, it

is

not surprising that convergence is faster when this ratio is

larger.

5

CONVERGENCE AND STRUCTURAL HETEROGENEITY

Structural heterogeneity —namely, differences in bandwidths and sensitivity parameters—

a second source of convergence. It ensures convergence by itself, even if no idiosyncratic

is

uncertainty is present. It also adds various new features to the analysis of convergence and
speed of convergence. Most prominently, aggregate shocks stop being irrelevant —as was
the case in Section 4— and become the driving force behind convergence.

In this section we isolate structural heterogeneity as a source of convergence, by assuming that there are no idiosyncratic shocks. We consider both sources of convergence

simultaneously in Section 6. We find it convenient to study separately the cases where
differences in bandwidths and differences in sensitivity parameters are the only sources of
convergence. We begin with the former case.
5.1 HETEROGENEOUS BANDWIDTHS

When structural heterogeneity due to different bandwidths is present, equation (3) may

be used

to show that:

Z() =

(6)

J AIA(.A) { -. c(IA)} d),

where fAr') denotes the probability density of bandwidths and C(tIA) the average position

within their cycle of the "sector" of the economy formed by units with bandwidths equal

to X.
Equation

(6) shows that, as mentioned in Section 3, units with a larger bandwidth

have a larger weight when determining the deviation of the aggregate from its frictionless

counterpart.

the sector.

to
if

of the bandwidth and the size of

that the aggregate path of the economy may converge
frictionless counterpart in one of two ways. First, convergence takes place

This equation also shows

that of its

units

The weight is proportional to both the size

within

each

sector approach a distribution uniform on their common bandwidth.

Each sector then behaves as in a frictionless economy, and adding over all sectors shows that
14

the economy's aggregate mimics that of its frictionless counterpart Convergence occurs in

this way when the density of idiosyncratic shocks spread out without limit as time passes

(see Section 4). Yet convergence may take place even when the aggregate deviation of
units with the same bandwidth does not converge at all, but synchronization among the
aggregate deviations of different bandwidths breaks down over time. This is the case with
sufficient differences in bandwidths.

6.1.1

CONVERGENCE

We start our discussion of convergence by presenting an example where differences

in bandwidths are the only source of convergence. All Os's are the same, there are no
idiosyncratic shocks, and all units start off at the beginning of their cycle. We consider
a cross—section distribution of the inverse-bandwidths —the 1/.X's— that is uniform on

[10,20] and assume that the z's and x's are the logarithms of economically meaningful
variables. Bandwidths therefore vary between 5 and 10 percentage points. Since there
are no idiosyncratic shocks, and all units start off at the beginning of their cycle, we may
imagine that there is only one unit in each sector. The deviation of any given sector does
not approach zero; it exhibits cycles that do not dampen out over time.

As common shocks begin to accumulate, units with different bands move in a fully
synchronized manner within their bandwidths until they start completing their first cycle

(at t = 0.05). The times at which units complete their cycles vary because bandwidths
differ across units; this is the source of convergence in this example.

From equation (5) we have that c = (a(t)/A)(mod 1), therefore the distribution of cj is
uniform on 10,1) every time accumulated common shocks are equal to a multiple of 0.1. It
departs from this distribution after every visit, yet every time by less. A visit to the uniform

distribution is characterized by the fact that the correlation between units' positions within

their cycle and their bandwidths decreases when compared to the previous visit. Figures

3a and 3b show the paths of Z(t) and J(i). The discontinuities in J(i) are due to the fact
that the density of 1/A is not continuous at its endpoints. Modifying this density slightly

at these points would lead to the same qualitative behavior without jumps. The Figure
shows that the aggregate deviation, Z(), and its sensitivity to small common shocks, J(),
oscillate on their way to zero.

When there is no stochastic heterogeneity, both Z(t) and J(t) only depend on time
through the current value of c(s); g(a, t)

g(a) remains constant as t varies (see Propo15

sition 1). Hence the path of Z(t) = SUP,>) jg(a) and

J(t) = SUP>() Ig'(a) are both

equal to the envelopes of the sample path of Z(t) and J(t). Figures 3c and 3d show how
Z(t) and J(t) evolve over time. This example also serves to show that convergence may
take place even if units' initial positions within their cycles are highly correlated with their
bandwidths. Structural heterogeneity achieves convergence by breaking down the correlation between the aggregates of different sectors.

Consider any cross—section distribution of 1/A that has a sufficiently smooth density.
Partition the set of possible bandwidths into a finite number of intervals, and approximate
the cross—section distribution of bandwidths within each interval by a uniform distribution.

The argument given above applies to the sector composed of units with bandwidths in
any one interval; these units' aggregate deviation therefore converges. It follows that the

behavior of the entire economy's aggregate converges to that of its counterpart without
friction. This argument explains why, when differences in bandwidths is the only source of
heterogeneity, convergence takes place when the inverse of units' bandwidths have a smooth

density. Since our model has a continuum of units, this is a relatively weak assumption.
The previous argument is based on assuming that c0 is constant; it can be extended to
the case where c0 and A are not "perfectly" correlated by requiring that the density of 1/A,
conditional on any value of c0, be sufficiently smooth.
ASSUMPTION 4 . Smoothness

(1). The random variable A has finite expectation and the

density of 1/A, conditional on any value of c0, has bounded variation V(A co) such that

EV(A' Ico) is finite.
Below we provide a proposition generalizing and formalizing the insights of this example.

PROPoSITION 4 Suppose that differences in bandwidths and units' initial positions within

their cycle are the only source of heterogeneity, and that Assumptions I and 4 hold. Then
the economy's aggregate behavior converges to that of its counterpart with no friction and
ct converges to a distribution uniform on the interval [0, 1).

Paoor: See the Appendix. I
5.1.2

SPEED OF CONVERGENCE

The example above shows that the rate at which the common shock a(t) grows —which

is irrelevant in the case of only stochastic heterogeneity— is crucial when heterogeneity in
16

bandwidths is the only source of convergence. The mechanism that leads to convergence

in this case is not based upon spreading units out, but on having them move around their
cycles

at different speeds. This mixing effect grows with a(t).

The example above also shows that the distance between the cross—section distribu-

tion of units' positions within their cycle anda distribution uniform on

[0, 1) does not

decrease monotonically over time. Even though the distribution of units within their cycle

approaches a distribution uniform on 10,1), there are periods when units "catch up" with
each other and the distance between Cg and its limiting distribution increases. This differs
from what we saw in Section 4; since the distance between ct and a distribution uniform on
[0,1) decreases monotonically over time when stochastic heterogeneity is the only source of
convergence and idiosyncratic shocks have independent increments.

When there is no stochastic heterogeneity, Z*(t) and

J(t) depend on t only through

the value of a(t); it follows that the speed of convergence grows with the rate at which
aggregate shocks accumulate. It is shown in the Appendix that, under the assumptions of

Proposition 4, J(t) is bounded from above by k/a(t) for some constant k that depends
on how smooth the corresponding densities are. This bound cannot be improved upon,

it is sharp when the cross—section distribution of units' bandwidths within their cycle is

uniform.
5.2 HETEROGENEOUS SENSITIVITY PARAMETERS

When different sensitivity parameters are the only source of convergence, equation (3)
may be used to show that:

(7)

Z() = ) J

{ — C(iO)} fe(8)dO,

where fe(8) denotes the probability density of sensitivity parameters and C(iIO) the average

position within their cycle of the "sector" of the economy formed by units with sensitivity parameter equal to 0. As in the case with different bandwidths, when differences in
sensitivity parameters are the only source of heterogeneity, aggregate shocks achieve convergence by gradually eliminating the synchronization between sectoral aggregates instead
of by having every sectoral aggregate deviation converge.

When all bandwidths are the same (without loss of generality A

1) and there are no

idiosyncratic shocks, equation (5) implies that c = (c0 + a(i)e)(mod 1); hence cg converges
17

to a distribution uniform on [0,1) because a(L)O flattens out without bound as aggregate
shocks accumulate. The correlation between the position within their cycle of units with
different sensitivity parameters decreases over time, since common shocks affect them differently and these differences accumulate.'9 As long as 0 has a sufficiently smooth density,

conditional on any value of cO, the economy's aggregate deviation converges to that of its
frictionless counterpart.

ASSUMPTION 5 Smoothness (2). The random variable 0 has a density fe(8) such that
fo(O) and 9f(9), conditional on any value of CO, have bounded variation V(fe(O) I ce) and

V(Ofe(9) co); and E,V(f9(8) co) and E,V(9f0(O) co) are both finite.
PROPOSITION 5 Suppose that differences in sensitivity parameters and units' initial posi-

tions within their cyck are the only source of heterogeneity, and that Assumptions I and 5
hold. Then the economy's aggregate behavior converges to that of its counterpart with no

friction and cg converges to a distribution uniform on the interval [0,1).
PROOF: See the Appendix. I
The speed at which the economy's aggregate converges to that of its frictionless coun-

terpart increases with the rate at which a(t) grows; it is shown in the Appendix that Z(t)
and J(t) are both bounded from above by k/a(L), where k depends on how smooth the cor-

responding densities are. This bound is sharp when sensitivity parameters have a uniform
distribution.

The mechanism that leads to convergence in this case combines those present when
either idiosyncratic shocks or differences in bandwidths are the sole source of heterogeneity.

On the one hand, aggregate shocks are the main determinant of convergence, on the other,

these shocks achieve convergence by spreading out indefinitely the x(t)'s, as idiosyncratic
shock8 did in Section 4.

6 INTERACTIONS
We have found conditions under which stochastic and structural heterogeneity yield

convergence separately. It follows that convergence is more likely to occur when both
sources of heterogeneity are present. We formalize this intuition at the end of Section A2
in the Appendix.

The results on the speed of convergence are, however, far less transparent. There is a
18

broad set of parameters for which the intuitive assertion that when a second mechanism is
added, convergence speeds up, is valid; surprisingly, however, this is not universally true.

Figure 4 presents an example of this paradox. It shows that adding structural hetero.geneity to stochastic heterogeneity may slow down the speed of convergence. In this exam-

ple, idiosyncratic shocks follow a Brownian motion (with instantaneous variance equal to

0.4 and 1/A is normal with mean 0.4 and variance t2). All units have the same sensitivity
parameters and their initial distribution within their cycle is uniform on [0,0.2]. Figure 4

shows the path of 1(t) for three values of the parameter ,. It is apparent that —beyond
a certain time threshold— convergence is faster when stochastic heterogeneity is the only
source of convergence (q = 0) than when structural heterogeneity is also present (q> 0).20

Figure 4 is best understood by comparing the aggregate deviation without structural

heterogeneity, Z(t), with the aggregate deviation of a sector composed of units with a
common bandwidth larger than average after structural heterogeneity is added. When
structural heterogeneity is added to idiosyncratic uncertainty, the sectoral aggregates corresponding to larger bandwidths converge slower than Z(t), since structural heterogeneity
reduces the variance of their idiosyncratic shocks relative to their bandwidths and it is this

ratio that determines the speed of convergence (see Section 4). For the same reason the
sectoral aggregates corresponding to smaller bandwidths converge faster than Z(t). Figure

4 shows an example where the slowdown of units with bandwidths larger than average
dominates over the combined effect of the acceleration of units with bandwidths smaller
than average and the decrease in synchronization between sectoral aggregates (see Section
5).
Perverse interactions may also be present when we add stochastic heterogeneity to an

economy where structural heterogeneity —in the form of differences in bandwidths— leads

to convergence by itself. This is best understood when we consider the case where there
are no differences in sensitivity parameters and we group units into sectors according to the

value of their idiosyncratic shock at time t, v,(i). Since the effect of v1(i) on units within a

sector is the same as the effect of having a common shock equal to a(t) + v1(t) instead of
a(t), the discussion in Section 5 shows that sectors with positive v(t)'s are typically nearer
to their steady state than they would be if there were no idiosyncratic shocks, while sectors

with negative realizations are farther away. When adding sectoral aggregate deviations,
structural heterogeneity decreases the degree of synchronization, yet it may happen that
units with negative shocks determine the overall speed of convergence. We have constructed
19

examples where this is the case.21

Finally, we consider the case where idiosyncratic shocks interact with differences in

sensitivity parameters. For simplicity we suppose that bandwidths are the same across
units. If the v,(t)'s are i.i.d. across units and independent from 0, then adding idiosyncratic
shocks speeds up convergence (this follows form Proposition A4 in the Appendix). Yet when

v,(t) depends on 0, there are cases where adding structural heterogeneity —in the form
of differences in sensitivity parameters— slows down the speed at which an economy with
stochastic heterogeneity converges.

7

FINAL REMARKS

In this paper we study the dynamic behavior of an (S,s) economy where units face
idiosyncratic shocks and differ in both their bandwidths and their responses to aggregate
shocks. We develop a framework that provides a meaningful characterization of the out—
of—steady state dynamics of an (S, s) economy, and study its convergence properties and
the speed at which this occurs.
The major building block in our approach is to work with the cross—section distribution
of units' positions within their cycle, conditional on the 8ample path of the aggregate 8hock.

This distribution, combined with that of structural differences and sensitivity parameters,
describes the actual state of the economy at a given instant in time and —if the number of
units is sufficiently large— does not depend on the value taken by every particular agent's

idiosyncratic shock but only on the common distribution function originating them. This
insight follows from the Clivenko—Cantelli Theorem (see Billingsley, 1986); it allows us to
apply results from probability theory when studying convergence and speed of convergence.

Although we work with (S,s) rules, the summary variables Z(t), J(t), Z(t) and J(t)
should be applicable to a much broader set of circumstances where m.icroeconomic frictions

influence aggregate dynamics.

An important methodological contribution of our approach is that it substantially reduces the dimensiona.lity of the problem. An alternative approach would be to characterize

the joint behavior of n units, in terms of the joint distribution function describing units' po-

sitions at time t based upon information available at time I = 0 (e.g. Caplin, 1985). Within
this approach, however, convergence means that given information available at time I = 0,

our best forecast of the n-dimensional random vector describing agents' positions within

their cycle at time I approaches a distribution uniform on the unit hypercube, tO, l]'. In
20

this case speed of convergence slows down as the number of agents grows, since demanding

that all agents be within a given distance from their uniform distribution becomes more
stringent. This differs from the steady state we consider in this paper, where the cross—
section distribution of units' positions within their cycle is uniform on the interval [0,1].
Considering statistics derived from the cross—section distribution —such as its mean and
sensitivity to common shocks— and realizing that it does not depend on the actual realiza-

tion of every agents' idiosyncratic shock simplifies the analysis considerably and provides

ground for optimism about future research in this area.
We have implicitly assumed in our analysis that the redefinition of initial conditions —
i.e. whatever moves the economy away from its steady state— occurs infrequently enough

so that the economy has time to converge back to its steady state; the insights developed
here, however, apply even when this is not the case (see Caballero and Engel 1989a, and the

working paper version of this paper). In general, there is a permanent tension between the
natural tendency for the economy's aggregate deviation to converge back to the steady state

and the impact of repeated large (finite) aggregate shocks. Given any process generating

the latter, the average distance of the economy from the steady state decreases with an
increase in the importance of stochastic and structural heterogeneity (with the caveats of
Section 6).

The techniques developed here have already found applications beyond the framework

of this paper. For example, Caplin and Leahy (1989) use them to prove convergence (up

to a location parameter) in the context of a fully symmetric two sided (S, s) economy
where heterogeneity is negligible; and Caballero and Engel (1989b) have used the concept

of synchronization developed here to show that when strategic interactions are present,
multiple equilibria can be ruled out once the cross—section distribution is sufficiently close

to its steady state.

To conclude, we stress that the principle of conditioning on the aggregate in order
to keep track of the evolution of the cross—section distribution is far more general than

the framework of this paper. This may be one of the building blocks of future work on
aggregation of heterogeneous units in the presence of non—vanishing correlation across units.

Department of Economics, Columbia University, New York, NY 10025, U.S.A.

Department of Economics, MiT (Cieplan and Universidad de Chile), Cambridge, MA
02139, U.S.A.
21

APPENDIX

Al. EXACT FORMULAS FOR TIlE SUMMARY VARIABLES
DEFINITION

Al Given non—negative real numbers a and t, we define the random variables

C(a,t) and Y(a,t) as follows:

aO+

(8)

C(a, )

(+

(9)

Y(a,) =

[C(a,)] (mod 1);

Vt)

with c0, Vt, 0 and A as in Section 2. We then have that the function g(a,i) defined in
Section 2 is equal to EA — E{AY(a,i)}.

The following three propositions provide expressions to calculate g(a,i) and Og/Oa
when only one of the three sources of heterogeneity considered in this paper —idiosyncratic
shocks, differences in bandwidths and differences in sensitivity parameters— is present, and

all units have the same initial position within their cycle. Following these results we show
how a simple conditioning argument extends them to the case where more than one source

of convergence is present and units differ in their initial positions within their cyde.

LEMMA Al Let X be a random variable whose density 1(z) has bounded variation. Then
X(mod 1) also has a density, f1(z), and f1(x) = Ekf(z + k).

Prtoor: This is a well known result in probability theory, for a proof under the assumptions
made above see Proposition 3.1 in Engel (1991). I
LEMMA A2 Let X denote a random variable whose characteristic function J(z) satisfies

Ek>1 IJ(27k)i <+00. Then:
(10)

E [X(mod 1)] =

—

E>i [J(2rk)],

where [z] denotes the imaginary part of the complex number rand x(mod 1) the difference

between x and the largest integer less than or equal than z.

Paoor: The Fourier coefficients of X and X(mod 1) are the same (see e.g. Lemma 3.1
in Engel, 1991); hence the Fourier coefficients of X(inod 1) are summable and X(mod 1)
22

has a continuous density, f1(x), with bounded variation. Applying Poisson's Summation
Formula (see Butzer and Nessel, 1971, p.202, for the version being used here) we then have

that fj(x) = EkJ(2rk)e_i2. Substituting this expression for fi(z) in E[X(modl)] =
f xf(z) dx, interchanging the order of integration and summation,22 and integrating the

resulting terms, leads to equation (10). I
PROPOSITION Al Suppose that CO

1,23 and 0 1 in equation (10), and assume

C, A

that the density of Vg has a characteristic function, J(z) that satisfies Ek>1 If(2wk)l < +.

Then:
(11)

g(a,t) =
k> 1

(12)

=

2

k>1

3 [j(2rkei21(c+a)]

where [z] and E[z] denote the real and imaginary parts of the complex number z.

Paoo:

The expression for g(a,i) follows directly from equation (10) in Lemma Al,
letting c + a + v play the role of X.
The expression for Og/Da can be derived formally by differentiating the sum in (11)
term by term. The change in the order of summation and differentiation is made rigorous
by applying Lebesgue's Dominated Convergence Theorem (see e.g. Billlngsley, 1986) and

using the assumption that the the Fourier coefficients of v are summable. I
PROPOSITION A2 Suppose that c0

c with c E [0,1), Vg

0 and 0 E 1, that EA is finite,

and that AfA(X) has finite total variation, where fA(A) denotes the density of A. Then:
(13)

(14)

g(a,t) = (._c)EA — a +

a/(k-.c)
0

(a,t) = —1+>J(k)21/t(k).

PROOF: The expression for g(a, t) follows from:

E(AY(a,t)] = J.\ [(÷ ) (modl)} fA(A)dA
A
A
ja/(k.c)
+ J+OO
a/(k+I—c) A(c.1-_k)fA(A)dA
a/(1—c) A(c+)fA(A)dA

23

= cEA + a —
k1

= cEA + a

—

a/(k+1—c)

ja/(kc)

k>1 0

The expression for Og/ôa is obtained by differentiating the latter expression. The assump-

tion that AIA(.A) has bounded variation is used when interchanging the order of differenti-

ation and summation. •
PRoPosITIoN A3 Suppose that co

c with c in [0,1), Vt

0, and A 1, and that 9f(8)

has bounded variation, where fe(9) denote8 the density of 0. Then:

g(a,i) =

!(a,t) =

+ Ek(k—c){Fe (k+:_c)

—a
—1

_F0()},

+

where Fe(O) denotes the cumulative distribution function of 0.

PRooF: The expression for g(a,t) is obtained using Lemma Al as follows:

E[(c+ aO)(modl)] =

J0x1e (X

=

+k—
—k

k

= aEO

(k—c)/a
—

+ c)fe(u)du

Eck
—(h—c)/
c)J"
k

fe(u) du

_____

=a—

___

The expression for Og/Oa is obtained by differentiating the latter expression; the assumption

that Ofe(9) has bounded variation is used when interchanging the order of summation and

differentiation. I
GENERALIZATIONS

When more than one source of convergence is present, we obtain expressions for g(a, *)

and Og/Oa by calculating E[AY(a,t)IX = z] —and the corresponding derivative— for an
appropriately chosen random vector X using one of the above propositions, and then taking

expected value with respect to X. This argument is based on the fact that ELJ(X,Y)] =
24

Ex[f(X,Y)IX = z)J. It requires that the corresponding proposition's regularity conditions
hold conditional on X = x for any x, and, when calculating Og/Oa, that they hold uniformly

in x. Next we show explicitly how to apply this argument for every one of the propositions
derived above.

I. If we want to apply Proposition Al we let
Vt

and

(co = ?,A = A,O = 0) play the role of

+ (aB/A) the role of c. This leads to the following expressions:

g(a,t)

=E

[EA {Ae12

k> 1

=2
k> 1

(a,t)A = A}]

[E6 {Oei2C()IO = o}]

with C(a,) defined in (8).
2. If we want to apply Proposition A2 we let (A Ic0 = ,

0 = 0, v = v) play the role of

A, aO + v that of a and that of c.
3. If we want to apply Proposition A3 we let (0 I c = , A = A, Vt = v) play the role of
0, ? + (v/A) that of c, and (a/A) that of a.

A2 CONVERGENCE
LEMMA A3

Let X denote a random variable that has a density, 1(z), with finite total

variation equal to V(f). Denote the density of X(mod 1) by f1(z), and the sup—distance
between X(mod 1) and a distribution uniform on [0,11 by R(X(mod 1), U). Then:
(15)
(16)

R(X(mod1), U),

JE[X(modl)1 —

R(X(mod 1), U) V(f).

PitooF: Equation (15) follows from:
IE[A'(mochl)l —

J(f() 1) zdz
I Ifi(z)—1)lzdz

Jo

I R(X(modl),U)xdz
Jo
= R(X(mod1),U).
25

For a proof of equation (16), which s due to Kemperman, see Proposition 3.3.c) in Engel

(1991). •
LEMMA A4

1. Suppose that X and Y are random variables such that (X Y = y) has

a density with finite total variation V(XIY = y) for all values of y and EyV(X I Y =
y) is finite. Then X has a density with finite total variation V(X) and V(X)

EyV(X I ' =
2.

Let 1(x), fa(x) and f(x) denote the densities of the random variables X, aX and
X + c, with a > 0, and suppose that 1(x) has finite total variation V(f). Then f(x)
and

f(x) also have finite total variation and V(fg) = V(f)/a; V(f) = V(f).

Paoop: The proof of the first statement is analogous to that of Proposition 4.3 in Engel

(1991). The proof of the second statement is trivial. I

PROOF OF PRoPosITIoN 3
Let R(c, U) denote the sup—distance between Ct and a distribution uniform on the unit

interval, and V(X) denote the total variation of the density of the random variable X.
From Lemma A3 it follows that R(cg, U) V(co + (vt/A)); Lemma A4 and Assumption

2 then imply that R(ct, U) <

V(v/A) = V(v).

Assumption 3 now implies that Ct

converges —in the sup—distance— to U. Since J'(i) = 8P,>t R(c,, U) (see Section 4), this

is equivalent to having J(t) converge to zero. That Z(t) also tends to zero follows from
the fact that, due to Lemma A3, it is bounded by

R(c,, U).

I

PROOF OF PRoPosmoN 4
We begin by noting that, since in this case Cg only depends on t through the value of

a(t), convergence of Z() and J(g) to zero is equivalent to convergence of Z() and J(t)
to zero. The same holds for Proposition 5.
Let 1t(c, U) denote the sup—distance between c and a distribution uniform on the unit

interval and V(X) denote the total variation of the density of the random variable X. From

Lemma A3 it follows that R(ct, U)

V(co + (a(t)/A)). Using Lemma A4 we then have

that R(c, U) EV(A1 co)/2a(t); therefore c converges to U and J(i) converges to
zero at least as fast as
26

Theorem 4.2 —due to HopI— in Engel (1991) shows that (cg,A) converges in the weak—

star topology to (U,A), with A independent from U. It follows that E(cgA) converges to
SEA, and therefore Z(t) converges to zero. I

PRooF OF PRoPosITIoN 5
It follows from Lemmas A3 and A4 that R(cg, U) k/a(t), with k = E0V(fe I co)/2;
therefore ct converges to a distribution uniform on [0,1) and Z(t) converges to zero.
To show that J(t) converges to zero, we first consider the case where c0

c. That

J(t) converges to zero in this case follows from the expression we derived for Og/Oa in

Proposition A3 and the fact that Ek fe (-) converges to f 0f0(9)dO E because
Ofe(O) is Riemann—integrable. Ftirthermore, since EO =

IJ(t)I

1

we have:

= >I:k_cf (k-c) — Ej'Ofe(O)dO

1jk_cf(k;c)Of(O)1
with (k — c)/a

9 (k + 1 — c)/a. It follows that J(t) V(Ofe(6))/a(t); therefore the

speed of convergence of J*(g) —and, due to Lemma A3 that of Z'(t) too— is bounded from

above by 1/a(t).
The case where c0 is not equal to a spike follows from the previous argument by conditioning on the value of c0 and using the hypotheses according to which EV(ef0(O) I c0) is

finite. I
GENERALIZATIONS

Propositions 3, 4 and 5 can be extended easily to the case where more than one source
of heterogeneity is present using a conditioning argument analogous to the one we used at

the end of Section Al. I
PR.0pOSITI0N A4 Suppose that X and Y are independent random variables such that the

density of X has bounded variation. Then the sup-distance between (X + Y)(mod 1) and a
distribution U uniform on 10, 1] is less than or equal than the sup—distance between (Xmod 1)

and U.

27

Paoor: Let fx(tz) and fx+v(u) denote the densities of X(mod 1) and (X + Y)(mod 1),
and Fy(u) the cumulative distribution function of Y(mod 1). From Lemma Al and the
independence assumption it follows that fx+y(u) = I fx(u — v)dFy(v). Hence:

Ifx+y(u)

—

= ILfx(u_v)dFv(v) — iJ

= I! (fx(ts—v)

I

Jo

—

1)dFy(v)I

Ifx(u—v) — ljdFy(v)I

jR(X(modl),U).
The desired conclusion follows by taking the supremum over all u in [0,1]. I

28

REFERENCES
AKERLOF, G.A.: "Irving Fisher on his Head: The Consequences of Constant ThresholdTarget Monitoring of Money Holdings," The Quarterly Journal of Economics, 93-2 (1979),
169—187.

ARROW, K.J., T.HARRIs, AND J.MARSIIACK: "Optimal Inventory Policy," Econometrica,

19 (1951), 250-272.
BENABOU, R.: "Optima! Price Dynamics and Speculation with a Storable Good," Econo-

met rica 57-1 (1989), 41—81.

BILLINGSLEY, P.: Probability and Measure, 2 Ed. John Wiley, New York, 1986.
BLANCRARD, O.J., AND S.FIscRER: Lectures on Macroeconomics, Mass.: MIT Press,
1989.

BLINDER, A.S.: "Retail Inventory Investment and Business Fluctuations," Brookings Papet-s on Economic Activity, 2 (1981), 443—505.

BUTZER., P.L., AND R.J.NEssEL: Fourier Analysis and Approzimation Vol. .1 OneDimensional Theory, Academic Press, New York, 1971.

CABALLERO, R.J. AND E.M.R.A. ENGEL: "The S-s Economy: Aggregation, Speed of
Convergence and Monetary Policy Effectiveness," Columbia Univ. Working Paper #420,
(1989a).

CABALLERO, RJ. AND E.M.R.A. ENGEL: "Heterogeneity and Output Fluctuations in a
Dynamic Menu Cost Economy," Columbia Univ. Working Paper #453, (1989b).

CABALLERO, R.J. AND E.M.R.A. ENGEL: "Dynamic (S,s) Economies: Aggregation,
Heterogeneity and Coordination," Columbia Univ. Working Paper #476, (1990).

CAPLIN, A.S.: "The Variability of Aggregate Demand with (S,s) Inventory Policies,"
Econometrica, 53 (1985), 1395—1410.

CAPLIN, A.S., AND E. SHESRINSKI: "Optimality of S,s Pricing Policies," inimeo (1987).

CAPLIN, A.S., AND D. SPULBER: "Menu Costs and the Neutrality of Money," Quarterly
Journal of Economics, 102-4 (1987), 703—726.

CAPLIN, A.S., AND J. LEAIIY: "State-Dependent Pricing and the Dynamics of Money and

Output" Columbia WP # 448, October (1989).
29

ENGEL, E.M.R.A.: A Road to Randomness in Physical Systems, Lecture Notes in Statistics, Springer Verlag, New York, 1991.
EHRHARDT, R.A., C.SCHULZ, AND H.WAGNER: "(s,S) Policies for a Wholesale Inven-

tory System," in Schwartz, L.B. (ed.), Multi-Level Production/Inventory Control Systems:
Theory and Practice. Amsterdam: North Holland, 1981, 145—161.

KARLIri, S., AND A.FABENs: "A Stationary Inventory Model with Markovian Demand,"

Chapter 11 in Mathematical Methods in the Social Sciences, ed. by K.J.Arrow, S.Kazlin
and P.Suppes. Stanford: Stanford University Press, 1959.
SCARF, H.E.: "The Optimality of (S,s) Policies in the Dynamic Inventory Problem" Chap-

ter 13 in Mathematical Methods in the Social Sciences, ed. by K..LArrow, S.Karlin and
P.Suppes. Stanford: Stanford University Press, 1959.

SHESI1INSKI, E., AND Y.Wniss: "Inflation and Costs of Price Adjustment," Review of
Economic Studies, 44 (1977), 287—303.

SHESHINSKI, E., AND Y.WEIss: "Optimum Pricing Policy under Stochastic Inflation,"
Review of &onomic Studies, 50 (1983), 513—529.

TsIDD0N, D.: "The (Mis)Behavior of the Aggregate Price Level," mimeo (1989).

30

FOOTNOTES
1. We thank Roland Benabou, Olivier Blanchard, Andrew Caplin, Peter Diamond, Mo-

hainmad Hammour, Esteban Jadresic, Keith Head, Robert Porter, four anonymous

referees and seminar participants at Columbia, MIT and Princeton for very useful comments. Ricardo Caballero acknowledges financial support from NSF through
Grant SES-9010443.

2. Others have performed comparative statics experiments in models with no aggregate
(continuous) shocks (e.g. Akerlof, 1979; Tsiddon, 1989).

3. Of course, studying the determination of the x(t)'s themselves can be, and has been,
a topic in itself.

4. We assume that the (S,s) rules followed by units are given exogenously. This has two
consequences. First, we do not consider the relation between the economy's aggregate
behavior and the determinants of the (S, s) policies' optimal target and trigger points.

This can be done easily, yet doing so is beyond the scope of this paper. Second, the
results we derive also apply in a broader class of problems, where (S, s) rules are not

optimal but can be justified as either simple rules that approximate more complex
first best rules or, perhaps equivalently, as arising from near rational behavior.
5. The only reason for having this assumption is that it simplifies some of the algebraic

expressions. It is easy to work without it, as we did in preliminary versions of this

paper. For example, this implies that in the retail inventory problem z1 represents
the inventory level in deviation from its long run average.

6. This assumption requires that the sum of changes in aggregate and idiosyncratic
components always be positive: O1da(i) +

dv,() 0. We assume that a(t) grows

sufficiently fast —compared to the rate at which idiosyncratic shocks disperse— for
this assumption to hold. On some occasions, however, calculations are simpler if we

consider distributions generating idiosyncratic shocks that have infinite tails. Our
model is appropriate in this case if the fraction of units violating the monotonicity
assumption is small.

7. The monotonicity assumption is appropriate in the inventory problem when returns
are dominated by new sales and the holding cost does not vary much; in the pricing
31

problem, when core inflation is sufficiently large; in the cash balance problem, when

expenditures dominate the interest rate variability; and in the technology, consumer

durables, and investment problems, when the obsolescence and depreciation rates
dominate the uncertainty faced by firms and consumers.

8. To reconstruct X(t) based on Z(t) we need to know the value of a(t). This is usually
obtained front a theoretical model for the frictionless economy.

9. Note that 0 and A do not have time subindices, indicating that units' sensitivity
parameters and bandwidths do not change over time.

10. The 1 is used in place of 1 to remind us that there are no units with c(i) = 1, since
this is a trigger point. Strictly speaking, this notation is unnecessary since the density

of an absolutely continuous random variable is determined up to a set of Lebesgue
measure zero. What we have in mind is a continuous version of this density.
11. This assumes that all sensitivity parameters are the same across units. The expression

for 1(t) is extended to the general case as follows. We apply the argument given in

the text with the density of ct conditional on the value of e instead of

f, and take

expectation with respect to 0, concluding that J(t) = Ee [9f(c,e=s)(1j1 — 1. The
assertion that 1(to) = 0 does not imply that /(t) remains equal to zero is still valid.
12. Considering suprema in the definitions above is just one possible choice. We could
work with a weighted average —over all possible values of a a(t) and $ t— where
the weights reflect the likelihood of different sample paths of the common shock and

the time discount rate.
13. Strictly speaking, we should consider higher derivatives of Z(t) with respect to a(t);
we do not see any economic motivation for doing this.

14. The total variation of a function 1(x) is equal to sup Ek If(zk+1) — f(zk)I, where
the supremum is taken over all finite increasing sequences z1 < x2 < X3 <

.... It

follows directly from this definition (see e.g. Proposition 3.4 in Engel, 1991) that the
total variation of a unimodal function is equal to twice the maximum value it attains.
More generally, if f(z) is piecewise continuously differentiable, with jumps of absolute

magnitude 61,62,..., then its total variation is equal to E6k + I If'(x)ldz.

32

15. Formally:

R(c.,tJ) = SUPA Pr{c. E A)
Pr{U

— 1

A}

where the supremum is taken over all l3orel sets with positive Lebesgue measure. The

proof may be found in Caballero and Engel (1989a).

16. We have limited our attention to cases where the economy converges to the steady
state, but the same approach can be used when this does not happen. In Caballero and
Engel (1989b) we show that when the v,(1)'s are stationary, the synchronizing features

of large aggregate shocks can only be partially undone by stationary idiosyncratic
shocks.

17. Given a random variable X, the real and imaginary parts of its first Fourier coefficient

are equal to the expected value of co€(2wX) and sin(2xX). Since the sine and cosine functions are periodic, these expectations are equal to those of cos(2rX(mod 1))

and sin(2TX(mod 1)) and therefore measure how near to a uniform distribution the
random variable X is after being folded back onto the unit interval.

18. When we say that g() converges to zero at the same rate as a positive decreasing
function h(t), we mean that

0 < lim (lim sup Ig(u)I/h(i)) < +oo.
—•+O
u>t

19.

Looking at a particular example —say, c0

0, A 1 and 0 uniform on [1/2,3/2]—

helps building the intuition behind how convergence takes place in this case. Since
such an analysis is entirely analogous to the one we made in Section 5.1, we omit it.

20. A similar phenomenon takes place for Z(i).
21. The argument given above assumes that units' idiosyncratic shocks are independent
from their bandwidths. If v and A are correlated, the perverse effect described above
may still happen. One exception, though, is when the v,(t)'s are identically distributed

except for a scale parameter that is proportional Aj;in this case adding idiosyncratic
shocks to differences in bandwidths always speeds up convergence. This follows from
Proposition A4 and the Glivenko—Cantelli Theorem.

22. This step is based on Fubini's Theorem. It is here where we use the assumption that
the Fourier coefficients of X are summable.
33

23. If A A we let vs/A play the role of v.

34

la
C

(V

2
——

-1.6

—1.2

-OS

—0.4

—0.0

0.4

lb

FIGURE

lc

0.0

1.2

1.6

2[a]

rq
4-)

I

__

I

-I-

a(t]=0 05t

Cu

- - - aCt)=0.lOt

NJ

zero
LI)

D

2[b]
CD

0

0

Cc?

0

1

2

3

4

b

t

6

7

8

9

S

7

8

9

10

6

7

8

9

10

10

2[c]
CD

c

0
m

0
0
0
q
00

1

2

3

4

5

t
2Cd]

0?

0
CD

0
0
p
1

2

3

4

5

t

3[aJ

0

ci
('4

Q
4.)

N

0
C

0
0
C\J

0.05

0.10

0.15

0.20 0.25 0.30 0.35 0.40 0.45 0.50
a

3[b]
c:i

0
C',

4-)

0

—)

0
I-

0.05 0.10

0.15

0.20 0.25 0.30 0.35 0.40 0.45 0.50
a

3(c)
(1

0

*1

0.05

0.10

0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50
a

3(d)
0)

0
CD

0
0
0

ci

0.05 0.10

0.15

0.20 0.25 0.30 0.35 0.40 0.45 0.50

4
a
a
0
.4

*

0

•1

0
a
I
—

0
0
0

0

2

4

8

S

t

12

14

16

11=0.0

15

20

