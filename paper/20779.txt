NBER WORKING PAPER SERIES

MARGINAL PRICING AND STUDENT INVESTMENT IN HIGHER EDUCATION
Steven W. Hemelt
Kevin M. Stange
Working Paper 20779
http://www.nber.org/papers/w20779

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2014

The research reported here was supported by the Institute of Education Sciences, U.S. Department
of Education, through Grant R305B110001 to the University of Michigan. The opinions expressed
are those of the authors and do not represent views of the Institute of Education Sciences or the U.S.
Department of Education. This research used data structured and maintained by the Michigan Consortium
for Educational Research (MCER). MCER data are modified for analysis purposes using rules governed
by MCER and are not identical to those data collected and maintained by the Michigan Department
of Education (MDE) and/or Michigan’s Center for Educational Performance and Information (CEPI).
Results, information and opinions solely represent the analysis, information and opinions of the author(s)
and are not endorsed by, nor do they reflect the views or positions of grantors, MDE and CEPI or any
employee thereof. Monica Hernandez, Andrew Litten, and Chris Zbrozek provided excellent research
assistance. We are grateful for helpful comments from John DiNardo, Susan Dynarski, Caroline Hoxby,
Michael Lovenhiem, Sarah Turner, Leslie Turner, and numerous seminar participants at the University
of Michigan, Stanford University, CUNY, the W.E. Upjohn Institute, and the NBER Education Program
Fall 2013 meetings. Hemelt can be contacted at hemelt@email.unc.edu; Stange can be contacted at
kstange@umich.edu. All errors and opinions are our own. The views expressed herein are those of
the authors and do not necessarily reflect the views of the National Bureau of Economic Research.¸˛
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2014 by Steven W. Hemelt and Kevin M. Stange. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.

Marginal Pricing and Student Investment in Higher Education
Steven W. Hemelt and Kevin M. Stange
NBER Working Paper No. 20779
December 2014
JEL No. I2,J24
ABSTRACT
This paper examines the effect of marginal price on students’ educational investments using rich administrative
data on students at Michigan public universities. Students facing zero marginal price for credits above
the full-time minimum (i.e., 12 credits) attempt and complete about the same average number of credits
as those whose institutions charge per credit. Zero marginal price induces a modest share of students
(i.e., 7 percent) to attempt up to one additional class (i.e., 3 credits) but also increases withdrawals,
resulting in little impact on earned credits or the likelihood of meeting “on-time” benchmarks toward
college completion. Consistent with theory, the moderate impact on attempted credits is largest among
students who would otherwise locate at the full-time minimum, which include lower-achieving and
socio-economically disadvantaged students.

Steven W. Hemelt
Department of Public Policy
University of North Carolina - Chapel Hill
Abernethy Hall, Campus Box 3435
Chapel Hill, NC 27599
hemelt@email.unc.edu
Kevin M. Stange
Gerald R. Ford School of Public Policy
University of Michigan
5236 Weill Hall
735 South State Street
Ann Arbor, MI 48109
and NBER
kstange@umich.edu

I. Introduction
Only slightly more than half of recent college entrants graduate within six years (Shapiro
et al., 2013) and time-to-degree has increased particularly for students from low-income families
(Bound, Lovenheim, & Turner, 2012). Such statistics have propelled those in federal, state, and
local policy circles to call for proposals aimed at increasing rates of degree completion and
shortening time-to-degree among college-goers (e.g., National Conference of State Legislatures,
2010). Indeed, recent proposals from the Obama administration suggest tying federal aid to
graduation rates and timely degree completion (Lewin, 2013).
In the face of such pressure, many institutions have looked at changes in tuition policies
as a means of generating revenue while also maintaining or improving student success. Marginal
price is one potentially important dimension of institutions’ pricing structures about which little
is known. By marginal price, we mean the price students are charged incrementally for each
additional course (or credit) they take in a given semester. Many students only take the minimum
course load to achieve full-time status (i.e., 12 credits), which at most institutions would translate
to earning a Bachelor’s degree in five years or more. At some institutions, the marginal price of
credits taken above 12 is zero; others have a linear, per-credit marginal price for all credit levels.
Indeed, some institutions have adopted “flat” pricing (i.e., zero marginal cost for credits above
12) in explicit expectation that students will respond by attempting and earning more credits and
graduating faster.
How individuals react to nonlinear price schedules is central to many areas of economics
and policymaking, as proposals in a variety of domains are predicated on the microeconomic
principle that individuals respond to marginal price. The design of the Earned Income Tax Credit
(EITC), many savings and retirement programs, and public health insurance programs all

2

incorporate nonlinear price schedules to achieve policy goals, as do pricing schedules in many
consumer markets such as phone and energy services.
Whether and how individuals respond to these marginal incentives remains largely an
open question with recent empirical evidence from other contexts mixed and no evidence from
the setting of education.1 A weak evidence base has not prevented colleges from touting
nonlinear pricing as one solution to colleges’ goals of increasing timely graduation rates. For
example, Adams State in Colorado recently made such a switch from per-credit (linear) to flat
(nonlinear) pricing, citing this shift as the reason average credit hours have increased in just two
years (Mumper, 2012). Similar policy shifts have been observed at Montana State, the University
of Texas, and many other institutions (Baum, Conklin, & Johnson, 2013). However, whether
nonlinear pricing alters students’ investment intensity as predicted by economic theory is not
known.
This paper is the first to examine the effect of marginal price on educational investment.
We focus on the effect of exposure to a “flat” pricing scheme at university, wherein the marginal
price of additional credits above the full-time minimum is zero, relative to a linear tuition pricing
scheme. Our contributions are fourfold. First, we add to the growing evidence base on whether
individuals respond to the marginal incentives embedded in nonlinear price schedules, albeit in a
new and policy-important context. As human capital investment is one of the most important
economic decisions individuals make, evidence about whether the standard model applies to this
setting is useful. Second, we exploit variation in the pricing structure faced by similar individuals

1

Saez (2010) finds that the self-employed respond to the first kink in the nonlinear EITC schedule, but the response
to subsequent kinks and for wage and salary workers is minimal. Ito (2013, 2014) finds that electricity and water
consumers respond to average price, not the marginal price embedded in the nonlinear price schedules they face. For
evidence from other settings, see Hausman (1981) for Federal income tax, Friedberg (2000) for retirement savings
plans, Kowalski (2012) for health insurance, Olmstead, Hanemann, and Stavins (2007) for water, and Borenstein
(2012) for energy services. Moffitt (1990) reviews the early literature on nonlinear pricing.

3

in very similar choice contexts. Much of the previous literature on nonlinear budget constraints
focuses on contexts in which similar individuals face the same price structure (e.g., the Federal
tax code), which creates numerous econometric problems such as the fact that tax rates (and thus
marginal incentives) are endogenous or that individuals with different marginal incentives may
be quite different.2 Third, we provide the first evidence on the effects of a policy that many
higher education institutions and states have turned to as a way to boost timely degree
completion. Identifying effective policies has become critical as federal and state funding is
increasingly tied to graduation rates and timely degree completion (National Conference of State
Legislatures, 2010; Lewin, 2013). Finally, our study informs the revenue consequences of
institutions’ pricing regimes. Public institutions increasingly rely on tuition revenue to supplant
declines in state appropriations and many have avoided across-the-board tuition increases,
instead altering other features of their pricing policies.
We assess the effect of marginal price using administrative data on all Michigan public
high school graduates in the classes of 2008 through 2011 who attended one of the state’s public
universities. Michigan is a compelling setting to study, as there is substantial policy variation
across very similar institutions, which is not present in other states. Figure 1 depicts the price
schedule at Michigan’s fifteen public universities. Eight charge students per credit taken, while
students at the other seven pay little additional tuition for courses taken beyond the full-time
minimum.3 The subsidy embedded in this non-linear price structure is substantial: 20 percent of
the direct costs of college among those who take five classes in a semester ($740 to $1,260 for
each additional 3-credit course). Though there are some differences in the characteristics of

2

Ito (2013, 2014) are exceptions. Moffitt (1990) reviews several of the econometric problems and Saez, Slemrod,
and Giertz (2012) discuss similar issues in the context of taxable income.
3
Flat pricing institutions typically charge additional tuition beyond some upper threshold (typically 18 credits) and
two charge very modest additional tuition beyond 12 credits.

4

students attending institutions with per-credit pricing and those with flat pricing (the latter
students typically being a bit more advantaged), there is considerable overlap between these two
groups. For instance, Central Michigan and Western Michigan Universities have identical
interquartile ranges of student ACT scores and similar levels of resources, though different
marginal pricing policies. We rely on this overlap, along with the assumption of selection on a
rich set of observed characteristics, to identify the causal effect of marginal price on credit
accumulation.
We find that exposure to flat tuition pricing has small to no effect on the average number
of credits attempted or earned in a semester and our results are precise enough to rule out even
small effects (i.e., of a bit less than 1 credit). When we look at the effects of flat tuition pricing
on the share of students meeting various discrete credit thresholds, we see evidence that flat
pricing induces a modest share of students to attempt a few more credits (i.e., up to one course,
or 3 credits, more). Yet, we find little evidence that these additional attempted credits translate
into more earned credits in a semester. Students facing no marginal price are more likely to
withdraw from or possibly fail at least one course. Accordingly, flat pricing is not associated
with increased cumulative credits earned, greater persistence, or reduced time-to-degree, though
estimates of these latter long-term outcomes are admittedly imprecise. As predicted by theory,
we also find the greatest attempted credit response among students who would take the full-time
minimum under linear pricing (students in the bottom of the achievement distribution and those
economically disadvantaged). There is no evidence to suggest that this pricing structure
influences students’ decisions to enroll part- versus full-time, likely because any marginal
pricing effect is swamped by discontinuities in financial aid eligibility or other considerations.
Various approaches to eliminating observed differences – rich controls, sample restrictions,

5

propensity score re-weighting, exact matching on observables – all suggest similar qualitative
results.
Our results suggest that eliminating the marginal price associated with credit intensity
will minimally affect students’ rate of progress towards degree and on-time degree completion
and may thus be a non-distortionary way of raising revenue. However, our analysis does not
fully address other possible effects of marginal pricing, including major choice, interest
exploration, financial burden, or academic performance.
This paper proceeds as follows. The next section discusses previous literature, with a
focus on the relationship between tuition pricing and progress through college. Section III
provides background on university pricing in the Michigan context. Section IV presents a simple
theoretical framework to guide our empirical work and help with the interpretation of results.
Section V describes the data used in the analyses and our empirical strategy. Section VI presents
results on credit-taking and explores their robustness, while Section VII discusses external
validity. Section VIII concludes.
II. Previous Literature
There is a large body of evidence showing that students’ enrollment, persistence, and
college choices are influenced by net college price. A consensus estimate is that a $1,000 change
in college price (1990 dollars) is associated with a 3 to 5 percentage point difference in
enrollment rates (Kane, 2006; Dynarski, 2003). Evidence on the effect of college price on
persistence and degree completion is rarer, but most studies suggest that persistence and
completion are modestly responsive to prices for at least some groups (Bettinger, 2004; Turner,
2004; Dynarski, 2008; DesJardins & McCall, 2010; Goldrick-Rab et al., 2011; Castleman &
Long, 2013). Price also appears to be a strong predictor of the specific college students choose to

6

attend (Long, 2004; Jacob, McCall, & Stange, 2013), institution-level enrollment (Hemelt &
Marcotte, 2011), and major choice (Stange, 2012). While suggestive of price response in
educational investment, this literature does not speak to whether students respond to changes in
marginal, as opposed to average, price.
We are aware of only one study that examines the relationship between marginal pricing
and student outcomes. In a working paper, Bound, Lovenheim, and Turner (2010) found that 4year public institutions with per-credit pricing had lower 4-year graduation rates than institutions
with flat pricing. Further, much of the increase in time-to-degree between 1972 and 1992
occurred at institutions that charge on a per-credit basis.4 While suggestive, this relationship may
have a number of explanations other than the causal effect of marginal pricing on student
progression through college.
At the same time, a number of interventions have been found to increase students’ credit
loads, either intentionally or inadvertently. For instance, the Promise Scholarship in West
Virginia explicitly tied aid to number of credits (and GPA), and resulted in more students taking
15 credits rather than the full-time minimum (Scott-Clayton, 2010). A similar result was found
for a scholarship program at the University of New Mexico (Miller, Binder, Harris, & Krause,
2011). Yet, work on Georgia’s HOPE scholarship, which tied eligibility and retention of funds to
maintaining a 3.0 GPA, found that HOPE reduced the likelihood that students took full courseloads and increased their propensity to withdraw from classes and divert credits to the summer
(Cornwell et al., 2005).
Other conditional aid grant programs (often in conjunction with advising or coaching)
have also had impacts on students’ credit loads. For instance, Richburg-Hayes et al. (2009) found

4

The analysis of per-credit versus flat pricing appeared in two footnotes and was not central to their main analysis
so was dropped in the subsequent published version of the paper.

7

that a performance-based scholarship at community colleges in New Orleans increased credit
loads, as did an intervention that combined financial incentives and academic support services at
a Canadian university (Angrist, Lang, & Oreopoulos, 2009). At a large Italian university,
Garibaldi, Giavazzi, Ichino, and Rettore (2012) found that charging students extra for taking too
long to graduate speeds up time-to-degree.
Together, these studies make clear that particular features of scholarship and grant
programs can have appreciable effects (positive or negative) on students’ credit loads and
progression through college. We look at marginal pricing policy as another potential lever
capable of influencing students’ credit loads – and ultimately their rates of college completion
and average time-to-degree. Since the interventions described above often tie awards explicitly
to credit-taking behavior and also typically target select student subgroups, they may not be
indicative of the broader potential effects of marginal pricing.
III. Background on University Pricing in Michigan
During the 2011-2012 academic year, eight of Michigan’s fifteen public 4-year
universities charged full-time undergraduate students differently based on the number of credits.
In these schools, tuition is a linear function of the number of credits taken, ranging from a low of
$246 per credit at Saginaw Valley State to a high of $421 at Michigan Technological University.
By contrast, the tuition schedule at the other seven institutions has a flat or near-flat range at fulltime status (12 credits). Students at these institutions pay a per-credit amount if part-time, but
almost no additional monetary cost from taking an additional course once they have reached fulltime status.5 The upper limit for which the zero marginal price applies varies from 16 to 18
credits. While per-credit pricing is generally more common at less selective institutions (all of
5

Appendix Table A1 includes more details about the pricing practices of the fifteen institutions. Two institutions,
UM-Dearborn and UM-Flint, charge a substantially lower per-credit fee ($80) once students reach full-time status.
We characterize these institutions has having “flat” pricing in our analysis.

8

the state’s community colleges charge per-credit while the state flagship university, University of
Michigan – Ann Arbor, does not), this is not always the case. Further, some institutions have
explicitly adopted flat pricing models to encourage students to take 15 credits, while others have
switched from the use of flat pricing to charging per credit (e.g., Ferris State in 2008-2009).
Tuition fees apply to any credits attempted in a semester after the course “drop date,”
regardless of outcome of the course (pass, fail, withdrawal, etc.). Students are generally given
one or two weeks to withdraw from classes while still receiving a full (or near full) refund of
tuition and fees. There does not seem to be any systematic difference in these policies by pricing
practice. Flat-pricing institutions in Michigan do not appear to be disproportionately more
generous (or strict) in their refund polices than do their per-credit pricing peers.
Marginal pricing is just one feature of pricing policies at these institutions. During the
2011-2012 academic year, seven charged differentially based on undergraduate level and three
charged differently for certain programs or majors (Presidents Council, State Universities of
Michigan, 2011). In this regard, Michigan institutions have pricing policies that are quite similar
to institutions nationally (Cornell Higher Education Research Institute, 2011; Ehrenberg, 2012).
IV. Theoretical Framework
We adapt a standard static (single-period) labor supply model to our setting in which the
tuition pricing schedule creates a kinked budget constraint on school intensity choice. We also
briefly sketch extensions to this basic model and discuss their implications.
A. Single-period model
Individual utility depends positively on lifetime consumption c and on time spent not in
school, n. Thus school attendance incurs effort cost. Individuals choose time spent in school, z, to

9

maximize utility u(c,n) subject to a nonlinear budget constraint and a standard time constraint.6
The budget constraint states that consumption equals the sum of endowed income (I) and lifetime
earnings minus tuition:

. In the single-period model, we simplify things by

assuming that each increment of schooling increases earning potential by a fixed amount w, thus
. This simplification allows us to abstract from effects of nonlinearities in the returns
to college education and to focus on schooling decisions in a single period.7 Tuition is a
nonlinear function of credit load:
,
where typically

.8 Together these elements generate the nonlinear budget constraint

depicted by the solid line in Figure 2. Below z* (i.e., the full-time minimum credit load), each
increment of schooling investment increases lifetime consumption by (w -

). Above z*, the net

return to each unit of investment is higher and thus the “price” of non-school time is also higher.
The dashed line depicts a linear (per-credit) tuition schedule.
How individuals respond to nonlinear budget constraints is complex, as reviewed in
Moffitt (1990). One finding is that a policy shift from a linear (dashed) to flat (solid) pricing
schedule will generate quite heterogeneous responses across students. Students that would locate
at z* when facing a linear pricing schedule (denoted by B) experience only a substitution effect
(non-school time has become more expensive) and would be predicted to increase their credit
intensity. However, students initially choosing to enroll beyond the full-time minimum (denoted
by A) also experience an income effect, thus the net effect for this group is ambiguous. Part-time
6

The time constraint is that total time spent in (z) and out (n) of school equals total time available, H: n + z = H.
Stange (2012) discusses the evidence on and implications of nonlinearities in returns and the dynamic nature of
schooling investment. Ignoring the nonlinearities in returns is like ignoring “career concerns” in labor supply
models, letting us treat schooling decisions made in different time periods independently. We discuss below how
relaxing these assumptions may impact our results.
8
We also ignore any increased marginal tuition for very high credit loads (typically 17 or 18 credits).
7

10

students who would locate below z* when pricing is linear (denoted C) will either remain on the
first segment (zero response) or switch segments by increasing credit loads above full-time.9 This
simple budget set analysis suggests that response may be greatest for students who otherwise
would choose to locate at the full-time minimum. In fact, continuous preferences would predict
we observe a “hole” in the density of students at the non-convex kink B. Our empirical analysis
explores this heterogeneity by stratifying our sample by students’ predicted credits (based on
baseline characteristics) when faced with a linear pricing scheme.
B. Extensions
The model described above omits four potentially important features of postsecondary
schooling: investment over time, nonlinear returns, uncertainty, and investment “lumpiness.”
Investment over time. Extending the analysis to more than one period, by itself, has little
impact on our qualitative predictions. Suppose earnings are linear in total credits accumulated
over multiple periods. If pricing is also linear, then the well-known consumption smoothing
result prevails; students will choose the same credit load in each period. However, the
introduction of nonlinear pricing separately in each period means that three possible outcomes
satisfy the first-order conditions. Some students will choose equal credit loads across all periods
at zlow, below full-time status (on the lower segment of the budget constraint). Others will choose
equal credit loads across all periods at zhigh, above full-time status. Some may also find it optimal
to choose zhigh in one period and zlow in another if this switching equilibrium dominates either of
the constant ones. That is, utility may be maximized by exerting the extra effort cost and
achieving the higher marginal return for one (but not all) periods.10 As with the one-period

9

Facing the new pricing schedule, there will be some people that are indifferent between the two segments.

10

A switching optimum with z1 = zlow and z2 = zhigh will satisfy the FOC as long as

dominates the constant-credit outcomes depends on the utility function.

11

. Whether this

model, switching from a linear to flat pricing schedule will have the greatest impact on credits
taken (in either period) for those who would otherwise locate at the full-time minimum.
Nonlinear returns. Perhaps the most controversial simplification of the model described
above is that it assumed each course credit increases lifetime earnings by the same increment.
This simplification permitted us to focus on the nonlinearities created by tuition policies.
However, there is evidence that the return to college education is nonlinear due to strong
“sheepskin” effects. The final credit earned to complete a degree has a much higher return than
the first few credits earned toward the same degree. First consider a one-period model where
each increment of schooling increases earning potential by a fixed amount w up to a threshold
level , at which point earnings jump by a discrete amount

and are constant thereafter. Thus

. In this case, the nonlinear return will dominate
intensity decisions. Students will bunch precisely at the
a level z

since it will never be optimal to choose

.11 Thus many students (who otherwise choose enough credits to achieve the

nonlinear return) will be unaffected by a shift from linear to flat pricing. However, the shift will
draw more people into the return kink, inducing them to acquire the degree. Again, those on the
margin of graduating should be most impacted by this marginal price change. This same logic
applies to the setting with multiple time periods, nonlinear returns, and no uncertainty. Since
credits earned in different time periods are perfect substitutes in the earnings production
function, students’ choice problem is similar in all periods. Thus decisions will be similarly
sensitive to marginal price in earlier or later time periods.
Uncertainty. The model assumes that people choose credit loads with perfect foresight
about future preferences (e.g., effort costs), credit completion, enrollment, and degree
11

If we permit additional credits beyond
still be a mass of students at .

to increase earnings, some students will locate at

12

, but there will

completion. Uncertainty along these dimensions alters the choice environment as it is resolved
over time. For instance, freshmen may be uncertain about future life events that may cause them
to drop out, enroll part-time, or otherwise switch budget constraint segments next year. Since the
payoffs to current decisions depend, in part, on these uncertain future outcomes, current choices
will be less responsive to price parameters when uncertainty is greatest, such as in the earliest
years. Students in later years of college, facing less uncertainty, should respond more sharply to
changes in price schedule.
Investment lumpiness. Lastly, the above discussion treats schooling intensity as
continuous, though in practice the number of credits is finite and “lumpy” as most classes are
worth either 3 or 4 credits. Such adjustment costs have been found to mute responses to
nonlinear incentives in other contexts (Chetty et al., 2011).
V.

Data and Empirical Approach
A. Data and Samples
We combine student-level data from several different administrative sources. From the

Michigan Consortium for Education Research (MCER), we begin with information on the entire
universe of Michigan public high school graduates from 2008 through 2011. These data include
demographic information (sex, race, ethnicity, free and reduced-price lunch eligibility (FARM),
LEP, special education), 11th grade achievement scores,12 and high school. We then use data
from the National Student Clearinghouse (NSC) to restrict our sample to students appearing in
college (anywhere up to August 2012).13

12

For these classes, we use a students’ composite ACT score since the ACT became a mandatory part of Michigan’s
high school testing in 2007.
13
For an extensive overview of the coverage and use of National Student Clearinghouse (NSC) data for research,
please consult Dynarski, Hemelt, and Hyman (2013). For the state of Michigan during our timeframe, enrollment
coverage is quite high (i.e., between 95 and 97 percent), and highest among 4-year public institutions (100 percent).

13

To examine credit accumulation at Michigan public institutions, we next merge these
records of college-going Michigan high school graduates onto data from the Michigan Student
Transcript and Academic Record Repository (STARR). STARR contains full, historical
transcript records (course-level data) for all individuals enrolled in 2-year or 4-year public
colleges in Michigan in the 2011-2012 academic year. While the state of Michigan mandated the
collection of the entire transcripts of students enrolled at any Michigan public college during that
year, there is some (small) variation in the degree to which institutions supplied course-taking
information from prior years. Therefore, we focus on STARR data from the Fall of 2011 and
Spring of 2012. These semesters occur at different points in an “on-time” college trajectory for
students, depending on the year of their high school graduation. For example, the 2011-2012
academic year corresponds to the on-time third year of college for the high school class of 2009.
Therefore, we examine whether students’ postsecondary persistence (and relatedly, the
composition of our sample) is related to flat pricing.
Our main analytic sample includes students from these high school cohorts (i.e., 2008
through 2011) who are enrolled full- or part-time in a Michigan public 4-year institution during
the fall and/or spring of the 2011-2012 academic year. This results in 212,320 student-bysemester observations (over 112,000 unique students) across all high school cohorts. For some
analyses we restrict our sample to only full-time students (194,391 observations) or to students
not attending the University of Michigan – Ann Arbor (187,707 observations for all students;
170,466 full-time).
Table 1 presents mean demographic and achievement characteristics, as well as collegelevel credit outcomes for this sample by institutional pricing structure. There are some small to
moderate differences in the average characteristics of students attending per-credit versus flat

14

pricing institutions. Generally speaking, students attending flat pricing schools are more
advantaged (less likely to be eligible for free or reduced-price meals, less likely to be minority)
and have higher college admissions scores. Though, as illustrated by the final two columns in
Table 1, the achievement advantage of students at flat schools is largely driven by the fact that
the University of Michigan – Ann Arbor uses a flat tuition pricing schedule.
When we look to mean outcomes by pricing policy, we see that on average, credit loads
of students at flat schools are a bit higher than those at per-credit schools. Indeed, the share of
students attempting more than 12 credits in a semester is about 8 to 12 percentage points higher
at flat schools than at per-credit institutions. Some mean differences vary more than others as a
function of the sample: For example, the share earning 15 or more credits in a semester is about
11 percentage points higher at flat colleges; but, when the University of Michigan – Ann Arbor
is excluded from the sample, this difference falls to only 3 percentage points. Obviously, these
raw differences in means do not control for other attributes of students and schools that are likely
correlated with course-taking behavior and progress through college.
B. Empirical Approach and Identification Strategy
Our basic approach is to compare the credits taken by students attending “flat” pricing
schools (at which the marginal price is zero for credits above the full-time minimum) to those
attending per-credit pricing schools using a linear probability model estimated via OLS:
(1)
In this specification,

is a measure of credits attempted or earned by individual i from

cohort c attending school j during semester t. Our primary outcome variables are total credit load
and indicators for attempting or earning a credit load greater than certain thresholds (e.g., at least
13 credits or at least 15 credits).

is an indicator for whether school j has flat pricing,

15

is

a vector of student-level measures of achievement and demographics during high school,
set of semester fixed effects,

represents cohort fixed effects, and

is a stochastic error

term. Some specifications control for a limited number of institution-level covariates
primary coefficient of interest is

is a

. The

, the effect of flat pricing on student credit-taking. To account

for correlation in the errors among students at the same college, we cluster standard errors at the
institution level.14
We address three main possible sources of bias in the basic model. First, students
attending “flat” schools may possess different characteristics that are correlated with college
performance than those attending per-credit schools. While this is certainly true overall, it is
worth noting that there is considerable student overlap on observable characteristics across
institutions. Figure 3 depicts the inter-quartile range of ACT scores for all fifteen institutions.
With the exception of the University of Michigan – Ann Arbor (a flat pricing school), every flat
school has several non-flat schools with considerable test score overlap. Further, we control for a
rich array of student-level characteristics. Our sample size permits us to do this extremely
flexibly by, for instance, looking within student groups defined very narrowly by full interactions
between these characteristics. In addition, we estimate models that instrument for pricing
structure using the policy of the nearest university to students’ high schools.
Second, it is theoretically possible that additional financial aid would offset the additional
tuition and fees associated with additional credits, diminishing the treatment. Grant programs
may explicitly increase in value as number of credits increase or cost-of-attendance could be
adjusted upwards (increasing eligibility) when additional credits are taken. Max Pell amount

14

Our main estimates account for the potential lack of independence between students attending the same college by
estimating cluster-robust standard errors that generalize the White (1980) heteroskedasticity-robust OLS standard
errors. Given concerns in the literature about the performance of such clustering when the number of clusters is
small (Cameron, Gelbach, & Miller, 2008), we also examine alternative methods for statistical inference.

16

increases discretely at quarter-time, half-time, three-quarters-time, and full-time, but does not
increase in value beyond 12 credits. Further, most students are receiving the maximum Pell
grant, so increases in their costs of attending will not increase the amount of grant aid for which
they are eligible. We are not aware of any institution, state, or federal programs that explicitly
increase aid for additional credits taken beyond 12.
Finally, it is possible that schools’ pricing schemes coincide with other college-level
attributes or policies that may influence outcomes, such as resources or advising. Our focus on
one sector in one state eliminates many institutional differences that correlate with pricing
structure nationally, but we cannot entirely rule out this possibility. We have four approaches for
addressing it. First, we include an institution-level control for median ACT composite scores of
incoming freshman or for per-student spending on instruction. Second, we examine differences
in credit-taking among students taking less than a full-time load (whose behavior should be
minimally affected by the pricing scheme for full-time students) as a falsification test. Third, we
exclude University of Michigan – Ann Arbor, which is an outlier both in terms of student
characteristics and institutional resources. Finally, we can identify students eligible to receive the
Kalamazoo Promise scholarship, which pays all tuition and fees at public Michigan institutions.
These students should be insensitive to marginal price and thus serve as a control group in a
difference-in-differences analysis, permitting us to account for other non-price institutional
factors that may be correlated with both marginal pricing policies and credit-taking outcomes.
It is worth contrasting our simple approach to those employed in other settings with nonlinear pricing. Often similar individuals face the same price structure (e.g., the Federal tax code),
which creates numerous econometric problems. For instance, since tax rates are determined by
income, marginal incentives are endogenous and individuals with different marginal incentives

17

may be quite different. A number of empirical strategies have been developed for these settings,
such as measuring “bunching” at budget set kinks (Saez, 2010), instrumenting for tax rates using
changes in the tax rate structure (reviewed in Saez, Slemrod, and Giertz, 2012), or structural
approaches (Hausman, 1985). Relative to these other methods, our setting permits a very
transparent comparison between observably identical students that face quite different marginal
incentives.15
VI.

Results
A. Distribution of Credits Attempted and Earned
Figure 4 plots the fraction of all students at or above each credit threshold, separately by

pricing policy for our full sample. We see little difference in the distribution of credits taken (and
earned) by part-time students regardless of pricing policy – but, modest differences emerge right
at the point where the marginal price diverges between the two sets of institutions (i.e., 12
credits). Students that face no marginal tuition price of a heavier course load are more likely to
take (and possibly earn) credits beyond the full-time minimum. At first glance, these patterns
suggest that marginal pricing policy may have some impact on course-taking and credit
accumulation.
B. Main Results
The raw difference reported in Figure 4 may overstate the true causal effect of flat pricing
because students attending flat pricing schools are slightly more higher achieving and
advantaged, which likely have independent effects on course-taking. Table 2 presents our main
regression estimates, which control for a rich set of individual covariates and median institution-

15

We assume that students do not choose a university based on the marginal pricing policy conditional on our rich
set of individual controls. A two-stage least squares approach using the pricing policy of the nearest university also
addresses this source of bias, though our 2SLS estimates are imprecise.

18

level ACT scores.16 In this table and throughout much of the paper we focus on full-time
students. Flat pricing does not appear to impact the decision to enroll full-time (i.e., 12 or more
credits) and the inclusion of part-time students does not meaningfully change our point estimates
for any outcome (columns 4 and 8).17 However, including part-time students reduces precision
by adding residual variation to our outcomes.
We see minimal evidence of an impact of flat pricing on average credits attempted and
even less evidence that flat pricing affects average credits earned. This conclusion is robust to
institutional controls and excluding University of Michigan – Ann Arbor from the sample.
Further, the estimates are quite precise and our standard errors on these null findings imply that
we could detect an effect of around 0.5 to 0.6 credits attempted or earned.
However, flat tuition pricing is associated with an increase in the likelihood that students
attempt at least 13 credits (more than the full-time minimum) of about 7 or 8 percentage points
(relative to a base of 80 percent). Since estimates at both the 13 and 15 attempted credit
thresholds are similar, this implies that these students are attempting about 3 additional credits,
or approximately one course.18 Student must earn 15 credits each semester in order to graduate
within four years. However, the impact of flat pricing on earned credits is much weaker (i.e., half
the magnitude or less of the effect on credits attempted), sometimes “wrong-signed,” and

16

The coefficients on the individual covariates are as expected from previous literature: male, non-white, poor,
limited English, special education, and students with low ACT all attempt fewer credits. Including many subject
tests rather than the ACT composite produces nearly identical results, quantitatively and qualitatively.
17
The null effect on full-time status also provides as a falsification check: given financial aid and other
discontinuities at the full-time threshold, flat pricing should not induce many part-time students to enroll full-time. If
we were to find an “effect” of flat pricing at this margin, we might be concerned about other unobserved, collegelevel attributes correlated with both flat pricing and students’ credits load decisions driving any other results.
18
We also used the re-weighting approach described by DiNardo, Fortin, and Lemieux (1996) to construct
counterfactuals of the entire distributions of credits attempted and earned, weighting students at per-credit schools to
mirror the observable characteristics of students at flat-pricing institutions. This procedure produces very similar
results: Marginal price has its largest effect on the likelihood of attempting up to 15 credits, but has a much more
modest impact on the likelihood of earning credits. Furthermore, there are only small (and insignificant) differences
in the distribution of credits attempted and earned by less-than-full-time students. These results are available from
the authors upon request.

19

insignificant. Therefore, additional attempted credits do not appear to translate into more credits
earned.
The inability to translate attempted credits into earned ones is largely explained by course
withdrawal and, to a lesser extent, course failure. Table 3 examines effects on course withdrawal
and failure, both for all students and just full-time students. In a given semester, flat pricing
increases the likelihood that students withdraw from at least one class by about 7 percentage
points and the likelihood of course failure by 3 to 4 percentage points. Since students at flat
pricing schools do not bear the financial cost of enrolling in a course and withdrawing after the
drop deadline, they appear to do so much more frequently.19 The effect on course failure
suggests one of two things: a) some students may simply stop showing up and never withdraw
from a class, when doing so imposes no direct financial cost (even if course failure has other
consequences); or b) students perform more poorly because of too heavy a credit load. Since
effort is not observed, our data do not permit us to separately identify these two channels.
Regardless, these findings suggest that the increased likelihood of course withdrawal (and to a
lesser extent failure) is what dampens the impact of flat pricing on credits earned.
C. Robustness
Table 4 examines the robustness of our main findings to various changes in sample,
specification, institutional controls, and statistical inference. Our full sample includes all college
students enrolled in 2011-2012, including students that have chosen to persist beyond the first
year. This may introduce sample selection bias if marginal price impacts persistence. Yet,
estimates focused on just freshmen (2011 high school graduates) are quite similar (column 2) to
the full sample for all outcomes.

19

Estimates from models which include UM-AA or do not control for institution-level ACT are similar.

20

Having data on the full universe of all students in public universities in the state permits
us to control for individual characteristics quite flexibly. Controlling for individual ACT score
non-linearly (column 3)20 or including separate fixed effects for the large number of
demographic groups defined by the six-way interaction of ACT score (each single point
separately), female, race/ethnicity, FARM, LEP, and special education status (column 4)
produces estimates that are nearly identical to our baseline specification.21
The next two columns attempt to address the possibility that institutions with flat pricing
may differ along other dimensions that may influence course-taking. Controlling for instructional
spending (rather than institution-level ACT score) does not alter our findings (column 5) on
credits attempted or earned. Specification (6) uses eligibility for the Kalamazoo Promise (KP)
Scholarship to construct difference-in-difference estimates as a way to control for institutional
characteristics (observed and unobserved) that may correlate with pricing policy and students’
credit-taking behavior. Since KP-eligible students do not pay tuition, they should be insensitive
to the marginal pricing structure of the institution they attend, but would be affected by other
college characteristics and policies. Their responsiveness to flat pricing can be used to net out the
effects of these unobserved institutional characteristics.22 The specification includes an indicator
for Not KP-eligible, an interaction between Flat and Not KP-eligible, and institution fixed
effects. Column (6) reports the coefficient on this interaction. Since Kalamazoo graduates are

20

That is, we include a dummy variable for each individual value of the ACT.
To address the possibility that students may choose to attend flat-pricing institutions based on unobservable
student characteristics, we also estimated 2SLS models in which we instrumented for flat pricing of institution
attended with the pricing policy of the university closest to a student’s high school. Point estimates are about twothirds the size of base model estimates (i.e., about a 5 percentage point impact on the likelihood a student attempts
13 or more credits), but substantially less precise (standard errors double). These results are qualitatively in line with
our overall pattern of findings. Results are available from the authors upon request.
22
As described by Bartik and Lachowska (2012), the KP provides a scholarship that covers up to 100% of all tuition
at public universities and colleges in Michigan, depending on how long a student was enrolled in Kalamazoo Public
School system. The scholarship was announced in 2005, so all students from KPS in our study were potentially
eligible.
21

21

quite different in characteristics and the institutions they attend from students generally, the latter
are re-weighted to resemble Kalamazoo graduates (via the use of a first-stage logistic regression
where we estimate the likelihood a student is KPS eligible as a function of our vector of studentlevel characteristics and institution fixed effects). For attempted credits, this specification is very
consistent with our earlier results. However, here we find evidence that a modest share of
students translate additional attempted credits into earned ones. Yet, we caution against reading
too deeply into this result as this specification (largely) identifies a treatment effect by comparing
credit-taking behavior of KP-eligible students to non-KP-eligible students at just two institutions:
Michigan State University and Western Michigan University. 23 In addition, Kalamazoo high
school graduates look quite different than the average student in our full sample: they are more
likely to be black and eligible for free or reduced-price meals. Broadly, this specification
assuages fears that our approach to estimating the effects of flat pricing on students’ credits loads
is substantially biased by unobserved, omitted characteristics of colleges that correlate with both
flat pricing and students’ course-taking behavior.
Finally, we examine alternative inference methods. Clustering standard errors at the
college-by-cohort level increases precision considerably. Implementing the wild bootstrap
procedure suggested by Cameron, Gelbach, and Miller (2008) reduces precision for some
outcomes, but not for attempting more than 12 credits or for likelihood of withdrawal.
D. Heterogeneity
Our theoretical framework suggests that students who would otherwise locate at the fulltime minimum of 12 credits would be most strongly affected by flat pricing. Such students
experience only a substitution effect (non-school time has become more expensive) and are
23

Nearly half of KP-eligible Kalamazoo students attend Western Michigan University, representing 64 percent of all
KP-eligible students at flat institutions. Two-thirds of KP-eligible students at per-credit schools attend Michigan
State University.

22

unambiguously predicted to increase their credit intensity. In fact, we should observe a “hole” in
the density of students at the full-time minimum at flat-pricing schools if credit intensity were
truly continuous. Since we cannot know the credit load that students at flat schools would choose
when faced with linear pricing, we use students at per-credit schools with identical observed
characteristics to form this counterfactual. We create a large number of mutually exclusive
student groups defined by the six-way interaction of ACT score (each single point separately),
female, race/ethnicity, FARM, LEP, and special education status. Within each of these groups
we compare the credits attempted (earned) between students at per-credit and flat-pricing
schools. Figure 5 shows these results graphically (and includes all students, part-time and fulltime).24 Groups are ordered according to the average number of credits attempted (earned) at percredit institutions so that those furthest left are the groups most likely to attempt (earn) close the
full-time minimum.25 The vertical distance provides an estimate of the effect of flat pricing for
each group. These comparisons are among very similar students (e.g., among black non-specialeducation non-LEP females who are eligible for free or reduced-price meals and scored a 23 on
the ACT).
Consistent with the theory, we find that estimated treatment effects on credits attempted
are largest for those students closest to the full-time minimum: students at flat schools attempt
about one credit more, on average. Treatment effects diminish somewhat, as we move up the
distribution of average attempted credits. Effects on credits earned are even smaller and close to
zero for all but the bottom third of groups. This suggests that our main results are indeed being
driven by impacts on credits attempted for those students who would locate near the 12-credit

24

The pictures are similar and the conclusions unchanged if we limit our sample for Figure 5 to full-time students.
The x-axis simply counts the number of student groups graphed where groups are ordered by the average credits
taken in per-credit schools. Only groups containing at least 50 students in each type of school are shown in Figure 5,
though the pattern is unchanged if more groups are included.
25

23

threshold under a per-credit pricing scheme. Students in the bottom 20 demographic subgroups
in Figure 5 are overwhelmingly black (90%), FARM (40%), have an average ACT composite
score of 16.4, and attempt 12.1 credits; while students in the top 20 demographic subgroups are
non-black, non-FARM, score an average of 27.9 on the ACT, and attempt an average of 14.3
credits. We repeated our regression analysis separately by quintile of predicted credits attempted
based on student characteristics with similar results.26
We also explored heterogeneity in our regression framework by explicitly contrasting
effects by observable characteristics, such as sex, eligibility for free or reduced-price meals, and
unique ACT score. This heterogeneity analysis was motivated by evidence of differential effects
of other interventions for women versus men (e.g., Anderson, 2008), the overtaking of men by
women in college entry and completion (Goldin, Katz, & Kuziemko, 2006), and the stronger
response by low-income students to college prices relative to their more advantaged peers (Kane,
1994; Dynarski, 2002). These results (reported in Appendix Table A3) are very consistent with
the pattern depicted in Figure 5: effects of flat pricing remain concentrated along the margin of
attempted (not earned) credits and withdrawal and are largest for poor and male students. These
are precisely the students who disproportionately populate the bottom demographic subgroups in
Figure 5.

26

These results are presented in Appendix Table A2. To construct quintiles we estimate a first-stage regression
using data only on students at per-credit institutions where the outcome is credits attempted and the only covariates
are student-level characteristics. We use coefficients from this model to predict the number of credits attempted for
all students in our analytic sample and divide students in quintiles based on this prediction. Students in the bottom
quintile are those closest to the 12-credit, full-time benchmark. Given recent concerns about the potential for this
process to introduce systematic errors in the extremes of the prediction distribution, thereby biasing subgroup
treatment effects (Abadie, Chingos, & West, 2013), we only include subgroups with more than 50 students per cell
in Figure 5. In addition, our main sample sizes are quite large, mitigating bias-causing errors due to over-fitting in
this prediction-based approach to exploring heterogeneity (Abadie, Chingos, & West, 2013, p. 4).

24

E. Interpreting the Effects of Flat Pricing
To examine effects of flat pricing on course-taking behavior by subject, we characterize
each course taken into one of 12 broad subject areas based on CIP codes (available at some
institutions), academic department/subject, and/or course title. Figure 6 illustrates our findings
graphically. The left bar depicts the mean number of credits attempted in each subject area by all
students at per-credit schools in the 2011-2012 academic year. The average course load includes
about one course each in Humanities/English and Social Science and two or three other courses
collectively across the other ten subjects. The right bar adds to this our subject-specific estimated
treatment effect of flat pricing. Though students at flat pricing schools do take slightly more
credits in these two main areas, the difference is modest and not statistically significant. Students
at per-credit schools take more credits in Other Professional/Technical subjects, which appears to
be driven by more credit-taking in communications and journalism at these schools. In results
not reported, we found that additional credits are not disproportionately in subjects we categorize
as “non-degree-related” and that there is little systematic substitution from 3- to 4-credit
courses.27 We conclude that the additional courses students are induced to take in response to a
subsidized marginal price are not substantively different than their typical courses and, if
anything, are in the core subjects of Humanities/English and Social Science.
F. Long-term Outcomes
We now explore the impact of marginal pricing on the longer-term outcomes of
persistence and credit accumulation. We track entry into and persistence through postsecondary
education using the National Student Clearinghouse (NSC). For each member of the high school

27

Results available from authors upon request. “Non-degree-related” includes CIP codes 31 through 37, including
Parks, Recreation, and Leisure Studies, Basic Skills/Remedial, Citizenship Activities, Health-related Knowledge and
Skills, Interpersonal and Social Skills, Leisure and Recreational Activities, and Personal Awareness and SelfImprovement.

25

cohorts of 2008 through 2011, we identify students (of any intensity) that enrolled in a Michigan
public 4-year university in the fall term immediately following high school graduation. 28 Figure
7 plots the fraction of these students enrolled in any college (Panel A) or a MI public 4-year
university (Panel B) over time, separately by high school cohort and the pricing policy of the
first institution attended. Across all institutions, 96% of students attend any college (including
Michigan universities, community colleges, and private colleges) in their second semester,
though enrollment drops to 83% by the start of the fourth academic year. Comparable rates for
enrollment at a Michigan public university are 93.6% and 72%, respectively.
Rates of persistence beyond the first year at any college are slightly higher for students
starting at institutions with flat (rather than per-credit) pricing. However, rates of persistence at
Michigan public universities are considerably higher among students starting at flat-pricing
schools (Panel B). These raw persistence patterns do not control for the characteristics of
students. When we control for such traits, students at flat institutions have lower rates of
persistence than would be predicted by their individual traits.29 Thus we find little evidence that
flat pricing improves students’ rates of persistence, either overall (at any institution) or at MI
public universities.
We now directly examine impacts on credits accumulated over several years. Recall that
STARR data contain information about all courses taken in 2011-2012 and in all prior terms,
among students still enrolled in the 2011-2012 academic year. Thus for all students in the 2008,
2009, and 2010 cohorts that persist to 2011-2012, we calculate cumulative credits attempted and
28

This sample includes 116,581 individuals, approximately 29,000 students from each of these four cohorts. Very
few students enter one of these institutions in the spring term, so the fall enrollment restriction is not too binding.
Students that delay entry into or eventually transfer to a Michigan public university from private or community
colleges are also excluded to ensure that the sample is similar across cohorts, given that later cohorts would
mechanically have few delayed or transfer entrants.
29
Appendix Table A5 presents regression results that control for individual and college characteristics when looking
at persistence.

26

earned as of Spring 2012. We make two important sample restrictions. First, we restrict our
analysis to students enrolled (at least part time) in any Michigan public 4-year college in all fall
and spring semesters since high school graduation (as indicated by the NSC).30 This restriction
permits us to abstract from students’ decisions to persist and instead focus on credits
accumulated among those that have decided to persist in all periods.31 Second, we only keep
students with complete consistency between their NSC and STARR records. 32 This restriction
assures we accumulate all credits attempted and earned by an individual.33
In Table 5 we analyze cumulative credits attempted, cumulative credits earned, and
whether cumulative credits earned are above the threshold for on-time, all as of Spring 2012.
Since these on-time thresholds differ by student level (sophomore, junior, senior), we present
estimates separately by cohort. Overall, we find little evidence that flat pricing encourages
students to attempt or accumulate more credits over time. On average, students have attempted
58.3 credits and earned 54.9 by the end of their second year in college, but there is little
difference between students at per-credit and flat pricing institutions. Nor are students at flat
institutions more likely to have earned 60 credits, a marker for graduating within four years.34
Results for the 2009 and 2008 cohorts are qualitatively similar: the typical student is attempting
and earning fewer credits than the on-time benchmark and there is minimal difference between
students at flat and per-credit schools. Any modest average attempted credit advantage seen
30

So members of the high school class of 2008 (2009, 2010) must be enrolled in a MI public university for all 8 (6,
4) fall and spring terms since high school graduation.
31
Further, our intention is to construct markers of on-time credit accumulation that are only relevant for students
that have already chosen to enroll. Given the minimal impact on persistence, we do not believe this restriction
creates grave concerns about sample selection bias.
32
Though NSC-STARR consistency is quite high in the 2011-2012 academic year (98%, similar for flat and percredit schools), it deteriorates in earlier years and becomes slightly worse at per-credit institutions. Thus results for
the 2008 and 2009 cohorts that rely on historical data (such as cumulative credits) should be interpreted with some
caution.
33
We find similar effects on credits attempted in 2011-2012 with this restricted sample as with the full sample
reported earlier. These results are available from the authors upon request.
34
Though not reported in the table, we find similar results for cumulative credits across fall and spring terms only
(excluding summer) and if we exclude the University of Michigan – Ann Arbor.

27

among students at flat pricing institutions is eliminated (and in some cases reversed) when
looking at credits earned.
VII.

External Validity
Our study focuses on public universities in Michigan because of the availability of rich

transcript data and because the state appears unique in having substantial policy variation among
similar institutions, likely because tuition policy is not set centrally. While focusing on a single
state and sector controls for many possible confounders, it raises the question of external
validity. Unfortunately there is no systematic source of information of the current use of flat or
per-credit pricing across many institutions nationally, so repeating our analysis for a wide range
of schools is not possible.35 As a check on external validity, in Table 6 we examine students at
public universities in the states of Minnesota and Texas using data contained in the 2004 and
2008 National Postsecondary Student Aid Study (NPSAS). These states have nationally
representative samples for students in public universities in both these years and, importantly,
have some variation in pricing practices across institutions and over time.36
Within the University of Minnesota System, the Duluth and Crookston campuses
transitioned from per-credit to flat pricing between 2004 and 2008, while the Twin Cities and
Morris campuses were flat throughout. Three of the Minnesota State Universities had flat pricing
and four had per-credit pricing in 2004, with one (Southwest State) going from per credit to flat
between 2004 and 2008. Though cross-sectional models suggest a positive association between
35

Standard sources such as the Integrated Postsecondary Education Data System (IPEDS) by the U.S. Department
of Education and the Annual Survey of Colleges by the College Board ask institutions to report the price for a
typical full-time student, but do not currently report whether this price varies with credit load. This is a point also
made by Baum et al (2013). IPEDS does contain an indicator for flat or per-credit pricing in 1993, but data from this
period would have limited applicability to the external validity of our results in 2011.
36
Other states with representative or large samples in NPSAS in 2004 and 2008 lack adequate variation in pricing
practices across institutions. For instance, all public four-year universities in California, New York, Ohio, and North
Carolina have flat pricing structures, as do most in Georgia. Flat pricing in Illinois is confined to the two most
selective institutions (University of Illinois Urbana-Champaign and University of Illinois Chicago) with no change,
making credible comparisons difficult. All public universities in Florida charge per credit hour.

28

flat pricing and credit intensity, including institution fixed effects eliminates this pattern. Though
the Duluth and Crookston campuses adopted flat pricing, their students did not gain on those at
the Twin Cities and Morris campuses where pricing policy was unchanged.37 In Texas, flat
pricing was introduced at five campuses in the wake of tuition deregulation in 2003: the
University of North Texas (2007), UT Austin (2005), UT Arlington (2006), UT Brownsville
(2006), and Texas A&M (2009). Prior to that, all institutions charged per credit. Again we find
little evidence that credit intensity increased appreciably following the adoption of flat pricing,
whether we examine the entire sample or restrict analysis to the UT System.
VIII. Discussion and Conclusions
As public colleges and universities replace lost state support with tuition revenue from
students, many have re-examined the common practice of charging a flat rate regardless of
students’ credit load, level, or program. At the same time, pressure from policymakers and the
public has compelled institutions to find ways to improve student progress and reduce time-todegree. These twin objectives appear to be at odds: raising prices may generate revenue but
could also deter enrollment, slow student progress, and ultimately reduce the number of college
graduates. Charging full-time students differentially based on the number of credits taken –
pricing at the margin – is one practice about which similar institutions have articulated different
views. Some have stressed the detrimental effects of marginal price on student success by, for
instance, reducing the marginal price to zero in order to get students to “Finish in Four,” as
Adam’s State’s plan is called. Others see marginal pricing as an equitable way of raising revenue
from students who consume more resources; “flat” pricing is viewed as a subsidy to students

37

Some cautions are warranted, however. The samples are very small and not representative at a school-level. Also,
data cleaning measures used in 2008 eliminate 87% of the sample of students at the seven Minnesota State campuses
during that year. These observations are dropped from all analysis and preferred specifications do not use Minnesota
State campuses in 2008.

29

who would have taken large course loads anyway. These divergent views are unsurprising given
the dearth of evidence on the subject.
This paper provides the first evidence on whether students’ educational investments
respond to these marginal price incentives. Using rich administrative data on all in-state students
at the 15 public universities in Michigan, we estimate that marginal price (above the full-time
minimum) has no detectable effect on the average number of credits attempted or earned in a
semester. We find that exposure to flat pricing compels about 7 percent of students to attempt
about one class more (i.e., up to 3 additional credits). This impact appears to be driven by
relatively stronger effects among low-income, minority, and lower-achieving college students
(i.e., point estimates are nearly twice as large for such groups). Yet, we see little evidence that
these additional attempted credits translate into more credits earned in a semester or
cumulatively, greater persistence, or reduced time-to-degree, though estimates of these longerterm outcomes are admittedly less precise. We argue that this disconnect between additional
credits attempted and earned is due to the increased propensity of students exposed to flat-pricing
to withdraw from (or fail) classes.
Based on these results, marginal pricing may be a non-distortionary way for institutions
to raise revenue. Additional revenue could be used to finance other interventions with a stronger
track record of improving student success, to increase financial aid, or possibly to lower the
average tuition price faced by students taking lower credit loads.
Our null finding stands in contrast to the rather large literature that documents substantial
student responses to price in other choice environments, such as the decision to enroll or the
choice of college. Our results suggest a need to dig deeper into the choices students make after
entering college, as price responsiveness at the enrollment margin does not appear to imply a

30

comparable responsiveness once students are enrolled. Policies designed with large student price
elasticities in mind (informed by the enrollment and college choice literature) may not translate
well to the problem of supporting and hastening student progress with marginal incentives.
There are several possible explanations for this difference. First, it is plausible that the
intensive credit-taking decision environment is quite different than at the extensive margin.
Students may perceive more constraints on their credit-load choices than on their college
choices. Second, the marginal price of intensity may simply be less salient than the overall
(average) price, which determines enrollment and college choice. In Michigan, we see some
variation in the salience of pricing policies (and its relation to cost savings and time-to-degree)
across institutions. For example, Lake Superior State University exclaims in large, bold font at
the top of its webpage on costs: “LSSU offers a flat tuition rate for those taking 12 to 17 credits.
This means you can take 17 credit hours for the price of 12, a savings of over $4,100 per year,
and over $16,400 in four years!”38 Other colleges simply state the overall and/or per-credit
tuition prices, sometimes buried in tables on registrar webpages. Lastly, it is possible that
students respond to some other feature of price than marginal price, such as average or expected
marginal price, as has been observed in other settings (Ito, 2013). A task for future work is to
separate these explanations, possibly through an experimental information intervention along the
lines of Chetty and Saez (2013). There are also several other possible effects of marginal price
that we have not yet explored, namely major choice, financial burden, or interest exploration.
These too are important questions for future research.

38

Source: http://www.lssu.edu/costs/

31

REFERENCES
Abadie, A., Chingos, M. M., & West. M. R. (2013). Endogenous stratification in randomized
experiments. NBER Working Paper No. 19742.
Anderson, M. L. (2008). Multiple inference and gender differences in the effects of early
intervention: A reevaluation of the Abecedarian, Perry Preschool, and Early Training
projects. Journal of the American Statistical Association, 103(484), 1481-1495.
Angrist, J., Lang, D., & Oreopoulos, P. (2009). Incentives and services for college achievement:
Evidence from a randomized trial. American Economic Journal: Applied Economics,
1(1), 136-163.
Bartik, T. K, & Lachowska, M. (2012). The short-term effects of the Kalamazoo Promise
Scholarship on student outcomes. W.E. Upjohn Institution for Employment Research,
Working Paper 12-186. Access: http://research.upjohn.org/up_workingpapers/186
Baum, S., Conklin, K., & Johnson, N. (2013, November 12). Stop penalizing poor college
students. New York Times, Opinion.
Bettinger, E. (2004). How Financial Aid Affects Persistence. In College Choices: The Economics
of Where to Go, When to Go, and How to Pay for It, ed. Caroline Hoxby. University of
Chicago Press.
Bound, J., Lovenheim, M. F., & Turner, S. (2012). Increasing time to Baccalaureate degree in
the United States. Education Finance and Policy, 7(4), 375-242.
Bound, J., Lovenheim, M. F., & Turner, S. (2010). Increasing time to Baccalaureate degree in
the United States. NBER Working Paper Series, No. 15982.
Borenstein, Severin. (2012). The Redistributional Impact of Nonlinear Electricity Pricing.
American Economic Journal: Economic Policy, 4(3): 56-90.
Cameron, A. C., Gelbach, J. B., & Miller, D. L. (2008). Bootstrap-based improvements for
inference with clustered errors. Review of Economics and Statistics, 90(3), 414-427.
Castleman, Benjamin L. and Bridget Terry Long. (2013). Looking Beyond Enrollment: The
Causal Effect of Need-Based Grants on College Access, Persistence, and Graduation.
NBER Working Paper No. 19306
Chetty, Raj, John Friedman, Tore Olsen, and Luigi Pistaferri, (2011). Adjustment Costs, Firm
Responses, and Micro vs. Macro Labor Supply Elasticities: Evidence from Danish Tax
Records. Quarterly Journal of Economics, 126: 749-804.

32

Chetty, Raj, and Emmanuel Saez. 2013. “Teaching the Tax Code: Earnings Responses to an
Experiment with EITC Recipients” American Economic Journal: Applied Economics,
5(1): 1-31.
Cornell Higher Education Research Institute. (2011). 2011 Survey of Differential Tuition at
Public Higher Education Institutions. Access:
http://www.ilr.cornell.edu/cheri/upload/2011CHERISurveyFinal0212.pdf
Cornwell, C., Hee Lee, K., & Mustard, D. B. (2005). Student responses to merit scholarship
retention rules. Journal of Human Resources, 40(4), 987-917.
DesJardins, S., & McCall, B. (2010). Simulating the effects of financial aid packages on college
student stopout, reenrollment spells, and graduation chances. The Review of Higher
Education, 33(4), 513-541.
DiNardo, J., Fortin, N. M., &Lemieux, T. (1996). Labor market institutions and the distribution
of wages, 1973-1992: A semiparametric approach. Econometrica, 64(5), 1001-1044.
Donald, S. G., Lang, K. (2007). Inference with difference-in-differences and other panel data.
Review of Economics and Statistics, 89(2), 221-233.
Dynarski, S., Hemelt, S. W., & Hyman, J. (2013). The missing manual: Using national student
clearinghouse data to track postsecondary outcomes. NBER Working Paper No. 19552.
Dynarski, S. (2008). Building the stock of college-educated labor. Journal of Human Resources,
43(3), 576-610.
Dynarski, S. (2003). Does aid matter? Measuring the effect of student aid on college attendance
and completion. American Economic Review, 93(1), 278-288.
Dynarski, S. (2002). The behavioral and distributional implications of aid for college. American
Economic Review, 92(2), 279-285.
Ehrenberg, R. G. (2012). American higher education in transition. Journal of Economic
Perspectives, 26(1), 193-216.
Friedberg, Leora. 2000. The Labor Supply Effects of the Social Security Earnings Test. Review
of Economics and Statistics, 82(1): 48–63.
Garibaldi, P., Giavazzi, F., Ichino, A., & Rettore, E. (2012). College cost and time to complete a
degree: Evidence from tuition discontinuities. Review of Economics and Statistics, 94(3),
699-711.
Goldin, C., Katz, L. F., Kuziemko, I. (2006). The homecoming of American college women: The
reversal of the college gender gap. Journal of Economic Perspectives, 20(4), 133-156.

33

Goldrick‐Rab, Sara, Douglas N. Harris, James Benson and Robert Kelchen. 2011. Conditional
Cash Transfers and College Persistence: Evidence from a Randomized Need‐Based Grant
Program. Institute for Research on Poverty Discussion Paper no. 1393‐11
Hemelt, S. W., & Marcotte, D. E. (2011). The Impact of Tuition Increases on Enrollment at
Public Colleges and Universities. Educational Evaluation and Policy Analysis, 33(4),
435-457.
Hausman, Jerry A. (1981). “Labor Supply.” In How Taxes Affect Economic Behavior, ed. Henry
J. Aaron and Joseph A. Pechman, 27–71. Washington, DC: Brookings Institution.
Hausman, Jerry A. (1985). Taxes and Labor Supply. In Handbook of Public Economics, Vol. I,
ed Alan Auerbach and Martin Feldstein. Elsevier Science Publishers (North-Holland)
Ito, Koichiro. (2013). How Do Consumers Respond to Nonlinear Pricing ? Evidence from
Household Water Demand. Working Paper, Stanford University.
Ito, Koichiro. (2014). Do Consumers Respond to Marginal or Average Price? Evidence from
Nonlinear Electricity Pricing. American Economic Review, 104(2): 537-63.
Jacob, B., McCall, B. P., & Stange, K. (2013). College as Country Club: Do Colleges Cater to
Students’ Preferences for Consumption? NBER Working Paper No. 18745. January
2013.
Johnson, W. R., & Turner, S. (2009). Faculty without students: Resource allocation in higher
education. Journal of Economic Perspectives, 23(2), 169-189.
Kane, T. J. (2006). Public Intervention in Postsecondary Education, In Eric Hanushek and Finis
Welch (eds.) Handbook on the Economics of Education, Amsterdam:
Elsevier/NorthHolland.
Kane, T. J. (1994). College entry by blacks sine 1970: The role of college costs, family
background, and the returns to education. Journal of Political Economy, 102(5), 878-911.
Kowalski, Amanda. (2013). Estimating the Tradeoff Between Risk Protection and Moral Hazard
with a Nonlinear Budget Set Model of Health Insurance. NBER Working Paper 18108.
Lewin, T. (2013, August 22). Obama’s plan aims to lower college costs. New York Times,
Education, p. A1.
Long, Bridget Terry. (2004). How Have College Decisions Changed Over Time? An Application
of the Conditional Logistic Choice Model. Journal of Econometrics, 121: 271-298.
Miller, C., Binder, M., Harris, V., & Krause, K. (2011). Staying on track: Early findings from a
performance-based scholarship program at the University of New Mexico. MDRC
Report.
34

Moffitt, Robert. (1990). The economics of kinked budget constraints. Journal of Economic
Perspectives. 4(2): 119-139.
Mumper, M. (2012, November 21). Improving college productivity with a full course-load.
Denver Post, Access: http://blogs.denverpost.com/opinion/2012/11/21/improvingcollege-productivity-full-courseload/29384/
National Conference of State Legislatures (2010). Improving College Completion: Action Steps
for Legislators, Access: http://www.ncsl.org/issues-research/educ/improving-collegecompletion-action-steps-for-le.aspx
Olmstead, Sheila M., Michael W. Hanemann, and Robert N. Stavins. (2007). Water demand
under alternative price structures. Journal of Environmental Economics and
Management, 54(2): 181-198.
Presidents Council, State Universities of Michigan (2011). Reports on Tuition and Fees, Access:
http://www.pcsum.org/ReportsandStudies/PCSUMReportsandStudies/TuitionandFeesRe
ports/tabid/79/Default.aspx
Richburg-Hayes, L., Cha, P., Cuevas, M., Grossman, A., Patel, R., & Sommo, C. (2009). Paying
for college success. MDRC Policy Brief.
Saez, Emmanuel, Joel B. Slemrod, and Seth H. Giertz. 2012. The elasticity of taxable income
with respect to marginal tax rates: A critical review. Journal of Economic Literature,
50(1): 3-50.
Saez, Emmanuel. 2010. Do Taxpayers Bunch at Kink Points? American Economic Journal:
Economic Policy, 2(3): 180-212.
Scott-Clayton, J. (2010). On money and motivation: A quasi-experimental analysis of financial
incentives for college achievement. Journal of Human Resources, 46(3), 614-646.
Shapiro et al., (2013). Completing college: A state-level view of student attainment rates.
National Student Clearinghouse Research Center, Signature Report #4.
Stange, K. (2012). An Empirical Investigation of the Option Value of College Enrollment.
American Economic Journal: Applied Economics, 4(1): 49-84.
Stange, K. (2012). Differential Pricing in Undergraduate Education: Effects on Degree
Production by Field. NBER Working Paper 19183.
Tuner, S. (2004). Going to College and Finishing College: Explaining Different Educational
Outcomes. In College Decisions: How Students Actually Make Them and How They
Could, ed. Caroline Hoxby. University of Chicago Press for NBER.

35

White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test
for heteroskedasticity. Econometrica, 48(4), 817-838.

36

Figure 1. Sticker Price for Michigan Public Universities, Fall 2011
First-time in-state students in non-differentiated programs

Source: Presidents Council, State Universities of Michigan, Report on Tuition and Fees 2011-2012.

Figure 2. Single-Period School Intensity Budget Constraint

Notes: Figure plots non-linear budget constraint (solid) for choice of school intensity if earnings increase linearly
with intensity and per-credit tuition price is reduced (from 𝑡𝑡1 to 𝑡𝑡2 ) for intensity greater than z*. Linear budget
constraint (dashed) is shown for reference.

Figure 3. ACT Score Ranges at Michigan Public Universities, by Pricing Policy
Inter-quartile Range of ACT Composite Score
32

th

75 ptile
30
28

Flat pricing
Per-credit pricing

Midpoint
th

25 ptile
26
24
22
20
18
16

Source: Integrated Postsecondary Education Data System (IPEDS), data for 2009-2010 incoming class.

Figure 4. Fraction of Students at or above Credit Threshold at Michigan Public
Universities
A. Credits Attempted

B. Credits Earned

Notes: Figure plots the fraction of students at Michigan public universities that attempt (or earn) at least X credits in
the semester, separately by the pricing structure of the university. Sample includes college-going Michigan high
school graduates form the classes of 2008 through 2011. Credit-taking is observed in the fall and spring of the 20112012 academic year.

Figure 5. Heterogeneous Effects of Flat Pricing by Student Characteristics
A. Credits Attempted

B. Credits Earned

Notes: Each demographic group is defined by a six-way interaction between ACT score, female, race/ethnicity,
FARM, LEP, and special education status. Only those groups containing at least 50 students are shown. Credittaking is observed in the fall and spring of the 2011-2012 academic year. See text for additional details.

Mean Credits Attempted

Figure 6. Effects on Mean Credits Attempted by Subject

4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0

Per-credit (actual)

Flat = Per-credit + estimated treatment effect

Notes: Per-credit mean is for all cohorts during 2011-2012 academic year. Flat (counterfactual) mean is per-credit
mean plus estimated effect of flat pricing on average credits taken in subject. Model includes indicators for each
unique term (e.g., Fall 2011), individual controls, institution-level ACT score, and cohort fixed effects. Sample
includes only FT students and excludes University of Michigan – Ann Arbor. Estimates for other samples are
similar. Standard errors (not reported) are clustered by institution. Significance of difference between flat and percredit schools denoted: *** p<0.01, ** p<0.05, * p<0.1.

Figure 7. Persistence Among Fall Enrollees at MI Public Universities, by High School
Cohort and Pricing Policy
A. Persistence at Any College

B. Persistence at Any MI Public 4-year University

Notes: Figures plot the fraction of students enrolled in any college (Panel A) or a MI public university separately by
high school cohort and pricing policy of first institution. Restricted to MI public high school graduates from 2008 to
2011 that enrolled in a MI public 4-year university in the fall immediately after high school.

Table 1. Student Sample Characteristics, by Marginal Pricing Practice
2008-2011 High School Graduates

Per-credit
schools (PC)
Demographic and Achievement Characteristics:
Female
0.554
(0.497)
Black
0.118
(0.322)
Hispanic
0.016
(0.124)
Other
0.041
(0.197)
White
0.826
(0.379)
FARM
0.069
(0.254)
LEP
0.038
(0.191)
Special Education
0.066
(0.248)
ACT Composite Score

College Outcomes:
Credits Attempted
Credits Earned
Attempt at least 12 credits
Earn at least 12 credits
Attempt more than 12 credits
Earn more than 12 credits
Attempt 15 or more credits
Earn 15 or more credits
N

Include all flat schools
Flat schools Difference
(F)
(F - PC)

Exclude UM-Ann Arbor
Flat schools Difference
(F)
(F - PC)

0.549
(0.498)
0.074
(0.261)
0.021
(0.142)
0.062
(0.241)
0.843
(0.363)
0.058
(0.234)
0.035
(0.183)
0.063
(0.243)

-0.005
(0.002)
-0.044
(0.001)
0.005
(0.001)
0.022
(0.001)
0.018
(0.002)
-0.011
(0.001)
-0.003
(0.001)
-0.003
(0.001)

0.560
(0.496)
0.079
(0.269)
0.022
(0.146)
0.033
(0.180)
0.866
(0.340)
0.069
(0.253)
0.028
(0.165)
0.074
(0.261)

0.006
(0.002)
-0.039
(0.002)
0.006
(0.001)
-0.007
(0.001)
0.040
(0.002)
0.000
(0.001)
-0.010
(0.001)
0.008
(0.001)

22.084
(4.187)

23.612
(4.661)

1.528
(0.020)

21.912
(3.897)

-0.171
(0.020)

13.62
(2.718)
12.487
(3.683)
0.901
(0.298)
0.785
(0.411)
0.682
(0.466)
0.583
(0.493)
0.379
(0.485)
0.310
(0.463)
128,552

14.399
(2.778)
13.274
(3.883)
0.937
(0.242)
0.814
(0.389)
0.803
(0.398)
0.674
(0.469)
0.513
(0.500)
0.421
(0.494)
83,768

0.779
(0.012)
0.787
(0.017)
0.036
(0.001)
0.029
(0.002)
0.121
(0.002)
0.091
(0.002)
0.135
(0.002)
0.111
(0.002)
--

13.90
(2.570)
12.514
(3.859)
0.923
(0.266)
0.765
(0.424)
0.766
(0.423)
0.606
(0.489)
0.449
(0.497)
0.342
(0.474)
59,155

0.280
(0.013)
0.027
(0.019)
0.022
(0.001)
-0.020
(0.002)
0.084
(0.002)
0.023
(0.002)
0.071
(0.002)
0.031
(0.002)
--

Notes: Each observation is a student-by-semester, so most students are included twice. Sample includes all students during the 20112012 academic year. The "other" category includes students who identify as American Indian, Asian American, Hawaiian, or Multiracial. Standard deviations (errors for difference) appear in parentheses.

Table 2. Marginal Tuition Pricing and College Credits Attempted and Earned

Outcome

mean

Average credits

14.46

Credits Attempted
Full-time Students
(1)
(2)
(3)
0.487
(0.362)

0.340
(0.397)

0.186
(0.284)

12 or more credits

All Students
mean
(4)

mean

13.93

0.237
(0.385)

13.36

0.92

0.016
(0.025)

Credits Earned
Full-time Students
(5)
(6)
(7)
0.335
(0.342)

-0.085
(0.139)

-0.130
(0.140)

All Students
mean
(8)
12.80

-0.097
(0.246)

0.80

-0.035
(0.022)

13 or more credits

0.80

0.083***
(0.026)

0.061**
(0.027)

0.068**
(0.029)

0.73

0.072
(0.043)

0.68

0.038
(0.041)

-0.012
(0.027)

0.001
(0.020)

0.62

0.007
(0.027)

15 or more credits

0.47

0.103
(0.068)

0.088
(0.079)

0.066
(0.064)

0.43

0.066
(0.067)

0.39

0.074
(0.048)

0.044
(0.050)

0.025
(0.037)

0.35

0.026
(0.040)

None

ACT
composite

ACT
composite

ACT
composite

None

ACT
composite

ACT
composite

ACT
composite

Exclude
UM-AA

Exclude
UM-AA

Exclude
UM-AA

Exclude
UM-AA

Institution controls

Institutional sample

All schools All schools

All schools All schools

Notes: Each cell reports the coefficient on indicator for "Flat Pricing" from a separate regression. All models include indicators for each unique term (e.g., Fall 2011), high school cohort, dummies for female, black,
Hispanic, other race, LEP and FARM and composite ACT score. All student sample includes all in-state students enrolled in a Michigan public university in the 2011-2012 academic year, resulting in 212,320 studentterm observations (187,707 excluding UM-Ann Arbor). Full-time sample includes 194,391 observations (170,466 excluding UM-Ann Arbor). Robust standard errors clustered at the college level appear in parentheses:
*** p<0.01, ** p<0.05, * p<0.1.

Table 3. Likelihood of Failing or Withdrawing from Course
Individual controls, institution-level ACT, excluding UM-Ann Arbor
All Students
Full-time Students Only
(1)
(2)
Panel A. Outcome = Withdrew from at least one class
Flat pricing

0.067***
(0.020)

0.067***
(0.019)

Outcome mean
Observations

0.110
187,420

0.109
170,328

Panel B: Outcome = Failed at least one class
Flat pricing

0.036**
(0.016)

0.036**
(0.017)

Outcome mean
Observations

0.111
185,069

0.104
169,081

Notes: Each cell reports the coefficient on indicator for "Flat Pricing" from a separate
regression. All models include dummies for unique cohort and term, dummies for
female, black, Hispanic, other race, LEP and FARM and composite ACT score of
individual, midpoint ACT of the institution, and exclude UM-Ann Arbor. Sample sizes
are smaller than Table 2 due to missing data for some students. Robust standard errors
clustered at the college level appear in parentheses: *** p<0.01, ** p<0.05, * p<0.1.

Table 4. Robustness of Main Results
Full-time Students
Flexible controls
2011
Base model Cohort only
(2)
(1)
Panel A. Credits Attempted
Average credits attempted

ACT score
flexibly
Group FEs
(3)
(4)

Institutional Characteristics

Inference

Control for
spending
(5)

Kzoo
diff-in-diff
(6)

Cluster
cohort x
college
(7)

Wild
bootstrap
(8)

0.186
(0.284)

0.228
(0.278)

0.183
(0.284)

0.180
(0.283)

-0.047
(0.323)

0.256
(0.189)

0.186
[0.204]

0.186
[0.42]

13 or more credits attempted

0.068**
(0.029)

0.073**
(0.028)

0.067**
(0.029)

0.066**
(0.029)

0.075*
(0.039)

0.065*
(0.035)

0.068***
[0.000]

0.068***
[0.000]

15 or more credits attempted

0.066
(0.064)

0.040
(0.075)

0.065
(0.064)

0.064
(0.064)

0.004
(0.065)

0.092**
(0.039)

0.066*
[0.052]

0.066
[0.24]

-0.130
(0.140)

-0.106
(0.155)

-0.136
(0.141)

-0.138
(0.142)

0.022
(0.188)

0.405
(0.334)

-0.130
[0.142]

-0.13
[0.64]

13 or more credits earned

0.001
(0.020)

0.006
(0.022)

0.001
(0.020)

0.000
(0.020)

0.043
(0.033)

0.070*
(0.038)

0.001
[0.916]

0.001
[0.74]

15 or more credits earned

0.025
(0.037)

0.003
(0.051)

0.024
(0.037)

0.024
(0.037)

-0.005
(0.038)

0.082**
(0.031)

0.025
[0.239]

0.025
[0.42]

0.067***
(0.019)

0.056***
(0.018)

0.068***
(0.019)

0.068***
(0.019)

0.034*
(0.019)

-0.005
(0.012)

0.067***
[0.00]

0.067***
[0.00]

0.036**
(0.017)

0.034
(0.022)

0.037**
(0.017)

0.037**
(0.017)

0.007
(0.020)

-0.015
(0.028)

0.036***
[0.00]

0.036
[0.22]

Linear

Linear

Linear +
ACT
flexibly

Group FEs

Linear

Linear

Linear

Linear

Institution controls?

ACT
composite

ACT
composite

ACT
composite

ACT
composite

Instruct. $ per
student

Fixed
effects

ACT
composite

ACT
composite

Institutional sample

Exclude
UM-AA

Exclude
UM-AA

Exclude
UM-AA

Exclude
UM-AA

Exclude
UM-AA

All

Exclude
UM-AA

Exclude
UM-AA

Panel B. Credits Earned
Average credits earned

Panel C. Withdrawal or Fail
Withdrew from at least one course
Fail at least one course

Student controls?

Notes: Each cell reports the coefficient on indicator for "Flat Pricing" from a separate regression. All models include indicators for each unique term (e.g., Fall 2011) and high school cohort.
Student controls include dummies for female, black, Hispanic, other race, LEP and FARM and composite ACT score. Specification (6) includes an indicator for Not KPS eligible, an
interaction between Flat and Not KPS eligible, and institutions fixed effects. The table reports the coefficient on this interaction. Sample sizes for specification (2) and (6) are 46,437 and
186,474 all others have a maximum sample size of 170,466. Robust standard errors clustered at the college level appear in parentheses. Specifications (7) and (8) report p-values in brackets.
*** p<0.01, ** p<0.05, * p<0.1.

Table 5. Marginal Tuition Pricing and Cumulative College Credits Attempted and Earned as of Winter 2012
Individual controls, institution-level ACT, excluding UM-Ann Arbor
Cumulative
credits
attempted
(1)

(2)

"On-time"
cumulative
credits earned
(3)

0.777
(1.408)

0.204
(0.885)

0.010
(0.040)

58.36

54.21

0.284

1.549
(2.026)

0.680
(1.254)

-0.004
(0.043)

88.50

82.52

0.308

Cumulative
credits earned

Panel A. High school class of 2010
"On-time" = 60 credits earned by Winter 2012, n = 17,352 students
Flat pricing
Outcome mean
Panel B. High school class of 2009
"On-time" = 90 credits earned by Winter 2012, n = 13,260 students
Flat pricing
Outcome mean
Panel C. High school class of 2008
On-time" = 120 credits earned by Winter 2012, n = 8,782 students
Flat pricing

3.653
(3.266)

2.277
(2.410)

0.020
(0.076)

Outcome mean

119.01

111.18

0.341

Notes: Each cell reports the coefficient on indicator for "Flat Pricing" from a separate regression. Sample is restricted to
students enrolled (part-time or full-time) in all fall and winter semesters since high school graduation and for which NSC and
STARR data agree on enrollment history. Cumulative credits includes credits taken during summer terms. All models include
dummies for female, black, Hispanic, other race, LEP and FARM and composite ACT score of individual, midpoint ACT of
the institution, and exclude UM-Ann Arbor. Robust standard errors clustered at the college level appear in parentheses: ***
p<0.01, ** p<0.05, * p<0.1.

Table 6. Effect of Flat Pricing on Credits Attempted, Other States
Panel A. Minnesota
Sample
All schools, All years

Controls
Full controls

Obs.
1500

UMN System, All years

Full controls

900

UMN System, All years

Full controls + Fixed effects

900

Overall sample mean

1500

Panel B. Texas
Sample
All schools, 2008

Controls
Full controls

2900

UT System, All years

Full controls

1600

UT System, All years

Full controls + Fixed effects

1600

Overall sample mean

4800

Credits Attempted
At least 13
At least 15 Average credits
0.093***
0.120***
0.578***
(0.031)
(0.044)
(0.176)
0.075*
-0.023
0.256
(0.043)
(0.065)
(0.252)
0.010
-0.117
-0.113
(0.051)
(0.089)
(0.317)
0.916
0.669
15.20

At least 13
0.014
(0.030)
0.019
(0.044)
-0.056
(0.060)
0.677

Credits Attempted
At least 15 Average credits
-0.033
-0.098
(0.031)
(0.109)
-0.095**
-0.167
(0.043)
(0.152)
0.009
-0.048
(0.061)
(0.211)
0.407
13.90

Notes: Sample is drawn from the 2004 and 2008 NPSAS, which is representative of students at public 4-year institutions in these years. Sample
sizes rounded to nearest 100. Each observation is a person-term, weighted by sample weights. Full controls include indicators for year and
semester, age, indicator for Pell recipient, GPA, EFC, family income, undergraduate level, and system (UMN or UT). Standard errors clustered
by person appear in parentheses: *** p<0.01, ** p<0.05, * p<0.1.

Table A1. Marginal Pricing Practices at Michigan's 4-year Public Universities

Type
Central Michigan University
Eastern Michigan University
Ferris State University
Grand Valley State University
Lake Superior State University
Michigan State University
Michigan Technological
Northern Michigan University
Oakland University
Saginaw Valley State University
University of Michigan-Ann
University of MichiganUniversity of Michigan-Flint
Wayne State University
Western Michigan University

per credit
per credit
per credit
flat
flat
per credit
per credit
flat
per credit
per credit
flat
flat
flat
per credit
flat

Per-credit price
(2011/2012)
$358
$247
$348

Flat range

12-16 credits
12-17 credits
$407
$421

Price differentials by…
level
Program or
(upper vs. lower)
school

yes
yes

yes

12-18 credit
$331
$246

yes
12-18 credits
> 12
> 12

$287
12-15 credits

yes

yes

yes
yes

yes

Withdrawal Policy
Can receive full (or near full) refund
of tuition and fees if withdraw by…
second meeting of course
one week into course
fourth day of the semester
end of first week of classes
sixth day of the semester
one-fourth of term of the class*
second Wednesday of semester
one week into course
two weeks into course
end of first week of classes
three weeks into course
two weeks into course
three weeks into course
two weeks into course
one week into course

Source: Presidents Council, State Universities of Michigan, Report on Tuition and Fees 2011-2012
Notes: UM-Dearborn and UM-Flint charge $80 for each credit above 12, though this is substantially lower than the rate charged per credit up to 12. Withdraw and refund policies come
directly from each institution's registrar, business, and/or records websites. * = measured in weekdays not class days.

Table A2. Impacts by Quintile of Predicted Credits Attempted
Full-time students, individual controls, institution-level ACT, excluding UM-Ann Arbor

Panel A. Credits Attempted
Average credits attempted
13 or more credits attempted
15 or more credits attempted
Panel B. Credits Earned
Average credits earned
13 or more credits earned
15 or more credits earned
Panel C. Withdrawal or Fail
Withdrew from at least one course

Overall
(1)

1 (low)
(2)

0.186
(0.284)
0.068**
(0.029)
0.066
(0.064)

0.321
(0.223)
0.119***
(0.035)
0.085
(0.059)

0.077
(0.306)
0.062*
(0.033)
0.036
(0.073)

0.105
(0.304)
0.044
(0.030)
0.055
(0.071)

0.119
(0.304)
0.050*
(0.028)
0.053
(0.063)

0.185
(0.323)
0.046**
(0.021)
0.073
(0.057)

-0.130
(0.140)
0.001
(0.020)
0.025
(0.037)

-0.179
(0.167)
0.017
(0.024)
0.031
(0.028)

-0.228
(0.147)
0.001
(0.024)
0.005
(0.041)

-0.195
(0.136)
-0.016
(0.021)
0.019
(0.042)

-0.231
(0.178)
-0.013
(0.023)
0.017
(0.040)

0.010
(0.224)
0.003
(0.016)
0.038
(0.040)

0.067***

0.077**
(0.029)

0.069***
(0.021)

0.069***
(0.019)

0.070***
(0.016)

0.057***
(0.013)

0.061**
(0.025)

0.035
(0.022)

0.033*
(0.017)

0.044**
(0.015)

0.021**
(0.009)

(0.019)
Failed at least one course

Quintile of Predicted Credits Attempted
2
3
4
(3)
(4)
(5)

0.036**
(0.017)

5 (high)
(6)

Notes: Each cell reports the coefficient on indicator for "Flat Pricing" from a separate regression. Students are grouped into quintiles based on their predicted
number of credits attempted from a regression model applied to students at per-credit schools. All models include dummies for unique cohort and term, dummies
for female, black, Hispanic, other race, LEP and FARM and composite ACT score of individual, midpoint ACT of the institution, and exclude UM-Ann Arbor.
Robust standard errors clustered at the college level appear in parentheses: *** p<0.01, ** p<0.05, * p<0.1.

Table A3. Impacts by Student Gender and Poverty Status
Full-time students, individual controls, institution-level ACT, excluding UM-Ann Arbor

Panel A. Credits Attempted
Average credits attempted
13 or more credits attempted
15 or more credits attempted
Panel B. Credits Earned
Average credits earned
13 or more credits earned
15 or more credits earned
Panel C. Withdrawal or Fail
Withdrew from at least one course

All
(1)

Female
(2)

Male
(3)

Non-FARM
(4)

FARM
(5)

0.186
(0.284)
0.068**
(0.029)
0.066
(0.064)

0.199
(0.322)
0.071**
(0.031)
0.073
(0.069)

0.172
(0.243)
0.064**
(0.029)
0.057
(0.060)

0.171
(0.286)
0.064**
(0.029)
0.063
(0.064)

0.352
(0.256)
0.117***
(0.037)
0.090
(0.063)

-0.130
(0.140)
0.001
(0.020)
0.025
(0.037)

-0.010
(0.170)
0.015
(0.021)
0.035
(0.042)

-0.274
(0.163)
-0.016
(0.024)
0.012
(0.035)

-0.132
(0.137)
0.000
(0.019)
0.024
(0.038)

-0.190
(0.232)
0.017
(0.025)
0.034
(0.033)

0.067***

0.061***
(0.018)

0.075***
(0.021)

0.067***
(0.018)

0.080**
(0.032)

0.029**
(0.010)

0.044*
(0.025)

0.035*
(0.016)

0.062*
(0.031)

(0.019)
Fail at least one course

0.036**
(0.017)

Notes: Each cell reports the coefficient on indicator for "Flat Pricing" from a separate regression. All models include dummies for
unique cohort and term, dummies for female, black, Hispanic, other race, LEP and FARM and composite ACT score of individual,
midpoint ACT of the institution, and exclude UM-Ann Arbor. Robust standard errors clustered at the college level appear in
parentheses: *** p<0.01, ** p<0.05, * p<0.1.

Table A4. Colleges attended by Kalamazoo Promise-eligible vs. Other Students

Kalamazoo-eligible students
#

Percent of Percent of
total
group

All other students
#

Percent of Percent of
total
group

Per-credit institutions
Central Michigan
Eastern Michigan
Ferris State
Michigan State
Michigan Tech
Oakland University
Saginaw Valley State
Wayne State

26
25
27
235
13
6
1
23

2%
2%
2%
20%
1%
1%
0%
2%

7%
7%
8%
66%
4%
2%
0%
6%

23,165
10,595
10,371
35,394
5,071
11,965
8,178
10,769

13%
6%
6%
19%
3%
6%
4%
6%

20%
9%
9%
31%
4%
10%
7%
9%

Flat-pricing institutions
Grand Valley State
Lake Superior State
U Michigan Ann Arbor
Northern Michigan
Western Michigan

59
4
203
26
510

5%
0%
18%
2%
44%

7%
0%
25%
3%
64%

19,045
2,306
23,722
7,043
17,692

10%
1%
13%
4%
10%

27%
3%
34%
10%
25%

Total

1,158

185,316

Notes: Includes all full-time students enrolled in 2011/2012 academic year. There are no Kalamazoo-eligible students attending
UM-Flint or UM-Dearborn (both flat schools), thus these are omitted from table and excluded from model and table.

Table A5. Marginal Tuition Pricing and College Persistence, First-time Fall Enrollees at MI Public Universities
Outcome = Enrolled in MI Public 4-year College

Outcome = Enrolled in Any College
mean

(1)

(2)

(3)

mean

(4)

(5)

(6)

Enrolled 1st Spring
(max n = 115,876)

0.964

0.005
(0.015)

-0.002
(0.011)

-0.008
(0.011)

0.936

0.011
(0.023)

-0.001
(0.014)

-0.010
(0.011)

Enrolled 2nd Fall
(max n = 87,108)
Enrolled 2nd Spring

0.922

0.011
(0.029)
0.019
(0.034)

-0.005
(0.018)
-0.001
(0.020)

-0.018
(0.015)
-0.017
(0.016)

0.836

0.024
(0.055)
0.047
(0.063)

-0.007
(0.030)
0.009
(0.033)

-0.033**
(0.015)
-0.019
(0.014)

Enrolled 3rd Fall
(max n = 57,997)
Enrolled 3rd Spring

0.868

0.024
(0.043)
0.024
(0.043)

-0.002
(0.024)
-0.003
(0.024)

-0.023
(0.017)
-0.024
(0.018)

0.759

0.053
(0.073)
0.059
(0.073)

0.007
(0.037)
0.012
(0.036)

-0.027*
(0.014)
-0.023
(0.015)

Enrolled 4th Fall
(max n = 29,364)
Enrolled 4th Spring

0.826

0.025
(0.050)
-0.006
(0.051)

-0.003
(0.027)
-0.031
(0.032)

-0.028
(0.018)
-0.063*
(0.031)

0.720

0.055
(0.078)
0.024
(0.075)

0.009
(0.039)
-0.018
(0.040)

-0.027
(0.016)
-0.061*
(0.031)

X

X
X
X

X

X
X
X

Individual characteristics
Institution ACT score
Exclude UM-Ann Arbor

0.896

0.847

0.779

0.794

0.735

0.676

Notes: Each cell reports the coefficient on indicator for "Flat Pricing" at first institution attended from a separate regression. Sample is restricted to MI public high school
graduates from 2008 to 2011 that enrolled in a MI public university in the fall immediately after high school graduation. All models include cohort fixed effects. Individual
controls include dummies for female, black, Hispanic, other race, LEP and FARM and composite ACT score. Robust standard errors clustered by first college appear in
parentheses: *** p<0.01, ** p<0.05, * p<0.1.

