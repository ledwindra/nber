{
    "id": 28664,
    "citation_title": "Do Workfare Programs Live Up to Their Promises? Experimental Evidence from Cote D\u2019Ivoire",
    "citation_author": [
        "Marianne Bertrand",
        "Bruno Cr\u00e9pon",
        "Alicia Marguerie",
        "Patrick Premand"
    ],
    "citation_publication_date": "2021-04-12",
    "issue_date": "2021-04-08",
    "revision_date": "None",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Experimental Design",
        "\n",
        "Public Economics",
        "\n",
        "National Fiscal Issues",
        "\n",
        "Health, Education, and Welfare",
        "\n",
        "Poverty and Wellbeing",
        "\n",
        "Labor Economics",
        "\n",
        "Labor Supply and Demand",
        "\n",
        "Development and Growth",
        "\n",
        "Development",
        "\n"
    ],
    "program": [
        "\n",
        "Development Economics",
        "\n",
        "Labor Studies",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nWorkfare programs are one of the most popular social protection and employment policy instruments in the developing world. They evoke the promise of efficient targeting, as well as immediate and lasting impacts on participants\u2019 employment, earnings, skills and behaviors. This paper evaluates contemporaneous and post-program impacts of a public works intervention in C\u00f4te d\u2019Ivoire. The program was randomized among urban youths who self-selected to participate and provided seven months of employment at the formal minimum wage. Randomized subsets of beneficiaries also received complementary training on basic entrepreneurship or job search skills. During the program, results show limited impacts on the likelihood of employment, but a shift toward wage jobs, higher earnings and savings, as well as changes in work habits and behaviors. Fifteen months after the program ended, savings stock remain higher, but there are no lasting impacts on employment or behaviors, and only limited impacts on earnings. Machine learning techniques are applied to assess whether program targeting can improve. Significant heterogeneity in impacts on earnings is found during the program but not post-program. Departing from self-targeting improves performance: a range of practical targeting mechanisms achieve impacts close to a machine learning benchmark by maximizing contemporaneous impacts without reducing post-program impacts. Impacts on earnings remain substantially below program costs even under improved targeting.\n\n",
    "acknowledgement": "\nThis paper is the result of a collaboration with the government of C\u00f4te d\u2019Ivoire. The public works intervention we study is part of an Emergency Youth Employment and Skills Development Project (PEJEDEC), funded by the World Bank and managed by BCPE, the Coordination Office for Employment Programs (\u201cBureau de Coordination des Programmes Emploi\u201d), under the Ministry of Labor and Social Affairs of C\u00f4te d'Ivoire. Data collection for the study was financed by PEJEDEC. Additional funding for the study came from the MESF and DIME i2i Trust Funds at the World Bank. Cr\u00e9pon consulted for the World Bank during study implementation. Premand worked for the World Bank during study implementation. Marguerie consulted for BCPE during study implementation and currently works for the World Bank. We are very thankful to Adama Bamba, Hermann Toualy, Ismahel Abdoul Barry and Fabrice Konan at BCPE; Marius Pokou, Martin Kouakou, Yves N\u2019Cho and Kassi Ernest Bohoussou at AGEROUTE; as well as Hamoud Wedoud Abdel Kamil at the World Bank. We thank Sondo Eloi Somtinda for outstanding field coordination throughout the study; Hugues Kouadio, Rosine Addy Mosso, Marie Judith Soro and Nathaniel Gbenro at ENSEA for leading baseline and midline data collection; as well as Jean Awe and Ismahel Abdoul Barry at BCPE for leading endline data collection. Horacio Vera Cossio, Morgane Hoffmann and Bertille Picard provided excellent research assistance and contributions, in particular on machine learning applications. Morgane Hoffmann drafted the machine learning appendix. We are deeply indebted to Susan Athey, Stefan Wager, Jonathan Davis and Jann Spiess for their suggestions on machine learning implementation. We thank Lori Beaman, Christopher Blattman, Stefanie Brodmann, Deon Filmer, Emanuela Galasso, Jessica Goldberg, Rema Hanna, Clement Imbert, Michael Knaus, Michael Lerner, William Parient\u00e9, Anthony Strittmatter, Dominique Van de Walle and seminar participants at CREST, UChicago, CSAE, ILO, IZA, St-Gallen and the World Bank for useful comments and suggestions. Computational reproducibility has been verified by DIME analytics. The findings, interpretations, and conclusions of the paper are those of the authors. They do not necessarily represent the views of the World Bank and its affiliated organizations, or those of the Executive Directors of the World Bank or the governments they represent, nor those of the National Bureau of Economic Research.\n\n\n"
}