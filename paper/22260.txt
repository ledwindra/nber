NBER WORKING PAPER SERIES

RECRUITING AND SUPPORTING LOW-INCOME, HIGH-ACHIEVING STUDENTS
AT FLAGSHIP UNIVERSITIES
Rodney J. Andrews
Scott A. Imberman
Michael F. Lovenheim
Working Paper 22260
http://www.nber.org/papers/w22260

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2016
We gratefully acknowledge that this research was made possible through data provided by the
University of Texas at Dallas Education Research Center. The conclusions of this research do not
necessarily reflect the opinions or official position of the Texas Education Agency, the Texas
Higher Education Coordinating Board, or the State of Texas. We would also like to thank Sara
Muehlenbein, Alyssa Carlson and Mark Lu for excellent research assistance. We are further
grateful for generous financial support for this project provided by the Greater Texas Foundation,
the Russell Sage Foundation and the William T. Grant Foundation. Finally, we'd like to thank
seminar participants at the Association for Education Finance and Policy Annual Meeting,
Brookings Institution, CESifo Economics of Education Conference, Dalhousie University,
Institute for Research on Poverty Summer Research Workshop, Michigan State University,
Middle Tennessee State University, NBER Education Working Group Meeting, Society of Labor
Economists Annual Meeting, the Swedish Institute for Social Research (SOFI), Syracuse/Cornell
Summer Education Seminar, United States Military Academy, University of Michigan,
University of Rochester, University of Virginia, and Vanderbilt University for helpful comments.
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2016 by Rodney J. Andrews, Scott A. Imberman, and Michael F. Lovenheim. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.

Recruiting and Supporting Low-Income, High-Achieving Students at Flagship Universities
Rodney J. Andrews, Scott A. Imberman, and Michael F. Lovenheim
NBER Working Paper No. 22260
May 2016
JEL No. H75,I23,J24
ABSTRACT
We study two interventions in Texas that were designed to overcome multiple hurdles faced by
low-income, high-ability college students. The Longhorn Opportunity Scholars (LOS) and
Century Scholars (CS) programs recruited at specified low-income high schools, provided
additional financial aid, and enhanced support services once enrolled in college if students
attended University of Texas - Austin or Texas A&M - College Station, respectively. These
flagship institutions are widely regarded as the top public universities in Texas. Using
administrative data that links K-12, postsecondary, and earnings records for Texas public college
students, we find via difference-in-differences estimates that the LOS program had a large,
positive effect on high-achievers: attendance at UT-Austin increased by 2.2 percentage points
(81%), and the likelihood of graduating from UT-Austin increased by 1.7 percentage points
(87%). Twelve or more years post-high school, earnings of those exposed to LOS rose by 4.0%.
These results entirely come from women, who saw enrollment at UT-Austin increase by 4.0
percentage points, graduation from UT-Austin increase by 2.6 percentage points and earnings
increase by 6.1%. We find no evidence that the CS program affected any postsecondary or labor
market outcomes. These results indicate that targeted recruitment combined with adequate
supports and financial aid can substantially increase enrollment of low-income students in higher
quality colleges and improve labor market outcomes. However, the differences in the LOS and
CS program effects highlight the importance of understanding how to design these programs to
maximize their impact on students.
Rodney J. Andrews
The University of Texas at Dallas
800 West Campbell Road
MS WT21
Richardson, TX 75080
and NBER
rodney.j.andrews@utdallas.edu

Michael F. Lovenheim
Department of Policy Analysis and Management
Cornell University
102 Martha Van Rensselaer Hall
Ithaca, NY 14853
and NBER
mfl55@cornell.edu

Scott A. Imberman
Michigan State University
486 W. Circle Drive
110 Marshall-Adams Hall
East Lansing, MI 48824-1038
and NBER
imberman@msu.edu
A online appendix is available at http://www.nber.org/data-appendix/w22260

1

Introduction

Changes in the US economy over the past several decades have led to historically high demand
for skilled labor (Autor, Katz and Kearney 2008), which has substantially increased the earnings
premium associated with having a college degree (Autor 2014). These rising returns to college
investment have been met with sluggish increases in postsecondary attainment, particularly
among students from low-income backgrounds (Lovenheim and Reynolds 2013; Bailey and
Dynarski 2011). The postsecondary education investment gap across the income distribution
combined with the large earnings premium associated with collegiate training suggests that
the current higher education system may contribute to, rather than mitigate, growing income
inequality in the US. Indeed, some evidence suggests that changes in the earnings premium
associated with college can explain between 60 and 70 percent of the rise in income inequality
over the past several decades (Goldin and Katz 2007). Developing policies that can support
successful college investment by students from low-income backgrounds is of primary policy
importance.
Differences in postsecondary attainment between low-income and high-income students take
two forms. The first is that students from low-income families are much less likely to attend
college at all (Bailey and Dynarski, 2011; Carneiro and Heckman, 2002).1 The second type
of investment gap, which has received far less attention, is that low-income students tend to
enroll in schools of lower quality than their higher-income counterparts (Hoxby and Avery
2013). In the NLSY97, only 2% of low-income students attended a flagship public school, while
among the highest-income students 16% did.2 The likelihood of attending a private school also
increases with income, and the proportion of students enrolling in a two-year school declines
with income. There is substantial evidence of large impacts of college quality on completion
(Cohodes and Goodman 2014; Bound, Lovenheim and Turner 2010), time to degree (Bound,
Lovenheim and Turner 2012), and subsequent earnings in the labor market (Andrews, Li and
Lovenheim 2016; Hoekstra 2009; Black and Smith 2006, 2004; Brewer, Eide and Ehrenberg
1 Tabulations from the 1997 National Longitudinal Survey of Youth (NLSY97) show that while only 13% of students from families
with earnings over $125,000 do not attend college, 56% of students from families with income below $25,000 do not attend college.
As family income increases, the likelihood of attending college increases steeply.
2 This is not just a reflection of the differences in enrollment. Among those who enroll in any college, 3.7% of low-income students
enroll in a public flagship university, and 18.4% of high income students enroll in this school type.

1

1999).3 Hence, differences in college quality between low-income and high-income students
could significantly affect gaps in both collegiate attainment and earnings.
To develop policies to address the gaps in postsecondary investment that exist across the
income distribution, it is critical to understand why they are present. There are five main explanations for why students from low-income households tend to graduate from college in general,
and from more elite colleges in particular, at lower rates. First, families with fewer resources
at the time of college usually have fewer resources with which to invest in a child throughout
his or her life. These “long run credit constraints” create differences in academic preparation
for college among high school students (Cameron and Taber 2004; Carneiro and Heckman,
2002). Second, there is increasing evidence that low-income students face information gaps
that often preclude them from applying to and enrolling in more selective schools, even when
they are academically qualified to do so and would pay little to nothing in out-of-pocket costs
(Hoxby and Avery 2013; Hoxby and Turner 2013). A third explanation is that low-income students are affected by both academic and social “mismatch” when they enroll in higher-quality
schools. On average, these students have worse academic preparation for college and often are
not part of the dominant cultural majority, particularly at more elite postsecondary institutions
(Aucejo, Arcidiacono and Hotz 2013; Arcidiacono and Koedel, 2014; Arcidiacono et al., 2011;
Dillon and Smith 2013). Mismatch effects could lower academic attainment among low-income
students who enroll in more-selective colleges. Fourth, the complexity of the financial aid application may prevent students from applying for aid, and thus attending more expensive schools
(Dynarski and Scott-Clayton, 2013, 2008, 2006; Bettinger, et al., 2012). Finally, resource constraints at the time of the college enrollment decision may prevent families from investing in a
higher-quality school (Lovenheim and Reynolds 2013).
Prior research has found at most modest effects on student outcomes of policies designed to
overcome any one of these disadvantages. One explanation for these results is that there are
interactive effects of student disadvantage, making it necessary for programs to address several
of these barriers simultaneously to effectively support postsecondary education among students
from low-income backgrounds. In this paper, we present what is to our knowledge the first
3 Dale and Krueger (2013, 2002) find little overall impact of college quality on earnings, but they do find sizable returns to college
quality for low-income students.

2

analysis in the literature of interventions aimed at addressing this broad array of disadvantages
faced by low-income students. The Longhorn Opportunity Scholarship (LOS) program at the
University of Texas at Austin (UT ,) and the Century Scholars (CS) program at Texas A&M
University – College Station, which are the two flagship schools of the Texas public higher
education system, began in 1999 and 2000, respectively.4 The programs targeted Texas public
high schools that served low-income students in urban areas and traditionally sent few students
to these institutions. Together, the LOS and CS programs were implemented in 110 high schools
in Texas.
While entirely independent, both programs offered a suite of interventions that attempt
to overcome the multiple disadvantages faced by low-income students in the higher education
system: lack of information about college quality, less academic preparation for college, and
lower financial resources. The programs engage in extensive outreach and recruiting, with
university staff providing information sessions and, for the CS program, students going back
to their high schools to share their experiences. This outreach and recruitment of students
from low-income high schools helps overcome information barriers that may preclude students
from these schools from applying to and enrolling in an elite postsecondary school. Program
participants also are provided scholarships to help alleviate financial strain. Since most of these
students qualified for substantial Federal grants, students in these programs would often have
sufficient grant aid to fully cover tuition and fees.5 Once enrolled, the LOS and CS programs
include multiple but distinct academic support services for students as well as policies that
help foster cohesion among the students. These services can help overcome social and academic
mismatch. Critically, the programs did not provide students with help in the admissions process;
all students who were induced to attend UT-Austin and Texas A&M were academically qualified
to attend those schools in the absence of these interventions.
We use administrative data from the State of Texas that links K-12 education records with
higher education enrollment and performance information as well as earnings records from the
4 Details

on the Century Scholars program can be found at https://scholarships.tamu.edu/Scholarship-Programs/
Century-Scholars. The Longhorn Scholars Program has since been discontinued though a description can be found in internet archives at https://web.archive.org/web/20030622194253/http://www.utexas.edu/student/finaid/scholarships/los_
index.html.
5 For example, CS scholars currently receive $5,000 per year for four years. Assuming scholarship amounts did not change, this
covered most of the $5,639 cost for tuition and fees in 2004. Similarly, LOS scholars in 2002 received $4,000 per year from the
program. Tuition at UT-Austin in 2005 was $7,286.

3

Texas unemployment insurance system. We exploit the roll-out of the LOS and CS programs
to identify their effects on higher education outcomes and post-college earnings in a differencein-difference framework. Because these interventions were targeted towards high-performing
students, we first generate a performance index using students’ high school test score information. Our analysis focuses on high-achieving students, who we define as the top 30% of
students within each high school on this performance index. The LOS and CS treatments targeted schools serving disadvantaged populations; many untreated high schools (such as those in
wealthy suburban areas) differ substantially from treated schools in both their observed characteristics and outcomes, which makes them poor candidates for inclusion in the control group
to estimate counterfactual trends. We therefore construct “trimmed common support” samples
for each intervention using the rich information we have about the demographics and collegesending patterns of each high school in Texas prior to 1999 combined with information on the
criteria UT-Austin and Texas A&M say they used to select the schools. Hence, our resulting
analysis samples are comprised of the set of schools that are more observationally-similar across
the treatment and control groups than would be the case if we used all public high schools in
Texas.
Conditional on the observed characteristics of schools, much of the targeting for these programs was based on geography. This makes it likely that there are equivalent control schools
that did not receive the treatment because of where they were located rather than because
of the populations of students they serve. We estimate difference-in-difference models using
these trimmed common support samples in which we compare changes in outcomes among
high-ability students in treated schools to changes in outcomes for high-ability students in
observationally-similar untreated schools when the LOS/CS programs are implemented. The
main identification assumption in these models is that the trends in enrollment patterns and
outcomes among high-achieving students would have been the same in treated and control high
schools absent the programs. We show extensive evidence of common trends in enrollment behavior, postsecondary outcomes, and labor market outcomes prior to the implementation of the
treatments and find little evidence of demographic shifts among students due to the treatments.
These findings strongly support our empirical strategy.

4

The results of our analysis differ across programs. The LOS program had a large effect on
the likelihood students enrolled in UT-Austin, increasing the enrollment rate by 2.2 percentage points (81% of the pre-treatment mean). These students were drawn predominantly from
“emerging research universities” (ERUs), which are the set of public four-year schools that
are the next quality tier down from the flagships. Six-year graduation rates from UT-Austin
increased substantially among students at LOS high schools: they were 1.7 percentage points
(87% of the pre-treatment mean) more likely to graduate from UT-Austin. While there is no
significant increase in overall graduation rates, we nonetheless find that earnings of high achieving students who attended LOS high schools increased by 4% twelve or more years after HS
graduation. Given that the treatments are a package that includes an increase in college quality
for some, extra financial aid for most, and support services while enrolled for all who participate, one can reasonably approximate a treatment on the treated effect by scaling the earnings
effect by the share of students in the treated sample who attend UT after the program begins.
This back-of-the-envelope treatment effect is equivalent to a 70% increase in earnings. While
large, we argue this effect size is reasonable when one considers that the targeted population is
high achieving, low income, and heavily minority. Such groups may be especially sensitive to
an intervention like this. We further note that all of the effects we see are concentrated among
women. There is no impact on either male enrollment or earnings but a 4.0 percentage point
increase in female UT enrollment and a 6.1% increase in female earnings.
In contrast to the LOS results, the CS program does not lead to a change in where students
attend college. In particular, it does not increase the likelihood students attend Texas A&M –
College Station, nor does it reduce UT-Austin enrollment. Consistent with the lack of enrollment effects, our results do not point to any impact of the CS program on postsecondary or
labor market outcomes. It is somewhat surprising that the CS and LOS programs have such
different effects. We argue this difference is likely driven by the fact that the LOS program was
larger in scope and the academic support services were more intensive. All students attending
UT-Austin from an LOS school received the academic support services, in contrast to the CS
program that limited services to scholarship recipients. The LOS support services were much
more academically-focused than in CS as well, and conversations with an LOS program official

5

suggests that the recruitment efforts associated with the LOS program were more intensive.
While the LOS program generates large long-run benefits for exposed students, the CS results
suggest that the design and implementation of these programs matter. Our findings underscore
the promise of the type of comprehensive support strategies we study but also highlight the
need to understand how best to design them in order to maximize their positive effects.

2

The Longhorn Opportunity and Century Scholars Programs

2.1

Program Description

The Longhorn Opportunity Scholars and Century Scholars Programs were first implemented in
1999 and 2000, respectively, to increase enrollment rates for low-income and minority students
at UT-Austin and Texas A&M in the wake of the state’s 1997 affirmative action ban. This ban
made it illegal for schools in the state to consider race as a factor in either admissions or the
provision of financial aid. The pre-existing affirmative action system was replaced by the Texas
Top 10% Rule in 1998, which stipulated that any student in the top 10% of his or her high
school class could attend any Texas public university.6 Post-1997, the vast majority of students
in UT-Austin and Texas A&M were admitted under this rule. As a result of the Top 10% rule,
during the period we study, students ranked outside the top 10 percent of their class at high
schools serving low-income students were very unlikely to enroll in UT-Austin or Texas A&M.
Despite the fact that many students from low-income schools became eligible to attend Texas
A&M and UT-Austin under this rule, minority enrollment at these colleges fell dramatically
(Kain, O’Brien and Jargowsky 2005). In response to these declines, the LOS and CS programs
were developed to try to recruit students from low-SES backgrounds to the state flagships and
to support their academic success while enrolled. The LOS program targeted 70 high schools
in Houston, Dallas, San Antonio, El Paso, Beaumont and Laredo that had high shares of
low-income and minority students and few prior applicants to UT-Austin. The CS program
similarly targeted 70 low-income schools in Houston, Dallas and San Antonio with few prior
applicants to Texas A&M.7 There was some overlap between the two programs, with students
6 The

ranking is determined by each high school separately, but typically is based on student grade point average.
2003, the CS program has expanded further and the LOS program has been replaced by the Discovery Scholars Program.
This program has many of the same elements as LOS, but eligibility is individual-based rather than high-school-based and support
services are separated from scholarships. We do not study post-2002 cohorts in this analysis because they are too young to obtain
7 Since

6

from several high schools being eligible for both programs. Over 600 students are admitted
to Texas A&M and UT-Austin under these programs each year. Figures 1 and 2 show the
geographic distribution of LOS and CS schools in our estimation sample, respectively. They
are mostly located in the large urban centers in the state; the focus of these programs is on the
urban poor. That these interventions are isolated to specific cities in Texas allows us to find
similar schools throughout the state that are untreated to form our control group.
Though administered by different universities, the two programs are similar in a number of
ways. First, most students are given additional financial aid if they enroll in the flagship school
running the specific program. Second, there is an active recruiting effort made at targeted high
schools to try and overcome any information barriers about cost, the likelihood of admission,
and the value of attending a higher-quality school that may have existed. Third, once enrolled,
the LOS and CS students are given access to academic support services. Fourth, both programs establish formal enrolled student and alumni communities that offer support, guidance,
networking and resources.
Despite these similarities, there are two substantive differences across the programs that
could lead them to have different effects on student outcomes. The first is their scope. For
LOS, initially the plan was to only offer services to students who received financial support
from the program, restricted to a maximum number of scholarships per high school. However,
in practice they allowed all enrolled students from targeted schools to receive program services
(but not the scholarship money). Furthermore, an administrator of the LOS program informed
us that students who did not qualify for LOS scholarship money directly usually qualified for
other scholarships. For CS, students from targeted high schools only received the academic
support services if they are awarded the scholarship money. Students also had to maintain a
minimum GPA in order to keep their CS fellowship.
The second difference between the programs is in the type of academic support services
offered. Under the LOS program, students were offered extensive support, including guaranteed
spaces in residence halls, free tutoring, and peer mentoring. In addition, the LOS program had
students enroll in small sections of introductory courses in mathematics, chemistry, biology,
economics and other fields exclusively for LOS students. These courses were widespread across
reliable earnings estimates in our data.

7

the university in multiple subject areas providing numerous opportunities for LOS students to
take advantage of the courses. A list of courses with exclusive LOS sections is provided in Online
Appendix Table A1. Instructors for these sections taught the same content but could tailor the
instruction to recognize that the students were coming from disadvantaged backgrounds and
likely had a lower baseline set of skills than the average first-year student. This may have been
particularly useful in difficult courses in math and science where these types of course sections
were popular. The academic support services in the CS program were much less extensive and
entailed faculty mentoring (in lieu of peer mentoring) as well as professional training in public
speaking, interviewing and presentation skills, while also maintaining a community service
requirement.
These interventions could influence several important postsecondary outcomes and earnings
in ambiguous directions that point to the need for an empirical analysis. In particular, we
might expect the LOS/CS programs to have a positive effect on student outcomes because
of the overall positive effects of college quality on educational attainment and earnings (e.g.,
Andrews, Li and Lovenheim, 2016; Bound, Lovenheim and Turner 2010; Hoekstra 2009; Black
and Smith 2004, 2006; Brewer, Eide and Ehrenberg 1999).8 Ex-ante, the LOS/CS programs
should increase the likelihood that students enroll in UT-Austin and Texas A&M. Indeed,
in interviews with ten freshmen recipients of the Longhorn Opportunity Scholarship, Bhagat
(2004) finds that the financial, social, and academic supports offered by LOS were the primary
reasons that students selected the University of Texas at Austin, suggesting that the programs
had positive effects on enrolling. This is consistent with the evidence in Domina (2007) of higher
flagship enrollment after the LOS/CS program implementation and Andrews, Ranchhod and
Sathy (2010) of higher SAT score sending to the flagships - a proxy for intent to apply to
a given school - among students in treated high schools. Outside of the flagships, the other
options for these students typically are worse in terms of the quality and resource levels of the
institution, including attending lower-quality four-year schools, attending a two-year college or
not attending college at all. We examine the enrollment effects of these programs directly below
using richer and more comprehensive data on enrollment than were used in this prior work.
8 Another potential mechanism is that increased financial support provided by the programs may help students progress through
the higher education system by relaxing credit constraints. However there is very little evidence that credit constraints or financial
aid have more than a modest impact on students’ paths through college (e.g., Johnson 2013; Stinebrickner and Stinebrickner 2008;
Bettinger 2004).

8

Our results suggest a more nuanced story that differs across LOS and CS treatments.
To the extent that the LOS and CS programs increased flagship enrollment, they would
lead to a substantial increase in college quality for treated students. To provide some context,
USNews and World Report ranks UT-Austin as the 58th and TAMU as the 68th best national
universities. The next highest public institutions in the state are UT-Dallas, ranked 145, Texas
Tech, ranked 156, and University of Houston at 186. Table 1 provides information on selectivity
and resources of Texas public institutions. The table compares University of Texas at Austin
and Texas A&M to “emerging research universities” (ERUs) and other four-year schools.9 The
means in the table show that both flagships are substantially more selective than the ERUs
and other 4-year institutions as measured by SAT scores of incoming students. The flagships
also spend substantially more per-student, have lower student-faculty ratios, higher graduation
rates and higher retention rates.
The ambiguity in predicted impacts of the programs from college quality improvements
arises because of potential tension between overall college quality effects and the potential for
academic “mismatch” that can occur when students of lower academic preparation are brought
into a more demanding educational environment.10 The students affected by the LOS and CS
programs tend to be high-achievers in their high schools, but because they come from lowincome schools, they still may be under-prepared for the academic rigor of a flagship university.
Indeed, this is the reason that the programs offer academic support services. If attending a
flagship causes these students to struggle academically, potentially leading to lower graduation,
persistence and earnings, then the LOS/CS programs could be harmful. This could be especially
problematic if the programs were simply recruiting students to attend or providing financial
aid. However, the LOS and CS programs provide a system of social and academic supports
that potentially mitigate, or even completely overcome, the effects of mismatch.
As a result of these conflicting theoretical impacts, a priori, it is not possible to determine the
net effect of the targeted recruitment programs. The success or failure of these programs hence
must be determined empirically. In addition to potentially reducing educational inequities,
9 The ERU designation is for institutions that are eligible for a special pool of state funds for increasing research output. These
are sometimes called “Tier 1” schools as part of the goal of the program is to increase the schools’ research and academic reputations
to the top tier of public universities in the US. For our purposes, this is a useful distinction as it provides a “second tier” of public
institutions below the flagships but with better resources than other institutions. This group includes UT Arlington, UT El Paso,
UT Dallas, UT San Antonio, Texas Tech University, University of North Texas, and the University of Houston.
10 See Arcidiacono and Lovenheim (2015) for an overview of the “quality-fit” tradeoff in higher education.

9

these programs may also help reduce income inequality if there are positive labor market impacts. Hence, it is critical to examine their effects on long-term outcomes such as educational
attainment and earnings. These arguments underscore the importance of conducting a rigorous
analysis that can identify the effects of these targeted recruitment programs on students.
2.2

Prior Literature

No prior work exists that examines the impact of a multifaceted treatment aimed at addressing
the multiple disadvantages faced by students from low-income backgrounds at selective higher
education institutions. However, there are several important studies that have examined programs containing individual components of the CS and LOS treatments. In particular, prior
work has examined the impacts of college outreach programs and financial aid, with very little
research being done on targeted college services. An important contribution of our analysis
stems from the fact that it may not be enough to merely address one of the disadvantages faced
by low-income students. Instead, to increase the postsecondary attainment of such students,
particularly at highly-selective schools, it may be necessary to provide interventions that simultaneously affect a range of student disadvantages. Our study is the first to provide evidence on
this type of broad intervention.
Previous research on college outreach programs has not found strong evidence they improve
student academic outcomes. Using National Education Longitudinal Study of 1988 (NELS:88)
data, Domina (2009) studies the effect of being exposed to a college outreach program that
provides information on the college application process and, in some cases, tutoring support and
college counseling services for high school students. Domina reports that about 5% of students
in the NELS:88 sample are exposed to such a program. Using propensity score matching
techniques, he finds little evidence that exposure to an outreach program influences high school
achievement or college enrollment. In a randomized controlled trial of Upward Bound, Myers
et al. (2004) find largely the same results, except for a positive four-year college enrollment
effect.
These studies do not examine the impact on college quality other than the four-year/2-year
margin. However, a major effect of the type of college outreach embedded in the CS/LOS

10

programs might be to influence students to attend a flagship rather than a non-flagship school.
There is some evidence that college outreach can positively influence the quality of schools to
which students apply and enroll. Hoxby and Turner (2013) conduct a randomized controlled
trial in which they send personalized information to high-achieving, low-income students on
college enrollment strategies, expected financial aid, and their likelihood of admission. They
find large increases in the quality of colleges to which students apply. The LOS and CS programs provide similar information as well as direct, in-person recruiting, and could have large
effects on the college choices made by students in the targeted high schools.11 For academic service provision, Angrist, Lang and Oreopoulos (2009) and Clotfelter, Hemelt, and Ladd (2016)
provide the analyses most relevant to our study. In the former, the authors randomly assign
students to receive peer mentoring and other services and/or financial incentives. They find that
the services and incentives combined led to academic gains for women. The latter study looks
at a program at University of North Carolina - Chapel Hill that provides financial assistance
and academic support services to low income students. While they are not able to assess the
impact of the program on sorting across schools (and hence see how it affects college quality) or
labor market outcomes, they find significant increases in grades and graduation rates. Further,
neither program had a recruitment component, which is a key feature of both the LOS and CS
treatments.
Our research also relates to a body of work that examines the effect of financial aid on
student collegiate choices and outcomes. Evidence from state merit aid programs that offer
free or highly-reduced tuition to in-state students who attend a public institution suggest these
programs are successful at altering the college enrollment decisions of high-achieving students
(Cohodes and Goodman 2014; Cornwell, Mustard and Sridhar 2006; Dynarski 2000). However,
these programs do not tend to increase students’ academic performance in college and may
reduce performance because they induce many students to enroll in lower-resource schools than
they otherwise would have (Cohodes and Goodman 2014; Fitzpatrick and Jones 2012; Sjoquist
and Winters 2012). Recent evidence from a randomized private scholarship in Nebraska, however, suggests aid receipt increases four-year enrollment, persistence and completion (Angrist
11 Other work has focused on reducing psychic and financial barriers to the application process. For example, Bettinger et. al.
(2012) find that providing assistance with the FAFSA increases college applications and enrollment amongst low income students
while Pallais (2015) finds that increasing access to free ACT score reports increases the amount of schools low income students
apply to and the quality of the schools they attend.

11

et al. 2014).
Importantly, the LOS and CS programs should have the opposite college quality effect to
what has been found in the merit aid literature. The likely alternative for these students is
a less-selective and lower-resource state university, community college or no college at all.12
UT-Austin and Texas A&M-College Station have much higher per-student expenditures, lower
student-faculty ratios and significantly higher 6-year graduation rates (Table 1). In addition,
both flagships have student bodies with higher measured pre-collegiate academic ability relative
to other public colleges and universities in Texas, as measured by the SAT score. Any resulting
peer effects, therefore, may play a role in driving the education differences across these schools
and could have a positive impact on LOS/CS students (Stinebrickner and Stinebrickner 2006;
Zimmerman 2003; Sacerdote 2001).
Finally, much prior research has examined the Texas Top 10% rule, which provides an important institutional backdrop for our analysis. The Top 10% rule was implemented in 1998
as an alternative to affirmative action. It gave automatic admission to any student in the top
10% of his or her high school class to any public college or university in Texas. There is a
large literature exploring the effect of the Texas Top 10% rule on enrollment and completion
outcomes, especially among minority students. This research tends to find that the plan increases enrollment among high-achieving students at flagship schools (Daugherty, Martorell and
McFarlin 2014; Niu and Tienda 2010; Domina 2007;), especially those who were in high schools
that traditionally did not send many students to these schools (Long and Tienda 2008; Domina
2007). The effects on completion are more ambiguous, with some studies finding a negative
effect (Cortes 2010) and some finding no effect (Daugherty, Martorell and McFarlin 2014). We
discuss in Section 4 how this policy affects our identification strategy.

3

Data

The data we use in this study come from three sources: administrative data from the Texas
Education Agency (TEA), administrative data from the Texas Higher Education Coordinating
12 While it is possible that some students would have attended private or out-of-state schools, such behavior is likely rare for the
population targeted by LOS/CS. We cannot directly test for such sorting with our data as we only observe attendance at public
institutions in Texas. However, we find no evidence that the likelihood of attending any postsecondary public institution changed
as a result of the programs.

12

Board (THECB), and quarterly earnings data from the Texas Workforce Commission (TWC).
The data are housed at the Texas Schools Project, at the University of Texas at Dallas Education
Research Center (ERC). These data allow one to follow a Texas student from Pre-Kindergarten
through college and into the workforce, provided individuals remain in Texas. We discuss each
of these data sets in turn.
Beginning in 1992, the TEA began collecting administrative data on all students enrolled in
public schools in Texas. These data contain students’ grade level, the school in which he or she
is enrolled, scores from state standardized tests, and a host of demographic and educational
characteristics such as race/ethnicity, gender, special education status, whether the student is
eligible for free or reduced-price lunch, whether the student is at risk of dropping out, and
enrollment in gifted and talented programs. The test score data we use are from the 11th grade
Texas Assessment of Academic Skills (TAAS) exams for reading, writing and mathematics.
The TAAS exams were administered to all students in Texas through 2002, and they were
“high stakes” in the sense that students had to achieve a passing score on them in order to
graduate. Because students can retake them, we use the lowest score for each student, which
typically corresponds to the score from the first time students take the exam. Although the
TEA data begin in 1992, in 1994 Texas redesigned the high school exams. We therefore restrict
to students who graduate in the high school classes of 1996-2002.
The LOS/CS programs targeted only high-ability students at each school. Hence, we focus
our analysis on the top of the within-school achievement distribution. We estimate the students’
academic ability as the first principal component of a factor analysis model that includes 11th
grade TAAS scores on mathematics, reading and writing. As argued by Cunha and Heckman
(2008) and Cunha, Heckman and Schennach (2010), combining test scores in a factor model
provides a stronger proxy for student academic ability than using any one test score alone. Using
this academic ability factor, we rank students in his or her school-specific 11th grade cohort.
Andrews, Li and Lovenheim (2016) present evidence that the within-high school rank on these
exams is highly correlated with whether one is admitted to a flagship university through the
Top 10% Rule,13 which is evidence that the relative rank on these exams is a good proxy for
13 Specifically, Andrews, Li and Lovenheim (2016) show that admission through the Top 10% Rule is highly predictive of attending
UT-Austin or Texas A&M, but conditional on the relative rank on the TAAS test scores this variable loses its predictive power.

13

relative academic rank in each high school.
Our higher education data from the THECB contain detailed information about college enrollment and key collegiate outcomes for all students who enroll in a public college or university
in the State of Texas. For these students, we observe the enrollment decision in every public
college or university in each semester, major choice, and the timing of all degrees received.14
The quarterly earnings data from the TWC are from Q1 2007 through Q1 2015 and contain
earnings for every worker in Texas, with the exception of those working for the Federal Government or US Postal Service. Because the LOS and CS programs are relatively recent, we
are constrained in the length of the post-high school time period over which we can observe
earnings. We construct three measures of earnings to provide insight into the role of timing.
The first is average log quarterly earnings in all quarters in which earnings are observed six or
more years post-high school graduation. The second uses all earnings observations that are at
least ten years after high school graduation and the third uses twelve or more years after high
school.
To construct our earnings measure, we first restrict the sample to individuals with at least
five quarters of $100 or more earnings in the relevant time period (6+, 10+ or 12+ years after
high school graduation) and drop the highest 0.5% of overall earnings quarters due to the
long right tail of the earnings distribution.15 We then demean log quarterly earnings within
year-quarter-cohort bins so that earnings are relative to the mean earnings within a high school
graduating cohort at a given time.16 We then average the demeaned earnings within individuals
to generate an adjusted log earnings measure.
A limitation of our data is that students only are followed if they both attend college in
Texas and work in Texas in an industry covered by unemployment insurance. Biases due to
differential attrition associated with the rollout of LOS and CS therefore can occur both in the
14 Ideally we would be able to look at GPA as well but unfortunately collection of GPA data by the state was not universal across
institutions until 1999.
15 We provide details on results using alternative sample constructions in Online Appendix Table A-11. Dropping the top 0.5% of
earnings quarters has little affect on the earnings estimates but reduces the standard errors. The 99.5th percentile of the quarterly
earnings distribution is $94,928.
16 We also exclude all earnings that occur while an individual is enrolled in a Texas public graduate school as these earnings are
unlikely to be reflective of permanent earnings (we do not observe if the student is enrolled in a private or out-of-state graduate
school). Further, we note that a worker-quarter is only observed if the worker has positive earnings in that quarter. Missing
observations can be due to unemployment, labor force non-participation or leaving the State of Texas. We do not include missing
observations as zeros because we are unsure whether an individual has left the state or is not working and residing in Texas. These
sample restrictions and the way in which we construct our earnings measures are very similar to the methods used by Andrews, Li
and Lovenheim (2014; 2016) with these data.

14

analyses of postsecondary outcomes and earnings. When examining educational outcomes, the
main concern is that the LOS/CS programs could induce students who would have attended an
out-of-state or private school to move to the in-state flagship.17 This will show up as a change
in the extensive margin of college enrollment in our data, whereas in actuality such students
may be switching across postsecondary schools of similar quality. Of course, these students still
would receive the academic services once enrolled as well as the scholarship money. This type
of sorting likely would lead us to overstate program impacts, because the students induced to
switch schools from the private or out of state sectors probably are better academically-prepared
for college and are from less disadvantaged backgrounds than other students at LOS and CS
schools.
We address this potential bias in a few ways. First, we note that in the wider population
affected by LOS and CS, very few students attend out-of-state or private schools. Indeed, in
Texas overall only 18% of first-time 4-year college enrollees who were seniors in high school the
prior year attend an out-of-state school. While similar statistics for in-state private schools are
not available, only 12% of enrollment in Texas degree granting institutions is in private colleges.
Given the low income of students in LOS/CS schools, we would expect these numbers to be far
smaller for our population of interest.
Second, we estimate whether the LOS and CS programs have any impact on attending an instate public institution. Thus, the treatment effect is relative to not attending college, attending
a private college, or attending an out-of-state college. As we show below, we find little indication
that students from LOS or CS schools were more likely to be observed in the postsecondary data
after program implementation. Thus, for the programs to induce private/out-of-state students
to move to the flagships, there would have to be an offsetting increase in non-college attendance
by other treated students, which is very unlikely. Furthermore, we show that increases in
enrollment at the flagships are completely offset by an equivalent reduction in attendance in
other in-state public colleges.
Attrition bias also can occur in the earnings data due to migration out of Texas. We find
some evidence that treated students are less likely to be present in our earnings samples. We
17 Daugherty, Martorell and McFarlin (2014) show that the Top 10% rule had just such an effect on student college-going in a
low-income district.

15

address any biases from such differential attrition in two ways. First, we test whether attending
an LOS or CS school “affects” predetermined student characteristics in the earnings samples
relative to students in comparison high schools. Second, we generate predicted earnings of
students based on their high school characteristics and test whether the LOS and CS programs
change the predicted earnings of those not in the earnings data. We find no evidence that the
targeted recruitment programs generate differences in pretreatment characteristics for students
in the earnings sample. Our results also indicate that those differentially attriting from the
earnings sample due to LOS/CS exposure have higher predicted earnings based on the large
set of pre-collegiate characteristics we observe. These tests indicate that our earnings estimates
likely do not suffer from attrition bias or, at worst, that our estimates are attenuated due to
the differential attrition of those with high predicted earnings.

4

Methodology

Our methodological approach to examining the effect of the LOS/CS programs on student college choice, academic outcomes and labor market earnings is to estimate difference-in-differences
models in which we compare changes in outcomes among cohorts of students when their school
becomes treated to changes among cohorts of students in observationally-similar schools that
are not treated. As discussed above, the LOS and CS programs are most likely to affect higherability students. We therefore restrict the analysis to students who are in the top 30% of their
high school class in a given year according to the ability index discussed in Section 3. We focus
on the top 30% of students rather than the top 10% because our ability index is an imperfect proxy for class rank. The top 30% of students accurately captures the large majority of
groups that are potentially eligible for enrollment in a state flagship from schools in our sample.
This feature of the data is highlighted in Figure 3, which shows enrollment in UT-Austin from
LOS-targeted schools and in TAMU from CS-targeted schools both before and after program
implementation. The vast majority of enrollees in the flagships are in the top three deciles of
the achievement distribution in those schools.
Figure 3 clearly demonstrates that the LOS program positively affected the likelihood of
enrollment at UT-Austin among students in treated high schools. Prior to the program’s im-

16

plementation (1996-1998), enrollment at UT-Austin among college attendees from high schools
that would later be treated by the LOS program was below enrollment among students at
observationally-similar untreated schools. After the program is implemented, enrollment increases much more in LOS schools than in the comparison schools, especially in the top three
deciles where we focus our analysis. In the bottom panel, the enrollment patterns at Texas
A&M surrounding the implementation of the CS program are quite different. Here, Texas
A&M enrollment from the schools that will receive the CS treatment differs little from comparison schools in the pre-CS period except in the ninth decile, where comparison enrollment
decreases, and the tenth, where it increases relative to treated schools. The drop-off in top
decile enrollment is likely due to students from high schools with both programs preferring
UT-Austin.18
In order to estimate the causal effect of the LOS and CS programs on college and labor
market outcomes, we use a difference-in-differences model that allows us to identify intentionto-treat effects of the LOS and CS programs. Starting with LOS, we estimate the following
equation using LOS-treated schools and a sample of comparison schools that are similar to
the LOS schools in the observed characteristics used by UT-Austin to determine treatment
eligibility.
Yijt = α + β1 LOS Schooljt + β2 LOS&CS Schooljt + Xijt Γ + φj + θt + εijt ,

(1)

where Yijt is an educational or labor market outcome of interest for student i from high school
j who graduates from high school in year t, and X is a vector of individual characteristics
such as high school test scores, race, gender, and economic disadvantage status.19 The model
also contains school fixed effects (φj ) and year fixed effects (θt ). The school fixed-effects make
this equation a difference-in-differences model where the timing of treatment varies by school.
The main treatment variable, LOS School is an indicator for whether the graduating cohort in
school j and year t is eligible for LOS. The variable equals zero for students who graduate from
schools that will join LOS in the future as well as those in never LOS schools and becomes one
when a student’s graduating cohort is eligible for LOS scholarships and services if they attend
18 Appendix

Figure A-1 shows similar patterns for the sample of high school graduates in the top 30% of their high school.
considers a student to be economically disadvantaged if he or she is eligible for subsidized school lunches or is enrolled
in another state or Federal anti-poverty program.
19 Texas

17

UT-Austin. Hence, β1 gives us our estimate for the impact of attending an LOS high school
on outcomes of interest. A key restriction in this “LOS sample” is that schools that are only
eligible for CS and not eligible for LOS are excluded from the sample. This allows us to include
LOS&CS Schooljt as an interaction between the two programs in the model. Nonetheless, our
focus is on the main LOS effect; we include the interaction term to avoid contamination of the
intention to treat from one program with the effect of the other. Throughout this analysis,
standard errors are clustered at the high school level.
For the CS program we estimate a similar model using a sample (the “CS sample”) that
includes all CS schools as the treatment and a comparison group of schools that are observably
similar to the CS schools but do not include any schools that participated in only the LOS
program. Hence we estimate

Yijt = α + β1 CS Schooljt + β2 CS&LOS Schooljt + Xijt Ω + φj + θt + εijt ,

(2)

In this case, β1 provides the causal effect of attending a CS participating high school, while β2
removes contamination from the LOS program in schools where both programs operate at the
same time.
In equations (1) and (2), the treatment parameters show how outcomes change among top
30% students in LOS/CS schools relative to top 30% students in untreated schools when the
programs are implemented. Hence, the main assumption under which β1 is identified is that
the trends in outcomes among schools not receiving the treatment are accurately measuring
counterfactual trends among the treated schools. This identification assumption is potentially
strong, especially since the programs are targeted at low-income schools that could have substantially different trends than non-LOS/CS schools absent the treatment.
To make this identification assumption more plausible in our context, we restrict the set
of untreated schools to those high schools with common support among key observable characteristics that determine treatment. Using data from the 1996-1998 school years (which is
before either program was implemented but includes implementation of the Top 10% rule),
we estimate separate logit regressions of the likelihood a high school becomes an LOS or a
CS school as a function of quadratic polynomials in the following school-level characteristics:

18

percent enrolling in the targeted flagship in 1996, 1997 and 1998, percent economically disadvantaged, percent black, and percent Hispanic. The first variable accounts for recent trends in
under-representation at the specific flagship institution (UT-Austin or TAMU) by measuring
how many students actually enroll in the pre-treatment period, a key factor in determining
eligibility.20 The last three variables account for the socioeconomic makeup of students in the
schools that also are important determinants of whether a school receives the LOS or CS program. We use this model to calculate propensity scores that show the likelihood a given high
school is treated by each program. The logit regression coefficient estimates are shown in Online
Appendix Table A-2.
We first drop all treated schools with a predicted treatment likelihood higher than the highest
control school and then drop all schools that have propensity scores less than 0.2 to generate
a common support sample that will more accurately account for counterfactual trends. We
construct this sample separately for the LOS treatment and for the CS treatment, and the
resulting untreated schools together with the treated schools constitute the LOS sample and
the CS sample, respectively. Thus, our trimmed common support samples are comprised of a
set of schools that have broadly similar likelihoods of being treated based on their observable
characteristics.21 Figure 4 shows the propensity score densities for treated and control schools
by likelihood bin, separately for UT-Austin (LOS) and Texas A&M (CS). In the figure, we have
excluded the large mass of control schools with propensity scores below 0.2 as they dominate
the graph if included. Ostensibly, we are excluding a large set of high schools that serve higherSES students and that have no probability of being selected for the LOS/CS treatments. As
the figures demonstrate, there also are several treated schools that have a predicted likelihood
of treatment that is greater than any control school. These schools are excluded from the main
analysis because they are sufficiently different from any comparison school that it makes the
identification assumptions that underly our estimator more difficult to support.
Throughout the study, we focus on samples that restrict to college attendees who are in
the top 30% of their high school class as measured by our achievement index, as these are the
20 While the CS program does not specifically state what metrics they use to select schools, they do say in their handbook that
the program is intended to “to increase the number of enrolled and retained students from under-represented Texas high schools.”
The LOS program specifically states that they target high schools where sending of ACT and SAT score reports to UT-Austin are
low. Unfortunately, we do not have data on score reporting and thus we use actual enrollment history as a proxy.
21 We have also conducted our analyses using samples that drop control schools below the lowest treated schools and samples that
trim at a propensity score of 0.1. In both cases we get similar results.

19

students who are most likely to be impacted by the programs. We show below that there is
no impact on the college attendance margin, so there is little concern that the composition of
our college enrollment sample is endogenous with respect to the LOS or CS treatments. For
the sake of completeness, however we also provide the full set of estimates for a sample of all
high school graduates in the top 30% of their high school class in the online appendix. As
expected, the results for the high school grad sample are attenuated since we are increasing the
number of students who contribute to the intention to treat estimate without actually increasing
treatment propensity. Nonetheless, in most cases, the estimates maintain the same direction
with the same level of statistical significance as the college attendee sample.
Table 2 shows demographic and measured high school academic achievement characteristics
for top 30% students in our trimmed common support samples who attend college. For both
the LOS and CS estimation samples, students in the comparison schools are higher achieving
and more likely to be white. However, in the LOS sample the comparison schools are more
economically disadvantaged. These samples are much more similar to each other than they
are to schools that are not in the common support. Indeed, in both the treated and control
groups, the majority of students are African American or Hispanic, a large proportion are at
risk of dropping out of high school, and they exhibit high rates of economic disadvantage. For
comparison, in the 2000-01 school year, the average economic disadvantage rate in Texas for
high school students was 36%.
Table 3 provides similar comparisons for our outcomes of interest. First, we consider the
student’s initial college of attendance. Within this sample of high-achieving college attendees,
very few students attend the flagships (as was evident in Figure 3). Only 6%-9% of top 30%
graduates from treated schools attend either UT or TAMU. Many attend emerging research
universities or other 4-year schools, and almost half of all the college attendees are observed
first attending a two-year school. Transfer rates are quite high, at almost 40%, and 6-year BA
attainment rates are low at under 25%. Outcomes in comparison schools tend to be slightly
better than in treatment schools, but the differences are not large. Overall, Tables 2 and 3
highlight that the LOS and CS schools are targeting schools that serve a large proportion of
disadvantaged students who have low postsecondary investment rates and poor postsecondary

20

outcomes.
The differences in demographic characteristics among the treated and comparison schools
is not a threat to identification as long as they are fixed. A key element to establishing the
validity of a difference-in-differences identification strategy is being able to show that exogenous
observed characteristics are not affected by the treatment. In Table 4, we provide balance tests
using equations (1) and (2) for the college attendee samples in which we exclude all characteristics in X and use each observable shown in the column header as a dependent variable. Panel
A shows results for LOS while Panel B shows the results for CS. The estimates for the LOS and
CS main effects are universally small and statistically insignificant in both estimation samples
while for the interaction effects only gifted and talented status in the LOS sample is statistically
significant. These results support our difference-in-differences identification strategy as there is
little indication of the program implementations correlating with demographic or performance
changes in high schools.22
Given the targeted nature of these programs, it is important to understand what drives the
assignment of high schools to treatment conditional on the observables. Returning to Figures 1
and 2 that show the geographic distribution of LOS and CS schools, respectively, as well as the
comparison schools, we see that much of the treatment variation is geographic. The LOS and
CS programs were targeted towards urban high schools in the largest cities in Texas.23 Thus,
there are observationally equivalent schools located outside these cities that comprise most of
the control groups. There are some comparison schools in these cities as well but they tend
to be located outside the urban centers and reflect the fact that these programs faced budget
constraints that allowed them only to treat a subset of qualifying schools. Figures 1 and 2
suggest that there is plausibly-exogenous variation in treatment status based on geography
that allows us to identify β1 in equations (1) and (2). While in our main estimates we do not
explicitly take advantage of this, we provide specification checks that restrict our comparison
schools so that they are not in districts or counties with treated schools and find similar results.
While our trimmed common support sample makes the common trends assumption more
likely to hold, it is important to provide direct evidence on the validity of this assumption.
22 Estimates

for the top 30% high school graduates are very similar and are shown in Appendix Table A-3.
former administrator of the LOS program told us that they restricted to schools in close proximity to UT-Austin’s recruitment
centers, which were located only in major cities.
23 A

21

Thus, we estimate event study models in which we interact indicators for whether a school will
ever be treated by the LOS or CS programs with each calendar year and estimate the impacts
on our outcomes of interest. This allows us to test explicitly for the existence of differential
pre-treatment trends in these outcomes. As we describe in detail below, we find no evidence
such trends exist for any outcome, which strongly supports our empirical strategy.
The second main assumption underlying our difference-in-difference strategy is that there
must not be external shocks in 1999-2002 that affected CS/LOS schools differently from the
control schools. It is difficult to test this assumption with our data. Of particular concern is
the imposition of the Top 10% rule in 1998. As a result of this rule, most admissions to the
flagship schools were from the top 10% of a class. Equations (1) and (2) are identified under the
assumption that the top 30% in the treated and control schools (as measured by achievement)
are similarly affected by the Top 10% rule. This assumption is made more palatable by the
use of the trimmed common support sample, since both treated and control schools serve lowSES students with low historical flagship enrollment rates. However, our event study estimates
also shed light on any bias from the Top 10% rule as this law went into effect in 1998 while
the LOS/CS treatments were not rolled out until 1999-2000. We therefore should see effects
in 1998 if the Top 10% Rule is driving our estimates, but as shown below the time pattern
of effects much more closely matches the timing of the LOS/CS roll-out than the Top 10%
rule implementation. Furthermore, we show that the LOS program does not positively affect
enrollment in Texas A&M and the CS program does not positively affect enrollment at UTAustin. If our results were simply picking up differential flagship enrollment increases due to
the top 10% rule, we would not expect to see such a pattern.
Equations (1) and (2) are designed to identify intent-to-treat (ITT) parameters. That is,
β1 shows the effect of being exposed to the LOS or CS intervention by being in a treated high
school (or by being a high-performing student in a treated high school). This is primarily
out of necessity as there are multiple treatments involved in the programs and it is unclear
which students get which treatment. From a policy perspective, the ITT is an extremely
important parameter because universities cannot compel take-up. In addition, there can be
spillover effects onto students who do not receive a LOS/CS scholarship, particularly from the

22

recruitment part of the programs. Thus, from the policymaker’s standpoint, the ITT is the
most relevant parameter and it is the one our empirical strategy is best designed to estimate.
We therefore focus on the ITT parameter throughout the study. We also provide some context
to the ITT estimates by calculating back of the envelope estimates of the effect of treatment
on the treated under a broad definition of what constitutes treatment in this context.

5

Results

5.1

Enrollment Effects of LOS and CS

Estimates of equations (1) and (2) using college enrollment outcomes as the dependent variable
are shown in Table 5. Panel A contains the results for the LOS program and Panel B shows
the estimates for the CS program. Each set of two estimates in a column is from a separate
regression.
In Panel A of column (1), we show the effect of the LOS and CS treatments on attending
any public college in Texas using the sample of high school graduates. Recall that we only have
data on students who attend public colleges in Texas; if the programs induce students to enter
the public university system from other places - private schools, out-of-state schools, or from
not attending college at all - it would appear as an increase in college enrollment in our data.
The estimates in Panel A show no evidence of a change in enrollment in a public Texas 2-year
or 4-year college or university due to the LOS program (first row). The estimates in the second
row, which represent the differential impact of a school being eligible for CS in addition to LOS,
also show no statistically significant effect. Similarly in Panel (B), the estimates in column (1)
are small and are not statistically insignificant at even the 10% level. From these results, we
conclude that the likelihood of attending any Texas public college is unaffected by the LOS/CS
treatments, which negates worries about selection into the college-going sample. As a result,
we focus on the college attendee sample for the remainder of the analysis. Full results for high
school graduates are provided in the online appendix.24
One of the main goals of the LOS and CS programs is to induce more students from the
targeted low income high schools to enroll in the flagships. Our results show that while the
24 These

results are included in Online Appendix Tables A-4,A-6, A-7, A-9 and A-10.

23

LOS program was very successful in this goal, the CS program had little impact on enrollment.
Columns (2) and (3) of Table 5 provide estimates of the impact of attending an LOS or CS high
school on enrollment at a flagship. We find an increase in attendance of 2.2 percentage points in
UT-Austin due to LOS exposure. In the pre-treatment years, the average UT-Austin enrollment
rate in our sample was 0.027; hence the LOS program increased UT-Austin enrollment by 81%.
However, as column (2) demonstrates, there was no effect of LOS on TAMU enrollment. This
is an important finding for two reasons. First, if the top 10% rule caused these enrollment
increases, we would expect both UT-Austin and Texas A&M enrollment to increase, contrary to
what the data indicate. Second, the LOS program did not simply shift students across flagships
but rather caused a substantial increase in college quality. This point is further highlighted by
the remaining columns of Table 5. Nearly all of the increase in UT-Austin enrollment came
from students who would have enrolled in the emerging research universities (ERUs). While
these students would have attended four-year schools in the absence of the program, they
nonetheless experience a substantial upgrade in college quality. As Table 1 shows, UT-Austin
has more resources, stronger peer quality, and better measured outcomes than the ERUs.25
In contrast to the enrollment effect of the LOS program, Panel (B) indicates that the CS
program did not increase enrollment at Texas A&M. Schools that received both treatments
experienced an increase in enrollment at UT-Austin of 2.2 percentage points, which is in line
with the results in panel (A) indicating that this result is due to the LOS rather than the CS
program.26 There is some indication of resorting among other four-year schools, but given that
it is hard to explain why the CS program would induce such behavior, we believe this result to
be spurious. Hence, it appears that the CS program was ineffective at altering the enrollment
behavior of students in treated schools. The differences across programs is likely due to their
differences in scope and the amount of resources put into recruiting students from these high
schools. However, we lack the data to be able to test these hypotheses directly.
A core identification assumption embedded in equations (1) and (2) is that the treatment
and comparison schools are trending similarly prior to the treatment. In order to provide
evidence in support of this assumption, Figure 5 shows event study estimates of enrolling in
25 Appendix Table A-4 contains enrollment estimates for the high school graduate sample. The estimates are qualitatively and
quantitatively similar to those shown in Table 5: the effect on UT-Austin enrollment is 82% of the pre-treatment enrollment rate.
26 Recall that the samples in Panels (A) and (B) are different due to different trimmed common support comparison groups, which
is why the estimates for the jointly-treated schools are not the same across panels.

24

UT-Austin and Texas A&M for each of the respective top-30% college-going samples. For
both programs, there is no evidence of a differential upward trend in the specified flagship’s
enrollment prior to treatment. Consistent with the results in Table 5, there is a clear increase
in UT-Austin enrollment after 1999, when the LOS program began in some schools, that is not
predictable from pre-treatment trends. However, there is no evidence of an increase in Texas
A&M enrollment after 2000 when the CS implementation begins. Furthermore, these results
suggest that the Top 10% rule is not a serious confounder in this setup, as there is no apparent
increase in enrollment in either flagship in 1998 (the first year of the Top 10% rule). That
is, any differential changes in enrollment between treated and untreated schools start to occur
in 2000 after LOS was implemented, not in 1998 when Texas Top 10% rule was implemented.
Overall, Figure 5 is consistent with the identification assumptions underlying our difference-indifferences. Appendix Figure A-2 shows event study estimates for enrollment effects of the LOS
program at schools other than UT-Austin. There is little evidence of pre-treatment trends for
any enrollment outcome, and the post-treatment estimates match those in Table 5 closely.
Given that the CS program did not impact college enrollment and both the scope of the
services provided and access to those services was smaller than LOS, ex-ante, one would predict
the CS program would not have large effects on collegiate and labor market outcomes. Indeed,
in our analysis of the CS program, we do not find a statistically significant effect on any outcome
we investigate. These results are sufficiently precise that we conclude the CS program had no
impact on flagship enrollment, graduation rates, major choice, or earnings. As a result, we focus
on the LOS program for the remainder of the analysis, while estimates for the CS program are
provided in the online appendix.27
5.2

Graduation and Major Choice Effects of LOS

Thus far, our results indicate that students in LOS schools experienced a substantial increase in
college quality by shifting from lower-resource public schools to UT-Austin. The prior literature
on the educational returns to college quality suggest that this intervention should lead to higher
BA receipt (Cohodes and Goodman 2014; Bound, Lovenheim and Turner 2010). Further, the
LOS program provides a number of services to students like peer mentoring that also have been
27 Online

appendix tables A-4, A-5, A-7, A-8 and A-10 contain results for the CS program.

25

shown to improve student performance (Angrist, Lang and Oreopolous 2009). In Panel (A) of
Table 6, we examine how the LOS program affected graduation from UT-Austin along with
four-, six-, and eight-year BA completion, attendance at a public Texas graduate school, and
transferring behavior between public TX institutions. In column (1), we show that the LOS
treatment led to a 1.7 percentage point increase in the likelihood of graduating from UT-Austin
within 6 years. This is an 87% increase relative to the pre-treatment mean and the graduation
effects are about 77% of the enrollment effects in Table 5. This suggests that the program was
very effective at getting the marginal attendees to graduate from UT-Austin. However, the
academic support services and scholarship funds may have increased graduation rates among
treated students who would have attended UT-Austin even in the absence of the program,
which means we cannot necessarily attribute the entire increase in UT-Austin graduation to
the marginal attendees. Columns (2)-(6) provide information on collegiate outcomes that shed
additional light on this question. The LOS treatment did not affect four, six, or eight-year
graduation rates overall in Texas nor did the program significantly affect public graduate school
attendance (though we cannot observe any impacts on graduate school enrollment at out-ofstate or private graduate schools). It also did not affect the likelihood of students transferring
between public Texas institutions, which is important because it indicates that marginal UTAustin students did not transfer away to other schools after their initial enrollment.
Figure 6 shows event studies of the main graduation outcomes we analyze. We find no
evidence of pre-treatment trends that would bias our results, and in all cases the timing of
the effects line up closely with when the LOS policy was implemented. Again, this provides
evidence that the impacts we estimate are coming from the LOS treatment rather than from
other policies such as the top 10% rule that were in place during this time period.
Table 7 provides a more direct analysis of the effect of the LOS program on the paths students
took through the postsecondary system. We categorize students into mutually exclusive groups
by their first college type attended (UT, TAMU, ERU, Other 4 Year, and 2 Year) and their
eventual collegiate outcome (graduate from a flagship, graduate from a non-flagship public 4year school, and do not graduate from a public 4-year institution).28 Each column and panel
28 We pool the flagships together when we look at graduation because there is little transferring across flagships in Texas (Andrews,
Li and Lovenheim 2014). We further pool the two non-flagship four-year school types together to keep the number of outcomes we
are analyzing to a manageable size.

26

combination comes from a different estimation of equation (1), where the dependent variable
is an indicator for students taking the given path. For example, in the first panel column
(1) shows the effect of the LOS program on the likelihood students begin at UT-Austin and
graduate from a flagship. The estimates in column (2) in the third panel show the effect of LOS
on the likelihood a student first enrolled in an ERU and then graduated from a non-flagship
four-year school. All graduation outcomes are within six years.
The estimates in Table 7 suggest that the LOS program’s main effect on college enrollment
behavior was to increase the proportion of students who both enroll in and graduate from UTAustin. These students are mostly drawn from a group that would have enrolled in an ERU,
some of whom would not have graduated within 6 years, as shown in the third panel. There
also is a small subset of students induced to attend UT-Austin who do not obtain a degree
within 6 years, but this effect is less than half the size of the UT graduation effect. Overall,
these results indicate that the LOS program induced many students who otherwise would have
attended a non-flagship research university to both enroll in and graduate from UT-Austin.
The slight increase in the UT-grad path relative to ERU-grad and ERU-non-grad paths reflects
the small and insignificant positive 6-year graduation estimate in Table 6. This finding runs
counter to what one would expect if the students are academically mismatched to the more
demanding educational environment. It is important to emphasize, however, that this is not
a direct test of mismatch as the students attending these colleges also are receiving enhanced
academic services. One policy-relevant interpretation of these results is that these academic
services are sufficient to overcome any academic mismatch faced by the treated students.
Another prediction of mismatch theory is that under-prepared students will gravitate to
easier majors when they are overmatched. In Panel (B) of Table 6, we examine whether the
LOS program induces students to alter their chosen course of study. We focus in this table on
the student’s “final major,” which is either the major at graduation or the last observed major
for students who do not graduate from a public Texas college by the end of our sample period.
LOS treatment increases the proportion of students majoring in social sciences and in arts
and humanities primarily at the expense of students enrolled in “other” unclassified majors.
This other category is comprised of education along with mainly vocational and technical

27

support majors. Importantly, there is no statistically (or economically) significant effect on the
proportion of students majoring in STEM. Hence, LOS does not reduce the average difficulty
of the majors students choose. There is growing evidence that mismatch leads students to shift
to easier majors (Arcidiacono, Aucejo and Hotz 2013; Arcidiacono, Aucejo and Spenner 2012).
The results in Table 6 show little evidence to support such mismatch effects for high achievers
in this setting, which possibly is due to the student support services included in the program.29
That students are not majoring in easier subjects but are attending and graduating from more
elite schools suggests the LOS program led to large increases in human capital accumulation.
5.3

Earnings Impacts of LOS

The large returns to college quality (Andrews, Li and Lovenheim 2016; Hoekstra 2009; Black
and Smith 2004, 2006; Brewer, Eide and Ehrenberg 1999) suggest that the LOS intervention
should increase earnings after college. Even so, college quality improvements only affect a subset
of treated students. Many more students are provided assistance through additional financial
aid, which might free up time to focus on their studies instead of working while in college.
Furthermore, all students from an LOS high school who attend UT-Austin receive access to
the suite of academic support, mentoring, and networking services provided by the program.
Hence, there are a number of avenues through which the LOS program could affect students’
earnings.
In Table 8, we examine the effect of the LOS program on earnings using the adjusted log
quarterly earnings measures discussed in Section 3.30 We examine all earnings 6+ years after
high school, 10+ years after high school and 12+ years after high school as long as the worker has
at least 5 quarters of earnings in the relevant time frame.31 Earnings estimates 12+ years after
high school graduation are particularly important as the former students would have typically
reached at least an age of 30 in this group. This is close to the age when cross sectional earnings
29 Arcidiacono, Aucejo, Coate and Hotz (2014) argue that a substantial amount - and possibly a majority - of the increase in
minority graduation rates they find after California’s affirmative action ban was due to behavioral responses that include expanded
services.
30 Online Appendix Tables A-8 through A-10 contain results for the CS program and for the high school graduate sample for the
LOS program.
31 In Online Appendix Table A-11 we provide estimates using different sample restrictions for the earnings sample. While our
primary sample restricts to individuals with at least 5 quarters of at least $100 of earnings in the specified time frames, we also
present estimates that loosen this restriction to 3 quarters, that restrict to calendar years with $100 or more in each quarter, and
that do not restrict to a minimum number of quarters. Estimates in these cases are qualitatively and quantitatively similar to those
provided in Table 8.

28

become most predictive of lifetime earnings (Haider and Solon, 2006).
In the even columns, we provide ITT earnings effects from the LOS program. Interestingly,
while the earnings in the 6+ years sample are small and not statistically significantly different
from zero at conventional levels, the estimates grow as we move to later samples. In the
10+ years sample, the estimated earnings impact is a statistically insignificant 2%. Crucially,
however, when we focus on 12+ years earnings, which are more likely to be reflective of lifetime
earnings, we see a large and statistically significant effect of 4%. There are two important
aspects of interpretation of this result. First, the gradual increase in wage returns as the LOS
students age is notable as it suggests that the effects come from actual skill development and
human capital improvements rather than simply better signaling from attending the higher
quality school. If the latter were true, then we would expect the wage returns to show up
immediately. The late development of the earnings returns suggest that the programs make the
students more likely to succeed in their long-run career paths rather than simply getting them
higher paying jobs at the outset. Second, we can use this information to develop a back of the
envelope estimate of the treatment effect. While it is tempting to simply inflate the returns by
the 2.2 percentage point increase in enrollment at UT-Austin, this would not be appropriate
due to the multifaceted nature of the intervention. In fact, every student from an LOS eligible
school who attends UT-Austin receives some treatment in the form of services, and most receive
financial support. Infra-marginal UT-Austin attendees are treated in addition to the students
who are induced to change institutions. Further, students who are on the attendance margin
are not only more likely to attend the flagship but they are also more likely to graduate from
the flagship, increasing the potential returns. With that in mind, we can calculate an implied
treatment effect by dividing the earnings impact by the total UT enrollment rate for top 30%
students from LOS schools after the schools become eligible. With 5.6% of students in this subsample attending UT-Austin, this leads to a treatment effect on the treated of approximately
70%. This is a particularly large earnings effect when compared to prior estimates of the impact
of college quality on earnings. Below, we explain why this is a plausible earnings impact for
the population of high achieving low-income minorities targeted by the LOS program.
In the odd-numbered columns of Table 8, we estimate whether being in an LOS high school

29

affects the likelihood that one appears in the earnings data. Across the time frames, there is a
1.5 to 1.9 percentage point reduction in being observed associated with attending an LOS high
school, and these estimates are statistically significant in the 6+ and 12+ earnings samples.
Thus, there appears to be some differential attrition from the sample. While this indicates
that the earnings estimates could be biased, we have good reason to believe that our results
are, at worst, attenuated by any differential attrition. This makes our results conservative
lower bounds. To more closely examine the attrition shown in Table 8, we test for balance of
pre-determined characteristics in the earnings samples as we do for the full sample in Table
4. These results are provided in Online Appendix Table A-12, and like those in Table 4, they
show no statistically significant effects except G&T for the interaction term. The estimates in
Table A-12 provides evidence that there is little attrition bias.
Nonetheless, when we consider the types of workers who are induced to attrit by LOS we
conclude that a worst case scenario is that we underestimate the earnings effect. The first
group includes those induced to attend graduate school. While we do not find a statistically
significant increase in public graduate school attendance, the estimate in Table 6 is 0.008 - about
1/2 of the attrition effect. Further, there could be increases in attendance at private and out-ofstate graduate programs. Nonetheless, in the 12+ year sample even those getting postgraduate
degrees would likely have completed their schooling. Hence, more people probably fall into
the second group, which is comprised of those who take jobs out of state.32 Graduating from
UT-Austin gives students access to a more national labor market, and thus it makes sense that
there is some attrition from the earnings data due to the treatment. Both of these arguments
suggest it will be the most highly-skilled and the highest earnings-potential students who exit
the earnings sample. To test this hypothesis, we estimate whether there is an LOS “effect” on
the predicted earnings of students who do not show up in the earnings sample. Specifically, we
predict earnings for those in the sample by regressing ln(earnings) on high school test scores
and demographics and then estimate model (1) using the predicted earnings as the outcome for
those who are not observed in the earnings data. In Online Appendix Table A-13, we show that
the earnings attriters exposed to LOS have 4% higher potential earnings. This indicates that
32 A potential third group is made up of the unemployed. However, it is very unlikely that the differential attrition is due to LOS
increasing unemployment, as the pattern of non-earnings results suggest students will become less likely to be unemployed. The
observed shifts in majors is not expected to increase unemployment, and we do not see any negative impacts on graduation. The
shift towards graduating from higher quality institutions (specifically UT-Austin) in particular is expected to reduce unemployment.

30

students who do not have observed earnings due to LOS exposure have higher potential earnings
than comparison attriters and hence any bias in our estimates would lead us to underestimate
earnings effects.
5.4

Specification Checks and Heterogeneous Impacts of LOS

In Table 9, we provide specification checks that address additional potential concerns about the
validity of our estimates. First, in our estimates we do not place geographic restrictions on the
comparison schools. This leaves open the possibility that we include comparison schools from
the same districts as LOS schools. These comparison schools could have been chosen based
on unobserved characteristics that are not accounted for in our propensity scores. Further,
those estimates do not take full advantage of the plausibly exogenous variation generated by
the geographic limitations placed on the programs. Nonetheless, we note that in practice we
have very few comparison schools from the same districts and counties as treated schools and a
substantial number of comparison schools became LOS schools after our analysis period when
the program expanded to other parts of Texas, particularly El Paso and the Rio Grande Valley.
In panels A and B of the table, we explicitly utilize the exogenous geographic variation generated
by the program implementation restrictions by dropping comparison schools in the same school
districts and counties as the LOS treated schools, respectively. In both cases, the results are
nearly identical to our baseline estimates. The third panel of Table 9 checks an opposing concern
which is that, if our comparison schools are not in the same areas as the LOS schools, then
perhaps we are picking up an urban/rural distinction rather than an LOS effect. Since we have
so few comparison schools in the major metropolitan areas of Houston, Dallas and San Antonio
where most LOS schools are located, we cannot test this directly. Instead, we estimate models
that restrict the sample to only include schools in Census designated Metropolitan Statistical
Areas (MSA) with populations greater than 300,000 people to ensure that all of the comparison
schools are in relatively urban areas. Once again, the results are nearly identical to baseline.
Table 10 provides some heterogeneity analyses to look at whether there are differences by
gender and economic status. Since 90% of the students in LOS schools are black or Hispanic
we do not provide results broken down by race. In Panels A and B, we first look at whether the

31

LOS impacts differ based on the income of the students by looking specifically at students who
qualify for free or reduced-price lunch. While the LOS program targeted low income schools,
a substantial number of students in these schools came from families with incomes that, while
modest, were not impoverished. This is reflected in the rates of economic disadvantage amongst
high school graduates from LOS schools of 50%.33 Further, while eligible schools were targeted
based on average student income, an individual’s income was not a factor in the receipt of a
scholarship. For most outcomes, the effects differ little by economic status. Students become
more likely to enroll and graduate from UT-Austin at the same rate, while there is no significant
impact on 6-year graduation rates in either case. When we turn to earnings estimates, some
differences emerge. First, both 10+ and 12+ year earnings estimates are larger for economically
disadvantaged students. While the differences are not statistically significantly different, they
nonetheless are consistent with lower income students being particularly well positioned to
benefit from the program in the long run. It is also worth noting that there is no attrition impact
for lower income students, while there is a significant one for higher income students. This is
also consistent with LOS inducing students to move out-of-state, as higher income students
would have more resources and less need to stay at home to, for example, take care of family
members. Hence, the earnings effects for non-disadvantaged students may be underestimated.
When we turn to panels C and D that look at gender heterogeneity, we see marked differences
between men and women. Virtually all of the increases we see in UT-Austin enrollment, UTAustin graduation and earnings accrue to women. Enrollment amongst women at UT-Austin
increases by 4 percentage points, a 164% increase relative to the pre-LOS mean for women, and
graduation increases by 2.6 percentage points, a 124% increase relative to the pre-LOS mean for
women. For earnings, we see a 6.1% increase. With a post-LOS enrollment rate in UT-Austin
of 0.058 this suggests that the treatment effect for women’s earnings is 105%. For men, on the
other hand, while all of these estimates are positive, none is statistically significantly different
from zero at even the 10% level and all are small in magnitude.
It is difficult to explain the different effects of the LOS program on men and women, and
unfortunately, our data are not well equipped to do so. However, there is some evidence
33 It is likely that this measure understates the true economic disadvantage rate of the school as students in high school are often
reported to be disadvantaged at lower rates than students in elementary schools due to lower take-up.

32

from prior research that can provide context to our findings. In an experiment that provided
additional academic support and/or financial incentives to students in college Angrist, Lang
and Oreopoulos (2009) find that women were more likely to take up the academic supports and,
when the supports were combined with incentives, performed better academically while men did
not. This indicates that it is possible that women were more attracted to the supports provided
by LOS and more likely to use them when enrolled. There also is evidence of larger benefits for
women in other education-related interventions. For example, Deming et al. (2014) show that
attending a higher quality high school school leads to substantially larger increases in college
attendance for women but not for men. Women also see improvement in grades and college
preparatory course taking while men do not. As another example, the Moving to Opportunity
housing voucher experiment saw larger improvements for women in terms of crime, health, and
educational attainment (Ludwig et al. 2013; Kling, Liebman, and Katz 2007; Kling, Ludwig,
and Katz 2005). Finally, Anderson (2008) shows that randomized early childhood education
interventions generated large short and long term effects for girls but not for boys.

6

Discussion

Overall our results show that there are large increases in enrollment in and graduation from
UT-Austin from the LOS program and large earnings returns, while there are no effects of the
CS program for Texas A&M University. Two questions that emerge from our findings are: why
was the LOS program more successful than CS and why are the LOS earnings effects so large?
There are a number of reasons why we might expect the CS program to be less effective
than LOS. One key difference is that it appears that the service component of the interventions could be quite important in helping students get through the more academically-rigorous
flagships. The services provided by LOS and CS differed quite substantially. The focus of CS
services was on professional and social development - providing students with interviewing and
job search advice, building communities and networks, and community service. In terms of academic supports, students were only provided faculty mentors (with whom, according to current
program rules, students are only required to meet twice in their sophomore year) and special
academic advising was only provided if a student’s GPA fell below 2.25. The LOS support

33

services, however, while also building a community of similar students, were far more focused
on academic supports. These included free tutoring, peer mentoring, special small sections of
freshman courses, and guaranteed on-campus residence.
However, the difference in service intensity does not explain why LOS was more successful at
attracting new students to UT-Austin than CS was at attracting new students to Texas A&M.
One potential explanation for this is that our sample if urban, heavily minority students may
have been reluctant to attend TAMU, which is located in a rural and less diverse part of the
state than UT-Austin and many other 4-year schools. During the study period, UT-Austin also
had a larger minority student population than Texas A&M.34 Another potential explanation is
that CS targeted inframarginal students. This is particularly likely due to the Top 10% rule
as most, and possibly all, of the students offered CS scholarships were also (at least implicitly)
admitted to UT-Austin as well. Hence, the CS scholarships may have targeted students who
were already set on attending either institution and the program was not effective at changing
their decision.
The second remaining question is whether the large earnings effects for LOS are plausible.
Overall, the treatment effect on the treated from the intervention (including at least one of services, scholarship, and/or switching institutions) is an approximately 70% increase in earnings.
While we are not aware of any evidence of how academic supports in college affect later life
earnings, this estimate is larger than estimates of the returns to attending an elite institution
relative to other institutions that range from 20% to 54% (Anelli, 2015; Hoekstra, 2009). The
individuals studied in those papers are quite different from our sample of low income students
who are primarily minorities. Hoekstra (2009) is only able to examine white students and is
not able to break down estimates by income. Anelli (2015) looks at an elite and expensive
private university in Milan, Italy and also does not break down results by income level. Further, in both studies identification comes from admission thresholds, which makes the students
academically marginal. In the LOS context, the students are low income, primarily minorities,
and are high ability. The mean test scores of LOS students who enroll in UT are about 0.8
standard deviations above that of the average Texas high school student, while the average
34 In 2000, the total population of College Station, TX which houses Texas A&M was just 68,000 with a racial composition of
82% white and 10% Hispanic. Austin, TX which houses UT-Austin had a population of 656,000 with a racial composition that was
68% white and 31% Hispanic. In terms of university racial statistics, in 2000 first-time freshmen at UT-Austin were 4% black and
15% Hispanic, while at TAMU those figures were 3% and 9%, respectively (Kain, O’Brien, Jargowsky 2015).

34

for all Texas high school students who enroll in UT is around 0.85 standard deviations. The
average LOS school attendee at UT is well within the 2nd quartile of all UT-Austin enrollees
from Texas in terms of high school test scores. Thus, LOS students are academically better
matched for UT-Austin than the students in RD studies of the returns to college quality. As a
result, we argue that our estimates suggest that low-income, high ability students (particularly
women) are primed to benefit substantially more than other students from increased college
quality and academic support services in college.
In addition, the apparent change in college quality is far larger in our analysis than in
Hoekstra (2009). On average the most likely alternative institutions (Hoekstra cannot observe
actual enrollment in other institutions) had per student spending at 91% of the flagship level and
SAT scores 95 points lower than the flagships. Returning to Table 1 and comparing UT-Austin
to the Emerging Research Universities where LOS students would have attended otherwise,
we see that the ERU’s have instructional spending at 46% of the UT-Austin rate and 75th
percentile SAT Scores 249 points lower.
The time path of the earnings returns also is important to highlight. Our estimates in Table
8 increase as we narrow to years further out in the individual’s life. In fact, the point estimates
more than double when we drop years 6 - 11 after high school graduation. This suggests that
the earnings improvements came from skill development rather than simply better signaling and
networking opportunities, as we would expect the latter to generate earnings returns earlier in
the student’s career whereas the former may take time to become valued in the labor market.

7

Conclusion

Persistent increases in the college wage premium combined with sluggish growth in collegiate
attainment, particularly among students from low-income backgrounds, make it of first-order
importance to understand what policies can reduce attainment gaps in higher education across
the socioeconomic distribution. Given the evidence of the educational and labor market returns to college quality as well as the low enrollment rates among low-income students at elite
schools, policies designed to raise enrollment rates of disadvantaged students at high-quality
colleges have the potential to reduce these disparities. Further, it is likely that students from

35

disadvantaged backgrounds would benefit from support services that enhance their experience.
We study two examples of such policies in Texas, the Longhorn Opportunity and Century
Scholars programs, which were designed to address the multitude of disadvantages faced by
low-income students in higher education: information, tuition subsidies, and support services
once enrolled. These programs were targeted at schools that served large numbers of low-income
students and that tended to send few students to University of Texas at Austin (LOS) or Texas
A&M University (CS).
We combine the timing of the implementation of the LOS and CS programs with detailed administrative data from K-12 records, higher education records, and earnings as long as workers
remain in Texas and attend a public university. We implement a set of difference-in-difference
estimators using trimmed common support samples of treated and comparison schools that
compare how the enrollment behavior, educational outcomes, and earnings of high-ability students change when the programs are implemented in targeted high schools.
Our estimates suggest that this type of bundled intervention can generate better outcomes
among targeted students. The LOS program induced many students to enroll in UT-Austin
instead of lower-resource four-year institutions. This shift towards the flagship provided a large
quality upgrade relative to the schools the students would have attended in the absence of
the program. High-achieving students affected by the LOS program saw large and statistically
significant increases in the likelihood of graduating from UT-Austin, and we find little evidence
of academic mismatch in the form of students switching to “easier” majors. We find that
the combination of academic support services, financial support, and higher college quality
increased the likelihood a student would graduate from UT-Austin and earnings 12 or more
years after a student completes high school. These effects are large - enrollment in UT-Austin
increases by over 80% and earnings of treated students (where treatment applies to all UTAustin enrollees from LOS schools, not just those students who change institutions) increases
by 70%. Virtually all of the impacts are concentrated among women. The large returns to the
program indicate that these high ability, low income, and heavily minority students may be
particularly sensitive to improvements in college quality and academic support services.
In contrast to the findings for the LOS program, the CS intervention had no effect on

36

enrollment behavior, postsecondary outcomes or labor market outcomes. We argue there are
two likely explanation for the differences in these programs. First, the support services provided
by CS were focused on professional development rather than academic supports, were less
intensive, and were not made as widely available to students from treated high schools. Second,
the relatively low minority populations and rural location of Texas A&M made it an unattractive
choice for the targeted students, particularly given that most were also admitted to UT-Austin.
Our analysis cannot determine how much of the impacts we find are due to the change in
school quality or the provision of academic supports and financial aid. We thus interpret our estimates as telling us whether a program that provides a full package of services to high-achieving,
low-income students that addresses the suite of disadvantages they face in the postsecondary
system affects their educational and labor market outcomes. The results suggest that programs
like the Longhorn Opportunity Scholarship hold much promise in promoting better postsecondary and labor market outcomes among these students. Furthermore, while it is unclear if
the students treated by the program are actually “overmatched” for the state flagships, the
results suggest that mismatch problems can be overcome with sufficient support services. Crucially, programs like these and the supports they provide can easily be replicated in any state
flagship institution. The estimates for the Century Scholar program, however, provides a cautious note as it is not automatic that such a program will succeed in attracting new students or
affecting postsecondary and labor market outcomes. More work focusing on the specific ways
in which these programs were implemented and the implications for effectiveness would be of
high value in order to better understand how to structure these programs to maximize their
positive effects on students.

37

References
[1] Altonji, Joseph G., Erica Blom and Costas Meghir. 2012. “Heterogeneity in Human Capital Investments:
High School Curriculum, College Major, and Careers.” NBER Working Paper No. 17985.
[2] Anelli, Massimo. 2015. “Returns to Elite College Education: A Quasi-Experimental Analysis” Bocconi
University, mimeo.
[3] Anderson, Michael. 2008. “Multiple Inference and Gender Differences in the Effects of Early Intervention:
A Reevaluation of the Abecedarian, Perry Preschool, and Early Training Projects” Journal of the American
Statistical Association 103(484): 1481-1495.
[4] Andrews, Rodney J., Jing Li and Michael F. Lovenheim. 2016. “Quantile Treatment Effects of College
Quality on Earnings.” Journal of Human Resources 51(1): 200-238.
[5] Andrews, Rodney J., Jing Li and Michael F. Lovenheim. 2014. “Heterogeneous Paths Through College:
Detailed Patterns and Relationships with Graduation and Earnings.” Economics of Education Review 42:
93-108.
[6] Andrews, Rodney J., Vimal Ranchhod, and Viji Sathy. 2010. “Estimating the Responsiveness of College
Applications to the Likelihood of Acceptance and Financial Assistance: Evidence from Texas.” Economics
of Education Review 29(1): 104-115.
[7] Angrist, Joshua, Daniel Lang and Philip Oreopoulos. 2009. “Incentives and Services for College Achievement:
Evidence from a Randomized Trial” American Economic Journal: Applied Economics 1(1): 136-163
[8] Angrist, Joshua, David Autor, Sally Hudson and Amanda Pallais. 2014. “Leveling Up: Early Results from
a Randomized Evaluation of Post-Secondary Aid.” NBER Working Paper No. 20800.
[9] Arcidiacono, Peter. 2004. “Ability Sorting and the Returns to College Major.” Journal of Econometrics
121(1-2): 343-375.
[10] Arcidiacono, Peter, Esteban M. Aucejo, Hanming Fang and Ken Spenner. 2011. “Does Affirmative Action
Lead to Mismatch? A New Test and Evidence.” Quantitative Economics 2(3): 303-333.
[11] Arcidiacono, Peter, Esteban M. Aucejo and Ken Spenner. 2011. “What Happens After Enrollment? An
Analysis of the Time Path of Racial Differences in GPA and Major Choice.” IZA Journal of Labor Economics
1(5).
[12] Arcidiacono, Peter, Esteban M. Aucejo, Patrick Coate and V. Joseph Hotz. 2014. “Affirmative Action and
University Fit: Evidence from Proposition 209” IZA Journal of Labor Economics 3(7).
[13] Arcidiacono, Peter, Esteban M. Aucejo and V. Joseph Hotz. 2013. “University Differences in the Graduation
of Minorities in STEM Fields: Evidence from California.” NBER Working Paper No. 18799.
[14] Arcidiacono, Peter and Cory Koedel. 2014. “Race and College Success: Evidence from Missouri.” American
Economic Journal: Applied Economics 6(3): 20-57.
[15] Arcidiacono, Peter and Michael F. Lovenheim. Forthcoming. “Affirmative Action and the Quality-Fit Tradeoff.” Journal of Economic Literature.
[16] Autor, David H. “Skills, Education, and the Rise of Earnings Inequality Among the ‘Other 99 Percent’.”
Science 344(6186): 843-851.
[17] Autor, David H., Lawrence F. Katz and Melissa S. Kearney. 2008. “Trends in U.S. Wage Inequality:
Revising the Revisionists.” Review of Economics and Statistics 90(2): 300-323.
[18] Bailey, Martha J. and Susan M. Dynarski. 2011. “Inequality in Postsecondary Education.” In G.J. Duncan
and R.J. Murnane (eds.), Whither Opportunity? Rising Inequality, Schools, and Children’s Life Chances.
Russell Sage: New York, New York.
[19] Bettinger, Eric. “How Financial Aid Affects Persistence.” In C.M. Hoxby (ed.), College Choices: The
Economics of Where to Go, When to Go, and How to Pay for it. University of Chicago Press: Chicago.

38

[20] Bettinger, Eric P, Bridgett Terry Long, Philip Oreopoulos, and Lisa Sonbonmatsu. 2012. “The Role of Application Assistance and Information in College Decisions: Results from the H&R Block Fafsa Experiment.”
Quarterly Journal of Economics 127(3): 1205-1242.
[21] Bhagat, Geeta Srinivasan. 2004. “The Relationship between factors that Influence College Choice and
Persistence in Longhorn Opportunity Scholarship Recipients at The University of Texas at Austin.” Doctoral
Dissertation at the University of Texas at Austin.
[22] Black, Dan A. and Jeffrey A. Smith. 2004. “How Robust is the Evidence on the Effects of College Quality?
Evidence from Matching.” Journal of Econometrics 121(1-2): 99-124.
[23] Black, Dan A. and Jeffrey A. Smith. 2006. “Estimating the Returns to College Quality with Multiple
Proxies for Quality.” Journal of Labor Economics 24(3): 701-728.
[24] Black, Dan A., Kermit Daniel and Jeffrey A. Smith. 2005. “College Quality and Wages in the United
States.” German Economic Review 6(3): 415-443.
[25] Bound, John, Michael F. Lovenheim and Sarah E. Turner. 2010. “Why Have College Completion Rates
Declined? An Analysis of Changing Student Preparation and Collegiate Resources.” American Economic
Journal: Applied Economics 2(3): 129-157.
[26] Bound, John, Michael F. Lovenheim and Sarah E. Turner. 2012. “Increasing Time to Baccalaureate Degree
in the United States.” Education Finance and Policy 7(4): 375-424.
[27] Brewer, Dominic J., Eric R. Eide and Ronald G. Ehrenberg. 1999. “Does It Pay to Attend an Elite Private
College? Cross-Cohort Evidence on the Effects of College Type on Earnings.” Journal of Human Resources
34(1): 104-123.
[28] Cameron, Stephen V. and Christopher Taber. 2004. “Estimation of Educational Borrowing Constraints
Using Returns to Schooling.” Journal of Political Economy 112(1): 132-182.
[29] Carneiro, Pedro and James J. Heckman. 2002. “The Evidence on Credit Constraints in Post-Secondary
Schooling.” The Economic Journal 112(482): 705-734.
[30] Clotfelter, Charles T., Steven W. Hemelt, and Helen F. Ladd. 2016. “Multifaceted Aid for Low-Income
Students and College Outcomes: Evidence from North Carolina.” NBER Working Paper No. 22217.
[31] Cohodes, Sarah and Joshua S. Goodman. 2014. “Merit Aid, College Quality, and College Completion:
Massachusetts’ Adams Scholarship as an In-Kind Subsidy.” American Economic Journal: Applied Economics
6(4): 251-283.
[32] Cornwell, Christopher, David B. Mustard, and Deepa J. Sridhar. 2006. “The Enrollment Effects of MeritBased Financial Aid: Evidence from Georgia’s HOPE Program.” Journal of Labor Economics 24(4): 761-786.
[33] Cortes, Kalena E. “Do Bans on Affirmative Action Hurt Minority Students? Evidence from the Texas Top
10% Plan.” Economics of Education Review 29(6): 1110-1124.
[34] Cunha, Flavio and James J. Heckman. 2008. “Formulating, Identifying and Estimating the Technology of
Cognitive and Noncognitive Skill Formation.” Journal of Human Resources 43(4): 738-782.
[35] Cunha, Flavio, James J. Heckman and Susanne M. Schennach. 2010. “Estimating the Technology of Cognitive and Noncognitive Skill Formation.” Econometrica 78(3): 883-931.
[36] Dale, Stacey Berg and Alan B. Krueger, 2014. “Estimating the Return to College Selectivity over the
Career Using Administrative Earnings Data.” Journal of Human Resources 49(2): 323-358.
[37] Dale, Stacey Berg and Alan B. Krueger, 2002. “Estimating the Payoff to Attending A More Selective
College: An Application of Selection on Observables and Unobservables.” Quarterly Journal of Economics
117(4): 1491-1527.
[38] Daugherty, Lindsay, Francisco Martorell and Isaac McFarlin, Jr. 2014. “Percent Plans, Automatic Admissions, and College Enrollment Outcomes.” IZA Journal of Labor Economics 3(10).

39

[39] Deming, David J, Justine S Hastings, Thomas J. Kane, and Douglas O. Staiger. 2014. “School Choice,
School Quality, and Postsecondary Attainment” American Economic Review 104(3): 991-1013.
[40] Dillon, Eleanor Wiske and Jeffrey Andrew Smith. 2013. “The Determinants of Mismatch Between Students
and Colleges.” NBER Working Paper No. 19286.
[41] Domina, Thurston. 2007. “Higher Education Policy as Secondary School Reform: Texas Public High Schools
after Hopwood.” Education Evaluation and Policy Analysis 29(3): 200-217.
[42] Domina, Thurston. 2009. “What Works in College Outreach: Assessing Targeted and Schoolwide Interventions for Disadvantaged Students.” Education Evaluation and Policy Analysis 31(2): 127-152.
[43] Dynarski, Susan. 2000. “Hope for Whom? Financial Aid for the Middle Class and Its Impact on College
Attendance.” National Tax Journal 53(3): 629-661.
[44] Dynarski, Susan and Judith Scott-Clayton. 2013. “Financial Aid Policy: Lessons from Research.” Future
of Children May.
[45] Dynarski, Susan and Judith Scott-Clayton. 2008. “Complexity and Targeting in Federal Student Aid: A
Quantitative Analysis.” Tax Policy and the Economy 22: 109-150.
[46] Dynarski, Susan and Judith Scott-Clayton. 2006. “The Cost of Complexity in Student Financial Aid:
Lessons from Optimal Tax Theory and Behavioral Economics.” National Tax Journal 59(2): 319-356.
[47] Fitzpatrick, Maria D. and Damon Jones. 2012. “Higher Education, Merit-Based Scholarships and PostBaccalaureate Migration.” NBER Working Paper No. 18530.
[48] Goldin, Claudia and Lawrence F. Katz. 2007. “Long-Run Changes in the Wage Structure: Narrowing,
Widening, Polarizing.” Brookings Papers on Economic Activity 2007(2): 135-165.
[49] Haider, Steven and Gary Solon. 2006. “Life-Cycle Variation in the Association between Current and Lifetime
Earnings” American Economic Review 96(4): 1308-1320.
[50] Hoekstra, Mark. 2009. “The Effect of Attending the Flagship State University on Earnings: A DiscontinuityBased Approach.” Review of Economics and Statistics 91(4): 717-724.
[51] Hoxby, Caroline and Christopher Avery. 2013. “The Missing ”One-Offs”: The Hidden Supply of HighAchieving, Low-Income Students.” Brookings Papers on Economic Activity. Spring: 1-50.
[52] Hoxby, Caroline and Sarah Turner. 2013. “Expanding College Opportunities for High-achieving, Low Income Students.” Stanford Institute for Economic Policy Research Discussion Paper 12-014.
[53] Johnson, Matthew T. 2013. “Borrowing Constraints, College Enrollment, and Delayed Entry.” Journal of
Labor Economics 31(4): 669-725.
[54] Kaine, John F., Daniel M. O’Brien and Paul A. Jargowsky. 2005. “Hopwood and the Top 10 Percent Law:
How They Have Affected the College Enrollment Decisions of Texas High School Graduates.” Report to the
Andrew W. Mellon Foundation: http://www.utdallas.edu/research/tsp-erc/pdf/wp kain 2005 hopwood top
10 percent.pdf.
[55] Kling, Jeffrey R., Jeffrey B. Liebman, and Lawrence F. Katz. 2007. “Experimental Analysis of Neighborhood
Effects.” Econometrica 75(1): 83119.
[56] Kling, Jeffrey R., Jens Ludwig, and Lawrence F. Katz. 2005. “Neighborhood Effects on Crime for Female and Male Youth: Evidence from a Randomized Housing Voucher Experiment.” Quarterly Journal of
Economics 120(1): 87130.
[57] Long, Mark. 2008. “College Quality and Early Adult Outcomes” Economics of Education Review 27(5):
588-602.
[58] Long, Mark and Marta Tienda. 2008. “Winners and Losers: Changes in Texas University Admissions
Post-Hopwood.” Education Evaluation and Policy Analysis 30(3): 255-280.
[59] Lovenheim, Michael F. and C. Lockwood Reynolds. 2013. “The Effect of Housing Wealth on College Choice:
Evidence from the Housing Boom.” Journal of Human Resources 48(1): 1-35.
40

[60] Ludwig, Jens, Greg J. Duncan, Lisa A. Gennetian, Lawrence F. Katz, Ronald C. Kessler, Jeffrey R. Kling,
and Lisa Sanbonmatsu. 2013. “Long-Term Neighborhood Effects on Low-Income Families: Evidence from
Moving to Opportunity.” American Economic Review 103(3): 22631.
[61] Myers, David, Rob Olsen, Neil Seftor, Julie Young, and Christina Tuttle. 2004. The Impacts of Regular
Upward Bound: Results from the Third Follow-up Data Collection. Washington, DC: Mathematica Policy
Research.
[62] Niu, Sunny Xinchun and Marta Tienda. 2010. “The Impact of the Texas Top Ten Percent Law on College
Enrollment: A Regression Discontinuity Approach.” Journal of Policy Analysis and Management 29(1):
84-110.
[63] Pallais, Amanda. 2015. “Small Differences that Matter: Mistakes in Applying to College.” Journal of Labor
Economics 33(2): 493-520.
[64] Sacerdote, Bruce. 2001. “Peer Effects With Random Assignment: Results For Dartmouth Roommates.”
Quarterly Journal of Economics 116(2): 681-704.
[65] Sjoquist, David L. and John V. Winters. 2012. “State Merit-based Financial Aid Programs and College
Attainment.” IZA Discussion Paper No. 6801.
[66] Stinebrickner, Ralph and Todd R. Stinebrickner. 2006. “What Can be Learned about Peer Effects Using
College Roommates? Evidence from New Survey Data and Students from Disadvantaged Backgrounds.”
Journal of Public Economics 90(8-9): 1435-1454.
[67] Stinebrickner, Ralph and Stinebrickner, Todd. 2008. “The Effect of Credit Constraints on the College
Drop-Out Decision: A Direct Approach Using a New Panel Study.” American Economic Review 98(5):
2163-2184.
[68] Zimmerman, David J. 2003. “Peer Effects in Academic Outcomes: Evidence from a Natural Experiment.”
Review of Economics and Statistics 85(1): 9-23.

41

Figure 1: UT Austin Longhorn Opportunity Scholars and Comparison Schools

^
_
_
^
_
^
_
_^
^
^
_
_
^
_
_
^
_^
^
_
^
_
^
_
^
^
_
_^
^
_

_
^
_
^
_
^
_
^
_
^
^
_

_
_
^
_
_^
^
_^
^
^
_

_
^

_
^

_
^

LOS High Schools
LOS Comparison Schools
Urban Areas

42

Figure 2: Texas A&M Century Scholars and Comparison Schools

_
^
_
^
_
_^
^
_
_
^
_^
^
^
_

_
_^
^
_
^
_
^
_
^
_
^
_
_
^
_
^
^^
_

_
^^
_
_
^

_
^

CS High Schools

CS Comparison Schools
Urban Areas

43

Figure 3: Flagship Enrollment as a Share of All College Attendees by Within High School
Achievement Decile

UT-Austin Enrollment from Longhorn Opportunity Scholar and
Comparison Schools
0.1

0.09

0.08

0.07

0.06

0.05

0.04

0.03

0.02

0.01

0
First Decile

Second Decile

Third Decile

1996 - 1998 LOS

Fourth Decile

Fifth Decile

1999 - 2002 LOS

Sixth Decile

Seventh Decile

1996 - 1998 Comparison

Eigth Decile

Ninth Decile

Tenth Decile

1999 - 2002 Comparison

TAMU Enrollment from Century Scholar and Comparison Schools
0.1

0.09

0.08

0.07

0.06

0.05

0.04

0.03

0.02

0.01

0
First Decile

Second Decile

Third Decile

1996 - 1998 CS

Fourth Decile
1999 - 2002 CS

Fifth Decile

Sixth Decile

Seventh Decile

1996 - 1998 Comparison

44

Eigth Decile

1999 - 2002 Comparison

Ninth Decile

Tenth Decile

Figure 4: Distribution of LOS and CS Treatment Probabilities by Treatment Status

All schools with estimated propensity scores below 0.2 are dropped from the estimation sample.

45

Figure 5: Flagship Enrollment Impacts by Year - Top 30% College Attendees Sample

LOS: Attend UT-Austin
.08
.06

Percentage

.04
.02
0
-.02
-.04
-.06
1996

1997

1998

1999
Year

2000

2001

2002

2001

2002

CS: Attend TAMU
.08
.06

Percentage

.04
.02
0
-.02
-.04
-.06
1996

1997

1998

1999
Year

2000

Notes: Authors’ estimation as described in the text. Each point represents a coefficient estimate and the bars extending from
each point is the 95% confidence interval calculated from standard errors that are clustered at the high school level. The
coefficient in 1998 is set to zero. All models include cohort and high school fixed effects as well as controls for the observed
characteristics included in equations (1) and (2). Models also include interactions between a school being eligible for both LOS
and CS interacted with each year.

46

47

Percentage

-.04

-.02

0

.02

.04

.06

.08

-.04

-.02

0

.02

.04

.06

.08

1996

1996

1998

1999
Year

2000

2001

1997

1998

1999
Year

2000

2001

LOS: Graduate Any Public in 8 Years

1997

LOS: Graduate from UT-Austin in 6 Years

2002

2002

-.04

-.02

0

.02

.04

.06

.08

-.04

-.02

0

.02

.04

.06

.08

1996

1996

1998

1999
Year

2000

2001

1997

1998

1999
Year

2000

2001

LOS: Attend Public Graduate School

1997

LOS: Graduate Any Public in 6 Years

2002

2002

Notes: Authors’ estimation as described in the text. Each point represents a coefficient estimate and the bars extending from each point is the 95% confidence interval calculated
from standard errors that are clustered at the high school level. The coefficient in 1998 is set to zero. All models include cohort and high school fixed effects as well as controls for
the observed characteristics included in equations (1) and (2). Models also include interactions between a school being eligible for both LOS and CS interacted with each year.

Percentage

Figure 6: LOS Education Impacts by Year - Top 30% College Attendees Sample

Percentage
Percentage

48

Percent

1999
Year

2000

2001

2002

1999
Year

2000

2001

2002

-.06
1998

-.12
1997

-.04

-.08

1996

-.02

0

.02

.04

.06

-.04

0

.04

.08

.12

LOS: Log Earnings - 12+ Years

-.12
1998

-.12
1997

-.08

-.08

0

.04

.08

.12

-.04

1996

LOS: Log Earnings - 6+ Years

-.04

0

.04

.08

.12

1996

1996

1998

1999
Year

2000

2001

1997

1998

1999
Year

2000

2001

LOS: In Earnings Sample - 12+ Years

1997

LOS: Log Earnings - 10+ Years

2002

2002

Notes: Authors’ estimation as described in the text. Each point represents a coefficient estimate and the bars extending from each point is the 95% confidence interval calculated
from standard errors that are clustered at the high school level. The coefficient in 1998 is set to zero. All models include cohort and high school fixed effects as well as controls for
the observed characteristics included in equations (1) and (2). Models also include interactions between a school being eligible for both LOS and CS interacted with each year.

Percent

Figure 7: LOS Earnings Impacts by Year - Top 30% College Attendees Sample

Percent
Percentage

Table 1: Characteristics of Public 4-Year Institutions in Texas

School Characteristic
Max USNews Ranking
Graduation Rate
Retention Rate
Avg Full Prof Salary
UG Student/Faculty FTE
Instr Exp per UG Student
Acad Support Exp per UG Student
Student Service Exp per UG Student
SAT Math 75th Percentile
SAT Reading 75th Percentile
Institutions

UT-Austin

Texas A&M

53
0.79
0.94
$137,871
14.0
$19,320
$5,633
$1,761
710
680
1

68
0.79
0.91
$128,367
17.0
$13,421
$3,853
$1,914
630
610
1

Emerging
Research
145
0.47
0.76
$122,131
22.6
$7,880
$2,865
$1,572
588
553
7

Other
4-Year
NA
0.37
0.64
$87,352
21.2
$6,491
$2,229
$1,387
519
537
21

Means from Integrated Postsecondary Education Data System (IPEDS) provided by the US Department
of Education. Data is from 2013-14 except expenditure data, which is from the 2012-13 school year.
“Emerging research” universities are institutions declared by the state of Texas to be eligible for special
funds to increase research activity. These include UT-Dallas, UT-Arlington, UT-San Antonio, UT-El
Paso, Texas Tech and University of Houston.

49

Table 2: Summary Statistics for Top 30% College Attendees Sample - Student
Characteristics

TAAS Writing
(Std Devs)
TAAS Reading
(Std Devs)
TAAS Math
(Std Devs)
White
Black
Hispanic
Gifted & Talented
At Risk
Male
Econ. Disadvantaged

Observations

LOS Sample
LOS Schools LOS Comparison
0.68
0.76
(0.38)
(0.36)
0.62
0.69
(0.35)
(0.33)
0.71
0.79
(0.41)
(0.37)
0.08
0.12
(0.28)
(0.32)
0.29
0.06
(0.45)
(0.25)
0.61
0.81
(0.49)
(0.39)
0.21
0.31
(0.41)
(0.46)
0.27
0.26
(0.45)
(0.44)
0.42
0.45
(0.49)
(0.50)
0.49
0.57
(0.50)
(0.50)
17,797

12,475

CS Sample
CS Schools CS Comparison
0.73
0.80
(0.38)
(0.35)
0.67
0.74
(0.34)
(0.31)
0.76
0.81
(0.40)
(0.36)
0.12
0.27
(0.33)
(0.44)
0.35
0.13
(0.48)
(0.34)
0.48
0.58
(0.50)
(0.49)
0.25
0.32
(0.43)
(0.46)
0.20
0.18
(0.40)
(0.38)
0.41
0.45
(0.49)
(0.50)
0.41
0.31
(0.49)
(0.46)
12,265

9,062

Notes: Authors’ tabulations using college attendees from the linked ERC-THECB data for the 19962002 high school graduating cohorts. Restricted to trimmed common support and top 30% of HS class
as defined by TAAS achievement index.

50

Table 3: Summary Statistics for Top 30% College Attendees Sample - Outcomes

Enroll in UT
Enroll in TAMU
Enroll in Emerging
Research U
Enroll in Other
4-Yr
Enroll in 2-Yr
Transfer
Major in
Arts & Humanities
Major in
Business
Major in
Social Science
Major in
STEM
Graduate UT
in 6 Yrs
Graduate TAMU
in 6 Yrs
Any Public BA
in 6 Yrs.
Has 5 qtrs of Earnings
(12+ Yrs after HS)

LOS Sample
LOS Schools LOS Comparison
0.043
0.047
(0.202)
(0.211)
0.023
0.038
(0.148)
(0.191)
0.144
0.074
(0.351)
(0.262)
0.268
0.397
(0.443)
(0.489)
0.522
0.443
(0.500)
(0.497)
0.38
0.38
(0.48)
(0.48)
0.21
0.16
(0.41)
(0.37)
0.18
0.16
(0.38)
(0.37)
0.08
0.09
(0.27)
(0.29)
0.10
0.14
(0.30)
(0.34)
0.031
0.036
(0.174)
(0.185)
0.015
0.032
(0.122)
(0.176)
0.209
0.316
(0.406)
(0.465)
0.78
0.78
(0.41)
(0.42)

CS Sample
CS Schools CS Comparison
0.048
0.084
(0.216)
(0.277)
0.043
0.053
(0.203)
(0.223)
0.214
0.111
(0.410)
(0.313)
0.181
0.316
(0.385)
(0.465)
0.513
0.438
(0.500)
(0.496)
0.40
0.36
(0.49)
(0.48)
0.21
0.18
(0.41)
(0.38)
0.19
0.17
(0.39)
(0.38)
0.08
0.10
(0.27)
(0.30)
0.11
0.14
(0.31)
(0.35)
0.039
0.075
(0.193)
(0.263)
0.032
0.047
(0.177)
(0.212)
0.243
0.343
(0.429)
(0.475)
0.81
0.75
(0.39)
(0.44)

Observations

17,797

12,475

12,265

9,062

Resid. Log Earn
(12+ Yrs after HS)

-0.046
(0.778)

0.022
(0.758)

0.035
(0.773)

0.072
(0.779)

Observations

13,944

9,683

9,963

6,755

Notes: Authors’ tabulations using college attendees from the linked ERC-THECB data for the 1996-2002
high school graduating cohorts. Restricted to trimmed common support and top 30% of HS class as
defined by TAAS achievement index.

51

52

0.006
(0.020)
0.049
(0.035)

CS
School
CS & LOS
School

0.015
(0.018)
0.039
(0.028)

0.022
(0.015)
0.016
(0.023)

0.003
(0.016)
0.028
(0.023)

-0.018
(0.015)
0.013
(0.019)

(5)

White
(6)

Black
(7)

Hisp

0.002
(0.009)
0.006
(0.008)

0.000
(0.008)
-0.014
(0.011)

-0.002
(0.009)
0.014
(0.011)

-0.005
(0.020)
0.047
(0.036)

0.012
(0.013)
0.012
(0.017)

-0.008
(0.015)
-0.015
(0.014)

0.003
(0.016)
0.005
(0.018)

Panel B: CS Sample (N=21,327)

-0.003
(0.023)
0.004
(0.032)

Panel A: LOS Sample (N=30,272)

TAAS Scores (SD)
Writing
Read
Math
(2)
(3)
(4)

-0.016
(0.019)
0.125
(0.077)

0.023
(0.037)
0.084***
(0.031)

(8)

G&T

-0.068
(0.046)
0.019
(0.041)

-0.005
(0.039)
0.045
(0.033)

(9)

At-Risk

-0.014
(0.017)
0.016
(0.017)

0.007
(0.012)
-0.007
(0.014)

(10)

Male

0.013
(0.020)
0.050∗∗
(0.019)

0.008
(0.021)
0.025
(0.021)

Econ
Disadv
(11)

Notes: Authors’ estimation of equations (1) and (2) in the text using data for the 1996-2002 high school graduating cohorts, excluding all student
characteristics and using the variable listed in the column title as the dependent variable. Each group of two coefficient estimates in each column comes
from the same regression. Restricted to trimmed common support who attend college and top 30% of HS class as defined by TAAS achievement index.
Standard errors clustered at the high school level are in parentheses: ***, **, * indicate significance at the 1%, 5% and 10% levels, respectively.

0.000
(0.019)
0.015
(0.028)

Achievment
Index
(1)

LOS
School
LOS & CS
School

Dep. Var. →

Table 4: Balance Tests for Trimmed Common Support – Top 30% College Attendees

Table 5: The Effect of the Longhorn Opportunity and Century Scholars
Programs on College Enrollment

Treatment

Attend Any
TX College
(1)

Attend
UT
(2)

Attend
TAMU
(3)

Attend Other
Research U
(4)

Attend Other
4 Yr
(5)

Attend
2yr
(6)

Panel A: Longhorn Opportunity Scholar Program
HS Grads
College Attendees
LOS School
LOS & CS
School

0.003
(0.012)
-0.015
(0.012)

HS Grads
CS School
CS & LOS
School

-0.022
(0.014)
-0.006
(0.013)

0.022****
(0.005)
-0.010
(0.008)

-0.009
(0.006)
0.012**
(0.006)

-0.025**
(0.010)
0.009
(0.011)

-0.005
(0.013)
-0.010
(0.015)

0.016
(0.015)
-0.001
(0.018)

0.032*
(0.018)
-0.036**
(0.014)

-0.008
(0.016)
0.009
(0.017)

Panel B: Century Scholars Program
College Attendees
0.002
(0.019)
0.024**
(0.012)

0.001
(0.009)
-0.003
(0.011)

-0.027**
(0.014)
0.006
(0.014)

Notes: Estimation of equations (1) and (2) in the text using the linked ERC-THECB data for
the 1996-2002 high school graduating cohorts. Each group of two coefficient estimates in each
column comes from the same regression. All models include high school and year fixed effects
as well as the demographic, high school and test score controls discussed in Section 4 of the
text. Restricted to trimmed common support and top 30% of HS class as defined by TAAS
achievement index. Sample sizes for the LOS college attendee and HS grad samples are 30,272
and 41,588, respectively. For CS the sample sizes are 21,327 and 30,027, respectively. Standard
errors clustered at the high school level are in parentheses: ***, **, * indicate significance at
the 1%, 5% and 10% levels, respectively.

53

54

0.020*
(0.010)
-0.004
(0.013)

Business

Arts &
Hum
(1)
-0.011
(0.010)
0.002
(0.011)

(2)

-0.004
(0.006)
-0.018**
(0.008)

0.017****
(0.004)
-0.005
(0.006)

0.016**
(0.007)
-0.004
(0.008)

Social
Sci
(3)

0.006
(0.012)
0.001
(0.014)

-0.012
(0.008)
-0.002
(0.009)

-0.004**
(0.002)
0.002
(0.002)

(5)
-0.000
(0.009)
-0.032****
(0.008)

(6)

Comm

Panel B: Major Field
STEM
Agr
(4)

0.008
(0.09)
0.011
(0.009)

Enroll in
Public Grad School
(6)

0.005
(0.011)
0.002
(0.014)

0.000
(0.012)
0.000
(0.014)

Panel A: Graduation, Transferring, and Graduate School
Grad Any Public Grad Any Public
Grad Any Public Transfer
in 4 Yrs
in 6 Yrs
in 8 Yrs
(2)
(3)
(4)
(5)

0.001
(0.008)
0.008
(0.008)

(7)

Health

-0.018*
(0.010)
0.027***
(0.009)

(8)

Other

0.009*
(0.005)
0.004
(0.006)

(9)

Undeclared

Notes: Estimation of equation (1) in the text using the linked ERC-THECB data for the 1996-2002 high school graduating cohorts. Each group of two
coefficient estimates in each column comes from the same regression. All models include high school and year fixed effects as well as the demographic, high
school and test score controls discussed in Section 4 of the text. Restricted to trimmed common support and top 30% of HS class as defined by TAAS
achievement index. Sample size is 30,272. Standard errors clustered at the high school level are in parentheses: ***, **, * indicate significance at the 1%,
5% and 10% levels, respectively.

LOS
School
LOS & CS
School

LOS
School
LOS & CS
School

Grad UT
in 6 Yrs
(1)

Table 6: The Effect of the Longhorn Opportunity Scholar Program on Education Outcomes – College Attendees

Table 7: Effect of LOS on College Graduation Pathways

LOS School
LOS & CS School

LOS School
LOS & CS School

LOS School
LOS & CS School

LOS School
LOS & CS School

LOS School
LOS & CS School

& Grad Flagship
(1)
0.016****
(0.004)
-0.006
(0.006)

Start UT
& Grad Non-Flagship
(2)
0.001
(0.002)
-0.002
(0.002)

& No TX Public BA
(3)
0.005*
(0.002)
-0.002
(0.003)

& Grad Flagship
(1)
-0.007
(0.004)
0.008**
(0.004)

Start TAMU
& Grad Non-Flagship
(2)
-0.000
(0.002)
0.000
(0.001)

& No TX Public BA
(3)
-0.001
(0.002)
0.004*
(0.002)

& Grad Flagship
(1)
-0.000
(0.001)
-0.000
(0.001)

Start Emerging Research U
& Grad Non-Flagship & No TX Public BA
(2)
(3)
-0.012**
-0.012*
(0.006)
(0.007)
0.008
0.002
(0.006)
(0.008)

& Grad Flagship
(1)
0.002
(0.001)
0.001
(0.001)

Start Other 4 Yr
& Grad Non-Flagship
(2)
-0.002
(0.010)
-0.007
(0.009)

& No TX Public BA
(3)
-0.004
(0.009)
-0.005
(0.010)

& Grad Flagship
(1)
0.002
(0.002)
0.001
(0.001)

Start 2 Yr
& Grad Non-Flagship
(2)
0.006
(0.007)
0.002
(0.007)

& No TX Public BA
(3)
0.007
(0.014)
-0.004
(0.017)

Notes: Estimation of equation (1) in the text using the linked ERC-THECB data for
the 1996-2002 high school graduating cohorts. Each group of two coefficient estimates
in each column comes from the same regression. All models include high school and year
fixed effects as well as the demographic, high school and test score controls discussed
in Section 4 of the text. Restricted to trimmed common support for college attendees
and top 30% of HS class as defined by TAAS achievement index. Sample size is 30,272
for all regressions. Standard errors clustered at the high school level are in parentheses:
***, **, * indicate significance at the 1%, 5% and 10% levels, respectively.

55

Table 8: The Effect of the Longhorn Opportunity Scholar Program on Earnings – College
Attendees

LOS
School
LOS & CS
School
Observations

In 6 Year
Earn Sample
(1)

Ln(Adj Earn)
6 Yrs After HS
(2)

In 10 Year
Earn Sample
(3)

Ln(Adj Earn)
10 Yrs After HS
(4)

In 12 Year
Earn Sample
(5)

Ln(Adj Earn)
12 Yrs After HS
(6)

-0.015**
(0.007)
0.012*
(0.007)

0.014
(0.016)
0.003
(0.017)

-0.015
(0.009)
0.015
(0.009)

0.020
(0.017)
-0.014
(0.018)

-0.019**
(0.009)
0.013
(0.010)

0.040**
(0.018)
-0.021
(0.021)

30,272

26,512

30,272

24,106

30,272

23,627

Notes: Estimation of equation (1) in the text using the linked ERC-THECB data for the 1996-2002 high school
graduating cohorts. Each group of two coefficient estimates in each column comes from the same regression. All
models include high school and year fixed effects as well as the demographic, high school and test score controls
discussed in Section 4 of the text. Restricted to trimmed common support and top 30% of HS class as defined by TAAS
achievement index. Ln(Adj Earn) is calculated as the average residual from a regression of log quarterly earnings on
cohort-by-quarter-year indicators. Only earnings among those with 5 quarters of earnings over $100 in the relevant
time period are included. The highest 0.5% of earnings quarters are excluded from the analysis sample. Standard
errors clustered at the high school level are in parentheses: ***, **, * indicate significance at the 1%, 5% and 10%
levels, respectively.

56

57

36,683

Observations

26,374

0.023***
(0.006)
-0.011
(0.008)

Attend
UT
(2)

28,050

28,826

0.007
(0.013)
0.002
(0.014)
28,826

-0.018*
(0.009)
0.016*
(0.009)
23,108

0.025
(0.017)
-0.016
(0.018)

28,050

0.017***
(0.005)
-0.006
(0.007)
28,050

0.007
(0.013)
0.001
(0.014)
28,050

-0.020*
(0.009)
0.012
(0.007)
22,530

0.022
(0.018)
-0.017
(0.018)

Panel B: Excluding those in Same County
Graduate Graduate in
In 10 Year
Ln(Adj Earn)
UT
6 Years
Earn Sample 10 Yrs After HS
(4)
(5)
(6)
(7)

28,826

0.017***
(0.004)
-0.005
(0.006)

Panel A: Excluding those in Same School District
Graduate Graduate in
In 10 Year
Ln(Adj Earn)
UT
6 Years
Earn Sample 10 Yrs After HS
(4)
(5)
(6)
(7)

26,374

-0.024**
(0.010)
0.013
(0.011)
26,374

0.016***
(0.005)
-0.007
(0.007)
26,374

-0.001
(0.013)
-0.007
(0.013)

26,374

-0.016
(0.010)
0.014
(0.010)

21,005

0.027
(0.019)
-0.017
(0.018)

Panel C: Only High Schools in an MSA with > 300, 000 People
Attend Other
Graduate Graduate in
In 10 Year
Ln(Adj Earn)
Research U
UT
6 Years
Earn Sample 10 Yrs After HS
(3)
(4)
(5)
(6)
(7)

28,050

-0.024**
(0.010)
0.009
(0.011)

Attend Other
Research U
(3)

28,826

-0.023**
(0.010)
0.009
(0.011)

Attend Other
Research U
(3)

26,374

-0.019**
(0.009)
0.012
(0.010)

In 12 Year
Earn Sample
(8)

28,050

-0.024**
(0.009)
0.016*
(0.010)

In 12 Year
Earn Sample
(8)

28,826

-0.023**
(0.009)
0.015
(0.010)

In 12 Year
Earn Sample
(8)

20,591

0.042**
(0.021)
-0.024
(0.022)

Ln(Adj Earn)
12 Yrs After HS
(9)

22,097

0.041**
(0.019)
-0.024
(0.021)

Ln(Adj Earn)
12 Yrs After HS
(9)

22,661

0.045**
(0.019)
-0.024
(0.021)

Ln(Adj Earn)
12 Yrs After HS
(9)

Notes: Estimation of equation (1) in the text using the linked ERC-THECB data for the 1996-2002 high school graduating cohorts. Each group of two
coefficient estimates in each column and panel comes from the same regression. All models include high school and year fixed effects as well as the
demographic, high school and test score controls discussed in Section 4 of the text. Restricted to trimmed common support and top 30% of HS class as
defined by TAAS achievement index. Column (1) contains highs school graduates and the remaining columns include college attendees. “Other Research
University” excludes Texas A&M. Ln(Adj Earn) is calculated as the average residual from a regression of log quarterly earnings on cohort-by-quarter-year
indicators. Only earnings among those with 5 quarters of earnings over $100 in the relevant time period are included. The highest 0.5% of earnings quarters
are excluded from the analysis sample. Standard errors clustered at the high school level are in parentheses: ***, **, * indicate significance at the 1%, 5%
and 10% levels, respectively.

0.006
(0.010)
-0.003
(0.011)

LOS
School
LOS & CS
School

Attend Any
College
(1)

38,501

Observations

Attend
UT
(2)

Attend Any
College
(1)
0.023***
(0.005)
-0.011
(0.008)

28,826

39,692

Observations

0.003
(0.010)
-0.015
(0.012)

0.023***
(0.005)
-0.011
(0.008)

-0.005
(0.001)
-0.017
(0.012)

LOS
School
LOS & CS
School

LOS
School
LOS & CS
School

Attend
UT
(2)

Attend Any
College
(1)

Table 9: Specification Checks of the Effects of the Longhorn Opportunity Scholars Program

58

15,835

Attend
UT
(2)
0.022**
(0.009)
-0.010
(0.002)

21,705

Attend Any
College
(1)

0.003
(0.017)
-0.028
(0.017)

19,883

Observations

LOS
School
LOS & CS
School

Observations

18,921

Observations

13,069

-0.001
(0.007)
0.013
(0.008)
13,069

-0.004
(0.013)
-0.005
(0.015)

Attend Other
Research U
(3)

17,203

-0.041**
(0.011)
0.019
(0.012)

Attend Other
Research U
(3)

14,437

-0.034**
(0.015)
-0.003
(0.015)

Attend Other
Research U
(3)

15,835

-0.020
(0.012)
0.017
(0.015)

Attend Other
Research U
(3)

15,835

-0.003
(0.012)
0.014
(0.011)
15,835

0.003
(0.012)
0.014
(0.011)
12,574

0.025
(0.024)
-0.029
(0.030)

13,069

0.005
(0.006)
0.014*
(0.007)

Graduate
UT
(4)

17,203

0.026***
(0.007)
-0.019**
(0.009)

Graduate
UT
(4)

14,437

0.017**
(0.007)
-0.001
(0.008)
14,437

-0.033**
(0.014)
-0.010
(0.015)

17,203

-0.023**
(0.011)
0.022*
(0.012)

13,069

0.021
(0.016)
0.003
(0.021)

13,069

-0.001
(0.014)
0.007
(0.013)

Panel C: Men
Graduate in
In 10 Year
6 Years
Earn Sample
(5)
(6)

17,203

-0.005
(0.016)
-0.000
(0.015)

Panel B: Women
Graduate in
In 10 Year
6 Years
Earn Sample
(5)
(6)

14,437

0.011
(0.015)
-0.007
(0.019)

10,139

0.004
(0.025)
0.013
(0.031)

Ln(Adj Earn)
10 Yrs After HS
(7)

13,967

0.033
(0.024)
-0.030
(0.028)

Ln(Adj Earn)
10 Yrs After HS
(7)

11,532

0.004
(0.023)
-0.002
(0.036)

Panel A: Not Economically Disadvantaged in HS
Graduate Graduate in
In 10 Year
Ln(Adj Earn)
UT
6 Years
Earn Sample 10 Yrs After HS
(4)
(5)
(6)
(7)

15,835

0.015***
(0.005)
-0.011
(0.008)

Panel A: Economically Disadvantaged in HS
Graduate Graduate in
In 10 Year
Ln(Adj Earn)
UT
6 Years
Earn Sample 10 Yrs After HS
(4)
(5)
(6)
(7)

13,069

-0.003
(0.013)
0.002
(0.017)

In 12 Year
Earn Sample
(8)

17,203

-0.028**
(0.009)
0.022*
(0.012)

In 12 Year
Earn Sample
(8)

14,437

-0.038**
(0.015)
0.002
(0.016)

In 12 Year
Earn Sample
(8)

15,835

-0.003
(0.012)
0.017
(0.011)

In 12 Year
Earn Sample
(8)

9,935

0.012
(0.030)
-0.001
(0.035)

Ln(Adj Earn)
12 Yrs After HS
(9)

17,203

0.061**
(0.025)
-0.035
(0.030)

Ln(Adj Earn)
12 Yrs After HS
(9)

11,306

0.024
(0.024)
-0.002
(0.036)

Ln(Adj Earn)
12 Yrs After HS
(9)

12,321

0.047*
(0.027)
-0.040
(0.034)

Ln(Adj Earn)
12 Yrs After HS
(9)

Notes: Estimation of equation (1) in the text using the linked ERC-THECB data for the 1996-2002 high school graduating cohorts. Each group of two
coefficient estimates in each column and panel comes from the same regression. All models include high school and year fixed effects as well as the
demographic, high school and test score controls discussed in Section 4 of the text. Restricted to trimmed common support and top 30% of HS class as
defined by TAAS achievement index. Column (1) contains highs school graduates and the remaining columns include college attendees. Ln(Adj Earn)
is calculated as the average residual from a regression of log quarterly earnings on cohort-by-quarter-year indicators. Only earnings among those with 5
quarters of earnings over $100 in the relevant time period are included. The highest 0.5% of earnings quarters are excluded from the analysis sample. Texas
defines a student as economically disadvantaged if he or she is eligible for free or reduced price lunch or another Federal or state anti-poverty program.
Standard errors clustered at the high school level are in parentheses: ***, **, * indicate significance at the 1%, 5% and 10% levels, respectively.

0.008
(0.016)
-0.041**
(0.019)

Attend
UT
(2)

Attend Any
College
(1)

LOS
School
LOS & CS
School

17,203

22,667

Observations

0.040***
(0.007)
-0.025**
(0.011)

-0.002
(0.013)
0.004
(0.012)

Attend
UT
(2)

LOS
School
LOS & CS
School

Attend Any
College
(1)

0.020***
(0.006)
-0.013
(0.009)

0.002
(0.012)
-0.003
(0.016)

LOS
School
LOS & CS
School

14,437

Attend
UT
(2)

Attend Any
College
(1)

Table 10: Heterogeneous Effects of the Longhorn Opportunity Scholar Program – College Attendees

