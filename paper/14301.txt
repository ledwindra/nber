NBER WORKING PAPER SERIES

TRANSFER PROGRAM COMPLEXITY AND THE TAKE UP OF SOCIAL BENEFITS
Henrik Jacobsen Kleven
Wojciech Kopczuk
Working Paper 14301
http://www.nber.org/papers/w14301

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2008

The views expressed herein are those of the author(s) and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2008 by Henrik Jacobsen Kleven and Wojciech Kopczuk. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.

Transfer Program Complexity and the Take Up of Social Benefits
Henrik Jacobsen Kleven and Wojciech Kopczuk
NBER Working Paper No. 14301
September 2008
JEL No. H53,I3,I38
ABSTRACT
This paper models complexity in social programs as a byproduct of efforts to screen between deserving
and undeserving applicants. While a more rigorous screening technology may have desirable effects
on targeting efficiency, the associated complexity introduces transaction costs into the application
process and may induce incomplete take up. The paper integrates the study of take up with the study
of classification errors of type I and type II, and argue that incomplete take up can be seen as a form
of type I error. We consider a government interested in ensuring a minimum income level for as many
deserving individuals as possible, and characterize optimal programs when policy makers can choose
the rigor of screening (and associated complexity) along with a benefit level and an eligibility criterion.
It is shown that optimal program parameters reflect a trade-off at the margin between type I errors
(including non-takeup) and type II errors. Optimal programs that are not universal always feature a
high degree of complexity. Although it is generally possible to eliminate take up by the undeserving
(type II errors), policies usually involve eligibility criteria that make them eligible and rely on complexity
to restrict their participation. Even though the government is interested only in ensuring a minimum
benefit level, the optimal policy may feature benefits that are higher than this target minimum. This
is because benefits generically screen better than either eligibility criteria or complexity. We present
numerical simulations on comparative statics with respect to budget size, ability distribution, complexity
costs, and stigma. Our results are discussed in light of empirical findings for public programs in the
United States.

Henrik Jacobsen Kleven
Department of Economics & STICERD
LSE
Houghton Street
London WC2A 2AE
United Kingdom
h.j.kleven@lse.ac.uk
Wojciech Kopczuk
Columbia University
420 West 118th Street, Rm. 1022 IAB
MC 3323
New York, NY 10027
and NBER
wk2110@columbia.edu

1

Introduction

The United States operates a large number of social programs offering support to those
in need. This includes cash assistance to the poor, food stamps, health insurance, housing
programs, child care support, and social security to the aged, blind and disabled. We observe
several striking differences in the design and outcomes of these programs. One difference lies
in the degree of targeting to selected groups of individuals viewed as ‘deserving’. Although
the U.S. welfare state in general relies on a much higher degree of targeting than most
other countries, there is substantial variation in targeting across different programs within
the U.S. At one end of the spectrum, the Medicare program is almost universal, whereas
at the other end of the spectrum, disability insurance programs serve a relatively small
population satisfying very stringent eligibility criteria. A second difference lies in the way
social programs are administered and in their degree of complexity. Targeted programs
tend to be characterized by a substantial amount of complexity and administrative hassle,
whereas universal programs are simpler and more transparent. A third difference lies in the
take up of social benefits. Incomplete take up among intended recipients is an important
issue in all means-tested programs in the U.S., but there is huge variation in participation
across different programs. This is shown in Table I, which compares 10 public programs in
the U.S. along the three dimensions just described.
The large variance in program design and outcomes reflects a number of underlying differences in factors such as funding, benefit generosity, ability distribution among potential
applicants, observability of true eligibility, and costs of screening. We set out a theoretical framework that accounts for all of these underlying differences in order to facilitate an
analysis of targeting, complexity and take up in social programs. We contribute to the existing literature along three dimensions. First, we take an initial step towards modeling and
analyzing complexity in public programs. We go beyond viewing complexity as a negative
side-effect of targeted programs, and treat it instead as a policy instrument which is chosen
alongside benefit levels and eligibility rules in the design of a program. Second, we explain
why governments may want to design a program with high complexity and incomplete take
up by eligibles even though they have access to policy instruments which could increase
take up. Third, we integrate the study of take up with the study of classification errors of
type I (false rejections) and type II (false awards) in benefit award processes. In fact, we
argue that non-enrollment in social programs can be seen as a form of type I error, and that
it has to be understood by considering the trade-off with the usual type I and II errors.
Empirical economists have long been concerned with the issue of incomplete take-up
rates in public programs. The empirical literature hypothesizes three possible explanations
for incomplete take up: welfare stigma, transaction costs, and imperfect information. The
seminal work in this area is the Moffitt (1983) model of welfare stigma, suggesting that
eligibles may find non-participation in a welfare program optimal because it is viewed as
demeaning and shameful. But the stigma hypothesis is consistent with other more concrete
costs associated with taking up social benefits. Indeed, a substantial amount of evidence
have documented that applying for welfare benefits involves large transaction costs aris-

1

ing from application processes being complex, tedious and time-consuming (Moffitt, 2003;
Currie, 2004).
The complexity of welfare programs may arise from detailed eligibility criteria, rigorous documentation requirements, difficult and time-consuming forms, or requiring multiple
trips to the program office for interviewing and testing. Moreover, some programs involve
frequent re-certification to continue to receive the benefit, and applicants are frequently rejected because they fail to fulfill the administrative requirements within the required time.
Notice that these forms of complexity reflect, at least in part, an attempt of program administrators to monitor true eligibility accurately, and hence complexity may have some
desirable effects on the magnitude of classification errors. At the same time, these monitoring activities introduce hassle into the application process, which may hurt take up. Indeed,
empirical research has shown that complexity and administrative hassle do reduce program
enrollment (Currie and Grogger, 2001; Bitler et al., 2003; Daly and Burkhauser, 2003; Aizer,
2007), and that such effects may be more important than stigma (Currie, 2004).
Despite the fact that complexity and administration seem to be very important for the
effects of public policies in general, and for the take up of social benefits in particular, we
are not aware of theoretical work modeling the complexity of public policy. Instead, the
literature on mechanism design has focused on the generosity and structure of benefits and
the incentives for ineligibles to reveal themselves truthfully. The key assumption in this
literature is that innate ability is unobservable at any cost, whereas earnings are perfectly
observable at no cost. The government has no access to a monitoring technology to assess
true eligibility and therefore has to rely on limitations in earnings-based benefits to induce
self-revelation. Our paper goes beyond this extreme assumption about information by
modeling the information collection process — the monitoring technology — used to elicit
true eligibility for social benefits. The empirical work by Benı́tez-Silva et al. (2004) on
disability insurance programs in the U.S. demonstrates that the monitoring technology can
be a very important aspect of program design.
The way we model the complexity — or the rigor — of a monitoring technology is
consistent with the evidence discussed above. It is an instrument used by program administrators to increase the intensity of screening in order to extract a better signal of true
eligibility, but which makes the application process more costly and therefore may induce
non-participation by eligibles. Our model also accounts for imperfect information about
eligibility on part of the potential welfare applicants. The role of imperfect information for
non-enrollment into social programs is well-documented (e.g. Daponte et al., 1999; Heckman
and Smith, 2004), and it serves to reinforce the importance of complexity in the decision
to apply for welfare. It is exactly because of imperfect information about eligibility that an
individual may be reluctant to incur the transaction costs associated with applying.
We characterize program characteristics in equilibrium when policy makers can choose
standard policy instruments — a benefit level and an eligibility rule — along with the
additional instrument capturing program complexity. We model a government interested
in income maintenance, i.e. ensuring a minimum income level for as many truly poor
(‘deserving’) individuals as possible, being constrained by a limited budget. We consider
2

income maintenance rather than social welfare maximization, because the former is more
consonant with real-world policy debates (Besley and Coate, 1992, 1995). In other words,
the primary purpose of the paper is to understand observed program design rather than
exploring the design chosen by a welfarist social planner.
We show that optimal program parameters reflect a trade-off at the margin between type
I errors (including non-takeup) and type II errors. Optimal programs that are not universal
always feature a high degree of complexity. Although it is generally possible to eliminate
take up by the undeserving (type II errors), policies usually involve eligibility criteria that
make them eligible and rely on complexity to restrict their participation. These policies
feature incomplete take up by the deserving along with classification errors of both type
I and II in the benefit award process. Even though the government is interested only in
ensuring a minimum benefit level, the optimal policy may feature benefits that are higher
than this target minimum. This is because benefits generically screen better than either
eligibility criteria or complexity. We present numerical simulations on comparative statics
with respect to budget size, ability distribution, complexity costs, and stigma. Our results
are discussed in light of empirical findings for public programs in the United States.
The rest of the paper is organized as follows. Section 2 defines the different classification
errors in public programs and discusses how they have been studied in the literature. Section
3 presents our model of transfer program complexity, and derives a number of results on
program design, complexity and take up. Section 4 presents numerical simulations, and
Section 5 offers a discussion of applications, assumptions, and extensions.

2

Classification Errors in Social Programs

We view non-participation by eligibles in social programs as a result of program parameters
chosen by policy makers. Viewed in this way, it is natural to think of incomplete take up
as a form of classification error of type I — a false negative. We introduce the following
terminology:
Definition 1 (classification errors)
• Type Ia errors (incomplete take up) occur if a program design results in some truly
eligible individuals not applying for benefits.
• Type Ib errors (rejection errors) occur if a program design results in some truly eligible
individuals applying for benefits and being rejected.
• Type II errors (award errors) occur if a program design results in some truly ineligible
individuals applying for benefits and being accepted.
For a government wanting to alleviate poverty among those who are truly eligible, being constrained by a limited budget, it is desirable to minimize all sources of error. The
occurrence of type Ia and type Ib errors undermine the goal of poverty alleviation, whereas
the occurrence of type II errors make the program more expensive and divert government
revenues away from other productive uses. Hence, the choice of parameters in a welfare
3

program — benefits, eligibility rules and the complexity of the screening process — reflects
the effect of each parameter on the different kinds of error. Indeed, a central message in
this paper is that public programs have to be understood by integrating the treatment of
all three types of classification error and considering the trade-off between them.
While a large empirical literature has analyzed the occurrence of incomplete take up
and hence the occurrence of type Ia error, much fewer papers have attempted to estimate
the occurrence of type Ib and type II errors.1 A small literature looking at classification
error rates in U.S. social security disability award processes suggests that both award and
rejection errors are very common. For example, the recent and interesting paper by Benı́tezSilva et al. (2004) estimates the award error rate of about 20% and the rejection error rate
of about 60%.2
Opposite the empirical literature, we have a theoretical literature analyzing optimal
mechanism design in transfer programs. A large set of papers have studied the relationship
between benefit structure and the incentives self-revelation.3 Assuming that there exists no
monitoring technology to assess true eligibility, these papers deal exclusively with type II
errors and how to avoid them by restricting benefits in different ways.
A smaller set of papers, starting with the important contribution by Akerlof (1978),
introduced a simplified monitoring technology into the mechanism design problem. This
monitoring technology — labelled ‘tagging’ by Akerlof — can identify perfectly a given
subset of eligibles. The screening process is imperfect because some eligibles are not tagged
(a type Ib error) and it is exogenous to policy makers. While Akerlof did not allow for type
II errors, a few subsequent papers extended his work to incorporate two-sided classification
error (Stern, 1982; Diamond and Sheshinski, 1995; Parsons, 1996) assuming fixed award
and rejection error rates.
Our paper is different from the existing literature in two important respects. First, the
monitoring technology is not exogenous in our model. We analyze the choice of monitoring
technology — the rigor of screening and associated complexity — as a policy instrument.
Second, we integrate the treatment of all three types of classification error, taking into
account that the magnitude of errors are endogenous to parameters chosen by policy makers.
This includes allowing for reduced take up in response to increased program complexity. In
order to zoom in on the participation decision in public programs, our framework abstracts
from other types of behavioral responses such as labor supply responses.
1

A qualification is in place here. Empirically, it is often difficult to distinguish between type Ia and type
Ib errors. What we observe in survey data is that some eligible individuals do not receive benefits, and this
may in principle reflect either form of type I error. This implies that estimates of take-up rates may in part
capture rejection errors as well.
2
An early study by Nagi (1969) reached broadly similar conclusions.
3
This literature includes Diamond and Mirrlees (1978) Nichols and Zeckhauser (1982), Blackorby and
Donaldson (1988), Bruce and Waldman (1991), Besley and Coate (1992, 1995) and Saez (2002).

4

3

A Model of Social Program Complexity

3.1

Individuals

We assume that each individual is characterized by two parameters: an innate characteristic a and the precision by which this characteristic can be observed by outsiders σ. The
characteristic a may reflect market productivity, or it may reflect other types of characteristics — say health or disability — depending on the program being considered. In the
following, we refer to a simply as ‘ability’ or ‘skill’. These skills are private information
and cannot be ascertained directly by anyone else. Instead, if the individual attempts to
claim welfare benefits, the government can test the individual and obtain a signal of true
ability, ã = a + ε/α. The noise term ε reflects that program testing is imperfect, whereas
the parameter α is a policy choice capturing the rigor of the test. We will come back to the
interpretation and implications of α below.
Based on empirical analyses of benefit award processes (see Benı́tez-Silva et al., 2004),
we assume that ã is a noisy but unbiased indicator of true ability so that ε is distributed
with mean zero and variance σ 2 . We assume that the normalized distribution of ε/σ (which
has mean zero and variance one) is characterized by a c.d.f. P (.), which is identical for
everyone. We allow for the fact that the precision of measured skill, σ, may vary across
individuals even if they have identical abilities. The heterogeneity in σ reflect that equally
eligible individuals may test with more or less uncertainty in the welfare program. Aspects
such as language barriers, unfamiliarity with the administrative procedures, inability to
understand the formal requirements of the test, etc., would all contribute to creating more
uncertainty in the test.
As for the α-parameter, one possible interpretation is to view it as the number of tests.
Under this interpretation, the government can subject an applicant to different tests in
order to obtain indicators of skill. Each test leads to an indicator given by ai = a + εi
where εi ∼ N (0, σ 2 ) — i.e., each indicator is a normally distributed unbiased indicator of
the true skill level with variance σ 2 . Examples of tests are interviews with case workers, a
requirement to provide supporting documents, an opinion of a medical commission regarding
disability, etc. The common denominator of these types of indicators is that they are costly
to an individual and the outcome is not known a priori. Under this interpretation, the
government estimates the skill of an individual using the arithmetic mean of α2 tests, the
distributional properties of which is exactly identical to ã = a + ε/α with ε ∼ N (0, σ 2 ).4
More generally, the policy parameter α determines the extent of randomness in the
application process. We maintain the assumption that reducing randomness imposes a
burden on individuals, because of increased out-of-pocket application costs and more time
spent on forms, interviewing and providing documentation, etc. We represent the cost to
the individual of complexity α by a function f (α).
We assume that the government sets an eligibility criterion for receiving benefits denoted
by ā. When the government relies on complexity α, benefits are granted to applicants who
√
Alternatively, if we had specified ã = a + ε/ α, then α (rather than α2 ) would be the number of tests.
We use the specification above because it is notationally simpler.
4

5

satisfy
ã = a + ε/α < ā.

(1)

The probability thatan applicant
with skill level a and precision σ receives benefits is

α(ā−a)
therefore given by P
. We come back to the properties of P (.) below.
σ
When making the participation decision, an individual knows the probability of being
granted the benefit and trades off the potential utility gain from welfare payments against
the cost of applying. We assume that utility depends on consumption C — equal to the
sum of ability a and the (potential) welfare benefit B — and on application costs f (α). The
utility level is given by u(C − Af (α)), with A being an indicator variable for having applied.
We make the standard assumption that u(.) is increasing and weakly concave (allowing for
the possibility of risk neutrality). We also assume that lim u(C) = ∞ and lim f (α) = ∞.
α→∞
C→∞
An individual chooses to apply when





α(ā − a)
α(ā − a)
u(a + B − f (α)) + 1 − P
u(a − f (α)) > u(a),
(2)
P
σ
σ


and, conditional on applying, will receive benefits with the probability of P α(ā−a)
.
σ
Ceteris paribus, a higher probability of receiving benefits increases the expected utility
from applying. The probability of receiving benefits conditional on applying depends on
the complexity parameter α, eligibility criterion ā, ability level a, and personal precision
of ability signals σ. A higher ā unambiguously increases the probability, whereas a higher
a unambiguously decreases it. The effect of complexity α and precision σ depends on the
sign of ā − a. When ā > a, higher complexity and better precision both increase the
probability of receiving benefits. This is intuitive: when the individual is eligible under
perfect information, reducing the noise in the eligibility metric is helpful. When ā < a,
we have the opposite situation. While greater complexity may increase or decrease the
likelihood of receiving benefits depending on the sign of ā − a, its effect on the ex post
utility level is unambiguously negative regardless of whether benefits are received or not.
Using the participation constraint (2), we may solve for the minimum probability, P̃ ,
consistent with applying for benefits:
P̃a (α, B) ≡

u(a) − u(a − f (α))
.
u(a + B − f (α)) − u(a − f (α))

(3)

Individuals with a probability of receiving benefits above this critical value choose to apply
for benefits, while the rest choose not to apply. In general, the threshold probability depends
on the skill level a. In particular, it may be shown to be decreasing or increasing in ability
depending on whether the utility function features decreasing or increasing absolute risk
aversion. We do not have a strong prior as to whether higher ability individuals are willing
to accept lower odds when applying for benefits, but the realistic case of decreasing absolute
risk aversion would imply that this is the case. There are a number of other factors not
modeled here that would have implications for this issue. For example, we restrict attention
to a flat benefit although in practice the size of the benefit could depend on the realization
of the indicator ã. Letting the benefit depend negatively on ã would increase the minimum
6

odds acceptable to the higher-ability individuals. Application costs may also vary with the
ability level. On the one hand, if it is easier for high-ability applicants to file an application,
their minimum acceptable probability would be lower. On the other hand, high-ability
applicants tend to face higher opportunity cost of time spent applying, which would make
their threshold probability higher.
We will simplify the analysis by restricting attention to the class of preferences that
eliminates the dependence of P̃a on a:
Assumption 1 The utility function has the Constant Absolute Risk Aversion (CARA)
−βC
form, u(C) = 1−eβ , where β ≥ 0 (this specification reduces to risk-neutrality u(C) = C
for β = 0).
Assumption 1 is not trivial and we elaborate on its consequences in the final section.5 Under
this assumption, the threshold probability level for applying is given by
(
1−e−βf (α)
, when β> 0,
1−e−βB
P̃ (α, B) =
(4)
f (α)
when β= 0,
B ,
P̃
which is no longer a function of the ability level. It is straightforward to show that ∂∂α
>0
∂ P̃
and ∂B < 0: a higher level of complexity increases the minimum acceptable probability of
receiving benefits, whereas higher benefits decrease it.
Expressing the participation constraint as


α(ā − a)
P
> P̃ (α, B),
(5)
σ

it can be solved for the precision level corresponding to indifference between applying and
not applying:
α(ā − a)

.
(6)
σ̄ a (α, ā, B) ≡
P −1 P̃ (α, B)
When ā > a, individuals with σ lower than σ̄ a (high precision) apply for benefits. When
ā < a, only individuals with σ greater than σ̄ a (low precision) choose to apply.

3.2

Population

We assume that there are two levels of ability: a low level aL and a high level aH . At
each ability level, individuals are heterogeneous with respect to σ: for some, their ability
level may be easily observable while for others it may be very difficult to ascertain without
extensive testing. We note the following:
Remark 1 At each ability level, let the precision of measured skill σ be distributed on
[0, ∞). There are three qualitative cases for the distribution of the probability of receiving
benefits in the population:
5

The only reason for making the CARA-assumption is that it eliminates the dependence of P̃a on a.
We argue in the final section that this implication of CARA is a realistic description of the real world,
although it may reflect dimensions of heterogeneity not incorporated in our model. Generalization of the
model to non-CARA preferences that preserves the central property of P̃a are possible by adding additional
dimensions of heterogeneity.

7

1. ā ≤ aL < aH . Probabilities are in (0, P (0)] and increasing in σ (always strictly
increasing for high-ability individuals, strictly increasing for low-ability individuals
only if ā < aL ).
2. aL < ā ≤ aH . Probabilities for low-ability individuals are in (P (0), 1) and strictly
decreasing in σ; probabilities for high-ability individuals are in (0, P (0)] and increasing
in σ (strictly increasing if ā < aH ).
3. aL < aH < ā. Probabilities are in (P (0), 1) for both types and are strictly decreasing
in σ.
Whenever a 6= ā, any probability in the appropriate open interval, (0, P (0)) or (P (0) , 1),
can be attained for some σ ∈ [0, ∞).
This remark implies a “non-monotonicity” in committing Type II errors: they have to
be committed when either ā < aL or ā > aH , but not for intermediate values of ā. In the
former cases, because the intervals of probabilities of receiving benefits are identical for the
low- and high-ability populations, it will be impossible to avoid type II errors altogether.
Note that P (0) reflects a property of the normalized distribution of ε and therefore it is
a constant independent of policy parameters or individual characteristics. In the natural
case where the likelihoods of over- and understating true ability are identical such that
median(ε) is zero, we have P (0) = 1/2. Recall that the threshold probability for applying
P̃ depends on the policy parameters α and B and, if these parameters are not constrained,
P̃ can take any value. As a result,
Remark 2 There exist policy parameters that result in no Type II errors (“full separation”); only low ability individuals apply. Such policies are characterized by aL < ā ≤ aH
and P̃ (α, B) ≥ P (0).
Moreover, there also exist policy parameters that additionally result in no Type Ia errors.
They are characterized by aL < ā ≤ aH and P̃ (α, B) = P (0).
One of the objectives of our analysis will be to determine whether policies with no type Ia
and type II errors are optimal and, despite their apparent attractiveness, we will show that in
the most interesting cases they are not. In particular, note that a government implementing
a policy of full separation where P̃ (α, B) = P (0) — i.e., no type II or type Ia errors —
will continue to make Type Ib errors. That is, despite that only low-ability individuals are
applying, some of them will be rejected. In fact, in the case of a symmetric distribution for
ε where P (0) = 1/2, some low-ability applicants will face probabilities of receiving benefits
as low as 1/2. Reducing the number of Type Ib errors can be accomplished by increasing
the rigor of screening α, but in order to avoid Type Ia errors, the government must increase
benefits correspondingly. Such increases are costly and, at the same time, constrained
in their size when one wants to simultaneously discourage high-ability individuals from
applying. As a result, the government faces serious constraints in pursuing policies that
reduce the number of type Ib errors without introducing other types of classification error.
8

As we will demonstrate, these constraints may be severe enough to justify committing all
three types of error.
To complete the characterization of the assumptions about the population, we need to
specify the distribution of σ. We will denote the c.d.f. of the distribution of σ for ability-type
a by Ga and the corresponding density function by ga . The support of both distributions is
assumed to be [0, ∞). We assume that ga (0) = 0, the density of individuals with perfectly
R∞
observable skill is zero. The number of individuals of type a is given by N̄a ≡ 0 dGa (σ),
with both N̄L and N̄H assumed to be positive and finite.
Some of our results will depend on the following regularity assumptions:
Assumption 2 (thin tail for low ability) lim σ 2 gL (σ) = 0.
σ→∞

0 (σ) < ∞.
Assumption 3 (finite slope of density at zero for high ability) lim gH
σ→0

The first assumption states that the distribution of σ has no thick tail. In particular,
it rules out the Pareto distribution, but it allows for distributions that have thinner tails
such as the log-normal distribution. Intuitively, it will allow for the number of low-ability
applicants to respond smoothly to policy changes that just discourage applying by everyone.
The second assumption will guarantee that small changes in policy that make it beneficial
for the high ability individuals to apply will result in only a small influx of them.
To summarize the model so far, Figure 1 illustrates the distribution of P (.) and classification errors for a particular program. Both panels show the P -distribution for low- and
high-ability individuals, with Panel A highlighting the results for the low-types and Panel
B highlighing the results for the high-types. The figure illustrates a program with ā > aH ,
implying that P (.) is distributed on the interval (P (0), 1) for both types and is strictly
decreasing in σ. We focus on this type of program, because it turns out to be interesting
later on. The graphs are based on an actual numerical simulation that we discuss in detail
in Section 4. The distribution of P (.) is determined by the distribution of the noise term
ε/σ (which is assumed to be normal so that P (0) = 1/2) along with the distribution of
the precision of measured skill σ (which is assumed to be log-normal). Given ā > aH ,

densities of P (.) are positive everywhere in the open interval 12 , 1 for both types, because any probability in this interval can be attained for some σ ∈ [0, ∞). At a given σ,
low-ability applicants have a higher probability of being awarded benefits, and hence the
P -distribution for low-ability individuals is shifted to the right compared to the distribution
for high-ability individuals. The two types have the same threshold probability P̃ (= 0.736
in the simulation), and individuals with higher P s than this (corresponding to those with
low σs) apply for benefits. The program is associated with all three types of classification
error. In the low-ability distribution, type Ia (take-up) errors are committed in the region
to the left of P̃ , while type Ib errors occur in the region to the right because probabilities
of acceptance are lower than 1. In the high-ability distribution, type II errors occur in the
region to the right of P̃ because probabilities of acceptance are greater than zero (in fact,
greater than 0.736). An interesting question is whether a program outcome of this kind can
be an equilibrium outcome. To study this question, we turn to the final piece of the model:
the specification of the government’s objective.
9

3.3

Government

We consider a problem of income maintenance extending the specification of Besley and
Coate (1992, 1995). They considered the design of income maintenance programs ensuring
that each individual obtains a target minimum benefit at a minimum fiscal cost. In our
model — as in reality — we do not necessarily have full participation, because eligible
individuals may choose not to apply for the benefit and because eligible applicants may
be rejected by program administrators due to imperfect testing. Hence, the objective becomes to provide a minimum benefit for as many low-ability (truly deserving) individuals
as possible, being constrained by a limited budget.6
Denoting by B̄ the target minimum benefit and by R the exogenously given budget size,
the government’s problem may be written as
max

α,ā,B

NL (α, ā, B)

(7)

subject to
[NL (α, ā, B) + NH (α, ā, B)] B ≤ R

(8)

B ≥ B̄,

(9)

and

where Na (α, ā, B) is the number of successful applicants of type a as a function of policy
parameters.
There are several aspects of our policy objective that deserve mentioning. First, even
though policy makers are interested in providing low-income support, they are not concerned
with the utility cost that program complexity imposes on individuals. As discussed in the
beginning, this is not a welfarist framework. While an extension of the model to social
welfare maximization would be interesting, the approach adopted here fits better with
actual political debates on poverty relief, which tends to be based on the notion that being
poor means having too little income, not having too low utility. In other words, we view
our modeling strategy primarily as a piece of positive economics, even though it may of
course also be seen as normative if one subscribes to the view that income maintenance
rather than utility maximization is normatively justifiable.
Second, we assume that benefits cannot fall below some minimum value despite that,
in general, not all of the low-ability individuals are going to receive benefits (note though
that the government can increase benefits above B̄). Reducing benefits to a small enough
value would allow for providing benefits to everyone, and therefore allowing for unrestricted
benefits is incompatible with a non-trivial problem of maximizing the number of deserving
recipients. Absent a direct welfarist objective, providing a target minimum income to
successful recipients is a natural way of modeling the goal of poverty alleviation.
Third, we do not model the revenue side of the system. While the distortions introduced
are undoubtedly important, our model does not necessarily describe the full society. Rather,
6

Interestingly, as noted by Besley and Coate (1992), this policy objective fits Mill’s (1848) characterization
of the poverty-alleviation problem as “how to give the greatest amount of needful help, with the smallest
encouragement to undue reliance on it.”

10

our “high-ability” individuals should be viewed as still relatively poor but not poor enough
to be in need of social welfare. Under this interpretation, benefits are financed by a wealthier
(and not modeled) segment of the society.
Fourth, the government pursues policies that are horizontally inequitable. Some lowability individuals are going to receive benefits while others will not. The point we make is
that it is not possible to pursue a horizontally equitable policy unless one is able to provide
benefits to everyone — rich and poor. This is a property of this model and, likely, of the
real world: in order to reach every poor individual we would have to accept a very large
number of Type II errors.
In the following section, we characterize social programs that solve the problem specified
above. We show that the solution depends, among other things, on the size of the program

budget R. We restrict attention to program budgets satisfying R < B̄ N̄L + N̄H . If the
budget were larger than this, the government’s problem has a simple solution: the number
of low-ability applicants reaches its theoretical maximum N̄L by giving a universal benefit

B ≥ B̄ to everybody, which is an affordable policy when R ≥ B̄ N̄L + N̄H . A universal
benefit would be implemented by letting the eligibility criterion ā tend to infinity, in which
case the probability of receiving benefits tends to 1 for everybody.

3.4

Results

We begin our analysis of the model by specifying the first-best allocation that the government would pursue under full information.
Definition 2 (first best) Suppose that it is possible to observe both a and σ. Then the

optimal policy provides benefits B̄ to min R/B̄, N̄L individuals with ability aL . The choice
of these individuals is undetermined (there are many first-best policies).

The requirement that a first-best program must reach min R/B̄, N̄L recipients amounts
to saying that the program either spends the entire budget R or, if there are unused funds,
this is because there are no low-ability individuals left who have not received benefits.
Notice that this definition of a first-best policy is conditional on the exogenous funds R
allocated to the program, and therefore does not account for the fact that the amount of
revenue allocated to a program may in itself depend on the information available to policy
makers. In particular, if information were perfect, it would not make sense to allocate
funds to a program such that R > B̄ · N̄L given the problem specified in (7)-(9). The
purpose of the above definition is not to specify a “global” first best, but to specify the best
possible outcome for a program designed under imperfect information at any given budget
size R. Given the presence of imperfect information, even if a program has a large budget,
R > B̄ · N̄L , it will not be able to reach all low-ability individuals, and this is therefore an
interesting case to consider. We come back to this point below.
As noted in Remark 2, there exist policies that result in providing benefits only to lowability individuals. In certain cases, it is possible to achieve one of the first-best allocations
despite the lack of perfect information.

11

Proposition 1 (first best) First-best programs always involve full separation. For R
small enough, first-best is feasible and the optimal program is characterized by aL < ā ≤ aH ,
B = B̄, and P̃ (α, B̄) ≥ P (0). The optimum is not necessarily unique.
Proof. Setting policy instruments such that aL < ā ≤ aH , B = B̄, and P̃ (α, B̄) ≥ P (0) ensures
that (i ) benefits are provided only to low-ability individuals and (ii ) each recipient receives only the

target minimum. The final requirement for a program to be first best is that NL = min R/B̄, N̄L .
To see that this is only possible if the budget is “small”, notice that the class of programs specified
above can never reach all low-ability individuals. The number of low-ability recipients within this
class of programs is maximized by setting ā = aH . Given ā = aH and B = B̄, it is not possible to
set α such that NL = N̄L . This is 
because, at any finite α, the probability of rejection for each lowα(aH −aL )
, is greater than zero, and α cannot be increased without bound
ability applicant, 1 − P
σ
because the associated increase in P̃ (α, B̄) would ultimately discourage all applications. Hence,
there is a maximum number of low-ability individuals NL∗ < N̄L that can be reached within the
class of programs we have specified. Define R∗ = B̄ · NL∗ < B̄ · N̄L as the largest budget that can
be spent on this type of program, and denoteby α∗ the level of α that achieves NL∗ . Now, for
R > R∗ , we always have NL < min R/B̄, N̄L and therefore not first best. Conversely, for any
R < R∗ , we can always ensure NL = min R/B̄, N̄L by increasing α beyond α∗ (because a higher
α increases P̃ and low-ability recipients fall to zero for high enough α because complexity costs
outweigh benefits). Finally, because first-best programs are always associated with R/B̄ < N̄L , and
because programs that provide benefits to any high-ability individual imply NL < R/B̄, first-best
policies always involve full separation.

The proposition shows that, if the budget is small enough, we can spend all of the
money providing the target minimum B̄ to low-ability individuals only, which is the firstbest outcome a the given budget. In particular, this is the case for R ∈ (0, R∗ ] where

R∗ < B̄ · N̄L . At the other extreme, if the budget is very large, R ≥ B̄ N̄L + N̄H ≡ R̄, we
pointed out above that the optimal program offers a universal benefit B ≥ B̄ to everybody.
This type of program is also first best, because the government can never do better than
this given the specified policy objective.7 The most interesting case is the one in between

the small-budget case R ∈ (0, R∗ ] and the very-large-budget case R ∈ R̄, ∞ , i.e. where

R ∈ R∗ , B̄ N̄L + N̄H , in which case first best is not feasible. The rest of this section is
devoted to characterizing optimal social programs in this intermediate range.
We have to consider both full separation (but non-first best) programs and non-full
separation programs. We start by noting that, at any budget size, full separation policies
are always feasible:
Lemma 1 (type II errors can be avoided) At any budget size, there exists a policy
that satisfies the budget constraint and involves full separation.
Proof. We just need to consider the situations where the first-best policy is not feasible. Let us
consider policies involving P̃ (α, B) = P (0) and ā = aH . For such policies, no high-ability individuals
apply, whereas all of the low-ability individuals apply. Consider increasing α while simultaneously
increasing B to keepP̃ (α, B) = P (0). By construction, this policy will retain full separation. As

L)
increases and tends to one for any σ and therefore, because all of the lowα → ∞, P α(ā−a
σ
ability individuals apply, the number of low-ability individuals receiving benefits increases and tends
to N̄L . Simultaneously, we need to have B → ∞ and therefore spending will be tending to ∞.
Hence, at some point the full budget will be spent.

7

Proposition 1 do not account for this type of first-best program. As mentioned above, the results in this
`
´
section restrict attention to program budgets satisfying R < B̄ N̄L + N̄H .

12

Notice that, when the budget is large, full-separation policies that exhaust the entire
budget feature benefits that are higher than B̄. Higher benefits tend to attract highability individuals, but they can be discouraged from applying by having a high degree of
complexity.
To characterize the optimal policy under full separation, we will need the following
lemma:
Lemma 2 Consider a < ā and P̃ (α, B) = P (0). Under assumption 2,
1. a small increase in α increases the number of individuals receiving benefits Na (α, ā, B)
(even though it reduces the number of applicants)
2. a small decrease in B has no effect on the number of individuals receiving benefits
Na (α, ā, B)
3. Na (α, ā, B) is continuously differentiable in α and B (despite switching from everyone
applying to non-full take-up).
Proof. See the appendix.
Assumption 2 guarantees smoothness of the number of beneficiaries when α and B
change so as to just stop some people from applying: these are the people with the highest
variances and the thin-tail assumption implies that there are not ‘many’ of them. We can
then characterize the optimal full-separation, non-first best program as follows:
Proposition 2 (best policy avoiding type II errors) Under assumption 2, the best policy implementing full separation when the first-best allocation is not feasible is characterized
L
by B > B̄, ā = aH , P̃ (α, B) > P (0), and ∂N
∂α = 0.
Proof. First, since the first-best allocation is not feasible, a full separation policy that spends all
of the budget must have B > B̄. By Lemma 1, there exist full separation policies that satisfy the
budget constraint.
Second, the best full separation policy involves ā = aH . To see this, suppose instead that ā < aH
in the optimum. Then we can increase ā to aH , which would imply more low-ability people receiving
benefits. Now, we are spending too much money, but we can reduce B until the budget is satisfied
(this is possible because initially B > B̄ and at B̄ not everything is spent). In the new equilibrium,
we have NL B = R and a lower B, so that NL must be higher, contradicting that ā < aH was
optimal.
Third, the optimal policy involves P̃ (α, B) > P (0). Conversely, suppose that P̃ (α, B) = P (0).
Consider increasing α slightly so that P̃ (α, B) > P (0). By Lemma 2, the number of low-ability
recipients increases and spending increases over R. Therefore, we may now reduce B until spending
falls to R (we may do so because B > B̄ to begin with). We end up with all of the budget spent,
lower benefits and therefore more low-ability individuals receiving benefits — a contradiction.
Finally, having established that B > B̄, a = aH , and P̃ (α, B) > P (0), the problem is to maximize
NL (α, aH , B) with respect to α and B, subject to NL (α, aH , B)B = R. The latter equation can be
N +B

∂NL

L
∂B
. The problem we solve is now equivalent to maximizing
solved for B = B(α) where ∂B
∂α = −
B
∂NL ∂B
∂B
L
NL (α, aH , B(α)) with respect to α. The first-condition is ∂N
∂α + ∂B ∂α = 0. Substituting for ∂α and
∂NL
∂NL ∂B
∂B
simplifying yields ∂α NL = 0. Inserting this into the original first-order condition ∂α + ∂B ∂α = 0,
L
we obtain ∂N
∂α = 0. We are guaranteed that such a point exists because NL is positive and increasing
in α at P̃ (α, B) = P (0) (by Lemma 2), NL is equal to zero when P̃ (α, B) = 1, and P̃ (α, B) itself
increases with α (and attains the value of one for a sufficiently high α).

13

This proposition has several implications. First, because P̃ (α, B) > P (0) both kinds of
Type I error are made:
Corollary 1 The best policy that avoids Type II errors involves both Type Ia and Ib errors.
Although the objective is to maximize the number of low-ability recipients and the
government is able to discourage high-ability individuals from applying, the optimal policy is
associated with incomplete take up. The reason is that discouraging high-ability individuals
from applying makes it impossible to provide benefits to all of the low-ability individuals
who do apply. Given that some Type Ib errors are being made, it is always optimal to
reduce their number somewhat at the cost of introducing some Type Ia errors.
Second, the optimal policy features benefits that are higher than the minimum required
level B̄. This is a mechanical result. Given that full separation imposes a restriction on ā
and given that a sufficiently high α discourages applications, the only way to spend all of
the budget while retaining full separation is by increasing B.
Third, the optimal full separation policy involves setting complexity α such that it
has no effect at the margin on the number of low-ability recipients. This implies that the
additional discouragement of low-ability applicants from a higher complexity cost (operating
through P̃ (α, B))
 offset by a higher probability of receiving benefits conditional
 is exactly
α(ā−aL )
. As we shall see below, this result does not carry over to optimal
on applying, P
σ
non-separation policies.
Finally, observe that full-separation policies (whether first-best is feasible or not) may
be very costly in terms of the complexity burden that they impose on welfare recipients. As
an example, consider the case of risk-neutrality where P̃ (α, B) = f (α)
B . At the optimum, we
have P̃ (α, B) ≥ P (0) and therefore f (α) ≥ P (0)B. Hence, the cost of complexity consumes
at least a fraction P (0) of welfare transfers. Recall that P (0) is the probability that an
individual will test below his true ability level. Under the natural assumption that the
distribution of tests is symmetric, i.e. P (0) = 21 , complexity consumes at least one-half of
the income surplus for those who get the benefit. Since some applicants are rejected in the
process, aggregate complexity costs may then constitute more than half of the surplus to
all welfare applicants.
So far, we have imposed the rigid restriction that the policy maker attempts to keep
high-ability individuals from applying. This must be the best policy if one can simultaneously set B = B̄ because the number of the low-ability recipients then reaches its theoretical
maximum. However, as we have shown, this is possible only if the budget is small enough
(Proposition 1). For greater budgets, the best full separation policy requires overpaying
benefits (Proposition 2), and therefore it is possible that allowing some high-ability individuals to apply while simultaneously reducing benefits will result in a higher number of
low-ability recipients. Indeed, we can show
Lemma 3 Under assumption 3, we can improve upon the policy characterized in Proposition 2 by increasing ā slightly.
Proof. In the appendix.
14

This result follows because a small increase in the eligibility threshold above aH has
only a second-order effect on the number of high-ability recipients who are just becoming
eligible while having a first-order effect on the number of low-ability recipients. This allows
for reducing the benefit below the level prevailing under the optimal full-separation policy
(where B > B̄), and therefore financing a higher number of low-ability recipients. Hence,
Corollary 2 (type II errors are optimal) When the first-best allocation cannot be implemented, the second-best policy always involves non-separation.
This is an important result. Even though it is possible to discourage high-ability individuals from applying, it is not optimal. The optimal policy will therefore involve both
Type I and Type II errors.
The rest of this section will be devoted to characterizing the optimal policy under nonfull separation. While Lemma 3 establishes that there exists non-separation programs with
ā > aH that dominate the best full separation program, we have to consider the possibility
that the optimal non-separation program is associated with a “stringent” eligibility criterion,
i.e. ā ≤ aH . All else equal, a stringent eligibility criterion will of course discourage highability applicants from applying, but we can bring them back in by having a low complexity
so that P̃ (α, B) < P (0). However, we can show that non-separation policies combining a
stringent eligibility criterion with low complexity (ā ≤ aH and P̃ (α, B) < P (0)) are always
dominated by non-separation policies that combine a lenient eligibility criterion with high
complexity (ā > aH and P̃ (α, B) ≥ P (0)):
Proposition 3 (eligibility criterion is “lenient”) When the first-best allocation is not
feasible, setting ā ≤ aH is never optimal.
Proof. Lemma 3 implies that, if the first best is not feasible, the full separation policy is not
optimal. Therefore, we want to consider non-full separation policies where ā ≤ aH and P̃ < P (0).
Suppose a policy of this kind, denoted by (α∗ , ā∗ , B ∗ ), is optimal. Consider then an alternative policy
that keeps B = B ∗ , set ā to satisfy max{ā∗ , aL }, and adjusts α to obtain P̃ = P (0). The number
of high-ability applicants drops to zero, whereas all of the low-ability applicants will apply with the
probability of receiving benefits increasing for each of them.8 This change therefore increases the
value of the objective function. If this policy results in a reduction in the total number of beneficiaries
(note that all of the previous high-ability recipients drop out), it is affordable and therefore it is an
improvement — contradiction. Otherwise, if the policy increases the total number of recipients, it
is not affordable. If B ∗ > B̄, we can then reduce benefits. Such an adjustment will maintain full
separation and if it yields an affordable policy it must be an improvement because full budget will
be spent on lower benefits paid to low-ability individuals only. This again contradicts the optimality
of the original policy. When reducing benefits to B̄ results in a policy that is still unaffordable, that
implies that it is possible to spend more than the full budget on a first-best allocation and therefore
the first-best allocation can be implemented as in the proof of Proposition 1, thereby contradicting
the assumption that first-best allocation is not feasible.
The intuition for the result in Proposition 3 is that stringent programs with low complexity are associated with a lot of type Ib errors. In particular, if ā ≤ aL , all low-ability
For the case where max{ā∗ , aL } = aL , there is a technical qualification due to the fact that the participation constraint (5) is written with strict inequality. Because of this, if ā = aL and P̃ = P (0), the
low-ability individuals would not apply. To be precise, the government would instead have to set ā = aL + δ
where δ can be arbitrarily small, in which case all low-ability individuals would apply.
8

15

applicants would face probabilities of receiving benefits below P (0). If instead aL < ā ≤ aH ,
low-ability applicants would face probabilities of receiving benefits distributed on (P (0) , 1],
but the rigor of screening is low and therefore, even though low-ability applicants are formally eligible, the distribution of the P s is concentrated toward the lower end of the support
P (0).
We next demonstrate that the optimal policy changes smoothly from the first-best region
to the non-full separation region.
Proposition 4 Denote by R∗ the maximum budget that allows for implementing the first
best allocation and let (α, ā, B) = α∗ , aH , B̄ be the corresponding optimal policy. Denote
by x(R) = (α(R), ā(R), B(R)) the optimal policies as a function of R, R ≥ R∗ . The function
x(R) is right-continuous at R∗ .
Proof. In the appendix.
Recall the structure of our problem: we maximize the number of low-ability recipients
NL subject to the constraints (NL + NH )B = R and B ≥ B̄. Lemma 2 guarantees that
NL and NH are both continuously differentiable at P̃ (α, B) = P (0) which is the only
point where it is not immediately obvious. Therefore, the maximum satisfies the following
first-order conditions (where λ is the Lagrange multiplier associated with the government
budget):


∂NL ∂NH
∂NL
−λ
+
B = 0,
(10)
∂α
∂α
∂α


∂NL
∂NL ∂NH
−λ
+
B = 0,
(11)
∂ā
∂ā
∂ā




∂NL
∂NL ∂NH
−λ
+
B − λ (NL + NH ) (B − B̄) = 0,
(12)
∂B
∂B
∂B
where the first bracketed term in equation (12) is non-positive and the second is nonnegative. When one considers a restricted problem of selecting α and ā holding B constant,
condition (12) need not hold but equations (10) and (11) remain valid. Consequently, as
long as α and ā are selected optimally given B, we must have:
∂NL /∂ā
∂NL /∂α
λB
=
=
.
∂NH /∂ā
∂NH /∂α
1 − λB

(13)

Neither eligibility criterion ā nor the intensity of screening/complexity α have a direct
revenue cost. Therefore, intuitively, what matters in comparing them is how well each of
them screens low- from high-ability individuals. This is summarized by the marginal change
in the number of low-ability recipients relative to the marginal change in the number of
high-ability recipients. At the optimum, the two instruments screen equally well. It is also
∂NL /∂ā
L /∂α
straightforward to show that when ∂N
> ∂N
∂NH ∂α , ā should be increased and/or α
H / ∂ā
reduced, with the opposite implication when the sign of this inequality is reversed.
∂NH
L
In general, the effect of α on the number of recipients of each type, ∂N
∂α and ∂α ,
∂NL /∂ā
may be either positive or negative. But because ∂N
is always positive, any program
H /∂ā
∂NH
L
satisfying eq. (13) must be associated with complexity such that ∂N
∂α and ∂α have the
16

same sign. In the next section, we present numerical simulations showing that the optimal
∂NH
L
solution is typically associated with ∂N
∂α and ∂α being negative.
Before continuing, we state the following very useful identity that links derivatives of the
number of recipients with respect to the three instruments (the proof is in the appendix):
∂Na
ā − a ∂Na
∂ P̃ /∂α ∂Na
=
+
,
∂α
α ∂ā
∂ P̃ /∂B ∂B

where

∂ P̃ /∂α
eβB − 1
· f 0 (α)
= − βf (α)
e
−1
∂ P̃ /∂B

(14)

This result follows because all three instruments operate through two margins. First, instruments can affect P̃ (α, B), the minimum acceptable probability of receiving benefits
consistent with applying. Second, instruments can affect the maximum realization of the
individual error term that results in obtaining benefits, α(ā−a). Complexity works through
both margins, whereas benefits work only through the first one and the eligibility criterion
works only through the second one.
We can now show that the government pursues social policies associated with incomplete
take up:
Proposition 5 (Type Ia errors are optimal) Under assumption 2, when the first-best
allocation is not feasible, for any value of B, the optimal choice of ā and α implies P̃ (α, B) >
P (0).
H
= 0 and ∂N
∂B = 0 (Lemma 2
shows that this holds at P̃ (α, B) = P (0), while it obviously holds at P̃ (α, B) < P (0)). As a
ā−a ∂Na
a
consequence, identity (14) becomes ∂N
∂α = α ∂ā , which implies

Proof. Conversely, suppose that P̃ (α, B) ≤ P (0). Then, we have

∂NL
∂B

∂NL /∂α
ā − aL ∂NL / ∂ā
∂NL /∂ā
=
>
∂NH /∂α
ā − aH ∂NH /∂ā
∂NH /∂ā
That, however, implies that the original policy could not have been optimal because it violates the
optimality condition (13) (and, in fact, α should be increased).

Corollary 2 and Proposition 5 together implies that, when the budget is not small,
social programs feature both type Ia and type II errors. Optimal programs of course also
feature type Ib errors because, given that α and 
ā > aH are finite, low-ability
applicants

α(ā−aL )
distributed on P̃ , 1 , and hence face
face probabilities of receiving benefits P
σ
9
non-zero probabilities of rejection. We have therefore shown that large-budget programs
are associated with all three types of classification error as illustrated in Figure 1.
An interesting issue regarding the optimal setting of instruments is the choice of the
optimal level of benefits. Given that the government cares only about the number of recipients, it may seem obvious that benefits should be set at the lowest possible level. But recall
that the best full-separation policy did not have this property: according to Proposition 2
benefits should be increased above their minimum level. In that context, this was a mechanical result driven by the inability to otherwise spend all of the budget on eligibles. However,
9

Notice that α cannot increase without bound because in that case, to prevent everybody from dropping
out of the program due to prohibitive application costs, B would also have to increase without limit, which
requires an unlimited budget, R = ∞. The eligibility criterion ā also cannot increase without bound unless
˜
ˆ
the budget is large enough to give benefits to everyone, i.e. R ≥ N̄L + N̄H B̄, in which case a universal
program would be optimal.

17

notice that benefits also play a screening role by potentially attracting high- and low-ability
applicants at different rates. Intuitively, if benefits are sufficiently good at screening, this
may warrant increasing them despite their budgetary cost. This possibility is reinforced by
the next proposition.
Proposition 6 (B screens better than α and ā) Suppose that α and ā are set optimally given B. Then,
∂NL /∂B
∂NL /∂ā
∂NL /∂α
λB
>
=
=
.
∂NH /∂B
∂NH /∂ā
∂NH /∂α
1 − λB

(15)

Proof. Equalities in the statement of the proposition repeat equation (13). To show that the
inequality is valid, recall identity (14) and note that P̃ (α, B) does not depend on the type. Therefore,
∂NL
∂B
∂NH
∂B

=

ā−aL
α
ā−aH
α

∂NL
∂ā
∂NH
∂ā

−
−

∂NL
∂α
∂NH
∂α

=

aH −aL ∂NL
α
∂ā
ā−aH ∂NH
∂NH
−
α
∂ā
∂α

/∂α
times
The denominator of the first term is equal to − ∂∂P̃P̃ /∂B

+

∂NH
∂B

ā−aH
α
ā−aH
α

∂NL
∂ā
∂NH
∂ā

−
−

∂NL
∂α
∂NH
∂α

and it is positive because ∂ P̃ /∂α >

0 while ∂ P̃ /∂B < 0. Therefore, the first term of the expression is unambiguously positive. When
∂NL /∂ā
∂NL /∂α
λB
α and ā are set optimally given B, we have ∂N
= ∂N
= 1−λB
and it is straightforward to
H /∂ā
H /∂α
λB
show that in this case the second term is equal to 1−λB . Therefore, we have
∂NL
∂B
∂NH
∂B

=

aH −aL ∂NL
α
∂ā
∂ P̃ /∂α ∂NH
− ∂ P̃ /∂B ∂B

+

λB
λB
>
.
1 − λB
1 − λB

(16)

This is an important result: on the margin, benefits are better at screening low- from
high-ability individuals than any of the other instruments. This is a global result that
holds for any value of B as long as the other instruments (complexity and eligibility) are
set optimally. Therefore, the only reason not to increase benefits beyond B̄ is the revenue
cost. In other words, the question is whether the advantage from using benefits to screen
is big enough to compensate for the extra revenue cost. From the screening point of view,
increasing benefits is preferred to the other two instruments.
When ā and α are set optimally, benefits should be increased from some level B if


∂NL
∂NL ∂NH
NL + NH
λB
λB NL + NH
∂NL
∂B
− λB
+
+
> 0 ⇒ ∂N
>
+
H
H
∂B
∂B
∂B
B
1 − λB 1 − λB B ∂N
∂B
∂B
λB
Recall equation (13): 1−λB
reflects the optimal extent of screening performed by the other
instruments. Benefits should be used beyond their minimal level only if they are sufficiently
better than the other instruments at screening by a factor identified in the last term — this
is a correction for the budgetary cost of increasing benefits. It is difficult for benefits to
λB
is high),
satisfy this condition if the other instruments are already good at screening ( 1−λB
when there are a lot of individuals whose benefits will have to be increased (NL + NH is
∂NL /∂B
H
high) and when B ∂N
∂B is small. Substituting for ∂NH /∂B using the equality in (16) yields

aH − aL ∂NL
λB NL + NH
>
.
1 − λB
B
−α ∂ P̃ /∂α ∂ā
∂ P̃ /∂B

18

Recalling that

∂NL /∂ā
∂NH /∂ā

=

λB
1−λB ,

we can rewrite this to

aH − aL ∂NH
∂ P̃ /∂α NL + NH
∂ P̃ /∂α R
,
>−
=−
α
∂ā
B
∂ P̃ /∂B
∂ P̃ /∂B B 2

(17)

where the last equality uses the budget identity R = B(NL + NH ). It is optimal to increase
B beyond B̄ if this condition holds when evaluated at B̄ and the optimal α and ā (at
B̄). How should we interpret this condition? B should be used if changes in eligibility ā
bring too many high-ability individuals, where the inequality gives the specific meaning to
L ∂NH
“too many”. Alternatively, note from identity (14) that ā−a
α
∂ā is the effect of α on the
number of high-ability individuals receiving benefits while holding the number of applicants
constant (i.e. holding P̃ constant). Thus, the same condition can be expressed in terms of
extra complexity bringing in “too many” high-ability individuals. The following proposition
characterizes the optimal choice of benefits.
Proposition 7 (optimal benefits) Suppose that the first-best allocation is not feasible,
R ≥ R∗ . Denote by NL∗ the number of low-ability
n recipients under the obest full separation
∗
policy identified by Proposition 2. Let ā = inf max NL (α, ā, B̄) ≥ NL∗ , aH < ā∗ < ∞.10
ā
α
Then,
1. For R sufficiently close to R∗ , setting B = B̄ is optimal.
2. For R sufficiently large, setting B = B̄ is optimal.
3. A sufficient condition for B > B̄ is given by



1
R
ā∗ − aH −1 ∗
−1
∗
G (NL ) ≥ GH
− NL
.
ā∗ − aL L
P (0) B̄

(18)

Proof. In the appendix.
The intuition for the first result is straightforward. When the budget is small (but large
enough to make first best infeasible), the eligibility threshold ā will be very close to aH . As
we cross aH with ā, initially we are still mostly providing benefits to low-ability individuals
(on the margin, the share of high-ability recipients is close to zero when ā is close to aH ).
Given the presence of such a good instrument that does not have a direct revenue cost,
it must dominate any instrument that does have a revenue cost (such as B). That is, as
the number of high-ability applicants is initially small, any screening benefits of using high
benefits have to be dominated by the costly nature of this instrument. The second part is
also intuitive: as the budget size increases, the number of individuals served increases as
well and therefore increasing benefits becomes more costly.
Part 3 is the most interesting. It gives the sufficient condition for B > B̄. Moreover,
note that this condition can be satisfied by varying GH without affecting any of the other
variables in eq. (18). In particular, the definitions of NL∗ and ā∗ are based solely on the
We know that ā∗ > aH because, from the proof of Proposition 3, if the first-best allocation is not
feasible, any non-full separation policy with ā ≤ aH is dominated by a full separation policy and therefore
also dominated by the best full separation policy NL∗ .
10

19

low-ability distribution and parameters — they do not depend on GH . Furthermore, the
∗
argument of G−1
H on the right-hand side depends on constants R, B̄ and again on NL so that
it is independent of GH . Finally, note that both the left-hand side and the argument of G−1
H
are positive due to the fact that ā∗ > aH and NL∗ delivers fewer low-ability recipients than
R/B̄ which is what the first-best policy would deliver. Thus, given parameters and lowability distribution, we will be able to find some distributions GH that satisfy the condition
identified in the above proposition. All that is required is selecting the distribution so
1
(R/B̄ − NL∗ ) high-ability individuals with σ smaller than
that there are more than P (0)
ā∗ −aH −1
∗
ā∗ −aL GL (NL ). This is a requirement imposed on GH at a particular strictly positive
point.11 The corollary below is a consequence of this reasoning and it highlights that the
case B > B̄ cannot be dismissed as being irrelevant because it will apply when the number
of high-ability applicants is sufficiently large.
Corollary 3 Fix the parameters of the problem other than the high-ability distribution.
Select some distribution of high-ability individuals G0H (σ) (with the corresponding number
0 ) and consider a class of distributions Gη (σ) = ηG0 (σ) (with
of high-ability individuals NH
H
H
0
the corresponding number of high-ability individuals ηNH ). For high enough η, setting
B > B̄ is optimal.
Proof. For sufficiently high η,
GηH







 ∗
ā∗ − aH −1
1
R
ā − aH −1
∗
∗
0
∗
−
N
.
G
(N
)
=
ηG
G
(N
)
≥
L
H
L
ā∗ − aL L
ā∗ − aL L
P (0) B̄

and this condition is equivalent to the inequality in Part 3 of Proposition 7.

4

Numerical Simulations

To establish a benchmark simulation, we set ability levels at aL = 1, aH = 2, the number
of low- and high-ability individuals at N̄L = 1000, N̄H = 1000, and the target minimum
benefit at B̄ = 1. The distribution of the noise term ε/σ is assumed to be normal (so that
P (0) = 21 ), and the precision of measured skill σ is assumed to be log-normal with a mean
and variance equal to 1. Notice that the log-normal distribution satisfies Assumptions 2
and 3. The coefficient of absolute risk aversion β is set equal to 2. Finally, to solve
the model numerically, we specify the functional form for the complexity cost function as
f (α) = c0 + c1 · αc2 . In the case of ‘no complexity’, we have α = 0 and hence f (0) = c0 , so
that c0 captures non-complexity related costs (such as stigma or other fixed costs) associated
with participating in a social program. In the benchmark simulation, we set c0 = 0, c1 = 0.5,
and c2 = 1. This is the calibration underlying illustration in Figure 1 and discussed in
Section 3.2.
Figures 2-5 shows comparative statics with respect to budget size, ability distribution,
complexity costs, and ‘stigma’ (c0 ). Each figure consists of six panels: eligibility criterion ā
in Panel A, screening intensity α and benefit B in Panel B, complexity costs as a share of
benefits f (α) /B in Panel C, the elasticity of low-ability recipients NL with respect to each of
11

In particular, there is no restriction imposed on the properties of GH (.) around zero so that we can pick
a distribution satisfying Assumption 3.

20

the three instruments in Panel D, and the share of individuals (L- and H-types, respectively)
applying for benefits (‘take-up rate’) and the share of individuals being awarded benefits
in Panels E and F. Figure 2 shows numerical results as a function of the program budget
R based on the benchmark calibration just described. The horizontal axis in the figure
starts at a budget size equal to R∗ — the largest budget where first best is feasible (R∗ '

810 in the benchmark) — and then increases the budget toward R̄ ≡ B̄ N̄L + N̄H — the
budget where a universal benefit giving B̄ to everyone becomes feasible (R̄ = 2000 in the
benchmark). The bold black curve in Figure 2 shows the benchmark results, whereas the
other curves show results for alternative ability distributions by changing the number of
high-ability individuals relative to low-ability individuals, N̄H /N̄L (keeping N̄L = 1000). In
particular, the think black curve is associated with N̄H /N̄L = 1.5, and the gray curve is
associated with N̄H /N̄L = 2. The vertical dashed line indicates R∗ + 500, which is the level
of budget that we are going to rely on in the subsequent experiments.
In the benchmark where N̄H /N̄L = 1, the figure shows that benefits are always kept at
their target minimum. The eligibility criterion ā starts at 2 where high-ability individuals
are just eligible. It then increases monotonically with the program budget R and tends
to infinity as R converges to R̄. In other words, a larger program budget (at a given
B̄) is always associated with more universalism in benefit provision. Interestingly, any
program that is not universal is associated with a substantial degree of complexity. In
the simulations reported in Figure 2, complexity costs as a proportion of the (potential)
benefit vary between 35% and 65%. Moreover, complexity α is increasing in the size of the
budget. In other words, as a program becomes better funded, it is optimal to spend the
extra funds making the program more lenient (increasing ā) rather than slacking on the
rigor of the screening process by reducing α. Although a high degree of complexity may in
itself discourage some low-ability individuals from applying, the combination of a high α
and a high ā allows the program to keep a high number of L-applicants (few type Ia errors)
and identify them with high precision (few type Ib errors). Another way to gauge the degree
of complexity is to consider the elasticity in equilibrium of the number of L-recipients with
respect to α shown in Panel D. What we see is that, at any budget size, complexity is
taken to a point where it has a negative effect on the number of L-recipients at the margin.
As discussed above, this is entirely consistent with an optimum given that the marginal
effect on H-recipients is also negative. As expected, as the size of the budget increases, all
instruments become less effective in increasing participation (elasticities get closer to zero).
Panels E and F shows the extent of classification errors as a function of budget size.
The type II error rate (the share of H-types receiving benefits) is initially zero, increases
as a function of R, and converges to 1 as R → R̄. The basic intuition is that, for a poorly
funded program, classification errors of type II is a luxury that it cannot afford, whereas a
well-funded program can afford making type II errors in order to reduce the amount of type
I errors. The type I error rate (i.e., type Ia + type Ib) equals 1 minus the share of L-types
receiving benefits. This rate is decreasing in R and tends to zero as R → R̄. The type
Ib error rate equals the take-up rate minus the share of L-individuals receiving benefits,
and is also decreasing with R. However, the type Ia error rate (1 - take-up rate) is not
21

monotonically decreasing in R, which may seem surprising. Although the type Ia error rate
does decrease in R at large enough Rs, at lower budget levels the government find it optimal
to trade-off type Ib errors for type Ia errors. This effect occurs because a larger budget
and the associated relaxation of the eligibility criterion invite more H-applicants into the
program, which makes testing more important. The implied increase in transaction costs
deter some L-applicants from applying but substantially lower the amount of type Ib errors.
Figure 2 also explores our theoretical finding that B > B̄ may be optimal. According to
Proposition 7, this may occur when the budget R is neither too close to R∗ , nor too close to
R̄. We showed that the requirement for B > B̄ in this intermediate budget range is that the
number of high-ability applicants is sufficiently large. The numerical simulations confirm
this result. As we increase N̄H /N̄L so as to get more H-applicants, it becomes optimal to
increase benefits at intermediate budget sizes. The range over which B > B̄ is optimal and
the optimal size of B in this interval are both monotonically increasing in N̄H /N̄L .
The next three figures focus on a fixed budget size, R = R∗ + 500, and then vary
the three parameters of the complexity cost function (c0 , c1 , and c2 ). Figure 3 considers
the implications of increasing the utility cost of complexity by increasing c1 from 0 to 2.
Notice that a higher c1 implies both a higher level of the complexity cost f (α) and a higher
marginal complexity cost f 0 (α), both of which influence the effect of α on the number of
a
recipients ∂N
∂α (cf. eq. 14). It is intuitive that an increase in c1 makes α less effective as
an instrument, which is confirmed by the figure showing α as a strongly declining function
of c1 . In fact, the reduction of α in response to a higher c1 is strong enough that the
total complexity costs as a share of benefits, f (α) /B, is reduced. At the same time, the
government makes the program more lenient by increasing ā. Hence, as c1 increases, the
optimal social program moves from a highly complex, highly targeted program to a less
complex and less discriminating program, with increased likelihood of all types of errors.
Figure 4 shows the effects of increasing c0 (pure stigma or other fixed costs of applying).
A higher c0 has a non-monotonic effect on the degree of complexity. At low levels of c0 ,
increasing stigma leads to increased complexity. The intuition for this result is as follows.
Higher stigma results in fewer applicants and those who apply have a high likelihood of
being awarded benefits. It then becomes harder to discriminate between low- and highability applicants, which makes it necessary to increase the rigor of testing. As the level of
stigma becomes large, convincing anyone to apply becomes very hard and this requires a
compensating reduction in complexity α (to restrict the reduction in take up) along with a
lenient eligibility criterion (to ensure a high probability of receiving benefits for those who
do apply). While stigma has a strong negative impact on equilibrium take up, it has an
indirect desirable effect on the amount of type Ib errors. The reduction in type Ib errors
may seem beneficial by itself, but it is the consequence of the difficulty of screening in the
presence of stigma: at very high levels of stigma, virtually all applicants are approved.
Moreover, higher stigma increases the number of high-ability applicants (via the relaxation
of the eligibility criterion) and thereby creates more type II errors. Overall, stigma is bad
for targeting efficiency, because it reduces the number of deserving recipients and increases
the number of undeserving recipients.
22

Figure 5 shows the effect of introducing convexity in f (α) by raising c2 above 1. Notice
that, besides introducing curvature in f (α), the parameter c2 also influences f (α) and
f 0 (α) and that the effects are ambiguous depending on whether α is greater than or less
than 1. It is therefore not a priori clear how c2 affects program design. The results in the
figure shows that the effect on equilibrium complexity α is ambiguous, whereas the effect on
the eligibility criterion ā is negative (other numerical configurations confirm this qualitative
effect).

5

Interpretations, Applications, and Extensions

This paper stresses the importance of transaction costs and imperfect information for incomplete take up in public programs. The standard economic model of welfare program
participation, starting with Moffitt (1983), focuses instead on welfare stigma as the reason
for incomplete take up. Moffitt’s model distinguishes between a flat component of stigma —
a fixed cost associated with program participation — and a variable component depending
on the size of the benefit. Under flat stigma, an increase in the size of the welfare benefit
imply a higher take-up rate, whereas under variable stigma there is no such effect of higher
benefits on take-up. Moffitt showed empirically that higher benefits are indeed associated
with higher take-up, consistent with the presence of flat stigma. However, his results are
also consistent with the presence of other fixed transaction costs from program participation such as those arising from the complexity and bureaucracy of the application process.
Indeed, a large number of empirical studies have documented that complexity and hassle
constitute important barriers to program enrollment. Moreover, the positive effect of benefits on take up is also consistent with the presence of imperfect information about eligibility.
When benefits are higher, it is more attractive for the imperfectly informed individuals to
enter the lottery for welfare benefits, thereby giving rise to a higher take-up rate.
While complexity and stigma are in many ways consistent and complementary explanations for low take up, they are also different in a very fundamental way: one is a direct policy
instrument and the other is not. Although there may be ways for policy to influence stigma,
the effects are indirect and involve a great deal of uncertainty.12 If stigma is the ultimate
reason for low take up, perhaps all we can do to increase take up is to make the programs
more generous by increasing benefits or relaxing eligibility criteria. The problem is that
this would make the programs more attractive to the undeserving and therefore increase
the amount of type II errors. On the other hand, if the complexity of welfare programs
is an important determinant of take up, it follows that complexity is just as important an
instrument as the size of the benefit and the stringency of the eligibility criterion. It also
12

For example, stigma may be affected by the terminology of the program (say, whether it is called welfare
or a tax credit), the way the program is advertised, whether or not administrative procedures are demeaning
to the applicant, the possibilities of applying by mail or through the Internet as opposed to going to a
program office, whether the transfer is paid in cash or in kind (the latter being more conspicuous), and so
on. While these aspects of policy making may affect the extent of stigma associated with a given program, we
should bear in mind that stigma reflects individual preferences for receiving a social benefit and is therefore
not a policy instrument per se. Our understanding of the effect of different policies on the preferences for
social benefits is still lacking.

23

follows that we should view high complexity and incomplete take-up as equilibrium outcomes of policy making under imperfect information, instead of simply a flaw of practical
program design that calls for remedial policy action. Hence, our paper presents a model
to explain the existence of complexity and incomplete take-up as equilibrium outcomes. It
has long been recognized in the theoretical literature that the appropriate design of welfare
programs reduces their cost by limiting take-up by non-deserving recipients. Our model fills
the gap in this literature by recognizing the trade-off due to the fact that the same policies
adversely affect take up by those who are the intended recipients.
More generally, our paper represents a first attempt to incorporate administrative complexity as a choice variable in policy analysis. Although several authors have suggested
that complexity is an important aspect of policy design, for example in the context of tax
policy (Slemrod, 1990; Slemrod and Yitzhaki, 2002), little has been done in terms of actual
modeling. We have emphasized the application to the design of transfer programs and the
take up of social benefits, but our model can also be applied to the analysis of tax policy and
tax evasion. This includes cash benefits which are provided through the tax system such
as the Earned Income Tax Credit (EITC) and the Child Tax Credit, and it may include
tax deductions and exemptions more generally. As elaborated by Holtzblatt and McCubbin
(2003), tax rules affecting low-income filers involve a great deal of complexity. A prima
facie evidence of the difficulties in dealing with the tax code is the high reliance on tax
preparers even among low-income tax payers despite the significant fees charged for such
services (Kopczuk and Pop-Eleches, 2007). It is conceivable that this complexity of the tax
code reflects the kind of trade-off between type I and type II errors studied in this paper.
Our model and results are consistent with several features of observed social policy and
take-up behavior within the United States. First, the model may be able to shed light on
the observation of large differences in complexity and participation rates across different
programs. We find that, in equilibrium, program characteristics and take up can vary
substantially depending on a number of key variables. This includes the size of the program
budget (R), the size of the minimum benefit (B̄), the distribution of true skills (aL , aH ,
N̄L , and N̄H ), the distribution of estimated skills (distribution of σ, Ga (.)), and the size
and structure of complexity costs (properties of f (α)). In other words, different types of
social programs will be designed differently and be associated with different take-up rates
because they serve different populations, because they involve different kinds of eligibility
tests, and because of differences in the size and generosity of programs. Other things being
equal, we have seen that programs with a small budget relative to the target benefit, i.e.
a small R/B̄, are predicted to have a stringent eligibility rule, high complexity, a high
occurrence of type I errors, and no or very few type II errors. This may perhaps reflect
a program such as the Special Supplemental Nutrition Program for Women, Infants and
Children (WIC) in the U.S. For larger programs, the model predicts that eligibility rules
are more lenient while complexity is still high, and that both types of classification error
occur. This would seem to reflect a program like the Disability Insurance (DI) program,
which is a large program involving complex and rigorous testing, and where both type I and
type II errors occur (Benı́tez-Silva et al., 2004). Finally, our model predicts that very large
24

programs will feature universal benefits and no complexity. This fits with the Medicare
program — by far the largest transfer program in the United States — which is a universal
program (conditional on being old) with a very low degree of complexity (default coverage)
and close to full take up.
Another potential difference across programs is the degree of stigma. Our model includes
the possibility of pure stigma as a constant in the complexity cost function, and we explored
numerically the implications of stigma for program design and outcomes. We find that highstigma programs have a low incidence of type Ib errors and low take-up rates. This pattern
arguably fits the pattern observed in practice: welfare programs tend to be associated with
relatively high stigma, imperfect take up and low false rejection rates, whereas programs
such as DI have low stigma, high take up and high false rejection rates.
Second, the model is consistent with the occurrence of different take-up behavior across
equally eligible individuals resulting from heterogeneity in the observability of skills (the
variance of the error term). In the model equilibrium, those with low variances face high
acceptance rates in the application process making it optimal for them to apply for benefits,
whereas equally eligible individuals with high variances face high risks of being rejected
by program administrators and hence find it not optimal to apply. The latter group of
individuals are those who, despite that they are truly deserving of the benefit, test with a
high degree of uncertainty and may easily fail to live up to the requirements of the program.
Language barriers, unfamiliarity with the administrative procedures, inability to understand
the formal requirements of the test, etc., would all contribute to creating more uncertainty in
the test. This is consistent with the large amount of evidence showing considerable variation
in program participation across eligible individuals depending on race, immigration status,
fluency in English, age, education, gender, and family status (Borjas and Hilton, 1996;
Currie, 2000, 2003; Heckman and Smith, 2004; Duggan and Kearney, 2005). For example,
our model can account for why newly arrived immigrants are characterized by a lower
take-up of social benefits, conditional on being eligible, than immigrants who are more
assimilated into society (Borjas and Hilton (1996)). Our results may also explain why
some ethnic groups (such as Hispanics and Asians) have lower take-up than others (such as
African Americans) as shown by Currie (2003).
Third, we find that complexity and administrative costs can be very high in equilibrium,
especially for governments eager to avoid giving money to the ‘undeserving’. Under certain
simplifying assumptions — low risk aversion and the noise of observed skill being distributed
with zero median — we find that transaction costs constitute more than 50 percent of the
amount of benefits granted. In the more realistic case of risk averse agents, transaction costs
as a share of total benefits are smaller than 50 percent but are nevertheless substantial.
Our model abstracts from several aspects that we would like to discuss briefly. First,
our model ignores the costs of administering a social program. In practice, there will be
administrative costs from the processing of applications due to the paper work involved,
the time spent by administrators and specialists for interviewing and testing, etc. Realistically, these administrative costs depend positively on the amount of complexity and on
the total number of applications that have to be processed. A positive relationship between
25

complexity and administrative costs obviously makes complexity less effective as a policy
instrument. On the other hand, administrative costs that are increasing in the number of
applications favor policies capable of increasing the number of deserving recipients with a
relatively small (or no) accompanying increase in the number of applicants. This tends to
improve the effectiveness of complexity as a policy instrument, because it identifies the truly
eligible applicants with more precision while making it more costly for would-be applicants
to claim the benefit. Given our result that benefits are particularly good at screening, it
may also increase the likelihood that higher benefits are paid in equilibrium.
Second, in our model, policy makers do not concern themselves with the negative effect of
complexity and hassle on individuals’ utility. As in the well-known Besley and Coate (1992,
1995) model, we assume that politicians care only about designing an efficient system of
income maintenance. Our paper should therefore be seen as being positive rather than
normative: it presents a model to explain and understand the behavior of imperfectly
informed policy makers engaging in poverty alleviation, not a model to identify the most
desirable policy from the point of view of a welfarist social planner. If politicians cared
about utility instead of income, it may seem obvious that complexity would be a less effective
instrument. However, even in a model of social welfare maximization, given that complexity
is modeled as a byproduct of efforts to screen between deserving and undeserving applicants,
it continues to be associated with some desirable effects. For example, a situation with no
complexity α = 0 — corresponding to program administrators flipping a coin to determine
eligibility — is an unlikely candidate for the program chosen by a social planner interested
in redistributing money from rich to poor. Second, complexity simultaneously serves as an
ordeal for program applicants. As shown by Nichols and Zeckhauser (1982) and others,
ordeals may be desirable in their own right provided that (i ) the utility gain from transfers
is lower for the undeserving and/or (ii ) the utility cost of the ordeal is higher for the
non-deserving.
Third, an important technical assumption in the model is constant absolute risk aversion.
This assumption guarantees that the minimum acceptable odds in the benefit award process
is the same for low- and high-ability individuals, and this is the only purpose for making it.
An assumption of increasing absolute risk aversion would imply that high-ability individuals
require better odds in order to apply. This would make it feasible to always implement the
first-best outcome by pushing complexity to a level where the minimum odds acceptable to
high-ability individuals are above one, while the minimum odds acceptable to low-ability
individuals remain below one. A more realistic assumption of decreasing absolute risk
aversion would not allow for such a counter-intuitive outcome, but it would make analysis
substantially more complicated.
We believe that the central implication of constant absolute risk aversion in the context
of the model has an intuitive and realistic economic content: it implies that, given odds
at which some low-ability individuals apply, we can always find a high-ability individual
who would also apply given the same odds. We believe that this is a realistic description
of the real world, although it may reflect dimensions of heterogeneity not incorporated in
our model. In our view, a generalization of the model to non-CARA preferences should
26

preserve this central property by adding additional dimensions of heterogeneity.
Finally, a possibility mentioned by Bertrand et al. (2004) and Currie (2004) is that nonparticipation in social programs may be explained, in part, by individuals being boundedly
rational. While we have not yet discussed psychological reasons for low take-up, our framework may be reinterpreted to capture a form of bounded rationality. In this interpretation,
the parameter σ (precision of observed skill) reflects the degree of irrationality. An individual with a high σ face a lot of uncertainty when being tested, even if he is truly eligible,
because he tends to make mistakes, say stupid things at the interview, appear to be lying
when he is really not, and so on. On the other hand, low-σ individuals do everything right
and respond well at the interview so as to give a very precise test. In the model equilibrium,
the individuals who are not taking up benefits, despite being eligible, are the least rational
ones (those with a high σ). This interpretation of our model has the flavor of the Luce
(1959) approach to bounded rationality in which individuals make random decision errors
and outcomes are the result of a probabilistic process. Clearly, there are other forms of
bounded rationality such as present bias and framing effects that may also be relevant to
the take-up of social benefits. So far, research on the effects and design of public policy
under bounded rationality is relatively unexplored, and is an interesting topic for future
research.

27

A

Proofs

Proof of Lemma 2. The total number of individuals of ability a receiving benefits is given by
σ̄ a (α,ā,B)
Z

Na (ā, α, B) =



P

α(ā − a)
σ


d Ga (σ)

(A.1)

0
∂Na
a
and we want to evaluate ∂N
∂α and ∂B when ā > a and P̃ (α, B) = P (0). Begin with the first of
these. Differentiating explicitly yields
σ̄ a (α,ā,B)
Z

∂Na
=
∂α

p(·)

ā − a
∂ σ̄ a
dGa (σ) +
P̃ (α, B)ga (σ̄ a ) .
σ
∂α

(A.2)

0

The first term is unambiguously positive. We will show that the second term is zero when ā > a
σ̄ a
yields
and P̃ (α, B) = P (0). Evaluating ∂∂α
 
−1
α(ā−a)
−1
(ā
−
a)P
−
α(ā
−
a)
p
σ̄ a
∂ σ̄ a
=


2
∂α
P −1 P̃ (α, B)

∂ P̃
∂α

=

σ̄ a
σ̄ 2a
−
α
α(ā − a)

 
−1
α(ā − a)
∂ P̃
.
p
σ̄ a
∂α

(A.3)
Note that limP̃ (α,B)→P (0) σ̄ a = ∞: as the threshold probability of receiving benefits approaches
P (0), the number of individuals not applying goes to zero. All other terms in expression (A.3): α,
P̃
ā − a, ∂∂α
and p(·) are positive and finite (the argument of p(·) goes to 0 as σ̄ a goes to infinity and
density at 0 is positive). Consequently, as we approach P (0) with P̃ , expression (A.3) tends to −∞
at the rate of σ̄ 2 . Consequently, the behavior of the second term of (A.2) depends on the behavior
of σ̄ 2a g(σ̄ a ) and, by assumption 2, lim σ̄ 2a g(σ̄ a ) = 0.
Now consider

∂Na
∂B .

It is

σ̄ a →∞
σ̄ a
P̃ (α, B)ga (σ̄ a )
equal to ∂∂B

and we have

∂ σ̄ a
∂B

−1

dP (P̃ )
= − (Pα(ā−a)
=
−1 (P̃ ))2
dB

−1

dP (P̃ )
1
−σ̄ 2a α(ā−a)
. It is straightforward to show as before that all terms but σ̄ a and g(σ̄ a ) are
dB
2
a
bounded away from zero and infinity. Therefore ∂N
∂B behaves as g(σ̄ a )σ̄ a and thus it is zero in the
limit by assumption 2.
Finally, the second term of (A.2) is uniformly zero when P̃ (α, B) < P (0) and the first term is
continuous. Therefore, the whole expression in (A.2) is continuous, which proves the third part of
a
the lemma. Similarly, ∂N
∂B is uniformly zero when P̃ (α, B) < P (0), so that it is also continuous at
P̃ (α, B) = P (0).

Proof of Lemma 3. Denote by (α∗ , aH , B ∗ ) the best policy under full-separation characterized
in Proposition 2, and consider increasing ā above aH . We will show first that the right-derivative
∗
∗
H ,B )
of NH with respect to ā is equal to zero at (α∗ , aH , B ∗ ): ∂NH (α∂ā,a
= 0. Differentiating (A.1)
+
with respect to ā yields
∂Na
=
∂ā

σ̄ a (α,ā,B)
Z



p

α(ā − a)
σ



α
∂ σ̄ a
ga (σ)dσ +
P̃ (α, B)ga (σ̄ a ),
σ
∂ā

(A.4)

0

such that


∗
∗
σ̄ H (α


Z ,ā,B )


∗
∂NH (α , aH , B )
α
∂ σ̄ H
= lim
p (·)
gH (σ)dσ +
P̃ (α∗ , B ∗ )gH (σ̄ H (α∗ , ā, B ∗ )) .
ā→aH 

∂ā+
σ
∂ā+

ā>aH 
∗

∗

0

Note that lim σ̄ H = 0, and therefore the second term is zero: we have g(0) = 0 while the other
ā→aH

components P̃ and

∂ σ̄ H
∂ā+

=

α
P −1 (·)

tend to finite limits (the limit of P −1 (·) is positive because we
∗

are considering a point with P̃ > P (0)). In the first term, the integrand p (·) ασ gH (σ) is bounded

28

from above in the neighborhood of σ = 0 by assumption 3 and because p(·) is bounded from above.
Therefore, the first term tends to zero.
σ̄ L
On the other hand, for the low-ability individuals we have that aL < ā, σ̄ L > 0, and ∂∂ā
> 0,
∂NL
so that the derivative ∂ā given by A.4 is strictly positive.
Hence, starting at the best full-separation policy (α∗ , aH , B ∗ ), we can increase the threshold
ā slightly above aH so as to give benefits to more low-ability people, while bringing in only an
infinitesimal number of high-ability people. We would then be spending too much money, but we
can reduce B below B ∗ until the revenue constraint is satisfied. At this new equilibrium, since B is
lower, the total number of recipients, NL +NH , is higher. Moreover, since the number of high-ability
recipients is infinitesimal, the number of low-ability recipients is higher than before.

Proof of proposition 4. Consider R = R∗ + ε. Denote the optimal policy at R∗ by (α∗ , aH , B̄)
and note that it involves P̃ > P (0) (if P̃ = P (0), increasing the number of low-ability recipients
could be increased by increasing α by Lemma 2 and therefore implement the first-best for an even
greater budget). To simplify notation, denote the optimal policy given ε by (α(ε), ā(ε), B(ε)).
We will show first that lim σ̄ H = 0. To see that note that the proof of Proposition 2 implies that
ε→0

∗

∗

we can achieve R B̄+ε > NL > RB̄ by sticking to the full separation policies. Note that we must have
∗
NH < B̄ε because otherwise NL ≥ RB̄ and the optimal non-separation policy would be preferred.




R σ̄
α(ā−aH )
H)
By definition NH = 0 H P α(ā−a
dG
(σ
).
We
know
that
P
> P (0) for everyone
H
H
σH
σH
because ā > aH . Therefore, NH > GH (σ̄ H )P (0) and consequently GH (σ̄ H ) <
implying that lim σ̄ H = 0.

NH
P (0)

<

ε
B̄P (0)

,

ε→0

Now observe that lim σ̄ H = 0 implies lim ā = aH . Recall that σ̄ H =
α(ā−aL )
so that
P −1 (P̃ (α,B))
R∗
(the number of
B̄

ε→0
H
σ̄ H = ā−a
ā−aL σ̄ L .

ε→0

Therefore, ā − aH =

σ̄ H
σ̄ L −σ̄ H (aH

α(ā−aH )
P −1 (P̃ (α,B))

and σ̄ L =

− aL ). Note also that GL (σ̄ L ) >

low-ability applicants which is still greater than the number of recipients must
H

be at least as high as in the full-separation optimum). Consequently, as σ̄ H → 0, σ̄Lσ̄−σ̄H → 0 and
therefore ā − aH → 0.
Consider what happens when ε → 0. The resulting value of the objective is NL (ε). NL is
a continuous function of policy parameters in the relevant region.13 Suppose that lim (α, ā, B) 6=
ε→0

(α∗ , ā∗ , B ∗ ). In that case, lim NL (ε) = NL (lim α(ε), lim ā(ε), lim B(ε)) < NL (α∗ , ā∗ , B ∗ ) — the last
ε→0

ε→0

ε→0

ε→0

inequality follows from the fact that the limiting point (lim α(ε), lim ā(ε), lim B(ε)) implements full
ε→0

ε→0

ε→0

separation because P̃ (α(ε), B(ε)) > P (0) (by Proposition 5), a(ε) → aH as demonstrated earlier and
(α∗ , ā∗ , B ∗ ) was the optimal point under full separation. This is however a contradiction because it
implies that for sufficiently small ε we would have been better off using the full separation policy
(and not using all of the money). Consequently, lim (α, ā, B) = (α∗ , aH , B̄).
ε→0

Proof of identity 14.

Recall the definition of Na , equation (A.1) and the definition of σ̄ a in
equation (6). α affects Na through two channels. First, α(ā − a) is the maximum realization of the
individual error term that results in receiving benefits — it enters both the integrand in Na and the
limit of integration. Second, the minimum acceptable probability threshold P̃ (α, B) influences who
applies. The effect of α on Na is the sum of these two effects. Instrument ā works only on the first
margin, while instrument B works only on the second margin. Recognizing that allows for writing
the effect of α as a combination of the effects with respect to the other two probabilities.

Proof of Proposition 7. Part 1.
Let α∗ be the optimal value of α at the full separation policy with maximum budget R∗ . Denote
by λ̃ the Lagrange multiplier from the problem of maximizing the objective function with respect
to α and ā while setting B = B̄. It can be easily shown that we will want to increase B over B̄ if
and only if
λ̃B ∂NH
λ̃B NL + NH
∂NL
>
+
(A.5)
∂B
∂B
B
1 − λ̃B
1 − λ̃B
The left-hand side is non-negative and we don’t have to worry about it increasing without bounds
13

Na is continuous when ā > a and has a discontinuity at ā = a when P̃ = P (0). In this case, the
discontinuity is at aL , but we are considering ā ≥ aH > aL .

29

∗
L
as ε changes — it converges to a finite limit of ∂N
∂B (α , aH , B̄). All terms ∗on the right-hand side
NL +NH
are non-negative and
is finite and bounded away from zero (NL > RB̄ and B = B̄). We will
B

show that

λ̃B
→ ∞ as ε → 0 and thus this inequality is violated for small enough ε. To see that,
1−λ̃B
∂NL /∂ā
λ̃B
= ∂N
. We will show that the numerator is finite while the denominator falls
H /∂ā
1−λ̃B

recall that
to zero. To see that, write explicitly ∂Na /∂ā:
∂Na
=
∂ā

Zσ̄a


αp

α(ā − a)
σ

0



ga (σ)
α
dσ +
P̃ (α, B)ga (σ̄ a )
−1
σ
P (P̃ (α, B))

(A.6)

All terms here are non-negative. The first-term vanishes for the high-types as ε → 0, because
lim σ̄ H = 0 while the integrand is bounded away from infinity in the neighborhood of σ = 0 by

ε→0

Assumption 3. It remains positive for low-ability individuals because σ̄ L remains bounded away from
zero as ε → 0. By Proposition 4, lim P̃ (α, B) = P̃ (α∗ , B̄) > P (0), so that P −1 (P̃ (α, B)) has nonε→0

zero limit. Consequently, for the high-ability types the second term disappears because gH (0) = 0
∂NL /∂ā
λ̃B
= ∞,
= lim ∂N
while it remains positive for the low-ability types. As a result lim 1−
H /∂ā
λ̃B
ε→0

ε→0

implying that the inequality (A.5) must be violated for sufficiently small ε and therefore B = B̄ is
optimal for sufficiently small εs.
Part 2.
This is an implication of condition (17) evaluated at B̄ and the optimal α and ā.
 To see this,
hold B̄ constant and increase R. The parameter α is bounded by P (0) < P̃ α, B̄ < 1, so that
∂ P̃ /∂α
∂ P̃ /∂B

βB

e −1
0
= − eβf
(α) −1 f (α) is bounded away from zero when evaluated at the optimal α and B̄.

H
Moreover, we can show that ∂N
∂ā → 0 as we keep increasing R. To see this, start by noting
∗
that, as R increases, ā has to increase. There exists a finite budget size R̄ ≥ B̄ (NL∗ + NH
) at which
everyone receives benefits, and at that budget size we have ā = ∞ and σ̄ a = ∞. As R approaches
this value, we have ā → ∞ and σ̄ a → ∞.
Now recall eq. (A.6) and consider what happens as ā and σ̄ a increases. The second term can
ga (σ̄ a )
be written as P̃ (α, B) σ̄a(ā−a)
. We must have lim σ̄ a ga (σ̄ a ) = 0 (if the limit exists), because

σ̄ a →∞

otherwise ga (·) would not be a distribution function. Moreover, ā − a tends to ∞ so that the second
term disappears in the limit. For the first term, integration by parts yields






Zσ̄a 
Zσ̄a 
σ̄ a

α(ā − a)
1 
α(ā − a)
α(ā − a) ga (σ)
+ P
dσ =
−P
σga (σ)
[ga (σ) + σga0 (σ)] dσ
αp

σ
σ
ā − a 
σ
σ
0
0
0



Zσ̄a 


1 
α(ā − a)
=
1 − P̃ (α, B) σ̄ a ga (σ̄ a ) + P
[ga (σ) + σga0 (σ)]dσ .

ā − a 
σ
0

1
tends to zero. The first-term in the bracket disappears as σ̄ a tends to infinity.
We have that ā−a
Because P (·) is a c.d.f., it can be bounded from above by 1, so that the second term is smaller
σ̄ a
R σ̄
than 0 a ga (σ) + σga0 (σ)dσ = σga (σ)
= σ̄ a ga (σ̄ a ) and therefore also disappears as σ̄ a gets large.
0

a
Consequently, ∂N
∂ā tends to zero as ā and σ̄ a — and budget size R — become large (for both Land H-types).
By implication, as we keep increasing the budget size R, the left-hand side of (17) goes to zero,
whereas the right-hand side increases without bound. As a result, for a large enough R the inequality
has to be violated.
Part 3.
Suppose that the optimal policy satisfies B = B̄. Because a full-separation policy delivers NL∗
individuals, an optimal policy must provide benefits to more than NL∗ individuals. By definition of
ā∗ , it must therefore satisfy ā ≥ ā∗ . Furthermore, it must satisfy GL (σ̄ L ) > NL∗ (the number of
low-ability applicants which is greater than the number of recipients must be greater than NL∗ ), such
ā−aH
∗
that σ̄ L > G−1
L (N ). Recall the identity σ̄ H = ā−aL σ̄ L . This formula is increasing in ā and therefore
∗
∗
ā −aH −1
∗
∗
H
σ̄ H ≥ āā∗−a
−aL σ̄ L > ā∗ −aL GL (NL ). Note that this lower limit is strictly positive because ā > aH .

30

Now, note that we also have an upper bound for σ̄ H : We need to have at least NL∗ low-ability
R
recipients and, with the budget R, we can then have no more than B̄
− NL∗ high-ability recipients.
R
Consequently, NH < B̄ − NL∗ while NH > P (0) GH (σ̄ H ) (at least a share P (0) of the high-ability


1
R
∗
applicants receive benefits, because P̃ (α, B) > P (0)). Consequently, σ̄ H < G−1
.
H
P (0) B̄ − NL


−1
ā∗ −aH −1
R
1
∗
∗
. If the upper bound is
Putting it together we have ā∗ −aL GL (NL ) < σ̄ H < GH P (0) B̄ − N
lower than the lower bound, there is no σ̄ H that satisfies this condition and therefore our original
assumption that B = B̄ is optimal must be false.14

14

Remarks:

1. There is no inconsistency with B = B̄ for small R — as we reduce R, a∗ → aH and therefore the
lower bound goes to zero (I think the upper bound also goes to zero, but apparently our assumption
of a finite slope of density guarantees that it does not go to zero that fast).
2. If we can choose B > B̄, a∗ would fall — this is the same argument as the one we made to show
that we can always spend all of the money on a full separation policy, higher B allows for setting
higher α while holding P̃ constant. With the same P̃ but higher α, probability of receiving benefits
for everyone goes up because ā > aL and screening is better — there is therefore more applicants
and they are more successful. Consequently, for high enough B we can guarantee the existence of σ H
that would satisfy the inequality.

31

References
Aizer, Anna. (2007). ‘Public health insurance, program take-up and child health’, Review
of Economics and Statistics .
Akerlof, George A. (1978). ‘The economics of ”tagging” as applied to optimal income
tax, welfare programs, and manpower planning’, American Economic Review 68(1), 8–19.
Benı́tez-Silva, Hugo, Buchinsky, Moshe and Rust, John. (2004), How large are the
classification errors in the Social Security award process?, Working Paper 10219, National
Bureau of Economic Research.
Bertrand, Marianne, Mullainathan, Sendhil and Shafir, Eldar. (2004). ‘A
behavioral-economics view of poverty’, American Economic Review Papers and Proceedings 94(2), 419–423.
Besley, Timothy and Coate, Stephen. (1991). ‘Public provision of private goods and
the redistribution of income’, American Economic Review 81(4), 979–84.
Besley, Timothy and Coate, Stephen. (1992). ‘Workfare versus welfare incentive arguments for work requirements in poverty-alleviation programs’, American Economic
Review 82(1), 249–61.
Besley, Timothy and Coate, Stephen. (1995). ‘The design of income maintenance
programmes’, Review of Economic Studies 62(2), 187–221.
Bitler, Marianne, Currie, Janet and Scholz, John Karl. (2003). ‘WIC participation
and eligibility’, Journal of Human Resources 38, 1139–79.
Blackorby, Charles and Donaldson, David. (1988). ‘Cash versus kind, self-selection
and efficient transfers’, American Economic Review 78(4), 691–700.
Blank, Rebecca M. (2002). ‘Evaluating welfare reform in the United States’, Journal of
Economic Literature 40(4), 1105–1166.
Borjas, George J. and Hilton, Lynette. (1996). ‘Immigration and the welfare state:
Immigrant participation in means-tested entitlement programs’, Quarterly Journal of
Economics 111(2), 576–604.
Bruce, Neil and Waldman, Michael. (1991). ‘Transfers in kind: Why they can be
efficient and nonpaternalistic’, American Economic Review 81(5), 1345–1351.
Currie, Janet. (2000), Do children of immigrants make differential use of public health
insurance?, in George J. Borjas., ed., ‘Issues in the Economics of Immigration’, The
University of Chicago Press, Chicago; London.
Currie, Janet. (2003), U.S. food and nutrition programs, in Robert A. Moffitt,, ed.
(2003), Means-Tested Transfer Programs in the United States, University of Chicago
Press.
32

Currie, Janet. (2004), The take up of social benefits, Working Paper 10488, National
Bureau of Economic Research.
Currie, Janet and Grogger, Jeffrey. (2001). ‘Explaining recent declines in Food Stamp
program participation’, Brookings-Wharton Papers on Urban Affairs pp. 203–244.
Daly, Mary C. and Burkhauser, Richard V. (2003), The Supplemental Security Income Program, in Robert A. Moffitt,, ed. (2003), Means-Tested Transfer Programs
in the United States, University of Chicago Press.
Daponte, Beth Osborne, Sanders, Seth and Taylor, Lowell. (1999). ‘Why do lowincome households not use Food Stamps? evidence from an experiment’, Journal of
Human Resources 34(3), 612–628.
Diamond, Peter A. and Mirrlees, James A. (1978). ‘A model of social insurance with
variable retirement’, Journal of Public Economics 10(3), 295–336.
Diamond, Peter A. and Sheshinski, Eytan. (1995). ‘Economic aspects of optimal
disability benefits’, Journal of Public Economics 57(1), 1–23.
Duggan, Mark G. and Kearney, Melissa S. (2005), The impact of child SSI enrollment
on household outcomes: Evidence from the Survey of Income and Program Participation,
Working Paper 11568, National Bureau of Economic Research.
Gruber, Jonathan. (2003), Medicaid, in Robert A. Moffitt,, ed. (2003), Means-Tested
Transfer Programs in the United States, University of Chicago Press.
Heckman, James J. and Smith, Jeffrey A. (2004). ‘The determinants of participation
in a social program: Evidence from a prototypical job training program’, Journal of Labor
Economics 22(2), 243–98.
Holtzblatt, Janet and McCubbin, Janet. (2003), Complicated lives: Tax administrative issues affecting low-income filers, mimeo, Department of the Treasury.
Kopczuk, Wojciech and Pop-Eleches, Cristian. (2007). ‘Electronic filing, tax preparers and participation in the Earned Income Tax Credit’, Journal of Public Economics
91(7-8), 1351–1367.
Luce, Robert Duncan. (1959), Individual Choice Behavior; a theoretical analysis, Wiley,
New York.
Mill, John Stuart. (1848), Principles of Political Economy, Vol. Books IV and V, Penguin, Harmondsworth, UK.
Moffitt, Robert. (1983). ‘An economic model of welfare stigma’, American Economic
Review 73(5), 1023–35.
Moffitt, Robert A., ed. (2003), Means-Tested Transfer Programs in the United States,
University of Chicago Press.
33

Nagi, Saad Z. (1969), Disability and Rehabilitation: Legal, Clinical, and Self-Concepts
and Measurement, Ohio State University Press, Columbus, OH.
Nichols, Albert L. and Zeckhauser, Richard. (1982). ‘Targeting transfers through
restrictions on recipients’, American Economic Review 72(2), 372–77.
Olsen, Edgar O. (2003), Housing programs for low-income households, in Robert A.
Moffitt,, ed. (2003), Means-Tested Transfer Programs in the United States, University
of Chicago Press.
Parsons, Donald O. (1996). ‘Imperfect ’tagging’ in social insurance programs’, Journal
of Public Economics 62(1-2), 183–207.
Saez, Emmanuel. (2002). ‘Optimal income transfer programs: Intensive versus extensive
labor supply responses’, Quarterly Journal of Economics 117(3), 1039–1073.
Scholz, John Karl. (1994). ‘The Earned Income Tax Credit: Participation, compliance
and anti-poverty effectiveness’, National Tax Journal 48(1), 59–81.
Slemrod, Joel. (1990). ‘Optimal taxation and optimal tax systems’, Journal of Economic
Perspectives 4(1), 157–78.
Slemrod, Joel and Yitzhaki, Shlomo. (2002), Tax avoidance, evasion and administration, in Alan Auerbach and Martin S. Feldstein., eds, ‘Handbook of Public
Economics’, Vol. 3, Elsevier/North Holland, Amsterdam; New York.
Stern, Nicholas. (1982). ‘Optimal taxation with errors in administration’, Journal of
Public Economics 17(2), 181–211.

34

TABLE 1. SOCIAL PROGRAMS IN THE UNITED STATES
TAKE UP1

TARGETING2

COMPLEXITY2

Medicaid

73%

Medium

High

Medicare Part B3

96%

Low

Low

Supplemental Security Income Program (SSI)

60%

High

High

Social Security Disability Insurance (DI)

No estimate

High

High

The Earned Income Tax Credit (EITC)

80%-86%

Medium

High

Temporary Assistance for Needy Families (TANF)4

60%-90%

Medium

High

below 50%

Medium

High

69%

Medium

Medium

67%, 73%, 38%

High

High

40%

Medium

High

PROGRAM

Housing Programs
Food Stamps
35

The Special Supplemental Nutrition Program
for Women,Infants and Children (WIC)
Child Care Subsidies

1) Estimated take-up rates are averages for the entire eligible populations except for Medicaid (children), SSI (elderly), and WIC (women, infants, children). Where
an interval is provided, this reflects diﬀerent estimation methods and/or data. Take-up estimates are taken from following sources. Medicaid: Gruber (2003), Medicare: Currie (2004), SSI: Daly and Burkhauser (2003), EITC: Scholtz (1994), TANF: Blank (2001), Housing Programs: Olsen (2003), Food Stamps: Currie (2003),
WIC: Bitler et al. (2003), Child Care Subsidies: Witte (2002).
2) Targeting is interpreted as the strictness of elibility criteria (the reverse of universalism), while complexity is interpreted broadly to include all transaction costs.
Targeting and complexity classifications (low, medium, high) are based on Moﬃtt (2003) and Currie (2004).
3) Medicare Part A is mandatory and therefore has a take-up rate equal to 100%.
4) Replaced Aid to Families with Dependent Children (AFDC) in 1996. Take-up estimates are based on the AFDC program.

FIGURE 1. DENSITIES OF P(.) AND CLASSIFICATION ERRORS
Panel A: Low-ability individuals highlighted
Low Ability

High Ability

Type Ia errors
Type Ib errors
occur in this region

P(a,B)
= 0.736

P(0)
= 0.5
High-s individuals

1
Low-s individuals

Panel A: High-ability individuals highlighted
Low Ability

High Ability

Type II errors
occur in region

P(0)
= 0.5

P(a,B)
= 0.736

High-s individuals

1
Low-s individuals

36

Figure 2: The relationship of the optimal program with revenue
3.4

NL = 1000, NH = 1000
Eligibility criterion (a)

A:

NL = 1000, NH = 1200
1.5

NL = 1000, NH = 2000
Benefit level (B) and screening intensity (α
α)

B:

1.3

B (left scale)
α (right scale)
3.2

1.2

1.4

3

1.1
1.3

2.8

1
1.2

2.6

0.9
1.1

2.4

0.8
1

2.2

2

0.9
1000

0.65

1200

1400

1600

C: Complexity costs in proportion to benefits (f(α) B)

0.6

1800

1000
0.6

0.6

0.5

0.55

0.4

0.5

0.3

0.45

0.2

0.4

0.1

0.35

0

0.3

1200

1400

1600

1800

D: Elasticity of L−individuals w.r.t. policy parameters
α

a

B

−0.1
1000

1

0.7

E:

1200

1400

1600

1800

1000

Low−ability individuals

1

0.6

0.6

1200

1400

1600

1800

High−ability individuals

rate

0.8

rate

0.8

F:

0.4

0.4

0.2

0.2
Take up rate
%Receiving benefits

0

Take up rate
%Receiving benefits
0

1000

1200

1400
Revenue

1600

1800

1000

37

1200

1400
Revenue

1600

1800

Figure 3: The relationship of the optimal program with c1, where f(α) = c0 + c1 ⋅ αc2, at R + 500
3.4

A:

Eligibility criterion (a)

1.3

Benefit level (B) and screening intensity (α
α)

B:

20

B (left scale)
α (right scale)
3.2
1.2

15

1.1

10

3

2.8

2.6

2.4
1

5

2.2

2

0.9
0.5

0.8

1.0

1.5

C: Complexity costs in proportion to benefits (f(α) B)

0

2.0

0.5
0.8

1.0

1.5

2.0

D: Elasticity of L−individuals w.r.t. policy parameters
α

a

B

0.6
0.7
0.4
0.6

0.2

0

0.5

−0.2
0.4
−0.4

0.3

−0.6
0.5

1

E:

1.0

1.5

2.0

0.5

Low−ability individuals

1

0.6

0.6

1.0

1.5

2.0

High−ability individuals

rate

0.8

rate

0.8

F:

0.4

0.4

0.2

0.2
Take up rate
%Receiving benefits

0

Take up rate
%Receiving benefits
0

0.5

1.0
c1

1.5

2.0

0.5

38

1.0
c1

1.5

2.0

Figure 4: The relationship of the optimal program with c0, where f(α) = c0 + c1 ⋅ αc2, at R + 500
120

A:

Eligibility criterion (a)

1.1

Benefit level (B) and screening intensity (α
α)

B:

1.2

B (left scale)
α (right scale)
100

1
1.05

80

0.8

60

1

0.6

40

0.4
0.95

20

0.2

0

0.9
0.0

1

0.2

0.4

0.6

0.8

C: Complexity costs in proportion to benefits (f(α) B)

1.0
0.8

0.9

0.6

0.8

0.4

0.7

0.2

0.6

0

0.5

0.2

0.4

0.6

0.8

1.0

D: Elasticity of L−individuals w.r.t. policy parameters
α

B (/100)

a

−0.2
0.0

1

0
0.0

0.2

E:

0.4

0.6

0.8

1.0

0.0

Low−ability individuals

1

0.6

0.6

0.4

0.6

0.8

1.0

High−ability individuals

rate

0.8

rate

0.8

0.2

F:

0.4

0.4

0.2

0.2
Take up rate
%Receiving benefits

0

Take up rate
%Receiving benefits
0

0.0

0.2

0.4

0.6

0.8

1.0

0.0

c0

0.2

0.4

0.6
c0

39

0.8

1.0

Figure 5: The relationship of the optimal program with c2, where f(α) = c0 + c1 ⋅ αc2, at R + 500
2.45

A:

Eligibility criterion (a)

1.1

Benefit level (B) and screening intensity (α
α)

B:

1.02

B (left scale)
α (right scale)
1
2.4

1.05
0.98

0.96
2.35

1
0.94

0.92
2.3

0.95
0.9

2.25

0.9
1.0

0.52

1.5

2.0

2.5

3.0

3.5

C: Complexity costs in proportion to benefits (f(α) B)

4.0

0.88
1.0

0.5

1.5

2.0

2.5

3.0

3.5

4.0

D: Elasticity of L−individuals w.r.t. policy parameters
α

a

B

0.5
0.4
0.48
0.3
0.46

0.44

0.2

0.42
0.1
0.4
0
0.38

0.36

−0.1
1.0

1

1.5

E:

2.0

2.5

3.0

3.5

4.0

1.0

Low−ability individuals

1

0.6

0.6

2.0

2.5

3.0

3.5

4.0

High−ability individuals

rate

0.8

rate

0.8

1.5

F:

0.4

0.4

0.2

0.2
Take up rate
%Receiving benefits

0

Take up rate
%Receiving benefits
0

1.0

1.5

2.0

2.5
c2

3.0

3.5

4.0

1.0

40

1.5

2.0

2.5
c2

3.0

3.5

4.0

