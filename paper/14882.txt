NBER WORKING PAPER SERIES

BAYESIAN AND FREQUENTIST INFERENCE IN PARTIALLY IDENTIFIED MODELS
Hyungsik Roger Moon
Frank Schorfheide
Working Paper 14882
http://www.nber.org/papers/w14882

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2009

We thank seminar participants at the 2007 NASM, the 2008 SETA, Boston College, Johns Hopkins,
Ohio State, Rice, UC Davis, UC Irvine, UCLA, and Vanderbilt for helpful comments. Moon gratefully
acknowledges financial support from the USC Faculty Development Award. Schorfheide gratefully
acknowledges financial support from the Alfred P. Sloan Foundation and the National Science Foundation
under Grant SES 0617803. The views expressed herein are those of the author(s) and do not necessarily
reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
Â© 2009 by Hyungsik Roger Moon and Frank Schorfheide. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including Â© notice, is given to the source.

Bayesian and Frequentist Inference in Partially Identified Models
Hyungsik Roger Moon and Frank Schorfheide
NBER Working Paper No. 14882
April 2009
JEL No. C11,C32,C35
ABSTRACT
A large sample approximation of the posterior distribution of partially identified structural parameters
is derived for models that can be indexed by a finite-dimensional reduced form parameter vector. It
is used to analyze the differences between frequentist confidence sets and Bayesian credible sets in
partially identified models. A key difference is that frequentist set estimates extend beyond the boundaries
of the identified set (conditional on the estimated reduced form parameter), whereas Bayesian credible
sets can asymptotically be located in the interior of the identified set. Our asymptotic approximations
are illustrated in the context of simple moment inequality models and a numerical illustration for a
two-player entry game is provided.

Hyungsik Roger Moon
University of Southern California
Department of Economics
KAP 300
University Park Campus
Los Angeles, CA 90089
moonr@usc.edu
Frank Schorfheide
University of Pennsylvania
Department of Economics
3718 Locust Walk
McNeil 525
Philadelphia, PA 19104-6297
and NBER
schorf@ssc.upenn.edu

1

Introduction

In partially identified models one can only bound, but not point-identify the structural
parameter vector of interest, Î¸. Such models arise in many areas of economics. Prominent
examples in macroeconomics are structural vector autoregressions (VARs) and dynamic
stochastic general equilibrium (DSGE) models. In the VAR literature the identification
problem has traditionally be addressed by imposing enough restrictions on the structural
form such that the mapping between one-step-ahead forecast errors and structural shocks
becomes one-to-one. More recently however, Canova and De Nicolo (2002) and Uhlig (2005)
have developed more agnostic identification schemes that only restrict the signs of a subset
of impulse responses in the initial periods after the impact of the shock, which leads to
partially identified structural VAR. In DSGE models partial identification arises for instance
if a subset of structural parameters guarantees the uniqueness of a rational expectations
equilibrium but does not affect the equilibrium law of motion, e.g., Lubik and Schorfheide
(2004).
Partially-identified models also percolate the microeconometric literature and include
censored sampling models and models for interval data, surveyed at length in Manski (2003).
Partial identification arises in models of industrial organization, for instance, in gametheoretic models with multiple equilibria studied by Bresnahan and Reiss (1991), Berry
(1994), Halie and Tamer (2003), Pakes, Porter, Ho, and Ishi (2005), Bajari, Benkard, and
Levin (2007), and Ciliberto and Tamer (2007). Given the lack of point identification researchers have rightly focused on set estimators for the parameter of interest. While the
macroeconometrics literature mostly applies Bayesian approaches, the microeconometric literature is dominated by frequentist procedures. The contribution of this paper is to compare
frequentist confidence sets and Bayesian credible sets, with a special focus on the properties
of Bayesian procedures.
Starting point of our analysis is a likelihood function indexed by a finite-dimensional,
identifiable reduced-form parameter vector Ï†. Reduced-form and structural parameter are
linked through a correspondence, which we express as Ï† = G(Î¸, Î±), where Î± âˆˆ AÎ¸ . The
presence of the nuisance parameter Î± complicates the inference about Î¸. We present a large
sample approximation of the posterior distribution of Î¸. The approximation is based on an
insight that dates back at least to Kadane (1974) and has recently been utilized, for instance,
by Poirier (1998): beliefs about the reduced form parameter Ï† are updated through the
likelihood function, but the conditional distribution of Î¸ given Ï† remains unchanged in view

2

of new data. It is well known that under very general conditions the posterior distribution
of Ï† is asymptotically normal. We construct such a normal approximation for Ï† following
the analysis in Johnson (1970) and combine it with conditional prior distributions of Î¸ given
Ï† to obtain our approximation of the posterior of Î¸. If H(Ï†, Î¾) is the prior probability that
Î¸ âˆˆ TÎ¾ conditional on Ï†, then we show that under some regularity conditions an O(nâˆ’1/2 )
accurate approximation of the posterior probability is given by H(Ï†Ì‚n , Î¾), where Ï†Ì‚n is the
maximum likelihood estimator of Ï†. This approximation implies there exist asymptotically
valid Bayesian credible sets inside the identified set of Î¸ parameters associated with Ï†Ì‚n ,
denoted by Î˜(Ï†Ì‚n ).
There is a rapidly growing literature on the construction of asymptotically valid frequentist confidence sets for Î¸, e.g. Manski and Tamer (2002), Imbens and Manski (2004),
Andrews, Berry, and Jia (2004), Pakes, Porter, Ho, and Ishi (2005), Rosen (2005), Galichon
and Henry (2006), Romano and Shaikh (2006), Woutersen (2006), Andrews and Guggenberger (2007), Andrews and Soares (2007), Canay (2007), Chernozhukov, Hong, and Tamer
(2007), Stoye (2007), and Beresteanu and Molinari (2008). The main challenge of this
literature is to obtain large sample approximations of the sampling distribution of an estimation objective function or a test statistic that conditional on Î¸ are uniformly valid for all
Ï† = G(Î¸, Î±), Î± âˆˆ AÎ¸ . While we do not develop new methods to construct frequentist confidence sets, we show that frequentist sets need to extend beyond the boundaries of Î˜(Ï†Ì‚n ).
Thus, we can deduce that in partially identified models, Bayesian credible sets tend to be
smaller than frequentist confidence sets. This finding is in contrast with the regular point
identified case, in which Bayesian and frequentist sets coincide in large samples.
The remainder of the paper is organized as follows. In Section 2 we briefly review the
construction of Bayesian and frequentist set estimates for regular, point-identified models.
We then generalize the setup to models in which Î¸ is set-identified and provide a simple
example of a partially identified model. The large sample approximation of the posterior of
Î¸ and the construction of asymptotically valid credible sets for partially identified models
is presented in Section 3. In Section 4 we illustrate properties of the large sample approximation using simple moment inequality models. Section 5 provides a numerical illustration
in the context of an entry-game model and Section 6 concludes. Proofs are collected in an
Appendix.
A word on notation. We often use M to denote a generic finite constant. When X is a
1/2

matrix, kXk = (tr (X 0 X))

denotes the Euclidean norm of X. We use N (Âµ, Ïƒ 2 ) to denote

a normal distribution with mean Âµ and variance Ïƒ 2 and Ï†N (Â·) and Î¦N (Â·) the probability

3

density (pdf) and cumulative density (cdf) functions of a vector of standard normal random
variables. Moreover, we denote the one-sided critical value for a standard normal random
variable by zÏ„ = Î¦âˆ’1
N (1 âˆ’ Ï„ ). U[a, b] denotes the uniform distribution on the interval [a, b].
We use Pba to denote a probability distribution of a random variable a conditional on the
realization of a random variable b. I{X â‰¤ Î¾} denotes the indicator function that is equal to
one if X â‰¤ Î¾ and zero otherwise. Finally, the notation âŠ† is used to denote weak inclusion
and âŠ‚ is used for strict inclusion.

2

Identified and Partially Identified Models

We begin with a heuristic comparison of large sample approximations of Bayesian posterior
distributions and the frequentist distribution of likelihood ratios in a point identified model
in which the likelihood function is locally approximately quadratic and the maximum likelihood estimator (MLE) has a Gaussian limit distribution. It is well known that in this
environment the Bayesian 1 âˆ’ Ï„ credible Highest Posterior Density (HPD) set is approximately a level set of the likelihood function and has a 1 âˆ’ Ï„ coverage probability from a
frequentist perspective. A formalization and refinement of the subsequent heuristics can be
found in Severini (1991), who derives asymptotic expansions for the posterior probability of
confidence regions based on the likelihood ratio statistic and for the (frequentist) coverage
probability of highest posterior density regions.
Suppose that a sequence of random variables Y n = {Yi }ni=1 is characterized by a density
p(Y n |Ï†) with respect to a dominating measure Âµ, where Ï† âˆˆ Î¦ âŠ† RK . Let ln (Ï†) = ln p(Y n |Ï†)
be the log likelihood function and Ï†Ì‚n denote the maximum likelihood estimator (MLE), that
is ln (Ï†Ì‚n ) â‰¥ ln (Ï†) for all Ï† âˆˆ Î¦. A large sample approximation of the Bayesian posterior
density can be obtained from a second-order Taylor expansion of the log-posterior density
function around the MLE Ï†Ì‚n . Let âˆ’JË†n be the Hessian of the likelihood function evaluated
at the maximum Ï†Ì‚n such that
1
ln (Ï†) = ln (Ï†Ì‚n ) âˆ’ (Ï† âˆ’ Ï†Ì‚n )0 JË†n (Ï† âˆ’ Ï†Ì‚n ) + Rl (kÏ† âˆ’ Ï†Ì‚n k2 ).
2

(1)

Similarly, let Ï€(Ï†) = ln p(Ï†) be the log prior density and assume that one can approximate
the log prior with a first-order Taylor series expansion of the form
Ï€(Ï†) = Ï€(Ï†Ì‚n ) + Ï€ (1) (Ï†Ì‚n )0 (Ï† âˆ’ Ï†Ì‚n ) + RÏ€ (kÏ† âˆ’ Ï†Ì‚n k).

4
1/2

Now transform Ï† according to s = JË†n (Ï† âˆ’ Ï†Ì‚n ), such that
1
= âˆ’ s0 s + Rl (kJË†nâˆ’1/2 sk2 )
2
âˆ’1/2
(1)
Ë†
Ï€(Ï†Ì‚n + Jn s) âˆ’ Ï€(Ï†Ì‚n ) = Ï€ (Ï†Ì‚n )0 JË†nâˆ’1/2 s + RÏ€ (kJË†nâˆ’1/2 sk2 ).

ln (Ï†Ì‚n + JË†nâˆ’1/2 s) âˆ’ ln (Ï†Ì‚n )

If Ï† is identifiable, then the smallest eigenvalue of Jn is positive and increasing with the
âˆ’1/2
sample size such that JË†n s tends to zero and the influence of the prior distribution on the

posterior vanishes as n âˆ’â†’ âˆ. Hence,
1
ln p(Ï†Ì‚n + JË†nâˆ’1/2 s|Y n ) âˆ’ ln p(Ï†Ì‚n |Y n ) â‰ˆ ln (Ï†) âˆ’ ln (Ï†Ì‚n ) â‰ˆ âˆ’ s0 s,
2
that is, the posterior distribution of Ï† is approximately normal. Under suitable regularity
conditions, it can be deduced that
PYÏ†n {2[ln (Ï†) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„ } âˆ’ P {Z 0 Z â‰¤ cÏ„ } âˆ’â†’ 0,

(2)

where Z âˆ¼ N (0, I). If one chooses cÏ„ such that P {Z 0 Z â‰¤ cÏ„ } = 1 âˆ’ Ï„ , then our heuristics
imply that the level set


CS = Ï† 2[ln (Ï†) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„
Ï†

(3)

provides a large sample approximation to the HPD set that is 1 âˆ’ Ï„ credible.
For a frequentist analysis it is convenient to approximate the likelihood function around
the probability limit Ï†0 of the maximum likelihood estimator:
1
0
ln (Ï†) = ln (Ï†0 ) + Zn,0
(Ï† âˆ’ Ï†0 ) âˆ’ (Ï† âˆ’ Ï†0 )0 Jn,0 (Ï† âˆ’ Ï†0 ) + R(kÏ† âˆ’ Ï†0 k2 ).
2

(4)

Here, Zn,0 and Jn,0 are the matrices of first and second derivatives of the log-likelihood
1/2

function evaluated at Ï†0 . Now let s = Jn,0 (Ï† âˆ’ Ï†0 ) and write
1
1 0
âˆ’1/2
âˆ’1/2
âˆ’1/2
âˆ’1
ln (Ï†) = ln (Ï†0 ) âˆ’ (s âˆ’ Jn,0 Zn,0 )0 (s âˆ’ Jn,0 Zn,0 ) + Zn,0
Jn,0
Zn,0 + R(kJn,0 sk2 ).
2
2
In â€œregularâ€1 models

1
n Jn,0

p

âˆ’1/2

âˆ’â†’ J0 and Jn,0 Zn,0 =â‡’ Z uniformly in Ï†0 , where Z âˆ¼

N (0, I). Under suitable regularity conditions one can show that
1
âˆ’1/2
âˆ’1/2
ln (Ï†0 ) âˆ’ ln (Ï†Ì‚n ) = âˆ’ (s âˆ’ Jn,0 Zn,0 )0 (s âˆ’ Jn,0 Zn,0 ) + op (1)
2
and deduce
n

sup PÏ†Y {2[ln (Ï†) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„ } âˆ’ P {Z 0 Z â‰¤ cÏ„ } âˆ’â†’ 0.

(5)

Ï†âˆˆÎ¦
1 An

important and widely studied irregular model in the econometrics literature is the autoregressive

model yt = Ï†ytâˆ’1 +t , where Ï† âˆˆ [0, 1], see Sims and Uhlig (1991). Here the convergence of Jn (Ï†)âˆ’1/2 Zn (Ï†)
to a limit distribution is not uniform in Ï† and Bayesian and frequentist interval estimates differ.

5
Thus, the set CS Ï† in (3) is also a uniformly valid frequentist confidence set.
The above analysis remains essentially unchanged if one uses a smooth one-to-one function Ï† = G(Î¸) to re-parameterize the problem in terms of a structural parameter of interest
Î¸. The set
CS Î¸ =



Î¸ 2[ln (G(Î¸)) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„

is (asymptotically) a 1 âˆ’ Ï„ credible set for a Bayesian and a 1 âˆ’ Ï„ confidence set for a
frequentist econometrician. The point of departure in this paper is to replace the function
G(Î¸) by a correspondence. Each value of the reduced form parameter Ï† âˆˆ Î¦ is associated
with a set of structural form parameters. This set is typically referred to as the identified set
and will be denoted by Î˜(Ï†). Likewise, each structural parameter is potentially associated
with multiple reduced form parameters, which we collect in the set Î¦(Î¸).
Example 1: Moment Inequalities. Consider the simple location model Yi = Ï† + Ui ,
where Ui is iid with some probability density function f (u). Suppose that the relationship
between the location parameter Ï† âˆˆ Î¦ âŠ† R and the structural parameter of interest is given
by the inequalities
Î¸ âˆ’ Î» â‰¤ Ï† â‰¤ Î¸,
where Î» is a known constant that determines the length of the identified set. The model
specification is similar to the simple treatment effect model, in which observations are missing with a known probability, analyzed in Imbens and Manski (2004). In this example
Î˜(Ï†) = [Ï†, Ï† + Î»] and Î¦(Î¸) = [Î¸ âˆ’ Î», Î¸]. 
To study inference with respect to the partially identified parameter Î¸ we express the
correspondence Î¦(Î¸) in terms of a functional relationship between Ï†, Î¸, and an auxiliary
parameter Î± such that
Ï† = G(Î¸, Î±).
We assume that for each Ï† there exists a suitable domain AÎ¸ such that


Î¦(Î¸) = Ï† Ï† = G(Î¸, Î±) for some Î± âˆˆ AÎ¸ .
In the moment inequality example we can choose2 G(Î¸, Î±) = Î¸âˆ’Î± and AÎ¸ = [0, Î»]. Replacing
the reduced form parameter in the likelihood function leads to the following log-likelihood
ratio:
ln (G(Î¸, Î±)) âˆ’ ln (Ï†Ì‚n ).
From the perspective of inference about Î¸ the auxiliary parameter Î± is a nuisance parameter.
2 The

choice of G(Î¸, Î±) is not unique, because one can express Î± through arbitrary functions that map

into the unit interval.

6

3

Large Sample Analysis

We now derive a large sample approximation of the posterior distribution of a parameter
Î¸ âˆˆ Î˜ âŠ† Rk in a partially identified model in which the identifiable reduced form parameter
Ï† âˆˆ Î¦ âŠ† RK is linked to Î¸ through a correspondence that takes the form Ï† = G(Î¸, Î±),
Î± âˆˆ AÎ¸ . We use the approximation to compare Bayesian credible sets and frequentist
confidence intervals in partially identified models.

3.1

Bayesian Analysis

In many applications Bayesian analysis can be conveniently implemented by combining
ln (G(Î¸, Î±)) with a prior distribution for Î¸ and Î±. One can use numerical methods such
as importance sampling or Markov-Chain Monte Carlo algorithms to approximate finitesample moments of the posterior distribution of Î¸. For a theoretical analysis, on the other
hand, it is more convenient to work with the joint distribution of Ï† and Î¸, decomposed into
the marginal distribution of Ï†, P Ï† , and the conditional distribution of Î¸ given Ï†, PÏ†Î¸ .
As emphasized by Kadane (1974), the derivation of the posterior distribution can be
done on the space of the reduced form parameter Ï†. Let T be a measurable subset of Î˜.
Then
I{Î¸ âˆˆ T } exp[ln (Ï†)]dPÏ†Î¸ dP Ï†
R R
exp[ln (Ï†)]dPÏ†Î¸ dP Ï†
Î¦ Î˜(Ï†)

Z Z
exp[ln (Ï†)]
Î¸ R
dP Ï†
=
I{Î¸ âˆˆ T }dPÏ†
Ï†
exp[l
n (Ï†)]dP
Î¦
Î˜(Ï†)
Î¦
Z
=
PÏ†Î¸ {Î¸ âˆˆ T }dPYÏ†n .
R R

PYÎ¸ n {Î¸

âˆˆT}

=

Î¦ Î˜(Ï†)

(6)

Î¦

Since conditional on Ï† the structural parameter Î¸ does not enter the likelihood function the
prior distribution of Î¸ given Ï†, PÏ†Î¸ , is not updated in view of the data Y n . This point also
has been emphasized by Poirier (1998). To obtain a large sample distribution of PYÎ¸ n , we will
replace PYÏ†n in (6) by a Gaussian approximation. There exists a long literature on normal
approximations of posterior distributions in identified models, including Bernstein (1934),
LeCam (1953), von Mises (1965). Our subsequent expansion of the posterior distribution of
Ï† follows work by Johnson (1970). Unlike Johnson, who provides higher-order expansions
of posterior distribution, we will only derive a first-order expansion. Rather starting from
low-level assumptions that guarantee the existence of a maximum likelihood estimate, we
begin by directly assuming the almost-sure convergence of the MLE.

7
n

Assumption 1 (i) The MLE Ï†Ì‚n exists and Ï†Ì‚n âˆ’â†’ Ï†0 [PÏ†Y0 ] almost surely.
n

(ii) For any Î´ > 0, lim supnâ†’âˆ supkÏ†âˆ’Ï†0 kâ‰¥Î´ n1 [ln (Ï†0 ) âˆ’ ln (Ï†)] > 0 [PÏ†Y0 ] almost surely.
In order to construct a normal approximation of the posterior distribution of Ï†, we need
to make a few additional assumptions that guarantee the smoothness of the log likelihood
function.
Assumption 2 (i) Î¦ is a compact subset in RK and Ï†0 âˆˆ int (Î¦) .
(ii) For n sufficiently large, p(Y n |Ï†) is twice continuously differentiable with respect to Ï†.
(iii)

1
n Jn,0

n

âˆ’â†’ J0 [PÏ†Y0 ] almost surely and Jn is well-defined and negative definite.

(iv) There exists a Î´ > 0 and a finite constant M such that kÏ†1 âˆ’ Ï†2 k implies that
1
n

n

kJn (Ï†1 ) âˆ’ Jn (Ï†2 )k â‰¤ M kÏ†1 âˆ’ Ï†2 k, [PÏ†Y0 ] almost surely.
Under Assumption 2, the log likelihood is continuous over a compact set, therefore the

MLE Ï†Ì‚n is well defined. Under Assumption 2(ii), the log likelihood function is twice continuously differentiable. As in the previous Section, we use âˆ’Jn (Ï†) to denote the matrix
of second derivatives of the log-likelihood function around Ï†. We continue to use the abbreviations Jn,0 = Jn (Ï†0 ) and JË†n = Jn (Ï†Ì‚n ). Assumptions 1 and 2 cover models with iid
observations as well as time series models for weakly dependent data without trends. Large
sample approximations of posterior distributions for non-stationary time series models can
be found in Phillips and Ploberger (1996) and Kim (1998).
Assumption 3 (i) The prior density p(Ï†) is uniformly bounded in Ï† âˆˆ Î¦ and continuously
differentiable in a neighborhood around Ï†0 .
(ii) There exists a Î´p > 0 such that inf kÏ†âˆ’Ï†0 kâ‰¤Î´p p(Ï†) > 0 and supkÏ†âˆ’Ï†0 kâ‰¤Î´p p(1) (Ï†) â‰¤ M
for some finite constant M.
According to Assumption 3 the parameter Ï†0 is drawn from the prior distribution P Ï†
whose density function is p(Ï†). When p(Ï†) is differentiable, we denote p(1) (Ï†) to be its first
1/2
derivative. We use s to denote the re-scaled parameter vector JË†n (Ï† âˆ’ Ï†Ì‚n ). Based on the

above assumption we obtain the following approximation to the posterior distribution of Ï†.
Theorem 1 Suppose Assumptions 1 â€“ 3 are satisfied. Let Y n be in the sure set of Assumptions 1 and 2.

8

(i) There exist finite constants M and N such that whenever n â‰¥ N we have for any sequence
of bounded functions |Hn (Ï†, Î¾)| < MH
Z
Z
Ï†
Hn (Ï†, Î¾) dPY n âˆ’



M
Hn Ï†Ì‚n + JË†nâˆ’1/2 s, Î¾ dÎ¦N (s) â‰¤ âˆš .
n
k
R

Ï†âˆˆÎ¦

(ii) There exist finite constants M and N such that whenever n â‰¥ N
sup
Î¾âˆˆRK

M
PYÏ†n {JË†n1/2 (Ï† âˆ’ Ï†Ì‚n ) â‰¤ Î¾} âˆ’ Î¦N (Î¾) â‰¤ âˆš .
n

Part (i) of Theorem 1 is proved in the Appendix. Part (ii) follows directly from Part
1/2
(i) by setting Hn (Ï†, Î¾) = I{JË†n (Ï† âˆ’ Ï†Ì‚n ) â‰¤ Î¾} and provides a normal approximation of the
âˆ’1/2
posterior distribution of Ï† = Ï†Ì‚n + JË†n s. The constant M in Theorem 1 depends on the

function H(Â·) only through the bound MH .
The remainder of the paper focuses on the characterization of the posterior distribution
of Î¸ and the posterior probability of subsets of Î˜. Let TÎ¾,n âŠ† Î˜ be a sequence of subsets of
the structural parameter space, indexed my a finite-dimensional vector Î¾. Moreover, define
Hn (Ï†, Î¾) = PÏ†Î¸ {Î¸ âˆˆ TÎ¾,n }.

(7)

If TÎ¾,n = {Î¸ â‰¤ Î¾} then Hn (Ï†, Î¾) is the prior (and posterior) cdf of Î¸ given Ï† and does not
depend on n. If Î¸ = [Î¸10 , Î¸20 ]0 and TÎ¾,n = {Î¸1 â‰¤ Î¾} then Hn (Ï†, Î¾) is the cdf of the sub-vector
Î¸1 conditional on Ï†. In the context of Example 1 we will be interested in the posterior
probability of the sequence of sets Tn,Î¾ = [Ï†Ì‚n + Î»Î¾, Ï†Ì‚n + Î»(1 âˆ’ Î¾)], which can be expressed as
R
H (Ï†, Î¾) dPYÏ†n . Some of our subsequent results require that Hn (Ï†, Î¾) satisfies a Lipschitz
Î¦ n
condition.
Assumption 4 The sequence of functions Hn (Ï†, Î¾) defined in (7) is Lipschitz in Ï†, that is,
|Hn (Ï†1 , Î¾) âˆ’ Hn (Ï†2 , Î¾)| â‰¤ M (Î¾)kÏ†1 âˆ’ Ï†2 k, where M (Î¾) is a constant that depends on Î¾.
Since we are interested in using large sample approximations of posterior distributions
to characterize asymptotically valid credible sets, we provide the following formal definition.
Î¸
Definition 1 A sequence of sets CSB,Ï„
(Y n ) is asymptotically 1 âˆ’ Ï„ credible if PYÎ¸ n {Î¸ âˆˆ
Î¸
CSB,Ï„
(Y n )} âˆ’â†’ 1 âˆ’ Ï„ .

Combining (6) and Theorem 1 we obtain the following approximation to the posterior
probability that {Î¸ âˆˆ TÎ¾,n }:

9
Corollary 1 Suppose Assumptions 1 â€“ 3 are satisfied. Let Y n be in the sure set of Assumptions 1 and 2. The function Hn (Ï†, Î¾) is defined in (7).
(i) There exist finite constants M and N such that whenever n â‰¥ N
Z
M
Hn (Ï†Ì‚n + JË†nâˆ’1/2 s, Î¾)Ï†N (s)ds â‰¤ âˆš .
PYÎ¸ n {Î¸ âˆˆ TÎ¾,n } âˆ’
n
RK
(ii) If the sequence of functions Hn (Ï†, Î¾) satisfies Assumption 4, then there exist finite
constants M (Î¾) and N such that whenever n â‰¥ N
M (Î¾)
PYÎ¸ n {Î¸ âˆˆ TÎ¾,n } âˆ’ Hn (Ï†Ì‚n , Î¾) â‰¤ âˆš .
n
(iii) If the sequence of functions Hn (Ï†, Î¾) satisfies Assumption 4 and for every Ï† âˆˆ Î¦ and
Ï„ â‰¥ Î¾ > 0 there is a set TÎ¾ (Ï†) âŠ‚ Î˜(Ï†) such that PÏ†Î¸ {Î¸ âˆˆ TÎ¾ (Ï†)} â‰¥ 1 âˆ’ Î¾, then there exists a
Î¸
sequence of sets CSB,Ï„
(Y n ) âŠ† TÎ¾ (Ï†Ì‚n ) âŠ‚ Î˜(Ï†Ì‚n ) that is asymptotically 1 âˆ’ Ï„ credible.

Part (i) of Corollary 1 is a direct consequence of Theorem 1. Part (ii) is proved in
the Appendix and implies that an O(nâˆ’1/2 ) accurate approximation of the posterior distribution of Î¸ can be calculated from the conditional prior distribution PÏ†Ì‚Î¸ , provided that
n

Hn (Ï†, Î¾) satisfies the Lipschitz condition. For instance, the Lipschitz condition is satisfied
in Example 1, if PÏ†Î¸ is U[Ï†, Ï† + Î»] and TÎ¾,n = {Î¸ â‰¤ Î¾}. According to Corollary 1(iii) one
can construct asymptotically valid credible sets as subsets of TÎ¾ (Ï†Ì‚n ). By construction, these
sets lie strictly inside of the identified set Î˜(Ï†Ì‚n ).

3.2

Frequentist Analysis

Starting point for our frequentist analysis is the log likelihood ratio ln (G(Î¸, Î±)) âˆ’ ln (Ï†Ì‚n ).
We begin by concentrating out the nuisance parameter Î±. Let
Î±Ì‚(Î¸) = argmaxÎ±âˆˆAÎ¸ ln (G(Î¸, Î±))
and define the profile objective function
Qn (Î¸) = 2[ln (G(Î¸, Î±Ì‚(Î¸))) âˆ’ ln (Ï†Ì‚n )].

(8)

We consider consider confidence intervals that are of the form
Î¸
CSF,Ï„
= {Qn (Î¸) â‰¥ âˆ’cÏ„ (Î¸)}.

(9)

If the critical value function cÏ„ (Î¸) is constant, then the confidence interval is a level set of
Î¸
the profile objective function Qn (Î¸). For CSF,Ï„
to be a confidence set that is uniformly

10

valid asymptotically the following condition has to be satisfied:
lim inf

n

inf PÏ†Y {Qn (Î¸) â‰¥ âˆ’cÏ„ (Î¸)} â‰¥ 1 âˆ’ Ï„.

(10)

nâˆ’â†’âˆ Ï†âˆˆÎ¦ Î¸âˆˆÎ˜(Ï†)

Constructing a critical value function such that (10) holds with equality can be challenging and is the subject of a number of recent papers, including Imbens and Manski (2004),
Chernozhukov, Hong, and Tamer (2007), Romano and Shaikh (2005), Andrews and Guggenberger (2007), and Andrews and Soares (2007). For the remainder of this section we will
assume that such a critical value function is available and we will conduct a comparison
between Bayesian and frequentist confidence sets.
Since the objective function Qn (Î¸) = 0 if Î¸ âˆˆ Î˜(Ï†Ì‚n ) we can deduce immediately that
Î¸
. We now proceed by
the frequentist confidence interval contains Î˜(Ï†Ì‚n ): Î˜(Ï†Ì‚n ) âŠ† CSF,Ï„
Î¸
providing some conditions under which Î˜(Ï†Ì‚n ) âŠ‚ CSF,Ï„
. Suppose to the contrary that
Î¸
Î˜(Ï†Ì‚n ) = CSF,Ï„
. As long as the likelihood function has a unique maximum Ï†Ì‚n , Qn (Î¸) = 0

if and only if Î¸ âˆˆ Î˜(Ï†Ì‚n ). Using our definition of Î¦(Î¸) notice that
n

n

PÏ†Y {Qn (Î¸) = 0} = PÏ†Y {Ï†Ì‚n âˆˆ Î¦(Î¸)}.
Now consider
inf
Î¸âˆˆÎ˜(Ï†)

n

PÏ†Y {Ï†Ì‚n âˆˆ Î¦(Î¸)} =

inf
Î¸âˆˆÎ˜(Ï†)

âˆš
n âˆš
PÏ†Y { n(Ï†Ì‚n âˆ’ Ï†) âˆˆ n(Î¦(Î¸) âˆ’ Ï†)}.

Let Î¸Ìƒ be such that Ï† is on the boundary of Î¦(Î¸Ìƒ). Moreover, assume that

âˆš

n(Î¦(Î¸Ìƒ) âˆ’ Ï†) can

be covered with a convex cone C that is centered at Ï†. Then we obtain
inf
Î¸âˆˆÎ˜(Ï†)

âˆš
n âˆš
n âˆš
PÏ†Y { n(Ï†Ì‚n âˆ’ Ï†) âˆˆ n(Î¦(Î¸) âˆ’ Ï†)} â‰¤ PÏ†Y { n(Ï†Ì‚n âˆ’ Ï†) âˆˆ C}.

This argument proves the following theorem.
Theorem 2 Suppose there exists a pair Î¸Ìƒ and Ï†Ìƒ such that (i) Ï†Ìƒ is a boundary point of Î¦(Î¸Ìƒ),
âˆš
(ii) n(Î¦(Î¸Ìƒ) âˆ’ Ï†Ìƒ) can be covered with a convex cone C, and (iii) P {Z âˆˆ C} â‰¤ 1 âˆ’ Ï„ . Then
Î¸
Î˜(Ï†Ì‚n ) âŠ‚ CSF,Ï„
.

Î¸
The set CSF,Ï„
is a confidence set for the entire parameter vector Î¸. To conduct inference
Î¸
onto the relevant subspace of Î˜. In
for a subset of parameters Î¸1 , one could project CSF,Ï„

this case, it is still true that the projection of Î˜(Ï†Ì‚n ) is a strict subset of the projection of
Î¸
CSF,Ï„
.

11

3.3

Bayesian versus Frequentist Sets

According to Theorem 2 an asymptotically valid frequentist confidence set for Î¸ extends
beyond Î˜(Ï†Ì‚n ), whereas Corollary 1(iii) implies that asymptotically valid Bayesian credible
sets can be constructed as subsets of Î˜(Ï†Ì‚n ). Thus, unlike in the identified case discussed in
Section 2, frequentist and Bayesian set estimates are numerically different in large samples
if a model is partially identified. In particular, one can obtain Bayesian credible sets that
are strict subsets frequentist confidence sets.
The frequentist literature on partially identified models is also concerned about estimates of the identified set Î˜(Ï†). Imbens and Manski (2004) highlight that confidence sets
for the set Î˜(Ï†) tend to be larger than confidence sets for an element Î¸ âˆˆ Î˜(Ï†). The existing literature is not very clear about the instances in which an empirical researcher might
prefer an a confidence set for Î˜(Ï†) over a confidence set for Î¸ âˆˆ Î˜(Ï†). A loose argument for
reporting an estimate of Î˜(Ï†) is that the econometricianâ€™s audience might be interested in
solving a minimax decision problem of the form3
min
n

n

max

Î´(Y )âˆˆD Ï†âˆˆÎ¦, Î¸âˆˆÎ˜(Ï†)

PÏ†Y [L(Î´(Y n ), Î¸)]

(11)

by replacing Î˜(Ï†) in (11) with a confidence set that covers Î˜(Ï†). Here Î´(Y n ) is a decision
function and L(Î´, Î¸) a loss function. In a Bayesian framework, the natural approach for the
econometrician would be to compute the posterior distribution for Î¸ and solve the decision
problem by minimizing posterior expected loss
min

Î´(Y n )âˆˆD

PYÎ¸ n [L(Î´(Y n ), Î¸)],

which does not require a credible set for Î˜(Ï†). Nonetheless, a posterior credible set could
be obtained, for instance, by taking unions of Î˜(Ï†) for values of Ï† in a set CSÏ„Ï† :
CSÏ„âˆ— =

[

Î˜(Ï†).

Ï†âˆˆCSÏ„Ï†

By construction, I{Î˜(Ï†) âŠ† CSÏ„âˆ— } â‰¥ I{Ï† âˆˆ CSÏ„Ï† }. If CSÏ„Ï† is both a valid frequentist
confidence set as well as a valid Bayesian credible set (see Section 2) we can deduce that
CSÏ„âˆ— is a valid set estimate for Î˜(Ï†) from both the Bayesian and the frequentist perspective.
3 As

an alternative to the expected loss one could consider the regret L(Î´(Y n ), Î¸) âˆ’ L(Î´ opt , Î¸).

12

4

Illustrations

The large sample approximations obtained in the previous section are now applied to several
specific examples, beginning with the moment inequality example presented in Section 2.
With our extensions of Example 1, we illustrate that Bayesian credible sets are asymptotically located inside Î˜(Ï†Ì‚n ), whereas frequentist confidence sets extend beyond the boundaries
of Î˜(Ï†Ì‚n ) (Section 4.1). This result also holds if frequentist inference is based on an integrated instead of a profile likelihood function (Section 4.2, Example 1 continued). Our large
sample Bayesian inference can be extended to cover the models in which the volume of the
identified set depends on an estimable parameters and is potentially zero. We show how
to modify the approximation of the posterior to allow for reduced form parameters that lie
on the boundary of Î¦ (Section 4.2, Example 2). Finally, we consider a model in which the
reduced form parameter is uniquely determined by the structural parameter, but not vice
versa. If inference is conducted for the entire parameter vector Î¸ (instead of a subset of Î¸),
then certain Bayesian 1 âˆ’ Ï„ credible sets are in fact valid 1 âˆ’ Ï„ frequentist confidence sets
(Section 4.2, Example 3).

4.1

Moment Inequalities, Part I

Consider Example 1 of Section 2: Yi = Ï† + Ui , Ui is iid with pdf f (u), and Î¸ âˆ’ Î» â‰¤ Ï† â‰¤ Î¸,
where Î» is known. Assume that the density function f (u) satisfies Assumptions 1 and 2 with
J0 = 1. Moreover, assume that the prior density p(Ï†, Î±) = p(Ï†)p(Î±) where p(Ï†) satisfies
Assumption 3 and the prior on the auxiliary parameter Î± = Î¸ âˆ’ Ï† is uniform on the interval
[0, Î»]. To obtain a large sample approximation of the posterior cdf of Î¸, let TÎ¾,n = {Î¸ â‰¤ Î¾}.
Thus, the function Hn (Ï†, Î¾) is the cdf of a U[Ï†, Ï† + Î»] random variable and of the form
ï£±
ï£´
ï£´
0
if Î¾ < Ï†
ï£´
ï£²
Hn (Ï†, Î¾) = PÏ†Î¸ {Î¸ â‰¤ Î¾} =
(12)
(Ï† âˆ’ Î¾)/Î» if Ï† â‰¤ Î¾ â‰¤ Ï† + Î» .
ï£´
ï£´
ï£´
ï£³
1
otherwise
If Î» > 0 the function Hn (Ï†, Î¾) in (12) satisfies the Lipschitz condition in Assumption 4 and
we obtain the following two approximations of the posterior probability Î¸ â‰¤ Î¾:
PÌ‚YÎ¸ n (i) {Î¸ â‰¤ Î¾} =

âˆš
1
(Î¾ âˆ’ Ï†Ì‚n )Î¦N ( n(Î¾ âˆ’ Ï†Ì‚n ))
Î»
âˆš
1
âˆ’ (Î¾ âˆ’ (Ï†Ì‚n + Î»))Î¦N ( n(Î¾ âˆ’ (Ï†Ì‚n + Î»)))
Î»


âˆš
âˆš
1
+ âˆš Ï†N ( n(Î¾ âˆ’ Ï†Ì‚n )) âˆ’ Ï†N ( n(Î¾ âˆ’ (Ï†Ì‚n + Î»))) ,
Î» n

PÌ‚YÎ¸ n (ii) {Î¸ â‰¤ Î¾} = Hn (Ï†Ì‚n , Î¾).

(13)

(14)

13

The posterior density associated with approximation (i) can be obtained by differentiating
the cdf PÌ‚YÎ¸ n (i) {Î¸ â‰¤ Î¾} with respect to Î¸:


âˆš
âˆš
1
pÌ‚(i) (Î¸|Y ) =
Î¦N ( n(Î¸ âˆ’ Ï†Ì‚n )) âˆ’ Î¦N ( n(Î¸ âˆ’ (Ï†Ì‚n + Î»))) .
Î»
n

(15)

Since Î¦N (x) = 1 âˆ’ Î¦N (âˆ’x), it is straightforward to verify that the approximate posterior
density pÌ‚(i) (Î¸|Y n ) is symmetric around the mode Î¸Ì‚n = Ï†Ì‚n + Î»/2. For large values of n
pÌ‚(i) (Î¸|Y n ) approaches the density function associated with PÌ‚YÎ¸ n (ii) : it jumps from 0 to 1/Î»
at Î¸ = Ï†Ì‚n , stays constant, and drops back to zero around Î¸ = Ï†Ì‚n + Î».
According to PÌ‚YÎ¸ n (ii) the posterior distribution of Î¸ is uniform on the Î˜(Ï†Ì‚n ) asymptotically. This suggests that the set
Î¸
CSB,Î¾
(Y n ) = [Ï†Ì‚n + Î¾Î»/2, Ï†Ì‚n + Î» âˆ’ Î¾Î»/2] âŠ‚ Î˜(Ï†Ì‚n )

is an asymptotically valid 1 âˆ’ Î¾ credible interval for Î¸. To verify this claim, let TÎ¾,n =
Î¸
CSB,Î¾
(Y n ) and define

Hn (Ï†, Î¾) = PÏ†Î¸ {Î¸ âˆˆ TÎ¾,n }.

(16)

This function is piecewise linear with a Lipschitz constant of 1/Î» (see Assumption 4). Thus,
Î¸
provided that Î» > 0, the posterior probability PYÎ¸ n {Î¸ âˆˆ CSB,Î¾
(Y n )} can according to

Corollary 1 be approximated by Hn (Ï†Ì‚n , Î¾) = 1 âˆ’ Î¾ in (16), which verifies the claim. If
Î» = 0 and Î¸ is point identified, the Lipschitz condition is violated and the asymptotic
approximation of the posterior cdf is of the form PÌ‚YÎ¸ n (i) {Î¸ â‰¤ Î¾} = Î¦N (Î¾), which leads to
âˆš
the â€œstandardâ€ interval Ï†Ì‚n Â± zÏ„ /2 / n.
To illustrate the frequentist analysis we assume that f (u) = Ï†N (u). Hence the profile
objective function is given by

âˆ’Qn (Î¸) =

ï£±
ï£´
ï£´
n(Ï†Ì‚n âˆ’ Î¸)2
ï£´
ï£²

0
ï£´
ï£´
ï£´
ï£³ n(Ï†Ì‚ âˆ’ Î¸ + Î»)2
n

if Î¸ â‰¤ Ï†Ì‚n
if Ï†Ì‚n < Î¸ < Ï†Ì‚n + Î» .

(17)

if Ï†Ì‚n + Î» â‰¤ Î¸

The finite-sample distribution of the maximum likelihood estimator is

âˆš

n(Ï†Ì‚n âˆ’ Ï†) âˆ¼ Z,

where Z is a standard normal random variable. It is convenient to re-scale Î¸ according
âˆš
to sÎ¸ = n(Î¸ âˆ’ Ï†). In terms of the sÎ¸ transform, the identified set Î˜(Ï†) is given by
âˆš
0 â‰¤ sÎ¸ â‰¤ nÎ». We can now characterize the distribution of the profile objective function as
ï£±
ï£´
ï£´
(Z âˆ’ sÎ¸ )2
if sÎ¸ â‰¤ Z
ï£´
ï£²
âˆš
âˆ’Qn (Ï† + nâˆ’1/2 sÎ¸ ) âˆ¼
(18)
0
if Z < sÎ¸ < Z + nÎ» .
ï£´
ï£´
âˆš
âˆš
ï£´
ï£³ (Z âˆ’ s + nÎ»)2 if Z + nÎ» â‰¤ s
Î¸
Î¸

14

Now suppose that the critical value cÏ„ solves the following equation:
âˆš
âˆš
âˆš
Î¦N ( nÎ» + cÏ„ ) âˆ’ Î¦N (âˆ’ cÏ„ ) = 1 âˆ’ Ï„.

(19)

In view of (18), we deduce
n

PÏ†Y {Qn (Î¸) â‰¥ âˆ’cÏ„ }
âˆš
âˆš
âˆš
=
infâˆš P {sÎ¸ âˆ’ nÎ» âˆ’ cÏ„ â‰¤ Z â‰¤ sÎ¸ + cÏ„ }
0â‰¤sÎ¸ â‰¤ nÎ»
âˆš
âˆš
âˆš
=
infâˆš Î¦N (sÎ¸ + cÏ„ ) âˆ’ Î¦N (sÎ¸ âˆ’ nÎ» âˆ’ cÏ„ )

inf

inf

Ï†âˆˆÎ¦ Î¸âˆˆÎ˜(Ï†)

0â‰¤sÎ¸ â‰¤ nÎ»

=

1 âˆ’ Ï„,

where the last line follows since the infimum is achieved at sÎ¸ = 0 or sÎ¸ =

âˆš

nÎ» and by the

definition of cÏ„ in (19) . Therefore, the resulting confidence interval is of the form


p
p
Î¸
n
CSF,Ï„ (Y ) = Ï†Ì‚n âˆ’ cÏ„ /n, Ï†Ì‚n + Î» + cÏ„ /n .

(20)

As pointed out by Imbens and Manski (2004), if the re-scaled length of the identified set is
large, then a 1âˆ’Ï„ confidence set for the parameter Î¸ is obtained by expanding the boundaries
âˆš
of the interval Î˜(Ï†Ì‚n ) using a one sided critical value cÏ„ â‰ˆ zÏ„ . If, on the other hand, the
âˆš
length of the identified set is zero (exact identification) or nÎ» is close to zero, then the
âˆš
boundaries of Î˜(Ï†Ì‚n ) have to be expanded by a two-sided critical value cÏ„ â‰ˆ zÏ„ /2 .
A comparison of the frequentist and the Bayesian interval leads to the relationship
Î¸
Î¸
CSB,Ï„
âŠ‚ Î˜(Ï†Ì‚n ) âŠ‚ CSF,Ï„
, as postulated in Corollary 1(iii) and Theorem 2. To see that

the conditions of Theorem 2 are satisfied, choose, for instance, Î¸Ìƒ = 0, Ï†Ìƒ = âˆ’Î». Hence
âˆš
Î¦(Î¸Ìƒ) âˆ’ Ï†Ìƒ = [0, Î»], which expands to C = R+ if scaled by n. Since P {Z âˆˆ R+ } = 1/2, a
confidence set with coverage probability greater than 50% has to extend beyond Î˜(Ï†Ì‚n ).
A graphical comparison of the frequentist confidence intervals and Bayesian credible
intervals is provided in Figure 1, assuming that f (u) = Ï†N (u). The two panels of the Figure
are drawn for a data set in which Ï†Ì‚n = 0. We overlay sample sizes n = 5 and n = 500. The
top panel depicts posterior densities p(Î¸|Y n ) = pÌ‚(i) (Î¸|Y n ) given in (15) and exact 90% HPD
intervals, calculated numerically. The bottom panel depicts the standardized frequentist
objective function

1
n Qn (Î¸)

from Equation (18), the critical values âˆ’cÏ„ /n that solve (19),

and 90% frequentist confidence intervals.

4.2

Moment Inequalities, Part II

Example 1 (continued): Frequentist Analysis with Integrated Likelihood. Previously, our frequentist analysis was based on a profile likelihood function, whereas the

15

Bayesian inference was based on an integrated likelihood function in which the nuisance parameter Î± was integrated out with respect to the prior distribution. We will now construct
a frequentist confidence interval for Î¸ based on the integrated objective function obtained
with a prior (or weight function) Î± âˆ¼ U[0, Î»]:
Z
ln,int (Î¸) = ln
exp[ln (G(Î¸, Î±))]dÎ±.
Î±âˆˆAÎ¸

If f (u) = Ï†N (u) then ln,int (Î¸) = ln pÌ‚(i) (Î¸|Y n ) defined in (15). Now consider the distribution
of exp[ln,int (Î¸)] near the boundaries of the identified set Î˜(Ï†) = [Ï†, Ï† + Î»]. If Î» > 0 and the
sample size is sufficiently large, then
ï£±


âˆš
ï£´

 ï£´
(Î»t)
âˆ’
n(Î¸
âˆ’
Ï†
)
ï£² Î¦N Î¦âˆ’1
0
N


P ln,int (Î¸) â‰¤ ln t â‰ˆ
âˆš
ï£´
âˆ’1
ï£´
ï£³ Î¦N Î¦N (Î»t) âˆ’ n(Î¸ âˆ’ (Ï†0 + Î»))

for small |Î¸ âˆ’ Ï†0 |
.
for small |Î¸ âˆ’ (Ï†0 + Î»)|

Thus, we obtain the following approximation for level sets:
 


âˆš
âˆš
Î¸
CSF,Ï„ = Î¸ ln,int (Î¸) â‰¤ ln(Ï„ /Î») = Ï†Ì‚n âˆ’ zÏ„ / n , Ï†Ì‚n + Î» + zÏ„ / n ,

(21)

where zÏ„ = Î¦âˆ’1
N (1 âˆ’ Ï„ ). From a comparison of (20) and (21) we deduce that the frequentist
intervals constructed from the profile and the integrated likelihood function are approximately the same. In particular, the interval obtained from the profile likelihood function
also has the property that it extends beyond Î˜(Ï†Ì‚n ). Thus, it is not the absence of a distribution over the identified set Î˜(Ï†), but rather the requirement that the 1 âˆ’ Ï„ coverage
probability is guaranteed for all Î¸ âˆˆ Î˜(Ï†) that leads to frequentist set to be larger than the
Bayesian set.
Example 2: Unknown Length of Identified Set. We previously assumed that the
length of the identified set is known and made a distinction between identified intervals
of length zero and length greater than zero. Now suppose that the length itself depends
on an unknown but estimable reduced form parameter Ï†2 â‰¥ 0: Î¸ âˆ’ Ï†2 â‰¤ Ï†1 â‰¤ Î¸ and
Î˜(Ï†) = [Ï†1 , Ï†1 + Ï†2 ]. This modified version of the inequality moment example is a stylized
representation of the treatment effect model studied by Imbens and Manski (2004). The
problem has been recently analyzed from a frequentist perspective in Stoye (2007). Let
Ï† = [Ï†1 , Ï†2 ] and assume that the prior distribution for Î¸ given Ï† is uniform on Î˜(Ï†).
We previously derived the approximation of the posterior distribution under the assumption that the â€œtrueâ€ reduced form parameter lies in the interior of the domain Î¦. This
(1)

assumption guaranteed that Ï†Ì‚n is also in the interior and the score ZÌ‚n = ln (Ï†Ì‚n ) = 0 eventually. To accommodate reduced form parameters on the boundary of Î¦, that is Ï†2 = 0 in

16

this example, the approximation in Theorem 1 can be modified as follows:
Z


H Ï†Ì‚n + JË†nâˆ’1/2 s, Î¾ dPYs n

(22)

1/2
JË†n (Î¦âˆ’Ï†Ì‚n )

Z
âˆ’
1/2
JË†n (Î¦âˆ’Ï†Ì‚n )



H Ï†Ì‚n + JË†nâˆ’1/2 s, Î¾ R

âˆ’1/2

Ï†N (s âˆ’ JË†n

ZÌ‚n )
ds = op (nâˆ’1/2 ).
âˆ’1/2
Ë†
Ï†
(s
âˆ’
J
ZÌ‚
)ds
1/2
n
n
JË† (Î¦âˆ’Ï†Ì‚n ) N
n

If the score ZÌ‚n is non-zero and the Hessian âˆ’JË†n is negative definite, the normal approxiâˆ’1/2
mation of s has to be centered at JË†n ZÌ‚n instead of zero. Moreover, the distribution of
âˆ’1/2
s is restricted to the set JË†n (Î¦ âˆ’ Ï†Ì‚n ), which guarantees that the resulting posterior of Ï†

has support on the domain Î¦. The above approximation requires an additional assumption
âˆ’1/2
that guarantees that JË†n ZÌ‚n is stochastically bounded.4 Due to the behavior of the score

ZÌ‚n , the bound is only valid with probability approaching one, rather than almost surely. If
we let H(Ï†, Î¾) = PÏ†Î¸ {Î¸ â‰¤ Î¾}, which is given by
ï£±
ï£² H (Ï†, Î¾) if Ï† = 0
0
2
H(Ï†, Î¾) =
,
ï£³ H (Ï†, Î¾) if Ï† > 0
+
2
where
ï£±
ï£² 0 if Î¾ < Ï†
1
H0 (Ï†, Î¾) =
,
ï£³ 1 if Ï† â‰¤ Î¾
1

H+ (Ï†, Î¾) =

ï£±
ï£´
ï£´
0
ï£´
ï£²

if Î¾ < Ï†1

Ï†1 âˆ’Î¾
Ï†2

ï£´
ï£´
ï£´
ï£³ 1

Ï†1 â‰¤ Î¾ â‰¤ Ï†1 + Ï†2 ,
otherwise

then (22) provides a large sample approximation to the posterior of Î¸ that is valid regardless
of whether the identified set has zero or non-zero length.
Example 3: Singleton Î¦(Î¸). In some models the set of structural parameters uniquely
determines the reduced form parameters, that is Î¦(Î¸) is a singleton, while Î˜(Ï†) is set-valued.
An example of such a model is a structural vector autoregression, in which Ï† corresponds
to the regression coefficients and the non-redundant elements of the variance-covariance
matrix of the one-step-ahead forecast errors. The vector Î¸ corresponds to a collection of
structural impulse response functions. These impulse responses depend in addition to Ï† on
a non-identifiable orthonormal matrix that rotates orthogonalized one-step-ahead forecast
errors into a vector of structural shocks.
Consider the following modification of Example 1: Î¸ = [Î¸1 , Î¸2 ]0 , Î¸1 âˆ’ Î» â‰¤ Ï† â‰¤ Î¸1 , and
Î¸2 = Î¸1 âˆ’ Ï†. Notice that the slackness parameter Î± that arose in Example 1 is now called
4 Classical

âˆ’1/2

analysis is typically based on the assumption that Jn,0 Zn,0 = Op (1). Thus, stochastic
âˆ’1/2

equicontinuity of the standardized score process Jn
Op (1).

(1)
âˆ’1/2
ZÌ‚n =
(Ï†)ln (Ï†) would suffice to ensure that JË†n

17

Î¸2 and part of the structural parameter vector Î¸. Î˜(Ï†) is located in a one-dimensional
subspace of Î˜ and remains set-valued, while Î¦(Î¸) = Î¸1 âˆ’ Î¸2 is a singleton. The projections
of the identified set Î˜(Ï†) on the domains of Î¸1 and Î¸2 are given by Î˜1 (Ï†) = [Ï†, Ï† + Î»] and
Î˜2 (Ï†) = [0, Î»] We maintain that conditional on Ï† the prior for Î¸1 is U[Ï†, Ï† + Î»], which
implies the prior on Î˜2 (Ï†) is also uniform.
Using the same arguments as for Example 1, replacing Î± by Î¸2 , one can deduce that
the set
Î¸1
CSB,Ï„
= [Ï†Ì‚n + Ï„ Î»/2, Ï†Ì‚n + Î» âˆ’ Ï„ Î»/2]
Î¸2
is an asymptotically valid 1 âˆ’ Ï„ credible set for Î¸1 . Similarly, CSB,Ï„
= [Ï„ Î»/2, Î» âˆ’ Ï„ Î»/2] is

a 1 âˆ’ Ï„ credible set for Î¸2 . Likewise, the set characterized in (20) is a valid 1 âˆ’ Ï„ frequentist
confidence set for Î¸1 . Thus, the lessons learned from Example 1 still apply to inference
about the Î¸1 element of the Î¸ vector.
More interestingly, we will now consider inference for the vector Î¸. Consider the following subsets of Î˜:


âˆš
âˆš
TÎ¾,n = Î¸1 , Î¸2 Ï†Ì‚n âˆ’ Î¾1 / n â‰¤ Î¸1 âˆ’ Î¸2 â‰¤ Ï†Ì‚n + Î¾1 / n, Î»Î¾2 /2 â‰¤ Î¸2 â‰¤ Î»(1 âˆ’ Î¾2 )

(23)

and define
ï£±
ï£² 1âˆ’Î¾
2
Hn (Ï†, Î¾) = PÏ†Î¸ {Î¸ âˆˆ TÎ¾,n } =
ï£³ 0

âˆš
âˆš
if Ï†Ì‚n âˆ’ Î¾1 / n â‰¤ Ï† â‰¤ Ï†Ì‚n + Î¾1 / n
otherwise

Since the sequence of functions Hn (Ï†, Î¾) does not satisfy the Lipschitz condition in Assumption 4 we use the following approximation
PÌ‚YÎ¸ n (i) {Î¸

Z
âˆˆ TÎ¾,n } = (1 âˆ’ Î¾2 )

âˆš
Î¾1 / n

âˆš
âˆ’Î¾1 / n

Ï†N (s)ds = (1 âˆ’ Î¾2 )(1 âˆ’ 2Î¦N (Î¾1 )).

Thus, an asymptotically valid credible set can be obtained by choosing Î¾1 â‰¥ 0 and 0 â‰¤ Î¾2 â‰¤ 1
such that (1 âˆ’ Î¾2 )(1 âˆ’ 2Î¦N (Î¾1 )) = 1 âˆ’ Ï„ . It turns out that the volume of the 1 âˆ’ Ï„ credible
set is minimized by setting Î¾2 = 0 and Î¾1 = zÏ„ /2 . The set Î˜(Ï†Ì‚n ), which is obtained from
TÎ¾,n in (23) by setting Î¾1 = 0 and Î¾2 = 0, is not an asymptotically valid credible set â€“ it
is too small. However, since one can construct valid credible sets with Î¾2 > 0, it is not the
case that Î˜(Ï†Ì‚n ) is nested in every asymptotically valid credible set. In this example Î˜(Ï†Ì‚n )
happens to be nested in the 1 âˆ’ Ï„ credible set with the smallest volume among the TÎ¾,n sets.
Now consider the following construction of a frequentist confidence interval for Î¸. Since
Î¦(Î¸) is a singleton, we can express Ï† = G(Î¸), without having to introduce an Î±. Moreover,

18

the natural relationship between the domains Î¦ and Î˜ is: Î¦ = {Ï† | Ï† = G(Î¸), Î¸ âˆˆ Î˜}. Thus,
inf

inf

Ï†âˆˆÎ¦ Î¸âˆˆÎ˜(Ï†)

=
=
=

inf

n

PÏ†Y {2[ln (G(Î¸)) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„ }
inf

Î¸âˆˆÎ˜ Ï†âˆˆÎ¦(Î¸)

(24)

n

PÏ†Y {2[ln (G(Î¸)) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„ }

n

Y
inf PG(Î¸)
{2[ln (G(Î¸)) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„ }

Î¸âˆˆÎ˜

n

inf PÏ†Y {2[ln (Ï†) âˆ’ ln (Ï†Ì‚n )] â‰¥ âˆ’cÏ„ }

Ï†âˆˆÎ¦

Using the large sample approximation described in Section 2 one can obtain an asymptotically valid confidence set CS Ï† that takes the form of the level set (3). In our example:
âˆš
âˆš
CS Ï† = [Ï†Ì‚n âˆ’ zÏ„ /2 / n, Ï†Ì‚n + zÏ„ /2 / n].
Î¸
According to (24) the corresponding confidence set for Î¸ is given by CSF,Ï„
=

S

Ï†âˆˆCS Ï†

Î˜(Ï†).

This set equals TÎ¾ in (23) for Î¾1 = zÏ„ /2 and Î¾2 = 0. Thus, the frequentist confidence set is
identical to Bayesian credible set that has the smallest volume among the TÎ¾ sets.

5

A Numerical Example: Bayesian Analysis of a TwoPlayer Entry Game

At last, we consider an example that has received a lot of attention in the microeconometric
literature on partially identified models: a two-player entry game, see for instance Bresnahan
and Reiss (1991), Berry (1994), Tamer (2003), and Ciliberto and Tamer (2007). Rather
than directly working with the asymptotic approximation derived in Section 3.1, we will use
Markov-Chain Monte Carlo techniques to generate posterior draws of Î¸ for a small (n = 50)
and a large (n = 1, 000) sample. We will focus on a fairly simple version of the entry game
without firm-specific regressors. Depending on the entry decision of the second firm, Firm l
either does not enter market i, operates as monopolist, or operates as duopolist. Potential
monopoly (M) and duopoly (D) profits are given by
M
Ï€i,l
= x0i Î²l + i,l ,

D
Ï€i,l
= x0i Î²l âˆ’ Î³l + i,l ,

l = 1, 2 i = 1, . . . , n

(25)

The 0i,l s capture latent profit components that are known to the two firms but unobserved
by the econometrician and xi is a vector of observable market characteristics. We assume
that the outcome of the entry game in each market is a pure strategy Nash equilibrium.
It is straightforward to verify that the Nash equilibrium is unique, except if both firms are
profitable as monopolist but not as duopolist. In the latter case, the model is silent about

19

which firm actually enters the market. As a consequence, the model only delivers bounds
for the probability of observing a particular monopoly.
Suppose that i,l âˆ¼ iidN (0, 1) and let Î¸ = [Î²10 , Î³1 , Î²20 , Î³2 ]0 . Using (25) it is straightforward to calculate probabilities that firm l is profitable as monopolist (duopolist) in market
i. For xi = x we denote these probabilities by Âµl (Î¸, x) and Î´l (Î¸, x), respectively. Moreover,
we use
Ï†(x) = [Ï†00 (x), Ï†01 (x), Ï†10 (x), Ï†11 (x)]0
to denote the reduced form probabilities of observing no entry, entry of Firm 1, entry of
Firm 2, or entry of both firms in a market with characteristics x. We observe no entry if
neither firm is profitable as monopolist, we observe a duopoly if both firms are profitable
as duopolists. An upper bound on the probability that Firm 1 operates as monopolist is
given by the probability that Firm 1 is profitable as monopolist and Firm 2 is not profitable
as duopolist. The lower bound is given by the sum of the probability that Firm 1 is profitable as monopolist and Firm 2 is not profitable as monopolist and of the probability that
Firm 1 would be profitable as duopolist, but Firm 2 would only be profitable as monopolist.
Formally,
(1 âˆ’ Âµ1 (x))(1 âˆ’ Âµ2 (x))

Ï†00 (x)

=

Ï†11 (x)

= Î´1 (x)Î´2 (x)

(26)
(27)

Ï†10 (x) â‰¤ Âµ1 (x)(1 âˆ’ Î´2 (x))

(28)

Ï†10 (x) â‰¥ Âµ1 (x)(1 âˆ’ Âµ2 (x)) + Î´1 (x)(Âµ2 (x) âˆ’ Î´2 (x)).

(29)

It can be verified that the Nash equilibrium restriction for a Firm 2 monopoly does not add
any further restrictions on the reduced form probabilities.
In order to be able to uniquely determine the reduced form parameters as a function
of the probabilities Âµi and Î´i , we introduce for each x an auxiliary parameter Î±(x) âˆˆ [0, 1]
that captures the slackness in the inequality restrictions for Ï†10 (x):
Ï†10 (x) = Âµ1 (x)(1 âˆ’ Âµ2 (x)) + Î´1 (x)(Âµ2 (x) âˆ’ Î´2 (x)) + Î±(x)(Âµ1 (x) âˆ’ Î´1 (x))(Âµ2 (x) âˆ’ Î´2 (x)). (30)
The second term, which is pre-multiplied by Î±, can be interpreted as the probability that
both firms are profitable as monopolists but not as duopolists. Consequentially, the slackness can be viewed as the probability of a sunspot shock that selects Firm 1 if the Nash
equilibrium is not unique. Equations (26), (27), and (30) define the function G(Î¸, Î±).
For the large sample theory presented in Section 3 to be applicable to the entry game
we need to assume that the regressor x is discretized. The discretization ensures that the

20

reduced-form parameter vector Ï† is finite dimensional and is not uncommon in the empirical
literature. These regressors are assumed to take only finitely many values. In the subsequent
numerical illustration we only use an intercept as regressor.
We proceed in several steps: (i) we specify a data generating process by choosing â€œtrueâ€
values of Î¸ and Î±, which imply a â€œtrueâ€ Ï†. (ii) Instead of specifying a prior distributions P Ï†
and PÏ†Î¸ , we start from a prior on Î¸ and Î± and generate draws from the implied distributions
P Ï† and PÏ†Î¸ . (iii) Finally, will generate two samples of size n = 50 and n = 1, 000 and
compare the posterior distributions.
The parameterization of the data generating process is summarized in the second column
of Table 1. The probabilities of a a Firm 1 monopoly, and Firm 2 monopoly, and a duopoly
are 48%, 33%, and 12%, respectively. The third column of Table 1 specifies the prior
distributions. We use fairly diffuse Gaussian priors for the elements of the Î¸ vector. The
distributions of Î³1 and Î³2 are truncated at zero to ensure that duopoly profits are less
than monopoly profits. The auxiliary parameter Î± has support on the unit interval. We
consider three different priors, centered at 0.2 (low Î±), 0.5 (Benchmark), and 0.8 (high Î±),
respectively. By evaluating the function G(Î¸, Î±) at random draws from the prior distribution
of Î¸ and Î± we obtain draws from the prior distribution of Ï†. Means and standard deviation
are reported in the last four rows of Table 1 under the Benchmark prior for Î±.
According to our previous analysis the prior distribution of Î¸ given Ï† plays an important
role in Bayesian inference for partially identified models. We depict unconditional prior
densities as well as prior densities conditional on the â€œtrueâ€ value of Ï† in Figure 2. Except
for Î±, the unconditional prior densities are essentially invisible because they are very diffuse
compared to the conditional priors. While in a fully identified model the prior PÏ†Î¸ should be
a pointmass at the singleton Î¸(Ï†), the entry game model is partially identified and leads to
a non-degenerate PÏ†Î¸ . The prior distribution on Î± induces a prior distribution for the profit
function parameters given the reduced form entry probabilities. Figure 2 illustrates how PÏ†Î¸
shifts as one changes the prior for Î±. While the prior for Î± could in principle be correlated
with the prior for Î¸, for instance to reflect the belief that the firm with higher expected
monopoly profits is more likely to enter the market if the equilibrium is not unique, we will
treat Î± and Î¸ as independent.
We now generate samples of n = 50 and n = 1, 000 observations from the data generating
process and us a random-walk Metropolis Algorithm to generate draws from the posterior
of Î¸ and Î±. Using the relationship Ï† = G(Î¸, Î±) we convert the Î¸-Î± draws into Ï† draws.
Figure 3 indicates that after 50 observations there is still substantial uncertainty about

21

the reduced form parameters. Since we specified the prior distribution for Ï† implicitly
through a prior for Î¸ and Î±, changes in the prior for Î± can in principle affect the prior and
posterior of Ï†. However, according to Figure 3 this effect is negligible in our illustration.
Figure 4 depicts posterior densities for the profit function parameters Î² and Î´. While the
prior distribution of Î± and hence PÏ†Î¸ has some effect on the posterior, overall the posterior
distribution is dominated by the uncertainty about the reduced form parameter. Finally, the
two panels of Figure 5 show scatter plots of draws from the posterior distribution of Î²1 and
Î³1 . Moreover, we outline the projection of the identified set Î˜(Ï†Ì‚n ) onto the domain of Î²1
and Î³1 . Here Ï†Ì‚n is the posterior mean of the reduced form parameter vector Ï†. According to
our asymptotic theory, the posterior distribution concentrates near Î˜(Ï†Ì‚n ), which is evident
from the posterior draws obtained with n = 1, 000.

6

Conclusion

We derived a large sample approximation for the posterior distribution of a structural parameter vector in a partially identified model to compare Bayesian credible sets and frequentist
confidence sets. Unlike in regular models, Bayesian and frequentist set estimates differ not
just with respect to their philosophical underpinnings. Frequentist confidence intervals have
to extend beyond the boundaries of the identified set (conditional on the estimated reduced
form parameter), whereas Bayesian credible sets can be be located in the interior of the
identified set asymptotically. The main challenge to frequentist inference is to establish the
uniform validity of the set estimate. The main challenge to Bayesian inference is to control
the shape of the prior distribution on the identified set conditional on the reduced form
parameter to avoid highly informative priors on the identified set induced by nonlinearities
of parameter transformations and to document the sensitivity of posterior inference to the
choice of prior even in large samples.

22

Appendix
The proof of Theorem 1 will closely follow the arguments in Johnson (1970). We rewrite
the posterior density of Ï† as
q Ï† (Ï†|Y n )

=

ï£±
ï£²

p(Ï†) exp[ln (Ï†)]
p(Ï†Ì‚n ) exp[ln (Ï†Ì‚n )]

ï£³ 0

otherwise
Ï†

pÏ† (Ï†|Y n )
âˆ’1/2

Define Î£Ì‚n = n1/2 JË†n

=

R

if Ï† âˆˆ Î¦

n

q (Ï†|Y )
.
q Ï† (Ï†|Y n )dÏ†
RK

z
n
Ï†
and z = Î£Ì‚âˆ’1
n (Ï† âˆ’ Ï†Ì‚n ) âˆˆ Î¦z . Moreover, let q (z|Y ) = q (Ï†Ì‚n + Î£Ì‚n z).

Then the posterior density of z can be expressed as
pz (z|Y n ) = R

q z (z|Y n )
.
q z (z|Y n )dz
RK

Let â„¦0 and â„¦1 denote the sure sets for which Assumptions 1 and 2 hold, respectively. We
begin by introducing several Lemmas that are useful for the proof of the theorem.
Lemma 1 Suppose that Assumptions 1 â€“ 2 hold. Fix a constant Îº1 with 0 < Îº1 < 1.
Then, one can choose a constant Î´1 > 0 and, for each Ï‰ âˆˆ â„¦1 a constant N1Ï‰ such that
the following statements hold: (a) If n â‰¥ N1Ï‰ and kÏ† âˆ’ Ï†0 k â‰¤ Î´1 , then there exists finite
constants Mmin and Mmax such that
0 < Mmin â‰¤ Î»min (nâˆ’1 Jn (Ï†)) â‰¤ Î»max (nâˆ’1 Jn (Ï†)) â‰¤ Mmax < âˆ.
(b) If n â‰¥ N1Ï‰ , then
0 < Mmin â‰¤ Î»min (nâˆ’1 JË†n ) â‰¤ Î»max (nâˆ’1 JË†n ) â‰¤ Mmax < âˆ
and (c)
âˆ’1
âˆ’1
0 < Mmax
â‰¤ Î»min (nâˆ’1 JË†n ) â‰¤ Î»max (nâˆ’1 JË†n ) â‰¤ Mmin
< âˆ.

Lemma 2 (Lemma 2.2 in Johnson) Suppose that Assumptions 1 â€“ 2 hold. Then, we
can choose a constant Î´2 (0 < Î´2 < 1), a constant Îº2 < 21 , and, for each Ï‰ âˆˆ â„¦1 , a constant
N2Ï‰ (â‰¥ N1Ï‰ ) such that if n â‰¥ N2Ï‰ and kzk â‰¤ Î´2 , then
 1  
1 
2
ln Ï†Ì‚n + Î£Ì‚n z âˆ’ ln Ï†Ì‚n â‰¤ âˆ’Îº2 kzk .
n
n
Lemma 3 (Lemma 2.3 in Johnson) Suppose that Assumptions 1 â€“ 2 hold. Suppose that
Î´ > 0 is given. Then, we can choose a constant Îº3 > 0 and, for each Ï‰ âˆˆ â„¦1 , a constant
N3Ï‰ (â‰¥ N2Ï‰ ) such that whenever n â‰¥ N3Ï‰ and kzk â‰¥ Î´, we have
 1  
1 
ln Ï†Ì‚n + Î£Ì‚n z âˆ’ ln Ï†Ì‚n â‰¤ âˆ’Îº3 .
n
n

23

Now define (our definition differs from Johnsonâ€™s)
p1 (Ï† âˆ’ Ï†Ì‚n ; Ï†Ì‚n ) = 1 +

p(1) (Ï†Ì‚n )0
p(Ï†Ì‚n )

(Ï† âˆ’ Ï†Ì‚n ).

Since Ï†Ì‚n â†’ Ï†0 a.s. and p(Ï†0 ) > 0, p(Ï†Ì‚n ) > 0 near Ï†0 .
Lemma 4 (Lemma 2.4 in Johnson) Suppose that Assumptions 1 â€“ 3 hold. Then, there
exists a constant Î´4 ,a constant M, and, for each Ï‰ âˆˆ â„¦0 , a constant N4Ï‰ (> N3Ï‰ ) such that
if n â‰¥ N4Ï‰ , then
Z

z



n

q (z|Y ) âˆ’ p1 Î£Ì‚n z; Ï†Ì‚n



kzkâ‰¤Î´4



1
exp âˆ’ nz 0 z
2


dz â‰¤

M
.
n

Lemma 5 Suppose Assumptions 1 â€“ 3 are satisfied. Let Y n be in the sure set of Assumptions 1 and 2. Then, there exist a finite constant M and a finite constant N such that
whenever n â‰¥ N we have
Z
RK




M
1 0
z
n
.
q (z|Y ) âˆ’ exp âˆ’ nz z dz â‰¤
2
n

Proof of Lemma 5 For a given Ï‰ âˆˆ â„¦0 , choose NÏ‰ â‰¥ N4Ï‰ in Lemma 4 such that when
n â‰¥ N4Ï‰ , the statements of Lemmas 1, 2, 3, and 4 hold, and for the Î´p in Assumption 3,
kÏ†Ì‚n âˆ’ Ï†0 k â‰¤ Î´p by Lemma 1 in Wu (1981). We bound


Z
1
q z (z|Y n ) âˆ’ exp âˆ’ nz 0 z dz
2
RK


Z


1
q z (z|Y n ) âˆ’ p1 Î£Ì‚n z; Ï†Ì‚n exp âˆ’ nz 0 z dz
â‰¤
2
RK


Z


1 0
+
1 âˆ’ p1 Î£Ì‚n z; Ï†Ì‚n exp âˆ’ nz z dz
2
RK
= I + II
Term I can be bounded by
Z
III + IV + IV =


1 0
q (z|Xn ) âˆ’ p1 Î£Ì‚n z; Ï†Ì‚n exp âˆ’ nz z dz
2
kzkâ‰¤Î´4


Z
Z


1
+
q z (z|Y n ) dz +
p1 Î£Ì‚n z; Ï†Ì‚n exp âˆ’ nz 0 z dz,
2
kzk>Î´4
kzk>Î´4
z







where Î´4 is defined in Lemma 4. The O(nâˆ’1 ) bound for III follows directly from Lemma
4. Now consider term IV :
Z
IV =

p(Ï†Ì‚n + Î£Ì‚n z)

p(Ï†Ì‚n )
M
â‰¤ M exp(âˆ’Îº3 n) â‰¤
.
n
kzk>Î´4



exp ln (Ï†Ì‚n + Î£Ì‚n z) âˆ’ ln (Ï†Ì‚n ) dz

24

The bound follows from Assumption 3 and Lemma 3. Finally, to obtain a bound for term
V , by Assumption 3 with kÏ†Ì‚n âˆ’ Ï†0 k â‰¤ Î´p and by Lemma 1(c), we can choose M such that
p1 (Î£Ì‚n z; Ï†Ì‚n ) â‰¤ 1 +

p(1) (Ï†Ì‚n )
p(Ï†Ì‚n )

Î£Ì‚n z â‰¤ 1 + M kzk .

Then,




Z
1
M
1
2
2
exp âˆ’ n kzk dz + M
.
kzk exp âˆ’ n kzk dz â‰¤
2
2
n
kzk>Î´4
kzk>Î´4

Z
V â‰¤

Combining the bounds for terms III, IV , and V, we have
M
.
n


For the term II, from the definition p1 Î£Ì‚n z; Ï†Ì‚n and (6) and by change of variable v =
âˆš
n kzk, we have




Z
Z
M âˆ
1
M
1 2 K
2
II â‰¤ M
kzk exp âˆ’ n kzk dz â‰¤
,
exp âˆ’ v v dv â‰¤
2
n
2
n
RK
0
Iâ‰¤

as required for the lemma. 
Proof of Theorem 1(i): For s =

âˆš

nz âˆˆ Î¦s the posterior is ps (s|Y n ) =

âˆš

âˆš
npz ( nz|Y n ).

âˆ’1/2
We now abbreviate H(Ï†Ì‚n + JË†n s, Î¾) = H(s, Î¾). Then,
Z
Z
Z
s
H(s, Î¾)dPY n âˆ’
H(s, Î¾)dÎ¦N (s) =
H(n1/2 z, Î¾)[pz (z|Y n ) âˆ’ n1/2 Ï†N (n1/2 z)]dz.
Î¦s

RK

RK

To prove the theorem it suffices to show that
r
Z
M
2Ï€
H(n1/2 z, Î¾)[pz (z|Y n ) âˆ’ n1/2 Ï†N (n1/2 z)]dz â‰¤
.
n RK
n
Consider the following bound
r
Z



2Ï€
H(n1/2 z, Î¾) pz (z|Y n ) âˆ’ n1/2 Ï†N n1/2 z dz
n RK
p

!
Z
2Ï€/n q z (z|Y n )
1 0
1/2
=
H(n z, Î¾) R
âˆ’ exp âˆ’ nz z
dz
2
q z (z|Y n ) dz
RK
RK
!
p
Z
2Ï€/n
â‰¤
H(n1/2 z, Î¾)q z (z|Y n ) 1 âˆ’ R
dz
q z (z|Y n ) dz
RK
RK



Z
1
dz
+
H(n1/2 z, Î¾) q z (z|Y n ) âˆ’ exp âˆ’ nz 0 z
2
RK
= I + II, say.

25
Since |H(n1/2 z, Î¾)| < MH , the first term can be bounded by
Z
I

r
z

n

q (z|Y ) dz âˆ’

â‰¤ MH
RK

Z
= MH
RK

Z
â‰¤ MH
RK

â‰¤

2Ï€
n



1 0
q (z|Y ) dz âˆ’
exp âˆ’ nz z dz
2
RK


1
q z (z|Y n ) âˆ’ exp âˆ’ nz 0 z dz
2
z

n

Z

M
.
n

The third inequality follows from Lemma 5. The bound for term II can be obtained in a
similar manner. 
Proof of Corollary 1(ii): Consider the following bound:
PYÎ¸ n {Î¸ âˆˆ TÎ¾,n } âˆ’ Hn (Ï†Ì‚n , Î¾)
Z
Î¸
Hn (Ï†Ì‚n + JË†nâˆ’1/2 s, Î¾)Ï†N (s)ds
â‰¤ PY n {Î¸ âˆˆ TÎ¾,n } âˆ’
RK
Z h
i
Hn (Ï†Ì‚n + JË†nâˆ’1/2 s, Î¾) âˆ’ Hn (Ï†Ì‚n , Î¾) Ï†N (s)ds
+
RK

= I + II, say.
Theorem 1 provides a bound for I. Using the Lipschitz assumption we deduce
Z
Z
M (Î¾)
âˆ’1/2
âˆ—
âˆ’1/2
âˆ—
Ë†
kÎ£Ì‚n kkskÏ†N (s)ds â‰¤ âˆš .
M (Î¾)
kJn skÏ†N (s)ds â‰¤ n
II â‰¤ M (Î¾)
n
RK
RK
The last inequality is a consequence of Lemma 1. 

References
Andrews, Donald, Steven Berry, and Panle Jia (2004): â€œConfidence Regions for Parameters
in Discrete Games with Multiple Equilibria, with an Application to Discount Chain
Store Location,â€ Manuscript, Department of Economics, Yale University.
Andrews, Donald and Patrik Guggenberger (2007): â€œValidity of Subsampling and â€˜Plug-in
Asymptoticsâ€™ Inference for Parameters Defined by Moment Inequalities,â€Manuscript,
Department of Economics, Yale University.
Andrews, Donald and Gustavo Soares (2007): â€œInference for Parameters Defined by Moment Inequalities Using Generalized Moment Selection,â€Manuscript, Department of
Economics, Yale University.

26

Bajari, Patrick, Lanier Benkard, and Jonathan Levin (2007): â€œEstimating Dynamic Models
of Imperfect Competition,â€Econometrica, 75, 1331-1370.
Beresteanu, Arie and Francesca Molinari (2008): â€œAsymptotic Properties for a Class of
Partially Identified Models,â€Econometrica, 76, 763-814.
Bernstein, S.N. (1934): Theory of Probability, Gostekhizdat, Moscow.
Berry, Steven (1994): â€œEstimating Discrete Choice Models of Product Differentiation,â€RAND
Journal of Economics, 25, 242-262.
Bresnahan, Timothy and Peter Reiss (1991): â€œEmpirical Models of Discrete Games,â€ Journal of Econometrics, 48, 57-81.
Canay, Ivan A. (2007): â€œEL Inference for Partially Identified Models: Large Deviation
Optimality and Bootstrap Validity,â€Manuscript, Department of Economics, University
of Wisconsin.
Canova, Fabio and Gianni De Nicolo (2002): â€œMonetary Disturbances Matter for Business
Cycle Fluctuations in the G-7,â€Journal of Monetary Economics, 49, 1131-59.
Chernozhukov, Victor, Han Hong, and Elie Tamer (2007): â€œEstimation and Confidence
Regions for Parameter Sets in Econometric Models,â€Econometrica, 75, 1243-1284.
Ciliberto, Federico and Elie Tamer (2007): â€œMarket Structure and Multiple Equilibria in
Airline Markets,â€Manuscript, Department of Economics, University of Virginia and
Northwestern University.
Galichon, Alfred and Marc Henry (2006): â€œInference in Incomplete Models,â€Manuscript,
Columbia University.
Halie, Phil and Elie Tamer (2003): â€œInference with an Incomplete Model of English Auctions,â€Journal of Political Economy , 111, 1-51.
Imbens, Guido and Charles Manski (2004): â€œConfidence Intervals for Partially Identified
Parameters,â€ Econometrica, 72, 1845-57.
Johnson, Richard, (1970): â€œAsymptotic Expansions of Associated with Posterior Distributions,â€Annals of Mathematical Statistics, 41, 851-864.
Kadane, Joseph B. (1974): â€œThe Role of Identification in Bayesian Theory,â€ in S.E. Fienberg and A. Zellner (eds.) Studies in Bayesian Econometrics and Statistics, 175-191.
North Holland, Amsterdam.

27

Kim, Jae-Young (1998): â€œLarge Sample Properties of Posterior Densities, Bayesian Information Criterion and the Likelihood Principle in Nonstationary Time Series Models,â€Econometrica, 66, 359-380.
LeCam, Lucien (1953): â€œOn Some Asymptotic Properties of Maximum Likelihood Estimates and Related Bayes Estimates,â€ University of California Publications in Statistics, 1, 277-330.
Lubik, Thomas and Frank Schorfheide (2004): â€œTesting for Indeterminacy: An Application
to U.S. Monetary Policy,â€ American Economic Review, 94, 190-217.
Manski, Charles (2003): Partial Identification of Probability Distributions, New York,
Springer Verlag.
Manski, Charles and Elie Tamer (2002): â€œInference on Regressions with Interval Data on
a Regressor or Outcome,â€Econometrica, 70, 519-547.
Pakes, Ariel, Jack Porter, Kate Ho and Joy Ishi (2005): â€œMoment Inequalities and Their
Application,â€ Manuscript, Department of Economics, Harvard University.
Phillips, Peter C.B. and Werner Ploberger (1996): â€œAn Asymptotic Theory of Bayesian
Inference for Time Series,â€Econometrica 64, 381-412.
Poirier, Dale (1998): â€œRevising Beliefs in Nonidentified Models,â€ Econometric Theory, 14,
483-509.
Romano, Joseph P. and Azeem M. Shaikh (2006): â€œInference for Partially Identified Econometric Models,â€ Manuscript, Stanford University.
Rosen, Adam (2005): â€œConfidence Sets for Partially Identified Parameters that Satisfy
a Finite Number of Moment Inequalities,â€ Manuscript, Department of Economics,
University College London.
Severini, Thomas (1991): â€œOn the Relationship between Bayesian and Non-Bayesian Interval Estimates,â€Journal of the Royal Statistical Society. Series B, 53 611-618.
Sims, Chris and Harald Uhlig (1991): â€œUnderstanding Unit Rooters: A Helicopter Tour,â€Econometrica,
59, 1591-1599.
Stoye, JoÌˆrg (2007): â€œMore on Confidence Intervals for Partially Identified Parameters,â€
Manuscript, Department of Economics, New York University.

28

Uhlig, Harald (2005): â€œWhat Are the Effects of Monetary Policy on Output? Results from
an Agnostic Identification Procedure,â€ Journal of Monetary Economics, 52, 381-419.
von Mises, Richard (1965): Mathematical Theory of Probability and Statistics, Academic
Press, New York.
Wu, Chien-Fu, (1981): â€œAsymptotic Theory of Nonlinear Least Squares Estimation,â€ Annals of Statistics, 9, 501-513.

29

Figure 1: Inference in the Inequality Condition Model, Known Length

Notes: The figures are drawn for Ï†Ì‚n = 0 and overlay n = 5 and n = 500. The top panel
depicts posterior densities p(Î¸|Y n ) and 90% credible intervals. The bottom panel depicts
the standardized frequentist objective function
and 90% frequentist confidence intervals.

1
n Qn (Î¸),

the cut-off value cÏ„ /n for Ï„ = 0.1,

30

Table 1: Entry Game: â€œTrueâ€ Parameters and Prior
Parameter

True Value

Prior Distribution

Structural Parameters Î¸
Î²1

0.7

N (0, 42 )

Î³1

1.0

N+ (0, 42 )

Î²2

0.5

N (0, 42 )

Î³2

1.0

N+ (0, 42 )

Auxiliary Parameter Î±
Î±

0.7

Benchmark: B(0.5, 0.22 )

0.7

Low Î±: B(0.2, 0.12 )

0.7

High Î±: B(0.8, 0.12 )

Implied Reduced Form Parameters Ï†
Ï†00

0.07

Âµ00 = 0.25, Ïƒ00 = 0.37

Ï†10

0.48

Âµ10 = 0.31, Ïƒ10 = 0.40

Ï†01

0.33

Âµ01 = 0.31, Ïƒ01 = 0.40

Ï†11

0.12

Âµ11 = 0.13, Ïƒ11 = 0.28

Notes: for the prior distribution of the reduced form parameters we report means Âµ and
standard deviations Ïƒ under Î± âˆ¼ B(0.5, 0.22 ). N (Î½, Ïƒ 2 ) and B(Âµ, Ïƒ 2 ) refer to Normal and
Beta distributions with mean Âµ and variance Ïƒ 2 .

31

Figure 2: Conditional Distribution of Î¸ Given Ï†

Notes: Benchmark Prior (solid, green), Low Î± Prior (long dashes, red), High Î± Prior (short
dashes, blue). Each panel depicts 3 unconditional prior densities and 3 densities conditional
on the â€œtrueâ€ Ï†. Except for Î± the unconditional prior densities appear invisible because
they are very diffuse compared to the conditional densities.

32

Figure 3: Posterior Distribution of Ï†, n = 50

Notes: Benchmark Prior (solid, green), Low Î± Prior (long dashes, red), High Î± Prior (short
dashes, blue). Since the posterior of Ï† is insensitive to the prior on Î± the three densities
appear on top of each other.

33

Figure 4: Posterior Distribution of Î¸, n = 50

Notes: Benchmark Prior (solid, green), Low Î± Prior (long dashes, red), High Î± Prior (short
dashes, blue).

34

Figure 5: Posterior Distribution of Î²1 and Î³1

Notes: The panels depict draws from the posterior distribution and an outline of the projection of Î˜(Ï†Ì‚n ) onto the Î²1 -Î³1 space.

