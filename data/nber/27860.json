{
    "id": 27860,
    "citation_title": "Behavioral Biases are Temporally Stable",
    "citation_author": [
        "Victor Stango",
        "Jonathan Zinman"
    ],
    "citation_publication_date": "2020-09-28",
    "issue_date": "2020-09-24",
    "revision_date": "None",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Estimation Methods",
        "\n",
        "Data Collection",
        "\n",
        "Microeconomics",
        "\n",
        "Behavioral Economics",
        "\n",
        "Macroeconomics",
        "\n"
    ],
    "program": [
        "\n",
        "Economics of Aging",
        "\n",
        "Asset Pricing",
        "\n",
        "Development Economics",
        "\n",
        "Environment and Energy Economics",
        "\n",
        "Economics of Health",
        "\n",
        "Industrial Organization",
        "\n",
        "Law and Economics",
        "\n",
        "Labor Studies",
        "\n",
        "Public Economics",
        "\n"
    ],
    "projects": null,
    "working_groups": [
        "\n",
        "Behavioral Finance",
        "\n",
        "Household Finance",
        "\n"
    ],
    "abstract": "\n\nSocial scientists often consider temporal stability when assessing the usefulness of a construct and its measures, but whether behavioral biases display such stability is relatively unknown. We estimate stability for 25 biases, in a nationally representative sample, using repeated elicitations three years apart. Bias level indicators are largely stable in the aggregate and within-person. Within-person intertemporal rank correlations imply moderate stability and increase dramatically when using other biases as instrumental variables. Additional results reinforce three key inferences: biases are stable, accounting for classical measurement error in bias elicitation data is important, and eliciting multiple measures of multiple biases is valuable.\n\n",
    "acknowledgement": "\nThanks to Hannah Trachtman and Sucitro Dwijayana Sidharta for outstanding research assistance; the Sloan/Sage Working Group on Behavioral Economics and Consumer Finance, the Roybal Center (grant # 3P30AG024962), the National University of Singapore, the Michigan Retirement Research Center, and the Pension Research Council/TIAA for funding and patience; Shachar Kariv and Dan Silverman for helping us implement their (with Choi and Muller) interface for measuring choice consistency; Charlie Sprenger for help with choosing the certainty premium elicitation tasks and with adapting the convex time budget tasks; Georg Weizsacker for help in adapting one of the questions we use to measure narrow bracketing; Julian Jamison for advice on measuring ambiguity aversion; Doug Staiger and Josh Schwartzstein for many conversations; and Erik Snowberg for helpful discussions re: measurement error. Special thanks to Joanne Yoong for collaboration on the Round 1 survey design and implementation. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}