                             NBER WORKING PAPER SERIES




                            JUDGING JUDGE FIXED EFFECTS

                                     Brigham R. Frandsen
                                        Lars J. Lefgren
                                       Emily C. Leslie

                                     Working Paper 25528
                             http://www.nber.org/papers/w25528


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   February 2019




We thank Jeffrey Denning, Kirill Evdokimov, Giovanni Mellace, and seminar participants at
Brigham Young University, MIT, and Dartmouth University for helpful feedback. We thank
Crystal Yang for help with gaining access to data from Miami-Dade County. We thank the
College of Family, Home, and Social Science of Brigham Young University for generous
financial support. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

¬© 2019 by Brigham R. Frandsen, Lars J. Lefgren, and Emily C. Leslie. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including ¬© notice, is given to the source.
Judging Judge Fixed Effects
Brigham R. Frandsen, Lars J. Lefgren, and Emily C. Leslie
NBER Working Paper No. 25528
February 2019
JEL No. C26,K14

                                           ABSTRACT

We propose a test for the identifying assumptions invoked in designs based on random
assignment to one of many "judges.'' We show that standard identifying assumptions imply that
the conditional expectation of the outcome given judge assignment is a continuous function with
bounded slope of the judge propensity to treat. The implication leads to a two-part test that
generalizes the Sargan-Hansen overidentification test and assesses whether implied treatment
effects across the range of judge propensities are possible given the domain of the outcome. We
show the asymptotic validity of the testing procedure, demonstrate its finite-sample performance
in simulations, and apply the test in an empirical setting examining the effects of pre-trial release
on defendant outcomes in Miami. When the assumptions are not satisfied, we propose a weaker
average monotonicity assumption under which IV still converges to a proper weighted average of
treatment effects.

Brigham R. Frandsen                               Emily C. Leslie
Department of Economics                           Department of Economics
Brigham Young University                          Brigham Young University
Provo, UT 84602                                   435 Crabtree Technology Building
frandsen@byu.edu                                  Provo, UT 84602
                                                  emily.c.leslie@gmail.com
Lars J. Lefgren
Department of Economics
Brigham Young University
130 Faculty Office Building
Provo, UT 84602
and NBER
lars_lefgren@byu.edu
                      Judging Judge Fixed Effects
        Brigham R. Frandsen‚àó              Lars J. Lefgren‚àó           Emily C. Leslie‚àó
                                    January 30, 2019


                                           Abstract
            We propose a test for the identifying assumptions invoked in designs based
        on random assignment to one of many ‚Äújudges.‚Äù We show that standard identi-
        fying assumptions imply that the conditional expectation of the outcome given
        judge assignment is a continuous function with bounded slope of the judge
        propensity to treat. The implication leads to a two-part test that generalizes
        the Sargan-Hansen overidentification test and assesses whether implied treat-
        ment effects across the range of judge propensities are possible given the do-
        main of the outcome. We show the asymptotic validity of the testing procedure,
        demonstrate its finite-sample performance in simulations, and apply the test
        in an empirical setting examining the effects of pre-trial release on defendant
        outcomes in Miami. When the assumptions are not satisfied, we propose a
        weaker average monotonicity assumption under which IV still converges to a
        proper weighted average of treatment effects.



1       Introduction

Examining the impact of incarceration length on subsequent labor market earnings,
Kling (2006) leveraged plausibly exogenous variation in sentence length arising from
the random assignment of offenders to judges. Specifically, he instrumented the of-
fender‚Äôs realized sentence with the average sentence of all other offenders who faced
the same judge. The paper pioneered a now widespread methodology, dubbed the
    ‚àó
    Department of Economics, Brigham Young University
We thank Jeffrey Denning, Kirill Evdokimov, Giovanni Mellace, and seminar participants at Brigham
Young University, MIT, and Dartmouth University for helpful feedback. We thank Crystal Yang for
help with gaining access to data from Miami-Dade County. We thank the College of Family, Home,
and Social Science of Brigham Young University for generous financial support.


                                               1
‚Äújudged fixed effects‚Äù design, in which the exogenous assignment to a judge, admin-
istrator, or other decision maker identifies the effects of some treatment on outcomes.
Recent examples employing this strategy include the effect of incarceration on eco-
nomic and family outcomes (Green and Winik, 2010; Loeffler, 2013; Aizer and Doyle,
2015; Mueller-Smith, 2015; Bhuller et al., 2016; Eren and Mocan, 2017; Arteaga, 2018;
Norris et al., 2018; Bhuller et al., 2018; Dobbie et al., 2018b), the effect of pretrial
detention on a variety of legal and economic outcomes (Gupta et al., 2016; Leslie
and Pope, 2017; Dobbie et al., 2018a), the effect of consumer bankruptcy on house-
hold financial well-being (Dobbie and Song, 2015; Dobbie et al., 2017), the effect of
bankruptcy on firm outcomes (Chang and Schoar, 2013), the effect of foster care on
child outcomes (Doyle, 2007, 2008), the effect of disability on labor supply, mortal-
ity, and intergenerational welfare use (Maestas et al., 2013; Dahl et al., 2014; Autor
et al., 2017; Black et al., 2018), and the effect of patents on innovation (Galasso and
Schankerman, 2015; Sampat and Williams, 2015).
   The judge fixed effects design is an example of a more general estimation scenario
in which one or more instrumental variables are used to estimate the causal effects
of binary treatment variable. Examples include experiments making use of a vari-
ety of information nudges to influence program take-up or enrollment (Hastings and
Weinstein, 2008; Barghava and Manoli, 2015; Bergman et al., 2017) and randomized
controlled trials with multiple intervention arms all aimed an increasing participation
in a single treatment (Olken, 2007; McKenzie et al., 2008; Thornton, 2008).It is cru-
cial that the treatment variable of interest be binary, but the instrument(s) need not
be; a valid continuous instrument can be broken up into a series of binary indicators
and remain valid. While we refer to the judge fixed effects design as the leading
special case, this article applies to any design in this broader instrumental variables
treatment effecs framework.

                                           2
   The intuition and transparency of the judge fixed effects design notwithstanding,
identification relies on assumptions that may be controversial in some settings and at
the very least deserve scrutiny. The design‚Äôs popularity and the policy relevance of the
research questions it has been employed to answer further underscore the importance
of testing the identifying assumptions.
   In this paper we develop a test of the identifying assumptions underlying the
judge fixed effects design. Most commonly, researchers using this design adopt the
local average treatment effects (LATE) framework introduced by Imbens and Angrist
(1994), which allows for heterogeneous treatment effects. The key assumptions are
that individuals are randomly assigned to judges, an exclusion restriction whereby
judges exert no influence on outcomes other than through their decision whether to
‚Äútreat‚Äù an individual, and that judge assignment has a weakly monotonic effect on
each individual‚Äôs treatment status. In the context of Kling‚Äôs (2006) original study,
this latter monotonicity condition implies that if judge A is more likely to incarcerate
offenders than judge B, every individual incarcerated by judge B would also have
been incarcerated by judge A had judge A handled the case. A variation on the
LATE framework relaxes monotonicity slightly, provided the average treatment effect
among individuals who violate monotonicity is identical to the average treatment
effect among some subset of individuals who satisfy it (de Chaisemartin, 2017).
   Our test follows from the implication that outcomes averaged at the judge level will
be a continuous function with bounded slope of the judge-level treatment probability
(or ‚Äúpropensity‚Äù). The slope of the function at any given point corresponds with
the marginal treatment effect, so that bounds on the slope arise from bounds on
the support of the outcome variable. We develop a two-part test of this implication
that takes into account that judge propensity is estimated and demonstrate that
our test has substantial statistical power in empirically reasonable settings. One

                                           3
part of the test can be characterized as a generalization of the traditional Sargan-
Hansen overidentification test (Sargan, 1958; Hansen, 1982), which probes the stricter
condition that average outcomes given the instrument are a linear function of the
treatment propensity. The other part of the test assesses whether implied treatment
effects are possible given the support of the outcome. Our test remains feasible even
when additional covariates are not available, a situation that would preclude the use
of traditional balance tests of randomization and existing tests examining how judge
severity varies across subgroups.
   Our procedure jointly tests exclusion and monotonicity, and therefore a rejection
suggests one or both may fail. When a priori institutional considerations support the
plausibility of the exclusion restriction (implying that a rejection is evidence against
the monotonicity condition), we propose a weaker average monotonicity condition
under which the instrumental variables estimator converges to a proper weighted
average of individual treatment effects. If, instead, a priori information suggests the
exclusion restriction fails, researchers may consider falling back on the relaxation of
the exclusion restriction described in KolesaÃÅr et al. (2015) to interpret estimates as
consistent estimates of treatment effects.
   We apply our test in an examination of the effect of pretrial release on the prob-
ability of conviction. We do so using exogenous variation in judge assignment for
offenders in Miami-Dade county, a setting used in Dobbie et al. (2018a). We reject
the null hypothesis that the exclusion restriction and monotonicity assumption hold.
Interpreting the estimates as causal effects of pretrial detention therefore requires
alternative assumptions such as the weaker average monotonicity assumption we pro-
pose and/or the relaxation of the exclusion restriction described in KolesaÃÅr et al.
(2015).
   Our paper builds on previous work related to tests of instrument validity. As

                                             4
mentioned above, our test can be seen as a generalization of the traditional Sargan
(1958) overidentification test to a setting with heterogeneous effects. Angrist and
Imbens (1995) show that the monotonicity condition can be tested in a setting with a
treatment that takes on more than two values. Our test complements their result by
allowing testing with a binary treatment as well, an important case in practice. Kita-
gawa (2015), Huber and Mellace (2015), MourifieÃÅ and Wan (2017), and Norris et al.
(2018) also proposed tests for instrument validity in settings with a binary treatment
similar to ours. These tests require a priori knowledge of the instruments‚Äô order with
respect to the probability of treatment, knowledge not commonly available in em-
pirical settings. Applying such tests as if the instrument order were known can lead
to substantial overrejection, as we show in simulations below. Most common in the
literature are informal tests that examine the correlation of judge severity across ob-
servable subgroups (Bhuller et al., 2018; Dobbie et al., 2018a). This approach cannot
detect violations of the exclusion restriction, and is only a weak test of monotonicity;
strict monotonicity requires not only that subgroup-specific propensities across judges
be positively correlated with the overall propensity, but that they are monotonically
increasing with the each judge‚Äôs overall propensity. This approach does, however, test
an implication of the weaker average monotonicity assumption we propose for when
our test rejects, and thus complements our approach well.



2    Econometric Framework

Consider a binary treatment indicator, Di for individual i, such as pre-trial release or
placement in foster care, whose possible effects on outcome Yi are of interest. Denote
the potential outcome realized by individual i if untreated by Yi (0), and if treated
by Yi (1). Individual i‚Äôs treatment effect is therefore Œ¥i := Yi (1) ‚àí Yi (0). A class of


                                           5
parameters of interest consists of weighted averages of the treatment effect:

                                           E [wi Œ¥i ]
                                    Œ±w =              ,                              (1)
                                           E [wi ]

for nonnegative weights wi . Treatment status is influenced by the assignment to a
judge, denoted by Ji ‚àà {0, . . . , J}. An individual‚Äôs potential treatment status as a
function of the judge assignment is given by Di (j) ‚àà {0, 1}. Define each judge‚Äôs
propensity to assign treatment as p (j) := E [Di (j)]. Observed variables include the
judge assignment Ji , treatment status Di := Di (Ji ), and outcome Yi := Yi (Di ).
   Treatment effect parameters of the form (1) can be consistently estimated under
the local average treatment effects (LATE) assumptions (Imbens and Angrist, 1994).
This framework makes the following assumptions:


Condition 1 (LATE instrumental variables validity) For all j ‚àà {0, . . . , J},
the following hold jointly:


  a. Random assignment and exclusion: the triple (Yi (0) , Yi (1) , Di (j)) is jointly
      independent of Ji ;

  b. Nontrivial instrument: the propensity p (j) is a nontrivial function of j;

  c. Monotonicity: For all j, w ‚àà {0, . . . , J}, either Di (j) ‚â• Di (w) for all i, or
      Di (j) ‚â§ Di (w) for all i.


   Conditions 1a and 1b will be satisfied if judge assignment is random, and judges
vary in their influence on treatment status, but do not otherwise affect outcomes.
Given part a, the second part can be verified, since under the first part of the con-
dition p (j) = E [Di |Ji = j]. Part a, however, cannot be directly verified. Part c,
monotonicity, means that any individual who is treated when assigned to a particular

                                           6
judge would also be treated if assigned to a judge of equal or greater propensity. It
implies that individuals can be partitioned into a group that never receives treatment
regardless of judge assignment (never-takers), a group that always receives treatment
regardless of judge assignment (always-takers), and groups corresponding to each
propensity value p who are treated when assigned to a judge with p (j) ‚â• p and
not otherwise. We refer to members of these latter groups as p-compliers. Imbens
and Angrist (1994) show that under Condition (1), weighted average treatment ef-
fects of the form (1) are identified, including the average treatment effect among each
complier group, and an overall complier average treatment effect that puts positive
weights on each of the complier groups.
   The LATE Condition 1 implies that expected outcomes conditional on judge as-
signment lie on a continuous funtion of the judge‚Äôs propensity, p (Ji ), and that the
slope of the function at some propensity value p is equal to the average treatment
effect among p-compliers. Any bounds on the magnitude of possible treatment effects
are also bounds on the slope of the conditional expectation function of Yi given p (Ji ).
At a minimum, treatment effects are bounded by the outcome variable‚Äôs support.
The following theorem formalizes this implication:


Theorem 2 Suppose Condition 1 holds and Yi has compact support. Then there
exists K < ‚àû such that E [Yi |Ji = j] = œÜ (p (j)) where œÜ ‚àà LipK ([0, 1]).


Proof. All proofs are in the Appendix.
   The result of the theorem means the judge fixed effects identifying assumptions
have testable implications. The requirement that the outcome have compact support
does not limit its usefulness: one can always replace the outcome by a set of indicator
variables of the form 1 (Yi ‚â§ y), and doing so leads to tests that exploit the whole
outcome distribution. We focus initially on the conditional expectation of Yi itself,

                                           7
and explore extensions to distributions and quantiles in an appendix.
    Common alternatives to the LATE assumptions also share this implication. The
traditional instrumental variables assumptions do not assume monotonicity, but do
require constant treatment effects. In this framework the result of Theorem 2 is even
stronger: E [Yi |Ji = j] is not only continuous, but a linear function of propensities.
de Chaisemartin (2017) presents a weaker monotonicity assumption under which a
proper weighted average of treatment effects is still identified. His ‚Äúcompliers-defiers
assumption‚Äù is that, for each pair of judges, there is a subset of compliers that (1)
is the same size as the set of defiers for that judge pair, and (2) has the same av-
erage treatment effect as the set of defiers (those whose treatment status response
violates monotonicity) for that judge pair. Replacing traditional monotonicity with
this compliers-defiers assumption leaves the result of Theorem 2 unchanged. Thus,
the test described below applies equally well when these alternative assumptions are
invoked.



3     Testing Procedure

Our proposed test is based on two observations that follow from Theorem 2: (1)
average outcomes conditional on judge assignment should fit a continuous function of
judge propensities; and (2) the slope of that continuous function should be bounded
in magnitude by the width of the outcome variable‚Äôs support. The tests consists of
examining whether observed outcomes averaged by judge are consistent with such a
function.
    Figure 1 illustrates graphically the intution behind the test. The top panel depicts
a situation in which the assumptions are satisfied, so that average outcomes by judge
lie on a continuous function of judge propensity, and that slope of that function is


                                           8
within the required bounds. The bottom panel illustrates two ways that violations of
the assumptions may appear. In the first (labeled ‚ÄúA‚Äù on the figure), two judges have
identical propensities, but different average outcomes; thus no continuous function can
pass through both points. In the second (labeled ‚ÄúB‚Äù), two adjacent judges do not
have identical propensities, but their average outcomes are sufficiently different that
the slope of the curve connecting them exceeds the possible treatment effect values.
   This suggests a conceptually straightforward procedure for testing the judge fixed
effects design‚Äôs assumptions:


  1. Regress the outcome Yi on a flexible function of the judge propensity, œÜ (p (Ji ))

  2. Jointly test fit and slope by

      (a) Regressing the residuals from step 1, ui = Yi ‚àíœÜ (p (Ji )), on judge indicators
           and testing whether the coefficients are jointly zero;

      (b) Testing whether the slopes of the function are within the bounds dictated
           by the support of Yi .


   This procedure presents two complications. The first is specifying the propensity
regression in step 1. The step 1 regression of the outcome on the judge propensi-
ties should be as flexible as the researcher‚Äôs assumptions regarding treatment effect
heterogeneity. A linear regression imposes constant treatment effects and makes the
test procedure above equivalent to the usual Sargan-Hansen overidentification test
(Sargan, 1958; Hansen, 1982). To impose minimal assumptions on treatment effect
heterogeneity, Theorem 2 suggests one should choose a flexible specification that ap-
proximates Lipschitz functions well, such as polynomials or splines (Chen, 2007). Our
simulations and application use b-splines (see Racine, 2018), but other bases could be



                                           9
used as well. Let the number of terms in the chosen series be m + 1, and let the func-
tion class in which the chosen specification lies be denoted Sm ; for example, degree-m
polynomials or degree-r splines with m ‚àí r knots. In the context of the judges design,
the number of terms in the approximating series is limited by the number of judges;
settings with a large number of judges, such as our application, allow the specification
to be quite flexible.
   The second complication is accounting for the estimation of the judge propensities
and the step 1 residuals when performing the tests in step 2. The simplest estimator
for p (Ji ) is simply the fitted value from a regression of treatment status Di on a
vector of judge indicators Wi = (1, 1 (Ji = 1) , . . . , 1 (Ji = J))0 , which amounts to the
fraction treated among individuals assigned to judge j, although it may be generalized
by adding controls to the first stage regression. Denote the estimated fitted values
PÃÇi . The first-step residuals also depend on a linear regression coefficient: collecting
the terms of the spline (or whichever basis is chosen) in the estimated propensity into
the vector SÃÇi , the estimated residual for the i-th observation is

                                               n
                                                                !‚àí1   n
                                               X                      X
                          uÃÇi = Yi ‚àí   SÃÇi0          SÃÇi SÃÇi0               SÃÇi Yi .
                                               i=1                    i=1


The fit component of our test is based on the second-step coefficients obtained by
regressing uÃÇi on Wi :                                 !‚àí1
                                    n
                                    X                           n
                                                                X
                             Œ≥ÃÇ =             Wi Wi0                  Wi uÃÇi .
                                       i=1                      i=1

Under the conditions of Theorem 2, Œ≥ÃÇ converges in probability to zero. Our procedure
tests this via the following Wald statistic:


                                        TÃÇ = nŒ≥ÃÇ 0 ‚Ñ¶ÃÇ‚àí1 Œ≥ÃÇ,                             (2)



                                                 10
                                                                        ‚àö
where ‚Ñ¶ÃÇ is a consistent estimator of the limiting covariance of nŒ≥ÃÇ, accounting for the
                     P                ‚àí1 P
                          n          0      n
first-step estimates      i=1 SÃÇi SÃÇ i      i=1 SÃÇi Yi and PÃÇi . Given an iid sample, a suitable

estimator is:

             n
                            !‚àí1          n 
                                                                              !         n
                                                                                                       !‚àí1
             X                           X                             0             X
‚Ñ¶ÃÇ =   n‚àí1         Wi Wi0          n‚àí1         Wi uÃÇi ‚àí RÃÇi Wi uÃÇi ‚àí RÃÇi          n‚àí1         Wi Wi0         ,
             i=1                         i=1                                            i=1



where RÃÇi is and adjustment term defined in the appendix.
   Given the assumptions so far, the test statistic (2) converges in distribution to a
chi-squared random variable with degrees of freedom equal to the difference between
the number of judges and the number of terms in the specification for œÜ, as the
following theorem formalizes:


Theorem 3 Suppose Condition 1 holds and œÜ ‚àà Sm , where m < J. Suppose further
that {Yi , Di , Ji }ni=1 comprise an iid sample and E |Yi |3 < ‚àû. Then
                                                           



                                           TÃÇ ‚Üí œá2 (J ‚àí m) .
                                               d



   Performing the fit component of the test means computing the test statistic and
obtaining the associated p-value from the appropriate chi-squared distribution.
   The slope component of the test examines whether the slopes of the function
relating outcomes to judge propensities lie between ‚àíK and K, recalling that K is
the width of the outcome variable‚Äôs support. The function relating average outcomes
given judge assignment to judge propensities is specified as


                                  œÜ (p) = Œ¥0 S0 (p) + ¬∑ ¬∑ ¬∑ + Œ¥m Sm (p) ,


where S0 , . . . , Sm are elements of a polynomial series, spline series, or whichever basis


                                                    11
is chosen for œÜ. When œÜ is specified as a quadratic b-spline, the maximum slope
occurs at one of the knots, {t0 = 0, t1 , . . . , tm‚àí2 , tm‚àí1 = 1}. The slope at the l-th knot
is given by
                                     2
                   œÜ0 (tl ) =               (Œ¥l+1 ‚àí Œ¥l ) ,           l = 0, . . . , m ‚àí 1,
                                tl+1 ‚àí tl‚àí1

where we define t‚àí1 = t0 = 0 and tm‚àí1 = tm = 1. The restriction on the slope of œÜ
corresponds to the following set of inequality constraints:

                                                                           m‚àí1
                                            2
                         ‚àíK ‚â§                      (Œ¥l+1 ‚àí Œ¥l ) ‚â§ K                 .
                                       tl+1 ‚àí tl‚àí1                            l=0

                         P                      ‚àí1 P
                                n                        n
Given estimates Œ¥ÃÇ =            i=1   SÃÇi SÃÇi0           i=1   SÃÇi Yi and corresponding variance matrix
that accounts for the estimation of PÃÇi , we implement the moment inequality testing
procedure proposed by Andrews and Soares (2010). This procedure first performs
generalized moment selection to eliminate inequalities that are far from binding, and
then constructs a modified method of moments (MMM) test statistic to test the
remaining inequalities. The appendix describes the details of the implementation.
   Finally, we combine the fit component and slope component of the test via a
weighted Bonferroni procedure to produce a single joint test.                            If we denote the
p-value from the fit component of the test as pf and the p-value from the slope-
component of the test as ps , then a joint level-Œ± test rejects if either pf < œâŒ± or
ps < (1 ‚àí œâ) Œ±, for some weight œâ ‚àà [0, 1]. Equivalently, one can define a joint p-
value as min {pf /œâ, ps / (1 ‚àí œâ)} and reject if the joint p-value is less than Œ±. The
choice of œâ governs the direction of power between the fit component and the slope
component, with values near one directing more power to the fit component of the
test. In the ‚Äújust identified‚Äù case when there are only two judges, the fit component
of the test will have no power, and therefore choosing œâ = 0 is appropriate. As the



                                                         12
number of judges grows, the specification of œÜ becomes more flexible and the number
of inequalities being tested in the slope component grows, causing the slope compo-
nent of the test to lose power; choosing œâ to be near one will be most appropriate in
cases with many judges, as in our application. The procedure described above has
asympotic size of at most Œ±; the simulations below show the test also performs well
in finite samples.
   The test has power against alternatives in which the conditional expectation of Yi
given the assigned judge differs from a continuous function of the judge propensity, or
in which the function has slopes that exceed the maximum possible treatment effect
size. This includes violations of random assignment or exclusion (Condition 1a) or
violations of monotonicity (Condition 1c). The test has power against violations of
random assignment when, for example, a given judge, jÃÉ, is more likely than other
judges to be assigned to a certain group of defendants, and that group differs in
its potential outcomes from other defendants. Similarly, the test has power against
violations of the exclusion restriction that arise when judges affect outcomes through
channels besides the treatment, so that defendants assigned to one judge jÃÉ experience
different average outcomes than defendants assigned to another judge with a similar
propensity.
   Finally, the test has power against violations of monotonicity when, for example,
a given judge jÃÉ with similar propensity to another judge nevertheless treats a quite
different set of defendants, and treatment affects those defendants differently from
the average. Under the preceding types of violations, average outcomes conditional
on Ji = jÃÉ will differ discretely from average outcomes conditional on other judges no
matter how close their propensity. As a result, the conditional expectation function
will not be well approximated by a continuous function with bounded slope, the
coefficients from regressing residuals on judge indicators will have nonzero probability

                                          13
limits, or the slopes will exceed the maximum treatment effects size and the test will
have asymptotic power.
    The test does not have power against all violations of Condition 1, however, as
is also the case for other specification tests in the literature (Kitagawa, 2015; Huber
and Mellace, 2015; MourifieÃÅ and Wan, 2017). For example, the test will not detect
violations of the monotonicity condition where two judges with similar propensity
nevertheless treat different types of defendants, but those types have identical average
treatment effects. (Monotonicity violations are unimportant in this case anyway,
because they do not induce bias unless treatment effects are heterogeneous.) Similarly,
the test will not detect violations of the exclusion restriction where two judges with
similar propensity values also have exclusion violations in similar magnitude and
direction. The test will not have power against knife-edge alternatives like this, but
will nevertheless have power against a wide class of alternatives as described in the
previous paragraph.



4     Implications if the test rejects

A test rejection constitutes evidence that either the exclusion restriction or the mono-
tonicity assumption (or both) fail to hold. Intuitively, it implies either that judges
influence outcomes beyond their propensity to assign treatment, or judges disagree on
their implicit ordering of which defendants should be treated. Strictly speaking, the
test does not distinguish which assumption is violated, although a priori information
may be informative about the nature of the violation. But regardless of which as-
sumption is violated, the consequence is that instrumental variables estimators using
the full set of judge indicators cannot be guaranteed to consistently estimate causal
parameters such as (1) except under special circumstances, described below.


                                          14
4.1       Exclusion restriction violations

If exclusion restriction violations cannot be ruled out, researchers may consider as-
sumptions that relax the exclusion restriction but still allow for identification of causal
parameters. One such assumption is the ‚Äúmany invalid instruments‚Äù condition pro-
posed by KolesaÃÅr et al. (2015), who allow the exclusion restriction to be violated, and
instead assume that the direct effects of instruments on the outcome are uncorrelated
with their effects on treatment.1 In the current setting, this means that a judge‚Äôs di-
rect effect on defendant outcomes is uncorrelated with his or her propensity to assign
treatment. Whether this assumption is plausible will depend on the specific setting.
       Mueller-Smith (2015) proposes a more traditional strategy for dealing with exclu-
sion restriction violations when the channels of the violations are observed, namely,
to treat the channels through which judges affect outcomes besides treatment as ad-
ditional endogenous variables. Under the traditional linear simultaneous equations
framework, which includes constant treatment effects and that the number of judges
is greater than the number of channels, the treatment effect of interest is identified.


4.2       Monotonicity violations

If a priori considerations rule out exclusion restriction violations, then a rejection
provides evidence against the strict monotonicity assumption, Condition 1c. A nat-
ural next step by researchers would be to relax monotonicity, perhaps by adopting
the weaker compliers-defiers condition (de Chaisemartin, 2017). Unfortunately, the
implication our procedure tests is also implied by the compliers-defiers condition,
meaning a rejection constitutes evidence against that assumption as well.
   1
    The proof that causal effects can be identified under this assumption uses a model with constant
treatment effects. A similar result may exist for a heterogeneous effects setting, but has not been
demonstrated.



                                                15
   Strict monotonicity can be relaxed in another way, however, that still preserves the
interpretation of the IV estimand as a proper weighted average of individual treatment
effects of form (1), and may hold even when strict monotonicity‚Äôs testable implication
is not satisfied. Define DÃÑi = Jj=1 Œªj Di (j) as individual i‚Äôs average treatment status
                              P

across judges, where Œªj is the probability of being assigned Ji = j, and consider the
following average monotonicity condition:
                                                        PJ                                     
Condition 4 (Average monotonicity) œâi :=                      j=1   Œªj (p (j) ‚àí p) Di (j) ‚àí DÃÑi ‚â•
0 almost surely.

Condition 4 means that for each individual, the covariance between the individual‚Äôs
judge-specific treatment status and judge overall treatment propensities is weakly
positive. This means that individuals may violate monotonicity with specific judges,
as long as they comply with monotonicity for enough other judges so that the overall
covariance stays nonnegative.
   Under this weaker notion of average monotonicity (and the exclusion restriction)
the IV two-stage least squares estimand can be interpreted as a proper weighted
average, as the following theorem shows.

Theorem 5 (IV weighted average) Suppose Condition 1a and 1b hold and define

                              E [(Yi ‚àí E [Yi ]) (E [Di |Ji ] ‚àí E [Di ])]
                    Œ≤2SLS =                                              .
                                    E (E [Di |Ji ] ‚àí E [Di ])2
                                                               


Then
                                               E [œâi Œ¥i ]
                                    Œ≤2SLS =               ,
                                               E [œâi ]

where œâi is defined in Condition 4.

Thus, falling back on Condition 4 when the test we propose rejects provides a way to
nevertheless interpret estimates causally.

                                             16
   But can the weaker average monotonicity condition be verified? Although the
individual weights œâi are not identified, as they are a function of potential treatment
status, their conditional expectation is, which provides a testable implication of Con-
dition 4. Given random assignment and the exclusion restriction, the conditional
expectation of œâi given some covariate Xi conditional upon which Ji is independent
of (Yi (0) , Yi (1) , {Di (j)}) is given by the covariance between judges‚Äô x-specific treat-
ment propensity and judges‚Äô overall propensity:

                                       J
                                       X
                    E [œâi |Xi = x] =         Œªj (p (j) ‚àí p) (px (j) ‚àí px ) ,
                                       j=1



where px = E [Di |Xi = x] and px (j) = E [Di |Ji = j, Xi = x]. The assumption that
œâi ‚â• 0 implies E [œâi |Xi = x] ‚â• 0 for all x in the support of Xi , which may be
tested by examining the observed covariance between judges‚Äô group-specific treatment
propensities and overall propensity. This gives a formal motivation to the informal
tests that overall propensity is positively correlated with group-specific propensities
in the applied literature (Bhuller et al., 2018; Dobbie et al., 2018a).
   If the many-invalid-instruments assumption and our average monotonicity as-
sumption seem reasonable in a given application, then using judge assignment for
identification is still appropriate even if our test rejects the conventional exclusion
and monotonicity conditions. However, these weaker assumptions do constrain the
scope of inference. In particular, they do not allow for the identification of marginal
effects along the entire distribution of judge propensities, as can be achieved in the
conventional framework (Mogstad et al., 2017). The weaker assumptions rely on aver-
aging across the entire set of judges, while identification of marginal effects throughout
the distribution requires assumptions to hold judge by judge.




                                               17
5     Simulations

The section illustrates how the proposed test‚Äôs performance in terms of finite-sample
size and power depends on features of the underlying data. The simulations‚Äô data
generating process mimics a setting with J judges, to whom individuals are assigned
with uniform probablity:
                                  Ji ‚àº U {1, . . . , J} .

A judge‚Äôs propensity to assign treatment is given by:


                                  p (Ji ) = Œ∏Ji / (J) .


The outcome is generated as


                                 Yi = Œ≤0 + Œ≤1 Di + Œµi ,


and treatment is determined by


                              Di = 1 (Œ¶ (‚àíŒΩi ) ‚â§ p (Ji )) ,


where
                                              p
                                 vi = œÅŒµi +       1 ‚àí œÅ2 Œ∑i

and
                                 (Œµi , Œ∑i ) ‚àº N (0, I2 ) .

In this setup the parameter Œ∏ governs the strength of the instruments and œÅ determines
the degree of treatment endogeneity. Note that this setup satisfies Condition 1. The
main simulation results set œâ = 1, which directs power to the fit component of the


                                            18
test. Further simulation results below show how the test performs under different
choices for œâ.
   The first set of simulations examines how the test‚Äôs size depends on the number
of observations. We set the simulation parameters as J = 10, Œ∏ = 1, Œ≤0 = Œ≤1 = 1,
and œÅ = .5. We consider sample sizes of n ‚àà {500; 1, 000; 2, 000; 5, 000; 10, 000}, and
for each sample size draw 999 samples from the data generating process described
above and perform the test with nominal size Œ± = .05, recording the rejection rate
for each sample size. The simulations show that the test has very close to nominal
size even for modest sample sizes. Figure 2 plots the rejection rate as a function of
the sample size. The horizontal line is at .05. The simulated rejection rate is very
near the nominal level throughout the range of sample sizes.
   The next set of simulations explores the test‚Äôs power to detect a violation of the
exclusion restriction, Condition 1a, which can arise if judges have direct effects on
outcomes other than through treatment. The data generating process is as described
above, except judges now have direct effects on the outcomes:

                                            J
                                            X
                        Yi = Œ≤0 + Œ≤1 Di +         Œ≥j 1 (Ji = j) + Œµi ,
                                            j=1


where the individual judge effects Œ≥j are drawn from a normal distribution with mean
zero and standard deviation that varies from zero (corresponding to no violation) to 1
(severe violation). We set n = 1000 for this set of simulations. The simulations show
that the proposed test‚Äôs power increases rapidly with the severity of the violation.
Figure 3 plots the rejection rate as a function of the standard deviation of the direct
judge effects. At the far left the rejection rate is very near .05, reproducing the result
that the test has correct size when the assumptions are satisfied. As the standard
deviation of the direct judge effects grows, the rejection rate increases rapidly. Power


                                            19
exceeds 90 percent when the standard deviation is 0.2 and is essentially 100 percent
for standard deviations above 0.3.
   The next set of simulations illustrates the test‚Äôs power to detect violations of the
monotonicity assumption, Condition 1c, which can occur if judges do not implicitly
agree on the order in which defendants should be treated. To allow for monotonicity
violations in the simulations, we introduce heterogeneity in defendants and judges.
We introduce an additional set of J judges (indexed J + 1, . . . , J) who order most
defendants identically to the first J judges, but order a fraction œÜ < .5 of defendants,
whom we call defiers, in the opposite order. Since violations of monotonicity only
lead to bias when treatment effects vary, we set defiers‚Äô treatment effect to ‚àíŒ≤1 . Let
the binary variable Fi with Pr (Fi = 1) = œÜ indicate whether a defendant is a defier.
Treatment assignment and outcomes are then determined as follows:
                   Ô£±
                   Ô£≤ Œ≤0 ‚àí Œ≤1 Di + Œµi , Fi = 1
                   Ô£¥
            Yi   =                                  ,
                   Ô£≥ Œ≤0 + Œ≤1 Di + Œµi , otherwise
                   Ô£¥
                   Ô£±
                   Ô£≤ 1 (Œ¶ (‚àíŒΩi ) ‚â§ 1 ‚àí p (Ji )) , Fi = 1 and Ji ‚â• J + 1
                   Ô£¥
           Di    =                                                      .
                   Ô£≥ 1 (Œ¶ (‚àíŒΩi ) ‚â§ p (Ji ))
                   Ô£¥                            ,       otherwise


The simulations show the proposed test has good power to detect violations of mono-
tonicity of this sort. Figure 4 plots the test‚Äôs rejection rate as a function of the fraction
of defiers œÜ. At the far left (œÜ = 0, corresponding to no violation) the test rejects at a
rate near Œ± = .05 as expected. As the fraction œÜ increases and the violation of mono-
tonicity becomes more severe, the rejection rate increases rapidly. Power exceeds 80
percent when the fraction of defiers is greater than .3.
   We also run simulations that allow us to compare how our test performs rela-
tive to the the test described in Kitagawa (2015). The Kitagawa test assumes a


                                             20
priori knowledge of the instruments‚Äô order with respect to the probability of treat-
ment. In the context of judge assignment, this assumption is problematic because
the judge propensities to treat are estimated rather than directly observed. To as-
sess the size of the Kitagawa test, we run simulations with four judges (the test
quickly becomes computationally burdensome as the number of judges increases)
with population propensities .25, .495, .5, and .505 using three different samples sizes
(n ‚àà {5, 000; 10, 000; 100, 000}). The monotonicity assumption in this scenario means
individuals fall into one of five compliance categories: always-takers, never-takers,
and one of three complier groups. We set the treatment effect equal to zero, and set
always-takers‚Äô outcomes to Yi = 0, judge 1 compliers‚Äô outcomes to Yi = 1, judge 2
compliers‚Äô outcomes to Yi = 2, judge 3 compliers‚Äô outcomes to Yi = 3, and never-
takers‚Äô outcomes to Yi = 4. With a nominal test size of 5%, rejection rates for the
Kitagawa test are 10.3% for a sample size of 5,000, and grow to 22.2% for n = 10, 000
and 27.9% with a sample size of 100,000. In comparison, rejection rates for our test
in the same simulations are 5.2%, 5.1% and 4.7%. The results show that the Kita-
gawa test substantially overrejects and that the distortion does not decrease with the
sample size over the range considered. For a large enough sample size, of course,
and given a dgp, estimation error in the propensities will become negligible and the
Kitagawa test will have correct size. But for any given sample size, there is a dgp
for which the Kitagawa test will fail to control size; that is, the Kitagawa test is not
uniformly asymptotically valid when propensities are estimated, as illustrated in our
simulations.
   Finally, we show how the test performs under different choices for œâ. To demon-
strate this, we run two sets of simulations: one with a small number of judges (J = 2),
in which we will see that small values for œâ are best, and another with a large number
of judges (J = 20) in which larger values for œâ are best. The outcome variable is

                                          21
binary, as in our application below, with expected value conditional on judge assign-
ment given by

                                                      J
                                                      X
                  Pr (Yi = 1|Ji ) = Œ≤0 + Œ≤1 Ji /k +         Œ≥j 1 (Ji = j) ,
                                                      j=0


and treatment propensity given by


                           Pr (Di = 1|Ji ) = Œ±0 + Œ±1 Ji /k.


As above, the Œ≥j terms represent violations of the exclusion restriction when they
are nonzero; in this set of simulations they are drawn from normal distribution with
standard deviation .2. This simulation setup also allows the assumptions to be vi-
olated when Œ≤1 > Œ±1 , as this would imply an average treatment effect greater than
one, which is impossible for a binary outcome. This corresponds to a violation of
the slope condition. In this simulation setup we set Œ≤1 = .3 and Œ±1 = .2. Using a
simulated sample size of n = 1, 000, we perform our test for several choices of œâ be-
tween zero and one, and examine how the test‚Äôs power depends on œâ in the few-judge
case (J = 2) and the many-judge case (J = 20). The simulation results show that
in the few-judge case, power is greatest when œâ = 0, since the fit component of the
test has no power in this case. The upper panel of Figure 5 shows that the test‚Äôs
power is over 80 percent when œâ = 0, and drops to zero when œâ = 1. The situation
is reversed in the many-judge case. The lower panel of Figure 5 shows that power
is very poor (around 10 percent) when œâ = 0, and increases for higher values of œâ.
Typical instances of the judge fixed effects design, including our application below,
involve relatively many judges. These simulation results suggest choosing œâ to be
high in these cases. In the application we set œâ = 1.


                                          22
6     Empirical Application: Pretrial Detention and

      Case Outcomes

To illustrate how to implement and interpret our test in practice, we replicate results
from the literature on the impact of pretrial detention on case outcomes. When an
individual is charged with a crime, he may be released or held in jail while the case
is being adjudicated. Several recent papers on pretrial detention (Gupta et al., 2016;
Leslie and Pope, 2017; Dobbie et al., 2018a) find that holding defendants pretrial
increases the probability that they will be convicted. In most settings, the only
purpose of the first hearing for the majority of defendants is to determine their pretrial
status. The judge at this hearing decides whether and how high to set bail. Causal
identification of the impact of detention on conviction comes from variation across
arraignment judges in the rates at which they detain people.


6.1    Background

We analyze a dataset from criminal cases in Miami-Dade that is identical to the data
from this location used in Dobbie et al. (2018a). Following arrest in Miami-Dade,
defendants are brought to a police station where they can secure their release by
posting bail according to a schedule based on seriousness of offense. For the 70% of
defendants who do not post bail immediately, there is a bail hearing within 24 hours
of arrest. At the hearing, the bail judge on duty may change the bail amount or
impose nonmonetary conditions, like monitoring.
    The weekday bail hearing shifts are presided over by a single judge, while ap-
proximately 60 judges preside at weekend bail hearings based on a rotating schedule.
Defendants are automatically assigned to the bail judge on duty, leaving little scope



                                           23
for manipulating judge assignment given the short window between arrest and the
hearing. The process of trial judge assignment is not connected to the bail hearing,
so the leniency of the bail judge does not have a systematic relationship with the
tendencies of judges involved in later stages of the case.


6.2    Data

Our data include all criminal cases on record in Miami-Dade between 2006 and 2014.
The court data include arrest charge, filing charge, and disposition charge; the out-
come for each charge; and the punishment for each guilty charge. We observe the bail
judge, bail amount and type, and if/when bail was posted. We know each defendant‚Äôs
name, gender, race, date of birth, and address. The individually identifying informa-
tion allows us to construct criminal history and future criminal activity during the
observation period. We restrict attention to cases in which there was a weekend bail
hearing; these are the cases assigned a bail judge based on a rotating schedule. Table
1 shows summary statistics for our sample, which is identical to the Miami-Dade
sample used in Dobbie et al. (2018a). The sample is predominantly male, and split
fairly evenly between whites and blacks. Defendants who are released pretrial are
less likely to have a prior offense from the past year and more likely to be white than
those detained pretrial. They are also less likely to be convicted, be sentenced to
incarceration, or to recidivate after case disposition. These differences are consistent
with the hypothesis that pretrial detention influences case outcomes. They also high-
light the nonrandom assignment of pretrial status, and the need to go beyond simple
comparisons of means to identify a causal effect.




                                          24
6.3    Research Design

We are interested in the relationship between pretrial release and conviction repre-
sented in the following equation:


                   convictedict = Œ≤0 + Œ≤1 releasedic + Œ≤2 Xict + ict

where convictedic is an indicator for whether individual i in case c was convicted,
releasedic is an indicator for whether the individual was released within three days
of the bail hearing, and Xic is a vector of defendant and case characteristics. OLS
will yield biased estimates if there are unobserved factors that are correlated with
both pretrial release and case outcomes. For example, defendants with above average
lawyers may have better outcomes at the bail hearing stage and a lower probability
of conviction.
   To estimate the causal effect of pretrial status on case outcomes, we begin by
instrumenting for whether an individual was released pretrial with a measure of the
leniency of his bail hearing judge. Following Dobbie et al., we use a leave-out mean
of residualized pretrial outcomes as an instrumental variable. We first regress actual
pretrial release status on a vector of bail year by bail day of week and court by
bail month by bail day of week fixed effects, to account for the possibility of bail
judges who are more likely to work certain days or months. The variation we use
for identification is therefore differences in leniency between judges working the same
day of the week within a month and year. Let the residual from this regression be
Released‚àóict . The instrumental variable for each defendant is the average of his bail
judge‚Äôs residuals for that year, excluding his own:

                                      
                              1             n                     n
                                                (Released‚àóikt ‚àí Œ£c=0  Released‚àóict
                                             tj                   itj
                                                                                     
             Zict =                        Œ£k=0
                          ntj ‚àí nitj

                                                  25
   where ntj is the number of cases seen by judge j in year t and nitj is the number
of cases of defendant i seen by judge j in year t.


6.4    Identification and Results

For our instrumental variable strategy to identify the causal effect of pretrial release,
the exclusion restriction and a monotonicity condition must hold. The exclusion
restriction in this setting requires both random assignment of judges and that judges
impact the outcome of interest only through pretrial detention. We provide evidence
that judge assignment is conditionally random in Table 2. Both the coefficients
and standard errors, and the p-values on the tests of joint significance indicate that
defendant characteristics are powerful predictors of pretrial status, but not of judge
leniency.
   Even if defendants are randomly assigned to judges, the exclusion restriction could
be violated if bail judges influence case outcomes through channels besides pretrial
release. For example, a bail judge who orders pretrial drug testing or treatment
influences outcomes other than through pre-trial detention and violates the exclusion
restriction.
   Monotonicity could be violated in this context if, for example, some judge were
harsh on average, but lenient toward female defendants. One approach employed
in the existing literature to assess the monotonicity assumption is to check whether
judge leniency within one subgroup is positively correlated with judge leniency within
another subgroup. Another test in the same spirit is to examine whether the first
stage estimates of the relationship between the residualized measure of judge leniency
Zict and individual pretrial status are positive for all subgroups, meaning that judges
who are more lenient overall are more likely to release members of any observable



                                           26
subgroup. As discussed above, this approach tests the weaker average monotonicity
condition, but is likely not a powerful test of strict monotonicity.
       Our joint test of the exclusion restriction and monotonicity assumption probes
whether there is a continuous relationship between judge leniency and case outcomes
(averaged at the judge level), taking into account that judge leniency is estimated.
This can be assessed graphically. Figure 6 plots average case outcomes by release rates
for each judge. Intuitively, our test assesses whether the data are consistent with all
points lying on a single continuous curve, to within sampling variation. Visually, this
appears to be unlikely.
       The formal test confirms the visual evidence. Table 3 shows results when we
apply our test to the data. We implement our test choosing œâ = 1, since with a large
number of judges, the slope component of the test has little power. The conclusions
are unchanged for a wide range of choices for œâ, however. The top panel shows that
we reject the null hypothesis on the full sample for various numbers of knots in the
spline function.2
       As discussed above, one possibility is to rely instead on the weaker average mono-
tonicity assumption, provided that the rejection is not due to exclusion restriction
violations. To assess the plausibility of our average monotonicity assumption, we
check that the first-stage coefficient is positive within subsamples defined by case and
defendant characteristics (see Tables 4 and 5), an approach used in several papers
in the literature (Gupta et al., 2016; Leslie and Pope, 2017; Dobbie et al., 2018a).
The results confirm that the first stage coefficient is positive and statistically signifi-
cant within several important observable subsamples. Based on these estimates, the
   2
    If we suspected that monotonicity violations along certain observable characteristics were to
blame, then we could test jointly across these dimensions. Assuming independence of the subsamples,
we could add up the chi-squared test statistics and degrees of freedom after running the test on all
subsamples defined by the relevant observables to get the joint test statistic and its chi-squared
degrees of freedom.


                                                27
average monotonicity assumption may be justified, and IV estimates have a causal in-
terpretation despite the violation of strict monotonicity, again, provided the rejection
was not due to exclusion restriction violations.
   To the extent that there are also exclusion restriction violations, we must invoke
the many invalid instruments assumption to interpret our IV estimates causally. If we
observe any potential non-focal treatment dimensions in the data, we can use them to
probe the many invalid instruments assumption. In our setting, we observe whether
or not the defendant was represented by a public defender. The bail judge has no
control over the specific public defender (and prosecutor) involved in the case, but
the court does have the final say on eligibility for representation by a public defender.
We construct the propensity for defendants appearing before each judge to receive a
public defender using the same approach as we did for the construction of the focal
propensity. The first stage for this non-focal propensity is just as strong as the focal
first stage, suggesting that this is, in fact, a channel through which judges exercise
real influence. Finally, we check whether there is a statistically significant correlation
between the focal and non-focal propensities, and find a correlation coefficient of -0.18
with a p-value smaller than .0001. The strength of this relationship makes the many
invalid instruments assumption less palatable for this context.
   Table 6 reports the estimated effect of pretrial release on conviction, and F-
statistics for the first stage. Pretrial release is estimated to reduce the probability
of conviction by 16 percentage points. The F-statistic from using the single judge
propensity to release instrument overstates the strength of the first stage. Using
jackknife instrumental variables estimation with the judge dummies reduces the size
of the F-statistic substantially..




                                           28
7      Conclusion

Judge fixed effects designs, or, more generally, treatment effects estimation involving
several dummy instrumental variables, are increasingly popular. Traditional overiden-
tification tests rely on often implausible constant treatment effects assumptions for
their validity. More recently developed tests that allow for heterogeneous treatment
effects, on the other hand, require that the order of the instruments by treatment
propensity be known, something that is rarely the case in judge fixed effects designs.
We have proposed a test of the identifying assumptions in judge fixed effects designs
that allows for heterogeneous treatment effects and accounts for the estimation of
judge propensities, established its asymptotic properties, and demonstrated its finite
sample performance in simulations and a real-world application to the effects of pre-
trial detention. Finally, we provided guidance on steps researchers can take when the
test reveals evidence against the identifying assumptions.



References

Anna Aizer and Joseph J. Doyle, Jr. Juvenile incarceration, human capital, and future
    crime: Evidence from randomly assigned judges. Quarterly Journal of Economics,
    130(2):759‚Äì803, May 2015.

Donald W. K. Andrews and Gustavo Soares. Inference for parameters defined by
    moment inequalities using generalized moment selection. Econometrica, 78(1):119‚Äì
    157, 2010. doi: 10.3982/ECTA7502.

Joshua D. Angrist and Guido W. Imbens. Two-stage least squares estimation of
    average causal effects in models with variable treatment intensity. Journal of the
    American Statistical Association, 90:430‚Äì442, 1995.

                                          29
Carolina Arteaga. The cost of bad parents: Evidence from incarceration on children‚Äôs
  education. Technical report, UCLA, 2018.

David Autor, Andreas Ravndal Kostol, Magne Mogstad, and Bradley Setzler. Dis-
  ability benefits, consumption insurance, and household labor supply. Working
  Paper 23466, National Bureau of Economic Research, June 2017. URL http:
  //www.nber.org/papers/w23466.

Saurabh Barghava and Dayanand Manoli. Psychological frictions and the incom-
  plete take-up of social benefits: Evidence from an irs field experiment. American
  Economic Review, 105(11):3489‚Äì3529, 2015.

Peter Bergman, Jeffrey Denning, and Day Manoli. Broken tax breaks? evidence from
  a tax credit information experiment with 1,000,000 students. Working Paper, 2017.

Manudeep Bhuller, Gordon B Dahl, Katrine V L√∏ken, and Magne Mogstad. Incarcer-
  ation, recidivism and employment. Working Paper 22648, National Bureau of Eco-
  nomic Research, September 2016. URL http://www.nber.org/papers/w22648.

Manudeep Bhuller, Gordon B Dahl, Katrine V L√∏ken, and Magne Mogstad. Incarcer-
  ation spillovers in criminal and family networks. Working Paper 24878, National
  Bureau of Economic Research, August 2018.

Bernard Black, Eric French, Jeremy McCauley, and Jae Song. The effect of disability
  insurance receipt on mortality. Technical report, Northwestern University, 2018.

Tom Chang and Antoinette Schoar. Judge specific differences in chapter 11 and firm
  outcomes. Technical report, University of Southern California, 2013.

Xiaohong Chen. Large Sample Sieve Estimation of Semi-Nonparametric Models, chap-
  ter 76, pages 5549‚Äì5632. 2007.

                                        30
Gordon B. Dahl, Andreas Ravndal Kost√∏l, and Magne Mogstad. Family welfare
  cultures *. The Quarterly Journal of Economics, 129(4):1711‚Äì1752, 2014. doi:
  10.1093/qje/qju019. URL http://dx.doi.org/10.1093/qje/qju019.

CleÃÅment de Chaisemartin. Tolerating defiance? local average treatment effects with-
  out monotonicity. Quantitative Economics, 8(2):367‚Äì396, 2017. doi: 10.3982/
  QE601. URL https://onlinelibrary.wiley.com/doi/abs/10.3982/QE601.

Will Dobbie and Jae Song. Debt relief and debtor outcomes: Measuring the effects
  of consumer bankruptcy protection. American Economic Review, 105(3):1272‚Äì
  1311, March 2015. doi: 10.1257/aer.20130612. URL http://www.aeaweb.org/
  articles?id=10.1257/aer.20130612.

Will Dobbie, Paul Goldsmith-Pinkham, and Crystal S. Yang. Consumer bankruptcy
  and financial health. Review of Economics and Statistics, 99(5):853‚Äì869, 2017.

Will Dobbie, Jacob Goldin, and Crystal S. Yang. The effects of pretrial detention
  on conviction, future crime, and employment: Evidence from randomly assigned
  judges. American Economic Review, 108(2):201‚Äì40, February 2018a. doi: 10.
  1257/aer.20161503. URL http://www.aeaweb.org/articles?id=10.1257/aer.
  20161503.

Will Dobbie, Hans Gr onqvist, Susan Niknami, MaÃärten Palme, and Mikael Priks.
  The intergenerational effects of parental incarceration. Working Paper 24186, Na-
  tional Bureau of Economic Research, January 2018b. URL http://www.nber.org/
  papers/w24186.

Joseph J. Doyle, Jr. Child protection and child outcomes: Measuring the effects of
  foster care. American Economic Review, 97(5):1583‚Äì1610, December 2007. doi: 10.


                                        31
  1257/aer.97.5.1583. URL http://www.aeaweb.org/articles?id=10.1257/aer.
  97.5.1583.

Joseph J. Doyle, Jr. Child protection and adult crime: Using investigator assignment
  to estimate causal effects of foster care. Journal of Political Economy, 116(4):
  746‚Äì770, 2008. doi: 10.1086/590216.

Ozkan Eren and Naci Mocan. Juvenile punishment, high school graduation and
  adult crime: Evidence from idiosyncratic judge harshness. Working Paper 23573,
  National Bureau of Economic Research, July 2017. URL http://www.nber.org/
  papers/w23573.

Alberto Galasso and Mark Schankerman. Patents and cumulative innovation: Causal
  evidence from the courts. The Quarterly Journal of Economics, 130(1):317‚Äì369,
  2015. doi: 10.1093/qje/qju029. URL http://dx.doi.org/10.1093/qje/qju029.

Donald P. Green and Daniel Winik. Using random judge assignment to estimate
  the effects of incarceration and probation on recidivism among drug offenders.
  Criminology, 48(2):357‚Äì387, 2010.

Arpit Gupta, Christopher Hansman, and Ethan Frenchman. The heavy costs of high
  bail: Evidence from judge randomization. The Journal of Legal Studies, 45(2):
  471‚Äì505, 2016.

Lars Peter Hansen. Large sample properties of generalized method of moments esti-
  mators. Econometrica, 50(4):1029‚Äì1054, July 1982.

Justine Hastings and Jeffrey Weinstein. Information, school choice, and academic
  achievement: Evidence from two experiments. The Quarterly Journal of Eco-
  nomics, 123(4):1373‚Äì1414, 2008.

                                        32
Martin Huber and Giovanni Mellace. Testing instrument validity for late identification
  based on inequality moment constraints. The Review of Economics and Statistics,
  97(2):398‚Äì411, 2015. doi: 10.1162/REST\ a\ 00450. URL https://doi.org/10.
  1162/REST_a_00450.

Guido W. Imbens and Joshua D. Angrist. Identification and estimation of local
  average treatment effects. Econometrica, 62(2):467‚Äì475, 1994. ISSN 00129682.
  URL http://www.jstor.org/stable/2951620.

Toru Kitagawa. A test for instrument validity. Econometrica, 83(5):2043‚Äì2063, 2015.
  ISSN 1468-0262. doi: 10.3982/ECTA11974. URL http://dx.doi.org/10.3982/
  ECTA11974.

Jeffrey R. Kling.    Incarceration length, employment, and earnings.        American
  Economic Review, 96(3):863‚Äì876, June 2006. doi: 10.1257/aer.96.3.863. URL
  http://www.aeaweb.org/articles?id=10.1257/aer.96.3.863.

Michal KolesaÃÅr, Raj Chetty, John Friedman, Edward Glaeser, and Guido W. Imbens.
  Identification and inference with many invalid instruments. Journal of Business
  & Economic Statistics, 33(4):474‚Äì484, 2015. doi: 10.1080/07350015.2014.978175.
  URL https://doi.org/10.1080/07350015.2014.978175.

Emily Leslie and Nolan G. Pope. The unintended impact of pretrial detention on
  case outcomes: Evidence from new york city arraignments. The Journal of Law
  and Economics, 60(3):529‚Äì557, 2017.

Chares E. Loeffler. Does imprisonment alter the life course? evidence on crimea nd
  employment from a natural experiment. Criminology, 51(1):137‚Äì166, 2013.

Nicole Maestas, Kathleen J. Mullen, and Alexander Strand. Does disability insurance

                                         33
  receipt discourage work? using examiner assignment to estimate causal effects of
  ssdi receipt. American Economic Review, 103(5):1797‚Äì1829, August 2013. doi: 10.
  1257/aer.103.5.1797. URL http://www.aeaweb.org/articles?id=10.1257/aer.
  103.5.1797.

David McKenzie, Suresh de Mel, and Christopher Woodruff. Returns to capital:
  Results from a randomized experiment. The Quarterly Journal of Economics, 123
  (4):1329‚Äì1372, 2008.

Magne Mogstad, Andres Santos, and Alexander Torgovitsky. Using instrumental
  variables for inference about policy relevant treatment effects. Working Paper
  23568, National Bureau of Economic Research, July 2017. URL http://www.
  nber.org/papers/w23568.

Ismael MourifieÃÅ and Yuanyuan Wan. Testing local average treatment effect assump-
  tions. The Review of Economics and Statistics, 99(2):305‚Äì313, 2017. URL https:
  //EconPapers.repec.org/RePEc:tpr:restat:v:99:y:2017:i:2:p:305-313.

Michael Mueller-Smith. The criminal and labor market impacts of incarceration.
  2015.

Samuel Norris, Matthew Pecenco, and Jeffrey Weaver. The effects of parental and
  sibling incarceration: Evidence from Ohio. Technical report, University of Southern
  California, 2018.

Benjamin Olken. Monitoring corruption: Evidence from a field experiment in indone-
  sia. Journal of Political Economy, 115(2):200‚Äì249, 2007.

Jeffrey S. Racine. A primer on regression splines. unpublished manuscript, May 2018.



                                         34
Bhaven Sampat and Heidi L Williams. How do patents affect follow-on innovation?
  evidence from the human genome. Working Paper 21666, National Bureau of Eco-
  nomic Research, October 2015. URL http://www.nber.org/papers/w21666.

J. D. Sargan. The estimation of economic relationships using instrumental variables.
  Econometrica, 26(3):393‚Äì415, 1958. ISSN 00129682, 14680262. URL http://www.
  jstor.org/stable/1907619.

Rebecca Thornton. The demand for, and impact of, learning hiv status. American
  Economic Review, 98(5):1829‚Äì1863, 2008.




Appendix

Proofs

Proof of Theorem 2. Condition 1 satisfies the conditions of Theorem 1 in Imbens
and Angrist (1994), which implies


 E [Yi |Ji = j] = (p (j) ‚àí p (1)) E [Yi (1) ‚àí Yi (0) |Di (j) > Di (0)] + E [Yi |Ji = 1] . (3)


By Condition 1c, monotonicity, for each individual i one can define a marginal
propensity, pÃÑi := inf {p : p = p (j) , Di (j) = 1}, such that when assigned a judge with
p (j) ‚â• pÃÑi , the individual is treated, and otherwise is untreated. For never-takers, we
define pÃÑi = ‚àû. For always-takers, pÃÑi = p (1). Note that pÃÑi depends only on Di (j), and
by Condition 1a is therefore independent of Ji , and that potential treatment status
can be written Di (Ji ) = pÃÑi ‚â§ p (Ji ). The right hand side of equation (3) then can be




                                            35
written


    œÜ (p (j)) = (p (j) ‚àí p (1)) E [Yi (1) ‚àí Yi (0) |p (1) < pÃÑi ‚â§ p (j)] + E [Yi |Ji = 1] ,


which depends on j only through p (j). By monotonicity the average slope of œÜ
through two points p and p0 (where p0 ‚â• p) can be written:


                 œÜ (p0 ) ‚àí œÜ (p) = (p0 ‚àí p) E [Yi (1) ‚àí Yi (0) |p ‚â§ pÃÑi ‚â§ p0 ] .


Let Y be the compact support of Yi . Noting that K := sup Y ‚àí inf Y is finite and
that |E [Yi (1) ‚àí Yi (0) |p ‚â§ pÃÑi ‚â§ p0 ]| ‚â§ K yields the result.
Proof of Theorem 3. Define the estimated judge propensity to treat as


                          pÃÇ (Zi ) = Wi0 Œ±ÃÇ,
                                          n
                                                               !‚àí1       n
                                          X                              X
                                Œ±ÃÇ =              Wi Wi0                       Wi Di .
                                           i=1                           i=1


Define vi := Di ‚àíWi0 Œ± and ui := Yi ‚àíSi0 Œ¥, where Si is a vector powers of p (Ji ) := Wi0 Œ±,
judge Ji ‚Äôs (population) propensity to treat, and Œ¥ is the vector of coefficients from the
population regression of Yi on Si . Write Si0 Œ¥ := f (Œª, Wi ), where Œª = (Œ±0 , Œ¥ 0 )0 . Letting

                                         n
                                                          !‚àí1            n
                                         X                               X
                                    ‚àí1
                            Œ¥ÃÇ =   n           SÃÇi SÃÇi0         n   ‚àí1
                                                                               SÃÇi Yi ,
                                         i=1                             i=1


                                                                     0 0
                                                                   
                                                                0
we can write uÃÇi = Yi ‚àí f ŒªÃÇ, Wi where ŒªÃÇ = Œ±ÃÇ , Œ¥ÃÇ                        , which has limiting behavior as
follows:                                   Ô£´          Ô£∂
                                        n     ‚àí1
                                       X Ô£¨ QW Wi vi Ô£∑
                    ‚àö        
                      n ŒªÃÇ ‚àí Œª = n‚àí1/2     Ô£≠          Ô£∏ + op (1) ,
                                       i=1   Q‚àí1
                                              S  S u
                                                  i i




                                                   36
where for some random vector Ai we adopt the notation QA := E [Ai A0i ]. By a mean
                                                0        
value expansion we can write uÃÇi = ui ‚àí ‚àá ŒªÃÉ, Wi      ŒªÃÇ ‚àí Œª , where ‚àá (Œª, Wi ) is the
Jacobian of f (Œª, Wi ) with respect to Œª,

                                                       Ô£´                Ô£∂
                                                             Wi ‚àÜ0i Œ¥
                                  ‚àá (Œª, Wi ) = Ô£≠
                                               Ô£¨                        Ô£∑
                                                                        Ô£∏
                                                               Si


and
                                                                           0
                             ÀÜi =       dS0 (pÃÇi )       dSm (pÃÇi )
                             ‚àÜ                     ,...,                          .
                                          dp               dp

The estimator on which the test statistic is based can therefore be expanded as:

                                     n
                                                                 !‚àí1             n
                   ‚àö         ‚àö    ‚àí1
                                     X                                           X
                       nŒ≥ÃÇ =  n n      Wi Wi0                           n   ‚àí1
                                                                                       Wi uÃÇi
                                               i=1                               i=1
                                                       n
                                                                            !
                                                       X
                            = Q‚àí1
                               W            n‚àí1/2            Wi ui ‚àí ri          + op (1) ,
                                                       i=1


where                   Ô£Æ     Ô£´               Ô£∂0 Ô£π Ô£´                                            Ô£∂
                                0         ‚àí1           0
                       Ô£Ø Ô£¨ Wi ‚àÜi Œ¥ Ô£∑ Ô£∫ Ô£¨ QW Wi (Di ‚àí Wi Œ±) Ô£∑
                ri = E Ô£∞Wi Ô£≠       Ô£∏ Ô£ªÔ£≠                    Ô£∏,
                                               ‚àí1
                             Si              QS Si ui

a consistent estimator for which is
                   Ô£´                Ô£´                   Ô£∂0 Ô£∂ Ô£´                                      Ô£∂
                            n
                            X            Wj ‚àÜ0j Œ¥ÃÇ                  QÃÇ‚àí1
                                                                      W Wi     (Di ‚àí pÃÇi ) Ô£∑
             RÃÇi = Ô£≠n‚àí1           Wj Ô£≠                                                     Ô£∏.           (4)
                   Ô£¨                 Ô£¨                  Ô£∑ Ô£∑Ô£¨
                                                        Ô£∏ Ô£∏Ô£≠
                                                                              ‚àí1
                            j=1              SÃÇj                            QÃÇS SÃÇi uÃÇi


By the central limit theorem we therefore have

                                        ‚àö
                                            nŒ≥ÃÇ ‚Üí N (0, ‚Ñ¶) ,
                                                   d




                                                       37
where
                               ‚Ñ¶ = Q‚àí1                    ‚àí1
                                    W V ar (Wi ui ‚àí ri ) QW


is consistently estimated by ‚Ñ¶ÃÇ in the text. The quadratic form


                                              nŒ≥ÃÇ 0 ‚Ñ¶ÃÇ‚àí1 Œ≥ÃÇ


is therefore asymptotically a chi-squared random variable with degrees of freedom
equal to the rank of ‚Ñ¶ÃÇ‚àí1 , in this case k ‚àí m.
Proof of Theorem 5. Define and note the following:


                        Yij = Yi (1) Di (j) + Yi (0) (1 ‚àí Di (j))
                              XJ
                        DÃÑi =     Œªj Di (j)
                                    j=1
                                    J
                                    X
                          p =             Œªj p(j)
                                    j=1
                                                                
                         YÃÑi    :   = DÃÑi Yi (1) + 1 ‚àí DÃÑi Yi (0)
                                    J
                                    X
                               =          Œªj Yij
                                    j=1
                               " J        #
                              X
                     E YÃÑi = E     Œªj Yij
                                          j=1
                                    "   J
                                                                           #
                                        X
                               =              Pr (Ji = j) E [Yi |Ji = j]
                                        j=1
                               = E [Yi ]


The IV estimand is the covariance between assigned judge propensity and individual




                                                   38
outcome divided by the variance of the judge propensity:

                                 E [(Yi ‚àí E [Yi ]) (E [Di |Ji ] ‚àí E [Di ])]
                     Œ≤2SLS =                                                .
                                       E (E [Di |Ji ] ‚àí E [Di ])2
                                                                  


Iterating expectations in the numerator and denominator, the right hand side be-
comes:

                          PJ
                            Œªj (E [(p(j) ‚àí p) (Yi ‚àí E [Yi ]) |Ji = j])
                              j=1
                                   PJ                  2
                                     j=1 Œªj (p(j) ‚àí p)
                       PJ                                       
                        j=1 Œªj E (p(j) ‚àí p) Yij ‚àí YÃÑi |Ji = j
                     =  PJ                                     ,
                           j=1 Œªj (p(j) ‚àí p) E    Di (j) ‚àí DÃÑi

                                                                               
where the second line follows from random assignment which implies E YÃÑi |Ji = j =
  
E YÃÑi = E [Yi ]. Noting that Œªj (p(j) ‚àí p) is deterministic and that random assign-
ment implies E [Yij |Ji = j] = E [Yij ], the IV estimand can be written:

                PJ                                      
                   j=1 Œªj (p(j) ‚àí p) E [Yij ] ‚àí E YÃÑi
                  hP                                          i
                       J
                E      j=1 Œªj (p(j) ‚àí p) Di (j) ‚àí DÃÑi
                    hP                                     i
                         J
                  E      j=1 Œª j (p(j) ‚àí   p) Y ij ‚àí  YÃÑ i
              =   hP                                          i
                       J
                E          Œª
                       j=1 j  (p(j)  ‚àí  p)   Di (j) ‚àí   DÃÑ  i
                  hP                                                                    i
                       J                                        
                E          Œª
                       j=1 j    (p(j) ‚àí   p)  D i (j) ‚àí    DÃÑ i    (Y i (1)   ‚àí Y i (0))
              =              hP                                              i            ,
                                  J                                         
                           E      j=1 Œª j (p(j) ‚àí  p)    D  i  (j) ‚àí   DÃÑ i



where the first equality follows from the interchangeability of integration and sum-
mation, and the final equality from the definitions of Yij and YÃÑi .
   Hence, given random assignment and the exclusion restriction (and notably with-
out imposing monotonicity), the IV estimand can be written as a weighted average




                                                 39
of individual-level treatment effects:

                                        E [œâi (Yi (1) ‚àí Yi (0))]
                             Œ≤IV =                               ,
                                                E [œâi ]

where the weights are given by

                                 J
                                 X                               
                         œâi :=         Œªj (p(j) ‚àí p) Di (j) ‚àí DÃÑi .
                                 j=1




Extensions

The proposed test has power against alternatives that shift the mean of Yi , but will
not have power against alternatives where other features of Yi are changed but not
the mean. The test naturally extends to have power against shifts in other features of
the distribution, as well. Instead of regressing Yi on the instrument indicators and the
propensity power series, one can simultaneously regress a set of indicator variables of
the form 1 (Yi ‚â§ yj ) for a grid of {yj } values and jointly test whether the coefficients
on the instrument indicators are zero across all equations.
   Alternatively, one can replace the mean regression with a set of quantile regressions
of Yi with a grid of quantile values œÑj ‚àà (0, 1). The test then consists of jointly testing
the hypothesis that the coefficients on the instrument dummies are zero across all
quantile regressions. In this case and the dummy dependent variable alternative
above, the test is carried out using a variance matrix accounting for the estimation
of pÃÇ (Ji ), analogous to the procedure described in the main text. These extensions
allow the test to have power against a wider array of alternatives, although at the
expense of more computational burden and perhaps a lack of specific power against


                                               40
alternatives where only the mean is shifted.


Generalized Moment Selection Implementation

The slope component of the test implements the moment inequality testing procedure
proposed by Andrews and Soares (2010). This procedure is based on the following
modified method of moments (MMM) test statistic:

                                   Ô£´Ô£Æ                    Ô£π2       Ô£Æ Ô£π2 Ô£∂
                             m‚àí1                   0                            0
                             X     Ô£¨Ô£∞ K ‚àí  œÜÃÇ (t )
                                          0 l Ô£ª + Ô£∞
                                                       K + œÜÃÇ (tl ) Ô£ª Ô£∑
                     MÃÇ =          Ô£≠                       0       Ô£∏,
                             l=0     s.e. œÜÃÇ (tl )    s.e. œÜÃÇ (tl )
                                                            ‚àí                        ‚àí


where [x]‚àí = x1 (x < 0),

                                    0                2                    
                                   œÜÃÇ (tl ) =                 Œ¥ÃÇ l+1 ‚àí Œ¥ÃÇ l ,
                                                tl+1 ‚àí tl‚àí1

                   0                 2                                    1/2
              s.e. œÜÃÇ (tl ) = n‚àí1/2             Œ£ÃÇl+1,l+1 + Œ£ÃÇl,l ‚àí 2Œ£ÃÇl+1,l          ,
                                  tl+1 ‚àí tl‚àí1
                                                                   P                ‚àí1 P
                                                                       n           0      n
and Œ£ÃÇ is a consistent estimator of the variance matrix of Œ¥ÃÇ =        i=1 SÃÇ i SÃÇi       i=1 SÃÇi Yi

that takes into account estimation of PÃÇi :

                      n 
                                                                                           !
                      X                                                               0
         Œ£ÃÇ = QÃÇ‚àí1                      ÀÜ i W 0 QÃÇ‚àí1 Wi vÃÇ SÃÇi uÃÇi ‚àí ‚àÜ
                              SÃÇi uÃÇi ‚àí ‚àÜ                            ÀÜ i W 0 QÃÇ‚àí1 Wi vÃÇ      QÃÇ‚àí1
                S                            i W                          i W                  S .
                       i=1


    Under the regularity conditions described in Andrews and Soares (2010), the dis-
tribution of the MMM test statistic can be approximated by the distribution of

                                            X                   X
                                   MÃÇ ‚àó =          [Zl‚àó ]2‚àí +          [‚àíZl‚àó ]2‚àí ,
                                            l‚ààL‚àí                l‚ààL+


where Z ‚àó is an m-element multivariate normal random variable with unit variances


                                                       41
and correlation matrix corresponding to the asymptotic variance of


                            ([0m√ó1 : Im ] ‚àí [Im : 0m√ó1 ]) Œ¥ÃÇ,


and the moments selected by the generalized moment selection are given by:
                               Ô£±                                     Ô£º
                                               0
                               Ô£≤         K ‚àí œÜÃÇ (tl )     ‚àö          Ô£Ω
                        L‚àí =       l:        0      ‚â§       ln n       ,
                               Ô£≥        s.e. œÜÃÇ (tl )                Ô£æ


and                            Ô£±                                     Ô£º
                                               0
                               Ô£≤         K + œÜÃÇ (tl )   ‚àö            Ô£Ω
                        L+ =       l:        0       ‚â§ ln n .
                               Ô£≥        s.e. œÜÃÇ (tl )        Ô£æ

The p-value from the slope component of the test can be found to arbitrary pre-
cision by simulating many multivariate draws, constructing MÃÇ ‚àó for each draw, and
computing the fraction of draws for which MÃÇ ‚àó ‚â• MÃÇ .


Tables




                                             42
                          Table 1: Summary Statistics

                                               Detained   Released   Full Sample
                                                mean       mean         mean
Panel A: Bail Information
Release on Recognizance                         0.05        0.11         0.07
Non-Monetary Bail                               0.11        0.38         0.20
Monetary Bail                                   0.83        0.51         0.73
Bail Amount (in thousands)                      59.94      24.80        48.38
Released in 14 Days                             0.06       1.00          0.37
Released Before Trial                           0.33        1.00         0.55
Panel B: Defendant Characteristics
Male                                            0.87        0.79        0.84
White                                           0.46        0.50        0.48
Black                                            0.54       0.50        0.52
Age at Bail Decision                            36.52      34.00        35.69
Prior Offense in Past Year                       0.40       0.22         0.34
Panel C: Charge Characteristics
Number of Offenses                               1.66       1.59        1.64
Felony Offense                                   0.51       0.56        0.53
Misdemeanor Only                                 0.49       0.44        0.47
Any Drug Offense                                 0.27       0.30        0.28
Any DUI Offense                                  0.00       0.00        0.00
Any Violent Offense                              0.14       0.30        0.19
Any Property Offense                             0.41       0.23        0.35
Panel E: Outcomes
Any Guilty Offense                               0.67       0.41        0.58
Guilty Plea                                      0.58       0.31        0.49
Any Incarceration                                0.25       0.17        0.22
Rearrest in 0-2 Years                            0.53       0.37        0.48
Rearrest Prior to Disposition 0-2 Years          0.14       0.16        0.15
Rearrest After Disposition                       0.40       0.25        0.35
Observations                                    62644      30714       93358




                                          43
            Table 2: Test of Random Judge Assignment

                                          (1)                  (2)
                                  Released in 3 Days     Judge Leniency
Male                                   -0.11‚àó‚àó‚àó               0.00
                                        (0.00)               (0.00)

Black                                         -0.03‚àó‚àó‚àó        0.00
                                               (0.00)        (0.00)

Age at Bail Decision                          -0.03‚àó‚àó‚àó        -0.00
                                               (0.00)        (0.00)

Prior Offense in Past Year                    -0.16‚àó‚àó‚àó        0.00
                                               (0.00)        (0.00)

Number of Offenses                            -0.02‚àó‚àó‚àó        0.00
                                               (0.00)        (0.00)

Felony Offense                                0.34‚àó‚àó‚àó         0.02
                                              (0.07)         (0.01)

Any Drug Offense                              0.04‚àó‚àó‚àó         0.00
                                              (0.01)         (0.00)

Any Violent Offense                           0.17‚àó‚àó‚àó         -0.00
                                              (0.01)         (0.00)

Any Property Offense                          -0.12‚àó‚àó‚àó        -0.00
                                               (0.00)        (0.00)

Missing Race                                -0.05             -0.00
                                           (0.03)            (0.00)
Joint Test p-value                          0.00               0.37
N                                         93358.00          93358.00
Standard errors in parentheses
‚àó
  p < 0.05, ‚àó‚àó p < 0.01, ‚àó‚àó‚àó p < 0.001




                                         44
                                   Table 3: Test Results

                        5 knots             10 knots             15 knots             20 knots
Full sample                935                 839                  819                  749
                          (504)               (499)                (494)                (489)
                         [0.000]             [0.000]              [0.000]              [0.000]

Note: This table displays the test statistics, degrees of freedom, and associated p-values from
 the proposed test. Each column shows results using a different number of knots in the spline
 function.




                 Table 4: First Stage Results by Case Characteristics

                            Crime Severity                           Crime Type
                          Misd.         Felony          Drug          Property          Violent
Judge Leniency            0.699***       0.281***       0.571***        0.479***         0.060
                         (0.057)        (0.048)        (0.061)         (0.053)          (0.065)
Observations             44130           49228          24987           30855           17015

Note: This table shows the results from regressing pretrial release status on the judge leniency
 instrument for subgroups defined by case characteristics. All specifications include controls for
 crime type and severity; whether the defendant is black; whether the defendant is male; age
 categories; whether the defendant has a prior offense within the past year; the number of counts;
 and whether the charges include any drug crimes, and violent crimes, and any property crimes.
 Standard errors are twoway clustered at the individual and judge levels.




                                              45
              Table 5: First Stage Results by Defendant Characteristics

                                        Priors                                  Race
                             No prior               Prior             Black              White
Judge Leniency                 0.491***              0.463***         0.527***            0.439***
                              (0.042)               (0.054)          (0.041)             (0.046)
Observations                   61697                31661             48900               44313

Note: This table shows the results from regressing pretrial release status on the judge leniency
 instrument for subgroups defined by defendant characteristics. All specifications include controls
 for crime type and severity; whether the defendant is black; whether the defendant is male; age
 categories; whether the defendant has a prior offense within the past year; the number of counts;
 and whether the charges include any drug crimes, and violent crimes, and any property crimes.
 Standard errors are twoway clustered at the individual and judge levels.




                           Table 6: First Stage and IV Results

                                                                                       Judge IV
Effect of pretrial release
Convicted                                                                               -0.165*
                                                                                       (0.079)
First-stage F for Z                                                                    226.291
                                                                                       (0.000)
First-stage F for dummies                                                               5.972
                                                                                       (0.000)

Note: The top panel displays the estimated effect of pretrial release on conviction, instrumenting
 for whether bail was met using judge leniency in column 1 and tercile leninecy in column 2.
 The bottom panel shows first-stage F statistics, and their corresponding p-values, using first
 the leniency instrument and then judge or tercile dummies. The first stage using dummies uses
 jackknife instrumental variables estimation.




                                               46
Figures




          47
                                   Illustrations of relationship between
                                   propensities and average outcomes
                                                 A. Consistent with assumptions
                      1
            Average outcomes (Y)
            .2    .4  0 .6    .8




                                   0        .2          .4           .6           .8       1
                                                         Propensity (Z)


                                                    B. Assumptions violated
                      1




                                                                                       B
            Average outcomes (Y)
                  .4    .6    .8




                                        A
            .2        0




                                   0        .2          .4           .6           .8       1
                                                         Propensity (Z)



Figure 1: Illustrations of hypothetical relationships between true judge propensities
to assign treatment and expected outcomes. Each dot represents a single judge.
The pattern in Panel A is consistent with the exclusion restriction and monotonicity,
because all the dots lie on a continuous function whose slope is nowhere larger in
magnitude that the largest possible treatment effects, given a binary outcome. The
pattern in Panel B could only arise if one or more of the assumptions were violated.
The judge labeled ‚ÄúA‚Äù has exactly the same propensity as another judge, but different
expected outcomes. The judge labeled ‚ÄúB‚Äù lies on a segment of the curve whose slope
is larger than one, implying an impossibly large treatment effect.


                                                           48
                           Rejection rate by sample size
                                   Nominal size = .05
  1
  .8
  .6
  .4
  .2
  0




       0            2000           4000         6000             8000          10000
                                      sample size


Figure 2: Monte Carlo simulation rejection rates from the test for instrument validity
as a function of the sample size (x-axis). The nominal size of the tests is .05. Based
on 999 iterations.




                                         49
             Rejection rate by severity of exclusion violation
                                     Nominal size = .05
  1
  .8
  .6
  .4
  .2
  0




       0              .2              .4               .6             .8           1
                           standard deviation of direct judge effects


Figure 3: Monte Carlo simulation rejection rates from the test for instrument validity
as a function of the severity of the exclusion restriction violation, as measured by the
standard deviation of the direct judge effects (x-axis). The nominal size of the tests
is .05. Based on 999 iterations.




                                            50
           Rejection rate by severity of monotonicity violation
                                    Nominal size = .05
  1
  .8
  .6
  .4
  .2
  0




       0              .1             .2               .3            .4             .5
                                       fraction defiers


Figure 4: Monte Carlo simulation rejection rates from the test for instrument validity
as a function of the severity of the monotonicity violation, as measured by the fraction
of defendants for whom judges disagree on the ordering. The nominal size of the tests
is .05. Based on 999 iterations.




                                          51
                 Power by weight given to fit
                   component of the test
                             Nominal size = .05
                                     A. Few judges
    1
    .8
    .6
    .4
    .2
    0




         0             .2           .4              .6           .8            1
                              weight given to fit component


                                    B. Many judges
    1
    .8
    .6
    .4
    .2
    0




         0             .2           .4              .6           .8            1
                              weight given to fit component



Figure 5: Monte Carlo simulation rejection rates from the test for instrument validity
as a function of the weight given to the fit component of the test. The upper panel
sets J = 2. The lower panel sets J = 20. The nominal size of the tests is .05. Based
on 999 iterations.                        52
                                           Judge leniency and average outcomes
                 .15            .1
    residualized conviction rate
  -.05        0  -.1 .05




                                     -.1      -.05       0            .05   .1   .15
                                                       judge leniency


Figure 6: Each dot corresponds to an individual bail judge. The x-axis measures
leniency, and is the average of the leave-out mean instrument for each bail judge.
The y-axis measures conviction rates for defendants who appeared before each bail
judge. Specifically, it is the average of the residual from regressing a dummy variable
for conviction on time/place fixed effects, and a vector of defendant and case char-
acteristics. Dot darkness reflects the number of bail hearings presided over by the
judge, with darker dots for higher caseloads. The median judge presided over 506
cases during our sample period.




                                                         53
