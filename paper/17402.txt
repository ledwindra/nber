NBER WORKING PAPER SERIES

THE IMPACT OF YOUTH SERVICE ON FUTURE OUTCOMES:
EVIDENCE FROM TEACH FOR AMERICA
Will Dobbie
Roland G. Fryer, Jr
Working Paper 17402
http://www.nber.org/papers/w17402

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2011

We are grateful to Cynthia Cho, Heather Harding, Brett Hembree, Wendy Kopp, Ted Quinn, Cynthia
Skinner, and Andy Sokatch for their assistance in collecting the data necessary for this project. We
also thank Lawrence Katz and seminar participants in the Harvard Labor Lunch for helpful comments
and suggestions. Brad Allan, Vilsa Curto, Abhirup Das, Sara D’Alessandro, Ben Hur Gomez, Meghan
Howard, Daniel Lee, Sue Lin, George Marshall, Rachel Neiger, Brendan Quinn, Wonhee Park, Gavin
Samms, Jonathan Scherr, and Allison Sikora provided truly exceptional research assistance and project
management support. Financial support from the Education Innovation Lab at Harvard University
[Fryer], and the Multidisciplinary Program on Inequality and Social Policy [Dobbie] is gratefully acknowledged.
Correspondence can be addressed to the authors by e-mail: dobbie@fas.harvard.edu [Dobbie] or rfryer@fas.harvard.edu
[Fryer]. The usual caveat applies. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2011 by Will Dobbie and Roland G. Fryer, Jr. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

The Impact of Youth Service on Future Outcomes: Evidence from Teach For America
Will Dobbie and Roland G. Fryer, Jr
NBER Working Paper No. 17402
September 2011
JEL No. I00,J01
ABSTRACT
Nearly one million American youth have participated in service programs such as Peace Corps and
Teach For America. This paper provides the first causal estimate of the impact of service programs
on those who serve, using data from a web-based survey of former Teach For America applicants.
We estimate the effect of voluntary youth service using a sharp discontinuity in the Teach For America
application process. Participating in Teach For America increases racial tolerance, makes individuals
more optimistic about the life chances of poor children, and makes them more likely to work in education.
We argue that these facts are broadly consistent with the “Contact Hypothesis,” which states that, under
appropriate conditions, interpersonal contact can reduce prejudice.
Will Dobbie
Education Innovation Laboratory
Harvard University
44 Brattle Street, 5th Floor
Cambridge, MA 02138
dobbie@fas.harvard.edu
Roland G. Fryer, Jr
Department of Economics
Harvard University
Littauer Center 208
Cambridge, MA 02138
and NBER
rfryer@fas.harvard.edu

“We need your service, right now, at this moment in history.... I’m asking you to
help change history’s course. Put your shoulder up against the wheel. And if you do,
I promise you - your life will be richer, our country will be stronger, and someday,
years from now, you may remember it as the moment when your own story and the
American story converged, when they came together, and we met the challenges of our
new century.”
President Barack Obama, at the signing of the Edward M. Kennedy Serve America
Act

1

Introduction

Over the past half century, nearly one million American youth have participated in national service
programs such as the Peace Corps, AmeriCorps, Teach For America, and City Year.1 These organizations have two stated objectives. The first is to provide services to communities in need. Peace
Corps sends volunteers to work in education, business, information technology, agriculture, and the
environment in more than 70 countries. Volunteers in Service to America (VISTA), a program in
AmeriCorps, enlists members to serve for a year at local nonprofit organizations or local government
agencies. Teach For America (TFA) recruits recent, accomplished college graduates to teach in some
of the most challenging urban public schools.
There is emerging empirical evidence that service organizations benefit the individuals that
they serve. Decker et al. (2006) find that students randomly assigned to Teach For America corps
members score 0.04 standard deviations high in reading and 0.15 standard deviations higher in
math compared to students in classrooms with traditional teachers. Moss et al. (2001) find that
students enrolled in an AmeriCorps tutoring program experience larger than expected gains in
reading performance.
A second objective of service organizations is to influence the values and future careers of those
that serve. Peace Corps stated mission includes helping to “promote a better understanding of
other peoples on the part of Americans.” VISTA hopes to encourage its members to fight poverty
throughout their lifetimes. Teach For America aims to develop a corps of alumni dedicated to
ending educational inequality even after their two-year commitment is over. Advocates of service
organizations point to notable alumni such as Christopher Dodd (Peace Corps), Reed Hastings
(Peace Corps), and Michelle Rhee (Teach For America), as evidence of the long term impact on
individuals that serve.
Despite nearly a million service program alumni and annual government support of over a billion
dollars, there is no credible evidence of the causal impact of service on those who serve.2 This is
1

This includes approximately 200,000 Peace Corps volunteers (http://multimedia.peacecorps.gov/multimedia/pdf
/about/pc_facts.pdf), 637,000 AmeriCorps Volunteers (http://www.americorps.gov/about/newsroom/states_news.asp),
28,000 Teach For America corps members (http://www.teachforamerica.org/about-us/our-history/), and 13,700
City Year volunteers (http://www.cityyear.org/mediakit.aspx).
2
The 2010 federal budget included $373 million for Peace Corps and $98 million for AmeriCorps VISTA. Decker
et al. (2006) report that school districts typically contribute about $1,500 per TFA member to offset recruiting costs,

1

due, in part, to the fact that service alumni likely had different values and career goals even before
serving. As a result, simple comparisons of service program alumni and non-alumni are likely to be
biased.
This paper provides the first causal estimate of the impact of service programs on those who
serve, using data from a web-based survey of TFA applicants - both those that were accepted and
those that were not - administered for the purposes of this study.3 The survey includes questions on
an applicant’s background, educational beliefs, employment, political idealism, and racial tolerance.
The section on educational beliefs asks about the extent to which individuals feel that the achievement gap is solvable, and the importance of teachers in reaching that goal. Employment variables
measure whether individuals are interested in working in education in the future, whether they are
currently employed in education, and whether they prefer to work in an urban or suburban school.
Political idealism is captured through a series of questions such as whether or not the respondent
self-identifies as liberal, or whether America should spend more money on specific social policies.
Racial tolerance is captured using an Implicit Association Test. For a complete list of questions,
see Online Appendix B.
Our identification strategy exploits the fact that admission into TFA is a discontinuous function
of an applicant’s predicted effectiveness, calculated using a weighted average of scored responses to
interview questions. As a result, there exists a cut-off point around which very similar applicants
receive different application decisions. The crux of our identification strategy is to compare the
average outcomes of individuals just above and below this cutoff. Intuitively, we attribute any
discontinuous relation between average outcomes and the interview score at the cutoff to the causal
impact of service in TFA.
The key threat to a causal interpretation of our estimates is that applicants may selectively
respond to our survey. In particular, one may be concerned that TFA alumni will be more likely to
respond, or that the non-alumni who respond will be different in some important way. Such selective
response could invalidate our empirical design by creating discontinuous differences in respondent
characteristics around the score cutoff. We evaluate this possibility in three ways. First, we test
whether the survey response rate changes at the admissions cutoff. Second, we test whether the
observable characteristics of survey respondents trend smoothly through the admissions cutoff score.
Finally, we examine the density of survey respondents around the cutoff score. In all three cases, we
find no evidence of the type of selective survey response that would invalidate our research design.
Our empirical analysis finds that serving in Teach For America increases an individual’s faith
and involvement in education, and increases racial tolerance. Political idealism remains essentially
or about $8 million per year in total.
3
There are several studies examining the correlation between service and later outcomes. McAdam and Brandt
(2009) compare 1993-1998 TFA alumni to TFA applicants who were admitted but chose not to serve. Haan (1974)
surveyed 220 Peace Corps members bound for service, comparing those admitted to those that returned. Yamaguchi
et al. (2008) surveyed individuals who “expressed interest” in AmeriCorps to individuals who applied to estimate the
impact of AmeriCorps on civic engagement, employment, and educational attainment. All of these studies suffer from
the same issues of self-selection and thus do not provide credible causal impacts of the effects of service programs on
future outcomes of those that serve.

2

unchanged. TFA alumni are 52.8 percentage points more likely to believe that the “achievement
gap is a solvable problem,” and 48.0 percentage points more likely to believe that teachers are the
most essential determinant of a student’s success. TFA alumni are also 35.5 percentage points more
likely to work for a K-12 school, and 47.5 percentage points more likely to work in an education
related career. Finally, serving in TFA increases implicit white-black tolerance by 0.980 standard
deviations. While service is also associated with higher implicit white-Hispanic tolerance, higher
explicit white-black tolerance in the Modern Racism Scale, and a higher probability of believing
that blacks and Hispanics are at least as intelligent as both whites and Asians, none of the estimates
for explicit racial tolerance are statistically significant. Taken literally, this implies that while there
is little treatment effect on measures of explicit tolerance, TFA increases the unconscious tolerance
of its members.
Analysis of subsamples reveals that the impact of service on faith in education and educational
involvement is larger for men, with no systematic differences by ethnicity or Pell Grant receipt – a
rough proxy for household income at college entry.
We argue that this new set of facts, particularly those on racial beliefs, are consistent with the
“Contact Hypothesis,” developed in Allport (1954) and extended by Brown and Hewstone (2005),
Hewstone and Brown (1986), and Pettigrew (1998). The “Contact Hypothesis” states that intergroup
contact increases tolerance. The majority of the empirical evidence shows that intergroup contact
is negatively correlated with intergroup prejudice (Pettigrew and Tropp 2006), and in real world
experimental settings, Boisjoly et al. (2006) and Barnhardt (2009) show that living with a minority
group increases tolerance among white college students and Hindu children, respectively. Similarly,
Clingingsmith et. al (2009) demonstrate that winning a lottery to participate in the Hajj pilgrimage
to Mecca increases belief in equality and harmony of ethnic groups among other outcomes.
TFA service typically involves sending a college educated young adult, whose parental income
is above the national average, into a predominantly poor and minority neighborhood. Seventy-four
percent of corps members in our sample are white, and eighty percent have at least one parent
with a college degree. The average parental income of a corps member while in high school is $118
thousand, compared to the national median family income of approximately $50 thousand (U.S.
Census Bureau 2000). In sharp contrast to this privileged upbringing, roughly eighty percent of
the students taught by corps members qualify for free or reduced-price lunch and more than ninety
percent are African-American or Hispanic.
There are three potential caveats to our analysis. First, because TFA introduced its discontinuous method of selecting applicants in 2007, our primary analysis includes only one cohort of TFA
applicants surveyed roughly a year after their service commitment ended. To address this issue, we
also collected data on TFA applicants from the 2003 to 2006 cohorts. Applicants in these cohorts
were admitted only if they met prespecified interview subscore requirements. For example, TFA
admitted applicants with the highest possible interview score in perseverance and organizational
ability so long as they had minimally acceptable scores in all other areas. In total, there were six
separate combinations of interview subscores that met the admissions requirements. We estimate

3

the impact of service for the 2003 to 2006 cohorts by instrumenting for TFA placement using an
indicator variable equal to one if a candidate meets one of the six subscore criteria for admissions,
controlling for fully nonparametric controls for each individual interview subscore. The impact of
TFA service is therefore identified using the interaction of the subscores. Our key identifying assumption is that, conditional on our nonparametric controls, the that the interaction of interview
subscores only impacts future outcomes through TFA placement. These estimates suggest that the
impacts of service are persistent, with older TFA alumni more likely to believe in the power of
education, more likely to be involved or employed in education, and are more racially tolerant.
The second caveat to our analysis is that the response rate of the 2007 cohort to our web-based
survey is only 30 percent. While there is no evidence of the type of selective survey response around
the interview score cutoff that would invalidate our empirical design, we cannot rule out unobserved
differences in who responded to our survey. With such a low response rate, the bounds on our
analysis include both positive and negative effects.4
Third, although TFA is broadly similar to other service organizations, it also differs in important
ways that limit our ability to generalize our results. To the extent that TFA’s impact on alumni
is driven by factors that all service organizations have in common, the results of our study will be
informative about the effects of service programs more generally. If one believes that the unique
attributes of TFA such as its selectivity or focus on urban teaching drive its impact, the results of
the study should be interpreted more narrowly.
The paper proceeds as follows. Section 2 provides a brief overview of Teach For America and its
relationship to other prominent service programs around the world. Section 3 describes our webbased TFA survey and sample. Section 4 details our research design and econometric framework
for estimating the causal impact of TFA on racial and educational beliefs, employment outcomes,
and political idealism. Section 5 describes our results. The final section concludes. There are three
online appendices. Online Appendix A provides further details of how we coded variables used
in our analysis and constructed the samples. Online Appendix B provides implementation details
and the complete survey administered to TFA applicants. Online Appendix C provides additional
results and robustness checks of our main analysis excluded from the main text.

2

A Brief Overview of Teach For America

A. History
Teach For America (TFA), a non-profit organization that recruits recent college graduates to
teach for two years in low-income communities, is one of the nation’s most prominent service programs. Based on founder Wendy Kopp’s undergraduate thesis at Princeton University, TFA was
created to build a movement to eliminate educational inequity by enlisting our nation’s most promis4

Approximately 26 percent of University of Chicago Business School alumni from the graduating classes of 1990
to 2006 responded to a web-based survey conducted in Bertrand, Goldin and Katz (2010). 10 percent of individuals
receiving UI benefits in New Jersey initially responded to an online survey conducted in Krueger and Mueller (2011),
with an additional 60 percent of those initial respondents dropping out of the follow-up survey.

4

ing future leaders. In 1990, TFA’s first year in operation, Kopp raised $2.5 million and attracted
2,500 applicants for 500 teaching slots in New York, North Carolina, Louisiana, Georgia, and Los
Angeles.
Since its founding, TFA corps members have taught more than three million students. Today,
there are 8,200 TFA corps members in 125 “high-need” districts across the country, including 13
of the 20 districts with the lowest graduation rates. Roughly 80 percent of the students reached
by TFA qualify for free or reduced-price lunch and more than 90 percent are African-American or
Hispanic.
TFA’s relatively recent founding by one individual stands in sharp contrast to the history of
other prominent social organizations such as Peace Corps and AmeriCorps, governmental organizations with their roots in 1960s-era social welfare programs. In 1993, President Bill Clinton signed
the National Community Service Trust Act, which established the Corporation for National and
Community Service, an umbrella organization for domestic community service programs. AmeriCorps incorporated two pre-existing programs, however: VISTA, which was created by President
Lyndon Johnson in 1964 as part of his “War on Poverty;”and the National Civilian Community
Corps, which was created by a bipartisan group of Senators in 1992. Peace Corps famously came
about as the result of a speech made in 1960 by then presidential candidate John F. Kennedy at
2 a.m. to students at the University of Michigan, in which he challenged them to spend two years
of their lives helping people in the developing world. President Kennedy signed an executive order
establishing the Peace Corps in 1961.
B. Application Process
Entry into TFA is highly competitive; in 2010, more than 46,000 individuals applied for just
over 4,000 spots. 12 percent of all Ivy League seniors applied. A significant number of seniors from
historically black colleges and universities also applied, including 1 in 5 at Spelman College and 1 in
10 at Morehouse College. 28 percent of incoming corps members received Pell Grants, and almost
one-third are people of color.
In its recruitment efforts, TFA focuses on individuals who possess strong academic records and
leadership capabilities, regardless of whether or not they have exposure to teaching practice prior
to entry into TFA. Despite this lack of formal training, students assigned to TFA corps members
score about 0.15 standard deviations higher in math and 0.04 standard deviations higher in reading
than students assigned to traditionally certified teachers (Decker et al. 2006).
To apply, candidates complete an online application, which includes a letter of intent, and a
resume. After a phone interview, the most promising applicants are invited to participate in an inperson interview, which includes a sample teaching lesson, a group discussion, a written exercise, and
a personal interview. Candidates who receive an in-person interview complete a sample teaching
lesson, participate in a group discussion, and have a one-on-one interview. Applicants who are
invited to interview are also required to provide transcripts, obtain two on-line recommendations,
and provide one additional reference.
Using information collected through the application and interview, TFA bases their selection of
5

candidates on a model that accounts for multiple criteria that they believe are linked to success in
the classroom, including achievement, perseverance, critical thinking, organizational ability, motivational ability, respect for others, and commitment to the TFA mission. TFA conducts ongoing
research on their selection criteria, focusing on the link between the selection criteria and observed
single-year gains in student achievement in TFA classrooms.
Between 2003 and 2006, TFA admitted candidates who met prespecified interview subscore
requirements. For example, TFA admitted all applicants with the highest possible achievement
score so long as they had minimally acceptable scores in all other areas. Or, applicants could be
admitted by having the highest possible score in perseverance and organizational ability, again so
long as they had minimally acceptable scores in all other areas. In total, there were six separate
combinations of interview subscores that met the admissions requirements. In 2007, TFA conducted
a systematic review of their admissions measures, improving the correlation between these subscores
and internal TFA measures of classroom success. Also starting in 2007, TFA began using a linear
function of the application subscores to help rank and select candidates.
Entry into Peace Corps is also competitive. In the 2009 fiscal year, Peace Corps received 15,386
applications for approximately 3,400 spots. The application process can take anywhere from six
to twelve months. Candidates must complete an online application, which includes two essays,
three references, employment history, resume, community and volunteer activities, educational
background, transcripts, and a health status review. Candidates are expected to have previous
experience in their areas of interest. For example, candidates interested in teaching English should
have three to six months of previous tutoring experience in English or a foreign language for at
least ten hours per month; candidates interested in health care should have three to six months
of volunteer or work experience in health care. The most qualified candidates are invited for an
interview. Successful candidates must then pass medical, legal, and suitability reviews before being
given an assignment.
Entry into AmeriCorps has generally been less competitive than entry into either TFA or Peace
Corps, but the number of applications in recent years has increased substantially. From November
2008 through June 2009, the most recent period that data is available, AmeriCorps received 146,699
online applications for approximately 59,000 slots. The application process for AmeriCorps varies
by program, but generally candidates must first submit an online application, which includes an
essay and two references. The most suitable candidates are then screened using a phone interview.
The entire application process takes approximately two months. While the application processes for
TFA and Peace Corps are both extremely competitive and generally draw graduates from selective
colleges, AmeriCorps members are more often between the ages of 18 and 21. Almost half are black
and more than half are high school dropouts at the time that they join the program (Jastrzab et
al. 1997).
C. Training and Placement
During our sample period, accepted applicants were required to take part in a five-week TFA
summer institute to prepare them for placement in the classroom at the end of the summer. The
6

TFA summer institute includes courses covering teaching practice, classroom management, diversity,
learning theory, literacy development, and leadership. During the institute, groups of participants
also take full teaching responsibility for a class of summer school students.
At the time of their interview, applicants submit their subject, grade, and location preferences.
TFA works to balance these preferences with the needs and requirements of districts. With respect
to location, applicants rank each TFA region as highly preferred, preferred, or less preferred and
indicate any special considerations, such as the need to coordinate with a spouse. Over 90 percent
of the TFA applicants accepted are matched to one of their “highly preferred” regions (Decker et
al., 2006).
TFA also attempts to match applicants to preferred grade levels and subjects, depending on an
applicants’ academic backgrounds, district needs, and state and district certification requirements.
As requirements vary from region to region, applicants may not be qualified to teach the same
subjects and grade levels in all regions. It is also difficult for school regions to predict the exact
openings they will have in the fall, and late changes in subject or grade-level assignments are not
uncommon.
TFA corps members are employed and paid directly by the school districts for which they work,
and generally receive the same salaries and health benefits as other first year teachers. Most districts
pay a $1,500 per corps member fee to TFA to offset screening and recruiting costs. TFA gives corps
members various additional financial benefits, including “education awards” of $4,725 for each year
of service, which they can use toward past or future educational expenses, and transitional grants
and no-interest loans to help corps members make it to their first paycheck.
TFA corps members are hired to teach in local school districts through alternative routes to
certification. Typically, they must take and pass exams required by their districts before they begin
teaching. Corps members may also be required to take additional courses to meet state certification
requirements or to comply with the requirements for highly qualified teachers under the No Child
Left Behind Act.
Peace Corps members also undergo an extensive training process. They are required to complete
a three-month intensive training program in the country in which they will be serving. The training
process varies by country. Members usually live in a village, receive training and orientation in the
local languages, and are expected to develop technical skills needed to do their work. In addition,
Peace Corps members receive cross-cultural training, health training, and safety training. For
instance, members might receive formal language instruction for five days a week in small groups.
As part of the training, Peace Corps members typically live with a host family, an experience
designed to ease the transition to the host site. Trainees also attend required medical sessions to
help them practice preventive health care while in the host country. AmeriCorps training is less
intensive than either TFA or Peace Corps training; members receive only a few weeks of training in
first aid and other basic skills needed to carry out their projects.

7

3

Teach For America Survey and Sample

To understand the impact of TFA on racial and educational beliefs, employment outcomes, and
political idealism, we conducted a web-based survey of the 2003-2009 TFA application cohorts
between April 2010 and May 2011. The survey contained 87 questions and lasted approximately 30
minutes. As an incentive to complete the survey, every individual was entered into a lottery for a
chance to win $5,000. The complete survey is available in Online Appendix B.
A. Contacting TFA Applicants
Applicants were first contacted using email addresses supplied to TFA in their initial applications. Between April 2010 and June 2010, applicants received up to three emails providing them
with information about the survey and link to the survey. Each email reminded applicants that by
completing the survey they would be automatically entered in a lottery for $5,000. Approximately
30 percent of the 2,567 2007 TFA alumni and 14 percent of the 4,801 2007 non-alumni started
the survey during this phase.5 To increase the response rate among non-alumni, we also contacted
individuals using phone numbers from TFA application records. We began by calling each of the
non-alumni who had not responded to the email and who had provided TFA a valid phone number
using a automated call system with a brief 30 second recording with information about the survey. We then contacted non-respondents using personal calls from an outsourced calling service.
Voicemails were left for those who did not answer the phone; for the 2007 cohort, those people were
called again a few weeks later. This strategy resulted in an additional 395 responses among 2007
non-alumni. The process was similar for the 2003 - 2006 and 2008 - 2009 cohorts, though we made
fewer follow up calls than with the 2007 cohort. Appendix B provides more details on each step of
this process.
These strategies yielded a final response rate of 32.7 percent among 2007 TFA alumni and 29.6
percent among 2007 non-alumni. Among the other cohorts, the response rate is lower for older
cohorts and non-alumni. The difference in the response rate between alumni and non-alumni is
smallest in the 2007 cohort, likely due to the additional phone calls to the non-alumni in this
cohort. Response rates are presented for all cohorts in Appendix Figure 1.
An important threat to our identification strategy is that the response rate changes discontinuously at the score cutoff. In this scenario, our results may be driven by changes in the type of
respondent at the cutoff rather than the causal impact of TFA. We test for differences in the response rate at the admissions cutoff in Figure 1. We plot the fraction of applicants taking the survey
in 0.0025 wide bins in interview score, and fitted values from a regression of an indicator variable for
taking the survey on an indicator variable for scoring above the cutoff score, a quadratic in interview
score, and a quadratic in interview score interacted with scoring above the cutoff. There is not a
5
Between June 2010 and July 2010 we also searched for both alumni and non-alumni non-responders on Facebook
using accounts specifically created for the TFA survey. Account pages included an overview of, and a link to, the
survey. We used email addresses from TFA to manually search for both alumni and non-admits on Facebook and
attempted to “friend” them. Despite finding 2,610 applicants on Facebook, this method yielded only 53 accepted
“friends.”

8

statistically significant impact of scoring above the cutoff score on survey response. If anything,
candidates with scores above the cutoff are somewhat less likely to have taken the survey. We test
for differences in survey response around the cutoff more formally in Section 5.4, finding no evidence
that our identifying assumption is violated.6
B. The Survey
Data collected in our online survey of TFA applicants is the heart of our analysis. We asked applications about their demographics and background information, educational beliefs, employment
outcomes and aspirations, political idealism, and racial beliefs. Whenever possible, survey questions
were drawn from known instruments such as the College and Beyond Survey, Harvard and Beyond
Survey, the The National Longitudinal Study of Adolescent Health Teacher Survey, the Modern
Racism Scale, and the General Social Survey. In this paper, we use only a small fraction of the data
we collected. For further details on these variables or those omitted from our analysis, see online
Appendix B.
The set of questions on educational beliefs were designed to measure the extent to which individuals feel that the achievement gap is solvable, that schools can achieve that goal, and the
importance of teachers in increasing student achievement. Survey respondents were asked whether
they agreed or disagreed with a series of statements on a five point Likert scale ranging from “agree
strongly” to “disagree strongly.” The statements included: “the achievement gap between children in
low-income and high–income areas is a solvable problem;” “great schools can close the achievement
gap;” and “if teachers try really hard, they can get through to even the most difficult or unmotivated
students.” These questions are similar to those asked in the The National Longitudinal Study of
Adolescent Health Teacher Survey. Other, more open-ended, questions included “what fraction of
blacks can we reasonably expect to obtain a college degree and individuals,” and “who is the most
important in determining how well students perform in school?” For questions with answers that do
not have clear cardinality, we create indicator variables equal to one if the response was “favorable”
(e.g. strongly agree that the achievement gap is a solvable problem).
Employment variables measure whether individuals are interested in working in education in
the future, whether they are currently employed in education, and whether they prefer to work in
an urban or suburban school. Political idealism is captured in a series of questions such as whether
or not the respondent self identifies as liberal or whether the government should spend more or less
on issues such as closing the achievement gap, welfare assistance, and fighting crime. For political
6

Appendix Figure 2 presents point estimates and associated 95 percent confidence intervals for the reduced form
impact of having a score above the cutoff (2007 - 2009) or having a set of eligible interview subscores (2003 - 2006)
on survey response in all cohorts. For the 2007 - 2009 cohorts we control for interview score and interview score
interacted with scoring above the cutoff score. For the 2003 - 2006 cohorts we include fully nonparametric controls
for each interview subscore, and report the point estimate for an indicator variable equal to one if the combination
of interview subscores is eligible for TFA admission. While there is little difference in the response rate of eligible
and ineligible applicants from the 2007 through 2009 cohorts, eligible applicants from the 2003 to 2006 are 6 to 11
percentage points more likely to respond to our survey. In Section 5.4 we test whether the eligible applicants who
take the survey are different on observable characteristics, finding that eligible applicants who took the survey are
more likely to be white or Asian in the 2003 through 2006 cohorts. The results for the 2003 to 2006 cohorts should
be interpreted with these differences in response rate in mind.

9

idealism, we create indicator variables equal to one if the response is more liberal.
In the final portion of the survey, we asked participants to take a 10 minute Implicit Association Test (IAT) that measured white-black implicit bias. We measure implicit associations as
they better indicate unconscious feelings about minorities (Bertrand, Chugh, Mullainathan 2005).7
Manipulation has been shown to be harder on the IAT than other measures (Steffens 2004), and a
recent meta-analysis reports the IAT is better at predicting behaviors than explicit attitudes when
the association measured involves a black-white comparison (Greenwald et al. 2009). IAT scores
also correlate well with other implicit measures of racist attitudes and real-world actions. For instance, individuals with more anti-black IAT scores are more likely to make negative judgments
about ambiguous actions by blacks (Rudman and Lee 2002); more likely to exhibit a variety of
micro-behaviors indicating discomfort with minorities, including less speaking time, less smiling,
fewer extemporaneous social comments, more speech errors, and more speech hesitations in an interaction with a black experimenter (McConnell and Leibold 2001); and are more likely to show
greater activation of the amygdala, an area of the brain associated with fear-driven responses, to the
presentation of unfamiliar black versus white faces (Phelps et al. 2000). Moreover, in Sweden IAT
scores predict discrimination in the hiring process among managers (Rooth 2007) and in the U.S.,
doctors with stronger anti-black IAT scores are less likely to prescribe thrombolysis for myocardial
infarction to black patients diagnosed with the same condition as the equivalent whites (Green et
al. 2006), though that latter finding has been questioned (Dawson and Arkes 2008).
We use a brief format IAT, developed in Sriram and Greenwald (2009), to assess the relative
strength of automatic associations between “good” and “bad” outcomes and white and black faces.
The brief format IAT performs similarly on test-retest and implicit-explicit correlations as the
standard IAT, but with one third the number of trials. We standardize Implicit Association Test
scores to have a mean of zero and a standard deviation of one, with higher values being more
favorable.
To complement the IAT measure of implicit bias, individuals were also asked about explicit racial
bias. Our first measure of explicit bias comes from the General Social Survey. Individuals were asked
to separately rate the intelligence of Asians, blacks, Hispanics, and whites on a seven point scale that
ranged from “almost all are unintelligent” to “almost all are intelligent.” We recoded this variable to
indicate whether individuals believe that blacks and Hispanics are at least as intelligent as whites
and Asians. Our second measure of explicit bias is the Modern Racism Scale (McConahay 1983).
The Modern Racism Scale consists of six questions that individuals are asked how much they agree
or disagree. Each item was re-scaled so that lower numbers are associated with a more anti-black
response, then a simple average was taken of the six questions. We normalized this scale to have
mean zero and standard deviation one across each cohort. The six statements that individuals are
presented are: “over the past few years, blacks have gotten more economically than they deserve;”
“over the past few years, the government and news media have shown more respect for blacks than
7

Some critics argue that the IAT may be assessing shared norms, familiarity, perceptual salience asymmetries, or
cultural knowledge that does not correspond to personal endorsement of that knowledge (e.g. Karpinski and Hilton
2001; Rothermund and Wentura 2004).

10

they deserve;” “it is easy to understand the anger of black people in America;” “discrimination
against blacks is no longer a problem in the United States;” “blacks are getting too demanding in
their push for equal rights;” and “blacks should not push themselves where they are not wanted.”
Index variables for each survey domain were also constructed by standardizing the sum of individual questions to have a mean of zero and a standard deviation of one in each cohort. Rather
than add dichotomous and standardized variables together, we converted all standardized variables
to indicator variables equal to one if the continuous version of the variable was above the median
of the full sample. Details on the coding of each measure are available in Appendix A.
C. The Final Sample
Our final sample consists of data from our web-based survey merged to administrative data
from Teach For America. The administrative records consist of admissions files and placement
information for the 2003 to 2009 application cohorts. Our data includes all TFA applicants invited
to the in-person interview. A typical applicant’s data include her name, undergraduate institution,
GPA, and major, admissions decision, placement information, and interview score. Data from TFA
administrative records and our web-based survey were matched using name, application year, college
and email address. Our primary sample consists of all 2007 applicants who responded to our survey.
Our secondary sample consists of survey respondents from all cohorts.
Summary statistics for the 2007 cohort are displayed in Table 1. 73 percent of the sample is
white, 7 percent is Asian, 7 percent is black, and another 6 percent is Hispanic.8 Alumni had an
average college GPA of 3.58 while non-alumni had an average GPA of 3.46. The parents of both the
typical alumni and non-alumni are highly educated; 58 percent of alumni have at least one parent
with a graduate degree, while 50 percent of non-alumni do. Over 80 percent of both groups have
at least one parent with a college degree. With that said, a significant fraction of TFA applicants
come from disadvantaged backgrounds. 19 percent of TFA alumni in our sample were eligible for a
Pell Grant in college, while 23 percent of non-alumni were eligible.

4

Research Design

Our identification strategy exploits the fact that entry into TFA is a discontinuous function of
an applicant’s interview score. Consider the following model of the relationship between future
outcomes (yi ) and serving in TFA (T F Ai ):
yi = α + γT F Ai + εi

(1)

The parameter of interest is γ, which measures the causal effect of service on future outcomes yi . The
problem for inference is that if individuals select into service organizations because of important
8

The racial distribution of TFA applicants mirrors that of colleges graduates at selective colleges more broadly. 5
percent of graduating seniors at “more selective” or “most selective” colleges are black. 6 percent are Hispanic (U.S.
Department of Education 2010). The 2011 TFA cohort is more diverse than previous cohorts, with 12 percent of the
cohort identifying as black and 8 percent identifying as Hispanic.

11

unobserved determinants of later outcomes, such estimates may be biased.9 In particular, it is
plausible that people who select into service organizations had different beliefs and outcomes before
they served: E[εi |yit−1 ] 6= 0. Since T F Ai may be a function of past beliefs and outcomes, this can
lead to a bias in the direct estimation of γ using OLS. The key intuition of our approach is that this
bias can be overcome if the distribution of unobserved characteristics of individuals who were just
below the bar for TFA is the same as the distribution among those who were just above the bar:
E[εi |scorei = c∗ + ∆]∆→0+ = E[εi |scorei = c∗ − ∆]∆→0+

(2)

where scorei is an individual’s interview score, and c∗ is the cutoff score below which very few
applicants are admitted to TFA. Equation (2) implies that the distribution of individuals to either
side of the cutoff is as good as random with respect to unobserved determinants of future outcomes
(εi ). In this scenario, we can control for selection into TFA using an indicator variable for whether
an individual has an interview score above the cutoff as an instrumental variable. Since service
in T F Ai is a discontinuous function of interview score, whereas the distribution of unobservable
determinants of future outcomes εi is by assumption continuous at the cutoff, the coefficient γ is
identified. Intuitively, any discontinuous relation between future outcomes and the interview score
at the cutoff can be attributed to the causal impact of service in TFA under the identification
assumption in equation (2).
Formally, let TFA placement (T F Ai ) be a smooth function of an individual’s interview score
(scorei ) with a discontinuous jump at the eligibility cutoff c∗ :
T F Ai = f (scorei ) + η(scorei ≥ c∗ ) + εi

(3)

In practice, the functional form of f (scorei ) is unknown. We follow Card et al. (2008) and Lee
and Lemieux (2010), among others, and approximate f (scorei ) with a quadratic in interview score
that is allowed to vary on either side of the cutoff. Estimation with a local linear regression, such
as that presented in Ludwig and Miller (2007) and Almond et al. (2010), gives similar results (see
Appendix Table 1).
The identified second stage parameter measures the average treatment effect for individuals
induced into TFA by scoring just above the cutoff. To address potential concerns about discreteness
in the interview score in both our first and second stage results, we cluster our standard errors at
the interview score level (Card and Lee 2008). The key threat to a causal interpretation of our
estimates is that applicants may selectively respond to our survey:
E[εi |surveyi = 1, scorei = c∗ + ∆]∆→0+ 6= E[εi |surveyi = 1, scorei = c∗ − ∆]∆→0+
where surveyi = 1 represents the set of TFA applicants who answered at least one question in our
web-based survey.
9

Studies that examine the association between service and future outcomes, such as Jastrzab and Winship (2008)
and McAdam and Brandt (2009), estimate equations such as (1).

12

In particular, one may be concerned that former TFA alumni will be more likely to respond,
or that the non-alumni who do respond will be different in some important way. Such selective
response could invalidate our empirical design by creating discontinuous differences in respondent
characteristics around the score cutoff. In Section 5.4 we evaluate this possibility of in three ways:
by testing whether the observable characteristics of survey respondents trends smoothly through
cutoff, by examining whether the fraction of applicants taking the survey trends smoothly through
the cutoff, and by examining the density of survey respondents around the cutoff. None of these
tests points to evidence of the type of selective survey response that would invalidate the empirical
design.
One final problem unique to our setting is that the cutoff score c∗ must be estimated from the
data. TFA does not specify a cutoff score each year. Rather, they select candidates using the
interview score as a guide until a prespecified number of teaching slots are filled. Our goal is to
identify the unknown score cutoff that best fits the data. To identify this optimal discontinuity
point, we use a technique similar to that used to identify structural breaks in time series data
and identify discontinuities in the dynamics of neighborhood racial composition (Card, Mas, and
Rothstein 2008). Specifically, we regress an indicator variable equal to one if the individual was
selected for TFA on a constant and an indicator variable equal to one if the individual scored above
a particular cutoff c in the full sample of applicants. We then loop over all possible cutoffs c in
0.0001 intervals, selecting the value of c that maximizes the R2 of our specification. Hansen (2000)
shows that this procedure yields a consistent estimate of the true discontinuity. A standard result
in the structural break literature (e.g., Bai 1997) is that one can ignore the sampling error in the
location of the discontinuity when estimating the magnitude of the discontinuity. Using different
cutoff points around the optimal c∗ yield very similar results.

5

Results

5.1

First Stage

First-stage results of the impact of the score cutoff on TFA service are presented graphically in
Figure 2. The figure presents actual and fitted values for our first stage regression. The sample
includes all 2007 applicants to TFA who answered at least one question on our survey. An individual
is defined as having served in TFA if she accepted the TFA offer and was assigned a school district.
Actual values are plotted in bins of size 0.0025.10 The fitted values are from a regression of an
indicator variable equal to one if an individual served in TFA on an indicator variable for being
above the cut-off score, c∗ , a quadratic trend in interview score, and a quadratic trend in interview
10

Lee and Lemieux (2010) propose a formal test for optimal bin width based on the idea that if the bins are narrow
enough, then there should not be a systematic relationship between the outcome variable and the running variable
within each bin. Otherwise, the bin is too wide and the mean value of the outcome variable is not representative
at the boundaries. A simple test for this consists of adding a set of interactions between the bin dummies and the
running variable to a base regression of the outcome variable on the set of bin dummies, and testing whether the
interactions are jointly significant. A bin width of 0.0025 passes this test.

13

score interacted with the indicator for being above the cut-off score. In symbols:
T F Ai = α1 +α2 (scorei ≥ c∗ )+α3 scorei +α4 score2i +α5 scorei ·(scorei ≥ c∗ )+α6 score2i ·(scorei ≥ c∗ )+εi
(4)
where α2 is the effect of having an interview score above the cutoff score on the probability of
service.
Figure 2 suggests that there is a large and precisely estimated increase in the probability of
serving in TFA at the cutoff score. About 35 percent of applicants scoring just below the cutoff
serve, while approximately 65 percent of applicants scoring just above the threshold serve. The
corresponding estimates are significant at the 1 percent level, suggesting that our empirical design
has considerable statistical power.

5.2

Main Results

Figure 3 summarizes our main results, and Figures 4 through 7 present results for each set of
questions separately. Each figure presents actual and fitted values for 2007 applicants to TFA who
answered at least one question on our survey. Section 5.5 provides results for additional cohorts.
Actual values are plotted in bins of size 0.0025. The fitted values are from a regression of the
dependent variable on an indicator variable for being above the cut-off score, c∗ , a quadratic in
interview score, and a quadratic in interview score interacted with the indicator for being above the
cut-off score. Thus, similar to our first stage specification, our reduced form specification is:
yi = α1 +α2 (scorei ≥ c∗ )+α3 scorei +α4 score2i +α5 scorei ·(scorei ≥ c∗ )+α6 score2i ·(scorei ≥ c∗ )+εi
(5)
where α2 is the reduced form effect of having an interview score above the cutoff score on the
probability of service. Below each figure we present the p-value associated with the reduced form
effect α2 . Results in tabular form, including two stage least squares estimates, are available in
Appendix C.
Our summary results in Figure 3 examine the standardized sum of dichotomous individual
questions from that domain. Continuous variables were converted to dichotomous variables by
creating an indicator variable equal to one if the continuous version of the variable was above the
median of the full sample. The racial tolerance index is made up of an individual’s white-black IAT
score only. Details on the coding of each measure are available in Appendix A. Figure 3 suggests
that serving in Teach For America increases an individual’s faith and involvement in education,
and increases racial tolerance. Individuals who serve score 1.582 standard deviations higher on our
index of educational faith, and 1.880 standard deviations on our index of educational employment.
TFA alumni are also 0.980 standard deviations “more tolerant” than non-alumni. Political idealism
remains essentially unchanged.
Figure 4 presents results for each education belief variable separately. Serving in TFA increases
an individual’s faith in the ability of poor children to compete with more advantaged children, and

14

the importance teachers in raising student achievement. Individuals who serve are 52.8 percentage
points more likely to believe that poor children can compete with more advantaged children, 47.7
percentage points more likely to believe that the achievement gap is solvable, 48.0 percentage points
more likely to believe that teachers are the most important determinant of success, 25.6 percentage
points more likely to believe that schools can close the achievement gap without the help of families,
and 84.5 percentage points more likely to disagree that there is little teachers can do to ensure that
students succeed. Individuals who serve also believe that we can reasonably expect 30.3 percent
more minorities to graduate from a four year college than individuals who do not serve.
The effect of TFA on involvement in education is depicted in Figure 5. An important criticism
of TFA is that corps members frequently depart before their two-year commitment has been fulfilled
or immediately after (Darling-Hammond et al. 2005). Our results do not address the question of
whether TFA teachers are more likely to stay in education compared to other teachers. Instead,
we ask whether TFA leads individuals to stay in education longer than they otherwise would have
without TFA.
Figure 5 suggests that those who serve in TFA are more likely to be employed in a K-12 school
or in education more generally one to two years after their commitment ends. Our two stage
least squares estimates suggest that serving in TFA increases the probability of being employed
in a K - 12 school by 35.5 percentage points and in education more broadly by 47.5 percentage
points. Individuals who serve are also 45.8 percentage points more likely to believe that service is
an important part of their career, and 35.9 percentage points more likely to prefer an urban teaching
job over a suburban teaching job. Interestingly, there is not a statistically significant effect of service
on wanting to work in education in the future, though the point estimate is positive. There is also
no effect of service on the preference of an urban teaching job over a finance job at the same salary,
though this may be because almost all survey respondents prefer teaching.
The effect of TFA on political idealism is depicted in Figure 6. Individuals were asked how
liberal they consider themselves, and whether we should spend more money closing the achievement
gap, on welfare assistance, and on fighting crime. Serving in TFA does not have a significant impact
on political idealism, at least as we have measured it here. We cannot rule out moderate size effects
of either direction, however.
Our final set of outcomes, racial tolerance, are presented in Figure 7. Our primary measure of
racial tolerance comes from the brief format Implicit Association Test (IAT), developed in Sriram
and Greenwald (2009), that assesses the relative strength of automatic associations between “good”
words and black faces. We normalize the IAT to have a mean of zero and a standard deviation of
one in each cohort. To complement the IAT measure, individuals were also asked about the relative
intelligence of whites, Asians, blacks and Hispanics, and a set of six questions that together make
up the Modern Racism Scale (McConahay 1983). We normalize the Modern Racism Scale to have a
mean of zero and a standard deviation of one in each cohort. Each measure is normed so that higher
numbers are associated with greater tolerance. More information on each measure is available in
the data appendix.

15

Remarkably, serving in TFA increases implicit white-black tolerance by 0.980 standard deviations. To put this in context, black applicants score 0.558 standard deviations higher than Asian
applicants on the IAT, while white and Hispanic applicants score 0.084 and 0.253 standard deviations higher respectively. The causal impact of TFA service is therefore equivalent to moving the
median Asian applicant to above the 50th percentile of the black distribution of racial tolerance
towards blacks.
Service is also somewhat associated with higher explicit white-black tolerance in the Modern
Racism Scale, and a higher probability of believing that blacks and Hispanics are at least as intelligent as both whites and Asians, though none of the estimates for explicit racial tolerance are
statistically significant. Taken literally, this implies that while there is little treatment effect on
measures of explicit tolerance, TFA increases the unconscious tolerance of its members.

5.3

Analysis of Subsamples

Table 2 investigates heterogeneous treatment effects across gender, ethnicity, and whether or not a
TFA applicant received a Pell Grant in college (a proxy for poverty). We allow for separate linear
trends in interview score by group. The impact of service on faith in education and educational
involvement is larger for men than for women. Service increases a male applicants faith in education
by 2.261 standard deviations, while increasing a female applicant’s faith in education by 0.867 standard deviations. Educational involvement increases 3.289 standard deviations for male applicants
and 0.917 standard deviations for female applicants.
The impact of service on faith in education is also larger for applicants without Pell Grants in
college, but smaller on involvement in education. There are no statistically significant differences
by ethnicity, though the point estimates tend to be larger for blacks and Hispanics, even for the
impact of service on racial tolerance.

5.4

Tests for Quasi-Random Assignment

Our empirical strategy assumes that applicants do not selectively respond to our survey. One specific
concern is that former TFA corps members will be more likely to respond. Similarly, we may be
concerned that the non-corps members who do respond will be different from the corps members
who respond in some important way. Such selective response could invalidate our empirical design
by creating discontinuous differences in respondent characteristics around the score cutoff. Although
the continuity assumption cannot be fully tested, we investigate whether the fraction of applicants
responding changes at the cutoff, whether the observable characteristics of survey respondents trends
smoothly through the cutoff, and examine the density of survey respondents around the cutoff.
Figure 1 tests whether the fraction of 2007 applicants responding to the survey changes at the
cutoff. We present actual and fitted values of the survey response rate. There does not appear to
be any difference in the response rate at the score cutoff. If anything, applicants above the cutoff
are somewhat less likely to take to the survey.11
11

Appendix Figure 2 presents analogous results for the other TFA cohorts. For the 2007 - 2009 cohorts we control

16

Figure 8 tests whether the observable characteristics of 2007 survey respondents trends smoothly
through the cutoff. If there is a discontinuous change at the cutoff, that would indicate that
respondents who were eligible for TFA differ in a way that would invalidate our research design. We
present actual and fitted values for 2007 applicants to TFA who answered at least one question on
our survey. Actual values are plotted in bins of size 0.0025. As with our first stage and reduced form
regressions, the fitted values are from a regression of the dependent variable on an indicator variable
for being above the cut-off score, a quadratic in interview score, and a quadratic in interview score
interacted with the indicator for being above the cut-off score. We examine gender, ethnicity, college
GPA, whether an individual had a Pell Grant in college, and whether an individual majored in a
math or science field. Survey respondents with interview scores just above the cutoff have lower
college GPAs, but are no more likely to be white or Asian, male, eligible for a Pell Grant, or to have
majored in a math or science field. Results are identical in the full sample of applicants.12
A final robustness test is to check whether the frequency of respondents changes at the cutoff.
To provide a formal estimate of a potential kink in the number of observations at the cutoff, we
follow the approach of McCrary (2008) and first collapse the data into equal sized bins. The two key
variables in the collapse data set are the number of observations in each bin and the interview score
that each bin is centered around. We then regress the number of observations in each bin on a third
order polynomial in interview score which we allow to vary on either side of the cutoff. A third order
polynomial does a good job of fitting the data with an R2 of 0.96 in the survey sample and 0.98
in the full sample. As suggested by Figure 9, the coefficient on the interaction term is statistically
insignificant in both samples. Results are similar for both higher and lower order polynomials.
Given the general lack of statistical significance of our robustness checks, we interpret our results
as showing no clear evidence that our identifying assumption is violated in our primary sample of
2007 applicants. Our robustness checks are less clear for the 2003 to 2006 cohorts. Eligible applicants
are more likely to respond to our survey, and survey respondents are more likely to be white or
Asian than non-respondents. The results from the 2003 to 2006 cohorts should be interpreted with
this caveat in mind.

5.5

Additional Cohorts

One potential caveat to our analysis is that it includes only one cohort of TFA applicants surveyed
roughly a year after their service commitment ended. If there are important longer term impacts
for interview score and interview score interacted with scoring above the cutoff score. For the 2003 - 2006 cohorts
we include fully nonparametric controls for each interview subscore, and report the point estimate for an indicator
variable equal to one if the combination of interview subscores is eligible for TFA admission. While there is little
difference in the response rate of eligible and ineligible applicants from the 2007 through 2009 cohorts, the marginal
eligible applicant from the 2003 to 2006 is approximately 6 to 11 percentage points more likely to respond to our
survey. The results from these cohorts should be interpreted with this caveat in mind.
12
Appendix Figure 3 presents results from all cohorts, minus Pell Grant status which is not available from 2003 to
2006. We plot reduced form coefficients and associated 95 percent confidence intervals for each cohort, each from a
separate regression. Eligible applicants who took the survey are more likely to be white or Asian in the 2003 through
2006 cohorts, and have somewhat higher college GPAs. Eligible and ineligible applicants do not differ by gender or
college major in any of the cohorts in our sample.

17

of service, our analysis will understate the true impact of TFA. If, on the other hand, the impacts
fade over time, our estimates are an upper bound on the true effects of TFA.
To shed some light on this issue, we also collected data on TFA applicants in the 2003 to 2006
and 2008 to 2009 cohorts. Recall that between 2003 and 2006, TFA admitted candidates who
met prespecified interview score requirements. For example, TFA admitted all applicants with the
highest possible critical thinking and organization skills so long as they had minimally acceptable
scores in all other areas. Or, applicants could be admitted by having the highest possible score in
perseverance and organizational ability, again so long as they had minimally acceptable scores in all
other areas. We estimate the impact of service in the 2003 to 2006 cohorts by instrumenting for TFA
placement using an indicator variable equal to one if a candidate meets one of the six subscore criteria
for admissions. We include fully nonparametric controls for each interview subscore. The impact
of TFA service is therefore identified using the interaction of the subscores. Our key identifying
assumption is that, conditional on our nonparametric controls, the that the interaction of interview
subscores only impacts future outcomes through TFA placement. For candidates from the 2008 and
2009 cohorts, we use our regression discontinuity strategy outlined in Section 4.
Figure 10 presents results for the impact of service on our summary measures for all available
cohorts. We plot reduced form coefficients and associated 95 percent confidence intervals for each
cohort. Each estimate comes from a separate regression. The impact of service on educational and
racial beliefs and educational involvement is persistent. Alumni from the 2003 to 2006 cohorts are
more likely to believe in the power of education, more likely to be employed in education, and are
more racially tolerant. Point estimates on the educational beliefs and involvement variables are
statistically significant for all alumni cohorts. The racial tolerance point estimate is statistically
significant at the 5 percent level for the 2006, 2005 and 2003 cohorts, and statistically significant at
the 10 percent level for the 2004 cohort. On the other hand, current TFA corps members from the
2008 and 2009 cohorts are only somewhat more likely to believe in the power of education, and are
no more racially tolerant than the marginal non-corps member.

6

Conclusion

Nearly one million American youth have participated in service programs such as Peace Corps and
Teach For America, and annual government spending in support of youth service programs exceeds
one billion dollars. This paper has shown that serving in Teach For America has a positive impact
on an individual’s faith in education, involvement in education, and surprisingly, racial tolerance.
The impact of service is also quite persistent, with effects present 5 years after the completion of the
TFA service commitment. The impact of service on educational beliefs and involvement is larger
for males, but there are no statistically significant differences by ethnicity.
Our results, particularly those on racial beliefs, are broadly consistent with the “Contact Hypothesis,” which suggests that contact with other groups will increase tolerance. Changes occur
through a combination of increased learning, changed behavior, new affective ties, and reappraisals

18

of one’s own group (Pettigrew 1998). A substantial empirical literature suggests that intergroup
contact is negatively correlated with intergroup prejudice (Pettigrew and Tropp 2006). Recent research suggests that this correlation may be causal. Boisjoly et al. (2006) show that white students
at a large state university who were randomly assigned black roommates in their first year are more
likely to endorse affirmative action, have more personal contact with minority groups, and view a
diverse student body as essential for a high-quality education. In a similar study, Barnhardt (2009)
shows that Hindus randomly assigned to live near Muslim neighbors are significantly more implicitly
and explicitly tolerant.
Recall, TFA service typically involves a considerable degree of intergroup contact over a two
year period – 74 percent of corps members in our sample are white, and 80 percent have at least
one parent with a college degree. The average parental income of a corps member is $118 thousand.
In stark contrast, roughly 80 percent of the students taught by TFA members qualify for free or
reduced-price lunch and more than 90 percent are African-American or Hispanic.
Taken together, the evidence presented in this paper suggests that TFA service has a significant
impact on an individual’s values and career decisions. Youth service, particularly service involving
extended periods of intergroup contact, may not only help disadvantaged communities, but help
create a more socially conscious and more racially tolerant society.

19

References
[1] Allport, Gordon W. 1954. “The Nature of Prejudice.” Reading, MA: Addison-Wesley.
[2] Almond, Douglas, Joseph Doyle, Amanda Kowalski, and Heidi Williams. 2010. “Estimating
Marginal Returns to Medical Care: Evidence from At-Risk Newborns.” Quarterly Journal
of Economics, 125(2): 591-634.
[3] Barnhardt, Sharon. 2009. “Near and Dear? Evaluating the Impact of Neighbor Diversity on
Inter-Religious Attitudes.” Unpublished working paper.
[4] Bai, Jushan. 1997. “Estimation of a Change Point in Multiple Regression Models.” The Review
of Economics and Statistics 79(4): 551-563.
[5] Bertrand, Marianne, Dolly Chugh and Sendhil Mullainathan. 2005. “New Approaches to Discrimination: Implicit Discrimination.” American Economic Review, 95(2): 94-98.
[6] Bertrand, Marianne, Claudia Goldin, and Lawrence Katz. 2010. “Dynamics of the Gender
Gap for Young Professionals in the Corporate and Financial Sectors.” American Economic
Journal: Applied Economics, 2(July): 228-255.
[7] Boisjoly, Johanne, Greg J. Duncan, Michael Kremer, Dan M. Levy, and Jacque Eccles. 2006.
“Empathy or Antipathy? The Impact of Diversity.” The American Economic Review 96(5):
1890-1905.
[8] Brown, Rupert, and Miles Hewstone. 2005. “An Integrative Theory of Intergroup Contact.”
Advances in Experimental Social Psychology 37: 255-343.
[9] Card, David, and David Lee. 2007. “Regression Discontinuity Inference with Specification Error.” Journal of Econometrics 142(2): 655-674.
[10] Card, David, Alexandre Mas, and Jesse Rothstein. 2008. “Tipping and the Dynamics of Segregation.” Quarterly Journal of Economics 123(1): 177-218.
bibitem Clingingsmith, David, Asim Ijaz Khwaja, and Michael Kremer. 2009. “Estimating the
Impact of the Hajj: Religion and Tolerance in Islam’s Global Gathering.” Quarterly Journal
of Economics 124(3): 1133-1170.
[11] Darling-Hammond, Linda, Deborah Holtzman, Su Jin Gatlin, and Julian Vasquez Heilig. 2005.
“Does Teacher Preparation Matter? Evidence about Teacher Certification, Teach for America, and Teacher Effectiveness.” Education Policy Analysis Archives, 13(42).
[12] Dawson, Neal V. and Hal R. Arkes. 2008. “Implicit Bias Among Physicians. ” Journal of General
Internal Medicine 24(1): 137-140.
[13] Decker, Paul T., Daniel P. Mayer, and Steven Glazerman. 2006. “Alternative routes to teaching:
The impacts of Teach for America on student achievement and other outcomes.” Journal
of Policy Analysis and Management, 25(1): 75 - 96.
[14] Green, Alexander R., Dana R. Carney, Daniel J. Pallin, Long H. Ngo, Kristal L. Raymond,
Lisa I. Iezzoni, and Mahzarin R. Banaji. 2006. “Implicit Bias among Physicians and its
20

Prediction of Thrombolysis Decisions for Black and White Patients. ” Journal of General
Internal Medicine 22(9): 1231-1238.
[15] Greenwald, Anthony G., T. Andrew Poehlman, Eric L. Uhlmann, and Mahzarin R. Banaji.
2009. “Understanding and using the Implicit Association Test: III. Meta-analysis of predictive validity.” Journal of Personality and Social Psychology 97: 17“41.
[16] Hann, Norma. 1974. “Changes in Young Adults After Peace Corps Experiences: PoliticalSocial Views, Moral Reasoning, and Perceptions of Self and Parents.” Journal of Youth and
Adolescence 3(3): 177-194.
[17] Hansen, Bruce E. 2000. “Sample Splitting and Threshold Estimation.” Econometrica 68: 575603.
[18] Hewstone, Miles and Rupert J. Brown. 1986. “Contact and conflict in intergroup encounters.”
Oxford: Basil Blackwell.
[19] Imbens, Guido, and Karthik Kalyanaraman. 2009. “Optimal Bandwidth Choice for the Regression Discontinuity Estimator.” NBER Working Paper No. 14726.
[20] Jastrzab, JoAnn, John Blomquist, Julie Masker, and Larry Orr. 1997. “Youth Corps: Promising
Strategies for Young People and their Communities.” Cambridge, MA: Abt Associates.
[21] Karpinski, Andrew and James L. Hilton. 2001. “Attitudes and the Implicit Association Test.”
Journal of Personality and Social Psychology 81(5): 774-788.
[22] Krueger, Alan, and Andreas Mueller. 2011. “Job Search, Emotional Well-Being and Job Finding
in a Period of Mass Unemployment: Evidence from High-Frequency Longitudinal Data.”
Unpublished Working Paper.
[23] Lee, David and Thomas Lemieux. 2010. “Regression Discontinuity Designs in Economics.”
Journal of Economic Literature 48: 281-355.
[24] Ludwig, Jens, and Douglas Miller. 2007. “Does Head Start Improve Children’s Life Chances?
Evidence from a Regression Discontinuity Design.” Quarterly Journal of Economics,
122(1):159-208.
[25] McAdam, Doug and Cynthia Brandt. 2009. “Assessing the Effects of Voluntary Youth Service:
The Case of Teach For America. ” Social Forces 88(2): 945-970.
[26] McConahay, John B. 1983. “Modern Racism and Modern Discrimination: The Effects of Race,
Racial Attitudes, and Context on Simulated Hiring Decisions.” Personality and Social Psychology Bulletin 37(2): 551-558.
[27] McConnell, Allen R. and Jill M. Leibold. 2001. “Relations among the Implicit Association Test,
Discriminatory Behavior, and Explicit Measures of Racial Attitudes.” Journal of Experimental Social Psychology 37(5): 436-442.
[28] McCrary, Justin. 2008. “Manipulation of the Running Variable in the Regression Discontinuity
Design.” Journal of Econometrics, 142(2)698-714.
21

[29] Moss, Marc, Janet Swartz, Dawn Obeidallah, Gerrie Stewart, and Diane Greene. 2001. “AmeriCorps Tutoring Outcomes Study.” Cambridge, MA: Abt Associates.
[30] Pettigrew, Thomas F. 1998. “Intergroup Contact Theory.” Annual Review of Psychology 49:
65-85.
[31] Pettigrew, Thomas F. and Linda R. Tropp. 2006. “A Meta-Analytic Test of Intergroup Contact
Theory.” Journal of Personality and Social Psychology 90(5): 751-783.
[32] Pettigrew, Thomas F. and Linda R. Tropp. 2008. “How Does Intergroup Contact Reduce Prejudice? Meta-analytic Tests of Three Mediators.” European Journal of Social Psychology
38(6): 922-934.
[33] Phelps, Elizabeth A., Kevin J. O’Connor, William A. Cunningham, E. Sumie Funayama, J.
Christopher Gatenby, John C. Gore, Mahzarin R. Banaji. 2000. “Performance on Indirect
Measures of Race Evaluation Predicts Amygdala Activation.” Journal of Cognitive Neuroscience 12(5): 729-738.
[34] Rooth, Dan-Olof. 2007. “Implicit Discrimination in Hiring: Real World Evidence.” IZA Discussion Paper No. 2764.
[35] Rothermund, Klaus and Dirk Wentura. “Underlying Processes in the Implicit Association Test:
Dissociating Salience From Associations.” Journal of Experimental Psychology 133(2): 139165.
[36] Rudman, Laurie A. and Matthew R. Lee. 2002. “Implicit and Explicit Consequences of Exposure
to Violent and Misogynous Rap Music.” Group Processes and Intergroup Relations 5(2):
133-150.
[37] Sriram, N., and Anthony G. Greenwald. 2009. “The Brief Implicit Association Test.” Experimental Psychology 56: 283“294.
[38] Steffens, Melanie C. 2004. “Is the Implicit Association Test Immune to Faking? ” Experimental
Psychology 51(3): 165-179.
[39] U.S. Census Bureau. 2000. Census 2000 Brief.
[40] U.S. Department of Education. 2010. Institute of Education Sciences, National Center for
Education Statistics.
[41] Xu, Zeyu, Jane Hannaway, and Colin Taylor. 2009. “Making a Difference? The Effects of Teach
For America in High School.” Working Paper 17. Washington, DC: National Center for
Analysis of Longitudinal Data in Education Research.
[42] Yamaguchi, Ryoko, Philip Gordon, Christopher Mulvey, Fatih Unlu, Laura Simpson, JoAnn
Jastrzab, Christopher Winship, Cristofer Price, Ken Lam, Cay Bradley, Melanie BrownLyons, Robert Grimm, Kevin Cramer, LaMonica Shelton, Nathan Dietz, Lillian Dote, and
Shelby Jennings. 2008. “Still Serving: Measuring the Eight-Year Impact of AmeriCorps on
Alumni. 2008. ” Cambridge, MA: Abt Associates.

22

Figure 1

.1

.2

Fraction Serving in TFA
.3
.4

.5

Survey Response

-.03

-.02

-.01

0
p-value=0.868

.01

.02

.03

This figure presents actual and fitted values for 2007 TFA applicants. The actual values are plotted
in bins of size 0.0025. The fitted values come from a regression of the dependent variable on an
indicator variable for scoring above the cutoff score, interview score, and interview score interacted
with an indicator variable for scoring above the cutoff score. The p-value is the significance of the
indicator variable.

23

Figure 2

0

.2

Fraction Serving in TFA
.4
.6

.8

1

First Stage Results

-.03

-.02

-.01

0
p-value=0.000

.01

.02

.03

This figure presents actual and fitted values for 2007 TFA applicants. The actual values are plotted
in bins of size 0.0025. The fitted values come from a regression of the dependent variable on an
indicator variable for scoring above the cutoff score, a quadratic in interview score, and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. The
p-value is the significance of the indicator variable.

24

Figure 3
Summary of Main Results
Involvement in Education

-1

-.5

-.5

0

0

.5

.5

1

1

1.5

Faith in Education

-.03

-.02

-.01

0
p-value=0.000

.01

.02

.03

-.03

-.02

0
p-value=0.006

.01

.02

.03

.02

.03

.5
0
-.5
-1

-1

-.5

0

.5

1

Racial Tolerance

1

Political Beliefs

-.01

-.03

-.02

-.01

0
p-value=0.169

.01

.02

.03

-.03

-.02

-.01

0
p-value=0.047

.01

This figure presents actual and fitted values for 2007 TFA applicants who took the survey. The actual
values are plotted in bins of size 0.0025. The fitted values come from a regression of the dependent
variable on an indicator variable for scoring above the cutoff score, a quadratic in interview score,
and a quadratic in interview score interacted with an indicator variable for scoring above the cutoff
score. The p-value is the significance of the indicator variable. Each index was constructed by
standardizing the sum of all questions in that area to have a mean of zero and a standard deviation
of one. All standardized variables were converted to indicator variables using the median of the full
sample. The variables included in each composite variable are available in the data Appendix.

25

Figure 4
Faith in Education

.8
Fraction
.4
.6
.2
0

0

.2

Fraction
.4
.6

.8

1

The achievement gap is solvable

1

Poor children can compete with more advantaged children

-.03

-.02

-.01

0
p-value=0.008

.01

.02

.03

-.03

-.01

0
p-value=0.020

.01

.02

.03

.8
Fraction
.4
.6
.2
0

0

.2

Fraction
.4
.6

.8

1

Teachers are most important determinant of student success

1

Fraction of minorities that should graduate college

-.02

-.03

-.02

-.01

0
p-value=0.009

.01

.02

.03

-.03

-.01

0
p-value=0.023

.01

.02

.03

.8
Fraction
.4
.6
.2
0

0

.2

Fraction
.4
.6

.8

1

Teachers can ensure most students achieve

1

Schools can close the achievement gap

-.02

-.03

-.02

-.01

0
p-value=0.197

.01

.02

.03

-.03

-.02

-.01

0
p-value=0.000

.01

.02

.03

This figure presents actual and fitted values for 2007 TFA applicants. The actual values are plotted
in bins of size 0.0025. The fitted values come from a regression of the dependent variable on an
indicator variable for scoring above the cutoff score, a quadratic in interview score, and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. The
p-value is the significance of the indicator variable.

26

Figure 5
Involvement in Education

.75
Fraction
.5
.25
0

0

.25

Fraction
.5

.75

1

Employed in Education

1

Employed at K - 12 School

-.03

-.02

-.01

0
p-value=0.073

.01

.02

.03

-.03

-.01

0
p-value=0.018

.01

.02

.03

.02

.03

.75
Fraction
.5
.25
0

0

.25

Fraction
.5

.75

1

Interested in working in education

1

Service Very Important

-.02

-.03

-.02

-.01

0
p-value=0.018

.01

.02

.03

-.03

-.01

0
p-value=0.587

.01

.75
Fraction
.5
.25
0

0

.25

Fraction
.5

.75

1

Prefer urban school over suburban

1

Prefer teaching over finance

-.02

-.03

-.02

-.01

0
p-value=0.468

.01

.02

.03

-.03

-.02

-.01

0
p-value=0.073

.01

.02

.03

This figure presents actual and fitted values for 2007 TFA applicants. The actual values are plotted
in bins of size 0.0025. The fitted values come from a regression of the dependent variable on an
indicator variable for scoring above the cutoff score, a quadratic in interview score, and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. The
p-value is the significance of the indicator variable.

27

Figure 6
Political Idealism

.8
Fraction
.6
.4
.2

.2

.4

Fraction
.6

.8

1

We should spend more closing the achievement gap

1

Liberal

-.03

-.02

-.01

0
p-value=0.354

.01

.02

.03

-.03

-.01

0
p-value=0.371

.01

.02

.03

.8
Fraction
.6
.4
.2

.2

.4

Fraction
.6

.8

1

We should spend more fighting crime

1

We should spend more on welfare assistance

-.02

-.03

-.02

-.01

0
p-value=0.094

.01

.02

.03

-.03

-.02

-.01

0
p-value=0.891

.01

.02

.03

This figure presents actual and fitted values for 2007 TFA applicants. The actual values are plotted
in bins of size 0.0025. The fitted values come from a regression of the dependent variable on an
indicator variable for scoring above the cutoff score, a quadratic in interview score, and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. The
p-value is the significance of the indicator variable.

28

Figure 7
Racial Tolerance

.8
.2

-1

.4

-.5

0

Fraction
.6

.5

1

Whites/Asians and Blacks/Hispanics are equally intelligent

1

Racial Tolerance

-.03

-.02

-.01

0
p-value=0.047

.01

.02

.03

-.03

-.02

-.01

0
p-value=0.425

.01

.02

.03

-1

-.5

0

.5

1

White - Black Modern Racism Score

-.03

-.02

-.01

0
p-value=0.151

.01

.02

.03

This figure presents actual and fitted values for 2007 TFA applicants. The actual values are plotted
in bins of size 0.0025. The fitted values come from a regression of the dependent variable on an
indicator variable for scoring above the cutoff score, a quadratic in interview score, and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. The
p-value is the significance of the indicator variable.

29

Figure 8
Test of Quasi-Random Assignment
Black or Hispanic

0

.4

.6

Fraction

Fraction
.2

.8

1

.4

White or Asian

-.03

-.02

-.01

0
p-value=0.803

.01

.02

.03

-.03

-.02

0
p-value=0.688

.01

.02

.03

.02

.03

.02

.03

Fraction
.2
0

0

.2

Fraction

.4

.4

Received Pell Grant

.6

Male

-.01

-.03

-.02

-.01

0
p-value=0.212

.01

.02

.03

-.03

-.02

0
p-value=0.357

.01

Math or Science Major

0

3.25

GPA
3.5

Fraction
.2

.4

3.75

College GPA

-.01

-.03

-.02

-.01

0
p-value=0.050

.01

.02

.03

-.03

-.02

-.01

0
p-value=0.922

.01

This figure presents actual and fitted values for 2007 TFA applicants who took the survey. The actual
values are plotted in bins of size 0.0025. The fitted values come from a regression of the dependent
variable on an indicator variable for scoring above the cutoff score, a quadratic in interview score,
and a quadratic in interview score interacted with an indicator variable for scoring above the cutoff
score. The p-value is the significance of the indicator variable.

30

Figure 9

0

100

Observations
200

300

400

Number of Observations

-.06

-.03

0

.03

.06

Full Sample (p-value=0.946)
Survey Sample (p-value=0.787)

This figure presents actual and fitted values for 2007 TFA applicants. The actual values are plotted
in bins of size 0.0025. The fitted values come from a regression of the dependent variable on an
indicator variable for scoring above the cutoff score, a cubic in interview score, and a cubic in
interview score interacted with an indicator variable for scoring above the cutoff score. The p-value
is the significance of the indicator variable.

31

Figure 10
Main Results by Cohort
Involvement in Education

-1

-1

Reduced Form Estimate
-.5
0
.5

Reduced Form Estimate
-.5
0
.5

1

1

Faith in Education

2009

2008

2007

2006
2005
Application Year

2004

2003

2009

2008

2006
2005
Application Year

2004

2003

2004

2003

Reduced Form Estimate
-.5
0
.5
-1

-1

Reduced Form Estimate
-.5
0
.5

1

Racial Tolerance

1

Political Beliefs

2007

2009

2008

2007

2006
2005
Application Year

2004

2003

2009

2008

2007

2006
2005
Application Year

This figure presents point estimates and 95 percent confidence intervals for the reduced form effects
by cohort. The 2007 - 2009 cohorts are estimate using a regression discontinuity design, control
for a quadratic interview score and a quadratic in interview score interacted with scoring above the
cutoff score. The 2003 - 2006 cohorts are estimate using the interaction between interview subscores
that determines TFA selection. For the 2003 - 2006 cohorts we include fully nonparametric controls
for each interview subscore, and report the point estimate for an indicator variable equal to one if
the combination of interview subscores is eligible for TFA admission.

32

Table 1
Summary Statistics
Mean
0.07
0.74
0.06
0.07
0.05
3.58
0.19
0.17
0.12
0.35
0.39
0.28
0.46

TFA
SD
0.25
0.44
0.23
0.25
0.21
0.29
0.39
0.37
0.33
0.48
0.49
0.45
0.50

N
1,233
1,233
1,233
1,233
1,233
1,233
1,233
1,233
1,233
1,201
1,201
1,200
1,200

Faith in Education
Poor children can compete with more advantaged children
The achievement gap is solvable
Fraction of minorities that should graduate college
Teachers are most important determinant of student success
Schools can close the achievement gap
Teachers can ensure most students achieve

0.76
0.57
0.66
0.69
0.73
0.76

0.43
0.49
0.26
0.46
0.44
0.43

1,101
1,100
922
1,071
1,100
1,101

0.55
0.41
0.53
0.37
0.53
0.53

0.50
0.49
0.27
0.48
0.50
0.50

931
932
753
895
933
933

Involvement in Education
Employed at K - 12 School
Employed in Education
Service Very Important
Prefer teaching over finance
Prefer urban school over suburban
Interested in working in education

0.45
0.54
0.80
0.88
0.75
0.53

0.50
0.50
0.40
0.32
0.43
0.50

1,233
1,233
1,146
1,135
1,134
1,233

0.20
0.26
0.72
0.90
0.56
0.48

0.40
0.44
0.45
0.31
0.50
0.50

1,067
1,067
971
949
954
1,067

Political Beliefs
Liberal
We should spend more closing the achievement gap
We should spend more on welfare assistance
We should spend more fighting crime

0.66
0.88
0.32
0.38

0.47
0.32
0.47
0.48

1,092
1,041
1,041
1,041

0.64
0.85
0.41
0.44

0.48
0.35
0.49
0.50

923
875
875
875

Racial Tolerance
IAT White-Black
Whites/Asians and Blacks/Hispanics are equally intelligent
White - Black Modern Racism Score

0.06
0.60
0.09

1.02
0.49
0.92

1,001
905
946

-0.07
0.58
-0.10

0.97
0.49
1.08

855
783
794

Background Variables
Asian
White
Black
Hispanic
Mixed Race
College GPA
Received Pell Grant
Math or Science Major
Married
Mother has BA
Mother has more than BA
Father has BA
Father has more than BA

33

Not TFA
Mean SD
N
0.07
0.26 1,067
0.71
0.45 1,067
0.07
0.25 1,067
0.06
0.24 1,067
0.04
0.20 1,067
3.46
0.35 1,067
0.23
0.42 1,067
0.19
0.40 1,067
0.13
0.34 1,067
0.40
0.49 1,026
0.33
0.47 1,026
0.28
0.45 1,023
0.41
0.49 1,023

This table reports summary statistics for the 2007 TFA application cohort. The sample is all applicants who
answered at least one survey question.

34

35

Male
Female
p-value
2.261∗∗∗
0.867∗∗∗ 0.006
(0.823)
(0.218)
2029
3.289∗∗
0.917∗∗∗ 0.023
(1.444)
(0.364)
2290
0.960
−0.068
0.225
(0.790)
(0.215)
2019
0.738
0.648∗∗∗ 0.326
(0.750)
(0.255)
1848

Pell
No Pell
Grant
Grant
0.791∗∗∗
1.286∗∗
(0.305)
(0.616)
1485
1.111∗∗ −0.575
(0.509)
(0.976)
1667
0.108
0.546
(0.311)
(0.594)
1480
0.406
1.421
(0.335)
(0.944)
1341
0.226

0.730

0.029

p-value
0.010

This table reports first stage, reduced form and two-stage least squares estimates. The sample is all 2007 applicants who answered
at least one question included in the composite index. All regressions control for a quadratic in the interview score interacted with
an indicator variable for scoring above the cutoff score. Standard errors are clustered at the interview score level. *** = significant
at 1 percent level, ** = significant at 5 percent level, * = significant at 10 percent level.

Racial Tolerance

Political Beliefs

Involvement in Education

Faith in Education

Asian/
Black/
White
Hispanic p-value
0.892
1.142∗∗∗ 0.106
(0.552)
(0.249)
2032
1.413
1.471∗∗∗ 0.152
(0.985)
(0.410)
2294
−0.196
0.248
0.703
(0.516)
(0.253)
2022
1.015
0.612∗∗
0.142
(0.691)
(0.272)
1852

Table 2
Subsample Results

7

Online Appendix A: Data Description and Construction of Variables
NOT FOR PUBLICATION

Data for this project comes from a web-based survey administered between April 2010 and May 2011.
This appendix describes these data and details the procedures used to code them.

7.1

Summary Indices

Racial Tolerance
This variable consists of the white - black IAT scores.
Faith in Education
This variable was constructed by standardizing the sum of our education belief questions to have a mean
of zero and a standard deviation of one in the full sample. Rather than add dichotomous and standardized
variables together, we converted all standardized variables to indicator variables. Specifically, we created an
indicator variable equal to one if the variable was above the median of the full sample. The set of measures
include whether poor children can compete with more advantaged children, whether the achievement gap
is solvable, the percent of minorities that should be expected to graduate college, whether teachers are the
most important determinant of student success, whether schools alone can close the achievement gap, and
whether teachers can ensure most students achieve.
Involvement in Education
This variable was constructed by standardizing the sum of our employment questions to have a mean of zero
and a standard deviation of one in the full sample. Rather than add dichotomous and standardized variables
together, we converted all standardized variables to indicator variables. Specifically, we created an indicator
variable equal to one if the variable was above the median of the full sample. The set of measures include
whether an individual is employed at a K - 12 school, whether an individual is employed in education more
broadly, whether an individual believes service is important, whether an individual is interested in working
in education in the future, whether an individual prefers teaching in an urban district to a finance career,
and whether an individual prefers teaching in an urban district to a suburban district.
Political Idealism
This variable was constructed by standardizing the sum of our political belief questions to have a mean of
zero and a standard deviation of one in the full sample. Rather than add dichotomous and standardized
variables together, we converted all standardized variables to indicator variables. Specifically, we created an
indicator variable equal to one if the variable was above the median of the full sample. The set of measures
include whether an individual self identifies as liberal or very liberal, whether an individual believes we
should spend more on closing the achievement gap, whether an individual believes we should spend more on
welfare, and whether an individual believes we should spend more on fighting crime.

7.2

Background

Parent’s Education
Respondents were asked "What is the highest level of education that your mother has completed?" and

36

"What is the highest level of education that your father has completed?" The answer choices range from less
than a high school diploma to Ph.D., Ed.D., or D.B.A. We recoded this variable to be two variables. The
first is equal to one if the respondent’s mother has a B.A. The second is equal to one if the respondent’s
mother has more than a B.A. We recoded the father variable in the same way.
Parent’s Income
Respondents were asked "During your senior year of high school, what is your best estimate of your parents’
income?" The answer choices range from less than $20,000 to $100,000 in $20,000 bins, up to $150,000 in
$25,000 bins and up to more than $250,000 in $50,000 bins. The responses to the earnings questions were
transformed into real-valued variables using the mid-point of each bin and $275,000 for the top most bin.

7.3

Racial Tolerance

Implicit Association Test
We use a brief format Implicit Association Test (IAT), developed in Sriram and Greenwald (2009), to assess
the relative strength of automatic associations between "good" words and black faces. The IAT relies on
a respondent’s speed of response to measure the strength of their unconscious mental associations. The
respondent must quickly categorize words and pictures of faces that appear on the screen. Faces are to
be categorized as black or white and words as good or bad. Pairs of categories appear on either side of
the screen. If the stimulus belongs to categories on the right (left) of the screen, respondents are to hit a
key on the right (left) side of the keyboard. Each respondent completes a number of versions of the task.
In the "compatible" versions, the two categories on one side are paired according to a stereotype, such as
black with bad words and white with good words. In the incompatible versions, the categories are paired
counter-stereotypically, such as black with good words and white with bad words. The key insight of the race
IAT is that an implicit bias against blacks shows up as a response time differential between the compatible
and incompatible versions.
We normalize the IAT measure so that it has a mean of zero and a standard deviation of one across the
sample of survey respondents, with higher measures associated with a more anti-black response.
Number of minority friends
Respondents were asked "Of your 10 best friends, how many are black or Hispanic?" The variable was coded
directly from the response.
Minority relationship
Respondents were asked "Have you ever dated someone that is black or Hispanic?" We recoded this variable
to equal one if the respondent said yes.
Blacks and Hispanics do not value education
Respondents were asked if they agreed or disagreed with the statement "blacks and Hispanics do not value
education to the same extent that whites and Asians do." We recoded this variable to equal one if the
respondent did not disagree strongly.
Blacks disadvantaged due to ability or will power
Respondents were asked "On average, blacks have worse jobs, income and housing than whites. These differences are mostly due to..." The answer choices were discrimination, blacks being born with less ability to

37

learn, blacks not having the same opportunities for education, and blacks not having the same motivation
or will-power. We recoded this variable to equal one if the respondent answered that blacks do not have the
same will-power or ability.
Believes whites/Asians work harder than blacks/Hispanics
Respondents were asked "Where would you rank whites on this scale?" The answer choices range from almost
all are lazy to almost all are hard working on a seven point scale. This question was repeated for Asians,
blacks and Hispanics. We coded this variable to equal to one if respondents said that either whites or Asians
were more intelligent than either blacks or Hispanics.
Believes whites/Asians are more intelligent than blacks/Hispanics
Respondents were asked "Where would you rank whites on this scale?" The answer choices range from almost all are unintelligent to almost all are intelligent on a seven point scale. This question was repeated for
Asians, blacks and Hispanics. We coded this variable to equal to one if respondents said that either whites
or Asians were more intelligent than either blacks or Hispanics.
Modern Racism Scale
Respondents were asked on a five point scale whether they agreed or disagreed with the following statements:
1) Over the past few years, blacks have gotten more economically than they deserve; 2) Over the past few
years, the government and news media have shown more respect for blacks than they deserve; 3) It is easy
to understand the anger of black people in America; 4) Discrimination against blacks is no longer a problem
in the United States; 5) blacks are getting too demanding in their push for equal rights; 6) blacks should not
push themselves where they are not wanted. Each item was rescaled so that higher numbers were associated
with a more anti-black response, then a simple average was taken of the six questions. We then normalized
the scale to have mean zero and standard deviation one across the sample of survey respondents.

7.4

Faith in Education

Poor children can compete
Respondents were asked if they agreed or disagreed with the statement "Students from low-income communities cannot be expected to do as well in school as students from more affluent communities." We recoded
this variable to equal one if the respondent disagreed strongly.
Achievement gap is solvable
Respondents were asked if they agreed or disagreed with the statement "The student achievement gap between children in low-income and high-income areas is a solvable problem." We recoded this variable to equal
one if the respondent agreed strongly.
Percent of minorities that should be expected to graduate from college
Respondents were asked "17 percent of blacks 25 and older currently have a college degree. What percent
of minority children can we reasonably expect to graduate from a 4-year college?"
Teachers are the most important determinant of success
Respondents were asked "Who is most important in determining how well students perform in school?"

38

The available responses were students, teachers and parents. We recoded this variable to equal one if the
respondent answered teachers.
Schools alone can close the achievement gap
Respondents were asked if they agreed or disagreed with the statement "Students can only succeed if they
have parents or family at home helping them." We recoded this variable to equal one if the respondent
strongly disagreed.
Teachers can ensure most students achieve
Respondents were asked if they agreed or disagreed with the statement "There really is very little a teacher
can do to ensure that most of his/her students achieve at a high level." We recoded this variable to equal
one if the respondent strongly disagreed.
Teachers are the most important source of success
Respondents were asked "Which do you believe is the most important source of student success?" The
answer choices included student’s home background, student’s intellectual ability, student’s enthusiasm or
perseverance, teacher’s attention to the unique interests and abilities of the student, teacher’s use of effective
methods of teaching, and teacher’s enthusiasm or perseverance. We recoded the variable to equal one if the
respondent chose any of the three sources related to teachers.
Teachers can get through to all students
Respondents were asked if they agreed or disagreed with the statement "If teachers try really hard, they can
get through to even to the most difficult or unmotivated students." We recoded this variable to equal one if
the respondent agreed strongly.
Teachers are responsible for keeping students in school
Respondents were asked if they agreed or disagreed with the statement "I feel that teachers have the primary
responsibility for keeping students from dropping out of school." We recoded this variable to equal one if the
respondent agreed strongly.
Teachers can ensure student success
Respondents were asked if they agreed or disagreed with the statement "There really is very little a teacher
can do to ensure that most of his/her students achieve at a high level." We recoded this variable to equal
one if the respondent disagreed strongly.
Students can succeed even without family support
Respondents were asked if they agreed or disagreed with the statement "Students can only succeed if they
have parents or family at home helping them." We recoded this variable to equal one if the respondent
disagreed strongly.
When a teacher should be fired
Respondents were asked "A teacher should be dismissed if the following happens once." The answer choices
included fails to make adequate progress on standardized tests, receives a poor evaluation from school administrators, receives a parent complaint, is found to have an inappropriate personal relationship with a student,

39

is found to have a past criminal record, commits a crime outside of school hours, makes an inappropriate
racial/sexual remark to students in class, and physically disciplines a student. For each answer we recoded
the variable to equal one if the respondent indicated yes.

7.5

Involvement in Education

Employed in a K - 12 School
Respondents were asked about their current employer. We coded a respondent as working at a K - 12 school
if they reported working for a K-12 public school, a K-12 charter school, or a K-12 private school. Respondents were coded as not working in a K - 12 school if they worked for a for-profit company, a not-for-profit,
a college or university, or a local, state or federal government.
Employed in K - 12 education
Respondents were asked about their current employer. We coded a respondent as working in education if they
reported working for a K-12 public school, a K-12 charter school, a K-12 private school, or a not-for-profit
that focuses on K-12 education. Respondents were coded as not working in K - 12 education if they worked
for a for-profit company, a not-for-profit that does not focus on K-12 education, a college or university, or a
local, state or federal government.
Prefers finance
Respondents were presented with the following scenario: "Consider two possible occupations: 1. Teaching in
an urban public school district, 60 hours a week. 2. Working as a Vice President at a Middle Market Private
Equity Firm, 60 hours a week. Both the teaching job and the finance job pay $50,000 per year. Which job
would you prefer?" If the respondent chose teaching, the hypothetical salary for the private equity position
was increased by $25,000. This scenario repeated itself until the respondent chose the finance job or the
salary reached $500,000. If the respondent chose the private equity position, the hypothetical salary for the
teaching position increased in the same manner. We recode this variable to equal one if the respondent
prefers the teaching position at equal pay.
Prefers urban teaching
Respondents were presented with the following scenario: "Now consider two possible teaching positions: 1.
Teaching in an urban public school district, 60 hours a week. 2. Teaching in a suburban public school district, 60 hours a week. Both the urban job and the suburban job pay $50,000 per year. Which job would you
prefer?" If the respondent chose urban teaching, the hypothetical salary for the suburban teaching position
was increased by $25,000. This scenario repeated itself until the respondent chose the suburban teaching
job or the salary reached $500,000. If the respondent chose the suburban teaching position, the hypothetical
salary for the urban teaching position increased in the same manner. We recode this variable to equal one
if the respondent prefers the urban teaching position at equal pay.
Job satisfaction
Respondents were asked "Overall, how satisfied are you with this job?" The answer choices ranged from
extremely satisfied to extremely unsatisfied on a six point scale. We recoded this variable to equal one if the
respondent was extremely satisfied.
Importance of job characteristics

40

Respondents were asked "In any job, not just the one you have now, how important are each of the following
aspects?" The characteristics included intellectual challenge, stress level, salary and benefits and service
to society. The answer choices ranged from very important to not important on a three point scale. For
each characteristic we recoded this variable to equal one if the respondent thought a characteristic was very
important.
Interested in future careers
Respondents were asked "What is your level of interest in the following careers?" The careers included principal, elected office, political advocacy, business, law, science/technology, starting a social venture, work on
Teach For America staff, and teaching. The answer choices ranged from high interest to low interest on a
three point scale. For each career we recode this variable to equal one if the respondent has a high interest.

7.6

Political Idealism

Liberal
Respondents were asked "Where would you place yourself on this scale of political views?" The answer
choices ranged from very liberal to very conservative on a five point scale. We recoded this variable to equal
one if the respondent identifies as liberal or very liberal.
Spending
Respondents were asked "For each of the following issues, indicate if the government is spending too much
money, the right amount, or too little." For each category we consider - lowering the crime rate, closing the
achievement gap and increasing welfare/cash assistance for the poor - we recode this variable to equal one if
the respondent believes we should spend more money on that issue.

41

8

Online Appendix B: Full TFA Applicant Web-Based Survey
NOT FOR PUBLICATION

8.1

Applicant Contact Process

Below, we detail the process used to contact TFA applicants regarding our survey.
A. Email (April 2010 – June 2010, May 2011)
TFA provided a total of 63,262 email addresses for applicants in the 2003 to 2009 cohorts. Each person
received up to three emails between April 2010 to June 2010. A final email was sent to non-alumni in May
2011.
The fraction of emails that “bounced” was higher for non-alumni and older cohorts. 11 percent of 2003
alumni and 36 percent on non-alumni emails “bounced,” while only 2 percent of 2009 alumni and 6 percent
on non-alumni emails “bounced.” Of those receiving the email, approximately 35 percent of alumni and 25
percent of non-alumni opened the email, with over 80 percent of those opening emails starting the survey.
B. Facebook
The second major touch point, for those who did not complete a survey after the initial emails, was
to find TFA applicants on Facebook using accounts specifically created for the TFA/EdLabs survey. First,
accounts for “Harvard EdLabs” were created on Facebook. Account pages included an overview of, and
a link to, the survey. Second, we used email addresses from TFA to manually search for both alumni and
non-admits on Facebook and attempted to “friend” them. Unfortunately, Facebook does not allow individual
profiles to be used for any commercial gain, and 5 of the 16 accounts were disabled. Even for those accounts
that were not disabled by Facebook, the outreach (i.e. the number of alumni and non-alumni that were
successfully added as friends) was not particularly successful. More specifically, 2,612 friend requests were
made resulting in 53 friend confirmations.
C. Phone calls (July – May)
The third and final attempt at contacting TFA non-alumni was personal phone calls, using phone numbers
from TFA application records. Non-alumni that had not yet taken the survey were contacted via phone in
the evenings during three iterations: in the first, during the summer, 400 numbers from the 2007 non-admits
were called personally while 2,680 2007 non-admits were called using an online, automated call system. The
400 calls were split into two groups for a brief experiment: 200 recipients would be offered a $20 Amazon
gift card for completing the survey, while the other 200 would not be offered any incentive. After the two
groups produced nearly identical rates of taking the survey, we decided to proceed with later callings without
offering incentives. The 2,680 numbers that were called using an automated call system heard a brief, 30
second recording that provided context about and a link to the survey.
During the second round of personal phone calls, 2,412 of the 2007 non-admits that were previously called
using the automated phone system and had not yet taken the survey were called. As before, voicemails were
left for those who did not answer the phone; in many (though not all) cases, those people were called again
a few weeks later.
During the final third round, the non-admits from the 2003 - 2006 and 2008 - 2009 cohorts were called
using the automated phone system then personal phone calls. These calls took place between April 2011
and May 2011.

42

8.2

Survey

Below is the full survey administered online between April 2010 and May 2011.
A. Demographics:
1. Please enter your preferred Email address below (e.g., jane.doe@acme.com).
2. Please enter your first name and last name below (e.g., John Smith).
3. Please indicate your birthdate using the dropdowns below.
4. Please indicate your sex.
5. Which of the following best describes your race/ethnicity? Asian, Pacific Islander, black, Non-Hispanic,
black, Hispanic, Native American or Alaskan Native, white, Non-Hispanic, white, Hispanic, Mixed
Race, black and white, Other Mixed Race, Other
6. What year did you apply to Teach For America?
7. Where do you live now? (e.g., 123 Single Street, Simpletown, WA, 92403)? Street Address, City,
State, Zipcode
8. Taken all together, how would you say things are these days? Would you say that you are very happy,
pretty happy or not too happy? Very happy? Pretty happy? Not too happy?
B. Background Information:
1. Where were you born? City, State, Country.
2. What High School did you graduate from? High School, City, State.
3. Which option below most accurately reflects your current relationship status? I am married, I am
single (never married), I am living with someone in a marriage like relationship, I am separated, I am
divorced, I am widowed.
4. How many children do you have?
5. What is the highest level of education that your mother has completed?, Less than a high school
diploma, High School diploma, Some college/vocational school, Bachelor’s degree, Master’s degree,
Law degree (JD, LLB), Medical degree (MD, DDS, DVM, etc.), Ph.D., Ed.D., D.B.A., Other/Not
Applicable
6. What is the highest level of education that your father has completed? Same options as above.
7. During your senior year of high school, what is your best estimate of your parents’ income? Do not
know, < $20,000, $20,000 to $39,999, $40,000 to $59,999, $60,000 to $79,999, $80,000 to $99,999,
$100,000 to $124,999, $125,000 to $149,999, $150,000 to $199,999, $200,000 to $250,000, > $250,000
8. We are interested in your educational history SINCE you applied to Teach For America. Please fill in
the level and type of degree for your three highest degrees obtained SINCE you applied to Teach For
America (e.g., M.A. in Education).
C. Teach For America:

43

1. How likely is it that you would recommend Teach For America to a friend or family member? Extremely
Likely, Moderately Likely, Somewhat Likely, Slightly Likely, Not at all Likely
2. Did you serve in Teach For America?
3. Where did you serve? Type in School, City, State (e.g., South Eugene HS, Eugene, OR)
4. How many years did you teach in the district where you were placed?
5. Looking back, do you wish you had ...Taught in the district for more years, Taught in the district the
same amount of time, Taught in the district for fewer years
6. How satisfied were you with your principal at your placement school? Extremely satisfied, Very
satisfied, Satisfied, Unsatisfied, Very unsatisfied, Extremely unsatisfied
7. How satisfied were you with your relationship with other teachers at your placement school? Same
answer choices as above.
8. If you could do it all over again, would you serve as a Teach For America corps member?
D. Employment
1. Your current employer is a ...For-profit company, Not-for-profit that focuses on K-12 education, Notfor-profit that does not focus on K-12 education, K-12 public school, K-12 charter school, K-12 private
school, College or university, Local, state or federal government, Other
2. What is your current or most recent occupation? Please be as specific as possible (e.g., high school
math teacher)
3. What was your title when you started with your current employer? (e.g., Vice President of Sales)
4. What is your current title?
5. In what year did you start working for your current employer?
6. What is your current annual income? < $20,000, $20,000 to $39,999, $40,000 to $59,999, $60,000
to $79,999, $80,000 to $99,999, $100,000 to $124,999, $125,000 to $149,999, $150,000 to $199,999,
$200,000 to $250,000, > $250,000
7. What was your annual income when you started this job? Same as Above
8. How many hours per week do you typically work at this job? < 30 hours, 31-35 hours, 36-40 hours,
41-45 hours, 46-50 hours, 51-55 hours, 56-60 hours, 61-65 hours, 66-70 hours, > 70 hours
9. Overall, how satisfied are you with this job? Extremely Satisfied, Very Satisfied, Satisfied, Unsatisfied,
Very Unsatisfied, Extremely Unsatisfied
10. In any job, not just the one you have now, how important are each of the following aspects? Very
Important, Somewhat Important, Not Important
Intellectual Challenge
Stress Level
Salary and Benefits
Service to Society

44

11. In your current job, how satisfied are you with each of the following aspects? Very Satisfied , Somewhat
Satisfied, Not Satisfied
Same as above.
12. Consider two possible occupations:
1. Teaching in an urban public school district, 60 hours a week.
2. Working as a Vice President at a Middle Market Private Equity Firm, 60 hours a week.
Both the teaching job and the finance job pay $50,000 per year.
Which job would you prefer?
13. Now consider two possible teaching positions:
1. Teaching in an urban public school district, 60 hours a week.
2. Teaching in a suburban public school district, 60 hours a week.
Both the urban job and the suburban job pay $50,000 per year.
Which job would you prefer?
14. We are interested in your past jobs. What were your last three occupations and titles, prior to working
for your current employer? Please be as specific as possible.
15. What is your level of interest in the following careers? High Interest, Some Interest, No Interest
Principal/Head of School
Elected Office
Political Advocacy
Business
Law
Science/Technology
Starting a Social Venture
Work on Teach For America staff
Teaching
E. Social and Civic Engagement:
1. In a typical month, how many total hours do you spend doing volunteer or charitable work? None,
1-5 hours, 5-10 hours, 11-15 hours, 16-20 hours, 21-25 hours, > 25 hours
2. Have you participated as a volunteer for any of the following groups during the past year? Select all
that apply.
Educational Work with Kids (e.g. tutoring)
Other Educational Work (e.g. school board, school governance organizations)
Other Work with Kids (e.g. Big Brother/Big Sisters, coaching)
Other Volunteer Work (religious organizations, alumni organizations)
3. Have you donated money to any charitable organization or group during the past year? Which group?
How much?
Name of Organization:
Amount Donated: $

45

4. Of your 10 best friends, how many are black or Hispanic?
5. Have you ever dated someone that is black or Hispanic? Yes, No
F. Beliefs:
1. For each of the following issues, indicate if the government is spending too much money, the right
amount, or too little.
Protecting the Environment
Improving the Nation’s Healthcare System
Lowering the Crime Rate
Reducing the level of Drug Addiction
Closing the Achievement Gap
Increasing Welfare/Cash Assistance for the Poor
Beliefs (Part One): 2/15 52% of survey complete
2. Where would you place yourself on this scale of political views?
Very Liberal
Liberal
Moderate
Conservative
Very Conservative
3. What type of school do you plan to send your children to?
Traditional public school
Charter school
Magnet school
Religiously affiliated or denominational private school
Private prep school
Not yet decided
Not applicable as I am not planning to have children
4. Which do you believe is the most important source of student success?
Student’s
Student’s
Student’s
Teacher’s
Teacher’s
Teacher’s

home background
intellectual ability
enthusiasm or perseverance
attention to the unique interests and abilities of the student
use of effective methods of teaching
enthusiasm or perseverance

The next series of questions asks whether you agree or disagree with a particular statement.
5. The student achievement gap between children in low-income and high-income areas is a solvable
problem. Agree strongly, Agree somewhat, Neither agree nor disagree, Disagree somewhat, Disagree
strongly

46

6. If teachers try really hard, they can get through to even to the most difficult or unmotivated students.
Same as above.
7. I feel that teachers have the primary responsibility for keeping students from dropping out of school.
8. There really is very little a teacher can do to ensure that most of his/her students achieve at a high
level.
9. Students can only succeed if they have parents or family at home helping them.
10. Students from low-income communities cannot be expected to do as well in school as students from
more affluent communities.
11. Great schools can close the achievement gap.
12. What are the three factors you think are the most significant causes of the achievement gap?
13. 17 percent of blacks 25 and older currently have a college degree. What percent of minority children
can we reasonably expect to graduate from a 4-year college?
14. Who is most important in determining how well students perform in school? Students, Teachers,
Parents
15. A teacher should be dismissed if the following happens once. Select all that apply.
Fails to make adequate progress on standardized tests
Receives a poor evaluation from school administrators
Receives a parent complaint
Is found to have an inappropriate personal relationship with a student
Is found to have a past criminal record
Commits a crime outside of school hours
Makes an inappropriate racial/sexual remark to students in class
Physically disciplines a student
G. Knowledge:
1. On nationally standardized math and reading exams such as the Long Term National Assessment of
Educational Progress (NAEP), the average black 8th grader tends to score how many grade levels
behind the average white student? One grade level behind, Two grade levels behind, Three grade
levels behind, Four grade levels behind, Five grade levels behind, Six or more grade levels behind
2. On nationally standardized math and reading exams such as the Long Term National Assessment of
Educational Progress (NAEP), the average Hispanic 8th grader tends to score how many grade levels
behind the average white student? Same as above.
3. What percentage of black, Hispanic, and white men aged 18 to 24 are incarcerated, on parole, or on
probation? % of black men aged 18-24, % of Hispanic men aged 18-24, % of white men aged 18-24
4. What percentage of black, Hispanic, and white male youth are currently active gang members? % of
black youth, % of Hispanic youth, % of white youth
5. What percentage of black, Hispanic, and white children are currently living in single parent households?
% of black children, % of Hispanic children, % of white children
6. What percentage of black, Hispanic, and white children are born out of wedlock? Same as above.

47

7. What percentage of black, Hispanic, and white mothers are currently eligible for state or federal
financial assistance (i.e. welfare)? % of black mothers, % of Hispanic mothers, % of white mothers
H. Beliefs
1. In the long run, hard work usually brings a better life and success; luck and connections don’t matter
that much. Agree strongly, Agree somewhat, Neither agree nor disagree, Disagree somewhat, Disagree
strongly
2. The government should take more responsibility to ensure that everyone is provided for. Same as
above.
3. Poor people in this country can escape from poverty. Same as above.
4. blacks and Hispanics do not value education to the same extent that whites and Asians do. Same as
above.
5. Why are people poor in this country? They are poor because society treats them unfairly, They are
poor because of laziness and lack of will power
6. On average, blacks have worse jobs, income and housing than whites. These differences are mostly
due to ...Discrimination blacks being born with less ability to learn, blacks not having the same
opportunities for education, blacks not having the same motivation or will-power
7. Where would you rank whites on this scale?
Almost all are lazy
Many more are lazy than hardworking
More are lazy than hardworking
Comparable numbers of lazy and hardworking
More are hardworking than lazy
Many more are hardworking than lazy
Almost all are hardworking
8. Where would you rank blacks on this scale? Same as above.
9. Where would you rank Hispanics on this scale? Same as above.
10. Where would you rank Asians on this scale?
11. Where would you rank whites on this scale?
Almost all are unintelligent
Many more are unintelligent than intelligent
More are unintelligent than intelligent
Comparable numbers of unintelligent and intelligent
More are intelligent than unintelligent
Many more are intelligent than unintelligent
Almost all are intelligent
12. Where would you rank blacks on this scale? Same as above.
13. Where would you rank Hispanics on this scale? Same as above.

48

14. Where would you rank Asians on this scale? Same as above.
15. Over the past few years, blacks have gotten more economically than they deserve. Agree strongly,
Agree somewhat, Neither agree nor disagree, Disagree somewhat, Disagree strongly
16. Over the past few years, the government and news media have shown more respect for blacks than
they deserve. Same as above.
17. It is easy to understand the anger of black people in America. Same as above.
18. Discrimination against blacks is no longer a problem in the United States. Same as above.
19. blacks are getting too demanding in their push for equal rights. Same as above.
20. blacks should not push themselves where they are not wanted. Same as above.

49

Online Appendix C: Additional Results

Fraction
.25

.5

Appendix Figure 1
Response Rate by Cohort

0

9

2009

2008

2007

2006
2005
Application Year
TFA

50

Not TFA

2004

2003

-.1

-.05

Reduced Form Estimate
0
.05
.1

.15

Appendix Figure 2
Survey Response by Cohort

2009

2008

2007

2006
2005
Application Year

2004

2003

This figure presents point estimates and 95 percent confidence intervals for the reduced form difference in
response rates by cohort. The 2007 - 2009 cohorts are estimate using a regression discontinuity design,
control for a quadratic in interview score and a quadratic in interview score interacted with scoring above
the cutoff score. The 2003 - 2006 cohorts are estimate using the interaction between interview subscores
that determines TFA selection. For the 2003 - 2006 cohorts we include fully nonparametric controls for each
interview subscore, and report the point estimate for an indicator variable equal to one if the combination
of interview subscores is eligible for TFA admission.

51

Appendix Figure 3
Test of Quasi-Random Assignment by Cohort
Black or Hispanic

-.3

-.3

Reduced Form Estimate
-.15
0
.15

Reduced Form Estimate
-.15
0
.15

.3

.3

White or Asian

2009

2008

2007

2006
2005
Application Year

2004

2003

2009

2008

2007

2004

2003

2004

2003

Reduced Form Estimate
-.15
0
.15
-.3

-.3

Reduced Form Estimate
-.15
0
.15

.3

College GPA

.3

Male

2006
2005
Application Year

2009

2008

2007

2006
2005
Application Year

2004

2003

2009

2008

2007

2006
2005
Application Year

-.3

Reduced Form Estimate
-.15
0
.15

.3

Math or Science Major

2009

2008

2007

2006
2005
Application Year

2004

2003

This figure presents point estimates and 95 percent confidence intervals for the reduced form effects by
cohort. The 2007 - 2009 cohorts are estimate using a regression discontinuity design, control for a quadratic
in interview score and a quadratic in interview score interacted with scoring above the cutoff score. The 2003
- 2006 cohorts are estimate using the interaction between interview subscores that determines TFA selection.
For the 2003 - 2006 cohorts we include fully nonparametric controls for each interview subscore, and report
the point estimate for an indicator variable equal to one if the combination of interview subscores is eligible
for TFA admission.

52

Appendix Table 1
Robustness of Index Outcomes
Polynomial Order
Bandwidth
Faith in Education

Involvement in Education

Political Beliefs

Racial Tolerance

0.02
1.462∗∗∗
(0.323)
1348
1.898∗∗∗
(0.551)
1541
0.408
(0.311)
1339
0.658∗
(0.355)
1231

1
0.04
0.960∗∗∗
(0.161)
1939
1.175∗∗∗
(0.268)
2193
0.123
(0.161)
1929
0.552∗∗∗
(0.176)
1766

0.06
0.871∗∗∗
(0.131)
2032
1.057∗∗∗
(0.216)
2294
0.083
(0.132)
2022
0.464∗∗∗
(0.142)
1852

0.02
2.969∗∗
(1.283)
1348
4.324∗
(2.413)
1541
0.771
(0.933)
1339
0.527
(1.191)
1231

2
0.04
1.568∗∗∗
(0.386)
1939
1.915∗∗∗
(0.659)
2193
0.465
(0.370)
1929
0.763∗
(0.428)
1766

0.06
1.256∗∗∗
(0.270)
2032
1.562∗∗∗
(0.459)
2294
0.258
(0.265)
2022
0.748∗∗∗
(0.301)
1852

This table reports two-stage least squares estimates with various polynomials and bandwidths. The sample
is all 2007 applicants who answered at least one question included in the composite index. All regressions
control for a quadratic in interview score and a quadratic in interview score interacted with an indicator
variable for scoring above the cutoff score. Standard errors are clustered at the interview score level. *** =
significant at 1 percent level, ** = significant at 5 percent level, * = significant at 10 percent level.

53

Appendix Table 2
Summary of Main Results

Faith in Education

Involvement in Education

Political Beliefs

Racial Tolerance

FS
0.313∗∗∗
(0.056)
2032
0.287∗∗∗
(0.053)
2294
0.309∗∗∗
(0.056)
2022
0.289∗∗∗
(0.058)
1852

RF
0.501∗∗∗
(0.129)
2032
0.554∗∗∗
(0.200)
2294
0.175
(0.127)
2022
0.270∗∗
(0.136)
1852

TSLS
1.598∗∗∗
(0.442)
2032
1.931∗∗∗
(0.754)
2294
0.565
(0.431)
2022
0.934∗
(0.503)
1852

TSLS
w/controls
1.582∗∗∗
(0.439)
2032
1.880∗∗∗
(0.745)
2294
0.603
(0.431)
2022
0.980∗∗
(0.501)
1852

This table reports first stage, reduced form, and two-stage least squares estimates. The sample is all 2007
applicants who answered at least one question included in the composite index. All regressions control for
a quadratic in interview score and a quadratic in interview score interacted with an indicator variable for
scoring above the cutoff score. Standard errors are clustered at the interview score level. *** = significant
at 1 percent level, ** = significant at 5 percent level, * = significant at 10 percent level.

54

Appendix Table 3
Faith in Education

Poor children can compete with more advantaged children

The achievement gap is solvable

Fraction of minorities that should graduate college

Teachers are most important determinant of student success

Schools can close the achievement gap

Teachers can ensure most students achieve

FS
0.312∗∗∗
(0.056)
2028
0.312∗∗∗
(0.056)
2028
0.320∗∗∗
(0.061)
1672
0.309∗∗∗
(0.057)
1963
0.312∗∗∗
(0.056)
2029
0.313∗∗∗
(0.056)
2030

RF
0.164∗∗∗
(0.062)
2028
0.150∗∗
(0.065)
2028
0.099∗∗∗
(0.038)
1672
0.148∗∗
(0.065)
1963
0.081
(0.062)
2029
0.265∗∗∗
(0.060)
2030

TSLS
0.526∗∗∗
(0.201)
2028
0.482∗∗
(0.213)
2028
0.310∗∗∗
(0.122)
1672
0.480∗∗
(0.214)
1963
0.258
(0.200)
2029
0.848∗∗∗
(0.223)
2030

TSLS
w/controls
0.528∗∗∗
(0.201)
2028
0.477∗∗
(0.212)
2028
0.303∗∗∗
(0.121)
1672
0.480∗∗
(0.213)
1963
0.256
(0.198)
2029
0.845∗∗∗
(0.221)
2030

This table reports first stage, reduced form, and two-stage least squares estimates. The sample is all 2007
applicants who took our web-survey. All regressions control for a quadratic in interview score and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. Standard errors
are clustered at the interview score level. *** = significant at 1 percent level, ** = significant at 5 percent
level, * = significant at 10 percent level.

55

Appendix Table 4
Involvement in Education

Employed at K - 12 School

Employed in Education

Service Very Important

Prefer teaching over finance

Prefer urban school over suburban

Interested in working in education

FS
0.287∗∗∗
(0.053)
2294
0.287∗∗∗
(0.053)
2294
0.292∗∗∗
(0.055)
2113
0.309∗∗∗
(0.056)
2081
0.286∗∗∗
(0.056)
2085
0.287∗∗∗
(0.053)
2294

RF
0.100∗
(0.056)
2294
0.138∗∗
(0.059)
2294
0.130∗∗
(0.055)
2113
0.029
(0.040)
2081
0.107∗
(0.060)
2085
0.033
(0.061)
2294

TSLS
0.348∗
(0.199)
2294
0.481∗∗
(0.211)
2294
0.447∗∗
(0.206)
2113
0.095
(0.132)
2081
0.375∗
(0.214)
2085
0.115
(0.213)
2294

TSLS
w/controls
0.355∗
(0.198)
2294
0.475∗∗
(0.210)
2294
0.458∗∗
(0.206)
2113
0.084
(0.132)
2081
0.359∗
(0.212)
2085
0.091
(0.212)
2294

This table reports first stage, reduced form, and two-stage least squares estimates. The sample is all 2007
applicants who took our web-survey. All regressions control for a quadratic in interview score and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. Standard errors
are clustered at the interview score level. *** = significant at 1 percent level, ** = significant at 5 percent
level, * = significant at 10 percent level.

56

Appendix Table 5
Political Idealism

Liberal

We should spend more closing the achievement gap

We should spend more on welfare assistance

We should spend more fighting crime

FS
RF
0.310∗∗∗
0.058
(0.056)
(0.062)
2011
2011
∗∗∗
0.304
0.040
(0.058)
(0.044)
1912
1912
∗∗∗
0.304
0.108∗
(0.058)
(0.065)
1912
1912
∗∗∗
0.304
−0.009
(0.058)
(0.066)
1912
1912

TSLS
0.186
(0.204)
2011
0.131
(0.148)
1912
0.356
(0.234)
1912
−0.030
(0.216)
1912

TSLS
w/controls
0.188
(0.204)
2011
0.138
(0.148)
1912
0.373
(0.234)
1912
0.004
(0.215)
1912

This table reports first stage, reduced form, and two-stage least squares estimates. The sample is all 2007
applicants who took our web-survey. All regressions control for a quadratic in interview score and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. Standard errors
are clustered at the interview score level. *** = significant at 1 percent level, ** = significant at 5 percent
level, * = significant at 10 percent level.

57

Appendix Table 6
Racial Tolerance

Racial Tolerance

Whites/Asians and Blacks/Hispanics are equally intelligent

White - Black Modern Racism Score

FS
RF
0.289∗∗∗ 0.270∗∗
(0.058)
(0.136)
1852
1852
∗∗∗
0.349
0.056
(0.060)
(0.070)
1685
1685
∗∗∗
0.305
0.205
(0.061)
(0.143)
1738
1738

TSLS
0.934∗
(0.503)
1852
0.160
(0.203)
1685
0.674
(0.490)
1738

TSLS
w/controls
0.980∗∗
(0.501)
1852
0.145
(0.201)
1685
0.633
(0.490)
1738

This table reports first stage, reduced form, and two-stage least squares estimates. The sample is all 2007
applicants who took our web-survey. All regressions control for a quadratic in interview score and a quadratic
in interview score interacted with an indicator variable for scoring above the cutoff score. Standard errors
are clustered at the interview score level. *** = significant at 1 percent level, ** = significant at 5 percent
level, * = significant at 10 percent level.

58

Appendix Table 7
Test of Quasi-Random Assignment

White or Asian

Black or Hispanic

Male

Received Pell Grant

Math or Science Major

College GPA

FS
0.287∗∗∗
(0.053)
2294
0.287∗∗∗
(0.053)
2294
0.288∗∗∗
(0.053)
2290
0.287∗∗∗
(0.053)
2294
0.287∗∗∗
(0.053)
2294
0.287∗∗∗
(0.053)
2294

RF
0.015
(0.059)
2294
−0.013
(0.033)
2294
−0.069
(0.055)
2290
−0.045
(0.049)
2294
0.004
(0.045)
2294
−0.069∗∗
(0.035)
2294

TSLS
0.051
(0.206)
2294
−0.047
(0.118)
2294
−0.240
(0.201)
2290
−0.158
(0.173)
2294
0.015
(0.158)
2294
−0.240∗
(0.126)
2294

TSLS
full sample
−0.032
(0.116)
7338
−0.016
(0.085)
7338
−0.240
(0.201)
2290
−0.080
(0.099)
7338
0.037
(0.087)
7338
−0.227∗∗∗
(0.075)
7338

This table reports first stage, reduced form, and two-stage least squares estimates for various baseline characteristics. The sample is all 2007 applicants. All regressions control for a quadratic in interview score and a
quadratic in interview score interacted with an indicator variable for scoring above the cutoff score. Standard
errors are clustered at the interview score level. *** = significant at 1 percent level, ** = significant at 5
percent level, * = significant at 10 percent level.

59

Appendix Table 8
Number of Observations
Bin
Size
0.0010

0.0025

0.0050

0.0075

0.0100

Survey
Sample
−0.319
(3.471)
112
−2.440
(8.962)
48
−3.230
(21.866)
24
−11.581
(20.629)
16
−71.076∗∗
(26.195)
12

Full
Sample
1.598
(7.056)
118
1.694
(24.762)
48
18.846
(47.167)
24
59.263
(59.457)
16
−61.337
(37.426)
12

This table reports reduced form results testing for differences in the number of observations around the
interview score cutoff. The sample is 2007 TFA applicants. *** = significant at 1 percent level, ** =
significant at 5 percent level, * = significant at 10 percent level.

60

