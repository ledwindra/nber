NBER WORKING PAPER SERIES

HETEROSKEDASTICITY-ROBUST INFERENCE IN FINITE SAMPLES
Jerry A. Hausman
Christopher J. Palmer
Working Paper 17698
http://www.nber.org/papers/w17698
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2011

The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research. Palmer acknowledges support from the National Science
Foundation Graduate Research Fellowship under Grant No. 0645960.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
Â© 2011 by Jerry A. Hausman and Christopher J. Palmer. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including Â© notice, is given to the source.

Heteroskedasticity-Robust Inference in Finite Samples
Jerry A. Hausman and Christopher J. Palmer
NBER Working Paper No. 17698
December 2011
JEL No. C01,C12
ABSTRACT
Since the advent of heteroskedasticity-robust standard errors, several papers have proposed adjustments
to the original White formulation. We replicate earlier findings that each of these adjusted estimators
performs quite poorly in finite samples. We propose a class of alternative heteroskedasticity-robust
tests of linear hypotheses based on an Edgeworth expansions of the test statistic distribution. Our preferred
test outperforms existing methods in both size and power for low, moderate, and severe levels of heteroskedasticity.
Jerry A. Hausman
Economics Department
MIT, Room E52-271A
50 Memorial Drive
Cambridge, MA 02142
and NBER
jhausman@mit.edu
Christopher J. Palmer
Economcis Department
MIT, Room E52-391
50 Memorial Drive
Cambridge, MA 02142
cjpalmer@mit.edu

Heteroskedasticity-Robust Inference in Finite Samples

Jerry Hausmanâˆ— and Christopher Palmerâ€ 
Massachusetts Institute of Technology
December 2011

Abstract
Since the advent of heteroskedasticity-robust standard errors, several papers have proposed adjustments to the original White formulation. We replicate earlier ndings that each of these adjusted estimators performs quite poorly in nite samples. We propose a class of alternative heteroskedasticity-robust
tests of linear hypotheses based on an Edgeworth expansions of the test statistic distribution. Our preferred test outperforms existing methods in both size and power for low, moderate, and severe levels of
heteroskedasticity.

Keywords : Heteroskedasticity; nite samples; Edgeworth expansion; bootstrap
JEL Codes : C1, C12
1

Introduction

The use of  White standard errors (White, 1980) is now prevalent in economics. However, it has long been
known that t-tests based on White standard errors over-reject when the null hypothesis is true and the
sample is not large. Indeed, it is not uncommon for the actual size of the test to be 0.15 when the nominal
size is the usual 0.05. Various xes to estimating the middle matrix

(X 0 Î£X) in equation (2) below have been

introduced. We consider the performance of some of these methods in this paper; see MacKinnon (2011) for
a more comprehensive discussion. The major nding seems to be that these attempted xes do not solve
the problem, as we demonstrate subsequently.
The other major approach has been to bootstrap the t-test, which will get the correct size (on average).
We benchmark the performance of techniques in this paper with the Wild bootstrap (WB), which MacKinnon
(2011) nds to perform best in terms of power. Hall (1992) has demonstrated that with a pivotal test statistic,
as occurs here, the bootstrapped test will be accurate to the second order in

n

rather than to the rst order,

which underlies the asymptotic expansion used for the White approach.
In this paper, we directly apply the second-order Edgeworth approximation approach to the test statistic
distribution using the results of Rothenberg (1988).

Hausman and Kursteiner (2008) used this approach

to estimate the covariance of the feasible generalized least squares estimator (FGLS) and found a marked
improvement. However, we nd that the second-order Edgeworth approach has signicant size distortions in
this setting. Instead, we nonparametrically bootstrap the covariance matrix of the parameter vector

Î²

and

then use the second-order Edgeworth expansion to modify the t-statistic critical value. Using MacKinnon's
(2011) Monte Carlo design, we nd this approach has excellent size properties and has power that is generally superior to the Wild bootstrap approach. We call this technique the  second-order bootstrap (SOB)
approach and recommend it for use in applied research, particularly when there are sample size concerns.
âˆ— Corresponding Author. John and Jennie S. MacDonald Professor of Economics, Economics Department, Massachusetts
Institute of Technology, E52-271D, 50 Memorial Drive, Cambridge, MA, 02142, USA and NBER; E-mail: jhausman@mit.edu;
Telephone: (617) 253-3644; Fax: (617) 253-1330.
â€  PhD Candidate, MIT Economics Department; E-mail: cjpalmer@mit.edu. Palmer acknowledges support from the National
Science Foundation Graduate Research Fellowship under Grant No. 0645960.

1

2

Traditional Robust Standard Error Estimators

For the model

y = XÎ² + u
with

V ar(u) = Î£,

the variance of the parameter vector

Î²Ì‚

(1)

estimated by OLS is

V ar(Î²Ì‚) = (X 0 X)âˆ’1 X 0 Î£X(X 0 X)âˆ’1 .
Let

n

denote the sample size and

k

denote the dimension of

Î².

covariance matrix estimators in the literature (commonly denoted

(2)

All of the heteroskedasticity-consistent

HCj

for

j = 0, 1, 2,

etc.) have the same

sandwich estimator form with variations in the estimated sample matrix that is used for

Î£.

We are interested in test statistics of the form

T =

c0 Î²Ì‚ âˆ’ c0 Î²0
p
c0 VÌ‚ c

(3)

H0 : c0 Î² = c0 Î²0 ,
0
estimating (X Î£X)

corresponding to a null hypothesis about a linear combination of the estimated parameters
where

VÌ‚

is an asymptotically valid estimate of

1

V ar(Î²Ì‚).

The following are approaches to

that have appeared in the literature.
1.

HC0

(White, 1980) is the original formulation used in White standard errors. White's (1980) contri-

bution was to recognize that

0 Î£X
Xd

is a consistent estimator of

Î£ = diag
where
2.

HC1

uÌ‚2i



X 0 Î£X

when using the sample matrix

uÌ‚2i

are the tted residuals from estimating (1) via OLS.

(MacKinnon and White, 1985) adjusts for degrees of freedom and is the most commonly used

robust standard error estimator and is employed by Stata's

robust

option.

 2
n
Î£=
diag uÌ‚i
nâˆ’k
3.

HC2

(MacKinnon and White, 1985) adjusts for the leverage values

projection matrix


Î£ = diag
4.

HCJ

where

HC3
HC2

uÌƒi =

=

nâˆ’1
n

HC4

uÌ‚2i
1 âˆ’ hi


diag

h

is the diagonal of the



 2
1
uÌƒi âˆ’ uÌƒuÌƒ0
n



uÌ‚i
1âˆ’hi .

(Davidson and MacKinnon, 1993) is an approximation to

(
Î£ = diag

6.

where

(MacKinnon and White, 1985) is the jackknife covariance matrix estimator.

Î£

5.

hi

PX = X(X 0 X)âˆ’1 X 0 .

uÌ‚i
1 âˆ’ hi

HCJ

and is a slight modication of

2 )

(Cribari-Neto, 2004) adjusts the residuals by a leverage factor that increases with the leverage.

(
Î£
where

=

diag

)

uÌ‚2i
Î´i

(1 âˆ’ hi )

Î´i = min {4, nhi /k}

We consider these approaches in terms of their size in Section 6 below. We nd using MacKinnon's (2011)
research design that each of the

HCj

estimators continues to have signicant size distortions when

moderate size.

1 We omit HC (Cribari-Neto et al., 2007) from our analysis as it is nearly identical to HC .
5
4

2

n

is of

3

Bootstrap Estimators

Another class of heteroskedasticity robust estimators uses the Wild bootstrap to estimate the distribution
of a given test statistic, forming a rejection region based on the realized bootstrap distribution. The Wild
bootstrap involves forming

B

bootstrap samples using the data generating process

yiâˆ— = Xi Î²Ìƒ + f (uÌƒi )viâˆ—
where

uÌƒi

are residuals from an estimate

estimated residuals, and

viâˆ—

Î²Ìƒ

of

Î² , f (Â·)

is one of several candidate transformations of the

is an independent random variable with mean 0 and variance 1.

For each

{Xi , yiâˆ— }, we estimate Î²Ì‚jâˆ— where j indexes the bootstrap sample, j = 1, . . . , B , and calculate
âˆ—
the test statistic of interest Tj , as in (3), using a particular heteroskedasticity-robust estimator of the variance
of Î²Ì‚ . Inference is then based on comparing the original test statistic to the Î±/2 and 1 âˆ’ Î±/2 percentiles of
 âˆ—
Tj .

bootstrap sample

MacKinnon (2011) shows that using the Wild bootstrap to estimate the distribution of test statistics
based on

HC1 ,

using

viâˆ— âˆˆ {âˆ’1, 1}

Î²Ìƒ is estimated imposing
uÌƒi
(where hÌƒi
HC3 , f (uÌƒi ) = 1âˆ’
hÌƒ

with equal probability, restricted residuals (i.e.

the null hypothesis), and a transformation of the residuals corresponding to
an element of the diagonal of the restricted projection matrix

PXÌƒ )

i

performs best in terms of size and power.

The bootstrap will have correct size on average by construction, so its power characteristics determine the
usefulness of the approach. We will benchmark our results with this particular variant of the Wild bootstrap
and show that our preferred estimator performs comparably in size and much better in power.

4

Second-Order Correction to Test Statistic Distribution
nâˆ’1 Edgeworth approximations for the distribution functions of test statistics that
combinations of Î² such as (3), assuming that the errors are normally distributed. Hall

Rothenberg (1988) derives
are linear functions

(1992) demonstrates that the second-order Edgeworth expansion approach and the bootstrap approach have
the same order of approximation in the case of pivotal test statistics. If the traditional, rst-order critical
values are Â±zÎ±/2 , then the second-order approximation
H0 : c0 Î² = c0 Î²0 are a multiplicative adjustment to zÎ±/2 :

t = Â±zÎ±/2
where

n

critical values

2
a(zÎ±/2
âˆ’ 1) + b
1
2
1 âˆ’ (1 + zÎ±/2 )V +
12
2n

t

for the test of the null hypothesis

!
= Â±zÎ±/2 Â· h

(4)

is the sample size and

fi4 uÌ‚4i
P 2 2 2
( fi uÌ‚i )
P 2 2
f g
P i2 i2
fi uÌ‚i
P 2
f Q
P i2 2ii
fi uÌ‚i
P

V

=

a =
b =

= nX(X 0 X)âˆ’1 c
(I âˆ’ PX )Î£f
p
g =
f 0 Î£f /n
Q = nPX Î£(PX âˆ’ 2I)
f

and

uÌ‚i

are the tted residuals and

Î£

is estimated with

HC0 .

We then calculate the test statistic in equation (3) and make inference by comparing it with the adjusted
critical value obtained from equation (4). In other words, we reject the null hypothesis if the test statistic
exceeds the adjusted critical value in magnitude

TÌ‚ > |t| and fail to reject otherwise.

We refer to this test as

the second-order (SO) approach. Applied researchers implementing a SO adjustment may nd it convenient
to calculate virtual standard errors by multiplying given standard errors by the adjustment factor
and comparing the resulting t-statistics to the traditional asymptotic critical value.

3

h

in (4)

4.1

Bootstrapped

While any estimate

VÌ‚

of

VÌ‚
V ar(Î²Ì‚)

can be used in (3), simulation results show that for small samples, the

empirical covariance matrix of a vector of nonparametrically bootstrapped
compute this estimated covariance matrix, for

B = 400

placement from the original data, forming a pairs bootstrap sample
calculate

Î²Ì‚jâˆ— = (X âˆ—0 X âˆ— )âˆ’1 X âˆ—0 y âˆ—

, and take

VÌ‚

Î²Ì‚

estimates performs best. To

bootstrap iterations we resample

(X âˆ— , y âˆ— ).

(X, y) with rej , we then

For each iteration

to be

B

VÌ‚ =

1 X  âˆ— Â¯âˆ—   âˆ— Â¯âˆ— 0
Î²Ì‚ âˆ’ Î²Ì‚
Î²Ì‚j âˆ’ Î²Ì‚
B âˆ’ 1 j=1 j

We refer to inference based on using
critical values

Â±zÎ±/2

VÌ‚

(5)

from (5) in equation (3) compared to the regular asymptotic

as the variance bootstrap (VB). When comparing the VB test statistic to the adjusted

critical values in (4), we call this the second-order bootstrap (SOB) approach.

5

Simulation Design

The data generating process for the simulations follows MacKinnon (2011) with a sample size of

yi

= Î²1 +

5
X

n = 40

Î²k Xik + ui

k=2

ui
Îµi
Ïƒi
Xik
Î²k
Î²5
where

z(Î³)

= Ïƒi Îµ i
âˆ¼ N (0, 1)
Î³
= z(Î³) (Xi Î²)
âˆ¼ LN (0, 1), k > 1
= 1, k < 5
= 0

is a scaling factor that ensures that the average variance of

(6)

ui is equal to 1. Î³ = 0 corresponds
Î³ . For context, in this simulation

to homoskedasticity, and the degree of heteroskedasticity increases with
design when

Î³ =2

Î³ = 1, HC1

robust standard errors are 44% larger than their homoskedastic counterparts, and

corresponds to standard errors that are 70% larger than the corresponding homoskedastic standard

errors.

6

Size Results

We compare the performance of the various variance estimators in the test

Î± = 0.05

H0 : Î²5 = 0 with signicance level

for 10,000 Monte Carlo simulations with varying degrees of heteroskedasticity using the research

design in (6).
simulations.

Since the data was generated with

Î²5 = 0,

this test should reject in approximately 5% of

Table 1 below shows rejection frequencies for three levels of heteroskedasticity, where none,

moderate and severe correspond to

Î³ = 0, 1, 2,

respectively. The rejection frequencies of each of the

decreasing in the degree of the heteroskedasticity. Of the

HCj

estimators,

HC3

and

HCJ

HCj

are

perform the best,

although they both over-reject for homoskedasticity and drastically under-reject for severe heteroskedasticity.
The rejection frequencies when we use the Rothenberg second-order critical values with test statistics
based on the

HC0

variance estimates, denoted SO, show that the exact adjustment proposed by Rothenberg

(1988) performs quite poorly.

Indeed, the SO test size is approximately the same as the original White

estimator.
The three bootstrap methods perform more consistently across the heteroskedasticity spectrum.
worth noting that whereas the rejection frequencies of the

HCj

of heteroskedasticity, the bootstrap tests perform quite well even under homoskedasticity.

4

It is

estimators decline signicantly with the degree
The variance

Table 1: Rejection Frequencies for Nominal Size 0.05 Test
Level of Heteroskedasticity
None

Moderate

Severe

Test statistic

Î³=0

Î³=1

Î³=2

HC0
HC1
HC2
HCJ
HC3
HC4

0.159

0.144

0.110

0.135

0.121

0.090

0.106

0.085

0.049

0.069

0.043

0.018

0.067

0.041

0.017

0.034

0.015

0.004

SO

0.156

0.149

0.134

VB

0.042

0.033

0.021

WB

0.046

0.050

0.040

SOB

0.045

0.045

0.039

bootstrap (VB) uses use the bootstrapped covariance matrix of

Î²Ì‚

from (5) with

B = 400

to compute the

test statistic (3) and compares it to the regular critical value, i.e. 1.96. Applying the Edgeworth expansion
to the distribution of the test statistic to adjust the critical value for the VB test statistic as in (4) (the SOB
approach) improves the rejection frequencies considerably for high degrees of heteroskedasticity. Rejection
frequencies from the Wild bootstrap (WB) approach are consistently close to their nominal value. Identifying
the Wild bootstrap and second-order bootstrap tests as having the best size properties, we now compare the
power of these two approaches.

7

Power Results

Figures 1 and 2 examine the power of the Wild bootstrap and second-order bootstrap tests. In each graph,

Î²5 and report rejection frequencies of the null hypothesis that Î²5 = 0, with Î± = 0.05.
Î²5 = 0, the rejection frequency is the size of the test statistic. Accordingly, a test
statistic has good size the closer its rejection frequency is to 0.05 when Î²5 = 0 and has greater power the
higher its rejection frequency is for Î²5 6= 0.
For both Î³ = 1 and Î³ = 2, the Wild bootstrap and second-order bootstrap tests have quite good size.
we vary the true value of

Note that when the true

However, the SOB approach has better power performance than the Wild bootstrap (WB), which is the best
of the bootstrap approaches for this design. For any magnitude of the true

Î²5

greater than approximately

0.1 (where the power performance of the two tests is quite similar), the SOB rejection frequencies are often
much higher than the WB rejection frequencies.

5

Figure 1: Power Results: Moderate Heteroskedasticity
1

0.9

SOB
WB

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
-0.7

-0.6

-0.5

-0.4

-0.3

Graph shows rejection frequencies for

-0.2

-0.1

0

True Î² 5

H0 : Î²5 = 0

0.1

0.2

0.3

0.4

0.5

0.6

given varying values of the true value of

0.7

Î²5 . Î³ = 1, n =

40, Î± = 0.05.

Figure 2: Power Results: Severe Heteroskedasticity
1

0.9

SOB
WB

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
-0.7

-0.6

-0.5

-0.4

-0.3

Graph shows rejection frequencies for

-0.2

-0.1

0

True Î² 5

H0 : Î²5 = 0

0.1

0.2

0.3

0.4

0.5

0.6

given varying values of the true value of

40, Î± = 0.05.

6

0.7

Î²5 . Î³ = 2, n =

8

Conclusion

White robust standard errors are universally used in econometrics. Their nite sample properties lead to
over-rejection under the null hypothesis, sometimes by a large amount. Over the past 25 years numerous
approaches have been suggested to x the problem.

In this paper, we suggest a second-order bootstrap

(SOB) approach that has approximately the correct size and superior power properties to the best of the
bootstrap approaches.

7

References

Cribari-Neto, F. (2004). â€œAsymptotic inference under heteroskedasticity of unknown
form,â€ Computational Statistics and Data Analysis, 45, 215-233.
Cribari-Neto, F., T. C. Souza, and K. L. P. Vasconcellos (2007). â€œInference under
heteroskedasticity and leveraged data,â€ Communications in Statistics: Theory and
Methods, 36, 1977â€“1988.
Davidson, R. and J. G. MacKinnon (1993). Estimation and Inference in Econometrics,
New York, Oxford University Press.
Davidson, R. and J. G. MacKinnon (2010). â€œWild bootstrap tests for IV regression,â€
Journal of Business and Economic Statistics, 28, 128-144.
Hall, P. (1992). The Bootstrap and Edgeworth Expansion, New York: Springer-Verlag.
Hannan, E.J. (1970). Multiple Time Series. New York: Wiley.
Hausman, J. and G. Kursteiner (2008). â€œDifference in difference meets generalized least
squares: higher order properties of hypotheses tests," Journal of Econometrics,
144, 371-391.
MacKinnon, J. G., and H. White (1985). â€œSome heteroskedasticity consistent covariance
matrix estimators with improved finite sample properties,â€ Journal of
Econometrics, 29, 305â€“325.
MacKinnon, J.G. (2011). â€œThirty years of heteroskedasticity-robust inference,â€ Queen's
Economics Department Working Paper No. 1268.
Rothenberg, T. J. (1988). â€œApproximate power functions for some robust tests of
regression coefficients,â€ Econometrica, 56, 997-1019.
White, H. (1980). â€œA heteroskedasticity-consistent covariance matrix estimator and a
direct test for heteroskedasticity,â€ Econometrica, 48, 817-838.

