NBER WORKING PAPER SERIES

HOW STRUCTURAL ARE STRUCTURAL PARAMETERS?
Jesús Fernández-Villaverde
Juan F. Rubio-Ramírez
Working Paper 13166
http://www.nber.org/papers/w13166

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 2007

We thank the editors, Daron Acemoglu, Kenneth Rogoff, and Mike Woodford; our two discussants,
Tim Cogley and Frank Schorfheide; Pau Rabanal, Garey Ramey, Stephanie Schmitt-Grohé, and Martín
Uribe, and participants at the NBER Macroeconomics Annual conference for comments. Beyond the
usual disclaimer, we must note that any views expressed herein are those of the authors and not necessarily
those of the Federal Reserve Bank of Atlanta or the Federal Reserve System. Finally, we also thank
the NSF for financial support. The views expressed herein are those of the author(s) and do not necessarily
reflect the views of the National Bureau of Economic Research.
© 2007 by Jesús Fernández-Villaverde and Juan F. Rubio-Ramírez. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

How Structural Are Structural Parameters?
Jesús Fernández-Villaverde and Juan F. Rubio-Ramírez
NBER Working Paper No. 13166
June 2007
JEL No. C11,C15,E10,E32
ABSTRACT
This paper studies how stable over time are the so-called "structural parameters" of dynamic stochastic
general equilibrium (DSGE) models. To answer this question, we estimate a medium-scale DSGE
model with real and nominal rigidities using U.S. data. In our model, we allow for parameter drifting
and rational expectations of the agents with respect to this drift. We document that there is strong evidence
that parameters change within our sample. We illustrate variations in the parameters describing the
monetary policy reaction function and in the parameters characterizing the pricing behavior of firms
and households. Moreover, we show how the movements in the pricing parameters are correlated with
inflation. Thus, our results cast doubts on the empirical relevance of Calvo models.
Jesús Fernández-Villaverde
University of Pennsylvania
160 McNeil Building
3718 Locust Walk
Philadelphia, PA 19104
and NBER
jesusfv@econ.upenn.edu
Juan F. Rubio-Ramírez
Duke University
P.O. Box 90097
Durham, NC 27708
juan.rubio-ramirez@duke.edu

1. Introduction
This paper studies the following problem: how stable over time are the so-called “structural
parameters” of dynamic stochastic general equilibrium (DSGE) models? To answer this
question, we estimate a medium-scale DSGE model with real and nominal rigidities using U.S.
data. In our model, we allow for parameter drifting and rational expectations of the agents
with respect to this drift. We document that there is strong evidence that parameters change
within our sample. In particular, we illustrate variations in the parameters describing the
monetary policy reaction function and in the parameters characterizing the pricing behavior
of firms and households. Moreover, we show how the movements in the pricing parameters
are correlated with inflation. Thus, our results cast doubts on the empirical relevance of
Calvo models.
Our findings are important because DSGE models are at the core of modern macroeconomics. They promise to be a laboratory that researchers can employ to match theory with
reality, to design economic policy, and to evaluate welfare. The allure of DSGE models has
captured the imaginations of many, inside and outside academia. In universities, a multitude
of economists implement DSGE models in their rich varieties and fashions. More remarkable still, a burgeoning number of policy-making institutions are estimating DSGE models
for policy analysis and forecasting. The Federal Reserve Board (Erceg, Guerrieri, and Gust,
2005), the European Central Bank (Christoﬀel, Coenen, and Warne, 2007), the Bank of
Canada (Murchison and Rennison, 2006), the Bank of Sweden (Adolfson et al., 2005), and
the Bank of Spain (Andrés, Burriel and Estrada, 2006) are at the front of the tide, but a
dozen other institutions are jumping on the bandwagon. In addition, the profession is accumulating experience with the good forecasting record of DSGE models, even when compared
with judgmental predictions from staﬀ economists (Laforte and Windle, 2006).
At the center of DSGE models, we have the “structural parameters” that define the
preferences and technology of the economy. We call these parameters “structural” in the
sense of Hurwicz (1962): they are invariant to interventions, including shocks by nature. The
structural character of the parameters is responsible for much of the appeal of DSGE models.
Since the parameters are fully interpretable from the perspective of economic theory and
invariant to policy interventions, DSGE models avoid the Lucas critique and can be used to
quantitatively evaluate policy.
Our point of departure is that, at least at some level, it is hard to believe that the
“structural parameters” of DSGE models are really structural given the class of interventions
we are interested in for policy analysis. Let us think, for instance, about technology. Most
DSGE models specify a stable production function, perhaps subject to productivity growth.
3

Except in a few papers (Young, 2004), the features of the technology, like the elasticity of
output to capital, are constant over time. But this constant elasticity is untenable in a world
where technological change is purposeful. We can expect that changes in the relative input
prices will induce changes in the new technologies developed and that those may translate
into diﬀerent elasticities of output to inputs. Similar arguments can be made along nearly
every dimension of a modern DSGE model.
The previous argument is not suﬃcient to dismiss the practice of estimating DSGE models
with constant parameter values. Simplifying assumptions, like stable parameters, are required
to make progress in economics. However, as soon as we realize the possible changing nature
of “structural” parameters, we weaken the justifications for inference exercises underlying
the program of DSGE modeling. The separation between what is “structural” and what is
reduced-form becomes much more ambiguous.1
The possibility but not the necessity of parameter drifting motivates the main question of
this paper: how much evidence of parameter drifting in DSGE models is in the data? If the
answer is that we find much support for drifting (where the metric to decide “much” needs
to be discussed), we would have to re-evaluate the usefulness of our estimation exercises or at
least modify them to account for parameter variation. Moreover, parameter drifting may also
be interpreted as a sign of model misspecification and, possibly, as a guide for improving our
models. If the answer is negative, i.e., if we find little parameter drifting, we would increase
our confidence in DSGE models as a procedure to tackle relevant policy discussions.
Beyond addressing our substantive question, this paper also develops new tools for the
estimation of dynamic equilibrium models with parameter drifting. We show how the combination of perturbation methods and the particle filter allows the eﬃcient estimation of this
class of economies. Indeed, all the required computations can be implemented in a standard
PC in a reasonable amount of time. We hope that those tools may be put to good use in other
applications, not necessarily in general equilibrium, that involve time-varying parameters in
essential ways.
Our main results are as follows. First, we oﬀer compelling proof of changing parameters in
the Fed’s behavior. Monetary policy became appreciably more aggressive in its stand against
inflation after Volcker’s appointment. This result agrees with Clarida, Galí, and Gertler
(2000), Lubick and Schorfheide (2004), Boivin (2006), and Rabanal (2007). Our contribution
1

Indeed, Hurwicz (1962) himself emphasized the contingency of the definition of structural parameters:
“...the concept of structure is relative to the domain of modifications anticipated ”; “If two individuals diﬀer
with regard to modifications they are willing to consider, they will probably diﬀer with regard to the relations
accepted as structural,” and “...this relativity of the concept of structure is due to the fact that it represents
not a property of the material system under observation, but rather a property of the anticipations of those
asking for predictions concerning the state of the system” (italics in the original).

4

is to re-derive the result within a model where agents understand and act upon the fact that
monetary policy changes over time.
Second, we expose the instability of the parameters controlling the level of nominal rigidity and indexation of prices and wages. Those changes are strongly correlated with changes in
inflation in an intuitive way: lower rigidities correlate with higher inflation and higher rigidities with lower inflation. Our finding suggests that a more thorough treatment of nominal
rigidities, possibly through state-dependent pricing models, may yield a high payoﬀ.
We want to be up-front about the shortcomings of our exercise. First, and foremost, we
face the limitations of the data. With 184 quarterly observations of the U.S. economy, there
is a tight bound on how much we can learn from the data (Ploberger and Phillips, 2003,
frame the problem of empirical limits for time series models precisely in terms of information
bounds). The main consequence of the limitations of the short sample size is relatively
imprecise estimates.
The second limitation, forcefully emphasized by Sims (2001), is that we do not allow
for changing volatilities in the innovations of the model, which is itself a particular form
of parameter drift. If the innovations in the U.S. data are heteroskedastic (as we report
in Fernández-Villaverde and Rubio-Ramírez, 2007), the estimation may attempt to pick up
the changing variance by spurious changes in the structural parameters. At the same time,
Cogley and Sargent (2005) defend that there is still variation in the parameters of a VAR,
even after controlling for heteroskedasticity. We are currently working on an extension of the
model with both parameter drifting and changing volatilities.
In our work, we build upon an illustrious tradition of estimating models with parameter
drifting. One classic reference is Cooley and Prescott (1976), where the authors studied the
estimation of regression parameters that are subject to permanent and transitory shocks. Unfortunately, the techniques in this tradition are within the context of the Cowles Commission’s
framework and, hence, are of little direct application to our investigation.
Our paper is also linked with a growing body of research that shows signs of parameter
drifting on dynamic models. Since the estimation of this class of models is a new undertaking, the evidence is scattered. One relevant literature estimates VARs with time-varying
parameters and/or stochastic volatility. Examples include Uhlig (1997), Bernanke and Mihov
(1988), Cogley and Sargent (2005), Primiceri (2005), and Sims and Zha (2006). The consensus emerging from these papers is that there is evidence of time variation in the parameters
of a VAR, although there is a dispute about whether the variation comes from changes in
the autoregressive components or from stochastic volatility. This evidence, however, is only
suggestive, since a DSGE model with constant parameters may be compatible with a timevarying VAR (Cogley and Sbordone, 2006).
5

A second literature has estimated equilibrium models with parameter variation, but it has
been less ambitious in the extent of the fluctuations studied. Fernández-Villaverde and RubioRamírez (2007) and Justiniano and Primiceri (2006) demonstrate the importance of stochastic
volatility to account for U.S. data using a DSGE model. King (2005) works with a simple RBC
economy with parameter drift in four parameters. However, his approach relies on particular
properties of his model and it is too cumbersome to be of general applicability. Canova
(2005) estimates a small scale New Keynesian model with parameter drifting but without the
agents being aware of these changes in the parameters. He uncovers important movements
in the parameters that enter into the Phillips curve and the Euler equations. Boivin (2006)
estimates a parameter-drifting Taylor rule with real-time data. He corroborates previous
findings of changes in the rule coeﬃcients obtained with final data. Benati (2006), elaborating
on an argument by Woodford (2006), questions the indexation mechanisms introduced in New
Keynesian models and shows that they are not structural to changes in monetary policy rules.
Oliner, Rudebusch, and Sichel (1996) find unstable parameters even in investment models
with more intricate representations of capital spending than those found in current DSGE
models. Owyang and Ramey (2004) estimate regime-switching models of monetary policy
and identify the evolving preferences of the monetary authority through their interaction with
the structural parameters.
There are also numerous papers that tell us about parameter drifting, albeit in an indirect
way. A common practice when estimating models has been to divide the sample into two
periods, usually before and after 1979, and argue that there are significant diﬀerences in the
inference results. One celebrated representative of this method is Clarida, Galí, and Gertler
(2000), a paper we will discuss later.
Finally, a literature that shares connections with our analysis is the one that deals with
DSGE models with a Markov-switching process in diﬀerent aspects of the environment, like
monetary or fiscal policy (Davig and Leeper, 2006a and 2006b, Chung, Davig, and Leeper,
2006, and Farmer, Waggoner, and Zha, 2006). The stated motivation of these papers is that
Markov switches help us understand the dynamics of the economy better. So far, none of
these papers has produced an estimated model.
The rest of the article is organized as follows. First, in section 2, we discuss diﬀerent ways
to think about parameter drifting in dynamic equilibrium models. In section 3, we develop
two simple examples of parameter drift that motivate our investigation. Section 4 spells out
a medium-scale model of the U.S. economy and discusses how to take this model to the data.
Section 5 introduces parameter drifting and explains how to adapt the approach in section 4
to handle this situation. We report our results in section 6. Section 7 concludes. An appendix
provides the interested reader with technical details.
6

2. Parameter Drifting and Dynamic Equilibrium Models
There are at least three ways to think about parameter drifting in an estimated DSGE model.
The simplest approach, which we call the pure econometric interpretation, is to consider
parameter drifting as a convenient phenomenon to fit the data better or as the consequence
of a capricious nature that agents in the model neither understand nor forecast. Despite
its simplicity, this interpretation violates the spirit of rational expectations: not having free
parameters that the researcher can play with. Consequently, we will not investigate this case
further.
The second way to think about parameter drifting is as a characteristic of the environment
that the agents understand and act upon. Let us come back to our example of the production
function. Imagine that the aggregate technology is given by a Cobb-Douglas function Yt =
t
AKtαt L1−α
where output Yt is produced with capital Kt and labor Lt given a technology level
t
A and share parameter αt . The only diﬀerence with the standard environment is that αt is
indexed by time (neither the realism nor the empirical justification of our example is crucial
for the argument, although we could argue in favor of both features). Let us also assume
that αt evolves over time as a random walk with reflecting boundaries at 0 and 1, to ensure
that the production function satisfies the usual properties. We could imagine that such drift
comes about because the new technologies developed have a random requirement of capital.
The solution of the agents’ problems are decision rules that have as one of their arguments
the current αt . Why? First, because αt determines current prices. Second, because αt helps
to forecast future values αt+j and hence to predict future prices. This interpretation is our
favorite one, and it will frame our reading of the results in section 6.
The final perspective about parameter drifting is as a telltale of model misspecification.
This point, raised by Cooley (1971) and Rosenberg (1968), is particularly cognate when
estimating DSGE models. These models are complex constructions. To make them useful for
policy purposes, researchers add many mechanisms that aﬀect the dynamics of the economy:
sticky prices and wages, adjustment costs, etc. In addition, DSGE models require tight
parametric assumptions for the utility function, the production function, the adjustment
costs, the distribution of shocks, etc. If we seriously misspecified the model along at least one
dimension, parameter drifting may appear as the only possibility left to the model to fit the
data. Our example in section 3 illustrates this point in detail. We will exploit this possibility
in our empirical results and assess how the drift in the parameters determining the degree
of nominal rigidity in the economy implies that time-dependent models of pricing decisions
may be flawed.

7

3. Two Examples
In this section, we present two simple examples that generate parameter drifting in estimated
DSGE models. We have chosen the examples to illustrate our points as clearly as possible
and not based on their relevance or plausibility. However, the examples are not far-fetched:
they deal with recurrent themes in the literature and are linked, albeit we do not explore this
connection to its fullest, to relevant features of the economy.
3.1. Parameter Drift as a Consequence of Changing Policies
The first example deals with the changes in the elasticity of monetary policy to diﬀerent
variables. It is common to postulate that the monetary authority uses open market operations
to set the short-run nominal interest rate Rt according to a Taylor rule:
Rt
=
R

µ

Rt−1
R

¶γ R µµ

Πt
Π

¶γ Π µ ¶γ y ¶1−γ R
yt
exp (σ m εmt )
ybt

The variable Π represents the target levels of inflation of the monetary authority, R the
steady-state gross return of capital, yt is output, and ybt a measure of target output. The
term εmt is a random shock distributed according to N (0, 1).
In an influential contribution, Clarida, Galí, and Gertler (2000) drove the attention of
the profession to changes in the elasticity parameter γ Π before and after Volcker’s appointment as Fed chairman in 1979. They document, with a slightly diﬀerent specification of the
Taylor rule, that γ Π more than doubles after 1979. This finding has been corroborated in
many studies and found resilient to modifications in the empirical specification (Lubick and
Schorfheide, 2004). The division of the sample between the time before and after 1979 has
also been exploited by Boivin and Giannoni (2006), who find that the point estimates of the
structural parameters also substantially vary between the two periods.
Changes in the policy coeﬃcients are one particular example of parameter drift. They
can be the consequence of the shifting priorities of the policy-makers or, as emphasized by
Sargent (1999), of changes in the perception of the eﬀectiveness of monetary policy. Once we
recognize that there is evidence of the parameter γ Π drifting over time, it is natural to assume
that agents are aware of the changes and act upon them. Such an environment may capture
some of the insights of Sims (1980) about the diﬀerence between a change in policy regime
(in our Taylor rule, a change in the way the interest rate is determined) and the evolution of
the policy within one regime, which could be represented in our context as the drift of the
parameters of the rule.

8

3.2. Parameter Drift as a Telltale of Model Misspecification
Our second example revisits several of the themes in Browning, Hansen, and Heckman (1999).
We explore the consequences for inference of an econometrician estimating a model with
infinitely lived agents when the data are actually generated by an overlapping generations
model. We show how our estimate of the discount factor will be a function of the true discount
factor, the elasticity of output to capital, and the changing age distribution of the population.
This example is relevant because variations in the age structure of the U.S. population have
been continuous due to shifts in fertility and mortality.
3.2.1. An Artificial World
We begin by creating a simple artificial world. In each period t, there are two generations of
households alive, young and old. Each household maximizes the life utility
log ctt + βEt log ctt+1
where the superindex denotes that the household was born in period t, the subindex the
period in which it consumes, and Et is the conditional expectations operator. The discount
factor, β, captures the preference for current consumption. We pick a log utility function to
simplify the algebra below.
Households work when young and get a wage wt for a unit of time that they supply inelastically. Households live oﬀ their savings when they are old. The period budget constraints
are ctt + st = wt and ctt+1 = Rt+1 st , where st is the household savings and Rt+1 the gross
1
return on capital. From the first order condition of households, we have that ctt = 1+β
wt and
β
t
ct = 1+β wt .
In each period, a number nt of new households is born. For the moment, we will assume
only that lt is the realization of some random process. Nothing of substance for our argument
is lost by assuming that the size of the new generation is exogenous.
The production side of the economy is defined by a Cobb-Douglas function yt = ktα lt1−α
where kt is the total amount of capital in the economy and lt the total amount of labor. If
we assume total depreciation in the economy, again to simplify the algebra, and impose the
condition lt = nt , we get by competitive pricing wt = (1 − α) ktα n−α
and Rt = αktα−1 n1−α
.
t
t
Now, all that remains is some accounting. Total consumption in the economy in period
t, Ct , is equal to the consumption of the old generation plus the consumption of the young
generation. The old consume all of their income, which is equal to the capital income of the
1
economy, Rt kt = αktα n1−α
. The young consume a fraction 1+β
of their income, which is equal
t
9

to the labor income of the economy wt lt = (1 − α) ktα n1−α
. Then total consumption is:
t
Ct =

1 + αβ α 1−α
k n
1+β t t

By the aggregate resource constraint, investment (or, equivalently, capital in period t + 1) is
It = kt+1 =

(1 − α) β
Ct
1 + αβ

Finally, we find per capita consumption cpc
t as:
cpc
t =

Ct
nt + nt−1

3.2.2. An Econometrician
Let us now suppose that we have an econometrician who aims to estimate a model with a
representative infinitely lived agent and T observations generated from our economy. To do
so, the econometrician postulates that the agent has a utility function:
max Et
{cpc
t }

∞
X
t=0

βt

" t
Y
i=0

#

(1 + γ t ) log cpc
t

where γ t is the (random) growth rate of the population between periods t − 1 and t:
1 + γt =

nt + nt−1
nt−1 + nt−2

and γ 0 = 0. This utility function is the same as in the canonical presentation of the RBC
model in Cooley and Prescott (1995) except that the growth rate of the population is stochastic instead of constant. The production side of the economy is the same as before,
yt = ktα lt1−α . Thus, the only diﬀerence between the artificial world we have created and the
model the econometrician estimates is that, instead of having two generations alive in each
moment, the econometrician estimates a model with a representative agent.
What are the consequences on the estimated parameters? Imagine that the econometrician
knows α and that the depreciation factor is 1. Then, a simple procedure to estimate the only
remaining unknown parameter in the model, the discount factor β, is to build the population
moment:
¡
¢ Rt+1
1
pc = βEt 1 + γ t+1
ct
cpc
t+1
10

and substitute the expectation by the sample mean:
bT =
β

1
T −1
PT −1
1
t=0
T −1

PT −1

1
t=0 cpc
t

¡
¢
1 + γ t+1 Rcpct+1
t+1

We study how this expression evolves over time. First, note that, by substituting the
expressions found before, we get:

Then:

¡
¢ Rt+1
(nt+1 + nt )2 α 1 + β 1
1 + γ t+1 pc =
ct+1
nt + nt−1 1 − α β Ct
PT −1
1
1
1
−
α
t=0 (nt + nt−1 ) Ct
b
βT = β
α 1 + β PT −1 (nt+1 +nt )2 1
t=0

nt +nt−1

Ct

We want to work on the previous expression. First, we substitute aggregate consumption
for its value in terms of capital and labor:
PT −1
1
t=0 (nt + nt−1 ) kα n1−α
1
−
α
1
t t
b
βT = β
PT −1 (nt+1 +nt )2 1
1+β α
α 1−α
t=0

nt +nt−1

kt nt

The only remaining endogenous element in this equation is kt . To eliminate it, we recursively
substitute kt−i to find:
¶αi #
t−1 µ
(1 − α) β 1−α Y (1 − α) β 1−α
k0αt
n
n
kt =
1 + αβ t−1 i=1
1 + αβ t−1−i
"

Then:
PT −1

nt +nt−1
t=0
n1−α
t

bT = β 1 1 − α
β
1 + β α PT −1

µ∙

(nt+1 +nt )2
t=0 (nt +nt−1 )n1−α
t

n1−α
t−1

Qt−1 ³ (1−α)β

n1−α
1+αβ t−1−i

´αi ¸

¶−α

k0αt
µ∙
¸ ¶
Qt−1 ³ (1−α)β 1−α ´αi αt −α
1−α
nt−1 i=1 1+αβ nt−1−i
k0
i=1

bT , which is biased and drifts over time according to the evolution of the
which delivers a β
population. This expression is composed of three parts. First, the true parameter, β, second
the deterministic bias,
1 1−α
1+β α
and finally the term involving the nt ’s and k0 , which fluctuates over time.

11

Without further structure on population growth over time, it is diﬃcult to say much about
b
β T . In the simple case where γ t = γ is constant, as T → ∞, the only factor dominating is:
bT ' β
β

1 1−α
(1 + γ)−2
1+β α

(1)

bT in the general case where γ t varies, we simulate the model
To explore the behavior of β
and estimate the parameter recursively with data from an economy with α = 0.3 and β = 0.96.
The growth rates of population are 2, 4, 3, 1, 2, and 5 percent each for 50 periods (i.e., for
period 1 to 50, growth rate is 2 percent, for period 51 to 100, the growth rate is 4 percent
bT
and so forth). We plot our results in figure 2.3.1, where we see the evolution over time of β

and how it inherits the properties of γ t . To facilitate comparison with (1), we superimpose
the value of (1) that would be implied if the growth rate in a period stayed constant over
bT converges to (1) within each block of 50 periods.
time. The graph shows how β

4. The Baseline Model

We will structure our investigation around a baseline New Keynesian business cycle model.
We pick this model because it is the paradigmatic representative of the DSGE economies
estimated by practitioners. Since on other occasions (Fernández-Villaverde, 2005), we have
gone on the record criticizing the problems of this framework, we do not feel obliged to repeat
those shortcomings here. Suﬃce it to say as a motivation that given the level of interest by
policy-making institutions in this model, it is diﬃcult to see a more appropriate vessel for
our exploration.
The New Keynesian model is well known (see the book-length description in Woodford,
2003). Consequently, we will be short in our presentation, and we will omit some of the technical aspects. On the other hand, for concreteness, we need to discuss the model in certain
detail. The interested reader can access the whole description of the model at a complementary technical appendix posted at www.econ.upenn.edu/~jesusfv/benchmark_DSGE.pdf.
In this section, to fix ideas, we will introduce the model without changes in the parameters.
In section 5, we will introduce the parameter change over time.
4.1. Households
The basic structure of the economy is as follows. A representative household consumes, saves,
holds real money balances, supplies labor, and sets its own wages subject to a demand curve
and Calvo’s pricing. The final output is manufactured by a competitive final good producer,

12

which uses as inputs a continuum of intermediate goods manufactured by monopolistic competitors. The intermediate good producers rent capital and labor to manufacture their good.
Also, the intermediate good producers face the constraint that they can only change prices
following a Calvo’s rule. Finally, there is a monetary authority that fixes the one-period
nominal interest rate through open market operations with public debt. Long-run growth
is induced by the presence of two unit roots, one in the level of neutral technology and one
in the investment-specific technology. These stochastic trends will allow us to estimate the
model with the raw, undetrended data.
We have a continuum of households in the economy indexed by j. The households maximize the following lifetime utility function, which is separable in consumption, cjt , real money
balances, mjt /pt , and hours worked, ljt :
E0

∞
X
t=0

β t dt

(

log (cjt − hcjt−1 ) + υ log

µ

mjt
pt

¶

1+ϑ
ljt
− ϕt ψ
1+ϑ

)

where β is the discount factor, h controls habit persistence, ϑ is the inverse of Frisch labor
supply elasticity, dt is a shock to intertemporal preference with the law of motion:
log dt = ρd log dt−1 + σ d εd,t where εd,t ∼ N (0, 1),
and ϕt is a labor supply shock with the law of motion:
log ϕt = ρϕ log ϕt−1 + σ ϕ εϕ,t where εϕ,t ∼ N (0, 1).
Households trade on the whole set of Arrow-Debreu securities, contingent on idiosyncratic
and aggregate events. Our notation ajt+1 indicates the amount of those securities that pay
one unit of consumption in event ωj,t+1,t purchased by household j at time t at (real) price
qjt+1,t . To save on notation, we drop the explicit dependence on the event. Households also
hold an amount bjt of government bonds that pay a nominal gross interest rate of Rt and
invest xt . Then, the j − th household’s budget constraint is:
Z
mjt bjt+1
cjt + xjt +
+
+ qjt+1,t ajt+1 dω j,t+1,t
pt
pt
¡
¢
bjt
mjt−1
= wjt ljt + rt ujt − μ−1
+ Rt−1 + ajt + Tt + zt
t Φ [ujt ] kjt−1 +
pt
pt

where wjt is the real wage, rt the real rental price of capital, ujt > 0 the intensity of use of
capital, μ−1
t Φ [ujt ] is the physical cost of ujt in resource terms, μt is an investment-specific

13

technological shock to be described momentarily, Tt is a lump-sum transfer, and zt is the
profits of the firms in the economy. We assume that Φ [1] = 0, Φ0 and Φ00 > 0.
Investment xjt induces a law of motion for capital:
µ
∙
¸¶
xjt
kjt = (1 − δ) kjt−1 + μt 1 − V
xjt
xjt−1
where δ is the depreciation rate and V [·] is a quadratic adjustment cost function such that
V [Λx ] = 0, where Λx is the growth rate of investment along the balance growth path. Note
that we index capital by the time its level is decided. The investment-specific technological
shock follows an autoregressive process:
μt = μt−1 exp (Λμ + zμ,t ) where zμ,t = σ μ εμ,t and εμ,t ∼ N (0, 1)
The first order conditions with respect to cjt , bjt , ujt , kjt , and xjt are:
dt (cjt − hcjt−1 )−1 − bβEt dt+1 (cjt+1 − hcjt )−1 = λjt ,
Rt
},
λjt = βEt {λjt+1
Πt+1
½

0
rt = μ−1
t Φ [ujt ] ,

¾
¢
λjt+1 ¡
−1
qjt = βEt
(1 − δ) qjt+1 + rt+1 ujt+1 − μt+1 Φ [ujt+1 ] , and
λjt
µ
∙
¸
∙
¸
¶
∙
¸µ
¶2
λjt+1 0 xjt+1
xjt
xjt
xjt
xjt+1
0
1 = qjt μt 1 − V
−V
+ βEqjt+1 μt+1
V
,
xjt−1
xjt−1 xjt−1
λjt
xjt
xjt
where λjt is the lagrangian multiplier associated with the budget constraint and qjt is the
marginal Tobin’s Q, the lagrangrian multiplier associated with the investment adjustment
constraint normalized by λjt .
The first order condition with respect to labor and wages is more involved. The labor employed by intermediate good producers is supplied by a representative, competitive firm that
hires the labor supplied by each household j. The labor supplier aggregates the diﬀerentiated
labor of households with the production function:
ltd =

µZ

1

η−1
η

ljt dj

0

η
¶ η−1

(2)

where η controls the elasticity of substitution among diﬀerent types of labor and ltd is the
aggregate labor demand.

14

The labor “packer” maximizes profits subject to the production function (2), taking as
given all diﬀerentiated labor wages wjt and the wage wt . From his maximization problem we
get:
¶−η
µ
wjt
ltd
∀j
(3)
ljt =
wt
R1
Then, to find the aggregated wage, we use again the zero profit condition wt ltd = 0 wjt ljt dj
to deliver:
1
µZ 1
¶ 1−η
1−η
wjt dj
.
wt =
0

Households set their wages following a Calvo’s setting. In each period, a fraction 1 − θw of
households reoptimize their wages. All other households can only partially index their wages
by past inflation. Indexation is controlled by the parameter χw ∈ [0, 1]. This implies that if
the household cannot change its wage for τ periods, its normalized wage after τ periods is
τ
χw
Y
Πt+s−1
wjt .
Πt+s
s=1

Since we assume complete markets and separable utility in labor (see Erceg et al., 2000),
we will concentrate on a symmetric equilibrium where cjt = ct , ujt = ut , kjt−1 = kt , xjt = xt ,
∗
λjt = λt , qjt = qt , and wjt
= wt∗ . In anticipation of that equilibrium, and after a fair amount
of manipulation, we arrive at the recursive equations:
η − 1 ∗ 1−η
(wt ) λt wtη ltd + βθw Et
ft =
η
and:
ft = ψdt ϕt

µ

wt
wt∗

¶η(1+ϑ)

¡ d ¢1+ϑ
+ βθw Et
lt

µ

µ

χ

Πt w
Πt+1
χ

Πt w
Πt+1

¶1−η µ

∗
wt+1
wt∗

¶−η(1+ϑ) µ

¶η−1

∗
wt+1
wt∗

ft+1

¶η(1+ϑ)

ft+1 .

that determine the evolution of wages.
Then, in every period, a fraction 1 − θw of households set wt∗ as their wage, while the
remaining fraction θw partially index their price by past inflation. Consequently, the real
wage index evolves:
wt1−η

= θw

µ

χ

w
Πt−1
Πt

¶1−η

1−η
wt−1
+ (1 − θw ) wt∗1−η .

15

4.2. The Final Good Producer
There is one final good produced using intermediate goods with the following production
function:
ε
µZ 1
¶ ε−1
ε−1
ytd =
yit ε di
.
(4)
0

where ε controls the elasticity of substitution.
Final good producers are perfectly competitive and maximize profits subject to the production function (4), taking as given all intermediate goods prices pti and the final good
price pt . Repeating the same steps as for wages, we obtain the demand functions for each
intermediate good:
µ ¶−ε
pit
ytd
∀i,
yit =
pt
R1
where ytd is the aggregate demand and the zero profit condition pt ytd = 0 pit yit di to deliver:
pt =

µZ

1

p1−ε
it di

0

1
¶ 1−ε

.

4.3. Intermediate Good Producers
There is a continuum of intermediate good producers. Each intermediate good producer i
has access to a technology represented by a production function:
¡ d ¢1−α
α
yit = At kit−1
− φzt
lit

where kit−1 is the capital rented by the firm, litd is the amount of the “packed” labor input
rented by the firm, the parameter φ corresponds to the fixed cost of production, and where
At follows:
At = At−1 exp (ΛA + zA,t ) where zA,t = σ A εA,t and εA,t ∼ N (0, 1)
1

α

The fixed cost φ is scaled by the variable zt = At1−α μt1−α . We can think of zt as a weighted
index of the two technology levels At and μt , where the weight is the share of capital in the
production function. The product φzt guarantees that economic profits are roughly equal
to zero in the steady state. Also, we rule out the entry and exit of intermediate good
z +αz
producers. Note that zt evolves over time as zt = zt−1 exp (Λz + zz,t ) where zz,t = A,t1−α μ,t
+αΛμ
and Λz = ΛA1−α
. We will see below that Λz is the mean growth rate of the economy.
Intermediate good producers solve a two-stage problem. First, given wt and rt , they rent
16

litd and kit−1 in perfectly competitive factor markets in order to minimize real costs, which
implies a marginal cost of:
mct =

µ

1
1−α

¶1−α µ ¶α 1−α α
wt rt
1
α
At

The marginal cost does not depend on i: all firms receive the same shocks and rent inputs at
the same price.
Second, intermediate good producers choose the price that maximizes discounted real
profits under the same pricing scheme as households. In each period, a fraction 1 − θp of
firms reoptimize their prices. All other firms can only index their prices by past inflation.
Indexation is controlled by the parameter χ ∈ [0, 1], where χ = 0 is no indexation and χ = 1
is total indexation.
The problem of the firms is then:
∞
X

λt+τ
max Et
(βθp )
pit
λt
τ =0
τ

subject to
yit+τ =

(Ã τ
Y

Πχt+s−1

s=1

Ã τ
Y

pit
Πχt+s−1
pt+τ
s=1

pit
− mct+τ
pt+τ
!−ε

!

yit+τ

)

d
yt+τ
,

where the marginal value of a dollar to the household is treated as exogenous by the firm.
Since there are complete markets in securities, this marginal value is constant across households and, consequently, λt+τ /λt is the correct valuation on future profits.
We write the solution of the problem in terms of two recursive equations in gt1 and gt2 :
¶−ε
Πχt
1
=
+ βθp Et
gt+1
Πt+1
µ χ ¶1−ε µ ∗ ¶
Πt
Πt
2
∗ d
g2
gt = λt Πt yt + βθp Et
Πt+1
Π∗t+1 t+1
gt1

µ

λt mct ytd

where εgt1 = (ε − 1)gt2 and Π∗t = p∗t /pt .
Given Calvo’s pricing, the price index evolves:

or, dividing by p1−ε
,
t

¡ χ ¢1−ε 1−ε
p1−ε
=
θ
pt−1 + (1 − θp ) p∗1−ε
Πt−1
p
t
t
1 = θp

µ

Πχt−1
Πt

¶1−ε
17

+ (1 − θp ) Π∗1−ε
t

4.4. The Government
The government sets the nominal interest rates according to the Taylor rule:
Rt
=
R

µ

Rt−1
R

¶γ R

⎛
⎛ yd ⎞γ y ⎞1−γ R
µ ¶γ Π
t
d
⎝ Πt
⎝ yt−1 ⎠ ⎠
exp (mt )
Π
Λyd

(5)

through open market operations that are financed with lump-sum transfers Tt to ensure that
the government budget is balanced period by period. The variable Π represents the target
levels of inflation (equal to inflation in the steady state), R the steady-state gross return of
capital, and Λyd the steady-state gross growth rate of ytd . With a bit of abuse of language,
d
we will refer to the term yydt /Λyd as the growth gap. The term mt is a random shock to
t−1
monetary policy that follows mt = σ m εmt where εmt is distributed according to N (0, 1). We
introduce the previous period interest rate, Rt , to match the smooth profile of the interest
rate over time observed in the U.S.
4.5. Aggregation
First, we begin with the aggregate demand:
ytd = ct + xt + μ−1
t Φ [ut ] kt−1
Then, using the production function for intermediate good producers, the fact that all the
firms pick the same capital-labor ratio, and market clearing in the output and input markets,
we find the aggregate demand must be equal to aggregate supply:
ytd

¡ ¢1−α
− φzt
At (ut kt−1 )α ltd
=
p
vt

where:
vtp

=

Z 1µ
0

pit
pt

¶−ε

di

is the aggregate loss of eﬃciency induced by price dispersion. By the properties of the index
under Calvo’s pricing:
µ χ ¶−ε
Πt−1
p
p
vt = θp
vt−1
+ (1 − θp ) Π∗−ε
.
t
Πt

18

Finally, we integrate labor demand over all households j to obtain:
Z

1

ljt dj = lt =

0

Z 1µ
0

wjt
wt

¶−η

djltd

where lt is the aggregate labor supply of households. Hence if we define:
vtw

=

Z 1µ
0

we get:

and:
vtw

= θw

µ

χ

w
wt−1 Πt−1
wt Πt

wjt
wt

¶−η

dj

ltd =

1
lt
vtw

¶−η

−η
w
vt−1
+ (1 − θw ) (Πw∗
.
t )

4.6. Equilibrium
A definition of equilibrium in this economy is standard and the equations that characterize
it are determined by the first order conditions of the household, the first order conditions of
the firms, the Taylor rule of the government, and market clearing.
To undertake our quantitative analysis, we must approximate the equilibrium dynamics
of the economy. Ours is a large model (even the version without parameter drifting has 19
state variables). Moreover, we will need to solve the model repeatedly during our estimation
process. We have argued elsewhere (Fernández-Villaverde, Rubio-Ramírez, and Santos, 2006)
that there is much to be gained from a nonlinear estimation of the model, both in terms of
accuracy and in terms of identification. This is particularly true if we want to allow the agents
in the economy to insure themselves against future changes in the parameters of the model.
Hence, we require a nonlinear solution method that is fast and accurate. In previous work
(Aruoba, Fernández-Villaverde, and Rubio-Ramírez, 2006), we have found that a second
order perturbation around the deterministic steady-state of the model fulfills the previous
desiderata.
But before solving the model, we clear up some technical issues. First, because of technological change, most of the variables are growing in average. To achieve the right accuracy in
the computation, we make the variables stationary and solve the model in the transformed
∗
et = λt zt , ret = rt μt , qet = qt μt , x
variables. Hence, we define e
ct = zctt , λ
et = xztt , w
et = wztt , w
et∗ = wztt ,
d
e
kt = kt , and yed = yt . Also note that Λc = Λx = Λw = Λw∗ = Λyd = Λz . Second, we choose
zt μt

t

zt

functional forms for Φ [·] and V [·]. For Φ [u] we pick Φ [u] = Φ1 (u − 1) +
19

Φ2
(u
2

− 1)2 . We

0
normalize u = 1 in the steadyh state.
i Hence, re = Φ [1] = Φ1 and Φ [1] = 0. The investment
t
t
adjustment cost function is V xxt−1
− Λx )2 . Then, along the balanced growth path,
= κ2 ( xxt−1
V [Λx ] = V 0 [Λx ] = 0.
We will perform our perturbation in logs. For each variable vart , we define vd
art =
log vart − log var, as the log deviation with respect to the steady state. Then, the states of
the model S t are given by:

⎞0
d
b
p
1
2
w
b
b
b
e
b
b
et−1 , b
gt−1 , b
gt−1 , k t−1 , Rt−1 , yet−1 , e
ct−1 , vbt−1 , vbt−1 , ⎠
Πt−1 , w
St = ⎝
,
b
b
b
et−1 , b
x
et−1 , λ
zet−1 , zμ,t−1 , dbt−1 , ϕ
b t−1 , zA,t−1
qet−1 , fet−1 , b
⎛

and the exogenous shocks are εt = (εμ,t , εd,t , εϕ,t , εA,t , εm,t )0 .
As a first step, we parameterize the matrix of variances-covariances of the exogenous
shocks as Ω (χ) = χΩ, where Ω (1) = Ω, is a diagonal matrix. However, nothing really depends
on that assumption, and we could handle an arbitrary matrix of variances-covariances. Then,
we take a perturbation solution around the deterministic steady state of the model, i.e., χ = 0.
From the output of the perturbation, we build the law of motion for the states:
³ 0 ´0 1 ³ 0 ´
³ 0 ´0
S t+1 = Ψs1 S t , ε0t +
S t , ε0t Ψs2 S t , ε0t + Ψs3
2

(6)

³ 0 ´0
where Ψs1 is a 1×24 vector and Ψk2 is a 24×24 matrix. The term Ψs1 S t , ε0t constitutes
³ 0 ´
³ 0 ´0
the linear solution of the model, S t , ε0t Ψs2 S t , ε0t is the quadratic component, and Ψs3
is a 1×24 vector of constants added by the second order approximation that corrects for
precautionary behavior. Some of the entries of the matrices Ψsi will be zero.
From the same output, we find the law of motion for the observables
¢0
¡
Y T = 4 log μ−1
t , 4 log yt , 4 log lt , log Πt , log Rt

´
³ 0 0
0
Now, define St = S t , S t−1 , ε0t−1 . We keep track of the past states, S t−1 , because some of
the observables in the measurement equation below will appear in first diﬀerences. Then, we
write to the observation equation:
0

Y T = Ψo1 (St0 , ε0t ) +

1 0 0
0
(St , εt ) Ψo2 (St0 , ε0t ) + Ψo3
2

(7)

where Ψo1 and Ψo3 1×48 matrices and Ψo2 is a 48×48 matrix.
While the law of motion for states is unique (or at least equivalent to a class of diﬀerent
states, all of which have the same implications for the dynamics of the model), the observation
20

equation depends on what we assume the researcher actually observes. In our case, we have
chosen the first diﬀerences of the relative price of investment, output, hours, inflation, and the
federal funds rate. Unfortunately, we do not know much about the right choice of observables
and how they may aﬀect our estimation results (for one of the few articles on this topic, see
Boivin and Giannoni, 2006).
4.7. The Likelihood Function
Equations (6) and (7) constitute the state space representation of our model. One convenient
properties of this representation is that we can exploit it to evaluate the likelihood of a DSGE
¡
¢
model, an otherwise challenging task. The likelihood, L YT ; Ψ , is the probability that the
model assigns to a sequence of realizations of the observable YT given parameter values:
©
ª
Ψ = β, h, υ, ϑ, δ, η, ε, α, φ, θw , χw , θp , χp , Φ2 , γ R , γ y , γ Π , Π, Λμ , ΛA , ρd , ρϕ , σ μ , σ d , σ A , σ m , σ ϕ .

Note that Φ1 is not included in Ψ because it is a function of the other parameters in the
¡
¢
economy to ensure that re = Φ1 . With L YT ; Ψ , we can estimate Ψ by maximizing the
likelihood or by combining it with a prior density for the model parameter to form a posterior
distribution.
¡
¢
How do we evaluate the likelihood L YT ; Ψ ? Given the Markov structure of our state
space representation, we begin by factorizing the likelihood function as:
T
¢ Y
¡
¢
¡
L Yt |Yt−1 ; Ψ
L YT ; Ψ =
t=1

Then, conditioning on the states:
¡
¢
L YT ; Ψ =

Z

L (Y1 |S0 ; Ψ) dS0

T Z
Y
t=2

¡
¢
L (Yt |St ; Ψ) p St |Yt−1 ; Ψ dSt

(8)

If we know St , computing L (Yt |St ; Ψ) is relatively easy. Conditional on St , the measurement equation (7) is a change of variables from εt to Y T . Hence, we can apply the change
of variable formula to evaluate the required probabilities. Similarly, if we know S0 , we can
employ (6) and the measurement equation (7) to compute L (Y1 |S0 ; Ψ) . Consequently, knowl¡
¢
T
edge of the sequence {p (St |Yt−1 ; Ψ)}t=1 and of p (S0 ; Ψ) allows us to find L YT ; Ψ . Evaluating (or at least drawing from) p (S0 ; Ψ) is usually straightforward, although often costly
(Santos and Peralta-Alva, 2005). The diﬃculty is to characterize the sequence of conditional
T
distributions {p (St |Yt−1 ; Ψ)}t=1 and to compute the integrals in (8).
21

An algorithm for doing so (but not the only one!; see the technical appendix to FernándezVillaverde and Rubio-Ramírez, 2007, for alternatives and references) is to use a simulation
technique known as the particle filter. Fernández-Villaverde and Rubio-Ramírez (2005 and
2007) have shown that the particle filter can be successfully applied to the estimation of
nonlinear and/or non-normal DSGE models. The particle filter is a sequential Monte Carlo
T
method that replaces the {p (St |Yt−1 ; Ψ)}t=1 by an empirical distribution of draws generated
by simulation. The bit of magic of the particle filter is that the simulation is generated through
a procedure known as sequential importance resampling (SIR). SIR guarantees that the Monte
Carlo method achieves suﬃcient accuracy in a reasonable amount of time, something that
cannot be achieved without resampling (Arulampalam et al., 2002). The appendix describes
in further detail the working of the particle filter.
4.8. A Bayesian Approach
We will confront our model with the data using Bayesian methods. The Bayesian paradigm
is a powerful and flexible perspective for the estimation of DSGE models (see the survey by
An and Schorfheide, 2006). First, Bayesian analysis is a coherent approach to inference based
on a clear set of axioms. Second, the Bayesian approach handles in a natural way misspecification and lack of identification, both serious concerns in the estimation of DSGE models
(Canova and Sala, 2006). Moreover, it has desirable small sample and asymptotic properties,
even when evaluated by classical criteria (Fernández-Villaverde and Rubio-Ramírez, 2004).
Third, priors are a flexible procedure to introduce presample information and to reduce the
dimensionality problem associated with the number of parameters. This property will be
especially attractive in our application, since parameter drifting will increase the practical
number of dimensions of our model.
¡
¢
The Bayesian approach combines the likelihood of the model L YT ; Ψ with a prior
density for the parameters p (Ψ) to form a posterior
¡
¢
¢
¡
p Ψ| YT ∝ L YT ; Ψ p (Ψ) .

The posterior summarizes the uncertainty regarding the parameters, and it can be used for
point estimation. For example, under a quadratic loss function, our point estimates will be
the mean of the posterior.
Since the posterior is also diﬃcult to characterize, we generate draws from it using a
Metropolis-Hastings algorithm. We use the resulting empirical distribution to obtain point
estimates, variances, etc. We describe this algorithm in the appendix.

22

5. Parameter Drifting
Now we are ready to deal with parameter drifting. Since the extension to other cases of
parameter variation is rather straightforward, we present only one example of drift within
our model.
Motivated by the first example in section 3, we will investigate the situation where the
Taylor rule is specified as:
Rt
=
R

µ

Rt−1
R

¶γ Rt

⎛
⎛ yd ⎞γ yt ⎞1−γ Rt
µ ¶γ Πt
t
d
⎝ Πt
⎝ yt−1 ⎠ ⎠
exp (mt )
Π
Λyd

(9)

Note the diﬀerence with the specification in (5): in the new equation the elasticities of the
©
ª
response of the interest rate γ Rt , γ Πt , γ yt are indexed by time.
We will postulate that the parameters follow an AR(1) in logs to ensure that the parameter
is positive:
©
ª
log γ Rt = min (1 − ρR ) log γ R + ρR log γ Rt−1 + εRt , 0
log γ Πt = (1 − ρΠ ) log γ Π + ρΠ log γ Πt−1 + εΠt
¡
¢
log γ yt = 1 − ρy log γ y + ρy log γ yt−1 + εyt

(10)
(11)
(12)

where {εRt , εΠt , εyt } are i.i.d. normal shocks and Q is a 3 × 3 matrix of covariances.2 We
allow for arbitrary correlation in the innovations, since it is plausible that the reasons why
the monetary authority becomes more (less) responsive to inflation are the same reasons it
will become less (more) responsive to the growth gap. Also, we could generalize the changes
in parameters by allowing changes in Π or in the variance of mt (R and Λyd are not chosen
by the monetary authority but they are implied by the other parameters of the model and
by Π). Finally, we impose the stability condition that the smoothing coeﬃcient γ Rt must be
less than 1 in levels (or less than 0 in logs).
Our specification of parameter drift emphasizes the continuity of the change process, in
opposition to the discrete changes in the parameters captured by a Markov-switching process
(see Davig and Leeper, 2006a and 2006b). We do not have a strong prior preference for one
version or the other. We like our specification because it is parsimonious and easy to handle,
and it captures phenomena such as the Fed’s gradual learning about the behavior of the
©
ª
The autoregressive coeﬃcients ρR , ρΠt , ρy and the matrix Q become in this formulation the new “structural parameters.” We are also skeptical about their true structural nature, but to avoid the infinite regression
problem, we will ignore our doubts for the moment.
2

23

economy.
According to our favorite interpretation of parameter drifting, we will assume that agents
understand that policy evolves over time following (10)-(12). Consequently, they react to it
and make their decisions based on the current values of γ t and on the fact that γ t will evolve
over time.
The drift of the parameters implies that the economy will travel through zones where the
Taylor principle is not satisfied. However, this may not necessarily mean that the equilibrium
is not unique. In the context of Markov-regime changes in the coeﬃcients of the Taylor rule,
Davig and Leeper (2006a) have developed what they call the generalized Taylor principle.
Davig and Leeper argue that a unique equilibrium survives if the Taylor rule is suﬃciently
active when the economy is in the active policy regime or if the expected length of time
the economy will be in the nonactive policy regime is suﬃciently small. To keep this paper
focused, we will not dwell on generating results equivalent to Davig and Leeper’s in our
environment. Suﬃce it to say that one further advantage of the Bayesian approach is that
we can handle restrictions on the parameter drifting with the use of the priors. For example,
we can implement a reflecting boundary on (10) by putting a zero prior on the possibility of
violating that boundary. Also, in our empirical analysis, we estimate γ Π as being bigger than
one. This suggests that the Taylor principle will be satisfied, at least on average.
Our formulation of parameter drifting has one important drawback: we do not model
explicitly why the parameters change over time. In section 3, we discussed that changes
in the policy parameters could be a reflection of changing political priorities or evolving
perceptions about the eﬀectiveness of policy. A more complete model would include explicit
mechanisms through which we discipline the movement of the parameters over time. Many of
those mechanisms can be incorporated into our framework, since we are rather flexible with
the type of functional forms for the parameter drift that we can handle.
The model in section 4 carries on except with the modification of (9) and the fact that all
the conditional expectations now incorporate the process (10). Thus, the states of the model
with parameter drifting are:
⎛

St = ⎝

d
b
b
p
1
2
w
bet−1 , b
bt−1 , b
b t−1 , w
gt−1
, gbt−1
,e
kt−1 , R
yet−1 , b
e
ct−1 , vbt−1
, vbt−1
,b
qet−1 , fet−1 ,
Π

b
b
et−1 , b
zet−1 , zμ,t−1 , dbt−1 , ϕ
b t−1 , zA,t−1 ; γ Rt−1 , γ Πt−1 , γ yt
x
et−1 , λ

⎞0

⎠,

where we have included γ Rt , γ Πt , and γ yt as three additional states. We will follow the
convention of separating drifting parameters from the other states with a “;” since they
are an object of interest by themselves. Similarly, we apply the particle filter to evaluate the
likelihood of the model and the Metropolis-Hastings algorithm to simulate from the posterior.
24

6. Empirical Analysis
This section presents our empirical analysis. First, we report the point estimates of the model
when we keep all parameters fixed over the sample. This estimation sets a natural benchmark
for the rest of the study. Second, we discuss the results of an exercise where we allow the
parameters of the Taylor rule of the monetary authority to change over time. Third, we
analyze the evolution of the parameters that control the level of price and wage rigidities. In
the interest of space, we select these two exercises as particularly illustrative of the procedure
we propose. However, we could have performed many other exercises within the framework
of our methodology.
We estimate the model using five time series for the U.S.: 1) the relative price of investment
with respect to the price of consumption, 2) real output per capita growth, 3) hours worked
per capita, 4) the CPI and 5) the federal funds rate. Our sample goes from 1955:Q1 to
2000:Q4. We stop our sample at the end of 2000 because of the absence of good information
on the relative price of investment after that time. To make the observed series compatible
with the model, we compute both real output and real gross investment in consumption
units. For that purpose, we use the relative price of investment defined as the ratio of an
investment deflator and a deflator for consumption. The consumption deflator is constructed
from the deflators of nondurable goods and services reported in the NIPA. Since the NIPA
investment deflators are poorly measured, we rely on the investment deflator constructed by
Fisher (2006), a series that ends at 2000:Q4. The appendix provides further information on
the construction of the data.
6.1. Point Estimation
Before reporting results, we specify priors for the model’s parameters. We adopt flat priors
for all parameters. We impose boundary constraints only to make the priors proper and
to rule out parameter values that are either incompatible with the model (i.e., a negative
value for a variance, Calvo parameters outside the unit interval) or implausible (the response
to inflation in the Taylor rule being bigger than 100). The looseness of such constraints
is shown by the fact that the simulations performed below never travel even close to the
bounds. Also, we fix four parameters, {υ, φ, Φ2 , δ} . The parameter controlling money demand
υ is irrelevant for equilibrium dynamics because the government will supply as much money
as required to implement the nominal interest rate determined by the Taylor rule. We fix
the parameter φ to zero, since we do not have information on pure profits by firms (in the
absence of entry/exit of firms, there are no serious implications for equilibrium dynamics).
The parameter of the investment adjustment cost, Φ2 , is set to 0.001 and depreciation, δ, to
25

0.0149 because they are diﬃcult to identify. Our choice of δ matches the capital-output ratio
in the data (remember that in our model we have both physical depreciation, controlled by
δ, and economic depreciation induced by the change in the relative price of capital).
Our choice of flat priors is motivated by the observation that, with this prior, the posterior
is proportional to the likelihood function.3 Consequently, our Bayesian results can be interpreted as a classical exercise where the mode of the likelihood function (the point estimate
under an absolute value loss function for estimation) is the maximum likelihood estimate.
Moreover, a researcher who prefers more informative priors can always reweight the draws
from the posterior to accommodate his favorite priors (Geweke, 1998).4 We repeated our
estimation with an informative prior without finding important diﬀerences in the results.
Table 6.1 summarizes our results by reporting the mean and the standard deviation of the
posterior.5 Most of our point estimates coincide with the typical findings of other estimation
exercises and the standard deviations are small. Hence, we comment only on a few of them.
We have a high degree of habit persistence, h is 0.88, and we have a Frisch elasticity of labor
supply of 0.74 (1/1.36), well within the bounds of findings in the recent microeconomic literature (Browning, Hansen, and Heckman, 1999). The estimates of elasticities of substitution
ε and η are around 8, implying average mark-ups of around 14 percent.
[TABLE 6.1 HERE]
The Calvo parameter for price adjustment, θp , is a relatively high 0.91, while the indexation level χp , is 0.15. It is tempting to compare our estimates with the microeconomic evidence
on the average duration of prices (Bils and Klenow, 2004, or Nakamura and Steinsson, 2006).
However, the comparison is diﬃcult because we have partial indexation: prices change every
quarter for all producers, a fraction θp because producers reoptimize and a fraction 1 − θp
because of indexation. The Calvo parameter for wage adjustment, θw , is 0.45, while the
indexation, χw , is 0.85. Our point estimates imply stronger nominal rigidities in price than
in wages, in line with Rabanal and Rubio-Ramírez (2005) or Galí and Rabanal (2004) but
diverging from Smets and Wouters (2003), who have much more informative priors.
©
ª
The policy parameters γ R , γ Π , γ y , Π are quite standard. The Fed smooths the interest
rate over time (γ R is estimated to be 0.79), and responds actively to inflation (γ R is 1.25)
3

There is a small qualifier: the bounded support of the priors. We can fix this small diﬀerence by thinking
about those bounds as frontiers of admissible parameter values in a classical perspective.
4
We do not argue that our flat priors are uninformative. After a reparameterization of the model, a flat
prior may become highly curved. Moreover, if we wanted to use the model for other purposes like forecasting
or to compare it with, for example, a VAR, we would need to elicit our priors more carefully.
5
A word of caution here: the estimates of the standard deviation with the particle filter are relatively unstable (Fernández-Villaverde and Rubio-Ramírez, 2007, and DeJong et al., 2007). Computational constraints
preclude us from running a simulation suﬃciently long to fully avoid this problem.

26

and weakly to the output growth gap (γ y is 0.19). We estimate that the Fed has a target for
quarterly inflation of 0.78 percent (or around 3 percent yearly).
The growth rates of the investment-specific technological change, Λμ , and of the neutral
technology, ΛA , imply that most of the growth in the U.S. economy (83 percent) is induced
by improvements in the capital-producing technology. This result corroborates the importance of modelling biased technological change for understanding growth and fluctuations
that Greenwood, Herkowitz, and Krusell (1997 and 2000) have so forcefully defended. The
estimated long-run growth rate of the economy, (ΛA + αΛμ ) / (1 − α) is 0.4 percent per quarter, or 1.6 percent annually, roughly the observed mean in the sample. Also, the standard
deviation σ μ is much higher than σ A .
Our estimation serves diﬀerent roles. First, it validates our model as a promising laboratory for our exercises with parameter drifting. Since in the benchmark case we obtain results
compatible with the literature and with the basic growth properties of the U.S. economy,
we know that the results with parameter drifting will indeed come from that feature of the
estimation. Second, we use our point estimates to initialize the parameters in the exercises
with parameter drifting.
In the next two subsections, we will report our findings when we allow one parameter
to vary at a time. We do this for convenience. First, allowing several parameters to move
simultaneously makes the computation and estimation of the model much more costly. Second, the information in the sample is limited, and it is diﬃcult to obtain stable estimates
otherwise. Third, especially in our second exercise, our objective is not so much to have the
richest possible model to fit the data well but to show that as soon as you let parameters
change over time, strong signs of misspecification appear. We will continue the exploration
of joint moves of parameters in the near future.
6.2. Evolution of Policy Parameters
Our first exercise studies the evolution of the policy parameters in the Taylor rule. This
investigation evaluates how much evidence there is in the data of a changing monetary policy
over time. As we discussed in section 3, the literature has extensively debated the topic
(Clarida, Galí, and Gertler, 2000, Cogley and Sargent, 2001, Lubick and Schorfheide, 2004,
Sims and Zha, 2006, Boivin, 2006, just to cite some papers). However, the empirical methods
applied so far are unsatisfactory because they rely either on divisions of the sample that do
not let the agents in the model forecast the changes in policy or on the estimation of reduced
forms.
Arguably, the most interesting parameter is γ Πt−1 , since this parameter controls how

27

aggressively the monetary authority responds to inflation. In addition, γ Πt−1 is intimately
linked with the issue of multiplicity of equilibria and the possibility of monetary policy being
a source of instability. Figure 6.2.1 plots our point estimate of the evolution of γ Πt−1 over time
plus the two standard deviations interval to gauge the uncertainty present in the estimation.
We report the smoothed values of γ Πt−1 using the whole sample (Godsill, Doucet, and West,
2004). We find it convenient, for expositional purposes, to eliminate some of the quarter-toquarter variation of the parameter. To accomplish this goal, in figure 6.2.2, we graph the
trend of the change of the parameter where we compute the trend using a Hodrick-Prescott
filter. We emphasize that this trend is only a device to read the graph more clearly and lacks
a formal statistical interpretation.
In both figures 6.2.1 and 6.2.2, γ Πt−1 starts low, slightly above 1 during the 1950s, 1960s,
and early 1970s, with periods when it was even below 1. However, in the mid-1970s, and
especially after Volcker’s appointment as chairman of the Board of Governors, γ Πt−1 soared.
The response to inflation reached its peak in the early 1980s, where it was as high as 6 in one
quarter. After that maximum, γ Πt−1 slowly decreases during the 1990s, perhaps reflecting the
Fed’s more permissive attitude to accommodate the strong productivity growth associated
with the Internet boom.
Since our model has parameter drifting, it is not straightforward to compare these numbers
with estimates obtained in fixed-parameter models. However, we clearly confirm the findings
of Clarida, Galí, and Gertler (2000), Lubick and Schorfheide (2004), and Boivin (2006) that
monetary policy has become much more active in the last 25 years. Our finding is also
consistent with the results of figure 12 in Cogley and Sargent (2001), where they trace the
evolution of the activism coeﬃcient as measured by a parameter-drifting VAR.
Another parameter of importance is the inflation target of the monetary authority, Π.
Histories like those in Taylor (1998), Sargent (1999), or Primiceri (2006) explain that the
inflation target may have changed over time as a reflection of the Fed’s varying beliefs about
the trade-oﬀ between unemployment and inflation. Figure 6.2.3 plots the evolution of the
target over time plus the two standard deviation interval. From the start of the sample until
the early 1970s and, later, for the 1990s, Π hovers around 1.004 or, in annual terms, around
1.6 percent. This number is close to the informal target or comfort zone that describes the
Fed’s behavior according to many commentators. During the intermediate years, the inflation
target increases, reflecting perhaps the views the Fed had about the possibility of exploiting
the Phillips curve or illustrating the information lags regarding the changing features of the
economy emphasized by Orphanides (2002). We find intriguing the similarity of figure 6.2.3 to
Romer and Romer’s (2002) hypothesis, based on narrative accounts and internal Greenbook
forecasts of the Fed, that monetary policy in the U.S. has gone through a long cycle of
28

moderation, aggressiveness, and renewed temperance.
Our estimates of the evolution of the inflation target provide a reality check on our procedure. In figure 6.2.4, we plot the inflation target versus realized inflation. If the estimation
is working properly, part of the variation in the inflation target needs to be accounted for,
in a purely mechanical fashion, by changes in inflation. That is precisely what we observe:
as inflation increases and then falls during the late 1960s and the 1970s, the target inflation
estimated goes up and down.
Note, however, that the inflation target fluctuates roughly between 40 and 50 percent
less than inflation. In particular during the 1970s, the inflation target is well below actual
inflation. This diﬀerence is accounted in two ways. First, by the form of our Taylor rule. We
d
assume that one input into the rule is the growth gap between the growth of output ytd /yt−1
and the long-run growth rate of the economy Λyd . The 1970s were years of very low growth
in comparison with Λyd .6 Thus, our model interprets the behavior of the Fed as lowering the
interest rates as a response to low output growth in exchange for higher inflation. Second, our
model backs up large negative technology shocks in the 1970s that push inflation above the
target level. Hence, an alternative way to think about this result is that our model suggests
that the big rise in inflation during the 1970s had less to do with changes in the inflation
target than with a series of unfavorable aggregate shocks.
We summarize our results. First, the Fed’s response towards inflation became more aggressive in the late 1970s and early 1980s and has stayed high since then with perhaps a small
fall. Second, the inflation target was relaxed in the 1970s but not enough to account for the
high inflation of that decade. We trust our results not only because they come from the
estimation of a coherent DSGE model, but also because they are consistent with the findings
of the existing literature that uses alternative estimation procedures, with narrative accounts
of monetary policy, and with the reality check explained above.
6.3. Evolution of Price and Wage Rigidities
A key set of parameters in our model are those determining the extent of price and wage
©
ª
rigidities, θp , χp , θw , χw . These four parameters generate the nominal rigidity in the economy required to match the impulse response functions documented by VARs (Christiano,
Eichenbaum, and Evans, 2005).
Given their importance in the model, it is unfortunate that these parameters have only
a tenuous link with microeconomic foundations. Even if the Calvo adjustment probabilities
6

This observation may have motivated a model where Λyd changes over time, but such models are, as
argued by Bansal and Yaron (2004), quite diﬃcult to estimate in small samples.

29

are the reduced form of a convex adjustment cost model, the environment that produces
this reduced form has changed over the years in our sample. We have gone from periods
of high inflation and low response of the monetary authority to rising prices to periods of
much lower inflation and a more aggressive attitude toward inflation by the Fed. Moreover,
the U.S. economy has experienced a notable level of deregulation, increasing competition in
internal markets from international trade, and lower unionization rates. The justification of
the indexation parameters or their relation to the Calvo adjustment probabilities is even less
clear. Why do agents index their prices and wages? And if they do, to which quantity? Past
inflation? Current inflation? Steady-state inflation? Wage inflation? Consequently, it is
©
ª
natural to examine the possibility that the parameters θp , χp , θw , χw drift over time, both
as a measure of how strong nominal rigidities have been in each diﬀerent moment and as a
tool to assess the extent of possible misspecification of the model along this dimension.
As in the case of policy parameters, we specify an AR(1) as the law of motion for the
parameters:
log θpt =
log χpt =
log θwt =
log χwt =

´
n³
o
min 1 − ρθp log θp + ρθp log θpt−1 + εθp t , 0
´
n³
o
min 1 − ρχp log χp + ρχ log χpt−1 + εχp t , 0
©¡
ª
¢
min 1 − ρθw log θw + ρθw log θwt−1 + εθw t , 0
©¡
ª
¢
min 1 − ρθw log χw + ρχ log χwt−1 + εχw t , 0

o
n
where εθp t , εχp t , εθw t , εχw t are i.i.d. normal shocks and where we take the minimum of the
value of the parameter induced by the autoregressive component and 0 to be sure that the
parameters are less than 1 in levels (they will always be more than 0 because we are taking
logs).
We report first the experiment where we let θpt , the Calvo parameter of price changes,
evolve over time. We find it more informative (and more directly comparable to the micro evidence) to report the average duration of the spell before the producers reoptimize,
1 (/1 − θpt ), in quarter terms. Figure 6.3.1 plots that duration while figure 6.3.2 plots the
HP-trend and, for comparison purposes, the HP-trend of the CPI. In this figure, as in all the
rest of the figures of the paper where we plot two diﬀerent variables, we follow the convention
that the continuous line represents the parameter on the left y-axis and the discontinuous
one the parameter on the right y-axis.7
7

We do not plot the standard deviations interval for the average price duration (neither later for the
average wage duration) because the transformation 1 (/1 − θpt ) generates implausibly large upper bounds as
soon as the simulation of θpt travels close to 1. The standard deviations interval for θpt show, however, that

30

Figures 6.3.1 and 6.3.2 reveal a clear pattern: average duration was high in the late 1950s,
dropped quickly in the 1960s, and only started to pick up in the late 1970s, continuing with
an upward trend until today. Interestingly enough, the changes in the average duration of
the spell before the producers reoptimize are strongly correlated with changes in inflation.
In figure 6.3.2 we see how times of increasing trend inflation (late 1960s, 1970s) are times of
falling average duration and vice versa: how times of decreasing trend inflation (the 1980s
and the 1990s) are times of increasing average duration.
Our second experiment regarding price rigidities is with χpt , the parameter that controls
price indexation. Figure 6.3.3 plots the evolution of the parameter over the sample plus the
two standard deviation interval and figure 6.3.4 its HP-trend (again, with the HP-trend of
the CPI superimposed). Indexation evolves in an opposite way to price duration: it starts
low in the 1950s and 1960s but rises very strongly during the late 1960s. Then, it drops
dramatically in the mid-1970s and stays low over the next 20 years (except for a temporary
increase in the early 1980s). In the last part of the sample, during the 1990s, χpt steadily
drops. The drop in indexation in the second half of the 1970s may be accounted for by firms
switching to more often optimal price adjustments and less automatic pricing rules. Firms
were perhaps induced by the volatile inflation of those years, which made partial indexation
a costly option. Mechanically, our estimation finds less indexation because inflation is less
persistent in the 1970s.
We find it illuminating to combine the evolution of the Calvo parameter θpt and of indexation χpt . We do so in figure 6.3.5 (for their levels) and in figure 6.3.6 (for their HP-trends).
The comparison of both parameters shows that periods of high price rigidities are also periods
of low indexation. The converse is true as well, except for the mid-1970s. This result points
out that adding indexation as an ad hoc procedure to increase the level of inflation inertia
may hide important dynamics in price adjustments.
We repeat our two experiments for wages. Figure 6.3.7 (in levels) and figure 6.3.8 (in HPtrends, with inflation superimposed) plot the evolution of the average duration of the spell
before workers reoptimize wages, 1 (/1 − θwt ), in quarter terms. In this case the evidence is
more diﬃcult to interpret, with a big spike in the second half of the 1980s which is probably
due to sampling uncertainty. However, it is still the case that, during the 1970s, as inflation
went up, wage rigidity went down, and as inflation was tamed in the early 1980s, wages again
became more rigid.
Figures 6.3.9 and 6.3.10 draw the evolution of wage indexation. Here, in comparison, the
clarity of the result is embarrassing: wage indexation is nearly the perfect mirror of inflation.
the parameter itself is estimated without too much uncertainty.

31

As we did for prices, we interpret this finding as the natural consequence of workers switching
to more often wage reoptimizations that make indexation less of an interesting rule in times of
high inflation.8 Less wage indexation is what the model needs to capture the higher volatility
of inflation in the data.
For completeness, we finish our graphical display with figures 6.3.11 to 6.3.16, where we
plot the evolution of the diﬀerent parameters controlling nominal rigidities against others.
Because of space constraints, we refrain from further discussion of the plots. However, the
reader can appreciate that the similarity in the evolution of the parameters over time solidifies
our confidence that we are uncovering a systematic pattern of relationships between nominal
rigidities and inflation.
We consider our findings to be strong proof of the changing nature of the nominal rigidities
in the economy and of a strong indication of model misspecification along the dimension of
price and wage adjustment. Calvo’s price adjustment cannot capture the evolution of the
fundamentals that determine the pricing decisions of firms and households. Our results
underscore that this problem is relevant empirically. Also, they suggest that the evidence
in Klenow and Kryvtsov (2005) that the intensive margin of price changes accounts for 95
percent of the monthly variance of inflation may be a product of the sample period (19882003), where the low level of inflation limits identification because it eliminates the source of
variation of the data. Indeed, in our figures 6.3.5 and 6.3.6, if we look at the period 1988-2000,
we observe less variation in the pricing parameters.
There are at least two possible sources for this misspecification of the pricing mechanism
of the model that could rationalize our findings. First, time-varying price and wage rigidity
parameters may be revealing a problem of omitted variables. For example, a change in the
probability of price adjustment translates into a diﬀerent slope of the (implicit) Phillips curve
in our model and thus, into a variation of inflation. However, in the data, there are other
shocks that aﬀect inflation, like the price of energy, the price of commodities, or exchange
rate fluctuations. Since we do not include these shocks, we may be capturing the changing
influence of these sources of inflation through variations in the Calvo parameters.9
8

During the early 1970s, there was a raise in the prevalence of cost-of-living allowance (COLA) escalators
in collective bargaining agreements (Hendricks and Kahn, 1985). This observation could be used to undermine
our result. However, even at their peak, COLAs only covered 6 million workers, a small percentage of the
labor force. Moreover, it is diﬃcult to map COLAs from the 1970s into our model, since they had many
contingent rules that make them quite diﬀerent from the naïve indexation rules that we use. In fact, it could
even be possible to think about a state-contingent COLA as an implicit form of reoptimization.
9
Similarly, part of the variation in the Calvo parameters may be accounted for by mark-up shocks, which
play an important role in models like Smets and Wouters’ (2003). However, it is diﬃcult to see which type of
mark-up shocks will have the level of persistence that we observe in the movements of the Calvo parameters
that we estimate.

32

The second source of misspecification may be the time-dependent structure of pricing
(either à la Calvo as in the model we have presented or à la Taylor). Thus, we can read our
results as favoring models of state-dependent pricing (Caballero and Engel, 1993, Caplin and
Leahy, 1991 and 1997), since those have an endogenously changing duration of prices and
wages. The extra analytical diﬃculty implied by state-dependent models (Dotsey, King, and
Wolman, 1999) may be a price we are forced to pay. Another strand of the literature that may
consider our results interesting is the one that deals with sticky information (Mankiw and
Reiss, 2002, and Sims, 2002). Higher inflation increases the incentives to gather information
and, hence, it is likely to imply more frequent price and wage adjustments.
Finally, our findings have relevant implications for optimal policy design. First, if we
interpret the evolution of parameters like θpt as exogenously given, it may be something that
the monetary authority may condition its behavior on (we do not enter into a discussion
of how it would estimate them in real time, we only raise this as a theoretical possibility).
Second, if we read our results as showing that the measured amount of price rigidities are
endogenous to monetary policy, optimal design becomes tougher than in the basic Ramsey
exercises.

7. Conclusion
How structural are the structural parameters of DSGE models? Less so than we often claim.
Our analysis indicates that there are large variations in the estimated values of several of
the key parameters of a benchmark medium-scale macroeconomic model during our sample
period.
We document changes in the response of the monetary authority to inflation and in the
inflation target that confirm previous findings by other researchers. In particular, we report a
move by the Fed toward a much more aggressive stand against raising prices in the late 1970s.
Also, we find that changes in the inflation target account, at most, for 40-50 percent of the
increase in inflation in the 1970s. Our results are remarkable because they are derived in a
context where agents understand that policy evolves over time and respond to that evolution.
We uncover that the parameters controlling nominal rigidities drift in a substantial way,
and more important, are strongly correlated with inflation. These findings cast serious doubts
on the usefulness of models based on Calvo pricing and invite deeper investigations of statedependent pricing models.
We do not want our work to be interpreted as a sweeping criticism of the estimation of
DSGE models, because it is not. The literature has made impressive progress over the last
years and has contributed much to improving our understanding of aggregate fluctuations
33

and the eﬀects of economic policy. We ourselves have been engaged in this research agenda
and plan to continue doing so. We hope, instead, that our paper will be read as an invitation
to further estimation of DSGE models with parameter drifting. This avenue is promising,
both as a mechanism for incorporating richer dynamics and as a diagnostic tool for detecting
gross misspecifications.
In fact, as our discussants have rightly pointed out, much remains to be done. We have
only scratched the surface of the problem of estimating DSGE models with parameter drifting.
We have not explored the model when we have diﬀerent sources of variations in the parameters
at the same time or when there is stochastic volatility in the shocks. Also, we have not
studied the consequences of drifting parameters for the dynamics of the business cycle or
for the impulse-response functions of the model. Finally, we have not evaluated diﬀerent
specifications of parameter drift or analyzed the possible reasons for parameter drifting in
detail.
Our skepticism about the structural nature of most “structural” parameters is not a call
to perform reduced-form exercises. Along with Tom Sargent and Mark Watson (FernándezVillaverde et al., 2007), we have singled out some of the problems of estimating reducedform models. But there are many other papers emphasizing the weaknesses of reduced-form
inference, too many indeed to even bother with a list. The fundamental point is that every
empirical procedure has strengths and limitations. As Hurwicz (1962) warned us many years
ago, just because we name something “structural,” we should not believe we have taken the
theoretical high-ground.

8. Appendix
This appendix oﬀers further details about the technical aspects of the paper. First, we discuss
some general computational aspects and elaborate on the solution of the model. Second, we
describe the particle filter that evaluates the likelihood function of the model. Third, we
comment on the estimation procedure. Fourth, we close with the details of the construction
of the data.
8.1. Computation of the Model
The most important feature of the algorithm to be described below to solve and estimate the
model is that it can be implemented on a good desktop computer. We coded all programs for
the perturbation of the model and the particle filter in Fortran 95 and compiled them in Intel
Visual Fortran 9.1 to run on Windows-based machines (except some Mathematica programs

34

to generate analytic derivatives). We use a Xeon Processor 5160 EMT64 at 3.00 GHz with
16 GB of RAM.
The solution of the model is challenging because we have 19 state variables plus the drifting
parameters that we allow in each empirical exercise. Moreover, we need to recompute the
solution of the model for each new set of parameter values in the estimation. The only
non-linear procedure that accomplishes this computation in a reasonable amount of time is
perturbation (Aruoba, Fernández-Villaverde, and Rubio-Ramírez, 2006). We implement our
solution by perturbing the equilibrium conditions of the rescaled version of the model (i.e.,
the one where we have already eliminated the two unit roots) around the deterministic steady
state. This means that the solution is locally accurate regardless of the level of technology in
the economy. Also, note that the steady state will depend on the level of inflation targeted
by the monetary authority.
We use Mathematica to compute the analytical derivatives and to generate Fortran 95
code with the corresponding analytical expression. Then, we load that output into a Fortran
95 code that evaluates the solution of the model for each parameter value as implied by the
Metropolis-Hastings algorithm to be described below. The solution will have the form:
³ 0
´0
³ 0 ´0 1 ³ 0 ´
³ 0 ´0
S t+1 , Jt0 = Γs1 S t , ε0t +
S t , ε0t Γs2 S t , ε0t + Γs3
2

(13)

where, recalling our notation, S t are the states, εt are the shocks, Jt is a vector of variables
of interest in the model that are not states, and the Γsi ’s are matrices of the right size. With
(13), and by selecting the appropriate rows, we build the state space representation:
³ 0 ´0 1 ³ 0 ´
³ 0 ´0
S t+1 = Ψs1 S t , ε0t +
S t , ε0t Ψs2 S t , ε0t + Ψs3
2
1
0
0
Y T = Ψo1 (St0 , ε0t ) + (St0 , ε0t ) Ψo2 (St0 , ε0t ) + Ψo3
2
´
³ 0 0
¡
¢0
0
where St = S t , S t−1 , εt−1 and Y T = 4 log μ−1
t , 4 log yt , 4 log lt , log Πt , log Rt .
8.2. Description of the Particle Filter
We provide now a short description of the particle filter. We will deliberately focus on the
intuition of the procedure and we will gloss over many technical issues that are relevant for
a successful application of the filter. We direct the interested reader to Fernández-Villaverde
and Rubio-Ramírez (2007), where we discuss most of those issues in detail, and the articles
in Doucet, de Freitas, and Gordon (2001), which present improved sequential Monte Carlo
algorithms, like Pitts and Shephard’s (1999) auxiliary particle filter.
35

As we described in the main text, given the Markov structure of our state space representation, we can factorize the likelihood function as:
T
¡
¢
¡ T ¢ Y
L Yt |Yt−1 ; Ψ
L Y ;Ψ =
t=1

and obtain the factorization:
¡
¢
L YT ; Ψ =

Z

L (Y1 |S0 ; Ψ) dS0

T Z
Y
t=2

¡
¢
L (Yt |St ; Ψ) p St |Yt−1 ; Ψ dSt

(14)

T

Consequently, if we had the sequence {p (St |Yt−1 ; Ψ)}t=1 and p (S0 ; Ψ), we could evaluate
the likelihood of the model. Santos and Peralta-Alva (2005) show conditions under which
we can draw the numerical solution of the model to approximate p (S0 ; Ψ). The two diﬃculties of evaluation (14) are then to characterize the sequence of conditional distributions
T
{p (St |Yt−1 ; Ψ)}t=1 and to compute the diﬀerent integrals in the expression.
The particle filter begins from the observation that, if somehow we can get N draws of the
½n
oN ¾T
T
i
form
st|t−1
from the sequence {p (St |Yt−1 ; Ψ)}t=1 , we can appeal to a law of large
i=1

t=1

numbers and substitute the integrals with a mean of the conditional likelihoods evaluated in
the empirical draws:
N
T
N
¡ T ¢
¢Y
¢
1 X ¡
1 X ¡
i
L Y ;Ψ '
L Y1 |s0|0 ; Ψ
L Yt |sit|t−1 ; Ψ
N i=1
N i=1
t=2

where our notation for the draws indicates in the subindex the conditioning set (i.e., t|t − 1
means a draw at moment t conditional on information until t − 1) and the superindex denotes
the index of the draw. The intuition of the procedure is that we substitute the exact but
T
unknown sequence {p (St |Yt−1 ; Ψ)}t=1 by its empirical counterpart.
T
How do we draw from {p (St |Yt−1 ; Ψ)}t=1 ? The second key idea of the particle filter is
that we can extend importance sampling (Geweke, 1989) to a sequential environment. The
following proposition, due in its original form to Rubin (1988), formalizes the idea:
n
oN
N
i
Proposition 1. Let st|t−1
be a draw from p (St |Yt−1 ; Ψ). Let the sequence {e
sit }i=1 be
i=1
n
oN
a draw with replacement from sit|t−1
where the resampling probability is given by
i=1

´
³
L Yt |sit|t−1 ; Ψ
³
´,
qti = P
N
i
i=1 L Yt |st|t−1 ; Ψ
36

N

Then {e
sit }i=1 is a draw from p (St |Yt ; Ψ).

n
oN
The proposition 1 shows how to recursively use a draw sit|t−1
from p (St |Yt−1 ; Ψ)
i=1
n oN
to get a draw sit|t
from p (St |Yt ; Ψ). This result is crucial. It allows us to incorporate
i=1
the information in Yt to change our current estimate of St . This is why this step is known
in filtering theory as update (the discerning reader has probably already realized that this
update is nothing more than an application of Bayes’ theorem).
The resampling step is key for the success of the filter. A naïve extension of Monte Carlo
½n
oN ¾T
i
techniques will just draw a whole sequence of
st|t−1
without stopping period by
i=1

t=1

period to resample according to proposition 1. Unfortunately, this naïve scheme diverges.
The reason is that all the sequences become arbitrarily far away from the true sequence of
states, which is a zero measure set and the sequence that is closer to the true states dominates
all the remaining ones in weight. A simple simulation shows that the degeneracy appears
even after very few steps.
n oN
, we draw N exogenous shocks, something quite simple, since the shocks in
Given sit|t
i=1¡
¢0
our model εit+1 = εiμ,t+1 , εid,t+1 , εiϕ,t+1 , εiA,t+1 , εim,t+1 are normally distributed. Then, we apoN
n
ply the law of motion for states that relates the sit|t and the shocks εit+1 to generate sit+1|t
.
i=1
This step, known as forecast, put us back at the beginning of proposition 1, but with the
diﬀerence that we have moved forward one period in our conditioning.
The following pseudocode summarizes the description of the algorithm:

n oN
Sample N values si0|0
from p (S0 ; Ψ).
n i=1 oN
n
oN
using sit−1|t−1
, the law of
Step 1, Prediction: Sample N values sit|t−1
i=1
i=1
motion for states and the distribution of ³shocks
´ εt .
Step 2, Filtering: Assign to each draw sit|t−1 the weight qti in proposition
1.
n
oN
i
Step 3, Sampling: Sample N times with replacement from st|t−1
using the
i=1
³ ´
N
probabilities {qti }i=1 . Call each draw sit|t . If t < T set t Ã t + 1 and go to
step 1. Otherwise stop.
Step 0, Initialization: Set t Ã 1.

With the output of the algorithm, we just substitute into our formula
N
T
N
¢Y
¢
¡ T ¢
1 X ¡
1 X ¡
i
L Y1 |s0|0 ; Ψ
L Yt |sit|t−1 ; Ψ
L Y ;Ψ '
N i=1
N i=1
t=2

37

(15)

and get an estimate of the likelihood of the model. Del Moral and Jacod (2002) and Künsch
(2005) show weak conditions under which the right-hand side of the previous equation is a
¡
¢
consistent estimator of L YT ; Ψ and a central limit theorem applies.
8.3. Estimation Procedure
We mention in the main part of the text that the posterior of the model
¡
¢
¡
¢
p Ψ| YT ∝ L YT ; Ψ p (Ψ)

is diﬃcult, if not impossible, to characterize. However, we can draw from it and build its
empirical counterpart using a Metropolis-Hastings algorithm. The algorithm is as follows:
Step 0, Initialization: Set i Ã 0 and an initial Ψi . Solve the model for Ψi
and build the state space representation. Evaluate prior p (Ψi ) and approximate
¡
¢
L YT ; Ψ with (15). Set i Ã i + 1.
¡
¢
Step 1, Proposal draw: Get a draw Ψ∗i from a proposal density q γ i−1 , γ ∗i .
Step 2, Solving the Model: Solve the model for Ψ∗i and build the new state
space representation.
¡
¢
Step 3, Evaluating the proposal: Evaluate p (Ψ∗i ) and L YT ; Ψ∗i with (15).
L(YT ;Ψ∗ )p(Ψ∗ )q (Ψi−1 ,Ψ∗ )
set
Step 4, Accept/Reject: Draw χi ∼ U (0, 1). If χi ≤ L(YT ;Ψ i )p(Ψ i )q Ψ∗ ,Ψ i
i−1
i−1 ( i
i−1 )
Ψi = Ψ∗i , otherwise Ψi = Ψi−1 .
Step 5, Iteration: If i < M, set i Ã i + 1 and go to step 1. Otherwise stop.
This algorithm requires us to specify a proposal density q (·, ·). We follow the standard
practice and choose a random walk proposal, Ψ∗i = Ψi−1 + κi , κi ∼ N (0, Σκ ), where Σκ is a
scaling matrix. This matrix is selected to get the appropriate acceptance ratio of proposals
(Roberts, Gelman and Gilks, 1997).
To reduce the “chatter” of the problem, we will keep the innovations in the particle
filter (i.e., the draws from the exogenous shock distributions and the resampling probabilities) constant across diﬀerent passes of the Metropolis-Hastings algorithm. As pointed out
by McFadden (1989) and Pakes and Pollard (1989), this is required to achieve stochastic
equicontinuity, and even if this condition is not strictly necessary in a Bayesian framework,
it reduces the numerical variance of the procedure.

38

8.4. Construction of Data
As we mention in the text, we compute both real output and real gross investment in consumption units to make the observed series compatible with the model. We define the relative
price of investment as the ratio of the investment deflator and the deflator for consumption.
The consumption deflator is constructed from the deflators of nondurable goods and services reported in the NIPA. Since the NIPA investment deflators are poorly measured, we
use the investment deflator constructed by Fisher (2006). For the real output per capita
series, we first define nominal output as nominal consumption plus nominal gross investment.
We define nominal consumption as the sum of personal consumption expenditures on nondurable goods and services, national defense consumption expenditures, federal nondefense
consumption expenditures, and state and local government consumption expenditures. We
define nominal gross investment as the sum of personal consumption expenditures on durable
goods, national defense gross investment, federal government nondefense gross investment,
state and local government gross investment, private nonresidential fixed investment, and private residential fixed investment. Per capita nominal output is defined as the ratio between
our nominal output series and the civilian noninstitutional population between 16 and 65.
Since we need to measure real output per capita in consumption units, we deflate the series
by the consumption deflator. For the real gross investment per capita series, we divide our
above mentioned nominal gross investment series by the civilian noninstitutional population
between 16 and 65 and the consumption deflator. Finally, the hours worked per capita series
is constructed with the index of total number of hours worked in the business sector and the
civilian noninstitutional population between 16 and 65. Since our model implies that hours
worked per capita are between 0 and 1, we normalize the observed series of hours worked per
capita such that it is, on average, 0.33.

References
[1] Adolfson, M., S. Laséen, J. Lindé, and M. Villani (2005). “Bayesian Estimation of an
Open Economy DSGE Model with Incomplete Pass-Through.” Sveriges Riksbank Working Paper Series 179.
[2] An, S. and F. Schorfheide (2006). “Bayesian Analysis of DSGE Models.” Econometric
Reviews, forthcoming.
[3] Andrés, J., P. Burriel, and A. Estrada (2006). “BEMOD: a DSGE Model for the Spanish
Economy and the Rest of the Euro Area.” Documento de Trabajo del Banco de España
0631.
[4] Aruoba, S.B., J. Fernández-Villaverde, and J. Rubio-Ramírez (2006). “Comparing Solution Methods for Dynamic Equilibrium Economies.” Journal of Economic Dynamics
and Control 30, 2477-2508.
39

[5] Arulampalam, A.S., S. Maskell, N. Gordon, and T. Clapp (2002). “A Tutorial on Particle
Filters for Online Nonlinear/Non-Gaussian Bayesian Tracking.” IEEE Transactions on
Signal Processing 50, 174-188.
[6] Bansal, R. and A. Yaron (2004). “Risks For The Long Run: A Potential Resolution of
Asset Pricing Puzzles.” Journal of Finance 59, 1481-1509
[7] Benati, L. (2006). “Investigating Inflation Persistence Across Monetary Regimes.”
Mimeo, European Central Bank.
[8] Bernanke, B.S. and I. Mihov (1998). “Measuring Monetary Policy.” Quarterly Journal
of Economics 113, 869-902.
[9] Bils, M. and P. Klenow (2004). “Some Evidence on the Importance of Sticky Prices.”
Journal of Political Economy 112, 947-985.
[10] Boivin, J. (2006). “Has U.S. Monetary Policy Changed? Evidence from Drifting Coeﬃcients and Real-Time Data.” Journal of Money, Credit and Banking, forthcoming.
[11] Boivin, J. and M. Giannoni (2006). “DSGE Models in a Data-Rich Environment.” NBER
Working Paper 12272.
[12] Browning, M., L.P. Hansen, and J.J. Heckman (1999). “Micro Data and General Equilibrium Models.” in J.B. Taylor & M. Woodford (eds.), Handbook of Macroeconomics,
volume 1, chapter 8, 543-633. Elsevier.
[13] Caballero, R. and E. Engel (1999). “Heterogeneity and Output Fluctuations in a Dynamic Menu-Costs Economy.” Review of Economic Studies 60, 95-119.
[14] Canova, F. (2005). “Monetary Policy and the Evolution of the U.S. Economy.” Mimeo,
CREI.
[15] Canova, F. and L. Sala (2006). “Back to Square One: Identification Issues in DSGE
Models.” Mimeo, CREI.
[16] Caplin, A. and J. Leahy (1991). “State-Dependent Pricing and the Dynamics of Money
and Output.” Quarterly Journal of Economics, 106, 683-708.
[17] Caplin, A. and J. Leahy (1997). “Aggregation and Optimization with State-Dependent
Pricing.” Econometrica 65, 601-626.
[18] Christiano, L., M. Eichenbaum, and C.L. Evans (2005). “Nominal Rigidities and the
Dynamic Eﬀects of a Shock to Monetary Policy.” Journal of Political Economy 113,
1-45.
[19] Christoﬀel, K, G. Coenen, and A. Warne (2007). “The New Area-Wide Model of the Euro
Area: Specification and First Estimation Results.” Mimeo, European Central Bank.
[20] Chung, H., T. Davig, and E. Leeper (2006). “Monetary and Fiscal Policy Switching.”
Mimeo, Indiana University.
[21] Clarida, R., J. Galí, and M. Gertler (2000). “Monetary Policy Rules and Macroeconomic
Stability: Evidence and Some Theory.” Quarterly Journal of Economics 115, 147-180.
[22] Cogley, T. and T.J. Sargent (2001). “Evolving Post-World War II U.S. Inflation Dynamics.” NBER Macroeconomics Annual, vol. 16.

40

[23] Cogley, T. and T.J. Sargent (2005). “Drifts and Volatilities: Monetary Policies and
Outcomes in the Post WWII U.S.” Review of Economic Dynamics 8, 262-302.
[24] Cogley, T. and A. Sbordone (2006). “Trend Inflation and Inflation Peristence in the New
Keynesian Phillips Curve.” Mimeo, University of California at Davis.
[25] Cooley, T.F. and E.C. Prescott (1976). “Estimation in the Presence of Stochastic Parameter Variation.” Econometrica 44, 167-184.
[26] Cooley, T.F. and E.C. Prescott (1995), “Economic Growth and Business Cycles” in T.
F. Cooley (ed.), Frontiers of Business Cycle Research. Princeton University Press.
[27] Davig, T. and E. Leeper (2006a). “Generalizing the Taylor Principle.” American Economic Review, forthcoming.
[28] Davig, T. and E. Leeper (2006b). “Endogenous Monetary Policy Regime Change.” NBER
International Seminar on Macroeconomics, forthcoming.
[29] DeJong, D.N., H. Dharmarajan, R. Liesenfeld, and J.F. Richard (2007). “An Eﬃcient Filtering Approach to Likelihood Approximation for State-Space Representations.” Mimeo,
University of Pittsburgh.
[30] Del Moral P. and J. Jacod (2002), “The Monte-Carlo Method for Filtering with Discrete
Time Observations. Central Limit Theorems.” in T. J. Lyons and T. S. Salisbury (eds.),
Numerical Methods and Stochastics. The Fields Institute Communications, American
Mathematical Society.
[31] Dotsey, M., R.G. King, and A. Wolman (1999). “State Dependent Pricing and the General Equilibrium Dynamics of Money and Output.” Quarterly Journal of Economics
655-690.
[32] Doucet. A., N. de Freitas, and N. Gordon (2001). Sequential Monte Carlo Methods in
Practice. Springer Verlag.
[33] Erceg, C.J., L. Guerrieri, and Christopher Gust (2006). “SIGMA: A New Open Economy
Model for Policy Analysis.” International Journal of Central Banking 2, 1-50.
[34] Farmer, R., D. Waggoner, and T. Zha (2006). “Indeterminacy in a Forward Looking
Regime Switching Model.” Mimeo, UCLA.
[35] Fernández-Villaverde, J. and J. Rubio-Ramírez (2004). “Comparing Dynamic Equilibrium Models to Data: a Bayesian Approach.” Journal of Econometrics, 123, 153-187.
[36] Fernández-Villaverde, J. and J. Rubio-Ramírez (2005). “Estimating Dynamic Equilibrium Economies: Linear versus Nonlinear Likelihood.” Journal of Applied Econometrics,
20, 891-910.
[37] Fernández-Villaverde, J. and J. Rubio-Ramírez (2007). “Estimating Macroeconomic
Models: A Likelihood Approach.” Review of Economic Studies, forthcoming.
[38] Fernández-Villaverde, J., J. Rubio-Ramírez, and M.S. Santos (2006). “Convergence
Properties of the Likelihood of Computed Dynamic Models.” Econometrica 74, 93-119.
[39] Fernández-Villaverde, J., J. Rubio-Ramírez, T.J. Sargent, and M. Watson (2006).
“A,B,C’s (and D)’s for Understanding VARs.” American Economic Review, forthcoming.
[40] Fisher, J. (2006). “The Dynamic Eﬀects of Neutral and Investment-Specific Technology
Shocks.” Journal of Political Economy 114, 413-451.
41

[41] Galí, J. and P. Rabanal (2004). “Technology Shocks and Aggregate Fluctuations: How
Well does the RBC Model Fit Postwar U.S. Data?” NBER Macroeconomics Annual,
vol. 19.
[42] Geweke, J. (1989). “Bayesian Inference in Econometric Models Using Monte Carlo Integration.” Econometrica 24, 1037-1399.
[43] Godsill, S.J., A. Doucet, and M. West (2004). “Monte Carlo Smoothing for Nonlinear
Time Series.” Journal of the American Statistical Association 99, 156-168.
[44] Greenwood, J, Z. Herkowitz, and P. Krusell (1997). “Long-Run Implications of
Investment-Specific Technological Change.” American Economic Review 87, 342-362.
[45] Greenwood, J, Z. Herkowitz, and P. Krusell (2000). “The Role of Investment-Specific
Technological Change in the Business Cycle.” European Economic Review 44, 91-115.
[46] Justiniano A. and G.E. Primiceri (2005). “The Time Varying Volatility of Macroeconomic Fluctuations.” Mimeo, Northwestern.
[47] Hendricks, W.E. and L. Khan (1985). Wage Indexation in the United States: Cola or
Uncola? Cambridge: Ballinger Publishing Company.
[48] King, T.B. (2006). “Dynamic Equilibrium Models with Time-Varying Structural Parameters.” Mimeo, Washington University.
[49] Künsch, H.R. (2005). “Recursive Monte Carlo Filters: Algorithms and Theoretical
Analysis.” Annals of Statistics 33, 1983-2021.
[50] Lubick, T. and F. Schorfheide (2004). “Testing for Indeterminacy: An Application to
U.S. Monetary Policy.” American Economic Review 94, 190-217.
[51] Mankiw, G.N. and R. Reiss (2002). “Sticky Information versus Sticky Prices: A Proposal
to Replace the New Keynesian Phillips Curve.” Quarterly Journal of Economics 117,
1295-1328.
[52] McFadden, D.L. (1989). “A Method of Simulated Moments for Estimation of Discrete
Response Models Without Numerical Integration.” Econometrica 57, 995-1026.
[53] Murchison, S. and A. Rennison (2006). “ToTEM: The Bank of Canada’s New Quarterly
Projection Model.” Bank of Canada Technical Report 97.
[54] Nakamura, E. and J. Steinsson (2006). “Five Facts About Prices: A Reevaluation of
Menu Cost Models.” Mimeo, Harvard University.
[55] Oliner, S. G. Rudebusch, and D. Sichel (1996) “The Lucas Critique Revisited: Assessing
the Stability of Empirical Euler Equations for Investment.” Journal of Econometrics 70,
291-316.
[56] Orphanides, A. (2002). “Monetary Policy Rules and the Great Inflation.” American
Economic Review 92, 115-120.
[57] Owyang, M.T. and G. Ramey (2004). “Regime Switching and Monetary Policy Measurement.” Journal of Monetary Economics 51, 1577-1597.
[58] Pakes, A. and D. Pollard (1989). “Simulation and the Asymptotics of Optimization
Estimators.” Econometrica 57, 1027-1057.

42

[59] Pitt, M.K. and N. Shephard (1999). “Filtering via Simulation: Auxiliary Particle Filters.” Journal of the American Statistical Association 94, 590-599.
[60] Ploberger, W. and P.C.B. Phillips (2003). “Empirical Limits for Time Series Econometric
Models.” Econometrica 71, 627-673.
[61] Primiceri, G.E. (2005). “Time Varying Structural Vector Autoregressions and Monetary
Policy”. Review of Economic Studies 72, 821-852.
[62] Primiceri, G.E. (2006). “Why Inflation Rose and Fell: Policymakers’ Beliefs and US
Postwar Stabilization Policy.” Quarterly Review of Economics 121, 867-901
[63] Rabanal, P. (2007). “Does Inflation Increase after a Monetary Policy Tightening? Answers based on an Estimated DSGE Model.” Journal of Economic Dynamics and Control
31, 906-937.
[64] Rabanal, P. and J.F. Rubio-Ramírez (2005). “Comparing New Keynesian Models of the
Business Cycle: A Bayesian Approach.” Journal of Monetary Economics 52, 1151-1166.
[65] Romer, C. and D. Romer (2002). “The Evolution of Economic Understanding and Postwar Stabilization Policy” in Rethinking Stabilization Policy, Federal Reserve Bank of
Kansas City.
[66] Roberts, G., A. Gelman, and W. Gilks (1997). “Weak Convergence and Optimal Scaling
of Random Walk Metropolis Algorthims.” Annals of Applied Probability 7, 110-120.
[67] Rubin, D.B. (1988). “Using the SIR Algorithm to Simulate Posterior Distributions”.
in J.M. Bernardo, M.H. DeGroot, D.V. Lindley, and A.F.M. Smith (eds), Bayesian
Statistics 3, 395-402, Oxford University Press.
[68] Santos, M.S. and A. Peralta-Alva (2005). “Accuracy of Simulations for Stochastic Dynamic Models”. Econometrica 73, 1939-1976.
[69] Sargent, T.J. (1999). The Conquest of American Inflation. Princeton University Press.
[70] Sims, C.A. (2001). “Discussion of Evolving Post-World War II U.S. Inflation Dynamics
by T. Cogley and T.J. Sargent.” NBER Macroeconomics Annual, vol. 16.
[71] Sims, C.A. (2002). “Implications of Rational Inattention.” Mimeo, Princeton University..
[72] Sims, C.A. and T. Zha (2006). “Were There Regime Switches in U.S. Monetary Policy?”
American Economic Review 96, 54-81.
[73] Smets, F. and R. Wouters (2003). “An Estimated Stochastic Dynamic General Equilibrium Model of the Euro Area.” Journal of the European Economic Association, 1,
1123-1175.
[74] Taylor, J. (1998). “Monetary Policy Guidelines for Unemployment and Inflation Stability.” In Inflation, Unemployment, and Monetary Policy, R.M. Solown and J.B. Taylor
(eds.). MIT Press.
[75] Uhlig, H. (1997). “Bayesian Vector Autoregressions with Stochastic Volatility.” Econometrica 65, 59-73.
[76] Woodford, M. (2006). “Interpreting Inflation Persistence: Comments on the Conference on Quantitative Evidence on Price Discrimination.” Journal of Money, Credit and
Banking, forthcoming.
[77] Young, A.T. (2004). “Labor’s Share Fluctuations, Biased Technical Change, and the
Business Cycle.” Review of Economic Dynamics 7, 916-931.
43

TABLE 6.1: Point Estimates
Parameter Point Estimate
S.D.
β

0.9999

0.001

h

0.8773

0.009

ψ

8.9420

0.045

ϑ

1.3586

0.004

α

0.2550

0.011

ε

7.9570

0.1593

η

7.9650

0.2984

κ

7.6790

0.600

θp

0.9067

0.012

χp

0.1505

0.100

γR

0.7900

0.012

γy

0.1904

0.056

γΠ

1.2596

0.075

Π

1.0078

3.6e-4

Λμ

0.0100

2.86e-4

ΛA

0.0005

4.57e-4

ρd

0.9506

0.006

ρϕ

0.9420

0.015

σμ

0.1010

0.006

σd

0.0600

0.003

σA

0.0072

0.002

σm

0.0030

8.4e-5

σϕ

0.0700

0.011

44

Figure 2.3.1: Estimate of β versus long−run limit
1.14

1.12

1.1

1.08

1.06

1.04

1.02

0

50

100

150

200

250

300

Figure 6.2.1: Evolution of Response to Inflation Figure 6.2.2: HP-Trend Evolution of Response to Inflation
12

4.5

Greenspan

10

4

8

3.5

6

2.5

2

2

0

1.5

1960

1970

1980

Volcker

ρπ

ρπ
4

-2

Greenspan

3

Volcker

1990

2000

1

1960

1970

Period

1980

1990

2000

Period

Figure 6.2.3: Evolution of Inflation Target
1.025

Figure 6.2.4: Inflation Target versus Inflation
1.04
Inflation Target
Inflation

1.02
1.03
1.015
1.02

π

1.01
1.005

1.01

1
1
0.995
0.99

1960

1970

1980

Period

1990

2000

0.99

1960

1970

1980

1990

2000

Figure 6.3.1: Average Price Duration

Figure 6.3.2: HP−Trend Price Rigidity vs. HP−Trend Inflation

20

10

0.04

5

0.02

10

Inflation

Quarters

Quarters

15

5

0

1960

1970

1980

1990

0

2000

1960

1970

1980

1990

0
2000

Period

Period

Figure 6.3.3: Price Indexation

Figure 6.3.4: HP−Trend Price Indexation vs. HP−Trend Inflation

0.7

0.4

0.025

0.35

0.02

0.3

0.015

0.25

0.01

0.2

0.005

0.6

χp

χp

0.4
0.3
0.2
0.1
0

1960

1970

1980

Period

1990

2000

0.15

1960

1970

1980

Period

1990

0
2000

Inflation

0.5

Figure 6.3.5: Price Rigidity vs. Indexation
1

Figure 6.3.6: HP−Trend Price Rigidity vs. HP−Trend Indexation
0.6

0.4

0.85

0.35

0.8

0.3

0.75

0.25

0.7

0.2

θp

θp
0.6

χp

0.4

χp

0.8

0.9

0.2

0.4
0
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

Period

0.65
0.15
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

Period

Figure 6.3.7: Average Wage Duration

Figure 6.3.8: HP−Trend Wage Rigidity versus HP−Trend Inflation

5

3

0.03

2.5

0.02

2

0.01

4.5

3.5
3

Inflation

Quarters

Quarters

4

2.5
2

1960

1970

1980

1990

1.5

2000

1960

1970

1980

1990

0
2000

Period

Period

Figure 6.3.9: Wage Indexation

Figure 6.3.10: HP−Trend Wage Indexation versus HP−Trend Inflation
0.025

0.9

0.85

0.02

0.8

0.8

0.015

0.7

0.75

0.01

0.6

0.7

0.005

χw

0.9

χw

1

0.5

1960

1970

1980

Period

1990

2000

0.65

1960

1970

1980

Period

1990

0
2000

Inflation

1.5

θw

0.8

0
0.6
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

0
0.6
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

Period

Period

10

5

10

3

5

2

0
0
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

0
1
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

Period

Period

Figure 6.3.15: Price Indexation vs. Wage Indexation

Figure 6.3.16: HP−Trend Price vs. HP−Trend Wage Indexation

0
0.6
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

Period

χp

0.8

0.5

χw

1

1

θw

10

θp

Figure 6.3.14: HP−Trend Price vs. HP−Trend Wage Rigidity

20

θw

θp

Figure 6.3.13: Price vs. Wage Rigidity

χp

0.8

0.5

0.4

1

0.3

0.9

0.2

0.8

0.1

0.7

0
0.6
1955 1960 1965 1970 1975 1980 1985 1990 1995 2000

Period

χw

0.5

1

1

χw

θw

Figure 6.3.12: HP−Trend Wage Rigidity vs. HP−Trend Indexation
1

χw

Figure 6.3.11: Wage Rigidity vs. Indexation
1

