NBER WORKING PAPER SERIES

LEARNING AND DISAGREEMENT IN AN UNCERTAIN WORLD
Daron Acemoglu
Victor Chernozhukov
Muhamet Yildiz
Working Paper 12648
http://www.nber.org/papers/w12648

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
October 2006

The views expressed herein are those of the author(s) and do not necessarily reflect the views of the
National Bureau of Economic Research.
Â© 2006 by Daron Acemoglu, Victor Chernozhukov, and Muhamet Yildiz. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including Â© notice, is given to the source.

Learning and Disagreement in an Uncertain World
Daron Acemoglu, Victor Chernozhukov, and Muhamet Yildiz
NBER Working Paper No. 12648
October 2006
JEL No. C11,C72,D83
ABSTRACT
Most economic analyses presume that there are limited differences in the prior beliefs of individuals,
as assumption most often justified by the argument that sufficient common experiences and observations
will eliminate disagreements. We investigate this claim using a simple model of Bayesian learning.
Two individuals with different priors observe the same infinite sequence of signals about some underlying
parameter. Existing results in the literature establish that when individuals are certain about the interpretation
of signals, under very mild conditions there will be asymptotic agreement---their assessments will
eventually agree. In contrast, we look at an environment in which individuals are uncertain about
the interpretation of signals, meaning that they have non-degenerate probability distributions over
the conditional distribution of signals given the underlying parameter. When priors on the parameter
and the conditional distribution of signals have full support, we prove the following results: (1) Individuals
will never agree, even after observing the same infinite sequence of signals. (2) Before observing the
signals, they believe with probability 1 that their posteriors about the underlying parameter will fail
to converge. (3) Observing the same sequence of signals may lead to a divergence of opinion rather
than the typically presumed convergence. We then characterize the conditions for asymptotic agreement
under "approximate certainty"---i.e., as we look at the limit where uncertainty about the interpretation
of the signals disappears. When the family of probability distributions of signals given the parameter
has "rapidly-varying tails" (such as the normal or exponential distributions), approximate certainty
restores asymptotic agreement. However, when the family of probability distributions has "regularly-varying
tails" (such as the Pareto, the log-normal, and the t-distributions), asymptotic agreement does not obtain
even in the limit as the amount of uncertainty disappears. Lack of common priors has important implications
for economic behavior in a range of circumstances. We illustrate how the type of learning outlined
in this paper interacts with economic behavior in various different situations, including games of common
interest, coordination, asset trading and bargaining.
Daron Acemoglu
Department of Economics
MIT, E52-380B
50 Memorial Drive
Cambridge, MA 02142-1347
and NBER
daron@mit.edu
Victor Chernozhukov
Department of Economics
MIT
Cambridge, MA 02142
vchern@mit.edu

Muhamet Yildiz
MIT Department of Economics (E52-371a)
50 Memorial Drive
Cambridge, MA 02142
myildiz@mit.edu

1

Introduction

The common prior assumption is one of the cornerstones of modern economic analysis. Most
models postulate that the players in a game have the â€œsame model of the world,â€ or more
precisely, that they have a common prior about the game form and payoï¬€ distributionsâ€“
for example, they all agree that some payoï¬€-relevant parameter vector Î¸ is drawn from a
known distribution G, even though each may also have additional information about some
components of Î¸. The typical justification for the common prior assumption comes from
learning; individuals, through their own experiences and the communication of others, will
have access to a history of events informative about the vector Î¸, and this process will lead to
â€œagreementâ€ among individuals about the distribution of the vector Î¸. A strong version of this
view is expressed in Savage (1954, p. 48) as the statement that a Bayesian individual, who
does not assign zero probability to â€œthe truth,â€ will learn it eventually as long as the signals
are informative about the truth. A more sophisticated version of this conclusion also follows
from Blackwell and Dubinsâ€™ (1962) theorem about the â€œmerging of opinionsâ€.1
Despite these powerful intuitions and theorems, disagreement is the rule rather than the
exception in practice. Just to mention a few instances, there is typically considerable disagreement even among economists working on a certain topic. For example, economists routinely
disagree about the role of monetary policy, the impact of subsidies on investment or the magnitude of the returns to schooling. Similarly, there are deep divides about religious beliefs
within populations with shared experiences, and finally, there was recently considerable disagreement among experts with access to the same data about whether Iraq had weapons of
mass destruction. In none of these cases, can the disagreements be traced to individuals having
access to diï¬€erent histories of observations. Rather it is their interpretations that diï¬€er. In
particular, it seems that an estimate showing that subsidies increase investment is interpreted
very diï¬€erently by two economists starting with diï¬€erent priors; for example, an economist
believing that subsidies have no eï¬€ect on investment appears more likely to judge the data or
the methods leading to this estimate to be unreliable and thus to attach less importance to this
evidence. Similarly, those who believed in the existence of weapons of mass destruction in Iraq
1

Blackwell and Dubinsâ€™ (1962) theorem shows that if two probability measures are absolutely continuous with
respect to each other (meaning that they assign positive probability to the same events), then as the number of
observations goes to infinity, their predictions about future frequencies will agree. This is also related to Doobâ€™s
(1948) consistency theorem for Bayesian posteriors, which we discuss and use below.

1

presumably interpreted the evidence from inspectors and journalists indicating the opposite as
biased rather than informative.
In this paper, we show that this type of behavior will be the outcome of learning by
Bayesian individuals with diï¬€erent priors when they are uncertain about the informativeness
of signals. In particular, we consider the following simple environment: one or two individuals
with given priors observe a sequence of signals, {st }nt=0 , and form their posteriors about some
underlying state variable (or parameter) Î¸. The only non-standard feature of the environment
is that these individuals may be uncertain about the distribution of signals conditional on
the underlying state. In the simplest case where the state and the signal are binary, e.g.,
Î¸ âˆˆ {A, B}, and st âˆˆ {a, b}, this implies that Pr (st = Î¸ | Î¸) = pÎ¸ is not a known number,
but individuals also have a prior over pÎ¸ , say given by FÎ¸ . We refer to this distribution FÎ¸ as
individualsâ€™ subjective probability distribution and to its density fÎ¸ as subjective (probability)
density. This distribution, which can diï¬€er among individuals, is a natural measure of their
uncertainty about the informativeness of signals. When subjective probability distributions
are non-degenerate, individuals will have some latitude in interpreting the sequence of signals
they observe.
We identify conditions under which Bayesian updating leads to asymptotic learning (individuals learning, or believing that they will be learning, the true value of Î¸ with probability 1
after observing infinitely many signals) and asymptotic agreement (convergence between their
assessments of the value of Î¸). We first provide some generalizations of existing results on
asymptotic learning and agreement. First, we show that learning under certainty leads to asymptotic learning and agreement. In particular, when each individual i is sure that pÎ¸ = pi for
some known number pi > 1/2 (with possibly p1 6= p2 ), then asymptotic learning and agreement
are guaranteed. Second, we establish the stronger results that when both individuals attach
probability 1 to the event that pÎ¸ > 1/2 for Î¸ âˆˆ {A, B}, then there will again be asymptotic
learning and agreement.
These positive results do not hold, however, when there is positive probability that pÎ¸ might
be less than 1/2. In particular, when FÎ¸ has a full support for each Î¸, we show that:
1. There will not be asymptotic learning. Instead each individualâ€™s posterior of Î¸ continues
to be a function of his prior.
2. There will not be asymptotic agreement; two individuals with diï¬€erent priors observing
2

the same sequence of signals will reach diï¬€erent posterior beliefs even after observing
infinitely many signals. Moreover, individuals attach ex ante probability 1 that they will
disagree after observing the sequence of signals.
3. Two individuals may disagree more after observing a common sequence of signals than
they did so previously. In fact, for any model of learning under uncertainty that satisfies
the full support assumption, there exists an open set of pairs of priors such that the
disagreement between the two individuals will necessarily grow starting from these priors.
While it may appear plausible that the individuals should not attach zero probability to
the event that pÎ¸ < 1/2, it is also reasonable to expect that the probability of such events
should be relatively small. This raises the question of whether the results regarding the lack
of asymptotic learning and agreement under uncertainty survive when there is a small amount
of uncertainty. Put diï¬€erently, we would like to understand whether the asymptotic learning
and agreement results under certainty are robust to a small amount of uncertainty.
We investigate this issue by studying learning under â€œapproximate certainty,â€ i.e., by considering a family of subjective density functions {fm } that become more and more concentrated
around a single pointâ€“thus converging to full certainty. It is straightforward to see that as
each individual becomes more and more certain about the interpretation of the signals, asymptotic learning obtains. Interestingly, however, the conditions for asymptotic agreement are
much more demanding than those for asymptotic learning. Consequently, even though each
individual expects to learn the payoï¬€-relevant parameters, asymptotic agreement may fail to
obtain. This implies that asymptotic agreement under certainty may be a discontinuous limit
point of a general model of learning under uncertainty. We show that whether or not this
is the case depends on the tail properties of the family of subjective density functions {fm }.
When this family has regularly-varying tails (such as the Pareto or the log-normal distributions), even under approximate certainty there will be asymptotic disagreement. When {fm }
has rapidly-varying tails (such as the normal distribution), there will be asymptotic agreement
under approximate certainty.
Intuitively, approximate certainty is suï¬ƒcient to make each individual believe that they
will learn the payoï¬€-relevant parameter, but they may still believe that the other individual
will fail to learn. Whether or not they believe this depends on how an individual reacts when
a frequency of signals diï¬€erent from the one he expects with â€œalmost certaintyâ€ occurs. If
3

this event prevents the individual from learning, then there will be asymptotic disagreement
under approximate certainty. This is because under approximate certainty, each individual
trusts his own model of the world and thus expects the limiting frequencies to be consistent
with his model. When the other individualâ€™s model of the world diï¬€ers, he expects the other
individual to be surprised by the limiting frequencies of the signals. Then whether or not
asymptotic agreement will obtain depends on whether this surprise is suï¬ƒcient to prevent the
other individual from learning, which in turn depends on the tail properties of the family of
subjective density functions {fm }.
Lack of asymptotic agreement has important implications for a range of economic situations. We illustrate some of these by considering a number of simple environments where two
individuals observe the same sequence of signals before or while playing a game. In particular,
we discuss the implications of learning in uncertain environments for games of coordination,
games of common interest, bargaining, games of communication and asset trading. We show
how, when they are learning under uncertainty, individuals will play these games diï¬€erently
than they would in environments with common priorsâ€“and also diï¬€erently than in environments without common priors but where learning takes place under certainty. For example,
we establish that contrary to standard results, individuals may wish to play games of common
interests before receiving more information about payoï¬€s. We also show how the possibility of
observing the same sequence of signals may lead individuals to trade only after they observe
the public information. This result contrasts with both standard no-trade theorems (e.g., Milgrom and Stokey, 1982) and existing results on asset trading without common priors, which
assume learning under certainty (Harrison and Kreps, 1978, and Morris, 1996). Finally, we
provide a simple example illustrating a potential reason why individuals may be uncertain
about informativeness of signalsâ€“the strategic behavior of other agents trying to manipulate
their beliefs.
Our results cast doubt on the idea that the common prior assumption may be justified by
learning. In many environments, even when there is little uncertainty so that each individual
believes that he will learn the true state, learning does not necessarily imply agreement about
the relevant parameters. Consequently, the strategic outcome may be significantly diï¬€erent
from that of the common-prior environment.2 Whether this assumption is warranted therefore
2

For previous arguments on whether game-theoretic models should be formulated with all individuals having
a common prior, see, for example, Aumann (1986, 1998) and Gul (1998). Gul (1998), for example, questions

4

depends on the specific setting and what type of information individuals are trying to glean
from the data.
Relating our results to the famous Blackwell-Dubins (1962) theorem may help clarify their
essence. As briefly mentioned in Footnote 1, this theorem shows that when two agents agree
on zero-probability events (i.e., their priors are absolutely continuous with respect to each
other), asymptotically, they will make the same predictions about future frequencies of signals.
Our results do not contradict this theorem, since we impose absolute continuity throughout.
Instead, our results rely on the fact that agreeing about future frequencies is not the same
as agreeing about the underlying state (or the underlying payoï¬€ relevant parameters).3 Put
diï¬€erently, under uncertainty, there is an â€œidentification problemâ€ making it impossible for
individuals to infer the underlying state from limiting frequencies and this leads to diï¬€erent
interpretations of the same signal sequence by individuals with diï¬€erent priors. In most economic situations, what is important is not future frequencies of signals but some payoï¬€-relevant
parameter. For example, what was essential for the debate on the weapons of mass destruction
was not the frequency of news about such weapons but whether or not they existed. What
is relevant for economists trying to evaluate a policy is not the frequency of estimates on the
eï¬€ect of similar policies from other researchers, but the impact of this specific policy when
(and if) implemented. Similarly, what may be relevant in trading assets is not the frequency
of information about the dividend process, but the actual dividend that the asset will pay.
Thus, many situations in which individuals need to learn about a parameter or state that
will determine their ultimate payoï¬€ as a function of their action falls within the realm of the
analysis here.
In this respect, our work diï¬€ers from papers, such as Freedman (1963, 1965) and Miller
and Sanchirico (1999), that question the applicability of the absolute continuity assumption
in the Blackwell-Dubins theorem in statistical and economic settings (see also Diaconis and
Freedman, 1986, Stinchcombe, 2005). Similarly, a number of important theorems in statistics,
for example, Berk (1966), show that under certain conditions, limiting posteriors will have
their support on the set of all identifiable values (though they may fail to converge to a
limiting distribution). Our results are diï¬€erent from those of Berk both because in our model
whether the common prior assumption makes sense when there is no ex ante stage.
3
In this respect, our paper is also related to Kurz (1994, 1996), who considers a situation in which agents
agree about long-run frequencies, but their beliefs fail to merge because of the non-stationarity of the world.

5

individuals always place positive probability on the truth and also because we provide a tight
characterization of the conditions for lack of asymptotic learning and agreement.
Our paper is also closely related to recent independent work by Cripps, Ely, Mailath and
Samuelson (2006), who study the conditions under which there will be â€œcommon learningâ€ by
two agents observing correlated signals. They show how individual learning may not lead to
â€œcommon knowledgeâ€ when the signal space is infinite. Cripps, Ely, Mailath and Samuelsonâ€™s
analysis focuses on the case in which the agents start with common priors and learn under
certainty (though they note how their results can be extended to the case of non-common
priors). Consequently, our emphasis on learning under uncertainty and the results on learning
under conditions of approximate certainty are not shared by this paper. Nevertheless, there
is a close connection between our result that under approximate certainty each agent expects
that he will learn the payoï¬€-relevant parameters but that he will disagree with the other agent
and Cripps, Ely, Mailath and Samuelsonâ€™s finding of lack of common learning with infinitedimensional signal spaces.
The rest of the paper is organized as follows. Section 2 provides all our main results in the
context of a two-state two-signal setup. Section 3 provides generalizations of these results to
an environment with K states and L â‰¥ K signals. Section 4 considers a variety of applications
of our results, and Section 5 concludes.

2

The Two-State Model

2.1

Environment

We start with a two-state model with binary signals. This model is suï¬ƒcient to establish all
our main results in the simplest possible setting. These results are generalized to arbitrary
number of states and signal values in Section 3.
There are two individuals, denoted by i = 1 and i = 2, who observe a sequence of signals
{st }nt=0 where st âˆˆ {a, b}. The underlying state is Î¸ âˆˆ {A, B}, and agent i assigns ex ante probability Ï€ i âˆˆ (0, 1) to Î¸ = A. The individuals believe that, given Î¸, the signals are exchangeable,

i.e., they are independently and identically distributed with an unknown distribution.4 That
4

See, for example, Billingsley (1995). If there were only one state, then our model would be identical to De
Finettiâ€™s canonical model (see, for example, Savage, 1954). In the context of this model, De Finettiâ€™s theorem
provides a Bayesian foundation for classical probability theory by showing that exchangeability (i.e., invariance
under permutations of the order of signals) is equivalent to having an independent identical unknown distribution and implies that posteriors converge to long-run frequencies. De Finettiâ€™s decomposition of probability

6

is, the probability of st = a given Î¸ = A is an unknown number pA ; likewise, the probability
of st = b given Î¸ = B is an unknown number pB â€“as shown in the following table:
a
b

A
pA
1 âˆ’ pA

B
1 âˆ’ pB
pB

Our main departure from the standard models is that we allow the individuals to be
uncertain about pA and pB . We denote the cumulative distribution function of pÎ¸ according
to individual iâ€“i.e., his subjective probability distributionâ€“by FÎ¸i . In the standard models, FÎ¸i
is degenerate and puts probability 1 at some pÌ‚iÎ¸ . In contrast, for most of the analysis, we will
impose the following assumption:
Assumption 1 For each i and Î¸, FÎ¸i has a continuous, non-zero and finite density fÎ¸i over
[0, 1].
The assumption implies that FÎ¸i has full support over [0, 1]. It is worth noting that while
this assumption allows FÎ¸1 (p) and FÎ¸2 (p) to diï¬€er, for many of our results it is not important
whether or not this is so (i.e., whether or not the two individuals have a common prior about
the distribution of pÎ¸ ). Moreover, as discussed in Remark 2, Assumption 1 is stronger than
necessary for our results, but simplifies the exposition.
In addition, throughout we assume that Ï€ 1 , Ï€ 2 , FÎ¸1 and FÎ¸2 are known to both individuals.5
We consider infinite sequences s â‰¡ {st }âˆ
t=1 of signals and write S for the set of all such

sequences. The posterior belief of individual i about Î¸ after observing the first n signals {st }nt=1
is
Ï†in (s) â‰¡ Pri (Î¸ = A | {st }nt=1 ) ,

where Pri (Î¸ = A | {st }nt=1 ) denotes the posterior probability that Î¸ = A given a sequence of

signals {st }nt=1 under prior Ï€ i and subjective probability distribution FÎ¸i (see footnote 7 for a
formal definition).
Throughout, without loss of generality, we suppose that in reality Î¸ = A. The two questions
of interest for us are:
distributions is extended by Jackson, Kalai and Smorodinsky (1999) to cover cases without exchangeability.
5
The assumption that player 1 knows the prior and probability assessment of player 2 regarding the distribution of signals given the state is used in the â€œasymptotic agreementâ€ results and in applications. Since our
purpose is to understand whether learning justifies the common prior assumption, we assume that agents do
not change their views because the beliefs of others diï¬€er from theirs.

7

Â¢
Â¡
1. Asymptotic learning: whether Pri limnâ†’âˆ Ï†in (s) = 1|Î¸ = A = 1 for i = 1, 2.

Â¯
Â¯
Â¢
Â¡
2. Asymptotic agreement: whether Pri limnâ†’âˆ Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ = 0 = 1 for i = 1, 2.

Notice that both asymptotic learning and agreement are defined in terms of the ex ante

probability assessments of the two individuals. Therefore, asymptotic learning implies that an
individual believes that he or she will ultimately learn the truth, while asymptotic agreement
implies that both individuals believe that their assessments will eventually converge.6

2.2

Asymptotic Learning and Disagreement

The following theorem gives the well-known result, which applies when Assumption 1 does not
hold. A version of this result is stated in Savage (1954) and also follows from Blackwell and
Dubinsâ€™ (1962) more general theorem applied to this case. Since the proof of this theorem
uses diï¬€erent arguments than those presented below and is tangential to our focus here, it is
relegated to the Appendix.
Theorem 1 Assume that for some pÌ‚1 , pÌ‚2 âˆˆ (1/2, 1], each FÎ¸i puts probability 1 on pÌ‚i , i.e.,
Â¡ Â¢
FÎ¸i pÌ‚i = 1 and FÎ¸i (p) = 0 for each p < pÌ‚i . Then, for each i = 1,2,
Â¡
Â¢
1. Pri limnâ†’âˆ Ï†in (s) = 1|Î¸ = A = 1.

Â¯
Â¯
Â¡
Â¢
2. Pri limnâ†’âˆ Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ = 0 = 1.

Theorem 1 is a slightly generalized version of the standard theorem where the individual

will learn the truth with experience (almost surely as n â†’ âˆ) and two individuals observing
the same sequence will necessarily agree. The generalization arises from the fact that learning
and agreement take place even though pÌ‚1 may diï¬€er from pÌ‚2 (while Savage, 1954, assumes
that pÌ‚1 = pÌ‚2 ). The intuition of this theorem is useful for understanding the results that will
follow. The theorem states that even if the two individuals have diï¬€erent expectations about
the probability of st = a conditional on Î¸ = A, the fact that pÌ‚i > 1/2 and that they hold
these beliefs with certainty is suï¬ƒcient for asymptotic learning and agreement. For example,
6

We formulate asymptotic learning in terms of each individualâ€™s initial probability measure so as not to take
a position on what the â€œobjectiveâ€ for â€œtrueâ€ probability measure
is. 



In terms
agreement, we will see that Pri limnâ†’âˆ Ï†1n (s) âˆ’ Ï†2n (s) = 0 = 1 also implies

 1 of asymptotic
2


limnâ†’âˆ Ï†n (s) âˆ’ Ï†n (s) = 0 for almost all sample paths, thus individual beliefs that there will be asymptotic agreement coincide with asymptotic agreement (and vice versa).

8

consider an individual who expects a frequency of a signals pÌ‚i > 1/2 when the underlying state
is Î¸ = A. First, to see why asymptotic learning applies it is suï¬ƒcient to observe that this
individual is sure that he will be confronted either with a limiting frequency of a signals equal
to pÌ‚i , in which case he will conclude that Î¸ = A, or he will observe a limiting frequency of
1 âˆ’ pÌ‚i , and he will conclude that Î¸ = B. Therefore, this individual believes that he will learn
the true state with probability 1. Next to see why asymptotic agreement obtains, suppose
that this individual is confronted with a frequency Ï > pÌ‚i of a signals. Since he believes with
certainty that the frequency of signals should be pÌ‚i when the state is Î¸ = A and 1 âˆ’ pÌ‚i when
the state is Î¸ = B, he will interpret the frequency Ï as resulting from sampling variation.
Given that Ï > pÌ‚i , this sampling variation is much much more likely when the state is Î¸ = A
and therefore, he will attach probability 1 to the event that Î¸ = A. Asymptotic agreement
then follows from the observation that individual i believes that individual j will observe a
frequency of a signals pÌ‚i when the state is Î¸ = A and expects that he will conclude from this
that Î¸ = A even though pÌ‚i 6= pÌ‚j (as long as pÌ‚i and pÌ‚j are both greater than 1/2 as assumed in
the theorem).
We next generalize Theorem 1 to the case where the individuals are not necessarily certain
about the signal distribution but their subjective distributions do not satisfy the full support
feature of Assumption 1.
Theorem 2 Assume that each FÎ¸i has a density fÎ¸i and satisfies FÎ¸i (1/2) = 0. Then, for each
i = 1,2,
Â¢
Â¡
1. Pri limnâ†’âˆ Ï†in (s) = 1|Î¸ = A = 1.

Â¯
Â¯
Â¡
Â¢
2. Pri limnâ†’âˆ Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ = 0 = 1.

This theorem will be proved together with Theorem 3. It is evident that the assumption

FÎ¸i (1/2) = 0 implies that pÎ¸ > 1/2, contradicting the full support feature in Assumption 1.
The intuition for this result is similar to that of Theorem 1: when both individuals attach
probability 1 to the event that pÎ¸ > 1/2, they will believe that the majority of the signals in
the limiting distribution will be st = a when Î¸ = A. Thus, each believes that both he and
the other individual will learn the underlying state with probability 1 (even though they may
both be uncertain about the exact distribution of signals conditional on the underlying state).
This theorem shows that results on asymptotic learning and agreement are substantially more
9

general than Savageâ€™s original theorem. Nevertheless, the result relies on the feature that
FÎ¸i (1/2) = 0 for each i = 1,2 and each Î¸. This implies that both individuals attach zero
probability to a range of possible models of the worldâ€“i.e., they are certain that pÎ¸ cannot
be less than 1/2. It may instead be more reasonable to presume that, under uncertainty,
each individual may attach positive (though perhaps small) probability to all values of pÎ¸ as
encapsulated by Assumption 1. We next impose this assumption and show that under the more
general circumstances where FÎ¸i has full support, there will be neither asymptotic learning nor
asymptotic agreement.
Theorem 3 Suppose Assumption 1 holds for i = 1,2. Then,
Â¢
Â¡
1. Pri limnâ†’âˆ Ï†in (s) 6= 1|Î¸ = A = 1 for i = 1,2;

Â¯
Â¯
Â¢
Â¡
2. Pri limnâ†’âˆ Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ 6= 0 = 1 whenever Ï€ 1 6= Ï€ 2 and FÎ¸1 = FÎ¸2 for each Î¸ âˆˆ
{A, B}.

This theorem contrasts with Theorems 1 and 2 and implies that the individual in question
will fail to learn the true state with probability 1. The second part of the theorem states that
if the individualsâ€™ prior beliefs about the state diï¬€er (but they interpret the signals in the
same way), then their posteriors will eventually disagree, and moreover, they will both attach
probability 1 to the event that their beliefs will eventually diverge. Put diï¬€erently, this implies
that there is â€œagreement to eventually disagreeâ€ between the two individuals, in the sense that
they both believe ex ante that after observing the signals they will fail to agree. This feature
will play an important role in the applications in Section 4 below.
Remark 1 The assumption that FÎ¸1 = FÎ¸2 in this theorem is adopted for simplicity. Even in
the absence of this condition, there will typically be no asymptotic agreement. Theorem 6 in
the next section generalizes this theorem to a situation with multiple states and multiple signals
and also dispenses with the assumption that FÎ¸1 = FÎ¸2 . It establishes that the set of priors and
subjective probability distributions that leads to asymptotic agreement is of â€œmeasure zeroâ€.
Remark 2 Assumption 1 is considerably stronger than necessary for Theorem 3 and is adopted
only for simplicity. It can be verified that for lack of asymptotic learning it is suï¬ƒcient (but not
necessary) that the measures generated by the distribution functions FAi (p) and FBi (1 âˆ’ p) be
10

absolutely continuous with respect to each other. Similarly, for lack of asymptotic agreement,
it is suï¬ƒcient (but not necessary) that the measures generated by FA1 (p), FB1 (1 âˆ’ p), FA2 (p)
and FBi (1 âˆ’ p) be absolutely continuous with respect each other. For example, if both indi-

viduals believe that pA is either 0.3 or 0.7 (with the latter receiving greater probability) and
that pB is also either 0.3 or 0.7 (with the former receiving greater probability), then there will
be neither asymptotic learning nor asymptotic agreement. Throughout we use Assumption 1
both because it simplifies the notation and because it is a natural assumption when we turn
to the analysis of asymptotic agreement under approximate certainty below.
Towards proving the above theorems, we now introduce some notation, which will be used
throughout the paper. Recall that the sequence of signals, s, is generated by an exchangeable
process, so that the order of the signals does not matter for the posterior. Let
rn (s) â‰¡ # {t â‰¤ n|st = a}
be the number of times st = a out of first n signals.7 By the strong law of large numbers,
rn (s) /n converges to some Ï (s) âˆˆ [0, 1] almost surely according to both individuals. Defining
the set
SÌ„ â‰¡ {s âˆˆ S : limnâ†’âˆ rn (s) /n exists} ,

(1)

Â¡
Â¢
this observation implies that Pri s âˆˆ SÌ„ = 1 for i = 1, 2. We will often state our results for all

sample paths s in SÌ„, which equivalently implies that these statements are true almost surely
or with probability 1. Now, a straightforward application of the Bayes rule gives
Ï†in (s) =

1
1+

1âˆ’Ï€ i
Ï€i

Pri (rn |Î¸=B)
Pri (rn |Î¸=A)

,

(2)

where Pri (rn |Î¸) is the probability of observing the signal st = a exactly rn times out of n
signals with respect to the distribution FÎ¸i . The next lemma provides a very useful formula for
Ï†iâˆ (s) â‰¡ limnâ†’âˆ Ï†in (s) for all sample paths s in SÌ„.
7

Given the definition of rn (s), the probability distribution Pri on {A, B} Ã— S is
] 1


â‰¡ Ï€i
Pri E A,s,n
prn (s) (1 âˆ’ p)nâˆ’rn (s) fAi (p) dp, and
0



] 1
i
B,s,n
i
â‰¡
1 âˆ’ Ï€i
(1 âˆ’ p)rn (s) pnâˆ’rn (s) fB
(p) dp
Pr E
0

at each event E

Î¸,s,n

0

= {(Î¸, s

) |s0t

âˆ

0
0
= st for each t â‰¤ n}, where s â‰¡ {st }âˆ
t=1 and s â‰¡ {st }t=1 .

11

Lemma 1 Suppose Assumption 1 holds. Then for all s âˆˆ SÌ„,
Ï†iâˆ (Ï (s)) â‰¡ lim Ï†in (s) =
nâ†’âˆ

1
1+

1âˆ’Ï€ i i
R (Ï (s))
Ï€i

,

(3)

where Ï (s) = limnâ†’âˆ rn (s) /n, and âˆ€Ï âˆˆ [0, 1],
fBi (1 âˆ’ Ï)
.
fAi (Ï)

Ri (Ï) â‰¡

(4)

Proof. Write
Pri (rn |Î¸ = B)
Pri (rn |Î¸ = A)

=

R1
0

U1
0

=

prn (1 âˆ’ p)nâˆ’rn fB (1 âˆ’ p)dp
R1
rn
nâˆ’rn f (p)dp
A
0 p (1 âˆ’ p)
prn (1âˆ’p)nâˆ’rn fB (1âˆ’p)dp
U1
rn (1âˆ’p)nâˆ’rn dp
0 p

U1
0

=

prn (1âˆ’p)nâˆ’rn fA (p)dp
U1
rn (1âˆ’p)nâˆ’rn dp
0 p

EÎ» [fB (1 âˆ’ p)|rn ]
.
EÎ» [fA (p)|rn ]

Here, the first equality is obtained by dividing the numerator and the denominator by the
same term. The resulting expression on the numerator is the conditional expectation of
fB (1 âˆ’ p) given rn under the flat (Lebesgue) prior on p and the Bernoulli distribution on
{st }nt=0 . Denoting this by EÎ» [fB (1 âˆ’ p)|rn ], and the denominator, which is similarly defined as

the conditional expectation of fA (p), by EÎ» [fA (p)|rn ], we obtain the last equality. By Doobâ€™s
consistency theorem for Bayesian posterior expectation of the parameter, as rn â†’ Ï, we have

that EÎ» [fB (1 âˆ’ p)|rn ] â†’ fB (1 âˆ’ Ï) and EÎ» [fA (p)|rn ] â†’ fA (Ï) (see, e.g., Doob, 1949, Ghosh

and Ramamoorthi, 2003, Theorem 1.3.2). This establishes
Pri (rn |Î¸ = B)
â†’ Ri (Ï) ,
Pri (rn |Î¸ = A)
as defined in (4). Equation (3) then follows from (2).
In equation (4), Ri (Ï) is the asymptotic likelihood ratio of observing frequency Ï of a when
the true state is B versus when it is A. Lemma 1 states that, asymptotically, individual i uses
this likelihood ratio and Bayes rule to compute his posterior beliefs about Î¸.
An immediate implication of Lemma 1 is that given any s âˆˆ SÌ„,
Ï†1âˆ (Ï (s)) = Ï†2âˆ (Ï (s)) if and only if

1 âˆ’ Ï€1 1
1 âˆ’ Ï€2 2
R
(Ï
(s))
=
R (Ï (s)) .
Ï€1
Ï€2

The proofs of Theorems 2 and 3 now follow from Lemma 1 and equation (5).
12

(5)

Proof of Theorem 2. Under the assumption that FÎ¸i (1/2) = 0 in the theorem, the argument in Lemma 1 still applies, and we have Ri (Ï (s)) = 0 when Ï (s) > 1/2 and Ri (Ï (s)) = âˆ
when Ï (s) < 1/2. Given Î¸ = A, then rn (s) /n converges to some Ï (s) > 1/2 almost surely acÂ¢
Â¢
Â¡
Â¡
cording to both i = 1 and 2. Hence, Pri Ï†1âˆ (Ï (s)) = 1|Î¸ = A = Pri Ï†2âˆ (Ï (s)) = 1|Î¸ = A =
Â¢
Â¢
Â¡
Â¡
1 for i = 1, 2. Similarly, Pri Ï†1âˆ (Ï (s)) = 0|Î¸ = B = Pri Ï†2âˆ (Ï (s)) = 0|Î¸ = B = 1 for
i = 1, 2, establishing the second part. Â¥

Proof of Theorem 3. Since fBi (1 âˆ’ Ï (s)) > 0 and fA (Ï (s)) is finite, Ri (Ï (s)) > 0.

Hence, by Lemma 1, Ï†iâˆ (Ï (s)) 6= 1 for each s, establishing the first part. The second part

follows from equation (5), since Ï€ 1 6= Ï€ 2 and FÎ¸1 = FÎ¸2 implies that for each s âˆˆ SÌ„, Ï†1âˆ (s) 6=
Â¯
Â¢
Â¡Â¯
Ï†2âˆ (s), and thus Pri Â¯Ï†1âˆ (s) âˆ’ Ï†2âˆ (s)Â¯ 6= 0 = 1 for i = 1, 2. Â¥
Intuitively, when Assumption 1 (in particular, the full support feature) holds, an individual

is never sure about the exact interpretation of the sequence of signals he observes and will
update his views about pÎ¸ (the informativeness of the signals) as well as his views about the
underlying state. For example, even when signal a is more likely in state A than in state
B, a very high frequency of a will not necessarily convince him that the true state is A,
because he may infer that the signals are not as reliable as he initially believed, and they may
instead be biased towards a. Therefore, the individual never becomes certain about the state,
which is captured by the fact that Ri (Ï) defined in (4) never takes the value zero or infinity.
Consequently, as shown in (3), his posterior beliefs will be determined by his prior beliefs
about the state and also by Ri , which tells us how the individual updates his beliefs about the
informativeness of the signals as he observes the signals. When two individuals interpret the
informativeness of the signals in the same way (i.e., R1 = R2 ), the diï¬€erences in their priors
will always be reflected in their posteriors.
In contrast, if an individual were sure about the informativeness of the signals (i.e., if i
were sure that pA = pB = pi for some pi > 1/2) as in Theorem 1, then he would never
question the informativeness of the signalsâ€“even when the limiting frequency of a converges
to a value diï¬€erent from pi or 1 âˆ’ pi . Consequently, in this case, for each sample path with
Ï (s) 6= 1/2 both individuals would learn the true state and their posterior beliefs would agree
asymptotically.
As noted above, an important implication of Theorem 3 is that there will typically be
â€œagreement to eventually disagreeâ€ between the individuals. In other words, given their priors,
13

both individuals will agree that after seeing the same infinite sequence of signals they will still
disagree (with probability 1). This implication is interesting in part because the common prior
assumption, typically justified by learning, leads to the celebrated â€œno agreement to disagreeâ€
result (Aumann, 1976, 1998), which states that if the individualsâ€™ posterior beliefs are common
knowledge, then they must be equal.8 In contrast, in the limit of the learning process here,
individualsâ€™ beliefs are common knowledge (as there is no private information), but they are
diï¬€erent with probability 1. This is because in the presence of uncertainty and full support
as in Assumption 1, both individuals understand that their priors will have an eï¬€ect on their
beliefs even asymptotically; thus they expect to disagree. Many of the applications we discuss
in Section 4 exploit this feature.

2.3

Divergence of Opinions

Theorem 3 established that the diï¬€erences in priors are reflected in the posteriors even in
the limit as n â†’ âˆ. It does not, however, quantify the possible disagreement between the
two individuals. The rest of this section investigates diï¬€erent aspects of this question. We
first show that two individuals that observe the same sequence of signals may have diverging
posteriors, so that common information can increase disagreement.
Theorem 4 Suppose that subjective probability distributions are given by FÎ¸1 and FÎ¸2 that
Â¯
Â¯
satisfy Assumption 1 and that there exists > 0 such that Â¯R1 (Ï) âˆ’ R2 (Ï)Â¯ > for each
Ï âˆˆ [0, 1]. Then, there exists an open set of priors Ï€ 1 and Ï€ 2 , such that for all s âˆˆ SÌ„,
Â¯
Â¯
Â¯ Â¯
lim Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ > Â¯Ï€ 1 âˆ’ Ï€ 2 Â¯ ;

nâ†’âˆ

in particular,
Pri

Â³

Â¯ Â¯
Â¯
Â¯Â´
lim Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ > Â¯Ï€ 1 âˆ’ Ï€ 2 Â¯ = 1.

nâ†’âˆ

Proof. Fix FÎ¸1 and FÎ¸2 and take Ï€ 1 = Ï€ 2 = 1/2. By Lemma 1 and the hypothesis
Â¯
Â¯
Â¯
Â¯
that Â¯R1 (Ï) âˆ’ R2 (Ï)Â¯ > for each Ï âˆˆ [0, 1], limnâ†’âˆ Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ > 0 for some 0 > 0,
Â¯
Â¯
while Â¯Ï€ 1 âˆ’ Ï€ 2 Â¯ = 0. Since both expressions are continuous in Ï€ 1 and Ï€ 2 , there is an open

neighborhood of 1/2 such that the above inequality uniformly holds for each Ï whenever Ï€ 1
8

Note, however, that the â€œno agreement to disagreeâ€ result derives from individualsâ€™ updating their beliefs
because those of others diï¬€er from their own (Geanakoplos and Polemarchakis, 1982), whereas here individuals
only update their beliefs by learning.

14

Â¡
Â¢
and Ï€ 2 are in this neighborhood. The last statement follows from the fact that Pri s âˆˆ SÌ„ = 1.
Intuitively, even a small diï¬€erence in priors ensures that individuals will interpret signals
diï¬€erently, and if the original disagreement is relatively small, after almost all sequences of
signals, the disagreement between the two individuals grows. Consequently, the observation
of a common sequence of signals causes an initial diï¬€erence of opinion between individuals to
widen (instead of the standard merging of opinions under certainty). Theorem 4 also shows that
both individuals are certain ex ante that their posteriors will diverge after observing the same
sequence of signals, because they understand that they will interpret the signals diï¬€erently.
This strengthens our results further and shows that for some priors individuals will â€œagree to
eventually disagree even moreâ€.
An interesting implication of Theorem 4 is also worth noting. As demonstrated by Theorems 1 and 2, when there is learning under certainty individuals initially disagree, but each
individual also believes that they will eventually agree (and in fact, that they will converge to
his beliefs). This implies that each individual expects the other to â€œlearn moreâ€. More specifÂ¢2 Â¡
Â¢2
Â¡
ically, let IÎ¸=A be the indicator function for Î¸ = A and Î›i = Ï€ i âˆ’ IÎ¸=A âˆ’ Ï†iâˆ âˆ’ IÎ¸=A
be a measure of learning for individual i,and let Ei be the expectation of individual i (under

the probability measure Pri ). Under certainty, Theorem 1 implies that Ï†iâˆ = Ï†jâˆ = IÎ¸=A ,
Â£
Â¤
Â¡
Â¢2
Â£ Â¤
Â£ Â¤
so that Ei Î›i âˆ’ Î›j = âˆ’ Ï€ i âˆ’ Ï€ j < 0 and thus Ei Î›i < Ei Î›j . Under uncertainty, this

is not necessarily true. In particular, Theorem 4 implies that, under the assumptions of the

theorem, there exists an open subset of the interval [0, 1] such that whenever Ï€ 1 and Ï€ 2 are in
Â£ Â¤
Â£ Â¤
this subset, we have Ei Î›i > Ei Î›j , so that individual i would expect to learn more than

individual j. The reason is that individual i is not only confident about his initial guess Ï€ i , but

also expects to learn more from the sequence of signals than individual j, because he believes
that individual j has the â€œwrong model of the world.â€ The fact that an individual may expect
to learn more than others will play an important role in some of the applications in Section 4.

2.4

Non-monotonicity of the Likelihood Ratio

We next illustrate that the asymptotic likelihood ratio, Ri (Ï), may be non-monotone, meaning
that when an individual observes a high frequency of signals taking the value a, he may conclude
that the signals are biased towards a and may put lower probability on state A than he would
have done with a lower frequency of a among the signals. This feature not only illustrates the
15

types of behavior that are possible when individuals are learning under uncertainty but is also
important for the applications we discuss in Section 4.
Inspection of expression (3) establishes the following:
Lemma 2 For any s âˆˆ SÌ„, Ï†iâˆ (s) is decreasing at Ï (s) if and only if Ri is increasing at Ï (s).
Proof. This follows immediately from equation (3) above.
When Ri is non-monotone, even a small amount of uncertainty about the informativeness
of the signals may lead to significant diï¬€erences in limit posteriors. The next example illustrates this point, while the second example shows that there can be â€œreversalsâ€ in individualsâ€™
assessments, meaning that after observing a sequence â€œfavorableâ€ to state A, the individual
may have a lower posterior about this state than his prior. The impact of small uncertainty
on asymptotic agreement will be more systematically studied in the next subsection.
Example 1 (Non-monotonicity) Each individual i thinks that with probability 1 âˆ’ , pA

and pB are in a Î´-neighborhood of some pÌ‚i > (1 + Î´) /2, but with probability > 0, the signals
Â¯
Â¯
are not informative. More precisely, for pÌ‚i > (1 + Î´) /2, > 0 and Î´ < Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯, we have
Â¡
Â¢
Â½
+ (1 âˆ’ ) /Î´ if p âˆˆ pÌ‚i âˆ’ Î´/2, pÌ‚i + Î´/2
i
(6)
fÎ¸ (p) =
otherwise
for each Î¸ and i. Now, by (4), the asymptotic likelihood ratio is
â§
Â¡ i
Â¢
Î´
i + Î´/2
âª
if
Ï
(s)
âˆˆ
pÌ‚
âˆ’
Î´/2,
pÌ‚
âª
1âˆ’ (1âˆ’Î´)
âª
â¨
i
Â¡
Â¢
R (Ï (s)) =
1âˆ’ (1âˆ’Î´)
i âˆ’ Î´/2, 1 âˆ’ pÌ‚i + Î´/2
âª
if
Ï
(s)
âˆˆ
1
âˆ’
pÌ‚
âª
Î´
âª
â©
1
otherwise.

This and other relevant functions are plotted in Figure 1 for â†’ 0 and Î´ â†’ 0. The likelihood
ratio Ri (Ï (s)) is 1 when Ï (s) is small, takes a very high value at 1 âˆ’ pÌ‚i , goes down to 1

afterwards, becomes nearly zero around pÌ‚i , and then jumps back to 1. By Lemmas 1 and 2,

Ï†iâˆ (s) will also be non-monotone: when Ï (s) is small, the signals are not informative, thus
Ï†iâˆ (s) is the same as the prior, Ï€ i . In contrast, around 1 âˆ’ pÌ‚i , the signals become very

informative suggesting that the state is B, thus Ï†iâˆ (s) âˆ¼
= 0. After this point, the signals
become uninformative again and Ï†iâˆ (s) goes back to Ï€ i . Around pÌ‚i , the signals are again

informative, but this time favoring state A, so Ï†iâˆ (s) âˆ¼
= 1. Finally, signals again become

uninformative and Ï†iâˆ (s) falls back to Ï€ i . Intuitively, when Ï (s) is around 1 âˆ’ pÌ‚i or pÌ‚i , the
16

âˆ

Ri
1

Ï†âˆi

Ï†âˆ1 âˆ’ Ï†âˆ2

1
1âˆ’ Ï€1
Ï€2

Ï€i

Ï€2-Ï€1
1âˆ’ Ï€2
Ï€1

1
0
0 1âˆ’ pÌ‚ i

pÌ‚ i

1

Ï 0
0 1âˆ’ pÌ‚ i

pÌ‚ i

1

Ï

0

1 âˆ’ pË† 2
1
0 1 âˆ’ pË†

pÌ‚ 2 pÌ‚ i

1

Ï

1: Â¯ The three panels show, respectively, the approximate values of Ri (Ï), Ï†iâˆ , and
Â¯Figure
1
Â¯Ï†âˆ âˆ’ Ï†2âˆ Â¯ as â†’ 0.
individual assigns very high probability to the true state, but outside of this region, he sticks
to his prior, concluding that the signals are not informative.
The first important observation is that even though Ï†iâˆ is equal to the prior for a large
range of limiting frequencies, as â†’ 0 and Î´ â†’ 0 each individual attaches probability 1 to the
event that he will learn Î¸. This is because as illustrated by the discussion after Theorem 1,
as

â†’ 0 and Î´ â†’ 0, each individual becomes convinced that the limiting frequencies will be

either 1 âˆ’ pÌ‚i or pÌ‚i .

However, asymptotic learning is considerably weaker than asymptotic agreement. Each
Â¯
Â¯
individual also understands that since Î´ < Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯, when the long-run frequency is in a

region where he learns that Î¸ = A, the other individual will conclude that the signals are
uninformative and adhere to his prior belief. Consequently, he expects the posterior beliefs
of the other individual to be always far from his. Put diï¬€erently, as

â†’ 0 and Î´ â†’ 0, each

individual believes that he will learn the value of Î¸ himself but that the other individual will
fail to learn, thus attaches probability 1 to the event that they disagree. This can be seen from
the third panel of Figure 1; at each sample path in SÌ„, at least one of the individuals will fail
to learn, and the diï¬€erence between their limiting posteriors will be uniformly higher than the
following â€œobjectiveâ€ bound
Â¯
Â¯Âª
Â©
min Ï€ 1 , Ï€ 2 , 1 âˆ’ Ï€ 1 , 1 âˆ’ Ï€ 2 , Â¯Ï€ 1 âˆ’ Ï€ 2 Â¯ .

When Ï€ 1 = 1/3 and Ï€ 2 = 2/3, this bound is equal to 1/3. In fact, the belief of each individual regarding potential disagreement can be greater than this; each individual believes
17

that he will learn but the other individual will fail to do so. Consequently, for each i,
Â¯
Â¯
Â¡
Âª
Â¢
Â©
Pri limnâ†’âˆ Â¯Ï†1n (s) âˆ’ Ï†2n (s)Â¯ â‰¥ Z â‰¥ 1 âˆ’ , where as â†’ 0, Z â†’ min Ï€ 1 , Ï€ 2 , 1 âˆ’ Ï€ 1 , 1 âˆ’ Ï€ 2 .
This â€œsubjectiveâ€ bound can be as high as 1/2.

The next example shows an even more extreme phenomenon, whereby a high frequency of
s = a among the signals may reduce the individualâ€™s posterior that Î¸ = A below his prior.
Example 2 (Reversal) Now suppose that individualsâ€™ subjective probability densities are
given by
fÎ¸i (p) =

â§ Â¡
â¨ 1âˆ’ âˆ’
â©

2

2

Â¢

/Î´ if pÌ‚i âˆ’ Î´/2 â‰¤ p â‰¤ pÌ‚i + Î´/2
if p < 1/2
otherwise

for each Î¸ and i = 1, 2, where

> 0, pÌ‚i > 1/2, and 0 < Î´ < pÌ‚1 âˆ’ pÌ‚2 . Clearly, as

gives:

â§
âª
âª
âª
âª
â¨ 0

Ri (Ï (s)) âˆ¼
=

âª
âª
âª
âª
â©

âˆ

â†’ 0, (4)

if Ï (s) < 1 âˆ’ pÌ‚i âˆ’ Î´/2,
or 1 âˆ’ pÌ‚i + Î´/2 < Ï (s) < 1/2,
or pÌ‚i âˆ’ Î´/2 â‰¤ Ï (s) â‰¤ pÌ‚i + Î´/2
otherwise.

Hence, the asymptotic posterior probability that Î¸ = A is
â§
if Ï (s) < 1 âˆ’ pÌ‚i âˆ’ Î´/2,
âª
âª
âª
âª
â¨ 1 or 1 âˆ’ pÌ‚i + Î´/2 < Ï (s) < 1/2,
Ï†iâˆ (Ï (s)) âˆ¼
or pÌ‚i âˆ’ Î´/2 â‰¤ Ï (s) â‰¤ pÌ‚i + Î´/2
=
âª
âª
âª
âª
â©
0 otherwise.

Consequently, in this case observing a suï¬ƒciently high frequency of s = a may reduce the
posterior that Î¸ = A below the prior. Moreover, the individuals assign probability 1 âˆ’ that
Â¯
Â¯
there will be extreme asymptotic disagreement in the sense that Â¯Ï†1âˆ (Ï (s)) âˆ’ Ï†2âˆ (Ï (s))Â¯ âˆ¼
= 1.
In both examples, it is crucial that the likelihood ratio Ri is not monotone. If Ri were

monotone, at least one of the individuals would expect that their beliefs will asymptotically
agree. To see this, take pÌ‚i â‰¥ pÌ‚j . Given the form of Ri (Ï), individual i is almost certain that,

when the state is A, Ï (s) will be close to pÌ‚i . He also understands that j would assign a very

high probability to the event that Î¸ = A when Ï (s) = pÌ‚j â‰¥ pÌ‚i . If Rj were monotone, individual

j would assign even higher probability to A at Ï (s) = pÌ‚i and thus his probability assessment
on A would also converge to 1 as â†’ 0. Therefore, in this case i will be almost certain that j
will learn the true state and that their beliefs will agree asymptotically.
18

Theorem 1 established that there will be asymptotic agreement under certainty. One might
have thought that as

â†’ 0 and uncertainty disappears, the same conclusion would apply. In

contrast, the above examples show that even as each FÎ¸i converges to a Dirac distribution (that

assigns a unit mass to a point), there may be significant asymptotic disagreement between the
two individuals. Notably this is true not only when there is negligible uncertainty, i.e.,

â†’0

and Î´ â†’ 0, but also when the individualsâ€™ subjective distributions are nearly identical, i.e., as
pÌ‚1 âˆ’ pÌ‚2 â†’ 0 . This suggests that the result of asymptotic agreement in Theorem 1 may not

be a continuous limit point of a more general model of learning under uncertainty.9 Instead,

we will see in the next subsection that whether or not there is asymptotic agreement under
approximate certainty (i.e., as FÎ¸i becomes more and more concentrated around a point) is
determined by the tail properties of the family of distributions FÎ¸i .

2.5

Agreement and Disagreement with Approximate Certainty

In this subsection, we characterize the conditions under which â€œapproximate certaintyâ€ ensures
asymptotic agreement. More specifically, we will study the behavior of asymptotic beliefs as
the subjective probability distribution FÎ¸i converges to a Dirac distribution and the uncertainty
about the interpretation of the signals disappears. As already illustrated by Example 1, as
FÎ¸i converges to a Dirac distribution, each individual will become increasingly convinced that
he will learn the true state. However, because asymptotic agreement is considerably more
demanding than asymptotic learning, this does not guarantee that the individuals will believe
that they will also agree on Î¸. We will demonstrate that whether or not there is asymptotic agreement in the limit depends on the family of distributions converging to certaintyâ€“in
particular, on their tail properties. For many natural distributions, a small amount of uncertainty about the informativeness of the signals is suï¬ƒcient to lead to significant diï¬€erences in
posteriors.
To state and prove our main result in this case, consider a family of subjective probability
i
density functions fÎ¸,m
for i = 1, 2, Î¸ âˆˆ {A, B} and m âˆˆ Z+ , such that as m â†’ âˆ, we have

i
i
i
that FÎ¸,m
â†’ FÎ¸,âˆ
where FÎ¸,âˆ
assigns probability 1 to p = pÌ‚i for some pÌ‚i âˆˆ (1/2, 1). Naturally,

there are many diï¬€erent ways in which a family of subjective probability distributions may
9

Nevertheless, it is also not the case that asymptotic agreement under approximate certainty requires the
support of the distribution of each FÎ¸i to converge to a set as in Theorem 2 (that does not assign positive
probability to piÎ¸ < 1/2). See Theorem 5 below.

19

converge to such a limiting distribution. Both for tractability and to make the analysis more
n
o
i
concrete, we focus on families of subjective probability distributions fÎ¸,m
parameterized by
a determining density function f . We impose the following conditions on f :
(i) f is symmetric around zero;
(ii) there exists xÌ„ < âˆ such that f (x) is decreasing for all x â‰¥ xÌ„;
(iii)
RÌƒ (x, y) â‰¡ lim

mâ†’âˆ

f (mx)
f (my)

(7)

exists in [0, âˆ] at all (x, y) âˆˆ R2+ .10
Conditions (i) and (ii) are natural and serve to simplify the notation. Condition (iii)
introduces the function RÌƒ (x, y), which will arise naturally in the study of asymptotic agreement
and has a natural meaning in asymptotic statistics (see Definitions 1 and 2 below).
In order to vary the amount of uncertainty, we consider mappings of the form x 7â†’
(x âˆ’ y) /m, which scale down the real line around y by the factor 1/m. The family of subjective
o
n
i
densities for individualsâ€™ beliefs about pA and pB , fÎ¸,m
, will be determined by f and the
Â¡
Â¢
transformation x 7â†’ x âˆ’ pÌ‚i /m.11 In particular, we consider the following family of densities
Â¢Â¢
Â¡ Â¡
i
fÎ¸,m
(p) = ci (m) f m p âˆ’ pÌ‚i

for each Î¸ and i where ci (m) â‰¡ 1/

(8)

R1 Â¡ Â¡
Â¢Â¢
i
dp is a correction factor to ensure that
0 f m p âˆ’ pÌ‚

i
fÎ¸,m
is a proper probability density function on [0, 1] for each m. We also define Ï†iâˆ,m â‰¡

limnâ†’âˆ Ï†in,m (s) as the limiting posterior distribution of individual i when he believes that the

i . In this family of subjective densities, the uncertainty
probability density of signals is fÎ¸,m
i
about pA is scaled down by 1/m, and fÎ¸,m
converges to unit mass at pÌ‚i as m â†’ âˆ, so that

individual i becomes sure about the informativeness of the signals in the limit. In other words,
as m â†’ âˆ, this family of subjective probability distributions leads to approximate certainty
(and ensures asymptotic learning; see the proof of Part 1 of Theorem 5).
10

Convergence will be uniform in most cases in view of the results discussed following Definition 1 below
(and of Egorovâ€™s Theorem, which links pointwise convergence of a family of functions to a limiting function to
uniform convergence, see, for example, Billingsley, 1995, Section 13).
11
This formulation assumes that pÌ‚iA and pÌ‚iB are equal. We can easily assume these to be diï¬€erent, but do not
introduce this generality here to simplify the exposition. Theorem 8 allows for such diï¬€erences in the context
of the more general model with multiple states and multiple signals.

20

The next theorem characterizes the class of determining functions f for which the resulting
n
o
i
family of the subjective densities fÎ¸,m
leads to asymptotic agreement under approximate
certainty.

Theorem 5 Suppose that Assumption 1 holds. For each i = 1, 2, consider the family of
o
n
i
defined in (8) for some pÌ‚i > 1/2, with f satisfying conditions (i)subjective densities fÎ¸,m

(iii) above. Suppose that f (mx) /f (my) uniformly converges to RÌƒ(x, y) over a neighborhood
Â¯
Â¯Â¢
Â¡
of pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ . Then,
Â¯Â¢
Â¯
Â¡
Â¡ Â¢
Â¡ Â¢Â¢
Â¡
1. limmâ†’âˆ Ï†iâˆ,m pÌ‚i âˆ’ Ï†jâˆ,m pÌ‚i = 0 if and only if RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ = 0.

Â¯
Â¯Â¢
Â¡
2. Suppose that RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ = 0. Then for every
mÌ„ âˆˆ Z+ such that
Pri

Â³

Â´
Â¯
Â¯
lim Â¯Ï†1n,m (s) âˆ’ Ï†2n,m (s)Â¯ >
<Î´

nâ†’âˆ

> 0 and Î´ > 0, there exists

(âˆ€m > mÌ„, i = 1, 2).

Â¯
Â¯Â¢
Â¡
3. Suppose that RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ 6= 0. Then there exists

> 0 such that for each

Î´ > 0, there exists mÌ„ âˆˆ Z+ such that:
Pri

Â³

Â´
Â¯
Â¯
lim Â¯Ï†1n,m (s) âˆ’ Ï†2n,m (s)Â¯ >
>1âˆ’Î´

nâ†’âˆ

(âˆ€m > mÌ„, i = 1, 2).

i (Ï) be the asymptotic likelihood ratio as defined in
Proof. (Proof of Part 1) Let Rm
Â¡ iÂ¢
i . One can easily check that lim
i
(4) associated with subjective density fÎ¸,m
= 0.
mâ†’âˆ Rm pÌ‚
Â¡ i
Â¡ iÂ¢
Â¡
Â¢Â¢
Â¡
Â¢
j
Hence, by (5), limmâ†’âˆ Ï†âˆ,m pÌ‚ âˆ’ Ï†jâˆ,m pÌ‚i = 0 if and only if limmâ†’âˆ Rm
pÌ‚i = 0. By

definition, we have:

Â¡ Â¡
Â¢Â¢
f m 1 âˆ’ pÌ‚1 âˆ’ pÌ‚2
lim
mâ†’âˆ
f (m (pÌ‚1 âˆ’ pÌ‚2 ))
Â¡
Â¢
= RÌƒ 1 âˆ’ pÌ‚1 âˆ’ pÌ‚2 , pÌ‚1 âˆ’ pÌ‚2
Â¯
Â¯Â¢
Â¡
= RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ ,

Â¡ iÂ¢
j
lim Rm
pÌ‚
=

mâ†’âˆ

where the last equality follows by condition (i), the symmetry of the function f . This establishes
Â¡ Â¢
Â¡ i
Â¡ iÂ¢
Â¡ i Â¢Â¢
j
i pÌ‚i = 0 (and thus lim
that limmâ†’âˆ Rm
= 0) if and only if
mâ†’âˆ Ï†âˆ,m pÌ‚ âˆ’ Ï†âˆ,m pÌ‚
Â¯
Â¯
Â¢
Â¡ 1
RÌƒ pÌ‚ + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ = 0.
Â¯Â¢
Â¯
Â¡
(Proof of Part 2) Take any > 0 and Î´ > 0, and assume that RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ = 0.
By Lemma 1, there exists

0

> 0 such that Ï†iâˆ,m (Ï (s)) > 1 âˆ’ whenever Ri (Ï (s)) < 0 . There
21

also exists x0 such that
Â¢
Â¢
Â¡
Â¡
Pr Ï (s) âˆˆ pÌ‚i âˆ’ x0 /m, pÌ‚i + x0 /m |Î¸ = A =
i

Z

x0

âˆ’x0

f (x) dx > 1 âˆ’ Î´.

(9)

Let Îº = minxâˆˆ[âˆ’x0 ,x0 ] f (x) > 0. Since f monotonically decreases to zero in the tails (see (ii)
Â¡
Â¢
above), there exists x1 such that f (x) < 0 Îº whenever |x| > |x1 |. Let m1 = (x0 + x1 ) / 2pÌ‚i âˆ’ 1 >
Â¯
Â¯
Â¡
Â¢
0. Then, for any m > m1 and Ï (s) âˆˆ pÌ‚i âˆ’ x0 /m, pÌ‚i + x0 /m , we have Â¯Ï (s) âˆ’ 1 + pÌ‚i Â¯ > x1 /m,
and hence

Â¢Â¢
Â¡ Â¡
0Îº
f m Ï (s) + pÌ‚i âˆ’ 1
<
= 0.
=
i
f (m (Ï (s) âˆ’ pÌ‚ ))
Îº
Â¡
Â¢
Therefore, for all m > m1 and Ï (s) âˆˆ pÌ‚i âˆ’ x0 /m, pÌ‚i + x0 /m , we have that
i
Rm
(Ï (s))

Ï†iâˆ,m (Ï (s)) > 1 âˆ’ .

Again, by Lemma 1, there exists
00 .

00

(10)

j
> 0 such that Ï†jâˆ,m (Ï (s)) > 1âˆ’ whenever Rm
(Ï (s)) <

Now, for each Ï (s),
Â¯
Â¯Â¢
Â¡
j
lim Rm
(Ï (s)) = RÌƒ Ï (s) + pÌ‚j âˆ’ 1, Â¯Ï (s) âˆ’ pÌ‚j Â¯ .

(11)

mâ†’âˆ

j
Moreover, by the uniform convergence assumption, there exists Î· > 0 such that Rm
(Ï (s))
Â¯
Â¯
Â¢
Â¡
Â¡
Â¢
uniformly converges to RÌƒ Ï (s) + pÌ‚j âˆ’ 1, Â¯Ï (s) âˆ’ pÌ‚j Â¯ on pÌ‚i âˆ’ Î·, pÌ‚i + Î· and

Â¯
Â¯Â¢
Â¡
RÌƒ Ï (s) + pÌ‚j âˆ’ 1, Â¯Ï (s) âˆ’ pÌ‚j Â¯ <

00

/2

Â¢
Â¡
for each Ï (s) in pÌ‚i âˆ’ Î·, pÌ‚i + Î· . Moreover, uniform convergence also implies that RÌƒ is continÂ¯
Â¯Â¢
Â¡
uous at pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ (and in this part of the proof, by hypothesis, it takes the value
Â¡
Â¢
0). Hence, there exists m2 < âˆ such that for all m > m2 and Ï (s) âˆˆ pÌ‚i âˆ’ Î·, pÌ‚i + Î· ,
Â¯
Â¯Â¢
Â¡
j
Rm
(Ï (s)) < RÌƒ Ï (s) + pÌ‚j âˆ’ 1, Â¯Ï (s) âˆ’ pÌ‚j Â¯ +

Â¡
Â¢
Therefore, for all m > m2 and Ï (s) âˆˆ pÌ‚i âˆ’ Î·, pÌ‚i + Î· , we have
Ï†jâˆ,m (Ï (s)) > 1 âˆ’ .

00

/2 <

00

.

(12)

Set mÌ„ â‰¡ max {m1 , m2 , Î·/x0 }. Then, by (10) and (12), for any m > mÌ„ and Ï (s) âˆˆ
Â¯
Â¯
Â¢
Â¡ i
pÌ‚ âˆ’ x0 /m, pÌ‚i + x0 /m , we have Â¯Ï†iâˆ,m (Ï (s)) âˆ’ Ï†jâˆ,m (Ï (s))Â¯ < . Then, (9) implies that
Â¯
Â¡Â¯
Â¢
Pri Â¯Ï†iâˆ,m (Ï (s)) âˆ’ Ï†jâˆ,m (Ï (s))Â¯ < |Î¸ = A > 1 âˆ’ Î´. By the symmetry of A and B, this
Â¢
Â¡
establishes that Pri |Ï†iâˆ,m (Ï (s)) âˆ’ Ï†jâˆ,m (Ï (s)) | < > 1 âˆ’ Î´ for m > mÌ„.
22

Â¯
Â¯Â¢
Â¡
j Â¡ iÂ¢
(Proof of Part 3) Since limmâ†’âˆ Rm
pÌ‚ = RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ is assumed to be
Â¡ Â¢
Â¡
Â¡ Â¢Â¢
strictly positive, limmâ†’âˆ Ï†jâˆ,m pÌ‚i < 1. We set = 1 âˆ’ limmâ†’âˆ Ï†jâˆ,m pÌ‚i /2 and use

similar arguments to those in the proof of Part 2 to obtain the desired conclusion.

Theorem 5 provides a complete characterization of the conditions under which approximate
certainty will lead to asymptotic agreement. In particular, it shows that, while approximate
certainty ensures asymptotic learning, it may not be suï¬ƒcient to guarantee asymptotic agreement. This contrasts with the result in Theorems 1 that there will always be asymptotic
agreement under full certainty. Theorem 5, instead, shows that even a small amount of uncertainty may be suï¬ƒcient to cause disagreement between the individuals.
The first part of the theorem provides a simple condition on the tail of the distribution
f that determines whether the asymptotic diï¬€erence between the posteriors is small under
approximate uncertainty. This condition can be expressed as:
Â¡ Â¡
Â¢Â¢
Â¯ 1
Â¯Â¢
Â¡ 1
f m pÌ‚1 + pÌ‚2 âˆ’ 1
2
2Â¯
Â¯
RÌƒ pÌ‚ + pÌ‚ âˆ’ 1, pÌ‚ âˆ’ pÌ‚ â‰¡ lim
= 0.
mâ†’âˆ
f (m (pÌ‚1 âˆ’ pÌ‚2 ))

(13)

The theorem shows that if this condition is satisfied, then as uncertainty about the informativeness of the signals disappears the diï¬€erence between the posteriors of the two individuals
will become negligible. Notice that condition (13) is symmetric and does not depend on i.
Intuitively, condition (13) is related to the beliefs of one individual on whether the other
Â¡ Â¢
i pÌ‚i = 0,
individual will learn. Under approximate certainty, we always have that limmâ†’âˆ Rm
so that each agent believes that he will learn the value of Î¸ with probability 1. Asymptotic

agreement (or lack thereof) depends on whether he also believes the other individual will learn
Â¯Â¢
Â¯
Â¡
the value of Î¸. When RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ = 0, an individual who expects a limiting

frequency of pÌ‚2 in the asymptotic distribution will still learn the true state when the limiting
frequency is pÌ‚1 . Therefore, individual 1, who is almost certain that the limiting frequency will
be pÌ‚1 , still believes that individual 2 will reach the same inference as himself. In contrast,
Â¯Â¢
Â¯
Â¡
when RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ 6= 0, individual 1 is still certain that limiting frequency of
signals will be pÌ‚1 and thus expects to learn himself. However, he understands that, when
Â¯
Â¯Â¢
Â¡
RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ 6= 0, an individual who expects a limiting frequency of pÌ‚2 will fail to

learn the true state when limiting frequency happens to be pÌ‚1 . Since he is almost certain that

the limiting frequency will be pÌ‚1 (or 1 âˆ’ pÌ‚1 ), he expects the other agent not to learn the truth
and thus he expects the disagreement between them to persist asymptotically.
Parts 2 and 3 of the theorem then exploit this result and the continuity of RÌƒ to show that
23

the individuals will attach probability 1 to the event that the asymptotic diï¬€erence between
their beliefs will disappear when (13) holds, and they will attach probability 1 to asymptotic
disagreement when (13) fails to hold. Thus the behavior of asymptotic beliefs under approximate certainty are completely determined by condition (13).
Theorem 5 establishes that whether or not there will be asymptotic agreement depends
Â¯
Â¯Â¢
Â¡
on whether RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ is equal to 0. We next investigate what this condition

means for determining distributions f . Clearly, this will depend on the tail behavior of f ,
n
o
i
which, in turn, determines the behavior of the family of subjective densities fÎ¸,m
. Suppose
x â‰¡ pÌ‚1 + pÌ‚2 âˆ’ 1 > pÌ‚1 âˆ’ pÌ‚2 â‰¡ y > 0. Then, condition (13) can be expressed as
f (mx)
= 0.
mâ†’âˆ f (my)
lim

This condition holds for distributions with exponential tails, such as the exponential or the
normal distributions. On the other hand, it fails for distributions with polynomial tails. For
example, consider the Pareto distribution, where f (x) is proportional to |x|âˆ’Î± for some Î± > 1.
Then, for each m,
f (mx)
=
f (my)

Âµ Â¶âˆ’Î±
x
> 0.
y

This implies that for the Pareto distribution, individualsâ€™ beliefs will fail to converge even when
there is a negligible amount of uncertainty. In fact, for this distribution, the asymptotic beliefs
i does not depend on m). If we take Ï€ 1 = Ï€ 2 = 1/2, then
will be independent of m (since Rm

the asymptotic posterior probability of Î¸ = A according to i is
Â¢âˆ’Î±
Â¡
Ï (s) âˆ’ pÌ‚i
i
Ï†âˆ,m (Ï (s)) =
(Ï (s) âˆ’ pÌ‚i )âˆ’Î± + (Ï (s) + pÌ‚i âˆ’ 1)âˆ’Î±
for any m.
As illustrated in Figure 2, in this case Ï†iâˆ,m is not monotone (in fact, the discussion in
the previous subsection explained why it had to be non-monotone for asymptotic agreement
to breakdown). To see the magnitude of asymptotic disagreement, consider Ï (s) âˆ¼
= pÌ‚i . In that
case, Ï†iâˆ,m (Ï (s)) is approximately 1, and Ï†jâˆ,m (Ï (s)) is approximately y âˆ’Î± / (xâˆ’Î± + y âˆ’Î± ).
Hence, both individuals believe that the diï¬€erence between their asymptotic posteriors will be
Â¯ 1
Â¯
Â¯Ï†âˆ,m âˆ’ Ï†2âˆ,m Â¯ âˆ¼
=

xâˆ’Î±
.
xâˆ’Î± + yâˆ’Î±

This asymptotic diï¬€erence is increasing with the diï¬€erence y â‰¡ pÌ‚1 âˆ’ pÌ‚2 , which corresponds to
the diï¬€erence in the individualsâ€™ views on which frequencies of signals are most likely. It is
24

1.0
0.8
0.6
0.4
0.2
0.0
0.0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

Figure 2: limnâ†’âˆ Ï†in (s) for Pareto distribution as a function of Ï (s) [Î± = 2, pÌ‚i = 3/4.]
also clear from this expression that this asymptotic diï¬€erence will converge to zero as y â†’ 0

(i.e., as pÌ‚1 â†’ pÌ‚2 ). This last statement is indeed generally true when RÌƒ is continuous:
Proposition 1 In Theorem 5, in addition, assume that RÌƒ is continuous on the set

D = {(x, y) | âˆ’ 1 â‰¤ x â‰¤ 1, |y| â‰¤ yÌ„} for some yÌ„ > 0. Then for every > 0 and Î´ > 0, there exist
Â¯
Â¯
Î» > 0 and mÌ„ âˆˆ (0, âˆ) such that whenever Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ < Î»,
Pri

Â³

Â´
Â¯
Â¯
<Î´
lim Â¯Ï†1n,m âˆ’ Ï†2n,m Â¯ >

nâ†’âˆ

(âˆ€m > mÌ„, i = 1, 2).

Proof. To prove this proposition, we modify the proof of Part 2 of Theorem 5 and use the
notation in that proof. Since RÌƒ is continuous on the compact set D and RÌƒ (x, 0) = 0 for each
Â¯
Â¯
Â¯Â¢
Â¯
Â¡
x, there exists Î» > 0 such that RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ < 00 /4 whenever Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ < Î». Fix

any such pÌ‚1 and pÌ‚2 . Then, by the uniform convergence assumption, there exists Î· > 0 such
Â¯Â¢
Â¯
Â¡
Â¡
Â¢
j
(Ï (s)) uniformly converges to RÌƒ Ï (s) + pÌ‚j âˆ’ 1, Â¯Ï (s) âˆ’ pÌ‚j Â¯ on pÌ‚i âˆ’ Î·, pÌ‚i + Î· and
that Rm
Â¯Â¢
Â¯
Â¡
RÌƒ Ï (s) + pÌ‚j âˆ’ 1, Â¯Ï (s) âˆ’ pÌ‚j Â¯ <

00

/2

Â¡
Â¢
for each Ï (s) in pÌ‚i âˆ’ Î·, pÌ‚i + Î· . The rest of the proof is identical to the proof of Part 2 in
Theorem 5.

This proposition implies that if the individuals are almost certain about the informativeness
of signals, then any significant diï¬€erence in their asymptotic beliefs must be due to a significant
diï¬€erence in their subjective densities regarding the signal distribution (i.e., it must be the case
Â¯
Â¯
that Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ is not small). In particular, the continuity of RÌƒ in Proposition 1 implies that
Â¯Â¢
Â¯
Â¡
when pÌ‚1 = pÌ‚2 , we must have RÌƒ pÌ‚1 + pÌ‚2 âˆ’ 1, Â¯pÌ‚1 âˆ’ pÌ‚2 Â¯ = 0, and thus, from Theorem 5, there
25

will be no significant diï¬€erences in asymptotic beliefs. Notably, however, the requirement that
pÌ‚1 = pÌ‚2 is rather strong. For example, Theorem 1 established that under certainty there will
be asymptotic agreement for all pÌ‚1 , pÌ‚2 > 1/2.
i (Ï) is continuous in the
It is also worth noting that the assumption that RÌƒ or limmâ†’0 Rm

relevant range is important for the results in Proposition 1. In particular, recall that Example 1
illustrated a situation in which this assumption failed and the asymptotic diï¬€erences remained
bounded away from zero, irrespective of the gap between pÌ‚1 and pÌ‚2 .
We next focus on the case where pÌ‚1 6= pÌ‚2 and provide a further characterization of which
classes of determining functions lead to asymptotic agreement under approximate certainty.
We first define:
Definition 1 A density function f has regularly-varying tails if it has unbounded support and
satisfies
lim

mâ†’âˆ

f (mx)
= H(x) âˆˆ R
f (m)

for any x > 0.
The condition in Definition 1 that H (x) âˆˆ R is relatively weak, but nevertheless has

important implications. In particular, it implies that H(x) â‰¡ xâˆ’Î± for Î± âˆˆ (0, âˆ). This follows

from the fact that in the limit, the function H (Â·) must be a solution to the functional equation
H(x)H(y) = H(xy), which is only possible if H(x) â‰¡ xâˆ’Î± for Î± âˆˆ (0, âˆ).12 Moreover, Seneta
(1976) shows that the convergence in Definition 1 holds locally uniformly, i.e., uniformly for
x in any compact subset of (0, âˆ). This implies that if a density f has regularly-varying
tails, then the assumptions imposed in Theorem 5 (in particular, the uniform convergence
assumption) are satisfied. In fact, we have that, in this case, RÌƒ defined in (7) is given by the
same expression as for the Pareto distribution,
Âµ Â¶âˆ’Î±
x
RÌƒ(x, y) =
,
y
and is everywhere continuous. As this expression suggests, densities with regularly-varying tails
behave approximately like power functions in the tails; indeed a density f (x) with regularlyvarying tails can be written as f (x) = L(x)xâˆ’Î± for some slowly-varying function L (with
12

To see this, note that since limmâ†’âˆ (f(mx)/f (m)) = H (x) âˆˆ R, we have




f (mxy)
f (mxy) f (my)
= lim
= H (x) H (y) .
H (xy) = lim
mâ†’âˆ
mâ†’âˆ
f (m)
f (my) f (m)

See de Haan (1970) or Feller (1971).

26

limmâ†’âˆ L(mx)/L (m) = 1). Many common distributions, including the Pareto, log-normal,
and t-distributions, have regularly-varying densities. We also define:
Definition 2 A density function f has rapidly-varying
â§
â¨ 0
f (mx)
= xâˆ’âˆ â‰¡
1
lim
mâ†’âˆ f (m)
â©
âˆ

tails if it satisfies
if
if
if

x>1
x=1
x<1

for any x > 0.

As in Definition 1, the above convergence holds locally uniformly (uniformly in x over any
compact subset that excludes 1). Examples of densities with rapidly-varying tails include the
exponential and the normal densities.
From these definitions, the following corollary to Theorem 5 is immediate and links asymptotic agreement under approximate certainty to the tail behavior of the determining density
function.
Corollary 1 Suppose that Assumption 1 holds and pÌ‚1 6= pÌ‚2 .
1. Suppose that in Theorem 5 f has regularly-varying tails. Then there exists

> 0 such

that for each Î´ > 0, there exists mÌ„ âˆˆ Z+ such that
Pri

Â³

Â´
Â¯
Â¯
lim Â¯Ï†1n,m (s) âˆ’ Ï†2n,m (s)Â¯ >
>1âˆ’Î´

nâ†’âˆ

(âˆ€m > mÌ„, i = 1, 2).

2. Suppose that in Theorem 5 f has rapidly-varying tails. Then for every

> 0 and Î´ > 0,

there exists mÌ„ âˆˆ Z+ such that
i

Pr

Â³

Â´
Â¯
Â¯ 1
2
Â¯
Â¯
lim Ï†n,m (s) âˆ’ Ï†n,m (s) >
<Î´

nâ†’âˆ

(âˆ€m > mÌ„, i = 1, 2).

This corollary therefore implies that whether there will be asymptotic agreement depends
on whether the family of subjective densities converging to â€œcertaintyâ€ has regularly or rapidlyvarying tails (provided that pÌ‚1 6= pÌ‚2 ).
Returning to the intuition above, Corollary 1 and the previous definitions make it clear
that the failure of asymptotic agreement is related to disagreement between the two individuals
about limiting frequencies, i.e., pÌ‚1 6= pÌ‚2 , together with suï¬ƒciently thick tails of the subjective

probability distribution so that an individual who expects pÌ‚2 should have suï¬ƒcient uncertainty
27

when confronted with a limiting frequency of pÌ‚1 . Along the lines of the intuition given there,
this is suï¬ƒcient for both individuals to believe that they will learn the true value of Î¸ themselves,
but that the other individual will fail to do so. Rapidly-varying tails imply that individuals
become relatively certain of their model of the world and thus when individual i observes a
limiting frequency Ï close to but diï¬€erent from pÌ‚i , he will interpret this as driven by sampling
variation and attach a high probability to Î¸ = A. This will guarantee asymptotic agreement
between the two individuals. In contrast, with regularly-varying tails, even under approximate
certainty, limiting frequencies diï¬€erent from pÌ‚i will be interpreted not as a sampling variation,
but as potential evidence for Î¸ = B, preventing asymptotic agreement.

3

Generalizations

The previous section provided our main results in an environment with two states and two
signals. In this section, we show that our main results generalize to an environment with K â‰¥ 2
states and L â‰¥ K signals. The main results parallel those of Section 2, and all the proofs for
this section are contained in the Appendix.
Â©
Âª
To generalize our results to this environment, let Î¸ âˆˆ Î˜, where Î˜ â‰¡ A1 , ..., AK is a set

containing K â‰¥ 2 distinct elements. We refer to a generic element of the set by Ak . Similarly,
Â©
Âª
let st âˆˆ a1 , ..., aL , with L â‰¥ K signal values. As before, define s â‰¡ {st }âˆ
t=1 , and for each
l = 1, ..., L, let

o
n
rnl (s) â‰¡ # t â‰¤ n|st = al

be the number of times the signal st = al out of first n signals. Once again, the strong law of
large numbers implies that, according to both individuals, for each l = 1, ..., L, rnl (s) /n almost
P
l
surely converges to some Ïl (s) âˆˆ [0, 1] with L
l=1 Ï (s) = 1. Define Ï (s) âˆˆ âˆ† (L) as the vector
n
o
Â¡
Â¢
Â¡
Â¢
PL l
Ï (s) â‰¡ Ï1 (s) , ..., ÏL (s) , where âˆ† (L) â‰¡ p = p1 , . . . , pL âˆˆ [0, 1]L :
p
=
1
, and let
l=1

the set SÌ„ be

n
o
SÌ„ â‰¡ s âˆˆ S : limnâ†’âˆ rnl (s) /n exists for each l = 1, ..., L .

(14)

With analogy to the two-state-two-signal model in Section 2, let Ï€ ik > 0 be the prior probability
Â¡
Â¢
individual i assigns to Î¸ = Ak , Ï€ i â‰¡ Ï€ i1 , ..., Ï€ iK , and plÎ¸ be the frequency of observing signal
s = al when the true state is Î¸. When players are certain about plÎ¸ â€™s as in usual models,

immediate generalizations of Theorems 1 and 2 apply. With analogy to before, we define FÎ¸i as
Â¡
Â¢
the joint subjective probability distribution of conditional frequencies p â‰¡ p1Î¸ , ..., pL according
28

to individual i. Since our focus is learning under uncertainty, we impose an assumption similar
to Assumption 1.
Assumption 2 For each i and Î¸, the distribution FÎ¸i over âˆ†(L) has a continuous, non-zero
and finite density fÎ¸i over âˆ†(L).
This assumption can be weakened along the lines discussed in Remark 2 above.
Â¡
Â¢
We also define Ï†ik,n (s) â‰¡ Pri Î¸ = Ak | {st }nt=0 for each k = 1, ..., K as the posterior

probability that Î¸ = Ak after observing the sequence of signals {st }nt=0 , and
Ï†ik,âˆ (Ï (s)) â‰¡ lim Ï†ik,n (s) .
nâ†’âˆ

Given this structure, it is straightforward to generalize the results in Section 2. Let us now
Kâˆ’1
define the transformation Tk : RK
, such that
+ â†’ R+
Âµ
Â¶
xk0 0
Tk (x) =
; k âˆˆ {1, ..., K} \ k .
xk

Here Tk (x) is taken as a column vector. This transformation will play a useful role in the
theorems and the proofs. In particular, this transformation will be applied to the vector Ï€ i of
priors to determine the ratio of priors assigned the diï¬€erent states by individual i. Let us also
Â¡
Â¢
define the norm kxk = maxl |x|l for x = x1 , . . . , xL âˆˆ RL .
The next lemma generalizes Lemma 1:

Lemma 3 Suppose Assumption 2 holds. Then for all s âˆˆ SÌ„,
Ï†ik,âˆ (Ï (s)) =
1+

S

1

i
i
k0 6=k Ï€ k0 fAk0 (Ï(s))
i
i
Ï€ k f k (Ï(s))
A

.

(15)

Our first theorem in this section parallels Theorem 3 and shows that under Assumption
2 there will be lack of asymptotic learning, and under a relatively weak additional condition,
there will also asymptotic disagreement.
Theorem 6 Suppose Assumption 2 holds for i = 1,2, then for each k = 1, ..., K, and for each
i = 1,2,
Â¡
Â¢
1. Pri Ï†ik,âˆ (Ï (s)) 6= 1|Î¸ = Ak = 1,and
29

Â¯
Â¢
Â¡Â¯
Â¡ Â¢
Â¡ Â¢
2. Pri Â¯Ï†1k,âˆ (Ï (s)) âˆ’ Ï†2k,âˆ (Ï (s))Â¯ 6= 0 = 1 whenever Pri ((Tk Ï€ 1 âˆ’Tk Ï€ 2 )0 Tk (f i (Ï(s)) =
0) = 0 and FÎ¸1 = FÎ¸2 for each Î¸ âˆˆ Î˜.

Â¡ Â¢
Â¡ Â¢
The additional condition in part 2 of Theorem 6, that Pri ((Tk Ï€ 1 âˆ’Tk Ï€ 2 )0 Tk (f i (Ï(s)) =

0) = 0, plays the role of diï¬€erences in priors in Theorem 3 (here â€œ 0 â€ denotes the transpose

of the vector in question). In particular, if this condition did not hold, then at some Ï (s), the
relative asymptotic likelihood of some states could be the same according to two individuals
with diï¬€erent priors and they would interpret at least some sequences of signals in a similar
manner and achieve asymptotic agreement. It is important to note that the condition that
Â¡ Â¢
Â¡ Â¢
Pri ((Tk Ï€ 1 âˆ’ Tk Ï€ 2 )0 Tk (f i (Ï(s)) = 0) = 0 is relatively weak and holds genericallyâ€“i.e., if
it did not hold, a small perturbation of Ï€ 1 or Ï€ 2 would restore it.13 The Part 2 of Theorem 6
therefore implies that asymptotic disagreement occurs generically.
The next theorem shows that small diï¬€erences in priors can again widen after observing
the same sequence of signals.
Â³ Â³Â¡
Â´
Â³Â¡
Â´Â´
Â¢
Â¢
Theorem 7 Under Assumption 2, assume 10 Tk fÎ¸1 (Ï) Î¸âˆˆÎ˜ âˆ’ Tk fÎ¸2 (Ï) Î¸âˆˆÎ˜
6= 0 for
each Ï âˆˆ [0, 1], each k = 1, ..., K, where 1 â‰¡ (1, ..., 1)0 . Then, there exists an open set of prior

vectors Ï€ 1 and Ï€ 2 , such that

and

Â¯
Â¯ Â¯ 1
Â¯ 1
2
2Â¯
Â¯ Â¯
Â¯Ï†
k,âˆ (Ï (s)) âˆ’ Ï†k,âˆ (Ï (s)) > Ï€ k âˆ’ Ï€ k for each k = 1, ..., K and s âˆˆ SÌ„
Â¯ Â¯
Â¯Â¢
Â¡Â¯
Pri Â¯Ï†1k,âˆ (Ï (s)) âˆ’ Ï†2k,âˆ (Ï (s))Â¯ > Â¯Ï€ 1k âˆ’ Ï€ 2k Â¯ = 1 for each k = 1, ..., K.

Â³ Â³Â¡
Â´
Â³Â¡
Â´Â´
Â¢
Â¢
The condition 10 Tk fÎ¸1 (Ï) Î¸âˆˆÎ˜ âˆ’ Tk fÎ¸2 (Ï) Î¸âˆˆÎ˜
6= 0 is similar to the additional

condition in part 2 of Theorem 6, and as with that condition, it is relatively weak and holds
generically. Finally, the following theorem generalizes Theorem 5. The appropriate construction of the families of probability densities is also provided in the theorem.
 
 


More formally, the set of solutions S â‰¡ { Ï€ 1 , Ï€2 , Ï âˆˆ âˆ†(L)2 : (Tk Ï€1 âˆ’ Tk Ï€2 )0 Tk (f i (Ï)) = 0} has
Lebesgue measure 0. This is a consequence of the Preimage Theorem and Sardâ€™s Theorem in diï¬€erential
topology (see, for example, Guillemin and Pollack, 1974, pp. 21 and 39). The Preimage Theorem implies that
if y is a regular value of a map f : X â†’ Y , then f âˆ’1 (y) is a submanifold of X with
 dimension
  equal to
dim X âˆ’ dim Y . In our context, this implies that if 0 is a regular value of the map (Tk Ï€1 âˆ’ Tk Ï€2 )0 Tk (f i (Ï)),
then the set S is a two dimensional submanifold of âˆ†(L)3 and thus has Lebesgue measure 0. Sardâ€™s theorem
implies that 0 is generically a regular value.
13

30

Theorem 8 Suppose that Assumption 2 holds. For each Î¸ âˆˆ Î˜ and m âˆˆ Z+ , define the

i
subjective density fÎ¸,m
by

i
(p) = c (i, Î¸, m) f (m (p âˆ’ pÌ‚ (i, Î¸)))
fÎ¸,m

where c (i, Î¸, m) â‰¡ 1/

(16)

Â¡ 0Â¢
f
(m
(p
âˆ’
pÌ‚
(i,
Î¸)))
dp,
pÌ‚
(i,
Î¸)
âˆˆ
âˆ†
(L)
with
pÌ‚
(i,
Î¸)
=
6
pÌ‚
i, Î¸ whenpâˆˆâˆ†(L)

R

ever Î¸ 6= Î¸0 , and f : RL â†’ R is a positive, continuous probability density function that satisfies

the following conditions:
(i) limhâ†’âˆ max{x:kxkâ‰¥h} f (x) = 0,
(ii)
RÌƒ (x, y) â‰¡ lim

mâ†’âˆ

f (mx)
f (my)

(17)

exists at all x, y, and
(iii) convergence in (17) holds uniformly over a neighborhood of each
Â¢
Â¢
Â¡
Â¡
pÌ‚ (i, Î¸) âˆ’ pÌ‚ j, Î¸0 , pÌ‚ (i, Î¸) âˆ’ pÌ‚ (j, Î¸) .

Also let Ï†ik,âˆ,m (Ï (s)) â‰¡ limnâ†’âˆ Ï†ik,n,m (s) be the asymptotic posterior of individual i with

i . Then,
subjective density fÎ¸,m

Â³
Â¡ Â¡
Â¢Â¢
Â¡ Â¡
Â¢Â¢Â´
= 0 if and only if
1. limmâ†’âˆ Ï†ik,âˆ,m pÌ‚ i, Ak âˆ’ Ï†jk,âˆ,m pÌ‚ i, Ak
Â³
Â´
Â´
Â³ Â¡
Â¢
Â¢
Â¡
Â¢
Â¡
0
RÌƒ pÌ‚ i, Ak âˆ’ pÌ‚ j, Ak , pÌ‚ i, Ak âˆ’ pÌ‚ j, Ak = 0 for each k 0 6= k.

Â¢
Â¢
Â¡
Â¡
2. Suppose that RÌƒ pÌ‚ (i, Î¸) âˆ’ pÌ‚ j, Î¸0 , pÌ‚ (i, Î¸) âˆ’ pÌ‚ (j, Î¸) = 0 for each distinct Î¸ and Î¸0 . Then
for every

> 0 and Î´ > 0, there exists mÌ„ âˆˆ Z+ such that
Â°
Â¡Â°
Â¢
Pri Â°Ï†1âˆ,m (s) âˆ’ Ï†2âˆ,m (s)Â° > < Î´

(âˆ€m > mÌ„, i = 1, 2).

Â¡
Â¡
Â¢
Â¢
3. Suppose that RÌƒ pÌ‚ (i, Î¸) âˆ’ pÌ‚ j, Î¸0 , pÌ‚ (i, Î¸) âˆ’ pÌ‚ (j, Î¸) 6= 0 for each distinct Î¸ and Î¸0 . Then
there exists

> 0 such that for each Î´ > 0, there exists mÌ„ âˆˆ Z+ such that

Â°
Â¢
Â¡Â°
Pri Â°Ï†1âˆ,m (s) âˆ’ Ï†2âˆ,m (s)Â° > > 1 âˆ’ Î´

(âˆ€m > mÌ„, i = 1, 2).

These theorems therefore show that the results about lack of asymptotic learning and
asymptotic agreement derived in the previous section do not depend on the assumption that

31

there are only two states and binary signals. It is also straightforward to generalize Proposition
1 and Corollary 1 to the case with multiple states and signals; we omit this to avoid repetition.
The results in this section are stated for the case in which both the number of signal values
and states are finite. They can also be generalized to the case of a continuum of signal values
and states, but this introduces a range of technical issues that are not central to our focus
here.

4

Applications

In this section we discuss a number of applications of the results derived so far. The applications
are chosen to show various diï¬€erent economic consequences from learning and disagreement
under uncertainty. Throughout, we strive to choose the simplest examples. The first example
illustrates how learning under uncertainty can overturn some simple insights from basic game
theory. The second example shows how such learning can act as an equilibrium selection
device as in Carlsson and van Damme (1993). The third example is the most substantial
application and shows how learning under uncertainty aï¬€ects speculative asset trading. The
fourth example illustrates how learning under uncertainty can aï¬€ect the timing of agreement
in bargaining. Finally, the last example shows how a special case of our model of learning
under uncertainty can arise when there is information transmission by a potentially biased
media outlet.14

4.1

Value of Information in Common-Interest Games

Consider a common-interest game in which the players have identical payoï¬€ functions. Typically in common interest games information is valuable in the sense that with more information
about underlying parameters, the value of the game in the best equilibrium will be higher. We
would therefore expect players to collect or at least wait for the arrival of additional informa14
In this section, except for the example on equilibrium selection and the last example of the game of belief
manipulation, we study complete-information games with possibly non-common priors. Formally, information
and belief structure in these games can be described as follows. Fix the state space â„¦ = Î˜ Ã— SÌ„, and for each
n < âˆ, consider the information partition I n = I n (s) = {(Î¸, s0 ) |s0t = st âˆ€t â‰¤ n} |s âˆˆ SÌ„ that is common for
both players. For n = âˆ, we introduce the common information partition I âˆ = I âˆ (s) = Î˜ Ã— {s} |s âˆˆ SÌ„ .
At each I n (s), player i = 1, 2 assigns probability Ï†in (s) to the state Î¸ = A and probability 1 âˆ’ Ï†in (s) to the
sate Î¸ = B. Since the players have a common partition at each s and n, their beliefs are common knowledge.
Notice that, under certainty, Ï†1âˆ (s) = Ï†2âˆ (s) âˆˆ {0, 1}, so that after observing s, both players assign probability
1 to the same Î¸. In that case, there will be common certainty of Î¸, or loosely speaking, Î¸ becomes â€œcommon
knowledge.â€ This is not necessarily the case under uncertainty.

32

tion before playing such games. We now show that when there is learning under uncertainty,
additional information can be harmful in common-interest games, and thus the agents may
prefer to play the game before additional information arrives.
To illustrate these issues, consider the payoï¬€ matrix
Î±
Î²

Î±
2Î¸, 2Î¸
1/2, 1/2

Î²
1/2, 1/2
1 âˆ’ Î¸, 1 âˆ’ Î¸

where Î¸ âˆˆ {0, 1}, and the agents have a common prior on Î¸ according to which probability of
Î¸ = 1 is Ï€ âˆˆ (1/2, 1). When there is no information, Î± strictly dominates Î² (since the expected
value of the payoï¬€ from (Î±, Î±) is strictly greater than 1/2 and the expected value of the payoï¬€
from (Î², Î²) is strictly less than 1/2). In the dominant-strategy equilibrium, (Î±, Î±), each player
receives 2Î¸ with probability Ï€, thus achieve an expected payoï¬€ of 2Ï€ > 1.
First, consider the implications of learning under certainty. Suppose that the agents are
allowed to observe an infinite sequence of signals s = {st }âˆ
t=1 , where each agent believes that

Pri (st = Î¸|Î¸) = pi > 1/2. Theorem 1 then implies that after observing the sequence of signals,

the agents will learn Î¸. If the frequency Ï (s) of signal with st = 1 is greater than 1/2, they
will learn that Î¸ = 1; otherwise they will learn that Î¸ = 0. If Ï (s) < 1/2, Î² strictly dominates
Î±, and hence (Î², Î²) is the dominant strategy equilibrium. If Ï (s) > 1/2, Î± strictly dominates
Î² and (Î±, Î±) is the dominant strategy equilibrium. Consequently, when they learn under
certainty before playing the game, the expected payoï¬€ to each player is 2Ï€ + (1 âˆ’ Ï€) > 2Ï€.
This implies that, if they have the option, the players would prefer to wait for the arrival of
public information before playing the game.
Let us next turn to learning under uncertainty. In particular, suppose that the agents do
not know the signal distribution and their subjective densities are similar to those in Example
2:
fÎ¸i (p)

=

â§ Â¡
â¨ 1âˆ’ âˆ’
â©

2

2

Â¢

/Î´ if pÌ‚i âˆ’ Î´/2 â‰¤ p â‰¤ pÌ‚i + Î´/2
if p < 1/2
otherwise

(18)

for each Î¸, where 0 < Î´ < pÌ‚1 âˆ’ pÌ‚2 and and Î´ are taken to be arbitrarily small (i.e., we consider
the limit where

â†’ 0 and Î´ â†’ 0, or loosely speaking, where

33

âˆ¼
= 0 and Î´ âˆ¼
= 0). Recall from

âˆ¼
= 0 and Î´ âˆ¼
= 0,
â§
âª
âª
âª
âª
â¨ 1
i
âˆ¼
Ï†âˆ (Ï (s)) =
âª
âª
âª
âª
â©
0

Example 2 that when

As discussed above, when

the asymptotic posterior probability of Î¸ = 1 is
if Ï (s) < 1 âˆ’ pÌ‚i âˆ’ Î´/2,
or 1 âˆ’ pÌ‚i + Î´/2 < Ï (s) < 1/2,
or pÌ‚i âˆ’ Î´/2 â‰¤ Ï (s) â‰¤ pÌ‚i + Î´/2,
otherwise.

âˆ¼
= 0 and Î´ âˆ¼
= 0, each agent believes that he will learn the true

value of Î¸, while the other agent will reach the opposite conclusion. This implies that both
agents expect that one of them will have Ï†iâˆ (Ï (s)) âˆ¼
= 1 while the other has Ï†iâˆ (Ï (s)) âˆ¼
= 0.
Consequently, the unique equilibrium will be (Î±, Î²), giving both agents an ex ante expected
payoï¬€ of 1/2, which is strictly less than the expected payoï¬€ to playing the game before the
arrival of information (which is 2Ï€). Therefore, when there is learning under uncertainty, both
agents may prefer to play the game before the arrival of public information.

4.2

Selection in Coordination Games

The initial diï¬€erence in playersâ€™ beliefs about the signal distribution need not be due to lack
of common prior; it may be due to private information. Building on an example by Carlsson
and van Damme (1993), we now illustrate that when the players are uncertain about the signal
distribution, small diï¬€erences in beliefs, combined with learning, may have a significant eï¬€ect
on the outcome of the game and may select one of the multiple equilibria of the game.
Consider a game with the payoï¬€ matrix
I
N

I
Î¸, Î¸
0, Î¸ âˆ’ 1

N
Î¸ âˆ’ 1, 0
0, 0

where Î¸ âˆ¼ N (0, 1). The players observe an infinite sequence of public signals s â‰¡ {st }âˆ
t=0 ,
where st âˆˆ {0, 1} and
Pr(st = 1|Î¸) = 1/ (1 + exp (âˆ’ (Î¸ + Î·))) ,

(19)

with Î· âˆ¼ N (0, 1). In addition, each player observes a private signal
xi = Î· + ui
where ui is uniformly distributed on [âˆ’ /2, /2] for some small

> 0.

Let us define Îº â‰¡ log(Ï (s)) âˆ’ log(1 âˆ’ Ï (s)). Equation (19) implies that after observing s,
the players infer that Î¸ + Î· = Îº. For small , conditional on xi , Î· is distributed approximately
34

uniformly on [xi âˆ’ /2, xi + /2] (see Carlsson and van Damme, 1993). This implies that conditional on xi and s, Î¸ is approximately uniformly distributed on [Îº âˆ’ xi âˆ’ /2, Îº âˆ’ xi + /2].
Now note that with the reverse order on xi , the game is supermodular. Therefore, there exist
extremal rationalizable strategy profiles, which also constitute monotone, symmetric Bayesian
Nash Equilibria. In each equilibrium, there is a cutoï¬€ value, xâˆ— , such that the equilibrium action is I if xi < xâˆ— and N if xi > xâˆ— . This cutoï¬€, xâˆ— , is defined such that player i is indiï¬€erent
between the two actions, i.e.,
Îº âˆ’ xâˆ— = Pr(xj > xâˆ— |xi = xâˆ— ) = 1/2 + O ( ) ,
where O ( ) is such that lim

â†’0 O (

) = 0. This establishes that
xâˆ— = Îº âˆ’ 1/2 âˆ’ O ( ) .

Therefore, when

is small, the game is dominance solvable, and each player i plays I if

xi < Îº âˆ’ 1/2 and N if xi > Îº + 1/2.
In this game, learning under certainty has very diï¬€erent implications from those above.
Suppose instead that the players knew the conditional signal distribution (i.e., they knew Î·),
so that we are in a world of learning under certainty. Then after s is observed, Î¸ would become
common knowledge, and there would be multiple equilibria whenever Î¸ âˆˆ (0, 1). This example
therefore illustrates how learning under uncertainty can lead to the selection of one of the
equilibria in a coordination game.

4.3

A Simple Model of Asset Trade

One of the most interesting applications of the ideas developed here is to models of asset
trading. Models of assets trading with diï¬€erent priors have been studied by, among others,
Harrison and Kreps (1978) and Morris (1996). These works assume diï¬€erent priors about
the dividend process and allow for learning under certainty. They establish the possibility of
â€œspeculative asset tradingâ€. We now investigate the implications of learning under uncertainty
for the pattern of speculative asset trading.
Consider an asset that pays 1 if the state is A and 0 if the state is B. Assume that Agent
2 owns the asset, but Agent 1 may wish to buy it. We have two dates, Ï„ = 0 and Ï„ = 1, and
the agents observe a sequence of signals between these dates. For simplicity, we again take this
to be an infinite sequence s â‰¡ {st }âˆ
t=1 . We also simplify this example by assuming that Agent
35

1 has all the bargaining power: at either date, if he wants to buy the asset, Agent 1 makes
a take-it-or-leave-it price oï¬€er PÏ„ , and trade occurs at price PÏ„ if Agent 2 accepts the oï¬€er.
Assume also that Ï€ 1 > Ï€ 2 , so that Agent 1 is more optimistic. This assumption ensures that
Agent 1 would like to purchase the asset. We are interested in subgame-perfect equilibrium of
this game.
Let us start with the case in which there is learning under certainty. Suppose that each
agent is certain that pA = pB = pi for some number pi > 1/2. In that case, from Theorem
1, both agents recognize at Ï„ = 0 that at Ï„ = 1, for each Ï (s), the value of the asset will the
same for both of them: it will be worth 1 if Ï (s) > 1/2 and 0 if Ï (s) < 1/2. Hence, at Ï„ = 1
the agents will be indiï¬€erent between trading the asset (at price P1 = Ï†1âˆ (Ï (s)) = Ï†2âˆ (Ï (s)))
at each history Ï (s). Therefore, if trade does not occur at Ï„ = 0, the continuation value of
Agent 1 is 0, and the continuation value of Agent 2 is Ï€ 2 . If they trade at price P0 , then the
continuation value of agents 1 and 2 will be Ï€ 1 âˆ’ P0 and P0 , respectively. This implies that at

date 0, Agent 2 accepts an oï¬€er if and only if P0 â‰¥ Ï€ 2 . Since Ï€ 1 > Ï€ 2 , Agent 1 is happy to

oï¬€er the price P0 = Ï€ 2 at date Ï„ = 0 and trade takes place. Therefore, with learning under
certainty, there will be immediate trade at Ï„ = 0.
We next turn to the case of learning under uncertainty and suppose that the agents do
not know pA and pB . In contrast to the case of learning under certainty, the agents now have
an incentive to delay trading. To illustrate this, we first consider a simple example where
subjective densities are as in Example 1, with

â†’ 0. Now, at date 1, if pÌ‚1 âˆ’ Î´/2 < Ï (s) <

pÌ‚1 + Î´/2, then the value of the asset for Agent 2 is Ï†2âˆ (Ï (s)) = Ï€ 2 , and the value of the asset
for Agent 1 is approximately 1. Hence, at such Ï (s), Agent 1 buys the asset from Agent 2 at

price P1 (Ï (s)) = Ï€ 2 , enjoying gains from trade equal to 1 âˆ’ Ï€ 2 . Since the equilibrium payoï¬€
of Agent 1 must be non-negative in all other contingencies, this shows that when they do not
trade at date 0, his continuation value is at least

(when

Â¡
Â¢
Ï€1 1 âˆ’ Ï€2

â†’ 0). The continuation value of Agent 2 must be at least Ï€ 2 , as he has the option

of never selling his asset. Therefore, they can trade at date 0 only if the total payoï¬€ from
Â¡
Â¢
trading, which is Ï€ 1 , exceeds the sum of these continuation values, Ï€ 1 1 âˆ’ Ï€ 2 + Ï€ 2 . Since this

is impossible, there will be no trade at Ï„ = 0. Instead, Agent 1 will wait for the information
to buy the asset at date 1 (provided that Ï (s) turns out to be in a range where he concludes
36

that the asset pays 1).
This example exploits the general intuition discussed after Theorem 4: if the agents are
uncertain about the informativeness of the signals, each agent may expect to learn more from
the signals than the other agent. In fact, this example has the extreme feature whereby each
agent believes that he will definitely learn the true state, but the other agent will fail to do
so. This induces the agents to wait for the arrival of additional information before trading.
This contrasts with the intuition that observation of common information should take agents
towards common beliefs and make trades less likely. This intuition is correct in models of
learning under certainty and is the reason why previous models have generated speculative
trade at the beginning (Harrison and Kreps, 1978, and Morris, 1996). Instead, here there is
delayed speculative trading.
The next result characterizes the conditions for delayed asset trading more generally:
Proposition 2 In any subgame-perfect equilibrium, trade is delayed to Ï„ = 1 if and only if
Â£ Â¤
Â£
Â©
ÂªÂ¤
E2 Ï†2âˆ = Ï€ 2 > E1 min Ï†1âˆ , Ï†2âˆ .

Â£
Â©
ÂªÂ¤
That is, when Ï€ 2 > E1 min Ï†1âˆ , Ï†2âˆ , Agent 1 does not buy at Ï„ = 0 and buys at Ï„ = 1 if
Â£
Â©
ÂªÂ¤
Ï†1âˆ (Ï (s)) > Ï†2âˆ (Ï (s)); when Ï€ 2 < E1 min Ï†1âˆ , Ï†2âˆ , Agent 1 buys at Ï„ = 0.
Proof. In any subgame-perfect equilibrium, Agent 2 is indiï¬€erent between trading and not,
and hence his valuation of the asset is Pr2 (Î¸ = A|Information). Therefore, trade at Ï„ = 0 can
take place at the price P0 = Ï€ 2 , while trade at Ï„ = 1 will be at the price P1 (Ï (s)) = Ï†2âˆ (Ï (s)).

At date 1, Agent 1 buys the asset if and only if Ï†1âˆ (Ï (s)) â‰¥ Ï†2âˆ (Ï (s)), yielding the payoï¬€ of
Â©
Âª
max Ï†1âˆ (Ï (s)) âˆ’ Ï†2âˆ (Ï (s)) , 0 . This implies that Agent 1 is willing to buy at Ï„ = 0 if and
only if

as claimed.

ÂªÂ¤
Â£
Â©
Ï€ 1 âˆ’ Ï€ 2 â‰¥ E1 max Ï†1âˆ (Ï (s)) âˆ’ Ï†2âˆ (Ï (s)) , 0
Â£
Â©
ÂªÂ¤
= E1 Ï†1âˆ (Ï (s)) âˆ’ min Ï†1âˆ (Ï (s)) , Ï†2âˆ (Ï (s))
ÂªÂ¤
Â£
Â©
= Ï€ 1 âˆ’ E1 min Ï†1âˆ (Ï (s)) , Ï†2âˆ (Ï (s)) ,

Â£ Â¤
Â£
Â©
ÂªÂ¤
Since Ï€ 1 = E1 Ï†1âˆ â‰¥ E1 min Ï†1âˆ , Ï†2âˆ , this result provides a cutoï¬€ value for the initial

diï¬€erence in beliefs, Ï€ 1 âˆ’ Ï€ 2 , in terms of the diï¬€erences in the agentsâ€™ interpretation of the
37

ÂªÂ¤
Â£
Â©
signals. The cutoï¬€ value is E1 max Ï†1âˆ (Ï (s)) âˆ’ Ï†2âˆ (Ï (s)) , 0 . If the initial diï¬€erence is

lower than this value, then agents will wait until Ï„ = 1 to trade; otherwise, they will trade
immediately. Consistent with the above example, delay in trading becomes more likely when
the agents interpret the signals more diï¬€erently, which is evident from the expression for the
cutoï¬€ value. This reasoning also suggests that if FÎ¸1 = FÎ¸2 for each Î¸ (so that the agents
interpret the signals in a similar fashion),15 then trade should occur immediately. The next
lemma shows that each agent believes that additional information will bring the other agentâ€™s
expectations closer to his own and will be used to prove that FÎ¸1 = FÎ¸2 indeed implies immediate
trading.
Lemma 4 If Ï€ 1 > Ï€ 2 and FÎ¸1 = FÎ¸2 for each Î¸, then
Â£ Â¤
E1 Ï†2âˆ â‰¥ Ï€ 2 .

Proof. Recall that ex ante expectation of individual i regarding Ï†jâˆ can be written as
Z 1
Â¡
Â¤
Â£ Â¤
Â£ i i
Â¢
(20)
Ei Ï†jâˆ =
Ï€ fA (Ï) Ï†jâˆ (Ï) + 1 âˆ’ Ï€ i fBi (1 âˆ’ Ï) Ï†jâˆ (Ï) dÏ
0
Â¡
Â¢
Z 1 i
Ï€ fA (Ï) + 1 âˆ’ Ï€ i fB (1 âˆ’ Ï)
fA (Ï) dÏ,
=
j
j
0 Ï€ fA (Ï) + (1 âˆ’ Ï€ ) fB (1 âˆ’ Ï)
where the first line uses the definition of ex ante expectation under the probability measure
Pri , while the second line exploits equations (3) and (4) and the fact that since FÎ¸1 = FÎ¸2 ,
fÎ¸1 (Ï) = fÎ¸2 (Ï) = fÎ¸ (Ï) for all Ï. Now define
Z

1

Ï€fA (Ï) + (1 âˆ’ Ï€) fB (1 âˆ’ Ï)
fA (Ï) dÏ.
2
2
0 Ï€ fA (Ï) + (1 âˆ’ Ï€ ) fB (1 âˆ’ Ï)
Â£ Â¤
Â¡ Â¢
Â£ Â¤
Â¡ Â¢
From (20), E1 Ï†2âˆ = I Ï€ 1 and Ï€ 2 = E2 Ï†2âˆ = I Ï€ 2 . Hence, it suï¬ƒces to show that I is
I (Ï€) â‰¡

increasing in Ï€. Now,
0

Z

1

fA (Ï)
2
Ï€ fA (Ï) + (1 âˆ’ Ï€ 2 ) fB

(fA (Ï) âˆ’ fB (1 âˆ’ Ï)) dÏ.
(1 âˆ’ Ï)
Â£
Â¡
Â¤
Â¢
Moreover, fA (Ï) / Ï€ 2 fA (Ï) + 1 âˆ’ Ï€ 2 fB (1 âˆ’ Ï) â‰¥ 1 if and only if fA (Ï) â‰¥ fB (1 âˆ’ Ï).
I (Ï€) =

0

15

Recall from Theorem 3 that even when FÎ¸1 = FÎ¸2 , agents interpret signals diï¬€erently because Ï€1 6= Ï€2 .

38

Hence,
I (Ï€) =

Z

=

Z

0

fA (Ï)
(fA (Ï) âˆ’ fB (1 âˆ’ Ï)) dÏ
+ (1 âˆ’ Ï€ 2 ) fB (1 âˆ’ Ï)
fA â‰¥fB
Z
fA (Ï)
(fB (1 âˆ’ Ï) âˆ’ fA (Ï)) dÏ
âˆ’
2 f (Ï) + (1 âˆ’ Ï€ 2 ) f (1 âˆ’ Ï)
Ï€
A
B
fA <fB
Z
Z
(fA (Ï) âˆ’ fB (1 âˆ’ Ï)) dÏ âˆ’
(fB (1 âˆ’ Ï) âˆ’ fA (Ï)) dÏ
â‰¥
Ï€ 2 fA (Ï)

fA â‰¥fB
1

0

fA <fB

(fA (Ï) âˆ’ fB (1 âˆ’ Ï)) dÏ = 0.

Together with the previous proposition, this lemma yields the following result establishing
that delay in asset trading can only occur when subjective probability distributions diï¬€er across
individuals.
Proposition 3 If FÎ¸1 = FÎ¸2 for each Î¸, then in any subgame-perfect equilibrium, trade occurs
at Ï„ = 0.
Proof. Since Ï€ 1 > Ï€ 2 and R1 = R2 , Lemma 1 implies that Ï†1âˆ (Ï (s)) â‰¥ Ï†2âˆ (Ï (s)) for
Â£
Â©
ÂªÂ¤
Â£ Â¤
each Ï (s). Then, E1 min Ï†1âˆ , Ï†2âˆ = E1 Ï†2âˆ â‰¥ Ï€ 2 , where the last inequality is by Lemma

4. Therefore, by Proposition 2, Agent 1 buys at Ï„ = 0.

This proposition establishes that when the two agents have the same subjective probability
distributions, there will be no delay in trading. However, as the example above illustrates,
when FÎ¸1 6= FÎ¸2 , delayed speculative trading is possible. The intuition is given by Lemma 4:
when agents have the same subjective probability distribution but diï¬€erent priors, each will
believe that additional information will bring the other agentâ€™s beliefs closer to his own. This
leads to early trading. However, when the agents diï¬€er in terms of their subjective probability
distributions, they expect to learn more from new information (because, as discussed after
Theorem 4 above, they believe that they have the â€œcorrect model of the worldâ€). Consequently,
they delay trading.
Learning under uncertainty does not necessarily lead to additional delay in economic transactions, however. Whether it does so or not depends on the eï¬€ect of the extent of disagreement
on the timing of economic transactions. We will next see that, in the context of bargaining,
the presence of learning under uncertainty may be a force towards immediate agreement rather
than delay.
39

4.4

Bargaining With Outside Options

Consider two agents bargaining over the division of a dollar. There are two dates, Ï„ âˆˆ {0, 1},
and Agent 2 has an outside option Î¸ âˆˆ {Î¸L , Î¸H } that expires at the end of date 1, where
Î¸L < Î¸H < 1 and the value of Î¸ is initially unknown. Between the two dates, the agents
observe an infinite sequence of public signals s â‰¡ {st }âˆ
t=1 with st âˆˆ {aL , aH }, where the signal
aL can be thought to be more likely under Î¸L .
Bargaining follows a simple protocol: at each date Ï„ , Agent 1 oï¬€ers a share wÏ„ to Agent
2. If Agent 2 accepts the oï¬€er, the game ends, Agent 2 receives the proposal, wÏ„ , and Agent
1 receives the remaining 1 âˆ’ wÏ„ . If Agent 2 rejects the oï¬€er, she decides whether to take her
outside option, terminating the game, or wait for the next stage of the game. We assume that
delay is costly, so that if negotiations continue until date Ï„ = 1, Agent 1 incurs a cost c > 0.
Finally, as in Yildiz (2003), the agents are assumed to be â€œoptimistic,â€ in the sense that
y â‰¡ E2 [Î¸] âˆ’ E1 [Î¸] > 0.
In other words, they diï¬€er in their expectations of Î¸ on the outside option of Agent 2â€“with
Agent 2 believing that her outside option is higher than Agent 1â€™s assessment of this outside
optionâ€“and y parameterizes the extent of optimism in this game.
We assume that the game form and beliefs are common knowledge and look for the subgameperfect equilibrium of this simple bargaining game.
By backward induction, at date Ï„ = 1, for any Ï (s), the value of outside option for Agent
1 is E2 [Î¸|Ï (s)] < 1, and hence she accepts an oï¬€er w1 if and only if w1 â‰¥ E2 [Î¸|Ï (s)]. Agent 2

therefore oï¬€ers w1 = E2 [Î¸|Ï (s)]. If there is no agreement at date 0, the continuation values of
the two agents are:
Â¤
Â£
V 1 = 1 âˆ’ c âˆ’ E1 E2 [Î¸|Ï (s)]

and

Â¤
Â£
V 2 = E2 E2 [Î¸|Ï (s)] = E2 [Î¸] ,

which uses the fact that there is no cost of delay for Agent 2. Since they have 1 dollar in total,
the agents will delay the agreement to date Ï„ = 1 if and only if
Â¤
Â£
E2 [Î¸] âˆ’ E1 E2 [Î¸|Ï (s)] > c.

Â£
Â¤
Here, E1 E2 [Î¸|Ï (s)] is Agent 1â€™s expectation about how Agent 2 will update her beliefs

after observing the signals s. If Agent 1 expects that the information will reduce Agent 2â€™s
40

expectation of her outside option more than the cost of waiting, then Agent 1 is willing to wait.
This description makes it clear that whether there will be agreement at date Ï„ = 0 depends
on Agent 1â€™s assessment of how Agent 2 will interpret the (public) signals.
When each agent is certain about the informativeness of the signals, they agree ex ante
that they will interpret the information correctly. Consequently, as in Lemma 4 in the previous
subsection, Agent 1â€™s Bayesian updating will indicate that the public information will reveal
him to be right. Yildiz (2004) has shown that this reasoning gives Agent 1 an incentive to
â€œwait to persuadeâ€ Agent 2 that her outside option is relatively low. More specifically, assume
that each agent i is certain that Pri (st = Î¸|Î¸) = pÌ‚i > 1/2 for some pÌ‚1 and pÌ‚2 , where pÌ‚1 and pÌ‚2
may diï¬€er. Then, from Theorem 1, the agents agree that Agent 2 will learn her outside option,
Â¢
Â¤
Â¡
Â£
i.e., Pri E2 [Î¸|Ï (s)] = Î¸ = 1 for each i. Hence, E1 E2 [Î¸|Ï (s)] = E1 [Î¸]. Therefore, Agent 1
delays the agreement to date Ï„ = 1 if and only if

y > c,
i.e., if and only if the level of optimism is higher than the cost of waiting. This discussion
therefore indicates that the arrival of public information can create a reason for delay in
bargaining games.
We now show that when agents are uncertain about the informativeness of the signals, this
motive for delay is reduced and there can be immediate agreement. Intuitively, each agent
understands that the same signals will be interpreted diï¬€erently by the other agent and thus
expects that they are less likely to persuade the other agent. This decreases the incentives to
delay agreement.
This result is illustrated starkly here, with an example where a small amount of uncertainty about the informativeness of signals removes all incentives to delay agreement. Suppose
that the agentsâ€™ beliefs are again as in Example 1 with

small. Now Agent 1 assigns probaÂ£
Â¤
bility more than 1 âˆ’ to the event that that Ï (s) will be either in pÌ‚ âˆ’ Î´/2, pÌ‚1 + Î´/2 or in
Â¤
Â£
1 âˆ’ pÌ‚ âˆ’ Î´/2, 1 âˆ’ pÌ‚1 + Î´/2 , inducing Agent 2 to stick to her prior. Hence, Agent 1 expects
that Agent 2 will not update her prior by much. In particular, we have

Thus

Â¤
Â£
E1 E2 [Î¸|Ï (s)] = E2 [Î¸] + O ( ) .
Â¤
Â£
E2 [Î¸] âˆ’ E1 E2 [Î¸|Ï (s)] = âˆ’O ( ) < c.
41

This implies that agents will agree at the beginning of the game. Therefore, the same forces that
led to delayed asset trading in the previous subsection can also induce immediate agreement
in bargaining when agents are â€œoptimisticâ€.

4.5

Manipulation and Uncertainty

Our final example is intended to show how the pattern of uncertainty used in the body of the
paper can result from game theoretic interactions between an agent and an informed party, for
example as in cheap talk games (Crawford and Sobel, 1982). Since our purpose is to illustrate
this possibility, we choose the simplest environment to communicate these ideas and limit the
discussion to the single agent settingâ€“the generalization to the case with two or more agents
is straightforward.
The environment is as follows. The state of the world is Î¸ âˆˆ {0, 1}, and the agent starts
with a prior belief Ï€ âˆˆ (0, 1) that Î¸ = 1 at t = 0. At time t = 1, this agent has to make a
decision x âˆˆ [0, 1], and his payoï¬€ is âˆ’ (x âˆ’ Î¸)2 . Thus the agent would like to form as accurate

an expectation about Î¸ as possible.
The other player is a media outlet, M , which observes a large (infinite) number of signals
âˆ
0
s0 â‰¡ {s0t }âˆ
t=1 with st âˆˆ {0, 1}, and makes a sequence of reports to the agent s â‰¡ {st }t=1

with st âˆˆ {0, 1}. The reports s can be thought of as contents of newspaper articles, while s0
correspond to the information that the newspaper collects before writing the articles. Since s0

is an exchangeable sequence, we can represent it, as before, with the fraction of signals that
are 1â€™s, denoted by Ï0 âˆˆ [0, 1], and similarly s is represented by Ï âˆˆ [0, 1]. This is convenient
as it allows us to model the mixed strategy of the media as a mapping
Ïƒ M : [0, 1] â†’ âˆ† ([0, 1]) ,
where âˆ† ([0, 1]) is the set of probability distributions on [0, 1]. Let i be the strategy that
puts probability 1 on the identity mapping, thus corresponding to M reporting truthfully.
Otherwise, i.e., if Ïƒ M 6= i, there is manipulation (or misreporting) on the part of the media

outlet M .16

We also assume for simplicity that Ï0 has a continuous distribution with density g1 when
Î¸ = 1 and g0 when Î¸ = 0, such that g1 (Ï) = 0 for all Ï â‰¤ ÏÌ„ and g1 (Ï) > 0 for all Ï > ÏÌ„, while
g0 (Ï) > 0 for all Ï â‰¤ ÏÌ„ and g0 (Ï) = 0 for all Ï > ÏÌ„. This assumption implies that if M reports
16

See Baron (2004) and Gentzkow and Shapiro (2006) for related models of media bias.

42

truthfully, i.e., Ïƒ M = i, then Theorem 2 applies and there will be asymptotic learning (and
also asymptotic agreement when there are more than one agent).
Now suppose instead that there are three diï¬€erent types of player M (unobservable to the
agent). With probability Î»H âˆˆ (0, 1), the media is honest and can only play Ïƒ H
M = i (where
the superscript is for type Hâ€“honest). With probability Î»Î± âˆˆ (0, 1 âˆ’ Î»H ), the media outlet is
of type Î± and is biased towards 1. Type Î± media outlet receives utility equal to x irrespective
of Ï0 , and hence would like to manipulate the agent to choose high values of x. With the
complementary probability Î»Î² = 1 âˆ’ Î»Î± âˆ’ Î»H , the media outlet is of type Î² and is biased
towards 0, and receives utility equal to 1 âˆ’ x.
Let us now look for the perfect Bayesian equilibrium of the game between the media outlet
and the agent. The perfect Bayesian equilibrium can be represented by two reporting functions
Ïƒ Î±M : [0, 1] â†’ âˆ† ([0, 1]) and Ïƒ Î²M : [0, 1] â†’ âˆ† ([0, 1]) for the two biased types of M , and updating
function Ï† : [0, 1] â†’ [0, 1], which determines the belief of the agent that Î¸ = 1 when the
sequence of reports is Ï, and an action function x : [0, 1] â†’ [0, 1], which determines the
choice of the agent as a function of Ï (there is no loss of generality here in restricting to pure
strategies).
In equilibrium, x must be optimal for the agent given Ï†; Ï† must be derived from Bayes
rule given Ïƒ Î±M , Ïƒ Î²M and the prior Ï€; and Ïƒ Î±M and Ïƒ Î²M must be optimal for the two biased media
outlets given x.
Note first that since the payoï¬€ to the biased media outlet does not depend on the true
Ï0 , without loss of generality, we can restrict Ïƒ Î±M and Ïƒ Î²M not to depend on Ï0 . Then, with a
slight abuse of notation, let Ïƒ Î±M (Ï) and Ïƒ Î²M (Ï) be the respective densities with which these
two types report Ï.
Second, the optimal choice of the agent after observing a sequence of signals with fraction
Ï being equal to 1 is
x (Ï) = Ï† (Ï) ,
for all Ï âˆˆ [0, 1], i.e., the agent will choose an action equal to his belief Ï† (Ï).
Third, an application of Bayesâ€™ rule implies the following belief for the agent:


â§
Î²
Î»Î± ÏƒÎ±
âª
M (Ï)+Î»Î² Ïƒ M (Ï) Ï€
âª
âª
if Ï â‰¤ ÏÌ„
âª
â¨ (1âˆ’Ï€)Î»H g0 (Ï)+Î»Î± ÏƒÎ±M (Ï)+Î»Î² ÏƒÎ²M (Ï)
Ï† (Ï) =


âª
Î²
âª
Î»H g1 (Ï)+Î»Î± ÏƒÎ±
âª
M (Ï)+Î»Î² Ïƒ M (Ï) Ï€
âª
â©
if Ï > ÏÌ„.
Î²
Î±
Ï€Î»H g1 (Ï)+Î»Î± ÏƒM (Ï)+Î»Î² ÏƒM (Ï)

43

(21)

The following lemma shows that any (perfect Bayesian) equilibrium has a very simple form:
Lemma 5 In any equilibrium, there exist Ï†A > Ï€ and Ï†B < Ï€ such that Ï† (Ï) = Ï†B for all
Ï < ÏÌ„ and Ï† (Ï) = Ï†A for all Ï > ÏÌ„.
Proof. From (21), Ï† (Ï) < Ï€ when Ï < ÏÌ„, and Ï† (Ï) > Ï€ when Ï > ÏÌ„. Since the media type
Î± maximizes x (Ï) = Ï† (Ï), we have Ïƒ Î±M (Ï) = 0 for Ï < ÏÌ„. Now suppose that the lemma is false
and there exists Ï1 , Ï2 â‰¤ ÏÌ„ such that Ï† (Ï1 ) > Ï† (Ï2 ). Then we also have Ïƒ Î²M (Ï1 ) = 0â€“since
media type Î² minimizes x (Ï) = Ï† (Ï). But in that case, equation (21) implies that Ï† (Ï1 ) = 0,
contradicting the hypothesis. Therefore, Ï† (Ï) is constant over Ï âˆˆ [0, ÏÌ„). The proof for Ï† (Ï)
being constant over Ï âˆˆ (ÏÌ„, 1] is analogous.
It follows immediately from this lemma that equilibrium beliefs will take the form given in
the next proposition:
Proposition 4 Suppose that Ï 6= ÏÌ„, then the unique equilibrium actions and beliefs are:
Ïƒ Î±M (Ï) = g1 (Ï)
Ïƒ Î²M (Ï) = g0 (Ï)
â§
Î»Î² Ï€
âª
â¨ (1âˆ’Ï€)Î»H +Î»Î²
x (Ï) = Ï† (Ï) =
âª
â© Ï€(Î»H +Î»Î± )
Ï€Î»H +Î»Î±

(22)
(23)
if Ï < ÏÌ„
(24)
if Ï > ÏÌ„.

Proof. Consider the case Ï < ÏÌ„. As in the proof of Lemma 5, Ïƒ Î±M (Ï) = 0. Since Ï† (Ï) is
constant over Ï âˆˆ [0, ÏÌ„) (by Lemma 5), equation (21) implies that Ïƒ Î²M is proportional to g0 on

this range. Since this range is the common support of the densities Ïƒ Î²M and g0 , it must be that
Ïƒ Î²M = g0 . Similarly, Ïƒ Î±M = g1 . Substituting these equalities in (21), we obtain (24).

This proposition implies that the unique equilibrium of the game between the media outlet
and the agent leads to a special case of our model of learning under uncertainty. In particular,
the beliefs in (24) can be obtained by the appropriate choice of the functions fA (Â·) and fB (Â·)
from equation (3) in Section 2. This illustrates that the type of learning under uncertainty
analyzed in this paper is likely to emerge in game-theoretic situations where one of the players
is trying to manipulate the beliefs of others.

44

5

Concluding Remarks

A key assumption of most theoretical analyses is that individuals have a â€œcommon prior,â€ meaning that they have beliefs consistent with each other regarding the game forms, institutions,
and possible distributions of payoï¬€-relevant parameters. This presumption is often justified by
the argument that suï¬ƒcient common experiences and observations, either through individual
observations or transmission of information from others, will eliminate disagreements, taking
agents towards common priors. This presumption receives support from a number of wellknown theorems in statistics and economics, for example, Savage (1954) and Blackwell and
Dubins (1962).
Nevertheless, existing theorems apply to environments in which learning occurs under certainty, that is, individuals are certain about the meaning of diï¬€erent signals. In many situations, individuals are not only learning about a payoï¬€-relevant parameter but also about the
interpretation of diï¬€erent signals. This takes us to the realm of environments where learning
takes place under uncertainty. For example, many signals favoring a particular interpretation
might make individuals suspicious that the signals come from a biased source. We show that
learning in environments with uncertainty may lead to a situation in which there is lack of
full identification (in the standard sense of the term in econometrics and statistics). In such
situations, information will be useful to individuals but may not lead to full learning.
This paper investigates the conditions under which learning under uncertainty will take
individuals towards common priors (or asymptotic agreement). We consider an environment
in which two individuals with diï¬€erent priors observe the same infinite sequence of signals
informative about some underlying parameter. Our environment is one of learning under uncertainty, since individuals have non-degenerate subjective probability distribution over the
likelihood of diï¬€erent signals given the values of the parameter. We show that when subjective
probability distributions of both individuals have full support (or in fact under weaker assumptions), they will never agree, even after observing the same infinite sequence of signals. We
also show that this corresponds to a result of â€œagreement to eventually disagreeâ€; individuals
will agree, before observing the sequence of signals, that their posteriors about the underlying
parameter will not converge. This common understanding that more information may not lead
to similar beliefs for agents has important implications for a variety of games and economic
models. Instead, when there is no full support in subjective probably distributions, asymptotic
45

learning and agreement may obtain.
An important implication of this analysis is that after observing the same sequence of
signals, two Bayesian individuals may end up disagreeing more than they originally did. This
result contrasts with the common presumption that shared information and experiences will
take individualsâ€™ assessments closer to each other.
We also systematically investigate whether asymptotic agreement obtain as the amount of
uncertainty in the environment diminishes (i.e., as we look at families of subjective probability
distributions converging to degenerate limit distributions with all their mass at one point).
We provide a complete characterization of the conditions under which this will be the case.
Asymptotic disagreement may prevail even under â€œapproximate certainty,â€ as long as the family
of subjective probability distributions converging to a degenerate distribution (and thus to an
environment with certainty) has regularly-varying tails (such as for the Pareto, the log-normal
or the t-distributions). In contrast, with rapidly-varying tails (such as the normal and the
exponential distributions), convergence to certainty leads to asymptotic agreement.
Lack of common beliefs and common priors has important implications for economic behavior in a range of circumstances. We illustrate how the type of learning outlined in this paper
interacts with economic behavior in various diï¬€erent situations, including games of coordination, games of common interest, bargaining, asset trading and games of communication. For
example, we show that contrary to standard results, individuals may wish to play commoninterest games before rather than after receiving more information about payoï¬€s. Similarly, we
show how the possibility of observing the same sequence of signals may lead to â€œspeculative delayâ€ in asset trading among individuals that start with similar beliefs. We also provide a simple
example illustrating why individuals may be uncertain about informativeness of signalsâ€“the
strategic behavior of other agents trying to manipulate their beliefs.
The issues raised here have important implications for statistics and econometrics as well
as learning in game-theoretic situations. As noted above, the environment considered here
corresponds to one in which there is lack of full identification. Nevertheless, Bayesian posteriors
are well-behaved and converge to a limiting distribution. Studying the limiting properties of
these posteriors more generally and how they may be used for inference in under-identified
econometric models is an interesting area for research.

46

6

Appendix: Omitted Proofs

Proof of Theorem 1. Under the hypothesis of the theorem and with the notation in (2), we have
"Âµ
Â¡ i Â¢nâˆ’rn
Â¶1âˆ’2rn /n #n
(1 âˆ’ pÌ‚i )rn
pÌ‚
pÌ‚i
Pri (rn |Î¸ = B)
=
,
= i rn
1 âˆ’ pÌ‚i
(pÌ‚ ) (1 âˆ’ pÌ‚i )nâˆ’rn
Pri (rn |Î¸ = A)
which converges to 0 or âˆ depending on limnâ†’âˆ rn /n is greater than 1/2 or less than 1/2. If
limnâ†’âˆ rn (s) /n > 1/2, then by (2), limnâ†’âˆ Ï†1n (s) = limnâ†’âˆ Ï†2n (s) = 1, and if limnâ†’âˆ rn (s) /n < 1/2,
then limnâ†’âˆ Ï†1n (s) = limnâ†’âˆ Ï†2n (s) = 0. Since limnâ†’âˆ rn (s) /n = 1/2 occurs with probability zero,
this shows the second part. The first part follows from the fact that, according to each i, conditional
on Î¸ = A, limnâ†’âˆ rn (s) /n = pÌ‚i > 1/2.
Proof of Lemma 3. The proof is identical to that of Lemma 1.
Proof of Theorem 6.
(Part1) This part immediately follows from Lemma 3, as each Ï€ik0 fAk0 (Ï (s)) is positive, and
Ï€ ik fAk (Ï (s)) is finite.
(Part 2) Assume FÎ¸1 = FÎ¸2 for each Î¸ âˆˆ Î˜. Then, by Lemma 3, Ï†1k,âˆ (Ï) âˆ’ Ï†2k,âˆ (Ï) = 0 if and
Â´
Â¢
Â¡ Â¢Â¢0 Â³Â¡
Â¡ Â¡ Â¢
only if Tk Ï€1 âˆ’ Tk Ï€ 2 Tk fÎ¸1 (Ï) Î¸âˆˆÎ˜ = 0. The latter inequality has probability 0 under both
probability measures Pr1 and Pr2 by hypothesis.

Proof of Theorem 7. Define Ï€Ì„ = (1/K, . . . , 1/K). First, take Ï€ 1 = Ï€2 = Ï€Ì„. Then,
P
P
1 1
2 1
Â³ Â³Â¡
Â´
Â³Â¡
Â´Â´
Â¢
Â¢
k0 6=k Ï€ k0 fAk0 (Ï (s))
k0 6=k Ï€ k0 fAk0 (Ï (s))
6= 0,
âˆ’
= 10 Tk fÎ¸1 (Ï(s)) Î¸âˆˆÎ˜ âˆ’ Tk fÎ¸2 (Ï(s)) Î¸âˆˆÎ˜
1
1
2
1
Ï€ k fAk (Ï (s))
Ï€ k fAk (Ï (s))
0

1 â‰¡ (1, . . . , 1) , and the
Â¯where
Â¯ inequality follows by the hypothesis of the theorem.
Â¯ Hence, by Lemma 3, Â¯
Â¯Ï†1k,âˆ (Ï (s)) âˆ’ Ï†2k,âˆ (Ï (s))Â¯ > 0 for each Ï (s) âˆˆ [0, 1]. Since [0, 1] is compact and Â¯Ï†1k,âˆ (Ï (s)) âˆ’ Ï†2k,âˆ (Ï (s))Â¯
Â¯
Â¯
is continuous in Ï (s), there exists > 0 such that Â¯Ï†1k,âˆ (Ï (s)) âˆ’ Ï†2k,âˆ (Ï (s))Â¯ > for each Ï (s) âˆˆ [0, 1].
Â¯
Â¯
Now, since Â¯Ï†1k,âˆ (Ï (s)) âˆ’ Ï†2k,âˆ (Ï (s))Â¯ is continuous in Ï€ 1 and Ï€ 2 , there exists a neighborhood N (Ï€Ì„)
of Ï€Ì„ such that
Â¯ 1
Â¯
Â¯ Â¯
Â¯Ï†k,âˆ (Ï (s)) âˆ’ Ï†2k,âˆ (Ï (s))Â¯ > Â¯Ï€ 1k âˆ’ Ï€ 2k Â¯ for each k = 1, ..., K and s âˆˆ SÌ„
Â¡ Â¢
for all Ï€1 , Ï€ 2 âˆˆ N (Ï€Ì„). Since Pri SÌ„ = 1, the last statement in the theorem follows.
Proof of Theorem 8. Our proof utilizes the following two lemmas.
Lemma A.
lim Ï†ik,âˆ,m (p) =

mâ†’âˆ

k0 ,

1
1+

P

Ï€ ik0
k0 6=k Ï€ik

.

RÌƒ (p âˆ’ pÌ‚ (i, Ak0 ) , p âˆ’ pÌ‚ (i, Ak ))

Â¡
Â¢
Proof. By condition (i), limmâ†’âˆ c i, Ak , m = 1 for each i and k. Hence, for every distinct k and

Â³
Â´
Â³ Â³
Â³
Â´Â´Â´
0
0
Â´
Â³
Â³
c i, Ak , m
f m p âˆ’ pÌ‚ i, Ak
Â¡
fAi k0 (p)
Â¢Â´
0
= lim
lim
= RÌƒ p âˆ’ pÌ‚ i, Ak , p âˆ’ pÌ‚ i, Ak .
lim i
k
k
mâ†’âˆ f k (p)
mâ†’âˆ c (i, A , m) mâ†’âˆ f (m (p âˆ’ pÌ‚ (i, A )))
A

Then, Lemma A follows from Lemma 3.

Â¥

47

Lemma
> 0 and h > 0, there exists mÌƒ such that for each m > mÌƒ, k â‰¤ K, and each
Â° B. For Â¡any ÎµÌƒÂ¢Â°
Ï (s) with Â°Ï (s) âˆ’ pÌ‚ i, Ak Â° < h/m,
Â¯
Â¡ Â¡
Â¢Â¢Â¯Â¯
Â¯ i
(25)
Â¯Ï†k,âˆ,m (Ï (s)) âˆ’ lim Ï†ik,âˆ,m pÌ‚ i, Ak Â¯ < ÎµÌƒ.
mâ†’âˆ

Â¡
Â¡
Â¢
Â¢
Proof. Since, by hypothesis, RÌƒ is continuous at each pÌ‚ (i, Î¸) âˆ’ pÌ‚ j, Î¸0 , pÌ‚ (i, Î¸) âˆ’ pÌ‚ (j, Î¸) , by
Lemma A, there exists h0 > 0, such that
Â¯
Â¡ Â¡
Â¢Â¢Â¯Â¯
Â¯
(26)
Â¯ lim Ï†ik,âˆ,m (Ï (s)) âˆ’ lim Ï†ik,âˆ,m pÌ‚ i, Ak Â¯ < ÎµÌƒ/2
mâ†’âˆ

mâ†’âˆ

and by condition (iii), there exists mÌƒ > h/h0 such that
Â¯
Â¯
Â¯
Â¯ i
Â¯Ï†k,âˆ,m (Ï (s)) âˆ’ lim Ï†ik,âˆ,m (Ï (s))Â¯ < ÎµÌƒ/2.
mâ†’âˆ

Â°
Â¢Â°
Â¡
holds uniformly in Â°Ï (s) âˆ’ pÌ‚ i, Ak Â° < h0 . The inequalities in (26) and (27) then imply (25).

(27)
Â¥

Â´ Â´
Â³
Â³ Â¡
Â¢
0
(Proof of Part 1) Since RÌƒ pÌ‚ i, Ak âˆ’ pÌ‚ i, Ak , 0 = 0 for each k 0 6= k (by condition (i)), Lemma
Â³
Â¡ Â¡
Â¢Â¢
Â¡ Â¡
Â¢Â¢
Â¡ Â¡
Â¢Â¢Â´
A implies that limmâ†’âˆ Ï†ik,âˆ,m pÌ‚ i, Ak = 1. Hence, limmâ†’âˆ Ï†ik,âˆ,m pÌ‚ i, Ak âˆ’ Ï†jk,âˆ,m pÌ‚ i, Ak
=
Â¡ Â¡
Â¢Â¢
j
j
j
k
0 if and only if limmâ†’âˆ Ï†k,âˆ,m pÌ‚ i, A
= 1. Since each ratio Ï€k0 /Ï€k is positive, by Lemma A, the
Â³ Â¡
Â´ Â¡
Â³
Â¢
Â¢
Â¡
Â¢Â´
k
k0
latter holds if only if RÌƒ pÌ‚ i, A âˆ’ pÌ‚ j, A
, pÌ‚ i, Ak âˆ’ pÌ‚ j, Ak = 0 for each k 0 6= k, establishing
Part 1.
(Proof of Part 2) Fix > 0 and Î´ > 0. Fix also any i and k. Since each Ï€ jk0 /Ï€ jk is finite, by
Lemma 3, there exists 0 > 0, such that Ï†ik,âˆ,m (Ï (s)) > 1 âˆ’ whenever fAi k0 (Ï (s)) /fAi k (Ï (s)) < 0
holds for every k 0 6= k. Now, by (i), there exists h0,k > 0, such that
Z
Â¡Â°
Â¡
Â¢Â°
Â¢
i Â°
k Â°
k
f (x) dx > (1 âˆ’ Î´) .
Ï (s) âˆ’ pÌ‚ i, A
â‰¤ h0,k /m|Î¸ = A =
Pr
kxkâ‰¤h0,k

Let

Â°
Â©
Â¡
Âª
Â¢Â°
Qk,m = p âˆˆ âˆ† (L) : Â°p âˆ’ pÌ‚ i, Ak Â° â‰¤ h0,k /m

and Îº â‰¡ minkxkâ‰¤h0,k f (x) > 0. By (i), there exists h1,k > 0 such that, whenever kxk > h1,k , f (x) <
0
Îº/2. There exists aÂ° suï¬ƒciently
Â´Â°constant m1,k such that for any m > m1,k , Ï (s) âˆˆ Qk,m , and
Â³ large
0 Â°
Â°
any k0 6= k, we have Â°Ï (s) âˆ’ pÌ‚ i, Ak Â° > h1,k /m, and
Â´Â´Â´
Â³ Â³
Â³
0
f m Ï (s) âˆ’ pÌ‚ i, Ak
f (m (Ï (s) âˆ’ pÌ‚ (i, Ak )))

<

0

0
Îº1
= .
2 Îº
2

Moreover,
since
Â³
Â´ Â¡limmâ†’âˆÂ¢ c (i, Î¸, m) = 1 for each i and Î¸, there exists m2,k > m1,k such that
k0
c i, A , m /c i, Ak , m < 2 for every k 0 6= k and m > m2,k . This implies
fAi k0 (Ï (s)) /fAi k (Ï (s)) < 0 ,

establishing that
(28)
Ï†ik,âˆ,m (Ï (s)) > 1 âˆ’ .
Â¢
Â¡
Â¡ 0Â¢
Now, for j 6= i, assume that RÌƒ pÌ‚ (i, Î¸) âˆ’ pÌ‚ j, Î¸ , pÌ‚ (i, Î¸) âˆ’ pÌ‚ (j, Î¸) = 0 for each distinct Î¸ and Î¸0 .
Â¡ Â¡
Â¢Â¢
Then, by Lemma A, limmâ†’âˆ Ï†jk,âˆ,m pÌ‚ i, Ak = 1, and hence by Lemma B, there exists m3,k > m2,k
such that for each m > m3,k , Ï (s) âˆˆ Qk,m ,
Ï†jk,âˆ,m (Ï (s)) > 1 âˆ’ .

48

(29)

Â°
Â°
Notice that when (28) and (29) hold, we have Â°Ï†1âˆ,m (s) âˆ’ Ï†2âˆ,m (s)Â° < . Then, setting mÌ„ = maxk m4,k ,
we obtain the desired inequality for each m > mÌ„:
X
Â°
Â°
Â¢
Â¡Â°
Â¡Â°
Â¢
Â¡
Â¢
Pri Â°Ï†1âˆ,m (s) âˆ’ Ï†2âˆ,m (s)Â° <
=
Pri Â°Ï†1âˆ,m (s) âˆ’ Ï†2âˆ,m (s)Â° < |Î¸ = Ak Pri Î¸ = Ak
kâ‰¤K

â‰¥

â‰¥

X

kâ‰¤K

X

kâ‰¤K

Â¡
Â¢
Â¡
Â¢
Pri Ï (s) âˆˆ Qk,m |Î¸ = Ak Pri Î¸ = Ak

(1 âˆ’ Î´)Ï€ik

= 1 âˆ’ Î´.
Â¡
Â¡
Â¢
Â¢
(Proof of Part 3) Assume that RÌƒ pÌ‚ (i, Î¸) âˆ’ pÌ‚ j, Î¸0 , pÌ‚ (i, Î¸) âˆ’ pÌ‚ (j, Î¸) 6= 0 for each distinct Î¸ and
Â¡ Â¡
Â¢Â¢
Î¸0 . Then, since each Ï€ jk0 /Ï€ jk is positive, Lemma A implies that limmâ†’âˆ Ï†jk,âˆ,m pÌ‚ i, Ak < 1 for each
k. Let
n
Â¡ Â¡
Â¢Â¢o
= min 1 âˆ’ lim Ï†jk,âˆ,m pÌ‚ i, Ak
/3 > 0.
k

mâ†’âˆ

Then, by part 2, for each k, there exists m2,k such that for every m > m2,k and Ï (s) âˆˆ Qk,m , we have
Ï†ik,âˆ (Ï (s)) > 1 âˆ’ . By Lemma B, there also exists m5,k > m2,k such that for every m > m5,k and
Ï (s) âˆˆ Qk,m ,
Â¡ Â¡
Â¢Â¢
Ï†jk,âˆ,m (Ï (s)) < lim Ï†jk,âˆ,m pÌ‚ i, Ak + â‰¤ 1 âˆ’ 2 < Ï†ik,âˆ (Ï (s)) âˆ’ .
mâ†’âˆ

Â°
Â°
This implies that Â°Ï†1âˆ,m (Ï (s)) âˆ’ Ï†2âˆ,m (Ï (s))Â° > . Setting mÌ„ = maxk m5,k and changing
Â° 1
Â°
Â°
Â°
Â°Ï†âˆ,m (s) âˆ’ Ï†2âˆ,m (s)Â° < at the end of the proof of Part 2 to Â°Ï†1âˆ,m (s) âˆ’ Ï†2âˆ,m (s)Â° > , we obtain
the desired inequality.

49

7

References
Aumann, Robert (1986): â€œCorrelated Equilibrium as an Expression of Bayesian Rational-

ity,â€ Econometrica, 55, 1-18.
Aumann, Robert (1998): â€œCommon priors: A Reply to Gul,â€ Econometrica, 66-4, 929-938.
Baron, David (2004): â€œPersistent Media Bias,â€ Stanford Graduate School of Business,
Mimeo.
Berk, Robert (1966): â€œLimiting Behavior of Posterior Distributions When the Model Is
Incorrect,â€ Annals of Mathematical Statistics, 37, 51-58.
Billingsley, Patrick (1995): Probability and Measure, Third Edition, Wiley and Sons, New
York.
Blackwell, David and Lester Dubins (1962): â€œMerging of Opinions with Increasing Information,â€ Annals of Mathematical Statistics, 33, 882-887.
Carlsson, Hans and Eric van Damme (1993): â€œGlobal Games and Equilibrium Selection,â€
Econometrica, 61, 981-1018.
Crawford, Vincent and Joel Sobel (1982): â€œStrategic Information Transmission,â€ Econometrica, 50:1431-52.
Cripps, Martin, Jeï¬€rey Ely, George Mailath and Larry Samuelson (2006): â€œCommon Learningâ€ Cowles Foundation Discussion Paper No. 1575, August 2006.
Doob, J. L. (1949): â€œApplication of the Theory of Martingales,â€ in Le Calcul des Probabilities et ses Applications, 23-27, Paris.
Diaconis Persi and David Freedman (1986): â€œOn Inconsistent Bayesian Estimates of Locationâ€ Annals of Statistics, 14, 68-87.
Feller, William (1971): An Introduction to Probability Theory and Its Applications. Volume
II, 2nd ed. Wiley, New York.
Freedman, David (1963): â€œOn the Asymptotic Behavior of Bayes Estimates in the Discrete
Case Iâ€ Annals of Mathematical Statistics, 34, 1386-1403.
Freedman, David (1965): â€œOn the Asymptotic Behavior of Bayes Estimates in the Discrete
Case IIâ€ Annals of Mathematical Statistics, 36, 454-456.
Geanakoplos, John and Heraklis Polemarchakis (1982): â€œWe Canâ€™t Disagree Forever,â€ Journal of Economic Theory, 28, 192-200.
Gentzkow, Matthew and Jesse M. Schapiro (2006): â€œMedia Bias and Reputation,â€ Journal
50

of Political Economy, 114, 280-317.
Ghosh J. K. and R. V. Ramamoorthi (2003): Bayesian Nonparametrics, Springer-Verlang,
New York.
Gul, Faruk (1998): â€œA Comment on Aumannâ€™s Bayesian viewâ€, Econometrica, 66-4, 923927.
Guillemin Victor and Alan Pollack (1974): Diï¬€erential Topology, Prentice Hall, New Jersey.
Haan, L. de (1970): On Regular Variation and Its Application to the Weak Convergence of
Sample Extremes, Mathematical Centre Tract 32, Mathematics Centre, Amsterdam, Holland.
Harrison, Michael and David Kreps (1978): â€œSpeculative Investor Behavior in a Stock
Market with Heterogenous Expectations,â€ Quarterly Journal of Economics, 92, 323-36.
Jackson, Matthew O., Ehud Kalai and Rann Smorodinsky (1999): â€œBayesian Representation of Stochastic Processes under Learning: De Finetti Revisited,â€ Econometrica, 67, 875-893.
Kurz, Mordecai (1994): â€œOn the Structure and Diversity of Rational Beliefs,â€ Economic
Theory, 4, 877-900.
Kurz, Mordecai (1996): â€œRational Beliefs and Endogenous Uncertainty: An Introduction,â€
Economic Theory, 8, 383-397.
Milgrom, Paul and Nancy Stokey (1982): â€œInformation, Trade and Common Knowledge,â€
Journal of Economic Theory, 26, 177-227.
Miller, Ronald I. and Chris W. Sanchirico (1999): â€œThe Role of Option with Continuity in
Merging of Opinions and Rational Learning,â€ Games and Economic Behavior, 29, 170-190.
Morris, Stephen (1996): â€œSpeculative Investor Behavior and Learning,â€ Quarterly Journal
of Economics, Vol. 111, No. 4, 1111-33.
Savage, Leonard J. (1954): The Foundations of Statistics, Dover reprint, New York, 1972.
Seneta, EugÃ¨ne (1976): Regularly Varying Functions, Lecture Notes in Mathematics, 508,
Springer, Berlin.
Stinchcombe, Maxwell (2005): â€œThe Unbearable Flightness of Bayesians: Generically Erratic Updating,â€ University of Texas, Austin, mimeo.
Yildiz, Muhamet (2003): â€œBargaining without a Common Prior â€” An Immediate Agreement
Theorem,â€ Econometrica, 71 (3), 793-811.
Yildiz, Muhamet (2004): â€œWaiting to Persuade,â€ Quarterly Journal of Economics, 119 (1),
223-249.

51

