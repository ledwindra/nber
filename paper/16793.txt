                                NBER WORKING PAPER SERIES




HIGHER ORDER PROPERTIES OF THE WILD BOOTSTRAP UNDER MISSPECIFICATION

                                           Patrick M. Kline
                                            Andres Santos

                                        Working Paper 16793
                                http://www.nber.org/papers/w16793


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     February 2011




The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

Â© 2011 by Patrick M. Kline and Andres Santos. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including Â© notice,
is given to the source.
Higher Order Properties of the Wild Bootstrap Under Misspecification
Patrick M. Kline and Andres Santos
NBER Working Paper No. 16793
February 2011
JEL No. C12

                                               ABSTRACT

We examine the higher order properties of the wild bootstrap (Wu, 1986) in a linear regression model
with stochastic regressors. We find that the ability of the wild bootstrap to provide a higher order refinement
is contingent upon whether the errors are mean independent of the regressors or merely uncorrelated.
In the latter case, the wild bootstrap may fail to match some of the terms in an Edgeworth expansion
of the full sample test statistic, potentially leading to only a partial refinement (Liu and Singh, 1987).
To assess the practical implications of this result, we conduct a Monte Carlo study contrasting the
performance of the wild bootstrap with the traditional nonparametric bootstrap.


Patrick M. Kline
Department of Economics
UC, Berkeley
508-1 Evans Hall #3880
Berkeley, CA 94720
and NBER
pkline@econ.berkeley.edu

Andres Santos
Department of Economics
8&6DQ'LHJR
9500 Gilman Drive
La Jolla, CA 92093-0508
a2santos@ucsd.edu
1     Introduction

The wild bootstrap of Wu (1986) and Liu (1988) provides a procedure for conducting inference in
the model:
                                           Y = X 0 Î²0 +  ,                                       (1)

where Y âˆˆ R, X âˆˆ Rdx and  may have a heteroskedastic structure of unknown form. This
robustness to arbitrary heteroscedasticity provides a distinct advantage over the residual bootstrap
of Freedman (1981) while retaining some of its computational and statistical advantages. This has
led to increasing attention among economists who are often concerned with robust inference in small
sample environments (Horowitz (1997, 2001), Cameron et al. (2008), Davidson and Flachaire (2008))
and to a variety of recent extensions beyond the basic linear regression model (Cavaliere and Taylor
(2008), GoncÌ§alves and Meddahi (2009), Davidson and MacKinnon (2010)). To date, however, the
higher order properties of the wild bootstrap have only been studied under the assumption that
the errors are mean independent of the regressors. Liu (1988) established that when this condition
holds the wild bootstrap provides a refinement over a normal approximation.

    In this paper we contribute to the literature by analyzing the higher order properties of the wild
bootstrap in instances where the conditional mean function may be misspecified. Concretely, we
examine the ability of the wild bootstrap to provide a refinement over the normal approximation
when  is uncorrelated with X but not necessarily mean independent of it â€“ a setting pervasive in
economics where regressors are stochastic rather than fixed or chosen by the econometrician. It is
precisely in such environments that heteroskedasticity is likely to arise (White (1982)) making the
higher order properties of the wild bootstrap of particular interest.

    We conduct our analysis in two steps. First, we compute the approximate cumulants (Bhat-
tacharya and Ghosh (1978)) of t-statistics under both the full sample and bootstrap distributions
with general assumptions on the wild bootstrap weights. We show that both the first and third
                                                         1
approximate cumulants may disagree up to order Op (nâˆ’ 2 ) if higher powers of X are correlated with
; a situation that is ruled out under proper specification. This higher order discordance between
the approximate cumulants under the full sample and bootstrap distribution implies that if valid
                                                                               1
Edgeworth expansions exist they would only be equivalent up to order Op (nâˆ’ 2 ) (Hall (1992)). As a
result, despite remaining consistent under misspecification, the wild bootstrap may fail to provide
a higher order refinement over a normal approximation.

    We complement this result by formally establishing the existence of valid one term Edgeworth ex-


                                                  2
pansions when the distribution of the wild bootstrap weights is additionally assumed to be strongly
nonlattice (Bhattacharya and Rao (1976)). In accord with Liu (1988) we note that one-sided wild
bootstrap tests obtain a refinement to order Op (nâˆ’1 ) under proper specification. However, this
result is undermined by certain forms of misspecification under which only some, but not all, of
the second order terms in the full sample Edgeworth expansion are matched by their bootstrap
counterparts. Consequently, the wild bootstrap may provide only a partial refinement over the
normal approximation (Liu and Singh (1987)). To assess the practical implications of this result,
we conclude by conducting a Monte Carlo study contrasting the performance of the wild bootstrap
with the traditional nonparametric bootstrap in the presence of misspecification.

    The rest of the paper is organized as follows. Section 2 contains our theoretical results while
Section 3 examines the implications of our analysis in a simulation study. We briefly conclude in
Section 4 and relegate all proofs to the Appendix.



2     Theoretical Results

While numerous variants of the wild bootstrap exist, we study the original version proposed by Wu
(1986) and Liu (1988). Succinctly, given a sample {Yi , Xi }ni=1 and Î²Ì‚ the OLS estimator from such
sample, the wild bootstrap generates new errors and dependant variables:

                           Yiâˆ— â‰¡ Xi0 Î²Ì‚ + âˆ—i             âˆ—i â‰¡ (Yi âˆ’ Xi0 Î²Ì‚)Wi ,                      (2)

where {Wi }ni=1 is an i.i.d. sample independent of the original data {Yi , Xi }ni=1 . A bootstrap estimator
                                                                                     âˆš
Î²Ì‚ âˆ— can then be computed from the sample {Yiâˆ— , Xi }ni=1 and the distribution of n(Î²Ì‚ âˆ— âˆ’ Î²Ì‚) conditional
                                                                    âˆš
on {Yi , Xi }ni=1 (but not {Wi }ni=1 ) used to approximate that of n(Î²Ì‚ âˆ’ Î²0 ). While it may not be
possible to compute the bootstrap distribution analytically, it is straightforward to simulate it.

    We focus our analysis on inference on linear contrasts of Î²0 , which includes both individual
coefficients and predicted values as special cases. In particular, for an arbitrary c âˆˆ Rdx we examine:
                            âˆš
                               n 0
                      Tn â‰¡      c (Î²Ì‚ âˆ’ Î²0 )             ÏƒÌ‚ 2 â‰¡ c0 Hnâˆ’1 Î£n (Î²Ì‚)Hnâˆ’1 c ,             (3)
                             ÏƒÌ‚
where the dx Ã— dx matrices Hn and Î£n (Î²) are defined by:
                            n                                     n
                       1X                                    1X
                  Hn â‰¡       Xi Xi0                 Î£n (Î²) â‰¡       Xi Xi0 (Yi âˆ’ Xi0 Î²)2 .              (4)
                       n i=1                                 n i=1
The bootstrap statistic Tnâˆ— is then the analogue to Tn but computed on {Yiâˆ— , Xi }ni=1 instead. Namely,
                              âˆš
                                  n
                       Tn â‰¡ âˆ— c0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚)
                         âˆ—
                                                   (ÏƒÌ‚ âˆ— )2 â‰¡ c0 Hnâˆ’1 Î£âˆ—n (Î²Ì‚ âˆ— )Hnâˆ’1 c ,          (5)
                               ÏƒÌ‚
                                                    3
where Hn is as in (4), and Î£âˆ—n (Î²) â‰¡       1
                                                    Xi Xi0 (Yiâˆ— âˆ’ Xi0 Î²)2 .
                                               P
                                           n    i


       As argued in Mammen (1993), under mild assumptions on the wild bootstrap weights {Wi }ni=1 ,
the distribution of Tnâˆ— conditional on {Yi , Xi }ni=1 , (but not {Wi }ni=1 ) provides a consistent estimator
for the distribution of Tn . Consequently, tests based upon a comparison of the statistic Tn to the
quantiles of the bootstrap distribution of Tnâˆ— are asymptotically justified. In what follows, we explore
whether such a procedure provides a refinement over employing the quantiles of a standard normal
distribution instead.



2.1        Assumptions

We explore the higher order properties of the wild bootstrap under the following assumptions:

Assumption 2.1. (i) {Yi , Xi }ni=1 is an i.i.d. sample, satisfying (1) with E[X] = 0; (ii) (Y, X)
are bounded almost surely; (iii) E[XX 0 ] = I and Î£0 â‰¡ E[XX 0 2 ] is full rank; (iv) For Z â‰¡
(X 0 , vech(XX 0 )0 , vech(XX 0 2 )0 )0 , and Î¾Z its characteristic function, lim supktkâ†’âˆž |Î¾Z (t)| < 1.1

Assumption 2.2. (i) {Wi }ni=1 is i.i.d., independent of {Yi , Xi }ni=1 with E[W ] = 0, E[W 2 ] = 1 and
E[W Ï‰ ] < âˆž, Ï‰ â‰¥ 9; (ii) For U â‰¡ (W, W 2 )0 , Î¾U its characteristic function, lim sup|t|â†’âˆž |Î¾U (t)| < 1.


       Assumption 2.1(i) allows for misspecification of the conditional mean function by requiring
E[X] = 0 rather than E[|X] = 0. In Assumption 2.1(ii) we impose that (Y, X) be bounded.
This specialized (yet widely applicable) setting simplifies the arguments employed in obtaining an
Edgeworth expansion for Tnâˆ— . Our finding that the wild bootstrap may fail to provide a higher order
refinement under misspecification would not be overturned if Assumption 2.1(ii) were weakened to
less stringent moment conditions. Assumption 2.1(ii) additionally imposes that E[XX 0 ] = I, which
is just a normalization in the present context; see Remark 2.1. The requirements on {Wi }ni=1 in
Assumption 2.2(i) are standard in the wild bootstrap literature and satisfied by all commonly used
choices of wild bootstrap weights.

       Assumptions 2.1(i)-(iii) and 2.2(i) suffice for showing that the approximate cumulants of Tn and
                                                                                    1
of Tnâˆ— under the bootstrap distribution may disagree up to order Op (nâˆ’ 2 ) under misspecification.
In order to additionally establish the existence of Edgeworth expansions, however, we also impose
Assumptions 2.1(iv) and 2.2(ii). These requirements, also known as Cramerâ€™s condition, are stan-
dard in the Edgeworth expansion literature (Bhattacharya and Rao (1976)). They are satisfied,
   1
       For a symmetric matrix A, vech(A) denotes a column vector composed of its unique elements.


                                                             4
for example, if the distributions of Z and U have a component that is absolutely continuous with
respect to Lebesgue measure. Unfortunately, this requirement rules out two frequently used wild
bootstrap weights: Rademacher random variables and the weighting scheme advocated in Mammen
(1993). Thus, while our results on approximate cumulants are applicable to these choices of weights,
our results on Edgeworth expansions are not.

Remark 2.1. Since we study Tn for generic vectors c âˆˆ Rdx , Assumption 2.1(iii) is just a convenient
normalization. Specifically, suppose E[XX 0 ] = Î£X for Î£X full rank. We may then rewrite (1) as:

                                                                          âˆ’1                             1
                               Y = XÌƒ 0 Î²I,0 +                 XÌƒ = Î£X 2 X                 Î²I,0 = Î£X2 Î²0 .                           (6)

It is then immediate that E[XÌƒ XÌƒ 0 ] = I. Moreover, since                                XÌƒi XÌƒi0 is invertible if and only if Hn is,
                                                                                  P
                                                                                      i

we obtain that for any cÌƒ âˆˆ Rdx and Î²Ì‚I the OLS estimator on {Yi , XÌƒi }ni=1 :
                                                  n            n
                     âˆš 0                âˆš 0 12 X             1 X
                                                        0 âˆ’1 2    âˆ’1         âˆš
                      ncÌƒ (Î²Ì‚I âˆ’ Î²Ìƒ0 ) = ncÌƒ Î£X (   Xi Xi ) Î£X   Î£X 2 Xi i = nc0 (Î²Ì‚ âˆ’ Î²0 ) ,                                        (7)
                                                       i=1                      i=1

                 1                                                                                                                    1
where c = Î£X2 cÌƒ. Similarly, cÌƒ0 ( n1                    âˆ’1 1               0         0      2 1                0 âˆ’1       2
                                         P                      P                                   P
                                             i XÌƒi XÌƒi )            i XÌƒi XÌƒi (Yi âˆ’ XÌƒi Î²Ì‚I ) ( n       i XÌƒi XÌƒi ) cÌƒ = ÏƒÌ‚ for c = Î£X cÌƒ.
                                                                                                                                     2
                                                            n

Hence, since the choice of c âˆˆ Rdx is arbitrary, studying Tn for some c under Assumption 2.1(iii) is
                                                                                                                        âˆ’1
equivalent to studying it under the assumption that E[XX 0 ] be full rank and cÌƒ = Î£X 2 c.

Remark 2.2. Assumption 2.1(iv) precludes X from containing a constant term. To accommodate
this common case, if the constant is the first element of the vector X, then Assumption 2.1(iv)
should hold for Z â‰¡ (X 0 , vechâˆ’1 (XX 0 )0 , vech(XX 0 2 )0 )0 where for a vector v = (v (1) , . . . , v (d) ) we
define vâˆ’1 â‰¡ (v (2) , . . . , v (d) ).



2.2       Approximate Cumulants

In what follows, for notational simplicity, we denote expectations, probability and law statements
conditional on {Yi , Xi }ni=1 (but not {Wi }ni=1 ) by E âˆ— , P âˆ— and Lâˆ— respectively. Additionally, we define
the following parameters which play a fundamental role in our higher order analysis:

      Ïƒ 2 â‰¡ c0 Î£ 0 c         Îº â‰¡ E[(c0 X)3 3 ]                 Î³0 â‰¡ E[(c0 X)2 X]                  Î³1 â‰¡ E[(c0 X)(X 0 X)] .          (8)

Finally, we let Î¦ denote the distribution of a standard normal random variable and Ï† its density.

    We begin our analysis by obtaining an asymptotic expansion for Tn and Tnâˆ— .




                                                                      5
Theorem 2.1. Suppose Assumption 2.1(i)-(iii) and 2.2(i) hold, and for c âˆˆ Rdx define:
                                        n                 n                              n
                   0            1 X                  1 X 0                  2    2    2X 0
           Ln â‰¡ c {I + âˆ†n } âˆš              Xi i âˆ’ 3 âˆš        (c Xi )i {(ÏƒÌ‚R âˆ’ Ïƒ ) âˆ’      Î³ Xi i }           (9)
                                 nÏƒ i=1            2Ïƒ n i=1                           n i=1 0
                          1 X             1      1
           Lâˆ—n â‰¡ c0 Hnâˆ’1 âˆš        Xi âˆ—i { âˆ’ 3 ((ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 )}                                            (10)
                           n i=1          ÏƒÌ‚ 2ÏƒÌ‚

where âˆ†n â‰¡ I âˆ’ Hn , ÏƒÌ‚R2 â‰¡ c0 Î£n (Î²0 )c + 2c0 âˆ†n Î£0 c and (ÏƒÌ‚sâˆ— )2 â‰¡ c0 Hnâˆ’1 Î£âˆ—n (Î²Ì‚)Hnâˆ’1 c. It then follows that:
                                               1                                1
                           Tn = Ln + op (nâˆ’ 2 )          Tnâˆ— = Lâˆ—n + opâˆ— (nâˆ’ 2 ) a.s.


   Recall that in Assumption 2.1(ii) the covariance E[XX 0 ] was normalized to equal the identity
matrix. Therefore âˆ†n â‰¡ I âˆ’ Hn is the estimation error in the Hessian and the first term in (9)
captures the contribution to Tn of not knowing the true value of E[XX 0 ]. Similarly, the contribution
of having to estimate the variance is divided into two parts: (i) n2 i Î³00 Xi i which reflects use of Î²Ì‚
                                                                    P

rather than Î²0 in the sample variance calculations and (ii) ÏƒÌ‚R2 âˆ’ Ïƒ 2 which captures the randomness
that would be present in estimating Ïƒ 2 if Î²0 were known. Interestingly, these terms are smaller
order under the bootstrap distribution due to the mean independence of âˆ— and X.

   Due to their polynomial form, the moments of Ln and Lâˆ—n are considerably easier to compute
than those of Tn and Tnâˆ— . However, the cumulants of Ln and Lâˆ—n provide only an approximation
to those of Tn and Tnâˆ— and were for this reason termed â€œapproximate cumulantsâ€ by Bhattacharya
and Ghosh (1978). Despite their approximate nature, the cumulants of Ln and Lâˆ—n play a crucial
role as they may be employed in place of the cumulants of Tn and Tnâˆ— when computing their second
order Edgeworth expansions if such expansions are indeed valid. Thus, a discordance between the
approximate cumulants is indicative of an analogous difference in the corresponding Edgeworth
expansions if such expansions do exist.

   Theorem 2.2 shows the approximate cumulants may disagree under misspecification.

Theorem 2.2. Let Xk (Ln ) and Xkâˆ— (Lâˆ—n ) denote the k th cumulants of Ln and Lâˆ—n respectively and
define ÎºÌ‚ â‰¡ n1 i (c0 Hnâˆ’1 Xi )3 (Yi âˆ’ Xi0 Î²Ì‚)3 . If Assumptions 2.1(i)-(iii) and 2.2(i) hold, then:
              P

                           Îº    Î³1   2c0 Î£0 Î³0                                  E[W 3 ]ÎºÌ‚
         X1 (Ln ) = âˆ’       âˆš âˆ’ âˆš  +     âˆš                     X1âˆ— (Lâˆ—n ) = âˆ’        âˆš
                        2Ïƒ 3 n Ïƒ n    Ïƒ3 n                                      2ÏƒÌ‚ 3 n
         X2 (Ln ) = 1 + O(nâˆ’1 )                                X2âˆ— (Lâˆ—n ) = 1 + Oa.s. (nâˆ’1 )
                         2Îº    6c0 Î£0 Î³0                                        2E[W 3 ]ÎºÌ‚
         X3 (Ln ) = âˆ’     âˆš  +     âˆš + O(nâˆ’1 )                 X3âˆ— (Lâˆ—n ) = âˆ’        âˆš     + Oa.s. (nâˆ’1 ) .
                        Ïƒ3 n    Ïƒ3 n                                             ÏƒÌ‚ 3 n

   Observe first that unless Îº = 0, the wild bootstrap fails to correct the first term in the first and
third cumulants if E[W 3 ] 6= 1. This property has already been noted in Liu (1988) who advocates

                                                        6
imposing E[W 3 ] = 1 for precisely this reason. However, even with this restriction, two additional
terms in the first and third cumulants of Ln remain. These terms capture (i) the correlation between
Hn and n1 i Xi i , and (ii) the additional randomness of employing Î²Ì‚ rather than Î²0 in estimating
          P

Ïƒ 2 . Both these expressions are of smaller order under mean independence but may be present
otherwise. Because the wild bootstrap imposes mean independence in the bootstrap distribution
it fails to mimic these terms. As a result, a discordance between the full sample and bootstrap
approximate cumulants will arise under misspecification if the error term  is correlated with higher
powers of X so that Î³0 or Î³1 are nonzero.



2.3    Edgeworth Expansions

Under the additional requirement that the Cramer conditions hold (Assumptions 2.1(iv) and 2.2(ii))
we now establish that the discordance in approximate cumulants indeed translates into an analogous
disagreement between Edgeworth expansions.

Theorem 2.3. Under Assumptions 2.1(i)-(iv) and 2.2(i)-(ii) it follows that uniformly in z:
                                 Ï†(z)Îº              Ï†(z)                                      1
          P (Tn â‰¤ z) = Î¦(z) +      3
                                     âˆš (2z 2 + 1) âˆ’ 3 âˆš (c0 Î£0 Î³0 (z 2 + 1) âˆ’ Î³1 Ïƒ 2 ) + o(nâˆ’ 2 )   (11)
                                6Ïƒ n               Ïƒ n
                                           3
                                Ï†(z)ÎºÌ‚E[W ] 2                1
         P âˆ— (Tnâˆ— â‰¤ z) = Î¦(z) +       3
                                        âˆš    (2z + 1) + o(nâˆ’ 2 )      a.s.                          (12)
                                   6ÏƒÌ‚ n

    As Theorem 2.3 shows, the wild bootstrap provides the usual skewness correction whenever
E[W 3 ] = 1. However, when the conditional mean function is misspecified, imposing mean inde-
pendence in the wild bootstrap sample implies the bootstrap distribution may fail to match all the
second order terms in the expansion for Tn . In particular, if  is correlated with higher moments of
X, so that Î³0 and Î³1 are not equal to zero, the wild bootstrap will only provide a partial refinement
over a normal approximation. The importance of such a refinement is dependent on the degree of
misspecification as measured by the magnitude of Î³0 and Î³1 . In particular, if the misspecification is
                         1
local with Î³0 , Î³1 = O(nâˆ’ 2 ), then the wild bootstrap does attain the usual higher order refinement.



3     Monte Carlo

We turn now to a study of the effect of misspecification on the finite sample performance of the wild
bootstrap through a series of Monte Carlo sampling experiments. To ensure that our theoretical
results are relevant, we restrict our attention to cases where: (i) X is continuously distributed

                                                    7
           Table 1: Rejection rates for 0.05 nominal size - One sided tests


                               Sample Size n = 10. Alternative Hypothesis H1 : Î² < 0
                 Noise Level Î» = 0.25           Noise Level Î» = 0.5             Noise Level Î» = 1
               Analytical Wild Pairs         Analytical Wild Pairs         Analytical Wild Pairs
    Ïˆ = âˆ’0.2     0.100    0.054 0.073          0.102     0.061 0.077          0.096     0.071 0.073
    Ïˆ = 0.0      0.094    0.076 0.078          0.094     0.076 0.078          0.094     0.076 0.078
    Ïˆ = 0.2      0.221    0.186 0.163          0.153     0.130 0.120          0.114     0.092 0.095

                               Sample Size n = 10. Alternative Hypothesis H1 : Î² > 0
                 Noise Level Î» = 0.25           Noise Level Î» = 0.5             Noise Level Î» = 1
               Analytical Wild Pairs         Analytical Wild Pairs         Analytical Wild Pairs
    Ïˆ = âˆ’0.2     0.207    0.136 0.115          0.149     0.104 0.082          0.112     0.079 0.061
    Ïˆ = 0.0      0.078    0.052 0.039          0.078     0.052 0.039          0.078     0.052 0.039
    Ïˆ = 0.2      0.094    0.047 0.049          0.083     0.055 0.047          0.078     0.050 0.046

                               Sample Size n = 20. Alternative Hypothesis H1 : Î² < 0
                 Noise Level Î» = 0.25           Noise Level Î» = 0.5             Noise Level Î» = 1
               Analytical Wild Pairs         Analytical Wild Pairs         Analytical Wild Pairs
    Ïˆ = âˆ’0.2     0.077    0.053 0.060          0.076     0.059 0.060          0.075     0.069 0.087
    Ïˆ = 0.0      0.068    0.072 0.095          0.068     0.072 0.095          0.068     0.072 0.095
    Ïˆ = 0.2      0.175    0.155 0.145          0.127     0.109 0.127          0.090     0.078 0.110

                               Sample Size n = 20. Alternative Hypothesis H1 : Î² > 0
                 Noise Level Î» = 0.25           Noise Level Î» = 0.5             Noise Level Î» = 1
               Analytical Wild Pairs         Analytical Wild Pairs         Analytical Wild Pairs
    Ïˆ = âˆ’0.2     0.148    0.107 0.093          0.101     0.081 0.081          0.070     0.057 0.054
    Ïˆ = 0.0      0.048    0.035 0.049          0.048     0.035 0.049          0.048     0.035 0.049
    Ïˆ = 0.2      0.070    0.044 0.042          0.052     0.043 0.047          0.049     0.039 0.043




and bounded, (ii)  is continuously distributed and bounded and (iii) the bootstrap weights W are
continuously distributed with E[W ] = 0, E[W 2 ] = 1, and E[W 3 ] = 1.

   Let Z âˆ¼ T N (Âµ, Ïƒ 2 , Ï„ ) denote a normal random variable with mean Âµ and variance Ïƒ 2 , truncated
to lie in the interval [âˆ’Ï„, Ï„ ]. The regressor X was drawn from a mixture of Z1 âˆ¼ T N (0, 1, 2) with
probability 0.1 and from Z2 âˆ¼ T N (1, 4, 4) with probability 0.9, recentered and scaled to have mean
zero and variance one. We generate the variable Y according to the relationship:

                                 Yi = Ïˆ{Xi2 âˆ’ E[X 3 ]Xi âˆ’ 1} + Î»Î· ,                                   (13)

where Î· is the exponential of a T N (0, 1, 2) random variable, recentered to have mean zero, and Ïˆ, Î»
are scalar parameters that will be changed across different Monte Carlo specifications.

   We examine the ability of the wild bootstrap to control size when conducting inference on the

                                                   8
              Table 2: Rejection rates for 0.05 nominal size - Two sided tests


                                  Sample Size n = 10. Alternative Hypothesis H1 : Î² 6= 0
                    Noise Level Î» = 0.25           Noise Level Î» = 0.5             Noise Level Î» = 1
                  Analytical Wild Pairs         Analytical Wild Pairs         Analytical Wild Pairs
       Ïˆ = âˆ’0.2     0.242    0.145 0.070          0.181     0.121 0.052          0.136     0.097 0.039
       Ïˆ = 0.0      0.109    0.087 0.033          0.109     0.087 0.033          0.109     0.087 0.033
       Ïˆ = 0.2      0.244    0.167 0.062          0.174     0.130 0.051          0.131     0.106 0.042

                                  Sample Size n = 20. Alternative Hypothesis H1 : Î² 6= 0
                    Noise Level Î» = 0.25           Noise Level Î» = 0.5             Noise Level Î» = 1
                  Analytical Wild Pairs         Analytical Wild Pairs         Analytical Wild Pairs
       Ïˆ = âˆ’0.2     0.156    0.110 0.068          0.120     0.094 0.051          0.095     0.071 0.032
       Ïˆ = 0.0      0.066    0.060 0.028          0.066     0.060 0.028          0.066     0.060 0.028
       Ïˆ = 0.2      0.176    0.139 0.074          0.109     0.099 0.048          0.079     0.072 0.035




slope coefficient in the following linear regression model:

                                              Yi = Î± + Xi Î² +  .                                                     (14)

By construction, the unique parameters (Î±, Î²) ensuring that E[X] = 0 in (14) are (Î±, Î²) = 0. The
parameter Ïˆ in (13) therefore governs the extent of misspecification in the regression model, with
Ïˆ = 0 corresponding to proper specification (E[Y |X] = 0). Similarly, the scale parameter Î» in (13)
controls the level of noise in the linear regression.

      Table 1 shows the empirical rejection rates of one-sided tests under different values of the pa-
rameters governing misspecification and residual noise. Code for our Monte Carlo experiments
is available online. All rejection rates were computed using 200 bootstrap repetitions and 1,000
Monte Carlo replications. We implement the wild bootstrap drawing the weights W from a recen-
tered Gamma distribution with shape parameter 4 and scale parameter 1/2 as suggested by Liu
(1988). For comparison with the wild bootstrap, we also examine the ability of the nonparametric
                                                                       2
(â€œpairsâ€) bootstrap and analytical t-tests to control size.

      The results suggest both the wild and nonparametric bootstraps yield improvements over an
analytical t-test for one sided alternaitves. The relative performance of the two bootstraps under
misspecification (Ïˆ 6= 0) is dependent on the level of misspecification, the direction of the test
and the level of noise. Table 2 provides false rejection rates for two-sided tests. Here the ranking
of the various techniques is more clear cut with the nonparametric bootstrap performing best
                                                                 âˆš
  2
      The nonparametric bootstrap computes the distribution of       nc0 (Î²Ì‚ âˆ’ Î²0 )/ÏƒÌ‚ under the empirical measure.


                                                        9
under misspecification and the normal approximation worst. Notably, the improvement of the wild
bootstrap over the first order analytical approximation is still substantial, illustrating the practical
importance of our theoretical finding of a partial refinement.



4    Conclusion

We find that the wild bootstrap may provide only a partial refinement over a normal approximation
when the conditional mean function is misspecified. This suggests that while the wild bootstrap
may not work as well as the nonparametric bootstrap in many settings where regression is used,
it will likely still generate an improvement over analytical techniques. Our Monte Carlo study, for
example, found that the wild bootstrap performed nearly as well as the nonparametric bootstrap
in one-sided tests and still provided substantial improvements over normal approximations in two-
sided tests. We conclude that in small sample environments where misspecification is of concern,
the nonparametric bootstrap possesses a modest advantage over the wild bootstrap.




                                                  10
                                            APPENDIX A - Proofs of Theorems 2.1 and 2.2

    The following is a table of the notation and definitions that will be used throughout the appendix.

         k Â· kF          On a matrix A, kAkF denotes the Frobenius norm.
         k Â· ko          On a matrix A, kAko denotes the usual operator norm.
                         For a vector Î» of positive integers and Î»(i) its ith coordinate |Î»| = i Î»(i) .
                                                                                              P
           |Î»|
                                                                                 âˆ‚ |Î»| f
            DÎ» f         For f : Rd â†’ R and Î» âˆˆ R, DÎ» f =                       (1)      (d)   .
                                                                           âˆ‚Î»      ...âˆ‚ Î»
             ei          The OLS residual ei = (Yi âˆ’ Xi Î²Ì‚).
             Î¦           The distribution of a standard normal random variable in Rd (d may be context specific).


Lemma A.1. Let {Zi }ni=1 be an i.i.d. sample of Z a k Ã— p random matrix with kZkF bounded a.s.. Then:
                                                               n
                                                         1 X                                  1
                                                   P (k âˆš       {Zi âˆ’ E[Zi ]}kF > Mn ) = o(nâˆ’ 2 ) ,
                                                          n i=1

for any sequence Mn â†‘ âˆž such that log(n) = o(Mn ).


Proof: Let Z (l,j) denote the (l, j) entry of Z. To establish the claim of the Lemma, then note that:
              n                                                                       n
        1 X                                              kp X (l,j)      (l,j)
  P (k âˆš       {Zi âˆ’ E[Zi ]}kF > Mn ) â‰¤ P (    max      |âˆš      {Z  âˆ’ E[Zi ]}| > Mn )
         n i=1                              1â‰¤lâ‰¤k,1â‰¤jâ‰¤p    n i=1 i
                                                                                             p
                                                                                           k X                n
                                                                                           X                kp X (l,j)       (l,j)
                                                                                       â‰¤               P (| âˆš       {Zi âˆ’ E[Zi ]}| > Mn ) . (15)
                                                                                                   j=1
                                                                                                              n i=1
                                                                                           l=1

        (l,j)              (l,j)
Since |Zi         âˆ’ E[Zi           ]| â‰¤ K a.s. for some K > 0 and 1 â‰¤ l â‰¤ k, 1 â‰¤ j â‰¤ p, Bernsteinâ€™s inequality implies:
                                                       n
                                                 kp X (l,j)       (l,j)                   Mn
                                            P (| âˆš       {Zi âˆ’ E[Zi ]}| > Mn ) â‰¤ 2 exp{âˆ’      },                                              (16)
                                                   n i=1                                 2kpK

since Mn â†‘ âˆž. Results (15), (16) and log(n) = o(Mn ) then establish the Lemma.

                               2
Lemma A.2. Let âˆ†n â‰¡ I âˆ’ Hn , ÏƒÌ‚R â‰¡ c0 Î£n (Î²0 )c + 2c0 âˆ†n Î£0 c and Assumptions 2.1(i)-(iii) hold. Then:

                                                       1
  (i) P (k âˆš1n           Xi i k > Mn ) = o(nâˆ’ 2 ) for any sequence Mn â†‘ âˆž with log(n) = o(Mn ).
                   P
                     i
                          Pk                                       1
  (ii) P (kHnâˆ’1 âˆ’            j=0    âˆ†jn ko > nâˆ’Î± ) = o(nâˆ’ 2 ) for any Î± âˆˆ [0, k+1
                                                                               2 ).
                                                   1
 (iii) P (kÎ²Ì‚ âˆ’ Î²0 k > nâˆ’Î± ) = o(nâˆ’ 2 ) for any Î± âˆˆ [0, 21 ).
                                                                       1
 (iv) P (|ÏƒÌ‚ 2 âˆ’ ÏƒÌ‚R
                   2          2
                                         Î³00 Xi i | > nâˆ’Î± ) = o(nâˆ’ 2 ) for any Î± âˆˆ [0, 21 ).
                                   P
                     +        n      i



Proof: Since kXk is bounded a.s. by Assumption 2.1(ii), the first claim follows by Lemma A.1. For the second
claim, notice Lemma A.1 implies that for any Mn â†‘ âˆž such that log(n) = o(Mn ) we must have:
                                                       Mn          1
                                           P (kâˆ†n kF â‰¥ âˆš ) = o(nâˆ’ 2 ) .                                                                       (17)
                                                        n
                                                 Pâˆž
Moreover, notice that if kâˆ†n kF < 1, then Hnâˆ’1 = j=0 âˆ†jn . Hence, we obtain:

                   k
                   X                                    X
  P (kHnâˆ’1 âˆ’             âˆ†jn ko > nâˆ’Î± ) â‰¤ P (k                 âˆ†jn ko > nâˆ’Î± and kâˆ†n kF < 1) + P (kâˆ†n kF â‰¥ 1)
                   j=0                                 jâ‰¥k+1
                                           X                                                           1      Î¾ k+1 (âˆ†n )                1
                                   â‰¤ P(           Î¾(âˆ†jn ) > nâˆ’Î± and kâˆ†n kF < 1) + o(nâˆ’ 2 ) â‰¤ P (                          > nâˆ’Î± ) + o(nâˆ’ 2 ) , (18)
                                                                                                              1 âˆ’ Î¾(âˆ†n )
                                          jâ‰¥k+1



                                                                                 11
where Î¾(âˆ†jn ) is the largest eigenvalue of âˆ†jn and we have exploited kâˆ†jn ko = Î¾(âˆ†jn ) and Î¾(âˆ†jn ) = Î¾ j (âˆ†n ). for the
second and third inequalities. Moreover, since Î¾(âˆ†n ) = kâˆ†n ko â‰¤ kâˆ†n kF , result (17) implies that P (|Î¾(âˆ†n )| â‰¥ 1/2) =
     1
o(nâˆ’ 2 ). Therefore, from (18) we are able to conclude that:
                      k
                                                                                      1                                              1
                      X
         P (kHnâˆ’1 âˆ’         âˆ†jn ko > nâˆ’Î± ) â‰¤ P (2Î¾ k+1 (âˆ†n ) > nâˆ’Î± ) + o(nâˆ’ 2 ) â‰¤ P (2kâˆ†n kk+1
                                                                                           F   > nâˆ’Î± ) + o(nâˆ’ 2 ) .                              (19)
                      j=0

                                                      1   Î±                                                   Î±              1
To conclude, exploit (19) and set Mn = n 2 âˆ’ k+1 in (17) to obtain P (2kâˆ†n kF > nâˆ’ k+1 ) = o(nâˆ’ 2 ).

    Next, note that Corollary III.2.6 in Bhatia (1997) implies |Î¾(Hnâˆ’1 ) âˆ’ 1| = |Î¾(Hnâˆ’1 ) âˆ’ Î¾(I)| â‰¤ kHnâˆ’1 âˆ’ IkF . By
                                                                             1
part (ii) of the Lemma, it follows that P (kHnâˆ’1 ko > 2) = o(nâˆ’ 2 ). Hence, we obtain:

  P (kÎ²Ì‚ âˆ’ Î²0 k > nâˆ’Î± )
                                          n                                                            n                 1
                                     2X                                               1 X              n 2 âˆ’Î±          1
                            â‰¤ P (k         Xi i k > nâˆ’Î± ) + P (kHnâˆ’1 ko > 2) = P (k âˆš       Xi i k >        ) + o(nâˆ’ 2 ) . (20)
                                     n i=1                                             n i=1              2

The third claim of the Lemma is then established by (20), part (i) and Î± < 1/2.

    In order to establish the final claim of the Lemma, first observe that by direct calculation we obtain:
                                                          n
                                       Î±              1X                                                           Î±          1
    P (kÎ£n (Î²Ì‚) âˆ’ Î£n (Î²0 )kF > nâˆ’ 2 ) = P (k                Xi Xi0 {(Xi0 (Î²Ì‚ âˆ’ Î²0 ))2 âˆ’ 2i Xi0 (Î²Ì‚ âˆ’ Î²0 )}kF > nâˆ’ 2 ) = o(nâˆ’ 2 )                (21)
                                                      n i=1

where the final result is implied by part (iii), (X, ) bounded a.s. by Assumption 2.1(ii) and Î± < 1. Similarly, by
Lemma A.1, for any sequence Mn â†‘ âˆž such that log(n) = o(Mn ) we also have:
                                                                         Mn         1
                                                  P (kÎ£n (Î²0 ) âˆ’ Î£0 kF > âˆš ) = o(nâˆ’ 2 ) .                                                        (22)
                                                                          n
                                                                                                                                 Î±           1
Let K > 0 be such that kÎ£0 ko < K and note that since (21)-(22) imply P (kÎ£n (Î²Ì‚) âˆ’ Î£0 ko > nâˆ’ 2 ) = o(nâˆ’ 2 ), it
                                                  1
follows that P (kÎ£n (Î²Ì‚)ko > K) = o(nâˆ’ 2 ). Hence, we conclude from part (ii) of the Lemma that:

  P (|c0 (Hnâˆ’1 âˆ’ I)Î£n (Î²Ì‚)(Hnâˆ’1 âˆ’ I)c| > nâˆ’Î± )
                                                                                                                                         1
                                                          â‰¤ P (Kkck2 kHnâˆ’1 âˆ’ Ik2o > nâˆ’Î± ) + P (kÎ£n (Î²Ì‚)ko > K) = o(nâˆ’ 2 ) . (23)
                                                                         1
Similarly, exploiting again that P (kÎ£n (Î²Ì‚)ko > K) = o(nâˆ’ 2 ) and part (ii) of the Lemma we also obtain:
                                                                                                   1
                                          P (|c0 (Hnâˆ’1 âˆ’ I âˆ’ âˆ†n )Î£n (Î²Ì‚)c| > nâˆ’Î± ) = o(nâˆ’ 2 ) .                                                  (24)

Moreover, since Î± < 1, exploiting (17), (21) and (22) we also conclude:

  P (|c0 âˆ†n (Î£n (Î²Ì‚) âˆ’ Î£0 )c| > nâˆ’Î± ) â‰¤ P (kck2 kâˆ†n ko kÎ£n (Î²Ì‚) âˆ’ Î£0 ko > nâˆ’Î± )
                                                                              Î±                                              Î±           1
                                                      â‰¤ P (kckkâˆ†n kF > nâˆ’ 2 ) + P (kckkÎ£n (Î²Ì‚) âˆ’ Î£0 kF > nâˆ’ 2 ) = o(nâˆ’ 2 ) . (25)

                                                                                                       M             1
                                                                            0
Since (X, ) is bounded, Lemma A.1 implies that P (k n1                          2
                                                                                                              = o(nâˆ’ 2 ) for any Mn â†‘ âˆž with
                                                                     P
                                                                        i (c Xi ) i Xi   âˆ’ Î³0 k >     âˆšn )
                                                                                                        n

log(n) = o(Mn ). Hence, using manipulations as in (25) we can conclude that:
                                              n
                                          1X                                                        1
                                   P (k         {i (c0 Xi )2 Xi0 âˆ’ Î³00 }(Î²Ì‚ âˆ’ Î²0 )k > nâˆ’Î± ) = o(nâˆ’ 2 ) .                                        (26)
                                          n i=1

Next, exploit parts (i) and (ii) of the Lemma and argue as in (25) to additionally conclude that:
                                      n                                                        n
                                   1X 0                                             1X                           1
            P (|Î³00 (Î²Ì‚ âˆ’ Î²0 ) âˆ’         Î³0 Xi i | > nâˆ’Î± ) â‰¤ P (kÎ³0 kkHnâˆ’1 âˆ’ Iko k       Xi i k > nâˆ’Î± ) = o(nâˆ’ 2 ) .                           (27)
                                   n i=1                                            n i=1

                                                                      12
Hence, by results (26), (27), X bounded a.s. and part (iii) of the Lemma we establish that:
                                                n
         0                0      2X 0
  P (|c Î£n (Î²Ì‚)c âˆ’ c Î£n (Î²0 )c +      Î³ Xi i | > nâˆ’Î± )
                                 n i=1 0
                                  n                     n                                          n
                              2X 0             2X 0                               1X 0                                              1
                     = P (|         Î³0 Xi i âˆ’       (c Xi )2 i Xi0 (Î²Ì‚ âˆ’ Î²0 ) +       (c Xi )2 (Xi0 (Î²Ì‚ âˆ’ Î²0 ))2 | > nâˆ’Î± ) = o(nâˆ’ 2 ) . (28)
                              n i=1            n i=1                              n i=1

To conclude, note that by direct manipulations we obtain that:

                                  ÏƒÌ‚ 2 = c0 (Hnâˆ’1 âˆ’ I)Î£n (Î²Ì‚)(Hnâˆ’1 âˆ’ I)c + c0 Î£n (Î²Ì‚)c + 2c0 (Hnâˆ’1 âˆ’ I)Î£n (Î²Ì‚)c ,                                (29)

and hence the final claim of the Lemma follows from (23), (24), (25) and (28).

Lemma A.3. Let Assumptions 2.1(i)-(iii) hold and Ln be as in (9). Then for any Î± âˆˆ [0, 1):
                                                                                                              1
                                                        lim sup P (|Tn âˆ’ Ln | > nâˆ’Î± ) = o(nâˆ’ 2 ) .
                                                            nâ†’âˆž


Proof: By a Taylor expansion we obtain for some ÏƒÌ„ 2 a convex combination of ÏƒÌ‚ 2 and Ïƒ 2 that:
                                                        n                                                     n
                                1 X            (Ïƒ âˆ’ ÏƒÌ‚) 0 âˆ’1       1 X
  Tn âˆ’ Ln = c0 {Hnâˆ’1 âˆ’ I âˆ’ âˆ†n } âˆš      Xi i +         c {Hn âˆ’ I} âˆš       Xi i
                               Ïƒ n i=1           ÏƒÌ‚Ïƒ                n i=1
                                                                          n                                         n
                                                               1 X 0             1               2X 0               3
                                                             +âˆš       c Xi i {âˆ’ 3 (ÏƒÌ‚ 2 âˆ’ ÏƒÌ‚R
                                                                                             2
                                                                                               +       Î³0 Xi i ) + 5 (ÏƒÌ‚ 2 âˆ’ Ïƒ 2 )2 } . (30)
                                                                n i=1           2Ïƒ               n i=1             4ÏƒÌ„

To study the right hand side of (30), first observe that Lemma A.2(i) and A.2(ii) imply that:
                                     n
         0                       1 X
  P (|c      {Hnâˆ’1   âˆ’ I âˆ’ âˆ†n }  âˆš      Xi i | > nâˆ’Î± )
                                Ïƒ n i=1
                                                                                                                   n
                                                                                          1               1 X                               1
                                       â‰¤ P (kckkHnâˆ’1 âˆ’ I âˆ’ âˆ†n ko >                          2   ) + P (k âˆš       Xi i k > log2 (n)) = o(nâˆ’ 2 ) . (31)
                                                                                       Î±
                                                                                      n log (n)            n i=1

Moreover, by identical manipulations but exploiting Lemma A.2(i) and A.2(iv) we can similarly conclude:
                                                n                         n
                                            1  X
                                                    0                  2X 0                           1
                                      P (| 3 âˆš                2    2
                                                   c Xi i {ÏƒÌ‚ âˆ’ ÏƒÌ‚R +      Î³ Xi i }| > nâˆ’Î± ) = o(nâˆ’ 2 ) .                                      (32)
                                          2Ïƒ n i=1                     n i=1 0

Next, notice that (X, ) bounded a.s. and Lemma A.1 further imply that:
                                                                                                          n
                                                              Î±                   1                    1X 0                Î±          1
                       P (|c0 (Î£n (Î²0 ) âˆ’ Î£0 )c| > nâˆ’ 2 ) = o(nâˆ’ 2 )                            P (|        Î³ Xi i | > nâˆ’ 2 ) = o(nâˆ’ 2 ) .      (33)
                                                                                                       n i=1 0

Therefore, we obtain from (29) together with (23) and (28) that since Î± < 1 we must have:
                                                                                            Î±             1
                                                             P (|ÏƒÌ‚ 2 âˆ’ Ïƒ 2 | > nâˆ’ 2 ) = o(nâˆ’ 2 ) .                                              (34)
                                                    Î±             1
This implies that P (|ÏƒÌ‚ âˆ’ Ïƒ| > nâˆ’ 2 ) = o(nâˆ’ 2 ) and since ÏƒÌ„ is a convex combination of Ïƒ 2 and ÏƒÌ‚ 2 that P (ÏƒÌ„ > ) =
     1
o(nâˆ’ 2 ) for any  < Ïƒ. Hence, exploiting (34) and manipulations as in (31) we can conclude:
                                             n
                              (ÏƒÌ‚ 2 âˆ’ Ïƒ 2 )2 X 0             âˆ’Î±                           5              1          1
                      P (|          5
                                      âˆš        c Xi  i | > n   ) â‰¤ P ((ÏƒÌ‚ 2
                                                                             âˆ’ Ïƒ 2 2
                                                                                  )  >       2   ) + o(nâˆ’ 2 ) = o(nâˆ’ 2 ) .                       (35)
                                  ÏƒÌ„ n i=1                                              Î±
                                                                                       n log (n)
                                                                              1
Similarly, for  < Ïƒ we can exploit P (ÏƒÌ‚ > ) = o(nâˆ’ 2 ) and Lemma A.2(i) to obtain:
                                            n
         (Ïƒ âˆ’ ÏƒÌ‚) 0 âˆ’1       1 X                          |Ïƒ âˆ’ ÏƒÌ‚|kck                  1              1
  P (|           c {Hn âˆ’ I} âˆš       Xi i | > nâˆ’Î± ) â‰¤ P (       2
                                                                      kHnâˆ’1 âˆ’ Iko > Î±    2   ) + o(nâˆ’ 2 )
           ÏƒÌ‚Ïƒ                n i=1                                               n log (n)
                                                                  2                               1              1          1
                                        â‰¤ P (|Ïƒ âˆ’ ÏƒÌ‚| >               Î±   ) + P (kHnâˆ’1 âˆ’ Iko > Î±         ) + o(nâˆ’ 2 ) = o(nâˆ’ 2 ) . (36)
                                                              kckn log(n)
                                                                      2                       n 2 log(n)


                                                                                       13
where the final result follows from Lemma A.2(ii), equation (34) and Î± < 1. The Lemma is then established due to
the decomposition in (30) and results (31), (32), (35) and (36).

Lemma A.4. Let {Ain }ni=1 be a triangular array of k Ã— p matrices, {cn }ni=1 be a sequence of scalars with {Ain }ni=1
and {cn }ni=1 measurable functions of {Yi , Xi }ni=1 . Suppose Assumptions 2.1(i) and 2.2(i) hold and
                                                              n
                                                        1X
                                            lim sup           kAin kÏ‰
                                                                    F <âˆž                      câˆ’1     Î±
                                                                                               n = o(n )          a.s.                          (37)
                                              nâ†’âˆž       n i=1

for some Î± âˆˆ [0, Ï‰âˆ’1                                         Ï‰
                  2Ï‰ ). Then, for any g : R â†’ R such that E[g (W )] < âˆž, it follows that:
                                                 n
                                              1X                                             1
                                     P âˆ— (k         Ain {g(Wi ) âˆ’ E[g(Wi )]}kF > cn ) = o(nâˆ’ 2 )                    a.s. .
                                              n i=1

                    (l,j)
Proof: Let Ain              denote the (l, j) entry of Ain and proceed as in equation (15) to conclude that:
                        n                                                        k    p            n
                    1X                                        XX          kp X (l,j)
           P âˆ— (k         Ain {g(Wi ) âˆ’ E[g(Wi )]}kF > cn ) â‰¤      P âˆ— (|      A     {g(Wi ) âˆ’ E[g(Wi )]}| > cn ) .                             (38)
                    n i=1                                      j=1
                                                                          n i=1 in
                                                                              l=1

Next, apply Markovâ€™s inequality and the Marcinkiewicz and Rosenthal inequalities (Lemmas 1.4.13 and 1.5.9 in de la
Pena and Gine (1999)) to obtain for some constants C1 and C2 that:
                   n                                       âˆš           n
  âˆš             1 X (l,j)                                    n     1 X (l,j)
      nP âˆ— (|         Ain {g(Wi ) âˆ’ E[g(Wi )]}| > cn ) â‰¤ Ï‰ E âˆ— [|         A       {g(Wi ) âˆ’ E[g(Wi )]}|Ï‰ ]
                n i=1                                       cn     n i=1 in
                           âˆš               n                                         âˆš         n
                             nC1 âˆ— 1 X (l,j)                               2 Ï‰         nC2 1 X (l,j) 2                Ï‰
                         â‰¤       E [(         (A in {g(W i ) âˆ’ E[g(W i )]}) ) 2 ] â‰¤       Ï‰ (     (Ain ) Var(g(Wi ))) 2 , (39)
                            cÏ‰n       n 2
                                          i=1
                                                                                     cÏ‰n 2 n
                                                                                      n       i=1

where in the final result we have used (37) and Ï‰ â‰¥ 2. The claim of the Lemma then follows by (37), (38), (39) and
Î± âˆˆ [0, Ï‰âˆ’1
         2Ï‰ ) by hypothesis.


Lemma A.5. Let (ÏƒÌ‚sâˆ— )2 â‰¡ c0 Hnâˆ’1 Î£âˆ—n (Î²Ì‚)Hnâˆ’1 c and {cn }ni=1 be measurable scalar-valued functions of {Yi , Xi }ni=1 . Let
Assumptions 2.1(i)-(ii), 2.2(i) hold and câˆ’1     Î±                       Ï‰âˆ’1
                                          n = o(n ) a.s. for some Î± âˆˆ [0, 2Ï‰ ). Then:


                                                1
   (i) P âˆ— (kÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k > cn ) = o(nâˆ’ 2 ) almost surely.
                                                          1
  (ii) P âˆ— (|(ÏƒÌ‚ âˆ— )2 âˆ’ (ÏƒÌ‚sâˆ— )2 | > c2n ) = o(nâˆ’ 2 ) almost surely.
                                                    1
 (iii) P âˆ— (|(ÏƒÌ‚sâˆ— )2 âˆ’ Ïƒ 2 | > ) = o(nâˆ’ 2 ) almost surely for any  > 0.

                      a.s.                                                                                 a.s.
Proof: Since Î²Ì‚ â†’ Î², (Y, X) are bounded by Assumption 2.1(ii) and kHnâˆ’1 ko â†’ 1, Lemma A.4 implies:
                                                                             n
                                                                         1X                                      1
                       P âˆ— (kÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k > cn ) â‰¤ P âˆ— (kHnâˆ’1 ko k               Xi (Yi âˆ’ Xi Î²Ì‚)Wi k > cn ) = o(nâˆ’ 2 )              a.s.          (40)
                                                                         n i=1


    For the second claim of the Lemma, proceed by standard manipulations to obtain the inequalities:

                 P âˆ— (|(ÏƒÌ‚ âˆ— )2 âˆ’ (ÏƒÌ‚sâˆ— )2 | > c2n )
                                                 n                                        n
                                            1X                                2X
                        = P âˆ— (|c0 Hnâˆ’1 {         Xi Xi0 (Xi0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚))2 âˆ’       Xi Xi0 âˆ—i Xi0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚)}Hnâˆ’1 c| > c2n )
                                            n i=1                             n i=1
                                                              n                                     n
                                                        1X                                     2X
                        â‰¤ P âˆ— (kck2 kHnâˆ’1 k2o {k              Xi Xi0 (Xi0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚))2 ko + k       Xi Xi0 âˆ—i Xi0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚)ko } > c2n ) .   (41)
                                                        n i=1                                  n i=1


                                                                                 14
Since X is bounded a.s., we then obtain from part (i) of the Lemma that for some K > 0 we must have:

                                        n
                                1X
  P âˆ— (kck2 kHnâˆ’1 k2o k               Xi Xi0 (Xi0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚))2 ko > c2n )
                                n i=1
                                                                                                                                             1
                                                                                          â‰¤ P âˆ— (kck2 kHnâˆ’1 k2o KkÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k2 > c2n ) = o(nâˆ’ 2 )    a.s. (42)

Let X (k) denote the k th coordinate of the vector X. Using k Â· ko â‰¤ k Â· kF , we can then conclude that:
                                                           n
                                                     2X
                    P âˆ— (kck2 kHnâˆ’1 k2o k                  Xi Xi0 âˆ—i Xi0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚)ko > c2n )
                                                     n i=1
                                                                                                             n
                                                                                                        2d2x X (j) (k) âˆ— 0 âˆ—
                                                    â‰¤ P âˆ— (kck2 kHnâˆ’1 k2o {               max       |          X Xi i Xi (Î²Ì‚ âˆ’ Î²Ì‚)|} > c2n )
                                                                                 1â‰¤jâ‰¤dx ,1â‰¤kâ‰¤dx          n i=1 i
                                                          dx X
                                                             dx                                    n
                                                          X                                   2d2x X (j) (k)
                                                    â‰¤                 P âˆ— (kck2 kHnâˆ’1 k2o k          X Xi Xi âˆ—i kkÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k > c2n ) .                     (43)
                                                          j=1 k=1
                                                                                               n i=1 i

Moreover, for any (j, k) we can then conclude from Lemma A.4 and part (i) of this Lemma that:

                                        n
    âˆ—                     2d2           X           (j)    (k)
  P (kck   2
               kHnâˆ’1 k2o k x                      Xi Xi Xi âˆ—i kkÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k > c2n )
                                    n       i=1
                                                                    n
                                                               2d2x X (j) (k)                                                               1
                                                  â‰¤ P âˆ— (k            Xi Xi Xi âˆ—i k > cn ) + P âˆ— (kck2 kHnâˆ’1 k2o kÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k > cn ) = o(nâˆ’ 2 ) , (44)
                                                                n i=1

almost surely. The second claim of the Lemma then follows from (41)-(44).

                                                                  a.s.                 a.s.
    To conclude, exploit that kHnâˆ’1 ko â†’ 1 and ÏƒÌ‚ 2 â†’ Ïƒ together with Lemma A.4 to obtain:


  P âˆ— (|(ÏƒÌ‚sâˆ— )2 âˆ’ Ïƒ 2 | > ) â‰¤ P âˆ— (|(ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 | >  âˆ’ |ÏƒÌ‚ 2 âˆ’ Ïƒ 2 |)
                                                                       n
                                                                 1X                                        âˆ’ |ÏƒÌ‚ 2 âˆ’ Ïƒ 2 |          1
                                                    â‰¤ P âˆ— (k           Xi Xi0 (Yi âˆ’ Xi Î²Ì‚)2 (Wi2 âˆ’ 1)kF >                   ) = o(nâˆ’ 2 )           a.s. ,   (45)
                                                                 n i=1                                    kck2 kHnâˆ’1 k2o

which establishes the third and final claim of the Lemma.

Lemma A.6. Let Assumptions 2.1(i)-(ii), 2.2(i), and for c âˆˆ Rdx define the following random variables:
                               âˆš 0
                         âˆ—        nc âˆ—
                        Ts,n â‰¡        (Î²Ì‚ âˆ’ Î²)         (ÏƒÌ‚sâˆ— )2 â‰¡ c0 Hnâˆ’1 Î£âˆ—n (Î²Ì‚)Hnâˆ’1 c .                                                                  (46)
                                 ÏƒÌ‚sâˆ—
                                                                                   1
It then follows that P âˆ— (|Tnâˆ— âˆ’ Ts,n
                                  âˆ—
                                      | > nâˆ’Î± ) = o(nâˆ’ 2 ) almost surely for any Î± âˆˆ [0, 2Ï‰âˆ’3
                                                                                          2Ï‰ ).


                                                                                                                                        1
Proof: Let  < Ïƒ 2 and note that parts (ii) and (iii) of Lemma A.5 imply P âˆ— (ÏƒÌ‚ âˆ— ÏƒÌ‚sâˆ— < ) = o(nâˆ’ 2 ) almost surely. For
any Î³ âˆˆ [0, Ï‰âˆ’1
             2Ï‰ ), part (i) of Lemma A.5 then establishes that:
                                                                       âˆš
                    âˆ—                                                n|ÏƒÌ‚ âˆ— âˆ’ ÏƒÌ‚sâˆ— |
                P       (|Tnâˆ—   âˆ’    âˆ—
                                    Ts,n |    >n    âˆ’Î±
                                                          )â‰¤P (   âˆ—
                                                                                     Ã— kckkÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k > nâˆ’Î± )
                                                                       ÏƒÌ‚ âˆ— ÏƒÌ‚sâˆ—
                                                                   âˆš                                                1
                                                            â‰¤ P âˆ— ( n|ÏƒÌ‚ âˆ— âˆ’ ÏƒÌ‚sâˆ— | > Î±âˆ’Î³ ) + P âˆ— (kÎ²Ì‚ âˆ— âˆ’ Î²Ì‚k > Î³      ) + P âˆ— (ÏƒÌ‚ âˆ— ÏƒÌ‚sâˆ— < )
                                                                                       n                          n kck
                                                                   âˆš                                  1
                                                            = P âˆ— ( n|ÏƒÌ‚ âˆ— âˆ’ ÏƒÌ‚sâˆ— | > Î±âˆ’Î³ ) + o(nâˆ’ 2 )        a.s. .                                        (47)
                                                                                       n

Since for any Î± âˆˆ [0, 2Ï‰âˆ’3                     Ï‰âˆ’1
                       2Ï‰ ) we may pick Î³ âˆˆ [0, 2Ï‰ ) so that Î± âˆ’ Î³ +
                                                                                                               1
                                                                                                               2   âˆˆ [0, Ï‰âˆ’1
                                                                                                                          Ï‰ ), the claim of the Lemma then

follows from result (47) and part (ii) of Lemma A.5.



                                                                                              15
Lemma A.7. Let Assumptions 2.1(i)-(iii), 2.2(i) hold, ei â‰¡ (Yi âˆ’ Xi0 Î²Ì‚) and ÎºÌ‚ â‰¡                       1           0 âˆ’1    3 3
                                                                                                            P
                                                                                                        n       i (c Hn Xi ) ei .   Then:

                                           Îº    Î³   2c0 Î£ Î³                                                     E[W 3 ]ÎºÌ‚
                        E[Ln ] = âˆ’          âˆš âˆ’ âˆš1 + 3 âˆš0 0                                    E âˆ— [Lâˆ—n ] = âˆ’        âˆš .
                                        2Ïƒ 3 n Ïƒ n   Ïƒ n                                                        2ÏƒÌ‚ 3 n

Proof: We first derive an expression for E[Ln ]. Note that E[XX 0 ] = I and E[X] = 0 imply:
                                    n                          n                        n
                         1 X                    1X                  1 X                1
                 E[c0 âˆ†n âˆš      Xi i ] = c0 E[       (I âˆ’ Xi Xi0 ) âˆš      Xi i ] = âˆ’ âˆš E[(c0 X)X 0 X]                                    (48)
                        Ïƒ n i=1                 n i=1              Ïƒ n i=1            Ïƒ n

due to the i.i.d. assumption. Similarly, exploiting the i.i.d. assumption and E[(c0 X)] = E[âˆ†n ] = 0 yields:
                            n                                          n
                       1   X
                                 0                                1   X
               E[       âˆš      (c  Xi ) i (ÏƒÌ‚ 2
                                               R âˆ’ Ïƒ 2
                                                       )] = E[     âˆš      (c0 Xi )i {c0 (Î£n (Î²0 ) âˆ’ Î£0 )c + 2c0 âˆ†n Î£0 c}]
                    2Ïƒ 3 n i=1                                 2Ïƒ 3 n i=1
                                                                  1
                                                           =       âˆš {E[(c0 X)3 3 ] âˆ’ 2E[(c0 X)2 X 0 ]Î£0 c} .                             (49)
                                                               2Ïƒ 3 n

The expression for E[Ln ] can then be obtained from (48), (49) and by analogous arguments concluding:
                                                       n                   n
                                                  1   X
                                                            0           2X 0               c0 Î£0 Î³0
                                          E[       âˆš      (c  Xi ) i Ã—      Î³  Xi  i ] =     âˆš .                                          (50)
                                               2Ïƒ 3 n i=1               n i=1 0            Ïƒ3 n


    In order to compute E âˆ— [Lâˆ—n ], observe that W âŠ¥ (Y, X) and E[W 2 ] = 1 implies that:
                                                 n          n
                                   1 âˆ— c0 Hnâˆ’1 X        âˆ—1
                                                           X                                          E[W 3 ]ÎºÌ‚
                 E âˆ— [Lâˆ—n ] = âˆ’       3
                                        E [ âˆš       X 
                                                     i i       c0 Hnâˆ’1 Xi Xi0 Hnâˆ’1 ce2i (Wi2 âˆ’ 1)] = âˆ’ 3 âˆš ,                                (51)
                                  2ÏƒÌ‚         n i=1      n i=1                                        2ÏƒÌ‚ n

which establishes the second claim of the Lemma.

Lemma A.8. Under Assumptions 2.1(i)-(iii) and 2.2(i), the second moments of Ln and Lâˆ—n satisfy:

                                   E[L2n ] = 1 + O(nâˆ’1 )                 E âˆ— [(Lâˆ—n )2 ] = 1 + Oa.s. (nâˆ’1 ) .


Proof: To calculate E[L2n ], first note that E[XX 0 ] = I, E[X] = 0 and direct calculations yield:

                 n                      n                      n                                        n
            1 X                      c0 X                 1 X                  1                        X
  E[(c0 âˆ†n âˆš        Xi i )2 ] = E[(       (I âˆ’ Xi Xi0 ) âˆš        Xi i )2 ] = 2 2 E[(c0 (I âˆ’ Xi Xi0 )(   Xk k ))2 ]
             nÏƒ i=1                  n i=1                 nÏƒ i=1             Ïƒ n
                                                                                                                       k=1
                                                                                n                                n
                                                   (n âˆ’ 1)                      X                                X
                                               +           E[{c0 (I âˆ’ Xi Xi )         Xk k }{c0 (I âˆ’ Xj Xj0 )         Xk k }] = O(nâˆ’1 ) . (52)
                                                    Ïƒ 2 n2
                                                                                k=1                              k=1

Similarly, exploiting the i.i.d. assumption together with E[X] = 0 and E[I âˆ’ XX 0 ] = 0 we obtain:

            n                       n                      n                 n                  n
       1 X 0              0    1 X                 1     X
                                                               0          0
                                                                            X
                                                                                         0
                                                                                              X
  E[( âˆš        c Xi i )(c âˆ†n âˆš        Xi i )] = 2 2 E[(     c Xi i )(c       (I âˆ’ Xi Xi ))(     Xi i )]
        nÏƒ i=1                  nÏƒ i=1           n Ïƒ      i=1               i=1                i=1
                                                                                     1
                                                                                =        E[(c0 X)(c0 X âˆ’ c0 XX 0 X)] = O(nâˆ’1 ) . (53)
                                                                                    nÏƒ 2

Exploiting identical arguments to (52) on the squares of the remaining terms of Ln and the Cauchy-Schwarz inequal-
ity and arguments identical to those in (53) to address cross terms arising from expanding the square, it is then
straightforward to establish that:
                                               n
                                  1 X 0                           c0 E[XX 0 2 ]c
                    E[L2n ] = E[( âˆš      c Xi i )2 ] + O(nâˆ’1 ) =                 + O(nâˆ’1 ) = 1 + O(nâˆ’1 ) .                                 (54)
                                 Ïƒ n i=1                               Ïƒ2



                                                                       16
    For notational simplicity, let ain â‰¡ c0 Hnâˆ’1 Xi and set ei â‰¡ (Yi âˆ’ Xi0 Î²Ì‚). To compute E âˆ— [(Lâˆ—n )2 ], first note that the
i.i.d. assumption together with E âˆ— [(âˆ—i )4 ] = e4i E[Wi4 ], E âˆ— [(âˆ—i )2 ] = e2i and E âˆ— [âˆ—i ] = 0 imply that:
                                    n               n                                   n
                       1      âˆ—
                                  X
                                             âˆ— 2
                                                   X
                                                               âˆ— 2                1 X 4 4
                            E   [(     ain  i ) (     a2
                                                        in {( i ) âˆ’ e 2
                                                                       i })] =             ain ei (E[W 4 ] âˆ’ 1) = Oa.s (nâˆ’1 ) .                            (55)
                    ÏƒÌ‚ 4 n2        i=1             i=1
                                                                               ÏƒÌ‚ 4 n2
                                                                                       i=1

Next, also note that by direct calculations, {Wi }ni=1 being i.i.d. and E âˆ— [(âˆ—i )3 ] = e3i E[W 3 ] we may establish:
                      n              n
        1       âˆ—
                    X
                              âˆ— 2
                                   X
              E   [(     a  
                          in i )  (     a2in {(âˆ—i )2 âˆ’ e2i })2 ]
     4ÏƒÌ‚ 6 n3        i=1            i=1
                            n                   n                          n X                             n
                     1      X
                                 âˆ— 2      âˆ— 2
                                                X
                                                          âˆ— 2
                                                                          X
                                                                                 âˆ—          âˆ—         âˆ—
                                                                                                           X
              =           {    E  [ain ( i ) (   a2
                                                   kn {( k ) âˆ’ e2 2
                                                                 k }) ] +      E   [(a in  i )(ajn  j )(   a2kn {(âˆ—k )2 âˆ’ e2k })2 ]}
                  4ÏƒÌ‚ 6 n3 i=1                                            i=1
                                                        k=1                                    j6=i                              k=1
                            n X
                              n                                                            n X
                     1      X                                                              X
              =           {               a2in a4kn E âˆ— [(âˆ—i )2 {(âˆ—k )2 âˆ’ e2k }2 ] + 2              a3in e3i a3jn e3j (E[W 3 ])2 } .                     (56)
                  4ÏƒÌ‚ 6 n3 i=1                                                             i=1 j6=i
                                 k=1

                                                                  1
                                                                           a2in e2i = ÏƒÌ‚ 2 and exploiting (55) and (56):
                                                                      P
Therefore, expanding the square, noting that                      n    i

                                                                    n
                                     âˆ—                   1 âˆ— X
                                 E       [(Lâˆ—n )2 ]   =       E [(     ain âˆ—i )2 ] + Oa.s. (nâˆ’1 ) = 1 + Oa.s. (nâˆ’1 ) ,                                    (57)
                                                        nÏƒÌ‚ 2      i=1

which establishes the second and final claim of the Lemma.

Lemma A.9. Let Assumptions 2.1(i)-(iii), 2.2(i) hold ei â‰¡ (Yi âˆ’ Xi0 Î²Ì‚) and ÎºÌ‚ â‰¡                                       1           0 âˆ’1    3 3
                                                                                                                           P
                                                                                                                       n       i (c Hn Xi ) ei .   Then:

                             7Îº    3Î³   12c0 Î£0 Î³0                                                                     7E[W 3 ]ÎºÌ‚
            E[L3n ] = âˆ’      3
                               âˆš âˆ’ âˆš1 +      âˆš     + O(nâˆ’1 )                                    E âˆ— [(Lâˆ—n )3 ] = âˆ’           âˆš + Oa.s. (nâˆ’1 ) .            (58)
                           2Ïƒ n Ïƒ n      Ïƒ3 n                                                                           2ÏƒÌ‚ 3 n

Proof: The calculations are cumbersome and for brevity we provide only the essential steps. Define:
                                                        n                         n                                        n
                                      1 X             1  X                             2X 0
                          Î“ n â‰¡ c0 âˆ†n âˆš      Xi i âˆ’ 3 âˆš     (c0 Xi )i {(ÏƒÌ‚R
                                                                            2
                                                                              âˆ’ Ïƒ2 ) âˆ’      Î³ Xi i } .                                                    (59)
                                     Ïƒ n i=1        2Ïƒ n i=1                           n i=1 0

                                                                                                        3
                    1
                         c0 i Xi i +Î“n . Under Assumption 2.1(ii), it can be shown that E[Î“3n ] = O(nâˆ’ 2 ) and similarly
                            P
Notice that Ln = Ïƒâˆš   n
                                    1
that E[( âˆš1n i c0 Xi i )3 ] = O(nâˆ’ 2 ). Therefore, by direct calculation and Holderâ€™s inequality:
            P

                              n                           n                              n
                          1 X 0                       1 X 0                          1 X 0
          E[L3n ]   = E[( âˆš                 3
                                 (c Xi )i ) ] + 3E[( âˆš                 2
                                                             (c Xi )i ) Î“n ] + 3E[( âˆš      (c Xi )i )Î“2n ] + E[Î“3n ]
                         Ïƒ n i=1                     Ïƒ n i=1                        Ïƒ n i=1
                                     n                                        n
                          1 X 0                        1 X 0
                    = E[( âˆš      (c Xi )i )3 ] + 3E[( âˆš      (c Xi )i )2 Î“n ] + O(nâˆ’1 ) .                                                                (60)
                         Ïƒ n i=1                      Ïƒ n i=1

Hence, we can establish the first claim of the Lemma by analyzing the remaining terms in (60). Note that
                                                                 n
                                                          1 X 0                    1
                                                      E[( âˆš      (c Xi )i )3 ] = 3 âˆš E[(c0 X)3 3 ] ,                                                     (61)
                                                         Ïƒ n i=1                 Ïƒ n

by the i.i.d. assumption and E[X] = 0. Similarly, by direct calculation we can also obtain the expression:
                       n                      n
                   1 X 0               c0 âˆ†n X
               E[( âˆš      (c Xi )i )2 âˆš         Xi i ]
                  Ïƒ n i=1                 nÏƒ i=1
                                                       n                n                           n                  n
                                           1           X                X            X              X                  X
                                 =              5   E[{ (c0 Xi )2 2i +   (c0 Xi )i   (c0 Xj )j }   c0 (I âˆ’ Xk Xk0 )   Xl l ]
                                         Ïƒ3 n   2
                                                        i=1                 i=1              j6=i               k=1                      l=1
                                    c0 Î£0 c                   2                             3
                                 = âˆ’ 3 âˆš E[(c0 X)(X 0 X)] âˆ’ 3 âˆš E[(c0 X)(Î³00 X)2 ] + O(nâˆ’ 2 ) .                                                          (62)
                                    Ïƒ n                     Ïƒ n


                                                                                  17
                                                                  1
                                                                                                         c0 Xi i )2 Î“n ] and obtain:
                                                                                                     P
By analogous arguments we can compute the remaining terms in E[( Ïƒâˆš n                                i

                                             n
                            1        1 X 0                                       3c0 Î£0 c                    3

                              5
                                E[( âˆš       (c Xi )i )3 c0 {Î£n (Î²0 ) âˆ’ Î£0 }c] =     âˆš E[(c0 X)3 3 ] + O(nâˆ’ 2 )                                  (63)
                           2Ïƒ         n i=1                                      2Ïƒ 5 n
                                                        n
                                       1       1 X 0              3 0                 3c0 Î£0 c 0          3
                                          E[( âˆš       (c Xi ) i ) {c âˆ† n Î£ 0 c}] = âˆ’     âˆš Î³ Î£0 c + O(nâˆ’ 2 )                                     (64)
                                       Ïƒ5       n i=1                                 Ïƒ5 n 0
                                                    n                       n
                                  1        1 X 0              3 1
                                                                   X
                                                                         0             3c0 Î£0 c 0           3

                                    5
                                      E[( âˆš       (c Xi ) i ) {       Î³ 0 Xi  i }] =   5
                                                                                           âˆš c Î£0 Î³0 + O(nâˆ’ 2 ) .                                 (65)
                                  Ïƒ         n i=1                n i=1                 Ïƒ n

The first claim of the Lemma then follows by combining the results from (60)-(65).

    Letting ain = c0 Hnâˆ’1 Xi and employing Assumption 2.1(ii), it can then be shown that:
                                                        n
                                            âˆ—   1 X                 1                                    3
                                          E [( âˆš       ain âˆ—i )3 ( 3 {(ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 })2 ] = Oa.s. (nâˆ’ 2 )                                      (66)
                                                 n i=1             2ÏƒÌ‚
                                                        n
                                                  1 X                 1                                    3
                                          E âˆ— [( âˆš       ain âˆ—i )3 ( 3 {(ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 })3 ] = Oa.s. (nâˆ’ 2 ) .                                  (67)
                                                   n i=1             2ÏƒÌ‚

Therefore, expanding the cube and exploiting that W âŠ¥ (Y, X) and E âˆ— [(âˆ—i )k ] = E[W k ]eki , it follows that:
                                                    n
                                        1 X                 1   3((ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 ) 3((ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 )2   ((ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 )3
               E âˆ— [(Lâˆ—n )3 ] = E âˆ— [( âˆš       ain âˆ—i )3 { 3 âˆ’            5
                                                                                   +            7
                                                                                                         âˆ’                     }]
                                         n i=1             ÏƒÌ‚          2ÏƒÌ‚                  4ÏƒÌ‚                    8ÏƒÌ‚ 9
                                                        n                                 n
                                     E[Wi3 ]   1X 3 3           3 âˆ— 1 X                                                     3
                                 =       âˆš   Ã—       ain e i âˆ’       E [( âˆš       ain âˆ—i )3 {(ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 }] + Oa.s (nâˆ’ 2 ) .                 (68)
                                     ÏƒÌ‚ 3 n    n i=1           2ÏƒÌ‚ 5        n i=1

Moreover, also note that by analogous arguments and direct calculations we further obtain:
                   n                            n
              1 X                  3 X 2
      E âˆ— [( âˆš       ain âˆ—i )3 { 5       a {(âˆ— )2 âˆ’ e2i }}]
               n i=1             2ÏƒÌ‚ n i=1 in i
                                  n                                                   n                               n
                 3             1X 5 âˆ— âˆ— 3 âˆ— 2                           9       âˆ—
                                                                                    X
                                                                                                âˆ—
                                                                                                    X
                                                                                                               âˆ— 2
                                                                                                                     X
          =            3   Ã—         ain E [(i ) {(i ) âˆ’ e2i }] +         5 E   [{     ain ( i )      a2
                                                                                                            (
                                                                                                          jn j  )  }     a2kn {(âˆ—k )2 âˆ’ e2i }]
              2ÏƒÌ‚ 5 n 2        n i=1                                2ÏƒÌ‚ 5 n 2        i=1            j6=i             k=1
                                   n                        n
                  9    1 X 2 2 E[W 3 ] X 3 3                  3
          =        âˆš Ã—     a e Ã—           ain ei + Oa.s. (nâˆ’ 2 ) .                                                                               (69)
              2ÏƒÌ‚ 5 n n i=1 in i n     i=1

The second claim of the Lemma is then established by (68) and (69).

Proof of Theorem 2.1: The first claim of the Theorem is an immediate consequence of Lemma A.3. For the second
                                                                                                               1
                                                                 âˆ—
claim, note that in lieu of Lemma A.6, it suffices to show that Tn,s = Lâˆ—n + opâˆ— (nâˆ’ 2 ) a.s.. For notational simplicity,
let ain = c0 Hnâˆ’1 Xi (Yi âˆ’ Xi0 Î²Ì‚) and apply Markovâ€™s inequality to conclude that:

                                                    n
                            C            1X 2                   C
  P âˆ— (|(ÏƒÌ‚sâˆ— )2 âˆ’ ÏƒÌ‚ 2 | > âˆš ) = P âˆ— (|       ain (Wi2 âˆ’ 1)| > âˆš )
                             n           n i=1                   n
                                                                                      n                               n
                                                                            n âˆ— 1X 2                           1 X 4
                                                                        â‰¤       E [(       ain (Wi2 âˆ’ 1))2 ] = 2     a E[(Wi2 âˆ’ 1)2 ] . (70)
                                                                            C 2      n i=1                    C n i=1 in

                                                                                              a.s.
                                                            1
                                                                        a4in E[(Wi2 âˆ’ 1)2 ] â†’ E[(c0 X)4 4i ]E[(W 2 âˆ’ 1)2 ] < âˆž, and therefore
                                                                P
However, under our moment assumptions,                      n       i
                                                                1
from (70) it follows that (ÏƒÌ‚sâˆ— )2 = ÏƒÌ‚ 2 + Opâˆ— (nâˆ’ 2 ) almost surely. The second claim of the Lemma then follows from a
second order Taylor expansion.

Proof of Theorem 2.2: Follows immediately from Lemmas A.7, A.8, A.9 and direct calculation.


                                                                                 18
                                                      APPENDIX B - Proofs of Theorem 2.3

Lemma B.1. Let Assumption 2.1(i)-(iv) hold and Ln be as in (9) with c 6= 0. Then, uniformly in z âˆˆ R:
                                                              Ï†(z)Îº              Ï†(z)                                      1
                      P (Ln â‰¤ z) = Î¦(z) +                       3
                                                                  âˆš (2z 2 + 1) âˆ’ 3 âˆš (c0 Î£0 Î³0 (z 2 + 1) âˆ’ Î³1 Ïƒ 2 ) + o(nâˆ’ 2 ) .
                                                             6Ïƒ n               Ïƒ n

Proof: Letting Z â‰¡ (X 0 , vech(XX 0 )0 , vech(XX 0 2 )0 )0 , it is clear that Ln is a smooth functional of                                        1
                                                                                                                                                        P
                                                                                                                                                    n    i   Zi and that
Z satisfies Cramerâ€™s condition by Assumption 2.1(iv). The claim of the Lemma then follows from Theorem 2.2 in
Hall (1992) and Theorem 2.2.

Lemma B.2. Let {ain }ni=1 be a triangular array of measurable scalar valued functions of {Yi , Xi }ni=1 and define
                                                                        P âˆ’1
Vin â‰¡ (ain Wi , a2in (Wi2 âˆ’ 1))0 , â„¦n â‰¡ n1 i E âˆ— [Vin Vin
                                                        0
                                                          ] and Sn â‰¡ âˆš1n i â„¦n 2 Vin . Suppose Assumptions 2.2(i)-(ii)
                                          P
                          a.s.
hold and (i) â„¦n â†’ â„¦ with â„¦ full rank, (ii) lim supnâ†’âˆž max1â‰¤iâ‰¤n |ain | < âˆž a.s. and (iii) For Kn () â‰¡ #{i :
min{|ain |, a2in } â‰¥ }, there a.s. exists an 0 such that Kn (0 )/ log(n) â†‘ âˆž. Then:
                                                                   1 Z
                                                                                                                          1
                                                                   X
                                             P âˆ— (Sn âˆˆ B) =                     dPj (âˆ’Î¦ : {Xkâˆ— (Sn )}) + o(nâˆ’ 2 )                  a.s.
                                                                   j=0     B

uniformly over all Borel sets B with Î¦((âˆ‚B) ) â‰¤ C for some constant C, (âˆ‚B) the  enlargement of âˆ‚B, Xkâˆ— (Sn )
the k th cumulant of Sn under P âˆ— and Pj the Cramer-Edgeworth measures.


Proof: We proceed by verifying the conditions of Theorem 3.4 in Skovgaard (1986). For t âˆˆ R2 , define:
                                                                      1                      1
                                                     Ïn (t) â‰¡            |X âˆ— (t0 Sn )| =        |E âˆ— [(t0 Sn )3 ]| ,                                               (71)
                                                                   3!ktk3 3               3!ktk3
since E[W ] = 0, E[W 2 ] = 1 and W âŠ¥ (Y, X). Hence, by Cauchy-Schwartz and convexity we obtain:
                                                                       1
                           n                                       âˆ’       n
                  1        X
                                  âˆ—      0    âˆ’1                 kâ„¦n 2 k3o X
  Ïn (t) â‰¤    3                  E [|t       â„¦n 2 Vin |3 ]   â‰¤        3               E âˆ— [kVin k3 ]
             n 2 ktk3      i=1
                                                                    n2          i=1
                                                                                                        1
                                                                                                  âˆ’       n
                                                                                               4kâ„¦n 2 k3o X
                                                                                           â‰¤        3             {E âˆ— [|ain |3 |Wi |3 ] + E âˆ— [a6in |Wi2 âˆ’ 1|3 ]} . (72)
                                                                                                  n2        i=1

                   a.s.                                                                              âˆ’ 12    a.s.         1
Note that â„¦n â†’ â„¦ with â„¦ full rank by hypothesis, implies kâ„¦n ko â†’ kâ„¦âˆ’ 2 ko < âˆž. Moreover, since {ain }ni=1 is
not random with respect to P âˆ— , we obtain from condition (ii) and result (72) that almost surely:
                                 âˆš                                         âˆ’1
          lim sup{ sup               nÏn (t)} â‰¤ lim sup{4kâ„¦n 2 k3o (E[|W |3 ] + E[|W 2 âˆ’ 1|3 ]) Ã— max {|ain |3 + a6in }} < âˆž .                                      (73)
             nâ†’âˆž          tâˆˆR2                         nâ†’âˆž                                                                     1â‰¤iâ‰¤n

Therefore, we conclude that almost surely there exists a sequence {rn } satisfying the following:
                                                                                 1                                    âˆš
                                                         sup Ïn (t) â‰¤                                        rn          n,                                        (74)
                                                         tâˆˆR2                   rn
which verifies conditions (I) and (II) of Theorem 3.4 in Skovgaard (1986).

    Next, let Î¾nâˆ— (t) â‰¡ E âˆ— [exp(it0 Sn )]. We aim to show that almost surely there exists a Î´ > 0 such that:
                                                                                           d4            th
                                                  lim sup{            sup             |      4
                                                                                               log(Î¾nâˆ— (     ))| Ã— rn2 } < âˆž .                                      (75)
                                                    nâ†’âˆž          0<h<Î´rn ,tâˆˆR2            dh             ktk

                          âˆ—                      âˆ’1       âˆš
Towards this end, define Î¾in (t) â‰¡ E âˆ— [exp(it0 â„¦n 2 Vin / n)]. By Corollary 8.2 in Bhattacharya and Rao (1976),
{ain }ni=1 being nonrandom with respect to P âˆ— and direct calculation it then follows that:
                                                                                             âˆ’1
                    âˆ—                    ktk2 âˆ—   âˆ’1             ktk2 kâ„¦n 2 k2o
                  |Î¾in (t) âˆ’ 1| â‰¤            E [kâ„¦n 2 Vin k2 ] â‰¤                E[W 2 + (W 2 âˆ’ 1)2 ] Ã— max (a2in + a4in ) .                                         (76)
                                          2n                           2n                             1â‰¤iâ‰¤n


                                                                                             19
                          âˆ’1         a.s.         1                            âˆš
Condition (ii), kâ„¦n 2 ko â†’ kâ„¦âˆ’ 2 ko < âˆž and rn                                    n then imply that almost surely there is a Î´ > 0 with:
                                                                                                          âˆ’1
                                  âˆ—                   Î´E[W 2 + (W 2 âˆ’ 1)2 ]           r2 kâ„¦n 2 k2o                         1
       lim sup{ sup             |Î¾in (t)      âˆ’ 1|} â‰¤                       Ã— lim sup{ n           { max (a2in + a4in )}} < .                              (77)
        nâ†’âˆž        ktkâ‰¤Î´rn                                     2                nâ†’âˆž        n        1â‰¤iâ‰¤n                  2

Since Î¾nâˆ— (t) =            âˆ—
                  Q
                        i Î¾in (t)   by the i.i.d. assumption and W âŠ¥ (Y, X) we obtain by direct calculation:
                                                                             n
                         d4     âˆ— th           2                          2
                                                                            X     d4     âˆ—    th
   lim sup{  sup       | 4 log(Î¾n (     ))| Ã— rn } â‰¤ lim sup{  sup       rn     | 4 log(Î¾in (     ))|}
     nâ†’âˆž 0<h<Î´rn ,tâˆˆR2  dh          ktk                nâ†’âˆž 0<h<Î´rn ,tâˆˆR2
                                                                            i=1
                                                                                 dh           ktk
                                                                         n X                                               n               âˆ’1
                                                                         X
                                                                                              âˆ—
                                                                                                                           X              â„¦n 2 Vin 4
                                         â‰¤ lim sup{ sup rn2                          |DÎ» log(Î¾in (t))|} â‰¤ lim sup{16rn2          E âˆ— [k     âˆš     k ]} , (78)
                                               nâ†’âˆž        ktkâ‰¤Î´rn        i=1 |Î»|=4
                                                                                                           nâ†’âˆž
                                                                                                                           i=1
                                                                                                                                              n

                                                                                                        âˆ—                                                     1
where the final inequality holds by Lemma 9.4 in Bhattacharya and Rao (1976) and result (77) implying |Î¾in (t)âˆ’1| <                                           2

for all ktk â‰¤ Î´rn and all 1 â‰¤ i â‰¤ n for n large enough. Moreover,
                                              1                                            1
                         n         âˆ’                            âˆ’        n
                         X        â„¦n 2 Vin 4
                                    âˆ—                    rn2 2kâ„¦n 2 k4o X 4
       lim sup{rn2           E [k   âˆš     k ]} â‰¤ lim sup{ Ã—                 {ain E[W 4 ] + a8in E[(W 2 âˆ’ 1)4 ]}} < âˆž                                       (79)
         nâ†’âˆž
                         i=1
                                      n            nâ†’âˆž   n      n       i=1

almost surely, by condition (i), (ii) and (74). It follows from (78) and (79) that (75) holds almost surely, which
verifies condition (IV) of Theorem 3.4 in Skovgaard (1986).

    To conclude, we aim to show that almost surely for any Î´ > 0 it follows that:

                                                                  lim sup{rn6 Ã— sup |Î¾nâˆ— (t)|} < âˆž .                                                       (80)
                                                                   nâ†’âˆž              Î´rn â‰¤ktk

Let Î¾U denote the characteristic function of U â‰¡ (W, W 2 âˆ’ 1)0 , Î·() â‰¡ supktkâ‰¥ |Î¾U (t)| and define:
                                                                   !
                                                       ain 0
                                               Ain â‰¡                  .                                                                                    (81)
                                                         0 a2in

        âˆ’1
Since â„¦n 2 , Ain are not random with respect to P âˆ— and W âŠ¥ (Y, X) we then obtain by direct calculation:
                                               n                               n                âˆ’1                  âˆ’1    âˆš
                                               Y                               Y     Ain â„¦n 2                        2
         sup      |Î¾nâˆ— (t)|     =       sup             âˆ—
                                                      |Î¾in (t)|   = sup         |Î¾U ( âˆš       t)| â‰¤ {Î·()}#{i:kAin â„¦n tkâ‰¥ n              âˆ€ktkâ‰¥Î´rn }
                                                                                                                                                           (82)
       Î´rn â‰¤ktk                     Î´rn â‰¤ktk i=1                   Î´rn â‰¤ktk i=1          n

                                                                                         âˆ’1                âˆ’1
for any  > 0. Moreover, since the smallest eigenvalue of â„¦n 2 equals kâ„¦n ko 2 , we also have:
                                                                                                          âˆš       1
                                              âˆ’1             âˆš                                    2       nkâ„¦n ko2
                            #{i :       kAin â„¦n 2 tk      â‰¥  n âˆ€ktk â‰¥ Î´rn } â‰¥ #{i : min{|ain |, ain } â‰¥            }.                                     (83)
                                                                                                            Î´rn
                    1
                         a.s.           1                            âˆš                                              âˆš       1
Thus, as kâ„¦n ko2 â†’ kâ„¦ko2 < âˆž and rn                                     n we may almost surely pick âˆ— such that âˆ— nkâ„¦n ko2 /Î´rn < 0 for
n sufficiently large. In addition, by Assumption 2.2(ii), Î·(âˆ— ) < 1; see page 207 in Bhattacharya and Rao (1976).
Hence, by result (82) and condition (iii) we conclude that almost surely:

                                               lim sup{rn6 Ã— sup |Î¾nâˆ— (t)|} â‰¤ lim sup rn6 Î·(âˆ— )Kn (0 ) = 0 ,                                             (84)
                                                  nâ†’âˆž               Î´rn â‰¤ktk                   nâ†’âˆž

verifying Condition (IIIâ€) of Theorem 3.4 in Skovgaard (1986). The claim of the Lemma therefore follows by direct
application of Theorem 3.4 in Skovgaard (1986).

                                                                                 âˆ—
                                                                                                                                  âˆš
Lemma B.3. Suppose Assumptions 2.1(i)-(iv) and 2.2(i)-(ii) hold and let c 6= 0, Ts,n â‰¡                                                nc0 (Î²Ì‚ âˆ— âˆ’ Î²Ì‚)/ÏƒÌ‚sâˆ— where
(ÏƒÌ‚sâˆ— )2 â‰¡ c0 Hnâˆ’1 Î£âˆ—n (Î²Ì‚)Hnâˆ’1 c. It then follows that almost surely, uniformly in z âˆˆ R:
                                                                                   Ï†(z)ÎºÌ‚E[W 3 ]                   1
                                               P âˆ— (Ts,n
                                                     âˆ—
                                                         â‰¤ z) = Î¦(z) +                  3
                                                                                          âˆš      (2z 2 + 1) + o(nâˆ’ 2 ) .                                   (85)
                                                                                     6ÏƒÌ‚ n


                                                                                      20
Proof: We proceed by verifying the conditions of Theorem 3.2 in Skovgaard (1981). First, define:

                                     ain â‰¡ c0 Hnâˆ’1 Xi (Yi âˆ’ Xi Î²Ì‚)                           ai â‰¡ c0 Xi (Yi âˆ’ Xi Î²0 ) .                    (86)

           a.s.                         a.s.
Since Î²Ì‚ â†’ Î²0 , kHnâˆ’1 âˆ’ Iko â†’ 0 and (X, ) is bounded a.s. by Assumption 2.1(ii), we obtain:


  lim sup{ max |ain âˆ’ ai |}
    nâ†’âˆž          1â‰¤iâ‰¤n

                             â‰¤ lim sup{kckkHnâˆ’1 âˆ’ Iko max kXi i k} + lim sup{kckkHnâˆ’1 ko kÎ²Ì‚ âˆ’ Î²0 k max kXi k2 } = 0 . (87)
                                  nâ†’âˆž                             1â‰¤iâ‰¤n                 nâ†’âˆž                               1â‰¤iâ‰¤n


Let Vin â‰¡ (ain Wi , a2in (Wi2 âˆ’ 1))0 and Vi â‰¡ (ai Wi , a2i (Wi2 âˆ’ 1))0 . By result (87), it then follows that:
                                                                     n
                                                                  1X âˆ—           0 a.s.
                                                         â„¦n â‰¡           E [Vin Vin ] â†’ E[V V 0 ] .                                         (88)
                                                                  n i=1

Assumption 2.2(ii) rules out Rademacher weights, which are the only ones satisfying E[W ] = 0 and P (W 2 = 1) = 1.
By Assumption 2.1(iii), W âŠ¥ (Y, X), c 6= 0 and W not being Rademacher, it is then possible to show E[V V 0 ] is full
rank. Next, pick a Î´0 such that:
                                                        P (min{|(c0 X)|, (c0 X)2 2 } â‰¥ Î´0 ) > 0 ,                                        (89)

which is possible since E[(c0 X)2 2 ] > 0 by Assumption 2.1(iii) and c 6= 0. By result (87), then:
                                    n                                                    n
                                 1X                          Î´0           1X
                    lim inf            1{min{|ain |, a2in } â‰¥ } â‰¥ lim inf      1{min{|ai |, a2i } â‰¥ Î´0 } > 0                      a.s. .   (90)
                       nâ†’âˆž       n i=1                       2     nâ†’âˆž n
                                                                           i=1

                                   âˆ’1
                       âˆš1
                             P
Defining Sn â‰¡            n    i   â„¦n 2 Vin , (88), (87) with Assumption 2.1(ii) and (90) verify conditions(i)-(iii) of Lemma B.2
respectively. Therefore, we can conclude that almost surely:
                                                                  1 Z
                                                                                                             1
                                                                  X
                                               P âˆ— (Sn âˆˆ B) =                 dPj (âˆ’Î¦ : {Xkâˆ— (Sn )}) + o(nâˆ’ 2 )                            (91)
                                                                  j=0     B


uniformly over all Borel sets B with Î¦((âˆ‚B) ) â‰¤ C for some constant C. This verifies condition (3.1) of Theorem
3.2 in Skovgaard (1981).

       Next, let t(i) denote the ith coordinate of t âˆˆ R2 and define the functions gn , fn : R2 â†’ R by:
                                                              1                                  t(2)        1
                                               fn (t) â‰¡ gn (â„¦n2 t)             gn (t) â‰¡ t(1) Ã— ( âˆš + ÏƒÌ‚n2 )âˆ’ 2 .                           (92)
                                                                                                   n
                                       âˆ—
Note that by construction, fn (Sn ) = Ts,n , fn (0) = 0 and kDfn (0)k = 1. Further, define the set:

                                                            Î“n â‰¡ {t âˆˆ R2 : ktk â‰¤ log(n)} .                                                 (93)

                                                                                 âˆš                       a.s.
The functions gn are differentiable everywhere except at t âˆˆ R2 with t(2) = âˆ’ÏƒÌ‚n2 n. However, since ÏƒÌ‚n2 â†’ Ïƒ 2 and
   1
          a.s.     1
kâ„¦n2 ko â†’ kâ„¦ 2 ko we obtain that almost surely for n sufficiently large, fn is differentiable on Î“n . Moreover, since a.s.
                      âˆ’1           âˆš
for n large enough kâ„¦n 2 ko log(n)/ n â‰¤ ÏƒÌ‚n2 /2 we obtain by direct calculation:
                                                                                                      5           1                 7
                 âˆš                                  âˆš    1             3  2 2 15kâ„¦n2 ko log(n) 2 2
         lim sup{ n sup sup |DÎ» fn (t)|} â‰¤ lim sup{4 nkâ„¦n2 k3F Ã— max{    Ã— 5,          3      Ã— 7}=0                                       (94)
           nâ†’âˆž      tâˆˆÎ“n |Î»|=3               nâ†’âˆž                      4n ÏƒÌ‚n       8n 2        ÏƒÌ‚n

almost surely; which verifies condition (3.11) of Theorem 3.2 in Skovgaard (1981). Similarly,

                          âˆš                        âˆš    1            1               âˆš    1                                  1
                   lim sup nkâˆ‡2 fn (0)k2F = lim sup nkâ„¦n2 âˆ‡2 gn (0)â„¦n2 k2F â‰¤ lim sup{ nkâ„¦n2 k2F Ã—                                 }=0      (95)
                    nâ†’âˆž                                  nâ†’âˆž                                     nâ†’âˆž                       2nÏƒÌ‚n6

                                                                                 21
almost surely, verifying condition (3.12) of Theorem 3.2 in Skovgaard (1981). Therefore, we conclude from (91), (94),
(95), Theorem 3.2 and Remark 3.4 in Skovgaard (1981) that an Edgeworth expansion for P âˆ— (Ts,n
                                                                                           âˆ—
                                                                                               âˆˆ B) holds almost
surely for all sets B such that Î¦((âˆ‚B) ) = O() (which includes all sets of the form (âˆ’âˆž, z])). In particular, (85)
holds by Theorem 3.2 in Skovgaard (1981) and Theorem 2.2.

Proof of Theorem 2.3: The first claim of the Theorem follows from Lemma B.1, Lemma A.3 and Lemma 5(a) in
Andrews (2002) while the second claim follows by Lemma B.3, Lemma A.6 and Lemma 5(a) in Andrews (2002).




References
Andrews, D. W. K. (2002). Higher-order improvements of a computationally attractive k-step bootstrap for
  extremum estimators. Econometrica, 70 119â€“162.

Bhatia, R. (1997). Matrix Analysis. Springer, New York.

Bhattacharya, R. N. and Ghosh, J. K. (1978). On the validity of the formal edgeworth expansion. The Annals
  of Statistics, 6 434â€“451.

Bhattacharya, R. N. and Rao, R. R. (1976). Normal Approximation and Asymptotic Expansions. John Wiley
  & Sons, New York.

Cameron, A. C., Gelbach, J. B. and Miller, D. L. (2008). Bootstrap-based improvements for inference with
  clustered errors. Review of Economics and Statistics, 90 414â€“427.

Cavaliere, G. and Taylor, A. M. R. (2008). Bootstrap unit root tests for time series with nonstationary volatility.
  Econometric Theory, 24 43â€“71.

Davidson, R. and Flachaire, E. (2008). The wild bootstrap, tamed at last. Journal of Econometrics, 146
  162â€“169.

Davidson, R. and MacKinnon, J. G. (2010). Wild bootstrap tests for iv regression. Journal of Business and
  Economic Statistics, 28 128â€“144.

de la Pena, V. H. and Gine, E. (1999). Decoupling: From Dependence to Independence. Springer-Verlag, New
  York.

Freedman, D. A. (1981). Bootstrapping regression models. The Annals of Statistics, 9 1218â€“1228.

GoncÌ§alves, S. and Meddahi, N. (2009). Bootstrapping realized volatility. Econometrica, 77 283â€“306.

Hall, P. (1992). The Bootstrap and Edgeworth Expansion. Springer-Verlag, New York.

Horowitz, J. L. (1997). Bootstrap methods in econometrics: Theory and numerical performance. In Advances in
  Economics and Econometrics: Theory and Applications, Seventh World Congress (D. M. Kreps and K. F. Wallis,
  eds.), vol. 3. Cambridge University Press.



                                                         22
Horowitz, J. L. (2001). The bootstrap. In Handbook of Econometrics (J. J. Heckman and E. Leamer, eds.), vol. 5,
  chap. 52. Elsevier.

Liu, R. Y. (1988). Bootstrap procedures under some non-i.i.d. models. The Annals of Statistics, 16 1696â€“1708.

Liu, R. Y. and Singh, K. (1987). On a partial correction by the bootstrap. The Annals of Statistics, 15 1713â€“1718.

Mammen, E. (1993). Bootstrap and wild bootstrap for high dimensional linear models. The Annals of Statistics,
  21 255â€“285.

Skovgaard, I. M. (1981). Transformation of an edgeworth expansion by a sequence of smooth functions. Sandi-
  navian Journal of Statistics, 8 207â€“217.

Skovgaard, I. M. (1986). On multivariate edgeworth expansions. International Statistical Review, 54 169â€“186.

White, H. (1982). Maximum likelihood estimation of misspecified models. Econometrica, 50 1â€“25.

Wu, C. F. J. (1986). Jacknife, bootstrap, and other resampling methods in regression analysis. Annals of Statistics,
  14 1261â€“1295.




                                                        23
