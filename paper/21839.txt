NBER WORKING PAPER SERIES

FREE TO CHOOSE: CAN SCHOOL CHOICE REDUCE STUDENT ACHIEVEMENT?
Atila Abdulkadiroglu
Parag A. Pathak
Christopher R. Walters
Working Paper 21839
http://www.nber.org/papers/w21839

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2015

Previously circulated as "School Vouchers and Student Achievement: First-Year Evidence from
the Louisiana Scholarship Program." We gratefully acknowledge funding from the National
Science Foundation. Data from the Louisiana Department of Education were made available to us
through the Institute for Innovation in Public School Choice, where Abdulkadiroglu and Pathak
are members of the scientific advisory board. Thanks also go to Josh Angrist, David Card, Raji
Chakrabarti, Melissa Clark, Pat Kline, Jesse Rothstein, and seminar participants at the MIT Labor
Economics Lunch, UC Berkeley, the 2016 All California Labor Economics Conference, the Fall
2016 APPAM Conference, UC San Diego, and the Stanford Opportunity Lab for suggestions and
comments. Nicole Gandre, Jon Schellenberg and Zhongji Wu provided excellent research
assistance. The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at http://www.nber.org/papers/w21839.ack
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
¬© 2015 by Atila Abdulkadiroglu, Parag A. Pathak, and Christopher R. Walters. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including ¬© notice, is given to the source.

Free to Choose: Can School Choice Reduce Student Achievement?
Atila Abdulkadiroglu, Parag A. Pathak, and Christopher R. Walters
NBER Working Paper No. 21839
December 2015, Revised December 2016
JEL No. I20
ABSTRACT
A central argument for school choice is that families value the freedom to exercise choice and can
make wise decisions. This principle may underlie why lottery-based school evaluations, which
exploit over-subscription due to excess demand, have almost always reported positive or zero
achievement effects. This paper reports on a striking empirical counterexample to these results.
We evaluate the Louisiana Scholarship Program (LSP), a school voucher plan providing public
funds for disadvantaged students to attend private schools of their choice. We exploit random
assignment of LSP vouchers at oversubscribed private schools to estimate the program‚Äôs effects
on test scores. LSP participation substantially reduces academic achievement: attendance at an
LSP-eligible private school lowers math scores by 0.4 standard deviations and increases the
likelihood of a failing math score by 50 percent. Voucher effects for reading, science and social
studies are also negative and large. Participating private schools charge below-average tuition,
and the program‚Äôs negative math effects are concentrated among participating schools with lower
tuition. Negative voucher effects may be due in part to selection of low-quality private schools
into the program.

Atila Abdulkadiroglu
Department of Economics
Duke University
213 Social Sciences Building
Durham, NC 27708
and NBER
atila.abdulkadiroglu@duke.edu
Parag A. Pathak
Department of Economics, E52-426
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and NBER
ppathak@mit.edu

Christopher R. Walters
Department of Economics
University of California at Berkeley
530 Evans Hall #3880
Berkeley, CA 94720-3880
and NBER
crwalters@econ.berkeley.edu

1

Introduction

The benefits and costs of increasing school choice in the US education system are a matter of continuing
debate. Choice advocates believe that increasing choice forces schools to compete for students, boosting
educational quality and promoting better matches between students and schools (Friedman, 1962; Hoxby,
2003). Proponents also cite surveys indicating that families are happier expressing choice, pointing to
economic revealed preference considerations as a rationale for choice (Howell and Peterson, 2002). The
additional freedom to choose may be the reason that numerous lottery-based studies of school choice, possible
only at schools where demand exceeds capacity, have found either positive or zero effects of choice programs
on student achievement. For instance, charter school lottery studies have found some charters increase
achievement markedly; impacts averaged over representative samples of charter schools are smaller but
rarely negative (Abdulkadiroƒülu et al., 2011; Angrist et al., 2013; Dobbie and Fryer, 2013; Chabrier et al.,
2016).1 Analyses of district-wide school choice plans show that attending a preferred public school yields
limited test score impacts while improving college quality (Cullen et al., 2006; Hastings et al., 2008; Deming
et al., 2014). Randomized evaluations of voucher plans in New York, Washington DC, and Dayton Ohio show
small average test score effects, with larger gains for some subgroups (Howell and Peterson, 2002; Mayer
et al., 2002; Howell et al., 2002; Krueger and Zhu, 2004; Wolf et al., 2007, 2010). Together, these findings
suggest that school choice programs generally produce zero or positive effects for participating students, and
almost never reduce student achievement.
This paper provides a striking contrast to the literature on lottery-based studies of school choice. We
evaluate the Louisiana Scholarship Program (LSP), a school choice program that provides private school
vouchers for disadvantaged Louisiana students attending low-performing public schools. Income-eligible
students enrolled in public schools graded ‚ÄúC‚Äù or below on an achievement-based rating system may apply
for an LSP voucher to cover tuition at an eligible private school. Private schools gain eligibility by applying to
the Louisiana Board of Elementary and Secondary Education to host LSP students (Louisiana Department
of Education, 2015a). If the number of eligible applicants to a private school exceeds the available seats,
LSP vouchers are distributed via stratified random lottery. We estimate causal effects of LSP vouchers by
comparing outcomes for lottery winners and losers in 2013, the first year after the LSP expanded throughout
Louisiana.
Lottery-based estimates show that LSP vouchers dramatically reduce academic achievement. Attendance
at an LSP-eligible private school is estimated to lower math scores by an average of 0.41 standard deviations
(œÉ) and reduce reading, science and social studies scores by 0.08œÉ, 0.26œÉ, and 0.33œÉ one year after the lottery.
LSP participation shifts the distribution of scores downward in all four subjects, increasing the likelihood
of a failing score by between 24 and 50 percent. These impacts are similar across family income levels
and geographic locations. LSP voucher effects are more negative in earlier grades, though vouchers reduce
1 An

exception is Angrist et al. (2013), a study that finds negative test score impacts for non-urban charter middle schools
in Massachusetts.

2

achievement in later grades as well.
We find suggestive evidence that the negative effects of the LSP may be linked to selection of lowquality private schools into the program. Compared to non-participating schools, LSP-eligible private schools
charge lower tuition, serve more minority students, and experience sharp relative declines in enrollment
prior to entering the program. Moreover, the program‚Äôs negative math impacts are concentrated among
the participating schools with lowest tuition. We find no evidence for other candidate explanations for
negative voucher impacts, including schools‚Äô inexperience with the voucher-eligible population, transitional
costs associated with the program‚Äôs statewide expansion, and the quality of fallback public school available
to LSP applicants. The LSP includes test-based accountability rules that aim to retrospectively identify and
remove low-quality schools, but lottery estimates are similar for schools that were subsequently sanctioned
for weak academic performance and for schools that were not sanctioned. This suggests that the program‚Äôs
accountability rules do not identify the low-quality schools that drive its negative achievement effects.
The rest of this article is organized as follows. The next section provides background on the Louisiana
Scholarship Program and describes the data used to evaluate it. Section 3 outlines our empirical approach
and reports lottery-based estimates of voucher effects. Section 4 documents the robustness of these estimates
to adjustments for differential attrition between lottery winners and losers. Section 5 explores mechanisms
that might explain negative voucher impacts. Section 6 concludes.

2

Data and Background

2.1

The Louisiana Scholarship Program

School voucher programs are expanding quickly in the United States: the number of students using educational vouchers increased by 130 percent between 2009 and 2015 (Alliance for School Choice, 2009, 2015).
Paralleling this national trend, the Louisiana Scholarship Program launched in New Orleans in 2008. Legislation proposed by Governor Bobby Jindal authorized statewide expansion of the program in 2012, and
it grew rapidly thereafter (Barrow, 2012). This can be seen in Figure 1, which plots the number of LSP
applicants, voucher recipients and participating schools by year. Through the 2011-2012 school year the LSP
awarded fewer than 2,000 vouchers annually for attendance at roughly 40 schools, mostly located in New
Orleans. By 2014, 12,000 students applied for more than 6,000 LSP vouchers to attend 126 private schools,
making the LSP the fifth-largest school voucher program in the US (Louisiana Department of Education,
2014a; Friedman Foundation for Educational Choice, 2015).
Eligibility for LSP vouchers is limited to students from families earning below 250 percent of the federal
poverty line. Applicants for grades 1 through 12 must also have attended public schools graded C, D, F
or T (turnaround) by the Louisiana School Performance Score (SPS) ratings system in the previous year.
Rising kindergarteners have no previous school and so are exempt from this requirement. SPS ratings are
based on a formula that combines test score levels, gains for low-achieving students, and (for high schools)

3

graduation rates; most of the weight is placed on test score levels. In 2014, 54 percent of Louisiana Public
Schools received SPS ratings low enough to qualify students for LSP vouchers (Louisiana Department of
Education, 2015b).
Students apply for LSP vouchers to cover tuition at eligible private schools of their choice. LSP vouchers
may also be used to attend public schools with SPS ratings of A or B, though few public schools participate
in the program. An LSP voucher pays the lesser of the private school‚Äôs tuition fee and the per-pupil funding
level of the student‚Äôs home district. LSP-eligible private schools typically charge less than public per-pupil
expenditure: in 2014 the average LSP voucher paid $5,311, while students‚Äô sending districts spent $8,605
(Louisiana Department of Education, 2014a). Private schools must accept the LSP voucher as full payment
of tuition; charging ‚Äútop-up‚Äù fees to LSP voucher recipients is prohibited.
Private schools gain eligibility to accept LSP voucher students by applying to the Louisiana Board of
Elementary and Secondary Education (BESE). The application requests a maximum number of LSP seats.
BESE reviews applications through site visits, financial audits, and health and safety assessments. If an
application is accepted, BESE authorizes a number of seats that may be less than the requested number.
Schools with more LSP voucher applicants than authorized seats must give priority to students with enrolled
siblings, those living nearby and those previously enrolled in D or F-rated public schools.2 Students may list
multiple schools on their LSP applications, and seats at a school are allocated in order of student preference
rankings, then by admissions priorities. Ties among equal priority students are broken by random lottery
(Louisiana Department of Education, 2015a).
To maintain eligibility private schools must undergo annual financial audits and administer Louisiana
state achievement tests to LSP students. Non-LSP students enrolled at participating schools are not required
to take these tests. Schools with more than 40 total voucher students or 10 voucher students per grade receive
a public Scholarship Cohort Index (SCI) score, an SPS-like rating based on the achievement of voucher
students. Schools with SCI scores less than 50 (equivalent to an F on the SPS scale) in the second year of
participation or a subsequent year are not eligible to enroll new voucher students the next year, though they
may retain students already enrolled. Schools without enough students to qualify for an SCI score may also
be barred from accepting new voucher students if less than 25 percent of their LSP enrollees earn ‚Äúproficient‚Äù
test scores. In 2013-2014, 28 private schools served enough LSP students to receive SCI scores and 15 were
sanctioned for scores below 50. Eight additional schools were sanctioned for low proficiency rates (Louisiana
Department of Education, 2014a).
The LSP has generated controversy since its inception. In response to a 2012 lawsuit filed by Louisiana‚Äôs
teachers unions, the state Supreme Court ruled that funds earmarked for public schools cannot constitutionally be used to fund the LSP. In response, the state legislature approved the use of funds not designated
for public education (Dreilinger, 2013b). In 2013 the US Department of Justice filed a lawsuit alleging that
the program interferes with federal desegregation orders by altering school racial composition. This lawsuit
2 Enrollees

in the Nonpublic School Early Childhood Development Program (NSECD), continuing students in transitional
grades, and transfers from ineligible private schools may also receive admission priority.

4

resulted in the requirement that applicant schools fill out ‚ÄúBrumfield-Dodd‚Äù reports documenting compliance with desegregation orders (Dreilinger, 2013c). LSP detractors cite persistently low test scores among
voucher students, while supporters note that the LSP serves very disadvantaged students and receives high
scores on surveys of parental satisfaction (Dreilinger, 2013a; Varney, 2014). The LSP is also relevant to more
general debates over school vouchers, serving as an example for similar proposed programs in other states
(Ardon and Candal, 2015). The expansion of voucher programs nationwide seems likely to be high on the
agenda of the current nominee for education secretary Betsy DeVos (Brown, 2016).

2.2

Data Sources

The Louisiana Department of Education provided data covering voucher applications, background characteristics, lottery outcomes and test scores for all students applying to the LSP between 2008 and 2012.
As shown in Figure 1, the program was not heavily oversubscribed prior to 2012. Our analysis therefore
focuses on students applying for LSP vouchers in Fall 2012, the first application cohort after the program
expanded statewide. Followup scores on Integrated Louisiana Educational Assessment Program (iLEAP) or
Louisiana Educational Assessment Program (LEAP) achievement tests are available for students in grades
three through eight.3 Primary outcomes are math, English Language Arts (ELA), science and social studies
LEAP and iLEAP scores in Spring 2013, the end of the academic year after LSP application. These scores
are in standard deviation units, normed using means and standard deviations for students in the New Orleans
Recovery School District (RSD) by grade and year.
The application data records students‚Äô rank-ordered choice lists of private schools, information for determining admission priorities, and voucher offers. We use this information to isolate random variation
in voucher receipt. Vouchers are randomly assigned within ‚Äúrisk sets‚Äù defined by application year, grade,
first-choice private school and priority status. Our lottery analysis sample consists of first-time LSP voucher
applicants for grades three through eight in 2012-2013, in risk sets in which some students were offered
vouchers and others were not.
Data on LSP applicants are supplemented with private school characteristics obtained from the Private
School Universe Survey (PSS), along with tuition information gathered via internet searches and phone calls.
The PSS, a biennial census of US private schools, collects data on enrollment by demographic group as well
as class size, instructional time, religious affiliation and geographic location. We matched the 2000-2012
waves of the PSS to voucher lottery data by school name and city, manually correcting small discrepancies
for a few inexact matches (e.g. missing hyphens or apostrophes). This procedure yielded matches for 142 of
159 schools that participated in the LSP between 2008 and 2013. We searched for tuition for all Louisiana
private schools in the 2012 PSS, and successfully collected data on 94 percent of LSP schools and 92 percent
of non-LSP schools. Appendix A provides further details on data processing and sample construction.
3 LEAP exams are taken in 4th and 8th grade; iLEAP exams are taken in 3rd, 5th, 6th and 7th. The iLEAP includes items
from nationally normed Iowa Tests of Basic Skills as well as items based on state testing criteria, while the LEAP includes only
items based on state criteria.

5

2.3

LSP Students and Schools

The LSP voucher applicant population is composed mostly of low-income minority students. Table 1 reports
descriptive statistics for first-time voucher applicants and enrollees in the 2012-2013 school year, as well as
for students enrolled in Louisiana public schools and the RSD. Eighty-six percent of LSP applicants are
Black compared to 45 percent in Louisiana and 94 percent in the RSD. LSP voucher applicants come from
families earning $15,471 on average. As shown in column (4), students who use LSP vouchers are slightly less
disadvantaged than the general population of applicants. Eighty-one percent of voucher recipients are Black
and average family income equals $17,389 for this group. These income levels are well below 250 percent of
the poverty line, the limit for LSP eligibility ($37,825 for a family of two and $57,625 for a family of four in
2012; see Department of Health and Human Services, 2012).
Private schools participating in the LSP differ systematically from other Louisiana private schools. This
can be seen in Table 2, which compares characteristics of LSP private schools to characteristics of other
private schools in the state. LSP schools open in both 2000 and 2012 experienced an average enrollment loss
of 13 percent over this time period, while other private schools grew 3 percent on average. LSP schools also
charge lower prices: average tuition is $4,898 for LSP schools and $5,760 for non-LSP schools, a difference
of roughly 15 percent. Most Louisiana private schools are associated with religious groups, but LSP schools
are more likely to be affiliated with the Catholic church than other schools. LSP schools also serve more
Black students and have larger student/teacher ratios than do non-LSP schools. Instructional time per day
and per year is comparable for these two groups.
Column (2) of Table 2 describes LSP schools that were oversubscribed and therefore admitted students
by random lottery in Fall 2012. These schools are the basis for our analysis of LSP voucher effects. Oversubscribed schools are smaller and serve more Black students than other LSP schools but are otherwise
generally similar. Columns (4) through (6) report corresponding statistics for schools in cities with at least
one LSP school and one non-LSP school. Characteristics in this matched city sample are similar to the
broader sample in columns (1) through (3), suggesting that differences between LSP and non-LSP schools
are not explained by geographic differences in private school markets.
Figure 2 presents a more complete investigation of enrollment trends by plotting average annual enrollment for a balanced panel of private schools open in both 2000 and 2012. Schools are permanently
categorized as LSP for this analysis if they received an LSP voucher student at any time through 2013-2014.
The resulting sample covers 93 of the 159 schools that ever participated in the LSP. Enrollment levels were
slightly higher in 2000 for schools that eventually opted in to the voucher program than for other private
schools. Mean enrollment began to decline for LSP schools around 2006, while enrollment was roughly constant for other schools until 2010. Enrollment fell in both groups after 2010, but this decline was sharper
among LSP schools. As a result, LSP schools were roughly 10 percent smaller than non-LSP schools by the
time the voucher program expanded statewide in 2012-2013.

6

3

Lottery Estimates of Voucher Effects

3.1

Empirical Framework

The primary equation of interest for our empirical analysis is

Yi = Œ≤Pi +

X

Œ≥` di` + Xi0 Œ¥ + i ,

(1)

`

where Yi is a test score for student i and Pi is an indicator equal to one if this student uses an LSP voucher
to attend a private school. The di` are a mutually exclusive and exhaustive set of lottery risk set dummies
indicating combinations of application school and priority status. Xi is a vector of baseline covariates
included to increase precision (gender, race, NSECD status, and family income quartiles).
Decisions to participate in the LSP may be related to potential academic achievement, so ordinary least
squares (OLS) estimation of equation (1) may not recover causal effects of voucher use. We therefore employ
a lottery-based instrumental variables (IV) strategy to estimate voucher effects. Let Zi denote an indicator
equal to one if student i was offered an LSP voucher. We estimate equation (1) by two-stage least squares
(2SLS), with first stage equation
Pi = œÄZi +

X

œÅ` di` + Xi0 Œ∏ + Œ∑i .

(2)

`

Two-stage least squares estimates are obtained via OLS estimation of (1) after substituting PÃÇi , the predicted
value from (2), for Pi . The voucher offer instrument Zi is randomly assigned within risk sets and therefore
independent of family background and other determinants of potential achievement. Assuming that voucher
offers only influence test scores through LSP participation and weakly increase the likelihood of participation
for all students, the 2SLS estimate of Œ≤ may be interpreted as a local average treatment effect (LATE), an
average causal effect of participation for ‚Äúcompliers‚Äù induced to attend private schools by LSP vouchers
(Imbens and Angrist, 1994; Angrist et al., 1996).

3.2

Covariate Balance

Within lottery risk sets, students offered LSP vouchers should look much like students not offered vouchers.
Table 3 presents a check on this by comparing baseline characteristics for voucher lottery winners and losers.
These calculations are restricted to our lottery analysis sample, which includes 1,412 first-time applicants for
grades three through eight in risk sets subject to random assignment in Fall 2012. Column (1) displays mean
characteristics for lottery losers, while column (2) reports coefficients from regressions of baseline variables on
the voucher offer indicator Zi , controlling for risk set indicators. Column (3) shows corresponding coefficients
for the 88 percent of applicants with followup test score data. Demographic characteristics and income
distributions are similar for lottery winners and losers, indicating that random assignment was successful.
Mean differences for individual characteristics are small, and p-values for joint tests of balance across all

7

baseline characteristics give no cause for concern.

3.3

IV Estimates

Lottery estimates show that LSP vouchers reduce academic achievement. Table 4 reports results for Spring
2013 math, ELA, science and social studies LEAP/iLEAP scores. As shown in column (1), lottery offers
boost the probability of voucher use by 68 percentage points in the year following the lottery. This estimate
corresponds to the first-stage coefficient œÄ in equation (2). Column (2) shows reduced form differences in
test scores between lottery winners and losers, obtained by substituting Yi for Pi on the left-hand side of
(2). Voucher lottery losers outscore winners by 0.28œÉ in math, 0.06œÉ in ELA, 0.18œÉ in science, and 0.23œÉ in
social studies.
Because the IV models estimated here are just-identified, 2SLS estimates of Œ≤ in equation (1) equal
ratios of corresponding reduced form and first stage estimates. These estimates appear in column (3). The
2SLS coefficients show that LSP participation lowers math scores by 0.41œÉ one year after the lottery, and
reduces ELA, science and social studies scores by 0.08œÉ, 0.26œÉ and 0.33œÉ, respectively. Estimates for math,
science, and social studies are highly statistically significant, though the estimate for ELA is insignificant
at conventional levels. Here and elsewhere, standard errors are clustered by risk set.4 Column (4) shows
corresponding OLS estimates. OLS and 2SLS estimates are very similar, suggesting little selection into
voucher use within lottery risk sets. The OLS estimates are negative and statistically significant in all four
subjects.
Together, the estimates in Table 4 clearly demonstrate that attendance at LSP-eligible private schools
reduces test scores for voucher recipients. It‚Äôs worth benchmarking the sizes of these effects against the
impacts of important educational interventions evaluated in the recent literature. Rouse (1998) estimates
that participation in the Milwaukee Parental Choice Program boosts math scores by 0.08 ‚àí 0.12œÉ per year.
Evidence from the Tennessee STAR experiment indicates that cutting class size by one third increases
achievement by roughly 0.2œÉ (Krueger, 1999; Chetty et al., 2011), while estimated standard deviations
of achievement impacts across teachers and schools range from 0.1 ‚àí 0.2œÉ (Chetty et al., 2014a; Angrist
et al., forthcoming). Studies of effective charter schools show annual score gains between 0.2œÉ and 0.4œÉ
(Abdulkadiroƒülu et al., 2011; Dobbie and Fryer, 2011; Angrist et al., 2012; Curto and Fryer, 2014). The
negative impacts of LSP vouchers, on the order of 0.3 ‚àí 0.4œÉ in math, science and social studies, are therefore
comparable in magnitude to some of the largest effects documented in recent studies of education programs.

3.4

Effects on Performance Categories

Louisiana‚Äôs educational accountability system groups LEAP and iLEAP scores into five performance categories: Unsatisfactory, Approaching Basic, Basic, Mastery or Advanced. High stakes are attached to these
4 Clustering

by risk set accounts for negative dependence between voucher offers for students in the same lottery. With a
fixed number of offers available, an offer for one student reduces the likelihood of offers for other students in the same risk set.

8

categories for both students and schools. Fourth and eighth grade students must score Approaching Basic
or above in math and ELA, and Basic or above in at least one subject, to be promoted to the next grade
(Louisiana Board of Elementary and Secondary Education, 2015). The SPS school rating system awards
points for each student scoring at least Basic; scores below Basic are considered failures and awarded no
points (Louisiana Department of Education, 2015b).
We investigate the effects of LSP vouchers on high-stakes performance categories in Table 5. Specifically,
this table reports 2SLS estimates of equation (1) for a series of outcomes equal to one if a student scores
at or above each performance category. To benchmark these effects we also report control complier means
(CCMs), average non-LSP outcomes for voucher lottery compliers. Appendix B provides the details of CCM
estimation and other methods for characterizing compliers employed in the analysis to follow.
LSP vouchers shift students into lower performance categories and increase the likelihood of failing scores.
Attending an LSP-eligible private school reduces the probability of scoring at least Approaching Basic in
math by 16 percentage points from a base of 80 percentage points, a result that can be seen in column (1)
of Table 5. This implies an 80 percent increase in Unsatisfactory math scores (16 points on a base of 20).
Vouchers also increase probabilities of Unsatisfactory scores in the other three subjects, though these effects
are smaller in magnitude. Column (2) shows that voucher use substantially boosts the likelihood of failing
tests in every subject: impacts on the probability of scoring at least Basic are negative and statistically
significant for all four tests. LSP participation reduces the probability that compliers earn passing math
scores by 21.6 percentage points from a base of 56.7, implying a 50 percent increase in failures (21.6/43.3).
Corresponding increases for ELA, science and social studies are 24, 29, and 33 percent.
Effects on higher score categories are smaller in absolute magnitude, but some imply large proportionate
impacts. As shown in column (3), vouchers cut the probability of qualifying for Mastery or above in math
by 6.7 percentage points from a base of 9.0, a 74 percent reduction. The corresponding decrease in science
is 65 percent (4.0/6.2). Fewer than 2 percent of compliers earn Advanced scores in each subject and impacts
on this category are small.
The bottom row of Table 5 looks specifically at the effects of LSP participation on the probability
that fourth and eighth grade students earn LEAP scores sufficient for grade promotion in the public school
accountability system. The outcome here is an indicator equal to one if a student scores at least Approaching
Basic in both math and ELA, and Basic or above in at least one subject. LSP participation more than doubles
the likelihood that students fail to qualify for grade promotion. Voucher use reduces the probability of passing
by 28.4 percentage points from a base of 78.6, implying a 133-percent increase in failures (28.4/21.4). Private
schools are not required to promote or retain students on the basis of state achievement test scores, of course,
but this result shows that LSP vouchers have substantial effects on an outcome used for high-stakes decisions
elsewhere.

9

3.5

Effects on Score Distributions

To develop a more complete picture of the distributional effects of LSP vouchers we estimate marginal test
score densities for compliers lotteried into and out of the program. Let Yi (1) and Yi (0) denote potential
scores for student i as a function of the LSP participation ‚Äútreatment‚Äù Pi . We characterize distributions of
these potential outcomes by estimating equations of the form
1
hK



Yi ‚àíy
h



√ó Pi = œÑy Pi +

X

Œ∫`y di` + Xi0 Œªy + viy ,

(3)

`

instrumenting Pi with the voucher offer indicator Zi as before. Here K(u) is a symmetric kernel function
maximized at u = 0 and h is a bandwidth. Under standard regularity conditions the 2SLS estimate of œÑy is
a consistent estimate of the density function of Yi (1) for voucher lottery compliers evaluated at y (Angrist
et al., 2016; Walters, 2014). Estimates of the density of Yi (0) for compliers are obtained by substituting
(1 ‚àí Pi ) for Pi on both sides of (3). Our implementation evaluates complier densities at a grid of 100 points
using a Gaussian kernel and Silverman‚Äôs (1986) rule-of-thumb bandwidth.
Figure 3 reveals that LSP participation shifts the entire achievement distribution downward for all four
subjects. This results in lower treated densities at high test score levels and higher treated densities at low
levels relative to distributions for non-treated compliers lotteried out of the program. The Figure also reports
Kolmogorov-Smirnov test statistics equal to maximum differences in estimated complier CDFs, along with
bootstrap p-values from tests of distributional equality (see Appendix B). These tests result in rejections of
distributional equality at conventional levels for all four subjects (p ‚â§ 0.02).

3.6

Effects on Subgroups

Previous studies of voucher programs and Catholic private schools have emphasized effect heterogeneity
across demographic groups, particularly by race (Neal, 1997; Howell and Peterson, 2002). Eighty-six percent of LSP applicants are Black so there is insufficient power to split our sample by race. We instead
investigate heterogeneity by family income and location, which may capture differences in resources and
schooling opportunities. Columns (1) and (2) of Table 6 report estimates from 2SLS models that interact
LSP participation with family income and add the interaction of income with the lottery offer as a second
instrument, controlling for a main effect of income. The income interaction is insignificant in all subjects,
implying similar effects for richer and poorer students. Columns (3) and (4) compare effects for students in
New Orleans and Baton Rogue, Louisiana‚Äôs two largest urban centers, or elsewhere. These estimates show
similar effects for urban centers and other locations, though estimates for New Orleans and Baton Rogue
are imprecise due to small samples.
A large literature evalutes the effects of Catholic private schools on student outcomes (Neal, 1997; Altonji
et al., 2005). Columns (5) and (6) of Table 7 report LSP voucher impacts by Catholic affiliation. Effects
are similar for Catholic and non-Catholic schools. The estimated effect for social studies is more negative

10

for Catholic schools, but this difference is only marginally significant and may be a chance finding given the
large number of splits examined. These estimates indicate that Catholic LSP schools do not improve test
scores for voucher applicants.
Columns (7) and (8) of Table 6 report effects by grade, which are relevant for understanding the effects
of LSP vouchers on human capital accumulation. Results here suggest that impacts of LSP participation
are more negative for younger children. Students in grades three through five lose 0.62œÉ in math, an
effect three times as large as the loss for students in grades six through eight (0.21œÉ). Similarly, vouchers
reduce ELA scores by 0.3œÉ for younger children, while the ELA estimate for older children is positive and
marginally significant. These cross-grade differences in effects are statistically significant at conventional
levels (p ‚â§ 0.01). Estimates of science and social studies effects are also more negative for younger applicants,
though differences for these subjects are not statistically significant.

4

Attrition

Even with random assignment of LSP vouchers, non-random attrition from the sample may compromise the
comparability of lottery winners and losers, possibly generating selection bias. Column (1) of Table 7 shows
that followup rates for the lottery sample are high: test scores are observed for at least 83 percent of lottery
losers in each subject. As shown in column (2), however, followup scores are more likely to be observed for
lottery winners than for losers. Specifically, the probability of an observed score is 8 percentage points higher
for lottery winners conditional on risk sets and baseline demographics. This difference is likely due to the
fact that LSP participants are tested in private schools for accountability purposes, while non-participants
who exit the public school system are not followed. It‚Äôs worth noting that baseline characteristics remain
balanced between winners and losers in the sample with followup scores, which can be seen in column (3) of
Table 3. Nonetheless, we cannot be assured of balance on unobserved characteristics.
We conduct two analyses to assess the robustness of our results to selective attrition. The first drops
lottery risk sets with large attrition differentials and reports estimates for the remaining sample. The second
constructs nonparametric bounds on local average treatment effects. The latter approach is in the spirit of
Lee (2009), who derives sharp bounds on treatment effects in randomized experiments under a monotonicity
assumption on the attrition process. Engberg et al. (2014) apply similar methods in a lottery-based research
design with imperfect compliance, an approach we follow here. Intuitively, if a voucher offer weakly reduces
the likelihood of attrition for all students, the usual LATE framework must be augmented with an additional
set of ‚Äúat risk‚Äù compliers who exit the sample when denied an offer. This prevents identification of the mean
treated outcome for the subgroup of compliers who remain in the sample, but this mean can be bounded
using observed response probabilities and quantiles of the outcome distribution. Appendix C formalizes this
argument and details the methods we use to construct bounds for LATE.
Adjustments for differential attrition do not overturn the conclusion that LSP participation reduces

11

achievement. Columns (4) through (6) of Table 7 report results after dropping risk sets with the largest
attrition differentials. This trimmed sample is constructed by computing risk set-specific differential attrition
rates, ordering students according to the rate for their risk set, and dropping the 25 percent of students with
largest differentials. Column (4) shows that followup rates in the remaining sample are roughly 90 percent,
and column (5) shows that differences in attrition between lottery winners and losers are small and no longer
statistically significant. As can be seen in column (6), 2SLS estimates of voucher effects are essentially
unchanged by the trimming procedure. Combined with the observation that baseline characteristics remain
balanced in the sample with followup scores, these results suggest that the attrition process is not very
selective. Our full sample lottery estimates are therefore likely to be reliable.
Columns (7) and (8) display estimated bounds on local average treatment effects for compliers. These
bounds are relatively wide owing to the large difference in attrition rates between lottery winners and losers.
Upper bounds for math, science and social studies are negative, however, and the associated confidence
intervals rule out small positive effects. The estimated upper bound for math is ‚àí0.18œÉ, and this estimate
is statistically significant at the 5-percent level. The conclusion that LSP vouchers reduce math scores is
therefore robust to this conservative adjustment for differential attrition.

5

Mechanisms

The negative effects of the LSP are surprising in view of the positive or zero effects found in studies of other
oversubscribed school choice programs. Table 8 compares math achievement effects and program rules for
the LSP and several other voucher programs evaluated in the recent literature. Other programs use roughly
similar income eligibility limits and rules for determining maximum voucher payments. Like the LSP, most
other programs also allow vouchers to be used for tuition at religious schools, and some require private schools
to opt in to participation. The LSP is fairly unusual in prohibiting families from topping up the voucher
payment when it falls short of private school tuition, which may limit incentives for expensive, high-quality
private schools to opt in. At the same time, the Milwaukee Parental Choice Program also prohibited top-up
payments at the time of Rouse‚Äôs (1998) evaluation, and this program increased achievement.
Overall, Table 8 shows that there is nothing distinctive about the basic structure of the LSP that would
be expected to yield negative achievement effects. We next assess several potential mechanisms that might
explain the negative effects of LSP vouchers: lack of private school experience with state tests and the LSPeligible population, problems associated with statewide expansion, disruption effects due to school switching,
the quality of public schools attended by LSP lottery losers, and negative selection of private schools into the
program. While this investigation is necessarily more speculative than our lottery-based analysis of program
impacts, we find suggestive evidence that negative voucher effects are linked to selection of lower-quality
private schools into LSP participation.

12

5.1

Experience with the LSP Program

Our estimates capture effects for students applying for LSP vouchers for 2012-2013, a year during which
the LSP expanded statewide. Private schools may have been inexperienced with standardized tests and
unfamiliar with the needs of LSP students during this transitional period. New participating schools also
had little time to adapt their curricula to match the content of state exams. This lack of experience with
LSP students and the program in general may have contributed to the LSP‚Äôs negative effects.
Table 9 presents the results of three analyses that shed light on this hypothesis. Columns (1) and (2)
compare effects for private schools that entered the LSP in 2012-2013 to schools that entered in prior years.
Earlier entrants had more time to adjust to state assessments and were more experienced with the program
before statewide expansion. Estimated effects for early and late entrants are negative and similar in all four
subjects. Evidently, the negative effects of the LSP are not driven by private schools new to the program.
Along similar lines, columns (3) and (4) of Table 9 investigate differences in effects between the transitional
2012-2013 cohort and earlier waves of applicants. Lack of oversubscription in the program‚Äôs early years
prevents a lottery-based analysis for earlier cohorts. As shown in Table 4, however, 2SLS and OLS estimates
for 2012-2013 are very similar, suggesting modest unobserved differences between applicants that accept and
decline vouchers. We therefore report OLS estimates for applicant cohorts prior to 2012, with the caveat
that these estimates may be affected by selection bias. OLS estimates for students applying from 2008 to
2011 are negative and similar to corresponding estimates for the 2012 cohort. This suggests that the negative
effects of LSP participation were present before expansion and are not a temporary artifact of the effort to
scale the program up statewide.5
Finally, to explore the role of mismatch between private school curricula and state exams, columns (5)
and (6) of Table 9 report estimates from 2SLS models that interact LSP participation with the share of
students at a school receiving LSP vouchers. The voucher share is jackknifed to remove the influence of a
student‚Äôs own enrollment choice. The average voucher enrollment share above the median of this measure
is 0.42. This implies that some participating private schools administer tests to a large fraction of their
students, and therefore have a strong incentive to tailor instruction to the content of state exams. Results
here show that if anything, schools serving more voucher students appear to generate larger achievement
losses than other schools. The estimates are negative for schools both above and below the median voucher
share, with slightly more negative math and social studies effects for schools above the median. Together,
the results in Table 9 provide no evidence that lack of experience with the LSP or temporary problems due
to the statewide expansion are responsible for the program‚Äôs negative effects.

5 Consistent with this evidence, a recent followup analysis by Mills and Wolf (2016) documents that the negative effects of
the LSP persist into the second year of participation for the 2012-2013 cohort. Their results show a large baseline imbalance
in the number of schools listed by lottery winners and losers, however, along with significantly smaller first-stage impacts on
LSP participation than we find in Table 4. This suggests that their data are not adequate to reconstruct the LSP voucher
assignment process.

13

5.2

School Switching and Disruption Effects

LSP participants switch from public schools to private schools. School switching may account for the negative
effects of LSP vouchers if moving between schools disrupts student learning. This explanation is implausible
for two reasons, however. First, typical estimates of the disruptive effect of school switching are small. For
example, Hanushek et al. (2004) estimate that switching reduces math achievement by roughly 0.03œÉ on
average. Second, school switching is a feature of all lottery-based evaluations of school choice programs,
and many of these studies (including the other voucher programs in Table 8) show zero or positive effects in
the first post-lottery year (Abdulkadiroƒülu et al., 2011; Cullen et al., 2006; Howell and Peterson, 2002; Wolf
et al., 2010). School switching alone is therefore insufficient to explain negative voucher impacts.

5.3

Public School Fallbacks

Lottery-based estimates capture causal effects of LSP participation relative to the schools that applicants
would otherwise attend. Recent research demonstrates that some public charter schools in New Orleans
generate very large test score gains (Abdulkadiroƒülu et al., 2015). If voucher lottery losers attend these or
other high-performing schools, the negative effects of LSP participation may be due to high scores in public
school fallbacks rather than low performance at private schools. To some extent this issue is addressed by
the distributional estimates in Figure 3, which show that mean untreated scores for compliers are below
mean scores in the New Orleans RSD. This indicates that complier scores are not especially high at fallback
public schools. Nevertheless, a proper interpretation of the effects of the LSP requires understanding the
mix of schools that define the voucher complier counterfactual.
We estimate characteristics of complier fallback schools with the equation
Cs(i) √ó (1 ‚àí Pi ) = œà(1 ‚àí Pi ) +

X

¬µ` di` + Xi0 Œ± + Œæi ,

(4)

`

instrumenting (1 ‚àí Pi ) with the voucher offer Zi . Here s(i) indicates the school attended by student i and
Cs(i) is a characteristic of this school. By the same logic underlying the density estimation procedure based
on equation (3), the 2SLS coefficient œà captures the average of Cs(i) for compliers denied the opportunity to
use LSP vouchers (Abadie, 2002).
Table 10 describes counterfactual schools for voucher compliers. Columns (1) and (2) report mean school
characteristics for offered and non-offered students, and column (4) reports 2SLS estimates of equation
(4). A voucher offer reduces the probability of attending a charter school from 0.14 to 0.04 and lowers the
probability of attending another public school from 0.77 to 0.22. As shown in column (4), these changes
imply that 14 percent of compliers attend charter schools when denied an offer, and 82 percent attend other
public schools. The remaining 4 percent attend schools of unknown type, possibly other private schools.
The last two rows of column (4) report fractions of students passing math and ELA tests at fallback
schools. These results come from estimation of (4) setting Cs equal to the fraction of students at school s

14

scoring Basic or above. Sixty-one percent of compliers‚Äô peers earn passing scores in math, and 57 percent
pass ELA. These rates are well below the Louisiana state average (roughly 70 percent in each subject) and
slightly below the RSD average (66 and 60 percent in math and ELA; Louisiana Department of Education,
2014b). This investigation of counterfactuals shows that negative effects of LSP participation are not due
to atypical fallback schools: compliers denied vouchers score below the RSD average and attend mostly
traditional public schools with achievement comparable to schools in a disadvantaged urban district. The
negative impacts of LSP vouchers are instead due to extremely low scores for compliers in private schools.

5.4

Private School Selection

The descriptive statistics in Table 2 show that the LSP attracts private schools with low tuition and declining
enrollment. This suggests that low-quality private schools may be disproportionately likely to opt in to
the LSP. To investigate whether negative selection of private schools can explain the program‚Äôs negative
achievement impacts, Table 11 reports relationships between voucher effects and measures of school quality
among participating schools.
Columns (1) and (2) show estimates from 2SLS models interacting LSP participation with a school‚Äôs
change in log enrollment between the two PSS waves prior to entering the LSP. The interaction coefficients
for changes in log enrollment are close to zero and statistically insignificant, implying that effects are not
especially negative for private schools experiencing the fastest enrollment losses. Estimates of this interaction
effect are reasonably precise: we can reject that an additional 10 percent annual decline in enrollment is
associated with a 0.08œÉ decrease in a school‚Äôs math effect.6
On the other hand, math achievement effects are significantly more negative for schools with lower tuition.
Columns (3) and (4) report results from models that interact LSP participation with tuition. The estimates
show that a $1,000 increase in tuition is associated with a 0.26œÉ increase in a school‚Äôs math effect. The
interaction model predicts a math effect of ‚àí0.06œÉ for a private school with average tuition, compared to
‚àí0.36œÉ for an average oversubscribed LSP school.7 Tuition interaction estimates for the other three subjects
are also positive, though somewhat smaller and statistically insignificant.
The tuition interaction estimates suggest that selection of low-quality schools into LSP participation can
account for a substantial portion of the program‚Äôs negative math effects. The LSP‚Äôs strict test-based accountability sanctions aim to mitigate this type of selection by removing low-performing participating schools.
Similar sanctions appear to be effective at improving achievement in other contexts (Chiang, 2009; Rockoff
and Turner, 2010; Rouse et al., 2013; Deming et al., forthcoming); we might expect the LSP to improve over
time if its sanctions successfully identify the participating schools with most negative achievement effects.
Columns (5) and (6) of Table 11 assess the efficacy of the program‚Äôs accountability rules by comparing effects
6 The upper bound of a 95 percent confidence interval for the additional achievement impact associated with a 100 percent
increase in enrollment is ‚àí0.09œÉ + 1.96 √ó 0.22œÉ = 0.34œÉ. Enrollment changes are computed over a two-year period, so this
corresponds to a 50 percent annual change. The upper bound of a 95 percent confidence interval for a 10 percent annual change
is therefore 0.34œÉ √ó 0.2 = 0.07œÉ.

7 Using the statistics in Table 2, the predicted effect for an average school is ‚àí0.36œÉ + 0.26œÉ √ó $5,760‚àí$4,653 = ‚àí0.06œÉ.
$1,000

15

for the 23 schools sanctioned for low scores in 2013-2014 to effects for unsanctioned schools. Estimates for
these two groups are similar and not statistically distinguishable. This implies that the unadjusted test
score levels used to determine LSP sanctions are not a reliable guide to causal achievement effects: voucher
impacts are equally negative for schools not sanctioned for low scores. In other words, existing accountability
rules do not appear to identify the low-quality schools that drive the negative effects of the LSP.

6

Conclusion

This paper shows that the expansion of school choice need not improve student achievement. The Louisiana
Scholarship Program, a large school choice program providing private school vouchers to poor students
attending low-performing public schools, reduces academic achievement one year after program entry, lowering mean test scores and increasing the likelihood of failure in math, reading, science, and social studies.
These impacts are consistent across subgroups and geographic locations, and are robust to adjustments for
differential attrition between lottery winners and losers.
Private schools must apply for eligibility to enroll LSP voucher students. Survey data indicate that LSPeligible schools charge lower tuition and experience rapid enrollment declines relative to other nearby private
schools before entering the program. In addition, tuition is inversely related to math achievement effects
among participating schools. These facts suggest that the LSP attracts a negatively-selected group of private
schools with substantial negative achievement effects. A further question is why this form of selection occurs
for the LSP but not for other similarly-structured voucher programs evaluated in the previous literature.
The links between the effects of school choice, program design, and market characteristics is an important
direction for future research.
The estimates reported here capture causal impacts of oversubscribed private schools. Evidently, many
parents wish to enroll their children in these schools despite their negative test score impacts. This may reflect
a lack of knowledge about achievement effects, or demand for school characteristics other than academic
quality, such as religious instruction or a change in peer environment. Existing estimates of the link between
achievement gains and adult earnings suggest that the perceived value of these other amenities would have
to be extraordinarily large to explain the choice to participate in the LSP. For example, Chetty et al. (2014b)
estimate that a one standard deviation increase in math scores due to improved teacher quality boosts the
present discounted value of lifetime earnings by about $42,000 at age 12. This implies that the test score
losses suffered by LSP participants in one year may be worth as much as $17,000 per student.8
Parent knowledge and program effectiveness may change over time as low-performing schools face accountability sanctions and information about school quality is revealed. Our estimates show that schools
8 Chetty et al. (2014b) calculate that the average present discounted value of earnings at age 12 in the US equals $522,000
in 2010 dollars. They estimate that a one standard deviation increase in teacher value-added in a single grade boosts adult
earnings by 1.3 percent. The standard deviation of teacher math value-added in student test score units equals 0.16œÉ, implying
that a one standard deviation improvement in test scores is worth $522, 000 √ó 0.013/0.16 = $42, 413. If the link between test
score effects and earnings effects is similar for the LSP, the math estimate in Table 4 translates into an earnings impact of
‚àí0.41 √ó $42, 413 = ‚àí$17, 389.

16

not sanctioned for low achievement perform just as poorly as sanctioned schools, indicating that level-based
accountability standards may not be sufficient to identify and remove unproductive schools unless the threat
of sanctions induces significant changes in future years. The evolution of choice behavior and program effects
for future cohorts is another key question for ongoing work.

17

0

0

30

3000

6000
Students

Schools
60
90

9000

120

150

12000

Figure 1: Louisiana Scholarship Program Students and Schools

2009

2010

2011

2012

2013

2014

Year
All schools
Applicants

NOLA schools
Vouchers

Notes: This figure plots the number of schools participating in the Louisiana Scholarship Program
(LSP; left axis) and the number of students applying for and receiving LSP vouchers (right axis). The
blue line shows the total number of schools by year, and the red line shows the number of schools in
New Orleans. The green line shows the number of applicants, and the orange line shows the number
of vouchers awarded. The vertical dashed line indicates the 2011-2012 school year.

320

340

Average enrollment
360
380
400

420

Figure 2: Enrollment Trends in Louisiana Private Schools

2000

2002

2004

2006
Year

All private schools
Other private schools

2008

2010

2012

Voucher schools

Notes: This figure plots average annual enrollment for private schools in Louisiana. Enrollment is
measured from the Private School Universe Survey (PSS). Voucher schools are defined as schools
eligible for the Louisiana Scholarship Program at any time through 2013-2014. Schools are included
if they have available PSS data in both 2000 and 2012, which covers 93 of 159 voucher schools.

.5

.5

Figure 3. Test Score Distributions for Voucher Compliers

.4

KS statistic: 0.13
Bootstrap p-value: 0.02

0

0

.1

.1

.2

Density
.3

Density
.2
.3

.4

KS statistic: 0.23
Bootstrap p-value: 0.00

-4

-3

-2

-1
0
Test score (std. dev.)

Treated compliers

1

-4

2

-3

-2

-1
0
Test score (std. dev.)

Treated compliers

Untreated compliers

2

Untreated compliers

B. ELA

.5

.6

A. Math

1

KS statistic: 0.20
Bootstrap p-value: 0.00

0

0

.1

.2

Density

Density
.2
.3

.4

.4

KS statistic: 0.20
Bootstrap p-value: 0.00

-4

-3

-2
-1
Test score (std. dev.)

Treated compliers

C. Science

0

1

Untreated compliers

2

-4

-3

-2

-1
0
Test score (std. dev.)

Treated compliers

1

2

Untreated compliers

D. Social Studies

Notes: This figure plots marginal potential test score distributions for Louisiana Scholarship Program voucher lottery compliers. Treated densities are estimated using 2SLS
regressions of the interaction of a kernel density function and an LSP participation indicator on the participation indicator, instrumented by a random offer indicator and
controlling for risk set dummies and baseline demographics. Untreated densities are estimated by replacing participation with one minus participation in this 2SLS procedure.
All models use a Gaussian kernel and the Silverman (1986) rule of thumb bandwidth. Vertical dashed lines indicate mean potential outcomes. KS statistics are maximum
differences in complier CDFs. The bootstrap procedure used to test distributional equality is described in Appendix B.

Table 1. Descriptive Statistics for Students
Louisiana Scholarship Program
Louisiana
RSD
Applicants
Enrollees
(1)
(2)
(3)
(4)
0.487
0.473
0.489
0.539
0.451
0.939
0.861
0.805
0.044
0.031
0.031
0.039
0.468
0.010
0.086
0.131
0.004
0.006

Female
Black
Hispanic
White
NSECD
Household income: Mean
25th percentile
Median
75th percentile
N

-

-

15,471
1,300
12,000
24,781

17,400
1,452
15,000
28,032

715,012

14,689

3,723

1,019

Notes: Columns (1) and (2) show statistics for students enrolled in Louisiana and Recovery School District
(RSD) public schools in grades 3-8 in the 2012-2013 school year. These statistics are obtained from the
Louisiana Department of Education website. Column (3) shows statistics for first-time applicants to Louisiana
Scholarship Program (LSP) schools in grades 3-8 for 2012-2013. Column (4) shows statistics for LSP
enrollees.

Table 2: Descriptive Statistics for Private Schools
All Louisiana private schools
LSP voucher
Oversubscribed
Other private
LSP voucher
schools
LSP schools
schools
schools
(1)
(2)
(3)
(4)
311
243
323
323

Enrollment in 2012

Matched city sample
Oversubscribed
LSP schools
(5)
239

Other private
schools
(6)
349

Enrollment growth, 2000-2012

-12.4%

-16.1%

2.8%

-7.7%

-10.4%

1.9%

Tuition

$4,898

$4,653

$5,760

$5,115

$4,740

$6,430

Fraction black

0.327

0.433

0.158

0.387

0.517

0.188

Fraction hispanic

0.020

0.021

0.037

0.021

0.021

0.041

Fraction white

0.622

0.517

0.752

0.564

0.433

0.714

Catholic school

0.645

0.679

0.391

0.594

0.619

0.367

Other religious affiliation

0.274

0.304

0.421

0.313

0.357

0.430

Student/teacher ratio

13.5

12.7

11.5

13.3

12.3

10.9

Days in school year

178.6

178.9

177.9

178.8

178.9

177.7

Hours in school day

6.8

6.8

6.7

6.8

6.7

6.7

124

56

235

96

42

158

N

Notes: This table reports characteristics of private schools in Louisiana using data from the Private School Universe Survey (PSS). Column (1) shows statistics for schools eligible
for Louisiana Scholarship Program vouchers at any time through 2012-2013. Column (2) shows statistics for voucher schools with applicants subject to random assignment in 20122013. Column (3) shows statistics for non-LSP private schools. Columns (4), (5) and (6) report statistics for schools in cities with both LSP and non-LSP private schools. The
second row reports average enrollment growth between 2000 and 2012 for schools with available data in both years. The third row measures tuition in the most recent available year,
usually 2015-2016. Tuition is available for 94 percent of voucher schools and 92 percent of other private schools.

Table 3. Covariate Balance
Offer differential
Non-offered mean All applicants
With followup
(1)
(2)
(3)
Female
0.474
0.012
0.008
(0.033)
(0.035)
Black
0.900
-0.034*
-0.028
(0.021)
(0.022)
Hispanic
0.030
0.003
0.001
(0.012)
(0.013)
White
0.050
0.019
0.018
(0.015)
(0.016)
NSECD
0.004
-0.001
-0.002
(0.006)
(0.006)
Household income
15,410
1,636
1,025
(1097)
(1118)
Income below p 25
0.254
-0.007
0.000
(0.029)
(0.030)
Income below p 50
0.503
-0.030
-0.017
(0.035)
(0.036)
Income below p 75
0.753
-0.048
-0.028
(0.034)
(0.035)
Joint p -value
N

-

0.659

0.932

1,412

1,248

Notes: This table compares characteristics of offered and non-offered applicants to
Louisiana Scholarship Program schools for grades 3-8 in the 2012-2013 school year.
The sample is restricted to first-time applicants subject to first choice random
assignment. Column (1) reports mean characteristics for applicants not offered a seat,
while columns (2) and (3) report differences between offered and non-offered
applicants. These differences come from regressions that control for risk set indicators.
The sample in column (3) is restricted to applicants with follow-up test scores. p 25 , p 50
and p 75 refer to the 25th, 50th and 75th percentiles of household income in the nonoffered group. The last row shows p -values from tests that all differentials equal zero.
Standard errors, clustered by risk set, are in parentheses.
* significant at 10%; ** significant at 5%; *** significant at 1%.

Table 4. Two-stage Least Squares Estimates of Voucher Effects on Test Scores
First stage
Reduced form
2SLS
OLS
Subject
(1)
(2)
(3)
(4)
Math
0.679***
-0.281***
-0.413***
-0.386***
(0.029)
(0.061)
(0.091)
(0.066)
N
1247
ELA

0.679***
(0.029)

-0.055
(0.053)

N
Science

-0.181***
(0.066)

N

-0.263***
(0.095)

-0.282***
(0.065)

-0.331***
(0.089)

-0.270***
(0.059)

1221
0.690***
(0.030)

N

-0.120**
(0.056)

1248
0.689***
(0.030)

Social studies

-0.081
(0.079)

-0.229***
(0.060)
1220

Notes: This table reports estimates of the effects of attendance at Louisiana Scholarship Program (LSP)
voucher schools on LEAP/iLEAP test scores. The sample includes first-time voucher applicants subject
to first choice random assignment applying to grades 3-8 in 2012-2013. Column (1) reports first stage
effects of a first-choice offer on attendance at an LSP school, while column (2) reports reduced form
effects of offers on test scores. Column (3) reports two-stage least squares estimates of the effects of
LSP participation, and column (4) reports corresponding ordinary least squares estimates. All models
control for risk set indicators and baseline demographics (sex, race, NSECD and indicators for
household income quartiles). Standard errors, clustered by risk set, are in parentheses.
* significant at 10%; ** significant at 5%; *** significant at 1%.

Table 5. Voucher Effects on Test Score Performance Categories
Approaching
Basic
Mastery
Basic or above
or above
or above
Advanced
Subject
(1)
(2)
(3)
(4)
Math
-0.156***
-0.216***
-0.067***
-0.012
(0.045)
(0.047)
(0.024)
(0.011)
CCM
[0.802]
[0.567]
[0.090]
[0.017]
N
1214
ELA
CCM
N
Science
CCM
N
Social studies
CCM
N
Qualify for promotion
(4th and 8th grade)
CCM
N

-0.022
(0.034)
[0.844]

-0.107**
(0.047)
[0.563]

-0.032
(0.031)
[0.100]

0.002
(0.011)
[0.009]

1222
-0.035
(0.047)
[0.810]

-0.096**
(0.041)
[0.759]

-0.153***
-0.040**
(0.049)
(0.018)
[0.468]
[0.062]
1211

-0.001
(0.004)
[0.003]

-0.160***
(0.045)
[0.513]
1209

-0.004
(0.003)
[0.004]

-0.026
(0.020)
[0.044]

-0.284***
(0.086)
[0.786]
347

Notes: This table reports 2SLS estimates of the effects of attendance at Louisiana
Scholarship Program (LSP) schools on LEAP/iLEAP score categories. The dependent
variable in each column is an indicator for scoring in the relevant performance category or
higher. The last row shows effects on passing LEAP exams for 4th and 8th graders. Passing
requires scores of Approaching Basic or above in math and ELA and Basic or above in at
least one subject. See notes to Table 4 for a description of the 2SLS model specification.
Control complier means (CCM), mean outcomes for non-offered compliers, are shown in
brackets. Standard errors, clustered by risk set, are in parentheses.
* significant at 10%; ** significant at 5%; *** significant at 1%.

By family income ($1,000s)

Subject
Math

Main effect
(1)
-0.413***
(0.093)

N
P- value
ELA

1247
0.636
-0.078
(0.082)

N
P- value
Science

N
P- value

-0.001
(0.004)
1248
0.787

-0.266***
(0.096)

N
P- value
Social studies

Interaction
(2)
-0.002
(0.005)

1221
0.708

-0.086
(0.083)
1115

-0.090
(0.119)
643

-0.412
(0.298)
132

-0.242**
(0.099)
1089

-0.542**
(0.268)
132

3rd-5th
(7)
-0.631***
(0.140)
664

-0.222
(0.135)
630

6th-8th
(8)
-0.207*
(0.110)
583
0.016

-0.301**
(0.119)
664

0.135*
(0.080)
584
0.002

-0.238
(0.148)
463

-0.396***
(0.119)
656

0.936
-0.301***
(0.092)
1088

0.394

-0.034
(0.121)
472

By grade

0.747

0.588
0.003
(0.005)

1220
0.473

-0.034
(0.259)
133
0.847

0.002
(0.005)

-0.338***
(0.091)

Table 6. Voucher Effects by Subgroup
By location
By Catholic affiliation
New Orleans/
Baton Rouge
Other
Catholic
Not Catholic
(3)
(4)
(5)
(6)
-0.276
-0.436***
-0.462***
-0.286***
(0.284)
(0.095)
(0.144)
(0.104)
133
1114
643
471
0.593
0.319

-0.470***
-0.105
(0.135)
(0.106)
629
463
0.035

-0.132
(0.137)
565
0.145

-0.387***
(0.131)
656

-0.276**
(0.122)
564
0.542

Notes: This table reports estimates from 2SLS models that interact Louisiana Scholarship Program (LSP) participation with observed student and school characteristics.
Columns (1) and (2) interact LSP participation with family income. Income is de-meaned in the estimation sample, so that main effects are at the mean. Column (3) shows
effects for students in New Orleans and Baton Rougue, while column (4) shows effects for students in other places. Columns (5) and (6) report effects for Catholic schools and
schools with other or no religious affiliation. Column (7) shows effects for students applying in third through fifth grade, while column (8) shows effects for students applying
in sixth through eighth. See notes to Table 4 for a description of the 2SLS model specification. P -values are from tests of the hypothesis that interaction effects or subgroup
differences are zero. Standard errors, clustered by risk set, are in parentheses.
* significant at 10%; ** significant at 5%; *** significant at 1%.

Non-offered
followup rate
(1)
0.856

Subject
Math
N
ELA

0.857
N

Science

0.836
N

Social studies

0.835
N

Table 7. Robustness to Adjustments for Differential Attrition
Full sample
Without imbalanced risksets
Offer
Non-offered
Offer
2SLS
differential
2SLS estimate
followup rate
differential
estimate
(2)
(3)
(4)
(5)
(6)
0.079***
-0.413***
0.908
0.017
-0.397***
(0.091)
(0.013)
(0.099)
1412
1247
1059
962
0.078***
(0.015)
1412

-0.081
(0.079)
1248

0.905

0.078***
(0.016)
1412

-0.263***
(0.095)
1220

0.890

0.079***
(0.016)
1412

-0.331***
(0.089)
1221

0.888

Bounds
Lower
bound
(7)
-0.494***
(0.091)

Upper
bound
(8)
-0.178**
(0.091)
1412

0.019
(0.013)
1059

-0.098
(0.095)
958

-0.208***
(0.080)

0.006
(0.015)
1059

-0.272***
(0.104)
942

-0.362***
(0.096)

0.008
(0.015)
1059

-0.362***
(0.112)
941

-0.404***
(0.104)

0.101
(0.087)
1412
-0.016
(0.097)
1412
-0.032
(0.102)
1412

Notes: This table explores the robustness of estimated voucher effects on test scores to adjustments for differential attrition between offered and non-offered students.
Column (1) shows the fraction of non-offered applicants with followup test scores. Column (2) shows coefficients from regressions of a followup indicator on an offer
indicator, controlling for sex, race, NSECD status, income quartiles and risk set dummies. Column (3) shows the full-sample 2SLS estimates from Table 4. Columns (4)
through (6) order the sample by risk-set specific attrition differentials and drop the 25 percent of students from risk sets with the largest differentials. Column (4) shows
followup rates in the trimmed sample, column (5) shows offered/non-offered attrition differentials, and column (6) shows 2SLS estimates. Columns (7) and (8) report
nonparametric bounds on local average treatment effects of LSP participation, estimated via the method described in Appendix C. Standard errors, clustered by risk set, are
in parentheses.
* significant at 10%; ** significant at 5%; *** significant at 1%.

Program
Louisiana Scholarship Program
(LA)
DC Opportunity Scholarship Program
(Washington, DC)

Study
(1)
Authors' estimates

Wolf et al. (2007)

Table 8. Voucher Effects and Program Characteristics
Math effect
Funding
Eligibility
Voucher amount
(2)
(3)
(4)
(5)
-0.41ùúé***
Public
Income < 2.5 x FPL,
Min. of tuition
low-performing school and public PPE
a

Top up allowed Schools opt in Religious schools
(6)
(7)
(8)
No
Yes
Yes

0.13ùúé*

Public

Income < 1.85 x FPL

Min. of tuition
and $7,500 (2004)

Yes

b

Yes

Yes

Parents Advancing Choice in Education Howell et al. (2002)
(Dayton, OH)

0.08ùúé

c

Private

Income < 2 x FPL

Min. of 0.6 x tuition
and $1,200 (1998)

Yes

No

Yes

School Choice Scholarships Foundation Howell et al. (2002)
(New York, NY)

0.08ùúéc

Private

Income < 1.3 x FPL

$1,400 (1997)

Yes

No

Yes

c

Private

Income < 2.7 x FPL

Min. of 0.6 x tuition
and $1,700 (1998)

Yes

No

Yes

Washington Scholarship Fund
(Washington, DC)

Howell et al. (2002)

-0.02ùúé

Milwaukee Parental Choice Program
Rouse (1998)
0.12ùúé***d
Public
Income < 1.75 x FPL
Public PPEe
Noe
Yes
Noe
(Milwaukee, WI)
Notes: This table compares program characteristics and achievement effects for school voucher programs. Column (1) lists the article evaluating each program, and column (2) reports estimated
effects on first-year math achievement in standard deviation units. Estimates from studies that report intent-to-treat (ITT) estimates are rescaled by first-stage effects on private school participation.
Column (3) indicates whether a program is publicly or privately funded. Column (4) lists eligibility criteria, with income limits reported as a fraction of the federal poverty line (FPL). Column (5)
reports the maximum amount of the voucher at the time of the evaluation. PPE refers to per-pupil expenditure. Column (6) indicates whether a program allows parents to "top up" the voucher by
paying additional tuition beyond the maximum voucher amount. Column (7) indicates whether schools must opt in to the program to become eligible for voucher payments. Column (8) indicates
whether the voucher can be used to pay tuition at religious schools.
a

ITT estimate from Table 4-1 is scaled by first stage effect from Table 2-5.
Footnote 4 suggests that families rarely paid out of pocket when tuition exceeded the voucher amount.
c
ITT estimates from Table 4 are scaled by baseline math standard deviations from Table 3 and first stage effects from Table 6.
d
This is an annual gain estimate from a student fixed effects specification pooling data for four years (Table VI, column (2)).
e
Since Rouse's (1998) study, the program rules have changed to reduce the maximum voucher below public per-pupil expenditure, allow a limited amount of top-up, and allow participation of religious schools.
* significant at 10%; ** significant at 5%; *** significant at 1%.
b

Subject
Math
N
P- value
ELA
N
P- value
Science
N
P- value
Social studies
N
P- value

Table 9. Voucher Effects by Experience with the Program
By year school entered program
By student application year (OLS)
In 2012
Before 2012
2008-2011
2012
(1)
(2)
(3)
(4)
-0.410***
-0.425**
-0.350***
-0.442***
(0.103)
(0.174)
(0.095)
(0.050)
757
490
615
3261
0.942
0.389
-0.078
(0.100)
758

-0.083
(0.131)
490

-0.185*
(0.110)
616

0.978
-0.291**
(0.114)
739

-0.515***
(0.115)
613

0.723

-0.286***
(0.041)
3189

-0.423***
(0.128)
613

-0.249*
(0.131)
533

-0.219
(0.153)
558
0.058

-0.295***
(0.041)
3189
0.339

-0.030
(0.114)
573
0.704

0.060
-0.291*
(0.157)
482

0.745

-0.100
(0.127)
540

0.865
-0.217
(0.174)
482

-0.354***
(0.110)
738

-0.165***
(0.040)
3259

By voucher enrollment share
Below median
Above median
(5)
(6)
-0.347**
-0.434***
(0.158)
(0.100)
540
572
0.000

-0.290**
(0.124)
532

-0.338**
(0.150)
558
0.005

Notes: This table reports estimates from models interacting Louisiana Scholarship Program (LSP) participation with measures of schools' experience
with the program. Column (1) shows 2SLS estimates for schools that entered the program in 2012, while column (2) reports estimates for schools
that participated in the program before 2012. Columns (3) and (4) report OLS estimates for students applying in 2008-2011 and 2012. The OLS
samples includes first-time applicants to LSP schools for grades 3-8 from the 2008-2009 school year through the 2012-2013 school year. OLS
models interact LSP participation with an indicator for applying before 2012, and control for first choice-year-grade indicators as well as sex, race,
NSECD status and family income quartile. Columns (5) and (6) show 2SLS estimates for schools above and below the sample median voucher
enrollment share. See notes to Table 4 for a description of the 2SLS model specification. P -values are from tests of the hypothesis that subgroup
differences are zero. Standard errors, clustered by risk set, are in parentheses.
* significant at 10%; ** significant at 5%; *** significant at 1%.

Table 10. Characteristics of Treatment and Fallback Schools for Voucher Applicants
All applicants
Voucher compliers
Offered
Not offered
Offered
Not offered
(1)
(2)
(3)
(4)
Voucher school
0.730
0.051
1.000
0.000
Charter school

0.044

0.140

0.000

0.141

Other public school

0.216

0.772

0.000

0.819

Unknown school type

0.010

0.037

0.000

0.040

Fraction Basic or above: Math

0.540

0.590

0.436

0.611

ELA

0.561

0.586

0.497

0.565

Notes: This table describes characteristics of schools attended by offered and non-offered applicants to the Louisiana
Scholarship Program. The sample includes first-time voucher applicants subject to first choice random assignment
applying to grades 3-8 in 2012-2013. Columns (1) and (2) compare characteristics of the schools attended by offered and
non-offered students. Columns (3) and (4) compare school characteristics for compliers who enroll in voucher schools in
response to random offers. Fractions scoring Basic or above in math and ELA cover all students attending public
schools, including non-applicants; for students attending voucher schools, these fractions include only voucher
applicants.

Subject
Math
N
P- value
ELA

Table 11. Voucher Effects by Measures of School Quality
By change in log enrollment
By tuition ($1,000s)
Main effect
Interaction
Main effect
Interaction
(1)
(2)
(3)
(4)
-0.352***
-0.092
-0.355***
0.263**
(0.098)
(0.223)
(0.091)
(0.121)
938
1050
0.679
0.030
-0.039
(0.091)

N
P- value
Science

-0.015
(0.332)
939
0.963

-0.214*
(0.111)
N
P- value

Social studies
N
P- value

-0.037
(0.087)
1051
0.114

-0.397
(0.276)

-0.196**
(0.100)

918
0.150
-0.273***
(0.104)

0.118
(0.113)

-0.265***
(0.090)

-0.023
(0.111)
575

-0.277*
(0.149)
653

-0.248**
(0.113)
568
0.876

0.170
(0.121)
1030
0.158

-0.129
(0.113)
673
0.501

1031
0.299
0.186
(0.313)

917
0.552

0.167
(0.106)

By performance sanction
Sanctioned
Not sanctioned
(5)
(6)
-0.384***
-0.452***
(0.118)
(0.139)
672
575
0.709

-0.322***
(0.125)
653

-0.341***
(0.129)
567
0.919

Notes: This table reports estimates from 2SLS models interacting Louisiana Scholarship Program (LSP) participation with measures of the quality of the private
schools to which students applied. Columns (1) and (2) show 2SLS estimates from a model interacting LSP participation with the change in log enrollment
between the two most recent PSS surveys prior to entering the program, instrumenting with the interaction of the change in log enrollment and the lottery offer.
The sample in these columns is restricted to schools for which PSS data are available. Columns (3) and (4) display 2SLS estimates interacting LSP participation
with tuition. The sample in these columns is restricted to schools with available tuition data. Column (5) reports effects for schools that were sanctioned for
academic performance in 2013-2014, and column (6) reports effects for schools that were not sanctioned. Interacting variables are de-meaned in the estimation
sample, so that main effects are at the mean. See notes to Table 4 for a description of the 2SLS model specification. P -values are from tests of the hypothesis that
interaction effects or subgroup differences are zero. Standard errors, clustered by risk set, are in parentheses.
* significant at 10%; ** significant at 5%; *** significant at 1%.

References
Abadie, A. (2002): ‚ÄúBootstrap tests for distributional treatment effects in instrumental variable models,‚Äù
Journal of the American Statistical Association, 97, 284‚Äì292.
Abdulkadiroƒülu, A., J. D. Angrist, S. Dynarski, T. J. Kane, and P. A. Pathak (2011): ‚ÄúAccountability and flexibility in public schools: Evidence from Boston‚Äôs charters and pilots,‚Äù Quarterly Journal of
Economics, 126(2), 699‚Äì748.
Abdulkadiroƒülu, A., J. D. Angrist, P. D. Hull, and P. A. Pathak (2015): ‚ÄúCharters without
lotteries: Testing takeovers in New Orleans and Boston,‚Äù IZA discussion paper no. 8985.
Alliance

for

School

Choice

(2009):

‚ÄúSchool

Choice

Yearbook

2008-2009,‚Äù

http://afcgrowthfund.org/yearbook.
‚Äî‚Äî‚Äî (2015): ‚ÄúSchool Choice Yearbook 2014-2015,‚Äù http://afcgrowthfund.org/yearbook.
Altonji, J. G., T. E. Elder, and C. R. Taber (2005): ‚ÄúSelection on observed and unobserved variables:
Assessing the effectiveness of Catholic schools,‚Äù Journal of Political Economy, 113, 151‚Äì184.
Angrist, J. D., S. R. Cohodes, S. M. Dynarski, P. A. Pathak, and C. R. Walters (2016): ‚ÄúStand
and deliver: Effects of Boston‚Äôs charter high schools on college preparation, entry and choice,‚Äù Journal of
Labor Economics, 34, 275‚Äì318.
Angrist, J. D., S. M. Dynarski, T. J. Kane, P. A. Pathak, and C. R. Walters (2012): ‚ÄúWho
benefits from KIPP?‚Äù Journal of Policy Analysis and Management, 31, 837‚Äì860.
Angrist, J. D., P. D. Hull, P. A. Pathak, and C. R. Walters (forthcoming): ‚ÄúLeveraging lotteries
for school value-added: Testing and estimation,‚Äù Quarterly Journal of Economics.
Angrist, J. D. and G. W. Imbens (1995): ‚ÄúTwo-stage least squares estimation of average causal effects
in models with variable treatment intensity,‚Äù Journal of the American Statistical Association, 90, 431‚Äì442.
Angrist, J. D., G. W. Imbens, and D. B. Rubin (1996): ‚ÄúIdentification of causal effects using instrumental variables,‚Äù Journal of the American Statistical Association, 91, 444‚Äì455.
Angrist, J. D., P. A. Pathak., and C. R. Walters (2013): ‚ÄúExplaining charter school effectiveness,‚Äù
American Economic Journal: Applied Economics, 5, 1‚Äì27.
Ardon, K. and C. S. Candal (2015): ‚ÄúModeling urban scholarship vouchers in Massachusetts,‚Äù Pioneer
Institute White Paper no. 134.
Barrow, B. (2012): ‚ÄúLouisiana Senate votes to expand vouchers, public charter schools,‚Äù The TimesPicayune, April 4th.

32

Brown, E. (2016): ‚ÄúTrump picks billionaire Betsy DeVos, school voucher advocate, as education secretary,‚Äù
The Washington Post, November 23rd.
Chabrier, J., S. R. Cohodes, and P. Oreopoulos (2016): ‚ÄúWhat can we learn from charter school
lotteries?‚Äù Journal of Economic Perspectives, 30, 57‚Äì84.
Chetty, R., J. N. Friedman, N. Hilger, E. Saez, D. W. Schanzenbach, and D. Yagan (2011):
‚ÄúHow does your kindergarten classroom affect your earnings? Evidence from Project STAR,‚Äù Quarterly
Journal of Economics, 126, 1593‚Äì1660.
Chetty, R., J. N. Friedman, and J. E. Rockoff (2014a): ‚ÄúMeasuring the impact of teachers I:
Evaluating bias in teacher value-added estimates,‚Äù American Economic Review, 104, 2593‚Äì2563.
‚Äî‚Äî‚Äî (2014b): ‚ÄúMeasuring the impact of teachers II: Teacher value-added and student outcomes in adulthood,‚Äù American Economic Review, 104, 2633‚Äì2679.
Chiang, H. (2009): ‚ÄúHow accountability pressure on failing schools affects student achievement,‚Äù Journal
of Public Economics, 93, 1045‚Äì1057.
Cullen, J. B., B. A. Jacob, and S. D. Levitt (2006): ‚ÄúThe effect of school choice on participants:
evidence from randomized lotteries,‚Äù Econometrica, 74, 1191‚Äì1230.
Curto, V. and R. G. Fryer (2014): ‚ÄúThe potential of urban boarding schools for the poor: Evidence
from SEED,‚Äù Journal of Labor Economics, 32, 65‚Äì93.
Deming, D. J., S. R. Cohodes, J. Jennings, and C. Jencks (forthcoming): ‚ÄúSchool accountability,
postsecondary attainment and earnings,‚Äù Review of Economics and Statistics.
Deming, D. J., J. S. Hastings, T. J. Kane, and D. O. Staiger (2014): ‚ÄúSchool choice, school quality,
and postsecondary attainment,‚Äù American Economic Review, 104, 991‚Äì1013.
Department of Health and Human Services (2012): ‚ÄúAnnual Update of the HHS Poverty Guidelines,‚Äù
Federal Register Notice.
Dobbie, W. and R. G. Fryer (2011): ‚ÄúAre high-quality schools enough to increase achievement among
the poor? Evidence from the Harlem Children‚Äôs Zone,‚Äù American Economic Journal: Applied Economics,
3, 158‚Äì187.
‚Äî‚Äî‚Äî (2013): ‚ÄúGetting beneath the veil of effective schools: Evidence from New York City,‚Äù American
Economic Journal: Applied Economics, 5, 28‚Äì60.
Dreilinger, D. (2013a): ‚ÄúHalf of Louisiana‚Äôs voucher students at D or F schools in program‚Äôs first year,
data shows,‚Äù The Times-Picayune, November 28th.

33

‚Äî‚Äî‚Äî (2013b): ‚ÄúLouisiana Supreme Court rules voucher funding violates the state Constitution,‚Äù The
Times-Picayune, May 7th.
‚Äî‚Äî‚Äî (2013c): ‚ÄúUS government sues to block vouchers in some Louisiana school systems,‚Äù The TimesPicayune, August 24th.
Engberg, J., D. Epple, J. Imbrogno, H. Sieg, and R. Zimmer (2014): ‚ÄúEvaluating education programs
that have lotteried admission and selective attrition,‚Äù Journal of Labor Economics, 32, 27‚Äì63.
Frangakis, C. E. and D. B. Rubin (2002): ‚ÄúPrincipal stratification in causal inference,‚Äù Biometrics, 58,
21‚Äì29.
Friedman, M. (1962): Capitalism and Freedom, Cambridge University Press.
Friedman

Foundation

for

Educational

Choice

(2015):

‚ÄúSchool

choice

in

America,‚Äù

http://www.edchoice.org/school-choice/school-choice-in-america.
Hanushek, E. A., J. F. Kain, and S. G. Rivkin (2004): ‚ÄúDisruption versus Tiebout improvement: the
costs and benefits of switching schools,‚Äù Journal of Public Economics, 88, 1721‚Äì1746.
Hastings, J. S., T. J. Kane, and D. O. Staiger (2008): ‚ÄúHeterogeneous preferences and the efficacy
of public school choice,‚Äù Working paper.
Howell, W. G. and P. E. Peterson (2002): The Education Gap: Vouchers and Urban Schools, Washington, DC: Brookings Institute Press.
Howell, W. G., P. J. Wolf, D. E. Campbell, and P. E. Peterson (2002): ‚ÄúSchool vouchers and
academic performance: results from three randomized field trials,‚Äù Journal of Policy Analysis and Management, 21, 191‚Äì217.
Hoxby, C. M. (2003): ‚ÄúSchool choice and school productivity: could school choice be a tide that lifts all
boats?‚Äù in The Economics of School Choice, ed. by C. M. Hoxby, Chicago, IL: University of Chicago
Press.
Imbens, G. W. and J. D. Angrist (1994): ‚ÄúIdentification and estimation of local average treatment
effects,‚Äù Econometrica, 62, 467‚Äì475.
Krueger, A. B. (1999): ‚ÄúExperimental estimates of education production functions,‚Äù Quarterly Journal
of Economics, 114, 497‚Äì532.
Krueger, A. B. and P. Zhu (2004): ‚ÄúAnother look at the New York City school voucher experiment,‚Äù
American Behavioral Scientist, 47, 658‚Äì698.
Lee, D. S. (2009): ‚ÄúTraining, wages and sample selection: Estimating sharp bounds on treatment effects,‚Äù
Review of Economic Studies, 76, 1071‚Äì1102.

34

Louisiana Board of Elementary and Secondary Education (2015): ‚ÄúBulletin 1566 - Pupil progression policies and procedures,‚Äù http://bese.louisiana.gov/documents-resources/policies-bulletins.
Louisiana
Report,

Department
2013-2014,‚Äù

of

Education

(2014a):

‚ÄúLouisiana

Scholarship

Program

Annual

https://www.louisianabelieves.com/docs/default-source/school-choice/2013-2014-

scholarship-annual-report.pdf.
‚Äî‚Äî‚Äî (2014b): ‚ÄúSpring 2014 LEAP Criterion-Referenced Test: State/District Achievement Level Summary
Report,‚Äù https://www.louisianabelieves.com/resources/library/test-results.
‚Äî‚Äî‚Äî (2015a): ‚ÄúLouisiana Scholarship Program 2015-2016 scholarship schools frequently asked questions,‚Äù
https://www.louisianabelieves.com/docs/default-source/school-choice/faq‚Äî2014-2015-scholarshipprogram.pdf.
‚Äî‚Äî‚Äî (2015b): ‚ÄúSchool Performance Scores,‚Äù https://www.louisianabelieves.com/accountability/schoolperformance-scores.
Mayer, D. P., P. E. Peterson, D. E. Myers, C. C. Tuttle, and W. G. Howell (2002): ‚ÄúSchool
choice in New York City after three years: An evaluation of the School Choice Scholarships Program.
Final report.‚Äù .
Neal, D. (1997): ‚ÄúThe effects of Catholic secondary schooling on educational achievement,‚Äù Journal of
Labor Economics, 15, 98‚Äì123.
Rockoff, J. E. and L. J. Turner (2010): ‚ÄúShort-run impacts of accountability on school quality,‚Äù
American Economic Journal: Economic Policy, 2, 119‚Äì147.
Rouse, C. (1998): ‚ÄúPrivate school vouchers and student achievement: Evidence from the Milwaukee Choice
Program,‚Äù Quarterly Journal of Economics, 113, 553‚Äì602.
Rouse, C. E., J. Hannaway, D. Goldhaber, and D. Figlio (2013): ‚ÄúFeeling the Florida heat? How
low-performing schools respond to voucher and accountability pressure,‚Äù American Economic Journal:
Economic Policy, 5, 251‚Äì281.
Silverman, B. W. (1986): Density Estimation for Statistics and Data Analysis, London: Chapman and
Hall.
Varney, J. (2014): ‚ÄúOne group that loves school vouchers? Parents,‚Äù The Times-Picayune, April 22nd.
Wald, A. (1940): ‚ÄúThe fitting of straight lines if both variables are subject to error,‚Äù The Annals of
Mathematical Statistics, 11, 284‚Äì300.
Walters, C. R. (2014): ‚ÄúThe Demand for Effective Charter Schools,‚Äù NBER working paper no. 20640.

35

Wolf, P., B. Gutmann, M. Puma, B. Kisida, L. Rizzo, N. Eissa, M. Carr, and M. Silverberg (2010): ‚ÄúEvaluation of the DC opportunity scholarship program: final report,‚Äù National Center for
Education Evaluation, Institute for Education Sciences Report 2010-4018.
Wolf, P. J., B. Gutmann, M. Puma, L. Rizzo, and N. Eissa (2007): ‚ÄúEvaluation of the DC opportunity
scholarship program: impacts after one year,‚Äù National Center for Education Evaluation, Institute for
Education Sciences Report 2007-4009.

36

Appendix A: Data
This project combines Louisiana Scholarship Program application and test score data provided by the
Louisiana Department of Education with private school characteristics from the Private School Universe
Survey. This appendix describes each data file used in the analysis and details the procedures used to clean
and match them.

A.1 Application data
The Louisiana Department of Education provided data on all LSP voucher applications submitted between
Fall 2008 and Fall 2012. The raw data includes 16,739 application records with information on a ranked
list of at least one and up to five private school choices. Additional variables code application grade and
year, admission priorities based on sibling status, NSECD status, geographic proximity, and previous school,
and the school for which a student was offered a voucher (if any). The application data also include basic
demographics (race and sex) along with family income used to determine eligibility for the LSP.
We extract first-time 2012-2013 applicants to grades 3-8 from the raw data. From this subsample we
select students in first-choice priority classes within which there is variation in first-choice voucher offers.
This leaves 1,412 students subject to random assignment at first choice schools. Within this sample the
lottery offer is coded as an indicator for a voucher offer at the first choice school, and risk sets are coded as
interactions of application grade and first choice school.

A.3 Test score data
The second data source in our analysis is a database of 7,187 LEAP and iLEAP scores on tests taken by LSP
applicants between Spring 2009 and Spring 2013. The test score file was meant to follow LSP applicants in
grades 3-8 for one year after application. Each record includes a set of variables recording scaled versions of
math, ELA, science, and social studies scores, along with performance category codes for these scores. We
standardize the scaled scores using means and standard deviations for RSD students in each subject, grade
and year. Students in the test score file are distinguished by a scrambled identifier called the randomid.
The file also includes a school identifier called the sitecd coding the testing location; this identifier is used in
most public data files provided by the Louisiana Department of Education. We use the sitecd field to merge
school names, LSP private school status, charter school and public school status, and SPS scores for public
schools into the data file. LSP participation is coded as an indicator equal to one if a student is tested at
an LSP-participating private school.
We drop records with no test score information. Two percent of student identifiers have multiple test
score records in the same year. Among these duplicates we give preference to (a) tests taken at LSP private
schools; and (b) complete records with no missing scores for any test. If a student has two sets of incomplete
scores and neither test was taken at an LSP school, we combine observations into one record with the most

37

complete possible set of scores. This leaves less than 0.5 percent of students with multiple conflicting records;
among these, we pick one record at random. Finally, the test score file is merged with the LSP applicant file
using the randomid, which appears in both files. Eighty-nine percent of LSP applicants in grades 3-8 have
a matching record in the test score file.

A.4 Private School Universe Survey
Characteristics for Louisiana private schools are measured from the Private School Universe Survey (PSS).
The PSS is a census of all US private schools conducted every two years by the National Center for Education
Statistics. PSS data files are available from 1990 through 2012. Key variables include total enrollment and
enrollment shares by race, number of teachers, religious affiliation, instructional time (length of school day
and year), geographic identifiers (state, county, zip code, city name and exact address), and a school identifier
that is constant over time.
We used school names and cities to match a list of participating LSP private schools provided by the
Louisiana Department of Education to PSS data from 2012, 2010 and 2008. Many LSP schools had exact
matches in the PSS, and others produced close inexact matches because of differences in punctuation or
naming conventions between the two data sets. For example, the PSS name field often included the modifier
‚Äúschool‚Äù when the LSP database did not (as in ‚ÄúST JOSEPH ELEMENTARY‚Äù vs. ‚ÄúST JOSEPH ELEMENTARY SCHOOL‚Äù). We manually matched these cases when school names and cities clearly made sense.
This resulted in matches for 142 of 159 LSP participant private schools. The remaining 17 schools either
had no close match in the PSS or multiple close matches with ambiguity regarding the correct school.

A.5 Tuition data
We searched for tuition data for the 359 Louisiana private schools present in the 2012 PSS. The search
took place in two phases. First, we checked school websites for 2015-2016 tuition information, converting
monthly or annual rates to 10-month tuition for all schools. Some schools listed discounts for certain
student categories, such as church members; we used the undiscounted rate in these cases. Second, when
no information was listed on a school‚Äôs website, we contacted the main office by phone. The combination of
online searches and phone calls yielded tuition for 116 of 124 voucher schools (94 percent) and 216 of 235
non-voucher schools (92 percent).

38

Appendix B: Complier Characteristics
This appendix describes the methods used to compute characteristics and potential outcome distributions
for LSP voucher lottery compliers. As in the local average treatment effect (LATE) framework of Imbens and
Angrist (1994), let Yi (1) and Yi (0) denote potential test scores as a function of the LSP treatment indicator
Pi , and let Pi (1) and Pi (0) denote potential treatment choices as a function of the voucher lottery offer Zi .
Observed treatment is Pi = Pi (Zi ) and the observed outcome is Yi = Yi (Pi ). Xi denotes a vector of baseline
covariates.
Assume the vector (Yi (1), Yi (0), Pi (1), Pi (0), Xi ) is independent of Zi and that Pi (1) ‚â• Pi (0) for all i,
with strict inequality for a positive measure of students. Then for any measurable function g(Yi , Xi ), Lemma
2.1 in Abadie (2002) implies
E [g(Yi , Xi )Pi |Zi = 1] ‚àí E [g(Yi , Xi )Pi |Zi = 0]
= E [g (Yi (1), Xi ) |Pi (1) > Pi (0)] ,
E [Pi |Zi = 1] ‚àí E [Pi |Zi = 0]

(5)

E [g(Yi , Xi )(1 ‚àí Pi )|Zi = 1] ‚àí E [g(Yi , Xi )(1 ‚àí Pi )|Zi = 0]
= E [g (Yi (0), Xi ) |Pi (1) > Pi (0)] .
E [1 ‚àí Pi |Zi = 1] ‚àí E [1 ‚àí Pi |Zi = 0]

(6)

The left-hand side of (5) is the Wald (1940) instrumental variables estimand using Zi as an instrument
for Pi in an equation for g(Yi , Xi )Pi . Likewise, the left-hand side of (6) is the IV estimand using Zi as an
instrument for (1 ‚àí Pi ) in an equation for g(Yi , Xi )(1 ‚àí Pi ). Equations (5) and (6) imply that these IV
procedures yield mean values of g(Yi , Xi ) for compliers in the treated and untreated states.
We apply these results to estimate complier characteristics and potential outcome distributions. In
practice our IV models control for lottery risk set indicators; the arguments in Angrist and Imbens (1995)
imply that the resulting 2SLS estimates are weighted averages of within-risk-set complier means. Control
complier means in Table 5 are obtained by setting g(Yi , Xi ) = Yi in equation (6). Counterfactual school
characteristics in Table 10 are obtained by setting g(Yi , Xi ) = Cs(i) . (The school characteristic Cs(i) may be
viewed as an additional outcome variable.)
Treated and untreated complier densities in Figure 3 are obtained by setting g(Yi , Xi ) =

1
hK



Yi ‚àíy
h



in (5) and (6). Density estimation also requires selecting the bandwidth h. We use Silverman‚Äôs (1986)
rule-of-thumb bandwidth for the Gaussian kernel function, given by:
h = 1.06œÉy n‚àí1/5 ,
where œÉy is the standard deviation of the outcome and n is the sample size. A complication arises in using
this rule for complier density estimation because standard deviations of complier outcomes and the number
of compliers in the data are unobserved. We estimate standard deviations of complier potential outcomes by
setting g(Yi , Xi ) equal to Yi and Yi2 in (5) and (6). This yields estimates of the first two noncentral moments
of Yi (1) and Yi (0) for compliers, which are then used to construct an estimate of œÉy for each potential
outcome. The expected number of treated compliers in the sample is n1c = pz ¬∑ œÄ ¬∑ n, where pz ‚â° P r [Zi = 1].

39

The number of treated compliers is the fraction of lottery winners times the population share of compliers
(equal to the first stage coefficient œÄ) times total sample size. Likewise, the expected non-treated complier
sample size is n0c = (1 ‚àí pz ) ¬∑ œÄ ¬∑ n. We plug in the empirical lottery offer probability and first stage coefficient
to these formulas to construct rule-of-thumb bandwidths appropriate for complier density estimation.
Figure 3 also reports bootstrap p-values from tests of the null hypothesis that treated and untreated
complier distributions are equal. The underlying tests are based on methods from Abadie (2002), who notes
that treated and untreated complier distributions are equal if and only if the distribution of Yi does not
depend on Zi . A test statistic for this hypothesis is the maximum difference in CDFs for the Zi = 1 and
Zi = 0 samples. Differences in CDFs are estimated by regressing 1 {Yi ‚â§ y} on Zi for 100 equally-spaced
values of y covering the support of Yi , controlling for risk set indicators. The Kolmogorov-Smirnov (KS)
statistic is the maximum of absolute values of the coefficients across these regressions.
A bootstrap distribution for the KS statistic is constructed by drawing samples with replacement stratified
by risk set, then randomly assigning simulated lottery offers to match the full-sample proportions offered
within each risk set. The KS statistic is then recomputed in each bootstrap sample. The bootstrap p-value
for a test of equality of treated and untreated complier distributions is the fraction of bootstrap KS statistics
greater than the full-sample KS statistic. We implement this procedure in Figure 3 using 250 bootstrap
trials.
Finally, to aid interpretation of the magnitudes of differences in distributions, the reported KS statistics
in Figure 3 are maximum differences in complier CDFs rather than maximum differences in offered and
non-offered CDFs. Complier CDFs are estimated by plugging 1 {Yi ‚â§ y} into (5) and (6) at the same 100
points used in the bootstrap tests for distributional equality.

40

Appendix C: Bounds on Voucher Effects
This appendix describes methods for bounding local average treatment effects in the presence of differential
attrition between lottery winners and losers. The arguments here follow those in Engberg et al. (2014),
adapted to the notation used in our analysis. As in Appendix B define potential outcomes Yi (p) and potential
treatments Pi (z), and assume these are independent of Zi . Now, however, let the treatment variable Pi take
three values: Pi ‚àà {0, 1, a}. When Pi = a, student i attrits from the sample and her outcome is not observed.
We make the following monotonicity assumption on responses to voucher offers:
Pi (1) 6= Pi (0) =‚áí Pi (1) = 1.
This restriction implies that any student who changes behavior in response to a voucher offer does so to
participate in the LSP program. In other words, no one exits LSP in response to an offer, and no one exits
the sample in response to an offer.
Under this assumption the population can be partitioned into the following groups:
1. Always takers: Pi (1) = Pi (0) = 1.
2. Never takers: Pi (1) = Pi (0) = 0.
3. Always attriters: Pi (1) = Pi (0) = a.
4. Compliers: Pi (1) = 1, Pi (0) = 0.
5. At risk: Pi (1) = 1, Pi (0) = a.
This classification scheme is a version of the principal stratification framework of Frangakis and Rubin
(2002), which divides an experimental population into groups defined by responses to random assignment.
The twist here relative to the usual LATE model is the presence of at risk students. Without such students,
IV estimates of voucher effects are consistent for local average treatment effects. With these students, LATE
is not identified and we must bound it.
Let œÄ g denote population shares of the five groups for g ‚àà {at, nt, aa, c, ar}. Likewise, let ¬µgp denote
the mean of Yi (p) for group g and p ‚àà {0, 1}. The average causal effect of voucher receipt for compliers is
LAT E ‚â° ¬µc1 ‚àí ¬µc0 . To bound this quantity, first note that the population shares of each group are identified
since
P r [Pi = 1|Zi = 0] = œÄ at ,
P r [Pi = 0|Zi = 1] = œÄ nt ,
P r [Pi = a|Zi = 1] = œÄ aa ,
P r [Pi = 0|Zi = 0] ‚àí P r [Pi = 0|Zi = 1] = œÄ c ,

41

P r [Pi = a|Zi = 0] ‚àí P r [Pi = a|Zi = 1] = œÄ ar .
Mean observed outcomes for non-treated students by offer status are:
E [Yi |Pi = 0, Zi = 1] = ¬µnt
0 ,
E [Yi |Pi = Zi = 0] =



œÄ nt



œÄ c +œÄ nt

¬µnt
0 +



œÄc
œÄ c +œÄ nt



¬µc0 .

These expressions show that the never taker mean is observed among students who decline offers, and the
group of non-offered, non-treated students is a mixture of never takers and compliers. The non-treated
complier mean can then be backed out as
¬µc0 =

(œÄ c + œÄ nt )E [Yi |Pi = Zi = 0] ‚àí œÄ nt E [Yi |Pi = 0, Zi = 1]
.
œÄc

It is straightforward to show that the moments in this equation are equivalent to those used in equation (6)
when g(Yi , Xi ) = Yi , substituting 1 {Pi = 0} for (1 ‚àí Pi ) since Pi is now an unordered treatment.
The presence of at-risk students prevents us from backing out ¬µc1 in similar fashion. To bound it, note
that we can identify the distribution of Yi (1) for the pooled population of compliers and at-risk students.
Specifically, we have
E [1 {Yi ‚â§ y} 1 {Pi = 1} |Zi = 1] ‚àí E [1 {Yi ‚â§ y} 1 {Pi = 1} |Zi = 0]
= P r [Yi (1) ‚â§ y|Pi (1) 6= Pi (0)]
E [1 {Pi = 1} |Zi = 1] ‚àí E [1 {Pi = 1} |Zi = 0]

(7)

‚â° F1 (y).
This result follows by applying equation (5).
The minimum possible value of ¬µc1 occurs when compliers occupy the entire lower tail of this mixture
distribution. The complier share in the mixture is œÄ c /(œÄ c + œÄ ar ). Then
h


i
œÄc
¬µc1 ‚â• E Yi (1)|Yi (1) ‚â§ F1‚àí1 œÄc +œÄ
, Pi (1) 6= Pi (0)
ar

=

h
n

o
i
h
n

o
i
œÄc
œÄc
E Yi 1 Yi ‚â§ F1‚àí1 œÄc +œÄ
1 {Pi = 1} |Zi = 1 ‚àí E Yi 1 Yi ‚â§ F1‚àí1 œÄc +œÄ
1 {Pi = 1} |Zi = 0
ar
ar
E [1 {Pi = 0} |Zi = 0] ‚àí E [1 {Pi = 0} |Zi = 1]
‚â° ¬µmin ,

where the second line follows from another application of equation (5), rescaling appropriately by the proban

o
œÄc
bility that the event Yi ‚â§ F1‚àí1 œÄc +œÄ
occurs in the mixture of treated compliers and at-risk students.
ar
Similarly, an upper bound for the treated complier mean is
h
 ar 
i
¬µc1 ‚â§ E Yi (1)|Yi (1) ‚â• F1‚àí1 œÄcœÄ+œÄar , Pi (1) 6= Pi (0)

=

h
n
 ar o
i
h
n
 ar o
i
E Yi 1 Yi ‚â• F1‚àí1 œÄcœÄ+œÄar
1 {Pi = 1} |Zi = 1 ‚àí E Yi 1 Yi ‚â• F1‚àí1 œÄcœÄ+œÄar
1 {Pi = 1} |Zi = 0
E [1 {Pi = 0} |Zi = 0] ‚àí E [1 {Pi = 0} |Zi = 1]
‚â° ¬µmax .

42

Bounds on LATE are then
¬µmin ‚àí ¬µc0 ‚â§ LAT E ‚â§ ¬µmax ‚àí ¬µc0 .
Estimation of these bounds is implemented with the following steps:
1. Estimate the probabilities œÄ ar and œÄ c as minus the shifts in the probability of attrition and nonparticipation induced by the lottery offer.
2. Estimate the CDF of Yi (1) for the mixture of compliers and at-risk students using equation (7).

 ar 

œÄc
and F1‚àí1 œÄcœÄ+œÄar . This can be done by searching over
3. Use the estimated CDF to find F1‚àí1 œÄc +œÄ
ar
values of y to find the point that yields the appropriate value of F1 (y).
4. Use the expressions above to estimate ¬µmax and ¬µmin .
5. Estimate ¬µc0 using equation (6), setting g(Yi , Xi ) = Yi and substituting 1 {Pi = 0} for (1 ‚àí Pi ).
6. Construct bounds for LATE using the estimates of ¬µmax , ¬µmin and ¬µc0 .
After estimating the bounds we obtain standard errors by conducting 100 bootstrap replications of the
entire procedure. In practice risk set indicators and baseline covariates are included in all regressions used
to estimate group shares, CDFs, and mean potential outcomes.

43

