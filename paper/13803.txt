NBER WORKING PAPER SERIES

DO SEX OFFENDER REGISTRATION AND NOTIFICATION LAWS AFFECT CRIMINAL
BEHAVIOR?
J.J. Prescott
Jonah E. Rockoff
Working Paper 13803
http://www.nber.org/papers/w13803

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
February 2008

We thank Charles Calomiris, Amit Khandelwal, Ray Fisman, Matthew Gentzkow, Justin McCrary,
Tom Miles, Daniel Paravisini, Doug Staiger, and Toni Whited for their comments and suggestions,
as well as seminar participants at Columbia Business School, Northwestern Law School, Syracuse
University, the American Law and Economics Meetings, the Canadian Law and Economics Meetings,
and the NBER Working Group on the Economics of Crime. Reid Aronson, Erik Johnson, Rembrand
Koning, Nicholas Lee, Elias Walsh, Oliver Welch, and Julia Zhou provided excellent research assistance.
JJ Prescott gratefully acknowledges the John M. Olin Center for Law & Economics at University of
Michigan Law School for financial support for this project. Jonah Rockoff would like to thank the
Paul Milstein Center for Real Estate at Columbia Business School for research support. The views
expressed herein are those of the author(s) and do not necessarily reflect the views of the National
Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2008 by J.J. Prescott and Jonah E. Rockoff. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

Do Sex Offender Registration and Notification Laws Affect Criminal Behavior?
J.J. Prescott and Jonah E. Rockoff
NBER Working Paper No. 13803
February 2008
JEL No. K14,K4
ABSTRACT
In recent decades, sex offenders have been the targets of some of the most far-reaching and novel crime
legislation in the U.S. Two key innovations have been registration and notification laws which, respectively,
require that convicted sex offenders provide valid contact information to law enforcement authorities,
and that information on sex offenders be made public. Using detailed information on the timing and
scope of changes in state law, we study how registration and notification affect the frequency of sex
offenses and the incidence of offenses across victims, and check for any change in police response
to reported crimes. We find evidence that registration reduces the frequency of sex offenses by providing
law enforcement with information on local sex offenders. As we predict from a simple model of criminal
behavior, this decrease in crime is concentrated among "local" victims (e.g., friends, acquaintances,
neighbors), while there is little evidence of a decrease in crimes against strangers. We also find evidence
that community notification deters crime, but in a way unanticipated by legislators. Our results correspond
with a model in which community notification deters first-time sex offenses, but increases recidivism
by registered offenders due to a change in the relative utility of legal and illegal behavior. This finding
is consistent with work by criminologists suggesting that notification may increase recidivism by imposing
social and financial costs on registered sex offenders and making non-criminal activity relatively less
attractive. We regard this latter finding as potentially important, given that the purpose of community
notification is to reduce recidivism.

J.J. Prescott
University of Michigan Law School
950 Legal Research
625 South State Street
Ann Arbor, Michigan 48109-1215 USA
jprescott@umich.edu
Jonah E. Rockoff
Columbia University
Graduate School of Business
3022 Broadway #603
New York, NY 10027-6903
and NBER
jonah.rockoff@columbia.edu

1. Introduction
Criminal recidivism poses a serious risk to public safety. According to a recent Bureau
of Justice Statistics study, over two-thirds of released inmates will return to prison within a few
years, often for committing serious offenses (BJS (2002)). National Corrections Reporting
Program data show that approximately 40 percent of all criminals sent to prison in the U.S. over
the last twenty years had already been convicted of a felony. Recently, victims’ advocates and
others have argued that persons convicted of sex offenses are highly likely to “same crime”
recidivate (Langan et al. (2003)). Although criminal behavior declines steeply with age after the
early twenties for most types of crime, the decline for sex offenses appears to be more gradual
(Hanson (2002)). Partly for these reasons, and because of a number of high-profile crimes in the
late 1980s and early 1990s, sex offenders have become the focus of considerable legislation and
public spending aimed at reducing recidivism.
In the 1990s, two sets of laws targeting sex offenders emerged across the United States.
A federal mandate in 1994 (the Jacob Wetterling Act, named after the victim of a crime in
Minnesota) required that states create registries of sex offenders for use by law enforcement.
Another federal mandate in 1996 (Megan’s Law, named after a victim in New Jersey, Megan
Kanka) required that states provide public notification of the location of sex offenders to local
residents or other “at risk” groups. The basic motivations for registration and notification were,
respectively, to aid law enforcement in supervising and apprehending sex offenders who may
recidivate and to help local households protect themselves through monitoring and avoiding
offenders in their neighborhoods. However, despite the similar motivations of state legislatures,
there was considerable variation in the timing with which states passed these laws, and states
were given considerable discretion concerning many important details of this legislation.
Despite the proliferation of sex offender registration and notification laws, it is unclear
whether they have been successful in reducing crime by sex offenders, or whether they have
achieved other goals (e.g., increasing the probability of capture). It is also unknown whether sex
offenders respond (or are able to respond) to these laws in other ways (e.g., adjusting how they
select their victims). The answers to these questions are important not only for evaluating the

1

costs and benefits of registration and notification laws, but also for understanding how an
important group of convicted criminals responds to changes in legal sanctions.1
The first studies that sought to measure the impact of registration and notification laws
(Schram and Milloy (1995) and Adkins et al. (2000)) compared recidivism rates of offenders in
Iowa and Washington State released just before and just after registration and notification laws
became effective.2 While neither study found a statistically significant difference in future
arrests for sex offenses between these two arguably comparable groups, both studies relied on
small samples of offenders. More recent studies have examined the relationship between the
timing of laws’ passage and changes in the annual frequency of sex offenses across states using
data from the FBI’s Uniform Crime Reports (Walker et al. (2005), Shao and Li (2006), and Agan
(2007)). Taken together, these studies find little evidence that these laws had a significant
impact on sex offenses.3
While we also use the timing of changes in state laws to study the impact of those laws
on criminal behavior, we are able to offer new evidence on a number of different questions
because our analysis differs significantly from earlier work in both the data we use and the
methodology we employ. First, we conducted extensive research into the sex offender
legislation of various states, and found that earlier studies had in many cases used incorrect legal
dates or incorrectly described the nature of these laws. Understanding the timing and scope of
this body of law is not an easy task, partially because sex offender laws have changed over time
due to legislative amendments and judicial decisions.4 We also take advantage of information on
the exact dates when laws became effective by using monthly data and allowing for variation in
crime frequency within years, in contrast to the earlier work using annual data.
1

Empirical work provides some support for the claim that criminals in general react to changes in expected
punishment (e.g., Levitt (1998), Kessler and Levitt (1999), Nagin (1998)). However, it is unclear whether this is
true for all types of individuals (see McCrary and Lee (2005) on juvenile offenders), and whether these results
extend to sex offenders in particular is unknown (see Bachman et al. (1992)).

2

Unlike many other states, registration and notification laws in Washington and Iowa were passed at the same time.

3

Only Shao and Li (2006) report any evidence that offender registration laws caused a statistically significant
reduction in sex offenses. However, their findings are sensitive to empirical specification and they group
registration and notification laws together as a single treatment. Agan (2007) offers some evidence that posting sex
offender information on the internet reduced the number of arrests for sex offenses, but her results are similarly
sensitive and open to alternative interpretations.

4

We describe the history of sex offender registration and notification laws in detail in Section 2 and provide basic
information on these enactments in the Appendix.

2

Second, unlike existing work, our analysis distinguishes between sex offender
registration and notification laws. Notification laws require the dissemination of information
about sex offenders (e.g., criminal history, physical description, home address, and other
information). Registration laws, in contrast, require that sex offenders register their residential
locations with a public authority (usually local police), but this information is otherwise kept
confidential. While registration requirements were intended solely to help law enforcement track
and apprehend recidivist offenders, notification laws aimed both at reducing crime through
greater public awareness and increasing the likelihood of capture conditional on the commission
of a crime (Prentky (1996), Pawson (2002), Levenson and D’Amora (2007)). We also
differentiate among the various features of different notification laws, e.g., access to paper
registry, internet access to information, or proactive community notification.5
Third, we make a methodological contribution to the sex offender and recidivism
literatures by using variation in the number of offenders actually registered with authorities to
separately identify the various ways in which registration and notification may influence criminal
behavior and police responsiveness. As a result, we are able to test several specific hypotheses
regarding the laws’ impacts on criminal behavior. For example, notification laws are aimed at
protecting the public against recidivists, but may also have a separate deterrent effect for
potential sex offenders who have not yet been convicted. The institution of a notification law
raises the expected punishment to potential first-time sex offenders because their crimes and
personal information will be made public upon release if they are caught and convicted. This
effect should be invariant to the number of offenders actually registered. In contrast, the effect
of registration on recidivism should be stronger when the registry contains information on a
larger number of sex offenders.
Last, but not least, we examine the effects of these laws on the relationship mix between
offenders and victims in addition to the overall frequency of reported sex offenses. Neither
registration nor notification were intended to affect the “incidence” of sex offenses across
different types of victims, but some observers have suspected that notification laws might simply
displace crime (see Prentky (1996), Filler (2001)) by changing the population of victims targeted
5

Agan (2007) examines registration and the availability of information via the internet, but this is the only instance
that we are aware of in which existing work on sex offender laws makes a distinction between registration and
notification.

3

by sex offenders. For example, if notification laws cause offenders to seek victims outside of
their neighborhoods, one might expect to see little overall reduction in crime, but a significant
change in the relationships between victims and offenders. We also study changes in the
probability that an arrest is made given a reported sex offense, or that the offense report is
“cleared exceptionally” because the victim refused to cooperate or the prosecution declined to
pursue the case. This last piece of our analysis serves as a robustness check and aids the
interpretation of our results on crime frequency.
We find evidence that sex offender registration and notification laws decreased the total
frequency of sex offenses in the states we examine. The registration of released sex offenders
alone is associated with a significant decrease in the frequency of crime. This is in line with
predictions from a simple model of criminal behavior in which the provision of information on
registered offenders to local authorities increases monitoring and the expected punishment for
recidivism. Moreover, as predicted by the model, the drop in the overall frequency of reported
sex offenses associated with registration is due primarily to reductions in attacks against “local”
victims who are known to an offender (i.e., a family member, friend, acquaintance, or neighbor).
Importantly, sex offenses by strangers appear unaffected by registration, indicating little or no
substitution of crimes from local to more distant victims.
In addition, we find that the creation of a community notification law (regardless of the
number of registered offenders) is associated with a reduction in the overall frequency of sex
offenses. One potential explanation for this effect, again consistent with our model, is that
notification raises the expected punishment for future offenders. Importantly, we find no
evidence that notification laws (as opposed to registration laws) reduced crime by lowering
recidivism. While notification is associated with a decrease in crime, this estimated effect is
actually weaker when a large number of offenders are on the registry. This finding is potentially
consistent with a number of explanations. But, as we show below, the evidence on balance
supports the existence of a significant “relative utility” effect, in which convicted sex offenders
become more likely to commit crime when their information is made public because the
associated psychological, social, or financial costs make crime more attractive.
The rest of the paper proceeds as follows. In Section 2, we provide a description of the
variation in the timing and scope of states’ registration and notification laws. Section 3 lays out

4

the potential effects of registration and notification using a simple model of criminal behavior
and presents our basic empirical methodology. In Section 4, we describe our data, and we
explain our empirical approach in Section 5. We present our main results in Section 6 and a
series of robustness checks in Section 7. Section 8 concludes.

2. The Evolution of Sex Offender Registration and Notification Laws
To characterize the sex offender registration and notification laws properly for the
empirical work below, we conducted legal research into the evolution of these laws in states
covered by the National Incident Based Reporting System (NIBRS) in the 1990s, the data used in
our analysis below. We constructed a detailed legal timeline for each state, relying principally
on paper legislative sources, legal databases containing statutory language and judicial opinions,
news releases and stories, and conversations and email communications with state employees.
We catalogued enactment dates, effective dates, and compliance dates for each legal change, and
verified, where possible, that such changes took place in reality, as opposed to simply on paper.
We cross-checked our research with other sources containing compilations of sex offender laws
and resolved all conflicts. Finally, we recorded the precise content of these legal changes, which
is particularly necessary with sex offender notification laws because they differ across states on
various dimensions.
Determining the timing with which sex offender registration and notification laws
became effective proved to be a difficult task. Table 1 illustrates this by showing the dates used
by Shao and Li (2006), Agan (2007), and Walker et al. (2005) in their analyses of the impact of
registries on crime rates, in addition to our own legal analysis.6 Comparisons of these dates
across research studies show a fairly low rate of agreement. There are only 15 states for which
all studies agreed on the exact date, and only 16 for which all dates fell within the same calendar
year. For example, consider the state of Utah, for which none of the four studies agree on the
6

Shao and Li (2007) and Walker et al. (2005) are more liberal in how they define a “registration” law, and, as
practical matter, appear to treat registration and notification as the same thing. Shao and Li refer to laws that include
notification provisions as well registration laws. Walker et al. state explicitly that they examine both “registration
and notification” laws, but do not distinguish between the two in their empirical work. Agan (2007), on the other
hand, recognizes the distinction with respect to internet availability of registry information, but nevertheless does not
include or consider other kinds of notification. This can lead to questionable coding as well as interpretation
problems. For example, Iowa enacted registration and a limited form of public access at the same time, and Agan’s
work attributes any change entirely to the registration law.

5

effective registry date. We place this moment on March 30, 1983, when Utah’s first generally
applicable sex offender registry became effective. Shao and Li use May 19, 1987, a date we
cannot locate in legislative history, but which is quite close to the enactment (as opposed to
effective) date of a 1987 law that re-codified and amended the registration law then in place.
Agan uses July 1, 1984, which likely refers to a 1984 law that also amended the original 1983
enactment, but the effective date for that law was February 16, 1984. Walker et al. use the year
1996, the year that Utah passed a notification law granting public access to the registry
information.
We divide the legal changes we study into four categories: registration, public access,
internet availability, and active notification. Registration laws are invariably the first strategy
states employ to protect against sex offender recidivism. These laws require that sex offenders
(always at least the violent and habitual ones) provide state authorities with information on their
demographics (e.g., age, race, distinguishing features) and location (e.g., home, work, or school
address), as well as criminal history, upon release from custody or probation. Until notification
laws were enacted, this information was held confidential by law enforcement. In theory,
registration laws may lower sex offense rates through increased police surveillance or by
reducing the expected payoff of committing a new sex offense via increased probability of
punishment. Registration can make sex offenses easier to solve because a set of likely offenders
will have already been identified, and authorities will know where to locate (and apprehend) that
set of offenders.
The remaining three categories of laws – public access, internet availability, and active
notification – are designed to make information about offenders (identity and location) available
to the public, rather than to assist police directly. As we explain in more detail below, the public
can, in theory, reduce sex offender recidivism by avoiding convicted offenders (reducing the
number of potential target victims) or though “community policing” (e.g., reporting suspicious
behavior). Most states began this process by providing public access to their registration
databases, but varied in the restrictions they placed on access to this information. Some states
(e.g., Idaho) only allowed the public to make information requests in writing or about specific
suspected persons. Others made information available about all sex offenders in the area and
allowed them to be openly inspected at police departments or other government agencies (e.g.,

6

Michigan). Both approaches to public access assume that potential victims or witnesses will
make use of these opportunities despite their nontrivial travel and time costs.
Over time, restrictive states loosened their access restrictions, and all states eventually
moved registration information onto the internet to minimize transactions costs and maximize
information dissemination. Sex offender “web registries” allow the public to search for
offenders using a suspected individual’s information (e.g., a name or alias) or by entering a
specific address into a search algorithm to determine whether registered offenders live nearby.
Many states also implemented some form of “active notification” of individuals likely to be
victimized. Active notification laws require that state officials do more than simply release
information to someone who inquires. Examples include announcing the release or residential
move of a sex offender through a notice placed in a newspaper, by personal visits or letters to
neighbors, former victims, or others likely to have direct contact with the offender, and opt-in
provisions, which allow former victims or members of the public to request notification if a
certain sex offender or one satisfying certain conditions is released or moves. Both of these
developments were designed to reduce the information costs for potential victims.7
Figure 1a shows the timing of adoption of registration, public access, internet availability,
and active notification for each NIBRS state (see also Appendix Table 1), as well as the year in
which agencies from each state began reporting to NIBRS. While a similar evolution of sex
offender laws from confidential registries to searchable internet sites and active notification
occurred across all states, there is significant variation in the timing of the passage of these laws.
For example, Idaho began registration and (limited) public access simultaneously in 1993, but
did not have an internet registry live until 2001 and did not have community notification until
2003. Texas, in contrast, began registration in 1991, started both public access and community
notification in 1995, and launched an internet site in 1999. This type of variation provides the
basis for our identification strategy.
Although typically a concern in studies that use variation in the timing of state laws to
identify their causal effects, endogeneity is unlikely to be a problem in this context for two
7

Michigan provides an example of a fairly typical sex offender law “timeline.” Michigan passed its first sex
offender registration law in July 1994 (effective October 1995), enacted its first public access law in January 1997
(effective April 1997), went online with its sex offender information in February 1999, and finally enacted an active
notification requirement in March 2006 (effective January 2007).

7

reasons. First, unlike criminal law in general, where rising crime rates might lead to increases in
penalties or police spending, many state sex offender laws were passed quickly, in response to
one or two well-publicized and usually gruesome incidents and not to a rising trend in sex
offenses. Indeed, many sex offender laws are named after the victim in the case that sparked the
legislative effort, and there is little evidence to suggest that legislative actions were motivated by
rising aggregate trends in sex offenses. Sex offense rates (like other violent crime rates) actually
declined over the period in which most of these laws were passed. Second, two federal laws
passed in 1994 and 1996 (motivated at least in part by specific crimes against individual children
in Minnesota and New Jersey) mandated that states pass registration and notification laws.
These federal laws left states with discretion as to substance and timing, but had minimum
requirements and did impose deadlines. Finally, the timing of passage was also partly dictated
by the pre-existing legislative schedule (e.g., Kentucky, North Dakota and Texas have
legislatures that meet only once every two years) rather than by changing sex offense trends.
We also collected information on the retroactivity of the registration and notification laws
of the states in our sample. Retroactivity provisions specify which offenders are covered by the
laws in light of the timing of their conviction or their release from custody. For example,
Massachusetts’ first registration law was not effective until October 1, 1996, but anyone
convicted on or after August 1, 1981, of a qualifying sex offense was nonetheless required to
register. As a result, in October 1996, Massachusetts already had fifteen years’ worth of released
sex offenders who were required to be registered.8 Michigan, on the other hand, made its sex
offender laws prospective. Michigan’s first registration law became effective on October 1,
1995, but it only required registration of individuals “convicted or released” on or after October
1, 1995. As a result, when the law became effective, Michigan’s registry was empty.9 We use
the size of the sex offender registry as an additional source of variation by which to identify the
causal effect of sex offender registration laws, and, with respect to notification laws, to

8

Indeed, close to 8,000 offenders were already registered when the Massachusetts registry became effective in
October, 1996 (Boston Globe (1996a, 1996b)). The total number of offenders estimated by the Massachusetts
Department of Public Safety to be required to register was 10,000.
9

Although we do not have data from the start of the Michigan registry, we have good historical data on registrations
in North Carolina and Kentucky since the inception of their laws. Neither of these states’ laws applied retroactively,
and, as we would expect, their registries started from almost nothing and grew gradually (and roughly linearly) over
time. See Appendix Figure 1.

8

separately identify deterrence of all potential offenders and “incapacitation” (by public
awareness) of recidivists, as we explain more fully below.10

3. Conceptual Model and Empirical Framework
We consider the potential effects of registration and notification on crime through a
simple model of behavior wherein individuals weigh the benefits and costs of crime commission.
Criminal offenses committed by individual i (Oi) are governed by the probability of punishment
(pi), the punishment he faces if convicted (fi), and the utility he receives from committing crime,
relative to other legal behaviors (ui).11 We add a subscript j for each potential victim, and a term
cj that reflects the cost to offender i of targeting victim j. Sex offenses require victims, and the
laws we consider were specifically intended to make it difficult for offenders to victimize people
in their vicinity – neighbors, acquaintances, and friends. By assumption, offenses are increasing
in the relative utility of commission, and decreasing in the cost of targeting a victim, the
probability of punishment, and the severity of punishment. For simplicity, we assume that
punishment and the relative utility of criminal behavior are invariant across victims.
Oij = Oij (cij, pij, fi, ui)

(1)

Equation 1 suggests that registration and notification laws are likely to influence the
number of offenses through several specific channels. First, registration may increase the ability
of police to monitor and apprehend registered sex offenders (RSOs), meaning pij would rise for
RSOs and particularly so in the case of local victims. Indirectly, this feature of registration may
also affect forward-looking, unregistered individuals, for whom the punishment (fi) now includes
a higher future probability of detection.12 However, so long as registry information remains

10

The choice whether to make a sex offender law retroactive is also unlikely to be endogenous to crime rates.
Under certain conditions, criminal laws with retroactive features can violate the U.S. and state constitutions. The
decision of whether to make a law retroactive in any particular state turned in significant part on governing judicial
opinions in the state.

11

This model follows the structure of Becker (1968). The utility term should be considered an analog to Becker’s
concept of the individual’s “willingness to commit an illegal act.”

12

It has been suggested to us that the registry might also lower the probability of punishment (p) for first-time
offenders if police must shift significant resources towards monitoring registered offenders. This is theoretically
possible and though we do not find evidence for this in our analysis we cannot determine whether this occurs.

9

confidential, it seems unlikely that it would alter the cost to targeting victims or the utility of
crime commission.
Notification—either via public access to registry information, an internet registry, or
active community notification—may further affect criminal behavior. First, the punishment for
sex offenses now includes public airing of personal information and one’s criminal history. This
publicity has been shown to have negative consequences for RSOs along several dimensions,
including loss of employment, housing or social ties, harassment from neighbors, and
psychological costs such as increased stress, loneliness, and depression (see Zevitz and Farkas
(2000a), Tewksbury (2005), and Levenson and Cotter (2005)). Thus, for individuals other than
RSOs, fi would be higher.13
In contrast, RSOs would already face the costs associated with notification, so
committing another offense only has the effect of prolonging their presence on the registry.
However, this may exert a relatively small influence on their behavior given that most RSOs face
an extended registration period (the federal requirement is 10 years, but a number of states have
lifetime registration for some or all types of offenses). Moreover, some researchers have
proposed that the negative consequences of notification may cause RSOs to commit more crime
(Freeman-Longo (1996), Prentky (1996), Winick (1998), Presser and Gunnison (1999), Edwards
and Hensley (2001)). In the context of our model, punishment (fi ) would stay constant for RSOs
(or perhaps rise slightly), while the relative utility of criminal behavior (ui) would rise.14
In addition, by allowing local residents, friends, and acquaintances to identify and avoid
registered offenders, notification may increase the costs of targeting this subset of potential
victims. Indeed, a major motivation for the passage of Megan’s Law was the presumption that
Megan Kanka would have avoided her fate had her parents been notified of her eventual

13

We believe this is, in all likelihood, correct. However, we note an argument made by Teichman (2005) that the
imposition of non-legal punishments for sex offenses could lead to lower expected punishment levels. Non-legal
punishments cause fewer offenders to be willing to plead guilty to sex offenses and allow them to commit credibly
to go to trial. Prosecutors with limited resources—who previously pled out most sex offenses— may optimally
respond by taking a few cases to trial and accepting many pleas for other, less serious offenses.

14

Although we conceive of these burdens on offenders as raising the relative utility of criminal behavior, one could
also think of them as lowering punishment levels because they make life in prison seem relatively more attractive
than life on the outside. Both of these effects would increase offenses committed by registered sex offenders. We
thank David Autor for this observation.

10

attacker’s presence in the neighborhood.15 However, even if local residents can avoid
victimization, it is unclear to what degree this will mitigate sex offenses overall. Prentky (1996)
makes this point succinctly:
“Although the immediate neighbors will be able to warn their children to stay
away from an offender, there is nothing to prevent the offender from going to the
adjacent community, or getting into his car and driving to an even more distant
community. In other words, we will accomplish nothing more than changing the
neighborhood in which the offender looks for victims. For those with a
rudimentary appreciation of the forces that motivate repetitive sex offenders, it is
all too obvious that notifying the neighbors will serve no purpose if the man is
intent on finding a victim.”
If offenders can easily target victims outside of their neighborhood who are unaware of their
presence, then notification may change the relationships of offenders and victims but have a
negligible impact on overall crime rates. In other words, the response of criminals to notification
may result in crime displacement, rather than crime reduction.16
In addition to raising the cost of targeting local victims, there may also be a “community
policing” effect of notification (Lieb (1996)) that increases the likelihood that an offender is
apprehended if he attacks a local victim (e.g., by increasing vigilance and knowledge of an
offender’s actions within the neighborhood). Again, if the likelihood of punishment only rises
for crimes against local victims, offenders may simply offend in other neighborhoods.
The ideas laid out above help us consider ways in which the effects of these laws can be
identified and distinguished with aggregate crime statistics. In particular, we can use the fact
that the measurable effect that registration and notification laws have on registered sex offender
behavior is likely to be proportional to the size of the registry, while any impact on other
individuals should not be sensitive to registry size. As a result, the effect of registration on crime
via increased probability of punishment (due to improved police surveillance and apprehension)
15

Though no legislators disputed this claim, other neighbors claimed that local households, including her parents,
did know that the house where Megan was killed contained a sex offender. See Filler (2001).

16

Crime displacement has been an important consideration in other empirical research on criminals’ responses to
changes in their environments. For example, Jacob et al. (2004) consider displacement of crime along a temporal
dimension due to weather shocks, and Di Tella and Schargrodsky (2004) test for geographic crime displacement in
their study of the effect of police on crime. Iyengar (2007) makes a related argument that changes in the relative
punishments for crimes under California’s “Three Strikes” Law caused a form of “displacement” (from less severe
to more severe crimes) through reduced marginal deterrence.

11

should be small when relatively few offenders are registered, and should grow in proportion to
the relative size of the registry. The potential impact of registration on the punishment level (fi)
for forward-looking, unregistered individuals, however, would not depend on the size of the
registry.
Likewise, notification may raise the expected punishment (fi) for individuals other than
registered sex offenders, and this would have a negative impact on aggregate crime, irrespective
of the size of the sex offender registry.17 Notification may also have several, offsetting effects on
registered sex offenders: increasing the cost to targeting local victims (cij), increasing the
probability of punishment for local crimes (pij), slightly increasing expected punishments (fi), and
increasing offenders’ relative utility of crime commission (ui). The combined effect on overall
crime frequency is indeterminate, but is likely to grow with the size of the registry.
Our simple model and the discussion above give rise to the empirical specification we use
in this paper. To examine the crime frequency, we estimate a reduced form equation:

(

(

)

)

C jt = α j + γ t + λX jt + ∑ D sj β 0 Rg ts + β 1 Nt ts + β 2 Rg ts + β 3 Nt ts * RgSize jt + ε jt

(2)

s

Cjt is a measure of crime frequency (e.g., offenses per 10,000 people) for reporting area j in time
period t.18 αj is a reporting area fixed effect to capture any persistent heterogeneity in crime
across areas, γt is a time effect to capture secular changes in crime over time, and Xjt are time
varying reporting area characteristics that are likely to impact crime. The variables “Rgt” and
“Ntt” are vectors of dummy variables indicating which states had a sex offender registry or a
notification law in place during time period t, and “RgSizejt” is a vector measuring the size of the
offender registries in area j in time period t.19 Dj indicates the state of reporting area j.

17

This response may in turn affect aggregate offender-victim relationships if offenders’ probability of punishment is
correlated with their relationship to victims. For example, the reporting rate to police, and hence the probability of
punishment, may be significantly lower for crimes committed against children within families (see Filler (2001)).

18

Our analysis can be done at various levels of geographic and time aggregation, so we use the phrases “reporting
area” and “time period” for generality here.

19

We present a specification with a general notification law for simplicity. In reality, there are different types of
notification, including access to a paper registry, public internet access, and proactive community notification. To
the extent possible given our data, we explore variation in the impacts of these different types of laws.

12

The coefficient β0 represents the impact of an offender registry on individuals other than
RSOs. If the registry increases expected punishment for unregistered individuals (due to future
registration) then this coefficient would be negative. A stronger prediction of our model,
however, is that β2 should be negative – an increase in the probability of punishment for RSOs
should lower crime by more when relatively larger numbers of offenders are registered.
Similarly, β1 indicates the effect of a sex offender notification law on individuals other
than RSOs. We hypothesize that this coefficient should be negative, reflecting higher expected
punishment for unregistered individuals from notification. In contrast, we do not have a clear
prediction for β3 due to notification’s offsetting effects on RSO behavior. A finding that β3 is
negative would indicate that notification reduces the availability of victims. Such a finding
would bolster claims made by proponents of notification, as protecting the public from
recidivism was the law’s intended effect. However, if offenders shift to more distant victims or
commit more crime in response to an increase in the relative utility of crime commission then we
could find an estimate for β3 close to zero or even positive.
We can also use the specification in Equation 2 to examine the impact of registration and
notification on the relationship between victims and offenders. If a sex offender law increases
expected punishment for non-RSOs (β0 and β1), the effect should be similar across victims.
However, the impact of the registry on RSOs should be greatest (β2 most negative) for offenses
against “local” victims. We would expect to find a much smaller negative effect with respect to
distant relationship offenses (e.g., crimes against strangers) or, potentially, a positive effect if
offenses are being displaced from local to distant victims. How the effect of notification on RSO
crimes (β3) should vary across victims is unclear. If the increased cost of targeting local victims
is a dominant effect, then a negative effect for local victims and a zero or positive effect for
distant victims is likely. However, if the increased relative utility of crime commission is the
dominant effect, then we might see a positive effect across all victims.
When examining arrests and crime clearance, we use incident-level data to estimate a
similar equation:

(

(

)

)

A it = ∑ Di j α j + γ t + λX it + ∑ Dis δ 0 Rg ts + δ 1 Nt ts + δ 2 Rg ts + δ 3 Nt ts * RgSize st + ε it
j

s

13

(3)

We add a subscript i to denote an incident within reporting area j, and use Ait to denote the
outcome of interest. The incident level variables (Xit) include all relevant factors known to
police regarding the crime and reported in the NIBRS. These include the characteristics of the
victim, offender, and their relationship, the type of offense committed, the number of victims and
offenders involved, etc. Other variables follow notation from Equation 2.
When predicting the effect of registration and notification laws on arrests, both police and
offender behavior become relevant. A registry or a notification law should not influence the
likelihood of arrest for individuals other than RSOs (δ0 and δ1) via changes in police behavior
because police have no additional information on these individuals. However, changes in
criminal behavior may affect arrest statistics. In Equation 1, if the punishment level (f) rises,
then individuals offend less by substituting away from marginal victims where the probability of
punishment (p) is relatively high. Thus, we may see a negative effect of registries and
notification laws on the likelihood of arrest (δ0 and δ1), but any effects should be of the same
sign as any effects on the frequency of offenses (β0 and β1).
The predicted effect on arrests rates for crimes committed by RSOs is also unclear. The
direct effect of the registry (δ2) should be to increase arrest rates, reflecting increased monitoring
and apprehension. However, RSOs may respond by forgoing offenses committed against victims
where the probability of arrest is high. Therefore, the effect on arrests should be positive if there
is no change in recidivism, but small if RSOs reduce offenses or shift towards another population
of victims where the probability of punishment has not risen.
A similar analysis applies to notification. A direct effect (δ3) on RSOs via “community
policing” should lead to an increase in arrest probability. However, if local victims use
notification to avoid RSOs and thereby increase targeting costs (c), offenders will only attack
local victims with low probabilities of punishment, and average observed arrest rates will
decrease. The other potential effect of notification is an increase in offenses due to a rise in the
relative utility of crime commission (u). This would lead to increases in arrest probability,
theoretically, as offenders victimize those for whom the probability of punishment was
previously too great. Thus, the impact of these policies on arrest probability must be interpreted
in light of their impact on overall crime frequency. Table 2 gives the predicted relationships

14

between the registration and notification variables in Equations 2 and 3 and the model
parameters and outcomes of interest.20

4. Data
The primary source of data we use in our analysis is the National Incident Based
Reporting System (NIBRS). NIBRS is a part of the FBI’s Uniform Crime Reporting Program
(UCR), but presents several opportunities for research that are unavailable with standard UCR
crime data. 21 First and foremost, NIBRS links information on victims, offenders, and arrestees
for each incident in the dataset. Thus, in addition to examining the impact of registration and
notification on reported crime frequency, which previous studies have sought to do using UCR
data, we are able to examine effects on the relationship mix between offenders and victims (or
the “incidence” of sex offenses) and on the ability of police to secure an arrest given that a crime
has been reported.22 In addition, the information on the timing of each incident is superior in the
NIBRS data, allowing us to better exploit within-year variation in the timing of sex offender laws
to identify our results. While UCR data are available by month, the UCR date reflects when an
incident was reported, not (necessarily) the month in which it occurred. In contrast, the NIBRS
reports the date on which an incident occurred.23

20

Note that, in addition to arrests, we also examine clearance of crimes due to non-cooperation by victims or
decisions by prosecutors not to pursue the case. These variables are available in the NIBRS and are of interest to us,
but victim cooperation and prosecutorial decisions are not part of our model and we leave discussion of these issues
until we present results in Section 7.

21

Like UCR, NIBRS identifies the agency reporting each incident. Because agencies cover a relatively small area
(i.e., a county or city) we can control for relevant fixed and time varying local characteristics.
22

NIBRS also contains information on whether an arrestee resides within the boundaries of the agency reporting the
crime, but the rate with which this variable is missing is high in some states and years and we do not include it in our
analysis.

23

If the date of occurrence is not known to the police (which occurs for about 20 percent of sex offenses) the NIBRS
reports the date on which the crime was reported to the police. Unfortunately, the NIBRS does not report both dates,
so we cannot directly measure the lag between occurrence and report. However, we can get a rough sense of the gap
between incident and report dates by exploiting the fact that a subset of crimes reported in the NIBRS took place in a
prior calendar year (i.e., some crimes that occurred in year T are reported in the data from year T+1). We examine
all sex offenses (excluding 2005) by the calendar month in which they took place and measure the fraction reported
in the following year. Of the sex offenses that took place in December, 11 percent were reported the year after,
while the corresponding figures for November, July, and March were 7, 2 and 1 percent, respectively. Thus, it is
likely that most crimes are reported to the police within a few months after they take place but that a non-trivial
fraction reported with a considerable lag. In any case, our qualitative results are not sensitive to dropping crimes for
which an incident date is unavailable.

15

While several features of the NIBRS are useful for our analysis, it does suffer from
significant limitations. First, like most data on crime, NIBRS only contains information on
incidents recorded by police. Changes in reported crime may be driven by true changes in
victimization or by changes in reporting by victims.24 We return to this issue when interpreting
our findings. Another limitation is that the first year for which NIBRS data are available (from
the ICPSR) is 1995—one year after the federal government required that states create sex
offender registries and one year before it required the registry information to be public. To
address this problem, we requested additional data, available for some states, back to 1991 from
the FBI, and have incorporated that data into our analysis below.25 A further difficulty with
NIBRS is that only a subset of states participates in the program. In 1995, there were just nine
states; by 1998, eight more states joined, and 30 states were included as of 2004. Our analysis
focuses on 15 states that were in the NIBRS by 1998: Colorado, Connecticut, Idaho, Iowa,
Kentucky, Massachusetts, Michigan, Nebraska, North Dakota, Ohio, South Carolina, Texas,
Utah, Vermont, and Virginia.26 These states are geographically spread across the U.S. (see
Figure 2), but they do not include any states from the far west (e.g., California) or the “deep”
South (e.g., Mississippi).
In addition to the complexity of new states joining NIBRS during our sample period, the
participation of law enforcement agencies can vary within a state. Agencies are identified in
NIBRS by an “Originating Agency Identifier” (ORI) code, and, within a state, the number of
reporting ORIs increases over time. For example, the number of reporting ORIs from Nebraska
more than quintupled between 1998 (the first reporting year) and 2005. We include ORI fixed
effects in all of our regressions. Thus, in addition to taking account of the growth in reporting
agencies over time, we also control for persistent heterogeneity in ORI characteristics.
Another data issue is that, although the NIBRS surveys ORIs on a monthly basis, an ORI
may not complete every report in a year. We exert considerable effort to ensure that our results
24

This issue runs throughout most empirical research on crime. There does exists a large, publicly available data set
on crime as reported by victims—The National Crime Victimization Survey (NCVS)—but it does not contain
geographic identifiers that would allow us to link registration and notification laws to crime incidents. Although we
cannot examine reporting issues directly, it is encouraging that national crime rates reported in the NCVS have
tracked UCR crime rates fairly well since the early 1990s.

25

The results with this additional data generally confirm results generated using only the 1995-2005 ICPSR data.

26

Tennessee and West Virginia also joined the NIBRS in 1998. However, both had passed registration and
notification laws by that time, and we therefore did not pursue collection of detailed legal data on these states.

16

are not driven by bad reporting. First, we use the indicators provided in NIBRS for whether an
ORI reported crime in a given month. Among ORIs reporting crime during any month of each
year, the fraction reporting for all twelve months ranged from 68 percent in 1995 to 89 percent in
2004. We limit our analysis to crimes that took place during months when the ORI reported
crime in the previous month, the current month, and the next four months. This restriction
causes us to drop less than 5 percent of sex offenses that occurred between February 1991 and
August 2005, and all offenses occurring outside this period.
Despite this initial cleaning of the data, we found a number of instances of apparent
underreporting of crimes in NIBRS.27 We also observe agencies that, according to the NIBRS
indicators, started reporting officially on a given month, but do not start reporting crime until
several months later. To address these concerns, we implement an algorithm to identify these
kinds of misreporting. First, we take all agency-period cells with a given number of crimes
reported, then we calculate the variance of the number of crimes reported in periods a given
length of time from the current period, and then we flag all observations that are outliers given
this variance (i.e., the observation has very small chance of occurring, assuming reports are
normally distributed with given variance).28 We also flag all adjacent months, to guard against
the possibility that underreporting in one month leads to over-reporting in others.
Multiple offenses can be reported in a single incident, and we classify an incident as a sex
offense if any of the reported offenses fell under one of three sex offense categories: rape and
sexual assault, sexual molestation (called “forcible fondling” in NIBRS), and other non-violent
sex offenses (i.e., “incest” and “statutory rape”).29 An additional complication is the non-trivial
number of sex offenses with multiple victims (8 percent) or multiple offenders (8 percent). The

27

For example, an agency might report about 500 crimes every month for many months, then report few or no
crimes for one month, and then return to the previous pattern of 500 crimes.

28

We repeat this process for reports up to six periods away and flag observations twice: first with 1 in one million
chances and second with 1 in one hundred thousand chances. The two-stage process is helpful because it allows us
to recalculate the variance after eliminating very distant outliers.

29

Incidents of other crimes are used in our analysis to control for other time varying factors that cause changes in
crime rates within an ORI over time. We classify other crimes as either ordinary assault or “other” crime, in order to
control for overall rates of crime and a type of violent crime arguably more similar to sex offenses. We classify an
incident as an assault if one of the offenses listed fell under an assault category but none of the offenses were a sex
offense. This latter condition affected only a small number of incidents: only 0.3 percent of incidents with a sex
offense also had an assault and just 0.02 percent of assaults also had a sex offense. Likewise, incidents of other
crime do not contain either a sex offense or an ordinary assault.

17

indicators we create for the relationship between the offender and the victim include all victims’
relationships. For example, if there were two victims, a family member and a friend of the
offender, both the family member and friend indicators are set equal to one.30 When we examine
arrests, we include the characteristics of the victim and offender as control variables. For
incidents with multiple victims or multiple offenders we record the characteristics of the first
victim and first offender listed. These variables are only used in our analysis of arrests.
Table 3 shows summary statistics on the sample of incidents we examine. For purposes
of comparison, we also include information on ordinary assaults. In general, assault is a more
common crime than sex offense in our data, with more than 14 assaults for every sex offense.
Reporting of incident dates, arrest rates and time until arrest are quite different for the two types
of crime. The frequency with which incident dates are not reported (and only a report date is
available) is higher for sex offenses (19 vs. 13 percent). Arrests are less common for sex
offenses (26 vs. 37 percent) and the time to arrest—conditional on the arrest occurring at least
one day after the incident—is considerably longer (24 vs. 14 days).
The relationship between offenders and victims is similar for sex offenses and assaults,
with family members and acquaintances as the two most common categories of offenders. The
overall fraction of (reported) incidents with an acquaintance is somewhat higher for sex offenses
(31 vs. 24 percent) but incidents of sex offense are less common between family members (25
vs. 29 percent) and significant others (8 vs. 18 percent).31 For both sex offenses and ordinary
assaults, in about 20 percent of incidents the victim claimed that the offender was a stranger or
did not know his/her relationship to the offender.
Assaults and sex offenses differ substantially in the demographic characteristics of
victims. While 51 percent of sex offense victims were below age 15, the corresponding figure
for assault is only 9 percent. Sex offense victims are also more likely to be female (87 vs. 58
percent) and white (78 vs. 68 percent). Offender characteristics between the two crimes also
differ. The age distribution of sex offenders is wider than for assault, with more mass in both the

30

The decision to code relationships in this way, as opposed to using only the relationship of the “closest” offender,
had no appreciable effect on our results.

31

Recall that a small portion of incidents have multiple offenders and/or victims, and we code all relationships
existing for each incident, so that these percentages can sum to greater than one.

18

youngest and oldest age groups. Reported sex offenders are much more likely to be male (96 vs.
77 percent) and somewhat more likely to be white (69 vs. 62 percent).
In addition to the information on victims, offenders, and arrestees from NIBRS, we
employ annual, county-level demographic data from the U.S. census on the fraction of the
population in 18 age categories and five ethnicities as well as annual county-level data on
income per capita, employment rates, and unemployment rates as controls in our regressions.
While some ORIs are smaller than counties, we believe these are the best annual data available
to control for any demographic shifts that may have occurred in ORIs over our sample period.
Two percent of ORIs are located in multiple counties. We assign to these ORIs a weighted
average of county characteristics based on the population of the ORI in each county.
Next, we use our legal research to classify each incident based on the laws in effect and
the number of offenders on the offender registry at the time of the incident. We mark each
incident with a set of dummy variables for the state of the registration and notification provisions
in effect in the state.32 Marking each incident with a value for the number of offenders on the
registry at the time of the incident is more difficult. Unfortunately, historical data on the size of
registries across states is very hard to find, particularly for the early years of registries’ existence.
We were able to find incomplete information on the number of registered offenders in each state
in governmental publications and elsewhere.33 In addition, we know that a number of states did
not apply their laws retroactively, and, for any such state, we are able to include a zero at the
start of the registry. This allows us to make some progress in determining the historical size of
the registries for the NIBRS states at the state level. In addition, we have a fairly comprehensive
data set on registered offenders nationwide as of August, 2007. This data set was compiled by a
private company (www.familywatchdog.com) that provides sex offender information to the

32

For example, an incident that occurred on July 1, 1995 in Michigan would have a registration law enacted, but no
registration or notification laws in effect at the time, while another incident occurring on July 1, 1999 in Michigan
would have registration, public access, and internet access in effect.

33

Two reports from the National Institute of Justice provide us with states’ registry sizes at the end of 1998 and
2001 (Bureau of Justice Statistics (2002)). In addition, we have been able to gather documents posted on-line by the
National Center for Missing and Exploited Children that provide counts of offenders registered in each state at
several points in time from 2003 through 2007. The exact dates when the information was gathered varied by state,
but, in general, this gives us a snapshot of registry sizes in 2003, 2005, 2006 and 2007. We also add additional data
points from news articles and government reports for specific states. It is our hope to be able to uncover more data
and improve our estimates of registry size in a future revision.

19

public, and was given to us for the purposes of research. From this data we calculate the number
of registered sex offenders by county within each NIBRS state.
In order to use these two sources of information in our analysis, we first run a least
squares regression of registry size on quadratic function of date, allowing for state specific
intercepts and slopes and using all data points available for each state. We then use the predicted
values from this regression as measures of the state registry size for each month. The results of
these regressions are depicted in Figure 3.34 We then allocate sex offenders to each county under
the assumption that the fraction of offenders by county today is reflective of the fractions by
county in past years.
One concern with the use of registry size is the potential for “reverse causation” by
changes in sex offense frequency. Registry size is largely a function of how long the registry has
been in existence, the degree to which the registration law applied retroactively to previously
released offenders, the inclusion or exclusion of offenders convicted of less serious crimes, and
overall compliance with the registration law. However, it is also clearly influenced by the
number of sex offenses committed in the past, since new offenders are added to the registry upon
their release. Fortunately, the lag with which new offenders are added to the registry is likely to
be quite long. For individuals sent to prison in 2002 whose first listed offense was Rape, Sexual
34

An alternative method for gauging the size of sex offender registries is to rely only on timing and retroactivity
provisions of each registry. For example, one could estimate registry size using the equation

RgSizeist =

t − t retro
,
365.25

where the size of the registry when incident i is committed on day t in state s (RgSizeist) is measured by the
difference between the date of the incident and the date to which the registration law is retroactive (tretro). This relies
on the intuition that registries start very small in states which had non-retroactive laws but states with retroactive
provisions will have larger registries, all else equal, from the start. From this point, all registries should grow
steadily over time as more offenders fall under the law’s requirements. This measure of RgSize roughly
approximates the number of “cohorts” of sex offenders required to register. Although some offenders will
eventually qualify to be removed from the registry, under federal law, violent offenders and offenders who commit
crimes against minors (a large percentage of sex offenders) must register for a minimum of ten years, and in many
states even non-violent offenders must register for a minimum of ten years and violent and repeat offenders must
register for life. In practice, this formulaic measure is somewhat similar to our empirical measure. For example,
both measures show that Michigan’s registry started small and grew steadily over time. However, the legal formula
predictions for some states diverge considerably from the empirical predictions. In particular, states that instituted
significant retroactivity clauses after their registry began (e.g., Connecticut, North Dakota, and Texas) did not see a
sharp rise in the number of offenders registered, as the legal formula would imply. Presumably, this is due to
difficulty in registering sex offenders no longer on probation (and whose whereabouts may be unknown) in a short
period of time. Because of the divergence of the formulaic and empirical registry size estimates, we rely on the
empirical predictions to avoid bias due to measurement error.

20

Assault, and Child Molestation, the median sentence length was 120, 72, and 68 months,
respectively, and the fraction with a sentence of one year or less was 1.7, 2.5, and 1.8 percent,
respectively.35 Thus, only a very small amount of registry size growth is due to recent
convictions, and any short-run change in the frequency of sex offenses driven by other factors is
unlikely to be correlated with short-run changes in registry size.

5. Empirical Methodology
We estimate the effects of registration and notification laws using the regression
specifications outlined in Section 3. All regressions include ORI fixed effects, year and month
fixed effects, and control for annual per-capita income, unemployment, and poverty rates and the
fraction of the population in five ethnicity categories and five-year age categories at the county
level. In addition, for some specifications, we include the number of ordinary assaults and of
other crimes committed per 10,000 persons as proxies for ORI-specific time-varying factors that
influence crime rates and may be correlated with the legal variables. Though we do not report
the coefficients, both assault rates and “other crime” rates are always positively related to sex
offenses and are highly statistically significant.36
The registry indicator signifies that the state has an active offender registry, and registry
size is measured using our empirical estimates, as explained in Section 4. For notification, we
have a number of potential measures because the details of these laws varied considerably by
state. Recall that there are three types of notification: public access, internet access, and
community notification. Within these categories, we focus on statutes that implied widely
available or “full” access to sex offender information by the public.
In particular, full public access refers below to a law in which access is not subject to the
discretion of local authorities and where the public can inquire about local offenders in general,
as opposed to making an inquiry regarding a specific person. Full internet access indicates that

35

Authors’ calculations using data from the National Corrections Reporting Program, 2002.

36

One could argue that including assault and other crime may be problematic in that these may also be decreased or
increased by sex offender laws, depending on their substitutability/complementary. However, their inclusion turns
out to have little influence on our results and, if anything, decreases the size of our estimated coefficients. We
therefore view them as appropriate controls for time-varying unobservable factors.

21

the internet registry is on-line and generally complete.37 Full community notification means a
law that makes notification mandatory and requires either neighbors or the media be provided
with sex offender information. Figure 1b shows the timing of the full versions of community
notification laws. In our regressions below, we define having a notification law to mean that at
least one of these “full” versions of notification is in place and effective.38
Two important issues regarding statistical inference in our analysis are that our sample
includes a small number of states and that our registry size variable is estimated from a first stage
regression. As noted by Donald and Lang (2007) and Cameron et al. (2007), clustering at the
group level (i.e., states in our sample) can lead to biased standard errors when the number of
groups is small. In addition, using regression estimates as independent variables will also
typically lead to underestimated standard errors (Murphy and Topel (1985)).
We use a bootstrap procedure to correct our standard errors for both of these problems.
Specifically, we repeat each regression in our analysis 100 times and calculate our standard
errors using the variance of the resulting estimates.39 Let βi be the estimated vector of
coefficients from repetition i. Our variance estimate is σˆ β2* , where

σ β2 =
*

∑ (β
N

1
N −1

− β ) , N = 100
2

i

i

In addition to sampling our states (with replacement) in each repetition, we take account
of any additional bias due to estimated regressors by using values for registry size calculated
37

We located news articles in six states suggesting that the internet registry was incomplete when launched, i.e., it
was missing information on a large share of registered offenders. For two of these states, we found notice of when
the web registry was completed. For the four states where we have an indication of incompleteness but do not have
any notice of completion, we consider the internet to be fully available three months after the site was launched.

38

Given the limited number of states and the fact that notification laws are designed to work in a similar fashion –
lowering information costs and increasing dissemination – our primary specification uses any full notification law in
effect. One complication that arises from this framework is that two states in our sample (Texas and Ohio) had
registration and notification laws in place prior to the start of the NIBRS data period. Thus, variation in crime
frequency within these states does not contribute to the identification of the main effects of these laws. Dropping
these states from our sample has very little impact on our results, and we report replications of our main results with
a restricted 13 state sample in Appendix Table 2.

39

In the simulations carried out by Cameron et al. (2007), this technique, which they term “paired bootstrap-se,”
does not perform as well as other techniques, such as “wild bootstrap,” in the sense that it finds a placebo to have a
statistically significant relationship with the dependent variable at the 0.05 level in around 10 percent of their
simulations. However, it is not clear from their work whether this difference is reflective of a general result that
would apply to our situation, i.e., an unbalanced panel with groups of differing size and independent variables that
have different variance across groups. We find the standard errors from a wild bootstrap are smaller than those from
the paired bootstrap, and we therefore use the paired bootstrap estimates.

22

from randomly drawn values from the distribution of our estimator in the “first stage” where we
estimate registry size. Specifically, we take the estimator of the K parameters from the first stage
( γ 0 ) and use the Cholesky decomposition of the variance-covariance matrix (V) to draw a new
vector ( γ i ) where γ i = γ 0 + V 2 R , R = [r1 ... rK ] , ri ~ i.i.d . N (0,1). We then use this vector of
1

coefficients to re-estimate registry size for each regression.
The unit of observation in our analysis is an ORI-by-month cell, and the dependent
variable is measured as annualized incidents per 10,000 persons covered by the ORI (i.e., we
multiply monthly incident rates by 12, for ease of interpretation).40 For the purposes of
analyzing data aggregated to the ORI-month level, our legal variables reflect the law as of the
15th day of the calendar month, even though our legal variables can vary within months in the
incident level data. The regressions are weighted by ORI population coverage so that the
coefficients reflect average changes in crime risk faced by a typical person covered by the
NIBRS sample, and to take account of likely heteroskedasticity.41

6. Crime Frequency and Relationship Mix Results
Our results for the overall frequency of sex offenses are shown in Table 4. With respect
to the consequences of sex offender registry laws, we find no evidence that registries deter first
time sex offenders. Specifically, the impact of an (empty) sex offender registry is estimated to
be positive, but that estimate is not statistically significant. Importantly, however, we do find
support for the claim that requiring registration reduces recidivism, presumably by increasing
monitoring and the likelihood of punishment for potential recidivists. The interaction of the
40

Studies of crime frequency often examine the natural log of crime as a dependent variable in regression analysis
(see, e.g., Shao and Li (2007)). This transformation is problematic in our case because we use monthly data from
very disaggregate areas and therefore have many observations in which zero sex offenses occur. However, for
comparison purposes, we present results in a number of our tables where the dependent variable is the natural log of
offenses plus one per 10,000 persons. The results from these specifications are quite similar in sign and significance
to our measure of crime per 10,000 persons, and we therefore do not discuss them. The similarity of the results is
not surprising, given that we weight our analysis by covered population, hence relying more on larger areas that are
unlikely to have months without the occurrence of at least one sex offense.

41

To illustrate the heteroskedasticity issue, suppose we have two ORIs, each with ten sex offenses per 10,000
persons in a given month, but one ORI has 1000 persons and another has 100,000. These two values correspond
roughly to the 5th and 95th percentile of covered population among ORIs in our sample. The smaller ORI in this
example had only one sex offense, and would drop to zero per 10,000 persons if there are no crimes the following
month (which is quite likely to happen given sampling variation). In contrast, the large ORI had 100 sex offenses
during the month, and is much less likely to drop to zero per 10,000 due to sampling error.

23

registry indicator with the size of the registry is negative and statistically significant, as predicted
by our simple model of criminal behavior. The interaction estimate in column (2) of -0.10
implies that each additional sex offender registered per 10,000 people reduces reported annual
sex offenses per 10,000 by 0.10 crimes. This is a substantial (1.1 percent) reduction and, if
correct, would give support to the idea that placing information on offenders in the hands of local
law enforcement helps reduce the frequency of sex offenses.
Notification laws also appear to affect the frequency of sex offenses. The estimates in
Table 4 suggest that notification makes a difference in criminal behavior, but not in the way that
proponents of these laws intended. The estimated effect of the existence of a law that requires
community notification on the frequency of sex offenses is negative and statistically significant.
The coefficient estimate in column (2) suggests that community notification laws reduce crime
frequency by -1.07 crimes per 10,000 persons per year (about 11.6 percent) via a deterrent effect
on individuals not currently registered as sex offenders. However, the interaction of notification
with registry size is positive and statistically significant. This implies that any beneficial impact
of registration (as discussed above) on recidivism by registered sex offenders is dampened by the
use of notification. This also suggests that the punitive aspects of notification laws may create
perverse effects (as discussed in Section 3). Our results indicate that a basic trade-off may apply
in the sex offender notification context—while some first time offenders are deterred by
notification sanctions, the imposition of those sanctions on convicted offenders ex post may
make them more likely to recidivate.42 We explore the reliability of the estimated coefficient on
the notification-registry size interaction further in Section 7.
How should a legislature approach this trade-off? For a simple back-of-the-envelope
analysis, imagine a state that must decide 1) whether to enact a registration law, 2) whether to
enact a notification law, and 3) how many offenders to cover with these laws. Because we find
no evidence that an empty registry has any effect on crime and a larger registry (absent
42

Another possible explanation for the increase in crime frequency associated with an increase in registry size is that
either the state authorities or citizens become overwhelmed with the number of offenders as the registry size grows.
This strikes us as unlikely. First, with respect to the police, we continue to see a reduction in the number of offenses
as the registry grows under a registration regime, suggesting that, although surely costly, police are not being
overwhelmed to the point where an additional registrant actually reduces the overall effectiveness of the system.
Second, notification regimes are primarily local. Therefore, most of the increase in registry rolls amounts to an
increase from zero registered offenders to two or three in a neighborhood or zip code. Citizens are not expected to
track thousands of offenders, and, indeed, notification systems are not designed to work that way.

24

notification) appears to reduce crime, our findings imply that a state should always employ a
registry (the optimal size of the registry depends on the shape of the relationship between sex
offense frequency and registry size). On the other hand, our results also suggest that notification
laws are only attractive when the size of the registry is relatively small. We estimate that putting
a notification law in place deters -1.07 yearly sex offenses per 10,000 people, but a notification
law that covers 14.79 sex offenders per 10,000 people (the sample mean) leads to 1.3 additional
recidivist sex offenses per 10,000 people.
If a state is required (as it is under federal law) to use both registration and notification,
the level of coverage turns out to be somewhat unimportant to the total number of crimes
committed. This is because the notification interaction coefficients are similar in magnitude to
the registration interaction coefficients, and the differences are not statistically significant. As a
result, because the interaction effects are not different from each other, our data do not indicate
that a larger registry – when combined with notification – reduces crime.
Given the significant costs of maintaining a large registry (both to the state and to those
required to register), one possible implication of these estimates is that states should consider a
narrow notification regime, in which all or most sex offenders are required to register, but only a
small subset of those offenders are subject to community notification. Alternatively, states might
consider notification substitutes capable of similar deterrence gains, but that avoid notificationrelated increases in recidivism. Because notification laws were enacted not to deter, but to
protect against recidivism, our results suggest a reevaluation of notification may be needed.
Table 5 presents estimates from regressions in which we disaggregate our previously
singular notification measure into three different types of notification regimes – full public
access, full internet access, and full active notification. As one would expect, disaggregating
results in less precision, and yet the basic pattern remains. Again, we find statistically significant
evidence that registration laws reduce recidivism. The coefficients on all three types of
notification laws and their interactions with registry size are the same sign—negative main
effect, positive interaction—and the standard errors are too large to reject the hypothesis that
they are equal to each other. Nevertheless, we find it interesting that the coefficient on the main
effect of active community notification is noticeably larger in magnitude, implying greater
deterrence of first-time offenders. The strength of the active notification result makes sense in

25

the context of our model, as active notification may be perceived as the most intrusive form of
notification and therefore may have particular deterrence value.
In Table 6, we investigate the extent to which registration and notification laws may have
affected the relationship mix of offenders and victims. To carry out this exercise, we divide
victims into three groups based on the intimacy of their relationship with the offender: “close,”
“near,” and “stranger.” The close group includes family members, significant others, and
friends; the near group includes neighbors, acquaintances, or offenders “otherwise known,” and
the stranger group includes incidents where the victim claimed the offender was a stranger or
where the offender-victim relationship was unknown to the victim.43 Again, in theory,
notification laws are designed specifically to protect individuals who know offenders or come
into contact with them in their local area by helping these potential targets avoid situations in
which they or their friends and relatives could be victimized. Accordingly, we examine whether
(as lawmakers hoped) the frequency of victims who were close or near to the offender drops, and
whether (as lawmakers had not hoped) the frequency of “stranger” sex offenses increases due to
crime displacement.
The results of this incidence analysis support the interpretation of the results in Table 4
above. According to our simple model (see Table 2), the deterrent effect of registration and
notification laws (the main effects) should not alter the relationship mix of sex offenses because,
by definition, first-time offenders are not currently registered (so neighbors, for example, cannot
protect themselves). The results in Table 6 are consistent with this prediction – notification has a
deterrent effect that is, percentage-wise, similar in magnitude across relationship groups,
although the estimate for strangers is not precisely estimated. In any event, there is no evidence
that the effect differs across groups, and, for all groups, the estimated coefficients on the
indicator for having a registry are not statistically significant.
However, as expected, and consistent with the hopes of policymakers and our prediction
in Table 2, the interactions between the registration law indicator and the size of the registry are
negative and of similar magnitude for both the close and near victim groups. In contrast, the
estimated interaction for the stranger group is slightly positive, and, though statistically
indistinguishable from zero, fairly precisely estimated. The effects in Table 6 for “close” and
43

Note this is distinct from instances in which the relationship variable is missing in NIBRS.

26

“near” victims are marginally significantly different from zero (p-values of 0.15 and 0.08,
respectively). These results line up well with the idea that the benefits of registration help reduce
crime by local offenders against local victims. The magnitude of the coefficient estimates
implies that each additional registered sex offender per 10,000 persons reduces these group
specific sex offense rates, in total, by 0.07 per 10,000 persons. Our results do not support the
notion that registration of sex offenders with local law enforcement reduces crimes committed
against more distant individuals, but, perhaps more importantly, the estimated coefficient in
column (4) does not suggest a significant increase in sex offenses against strangers due to
displacement, as some critics of these laws feared might happen.
Our model provides two possible predictions for the effect of the interaction between the
notification law indicator and the size of the registry. If notification laws make it more costly for
a sex offender to target local victims (raising cij), then we should see negative effects on the
frequency of sex offenses for near and close victims, but less of a reduction or even an increase
(if there is displacement) for stranger victims. On the other hand, if notification laws instead
primarily reduce the relative utility of legal behavior for RSOs – by making life outside of prison
significantly less attractive – we could see an increase in the frequency of crime as the registry
size grows. Furthermore, if notification laws do not alter the relative cost of attacking certain
victims, the growth in crime should be similar across groups. The estimated coefficients in
Table 6 favor this last scenario. The notification-registry size interaction is positive and
statistically significant across all groups, and, as percentages, the increases are almost identical
(with stranger crimes increasing by 0.82 percent, while crimes against close and near victims
rose by 0.88 percent and 0.72 percent respectively). These results shore up the claim that
notification may serve as a crime deterrent against non-registered offenders, but may be less
effective at reducing recidivism among offenders on the registry by allowing local victims to
protect themselves. Indeed, the evidence bolsters the plausibility of a relative utility effect, one
that increases recidivism of registered sex offenders.
The estimated effects of registration and notification laws on various arrest variables for
all sex offenses are shown in Table 7.44 Neither of the arrest variables shows a statistically
44

For analysis of arrests and clearance, we make several changes to our regression specification, as noted in Section
3. First, we examine incident level data instead of ORI-month aggregates. Second, we drop the controls for assaults
and other crimes (which are aggregate statistics) and include incident specific variables in addition to the controls

27

significant relationship with either type of law. If the decrease in crime frequencies associated
with registration was indeed caused by increased probability of punishment, the response by
offenders to this changed probability must undo (in equilibrium) any detectable change in arrest
probability and in the time to arrest. The notification coefficients show the same pattern. A
notification law may reduce the number of crimes, but does not appear to increase the probability
of arrest. The coefficient on the interaction of notification with registry size is also statistically
insignificant. The estimate is positive, as would be predicted by a change in crime due to a
relative utility effect, but it is also very imprecisely estimated.
With respect to dropped cases, we find little evidence that the probability a victim would
not cooperate was associated with the registration and notification variables. Looking at the
probability that the prosecution decides not to prosecute someone for lack of evidence, we find
suggestive evidence that this occurred more frequently in areas with a registry in place but few
registered offenders, but less frequently as the number of registered offenders rose, at least until
the advent of community notification. One could certainly tell a story that would substantiate
this type of result. For example, prosecutions may suffer at the start of a registration regime as
police personnel are used and criminal justice resources are spent on the construction and
introduction of the registry, but as the number of registered offenders rises, police may have
access to more and better information about local offenders, leading to stronger average cases.
Later, with the arrival of notification, prosecutors may have found that the advantages of
registration information to the state became degraded when community members also had this
information, perhaps because of false accusations (to which we will return). However, the
evidence here is clearly not strong enough to say anything conclusive.
At a minimum, our analysis provides some evidence to support the claims of those who
argue that registration and notification laws matter. Registration laws seem to reduce recidivism,
and notification laws appear to deter those not currently registered. Our work also suggests that
notification laws may harden registered sex offenders, however, making them more likely to

mentioned earlier: victim and offender age indicators (in five-year categories), victim and offender sex and ethnicity
indicators, indicators for the type of offender-victim relationship, indicators for the number of victims and the
number of offenders (capped at four), and indicators for the type of sex offense (i.e., rape and sexual assault, sexual
molestation, other non-violent sex offense). The motivation for this added set of covariates is to control (as best we
can) for the information available to law enforcement authorities and to examine law enforcement performance
conditional on this information.

28

commit sex offenses, perhaps because legal behavior is significantly less attractive for registered
sex offenders living under a notification regime.

7. Robustness Checks
In this section, we address a number of possible concerns about the results presented in
Tables 4 through 6 and our interpretation of those findings. We first inquire into the possibility
that our results are driven by some omitted variable or trend by checking whether our
identification approach generates similar results for non-sex related crimes. We also discuss the
robustness of our specification and sample choice. Second, we consider whether the results we
find, especially with respect to the “relative utility effect” might be driven by changes in
reporting behavior. Although we cannot completely rule out the possibility of changes in
reporting behavior, we present a number of findings that seem inconsistent with this explanation.
7.1. Falsification Tests and Specification Checks
One concern with our basic results is that there may be changes in crime frequency due to
other unobservable factors correlated with registration and notification laws. We control for a
number of local economic and demographic variables and for contemporaneous crime, but the
limits of our empirical strategy may still allow for omitted variables bias. In order to increase
our confidence that the results above are indeed indicative of the relation between sex offenses
and registration and notification laws, we repeat our analysis on the overall frequency of other
types of crime that we believe are far less likely to be impacted by the criminal behavior of sex
offenders or individuals on the margin of committing a first sex offense. We regard these
estimates as “placebo tests” in which we would expect to find no statistically significant
relationships between the laws and crime frequencies.45

45

According to our model, the relative utility effect generated by notification might cause registered sex offenders to
commit more crime in general. In that sense, with respect to the interaction of notification laws and registry size, the
coefficients in Table 8 should not be viewed as a falsification check in the usual sense. However, we purposefully
selected comparison crimes that we felt were very different from sex offenses to considerably reduce the likelihood
that changes in the behavior of registered sex offenders would show up in overall crime frequencies. Released sex
offenders do commit many other types of crime besides sex offenses. For example, among all sex offenders
released in 16 states in 1994, subsequent arrests for auto theft occurred half as frequently as arrests for another sex
offense (Authors’ Calculations, data from ICPSR 3335 “Recidivism of Prisoners Released in 1994”). However,
while released sex offenders are far more likely to be arrested for sexual offenses than other released criminals, they
are considerably less likely to be arrested for the crimes we consider in Table 8. Given that released sex offenders

29

The crimes we selected for this purpose are auto theft, drug offenses, fraud, weapons
violations, forgery, and larceny. While our intuition is that these crimes are quite different from
sex offenses, many of them occur with roughly similar frequency. The results from these
regressions are shown in Table 8 and are calculated using the same framework used to estimate
the impact of these laws on sex offenses. Of the 24 coefficients we estimate, we find only two
statistically significant relationships between reported crime rates in these non-sex offense
categories and our registration and notification variables (which might easily occur randomly).
One of these estimates, for weapons crimes in column (1), does not “mimic” our basic results
because that coefficient is on the indicator for whether a registry is effective. Recall that, in
Table 4, we found no evidence that the existence of a registry law alone had any effect on the
frequency of sex offenses. We also find a significant effect of registry size on the number of
larceny crimes (column (6)), but, again, the result does not suggest our findings on sex offenses
are spurious -- the larceny effect has the wrong sign. More importantly, the signs and
magnitudes of all of the coefficients increase our confidence that our earlier results are not driven
by spurious correlation with general trends in crime. For example, the coefficients on registry
size are all positive or very close to zero in these specifications. These results support the
conclusion that the estimates in Table 4 are not driven by correlations between the registration
and notification variables and omitted variables or trends in the data.
Another concern when dealing with relatively few states in a quasi-experimental setting
like ours is that one large state might plausibly account for all of the relevant results (see Currie
and MacLeod (2007)). We check the robustness of our findings to this possibility by running a
series of regressions in which one state is dropped from the sample. We do not report the results
of this exercise, but the coefficients generated remain remarkably robust to the exclusion of each
state. The point estimates change somewhat for different combinations, but the basic pattern of
results and the statistical significance of the coefficients is unaffected.
Our analysis controls for ORI effects, month and year effects, local economic and
demographic characteristics, and for contemporaneous crime trends. But, it is always possible
that our approach attributes the consequences of some unknown trend to our registration and

constitute a relatively small portion of all released criminals, it seems likely that the portion of incidents committed
by sex offenders in these “placebo” categories is very low.

30

notification variables. Up to this point, we have not included state-specific trends in our analysis
because one of our key variables – registry size – closely approximates a state trend (see Figure
3). Therefore, by including a state trend as a control variable, our empirical approach would
essentially identify off of cross-county variation and non-linearities in registry growth, as
described in Section 3. This requires that we, in effect, throw away a great deal of information in
an attempt to account for a possible, unknown state-level linear trend. Nevertheless, it is a useful
exercise, even though we view our earlier results as more reliable.
In Table 9, we present our original results, along with a specification that includes statespecific linear trends (in columns (3) and (6)). Our basic results are fairly robust to the inclusion
of the trends. The magnitude of the direct notification effect drops, but remains marginally
statistically significant (p-value of 0.15).46 The coefficient on registry size is smaller but similar
in magnitude relative to the other specifications and marginally significant (p-value of 0.12).
The interaction of notification and registry size remains highly significant regardless of the
specification. The inclusion of linear state-specific trend controls thus changes the picture
slightly, but, in most important respects, the basic results from Table 4 remain robust.
7.2. Reporting Behavior
The coefficients we estimate provide, we believe, important evidence about the likely
effects of two important and pervasive sex offender laws. Across all specifications and samples,
registration reduces the number of sex offenses, presumably by providing law enforcement with
information on local sex offenders. Notification appears to deter non-registered sex offenders by
imposing an unpleasant shaming penalty, but seems to contribute to recidivism by reducing the
attractiveness of legal behavior.
There are, of course, other ways in which our findings can be interpreted. We can only
examine the frequency of reported crime, and it is therefore possible that our findings are
affected by changes in victim reporting behavior.47 For example, the sanction of notification
46

It is worth noting that the coefficient on notification is statistically significant at the 5% level when we restrict our
sample to the 13 states that actually passed a notification statute during our sample period. With the addition of
state-specific linear trends as controls, it makes less sense to include the two states (Texas and Ohio) for which there
is no legal variation in registration and full notification during our sample period.

47

Data from the National Crime Victimization Survey (1996-2005) indicate that less than 50 percent of rape and
sexual assault victimizations are reported to the police. While reporting rates do not vary greatly by the age of
victim in the NCVS, it is important to note that this survey does not include victims below age 12.

31

may reduce reporting by victims who have a personal relationship with the offender and consider
the new punishment too harsh. But this seems unlikely to be the entire story, given the effects
we find for the “near” group of victims, which includes neighbors and acquaintances, and that
we find a decrease in crime associated with registration alone.48 Another possibility is that
registration and notification laws may cause offenders to move away from family, friends, and
acquaintances due to a “shaming” effect. Thus, a decrease in crimes against these groups could
be explained by their reduced contact with offenders. However, it seems more likely, a priori,
that this type of mechanical change in the relationship mix of reported offenses would be greater
for community notification laws, since registration laws are likely to involve little or no shaming.
Moreover, it is important to recall that our results do not provide any evidence that notification
decreases recidivism, only deterrence of unregistered offenders. Finally, another story one could
tell whereby a community notification law decreases sex offenses regardless of the number of
registered offenders is that the law increases awareness of sex offenses in general and makes all
potential victims more cautious. Unfortunately, we do not know of any data available that would
allow us to test this hypothesis directly.
More importantly, our finding that the interaction of notification and registry size is
associated with an increase in crime could be generated by two different plausible changes in
reporting behavior. First, as a registry grows and an increasing number of individuals are
notified that a sex offender lives nearby, notification could lead to an increase in frivolous
reporting of sex offenses, because the proximity of a sex offender is made known and salient.
Second, the passage of notification laws and knowledge that a sex offender lives nearby might
increase the number of true reports for crimes that, prior to the implementation of notification,
would have gone undetected. Both of these hypotheses are possible, but we find little evidence
to support them in the data.
If frivolous reports of sex offenses had increased, holding offender behavior constant, we
would expect to see either a reduction in the likelihood that a report led to an arrest (because the
average case reported has, all else equal, less merit) and/or an increase in the probability that a
48

Changes in reporting behavior might also lead us to underestimate the negative effects of registration of
recidivism. For example, if registration leads victims to believe that their reports are more likely to lead to an arrest,
they might be more likely to report crimes. We do not regard this story as likely. While victims may know of a
registry’s existence, they are probably unlikely to know whether their assailant is registered. However, the
estimated effect of simply having a registry, while positive, is never statistically significant.

32

case was dismissed by the prosecutor, because the average case became weaker. In our analysis
(Table 7) we found only mixed evidence: the estimated interaction of notification with registry
size was positive for the prosecutorial dismissal rate but estimate for the arrest rate was exactly
the same size. Thus, it is hard to reconcile our results on the interaction of notification and
registry size with a simple story about reporting bias.
If shifts in reporting behavior affect different types of sex offenses differently, we can use
that fact to test further the robustness of our results. While registration and notification laws
apply uniformly to rapists and child molesters, one might hypothesize that both types of
reporting biases described above (frivolous reporting and meritorious reporting of previously
undetected crime) are a concern primarily in the child molestation (fondling) context.
Information that a sex offender lives nearby may cause parents to be more aware of their
children’s’ behavior or whereabouts. It may also lead parents to investigate their suspicions
more than they otherwise would have done without that information. But knowledge of the
proximity of sex offender alone may be less likely, all else equal, to change reporting behavior
substantially in the case of forcible rape.
In Table 10, we divide our sample into three sex offense groups: sex offenses
(reproduced from Table 4), forced fondling, and forcible rape. Rape and forced fondling
constitute the bulk of all sex offenses (see Table 3). If either form of increased reporting were
driving the recidivism findings, we would expect to see the notification-registry size interaction
effect only in forced fondling cases, or at least primarily in those cases. But, we actually see
almost identical point estimates (both statistically significant) for both types of sex offenses. The
notification-registry interaction effect (in percentage terms) is somewhat higher for fondling than
it is for rape, but that difference is small. These results do not support the idea that our findings
are driven primarily by changes in reporting behavior.

8. Conclusion
Using detailed data on state laws and incident-level crime data from NIBRS, we
examined the effect of registration and notification laws on the total frequency of crime, the
incidence of that crime on various victim groups, and on police performance, conditional on a
crime occurring. We find evidence suggesting that registration laws reduce the frequency of sex

33

offenses, particularly for local victims, by providing information on convicted sex offenders to
local authorities. Our results also suggest that the reduction in crime was locally concentrated, in
line with policymakers’ intentions, with reductions generally greater among victims with a
personal connection to offenders. We did not find evidence of any crime displacement that
would increase victimizations of strangers. We also find evidence that notification laws reduce
crime, but do so by deterring potential criminals, not necessarily recidivists. In fact, our results
suggest that registered offenders might be more likely to commit crime in a state that imposes a
set of notification requirements, perhaps because of heavy social and financial costs associated
with the public release of their information.
Though researchers are still in the process of measuring the benefits of registration and
notification laws, the costs have been well documented. A number of researchers have
documented financial, physical, and psychological damage done to registered sex offenders and
their families (e.g., Zevitz and Farkas (2000a), Tewksbury (2005), and Levenson and Cotter
(2005)). The labor and capital costs to law enforcement agencies who are required to monitor
offenders can also be substantial (Zevitz and Farkas (2000b)). Moreover, there is evidence that
these laws have created financial and psychological costs for neighbors of registered sex
offenders. Linden and Rockoff (2006) and Pope (2006) document declines in property value for
households living close to registered offenders, and several studies find little evidence that
community notification alleviates concerns among community members who have been notified
of an offender’s presence (Zevitz and Farkas (2000b), Beck and Travis (2004) (2006)).
The lack of empirical evidence on the benefits of registration and notification has not
stopped politicians and policymakers from further regulation of sex offenders. Registration and
notification laws are, in some sense, old technology. Today, states are in the midst of imposing
ever more draconian laws, such as residency restrictions and civil commitment, as a means to
reduce recidivism of sex offenders. These more restrictive policies clearly impose higher costs
on sex offenders and their families than registration and notification laws, and future research is
needed to understand the impact of these policies on criminal behavior.

34

References
Adkins, G., Huff, D., Stageberg, P. (2000) “The Iowa Sex Offender Registry and
Recidivism,” Report of the Iowa Department of Human Rights, Division of Criminal and
Juvenile Justice Planning and Statistical Analysis Center.
Agan, A. (2007) “Sex Offender Registries: Fear without Function?” Unpublished
Manuscript.
Bachman, R., Paternoster, R., Ward, S. (1992) “The Rationality of Sexual Offending:
Testing a Deterrence/Rational Choice Conception of Sexual Assault,” Law and Society Review
26(2): 343-372.
Barr, R. and Pease, K. (1990) “Crime Placement, Displacement, and Deflection,” Crime
and Justice 12: 277-318.
Beck, V.S. and Travis, L.F. (2004) “Sex Offender Notification and Fear of
Victimization,” Journal of Criminal Justice 32(): 455-463
Beck, V.S. and Travis, L.F. (2006) “Sex Offender Notification: A Cross-State
Comparison,” Police Practice and Research 7(4): 293-307
Becker, G.S. (1968) “Crime and Punishment: An Economic Approach,” Journal of
Political Economy, 76(2): 169-217.
Bedarf, A.R. (1995) “Examining Sex Offender Community Notification Laws,”
California Law Review, 83(3) 885-939.
Boston Globe (October 5, 1996) “High-risk Sex Offenders to be Named on TV,” by
Jordana Hart, Globe Staff.
Bureau of Justice Statistics (2002) “Fact Sheet: Summary of State Sex Offender
Registries, 2001.” U.S. Dept. of Justice, Office of Justice Programs (March): NCJ 192265.
Bureau of Justice Statistics (2002) “Recidivism of Prisoners Released in 1994.” U.S.
Dept. of Justice, Office of Justice Programs (March): NCJ 193427
Cameron, C., Gelbach, J.B., Miller, D.L. (2007) “Bootstrap-Based Improvements for
Inference with Clustered Errors” Florida State University Law and Economics Research Paper
Series, Paper No. 07/002.
Currie, J. and MacLeod, W.B. (2007) “First Do No Harm? Tort Reform and Birth
Outcomes,” Quarterly Journal of Economics, forthcoming.
Di Tella, R. and Schargrodsky, E. (2004) “Do Police Reduce Crime? Estimates Using the
Allocation of Police Forces after a Terrorist Attack,” American Economic Review 94(1): 115133.
35

Donald, S.G. and Lang, K. (2007) “Inference with Difference-In-Differences and Other
Panel Data” The Review of Economics and Statistics 89(2): 221–233.
Edwards, W. and Hensley, C. (2001) “Contextualizing Sex Offender Management
Legislation and Policy: Evaluating the Problem of Latent Consequences in Community
Notification Laws,” International Journal of Offender Therapy and Comparative Criminology
45(1): 83-101.
Filler, D.M. (2001) “Making the Case for Megan’s Law: A Study in Legislative
Rhetoric,” Indiana Law Journal 76: 315-345.
Hanson, R.K. (2002) “Recidivism and Age: Follow-Up Data from 4,673 Sexual
Offenders,” Journal of Interpersonal Violence 17(10): 1046-1062.
Iyengar, R. (2007) “I’d Rather be Hanged for a Sheep than a Lamb: The Unintended
Consequences of ‘Three-Strikes’ Laws,” Unpublished Manuscript.
Jacob, B.A. Lefgren, L. and Moretti, E (2004) “The Dynamics of Criminal Behavior:
Evidence from Weather Shocks,” NBER Working Paper #10739.
Kessler, D. and Levitt, S.D. (1999) “Using Sentencing Enhancements to Distinguish
between Deterrence and Incapacitation,” Journal of Law and Economics 42(1): 343-363.
Langan, P.A., Schmitt, E.L., Durose, M.R. (2003) “Recidivism of Sex Offenders
Released from Prison in 1994,” Bureau of Justice Statistics Report NCJ 198281.
Levenson, J.S. and Cotter, L.P. (2005) “The Effect of Megan’s Law on Sex Offender
Reintegration,” Journal of Contemporary Criminal Justice 21(1): 49-66.
Levenson, J.S. and D'Amora, D.A. (2007) “Social Policies Designed to Prevent Sexual
Violence: The Emperor's New Clothes?” Criminal Justice Policy Review 18(2): 168-199
Levitt, S.D. (1998) “Juvenile Crime and Punishment,” Journal of Political Economy
106(6): 1156-1185.
Lieb, R. (1996) “Community Notification Laws: ‘A Step Toward More Effective
Solutions,’” Journal of Interpersonal Violence 11(2): 298-300.
Linden, L.L. and Rockoff, J.E. (2006) “There Goes the Neighborhood? Estimates of the
Impact of Crime Risk on Property Values from Megan's Laws,” NBER Working Paper #12253.
McCrary, J., and Lee, D.S. (2005) “Crime, Punishment, and Myopia,” NBER Working
Paper #11491.

36

Murphy, K.M., and Topel, R.H. (1985) “Estimation and Inference in Two-Step
Econometric Models” Journal of Business and Economic Statistics 3(4): 370-379
Nagin, D.S. (1998) “Criminal Deterrence Research at the Outset of the Twenty-First
Century,” Crime and Justice 23: 1-42.
North Carolina State Bureau of Investigation, “NC Sex Offender and Predator Statistics
by County” 1996 – 2001, Online at: sbi2.jus.state.nc.us/crp/public/other/sexofsum.htm
Ohio Legislative Service Commission (2002) “Ohio Facts 2002.”
Pawson, R. (2002) “Does Megan’s Law Work? A Theory-Driven Systematic Review,”
ESRC UK Centre for Evidence Based Policy and Practice, Working Paper 8
Prentky, R.A. (1996) “Community Notification and Constructive Risk Reduction,”
Journal of Interpersonal Violence 11(2): 295-298.
Pope, J.C. (2007) “Do Scarlet Letters Lead to Scarlet Homes? Household Reactions to
Public Information from Sex Offender Registries,” Unpublished Manuscript.
Presser, L. and Gunnison, E. (1999) “Strange Bedfellows: Is Sex Offender Notification a
Form of Community Justice?” Crime Delinquency 45(3): 299-315.
Schram, D.D. and Milloy, C.D. (1995) “Community Notification: A Study of Offender
Characteristics and Recidivism,” Washington State Institute for Public Policy Working Paper.
Shao, L. and Li, J. (2006) “The Effect of Sex Offender Registration Laws on Rape
Victimization,” Unpublished Manuscript.
Teichman, D. (2005) “Sex, Shame, and the Law: An Economic Perspective on Megan’s
Laws,” Harvard Journal on Legislation 42(1): 335-415.
Tewksbury, R. (2005) “Collateral Consequences of Sex Offender Registration” Journal
of Contemporary Criminal Justice 21(1): 67-81.
U.S. Census Bureau (2002), Table CO-EST2001-12-00 - Time Series of Intercensal State
Population Estimates: April 1, 1990 to April 1, 2000, Release Date: April 11, 2002.
U.S. Census Bureau (2002), Intercensal Estimates of the United States Population by Age
and Sex, 1990-2000: All Months.
U.S. Census Bureau (2006), Table 1: Annual Estimates of the Population for the United
States, Regions, and States and for Puerto Rico: April 1, 2000 to July 1, 2006 (NST-EST200601), Release Date: December 22, 2006.

37

U.S. Census Bureau (2006), County Population by Age, Sex, Race, and Hispanic Origin:
April 1, 2000 through July 1, 2006.
U.S. Dept. of Justice, Federal Bureau of Investigation. NATIONAL INCIDENT-BASED
REPORTING SYSTEM, 1995-2005 [Computer files]. Compiled by the U.S. Dept. of Justice,
Federal Bureau of Investigation. ICPSR ed. Ann Arbor, MI: Inter-university Consortium for
Political and Social Research [producer and distributor]
Walker, J.T., Maddan, S., Vásquez, B.E., VanHouten, A.C., Ervin-McLarty, G. (2005)
“The Influence of Sex Offender Registration and Notification Laws in the United States,”
Arkansas Crime Information Center Working Paper.
Winick, B.J. (1998) “SEX OFFENDER LAW IN THE 1990s: A Therapeutic
Jurisprudence Analysis,” Psychology, Public Policy, and Law 4(1): 505-570.
Zevitz, R.G., Farkas, M.A. (2000a) “Sex Offender Community Notification: Managing
High Risk Criminals or Exacting Further Vengeance?” Behavioral Sciences and the Law 18:
375-391.
Zevitz, R.G., Farkas, M.A. (2000b) “Sex Offender Community Notification: Assessing
the Impact in Wisconsin” National Institute of Justice Report, December 2000

38

Table 1: Disagreement Among Researchers on "Registry Dates"
Prescott and
Rockoff (2008)
Definition:
Alabama
Alaska
Arizona
Arkansas
California
Colorado
Connecticut
Delaware
D.C.
Florida
Georgia
Hawaii
Idaho
Illinois
Indiana
Iowa
Kansas
Kentucky
Louisiana
Maine
Maryland
Massachusetts
Michigan
Minnesota
Mississippi
Missouri
Montana
Nebraska
Nevada
New Hampshire
New Jersey
New Mexico
New York
North Carolina
North Dakota
Ohio
Oklahoma
Oregon
Pennsylvania
Rhode Island
South Carolina
South Dakota
Tennessee
Texas
Utah
Vermont
Virginia
Washington
West Virginia
Wisconsin
Wyoming

Registration
Effective

7/1/1991
01/01/1995

7/1/1993

7/1/1995
1/1/1995

10/1/1996
10/1/1995

1/1/1997

7/1/1993
7/1/1997

7/1/1994

9/1/1991
3/30/1983
9/1/1996
7/1/1994

Shao and
Li (2006)

Agan (2007) Walker et al. (2005)

Registry
Effective

"Registry
Begins"

"Registration and
Notification
Implementation"

1967
8/10/1994
1951
8/1/1987
1944
7/1/1991
10/1/1994
6/27/1994

5/26/1996
8/10/1994
6/1/1996
8/1/1997
1955
1996
1998
6/27/1994
6/1/2000
10/1/1993
7/1/1996
7/1/1997
7/1/1993
1/1/1996
7/1/1994
7/1/1995
7/1/1993
7/15/1994
6/18/1992
9/1/1996
10/1/1995

1998
1994
1996
1997
1996
1998
1998
1994
1999
1997
1996
1998
1993
1996
1998
1995
1994
1994
1992
1995
1995
1999
1995
1998
1995
1995
1995
1997
1998
1996
1993
1995
1995
1996
1995
1997
1998
1993
1996
1996
1999
1995
1997
1999
1996
1996
1997
1990
1993
1997
1999

10/1/1993
7/1/1994
6/14/1995
7/1/1993
8/15/1986
7/1/1994
7/1/1995
7/1/1993
7/15/1994
6/18/1992
7/13/1992
10/1/1995
10/1/1996
10/1/1995
7/1/1994
8/1/1991
1/1/1995
7/1/1989
7/1/1997
1961
1/1/1993
10/31/1994
7/1/1995
1/21/1996
1/1/1996
8/1/1991
1963
11/1/1989
1/1/1990
4/21/1996
7/1/1992
7/1/1994
7/1/1994
1/1/1995
9/1/1991
5/19/1987
9/1/1996
7/1/1994
6/7/1990
7/10/1993
12/25/1993
1/1/1995

10/1/1995
7/1/1991
1994
7/1/1979
1989
1/1/1997
1/1/1998
1993
10/31/1994
7/1/1995
1/21/1996
1/1/1996
1991
7/1/1997
11/1/1989
10/3/1989
4/21/1996
1992
7/1/1994
1994
1/1/1995
9/1/1991
7/1/1984
7/1/1996
7/1/1994
2/28/1990
1993
6/1/1997
1994

Researchers
All Agree

Researchers
Agree Within
Calendar Year

No
Yes
No
No
No
No
No
Yes
No
Yes
No
No
Yes
No
No
Yes
No
No
Yes
No
Yes
No
Yes
No
No
No
No
No
No
No
No
Yes
No
Yes
No
No
No
No
Yes
No
No
No
No
No
No
Yes
No
Yes
Yes
No
No

No
Yes
No
No
No
No
No
Yes
Yes
No
No
No
Yes
No
No
Yes
No
Yes
Yes
No
Yes
No
Yes
No
No
No
No
Yes
No
No
No
Yes
No
Yes
No
No
No
No
Yes
No
No
No
No
No
No
Yes
No
Yes
Yes
No
No

Note: Dates given by Matson and Lieb (1996) are not shown; they review state laws but do not examine criminal behavior.

Table 2: Model Predictions for Registration and Notification Coefficients
Variable of Interest

Model Parameters

Overall Frequency of Offenses

Relationship Mix

Probability of Arrest

Registration
Law

Notification
Laws

Registration Law
* Registry Size

Notification Laws
* Registry Size

p↑ non-RSOs

f↑ non-RSOs

p↑ (local) RSOs

p↑/c↑ (local) RSOs
u↑ RSOs

Negative

Negative

Negative
(Zero w/ Displacement)

p↑/c↑ Negative
(Zero w/ Displacement)
u↑ Positive

No Differences
Across Relationships

No Differences
Across Relationships

Stronger Local Effects

c↑ Stronger Local Effects
u↑ No Differences

Same Sign as Frequency

Negative (But Moves to
Zero as Frequency
Declines or Crime
Displaced)

p↑ Positive (Zero w/
Displacement)
c↑ Negative
(Zero w/ Disp.)
u↑ Positive

Same Sign as Frequency

Note: For details on how these predictions were made, see text of Section 3.

Table 3: Summary Statistics on Reported Crime Incidents
Sex Offenses

Assaults

328,260
37.9%
41.8%
20.3%
18.9%
25.7%
24.3
7.1%
5.1%

4,757,118
n/a
n/a
n/a
12.8%
37.3%
13.7
4.8%
6.6%

Offender-Victim Relationship
Family Member
Friend
Significant Other
Acquaintance
Neighbor
Otherwise Known
Stranger
Relationship Unknown
Missing Relationship Information

25.0%
7.0%
8.0%
31.0%
2.4%
9.6%
8.4%
11.8%
4.3%

29.2%
2.8%
17.6%
23.7%
1.8%
9.3%
9.7%
10.2%
4.5%

Victim Characteristics
Female
White
Black
Aged 0-4
Aged 5-9
Aged 10-14
Aged 15-19
Aged 20-29
Aged 30-39
Aged 40-49
Aged 50-65
Aged 65+

86.5%
77.6%
17.9%
8.7%
14.8%
27.1%
23.8%
13.1%
7.2%
3.6%
1.1%
0.5%

58.4%
68.2%
28.3%
0.7%
1.6%
6.9%
15.3%
30.2%
24.0%
14.5%
5.6%
1.3%

Offender Characteristics
Male
White
Black
Aged 0-9
Aged 10-14
Aged 15-19
Aged 20-29
Aged 30-39
Aged 40-49
Aged 50-65
Aged 65+

95.9%
69.0%
24.1%
2.3%
11.2%
20.1%
25.5%
20.5%
12.0%
6.5%
1.9%

76.8%
61.5%
33.9%
0.5%
6.2%
15.9%
31.3%
25.4%
14.5%
5.1%
0.9%

Total Number of Incidents in Sample
Rape and Sexual Assault
Sexual Molestation
Other Non-Violent Sex Offenses
Percent of Incidents with Report Date
Percent of Incidents Leading to Arrest
Average Days to Arrest
Prosecution Drops Charges
Victim Refuses to Cooperate

Notes: Sample includes all sex offenses and assaults reported in the 15 NIBRS states that we
include in our analysis. Relationships total to more than 100% in this table because some incidents
involved more than one relationship.

Table 4: Effects of Registration and Notification on Sex Offense Frequency

Registry Effective

Registry Effective *
Registry Size

Notification

Notification *
Registry Size

Sex Offenses
per 10,000

Sex Offenses
per 10,000

ln (Sex
Offenses per
10,000)

ln (Sex
Offenses per
10,000)

(1)

(2)

(3)

(4)

0.341
(0.436)
[.45]

0.309
(0.482)
[.54]

0.028
(0.032)
[.39]

0.026
(0.034)
[.46]

-0.083
(0.034)
[.03]

-0.100
(0.041)
[.03]

-0.006
(0.002)
[.03]

-0.007
(0.003)
[.03]

-1.153
(0.363)
[.01]

-1.069
(0.367)
[.02]

-0.079
(0.028)
[.02]

-0.075
(0.027)
[.02]

0.084
(0.029)
[.02]

0.088
(0.032)
[.02]

0.006
(0.002)
[.02]

0.006
(0.002)
[.02]

9

Assault/Crime Controls
Mean Offense Frequency
Mean Registry Size
Observations
R-squared

9

9.17
14.79

9.17
14.79

9.17
14.79

9.17
14.79

210,209

210,209

210,209

210,209

0.35

0.36

0.68

0.68

Notes: The dependent variable is annualized incidents per 10,000 persons in columns (1)-(2). In
columns (3)-(4), the dependent variable is the natural log of annualized incidents plus one per 10,000
persons. The unit of observation is a reporting agency (ORI) by month cell. Registry size is measured
in offenders per 10,000 persons (mean registry size is reported). The notification laws represent "full"
access by the public to information on offenders; for more details see the text in Section 5. Registry size
is empirically estimated from registry data, as explained in the text in Section 3. All regressions control
for county income and demographics, ORI fixed effects, year fixed effects, and month fixed effects.
Columns, as indicated, also control for rates of assault and other crime. Regressions are weighted by
the covered population in each ORI. Standard errors (in parentheses) are estimated via bootsrapping. Pvalues shown in backets.

Table 5: Effects of Registration and Notification on Sex Offense Frequency
Sex Offenses
per 10,000

Sex Offenses
per 10,000

ln (Sex Offenses
per 10,000)

ln (Sex Offenses
per 10,000)

(1)

(2)

(4)

(5)

Registry Effective

0.236
(0.402)
[.57]

0.179
(0.42)
[.68]

0.014
(0.026)
[.59]

0.011
(0.027)
[.68]

Registry Effective *
Registry Size

-0.099
(0.033)
[.01]

-0.121
(0.037)
[.01]

-0.007
(0.002)
[.01]

-0.008
(0.002)
[.01]

Public Access

-0.423
(0.442)
[.36]

-0.301
(0.376)
[.44]

-0.039
(0.036)
[.31]

-0.032
(0.032)
[.35]

Public Access *
Registry Size

0.046
(0.029)
[.15]

0.059
(0.031)
[.08]

0.004
(0.002)
[.09]

0.005
(0.002)
[.05]

Internet

-0.274
(0.222)
[.24]

-0.201
(0.234)
[.41]

0.002
(0.02)
[.94]

0.006
(0.021)
[.79]

Internet *
Registry Size

0.036
(0.013)
[.02]

0.035
(0.013)
[.03]

0.001
(0.001)
[.28]

0.001
(0.001)
[.31]

Active Notification

-1.896
(0.775)
[.03]

-1.541
(0.601)
[.03]

-0.139
(0.064)
[.05]

-0.120
(0.052)
[.04]

Active Notification *
Registry Size

0.069
(0.075)
[.38]

0.047
(0.069)
[.51]

0.004
(0.006)
[.46]

0.003
(0.005)
[.57]

9

Assault/Crime Controls
Mean Offense Frequency
Mean Registry Size
Observations
R-squared

9

9.17
14.79

9.17
14.79

9.17
14.79

9.17
14.79

210,209

210,209

210,209

210,209

0.35

0.36

0.68

0.68

Notes: The dependent variable is annualized incidents per 10,000 persons in columns (1)-(2). In columns (3)(4), the dependent variable is the natural log of annualized incidents plus one per 10,000 persons. The unit of
observation is a reporting agency (ORI) by month cell. Registry size is measured in offenders per 10,000
persons (mean registry size is reported). The notification laws represent "full" access by the public to
information on offenders; for more details see the text in Section 5. Registry size is empirically estimated from
registry data, as explained in the text in Section 3. All regressions control for county income and demographics,
ORI fixed effects, year fixed effects, and month fixed effects. Columns, as indicated, also control for rates of
assault and other crime. Regressions are weighted by the covered population in each ORI. Standard errors (in
parentheses) are estimated via bootsrapping. P-values shown in backets.

Table 6: Effects of Registration and Notification on Sex Offense
Frequency and Relationship Mix
All Victims

"Close"
Victims

"Near" Victims

"Stranger"
Victims

(1)

(2)

(3)

(4)

Registry Effective

0.309
(0.482)
[.54]

0.032
(0.172)
[.86]

0.162
(0.212)
[.46]

-0.116
(0.171)
[.51]

Registry Effective *
Registry Size

-0.100
(0.041)
[.03]

-0.032
(0.021)
[.15]

-0.034
(0.017)
[.08]

0.004
(0.01)
[.68]

Notification

-1.069
(0.367)
[.02]

-0.330
(0.1)
[.01]

-0.315
(0.163)
[.08]

-0.255
(0.127)
[.07]

Notification *
Registry Size

0.088
(0.032)
[.02]

0.030
(0.013)
[.05]

0.027
(0.014)
[.08]

0.015
(0.007)
[.06]

9.17
14.79

3.41
14.79

3.78
14.79

1.83
14.79

210,209

210,209

210,209

210,209

0.36

0.20

0.21

0.29

Mean Offense Frequency
Mean Registry Size
Observations
R-squared

Note: The unit of measurement for the dependent variables is annualized incidents per 10,000 persons, and
the unit of observation is a reporting agency (ORI) by month cell. Registry size is measured in offenders
per 10,000 persons. The notification laws represent "full" access by the public to information on offenders;
for more details see the text in Section 5. Registry size is empirically estimated from registry data, as
explained in the text in Section 3. The regressions control for rates of assault and other crime, county
income and demographics, ORI fixed effects, year fixed effects, and month fixed effects, as described in the
text. In Columns 2 to 4, the assault and other crime variables are specific to incidents with the same
offender-victim relationship as the dependent variable. Regressions are weighted by the covered population
in each ORI. Standard errors (in parentheses) are estimated via bootsrapping. P-values shown in backets.

Table 7: Effects of Registration and Notification on Arrest Outcomes

Registry Effective

Registry Effective *
Registry Size

Notification

Notification *
Registry Size

Observations
R-squared

Arrest Made

Time to Arrest
(in days)

Victim Refuses
to Cooperate

Prosecution
Drops Charges

(1)

(2)

(3)

(4)

-0.001
(0.038)
[.97]

-1.631
(1.556)
[.32]

0.019
(0.013)
[.16]

0.051
(0.018)
[.02]

-0.001
(0.005)
[.88]

0.024
(0.111)
[.83]

-0.001
(0.001)
[.34]

-0.004
(0.002)
[.08]

-0.015
(0.038)
[.70]

0.440
(2.38)
[.86]

-0.017
(0.014)
[.26]

0.002
(0.022)
[.93]

0.003
(0.003)
[.36]

-0.047
(0.112)
[.68]

0.002
(0.001)
[.12]

0.003
(0.002)
[.10]

287,789

65,702

287,789

287,789

0.10

0.12

0.10

0.14

Notes: The unit of observation is a reported sex offense. The dependent variables in columns (1), (3), and
(4) are zero-one indicators, respectively, for whether an arrest was made in connection with a report, for
whether the report was cleared because the prosecution declined to pursue the case, and for whether it was
cleared because the victim did not cooperate. In column (2), the sample is restricted to reported sex
offenses that lead to an arrest, and the dependent variable is the number of days from the report/occurrence
of an incident until an arrest was made. The regression includes controls for victim and offender
characteristics, victim-offender relationship, type of sex offense, ORI fixed effects, year fixed effects, and
month fixed effects, as described in the text. Standard errors (in parentheses) are calculated via
bootstrapping. P-values are given in brackets.

Table 8: Falsification Tests: Effects of Registration and
Notification on the Frequency of Other Crimes

Registry Effective

Registry Effective *
Registry Size

Notification

Notification *
Registry Size

Mean Offense Frequency
Mean Registry Size
Observations
R-squared

Weapons

Forgery

Fraud

Auto Theft

Drugs

Larceny

(1)

(2)

(3)

(4)

(5)

(6)

-1.790
(0.739)
[.04]

-2.434
(1.279)
[.09]

-2.293
(1.81)
[.23]

1.263
(1.239)
[.33]

-2.837
(1.945)
[.18]

2.884
(8.581)
[.74]

0.068
(0.067)
[.33]

0.182
(0.141)
[.23]

0.087
(0.16)
[.60]

-0.100
(0.099)
[.33]

0.349
(0.253)
[.20]

1.393
(0.627)
[.05]

0.565
(0.741)
[.46]

2.165
(1.789)
[.25]

0.778
(1.458)
[.61]

0.219
(1.333)
[.87]

-2.283
(2.031)
[.29]

2.461
(5.39)
[.66]

-0.060
(0.058)
[.33]

-0.131
(0.117)
[.29]

-0.083
(0.123)
[.51]

0.030
(0.066)
[.65]

0.080
(0.164)
[.63]

-0.070
(0.458)
[.88]

6.58
14.79

12.32
14.79

16.06
14.79

29.58
14.79

41.91
14.79

241.41
14.79

210,209

210,209

210,209

210,209

210,209

210,209

0.39

0.52

0.54

0.80

0.60

0.86

Notes: The unit of measurement for the dependent variables is annualized incidents per 10,000 persons, and the unit
of observation is a reporting agency (ORI) by month cell. Registry size is measured in offenders per 10,000
persons. The notification laws represent "full" access by the public to information on offenders; for more details
see the text in Section 5. Registry size is empirically estimated from registry data, as explained in the text in
Section 3. The regressions control for county income and demographics, ORI fixed effects, year fixed effects,
month fixed effects, and rates of assault and other crime. Regressions are weighted by the covered population in
each ORI. Standard errors (in parentheses) are estimated via bootsrapping. P-values shown in backets.

Table 9: Robustness of Registration and Notification Effects
on Sex Offense Frequency

Registry Effective

Registry Effective *
Registry Size

Notification

Notification *
Registry Size

Sex
Offenses
per 10,000

Sex
Offenses
per 10,000

(1)

(2)

(3)

(4)

(5)

(6)

0.341
(0.436)
[.45]

0.309
(0.482)
[.54]

-0.185
(0.289)
[.54]

0.028
(0.032)
[.39]

0.026
(0.034)
[.46]

-0.009
(0.021)
[.68]

-0.083
(0.034)
[.03]

-0.100
(0.041)
[.03]

-0.061
(0.036)
[.12]

-0.006
(0.002)
[.03]

-0.007
(0.003)
[.03]

-0.005
(0.002)
[.05]

-1.153
(0.363)
[.01]

-1.069
(0.367)
[.02]

-0.440
(0.285)
[.15]

-0.079
(0.028)
[.02]

-0.075
(0.027)
[.02]

-0.025
(0.024)
[.32]

0.084
(0.029)
[.02]

0.088
(0.032)
[.02]

0.056
(0.019)
[.02]

0.006
(0.002)
[.02]

0.006
(0.002)
[.02]

0.004
(0.001)
[.02]

9

9
9

9

9
9

9.17
14.79

9.17
14.79

9.17
14.79

9.17
14.79

9.17
14.79

9.17
14.79

210,209

210,209

210,209

210,209

210,209

210,209

0.35

0.36

0.36

0.68

0.68

0.68

Assault/Crime Controls
State Linear Trends
Mean Offense Frequency
Mean Registry Size
Observations
R-squared

ln (Sex
ln (Sex
ln (Sex
Offenses per Offenses per Offenses per
10,000)
10,000)
10,000)

Sex
Offenses
per 10,000

Notes: The dependent variable is annualized incidents per 10,000 persons in columns (1)-(3). In columns (4)-(6), the
dependent variable is the natural log of annualized incidents plus one per 10,000 persons. The unit of observation is a
reporting agency (ORI) by month cell. Registry size is measured in offenders per 10,000 persons (mean registry size is
reported). The notification laws represent "full" access by the public to information on offenders; for more details see the
text in Section 5. Registry size is empirically estimated from registry data, as explained in the text in Section 3. All
regressions control for county income and demographics, ORI fixed effects, year fixed effects, and month fixed effects.
Columns, as indicated, also control for rates of assault and other crime and state-specific linear trends. Regressions are
weighted by the covered population in each ORI. Standard errors (in parentheses) are estimated via bootsrapping. Pvalues shown in backets.

Table 10: Effects of Registration and Notification on the Frequency
of Various Sex Offenses

Registry Effective

Registry Effective *
Registry Size

Notification

Notification *
Registry Size

Sex
Offenses
per 10,000

Sex
Offenses
per 10,000

Fondling
Offenses
per 10,000

Fondling
Offenses
per 10,000

Rape
Offenses
per 10,000

Rape
Offenses
per 10,000

(1)

(2)

(3)

(4)

(5)

(6)

0.341
(0.436)
[.45]

0.309
(0.482)
[.54]

0.087
(0.227)
[.71]

0.071
(0.248)
[.78]

0.207
(0.206)
[.34]

0.196
(0.23)
[.41]

-0.083
(0.034)
[.03]

-0.100
(0.041)
[.03]

-0.051
(0.022)
[.04]

-0.058
(0.024)
[.04]

-0.022
(0.017)
[.23]

-0.031
(0.021)
[.17]

-1.153
(0.363)
[.01]

-1.069
(0.367)
[.02]

-0.338
(0.216)
[.15]

-0.300
(0.213)
[.19]

-0.739
(0.291)
[.03]

-0.700
(0.303)
[.04]

0.084
(0.029)
[.02]

0.088
(0.032)
[.02]

0.042
(0.015)
[.02]

0.044
(0.015)
[.01]

0.043
(0.018)
[.04]

0.046
(0.02)
[.05]

9

Assault/Crime Controls
Mean Offense Frequency
Mean Registry Size
Observations
R-squared

9

9

9.17
14.79

9.17
14.79

3.85
14.79

3.85
14.79

4.71
14.79

4.71
14.79

210,209

210,209

210,209

210,209

210,209

210,209

0.35

0.36

0.23

0.24

0.28

0.29

Notes: The dependent variable is annualized incidents per 10,000 persons in columns (1)-(3) and is the natural log
of this value in columns (4)-(6). The unit of observation is a reporting agency (ORI) by month cell. Registry size is
measured in offenders per 10,000 persons (mean registry size is reported). The notification laws represent "full"
access by the public to information on offenders; for more details see the text in Section 5. Registry size is
empirically estimated from registry data, as explained in the text in Section 3. All regressions control for county
income and demographics, ORI fixed effects, year fixed effects, and month fixed effects. Columns, as indicated,
also control for rates of assault and other crime and state-specific linear trends. Regressions are weighted by the
covered population in each ORI. Standard errors (in parentheses) are estimated via bootsrapping. P-values shown
in backets.

Appendix Table 1: Evolution of Registration and Notification Laws, by State
(1)
(2)
(3)
reg-eff-date pubacc- eff pubacc-disc
a

(8)
(7)
comm-effinternet-live
date

(10)
commmand

(11)
comm- optin

(12)
commvictim

(13)
commneighbor

(14)
commmedia

b

05/30/2006

N/A

N/A

12/01/1999

N/A

c

N/A

N/A

N/A

N/A

07/01/2003

N/A

N/A

N/A

07/01/2003

07/01/1998

N/A

N/A

N/A

07/01/1998

N/A

(4)
pubaccmand

(5)
pubaccwritreq

(6)
pubaccspecific

07/01/1999

N/A

N/A

07/30/2001

12/01/1999

12/1/1999

c

N/A

N/A

1/1/1999

c

10/01/1995

10/01/1995

e

07/01/2001

07/01/2003

e

03/16/2000

07/01/1998

(9)
comm-disc

Colorado

07/01/1991

06/05/1995

Connecticut

01/01/1995

10/1/1998

c

N/A

10/1/1998

Idaho

07/01/1993

07/01/1993

N/A

07/01/1993

Iowa

07/01/1995

07/01/1995

N/A

07/01/1995

07/01/1995

Kentucky

01/01/1995

N/A

N/A

N/A

N/A

N/A

04/11/2000

01/01/1999

Massachusetts

10/01/1996

10/01/1996

N/A

10/01/1996

10/01/1996

N/A

08/03/2004

09/10/1999

09/10/1999

N/A

N/A

N/A

09/10/1999

N/A

Michigan

10/01/1995

04/01/1997

N/A

04/01/1997

N/A

N/A

02/01/1999

01/01/2007

N/A

N/A

01/01/2007

N/A

N/A

N/A

Nebraska

01/01/1997

N/A

N/A

N/A

N/A

N/A

03/30/2000

07/15/1998

7/15/1998

7/15/1998

(lower risk)

(high risk)

N/A

N/A

07/15/1998

07/15/1998

North Dakota

07/01/1993

08/01/1995

N/A

08/01/1995

N/A

N/A

11/06/2001

08/01/1995

N/A

08/01/2001

08/01/1995

N/A

Ohio

07/01/1997

07/01/1997

N/A

07/01/1997

N/A

N/A

12/18/2003

07/01/1997

N/A

07/01/1997

N/A

South Carolina

07/01/1994

06/18/1996

N/A

06/18/1996

06/18/1996

06/18/1996

11/22/1999

06/18/1996

6/18/1996

Texas

09/01/1991

09/01/1995

N/A

09/01/1995

09/01/1995

N/A

01/11/1999

09/01/1995

Utah

03/30/1983

04/29/1996

07/01/1998

03/15/1996

07/01/1998

N/A

N/A

N/A

Vermont

09/01/1996

05/29/2000

N/A

05/29/2000

N/A

N/A

10/01/2004

09/01/1996

05/26/2006

N/A

Virginia

07/01/1994

07/01/1998

N/A

07/01/1998

07/01/1998

07/01/1998

01/01/1999

07/01/2006

N/A

N/A

06/05/1995

03/15/1996

e

07/01/1993

d

07/01/1993

070/1/1995

j

e

03/15/1996

e

f

07/12/2006

08/01/1995

h

01/01/1999

g

08/01/1997

07/01/1997
i

09/01/2005
(newspapers)

6/30/1999
(newspapers)

09/01/1995

k

01/01/1999

g

07/01/1997

01/01/1999

10/01/1995

g

07/01/1997

(if

c

01/01/1999

f

N/A

01/01/1999

g

(victims only)

opt-in)

N/A

N/A

06/18/1996

06/30/1999

N/A

N/A

09/01/1999

09/01/1995

N/A

N/A

N/A

N/A

09/01/1996

09/01/1996

(victim only)

(if opt-in)

05/26/2006

N/A

07/01/2006

N/A

N/A

N/A

l

Notes: a: repealed 07/1/1999; b: repealed 05/30/2006; c: enjoined 05/17/2001 until 05/03/2003; d: repealed 07/01/2001; e: repealed 07/01/1998; f: repealed 04/11/2001, reeffective 07/12/2006; g: repealed 04/11/2001; h: repealed 08/01/1997; i: except for
newspapers as of 06/30/1999; j: repealed 09/01/1997; k: repealed 09/01/2005 for newspapers; l: discretionary after 09/01/2005.
Columns (1)-(7): (1) the effective date of the first registration law; (2) the effective date of the first public access law of any kind; (3) the date that a discretionary public access law, if applicable, became effective; (4) the date that mandatory public access law, if
applicable, became effective; (5) the date on which a "written request" requirement, if applicable, became effective; (6) the date on which "specific person request only" restriction, if applicable, became effective; (7) the date on which public access was moved onto
the internet, thereby removing all previous access restrictions.
Columns (8)-(14): (8) the effective date the first active community notification provision; (9) the date the notification law, if discretionary, became effective; (10) the date the notification law, if mandatory, became effective; (11) the date that a notification law that
required that people "opt-in" to the notification system, if applicable, became effective; (12) the date that notification law that notified former victims, if applicable, became effective; (13) the date that a notification law that informed neighbors specifically, either by
a written notice or by a personal visit, became effective, if applicable; (14) the date that a notification law that used the media to deliver any notification, if applicable, became effective.

Appendix Table 2: Effects of Registration and Notification
on Sex Offense Frequency
(13 State Sample)

Registry Effective

Registry Effective *
Registry Size

Notification

Notification *
Registry Size

Sex Offenses
per 10,000

Sex Offenses
per 10,000

ln (Sex
Offenses per
10,000)

ln (Sex
Offenses per
10,000)

(1)

(2)

(3)

(4)

0.328
(0.414)
[.45]

0.266
(0.458)
[.57]

0.031
(0.031)
[.34]

0.028
(0.033)
[.43]

-0.075
(0.036)
[.06]

-0.092
(0.044)
[.06]

-0.006
(0.002)
[.04]

-0.007
(0.003)
[.03]

-1.131
(0.38)
[.01]

-1.065
(0.36)
[.01]

-0.077
(0.026)
[.01]

-0.073
(0.025)
[.01]

0.086
(0.029)
[.01]

0.090
(0.031)
[.02]

0.006
(0.002)
[.02]

0.006
(0.002)
[.02]

9

Assault/Crime Controls
Mean Offense Frequency
Mean Registry Size
Observations
R-squared

9

9.20
14.66

9.20
14.66

9.20
14.66

9.20
14.66

173,706

173,706

173,706

173,706

0.30

0.31

0.61

0.62

Notes: The dependent variable is annualized incidents per 10,000 persons in columns (1)-(2). In
columns (3)-(4), the dependent variable is the natural log of annualized incidents plus one per 10,000
persons. The unit of observation is a reporting agency (ORI) by month cell. Registry size is measured
in offenders per 10,000 persons (mean registry size is reported). The notification laws represent "full"
access by the public to information on offenders; for more details see the text in Section 5. Registry size
is empirically estimated from registry data, as explained in the text in Section 3. All regressions control
for county income and demographics, ORI fixed effects, year fixed effects, and month fixed effects.
Columns, as indicated, also control for rates of assault and other crime. Regressions are weighted by
the covered population in each ORI. Standard errors (in parentheses) are estimated via bootsrapping. Pvalues shown in backets.

Figure 1a: Registration and Notification Laws in NIBRS States

Registration
Community Notification

Public Access
Year Joined NIBRS

20
05

20
00

19
95

19
90

Colorado
Connecticut
Idaho
Iowa
Kentucky
Massachusetts
Michigan
Nebraska
North Dakota
Ohio
South Carolina
Texas
Utah
Vermont
Virginia

Internet

Note: Depicted are dates when registration, public access, and community notification laws are effective, and when
an internet site goes live. These include all laws, regardless of special restrictions. Utah's registration law was
effective in 1983. For details see Appendix Table 1.

Figure 1b: Registration and “Full” Notification Laws in NIBRS States

Registration
Community Notification

Public Access
Year Joined NIBRS

20
05

20
00

19
95

19
90

Colorado
Connecticut
Idaho
Iowa
Kentucky
Massachusetts
Michigan
Nebraska
North Dakota
Ohio
South Carolina
Texas
Utah
Vermont
Virginia

Internet

Note: Depicted are dates when 'full' versions registration, public access, and community notification laws are
effective, and when a complete internet registry site goes live. Utah's registration law was effective in 1983. For
details see Appendix Table 1 and the text in Section 5.

Figure 2: States Included in NIBRS Data Analysis

Note: Shaded states are those included in our analysis. They include: Colorado,
Connecticut, Idaho, Iowa, Kentucky, Massachusetts, Michigan, Nebraska, North,
Dakota, Ohio, South, Carolina, Texas, Utah, Vermont, and Virginia.

4000
3000
2000
1000
20
04

20
03

20
02

20
01

0
North Carolina Registry Size

20
00

19
99

19
98

19
97

19
96

0
19
95

Kentucky

6000
4000
2000

North Carolina

8000

5000

Appendix Figure 1: North Carolina and Kentucky
Registry Counts, 1995-2004

Kentucky Registry Size

Notes: This figure depicts the number of registered sex offenders in North Carolina and
Kentucky at the end of each year following the start of these registries in January of 1996
and 1995, respectively. The North Carolina numbers are from reports available on the
internet registry website and the Kentucky figures are taken from a report by Luallen
(2004). Unlike North Carolina, offenders in Kentucky had to be both released and
convicted after the law’s passage to be required to register.

