NBER WORKING PAPER SERIES

RECURSIVE CONTRACTS AND ENDOGENOUSLY INCOMPLETE MARKETS
Mikhail Golosov
Aleh Tsyvinski
Nicolas Werquin
Working Paper 22012
http://www.nber.org/papers/w22012

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
February 2016

Golosov and Tsyvinski thank the NSF for financial support. The views expressed herein are those
of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2016 by Mikhail Golosov, Aleh Tsyvinski, and Nicolas Werquin. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

Recursive Contracts and Endogenously Incomplete Markets
Mikhail Golosov, Aleh Tsyvinski, and Nicolas Werquin
NBER Working Paper No. 22012
February 2016
JEL No. C61,E2,E61
ABSTRACT
In this chapter we study dynamic incentive models in which risk sharing is endogenously limited
by the presence of informational or enforcement frictions. We comprehensively overview one of
the most important tools for the analysis such problems — the theory of recursive contracts.
Recursive formulations allow to reduce often complex models to a sequence of essentially static
problems that are easier to analyze both analytically and computationally. We first provide a selfcontained treatment of the basic theory: the Revelation Principle, formulating and simplifying the
incentive constraints, using promised utilities as state variables, and analyzing models with
persistent shocks using the first-order approach. We then discuss more advanced topics: duality
theory and Lagrange multiplier techniques, models with lack of commitment, and martingale
methods in continuous time. Finally, we show how a variety of applications in public economics,
corporate finance, development and international economics featuring incomplete risk-sharing
can be analyzed using the tools of the theory of recursive contracts.

Mikhail Golosov
Department of Economics
Princeton University
111 Fisher Hall
Princeton, NJ 08544
and NBER
golosov@princeton.edu
Aleh Tsyvinski
Department of Economics
Yale University
Box 208268
New Haven, CT 06520-8268
and NBER
a.tsyvinski@yale.edu

Nicolas Werquin
Toulouse School of Economics
21 allee de Brienne
31000 Toulouse
nwerquin@gmail.com

1

Introduction

Dynamic incentive problems are ubiquitous in macroeconomics. The design of social insurance
programs by governments, long-run relationships between banks and enterpreneurs, informal insurance contracts against idiosyncratic shocks provided in village economies, sovereign borrowing
and lending between countries can all be understood using the theory of dynamic incentives.
These models have been widely used in macroeconomics, public economics, international macro,
finance, developement, or political economy, both for explaining existing patterns in the data and
for normative policy analysis. The unifying feature of these models is that, at their essence, they
study endogenously incomplete markets, i.e., environments in which risk sharing is constrained
by (informational or enforcement) frictions and insurance arrangements arise endogenously.
One of the most important tools used for studying dynamic incentive problems is the theory of recursive constracts. Recursive formulations allow one to reduce often complex models
to a sequence of essentially static problems that are easier to analyze both analytically and
computationally. This substantially simplifies the analysis and the characterization of the optimal insurance arrangements in rich and realistic environments. The goal of this chapter is
to provide an overview of the theory of recursive contracts and give a number of examples of
application. The analysis in the theoretical part is self-contained; whenever a textbook approach
is not directly applicable (e.g., when the assumptions needed to apply the recursive techniques
in Stokey et al. (1989) are not met), we provide the necessary mathematical background. We
also discuss the strengths and weaknesses of several alternative approaches to solving dynamic
incentive problems that emerged in the literature. In the last part of the chapter we show how
the methods of recursive contracts can be used in a variety of applications.
Our paper is organized as follows. Section 2 considers a prototypical dynamic incentive
problem – insurance against privately observable idiosyncratic taste shocks under perfect commitment by the principal. The goal of this section is to provide an example of a self-contained,
rigorous and relatively general treatment of a dynamic incentive problem. We also use this
economy in subsequent sections to illustrate other approaches to the analysis of dynamic incentive problems. In Section 2 we highlight the three main steps in the analysis: first, applying
the Revelation Principle to set up a mechanism design problem with incentive constraints; second, simplifying this problem by focusing on one-shot incentive constraints; and third, writing
this problem recursively using “promised utilities” as state variables. We then show how this
recursive formulation can be used to characterize the properties of the optimal insurance arrangements in our economy. We derive general features of the optimal insurance contract and
characterize the long-run behavior of the economy in Section 2.4. We show how to overcome
the technical difficulties that arise when the idiosyncratic shocks are persistent in Section 2.5,
and conclude by showing how the same techniques can be applied to other dynamic incentive
problems, such as moral hazard.
Section 3 considers more advanced topics. We focus on three topics: using Lagrange mul-

1

tiplier tools in recursive formulations, studying dynamic insurance problems in economies in
which the principal has imperfect commitment, and applying martingale techniques to study
recursive contracts in continuous time. Section 3.1 discusses the Lagrangian techniques. Using Lagrangians together with the recursive methods of Section 2 greatly expands the class of
problems that can be characterized. We first provide an overview of the theory of constrained
optimization using Lagrange multipliers, with a particular focus on showing how to use them in
the infinite dimensional settings that frequently arise in macroeconomic applications. We then
show how to apply these theoretical techniques to incentive problems to obtain several alternative recursive formulations having some advantages relative to those discussed in Section 2. A
number of results in this section are new to the dynamic contracts literature. In Section 3.2 we
show how to analyze dynamic insurance problems in settings where the principal cannot commit
to the contracts. The arguments used to prove simple versions of the Revelation Principle under
commitment fail in such an environment; we discuss several ways to generalize it and write a
recursive formulation of the mechanism design problem. Our characterization of such problems
relies heavily on our analysis of Section 3.1. Finally, in Section 3.3, we show how to analyze
a dynamic contracting problem in continuous time using martingale methods and the dynamic
programming principle. To keep the analysis self-contained, we start by stating the results of
stochastic calculus that we use. Continuous-time methods often simplify the characterization of
optimal contracts, allowing for analytical comparative statics and easier numerical analysis of
the solution.
Section 4 gives a number of applications of the recursive techniques discussed in Sections 2
and 3 to various environments. We show that these diverse applications share three key features:
(i ) insurance is endogenously limited by the presence of a friction; (ii ) the problem is dynamic;
(iii ) the recursive contract techniques that we develop in the theoretical sections allow us to
derive deep characterizations of these problems. We explain how theoretical constructs such as
the incentive constraints and promised utilities can be mapped into concrete economic concepts,
and how the predictions of dynamic incentive models can be tested empirically and used for
policy analysis. In Section 4.1, we apply the techniques and results of Section 2 to public
finance where the endogenous market incompleteness and the limited social insurance arise
due to the unobservability of the shocks that agents receive. We derive several central results
characterizing the optimal social insurance mechanisms and show how to implement the optimal
allocations with a tax and transfer system that arises endogenously, without restricting the
system exogenously to a specific functional form. In Section 4.2 we show how recursive techniques
can be applied to study the effect of informational frictions on firm dynamics and optimal capital
structure. Section 4.3 presents applications of these techniques to study insurance in village
economies in developing countries where contracts are limited by enforcement and informational
frictions. Section 4.4 discusses applications to international borrowing and lending.

2

2

A simple model of dynamic insurance

In this section we study a prototypical model of dynamic insurance against privately-observed
idiosyncratic shocks. Our goal is to explain the key steps in the analysis and the main economic
insights in the simplest setting. The mathematical techniques that we use as well as the economic
insights that we obtain extend to many richer and more realistic environments. We discuss
examples of such environments in following sections.

2.1

Environment

We consider a discrete-time economy that lasts T periods, where T may be finite or infinite.
The economy is populated by a continuum of ex-ante identical agents whose preferences over
period-t consumption ct ≥ 0 are given by θt U (ct ), where θt ∈ Θ ⊂ R+ is an idiosyncratic “taste
shock” that the individual receives in period t, and U is a utility function.
Assumption 1. The utility function U : R+ → R is an increasing, strictly concave, differentiable function that satisfies the Inada conditions limc→0 U 0 (c) = ∞ and limc→∞ U 0 (c) = 0.
All agents have the same discount factor β ∈ (0, 1). In each period the economy receives e
units of endowment which can be freely transfered between periods at rate β.
The idiosyncratic taste shocks are stochastic. We use the notations θt = (θ1 , . . . , θt ) ∈ Θt to

denote a history of realizations of shocks up to period t and πt θt to denote the probability of

realization of history θt . We assume that the law of large numbers holds so that πt θt is also
the measure of individuals who experienced history θt .1 An individual privately learns his taste
shock θt at the beginning of period t. Thus, at the beginning of period t an agent knows his
history θt of current and past shocks, but not his future shocks. This implies that his choices in
period t, and more generally all the period-t random variables xt that we encounter, can only
be a function of this history.
Some parts of our analysis use results from probability theory and require us to be more
formal about the probability spaces that we use. A standard way to formalize these stochastic
processes is as follows.2 Let ΘT be the space of all histories θT and let πT be a probability



measure over the Borel subsets B ΘT of ΘT . Thus, ΘT , B ΘT , πT forms a probability

space. Any period-t random variable is required be measurable with respect to B Θt , that
T −t , where B is a Borel subset of Θt . This
is, for any Borel subset M of R, x−1
t (M ) = B × Θ
formalizes the intuition that the realization of shocks in future periods is not known as of period
t.
Until Section 2.5.1 we make the following assumptions about the idiosyncratic taste shocks:
Assumption 2. The set Θ ⊂ R+ of taste shocks is discrete and finite with cardinality |Θ|.
Agents’ shocks evolve according to a first-order Markov process, that is, the probability of drawing
1
2

The assumption that the law of large numbers holds can be justified formally (see Uhlig (1996), Sun (2006)).
See Stokey et al. (1989, Chapter 7) for a review of the measure-theoretic apparatus.

3

type θt in period t depends only on the period-(t − 1) type:

πt θt θt−1 = π (θt |θt−1 ) , ∀θt−1 ∈ Θt−1 , θt ∈ Θ,
where θt−1 is the last component of θt−1 .

We use the notation πt θt |θs for t > s to denote the probability of realization of history θt
up to period t conditional on the realization of history θs up to period s, with a convention that

πt θt |θs = 0 if the first s elements of θt are not θs (history θt in period t cannot occur if θs
was not realized up to period s). We use θst to denote (θs , . . . , θt ). Finally we index the elements
of Θ by the subscript (j) for j ∈ {1, . . . , |Θ|}, and assume that θ(1) < θ(2) < . . . < θ(|Θ|) .
We consider the problem of a social planner who chooses consumption allocations3 ct : Θt →
R+ to maximize agents’ ex-ante expected utility and has the ability to commit to such allocations
in period 0. At this stage we are agnostic about who this planner is. One can think of it as
a government that provides insurance to agents, or as some decentralized market arrangement.
We study the optimal insurance contract that such a planner can provide given the feasibility
constraint and informational constraints. We use the shortcut c to denote the consumption plan


ct θt t≥1,θt ∈Θt .
The ex-ante, “period-0” expected utility of all agents is denoted by U0 (c) and is given by
"
U0 (c) ≡ E0

T
X

#
β

t−1

θt U (ct ) =

T X
X



β t−1 πt θt θt U ct θt .

(1)

t=1 θt ∈Θt

t=1

Here E0 represents the (unconditional) expectation at time 0, before the first-period type θ1
is known. Under our assumption that resources can be freely transferred between periods, the
resource constraint is
" T
#
X
1 − βT
t−1
e.
(2)
E0
β ct ≤
1−β
t=1

Note that to write the left hand side of this feasibility constraint we again implicitly invoke the
law of large numbers.
When the realizations of the taste shocks are observable by the planner, this problem can
easily be solved explicitly. Let ζ > 0 be the Lagrange multiplier on the feasibility constraint.
The optimal allocation cfb in the case where shocks are observable (the “first best” allocation)
is a solution to


t
θt U 0 cfb
= ζ, ∀t ≥ 1, ∀θt ∈ Θt .
(3)
t θ

t is independent of period t or the
It is immediate to see that this equation implies that cfb
t θ
past history of shocks θt−1 , and only depends on the current realization of the shock θt . That is,
the informationally-unconstrained optimal insurance in this economy gives agents with a higher
3



Formally,
ct is a random variable over the probability space ΘT , B ΘT , πT that is measurable with respect

to B Θt .

4

realization of the shock θ in any period (hence whose current marginal utility of consumption
is higher) more consumption than agents with a lower realization of a taste shock.

2.2

The Revelation Principle and incentive compatibility

We are interested in understanding the properties of the best insurance arrangements that a
planner can provide in the economy with private information. This insurance can be provided
by many different mechanisms: the agents may be required to live in autarky and consume their
endowment, or may be allowed to trade assets, or may be provided with more sophisticated
arrangements by the planner. A priori it is not obvious how to set up the problem of finding
the best mechanism to provide the highest utility to agents. This problem simplifies once we
apply the results of the mechanism design literature, in particular the Revelation Principle.
Textbook treatments of the Revelation Principle are widely available (see, e.g. Chapter 23 in
Mas-Colell et al. (1995)). Here we outline the main arguments behind the Revelation Principle
in our context. This overview is useful both to keep the analysis self-contained and to emphasize
subtleties that emerge in using the Revelation Principle once additional frictions, such as lack
of commitment by the planner, are introduced.
Hurwicz (1960, 1972) provided a general framework to study various arrangements of allocation provision in environments with private information. He showed that such arrangements can
be represented as abstract communication mechanisms. Consider an arbitrary message space
M that consists of a collection of messages m. Each agent observes his shock θt and sends a
(possibly random) message mt ∈ M to the principal. The agent’s reporting strategy in period
t is a map σ̃t : Θt → ∆ (M ). The planner in turn chooses a (possibly stochastic) allocation
rule c̃t : M t → ∆ (R+ ), where ∆ (R+ ) denotes a probability measure on R+ . The strategies




σ̃ = σ̃t θt t≥1,θt ∈Θt and c̃ = c̃t mt t≥1,mt ∈M t induce a measure over the consumption
paths {ct }t≥1 ∈ RT+ , which we denote by c̃ ◦ σ̃. The expected utility of each agent is then
hP
i
T
t−1 U (c ) , where the superscript in Ec̃◦σ̃ means that the expectation is
equal to Ec̃◦σ̃
β
t
t=1
computed using the probability distribution c̃ ◦ σ̃ over the paths {ct }t≥1 . The strategy σ̃ is
incentive compatible for the agent if4,5
"
Ec̃◦σ̃

T
X

#
β t−1 θt U (ct ) − Ec̃◦σ̃

0

t=1

" T
X

#
β t−1 θt U (ct ) ≥ 0, ∀σ̃ 0 .

(4)

t=1

4
When T is allowed to be infinite, these sums may not be well-defined for all σ, and we require (4) to hold as
lim supT →∞ .
5
Note that hthe constraints (4) alsoi include all
h the constraints that iensure that σ̃ is optimal after any history
t
c̃◦σ̃ PT
s−t
t
c̃◦σ̃ 0 PT
s−t
t, θ , i.e., E
θs U (cs ) θ − E
θs U (cs ) θt ≥ 0, ∀σ̃ 0 .
s=t β
s=t β

5

A mechanism Γ̃ = (M, c̃ ◦ σ̃) is incentive compatible if it satisfies (4), and feasible if it satisfies
"
c̃◦σ̃

E

T
X

#
β

t−1

ct ≤

t=1

1 − βT
e.
1−β

(5)

The key insight behind the Revelation Principle is that any outcome c̃ ◦ σ̃ of an incentive
compatible and feasible mechanism can be achieved as the outcome of a direct truthtelling mechanism, in which agents report their types directly to the principal. Define a direct mechanism

as a reporting strategy σt : Θt → Θ. Define a truthtelling strategy σ truth as σttruth θt−1 , θ = θ
for all θt−1 , θ. The key observation is that there exists c = {ct }t≥1 , with ct : Θt → ∆ (R+ ) for
each t, such that the (induced) measure c ◦ σ truth replicates the measure c̃ ◦ σ̃.6
Theorem 1. (Revelation Principle.) The outcome of any incentive compatible and feasible
mechanism Γ̃ = (M, c̃ ◦ σ̃) is also the outcome of an incentive compatible and feasible direct

truthful mechanism Γ = Θ, c ◦ σ truth .
Proof. By construction, we have
c◦σ truth

E

" T
X

#
β

t−1

c̃◦σ̃

ct = E

t=1

" T
X

#
β

t−1

ct ,

t=1

so that the thruthtelling strategy satisfies (5). Any alternative strategy σ 0 induces a measure
c ◦ σ 0 which replicates the measure c̃ ◦ σ̃ 0 for some strategy σ̃ 0 in the original mechanism.
Therefore
" T
" T
#
#
X
X
0
truth
β t−1 θt U (ct ) ≥ 0, ∀σ 0 .
(6)
Ec◦σ
β t−1 θt U (ct ) − Ec◦σ
t=1

t=1

This concludes the proof.
We can simplify our analysis further by showing that there is no loss of generality in focusing on deterministic direct mechanisms, where each history of reports yields a deterministic
consumption allocation (rather than a measure) cdet
: Θt → R+ . We show:
t

Proposition 1. For any incentive compatible and feasible direct mechanism Γ = Θ, c ◦ σ truth

there exists an incentive compatible, feasible, deterministic direct mechanism Θ, cdet ◦ σ truth
that achieves the same ex-ante utility.
Proof. Consider any incentive compatible and feasible, but possibly stochastic, direct mechanism

6
The proof of this observation is straightforward. For simplicity, assume
that σ̃ and c̃ involve randomization

over a finite number of elements after
each history and let σ̃ t mt |θt be the probability that agent θt sends a

history of messages mt , and c̃t x|mt be the probability that the
delivers
x to an agent with
 principal
 consumption

P
a reported history mt . Then ct is simply defined by ct x|θt ≡ mt c̃t x|mt σ̃ t mt |θt . Given this definition
of c the payoff of any strategy σ̃ in the original mechanism (M, c̃ ◦ σ̃) can be replicated by a strategy σ.

6


Γ = Θ, c ◦ σ truth . Define a deterministic consumption allocation cdet
: Θt → R+ implicitly by
t



truth 
U cdet
θt = Ec◦σ
U (ct ) θt , ∀t ≥ 1, θt ∈ Θt ,
t

(7)

where the right hand side is the expected consumption given at time t under the mechanism Γ
to the agent who reports the history θt . Since U is concave by Assumption 1, Jensen’s inequality
implies that


truth 
θt , ∀θt ,
Ec◦σ
ct θt ≥ cdet
t

hence the mechanism Θ, cdet ◦ σ truth is feasible. By construction, we have that for all t, θt ,


truth 
det
truth 
Ec◦σ
U (ct ) θt = Ec ◦σ
U (ct ) θt , since the conditional expectation in (7) implies
that for any report the agent receives the same utility under c and under cdet , hence the mechanism is incentive compatible. This concludes the proof.


With a slight abuse of notation we will use c = ct θt t≥1,θt ∈Θt instead of cdet
t . The
incentive constraint in the deterministic direct mechanism can be written simply as
T X
X

 


β t−1 πt θt θt U ct θt − U ct σ 0t θt
≥ 0 for all ∀σ 0 .

(8)

t=1 θt ∈Θt

The proof of the Revelation Principle requires very few assumptions except the ability of the
social planner to commit to the long-term contract in period 0. Theorem 1 and Proposition 1
are very powerful results that provide a simple way to find informationally-constrained optimal
allocations. In particular, such allocations are a solution to the problem
V (e) ≡ sup
c

∞ X
X



β t−1 πt θt θt U ct θt
(9)

t=1 θt ∈Θt

subject to (2), (8).
If the supremum of this problem is attained by some vector c∗ , any insurance arrangement in
which agents consume c∗ in equilibrium is efficient.
In Sections 2.3, 2.4 and 2.5 we focus on describing general methods to solve the maximization
problem defined in (9). We give examples of specific insurance arrangements when discussing
various applications in Section 4.

2.3

Recursive formulation with i.i.d. shocks

The analysis of the solution to problem (9) is significantly simplified if shocks are independently
and identically distributed. In more general Markov settings, many of the same arguments
continue to hold but they are more cumbersome, and analytical results are more difficult to
obtain. For this reason we first focus on i.i.d. shocks and discuss general Markov shocks in
Section 2.5.

7

Assumption 3. Types θ are independent and identically distributed, that is, πt θt θt−1
P
π (θt ). Without loss of generality we assume that E [θ] = θ∈Θ π (θ) θ = 1.
2.3.1



=

Main ideas in a finite-period economy

In an economy with a finite number of periods, the maximization problem (9) is defined over
a closed and bounded set, because the feasibility constraint imposes that for all t, θt , we have

T
−T
0 ≤ ct θt ≤ β 1−β
e. In finite dimensions closed and bounded sets are
1−β (β minθ∈Θ π (θ))
compact and therefore by Weierstrass’ theorem the maximum of problem (9) is achieved, so
that we can replace the “sup” with a “max”. Moreover, it is easy to see that at the optimum
the feasibility constraint must hold with equality.
We want to simplify the set of the incentive constraints in problem (9). Equation (8) should
hold for all possible reporting strategy σ 0 . The set of such strategies is large; it consists of all
strategies in which an agent misreports his type in some (possibly all) states only in period
1, all strategies in which he misreports his types in some states in periods 1 and 2, an so on.
Most of these constraints are redundant. We say that that σ 00 is a one-shot deviation strategy

if σt00 θt−1 , θt 6= θt for only one θt . It turns out that if (8) is satisfied for one-shot deviations,
it is satisfied for all deviations in a finite period economy. Formally, we can write a one-shot
incentive constraint (see Green (1987)) as: for all θt−1 , θ, θ̂,
θU ct θt−1 , θ



+β

T −t
X

X



t+s
β s−1 πt+s θt+s θt+s U ct+s θt−1 , θ, θt+1

s=1 θt+s ∈Θt+s
T −t
 

X
t−1
≥θU ct θ , θ̂ + β

X

(10)
β s−1 πt+s θ


t+s





t+s
θt+s U ct+s θt−1 , θ̂, θt+1



.

s=1 θt+s ∈Θt+s

Proposition 2. Suppose that T is finite and shocks are i.i.d. An allocation c satisfies (8) if
and only if it satisfies (10).
Proof. That (8) implies (10) is clear, since (10) considers a strict subset of the possible deviations.
To show the converse, consider any reporting strategy σ 0 . Suppose that the last period in which
the agent misreports his type is period t. By (10), for any θt the agent gets higher utility
from reporting his type truthfully in that period than from deviating. Therefore, the strategy
σ 00 which coincides with σ 0 in the first t − 1 periods and reveals types truthfully from period
t onwards gives higher utility to the agent than σ 0 . Backward induction then implies that
truthtelling gives higher utility than σ 0 , establishing the result.
Proposition 2 simplifies the maximization problem (9) by replacing the constraint set (8)
with a smaller number of constraints (10). This simplified problem is still too complicated to be
solved directly. We next show how to re-write this problem recursively to reduce it to a sequence
of essentially static problems which can be easily analyzed analytically and computationally.

8

We take several intermediate steps to re-write constraints (2) and (10). First, observe that
the constraint set defined by equations (2) and (10) is not convex. Although much of the analysis
can be done for a non-convex maximization problem, we can obtain convexity by a simple change

of variables: instead of choosing consumption ct (θt ) we can choose utils ut (θt ) ≡ U ct θt .
The resource cost of providing u units of utils is C(u) = U −1 (u), where the cost function C,
defined on the range of U , is increasing, differentiable and strictly convex by Assumption 1. Let
u and ū be the (possibly infinite) greatest lower bound and smallest upper bound of U . Observe
that limu→u C(u) = 0 and limu→u C(u) = ∞. We use U to denote the domain of C, which is
(u, ū) if the utility function is unbounded below and [u, ū) if it is bounded below. Given this


change of variables, the incentive constraint (10) becomes linear in u = ut θt t,θt , while the
resouce constraint resource constraint becomes
" T
#
X
1 − βT
t−1
e,
E0
β C (ut ) ≤
1−β
t=1

which defines a convex set of feasible u.
The second simplification is to define a continuation (or promised) utility variable

vt θ

t



≡

T −t
X

X



t+s
β s−1 π θt+s θt θt+s ut+s θt , θt+1
.

(11)

s=1 θt+s ∈Θt+s

Using repeated substitution we get
 X



vt θ t =
π (θ) θut+1 θt , θ + βvt+1 θt , θ , ∀θt ,

(12)

θ∈Θ

where we use the convention vT = 0. Given this definition we can re-write the incentive constraints (10) as






θut θt−1 , θ + βvt θt−1 , θ ≥ θut θt−1 , θ̂ + βvt θt−1 , θ̂ , ∀θt−1 , θ, θ̂.

(13)

We are now ready to simplify our analysis by observing that while the original maximization
problem does not have an obvious recursive structure, its dual does. Our arguments imply that
the maximization
(9) can be re-written
as the maximization of the planner’s objective
 problem




t
t
over (u, v) =
ut θ t,θt , vt θ t,θt subject to the constraints (2), (12) and (13). Let
∗
∗
(u , v ) be the solution to that problem and v0 be the value of the maximum. Then, by
standard duality arguments, (u∗ , v∗ ) also minimizes the cost of providing (u, v) subject to the
incentive compatibility constraints and the “promise-keeping constraint”
"
E0

T
X

#
β t−1 θt ut θ

t=1

9


t

= v0 .

(14)


Using the definition of v1 θ1 , this constraint can be rewritten as
v0 =

X

π (θ) [θu1 (θ) + βv1 (θ)] .

(15)

θ∈Θ

Define the set Γ (v0 ) as
Γ (v0 ) = {(u, v) : (12), (13), (15) hold} .

(16)

We thus obtain that (u∗ , v∗ ) is the solution to
"
K0 (v0 ) ≡

max
(u,v)∈Γ(v0 )

E0 −

T
X

#
β t−1 C (ut ) .

(17)

t=1

The key simplification allowed by this formulation is that it can be easily solved using
recursive techniques. Let KT (·) ≡ −C (·), which has domain VT = U. Define the functions Kt
for t > 0 and their domains Vt recursively by
Kt (v) ≡

X

max

{(u(θ),w(θ))}θ∈Θ

π (θ) [−C (u (θ)) + βKt+1 (w (θ))]

(18)

θ∈Θ

subject to the promise keeping constraint:
v=

X

π (θ) [θu (θ) + βw (θ)] ,

(19)

θ∈Θ

and the incentive compatibility constraint:
 
 
θu (θ) + βw (θ) ≥ θu θ̂ + βw θ̂ , ∀θ, θ̂,

(20)

and
u (θ) ∈ U, w (θ) ∈ Vt+1 .
Equation
(18) defines the 
domain of Kt , denoted by Vt . It is easy to verify that it is either
h
T −t+1
T −t+1
1−β T −t+1
1−β T −t+1
u, 1−β ū or 1−β1−β u, 1−β1−β ū , depending on whether the utility function is
1−β
bounded below or not. It is easy to see that the function K0 defined in (17) satisfies (18) for t = 0.
Standard arguments establish that Kt is a continuous, strictly decreasing, strictly concave, and
differentiable function. For any value v ∈ Vt , let ~uv,t = {uv,t (θ)}θ∈Θ and w
~ v,t = {wv,t (θ)}θ∈Θ
denote the solution (i.e., the argmax) of the Bellman equation (18). We call (~uv,t , w
~ v,t ) the policy
functions of the Bellman equation. Given our assumption that C is strictly convex, these policy
functions are unique for each v, t.
We can now describe how to find the solution to (17). The main simplification comes from

the fact that if we know the optimal value vt∗ θt after any history θt , we can find the optimal
allocations in the nodes following θt without having to know the optimal allocations in any other
node. We start with t = 0. Since K0 (v) is (minus) the amount of resources required to achieve

10

T

the expected utility v, the initial value v0 must satisfy K0 (v0 ) = − 1−β
1−β e. The constrained∗
optimal utility allocation in period 1 for an agent with shock θ1 , u1 (θ1 ), is then given by the
policy function uv0 ,1 (θ1 ), and his expected utility starting from period 2, v1∗ (θ1 ), is wv0 ,1 (θ1 ).
The optimal utility allocation in period two for a history of shocks (θ1 , θ2 ), u∗2 (θ1 , θ2 ), is then
given by uwv0 ,1 (θ1 ),2 (θ2 ), and similarly for v2∗ (θ1 , θ2 ). This way we can use forward induction to
find the solution to (9), (u∗ , v∗ ). We say that the solution (u∗ , v∗ ) is generated by the policy
functions of the Bellman equation (18) given v0 .
2.3.2

Extension to an infinite period economy

In the previous section we showed a simple way to characterize the solution to a dynamic
contracting problem recursively when the number of periods is finite. For many applications
it is more convenient to work with infinite periods for at least two reasons. One is that many
problems do not have a natural terminal period and the assumption of infinite periods is more
convenient. The second reason is that the assumption of infinite periods allows us to obtain
sharp insights about the economic forces behind the optimal provision of incentives that are
more difficult to see in finite-period economies.
The key step in the analysis of Section 2.3.1 consisted of setting up the dual problem (17) and
its recursive representation (18). The infinite period analogue of the sequential dual problem is
"
K (v0 ) ≡ sup E0 −
u

∞
X

#
β t−1 C (ut )

t=1

(21)

subject to (8), (14).
We now show that the value function K defined in (21) can be written recursively, and that
the solution to this recursive formulation can, under some conditions, recover the maximum to
1
1
ū, v = 1−β
u, and V = [v, v̄) if the utility is bounded below
our primal problem (9). Let v̄ = 1−β

7
and V = (v, v̄) otherwise. We denote by B (v) the set of pairs (~u, w)
~ = {u (θ)}θ∈Θ , {w (θ)}θ∈Θ
that satisfy the constraints of the recursive problem, i.e.,
n
o
B (v) ≡ (~u, w)
~ ∈ U|Θ| × V|Θ| : (19), (20) hold .

(22)

We first prove an infinite period analogue of the Bellman equation (18). Several of the arguments
are based on those in Farhi and Werning (2007).
7

In our benchmark taste shock model it is easy to find the domain of K that we denote by V. Any constant
consumption sequence is incentive compatible, so it satisfies
set is bounded below by 0,
P(8). Since the consumption
1
the greatest lower bound for the set V must be v = U (0) θ∈Θ π (θ) θ = 1−β
u, where we used the normalization
1
Eθ = 1. If U (0) is finite, so is v. Similarly, since the consumption set is unbounded above, v̄ = 1−β
ū is the
least upper bound of V. Since (8) and (14) define a convex set, any v0 ∈ (v, v̄) can be attained by incentive
compatible allocations, which establishes that V = [v, v̄) if the utility is bounded below and V = (v, v̄) otherwise.
It is not always possible to characterize the domain of the value function in such a simple way. The general way
to characterize the set V is described in Proposition 8.

11

Proposition 3. Suppose that the utility function satisfies Assumption 1, shocks are i.i.d. and
T = ∞. Then K satisfies the Bellman equation
K(v) =

max
(~
u,w)∈B(v)
~

X

π (θ) [−C (u (θ)) + βK (w (θ))] .

(23)

θ∈Θ

Proof. We first show that the maximum in problem (23) is well-defined. That is, for any v ∈ V,
there exist (~uv , w
~ v ) that maximize the right hand side of (23) within the set B (v) defined in
(22). To do so we restrict the optimization over (~u, w)
~ to a compact set. Since the right hand
side of (23) is a function of two variables (~u, w)
~ that is continuous, this implies that it reaches
its maximum.
The allocation (~u0 , w
~ 0 ) defined by u0 (θ) = (1 − β) v and w0 (θ) = v for all θ ∈ Θ satisfies the
constraints (19) and (20) and yields value −C ((1 − β) v) + βK (v) ≡ K v . Therefore the r.h.s.
of the Bellman equation is larger than K v . Now suppose that for some θ, w (θ) is such that
βπ (θ) K (w (θ)) < K v . Then we have
X

π (θ) [−C (u (θ)) + βK (w (θ))] < K v ,

θ∈Θ

a contradiction. Thus we can restrict the search to {w (θ) s.t. βπ (θ) K (w (θ)) ≥ K v } and,
similarly, to {u (θ) s.t. − π (θ) C (u (θ)) ≥ K v }. Moreover, we have limu→ū −C (u) = −∞ and
limv→v̄ K (v) = −∞. To show the latter, consider the function K̄ (v) which maximizes the
objective function (21) subject to delivering lifetime utility v0 = v, without the incentive constraints. Obviously K̄ (v) ≥ K (v). We easily obtain that the solution to this relaxed problem


1
E C C 0−1 (γv θ) where γv > 0 is the multiplier on the promise-keeping conis K̄ (v) = − 1−β


straint. We have E θC 0−1 (γv θ) = (1 − β) v, so limv→v̄ γv = ∞ and hence limv→v̄ K̄ (v) = −∞.
This implies that limv→v̄ K (v) = −∞, and therefore the previous arguments lead to upper
¯θ , v̄¯θ for u (θ) and w (θ), respectively. Moreover, E [θu (θ) + βw (θ)] goes to −∞ if u (θ)
bounds ū
¯θ , w̄
¯θ . This contradicts the promise keeping
or w (θ) go to −∞, because of the upper bounds ū
constraint, and thus gives us lower bounds uθ , wθ for all θ. Therefore, we can restrict the search
h
i h
i
Q
¯θ × w , w̄
¯θ . This concludes the proof that
for {u (θ) , w (θ)}θ∈Θ to the compact set θ∈Θ uθ , ū
θ
the maximum in the right hand side of (23) is attained.
Next, we show that K, the solution to (21), satisfies the Bellman equation (23). We start
by showing that the left hand side is weakly smaller than the right hand side. Suppose that for
some v, we have
X
K (v) > max
π (θ) [−C (u (θ)) + βK (w (θ))] .
(~
u,w)∈B(v)
~

θ∈Θ

Thus there exists ε > 0 such that
K (v) ≥ E [−C (u (θ)) + βK (w (θ))] + ε, ∀ (~u, w)
~ ∈ B (v) .

12



Now consider an allocation u = ut θt t≥1,θt ∈Θt that satisfies incentive compatibility (8) and

delivers lifetime utility v. We can write u = {u1 (θ1 )}θ1 ∈Θ , {u2 (θ1 )}θ1 ∈Θ , where for all θ1 ,


u2 (θ1 ) = ut θ1 , θ2t t≥2,θt ∈Θt−1 . Let w2 (θ1 ) denote the lifetime utility achieved by u2 (θ1 ).8
2

The pair (~u1 , w
~ 2 ) = {u1 (θ1 )}θ1 ∈Θ , {w2 (θ1 )}θ1 ∈Θ satisfies (19) and (20), i.e., (~u1 , w
~ 2 ) ∈ B (v).
Thus, the previous inequality implies that
K (v) ≥E [−C (u1 (θ1 )) + βK (w2 (θ1 ))] + ε
" ∞
##
"
X

t−2
t
β C ut θ1 , θ2
+ε
≥E −C (u1 (θ1 )) + βE1 −
t=2

"
=E0 −

∞
X

#
β t−1 C ut θt



+ ε,

t=1

where the second inequality follows from the definition of K (w2 (θ1 )), since the allocation u2 (θ1 )
satisfies (8) and yields w2 (θ1 ). Since this reasoning holds for any allocation u that satisfies (8)
and delivers v, we get a contradiction.
Next we show the reverse inequality. Note that by definition of the supremum in (21), for


all v and ε > 0 there exists an allocation ũv,ε = ũv,ε
θt that satisfies (8) and delivers v with
t
cost
#
" ∞
X

E0 −
β t−1 C ũv,ε
θt
> K (v) − ε.
t
t=1

Let
(~uv , w
~ v ) ∈ arg

max
(~
u,w)∈B(v)
~

E [−C (u (θ)) + βK (w (θ))] .


Consider the incentive compatible allocation u defined by u1 θ1 = uv (θ1 ) for all θ1 ∈ Θ and

8

Note that the continuation utilities,
and in particular w2i(θ) for all θ, are well defined. Indeed, if not, then
hP


T
t−1
β
θt ut θt ∨ 0 = ∞. Since the cost function is convex, we have
t=1
hP
i
T
t−1
C (u) ≥ −B + A {θu ∨ 0} for some A, B > 0, and hence limT →∞ Es
C ut θ t
≥ −B + AUs+ = ∞.
t=1 β
This implies
" T
#
" T
#
X t−1
X
X t−1
t 
t 
s
β C ut θ
= ∞,
lim E0
β C ut θ
=
π0 (θ ) lim Es

for some s ≥ 0, Us+ ≡ limT →∞ Es

T →∞

t=1

T →∞

θ s ∈Θs

which contradicts the feasibility constraint (2).

13

t=1



w (θ ),ε
ut θt = ũt v 1
θt for all t ≥ 2, θt ∈ Θt . We have
"
K (v) ≥E0 −

∞
X

#
β

t−1

C ut θ

t



t=1

"

"

=E0 −C (uv (θ1 )) + βE1 −

∞
X

β t−2 C



w (θ ),ε
ũt v 1

θ


t

##

t=2

≥E0 [−C (uv (θ1 )) + βK (wv (θ1 ))] − βε
=

max
(~
u,w)∈B(v)
~

E [−C (u (θ)) + βK (w (θ))] − βε.

Since ε > 0 was arbitrary, we can let ε → 0 in this inequality. We have thus shown that the
value function (21) of the dual planner’s problem satisfies the Bellman equation (23).
The function K inherits the same properties as the function Kt in the finite period version
of this economy.
Lemma 1. Suppose that the utility function satisfies Assumption 1, shocks are i.i.d. and
T = ∞. Then K is continuous on V, strictly concave, strictly decreasing, differentiable, with
limv→v K (v) = limv→v K 0 (v) = 0 and limv→v̄ K (v) = limv→v̄ K 0 (v) = −∞.
Proof. The objective function in (21) is concave and the constraint set is convex, therefore, K is
weakly concave. To show the strict concavity of K, pick any v a , v b ∈ V such that v a 6= v b , and
let (~uva , w
~ va ) and (~uvb , w
~ vb ) be the corresponding policy functions that maximize the right hand
side of (23). The incentive constraint (20) implies that ~uva 6= ~uvb . Let v α ≡ αv a + (1 − α) v b ,
and (~uvα , w
~ vα ) be the corresponding policy function. Since (19) and (20) are linear in u (θ) and
w (θ), we obtain that
(α~uva + (1 − α) ~uvb , αw
~ va + (1 − α) w
~ vb ) ∈ B (v α ) .
Thus K satisfies
X
K (v α ) =
π (θ) [−C (uvα (θ)) + βK (wvα (θ))]
θ∈Θ

≥

X

π (θ) [−C (αuva (θ) + (1 − α) uvb (θ)) + βK (αwva (θ) + (1 − α) wvb (θ))] ,

θ∈Θ

so that by the strict concavity of −C and the weak concavity of K we get
K (v α ) >

α

X

π (θ) [−C (uva (θ)) + βK (wva (θ))]

θ∈Θ

+ (1 − α)

X

 
π (θ) [−C (uvb (θ)) + βK (wvb (θ))] = αK (v a ) + (1 − α) K v b ,

θ∈Θ

Therefore K is strictly concave.

14

The weak concavity implies that K is continuous on the interior of V (Excercise 4.23 in
Rudin (1976)). To show the continuity of K on V it remains to show that limv→v K (v) = K (v)

when the utility is bounded below. Since the only feasible solution that delivers v has ut θt = u
1
for all t, θt , we have in this case K (v) = − 1−β
C (u) = 0. Therefore showing the continuity at v
1
is equivalent to showing that limv→v K (v) = 0. Let K (v) = − 1−β
C ((1 − β) v) be the cost of

t
t
delivering ut θ = (1 − β) v independently of θ . Since this allocation is incentive compatible,
we have 0 ≥ K (v) ≥ K (v) for all v. K is continuous on V with limv→v K (v) = 0, therefore
limv→v K (v) = 0.
We already showed that limv→v̄ K (v) = −∞ in the proof of Proposition 3.
To show the strict monotonicity, for any v0a < v0b pick v ∈ (v, v0a ) and αv ∈ (0, 1) such that

v0a = αv v + (1 − αv ) v0b . Since K is strictly concave, we have K (v0a ) > αv K (v) + (1 − αv ) K v0b .



Letting v → v in this inequality, we obtain K (v0a ) ≥ 1 − αv K v0b ≥ K v0b , and hence

K is weakly decreasing. But then using K (v) ≥ K v0b in the previous inequality leads to



K (v0a ) > αv K v0b + (1 − αv ) K v0b = K v0b , so that K is strictly decreasing.
Next we show the differentiability of the cost function K in the case where the utility is
unbounded. A slightly different perturbational argument can be used to establish the differentiability when the utility function is bounded, taking care of the situations when the optimum
is at the corners (see, e.g., Farhi and Werning (2007)). Fix an interior v and define, for all
x ∈ (−ε, ε) for some small ε > 0,
Lv (x) =

X

π (θ) [−C (uv (θ) + x) + βK (wv (θ))] .

θ∈Θ

The allocation (~ux , w
~ x ) with ux (θ) = uv (θ) + x and wx (θ) = wv (θ) for all θ is incentive
compatible and delivers lifetime utility v + x. Therefore, for all x we have Lv (x) ≤ K (v + x),
with equality if x = 0. Since Lv (·) is concave and differentiable on (−ε, ε) (because −C (·) is),
the Benveniste-Scheinkman theorem (Benveniste and Scheinkman (1979), or Theorem 4.10 in
Stokey et al. (1989)) implies that K is differentiable at v and we have K 0 (v) = L0v (0). Direct
calculation of L0v (0) shows that
K 0 (v) =

X



π (θ) −C 0 (uv (θ)) ≤ 0.

(24)

θ∈Θ

The bounds K (v) ≤ K (v) ≤ K̄ (v) (see the proof of Proposition 3) and the limits limv→v K 0 (v) =
0 and limv→v̄ K̄ 0 (v) = −∞ imply that limv→v K 0 (v) = 0 and limv→v̄ K 0 (v) = −∞.
Finally, we are ultimately interested in recovering a solution to the problem (9). Analogous
to the finite period case, we call the solution to (23) a policy function and denote it by (~uv , w
~ v ).
For any initial v0 these functions generate (u, v) as in Section 2.3.1.
Proposition 4. Suppose that the utility function satisfies Assumption 1, shocks are i.i.d. and
e
T = ∞. Let v0 be defined by K (v0 ) = − 1−β
. If the sequence (u, v) generated by the policy
15

functions to the Bellman equation (23) given v0 satisfies


lim t→∞ E0 β t vt θt = 0

(25)



lim sup E0 β t vt σ t θt
≥ 0, ∀σ

(26)

and
t→∞

then (u, v) achieves the supremum of the primal maximization problem (9).
Proof. Let (u, v) denote the allocations generated by the policy functions (~u, w)
~ starting at v0 .
First, we show that (u, v) achieves the supremum of the dual problem (21), i.e., that (u, v)
satisfies the constraints (14) and (8) and attains K (v0 ). To see that the constraint (14) is
satisfied, note that by repeated substitution, (u, v) satisfies
"
v0 = E0

T
X

#
β

t−1

θt ut θ

t





+ β T E0 vT θT .

t=1

If (u, v) satisfies (25), then taking limits as T → ∞ (see footnote 8 for the existence of the limit
on the right hand side) leads to
v0 = E0

"∞
X

#
β

t−1

θt ut θ

t



.

t=1

To see that (u, v) satisfies the incentive compatibility constraint (8), consider any reporting
strategy σ. Since the policy functions (~u, w)
~ that generate (u, v) satisfy (20), repeated substitution implies that (u, v) satisfies
"
v0 ≥ E0

T
X

#
β t−1 θt u σ t θ


t



+ β T E0 vT σ T θT
.

t=1

If the condition (26) is satisfied, taking limits implies that
(

"

lim sup v0 − E0
T →∞

T
X

#)
β

t−1

t

θt U ct σ θ

t



≥ 0 ∀σ,

t=1

establishing that (u, v) satisfies (8).
We next show that (u, v) attains K (v0 ). Repeatedly applying the Bellman equation (23)
yields
#
" T
X



t−1
t
.
K (v0 ) = E0 −
β C ut θ
+ β T E0 K vT θT
t=1

16



Since lim supT →∞ β T E0 K vT θT
≤ 0 we obtain
"
K (v0 ) ≤ E0 −

∞
X

#
β

t−1

C ut θ

t



.

t=1

 P

t−1 C u θ t
But (u, v) satisfies the constraints of problem (21), thus K (v0 ) ≥ E0 − ∞
.
t
t=1 β
Therefore (u, v) achieves the supremum of the dual problem (21).
Second, we show that the maximum to the dual problem (21) is also a maximum to the
e
primal problem (9). Since (u, v) delivers v0 which satisfies −K (v0 ) = 1−β
, u satisfies the
feasibility constraint (2) and therefore V (e) ≥ v0 . Suppose that this inequality is strict, so that
there exists (u0 , v0 ) that delivers lifetime utility v00 > v0 , is incentive compatible and satisfies
P∞ t−1

e
E0
C (u0t ) ≤ 1−β
. The continuity and strict monotonicity of K (Lemma 1) imply
t=1 β

P∞ t−1
e
0
C (u0t ) ≥ −K(v00 ), this establishes a
. Since E0
that −K(v0 ) > −K (v0 ) = 1−β
t=1 β
contradiction.
If the utility function is bounded, then the limiting conditions (25) and (26) are automatically
satisfied and Proposition 4 implies simultaneously that the supremum to problem (21) is attained
and that it can be recovered from the policy functions of the Bellman equation (23). When the
utility function is unbounded, an extra step is needed to verify that the policy functions generate
a solution that satisfies the “continuity at infinity” conditions (25) and (26). These conditions
are standard in the statement of the one-shot deviation principle to ensure that the agent cannot
gain by some infinite sequence of deviations (see, e.g., Theorem 4.2 in Fudenberg and Tirole
(1991)). We show in an example in Section 2.4 how to verify ex-post these conditions with
unbounded utilities.
The analysis above can be simplified if we modify Assumption 1 and assume that the domain
of U is compact. In this case C (·) is a bounded function on a compact set [u, ū]. The results of
Propositions 3 and 4 can be proven immediately using standard contraction mapping arguments
(see Chapter 9 in Stokey et al. (1989)). Moreover, the results of Stokey et al. (1989) show that
the function K that satisfies the functional equation (23) is the unique fixed point of the Bellman
operator defined on the space of continuous and bounded functions by
B (k) (v) =

max
(~
u,w)∈B(v)
~

X

π (θ) [−C (u (θ)) + βk (w (θ))] ,

θ∈Θ

and that for all bounded and continuous k0 the sequence {kn }n≥0 defined by kn = B n k0 for
all n converges to K. This chararacterization is useful to compute the solution to the problem
numerically.

17

2.4

Characterization of the solution with i.i.d. shocks

In this section we characterize the solution to the Bellman equation (23). At the end of this
section we provide a simple example showing how to verify the limiting conditions (25) and (26)
when the utility function is unbounded.

For simplicity, we assume that θ can take only two values, Θ = θ(1) , θ(2) , with θ(1) < θ(2) .
The incentive constraints (13) with two shocks reduce to




θ(1) u θ(1) + βw θ(1) ≥ θ(1) u θ(2) + βw θ(2) ,

(27)





θ(2) u θ(2) + βw θ(2) ≥ θ(2) u θ(1) + βw θ(1) .

(28)

and

Proposition 5. Suppose that the utility function satisfies Assumption 1, shocks are i.i.d., |Θ| =
2 and T = ∞. The constraint (27) binds, and the constraint (28) is slack for all interior v.




Moreover uv θ(1) ≤ uv θ(2) and wv θ(1) ≥ v ≥ wv θ(2) , with strict inequalities for all

interior v. The policy functions uv (θ) , wv (θ) are continuous in v for all θ ∈ Θ. If wv θ(2) is
interior, the policy functions satisfy




K 0 (v) = E K 0 (wv ) = E −C 0 (uv ) , ∀v.

(29)

Proof. The proof proceeds by guessing that the constraint (28) is slack and solving a relaxed
problem (23) in which this constraint is dropped. We then verify ex post that (28) is satisfied.
The strict concavity of the objective function in (23) and the convexity of the constraint set then
implies that the solution to the relaxed problem is the unique solution to the original problem.
Let ξv ≥ 0 and γv ≥ 0 be the Lagrange multipliers on the incentive compatibility constraint
(27) and the promise-keeping constraint (19) in the relaxed problem. The first order conditions


with respect to u θ(1) and u θ(2) are



π θ(1) C 0 uv θ(1) − ξv θ(1) ≥ γv π θ(1) θ(1) ,



π θ(2) C 0 uv θ(2) + ξv θ(1) ≥ γv π θ(2) θ(2) ,

(30)
(31)



where these constraints hold with equality if uv θ(1) > u and uv θ(2) > u, respectively.


Similarly, the first order conditions with respect to w θ(1) and w θ(2) are



−π θ(1) K 0 wv θ(1) − ξv ≥ γv π θ(1) ,



−π θ(2) K 0 wv θ(2) + ξv ≥ γv π θ(2) ,

(32)
(33)



where these constraints hold with equality if wv θ(1) > v and wv θ(2) > v, respectively.


We first show that uv θ(1) , wv θ(1) are interior for all interior v. (We show below that


uv θ(2) is also interior.) Suppose that uv θ(1) = u. Since C 0 (u) = 0, (30) implies that

18



ξv = γv = 0. If uv θ(2) > u, then (31) would hold with equality, implying C 0 uv θ(2) = 0,


a contradiction. Thus we have uv θ(1) = uv θ(2) = u, and the same reasoning implies that


wv θ(1) = wv θ(2) = v, which contradicts the promise keeping constraint (19) when v is

interior. Therefore we must have uv θ(1) > u so that (30) holds with equality. An identical

reasoning implies that wv θ(1) > v, so that (32) holds with equality.
We now show that ξv > 0 for all interior v. If ξv = 0, then (32) and (33) imply that


wv θ(2) ≥ wv θ(1) by the concavity of K. Moreover (30) and (31) with θ(2) > θ(1) imply that


uv θ(2) > uv θ(1) . This violates the incentive constraint (27), and hence ξv > 0 if v > v. This
implies that the constraint (27) holds with equality for all v > v, and it also trivially holds as
an equality for v = v.
We show next that the solution to the relaxed problem satisfies (28). Suppose not, i.e.,




θ(2) uv θ(2) + βwv θ(2) < θ(2) uv θ(1) + βwv θ(1) .


Sum this equation with (27) which holds with equality, to obtain uv θ(2) < uv θ(1) , and thus


wv θ(2) > wv θ(1) > v. This implies that (33) holds with equality. But (32) and (33) with


ξv ≥ 0 then imply that wv θ(2) ≤ wv θ(1) , a contradiction. Therefore the incentive constraint
(28) is satisfied in the relaxed problem for all v. Moreover, if v is interior, the same reasoning
with ξv > 0 implies that (28) is slack.


Summing the incentive constraints (27) and (28) implies uv θ(2) ≥ uv θ(1) and hence



wv θ(1) ≥ wv θ(2) . In particular, uv θ(2) is interior for all interior v, and (31) holds with




equality. Now suppose v > v. If wv θ(2) = v, then wv θ(1) > wv θ(2) . If wv θ(2) >


v, then (33) holds with equality, and (32) with ξv > 0 yields wv θ(1) > wv θ(2) by the


strict concavity of K. We then obtain uv θ(1) < uv θ(2) from (27). When v is interior, we
saw that uv (θ) is interior for all θ and therefore Benveniste-Scheinkman arguments (see the
arguments leading to equation (24)) establish that K 0 (v) = E [−C 0 (uv )] = −γv . This equation
also holds at the boundary v = v since in this case both sides of this expression are equal

to zero. Therefore, equations (32) and (33), assuming that wv θ(2) is interior, imply that



−K 0 wv θ(1) > −K 0 (v) and −K 0 wv θ(2) < −K 0 (v) respectively, so that wv θ(2) < v <

wv θ(1) .
Next we show that the policy functions are continuous in v. The objective function in (23)
is continuous and strictly concave on U2 × V2 . Following the same steps as in the proof of
Proposition 3, we restrict the optimization over (~u, w)
~ to a compact set X ⊂ U2 × V2 . The
constraint set B (·) : V → X defined in (22) is then a continuous, compact-valued and convexvalued correspondence. Thus, by the theorem of the Maximum (see, e.g., Theorem 3.6 and
Exercise 3.11a in Stokey et al. (1989)), the function (~uv , w
~ v ) is continuous in v.
We now prove equation (29). We saw above that for all v ≥ v, K 0 (v) = E [−C 0 (uv )] = −γv .
Moreover, when v is interior, summing the conditions (30) and (31) (which both hold with
equality), and the conditions (32) and (33) (the former holds with equality, the latter does as

19



well if wv θ(2) > v) yields E [K 0 (wv )] ≤ E [−C 0 (uv )], with equality if wv θ(2) is interior.
Finally, this equation holds with equality if v = v.
Note finally that from (30) and (31), we obtain that for all interior v,
− θ(1) K 0 (v) < C 0 uv θ(1)



< −K 0 (v) < C 0 uv θ(2)



< −θ(2) K 0 (v) .

(34)

Proposition 5 highlights the main principle underlying the optimal provision of incentives in
dynamic economies. Consider the unconstrained first-best allocation, given by
1




1 0  fb
C 0 ufb
θ
=
C
u
θ
.
(1)
(2)
v
v
θ(1)
θ(2)

(35)

In this case the future continuation allocations are independent of the current realization of the
shock: the social planner redistributes resources from agents with shock θ(1) to agents with shock
θ(2) . As we discussed above, this allocation is not incentive compatible when shocks are private
information. To provide incentives, the social planner spreads out future promised utilities wv ,
rewarding agents who report a lower shock and punishing those who report a higher shock. In
exchange, a higher reported shock gives the agent a higher utility today. The bounds (34) imply
1
θ(2)

C 0 uv θ(2)



<

1
θ(1)

C 0 uv θ(1)



.

Therefore the spread in the current period utilities (or consumption allocations) is not as large
as in the first best allocation. This reflects the fact that private information makes redistribution
more costly. The resources are still being redistributed away from the θ(2) -type, which is implied
by the fact that his incentive constraint binds at the optimum.
Equation (29) shows how the planner allocates the costs of providing incentives over time.
Fluctuations in promised utilities are costly due to the concavity of the cost function, and it is
optimal to smooth these costs over time. The best smoothing can be achieved if the forecast of
future marginal costs of providing incentives based on the current information, Et [K 0 (vt+s )], is
equal to the current period marginal cost, K 0 (vt ), so that K 0 (vt ) is a random walk. This result
is a manifestation of the same general principle that underlies consumption smoothing in the
permanent income hypothesis (see Friedman (1957), Hall (1978)) or tax smoothing in public
finance (see Barro (1979)).
Analogous to other environments with cost smoothing, the random walk nature of K 0 (vt )
has powerful implications about the long-run properties of the solution.9 To derive these implications, we first introduce the notion of martingale and the Martingale Convergence Theorem
(see Billingsley (1995), Section 35):
9

See Chamberlain and Wilson (2000) for an analogous result in consumption smoothing models and Aiyagari
et al. (2002) for tax smoothing.

20


Definition 1. Let Xt θt be a random variable on the probability space (Ω, F, P). The sequence
{Xt , Ft }t=1,2,... is a martingale if:
(i ) {Ft }t≥1 is an increasing sequence of σ-algebras,
(ii ) Xt is measurable with respect to Ft ,
(iii ) E0 [|Xt |] < ∞, and
(iv ) Et [Xt+1 ] = Xt with probability 1.
A submartingale is defined as above except that the condition (iv ) is replaced by Et [Xt+1 ] ≥
Xt . Any martingale is a submartingale. We have the following important result (Theorem 35.5
in Billingsley (1995)):
Theorem 2. (Martingale Convergence Theorem.) Let {Xt }∞
t=0 be a submartingale. If
M ≡ supt E0 [|Xt |] < ∞, then Xt → X with probability 1, where X is a random variable on
(Ω, F, P) satisfying E0 [|X|] ≤ M .
To apply this result in our context, observe that the policy functions induce a law of motion
for the distribution of promised utilities over time. For any probability distribution Ψ on V,
define an operator T as
(T Ψ) (A) ≡

ˆ "X
V

#
π (θ) I{wv (θ)∈A} Ψ (dv) ,

(36)

θ∈Θ

for all Borel sets A ⊂ V. T Ψ defines another probability distribution on V. This operator allows
us to study the dynamics of the distribution of lifetime utilities in our economy. In particular, let
Ψ0 be a probability distribution on V that assigns probability 1 to v0 and define Ψt recursively
as Ψt = T Ψt−1 . In other words, initially in period 0 everyone is identical with the same lifetime
utility v0 . Over time idiosyncratic shocks lead to inequality in lifetime promises captured by the
distribution Ψt in period t. A distribution is invariant if it satisfies Ψ = T Ψ.

Suppose that the utility function is unbounded below, so that wv θ(2) is always inte
rior. Consider the random variable K 0 vt θt defined recursively on the probability space



(Θ∞ , B (Θ∞ ) , π∞ ) starting at K 0 (v0 ). The sequence K 0 vt θt , B Θt t=1,2,..., is a martin

gale. Indeed, B Θt t≥1 is an increasing sequence of σ-algebras, K 0 (vt ) is measurable with

respect to B Θt , E0 [|K 0 (vt )|] = −E0 [K 0 (vt )] = −K 0 (v0 ) < ∞, and Et [K 0 (vt+1 )] = K 0 (vt )
follows from Lemma 5. Hence all the conditions of Definition 1 are satisfied, and Theorem 2
implies that K 0 (vt ) converges almost surely to a random variable X. That is, for almost all
histories θ∞ ∈ Θ∞ , we have K 0 (vt (θ∞ )) → X (θ∞ ). The following proposition, whose proof
follows Thomas and Worrall (1990), further characterizes the limit of the sequence:
Proposition 6. Suppose that the utility function satisfies Assumption 1, shocks are i.i.d., |Θ| =

2 and T = ∞.10 If the utility function is unbounded below, then vt θt → −∞ as t → ∞ with
10

The condition |Θ| = 2 is not important for this proposition. It is easy to show that the margingale property
(29) holds for any number of shocks.

21

probability 1. If the utility function is bounded below by v, then the unique invariant distribution
of continuation utilities on V assigns mass 1 to the lower bound v.

Proof. Suppose that the utility function is unbounded below. Then Kt0 vt θt is a martingale,

and Theorem 2 implies that for almost all θ∞ , Kt0 vt θt converges to some random variable
X (θ∞ ). We now show that its limit X (θ∞ ) is equal to 0 almost surely.


Consider a path θt such that Kt0 vt θt → κ < 0. The sequence vt θt thus converges to
v̂ > v, solution to K 0 (v̂) = κ. With probability one, the state θ(2) occurs infinitely often on this
path. Take the subsequence composed of the dates {tn }n=1,2,... where the state θ(2) occurs. We


have limn→∞ vtn −1 θtn −1 = v̂ and limn→∞ vtn θtn = v̂. Since the policy function wv (θ) is
continuous in v for all θ ∈ Θ, we obtain


lim wvtn −1 (θtn −1 ) θ(2) = wv̂ θ(2) .

n→∞




But wvtn −1 (θtn −1 ) θ(2) = vtn θtn −1 , θ(2) = vtn θtn , hence we also have

lim wvtn −1 (θtn −1 ) θ(2) = v̂.

n→∞



This implies that wv̂ θ(2) = v̂, which contradicts the inequality wv̂ θ(2) < v̂ proved in Proposition 29.

Now suppose that the utility function is bounded below by v > −∞. In this case −Kt0 vt θt
is a (possibly unbounded) submartingale. Note that the point v is absorbing, i.e. uv (θ) = u and
wv (θ) = v for all θ ∈ Θ. Consider an invariant distribution Ψ of continuation utilities on V, and
let Supp (Ψ) ⊂ V denote its support. Let Mv denote the Markov chain characterizing the law of
motion of continuation utilities, starting at v. Define the set S1 ⊂ Supp (Ψ) consisting of all the
continuation utility values v for which Mv reaches v in a finite number of steps with positive
probability, and the set S2 = Supp (Ψ) \ S1 . By construction of S1 , every state v ∈ S1 \ {v}
is transient, so that such a v cannot be in the support of the invariant distribution. Now, for


v ∈ S2 , the Markov chain Mv defines a sequence vt θt t,θt . By construction of S2 , the process

Kt0 vt θt is a martingale and the previous arguments show that v cannot be in the support
of the invariant distribution. Therefore Supp (Ψ) = {v}.
The result of Proposition 6 is often referred to as the immiseration result. It shows that a
feature of the optimal contract is that agents’ consumption, c∗t , goes to 0 with probability 1 as
t → ∞. When the utility function is unbounded below, this implies that agents’ utility diverges
(0)
to −∞; otherwise the only invariant distribution is degenerate and assigns probability 1 to U1−β
.
∗
The fact that ct → 0 w.p. 1 does not mean that everyone’s consumption converges to zero.
As we saw in Proposition 5, an agent with shock realization θ(1) always gets a strictly higher
promised utility (and hence consumption) in the future. Thus there are always some agents
(whose measure goes to zero as t → ∞) with strictly positive consumption. In Section 3.2 we
shut down the intertemporal transfer of resources and show that the immiseration result still

22

holds in those settings. This will lead to an implication of the optimal provision of incentives:
in order to provide incentives for agents to reveal their private information, the planner needs
to increase inequality without bounds over time. As time goes to infinity this inequality grows
until a measure 0 of agents consume the entire endowment of the economy.
The intuition for this result is as follows. To provide incentives to the agents to reveal
information in the current period, the principal needs to commit to increasing inequality (in
promised utilities and therefore consumption) in the future. When the interest rates are equal
to the discount factor, as we assumed in this section, there are no offsetting forces and inequality
under the optimal contract grows over time. In the infinite period economy it approaches an
extreme level as t → ∞ in which only a measure zero of agents have positive consumption. We
revisit this result in subsequent sections, especially in Sections 2.4.1 and 3.2.
2.4.1

Existence of a non-degenerate invariant distribution

In this section we show a simple example where there exists a non-degenerate invariant distribution of utilities if additional constraints are imposed. We study the simplest case in which
the planner is required to promise future utilities in a compact set [w, w̄], where v < w < w̄ < v̄.
In Section 3.2 we show how similar constraints can emerge from more sophisticated political
economy arguments, but for now we simply impose11
w (θ) ∈ [w, w̄] , ∀θ ∈ Θ

(37)

in problem (23). It is easy to see that all the properties of the modified Bellman equation
continue to satisfy the results of Lemma 1 except for the fact that K 0 (v) is now strictly negative
and finite on the set [w, w̄].
Lemma 2. Suppose that all the assumptions of Proposition 5 are satisfied and in addition the


constraint (37) is imposed. Then there are no absorbing points: wv θ(1) > wv θ(2) for all
v ∈ [w, w̄].


Proof. Suppose wv θ(1) = wv θ(2) = v ∈ [w, w̄) for some v, implying (from (27) and (19))


1
that uv θ(1) = uv θ(2) = (1 − β) v. Thus K (v) = K (v) ≡ − 1−β
C ((1 − β) v), where K (v)
was defined in the proof of Proposition 3. Substracting equations (30) and (32) (written as an

inequality because of the condition wv θ(1) ≥ w), we obtain
K 0 (v) ≤ −

1
θ(1)

C 0 ((1 − β) v) =

1
θ(1)

K 0 (v) .

But θ(1) < 1 contradicts the fact that K (v 0 ) ≥ K (v 0 ) for all v 0 > v. For v = w̄, a similar reasoning with equations (31) and (33) (written as an inequality because of the condition
11

Our arguments here adapt Atkeson and Lucas (1995), Phelan (1995). See also Farhi and Werning (2007),
Hosseini et al. (2013).

23



wv θ(2) ≤ w̄) implies that K 0 wv θ(2) ≥

1
θ(2)

K 0 wv θ(2)



+

ξv
π (θ(2) )



1−

θ(1)
θ(2)



We then show that a non-degenerate long-run distribution of utilities and consumption exists.
Proposition 7. Suppose that all the assumptions of Proposition 5 are satisfied and in addition
the constraint (37) is imposed. Then there exists a unique invariant and non-degenerate distribution Ψ of utilities, and for any initial measure Ψ0 on the state space, T n (Ψ0 ) converges to
Ψ∗ as n → ∞ at a geometric rate that is uniform in Ψ0 .
Proof. The result follows from Theorem 11.12 in Stokey et al. (1989), which holds if condition
M p. 348 in Stokey et al. (1989) is satisfied. To show this condition, it is sufficient to show that
there exists ε > 0 and an integer N < ∞ such that, for all v ∈ [w, w̄], P N (v, w) ≥ ε, where P
denotes the transition matrix of the Markov chain M that characterizes the law of motion of
continuation utilities; that is, the probability of reaching w starting in N steps from any v is at
least as large than ε.
To show this we proceed in two steps. First, we prove that if the continuation utility v in the
current period is close enough to w, receiving a high taste shock θ(2) implies that the promised
utility in the next period is w. That is, there exists ε > 0 such that, for all v ≤ w + ε, we

have wv θ(2) = w. Suppose by contradiction that this is not the case, and consider a sequence

vn > w with limn→∞ vn = w, such that wvn θ(2) > w for all n. The martingale property (29)
then writes




K 0 (vn ) = π θ(1) K 0 wvn θ(1) + π θ(2) K 0 wvn θ(2) .


Letting n → ∞ in this equation imposes ww θ(1) = ww θ(2) = w, which contradicts Lemma
2.
Second, we prove that there exists δ > 0 such that, for any v > w + ε, receiving a high taste

shock θ(2) implies that the promised utility in the next period, wv θ(2) , is smaller than v − δ.

To show this, note that since wv θ(2) is continuous in v, it is either bounded away from the

45° line for w > w + ε, or wv θ(2) = v for some v ∈ [w + ε, w̄]. By the martingale property, the

latter implies that wv θ(1) = v, contradicting Lemma 2.
These results imply that there exists N < ∞ such that, for any v ∈ [w, w̄], the promised
utility after a sequence of N high taste shocks θ(2) , starting from v, is w. This implies that
N
ε < π θ(2)
is a uniform lower bound on the probability of being at w in N steps. Thus
condition M is satisfied in Stokey et al. (1989), which concludes the proof.
The immiseration result does not hold in the case where expected discounted utilities from
each period onward are constrained by (37), because the lower bound w > v acts as a reflective (rather than absorbing) barrier (Lemma 2), creating mean reversion that leads to a
non-degenerate invariant distribution.

24

2.4.2

A simple example

In this section we address one remaining issue of our analysis. Proposition 4 showed that
the allocation generated by the policy functions of our Bellman equation is the solution to the
original problem (9) as long as it satisfies the limiting conditions (25) and (26). These conditions
are trivially satisfied if the utility function is bounded, but many convenient functional forms
assume unbounded utility. In this section we show a simple example with an unbounded utility
function that allows us to easily verify conditions (25) and (26). This example also leads to a
characterization of the solution to the Bellman equation “almost” in closed form. We assume
a logarithmic utility U (c) = ln c; similar arguments extend to CRRA and CARA preferences.
Note that (u, v) ∈ Γ (v0 ) if and only if (u − (1 − β) v0 , v − v0 ) ∈ Γ (0), where Γ (·) is defined in
(16). We can thus re-write the dual planner’s problem (21) as
"
K (v0 ) =

max
(u,v)∈Γ(v0 )

E0 −

max
(ũ,ṽ)∈Γ(0)

#
β

t−1

exp (ut )

t=1

"
=

∞
X

E0 −

∞
X

#
β t−1 exp (ũt + (1 − β) v0 ) = exp ((1 − β) v0 ) K (0) .

t=1

This implies that if {u0 (θ) , w0 (θ)}θ∈Θ is the solution to the Bellman equation (23) for v = 0,
then {u0 (θ) + (1 − β) v, w0 (θ) + v}θ∈Θ is the solution to (23) for any v. This property allows us
to establish bounds on (25) and (26). If we start with some initial v0 and generate (u, v) using


the policy functions uv θt , wv θt of the Bellman equation (23) as described in Section 2.3,
we have


vt θt =wvt−1 (θt−1 ) (θt ) = vt−1 θt−1 + w0 (θt )

=wvt−2 (θt−2 ) (θt−1 ) + w0 (θt ) = vt−2 θt−2 + w0 (θt−1 ) + w0 (θt )
t
X

= . . . = v1 θ1 + w0 (θ2 ) + . . . + w0 (θt ) = v0 +
w0 (θs ) .
s=1

Let A ≡ minΘ {w0 (θ)} and Ā ≡ maxΘ {w0 (θ)}, so that A ≤ w0 (θ) ≤ Ā for all θ ∈ Θ. Then


β t (v0 + tA) ≤ β t vt θt ≤ β t v0 + tĀ for all t, θt . Since limt→∞ β t t = 0, this implies that

limt→∞ β t vt θt = 0 for all θ∞ ∈ Θ∞ , which implies both (25) and (26).
Since the value function K is homogeneous, it is easy to find it “almost” in closed form. Our
arguments established that K(v) = a exp ((1 − β) v) for some a < 0. The parameter a can then
be found as a fixed point of the equation
a=

max
(~
u,w)∈B(0)
~

X

π (θ) [− exp (u (θ)) + βa exp ((1 − β) w (θ))] .

θ∈Θ

The arguments used in this example can be extended
to utility
 functions
  in the CRRA or CARA

1
1
classes by observing that if (u, v) ∈ Γ (v0 ) then |v0 | u, |v0 | v ∈ Γ |vv00 | .

25

2.5

Autocorrelated shocks

We now address the case where the taste shocks θ follow a first-order Markov process. The
goal of this section is to derive a recursive formulation for the planner’s dual problem. We

assume that the probabilities of the first period types θ1 ∈ Θ are given by π θ1 θ(1) , i.e.,
as if the type realization in period 0 was the seed value θ(1) . This assumption carries no loss
of generality and simplifies the exposition. Fernandes and Phelan (2000) show how to write a
recursive formulation of the planner’s problem.
We define the analogue of the temporary incentive compatibility constraint (10) in the case
where shocks are first-order Markov as follows. For all θt−1 , θ, θ̂,
θU ct θt−1 , θ



+β

T −t
X

X



t+s
β s−1 π θt+s |θ θt+s U ct+s θt−1 , θ, θt+1

s=1 θt+s ∈Θt+s
T −t
 

X
≥θU ct θt−1 , θ̂ + β
s=1

X

(38)
β

s−1

π θ

t+s







|θ θt+s U ct+s θ

t−1

t+s
, θ̂, θt+1



.

θt+s ∈Θt+s

The one-shot-deviation result of Proposition 2 extends to the problem with persistent shocks:
Lemma 3. Suppose that either T is finite, or U is bounded. Suppose moreover that the shocks
θ follow a first-order Markov process. An allocation c satisfies (8) if and only if it satisfies (38).
Proof. Suppose that (8) is violated for some strategy σ 0 but (38) holds. If σ 0 involves misreporting in finitely many nodes, the arguments of Proposition 2 apply directly. If T is infinite
and σ 0 recommends lying at infinitely many nodes, we have, by the previous result,
∞ X
X

∞ X

 X


β t−1 πt θt θt U ct θt ≥
β t−1 πt θt θt U ct σ 0t θt
− ...

t=1 θt ∈Θt

t=1 θt ∈Θt


∞
X
T 
... − β


X

β s−1 πT +s θ


T +s

θT +s U cT +s σ 0T +s θ


T +s

− U cT +s θ


T +s

.

s=1 θT +s ∈ΘT +s

Since the utility is bounded, the second line converges to zero as T → ∞, which establishes that
if c satisfies (38) then it satisfies (8).
We follow Section 2.3 and re-define our maximization with respect to ut (θt ) rather than
ct (θt ). We now emphasize the main differences that persistent shocks introduce. As in Section
2.3, we start by assuming that T is finite.

26

Finite-Period Economy. In this section we consider the case T < ∞. For any history θt ∈ Θt

and any θ0 ∈ Θ, define vt θt |θ0 as
t

vt θ θ

0



≡

T −t
X

X



t+s
t+s 0
θ θt+s ut+s θt , θt+1
,
β s−1 π θt+1

(39)

s=1 θt+s ∈Θt+s


t+s
where θt , θt+1
denote the histories θt+s whose first t elements are θt . This allows us to write
(38) as






θut θt−1 , θ + βvt θt−1 , θ |θ ≥ θut θt−1 , θ̂ + βvt θt−1 , θ̂ |θ , ∀θt−1 , θ, θ̂.

(40)

Unlike the case of i.i.d. shocks, considered in Section 2.3.1, the continuation utility of an agent
who reports θt depends not only on the history of reports but also on the true period-t shock
θt0 of the agent. The economic intuition for this result is that when shocks are autocorrelated,
the realization of the shock θt0 is informative about the realization of future shocks from period
t + 1 onward. Repeated substitution allows us to re-write vt as
 X



vt θ t θ 0 =
π θ θ0 θut+1 θt , θ + βvt+1 θt , θ |θ , ∀θt , θ0 ,

(41)

θ∈Θ


with the convention that vT θT |θ0 = 0 if T is finite. The initial utility v0 is given by
v0 =

X


π θ θ(1) [θu1 (θ) + βv1 (θ |θ )] .

(42)

θ∈Θ



Let v = vt θt |θt0 t≥1,θt ∈Θt ,θ0 ∈Θ . The set Γ (v0 ) is now defined as the set of allocations
t
(u, v) that satisfy (40), (41), (42). The direct extension of the arguments of Section 2.3 imply
that the optimal incentive compatible allocation (i.e., the solution to the primal problem (9))
exists and is a solution to the dual maximization problem
"
K̃ (v0 ) ≡

max
(u,v)∈Γ(v0 )

−

T X
X

#
β t−1 πt θt θ(1) C ut θ



t

.

(43)

t=1 θt ∈Θt

This problem can be written recursively following the same ideas as we used to obtain the
Bellman equations (18) and (23), with two differences: (i ) the state space is larger when the
shocks are autocorrelated, and (ii ) the space of feasible values for the state variables is now more
difficult to characterize. We show both of these differences using backward induction arguments.
The need for the larger state space can be seen already from the incentive constraints. Each

history of reports θt has an associated |Θ|-dimensional vector of “promised utilities” vt θt |· =

 |Θ|

vt θt θ(j) j=1 , where for each j, vt θt θ(j) is the promised utility allocated to the agent
who reports history θt and whose realized type in period t is actually θ(j) . Moreover, the
expectation over the future realizations of shocks in period t+1 depends on the period-t shock θt .

27

Therefore the state space has dimensionality |Θ| + 1. We now describe the recursive construction



of the value function Kt v θ(1) , . . . , v θ(|Θ|) , θ− and its domain Vt × Θ. Let VT be the
space of all vectors v (·) ∈ R|Θ| with the property that there exists some u ∈ U such that


P
v θ(i) = u θ∈Θ π θ θ(i) θ for all i ∈ Θ. Let KT (v (·) , θ) = −C (u) for all such v (·) ∈ VT .
This definition simply captures the fact that in the last period the principal cannot provide any
insurance against the period-T shocks (by incentive compatibility (40)), and KT is then (minus)
the cost of the feasible promises that the principal can make in period T − 1. For t > 0 define
Kt recursively as
Kt (v (·) , θ− ) =

max

{u(θ),w(θ|· )}θ∈Θ

X

π (θ |θ− ) [−C (u (θ)) + βKt+1 (w (θ |· ) , θ)]

(44)

θ∈Θ

subject to the promise-keeping constraints
 X

v θ(j) =
π θ θ(j) [θu (θ) + βw (θ |θ )] , ∀j ∈ {1, . . . , |Θ|} ,

(45)

θ∈Θ

the incentive compatibility constraints
 


θu (θ) + βw (θ |θ ) ≥ θu θ̂ + βw θ̂ |θ , ∀θ, θ̂ ∈ Θ,

(46)

and
u(θ)∈ U, w(θ|·) ∈ Vt+1 , ∀θ ∈ Θ.

(47)

The domain of Kt is Vt × Θ, where Vt is defined as the set of all v (·) ∈ R|Θ| with the property
that there exist {u (θ) , w (θ |· )}θ∈Θ such that the constraints (45) and (47) are satisfied.
So far we defined Kt from purely mathematical considerations by observing that the solution
to the maximization problem (43) after any history θt could be found independently of any other
history θ̂t , as long as we keep track of the vector v (·) and the realization of the period-t shock θt .
It is useful to descibe the economic intuition behind these equations. Equation (46) is simply
the incentive constraint, familiar from Section 2.3. Equation (45) for θ(j) = θ− summarizes
the expected utility that an agent with period-(t − 1) shock θ− receives in period t. This
equation is the analogue of the promise-keeping constraint (19) in the i.i.d. case. Equations
(45) for θ(j) 6= θ− are auxillary “threat-keeping” constraints, which allow us to keep track of
the incentives provided in the previous period. Since allocations are incentive-compatible, no
agent misrepresents his type “along the equilibrium path” and hence no agent actually obtains


utility v θ(j) for θ(j) 6= θ− . One can think of those v θ(j) as threats that the principal
chooses in period (t − 1) to ensure that agents do not misrepresent their type. Equation (45)
in period t ensures that the principal’s subsequent choices are consistent with that threat.
The principal chooses a common allocation for all the agents that report θ− . This common
allocation simultaneously delivers utility v (θ− ) to the agents with true type θ− (i.e., when

expected values are computed using the probabilities π (θ |θ− )), and v θ(j) to the agents with

28


true types θ(j) (i.e., when expected values are computed using the probabilities π θ θ(j) ) for
each j ∈ {1, . . . , |Θ|}.
The relationship between the function K0 (v (·) , θ− ) defined in (44) and the function K̃0 (v0 )
defined in (43) is as follows. Observe that there are no auxiliary threat-keeping constraints in
the set Γ (v0 ). It is mathematically equivalent to saying that those constraints are slack. Thus,

given our assumption that shocks in period 1 are drawn from π ·|θ(1) , the relationship between
K0 (v (·) , θ− ) and K̃0 (v0 ) is simply
K̃ (v0 ) =


max
K1 v(·), θ(1) .
v(·)∈V0 ,v (θ(1) )=v0

(48)

This gives a simple way to find the solution (u∗ , v∗ ) for the primal problem (9). The value
of this problem problem should be such that the feasibility constraint holds with equality, which
T
can be found as a solution to K̃ (v0 ) = − 1−β
1−β e. Then from the maximization problem (48) we
generate the vector v0 (·). Finally, we use the policy functions to the Bellman equation (44) to
generate the solution (u∗ , v∗ ), analogous to the i.i.d. case.
Infinite-Period Economy. We now turn to the recursive formulation in the infinite-period
economy, T = ∞. Assume for simplicity that the utility function is bounded, i.e. U = [u, ū].
Let V be the set of promised utility vectors v (·) for which there exists an allocation u such that


v θ(j) =

∞ X
X



β t−1 π θt θ(j) θt ut θt , ∀j ∈ {1, . . . , |Θ|} ,

(49)

t=1 θt ∈Θt

and for all t ≥ 1, for all θt−1 , θ, θ̂,


∞
X

X



t+s
t−1
s−1
t+s
t−1
θut θ , θ + β
β π θ |θ θt+s ut+s θ , θ, θt+1


s=1 θt+s ∈Θt+s


∞
X




X

t+s
≥θut θt−1 , θ̂ + β
.
β s−1 π θt+s |θ θt+s ut+s θt−1 , θ̂, θt+1


t+s
t+s
s=1 θ

(50)

∈Θ

For any θ− ∈ Θ and v (·) ∈ V, the Bellman equation writes
K (v (·) , θ− ) =

max

{u(θ),w(θ|· )}θ∈Θ

X

π (θ |θ− ) [−C (u (θ)) + βK (w (θ |· ) , θ)]

(51)

θ∈Θ

subject to (45), (46), and u (θ) ∈ U, w (θ |· ) ∈ V for all θ.
This Bellman equation is a direct extension of the Bellman equation (23) in the i.i.d. case.
The need to keep track of a larger number of state variables in the case of general Markov shocks
follows from our discussion in the finite period economy. One additional consideration that (51)
introduces is that it is defined over a set V, which needs to be found. The work of Abreu et al.

29

(1990) provides a method of finding this set and characterizing its properties.
Proposition 8. The set V is non-empty, compact and convex. It is the largest bounded fixed
e ⊂ R|Θ| as
point of the operator A defined for an arbitrary compact set V
e=
AV



e ∀θ .
v (·) s.t. ∃ {u (θ) , w (θ |· )}θ∈Θ :(45), (46) hold and w (θ |· ) ∈ V,

It is the limit of the monotonically decreasing sequence of compact sets {Vn }n=0,1,... defined as
h
i|Θ|
T
θ(1)
θ(|Θ|)
V0 = 1−β
and Vn = A Vn−1 for n ≥ 1, so that V = limn→∞ Vn = ∞
u, 1−β
ū
n=1 Vn .
Proof. The set V is nonempty because any allocation that is independent of the report is incen

tive compatible. V is convex since vu θ(j) is affine in u for all j ∈ {1, . . . , |Θ|}, where vu θ(j)
is defined by the right hand side of (49). The construction of V as the largest compact fixed
point of the operator A follows from the results of Abreu et al. (1990). Here we give a simple
proof that V is compact and is a fixed point of A .



Let U denote the space of allocations u = ut θt t≥1,θt ∈Θt , with ut θt ∈ [u, ū] for all t ≥ 1,
θt ∈ Θt . Since Θt < ∞ for all t ≥ 1, U is the countable product of the compact metric spaces
[u, ū]. Embedding U with the product topology, we obtain that U is a compact metric space
(the compactness follows from a diagonalization argument). A sequence u(n) in U converges as

(n)
n → ∞ if and only if all of its projections ut θt converge in [u, ū] as n → ∞.
We now show that V is compact. Since the utility function is bounded, vu is bounded and

∞
hence V is bounded. To prove that V is closed, let ~v (n) n=1 be a Cauchy sequence in V, and



∞
let ~v (∞) = v (∞) θ(j) j=1,...,J its limit. Let u(n) n=1 be a sequence of allocations such that



∞
v (n) θ(j) = vu(n) θ(j) for all j ∈ {1, . . . , |Θ|} and all n ≥ 1. Since U is compact, u(n) n=1
 (ϕ(n)) ∞
contains a convergent subsequence u
, denote by u(∞) its limit. We have u(∞) ∈ U.
n=1

Since vu θ(j) is continuous in u we get, for all j ∈ {1, . . . , |Θ|},




v (∞) θ(j) = lim v (ϕ(n)) θ(j) = lim vu(ϕ(n)) θ(j) = vu(∞) θ(j) .
n→∞

n→∞

Finally, since u(n) satisfies the incentive constraints (50), by continuity we obtain that u(∞)
satisfies (50) as well. Thus ~v (∞) ∈ V, hence V is closed. Since V ⊂ R|Θ| , we obtain that V is
compact.
Next we show that V is a fixed point of A , that is A V = V. First let ~v ∈ V. Then there exists




u = ut θt t,θt ∈ U that satisfies the incentive constraints (50) and delivers v θ(j) = vu θ(j)
for all j ∈ {1, . . . , |Θ|}. Define the allocation rule {u (θ) , w (θ |· )}θ∈Θ by u (θ) = u1 (θ) and


w θ θ(j 0 ) = vu∞
θ(j 0 ) , where u∞
2 (θ) is the continuation of the allocation u from period 2
2 (θ)
1
onwards given the history θ = θ. We have w (θ |· ) ∈ V for all θ ∈ Θ because the allocation

30

u∞
2 (θ) satisfies the incentive compatibility condition (50) after all histories. Moreover, we have
θu (θ) + βw (θ |θ ) = θu1 (θ) + βvu∞
(θ) (θ)
  2


 
≥θu1 θ̂ + βvu∞ (θ̂) (θ) = θu θ̂ + βw θ̂ |θ ,
2

where the inequality follows from (50). Hence {u (θ) , w (θ |· )}θ∈Θ satisfies (46). Finally, by
construction {u (θ) , w (θ |· )}θ∈Θ satisfies (45). Thus, ~v ∈ A V and hence V ⊂ A V. For the
converse, suppose that ~v ∈ A V. Then there exists some allocation rule {u (θ) , w (θ |· )}θ∈Θ such
that the incentive constraints (46) hold and w (θ |· ) ∈ V for all θ. Define an allocation u as
follows. Let u1 (θ) = u (θ). For each θ ∈ Θ, since w (θ |· ) ∈ V there exists some allocation


ũ (θ) such that vũ(θ) θ(j) = w θ θ(j) for all j ∈ {1, . . . , |Θ|}. Define u∞
2 (θ) = ũ (θ). The
allocation u constructed in this way is in U, satisfies the incentive constraints (50), and delivers


vu θ(j) = v θ(j) . Thus, ~v ∈ V and hence A V ⊂ V.
2.5.1

Continuum of shocks and the first order approach

The previous section provides a general way to characterize recursively the solution to the
optimal insurance problem when shocks are Markovian. One practical difficulty in using the
Bellman equation (51) in applications is that the dimensionality of the state space grows with
the number of shocks. As the number of shocks becomes large, solving problem (51) becomes
intractable. To keep the problem manageable, it is useful to have a method that keeps the
number of state variables small.
One approach is to guess that only some of the incentive constraints (38) bind at the optimum. In this case all the non-binding constraints can be dropped, which also eliminates the
need to keep track of the state variables associated with that state. The natural candidate for
binding constraints are the local constraints, that ensure that a type θ does not want to mimic
the types closest to his. In this section we decribe how to construct this relaxed problem and
provide sufficient conditions that can be verified ex-post to make sure that the dropped incentive
constraints are satisfied.12
This analysis can be done with a discrete number of shocks, but it becomes particularly
simple if instead we allow for a continuum of shocks. In this case applying the envelope theorem
to the incentive compatibility condition gives a simple and tractable way to derive the Bellman
equation. This problem has been analyzed in detail by Kapička (2013) and Pavan et al. (2014),
and here we follow the exposition of the former.

Let the taste shocks θt in each period belong to an interval Θ = θ, θ̄ ⊂ R∗+ , with θ̄ < ∞.
We assume that the stochastic process for the shocks θt is Markov with continuous density
t+s
π (θt |θt−1 ). We use πs (· |θt ) to denote the p.d.f. of histories θt+1
given that the shock θt
12

It is important to keep in mind that there is a large class of incentive problems with persistent shocks in
which non-local incentive constraints bind (Battaglini and Lamba (2015)) and thus the relaxed problem may not
satisfy the sufficient conditions.

31

occured in period t, that is,

t+s
πs θt+1
|θt = π (θt+s |θt+s−1 ) × . . . × π (θt+1 |θt ) .
Assume as in the previous section that these probabilities are generated from the seed value
θ0 = θ(1) . We make the following assumptions:
Assumption 4. Assume that the density π (θ |· ) is uniformly Lipshitz-continuous for all θ, and
−)
that the derivatives π̂ (θ |θ− ) ≡ ∂π(θ|θ
exist and are uniformly bounded.
∂θ−
These assumptions can be substantially relaxed (see Kapička (2013), Pavan et al. (2014)
for more general treatments of the problem), but they considerably simplify our analysis. To
simplify the integrability conditions, we further asssume in this section that the utility function
is bounded.
Having a continuum of shocks does not change the arguments leading to the recursive characterization of the constraints (41), (40), with the only difference that the sum over a finite
number of shock realizations in equation (41) is now replaced by integrals. Constraints (41) and
(40) can be written as


vt θ

t−1

, θ̂t |θt



ˆ h
i




=
θ0 ut+1 θt−1 , θ̂t , θ0 + βvt+1 θt−1 , θ̂t , θ0 θ0 π θ0 |θt dθ0 , ∀θt , θ̂t , (52)
Θ

and
n



o


θt ut θt−1 , θt + βvt θt−1 , θt |θt = max θt ut θt−1 , θ̂ + βvt θt−1 , θ̂ |θt
, ∀θt−1 , θt .
θ̂∈Θ

(53)

Lemma 4. Suppose Assumption 4 is satisfied and the utility function is bounded. Then the

function vt θt−1 , θt |· is differentiable with respect to the realized period-t type θ for each history

of reports θt = θt−1 , θt and its derivative evaluated at θt is given by
ˆ
v̂t θ

t





=




θ0 ut+1 θt , θ0 + βvt+1 θt , θ0 θ0 π̂ θ0 |θt dθ0 .

(54)

Θ

Moreover, if an allocation is incentive compatible, then for all t ≥ 1, θt ∈ Θt ,
ˆ
θt ut θ

t−1



, θt + βvt θ

t−1

θt





, θt |θt =




ut θt−1 , θ + βv̂t θt−1 , θ dθ + ν θt−1 ,

θ





where ν θt−1 = limθ→θ θut θt−1 , θ + βvt θt−1 , θ |θ .

32

(55)




Proof. Let St+1 θt , θ0 = θ0 ut+1 θt , θ0 + βvt+1 θt , θ0 |θ0 . Then

 ˆ
 π (θ0 |θ + ∆θ ) − π (θ0 |θ ) 0
vt θt−1 , θt |θ + ∆θ − vt θt−1 , θt |θ
St+1 θt , θ0
=
dθ
∆θ
∆θ
ˆΘ


St+1 θt , θ0 π̂ θ0 |θ dθ0 ,
−−−−→
∆θ→0

Θ

where the last step follows from the dominated convergence theorem, noting that St+1 θt , θ0
π(θ0 |θ+∆θ )−π(θ0 |θ )
are bounded by the uniform Lipschitz continuity
∆θ
 
t−1
vt θ , θt |· is differentiable, and it is Lipschitz continuous on η, θ̄ for all

and



of π (θ0 |· ). Hence
η > θ since π̂ (θ0 |θ )

is uniformly
 bounded.




Let Ŝt θt−1 , θ̂t |θt = θt ut θt−1 , θ̂t + βvt θt−1 , θ̂t |θt . Then Ŝt is differentiable in θt

 
on η, θ̄ (denote by Ŝθ,t its derivative) and Lipschitz in θt on η, θ̄ . Hence it is absolutely

continuous and has a bounded
derivative
with respect to θt on η, θ̄ . Since the allocation is



incentive compatible, Ŝt θt−1 , θ̂t |θt is maximized at θ̂t = θt . By Theorem 2 in Milgrom and

Segal (2002), Ŝt θt−1 , θt |θt can be represented as an integral of its derivative:
ˆ
Ŝt θ

t−1

θt



, θt |θt =



Ŝθ,t θt−1 , θ, θ dθ + Ŝt θt−1 , η |η

η

ˆ

θt



=




ut θt−1 , θ + βvθ,t θt−1 , θ |θ dθ + Ŝt θt−1 , η |η .

η

Take the limit as η → θ to get expression (55).
We can now define a relaxed problem by replacing the temporary incentive compatibility
constraints (53) by the envelope condition (55) for all histories. This substantially simplifies
the analysis, as the latter constraint only depends on the lifetime utility and marginal lifetime
utility of the truthteller, rather than the continuation utility of all possible types as in Section
2.5. In the recursive formulation of the planner’s problem, the choice variables are the current
utility u (θ), the continuation utility of the truthtelling agent w (θ), and the marginal change in
the continuation utility of the truthtelling agent ŵ (θ). The state variables are the reported taste
shock realization θ− in the previous period, the promised utility v of an agent who truthfully
announced θ− last period, and the marginal promised utility v̂ of an agent who truthfully
announced θ− last period.
We now show the recursive formulation of the relaxed problem in an infinite-period economy.
Let V̂ (θ− ) denote the set of lifetime utility and marginal lifetime utility pairs (v, v̂) ∈ R2 for
which there exist values {u (θ) , w (θ) , ŵ (θ)}θ∈Θ such that the following conditions hold:
(i ) the envelope condition:
ˆ

θ



θu (θ) + βw (θ) =



u θ0 + β ŵ θ0 dθ0 + lim {θu (θ) + βw (θ)} , ∀θ ∈ Θ,
θ→θ

θ

33

(56)

(ii ) the promise-keeping constraint:
ˆ
 0



θ u θ0 + βw θ0 π θ0 |θ− dθ0 ,

v=

(57)

Θ

(iii ) the marginal promise-keeping constraint:
ˆ
 0



θ u θ0 + βw θ0 π̂ θ0 |θ− dθ0 ,

v̂ =

(58)

Θ

(iv ) (w (θ) , ŵ (θ)) ∈ V̂ (θ) for all θ ∈ Θ.
Note that in general V̂ (θ) depends on the realized value of θ. It can be characterized along the
lines of Proposition 8.
For any θ− ∈ Θ and pair (v, v̂) ∈ V̂ (θ− ), the Bellman equation writes
ˆ
K (v, v̂, θ− ) = sup
~)
~ ŵ
(~u,w,

{−C (u (θ)) + βK (w (θ) , ŵ (θ) , θ)} π (θ |θ− ) dθ

(59)

Θ

subject to (56), (57), (58), and u (θ) ∈ U, (w (θ) , ŵ (θ)) ∈ V̂ (θ) for all θ ∈ Θ.
We finally discuss when the relaxed problem gives the solution to the original problem.
The envelope condition (55) is necessary but not sufficient for an allocation to be temporarily
incentive compatible. A simple sufficient condition is given in the next proposition:
Proposition 9. Suppose that an allocation u satisfies the envelope condition (55) and, in addition,




ut θt−1 , θ̂t + βv̂t θt−1 , θ̂t |θt
(60)




∂
is increasing in θ̂t for all t, θt−1 and almost all θt , where vt θt−1 , θ̂t |θt ≡ ∂θ
vt θt−1 , θ̂t |θt .
Then u is temporary incentive compatible.


Proof. Fix t, θt−1 , and let St θt−1 , θt ≡ Ŝt θt−1
, θt |θt . An allocation is temporarily incen

tive compatible if St θt−1 , θt ≥ Ŝt θt−1 , θ̂t |θt for all θt−1 , θt , θ̂t . Equation (55) shows that

St θt−1 , · is differentiable for almost all θ ∈ Θ with



∂
St θt−1 , θ =ut θt−1 , θ + βv̂t θt−1 , θ .
∂θ
We thus have



St θt−1 , θt − St θt−1 , θ̂t
ˆ θt
ˆ θt
 0



∂
t−1 0
=
St θ , θ dθ =
ut θt−1 , θ0 + βv̂t θt−1 , θ0 θ0 dθ0
0
θ̂t ∂θ
θ̂t
ˆ θt n 




o


dθ0 = Ŝt θt−1 , θ̂t |θt − St θt−1 , θ̂t ,
≥
ut θt−1 , θ̂t + βv̂t θt−1 , θ̂t θ0
θ̂t

34

where the inequality follows
 from the
 monotonicity
 of (60),and the
 last equality

follows from

∂
t−1
t−1
t−1
the differentiability of Ŝt θ , θ̂t |θt , with ∂θ Ŝt θ , θ̂t |θ = ut θ , θ̂t + βv̂t θt−1 , θ̂t |θ .
We obtain that u is temporarily incentive compatible.
If the shocks are i.i.d., the second term in expression (60) drops out and the proposition

is equivalent to a simple requirement that ut θt is increasing in θt , and one can show that
this requirement is necessary as well. In the static setting, u satisfies the Spence-Mirrlees
condition and this sufficient condition reduces to the familiar necessary and sufficient condition
that allocations are monotonic, see Myerson (1981). Unfortunately, in the dynamic model with
persistent shocks, the monotonicity condition on (60) is not necessary, and moreover there is no
one-to-one mapping between marginal lifetime utilities and allocations. Moreover, in practice
condition (60) is difficult to verify directly, and we have to check ex post (possibly numerically)
in specific applications (see, e.g., Section 4.1) whether the solution to the relaxed problem is
indeed an optimal allocation.

2.6

Other Models

The techniques that we introduced in the previous sections in the context of the taste shock
model can be easily applied to many more environments. First, Green (1987) and Thomas
and Worrall (1990) study a model closely related to the one we analyzed above, in which the
agent receives privately observed i.i.d. or persistent endowment (or income) shocks θt ∈ Θ:
in each period t ≥ 1, the agent observes his income shock θt and reports its realization to

the planner, who then provides a transfer τt θt to the agent. Second, Spear and Srivastava
(1987)and Phelan and Townsend (1991) study a moral hazard model in which agents exert a
privately observed effort level θt ∈ Θ in each period. The output produced from that effort
is stochastic and observable to the planner. The case where current effort affects only current
output corresponds to the i.i.d. assumption 3 in the taste shock model, while the case where
current effort also affects future output corresponds to the taste shock model with persistent
types. Third, Thomas and Worrall (1988), Kocherlakota (1996), Ligon et al. (2002) show that
models of limited commitment, in which there is no asymmetry of information but one or both
parties are free to walk away to the insurance contract, can be analyzed using similar recursive
techniques using promised utility as state variable; we discuss applications of these models in
Section 4.
Here we describe briefly how to apply our recursive techniques to a model of moral hazard.
Agents exert an effort level θt ∈ Θ = [0, ∞) in each period. The planner does not observe the

agent’s effort, but only the (random) output produced from that effort, yt ∈ Y = y(1) , y(2) ,
with 0 = y(1) < y(2) . The flow utility at time t is U (ct ) − h (θt ), where the utility from
consumption U (·) : R+ → R is twice differentiable, strictly increasing and strictly concave,
and the disutility of effort h (·) : R+ → R is twice differentiable, strictly increasing and strictly
convex with h (0) = 0 and h0 (0) ≥ 0.

35

We assume that the probability of output yt ∈ Y in period t depends only on the effort θt ∈ Θ

exerted by the agent in the current period.13 We denote it by π (yt |θt ), with 0 = π y(2) |0 <



π y(2) |θ < 1 for all θ ∈ (0, ∞), and π y(2) |· is twice differentiable with πθ y(2) |· > 0. An


allocation in this model is a pair of sequences of functions θ = θt y t−1 t≥1 (with y 0 = ∅)
describing the effort recommended by the planner to the agent given the observed history at


the beginning of each period t, and a sequence of utility payments u = ut y t t≥1 given
the observed history of output at the end of each period t. The planner chooses the incentive
compatible allocation {c, θ} that minimizes the cost of delivering lifetime utility v0 , that is,
letting C ≡ U −1 ,
K (v0 ) ≡

maxθ,u

θ

E

"∞
X

#
β

t−1

β


t−1



yt − C ut y

t



(61)

t=1

subject to

Eθ
Eθ̂

"∞
X
t=1
"∞
X

#
ut y


t

− h θt y


t−1

= v0 ,

#
o
n



≤ v0 , ∀θ̂,
β t−1 ut y t − h θ̂t y t−1

t=1

where the superscripts over expectations Eθ and Eθ̂ indicate that the probability distribu
tions over the paths of output y t t≥1 inside the brackets depend on the agent’s correspond
ing strategies θ and θ̂ (respectively), that is, for any t and random variable Xt y t we let


P
Eθ [Xt ] ≡ yt ∈Y t πt y t θt Xt y t . Thus, each expectation in the incentive constraint depends
on the agent’s effort directly through the cost of effort h (θt ), and indirectly through its effect

on the probability distribution πt y t |θ over the paths of y t .
Defining the continuation utility of an obedient agent up to and after date t as in (11), we
can rewrite this problem recursively:
K (v) =

X

max

~
θ≥0,~
u≥u,w≥v

s.t. v =

X

π (y |θ ) [y − C (u (y)) + βK (w (y))]

y∈Y

π (y |θ ) [u (y) − h (θ) + βw (y)] ,

(62)

y∈Y

πθ y(2) |θ







u y(2) − u y(1) + β w y(2) − w y(1)
− h0 (θ) ≤ 0
with equality if θ > 0,

where the incentive compatibility constraint is replaced by a first-order condition, assuming for
13

The analysis of the case where current effort also affects future output is slightly more involved than that
of Section 2.5. This is because there is a form of non-separability of the agent’s lifetime utility (incentives in a
given period depend no longer only on his current true type and past reports, but also on his past true types)
which implies that truthful revelation does not necessarily hold off the equilibrium path (i.e., after the agent has
deviated from the recommended action in the past); see Example of Section S.5. in Pavan et al. (2014). Thus,
after a deviation an agent may prefer to engage in a strategy of infinite deviations. Fernandes and Phelan (2000)
nevertheless show how to write a recursive formulation of this problem.

36

simplicity that the first order approach is valid.
Following the steps leading to Proposition 5 gives the following characterization of the solution to the planner’s problem. For any interior v, the optimal contract (θv , ~uv , w
~ v ) satisfies
the following martingale property (with respect to the probability measure associated with the
optimum effort strategy Pθ ):




K 0 (v) = Eθv −C 0 (uv ) = Eθv K 0 (wv ) .

(63)

This can be re-written as:
1
u0 (ct (y t ))

=

X

π yt+1 θt+1 y t

yt+1 ∈Y



1
,
u0 (ct+1 (y t , yt+1 ))

(64)

and is known in the literature as the Inverse Euler Equation (see Diamond and Mirrlees (1978),
Rogerson (1985), Spear and Srivastava (1987), Golosov et al. (2003)). We derive implications of
this equation in Section 4.1 and show by comparing it to the individual’s Euler equation that
agents’ savings are constrained in the optimal insurance arrangement.
We can analyze this problem (62) along the lines of the proof of Proposition 5. A utilityeffort pair (v, θv ) is absorbing if and only if θv = 0 and (uv (y) , wv (y)) = ((1 − β) v, v). The
recommended effort θv is strictly positive as long as the promised utility is small enough, v < v̄.
If h0 (0) = 0, we find v̄ = ∞, and the Martingale Convergence Theorem implies that immisera
tion occurs: vt θt → v as t → ∞ with probability 1. If instead h0 (0) > 0, the principal may

eventually “retire” the agent (i.e., recommend effort θt y t = 0 and provide constant consump

tion ct y t = c) when vt θt ≥ v̄, as for a large enough promised utility the benefit of inducing
him to work outweighs the cost of providing the necessary incentives and compensating him for
the higher effort.

3

Advanced Topics

In this Section we discuss three additional topics that significantly expand the applicability of
the recursive contracts. In Section 3.1 we overview the theory of Lagrange multipliers and show
how it can help solve many dynamic incentive problems recursively even if they do not fit into
the canonical setup described in Section 2. Section 3.2 shows how to extend the analysis to
settings in which the ability of the principal to commit is imperfect. Finally, in Section 3.3,
we describe the analysis of dynamic contracting problems in continuous time using martingale
methods. Throughout this section we do not aim at the same level of rigor as in Section 2; we
omit several technical details and refer to the relevant papers for the complete proofs.

37

3.1

Lagrange multipliers

The key feature that allowed us to analyze the dynamic contracting problem (17) is that we
could write the incentive constraints in a simple recursive form. In many applications, however,
the optimal contracting problem often has additional constraints that cannot easily be written
recursively. For example, if we replaced the present value budget constraint (2) with a requirement that the total consumption of all agents should be equal to the total endowment in each
period, the previous method could not be applied directly. In this section we desribe a simple
approach that allows us to extend our analysis to such problems. The main idea behind this
approach is to assign Lagrange multipliers to all the constraints that do not have a straightforward recursive representation, and to apply the techniques developed in the previous sections
to the resulting Lagrangian.
We start in Section 3.1.1 by giving a general theoretical background about the properties of
Lagrange multipliers in infinite dimensional spaces. Infinite dimensional spaces are common in
macroeconomic applications but the Lagrangian techniques are more subtle in such spaces than
in finite dimensions. The main results of this section are, first, Theorems 3 and 4, which provide
conditions under which the Lagrangian exists and characterize the solution to the constrained
optimization problem, and second, Theorem 5, which provides sufficient conditions that ensure
that the Lagrangian can be written as an infinite sum, allowing us to apply the standard techniques familiar from finite-dimensional optimization theory. Sections 3.1.2 through 3.1.4 give
several examples of applications of these techniques. The reader only interested in practical
applications can skip Section 3.1.1 in the first reading.
3.1.1

Main theoretical results

The classical reference about using Lagrange multipliers to solve optimization problems is Luenberger (1969). Here we state two main results from this book, adapting them to our setting.
To use this approach, we need to set our problem in abstract linear spaces.14 Before starting
our analysis we introduce the notions of convex cones and mappings, dual spaces, and lp spaces.
First, let P be a convex cone in a vector space V, that is, P satisfies αx + βy ∈ P for all
x, y ∈ P and α, β > 0. This convex cone defines a partial order ≤ on V, such that x ≥ y if
x − y ∈ P . By definition, P is the positive cone with respect to this partial order, i.e., the
subset V + = {x ∈ V : x ≥ 0}. We write x > 0 if x is an interior point of the positive cone
P . By introducing a cone defining the positive vectors in the vector space V, we thus define
an ordering relation ≤ and make it possible to consider inequality problems in the abstract
vector space V. (Often the positive cones of the vector spaces we consider are constructed
naturally, e.g., the positive orthant of Rn , or the non-negative continuous functions of C ([a, b]).)
A mapping G : V1 → V2 from the vector space V1 to a vector space V2 having a cone P
defined as the positive cone is said to be convex if the domain Ω of G is a convex set and if
14

For a review of basic functional analysis, see Luenberger (1969), or Chapters 3 and 15 in Stokey et al. (1989).

38

G (αx1 + (1 − α) x2 ) ≤ αG (x1 ) + (1 − α) G (x2 ) for all x1 , x2 ∈ Ω and all α ∈ (0, 1).
Second, the dual V ∗ of a normed vector space V is the space of all bounded linear functionals
on V, i.e., f : V → R. The norm of an element f ∈ V ∗ is kf k = supkxk≤1 |f (x)|. The value of the
linear functional x∗ ∈ V ∗ at the point x ∈ V, that is x∗ (x), is denoted by hx, x∗ i. For 1 ≤ p < ∞,
P
p
the space lp consists of all sequences of scalars {u1 , u2 , . . .} for which ∞
n=1 |un | < ∞, and the
space l∞ consists of the bounded sequences. The norm of an element u = {un }n≥1 ∈ lp is
P
p 1/p
for p < ∞, and as kukp = supn |un | for p = ∞. Then for every
defined as kukp = ( ∞
i=1 |un | )
−1
p ∈ [1, ∞), the dual space of lp is lq , where q = 1 − p−1
. This is because every bounded
P
linear functional f on lp , 1 ≤ p < ∞ can be represented uniquely in the form f (u) = ∞
n=1 vn un ,
where v = {vn }n∈N∗ is an element of lq ; specifically, for all n ≥ 1, vn ≡ f (en ), where en ∈ lp
is the sequence that is identically zero except for a 1 in the nth component. The dual of l∞
strictly contains l1 . Finally, given a normed space V together with a positive convex cone
P ⊂ V, it is natural to define a corresponding positive convex cone P ∗ in the dual space V ∗ by
P ∗ = {x∗ ∈ V ∗ : ∀x ∈ P, hx, x∗ i ≥ 0}.
We can now introduce the theory of Lagrange multipliers. Consider a problem
min ϕ (x)
x

(65)

subject to Φ (x) ≤ 0, x ∈ Γ,
where Γ is a convex subset of a vector space X, ϕ : Γ → R is a convex functional, Φ : Γ → Z is a
convex mapping to a normed vector space Z that has positive cone P . Let Z ∗ be the dual space
∗ be its positive orthant (i.e., all z∗ ∈ Z ∗ such that z∗ ≥ 0). We assume throughout
of Z and Z+
this section that the minimum of problem (65) is attained. This assumption is not necessary but
it simplifies the statement of the theorems, and we will see in our context (Proposition 10) that
it can often be verified directly. Theorems 1 p. 217 and Corollary 1 p. 219 in Luenberger (1969)
give the main results for solving the minimization problem (65) using Lagrange multipliers.
Theorem 3. Assume that the minimum in (65) is achieved at x̂. Suppose that P contains an
∗ such
interior point, and that there exists x0 ∈ Γ such that Φ (x0 ) < 0. Then there is ẑ∗ ∈ Z+
that the Lagrangian
L (x, z∗ ) = ϕ (x) + hΦ (x) , ẑ∗ i
has a saddle point at (x̂, ẑ∗ ), i.e.,
∗
L (x̂, z∗ ) ≤ L (x̂, ẑ∗ ) ≤ L (x, ẑ∗ ) , ∀x ∈ Γ, ẑ∗ ∈ Z+
.

(66)

Moreover,
hΦ (x̂) , ẑ∗ i = 0.
Theorem 3 establishes that for convex problems there generally exists a Lagrangian such
that the solution to the original constrained minimization problem is also a solution to the

39

minimization of the unconstrained Lagrangian. The next result (Theorem 2 p. 221 in Luenberger
(1969)) ensures the sufficiency:
Theorem 4. Let X, Z, Γ, P, ϕ, Φ be as above and assume that the positive cone P ⊂ Z is closed.
∗ and an x̂ ∈ Γ such that the Lagrangian L (x, z∗ ) has a saddle
Suppose that there exist ẑ∗ ∈ Z+
point at x̂, ẑ∗ . Then x̂ is a solution to (65).
Thus, if ϕ and Φ are convex, the positive cone P ⊂ Z is closed and has non-empty interior,
and the regularity condition Φ (x0 ) < 0 is satisfied, then the saddle point condition is necessary
and sufficient for optimality of x̂.
One way to find a saddle point of L is to use the following result (see Bertsekas et al. (2003)).
Corollary 1. (x̂, ẑ∗ ) is a saddle point of L if and only if the equality
inf sup L (x, z∗ ) = sup inf L (x, ẑ∗ )

(67)

∗ x∈Γ
z∗ ∈Z+

x∈Γ z∗ ∈Z ∗

+

is satisfied, and
x̂ = arg min sup L (x, z∗ ) ,
x∈Γ z∗ ∈Z ∗
+

(68)

ẑ∗ = arg max
inf L (x, z∗ ) .
∗
∗
z ∈Z+ x∈Γ

In particular, suppose that the conditions of Theorem 3 hold, so that L (x, z∗ ) has a saddle point
∗ and is unique for
at (x̂, ẑ∗ ). Suppose moreover that arg minx∈Γ L (x, z∗ ) exists for each z∗ ∈ Z+
z∗ = ẑ∗ . Then (x̂, ẑ∗ ) is the solution to maxz∗ ∈Z+∗ minx∈Γ L (x, z∗ ).
Proof. Suppose (x̂, ẑ∗ ) is a saddle point. Then
inf sup L (x, z∗ ) ≤ sup L (x̂, z∗ ) = L (x̂, ẑ∗ ) = inf L (x, ẑ∗ ) ≤ sup inf L (x, z∗ ) .

x∈Γ z∗ ∈Z ∗

+

x∈Γ

∗
z∗ ∈Z+

∗ x∈Γ
z∗ ∈Z+

By the max-min inequality, inf x∈Γ supz∗ ∈Z+∗ L (x, z∗ ) ≥ supz∗ ∈Z+∗ inf x∈Γ L (x, ẑ∗ ), establishing
that all these inequalities hold with equality, and hence (67) and (68) is satisfied.
Conversely, suppose that (67) and (68) hold. Then
sup inf L (x, z∗ ) = inf L (x, ẑ∗ ) ≤ L (x̂, ẑ∗ ) ≤ sup L (x̂, z∗ ) = inf sup L (x, z∗ ) .
∗
z∗ ∈Z+

x∈Γ

x∈Γ

∗
z∗ ∈Z+

x∈Γ z∗ ∈Z ∗

+

Using (67) implies that (x̂, ẑ∗ ) is a saddle point.
Finally suppose that the conditions of Theorem 3 are satisfied, so that L (x, z∗ ) has a saddle
∗ and is unique
point at (x̂, ẑ∗ ), and that x (z∗ ) ≡ arg minx∈Γ L (x, z∗ ) exists for each z∗ ∈ Z+
for z∗ = ẑ∗ . Then, by (68) we have ẑ∗ = arg maxz∗ ∈Z+∗ L (x (z∗ ) , z∗ ). By the uniqueness
assumption we have L (x (ẑ∗ ) , ẑ∗ ) < L (x, ẑ∗ ) for all x 6= x (ẑ∗ ), so that the saddle point (66)
can only be achieved at (x (ẑ∗ ) , ẑ∗ ), establishing that x̂ = x (ẑ∗ ). We obtain that the solution
to maxz∗ ∈Z+∗ minx∈Γ L (x, z∗ ) is (x̂, ẑ∗ ).
40

The max min problem in Corollary 1 provides a simple way to find the solution to the
minimization problem together with the corresponding Lagrangian. The uniqueness qualifier is
important for that result; without it there may exist solutions to the max min problem that are
not saddle points, i.e., that are not a solution to the original optimization problem (see, e.g.,
Messner and Pavoni (2004)).
In economic applications, Φ often represents per-period constraints and it can be written as
Φ = {Φ1 , Φ2 , ...}. The most natural vector space to choose in such situations is the space of
bounded sequences, l∞ . In this case we define the positive cone P of l∞ as the positive orthant,
i.e., the subset of non-negative sequences of l∞ . Excercise 15.7 in Stokey et al. (1989) shows
that l∞ is the only lp -space that has a positive orthant with a non-empty interior, which is a
requirement needed to apply the theorems above.
A limitation of the space l∞ is that its dual is complicated. It contains the space of summable
sequences l1 , but it also includes other sequences which are not summable. This makes the
analysis difficult because the linear operator hΦ (x) , zi may take a complicated form. The
analysis simplifies if it can be ensured that the mappings ϕ and Φ are not affected by how x
behaves “at infinity”, in which case we provide an l1 representation of the Lagrange multipliers
and each constraint Φn (x) will have a scalar multiplier λn associated with it. For any x, y ∈ l∞ ,
define an operator xT (x, y) as xT (x, y) = xt if t ≤ T and xT (x, y) = yt if t > T. We use the
notation xTt (x, y) to denote the t-th element of this operator.
Assumption 5. Let X, Z = l∞ , Ψ = {x ∈ Γ : ϕ (x) < ∞}. Suppose that:

(i) If (x, y) ∈ Ψ × l∞ satisfy xT (x, y) ∈ Ψ for all T large enough, then ϕ xT (x, y) → ϕ (x)
as T → ∞.
(ii) If x, y ∈ Γ and xT (x, y) ∈ Γ for all T large enough, then:

lim Φt xT (x, y) = Φt (x) ,

(a)

∀t,

(b)


∃M s.t. ∀T large enough, Φ xT (x, y) ≤ M,



∀T large enough, lim Φt xT (x, y) − Φt (y) = 0.

(c)

T →∞

t→∞

Le Van and Saglam (2004) prove that under these assumptions the Lagrangian can be written
as an infinite sum:15
Theorem 5. Let x̂ be a solution to (65). Suppose that for all x ∈ Γ, we have Φ (x) ∈ l∞ .
Assume that there exists x0 ∈ Γ such that Φ (x0 ) < 0, that is, supt Φt (x0 ) < 0 (Slater condition).
Assume finally that Assumption 5 is satisfied and that xT (x̂, x0 ) ∈ Γ ∩ Ψ for all T large enough.
Then there exists ẑ∗ ∈ l1 with ẑ∗ ≥ 0 such that
∞
X

ẑt∗ Φt (x̂) = 0,

t=1
15

See also Rustichini (1998) who provides an alternative set of sufficient conditions ensuring the summability
of the Lagrange multipliers.

41

and
ϕ (x) +

∞
X

ẑt∗ Φt (x)

≥ ϕ (x̂) +

∞
X

t=1

ẑt∗ Φt (x̂) , ∀x ∈ Γ.

t=1

In the next sections, we apply this theory to dynamic contracting problems.
3.1.2

Application: recursive contracts in general equilibrium

Consider a simple modification of the setup in Section 2.3, in which the planner can no longer
freely borrow and lend at an exogenous interest rate. Instead we require that the economy-wide
feasibility constraint hold period by period, i.e.,
X



πt θt C ut θt ≤ e, ∀t ≥ 1.

(69)

θt ∈Θt

This problem is analyzed by Atkeson and Lucas (1992). For simplicity we assume |Θ| = 2 and
i.i.d. shocks to parallel our discussion in Sections 2.3 and 2.4. Thus we study the problem
"∞
X

#
t−1

t



(70)



E0 C ut θt
≤ e, ∀t ≥ 1,

(71)

max E0
u

β

θt ut θ

t=1

subject to

and

"
E0

∞
X

#
β

t−1



θt ut θ

t



t

− ut σ θ

t



≥ 0, ∀σ.

(72)

t=1

Assume for now that the maximum in the problem (70) is attained for all e > 0; we will show
this formally below.



Let Γ be the set of sequences u = ut θt t≥1,θt ∈Θt , indexed by t, θt , such that u satisfies
the period-0 incentive constraint (72) and the sequence {E0 [C (ut )] − e}∞
t=1 is bounded in sup
t
norm. The set Γ is convex and has an interior point, e.g., ut θ = ε for all t, θt and ε > 0
sufficiently small.
We start with the sufficient conditions first. Let X be the space of all infinite sequences,
Z = l∞ and Φ = {Φ1 , Φ2 , ..} where Φt : Γ → R is defined by Φt (u) = E0 [C (ut )] − e. Suppose
16
that we can find a non-negative sequence λ = {λt }∞
t=1 such that the problem
"
max E0
u∈Γ

∞
X

#
β

t−1

θt ut −

t=1

∞
X

λt {E0 [C (ut )] − e}

(73)

t=1

has a maximum û and E0 [C (ût )] = e for all t. To verify that (û, λ) is a saddle point, observe
16

To be consistent with discussion in Section 3.1.1, we use the fact that minimizing ϕ is equivalent to maximizing

−ϕ.

42

∗ , we have hΦ (û) , z∗ i ≤ 0 = hΦ (û) , λi. Moreover, the regularity condition
that for any z∗ ∈ Z+

Φ (u0 ) < 0 holds for some u0 ∈ Γ, i.e. u0 satisfies incentive compatibility (take u0t θt = ε).
Therefore û is a solution to the original problem (70) by Theorem 4. Note that we impose no
boundedness assumption on the utility function.
To illustrate an application of this result, consider an example with logarithmic preferences.
We argue that the Lagrange multiplier λ has the form λt = λ1 β t for some λ1 . Following the
same steps as in Section 2.3, replace the period-0 incentive constraints with a sequence of oneshot constraints. Moreover, we consider an auxiliary planner’s problem that has a recursive
structure, by augmenting the set of constraints with the promise-keeping condition

"
E0

∞
X

#
β

t−1

θt ut θ

t



= v0 .

(74)

t=1

The constraint set is then the set Γ (v0 ) defined in (16). We can re-write the problem (73)-(74)
as
∞
X
max v0 −
λt {E0 [C (ut )] − e} .
(u,v)∈Γ(v0 )

t=1

The solution to this problem coincides, given our guess λt = λ1 β t , with the solution to the
problem
∞
X
max −
β t−1 E0 [C (ut )] ,
(u,v)∈Γ(v0 )

t=1

which is, of course, the same problem as the one we analyzed in Section 2.3. Therefore, if we can
show that the solution to that problem satisfies the feasibility constraint (69) for each period t,
we found the solution to our new problem. We recover the solution to the original problem by
maximizing the auxiliary problem over v0 .
We now check that this is the case. Let (u, v) be the allocation generated by the policy
functions to the Bellman equation (23) for some v0 . The optimality conditions (29) imply




 



K 0 (v0 ) = E0 −C 0 (u1 ) = E0 K 0 (v1 ) = E0 E1 −C 0 (u2 ) = E0 −C 0 (u2 ) .
When preferences are logarithmic, C = C 0 = exp, thus forward induction implies E0 [C (u1 )] =
1
e, this implies that E0 [C (ut )] = e for all
E0 [C (ut )] for all t. Since v0 must satisfy K (v0 ) = 1−β
t, establishing our result (and justifying our guess for λt ).
When we set up the maximization problem (73) we assumed the existence of a summable
sequence λ such that the feasibility constraints are satisfied with equality in all periods at the
optimum. We subsequently showed how to explicitly construct such a sequence of multipliers in
an example with logarithmic preferences. We now conclude this section by discussing sufficient
conditions ensuring the existence of a summable sequence of Lagrange multipliers. Note that

43

without any further assumptions, the maximization problem
"
max
u∈Γ,Φ(u)≤0

E0

∞
X

#
β t−1 θt ut

t=1

satisfies all the conditions of Theorem 3, so that a Lagrangian exists. To show that it is a
summable sequence we verify conditions of Theorem 5. It is the easiest to do in the case of
bounded utility.17 In this case any sequence u lies in l∞ . Assumption 5.i holds following the
same arguments as those used in the proof of Proposition 10 (see below). Since the constraint


(69) holds for each t, we immediately have E0 [C (ut )] = E0 C xTt (u, v) for T sufficiently


large holding t fixed, and E0 C xTt (u, v) = E0 [C (vt )] for t sufficiently large holding T fixed,
which verifies Assumptions 5.ii.a and 5.ii.c. Assumption 5.ii.b holds by definition of Γ. Therefore
Thereom 5 establishes that the Lagrange multipliers form a summable sequence.
Existence of a maximum
We finally show the existence of the maximum in problem (70). Note that we already showed
the existence in Section 2.3.2 using the (finite-dimensional) Bellman formulation of the problem.
Here we do so directly, using techniques that can be applied to other contexts where the previous
approach is not readily available. It is not obvious a priori that the maximum in this problem
exists. In finite dimensional spaces, the continuity of the objective function and the compactness
of the constraint sets are easily obtained, implying directly the existence of a maximum. These
properties are more difficult to obtain in infinite period economies. The next proposition guarantees that the infinite-horizon planner’s problem is a well-defined maximization problem, i.e.,
there exist feasible (u∗ , v∗ ) for which the supremum is achieved. The reader interested mostly
in the applications can skip this section.
Proposition 10. The maximum in the problem (70) is attained for all e > 0.
Proof. One of the easiest ways to show the existence of the minimum in the planner’s problem
is to truncate the economy at any finite period T , show the existence of the solution for this
truncated economy, and finally show that the limit of this solution achieves the supremum of the
original problem as T → ∞. To show these we adapt the arguments of Ekeland and Scheinkman
(1986).
We first restrict allocations in each period to compact sets as follows. Fix e > 0. For any

¯t ∈ (u, ū) such that πt θt C (ū
¯t ) ≥ e for all θt , that is,
t ≥ 1, define ū
¯t = C −1
ū



e
minθ∈Θ (π (θ))t


.


¯t for any history θt ∈ Θt , then E0 [C (ut )] > e, and the allocation is not feasible.
If ut θt > ū
17

See Rustichini (1998) for existence arguments when utility is not bounded.

44


¯t , and similarly, letting
This gives us an upper bound ut θt ≤ ū
"
v̄¯t = Et

∞
X

#
β

s−1 ¯

ūt+s < v̄,

s=1


P∞ t−1

we have vt θt ≤ v̄¯t . Moreover, E0
θt ut θt goes to −∞ if us (θs ) → −∞ for some
t=1 β
¯t for all t ≥ 0. But this allocation is dominated by
(s, θs ), because of the upper bounds ū



ũt (θt ) = C −1 (e) for all t, θt . Thus for each t we must have ut θt ≥ ut θt , which then



gives us lower bounds ut θt ≥ ut ≡ minΘt ut θt and, similarly, vt θt ≥ v t . Therefore we can
impose the additional constraints

¯t ,
ut ≤ ut θt ≤ ū

v t ≤ vt θt ≤ v̄¯t .
Next, we truncate the economy to T < ∞ periods and allow the planner to provide incentives
in the last period “for free”. That is, we define
V T (e) =

E
sup
h
i 0
¯t
ut ( )∈ u ,ū
h t i
vt (θt )∈ v ,v̄¯t
t
θt

" T
X

#
β t−1 θt ut θ


t

t=1

subject to the promise keeping constraints
 X



vt θ t =
π (θ) θut+1 θt , θ + βvt+1 θt , θ , ∀t ≤ T − 1,
θ∈Θ

the incentive compatibility constraints






θut θt−1 , θ + βvt θt ≥ θut θt−1 , θ̂ + βvt θt−1 , θ̂ , ∀t ≤ T,
and the feasibility constraints
E0 [C (ut )] ≤ e, ∀t ≤ T.
Note that the last incentive constraint is:






θuT θT −1 , θ + βvT θT ≥ θuT θT −1 , θ̂ + βvT θT −1 , θ̂ for all θT −1 , θ̂,
and the last two promise-keeping constraints are:

 X



vT −1 θT −1 =
π (θ) θuT θT −1 , θ + βvT θT −1 , θ
and v T ≤ vT θT ≤ v̄¯T ,
θ∈Θ

that is, the promise in period T has no resource cost. In theh truncated
we maximize
i h problem
i
Q
¯t × v , v̄¯t , so a maximum
a continuous function over a compact set, namely 1≤t≤T ut , ū
t
θt ∈Θt

45

exists (which is, in fact, unique, since the objective is strictly convex). Call this maximum
 


uT , vT = uTt θt ; vtT θt t,θt .

We now show that limT →∞ uT , vT achieves the maximum of the original problem. By
definition of a supremum, for any ε > 0 we can find an incentive compatible and feasible
allocation (ũ, ṽ) for the original problem such that
"
E0

∞
X

#
β

t−1

θt ũt θ

t



> V (e) − ε.

t=1

(Note that the r.h.s. is finite.) The truncation at T periods satisfies all the constraints of the
truncated economy, so
"
T

V (e) ≥ E0

T
X

#
β

t−1

θt ũt θ

t



, ∀T ≥ 1.

t=1

Hence

"
T

lim inf V (e) ≥ E0
T →∞

∞
X

#
β

t−1

θt ũt θ

t



.

t=1

Since ε is arbitrary,
lim inf V T (e) ≥ V (e) .
T →∞

i h
i

 h
¯t × v , v̄¯t .
To show the reverse inequality, fix t ≥ 1. For all T ≥ t, uTt θt , vtT θt ∈ ut , ū
t




Thus, the sequences uTt θt T ≥t and vtT θt T ≥t must have convergent subsequences as
T → ∞. We can then use a diagonal procedure to obtain an incentive compatible and feasible



, as follows. Arrange states as
allocation u∞
θt , vt∞ θt
t
t≥1,θt ∈Θt



R = θ(1) , ..., θ(|Θ|) , θ(1) , θ(1) , . . . , θ(1) , θ(|Θ|) , . . . .
Choose a subsequence of uT , v T so that the first element converges, i.e.,


 ∞

lim uT1 θ(1) , v1T θ(1) = u∞
.
1 θ(1) , v1 θ(1)

T →∞

From that subsequence choose another subsequence so that the second element converges, i.e.,


 ∞

lim uT1 θ(2) , v1T θ(2) = u∞
.
1 θ(2) , v1 θ(2)

T →∞

Repeat the procedure so that we get (u∞ , v ∞ ), and call the final subsequence {Tn }n≥0 . Since


for each t ≤ T, θt ∈ Θt , uTt θt , vtT θt lie in a closed set defined by the incentive constraints,



u∞
θt , vt∞ θt also lie in the same set, i.e. they are incentive compatible. Since C(ut θt )
t

46

h
i



¯t , C T θt ≡ C(uTt θt ) (and C T θt = 0 for t ≥ T ) converges pointwise,
is continuous on ut , ū
i

 h  
¯t ) .
lim C Tn θt = C ∞ θt ∈ C ut , C (ū

Tn →∞





Now we can think of π1 θ(1) , ..., π1 θ(|Θ|) , βπ2 θ(1) , θ(1) , .. as a measure on R. For all t ≥
n
o
is a sequence of positive measurable functions on that space that converges
1, θt uTt n θt
n≥1

∞
pointwise to θt ut θt as n → ∞. By Fatou’s lemma (Lemma 7.9 in Stokey et al. (1989))

θt u∞
θt is also measurable, and
t
lim sup
n→∞

Tn X
X

∞ X
 X

β t−1 πt (θt ) θt uTt n θt ≤
β t−1 πt (θt ) θt u∞
θt ≤ V (e) ,
t

t=1 θt ∈Θt

t=1 θt ∈Θt



where the last inequality follows from the fact that u∞
θt satisfies the constraints of problem
t
(9), but may not maximize the objective. Therefore, we obtain
lim sup V Tn (e) ≤ V (e) .
n→∞

We therefore showed that limn→∞ V Tn (e) exists and
V (e) = lim V Tn (e) .
n→∞


Moreover, we showed that a maximum of V (e) is achieved by the limit of the sequence uTn , vTn .
This concludes the proof.
3.1.3

Application: Sustainability constraints

Suppose in addition to constraint (69) we further impose a constraint that social welfare in any
period cannot drop below a threshold U ,

E0

"∞
X

#
β

s−1

θt+s ut+s ≥ U , ∀t ≥ 1.

(75)

s=1

Such constraints naturally arise in various settings with imperfect commitment, participation
constraints, etc. We discuss an example of those in Section 4.4 in the context of an international
finance model, where they capture the need to provide incentives for the agents to stick to the
contract rather than defaulting and reverting to their outside option (in that case, the value of
autarky).18 We add this constraint (75) to problem (70) and assume that the utility function is
bounded.
18

Such constraints would also appear in models of political economy in which a government is tempted to
re-optimize, see e.g. Acemoglu et al. (2008), Sleet and Yeltekin (2008) and Farhi et al. (2012).

47

As before, we have for all t,
"
lim E0

T →∞

∞
X

"

#
β s−1 θt+s xTt (u, v) = E0

∞
X

#
β s−1 θt+s ut+s ,

s=1

s=1

since the utility is bounded; and for t sufficiently large holding T fixed, we have
"
E0

∞
X

"

#
β s−1 θt+s xTt (u, v) = E0

s=1

∞
X

#
β s−1 θt+s vt+s ,

s=1

which verifies Assumptions 5.ii.a and 5.ii.c for the constraints (75). The other parts of Assumption 5 are verified as before. As long as U is not too high, we can find an interior point x0
that satisfies Φ (x0 ) < 0. Theorem 5 thus establishes that there exists a non-negative summable
sequence of Lagrange multipliers {µt }∞
t=1 , such that the solution to our problem is also a solution
to
"∞
#
"∞
#
∞
∞
X
X
X
X
max E0
β t−1 θt ut +
µt E0
β s−1 θt+s ut+s −
λ̃t E0 [C (ut )] .
u∈Γ

t=1

t=1

s=1

t=1

Since {µt }∞
t=1 is summable, we can rewrite the equation above as
"
E0

∞
X

β t−1 θt ut +

t=1

∞ X
∞
X

β s−1 µt θt+s ut+s −

t=1 s=1

∞
X

#
λ̃t C (ut ) = E0

t=1

"

∞
X

#
β̄t {θt ut − λt C (ut )} ,

t=1

(76)
where β̄t =
1
t−2 β + µt−1 , letting µ0 = 0, with
t=1 β̄t < ∞ and λt = λ̃t /β̄t .
This problem can be solved using our usual techniques. Augmenting the problem with a promisekeeping constraint, we can replace u ∈ Γ with (u, v) ∈ Γ (v0 ) and observe that the maximum
can be written recursively, letting β̂t+1 = β̄t+1 /β̄t , as
β t−1 + µ

P∞

β t−2 + ... + µ

kt (v) =

max

{u(θ),w(θ)}θ∈Θ

h
i
E θu − λt C (u) + β̂t+1 kt+1 (w)

subject to (19), (20).
We can extend Lemma 1 directly to kt , with the only exception that kt is not strictly decreasing
but rather inversely U -shaped. (We can easily show that v 7→ kt (v) is concave, continuous, and
satisfies kt (v) −−−→ −∞ and kt (v) −−−→ v.) Much of the analysis in Section 2.4 continues to
v→v̄

v→v

hold but the condition (29) now becomes
kt0 (v) =


β̂t+1  0
E kt+1 (wv ) .
β

(77)

Observe that β̂t+1 ≥ β with strict inequality if µt > 0. Therefore the marginal cost kt0 is
no longer a martingale if constraint (75) binds, which implies a form of mean-reversion. To
see this, observe that since k is inversely U-shaped, kt0 is positive for low v and negative for

48

high v. Therefore equation (77) shows that the marginal cost decreases in expectation if v is
 0

low (because then E kt+1
(wv ) = β kt0 (v) ≤ kt0 (v)) and increases if v is high (because then
β̂t+1
 0

E kt+1
(wv ) = β kt0 (v) ≥ kt0 (v)).
β̂t+1

3.1.4

Using Lagrange multipliers instead of promised utilities

In our discussion so far we have used the following technique to solve dynamic incentive problems:
we formed a Lagrangian using all the constraints except the incentive constraints, and then
introduced the promised utilities in order to write the incentive constraints recursively. In
principle, there is nothing special about the incentive constraints per se: we could extend the
Lagrangian to those constraints also, eliminating the need to use promised utilities at all. Here
we describe how this can be done, using a version of our benchmark partial equilibium model
of Section 2.3.2 as an example.
Consider the maximization problem
"
K (v0 ) ≡ max E −
u

∞
X

#
β t−1 C (ut )

(78)

t=1

subject to (10) ∀t ≥ 1, and (14),
that we analyzed in Section 2.3.2. Since the objective function is strictly concave and the
constraint set is convex, its solution û is unique. Define W : R → R as
"
W (α) ≡ max E
u

∞
X

#
β t−1 (αθt ut − C (ut ))

t=1

(79)

subject to (10) ∀t ≥ 1.
If α̂ is the Lagrange multiplier on constraint (14), then W (α̂) is simply the Lagrangian associated
with problem (78), whose unique maximum (the objective is strictly concave and the constraints
are linear) is attained at û by Theorem 4.19
We now show how applying Corollary 1 leads to a recursive characterization of this problem,
using different techniques than those described in Section 2.3.2. We then discuss the strengths
and weaknesses of these two alternative approaches. For simplicity we assume that |Θ| = 2; the
analysis extends straightforwardly to any number of shocks.
When |Θ| = 2 there are two incentive constraints (10) in period 1 corresponding to shocks
θ(1) and θ(2) . Adapting the arguments of Proposition 5 shows that the constraint of type θ(2)

is slack. Let ξˆ θ(1) be the Lagrange multiplier on the first-period incentive constraint of type
θ(1) in problem (79). By Corollary 1 (written for a maximization rather than minimization

19

α̂ can be found from a max min problem as in Corollary 1 by observing that
 we can replace
P∞by monotonicity
t−1
the equality constraint (14) in problem (78) with the inequality constraint E
θt ut θ t ≥ v 0 .
t=1 β

49


problem),20 ξˆ θ(1) and the solution to (79) are also the solution to
W (α) ≡ min max E
ξ≥0

"∞
X

u

#
β

t−1

(αθt ut − C (ut ))

t=1

"

(

"


+ξ

θ(1) u1 θ(1) + E

∞
X

#)
β t−1 θt ut θ1 = θ(1)

t=2

(

"


− θ(1) u1 θ(2) + E

∞
X

#)#
β t−1 θt ut θ1 = θ(2)

t=2

subject to (10) ∀t ≥ 2.
Re-arrange these terms and use the definition of W to obtain
W (α) ≡ min

max

ξ≥0 u(θ(1) ),u(θ(2) )

"
π θ(1)



αθ(1) +
"

+ π θ(2)



αθ(2) −

!

ξθ(1)
π θ(1)







u1 θ(1) − C u1 θ(1)



!#

+ βW

ξ

α+
π θ(1)

!#

+ βW

ξ

α−
π θ(2)

!

ξθ(1)
π θ(2)





u1 θ(2) − C u1 θ(2)

.

(80)
Problem (80) is an alternative way to characterize the solution to the maximization problem
(78). The function W can be found using standard contraction mapping techniques (see Marcet
and Marimon (2015) for proofs). The policy functions to this Bellman equation can then be
used to generate the solution û the same way we did in Section 2.3.2.
We conclude this section by comparing the two alternative recursive formulations (23) and
(80). On the one hand, the max operator in (23) is simpler to handle than the min max operator
in (80).21 This makes (23) easier to use in many simple applications. On the other hand, the
function W is defined over an a priori known domain, R, while the domain of K is endogenous.
We could easily characterize the latter in the setup of Section 2.3.2, see footnote 7. In more
general settings, however (with Markov shocks, additional constraints, etc.), characterizing the
state space is more difficult and requires using the techniques of Abreu et al. (1990) (see Propo20

We can verify the sufficient conditions allowing us to apply Corollary 1 using the same steps as in Section
3.1.2.

21
Many insights can be obtained from problem (80) without considering the min part. Since ξˆ θ(1) ≥ 0
(in fact, with strict inequality from the discussion in Proposition 5), problem (80) immediately shows that the


ξ̂(θ
)
weight α θ(1) ≡ α̂ + π θ(1) increases for the agent who reports θ(1) , i.e. α θ(1) ≥ α̂, while the weight
( (1) )


ξ̂(θ
)
α θ(2) ≡ α̂ − π θ(1) decreases, i.e. α θ(2) ≤ α̂. To see the implication of this fact, observe that the solution to
( (2) )
P∞ t−1

(79), ûα , has a property that E
θt uα
is increasing in α, so that higher weights correspond to higher
t
t=1 β
lifetime utilities. Therefore we showed, without explicitly considering the min operator, that the expected lifetime
utility starting from next period increases for an agent who reports θ(1) , and decreases for the agent who reports
θ(2) . See Acemoglu et al. (2011) for another application of this technique.

50

sition 8), so that using the tools described in this section can be simpler. An in-depth discussion
of this approach is outside the scope of our work and we refer the interested reader to the papers
that describe it in more detail. The pionnering work that first developed this approach is Marcet
and Marimon (2015). The more recent applications are Messner et al. (2012, 2014), Cole and
Kubler (2012), Espino et al. (2013).

3.2

Mechanism Design Without Commitment

In our discussion so far we assumed that the principal, who provides insurance to agents, has
perfect commitment: it implicitly promises a menu of allocations for infinitely many periods and
never entertains the possibility of reneging on those promises as time goes by. This assumption
was crititcal in proving the Revelation Principle in Theorem 1. This assumption is not innocuous.
For example, we saw in Proposition 6 that long-run immiseration is a common feature of the
optimal insurance contracts. While such a contract is optimal ex-ante in period 0, it provides
the worst possible allocation in the long run. Any benevolent principal would like to re-optimize
at that point. Thus the assumption that the principal has perfect commitment is very strong
in many applications.
In this section we discuss several approaches to analyze dynamic contracting problems in
environments where the principal cannot commit. We start with the set up of Section 2.2 with
two modifications. First, we assume that insurance in that economy is provided by a benevolent
principal, which we call “the government”, that cannot commit ex-ante, in period 0 to its future
actions. Second, in order to focus on information revelation and various generalizations of
Theorem 1 we abstract from borrowing and lending and assume that the total consumption of
all agents should be equal to the total endowment e in each period, as in Section 3.1.2.
Since the government cannot commit, we formally describe the environment as an infinitely
repeated game between one large player (the government) and a continuum of atomistic agents.22
Each period of the game is divided into two stages. In the first stage agents report information
about the realization of their idiosyncratic shock to the government, and in the second stage
the government chooses allocations.23 As in Section 2.2, it is helpful to start by describing
communication between the agent and the principal using a general message space M .
Agents’ reporting strategies in period t are maps σ̃t : M t−1 × Θt × H t → ∆ (M ), and the
government’s strategy is a map c̃t : M t × H̆ t → ∆ (R+ ), where M t−1 and Θt are the histories
of reports and the realizations of shocks for each agent, and H t and H̆ t (described below)
are the aggregate histories of the game. To avoid complicating our discussion with measuretheoretic apparatus, we assume that ∆ (M ) and ∆ (R+ ) assign finite probabilities to finitely
many elements. The assumption of a continuum of agents simplifies the analysis. By the law
22

See Chari and Kehoe (1990, 1993) for classic references.
Although this set up appears a bit stylized, many of its features emerge naturally in many more sophisticated
models of political economy. For example, models in which policies are chosen via probabilistic voting à la Lindbeck
and Weibull (1987) in each period often reduce to our set up with a benevolent government that cannot commit
to its future actions. See Farhi et al. (2012), Scheuer and Wolitzky (2014) or Dovis et al. (2015) for applications.
23

51

of the large numbers, σ̃ generates the aggregate distribution of reports that the government
receives from the agents, and c̃ generates the distribution of consumption allocations provided
by the government. Moreover, these distributions are not affected if an individual agent (who
is of measure zero) deviates from his equilibrium strategy. Assuming that these aggregate
distributions are observed, history H t consists of the aggregate distributions generated by σ̃
and c̃ up to period t − 1, while H̆ t consists of H t and the distribution of aggregate reports
generated by σ̃t .
We describe how to characterize the perfect Bayesian equilibrium (PBE) of this game that
delivers that highest ex-ante utility to agents. Well-known arguments (see Chari and Kehoe
(1990) or a textbook treatment in Chapter 23 of Ljungqvist and Sargent (2012) for details)
imply that to characterize such an equilibrium it is sufficient to focus only on a subset of the
histories of the game. Namely, it is sufficient to characterize the reporting done by the agents
and allocations provided by the government “on the equilibrium path”. If the government ever
deviates from the equilibrium path distribution of allocations (up to a measure zero) then in
subsequent histories agents and the government switch to the worst PBE. With a slight abuse of
notation, we use (σ̃, c̃) to describe the behavior of agents and the government “on the equilibrium
path”, i.e., mappings σ̃t : M t−1 × Θt → ∆ (M ) and c̃t : M t → ∆ (R+ ) which no longer have the

aggregate histories in H t , H̆ t as arguments. We use σ̃t m mt−1 , θt to denote the probability

that an agent with history mt−1 , θt reports the message m in period t.
The pair (σ̃, c̃) must satisfy three constraints. First, in equilibrium each individual agent
finds it optimal to stick to his reporting strategy σ̃ rather than deviating to any other reporting
strategy σ̃ 0 , so that the constraint (4) is satisfied. Note that to write this constraint we implicitly
used the assumption of a continuum of agents. If an individual agent chooses σ̃ 0 rather than σ̃,
the aggregate distribution of reports to the government remains unchanged and therefore the
equilibrium allocations remain the same. Thus the same c̃ appears on both sides of the incentive
constraint. Second, any allocation that the government chooses must also be feasible, i.e. satisfy
Ec̃◦σ̃ [ct ] ≤ e, ∀t.

(81)

Third, the government should not find it optimal to deviate from its equilibrium play at any
point of time. This constraint can be written as
"
c̃◦σ̃

E

∞
X

#
β

s−t


θs U (cs ) ≥ W̃t {σ̃s }ts=1 +

s=t

β
U (e) , ∀t.
1−β

(82)

The left hand side of this constraint is the government’s payoff from continuing to play its
equilibrium strategy in period t. The right hand side consists of two parts: the value of the best
one-time deviation W̃t (to be defined below) followed by the value of the worst PBE starting
from the next period. Since we assumed that shocks are i.i.d., it is easy to show that the worst
PBE is such that agents reveal no information to the government and receive forever the same

52

per capita allocation e independently of the shock. The expected value of this allocation is
1
1−β U (e).

We now derive the value of deviation W̃t . Let µt mt denote the measure of agents who
report history mt . It is defined recursively as µ−1 = 1 and


 X

µt mt = µt−1 mt−1
π θt σ̃t mt mt−1 , θt .
θt ∈Θt

The measure µt depends on the entire history of reports up to period t, {σ̃s }ts=1 . We use


Eσ̃ θ mt to denote the government’s posterior expectation of an agent’s type being θ, conditional on the history of reports mt . The best deviation solves

W̃t {σ̃s }ts=1 =

max

X

{cw (mt )}mt ∈M t

µt m t

  σ̃ 


E θ mt U cw mt

(83)

mt ∈M t

subject to the feasibility constraint
X



µt mt cw mt ≤ e.

(84)

mt ∈M t

At this stage of our discussion it is useful to compare our set up to that with commitment in Section 2.2. Relative to the environment in that section, we have one additional
constraint, (82). The important feature of this constraint is that posterior beliefs appear on
both sides of this constraint. This complicates the analysis. In particular, note that the proof
of Theorem 1 does not need to go through when constraint (82) is imposed. If we replace

Γ̃ = (M, c̃ ◦ σ̃) with a direct truthful mechanism Θ, c ◦ σ truth , we still obtain feasible and
incentive
compatible
allocations for all agents as in the proof of Theorem 1. However we have



t
truth
W̃t σs
≥ W̃t {σ̃s }ts=1 , generally with a strict inequality, since a direct mechanism
s=1
reveals more precise information to the government and increases its incentives to deviate. Since


P∞ s−t
truth P∞
s−t θ U (c ) , the direct
by construction we have Ec̃◦σ̃
θs U (cs ) = Ec◦σ
s
s
s=t β
s=t β
truthtelling mechanism tightens the sustainability constraint of the government. Intuitively,
this mechanism always reveals more information to the government than any other communication mode, increasing the gains for the government from ex-post reoptimization and lowering
ex-ante welfare.
The discussion in the previous paragraph implies that it is generally not without loss of
generality to restrict attention to mechanisms in which agents report their type directly to the
government, as we did in Section 2.2, and that one needs to work with more general message
spaces to characterize the optimal insurance in this setting. Here we outline how it can be done.
Our discussion is based on Golosov and Iovino (2014); for more detailed discussion and proofs
we refer the reader to that paper.24
24

Formally, Golosov and Iovino (2014) study a slightly more general game that allows agents’ and government’s
strategies to depend on the realization of payoff irrelevant variables. This convexifies the set of equilibrium payoffs

53

To find the optimal insurance without commitment, the best PBE solves
"
max Ec̃◦σ̃
c̃,σ̃

∞
X

#
β t−1 θt U (ct )

(85)

t=1

subject to (4), (81), (82). Under some technical conditions this problem can be significantly
simplified. In particular with i.i.d. shocks the history of past realization of shocks is irrelevant
and we can simply restrict attention to reporting strategies of the form σ̃t : M t−1 × Θt →
∆ (M ). Similarly, one can also show the analogue of Proposition 1 that stochastic allocations of
consumption are suboptimal, so that we can assume without loss of generality that c̃t : M t → R+ .
Finally without loss of generality we can restrict M to a finite set.25
We now show how to write this problem recursively. As in Section 2, it is more convenient
to change variables and optimize with respect to ut = U (c̃t ), and constraint (4) simplifies if we
use a one shot deviation principle. Using the same arguments as those leading to equation (10),
we can rewrite (4) as: for all mt ∈ M t ,

vt m t =

X

π (θ) σ̃t+1 m mt , θ




θut+1 mt , m + βvt+1 mt , m ,

(86)

(θ,m)∈Θ×M


and for all mt , θ ∈ M t × Θ, for all m ∈ M and some mθ ∈ M ,




θut+1 mt , mθ + βvt+1 mt , mθ ≥ θut+1 mt , m + βvt+1 mt , m

(87)

with for all m ∈ M ,
σ̃t+1 m mt , θ

 




 
θut+1 mt , mθ + βvt+1 mt , mθ − θut+1 mt , m + βvt+1 mt , m
= 0.
(88)
Equation (86) is simply a generalization of (12) to the setting in which agents reveal noisy information to the government. The next two equations form the incentive compatibility conditions.
Equation (87) says that there must be some message mθ that agent θ prefers to all others given
the past history of messages mt and shock realization θ. Equation (88) says that if an agent
with current shock realization θ reports any message m other than mθ with positive probability

σ̃t+1 m mt , θ , then he must be indifferent between reporting m and mθ , since any report he
sends must give him the highest utility. Equations (87) and (88) are a generalization of (13)

and have recursive structure, with vt mt playing the role of the state variable.
We now show how to write the problem of maximizing (85) subject to (81), (82),
(86)-(88)
n o
∞
and
recursively using the Lagrangian techniques introduced in Section 3.1.2. Let λ̃ = λ̃t
t=1
∞
χ̃ = {χ̃t }t=1 be sequences of multipliers on the constraints (5) and (82), respectively. Assuming
and ensures that some technical condititions simplifying the analysis hold. To ease the exposition we simply
assume that those conditions are satisfied.
25
Specifically, the cardinality of M can be taken to be 2|Θ| − 1.

54

that these sequences are summable (see Section 3.1.1), we can write the Langrangian, using
Abel’s formula, as26
∞
i
h
X
max Eσ̃
(89)
β̄t θt ut − λt C (ut ) − χt W̃t
u,σ̃

t=1

P
subject to (86)-(88), where β̄t = β t−1 + ts=1 β t−s χ̃s , λt = λ̃t /β̄t , χt = χ̃t /β̄t . Note that this
problem is very similar to the problem considered in Section 3.1.3, except that now we choose
the optimal amount of information that is revealed to the government, σ̃, and the costs of
information revelation are captured by the terms χt W̃t .
This problem still does not have a natural recursive form. Our recursive characterization
in Section 3.1.2 relied on the fact that the linearity of the objective function allowed us to
separately solve for the optimal allocations after any history θt (which without commitment
becomes a history of reports mt ) without paying attention to the other histories. The key
difficulty now is that W̃t depends on the distribution of reports that are sent by all agents.
We show here how to write a recursive formulation under the assumption that preferences are
logarithmic. Golosov and Iovino (2014) use the techniques of Section 3.1.1 to obtain the same
characterization for arbitrary concave utility functions.
When preferences are logarithmic, W̃t is easy to simplify. The first order conditions of
problem (89) give
0
λw
t C

uw
t

t

m



σ̃



= E θ mt = P


σ̃t mt mt−1 , θ
,
0
t−1 , θ 0 )
θ0 ∈Θ π (θ ) σ̃t (mt |m

w
w
where uw
t ≡ U (ut ) and λt is the Lagrange multiplier on constraint (84). With logarithmic
preferences, C 0 = C = exp. Using this fact together with (84) we can easily find that λw
t = 1/e.
The key property is that this multiplier does not depend on particular values of {σ̃t }mt ,θt , and
therefore W̃t can be written as


X



W̃t {σ̃s }ts=1 =
µt−1 mt−1 Wt σ̃t m mt−1 , θ


(m,θ)∈M ×Θ

,

mt−1

where


Wt {σ̃ (m |·, θ )}(m,θ)∈M ×Θ =

max

{uw (m)}

m∈M

X

w
π (θ) σ̃ (m |·, θ ) [θuw (m) − λw
t C (u (m))] .

(m,θ)∈M ×Θ

If we subsitute this equation into (89), we can easily write the problem recursively, letting

26

∗

∗

Since consumption allocations are deterministic, we write Eσ̃ rather than Euσ̃ .

55

β̂t+1 ≡ β̄t+1 /β̄t , as
kt (v) =

max

{u(m),w(m),σ(m|θ )}(m,θ)∈M ×Θ
σ(·|θ )∈∆(M )

h
i


Eσ θu − λt C (u) + β̂t+1 kt+1 (w) − χt Wt {σ (m |θ )}m,θ
(90)

subject to: for all θ,
v=

X

π (θ) σ (m |θ ) [θu (m) + βw (m)] ,

(θ,m)∈Θ×M

for all m and some mθ ,
θu (mθ ) + βw (mθ ) ≥ θu (m) + βw (m) ,
and for all m,
σ (m |θ ) [{θu (mθ ) + βw (mθ )} − {θu (m) + βw (m)}] = 0.
Note that problem (90) is very similar to problem (18) in Section 2, with two modifications.
First, the objective function has an additional term −χt Wt which captures the additional cost of
information revelation off the equilibrium path. Second, agents generally play mixed strategies
over the message space M rather than a pure reporting strategy over the set Θ.
Golosov and Iovino (2014) analyze this problem and show that the optimal amount of information that each agent reveals depends on the promised utility v. The key insight of their
paper is that the agents who should reveal more information to the government are those for
whom such revelation saves the most resources to the government on the equilibrium path. In
particular, in the set up discussed above, the government loses relatively little resources if it
delivers a low value of v without knowing the realization of θ, while information revelation by
agents with higher v leads the government to save more resources. Golosov and Iovino (2014)
show that for all v sufficiently small agents reveal no information to the government and play the
same reporting strategy independently of the realization of their shock; on the other extreme,
agents with sufficiently high promise v reveal full information to the government (at least as
long as U exhibits decreasing absolute risk aversion) just as in Section 2.2. Golosov and Iovino
(2014) further generalize their analysis by considering Markov shocks and obtaining a recursive
characterization along the lines of Section 2.5.27 They show that the government’s participation
constraints imply the existence of an endogenous lower bound below which agents’ promised
utility never falls, preventing the emergence of long-run immiseration which was obtained in
Section 2.4.

27

The problem of information revelation with persistent shocks is related to the literature on the ratchet effect,
see Freixas et al. (1985) and Laffont and Tirole (1988).

56

3.2.1

Optimal insurance with a mediator

In the game described in the previous section we assumed a particular communication protocol
between the agents and the government: agents first report some information to the government,
then the government takes some action. In settings where the government could commit, as in
Section 2.5, restricting attention to such communication protocols was without loss of generality
due to Theorem 1. As we saw, Theorem 1 fails when the government cannot commit. One may
wonder if better outcomes can be attained if richer ways to communicate between agents and
the government are available. The answer to this question turns out to be yes. Here we descibe
what the optimal communication devices are and how to characterize the optimal contracts in
such settings.
Suppose agents and the government can communicate indirectly, using a third party called
a “mediator”. The mediator can be a trusted third person with no stake in the outcome of the
game, or simply a machine that takes reports from the agents and recommends the action to
the government as a function of those reports using a pre-determined rule. Thus, the game is
essentially the same as in the previous section, with the following modification. In each period,
the agents first send reports σ̃t : M t−1 × Θt → ∆ (M ) to the mediator, then the mediator makes
recommendations σ̃tmed : M t → ∆ (R+ ) to the government about which consumption allocation
the government should pick. The government is then free to make any choice it wants.
Studying equilibria in this communication game using a mediator is interesting for the following reason. First, without loss of generality we can restrict attention to direct truthtelling
strategies σ truth for the agents, as defined in Section 2.2 (and hence we can assume that σ̃tmed is
a mapping from Θt to ∆ (R+ )). Moreover, with a mediator we can replicate the outcome of any
perfect Bayesian equilibrium with any other communication device. Thus, we get a version of
Theorem 1 for Bayesian Nash equilibria (see Myerson (1982, 1986) and Mas-Colell et al. (1995)
(Sec. 23.D)). Therefore, the equilibrium with a mediator provides an upper bound on what can
be achieved using any other communicating device.
We want to make two observations about games with a mediator. First, while without loss
of generality we can assume that agents report their types truthfully to the mediator, the mediator generally randomizes to garble the information that the government receives – otherwise
we government would be able to learn information perfectly about the agent’s type and this
mechanism would be equivalent to the direct truthtelling mechanism discussed in the previous
section. Second, while any PBE (using arbitrary communicating devices) can be implemented
as a PBE in a game with a mediator, the converse is not true. Thus, whether the equilibrium
with a mediator provides a reasonable description of the optimal insurance arrangement often
depends on the context. For example, many negotiations of the resolutions of conflicts between
countries already use mediators, so that this approach may be natural. On the other hand, in
many political settings it seems often difficult to introduce an uninterested third party outside of
the politician’s control, and the approach we described in the previous section may be preferable.

57

To see how this approach alters the incentive constraints, we consider the analogue of the
recursive problem (90). The mediator generally needs to randomize between different allocations
that it recommends to the government. For simplicity we assume that the mediator offers finitely
many recommendations m1 , . . . , mI to the government for each agent’s report. The reporting

strategies of the mediator are now simply σ̃tmed m mt−1 , θt for m ∈ M ≡ {m1 , . . . , mI }.
Assuming the one-shot deviation principle and that the dependence of period-t strategies on
θt−1 is redundant, we can write the agents’ incentive constraint as (86) and
X

med
σ̃t+1
m mt , θ




θu mt+1 + βvt+1 mt+1

m

≥

X

med
σ̃t+1
m mt , θ0




θu mt+1 + βvt+1 mt+1 , ∀θ0 .

(91)

m

Constraint (91) is weaker than constraints (87) and (88), so that more allocations are incentive
compatible when a mediator is used. One way to understand the intuition is as follows. When
an agent communicates using a mediator, he has no control over which recommendation the
mediator makes to the government. Thus his incentive constraint (91) should hold in expecation,
over all the recommendations that the mediator may make. When an agent communicates with
the government directly, he would never send any message to the government which is dominated
by another message. Therefore his incentive constraint (87), (88) should be satisfied for all the
messages sent to the government.
It remains to descibe how the government forms posterior beliefs based on the mediator’s
recommendations. The government’s behavior
that the
is formallyidentical to that in (83) except

t
t
med
value of the best deviation is now simply W̃t σ̃s
rather than W̃t {σ̃s }s=1 , so that the
s=1
government uses the mediator’s recommendations described by σ̃ med rather than agents’ reports
σ̃ to form its posterior beliefs. Nevertheless the mathematical structure of the two problems is
identical and we obtain a similar recursive representation as in (90), except that the incentive
constraints are replaced by: for all θ0 ,
X

σ med (m |θ ) [θu (m) + βw (m)] ≥

X

m


σ med m θ0 [θu (m) + βw (m)] .

m

A caution. We conclude this section with a caution about the usage of the term “Revelation
Principle” in the literature. Some authors reserve this term only for principal-agent models and
Theorem 1. Since Theorem 1 does not hold if the principal cannot commit, those authors often
say that “the Revelation Principle fails without commitment” (see, e.g. Laffont and Tirole (1988)
or Bester and Strausz (2001)). Other authors use this term more broadly as in Section 3.2.1,
when the mechanism designer is thought not as a principal per se but rather as a mechanical
randomizing device. In such settings truthful direct revelation holds both when the agents and
the principal can and cannot commit (see, e.g. Myerson (1982, 1986) and Mas-Colell et al.
(1995)), and one often hears that “the Revelation Principle always holds”. While it may be

58

confusing, there is no disagreement about the mathematical facts, and one just needs to be
careful about which version of the Revelation Principle one refers to.

3.3

Martingale Methods in Continuous Time

We now show how dynamic contracting problems can be conveniently analyzed in continuous
time frameworks. We only briefly touch on this literature here. Sannikov (2008, 2014) analyzed a continuous-time dynamic moral hazard problem where observable output follows a
Brownian motion whose drift is given by the agent’s unobservable effort. Williams (2009, 2011)
uses the stochastic Pontryagin principle based on the work of Bismut (1973, 1978) to analyze
a continuous-time version of the Thomas and Worrall (1990) endowment shock model, and
Cvitanic and Zhang (2012) apply the same techniques to moral hazard and adverse selection
problems. Zhang (2009) considers a dynamic contracting problem with a finite Markov chain
for the types. Miao and Zhang (2014) extend the Lagrangian techniques introduced in Section
3.1 to a model of limited commitment in continuous time.
Here we follow Sannikov (2008) who uses the dynamic programming principle in continuous
time to analyze the moral hazard model described in the discrete time setting in Section 2.6. We
start with a short primer on the mathematical techniques that allow us to solve this problem.
A fully rigorous exposition of these techniques is beyond the scope of this paper, but we present
the main tools that allow us to describe Sannikov (2008)’s model in a self-contained way.
3.3.1

Mathematical Background

For the basics of Brownian motion and stochastic processes, see e.g. Revuz and Yor (1999),
Øksendal (2003), or Karatzas and Shreve (2012). For an exposition of the theory of stochastic
optimal control, see e.g. Yong and Zhou (1999). In this section, after briefly introducing
the basics of stochastic processes, we simply state the three fundamental theorems that will
be important in the analysis of the continuous-time dynamic contracting model below, namely
Itô’s lemma, the Martingale Representation Theorem, and Girsanov’s theorem. We also describe
heuristically the dynamic programming principle in continuous time.
A stochastic process X is a family of random variables {Xt }t≥0 on a probability space


(Ω, F , P). Define the filtration {Ft }t≥0 such that for all t, Ft = σ {Xs }s≤t is the σalgebra generated by X from time 0 to time t. We say that the process X is Markovian if
P (Xt ∈ A |Fs ) = P (Xt ∈ A |Xs ) for all t > s and all Borel sets A. The process X is a martingale
(resp., submartingale) if E [|Xt |] < ∞ for all t ≥ 0 and E [Xt |Fs ] = Xs (resp. E [Xt |Fs ] ≥ Xs )
for all t > s. A stochastic process Z = {Zt }t≥0 on (Ω, F , P) is a Brownian motion if it satisfies
(see Section 37 in Billingsley):
(i ) The process starts at 0: P (Z0 = 0) = 1;

59

(ii ) The increments are independent: if 0 ≤ t0 ≤ . . . ≤ tn , then


P Ztk − Ztk−1 ∈ Ak , ∀k ≤ n =

n
Y


P Ztk − Ztk−1 ∈ Ak ;

k=1

(iii ) For 0 ≤ s < t the increment Zt − Zs is normally distributed with mean 0 and variance
t − s:
ˆ
1
2
P (Zt − Zs ∈ A) = p
e−x /2(t−s) dx;
2π (t − s) A
(iv ) The sample paths are continuous: for each ω ∈ Ω, the function t 7→ Zt (ω) is continuous.
In particular, a Brownian motion is a martingale.
We now define the concept of quadratic variation of a martingale. Consider a martingale M
that has continuous sample paths. Consider a partition Πt = {t0 , . . . , tn } of the interval [0, t]
with 0 = t0 < t1 < . . . < tn = t, and denote its mesh by kΠt k ≡ max1≤k≤n (tk − tk−1 ). Denoting
by P lim the limit of a process in the sense of the convergence in probability, we can show that
P lim

kΠt k→0

n
X

Mtk − Mtk−1

2

= hM it ,

k=1

where hM i is an adapted process with continuous and non-decreasing sample paths, called the
quadratic variation of the martingale M . In particular, in the case where M is a Brownian
motion, hM i is the deterministic process hM it = t, and the convergence holds almost surely.
Since hM i has non-decreasing sample paths ω, we can define the (path-by-path) Lebesgue´t
Stieljes integral 0 Xs (ω) d hM is (ω) for each ω of a stochastic process X on an interval [0, T ]
with T < ∞ (in the case where M is a Brownian motion, d hM is = ds is simply the Lebesgue
measure).
We refer to Revuz and Yor (1999) for the rigorous construction of the stochastic integral
´t
0 Xs dMs of a process X with respect to a martingale M that has continuous sample paths
(e.g., a Brownian motion). For such a martingale M , let L2 (M ) denote the (Hilbert) space of
processes X such that for all t ≥ 0 theh map (ω, s) 7→i Xs (ω) defined on Ω × [0, t] is measurable
´T
with respect to Ft ⊗ B ([0, t]), and E 0 Xs2 d hM is < ∞. The construction of the stochastic
integral involes several steps. Suppose first that X is a “simple” process, in the sense that there
exists a partition 0 = t0 < t1 < . . . < tn = T of [0, T ] such that Xs = ξj for all s ∈ (tj , tj+1 ],
where ξj is a bounded Ftj -measurable random variable. That is, X can be written as
Xs (ω) =

n−1
X

ξj (ω) I(tj ,tj+1 ] (s) .

j=0

60

We can then define, for tk < t ≤ tk+1 ,
ˆ

t

Xs dMs ≡

It (X) =
0

k−1
X

ξj (Mt+1 − Mt ) + ξk (Mt − Mtk ) .

j=0

The integral I (X) is then a square integrable continuous martingale with quadratic variation
´t
given by hI (X)it = 0 Xs2 d hM is . Next, any process X ∈ hL2 (M ) can be approximated
by a
i
´T
2
n
n
sequence of simple processes {X }n≥0 in the sense that E 0 (Xs − Xs ) d hM is → 0. We
can then show that the sequence of integrals I (X n ) is a Cauchy sequence in the complete space
L2 (M ). Its limit defines the stochastic integral. It satisfies E [It (X)] = 0 and is a martingale.
We now state the three main theorems which we use in our analysis. The first, Itô’s lemma,
is an extension of the chain rule from standard calculus:
Theorem 6. (Itô’s lemma.) Let f be a deterministic C 2 function and M a squared integrable
martingale. We have:
ˆ
f (Mt ) = f (M0 ) +
0

t

1
f (Ms ) dMs +
2

ˆ

0

t

0

f 00 (Ms ) d hM is .

The second important result is the Martingale Representation Theorem. If M is a martingale,
define the exponential martingale


1
E (M )t = exp Mt − hM it .
2

(92)

We can then show that E (M )t is a supermartingale, and it is a martingale if in addition


E exp 12 hM iT
< ∞. In particular, if Mt is defined as a stochastic integral with respect
´t
´t
to a Brownian motion Z, i.e. Mt = 0 µs dZs with 0 µ2s ds < ∞ a.s., then
ˆ
E (M )t = exp

0

t

1
µs dZs −
2

ˆ

t

µ2s ds


(93)

0

h
 ´
i
T
is a martingale if E exp 12 0 µ2s ds < ∞.
Theorem 7. (Martingale Representation theorem.) Let Z be a given Brownian motion.
Every square integrable continuous martingale M adapted to the filtration F Z generated by Z
admits a unique representation
ˆ t
Mt = M0 +
βs dZs
0

h
´
i
T
for some process β adapted to F Z that satisfies E exp 0 βs2 ds < ∞.
Finally, the third important result that we will use is Girsanov’s theorem, which concerns
the changes of measures.

61

Theorem 8. (Girsanov theorem.) Let Z be a Brownian motion and µ be an adapted process
´t
with 0 µ2s ds < ∞ a.s. Let E (M )t be defined by (93). If E [E (M )T ] = 1 (that is, if E (M ) is a
martingale) then, under
P̃ (dω) = E (M )T (ω) × P (dω) ,
the process

ˆ
Z̃ = Z −

t

µs ds
0

is a Brownian motion.
Finally we describe heuristically the dynamic programming principle in continuous time.
We skip many of the technicalities andrefer to Yong andZhou (1999) for a rigorous exposition.
Consider a filtered probability space Ω, F , {Ft }t≥0 , P , on which a Brownian motion Z is
defined, and let T ∈ (0, ∞) and A ⊂ R be a given Borel set. The state of a system at time t is
described by a stochastic process Xt ∈ R that evolves according to
ˆ
Xt0 = x +

ˆ

t0

t0

b (s, Xs , us ) ds +
t

σ (s, Xs , us ) dZs , 0 ≤ t ≤ t0 ≤ T,

(94)

t

where u : [0, T ] × Ω → A is the control process, and b, σ : [0, T ] × R × A → R. The goal is to
choose u to maximize the functional
ˆ T

J (u) ≡ E
f (s, Xs , us ) ds + g (XT ) ,
(95)
t

where f : [0, T ] × R × A → R and g : R → R.28 We assume that the functions b, σ, f, g, satisfy
suitable conditions ensuring that there exists a unique solution X to (94) for any t, x, u and that
the functional J (u) in (95) is well defined (see Definition 1.6.15. and Conditions (S1)0 and (S2)0
in Yong and Zhou (1999)). The control process u is admissible if: (i ) ut is {Ft }t≥0 -adapted; (ii )
X is the unique solution of equation (94); (iii ) the functions s 7→ f (s, Xs , us ) and s 7→ g (XT )
are in L1F ([0, T ] , R) and L1FT (Ω, R), respectively. The value function of the stochastic control
problem that we consider is
V (t, x) = sup J (u) ,
u

where the supremum is over all admissible controls u.29
28

Here the control problem ends at a fixed duration T . In our analysis of the moral hazard problem we will
deal instead with random horizons T optimally chosen by the principal (“retirement”), that is, where T is the
stopping time T ≡ inf {t ≥ 0 : xt ∈
/ O} for some open set O ⊂ R. The dynamic programming principle can be
extended to this case, see e.g. Section 2.7. in Yong and Zhou (1999) and Chapter 4 in Øksendal and Sulem
(2005).
29
Rigorously, it is often
to consider a weak formulation of the problem, in which the
 natural and necessary

filtered probability space Ω, F , {Ft }t≥0 , P and the Brownian motion Z are not fixed, but parts of the control
(see Sections 2.4.2. and 4.3.1. in Yong and Zhou (1999)). This is because the objective of the stochastic control
problem is to minimize the expectation of a random variable that depends only on the distribution of the processes
involved. We ignore this distinction in the sequel.

62

Theorem 9. (Dynamic Programming Principle.) For any stopping time τ with values in
[0, T ], the value function V (t, x) is equal to
ˆ
V (t, x) = sup E

τ


f (s, Xs , us ) ds + V (τ, Xτ ) .

u

t

Moreover, for all admissible controls u,
ˆ
Mt0 ≡

t0

f (s, Xs , us ) ds + V t0 , Xt0



t

is a supermartingale (i.e., −Mt0 is a submartingale), and it is a martingale if and only if u is
optimal. Suppose the value function V ∈ C 1,2 ([0, T ] × R). Then V is a solution to the following
second-order Hamilton-Jacobi-Bellman partial differential equation:

h
i
∂V
1 2
∂2V
− ∂V + sup
u∈A f (t, x, u) + b (t, x, u) ∂x + 2 σ (t, x, u) ∂x2 = 0,
∂t
V (T, x) = g (x) ,

∀ (t, x) ∈ [0, T ] × R,
∀x ∈ R.

Note that the last statement assumes smoothness conditions about the value function V ,
which is endogenous.30
3.3.2

Continuous-Time Model: Transitory effects of effort on output

We now analyze the moral hazard problem in a continuous time framework (see Section 2.6
for the discrete time version of the model), following Sannikov (2008)’s exposition. Our aim is
to derive and explain the main results with the minimum of technicalities. Therefore we omit
many technical details and refer to Sannikov’s work for the fully rigorous proofs.
We analyze a model where the agent’s current effort affects only current output. The agent
 
derives utility U (ct ) − h (θt ) from consumption ct ≥ 0 and effort θt ∈ 0, θ̄ at time t, where U is
twice continuously differentiable, increasing and concave with U (0) = 0 and limc→∞ U 0 (c) = 0,
and h is differentiable, increasing and convex with h (0) = 0 and h0 (0) > 0.
Fix a reference probability space (Ω, F , P) with a standard Brownian motion Z under P.
If the agent works according to the effort process θ = {θt }t∈[0,∞) with 0 ≤ θt ≤ θ̄ for all t, he
´t
generates an output yt given by yt = 0 θs ds + σZt , i.e.
dyt = θt dt + σdZt ,
where σ > 0 is a constant. The principal observes yt , but not θt nor Zt , and compensates the
agent with a consumption process c = {ct }t≥0 with ct ≥ 0 for all t. Denoting by Fty the filtration
generated by yt , we impose that the process ct is Fty -adapted, i.e., the agent’s compensation ct
30

There exist other notions of solutions to stochastic differential equations, called viscosity solutions, which
avoid making such assumptions, see e.g. Section 4.5. in Yong and Zhou (1999).

63

is conditional on past output {ys }s≤t .
Rather than fixing the underlying Brownian motion Z and solving for the agent’s effort
choice θ as a function of Z, we can instead view the agent as choosing a probability measure
31 That is, for each effort process θ we can define a process Z θ =
Pθ on
t
 the´output space.
t
σ −1 yt − 0 θs ds . By Girsanov’s theorem, Ztθ is a Brownian motion under the measure Pθ ,
where
´
´t
1 t 2
Pθ (dω) = E (Z)t P (dω) = e 0 θs dZs − 2 0 θs ds P (dω) .
A change of measure from Pθ to Pθ̂ on the space of output paths corresponds to a change in the
drift of the output process from θ to θ̂.
Planner’s problem. If he receives consumption c = {ct }t≥0 and provides effort θ = {θt }t≥0 ,
the agent gets the expected utility
θ

ˆ

∞

U (c, θ) = E

e

−rt


(U (ct ) − h (θt )) dt ,

(96)

0

where Eθ denotes the expectation under the probability measure Pθ induced by the strategy
θ, as defined above. The superscript θ over the expectation Eθ highlights that the agent’s
strategy affects the probability distribution over paths of output, and thus over compensation
realizations. Thus, the utility depends on the agent’s effort directly, as it enters the cost of effort
h (θt ), and indirectly through its effect on the probability distribution over the paths of yt .
The principal gets expected profit
Eθ

ˆ

∞


ˆ
e−rt (dyt − ct dt) = Eθ

0

∞


e−rt (θt − ct ) dt .

(97)

0

A contract (c, θ) is incentive compatible if the agent finds it optimal to exert the contractual
effort θt at every t, i.e., if {θt }t≥0 maximizes his expected utility U (c, θ) given {ct }t≥0 :
θ

ˆ

∞

e

E

−rt



θ̂

ˆ

(U (ct ) − h (θt )) dt ≥ E

0

∞

e

−rt



  
U (ct ) − h θ̂t dt , ∀θ̂.

(98)

0

The contract must deliver initial promised utility v̂0 , i.e.
θ

ˆ

∞

−rt

e

E


(U (ct ) − h (θt )) dt ≥ v̂0 .

(99)

0

The principal’s problem consists of choosing the contract (c, θ) that maximizes his expected
profit (97) among all the contracts that satisfy the incentive compatibility (98) and promise

31

Similarly, in the standard static moral hazard problem, we can view the agent as choosing the probability
distribution P (y |θ ) over output values y generated by his effort θ.

64

keeping (99) constraints, that is,
θ

ˆ

∞

max E
c,θ

e

−rt


(θt − ct ) dt

0

subject to (98), (99).
The principal can commit to the contract he offers.
Reducing the planner’s problem to an optimal stochastic control problem. The
planner’s problem can be solved by reducing it to an optimal stochastic control problem. As
in the discrete time framework, we use the agent’s continuation utility vt (defined formally below) as state variable. The key simplification of the planner’s problem comes again from the
(continuous-time equivalent of the) one-shot deviation principle, which substantially reduces
the set of nincentive
constraints: the agent’s incentive constraints hold for all alternative strateo
gies θ̂ = θ̂t
if they hold just for strategies that differ from θ = {θt }t≥0 for an instant.
t≥0

The Martingale Representation Theorem then allows us to express the instantaneous incentive
constraints in terms of vt .
Fix an arbitrary consumption process c = {ct }t≥0 and an effort strategy θ = {θt }t≥0 (not
necessarily optimal for the agent given c). The agent’s continuation value vt (c, θ), defined as
his expected future payoff from (c, θ) after time t (i.e., after a given history of output {ys }s≤t ),
is given by
ˆ

∞

vt (c, θ) =Eθ

e−r(s−t) (U (cs ) − h (θs )) ds |Ft .

(100)

t

Throughout this section, for a given time t and contract (c, θ), we also define the agent’s total
expected payoff from the contract (c, θ) given the information at time t as:32
Vtc,θ

θ

ˆ

=E

∞

−rs

e



ˆ

(U (cs ) − h (θs )) ds |Ft =

0

t

e−rs (U (cs ) − h (θs )) ds + e−rt vt (c, θ) .

0

(101)
We first derive the law of motion of vt (c, θ) by applying the Martingale Representation Theorem.
Proposition 11. Fix a contract (c, θ) with finite expected payoff to the agent. An adapted
process vt is the continuation value process (as defined in (100)) associatedh with the
contract
´t 2 i
(c, θ) if and only if there exists an Ft -adapted process β = {βt }t≥0 with E 0 βs ds < ∞ for
all t such that, for all t ≥ 0,
dvt = (rvt − U (ct ) + h (θt )) dt + βt (dyt − θt dt)

(102)



and the transversality condition limt→∞ Eθ e−rt vt0 +t |Ft0 = 0 holds almost everywhere.
Proof. Fix a contract (c, θ). The process Vtc,θ defined in (101) is a martingale under the prob32

See Theorem 9 above.

65

ability measure Pθ . Hence by the Martingale Representation Theorem there exists an adapted
process βt such that
ˆ t
c,θ
c,θ
e−rs βs σdZsθ , 0 ≤ t < ∞,
Vt = V0 +
0



where Ztθ = σ −1 yt −

´t
0

θs ds



is a Brownian motion under Pθ . Differentiating both expres-

sions for Vtc,θ with respect to t and equating them implies that vt (c, θ) satisfies (102). The
transversality condition (for simplicitly with t0 = 0) follows from
θ

ˆ

t

e

lim E

t→∞

−rs



θ

ˆ

(U (cs ) − h (θs )) ds = E

∞

e

−rs


(U (cs ) − h (θs )) ds ,

0

0

´t
by the Dominated Convergence Theorem using that θs , and thus 0 e−rs (U (cs ) − h (θs )) ds, is


bounded. A similar argument shows that limt→∞ Eθ e−rt vt0 +t |Ft0 = 0 for all times t0 ≥ 0.
Conversely, suppose that vt is a process that satisfies (102) (for some starting value v0 and
some volatility process βt ) and the transversality condition. Define Vt as
ˆ

t

Vt =

e−rs (U (cs ) − h (θs )) ds + e−rt vt .

0

Differentiating Vt implies that it is a martingale when the agent is following the effort strategy
θ, i.e., under the probability measure Pθ . Therefore
θ

θ

ˆ

v0 =V0 = E [Vt |F0 ] = E

t

e

−rs





(U (cs ) − h (θs )) ds |F0 + Eθ e−rt vt |F0 .

0

Since the transversality condition is satisfied (for t0 = 0), taking limits as t → ∞ in the previous
equation implies that v0 = v0 (c, θ). A similar argument shows that vt is the continuation value
process vt (c, θ) defined by (100) at any time t ≥ 0.
The law of motion (102) of the continuation utility has the following interpretation. Since
dyt − θt dt = σdZtθ has mean zero when the agent takes the recommended effort level θ,
[rvt (c, θ) − (U (ct ) − h (θt ))] is the drift of the agent’s continuation value. The value that the
principal owes to the agent (future expected payoff), vt (c, θ), grows at the rate of interest r,
and falls due to the flow of repayments (U (ct ) − h (θt )). The transversality condition has to
hold if the debt is eventually repaid. Since the agent’s compensation and recommended effort
are determined by output yt , his continuation payoff vt (c, θ) is also determined by output, and
the process rβt then expresses the sensitivity of the agent’s continuation value to output at a
given time, which will be the key to affect the agent’s incentives.
The previous lemma is useful because it allows us to simplify the set of incentive constraints
with a version of the one-shot deviation principle (Proposition 12 below), which shows that the
agent’s incentive constraints hold for all alternative strategies θ̂ if they hold for all strategies
which differ from θ for an infinitesimally small amount of time. Heuristically, suppose that

66

the agent has conformed to the contract (cs , θs ) for s ≤ t and cheats by performing effort θ̂ in
the interval [t, t + dt] and reverting to{θs } for s ≥ t + dt. His immediate consumption ct is
unaffected, his cost on [t, t + dt] is h θ̂ dt, and his expected benefit on [0, ∞), i.e. the expected
impact of effort on his continuation value, is Eθ̂ [βt dyt ] = βt θ̂dt. Hence for the contract to be
incentive compatible we must have
n
 
o
βt θt − h (θt ) = max −h θ̂ + βt θ̂ ,
θ̂≥0

almost everywhere.33 This argument can be made rigorous, and in addition the condition is not
only necessary but also sufficient:
n ifothis one-shot condition holds at each instant t, then any
is suboptimal.
dynamic deviation strategy θ̂ = θ̂s
s≥0

Proposition 12. Let (c, θ) be a contract with agent’s continuation value vt (c, θ) and let βt be
the process from Lemma 11 that represents vt (c, θ). Then (c, θ) is incentive compatible if and
 
only if ∀θ̂ ∈ 0, θ̄ , ∀t ≥ 0,
n
 o
θt ∈ arg max βt θ̂ − h θ̂ , a.e.

(103)

θ̂≥0

Proof. Suppose
that (103) is satisfied. Suppose that an agent follows the alternative effort
n o
t
process θ̂ = θ̂s
until time t and reverts back to θ thereafter; denote by θ̂ this strategy.
s≥0

t

The time-t expectation of his total payoff is given by Vtc,θ̂ defined in (101),
Vtc,θ̂

ˆ

t

=

t


 
e−rs U (cs ) − h θ̂s ds + e−rt vt (c, θ) .

0

t


Differentiating Vtc,θ̂ and using equation (102) to compute d e−rt vt (c, θ) , we find34
t

dVtc,θ̂ = e−rt

n

 
o


βt θ̂t − h θ̂t − (βt θt − h (θt )) dt + e−rt βt dyt − θ̂t dt .



t
Thus, since dyt − θ̂t dt is a Brownian motion under Pθ̂ , if (103) holds the drift of Vtc,θ̂ under
t

the probability measure Pθ̂ is non-positive and thus Vtc,θ̂ is a Pθ̂ -supermartingale. Hence we
have
ˆ t



  
t
0
 −rt

c,θ̂
θ̂
−rs
θ̂
θ̂
E
e
U (cs ) − h θ̂s ds + E e vt (c, θ) = E Vt
|F0 ≤ V0c,θ̂ = v0 (c, θ) .
0

33

Note the fixed point nature of the argument: θt generates vt (c, θ) which yields βt ; in turn, the incentives
have to be satisfied given this process βt .
34
This equation evaluates the incremental change in the agent’s utility from pursuing the alternative effort
strategy θ̂ for an additional unit of time during [t, t + dt], and shows that in expectation such an incremental
deviation hurts the agent. The
o equation then uses a supermartingale argument to obtain inductively that
n next
the whole deviation strategy θ̂t
is worse than {θt }t≥0 .
t≥0

67




θ̂ e−rt v (c, θ) ≥ −e−rt h θ̄ , we obtain
Taking
the
limit
as
t
→
∞
using
the
fact
that
E
t


v0 c, θ̂ ≤ v0 (c, θ).
Conversely, if (103) does not hold on a set of times
paths
with positive measure,
 and
 sample


then pick a deviation θ̂ defined as θ̂t = arg maxθ̂ −h θ̂ + βt θ̂ everywhere. The drift of
t

Vtc,θ̂ under Pθ̂ is non-negative and positive on a set of positive measure, so that for t large
enough the time-0expected payoff from following θ̂ until time t and switching to θ thereafter


0
t
t
is v0 c, θ̂ = Eθ̂ Vtc,θ̂ |F0 > V0c,θ̂ = v0 (c, θ). Thus the strategy θ is suboptimal.
For a given effort θ, denote by β (θ) the sensitivity that maximizes (−h (θ) + βθ), namely
β (θ) = h0 (θ) if θ > 0 and take β (θ) = 0 if θ = 0.
Propositions 11 and 12 imply that there is a one-to-one correspondence between incentivecompatible contracts (c, θ) and controlled processes vt that satisfy the one-shot deviation conditions (103), so that β (θt ) replaces βt in (102). We are now ready to reformulate the planner’s
problem as a stochastic control problem, using the continuation value vt as the single state
variable.
Solution to the optimal stochastic control problem. The planner maximizes his expected profit (97) over incentive compatible contracts (c, θ) subject to the law of motion of vt ,
the transversality conditions, and delivering initial promised utility v̂0 . We consider a relaxed
problem without the transversality condition (to be checked ex-post). Before we analyze this
problem, note that as in the discrete time setting, the principal has the option of “retiring” the
agent at a given time τ by allocating a constant consumption ct = c and recommending zero
effort θt = 0 for all t ≥ τ . The continuation value at retirement time τ is then vτ = r−1 U (c), so
that c = U −1 (rvτ ). The retirement time τ must be specified in the contract, so it is a stopping
time with respect to the filtration Ft generated by the output process y. We can thus write the
principal’s value of the optimal contract as
K (v̂0 ) =

maxc,θ,τ

θ

ˆ

τ

e

E

−rt



(θt − ct ) dt +

0

subject to

σdZtθ




e−rτ −1
U (rvτ )
−
r

(104)

dvt = (rvt − U (ct ) + h (θt )) dt + β (θt ) σdZtθ

(105)

v0 = v̂0 .

(106)

Note in particular that the incentive constraints (98) are automatically satisfied if the constraint
(105) holds. The function K (v) can be found using standard optimal control and optimal stopping techniques, where the control variables are θt , ct , τ and the state variable is vt . The principal’s problem can be solved in two steps: first, guess an optimal contract using the appropriate
Bellman equation; second, verify ex post that this contract is indeed optimal.
We start by conjecturing the optimal contract. The function K is continuous on [0, ∞)
with K (v) ≥ −r−1 U −1 (rv) for all v. It satisfies the following Hamilton-Jacobi-Bellman (HJB)

68

equation:35
(
rK (v) = max

− U −1 (rv) ;
)
1
max (θ − c) + (rv − U (c) + h (θ)) K 0 (v) + σ 2 (β (θ))2 K 00 (v)
2
0≤θ≤θ̄

(107)

c≥0

with the three boundary conditions
K (0) = 0, K (v̄) = −r−1 U −1 (rv̄) , K 0 (v̄) = −U −10 (rv̄) ,

(108)

for some v̄ ≥ 0. Intuitively, (107) means that the principal maximizes the expected current
flow of profit (θ − c) plus the expected change of future profit due to the drift and volatility of
the agent’s continuation value, until the stopping time τ at which the principal either retires
the agent (if vτ = v̄) or fires him (if vτ = 0). The second and third boundary conditions
in (108) mean that the optimal retirement time occurs at the continuation value v̄ where the
value-matching condition (which equates the value of retiring the agent with that of continuing
with positive effort) and the smooth-pasting condition (which equates the marginal values of
retiring and continuing) are satisfied. We can show that there exists a unique function K that
satisfies the HJB equation (107) with the three boundary conditions (108). The stopping time

τ = inf t ≥ 0 : K (v) ≤ −r−1 U −1 (rv) satisfies τ < ∞ a.s.,36 and the function K is concave.
Define, for an arbitrary control policy (c, θ), the process
ˆ
Gc,θ
t

=

t

e−rs (θs − cs ) ds + e−rt K (vt ) .

(109)

0

The following proposition conjectures the optimal contract from the solution to (107), (108) and
then verifies that it is indeed optimal using martingale techniques:
Proposition 13. Denote by θ (v) , c (v) the maximizers in the right hand side of the HJB equation.37 Consider the unique solution K (v) ≥ −r−1 U −1 (rv) to the HJB equation (107) that
satisfies the conditions (108) for some v̄ ≥ 0. For any v̂0 ∈ [0, v̄], define the process vt by

35
In fact, this is a Hamilton-Jacobi-Bellman Variational Inequality (HJBVI), where the HJB comes from the
optimal stochastic control problem and the VI comes from the optimal stopping problem. See Chapter 4 in
Øksendal and Sulem (2005).
36
If h0 (0) = 0, the retirement point v̄ may not be finite, so that K (v), c (v), θ (v) asymptote to K0 (v), ∞, 0
as v → ∞.
37
The optimal effort maximizes the difference between the expected flow of output θ, and the costs of compensating the agent for his effort, −h (θ) K 0 (v), and of exposing him to income uncertainty to provide incentives,
2
− σ2 β (θ)2 K 00 (v). The optimal consumption is 0 for v small enough (i.e., for K 0 (v) ≥ −1/u0 (0)), and it is
increasing in v according to K 0 (v) = −1/U 0 (c) otherwise, where 1/U 0 (c) and −K 0 (v) are the marginal costs of
giving the agent value through current consumption and through his continuation payoff, respectively.

69

v0 = v̂0 and
dvt = r (vt − u (c (vt )) + h (θ (vt ))) dt + rβ (θ (vt )) (dyt − θ (vt ) dt)

(110)

until the stopping time τ when vτ hits 0 or v̄. Define the contract (c, θ) with payments ct = c (vt )
and recommended effort θt = θ (vt ) for t < τ , and ct = U −1 (rvτ ) and θt = 0 for t ≥ τ . Then
(c, θ) is incentive compatible and it has value v̂0 = v0 (c, θ) to the agent and profit K (v̂0 ) to the
principal. Moreover, consider a concave solution K of the HJB equation (107). Any incentive
compatible contract (c, θ) yields to the principal a profit less than or equal to K (v0 (c, θ)).
Proof. Let vt be given by the stochastic differential equation (110) for t ≤ τ and vt = vτ for
t > τ (note in particular that v ∈ [0, v̄] is bounded). We show that vt = vt (c, θ) for all t ≥ 0,
where vt (c, θ) is the agent’s true continuation value in the contract (c, θ) constructed above.
This will imply in particular that the agent gets value v0 (c, θ) = v̂0 from the contract. From
the representation of vt (c, θ) in Proposition 11, we have
d (vt (c, θ) − vt ) = r (vt (c, θ) − vt ) dt + (βt − β (θ (vt ))) σdZtθ ,
hence for all s ≥ 0, Eθ [vt+s (c, θ) − vt+s ] = ers (vt (c, θ) − vt ). But Eθ [vt+s (c, θ) − vt+s ] is
bounded, hence vt = vt (c, θ). Moreover, the contract (c, θ) is incentive compatible by construction since the process from Proposition 11 that represents vt (c, θ) is βt = β (θt ).
Next we show that the principal gets expected profit K (v̂0 ) from the contract. Differentiating
expression (109) and applying Itô’s lemma to K (vt ) yields that the drift of Gc,θ
under Pθ is
t
−rt

e




1 2
2
00
(θt − ct − rK (vt )) + (rvt − U (ct ) + h (θt )) K (vt ) + σ (β (θt )) K (vt ) .
2
0

Thus, when ct = c (vt ) and θt = θ (vt ), the drift of Gc,θ
under Pθ is equal to zero before time
t
τ , so that Gc,θ
is a martingale. By the Optional Stopping Theorem, we thus obtain that the
t
principal’s profit from the contract is
θ

ˆ

τ

e

E

0

−rs


h
i


(θs − cs ) ds + Eθ e−rτ K (vτ ) = E Gc,θ
= Gc,θ
τ
0 = K (v0 (c, θ)) .

Finally, consider an alternative incentive compatible contract (c, θ). Then (107) implies that
the drift of Gc,θ
under Pθ is smaller than zero, so that Gc,θ
is a bounded supermartingale. By
t
t
the Optional Stopping Theorem, we obtain that the principal’s expected profit at time 0 is less
than or equal to Gc,θ
= K (v0 (c, θ)). We refer to Sannikov (2008) for the technical details
0
omitted in this sketch of proof.
For any v0 > v̄, the function K (v) is negative and is an upper bound on the principal’s
value function; thus, there is no profitable contract with positive profit to the principal in that
range. In the range (0, v̄), replacing the optimal consumption c (v) and effort θ (v) into the

70

HJB equation, we obtain a non-linear second order differential equation for K (v) which can be
solved numerically. Finally, note that the envelope theorem applied to the HJB equation before
retirement implies
1
(rv − U (c) + h (θ)) K 00 (v) + σ 2 (β (θ))2 K 000 (v) = 0.
2
By Itô’s lemma, the left hand side is the drift of K 0 (vt ) = −1/U 0 (ct ) on the interval [v, v̄].
Thus the inverse of the agent’s marginal utility is a martingale when the agent’s consumption
is positive, a result that parallels the Inverse Euler Equation (64) found in the discrete-time
model.
Sannikov (2014) extends the analysis of the moral hazard model in continuous time to the
case where current actions affect not only current output, but also future output. The solution
to this problem is more involved than that of Sannikov (2008), but the steps and the martingale techniques (using the Martingale Representation Theorem to simplify the set of incentive
constraints and reduce the problem to a stochastic control problem) are similar.
We conclude this section with a brief discussion of the benefits of using a continuous-time
rather than discrete-time framework to analyze dynamic contracting problems. First, the
Hamilton-Jacobi-Bellman equation is more tractable analytically than the discrete-time Bellman equation (23). In particular De Marzo and Sannikov (2006) show how differentiating the
HJB equation and its boundary conditions that characterize the optimal contract allows us to
derive comparative statics results analytically. Here we illustrate their method on a simple example. Suppose we are interested in the effect of the volatility σ 2 on the principal’s profit K (v).
Differentiating (107) yields, for v ∈ (0, v̄),
1
∂K (v)
r
= (β (θ))2 K 00 (v) + (rv − U (c) + h (θ))
2
∂σ
2



∂K (v)
∂σ 2

0

1
+ σ 2 (β (θ))2
2



∂K (v)
∂σ 2

00
,

with the following boundary condition, obtained by differentiating the value-matching condition
(108) at v̄:
 ∂v̄
∂K
0
−10
(v̄)
=
−
K
(v̄)
+
U
(rv̄)
= 0.
∂σ 2
∂σ 2
A generalization of the Feynman-Kac formula (see De Marzo and Sannikov (2006) for the technical details) implies that the solution to this differential equation can be written as a conditional
expectation:
∂K (v) 1 θ
= E
∂σ 2
2

ˆ

τ

e

−rt 2

00

−rτ

β (θt ) K (vt ) dt + e

0


∂K
(v̄) |v0 = v < 0,
∂σ 2

where vt evolves according to (105), and where the inequality follows from the strict concavity
of the profit function K. Intuitively, the right hand side of this equation sums the profit gains
and losses along the path of vt due to an increase in σ 2 . This shows that a higher volatility

71

σ 2 reduces the principal’s profit. We can similarly evaluate the effects of all the parameters of
the model on the principal’s profit, the agent’s time-0 utility (by differentiating the optimality
condition K 0 (v0 ) = 0), or the value at retirement v̄ (by differentiating the boundary conditions
(108)).
Finally, another advantage of the continuous-time problem is that it is also more tractable
computationally. In particular, the continuous-time formulation (107) can be computed more
easily as the solution to an ordinary differential equation with a free boundary, while computing
the solution to the discrete time Bellman equation (23) is more involved.

4

Applications

In this section we discuss several applications of the theory of recursive contracts. The methods developed in the previous sections can be used to analyze questions in public economics,
corporate finance, development, international finance, and political economy. Our goal is not to
provide a comprehensive overview of those fields. Rather we want to show how several general
principles emphasized above can be used to obtain rich insights in very different areas and relate
those insights to empirical observations.

4.1

Public Finance

Individuals are subject to a variety of idiosyncratic shocks. Illness, disability, job loss, structural
changes in the economy that diminish the value of human capital, unexpected promotions and
demotions, success and failure in business ventures, all significantly affect individuals’ incomes.
It has been recognized at least since the work of Vickrey (1947) that the tax and transfer system
can provide insurance against such shocks and help individuals smooth their consumption across
different dates and states. A natural question is then how to design the optimal social insurance
system that provides the best insurance given the distortions imposed by those programs.
Diamond and Mirrlees (1978), Diamond et al. (1980) and Diamond and Mirrlees (1986)
were some of the first papers to systematically study this question. At the same time, solving
these problems either analytically or computationally is very difficult even in relatively simple
dynamic settings. The advances in the theory of recursive contracts in the late 1980s and
1990s delivered a set of tools that that allowed to overcome many of the difficulties. The New
Dynamic Public Finance literature applied those tools to the study of dynamic optimal taxation:
see, e.g., Golosov et al. (2003), Albanesi and Sleet (2006), Golosov et al. (2006), Golosov and
Tsyvinski (2006, 2007), Farhi and Werning (2013, 2012, 2007), Werning (2009), Kocherlakota
(2010), Golosov et al. (2016), Stantcheva (2014). In what follows, we decribe a model that
illustrates some of the main results of this literature.
We focus on a partial equilibrium model in which individuals are subject to idiosyncratic

72

shocks to labor productivity.38 The economy lasts T periods, where T can be finite or infinite.
Each agent’s preferences are described by a time separable utility function over consumption
ct ≥ 0 and labor supply lt ≥ 0,
" T
#
X
β t−1 U (ct , lt ) ,
(111)
E0
t=1

where β ∈ (0, 1) is a discount factor, E0 is a period-0 expectation operator, conditional on
the shock at date t = 0, and U : R2+ → R is differentiable, strictly increasing and concave in
consumption, and decreasing and concave in labor supply. The partial derivatives of the utility
function are denoted by Uc and Ul .
Agents draw their initial type (skill) θ1 from a distribution π1 (·) in period 1. From then on
skills follow a Markov process πt (θt |θt−1 ), where θt−1 is the agent’s skill realization in period
t − 1. We denote the probability density function of period-t types conditional on θt−1 by
πt (· |θt−1 ). Skills are non-negative: θt ∈ Θ ⊂ R+ for all t. At this stage we are agnostic about
the dimensionality of Θ and allow Θ to be discrete or continuous. The set of possible histories
up to period t is denoted by Θt . An agent of type θt who supplies lt units of labor produces
yt = θt lt units of output.
In this partial equilibrium economy, yt also denotes the labor income of individuals. Individuals can freely borrow and lend at an exogenous interest rate R. We assume that there is
no insurance available to individuals except self-insurance through borrowing and lending and
through taxes and transfers provided by the government. We are interested in understanding
how the government can design the optimal tax system Tt (·) as a function of the information
it has about individuals. We are thinking of the function Tt in very general terms: it is a combination of all taxes and transfers that individuals pay to or receive from the government. We
are seeking a function Tt that maximizes welfare given by (111) in a competitive equilibrium.39
If individuals’ skills are observable, the optimal tax function is very simple: Tt should depend on the realization of the shocks θt and prescribe positive or negative transfers without
distorting either labor supply or savings decisions. In reality idiosyncratic shocks are difficult to
observe. Even disability insurance programs which extensively employ medical examinations to
determine whether an applicant is subject to medical conditions that make a person unable to
work are subject to subtantial moral hazard problems and asymmetric information (see Golosov
and Tsyvinski (2006) and references therein). Therefore we make the assumption that the realizations of θt are not observed by the government and the only observable choices are labor
income, consumption and capital.
We study the optimal taxes using a two-step procedure. In the first step, we invoke the
Revelation Principle (see Section 2.2) and write the problem as a mechanism design program
38
See Albanesi (2011), Shourideh (2010), Abraham and Pavoni (2008) for applications of recursive contracting
tools to taxation with shocks to savings, Stantcheva (2014) for human capital accumulation, Hosseini et al. (2013)
for fertility choices.
39
It is straightforward to extend this analysis and allow other welfare criteria or expenditures on public goods
(see, e.g. Golosov et al. (2003)).

73

whose solution can be characterized using recursive techniques. In the second step, we back out
a tax function Tt that can implement that solution in a competitive equilibrium.
The mechanism design problem is as follows. Let reports be given by σt : Θt → Θ and
allocations by ct : Θt → R+ , yt : Θt → R+ , for all t ≥ 1. The incentive constraint (8) writes
"
E0
≥E0

T
X

t=1
" T
X

β

t−1

U

β t−1 U

t=1

 yt θt
ct θ ,
θt

 !#

t

 yt σ t θt
ct σ t θt ,
θt

(112)

 !#
, ∀σ T ∈ ΣT ,

and the feasibility constraint (2) becomes
"
E0

T
X

#
R

1−t

ct θ

t



"
≤ E0

t=1

T
X

#
R

1−t

yt θ

t



.

(113)

t=1

The planner maximizes the ex-ante expected utility (111) of the agents, i.e., provides optimal
ex-ante insurance. This problem is thus similar to that analyzed in Section 2, see equations
(9) or (61). Solving this problem directly is difficult. There are prohibitively many incentive
constraints (112) either for analytical or numerical analysis in most applications. In the next
sections we overcome this problem using recursive techniques. For concreteness, we assume
separable isoelastic preferences
U (c, l) =

l1+ε
c1−σ − 1
−
.
1−σ
1+ε

(114)

While these preferences are not needed for most of the insights, they simplify the exposition of
the main results.
4.1.1

Analysis with i.i.d. shocks

We start the analysis by assuming that shocks are independent and identically distributed over
time, so that the probability of realization of any θ ∈ Θ in any period can be written as π (θ).
This assumption, although unrealistic, allows us to illustrate many insights very transparently.
We follow the steps familiar from the analysis in Sections 2.3 and 2.4. To ensure convexity, we
rewrite our maximization problem in terms of utils of consumption and leisure rather than c and
l. To this end we define the functions C (u) = [1 + (1 − σ) u]1/(1−σ) and Y (h) = [(1 + ε) h]1/(1+ε) .
We apply the one-shot deviation result from Propositions 2 and 3 to write the incentive compatibility and promise keeping constraints as:









−(1+ε)
−(1+ε)
h θt−1 , θ̂ + βvt θt−1 , θ̂
ut θt − θt
h θt + βvt θt ≥ ut θt−1 , θ̂ − θt

74

for all θt−1 ∈ Θt−1 , θ̂ ∈ Θ, with
ˆ h



i
t−1
vt−1 θ
=
ut θt−1 , θ − θ−(1+ε) h θt−1 , θ + βvt θt−1 , θ dπ (θ) .
Θ

Following the same steps as in Section 2.3 we write the Bellman equation as
ˆ
Kt (v) =



min

{u(θ),h(θ),w(θ)}θ∈Θ


C (u (θ)) − Y (h (θ)) + R−1 Kt+1 (w (θ)) dπ (θ)

(115)

Θ

subject to the incentive constraints: for all θ, θ̂ ∈ Θ,
 
 
 
u (θ) − θ−(1+ε) h (θ) + βw (θ) ≥ u θ̂ − θ−(1+ε) h θ̂ + βw θ̂ ,
the promise-keeeping constraint:
ˆ h
i
v=
u (θ) − θ−(1+ε) h (θ) + βw (θ) dπ (θ) ,
Θ

and KT +1 (w) = 0 for all w if T is finite. When T is infinite, the subcript t drops out of the
Bellman equation above.
Many of the qualitative properties of this model can be obtained along the lines of Proposition
5. For example, using steps analogous to those of Section 2.4, it is easy to show the analogue of
equations (29) and (63):40


 0

Kt0 (v) = E C 0 (uv,t ) = (βR)−1 E Kt+1
(wv,t ) |v .

(116)

Moreover, optimality also requires: for all θ, t, v,
0
C 0 (uv,t (θ)) = (βR)−1 Kt+1
(wv,t (θ)) .

(117)

The intution for this result is simple. The planner can provide incentives to reveal information
either intratemporally, by giving an agent higher contemporaneous utility, or intertemporally,
by giving higher future promises. Condition (117) implies that it is optimal to equalize the
marginal costs of the two ways of providing incentives.
These conditions have some immediate but unexpected implications for taxation. Note that
0
C = U1c , where Uc is the marginal utility of consumption, and hence (116) can be re-written as


βR
1
v , ∀v, t, θ.
=E
Uc (cv,t (θ))
Uc (cv,t+1 )
40

This condition is particularly easy to derive if Θ is finite, in which case it can be obtained by simple
manipulation of the Lagrangians on the incentive constraints.

75

The policy functions generate the constrained-optimal stochastic processes {c∗t , yt∗ }Tt=1 that satisfy the Inverse Euler equation (see our discussion in Section 2.6 as well as Golosov et al. (2003)):
#
"
βR
1
 .
= Et
Uc (c∗t )
Uc c∗t+1

(118)

 
1
By Jensen’s inequality, we have E X1 ≥ E[X]
for any random variable X, with strict inequality
if X is non-deterministic. Therefore this equation implies that at the optimum,


Uc (c∗t ) ≤ βREt Uc c∗t+1 ,
with strict inequality if future consumption is uncertain. Therefore, it follows that the optimal
tax system must introduce positive savings distortions in this economy. One useful way to
summarize the distortions introduced by the tax system is to define the savings wedge as
1−

τts

θ

t



 

Uc c∗t θt , yt∗ θt /θt
1

 .
≡
∗ (θ t+1 ) /θ
βR Et Uc c∗t+1 (θt+1 ) , yt+1
t+1

(119)


Optimality implies that τts θt ≥ 0 for all θt , with strict equality if consumption in t + 1 is
uncertain.
Decentralization We now describe how the government can design a tax system Tt such that
agents optimally choose consumption and income {c∗t , yt∗ }Tt=1 given a budget constraint
ct + kt+1 ≤ yt + Rkt − Tt .
That is, this tax function Tt is an implementation or decentralization of the constrained optimum.
We want to understand what arguments Tt (·) should depend on and how to construct it.
In general, there are many tax systems that implement the same allocation.41 Here we
consider a particularly simple implementation that arises naturally from the recursive problem.
Observe that to find the optimal allocations in period t in the Bellman equation (115), we did
not need to know the whole past history θt . It was sufficient to know the summary statistics

vt−1 θt−1 together with the current period shock θt . A natural analogue of the promised utility
in competitive equilibium is the agent’s savings. Albanesi and Sleet (2006) use this insight to
show that when types are i.i.d. and the utility function is separable between consumption and
labor supply we can construct an optimal tax system in which taxes in period t depend only on
labor income yt and on savings kt at the beginning of that period.
Proposition 14. Assume that shocks are i.i.d. and preferences are separable in consumption




For example, an extreme tax system Tt {ys }ts=1 defined as Tt {ys }ts=1 = yt∗ θt −c∗t θt if ys = ys∗ (θs ) for

t
all θs ≤ θt and Tt {ys }s=1 = ∞ otherwise, ensures that the only feasible choices for a consumer are {c∗t , yt∗ }Tt=1 .

Then the incentive compatibility constraint ensures that Tt {ys }ts=1 implements {c∗t , yt∗ }Tt=1 .
41

76

and labor. The optimal allocations can be implemented by a tax system Tt (kt , yt ).
Proof. We show this result in a two-period economy. Let K2 (w2 ) denote planner’s minimized
cost function (115) in period 2, and u∗w2 (θ) , h∗w2 (θ) denote the policy functions that solve the
second-period planner’s problem.
In period 2, consider an individual who enters the period with savings k2 and chooses labor

income y2 . Suppose that k2 = K2 (w2 ) for some promised utility w2 , and y2 = Y h∗w2 (θ) for
 
some θ ∈ Θ = θ, θ̄ . We then define the tax function T2 (k2 , y2 ) as42



T2 K2 (w2 ) , Y h∗w2 (θ) = K2 (w2 ) + Y h∗w2 (θ) − C u∗w2 (θ) .
By incentive compatibility, an agent with savings k2 = K2 (w2 ) and type θ in period 2 chooses


labor supply and consumption (y2 , c2 ) = Y h∗w2 (θ) , C u∗w2 (θ) , that is, the levels optimally
assigned to his promised utility-type pair (w2 , θ).
In period 1, consider an individual who enters the period with savings k1 and chooses labor in
come y10 (which may or may not be optimal given his first-period type θ). Denote by c01 , R−1 k20
his optimal consumption-savings choice given (k1 , y10 ), and by ũ0 = U (c01 )+βE [V2 (k20 , θ2 )] (where
V2 is the maximized objective of the agent in period 2) the utility that he achieves with this
combination, gross of the disutility of labor. The key is that the cost-minimizing way for the

planner to deliver utility ũ0 to the agent is to offer the pair (u01 , w20 ) = U (c01 ) , K2−1 (k20 ) , and
the corresponding cost is Cũ0 = c01 + R−1 k20 .
 
Now suppose that y10 = y1∗ (k1 , θ0 ) for some θ0 ∈ Θ = θ, θ̄ , where y1∗ (k1 , θ0 ) denotes the firstperiod income optimally allocated to type θ0 in the solution to the planner’s problem. Define
the tax function T1 (k1 , y10 ) as
T1 k1 , y1∗ k1 , θ0




= k1 + y1∗ k1 , θ0 − Cũ0 .

If the individual’s true type is θ 6= θ0 , by lying he reaches utility ũ0 −θ−(1+ε) h (y1∗ (k1 , θ0 )). But by
incentive compatibility this is smaller than the utility he gets by reporting his true type, namely
ũ − θ−(1+ε) h (y1∗ (k1 , θ)). Thus under this tax function the agent finds it optimal to choose the
income that corresponds to his true type in period 1, and his choice of savings will be exactly
equal to k2 = K2 (w2 (θ)), since his net income is Cũ .
This proposition shows simultaneously that optimal allocations can be implemented by a
joint tax on current period savings and labor income, and provides a method of constructing
this tax.
When thinking about the relationship between this tax Tt and taxes in the data, it is important to keep in mind that Tt in the model corresponds to the sum of all taxes and transfers
∂Tt
t
in the data. The marginal distortions with respect to capital and labor income, ∂T
∂kt and ∂yt ,
42


The tax function can be easily extended to deter any move y2 > Y (h∗w2 (θ)) and y < Y h∗w2 θ̄ .

77

correspond to the effective marginal tax rates in the data, which are a sum of statutory tax
rates and the rates of phasing out of transfers in capital and labor income respectively. Because
of the phasing out of transfers, there is no reason to expect a priori that marginal taxes in the
model and effective marginal taxes in the data are progressive.43 For example, if individuals
with more wealth receive less insurance against labor income shocks (e.g., if they are not eligible
to some welfare programs because of means-testing), we should expect the marginal labor taxes
to be decreasing in capital.
4.1.2

Persistent shocks

An important limitation of the previous discussion is the assumption that shocks are i.i.d. The
empirical labor literature has emphasized that idiosyncratic shocks are highly persistent (for
example, Storesletten et al. (2004) or Guvenen et al. (2015)). In this section we discuss how to
extend our analysis to persistent (Markov) shocks.
It is useful to assume, both for analytical tractability and for connecting the analysis to the
empirical literature, that shocks are drawn from a continuous distribution. We focus on a family
of stochastic processes frequently used in the applied labor and public finance literatures.44
Assumption 6. Suppose that shocks θt evolve according to
ln θt = bt + ρ ln θt−1 + ηt ,
where ηt is drawn from one of the following three distributions:
(a) lognormal: ηt ∼ N (0, ν) ;
(b) Pareto-lognormal: ηt ∼ N E (µ, ν, a), where N E is a normal-exponential distribution;
(c) mixture of lognormals: ηt ∼ N (µi , νi ) with probability pi for i = 1, ..., I. Let ν = maxi νi .
We can write the planner’s problem recursively by applying the first-order approach discussed
in Section 2.5. Under these assumptions the Bellman equation writes:
ˆ
Kt (v, v̂, θ− ) =

max

~)
~ ŵ
(~u,~h,w,

∞


Y (h (θ)) − C (u (θ)) + R−1 Kt+1 (w (θ) , ŵ(θ), θ) πt (θ |θ− ) dθ

0

(120)

43

In the U.S. there is significant heterogeneity in the shapes of the effective tax rates as a function of income
as they vary by state, family status, age, type of residence a person lives in, etc. Some typical patterns of the
effective marginal rates in the U.S. data are increasing, U-shaped, and inverted S-shaped (see CBO (2007) and
Maag et al. (2012)).
44
For example, Storesletten et al. (2004) and Farhi and Werning (2013) use lognormal distributions, Badel and
Huggett (2014) and Lockwood et al. (2014) use Pareto-lognormal distributions, Geweke and Keane (2000) and
Guvenen et al. (2015) use mixtures of lognormals.

78

subject to the promise-keeping and marginal promise-keeping constraints
ˆ

∞

v =

$(θ)πt (θ |θ− ) dθ,

(121)

$(θ)π̂t (θ |θ− ) dθ,

(122)

ˆ0 ∞
v̂ =
0

$ (θ) = u (θ) − θ−(1+ε) h (θ) + βw (θ) ,

(123)

$̇ (θ) = (1 + ε) θ−(2+ε) h (θ) + β ŵ (θ) .

(124)

and the envelope condition

This problem can then be analyzed using optimal control techniques (see Golosov et al. (2016)).
The analysis of savings distortions remains unchanged. In particular, the Inverse Euler
Equation (118) continues to hold in this economy. The same arguments as in the previous
section immediately imply the optimality of savings distortions.
We now turn to the analysis of labor distortions. We define the labor wedge as
1−

τty

θ

t




 
−Ul c∗t θt , yt∗ θt /θt
≡
.
θt Uc (c∗t (θt ) , yt∗ (θt ) /θt )

(125)


To simplify the notations, for any history θt = θt−1 , θ and random variable xt , we use the


short-hand notations xt (θ) to denote xt θt−1 , θ and xt−1 to denote xt−1 θt−1 . Manipulating
the first-order conditions we obtain
τty (θ)
= (1 + ε)
1 − τty (θ)
+ ρβR

´∞
θ

1

πt (x0 ) dx0
θπt (θ)

y
τt−1
y
− τt−1

ˆ
θ

∞

Uc,t (θ)
Uc,t (x)

ˆ


1−

0

∞

 0
Uc,t (x)
0
π
x
dx
t
Uc,t (x0 )



π (x) dx
´∞t
0
0
θ πt (x ) dx

Uc,t (θ)
.
Uc,t−1

(126)
Equation (126) shows that the optimal labor distortion is the sum of two terms. The first
(“intratemporal”) term on the right hand side captures the costs and benefits of labor distortions
in providing insurance against period-t shocks. A labor distortion for type θ discourages that
type’s labor supply, as captured by the Frisch elasticity of labor supply ε. This lowers total
output in proportion to θπt (θ) but allows the planner to relax the incentive constraints for all
types above θ, a trade-off
by the hazard ratio (of period-t shocks conditional on
´ ∞ summarized
0
0
t−1
θ πt (x )dx
. Finally, the relaxed incentive constraints allow the planner
a given history θ ),
θπt (θ)
to extract more resources from individuals with skills above θ and transfer them to all agents.
The social value of this transfer is captured by the integral term on the r.h.s., which depends
on the marginal utilities of consumption of agents with skills above θ, weighted by the average
marginal utility. The second term (“intertemporal”) on the right hand side captures how the

79

planner uses distortions in the current period t to provide incentives for information revelation
in earlier periods. It depends on the information that the period-t shock carries about θt−1 ,
U (θ)
summarized by the coefficient ρ, and on the ratio Uc,t
which captures the fact that it is
c,t−1
cheaper to provide incentives in those states in which the marginal utility of consumption is
high.
We can also use the decomposition (126) to obtain insights about the time series properties
of the optimal labor distortions, as studied by Farhi and Werning (2013). Multiplying the
expression above by U1c,t πt (θ) and integrating by parts yields

Et−1




y
τt−1
τty
1
1
1
= ρβR
+ (1 + ε) Covt−1 ln θ,
.
y
Uc,t−1
Uc,t
1 − τty Uc,t
1 − τt−1

(127)

Equation (127) shows that the marginal utility-adjusted labor distortions follow an AR(1)
process with a drift. The persistence of that process is determined by the persistence of
the shock
 ρ, and its drift is strictly positive since we should generally expect that
 process
1
Covt−1 ln θ, Uc,t > 0. Farhi and Werning (2013) conclude that the optimal labor distortions
should increase with age.
Golosov et al. (2016) use condition (126) to characterize the dependence of labor wedges on
the realization of the shock θ. In particular they show the asymptotic laws of motion45

−1
σ
a

−
,
(θ)
1+ε
σ+ε

−1
∼
y
1 − τt (θ) θ→∞  ln θ 1
,
τty

ν2

and

1+ε

if ηt is Pareto-lognormal,

a
1+ε

−

σ
σ+ε

>0
(128)

if ηt is lognormal or a mixture,

y
τt−1
τty (θ)
∼ ρβR
y
1 − τty (θ) θ→0
1 − τt−1



ct (0)
ct−1

−σ
.

(129)

Given the fact that (ln θ)−1 is very slowly moving, equation (128) implies that the labor distortions are approximately flat for high realizations of θt for all three classes of distributions
(although in the cases of lognormal and mixture of lognormal distributions they eventually
converge to zero), they do not depend on the past history of shocks, and they are given by
relatively simple closed-form expressions. Equation (129) shows that the labor distortions for
low shocks depend on the persistence, the past history, and the growth rate of consumption,
and are generally increasing in age.
Another implication of these equations is that the higher moments, such as the kurtosis,
play an important qualitative and quantitative role for the size of the labor distortions. Some of
the best estimates of those moments are obtained by Guvenen et al. (2014) and Guvenen et al.
(2015) who use U.S. administrative data on a random sample of 10% of the U.S. male taxpayers
to estimate the stochastic process for labor earnings. Golosov et al. (2016) use that finding to
45

For any functions h, g and c ∈ R̄, h(x) ∼ g(x) if limx→c h (x) /g(x) = 1.
x→c

80

calibrate their model using newly available estimates of idiosyncratic shocks. The optimal labor
distortions are U-shaped while savings distortions are increasing in current earnings. Welfare
in the constrained optimum is 2 to 4 percent higher than in the equilibrium with affine taxes.
These findings (both the U-shape and the relatively high welfare gains from non-linear, historydependent taxation) are largely driven by the high kurtosis found in the labor earnings process
in the data. This suggests that a system of progressive taxes and history-dependent transfers
that are being phased out relatively quickly with income can capture most of the welfare gains
in this economy.

4.2

Corporate Finance

In this section we describe some applications of the recursive contract theory to corporate
finance. We show how financing frictions arise endogenously from agency problems, leading
to implications for firms’ capital structure and dynamics. To cite only a few papers in this
literature, such models have been analyzed by Albuquerque and Hopenhayn (2004), Clementi
and Hopenhayn (2006), DeMarzo and Fishman (2007a,b) in discrete-time environments, and by
De Marzo and Sannikov (2006), Biais et al. (2007), DeMarzo et al. (2012), Biais et al. (2010),
He (2009) in continuous-time environments.
Endogenous financing frictions and firm dynamics. A large empirical literature (see,
e.g., Caves (1998) for a survey) describes the properties of firm dynamics, e.g., the characteristics
and evolution of their size, growth rates, and survival probabilities. In particular, as firms get
older, their size and survival probability increase, the mean and variance of their growth rates
decrease, and the hazard rates for exit first increase and then decrease. Moreover, starting with
the work of Fazzari et al. (1988), many authors have found that firms’ investment responds
positively to innovations in the cash-flow process (after controlling for Tobin’s q), suggesting the
importance of borrowing constraints, and that the investment-cash flow sensitivity decreases
with the firm’s age and size. Clementi and Hopenhayn (2006) analyze a dynamic moral hazard
model where such features arise endogenously in the optimal contract between a borrower (a
firm, or agent) and a lender (bank, or principal) who cannot observe the outcome of the project.
They describe the optimal contract and show that the model yields rich testable predictions
about firm dynamics that are in line with the evidence presented above.
Their model is as follows. The borrower and the lender are both risk-neutral, have the same
discount factor β, and have the ability to commit to contracts. The agent’s project requires a
fixed initial investment I0 > 0 and a per-period investment of capital, denoted kt . Revenues are
stochastic (i.i.d.) and increase with the amount of capital advanced by the bank. Specifically,
in each period t, with probability π the project is successful and yields revenue R (kt ), where R
is continuous, bounded and concave, whereas with probability (1 − π) it yields zero revenues.

Denote the outcome of the project in period t by θt ∈ Θ = θ(1) , θ(2) = {0, 1}, where θ(1) = 0 is

81

failure and θ(2) = 1 is success, and histories up to period t by θt . The project can be liquidated
at the beginning of each period, with scrap value S ≥ 0.
Suppose first that revenues are observable. The efficient amount of capital is advanced
in every period, k ∗ = arg max (πR (kt ) − kt ), and running the project is efficient if W ∗ ≡
1
∗
∗
∗
1−β (πR (k ) − k ) > I0 . Assume that W > S. Thus, in the benchmark complete-information
version of the model, the firm neither grows, shrinks, or exits: its size k ∗ is constant. This
feature allows us to cleanly analyze the implications of informational frictions for the firm’s
dynamics.
Now suppose that revenues are private information to the borrower. Thus, in each period
the borrower observes the outcome of the project and sends a report to the lender according to


a strategy σ = σt θt t≥1 . The timing of events is as follows. At the beginning of each period
t, the bank decides whether (and if so, with which probability) to liquidate the firm, in which
case it gets the scrap value S and compensates the agent with a transfer Qt ≥ 0. Denote by




α = αt σ t θt
the liquidation probabilities and by Q = Qt σ t θt
the transfers
t≥1
t≥1
from the lender to the borrower in case of liquidation. Then, if the firm is not liquidated, the
bank chooses the amount of capital kt it lends to the firm, and the borrower’s repayment τt if


the project is successful. Denote by k = kt σ t−1 θt−1
the capital advancements and
t≥1



t−1
t−1
by τ = τt σ
θ
, σt (θt ) t≥1 the contingent payments from the borrower to the lender
in case of success (there is no transfer in case of failure). The firm is restricted at all times to
have a nonnegative cash flow, i.e., the following limited-liability constraint must be satisfied:



τt σ t−1 θt−1 , θ(2) ≤ R kt σ t−1 θt−1
for all t, θt−1 . The outcome θt of the project is

then realized and privately observed by the borrower, who sends a report σt θt and transfers

τt σ t θt to the bank in case of a (truthfully reported) success.
We define “equity” as the entrepreneur’s share of the total firm’s value, and “debt” as the

lender’s share. That is, equity (denoted by Vt {k, τ , α, Q, σ} , σ t−1 θt−1 ) and debt (denoted

by Bt {k, τ , α, Q, σ} , σ t−1 θt−1 ) are the expected discounted cash flows (or continuation
values) accruing to the borrower and the lender, respectively, under the contract {k, τ , α, Q, σ}

and reporting strategy σ, given the history of reports σ t−1 θt−1 . In particular, the value of
equity corresponds to the promised utility variable (11) in the taste shock model of Section 2.
This setup is formally similar to that in Section 2.3 and can be analyzed using the same
recursive techniques. Specifically, we write the problem in recursive form using the value of
equity v as the state variable. We can show that the set of continuation values v that can
be supported by a feasible contract (see footnote 7) is [0, ∞). A constrained-efficient contract
maximizes the value obtained by the lender, B (v0 ), in the space of incentive-compatible and
feasible contracts, subject to delivering some utility v0 ≥ 0 to the entrepreneur. The pair
(v0 , B (v0 )) defines the capital structure of the firm (equity and debt) and implies a total value
for the firm W (v0 ) = v0 + B (v0 ).
Denote by W (·) the value of the firm prior to the liquidation decision, and by Ŵ (·) the
value of the firm conditional on not being liquidated. Following the steps of Proposition 3, we

82

obtain that the latter is given by the following Bellman equation:
Ŵ (v̂) =

max

{k,τ,w}≥0
~




(πR(k) − k) + β (1 − π) W w θ(1) + πW w θ(2)

subject to the promise-keeping constraint:



v̂ = π (R (k) − τ ) + β (1 − π) w θ(1) + πw θ(2) ,

(130)

the incentive compatibility constraint in the high state:


R (k) − τ + βw θ(2) ≥ R (k) + βw θ(1) ,

(131)

and the limited liability constraint
τ ≤ R (k) .

(132)

The liquidation decision of the firm can be formalized as follows. At the beginning of the period,
the firm is liquidated with probability α, and the borrower receives Q, and it is kept in operation
with probability 1 − α, in which case the borrower receives the continuation value v̂. The value
function W (·) then solves the following Bellman equation:
W (v) =

αS + (1 − α) Ŵ (v̂)

max
α∈[0,1],{Q,v̂}≥0

subject to
v = αQ + (1 − α) v̂.
Clementi and Hopenhayn (2006) show that the solution to this problem is as follows. If the
equity v is large enough, then the policy of providing the unconstrained efficient level of capital
k ∗ in every period is both feasible and incentive compatible. The minimum value v ∗ for which
this is the case is given by the solution to the problem:
v∗ ≡

min
τ,{w(θ)}θ∈Θ




(πR(k ∗ ) − τ ) + β (1 − π) w θ(1) + πw θ(2)



subject to R (k ∗ ) − τ + βw θ(2) ≥ R (k ∗ ) + βw θ(1) ,


τ ≤ R (k ∗ ) , w θ(1) ≥ v ∗ , w θ(2) ≥ v ∗ .
1
We get v ∗ ≡ 1−β
πR (k ∗ ). Next, we can show that there exists a value v∗ ∈ (0, v ∗ ) such that:
(i ) when v ≥ v ∗ , the firm’s value W (v) is equal to W ∗ . Letting kv = k ∗ at any future date,

with τv = 0 and wv θ(j) = v ∗ for all j ∈ {1, 2}, is optimal.
(ii ) when v ∈ [v∗ , v ∗ ), the policy function is as follows: α (v) = 0, kv < k ∗ , τv = R (kv ),




and wv θ(1) < v < wv θ(2) . The values wv θ(1) , wv θ(2) are given as a function of kv by
the promise-keeping and incentive compatibility constraints (130), (131), which both hold with

83

equality.46 Moreover, kv is increasing in v for v close enough to v ∗ , kv is decreasing in v for v


close enough to v∗ , wv θ(1) , wv θ(2) are increasing in v, and equity is a submartingale, i.e.
v < E [wv ]. The value function W (v) is strictly increasing and concave.
(iii ) when v < v∗ , the firm is liquidated with positive probability α (v) = 1 − v/v∗ and
transfer Q = 0, and continues at value v̂ = v∗ with probability (1 − α (v)). The firm’s value is
equal to W (v) = α (v) S + (1 − α (v)) Ŵ (v∗ ).
This characterization of the optimal contract has the following interpretation and implications. The contract determines stochastic processes for the firm size kt , equity vt , and debt
B (vt ) = W (vt ) − vt . Specifically, consider an entrepreneur who starts with equity v0 ∈ (v∗ , v ∗ ).

Starting from this region, a good shock raises the value of equity to wv θ(2) > v, and a bad
shock reduces it. The submartingale property (which follows from equation (130)) implies that
the equity vt of surviving firms on average increases over time, and the monotonicity of the
functions wv (θ) implies the this process vt displays persistence. Eventually, equity reaches either the lower threshold v∗ (after a series of negative shocks), leading to the region where it is
optimal to liquidate the firm with positive probability, or the upper threshold v ∗ (after a series
of positive shocks), at which the incentive constraints no longer bind and the unconstrained
efficient level of capital k ∗ is advanced from then on. There are therefore two absorbing states:
either the firm is liquidated, or it attains its efficient size. In the transition, the transfer τv in
the event of a good shock is set equal to the maximum possible amount R (kv ). This is because
the bank and the firm are both risk-neutral, so that it is optimal to backload the distribution
of dividends to the borrower (by choosing the highest possible value of transfers τ and raising

wv θ(j) accordingly) in order to allow the equity to reach v ∗ as fast as possible. Finally, when
k∗
, and the lender’s continuation
v ∗ is attained, the firm’s future cash flows are v ∗ = W (v ∗ ) + 1−β
k∗
∗
value is B (v ) = − 1−β . This means that the entrepreneur has accumulated assets at the bank
1
(at the interest rate r such that β = 1+r
) up to the positive balance k ∗ / (1 − β) while his payments were being postponed and all the cash flows were received by the lender; this balance is
exactly enough to finance the project at the efficient scale from then on.
Next, the optimal contract shows that when equity is below the threshold, the amount of
capital advanced by the bank is strictly smaller than the unconstrained efficient level: kv < k ∗ .
We can interpret this result as an (endogenous) borrowing constraint to which the entrepreneur
is subject. Moreover, if v is close enough to v ∗ , higher equity relaxes the borrowing constraint
and allows the entrepreneur to finance the project on a more efficient scale, as kv is increasing in
v.47 Such financing frictions arise endogenously in the optimal contract due to moral hazard. To
provide incentives for the successful entrepreneur to truthfully report the (good) outcome of his
project, the optimal contract requires the borrower’s compensation to be sensitive to reported


If these values are such that wv θ(2) > v ∗ , then other values for the transfer τv (along with wv θ(2) ) are
also optimal.
47
The authors also run numerical simulations and find that for all v, kwv (θ ) < kv and kwv (θ ) > kv , so that
(1)
(2)
the amount of capital advanced by the lender increases after a success, and decreases after a decline.
46

84



output, which necessitates a spread wv θ(2) − wv θ(1) between the future equity values in
the successful vs. unsuccessful states. Moreover, advancing more capital today tightens the
incentive constraint (as the borrower will have to repay more in case of success, since τ = R (k))
and thus requires a larger spread between future continuation values. But this spread is costly,
because the marginal revenue is decreasing in capital and hence the firm’s total value W (·) is
concave. Therefore, the trade-off between higher capital and profits today against a lower firm’s
value in future periods implies an inefficient level of financing kv < k ∗ in the optimal contract.
These results imply that revenue shocks affect the financial structure (v, B (v)) of the firm,
and yield rich implications for firm dynamics (size, growth and survival probability). Defining
the firm’s size as the level of capital kt invested in the project, and investment as kt − kt−1 ,
and simulating a calibrated version of the model, the authors obtain the following testable
predictions. First, firm age and size are positively correlated. Second, the mean and variance
of growth decrease with size and age. Third, the survival probability P (T > t |v ), where T is
the stopping time for exit, increases with the value of equity v and thus with age. The hazard
rates for exit follow an inverted U-shaped function of age, as it takes a few periods for young
firms to reach the liquidation region from their initial value v0 , and a selection effect implies
that older (surviving) firms have on average higher values and hence lower hazard rates. All
these properties are consistent with the empirical evidence on firm dynamics (see the references
in Clementi and Hopenhayn (2006) for a survey of the empirical literature). Finally, the authors
argue that simulated data generated using the policy functions of the model would reproduce the
empirical prediction that investment responds positively to innovations in the cash-flow process,
and that the sensitivity of investment to cash-flows decreases with the age and size of the firm.
Importantly, in the model, the financing frictions (borrowing constraints) arise endogenously as
a feature of the optimal contract.
Optimal capital structure. We now describe another application of recursive contracts to
corporate finance in a continuous-time framework using the techniques described in Section
3.3.2, following a simple version of De Marzo and Sannikov (2006).48 In their model the agent
(firm) can unobservably divert cash flows for its private benefit; investors control its wage and
choose when to liquidate the project. While Clementi and Hopenhayn (2006) focused on the
importance of informational frictions for firm investment and growth as a function of the the
history of profit realizations (so that the scale, i.e. the capital, of the firm is an endogenous part of
the optimal incentive contract), the closely related framework of De Marzo and Sannikov (2006)
assume instead that the firm has a fixed size and are concerned with the optimal choice of the
firm’s capital structure.49 Specifically, they propose an implementation of the optimal contract
using simple financial instruments. This implementation is composed of a combination of long
term debt with a constant coupon, a credit line, and equity. In this implementation the firm is
48
49

A discrete time version of this problem has been analyzed by DeMarzo and Fishman (2007b).
DeMarzo et al. (2012) extend this model to include investment and non-constant firm size.

85

compensated by holding a fraction of the equity, and defaults if debt service payments are not
made or the credit line is overdrawn; dividends are paid when cash flows exceed debt payments
and the credit line is paid off. This analysis can therefore help understand the choice between
various forms of borrowing for firms, in particular the characteristics of credit line contracts, an
empirically important component of firm financing. Finally, as we saw in Section 3.3.2, setting
the model in continuous time allows the authors to obtain both a clean characterization of the
optimal contract through an ordinary differential equation, as well as analytical comparative
statics of the optimal contract with respect to the parameters of the model.
We now turn to a formal description of the model. An agent manages a project that generates
stochastic cash flows given by:
dŷt = (µ − θt ) dt + σdZt ,
where Zt is a standard Brownian motion, and θt ≥ 0 is the agent’s private action, which can be
interpreted as cash flow diversion. This unobserved diversion generates private benefit to the
agent at rate λθt , with λ ∈ (0, 1]. The principal observes only the reported cash flows {ŷt }t≥0 .50
The principal and the agent are risk-neutral and discount the future at rate r and γ respectively,
with γ > r. The project requires external capital of I0 ≥ 0 to be started. The principal offers a
contract (c, τ ) that specifies the agent’s compensation dct ≥ 0 for all t and a termination date
τ , as functions of the histories {ŷs }s≤t . In the event of termination, the agent gets his outside
option R ≥ 0 and the principal receives the liquidation payoff L ≥ 0.
The optimal contract maximizes the principal’s expected profit subject to delivering expected
utility v̂0 to the agent and the incentive compatibility constraints. We can show that in the
optimal contract we have θt = 0 for all t ≥ 0. The problem is similar to that analyzed in Section
3.3.2 and can be expressed as:
ˆ

max Eθ=0
c,τ

τ

e−rt (dŷt − dct ) + e−rτ L



0

subject to the promise-keeping constraint:
θ=0

ˆ

τ

v̂0 = E

−γt

e

dct + e

−γτ


R

0

and the incentive compatibility constraints:
θ̂

ˆ

v̂0 ≥ E

τ

e

−γt





dct + λθ̂t dt + e

−γτ


R ,

0

for any deviation strategy θ̂.
Following identical steps as in Section 3.3.2 (see in particular Proposition 11), we find that
50

De Marzo and Sannikov (2006) consider a more general model in which the agent can secretely save and thus
over-report, i.e. θt < 0, but show that in the optimal contract the agent always chooses to maintain zero savings.

86

there is a one-to-one correspondence between incentive-compatible contracts (c, τ ) and controlled
processes (with controls (ct , βt ))
dvt = γvt dt − dct + βt (dŷt − µdt) ,

(133)

where the sensitivity of the agent’s promised value to his report satisfies βt ≥ λ for all t ≤ τ .
The termination time τ is the earliest time that the agent’s promised value vt reaches R. The
one-shot incentive constraint (Proposition 12) here says that truth-telling is incentive compatible
if and only if βt ≥ λ for all t, since the agent has incentives not to steal cash flows if he gets at
least λ of promised value for each reported dollar.
De Marzo and Sannikov (2006) characterize the optimal contract as follows. Denote by K (v)
the principal’s value function. It is easy to see that the optimal contract must satisfy K 0 (v) ≥ −1
for all v. This is because the principal can always give to the agent with current promised utility
v a lump-sum transfer dc > 0 and then revert to the optimal contract with utility v − dc, so that
K (v) ≥ K (v − dc) − dc. Defining v̄ as the lowest value such that K 0 (v̄) = −1, it is optimal to
keep the agent’s promised utility in the range [R, v̄] and to set dct = (v − v̄) I{v≥v̄} . The function
K (v) can then be characterized recursively as in Section 3.3.2. The Hamilton-Jacobi-Bellman
equation is
1
rK (v) = max µ + γvK 0 (v) + β 2 σ 2 K 00 (v) ,
β≥λ
2
with K (v) =K (v̄) − (v − v̄) for v > v̄,
with the following value-matching, smooth-pasting, and super-contact conditions
K (R) = L, K 0 (v̄) = −1, K 00 (v̄) = 0.
The function K (·) is concave so that it is optimal to set βt = λ for all t. The optimal contract
(with v̂0 ∈ [R, v̄]) is such that vt evolves according to (133) with dct = 0 when vt ∈ [R, v̄). If
vt = v̄, payments dct cause vt to reflect at v̄. The contract is terminated at time τ when vt
reaches R.51
De Marzo and Sannikov (2006) propose an implementation of the optimal contract using
equity, long-term debt D, and a credit line C L . If the agent defaults on a debt coupon payment
or his credit balance exceeds C L , the project is terminated. The idea behind this implementation
is to map the interval of continuation values [R, v̄] into a credit line, with point v̄ corresponding
to balance 0. From (133), we can write the evolution of the credit balance λ−1 (v̄ − vt ) (where

51

In the discrete-time setting described the previous section (based on the work of Clementi and Hopenhayn (2006)), allowing for randomization over the decision to terminate the project could improve the contract.
De Marzo and Sannikov (2006) show that in the continuous-time framework, such randomization is not necessary:
without loss of generality the termination time τ is based only on the firm’s (reported) past performance.

87

λ is simply a normalization) as

d

v̄ − vt
λ



 



γ 
dct
v̄ − vt
= −dŷt + γ
dt + µ − v̄ dt +
.
λ
λ
λ

The first term in the right hand side of this expression, −dŷt , is the credit balance reduction
due to the cash flows, where each dollar of cash flow substracts exactly one dollar from the
credit line balance. The next three terms in the right hand side (inside the brackets) are the
three components that compose the implementation of the contract. The first term inside the
brackets is the interest charged on the credit balance λ−1 (v̄ − vt ), so that the implementation
of the optimal contract has a credit line C L = λ−1 (v̄ − R), up to which credit is available to
the firm at interest rate γ. The second term inside the brackets is the coupon rD on long-term
debt, so that the face value of the debt is D = r−1 (µ − γv̄/λ). Finally the third term inside the
brackets consists of the dividend payments made by the firm, i.e. the equity. The agent gets
a fraction λ of the dividends dct , while outside investors hold the remaining firm’s equity, debt
and credit line. Cash flows in excess of the debt coupon payments are issued as dividends once
the credit line is fully repaid. Termination occurs when the credit line balance reaches the credit
limit C L . Observe that the balance on the credit line fluctuates with the past performance of
the firm, in particular leverage decreases with its profitability since the firm pays off the credit
line when it makes profits.
De Marzo and Sannikov (2006) further analyze this optimal capital structure, i.e. how the
amount of long-term debt and the size of the credit line depend on the parameters of the model,
by deriving analytical comparative statics using the techniques described in Section 3.3.2. We
refer the reader to the original paper for an in-depth analysis of these questions.

4.3

Development Economics

There is a large literature that studies informal insurance arrangements in the context of village economies. An early work of Townsend (1994), for example, showed that in rural India
idiosyncratic variation in consumption is systematically related to idiosyncratic variation in income, implying that households can only achieve partial insurance against their idiosyncratic
risks. Models of limited commitment developed by Thomas and Worrall (1988), Kehoe and
Levine (1993), Kocherlakota (1996), Alvarez and Jermann (2000), Ligon et al. (2000), Ligon
et al. (2002) can potentially explain these observations. In these models, all the information is
public (there is no information friction); instead there is an enforcement friction: agents are
free to walk away from the insurance contract at any time. Nevertheless, these models can be
analyzed using the same recursive techniques as those described in Section 2. Analogous to the
asymmetric information models we analyzed, the state variable is the utility promised to the
agent. The only formal difference is that the incentive compatibility constraints (8) are replaced
by participation constraints that we formally define in equation (134).

88

Here we describe the two-sided limited commitment framework analyzed by Ligon et al.

(2002). The (observable) period-t state of nature θt ∈ Θ = θ(1) , . . . , θ(|Θ|) is stochastic and

follows a Markov process with transition probability π θ(i) θ(j) > 0 for all i, j. There are two



agents with period-t utilities U 1 c1t , U 2 c2t and exogenous non-storable endowments yt1 , yt2
determined by θt . At least one of the two households is risk averse, and they both discount the
future at rate β. A risk-sharing contract τ specifies for every date t and history θt a (possibly

negative) transfer τt θt from household 1 to household 2. A first-best, or full risk-pooling,
U 20 (y 2 (θt )+τt (θt ))
contract τ is such that for all dates and states, the ratio of marginal utilities U 10 yt1 (θ )−τ (θt ) is
(t t t )
constant across all histories and dates, so that each individual’s consumption is only a function
of the aggregate endowment.
The key friction of the model is that agents can walk away from the insurance contract,

after which both households consume at autarky levels forever after, i.e. τt θt = 0 for all
t, θt . Household j ∈ {1, 2} has no incentive to break the contract if the following sustainability
constraint holds: for all θt ∈ Θt ,
Uj



cjt

θ


t

"
+ Et

∞
X

βsU j



cjt+s

θ


t+s

#
≥ Uj



ytj



(θt ) + Et

"

∞
X

βsU j





j
yt+s
(θt+s )

#
,

s=1

s=1

(134)
and
=
for all s, and where Et is the expecwhere
tation
Section 3.2 (where the government was unable to commit), it is
useful to describe the present environment with bilateral lack of commitment as a repeated game
between the two agents. Since reversion to autarky is the worst subgame-perfect punishment,
there is a one-to-one relationship between sustainable contracts and subgame perfect equilibria
(see Abreu (1988)).We now show how to characterized the set of constrained-efficient sustainable contracts, using recursive arguments formally similar to those we used in Section 2. By the
Markov structure of the income process and the forward-looking nature of the constraints, the
set of sustainable continuation contracts (i.e., for which conditions (134) are satisfied) depends
only on the current state θ and not on the history leading to that state. The constrained efficient allocations maximize the expected lifetime utility of agent 2 subject to both sustainability
constraints (134), and to delivering at least a given utility level v 1 to the agent 1, given that the
current state is θ. Before we formally write this problem, we describe the space of discounted
expected utilities v 1 , v 2 for each agent (defined as in (11)) for which there exists a sustainable
contract that delivers those values, given that the current state is θ (see footnote 7). We can


show that this set is an interval of the form v j (θ) , v̄ j (θ) for each agent j ∈ {1, 2}, where the
minimum sustainable utilities when the current state is θ are
"∞
#
X


v j (θ) = U j y j (θ) + E
β s U j ysj (θs ) |θ
= ys1 (θs ) − τs (θs )
conditional on θt . As in

c1s (θs )

c2s (θs )

ys2 (θs ) + τs (θs )

s=1

for j ∈ {1, 2}, that is, the value of autarky for agent j from state θ onwards.

89

The ex-post efficiency frontier, calculated once the current state θ is known, can then be


characterized in recursive form as follows: for v 1 ∈ v 1 (θ) , v̄ 1 (θ) ,

V v1, θ =

max

τ (θ),{w1 (θ0 )}θ0 ∈Θ

X


 
U 2 y 2 (θ) + τ (θ) + β
π θ0 |θ V w1 θ0 , θ0
θ0 ∈Θ

subject to to the promise-keeping constraint
X



U 1 y 1 (θ) − τ (θ) + β
π θ0 |θ w1 θ0 = v 1 ,

(135)

θ0 ∈Θ

the sustainability constraints

V w

1



w1 θ0 ≥ v 1 θ0 , ∀θ0 ,

 
θ0 , θ0 ≥ v 2 θ0 , ∀θ0 ,

(136)
(137)

(the constraint w1 (θ0 ) ≤ v̄ 1 (θ0 ) is equivalent to (137)), and the non-negativity constraints
y 1 (θ) − τ (θ) ≥ 0, and y 2 (θ) + τ (θ) ≥ 0.

(138)

The Lagrange multiplier λ associated with the constraint (135) is the key variable in the
analysis of optimal insurance contracts. The first-order conditions and envelope condition of the
problem imply that λ is related to the ratio of the marginal utilities of consumption by

∂
λ = − V v1, θ =
∂v


U 20 y 2 (θ) + τ (θ)
ψ2 − ψ1
+ 10 1
,
10
1
U (y (θ) − τ (θ))
U (y (θ) − τ (θ))

(139)

where ψ1 , ψ2 are the Lagrange multipliers associated with the non-negativity constraints (138).
and other multipliers for the evolution. Suppose that the value of λ is known. If λ is in
the set of marginal utility ratios which can be generated by feasible transfers in state θ (i.e., by
τ (θ) ∈ [−y2 (θ) , y1 (θ)]), then there is a unique interior solution and the value of the transfer τ (θ)
is pinned down by equation (139) with ψ1 = ψ2 = 0. Otherwise, there is a corner solution with all
income going to one of the households, i.e., τ (θ) ∈ {−y2 (θ) , y1 (θ)} (with a positive multiplier ψ2
or ψ1 ). Therefore the constrained efficient contracts can be fully characterized by the evolution of




the multiplier λ θt along with an initial value λ0 ∈ minθ {λθ } , maxθ λ̄θ (varying the value
of λ0 traces out the Pareto frontier). This can be easily done using the first-order conditions

0
∂
1 (θ )
with respect to w1 (θ0 ), which writes, for all θ0 ∈ Θ, − ∂v
V w1 (θ0 ) , θ0 = λ+χ
1+χ2 (θ0 ) , where
βπ (θ0 |θ ) χ1 (θ0 ) and βπ (θ0 |θ ) χ2 (θ0 ) are the multipliers associated with the constraints (136),



(137). Ligon et al. (2002) show that there exist |Θ| intervals λθ , λ̄θ , such that λ θt evolves

90

according to




if λ θt < λθt+1 ,
λθt+1 ,

i
 

 h
λ θt , θt+1 = λ θt , if λ θt ∈ λθt+1 , λ̄θt+1 ,
(140)




λ̄
if λ θt > λ̄θt+1 .
θt+1 ,


∂
∂
Specifically, λθ ≡ − ∂v
V v 1 (θ) , θ and λ̄θ ≡ − ∂v
V v̄ 1 (θ) , θ where v̄ 1 (θ) is the maximum

feasible expected value for agent 1, which satisfies V v̄ 1 (θ) , θ = v 2 (θ).
To understand the intuition underlying this result, suppose for simplicity that the nonnegativity constraints on consumption (138) never bind, i.e., ψ1 = ψ2 = 0. We already argued
that in a full risk-pooling contract, the current transfers in every period are chosen such that the
ratio of the two households’ marginal utilities (139) is constant. Now consider a constrainedefficient contract, where the evolution of this ratio is given by equation (140). Suppose that the

marginal utility ratio last period was λ θt , and that the current state is θt+1 = θ0 , which defines





an interval of possible marginal utility ratios λθ0 , λ̄θ0 . If λ θt ∈ λθ0 , λ̄θ0 , then we choose





τ θt so that λ θt , θ0 = λ θt . If instead λ θt < λθ0 (respectively, if λ θt > λ̄θ0 ), household 1
(resp., household 2) would want to break the contract if the ratio of marginal utilities remained
constant, as the short-term costs of making the corresponding transfer in the current period
would exceed the long-term insurance benefits coming from promises of future reciprocation.
Hence full risk-pooling, which would occur with complete markets, is not feasible in this case.


We then choose λ θt , θ0 = λθ0 (resp., λ θt , θ0 = λ̄θ0 ). The value λ = λθ0 (respectively, λ = λ̄θ0 )
corresponds to household 1 receiving its minimum possible sustainable surplus v 1 (θ0 ) in state θ0
(resp., its maximum surplus v̄ 1 (θ0 )), or equivalently household 2 getting v̄ 2 (θ0 ) (resp., v 2 (θ0 )).
In other words, if full risk-sharing is not possible the ratio of marginal utilities must change
to an endpoint (i.e., by the minimum possible amount) so that one of the households is just
indifferent between staying in the contract and reneging.52
Ligon et al. (2002) then test the model on the data for three Indian villages, using the model
to predict consumption allocations (by estimating empirically the initial ratio of marginal utilities and values for the model’s parameters that provide the best fit to the data), and measuring
the difference between these predictions and the actual data. They find that the dynamic limited commitment model does a substantially better job at explaining the dynamic response of
consumption to income than do models of full insurance, static limited commitment, or autarky.
In models of limited commitment, the key to the amount of informal insurance that can be
provided in the optimal contract depends on how costly reneging is for the households. That
is, the value of autarky is the most important determinant of the extent of insurance. Recent
We can show that for a sufficiently high discount factor β ≥ β ∗ ∈ [0, 1) the λ-intervals overlap and thus
there is some first-best contract which is sustainable, whereas if the households are sufficiently impatient, i.e.
β ≤ β∗ ∈ (0, 1), then no non-autarkic contract exists. In the former case, irrespective of initial value of λ0 , and
hence of the initial division of the surplus from the contract, the contract converges with probability one to a
first-best contract. Thus, if people are sufficiently patient, absence of commitment cannot justify the observed
lack of diversification in individual consumption as being efficient.
52

91

work by Morten (2013) studies a model of risk sharing with endogenous commitment in which
temporary migration is possible. The possibility of migration has the unintended consequence of
improving self insurance of individuals and the value of autarky, and worsening the risk sharing
in the economy. She studies the joint determination of risk sharing and migration decisions
and decomposes the welfare effects of migration between changes in income and changes in the
endogenous structure of insurance. Morten (2013) further structurally estimates the model on
a panel from rural India and argues that the possibility of migration may significantly reduce
risk sharing.
There is by now a large literature studying the predictions of models with contracting frictions in the development economics context. For example, Karaivanov and Townsend (2014)
is a comprehensive study comparing exogenously incomplete markets to markets which are endogenously incomplete due to contractual frictions. Their focus is on consumption, income,
investment and asset behavior of small businesses in Thailand. They conclude that the exogenously incomplete market model has the best fit for their rural sample while the dynamic
moral hazard model is more appropriate for urban households. A recent paper by Kinnan (????)
develops a test to distinguish barriers to informal insurance in Thai villages for three types of
models: limited commitment, moral hazard, and hidden income, based on the theoretical prediction (see, e.g., equation (64)) that a single lag of inverse marginal utility is sufficient to forecast
current inverse marginal utility, which is satisfied by the first two models but not the latter. She
concludes that hidden income is more likely to be the cause of barriers to insurance.

4.4

International Finance

In this section, we describe an application of the recursive contract models to the international
finance context, based on Kehoe and Perri (2002). The benchmark model is one of limited
commitment similar to that studied in the previous section, but we now analyze it using the
duality theory described in Section 3.1.4. Models of limited commitment are useful to analyze
questions related to sovereign debt default as they provide a framework that can explain the
mechanisms by which countries are induced to participate in contracts involving transfers backed
only by promises of future repayment, i.e., without a legal authority enforcing them. In such
models, countries are free to renege on their debts; the only threat is exclusion from future
participation in the financial market.
Standard international business cycle models with either complete or exogenously incomplete
markets typically deliver predictions that are at odds with the data (see Backus et al. (1992)), for
instance, that cross-country correlations of consumption are much higher than those for output,
and that both employment and investment in different countries comove negatively. Moreover,
net exports and investment are much more volatile in these models than in the data. Kehoe
and Perri (2002) show that introducing endogenously incomplete markets due to limited loan
enforcement frictions in an otherwise standard international business cycle model can resolve

92

these puzzles. This feature allows the model to reproduce the data’s positive cross-country
comovements of factors of production, consumption and output.
We now formally describe the model. There are two countries i = 1, 2 that produce using
domestic labor and capital inputs and face exogenous idiosyncratic Markov techology shocks




Ai θt . Output in country i after a history of shocks θt is given by F ki θt−1 , Ai θt li θt .




The social planner’s problem consists of choosing allocations ci θt , li θt , ki θt−1 i,t to
maximize a weighted (with weights λi ) sum of utilities of the representative consumers in each
country:
(∞
)
X
X X



max
λi
β t π θt U ci θt , li θt
(141)
c,l,k

t=0 θt ∈Θt

i=1,2

subject to the feasibility constraint
X

X






ci θt + ki θt =
F ki θt−1 , Ai θt li θt + (1 − δ) ki θt−1 ,

i=1,2

i=1,2

and the enforcement constraints (similar to (134)): for i = 1, 2,
∞ X
X

 

β s−t π θs θt U (ci (θs ) , li (θs )) ≥ V i ki θt−1 , θt ,

(142)

s=t θs ≥θt

 
where V i ki θt−1 , θt denotes country i’s value of autarky from θt onward, given by
V i ki θ

t−1



,θ

t



= max
c,l,k

∞ X
X
s=t θs
s


β s−t π θs θt U (c1 (θs ) , l1 (θs ))

subject to ci (θs ) + ki (θ ) ≤ F ki θ

(143)

s−1



, Ai (θs ) li (θs ) + (1 − δ) ki θs−1 .

The enforcement constraints are formally derived from arguments similar to those we used to
obtain (82) in Section 3.2. They ensure that it is the best response for each country to stick to
their equilibrium strategies.
We can re-write this problem recursively using the Marcet and Marimon (2015) approach


(see Section 3.1.4). Letting β t π θt µi θt denote the multipliers on the enforcement constraints
(142), we can write the Lagrangian of the social planner’s problem as (similar derivation as
equation (76))
∞ X X
X

t

βπ θ

t








Mi θt−1 U ci θt , li θt

t=0 θt ∈Θt i=1,2

(144)
 



+ µi θt U ci θt , li θt − V i ki θt−1 , θt




subject to the feasibility constraint, where Mi θt is a cumulative Lagrange multiplier defined

93

recursively as



Mi θt = Mi θt−1 + µi θt ,

(145)



for t ≥ 0, with Mi θ−1 = λi . Thus the cumulative multiplier Mi θt is equal to the original
planning weight λi at time 0, and to the sum of the initial weight and the past multipliers on the
enforcement constraints at time t ≥ 1 and history θt . Using the techniques described in Section
 M2 (θt )
3.1.4 and denoting by z θt = M1 (θt ) the relative weight on country 2, this problem can be written recursively and its solution is stationary in the state space that consists of the current shock,



the current capital stocks, and the relative weight, i.e. xt = θt , k1 θt−1 , k2 θt−1 , z θt−1 .
It is instructive to compare this objective (144) with the unconstrained objective (141). The
enforcement constraints introduce three key differences. First, starting at the beginning of the

period, the cumulative Lagrange multiplier Mi θt−1 shifts the (relative) weights of each agent.

Second, the current Lagrange multiplier µi θt on the sustainability constraint further changes
the weight on current consumption (as well as on future consumption by affecting the future

cumulative multiplier Mi θt ). These two forces translate in the first-order conditions into a
distortion of the relative marginal utilities of consumption:



M2 θt−1 + µ2 θt
U1c θt
=
.
U2c (θt )
M1 (θt−1 ) + µ1 (θt )

(146)


Third, accumulating more capital ki θt−1 tightens the enforcement constraint by increasing
the value of autarky. As a result, the Euler equation (and capital accumulation) is distorted as
follows:
"
#


X

 µi θt+1



Mi θt+1
t+1
t+1
t+1
t
+1−δ −
Fik θ
Uic θ
V
θ
.
Uic θ = β
π (θt+1 |θt )
Mi (θt )
Mi (θt ) ik
θt+1

(147)
Uil (θt )
Uic (θt )

θt



= Fil
The last first-order condition writes
: there is no distortion in the consumptionlabor decision, since this margin does not affect the enforcement constraint.53 These first
order conditions along with the transition law for z2 θt can be straightforwardly rewritten as


µi (θt )
functions of z2 θt−1 and the normalized multipliers µ̃i θt ≡ Mi (θt−1 ) . The solution to this
problem can then be characterized by allocations of the form (ci (xt ) , li (xt ) , ki (xt )), where the



state vector is xt = θt , k1 θt−1 , k2 θt−1 , z θt−1 . These policy functions satisfy the firstorder conditions above, the feasibility and enforcement constraints, and the complementary
slackness conditions on the multipliers.
The model has the following implications. Suppose that the home country (say, country


i = 1) is hit in history t, θt with a positive and persistent productivity shock A1 θt > 0.
Equation (143) shows that such a shock increases the home country’s value of autarky, and thus
53

Kehoe and Perri (2004) show how to decentralize the constrained efficient allocation as a competitive equilibrium using a tax on capital income to replicate the wedge in the Euler equation (147) generated by the enforcement
constraint.

94

tightens its enforcement constraint (142). This may lead the enforcement constraint to bind,

which translates into a positive multiplier µ1 θt in the first-order condition (146). This in
turn implies that the planner increases the relative weight to the home country in its objective


and allocates it higher consumption c1 θt (i.e., lower marginal utility U1c θt ) to prevent it
from defaulting. Moreover, this increase in consumption is persistent, because the productivity

shock is persistent and the positive multiplier µ1 θt raises the cumulative multiplier M1 (θs )
of the home country (defined in (145)) in all future periods s ≥ t. In contrast, consumption
in the foreign country does not vary much, as risk-sharing in this economy is limited. Finally,
the planner optimally restricts the investment flow into country 1 in order to reduce the home
country’s future value of autarky in equation (147) and relax the enforcement constraint. It
also increases labor effort and investment in the foreign country to raise country 1’s value of
participating into the contract, leading to positive cross-country correlations of investment and
employment and to a trade surplus (positive net exports) in the home country.
Now compare these effects with those that would occur in an economy without enforcement
frictions, i.e., with complete markets. In response to a positive productivity shock in the home
country, and hence a higher productivity of capital and labor, the planner optimally increases
the domestic labor effort and the capital stock, both by saving more and increasing investment
flowing from abroad. In contrast, foreign labor effort and investment decrease. Moreover,
because of risk sharing, the domestic economy shares its consumption gains, leading to an
increase in the consumption of the foreign country. The responses are qualitatively similar but
muted in a model where markets are exogenously incomplete (only bonds are allowed). In such
models, therefore, output is less correlated across countries than is consumption, the crosscountry correlations of investment and employment are negative, and a positive productivity
shock leads to a trade deficit in the home country (due to the net inflow of investment).
Kehoe and Perri (2002) calibrate the economy and analyze numerically these implications of
the model with endogenously incomplete markets. They find that it matches the data’s positive
cross-country comovements of factors of production (employment, investment) and the crosscountry comovements of consumption and output. This resolves several of the puzzles arising in
standard (complete or exogenously incomplete market-)models of international finance described
in the first paragraph of this section.
There is a large literature that analyzes questions of international debt and sovereign default using models of (one- or two-sided) limited commitment. The seminal paper is Eaton and
Gersovitz (1981), and this literature has been comprehensively reviewed by Aguiar and Amador
(2013). In particular, Aguiar et al. (2009) analyze the behavior of sovereign debt and foreign
direct investment in a small open economy (rather than in a two-country general equilibrium
environment as analyzed in the previous paragraphs) where the government lacks commitment
(leading to potential default and expropriation of capital) and is more impatient than the market. While the standard one-sided limited commitment model (see Thomas and Worrall (1994))
predicts that the government will eventually accumulate enough assets to overcome its commit-

95

ment problem,54 the additional assumption of a higher degree of impatience (and hence, the
combination of front loading due to impatience and back loading due to limited commitment)
leads to cycles in both sovereign debt and foreign direct investment, as well as a “debt overhang”
effect whereby investment is distorted by more in recessions than in booms.

5

Conclusion

The theory of recursive contracts underpins a variety of applications in a range of fields, from
public finance to development economics. A unifying feature of these applications is that they
feature frictions such as unobservability of shocks or actions or non-enforceability of contracts
that endogenously limit the amount of risk sharing and insurance that can be achieved. This
chapter provides a self-contained treatment of the fundamental techniques and the more advanced topics of recursive contracts. We also survey a number of applications through the lens
of this unified theoretical treatment that illustrate the versatility of the theoretical apparatus.

References
Abraham, A. and N. Pavoni (2008): “Efficient allocations with moral hazard and hidden
borrowing and lending: A recursive formulation,” Review of Economic Dynamics, 11, 781–
803.
Abreu, D. (1988): “On the theory of infinitely repeated games with discounting,” Econometrica, 383–396.
Abreu, D., D. Pearce, and E. Stacchetti (1990): “Toward a theory of discounted repeated
games with imperfect monitoring,” Econometrica, 1041–1063.
Acemoglu, D., M. Golosov, and A. Tsyvinski (2008): “Political economy of mechanisms,”
Econometrica, 76, 619–641.
——— (2011): “Power fluctuations and political economy,” Journal of Economic Theory, 146,
1009–1041.

54

One-sided limited commitment models generally imply that the optimal contract features a form back loading:
the profile of consumption is shifted towards the future. The intuition is as follows. Additional consumption in
a particular period helps ensure the agent’s participation in the contract. Moreover, it also helps satisfy the
enforcement constraints in all previous periods as well, since the left-hand side of the enforcement constraint
(e.g., (142)) is forward-looking. At the margin, therefore, consumption in the future is preferable as it relaxes
all the preceding participation constraints. As a result the relevant Euler equation includes the cumulative sums
of Lagrange mutlipliers that take into account all of the binding constraints in the previous periods. When the
government and the market have the same degree of impatience, the economy will eventually achieve perfect risk
sharing with constant consumption, so that a country has an incentive to save to grow out of the enforcement
constraints if it is patient enough. Ray (2002) shows that the backloading result and eventual reaching of the
unconstrained allocations apply in very general settings.

96

Aguiar, M. and M. Amador (2013): “Sovereign debt,” chapter prepared for the Handbook of
International Economics, 4.
Aguiar, M., M. Amador, and G. Gopinath (2009): “Investment cycles and sovereign debt
overhang,” The Review of economic studies, 76, 1–31.
Aiyagari, S. R., A. Marcet, T. J. Sargent, and J. Seppälä (2002): “Optimal taxation
without state-contingent debt,” Journal of Political Economy, 110, 1220–1254.
Albanesi, S. (2011): “Optimal taxation of entrepreneurial capital with private information,”
Working paper.
Albanesi, S. and C. Sleet (2006): “Dynamic optimal taxation with private information,”
Review of Economic Studies, 73, 1–30.
Albuquerque, R. and H. Hopenhayn (2004): “Optimal lending contracts and firm dynamics,” Review of Economic Studies, 71, 285–315.
Alvarez, F. and U. J. Jermann (2000): “Efficiency, equilibrium, and asset pricing with risk
of default,” Econometrica, 775–797.
Atkeson, A. and R. E. Lucas (1992): “On efficient distribution with private information,”
Review of Economic Studies, 59, 427–453.
——— (1995): “Efficiency and equality in a simple model of efficient unemployment insurance,”
Journal of Economic Theory, 66, 64–88.
Backus, D. K., P. J. Kehoe, and F. E. Kydland (1992): “International real business
cycles,” Journal of political Economy, 745–775.
Badel, A. and M. Huggett (2014): “Taxing top earners: a human capital perspective,”
Working paper.
Barro, R. J. (1979): “On the determination of the public debt,” The Journal of Political
Economy, 940–971.
Battaglini, M. and R. Lamba (2015): “Optimal dynamic contracting: the first-order approach and beyond,” Working paper.
Benveniste, L. M. and J. A. Scheinkman (1979): “On the differentiability of the value
function in dynamic models of economics,” Econometrica, 47, 727–32.
Bertsekas, D. P., A. Nedi, and A. E. Ozdaglar (2003): Convex analysis and optimization,
Athena Scientific.

97

Bester, H. and R. Strausz (2001): “Contracting with imperfect commitment and the revelation principle: The single agent case,” Econometrica, 69, 1077–98.
Biais, B., T. Mariotti, G. Plantin, and J.-C. Rochet (2007): “Dynamic security design:
Convergence to continuous time and asset pricing implications,” The Review of Economic
Studies, 74, 345–390.
Biais, B., T. Mariotti, J.-C. Rochet, and S. Villeneuve (2010): “Large risks, limited
liability, and dynamic moral hazard,” Econometrica, 73–118.
Billingsley, P. (1995): Probability and measure, Wiley Series in Probability and Statistics,
Wiley.
Bismut, J.-M. (1973): “Conjugate convex functions in optimal stochastic control,” Journal of
Mathematical Analysis and Applications, 44, 384–404.
——— (1978): “An introductory approach to duality in optimal stochastic control,” SIAM
review, 20, 62–78.
Caves, R. E. (1998): “Industrial organization and new findings on the turnover and mobility
of firms,” Journal of economic literature, 1947–1982.
CBO (2007): “Historical effective federal tax rates, 1979 to 2005,” Congressional Budget Office.
Chamberlain, G. and C. A. Wilson (2000): “Optimal intertemporal consumption under
uncertainty,” Review of Economic dynamics, 3, 365–395.
Chari, V. V. and P. J. Kehoe (1990): “Sustainable plans,” Journal of Political Economy,
98, 783–802.
——— (1993): “Sustainable plans and debt,” Journal of Economic Theory, 61, 230–261.
Clementi, G. L. and H. A. Hopenhayn (2006): “A theory of financing constraints and firm
dynamics,” The Quarterly Journal of Economics, 121, 229–265.
Cole, H. and F. Kubler (2012): “Recursive contracts, lotteries and weakly concave pareto
sets,” Review of Economic Dynamics, 15, 479–500.
Cvitanic, J. and J. Zhang (2012): Contract theory in continuous-time models, Springer
Science & Business Media.
De Marzo, P. and Y. Sannikov (2006): “Optimal security design and dynamic capital
structure in a continuous-time agency model,” The Journal of Finance, 61, 2681–2724.
DeMarzo, P. M. and M. J. Fishman (2007a): “Agency and optimal investment dynamics,”
Review of Financial Studies, 20, 151–188.

98

——— (2007b): “Optimal long-term financial contracting,” Review of Financial Studies, 20,
2079–2128.
DeMarzo, P. M., M. J. Fishman, Z. He, and N. Wang (2012): “Dynamic agency and the
q theory of investment,” The Journal of Finance, 67, 2295–2340.
Diamond, P. and J. Mirrlees (1978): “A model of social insurance with variable retirement,”
Journal of Public Economics, 10, 295–336.
——— (1986): “Payroll-tax financed social insurance with variable retirement,” The Scandinavian Journal of Economics, 88, 25–50.
Diamond, P. A., L. J. Helms, and J. A. Mirrlees (1980): “Optimal taxation in a stochastic
economy: A Cobb–Douglas example,” Journal of Public Economics, 14, 1–29.
Dovis, A., M. Golosov, and A. Shourideh (2015): “Political economy of sovereign debt:
Cycles of debt crisis and inequality overhang,” Working paper.
Eaton, J. and M. Gersovitz (1981): “Debt with potential repudiation: Theoretical and
empirical analysis,” The Review of Economic Studies, 289–309.
Ekeland, I. and J. A. Scheinkman (1986): “Transversality conditions for some infinite
horizon discrete time optimization problems,” Mathematics of operations research, 11, 216–
229.
Espino, E., J. Kozlowski, and J. M. Sanchez (2013): “Too big to cheat: efficiency and
investment in partnerships,” FRB of St. Louis Working Paper No 2013-001C.
Farhi, E., C. Sleet, I. Werning, and S. Yeltekin (2012): “Non-linear capital taxation
without commitment,” Review of Economic Studies, 79, 1469–1493.
Farhi, E. and I. Werning (2007): “Inequality and social discounting,” Journal of Political
Economy, 115, 365–402.
——— (2012): “Capital taxation: Quantitative explorations of the inverse Euler equation,”
Journal of Political Economy, 120, 398–445.
——— (2013): “Insurance and taxation over the life cycle,” Review of Economic Studies, 80,
596–635.
Fazzari, S. M., R. G. Hubbard, B. C. Petersen, A. S. Blinder, and J. M. Poterba
(1988): “Financing constraints and corporate investment,” Brookings Papers on Economic
Activity, 141–206.
Fernandes, A. and C. Phelan (2000): “A recursive formulation for repeated agency with
history dependence,” Journal of Economic Theory, 91, 223–247.

99

Freixas, X., R. Guesnerie, and J. Tirole (1985): “Planning under incomplete information
and the ratchet effect,” Review of Economic Studies, 52, 173–91.
Friedman, M. (1957): A theory of the consumption function, National Bureau of Economic
Research, Inc.
Fudenberg, D. and J. Tirole (1991): Game theory, MIT Press.
Geweke, J. and M. Keane (2000): “An empirical analysis of earnings dynamics among men
in the PSID: 1968-1989,” Journal of Econometrics, 96, 293–356.
Golosov, M. and L. Iovino (2014): “Social insurance, information revelation, and lack of
commitment,” NBER Working paper No. w20633.
Golosov, M., N. Kocherlakota, and A. Tsyvinski (2003): “Optimal indirect and capital
taxation,” Review of Economic Studies, 70, 569–587.
Golosov, M., M. Troshkin, and A. Tsyvinski (2016): “Redistribution and social insurance,” American Economic Review, forthcoming.
Golosov, M. and A. Tsyvinski (2006): “Designing optimal disability insurance: A case for
asset testing,” Journal of Political Economy, 114, 257–279.
——— (2007): “Optimal taxation with endogenous insurance markets,” The Quarterly Journal
of Economics, 122, 487–534.
Golosov, M., A. Tsyvinski, and I. Werning (2006): “New dynamic public finance: A
user’s guide,” NBER Macroeconomics Annual, 21, 317–363.
Green, E. J. (1987): “Lending and the smoothing of uninsurable income,” in Contractual
Arrangements for Intertemporal Trade, ed. by E. C. Prescott and N. Wallace, Minneapolis:
University of Minnesota Press.
Guvenen, F., S. Ozkan, and J. Song (2014): “The nature of countercyclical income risk,”
Journal of Political Economy, 122, 621–660.
Guvenen, F., J. Song, S. Ozkan, and F. Karahan (2015): “What do data on millions of
US workers reveal about life-cycle earnings risk?” NBER Working Paper No. w20913.
Hall, R. E. (1978): “Stochastic implications of the life cycle-permanent income hypothesis:
Theory and evidence,” The Journal of Political Economy, 86, 971–987.
He, Z. (2009): “Optimal executive compensation when firm size follows geometric brownian
motion,” Review of Financial Studies, 22, 859–892.

100

Hosseini, R., L. E. Jones, and A. Shourideh (2013): “Optimal contracting with dynastic
altruism: family size and per capita consumption,” Journal of Economic Theory, 148, 1806–
1840.
Hurwicz, L. (1960): “Optimality and informational efficiency in resource allocation processes,”
in Mathematical methods in the social sciences, 1959: proceedings of the first Stanford symposium, Stanford University Press, 27.
——— (1972): “On informationally decentralized systems,” in Decision and organization: a
volume in honor of Jacob Marschak, North-Holland.
Kapička, M. (2013): “Efficient allocations in dynamic private information economies with
persistent shocks: A first order approach,” Review of Economic Studies, 80, 1027–1054.
Karaivanov, A. and R. M. Townsend (2014): “Dynamic financial constraints: Distinguishing mechanism design from exogenously incomplete regimes,” Econometrica, 82, 887–959.
Karatzas, I. and S. Shreve (2012): Brownian motion and stochastic calculus, vol. 113,
Springer Science & Business Media.
Kehoe, P. J. and F. Perri (2002): “International business cycles with endogenous incomplete
markets,” Econometrica, 70, 907–928.
——— (2004): “Competitive equilibria with limited enforcement,” Journal of Economic Theory,
119, 184–206.
Kehoe, T. J. and D. K. Levine (1993): “Debt-constrained asset markets,” The Review of
Economic Studies, 865–888.
Kinnan, C. (????): “Distinguishing barriers to insurance in Thai villages,” Working paper.
Kocherlakota, N. (2010): The New Dynamic Public Finance, Princeton University Press,
USA.
Kocherlakota, N. R. (1996): “Implications of efficient risk sharing without commitment,”
The Review of Economic Studies, 63, 595–609.
Laffont, J.-J. and J. Tirole (1988): “The dynamics of incentive contracts,” Econometrica,
56, 1153–75.
Le Van, C. and H. C. Saglam (2004): “Optimal growth models and the Lagrange multiplier,”
Journal of Mathematical Economics, 40, 393–410.
Ligon, E., J. P. Thomas, and T. Worrall (2000): “Mutual insurance, individual savings,
and limited commitment,” Review of Economic Dynamics, 3, 216–246.

101

——— (2002): “Informal insurance arrangements with limited commitment: Theory and evidence from village economies,” The Review of Economic Studies, 69, 209–244.
Lindbeck, A. and J. W. Weibull (1987): “Balanced-budget redistribution as the outcome
of political competition,” Public choice, 52, 273–297.
Ljungqvist, L. and T. Sargent (2012): Recursive Macroeconomic Theory, MIT Press.
Lockwood, B. B., C. G. Nathanson, and E. G. Weyl (2014): “Taxation and the allocation
of talent,” Working paper.
Luenberger, D. (1969): Optimization by vector space methods, Wiley-Interscience.
Maag, E., C. E. Steuerle, R. Chakravarti, and C. Quakenbush (2012): “How marginal
tax rates affect families at various levels of poverty,” National Tax Journal, 65, 759–82.
Marcet, A. and R. Marimon (2015): “Recursive contracts,” Mimeo, European University
Institute.
Mas-Colell, A., M. Whinston, and J. Green (1995): Microeconomic theory, Oxford University Press, New York.
Messner, M. and N. Pavoni (2004): “On the recursive saddle point method,” Dynamic
Games and Applications, 1–13.
Messner, M., N. Pavoni, and C. Sleet (2012): “Recursive methods for incentive problems,”
Review of Economic Dynamics, 15, 501–525.
——— (2014): “The dual approach to recursive optimization: Theory and examples,” in 2014
Meeting Papers, Society for Economic Dynamics, 1267.
Miao, J. and Y. Zhang (2014): “A duality approach to continuous-time contracting problems
with limited commitment,” Journal of Economic Theory, 159, 929–928.
Milgrom, P. and I. Segal (2002): “Envelope theorems for arbitrary choice sets,” Econometrica, 70, 583–601.
Morten, M. (2013): “Temporary migration and endogenous risk sharing in village india,”
Working paper.
Myerson, R. B. (1981): “Optimal auction design,” Mathematics of operations research, 6,
58–73.
——— (1982): “Optimal coordination mechanisms in generalized principal-agent problems,”
Journal of Mathematical Economics, 10, 67–81.
——— (1986): “Multistage games with communication,” Econometrica, 323–358.

102

Øksendal, B. (2003): Stochastic differential equations, Springer.
Øksendal, B. K. and A. Sulem (2005): Applied stochastic control of jump diffusions, vol.
498, Springer.
Pavan, A., I. Segal, and J. Toikka (2014): “Dynamic mechanism design: A Myersonian
approach,” Econometrica, 82, 601–653.
Phelan, C. (1995): “Repeated moral hazard and one-sided commitment,” Journal of Economic
Theory, 66, 488–506.
Phelan, C. and R. M. Townsend (1991): “Computing multi-period, information-constrained
optima,” Review of Economic Studies, 58, 853–81.
Ray, D. (2002): “The time structure of self-enforcing agreements,” Econometrica, 70, 547–582.
Revuz, D. and M. Yor (1999): Continuous martingales and Brownian motion, vol. 293,
Springer Science & Business Media.
Rogerson, W. P. (1985): “Repeated moral hazard,” Econometrica, 53, 69–76.
Rudin, W. (1976): Principles of mathematical analysis, New York: McGraw-Hill Book Co.,
third ed.
Rustichini, A. (1998): “Lagrange multipliers in incentive-constrained problems,” Journal of
Mathematical Economics, 29, 365–380.
Sannikov, Y. (2008): “A continuous-time version of the principal-agent problem,” The Review
of Economic Studies, 75, 957–984.
——— (2014): “Moral hazard and long-run incentives,” .
Scheuer, F. and A. Wolitzky (2014): “Capital taxation under political constraints,” .
Shourideh, A. (2010): “Optimal taxation of capital income: A Mirrleesian approach to capital
accumulation,” Working paper.
Sleet, C. and S. Yeltekin (2008): “Politically credible social insurance,” Journal of Monetary Economics, 55, 129–151.
Spear, S. and S. Srivastava (1987): “On repeated moral hazard with discounting,” The
Review of Economic Studies, 54, 599–617.
Stantcheva, S. (2014): “Optimal taxation and human capital policies over the life cycle,”
Working paper.

103

Stokey, N. L., R. E. Lucas, and E. C. Prescott (1989): Recursive methods in economic
dynamics, Cambridge, MA: Harvard University Press.
Storesletten, K., C. I. Telmer, and A. Yaron (2004): “Consumption and risk sharing
over the life cycle,” Journal of Monetary Economics, 51, 609–633.
Sun, Y. (2006): “The exact law of large numbers via Fubini extension and characterization of
insurable risks,” Journal of Economic Theory, 126, 31–69.
Thomas, J. and T. Worrall (1988): “Self-enforcing wage contracts,” The Review of Economic Studies, 55, 541–554.
——— (1990): “Income fluctuation and asymmetric information: An example of a repeated
principal-agent problem,” Journal of Economic Theory, 51, 367–390.
——— (1994): “Foreign direct investment and the risk of expropriation,” The Review of Economic Studies, 81–108.
Townsend, R. M. (1994): “Risk and insurance in village India,” Econometrica, 539–591.
Uhlig, H. (1996): “A law of large numbers for large economies,” Economic Theory, 8, 41–50.
Vickrey, W. (1947): Agenda for progressive taxation, The Ronald Press Company.
Werning, I. (2009): “Nonlinear capital taxation,” MIT working paper.
Williams, N. (2009): “On dynamic principal-agent problems in continuous time,” Working
paper.
——— (2011): “Persistent Private Information,” Econometrica, 79, 1233–1275.
Yong, J. and X. Y. Zhou (1999): Stochastic controls: Hamiltonian systems and HJB equations, vol. 43, Springer Science & Business Media.
Zhang, Y. (2009): “Dynamic contracting with persistent shocks,” Journal of Economic Theory,
144, 635–675.

104

