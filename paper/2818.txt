NBER WORKING PAPER SERIES

A

NARKOV MODEL OF HETEROSKEDASTICITY,
RISK,
AND LEARNING IN THE STOCK MARKET

Christopher

M. Turner

Richard Startz
Charles R. Nelson

Working Paper No. 2818

NATIONAL BUREAU OF' ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 1989

participation was supported in part by the Center for the Study of
This research is part
Banking and Security Markets University of Washington.
of NBER's research program in Financial Markets and Monetary Economics. Any
opinions expressed are those of the authors not those of the National Bureau
of Economic Research.
Nelson's

NBER Working Paper #2818
January 1989

A MARKOV MODEL OF HETEROSKEDASTICITY,

RISK,
IN THE STOCK MARKET

AND LEARNING

ABSTRACT

Risk

prenila in t lie stock

titarket

are assumed to

move svitlm

ti ume

varying risk.

We

present a model in

which the variance of timeexcess return of a portfolio depends ott a state variable generated by a first—order
Markov process. A model in which the realization of the state is knosvn to economic agents, hut uuknosvn
'l'lme paraumeterestimates are found to iimmply that time risk premium
rises.
We then extend the nmodel to allosc agents to he uncertain about
declines as time variance of returns
time state. Agents make their decisions in tseriod I using a prior distribution of time state based only on past

to the econometrician. is estimimated.

realizations of the excess return t hrouglm
paraisseter estimates from this

imsodel

period

/

— I plus knowledge of the

are consistent

structure of the model. TIse

witis asset pricing theory.

Christopher N. Turner

Richard Startz

Department of

Departmentof Economics
DR-3D
Universityof Washington
Seattle, WA 98195

Economics

DR-3D

University of Washington
Seattle,

WA

98195

Charles R. Nelson
Economics
Department
DR-3D

of

University
Seattle,

of Washington

WA

98195

it) Is!iislstioo
In a simple tsi'o asset world, where
Risk averse agents require compensation for lioldiiig risky assets.
while tie oilier is riskless. t lie nondiversiflable risk
one asset is risky with norilially distributed returns
the riskiess rate. If the excess return has a
is simply t lie ant icipateil variance of I lie excess ret sirn above
constant variance t lien the risk 1ire!noiio is constant.

The iioriiial return/constant variance nioilel of asset prices does not provide an adequate explanation
an asset
of the behavior of asset niarkets such a.s the stock market. The returns [win iiiany assets, including
from any of the coiiiinon stock market indices, appear so he drawn from
consisting of a portfolio of stocks
In particular the empiricaldial rihutions of retursss
non —nornsal unconditional distributions ( Faioa, 1961).
froni these assets tend to have a pronounced peaks and heavy tails- (Gallant 1988; Schwert, 1987, 1988).
and Poor's index
TIns is demonstratedfor ret urns froni a portfolio consisting of stocks froni Standard
the prohabihity mass of the empirical
by the histograni shown in Figure (1)- In tlsis distribution 39Z of
the niean, 30% more than in the norosal density.
density lies witlon one—halfof a standard deviation from
to heteroskedasticit.y.
This shapeis typical of unconditional densities of normal observations subject
individual
observations.
variances
of
the
The sample variance of the densitywill be a weighted average of the
than the smallest variance and smaller than the largest variance. As a resolt, some

It will

he larger

than the sample variance, these will be more
observations are drawn from densities with smaller variances
with the sample variance. Likewise, some observations will be drawn from
peaked than a normal density
more mass in their tails then does
densities with larger variances than the sample variance, these will have
of the data is a linear combination of
a normal with the sansple variance. As the unconditional density
these normmial densities, it

will have niore mass in its peak

and tails than the

simsmple

nornsal.

of asset prices is not only heterogenous but also is
suggests that the variance
ct. at (1987), Sehwert (1987, 1988).
predictable,c.f. Bollerslev, vi. at (1987), Mandlebroit (1963), Engle,
of these variances with an autoregressive conditional
Engle and Bohierslev demonstrate the predictability
Schwert explores this aspect with an autoregression on
heteroskedasticity model and a generalization.
on n000nal returns. Their conclusions imply that a properly specified
squared errors and a Markov niodel
a
element. This in torn
model of the risk prensiuns must allow a time dependent variance with predictable

A large literature

intilies that the risk preniiuni will lit tinu' detienileut.

si ice future risk moves in a predictable fashion.

We introducea nioilel of Ilii sI tick tijarket- in which tie excess ret urn is drawn from a uiixt
tire of two
normal densities. In snir nioilcl t lie stork market is assumed to ssritcli between two states. The stale of
the market in each period deternitnes seliicli of two normal dist ributions is used to
generate tlie excess

return for that period. The states are cliaract erized by the variances of their densities. There is a
"high
variance" state and a. "low variance" state. The state itself is assumed to be
generated b a first—order
Markov process. TIns approach was first tirotiosed by Haniiltoti (I ttt7A, 198713) in a dilferent context.
Like Bollerslev (1987), I his model leads to a variance srlucli is a function of the variance of prior
periods.
however, our model will allow the conditional variance to be a stochastic function of the prior period's
variance, Thus model will allow its to exauiinebol Ii the lieteroskedasticit.v of excess ret urns, and
their time
dependence.
We use the model to explore the relationship between the

timmie dependent variance and the risk
premium in the stork market. We will develop two models based on the heteroskedastic structure discussed
above. Each model will be based on a different assuniption on
agent.s' information sets. We will estimate

each nsodel using postwar data from excess returns based on

a portfolio of stocks iii

Standard and Poor's

index.
In the first nsodel we will simimply assunse that economic agents know the realization of the Markov
process underlying the generation of states, even though the econommietrician does not observe the state.
There are two risk prensia in this sperification. The first is sinsply the difference between the iiiean of the
distribution of the low variance state and the riskless return. Agents will require an increase in return over
the riskiess asset to hold an asset with a randons retsmrn. The second premium is
given by the difference
between the niean of the distribution of the high variance state and that of the low variance state. This
is the added return necessary to compensate for increased risk in the high variance state. Note that this
is the standard nsodel where agents know the variance extended to the case when the return on the
risky
asset has a beterogenous variance.
We will assunme that neither economic agents nor the economnetricianobserve the states
directly in the
second model. Each period they formms probabilitiesof each
possible state in the followingperiod conditional
on current and past excess returns. They use these probabilities in
nsaking their portfolio choices

in thuse

periods. The paranseter of interest is the increase in return necessaryto coospensate the agents for a given

percentage increase

ii tie prior probability i,f the high variance state.

In Srctw;i 9.9 we explore t IIC
we develop the

WO

SiIIIpie 1110(1(15

iii (lie risk preliliUI!, iiisciissed above. In Section

2.3

statistical specitication of the model. Sclzou 2. discusses ilaximuni likelihood estimation

of the specification.

'Ils is

furl her developed in Appenlu .4. In Section 9.5 ive report estimates of the
parameters anil interprete hem . I lere we report (lie full saniple posterior tlist ribution of the slate in each

priod.
9.1)

In tea

o,mi,c mmioIel

ma

of e.mcess

met semis

in

i Iso slob u'o,ld

(onsider a two asset economy. The first asset is riskiess. ieldiig a sure return r1. 'Jim second asset
yields a normally distributed return per dollar invested

=
where 5, is an index of the state and where r1

simply y,

=

—

rj.

Time expected value

('o

q with time dependent expectation

,

and variance

if Si = 0

I'm' if 3, = I
> i,. The excess

(1)
return of the risky asset at time t is then

of excess returns is then Jit =

—

r1. while its variance is

= Vt.

The states, S,, are generated by a realization of a first order Markov process wit.!, transition probabilities
P(S, = 1S_,

= 1) =

P(S, = OIS(_] =

I) = 1— P

P(S, = 01St_i =

0)

(2)

=q

P(S, = 1S,_m = 0) =

I — q.

The expected value of excess returns, p,, is the premium agents require at time I for accepting the
variance in returns associated with the risky asset. In general. p, is thought to be positive and to be

positively related to the variance

o. The nature of this relationship,

however, depends on the inforniation

agents acquire.

2.1 Agents Luau, the states
Assume agents know the realization of the Markov process generating the states, thus they know (lie

extent of risk in each period. In this case the excess return will he given by
Pt

= pm + Cm,

(

N(0.o)

(3)

t. It is expected to be positively related to a. Note that ,t, is a
hence the risk preunuin Js will also he a detertin ,istic function of the

where p, is the risk pretionin in time

,letern,instic function of the state

ii, each

state. 'I'lnis, the risk premium
that period's state. That

, y,

(let ertitined by
period is simply the iitean of the normal distribut ion

E(,lS, = i), = 0,1.

Ii's

Letting,

ifS,0

p,, if S =
If agents are risk averse, we expect that t'' > i's ? 0
2.9 .4geots arc

s;ssic of tire

as Sj =

(4)

1.
1

is the high variance state.

states

5,, tlteit the process by which agents form their expectations must
and
he specified. here we will assnme that agents are unsure of the prevailing state in the past, present,
the
i.e.
know
and
equations (2)
know the structure generating the states,
they
future. We assonie

If agents are unsure of the state,
agents

the excess returns are drawn. Agents base their buying
parameters of the normal densities front which
and selling decisions in period I on a prior distribution of the state in that period. Each period they
rule. .kgents' prior
update their beliefs about that period's state with current information using Bayes'
—
I
1.
distribution of the state in period I will be based on information through
=
Let 4', be the information set through period t, then agents' prior distribution of the state is P(5,

iI4',.'), i = 0.1.

In period I they observe 4', and update their prior distribution using Bayes theorem

P(S, = l4't—') x f(4"ISt = i, 4'_t )
P(S, = '14'') =

—

(.))

f('F,I4',_t)

= i, 4',—,) is the distribution of the information set conditional on the state of
=
the systens, f(4', 4',_') is the unconditional distribution of the information set, and P(S, = il4',), i 0.1
distribution of the state conditionalon all the information through period I. The Markov
is the

for i = 0,1.

Here 1(4', 1St

posterior

structure underlying the state ensures that the prior distribution for the state in the following period is
sinsply a linear transformationof the posterior
P(St+, = I4't) =

i

for = 0,1. P(S,_, = iISt =

+t

= iS, = j)P(S, = iI4")

j) is given by the appropriate transition probabilitiesin equations (2).

(6)

Ilie prior distriloition may

be snitonarized by the probability oltiw high variance st-ate, I(S,=

1t_

without loss of infiirniat ion, since I lie model has only two stales. Agents' port folio choice may lie specified
as a shuttle function of I his prohalnhit'. That is, agents require an increase in I lie excess ret urn in period I
when faced wit-h an increase iii I lair prior prohatsi ity that the state in that period will be the high variance
state. We model the risk 1ireiiii 11111, whieii agents are uiiisiire of the state, as si iii ply

lIti

+ jlP(5' =
where

(7)

)

is positive. The constant, 0, represents agents' required excess return for holding an asset in the

low variance state.

3.0 Specification
We scill estimate three specifications based on the models discussed above.

The models will he

estimated on postwar nsonthly returns front a portfolio consisting of the stocks in Standard and Poor's
index. Thefirst tsro specifications will he direct translations fromthe econonsic models discussed previously.
The third svill take into account agents behavior during the period.
in the model where the states are known with certainty, no change is necessary for estinsation. Equations (3) and (4) may he rewritten as

= (i —
ui. =

)

—

Sihi-o + 5(01

+ e1,

e

N(O,c7)

(8)

5fr + Sic-I

S is given by the

where /15 and pt are the risk preniia in the low and high variance states, respectively.

first—order Markov process with equations (2) as the transition probabilities. Again, since agents are risk
averse we expect both /ts and

ji to be nnn—uegativeand

/10

JII.

The model in which agents are unsure of the state, equation (7) may specified as

= a + P)S5 = it1_1(+ e,
=

(1

—

S1)c-5

ri

+ Sc-j.

N)O,c?)

-

-

-

(9)

The risk preosinni in period (is agents' expectation of the excess return conditionalon information through
period I — 1. As before it is a /3P(S5 = I I4ii_m). It should always be posit-ive and increasing in the
—I-

anticipated variance, so that we expect both

a and jd

to be positive.

stsecification oft lie iiioilel assuisse that agents are only alile to t rasle assets once earls period.
Wills uioutlsly data this assnusptiou shsoulsl be questioned, as agents may make niany trades witlou each
At t lie hegi suing of period I, agents value their assets based on their prior distribution of the state
'Else above

period.

its that period, P( S5

=

1

4's-

). During the period agents continue to observe trades Agents' posterior

distribution of the state based on this data will effect the price and return of the asset. Since all we observe
is Ilie posterior dist ribut ion at the cud of the period I, and tIi is is a function of pi, we cannot include t lie
posterior

iii our speciHeation of ys ( Pagaii

and Ullals , 1988). Since agents know t lie struct ure of t lie systens,

we can issodeltheir behavior using the trne value of the state as a Isroxy for agents' posterior distrilsution.
Thus leads to the specification

= (1 — Ss)os + Ssos + 7P)Ss = fl4'i_s)
—
a? = (I Sda + S5e
where

is

5,

We

all

tiose

I

the parauseters

by

in

equations (10).

react to

Ageists

au

transition probabilities.

increase in the anticipated

decreasing the asset's value at the beginning of the period.

variance,and the anticipatedvariance is

E(afl4'st) =
we expect

)lO)

as the
generated by the first—order Markov process with equations (2)

cais sign

variance in

en

Since °?

is

the high

given by
P(Ss

= h!s_flc? + P(Ss = 014's—i)4

to be positive. Equivalentlywe may note that

-y

(11)

expresses the increase in excess return risk

averse agents requireto hold the risky asset for a given increasein their prior probability that this period's
state will

be the high variancestate.

asset will rise as

agents realize this

If in
is

period I

the true

state

is

the low variancestate, the return of the

the case and alter their portfolios,

its

favor

of the

risky asset.

behavior drives its price up at the end oft relative to the asset's price at the beginning of the period.
expect Ca to be positive. Likewise,if the
fall as

agents beconse convinced this

We nsay also sign a linear

is

true

combination of the parameters.

= 014's_i) + (at +

Thus,

0 should be be negative.
;t, is given

the risk presniuut in

Note that

on the current information set
by the expected value of ys conditional

If

4'st
=

)P(Ss

will always

be positive as long as os > 0 and

+

os

0.

I,

Thus, the risk premium is

14's_i)

and increase with P)55
agents are risk averse, this equation should always be positive

expectation

We

state is the high variance state, the return of the asset will

the ease and revalue it downwards.

= aaP(Ss

This

(12)

= ll+s_i). The

Finally, if both of these conditions

hold

iii t Ii i neitualit

I lien

>

dI')__i',

the risk pcenooni

will increase with agents' prior jiroliahihity01 the

(I,

(13)

high variance stat.e.

'ho conitilete t lie model, ageots' inforniation set joust lie specifier!. In thus case,
for I

t, 2
it

(91,92

Ui)

'I'. We assunie agents oniy observe past realizations of the excess return of the stock market

when fornong their prior distribution of the state.
I loicever,

ilii =

This assunitition is siinily niade for convenience.

is t eiiahile—t lie stock niarket. lia.s often been modeled as

a

crap gaoie, independent of tlie

real econoi iv. An ext ension of t lie niorle! in whiich agents nse ot her variables

in forming tliei r prior

is in

hirelieralion

4.1)

Estniiol on
Models

iii

which observations are chiosen froni a small set of distribntions are not new. In statistics

they are caller! Jinit.c ;iicc/src distribntions and their estimation is one of the
Pearson derived the first solnt ion: an application of thie niet hod of oionient
roots of a nonic pohynonsia!. In Pearson's problem

s

ohrhest

applied problems.

ivliicb involved finding the

and in the statistics literature in general, the distribution

governing the state is generally binoniial (Everitt and Hand, 1981).

In econojoetrics the use of finite nsixture distributions was discnssed in Coldfeld and Quandt (1973),
who called them switching regressions. They suggested that a Markov process could be osed to generate
the states. More recently Hanmilton (1987A, 1987B) modeled the growth rate of nonstationary tinse series,
such as gross national product, subject to occasional discrete shifts in rate of growth or in variance using
a Markov process. Specifically he considered niodels of the sanse foros as equations (8), though with
autoregressive terms connnon to both states. Schwert (1988) uses Hanolton's nsodel to study the instability

of nonunal stock niarket returns.
Cosslett and Lee (1985) derived the likelihood function for this model. They use the rule of elinmination

to derivethe joint densityof the data fromthe density of the data conditionalon the state vector and unconditional distribution of the state vector. In our case, the likelihood is given by f(ym,92,...,yTkm,x2,...,xr).
T. In the model
In the nsodel where agents are certain of the state, ri is the null vector for I = 1,2
where agents are uncertainof the state ri is their prior probability of the high variance state, i.e.
Zr

= P(S = lFyt.yz

Ui—I).

(14)

for I

2.1..,7. With this notation, the likelihoodis given by an enumeration of all possible stales weighted

b their probabilities.

f(y1,p2 ,...,YTIrI,r2,..., IT) =

{ft l,...,PTISI

= ,...,ST = 1T,.rl,

:7')

?1=5N5,=5

x P(S1 = 11,St =
The teriiis in tIns equal ion are easy to describe. Since
for the stale, I lte density of the dat a vector, Si, 52

yy(Si = ,...,5T = LT,XI

fly'
for

i

=

0, 1, k

= 1.2

pm

12

(15)

= IT)}

conditionalon xj is serially nneorrelat.ed except
conditionalon the slate vector is given by
J!T)

=

flfL3I83 = ij,:m)

T. Given the Markov structure underlying the probability

(IS)
model, the uncondi-

tional distribution of the state vector is given by
P(S, = i1,S2 =

= 'T) =
flP(S1 =

12

= 1,)P(S,

= ii)

(17)

forit=0,l.k=1,....T.
Direct maxinsizalion of the log of the likelihood function requires the evaluation of 2T terms in every
iteration

of mnaxiosization routine. It is

comnputationally intractable for any reasonable sample size. We

(15). For this problem, it eoosists of three nteps: (1) the
nonmination of starting values; (2) the evaluation of the expectation of the likelihood function, conditional
on tise current parameter estimates; and (3) the inaxinsization of the log likelihood's expectation. Tue
adopt the EM.algorithm to

snsaxinsize equation

algorithm is discussed in detail, an

it relates to thin

problem, in Appcndm.r A.

5.0 Rcsslts

The analysis

was carried out for monthly data from

Standard and Poor's index of 500 stock prices.

The series analyzed was the percentage nominal total return lens the three muonth T-bill rate of return,
i.e. the monthly excess return of the portfolio times 100. The period of estimation was fronm January 1946
through December

1987.

The results of the estimation for the suodel in which agents know the state are

the models
presented in Tables (1) and (2). Estimates from

in

which agents are uncertain of the states

o

Model

o

p

I 7.(i65

0.5983

(1.1118)

(0.1871)

I

II

13.3101

43.968!

P

lit

I'

'

-1138.73

-1.0762

0.8451

0.8641

(1.1515) (9.8076) (0.2075) (0.3987) (0.3359)
Model 1:
Model I!:

q

0.977!

-1423.69 0.0377

(0.0552)

Con ant Mean, Constant Variance
Markov Mean, Markov Variance

Sample Period: January 194C—Dcceniher 1987
Observations:

501

Table

1

Estittiation results for model in which agents know the stale in each period. Asymptotic standard
errors in parantheses.

are presented in Table (3). In Section 2.5.1 we will assess the implications the estimated model has for
heteroskedasticity in excess returns. In the following section we will examine the models' implications for
the risk premium.
5.1 Basic characlcrist.ics of the two state varmancc model
The basic hypothesis upon which this paper is founded is that there are two states in the volatility of

stock market returns, i.e. the density of excess returns is a mixture of two normals with different variances.
Fsmrther, the distribution of the state has a time dependent element. In t.his section we will test the
hypotheses of two states and time dependence.
IJnfortunatelv, the test of the hypothesis of only one stale forces p and q to the edge of their parameter
space: under the null one must be zero and the other unity. Under these conditions, the likelihood ratio

k

test is not asymptotically distributed
However, Wolfe (1971) suggests a modified likelihood ratio
statistic for testing tile hypothesis of a mixed mnultivariate normal distribution against the null of simple

10

stitiltivariate storusality. Is our sil uatsost the storistals are not sossltivariate,so the statistic simplifies to
A' =
where

(

is

;(T- 3X( - f0)

(18)

the log likelihood of the one state model, Model 1, iii Table (1), and is the log likelihood of the
statistic is asymptotically distributed 2 with two degrees of freedom.

full two stale model, Model 11. This

The valne of this statistic is

29.9010.

This value is significant at any reasonable level of signficance.

Unfortunately, simulat.ious Isv Eventt (1981) show that this test has low power unless liii — psi > 2.
Further, the jsower of the test has also been questioned for lieteroskedastic models such as ours.
Figure (2) plots

the probability

of the high variance

states conditional on all the data, J'(S, =

lips, y2
PT), for the full and sub—samples respectively. These posterior probabilities provide a visual
test of the mixture hypothesis. In general if the null hypothesis of simple normality is true, then the plots
of these probabilities should indicate uncertainty of the stale in usost periods. They should be relatively

at 0.5. There are few l)eniOds in the sausples in which the probability hover around 0.5.
The full sausple posterior is between 0.20 and 0.80 in only 18% of tbe sausple.
Statistically, the mixture usodel, Model II, requires that the two states be characterized by different
flat and centered

and/or different variances. The variances in the two states are very well defined. The high variance
state is suore than three times that in the low variance state. As will be discussed below, the standard
ssseans

error of this parauseter and all the high state parassseters are quite large. We may test the hupothesis
= o, while letting $ ie Despite the relatively large standard error of d? we usay reject the null at

p

a reasonable level of confidence, the t-statistic is 3.2024.

Though not as widely seperated as the variances,
test
of
the
the iueaus of the distributions are distinct. A
hypothesis that i's = Os against the alternative,
while letting a? ag, yields a t.statistic of -4.6375.
The estimates of the transition probabilities suggest the low variance state will predosuinate. The

estimates of the transition probabilities, p and q, of the Markov process suggest that the stationary, or
unconditional, probabilities of the states for the full sample will be 0.8557 and 0.1443 for for the low and
high variance states, respectively. Thus, for any given sample only about 14% of the observations will be
expected to fall into the high variance state.

c

* We may test the hypotheses
C, and p,
of the hypothesis that I — p = q = 0.

!ss however, we easisot test thesisJointly as this is equivalent

to a test

l.cngtli iii
Length (1
high Iarialtce Low I'anti lice
Lpisodes
Episode.c

lEigh I ariall c
L;,siodes
I ) > 0.5

P(5'

7 mont Its
A ugust- —September

April ---July

2 months

11146

1962

I)ecemiiber 111611

1

.1mw 11)70

Novemither 1117t--—F'eliruary 1075
Atigu sI 1986 -.J unitary 1987
Septeitiber-— l)ecemiiher 1987
eami

186

88

7

10

10

137

(i

7

4
(1.5 mont Its

77.5 muon) Im

5.0

64.0

Table 2
This table describes time posicrior (IiStflhUtiOii oft he state conditional on all the data in the
full sample. The first column lists the dates of the periods in which the probability of the high
variance state exeeded one half. The second columumi lists the length of these periods. The last
column lists the lengths of intervening periods in which t lie probability of the low state exceeded
one half.

The improbability of the high variance state niakes inference on high variance state parameters difficult. The sample size in estimating the high variance state parameters is, of course, dependent on the
number of observations that fall into the high variance state. Figure (2) show that there are relatively few
of these periods. More formally, Appcndcr A, shows that the sansple size in estimating these parametersis effectively
P(S1 = I y ,..-, yr) 64.7385 in this case. Thus, due to the relatively few periods in which

the high variance state is likely, we will not be able to estimate any of the parameters associated with it
precisely.
The point estimates of the probabilities p and q suggest a strong time dependence iii the Markov process
generating the states. However, the large standard error of suggests that p can lie almost anywhere
between 0 and 1. This possibility makes a formal test of time dependence in the model particularly
interesting. Recall that a binomial process is simply a Markov process wit-h p = 1 — q. A binomial process
removes the dependence of the probability distribution of the current- state on past states. Fortunately,

the null hypothesis of a hinonual is nested within the Markor and does not reijilire p and q to lie near the
boundaries of their possible values. We may reject t los liypot liesis, the t-statistic is 2.5603.
The point estimate of p suggests that
Since

once

in the high

variance state, the state is expected to persist.

j is greater then 0.5, in hot Ii 'lahle (1) and (2), the high variance state is expected to persist for at

least tss'o periods. More specifically, we wish to find the smallest value off for which

=

i.Si+ji = i,...,Ss+i =

= i) < 0.5,

(19)

j

the probability of remaining in tlie state i for cossecutive periods is less then one half. For our sunpie
first—order Markov process the number of periods, following lisuolton (1987A). is given by 1/)1 — F)
i=
i.e.

iS1 = ifl.

For

the logli variance state, s = I

so t list

j=

S

j

11)1 —

p), or 7.3586 months That is, once iii the

high variance state, the stock market is expected to stay in that state for about seven months. The loss
variance state is osnrh more persistent, setting

Note that as

i = 0, we then calculate j = 17(1

—

q), or 43.6205 mouths.

is near unity, small changes in it iosply large changes in the nsininiuisi value

off satisviug

(19).
The persistence of the states and general behavior of the stock nsarket is described in a non—parametric
way in Figure (2) and Table (2). They summarize the posterior distribution of the state in each period.
conditional on the entire sample used in estimation. Generally, these plots and tables indicate that both
states are persistent,and that the low variance state is very persistent.

It persisted, in expectation, without

break frons October 1946 until November 1962. fifteen and half years. Further, the probability of the high
variance state does not exceed 0.2 during the 1950's. This period heavily influences the estimates of p and
q.
5.2 Imphcalionsfor ihc risk prcnsiuni

II, where agents are assunsed

to know the state do not support an increasing risk
prensium. The parameter estimates indicate that agents require an increase in annual return over T-bills
of approximately11% to hold the risky asset in low variance periods. However, the estimates also suggest
Estimates of Model

the premium declines as the level of risk increases, i.e.
then

s, it is also significantlynegative.

ii c

j?s.

Further not only is

We can reject the hypothesis

Th significantly less

of a risk prensiumn increasing in the

variance. These parameter estimates are in agreement with those found by Schwert (1988) in his analysis

13

Aide]

5%

III

l3.0458
1.3023)

AIodl
IV

5%

52.996:!

0.33643032!

I'

V2

0.9728

1423.26

0.0056

(13.8229) (0.0097) (0.0261) (0.3048) (0.0370)

r
12.7085

0.8072

q

19.9850

no

°i

0.528

- 1.19:19

2.3802

Model

fl]

q
0.97211

'

I?.-

-1421.41 0.0454

(1.0119) (0.3142) (0.0618)

(1.5247) (16.2129) (0.2356) (0.5:140)
Alode]

P

0.8248

5 gj(ç arc ussure ol tie state
r\g(llt s learn about lie st(.e during the period

il:

Suiiiple Period:
Ol,seria (ions:

.lau nary

1946—-

December 1 !I$(

504

Table 1
Estimation results for the models in svhids agents are unsure of the states. In Mode! III agents
make trades based on a prior distribution of the state using last period's excess return. In Model
IV they make trades based on this prior and on a posterior distribution using trades during the

perod -

model.
of nominal returnsfrom stocks usingHamilton's (1987B)autoregressive

a likely explanation

for this result. If agents are uncertaits of the state, so that
Model III is the correct model, then estimates based on Model II will be inconsistent. Agents' expectation.
Mis—specification is

or forecast, of the state is P(S1 =

1

4'j ). If agents are uncertain of the state, then this model suffers.

from the usual error in variables problem since the forecast error, S5 — P(S1 = 1Ij._.i), is included on the
right, hand side in equations (8).

The parameter estimates for Model III, equations (9). are described in Table (3). They provide support
for a risk premium rising as the anticipated level of risk rises. In this nsodel, the level of risk is measured
by the probability of tile high variance state. This model predicts agents will require an annual return of
approxiniately 4%, if certain next. period's return will be drawn from the low variance density. For a one
percent increase in the probability of the high variance slate, agents require an increase in monthly return
Schwert's analysis was based on a different dataset. lie used stock prices beginning tn the mid—nineteenth century.

14

of 0.03%. Agents perceivetire stock market in the high variance state to ire very risky. if certain of tIre
high variance state, they require an annual ret urn of about 49%. However, I lie urrcorrditioaal probability
of tire high variance state is oniy 0.1236. 'I'his suggests tire risk preiniarri will average approximately 9(3
on air annual basis.
Tlrorrglr tire estimates of Model Ill are consistent with tireory, tire estimated model explains very little

of tire variance iii excess returns. Tire model always predicts a positive return, this its R2 is less tlren 0.6%.
Tbe reasorr wiry it caurrot predict a negative return is that tire specification ignores tIre news effect . Agents
acquire inrfornratiorr by observing trades during tire period. II agenrts don't krrow period I is drawn from tIre
of information is bad news. As agent s observe trades within period
high variance density, tiren this

isi

they sciH adjust their prior distribution of tire state arid revalue stocks dowuwarris. Likewise, if agent
don't know period t is drawn from the low variance density it is good news. They ucill adjust tireir prior
I

distribution of tire state and revalue their stocks upwards. Model IV gerreralizesthe case where agents are
unsure of tire state to allow learning during the period.
Note that Model IV also suggests tire direction of bias of the estimate of the risk prenrinur when agents
are assunrred to know the state. Estimnatiug Modei ii under tisis reginre would yield paraureter estimates
which smear the risk prensium and this news effect together. Since an increasing risk prenniuur and the
to be an upwardly biased estimate
news effect have opposite effects on excess returns, we would expect
of the risk premium and

jij to he a downwardly biased estimate.

The estimated results indicate that we have sorted out the risk premium and the news effect. In
general, tire signs on the parameters are as predicted in Section 2.3 and suggested above. The paranreters
3 and no are significantly greater than zero, while is signficantiy negative. The latter two paranreters
are aiso significantly different from each other, the t-atatistic is -2.9737. They capture the effect of the state

a

on the return of the stock during the period—the high variance state is bad news and the low variance
state is good news. The high variance state is very bad news. All else constant, the estimates predict that

the retsmrns from the stock market

on annual basis relative to the market for
or, greatly improves the fit. The fl2 rises to 4.5%.

will drop by more then 15%

T-bilis. Allowing for a news effeci, os

In the mrrodel agents are assunsed to know the parameters, thus we should expect that no matter how
large the fall in the market,a perfectly forseen high variance period should lead to a positive expectation
of the excess return. That is, we should expect

+ am > 0. The estimates indicate that such a period

15

leads o alt expected annual excess ret urn of 1 5'/i. Note however, due to

the large standard errors of the

high variance paraniets'rs this increase is not statisticallysignificant.
Recall froflt equation (12)

Seittoii

2.

is jiosi t ice.

that I tie risk

prenhlilIti is given by the expectation of

the excess return.

showed hat the risk preitliiiiit is increasing with lie anticipated variance if the derivative, (13)

'this

is trite if

—f

ill > ti5. 'Fite point estimates indicate that the risk prelniuni does increase

with the anticipated variance. Again due to the large standard errors of the high variance parameters this
increase is tot statistical! significant front zero. As with Model Ill, t lie nitcoitilittostal probability of the
Idght variance state ittay be used to derive the average risk pretitiulil . lit this case this probability is 0.1 ]38.

e

Emplovi itg I his sal a equation (12) t lie risk preilti nut is predicted to average a pproximatch 7.5% per
year for tie fit] and sub—sanipIes, respect i velv.
11(1

I

Ezaustining Figure (2) closely, it becomes appareuit that whenever the stock market enters the high
variance state, it falls. In the next. period it generally recovers more then it has lost. The parameter

Our usiodel provides a basis for understanding this behavior: The
probability of the higli variance state following a low variance state is quite small, so that agents are
is negative this leads to a big drop in the market. In the following period,
always surprised. Since

est.itti ates suntutarize t his teutdancy.

the probability of the high variance state is quite large, so that agents anticipate it, and collect their risk
preuiiiulfl. The estimates in Table (3) indicate the risk preuiuiuuut will nearly double in the period that is,
ci post, high variance, rising to 13.6%. This fact is made clear by Figure (3). This figure compares agents'
prior distribution with the posterior conditional on all the data. This econouuetrician's posterior leads the
agent's prior. That is, most periods in which the agents' jtrior gives significant weight to the high variance
state, follow periods in which the posterior gives weight to that state. In short, agents are often surprised
by the move-from low variance to high variance. They are not surprised if (he system remains in the high
variance state.
6.0 Conclusion
We have shown that an adequate model of the excess return from the stock market may be constructed
with a nsixt ore of normal densities with different means and variances. The heteroskedasticity that. this

mixtureimplies has a strong time dependence, suggesting that the conditional variance of the market can
be forecasted.

IU
Ibis result suggesls t

I lie umarket 's riskiness.

tat Ilie risk preiti11111 will itiove over time

Agents forecast of t lie imiarket'5 van

about tIme state gaued rlurimig

a mice

lii

resjmoiise to agents perception

of

is mutt always successful, so iiifonmimatiomi

periods is immiportamit to explaiuiug the overall return.

20
10

1

Figure
-10

Density Normal Corresponding with
0

Portfolio 500 Poor's & Standard from
Return Excess Postwar

-20

-30

0
0

0
0

c'J

LI-

Q.

E

C,)

0

C)

a)

CO

Cu

C)
>'

a)

a)
0 0

0

0

Co

0

d
0

d

c'J

w

C)
'C

(I,
C),
a)

cr

a)

C

0

0

cJ

0

0

0

0

(N

1950

1955

1960

Figure 2

yfl])

1970

P(S[t]=1 I y[1 ],y[2]

1965

1975

1980

Excess Return of Standard & Poor's Index
Posterior Distribution of the High Variance State

1985

a-

0ctl0

.0

>.

lJ

II

II

3 Figure
y[t-1]) P(S[tl=lIy[1] Prior:
..,y[TJ) P(S[t]=1y[1] Posterior:
1970
1965
1960

Prior

Posterior

Probability Posterior Econometrician's the with
State Variance High the of Probability Prior Agents'

1950

ci
0

ci

c'J
LI)

0
La
0

0
h

LU

P
0

0

0

.0
Ct
.0

BIBLIOGRAPHY
11a ii

iii. l,eon ard F., Ted Petrie,
0cm

George Smiles, and Norinan Weiss. (1970). "A M axi uncut ion Technique

ring iii t lie Statistical A nal sis of Probalnlist is- Fuuct tons of M arkoc Cliaius," 7/ic Annals of

AIat/iciuaticalStatistics,41, No. I, pp. 164-171.
Bollerslev, Tim., Robert

F'. Engle, and Jeffrey M. Wooldridge. (1987).

"A Capital Asset Model wit Ii

Titue—varvi ng Covari ances," Journal of Political Econstay 96. No.
Cossleti. Stephen R. and Lnng—FeiLee. (1985). "Serial Correlation

Journal of Econosuctncs, 27, pp.

1, pp. 116—Ill

in Latent Discrete Variable Models,'

79—97.

Engle, Robert F., David M. Lilien, and Russel P. Robins. (1987). "Estimating Time Varying Risk

Premiain the Term Structure: The ARCFI-M Model,' Econooictrica. 55, No.

2, pp. 391-407.

Everitt. D. 5. (1981). "A Monte Carlo Investigation of the LikelihoodRatio Test for the Number of
Components in a Mixture of Normal Distributions," Ma/tn'. Bc/tat'. Rcs.
Hamilton. James D. (1987A). "A New Approach to the Economic Analysis of Nonstationary Tune Series
and the Business Cycle," Econonicteica, forthcoming.
(1988). "Analysis of Time Series Subject to Changes in Regime," Unpublished Manuscript,

(1987B). "Rational—Expectations Econometric Analysisof Changes in Regime: An Investigation of
the Term Structure of Interest Rates," Unpublished Manuscript,
Lindley. D. V. (1984). Baycssan Statistics, A Rceira'. Society for Industrial and Applied Mathematics.
Little, Roderick 3. A. and Donald B. Rubin. (1987). Statistical Analystsa'sth Missing Data. John Wiley

&

Sons.

Pagan. Adrian and Ansan Ullah(1988). "The Econometric Analysis of Models with Risk Terms,"

Journal of Applzcd Econometrics. Vol. 3, pp. 87-105.
Schwert, C. \Villiam, (1988). "Business Cycles, Financial Crises, and Stock Volatility," Unpoblishcd
A-lannscczpt
(1987). "Why Does Stock Market Volatility Change Over Tinse?" ffnpvblsshcd Manuscript.

22

Ionaiio. .os

1t

\\ads\vllrtIt

1.

011(1

Aiidrtw F.

.'i—gal. (

IJ5).

( OIllll7l7 10(llj(i1

Ill

I'7ObOblIllV alIll

5l1l!t(lIe..

.' Ilrookl/( ((11.

oil of (lie I,ikeliliood lquaIiouis for Incomplete
l)al a from Exponent al l'aiutlies," ( o,lii000ieilllous is SIaI,sfies, B5 No, I, pp. i5 —6-I

Siiitilherg. llolf. ( 1976). 'Au

IIeF0I7V7 M(lIlO(l for SuIiiI

\'\olfe, 2. II. (1971). "A Monte Carlo Study of the Sanipliiig l)islriliutioii of the likelihood Ratio for
Mixtures of Mill iiioriiial Dist rihut.ioiis." Noval Personnel and l'rai uiitug Research Lahorator,
Techii,cal Ba//eli ii, STB—72—2.

A ppenilix A

MAXIMUM LIKELIHOOD ESTIMATION OF MARKOV MODELS
WITH THE EM-ALGORITHM
A. I hit codaction
As noted

iii the

body of die paper, direct itiaxinozation of the likelihood function as defined in

2

teriiis in every iteration, It is coiiipntstionaily jut ractalile
equation (2—15) requires the evaluation of
for sn' reasonside sample size. We employ t lie EM—algorithm to uiaxiuiize t lie likelihood tnnct <iii. The
algoritInn was developed from an old ad hoc idea for handling nnssmg data. (1) replace t lie isnssing
values by estimated values; (2) estimate the parameters; (3) re—estimate the missing values assuming the
est iniat ed values are correct; (4) iterate over (2) and (3) until convergence.Missing data niet liods are
relevant for our purposes because the states, Si, may be interpretedas flossing data.

'[lie algorithm differs from this technique in that the usissing values are not filled in, rather they
are replaced by sufficient statistics or, as in our case, the likelihood function is approximated in step (3).
This is called the E—step, or expectation step, while step (2) is the Al—step, or maximization step. A
good introduction to the algorithm is provided by Little and Rubin (1987). In general, if the underlying
distrihution is from an exponential distribution, each iteration of the algorithm will yield a higher value
of the likelihood, unless it is at a maximum. Denipster cL a!. (1977) show this for the general missing
data problem. Baumo.ct. aL (1970), shows the EM.algorithns maximizes the likelihood function if such
exists, when the data is a nsixture of exponential distributions and the underlying state is
generated by a Markov process. A basic problem with the algorithns is that its rate of convergence is
proportional to the usissiug information. As the missing state variable contains much information, the

a

muaximouns

algorithm's convergence will be

slow in our case. However, as will be denmonstrated below, the ease in

interpretation and coding make—up for the lack of speed in computation.
Scctmon A-2 presents the M—step for estinmation of the parameters of the Markov msiodel. We show that
the expected value of the likelihood function nmay be maxinsized by the simultaneous solution of normal
equations developed from the first—order conditions. The following section presents the E—step. \\'e derive
the distribution of the state conditional on the parameters. The final section combines these steps and
presents

time

formal EM—algorithm.

24

A. 2 lb

Pit

step: Itlaxiniriio likelilrisid estimates

of the

paraoreters when the rhistriloition of the state

is k noun
If the state were known in cacti period, t lien (lie likelihood function for each ohiservation

Yi

would

siiii ny lie givim by t lo' exp
—

'1' lie

Sr))cs,i/as)

error, ;,r, is given liv

p

=

ii

yr -Yr

For

hir(ci,i/ei).

-i

o

—

—

i&rr

—

ri

Model

Ii

Model

Ill

(A—I)

(A—2)

Model IV

i = 0. 1, and where r is a regressor coninroi to hot Ii states.

M axi

oization of the full likelihood with

respect to the paranieters is trivial.
However, we don't know the st ate.

lirior to observing the realization

If we knew the probability distribution of the state of the systeoi

Yr. t lien tire expected value of

yr

where P(81

=

tire likelihood for an observation is

P(Si = i)(c1,1/cj)

(A-2)

= 1). i = 0,1. is the prior probability of the state in period 1.

The log of the full expected

likelihood is £ =

in giThe first order conditionsfor maximizingthe likelihood for the model in which agents learn about the

state are given by

=
aa1

1=1

=

= i)d(c,/cj)(yi
P(Si
qrc'

I

—

))—1) =

0,

P(Sr = i)(eji/cj)(yi - o - 7X)(-r) =

Note that the posterior distribution of the state in period
P)Si

—

This suggests that the solutions to equations

i = 0,1.

(A—3) may be obtained

the weights
P(Sr

= iIyi),

= Co + C1,i

cT

(.4—3)..
0.

observing Pi is simply

= i)(c1,1/aj),

= iIyi) =

=

I upon

i = 0.1

(A-4)

by weighted least squares. Defining

i = 0,1
(A-5)

25

the first order con iiit us suggest

t lie normal eqnat toils

_j ('a,i
°

11 (.r

('situ

0

t

('i,

('11r1

('11r,

D1.r

Solving for tlie paraniet er esti itat en, sis,

at, and

,

t 5IYI

1s

(1

\

:

t'.yt

is of course, trivial.

Note that in the case when agents know the state, t lie appropriate normal
subset the equations (A—ti). These tony be solved to yield the estimates

h1)

T= l,
-2 =

(A—fl)

ilyñyt

= ilyt)

-'

equations are given by a

—
1
s—fl..

>_J
P(5 = lyt)(yt Th)2
—--—--—---—--—--,
=
—

i = 0.1

P(S1

Notethat the effectivesample size in equations (A—7) for state i is simply the sum of the weights,
P(S1 =
ijyi). Note also that lithe posterior distribution of the state variable is degenerate—if S1 is known with
certainty——then

the estimates take on the intnitively pleasing forms

t=0l
-

—

1V5,=i

(A-fl)
—2

07

=

ws,—(Yi

—
,

-s=0,1.

The parameterswhereagentsdon't know the state uoay he estimated in the same way.
For all three models the estimates of the parameters of the density in each state are not dependents
on the transition probabilities, p and q. This implies that the maximum likelihood estimates of the
probabilities conditional on the moaximnin likelihood estimates of the density parameters will be the same
as the unconditional estinmates. Thus, a two—step technique may be ensployed to maximize the expectation
of the likelihood function with respect to all of the parameters of the model. First, the appropriate nornmal
equations are solved to estimate the parameters of the density of fit- Second, the expected value of the
likelihood function is maximiuzed with respect top and q conditional on the estimates of density parameters.
Hamilton )1988) extends this method by deriving normal equations for the transition probabilities.

26

A. :t 'Ike

F'

steji' 'l'lie ihsti-iliitii,ri of the statC when the parameters are known

Wit ii real data, of course, tie tlmsiriliut iii oft lie state tilt he svstciti, , will (leverhe known. However,
Itayes t lieoretii niav lie eiiiployed to derive
II ecall

that Bayes t lieoremmi

soiiie paraiiiet er

f, (lien

is given

tie distribution

cotiditmomiai

oti a/I the parameters and t lie data.

h' (lie Is ic of coma! I tonal expectat oiis. That

the deiisi t v of t Iiat part! iet er

gi ccii an observationm is

f')

F(f');(91
——'—---—,

(A-9)

p(ytk)!i(f')df.

( A—b)

y)

P1

is, if we are interested iii

9,

where (lie uticoiiditional density ol 9 i given by
1(9 =

4'

it

is held

I + 1.

Bayes'

the parameter space of f'. It is customary to refer to p(f') as the prior density,
prior to t lie datuimi g,. Likewise, p(yt ) is the density posteriorto yi.
Where '4' is

In time series, (lie posterior (lensit.y in period
heorem for the (list ribnt ion of f' using bot I y and
p(y!yi.-t.ys) =

but (his is just.

I

becomes the prior density for period

y+t is gi vets by
x_p(y,yI')

as

(A—il)

p(y') x p(ys+il',yt)
p(ytiym) xp(y,)

x

p(f'Iym+i,yi) =

(A-12)

= (v(R/) x P(Ytf')\ p(yi+ilf',yt)

\

The parantheses

't)

I (t+sIi)

is just Bayes' theorem, so that

x p(yi+Ie',yt)
p(yt+i.y,) = p('J'Iyi)p(ym+i yt) —-

(A—13)

',

This equation is the basis for Bayesian sequential updating. When we have a posterior distribution of
based on observations Yi,yz ,yt— and we observe y, we may update it simply by allowing the posterior
distribution at time I to become the distribution prior to observing

In Markov models, when the parameterof interest is the state, Bayes theorens takes on an especially
tractable form. These iisodels are characterized by a finite number of states, in the case at hand two.
This results in a discrete prior distribution.

Furthermore, the distribution of the state is dependent

ottlv

ott t Ite

rt'alizetl stale itt t lie 1trevttots periotl. i'lie prevtotts state is uitkitowtt, ltttwever, we have its
t
t]y< ). t (tI,
(yt.y Mt t), front the previous attttltcatioit of

-

pttstei-ior dot rilttttittit, I'(S
Bayes Ilteitreut.

ilte prior tlistriltttttoit

will sitttjtly be last periods pttstenor tt1ttlated witlt the appropriate

ra ito ¶ ion jtrttltaItilitits

=

ily-t)

d5t_t =

J)P(St =ii-i)

(A-li)

1=1<

Nole that in tlte ittitial period, there is ito posterior front t lit' previous period. This ohservatioit is
most easily liattdled liv a.ssittttittg t hat the !vharkttv process logart inlinitely far into the past. Thus, the
prior distribution of tlte first oliservalion is siittttly the steady stale proltalithitydistrihsition of the state.

That is. t Its' Itrior for t lie first oltservat1011,

Mi,

IS

delised to be

P(55 = 1) = 2 — —
p q

P(So=0)=

2—p— q
('onditiostal on the state, Mt is distributed iid Normal. Thus the likelihood of Mt

is given by the set of

equations defined by the normal densities
pi(ytlSt = i.y5_1) =

= 0,1.

(ej s/srj).

whereas before e,1 is defined by equation (A—2).
The Marhov structure also siittplifies the structure of the the unconditional density of Pr, p(y). Due
to the discrete prior, the integral of equation (A—b) is replaced by the sutttntatiou
p(yilyt_1) = P(51 = 0Yr_t) x

= 0)

P(51

= flr_1) x pi(ytlSt =

1).

Note that weigltts ou the deusities sutrt to unity by definition, since P(St = up1..3), i = 0,1 is a well
defined distribution function. Thus, p(yrlyg_j) is sinsply a rstixed density: it is a proper density furtction
that integrates to one.
Simple application of Bayes theorem gives the posterior distribution of the state conditional ott inforutation through period t,
P(S5

= iy1_1) x ps(yr
p(yrIy_1)

r = i)

=0,1

We itow scant to ittitlate tins (list rihutittu to titid the distribution of the state cotitlittoital Ott the data

i

ltrttuglt tteriotl

'litat

i. we svislt to evaluate I itt

prttttaltility It( St

—

I IYT)

(A IS) be the prior tlist ri tittiott oft Ite state, and itptlate this tltstributioit fttr t
I lteoreitt. Suppose sve have terloruted the update tltcttuglt t

—1-

j

---

—I

We now let. expression

I, t + 2

'I' using Bayes

1. We wish to add observation

Ott, to

our 1tttsterior. 'l'lteit the cttittpotteuts of Bayes tlteoreitt are given by
It)St = I )Yt

Prior:
Likeliltood:

I) ncttitditiooal:

(A—19

)

f(yt+1St = 1, Yij—i)
Tht--lytj—i)

(A—20)
(A—21

Note t hat. tlte ttncottditioital distrihttt ion, expression ( A—21 ) may be derived by integrating the state out
of tlte likelihood. In general, the likelihood itself is difficult to evaluate. Recall that the data, Pt, is
uncorrelated except for the state and tltat the state is generated by a first order Markov proces. Tltis
implies that

=

ij-i ,..,St-Fi

= 11,51

=
(A-22(

= f)y+,ISt+-t =
for z = 0.1. Ve

can tlteit obtaiit tlte likelihood using the rule of elinsination,

=

1,y_) =

I

f)yt+St÷-i

>
'j_ 1=0

The expression P(St,.jI = 1j—I55

=

i

for = 0,1 is readily

AU we need do is follow the algorithns for updating the probability P(S1tconditional on

St

= 1.

(A—23)

= i5_t)P(Ss+.1
= '—iP5t =

evaluated using Bayes theoreiu.

= l1y5+t-), for It = 1,2

j—l,

That is,

= liSt = l,y(+k) =

= flS( = l.Ytt-)
x f)yt+dSi =

l,Si+t- =
=
f(yt+kISs 1,)'jt-t-)

Each component on the

right

1,y5.)

(A-24(

hand sideof equation (A—24) may be easily evaluated. The likelihood is

f(yt-i-t-ISt= I, Sst-

= 1'YI+J—2) = (cIs+k/c1).

(A—25)

The "unconditional" density of the new datum. Pitt- IS
f(yt÷tlSs =

l,Yt+t-i) = P)S1+t-iS1 = l,y(+k_I)(eI,s÷kIct).

(A-26)

24

Ii

alit. the iri,ir 1iroltaliilitv of t lie state,
- 11.5 - 1,Ytk ), is simply

i-—-

liSt:

I, contlit

na! ott .5 anti

(1- q)lt(5Nk

)

01St:

tie that a, i.e.
t'Ytk

t

lii expression

)

(A-27)

Bayes theorem for niaking infereuce ott the state repeatedly allows us to
evaluate eitoa t.ion ( A 22), and (lois tlie Ii keliltood . C) nce we have t lie Ii keliltood it is easy to evaluate (lie
unconditional dist riliut.ion of the state. Evaluating Bayes theorem is t lien just a matter of substitution.
Applying et1uat ion

( A -2-I ),

A. :TIie EM algorithm: Maxinoon Iikelihotul estiitisttes ut the parameters when the sltstrittstjou

of kit,

state is unknown
So far we have derived a met hod of suit aining naxinoutn likelihood est iniat es of t lie paruoneters of
the density function of each state and transition pruubabilities guru the probability slistrilout mu of I lie

state. We have also found a method of obtaining the probability of each state quu'cuu the parameters of
density functions and the transition probabilities. Conubiningthese two techniques auud iterating give us
the EM-algoritluo.
The combined algorithm is as follows: (1) Nominate estimates of the parameters. Denote the nouninated estimates, g[]. in Model Ii this is

=

(,u1.

,iç51.

21s1

a°I,pi5i. q15])

(A—28)

= l,2....,T conditional on the
(2) Use Bayes theorem to derive the probability distribution of St, I
parameter estimates i°1, P)S5 = iOhi,yT), i = 0,1: (3) Set the weights employed in the weighted least
squares estimation, equations (A—6) equal to the probabilities associated with the distribntton derived
by Bayes theorenu. Thns, we are asserting that the known prior distribution of the state in equation
is
suuu,Its-ft
ItT). Thus. the posterior distribution of equation )A—4) simply
(A—2) is P(St = ulyt

(4) Use the two-step estimation technique
discussed in Section 3.4.1 to obtain new estimates of the paranieters. Set 911 equal to the resulting estimates
=

1IYT). This is presented formally in Hamilton (1988).

of the parameters,

ii. g1ai, &i51,is1, E0]).

=
%\'here

i, etc... represent the maximum

(A—29)

likelihood estinuates of the parameters of Model II conditional

j

on the posterior distribution F) S = 39171), =

0, 1:

(5) Iterate steps (2) through (4) until an appropriate

:30

(oiivergelicc criteria is

iiiit .

Iii iiiir iiiiji1iiiii'iitat iiiii iii t!ti'

- N-•
Fills tecliiiiqne

fbi

Bayes theorem gives us
concerning t lie

st

Univ yields

lie

K

a!gs.irit !iiii

the stiijijiiitg ctiiiilit oii was ioet when

0.00!.

(A-30)

iiiaxiiiiiiiii likelihood estijijates of tIe

posterior ilist riloitioii

l(5 ijyfl,

i

=-

liaraineters hut application of
0,1. 'I'lus allows us to make inferences

ate of 1 lie sys! em, and to evalnate agents' prior distribution of the state.

