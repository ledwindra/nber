NBER WORKING PAPER SERIES

PROGRAM DESIGN AND STUDENT OUTCOMES IN GRADUATE EDUCATION
Jeffrey Groen
George H. Jakubson
Ronald G. Ehrenberg
Scott Condie
Albert Yung-Hsu Liu
Working Paper 12064
http://www.nber.org/papers/w12064
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
February 2006

We are grateful to Sharon Brucker, Charles Clotfelter, Anne Polivka, John Siegfried, Sarah Turner, Harriet
Zuckerman, and seminar participants at Cornell University, Penn State University, the Bureau of Labor
Statistics, the Association of Public Policy Analysis and Management, the NBER Higher Education Meeting,
and the ASSA Annual Meeting for useful comments. We thank the Andrew W. Mellon Foundation for
funding and the National Science Foundation for access to data from the Survey of Earned Doctorates. The
views expressed herein are those of the author(s) and do not necessarily reflect the views of the Andrew W.
Mellon Foundation, the National Science Foundation, the Bureau of Labor Statistics, or the National Bureau
of Economic Research.
©2006 by Jeffrey Groen, George H. Jakubson, Ronald G. Ehrenberg, Scott Condie, and Albert Yung-Hsu
Liu. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.

Program Design and Student Outcomes in Graduate Education
Jeffrey Groen, George H. Jakubson, Ronald G. Ehrenberg, Scott Condie, and Albert Yung-Hsu
Liu
NBER Working Paper No. 12064
February 2006
JEL No. I2
ABSTRACT
Doctoral programs in the humanities and related social sciences are characterized by high attrition
and long times-to-degree. In response to these problems, the Andrew W. Mellon Foundation
launched the Graduate Education Initiative (GEI) to improve the quality of graduate programs and
in turn reduce attrition and shorten times-to-degree. Over a 10-year period starting in 1991, the
Foundation provided a total of over $80 million to 51 departments at 10 major research universities.
We estimate the impact of the GEI on attrition rates and times-to-degree using competing risk
duration models and student-level data. The data span the start of the GEI and include information
for students at a set of control departments. We estimate that the GEI had modest impacts on student
outcomes in the expected directions: reducing attrition rates, reducing times-to-degree and increasing
completion rates. The impacts of the GEI appear to have been driven in part by reductions in entering
cohort size, improvements in financial support and increases in student quality.
Jeffrey Groen
Bureau of Labor Statistics
2 Massachusetts Avenue, NE
Washington, DC 20212-0001
groen.jeffrey@bls.gov
George Jakubson
Cornell Higher Education Research Institute
ILR-Cornell University
256 Ives Hall
Ithaca, NY 14853-3901
gj10@cornell.edu
Ronald G. Ehrenberg
Cornell Higher Education Research Institute
ILR-Cornell University
256 Ives Hall
Ithaca, NY 14853-3901
and NBER
rge2@cornell.edu

Scott Condie
Cornell Higher Education Research Institute
ILR-Cornell University
256 Ives Hall
Ithaca, NY 14853-3901
ssc37@cornell.edu
Albert Yung-Hsu Liu
Cornell Higher Education Research Institute
ILR-Cornell University
256 Ives Hall
Ithaca, NY 14853-3901

1. Introduction
Students pursuing a doctorate in the humanities face a long and challenging road. The
length of time it takes students to earn a doctorate in the humanities is longer than in any other
broad field of study (Hoffer et al. 2003). By the late 1980s, time-to-degree in the humanities had
risen 15-20 percent since the mid-1970s to a median figure of approximately nine years (Bowen
and Rudenstine 1992). Furthermore, doctoral programs in the humanities are characterized by
high attrition. Even in some of the most highly regarded departments in the country, it is
common for more than half the students who start a PhD program to leave without earning a
doctorate (Bowen and Rudenstine 1992).
Motivated by these trends, the Andrew W. Mellon Foundation launched the Graduate
Education Initiative (GEI) in 1991 to improve the structure and organization of PhD programs in
the humanities and related social sciences. Such changes were seen as necessary in order to
combat high rates of student attrition and long time-to-degree. In terms of these measures,
doctoral programs in the humanities fared much worse than programs in any other broad field of
study. While attrition and time-to-degree were deemed important in themselves, they were also
seen as indicators of the effectiveness of graduate programs. In the humanities, several
characteristics of doctoral programs were believed to contribute to high attrition and long
degrees, including a proliferation of courses, elaborate and sometimes conflicting requirements,
epistemological disagreement on fundamentals, and inadequate funding at the dissertation stage.
Finally, projections about faculty shortages in the late 1990s made the goal of reducing student
attrition particularly timely (Bowen and Sosa 1989, McMillen 1991).
Over a 10-year period, the Foundation spent a total of over $80 million on the GEI and
allocated the funds to 51 departments (or programs) at 10 major research universities. While the

1

amount of money was indeed substantial, equally important is how the money was spent. Earlier
research the Foundation undertook showed that simply giving money to students or institutions
was not likely to improve graduate programs (Bowen and Rudenstine 1992). For instance,
students in the humanities with generous, multi-year financial support from national fellowship
programs had completion rates and times-to-degree at about the same level as other students.
Furthermore, high attrition and long time-to-degree were the norm even at highly ranked (and
relatively well-funded) departments in the humanities.
The architects of the GEI determined that improvements in graduate education would
require changes within departments and their PhD programs. The assumption was that graduate
students had problems completing their degrees because programs had become unwieldy,
supervision was uneven, expectations were unclear, and support at the time that students needed
to finish their dissertations was scarce. In order to achieve changes within departments, the
Foundation shifted much of its appropriations from portable grants awarded to students to block
grants awarded to universities which then selected departmental recipients.
This paper estimates the impact of the GEI on attrition rates and time-to-degree. Our
analysis is based on systematic data on student progress collected annually from the departments
that participated in the GEI. The data allow us to track the progress of each student who started
PhD programs in participating (“treatment”) departments over a 21-year period spanning the
introduction of the GEI. To account for external forces (such as the job market for humanities
PhDs) that affect all PhD programs, the Foundation also identified a set of roughly comparable
departments to serve as a control group. The control departments provided similar data on
student progress but did not receive any funding from the Foundation under the GEI.

2

We use an evaluation design that takes account of pre-program differences between
treatment and control departments. Under our difference-in-differences strategy, the impact of
the GEI is identified from a comparison of the time trend in treatment departments’ outcomes to
the time trend in control departments’ outcomes. The collection of annual data allows us to
model the impact of the program in terms of year-to-year transition probabilities.
We estimate that, on average, the GEI had modest impacts on student outcomes in the
expected directions: reducing attrition rates, reducing time-to-degree, and increasing completion
rates. The overall impacts of the GEI appear to have been driven in part by reductions in cohort
size, increases in financial aid, and increases in student quality. We also find that more generous
financial aid has a larger impact on reducing attrition than on encouraging completion. While
the impact of aid on attrition is considerable, even the most generous financial-aid packages are
associated with considerable attrition. In other words, attrition decisions are not primarily due to
financial-support problems.
In addition to providing evidence on the GEI, our paper is significant because of the
methodology it applies to the study of student outcomes in graduate education. First, by using
data on all entrants to PhD programs, we are able to simultaneously model both reasons that
students exit their programs (drop out or completion). In contrast, most recent studies of
outcomes in graduate education do not treat the two risks at the same time and tend to focus on
one or the other (e.g., Siegfried and Stock 2001).1 Second, in our analysis of the impact of
financial aid on student outcomes, we use an instrumental-variables strategy to account for the

1

Two exceptions are Ehrenberg and Mavros (1995) and Van Ours and Ridder (2003). The methodology we employ
can also be applied to persistence at the undergraduate level; for an example of a related approach to undergraduate
persistence, see DesJardins, Ahlburg, and McCall (1999).

3

endogeneity of aid. This represents an improvement over previous research, which is subject to
critique due to the effects of unmeasured ability (Ehrenberg and Mavros 1995).
The remainder of the paper is organized as follows. The next section describes the
implementation of the program and describes the student-level data that were collected for the
purpose of our evaluation. Section 3 presents our econometric approach to estimating program
impacts. Section 4 presents results on estimated impacts, provides evidence on the mechanisms
underlying the impacts, and presents some robustness checks. Section 5 summarizes our
conclusions.
2. The Graduate Education Initiative: Implementation and Data Collection
2.1 Goals and Implementation
The GEI was designed so as to clarify expectations, rationalize programs, and increase
financial support. The premise was that students would be given a series of deadlines and that if
they met them, then they could be considered for funding. There were to be no guarantees of
funding; rather a competitive situation was supposed to prevail which would motivate all
students. It was assumed that making big departmental changes in graduate education would
take time and that the program could last as long as a decade. Each participating department
committed to the goals of the program and developed detailed strategies to achieve them.
Treatment departments allocated the vast majority of the Foundation’s grants to
individual graduate students on a competitive basis. In accordance with the goal of encouraging
students to move expeditiously through their programs, only students making good progress
towards their degrees were eligible for funding. In particular, students beyond their sixth year of
study were ineligible for funding. Foundation support was designed to address causes for delay.
Most departments identified three periods when such delays were like to occur: first, the

4

transition from coursework to the beginning of dissertation research; second, the “finishing up”
(or final year) of the dissertation stage; and third, summers (when students often lost
momentum).
Aside from changes in student aid, the GEI affected treatment departments through a
variety of structural and programmatic changes. Departments typically used small amounts of
the grants to fund program changes such as research colloquia and seminars on pedagogy that
contributed to the overall quality of their graduate programs. As a result, departments were
“committed not only to advancing the progress of students who may be supported by the
Foundation’s grants, but to establishing incentives, structures, and attitudes that will improve
their programs overall” (AWM Foundation 1991). While each department developed its own
proposal for addressing the goals of the GEI program, there was a large overlap in their
approaches. The “innovations” made by departments can be classified into several categories.
Table 1 presents the categories along with representative examples.
The Foundation intended the grants to supplement, rather than supplant, internal funds for
the support of graduate students in the treatment departments. As such, participating institutions
were required to maintain the real value of their levels of such internal support over the life of
the program.2 Treatment departments received roughly $150,000 per year on average from the
Foundation. On average, GEI funding represented about 8 percent of departments’ overall
budgets for student support.

2

Our analysis of data from department financial reports submitted to the Foundation suggests that participating
institutions did in fact meet this requirement. In treatment departments, the real value of internal support per student
increased by an average of about 2 percent per year over the life of the GEI program.

5

2.2 Treatment and Control Departments
The treatment departments come from ten universities: UC-Berkeley, Chicago,
Columbia, Cornell, Harvard, Michigan, Pennsylvania, Princeton, Stanford, and Yale. These
institutions were chosen because they had attracted the largest number of winners of portable
Mellon Graduate Fellowships in the Humanities and were therefore regarded as having unusually
strong doctoral programs in the humanities. Each of these institutions, in turn, identified four,
five, or six departments to participate in the program. Under the program, Foundation grants to
participating institutions began in the 1991-92 academic year and continued through the 2000-01
academic year.
The control departments were chosen after the program was under way. The first set of
controls was chosen from the participating institutions. During the first five years of the
program, the Foundation asked each participating institution to provide data for their
departments that were not already participating in the program. In the end, five of the ten
institutions agreed to provide data for at least some of these departments. The second set of
controls was chosen from non-participating institutions. In the mid-1990s, three universities –
UCLA, UC-San Diego, and North Carolina – agreed to provide data for particular departments.
Like the treatment departments, the control departments provided data for all entrants to their
PhD programs starting with the 1982 entering cohort. The control departments span a similar
range of fields as the treatment departments; however, the Foundation did not attempt to match
treatment and control departments along dimensions such as quality or size. Our evaluation
design accounts for the fact that treatment and control departments are not necessarily
comparable at the time the program was implemented.

6

Our evaluation is based on treatment and control departments in ten fields in the
humanities and related social sciences: Anthropology, Art History, Classics, Comparative
Literature, English, History, Music, Philosophy, Political Science, and Religion. The list of
departments in our study is given in Table 2. These departments accounted for 18 percent of all
PhDs awarded nationally in these fields from 1980 to 1991, according to data from the Survey of
Earned Doctorates. Among departments ranked in the top 10 of their field by the National
Research Council, our study departments represent a much larger percentage of PhDs awarded
nationally, 50 percent.3
Given the design of the study, especially the fact that the treatment was not randomly
assigned, it is useful to compare the treatment and control departments. We collected data on
three characteristics of departments from the 1995 National Research Council study of doctoral
programs (Goldberger et al. 1995): number of faculty, number of PhD students, and rank of PhD
program (based on the scholarly quality of the program faculty). Overall, treatment departments
are more highly ranked and larger, in terms of both faculty and PhD students. The typical
treatment department is ranked in the top 10, while the typical control department is ranked in
the second 10 (average rankings of 8.2 vs. 14.3). Treatment departments have slightly more
faculty (32.4 vs. 25.0) and many more PhD students (101.3 vs. 61.5) than do control
departments.
2.3 Description of Student-Level Data
The data used in this evaluation were collected from the institutions of the treatment and
control departments on an ongoing basis. The data cover all students who started PhD programs

3

Before the GEI was implemented, students in study departments finished their degrees somewhat faster than
students in other departments. The median number of years between entry to graduate school and the awarding of
the PhD was 10.1 years for PhDs awarded by study departments from 1980 to 1991 and 11.8 for other departments.

7

in study departments between 1982 and 2002. Overall, our data represent 22,994 students,
including 14,488 students from treatment departments and 8,506 students from control
departments.
The dataset includes detailed information on student progress and financial support. For
each year that a student is enrolled, the dataset indicates whether the student completed the year
and continued in the program, whether the student terminated graduate study during the year, or
whether the student graduated with a PhD during the year. Financial support information is also
recorded annually and covers four types of support (from internal and external sources):
fellowships, teaching or research assistantships, tuition grants, and summer support.
The dataset also includes a variety of student characteristics collected from admissions
files. Included among these characteristics are demographic variables such as gender,
citizenship, race and ethnicity; information on educational background including whether the
student had a master’s degree upon entry to the PhD program; and scores on the verbal and math
portions of the Graduate Record Examination (GRE).
While the GEI was implemented at a specific time (in the 1991-92 academic year),
students in treatment departments were differentially exposed to the GEI depending on their
entering cohort. The 1982-1985 entering cohorts had essentially no exposure to the GEI, the
1986-1990 cohorts had some exposure, and the 1991-2002 cohorts were fully exposed to the
GEI. Among students who had no exposure to the GEI (the 1982-85 entering cohorts), 53
percent graduated, 45 percent dropped out, and 3 percent were still enrolled 17 years after entry.
The bulk of attrition occurs in the first four years of enrollment, as shown in Figure 1. Among
dropouts in these cohorts, 30 percent dropped out in the first year and 69 percent dropped out in
the first four years. In terms of completions, the modal years for finishing the PhD are years 6,

8

7, and 8, which represent 49 percent of all completions in these cohorts. There is a significant
right tail in the distribution, with 10 percent of graduates in years 12-17.4
3. Econometric Approach
We estimate the impact of the GEI on student outcomes using a competing-risk duration
model. In the model, time is discrete and measured in years. We directly model student
transitions from one year to the next. Conditional on surviving to a particular year of enrollment,
students may continue on in their programs to the following year or exit their programs. In turn,
students may exit their programs as a result of one of the competing risks: attrition and
completion. Thus, there are three transition probabilities:
P1t = P[attrition in year t | survived through year (t-1)],
P2t = P[completion in year t | survived through year (t-1)], and
P0t = 1-P1t-P2t = P[continue in program through year t | survived through year (t-1)].
We specify these transition probabilities as functions of explanatory variables using a
multinomial logit form:
Pjt =

exp( xt′θ jt )

∑ exp( x′θ
t

kt )

, j = 0, 1, 2.

k

The vector of explanatory variables for a particular year is xt. We allow the parameters of the
model to vary freely across years. The sample of students used to estimate the model for a given
year is the sub-sample of students still enrolled at the beginning of that year. (For years 1-3 we
do not allow the completion option, so we simply have a binary logit model for continuation vs.
attrition.)
This model accommodates both time-varying and fixed explanatory variables. Our
baseline model includes explanatory variables for student gender, race/ethnicity, and citizenship.

4

Median (mean) time-to-degree is 8 (8.16) years and median (mean) time-to-attrition is 3 (3.98) years.

9

It also includes indicator variables for institutions and fields, in order to capture the effects of
institution-wide factors and field-specific factors such as differences in curriculum. In some
specifications, we also include indicators for the type of financial aid that each student had in
each year.
Three of the explanatory variables identify the effects of the GEI program. The variable
Treatment is an indicator variable that equals 1 for students in treatment departments and equals

0 for students in control departments. The variable Post is an indicator variable that identifies
when the GEI program is in effect; it equals 1 for observations in the treatment period and equals
0 for observations in the pre-treatment period. The definition of Post depends on a student’s
entering cohort as well as the year of enrollment. Students in cohorts 1982-1985 have Post = 0
for all years and students in cohorts 1991-2002 have Post = 1 for all years. Students in cohorts
1986-1990 have Post = 0 for years prior to 1991 and Post = 1 for years starting in 1991. The
third variable is the interaction between the other two variables: Treatment × Post . With these
variables, our estimated impacts of the GEI are identified from differential time trends for
students in treatment departments relative to those in control departments.
After estimating the model, we use simulations to express the program impacts in terms
of cumulative probabilities of attrition and completion.5 We start by considering a fixed set of
people for the simulations: students who entered treatment departments after the GEI was
implemented. For each student, we use his (time-invariant) characteristics (xt = x for all t) and
the estimated parameters to predict his transition probabilities (P0t, P1t, P2t) for each year of

5

An alternative approach to our duration framework is to specify the model with cumulative rather than transition
probabilities. We obtain roughly similar results with this alternative approach. However, we prefer the duration
framework because it is more flexible.

10

enrollment t, supposing that he survived to that year. Then we use these transition probabilities
to predict the probabilities of attrition (at), graduation (gt), and continuation (ct) in each year t:

⎡( t −1) ⎤
⎡( t −1) ⎤
⎡ t
⎤
at = ⎢∏ Poj ⎥ P1t , g t = ⎢∏ Poj ⎥ P2t , and ct = ⎢∏ Poj ⎥ .
⎣ j =1 ⎦
⎣ j =1 ⎦
⎣ j =1 ⎦
Finally, we compute cumulative probabilities of attrition (At) and graduation (Gt) by the end of
each year of enrollment:
t

t

j =1

j =4

At = ∑ a j , t=1-11; and Gt = ∑ g j , t=4-11.

For each student in the simulation sample, we predict two sets of these probabilities, one
with Treatment × Post = 1 and one with Treatment × Post = 0 . The difference between the two
sets of predictions reflects the effect of the GEI program. These probabilities vary across
students due to variation in the explanatory variables; our estimates are based on averages of
these probabilities over the set of students in the simulation sample. We also compute the impact
of the GEI on mean elapsed time-to-degree based on the average cumulative probabilities of
completion.6 We estimate standard errors for the estimated program impacts using a bootstrap
approach. In the bootstrap, we sample clusters of students based on department/cohort cells in
order to account for the fact that the identifying variation is across departments and across time.

6

The estimated impact on time-to-degree reflects the combination of two conceptually distinct impacts. The first is
the impact of the program on time-to-degree for students who would have graduated in the absence of the program.
The second is the impact on measured time-to-degree of changing the set of students who graduate. The first impact
is likely to be a decrease in time-to-degree. The second impact may be an increase or decrease in time-to-degree,
depending on whether the marginal students affected by the program have long or short times-to-degree.

11

4. Results

4.1 Overall Impacts
We present two sets of estimates from our baseline specification. The first set of
estimates treats the department as the central unit of analysis and reflects the impact for a typical
department. These estimates are relevant because the GEI was designed to affect entire
departments, not just students who received GEI funding. We obtain these estimates by
weighting each observation by the inverse of the size of the student’s entering cohort. In the
second set, our estimates reflect the impact for a typical student. We obtain these estimates by
giving equal weight to each student in the estimation. The two sets of estimates will differ to the
extent that the GEI had different effects in larger and smaller programs.
Appendix Table 1 presents the estimated coefficients on the Treatment × Post variable,
which is the key variable for identifying the impact of the GEI program. A null hypothesis that
the coefficients are zero in all years (jointly) can be rejected for attrition, but not for completion.
This result holds regardless of the weighting scheme.
The simulation results for the department-weighted version are shown in Figure 2. The
impacts on attrition are shown in the top left panel. There are two lines in this panel; each line
indicates the cumulative probability of attrition as of each year of enrollment, as predicted by the
model. The solid line shows the probabilities for treatment departments for the case with the
GEI program. The dashed line shows the probabilities for treatment departments for the
(hypothetical) case without the GEI program. Since the solid line is always below the dashed
line, the figure indicates that the program reduced attrition rates. The gap between the lines
indicates the magnitude of the program impact. For instance, the probabilities of attrition for
year 7 are 0.294 without the program and 0.267 with the program. The average impact over all

12

years is 0.029 (or 2.9 percentage points), as shown in Table 3. A comparison of the hazard rates
for the two groups, shown in the top right panel of Figure 2, indicates that the primary impact of
the GEI on attrition occurred in students’ first and eighth years of enrollment.
The impacts on completion are shown in the bottom left panel of Figure 2. In this case,
the solid line is always above the dashed line, indicating that the program increased cumulative
completion rates. To give an example, the probabilities of completion for year 8 are 0.402
without the program and 0.431 with the program. The average impact over all years is 0.018 (or
1.8 percentage points), as shown in Table 3. This translates into a reduction in mean time-todegree (as of year 11) of 0.119 years, or 1.4 months. The small impact on time-to-degree is not
surprising if the marginal students affected by the program have long times-to-degree. The
hazard rates in Figure 2 indicate that the primary impact of the GEI on completion was in years
6, 7, and 8 (the modal years of completion).
The estimated program impacts in the department-weighted version of our baseline
specification are in the intended direction but modest in magnitude. In contrast, the studentweighted estimates are smaller. The average impacts across years in the student-weighted
version are -2.0 percentage points for attrition, 0.5 percentage points for completion, and -.041
years for time-to-degree (Table 3). A comparison of the two sets of results suggests that the GEI
had larger impacts in smaller departments, which receive greater weight in the departmentweighted analysis than in the student-weighted analysis.7

7

This finding is confirmed by a variation on our model that allows the estimated program impacts to vary across
sub-groups of departments based on department size. We classified departments into three categories based on
average cohort size for the 1982-1990 entering cohorts, and the estimated program impacts were largest for the
small departments (those with an average cohort size of 7.5 or fewer).

13

4.2 Potential Mechanisms
In addition to measuring the size of the impacts, it is critical to understand the
mechanisms by which the GEI influenced outcomes. While this is a challenge in any evaluation,
it is particularly difficult here because each department implemented the GEI somewhat
differently. Furthermore, implementing the GEI was a dynamic process involving extensive
experimentation at the departmental level. In this section, we explore the role of cohort size,
student quality, and financial aid in explaining the measured impact of the GEI.
We evaluate the role of these potential mechanisms in a two-step process. First, we
estimate the impact of each variable on student outcomes by including it among the explanatory
variables in our duration model. For this purpose, we use a simplified version of our model in
which the dependent variable represents the cumulative probabilities of attrition, completion, and
continuation for year 8. Second, we estimate the impact of the GEI on each variable by using it
as the dependent variable in a linear regression with Treatment , Post , Treatment × Post ,
institutional indicators, and field indicators as explanatory variables. The estimated impacts for
this second step are reported in Table 4. The impacts for the first step are reported in Table 5 as
average marginal effects on the probabilities of attrition and completion.

Cohort Size and Student Quality
Reducing the size of entering cohorts was often an explicit goal of treatment departments.
The logic was that with smaller cohorts, departments could concentrate their faculty and
financial resources on fewer students and each student would have a better change at success.
We find that the GEI did in fact lead to a decrease in cohort size. According to the point
estimate in Table 4, the GEI reduced cohort size by 2-3 students. A comparison of means (not
shown) reveals that cohort size fell over time in both treatment and control departments and the

14

reductions occurred primarily in the larger departments. In addition, we find that cohort size
increases the probability of attrition but has almost no impact on the probability of completion
(Table 5).
The reductions in cohort size, together with increases in financial support from the GEI,
would be expected to lead to increases in the quality of students who enrolled in treatment
departments. We find some evidence of this in GRE scores. We estimate that the GEI increased
GRE verbal scores by about 10 points on average; however, we find no impact on GRE math
scores (Table 4). We also find that higher GRE verbal scores are associated with lower attrition
(Table 5); thus, the change in GRE scores can explain some of the measured impact of the GEI
on attrition.8
Another indicator of student quality, the share of students who held a master’s degree at
the start of their PhD program, decreased because of the GEI (Table 4). This change is
consistent with the change in GRE verbal scores, since students with a prior master’s degree
have lower GRE scores than other students. However, having a prior master’s degree is a strong
predictor of success in a PhD program; we estimate that it lowers the probability of attrition by
13 percentage points and increases the probability of completion by 11 percentage points (Table
5). Thus, the reduction in the share of students with a prior master’s degree worked against the
goals of the GEI.
One way to summarize the role of changes in student quality and cohort size in the GEI
is to include them as control variables in our duration model and see how this changes the

8

Interestingly, the results in Table 5 show differences between the GRE verbal and math scores as predictors of
student outcomes. Higher GRE verbal scores decrease the probability of attrition but have no impact on the
probability of completion. By contrast, higher GRE math scores increase the probability of completion but have no
impact on the probability of attrition. These results point to differences in the skill requirements between the
coursework and dissertation stages.

15

measured impact of the GEI. Doing this decreases the estimated impacts of the GEI somewhat
(Table 3). This indicates that reductions in cohort size and increases in student quality can
explain a small part of the impact of the GEI.

Financial Support
Another route through which the GEI might have been expected to influence times-todegree and attrition rates is through the improvements in financial support that it enabled
departments to provide to students enrolled in their programs. Overall, the GEI appears to have
led to an increase in financial support. We find that the share of students with academic-year
fellowships, assistantships, and summer support increased by more at treatment departments than
at control departments (Table 4). However, the GEI led to a decrease in average stipends for
assistants at treatment departments relative to control departments. This suggests that control
departments may have responded to the GEI program by increasing their own financial support
for graduate students in order to remain competitive in the quest for top students.
We examine the impact of aid on student outcomes by including indicators for each type
of aid (fellowship, TA/RA, tuition grant, summer support) in the duration model.9 We use
simulations to examine the impact of aid on cumulative probabilities of attrition and completion.
We follow the basic structure of our earlier simulations but make some changes because
students’ financial-aid packages can vary across years of enrollment. We consider several
hypothetical financial-aid profiles and compare outcomes across profiles. Each profile contains
a financial package for each year of enrollment from year 1 through year 6; after year 6, all
profiles contain no aid of any type. In the simulation for a given profile, we assign the profile to

9

In this version of the model, we include cohort size and student quality measures among the explanatory variables,
but do not include the set of three variables that identify the effects of the GEI program.

16

all students and then use the estimated model to predict cumulative probabilities of attrition and
completion for each year of enrollment. We then take averages of these probabilities across
students to produce a path of probabilities by year of enrollment for each financial-aid profile.10
A potential problem with this model is that the measured relationship between aid and
student outcomes reflects unobserved student ability as well as the true impact of aid. This is a
possibility if financial aid is awarded systematically to students who have lower expected
probabilities of attrition and/or higher probabilities of completion. Therefore, we use an
instrumental-variables (IV) strategy with the instruments based upon two sets of variables. The
first set measures a student’s GRE scores relative to the average in her department, cohort, and
year of enrollment. The second set is the proportions of students receiving each type of aid in
the department, cohort, and year of enrollment.11 Our IV strategy is an improvement over
previous research, which is subject to critique due to the effects of unmeasured ability
(Ehrenberg and Mavros 1995).
Table 6 summarizes the simulation results for each profile with cumulative probabilities
of attrition and completion by the end of particular years. The first four profiles are prototypes:
each has a single type of aid for years 1-6. For example, the first profile has no aid and the
second profile has a tuition grant. Comparing these profiles indicates that having a tuition grant
lowers attrition by year 2 by 26.7 percentage points and by year 4 by 23.0 percentage points.
The figures on completion indicate that having a tuition grant raises the probability of

10

These simulations are similar in sprit to the approaches taken by Ehrenberg and Mavros (1995) and DesJardins,
Ahlburg, and McCall (2002).

11

For a given student in a department/cohort/year cell, the proportions are computed using data for students in the
cell except the given student. We limit the sample to department/cohort/year cells where at least 80% of the
observations have complete data on the financial-aid and student-quality variables and to observations within these
cells that contain complete data on those variables. We implement our IV strategy in two steps. First, we estimate
linear regressions of each aid variable on the instruments and the other exogenous variables. Second, we include
predicted values from these regressions among the independent variables of our duration model.

17

completion by year 7 by 6.5 percentage points. Figure 3 presents a graphical comparison of
student outcomes across the four profiles.
The general pattern in the comparison of the prototypes is that more generous financial
aid reduces the probability of attrition and increases the probability of completion. This finding,
together with the evidence that the GEI led to an increase in aid, suggests that financial aid is an
important mechanism in accounting for the estimated impacts of the GEI on student outcomes.
In addition, the analysis of financial aid reveals some more general findings. First, while more
generous aid reduces the probability of attrition, even the most generous financial-aid packages
are associated with considerable attrition. This result points to the role of factors other than
financial support problems in accounting for attrition from doctoral programs. Second, more
generous aid has a larger impact on reducing attrition than on encouraging completion. This
result points to differences between the coursework stage and dissertation stages of PhD
programs.
The remaining profiles in Table 6 form the basis for more subtle comparisons of the
timing and mix of financial aid. These are examples of the types of funding decisions that
departments are likely to face in practice. These comparisons suggest that the timing of a
teaching or research assistantship is crucial. Having an assistantship in the early years of PhD
programs (compared to having a fellowship) increases attrition, but having an assistantship in the
middle years does not increase attrition or discourage completions. Another comparison
suggests that summer support does not reduce attrition or encourage completions.
To summarize our findings in this section, we find some evidence that increases in
financial aid, reductions in cohort size, and increases in student quality can account for part of
the impact of the GEI on student outcomes. In a related paper, we examine the impact of the

18

GEI on more detailed measures of departmental characteristics, including advising, course
requirements, and department culture (Ehrenberg et al. 2005). These descriptions come from a
recent survey of students who started PhD programs in treatment and control departments
between 1982 and 1997. The findings in that paper suggest that the GEI reduced attrition rates
and improved completion rates through the routes of improving clarity of departmental
expectations and encouraging students to finish their dissertations as quickly as possible.

4.3 Robustness Checks
Our estimated impacts of the GEI on student outcomes may understate the true impact of
the GEI due to treatment contamination. Generically, treatment contamination exists in an
intervention when some of the controls are affected by the treatment. To the extent that this
occurs, the affected controls are not suitable for use in the evaluation. In this study, the most
plausible case of treatment contamination is that control departments in participating institutions
(i.e., institutions with treatment departments) were directly influenced by the GEI program. Five
universities in the study have both treatment and control departments: Cornell, Michigan,
Princeton, Stanford, and Yale (see Table 2). Control departments at these institutions could have
been affected by the program through at least two channels. First, institutions could have
responded to the increased external support in treatment departments by reallocating internal
funding towards control departments. Second, control departments could have mimicked
structural changes that were being made by treatment departments.
We test for contamination by distinguishing between control departments at participating
and non-participating institutions. We add variables to our baseline model that allow us to
produce two sets of program impacts based on the time pattern of student outcomes in treatment
departments relative to (1) control departments in participating institutions or (2) control

19

departments in non-participating institutions.12 If contamination exists, the introduction of the
GEI should be associated with similar changes at treatment departments and control departments
in participating institutions. In this case, the measured impact of the GEI using control
departments in participating institutions would be smaller than the measured impact using
control departments in non-participating institutions.
The results of this test are shown in Table 7. Using control departments at participating
institutions as the comparison group for treatment departments produces estimates of program
impacts that are larger than (in the case of attrition) or about the same as (in the case of
completion) estimates using control departments at non-participating institutions. Thus, the
results provide no evidence for this form of treatment contamination. Of course, changes that
may have occurred at treatment departments to improve their graduate programs may have been
known to control departments at non-participating institutions as well. This in turn may have
caused these departments to make similar changes in their programs for competitive reasons. If
this were true, all control departments would be somewhat affected by the GEI and our estimates
would represent lower bounds on the true effects of the GEI on student outcomes.
Another reason that our estimates may understate the true impact of the GEI is that the
changes took place gradually over time. Treatment departments envisioned big changes in their
departments and that is one reason the Foundation funded the GEI for ten years. With changes
taking place gradually over time, students in the initial cohorts that were exposed to the GEI may
not have been affected very much, but students in later cohorts may have been affected more.
We test for this by re-defining the timing of program introduction from the simple pre/post

12

In addition, we drop the institutional indicators from the model. We cannot include them in the contamination
model because in some fields there is only a single department of a given type of control. However, omitting these
variables from our baseline model has only a small effect on the measured impact of the GEI (see Table 7).

20

definition to one involving three time periods. In treatment departments, the 1982-1985 entering
cohorts had essentially no exposure to the GEI, the 1986-1990 cohorts had some exposure, and
the 1991-2002 cohorts were fully exposed to the GEI. Estimated program impacts for the fullyexposed cohorts are much larger than for the transition cohorts (Table 7). This supports the
presumption that structural change was a gradual process in treatment departments and the
impacts of this change (as well as the direct impact of financial aid) increased with exposure.
Relative to the impacts from the baseline model, the estimated program impacts for the fullyexposed cohorts are about one-third larger.
5. Conclusions
The Graduate Education Initiative was a ten-year program of funding from the Andrew
W. Mellon Foundation to improve the structure and organization of PhD programs in the
humanities and related social sciences, and in turn to reduce high rates of student attrition and
long time-to-degree. This paper provides estimates of the impact of the GEI on student
outcomes using detailed student-level data for 21 cohorts of students spanning the introduction
of the GEI.
We estimate that, on average, the GEI had modest impacts on student outcomes in the
expected directions: reducing attrition rates, reducing time-to-degree, and increasing completion
rates. The overall impacts of the GEI appear to have been driven in part by reductions in cohort
size, increases in financial aid, and increases in student quality. Prior to the GEI, the typical
department in our study had an attrition rate of 42 percent and a completion rate of 48 percent
(by year 11). According to our point estimates, the GEI reduced the attrition rate in a typical
department by 3 percentage points (e.g. from 42% to 39%) and increased the completion rate by
2 percentage points (e.g. from 48% to 50%). However, these estimates may represent lower

21

bounds on the true effects due to the possibility of treatment contamination and competitive
responses by control departments.
In addition to assessing the GEI, our paper has also provided more general evidence on
several aspects of graduate education in the humanities. For example, we find that more
generous financial aid has a larger impact on reducing attrition than on encouraging completion.
While the impact of aid on attrition is considerable, even the most generous financial-aid
packages are associated with considerable attrition. In other words, attrition decisions are not
primarily due to financial-support problems.
An important subject for future research is the influence of the academic job market on
completion rates and times-to-degree. It is believed that the job market provides students with
strong incentives to finish their dissertations (Breneman 1976). In a strong job market, the
opportunity costs to remaining enrolled are large; conversely, a weak job market may induce
students to delay completion in order to polish their dissertations to better compete for scare
positions. If the job market does in fact exert a strong influence on completion rates and timesto-degree, reform efforts (such as the GEI) that primarily involve changes to doctoral programs
may not have large impacts on student outcomes.

22

References
Andrew W. Mellon Foundation. 1991. “Foundation Announces Major New Program in Graduate
Education.” Press Release, March 25.
Bowen, William G. and Neil L. Rudenstine. 1992. In Pursuit of the PhD (Princeton, NJ:
Princeton University Press).
Bowen, William G. and Julie Ann Sosa. 1989. Prospects for Faculty in the Arts and Sciences
(Princeton, NJ: Princeton University Press).
Breneman, David W. 1976. “The PhD Production Process.” In: Joseph T. Froomkin, Dean T.
Jamison, and Roy Radner, eds. Education as an Industry (Cambridge, MA: Ballinger), pp. 3-52.
DesJardins, Stephen L., Dennis A. Ahlburg, and Brian P. McCall. 1999. “An Event History
Model of Student Departure.” Economics of Education Review 18: 375-390.
________. 2002. “Simulating the Longitudinal Effects of Changes in Financial Aid on Student
Departure from College.” Journal of Human Resources 37 (Summer): 653-679.
Ehrenberg, Ronald G., George H. Jakubson, Jeffrey Groen, Eric So, and Joseph Price. 2005.
“Inside the Black Box of Doctoral Education: What Program Characteristics Influence Doctoral
Students’ Attrition and Graduation Probabilities?” Working Paper 83, Cornell Higher Education
Research Institute.
Ehrenberg, Ronald G. and Pangiotis Mavros. 1995. “Do Doctoral Students’ Financial Support
Patterns Affect Their Times-to-Degree and Completion Probabilities?” Journal of Human
Resources 30 (Summer): 581-609.
Goldberger, Marvin L., Brendan A. Maher, and Pamela Ebert Flattau, eds. 1995. Research
Doctorate Programs in the United States: Continuity and Change. Committee for the Study of
Research-Doctorate Programs in the United States, National Research Council (Washington, DC:
National Academy of Sciences).
Hoffer, Thomas B., Scott Sederstrom, Lance Selfa, Vince Welch, Mary Hess, Shana Brown,
Sergio Reyes, Kristy Webber, and Isabel Guzman-Barron. 2003. Doctorate Recipients from
United States Universities: Summary Report 2002. Chicago: National Opinion Research Center.
McMillen, Liz. 1991. “Mellon Foundation Plans to Spend $50-Million over 5 Years to Improve
Doctoral Education.” Chronicle of Higher Education, April 3, p. A29.
Siegfried, John J. and Wendy A. Stock. 2001. “So You Want to Earn a Ph.D. in Economics: How
Long Do You Think It Will Take?” Journal of Human Resources 36 (Spring): 364-378.
Van Ours, J.C. and G. Ridder. 2003. “Fast Track or Failure: A Study of the Graduation and
Dropout Rates of PhD Students in Economics.” Economics of Education Review 22: 157-166.

23

Table 1. Innovations in Graduate Education Initiative
Category of Innovation

Examples

Clarification of expectations

Establish clear deadlines for tasks

Monitoring progress

Yearly progress review by Director of Graduate Studies
Required to submit progress reports while writing dissertation

Group workshops/colloquia

Required seminars on prospectus preparation
Optional brown bag lunches/seminars to encourage esprit de corps

Dissertation writing workshops

Required meetings with fellow students during writing stage
Required to present chapters to seminars

Curricular changes

Streamline curriculum and reduce requirements
Change format of comprehensive exams

Methods of enforcing deadlines

Funding conditional on being “on time”
Change in policy on “incomplete” grades

TA-related changes

Ineligible for TA position if prospectus not completed by 4th year

Reduction of size of entering cohort

Accept fewer students in a given class

Make better use of summers

Define tasks students expected to accomplish during summer
Fund students for specific tasks during summer

Faculty/staff resources

Establish a placement director
Fund a language teacher to prepare for language exams

Funding conditional on timely progress

Eligible for summer funding to prepare for comprehensive exam
only if met deadline for coursework
Eligible for 6th year fellowship funding to write up research
results only if bulk of research was completed by end of 5th year

24

Table 2. Treatment and Control Departments in Study
Field
Anthropology

Treatment
Columbia, Harvard, Princeton,
Stanford, Yale

Control
Cornell, North Carolina, UCLA,
UC-San Diego

Art History

Harvard, Michigan, Princeton,
UC-Berkeley, Yale

Cornell, Stanford, UCLA

Classics

Michigan, Pennsylvania,
UC-Berkeley

Cornell, North Carolina,
Princeton, Yale, UCLA

Comparative Literature

Cornell, UC-Berkeley

Princeton, Michigan, UCLA, Yale

English

Chicago, Columbia, Cornell,
Harvard, Michigan, Pennsylvania,
Stanford, UC-Berkeley, Yale

Princeton, UCLA, UC-San Diego

History

Chicago, Cornell, Michigan,
Pennsylvania, Princeton, Stanford,
UC-Berkeley, Yale

North Carolina, UCLA,
UC-San Diego

Music

Columbia, Pennsylvania, Yale

Cornell, Michigan, Princeton,
Stanford, UCLA, UC-San Diego

Philosophy

Chicago, Columbia, Stanford

Cornell, North Carolina, UCLA,
UC-San Diego, Yale

Political Science

Chicago, Cornell, Harvard,
Princeton

North Carolina, Stanford, UCLA,
UC-San Diego, Yale

Religion

Columbia, Harvard

Princeton, Stanford, Yale

Note: Overall, there are 44 treatment departments and 41 control departments in the study.

25

Table 3. Estimated Impacts of the GEI on Student Outcomes
A. Baseline model

Attrition
Completion
Time-to-degree

Weighting
Dept/Cohort
Student
-.029
-.020
(.016)
(.014)
.018
.005
(.015)
(.013)
-.119
-.041
(.100)
(.084)

B. Baseline model with additional controls: cohort size and student quality

Attrition
Completion
Time-to-degree

Weighting
Dept/Cohort
Student
-.026
-.014
(.016)
(.014)
.015
.003
(.015)
(.013)
-.104
-.062
(.098)
(.081)

Notes: Results labeled “Student” are from unweighted regressions on student-level data; those
labeled “Dept/Cohort” are from regressions on student-level data weighted by the inverse of
cohort size. The first number in each cell is an average (over years of enrollment) program
impact on the cumulative probability of attrition or completion; for time-to-degree, the first
number is the program impact on the average number of years between entry to the PhD program
and the awarding of the PhD (for those who finished in 11 years or less). The second number in
each cell is a bootstrap standard error that is based on 1,000 replications and accounts for
clustering of students by department and cohort.

26

Table 4. Changes in Cohort Size, Student Quality, and Financial Aid

Cohort Size

Sample
Mean
13.2

GRE Verbal

666.2

GRE Math

635.9

Prior Master’s Degree

0.26

Fellowship

0.48

TA or RA

0.40

Tuition Grant

0.62

Summer Support

0.20

Any Aid (excl. summer)

0.71

Fellowship Amount

$7,655

TA/RA Amount

$6,895

Tuition Grant Amount

$9,569

Program
Impact
-2.166
(1.619)
9.650
(6.405)
-3.740
(6.317)
-0.111
(0.039)
0.053
(0.035)
0.050
(0.033)
0.003
(0.039)
0.034
(0.036)
0.039
(0.038)
$366
($374)
-$1,423
($335)
-$656
($337)

Notes: Each row comes from a separate regression. All amounts are in 1991 dollars. Analysis of
amounts is based on observations with positive amounts only. Standard errors are in parentheses
and account for clustering of student observations by department and pre-/post-GEI.

27

Table 5. Effects of Explanatory Variables on Student Outcomes

Cohort Size
GRE Verbal / 100
GRE Math / 100
Prior Master’s Degree
Female
Non-U.S. Citizen
U.S. Citizen, Non-White

Impact on
Pr(attrition)
0.0023
(0.0006)
-0.0207
(0.0053)
-0.0077
(0.0045)
-0.1262
(0.0094)
0.0155
(0.0077)
-0.0632
(0.0112)
0.0242
(0.0128)

Impact on
Pr(completion)
-0.0010
(0.0006)
0.0104
(0.0052)
0.0225
(0.0045)
0.1140
(0.0103)
-0.0304
(0.0077)
0.0888
(0.0119)
-0.0362
(0.0119)

Notes: The first number in each cell is the average marginal effect of the characteristic on the
cumulative probability of attrition or completion. The second number in each cell is the
associated standard error. The results are based on a cumulative probability model with
outcomes as of the 8th year of enrollment. Student weighting is used for all characteristics
except cohort size, which is based on department/cohort weighting. As of the 8th year
enrollment, 37% had graduated, 37% has dropped out, and 26% were continuing.

28

Table 6. Impact of Financial Aid on Attrition and Completion
Financial Aid Profile (Years 1-6)
Fellowship
TA/RA
Tuition
Summer
[Prototypes]
1.
----2.
--1-6
-3.
-1-6
1-6
-4.
1-6
-1-6
-2-1 Tuition vs. No Aid
3-2 TA/RA vs. Tuition Only
4-3 Fellowship vs. TA/RA
[Impact of Summer Support]
5.
1-2,5-6
3-4
1-6
-6.
1-2,5-6
3-4
1-6
2-3
Diff
[Fellowship vs. TA in Middle Years]
7.
1-6
-1-6
-8.
1-2,5-6
3-4
1-6
-Diff
[Timing of TA, Early vs. Late]
9.
1,4-6
2-3
1-6
-10.
1-3,6
4-5
1-6
-Diff

Pr(attrition)*100
2
4
7

Pr(completion)*100
6
7
9

40.4
13.7
15.3
8.4
-26.7
1.6
-6.9

47.6
24.6
22.9
17.8
-23.0
-1.7
-5.1

52.4
33.6
29.1
28.9
-18.8
-4.5
-0.2

13.9
16.3
18.1
12.3
2.4
1.8
-5.8

22.9
29.4
31.9
27.7
6.5
2.5
-4.2

34.1
45.8
49.2
47.0
11.7
3.4
-2.2

8.4
8.4
0.0

16.6
17.8
1.2

27.7
28.7
1.0

13.5
13.3
-0.2

28.8
28.5
-0.3

48.1
47.5
-0.6

8.4
8.4
0.0

17.8
16.6
-1.2

28.9
27.7
-1.2

12.3
13.5
1.2

27.7
28.8
1.1

47.0
48.1
1.1

11.7
8.4
-3.3

19.2
18.1
-1.1

30.1
27.8
-2.3

12.1
14.3
2.2

27.3
29.4
2.1

46.2
48.4
2.2

Notes: Figures in table are cumulative probabilities of attrition or completion (multiplied by 100) by the end of particular years of
enrollment. All profiles involve no aid for years 7-11. Results based on student-weighted model with instruments for aid, as
described in the text.

29

Table 7. Impact of the GEI on Outcomes: Robustness Checks

1.

Weighting: Dept/Cohort
Time to
Attrition Completion
Degree
-.029
.018
-.119
(.016)
(.015)
(.100)
-.026
.019
-.136
(.018)
(.017)
(.109)

Baseline (Table 3)

1a. Baseline without Institutional Indicators
2.

Contamination Model
Treatment vs. Controls in Participating Institutions
Treatment vs. Controls in Non-Participating Institutions

3.

Timing of Program Introduction
Post-GEI Cohorts (1991-2002) vs. Pre-1986 Cohorts
Transition Cohorts (1986-1990) vs. Pre-1986 Cohorts

-.041
(.029)
-.011
(.020)

.014
(.023)
.019
(.025)

-.091
(.149)
-.086
(.168)

-.039
(.025)
-.007
(.021)

.024
(.018)
.009
(.017)

-.111
(.117)
-.145
(.112)

Notes: The contamination model does not include institutional indicators. For a description of
weighting, point estimates, and standard errors, see the notes to Table 3.

30

Figure 1. Distribution of Attrition and Completion for Pre-Program Cohorts
A. Attrition

Percent of Students

30

20

10

0

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16 17

Year of Attrition

B. Completion

Percent of Students

20

10

0

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16 17

Year of Completion

31

Figure 2. Program Impacts on Attrition and Completion
Cumulative Probabilities

Hazard Rates
A. Attrition
.1

Conditional Prob. of Attrition

Probability of Attrition

.4

.3

.2

.1

0

.08

.06

.04

.02
1

2

3

4

5
6
7
Year of Enrollment
Program

8

9

10

11

1

2

3

4

Non-Program

5
6
7
Year of Enrollment
Program

8

9

10

11

10

11

Non-Program

B. Completion
.3
Conditional Prob. of Completion

.6

Probability of Completion

.5
.4
.3
.2
.1
0

.2

.1

0
1

2

3

4

5
6
7
Year of Enrollment
Program

8

9

10

11

1

Non-Program

2

3

4

5
6
7
Year of Enrollment
Program

8

9

Non-Program

Note: The figures are from regressions weighted by the inverse of cohort size and correspond to
the “Department/Cohort” results in Table 3.

32

Figure 3. Impact of Financial Aid on Attrition and Completion
A. Attrition

Prob. of Attrition

.5
.4
.3
.2
.1
0
No Tuit TAFwp

No Tuit TAFwp

No Tuit TAFwp

Year 2

Year 4

Year 7

No Tuit TAFwp

No Tuit TAFwp

No Tuit TAFwp

Year 6

Year 7

Year 9

B. Completion

Prob. of Completion

.5
.4
.3
.2
.1
0

Notes: The figures display cumulative probabilities of attrition and completion by the end of
particular years of enrollment. The financial aid profiles are as follows: No = No aid for years 16, Tuit = Tuition grant for years 1-6, TA = TA/RA and tuition grant for years 1-6, Fwp =
fellowship and tuition grant for years 1-6. All profiles involve no aid for years 7-11.

33

Appendix Table 1. Coefficients on Treatment × Post Variable from Transition Models
Weighting
Dept/Cohort
Attrition

1

2

3

-0.489
(0.171)

-0.081
(0.153)

0.344
(0.183)

Completion
Student
Attrition
Completion

-0.543
(0.126)

-0.024
(0.115)

0.411
(0.131)

Year of Enrollment
4
5
6

7

8

9-11

p-value for
H0: β=0

-0.323
(0.204)
0.503
(0.308)

-0.048
(0.255)
0.027
(0.195)

0.158
(0.281)
0.124
(0.171)

-0.123
(0.306)
0.073
(0.174)

-0.672
(0.476)
-0.029
(0.188)

0.365
(0.295)
-0.163
(0.157)

0.029

-0.133
(0.156)
0.161
(0.252)

-0.052
(0.205)
-0.083
(0.157)

-0.019
(0.229)
0.127
(0.14)

0.114
(0.258)
-0.021
(0.138)

-0.022
(0.302)
-0.096
(0.15)

0.115
(0.228)
-0.082
(0.125)

0.000

Notes: Standard errors in parentheses. These results correspond to models in top panel of Table 3.

34

0.611

0.882

