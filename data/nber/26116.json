{
    "id": 26116,
    "citation_title": "Re-engineering Key National Economic Indicators",
    "citation_author": [
        "Gabriel Ehrlich",
        "John Haltiwanger",
        "Ron Jarmin",
        "David Johnson",
        "Matthew D. Shapiro"
    ],
    "citation_publication_date": "2019-07-29",
    "issue_date": "2019-07-25",
    "revision_date": "2020-12-15",
    "topics": [
        "\n",
        "Econometrics",
        "\n",
        "Data Collection",
        "\n",
        "Macroeconomics",
        "\n",
        "Business Cycles",
        "\n"
    ],
    "program": [
        "\n",
        "Economic Fluctuations and Growth",
        "\n",
        "Monetary Economics",
        "\n",
        "Productivity, Innovation, and Entrepreneurship",
        "\n"
    ],
    "projects": null,
    "working_groups": null,
    "abstract": "\n\nTraditional methods of collecting data from businesses and households face increasing challenges. These include declining response rates to surveys, increasing costs to traditional modes of data collection, and the difficulty of keeping pace with rapid changes in the economy. The digitization of virtually all market transactions offers the potential for re-engineering key national economic indicators. The challenge for the statistical system is how to operate in this data-rich environment. This paper focuses on the opportunities for collecting item-level data at the source and constructing key indicators using measurement methods consistent with such a data infrastructure. Ubiquitous digitization of transactions allows price and quantity be collected or aggregated simultaneously at the source. This new architecture for economic statistics creates challenges arising from the rapid change in items sold. The paper explores some recently proposed techniques for estimating price and quantity indices in large-scale item-level data. Although those methods display tremendous promise, substantially more research is necessary before they will be ready to serve as the basis for the official economic statistics. Finally, the paper addresses implications for building national statistics from transactions for data collection and for the capabilities and organization of the statistical agencies in the 21st century.\n\n",
    "acknowledgement": "\nWe acknowledge financial support of the Alfred P. Sloan Foundation and the additional support of the Michigan Institute for Data Science and the Michigan Institute for Teaching and Research in Economics. The results here are in part based on researchers own analyses calculated (or derived) based in part on data from The Nielsen Company (US), LLC and marketing databases provided through the Nielsen Datasets at the Kilts Center for Marketing Data Center at The University of Chicago Booth School of Business. The conclusions drawn from the Nielsen data are those of the researchers and do not reflect the views of Nielsen. Nielsen is not responsible for, had no role in, and was not involved in analyzing and preparing the results reported herein. We also use the NPD data housed at the U.S. Census Bureau. All results using the NPD data have been reviewed to ensure that no confidential information has been disclosed (CBDRB-FY19-122). Any opinions and conclusions expressed herein are those of the authors and do not necessarily represent the view of the U.S. Census Bureau. We thank Katharine Abraham, Robert Cage, Robert Feenstra, David Friedman, Greg Kurtzon, Robert Martin, Stephen Redding and David Weinstein for helpful comments. We thank Jamie Fogel, Diyue Guo, Edward Olivares, Luke Pardue, Dyanne Vaught, and Laura Zhao for superb research assistance. The views expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.\n\n\n"
}