NBER WORKING PAPER SERIES

LONG RUN GROWTH OF FINANCIAL TECHNOLOGY
Maryam Farboodi
Laura Veldkamp
Working Paper 23457
http://www.nber.org/papers/w23457

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2017

We thank Marios Angeletos, Markus Brunnermeier, Martin Eichenbaum, Sergio Rebelo, Steven
Strongin and Xavier Vives, seminar and conference participants at Cornell, Fordham, Maryland,
NYU, Princeton, Stanford, Yale and the SED conference, the NASDAQ DRP research day and
the LAEF conference on information in finance for comments. We thank Goldman Sachs for their
financial support through the GMI Fellowship program. We thank John Barry, Chase Coleman,
Matias Covarrubias, Roxana Mihet and Arnav Sood for their capable research assistance. The
views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at http://www.nber.org/papers/w23457.ack
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
¬© 2017 by Maryam Farboodi and Laura Veldkamp. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including ¬© notice, is given to the source.

Long Run Growth of Financial Technology
Maryam Farboodi and Laura Veldkamp
NBER Working Paper No. 23457
May 2017
JEL No. E2,G14
ABSTRACT
In most sectors, technological progress boosts efficiency. But financial technology and the
associated data-intensive trading strategies have been blamed for market inefficiency. A key
cause for concern is that better technology might induce traders to extract other's information
from order flow data mining, rather than produce information themselves. Defenders of these new
trading strategies argue that they provide liquidity by identifying uninformed orders and taking
the other side of their trades. We adopt the lens of long-run growth to understand how
improvements in financial technology shape information choices, trading strategies and market
efficiency, as measured by price informativeness and market liquidity. We find that unbiased
technological change can explain a market-wide shift in data collection and trading strategies. But
our findings also cast doubt on common wisdom. First, although extracting information from
order flow does crowd out production of fundamental information, this does not compromise
price informativeness. Second, although taking the opposite side of uninformed trades is typically
called "providing liquidity," the rise of such trading strategies does not necessarily improve
liquidity in the market as a whole.

Maryam Farboodi
26 Prospect Ave
Bendheim Center for Finance
Princeton University
Princeton, NJ 08540
farboodi@princeton.edu
Laura Veldkamp
Stern School of Business
New York University
44 W Fourth Street,Suite 7-77
New York, NY 10012
and NBER
lveldkam@stern.nyu.edu

‚Äú[I]ts all about getting as much customer order flow as possible ... The more trades these
sophisticated machines get to see, the better they become [at] making money for their creators.‚Äù
(Reuters, August 14, 2009)
In most sectors, technological progress boosts efficiency. But in finance, information technology and
the new data-intensive trading strategies it has spawned have been blamed for market volatility, illiquidity
and inefficiency. One reason financial technology is suspect is that its rise has been accompanied by a shift
in the nature of financial analysis and trading. Instead of ‚Äúkicking the tires‚Äù of a firm, investigating its
business model or forecasting its profitability, many traders today engage in statistical arbitrage: They
search for ‚Äúdumb money,‚Äù or mine order flow data and develop algorithms to profit from patterns in
others‚Äô trades. It appears that technology makes it easier to detect what others know. If so, does financial
technology deter information production and reduce market efficiency?
Teasing out the effect of technology with data alone is difficult. Many other concurrent trends may
mask the effects. Furthermore, it is not obvious which predictions to test when technological change affects
equilibrium prices and behavior of all market participants. Therefore, we build a model to explore whether
improvements in data processing naturally favor one type of information processing over another, and what
consequences this has for market efficiency.
Our contribution is to sort out what are and what are not logical consequences of long-run information technology growth on financial markets. The model explains why, with poor technology, uncovering
fundamental data is more profitable than mining order flow data, even if the technology for doing both
activities is equally poor. As information technology improves, the model teaches us that the incentive to
mine order flow data grows, and can crowd out fundamental data gathering. Contrary to popular wisdom,
this shift in data processing and in trading strategies does not necessarily compromise financial market
efficiency. Efficiency, as measured by price informativeness, continues to rise, even if fundamental data
gathering falls. Efficiency, as measured by the price impact of an uninformed trade (liquidity), stagnates.
Even though order flow data allows investors to identify uninformed trades, and even though investors use
this information to take the opposite side of these trades, market-wide liquidity may not improve.
To explore these forces, our model of the financial economy (in Section 1) requires the following features. First, investors choose between styles of financial analysis, observe the data produced from that
analysis, and then invest. Financial analysis here means processing some type of data. One analysis style
is fundamental analysis, which involves processing earnings reports, business model simulations, macro
announcement data etc., that help to predict the future value of a firm. The other style of analysis is
extracting information from the trades (order flow) of others. Modeling the trade-off between analyzing
fundamental and order flow data is new and allows us to explore the market inefficiency argument. Second,
we incorporate long-lived assets. This feature is essential to understand the long-run balanced growth of
fundamental and order flow analysis. Long-lived assets also create the future information risk that compromises market liquidity. Third, the driving force behind the model is technological change in the total
flow of data the sector can analyze or process. Of course, other trends, such as a decline in fees, entry
of new investors or assets, digitization, changes in covariance or improvements in order flow execution are
operating during this period as well. We want to take one simple trend, unbiased technological progress in
data processing, and see how much that alone can explain. This simple driving force offers a foundation
for exploring financial technology growth, to which many other ingredients and trends might eventually
1

be added. Finally, we also explore biased technological change that only improves the efficiency of order
flow analysis. While the dynamic patterns of information choices change, the basic message does not. The
surge in order flow mining does not undermine price informativeness, nor does it substantially improve
liquidity.
Our theoretical results examine how investors choose to use their growing capacity to process data.
The main mechanism underlying the results is that an increase in total information creates an endogenous
change in the relative value of fundamental versus order-flow information (Section 2). When technology
is poor, information is scarce, and it is very valuable to know about the fundamental value of an asset.
The alternative strategy of processing data to identify uninformed trades is not valuable when so little
of trade is well-informed. When more investors are well-informed, it becomes more valuable to identify
and trade against the remaining non-informational trades. Order flow analysis allows investors to target
these more profitable trades. In fact, for a range of technology levels, the more order flow analysis and
trading is done, the more profitable it is for other investors to pile in with yet more order flow analysis and
trading. This complementarity in trading strategies allows order flow trading to not only catch up with
trading on fundamental information, but actually to surpass it and crowd out much of the fundamental
analysis that was previously done at lower technology levels. And yet, in the long run, as the capacity
for data processing becomes large, fundamental analysis cannot disappear. If it did, there would be no
information to extract from order flow. Instead, eventually, order flow analysis and fundamental analysis
grow together, in proportion to each other.
When we turn to discuss the consequences of this shift in data analysis and trading strategies, it is
useful to see time paths. To produce these, we need to put some plausible numbers to the model. Section
3 calibrates the model to financial market data so that we can explore the growth transition path and its
consequences for market efficiency numerically.
The results on market efficiency offer two surprises. First, even as order flow analysis crowds out
fundamental analysis and reduces the discovery of information about the future asset value, price informativeness continues to rise. The reason is that order flow information allows order flow traders to extract
fundamental information from prices. That makes the order flow traders, and thus the average trader,
better informed about future asset fundamentals. When the average trader is better informed, prices are
more informative. This might lead one to conclude that price informativeness doesn‚Äôt measure financial
efficiency in the way we thought it did. But according to this commonly-used measure, market efficiency
continues to improve as technology progresses.
Second, even though order flow traders systematically take the opposite side of uninformed trades,
the rise of order flow trading does not enhance market liquidity (Section 4). This is surprising because
taking the opposite side of uninformed trades is often referred to as ‚Äúproviding liquidity.‚Äù This is one of
the strongest arguments that proponents of activities such as high-frequency trading use to defend their
methods. But if by providing liquidity, we really mean reduce the price impact of uninformed trade, the
rise of order flow trading may not accomplish that. The problem is not order flow trading today, but
the expectation of informed trading of any kind ‚Äì fundamental or order flow ‚Äì tomorrow. The fact that
tomorrow‚Äôs investors will be well-informed gives rise to future information risk. This is the risk posed by
information that is unknown today, will be learned tomorrow, and will move tomorrow‚Äôs price. Because
assets are long-lived, tomorrow‚Äôs price uncertainty is today‚Äôs payoff risk. So future data processing raises

2

the risk of investing in assets today. More risk per share of asset today is what causes the sale of one share
of the asset to have a larger effect on the price.
Thus, the rise in order-flow trading, rise in return uncertainty, and stagnation of liquidity, emerge
as concurrent trends with financial technology as their common cause. For asset returns, the net effect
of future information risk and less uncertainty about dividends today is a slightly lower risk premium,
consistent with empirical equity premia measures.
Finally, Section 5 shows why these trends in market efficiency are relevant for the real economy. This
last section sketches two extensions of the model. One argues that, if firm managers are compensated with
equity, better price informativeness improves their incentives to exert optimal effort. The second extension
shows how the same forces that underlie market liquidity also reduce the cost of equity issuance for a firm
that wants to raise capital for real investment. Thus more liquid markets should also promote efficient real
investment and long-run economic growth.
Contribution to the existing literature

Our model combines features from a few disparate literatures.

Long run trends in finance are featured in Asriyan and Vanasco (2014), Biais, Foucault, and Moinas (2015),
and Glode, Green, and Lowery (2012), who model growth in fundamental analysis or an increase in its
speed. Davila and Parlatore (2016) explore a decline in trading costs. Philippon (2015) argues that
increased issuance can explain the growth of the financial sector. Our assumption that there is long-run
growth in information processing is supported by the rise in price informativeness documented by Bai,
Philippon, and Savov (2013).
A small, growing literature examines order-flow information in equilibrium models. In Yang and Ganguli (2009), agents can choose whether or not to purchase a fixed bundle of fundamental and order-flow
information. In Yang and Zhu (2016) and Manzano and Vives (2010), the precision of fundamental and
order-flow information is exogenous. Babus and Parlatore (2015) examine intermediaries who observe the
order flow of their customers. Our order flow signals also resemble Angeletos and La‚ÄôO (2014)‚Äôs sentiment
signals about other firms‚Äô production, Banerjee and Green (2015)‚Äôs signals about motives for trade, the
signaling by He (2009)‚Äôs intermediaries, and the noise in government‚Äôs market interventions in Brunnermeier, Sockin, and Xiong (2017). But none of these papers examines the choice that is central to this
paper: The choice of whether to process more about asset payoffs or to analyze more order flow. Without
that trade-off, these papers cannot explore how the incentives to process each type of information change
as productivity improves. Furthermore, this paper adds a long-lived asset in a style of model that has
traditionally been static.1 The long-lived asset causes growth in future information processing to have
feedback effects on uncertainty and information choices today.
In the microstructure literature, our model contributes a new perspective on what high-frequency
traders do, which complements work by Du and Zhu (2017), Crouzet, Dew-Becker, and Nathanson (2016)
and others. Empirically, Hendershott and Menkveld (2014) and Hendershott, Jones, and Menkveld (2011)
use natural experiments to measure how fundamental and algorithmic trading affects liquidity. By contributing theory to this discussion, we can understand why the shift is taking place.
1

Exceptions include 2- and 3-period models, such as Cespa and Vives (2012).

3

1

Model

To explore the dynamic evolution of financial analysis style and its consequences, we incorporate information choice in a dynamic model with long-lived assets and asymmetric information, as in Wang (1993).
While the long-lived asset assumption is unusual in information choice models, it is crucial for the liquidity
and long-run balanced growth results. The choice of fundamental information precision resembles that in
repeated static models such as Kacperczyk, Nosal, and Stevens (2015). But the new aspect of our information choice is that acquiring fundamental information trades off with extracting of information from order
flow. Of course, it would be simpler to assume that the mix of information changes exogenously. But that
would not inform us about why investment strategies are changing. If we took that approach, we might
wrongly attribute the stagnation of market liquidity to an increase in order flow information extraction,
instead of understanding both as outcomes of growth in financial technology.
A key question is how to model information extraction from order flow, which, in practice, can take
many forms. Extraction might take the form of high-frequency trading, where the information of an
imminent trade is used to trade before the new price is realized. It could be mining tweets or Facebook
posts to gauge sentiment. Extraction could take the form of ‚Äúpartnering,‚Äù a practice where brokers sell
their order flow to hedge funds, who systematically trade against, what are presumed to be uninformed
traders.2 Finally, it may mean looking at price trends, often referred to as technical analysis, in order to
discern what information others may be trading on. All of these practices have in common that they are not
uncovering original information about the future payoff of an asset. Instead, they are using information to
profit from what others already know (or don‚Äôt know). We capture this general strategy, while abstracting
from many of its details, by allowing investors to observe a signal about the non-informational trades of
other traders. This order flow signal allows our traders to profit in three ways. 1) They can identify and
then trade against uninformed order flow; 2) they can remove noise from the equilibrium price to uncover
more of what others know; or 3) they can exploit the mean-reversion of order flow shocks to buy before
price rises and sell before it falls. These three strategies have an equivalent representation in the model
and collectively cover many of the ways investors profit from information technology.

1.1

Setup

Investor preferences and endowments At the start of each date t, a measure-one continuum of
overlapping generations investors is born. Investors born at time t have constant absolute risk aversion
utility over total, end of period t consumption cÃÉt :
U (cÃÉt ) = ‚àíe‚àíœÅcÃÉt

(1)

where œÅ is absolute risk aversion.We adopt the convention of using tildes to indicate t-subscripted variables
that are not in the agents‚Äô information set when they make time-t investment decisions.
Each investor i born at date t is endowed with an exogenous income that is eÃÉit units of consumption
goods. Investors can use their income to buy risky assets at the start of the period. But they cannot trade
2

Market evidence suggests that hedge funds value the opportunity to trade against the uninformed, as noted by Goldstein
in a 2009 Reuters article: ‚ÄúRight now, ETrade sends about 40% of its customer trades to Citadels market-maker division
. . . Indeed, the deal is so potentially lucrative for Citadel that the hedge fund is willing to make an upfront $100 million cash
payment to the financially-strapped online broker.‚Äù

4

shares of or any assets contingent on this income.
There is a single tradeable asset.3 Its supply is one unit per capita. It is a claim to an infinite stream
of dividend payments {dt }:
dÀút = ¬µ + GdÀút‚àí1 + yÃÉt .

(2)

where ¬µ and G < 1 are known parameters. The innovation yÃÉt ‚àº N (0, œÑ0‚àí1 ) is revealed and dÀút is paid out
at the end of each period t.
An investor born at date t, sells his assets at price pt+1 to the t + 1 generation of investors, collects
dividends dÀút per share, combines that with the endowment that is left (eÃÉit ‚àí qit pt ), times the rate of time
preference r > 1, and consumes all those resources. Thus the cohort-t investor‚Äôs budget constraint is
cÃÉt = r(eÃÉit ‚àí qit pt ) + qit (pt+1 + dÀút )

(3)

where qit is the shares of the risky asset that investor i purchases at time t and dÀút are the dividends paid
out at the start of period t + 1. Since we do not prohibit ct < 0, all pledges to pay income for risky assets
are riskless.
The value of endowments is correlated with the dividend: eÃÉit = eÃÑ + hit yÃÉt + Àúeit , where eÃÑ is known and
Àúeit ‚àº N (0, œÑe‚àí1 ) is independent across agents and independent of all the other shocks in the economy.
The variable hit governs the correlation of agent i‚Äôs endowment with output. That variable has a common
component and an investor-specific component: hit = xÃÉt + Àúhit where xÃÉt ‚àº N (0, œÑx‚àí1 ) and Àúhit ‚àº N (0, œÑh‚àí1 ).4
This rich, correlated endowment process serves simply to avoid noise traders. For information to have
value, prices must not perfectly aggregate asset payoff information. As in Manzano and Vives (2010), we
inject noise in prices by giving investors both informational and non-informational ‚Äì hedging ‚Äì reasons
for trade. Investors have non-financial income risk that they hedge with financial assets. Shocks to this
hedging demand is our source of noise in prices. Equivalently, xÃÉt could also be interpreted as aggregate
demand, sentiment or noise trading. For now, we assume that xÃÉt is independent over time. We discuss the
possibility of autocorrelated xÃÉt in Section 2.4.
Information Choice If we want to examine how the nature of financial analysis has changed over time,
we need to have at least two types of analysis to choose between. Financial analysis in this model means
signal acquisition. Our constraint on acquisition could represent the limited research time for uncovering
new information. But it could also represent the time required to process and compute optimal trades
based on information that is readily available from public sources.
Investors choose how much information to acquire or process about the next-period dividend innovation
yÃÉt , and also about the hedgers‚Äô demand shocks, xÃÉt . We call Œ∑f it = yÃÉt + Àúf it a fundamental signal and
Œ∑xit = xÃÉt + Àúxit an order-flow signal. What investors are choosing is the precision of these signals. In
other words, if the signal errors are distributed Àúf it ‚àº N (0, ‚Ñ¶f it ) and Àúxit ‚àº N (0, ‚Ñ¶ÃÇxit ), then the precisions
‚Ñ¶f it and ‚Ñ¶ÀÜxit are choice variables for investor i. For notational convenience, we define ‚Ñ¶xit = œÑh + ‚Ñ¶ÃÇxit .
Instead of choosing ‚Ñ¶ÀÜxit ‚â• 0, we then allow the investor choose ‚Ñ¶xit ‚â• œÑh . Then ‚Ñ¶xit represents the joint
3

We describe a market with a single risky asset because our main effects do not require multiple assets. However, we have
some results for the generalized, multi-asset setting.
4
The fact that the mean of hit is zero is just for simplification. Assuming a non-zero mean affects the average asset price.
But we have checked that it does not affect our main results.

5

signal precision that the investor has both from order-flow analysis and from observing his own endowment
exposure to systemic financial risk.
The constraint that investors face when choosing information is
‚Ñ¶2f it + œáx ‚Ñ¶2xit ‚â§ Kt .

(4)

This represents the idea that getting more and more precise information about a given variable is tougher
and tougher. But acquiring information about a different variable is a separate task, whose shadow cost is
additive.
The main force in the model is technological progress in information analysis. Specifically, we assume
that Kt is a deterministic, increasing process.
Information sets and equilibrium

First, we recursively define two information sets. The first is all

+
the variables that are known at the end of period t ‚àí 1. This information is {It‚àí1 , yt‚àí1 , dt‚àí1 , xt‚àí1 } ‚â° It‚àí1
.

This is what investors know when they choose what signals to acquire. The second information set is
+
{It‚àí1 , yt‚àí1 , dt‚àí1 , xt‚àí1 , Œ∑f it , Œ∑xit , hit , pt } ‚â° It‚àí1
. This includes the two signals the investor chooses to see,

information contained in equilibrium prices and the information conveyed by one‚Äôs endowed income. This
is the information set the investor has when they make investment decisions. The time 0 information set
includes the entire sequence of information capacity: I0 ‚äÉ {Kt }‚àû
t=0 .
An equilibrium is a sequence of information choices {‚Ñ¶f it }, {‚Ñ¶xit } and portfolio choices {qit } by investors
such that
+
1. Investors choose signal precisions ‚Ñ¶f it and ‚Ñ¶xit to maximize E[ln(E[U (ci,t+1 )|It ])|It‚àí1
], where U is

defined in (1), taking the choices of other agents as given.5 This choice is subject to (4), ‚Ñ¶f it ‚â• 0
and ‚Ñ¶xit ‚â• œÑh .
2. Investors choose their risky asset investment qit to maximize E[U (cit )|Œ∑f it , Œ∑xit , hit , pt ], taking the
asset price and the actions of other agents as given, subject to the budget constraint (3).
3. At each date t, the risky asset price clears the market:
Z
qit di = 1

1.2

‚àÄt.

(5)

Solving the Model

There are four main steps to solve the model.
Step 1: Solve for the optimal portfolios, given information sets. Each investor i at date t chooses a
number of shares qit of the risky asset to maximize expected utility (1), subject to the budget constraint
(3). The first-order condition of that problem is
qit =

E[pt+1 + dÀút |Iit ] ‚àí rpt
‚àí hit
œÅit V ar[pt+1 + dÀút |Iit ]

(6)

5
E ln E preferences deliver a simple expression for the objective that is linear in signal precision. It is commonly used in
information choice models (Kacperczyk, Nosal, and Stevens, 2015), (Crouzet, Dew-Becker, and Nathanson, 2016). The same
trade-offs arise with expected utility. Results available on request.

6

Step 2: Clear the asset market. Given this optimal investment choice, we can impose market clearing
(5) and obtain a price function that is linear in past dividends dt‚àí1 , the t-period dividend innovation yÃÉt ,
and the aggregate component of the hedging shocks xÃÉt :
pt = At + Bdt‚àí1 + Ct yÃÉt + Dt xÃÉt

(7)

where the coefficients At , B, Ct and Dt solve the following set of equations:


r¬µ
1
Àú
At+1 +
At =
‚àí œÅV ar[pt+1 + dt |It ]sÃÑ .
r
r‚àíG
G
r‚àíG

(9)

1
(1 ‚àí œÑ0 V ar[yÃÉt |Iit ])
r‚àíG

(10)

B=

Ct =

(8)

rDt = ‚àíœÅV ar[pt+1 + dÀút |Iit ] +

Ct
r
V ar[yÃÉt |Iit ] œÑx
r‚àíG
Dt

(11)

where ‚Ñ¶pit is the precision of the information about dÀút , extracted jointly from prices and order flow signals.
V ar[yÃÉt |Iit ] = (œÑ0 + ‚Ñ¶f it + ‚Ñ¶pit )‚àí1

(12)

is the posterior uncertainty about next-period dividend innovations and the resulting uncertainty about
asset returns is proportional to
2
2
œÑx‚àí1 + (1 + B)2 V ar[yÃÉt |Iit ].
V ar[pt+1 + dÀút |Iit ] = Ct+1
œÑ0‚àí1 + Dt+1

(13)

Step 3: Compute ex-ante expected utility. When choosing information to observe, investors do not
know what signal realizations will be, nor do they know what the equilibrium price will be. The relevant
+
information set for this information choice is It‚àí1
.

After we substitute the optimal portfolio choice (6) and the equilibrium price rule (7) into utility (1), and
+
take log and then the beginning of time-t expectation (‚àíE[ln(E[exp(œÅcit )|Œ∑f it , Œ∑xit , hit , pt ])|It‚àí1
]), we get

an time-1 expected utility expression that is similar to most CARA-normal models: œÅ r eit +œÅE[qit (E[pt+1 +
2
+
2 V ar[p
‚àí1 +
Àú
dÀút |Iit ] ‚àí pt r)|It‚àí1
] ‚àí œÅ2 E[qit
t+1 + dt |Iit ] |It‚àí1 ]. Appendix A shows that the agent‚Äôs choice variables
‚Ñ¶f it and ‚Ñ¶xit show up only through the conditional precision of payoffs, V ar[pt+1 + dÀút |Iit ]‚àí1 . The reason for
this is that the first-moment terms in asset demand ‚Äì E[pt+1 + dÀút |Iit ] and p ‚Äì have ex-ante expected values
that do not depend on the precision of any given investor‚Äôs information choices. In other words, choosing to
get more data of either type does not, by itself, lead one to believe that payoffs or prices will be particularly
high or low. So, information choices amount to minimizing the payoff variance V ar[pt+1 + dÀút |Iit ], subject
to the data constraint. The payoff variance, in turn, has a bunch of terms the investor takes as given, plus
a term that depends on dividend variance, V ar[yÃÉt |Iit ]. Equation (12) shows that V ar[yÃÉt |Iit ] depends on
the sum of fundamental precision ‚Ñ¶f it and price information ‚Ñ¶pit . Price information precision is ‚Ñ¶pit =
7

(Ct /Dt )2 (œÑx + ‚Ñ¶xit + œÑh ), which is linear in ‚Ñ¶xit . Thus expected utility is a function of the sum of ‚Ñ¶f it and
(Ct /Dt )2 ‚Ñ¶xit .
Thus, optimal information choices maximize the weighted sum of fundamental and order-flow precisions:

max‚Ñ¶f it ,‚Ñ¶xit ‚Ñ¶f it +
s.t. (4),

Ct
Dt

2
‚Ñ¶xit

(14)

‚Ñ¶f it ‚â• 0, and ‚Ñ¶xit ‚â• œÑh .

Step 4: Solve for information choices. The first order conditions yield
‚Ñ¶xit

1
=
œáx



Ct
Dt

2
‚Ñ¶f it

(15)

This solution implies that information choices as symmetric. Therefore, in what follows, we drop the i
subscript to denote an agent‚Äôs data processing choice.
The information choices are a function of pricing coefficients, like C and D, which are in turn functions
of information choices. To determine the evolution of analysis and its effect on asset markets, we need to
compute a fixed point to a highly non-linear set of equations. After substituting in the first order conditions
for ‚Ñ¶f t and ‚Ñ¶xt , we can write the problem as two non-linear equations in two unknowns.

1.3

Interpreting Order Flow Trading

Why are order flow signals useful? They don‚Äôt predict future dividends or future prices. They only provide
information about current demand. The reason that information is valuable is that it tells the investor
something about the difference between price and expected asset value. One can see this by looking at
the signal extracted from prices. Price is a noisy signal about dividends. To extract the price signal, we
subtract the expected value of all the terms besides the dividend, and divide by the dividend coefficient
Ct . The resulting signal extracted from prices is
(pt ‚àí At ‚àí Bdt‚àí1 ‚àí Dt E[xÃÉt |Iit ])
Dt
= yÃÉt +
(xÃÉt ‚àí E[xÃÉt |Iit ]) .
Ct
C
{z
}
| t

(16)

signal noise

Notice how order flow shocks xÃÉt are the noise in the price signal. So information about this order flow
reduce noises in the price signal. In this way, the order flow signal can be used to better extract others‚Äô
dividend information from the price. This is the sense in which order flow analysis is information extraction.
Of course, real order flow traders are not taking their orders, and then inverting an equilibrium pricing
model to infer future dividends. But another way to interpret the order flow trading strategy is that
it is identifying non-information trades to trade against. In equation (16), notice that when xÃÉt is high,
hedging traders are mostly sales. Since (Dt /Ct ) < 0, high xÃÉt makes the expected dividend minus price
high, which leads those with order flow information to buy. Thus, order flow trading amounts to finding the
non-informational trades and systematically taking the opposite side. For simplicity, we gave all investors
informational and hedging motives for trade. But the same forces emerge if the hedging trades are done by
a different class of agents, which we might call uninformed retail investors or liquidations by pension funds.
This trading strategy of trading against uninformed trades is commonly referred to as trading against
‚Äúdumb money.‚Äù
8

The key to the main results that follow is that reducing the noise in xÃÉt reduces price noise variance
in proportion to (Dt /Ct )2 . Put conversely, increasing precision of information about xÃÉt (the reciprocal
of variance) increases the precision of dividend information, in proportion to (Ct /Dt )2 . What causes the
long-run shifts is that the marginal rate of substitution of order flow for fundamentals signals, (Ct /Dt )2 ,
changes as technology grows.
If we interpret order flow trading as finding dumb money, it is easy to see why it becomes more valuable
over time. If there is very little information, everyone is ‚Äúdumb,‚Äù and finding dumb money is pointless.
But when informed traders become sufficiently informed, distinguishing dumb from smart money, before
taking the other side of a trade, becomes essential.

1.4

Measuring Financial Market Efficiency

To study the effects of financial technology on market efficiency, we assess efficiency in two ways. One
measure of efficiency is price informativeness. The asset price is informative about the unknown future
dividend innovation yÃÉt . The coefficient Ct on the dividend innovation yÃÉt in the equilibrium price equation
(7) measures price informativeness. Ct governs the extent to which price reacts to a dividend innovation.
It corresponds to the price informativeness measure of Bai, Philippon, and Savov (2013).
The other measure of market efficiency is liquidity. Liquidity is the price impact of an uninformed
(hedging) trade. That impact is the price coefficient Dt . Note that Dt is negative because a high endowment
of risk correlated with dividends makes an investor less willing to hold risky assets; the reduced demand
lowers the price. So, a more negative Dt represents a higher price impact and a less liquid market.
Increasing (less negative) Dt is an improvement in liquidity.

2

Analytical Results: A Secular Shift in Financial Analysis

Our main objective is to understand how technological progress in information (data) processing affects
financial analysis choices, trading strategies, and market efficiency. In this section, we focus mainly on the
question: How does the decision to analyze fundamental or order flow information change as technology
improves? The information choice results illuminate why the effects of technology on market efficiency are
mixed. Along the way, we learn why both types of information can improve price informativeness and also
why both can create payoff risk and thereby impair market liquidity.
We begin by exploring what happens in the neighborhood near no information processing, K ‚âà 0. We
show that all investors prefer to acquire only fundamental information in this region. Thus, at the start of
the growth trajectory, investors primarily investigate firm fundamentals. Next, we prove that an increase
in aggregate information processing increases the value of order flow information, relative to fundamental
information. Fundamental information has diminishing relative returns. But in some regions, order flow
information has increasing returns. What does this mean for the evolution of analysis? The economy starts
out doing fundamental analysis and then rapidly shifts to order flow analysis. We explore this mechanism,
as well as its long run limit, in the following propositions.

9

2.1

Analysis Choices when Information Is Scarce

In order to understand why investors with little information capacity use it all on fundamental information,
we start by thinking about what makes each type of information valuable. Fundamental information is
valuable because it informs an investor about whether the asset is likely to have a high dividend payoff
tomorrow. Since prices are linked to current dividends, this also predicts a high asset price tomorrow and
thus a high return. Knowing this allows the investor to buy more of the asset in times when its return will
be high and less when return is likely to be low.
In contrast, order flow information is not directly relevant to future payoff or future price. But one
can still profit from trading on order flow. An investor who knows that hedging demands are high will
systematically profit by selling the asset because high hedging demands will make the price higher than the
fundamental value, on average. In other words, order flow signals allow one to trade against dumb money
The next result proves that if the price has very little information embedded in it, because information is
scarce (Kt is low), then getting order flow data to extract price information is not very valuable. In other
words, if all trades are ‚Äúdumb,‚Äù then identifying the uninformed trades has no value.
Result 1 When information is scarce, order flow analysis has zero marginal value:
As Kt ‚Üí 0, for any future path of prices (At+j , Bt+j , Ct+j and Dt+1 , ‚àÄj > 0), dU1 /d‚Ñ¶xt ‚Üí 0.
The proof (in Appendix B) establishes two key claims: 1) that when K ‚âà 0, there is no information in
the price: Ct = 0 and 2) that the marginal rate of substitution of order flow information for fundamental
information is proportional to (Ct /Dt )2 . Thus, when the price contains no information about future
dividends (Ct = 0), then analyzing order flow is has no marginal value (Ct /Dt )2 = 0. Order flow information
is only valuable in conjunction with the current price pt because it allows one to extract more information
from price. Order flow trading when Kt = 0 is like removing noise from a signal that has no information
content.
This results explains why analysts focus on fundamentals when financial analysis productivity is low.
In contrast, when prices are highly informative, order flow information is like gold because it allows one
to identify exactly the price fluctuations that are not informative and are therefore profitable to trade
on. The next results explain why order flow analysis increases with productivity growth and why it may
eventually start to crowd out fundamental analysis.
As financial technology grows, order flow analysis takes off.

The concern with the deleterious

effects of financial technology on market efficiency stemmed from the concern that technology will deter
the research and discovery of new fundamental information. This concern is not unwarranted. Not only
does more fundamental information encourage extraction of information from order flow, but once order
flow analysis starts, it feeds on itself.
The next result shows that, as long as price information is low or order flow analysis is not too large,
both types of analysis increase the ratio of the information content C to the noise D. This increases the
marginal value of order flow information, relative to fundamental information. Thus, fundamental analysis
complements order flow information and order flow information complements itself.
Result 2 Complementarity in order flow analysis:
If ‚Ñ¶xt < œÑ0 + ‚Ñ¶f t and either
10

1. Ct /Dt is smaller in absolute value than (2 V ar[pt+1 + dÀút |Iit ])‚àí1 , or
‚àö
2. V ar[pt+1 + dÀút |Iit ] < 3
then

‚àÇ(Ct /Dt )2
‚àÇ‚Ñ¶f t

> 0 and

‚àÇ(Ct /Dt )2
‚àÇ‚Ñ¶xt

‚â• 0.

Unlike fundamental analysis, the rise in order-flow analysis can increase the value of further order-flow
analysis. For fundamental information, the increase in |Ct /Dt | makes additional fundamental information
less valuable. This result resembles the strategic substitutability in information identified by Grossman
and Stiglitz (1980), in a model with a different information structure. But for order flow information, the
effect is the opposite. More precise average order flow information (higher ‚Ñ¶xt ) can increase (Ct /Dt )2 ,
which is the marginal rate of substitution of order flow information for fundamental information. The rise
in the relative value of order flow data is what makes investors shift data analysis from fundamental to
order flow when others do more order flow analysis. That is complementarity.6
Complementarity comes from a rise in the price signal-to-noise ratio. From (10), we know that Ct
is proportional to 1 ‚àí œÑ0 V ar[yÃÉt |Iit ]. As either type of information precision (‚Ñ¶f t or ‚Ñ¶xt ) improves, the
uncertainty about next period‚Äôs dividend innovation V ar[yÃÉt |Iit ] declines, and Ct increases. Dt is the
coefficient on noise xÃÉt . The price impact of uninformative trades Dt may also increase with information,
as we explain below. But conditions (1) and (2) guarantee that Dt does not rise at a rate faster than Ct
so that the ratio Ct /Dt , which is the signal-to-noise ratio of prices, and the marginal value of order flow
precision, increases with more information.
Intuitively, higher signal-to-noise (more informative) prices encourage order flow trading because the
value of order flow analysis comes from the ability to better extract the signal from prices. In this model
(as in most information processing problems), it is easier to clear up relatively clear signals than very
noisy ones. So the aggregate level of order-flow analysis improves the signal clarity of prices, which makes
order-flow analysis more valuable.7

2.2

Market Efficiency and Future Information Risk

To understand how the value of information changes, we consider marginal changes in fundamental and
order flow analysis. We begin by exploring the effect on each price coefficient (Ct , Dt ) separately. Then,
we turn to the question of how analysis affects the ratio (C/D)2 , which governs the marginal rate of
substitution between order flow and fundamental analysis. Taken together, these results paint a picture of
technological progress having mixed effects on market efficiency. The proofs are in Appendix B.
Result 3 Both fundamental and order flow analysis increase price informativeness. If r‚àíg > 0
and (œÑx + ‚Ñ¶xt ) is sufficiently small, then ‚àÇCt /‚àÇ‚Ñ¶f t > 0 and ‚àÇCt /‚àÇ‚Ñ¶xt > 0.
The more information investors have, the more information is reflected in the risky asset price. While
the idea that dividend (fundamental) information improves price informativeness is unsurprising, the question of whether order-flow speculation improves or reduces price informativeness is not obvious. It turns
6

With a linear information constraint, or a simple cost function for Kt , the same intuition holds. With linearity, there is a
Ct
secular shift to order flow information acquisition once D
falls below ‚àí1. After that, the equilibrium level of the two types
t
of information will be such that investors remain indifferent.
7
When we consider a marginal change in analysis choice in the infinite future (a change in the steady state), the results
are similar, but with more complex necessary conditions.

11

out that they increase the information content because by selling the asset when the price is high for
non-fundamental reasons and buying when the price is erroneously low, they make it easier to extract information from prices. Better informed traders who learn both from independent signals and from prices,
therefore have better information, take more aggressive positions which in turn, cause the price so reveal
even more information.
Liquidity here is the impact a non-informational trade has on price. A liquid market is one where one
can buy or sell large quantities, in a way that is not correlated with dividends, without moving price by
much. The next two results together show that information today and information tomorrow have opposite
effects on today‚Äôs liquidity. These opposite results are why it was important to use a dynamic model to
think about the long run effects on increasing information technology.
Result 4 If order flow is not too volatile, then both fundamental and order flow analysis
improve concurrent liquidity. If œÑx > œÅr/(r ‚àí g), then ‚àÇDt /‚àÇ‚Ñ¶f t > 0 and ‚àÇDt /‚àÇ‚Ñ¶xt > 0.
The contemporaneous effect is that both types of analysis can increase liquidity. The rationale is that
both types of traders trade against non-informational trades and mitigate their price impact. Order flow
investors profit by identifying and trading against non-informational trades. Non-informational trades
that are clearly identifiable, will find eager counterparties, and will have little price impact. Fundamental
traders buy when the price is low, relative to their fundamental information. This is exactly the same
states where hedgers are selling. By taking the other side of the hedging trade, both types of traders
mitigate hedgers‚Äô price impact. Lower price impact is higher liquidity.
Why would this result be reversed if order flow was volatile (œÑx low)? A low œÑx means that prices are
very noisy. When information improves, noise trades can be mis-attributed to agents having fundamental
information. This mis-attribution causes prices to move more. In other words, the presence of informed
traders makes others more hesitant to trade against hedging trades, increasing their price impact. Both
components of this contemporaneous effect are present in static models as well.
Another way of understanding liquidity is to think about it as a change in the quantity of risk per
share. More information of either type today makes the dividend less risky ‚Äì lower conditional variance ‚Äì
and helps to forecast tomorrow‚Äôs price. If one share of the asset involves bearing little risk, then market
investors don‚Äôt need much price concession to induce them to hold a little extra risk. When one share
is riskier, then inducing the market to buy one more share requires them to take on lots of risk, which
requires a large price concession. This effect shows up in (11), the formula for Dt , which depends negatively
on V ar[pt+1 + dÀút |Iit ]‚àí1 , the variance of the asset payoff. Assets with more uncertain payoffs have more
negative Dt , which means selling or buying a share has more price impact. This risk-based interpretation
helps explain the next result about how future information affects today‚Äôs liquidity.
Result 5 More future information reduces liquidity today. If |Ct+1 /Dt+1 | is sufficiently large, then
‚àÇDt /‚àÇV ar[yÃÉt+1 |Ii(t+1) ] < 0.
The reason that future information can reduce liquidity is because it makes future price pt+1 more
sensitive to future information and thus harder to forecast today. If tomorrow, many investors will trade on
precise (t + 1) information, then tomorrow‚Äôs price will be very sensitive to tomorrow‚Äôs dividend information
yt+1 and tomorrow‚Äôs order flow information xt+1 . In other words, both Ct+1 and Dt+1 will be high.
12

But investors today do not know what will be learned tomorrow. Therefore, tomorrow‚Äôs analysis makes
tomorrow‚Äôs price (pt+1 ) more sensitive to shocks that today‚Äôs investors are uninformed about. Because
tomorrow‚Äôs price is a component of the payoff to the asset purchased at date t, today‚Äôs investors face high
asset payoff risk (V ar[pt+1 + dÀút |Iit ]). This is what we call future information risk. Invoking the logic above,
a riskier asset has a less liquid market. We can see this relationship in the formula for Dt (eq 11) where
V ar[pt+1 + dÀút |Iit ] shows up in the first term. Thus, future information reduces today‚Äôs liquidity.
At this point, the assumption that assets are long-lived becomes essential. In a repeated static model,
payoffs are exogenous. Without dynamics, information learned tomorrow cannot affect payoff risk today.
Thus, the contribution of using a long-lived asset model to think about information choice is all the results
that depend on future information risk.
We can see the relationship between tomorrow‚Äôs price coefficients and future information risk in the
formula for the variance of the asset payoff:
2
2
V ar[pt+1 + dÀút |Iit ] = Ct+1
œÑ0‚àí1 + Dt+1
œÑx‚àí1 + (1 + B)2 V ar[yÃÉt |Iit ]

(17)

We know that time-t information increases period-t information content Ct . Similarly, time t+1 information
increases Ct+1 . Future information may increase or decrease Dt+1 . But as long as Ct+1 /Dt+1 is large
2 œÑ ‚àí1 + D 2 œÑ ‚àí1 . Since future information
enough, the net effect of t + 1 information is to increase Ct+1
t+1 x
0

cannot affect today‚Äôs dividend uncertainty V ar[yÃÉt |Iit ], the net effect of future information is to raise
today‚Äôs payoff variance. What this means economically is that tomorrow‚Äôs prices will be more responsive
to tomorrow‚Äôs fundamental and order flow shocks. That is what makes the price more uncertain today.
In our dynamic model, information improves today and improves again tomorrow. That means the
static effect and dynamic effect are competing.8 The net effect of the two is sometimes positive, sometimes
negative. But it is never as clear-cut as what a static information model would suggest. What we learn is
that information technology efficiency and liquidity are not synonymous. If fact, because it makes prices
more informative, financial technology can also make markets function in a less liquid way.

2.3

Analysis and Price in the Long-Run

The result that order flow analysis feeds on itself suggests that in the long run, order flow analysis will
crowd out fundamental analysis. But that does not happen. When order flow precision (‚Ñ¶xt ) is high,
the necessary conditions for Proposition 2 break down. The next result tells us that, in the long run as
information becomes abundant, growth in fundamental and order-flow analysis becomes balanced. For this
result, the long-lived asset assumption is crucial.
Result 6 High-Information Limit As Kt ‚Üí ‚àû, both analysis choices ‚Ñ¶f t and ‚Ñ¶xt tend to ‚àû such that
(a) ‚Ñ¶f t /‚Ñ¶xt does not converge to 0;
(b) ‚Ñ¶f t /‚Ñ¶xt does not converge to ‚àû; and
(c) if œÑ0 is sufficiently large, there exists an equilibrium where ‚Ñ¶f t /‚Ñ¶xt converges to finite, positive constant.
8

This variance argument is similar to part of an argument made for information complementarity in Cai (2016a), an
information choice model with only fundamental information.

13

See Appendix B for the proof and an expression (90) for the lower bound on œÑ0 .
It is not surprising that fundamental analysis will not out-strip order flow analysis (part (a)). We know
that more fundamental analysis lowers the value of additional fundamental analysis and raises the value
of order flow analysis. This is the force that prompts order flow analysis to explode at lower levels of
information K.
But what force restrains the growth of order flow analysis? The reason that fundamental analysis
cannot become a negligible fraction of order flow analysis (part (b)) is that, if it did, the price signalto-noise ratio (Ct /Dt )2 would fall; this would reduce the incentive to acquire order flow information. In
sum, if fundamental analysis is too scarce, the value of mining order flow falls, and brings the two types of
analysis back to some fixed proportion.
This balanced growth result only arises in a model with long-lived assets. What makes the growth
of (Ct /Dt )2 slow down as information becomes abundant is the rise of future information risk. Result
5 teaches us that when Kt is high, future information risk (high V ar[pt+1 + dÀút |Iit ]) increases the price
impact of uninformed trades |Dt |. That V ar[pt+1 + dÀút |Iit ] term does not show up in the equation (10)
for Ct because more uncertain future prices do not increase the weight on dividend signals today. Thus,
it is future information risk, which becomes particularly large at high levels of financial technology, that
causes Dt to grow as fast as Ct , which brings order flow analysis back into proportion with fundamental
analysis. In the Appendix, Lemma 4 shows formally that (Ct /Dt )2 is bounded above by the inverse of
future information risk. When assets are not long-lived, their payoffs are exogenous, future information
risk is zero, and (Ct /Dt )2 can growth without bound. Without a long-lived asset, the balanced growth
path does not exist.

2.4

Persistent order flow or information about future events.

A key to many of our results is that the growth of financial technology creates more and more future
information risk. This is the risk that arises because shocks that affect tomorrow‚Äôs prices are not learnable
today. This raises the question: What if these shocks could be learned about today? What if order flow
shocks were not independent? What if information about future dividend shocks was available today?
Would future information processing still increase risk?
Yes, as long as there is still some uncertainty and thus something to be learned in the future, future
information will still create risk for returns today. Tomorrow‚Äôs price would depend on the new information,
learned tomorrow about shocks that will materialize in t + 2 or t + 3. That new information observed in
t + 1 will affect t + 1 prices. That new future information, only released in t + 1 cannot be known at
time t. This future information becomes a new source of unlearnable risk. The general point is this: As
long as new information keeps arriving, it creates risk. The risk is that before the information arrives, one
does not know it and can not know it, no matter how much analysis is done. And yet, this information
yet to arrive will affect future prices in a uncertain way. When information processing technology is poor,
the poorly-processed information has little price effect. Thus future information poses little risk. When
information processing improves, the risk of unknown future information grows.
Of course, if order flow were persistent, then signals about xÃÉt would be payoff relevant. The xÃÉt signal
would be informative about xÃÉt+1 , which affects the price pt+1 and thus the payoff of a time t risky asset.
Learning directly about asset future asset payoffs is fundamentally different than learning about demand

14

shocks that only affect the interpretation of the current price. In such a model, agents would attempt
to distinguish the persistent and transitory components of order flow. The persistent, payoff-relevant
component would play the role of dividend information in this model. The transitory component of order
flow would play the role of the i.i.d. xÃÉt shock in this setting.

3

Parameter Choice

The results so far reveal that low-tech investors do analyze fundamentals; as financial technology develops,
order flow analysis takes off and feeds on itself; and eventually, with advanced technology, both types
of analysis grow proportionately. Although we‚Äôve traced out forces affecting price informativeness and
liquidity, we don‚Äôt know whether these effects are large or small and which dominate. To explore these
issues, we need to solve a calibrated model numerically.
Our calibration strategy is to estimate our equilibrium price equation on recent asset price and dividend
data. By choosing model parameters that match the pricing coefficients, we ensure that we have the right
average price, average dividend, volatility and dividend-price covariance at the simulation end point. What
we do not calibrate to is the evolution of these moments over time. The time path of price and price
coefficients are over-identifying moments that we can use to evaluate model performance.
First, we describe the data used for model calibration. Next, we describe moments of the data and
model that we match to identify model parameters. Most of these moments comes from estimating a
version of our price equation (7) and choosing parameters to match the price coefficients in the model with
the data. In the next section, we report the results.
Data

We use two datasets that both come from CRSP. The first is the standard S&P 500 market

capitalization index based on the US stock market‚Äôs 500 largest companies.9 The dataset consists of:
the value-weighted price level of the index pt , and the value-weighted return (pt + dt )/pt‚àí1 , where dt is
dividends. Both are reported at a monthly frequency for the period 1999.12-2015.
Given returns and prices, we impute dividends per share as
dt =

!
pt + dt
pt
‚àí
pt‚àí1 .
pt‚àí1
pt‚àí1

Both the price series and the dividend series are seasonally adjusted and exponentially detrended. As
prices are given in index form, they must be scaled to dividends in a meaningful way. The annualized
dividend per share is computed for each series by summing dividends in 12 month windows. Then, in the
same 12-month window, prices are adjusted to match this yearly dividend-price ratio.
Finally, because the price variable described above is really an index, and this index is an average
of prices, the volatility of the average will likely underestimate the true volatility of representative stock
prices. In order to find an estimate for price volatility at the asset level, we construct a quarterly time
9
As a robustness check, we redo the calibration using a broader index: a composite of the NYSE, AMEX and Nasdaq. This
is a market capitalization index based on a larger cross-section of the market - consisting of over 8000 companies (as of 2015).
The results are similar. Moment estimates are within about 20% of each other. This is close enough that the simulations
differ imperceptibly. Results are available upon request.

15

series of the average S&P constituent stock price for the period 2000-2015. Compustat gives us the S&P
constituent tickets for each quarter. From CRSP, we extract each company‚Äôs stock price for that quarter.
Moments

Using the price data and implied dividend series, we estimate the dividend AR(1) process (2)

and the linear price equation (7). We let yÃÉt and Dxt be regression residuals. We estimate A = 16.03,
C = 7.865 and D = ‚àí5.7. We can then map these estimates into the underlying model parameters G, œÑx‚àí1 ,
œÑ0‚àí1 , ¬µ and œáx , using the model solutions (8), (9), (10) and (11), as well as
V ar[pt ] = (Ct2 +

B2
)œÑ ‚àí1 + Dt2 œÑx‚àí1 .
1 ‚àí G2 0

Of course, in the model, At , Ct and Dt take on different values at different dates t. So we need to choose
a theoretical date t at which to calibrate. Since our model requires solution by backwards induction, we
choose the last date T . Given t + 1 parameters, we can solve the model and find t parameters. Therefore,
we use the empirical price coefficient estimates to tell us the model coefficients at the end of our simulation,
denoted AT , CT and DT . We use steady state solutions of the model to map these estimated coefficients
back into model parameters.10 Note that B is constant because it is a simple function of fixed parameters.
Table 1: Parameters

G
0.937

¬µ
0.415

œÑ0‚àí1
0.245

œÑx‚àí1
0.551

œáx
0.686

r
1.03

œÅ
0.10

The first five parameters in Table 1 are calibrated to match the model and data values of the five
equations above. This is an exactly identified system. The riskless rate is set to match a 3% net return.
The last parameter is risk aversion. Risk aversion clearly matters for the level of the risky asset price. But
it is tough to identify. The reason for the difficulty is that if we change risk aversion, and then re-calibrate
the mean, persistence and variance parameters to match price coefficients and variance at the new risk
aversion level, the predictions of the model are remarkably stable. Roughly, doubling variance and halving
risk aversion mostly just redefines units of risk. Therefore, we use the risk aversion œÅ = 0.10 in what follows
and explore other values to show that the results do not depend on this choice. This œÅ implies a relative
risk aversion that is 0.65, not particularly high. In the appendix, we show an example of an alternative
parameterization with even lower risk aversion, show how the other parameters change, and show that it
yields similar results. We explore variations in other parameters as well.
Computation

The one thing that changes at each date is the total information capacity Kt . We start

the routine with KT = 10.11 In each period prior to that, we reduce Kt by 0.02. So if the last period is
denoted T , then KT ‚àí1 = 9.99 and KT ‚àí2 = 9.98. We simulate the model in this fashion for 500 periods.
We solve the model by choosing a final date T and using our estimated price function parameters to
initialize the backwards induction algorithm. We use the AT , BT , CT and DT from the data and our
10

Steady state solutions means solutions to a model where we believe that forever after that information would remain
constant Kt+1 = Kt and price would have stable coefficients, At+1 = At , Ct+1 = Ct and Dt+1 = Dt .
11
We checked the robustness of alternative KT values and found that it makes no difference to our conclusions. For example,
when we used KT = 5, we found that the results look as if we‚Äôd simulated the results with KT = 10 and truncated the time
series plot where Kt reaches 5. The other calibrated parameters are identical when we vary K, except for œáx , which moves
approximately proportionately with KT . For example, for Kt = 5, œáx falls by about one-half, from 0.68 to 0.31.

16

calibrated parameters to solve backwards for At , Bt , Ct and Dt , t = T ‚àí 1, ¬∑ ¬∑ ¬∑ , 1. Knowing time-t price
coefficients, we can solve for optimal information choices ‚Ñ¶f t and ‚Ñ¶xt . Then, we use the time-t solutions
and our model solution to get t ‚àí 1 information choices and price coefficients, and so forth. At each date,
we are using a function minimization routine that finds the zeros of a non-linear equation in
Multiple Equilibria

The non-linear equation in

Ct
Dt

Ct
Dt .

that characterizes the solution can have multiple

solutions. It turns out, that for the parameter values we explore, this equation has only one real root.

4

Numerical Results

A common concern is that, as financial technology improves, the extraction of information from order flow
will crowd out original research, and in so doing, will reduce the informativeness of market prices. On
the flip side, if technology allows investors to identify uninformed trades and take the other side of those
trades, such activity is thought to improve market liquidity. While both arguments have some grain of
truth in them, countervailing equilibrium effects mean that neither conjecture is correct.
We begin by revisiting the forces that make order flow information more valuable over time, this time,
assigning a magnitude to the effect. Then, we explore why the change from information production to
extraction does not harm price informativeness. Next, we use our numerical model to tease out the reasons
for stagnating market liquidity, despite a surge in activity that looks like liquidity provision. Finally, we
ask whether the model contradicts long-run trend in equity premia and explore the possibility of biased
technological change.

4.1

Transition from Fundamental to Order Flow Analysis

Figure 1: Evolution of fundamental analysis and order flow analysis. What is driving the change over time is an increase
in total information processing K. Fundamental information is the choice variable ‚Ñ¶f t , scaled by fundamental variance œÑ0‚àí1 .
Order flow information is the part of ‚Ñ¶xt that the investor can choose, ‚Ñ¶ÀÜxt = ‚Ñ¶xt ‚àí œÑh , scaled by non-fundamental order flow
variance œÑx‚àí1 .
10

Total Information Kt
Fundamental Analysis +ft
Order-.ow Analysis +xt

8

6

4

2

0
0

50

100

150

200

250

300

350

400

450

500

time

Figure 1 shows that order flow analysis is scarce initially. Consistent with Result 1, we see that when

17

information processing ability is limited, almost all of that ability is allocated to processing fundamental
information. But once fundamental information is sufficiently abundant, order-flow analysis takes off.
Not only does order flow processing surge, but it increases by so much that, the amount of fundamental
information declines, even though the total ability to process information has improved. Once it takes off,
order flow trading quickly comes to dominate fundamentals-based trading.
Exploring alternative parameter values reveals that this result is quite robust. ‚Ñ¶xt consistently surpasses
‚àö
‚àö
‚Ñ¶f t once Ct /Dt crosses œáx . There are parameters for which Ct /Dt never exceeds œáx , but even in those
cases, ‚Ñ¶xt increases faster, while ‚Ñ¶f t is concave. Thus, over time, the growth of fundamental analysis is
slowing down.

Figure 2: Hedge Funds are Shifting Away from Fundamental Analysis.
Source: Lipper TASS. Data is monthly from 1994-2015. Database reports on 17,534 live and defunct funds.
10

#10 8

Fundamental
Quantitative
Mixture
Quant & Mix

8

$

6
4
2
0
1995

1997

1999

2001

2003

2005

2007

2009

2011

2013

2015

(a) Assets Under Management per Fund
10

#10 11

Fundamental
Quantitative
Mixture
Quant & Mix

8

$

6
4
2
0
1995

1997

1999

2001

2003

2005

2007

2009

2011

2013

2015

(b) Total Assets Under management

Related trends in data The shift from fundamental to order flow analysis in our model should show
up empirically as a change in investment strategies. Indeed, there is some evidence that funds have shifted
their strategy over time, in a way that is plausibly consistent with our predictions. In the TASS database,
many hedge funds report that their fund has a ‚Äúfundamental‚Äù, ‚Äúmixture,‚Äù or ‚Äúquantitative‚Äù strategy.
Figure 2 illustrates the evolutions of assets under management, by fund, and in total, for these different
styles of funds. While other trends are also apparent, one clear trend is that fundamental analysis is
waning in recent years, in favor of strategies based on market data. This shift in reported style suggests a
transformation in the way information technologies are used in finance.
Another quite different indicator that points to the growing importance of order flow data comes from
the frequency of web searches. Google trends reports the frequency of searches that involve specific search
18

terms. Figure 3 shows that from 2004 to 2016, the frequency of searches for information about ‚Äúorder
flow‚Äù has risen roughly 3-fold. This is not an overall increase in attention to asset market information.
In contrast, the frequency of searches for information about ‚Äúfundamental analysis‚Äù fell by about one-half
over the same time period.
Figure 3: Google trends: Fraction of Google searches involving ‚Äúorder flow‚Äù or ‚Äúfundamental analysis.‚Äù Source:
Google trends. Data is the weekly fraction of searches involving these search terms. Series is normalized to make the highest
data point equal to 100.
100
90

Google trend index

80
70
60
50
40
30

Order-.ow
Fundamental Analysis

20
10
2004

2006

2008

2010

2012

2014

2016

Figure 4: Algorithmic Trading Growth 2001-2006. Source: Hendershott, Jones, and Menkveld (2011). Their proxy
for algorithmic trading is the dollar volume of trade per electronic message. The rise is more pronounced for largest market
cap (Q1) stocks. Q1-Q5 are the 5 quintiles of NYSE stocks, ordered by size (market capitalization).

Much of the trade against order flow takes the form of algorithmic trading. This happens for a couple
of reasons. First, while firm fundamentals are slow-moving, order flow can reverse rapidly. Therefore,
mechanisms that allow traders to trade quickly are more valuable for fast-moving order flow based strategies. Second, while fundamental information is more likely to be textual, partly qualitative, and varied in
nature, order flow is more consistently data-oriented and therefore more amenable to algorithmic analysis.
Hendershott, Jones, and Menkveld (2011) measure algorithmic trading and find that it has increased, but
it increased most rapidly during the period between the start of 2001 and the end of 2005. During this
six-year window, average trade size fell and algorithmic trading increased, about seven-fold (Figure 4).
19

This rapid transition is another feature of the data our model can explain.

4.2

Price Informativeness

Price informativeness measures of financial market efficiency in the sense that efficient prices aggregate
all the information known to market participants about future firm fundamentals. Informative prices are
important because they can inform firm managers‚Äô investment decisions and make equity compensation a
useful incentive tool by aligning firm value and equity compensation. Finally, informative prices allocate
new capital to the most productive firms.
Prices are informative if a change in future dividends is reflected in the price. Our equilibrium price
solution (7) reveals that this marginal price impact dpt /dyÃÉt is Ct . As the productivity of financial analysis
rises, and more information is acquired and processed, the informativeness of the price (Ct ) rises. Both
fundamental analysis and order flow analysis have the same objective, to help investors better discern the
true value of the asset. Thus both raise price informativeness.
The solid line labeled Ct in Figure 5 confirms that as financial analysis becomes more productive,
informativeness rises. The effect of a one-unit change in the dividend innovation, which is about 2 standard
deviations, increases the price by between 0 and 8 units. Since the average price level is about 80, this 2
standard deviation shock to dividends produces a negligible price change for very low levels of technology
and a 10% price rise when financial technology becomes more advanced.
Figure 5: Price Informativeness (Ct ) Rises and Price Impact of Trades (|Dt |) Stagnates. Ct is the impact
of future dividend innovations on price. (|Dt |) is the price impact of a one-unit uninformed trade. This illiquidity measure
is flat, despite the rise of market-making (order-flow) trades. (Ct /Dt )2 tells us the marginal value of order-flow information,
relative to fundamental information. The x-axis is time.
8
7
6
5

Price Info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

4
3
2
1
0
0

50

100

150

200

250

300

350

400

450

500

time

Related trends in data

Bai, Philippon, and Savov (2013) measure a long-run rise in equity price

informativeness. They measure price informativeness using a coefficient from a regression of future earnings
(at 1-year, 3-year and 5-year horizons) on the current ratio of market value to book value. Over the period
1960-2010, they find a 60% rise in three-year price informativeness and an 80% rise in five year price
informativeness, both of which are highly statistically significant.

20

Our claim is not that our model explains all of this phenomenon, or that we can match the timing
or magnitude of the increase. We only wish to suggest that our predictions are not at odds with other
long-run trends in financial markets. This is a model with only one risky asset, with no frictions, no habits
or low-frequency risks. It is deliberately kept simple, in order to explore the workings of a new mechanism
governing long run shifts in trading strategies. In reality, there are many assets and many sectors, which
each go through the transition from fundamental to order flow research at different times. The rise in
financial technology does not prompt more analysis of all assets at all times. Because of complementarity
in order flow analysis, more information drives up the price of one or a few assets, leaving others unstudied.
Thus, the average rise in price informativeness is overstated by the 1-asset model.12

4.3

Price Impact of Trades (Liquidity)

Market liquidity is an important object of study in finance (Hasbrouck, 2007). Liquidity is particularly
important in the debate on financial technology because it is one of the most common arguments in defense
of order flow based trading strategies. The claim is that traders who identify uninformed order flow and
offer to take the other side of those orders provide market liquidity.
A common metric of market liquidity is the sensitivity of an asset‚Äôs price to a buy or sell order. If a
buy order causes a large increase in the asset price and conversely a sell order causes a large fall, then
buying and selling this asset is costly. In such a market, trading strategies that require frequent or large
trades would have a harder time generating a profit. In our model, price impact is the impact of a oneunit hedging trade (dpt /d(‚àíxÃÉt )). We consider a hedging trade because the alternative is considering an
information-based trade. The impact of an information-based trade would reflect the fundamental (future
dividend) which must have moved to change the information. That question of how much a change in
the fundamental changes price is one we already explored. That is price informativeness. The linear price
solution (7) reveals that price impact is dpt /d(‚àíxÃÉt ) = ‚àíDt .
Looking at the dashed line in Figure 5, we see that the price impact of hedging trades, ‚àíDt , rises in the
early periods when only ‚Ñ¶f t is increasing and then declines as information becomes more abundant. But
what is striking about this result is that the changes are quite small. A hedging trade that is the size of 1%
of all outstanding asset shares would increase the price by 0.05 ‚àí 0.06 units. Since the average price is 80,
this amounts to a 0.6% ‚àí 0.7% (60 - 70 basis point) increase in the price. Exploring different parameters,
we see that the dynamics of market liquidity can vary. But what is consistent is that the changes are small
compared to the change in price informativeness.
Flat liquidity is a result of two competing forces. Recall from Section 2 that the liquidity of a risky asset
is determined by the riskiness (uncertainty) of its payoff. Purchases or sales of assets with more uncertain
payoffs have larger price effects. Result 4 tells us that more information today reduces uncertainty about
dividends dÀút , which in turn reduces the price impact of non-fundamental trades, improving liquidity. But
Result 5 tells us that if information technology is advanced tomorrow, then tomorrow‚Äôs shocks will have a
large effect on tomorrow‚Äôs price, which makes today‚Äôs payoff risky and today‚Äôs liquidity low. The reason
liquidity changes so little is that the static force (r/(r ‚àí G))V ar[yÃÉt |Iit ](Ct /Dt ) and the dynamic force
12

Our framework could come closer to the data with multiple assets. What we cannot do with multiple assets is characterize
the long run growth path that is central to this paper‚Äôs results. Because of the complementarity in order flow processing,
many such growth paths may exist. Therefore, we stick with our transparent one-asset model, with clear predictions, at the
expense of being able only to make qualitative comparisons with data.

21

Figure 6: Liquidity Fragility Grows. Figure plots |Dt | where there are three one-time, zero-probability, unanticipated
uncertainty shocks. Each shock is a change in expected precision œÑ0,t+1 to 1/2 ¬∑ œÑ0 , which is then not realized at t + 1.
9

Illquidity jDt j
8

7

6

5

4
0

50

100

150

200

250

300

350

400

450

500

time

‚àíœÅV ar[pt+1 + dÀút |Iit ] are nearly cancelling each other out.13
Related trends in data

Many empirical researchers have found little in the way of long-run trends in

market liquidity. Studying liquidity over the last century, Jones (2002) finds lots of cyclical variation, but
little trend in bid-ask spreads. Recent work by Koijen and Yogo (2016) however, measures a large fall in
the price impact of institutional traders. This may not be inconsistent with our results for two reasons.
First, our liquidity measure is the price impact of a non-informational trade. That is not the same as the
price impact of an institutional trader who will often be trading on information. Second, in many cases,
the way institutional traders have reduced their price impact is to find uninformed order flow to trade
against. To the extent that reduced price impact reflects more market making and less direct trading on
information, this reduced impact is consistent with our long-run order flow analysis trend.
Fragile Liquidity

Although liquidity remains mostly flat as technology improves, liquidity becomes

more fragile, meaning that it is more sensitive to changes in model parameters. For example, suppose
agents face a one-time increase in uncertainty. Specifically, investors find out that the variance of next
‚àí1
will be doubled, only for one period, and never again. The actual high
period‚Äôs dividend innovations œÑ0,t+1

variance shock is never realized, making this a pure belief shock. Figure 6 shows that when information
technology is poor, uncertainty has little effect on liquidity. But when information technology is very
productive, the same change in uncertainty results in a dramatic fall in market liquidity.
Liquidity is fragile in response to other shocks as well. A similar exercise where the cost of order flow
processing (œáx ) surges for one period produces similar outcomes. See appendix for detailed results.

4.4

Trend in the Equity Premium

Our focus is on how technological change affects trading strategies and market efficiency. But it is useful to
understand whether this mechanism is consistent or at odds with long-run trends in the equity premium.
The idea that information reduces risk, which lowers the return on risky assets is an old one. However,
exploring the magnitude of that decline in our setting offers some insight about the magnitude of the
13

A version of this effect can arise in a dynamic model with only fundamental analysis (see Cai (2016b)).

22

information trend in the model. If the model‚Äôs equity premium needed to fall by some outrageous amount,
in order to see any effect on price informativeness or liquidity, it would diminish the relevance of our
mechanism.
Figure 7: Technological Progress Reduces the Risk Premium Modestly. The risk premium is 1 +
where d¬Ø = ¬µ/(1 ‚àí G) is the average dividend payment. The x-axis is time.

d¬Ø
A+B d¬Ø

‚àí r,

0.06
Risk premium

E[pt+1 +d~t ]
E[pt ]

0.058
0.056
0.054
0.052
0.05
0

50

100

150

200

250

300

350

400

450

500

time

Instead, Figure 7 shows that the decline in the risk premium predicted by the model is quite modest.
The risk premium falls from a maximum of around 6% to 5% by the end. Of course, replicating the level
of the risk premium is not a success. That is nearly a by-product of calibrating the model to match the
price regression coefficients in (7). This calibration approach implies that the model matches the pricedividend ratio, and by extension, comes close to matching the equity premium. However, the decline in the
premium is related the growth in information processing. It tells us that the amount of information needed
to explain the declining equity premium is consistent with the amount needed to explain growing price
informativeness and flat liquidity. This is an over-identifying moment that lends support to our modeling
and calibration approach.
Related trends in data Jones (2002) documents that the equity premium is 1% lower in the 2000‚Äôs
than it was in the early 1900‚Äôs. Our results are also a similar magnitude to those of Lettau, Ludvigson, and
Wachter (2008) who report that the price-dividend ratio rose from 3 to 4 in the late 20th century. They
estimate a structural asset pricing model with regime switches in volatility and conclude that, because of
the fall in macro risk in the early 1990‚Äôs, the equity premium shifted down by 1.5%.

4.5

Unbalanced technological change

We have modeled technological progress that increases the potential precision of fundamental or order
flow information equally. But it is quite possible that technological progress has not been balanced. The
concern is that the productivity of order flow analysis has grown faster than fundamental analysis, because
fundamental information tends to be more textual or qualitative. To explore this possibility, we take an
extreme view of the imbalance and consider a world where the only efficiency growth is in order flow data
processing. The truth is likely somewhere between this unbalanced growth model and the balanced growth
model we analyzed before.
When only order flow data processing improves, a few things change (Figure 8). First, fundamental
information analysis falls monotonically, rather than rising and then falling. This is simply because when

23

order flow analysis becomes more productive, it makes fundamental information processing strictly less
attractive. Also, price informativeness (C/|D|) is mostly flat. In contrast, with balanced growth, it was
steadily increasing. The trajectory of C/|D| is flatter because, while both types of information processing
make prices clearer signals, fundamental information processing improves signal quality by more.
What is surprising is that C/|D| does not fall. Even C alone does not fall. Even though the discovery
of new information about future dividends ‚Ñ¶f t falls precipitously, dividend information is still more heavily
weighted (C) and more clearly reflected (C/|D|) in prices. Order flow traders are adept at inferring what
others know from prices. This inference makes them well-informed about yÃÉt , albeit indirectly. If many
traders have precise knowledge of order flow, the average trader ends up being well-informed about yÃÉt , even
if less research on yÃÉt was done by the market. The net result of less research but more learning through
prices is an increase in total information. This shows up in prices as a higher price impact C of changes in
dividend innovations.
In short, our main conclusions are unaltered. Liquidity is still flat. Market efficiency does not plummet,
by either measure, even through order flow analysis crowds out fundamental analysis. The unbalanced
change simply affects the rate at which market efficiency evolves.
Figure 8: Unbalanced Technological Progress: œáx falls. Information choices (left) and market efficiency (right) with
progress only in order flow analysis. Ct is the impact of future dividend innovations on price. (‚àíDt ) is the price impact of a
one-unit uninformed trade. (Ct /Dt )2 tells us the marginal rate of transformation of order-flow and fundamental information.
The x-axis is time. This version of the model reduces œáx over time, without changing K.
8
7
3
6
5

2.5

2

Fundamental +f t
Extraction +xt

4
3

Price info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

2

1.5

1
1
0
50

5

100

150

200

250

300

350

400

450

500

50

100

150

200

250

300

350

time

time

(a) Information Acquisition

(b) Price Coefficients

400

450

500

Real Economic Effects

We‚Äôre argued that the growth in financial technology has transformed the financial sector and affected
financial market efficiency in unexpected ways. But why should we care about financial market efficiency?
What are the consequences for real economic activity? In this section, we provide a sketch of two channels through which changes in informativeness and price impact can alter the efficiency of real business
investment.

24

5.1

Manager incentive effects

The key friction in the first spillover model is that the manager‚Äôs effort choice is unobserved by equity
investors. The manager exerts costly effort only because he is compensated with equity. The manager only
has an incentive to exert effort if the value of his equity is responsive to his effort. Because of this, the
efficiency of the manager‚Äôs effort choice depends on asset price informativeness.
Of course, this friction reflects the fact that the wage is not an unconstrained optimal contract. The
optimal compensation for the manager is to pay him for effort directly or make him hold all equity in the
firm. We do not model the reasons why this contract is not feasible because it would distract from our main
point. Our stylized sketch of a model is designed to show how commonly-used compensation contracts
that tie wages to firm equity prices (e.g., options packages) also tie price informativeness to optimal effort.
Time is discrete and infinite. There is a single firm whose profits dÀút depend on a firm manager‚Äôs labor
choice lt . Specifically, dÀút = g(lt ) + yÃÉt , where g is increasing and concave and yÃÉt ‚àº N (0, œÑ0‚àí1 ) is unknown at
t. Because effort is unobserved, the manager‚Äôs pay wt is tied to the equity price pt of the firm: wt = wÃÑ + pt .
However, effort is costly. We normalize the units of effort so that a unit of effort corresponds to a unit of
utility cost. Insider trading laws prevent the manager from participating in the equity market. Thus the
manager‚Äôs objective is
Um (lt ) = wÃÑ + pt ‚àí lt

(18)

The firm pays out all its profits as dividends each period to its shareholders. Firm equity purchased at
time t is a claim to the present discounted stream of future profits {dÀút , dÀút+1 . . .}.
The preferences, endowments, budget constraint and information choice sets of investors are the same
as before. Order flow signals are defined as before. Fundamental analysis now generates signals of the
form Œ∑f it = g(lt ) + yÃÉt + Àúf it , where the signal noise is Àúf it ‚àº N (0, ‚Ñ¶f t ). Investors choose the precision ‚Ñ¶f t
of this signal, as well as their order flow signal ‚Ñ¶xt . Equilibrium is defined as before, with the additional
condition that the manager effort decision maximizes (18).
Solution

As before, the asset market equilibrium has a linear equilibrium price:
pt = At + Ct (g(lt ) + yÃÉt ) + Dt xÃÉt

(19)

Notice that since dividends are not persistent, dt‚àí1 is no longer relevant for the t price
The firm manager chooses his effort to maximize (18). The first order condition is Ct g 0 (lt ) = 1, which
yields an equilibrium effort level lt = (g 0 )‚àí1 (1/Ct ). Notice that the socially optimal level would set the
marginal utility cost of effort equal to the marginal product g 0 (lt ) = 1. When Ct is below one, managers
under-provide effort, relative to the social optimum because their stock compensation moves less than
one-to-one with the true value of their firm.
Similar to before, the equilibrium level of price informativeness C is
1
(1 ‚àí œÑ0 V ar[g(lt ) + yÃÉt |Iit ]) .
(20)
r
Thus, as more information is analyzed, dividend uncertainty (V ar[g(lt )+ yÃÉt |Iit ]) falls, Ct rises and managers
Ct =

are better incentivized to exert optimal effort. While the model is stylized and the solution presented here

25

is only a sketch, it is designed to clarify why trends in financial analysis matter for the real economy.
The most obvious limitation of the model is its single asset. One might wonder whether the effect would
disappear if the asset‚Äôs return was largely determined by aggregate risk, which is out of the manager‚Äôs
control. However, if there were many assets, one would want to rewrite the compensation contract so that
the manager gets rewarded for high firm-specific returns. This would look like benchmarked performance
pay. If the contract focused on firm-specific performance, the resulting model would look similar to the
single asset case here.
In short, this model suggests that trends in the financial sector are all positive for real economic efficiency
because more analysis of either type makes price more informative and thereby improves incentives.

5.2

Equity Issuance Cost

The second real spillover highlights a downside of financial technology growth. More information technology
creates future information risk, which raises the risk of holding equity, making capital more costly for firms.
Suppose that a firm has a profitable investment opportunity and wants to issue new equity to raise
capital for that investment. For every dollar of capital invested, the firm can produce an infinite stream of
dividends dt . Dividends follow the same stochastic process as described in the original model. However,
the firm needs funds to invest and raises those finds by issuing equity. The firm chooses a number of shares
sÃÑ to maximize the total revenue raised (maximize output). Each share sells at price p, which is determined
by the investment market equilibrium, minus an investment or issuance cost:
E[sÃÑp ‚àí c(sÃÑ)|If ]
The firm makes its choice conditional on the same prior information that all the investors have. But does
not condition on p. It does not take price as given. Rather, the firm chooses sÃÑ, taking into account its
impact on the equilibrium price. The change in issuance is permanent and unanticipated. The rest of the
model is the same as the dynamic model in section 1.
Solution

Given the new asset supply sÃÑ, the asset market solution and information choice solution to the

problem are the same as before. But how the firm chooses sÃÑ depends on how new issuance affects the asset
price. When the firm issues new equity, all asset market participants are aware that new shares are coming
online. Equity issuance permanently changes the known supply of the asset sÃÑ. Supply sÃÑ enters the asset
price in only one place in the equilibrium pricing formula, through At . Recall from 8 that


1
r¬µ
Àú
At =
At+1 +
‚àí œÅV ar[pt+1 + dt |I]sÃÑ .
r
r‚àíG

(21)

Taking At+1 as given for the moment, dAt /dsÃÑ = ‚àíœÅV ar[pt+1 + dÀút |I]/r. In other words, the impact of a
one-period change in asset supply depends on the conditional variance (the uncertainty about) the future
asset payoff, pt+1 + dÀút . Recall from the discussion of price impact of trades in Section 4.3 that in a dynamic
model, more information analysis reduces dividend uncertainty but can result in more uncertainty about
future prices. These two effects largely offset each other.
Figure 9 plots the modest increase and decrease in payoff risk from these competing effects on the price
impact of issuing new equity. To give the units of the price impact some meaning, the issuance cost is
26

Figure 9: Payoff Risk and The Cost of Raising Capital. The left panel shows payoff risk, which is V ar[pt+1 + dÀút |It ].
The right panel shows the absolute price impact of a one-unit change in issuance, normalized by the average level of dividends.
5

50

Payo, Risk V ar[pt+1 + dt jIt ]

48

Price Impact dAt =d7
s

4.8

46

4.6

44

4.4

42

4.2

40

4

38

3.8

36

3.6

34

3.4

32

3.2
3

30
0

50

100

150

200

250

300

350

400

450

0

500

50

100

150

200

250

300

350

400

450

500

time

time

scaled by the average dividend payment so that it can be interpreted as the change in the price-dividend
ratio from a one-unit change in equity supply. Thus a one-unit increase in issuance reduces the asset price
by an amount equal to 4 months of dividends, on average.
We learn that technological progress in information analysis ‚Äì of either type ‚Äì initially makes asset
payoffs slightly more uncertain, which makes it more costly to issue new equity. When we now take into
account that the increase in asset supply is permanent, the effect of issuance is amplified, relative to the
one-period (fixed At+1 ) case. But when analysis becomes sufficiently productive, issuance costs decrease
again, as the risk-reducing power of more precise information dominates.
Again, a key limitation of the model is its single asset. With multiple assets, one firm‚Äôs issuance is a
tiny change in the aggregate risk supply. But the change in the supply of firm-specific risk looks similar to
this problem. If one were to evaluate this mechanism quantitatively, the magnitude would depend on how
much the newly issued equity loads on idiosyncratic risk versus aggregate risk.

6

Conclusion

Technological progress is the driving force behind most models of long-run economic growth. Yet it is
surprisingly absent in models of the financial economy. We explore the consequences of a simple deterministic increase in the productivity of information processing in the financial sector. While studies have
documented an increase in price informativeness (Bai, Philippon, and Savov, 2013), we know of no theories
that explore the consequences of such changes on market equilibrium or efficiency.
We find that when the financial sector becomes more efficient at processing information, it changes the
incentives to acquire information about future dividends (fundamentals) versus order flow (non fundamental
shocks to price). Thus a simple rise in information processing productivity can explain a transformation
of financial analysis from a sector that primarily investigates the fundamental profitability of firms to a
sector that does a little fundamental analysis but mostly concentrates on acquiring and processing client
order flow. This is consistent with suggestive evidence that the nature of financial analysis and associated
trading strategies have changed.

27

Many feared that this technological transformation was harming market efficiency, while others argued
that markets are more liquid/efficient than ever before. The concern was that the decline of fundamental
analysis would compromise price informativeness. We do not find that to be the case. Although fundamental analysis declines, price informativeness continues to rise. The reason is that even if many traders
are extracting others‚Äô information, this still makes the average trader better informed and the price more
informative. But the benefits of the technological transformation may also be overstated. The promise
that traders standing ready to take the other side of uninformed traders would improve market liquidity
is only half the story. What this narrative misses is that more informed traders in the future make prices
react more strongly to new information, which makes future asset values riskier. This increase in risk
makes traders move market prices by more and pushes market liquidity back down. The net effect could
go either way and is likely to be small.
Of course, there are many other features one might want to add to this model to speak to other
related trends in financial markets. One might make fundamental changes more persistent than order
flow innovations so that different styles of trade were associated with different trading volumes. Another
possibility is to explore regions in this model where the equilibrium does not exist and use the non-existence
as the basis for a theory of market breakdowns or freezes. Another extension might ask where order flow
signals come from. In practice, people observe order flow because they intermediate trades. Thus, the value
of the order flow information might form the basis for a new theory of intermediation. In such a world,
more trading might well generate more information for intermediaries and faster or stronger responses of
markets to changes in market conditions. Finally, one might regard this theory as a prescriptive theory
of optimal investment, compare it to investment practice, and compute expected losses from sub-optimal
information and portfolio choices. For example, a common practice now is to blend fundamental and
order flow trading by first selecting good fundamental investment opportunities and then using order flow
information to time the trade. One could construct such a strategy in this model, compare it to the optimal
blend of trading strategies, and see if the optimal strategy performs better on market data.
While this project with its one simple driving force leaves many question unanswered, it also provides
a tractable foundation on which to build, to continue exploring how and why asset markets are evolving,
as financial technology improves.

28

References
Angeletos, M., and J. La‚ÄôO (2014): ‚ÄúSentiments,‚Äù Econometrica, 81(2), 739‚Äì779.
Asriyan, V., and V. Vanasco (2014): ‚ÄúInformed Intermediation over the Cycle,‚Äù Stanford University Working
Paper.
Babus, A., and C. Parlatore (2015): ‚ÄúStrategic Fragmented Markets,‚Äù Working Paper New York University
Stern school of Business.
Bai, J., T. Philippon, and A. Savov (2013): ‚ÄúHave Financial Markets Become More Informative?,‚Äù NBER
Working Paper 19728.
Bali, T. G., S. J. Brown, and M. O. Caglayan (2014): ‚ÄúMacroeconomic Risk and Hedge Fund Returns,‚Äù
Journal of Financial Economics, 114(1), 1‚Äì19.
Banerjee, S., and B. Green (2015): ‚ÄúSignal or noise? Uncertainty and learning about whether other traders are
informed,‚Äù Journal of Financial Economics, 117 (2), 398‚Äì423.
Biais, B., T. Foucault, and S. Moinas (2015): ‚ÄúEquilibrium Fast Trading,‚Äù Journal of Financial Economics,
116, 292‚Äì313.
Brunnermeier, M., M. Sockin, and W. Xiong (2017): ‚ÄúChina‚Äôs Model of Managing the Financial System,‚Äù
Working Paper, Princeton University.
Cai, Z. (2016a): ‚ÄúDynamic Information Acquisition in an Infinite-Horizon Framework,‚Äù Working Paper, University
of Minnesota.
(2016b): ‚ÄúDynamic Information Complementarity in Information Acquisition,‚Äù Working Paper, University
of Minnesota.
Cespa, G., and X. Vives (2012): ‚ÄúDynamic Trading and Asset Prices: Keynes vs. Hayek,‚Äù Review of Economic
Studies, 79 (2), 539‚Äì580.
Crouzet, N., I. Dew-Becker, and C. Nathanson (2016): ‚ÄúA Model of Multi-Frequency Trade,‚Äù Northwestern
University Working Paper.
Davila, E., and C. Parlatore (2016): ‚ÄúTrading Costs and Informational Efficiency,‚Äù NYU Working Paper.
Du, S., and H. Zhu (2017): ‚ÄúWhat Is the Optimal Trading Frequency in Financial Markets?,‚Äù Review of Financial
Studies, forthcoming.
Edelman, D., W. Fund, and D. A. Hsieh (2013): ‚ÄúExploring Uncharted Territories of the Hedge Fund Industry:
Empirical Characteristics of Mega Hedge Fund Firms,‚Äù Journal of Financial Economics, 109(3), 734‚Äì758.
Glode, V., R. Green, and R. Lowery (2012): ‚ÄúFinancial Expertise as an Arms Race,‚Äù Journal of Finance, 67,
1723‚Äì1759.
Grossman, S., and J. Stiglitz (1980): ‚ÄúOn the impossibility of informationally efficient markets,‚Äù American
Economic Review, 70(3), 393‚Äì408.
Hasbrouck, J. (2007): Empirical Market Microstructure. Oxford University Press, first edn.
He, Z. (2009): ‚ÄúThe Sale of Multiple Assets with Private Information,‚Äù Review of Financial Studies, 22, 4787‚Äì4820.

29

Hendershott, T., C. Jones, and A. Menkveld (2011): ‚ÄúDoes Algorithmic Trading Improve Liquidity?,‚Äù Journal
of Finance, 66, 1‚Äì34.
Hendershott, T., and A. Menkveld (2014): ‚ÄúPrice Pressures,‚Äù Journal of Financial Economics, 114, 405‚Äì423.
Jones, C. (2002): ‚ÄúA Century of Stock Market Liquidity and Trading Costs,‚Äù Columbia University Working Paper.
Kacperczyk, M., J. Nosal, and L. Stevens (2015): ‚ÄúInvestor Sophistication and Capital Income Inequality,‚Äù
Imperial College Working Paper.
Koijen, R., and M. Yogo (2016): ‚ÄúAn Equilibrium Model of Institutional Demand and Asset Prices,‚Äù NYU
Working Paper.
Lettau, M., S. Ludvigson, and J. Wachter (2008): ‚ÄúThe Declining Equity Premium: What Role Does Macroeconomic Risk Play?,‚Äù Review of Financial Studies, 21 (4), 1653‚Äì1687.
Manzano, C., and X. Vives (2010): ‚ÄúPublic and Private Learning from Prices, Strategic Substitutability and
Complementarity, and Equilibrium Multiplicity,‚Äù CEPR Discussion Papers 7949, C.E.P.R. Discussion Papers.
Philippon, T. (2015): ‚ÄúHas the U.S. Finance Industry Become Less Efficient? On the Theory and Measurement of
Financial Intermediation,‚Äù American Economic Review, 105(4), 14081438.
Wang, J. (1993): ‚ÄúA Model of Intertemporal Asset Prices Under Asymmetric Information,‚Äù Review of Economic
Studies, 60, 249‚Äì282.
Yang, L., and J. Ganguli (2009): ‚ÄúComplementarities, Multiplicity, and Supply Information,‚Äù Journal of the
European Economic Association, 7(1), 90‚Äì115.
Yang, L., and H. Zhu (2016): ‚ÄúBack-Running: Seeking and Hiding Fundamental Information in Order Flows,‚Äù .

30

A
A.1

Model Solution Details
Bayesian Updating

To form the conditional expectation, E[fit |Iit ], we need to use Bayes‚Äô law. But first, we need to know what signal investors
extract from price, given their observed endowment exposure ht and their order-flow signal Œ∑x . We can rearrange the the linear
price equation (7) to write a function of the price is the dividend innovation plus mean zero noise: Œ∑pit = yÃÉt + (Dt /Ct )(xÃÉt ‚àí
E[xÃÉt |Œ∑xit ]), where the price signal and the signal precision are
Œ∑pit ‚â° (pt ‚àí At ‚àí Bdt‚àí1 ‚àí Dt E[x|Œ∑xit ])/Ct

(22)

‚Ñ¶pt ‚â° (Ct /Dt )2 (œÑx + ‚Ñ¶xt )

(23)

For the simple case of an investor who learned nothing about order flow (E[x] = 0) the information contained in prices is
(pt ‚àí At ‚àí Bdt )/Ct , which is equal to yÃÉt + Dt /Ct xÃÉt . Since xÃÉt is a mean-zero random variable, this is an unbiased signal of the
asset dividend innovation yÃÉt . The variance of the signal noise is V ar[D/Cx] = (D/C)2 œÑx‚àí1 . The price signal precision ‚Ñ¶pt is
the inverse of this variance.
But conditional on hit and Œ∑xit , xÃÉt is typically not a mean-zero random variable. Instead, investors use Bayes‚Äô law to
combine their prior that xÃÉt = 0, with precision œÑx with their endowment and order flow signals: hit with precision œÑh and Œ∑xit
with precision ‚Ñ¶xit . The posterior mean and variance are
E[x|hit , Œ∑xit ] =

œÑh hit + (‚Ñ¶xit ‚àí œÑh )Œ∑xit
œÑx + ‚Ñ¶xit

(24)

1
œÑx + ‚Ñ¶xit

(25)

V [x|hit , Œ∑xit ] =

Since that is equal to yÃÉt + Dt /Ct (xÃÉt ‚àí E[xÃÉt |Œ∑xit ]), the variance of price signal noise is (Dt /Ct )2 V ar[xÃÉt |Œ∑xit ]. In other words,
the precision of the price signal for agent i (and therefore for every agent since we are looking at symmetric information choice
equilibria) is ‚Ñ¶pit ‚â° (Ct /Dt )2 (œÑx + ‚Ñ¶xit ).
Now, we can use Bayes‚Äô law for normal variables again to form beliefs about the asset payoff. We combine the prior ¬µ,
the price/order-flow information Œ∑pit , and the fundamental signal Œ∑f it into a posterior mean and variance:
E[yÃÉt |Iit ] = (œÑ0 + ‚Ñ¶pit + ‚Ñ¶f it )‚àí1 (œÑ0 ¬µ + ‚Ñ¶pit Œ∑pit + ‚Ñ¶f it Œ∑f it )

(26)

V [yÃÉt |Iit ] = (œÑ0 + ‚Ñ¶pit + ‚Ñ¶f it )‚àí1

(27)

Average expectations and precisions: Next, we integrate over investors i to get the average conditional expectations. Begin
by considering average price information. The price informativeness is ‚Ñ¶pit ‚â° (Ct /Dt )2 (œÑx + ‚Ñ¶xit ). In principle, this can vary
across investors. But since all are ex-ante identical, they make identical information decisions. Thus, ‚Ñ¶pit = ‚Ñ¶pt for all
investors i. Since this precision is identical for all investors, we drop the i subscript in what follows. But the realized price
signal still differs because signal realizations are heterogeneous. Since the signal precisions are the same for all agents, we
R
can just integrate over signals to get the average signal: Œ∑pit di = (1/Ct )(pt ‚àí At ‚àí Bdt‚àí1 ) ‚àí (Dt /Ct )V ar(xÃÉt |I)‚Ñ¶xt xÃÉt . Since
2
‚Ñ¶‚àí1
pt = (D/C) V ar(x|I), we can rewrite this as
Z

1
Ct ‚àí1
(pt ‚àí At ‚àí Bdt‚àí1 ) ‚àí
‚Ñ¶ ‚Ñ¶xt xÃÉt
(28)
C
Dt pt
Next, let‚Äôs define some conditional variance / precision terms that simplify notation. The first term, ‚Ñ¶t , is the precision
of future price plus dividend (the asset payoff). It comes from taking the variance of the pricing equation (7). It turns out
can be decomposed into a sum of two terms. The first, VÃÇ , is the variance of the dividend innovation.
that the variance ‚Ñ¶‚àí1
t
This variance depends on information choices ‚Ñ¶f t and ‚Ñ¶xt . The other term Zt depends on future information choices through
t + 1 price coefficients.
Œ∑pi di =

VÃÇt ‚â° V ar(yÃÉt |I) = (œÑ0 + ‚Ñ¶f + ‚Ñ¶pt )‚àí1 = (œÑ0 + ‚Ñ¶f + (C/D)2 (œÑx + ‚Ñ¶xt ))‚àí1

(29)

2
2
‚Ñ¶‚àí1
‚â° V ar[pt+1 + dÀút |I] = Ct+1
œÑ0‚àí1 + Dt+1
œÑx‚àí1 + (1 + B)2 VÃÇ
t

(30)

31

Zt =

œÅ
2
2
(r ‚àí G)(Ct+1
œÑ0‚àí1 + Dt+1
œÑx‚àí1 )
r

(31)

r
r
Zt + (
)2 VÃÇ
œÅ(r ‚àí G)
r‚àíG

(32)

=
‚Ñ¶‚àí1
t

The last equation (32) shows the relationship between ‚Ñ¶, VÃÇ and Zt . This decomposition is helpful because we will repeatedly
take derivatives where we take future choices (Zt ) as given and vary current information choices (VÃÇ ).
Next, we can compute the average expectations
Z

Z

A.2




1
Ct ‚àí1
E[yÃÉt |Iit ] di = VÃÇt ‚Ñ¶f t yÃÉt + ‚Ñ¶pt
(pt ‚àí At ‚àí Bdt‚àí1 ) ‚àí
‚Ñ¶pt ‚Ñ¶xt xÃÉt
C
Dt


1
Ct
= VÃÇ ‚Ñ¶f t yÃÉt + ‚Ñ¶pt (pt ‚àí At ‚àí Bdt‚àí1 ) ‚àí
‚Ñ¶xt xÃÉt
C
Dt

E[pt+1 + dÀút |Iit ]

di = At + (1 + B)E[dÀút |Iit ] = At + (1 + B) (¬µ + Gdt‚àí1 + E[yÃÉt |Iit ]) .

(33)

(34)

(35)

Solving for equilibrium prices

The new price conjecture is
pt = At + Bt dt + Ct yÃÉt + Dt xÃÉt

(36)

where the sequence of pricing coefficients is known at every date. The signals Œ∑f it and Œ∑xit are the same as before, except that
their precisions ‚Ñ¶f t and ‚Ñ¶xt may change over time if that is the solution to the information choice problem.
The conditional expectation and variance of yÃÉt (26) and (27) are the same, except that the ‚Ñ¶pt term gets a t subscript now
because ‚Ñ¶pt ‚â° (Ct /Dt )2 (œÑx + ‚Ñ¶xt ). Likewise the mean and variance of xÃÉt (24) and (25) are the same with a time-subscripted
‚Ñ¶xt . Thus, the average signals are the same with t-subscripts:
Z
Œ∑pi di =

Dt
1
(pt ‚àí At ‚àí Bt dt ) ‚àí
V ar(x|I)‚Ñ¶xt xÃÉt
Ct
Ct

(37)

2
Since ‚Ñ¶‚àí1
pt = (Dt /Ct ) V ar(x|I), we can rewrite this as

Z

1
Ct ‚àí1
(pt ‚àí At ‚àí Bt dt ) ‚àí
‚Ñ¶ ‚Ñ¶xt xÃÉt
(38)
Ct
Dt pt
Solving for non-stationary equilibrium prices To solve for equilibrium prices, start from the portfolio first-order
condition for investors (6) and equate total demand with total supply. The total risky asset demand (excluding hedging
shocks) is
Œ∑pi di =

Z
qit di =






1
1
Ct
‚Ñ¶t At+1 + (1 + Bt+1 ) ¬µ + Gdt + VÃÇt ‚Ñ¶f t yÃÉt + ‚Ñ¶pt (pt ‚àí At ‚àí Bt dt ) ‚àí
‚Ñ¶xt xÃÉt
‚àí pt r .
œÅ
Ct
Dt

(39)

The market clearing condition equates the expression above to the residual asset supply xÃÑ + xÃÉt . The model assumes the
asset supply is 1. We use the notation xÃÑ here for more generality because then we can apply the result to the model with
issuance costs where asset supply is a choice variable. Rearranging the market clearing condition (just multiplying through
and bringing p terms to the left) yields
by œÅ‚Ñ¶‚àí1
t
1
]pt = ‚àíœÅ‚Ñ¶‚àí1
t (xÃÑ + xÃÉt ) + At+1
Ct
1
Ct
+(1 + Bt+1 )(¬µ + Gdt ) + (1 + Bt+1 )VÃÇt ‚Ñ¶f t yÃÉt ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt (At + Bt dt ) ‚àí (1 + Bt+1 ) VÃÇt ‚Ñ¶xt xÃÉt
Ct
Dt
Solving for p and matching coefficients yields
[r ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt

At = [r ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt

1
1 ‚àí1
] [At+1 + (1 + Bt+1 )¬µ ‚àí œÅ‚Ñ¶‚àí1
At ]
t xÃÑ ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt
Ct
Ct

(40)

(41)

Multiplying both sides by the inverse term:
rAt ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt

1
1
At = At+1 + (1 + Bt+1 )¬µ ‚àí œÅ‚Ñ¶‚àí1
At
t xÃÑ ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt
Ct
Ct

32

(42)

and cancelling the 1 + B term on both sides leaves
At =


1
At+1 + (1 + Bt+1 )¬µ ‚àí œÅ‚Ñ¶‚àí1
t xÃÑ
r

(43)

Matching coefficients on dt yields:
Bt = [r ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt



Bt
1 ‚àí1
(1 + Bt+1 )G ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt
]
Ct
Ct

(44)

Multiplying on both sides by the inverse term
rBt ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt

1
Bt
Bt = (1 + Bt+1 )G ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt
Ct
Ct

(45)

and cancelling the last term on both sides yields
1
(1 + Bt+1 )G
(46)
r
As long as r and G don‚Äôt vary over time, it seems that a stationary solution for B at least exists. That stationary solution
would be (9).
Next, collecting all the terms in yÃÉt
Bt =

Ct = [r ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt

1 ‚àí1
] (1 + Bt+1 )VÃÇt ‚Ñ¶f t
Ct

(47)

multiplying both sides by the first term inverse yields rCt ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt = (1 + Bt+1 )VÃÇt ‚Ñ¶f t . Then dividing through by r
and collecting terms in VÃÇ (1 + Bt+1 ) yields Ct = (1/r)(1 + Bt+1 )VÃÇt (‚Ñ¶pt + ‚Ñ¶f t ). Next, using the fact that VÃÇ ‚àí1 = œÑ0 + ‚Ñ¶pt + ‚Ñ¶f ,
we get Ct = 1/r(1 + Bt+1 )(1 ‚àí œÑ0 VÃÇt ). Of course the VÃÇ term has Ct and Dt in it. If we use the stationary solution for B (if r
and G don‚Äôt vary) then we can simplify to get
Ct =

1
(1 ‚àí œÑ0 VÃÇt ).
r‚àíG

(48)

Lemma 1 If ‚Ñ¶f t > 0, then Ct > 0.
Proof: Using equation (48), it suffices to show that 1/(r ‚àí G) > 0 and (1 ‚àí œÑ0 VÃÇt ) > 0. From the setup, we assumed that
r > 1 and G < 1. By transitivity, r > G and r ‚àí G > 0. For the second term, we need to prove equivalently that œÑ0 VÃÇt < 1
and thus that œÑ0 < VÃÇt‚àí1 . Recall from (29) that VÃÇ ‚àí1 = œÑ0 + ‚Ñ¶f t + ‚Ñ¶pt . Since ‚Ñ¶f t and ‚Ñ¶pt are defined as precisions, they must
be non-negative. Furthermore, we supposed that ‚Ñ¶f t > 0. Thus, œÑ0 < VÃÇt‚àí1 , which completes the proof. 
Finally, we collect terms in xÃÉt .
Dt = [r ‚àí (1 + Bt+1 )VÃÇt ‚Ñ¶pt

1 ‚àí1
Ct
] [‚àíœÅ‚Ñ¶‚àí1
‚àí (1 + Bt+1 ) VÃÇt ‚Ñ¶xt ]
t
Ct
Dt

(49)

multiply by the inverse term, and the use ‚Ñ¶pt = (Ct /Dt )2 (œÑx + ‚Ñ¶xt ) to get
rDt ‚àí (1 + Bt+1 )VÃÇt

Ct
Ct
(œÑx + ‚Ñ¶xt ) = ‚àíœÅ‚Ñ¶‚àí1
‚àí (1 + Bt+1 ) VÃÇt ‚Ñ¶xt
t
Dt
Dt

(50)

Then, adding (1 + B)C/DVÃÇ ‚Ñ¶x to both sides, and substituting in B (stationary solution), we get
Dt ‚àí

1
Ct
œÅ
VÃÇt œÑx
= ‚àí ‚Ñ¶‚àí1
r‚àíG
Dt
r t

(51)

Of course, Dt still shows up quadratically, and also in VÃÇt . The future coefficient values Ct+1 and Dt+1 show up in ‚Ñ¶t .
Lemma 2 Dt < 0
Proof: Start from equation (53) in the LongRunEvolution Nov2016, substitute in (29) but does not set ‚Ñ¶f = 0. Since we will
often treat the signal-to-noise ratio in prices as a single variable, we define
Œæ‚â°
Also let: Œ± ‚â°

œÅr
.
r‚àíG

Ct
Dt

This gives the general version of (56):

33

(52)

Œæ 3 (Zt œÑx + Zt ‚Ñ¶x ) + Œæ 2 (‚Ñ¶x ) + Œæ(Œ± + Zt œÑ0 + Zt ‚Ñ¶f ) + ‚Ñ¶f = 0

(53)

Then, use the budget constraint to express the first order conditions as (15). One can solve for both ‚Ñ¶x and ‚Ñ¶f in terms of Œæ:

‚Ñ¶f =
‚Ñ¶x =


œáf
K
œáx

1
K
2
œáf 4 
1 + œáx Œæ
1‚àí

1
1+

œáf 4
Œæ
œáx

(54)
 12

œá

=

K œáfx



œáx 1 +

œáf 4 
Œæ
œáx

1
2

Œæ2 =

1
Œæ 2 œáf 
K
2
œáf 4 
œáx œáf 1 + œá Œæ
x

(55)

Now I can substitute both of these into equation (53), which fully determines Œæ, in terms of exogenous variables.


Œæ Œæ 2 Zt œÑx + Œ± + Zt œÑ0 + Œæ 2 ‚Ñ¶x (1 + ŒæZt ) + ‚Ñ¶f (1 + ŒæZt ) = 0

(56)

First note that
‚Ñ¶f + Œæ 2 ‚Ñ¶x = ‚àí

Œæ(Œæ 2 Zt œÑx + Œ± + Zt œÑ0 )
(1 + ŒæZt )

where the left hand side is the objective function. So we know the maximized value of objective function solely as a function
C
. Keep in mind that since we already imposed an optimality condition (??), this latter equation holds only at the
of Œæ = D
optimum.
Substituting in for ‚Ñ¶f t and ‚Ñ¶xt from (54) and (55) yields an equation that implicitly defines Œæ as a function of primitives,
K and future equilibrium objects, embedded in Zt .


1
œáf 4 
K
2
Œæ Œæ 2 Zt œÑx + Œ± + Zt œÑ0 + (1 + ŒæZt )(1 +
Œæ )
=0
œáf 4 
œáx
œáf 1 + œáx Œæ
Œæ 3 Zt œÑx + Œæ(Œ± + Zt œÑ0 ) + (1 + ŒæZt )(

K 12
œáf 4 12
) (1 +
Œæ ) =0
œáf
œáx

(57)

The left hand side must equal zero for the economy to be in equilibrium. However, all the coefficients K, œáf , œáx , œÑ0 , œÑx are
assumed to be positive. Furthermore, Zt is a variance. Inspection of (31) reveals that it must be strictly positive. Thus, the
only way that the equilibrium condition can possibly be equal to zero is if Œæ < 0. Recall that Œæ = Ct /Dt . The previous lemma
proved that Ct > 0. Therefore, it must be that Dt < 0.

A.3

Solving Information Choices

Details of Step 3: Compute ex-ante expected utility. Note that the expected excess return (E[pt+1 + dÀút |Iit ] ‚àí pt r) depends on
fundamental and supply signals, and prices, all of which are unknown at time t = 0. Because asset prices are linear functions
of normally distributed shocks, E[pt+1 + dÀút |Iit ] ‚àí pt r, is normally distributed as well. Thus, (E[pt+1 + dÀút |Iit ] ‚àí pt r)‚Ñ¶(E[pt+1 +
dÀút |Iit ] ‚àí pt r) is a non-central œá2 -distributed variable. Computing its mean yields the expression in the text.
Details of Step 4:
Solve for fundamental information choices. Note that in expected utility (14), the choice variables ‚Ñ¶f t and ‚Ñ¶xt enter
+
+
only through the posterior variance ‚Ñ¶‚àí1 and through V [E[pt+1 + dÀút |Iit ] ‚àí pt r|It‚àí1
] = V [pt+1 + dÀút ‚àí pt r|It‚àí1
] ‚àí ‚Ñ¶‚àí1
t . Since
+
+
Àú
Àú
there is a continuum of investors, and since V [pt+1 + dt ‚àí pt r|It‚àí1 ] and E[E[pt+1 + dt |Iit ] ‚àí pt r|It‚àí1 ] depend only on t ‚àí 1
variables, parameters and on aggregate information choices, each investor takes them as given. If the objective is to maximize
an increasing function of ‚Ñ¶, then information choices must maximize ‚Ñ¶ as well.

34

Internet Appendix: Not for Publication
B

Proofs

The next lemma proves the following: If no one has information about future dividends, then no one‚Äôs trade is based on
information about future dividends, thus the price cannot contain information about future dividends. Since Ct is the price
coefficient on future dividend information, Ct = 0 means that the price is uninformative. In short, price cannot reflect
information that no one knows.
Lemma 3 When information is scarce, price is uninformative: As Kt ‚Üí 0, for any future path of prices (At+j , Bt+j , Ct+j
and Dt+1 , ‚àÄj > 0), the unique solution for the price coefficient Ct is Ct = 0.
Proof: Step 1: As ‚Ñ¶f t ‚Üí 0, prove Ct is always a solution.
Start with the equation for Dt (11). Substitute in for ‚Ñ¶ using (32) and 1 + B = r/(r ‚àí G) and rewrite it as
Dt =



1
œÅr
Ct
VÃÇt œÑx
‚àí
‚àí Zt VÃÇt‚àí1
r‚àíG
Dt
(r ‚àí G)

(58)

Then, express Ct from (48) as Ct = 1/(r ‚àí G)VÃÇt (VÃÇt‚àí1 ‚àí œÑ0 ) and divide Ct by Dt , cancelling the VÃÇt /(r ‚àí G) term in each to get
Ct
VÃÇt‚àí1 ‚àí œÑ0
=
œÅr
C
t
Dt
‚àí Zt VÃÇt‚àí1
œÑx Dt ‚àí (r‚àíG)

(59)

If we substitute in VÃÇt‚àí1 = œÑ0 + ‚Ñ¶pt + ‚Ñ¶f t from (29) and then set ‚Ñ¶f t = 0, we get
Ct
=
Ct
Dt
œÑx D
‚àí
t

‚Ñ¶pt
‚àí Zt (œÑ0 + ‚Ñ¶pt )

(60)

œÅr
(r‚àíG)

Then, we use the solution for price information precision ‚Ñ¶pt = (C/D)2 (œÑx + ‚Ñ¶x ) and multiply both sides by the denominator
of the fraction to get
"
#  
 2
2
Ct
œÅr
Ct
Ct
Ct
œÑx
‚àí
‚àí Zt (œÑ0 +
(œÑx + ‚Ñ¶x )) =
(œÑx + ‚Ñ¶x )
Dt
Dt
(r ‚àí G)
Dt
Dt

(61)

We can see right away that since both sides are multiplied by C/D, as ‚Ñ¶f t ‚Üí 0, for any given future price coefficients Ct+1
and Dt+1 , C = 0 is always a solution.

Step 2: prove uniqueness.
Next, we investigate what other solutions are possible by dividing both sides by C/D:
œÑx

Ct
œÅr
‚àí
‚àí Zt (œÑ0 +
Dt
(r ‚àí G)



Ct
Dt

2


(œÑx + ‚Ñ¶x )) ‚àí

Ct
Dt


(œÑx + ‚Ñ¶x ) = 0

(62)

This is a quadratic equation in C/D. Using the quadratic formula, we find
‚Ñ¶xt ¬±
Ct
=
Dt

p
‚Ñ¶2xt ‚àí 4Zt (œÑx + ‚Ñ¶xt )(œÅr/(r ‚àí G) + œÑ0 Zt )
‚àí2Zt (œÑx + ‚Ñ¶xt )

(63)

If we now take the limit as ‚Ñ¶xt ‚Üí 0, the term inside the square root becomes negative, as long as r ‚àí G > 0. Thus, there
are no additional real roots when ‚Ñ¶xt = 0.
Similarly, if ‚Ñ¶x is not sufficiently large, there are no real roots of (63), which proves that: As ‚Ñ¶f t ‚Üí 0, if we take Ct+1
and Dt+1 as given, and ‚Ñ¶xt is sufficiently small, then the unique solution for the price coefficient C is C = 0. 
Proof of Result 1 From lemma 3, we know that as Ct = 0. From the first order condition for information (15), we see
that the marginal utility of order flow information relative to fundamental information (marginal rate of substitution) is a
positive constant times (Ct /Dt )2 . If Ct = 0, then ‚àÇUit /‚àÇ‚Ñ¶xit is a positive constant time zero, which is zero.

35

Proof of Result 3
Claim: If r ‚àí g > 0 and (œÑx + ‚Ñ¶xt ) is sufficiently small, then ‚àÇCt /‚àÇ‚Ñ¶f t > 0 and ‚àÇCt /‚àÇ‚Ñ¶xt > 0.
1
(1 ‚àí œÑ0 VÃÇt ).
From (48), Ct = r‚àíG
From (29), VÃÇt is defined as


VÃÇ = [œÑ0 + ‚Ñ¶f t +

Ct
Dt

2

(œÑx + ‚Ñ¶xt )]‚àí1

(64)

Notice that Ct shows up twice, once on the left side and once in VÃÇ . Therefore, we use the implicit function theorem to
1
1
differentiate. If we define F ‚â° Ct ‚àí r‚àíG
(1 ‚àí œÑ0 VÃÇ ), then ‚àÇF/‚àÇCt = 1 + r‚àíG
œÑ0 ‚àÇ VÃÇ /‚àÇCt . Since œÑx and ‚Ñ¶xt are both precisions,
‚àí1
2
both are positive. Therefore, ‚àÇ VÃÇ /‚àÇCt = 2Ct /Dt (œÑx + ‚Ñ¶xt ). This is positive, since we know that Ct > 0. That implies that
the derivative of the inverse is ‚àÇ VÃÇ /‚àÇCt = ‚àíVÃÇ 2 2Ct /Dt2 (œÑx + ‚Ñ¶xt ), which is negative. The ‚àÇF/‚àÇCt term is therefore one plus
2
a negative term. The result is positive, as long as the negative term is sufficiently small: r‚àíG
œÑ0 VÃÇ 2 Ct /Dt2 (œÑx + ‚Ñ¶xt ) < 1. We
can express this as an upper bound on œÑx + ‚Ñ¶xt by rearranging the inequality to read: (œÑx + ‚Ñ¶xt ) < 1/2(r ‚àí G)œÑ0‚àí2 VÃÇ ‚àí2 Dt2 /Ct .
Next, we see that ‚àÇ VÃÇ ‚àí1 /‚àÇ‚Ñ¶f t = 1. Thus, ‚àÇ VÃÇ /‚àÇ‚Ñ¶f t < 0. Since ‚àÇF/‚àÇ VÃÇ > 0, this guarantees that ‚àÇF/‚àÇ‚Ñ¶f t < 0.
Likewise, ‚àÇ VÃÇ ‚àí1 /‚àÇ‚Ñ¶xt = (Ct /Dt )2 . Since the square is always positive, ‚àÇ VÃÇ /‚àÇ‚Ñ¶xt < 0. Since ‚àÇF/‚àÇ VÃÇ > 0, this guarantees
that ‚àÇF/‚àÇ‚Ñ¶xt < 0.
Finally, the implicit function theorem states that ‚àÇCt /‚àÇ‚Ñ¶f t = ‚àí(‚àÇF/‚àÇ‚Ñ¶f t )/(‚àÇF/‚àÇCt ). Since the numerator is positive,
the denominator is negative and there is a minus sign in front, ‚àÇCt /‚àÇ‚Ñ¶f t > 0. Likewise, ‚àÇCt /‚àÇ‚Ñ¶xt = ‚àí(‚àÇF/‚àÇ‚Ñ¶xt )/(‚àÇF/‚àÇCt ).
Since the numerator is positive, the denominator is negative and there is a minus sign in front, ‚àÇCt /‚àÇ‚Ñ¶xt > 0. 
Proof of Result 4, part 1
Claim: If œÑx > œÅr/(r ‚àí G) and Dt < 0, then ‚àÇDt /‚àÇ‚Ñ¶f t > 0.
Proof:
From market clearing:

Dt = [r ‚àí (1 + B)VÃÇ + ‚Ñ¶p

C
1 ‚àí1
] [‚àíœÅ‚Ñ¶‚àí1
‚àí (1 + B) VÃÇ ‚Ñ¶x ]
t
C
D

C 2
C
Use ‚Ñ¶p = ( D
) (‚Ñ¶x + œÑx ) to get Dt r ‚àí (1 + B)VÃÇt D
(œÑx ) = ‚àíœÅ‚Ñ¶‚àí1
t . Then, use the stationary solution for B : 1 + B =

Dt ‚àí

C
œÅ
1
VÃÇt œÑx = ‚àí ‚Ñ¶‚àí1
r‚àíG D
r t

(65)
r
:
r‚àíG

(66)

Then use (32) to substitute in for ‚Ñ¶‚àí1
t :

Dt = ‚àí

1
1
rœÅ
Ct
Zt ‚àí
VÃÇ +
VÃÇt
œÑx
r‚àíG
(r ‚àí G)2
r ‚àí G Dt

(67)

In the above, the RHS, less the last term, is the loading on Xt+1 , and the last term represents price feedback. We then
‚àÇF
‚àÇF
define F ‚â° L.H.S. of (67) ‚àí R.H.S. of (67). So that we can apply the implicit function theorem as ‚àÇDt /‚àÇ‚Ñ¶f = ‚àí ‚àÇ‚Ñ¶
/ ‚àÇD
.
t
f
We begin by working out the denominator.
Ct
‚àÇF
rœÅ
‚àÇ VÃÇ
1 ‚àÇ VÃÇ + Dt
=1+0+
‚àí
œÑx
2
‚àÇDt
(r ‚àí G) ‚àÇDt
r ‚àí G ‚àÇDt

(68)

‚àÇ VÃÇ
‚àÇ VÃÇ ‚àÇ VÃÇ ‚àí1
2C 2
C2
=
= ‚àíVÃÇ 2 [‚àí 3t (œÑx + ‚Ñ¶x )] = 2 3 VÃÇt3 (œÑx + ‚Ñ¶x )
‚àÇDt
Dt
D
‚àÇ VÃÇ ‚àí1 ‚àÇDt

(69)

‚àÇ VÃÇ

Ct
Dt

‚àÇDt

=

Ct ‚àÇ VÃÇt
C
+ VÃÇ (‚àí 2 )
Dt ‚àÇDt
D

36

(70)

C
Ct
VÃÇ [2 (œÑx + ‚Ñ¶x ) ‚àí 1]
D2
Dt

=

(71)

‚àÇF
rœÅ
C2 3
œÑx C
Ct
=1+
¬∑
2
VÃÇt (œÑx + ‚Ñ¶x ) ‚àí
VÃÇt [2 (œÑx + ‚Ñ¶x ) ‚àí 1]
‚àÇDt
(r ‚àí G)2
D3
r ‚àí G D2
Dt

(72)

‚àÇF
rœÅ
‚àÇ VÃÇ
1 Ct ‚àÇ VÃÇ
=0‚àí0+
‚àí
œÑx
‚àÇ‚Ñ¶f
(r ‚àí G)2 ‚àÇ‚Ñ¶t
r ‚àí G Dt ‚àÇ‚Ñ¶t

(73)

Recall the definition VÃÇt ‚â° [œÑ0 + ‚Ñ¶f t +

Ct 2
(œÑx
Dt

+ ‚Ñ¶x )]‚àí1 . Differentiating VÃÇ , we get

‚àí1
‚àÇ VÃÇt
‚àÇ VÃÇt‚àí1
‚àÇ VÃÇ
2 ‚àÇ VÃÇt
=
¬∑
=
‚àí
VÃÇ
= ‚àíVÃÇt2
t
‚àÇ‚Ñ¶f
‚àÇ‚Ñ¶f
‚àÇ VÃÇt‚àí1 ‚àÇ‚Ñ¶f

(74)

‚àÇF
1
Ct
rœÅ
=
]
VÃÇt2 [ œÑx ‚àí
‚àÇ‚Ñ¶f
r‚àíG
Dt
r‚àíG

(75)

substituting this in to (73) yields

Substituting in the derivative of VÃÇ , we get

‚àÇDt
=‚àí
‚àÇ‚Ñ¶f
1

2rœÅ
C2
(r‚àíG)2 D 3

rœÅ
1
VÃÇ 2 [ Ct œÑ ‚àí r‚àíG
]
r‚àíG t Dt x
œÑx C
2
VÃÇt (œÑx + ‚Ñ¶x ) ‚àí r‚àíG D2 VÃÇt [2 CœÅ (œÑx

+ ‚Ñ¶x ) ‚àí 1]

(76)

Ct
< 0, and r > G, then the numerator is positive (including the leading negative sign).
Observe that if D
t
The denominator is positive if the following expression is positive:

r‚àíG
r Ct
2C
VÃÇt (œÑx + ‚Ñ¶x ) ‚àí œÑx VÃÇt [
(œÑx + ‚Ñ¶x ‚àí 1)] > 0
+ 2œÅ
C
r
‚àí
G
D
D
t
VÃÇ
D2

(77)

r ‚àí G D2
Ct
rœÅ
+ 2VÃÇt
(œÑx + ‚Ñ¶x )[
‚àí œÑx ] + œÑx VÃÇt > 0.
Dt
r‚àíG
VÃÇt C

(78)

This is equivalent to

rœÅ
Lemma 2 proves that D < 0. That makes the middle term potentially negative. However, if [ r‚àíG
‚àí œÑx ] < 0 as well, the
rœÅ
product of this and D is positive. Thus the middle term is positive. That inequality can be rearranged as œÑx > r‚àíG
. Since
the rest of the terms are squares and precisions, the rest of the expression is positive as well.
rœÅ
t
Thus if œÑx > r‚àíG
, then ‚àÇD
> 0. 
‚àÇ‚Ñ¶t

Proof of Result 4, part 2
If œÑx > œÅr/(r ‚àí g) and Dt < 0, then ‚àÇDt /‚àÇ‚Ñ¶xt > 0.
‚àÇF
‚àÇF
. The previous proof already proved that if
Proof: Begin with the implicit function theorem: ‚àÇDt /‚àÇ‚Ñ¶x = ‚àí ‚àÇ‚Ñ¶
/ ‚àÇD
x
t
rœÅ
œÑx > r‚àíG , the denominator is positive. All that remains is to sign the numerator.

‚àÇF
rœÅ
‚àÇ VÃÇ
1 Ct
‚àÇ VÃÇ
=0+0+
‚àí
œÑx
‚àÇ‚Ñ¶x
(r ‚àí G)2 ‚àÇ‚Ñ¶x
r ‚àí G Dt ‚àÇ‚Ñ¶x

37

where ‚àÇ VÃÇ /‚àÇ‚Ñ¶x = ‚àíVÃÇ 2 (C 2 )/(D2 ). Substituting the partial of VÃÇ into the partial of F yields
C2
‚àÇF
rœÅ
1 Ct
= VÃÇ 2 2 (‚àí
œÑx ).
+
‚àÇ‚Ñ¶x
D
(r ‚àí G)2
r ‚àí G Dt
Combining terms,
VÃÇ
‚àÇDt
=‚àí
‚àÇ‚Ñ¶x

rœÅ
2 C2
1 Ct
(‚àí (r‚àíG)
2 + r‚àíG D œÑx )
D2
t
‚àÇF
‚àÇDt
2

Ct
C
< 0. Since r > G, by assumption, ‚àÇF/‚àÇ‚Ñ¶x is negative (i.e., the D
We know from lemmas 1 and 2 that D
2 factor does
t
not change the sign). Applying the implicit function theorem tells us that ‚àÇDt /‚àÇ‚Ñ¶xt > 0. 
Proof of Result 2
The strategy for proving this result is to apply the implicit function theorem to the price coefficients that come from
coefficient matching in the market-clearing equation. After equating supply and demand and matching all the coefficients on
xÃÉt , we arrive at (11). Rearranging that equation gives us the expression for Ct /Dt in (59). If we subtract the right side of
(59) from the left, we are left with an expression that is equal to zero in equilibrium, which we‚Äôll name F :

VÃÇt‚àí1 ‚àí œÑ0
Ct
‚àí
œÅr
C
t
Dt
‚àí Zt VÃÇt‚àí1
œÑx Dt ‚àí (r‚àíG)

‚àí1
‚àÇF
‚àÇF
and ‚àÇC/D
= ‚àí ‚àÇC/D
. In particular, we have:
‚àÇ‚Ñ¶f
‚àÇ‚Ñ¶f
F =

We compute

‚àÇC/D
‚àÇ‚Ñ¶x

‚àÇF
‚àÇC/D

=

=

‚àÇF
‚àÇ‚Ñ¶f

=‚àí

‚àÇF
‚àÇC/D

‚àí1

‚àÇF
‚àÇ‚Ñ¶x



‚àí1
Ct
Ct
œÅr
1 ‚àí 2 (œÑx + ‚Ñ¶x )
œÑx
‚àí
‚àí Zt VÃÇ ‚àí1
Dt
Dt
r‚àíG


‚àí2 

C
Ct
œÅr
t
+(VÃÇ ‚àí1 ‚àí œÑ0 ) œÑx
‚àí
‚àí Zt VÃÇ ‚àí1
œÑx ‚àí Zt 2 (œÑx + ‚Ñ¶x )
Dt
r‚àíG
Dt

‚àí2
Ct
œÅr
1 ‚àí œÑx
‚àí
‚àí Zt VÃÇ ‚àí1
Dt
r‚àíG






Ct
Ct
Ct
œÅr
‚àí Zt VÃÇ ‚àí1 ‚àí (VÃÇ ‚àí1 ‚àí œÑ0 ) œÑx ‚àí Zt 2 (œÑx + ‚Ñ¶x )
2 (œÑx + ‚Ñ¶x )
œÑx
‚àí
Dt
Dt
r‚àíG
Dt

=
=

We notice that



‚àÇF
‚àÇ‚Ñ¶x

‚àí1

‚àí2

Ct
Ct
œÅr
œÅr
‚àí
‚àí Zt VÃÇ ‚àí1
+ (VÃÇ ‚àí1 ‚àí œÑ0 ) œÑx
‚àí
‚àí Zt VÃÇ ‚àí1
(‚àíZt )
‚àí(1) œÑx
Dt
r‚àíG
Dt
r‚àíG

‚àí2 


Ct
œÅr
œÅr
Ct
‚àí œÑx
‚àí
‚àí Zt VÃÇ ‚àí1
‚àí
‚àí Zt VÃÇ ‚àí1 + Zt (VÃÇ ‚àí1 ‚àí œÑ0 )
œÑx
Dt
r‚àíG
Dt
r‚àíG
=



Ct
Dt

2

‚àÇF
‚àÇ‚Ñ¶f

since

‚àÇF
‚àÇF ‚àÇ VÃÇ ‚àí1
‚àÇF
=
=
‚àÇ‚Ñ¶x
‚àÇ VÃÇ ‚àí1 ‚àÇ‚Ñ¶x
‚àÇ VÃÇ ‚àí1



Ct
Dt

2

‚àÇ VÃÇ ‚àí1
=
‚àÇ‚Ñ¶f



Ct
Dt

2

‚àÇF
‚àÇ‚Ñ¶f

.
Then:


‚àÇC/D
= 
‚àÇ‚Ñ¶f

Ct
œÑx D
‚àí
t

œÅr
r‚àíG


œÅr
Ct
œÑx D
‚àí r‚àíG
‚àí Zt VÃÇ ‚àí1 + Zt (VÃÇ ‚àí1 ‚àí œÑ0 )
t
2 h




i
œÅr
Ct
Ct
Ct
‚àí Zt VÃÇ ‚àí1 ‚àí 2 D
(œÑx + ‚Ñ¶x ) œÑx D
‚àí r‚àíG
‚àí Zt VÃÇ ‚àí1 ‚àí (VÃÇ ‚àí1 ‚àí œÑ0 ) œÑx ‚àí Zt 2 D
(œÑx + ‚Ñ¶x )
t
t
t
(79)

Result 2, part 1: If C/D ‚â§ 0, ‚Ñ¶x < œÑ0 + ‚Ñ¶f and C/D > ‚àíZt /2 , then ‚àÇC/D
< 0 and ‚àÇC/D
‚â§0
‚àÇ‚Ñ¶f
‚àÇ‚Ñ¶x
The numerator of (79) is


Ct
œÅr
Ct
œÅr
œÑx
‚àí
‚àí Zt VÃÇ ‚àí1 + Zt (VÃÇ ‚àí1 ‚àí œÑ0 ) = œÑx
‚àí
‚àí Zt œÑ0 < 0
Dt
r‚àíG
Dt
r‚àíG

38

The inequality holds since we‚Äôve proven that Ct /Dt < 0 and r > G.

Ct
‚àí
In the denominator, however, not all the terms are negative. The denominator of (79), divided by by œÑx D
t

œÅr
r‚àíG


‚àí Zt VÃÇ ‚àí1 +

Zt (VÃÇ ‚àí1 ‚àí œÑ0 ) is:




 
‚àí1
Ct
Ct
Ct
œÅr
‚àí 2 (œÑx + ‚Ñ¶x ) + (VÃÇ ‚àí1 ‚àí œÑ0 ) œÑx ‚àí Zt 2 (œÑx + ‚Ñ¶x )
œÑx
‚àí
‚àí Zt VÃÇ ‚àí1
Dt
Dt
Dt
r‚àíG
(80)
œÅr
Ct
Ct
The only positive term is ‚àí2 D
‚Ñ¶
.
Then,
is
it
easy
to
see
that
if
C/D
is
sufficiently
close
to
zero,
then
‚àí2
‚Ñ¶
<
+
x
Dt x
r‚àíG
t
Zt (œÑ0 + ‚Ñ¶f ), so (80) is negative.
Thus, the numerator is negative and if C/D is sufficiently close to zero the denominator is positive, so ‚àÇC/D
< 0 and
‚àÇ‚Ñ¶f
 2
‚àÇC/D
‚àÇC/D
Ct
= D
< 0 if C/D < 0 and ‚àÇC/D
= 0 if C/D = 0. 
‚àÇ‚Ñ¶x
‚àÇ‚Ñ¶f
‚àÇ‚Ñ¶x
t


œÑx

œÅr
Ct
‚àí
‚àí Zt VÃÇ ‚àí1
Dt
r‚àíG



2Z ‚àí1

Proof of Result 2, part 2 Claim: If C/D ‚â§ 0, and C/D < ‚àí 3t , then ‚àÇC/D
< 0 and
‚àÇ‚Ñ¶f
To see this, we analyze if under these new condition inequality (80) holds. We have:

‚àÇC/D
‚àÇ‚Ñ¶x

‚â§0

 2
Ct
œÅr
Ct
(œÑx + ‚Ñ¶x )
‚àí Zt (œÑ0 + ‚Ñ¶f ) ‚àí 2 ‚Ñ¶x ‚àí 3Zt
r‚àíG
Dt
Dt


 2
œÅr
Ct
Ct
Ct
‚àí
‚àí Zt (‚Ñ¶x ) ‚àí
‚Ñ¶x 2 ‚àí 3Zt
‚àí 3Zt
œÑx
r‚àíG
Dt
Dt
Dt

‚àí
=
So if C/D < ‚àí

2Zt‚àí1
,
3

we can prove the above claim:
=
<
<


 2

Ct
Ct
Ct
œÅr
‚àí Zt (‚Ñ¶x ) ‚àí
‚Ñ¶x 2 ‚àí 3Zt
‚àí 3Zt
œÑx
r‚àíG
Dt
Dt
Dt
 2
Ct
œÅr
‚àí
‚àí Zt (‚Ñ¶x ) ‚àí 3Zt
œÑx
r‚àíG
Dt
0
‚àí

Now, combining the two previous claims, we have that if ‚Ñ¶x < œÑ0 + ‚Ñ¶f and Zt >
t
condition Zt > ‚àö13 implies that ‚àíZ
<‚àí
2
of C/D and thus proved result 2.

2Zt‚àí1
3

1
‚àö
,
3

then

‚àÇC/D
‚àÇ‚Ñ¶f

< 0 and

‚àÇC/D
‚àÇ‚Ñ¶x

‚â§ 0. The

so with claims 3, 4 and 5 we have guaranteed the result for the entire support

Proof of Result 6a: ‚Ñ¶f t /‚Ñ¶xt does not converge to 0
If ‚Ñ¶f t /‚Ñ¶xt converges to ‚àû, then by the first order condition, it must be that Œæ ‚Üí ‚àû. It is sufficient to show that Œæ ‚Üí ‚àû
violates equation (57). Rearrange (57) to get
"

#

K 12
œáf 4 12
K 1
œáf 4 21
Œæ ) + œÑ0 + ŒæŒ± + ( ) 2 (1 +
Œæ ) =0
ŒæZt Œæ œÑx + ( ) (1 +
œáf
œáx
œáf
œáx


2

(81)

The term in square brackets is negative and the one outside is positive. Assume Œæ ‚Üí ‚àû. If Zt does not go to zero, then the
negative term grows faster and the equality cannot hold. So it must be that Zt ‚Üí 0. Using equation (31) of the draft, that
requires that both Ct+1 ‚Üí 0 and Dt+1 ‚Üí 0. In order for Ct+1 to go to zero, VÃÇ ‚Üí œÑ0‚àí1 . But since Œæ ‚Üí ‚àû, from equation (29)
in the main draft, VÃÇ ‚Üí 0, which is a contradiction.
Proof of Result 6b: As K ‚Üí ‚àû, ‚Ñ¶f t /‚Ñ¶xt does not converge to ‚àû
If ‚Ñ¶f t /‚Ñ¶xt did converge to ‚àû as K ‚Üí ‚àû, then by the first-order condition (15), it would have to be that Œæ ‚Üí 0. So it
suffices to show that ‚Ñ¶f t /‚Ñ¶xt = ‚àû is inconsistent with Œæ = 0, in equilibrium.
Start from the equilibrium condition (56), which must be zero in equilibrium. If Œæ ‚Üí 0, then the first term goes to zero.
The proof of lemma 4 proves, along the way, that (1 + ŒæZt ) > 0. (Otherwise, (56) can never be zero because it is always
negative.) Thus the second term ‚Ñ¶xt Œæ 2 (1 + ŒæZt ) must be non-negative.
The third term ‚Ñ¶f t (1 + ŒæZt ) also converges to ‚àû because ‚Ñ¶f t ‚Üí ‚àû and (1 + ŒæZt ) > 0. How do we know that ‚Ñ¶f t ‚Üí ‚àû?
In principle, ‚Ñ¶f t /‚Ñ¶xt could become infinite either because ‚Ñ¶f t became infinite or because ‚Ñ¶xt goes to zero. But if ‚Ñ¶xt goes to

39

zero and ‚Ñ¶f t is finite, then the information processing constraint (3), which requires that the weighted sum of ‚Ñ¶f t and ‚Ñ¶xt
be K cannot be satisfied as K ‚Üí ‚àû.
Since one term of (56) becomes large and positive and the other two are non-negative in the limit, the sum of these three
terms cannot equal zero. Therefore, ‚Ñ¶f t /‚Ñ¶xt ‚Üí ‚àû cannot be an equilibrium.
Proof of Result 6c: there exists an equilibrium where ‚Ñ¶f t /‚Ñ¶xt converges to a constant.
By the first order condition (15), we know that ‚Ñ¶f t /‚Ñ¶xt converges to a constant, if and only if Œæ converges to a constant.
Thus, it suffices to show that there exists a constant Œæ that is consistent with equilibrium, in the high-K limit.
Suppose Œæ and Zt are constant in the high-K limit. In equation (57) as K ‚Üí ‚àû, the last term goes to infinity, unless
Œæ ‚Üí Z1t . If the last term goes to infinity and the others remain finite, this cannot be an equilibrium because equilibrium
. The question that remains is whether Œæ and Zt
requires that the left side of (57) is zero. Therefore, it must be that Œæ ‚Üí ‚àí1
Zt
are finite constants, or whether one explodes and the other converges to zero, in the high-K limit.
¬Ø Then Zt = ZÃÑ is constant too. The rest of the proof checks to see if such a
Suppose Œæ = ‚àí Z1t , which is constant (Œæ = Œæ).
¬Ø
proposed constant- Œæ solution is consistent with equilibrium. We do this by showing that Œæ does not explode on contract as
K increases. In other words, for Œæ = ‚àí1
to be stable and thus the ratio of fundamental to technical analysis to be stable, we
Zt
need that ‚àÇŒæ/‚àÇK ‚Üí 0, in other words, Œæ and therefore ‚Ñ¶f t /‚Ñ¶xt converges to a constant as K ‚Üí ‚àû.
Step 1: Derive dŒæ/dK: Start from the equilibrium condition for Œæ (57) and apply the implicit function theorem:

œáf 4 12
1 1 12
) (1 + ŒæZt )(1 +
Œæ ) dK
3Zt œÑx Œæ 2 + A + Zt œÑ0 dŒæ + (
2 Kœáf
œáx
#
"
œáf 4 ‚àí 12 œáf 3
œáf 4 12
1 K 12
K 12
+
( ) (1 + ŒæZt )(1 +
Œæ ) (4 Œæ ) + Zt ( ) (1 +
Œæ ) dŒæ = 0
2 œáf
œáx
œáx
œáf
œáx



So we have
œá

1

‚àí(1 + ŒæZt )(1 + œáfx Œæ 4 ) 2
dŒæ
1 1 12
= (
)
dK
2 Kœáf 3Zt œÑx Œæ 2 + A + Zt œÑ0 + 2 œáf ( K ) 12 (1 + ŒæZt )(1 + œáf Œæ 4 )‚àí 21 Œæ 3 + Zt ( K ) 21 (1 +
œáx œáf
œáx
œáf

œáf 4 1
Œæ )2
œáx

Use equation 57 to write the numerator as

(1 + ŒæZt )(1 +
Now use this to rewrite

dŒæ
dK

œáf 1
œáf 4 12
Œæ ) = ‚àí( ) 2 Œæ(Œæ 2 Zt œÑx + A + Zt œÑ0 )
œáx
K

(82)

as
dŒæ
1
=
dK
2K

1
3Zt œÑx Œæ2 +A+Zt œÑ0
Œæ(Œæ2 Zt œÑx +A+Zt œÑ0 )

‚àí

œá
2 œáfx (1

+

œáf 4 ‚àí1 3
Œæ ) Œæ
œáx

‚àí

Zt
(1+ŒæZt )

(83)

Step 2: Show that dŒæ/dK ‚Üí 0 as K ‚Üí ‚àû, as long as X(¬∑) 6 ‚Üí0
As K ‚Üí ‚àû, it is clear that 1/2K ‚Üí 0. As long as the term that multiplies 1/2K stays finite, the product will converge
to zero. Since the numerator is just 1, the second term will be finite, as long as the denominator does not go to zero. Define

X(Œæ, Zt ) =

3Zt œÑx Œæ 2 + A + Zt œÑ0
œáf
œáf 4 ‚àí1 3
Zt
‚àí 2 (1 +
Œæ ) Œæ ‚àí
Œæ(Œæ 2 Zt œÑx + A + Zt œÑ0 )
œáx
œáx
(1 + ŒæZt )

(84)

which is the denominator of the second fraction on the rhs of equation (83). Then if X 6‚Üí 0, 1/X is finite, then 1/2K ‚àó 1/X
goes to zero as K gets large. Thus, we get that ‚àÇŒæ/‚àÇK ‚Üí 0 as K ‚Üí ‚àû.
Step 3: X(¬∑) 6‚Üí 0.
To complete the proof, we need to show that Œæ¬Ø = ‚àí ZÃÑ1 which satisfies the equilirium condition (89) as K ‚Üí ‚àû, does not cause
X(¬∑) = 0. We can check this directly: in equation (84), if Œæ = ‚àí Z1t , the denominator of the last term becomes zero; so last
C
term becomes infinite. The only term in (84) with opposite sign is the middle term, which is finite if Œæ = D
is finite (the
running assumption). If the last term of X tends to infinity and the only term of opposite sign is finite, the sum cannot be 0.
¬Ø 6= 0.
Thus, for Œæ¬Ø = ‚àí ZÃÑ1 , which is the limit attained in the limit as K ‚Üí ‚àû, we have that X(Œæ)

40

Step 4: As K ‚Üí ‚àû, if (90) holds, the real, finite-Œæ solution exists.
From equations (29-32), as K ‚Üí ‚àû at least one of the two information choices goes to ‚àû, so with finite, non-zero

lim VÃÇ = 0

C
:
D

(85)

K‚Üí‚àû

r
2
2
Zt = Dt+1
(Œæt+1
œÑ0‚àí1 + œÑx‚àí1 )
œÅ(r ‚àí G)
œÅ
1
lim Dt = ‚àí ‚Ñ¶‚àí1
=‚àí
Zt
K‚Üí‚àû
r t
(r ‚àí G)
=
lim ‚Ñ¶‚àí1
t

(86)

K‚Üí‚àû

(87)

A word of interpretation here: Equation (32), which defines ‚Ñ¶‚àí1 is the total future payoff risk. As VÃÇ ‚Üí 0, it means the
predictable part of this variance goes away as information capacity gets large. Zt , which is the unpredictable part, remains
and governs liquidity, Dt .
Next, solve (86) for Dt+1 , backdate the solution 1 period, to get an expression for Dt , and equate it to the expression for
Dt in (87). This implies that limK‚Üí‚àû D = DÃÑ is constant and equal to both of the following expressions

DÃÑ2 =

‚àírZt
Zt
=
¬Ø Œæ¬Ø2 œÑ ‚àí1 + œÑx‚àí1 )
(r
‚àí
G)2 Œæ¬Ø2
œÅ(r ‚àí G)Œæ(
0

(88)

¬Ø
We can cancel Zt on both sides, which delivers a quadratic equation in one unknown in Œæ:
r(r ‚àí G) ¬Ø
Œæ¬Ø2 œÑ0‚àí1 +
Œæ + œÑx‚àí1 = 0.
œÅ

(89)

In order for Œæ¬Ø to exist equation (89) requires that the expression inside the square root term of the quadratic formula (often
written as (b2 ‚àí 4ac)) not be negative. This imposes the parametric restriction


r(r ‚àí G)
œÅ

2

‚àí 4œÑ0‚àí1 œÑx‚àí1 ‚â• 0.

(90)

Rearranging this to put œÑ0 on the left delivers œÑ0 ‚â• œÑ , where œÑ = 4œÑx‚àí1 œÅ2 (r(r ‚àí G))‚àí2 . If we instead rearrange this to put œÑx
on the left delivers œÑx ‚â• œÑ , where œÑ = 4œÑ0‚àí1 œÅ2 (r(r ‚àí G))‚àí2 .

Lemma 4 Balanced growth path depends on future information risk and long-lived assets. |Dt | ‚â•
with strict inequality if K > 0.

œÅ(r‚àíG)
Ct
r


2
2
Ct+1
œÑ0‚àí1 + Dt+1
œÑx‚àí1 ,

Proof. Use equation (57) to write

(1 + ŒæZt )(1 +

œáf 4 12
œáf 1
Œæ ) = ‚àí( ) 2 Œæ(Œæ 2 Zt œÑx + Œ± + Zt œÑ0 )
œáx
K

(91)

Since we‚Äôve proven that Œæ ‚â§ 0 (lemma 2). And we know from lemma 1 that if K > 0, then Ct > 0 so that Œæ < 0 with strict
inequality. The other terms on the right side are strictly positive squares or positive constants, with a negative sign in front.
1
œá
Thus, the right hand side of the equation (82) is positive. On the left, since (1 + œáfx Œæ 4 ) 2 is a square root, and therefore
positive, this implies that (1 + ŒæZt ) must be positive as well for the equality to hold. (1 + ŒæZt ) > 0 implies that Zt < ‚àí1/Œæ
Substitute for Zt to get the result. This result puts a bound on how liquid the price can be. The liquidity is bounded by the
product of price informativeness and un-learnable, future risk.
2
2
To get from this result to balanced growth requires the following steps: The result says that Ct /|Dt | < œÅ ((r ‚àí G)/r) (Ct+1
œÑ0‚àí1 + Dt+1
œÑx‚àí1
‚àí1
2
2
‚àí1
The first term is just fixed parameters. The second term, (Ct+1 œÑ0 + Dt+1 œÑx ) is the variance of the part of tomorrow‚Äôs price
that depends on future shocks, xt+1 and yt+1 . This is the future information risk. It converges to a large, positive number as
K grows. When information is abundant, high future information risk pushes Ct /|Dt | down, toward a constant.
In contrast, if order flow analysis were to keep growing faster than fundamental analysis (‚Ñ¶f t /‚Ñ¶xt were to fall to zero), by
the first order condition (15), it means that (Ct /Dt )2 keeps rising to infinity. But if (Ct /Dt )2 is converging to infinity, then at
some point, it must violate the inequality above because the right side of the inequality is decreasing over time. Thus, order
flow analysis cannot grow faster than fundamental analysis forever.

41

The only solution that reconciles the first order condition, with the equilibrium price coefficients, is one where (‚Ñ¶f t /‚Ñ¶xt )
stabilizes and converges to a constant. If fundamental analysis grows proportionately with order flow analysis, the rise in
the amount of fundamental analysis makes prices more informative about dividends: Ct increases. Proportional growth in
fundamental and order flow analysis allows Ct to keep up with the rise in Dt , described above. Therefore, as information
technology grows (K ‚Üí ‚àû), a stable Ct /Dt rationalizes information choices (‚Ñ¶xt , ‚Ñ¶f t ) that grow proportionately, so that
‚Ñ¶xt /‚Ñ¶f t converges to a constant.

C

Robustness of Numerical Results

We want to investigate the effect of changing parameters on the predictions of the numerical model. First, we show how
re-calibrating the model with different risk aversion affects the values of other calibrated parameters. Then we show how
changes in risk aversion and other parameters have modest effects on results. We consider changes to the exogenous, yet
important parameters of time preference, risk aversion and terminal capacity, first. Then, we consider altering endogenous,
calibrated parameters of dividend innovation variance, hedging innovation variance and relative cost of order-flow information.

Lower risk aversion The steady state coefficients with low risk aversion œÅ = 0.05 are We find AT = 16.03, CT = 7.865
and DT = ‚àí3.0. AT and CT are unchanged, while DT changed from = ‚àí5.7, for high risk aversion to 3.0. Table 2 shows
the original calibration and a lower-risk aversion calibration to highlight how the other parameters adjust when risk aversion
changes.

Table 2: Parameters

G
¬µ
œÑ0‚àí1
œÑx‚àí1
œáx
r
œÅ

low risk av
0.9365
0.235
0.2575
1.9850
10.6625
1.03
0.05

high risk av
0.9365
0.4153
0.2445
0.5514
0.6863
1.03
0.1

Similarly, after re-calibrating, risk aversion makes only a minor difference. With œÅ = 0.05, order flow analysis still outstrips
fundamental analysis between periods 4 and 5. But if falls slightly more slowly. The ending value of ‚Ñ¶f t is 1.8, instead of 1.6.

Changes to fixed parameters We consider lower/higher time preference, risk aversion and terminal capacity. Whenever a parameter is changed, all other parameters are re-calibrated to match that new value and the numerical model is
simulated again.

42

Figure 10: Results with different rates of time preference. The first row is information acquisition, the second row
is capacity allocation and the third row are the price coefficients. Column 1 is the baseline calibration used in the paper,
corresponding to r = 1.03. Column 2 displays the path with r = 1.01 and column 3 with r = 1.05.
10

10

10

9

9

9

8

8

8

7

7

7

6

6

6

5

5

5

4

4

4

3

3

3

2

2

2

1

1

0

1

0
0

50

100

150

200

250

300

350

400

450

500

Total Information Kt
Fundamental Analysis +f t
Order-.ow Analysis +xt

0
0

50

100

150

200

time

250

300

350

400

450

500

0

50

100

150

200

time

8

9

8

7

8

7

7

6

250

300

350

400

450

500

400

450

500

time

Price Info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

6

6
5

5
5

4

4
4

3

3
3

2

2

2

1

1

1

0

0
0

50

100

150

200

250

300

350

400

450

500

0
0

50

100

150

200

250

300

350

400

450

500

0

50

100

150

200

250

300

time

time

time

(a) Baseline r = 1.03

(b) r = 1.01

(c) r = 1.05

350

Figure 11: Results with different risk premia. The first row is capacity allocation and the second row is the price coefficients.
Column 1 is the baseline calibration used in the paper, corresponding to œÅ = 0.1. Column 2 displays the path with œÅ = 0.05
and column 3 with œÅ = 0.2.
10

10

10

9

9

9

8

8

8

7

7

7

6

6

6

5

5

5

4

4

4

3

3

3

2

2

2

1

1

0

1

0
0

50

100

150

200

250

300

350

400

450

500

Total Information Kt
Fundamental Analysis +f t
Order-.ow Analysis +xt

0
0

50

100

150

200

time

250

300

350

400

450

500

0

50

100

150

200

time

8

8

7

7

6

6

5

5

4

4

3

3

2

2

1

1

250

300

350

400

450

500

400

450

500

time

12

10

8

Price Info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

6

4

2

0

0
0

50

100

150

200

250

300

350

400

450

500

0
0

50

100

150

200

250

300

350

400

450

500

0

50

100

150

200

250

300

time

time

time

(a) Baseline œÅ = 0.1

(b) œÅ = 0.05

(c) œÅ = 0.2

43

350

Figure 12: Results with different terminal capacities. The first row is capacity allocation and the second row is the price
coefficients. Column 1 is the baseline calibration used in the paper, corresponding to KT = 10. Column 2 displays the path
with KT = 5 and column 3 with KT = 15.
10

5

9

4.5

8

4

7

3.5

6

3

5

2.5

4

2

3

1.5

2

1

15

Total Information Kt
Fundamental Analysis +f t
Order-.ow Analysis +xt
10

5

0.5

1

0

0
0

50

100

150

200

250

300

350

400

450

0
0

500

50

100

150

200

250

300

350

400

450

500

0

8

8

7

7

7

6

6

6

5

5

5

4

4

4

3

3

3

2

2

2

1

1

0
100

150

200

250

150

200

300

350

400

450

500

250

300

350

400

450

500

Price Info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

1

0
50

100

time

8

0

50

time

time

0
0

50

100

150

200

250

300

350

400

450

500

0

50

100

150

200

250

300

350

time

time

time

(a) Baseline KT = 10

(b) KT = 5

(c) KT = 15

400

450

500

Changes to calibrated parameters We consider lower/higher dividend shock variance, hedging shock variance
and relative cost of order-flow information. As these parameters are determined jointly by the calibration, we cannot simply
change them and re-calibrate as above. Rather, we calibrate to the baseline then change the parameter of interest for the
experiment and then recover the model‚Äôs terminal values associated with that new parameter of interest. It is important to
note that we do not re-calibrate the other parameters when we make changes here.

Figure 13: Results with different terminal values of œÑ0 . The first row is capacity allocation and the second row is the price
coefficients. Column 1 is the baseline calibration used in the paper. Column 2 displays the path for a lower œÑ0 and column 3
for a higher œÑ0 .
10

10

10

9

9

9

8

8

8

7

7

7

6

6

6

5

5

5

4

4

4

3

3

3

2

2

2

1

1

0

1

0
0

50

100

150

200

250

300

350

400

450

500

Total Information Kt
Fundamental Analysis +f t
Order-.ow Analysis +xt

0
0

50

100

150

200

time

250

300

350

400

450

500

0

50

100

150

200

time

250

300

350

400

450

500

400

450

500

time

8

8

9

7

7

8

6

6

5

5

4

4

3

3

2

2

1

1

Price Info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

7
6
5
4
3

0

2
1

0
0

50

100

150

200

250

300

350

time

(a) Baseline œÑ0

400

450

500

0
0

50

100

150

200

250

300

350

time

(b) œÑ0‚àó = 0.8œÑ0

44

400

450

500

0

50

100

150

200

250

300

350

time

(c) œÑx‚àó = 1.2œÑ0

Figure 14: Results with different terminal values of œÑx . The first row is capacity allocation and the second row is the price
coefficients. Column 1 is the baseline calibration used in the paper. Column 2 displays the path for a lower œÑx and column 3
for a higher œÑx .
10

10

10

9

9

9

8

8

8

7

7

7

6

6

6

5

5

5

4

4

4

3

3

3

2

2

2

1

1

0

1

0
0

50

100

150

200

250

300

350

400

450

500

Total Information Kt
Fundamental Analysis +f t
Order-.ow Analysis +xt

0
0

50

100

150

200

time

250

300

350

400

450

500

0

50

100

150

200

time

8

8

9

7

7

8

6

6

5

5

4

4

3

3

2

2

1

1

250

300

350

400

450

500

400

450

500

time

Price Info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

7
6
5
4
3

0

2
1
0

0
0

50

100

150

200

250

300

350

400

450

500

0

50

100

150

200

250

300

350

400

450

0

500

50

100

150

200

250

300

350

time

time

time

(a) Baseline œÑx

(b) œÑx‚àó = 0.8œÑx

(c) œá‚àóx = 1.2œÑx

Figure 15: Unbalanced growth model under different terminal values of œáx . The first row is capacity allocation and the
second row is the price coefficients. Column 1 is the baseline calibration used in the paper. Column 2 displays the path for a
lower œáx and column 3 for a higher œáx .
10

10

10

9

9

9

8

8

8

7

7

7

6

6

6

5

5

5

4

4

4

3

3

3

2

2

2

1

1

0

1

0
0

50

100

150

200

250

300

350

400

450

500

Total Information Kt
Fundamental Analysis +f t
Order-.ow Analysis +xt

0
0

50

100

150

200

time

250

300

350

400

450

500

0

50

100

150

200

time

8

9

7

8

250

300

350

400

450

500

time

7

6

7

6

5
6

5
5

4

4

3

4

Price Info Ct
Illiquidity jDt j
Ct 2
)
Marg. Value of Order-.ow ( D
t

3
3
2

2

2

1

1

0

0
0

50

100

150

200

250

300

350

400

450

500

1

0
0

50

100

150

200

250

300

350

400

450

500

0

50

100

150

200

250

300

350

time

time

time

(a) Baseline œáx

(b) œá‚àóx = 0.5œáx

(c) œá‚àóx = 2œáx

45

400

450

500

Liquidity Fragility
The main text shows that liquidity becomes more sensitive to one-period changes in future expected dividend variance. A
similar degree of liquidity fragility arises from changes in the cost œáx of order flow data processing. Figure 16 shows the
reaction of liquidity |Dt | to a one-time, unexpected doubling of œáx . Notice that an equal sized movement in œáx has a small
effect when technology is low and a larger effect as financial technology progresses.

Figure 16: Fragility of Liquidity: Cost of Order Flow Processing
7

Illquidity jDt j
6.5

6

5.5

5

4.5
0

50

100

150

200

250

300

350

400

450

500

time

D

Data Appendix

Asset price and return data for calibration Calibrating the numerical model requires some price and dividend
series that accurately represents the market as a whole. However, it is not clear what the best method for defining this
representative asset it. One option is to pick some historically representative stock, such as General Electric, or Apple, but
even though these stocks may be the best available representative, that does not mean that they capture the market as a
whole. Another option is to take an index, such as the S&P500, as a representative of the market. While using an index
may capture more about the market, its realizations in levels are not representative of actual prices or dividends, but rather
just a tracking mechanism of the evolution of the market. Aware of the deficiencies in both approaches, we choose the added
information of the S&P500 index and live with the difficulty of normalizing prices and dividends to better fit a representative
asset.
We use CRSP‚Äôs monthly S&P500 data from 2000-2015 to calibrate the steady-state of our model. Cleaning and normalizing
the data takes several steps:
1. Impute dividends In order to impute a dividend series for the market as a whole, we use the price, return including
dividends and return excluding dividends series.
d t = pt

p

t+1

+ dt

pt

‚àí

pt+1 
pt

2. Clean up data We log de-trend and deseasonalize the price and dividend series and then normalize the dividend series
to 1.
3. Normalize dataIn order to match the price series to dividends in a meaningful way, we take price-dividend (PD) ratios
from CRSP for all S&P500 members and calculate an annual market cap.-weighted PD ratio. Then, prices are normalized
year-by-year to match that observed PD ratio.
It turns out that this normalization process loses little of the dynamics of the index series, while also being far more
accurate in terms of the describing the level relationship between prices and dividends for a representative asset of the market.
Figure 18(a) displays the normalized price series with the actual price-index series. Figure 18(b) displays the normalized
dividend series with the imputed dividend series described above.

46

Figure 17: Comparison of normalized series with actual series. Source: CRSP

1.2

3.5

1600

1.1

3

1400

25

15

10
2001

2003

2005

2007

2009

2011

2013

2.5

0.9

2

1000

0.8

1.5

800

0.7

1

600

0.6

1200

20

1

4

0.5
2001

2015

Actual

1.3

1800

Normalized

30

4.5
Normalized S&P div series
Actual S&P div series

2000

Actual

Normalized S&P price series
Actual S&P price series

35

Normalized

1.4

2200

40

(a) Price comparison

2003

2005

2007

2009

2011

2013

2015

(b) Dividend comparison

Hedge Fund Data: Lipper TASS Database The figure showing the shift over time in investment strategies
is based on hedge fund data from Lipper. Lipper TASS provides performance data on over 7,500 actively reporting hedge
funds and funds of Hedge Funds and also provides historical performance data on over 11,000 graveyard funds that have
liquidated or stopped reporting. In addition to performance data, data are also available on certain fund characteristics, such
as investment approach, management fees, redemption periods, minimum investment amounts and geographical focus. This
database is accessible from Wharton Research Data Services (WRDS).
Though the database provides a comprehensive window into the hedge fund industry, data reporting standards are low.
There is a large portion of the industry (representing about 42% of assets) that simply do not report anything (Edelman,
Fund, and Hsieh, 2013). Reporting funds regularly report only performing assets (Bali, Brown, and Caglayan, 2014). While
any empirical analysis must be considered with caution, some interesting stylized facts about the current state and evolution
of the hedge fund industry do exist in these data.
All hedge fund data is monthly and come from Lipper TASS. In total, the database reports on 17,534 live and defunct
funds. Data are from 1994-2015, as no data was kept on defunct funds before 1994. A significant portion of this total consists
of the same fund reported in different currency and thus are not representative of independent fund strategies (Bali, Brown,
and Caglayan, 2014). Therefore, we limit the sample to only U.S.-based hedge funds and remove funds of funds. This limits
the sample size to 10,305 funds. As the focus is to gain insight into the division between fundamental and quantitative strategy
in the market, We further limit the sample to the 7093 funds who explicitly possess these characteristics, described below.
Firms are born and die regularly throughout the sample. There are never more than 3000 existing, qualifying funds at any
point in time. By the end of 2015, there were just over 1000 qualifying funds.
Lipper TASS records data on each fund‚Äôs investment strategies. In total, there are 18 different classifications and most
of these classifications have qualities of both fundamental and quantitative analysis. An example of a strategy that could
be considered both, ‚ÄúMacro: Active Trading strategies utilize active trading methods, typically with high frequency position
turnover or leverage; these may employ components of both Discretionary and Systematic Macro strategies.‚Äù However, 4
strategy classifications explicitly denote fund strategy as being fundamental or quantitative. They are:
‚Ä¢ Fundamental: This denotes that the fund‚Äôs strategy is explicitly based on fundamental analysis.
‚Ä¢ Discretionary: This denotes that the fund‚Äôs strategy is based upon the discretion of the fund‚Äôs manager(s).
‚Ä¢ Technical: This denotes that the fund deploys a technical strategy.
‚Ä¢ Systematic Quant: This denotes that funds deploy technical/algorithmic strategy.
Using these classifications, it is possible to divide hedge fund strategy into three broad groups:
‚Ä¢ Fundamental: Those funds whose strategy is classified as fundamental and/or discretionary, and not technical and/or
sytematic quant.
‚Ä¢ Quantitative: Those funds whose strategy is classified as technical and/or systematic quant, and not technical and/or
sytematic quant.
‚Ä¢ Mixture: Those funds whose strategy is classified as having at least one of fundamental or discretionary and at least
one of technical or systematic quant.

47

From 2000-2015, the assets under management (AUM) has systematically shifted away from fundamental firms to firms that
deploy some sort of quantitative analysis in their investment approach. In mid-2000, the assets under management per
fundamental firm was roughly 8 times the size of that in a quantitative or mixture firm, but this had equalized by 2011,
representing a true shift away from fundamental analysis and towards quantitative analysis in the hedge fund industry.

48

